

# 第一章：理解生成式AI：入门

在他影响深远的著作《奇点临近》（2005年）中，著名发明家和未来学家雷·库兹韦尔断言，我们正处于技术进步指数级加速的边缘。他设想了一个未来，其中技术创新将继续加速，最终导致一个**奇点**——一个**人工智能**（AI）能够超越人类智能、模糊人类与机器之间界限的点。快进到今天，我们发现自己在沿着库兹韦尔描绘的轨迹前进，生成式AI标志着这一路径上的重大进步。今天，我们正经历着最先进的生成模型能够作为协作伙伴，具备合成理解和生成反映人类智能的复杂响应。生成方法的快速和指数级增长正在推动库兹韦尔愿景的实现，从根本上重塑了我们与技术互动的方式。

在本章中，我们为任何希望将生成式AI应用于其工作、研究或研究领域的人打下概念基础，扩展了对这项技术做什么、它是如何产生的以及如何使用的根本理解。它阐述了生成模型与经典**机器学习**（ML）范式之间的区别，并阐明了它们如何识别数据中的复杂关系和独特性，以合成类似人类的文本、音频和视频。我们将探讨关键的基础生成方法，如生成对抗网络（GANs）、扩散模型和变换器，并特别强调它们的实际应用。

此外，本章还希望消除围绕生成式AI的一些常见误解，并提供采用这项新兴技术的道德指南，考虑到其环境影响，并倡导负责任的发展和采用。我们还将强调生成模型在解决商业挑战方面的适用场景。到本章结束时，我们将更好地理解生成式AI的潜力及其在广泛领域的应用，并批判性地评估了风险、局限性和长期考虑。

无论你的兴趣是业余的，你是在从不同领域过渡的专业人士，还是数据科学或ML领域的资深从业者，本章都提供了对生成式AI负责任采用的有益理解，以做出明智的决定。

最终，我们希望通过介绍生成式AI和**大型语言模型**（LLMs）的入门探索来建立一个基础，分为两部分。

书的开头将介绍生成式AI的基础和历史，概述各种类型，例如生成对抗网络（GANs）、扩散器（diffusers）和转换器（transformers），追溯**自然语言生成**（**NLG**）的基础，并展示从原型到生产的实现生成模型的基本步骤。接下来，我们将关注稍微更高级的应用基础，包括微调生成模型、提示工程以及针对生成AI负责任采用的伦理考量。让我们开始吧。

# 生成式AI

在最近几十年里，人工智能取得了惊人的进步。该领域的起源可以追溯到精心设计的经典统计模型，旨在帮助我们分析和理解数据。随着我们开发了更强大的计算方法来处理和存储数据，该领域发生了转变——交汇于计算机科学和统计学，为我们带来了机器学习（ML）。ML系统可以从大量数据中学习复杂关系并揭示潜在见解，从而改变我们统计建模的方法。

这种转变为深度学习的兴起奠定了基础，这是一次实质性的进步，它引入了多层神经网络（即相互连接的函数系统）来模拟复杂模式。深度学习使强大的判别式模型成为各个研究领域进步的关键，包括图像识别、语音识别和自然语言处理。

然而，随着生成式AI的出现，旅程仍在继续。生成式AI利用深度学习的力量来实现更广泛的目标。它不是对数据进行分类和区分，而是寻求学习和复制数据分布，以“创建”全新且看似原创的数据，类似于人类的输出。

# 区分生成式AI与其他AI模型

再次强调，判别式模型和生成式模型之间的关键区别在于它们的目标。判别式模型旨在根据输入数据预测目标输出。例如，分类算法，如逻辑回归或支持向量机，在数据中找到决策边界，将输入分类为一类或多类。神经网络通过反向传播（或回溯以解决错误）优化权重，学习输入输出映射，以做出准确的预测。高级梯度提升模型，如XGBoost或LightGBM，通过采用决策树和结合梯度提升（或模型的战略集成）的原则，进一步增强了这些判别式模型，以做出高度准确的预测。

生成式方法通过广泛的训练学习复杂关系，以生成新的数据序列，从而实现许多下游应用。实际上，这些模型通过复制在训练数据中发现的数据的统计模式和属性来创建合成输出，捕捉细微差别和独特性，这些与人类行为紧密相关。

在实践中，判别性图像分类器为包含猫或狗的图像贴标签。相比之下，生成模型可以通过学习现有图像中的像素分布和隐含特征来合成多样化的、逼真的猫或狗图像。此外，生成模型可以在不同模态上进行训练，以在以合成为重点的应用中解锁新的可能性，生成类似人类的照片、视频、音乐和文本。

有几种关键方法构成了许多最近在生成式人工智能领域进步的基础，每种方法都有独特的方法和优势。在下一节中，我们将回顾生成式进步的历史，包括对抗网络、变分自编码器、扩散模型和自回归转换器，以更好地理解它们的影响和影响。

## 简要概述生成方法

现代生成式建模涵盖了适用于不同数据类型和不同任务的多样化架构。在此，我们简要介绍了一些年来涌现的关键方法，使我们达到了最先进的模型：

+   **生成对抗网络（GANs**）涉及两个相互连接的神经网络——一个作为生成器以创建逼真的合成数据，另一个作为判别器以区分真实和合成（伪造）数据点。生成器和判别器在**零和游戏**中是竞争对手，每个都在努力超越对方。这种对抗关系逐渐提高了生成器产生生动逼真合成数据的能力，使GANs擅长创建复杂的图像分布并实现照片级图像合成。

+   **变分自编码器（VAEs**）采用独特的学习方法将数据压缩成更简单的形式（或潜在表示）。这个过程涉及一个编码器和一个解码器共同工作（Kingma & Welling, 2013）。虽然VAEs可能不是图像质量的最佳选择，但它们在有效地分离和理解复杂数据模式方面是无与伦比的。

+   **扩散模型**在多个步骤中持续向数据添加高斯噪声以破坏它。高斯噪声可以被视为应用于信号以扭曲它的随机变化，从而产生“噪声”。扩散模型经过训练以消除添加的噪声以恢复原始数据分布。这种逆向工程过程使扩散模型能够生成多样化、高质量且与原始数据分布紧密相似的样本，产生多样化的高保真图像（Ho et al., 2020）。

+   **自回归转换器**利用可并行化的自注意力来建模复杂的序列依赖关系，在语言相关任务中表现出卓越的性能（Vaswani等人，2017年）。预训练模型如GPT-4或Claude已经展示了在自然语言任务中进行泛化的能力以及令人印象深刻的人似文本生成。尽管存在伦理问题和滥用担忧，但转换器已成为语言建模和多模态生成领域的领跑者。

总体而言，这些方法为在包括图像、视频、音频和文本在内的广泛领域的高级生成建模铺平了道路。尽管架构和工程创新每天都在进步，但生成方法在多种模态上展示了无与伦比的合成能力。在本书中，我们将探索和应用生成方法来模拟现实世界场景。然而，在深入探讨之前，我们通过解决一些常见的误解来进一步区分生成方法和传统机器学习方法。

## 阐明判别和生成范式之间的误解

为了更好地理解传统机器学习模型（通常称为判别模型）和生成方法的独特能力和应用，在此，我们澄清一些常见的误解和神话：

**神话1**：生成模型在识别模式方面的效果不如判别模型有效。

**真相**：最先进的生成模型以其令人印象深刻的能力而闻名，能够识别和追踪模式，与一些判别模型相媲美。尽管主要关注创造性合成，但生成模型也显示出分类能力。然而，生成模型输出的类别可能难以解释，因为生成模型并非明确训练来学习决策边界或预定的关系。相反，它们可能只学会根据在训练过程中隐式（或自然）学习的标签来模拟分类。简而言之，在模型结果解释重要的情况下，使用判别模型进行分类可能是更好的选择。

**示例**：以GPT-4为例。除了合成类似人类的文本外，它还能理解上下文，捕捉长距离依赖关系，并在文本中检测模式。GPT-4利用这些固有的语言处理能力来区分类别，例如传统分类器。然而，由于GPT通过大量训练学习语义关系，其决策过程的解释无法使用任何既定方法完成。

**神话2**：生成AI最终将取代判别AI。

**真相**：这是一个常见的误解。判别模型一直是高风险预测任务的首选，因为它们直接专注于学习类别之间的决策边界，确保高精度和可靠性。更重要的是，判别模型可以进行事后解释，这使得它们成为医疗、金融和安全等关键领域应用的最终选择。然而，随着可解释性技术的出现，生成模型可能会越来越受欢迎，用于高风险建模。

**示例**：考虑一个专门用于医疗疾病预测的判别模型。一个专门的模型可以将数据点（例如，皮肤图像）分类为健康或不健康，为医疗专业人员提供早期干预和治疗计划的工具。可以使用事后解释方法，如SHAP，来识别和分析影响分类结果的关键特征。这种方法提供了对具体结果（即特征归因）的清晰见解。

**神话3**：生成模型持续从用户输入中学习。

**真相**：并不完全是这样。生成型大型语言模型使用的是静态方法进行训练。这意味着它们从庞大的训练数据集中学习，其知识仅限于训练窗口内的信息。虽然可以通过添加额外的数据或上下文信息来增强模型，以帮助它们进行上下文化，给人一种实时学习的印象，但底层模型本身基本上是冻结的，不会实时学习。

**示例**：GPT-3于2020年训练，并且只包含到那时为止的信息，直到其继任者GPT-3.5在2023年3月发布。自然地，GPT-4是在更近期的数据上训练的，但由于训练限制（包括性能回报递减），可以合理地预期后续的训练检查点将定期发布，而不是持续不断地发布。

虽然生成模型和判别模型具有不同的优势和局限性，但知道何时应用每个范例需要评估几个关键因素。既然我们已经澄清了一些关于它们能力的常见误解，让我们将注意力转向为特定任务或问题选择正确方法的指南。

## 选择正确的范例

在生成模型和判别模型之间进行选择取决于各种因素，例如手头的任务或问题、可用数据的数量和质量、期望的输出以及所需的性能水平。以下是一个关键考虑因素的列表：

+   **任务特异性**：判别模型更适合高风险应用，如疾病诊断、欺诈检测或信用风险评估，在这些应用中，精度至关重要。然而，生成模型在合成图像、文本、音乐或视频等创造性任务上更为擅长。

+   **数据可用性**：判别模型在训练于小数据集时往往会过拟合（或记忆示例），这可能导致泛化能力差。另一方面，由于生成模型通常在大量数据上预训练，即使输入最小，它们也能产生多样化的输出，这使得它们在数据稀缺时成为一个可行的选择。

+   **模型性能**：在需要学习和解释类别之间的决策边界或数据中的预期关系被充分理解的任务中，判别模型优于生成模型。生成模型通常在不太受约束的任务中表现出色，这些任务需要一定程度的感知创造性和灵活性。

+   **模型可解释性**：虽然两种范式都可以包括被认为是“黑盒”或本质上不可解释的模型，但生成模型可能更难以解释，有时甚至不可能解释，因为它们通常涉及复杂的数据生成过程，这些过程依赖于理解潜在的数据分布。另一方面，判别模型通常专注于学习类别之间的边界。在使用模型可解释性是关键要求的用例中，判别模型可能更合适。然而，生成模型的可解释性研究正在取得进展。

+   **模型复杂性**：通常，判别模型需要的计算能力更少，因为它们学会直接预测给定一组明确定义的输入的一些输出。

    另一方面，生成模型可能消耗更多的计算资源，因为它们的训练目标是同时捕捉输入和假设输出之间复杂的隐藏关系。准确学习这些复杂性需要大量的数据和大量的计算。在生成型大型语言模型训练中的计算效率（例如，量化）是一个充满活力的研究领域。

最终，在生成模型和判别模型之间做出选择，应该考虑到所涉及的权衡。此外，采用这些范式需要不同层次的基础设施、数据整理和其他先决条件。偶尔，结合两种模型优势的混合方法可以作为一个理想的解决方案。例如，一个预训练的生成模型可以被微调为一个分类器。我们将在[*第五章*](B21773_05.xhtml#_idTextAnchor180)中学习关于特定任务微调的内容。

现在我们已经探讨了传统机器学习（即判别范式）和生成范式之间的关键区别，包括它们各自的风险，我们可以回顾一下我们是如何到达这个范式转变的。在下一节中，我们将简要回顾生成人工智能的演变。

# 回顾生成人工智能的演变

生成式AI领域经历了前所未有的加速，导致像GPT这样的基础模型的发展和采用激增。然而，这种势头已经持续了几十年，由机器学习和自然语言生成研究中的持续和重大进步所驱动。这些发展使我们达到了当前最先进的模型时代。

要充分理解当前生成式AI的状态，了解其演变过程至关重要，从传统的语言处理技术开始，过渡到更近期的进步。

## NLP传统方法的概述

**自然语言处理**（**NLP**）技术使机器能够理解、解释和生成人类语言。它起源于传统的统计技术，如n-gram和**隐马尔可夫模型**（**HMMs**），这些技术将语言结构转换为机器可以理解的数学模型。

最初，n-gram和HMMs是NLP中使用的首要方法。N-gram根据序列中的最后“*n*”个词预测序列中的下一个词，而HMMs通过将每个词视为马尔可夫过程中的一个状态来模拟序列。这些早期方法擅长捕捉语言中的局部模式和短距离依赖关系。

随着计算能力和数据可用性的增长，自然语言处理出现了更复杂的技术。其中之一是**循环神经网络**（**RNN**），它能够管理跨越扩展序列的关系，并在先前上下文影响未来预测的任务中证明其有效性。

随后，**长短期记忆网络**（**LSTMs**）被开发出来。

与传统的RNNs不同，LSTMs具有独特的保留相关长期信息的同时忽略无关数据的能力，在长期序列中维持语义关系。

进一步的进步导致了序列到序列模型的引入，这些模型通常使用LSTMs作为其底层结构。这些模型通过显著提高效率和有效性，在机器翻译和文本摘要等领域实现了革命性的变革。

总体而言，NLP从传统的统计方法发展到高级神经网络，改变了我们与机器互动的方式，并使无数应用成为可能，例如机器翻译和信息检索（IR）（或根据查询查找相关文本）。随着NLP领域的成熟，结合了传统统计方法和高级神经网络的优势，一场文艺复兴正在形成。下一代NLP的进步将引入Transformer架构，从开创性的论文《Attention is All You Need》开始，随后是BERT和GPT等模型的发布。

## 基于Transformer模型的到来和演变

2017年发布的名为《Attention is All You Need》的研究论文，在自然语言处理领域引发了范式转变。这篇关键论文介绍了转换器模型，这是一种架构创新，为序列语言任务，如翻译，提供了一种前所未有的方法。转换器模型与先前按顺序处理序列的模型形成对比。相反，它同时处理输入序列的不同部分，根据任务确定其相关性。这种创新的处理方法解决了序列中长期依赖关系的复杂性，使模型能够提取完成任务所需的临界语义信息。转换器是一个如此关键的进步，以至于几乎每个最先进的生成型LLM都应用了原始架构的某种变体。其重要性和影响力促使我们对原始转换器进行了详细的探索和实现，详见[*第3章*](B21773_03.xhtml#_idTextAnchor081)。

随着转换器的出现，自然语言处理领域取得了重大进步，包括GPT-1或生成预训练转换器1（Radford等，2018）。GPT-1引入了一种新颖的方向性架构来解决各种NLP任务。

与GPT-1同时出现的是**BERT**，或称为**双向编码器表示从转换器**，这是基于转换器模型家族的开创性工作。BERT在它的前辈中脱颖而出，它正向和反向（或双向）分析句子。这种双向分析使BERT能够更有效地捕捉语义和句法细微差别。在当时，BERT在应用于复杂自然语言任务，如命名实体识别、问答和情感分析时，取得了前所未有的成果（Devlin等，2018）。

后来，GPT-2，作为GPT-1的更大继任者，引起了极大的关注，因为它在各种任务上大大超越了其所有前辈。事实上，GPT-2在生成类似人类输出的能力上如此前所未有，以至于对其潜在影响的担忧导致了其最初发布的延迟（Hern，2019）。

在早期担忧之后，OpenAI继续开发了GPT-3，这标志着LLM潜力的飞跃。开发者展示了在巨大规模上训练的潜力，达到了1750亿个参数（或训练期间学习的可调整变量），超过了其两个前辈。GPT-3是一个“通用”的学习者，能够执行从其训练语料库中隐式学习到的广泛自然语言任务，而不是通过特定任务的微调。这种能力引发了在各个领域和任务中开发基础模型用于通用用途的探索。GPT-3的独特设计和前所未有的规模导致了一代生成模型的出现，这些模型能够隐式地通过其广泛的训练执行无限数量的越来越复杂的下游任务。

## GPT-4的开发和影响

GPT-4的发展标志着在大型、多模态模型潜力方面取得了重大进步。GPT-4能够处理图像和文本输入并生成文本输出，代表了在先前的模型之上的又一次巨大飞跃。

GPT-4在各种专业和学术基准测试中展现了人类水平的表现。例如，它通过了一场模拟的律师资格考试，得分位于测试者前10%（OpenAI，2023）。

GPT-4的一个关键区别在于预训练之后发生的事情。OpenAI应用了**带有人类反馈的强化学习**（**RLHF**）——这是一种从用于教授自动驾驶汽车根据其遇到的环境做出决策的技术中衍生出来的风险/奖励训练。在GPT-4的情况下，模型学会了适当地对各种场景做出反应，并在过程中结合了人类反馈。这种新颖的改进策略极大地提高了模型的事实性和对期望行为的遵守。RLHF的集成展示了模型如何更好地与人类的判断相一致，以实现负责任的AI的目标。

然而，尽管展示了开创性的能力，GPT-4与早期的GPT模型具有类似的局限性。它并不完全可靠，并且具有有限的上下文窗口（或输入大小）。这意味着它不能接收大文本或文档作为输入。它也容易产生幻觉。正如讨论的那样，幻觉是一种拟人化的描述，指模型倾向于生成不基于事实或现实的內容。幻觉的发生是因为生成式语言模型（未经增强）纯粹基于语义上下文合成内容，而不进行任何逻辑处理以验证事实性。这种弱点带来了有意义的风险，尤其是在基于事实的结果至关重要的环境中。

尽管存在局限性，GPT-4在语言模型性能上取得了重大进展。与之前的模型一样，GPT-4的开发和潜在用途强调了未来AI应用中安全和伦理考虑的重要性。因此，GPT-4的兴起加剧了关于部署如此强大模型潜在影响的持续讨论和研究。在下一节中，我们将简要概述一些仅与生成式AI相关的已知风险。

# 展望风险和影响

生成式和判别式AI都引入了独特的风险和收益，这些必须仔细权衡。然而，生成式方法不仅能够继承，还能加剧许多与传统机器学习相关的风险，同时也会引入新的风险。因此，在我们能够在现实世界和大规模上采用生成式AI之前，理解这些风险并建立负责任的治理原则以帮助减轻这些风险是至关重要的：

+   **幻觉**：这是一个广泛使用的术语，用来描述模型生成事实不准确信息的情况。生成模型擅长在没有事实依据的情况下产生听起来合理的输出。因此，用事实信息来定位生成模型至关重要。术语“定位”指的是在模型输入中附加已知为事实的额外信息。我们在[*第七章*](B21773_07.xhtml#_idTextAnchor225)中探讨了定位技术。此外，制定一个包括人工审查在内的评估模型输出的策略也是必不可少的。

+   **剽窃**：由于生成模型有时是在未经许可的数据集上训练的，一些训练语料库可能包括未经明确许可的数据。模型可能会产生受版权保护的信息或可以声称为知识产权的信息。

+   **意外记忆**：与许多在大量语料库上训练的机器学习模型一样，生成模型倾向于记住训练数据的一部分。特别是，它们容易记住那些不适合更广泛模式的不常见示例。在某些情况下，模型可能会记住可以提取和暴露的敏感信息（Brundage等人，2020年；Carlini等人，2020年）。因此，无论是消费预训练模型还是微调（即继续模型训练），训练数据的选择至关重要。

+   **毒性和偏见**：大规模模型训练的另一个副作用是模型不可避免地会学习训练数据中嵌入的社会偏见。偏见可能表现为生成文本或图像中的性别、种族或社会经济偏见，通常复制或放大刻板印象。我们在[*第八章*](B21773_08.xhtml#_idTextAnchor251)中详细介绍了这种风险的缓解措施。

对于一些风险的理解，我们将关注采用生成式AI的微妙影响：

+   **伦理**：正如所讨论的，这些模型不可避免地会学习和复制训练数据中固有的偏见，引发严重的伦理问题。同样，由于模型容易记住和暴露其训练数据，数据隐私和安全问题也出现了。这导致了对于强有力的伦理指南和数据隐私法规的呼吁（Gebru等人，2018年）。

+   **环境**：大型语言模型（LLM）是计算巨人，需要前所未有的资源进行训练和实施。因此，它们不可避免地会产生环境影响。训练一个LLM所需的能源消耗会产生大量的二氧化碳排放——大约相当于五辆汽车终身的排放量。因此，正在进行多项工作以提高模型效率并减少碳足迹。例如，如减少位精度训练（或量化）和参数高效微调（在第[*第五章*](B21773_05.xhtml#_idTextAnchor180)中讨论）等技术可以减少整体训练时间，有助于缩小碳足迹。

+   **社会**： 除了环境影响，大型语言模型（LLMs）也具有社会影响。随着这些模型在生成文本、模拟智能对话和自动化基本任务方面变得熟练，它们为自动化工作提供了前所未有的机会。由于各种复杂因素，这种在美国大规模自动化的潜力可能会不成比例地影响边缘化或代表性不足的社区。因此，这加剧了关于劳动权利和需要额外保护以最小化伤害的先前担忧。

+   **商业与劳动力**： 除了更广泛的社会经济影响，我们还必须考察对商业部门的直接影响。虽然生成式人工智能开辟了新的机会，但如果处理不当，劳动力市场的变化可能会带来巨大的破坏。除了劳动力影响之外，人工智能的进步也显著影响了各个商业部门。它们可能导致新角色的创造、商业模式的改变和机会的产生，需要持续的治理策略和以包容性、道德和负责任采用为中心的探索框架。

应对这些挑战需要技术、科学上的改进，针对特定数据的法规和法律，道德规范，以及以人为本的人工智能治理策略。这些都是构建一个公平、安全、包容的人工智能驱动未来的关键。

在讨论了生成式人工智能的历史、风险和限制之后，我们现在更有能力探索这种变革性技术的广泛机会和应用。

# 介绍生成式人工智能的应用案例

生成式人工智能已经开始颠覆各个行业。这项技术正在许多学科中掀起波澜，从增强基于语言的任务到重塑数字艺术。以下部分提供了生成式人工智能在不同行业中的实际应用示例：

+   **传统自然语言处理**： 如Open AI的GPT系列等大型语言模型（LLMs）已经提升了传统的自然语言处理（NLP）和自然语言生成（NLG）。正如所讨论的，这些模型具有生成连贯、相关且类似人类文本的独特能力。这些模型的可能性在GPT-3在多个语言任务中优于经典和现代方法时得到了证明，展示了人类语言前所未有的理解。GPT-4和Claude 3的发布标志着另一个里程碑，将最先进模型的标准进一步提高。

+   **数字艺术创作**： “生成艺术”的出现是生成式人工智能在数字艺术领域产生激进影响的证据。例如，艺术家可以使用人工智能生成模型来创建复杂的设计，从而让他们专注于艺术的概念性方面。这简化了过程，减少了高级技术专长的需求。

+   **音乐创作**: 在音乐产业中，生成式人工智能可以增强创作过程。几个平台提供了高质量的AI驱动音乐创作工具，可以生成结合不同时代和流派的音乐风格的长期音乐作品。

+   **简化业务流程**: 一些企业已经开始采用生成式人工智能来使流程更快、更高效。生成式人工智能带来的运营效率使员工能够专注于更具战略性的任务。例如，完全集成的LLM电子邮件客户端可以组织电子邮件，并且（与其他技术结合）随着时间的推移学会优先处理关键电子邮件。

+   **娱乐**: 尽管仍处于实验阶段，但大型语言模型（LLMs）在颠覆创意写作和叙事方面展现出有希望的潜力，尤其是在游戏行业。例如，程序化游戏可以利用LLMs来增强动态叙事，并创造更具吸引力和个性化的用户体验。随着技术的进步，我们可能会看到LLMs在游戏领域的更广泛采用，为互动叙事开辟新的可能性。

+   **时尚**: 在时尚产业中，生成模型帮助设计师进行创新。通过使用最先进的生成式人工智能模型，设计师可以通过简单地调整几个配置来创建和可视化新的服装风格。

+   **建筑和施工**: 在建筑领域，生成增强工具可以帮助建筑师和城市规划师优化和生成设计方案，从而实现更高效和可持续的建筑设计。

+   **食品行业**: 新兴的AI驱动烹饪助手可以生成独特的食物组合、新颖的食谱以及针对高度特定饮食需求的修改食谱。

+   **教育**: 生成式人工智能增强的教育平台可以自动创建学习辅助工具，这些工具可以促进个性化的学习体验，并自动生成定制内容以适应特定的和多样化的学习风格。

然而，我们必须在机会的广度与复杂的约束之间取得平衡，并持续推广道德使用。作为数据科学家、政策制定者和行业领导者，我们必须继续努力营造有利于负责任AI部署的环境。尽管如此，随着生成式人工智能的持续发展，它带来了充满新颖创新和应用的未来。

# 生成式人工智能应用的未来

生成式人工智能不懈的进步预示着一个充满可能性和复杂挑战的未来。想象一个未来，一个基于世界领先的气候变化研究训练的生成模型可以提供实际且具有突破性的应对策略，并精确地提供其应用的详细信息。

然而，随着我们拥抱越来越以AI为中心的未来，我们不应忽视现有的挑战。这些挑战包括AI工具的潜在误用、不可预测的后果以及AI采用背后的深刻伦理考量。此外，可持续和环保的发展至关重要，因为训练大规模模型可能需要大量资源。

在加速进步的时代，所有利益相关者之间的合作——从数据科学家、AI爱好者、政策制定者到行业领导者——是至关重要的。通过配备全面的监督、稳健的指导方针和战略教育计划，共同努力可以保障一个生成式AI无处不在的未来。

尽管存在这些障碍，生成式AI的变革潜力依然无可置疑。凭借其重塑行业、重新定义社会基础设施以及改变我们的生活方式、学习和工作方式的能力，生成式AI提醒我们，我们正处于一个关键时刻——这是一个由数十年的科学研究和技术创新推动的时刻，这些创新正在汇聚起来，推动我们作为一个社会向前发展。

# 摘要

在本章中，我们追踪了生成式AI的演变，将其与传统机器学习区分开来，探讨了其演变过程，讨论了其风险和影响，并希望消除一些常见的误解。我们考虑了一些基于其负责任采用的考虑的潜在可能性。

随着我们进入下一章，我们将探讨生成式AI背后的基本架构，这将为我们提供对关键生成方法的基础理解，包括生成对抗网络（GANs）、扩散模型和转换器。这些机器学习方法构成了生成式AI的骨架，并在带来今天我们所看到的惊人进步中发挥了关键作用。

# 参考文献

本参考部分作为本书中引用的资源的存储库；您可以探索这些资源，以进一步加深对主题的理解和知识：

+   [https://doi.org/10.1007/s11023-020-09526-7https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction](https://doi.org/10.1007/s11023-020-09526-7https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction)

)

+   Brundage, M., Avin, S., Clark, J., Toner, H., Eckersley, P., Garfinkel, B., Dafoe, A., Scharre, P., Zeitzoff, T., Filar, B., Anderson, H., Roff, H., Allen, G. C., Steinhardt, J., Flynn, C., Ó hÉigeartaigh, S., Beard, S., Belfield, H., Farquhar, S., & Amodei, D. (2018). *人工智能的恶意使用：预测、预防和缓解*. arXiv [cs.AI]. [http://arxiv.org/abs/1802.07228](http://arxiv.org/abs/1802.07228).

+   Carlini, N., Tramer, F., Wallace, E., Jagielski, M., Herbert-Voss, A., Lee, K., Roberts, A., Brown, T., Song, D., Erlingsson, U., Oprea, A., & Raffel, C. (2020). *从大型语言模型中提取训练数据*. arXiv [cs.CR]. [http://arxiv.org/abs/2012.07805](http://arxiv.org/abs/2012.07805).

+   Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2018). *BERT：用于语言理解的深度双向Transformer预训练*. arXiv [cs.CL]. [http://arxiv.org/abs/1810.04805](http://arxiv.org/abs/1810.04805).

+   Hagendorff, T. (2020). 对 *AI伦理的伦理：指南评估* 的出版商更正. *心智与机器*, 30(3), 457–461\. [https://doi.org/10.1007/s11023-020-09526-7](https://doi.org/10.1007/s11023-020-09526-7).

+   Hern, A. (2019, February 14). *新的AI假文本生成器可能过于危险而无法发布，开发者表示*. *《卫报》*. [https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction](https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction).

+   Ho, J., Jain, A., & Abbeel, P. (2020). *去噪扩散概率模型*. arXiv [cs.LG]. [http://arxiv.org/abs/2006.11239](http://arxiv.org/abs/2006.11239).

+   Kaplan, J., McCandlish, S., Henighan, T., Brown, T. B., Chess, B., Child, R., Gray, S., Kingma, D. P., & Welling, M. (2013). *自编码变分贝叶斯*. arXiv [stat.ML]. [http://arxiv.org/abs/1312.6114](http://arxiv.org/abs/1312.6114).

+   Muhammad, T., Aftab, A. B., Ahsan, M. M., Muhu, M. M., Ibrahim, M., Khan, S. I., & Alam, M. S. (2022). *基于Transformer的深度学习模型用于股票价格预测：孟加拉国股票市场案例研究*. arXiv [q-fin.ST]. [http://arxiv.org/abs/2208.08300](http://arxiv.org/abs/2208.08300).

+   OpenAI. (2023). *GPT-4技术报告*. arXiv [cs.CL]. [http://arxiv.org/abs/2303.08774](http://arxiv.org/abs/2303.08774).

+   Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2018). *语言模型是无监督的多任务学习者*.

+   Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., & Polosukhin, I. (2017). *Attention Is All You Need*. arXiv [cs.CL]. [http://arxiv.org/abs/1706.03762](http://arxiv.org/abs/1706.03762).
