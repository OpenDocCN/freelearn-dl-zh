# 前言

通过本书，我们开始探索**大型语言模型（LLMs**）及其在**人工智能（AI**）领域所代表的变革范式。这本全面指南帮助您深入了解这些尖端技术的根本概念，从这些技术的坚实基础理论到 LLMs 提供的实际应用，最终聚焦于使用生成式 AI 解决方案时的伦理和责任考量。本书旨在为您提供对市场上新兴的 LLMs 如何影响个人、大型企业和社会的深刻理解。它侧重于如何构建由 LLMs 驱动的强大应用，利用新的 AI 编排器如 LangChain，并揭示现代应用开发中的新趋势。

在本书结束时，您将能够更轻松地导航快速发展的生成式 AI 解决方案生态系统；此外，您将拥有在日常工作以及商业中充分利用 LLMs 的工具。让我们开始吧！

# 本书面向对象

本书旨在主要吸引具有一定 Python 代码基础的技术受众。然而，理论章节和动手实践基于生成式 AI 基础和行业引领的用例，这也可能对非技术受众产生兴趣。

总体而言，本书面向那些希望全面了解大型语言模型（LLMs）的变革力量及其定义，并能够自信且前瞻性地在快速发展的 AI 领域中导航的个体。所有类型的读者都欢迎，但从中受益最大的读者包括：

+   **软件开发人员和工程师**：本书为希望利用 LLMs 构建应用的开发者提供实用指导。它涵盖了将 LLMs 集成到应用后端、API、架构等方面的内容。

+   **数据科学家**：对于有兴趣将 LLMs 部署到实际应用中的数据科学家，本书展示了如何将模型从研究阶段过渡到生产阶段。它涵盖了模型服务、监控和优化。

+   **AI/ML 工程师**：专注于 AI/ML 应用的工程师可以利用本书了解如何构建和部署 LLMs 作为智能系统和代理的一部分。

+   **技术创始人/CTO**：初创公司创始人和技术总监可以使用本书评估在其应用和产品中是否以及如何使用 LLMs。它提供了技术概述，并考虑了商业因素。

+   **学生**：攻读 AI、机器学习（ML）、**自然语言处理（NLP**）或计算机科学的研究生和高年级本科生可以通过本书了解 LLMs 在实际中的应用。

+   **LLM 研究人员**：致力于新型 LLM 架构、训练技术等工作的研究人员将获得对实际模型使用及其相关挑战的见解。

# 本书涵盖内容

*第一章*，*大型语言模型简介*，介绍了 LLMs，这是生成 AI 领域中一套强大的深度学习神经网络。它介绍了 LLMs 的概念，它们与经典机器学习模型的区别，以及相关术语。它还讨论了最受欢迎的 LLMs 的架构，进而探讨 LLMs 的训练和消费方式，并将基础 LLMs 与微调 LLMs 进行比较。到本章结束时，你将了解 LLMs 是什么以及它们在 AI 领域的定位，为后续章节打下基础。

*第二章*，*LLMs 在 AI 应用中的运用*，探讨了 LLMs 如何革命性地改变软件开发的世界，引领 AI 应用的新时代。到本章结束时，你将更清晰地了解 LLMs 如何嵌入不同的应用场景，借助目前 AI 开发市场中可用的新的 AI 编排框架。

*第三章*，*为你的应用选择 LLM*，强调了不同的 LLM 可能具有不同的架构、大小、训练数据、能力和限制。为你的应用选择正确的 LLM 不是一个简单的决定，因为它可以显著影响解决方案的性能、质量和成本。在本章中，我们将指导你选择适合你应用的正确 LLM 的过程。我们将讨论市场上最有前途的 LLMs，比较 LLMs 时使用的最主要标准和工具，以及大小和性能之间的各种权衡。到本章结束时，你应该清楚地了解如何为你的应用选择正确的 LLM 以及如何有效地和负责任地使用它。

*第四章*，*提示工程*，解释了为什么提示工程在设计 LLM 驱动的应用时是一项至关重要的活动，因为提示对 LLMs 的性能有巨大影响。实际上，有几种技术可以实现，不仅能够完善你的 LLM 的响应，还能降低与幻觉和偏见相关的风险。在本章中，我们将涵盖提示工程领域的最新技术，从基本方法到高级框架。到本章结束时，你将具备构建功能强大且稳固的提示的基础，这些提示对于即将到来的章节也将是相关的。

*第五章*，*在应用程序中嵌入 LLMs*，讨论了随着使用 LLMs 开发应用程序的出现而引入软件开发领域的新组件集。为了使在应用程序流程中编排 LLMs 及其相关组件更加容易，出现了几个 AI 框架，其中 LangChain 是最广泛使用之一。在本章中，我们将深入研究 LangChain 及其使用方法，并学习如何通过 Hugging Face Hub 调用开源 LLM API，以及如何管理提示工程。到本章结束时，你将拥有使用 LangChain 和开源 Hugging Face 模型开始开发 LLM 驱动应用程序的技术基础。

*第六章*，*构建对话式应用程序*，让我们通过第一个基于 LLMs 的应用程序的具体实现来开始本书的动手实践部分。在本章中，我们将逐步实现一个对话式应用程序，使用 LangChain 及其组件。我们将配置一个简单聊天机器人的架构，添加记忆组件、非参数化知识和使聊天机器人“有代理性”的工具。到本章结束时，你将能够仅用几行代码设置自己的对话式应用程序项目。

*第七章*，*使用 LLMs 的搜索和推荐引擎*，探讨了 LLMs 如何通过嵌入和生成模型来增强推荐系统。我们将讨论推荐系统的定义和演变，了解生成式 AI 如何影响这一研究领域，并学习如何使用 LangChain 构建推荐系统。到本章结束时，你将能够创建自己的推荐应用程序，并利用 LangChain 作为框架来利用最先进的 LLMs。

*第八章*，*使用 LLMs 处理结构化数据*，涵盖了 LLMs 的一个强大功能：处理结构化、表格数据的能力。我们将看到如何通过插件和有代理性的方法，我们可以将 LLMs 作为我们与结构化数据之间的自然语言界面，缩小业务用户与结构化信息之间的差距。为了演示这一点，我们将使用 LangChain 构建一个数据库助手。到本章结束时，你将能够为你的数据领域构建自己的自然语言界面，结合非结构化数据与结构化数据源。

*第九章*，*与代码一起工作*，涵盖了 LLMs 的另一个重要能力：与编程语言一起工作。在前一章中，我们已经看到了这种能力的一瞥，当时我们要求我们的 LLM 生成针对 SQL 数据库的 SQL 查询。在本章中，我们将探讨 LLMs 可以用代码以哪些其他方式使用，从“简单”的代码理解和生成到构建表现得像算法的应用程序。到本章结束时，你将能够为你的编码项目构建由 LLM 驱动的应用程序，以及构建具有自然语言界面的 LLM 驱动的应用程序来处理代码。

*第十章*，*使用 LLMs 构建多模态应用程序*，在构建代理的同时超越了 LLMs，引入了多模态的概念。我们将看到将不同 AI 领域的基座模型（语言、图像、音频）组合成一个单一代理的逻辑，该代理可以适应各种任务。你将学习如何使用 LangChain 构建一个多模态代理，使用单模态 LLMs。到本章结束时，你将能够构建自己的多模态代理，为其提供执行各种 AI 任务所需的工具和 LLMs。

*第十一章*，*微调大型语言模型*，涵盖了微调 LLMs 的技术细节，从其背后的理论到使用 Python 和 Hugging Face 的动手实现。我们将深入探讨如何准备你的数据以微调基础模型，以及讨论你的微调模型的托管策略。到本章结束时，你将能够使用自己的数据微调 LLM，以便构建由该 LLM 驱动的特定领域应用。

*第十二章*，*负责任的 AI*，介绍了减轻 LLMs（以及 AI 模型）潜在危害的学科基础——即负责任的 AI。这很重要，因为 LLMs 开启了新的风险和偏见的大门，这些风险和偏见在开发 LLM 驱动的应用程序时需要考虑。

然后，我们将转向与 LLMs 相关的风险以及如何使用适当的技术来预防或至少减轻它们。到本章结束时，你将更深入地了解如何防止 LLMs 使你的应用程序可能产生危害。

*第十三章*，*新兴趋势和创新*，探讨了生成 AI 领域的最新进展和未来趋势。

# 为了充分利用本书

本书旨在提供 LLMs 是什么、它们的架构以及为什么它们正在革命化 AI 领域的坚实基础理论。它采用了一种动手方法，为你提供了一步一步的指南，用于实现特定任务的 LLMs 驱动的应用程序，并使用像 LangChain 这样的强大框架。此外，每个示例都将展示不同 LLM 的使用，以便你可以欣赏它们的差异化特点以及何时使用适当的模型来完成特定任务。

总体而言，本书将理论概念与实际应用相结合，对于想要在 LLMs 及其在 NLP 中的应用中获得坚实基础的人来说，是一本理想的资源。以下先决条件将帮助您最大限度地利用本书：

+   对神经网络背后的数学（线性代数、神经元和参数以及损失函数）的基本理解

+   对机器学习概念的基本理解，例如训练集和测试集、评估指标和自然语言处理

+   对 Python 的基本理解

## 下载示例代码文件

本书代码包托管在 GitHub 上，网址为[`github.com/PacktPublishing/Building-LLM-Powered-Applications`](https://github.com/PacktPublishing/Building-LLM-Powered-Applications)。我们还有其他来自我们丰富图书和视频目录的代码包，可在[`github.com/PacktPublishing/`](https://github.com/PacktPublishing/)找到。查看它们吧！

## 下载彩色图像

我们还提供了一份包含本书中使用的截图/图表彩色图像的 PDF 文件。您可以从这里下载：[`packt.link/gbp/9781835462317`](https://packt.link/gbp/9781835462317)。

## 使用的约定

本书通篇使用了多种文本约定。

`CodeInText`：表示文本中的代码词汇、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 昵称。例如：“我设置了两个变量`system_message`和`instructions`。”

代码块设置为以下格式：

```py
[default]
$pip install openai == 0.28
import os
import openai
openai.api_key = os.environment.get('OPENAI_API_KEY')
response = openai.ChatCompletion.create(
    model="gpt-35-turbo", # engine = "deployment_name".
    messages=[
        {"role": "system", "content": system_message},
        {"role": "user", "content": instructions},
    ]
) 
```

任何命令行输入或输出都按以下方式编写：

```py
{'text': "Terrible movie. Nuff Said.[…]
 'label': 0} 
```

**粗体**：表示新术语、重要词汇或屏幕上看到的词汇。例如，菜单或对话框中的文字会像这样显示。例如：“[...]他发现重复提示末尾的主要指令可以帮助模型克服其内在的**近期偏差**。”

警告或重要提示如下所示。

技巧和窍门如下所示。

# 联系我们

我们欢迎读者的反馈。

**一般反馈**：请通过`feedback@packtpub.com`发送电子邮件，并在邮件主题中提及本书的标题。如果您对本书的任何方面有疑问，请通过`questions@packtpub.com`发送电子邮件给我们。

**勘误表**：尽管我们已经尽最大努力确保内容的准确性，但错误仍然可能发生。如果您在这本书中发现了错误，如果您能向我们报告，我们将不胜感激。请访问[`www.packtpub.com/submit-errata`](http://www.packtpub.com/submit-errata)，点击**提交勘误**，并填写表格。

**盗版**：如果您在互联网上以任何形式遇到我们作品的非法副本，如果您能提供位置地址或网站名称，我们将不胜感激。请通过`copyright@packtpub.com`与我们联系，并附上材料的链接。

**如果您有兴趣成为作者**：如果您在某个领域有专业知识，并且您有兴趣撰写或为书籍做出贡献，请访问[`authors.packtpub.com`](http://authors.packtpub.com)。

# 分享您的想法

一旦您阅读了《构建 LLM 驱动应用程序》，我们非常乐意听到您的想法！请[点击此处直接访问该书的亚马逊评论页面](https://packt.link/r/1835462316)并分享您的反馈。

您的评论对我们和科技社区非常重要，并将帮助我们确保我们提供高质量的内容。

# 下载本书的免费 PDF 副本

感谢您购买本书！

您喜欢在路上阅读，但无法携带您的印刷书籍到处走？

您选择的设备是否与您的电子书购买不兼容？

别担心，现在每购买一本 Packt 书籍，您都可以免费获得该书的 DRM 免费 PDF 版本。

在任何地方、任何设备上阅读。直接从您最喜欢的技术书籍中搜索、复制和粘贴代码到您的应用程序中。

优惠不止于此，您还可以获得独家折扣、时事通讯和丰富的免费内容，每天直接发送到您的邮箱。

按照以下简单步骤获取好处：

1.  扫描下面的二维码或访问以下链接：

![二维码图片](img/B21714_Free_PDF_QR.png)

[`packt.link/free-ebook/9781835462317`](https://packt.link/free-ebook/9781835462317)

1.  提交您的购买证明。

1.  就这些！我们将直接将免费 PDF 和其他好处发送到您的邮箱。
