# 10

# 生成模型的未来：超越扩展

在过去十年中，人工智能进步的主导范式一直是**扩展规模**——增加模型大小（参数数量）、扩大训练数据集，以及应用更多计算资源。这种方法带来了令人印象深刻的成果，每次模型规模的跃升都带来了更好的能力。然而，仅仅扩展规模正面临收益递减和日益增长的挑战，包括可持续性、可访问性以及解决基本的人工智能限制。生成式人工智能的未来在于超越简单的扩展，在于更高效的架构、专业的方法和混合系统，这些系统能够克服当前的局限性，同时使这些强大的技术更加民主化。

在本书中，我们探讨了使用生成式人工智能模型构建应用程序。我们关注代理人的核心地位，因为我们已经开发了可以在多个领域进行推理、规划和执行任务的自主工具。对于开发人员和数据科学家，我们已经展示了包括工具集成、基于代理的推理框架、RAG 和有效的提示工程等技术，所有这些技术都是通过 LangChain 和 LangGraph 实现的。随着我们探索的结束，考虑这些技术的含义以及快速发展的代理人工智能领域可能将我们引向何方是合适的。因此，在本章中，我们将反思生成模型的当前局限性——不仅限于技术层面，还包括它们引发的更大的社会和伦理挑战。我们将探讨解决这些问题的策略，并探索真正的价值创造机会所在——特别是在为特定行业和用例定制模型时。

我们还将考虑生成式人工智能对就业的影响，以及它如何重塑整个行业——从创意领域和教育到法律、医学、制造业甚至国防。最后，我们将探讨关于虚假信息、安全、隐私和公平的一些难题，并共同思考这些技术如何在现实世界中实施和监管。

本章我们将讨论的主要内容包括：

+   生成式人工智能的现状

+   扩展的局限性及新兴的替代方案

+   经济和行业转型

+   社会意义

# 生成式人工智能的现状

正如本书所讨论的，近年来，生成式人工智能模型在文本、图像、音频和视频等多种模态上生产类似人类内容方面取得了新的里程碑。像 OpenAI 的 GPT-4o、Anthropic 的 Claude 3.7 Sonnet、Meta 的 Llama 3 以及 Google 的 Gemini 1.5 Pro 和 2.0 等领先模型在内容生成方面表现出令人印象深刻的流畅性，无论是文本还是创意视觉艺术。

人工智能发展的一个转折点发生在 2024 年末，随着 OpenAI 的 o1 模型的发布，紧接着是 o3 模型的推出。这些模型代表了人工智能能力的一个根本性转变，尤其是在需要复杂推理的领域。与之前几代产品中看到的渐进式改进不同，这些模型在性能上实现了非凡的飞跃。它们在国际数学奥林匹克竞赛中取得了金牌级别的成绩，并在物理、化学和生物学问题上的表现与博士水平相当。

与 o1 和 o3 等较新模型区分开来的是，它们基于前一代的 transformer 架构的迭代处理方法。这些模型实现了研究人员描述为*递归*的计算模式，允许对信息进行多次处理，而不是仅仅依赖于单次正向传递。这种方法允许模型将额外的计算资源分配给更具挑战性的问题，尽管这仍然受限于其基本架构和训练范式。虽然这些模型为不同类型的输入集成了某些专门的注意力机制，但它们仍然在大规模、同质化的神经网络约束内运行，而不是真正的模块化系统。它们的训练方法已经超越了简单的下一个标记预测，包括对中间推理步骤的优化，尽管核心方法仍然基于统计模式识别。

市场推广的具有*推理能力*的模型的出现，暗示了这些系统处理信息方式的潜在演变，尽管仍然存在重大局限性。这些模型在特定的结构化推理任务上表现出改进的性能，并能跟随更明确的思维链条，尤其是在其训练数据中表现良好的领域内。然而，正如与人类认知的比较所表明的，这些系统在处理新领域、因果理解和真正新概念的发展方面仍然面临挑战。这代表了企业在利用人工智能技术方面的一个渐进式进步，而不是能力的一个根本性转变。探索这些技术的组织应实施严格的测试框架来评估其特定用例的性能，特别关注边缘情况和需要真正因果推理或领域适应的场景。

具有增强推理方法的模型显示出希望，但伴随着重要的局限性，这些局限性应指导商业实施：

+   **结构化分析方法**：最近的研究表明，这些模型可以遵循某些类型问题的多步推理模式，尽管将其应用于战略商业挑战仍然是一个活跃的探索领域，而不是一个确立的能力。

+   **可靠性考虑**：虽然逐步推理方法在某些基准任务上显示出希望，但研究表明，这些技术在某些情况下实际上可能会放大错误。

+   **半自主代理系统**：结合推理技术的模型可以减少人为干预执行一些任务，但当前的实现需要仔细监控和限制措施，以防止错误传播并确保与业务目标一致。

尤其值得注意的是代码生成能力的提升，这些推理模型不仅能编写代码，还能理解、调试和迭代改进它。这种能力预示着一个未来，AI 系统可能能够自主地创建和执行代码，本质上是通过编程自己来解决新问题或适应变化条件——这是迈向更通用人工智能的基本步骤。

基于推理方法的模型在潜在的商业应用方面具有重要意义，尽管目前更多地是抱负而非广泛实施。早期采用者正在探索可能帮助分析市场数据、识别潜在运营问题并通过结构化推理方法增强客户支持的 AI 助手系统。然而，这些实施仍然主要是实验性的，而不是完全自主的系统。

大多数当前的商业部署都集中在更窄、定义明确的任务上，并有人类监督，而不是像营销材料中有时描述的那样完全自主的场景。虽然研究实验室和领先的技术公司正在展示有希望的原型，但真正基于推理的复杂商业决策系统的广泛部署仍然是一个新兴的前沿领域，而不是一个成熟的实践。探索这些技术的组织应专注于受控的试点项目，并使用仔细评估的指标来评估真正的商业影响。

对于正在评估 AI 能力的企业来说，推理模型代表了将 AI 转变为可靠且适用于高价值商业应用工具的重大进步。这一进步将生成式 AI 从主要的内容创作技术转变为战略决策支持系统，能够增强核心业务运营。

这些推理能力的实际应用有助于解释为什么像 o1 这样的模型的发展在人工智能的演变中是一个关键时刻。正如我们将在后面的章节中探讨的，这些推理能力的影响在各个行业之间差异很大，一些行业可能比其他行业更快地受益。

区分这些推理模型的特点不仅在于它们的性能，还在于它们实现性能的方式。虽然之前的模型在多步推理上存在困难，但这些系统展示了构建连贯逻辑链、探索多种解决方案路径、评估中间结果和构建复杂证明的能力。广泛的评估揭示了与早期模型根本不同的推理模式——更类似于专家人类推理者的有意识问题解决方法，而不是统计模式匹配。

这些模型对我们讨论扩展规模最重要的方面是，它们的性能并非主要通过增加规模来实现。相反，它们代表了架构和训练方法的突破：

+   **高级推理架构**，支持递归思维过程

+   **过程监督学习**，评估和奖励中间推理步骤，而不仅仅是最终答案

+   **测试时计算分配**，允许模型对困难问题进行更长时间的思考

+   **自我博弈强化学习**，模型通过与自己竞争来提高

这些发展挑战了简单的扩展假设，通过展示定性架构创新和新的训练方法可以带来能力的跳跃式改进。这表明，AI 发展的未来可能更多地取决于模型的结构如何思考，而不是原始参数数量——这是我们将在扩展规模的局限性部分进一步探讨的主题。

下表追踪了 AI 系统在 25 年期间相对于人类性能在各种能力上的进展。人类性能作为基准（在垂直轴上设置为零），而每个 AI 能力的初始性能被归一化到-100。图表揭示了不同 AI 能力达到并超越人类水平性能的不同轨迹和时间表。注意预测推理的曲线特别陡峭，这表明这一能力仍处于快速发展阶段，而不是趋于平缓。阅读理解、语言理解和图像识别都在大约 2015 年至 2020 年之间超过了人类性能阈值，而手写和语音识别则更早达到了这一里程碑。

人类认知与生成式 AI 之间的比较揭示了几个在 2022 年至 2025 年之间尽管取得了显著进步但依然持续存在的根本性差异。以下是一个表格，总结了当前生成式 AI 与人类认知相比的关键优势和不足：

| **类别** | **人类认知** | **生成式 AI** |
| --- | --- | --- |
| **概念理解** | 建立在物理和社会经验基础上的因果模型；在统计模式之外建立有意义的概念关系 | 主要依赖统计模式识别，缺乏真正的因果理解；可以流畅地操作符号，但没有更深层次的语义理解 |
| **事实处理** | 将知识与显著认知偏差相结合；在保持生存功能可靠性的同时，容易受到各种推理错误的影响 | 产生自信但往往幻觉的信息；尽管检索增强，但难以区分可靠和不可靠的信息 |
| **自适应学习和推理** | 慢速掌握复杂技能但样本效率高；通过类比思维在不同领域间转移策略；可以从熟悉环境中的几个例子中推广 | 需要大量数据集进行初始训练；推理能力强烈受限于训练分布；越来越擅长情境学习，但在真正新颖的领域方面存在困难 |

|

**记忆和状态跟踪**

| 有限的短期记忆（4-7 个块）；尽管容量有限，但擅长跟踪相关状态；通过选择性注意进行补偿 | 理论上具有无限大的上下文窗口，但在跨场景中连贯跟踪对象和代理状态方面存在根本性困难 |
| --- | --- |
| **社会理解** | 通过具身经验自然发展他人心理状态模型；对社会动态有直观的理解，个体适应性各异 | 跟踪不同信念状态和社会动态的能力有限；需要专门的微调以实现基本的心智理论能力 |
| **创造性生成** | 生成超出先前经验的创新组合；创新基于重组，但可以推动概念边界 | 受限于训练分布；产生已知模式的变体而不是根本性的新概念 |
| **架构属性** | 模块化、分层组织，具有专用子系统；并行分布式处理，能源效率显著（约 20 瓦特） | 架构大体同质，功能专业化有限；训练和推理都需要大量计算资源 |

表 10.1：人类认知与生成式 AI 的比较

尽管当前的人工智能系统在跨模态（图像、视频、连贯文本）生成高质量内容方面取得了非凡的进步，但它们在更深层次的认知能力方面仍然存在显著的局限性。

最近的研究突出了社会智能方面的特别深刻的局限性。Sclar 等人于 2024 年 12 月进行的一项研究发现，即使是像 Llama-3.1 70B 和 GPT-4o 这样的前沿模型，在具有挑战性的**心智理论**（**ToM**）场景中的表现也相当糟糕（准确率低至 0-9%）。这种无法模拟他人心理状态的能力，尤其是在他们与可用信息不同时，代表了人类与 AI 认知之间的一个根本性差距。

有趣的是，同一项研究发现，通过精心设计的 ToM 场景进行针对性的微调可以获得显著的改进（+27 个百分点），这表明某些局限性可能反映了不充分的训练示例，而不是不可逾越的架构限制。这种模式也扩展到其他能力——而仅仅通过扩展规模并不能克服认知限制，专门的训练方法显示出希望。

在状态跟踪能力方面的差距尤为相关。尽管理论上具有无限大的上下文窗口，AI 系统在通过复杂场景连贯跟踪物体状态和代理知识方面仍然存在困难。人类尽管工作记忆容量有限（根据最新的认知研究，通常是 3-4 个块），但通过选择性注意和有效的信息组织策略，在跟踪相关状态方面表现出色。

尽管 AI 系统在多模态集成（文本、图像、音频、视频）方面取得了显著的进步，但它们仍然缺乏人类自然发展出的无缝跨模态理解。同样，在创造性生成方面，AI 仍然受限于其训练分布，产生的是已知模式的变体，而不是根本性的新概念。

从建筑学的角度来看，人脑模块化、分层的组织结构以及专门的子系统使得其相较于需要大量计算资源的 AI 的相对同质化架构，具有令人瞩目的能源效率（约 20 瓦）。此外，AI 系统可能会持续放大其训练数据中存在的偏差，从而在性能限制之外引发伦理问题。

这些差异表明，虽然某些能力可能通过更好的训练数据和技巧得到提升，但其他能力可能需要更根本的架构创新，以弥合统计模式匹配与真正理解之间的差距。

尽管在生成式 AI 方面取得了令人印象深刻的进步，但人类与 AI 在认知的多个维度上仍然存在根本性的差距。最重要的是，AI 缺乏：

+   知识的现实世界基础

+   在不同情境下的适应性灵活性

+   真正的深层流畅理解

+   能源高效的加工

+   社会和情境意识

这些局限性不是孤立的问题，而是真正类人人工智能开发中相同根本挑战的相互关联方面。随着技术进步，AI 的监管环境正在迅速演变，创造了一个复杂的全球市场。欧盟的 AI 法案于 2024 年实施，它制定了严格的要求，导致一些 AI 工具在欧洲市场的可用性被推迟或受限。例如，Meta AI 仅在 2025 年才在法国推出，比其在美国的发布晚了两年，这是由于监管合规挑战。这种日益增长的监管差异为 AI 的演变增添了另一个维度，因为公司必须调整其产品以符合不同的法律要求，同时保持竞争优势。

# 扩展的局限性和新兴的替代方案

理解扩展范式和新兴替代方案的局限性对于今天构建或实施 AI 系统的人来说至关重要。作为开发者和利益相关者，认识到收益递减何时开始出现有助于做出更好的投资决策、技术选择和实施策略。超越扩展的转型既是一个挑战，也是一个机遇——挑战我们重新思考如何推进 AI 能力，同时也是一个机遇，可以创建更高效、更易于访问和更专业的系统。通过探索这些局限性和替代方案，读者将更好地装备自己，以应对不断演变的 AI 领域，做出明智的架构决策，并确定针对其特定用例最有希望的路径。

## 扩展假设受到挑战

当前在训练超大型模型时的计算量翻倍时间大约为 8 个月，超过了如摩尔定律（晶体管密度在成本增加的情况下以目前大约 18 个月的速度增长）和洛克定律（如 GPU 和 TPU 等硬件的成本每 4 年减半）等既定的扩展定律。

根据 Leopold Aschenbrenner 于 2024 年 6 月的“情境意识”文档，自 2010 年以来，AI 训练计算量每年增加约 4.6 倍，而 GPU FLOP/s 的年增长率仅为约 1.35 倍。算法改进每年大约带来 3 倍的性能提升。这种计算扩展的非凡速度反映了 AI 发展中前所未有的军备竞赛，远远超出了传统半导体扩展规范。

Gemini Ultra 的最终训练运行估计使用了大约 5 × 10²⁵ FLOP，这使得它（截至本文撰写时）可能是训练过的计算量最大的模型。同时，自 2010 年以来，语言模型训练数据集每年增长约 3.0 倍，创造了巨大的数据需求。

到 2024-2025 年，关于**规模假设**——即仅仅通过扩大模型规模、数据和计算能力就能必然导致**通用人工智能**（**AGI**）的想法，已经发生了重大的视角转变。尽管在这一方法上投入了巨额资金（估计近半兆美元），但证据表明，仅靠规模扩张已经因为以下几个原因而开始遇到边际效益递减：

+   首先，性能已经开始停滞不前。尽管模型规模和训练计算能力有了巨大的增加，但像幻觉、不可靠的推理和事实不准确这样的基本挑战即使在最大的模型中也依然存在。像 Grok 3（其计算能力是其前身 15 倍）这样的高调发布仍然表现出推理、数学和事实信息的基本错误。

+   第二，竞争格局发生了巨大变化。像 OpenAI 这样的公司曾经明显的技术领先优势已经削弱，现在市场上已经有了 7-10 个 GPT-4 级别的模型。像 DeepSeek 这样的中国公司以显著较少的计算能力（训练成本仅为 1/50）实现了相当的性能，挑战了资源优势巨大就能转化为不可逾越的技术领先的观点。

+   第三，经济不可持续性变得明显。规模方法导致了巨大的成本，而没有相应的收入。价格战已经爆发，具有相似能力的竞争对手相互压价，压缩了利润空间，侵蚀了更大模型的经济学依据。

+   最后，行业对这些局限性的认识已经增长。包括微软 CEO 萨提亚·纳德拉和著名投资者马克·安德森在内的关键行业人物，已经公开承认，规模定律可能已经触及天花板，类似于摩尔定律最终在芯片制造中放缓的情况。

## 大型科技公司与中小企业

开源 AI 的兴起在这一转变的格局中尤其具有变革性。像 Llama、Mistral 等项目已经使强大的基础模型的可访问性民主化，允许较小的公司无需巨额投资就能构建、微调和部署他们自己的 LLMs。这个开源生态系统为创新创造了肥沃的土壤，其中由小型团队开发的特定领域模型可以在特定应用中超越科技巨头的通用模型，进一步削弱了仅靠规模的优势。

几家较小的公司已经成功地展示了这种动态。Cohere 公司，其团队规模仅为 Google 或 OpenAI 的一小部分，通过专注于指令遵循和可靠性的创新训练方法，开发了专门针对企业的模型，这些模型在商业应用中与较大的竞争对手相匹配或超过。类似地，Anthropic 通过强调宪法 AI 方法而不是仅仅规模，实现了 Claude 模型在推理和安全基准测试中经常超越较大竞争对手的卓越表现。在开源领域，Mistral AI 反复证明，它们精心设计的较小模型可以实现与规模大得多模型相媲美的性能。

越来越明显的是，大型科技公司曾经拥有的清晰的技术护城河正在迅速侵蚀。2024-2025 年的竞争格局发生了戏剧性的变化。

多个有能力的模型已经出现。在 OpenAI 曾经独自拥有 ChatGPT 和 GPT-4 的时候，现在市场上已经有来自 Anthropic、Google、Meta、Mistral 和 DeepSeek 等公司的 7-10 个类似模型，这显著降低了 OpenAI 的感知独特性和技术优势。

价格战和商品化趋势加剧。随着能力的均衡，供应商们开始进行激进的降价。OpenAI 为了应对竞争压力，尤其是来自提供类似能力但成本更低的中国的公司的压力，已经多次降低价格。

非传统玩家已经展示了快速追赶的能力。DeepSeek 和 ByteDance 等公司通过显著降低训练成本实现了与竞争对手相当的模式质量，证明了创新训练方法可以克服资源差异。此外，创新周期已经大幅缩短。新的技术进步在几周或几个月内就能得到匹配或超越，而不是几年，这使得任何技术领先都越来越短暂。

观察技术采用格局，我们可以考虑 AI 实施的两种主要场景。在集中式场景中，生成式 AI 和 LLMs 主要由大量投资于必要的计算硬件、数据存储和专门 AI/ML 人才的大型科技公司开发和控制。这些实体生产通用专有模型，这些模型通常通过云服务或 API 向客户开放，但这些一刀切解决方案可能无法完美地满足每个用户或组织的需要。

相反，在自助服务场景中，公司或个人承担了微调自身 AI 模型的任务。这种方法使他们能够创建针对用户特定需求和专有数据的定制模型，提供更精准和相关的功能。随着计算、数据存储和 AI 人才成本的下降，对专业模型的定制微调对于小型和中型公司来说已经可行。

很可能会出现一个混合格局，其中两种方法根据用例、资源、专业知识和隐私考虑因素发挥不同的作用。大型公司可能会继续在提供行业特定模型方面表现出色，而较小的实体可能会越来越多地微调自己的模型以满足特定需求。

如果出现强大的工具来简化并自动化人工智能开发，定制生成模型甚至可能对地方政府、社区团体和个人解决超本地问题具有可行性。虽然大型科技公司目前主导着生成人工智能的研究和开发，但较小的实体最终可能从这些技术中获得最大的收益。

## 纯规模化之外的兴起替代方法

随着规模化的局限性变得更加明显，几种替代方法正在获得关注。许多超越纯粹规模化的观点都受到了利奥波德·阿申布伦纳（Leopold Aschenbrenner）有影响力的 2024 年 6 月论文《情境意识：未来十年》([`situational-awareness.ai/`](https://situational-awareness.ai/))的启发，该论文全面分析了人工智能规模化的趋势及其局限性，同时探讨了进步的替代范式。这些方法可以归纳为三个主要范式。让我们逐一看看它们。

### 规模化提升（传统方法）

人工智能进步的传统方法一直集中在规模化提升——通过更大的模型、更多的计算和更大的数据集追求更大的能力。这个范式可以分解为几个关键组成部分：

+   **增加模型大小和复杂性**：自 2017 年以来，主要的方法一直是创建具有更多参数的越来越大型的神经网络。GPT-3 扩展到 1750 亿个参数，而更近期的模型如 GPT-4 和 Gemini Ultra 据估计具有数万亿个有效参数。每次规模的增加通常都会在广泛的任务中带来能力的提升。

+   **扩展计算资源**：训练这些庞大的模型需要巨大的计算基础设施。现在最大的 AI 训练运行消耗的资源相当于小型数据中心，其电力消耗、冷却需求和专用硬件需求使得除了最大的组织之外的所有组织都无法触及。一个前沿模型的单一训练运行可能耗资超过 1 亿美元。

+   **收集庞大的数据集**：随着模型的增长，其对训练数据的渴望也在增加。领先的模型在万亿个标记上训练，实际上消耗了互联网、书籍和专用数据集中大部分高质量文本，这种方法需要复杂的数据处理管道和大量的存储基础设施。

+   **局限性日益显现**：虽然这种方法至今主导了人工智能的发展并产生了显著的结果，但它面临着越来越多的挑战，包括投资回报递减、经济可持续性和仅通过扩展无法克服的技术障碍。

### **缩减（效率创新）**

效率范式通过几种关键技术来实现以更少的资源做更多的事情：

+   **量化**通过减少权重和激活的位数将模型转换为较低的精度。这项技术可以将大型模型性能压缩到更小的形式，显著降低计算和存储需求。

+   **模型蒸馏**将知识从大型“教师”模型转移到更小、更高效的“学生”模型，使得在更有限的硬件上部署成为可能。

+   **记忆增强架构**代表了一种突破性的方法。Meta FAIR 在 2024 年 12 月关于记忆层的研究展示了如何在不增加计算需求成比例的情况下提高模型能力。通过用可训练的关键值记忆层替换一些前馈网络，并将这些层扩展到 1280 亿个参数，研究人员实现了事实准确性的超过 100%的提高，同时也在编码和一般知识任务上提升了性能。令人惊讶的是，这些记忆增强模型与使用 4 倍更多计算量训练的密集模型的表现相当，直接挑战了更多计算是通往更好性能的唯一途径的假设。这种方法专门针对事实可靠性——解决传统架构中尽管规模增加但持续存在的幻觉问题。

+   **专用模型**为通用系统提供了另一种选择。这些模型不是通过规模来追求通用智能，而是针对特定领域进行定制，通常在较低的成本下提供更好的性能。微软的 Phi 系列，现已发展到 phi-3（2024 年 4 月），展示了精心数据整理如何显著改变扩展定律。虽然像 GPT-4 这样的模型是在庞大的、异构的数据集上训练的，但 Phi 系列通过专注于高质量的教科书式数据，使用更小的模型实现了显著的性能。

### **扩展（分布式方法）**

这种分布式范式探讨了如何利用模型和计算资源网络。

**测试时计算**将重点从训练更大的模型转移到在推理时分配更多的计算。这使得模型能够更彻底地通过问题进行推理。谷歌 DeepMind 的 Mind Evolution 方法在复杂规划任务上实现了超过 98%的成功率，而不需要更大的模型，展示了在推理期间进化搜索策略的力量。这种方法由于非常长的提示，消耗了三百万个标记，而正常的 Gemini 操作只需要 9000 个标记，但实现了显著更好的结果。

近期在推理能力方面的进步已经超越了简单的自回归标记生成，通过引入**思想**的概念——表示推理过程中中间步骤的标记序列。这种范式转变使得模型能够通过树搜索和反思性思维方法来模仿复杂的人类推理。研究表明，在测试时间推理过程中鼓励模型使用更多标记进行思考可以显著提高推理准确性。

出现了多种方法来利用这一洞察：基于过程的监督，其中模型生成逐步推理链并从中间步骤获得奖励。**蒙特卡洛树搜索**（**MCTS**）技术通过探索多个推理路径来寻找最优解，以及训练用于迭代解决问题、改进先前尝试的修订模型。

例如，2025 年的 rStar-Math 论文（*rStar-Math：小型 LLM 可以通过自我进化的深度思考掌握数学推理*）证明了模型可以在不通过从更优模型中蒸馏的情况下，达到与 OpenAI 的 o1 相当的推理能力，而是通过 SLM（基于强化学习的过程奖励模型）引导的 MCTS 进行“深度思考”。这代表了与传统扩展方法相比，提高 AI 能力的一种根本不同的方法。

**RAG**将模型输出建立在外部知识源的基础上，这比简单地扩大模型规模更有效地解决了幻觉问题。这种方法允许即使是更小的模型也能访问准确、最新的信息，而无需将其全部编码到参数中。

**高级记忆机制**显示出有希望的结果。最近的创新，如 Meta FAIR 的记忆层和 Google 的 Titans 神经网络记忆模型，在大幅降低计算需求的同时展现出卓越的性能。Meta 的记忆层使用可训练的键值查找机制向模型添加额外的参数，而不会增加 FLOPs。它们在事实性问答基准测试中提高了超过 100%的事实准确性，同时也在编码和一般知识任务上提升了性能。这些记忆层可以扩展到 1280 亿个参数，并且已经预训练到 1 万亿个标记。

在这个范式中的其他创新方法包括：

+   **神经注意力记忆模型（NAMMs）**在不改变其架构的情况下提高了 transformers 的性能和效率。NAMMs 可以将输入上下文缩小到原始大小的几分之一，同时在 LongBench 上提高 11%的性能，并在 InfiniteBench 上实现 10 倍的性能提升。它们已经证明了零样本迁移到新的 transformer 架构和输入模态的能力。

+   **概念级建模**，如 Meta 的大型概念模型所示，在比标记更高的抽象级别上运行，从而实现更有效的处理。LCMs 不是在离散标记上操作，而是在代表抽象意义单位（概念）的高维嵌入空间中进行计算，这些概念对应于句子或话语。这种方法本质上是无模态的，支持超过 200 种语言和多种模态，包括文本和语音。

+   **以视觉为中心的增强**，如 OLA-VLM，针对视觉任务优化多模态模型，无需多个视觉编码器。OLA-VLM 在深度估计任务中比基线模型提高了高达 8.7% 的性能，并在分割任务中实现了 45.4% 的 mIoU 分数（与 39.3% 的基线相比）。

这种转变表明，人工智能发展的未来可能不会仅由拥有最多计算资源的组织主导。相反，训练方法、架构设计和战略专业化的创新可能在人工智能发展的下一阶段决定竞争优势。

## 训练数据质量的发展

训练数据质量的发展变得越来越复杂，遵循三个关键发展。首先，领先的模型发现书籍在内容上比网络爬取的内容具有关键优势。GPT-4 被发现广泛记忆了文学作品，包括《哈利·波特》系列、奥威尔的《1984》和《指环王》三部曲——这些作品具有连贯的叙事、逻辑结构和精致的语言，而网络内容往往缺乏这些。这有助于解释为什么早期能够访问书籍语料库的模型往往优于主要在网络上训练的大型模型。

第二，数据整理已演变成多级方法：

+   **黄金数据集**：代表最高质量标准的传统主题专家创建的集合

+   **银级数据集**：模仿专家级指令的 LLM 生成内容，使训练示例的规模实现大规模扩展

+   **超级黄金数据集**：由众多专家严格验证的、具有多层验证层的精选集合

+   **合成推理数据**：专注于逐步问题解决方法的特别生成的数据集

第三，质量评估变得越来越复杂。现代数据准备管道采用多个过滤阶段、污染检测、偏差检测和质量评分。这些改进极大地改变了传统的扩展定律——一个经过良好训练的 70 亿参数模型，如果数据质量优异，现在可以在复杂推理任务上优于早期的 1750 亿参数模型。

这种以数据为中心的方法代表了纯参数缩放的根本性替代方案，表明人工智能的未来可能属于更高效、更专业的模型，这些模型在精确针对的数据上训练，而不是在所有可用内容上训练的庞大通用系统。

数据质量面临的一个新兴挑战是互联网上人工智能生成内容的日益普遍。随着生成式人工智能系统产生越来越多的在线文本、图像和代码，基于这些数据训练的未来模型将越来越多地学习来自其他人工智能输出的内容，而不是原始的人类创造内容。这可能导致潜在的反馈循环，最终可能导致性能停滞，因为模型开始放大先前人工智能生成中存在的模式、局限性和偏差，而不是从新鲜的人类例子中学习。这种*人工智能数据饱和*现象强调了继续为训练未来模型精心挑选高质量、经过验证的人类创造内容的重要性。

## 通过技术进步实现民主化

人工智能模型训练成本的快速下降代表着技术领域的重大转变，使得更多人能够参与到前沿的人工智能研究和开发中。这一趋势的推动因素包括训练制度的优化、数据质量的提升以及新型模型架构的引入。

下面是使生成式人工智能更加易于访问和有效的关键技术和方法：

+   **简化的模型架构**：简化模型设计，便于管理，提高可解释性，降低计算成本

+   **合成数据生成**：人工训练数据，在保留隐私的同时增强数据集

+   **模型蒸馏**：将大型模型中的知识转移到更小、更高效的模型中，以便于部署

+   **优化的推理引擎**：软件框架，可以增加在给定硬件上执行人工智能模型的速度和效率

+   **专用 AI 硬件加速器**：如 GPU 和 TPU 等专用硬件，显著加速人工智能计算

+   **开源和合成数据**：高质量公开数据集，促进协作，增强隐私性，同时减少偏差

+   **联邦学习**：在去中心化数据上训练，提高隐私性，同时从多样化的数据源中获益

+   **多模态**：在顶级模型中将语言与图像、视频和其他模态集成

在帮助降低成本的技术进步中，量化技术已成为一个重要的贡献者。开源数据集和如合成数据生成等技术进一步民主化了对人工智能训练的访问，通过提供高质量、数据高效的模式开发以及减少对庞大、专有数据集的依赖。开源倡议通过提供成本效益高、协作性强的创新平台来推动这一趋势。

这些创新共同降低了阻碍现实世界生成式 AI 应用的障碍，以几种重要方式：

+   通过量化蒸馏将大型模型性能压缩成远更小的形式，从而降低了财务障碍

+   通过合成数据技术可能解决隐私考虑因素，尽管对于 LLMs 的联邦学习的可靠、可重复的实现仍然是一个持续研究而非已验证的方法论领域

+   通过将生成与外部信息相结合，缓解了阻碍小型模型的准确性限制

+   专用硬件显著加速了吞吐量，而优化的软件最大化了现有基础设施的效率

通过解决成本、安全性和可靠性等限制，这些方法通过民主化访问，为广泛的人群解锁了利益，将生成式创造力从狭窄的集中转向赋能多样化的人类才能。

景观正在从关注纯粹模型大小和蛮力计算转向聪明、细致的方法，这些方法最大化了计算效率和模型功效。随着量化及相关技术降低了障碍，我们正准备进入一个更加多元和动态的 AI 发展时代，其中资源财富不是 AI 创新领导力的唯一决定因素。

## 后训练阶段的新的扩展定律

与传统的预训练扩展不同，在预训练扩展中，性能改进最终会随着参数数量的增加而达到平台期，推理性能会随着推理过程中花费更多时间“思考”而持续提高。几项研究表明，允许模型有更多时间逐步解决复杂问题可以增强它们在某些领域的解决问题的能力。这种方法，有时被称为“推理时间扩展”，仍然是一个不断发展的研究领域，但已显示出有希望的结果。

这种新兴的扩展动态表明，尽管预训练扩展可能接近边际收益递减，但后训练和推理时间扩展代表了有希望的新前沿。这些扩展定律与指令遵循能力之间的关系尤其引人注目——模型必须具备足够的指令遵循能力，才能展示这些测试时间扩展的好处。这为将研究努力集中在增强推理时间推理上而不是简单地扩大模型规模提供了有力的论据。

在考察了扩展的技术限制和新兴替代方案之后，我们现在转向这些发展的经济后果。正如我们将看到的，从纯扩展转向更有效的方法对市场动态、投资模式和价值创造机会具有重大影响。

# 经济与产业转型

通过在各个行业自动化任务，整合生成式 AI 承诺带来巨大的生产力提升，同时由于变革的速度，可能会因劳动力中断而造成影响。根据普华永道 2023 年 G*lobal Artificial Intelligence Impact Index*和摩根大通 2024 年*The Economic Impact of Generative AI*的报告，到 2030 年，AI 可能为全球经济贡献高达 15.7 万亿美元，将全球 GDP 提升至 14%。这种经济影响将分布不均，中国可能看到 GDP 增长 26%，北美大约 14%。预计将看到最高影响的行业包括（按顺序）：

+   医疗保健

+   汽车行业

+   金融服务业

+   交通运输与物流

JPM 的报告强调，AI 不仅仅是简单的自动化——它从根本上增强了商业能力。未来的收益可能会随着技术部门领导力的演变以及创新在各个行业的扩散而遍布整个经济。

AI 采用的演变可以在以往技术革命的大背景下更好地理解，这些革命通常遵循 S 曲线模式，有三个不同的阶段，正如 Everett Rogers 在其开创性作品《创新的扩散》中所描述的。虽然典型的技术革命在历史上通常需要数十年才能遵循这些阶段，但 Leopold Aschenbrenner 的《未来十年：情境意识》（2024）认为，由于 AI 自我改进和加速自身发展的独特能力，AI 的实施可能遵循一个压缩的时间表。Aschenbrenner 的分析表明，传统的 S 曲线可能对于 AI 技术来说会陡峭得多，可能将原本需要数十年的采用周期压缩到几年：

1.  **学习阶段（5-30 年）**：初步实验和基础设施开发

1.  **实施阶段（10-20 年）**：一旦基础设施成熟，将快速扩展

1.  **优化阶段（持续进行）**：饱和后的渐进式改进

近期分析表明，AI 的实施可能遵循一个更复杂、分阶段的轨迹：

+   **2030-2040**：制造业、物流和重复性办公任务可能达到 70-90%的自动化

+   **2040-2050**：服务行业如医疗和教育可能达到 40-60%的自动化，随着类人机器人以及 AGI 能力的成熟

+   **2050 年后**：社会和伦理考虑可能延迟需要同理心的角色的全面自动化

根据世界经济论坛“2023 年就业未来报告”和麦肯锡全球研究院对跨行业自动化潜力的研究，我们可以绘制出关键行业的相对自动化潜力图：

特定的自动化水平和预测揭示了采用率的差异：

| **行业** | **自动化潜力** | **关键驱动因素** |
| --- | --- | --- |
| 制造业 | 高——特别是在重复性任务和结构化环境中 | 协作机器人、机器视觉、AI 质量控制 |
| 物流/仓储 | 高——尤其是在分类、拣选和库存方面 | 自主导航移动机器人（AMRs）、自动化分类系统 |

|

医疗保健

| 中等——主要集中在行政和诊断任务 | 人工智能诊断辅助、机器人手术、自动化文档 |
| --- | --- |
| 零售 | 中等——主要在库存和结账流程中 | 自助结账、库存管理、自动化履行 |

表 10.2：特定行业自动化水平的状态和预测

这份数据支持了对不同行业自动化时间表的细致看法。虽然制造业和*物流*正迅速向高度自动化迈进，但涉及复杂人际互动的服务行业面临更大的障碍。

2023 年早期麦肯锡的估计表明，大型语言模型（LLMs）可以直接自动化 20%的任务，间接转型 50%的任务。然而，实施证明比预期更具挑战性。最成功的部署是那些增强人类能力而不是试图完全替代的。

## 行业特定的转型和竞争动态

2024-2025 年间，人工智能提供商的竞争格局发生了显著变化。随着技术能力在供应商之间趋同，价格竞争加剧，整个行业的利润空间受到压力。公司面临挑战，在核心技术之外建立可持续的竞争优势，因为差异化越来越依赖于领域专业知识、解决方案集成和服务质量，而不是原始模型性能。与最初的预测相比，企业采用率仍然保持适度，这表明在扩展假设下进行的巨大基础设施投资可能难以在短期内产生足够的回报。

领先的制造业采用者——如全球灯塔工厂——已经使用人工智能驱动的机器人自动化了 50-80%的任务，在 2-3 年内实现了投资回报率。根据 ABI Research 的 2023 年协作机器人市场分析([`www.abiresearch.com/press/collaborative-robots-pioneer-automation-revolution-market-to-reach-us7.2-billion-by-2030`](https://www.abiresearch.com/press/collaborative-robots-pioneer-automation-revolution-market-to-reach-us7.2-billion-by-2030))，协作机器人的部署时间比传统工业机器人更快，实施周期平均缩短 30-40%。然而，这些进步主要在结构化环境中有效。先驱设施与行业平均水平（目前为 45-50%的自动化）之间的差距既说明了未来的潜力，也说明了实施挑战。

在创意产业中，我们看到了特定领域的进展。例如，GitHub Copilot 这样的软件开发工具正在改变开发者的工作方式，尽管具体任务自动化的百分比仍然难以精确量化。同样，数据分析工具正在越来越多地处理金融和营销领域的常规任务，但具体实施的程度差异很大。根据麦肯锡全球研究院 2017 年的研究，只有大约 5%的职业可以通过现有技术实现完全自动化，而许多职业有相当一部分的活动可以自动化（在 60%的职业中，大约 30%的活动可以自动化）。这表明，大多数成功的实施都是增强而不是完全取代人类能力。

## 职业演变和技能影响

随着自动化在各个行业的采用不断推进，对就业的影响将在不同行业和时间段内显著不同。根据当前的采用率和预测，我们可以预测特定角色将如何演变。

### 近期影响（2025-2035）

随着自动化在各个行业的采用不断推进，对就业的影响将在不同行业和时间段内显著不同。虽然精确的自动化百分比难以预测，但我们能识别出特定角色可能如何演变的清晰模式。

根据麦肯锡全球研究院的研究，只有大约 5%的职业可以通过当前技术实现完全自动化，尽管大约 60%的职业至少有 30%的活动可以自动化。这表明，随着人工智能能力的提升，职业转型——而不是全面替代——将成为主要模式。迄今为止最成功的实施都是增强人类能力而不是完全取代工人。

自动化的潜力在不同行业之间存在很大差异。制造业和物流业，由于其结构化环境和重复性任务，比需要复杂人际互动的行业（如医疗保健和教育）具有更高的自动化潜力。这种差异在经济的转型时间表上造成了不均衡。

### 中期影响（2035-2045）

随着服务业在未来十年内达到 40-60%的自动化水平，我们可以预期传统专业角色将发生重大转变：

+   **法律行业**：常规法律工作，如文件审查和起草，将大部分实现自动化，从根本上改变初级律师和律师助理的岗位职责。已经开始这一转变的律师事务所报告称，在显著增加案件处理能力的同时，保持了人员编制。

+   **教育**：教师将利用人工智能进行课程准备、行政任务和个性化学生支持。学生已经通过个性化的教学互动使用生成式人工智能来学习新概念，通过自己节奏的后续问题来澄清理解。教师的角色将向导师、批判性思维发展和创造性学习设计转变，而不是纯粹的信息传递，专注于人类指导最能增加价值的方面。

+   **医疗保健**：虽然临床决策将主要依靠人类，但诊断支持、文档编制和常规监测将越来越自动化，使医疗服务提供者能够专注于复杂病例和患者关系。

### 长期转变（2045 年及以后）

随着技术接近需要更多同理心的角色，我们可以期待以下需求：

+   **专业专长**：对人工智能伦理、法规、安全监督和人类-人工智能协作设计方面的专家需求将显著增长。随着系统变得更加自主，这些角色对于确保负责任的结果至关重要。

+   **创意领域**：音乐家和艺术家将开发新的形式的人类-人工智能协作，可能提高创意表达和可及性，同时引发关于归属和原创性的新问题。

+   **领导和战略**：需要复杂判断、道德推理和利益相关者管理的角色将是最后看到显著自动化的，这可能会增加它们在经济学中的相对价值。

## 经济分配和公平考虑

没有明确的政策干预，人工智能的经济效益可能会不成比例地流向那些拥有资本、技能和基础设施以利用这些技术的群体，这可能会加剧现有的不平等。这一担忧尤其适用于以下方面：

+   **地理差异**：拥有强大技术基础设施和教育系统的地区可能会进一步领先于欠发达地区。

+   **基于技能的不平等**：拥有教育和对 AI 系统具有补充能力的工人可能会看到工资增长，而其他人可能面临失业或工资停滞。

+   **资本集中**：成功实施人工智能的组织可能会获得不成比例的市场份额，可能导致行业集中度更高。

解决这些挑战需要协调一致的政策方法：

+   投资于教育和再培训计划，以帮助工人适应不断变化的就业需求

+   促进竞争并防止过度市场集中的监管框架

+   针对面临重大中断的地区和社区提供有针对性的支持

在所有时间段中的一致模式是，尽管常规任务面临越来越多的自动化（由特定行业因素决定的速率），但指导人工智能系统并确保负责任的结果的人类专业知识仍然至关重要。这种演变表明，我们应该期待转型而不是全面替代，技术专家在开发人工智能工具和实现其商业潜力方面仍然至关重要。

通过自动化常规任务，高级人工智能模型最终可能释放出人类时间，用于更高价值的工作，从而可能提高整体经济产出，同时也会带来需要深思熟虑的政策响应的转型挑战。推理能力的人工智能的发展可能会加速分析角色的这种转变，而对需要情商和人际交往技能的角色影响较小。

# 社会意义

作为人工智能生态系统的开发者和利益相关者，理解这些技术的更广泛的社会影响不仅是一项理论练习，而是一项实际需要。我们今天做出的技术决策将塑造人工智能对信息环境、知识产权系统、就业模式和监管环境的影响。通过审视这些社会维度，读者可以更好地预测挑战，设计更负责任的系统，并有助于塑造一个未来，其中生成式人工智能创造广泛的好处，同时最大限度地减少潜在的危害。此外，了解这些影响有助于应对日益影响人工智能开发和部署的复杂伦理和监管考量。

## 错误信息和网络安全

人工智能在信息完整性和安全性方面是一把双刃剑。虽然它使检测虚假信息更好，但它同时促进了以前所未有的规模和个性化程度创建越来越复杂的虚假信息。生成式人工智能可以创建针对特定人口和个人的针对性虚假信息宣传活动，使人们更难区分真实和被操纵的内容。当与微定位能力结合使用时，这可以在社交平台上实现精确的意见操纵。

除了纯粹的错误信息之外，生成式人工智能通过使模仿可信联系人写作风格的个性化钓鱼信息成为可能，加速了社会工程攻击。它还可以生成恶意软件的代码，使复杂的攻击对技术能力较低的危险行为者变得可行。

深伪现象可能是最令人担忧的发展。现在的人工智能系统可以生成逼真的虚假视频、图像和音频，似乎显示真实的人说或做他们从未做过的事情。这些技术威胁着侵蚀对媒体和机构的信任，同时为实际的不法行为提供了合理的否认理由（“这只是人工智能的伪造”）。

创作与检测之间的不对称性提出了重大挑战——通常生成令人信服的虚假内容比构建检测系统的成本更低、更容易。这为传播虚假信息的人创造了持续的竞争优势。

规模化方法中的局限性对虚假信息问题具有重要意义。虽然人们期待更强大的模型能够发展出更好的事实基础和推理能力，但即使在最先进的系统中也持续出现的幻觉表明，仅靠技术解决方案可能是不够的。这促使人们转向结合 AI 与人类监督和外部知识验证的混合方法。

为了应对这些威胁，需要几种互补的方法：

+   **技术保障**：内容溯源系统、数字水印和高级检测算法

+   **媒体素养**：广泛教育识别被操纵的内容和评估信息来源

+   **监管框架**：针对深度伪造和自动化虚假信息的法律

+   **平台责任**：增强内容审查和身份验证系统

+   **协作检测网络**：跨平台共享虚假信息模式

将 AI 的生成能力与互联网规模的分发机制相结合，对支撑民主社会的信息生态系统提出了前所未有的挑战。解决这个问题需要技术、教育和政策领域的协调努力。

## 版权和归属挑战

生成式 AI 为开发者提出了重要的版权问题。最近的法院裁决([`www.reuters.com/world/us/us-appeals-court-rejects-copyrights-ai-generated-art-lacking-human-creator-2025-03-18/`](https://www.reuters.com/world/us/us-appeals-court-rejects-copyrights-ai-generated-art-lacking-human-creator-2025-03-18/))确立了 AI 生成的、缺乏显著人类创造性输入的内容不能获得版权保护。美国上诉法院在 2025 年 3 月明确裁定，根据版权法，“注册需要人类作者”，从而确认仅由 AI 创作的作品不能获得版权。

所有权问题取决于人类参与。仅由 AI 生成的输出不受版权保护，而由人类指导且具有创造性选择的 AI 输出可能受版权保护，AI 辅助的人类创作仍享有标准版权保护。

在版权作品中训练 LLM 的问题仍然存在争议。虽然有些人认为这构成了作为转换过程的合理使用，但最近的案例对此提出了挑战。2025 年 2 月，路透社的裁决([`www.lexology.com/library/detail.aspx?g=8528c643-bc11-4e1d-b4ab-b467cd641e4c`](https://www.lexology.com/library/detail.aspx?g=8528c643-bc11-4e1d-b4ab-b467cd641e4c))驳回了在受版权保护的法律材料上训练的 AI 的合理使用辩护。

这些问题显著影响了创意产业，在这些产业中，既定的补偿模式依赖于清晰的产权和归属。在视觉艺术、音乐和文学等领域，这些挑战尤为突出，因为生成式 AI 可以创作出风格上与特定艺术家或作者相似的作品。

建议的解决方案包括内容来源系统跟踪训练来源、补偿模型将版税分配给其作品为 AI 提供信息的创作者、技术水印以区分 AI 生成内容，以及建立明确的归属标准的法律框架。

在实施 LangChain 应用时，开发者应跟踪和归属源内容，实施过滤器以防止逐字复制，记录用于微调的数据来源，并考虑适当的引用来源的检索增强方法。

国际框架各不相同，欧盟 2024 年的 AI 法案规定了特定的数据挖掘例外情况，并赋予版权持有者从 2025 年 8 月开始的选择退出权利。这一困境凸显了迫切需要能够跟上技术进步并处理权利持有者与 AI 生成内容之间复杂互动的法律框架。随着法律标准的演变，能够适应不断变化要求的灵活系统为开发者和用户提供了最佳的保护。

## 规章制度和实施挑战

以负责任的方式实现生成式 AI 的潜力，需要解决法律、伦理和监管问题。欧盟的 AI 法案对 AI 系统采取了全面、基于风险的监管方法。它根据风险水平对 AI 系统进行分类：

+   **低风险**：基本 AI 应用，潜在危害有限

+   **有限风险**：需要透明度义务的系统

+   **高风险**：应用于关键基础设施、教育、就业和基本服务

+   **不可接受的风险**：被认为对权利和安全构成根本威胁的系统

高风险 AI 应用，如医疗软件和招聘工具，在数据质量、透明度、人工监督和风险缓解方面面临严格的要求。法律明确禁止某些被认为对基本权利构成“不可接受风险”的 AI 用途，例如针对弱势群体的社会评分系统和操纵性做法。AI 法案还要求开发者遵守透明度义务，并针对具有高影响潜力的通用 AI 模型制定了具体规则。

此外，对算法透明度的需求也在不断增长，科技公司和发展者面临着揭示更多关于其系统内部运作的压力。然而，公司往往抵制披露，认为透露专有信息会损害其竞争优势。这种透明度与知识产权保护之间的紧张关系尚未解决，开源模型可能推动更大的透明度，而专有系统则保持更多的神秘性。

当前内容监管的方法，如德国网络执法法（NetzDG），要求平台在 24 小时内删除虚假新闻和仇恨言论，已被证明是不切实际的。

对扩展限制的认识对监管具有重要意义。早期的人工智能治理方法主要侧重于监管对计算资源的访问。然而，最近的技术创新表明，使用显著更少的计算资源就能实现最先进的性能。这促使监管框架转向治理 AI 的能力和应用，而不是用于训练它们的资源。

为了在降低风险的同时最大化收益，组织应确保在 AI 开发中有人工监督、多样性和透明度。将道德培训纳入计算机科学课程可以帮助通过教授开发者如何构建设计上就是道德的应用程序来减少 AI 代码中的偏见。另一方面，政策制定者可能需要实施预防误用的护栏，同时为工人提供支持，以适应活动的转变。

# 摘要

随着我们使用 LangChain 对生成式 AI 的探索即将结束，我们希望您不仅掌握了技术知识，而且对这些技术未来的发展方向有了更深入的理解。从基本的 LLM 应用到复杂的代理系统，这一过程代表了当今计算领域最激动人心的前沿之一。

本书涵盖的实用实现——从 RAG 到多代理系统，从软件开发代理到生产部署策略——为构建今天强大的、负责任的 AI 应用提供了基础。然而，正如我们在最后一章所看到的，该领域正迅速发展，超越了简单的扩展方法，朝着更高效、专业化和分布式的范式发展。

我们鼓励您应用所学知识，尝试我们探索的技术，并为这个不断发展的生态系统做出贡献。与本书相关的存储库（[`github.com/benman1/generative_ai_with_langchain`](https://github.com/benman1/generative_ai_with_langchain)）将随着 LangChain 和更广泛的生成式 AI 领域的持续发展而维护和更新。

这些技术的未来将由使用它们的实践者来塑造。通过开发深思熟虑、有效且负责任的实施方案，您可以帮助确保生成式 AI 实现其作为增强人类能力并带来有意义挑战的变革性技术的承诺。

我们很期待看到您所构建的内容！

# 订阅我们的每周通讯

订阅 AI_Distilled，这是 AI 专业人士、研究人员和创新者的首选通讯，请访问`packt.link/Q5UyU`。

![](img/Newsletter_QRcode1.jpg)
