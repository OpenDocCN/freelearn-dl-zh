- en: '19'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '19'
- en: TensorFlow 2 Ecosystem
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 2 生态系统
- en: 'In this chapter, we will learn about the different components of the TensorFlow
    ecosystem. The chapter will elaborate upon TensorFlow Hub – a repository for pretrained
    deep learning models – and TensorFlow Datasets – a collection of ready-to-use
    datasets for ML tasks. TensorFlow JS, the solution for training and deploying
    ML models on the web, will be introduced. We will also learn about TensorFlow
    Lite, an open-source deep learning framework for mobile and edge devices. Some
    examples of Android, iOS, and Raspberry Pi applications will be discussed, together
    with examples of deploying pretrained models such as MobileNet v1, v2, v3 (image
    classification models designed for mobile and embedded vision applications), PoseNet
    for pose estimation (a vision model that estimates the poses of people in image
    or video), DeepLab segmentation (an image segmentation model that assigns semantic
    labels (for example, dog, cat, and car) to every pixel in the input image), and
    MobileNet SSD object detection (an image classification model that detects multiple
    objects with bounding boxes). The chapter will conclude with an example of federated
    learning, a decentralized machine learning framework that is thought to respect
    user privacy. The chapter includes:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习 TensorFlow 生态系统的不同组件。章节将详细介绍 TensorFlow Hub——一个预训练深度学习模型的仓库——以及 TensorFlow
    Datasets——一个用于机器学习任务的现成数据集集合。还将介绍 TensorFlow JS，这是一个用于在 Web 上训练和部署机器学习模型的解决方案。我们还将了解
    TensorFlow Lite，一个开源深度学习框架，专为移动和边缘设备设计。章节将讨论一些 Android、iOS 和 Raspberry Pi 应用的示例，以及部署预训练模型的示例，如
    MobileNet v1、v2、v3（为移动和嵌入式视觉应用设计的图像分类模型）、PoseNet（用于姿势估计的视觉模型，能够估算图像或视频中人的姿势）、DeepLab
    分割（一个图像分割模型，将语义标签（例如，狗、猫、汽车）分配给输入图像中的每个像素）以及 MobileNet SSD 目标检测（一个图像分类模型，能够检测多个对象并给出边界框）。本章的最后将介绍联邦学习的示例，这是一种去中心化的机器学习框架，旨在尊重用户隐私。章节内容包括：
- en: TensorFlow Hub
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow Hub
- en: TensorFlow Datasets
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow Datasets
- en: TensorFlow Lite and using it for mobile and edge applications
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow Lite 及其在移动和边缘应用中的使用
- en: Federated learning at edge
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 边缘的联邦学习
- en: TensorFlow JS
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow JS
- en: Using Node.js with TensorFlow models
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Node.js 与 TensorFlow 模型
- en: All the code files for this chapter can be found at [https://packt.link/dltfchp19](https://packt.link/dltfchp19)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码文件可以在 [https://packt.link/dltfchp19](https://packt.link/dltfchp19) 找到
- en: Let’s begin with TensorFlow Hub.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 TensorFlow Hub 开始。
- en: TensorFlow Hub
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow Hub
- en: Even if you have a powerful computer, training a machine learning model can
    take days or weeks. And once you’ve trained the model, deploying it to different
    devices can be difficult and time-consuming. Depending upon the platform you want
    to deploy, you might need it in different formats.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你拥有一台强大的计算机，训练一个机器学习模型也可能需要几天或几周。而且，一旦你训练好模型，将其部署到不同的设备上可能既困难又费时。根据你要部署的平台，你可能需要不同的格式。
- en: 'You can think of TensorFlow Hub as a library with many pretrained models. It
    contains hundreds of trained, ready-to-deploy deep learning models. TensorFlow
    Hub provides pretrained models for image classification, image segmentation, object
    detection, text embedding, text classification, video classification and generation,
    and much more. The models in TF Hub are available in SavedModel, TFLite, and TF.js
    formats. We can use these pretrained models directly for inference or fine-tune
    them. With its growing community of users and developers, TensorFlow Hub is the
    go-to place for finding and sharing machine learning models. To use TensorFlow
    Hub, we first need to install it:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以把 TensorFlow Hub 当作一个包含许多预训练模型的库。它包含数百个经过训练、可以直接部署的深度学习模型。TensorFlow Hub
    提供了图像分类、图像分割、目标检测、文本嵌入、文本分类、视频分类和生成等预训练模型。TF Hub 中的模型可以以 SavedModel、TFLite 和 TF.js
    格式提供。我们可以直接使用这些预训练模型进行推理，或者对它们进行微调。随着用户和开发者社区的不断壮大，TensorFlow Hub 已成为寻找和分享机器学习模型的首选平台。要使用
    TensorFlow Hub，我们首先需要安装它：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once installed, we can import it simply using:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，我们可以通过以下方式简单地导入它：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'and load the model using the `load` function:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 并使用 `load` 函数加载模型：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here `handle` is a string, which contains the link of the model we wants to
    use. If we want to use it as part of our existing model, we can wrap it as a Keras
    layer:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的 `handle` 是一个字符串，包含我们想要使用的模型链接。如果我们希望将其作为现有模型的一部分使用，可以将其包装为 Keras 层：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: By changing the parameter `trainable` to `True`, we can fine-tune the model
    for our specific data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将参数 `trainable` 更改为 `True`，我们可以针对我们的特定数据对模型进行微调。
- en: '*Figure 19.1* shows the easy-to-use web interface to select different models
    at the `tfhub.dev` site. Using the filters, we can easily find a model to solve
    our problem.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 19.1* 显示了 `tfhub.dev` 网站的易用 Web 界面，用于选择不同的模型。通过使用过滤器，我们可以轻松找到解决我们问题的模型。'
- en: We can choose which type and format we need, as well as who published it!
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择需要的类型和格式，以及发布者！
- en: '![](img/B18331_19_01.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_01.png)'
- en: 'Figure 19.1: The tfhub.dev site showing different filters'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.1：显示不同过滤器的 tfhub.dev 网站
- en: Using pretrained models for inference
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用预训练模型进行推理
- en: 'Let us see how you can leverage pretrained models from TensorFlow Hub. We will
    consider an example of image classification:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何利用 TensorFlow Hub 中的预训练模型。我们将考虑一个图像分类的示例：
- en: 'Let us import the necessary modules:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们导入必要的模块：
- en: '[PRE4]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We define a function for loading an image from a URL. The functions get the
    image from the web, and we reshape it by adding batch indexes for inference. Also,
    the image is normalized and resized according to the pretrained model chosen:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了一个从 URL 加载图像的函数。该函数从网页上获取图像，并通过添加批次索引进行推理。图像还根据所选的预训练模型进行了归一化和缩放：
- en: '[PRE5]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Another helper function to show the image:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另一个辅助函数，用于显示图像：
- en: '[PRE6]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The model we are using is EfficientNet-B2 ([https://arxiv.org/abs/1905.11946](https://arxiv.org/abs/1905.11946))
    trained on the ImageNet dataset. It gives better accuracy, is smaller in size,
    and gives faster inference. For convenience, we choose images to be resized to
    330 x 330 pixels. We use the helper function defined in step 2 to download the
    image from Wikimedia:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用的模型是 EfficientNet-B2（[https://arxiv.org/abs/1905.11946](https://arxiv.org/abs/1905.11946)），该模型是在
    ImageNet 数据集上训练的。它提供更好的准确性，体积更小，并且推理速度更快。为了方便起见，我们选择将图像调整为 330 x 330 像素。我们使用在第
    2 步中定义的辅助函数从 Wikimedia 下载图像：
- en: '[PRE7]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](img/B18331_19_02.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_02.png)'
- en: 'Figure 19.2: The image taken from the web for classification, scaled to size
    330 x 330 pixels'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.2：从网页上获取的用于分类的图像，缩放为 330 x 330 像素
- en: 'For completeness, we also get all the labels of ImageNet data so that we can
    infer the label from the model prediction; we download it from a public repository
    of TensorFlow:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了完整性，我们还获取了 ImageNet 数据集的所有标签，以便从模型预测中推断标签；我们从 TensorFlow 的公共存储库下载它：
- en: '[PRE8]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now that all the ingredients are ready, we download the model from `tfhub.dev`:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在所有的准备工作都完成了，我们从 `tfhub.dev` 下载模型：
- en: '[PRE9]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We get the softmax probabilities for all the classes for the image downloaded
    in step 5:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们获取图像在第 5 步下载后的所有类别的 Softmax 概率：
- en: '[PRE10]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let us see the top prediction:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看顶部的预测结果：
- en: '[PRE11]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](img/B18331_19_03.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_03.png)'
- en: 'Figure 19.3: The image with the label prediction of lion'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.3：带有狮子标签预测的图像
- en: So, as we can see, in a few lines of code we get a perfect inference – the image
    is of a lioness, and the closest label for it in the ImageNet dataset is that
    of a lion, which the model has correctly predicted. By using the pretrained models
    of TF Hub, we can focus on our product workflow, and get better models and faster
    production.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，通过几行代码，我们就能得到完美的推理结果——图像是一只母狮，而 ImageNet 数据集中最接近它的标签是狮子，模型正确地做出了预测。通过使用
    TF Hub 的预训练模型，我们可以将精力集中在产品工作流上，从而获得更好的模型和更快的生产。
- en: TensorFlow Datasets
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 数据集
- en: '**TensorFlow Datasets** (**TFDS**) is a powerful tool for anyone working with
    machine learning. It provides a collection of ready-to-use datasets that can be
    easily used with TensorFlow or any other Python ML framework. All datasets are
    exposed as `tf.data.Datasets`, making it easy to use them in your input pipeline.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorFlow 数据集** (**TFDS**) 是一个功能强大的工具，适用于所有从事机器学习的人。它提供了一系列现成可用的数据集，可以轻松地与
    TensorFlow 或任何其他 Python ML 框架一起使用。所有数据集都作为 `tf.data.Datasets` 提供，便于在输入管道中使用。'
- en: 'With TFDS, you can quickly get started with your machine learning projects
    and save time by not having to collect and prepare your own data. The library
    currently contains a wide variety of datasets, including image classification,
    object detection, text classification, and more. In addition, the library provides
    tools for creating new datasets from scratch, which can be useful for researchers
    or developers who need to create custom datasets for their own projects. TFDS
    is open source and released under the Apache 2.0 license. To be able to use TFDS,
    you will need to install it:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TFDS，您可以快速开始机器学习项目，节省时间，无需自行收集和准备数据。该库目前包含各种各样的数据集，包括图像分类、目标检测、文本分类等。此外，库还提供了从零开始创建新数据集的工具，这对于需要为自己项目创建自定义数据集的研究人员或开发人员非常有用。TFDS
    是开源的，且以 Apache 2.0 许可证发布。要使用 TFDS，您需要安装它：
- en: '[PRE12]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Once installed, you can import it as:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 安装后，您可以像这样导入它：
- en: '[PRE13]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'At the time of writing this book, TFDS contained 224 public datasets for a
    large range of tasks:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写本书时，TFDS 包含了 224 个公共数据集，涵盖了广泛的任务：
- en: '[PRE14]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In this section, we will introduce you to TFDS and show how it can simplify
    your training process by exploring its underlying structure as well as providing
    some best practices for loading large amounts into machine learning models efficiently.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向您介绍 TFDS，并展示它如何通过探索其底层结构来简化您的训练过程，并提供一些加载大量数据到机器学习模型中的最佳实践。
- en: Load a TFDS dataset
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载 TFDS 数据集
- en: 'Each dataset in TFDS is identified by its unique name, and associated with
    each dataset is also a publisher and dataset version. To get the data, you can
    use the TFDS `load` function (it is a powerful function with a lot of flexibility;
    you can read more about the function at [https://www.tensorflow.org/datasets/api_docs/python/tfds/load](https://www.tensorflow.org/datasets/api_docs/python/tfds/load)):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: TFDS 中的每个数据集都有唯一的名称，并且每个数据集都与发布者和数据集版本相关联。要获取数据，您可以使用 TFDS 的 `load` 函数（这是一个功能强大的函数，具有很大的灵活性；您可以在[https://www.tensorflow.org/datasets/api_docs/python/tfds/load](https://www.tensorflow.org/datasets/api_docs/python/tfds/load)上查看更多关于此函数的内容）：
- en: '[PRE16]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You only need to specify the dataset name; the rest of the parameters are optional.
    You can read more about the optional arguments from TFDS docs. For example, below,
    we are downloading the famous MNIST dataset:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 您只需要指定数据集名称，其余参数是可选的。您可以从 TFDS 文档中了解更多关于可选参数的内容。例如，下面我们将下载著名的 MNIST 数据集：
- en: '[PRE17]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The preceding statement downloads both the training and test dataset of MNIST
    into the variable data. Since the `as_supervised` flag is set to `True`, the labels
    are downloaded with the data, and the detailed information about the dataset is
    downloaded in `info`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 上述语句将 MNIST 的训练和测试数据集都下载到变量数据中。由于 `as_supervised` 标志被设置为 `True`，标签会与数据一起下载，关于数据集的详细信息则会下载到
    `info` 中。
- en: 'Let us first check the info:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们检查信息：
- en: '[PRE18]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'So, we can see that the information is quite extensive. It tells us about the
    splits and the total number of samples in each split, the keys available if used
    for supervised learning, the citation details, and so on. The variable data here
    is a list of two TFDS dataset objects – the first one corresponding to the test
    dataset and the second one corresponding to the train dataset. TFDS dataset objects
    are `dict` by default. Let us take one single sample from the train dataset and
    explore:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们可以看到信息是相当详细的。它告诉我们每个拆分中的样本数、如果用于监督学习时可用的键、引用细节等。这里的变量数据是一个包含两个 TFDS 数据集对象的列表——第一个是对应测试数据集，第二个是对应训练数据集。TFDS
    数据集对象默认是 `dict` 类型。让我们从训练数据集中获取一个样本并进行探索：
- en: '[PRE20]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'You can see that the sample is an image of handwritten digits of the shape
    28 x 28 x 1 and its label is `2`. For image data, TFDS also has a method `show_examples`,
    which you can use to view the sample images from the dataset:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，样本是一个 28 x 28 x 1 形状的手写数字图像，其标签为 `2`。对于图像数据，TFDS 还提供了一个 `show_examples`
    方法，您可以用它来查看数据集中的示例图像：
- en: '[PRE22]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![A picture containing diagram  Description automatically generated](img/B18331_19_04.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图像包含图表  描述自动生成](img/B18331_19_04.png)'
- en: 'Figure 19.4: Sample from test dataset of MNIST dataset'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.4：MNIST 数据集的测试数据集样本
- en: Building data pipelines using TFDS
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 TFDS 构建数据管道
- en: 'Let us build a complete end-to-end example using the TFDS data pipeline:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 TFDS 数据管道构建一个完整的端到端示例：
- en: 'As always, we start with importing the necessary modules. Since we will be
    using TensorFlow to build the model, and TFDS for getting the dataset, we are
    including only these two for now:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 和往常一样，我们首先导入必要的模块。由于我们将使用TensorFlow构建模型，并且使用TFDS获取数据集，因此现在只导入这两个：
- en: '[PRE23]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Using the Keras Sequential API, we build a simple convolutional neural network
    with three convolutional layers and two dense layers:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Keras的顺序API，我们构建了一个简单的卷积神经网络，包含三个卷积层和两个全连接层：
- en: '[PRE24]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We will be building a binary classifier, so we choose binary cross entropy
    as the loss function, and Adam as the optimizer:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将构建一个二分类器，因此选择二元交叉熵作为损失函数，Adam作为优化器：
- en: '[PRE25]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, we come to the dataset. We are using the `horses_or_humans` dataset,
    so we use the `tfds.load` function to get the training and validation data:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们来处理数据集。我们使用`horses_or_humans`数据集，因此使用`tfds.load`函数获取训练数据和验证数据：
- en: '[PRE26]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The images need to be normalized; additionally, for better performance, we
    will augment the images while training:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像需要进行归一化；此外，为了提高性能，我们将在训练过程中对图像进行增强：
- en: '[PRE27]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'So now we build the pipeline; we start with `cache` for better memory efficiency,
    apply the pre-processing steps (normalization and augmentation), ensure that data
    is shuffled while training, define the batch size, and use `prefetch` so that
    the next batch is brought in as the present batch is being trained on. We repeat
    the same steps for the validation data. The difference is that validation data
    need not be augmented or shuffled:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们开始构建数据管道；首先使用`cache`以提高内存效率，应用预处理步骤（归一化和增强），确保在训练时数据会被打乱，定义批次大小，并使用`prefetch`，以便在当前批次训练时下一个批次也已准备好。我们对验证数据执行相同的步骤，唯一的区别是验证数据不需要进行增强或打乱：
- en: '[PRE28]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'And finally, we train the model:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们开始训练模型：
- en: '[PRE29]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Play around with different parameters of the data pipeline and see how it affects
    the training time. For example, try removing `prefetch` and `cache` and not specifying
    `num_parallel_calls`.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试调整数据管道的不同参数，观察其如何影响训练时间。例如，可以尝试去除`prefetch`和`cache`，并且不指定`num_parallel_calls`。
- en: TensorFlow Lite
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow Lite
- en: 'TensorFlow Lite is a lightweight platform designed by TensorFlow. This platform
    is focused on mobile and embedded devices such as Android, iOS, and Raspberry
    Pi. The main goal is to enable machine learning inference directly on the device
    by putting a lot of effort into three main characteristics: (1) a small binary
    and model size to save on memory, (2) low energy consumption to save on the battery,
    and (3) low latency for efficiency. It goes without saying that battery and memory
    are two important resources for mobile and embedded devices. To achieve these
    goals, Lite uses a number of techniques such as quantization, FlatBuffers, mobile
    interpreter, and mobile converter, which we are going to review briefly in the
    following sections.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Lite是一个由TensorFlow设计的轻量级平台。该平台专为移动设备和嵌入式设备（如Android、iOS和树莓派）设计。其主要目标是通过在设备上直接进行机器学习推理来实现高效能，重点关注三个主要特点：（1）小型二进制文件和模型大小以节省内存，（2）低能耗以节省电池，（3）低延迟以提高效率。不言而喻，电池和内存是移动设备和嵌入式设备的两项重要资源。为了实现这些目标，Lite采用了一些技术，如量化、FlatBuffers、移动解释器和移动转换器，接下来我们将简要回顾这些技术。
- en: Quantization
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 量化
- en: Quantization refers to a set of techniques that constrains an input made of
    continuous values (such as real numbers) into a discrete set (such as integers).
    The key idea is to reduce the space occupancy of **Deep Learning** (**DL**) models
    by representing the internal weight with integers instead of real numbers. Of
    course, this implies trading space gains for some amount of performance of the
    model. However, it has been empirically shown in many situations that a quantized
    model does not suffer from a significant decay in performance. TensorFlow Lite
    is internally built around a set of core operators supporting both quantized and
    floating-point operations.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 量化是指一套将由连续值（例如实数）组成的输入约束为离散集合（例如整数）的技术。其核心思想是通过使用整数而非实数来表示内部权重，从而减少**深度学习**（**DL**）模型的空间占用。当然，这意味着在空间节省的同时，模型的性能可能会有所牺牲。然而，许多实际情况已经证明，量化后的模型并不会出现显著的性能下降。TensorFlow
    Lite在内部构建了一套核心操作符，支持量化和浮动点操作。
- en: 'Model quantization is a toolkit for applying quantization. This operation is
    applied to the representations of weights and, optionally, to the activations
    for both storage and computation. There are two types of quantization available:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 模型量化是一个应用量化的工具包。此操作应用于权重的表示，并可选择性地应用于激活，以便进行存储和计算。有两种量化类型：
- en: Post-training quantization quantizes weights and the result of activations post-training.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练后量化对权重和训练后的激活结果进行量化。
- en: Quantization-aware training allows for the training of networks that can be
    quantized with minimal accuracy drop (only available for specific CNNs). Since
    this is a relatively experimental technique, we are not going to discuss it in
    this chapter, but the interested reader can find more information in [1].
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 量化感知训练允许训练能够以最小精度损失进行量化的网络（仅适用于特定的 CNN）。由于这是一种相对实验性的技术，我们在本章中不讨论，但有兴趣的读者可以在[1]中找到更多信息。
- en: 'TensorFlow Lite supports reducing the precision of values from full floats
    to half-precision floats (`float16`) or 8-bit integers. TensorFlow reports multiple
    trade-offs in terms of accuracy, latency, and space for selected CNN models (see
    *Figure 19.5*, source: [https://www.tensorflow.org/lite/performance/model_optimization](https://www.tensorflow.org/lite/performance/model_optimization)):'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Lite 支持将数值的精度从全浮点数降低到半精度浮点数（`float16`）或 8 位整数。TensorFlow 报告了关于精度、延迟和空间的多种权衡，适用于选定的
    CNN 模型（见 *图 19.5*，来源：[https://www.tensorflow.org/lite/performance/model_optimization](https://www.tensorflow.org/lite/performance/model_optimization)）：
- en: '![Table  Description automatically generated](img/B18331_19_05.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![表格 说明自动生成](img/B18331_19_05.png)'
- en: 'Figure 19.5: Trade-offs for various quantized CNN models'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.5：不同量化 CNN 模型的权衡
- en: FlatBuffers
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FlatBuffers
- en: FlatBuffers ([https://google.github.io/flatbuffers/](https://google.github.io/flatbuffers/))
    is an open-source format optimized to serialize data on mobile and embedded devices.
    The format was originally created at Google for game development and other performance-critical
    applications. FlatBuffers supports access to serialized data without parsing/unpacking
    for fast processing. The format is designed for memory efficiency and speed by
    avoiding unnecessary multiple copies in memory. FlatBuffers works across multiple
    platforms and languages such as C++, C#, C, Go, Java, JavaScript, Lobster, Lua,
    TypeScript, PHP, Python, and Rust.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: FlatBuffers（[https://google.github.io/flatbuffers/](https://google.github.io/flatbuffers/)）是一种开源格式，经过优化用于在移动和嵌入式设备上序列化数据。该格式最初由
    Google 为游戏开发和其他性能关键型应用创建。FlatBuffers 支持无需解析/解包即可访问序列化数据，以便进行快速处理。该格式通过避免在内存中进行不必要的多重复制，旨在提高内存效率和速度。FlatBuffers
    支持跨多个平台和语言，如 C++、C#、C、Go、Java、JavaScript、Lobster、Lua、TypeScript、PHP、Python 和 Rust。
- en: Mobile converter
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 移动转换器
- en: A model generated with TensorFlow needs to be converted into a TensorFlow Lite
    model. The converter can introduce optimizations for improving the binary size
    and performance. For instance, the converter can trim away all the nodes in a
    computational graph that are not directly related to inference but instead are
    needed for training.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 生成的模型需要转换为 TensorFlow Lite 模型。转换器可以引入优化，以提高二进制文件的大小和性能。例如，转换器可以去除计算图中与推理无关的所有节点，这些节点只是训练时需要的。
- en: Mobile optimized interpreter
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 移动优化的解释器
- en: TensorFlow Lite runs on a highly optimized interpreter that is used to optimize
    the underlying computational graphs, which in turn are used to describe the machine
    learning models. Internally, the interpreter uses multiple techniques to optimize
    the computational graph by inducing a static graph order and by ensuring better
    memory allocation. The interpreter core takes ~100 kb alone or ~300 kb with all
    supported kernels.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Lite 运行在一个高度优化的解释器上，该解释器用于优化底层的计算图，而计算图又用于描述机器学习模型。在内部，解释器使用多种技术来优化计算图，通过引入静态图顺序并确保更好的内存分配。解释器核心本身大约为
    ~100 KB，包含所有支持的内核时大约为 ~300 KB。
- en: Computational graphs are the graphical representation of the learning algorithm;
    here, nodes describe the operations to be performed and edges connecting the nodes
    represent the flow of data. These graphs provide the deep learning frameworks
    with performance efficiency, which we are not able to achieve if we construct
    a neural network in pure NumPy.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 计算图是学习算法的图形表示；在这里，节点描述要执行的操作，连接节点的边表示数据的流动。这些图形为深度学习框架提供了性能效率，而如果我们在纯 NumPy
    中构建神经网络，是无法实现这种效率的。
- en: Supported platforms
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 支持的平台
- en: On Android, the TensorFlow Lite inference can be performed using either Java
    or C++. On iOS, TensorFlow Lite inference can run in Swift and Objective-C. On
    Linux platforms (such as Raspberry Pi), inferences run in C++ and Python. TensorFlow
    Lite for microcontrollers is an experimental port of TensorFlow Lite designed
    to run machine learning models on microcontrollers based on Arm Cortex-M ([https://developer.arm.com/ip-products/processors/cortex-m](https://developer.arm.com/ip-products/processors/cortex-m))
    and series processors, including Arduino Nano 33 BLE Sense ([https://store.arduino.cc/nano-33-ble-sense-with-headers](https://store.arduino.cc/nano-33-ble-sense-with-headers)),
    SparkFun Edge ([https://www.sparkfun.com/products/15170](https://www.sparkfun.com/products/15170)),
    and the STM32F746 Discovery kit ([https://www.st.com/en/evaluation-tools/32f746gdiscovery.xhtml](https://www.st.com/en/evaluation-tools/32f746gdiscovery.xhtml)).
    These microcontrollers are frequently used for IoT applications.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Android 上，TensorFlow Lite 推理可以使用 Java 或 C++ 执行。在 iOS 上，TensorFlow Lite 推理可以在
    Swift 和 Objective-C 中运行。在 Linux 平台（如 Raspberry Pi）上，推理运行在 C++ 和 Python 中。TensorFlow
    Lite for microcontrollers 是 TensorFlow Lite 的一个实验性移植版，旨在运行基于 Arm Cortex-M（[https://developer.arm.com/ip-products/processors/cortex-m](https://developer.arm.com/ip-products/processors/cortex-m)）及系列处理器的微控制器上的机器学习模型，包括
    Arduino Nano 33 BLE Sense（[https://store.arduino.cc/nano-33-ble-sense-with-headers](https://store.arduino.cc/nano-33-ble-sense-with-headers)）、SparkFun
    Edge（[https://www.sparkfun.com/products/15170](https://www.sparkfun.com/products/15170)）和
    STM32F746 Discovery kit（[https://www.st.com/en/evaluation-tools/32f746gdiscovery.xhtml](https://www.st.com/en/evaluation-tools/32f746gdiscovery.xhtml)）。这些微控制器常用于物联网应用。
- en: Architecture
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构
- en: 'The architecture of TensorFlow Lite is described in *Figure 19.6* (from [https://www.tensorflow.org/lite/convert/index](https://www.tensorflow.org/lite/convert/index)).
    As you can see, both **tf.keras** (for example, TensorFlow 2.x) and **low-Level
    APIs** are supported. A standard TensorFlow 2.x model can be converted by using
    **TFLite Converter** and then saved in a **TFLite FlatBuffer** format (named `.tflite`),
    which is then executed by the **TFLite interpreter** on available devices (GPUs
    and CPUs) and on native device APIs. The concrete function in *Figure 19.6* defines
    a graph that can be converted to a TensorFlow Lite model or be exported to a **SavedModel**:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Lite 的架构如 *图 19.6* 所示（来自 [https://www.tensorflow.org/lite/convert/index](https://www.tensorflow.org/lite/convert/index)）。如您所见，**tf.keras**（例如，TensorFlow
    2.x）和 **低级 API** 都得到支持。可以通过 **TFLite Converter** 转换标准 TensorFlow 2.x 模型，然后保存为
    **TFLite FlatBuffer** 格式（文件名为 `.tflite`），然后由 **TFLite 解释器** 在可用设备（GPU 和 CPU）以及本地设备
    API 上执行。*图 19.6* 中的具体功能定义了一个可以转换为 TensorFlow Lite 模型或导出为 **SavedModel** 的图：
- en: '![Diagram  Description automatically generated](img/B18331_19_06.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![Diagram  Description automatically generated](img/B18331_19_06.png)'
- en: 'Figure 19.6: TensorFlow Lite internal architecture'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.6：TensorFlow Lite 内部架构
- en: Using TensorFlow Lite
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 TensorFlow Lite
- en: 'Using TensorFlow Lite involves the following steps:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TensorFlow Lite 包括以下步骤：
- en: '**Model selection**: A standard TensorFlow 2.x model is selected for solving
    a specific task. This can be either a custom-built model or a pretrained model.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型选择**：选择一个标准的 TensorFlow 2.x 模型来解决特定任务。这可以是一个自定义构建的模型，也可以是一个预训练模型。'
- en: '**Model conversion**: The selected model is converted with the TensorFlow Lite
    converter, generally invoked with a few lines of Python code.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型转换**：选择的模型通过 TensorFlow Lite 转换器进行转换，通常只需几行 Python 代码即可调用。'
- en: '**Model deployment**: The converted model is deployed on the chosen device,
    either a phone or an IoT device, and then run by using the TensorFlow Lite interpreter.
    As discussed, APIs are available for multiple languages.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型部署**：转换后的模型部署到选定的设备上，无论是手机还是物联网设备，然后通过 TensorFlow Lite 解释器运行。如前所述，提供了多种语言的
    API。'
- en: '**Model optimization**: The model can be optionally optimized by using the
    TensorFlow Lite optimization framework.'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型优化**：可以选择使用 TensorFlow Lite 优化框架对模型进行优化。'
- en: A generic example of an application
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个应用程序的通用示例
- en: 'In this section, we are going to see how to convert a model to TensorFlow Lite
    and then run it. Note that training can still be performed by TensorFlow in the
    environment that best fits your needs. However, inference runs on the mobile device.
    Let’s see how with the following code fragment in Python:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示如何将模型转换为 TensorFlow Lite 并运行它。请注意，训练仍然可以在最适合您需求的环境中通过 TensorFlow 执行。然而，推理将在移动设备上运行。让我们通过以下
    Python 代码片段来看看：
- en: '[PRE30]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The code is self-explanatory. A standard TensorFlow 2.x model is opened and
    converted by using `tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)`.
    Pretty simple! Note that no specific installation is required. We simply use the
    `tf.lite` API ([https://www.tensorflow.org/api_docs/python/tf/lite](https://www.tensorflow.org/api_docs/python/tf/lite)).
    It is also possible to apply a number of optimizations. For instance, post-training
    quantization can be applied by default:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 代码本身很容易理解。通过使用 `tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)` 打开并转换一个标准的
    TensorFlow 2.x 模型。非常简单！请注意，您无需特定安装。我们只需使用 `tf.lite` API ([https://www.tensorflow.org/api_docs/python/tf/lite](https://www.tensorflow.org/api_docs/python/tf/lite))。还可以应用一些优化。例如，默认情况下可以应用训练后量化：
- en: '[PRE31]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Once the model is converted, it can be copied onto the specific device. Of
    course, this step is different for each different device. Then the model can run
    by using the language you prefer. For instance, in Java the invocation happens
    with the following code snippet:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型转换完成，就可以将其复制到特定的设备上。当然，这一步骤对于每个设备来说有所不同。然后，可以使用您偏好的编程语言来运行模型。例如，在 Java 中，调用的代码如下：
- en: '[PRE32]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Again, pretty simple! What is very useful is that the same steps can be followed
    for a heterogeneous collection of mobile and IoT devices.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，非常简单！非常有用的是，您可以对异构的移动设备和物联网设备集群遵循相同的步骤。
- en: Using GPUs and accelerators
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 GPU 和加速器
- en: 'Modern phones frequently have accelerators on board that allow floating-point
    matrix operations to be performed faster. In this case, the interpreter can use
    the concept of Delegate, and specifically, `GpuDelegate()`, to use GPUs. Let’s
    look at an example in Java:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现代手机通常配备加速器，能够加速浮动点矩阵运算。在这种情况下，解释器可以使用 Delegate 概念，特别是使用 `GpuDelegate()` 来利用
    GPU。我们来看一个 Java 示例：
- en: '[PRE33]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Again, the code is self-commenting. A new `GpuDelegate()` is created and then
    it is used by the interpreter to run the model on a GPU.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，代码也是自注释的。首先创建一个新的 `GpuDelegate()`，然后由解释器使用该代理来在 GPU 上运行模型。
- en: An example of an application
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用程序示例
- en: 'In this section, we are going to use TensorFlow Lite for building an example
    application that is later deployed on Android. We will use Android Studio ([https://developer.android.com/studio/](https://developer.android.com/studio/))
    to compile the code. The first step is to clone the repo with:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 TensorFlow Lite 构建一个示例应用程序，后续将其部署到 Android 上。我们将使用 Android Studio
    ([https://developer.android.com/studio/](https://developer.android.com/studio/))
    来编译代码。第一步是克隆仓库，命令如下：
- en: '[PRE34]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Then we open an existing project (see *Figure 19.7*) with the path `examples/lite/examples/image_classification/android`.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们打开一个现有项目（见 *图 19.7*），路径为 `examples/lite/examples/image_classification/android`。
- en: 'Then you need to install Android Studio from [https://developer.android.com/studio/install](https://developer.android.com/studio/install)
    and an appropriate distribution of Java. In my case, I selected the Android Studio
    macOS distribution and installed Java via `brew` with the following command:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您需要从 [https://developer.android.com/studio/install](https://developer.android.com/studio/install)
    安装 Android Studio 和合适的 Java 版本。在我的情况下，我选择了 macOS 版本的 Android Studio，并通过 `brew`
    使用以下命令安装了 Java：
- en: '[PRE35]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'After that, you can launch the `sdkmanager` and install the required packages.
    In my case, I decided to use the internal emulator and deploy the application
    on a virtual device emulating a Google Pixel 3 XL. The required packages are reported
    in *Figure 19.7*:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您可以启动 `sdkmanager` 并安装所需的包。在我的情况下，我决定使用内部模拟器，并将应用程序部署到模拟 Google Pixel 3
    XL 的虚拟设备上。所需的包在*图 19.7*中列出：
- en: '![Graphical user interface, text  Description automatically generated](img/B18331_19_07.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本 描述自动生成](img/B18331_19_07.png)'
- en: 'Figure 19.7: Required packages to use a Google Pixel 3 XL emulator'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.7：使用 Google Pixel 3 XL 模拟器所需的包
- en: 'Then, start Android Studio and select **Open an existing Android Studio project**,
    as shown in *Figure 19.8*:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，启动 Android Studio，选择 **打开现有的 Android Studio 项目**，如 *图 19.8* 所示：
- en: '![Graphical user interface, text, application  Description automatically generated](img/B18331_19_08.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本，应用程序 描述自动生成](img/B18331_19_08.png)'
- en: 'Figure 19.8: Opening a new Android project'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.8：打开一个新的 Android 项目
- en: 'Open **Adv Manager** (under the **Tool** menu) and follow the instructions
    for how to create a virtual device, like the one shown in *Figure 19.9*:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 打开 **Adv Manager**（在 **工具** 菜单下）并按照如何创建虚拟设备的说明进行操作，如 *图 19.9* 所示：
- en: '![](img/B18331_19_09.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_09.png)'
- en: 'Figure 19.9: Creating a virtual device'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.9：创建虚拟设备
- en: Now that you have the virtual device ready, let us dive into the TensorFlow
    Lite models and see how we can use them.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经准备好了虚拟设备，让我们深入了解TensorFlow Lite模型，并看看如何使用它们。
- en: Pretrained models in TensorFlow Lite
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow Lite中的预训练模型
- en: 'For many interesting use cases, it is possible to use a pretrained model that
    is already suitable for mobile computation. This is a field of active research
    with new proposals coming pretty much every month. Pretrained TensorFlow Lite
    models are available on TensorFlow Hub; these models are ready to use ([https://www.tensorflow.org/lite/models/](https://www.tensorflow.org/lite/models/)).
    As of August 2022, these include:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多有趣的应用场景，可以使用已经适合移动计算的预训练模型。这是一个活跃的研究领域，每个月都会有新的提案。预训练的TensorFlow Lite模型可以在TensorFlow
    Hub上找到；这些模型已准备好使用（[https://www.tensorflow.org/lite/models/](https://www.tensorflow.org/lite/models/)）。截至2022年8月，这些模型包括：
- en: '**Image classification**: Used to identify multiple classes of objects such
    as places, plants, animals, activities, and people.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像分类**：用于识别多个类别的对象，例如地点、植物、动物、活动和人物。'
- en: '**Object detection**: Used to detect multiple objects with bounding boxes.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**目标检测**：用于检测多个带有边界框的对象。'
- en: '**Audio speech synthesis**: Used to generate speech from text.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音合成**：用于从文本生成语音。'
- en: '**Text embedding**: Used to embed textual data.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本嵌入**：用于嵌入文本数据。'
- en: '**Segmentations**: Identifies the shape of objects together with semantic labels
    for people, places, animals, and many additional classes.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分割**：识别对象的形状，并为人物、地点、动物和许多其他类别添加语义标签。'
- en: '**Style transfers**: Used to apply artistic styles to any given image.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**风格迁移**：用于将艺术风格应用于任何给定的图像。'
- en: '**Text classification**: Used to assign different categories to textual content.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本分类**：用于将不同类别分配给文本内容。'
- en: '**Question and answer**: Used to provide answers to questions provided by users.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**问答系统**：用于为用户提供问题的答案。'
- en: In this section, we will discuss some of the optimized pretrained models available
    in TensorFlow Lite out of the box as of August 2022\. These models can be used
    for a large number of mobile and edge computing use cases. Compiling the example
    code is pretty simple.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论截至2022年8月，TensorFlow Lite中一些经过优化的预训练模型。这些模型可用于大量的移动和边缘计算应用场景。编译示例代码非常简单。
- en: You just import a new project from each example directory and Android Studio
    will use Gradle ([https://gradle.org/](https://gradle.org/)) for synching the
    code with the latest version in the repo and for compiling.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 您只需从每个示例目录导入新项目，Android Studio会使用Gradle（[https://gradle.org/](https://gradle.org/)）同步代码并与仓库中的最新版本编译。
- en: 'If you compile all the examples, you should be able to see them in the emulator
    (see *Figure 19.10*). Remember to select **Build** | **Make Project**, and Android
    Studio will do the rest:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您编译了所有示例，应该能够在模拟器中看到它们（请参见*图 19.10*）。记得选择**Build** | **Make Project**，然后Android
    Studio会完成剩下的工作：
- en: '![](img/B18331_19_10.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_10.png)'
- en: 'Figure 19.10: Emulated Google Pixel 3 XL with TensorFlow Lite example applications'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.10：模拟的 Google Pixel 3 XL 运行 TensorFlow Lite 示例应用程序
- en: Edge computing is a distributed computing model that brings computation and
    data closer to the location where it is needed.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算是一种分布式计算模型，将计算和数据带到需要它们的位置。
- en: Image classification
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像分类
- en: 'As of August 2022, the list of available models for pretrained classification
    is rather large, and it offers the opportunity to trade space, accuracy, and performance
    as shown in *Figure 19.11* (source: [https://www.tensorflow.org/lite/models/trained](https://www.tensorflow.org/lite/models/trained)):'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2022年8月，预训练分类模型的可用列表相当庞大，且如*图 19.11*所示，它提供了在空间、准确性和性能之间进行权衡的机会（来源：[https://www.tensorflow.org/lite/models/trained](https://www.tensorflow.org/lite/models/trained)）：
- en: '![](img/B18331_19_11.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_11.png)'
- en: 'Figure 19.11: Space, accuracy, and performance trade-offs for various mobile
    models'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.11：各种移动模型的空间、准确性和性能的权衡
- en: MobileNet V1 is a quantized CNN model described in Benoit Jacob [2]. MobileNet
    V2 is an advanced model proposed by Google [3]. Online, you can also find floating-point
    models, which offer the best balance between model size and performance. Note
    that GPU acceleration requires the use of floating-point models. Note that recently,
    AutoML models for mobile have been proposed based on an automated **mobile neural
    architecture search** (**MNAS**) approach [4], beating the models handcrafted
    by humans.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: MobileNet V1 是在 Benoit Jacob [2] 中描述的量化 CNN 模型。MobileNet V2 是由 Google 提出的先进模型
    [3]。在线上，您也可以找到浮点模型，这些模型在模型大小和性能之间提供了最佳平衡。请注意，GPU 加速需要使用浮点模型。最近，基于自动化的**移动神经架构搜索**（**MNAS**）方法提出了用于移动设备的
    AutoML 模型 [4]，超过了人工设计的模型。
- en: We discussed AutoML in *Chapter 13*, *An Introduction to AutoML*, and the interested
    reader can refer to MNAS documentation in the references [4] for applications
    to mobile devices.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第13章*“AutoML 简介”中讨论了 AutoML，并且感兴趣的读者可以参考参考文献中的 MNAS 文档 [4]，了解其在移动设备上的应用。
- en: Object detection
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对象检测
- en: TensorFlow Lite format models are included in TF Hub. There is a large number
    of pretrained models that can detect multiple objects within an image, with bounding
    boxes. Eighty different classes of objects are recognized. The network is based
    on a pretrained quantized COCO SSD MobileNet V1 model. For each object, the model
    provides the class, the confidence of detection, and the vertices of the bounding
    boxes ([https://tfhub.dev/s?deployment-format=lite&module-type=image-object-detection](https://tfhub.dev/s?deployment-format=lite&module-type=image-object-detection)).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Lite 格式的模型包含在 TF Hub 中。有大量预训练模型可以检测图像中的多个对象，并带有边界框。识别八十种不同类别的对象。该网络基于预训练的量化
    COCO SSD MobileNet V1 模型。对于每个对象，模型提供类别、检测置信度和边界框的顶点（[https://tfhub.dev/s?deployment-format=lite&module-type=image-object-detection](https://tfhub.dev/s?deployment-format=lite&module-type=image-object-detection)）。
- en: Pose estimation
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 姿势估计
- en: TF Hub has a TensorFlow Lite format pretrained model for detecting parts of
    human bodies in an image or a video. For instance, it is possible to detect noses,
    left/right eyes, hips, ankles, and many other parts. Each detection comes with
    an associated confidence score ([https://tfhub.dev/s?deployment-format=lite&module-type=image-pose-detection](https://tfhub.dev/s?deployment-format=lite&module-type=image-pose-detection)).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: TF Hub 有一个 TensorFlow Lite 格式的预训练模型，用于在图像或视频中检测人体的各个部分。例如，可以检测鼻子、左/右眼、臀部、脚踝等许多部位。每个检测都附带一个关联的置信度分数（[https://tfhub.dev/s?deployment-format=lite&module-type=image-pose-detection](https://tfhub.dev/s?deployment-format=lite&module-type=image-pose-detection)）。
- en: Smart reply
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 智能回复
- en: TF Hub also has a TensorFlow Lite format pretrained model for generating replies
    to chat messages. These replies are contextualized and similar to what is available
    on Gmail ([https://tfhub.dev/tensorflow/lite-model/smartreply/1/default/1](https://tfhub.dev/tensorflow/lite-model/smartreply/1/default/1)).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: TF Hub 还有一个 TensorFlow Lite 格式的预训练模型，用于生成聊天消息的回复。这些回复是上下文相关的，类似于 Gmail 上可用的内容（[https://tfhub.dev/tensorflow/lite-model/smartreply/1/default/1](https://tfhub.dev/tensorflow/lite-model/smartreply/1/default/1)）。
- en: Segmentation
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分割
- en: There are pretrained models ([https://tfhub.dev/s?deployment-format=lite&module-type=image-segmentation](https://tfhub.dev/s?deployment-format=lite&module-type=image-segmentation))
    for image segmentation, where the goal is to decide what the semantic labels (for
    example, person, dog, and cat) assigned to every pixel in the input image are.
    Segmentation is based on the DeepLab algorithm [5].
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 有预训练模型（[https://tfhub.dev/s?deployment-format=lite&module-type=image-segmentation](https://tfhub.dev/s?deployment-format=lite&module-type=image-segmentation)）用于图像分割，目标是决定输入图像中每个像素分配的语义标签（例如人、狗和猫）。分割基于
    DeepLab 算法 [5]。
- en: Style transfer
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 风格转移
- en: TensorFlow Lite also supports artistic style transfer (see *Chapter 20*, *Advanced
    Convolutional Neural Networks*) via a combination of a MobileNet V2-based neural
    network, which reduces the input style image to a 100-dimension style vector,
    and a style transform model, which applies the style vector to a content image
    to create the stylized image ([https://tfhub.dev/s?deployment-format=lite&module-type=image-style-transfer](https://tfhub.dev/s?deployment-format=lite&module-type=image-style-transfer)).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Lite 还支持艺术风格转移（见*第20章*“高级卷积神经网络”），通过基于 MobileNet V2 的神经网络将输入的风格图像减少为100维度风格向量，并且应用风格转换模型，将风格向量应用于内容图像以创建风格化的图像（[https://tfhub.dev/s?deployment-format=lite&module-type=image-style-transfer](https://tfhub.dev/s?deployment-format=lite&module-type=image-style-transfer)）。
- en: Text classification
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本分类
- en: 'There are models for text classification and sentiment analysis ([https://tfhub.dev/s?deployment-format=lite&module-type=text-classification](https://tfhub.dev/s?deployment-format=lite&module-type=text-classification))
    trained on the Large Movie Review Dataset v1.0 ([http://ai.stanford.edu/~amaas/data/sentiment/](http://ai.stanford.edu/~amaas/data/sentiment/))
    with IMDb movie reviews that are positive or negative. An example of text classification
    is given in *Figure 19.12*:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些针对文本分类和情感分析的模型（[https://tfhub.dev/s?deployment-format=lite&module-type=text-classification](https://tfhub.dev/s?deployment-format=lite&module-type=text-classification)），这些模型在大型电影评论数据集v1.0（[http://ai.stanford.edu/~amaas/data/sentiment/](http://ai.stanford.edu/~amaas/data/sentiment/)）上进行训练，数据集包含了正面或负面的IMDb电影评论。*图19.12*给出了一个文本分类示例：
- en: '![](img/B18331_19_12.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_12.png)'
- en: 'Figure 19.12: An example of text classification on Android with TensorFlow
    Lite'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.12：使用TensorFlow Lite在Android上的文本分类示例
- en: Large language models
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大型语言模型
- en: 'There are pretrained large language models based on transformer architecture
    ([https://tfhub.dev/s?deployment-format=lite&q=bert](https://tfhub.dev/s?deployment-format=lite&q=bert)).
    The models are based on a compressed variant of BERT [6] (see *Chapter 6*, *Transformers*)
    called MobileBERT [7], which runs 4x faster and has a 4x smaller size. An example
    of Q&A is given in *Figure 19.13*:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 有基于变压器架构的预训练大型语言模型（[https://tfhub.dev/s?deployment-format=lite&q=bert](https://tfhub.dev/s?deployment-format=lite&q=bert)）。这些模型基于BERT
    [6]的压缩变种（参见*第6章*，*变压器*），称为MobileBERT [7]，其运行速度比原版快4倍，且模型大小减少4倍。*图19.13*给出了一个问答示例：
- en: '![](img/B18331_19_13.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_13.png)'
- en: 'Figure 19.13: An example of Q&A on Android with TensorFlow Lite and BERT'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.13：使用TensorFlow Lite和BERT在Android上的问答示例
- en: A note about using mobile GPUs
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于使用移动GPU的说明
- en: 'This section concludes the overview of pretrained models for mobile devices
    and IoT. Note that modern phones are equipped with internal GPUs. For instance,
    on Pixel 3, TensorFlow Lite GPU inference accelerates inference to 2–7x faster
    than CPUs for many models (see *Figure 19.14*, source: [https://blog.tensorflow.org/2019/01/tensorflow-lite-now-faster-with-mobile.xhtml](https://blog.tensorflow.org/2019/01/tensorflow-lite-now-faster-with-mobile.xhtml)):'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 本节总结了针对移动设备和物联网的预训练模型概述。请注意，现代手机配备了内置GPU。例如，在Pixel 3上，TensorFlow Lite的GPU推理可以将推理速度加速到比CPU快2到7倍（参见*图19.14*，来源：[https://blog.tensorflow.org/2019/01/tensorflow-lite-now-faster-with-mobile.xhtml](https://blog.tensorflow.org/2019/01/tensorflow-lite-now-faster-with-mobile.xhtml)）：
- en: '![](img/B18331_19_14.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_14.png)'
- en: 'Figure 19.14: GPU speed-up over CPU for various learning models running on
    various phones'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.14：在不同手机上运行的各种学习模型GPU加速与CPU的对比
- en: An overview of federated learning at the edge
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘计算中的联邦学习概述
- en: As discussed, edge computing is a distributed computing model that brings computation
    and data closer to the location where it is needed.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，边缘计算是一种分布式计算模型，它将计算和数据带到需求的地点。
- en: Now, let’s introduce **Federated Learning** (**FL**) [8] at the edge, starting
    with two use cases.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们介绍边缘的**联邦学习**（**FL**）[8]，从两个使用案例开始。
- en: Suppose you built an app for playing music on mobile devices and then you want
    to add recommendation features aimed at helping users to discover new songs they
    might like. Is there a way to build a distributed model that leverages each user’s
    experience without disclosing any private data?
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你为移动设备开发了一个播放音乐的应用，然后你想添加推荐功能，帮助用户发现他们可能喜欢的新歌曲。有没有一种方法可以构建一个分布式模型，利用每个用户的经验，而不泄露任何私人数据？
- en: Suppose you are a car manufacturer producing millions of cars connected via
    5G networks, and then you want to build a distributed model for optimizing each
    car’s fuel consumption. Is there a way to build such a model without disclosing
    the driving behavior of each user?
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你是一家汽车制造商，生产数百万辆通过5G网络连接的汽车，然后你想要构建一个分布式模型，用于优化每辆车的燃油消耗。有没有一种方法可以在不泄露每个用户的驾驶行为的情况下构建这样的模型？
- en: Traditional machine learning requires you to have a centralized repository for
    training data either on your desktop, in your data center, or in the cloud. Federated
    learning pushes the training phase at the edge by distributing the computation
    among millions of mobile devices. These devices are ephemeral in that they are
    not always available for the learning process, and they can disappear silently
    (for instance, a mobile phone can be switched off all of a sudden). The key idea
    is to leverage the CPUs and the GPU of each mobile phone that is made available
    for an FL computation. Each mobile device that is part of the distributed FL training
    downloads a (pretrained) model from a central server, and it performs local optimization
    based on the local training data collected on each specific mobile device. This
    process is similar to the transfer learning process (see *Chapter 20*, *Advanced
    Convolutional Neural Networks*), but it is distributed at the edge. Each locally
    updated model is then sent back by millions of edge devices to a central server
    to build an averaged shared model.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的机器学习要求你拥有一个集中式的训练数据存储库，无论是在你的桌面、数据中心还是云端。联邦学习通过将计算分配到数百万个移动设备上，将训练阶段推送到边缘。这些设备是短暂的，因为它们并非始终可用进行学习过程，并且它们可能会悄无声息地消失（例如，手机可能突然关机）。关键思想是利用每个参与
    FL 计算的手机的 CPU 和 GPU。每个参与分布式 FL 训练的移动设备从中央服务器下载一个（预训练的）模型，并基于每个特定移动设备收集的本地训练数据进行本地优化。这个过程类似于迁移学习过程（见*第
    20 章*，*高级卷积神经网络*），但它是在边缘进行分布式的。每个本地更新的模型随后由数百万个边缘设备发送回中央服务器，以构建一个平均共享的模型。
- en: 'Of course, there are many issues to be considered. Let’s review them:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，还有许多问题需要考虑。让我们回顾一下：
- en: '**Battery usage**: Each mobile device that is part of an FL computation should
    save as much as possible on local battery usage.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电池使用**：每个参与 FL 计算的移动设备应尽量减少本地电池的使用。'
- en: '**Encrypted communication**: Each mobile device belonging to an FL computation
    has to use encrypted communication with the central server to update the locally
    built model.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加密通信**：每个属于 FL 计算的移动设备必须使用加密通信与中央服务器更新本地构建的模型。'
- en: '**Efficient communication**: Typically, deep learning models are optimized
    with optimization algorithms such as SGD (see *Chapter 1*, *Neural Network Foundations
    with TF*, and *Chapter 14*, *The Math Behind Deep Learning*). However, FL works
    with millions of devices and there is, therefore, a strong need to minimize the
    communication patterns. Google introduced a Federated Averaging algorithm [8],
    which is reported to reduce the amount of communication 10x–100x when compared
    with vanilla SGD. Plus, compression techniques [9] reduce communication costs
    by an additional 100x with random rotations and quantization.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高效通信**：通常，深度学习模型通过诸如 SGD（见*第 1 章*，*基于 TF 的神经网络基础*，以及*第 14 章*，*深度学习背后的数学*）等优化算法进行优化。然而，FL
    与数百万设备合作，因此强烈需要最小化通信模式。谷歌推出了一种联邦平均算法 [8]，据报道，与传统的 SGD 相比，这种算法可以将通信量减少 10 倍到 100
    倍。此外，压缩技术 [9] 通过随机旋转和量化进一步将通信成本降低 100 倍。'
- en: '**Ensure user privacy**: This is probably the most important point. All local
    training data acquired at the edge must stay at the edge. This means that the
    training data acquired on a mobile device cannot be sent to a central server.
    Equally important, any user behavior learned in locally trained models must be
    anonymized so that it is not possible to understand any specific action performed
    by specific individuals.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**确保用户隐私**：这可能是最重要的一点。所有在边缘获取的本地训练数据必须保留在边缘。这意味着，在移动设备上获取的训练数据不能发送到中央服务器。同样重要的是，任何在本地训练模型中学习到的用户行为必须被匿名化，以确保无法识别出具体个体执行的任何特定操作。'
- en: '*Figure 19.15* shows a typical FL architecture [10]. An FL server sends a model
    and a training plan to millions of devices. The training plan includes information
    on how frequently updates are expected and other metadata.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 19.15* 显示了一个典型的 FL 架构 [10]。FL 服务器将模型和训练计划发送给数百万个设备。训练计划包含有关更新频率和其他元数据的信息。'
- en: 'Each device runs the local training and sends a model update back to the global
    services. Note that each device has an FL runtime providing federated learning
    services to an app process that stores data in a local example store. The FL runtime
    fetches the training examples from the example store:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 每个设备都进行本地训练，并将模型更新发送回全球服务。请注意，每个设备都有一个FL运行时，为存储数据的本地示例库中的应用进程提供联邦学习服务。FL运行时从示例库中获取训练示例：
- en: '![](img/B18331_19_15.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_15.png)'
- en: 'Figure 19.15: An example of federated learning architecture'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.15：联邦学习架构示例
- en: TensorFlow FL APIs
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow FL API
- en: '**The TensorFlow Federated** (**TTF**) platform has two layers:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorFlow Federated**（**TTF**）平台有两层：'
- en: '**Federated learning** (**FL**), as discussed earlier, is a high-level interface
    that works well with `tf.keras` and non-`tf.keras` models. In the majority of
    situations, we will use this API for distributed training that is privacy-preserving.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**联邦学习**（**FL**），如前所述，是一个与`tf.keras`和非`tf.keras`模型配合良好的高级接口。在大多数情况下，我们将使用这个API进行隐私保护的分布式训练。'
- en: '**Federated core** (**FC**), a low-level interface that is highly customizable
    and allows you to interact with low-level communications and with federated algorithms.
    You will need this API only if you intend to implement new and sophisticated distributed
    learning algorithms. This topic is rather advanced, and we are not going to cover
    it in this book. If you wish to learn more, you can find more information online
    ([https://www.tensorflow.org/federated/federated_core](https://www.tensorflow.org/federated/federated_core)).'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**联邦核心**（**FC**），一个高度可定制的低级接口，允许你与低级通信和联邦算法进行交互。只有在你打算实现新的和复杂的分布式学习算法时，你才需要这个API。这个主题相当高级，我们在本书中不会详细讨论。如果你想了解更多，可以在线找到更多信息（[https://www.tensorflow.org/federated/federated_core](https://www.tensorflow.org/federated/federated_core)）。'
- en: 'The FL API has three key parts:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: FL API有三个关键部分：
- en: '**Models**: Used to wrap existing models for enabling federating learning.
    This can be achieved via the `tff.learning.from_keras_model()`, or via the subclassing
    of `tff.learning.Model()`. For instance, you can have the following code fragment:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型**：用于封装现有模型以启用联邦学习。这可以通过`tff.learning.from_keras_model()`实现，或者通过子类化`tff.learning.Model()`实现。例如，你可以使用以下代码片段：'
- en: '[PRE36]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '**Builders**: This is the layer where the federated computation happens. There
    are two phases: compilation, where the learning algorithm is serialized into an
    abstract representation of the computation, and execution, where the represented
    computation is run.'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建器**：这是联邦计算发生的层。该层有两个阶段：编译阶段，将学习算法序列化为计算的抽象表示；执行阶段，运行表示的计算。'
- en: '**Datasets**: This is a large collection of data that can be used to simulate
    federated learning locally – a useful step for initial fine-tuning.'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据集**：这是一个可以用于在本地模拟联邦学习的大型数据集——这是进行初步微调的有用步骤。'
- en: 'We conclude this overview by mentioning that you can find a detailed description
    of the APIs online and also a number of coding examples ([https://www.tensorflow.org/federated/federated_learning](https://www.tensorflow.org/federated/federated_learning)).
    Start by using the Colab notebook made available by Google ([https://colab.research.google.com/github/tensorflow/federated/blob/v0.10.1/docs/tutorials/federated_learning_for_image_classification.ipynb](https://colab.research.google.com/github/tensorflow/federated/blob/v0.10.1/docs/tutorials/federated_learning_for_image_classification.ipynb)).
    The framework allows us to simulate the distributed training before running it
    in a real environment. The library in charge of FL learning is `tensorflow_federated`.
    *Figure 19.16* discusses all the steps used in federated learning with multiple
    nodes, and it might be useful to better understand what has been discussed in
    this section:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过提到你可以在线找到API的详细描述以及许多编码示例来结束这个概述（[https://www.tensorflow.org/federated/federated_learning](https://www.tensorflow.org/federated/federated_learning)）。可以通过Google提供的Colab笔记本开始使用（[https://colab.research.google.com/github/tensorflow/federated/blob/v0.10.1/docs/tutorials/federated_learning_for_image_classification.ipynb](https://colab.research.google.com/github/tensorflow/federated/blob/v0.10.1/docs/tutorials/federated_learning_for_image_classification.ipynb)）。该框架允许我们在真实环境中运行之前模拟分布式训练。负责FL学习的库是`tensorflow_federated`。*图
    19.16*讨论了在多个节点上进行联邦学习的所有步骤，可能有助于更好地理解本节讨论的内容：
- en: '![](img/B18331_19_16.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_16.png)'
- en: 'Figure 19.16: An example of federated learning with multiple nodes (source:
    https://upload.wikimedia.org/wikipedia/commons/e/e2/Federated_learning_process_central_case.png)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.16：带有多个节点的联邦学习示例（来源：[https://upload.wikimedia.org/wikipedia/commons/e/e2/Federated_learning_process_central_case.png](https://upload.wikimedia.org/wikipedia/commons/e/e2/Federated_learning_process_central_case.png)）
- en: The next section will introduce TensorFlow.js, a variant of TensorFlow that
    can be used natively in JavaScript.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将介绍 TensorFlow.js，这是一个 TensorFlow 的变种，可以在 JavaScript 中本地使用。
- en: TensorFlow.js
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow.js
- en: TensorFlow.js is a JavaScript library for machine learning models that can work
    either in vanilla mode or via Node.js. In this section, we are going to review
    both of them.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow.js 是一个用于机器学习模型的 JavaScript 库，可以在常规模式或通过 Node.js 模式下工作。在本节中，我们将回顾这两种模式。
- en: Vanilla TensorFlow.js
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常规 TensorFlow.js
- en: TensorFlow.js is a JavaScript library for training and using machine learning
    models in a browser. It is derived from deeplearn.js, an open-source, hardware-accelerated
    library for doing deep learning in JavaScript, and is now a companion library
    to TensorFlow.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow.js 是一个用于在浏览器中训练和使用机器学习模型的 JavaScript 库。它源自 deeplearn.js，这是一个开源的硬件加速库，用于在
    JavaScript 中进行深度学习，现在它是 TensorFlow 的一个伴随库。
- en: The most common use of TensorFlow.js is to make pretrained ML/DL models available
    on the browser. This can help in situations where it may not be feasible to send
    client data back to the server due to network bandwidth or security concerns.
    However, TensorFlow.js is a full-stack ML platform, and it is possible to build
    and train an ML/DL model from scratch, as well as fine-tune an existing pretrained
    model with new client data.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow.js 最常见的用途是使预训练的机器学习/深度学习模型在浏览器中可用。这在一些情况下非常有用，比如由于网络带宽或安全问题，无法将客户端数据发送回服务器。然而，TensorFlow.js
    是一个全栈的机器学习平台，除了可以构建和训练机器学习/深度学习模型外，还可以用新的客户端数据微调现有的预训练模型。
- en: An example of a TensorFlow.js application is the TensorFlow Projector ([https://projector.tensorflow.org](https://projector.tensorflow.org)),
    which allows a client to visualize their own data (as word vectors) in 3-dimensional
    space, using one of several dimensionality reduction algorithms provided. There
    are a few other examples of TensorFlow.js applications listed on the TensorFlow.js
    demo page ([https://www.tensorflow.org/js/demos](https://www.tensorflow.org/js/demos)).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 TensorFlow.js 应用示例是 TensorFlow Projector ([https://projector.tensorflow.org](https://projector.tensorflow.org))，它允许客户端在三维空间中可视化他们自己的数据（作为词向量），并使用提供的几种降维算法之一。TensorFlow.js
    演示页面上列出了其他一些 TensorFlow.js 应用示例 ([https://www.tensorflow.org/js/demos](https://www.tensorflow.org/js/demos))。
- en: Similar to TensorFlow, TensorFlow.js also provides two main APIs – the Ops API,
    which exposes low-level tensor operations such as matrix multiplication, and the
    Layers API, which exposes Keras-style high-level building blocks for neural networks.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 TensorFlow，TensorFlow.js 也提供了两个主要的 API——Ops API，它提供低级别的张量操作，如矩阵乘法；以及 Layers
    API，它提供了 Keras 风格的神经网络高级构建模块。
- en: At the time of writing, TensorFlow.js runs on three different backends. The
    fastest (and also the most complex) is the WebGL backend, which provides access
    to WebGL’s low-level 3D graphics APIs and can take advantage of GPU hardware acceleration.
    The other popular backend is the Node.js backend, which allows the use of TensorFlow.js
    in server-side applications. Finally, as a fallback, there is the CPU-based implementation
    in plain JavaScript that will run in any browser.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，TensorFlow.js 在三种不同的后端上运行。最快的（也是最复杂的）是 WebGL 后端，它提供了对 WebGL 低级别 3D 图形
    API 的访问，并且可以利用 GPU 硬件加速。另一个流行的后端是 Node.js 后端，它允许在服务器端应用中使用 TensorFlow.js。最后，作为备选方案，还有基于
    CPU 的纯 JavaScript 实现，可以在任何浏览器中运行。
- en: In order to gain a better understanding of how to write a TensorFlow.js application,
    we will walk through an example of classifying MNIST digits using a CNN provided
    by the TensorFlow.js team ([https://storage.googleapis.com/tfjs-examples/mnist/dist/index.xhtml](https://storage.googleapis.com/tfjs-examples/mnist/dist/index.xhtml)).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解如何编写 TensorFlow.js 应用程序，我们将通过一个示例来展示如何使用 TensorFlow.js 团队提供的卷积神经网络（CNN）对
    MNIST 手写数字进行分类 ([https://storage.googleapis.com/tfjs-examples/mnist/dist/index.xhtml](https://storage.googleapis.com/tfjs-examples/mnist/dist/index.xhtml))。
- en: The steps here are similar to a normal supervised model development pipeline
    – load the data, define, train, and evaluate the model.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的步骤与正常的监督学习模型开发流程类似——加载数据、定义、训练和评估模型。
- en: 'JavaScript works inside a browser environment, within an HTML page. The HTML
    file (named `index.xhtml`) below represents this HTML page. Notice the two imports
    for TensorFlow.js (`tf.min.js`) and the TensorFlow.js visualization library (`tfjs-vis.umd.min.js`)
    – these provide library functions that we will use in our application. The JavaScript
    code for our application comes from `data.js` and `script.js` files, located in
    the same directory as our `index.xhtml` file:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: JavaScript在浏览器环境内工作，在HTML页面中。下面的HTML文件（命名为`index.xhtml`）表示该HTML页面。注意两个TensorFlow.js（`tf.min.js`）和TensorFlow.js可视化库（`tfjs-vis.umd.min.js`）的导入——这些提供了我们在应用中使用的库函数。我们的应用程序的JavaScript代码来自`data.js`和`script.js`文件，位于与`index.xhtml`文件相同的目录中：
- en: '[PRE37]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'For deployment, we will deploy these three files (`index.xhtml`, `data.js`,
    and `script.js`) on a web server, but for development, we can start a web server
    up by calling a simple one bundled with the Python distribution. This will start
    up a web server on port `8000` on `localhost`, and the `index.xhtml` file can
    be rendered on the browser at `http://localhost:8000`:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 对于部署，我们将这三个文件（`index.xhtml`、`data.js`和`script.js`）部署到一个网络服务器上，但对于开发，我们可以通过调用一个简单的、与Python发行版一起捆绑的Web服务器来启动一个Web服务器。这将在`localhost`的`8000`端口启动一个Web服务器，`index.xhtml`文件可以通过浏览器在`http://localhost:8000`上进行渲染：
- en: '[PRE38]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The next step is to load the data. Fortunately, Google provides a JavaScript
    script that we have called directly from our `index.xhtml` file. It downloads
    the images and labels from GCP storage and returns shuffled and normalized batches
    of image and label pairs for training and testing. We can download this to the
    same folder as the `index.xhtml` file using the following command:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是加载数据。幸运的是，Google提供了一个JavaScript脚本，我们直接从`index.xhtml`文件中调用它。它从GCP存储中下载图像和标签，并返回已打乱并标准化的图像和标签对的批次，用于训练和测试。我们可以使用以下命令将其下载到与`index.xhtml`文件相同的文件夹中：
- en: '[PRE39]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'For Windows users, you will need to first download Wget: [https://eternallybored.org/misc/wget/](https://eternallybored.org/misc/wget/)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Windows用户，你需要首先下载Wget：[https://eternallybored.org/misc/wget/](https://eternallybored.org/misc/wget/)
- en: 'Model definition, training, and evaluation code is all specified inside the
    `script.js` file. The function to define and build the network is shown in the
    following code block. As you can see, it is very similar to the way you would
    build a sequential model with `tf.keras`. The only difference is the way you specify
    the arguments, as a dictionary of name-value pairs instead of a list of parameters.
    The model is a sequential model, that is, a list of layers. Finally, the model
    is compiled with the Adam optimizer:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 模型定义、训练和评估的代码都在`script.js`文件中指定。定义和构建网络的函数显示在下面的代码块中。正如你所看到的，它与使用`tf.keras`构建顺序模型的方法非常相似。唯一的不同是指定参数的方式，它使用的是名称-值对的字典，而不是参数列表。这个模型是一个顺序模型，也就是说，它是一个层的列表。最后，模型使用Adam优化器进行编译：
- en: '[PRE40]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The model is then trained for 10 epochs with batches from the training dataset
    and validated inline using batches from the test dataset. A best practice is to
    create a separate validation dataset from the training set. However, to keep our
    focus on the more important aspect of showing how to use TensorFlow.js to design
    an end-to-end DL pipeline, we are using the external `data.js` file provided by
    Google, which provides functions to return only a training and test batch. In
    our example, we will use the test dataset for validation as well as evaluation
    later.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，模型将在10个epochs内使用来自训练数据集的批次进行训练，并使用来自测试数据集的批次进行内联验证。最佳实践是从训练集中创建一个单独的验证数据集。然而，为了保持我们专注于展示如何使用TensorFlow.js设计端到端DL管道的更重要方面，我们使用了Google提供的外部`data.js`文件，该文件提供了返回仅训练和测试批次的函数。在我们的示例中，我们将使用测试数据集进行验证，并稍后进行评估。
- en: 'This is likely to give us better accuracies compared to what we would have
    achieved with an unseen (during training) test set, but that is unimportant for
    an illustrative example such as this one:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能会给我们带来比使用一个未见过的（在训练过程中未见过的）测试集时更好的准确度，但对于像这样说明性的示例来说，这并不重要：
- en: '[PRE41]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Once the model finishes training, we want to make predictions and evaluate
    the model on its predictions. The following functions will do the predictions
    and compute the overall accuracy for each of the classes over all the test set
    examples, as well as produce a confusion matrix across all the test set samples:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型完成训练，我们希望进行预测并评估模型的预测。以下函数将进行预测，并计算所有测试集示例中每个类别的总体准确性，同时生成整个测试集样本的混淆矩阵：
- en: '[PRE42]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Finally, the `run()` function will call all these functions in sequence to
    build an end-to-end ML pipeline:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`run()`函数将按顺序调用所有这些函数，以构建端到端的机器学习管道：
- en: '[PRE43]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Refreshing the browser location, `http://localhost:8000/index.xhtml`, will invoke
    the `run()` method above. *Figure 19.17* shows the model architecture and the
    plots of the progress of the training.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 刷新浏览器位置`http://localhost:8000/index.xhtml`，将调用上面的`run()`方法。*图 19.17*展示了模型架构和训练进度的图表。
- en: 'On the left are the loss and accuracy values on the validation dataset observed
    at the end of each batch, and on the right are the same loss and accuracy values
    observed on the training dataset (blue) and validation dataset (red) at the end
    of each epoch:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧显示的是每个批次结束时在验证数据集上的损失和准确度值，右侧显示的是每个时期结束时在训练数据集（蓝色）和验证数据集（红色）上的损失和准确度值：
- en: '![](img/B18331_19_17.1.png)![](img/B18331_19_17.2.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_17.1.png)![](img/B18331_19_17.2.png)'
- en: 'Figure 19.17: Model loss and accuracy as it is being trained'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.17：模型损失和准确度在训练过程中的变化
- en: 'In addition, the following figure shows the accuracies across different classes
    for predictions from our trained model on the test dataset, as well as the confusion
    matrix of predicted versus actual classes for test dataset samples:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，以下图表展示了我们训练的模型在测试数据集上进行预测时，不同类别的准确度，以及测试数据集样本的预测类别与实际类别的混淆矩阵：
- en: '![](img/B18331_19_18.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18331_19_18.png)'
- en: 'Figure 19.18: Confusion metrics and accuracy for each class as obtained by
    the trained model'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.18：通过训练后的模型获得的混淆矩阵和每个类别的准确度
- en: 'Readers might enjoy seeing this live example from the TensorFlow team training
    a TFJS model on the MNIST dataset: [https://storage.googleapis.com/tfjs-examples/mnist/dist/index.xhtml](https://storage.googleapis.com/tfjs-examples/mnist/dist/index.xhtml).'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 读者可能会对TensorFlow团队在MNIST数据集上训练TFJS模型的这个实时示例感兴趣：[https://storage.googleapis.com/tfjs-examples/mnist/dist/index.xhtml](https://storage.googleapis.com/tfjs-examples/mnist/dist/index.xhtml)。
- en: We have seen how to use TensorFlow.js within the browser. The next section will
    explain how to convert a model from Keras into TensorFlow.js.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经学习了如何在浏览器中使用TensorFlow.js。下一节将解释如何将Keras模型转换为TensorFlow.js模型。
- en: Converting models
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换模型
- en: 'Sometimes it is convenient to convert a model that has already been created
    with `tf.keras`. This is very easy and can be done offline with the following
    command, which takes a Keras model from `/tmp/model.h5` and outputs a JavaScript
    model into `/tmp/tfjs_model`:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 有时将已经用`tf.keras`创建的模型转换成其他格式非常方便。这非常简单，可以离线使用以下命令完成，该命令将从`/tmp/model.h5`中获取Keras模型，并将JavaScript模型输出到`/tmp/tfjs_model`目录中：
- en: '[PRE44]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'To be able to use this command, you will need a Python environment with TensorFlow
    JS installed using:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用此命令，您需要一个安装了TensorFlow JS的Python环境，可以使用以下命令进行安装：
- en: '[PRE45]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: This will install the above converter. The next section will explain how to
    use pretrained models in TensorFlow.js.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这将安装上述转换器。下一节将解释如何在TensorFlow.js中使用预训练模型。
- en: Pretrained models
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预训练模型
- en: TensorFlow.js comes with a significant number of pretrained models for deep
    learning with image, video, and text. The models are hosted on npm, so it’s very
    simple to use them if you are familiar with Node.js development.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow.js提供了大量的深度学习预训练模型，涵盖图像、视频和文本。由于这些模型托管在npm上，如果您熟悉Node.js开发，使用它们会非常简单。
- en: '*Table 19.1* summarizes some of the pretrained models available as of August
    2022 (source: [https://github.com/tensorflow/tfjs-models](https://github.com/tensorflow/tfjs-models)):'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '*表 19.1*总结了截至2022年8月可用的一些预训练模型（来源：[https://github.com/tensorflow/tfjs-models](https://github.com/tensorflow/tfjs-models)）：'
- en: '| **Images** |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| **图片** |'
- en: '| **Model** | **Details** | **Install** |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **详情** | **安装** |'
- en: '| MobileNet ([https://github.com/tensorflow/tfjs-models/tree/master/mobilenet](https://github.com/tensorflow/tfjs-models/tree/master/mobilenet))
    | Classify images with labels from the ImageNet database. | `npm i @tensorflow-models/mobilenet`
    |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| MobileNet ([https://github.com/tensorflow/tfjs-models/tree/master/mobilenet](https://github.com/tensorflow/tfjs-models/tree/master/mobilenet))
    | 使用ImageNet数据库的标签进行图像分类。 | `npm i @tensorflow-models/mobilenet` |'
- en: '| PoseNet ([https://github.com/tensorflow/tfjs-models/tree/master/posenet](https://github.com/tensorflow/tfjs-models/tree/master/posenet))
    | A machine learning model that allows for real-time human pose estimation in
    the browser; see a detailed description here: [https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5](https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5).
    | `npm i @tensorflow-models/posenet` |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| PoseNet ([https://github.com/tensorflow/tfjs-models/tree/master/posenet](https://github.com/tensorflow/tfjs-models/tree/master/posenet))
    | 一个机器学习模型，允许在浏览器中实时进行人体姿势估计；详细描述请参见：[https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5](https://medium.com/tensorflow/real-time-human-pose-estimation-in-the-browser-with-tensorflow-js-7dd0bc881cd5)。
    | `npm i @tensorflow-models/posenet` |'
- en: '| Coco SSD ([https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd](https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd))
    | Object detection model that aims to localize and identify multiple objects in
    a single image; based on the TensorFlow object detection API ([https://github.com/tensorflow/models/blob/master/research/object_detection/README.md](https://github.com/tensorflow/models/blob/master/research/object_detection/README.md)).
    | `npm i @tensorflow-models/coco-ssd` |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| Coco SSD ([https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd](https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd))
    | 物体检测模型，旨在定位和识别单张图像中的多个物体；基于 TensorFlow 物体检测 API ([https://github.com/tensorflow/models/blob/master/research/object_detection/README.md](https://github.com/tensorflow/models/blob/master/research/object_detection/README.md))。
    | `npm i @tensorflow-models/coco-ssd` |'
- en: '| BodyPix ([https://github.com/tensorflow/tfjs-models/tree/master/body-pix](https://github.com/tensorflow/tfjs-models/tree/master/body-pix))
    | Real-time person and body-part segmentation in the browser using TensorFlow.js.
    | `npm i @tensorflow-models/body-pix` |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| BodyPix ([https://github.com/tensorflow/tfjs-models/tree/master/body-pix](https://github.com/tensorflow/tfjs-models/tree/master/body-pix))
    | 使用 TensorFlow.js 在浏览器中实时进行人体和身体部位分割。 | `npm i @tensorflow-models/body-pix` |'
- en: '| DeepLab v3([https://github.com/tensorflow/tfjs-models/tree/master/deeplab](https://github.com/tensorflow/tfjs-models/tree/master/deeplab))
    | Semantic segmentation. | `npm i @tensorflow-models/deeplab` |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| DeepLab v3([https://github.com/tensorflow/tfjs-models/tree/master/deeplab](https://github.com/tensorflow/tfjs-models/tree/master/deeplab))
    | 语义分割。 | `npm i @tensorflow-models/deeplab` |'
- en: '| **Audio** |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| **音频** |'
- en: '| **Model** | **Details** | **Install** |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **详情** | **安装** |'
- en: '| Speech Commands ([https://github.com/tensorflow/tfjs-models/tree/master/speech-commands](https://github.com/tensorflow/tfjs-models/tree/master/speech-commands))
    | Classify 1-second audio snippets from the speech commands dataset ([https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md)).
    | `npm i @tensorflow-models/speech-commands` |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| Speech Commands ([https://github.com/tensorflow/tfjs-models/tree/master/speech-commands](https://github.com/tensorflow/tfjs-models/tree/master/speech-commands))
    | 对来自语音命令数据集的 1 秒音频片段进行分类 ([https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md))。
    | `npm i @tensorflow-models/speech-commands` |'
- en: '| **Text** |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| **文本** |'
- en: '| **Model** | **Details** | **Install** |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **详情** | **安装** |'
- en: '| Universal Sentence Encoder ([https://github.com/tensorflow/tfjs-models/tree/master/universal-sentence-encoder](https://github.com/tensorflow/tfjs-models/tree/master/universal-sentence-encoder))
    | Encode text into a 512-dimensional embedding to be used as inputs to natural
    language processing tasks such as sentiment classification and textual similarity.
    | `npm i @tensorflow-models/universal-sentence-encoder` |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| Universal Sentence Encoder ([https://github.com/tensorflow/tfjs-models/tree/master/universal-sentence-encoder](https://github.com/tensorflow/tfjs-models/tree/master/universal-sentence-encoder))
    | 将文本编码为 512 维度的嵌入，用于自然语言处理任务，如情感分类和文本相似度分析。 | `npm i @tensorflow-models/universal-sentence-encoder`
    |'
- en: '| Text Toxicity ([https://github.com/tensorflow/tfjs-models/tree/master/toxicity](https://github.com/tensorflow/tfjs-models/tree/master/toxicity))
    | Score the perceived impact a comment might have on a conversation, from “Very
    toxic” to “Very healthy”. | `npm i @tensorflow-models/toxicity` |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| Text Toxicity ([https://github.com/tensorflow/tfjs-models/tree/master/toxicity](https://github.com/tensorflow/tfjs-models/tree/master/toxicity))
    | 评估评论可能对对话产生的影响，从“非常有毒”到“非常健康”。 | `npm i @tensorflow-models/toxicity` |'
- en: '| **General Utilities** |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| **通用工具** |'
- en: '| **Model** | **Details** | **Install** |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **详情** | **安装** |'
- en: '| KNN Classifier ([https://github.com/tensorflow/tfjs-models/tree/master/knn-classifier](https://github.com/tensorflow/tfjs-models/tree/master/knn-classifier))
    | This package provides a utility for creating a classifier using the K-nearest
    neighbors algorithm; it can be used for transfer learning. | `npm i @tensorflow-models/knn-classifier`
    |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| KNN 分类器 ([https://github.com/tensorflow/tfjs-models/tree/master/knn-classifier](https://github.com/tensorflow/tfjs-models/tree/master/knn-classifier))
    | 该包提供了一个创建 K-近邻分类器的工具；它可以用于迁移学习。 | `npm i @tensorflow-models/knn-classifier`
    |'
- en: 'Table 19.1: A list of some of the pretrained models on TensorFlow.js'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 表 19.1：TensorFlow.js 上一些预训练模型的列表
- en: 'Each pretrained model can be directly used from HTML. For instance, this is
    an example with the KNN classifier:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 每个预训练模型可以直接从 HTML 中使用。例如，这是一个使用 KNN 分类器的示例：
- en: '[PRE46]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The next section will explain how to use pretrained models in Node.js.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将解释如何在 Node.js 中使用预训练模型。
- en: Node.js
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Node.js
- en: In this section, we will give an overview of how to use TensorFlow with Node.js.
    Let’s start.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将概述如何在 Node.js 中使用 TensorFlow。让我们开始吧。
- en: 'The CPU package is imported with the following line of code, which will work
    for all macOS, Linux, and Windows platforms:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: CPU 包通过以下代码行导入，这将适用于所有 macOS、Linux 和 Windows 平台：
- en: '[PRE47]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The GPU package is imported with the following line of code (as of November
    2019, this will work only on a GPU in a CUDA environment):'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: GPU 包通过以下代码行导入（截至 2019 年 11 月，这仅适用于 CUDA 环境中的 GPU）：
- en: '[PRE48]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'An example of Node.js code for defining and compiling a simple dense model
    is reported below. The code is self-explanatory:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个 Node.js 代码示例，用于定义和编译一个简单的全连接模型。代码不言自明：
- en: '[PRE49]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Training can then start with the typical Node.js asynchronous invocation:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以使用典型的 Node.js 异步调用开始训练：
- en: '[PRE50]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: In this section, we have discussed how to use TensorFlow.js with both vanilla
    JavaScript and Node.js using sample applications for both the browser and backend
    computation.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们讨论了如何通过样例应用程序在浏览器和后端计算中使用 TensorFlow.js，涵盖了原生 JavaScript 和 Node.js 的使用方法。
- en: Summary
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have discussed different components of the TensorFlow ecosystem.
    We started with TensorFlow Hub, the place where many pretrained models are available.
    Next, we talked about the TensorFlow Datasets and learned how to build a data
    pipeline using TFDS. We learned how to use TensorFlow Lite for mobile devices
    and IoT and deployed real applications on Android devices. Then, we also talked
    about federated learning for distributed learning across thousands (millions)
    of mobile devices, taking into account privacy concerns. The last section of the
    chapter was devoted to TensorFlow.js for using TensorFlow with vanilla JavaScript
    or with Node.js.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了 TensorFlow 生态系统的不同组件。我们从 TensorFlow Hub 开始，这是许多预训练模型的聚集地。接下来，我们介绍了
    TensorFlow Datasets，并学习了如何使用 TFDS 构建数据管道。我们了解了如何使用 TensorFlow Lite 为移动设备和物联网设备提供服务，并在
    Android 设备上部署了实际应用。然后，我们还讨论了针对成千上万（甚至百万）移动设备的联邦学习，以考虑隐私问题。本章的最后一节专门讨论了如何使用 TensorFlow.js
    将 TensorFlow 与原生 JavaScript 或 Node.js 一起使用。
- en: The next chapter is about advanced CNNs, where you will learn some advanced
    CNN architectures and their applications.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将讨论高级 CNN，您将学习一些高级 CNN 架构及其应用。
- en: References
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Quantization-aware training: [https://github.com/tensorflow/tensorflow/tree/r1.13/tensorflow/contrib/quantize](https://github.com/tensorflow/tensorflow/tree/r1.13/tensorflow/contrib/quantize)'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 量化感知训练：[https://github.com/tensorflow/tensorflow/tree/r1.13/tensorflow/contrib/quantize](https://github.com/tensorflow/tensorflow/tree/r1.13/tensorflow/contrib/quantize)
- en: Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard, A., Adam, H., and
    Kalenichenko, D. (Submitted on 15 Dec 2017). *Quantization and Training of Neural
    Networks for Efficient Integer-Arithmetic-Only Inference*. [https://arxiv.org/abs/1712.05877](https://arxiv.org/abs/1712.05877)
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Jacob, B., Kligys, S., Chen, B., Zhu, M., Tang, M., Howard, A., Adam, H., 和
    Kalenichenko, D. (提交于 2017 年 12 月 15 日)。*量化和神经网络的训练，以实现高效的整数运算推理*。[https://arxiv.org/abs/1712.05877](https://arxiv.org/abs/1712.05877)
- en: 'Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L-C. (Submitted on 13
    Jan 2018 (v1), last revised 21 Mar 2019 (v4)). *MobileNetV2: Inverted Residuals
    and Linear Bottlenecks*. [https://arxiv.org/abs/1806.08342](https://arxiv.org/abs/1806.08342)'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L-C. (提交于 2018 年 1 月
    13 日 (v1)，最后修订于 2019 年 3 月 21 日 (v4))。*MobileNetV2：倒残差和线性瓶颈*。[https://arxiv.org/abs/1806.08342](https://arxiv.org/abs/1806.08342)
- en: 'Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le,
    Q. V. *MnasNet: Platform-Aware Neural Architecture Search for Mobile*. [https://arxiv.org/abs/1807.11626](https://arxiv.org/abs/1807.11626)'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., 和 Le, Q.
    V. *MnasNet：面向移动平台的神经网络架构搜索*。[https://arxiv.org/abs/1807.11626](https://arxiv.org/abs/1807.11626)
- en: 'Chen, L-C., Papandreou, G., Kokkinos, I., Murphy, K., and Yuille, A. L. (May
    2017). *DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous
    Convolution, and Fully Connected CRFs*. [https://arxiv.org/pdf/1606.00915.pdf](https://arxiv.org/pdf/1606.00915.pdf)'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Chen, L-C., Papandreou, G., Kokkinos, I., Murphy, K., 和 Yuille, A. L.（2017年5月）。*DeepLab：使用深度卷积网络、空洞卷积和全连接CRF进行语义图像分割*。[https://arxiv.org/pdf/1606.00915.pdf](https://arxiv.org/pdf/1606.00915.pdf)
- en: 'Devlin, J., Chang, M-W., Lee, K., and Toutanova, K. (Submitted on 11 Oct 2018
    (v1), last revised 24 May 2019 v2). *BERT: Pre-training of Deep Bidirectional
    Transformers for Language Understanding*. [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Devlin, J., Chang, M-W., Lee, K., 和 Toutanova, K.（提交于2018年10月11日（v1），最后修改于2019年5月24日（v2））。*BERT：用于语言理解的深度双向变换器预训练*。[https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)
- en: 'Anonymous authors, Paper under double-blind review. (modified: 25 Sep 2019).
    *MOBILEBERT: TASK-AGNOSTIC COMPRESSION OF BERT BY PROGRESSIVE KNOWLEDGE TRANSFER*.
    ICLR 2020 Conference Blind Submission Readers: Everyone. [https://openreview.net/pdf?id=SJxjVaNKwB](https://openreview.net/pdf?id=SJxjVaNKwB)'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '匿名作者，论文正在进行双盲审稿。（修改时间：2019年9月25日）。*MOBILEBERT: BERT的任务无关压缩通过渐进式知识迁移*。ICLR 2020会议盲审提交，读者：所有人。[https://openreview.net/pdf?id=SJxjVaNKwB](https://openreview.net/pdf?id=SJxjVaNKwB)'
- en: McMahan, H. B., Moore, E., Ramage, D., Hampson, and S., Arcas, B. A. y. (Submitted
    on 17 Feb 2016 (v1), last revised 28 Feb 2017 (this version, v3)). *Communication-Efficient
    Learning of Deep Networks from Decentralized Data*. [https://arxiv.org/abs/1602.05629](https://arxiv.org/abs/1602.05629)
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: McMahan, H. B., Moore, E., Ramage, D., Hampson, S., Arcas, B. A. y.（提交于2016年2月17日（v1），最后修改于2017年2月28日（此版本，v3））。*从分散数据中高效学习深度网络*。[https://arxiv.org/abs/1602.05629](https://arxiv.org/abs/1602.05629)
- en: 'Konečný, J., McMahan, H. B., Yu, F. X., Richtárik, P., Suresh, A. T., and Bacon,
    D. (Submitted on 18 Oct 2016 (v1), last revised 30 Oct 2017 (this version, v2)).
    *Federated Learning: Strategies for Improving Communication Efficiency*. [https://arxiv.org/abs/1610.05492](https://arxiv.org/abs/1610.05492)'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Konečný, J., McMahan, H. B., Yu, F. X., Richtárik, P., Suresh, A. T., 和 Bacon,
    D.（提交于2016年10月18日（v1），最后修改于2017年10月30日（此版本，v2））。*联邦学习：提高通信效率的策略*。[https://arxiv.org/abs/1610.05492](https://arxiv.org/abs/1610.05492)
- en: 'Bonawitz, K. et al. (22 March 2019). *TOWARDS FEDERATED LEARNING AT SCALE:
    SYSTEM DESIGN*. [https://arxiv.org/pdf/1902.01046.pdf](https://arxiv.org/pdf/1902.01046.pdf%20)'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bonawitz, K. 等人（2019年3月22日）。*迈向大规模联邦学习：系统设计*。[https://arxiv.org/pdf/1902.01046.pdf](https://arxiv.org/pdf/1902.01046.pdf%20)
- en: Join our book’s Discord space
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的书籍Discord空间
- en: 'Join our Discord community to meet like-minded people and learn alongside more
    than 2000 members at: [https://packt.link/keras](https://packt.link/keras)'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区，结识志同道合的人，并与2000多名成员共同学习：[https://packt.link/keras](https://packt.link/keras)
- en: '![](img/QR_Code1831217224278819687.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code1831217224278819687.png)'
