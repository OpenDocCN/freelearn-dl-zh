- en: Demystifying Artificial Intelligence and Fundamentals of Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解密人工智能与机器学习基础
- en: '"Just as electricity transformed almost everything 100 years ago, today I actually
    have a hard time thinking of an industry that I don''t think AI will transform
    in the next several years."'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “正如电力在100年前几乎改变了一切，今天我实际上很难想出一个我认为在接下来的几年中不会被人工智能改变的行业。”
- en: '- Andrew Ng'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '- 安德鲁·吴'
- en: This quote may appear extremely familiar and it's needless to say that, as a
    statement, it is really strongly resonant with respect to the current technological
    disruption. Over the recent course of time, **Artificial Intelligence** (**AI**)has
    been a great area of interest to almost every industry. Be it an educational company,
    a telecommunications firm, or an organization working in healthcare —all of them
    have incorporated AI to enhance their businesses. This uncanny integration of
    AI and several other industries only promises to get better with time and solve
    critical real-world problems in intelligent ways. Today, our phones can make clinical
    appointments for us upon our instructions, our phone cameras can tell us several
    human-perceived attributes of the images they capture, and our car alarm systems
    can detect our driving gestures and can save us from possible accidents. The examples
    will only get better and better and will grow as intelligent as possible with
    advancements in research, technology, and the democratization of computing power.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这句话可能听起来非常熟悉，毋庸置疑，作为一句声明，它在当前的技术颠覆背景下产生了强烈的共鸣。近年来，**人工智能**（**AI**）已成为几乎每个行业的重要关注点。无论是教育公司、电信公司，还是在医疗行业工作的组织——所有这些行业都已将人工智能融入其中，以提升其业务。人工智能与多个行业的这种深度融合，随着时间的推移只会变得更好，并以智能的方式解决现实世界中的关键问题。今天，我们的手机可以根据指示为我们预约临床检查，我们的手机摄像头能够告诉我们它们拍摄的图像中的多个由人类感知的属性，我们的汽车报警系统可以检测到我们的驾驶动作，并在可能发生事故时保护我们。这些例子只会越来越好，并随着研究、技术进步和计算能力的普及变得更加智能。
- en: As we step into the era of Software 2.0, it is extremely important to understand
    why a technology that has existed since the 1950s is making most of the headlines
    in recent times. Yes! Artificial intelligence was born in the 1950s when a handful
    of computer scientists and mathematicians such as **Alan Turing** started to think
    about whether machines could think and whether they could be empowered with intelligence
    so that they can answer questions on their own without being explicitly programmed.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们迈入软件2.0时代，理解为什么一项自1950年代就已存在的技术如今成为头条新闻显得尤为重要。是的！人工智能诞生于1950年代，当时一小部分计算机科学家和数学家，如**艾伦·图灵**，开始思考机器是否能思考，是否可以赋予它们智能，让它们无需显式编程就能自主回答问题。
- en: Soon after this inception, the term **artificial intelligence** was first coined
    by **John McCarthy** in 1956 in an academic conference. From the question "**Can
    machines think?**" (proposed by Turing in his paper, entitled *Computing Machinery
    and Intelligence*) around 1950 to the current day in the 21^(st) century, the
    world of AI has shown some never-seen-before results that we could never have
    even thought of.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一思想诞生后不久，**约翰·麦卡锡**于1956年在一次学术会议上首次提出了“人工智能”这一术语。从**图灵**在其论文《计算机机械与智能》中提出的“**机器能思考吗？**”（大约在1950年）问题，到今天的21世纪，人工智能的世界展现了一些前所未见的结果，甚至是我们曾经无法想象的。
- en: Today, it is almost impossible to think of a day without using **the web. **It
    has easily become one of our fundamental necessities. Our favorite search engines can
    directly answer our questions rather than give us a list of relevant links. They
    can analyze online text and detect their intent and summarize their content. All
    of this is possible because of AI.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，几乎不可能想象一个没有使用**互联网**的日子。它已经轻松成为我们生活中的基本需求之一。我们最喜爱的搜索引擎能够直接回答我们的问题，而不是给出一长串相关的链接。它们可以分析在线文本，理解其意图并总结内容。所有这一切的实现，都是因为人工智能的存在。
- en: 'This book aims to be a hands-on guide to the readers on how they can use AI
    techniques such as **deep learning** to make intelligent web applications based
    on **computer vision**, **natural language processing**, **security**, and lots
    more.This chapter provides the readers with a quick refresher on AI and its different
    types and the basic concepts of ML, and introduces some of the biggest names in
    the industry and what they are doing by fusing AI and web technologies. We will
    be covering the following aspects:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在为读者提供一份实用指南，教读者如何利用**深度学习**等人工智能技术，基于**计算机视觉**、**自然语言处理**、**安全性**等领域，构建智能化的Web应用程序。本章为读者提供了人工智能及其不同类型的快速回顾，并介绍了机器学习的基本概念，同时介绍了行业中的一些大牌公司及其如何将人工智能与Web技术融合的案例。我们将覆盖以下内容：
- en: Introduction to AI and its different types
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能及其不同类型简介
- en: '**Machine Learning** (**ML**): The most popular AI'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）：最受欢迎的人工智能技术'
- en: A brief introduction to **Deep Learning** (**DL**)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度学习**（**DL**）的简要介绍'
- en: The relationship between AI, ML, and DL
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能、机器学习与深度学习之间的关系
- en: Fundamentals of ML
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的基本原理
- en: The web before and after AI
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能之前和之后的Web
- en: The biggest web-AI players and what they are doing
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主要的Web-AI玩家及其正在进行的工作
- en: Introduction to artificial intelligence and its types
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能及其类型简介
- en: In a simpler sense, artificial intelligence is all about giving machines the
    ability to perform intelligently. For example, many of us can play chess. Essentially,
    we do this first by *learning* the fundamentals of playing the game and then we
    engage ourselves in actually playing the game with others. But can machines do
    this? Can machines learn on their own and play the game of chess with us?
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，人工智能就是赋予机器执行智能行为的能力。例如，我们许多人都能下棋。从本质上讲，我们通过*学习*下棋的基本原理，接着我们参与与他人对弈。那么，机器可以做到吗？机器能否独立学习并与我们下棋呢？
- en: AI attempts to make this possible by giving us the power to synthesize what
    we call *intelligence* in terms of some rules and instill it into machines. **Machines**
    as mentioned here can be anything that can compute. For example, it could be software
    or a robot.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能试图通过将我们所谓的*智能*以某些规则的形式赋予机器来实现这一目标。**机器**在这里指的是任何能够进行计算的事物。例如，它可以是软件或机器人。
- en: 'There are actually several types of AI. The popular ones are the following:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 其实，人工智能有多种类型。流行的类型包括：
- en: Fuzzy systems
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模糊系统
- en: Expert systems
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专家系统
- en: ML systems
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习系统
- en: The final type sounds the most familiar here. We will get to it in the next
    section. But before we proceed with it, it is a good time to take a look at some
    of the points that enable the AI advancements we are witnessing today.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一种类型听起来最为熟悉。我们将在下一节中详细介绍它。但在我们继续之前，现在是回顾一下推动当前人工智能进展的一些关键因素的好时机。
- en: Factors responsible for AI propulsion
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推动人工智能发展的因素
- en: 'The major factors that are driving the AI force are the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 推动人工智能发展的主要因素有以下几种：
- en: Data
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据
- en: Algorithmic advancements
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法的进展
- en: Computer hardware advancements
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机硬件的进展
- en: The democratization of high-performance computing
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高性能计算的普及
- en: Data
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据
- en: 'The amount of data we have today is enormous—as **Hal Varian**, Chief Economist
    at Google, put it in 2016:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的数据量庞大——正如Google首席经济学家**Hal Varian**在2016年所说：
- en: '"Between the dawn of civilization and 2003, we only created five exabytes;
    now we''re creating that amount every two days. By 2020, that figure is predicted
    to sit at 53 zettabytes (53 trillion gigabytes)—an increase of 50 times."'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '"自人类文明的黎明到2003年，我们仅创造了五个艾字节；而现在，我们每两天就能创造这么多数据。到2020年，这一数字预计将达到53泽字节（53万亿吉字节）——增长了50倍。"'
- en: That's a lot of data. As the number of digital devices grows, this volume of
    data will only continue to grow exponentially. Gone are the times when a running
    car only displayed the speed on the speedometer. We're in an age where every part
    of the car can be made to produce logs at every split second, enabling us to entirely
    reconstruct any moment of the car's life.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这可是庞大的数据量。随着数字设备的数量不断增长，这种数据量只会呈指数增长。过去，汽车行驶时仪表盘上仅显示车速。而今天，我们进入了一个时代，汽车的每个部件都可以在每一刻生成日志，帮助我们完全重建汽车生命周期的任何一个瞬间。
- en: The more a person gets to learn from life, the wiser the person becomes, and
    the better they can predict outcomes of events in the future. Analogically with
    machines, the greater the amount of (quality) data that a piece of software gets
    to train upon, the better it gets at predicting future unseen data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一个从生活中学到的东西越多，这个人就会变得越智慧，也就能更好地预测未来事件的结果。类比于机器，软件训练所得到的（优质）数据越多，它在预测未来未见数据时就越准确。
- en: 'In the last few years, the availability of data has grown manifold due to various
    factors:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几年里，由于多种因素，数据的可用性呈指数增长：
- en: Cheaper storage
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更便宜的存储
- en: Higher data transmission rates
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高的数据传输速率
- en: Availability of cloud-based storage solutions
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于云的存储解决方案的可用性
- en: Advanced sensors
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级传感器
- en: The Internet of Things
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物联网
- en: An increase in the various forms of digital electronic devices
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各种数字电子设备形式的增加
- en: Increased usage of websites and native apps
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网站和本地应用程序的使用增加
- en: There are more digital devices now than ever. They are all equipped with systems
    that can generate logs at all times and transmit them over the internet to the
    companies that manufacture them or any other vendor that buys that data. Also,
    a lot of logs are created by the websites or apps people use. All of these are
    easily stored in cloud-based storage solutions or in physical storage of high
    storage capacity, which are now cheaper than before.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的数字设备比以往任何时候都要多。它们都配备了可以随时生成日志的系统，并通过互联网将这些日志传输到制造它们的公司或任何购买这些数据的其他供应商。此外，许多日志是由人们使用的网站或应用程序创建的。所有这些都可以轻松地存储在基于云的存储解决方案中，或存储在高存储容量的物理存储设备中，而这些现在比以前便宜了。
- en: If you look around yourself, you will probably be able to see a laptop on which
    you regularly use several pieces of software and websites—all of which may be
    collecting data on every action you perform on them. Similarly, your phone acts
    as such a data-generating device. With a television with several channels provided
    by your television service provider—both the service provider and the channel
    provider are collecting data about you to serve you better and to improve their
    products. You can only imagine the massive amount of data a single person generates
    on a daily basis, and there are billions of us on this planet!
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你环顾四周，可能会看到一台你经常使用多个软件和网站的笔记本电脑——这些软件和网站可能都在收集你在上面执行的每个操作的数据。同样，你的手机也是这样一个数据生成设备。通过你的电视机，提供多个频道的电视服务提供商——无论是服务提供商还是频道提供商，都在收集关于你的数据，以便更好地为你服务并改进他们的产品。你只需要想象一下，单个人每天产生的庞大数据量，而在这个星球上有数十亿人！
- en: Advancements in algorithms
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 算法的进步
- en: An algorithm is an unambiguous sequence of steps that leads to the solution
    of a given problem. Over time, with the expansion of science and human understanding
    of the laws of nature by the aid of mathematics, algorithms have seen improvements.
    More often than not, nature has inspired solutions to complex problems. A neural
    network is probably the most talked-about, nature-inspired algorithm in the present
    day.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 算法是一组明确无误的步骤，能解决给定问题。随着时间的推移，科学的发展以及人类借助数学理解自然法则的深入，算法得到了改进。自然界常常为复杂问题提供了灵感。神经网络可能是如今最受关注的、自然启发的算法之一。
- en: When computer logic began with multiple if-else ladders, no one would ever have
    thought that one day we'd have computer programs that would learn to produce results
    similar to the if-else ladder without the need to write conditions manually. What's
    more, we have computer programs today that generate other programs that can simulate
    AI!
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算机逻辑开始使用多个if-else阶梯时，没人会想到有一天我们会有计算机程序，能够学习生成类似于if-else阶梯的结果，而无需手动编写条件。更重要的是，今天我们有计算机程序，可以生成其他程序，来模拟人工智能！
- en: Surely, with each passing day, algorithms developed by humans and now, by machines
    too, are getting smarter and more powerful at performing their tasks. This has
    directly impacted the rise of neural networks, which, in their rudimentary form,
    seem to be a time-consuming super-nesting of loops to solve matrices and vector
    arithmetic problems.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，随着时间的推移，人类开发的算法，甚至现在由机器开发的算法，正变得越来越智能、越来越强大，能够更好地执行任务。这直接推动了神经网络的兴起，虽然它们的初步形式似乎是一个耗时的超嵌套循环，用于解决矩阵和向量运算问题。
- en: Advancements in hardware
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 硬件的进步
- en: When Intel revealed its first Dynamic RAM module in 1970, it was capable of
    holding 1 KB of data. Approximately 50 years later, we've 128 GB RAM modules available
    in the market. That's nearly 1.28 x 10⁸ times as much memory space.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当英特尔在1970年推出首款动态随机存取内存（DRAM）模块时，它能够存储1KB的数据。大约50年后，市场上已经有了128GB的内存模块。这是原来容量的1.28
    x 10⁸倍。
- en: A similar trend has been exhibited by hard disks. With the first hard disk for
    personal computers being able to store a precious 5 megabytes, 2016 saw Seagate
    announcing a 60-terabyte storage on a solid-state drive. That's a 1.2 x 10⁷ fold
    increase.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 硬盘也展示了类似的趋势。第一款个人计算机硬盘只能存储宝贵的5兆字节，而2016年，希捷公司宣布推出一款60TB的固态硬盘存储。这是1.2 x 10⁷倍的增长。
- en: But we've only yet talked about direct individual computing comparisons, without
    considering the effect of technological growth since the first computers were
    introduced. Today, with the advent of cloud computing, it's become common to hear
    someone talking about **unlimited cloud storage**.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们只讨论了直接的个人计算比较，并没有考虑自第一台计算机推出以来技术增长的影响。今天，随着云计算的到来，听到人们谈论**无限云存储**已经变得非常普遍。
- en: AI has greatly benefited from this exponential increase in computing speed and
    data storage.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能在计算速度和数据存储的指数级增长中受益匪浅。
- en: The democratization of high-performance computing
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高性能计算的民主化
- en: With the reducing costs of commodity hardware and their increasing performance
    capabilities, high-performance computing is not something exclusive to tech giants
    these days. Today, it is very easily possible for any single person to set up
    for their personal use a network of computing devices to facilitate high-performance
    computing if they're not already satisfied with the exceptional performance that
    can be delivered through single devices. However, investing in hardware is not
    the only way of availing high-performance computing. The emergence of cloud-based
    computing solutions has resulted in very high-speed computing infrastructure available
    with click-deploy methods. Users can, at any moment, launch a cloud-based instance
    over the network and run their performance-intensive software on it at minimal
    charges.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 随着商品硬件成本的降低和性能的提升，高性能计算如今不再是科技巨头的专属。今天，任何个人都可以非常容易地为自己的个人使用搭建一个计算设备网络，以实现高性能计算，前提是他们不满足于单一设备所能提供的卓越性能。然而，投资硬件并不是获得高性能计算的唯一方式。基于云计算的解决方案的出现，使得通过点击部署方法即可使用非常高速的计算基础设施。用户可以随时在网络上启动云实例，并以最低的费用在其上运行性能密集型的软件。
- en: With high-performance computing becoming readily available to individual developers,
    the development of AI solutions has come into the hands of a wide community of
    developers. This has led to a boom in the number of creative and research-based
    applications of AI.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 随着高性能计算的普及，个人开发者手中掌握了开发人工智能解决方案的能力。这促使了人工智能的创意和研究型应用数量的激增。
- en: Let's now unravel the most popular form of AI as of the time of writing and
    discuss some important concepts regarding it.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在揭开当前最流行的人工智能形式，并讨论一些关于它的重要概念。
- en: ML – the most popular form of AI
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习 – 最流行的人工智能形式
- en: Without taking any mathematical notations or too many theoretical details, let's
    try to approach the term **Machine Learning** (**ML**)from an intuitive perspective.
    For doing this, we will have to take a look at how we actually learn. Do you recollect,
    at school, when we were taught to identify the parts of speech in a sentence?
    We were presented with a set of rules to identify the part of the speeches in
    a sentence. We were given many examples and our teachers in the first place used
    to identify the parts of speeches in sentences for us to *train* us effectively
    so that we could use this learning experience to identify the parts of speeches
    in sentences that were not taught to us. Moreover, this learning process is fundamentally
    applicable to anything that we learn.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 不考虑任何数学符号或过多的理论细节，让我们从直观的角度尝试理解**机器学习**（**ML**）这一术语。为此，我们需要看看我们是如何实际学习的。你还记得在学校时，我们被教导如何识别句子中的词性吗？我们被提供了一套规则来识别句子中的词性。我们得到了许多例子，最初我们的老师会为我们识别句子中的词性，以便有效地*训练*我们，使我们能够利用这种学习经验来识别那些没有教给我们的句子中的词性。此外，这个学习过程本质上适用于我们所学的任何内容。
- en: 'What if we could similarly train the machines? What if we could program them
    in such a way that they could learn from experiences and could start answering
    questions based on this knowledge? Well, this has already been done, and, knowingly
    or unknowingly, we are all taking the benefits yielded by this. And this is exactly what
    ML is when discussed intuitively. For a more formal, standard understanding, let''s
    take a look at the following definition by Tom Mitchell in his book, *Machine
    Learning*:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们也能以类似的方式训练机器呢？如果我们能以某种方式编程，让它们能从经验中学习，并且基于这些知识开始回答问题呢？嗯，这已经实现了，而无论我们是否意识到，我们都在享受它带来的好处。这正是直观理解下的机器学习（ML）。为了更正式、标准的理解，我们来看一下汤姆·米切尔（Tom
    Mitchell）在《机器学习》一书中给出的定义：
- en: '"A computer program is said to learn from experience E with respect to some
    task T and some performance measure P, if its performance on T, as measured by
    P, improves with experience E."'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '"一个计算机程序如果能在某个任务T和某个性能衡量标准P下，随着经验E的增加，其在T任务上的表现（通过P衡量）得到改进，那么我们就说它从经验E中学习。"'
- en: The preceding definition is a more precise version of what we just discussed
    about ML from an intuitive perspective. It is important to note here that most
    AI wizardry that we see today is possible due to this form of AI.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的定义是我们刚才从直观角度讨论的机器学习（ML）更精确的版本。值得注意的是，今天我们所看到的大多数人工智能奇迹正是因为这种形式的人工智能得以实现。
- en: We now have a fair idea of what ML is. Now, we will move to the next section,
    which discusses the most powerful subfield of ML—DL. We will not go into the bone-breaking
    mathematical details. Instead, we will break it down intuitively, as in this section.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在对机器学习（ML）有了一个大致的了解。接下来，我们将进入下一部分，讨论机器学习中最强大的子领域——深度学习（DL）。我们不会深入讲解复杂的数学细节，而是像这一部分一样，直观地进行解析。
- en: What is DL?
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是深度学习（DL）？
- en: Now comes the most exciting part and probably the hottest technical term of
    this century. Reality apart, we now understand the **learning **to some extent,
    so let's get to the first part of the term *deep learning*—**deep**.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是最激动人心的部分，可能也是本世纪最火的技术术语。现实暂且不提，我们现在在某种程度上已经理解了**学习**，那么让我们来讨论术语*深度学习*中的第一个部分——**深度**。
- en: 'DL is a type of machine learning but it is purely based on **neural networks**.
    We will take a look at neural networks too but in the next chapter. The basic
    objective of any machine learning system is to *learn useful representations of
    the data* given to it. But what makes DL different? It turns out that DL systems
    treat data as a representation of layers. For example, an image can be treated
    as a representation of layers of varying properties such as edges, contours, orientation,
    texture, and gradients. The following diagram from the book, *Deep Learning with
    Python*, byFrançois Chollet captures this idea nicely:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）是机器学习的一种类型，但它完全基于**神经网络**。我们将在下一章中讨论神经网络。任何机器学习系统的基本目标是*学习所给数据的有用表示*。那么，深度学习有什么不同呢？事实证明，深度学习系统将数据视为层次的表示。例如，一张图像可以视为不同特征层次的表示，特征层次包括边缘、轮廓、方向、纹理和梯度等。《Python深度学习》一书中的以下图示很好地呈现了这个概念：
- en: '![](img/8b22fd60-5661-44c7-b485-a00f74f9fb83.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b22fd60-5661-44c7-b485-a00f74f9fb83.jpg)'
- en: 'In the preceding diagram, a DL system is being employed to classify an image
    of a hand-written digit. The system takes the image of the handwritten digit as
    its input and tries to learn its underlying representations. In the first layer,
    the system learns generic features such as strokes and lines. As the layers increase,
    it learns about the features that are more specific to the given image. The more the number
    of layers, the *deeper* the system gets. Let''s take a look at the following definition,
    which is given by François Chollet in his book, *Deep Learning with Python*:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，一个深度学习系统被用来对手写数字的图像进行分类。系统以手写数字图像作为输入，并尝试学习其底层表示。在第一层，系统学习诸如笔画和线条等通用特征。随着层数的增加，它会学习到更加具体的特征。层数越多，系统就越*深*。我们来看一下弗朗索瓦·肖莱（François
    Chollet）在《Python深度学习》一书中给出的定义：
- en: '"The **deep** in deep learning isn''t a reference to any kind of deeper understanding
    achieved by the approach; rather, it stands for this idea of successive layers
    of representations. How many layers contribute to a model of the data is called
    the depth of the model. [...] In deep learning, these layered representations
    are (almost always) learned via models called neural networks, structured in literal
    layers stacked on top of each other."'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '"深度学习中的**深度**并不是指通过这种方法所获得的任何更深的理解；它实际上代表的是连续的层次化表示。多少层次的表示在数据模型中起到作用，这被称为模型的深度。[...]
    在深度学习中，这些分层表示几乎总是通过称为神经网络的模型学习的，神经网络的结构是通过字面上的层次堆叠在一起的。"'
- en: The definition quite aptly captures all of the necessary ingredients of DL and
    beautifully introduces the concept of treating data as a layered representation.
    So, a DL system, in a broad sense, breaks down the data into simple representations
    in a layered fashion, and to learn these representations, it often makes use of
    many layers (which is referred to as *deep*). We will now take a look at the big
    picture, which tells us how AI, ML, and DL are related to each other.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这个定义恰如其分地捕捉到了深度学习的所有必要要素，并巧妙地引入了将数据视为分层表示的概念。因此，广义上的深度学习系统将数据分解成简单的分层表示，并且为了学习这些表示，它通常使用多层（这就是所谓的*深度*）。接下来，我们将从大局出发，了解AI、ML和DL之间的关系。
- en: The relation between AI, ML, and DL
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI、ML和DL之间的关系
- en: 'To make sure that our basics are clear regarding the distinction between AI,
    ML, and DL, let''s refer to the following diagram, which elegantly captures the
    relationship between these three big names:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保我们对AI、ML和DL之间的区别有清晰的理解，下面的图表将帮助我们优雅地展示这三者之间的关系：
- en: '![](img/f7e17554-5438-49ea-964b-365d2bada273.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f7e17554-5438-49ea-964b-365d2bada273.jpg)'
- en: The diagram is quite self-explanatory and it has been referred to in many books
    in the field of DL. Let's try drawing an interesting conclusion from this diagram.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表非常直观，且在许多深度学习领域的书籍中都有提到。让我们试着从这个图表中得出一个有趣的结论。
- en: All DL systems are ML systems and therefore all DL systems are AI systems as
    well. But the converse is not true—not all AI systems are DL systems.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的深度学习系统都是机器学习系统，因此所有的深度学习系统也是人工智能系统。但反过来并不成立——并非所有的人工智能系统都是深度学习系统。
- en: The statement may appear slightly confusing at first glance, but if we got our
    basics right, then this captures the distinction between AI, ML, and DL beautifully.
    We will proceed toward revisiting some of the necessary ML terminologies and concepts
    that will be required in the latter parts of this book.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个表述可能乍一看有些令人困惑，但如果我们掌握了基础，那么这句话就能很好地阐明AI、ML和DL之间的区别。接下来，我们将回顾一些必要的ML术语和概念，这些概念将在本书后续部分中用到。
- en: Revisiting the fundamentals of ML
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重温ML的基本概念
- en: 'We have already seen what is meant by ML. In this section, we will focus on
    several terminologies such as supervised learning and unsupervised learning, and
    we will be taking a look at the steps involved in a standard ML workflow. But
    you may ask: why ML? We are supposed to learn about the applications of *DL* in
    this book. We just learned that DL is a type of ML only. Therefore, a quick overview
    of the basic ML-related concepts will certainly help. Let''s start with several
    types of ML and how they differ from each other.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了ML的含义。在本节中，我们将重点讨论几个术语，如监督学习和无监督学习，并将回顾标准ML工作流中涉及的步骤。但你可能会问：为什么是ML？我们应该在本书中学习*深度学习（DL）*的应用。我们刚刚了解到，DL只是一种ML。因此，快速回顾一下基本的ML相关概念将会有所帮助。让我们从几种类型的ML及其相互区别开始。
- en: Types of ML
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ML的类型
- en: 'ML encompasses a multitude of algorithms and topics. While every such algorithm
    that makes up an ML model is nothing but a mathematical computation on given data,
    the form of data that is provided and the manner of the task to be performed on
    it might hugely vary. Sometimes, you might want your ML model to predict future
    house prices based on the data of previous house prices with respect to details
    of the house such as the number of rooms and number of stories it has, and at
    other times, you might want your ML model to learn how to play computer games
    against you. You can easily expect the input data for the first task to be in
    tabular format, but for the second example, you might not be able to come up with
    the same. Hence, ML algorithms branch into three major categories and another
    form that derives from them, based on the input data they receive and the kind
    of output they are supposed to produce, namely, the following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习涵盖了众多的算法和话题。虽然每个构成机器学习模型的算法都只是对给定数据进行的数学计算，但提供的数据形式以及任务执行的方式可能有很大不同。有时，你可能希望你的机器学习模型根据过去房价的数据，结合房屋的详细信息（如房间数量和楼层数），预测未来的房价；而在其他时候，你可能希望你的机器学习模型学会如何与人对战玩电子游戏。对于第一个任务，你可以预期输入数据是表格格式的，但对于第二个例子，可能无法像第一个那样呈现。因此，机器学习算法根据它们接收的输入数据以及它们应该生成的输出类型，分为三大类及其衍生形式，具体如下：
- en: Supervised learning
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监督学习
- en: Unsupervised learning
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Reinforcement learning
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强化学习
- en: Semi-supervised learning
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 半监督学习
- en: 'The following diagram captures the three major types of ML, along with the
    hybrid form as a fourth type, and a very brief summary on each type:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了三种主要的机器学习类型，以及作为第四种类型的混合形式，并对每种类型进行了简要概述：
- en: '![](img/bc83753f-d373-4b82-a266-72673135f8d1.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bc83753f-d373-4b82-a266-72673135f8d1.png)'
- en: You may have heard of the fourth form of ML—semi-supervised learning, which
    fuses both the worlds of supervised and unsupervised learning.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听说过机器学习的第四种形式——半监督学习，它融合了监督学习和无监督学习的特点。
- en: Let's now understand these types of ML in greater depth, according to how they
    function and the types of problems they can be used to solve.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们根据它们的工作原理以及它们能够解决的问题类型，深入理解这些机器学习类型。
- en: Supervised learning
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习
- en: 'In this form of ML, the algorithm is presented with a huge number of training
    samples, which contain information about all of the parameters, or *features*, that
    would be used to determine an output feature. This output feature could be a continuous
    range of values or a discrete collection of labels. Based on this, supervised
    ML algorithms are divided into two parts:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种机器学习形式中，算法会接收到大量的训练样本，这些样本包含有关所有参数或*特征*的信息，这些参数或特征将用于确定输出特征。这个输出特征可以是一个连续的值域，也可以是一个离散的标签集合。基于这一点，监督学习算法可以分为两部分：
- en: '**Classification**: Algorithms that produce discrete labels in the output feature,
    such as *normal* and *not normal* or a set of news categories'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：在输出特征中生成离散标签的算法，如*正常*和*不正常*，或者一组新闻类别。'
- en: '**Regression**: When the output feature has real values, for example, the number
    of votes a political party might receive in an election, or the temperature of
    a material at which it is predicted to reach its melting point'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**：当输出特征具有真实值时，例如，一个政党在选举中可能获得的票数，或一个材料在达到其熔点时的温度。'
- en: Most ML enthusiasts, when they begin their study of machine learning, tend to
    familiarize themselves with supervised learning first due to its intuitive simplicity.
    It has some of the simplest algorithms, which are easy to understand without a
    deep knowledge of mathematics and are even derived from what mathematics students
    learn in their final years at schools. Some of the most well known supervised
    learning algorithms are linear regression, logistic regression, support vector
    machines, and k-nearest neighbors.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习爱好者在开始学习机器学习时，通常首先接触到监督学习，因为它直观且简单。它有一些最简单的算法，易于理解，即使没有深入的数学知识，也能理解，甚至这些算法源自数学学生在学校最后几年的学习内容。最著名的监督学习算法包括线性回归、逻辑回归、支持向量机和k近邻算法。
- en: Unsupervised learning
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Unsupervised learning presents itself in scenarios where the training samples
    do not carry with them output feature(s). You could wonder then, what are we supposed
    to learn or predict in such situations? The answer is similarity. In more elaborate
    terms, when we have a dataset for unsupervised learning, we're usually trying
    to learn the similarity between the training samples and then to assign classes
    or *labels* to them.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习适用于训练样本没有输出特征的情况。你可能会想，那么在这种情况下，我们究竟要学习或预测什么呢？答案是相似性。更具体地说，当我们有一个无监督学习的数据集时，我们通常是试图学习训练样本之间的相似性，然后为它们分配类别或*标签*。
- en: Consider a crowd of people standing in a large field. All of them have features
    such as age, gender, marital status, salary range, and education level. Now, we
    wish to group them based on their similarities. We decide to form three groups
    and see that they arrange themselves in a manner of gender—a group of females,
    a group of males, and a group of people who identify with other genders. We again
    ask them to form subgroups within those groups and see what people make groups
    based on their age ranges—children, teenagers, adults, and senior citizens. This
    gives us a total of 12 such subgroups. We could make further smaller subgroups
    based on the similarity any two individuals exhibit. Also, the manner of grouping
    discussed in the preceding example is just one among several manners of forming
    groups. Now, say we have 10 new members joining the crowd. Since we already have
    our groups defined, we can easily sort these new members into those groups. Hence,
    we can successfully apply group labels to them.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一群人站在一个大草地上，他们都有年龄、性别、婚姻状况、薪资范围和教育水平等特征。现在，我们希望根据他们的相似性将他们分组。我们决定将他们分为三个组，看到他们根据性别自发地分为女性组、男性组和其他性别的组。然后，我们再要求他们在这些组内根据年龄段形成子组—儿童、青少年、成人和老年人。这样我们就得到了12个子组。我们还可以根据任何两个个体的相似性进一步细分子组。此外，前述的分组方式只是多种分组方式中的一种。现在，假设有10个新成员加入了这群人。由于我们已经定义好了组，因此可以很容易地将这些新成员分配到这些组中。因此，我们可以成功地为他们分配组标签。
- en: 'The preceding example demonstrates just one form of unsupervised learning,
    which can be divided into two types:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 上述例子展示了无监督学习的一种形式，它可以分为两种类型：
- en: '**Clustering**: This is to form groups of training samples based on the similarity
    of their features.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**：这是根据特征的相似性将训练样本分组。'
- en: '**Association**: This is to find abstract associations or rules exhibited between
    features or training samples. For example, on analyzing a shop''s sales logs,
    it was found that customers buy beer mostly after 7 p.m.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关联**：这是指发现特征或训练样本之间的抽象关联或规则。例如，通过分析商店的销售日志，发现顾客大多在晚上7点后购买啤酒。'
- en: K-means clustering, DBSCAN, and the Apriori algorithm are some of the best-known
    algorithms used for unsupervised learning.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: K均值聚类、DBSCAN和Apriori算法是一些广为人知的用于无监督学习的算法。
- en: Reinforcement learning
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习
- en: '**Reinforcement learning** (**RL**), is a form of ML wherein a virtual agent
    tries to learn how to interact with its surroundings in such a way that it can
    achieve the maximum reward from it for a certain set of actions.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**强化学习**（**RL**）是一种机器学习方法，其中虚拟智能体尝试通过与环境的交互来学习，以便能够从某一特定的动作集合中获得最大的奖励。'
- en: Let's try to understand this with a small example—say you build a robot that
    plays darts. Now, the robot will get a maximum reward only when it hits the center
    of the dartboard. It begins with a random throw of dart and lands on the outermost
    ring. It gets a certain amount of points, say x1\. It now knows that throwing
    near that area will yield it an expected value of x1\. So, in the next throw,
    it makes a very slight change of angle and luckily lands in the second outermost
    right, fetching it x2 points. Since x2 is greater than x1, the robot has achieved
    a better result and it will learn to throw nearby this area in the future. If
    the dart had landed even further out than the outermost ring, the robot would
    keep throwing it near the first throw that it made until it got a better result.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个小例子来理解这一点——假设你构建了一个玩飞镖的机器人。现在，机器人只有在击中飞镖盘中心时才会获得最大奖励。它从一次随机的投掷开始，落在最外圈。它获得了一定的积分，假设是x1。它现在知道，投掷到这个区域附近会得到预期值为x1的结果。所以，在下一次投掷时，它稍微改变了一下角度，幸运地落在了第二外圈，获得了x2积分。由于x2大于x1，机器人取得了更好的结果，并且它将学会将飞镖投掷到该区域附近。如果飞镖落得比最外圈还远，机器人将不断向它的第一次投掷位置靠近，直到得到更好的结果。
- en: Over several such trials, the robot keeps learning the better places to throw
    and makes small detours from those positions until it gets the next better place
    to throw at. Eventually, it finds the bull's eye and meets the highest points
    every time.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在几次这样的试验中，机器人不断学习更好的投掷位置，并且从这些位置稍作偏离，直到找到下一个更好的投掷点。最终，它找到了靶心，并且每次都能获得最高的分数。
- en: In the preceding example, your robot is the agent who is trying to throw a dart
    at the dartboard, which is the environment. Throwing the dart is the action the
    agent performs on the environment. The points the agent gets act as the reward.
    The agent, over multiple trials, tries to maximize the reward that it gets by
    performing the actions.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，你的机器人是那个试图向飞镖盘投掷飞镖的智能体，而飞镖盘则是环境。投掷飞镖是智能体对环境执行的动作。智能体得到的积分充当奖励。在多次试验中，智能体通过执行不同的动作来尽可能最大化它获得的奖励。
- en: Some well-known RL algorithms are Monte Carlo, Q-learning, and SARSA.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一些著名的强化学习算法包括蒙特卡洛方法、Q学习和SARSA。
- en: Semi-supervised learning
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 半监督学习
- en: While we have discussed the three major types of ML, there exists yet another
    type, which is semi-supervised learning. By the name of the term, you could guess
    that it would have to do something with a mix of labeled and unlabeled training
    samples. In most cases, the number of unlabeled training samples exceeds the number
    of labeled samples.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们已经讨论了三种主要的机器学习类型，但仍然存在另一种类型，那就是半监督学习。根据这个术语的名称，你可以猜到它与标注和未标注的训练样本混合有关。在大多数情况下，未标注的训练样本数量超过了标注样本的数量。
- en: Semi-supervised learning has been used successfully to produce more efficient
    results when some labeled samples are added to a problem entirely belonging to
    unsupervised learning. Also, since only a few samples are labeled, the complexity
    of supervised learning is avoided. With this approach, we can produce better results
    than we would get from a purely unsupervised learning system and incur lesser
    computational cost than a pure supervised learning system.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习在将一些标注样本加入到完全属于无监督学习的问题中时，已被成功地应用于产生更高效的结果。此外，由于只有少量样本被标注，因此避免了监督学习的复杂性。采用这种方法，我们可以得到比纯粹无监督学习系统更好的结果，同时也比纯监督学习系统消耗更少的计算资源。
- en: Necessary terminologies
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 必要的术语
- en: We have made ourselves familiar with different types of ML systems. Now, we
    will learn about some extremely important terminologies related to ML that will
    help us in the later chapters of this book.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了不同类型的机器学习系统。现在，我们将学习一些与机器学习密切相关的重要术语，这些术语将在本书后续章节中帮助我们理解。
- en: Train, test, and validation sets
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练集、测试集和验证集
- en: Any ML system is to be given **data**. Without data, it is practically impossible
    to design an ML system.We are not concerned about the quantity of the data as
    of now, but it is important to keep in mind that we need data to devise an ML
    system. Once we have that data, we use it for *training* our ML systems so that
    they can be used to *predict something *on the new data (*something* is a broad
    term here and it varies from problem to problem). So, the data that is used for
    training purposes is known as a **train set **and the data on which the systems
    are tested is known as a **test set**. Also, before actually employing the model
    on the test data, we tend to validate its performance on another set of data,
    which is called a **validation set**. Sometimes, we don't get the data in these
    nice partitions; we just get the data in a raw unfathomable format, which we further
    process and make these partitions with accordingly.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 任何机器学习系统都需要**数据**。没有数据，设计一个机器学习系统几乎是不可能的。现在我们并不关心数据的数量，但需要记住的是，我们需要数据来设计机器学习系统。一旦我们有了数据，就会用它来*训练*我们的机器学习系统，以便它们能在新数据上*预测一些东西*（这里的“东西”是一个广泛的术语，根据不同的问题有所不同）。因此，用于训练的数据显示为**训练集**，而用于测试模型的数据显示为**测试集**。另外，在实际将模型应用于测试数据之前，我们通常会在另一组数据上验证其性能，这组数据称为**验证集**。有时，我们无法直接获得这些精确划分的数据，我们只能得到原始、难以理解的数据，然后再根据需要进行处理和划分。
- en: Technically, all of the instances in these three different sets are supposed
    to vary from each other while the distribution in the data is supposed to be the
    same. Nowadays, many researchers have found critical issues regarding these assumptions
    and have come up with something called **adversarial training**,which is out of
    the scope of this book.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，这三组数据中的所有实例都应该彼此有所不同，同时数据中的分布应该是相同的。如今，许多研究者发现这些假设存在重要问题，并提出了一种叫做**对抗训练**的方法，这超出了本书的讨论范围。
- en: Bias and variance
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 偏差和方差
- en: Bias and variance are very intrinsic to any ML model. Having a good understanding
    of them really helps in the further assessment of the models. The *trade-off*
    between the two is actually used by the practitioners to assess the performance
    of machine learning systems.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差和方差是任何机器学习模型中非常内在的特征。对它们有很好的理解，实际上有助于进一步评估模型。**偏差和方差的权衡**实际上是实践者用来评估机器学习系统性能的一个重要工具。
- en: You are encouraged to see this lecture by Andrew Ng to learn more about this
    trade-off, at [https://www.youtube.com/watch?v=fDQkUN9yw44&t=293s.](https://www.youtube.com/watch?v=fDQkUN9yw44&t=293s)
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你观看安德鲁·吴的这场讲座，了解更多关于这种权衡的内容，链接：[https://www.youtube.com/watch?v=fDQkUN9yw44&t=293s](https://www.youtube.com/watch?v=fDQkUN9yw44&t=293s)
- en: Bias is the set of assumptions that an ML algorithm makes to learn the representations
    underlying the given data. When the bias is high, it means that the corresponding
    algorithm is making more assumptions about the data and in the case of low bias,
    an algorithm makes as little an amount of assumptions as possible. An ML model
    is said to have a low bias when it performs well on the train set. Some examples
    of low-bias ML algorithms are k-nearest neighbors and support vector machines while
    algorithms such as logistic regression and naive Bayes are generally high-bias
    algorithms.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 偏差是机器学习算法为学习给定数据中潜在的表示所做的一系列假设。当偏差较高时，意味着相应的算法对数据做出了更多的假设；而当偏差较低时，算法尽可能少地做出假设。一个机器学习模型在训练集上表现良好时，通常被认为具有低偏差。一些低偏差的机器学习算法包括k近邻和支持向量机，而像逻辑回归和朴素贝叶斯这样的算法通常是高偏差算法。
- en: Variance in an ML context concerns the information present in the data. Therefore,
    high variance refers to the quality of how well an ML model has been able to capture
    the overall information present in the data given to it. Low variance conveys
    just the opposite. Algorithms such as support vector machines are generally high
    on variance and algorithms such as naive Bayes are low on variance.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，方差涉及数据中存在的信息。因此，高方差指的是机器学习模型能够捕捉到数据中整体信息的质量。低方差则恰恰相反。像支持向量机这样的算法通常具有高方差，而像朴素贝叶斯这样的算法则具有低方差。
- en: Overfitting and underfitting
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过拟合与欠拟合
- en: 'When an ML model performs very well on the training data but poorly on the
    data from either the test set or validation set, the phenomenon is referred to
    as **overfitting**. There can be several reasons for this; the following are the
    most common ones:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个机器学习模型在训练数据上表现非常好，但在测试集或验证集上的表现较差时，这种现象被称为**过拟合**。造成这种现象的原因可能有多种，以下是最常见的一些：
- en: The model is very complex with respect to the data. A decision tree with very
    high levels and a neural network with many layers are good examples of model complexity
    in this case.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型相对于数据过于复杂。具有非常高层次的决策树或层数较多的神经网络是这类模型复杂性的典型例子。
- en: The data has lots of features but very few instances of the population.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据有很多特征，但样本数量非常少。
- en: In ML literature, the problem of overfitting is also treated as a problem of
    *high variance*. **Regularization** is the most widely used approach to prevent
    overfitting.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习文献中，过拟合的问题也被视为*高方差*问题。**正则化**是防止过拟合的最常用方法。
- en: 'We have already discussed the concept of bias. A model has a low bias if it
    performs well on the training data, that is, the model is not making too many
    assumptions on the data to infer its representation. If the model fails miserably
    on the training data, it is said that the model has a high bias and the model
    is **underfitting**. There can be many reasons for underfitting as well. The following
    are the most common ones in this case:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论过偏差的概念。一个模型如果在训练数据上表现良好，则偏差较低，也就是说，模型在推断数据的表示时没有做出过多假设。如果模型在训练数据上表现糟糕，则称该模型有高偏差，并且该模型是**欠拟合**的。欠拟合可能有很多原因，以下是其中最常见的一些：
- en: The model is too simple to learn the underlying representation of the data given
    to it.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型过于简单，无法学习到数据的潜在表示。
- en: The features of the data have not been engineered well before feeding them to
    the ML model. The engineering part is very popularly known as feature engineering.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的特征在输入给机器学习模型之前没有进行有效的工程化。特征工程是这个过程中的重要部分。
- en: 'Based on this discussion, we can draw a very useful conclusion: an ML model
    that is overfitting might be suffering from the issue of high variance whereas
    an underfitting model might be suffering from the issue of high bias.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这一讨论，我们可以得出一个非常有用的结论：一个过拟合的机器学习模型可能正遭遇高方差的问题，而一个欠拟合的模型可能正遭遇高偏差的问题。
- en: 'The discussion of overfitting and underfitting remains incomplete without the
    following diagram (shown by Andrew Ng during his flagship course, *Machine Learning*):'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有以下图表，关于过拟合和欠拟合的讨论将是不完整的（该图由Andrew Ng在他的旗舰课程*机器学习*中展示）：
- en: '![](img/786819b2-885e-4fa8-80bf-de2842258087.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/786819b2-885e-4fa8-80bf-de2842258087.png)'
- en: The preceding diagram beautifully illustrates underfitting and overfitting in
    terms of curvea fitting through the data points. It also gives us an idea of a
    model that **generalizes** well, that is, performs well on both the train and
    test sets. The model prediction line in blue is way off the samples, leading to
    underfitting, while in the case of overfitting, the model captures all points
    in the training data but does not yield a model that would perform well on data
    outside training data.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图表清晰地展示了通过数据点拟合曲线的欠拟合和过拟合情况。它还向我们展示了一个**泛化**良好的模型，即在训练集和测试集上都能表现良好的模型。蓝色的模型预测线远离样本，导致欠拟合，而在过拟合的情况下，模型捕捉了训练数据中的所有点，但并没有产生一个在训练数据以外能够表现良好的模型。
- en: Often, the idea of learning representations of the data is treated as a problem
    of approximating a function that best describes the data. And a function can easily
    be plotted graphically like the previous one, hence, the idea of **curve fitting**.
    The sweet spot between underfitting and overfitting where a model generalizes
    well is called a good fit.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，将数据的表示学习视为近似最能描述数据的函数问题。一个函数可以像之前的图形一样轻松地绘制，因此，出现了**曲线拟合**的概念。模型能够很好地泛化的、介于欠拟合和过拟合之间的最佳位置被称为良好拟合。
- en: Training error and generalization error
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练误差和泛化误差
- en: The mistakes that a model makes while predicting during its training phase are
    collectively referred to as its **training error**. The mistakes that model makes
    when tested on either the validation set or the test set are referred to as its
    **generalization** **error**.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在训练阶段进行预测时所犯的错误统称为**训练误差**。模型在验证集或测试集上测试时所犯的错误被称为**泛化误差**。
- en: 'If we were to draw a relationship between these two types of error and bias
    and variance (and eventually overfitting and underfitting), this would look something
    like the following (although the relationship may not be linear every time as
    depicted in the diagrams):'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要绘制这两种误差与偏差和方差（以及最终的过拟合和欠拟合）之间的关系图，它大致会是下面这样的（尽管这种关系不一定总是像图中所示的那样线性）：
- en: '![](img/46c1d591-c385-4491-baca-a52af92648cb.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](img/46c1d591-c385-4491-baca-a52af92648cb.png)'
- en: If an ML model is underfitting (high bias), then its training error has to be
    high. On the other hand, if the model is overfitting (high variance), then its
    generalization error is high.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个机器学习模型欠拟合（高偏差），那么它的训练误差必然较高。另一方面，如果模型过拟合（高方差），那么它的泛化误差较高。
- en: We will look at a standard ML workflow in the following section.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的部分中查看一个标准的机器学习工作流程。
- en: A standard ML workflow
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个标准的机器学习工作流程
- en: Any project starts with a problem in mind and ML projects are no exception.
    Before starting an ML project, it is very important to have a clear understanding
    of the problem that you are trying to solve using ML. Therefore, problem formulation
    and mapping with respect to the standard ML workflow serve as good starting points
    in an ML project. But what is meant by an **ML workflow**? This section is all
    about that.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 任何项目都始于一个明确的问题，机器学习项目也不例外。在开始一个机器学习项目之前，明确理解你试图通过机器学习解决的问题是非常重要的。因此，问题的提出和与标准机器学习工作流程的映射是机器学习项目的良好起点。那么，**机器学习工作流程**指的是什么呢？这一部分将讨论这一主题。
- en: Designing ML systems and employing them to solve complex problems requires a
    set of skills other than just ML. It is good to know that ML requires knowledge
    of several things such as statistics, domain knowledge, software engineering,
    feature engineering, and basic high-school mathematics in varying proportions.
    To be able to design such systems, certain steps are fundamental to almost any
    ML workflow and each of these steps requires a certain skill set. In this section,
    we are going to take a look at these steps and discuss them briefly.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 设计机器学习（ML）系统并使用它们解决复杂问题需要一套除机器学习外的其他技能。需要知道的是，机器学习需要掌握多个方面的知识，如统计学、领域知识、软件工程、特征工程以及基础的高中数学，且各部分所需比例不同。要能够设计这样的系统，某些步骤对于几乎任何机器学习工作流程来说都是至关重要的，每个步骤都需要特定的技能。在这一部分，我们将简要了解这些步骤并讨论它们。
- en: This workflow is inspired by **CRISP-DM**, which stands for** Cross Industry
    Standard Process for Data Mining** and is extremely widely used across many industries
    pertaining to data mining and analytics.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这个工作流程的灵感来源于**CRISP-DM**，它代表着**跨行业数据挖掘标准流程**，在涉及数据挖掘和分析的众多行业中广泛应用。
- en: Data retrieval
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据获取
- en: As mentioned earlier in this chapter, ML systems need data for functioning.
    It is not available all of the time, in fact, most of the time, the data itself
    is not available in a format with which we can actually start training ML models.
    But what if there is no standard dataset for a particular problem that we are
    trying to solve using ML? Welcome to reality! This happens for most real-life
    ML projects. For example, let's say we are trying to analyze the sentiments of
    tweets regarding the New Year resolutions of 2018 and trying to estimate the most
    meaningful ones. This is actually a problem for which there is no standard dataset
    available. We will have to scrape it from Twitter using its APIs. Another great
    example is business logs. Business logs are treasures of knowledge. If effectively
    mined and modeled, they can help in many decision-making processes. But often,
    logs are not available directly to the ML engineer. So, the ML engineer needs
    to spend a considerable amount of time figuring out the structure of the logs
    and they might write a script so that the logs are captured as required. All of
    these processes are collectively called **data retrieval** or **data collection**.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本章前面所提到的，机器学习系统需要数据才能运行。数据并非总是可用，实际上，大部分时间数据本身并不是以可以直接用于训练机器学习模型的格式存在。但是，如果我们针对某个问题没有标准数据集，如何处理呢？这就是真实的情况！这种情况出现在大多数现实中的机器学习项目中。例如，假设我们想分析2018年新年决心相关的推文情感，并尝试估算出其中最有意义的内容。这实际上是一个没有标准数据集的问题。我们将不得不通过推特的API来抓取数据。另一个很好的例子是商业日志。商业日志是知识的宝藏。如果有效地挖掘和建模，它们可以帮助许多决策过程。但是，通常日志不会直接提供给机器学习工程师。因此，机器学习工程师需要花费大量时间去弄清楚日志的结构，并可能编写脚本来按照需求捕获日志。所有这些过程统称为**数据获取**或**数据收集**。
- en: Data preparation
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'After the data collection phase, we tend to prepare the data to feed it to
    the ML systems and this is known as **data preparation**. It is worth mentioning
    that this is the most time-consuming part of an ML workflow/pipeline. Data preparation
    includes a series of steps and they are as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据收集阶段之后，我们倾向于准备数据，将其输入到机器学习系统中，这被称为**数据准备**。值得一提的是，这是机器学习工作流/管道中最耗时的部分。数据准备包括一系列步骤，具体如下：
- en: Exploratory data analysis
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索性数据分析
- en: Data processing and wrangling
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据处理与整理
- en: Feature engineering and extraction
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征工程与提取
- en: Feature scaling and selection
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征缩放和选择
- en: This is one of the most time-consuming parts of an ML project. When we take
    a broader look at the process, we find that data identification and collection
    are also sometimes really important aspects as the correct format, as mentioned
    previously, might not always be available.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这是机器学习项目中最耗时的部分之一。当我们从更广泛的角度审视整个过程时，我们发现数据识别和收集有时也非常重要，因为如前所述，正确的格式可能并不总是可用。
- en: Exploratory Data Analysis (EDA)
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索性数据分析（EDA）
- en: After the data is collected, the first step in the data preparation stage is
    **Exploratory Data Analysis**, which is very popularly known as **EDA**. EDA techniques
    allow us to know the data in a detailed manner for better understanding. This
    is an extremely vital step in the overall ML pipeline because without good knowledge
    about the data itself, if we blindly fit an ML model to the data, it most likely
    will not produce good results. EDA gives us a direction in which to proceed and
    helps us to decide further steps in the pipeline. EDA involves many things such
    as calculating useful statistics about the data and determining whether the data
    suffers from any outliers. It also comprises effective data visualization, which
    helps us to interpret the data graphically and therefore helps us to communicate
    vital facts about the data in a meaningful way.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 数据收集完成后，数据准备阶段的第一步是**探索性数据分析**，通常简称为**EDA**。EDA技术使我们能够更详细地了解数据，从而更好地理解数据。这是整个机器学习管道中极其重要的一步，因为如果我们对数据本身缺乏充分的了解，盲目地将机器学习模型应用于数据，很可能不会产生好的结果。EDA为我们提供了前进的方向，并帮助我们决定管道中的后续步骤。EDA涉及许多内容，如计算数据的有用统计量，并确定数据是否存在离群值。它还包括有效的数据可视化，帮助我们图形化地解读数据，从而以有意义的方式传达数据的关键信息。
- en: In short, EDA is all about getting to know about the data better.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，EDA的核心就是更好地了解数据。
- en: Data processing and wrangling
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据处理与整理
- en: We have performed some statistical analyses on the data. Now what? Most of the
    time, the data that is collected from several data sources is present in its raw
    form, which cannot be fed to an ML model, hence the need for further data processing.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经对数据进行了某些统计分析。现在怎么办？大多数情况下，从多个数据源收集的数据以原始形式呈现，无法直接输入到机器学习模型中，因此需要进一步的数据处理。
- en: But you might ask, why not collect the data in a way so that it gets retrieved
    with all of the necessary processing done? This is typically not a good practice
    as it breaks the modularity of the workflow.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 但你可能会问，为什么不以一种方式收集数据，使其在检索时就完成所有必要的处理？这通常不是一个好的做法，因为它破坏了工作流的模块化。
- en: This is why to make the data consumable in the later steps in the workflow,
    we need to clean, transform, and persist it. This includes several things such
    as data normalization, data standardization, missing value imputation, encoding
    from one value to another, and outlier treatment. All of these are collectively
    named **data wrangling**.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 正因为如此，为了使数据在工作流后续步骤中可以使用，我们需要对其进行清理、转换和持久化。这包括多项工作，如数据归一化、数据标准化、缺失值填补、从一个值到另一个值的编码转换以及离群值处理。所有这些统称为**数据整理**。
- en: Feature engineering and extraction/selection
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程与提取/选择
- en: Consider a situation where an employee from an analytics firm is given the company's
    billing data and is asked by their manager to build a machine learning system
    with it so the company's overall financial budget could be optimized. Now, this
    data is not in a format that can be given directly to an ML model since ML models
    expect data in the form of numeric vectors.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有一家分析公司的一名员工收到公司的账单数据，并被经理要求使用这些数据建立一个机器学习系统，以便优化公司的整体财务预算。现在，这些数据的格式无法直接提供给机器学习模型，因为机器学习模型期望数据以数值向量的形式呈现。
- en: Although the data might be in good shape, the employee will still have to do
    *something* to convert that data into a favorable form. Given that the data is
    already wrangled, they still need to decide what features he is they are going
    to include in the final dataset. Practically, anything measurable can be a feature
    here. This is where good domain knowledge comes. This knowledge can help the employee
    to choose the features that have *high predictive power*. It may sound a bit light-weight,
    but it requires a lot of skills and it is definitely a challenging task. This
    is a classic example of **feature engineering**.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然数据可能已经处理得不错，但员工仍然需要做*某些事情*，以将这些数据转换为有利的形式。尽管数据已经经过清理，但他们仍然需要决定哪些特征要包含在最终数据集中。实际上，任何可度量的内容都可以是一个特征。此时，良好的领域知识非常重要。这些知识能够帮助员工选择具有*高预测能力*的特征。听起来可能有点简单，但这实际上需要大量的技能，并且绝对是一个具有挑战性的任务。这是**特征工程**的经典例子。
- en: Sometimes, we employ several techniques that help us in the automatic extraction
    of the most meaningful features from a given dataset. This is particularly useful
    when the data is very high dimensional and the features are hard to interpret.
    This is known as **feature selection**. Feature selection not only helps to develop
    an ML model with the data that has the most relevant features but it also helps
    to enhance the model's predictive performance and to reduce its computation time.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们采用一些技术来帮助我们从给定的数据集中自动提取最有意义的特征。特别是在数据维度非常高且特征难以解释时，这一点特别有用。这被称为**特征选择**。特征选择不仅有助于开发一个具有最相关特征的机器学习模型，还能提高模型的预测性能并减少计算时间。
- en: Apart from feature selection, we might want to reduce the dimensionality of
    the data to better visualize it. Besides, **dimensionality reduction** is also
    employed to capture a representative set of features from the complete set of
    data features. **Principal Component Analysis** (**PCA**) is one such very popular
    dimensionality reduction technique.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 除了特征选择，我们可能还希望通过降维来更好地可视化数据。此外，**降维**还用于从完整的数据特征集中捕获一组具有代表性的特征。**主成分分析**（**PCA**）就是一种非常流行的降维技术。
- en: It is important to keep in mind that feature selection and dimensionality reduction
    are not the same.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 需要牢记的是，特征选择和降维并不是同一回事。
- en: Modeling
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建模
- en: We have finally come to the step that appears to be the most exciting one—the
    **ML modeling** part. But it is worth noting here that a good ML project is not
    just about this part. All of the previously mentioned parts contribute equally
    to the standard of the project. In fact, it matters a lot how the data is being
    collected for the project, and for this, we are helped by powerful data engineers.
    For now, let's leave that part aside.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于来到了看似最激动人心的步骤——**机器学习建模**部分。但值得注意的是，一个好的机器学习项目不仅仅是关于这一部分。之前提到的所有部分同样对项目标准的提升起到了关键作用。实际上，数据是如何收集的对项目来说非常重要，为此，我们有强大的数据工程师提供帮助。现在，先把这部分放到一边。
- en: We already have the data in pretty good shape by now. In the process of modeling
    the data, we feed the training data to ML models for training them, we monitor
    their training progress and tune different hyperparameters so their performance
    is optimized, and we evaluate the model on the test set. *Model comparison* is
    also a part of this phase. It is indeed an *iterative* process and involves *trial
    and error* to some extent.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经将数据处理得相当好。在建模过程中，我们将训练数据输入到机器学习模型中进行训练，监控它们的训练进度，并调整不同的超参数以优化其性能，然后在测试集上评估模型。*模型比较*也是这一阶段的一部分。事实上，这确实是一个*迭代*的过程，并在一定程度上涉及*试错*。
- en: The main objective here is to come up with an ML model that best represents
    the data, that is, it *generalizes* well. Computation time is another factor we
    must consider here because we want a model that performs well but within a feasible
    time frame and thereby optimizing a certain business outcome.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的主要目标是提出一个最佳地表示数据的机器学习模型，即它能够*很好地泛化*。计算时间是我们在这里必须考虑的另一个因素，因为我们需要一个在合理时间框架内表现良好的模型，从而优化某个业务结果。
- en: 'Following are the parts that constitute the core of modeling:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是构成建模核心部分的内容：
- en: Model training
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型训练
- en: Model evaluation
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型评估
- en: Model tuning
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型调优
- en: Model training
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练
- en: This is the fundamental part of modeling as we introduce the data to different
    ML models and **train** the model so that it can learn the representations of
    the data holistically. We can see how a model is making progress during its training
    using *training error*. We often bring *validation error* (which means we validate
    the model training simultaneously) into this picture as well, which is a standard
    practice. Most of the modern libraries today allow us to do this and we will see
    it in the upcoming chapters of this book. We will now discuss some of the most
    commonly used error metrics.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这是建模的基础部分，我们将数据输入不同的机器学习模型并**训练**模型，以使其能够全面地学习数据的表示。我们可以通过*训练误差*来看模型在训练过程中如何进展。我们通常还会引入*验证误差*（即我们同时验证模型训练），这是一个标准做法。现在的现代库大多数都支持这样做，我们将在本书接下来的章节中看到。接下来我们将讨论一些最常用的误差指标。
- en: Model evaluation
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型评估
- en: We have trained an ML model but how well will the model perform on the data
    it has never seen before? We answer this question using **model evaluation**.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经训练了一个机器学习模型，但它在从未见过的数据上表现如何呢？我们用**模型评估**来回答这个问题。
- en: Different machine learning algorithms call for different evaluation metrics.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的机器学习算法需要不同的评估指标。
- en: 'For supervised learning methods, we usually use the following:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 对于监督学习方法，我们通常使用以下指标：
- en: 'The confusion matrix, which is a matrix consisting of four values: True Positive,
    False Positive, True Negative, and False Negative'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混淆矩阵，它由四个值组成：真正例、假正例、真负例和假负例
- en: Accuracy, precision, recall, and F1-score (these are all byproducts of the confusion
    matrix)
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准确率、精确率、召回率和F1分数（这些都是混淆矩阵的衍生指标）
- en: The **Receiver Operator Characteristic** (**ROC**) curve and the **Area Under
    Curve** (**AUC**) metric
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**接收者操作特征**（**ROC**）曲线和**曲线下面积**（**AUC**）指标'
- en: R-square (coefficient of determination), **Root Mean Square Error** (**RMSE**),
    F-statistic, **Akaike Information Criterion** (**AIC**), and p-values specifically
    for regression models
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R平方（决定系数）、**均方根误差**（**RMSE**）、F统计量、**赤池信息量准则**（**AIC**）以及专门针对回归模型的p值
- en: Throughout this book, we will be incorporating these metrics to evaluate our
    models. Although these are the most common evaluation metrics, be it for ML or
    DL, there are more specific evaluation metrics that correspond to different domains.
    We will get to that as well as we go along.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将结合这些指标来评估我们的模型。虽然这些是最常见的评估指标，无论是针对机器学习（ML）还是深度学习（DL），但针对不同领域还有更具体的评估指标。我们将在后续章节中讲到这些内容。
- en: It worth mentioning here that we often tend to fall into the trap of the *accuracy
    paradox *in the case of* classification *problems where the data is *imbalanced*.
    In these cases, classification accuracy only tells one part of the story, that
    is, it gives the percentage of correct predictions made out of the total number
    of predictions made. This system fails miserably in the case of imbalanced datasets
    because accuracy does not capture how well a model is performing at predicting
    the negative instances of the dataset (which is originally the problem—predicting the
    uncommon class(es)).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里值得一提的是，在*分类*问题中，特别是当数据*不平衡*时，我们常常会陷入*准确性悖论*的陷阱。在这些情况下，分类准确率只能反映一部分情况，即它给出了正确预测的百分比，而不是模型对负类实例（即最初的问题——预测不常见类别）的预测能力。这种系统在数据不平衡的情况下会失败，因为准确性并不能反映模型在预测负类实例时的表现。
- en: 'Following are the most commonly used metrics for evaluating unsupervised methods
    such as clustering:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是评估无监督方法（如聚类）时最常用的指标：
- en: Silhouette coefficients
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 轮廓系数
- en: Sum of squared errors
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平方误差之和
- en: Homogeneity, completeness, and the V-measure
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同质性、完整性和V度量
- en: The Calinski-Harabasz index
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卡林斯基-哈拉巴兹指数
- en: The evaluation metrics/error metrics remain the same for a train set, a test
    set, or a validation set. We cannot just jump to a conclusion just by looking
    at the performance of a model on the train set.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 评估指标/误差指标对于训练集、测试集或验证集是相同的。我们不能仅仅通过查看模型在训练集上的表现就得出结论。
- en: Model tuning
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型调优
- en: By this phase, we should have a baseline model with which we can go further
    for **tuning the model** to make it perform even better. Model tuning corresponds
    to **hyperparameter tuning/optimization**.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 到了这一阶段，我们应该已经有了一个基准模型，可以在此基础上进一步**调整模型**，使其表现更好。模型调整对应于**超参数调整/优化**。
- en: ML models come with different *hyperparameters* that cannot be learned from
    model training. Their values are set by the practitioners. You can compare the
    hyperparameter values to the knobs of an audio equalizer where we manually adjust
    the knobs to have the perfect aural experience. We will see how hyperparameter
    tuning can drastically enhance the performance of a model in later chapters.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型有不同的*超参数*，这些超参数无法通过模型训练来学习。它们的值由从业者设置。你可以将超参数的值比作音频均衡器的旋钮，我们手动调整旋钮以获得完美的听觉体验。在后续章节中，我们将看到超参数调优如何极大地提升模型的性能。
- en: 'There are several techniques for tuning hyperparameters and the most popularly
    incorporated are the following:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种技术可以用来调优超参数，最常用的有以下几种：
- en: Grid searching
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网格搜索
- en: Random searching
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机搜索
- en: Bayesian optimization
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 贝叶斯优化
- en: Gradient-based optimization
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于梯度的优化
- en: Evolutionary optimization
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进化优化
- en: Model comparison and selection
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型比较与选择
- en: 'After we are done with the model tuning part, we would definitely want to repeat
    the whole *modeling *part for models other than the current one in the hope that
    we might get better results. As ML practitioners, it is our job to ensure that
    the model we have finally come up with is better than the other ones (obviously
    in various aspects). Naturally, comparing different ML models is a time-consuming
    task and we may not be able to always afford to do this when we need to meet short
    deadlines. In cases like this, we incorporate the following aspects of an ML model:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成模型调优部分后，我们肯定会希望对当前模型之外的其他模型重复整个*建模*过程，希望能得到更好的结果。作为机器学习从业者，我们的职责是确保最终得出的模型比其他模型更优秀（显然是在多个方面）。自然地，比较不同的机器学习模型是一项耗时的任务，而当我们需要赶在短时间内完成任务时，可能无法总是进行此操作。在这种情况下，我们会考虑以下几个模型方面：
- en: Explainability, which answers a given question (how interpretable is the model
    and how easily it can be explained and communicated?)
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可解释性，它回答了一个特定问题（模型的可解释性如何？它有多容易被解释和传达？）
- en: In-memory versus out-of-memory modeling
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存中建模与外存建模
- en: The number of features and instances in the dataset
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集中的特征和实例数量
- en: Categorical versus numerical features
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别特征与数值特征
- en: The nonlinearity of the data
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的非线性
- en: Training speed
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练速度
- en: Prediction speed
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测速度
- en: These metrics are the most popular ones but it hugely depends on the problem
    at hand. When these metrics do not apply, a good rule of thumb is to see how a
    model is performing on the validation set.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标是最常见的，但它们在很大程度上取决于所面临的问题。当这些指标不适用时，一个好的经验法则是查看模型在验证集上的表现。
- en: Deployment and monitoring
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署与监控
- en: After a machine learning model is built, it is merged with the other components
    of an application and is taken into production. This phase is referred to as **model
    deployment**. The true performance of the developed ML model is evaluated after
    it is deployed into real systems. This phase also involves thorough monitoring
    of the model to figure out the areas where the model is not performing well and
    which aspects of the model can be improved further. Monitoring is extremely crucial
    as it provides the means to enhance the model's performance and thereby enhance
    the performance of the overall application.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建好机器学习模型后，它将与应用程序的其他组件合并，并投入生产。这个阶段称为**模型部署**。开发的机器学习模型的真实表现会在部署到实际系统后进行评估。此阶段还涉及对模型的全面监控，找出模型表现不佳的领域，以及可以进一步改进的方面。监控至关重要，因为它为提升模型的表现提供了手段，从而提升整个应用程序的表现。
- en: So, that was a kind of a primer of the most important terminologies/concepts
    required for an ML project.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是进行机器学习项目时最重要的术语/概念的简要介绍。
- en: For a more rigorous study of the basics of ML, you are encouraged to go through
    these resources: *Machine Learning Crash Course* by Google ([https://developers.google.com/machine-learning/crash-course/](https://developers.google.com/machine-learning/crash-course/)) and *Python
    Machine Learning* by Sebastian Raschka ([https://india.packtpub.com/in/big-data-and-business-intelligence/python-machine-learning](https://india.packtpub.com/in/big-data-and-business-intelligence/python-machine-learning)).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更深入地学习机器学习基础，建议你通过以下资源进行学习：Google的*机器学习速成课程*（[https://developers.google.com/machine-learning/crash-course/](https://developers.google.com/machine-learning/crash-course/)）和Sebastian
    Raschka的*Python机器学习*（[https://india.packtpub.com/in/big-data-and-business-intelligence/python-machine-learning](https://india.packtpub.com/in/big-data-and-business-intelligence/python-machine-learning)）。
- en: 'For easy reference, you may refer to the following diagram as given in the
    book, *Hands-on Transfer Learning with Python* (by Dipanjan et. al), which depicts
    all of the preceding steps pictorially:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便参考，你可以查看书中给出的以下图示，来自《*Python实践转移学习*》（Dipanjan等人），该图以图像的形式展示了前面提到的所有步骤：
- en: '![](img/1adb3e40-cbd7-469f-8234-3002ac0d91c2.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1adb3e40-cbd7-469f-8234-3002ac0d91c2.png)'
- en: Practically, ML has brought about a lot of enhancements across a wide range
    of sectors and almost none are left to be impacted by it. This book is focused
    on building *intelligent web applications*. Therefore, we will start the next
    section by discussing the web in general and how it has changed since the advent
    of AI from a before-and-after perspective. Eventually, we will study some big
    names and how they are facilitating AI for building world-class web applications
    that are not only intelligent but also solve some real problems.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，机器学习（ML）在各个领域带来了大量的改进，几乎没有一个领域没有受到它的影响。本书的重点是构建*智能网页应用程序*。因此，我们将在下一部分开始讨论网页的整体情况以及自人工智能出现以来它是如何变化的，采用前后对比的方式。最终，我们将学习一些大公司及其如何利用人工智能构建世界级的网页应用，这些应用不仅智能，而且解决一些实际问题。
- en: The web before and after AI
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能前后的网页
- en: If you have been a regular user of the World Wide Web since 2014, you'd agree
    to a visible rapid flurry of changes in websites. From solving *ReCaptcha* challenges
    of increasingly illegible writing to being automatically marked as *human* in
    the background, web development has been one of the forerunners in the display
    of the wealth of artificial intelligence that has been created over the last two
    decades.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你自2014年起就是万维网的常规用户，你会同意网站的变化速度是显而易见的。从解决越来越难以辨认的*ReCaptcha*挑战到在后台自动标记为*人类*，网页开发一直是展示过去二十年里人工智能成果的先行者之一。
- en: 'Sir Tim Berners-Lee, attributed as the inventor of the internet, has put forward
    his views on a Semantic Web:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 被誉为互联网发明者的蒂姆·伯纳斯-李爵士提出了他的语义网观点：
- en: '"I have a dream for the Web [in which computers] become capable of analyzing
    all the data on the Web – the content, links, and transactions between people
    and computers. A "Semantic Web", which makes this possible, has yet to emerge,
    but when it does, the day-to-day mechanisms of trade, bureaucracy, and our daily
    lives will be handled by machines talking to machines. The "intelligent agents"
    people have touted for ages will finally materialize."'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '"我对Web的梦想是[计算机]能够分析Web上的所有数据——内容、链接以及人类与计算机之间的交易。一个实现这一目标的“语义网”尚未出现，但一旦它出现，日常的贸易、官僚机制以及我们日常生活的各个方面将由机器与机器之间的对话来处理。人们长期以来推崇的“智能代理”将最终得以实现。"'
- en: From serving static pages with tons of information visible in them and links
    that permanently take you to related resources, the web is now an ever-changing
    portal of information generated dynamically. You might never see the same view
    of a web page again if you refresh it.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 从呈现大量信息并且其中的链接将你永久带到相关资源的静态页面，到如今网页已经成为一个动态生成信息、不断变化的门户。如果你刷新网页，你可能再也看不到相同的页面视图。
- en: Let's understand some of the most important shifts in web development that have
    come about due to the rise of AI.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解一下由于人工智能的兴起，网页开发发生的一些最重要的变化。
- en: Chatbots
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聊天机器人
- en: If you have ever wondered how some web pages provide 24/7 live help through
    chat on their websites, the answer would almost always be a chatbot is answering
    your queries from the other end. When in 1966 Joseph Weizenbaum's ELIZA chatbot
    created waves across the world by beating the Turing Test, we would never have
    thought of the impact chatbots would create in the World Wide Web (a reason for
    this, though, could be that ARPANET was itself only created in 1969).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾经好奇，为什么有些网页能通过聊天窗口提供24小时全天候帮助，答案几乎总是一个聊天机器人在另一个端口回答你的问题。当1966年约瑟夫·魏岑鲍姆的ELIZA聊天机器人通过图灵测试而引起全球轰动时，我们几乎无法预见聊天机器人将会在万维网上产生如此巨大的影响（不过一个原因可能是ARPANET直到1969年才创建）。
- en: Today, chatbots are everywhere. Many Fortune 500 companies are pursuing research
    in the domain and have come out with implementations of chatbots for their products
    and services. In a recent survey done by Oracle, featuring responses from 800
    top executives of several companies and startups, it was found that nearly 80%
    of them said they had already used or were planning to use a chatbot in their
    customer-facing products by 2020.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，聊天机器人无处不在。许多《财富》500强公司都在这个领域进行研究，并推出了针对其产品和服务的聊天机器人实现。在Oracle进行的一项最新调查中，涵盖了来自多个公司和初创公司的800名高管的反馈，调查发现近80%的受访者表示，他们已经使用或计划在2020年之前将聊天机器人应用于面向客户的产品。
- en: Before AI began powering chatbots, as in the case with ELIZA (and its successor
    ALICE), chatbots were mostly about a fixed set of responses mapped to several
    input patterns. Coming across the word *mother* or *father* in a sentence entered
    by the user would almost certainly produce a response asking about the family
    of the user or their well-being. This clearly wasn't the response desired if the
    user wrote something like "I do not want to talk about XYZ's family".
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能开始驱动聊天机器人之前，像ELIZA（及其后继者ALICE）这样的聊天机器人，通常只是根据几个输入模式映射到一组固定的响应。当用户输入句子中出现*母亲*或*父亲*这类词时，几乎肯定会得到询问用户家庭或健康状况的回复。如果用户写下类似“我不想谈论XYZ的家庭”的内容，这显然并不是他们期望的回答。
- en: And then, there is the famous "sorry, I did not get that" response of such rule-based
    chatbots, which made them appear quite stupid at times. The advent of neural-network-based
    algorithms saw chatbots being able to understand and customize responses based
    on user emotion and the context of the user input. Also, some chatbots scrape
    online data in case of encountering any new query and build up answers in real
    time about the topics mentioned in the new, unknown queries. Apart from that,
    chatbots have been used to provide alternative interfaces to business portals.
    It is now possible to book hotels or flights over a chatbot platform provided
    by WhatsApp.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，还有那种经典的“抱歉，我没听懂”的回答，这种基于规则的聊天机器人有时显得非常愚笨。神经网络算法的出现使得聊天机器人能够根据用户情感和输入的上下文理解并定制回应。此外，一些聊天机器人会抓取在线数据，以便在遇到新问题时实时构建与新问题中提到的话题相关的回答。除此之外，聊天机器人还被用来为商业门户提供替代界面。现在，通过WhatsApp提供的聊天平台，你可以预定酒店或航班。
- en: Facebook Messenger's bot platform saw over 100,000 bots created in the first
    17 months of its being opened to the public. Hundreds of pages on the social networking
    giant today have automated responses for users who send messages to their pages.
    Several bots are running on Twitter that can create content, closely mimicking
    a human user, and can respond to messages or comments made on their posts.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: Facebook Messenger的机器人平台在对公众开放的前17个月内创造了超过100,000个机器人。如今，社交网络巨头Facebook上的数百个页面都为向其页面发送消息的用户提供自动回复。一些机器人在Twitter上运行，能够生成内容，*
    closely* 模仿人类用户，并且可以回复用户在其帖子上的消息或评论。
- en: You can chat with an online version of ELIZA at [eliza.botlibre.com](http://eliza.botlibre.com).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[eliza.botlibre.com](http://eliza.botlibre.com)与ELIZA的在线版本聊天。
- en: Web analytics
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络分析
- en: In the early years of the internet, many websites carried odometer-style counters
    embedded in them. These were simple counts of the number of hits the website or
    a particular page had received. Then, they grew in their available formats—plain
    counters, counters per day/week/month, and even geolocation-based counters.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在互联网的早期，许多网站都嵌入了类似里程计的计数器。这些计数器简单地统计网站或某个特定页面收到的访问次数。后来，计数器的形式也越来越多样化——包括普通计数器、按天/周/月计数的计数器，甚至基于地理位置的计数器。
- en: The collection of data, which is essentially the logs of the interactions of
    users and how they interact with a web-based application, processing this data
    to produce performance indicators, and then finally to identify measures that
    can be taken by a company to improve their web application is collectively  known
    as web analytics.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 网络分析是指收集数据，这些数据本质上是用户的交互日志以及他们如何与基于网络的应用程序互动，处理这些数据以产生绩效指标，然后最终识别出可以采取的措施，帮助公司改善其网络应用程序。
- en: Since the invention of the internet, web applications today generate a huge
    amount of logs every moment. Even leaving your mouse pointer idle on a web page
    might be getting reported to a Google Analytics dashboard, from where the webmaster
    would be able to see which pages are being viewed by users and how much time they
    are spending on the pages. Also, the flow users take between pages would be a
    very interesting metric.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 自互联网发明以来，今天的网络应用程序每时每刻都会生成大量的日志。即使你将鼠标指针保持在网页上不动，可能也会被报告到Google Analytics仪表盘，从而网站管理员可以查看用户访问了哪些页面，以及他们在页面上停留了多长时间。此外，用户在各页面之间的流动路径也是一个非常有趣的指标。
- en: While the earliest web analytics tools would merely measure page hits, being
    able to create a map of how many times a given page was visited and how many times
    it was a unique user, they could hardly provide anything about the visiting patterns
    of users, unless they were specifically hardcoded, which would be presented in
    very generalized manners and were never website specific. The same form of analytics
    was being provided to a company doing e-commerce as was being provided to a personal
    website.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然最早的网络分析工具仅仅测量页面访问次数，能够创建一个页面被访问多少次、多少次是独立用户访问的图示，但它们几乎无法提供用户访问模式的任何信息，除非这些信息被专门硬编码进去，这些数据通常以非常笼统的方式呈现，并且从未与网站特定的内容相关联。相同的分析形式被提供给电商公司，也同样被提供给个人网站。
- en: With the revolution that AI brought around in the web analytics domain, tools
    today that deploy the power of artificial intelligence can come up with future
    predictions of website performance and even suggest removing or adding specific
    content on a web page to improve user engagement with that page.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人工智能在网络分析领域带来的革命，今天的工具可以利用人工智能的力量，预测网站未来的表现，甚至建议删除或添加网页上的特定内容，以提高用户与网页的互动。
- en: Spam filtering
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 垃圾邮件过滤
- en: When half the emails being sent across the world are marked spam, it's an issue.
    While at first thought, we associate fraudulent and unnecessary emails promoting
    businesses and products as spam, that's only a part of the definition. It is important
    to realize that even good, quality content when posted on the same document several
    times over is spam. Furthermore, the web has evolved since the term *spam* was
    first used in Usenet groups. What was initially an activity performed with the
    intention of annoying people, or driving in messages forcefully to certain target
    users, spam today is much more evolved and potentially a lot more dangerous—from
    being able to track your browser activity to identity theft, there is a lot of
    malicious spam on the internet today that compromises user security and privacy.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 当全球一半的电子邮件被标记为垃圾邮件时，这就成了一个问题。虽然我们最初可能会将那些推广业务和产品的欺诈性或不必要的电子邮件视为垃圾邮件，但这仅是其定义的一部分。重要的是要意识到，即使是优质的内容，当它在同一文档中重复多次发布时，也会成为垃圾邮件。此外，自从“垃圾邮件”这一术语首次出现在Usenet群组中以来，互联网已经发生了巨大变化。最初，垃圾邮件是为了打扰他人或强制推送信息给特定目标用户而进行的活动，但今天的垃圾邮件已经变得更加复杂，潜在地也更加危险——从能够追踪你的浏览器活动到身份盗窃，今天的互联网充斥着大量危害用户安全和隐私的恶意垃圾邮件。
- en: Today, we have spam of various kinds—instant messenger spam, website spam, advertisement
    spam, SMS spam, social media spam, and many other forms.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，我们面临着各种类型的垃圾邮件——即时通讯垃圾邮件、网站垃圾邮件、广告垃圾邮件、短信垃圾邮件、社交媒体垃圾邮件，以及许多其他形式的垃圾邮件。
- en: Apart from a few, most types of spam are exhibited on the internet. It is hence
    critical to be able to filter spam and take protective measures against it. While
    the most initial spam-fighting began as early as the 1990s with identifying the
    IP addresses that were sending out spam emails, it was soon realized to be a highly
    inefficient method to do so as the blacklist grew large and its distribution and
    maintenance became a pain.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 除了少数几种，大多数类型的垃圾邮件都出现在互联网上。因此，能够过滤垃圾邮件并采取保护措施至关重要。虽然最早的反垃圾邮件工作可以追溯到1990年代，那时通过识别发送垃圾邮件的IP地址来进行处理，但很快就意识到这种方法效率极低，因为黑名单变得越来越庞大，且其分发和维护非常繁琐。
- en: In the early 2000s, when Paul Graham published a paper titled *A Plan for Spam*,
    for the first time, an ML model—Bayesian filtering—was deployed to fight spam.
    Soon, several spam-fighting tools were spun from the paper and proved to be efficient.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在2000年代初，当保罗·格雷厄姆发布了一篇名为*《垃圾邮件计划》*的论文时，首次使用了机器学习模型——贝叶斯过滤——来应对垃圾邮件。很快，几款反垃圾邮件工具便从这篇论文中衍生出来，并证明它们非常高效。
- en: 'Such was the impact of Bayesian filtering method against spam that, at the *World
    Economic Forum* in 2004, the founder of Microsoft, Bill Gates went forward to
    say that:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯过滤方法对抗垃圾邮件的影响如此之大，以至于在2004年*世界经济论坛*上，微软创始人比尔·盖茨曾表示：
- en: '"Two years from now, spam will be solved."'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: “两年后，垃圾邮件问题将会得到解决。”
- en: Bill Gates, however, as we know today, could not have been more wrong in this
    one prediction. Spam evolved, with spammers studying Bayesian filtering and finding
    out ways to avoid being marked as spam in the detection phase. Today, neural networks
    are deployed on large scale, continuously scanning new emails and taking decisions
    on determining spam or non-spam content, which could not have been logically reached
    by a human by merely studying logs of email spam.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如我们今天所知，比尔·盖茨在这个预测上完全错了。垃圾邮件不断演变，垃圾邮件发送者研究贝叶斯过滤方法，找出了规避检测阶段标记为垃圾邮件的方式。如今，神经网络被大规模部署，持续扫描新的电子邮件并决定是否为垃圾邮件，这些判断是人类仅仅通过研究垃圾邮件日志无法做出的。
- en: Search
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 搜索
- en: One of the most strongly impacted domains by the rise of AI has been web search.
    From its humble beginnings of having to know the exact wording of the particular
    web page's title that you wished to visit, to search engines being able to identify
    songs that are audible in your environment, the domain has been entirely transformed
    due to AI.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的崛起对网络搜索领域产生了深远影响。从最初必须精确知道你希望访问的网页标题的准确措辞，到现在搜索引擎能够识别你周围环境中的歌曲，这一领域因人工智能而彻底改变。
- en: 'When in 1991, Tim Berners-Lee set up the World Wide Web Virtual Library, it
    looked something like this:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 当1991年蒂姆·伯纳斯-李建立了万维网虚拟图书馆时，它大致是这样的：
- en: '![](img/120bb432-ece2-40bf-9b64-19142d707316.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](img/120bb432-ece2-40bf-9b64-19142d707316.png)'
- en: It was a collection of manually listed web pages, filterable by the search box,
    which appeared at the right-top. Clearly, instead of trying to predict what the
    user was intending to find, the user himself/herself had to decide the category
    to which their search term would belong to.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个手动列出的网页集合，可以通过出现在右上角的搜索框进行过滤。显然，与其预测用户的搜索意图，用户自己必须决定其搜索词所属的类别。
- en: The current face of the web search engines was introduced by Johnathan Fletcher
    in December 1993, when he created JumpStation, the first search engine to use
    the modern-day concepts of crawling, indexing, and searching. The appearance used
    by JumpStation was how we see the leading search providers such as Google and
    Bing today, and made Johnathan the "Father of the search engine".
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 当前网页搜索引擎的面貌是在1993年12月由Johnathan Fletcher提出的，当时他创建了JumpStation，这是第一个使用现代爬虫、索引和搜索概念的搜索引擎。JumpStation的界面设计正是我们今天看到的Google和Bing等主流搜索引擎的样子，这使得Johnathan成为了“搜索引擎之父”。
- en: Two years later, in December 1995, when AltaVista was launched, it brought a
    radical shift in search technology—unlimited bandwidth, search tips, and even
    allowing natural language queries—a feature brought in more strongly by Ask Jeeves
    in 1997.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 两年后，即1995年12月，当AltaVista推出时，它带来了搜索技术的根本变化——无限带宽、搜索提示，甚至允许自然语言查询——这一功能在1997年被Ask
    Jeeves更强力地引入。
- en: Google came around in 1998\. And it brought with itself the technology of PageRank.
    However, several contenders were present in the market, and Google didn't dominate
    the search engine game right then. Five years later, when Google filed its patent
    for using neural networks to customize search results based on users' previous
    search history and record of visited websites, the game shifted very quickly toward
    Google becoming the strongest provider in the search domain.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: Google于1998年诞生，并带来了PageRank技术。然而，当时市场上有多个竞争者，Google并没有立即主导搜索引擎市场。五年后，当Google申请使用神经网络根据用户的历史搜索记录和访问过的网站定制搜索结果的专利时，局势迅速发生变化，Google很快成为搜索领域最强大的提供者。
- en: Today, a huge code base, deploying several deep neural networks working in coherence,
    powers Google Search. Natural language processing, which majorly deploys neural
    networks, has allowed Google to determine the content relevancy of web pages,
    and machine vision thanks to **Convolutional Neural Networks** (**CNNs**) has
    been able to produce accurate results visible to us in the Google Image Search.
    It should not come as a surprise that John Ginnandrea led Google Search and introduced
    the Knowledge Graph (the answers Google sometimes comes up with on certain questions
    such as queries); he's one of the most sought-after specialists in AI and has
    now been recruited by Apple, to improve Siri, which is again a neural network
    product.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，Google 搜索依靠着一个庞大的代码库，部署了多个协同工作的深度神经网络。自然语言处理，主要依靠神经网络，已使 Google 能够判断网页内容的相关性，而得益于**卷积神经网络**（**CNNs**），机器视觉已经能够在
    Google 图片搜索中生成准确的结果。令人不意外的是，John Ginnandrea 曾领导 Google 搜索并推出了知识图谱（Google 有时会给出答案的某些问题，如查询结果）；他是
    AI 领域最受追捧的专家之一，现在已经被 Apple 招募，以改进 Siri，Siri 也是一个神经网络产品。
- en: Biggest web-AI players and what are they doing with AI
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最大的网络AI公司及其在AI领域的应用
- en: The growth spurt of AI saw several contenders running to make the most out of
    it. Over the last two decades, several individuals, start-ups, and even huge industrialists
    have sought to reap the benefits offered by the applications of AI. There are
    products in the market to whom artificial intelligence serves as the very heart
    of their business.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的快速增长吸引了众多竞争者争相利用这一机会。在过去的二十年里，多个个人、初创公司甚至大型企业都在寻求从人工智能应用中获取利益。市场上已经出现了一些产品，其中人工智能是它们业务的核心。
- en: <q>"War is 90% information."
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '<q>"战争是90%的信息。"  '
- en: '- Napoleon Bonaparte, 18th Century A.D.</q>'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: —— 拿破仑·波拿巴，公元18世纪</q>
- en: In the Second World War, the Allied forces deployed bomber aircraft. These were
    key to the strategies employed by the Allied forces. But somehow, these bombers
    failed to deliver due to them being shot down in large numbers when in enemy territory.
    It was clear that the bombers needed more armor. But due to the weight of armor,
    it was not possible to entirely cover the aircraft. Hence, it was decided that
    the most critical areas of the aircraft should be covered up with extra armor. 
    Abraham Wald, a Jewish mathematician, was asked to come up with a way to determine 
    which areas of the aircraft had to be armor-plated. He studied the aircraft that
    had come back from battle and made note of which areas carried the most bullet
    marks.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次世界大战中，盟军部署了轰炸机。这些轰炸机是盟军策略的关键。但由于大量轰炸机在敌方领土被击落，这些轰炸机未能完成任务。显然，轰炸机需要更多的装甲。然而，由于装甲重量的限制，无法完全覆盖整个飞机。因此，决定将飞机最关键的部位加装额外的装甲。犹太数学家
    Abraham Wald 被要求提出一个方法，来确定哪些部位需要装甲保护。他研究了从战斗中归来的飞机，并记录下哪些部位承受了最多的弹孔。
- en: 'It was found that the wings, the nose, and tail were the parts that carried
    the highest number of bullet marks, and it was concluded that these were the parts
    that needed more armor, while the cockpit and the engines displayed the least
    bullet holes:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 研究发现，机翼、机头和尾部是承受最多弹孔的部分，因此得出结论，这些部分需要更多的装甲，而驾驶舱和发动机则显示出最少的弹孔：
- en: '![](img/a6c5d938-0eea-4819-8a4c-6e5561ccbd12.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a6c5d938-0eea-4819-8a4c-6e5561ccbd12.png)'
- en: But surprisingly, going against the regular method of thought, Wald suggested
    that it was the cockpit and the engines that needed armor because it was those
    bombers that were not returning. Bullets in the tail, wings, and nose could not
    deal fatal damage to the aircraft and hence they returned successfully.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 但令人惊讶的是，Wald 持不同的观点，他建议应加强驾驶舱和发动机的装甲，因为正是那些未能返回的轰炸机才是问题所在。尾部、机翼和机头的弹孔不会对飞机造成致命伤害，因此这些飞机能够成功返回。
- en: This is how, working with data and identifying the correct pattern, the entire
    course of the Second World War was changed by a mathematician. Data has been termed
    as the new oil. What makes it more interesting is that when you have oil, you
    burn it to produce electricity and energy, to drive vehicles. But with data, you
    use it to improve business and make decisions, which, in the future, produce more
    data. The companies that realized this and took the most benefit out of the data
    available have seen huge growth in recent times. Let's explore what few of such
    companies are doing with all of the data available, using AI.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样，通过与数据的合作，识别出正确的模式，一位数学家改变了整个第二次世界大战的进程。数据被称为新的石油。更有趣的是，当你拥有石油时，你会将其燃烧以产生电力和能源，驱动车辆。而拥有数据时，你利用它来改善业务和做出决策，进而在未来产生更多的数据。那些意识到这一点并最大化利用现有数据的公司，近年来实现了巨大的增长。让我们看看这些公司如何利用所有数据，通过AI创造新机会。
- en: Google
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谷歌
- en: A name that comes to almost every mind as soon as the term AI is mentioned,
    Google has revolutionized and pushed the edges of AI continuously.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 提到AI这个词几乎每个人都会想到的一个名字，谷歌不断地推动并革命化了AI的边界。
- en: '"We are now witnessing a new shift in computing: the move from a mobile-first
    to an AI-first world."   -Sundar Pichai, CEO, Google'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: “我们现在正在见证计算领域的一个新转变：从移动优先到AI优先的世界。”——桑达尔·皮查伊，谷歌CEO
- en: Google has been using AI across several of its products; let's go through some
    of them here.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌已经在多个产品中应用AI，接下来我们来看看其中的一些。
- en: Google Search
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谷歌搜索
- en: 'Searching for `who is the google ceo` on December 14, 2018 brought up a results
    page resembling the following screenshot:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 2018年12月14日，搜索`谁是谷歌CEO`，得到的结果页面大致如下图所示：
- en: '![](img/11e3506d-ee55-42ad-a013-ee0a1016a75b.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![](img/11e3506d-ee55-42ad-a013-ee0a1016a75b.png)'
- en: The preceding feature, which generates answers to commonly asked questions,
    is known as the *Google Knowledge Graph*, which we mentioned in an earlier section. Besides
    this one feature, Google Search has grown exponentially more powerful due to AI
    techniques such as natural language processing and information extraction.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 上述功能，通过生成常见问题的答案，被称为*谷歌知识图谱*，我们在之前的章节中提到过。除了这一功能，得益于自然语言处理和信息提取等AI技术，谷歌搜索的功能也变得更加强大。
- en: 'The ability to come up with exact timings in a video that relate to a query
    made by the user is possible, all thanks to AI:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 通过AI技术，能够准确地在视频中提取与用户查询相关的时间点：
- en: '![](img/b6b48628-65c7-4267-a4d4-523f18176d6c.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b6b48628-65c7-4267-a4d4-523f18176d6c.png)'
- en: Next, we will look at Google Translate.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看一下谷歌翻译。
- en: Google Translate
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谷歌翻译
- en: Supporting over 100 languages, Google Translate is probably the best translation
    tool publicly available on the internet. From being able to detect the language
    being fed into it to converting it into the desired language as set by the user,
    there's a deep mesh of neural networks running in the background to produce the
    best results. This algorithm, to which Google switched in November 2016, was named
    the *Google Neural Machine Translation* algorithm. It is available on the web
    as an API to web developers who wish to translate their website's content in real
    time to be able to cater to users of different locales. Also, the service is integrated
    with Google Chrome, the browser made by Google, and provides real-time translations
    of web pages as soon as the user visits them in the browser.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 支持超过100种语言，谷歌翻译可能是互联网上最好的公共翻译工具。从能够检测输入的语言，到将其转换成用户设定的目标语言，背后有一张深度神经网络在运行，以提供最佳的翻译效果。这个算法，谷歌自2016年11月起切换使用，被命名为*谷歌神经机器翻译*算法。它以API形式提供给网页开发者，帮助他们将网站内容实时翻译，以便能够服务不同地区的用户。此外，这项服务还与谷歌浏览器Google
    Chrome集成，能够在用户访问网页时，实时翻译网页内容。
- en: Google Assistant
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谷歌助手
- en: 'One of the most recent ventures of Google, Google Assistant, is a competitor
    to Apple''s Siri and Microsoft''s Cortana and a successor of Google Now. It is
    an AI-powered virtual assistant available on mobile and smart home devices (branded
    as *Google Home*). Currently, it can make searches on the user''s Google Drive
    data, produce results based on the user''s preferences, provide reminders of notes
    given by the user, dial numbers, send text messages, and much more as directed
    by the user either by normal tap-input on touch screens or by voice input:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: Google 的最新项目之一——Google Assistant，是 Apple 的 Siri 和 Microsoft 的 Cortana 的竞争者，也是
    Google Now 的继任者。它是一个基于 AI 的虚拟助手，可在移动设备和智能家居设备（品牌为*Google Home*）上使用。目前，它可以在用户的
    Google Drive 数据上进行搜索，根据用户的偏好生成结果，提供用户给出的备忘提醒，拨打电话、发送短信，并根据用户的指示，通过触摸屏上的正常点击输入或语音输入执行更多任务：
- en: '![](img/02c4611b-f44d-47af-8ba3-932197617f70.jpeg)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02c4611b-f44d-47af-8ba3-932197617f70.jpeg)'
- en: Next, we will look at other products.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看看其他产品。
- en: Other products
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他产品
- en: AI is one of the primary technologies powering Google Ads. Click baiting or
    the problem of fake clicks was solved using neural networks. Further, determining
    which type of ads performed best down to the level of each single web page is
    efficiently facilitated by the use of AI. These technological advancements of
    Google's ad services made it rapidly grab the internet advertisement space from
    the preexisting advertising platforms.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: AI 是 Google 广告的主要技术之一。点击诱饵或虚假点击问题通过神经网络得到了有效解决。此外，通过使用 AI，可以高效地确定哪种类型的广告在每个网页上的表现最佳。这些技术进步使得
    Google 的广告服务迅速抢占了互联网广告市场，超越了之前的广告平台。
- en: Google projects such as Google Lens, self-driving cars, and many others have
    been primarily AI-based projects.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: Google 的一些项目，如 Google Lens、自动驾驶汽车等，主要都是基于 AI 的项目。
- en: Facebook
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Facebook
- en: Being the largest social networking platform on the internet with several profiles,
    Facebook generates a huge amount of data on a daily basis. Data of its users posting
    content, reports made by the users, logs of the various APIs provided by Facebook,
    and so on all add up to nearly 4 petabytes of data generated every day. Needless
    to say, the tech giant has capitalized on this data gold and come up with ways
    to make its platform safer for users and to boost user engagement.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 作为互联网上最大的社交平台，Facebook 每天生成大量数据。用户发布的内容、用户提交的报告、Facebook 提供的各种 API 的日志等等，所有这些加起来每天会产生近
    4 个拍字节的数据。不用多说，这个科技巨头已经利用这一数据宝藏，想出了方法来使其平台更安全，并提升用户参与度。
- en: Fake profiles
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 虚假账户
- en: A primary issue faced by Facebook was the presence of *fake profiles* in huge
    numbers. To deal with them, Facebook deployed AI-based solutions to automatically
    mark and challenge such profiles to confirm their identity. In the first quarter
    of 2018 alone, Facebook disabled nearly 583 million fake or clone accounts.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: Facebook 面临的一个主要问题是存在大量的*虚假账户*。为了解决这个问题，Facebook 部署了基于 AI 的解决方案，自动标记并挑战这些账户，确认其身份。仅在
    2018 年第一季度，Facebook 就禁用了近 5.83 亿个虚假或克隆账户。
- en: Fake news and disturbing content
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 假新闻与令人不安的内容
- en: 'Another issue faced by Facebook and their acquired messaging service, WhatsApp,
    was the issue of fake news or misleading news. Also, adding to the degradation
    of user experience was the presence of visually and/or emotionally disturbing
    content on the platform. And finally, there was something that nearly all online
    platforms had to fight: spam. Facebook''s AI algorithms over the years have become
    very good at identifying and removing spam. By the application of computer vision
    solutions facilitated by the usage of CNNs, Facebook has been able to come up
    with a feature that covers/blurs visually disturbing images and videos and asks
    for user consent before allowing users to view them.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个 Facebook 及其收购的消息服务 WhatsApp 面临的问题是虚假新闻或误导性新闻。此外，平台上出现的视觉上和/或情感上令人不安的内容，进一步降低了用户体验。最后，还有几乎所有在线平台都必须应对的问题：垃圾邮件。Facebook
    的 AI 算法多年来在识别和删除垃圾邮件方面变得非常擅长。通过应用计算机视觉解决方案，利用 CNN（卷积神经网络），Facebook 开发了一项功能，可以遮挡/模糊令人不安的图像和视频，并在允许用户查看之前要求用户同意。
- en: Work on identifying and taking down fake news is currently under progress and
    is almost entirely being done by the application of AI.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 识别并删除假新闻的工作目前正在进行中，几乎完全通过 AI 的应用来实现。
- en: Other uses
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他用途
- en: Facebook provides its own Messenger bot platform, which is hugely used by Facebook
    pages and developers to add rich interaction into the instant messaging service
    provided by the company.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: Facebook提供了自己的Messenger机器人平台，Facebook页面和开发者广泛使用该平台，将丰富的互动功能加入公司提供的即时消息服务中。
- en: Amazon
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 亚马逊
- en: The leading e-commerce platform on the internet, Amazon has incorporated AI
    in almost all of its products and services. While a late-comer to the AI party
    being enjoyed by Google, Facebook, Microsoft, and IBM, Amazon quickly grew and
    attracted attention to the various uses it put AI to. Let's go through some of
    the major applications that Amazon came out with.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 作为全球领先的电子商务平台，亚马逊几乎将AI融入了其所有的产品和服务中。虽然它是比Google、Facebook、Microsoft和IBM等公司晚加入AI阵营的，但亚马逊迅速崛起，并吸引了人们对其AI应用的关注。让我们看看亚马逊推出的一些主要应用。
- en: Alexa
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Alexa
- en: The AI that powers all Alexa and Echo devices produced by the company, Alexa
    is the name given to the virtual assistant AI developed in direct competition
    with Google Home, which was powered by Google Assistant (formerly Google Now).
    Not debating on which is better, Alexa is a fairly advanced AI, being able to
    produce answers to questions that many users have found interesting and witty.
    Alexa products have recently seen a rise in adoption with Amazon's move to make
    Alexa Skills Studio available to developers publicly, who added greatly to the
    actions that Alexa can perform.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 为所有由公司生产的Alexa和Echo设备提供支持的AI，Alexa是与Google Home竞争的虚拟助手AI的名字，后者由Google Assistant（前身为Google
    Now）提供支持。不讨论哪个更好，Alexa是一个相当先进的AI，能够回答许多用户觉得有趣和机智的问题。随着亚马逊将Alexa Skills Studio向开发者公开，Alexa产品的使用已显著增长，开发者为Alexa能执行的操作做出了巨大贡献。
- en: Amazon robotics
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 亚马逊机器人技术
- en: As soon as a user buys a product from the website, a robot sitting in the sprawling
    huge 855,000 square-foot fulfillment center at Kent, Washington (obviously, only
    for products available there) stirs up, lifts a large crate of products, and makes
    its way toward the site, carrying the very product sold on the platform, where
    a worker picks it up from the crates to further process it. Amazon recently equipped
    its Milwaukee fulfillment center with the same technology after a very successful
    run previously and plans to extend it to 10 other large centers soon.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户在网站上购买产品时，位于华盛顿州肯特市、占地855,000平方英尺的巨大配送中心内的一台机器人便会启动，搬起一大箱产品，朝着站点移动，将在平台上售出的产品送到工人手中，工人会从箱子中取出并进一步处理。亚马逊最近在密尔沃基配送中心安装了相同的技术，并计划在不久后将其扩展到其他10个大型中心。
- en: DeepLens
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DeepLens
- en: An artificial intelligence-enabled video camera would have been the ultimate
    geek fantasy in the early 2000s. With the coming of Amazon's DeepLens, which is
    exactly that, the possibilities opened up are endless. Imagine a situation where
    you are a host to a party and you get notified of every guest who comes in, directly
    on your phone. Surprisingly enough, this has been achieved and experiments have
    even been done on equipping public places with CCTV cameras that can identify
    criminals and trigger alerts automatically.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 一台人工智能驱动的视频摄像机曾是2000年代初的极客梦想。随着亚马逊推出的DeepLens，这一梦想成为现实，开启的可能性是无穷的。试想一下，当你是派对的主持人时，手机会通知你每个到来的宾客。令人惊讶的是，这已经实现，甚至已经进行过在公共场所安装CCTV摄像头来识别罪犯并自动触发警报的实验。
- en: Summary
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we briefly introduced many important concepts and terminologies
    that are vital to execute an ML project in general. These are going to be helpful
    throughout this book.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们简要介绍了许多对执行ML项目至关重要的重要概念和术语。这些内容将在本书中为您提供帮助。
- en: We started with what AI is and its three major types. We took a look at the
    factors that are responsible for the AI explosion that is happening around us.
    We then took a quick tour of several components of ML and how they contribute
    to an ML project. We saw what DL is and how AI, ML, and DL are connected.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从人工智能（AI）是什么以及它的三种主要类型开始。我们观察了推动周围AI爆炸性增长的因素。接着，我们简要了解了机器学习（ML）的几个组件以及它们如何在ML项目中发挥作用。我们看到了什么是深度学习（DL），以及AI、ML和DL是如何相互关联的。
- en: Toward the very end of this chapter, we saw some examples where AI is being
    merged with web technologies to make intelligent applications that promise to
    solve complex problems. Behind almost all of the AI-enabled applications sits
    DL.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后，我们看到了几个例子，其中AI与Web技术相结合，创建智能应用，承诺解决复杂问题。几乎所有支持AI的应用背后都有深度学习（DL）的身影。
- en: In the next chapters, we are going to leverage DL to make smart web applications.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将利用深度学习（DL）来构建智能网页应用。
