- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Introducing 3D Computer Vision and Geometry
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍3D计算机视觉与几何学
- en: In this chapter, we will learn about some basic concepts of 3D computer vision
    and geometry that will be especially useful for later chapters in this book. We
    will start by discussing what rendering, rasterization, and shading are. We will
    go through different lighting models and shading models, such as point light sources,
    directional light sources, ambient lighting, diffusion, highlights, and shininess.
    We will go through a coding example for rendering a mesh model using different
    lighting models and parameters.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习一些3D计算机视觉和几何的基本概念，这些概念将特别有助于本书后续章节的内容。我们将从讨论渲染、光栅化和着色开始。我们将讲解不同的光照模型和着色模型，如点光源、方向光源、环境光、漫反射、高光和光泽度。我们将通过一个示例代码，展示如何使用不同的光照模型和参数来渲染网格模型。
- en: We will then learn how to use PyTorch for solving optimization problems. Particularly,
    we will go through stochastic gradient descent over heterogeneous mini-batches,
    which becomes possible by using PyTorch3D. We will also learn about different
    formats for mini-batches in PyTorch3D, including the list, padded, and packed
    formats, and learn how to convert between the different formats.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将学习如何使用PyTorch来解决优化问题。特别是，我们将学习如何使用PyTorch3D进行异构小批量的随机梯度下降。我们还将学习PyTorch3D中小批量的不同格式，包括列表格式、填充格式和打包格式，并学习如何在这些格式之间转换。
- en: In the last part of the chapter, we will discuss some frequently used rotation
    representations and how to convert between these representations.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后部分，我们将讨论一些常用的旋转表示方法，以及如何在这些表示之间进行转换。
- en: 'In this chapter, we’re going to cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Exploring the basic concepts of rendering, rasterization, and shading
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索渲染、光栅化和着色的基本概念
- en: Understanding the Lambertian shading and Phong shading models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解Lambertian着色模型和Phong着色模型
- en: How to define a PyTorch tensor and optimize the tensor using an optimizer
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何定义PyTorch张量，并使用优化器优化张量
- en: How to define a mini-batch and heterogeneous mini-batch and packed and padded
    tensors
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何定义小批量、异构小批量以及打包和填充张量
- en: Rotations and different ways to describe rotations
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旋转及描述旋转的不同方法
- en: Exponential mapping and log mapping in the SE(3) space
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在SE(3)空间中的指数映射和对数映射
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: To run the example code snippets in this book, the readers need to have a computer,
    ideally with a GPU. However, running the code snippets only with CPUs is not impossible.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行本书中的示例代码片段，读者需要拥有一台计算机，最好配备GPU。然而，仅使用CPU运行代码片段也是可能的。
- en: 'The recommended computer configuration includes the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐的计算机配置包括以下内容：
- en: A modern GPU – for example, the Nvidia GTX series or RTX series with at least
    8 GB of memory
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台现代GPU——例如，具有至少8GB内存的Nvidia GTX系列或RTX系列
- en: Python 3
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3
- en: PyTorch library and PyTorch3D libraries
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch库和PyTorch3D库
- en: The code snippets with this chapter can be found at [https://github.com/PacktPublishing/3D-Deep-Learning-with-Python.](https://github.com/PacktPublishing/3D-Deep-Learning-with-Python)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的代码片段可以在[https://github.com/PacktPublishing/3D-Deep-Learning-with-Python.](https://github.com/PacktPublishing/3D-Deep-Learning-with-Python)找到
- en: Exploring the basic concepts of rendering, rasterization, and shading
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索渲染、光栅化和着色的基本概念
- en: '**Rendering** is a process that takes 3D data models of the world around our
    camera as input and output images. It is an approximation to the physical process
    where images are formed in our camera in the real world. Typically, the 3D data
    models are meshes. In this case, rendering is usually done using ray tracing:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**渲染**是一个过程，它将周围世界的3D数据模型作为输入，并输出图像。这是对现实世界中相机形成图像的物理过程的近似。通常，3D数据模型是网格。在这种情况下，渲染通常通过光线追踪完成：'
- en: '![Figure 2.1: Rendering by ray tracing (rays are generated from camera origins
    and go through the image pixels for finding relevant mesh faces) ](img/B18217_02_001.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1：光线追踪渲染（光线从相机原点发射，并通过图像像素查找相关网格面）](img/B18217_02_001.jpg)'
- en: 'Figure 2.1: Rendering by ray tracing (rays are generated from camera origins
    and go through the image pixels for finding relevant mesh faces)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1：光线追踪渲染（光线从相机原点发射，并通过图像像素查找相关网格面）
- en: An example of ray tracing processing is shown in *Figure 2**.1*. In the example,
    the world model contains one 3D sphere, which is represented by a mesh model.
    To form the image of the 3D sphere, for each image pixel, we generate one ray,
    starting from the camera origin and going through the image pixel. If one ray
    intersects with one mesh face, then we know the mesh face can project its color
    to the image pixel. We also need to trace the depth of each intersection because
    a face with a smaller depth would occlude faces with larger depths.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 光线追踪处理的示例如 *图 2.1* 所示。在该示例中，世界模型包含一个 3D 球体，该球体由一个网格模型表示。为了形成 3D 球体的图像，对于每个图像像素，我们生成一条射线，从相机原点出发并穿过图像像素。如果一条射线与一个网格面相交，那么我们知道该网格面可以将其颜色投射到图像像素上。我们还需要追踪每次相交的深度，因为具有较小深度的面会遮挡具有较大深度的面。
- en: Thus, the process of rendering can usually be divided into two stages – rasterization
    and shading. The ray tracing process is a typical rasterization process – that
    is, the process of finding relevant geometric objects for each image pixel. Shading
    is the process of taking the outputs of the rasterization and computing the pixel
    value for each image pixel.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，渲染过程通常可以分为两个阶段——光栅化和着色。光线追踪过程是典型的光栅化过程——即为每个图像像素找到相关几何对象的过程。着色是根据光栅化的输出计算每个图像像素的像素值的过程。
- en: 'The `pytorch3d.renderer.mesh.rasterize_meshes.rasterize_meshes` function in
    PyTorch3D usually computes the following four things for each image pixel:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch3D 中的 `pytorch3d.renderer.mesh.rasterize_meshes.rasterize_meshes` 函数通常为每个图像像素计算以下四个内容：
- en: '`pix_to_face` is a list of face indices that the ray may intersect.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pix_to_face` 是一个包含射线可能与之相交的面索引的列表。'
- en: '`zbuf` is a list of depth values of these faces.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zbuf` 是一个包含这些面深度值的列表。'
- en: '`bary_coords` is a list of barycentric coordinates of the intersection point
    of each face and the ray.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bary_coords` 是一个包含每个面与射线交点的重心坐标的列表。'
- en: '`pix_dists` is a list of signed distances between pixels (*x* and *y*) and
    the nearest point on all the faces where the ray intersects. The values of this
    list can take negative values since it contains signed distances.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pix_dists` 是一个包含像素（*x* 和 *y*）与所有相交面的最近点之间符号距离的列表。由于它包含符号距离，因此该列表的值可以为负值。'
- en: Note that usually, one face with the smallest depth would occlude all the mesh
    faces with larger depths. Thus, if all we need is the rendered image, then all
    we need in this list is the face with the smallest depth. However, with the more
    advanced setting of differentiable rendering (which we will cover in later chapters
    of this book), the pixel colors are usually fused from multiple mesh faces.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，通常具有最小深度的一个面会遮挡所有深度更大的网格面。因此，如果我们只需要渲染图像，那么这个列表中只需要包含最小深度的面。然而，在更高级的可微渲染设置下（我们将在本书后面的章节中讨论），像素颜色通常是从多个网格面融合而来的。
- en: Understanding barycentric coordinates
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解重心坐标
- en: 'For each point coplanar with a mesh face, the coordinates of the point can
    always be written as a linear combination of the coordinates of the three vertices
    of the mesh face. For example, as shown in the following diagram, the point p
    can be written as ![](img/01.png), where *A*, *B*, and *C* are the coordinates
    of the three vertices of the mesh face. Thus, we can represent each such point
    with the coefficients u, v, and w. This representation is called the barycentric
    coordinates of the point. For point lays within the mesh face triangle, ![](img/02.png)
    and all u,v,w are positive numbers. Since barycentric coordinates define any point
    inside a face as a function of face vertices, we can use the same coefficients
    to interpolate other properties across the whole face as a function of the properties
    defined at the vertices of the face. For example, we can use it for shading as
    shown in *Figure 2**.2*:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于与网格面共面的每个点，该点的坐标总可以表示为网格面三个顶点坐标的线性组合。例如，如下图所示，点 p 可以表示为 ![](img/01.png)，其中
    *A*、*B* 和 *C* 是网格面三个顶点的坐标。因此，我们可以用系数 u、v 和 w 来表示每个这样的点。这个表示方法称为该点的重心坐标。如果点位于网格面三角形内，![](img/02.png)，且所有
    u、v、w 均为正数。由于重心坐标将面内的任何点定义为面顶点的函数，我们可以使用相同的系数根据在面顶点处定义的属性在整个面上插值其他属性。例如，我们可以将其用于着色，如
    *图 2.2* 所示：
- en: '![Figure 2.2: Definition of the barycentric coordinate system ](img/B18217_02_002.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.2：重心坐标系的定义](img/B18217_02_002.png)'
- en: 'Figure 2.2: Definition of the barycentric coordinate system'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2：重心坐标系的定义
- en: Once we have a list of the `pix_to_face`, `zbuf`, `bary_coords`, and `dists`
    values, a shading process would mimic the physical process of image formation
    as in the real world. Thus, we are going to discuss several physical models for
    color formation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了`pix_to_face`、`zbuf`、`bary_coords`和`dists`值的列表，着色过程就会模拟现实世界中图像形成的物理过程。因此，我们将讨论几种颜色形成的物理模型。
- en: Light source models
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 光源模型
- en: 'Light propagation in the real world can be a sophisticated process. Several
    approximations of light sources are usually used in shading to reduce computational
    costs:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界中的光传播可能是一个复杂的过程。为了减少计算成本，着色中通常会使用几种光源的近似模型：
- en: The first assumption is ambient lighting, where we assume that there is some
    background light radiation after sufficient reflections, such that they usually
    come from all directions with almost the same amplitude at all image pixels.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个假设是环境光照，我们假设在足够反射后会有一些背景光辐射，这些光通常从各个方向发出，且所有图像像素的振幅几乎相同。
- en: Another assumption that we usually use is that some light sources can be considered
    point light sources. A point light source radiates lights from one single point
    and the radiations at all directions have the same color and amplitude.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通常使用的另一个假设是，某些光源可以被视为点光源。点光源从一个单一的点发出光线，所有方向的辐射具有相同的颜色和振幅。
- en: A third assumption that we usually use is that some light sources can be modeled
    as directional light sources. In such a case, the light directions from the light
    source are identical at all the 3D spatial locations. Directional lighting is
    a good approximation model for cases where the light sources are far away from
    the rendered objects – for example, sunlight.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通常使用的第三个假设是，某些光源可以被建模为定向光源。在这种情况下，光源发出的光线在所有三维空间位置上的方向是相同的。定向光照是当光源远离渲染物体时的良好近似模型——例如，阳光。
- en: Understanding the Lambertian shading model
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解Lambertian着色模型
- en: 'The first physical model that we will discuss is Lambert’s cosine law. Lambertian
    surfaces are types of objects that are not shiny at all, such as paper, unfinished
    wood, and unpolished stones:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论的第一个物理模型是Lambert的余弦定律。Lambertian表面是指那些完全不光亮的物体类型，如纸张、未加工的木材和未抛光的石头：
- en: '![Figure 2.3: Light diffusion on Lambertian surfaces ](img/B18217_02_003.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.3：光在Lambertian表面上的扩散](img/B18217_02_003.jpg)'
- en: 'Figure 2.3: Light diffusion on Lambertian surfaces'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3：光在Lambertian表面上的扩散
- en: '*Figure 2**.3* shows an example of how lights diffuse on a Lambertian surface.
    One basic idea of the Lambertian cosine law is that for Lambertian surfaces, the
    amplitude of the reflected light does not depend on the viewer’s angle, but only
    depends on the angle ![](img/03.png) between the surface normal and the direction
    of the incident light. More precisely, the intensity of the reflected light ![](img/04.png)
    is as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.3* 显示了光如何在Lambertian表面上扩散的示例。Lambertian余弦定律的一个基本思想是，对于Lambertian表面，反射光的振幅不依赖于观察者的角度，而仅仅依赖于表面法线与入射光方向之间的角度
    ![](img/03.png)。更准确地说，反射光的强度 ![](img/04.png) 如下：'
- en: '![](img/05.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/05.png)'
- en: 'Here, ![](img/06.png) is the material’s reflected coefficient and ![](img/07.png)
    is the amplitude of the incident light. If we further consider the ambient light,
    the amplitude of the reflected light is as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/06.png) 是材料的反射系数，![](img/07.png) 是入射光的振幅。如果我们进一步考虑环境光，反射光的振幅如下：
- en: '![](img/08.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/08.png)'
- en: Here, ![](img/09.png) is the amplitude of the ambient light.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/09.png) 是环境光的振幅。
- en: Understanding the Phong lighting model
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解Phong光照模型
- en: 'For shiny surfaces, such as polished tile floors and glossy paint, the reflected
    light also contains a highlight component. The Phong lighting model is a frequently
    used model for these glossy components:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于光滑的表面，如抛光瓷砖地板和光泽涂料，反射光也包含一个高光成分。Phong光照模型是处理这些光泽成分的常用模型：
- en: '![Figure 2.4: The Phong lighting model ](img/B18217_02_004.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.4：Phong光照模型](img/B18217_02_004.jpg)'
- en: 'Figure 2.4: The Phong lighting model'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4：Phong光照模型
- en: An example of the Phong lighting model is shown in *Figure 2**.4*. One basic
    principle of the Phong lighting model is that the shiny light component should
    be strongest in the direction of reflection of the incoming light. The component
    would become weaker as the angle ![](img/10.png) between the direction of reflection
    and the viewing angle becomes larger.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Phong 光照模型的示例如*图 2**.4*所示。Phong 光照模型的一个基本原理是，光泽光成分应该在入射光反射方向上最强。随着反射方向和观察角度之间的角度
    ![](img/10.png) 变大，光泽成分会变弱。
- en: 'More precisely, the amplitude of the shiny light component ![](img/101.png)
    is equal to the following:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 更准确地说，光泽光组件的振幅 ![](img/101.png) 等于以下公式：
- en: '![](img/11.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/11.png)'
- en: Here, the exponent ![](img/12.png) is a parameter of the model for controlling
    the speed at which the shiny components attenuate when the viewing angle is away
    from the direction of reflection.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，指数 ![](img/12.png) 是模型的一个参数，用于控制光泽成分在观察角度偏离反射方向时衰减的速度。
- en: 'Finally, if we consider all three major components – ambient lighting, diffusion,
    and highlights – the final equation for the amplitude of light is as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果我们考虑所有三大主要成分——环境光、漫反射和高光——那么光的最终振幅方程如下：
- en: '![](img/13.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/13.png)'
- en: 'Note that the preceding equation applies to each color component. In other
    words, we will have one of these equations for each color channel (red, green,
    and blue) with a distinct set of ![](img/14.png) values:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前述方程适用于每个颜色成分。换句话说，我们会为每个颜色通道（红色、绿色和蓝色）分别有一个这样的方程，并且有一组独特的 ![](img/14.png)
    值：
- en: Now, we have learned about the basic concepts of rendering, rasterization, and
    rendering. We have also learned about the different light source models and shading
    models. We are ready to perform some coding exercises to use these light sources
    and shading models.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经了解了渲染、光栅化和渲染的基本概念。我们还学习了不同的光源模型和着色模型。我们已经准备好进行一些编码练习，利用这些光源和着色模型。
- en: Coding exercises for 3D rendering
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3D 渲染的编码练习
- en: 'In this section, we will look at a concrete coding exercise using PyTorch3D
    for rendering a mesh model. We are going to learn how to define a camera model
    and how to define a light source in PyTorch3D. We will also learn how to change
    the incoming light components and material properties so that more realistic images
    can be rendered by controlling the three light components (ambient, diffusion,
    and glossy):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过使用 PyTorch3D 渲染网格模型来进行一个具体的编码练习。我们将学习如何定义摄像机模型以及如何在 PyTorch3D 中定义光源。我们还将学习如何更改输入的光成分和材质属性，以便通过控制三种光成分（环境光、漫反射和高光）渲染出更逼真的图像：
- en: 'First, we need to import all the Python modules that we need:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要导入所有需要的 Python 模块：
- en: '[PRE0]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we need to load the mesh that we are going to use. The `cow.obj` file
    contains a mesh model for a toy cow object:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们需要加载将要使用的网格。`cow.obj` 文件包含一个玩具牛对象的网格模型：
- en: '[PRE1]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will define the cameras and light sources next. We use the `look_at_view_transform`
    function to map easy-to-understand parameters, such as the distance from the camera,
    elevation angle, and azimuth angle to obtain the rotation (R) and translation
    (T) matrices. The `R` and `T` variables define where we are going to place our
    camera. The `lights` variable is a point light source placed at `[0.0, 0.0, -3.0]`
    as its location:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将定义摄像机和光源。我们使用 `look_at_view_transform` 函数来映射易于理解的参数，如摄像机与物体的距离、俯仰角度和方位角度，从而得到旋转（R）和位移（T）矩阵。`R`
    和 `T` 变量定义了我们将如何放置摄像机。`lights` 变量是一个放置在 `[0.0, 0.0, -3.0]` 位置的点光源：
- en: '[PRE2]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will define a `renderer` variable of the `MeshRenderer` type. A `renderer`
    variable is a callable object, which can take a mesh as input and output the rendered
    images. Note that the renderer takes two inputs in its initialization – one rasterizer
    and one shader. PyTorch3D has defined several different types of rasterizers and
    shaders. Here, we are going to use `MeshRasterizer` and `HardPhongShader`. Note
    that we can also specify the setting of the rasterizer. `image_size` is equal
    to `512` here, which implies the rendered images would be 512 x 512 pixels. `blur_radius`
    is set to `0` and `faces_per_pixel` is set to `1`. The `blur_radius` and `faces_per_pixel`
    settings are the most useful for differentiable rendering, where `blur_radius`
    should be greater than `0` and `faces_per_pixel` should be greater than `1`:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将定义一个`renderer`变量，它是`MeshRenderer`类型的。`renderer`变量是一个可调用对象，可以接受网格作为输入并输出渲染图像。注意，渲染器的初始化需要两个输入——一个光栅化器和一个着色器。PyTorch3D已经定义了几种不同类型的光栅化器和着色器。在这里，我们将使用`MeshRasterizer`和`HardPhongShader`。值得注意的是，我们还可以指定光栅化器的设置。`image_size`设置为`512`，这意味着渲染的图像将是512
    x 512像素。`blur_radius`设置为`0`，`faces_per_pixel`设置为`1`。`blur_radius`和`faces_per_pixel`的设置对于可微分渲染非常有用，其中`blur_radius`应该大于`0`，而`faces_per_pixel`应该大于`1`：
- en: '[PRE3]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We are therefore ready to run our first rendering results by calling the renderer
    and passing the mesh model. The rendered image is shown in *Figure 2**.5*:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我们已经准备好通过调用渲染器并传递网格模型来运行第一次渲染结果。渲染图像如*图 2.5*所示：
- en: '[PRE4]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Figure 2.5: The rendered image when the light source is placed in front ](img/B18217_02_005.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.5：光源放置在前方时的渲染图像](img/B18217_02_005.jpg)'
- en: 'Figure 2.5: The rendered image when the light source is placed in front'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5：光源放置在前方时的渲染图像
- en: 'Next, we will change the location of the light source to the back of the mesh
    and see what will happen. The rendered image is shown in *Figure 2**.6*. In this
    case, the light from the point light source cannot intersect with any mesh faces
    that are facing us. Thus, all the colors that we can observe here are due to ambient
    light:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将把光源的位置改变到网格的后面，看看会发生什么。渲染图像如*图 2.6*所示。在这种情况下，点光源发出的光无法与任何朝向我们的网格面相交。因此，我们能观察到的所有颜色都是由于环境光造成的：
- en: '[PRE5]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Figure 2.6: The rendered image when the light source is placed behind the
    toy cow ](img/B18217_02_006.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.6：光源放置在玩具牛后方时的渲染图像](img/B18217_02_006.jpg)'
- en: 'Figure 2.6: The rendered image when the light source is placed behind the toy
    cow'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6：光源放置在玩具牛后方时的渲染图像
- en: In the next experiment, we are going to define a `materials` data structure.
    Here, we change the configuration so that the ambient components are close to
    0 (indeed, being `0.01`). Because the point light source is behind the object
    and the ambient light is also turned off, the rendered object does not reflect
    any light now. The rendered image is shown in *Figure 2**.7:*
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在接下来的实验中，我们将定义一个`materials`数据结构。在这里，我们更改配置，使得环境光成分接近0（实际上为`0.01`）。由于点光源位于物体后面，且环境光也被关闭，渲染的物体现在不再反射任何光。渲染图像如*图
    2.7*所示：
- en: '[PRE6]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![Figure 2.7: The rendered image without ambient light and the point light
    source behind the toy cow ](img/B18217_02_007.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.7：没有环境光且点光源位于玩具牛后方的渲染图像](img/B18217_02_007.jpg)'
- en: 'Figure 2.7: The rendered image without ambient light and the point light source
    behind the toy cow'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7：没有环境光且点光源位于玩具牛后方的渲染图像
- en: 'In the next experiment, we will rotate the camera again and redefine the light
    source location so that the light can shine on the cow’s face. Note that when
    we define the material, we set `shininess` to `10.0`. This `shininess` parameter
    is precisely the `p` parameter in the Phong lighting model. `specular_color` is
    `[0.0, 1.0, 0.0]`, which implies that the surface is shiny mainly in the green
    component. The rendered results are shown in *Figure 2**.8*:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在接下来的实验中，我们将再次旋转相机，并重新定义光源位置，使光线能够照射到牛的面部。请注意，在定义材质时，我们将`shininess`设置为`10.0`。这个`shininess`参数正是Phong光照模型中的`p`参数。`specular_color`是`[0.0,
    1.0, 0.0]`，这意味着表面在绿色成分上光泽最强。渲染结果如*图 2.8*所示：
- en: '[PRE7]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Figure 2.8: The rendered image with specular lighting components ](img/B18217_02_008.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.8：带有镜面光照成分的渲染图像](img/B18217_02_008.jpg)'
- en: 'Figure 2.8: The rendered image with specular lighting components'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.8：带有镜面光照成分的渲染图像
- en: 'In the next experiment, we are going to change `specular_color` to `red` and
    increase the `shininess` value. The results are shown in *Figure 2**.9*:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个实验中，我们将把`specular_color`改为`red`并增加`shininess`值。结果见*图 2.9*：
- en: '[PRE8]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![Figure 2.9: The rendered image with a red specular color ](img/B18217_02_009.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.9：带有红色高光颜色的渲染图像](img/B18217_02_009.jpg)'
- en: 'Figure 2.9: The rendered image with a red specular color'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9：带有红色高光颜色的渲染图像
- en: 'Finally, we turn off the shininess and the results are shown in *Figure 2**.10*:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们关闭了高光效果，结果见*图 2.10*：
- en: '[PRE9]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Figure 2.10: The rendered image without specular components ](img/B18217_02_010.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.10：没有高光成分的渲染图像](img/B18217_02_010.jpg)'
- en: 'Figure 2.10: The rendered image without specular components'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10：没有高光成分的渲染图像
- en: In the first part of this chapter, we mainly discussed rendering and shading,
    which are super important for 3D computer vision. Next, we will discuss another
    very important topic for 3D deep learning, which is the heterogeneous batch issue
    for optimization.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的第一部分，我们主要讨论了渲染和阴影，它们对3D计算机视觉至关重要。接下来，我们将讨论另一个对3D深度学习非常重要的话题——优化中的异构批次问题。
- en: Using PyTorch3D heterogeneous batches and PyTorch optimizers
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyTorch3D异构批次和PyTorch优化器
- en: In this section, we are going to learn how to use the PyTorch optimizer on PyTorch3D
    heterogeneous mini-batches. In deep learning, we are usually given a list of data
    examples, such as the following ones – ![](img/15.png).. Here, ![](img/16.png)
    are the observations and ![](img/17.png) are the prediction values. For example,
    ![](img/18.png) may be some images and ![](img/20.png) the ground-truth classification
    results – for example, “cat” or “dog”. A deep neural network is then trained so
    that the outputs of the neural networks are as close to ![](img/21.png) as possible.
    Usually, a loss function between the neural network outputs and ![](img/22.png)
    is defined so that the loss function values decrease as the neural network outputs
    become closer to ![](img/22.png).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中，我们将学习如何在PyTorch3D异构小批次上使用PyTorch优化器。在深度学习中，我们通常会获得一个数据示例列表，如下所示– ![](img/15.png)..
    这里，![](img/16.png)是观察值，![](img/17.png)是预测值。例如，![](img/18.png)可能是一些图像，而![](img/20.png)是实际的分类结果——例如，“猫”或“狗”。然后，训练一个深度神经网络，使得神经网络的输出尽可能接近![](img/21.png)。通常，定义一个神经网络输出与![](img/22.png)之间的损失函数，使得损失函数值随着神经网络输出接近![](img/22.png)而减小。
- en: 'Thus, training a deep learning network is usually done by minimizing the loss
    function that is evaluated on all training data examples, ![](img/23.png) and![](img/24.png).
    A straightforward method used in many optimization algorithms is computing the
    gradients first, as shown in the following equation, and then modifying the parameters
    of the neural network along the direction of the negative gradient. In the equation,
    *f* represents the neural network that takes ![](img/25.png) as its input and
    has parameters Ɵ; loss is the loss function between the neural network outputs
    and the ground-truth prediction![](img/26.png):'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，训练深度学习网络通常是通过最小化在所有训练数据示例上评估的损失函数来完成的，![](img/23.png) 和![](img/24.png)。许多优化算法中常用的一种直接方法是首先计算梯度，如下方程所示，然后沿负梯度方向修改神经网络的参数。在方程中，*f*代表神经网络，它以![](img/25.png)为输入，参数为Ɵ；loss是神经网络输出与真实预测![](img/26.png)之间的损失函数：
- en: '![](img/27.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/27.jpg)'
- en: 'However, computing this gradient is expensive, as the computational cost is
    proportional to the size of the training dataset. In reality, a **Stochastic Gradient
    Descent** (**SGD**) algorithm is used instead of the original gradient descent
    algorithm. In the SGD algorithm, the descent direction is computed as in the following
    equation:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，计算这个梯度是昂贵的，因为计算成本与训练数据集的大小成正比。实际上，**随机梯度下降**（**SGD**）算法取代了原始的梯度下降算法。在SGD算法中，下降方向按照以下方程计算：
- en: '![](img/28.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/28.png)'
- en: In the equation, the so-called mini-batch D is a small subset of all the training
    data examples. The mini-batch D is randomly sampled from the whole training data
    examples in each iteration. The SGD algorithm has a much lower computational cost
    than the gradient descent algorithm. Due to the law of large numbers, the computed
    descent directions in SGD are approximately close to the gradient descent directions.
    It is also widely believed that SGD introduces certain implicit regularization,
    which may contribute to the nice generalization properties of deep learning. The
    method for choosing the size of the mini-batch is an important hyperparameter
    that needs to be considered carefully. Nevertheless, the SGD algorithm and its
    variants have been the methods of choice for training deep learning models.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方程中，所谓的小批量D是所有训练数据示例的一个小子集。小批量D在每次迭代中从整个训练数据示例中随机抽样。SGD算法的计算成本远低于梯度下降算法。根据大数法则，SGD中计算出的下降方向大致接近梯度下降的方向。普遍认为，SGD引入了某种隐式正则化，这可能有助于深度学习模型的良好泛化性能。选择小批量大小的方法是一个需要认真考虑的重要超参数。尽管如此，SGD算法及其变种仍然是训练深度学习模型的首选方法。
- en: For many data types, such as images, the data can easily be made homogeneous.
    We can form a mini-batch of images all with the same widths, heights, and channels.
    For example, a mini-batch of eight images with three channels (the three colors
    red, green, and blue), a height of 256, and a width of 256 can be made into a
    PyTorch tensor with the dimensions 8 x 3 x 256 x 256\. Usually, the first dimension
    of the tensor represents the data sample indices within the mini-batch. Usually,
    computations on this kind of homogeneous data can be done efficiently using GPUs.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多数据类型，例如图像，数据可以很容易地变得同质化。我们可以形成一个小批量的图像，所有图像具有相同的宽度、高度和通道。例如，一个包含三通道（红色、绿色和蓝色）、高度为256、宽度为256的八张图像的小批量，可以构成一个PyTorch张量，维度为8
    x 3 x 256 x 256。通常，张量的第一维表示小批量中的数据样本索引。通常，对这种同质数据的计算可以高效地使用GPU完成。
- en: On the other hand, 3D data is usually heterogeneous. For example, meshes within
    one mini-batch may contain different numbers of vertices and faces. Processing
    this heterogeneous data on GPUs efficiently is not a trivial issue. Coding for
    the heterogeneous mini-batch processing can also be tedious. Luckily, PyTorch3D
    has the capacity to handle heterogeneous mini-batches very efficiently. We will
    go over a coding exercise involving these PyTorch3D capacities in the next section.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，3D数据通常是异构的。例如，一个小批量中的网格可能包含不同数量的顶点和面。高效地在GPU上处理这种异构数据并不是一件简单的事。异构小批量处理的编程也可能非常繁琐。幸运的是，PyTorch3D具备非常高效地处理异构小批量的能力。我们将在下一节中讨论涉及这些PyTorch3D能力的编程练习。
- en: A coding exercise for a heterogeneous mini-batch
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个关于异构小批量的编程练习
- en: In this section, we are going to learn how to use the PyTorch optimizer and
    PyTorch3D heterogeneous mini-batch capacities by looking at a toy example. In
    this example, we will consider a problem where a depth camera is placed at an
    unknown location and we want to estimate the unknown location using the sensing
    results of the camera. To simplify the problem, we assume that the orientation
    of the camera is known and the only unknown is the 3D displacement.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过一个玩具示例来学习如何使用PyTorch优化器和PyTorch3D的异构小批量功能。在这个示例中，我们将考虑一个问题：一个深度摄像头被放置在一个未知位置，我们希望利用摄像头的感知结果估计这个未知位置。为了简化问题，我们假设摄像头的方向已知，唯一未知的是3D位移。
- en: 'More specifically, we assume that the camera observes three objects in the
    scene and we know the ground-truth mesh models of the three objects. Let us look
    at the code using PyTorch and PyTorch3D to solve the problem as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，我们假设摄像头观察到场景中的三个物体，并且我们知道这三个物体的真实网格模型。让我们看一下使用PyTorch和PyTorch3D解决该问题的代码，如下所示：
- en: 'In the first step, we are going to import all the packages that we are going
    to use:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一步中，我们将导入所有我们将要使用的包：
- en: '[PRE10]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the next step, we will define a `torch` device using either a CPU or CUDA:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一步中，我们将使用CPU或CUDA定义一个`torch`设备：
- en: '[PRE11]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The mesh models that you are going to use in this toy example are included
    in the code repository and are under the `data` subfolder. We are going to use
    three mesh models contained in the `cube.obj`, `diamond.obj` and `dodecahedron.obj`
    files. In the following code snippet, we are using the `Open3D` library to load
    these mesh models and visualize them:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将在这个示例中使用的网格模型已包含在代码库中，并位于`data`子文件夹下。我们将使用包含在`cube.obj`、`diamond.obj`和`dodecahedron.obj`文件中的三个网格模型。在以下代码片段中，我们使用`Open3D`库加载这些网格模型并进行可视化：
- en: '[PRE12]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next, we are going to use PyTorch3D to load the same meshes and build a list
    of meshes, which is the `mesh_list` variable:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用PyTorch3D加载相同的网格并构建一个网格列表，即`mesh_list`变量：
- en: '[PRE13]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Finally, we can create a PyTorch3D mini-batch of meshes by using the `join_meshes_as_batch`
    PyTorch3D function. The function takes a list of meshes and returns a mini-batch
    of meshes:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以通过使用`join_meshes_as_batch` PyTorch3D函数创建一个PyTorch3D迷你批次的网格。该函数接受一个网格列表并返回一个迷你批次的网格：
- en: '[PRE14]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In each PyTorch3D mini-batch, there are three ways to represent vertices and
    faces:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个PyTorch3D迷你批次中，有三种方式来表示顶点和面：
- en: '**List format**: The vertices are represented by a list of tensors where each
    tensor represents the vertices or faces of one mesh within the mini-batch.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**列表格式**：顶点由一个张量列表表示，每个张量表示一个迷你批次中一个网格的顶点或面。'
- en: '**Padded format**: All the vertices are represented by one tensor and the data
    of the smaller meshes are zero-padded so that all the meshes now have the same
    numbers of vertices and faces.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**填充格式**：所有顶点由一个张量表示，小的网格数据通过零填充，使得所有网格现在具有相同数量的顶点和面。'
- en: '**Packed format**: All the vertices or faces are packed into one tensor. For
    each vertex or face, which mesh it belongs to is tracked internally.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**打包格式**：所有顶点或面都打包到一个张量中。对于每个顶点或面，内部会跟踪它属于哪个网格。'
- en: The three representations all have their pros and cons. Nevertheless, the formats
    can be converted between each other efficiently by using the PyTorch3D API.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这三种表示方法各有优缺点。然而，可以通过使用PyTorch3D API高效地在它们之间进行转换。
- en: 'The next code snippet shows an example of how to return vertices and faces
    in a list format from a mini-batch:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一个代码片段展示了如何从迷你批次中返回列表格式的顶点和面：
- en: '[PRE15]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To return vertices and faces in the padded format, we can use the following
    PyTorch3D API:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要返回填充格式的顶点和面，我们可以使用以下PyTorch3D API：
- en: '[PRE16]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To get vertices and faces in the packed format, we can use the following code
    snippet:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要以打包格式获取顶点和面，我们可以使用以下代码片段：
- en: '[PRE17]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'In this coding example, we consider the `mesh_batch` variable as the ground-truth
    mesh model for the three objects. We will then simulate a noisy and displaced
    version of the three meshes. In the first step, we want to clone the ground truth
    mesh models:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个编码示例中，我们将`mesh_batch`变量视为三个物体的真实网格模型。接下来，我们将模拟这三个网格的一个有噪声并发生位移的版本。在第一步，我们要克隆真实网格模型：
- en: '[PRE18]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We then define a `motion_gt` variable to represent the displacement between
    the camera location and the origin:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们定义一个`motion_gt`变量来表示相机位置与原点之间的位移：
- en: '[PRE19]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To simulate the noisy depth camera observations, we generate some random Gaussian
    noise with a mean equal to `motion_gt`. The noises are added to `mesh_batch_noisy`
    using the `offset_verts` PyTorch3D function:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了模拟有噪声的深度相机观测，我们生成一些均值为`motion_gt`的随机高斯噪声。这些噪声通过`offset_verts` PyTorch3D函数被加到`mesh_batch_noisy`中：
- en: '[PRE20]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To estimate the unknown displacement between the camera and the origin, we
    will formulate an optimization problem. First, we will define the `motion_estimate`
    optimization variable. The `torch.zeros` function will create an all zero PyTorch
    tensor. Note that we set `requires_grad` to `true`. What that means is that when
    we run gradient backpropagation from the `loss` function, we want the gradient
    for this variable to be automatically computed by PyTorch for us:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了估计相机与原点之间的未知位移，我们将构建一个优化问题。首先，我们将定义`motion_estimate`优化变量。`torch.zeros`函数将创建一个全零的PyTorch张量。请注意，我们将`requires_grad`设置为`true`。这意味着当我们从`loss`函数运行梯度反向传播时，我们希望PyTorch自动为此变量计算梯度：
- en: '[PRE21]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next, we are going to define a PyTorch optimizer with a learning rate of `0.1`.
    By passing a list of variables to the optimizer, we specify the optimization variables
    for this optimization problem. Here, the optimization variable is the `motion_estimate`
    variable:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一个学习率为`0.1`的PyTorch优化器。通过将变量列表传递给优化器，我们指定了该优化问题的优化变量。在这里，优化变量是`motion_estimate`变量：
- en: '[PRE22]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The major optimization procedure is then shown as follows. Basically, we run
    the stochastic gradient descent for 200 iterations. The resulting `motion_estimate`
    should be very close to the ground truth after the 200 iterations.
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主要的优化过程如下所示。基本上，我们运行随机梯度下降200次迭代。经过200次迭代后，得到的`motion_estimate`应该非常接近地面真值。
- en: 'Each optimization iteration can be divided into the following four steps:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 每次优化迭代可以分为以下四个步骤：
- en: In the first step, `optimizer.zero_grad()` resets all the gradient values from
    the values computed in the last iteration to zero.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一步，`optimizer.zero_grad()`将所有梯度值从上一次迭代计算的值重置为零。
- en: In the second step, we compute the `loss` function. Note that PyTorch retains
    a dynamic computational graph. In other words, all the computation procedures
    toward the `loss` function are recorded and will be used in the backpropagation.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二步，我们计算`loss`函数。请注意，PyTorch保留了动态计算图。换句话说，所有计算`loss`函数的步骤都会被记录下来，并在反向传播中使用。
- en: In the third step, `loss.backward()` computes all the gradients from the `loss`
    function to the optimization variables in the PyTorch optimizer.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第三步，`loss.backward()`计算从`loss`函数到PyTorch优化器中的优化变量的所有梯度。
- en: In the fourth and final step, `optimizer.step` moves all the optimization variables
    one step in the direction of decreasing the `loss` function.
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第四个也是最后一步，`optimizer.step`将所有优化变量朝着减小`loss`函数的方向移动一步。
- en: 'In the process of computing the `loss` function, we randomly sample 5,000 points
    from the two meshes and compute their Chamfer distances. The Chamfer distance
    is a distance between two sets of points. We will have a more detailed discussion
    of this distance function in later chapters:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算`loss`函数的过程中，我们从两个网格中随机抽取5,000个点并计算它们的Chamfer距离。Chamfer距离是两组点之间的距离。我们将在后续章节中更详细地讨论这个距离函数：
- en: '[PRE23]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We can check that the optimization process here would converge to the `[3,4,5]`
    ground-truth location very quickly.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以检查优化过程是否会非常快速地收敛到`[3,4,5]`的地面真值位置。
- en: In this coding exercise, we learned how to use heterogenous mini-batches in
    PyTorch3D. Next, we will discuss another important concept in 3D computer vision.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个编程练习中，我们学习了如何在PyTorch3D中使用异构小批量。接下来，我们将讨论3D计算机视觉中的另一个重要概念。
- en: Understanding transformations and rotations
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解变换和旋转
- en: In 3D deep learning and computer vision, we usually need to work with 3D transformations,
    such as rotations and 3D rigid motions. PyTorch3D provides a high-level encapsulation
    of these transformations in its `pytorch3d.transforms.Transform3d` class. One
    advantage of the `Transform3d` class is that it is mini-batch based. Thus, as
    frequently needed in 3D deep learning, it is possible to apply a mini-batch of
    transformations on a mini-batch of meshes only within several lines of code. Another
    advantage of `Transform3d` is that gradient backpropagation can straightforwardly
    pass through `Transform3d`.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在3D深度学习和计算机视觉中，我们通常需要处理3D变换，例如旋转和3D刚性运动。PyTorch3D在其`pytorch3d.transforms.Transform3d`类中对这些变换提供了高层封装。`Transform3d`类的一个优点是它是基于小批量处理的。因此，像3D深度学习中常见的那样，可以仅用几行代码就对一批网格应用小批量变换。`Transform3d`的另一个优点是梯度反向传播可以直接通过`Transform3d`进行。
- en: PyTorch3D also provides many lower-level APIs for computations in the Lie groups
    SO(3) and SE(3). Here, SO(3) denotes the special orthogonal group in 3D and SE(3)
    denotes the special Euclidean group in 3D. Informally speaking, SO(3) denotes
    the set of all the rotation transformations and SE(3) denotes the set of all the
    rigid transformations in 3D. Many low-level APIs on SE(3) and SO(3) are provided
    in PyTorch3D.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch3D还提供了许多用于Lie群SO(3)和SE(3)计算的低级API。这里，SO(3)表示3D中的特殊正交群，而SE(3)表示3D中的特殊欧几里得群。通俗地说，SO(3)表示所有旋转变换的集合，SE(3)表示3D中所有刚性变换的集合。PyTorch3D提供了许多关于SE(3)和SO(3)的低级API。
- en: In 3D computer vision, multiple representations exist for rotations. One representation
    is the rotation matrices ![](img/29.png).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在3D计算机视觉中，旋转有多种表示方法。一种表示方法是旋转矩阵！[](img/29.png)。
- en: In this equation, *x* is a 3D vector and *R* is a 3 x 3 matrix. To be a rotation
    matrix, *R* needs to be an orthogonal matrix and has a determinant of +1\. Thus,
    not all 3 x 3 matrices can be a rotation matrix. The degree of freedom for rotation
    matrices is 3.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方程中，*x*是一个3D向量，*R*是一个3x3矩阵。要成为旋转矩阵，*R*需要是一个正交矩阵，且行列式为+1。因此，并非所有的3x3矩阵都可以是旋转矩阵。旋转矩阵的自由度是3。
- en: A 3D rotation can also be represented by a 3D vector *v,* where the direction
    of *v* is the rotation axis. That is, the rotation would keep *v* fixed and rotate
    all the other things around *v*. It is also conventional to use the amplitude
    of *v* to represent the angle of rotation.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 3D 旋转也可以由一个 3D 向量 *v* 来表示，其中 *v* 的方向是旋转轴。也就是说，旋转会保持 *v* 固定，并围绕 *v* 旋转其他所有物体。通常，*v*
    的幅度用来表示旋转角度。
- en: 'There are various mathematical connections between the two representations
    of rotation. If we consider a constant speed rotation around the axis v, then
    the rotation matrices become a matrix-valued function of the time *t*, *R(t)*.
    In this case, the gradient of *R(t)* is always a skew-symmetric matrix, in the
    form shown in the following equation:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 旋转的两种表示之间有各种数学联系。如果我们考虑围绕轴 *v* 以恒定速度旋转，那么旋转矩阵将成为时间 *t* 的矩阵值函数 *R(t)*。在这种情况下，*R(t)*
    的梯度始终是一个斜对称矩阵，形式如下所示：
- en: '![](img/30.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/30.jpg)'
- en: 'Here, the following applies:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这里适用以下内容：
- en: '![](img/31.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/31.png)'
- en: As we can see from these two equations, the skew-symmetric matrix of the gradient
    is uniquely determined by the vector *v* and vice versa. This mapping from the
    vector *v* to its skew-symmetric matrix form is usually called the hat operator.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 从这两个方程中我们可以看到，梯度的斜对称矩阵是由向量 *v* 唯一确定的，反之亦然。这个从向量 *v* 到其斜对称矩阵形式的映射通常称为帽子运算符。
- en: 'A closed-form formula from the skew-symmetric matrix gradient to the rotation
    matrix exists as follows. The mapping is called the exponential map for ![](img/32.png):'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 从斜对称矩阵梯度到旋转矩阵的闭式公式如下。该映射被称为指数映射，用于 ![](img/32.png)：
- en: '![](img/33.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/33.jpg)'
- en: 'Certainly, the inverse mapping of the exponential map also exists:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，指数映射的逆映射也是存在的：
- en: '![](img/34.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/34.png)'
- en: The mapping is called the logarithmic map for ![](img/35.png).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 该映射被称为对数映射，用于 ![](img/35.png)。
- en: All the hat, inverse hat, exponential, and logarithmic operations have already
    been implemented in PyTorch3D. PyTorch3D also implements many other frequently
    used 3D operations, such as quaternion operations and Euler angles.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的帽子运算符、逆帽子运算符、指数运算和对数运算都已在 PyTorch3D 中实现。PyTorch3D 还实现了许多其他常用的 3D 操作，例如四元数操作和欧拉角。
- en: A coding exercise for transformation and rotation
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转换和旋转的编码练习
- en: 'In this section, we will go through a coding exercise on how to use some of
    PyTorch3D’s low-level APIs:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过一个编码练习来介绍如何使用 PyTorch3D 的一些低级 API：
- en: 'We begin by importing the necessary packages:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先导入必要的包：
- en: '[PRE32]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We then define a PyTorch device using either a CPU or CUDA:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用 CPU 或 CUDA 来定义一个 PyTorch 设备：
- en: '[PRE33]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Next, we will define a mini-batch of four rotations. Here, each rotation is
    represented by one 3D vector. The direction of the vector represents the rotation
    axis and the amplitude of the vector represents the angle of rotation:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一个包含四个旋转的小批次。在这里，每个旋转由一个 3D 向量表示。向量的方向表示旋转轴，向量的幅度表示旋转角度：
- en: '[PRE34]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The shape of `log_rot` is `[4, 3]`, where `4` is the batch size and each rotation
    is represented by a 3D vector. We can use the hat operator in PyTorch3D to convert
    them into the 3 x 3 skew-symmetric matrix representation as follows:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`log_rot` 的形状是 `[4, 3]`，其中 `4` 是批大小，每个旋转由一个 3D 向量表示。我们可以使用 PyTorch3D 中的帽子运算符将它们转换为
    3 x 3 斜对称矩阵表示，代码如下：'
- en: '[PRE35]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The backward conversion from the skew-symmetric matrix form to the 3D vector
    form is also possible using the `hat_inv` operator:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从斜对称矩阵形式到 3D 向量形式的反向转换也可以使用 `hat_inv` 运算符完成：
- en: '[PRE36]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'From the gradient matrix, we can compute the rotation matrix by using the PyTorch3D
    `so3_exp_map` function:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从梯度矩阵，我们可以通过使用 PyTorch3D 的 `so3_exp_map` 函数计算旋转矩阵：
- en: '[PRE37]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The inverse conversation is `so3_log_map`, which would map the rotation matrix
    back to the gradient matrix again:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 反向转换是 `so3_log_map`，它将旋转矩阵映射回梯度矩阵：
- en: '[PRE38]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: These coding exercises show the most frequently used PyTorch3D APIs for transformations
    and rotations. These APIs can be very useful for real-world 3D computer vision
    projects.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这些编码练习展示了 PyTorch3D 在变换和旋转方面最常用的 API。这些 API 对于现实世界中的 3D 计算机视觉项目非常有用。
- en: Summary
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about the basic concepts of rendering, rasterization,
    and shading, including light source models, the Lambertian shading model, and
    the Phong lighting model. We learned how to implement rendering, rasterization,
    and shading using PyTorch3D. We also learned how to change the parameters in the
    rendering process, such as ambient lighting, shininess, and specular colors, and
    how these parameters would affect the rendering results.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了渲染、光栅化和着色的基本概念，包括光源模型、兰伯特着色模型和冯氏光照模型。我们学习了如何使用PyTorch3D实现渲染、光栅化和着色。我们还学习了如何更改渲染过程中诸如环境光、光泽度和镜面反射颜色等参数，并探讨了这些参数如何影响渲染结果。
- en: We then learned how to use the PyTorch optimizer. We went through a coding example,
    where the PyTorch optimizer was used on a PyTorch3D mini-batch. In the last part
    of the chapter, we learned how to use the PyTorch3D APIs for converting between
    the different representations or rotations and transformations.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们学习了如何使用PyTorch优化器。我们通过一个代码示例，展示了如何在PyTorch3D的小批量数据上使用PyTorch优化器。在本章的最后，我们学习了如何使用PyTorch3D的API进行不同表示、旋转和变换之间的转换。
- en: In the next chapter, we will learn some more advanced techniques for using deformable
    mesh models for fitting real-world 3D data.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习一些更高级的技巧，使用可变形网格模型来拟合真实世界的3D数据。
- en: 'PART 2: 3D Deep Learning Using PyTorch3D'
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分：使用PyTorch3D进行3D深度学习
- en: This part will cover some basic 3D computer vision processing using PyTorch3D.
    Implementing these 3D computer vision algorithms may become easier by using PyTorch3D.
    The readers will get a lot of hands-on experience working with meshes, point clouds,
    and fitting from images.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分将介绍一些使用PyTorch3D进行基本3D计算机视觉处理的方法。通过使用PyTorch3D，实施这些3D计算机视觉算法可能会变得更加容易。读者将获得大量与网格、点云和图像拟合相关的实践经验。
- en: 'This part includes the following chapters:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 3*](B18217_03.xhtml#_idTextAnchor046), *Fitting Deformable Mesh Models
    to Raw Point Clouds*'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第3章*](B18217_03.xhtml#_idTextAnchor046)，*将可变形网格模型拟合到原始点云*'
- en: '[*Chapter 4*](B18217_04.xhtml#_idTextAnchor059), *Learning Object Pose Detection
    and Tracking by Differentiable Rendering*'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第4章*](B18217_04.xhtml#_idTextAnchor059)，*通过可微分渲染进行物体姿态检测与跟踪*'
- en: '[*Chapter 5*](B18217_05.xhtml#_idTextAnchor070), *Understanding Differentiable
    Volumetric Rendering*'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第5章*](B18217_05.xhtml#_idTextAnchor070)，*理解可微分体积渲染*'
- en: '[*Chapter 6*](B18217_06.xhtml#_idTextAnchor081), *Exploring Neural Radiance
    Fields (NeRF)*'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B18217_06.xhtml#_idTextAnchor081)，*探索神经辐射场（NeRF）*'
