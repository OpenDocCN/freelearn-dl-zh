- en: Image Classification Using TensorFlow Hub
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow Hub进行图像分类
- en: We have discussed the image classification task in all of the previous chapters
    of this book. We have seen how it is possible to define a convolutional neural
    network by stacking several convolutional layers and how to train it using Keras.
    We also looked at eager execution and saw that using AutoGraph is straightforward.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的前几章中，我们讨论了图像分类任务。我们已经看到如何通过堆叠多个卷积层来定义卷积神经网络，并学习如何使用Keras来训练它。我们还了解了eager执行，并发现使用AutoGraph非常直接。
- en: So far, the convolutional architecture used has been a LeNet-like architecture,
    with an expected input size of 28 x 28, trained end to end every time to make
    the network learn how to extract the correct features to solve the fashion-MNIST
    classification task.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，使用的卷积架构一直是类似LeNet的架构，预期输入大小为28 x 28，每次训练时从头到尾训练，以使网络学习如何提取正确的特征来解决fashion-MNIST分类任务。
- en: Building a classifier from scratch, defining the architecture layer by layer,
    is an excellent didactical exercise that allows you to experiment with how different
    layer configurations can change the network performance. However, in real-life
    scenarios, the amount of data available to train a classifier is often limited.
    Gathering clean and correctly labeled data is a time-consuming process, and collecting
    a dataset with thousands of samples is tough. Moreover, even when the dataset
    size is adequate (thus, we are in a big data regime), training a classifier on
    it is a slow process; the training process might require several hours of GPU
    time since architectures more complicated than our LeNet-like architecture are
    necessary to achieve satisfactory results. Different architectures have been developed
    over the years, all of them introducing some novelties that have allowed the correct
    classification of color images with a resolution higher than 28 x 28.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 从零开始构建分类器，逐层定义架构，是一个非常好的教学练习，能够让你实验不同的层配置如何影响网络的表现。然而，在现实场景中，用于训练分类器的数据量通常是有限的。收集干净且正确标注的数据是一个耗时的过程，收集包含成千上万样本的数据集非常困难。而且，即使数据集的大小足够（也就是我们处于大数据范畴），训练分类器的过程依然是一个缓慢的过程；训练可能需要数小时的GPU时间，因为比LeNet架构更复杂的架构是实现令人满意结果所必需的。多年来，已经开发出了不同的架构，所有这些架构都引入了一些新颖的设计，使得可以正确地分类分辨率高于28
    x 28的彩色图像。
- en: Academia and industry release new classification architectures to improve the
    state of the art year on year. Their performance for an image classification task
    is measured by looking at the top-1 accuracy reached by the architecture when
    trained and tested on massive datasets such as ImageNet.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 学术界和工业界每年都会发布新的分类架构，以提高现有技术水平。通过观察架构在像ImageNet这样的庞大数据集上训练和测试时的top-1准确率，可以衡量它们在图像分类任务中的表现。
- en: ImageNet is a dataset of over 15 million high-resolution images with more than
    22,000 categories, all of them manually labeled. The **ImageNet Large Scale Visual
    Recognition Challenge** (**ILSVRC **) is a yearly object detection and classification
    challenge that uses a subset of ImageNet of 1,000 images for 1,000 categories.
    The dataset used for the computation is made up of roughly 1.2 million training
    images, 50,000 validation images, and 100,000 testing images.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: ImageNet是一个包含超过1500万张高分辨率图像的数据集，涵盖超过22,000个类别，所有图像都经过手动标注。**ImageNet大规模视觉识别挑战赛**（**ILSVRC**）是一个年度的目标检测与分类挑战，使用ImageNet的一个子集，包含1000个类别的1000张图像。用于计算的数据集大致包括120万张训练图像、5万张验证图像和10万张测试图像。
- en: To achieve impressive results on an image classification task, researchers found
    that deep architectures were needed. This approach has a drawback—the deeper the
    network, the higher the number of parameters to train. But a higher number of
    parameters implies that a lot of computing power is needed (and computing power
    costs!). Since academia and industry have already developed and trained their
    models, why don't we take advantage of their work to speed up our development
    without reinventing the wheel every time?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在图像分类任务中取得令人印象深刻的结果，研究人员发现需要使用深度架构。这种方法有一个缺点——网络越深，训练的参数数量就越多。但更多的参数意味着需要大量的计算能力（而计算能力是有成本的！）。既然学术界和工业界已经开发并训练了他们的模型，为什么我们不利用他们的工作来加速我们的开发，而不是每次都重新发明轮子呢？
- en: In this chapter, we'll discuss transfer learning and fine-tuning, showing how
    they can speed up development. TensorFlow Hub is used as a tool to quickly get
    the models we need and speed up development.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论迁移学习和微调，展示它们如何加速开发过程。TensorFlow Hub 作为一种工具，用于快速获取所需模型并加速开发。
- en: By the end of this chapter, you will know how to transfer the knowledge embedded
    in a model to a new task, using TensorFlow Hub easily, thanks to its Keras integration.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，您将了解如何使用 TensorFlow Hub 并通过其与 Keras 的集成，轻松地将模型中嵌入的知识迁移到新任务中。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Getting the data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取数据
- en: Transfer learning
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迁移学习
- en: Fine-tuning
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调
- en: Getting the data
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取数据
- en: 'The task we are going to solve in this chapter is a classification problem
    on a dataset of flowers, which is available in **tensorflow-datasets** (**tfds**).
    The dataset''s name is `tf_flowers` and it consists of images of five different
    flower species at different resolutions. Using `tfds`, gathering the data is straightforward,
    and we can get the dataset''s information by looking at the `info` variable returned
    by the `tfds.load` invocation, as shown here:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章要解决的任务是一个关于花卉数据集的分类问题，该数据集可在**tensorflow-datasets**（**tfds**）中找到。该数据集名为`tf_flowers`，包含五种不同花卉物种的图像，分辨率各异。通过使用`tfds`，获取数据非常简单，我们可以通过查看`tfds.load`调用返回的`info`变量来获取数据集的信息，如下所示：
- en: '`(tf2)`'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding code produces the following dataset description:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下的数据集描述：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'There is a single split train with 3,670 labeled images. The image resolution
    is not fixed, as we can see from the `None` value in the height and width position
    of the `Image` shape feature. There are five classes, as expected. Looking at
    the `download` folder of the dataset (default to `~/tensorflow_datasets/downloads/extracted`),
    we can find the dataset structure and look at the labels, which are as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集有一个训练集划分，包含3,670张带标签的图像。由于`Image`形状特征的高度和宽度位置显示为`None`，图像分辨率不固定。数据集包含五个类别，正如我们预期的那样。查看数据集的`download`文件夹（默认为`~/tensorflow_datasets/downloads/extracted`），我们可以找到数据集的结构，并查看标签，具体如下：
- en: Daisy
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 雏菊
- en: Dandelion
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蒲公英
- en: Roses
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 玫瑰
- en: Sunflowers
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向日葵
- en: Tulips
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 郁金香
- en: 'Every image of the dataset is licensed under a Creative Commons by attribution
    license. As we can see from the `LICENSE.txt` file, the dataset has been gathered
    by scraping Flickr. The following is an image sampled from the dataset:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的每张图片都具有知识共享许可（Creative Commons by attribution）。从`LICENSE.txt`文件中我们可以看到，数据集是通过爬取
    Flickr 网站收集的。以下是从数据集中随机选取的一张图片：
- en: '![](img/ab6fc0e7-df71-4117-a2db-4449845c69a7.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ab6fc0e7-df71-4117-a2db-4449845c69a7.png)'
- en: Image labeled as sunflower. Filesunflowers/2694860538_b95d60122c_m.jpg - CC-BY
    by Ally Aubry ([https://www.flickr.com/photos/allyaubryphotography/2694860538/](https://www.flickr.com/photos/allyaubryphotography/2694860538/)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 被标记为向日葵的图像。文件sunflowers/2694860538_b95d60122c_m.jpg - 由 Ally Aubry 提供的 CC-BY
    许可（[https://www.flickr.com/photos/allyaubryphotography/2694860538/](https://www.flickr.com/photos/allyaubryphotography/2694860538/)）。
- en: Very often, datasets are not made of pictures where only the labeled subject
    appears, and these kinds of datasets are perfect for developing algorithms that
    are robust at handling noise in the data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集通常并不是由仅包含标注对象的图片组成的，这类数据集非常适合开发能够处理数据中噪声的强大算法。
- en: 'The dataset is ready, although it is not correctly split following the guidelines.
    In fact, there is only a single split when, instead, three splits (train, validation,
    and test) are recommended. Let''s create the three non-overlapping splits, by
    creating three separate `tf.data.Dataset` objects. We''ll use the `take` and `skip` methods of
    the dataset object:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集已经准备好，尽管它并未按指导原则正确划分。事实上，数据集只有一个划分，而推荐使用三个划分（训练集、验证集和测试集）。让我们通过创建三个独立的`tf.data.Dataset`对象来创建这三个不重叠的划分。我们将使用数据集对象的`take`和`skip`方法：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Alright. Now we have the required three splits, and we can start using them
    to train, evaluate, and test our classification model, which will be built by
    reusing a model that someone else trained on a different dataset.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。现在我们已经获得了所需的三种数据集划分，可以开始使用它们来训练、评估和测试我们的分类模型，该模型将通过重用别人基于不同数据集训练的模型来构建。
- en: Transfer learning
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习
- en: Only academia and some industries have the required budget and computing power
    to train an entire CNN from scratch, starting from random weights, on a massive
    dataset such as ImageNet.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 只有学术界和一些行业才具备训练整个卷积神经网络（CNN）从零开始所需的预算和计算能力，尤其是在像 ImageNet 这样的大型数据集上，从随机权重开始。
- en: Since this expensive and time-consuming work has already been done, it is a
    smart idea to reuse parts of the trained model to solve our classification problem.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这项昂贵且耗时的工作已经完成，重用训练过的模型的部分来解决我们的分类问题是一个明智的做法。
- en: In fact, it is possible to transfer what the network has learned from one dataset
    to a new one, thereby transferring the knowledge.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，可以将网络从一个数据集上学到的知识转移到一个新的数据集上，从而实现知识的迁移。
- en: 'Transfer learning is the process of learning a new task by relying on a previously
    learned task: the learning process can be faster, more accurate, and require less
    training data.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是通过依赖先前学习的任务来学习新任务的过程：学习过程可以更快、更准确，并且需要更少的训练数据。
- en: The transfer learning idea is bright, and it can be successfully applied when
    using convolutional neural networks.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习的想法非常聪明，并且在使用卷积神经网络时可以成功应用。
- en: 'In fact, all convolutional architectures for classification have a fixed structure,
    and we can reuse parts of them as building blocks for our applications. The general
    structure is composed of three elements:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，所有用于分类的卷积架构都有一个固定结构，我们可以将它们的部分作为构建模块来为我们的应用提供支持。一般结构由三个元素组成：
- en: '**Input layer**: The architecture is designed to accept an image with a precise
    resolution. The input resolution influences all of the architecture; if the input
    layer resolution is high, the network will be deeper.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入层**：该架构设计用于接受具有精确分辨率的图像。输入分辨率影响整个架构；如果输入层的分辨率较高，网络将会更深。'
- en: '**Feature extractor**: This is the set of convolution, pooling, normalizations,
    and every other layer that is in between the input layer and the first dense layer.
    The architecture learns to summarize all the information contained in the input
    image in a low-dimensional representation (in the diagram that follows, an image
    with a size of 227 x 227 x 3 is projected into a 9216-dimensional vector).'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征提取器**：这是一组卷积层、池化层、归一化层以及位于输入层与第一个全连接层之间的所有其他层。该架构学习将输入图像中包含的所有信息总结为低维表示（在下面的图示中，大小为227
    x 227 x 3的图像被投影到一个9216维的向量中）。'
- en: '**Classification layers**: These are a stack of fully connected layers—a fully-connected
    classifier built on top of the low-dimensional representation of the input extracted
    by the classifier:'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类层**：这些是一个由全连接层组成的堆叠——一个建立在分类器提取的低维输入表示之上的全连接分类器：'
- en: '![](img/3a3d0051-3db8-4c0e-a21a-fb2b60674bea.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3a3d0051-3db8-4c0e-a21a-fb2b60674bea.png)'
- en: The AlexNet architecture; the first deep neural network used to win the ImageNet
    challenge. Like every other convolutional neural network for classification, its
    structure is fixed. The input layer consists of an expected input image with a
    resolution of 227 x 227 x 227\. The feature extractor is a series of convolutional
    layers followed by max-pooling to reduce the resolution while going deeper; the
    last feature map 6 x 6 x 256, is reshaped in a 6 * 6 * 256 = 9216 feature vector.
    The classification layers are a traditional fully-connected architecture, which
    ends with 1,000 output neurons since the network was trained on 1,000 classes.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet架构：第一款用于赢得ImageNet挑战的深度神经网络。像所有其他用于分类的卷积神经网络一样，它的结构是固定的。输入层由一个期望的输入图像组成，分辨率为227
    x 227 x 227。特征提取器是由一系列卷积层组成，后跟最大池化层以减少分辨率并向更深层推进；最后的特征图6 x 6 x 256被重塑为一个6 * 6
    * 256 = 9216维的特征向量。分类层是传统的全连接架构，最终输出1,000个神经元，因为该网络是在1,000个类别上训练的。
- en: Transferring the knowledge of a trained model to a new one requires us to remove
    the task-specific part of the network (which is the classification layers) and
    keep the CNN fixed as the feature extractor.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将训练模型的知识转移到新模型中需要我们移除网络中任务特定的部分（即分类层），并将CNN保持为固定的特征提取器。
- en: This approach allows us to use the feature extractor of a pre-trained model
    as a building block for our new classification architecture. When doing transfer
    learning, the pre-trained model is kept constant, while only the new classification
    layers attached on top of the feature vector are trainable.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法允许我们将预训练模型的特征提取器作为构建模块用于我们的新分类架构。在进行迁移学习时，预训练模型保持不变，而附加在特征向量上的新分类层是可训练的。
- en: 'In this way, we can train a classifier by reusing the knowledge learned on
    a massive dataset and embedding it into the model. This leads to two significant
    advantages:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们可以通过重用在大规模数据集上学到的知识并将其嵌入到模型中来训练分类器。这带来了两个显著的优势：
- en: It speeds up the training process since the number of trainable parameters is
    low
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它加速了训练过程，因为可训练的参数数量较少。
- en: It potentially mitigates the overfitting problem since the extracted features
    come from a different domain and the training process can't make them change
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它有可能减轻过拟合问题，因为提取的特征来自不同的领域，训练过程无法改变它们。
- en: 'So far, so good. The transfer learning idea is bright, and it can help to deal
    with several real-life problems when datasets are small and resources are constrained.
    The only missing part, which also happens to be the most important one, is: where
    can we find pre-trained models?'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，一切都很好。迁移学习的思路很明亮，当数据集较小且资源受限时，它有助于解决一些现实问题。唯一缺失的部分，恰恰也是最重要的部分是：我们可以在哪里找到预训练模型？
- en: For this reason, the TensorFlow team created TensorFlow Hub.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 正因如此，TensorFlow团队创建了TensorFlow Hub。
- en: TensorFlow Hub
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow Hub
- en: 'The description of TensorFlow Hub that can be found on the official documentation
    describes what TensorFlow Hub is and what it''s about pretty well:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 官方文档中对TensorFlow Hub的描述很好地阐明了TensorFlow Hub是什么以及它的作用：
- en: 'TensorFlow Hub is a library for the publication, discovery, and consumption
    of reusable parts of machine learning models. A *module* is a self-contained piece
    of a TensorFlow graph, along with its weights and assets, that can be reused across
    different tasks in a process known as transfer learning. Transfer learning can:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Hub是一个用于发布、发现和使用可重用机器学习模型组件的库。一个*模块*是TensorFlow图中的一个自包含部分，包含它的权重和资产，可以在不同任务中重复使用，这个过程被称为迁移学习。迁移学习可以：
- en: '- Train a model with a smaller dataset'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '- 使用较小的数据集训练模型'
- en: '- Improve generalization, and'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '- 提升泛化能力，且'
- en: '- Speed up training'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '- 加速训练'
- en: Thus, TensorFlow Hub is a library we can browse while a looking for a pre-trained
    model that best fits our needs. TensorFlow Hub comes both as a website we can
    browse ([https://tfhub.dev](https://tfhub.dev)) and as a Python package.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，TensorFlow Hub是一个我们可以浏览的库，可以在其中寻找最适合我们需求的预训练模型。TensorFlow Hub既可以作为一个我们可以浏览的网站（[https://tfhub.dev](https://tfhub.dev)），也可以作为一个Python包使用。
- en: 'Installing the Python package allows us to have perfect integration with the
    modules loaded on TensorFlow Hub and TensorFlow 2.0:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 安装Python包可以完美集成加载到TensorFlow Hub上的模块和TensorFlow 2.0：
- en: '`(tf2)`'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: That is all we need to do to get access to a complete library of pre-trained
    models compatible and integrated with TensorFlow.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们所需的全部操作，就能访问与TensorFlow兼容且集成的完整预训练模型库。
- en: The TensorFlow 2.0 integration is terrific—we only need the URL of the module
    on TensorFlow Hub to create a Keras layer that contains the parts of the model
    we need!
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 2.0的集成非常棒——我们只需要TensorFlow Hub上模块的URL，就能创建一个包含我们所需模型部分的Keras层！
- en: 'Browsing the catalog on [https://tfhub.dev](https://tfhub.dev) is intuitive.
    The screenshot that follows shows how to use the search engine to find any module
    that contains the string `tf2` (this is a fast way to find an uploaded module
    that is TensorFlow 2.0 compatible and ready to use):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在[https://tfhub.dev](https://tfhub.dev)浏览目录是直观的。接下来的截图展示了如何使用搜索引擎找到包含字符串`tf2`的任何模块（这是一种快速找到已上传的TensorFlow
    2.0兼容且可用模块的方法）：
- en: '![](img/06f478e5-a08c-448d-9c33-b75878e7632b.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/06f478e5-a08c-448d-9c33-b75878e7632b.png)'
- en: 'The TensorFlow Hub website ([https://tfhub.dev](https://tfhub.dev)): it is
    possible to search for modules by query string (in this case, tf2) and refine
    the results by using the filter column on the left.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Hub官网（[https://tfhub.dev](https://tfhub.dev)）：可以通过查询字符串（在这种情况下为tf2）搜索模块，并通过左侧的过滤栏精细化搜索结果。
- en: 'There are models in both versions: feature vector-only and classification,
    which means a feature vector plus the trained classification head. The TensorFlow
    Hub catalog already contains everything we need for transfer learning. In the
    next section, we will see how easy it is to integrate the Inception v3 module
    from TensorFlow Hub into TensorFlow 2.0 source code, thanks to the Keras API.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 该库中有两种版本的模型：仅特征向量和分类模型，这意味着特征向量加上训练过的分类头。TensorFlow Hub目录中已经包含了迁移学习所需的一切。在接下来的部分，我们将看到如何通过Keras
    API将TensorFlow Hub中的Inception v3模块轻松集成到TensorFlow 2.0源代码中。
- en: Using Inception v3 as a feature extractor
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Inception v3作为特征提取器
- en: The complete analysis of the Inception v3 architecture is beyond the scope of
    this book; however, it is worth noting some peculiarities of this architecture
    so as to use it correctly for transfer learning on a different dataset.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对Inception v3架构的完整分析超出了本书的范围；然而，值得注意的是该架构的一些特点，以便正确地在不同数据集上进行迁移学习。
- en: 'Inception v3 is a deep architecture with 42 layers, which won the **ImageNet
    Large Scale Visual Recognition Competition** (**ILSVRC**) in 2015\. Its architecture
    is shown in the following screenshot:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Inception v3是一个深度架构，包含42层，它在2015年赢得了**ImageNet大规模视觉识别挑战赛**（**ILSVRC**）。其架构如下图所示：
- en: '![](img/0ef8f6ae-c05d-4b57-9342-033cc828716f.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0ef8f6ae-c05d-4b57-9342-033cc828716f.png)'
- en: Inception v3 architecture. The model architecture is complicated and very deep.
    The network accepts a 299 x 299 x 3 image as input and produces an 8 x 8 x 2,048
    feature map, which is the input of the final part; that is, a classifier trained
    on 1,000 +1 classes of ImageNet. Image source: [https://cloud.google.com/tpu/docs/inception-v3-advanced](https://cloud.google.com/tpu/docs/inception-v3-advanced).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Inception v3架构。该模型架构复杂且非常深。网络接受一个299 x 299 x 3的图像作为输入，并生成一个8 x 8 x 2,048的特征图，这是最终部分的输入；即一个在1,000
    + 1个ImageNet类别上训练的分类器。图像来源：[https://cloud.google.com/tpu/docs/inception-v3-advanced](https://cloud.google.com/tpu/docs/inception-v3-advanced)。
- en: The network expects an input image with a resolution of 299 x 299 x 3 and produces
    an 8 x 8 x 2,048 feature map. It has been trained on 1,000 classes of the ImageNet
    dataset, and the input images have been scaled in the [0,1] range.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 网络期望输入的图像分辨率为299 x 299 x 3，并生成一个8 x 8 x 2,048的特征图。它已在ImageNet数据集的1,000个类别上进行训练，输入图像已被缩放到[0,1]范围内。
- en: All this information is available on the module page, reachable by clicking
    on the search result on the TensorFlow Hub website. Unlike the official architecture
    shown previously, on this page, we can find information about the extracted feature
    vector. The documentation says that it is a 2,048-feature vector, which means
    that the feature vector used is not the flattened feature map (that would have
    been an 8 * 8 * 2048 dimensional vector) but one of the fully-connected layers
    placed at the end of the network.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些信息都可以在模块页面找到，用户可以通过点击TensorFlow Hub网站的搜索结果来访问该页面。与前面显示的官方架构不同，在该页面上，我们可以找到关于提取特征向量的信息。文档说明它是一个2,048维的特征向量，这意味着所使用的特征向量并不是展平后的特征图（那将是一个8
    * 8 * 2048维的向量），而是网络末端的一个全连接层。
- en: It is essential to know the expected input shape and the feature vector size
    to feed the network with correctly resized images and to attach the final layers,
    knowing how many connections there would be between the feature vector and the
    first fully-connected layer.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 了解期望的输入形状和特征向量大小对于正确地将调整大小后的图像输入到网络并附加最终层是至关重要的，知道特征向量与第一个全连接层之间会有多少连接。
- en: 'More importantly, it is necessary to know on which dataset the network was
    trained since transfer learning works well if the original dataset shares some
    features with the target (new) dataset. The following screenshot shows some samples
    gathered from the dataset used for the ILSVRC in 2015:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，需要了解网络是在哪个数据集上进行训练的，因为迁移学习效果良好是因为原始数据集与目标（新）数据集有一些相似的特征。以下截图展示了从2015年ILSVRC使用的数据集中收集的一些样本：
- en: '![](img/29f5f1af-d36c-4d83-83fa-08fd9e447366.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/29f5f1af-d36c-4d83-83fa-08fd9e447366.png)'
- en: Samples gathered from the dataset used in the ILSVRC 2015 competition. High-resolution
    images, with complex scenes and rich details.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 从ILSVRC 2015竞赛使用的数据集中收集的样本。高分辨率图像，复杂的场景和丰富的细节。
- en: As you can see, the images are high-resolution images of various scenes and
    subjects, rich in detail. The variance of details and subjects is high. Therefore,
    we expect the feature extractor learned to extract a feature vector that is a
    good summary of images with these features. This means that if we feed the pre-trained
    network with an image that contains similar features to the one the network saw
    during the training, it will extract a meaningful representation as a feature
    vector. On the contrary, if we fed the network with an image that does not contain
    similar features (an image that, for instance, is not rich in detail like ImageNet,
    such as a simple image of a geometric shape), the feature extractor would be unlikely
    to extract a good representation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这些图像是各种场景和主题的高分辨率图像，细节丰富。细节和主题的变化性很高。因此，我们期望学习到的特征提取器能够提取一个特征向量，作为这些特征的良好总结。这意味着，如果我们将一张与网络在训练中看到的图像具有相似特征的图像输入到预训练网络中，它将提取一个有意义的表示作为特征向量。相反，如果我们输入的图像没有类似的特征（例如，像
    ImageNet 这样的简单几何形状图像，它缺乏丰富的细节），特征提取器就不太可能提取出一个好的表示。
- en: The feature extractor of Inception v3 is certainly good enough to be used as
    a building block for our flowers classifier.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Inception v3 的特征提取器肯定足够好，可以作为我们花卉分类器的构建模块。
- en: Adapting data to the model
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据适配到模型中
- en: 'The information found on the module page also tells us that it is necessary
    to add a pre-processing step to the dataset split built earlier: the `tf_flower`
    images are `tf.uint8`, which means they are in the [0,255] range, while Inception
    v3 has been trained on images in the [0,1] range, which are thus `tf.float32`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 模块页面上找到的信息还告诉我们，有必要向之前构建的数据集拆分中添加一个预处理步骤：`tf_flower` 图像是 `tf.uint8` 类型，这意味着它们的范围是
    [0,255]，而 Inception v3 是在 [0,1] 范围内的图像上训练的，因此它们是 `tf.float32` 类型：
- en: '`(tf2)`'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE4]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Moreover, the Inception architecture requires a fixed input shape of 299 x
    299 x 3\. Therefore, we have to ensure that all our images are correctly resized
    to the expected input size:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Inception 架构要求固定的输入形状为 299 x 299 x 3。因此，我们必须确保所有图像都被正确调整为预期的输入大小：
- en: '`(tf2)`'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE5]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'All the required pre-processing operations have been defined, so we are ready
    to apply them to the `train`, `validation`, and `test` splits:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 所有必需的预处理操作已经定义好，因此我们可以准备将它们应用于 `train`、`validation` 和 `test` 数据集：
- en: '`(tf2)`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To summarize: the target dataset is ready; we know which model we want to use
    as a feature extractor;  the module information page told us that some preprocessing
    steps were required to make the data compatible with the model.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下：目标数据集已经准备好；我们知道要使用哪个模型作为特征提取器；模块信息页面告诉我们需要进行一些预处理步骤，以使数据与模型兼容。
- en: Everything is set up to design the classification model that uses Inception
    v3 as the feature extractor. In the next section, the extreme ease of use of the `tensorflow-hub`
    module is shown, thanks to its Keras integration.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都已准备好设计一个使用 Inception v3 作为特征提取器的分类模型。在接下来的部分中，将展示 `tensorflow-hub` 模块的极易使用，得益于其与
    Keras 的集成。
- en: Building the model – hub.KerasLayer
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建模型 - hub.KerasLayer
- en: 'The TensorFlow Hub Python package has already been installed, and this is all
    we need to do:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Hub Python 包已经安装好，这就是我们所需要做的全部：
- en: Download the model parameters and graph description
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载模型参数和图形描述
- en: Restore the parameters in its graph
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 恢复其图形中的参数
- en: Create a Keras layer that wraps the graph and allows us to use it like any other
    Keras layer we are used to using
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 Keras 层，包装图形并使我们能够像使用其他任何 Keras 层一样使用它
- en: 'These three points are executed under the hook of the `KerasLayer tensorflow-hub`
    function:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这三点操作是在 `KerasLayer tensorflow-hub` 函数的钩子下执行的：
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `hub.KerasLayer` function creates `hub.keras_layer.KerasLayer`, which is
    a `tf.keras.layers.Layer` object. Therefore, it can be used in the same way as
    any other Keras layer—this is powerful!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`hub.KerasLayer` 函数创建了 `hub.keras_layer.KerasLayer`，它是一个 `tf.keras.layers.Layer`
    对象。因此，它可以像其他任何 Keras 层一样使用——这非常强大！'
- en: 'This strict integration allows us to define a model that uses the Inception
    v3 as a feature extractor and it has two fully connected layers as classification
    layers in very few lines:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这种严格的集成使我们能够定义一个使用 Inception v3 作为特征提取器的模型，并且它具有两个全连接层作为分类层，这只需要非常少的代码行数：
- en: '`(tf2)`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The model definition is straightforward, thanks to the Keras integration. Everything
    is set up to define the training loop, measure the performance, and see whether
    the transfer learning approach gives us the expected classification results.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 由于有 Keras 集成，模型定义非常简单。所有的设置都已经完成，能够定义训练循环、衡量性能，并检查迁移学习方法是否能给出预期的分类结果。
- en: Unfortunately, the process of downloading a pre-trained model from TensorFlow Hub
    is fast only on high-speed internet connections. A progress bar that shows the
    download progress is not enabled by default and, therefore, a lot of time could
    be required (depending on the internet speed) to build the model for the first
    time.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，从 TensorFlow Hub 下载预训练模型的过程，只有在高速互联网连接下才会快速。进度条显示下载进度默认未启用，因此，第一次构建模型时，可能需要较长时间（取决于网络速度）。
- en: 'To enable a progress bar, using the `TFHUB_DOWNLOAD_PROGRESS` environment variable is
    required by `hub.KerasLayer`. Therefore, on top of the script, the following snippet
    can be added, which defines this environment variable and puts the value of 1
    inside it; in this way, a handy progress bar will be shown on the first download:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用进度条，`hub.KerasLayer` 需要使用 `TFHUB_DOWNLOAD_PROGRESS` 环境变量。因此，可以在脚本顶部添加以下代码片段，定义这个环境变量并将值设置为
    1；这样，在第一次下载时，将会显示一个方便的进度条：
- en: '[PRE9]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Training and evaluating
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练和评估
- en: Using a pre-trained feature extractor allows us to speed up the training while
    keeping the training loop, the losses, and optimizers unchanged, using the same
    structure of every standard classifier train.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预训练的特征提取器可以加速训练，同时保持训练循环、损失函数和优化器不变，使用每个标准分类器训练的相同结构。
- en: 'Since the dataset labels are `tf.int64` scalars, the loss that is going to
    be used is the standard sparse categorical cross-entropy, setting the `from_logits`
    parameter to `True`. As seen in the previous chapter, [Chapter 5](d4dd1390-8b84-4ec9-9610-769e3c8fdc55.xhtml), *Efficient
    Data Input Pipelines and Estimator API, *setting this parameter to `True` is a
    good practice since, in this way, it''s the loss function itself that applies
    the softmax activation function, being sure to compute it in a numerically stable
    way, and thereby preventing the loss becoming `NaN`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集标签是 `tf.int64` 标量，因此使用的损失函数是标准的稀疏分类交叉熵，并将 `from_logits` 参数设置为 `True`。如上一章所述，[第
    5 章](d4dd1390-8b84-4ec9-9610-769e3c8fdc55.xhtml)，*高效的数据输入管道与估算器 API*，将此参数设置为 `True`
    是一种良好的做法，因为这样损失函数本身会应用 softmax 激活函数，确保以数值稳定的方式计算，从而防止损失变为 `NaN`：
- en: '[PRE10]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The training loop produces the following output (cut to highlight only the
    essential parts):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 训练循环产生了以下输出（剪辑以突出显示仅重要部分）：
- en: '[PRE11]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: After a single training epoch, we got a validation accuracy of 0.87, while the
    training accuracy was even lower (0.83). But by the end of the tenth epoch, the
    validation accuracy had even decreased (0.86), while the model was overfitting
    the training data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个训练周期后，我们得到了 0.87 的验证准确率，而训练准确率甚至更低（0.83）。但是到了第十个周期结束时，验证准确率甚至下降了（0.86），而模型开始对训练数据发生过拟合。
- en: In the *Exercises* section, you will find several exercises that use the previous
    code as a starting point; the overfitting problem should be tackled from several
    points of view, finding the best way to deal with it.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *练习* 部分，你将找到几个使用前述代码作为起点的练习；过拟合问题应从多个角度进行处理，寻找最佳解决方法。
- en: Before starting the next main section, it's worth adding a simple performance
    measurement that measures how much time is needed to compute a single training
    epoch.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始下一个主要部分之前，值得添加一个简单的性能测量，来衡量计算单个训练周期所需的时间。
- en: Training speed
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练速度
- en: Faster prototyping and training is one of the strengths of the transfer learning
    approach. One of the reasons behind the fact that transfer learning is often used
    in industry is the financial savings that it produces, reducing both the development
    and training time.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 更快速的原型设计和训练是迁移学习方法的优势之一。迁移学习在工业界被广泛使用的原因之一是它能够节省资金，减少开发和训练时间。
- en: To measure the training time, the Python `time` package can be used. `time.time()` returns
    the current timestamp, allowing you to measure (in milliseconds) how much time
    is needed to perform a training epoch.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 要测量训练时间，可以使用 Python 的 `time` 包。`time.time()` 返回当前时间戳，可以让你测量（以毫秒为单位）完成一个训练周期所需的时间。
- en: 'The training loop of the previous section can thus be extended by adding the
    time module import and the duration measurement:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，可以通过添加时间模块导入和持续时间测量来扩展前一节的训练循环：
- en: '`(tf2)`'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE12]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'On average, running the training loop on a Colab notebook ([https://colab.research.google.com](https://colab.research.google.com))
    equipped with an Nvidia k40 GPU, we obtain an execution speed as follows:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 平均而言，在配备Nvidia k40 GPU的Colab笔记本（[https://colab.research.google.com](https://colab.research.google.com)）上运行训练循环，我们获得的执行速度如下：
- en: '[PRE13]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As shown in the next section, transfer learning using a pre-trained model as
    a feature extractor gives a considerable speed boost.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如下一节所示，使用预训练模型作为特征提取器的迁移学习可以显著提高速度。
- en: Sometimes, using a pre-trained model as a feature extractor only is not the
    best way to transfer knowledge from one domain to another, often because the domains
    are too different and the features learned are useless for solving the new task.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，仅将预训练模型作为特征提取器并不是将知识从一个领域迁移到另一个领域的最佳方法，通常是因为两个领域差异太大，且所学到的特征对于解决新任务并无帮助。
- en: In these cases, it is possible—and recommended—to not have a fixed-feature extractor
    part but let the optimization algorithm change it, training the whole model end
    to end.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，实际上—并且建议—不使用固定的特征提取部分，而是让优化算法去改变它，从而端到端训练整个模型。
- en: Fine-tuning
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调
- en: Fine-tuning is a different approach to transfer learning. Both share the same
    goal of transferring the knowledge learned on a dataset on a specific task to
    a different dataset and a different task. Transfer learning, as shown in the previous
    section, reuses the pre-trained model without making any changes to its feature
    extraction part; in fact, it is considered a non-trainable part of the network.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 微调是迁移学习的另一种方法。两者的目标相同，都是将针对特定任务在数据集上学到的知识迁移到不同的数据集和任务上。如前一节所示，迁移学习是重用预训练模型，并且不对其特征提取部分进行任何更改；实际上，它被认为是网络的不可训练部分。
- en: Fine-tuning, instead, consists of fine-tuning the pre-trained network weights
    by continuing backpropagation.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，微调则是通过继续反向传播来微调预训练网络的权重。
- en: When to fine-tune
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时进行微调
- en: Fine-tuning a network requires having the correct hardware; backpropagating
    the gradients through a deeper network requires you to load more information in memory.
    Very deep networks have been trained from scratch in data centers with thousands
    of GPUs. Therefore, prepare to lower your batch size to as low as 1, depending
    on how much available memory you have.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 微调网络需要有正确的硬件；通过更深的网络反向传播梯度需要在内存中加载更多的信息。非常深的网络通常是在拥有数千个GPU的数据中心从零开始训练的。因此，准备根据可用内存的大小，将批量大小降至最低，例如降至1。
- en: 'Hardware requirements aside, there are other different points to keep in mind
    when thinking about fine-tuning:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 除了硬件要求外，在考虑微调时还有其他需要注意的不同点：
- en: '**Dataset size**: Fine-tuning a network means using a network with a lot of
    trainable parameters, and, as we know from the previous chapters, a network with
    a lot of parameters is prone to overfitting.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集大小**：微调网络意味着使用一个具有大量可训练参数的网络，正如我们在前几章中了解到的，拥有大量参数的网络容易发生过拟合。'
- en: If the target dataset size is small, it is not a good idea to fine-tune the
    network. Using the network as a fixed-feature extractor will probably bring in
    better results.
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果目标数据集的大小较小，那么微调网络并不是一个好主意。将网络作为固定特征提取器使用，可能会带来更好的结果。
- en: '**Dataset similarity**: If the dataset size is large (where large means with
    a size comparable to the one the pre-trained model has been trained on) and it
    is similar to the original one, fine-tuning the model is probably a good idea.
    Slightly adjusting the network parameters will help the network to specialize
    in the extraction of features that are specific to this dataset, while correctly
    reusing the knowledge from the previous, similar dataset.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集相似性**：如果数据集的大小很大（这里的大是指大小与预训练模型训练时使用的数据集相当）且与原始数据集相似，那么微调模型可能是一个好主意。稍微调整网络参数将帮助网络专注于提取特定于该数据集的特征，同时正确地重用来自先前相似数据集的知识。'
- en: If the dataset size is large and it is very different from the original, fine-tuning
    the network could help. In fact, the initial solution of the optimization problem
    is likely to be close to a good minimum when starting with a pre-trained model,
    even if the dataset has different features to learn (this is because the lower
    layers of the CNN usually learn low-level features that are common to every classification
    task).
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果数据集很大且与原始数据差异很大，微调网络可能会有所帮助。事实上，从预训练模型开始，优化问题的初始解很可能接近一个好的最小值，即使数据集有不同的特征需要学习（这是因为卷积神经网络的低层通常学习每个分类任务中常见的低级特征）。
- en: If the new dataset satisfies the similarity and size constraints, fine-tuning
    the model is a good idea. One important parameter to look at closely is the learning
    rate. When fine-tuning a pre-trained model, we suppose the model parameters are
    good (and they are since they are the parameters of the model that achieved state-of-the-art
    results on a difficult challenge), and, for this reason, a small learning rate
    is suggested.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如果新数据集满足相似性和大小的限制，微调模型是一个好主意。需要特别关注的一个重要参数是学习率。在微调一个预训练模型时，我们假设模型参数是好的（并且确实是，因为它们是实现了先进成果的模型参数），因此建议使用较小的学习率。
- en: Using a high learning rate would change the network parameters too much, and
    we don't want to change them in this way. Instead, using a small learning rate,
    we slightly adjust the parameters to make them adapt to the new dataset, without
    distorting them too much, thus reusing the knowledge without destroying it.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用较高的学习率会过度改变网络参数，而我们不希望以这种方式改变它们。相反，使用较小的学习率，我们稍微调整参数，使其适应新的数据集，而不会过度扭曲它们，从而重新利用知识而不破坏它。
- en: 'Of course, if the fine-tuning approach is chosen, the hardware requirements
    have to be kept in mind: lowering the batch size is perhaps the only way to fine-tune
    very deep models when using a standard GPU to do the work.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，如果选择微调方法，必须考虑硬件要求：降低批量大小可能是使用标准 GPU 微调非常深的模型的唯一方法。
- en: TensorFlow Hub integration
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow Hub 集成
- en: 'Fine-tuning a model downloaded from TensorFlow Hub might sound difficult; we
    have to do the following:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 微调从 TensorFlow Hub 下载的模型可能听起来很困难；我们需要做以下几步：
- en: Download the model parameters and graph
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载模型参数和图
- en: Restore the model parameters in the graph
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恢复图中的模型参数
- en: Restore all the operations that are executed only during the training (activating
    dropout layers and enabling the moving mean and variance computed by the batch
    normalization layers)
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恢复所有仅在训练期间执行的操作（激活丢弃层并启用批量归一化层计算的移动均值和方差）
- en: Attach the new layers on top of the feature vector
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将新层附加到特征向量上
- en: Train the model end to end
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端到端训练模型
- en: 'In practice, the integration of TensorFlow Hub and Keras models is so tight
    that we can achieve all this by setting the `trainable` Boolean flag to `True`
    when importing the model using `hub.KerasLayer`:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，TensorFlow Hub 和 Keras 模型的集成非常紧密，我们只需在通过`hub.KerasLayer`导入模型时将`trainable`布尔标志设置为`True`，就能实现这一切：
- en: '`(tf2)`'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE14]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Train and evaluate
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练并评估
- en: What happens if we build the same model as in the previous chapter, [Chapter
    5](d4dd1390-8b84-4ec9-9610-769e3c8fdc55.xhtml), *Efficient Data Input Pipelines
    and Estimator API*, and we train it on the `tf_flower` dataset, fine-tuning the
    weights?
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们构建与前一章[第5章](d4dd1390-8b84-4ec9-9610-769e3c8fdc55.xhtml)中相同的模型，*高效的数据输入管道与估算器
    API*，并在`tf_flower`数据集上进行训练，微调权重，会发生什么情况？
- en: 'The model is thus the one that follows; please note how the learning rate of
    the optimizer has been reduced from `1e-3` to `1e-5`:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，模型如下所示；请注意优化器的学习率已从`1e-3`降低到`1e-5`：
- en: '`(tf2)`'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`(tf2)`'
- en: '[PRE15]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In the following box, the first and last training epochs'' output is shown:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下框中，展示了第一次和最后一次训练时期的输出：
- en: '[PRE16]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As expected, the test accuracy reached the constant value of 1; hence we overfitted
    the training set. This was something expected since the `tf_flower` dataset is
    smaller and simpler than ImageNet. However, to see the overfitting problem clearly,
    we had to wait longer since having more parameters to train makes the whole learning
    process extremely slow, especially compared to the previous train when the pre-trained
    model was not trainable.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，测试准确率达到了常数值 1；因此我们对训练集进行了过拟合。这是预期的结果，因为`tf_flower`数据集比ImageNet小且简单。然而，要清楚地看到过拟合问题，我们必须等待更长时间，因为训练更多的参数使得整个学习过程变得非常缓慢，特别是与之前在预训练模型不可训练时的训练相比。
- en: Training speed
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练速度
- en: By adding the time measurements as we did in the previous section, it is possible
    to see how the fine-tuning process is extremely slow compared to transfer learning,
    using the model as a non-trainable feature extractor.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 通过像前一节那样添加时间测量，可以看到微调过程相对于迁移学习（使用模型作为不可训练的特征提取器）而言是非常缓慢的。
- en: In fact, if, in the previous scenario, we reached an average training speed
    per epoch of about 16.2 seconds, now we have to wait, on average, 60.04 seconds,
    which is a 370% slowdown!
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，如果在前面的场景中，我们每个 epoch 的平均训练时间大约为 16.2 秒，那么现在我们平均需要等待 60.04 秒，这意味着训练速度下降了
    370%！
- en: Moreover, it is interesting to see that at the end of the first epoch, we reached
    the same validation accuracy as was achieved in the previous training and that,
    despite overfitting the training data, the validation accuracy obtained at the
    end of the tenth epoch is greater than the previous one.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，值得注意的是，在第一轮训练结束时，我们达到了与之前训练相同的验证准确率，并且尽管训练数据出现了过拟合，但在第十轮训练结束时获得的验证准确率仍高于之前的结果。
- en: This simple experiment showed how using a pre-trained model as a feature extractor
    could lead to worse performance than fine-tuning it. This means that the features
    the network learned to extract on the ImageNet dataset are too different from
    the features that would be needed to classify the flowers, dataset correctly.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的实验展示了使用预训练模型作为特征提取器可能导致比微调模型更差的性能。这意味着，网络在 ImageNet 数据集上学到的特征与分类花卉数据集所需的特征差异太大。
- en: Choosing whether to use a pre-trained model as a fixed-feature extractor or
    to fine-tune it is a tough decision, involving a lot of trade-offs. Understanding
    whether the pre-trained model extracts features that are correct for the new task
    is complicated; merely looking at dataset size and similarity is a guideline,
    but in practice, this decision requires several tests.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 是否使用预训练模型作为固定特征提取器，还是对其进行微调，是一个艰难的决定，涉及到许多权衡。了解预训练模型提取的特征是否适合新任务是复杂的；仅仅通过数据集的大小和相似性来作为参考是一个指导原则，但在实际操作中，这个决策需要进行多次测试。
- en: Of course, it is better to use the pre-trained model as a feature extractor
    first, and, if the new model's performance is already satisfactory, there is no
    need to waste time trying to fine-tune it. If the results are not satisfying,
    it is worth trying a different pre-trained model and, as a last resort, trying
    the fine-tuning approach (because this requires more computational power, and
    it is expansive).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，最好先将预训练模型作为特征提取器使用，并且如果新模型的表现已经令人满意，就无需浪费时间进行微调。如果结果不理想，值得尝试使用不同的预训练模型，最后的手段是尝试微调方法（因为这需要更多的计算资源，且成本较高）。
- en: Summary
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, the concepts of transfer learning and fine-tuning were introduced.
    Training a very deep convolutional neural network from scratch, starting from
    random weights, requires the correct equipment, which is only found in academia
    and some big companies. Moreover, it can be a costly process since finding the
    architecture that achieves state-of-the-art results on a classification task requires
    multiple models to be designed and trained and for each of them to repeat the
    training process to search for the hyperparameter configuration that achieves
    the best results.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了迁移学习和微调的概念。从头开始训练一个非常深的卷积神经网络，且初始权重为随机值，需要合适的设备，这些设备只存在于学术界和一些大公司中。此外，这还是一个高成本的过程，因为找到在分类任务上达到最先进成果的架构需要设计和训练多个模型，并且每个模型都需要重复训练过程来寻找最佳的超参数配置。
- en: For this reason, transfer learning is the recommended practice to follow. It
    is especially useful when prototyping new solutions since it speeds up the training
    time and reduces the training costs.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，迁移学习是推荐的做法，尤其是在原型设计新解决方案时，它能够加速训练时间并降低训练成本。
- en: TensorFlow Hub is the online library offered by the TensorFlow ecosystem. It
    contains an online catalog that anyone can browse to search for a pre-trained
    model ready to be used. The models come with all the required information to use
    them, from the input size to the feature vector size, through to the dataset that
    has been used to train the model and its data type. All this information can be
    used to design the correct data input pipeline that correctly feeds the network
    with the right data (shape and data type).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Hub 是 TensorFlow 生态系统提供的在线库，包含一个在线目录，任何人都可以浏览并搜索预训练模型，这些模型可以直接使用。模型附带了所有必要的信息，从输入大小到特征向量大小，甚至包括训练模型时使用的数据集及其数据类型。所有这些信息可用于设计正确的数据输入管道，从而确保网络接收到正确形状和数据类型的数据。
- en: The Python package that comes with TensorFlow Hub is perfectly integrated with
    TensorFlow 2.0 and the Keras ecosystem, allowing you to download and use a pre-trained
    model just by knowing its URL, which can be found on the Hub website.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Hub 附带的 Python 包与 TensorFlow 2.0 和 Keras 生态系统完美集成，使你仅需知道模型的 URL（可以在
    Hub 网站上找到），就能下载并使用预训练模型。
- en: The `hub.KerasLayer` function not only allows you to download and load a pre-trained
    model but also offers the capability of doing both transfer learning and fine-tuning
    by toggling the `trainable` flag.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`hub.KerasLayer` 函数不仅可以让你下载和加载预训练模型，还可以通过切换 `trainable` 标志来实现迁移学习和微调的功能。'
- en: In the *Transfer Learning* and *Fine-Tuning* sections, we developed our classification
    models and trained them using a custom training loop. TensorFlow Datasets has
    been used to easily download, process, and get the `tf.data.Dataset` objects that have
    been used to utilize the processing hardware in its entirety, by defining high-efficiency
    data input pipelines.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *迁移学习* 和 *微调* 部分，我们开发了分类模型，并使用自定义训练循环进行了训练。TensorFlow Datasets 被用来轻松下载、处理，并获取
    `tf.data.Dataset` 对象，这些对象通过定义高效的数据输入管道来充分利用处理硬件。
- en: 'The final part of this chapter was dedicated to exercises: most of the code
    in the chapter has been left incomplete deliberately, so as to allow you to get
    your hands dirty and learn more effectively.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的最后部分是关于练习：本章的大部分代码故意未完成，以便让你动手实践，更有效地学习。
- en: Classification models built using convolutional architectures are used everywhere,
    from industry to smartphone applications. Classifying an image by looking at its
    whole content is useful, but sometimes its usage is limited (images more often
    than not contain more than one object). For this reason, other architectures that
    use convolutional neural networks as building blocks have been developed. These
    architectures can localize and classify more than one object per image, and these
    are the architectures that are used in self-driving cars and many other exciting
    applications!
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 使用卷积架构构建的分类模型广泛应用于各个领域，从工业到智能手机应用。通过查看图像的整体内容来进行分类是有用的，但有时这种方法的使用范围有限（图像通常包含多个物体）。因此，已经开发出了其他架构，利用卷积神经网络作为构建模块。这些架构可以在每张图像中定位并分类多个物体，这些架构广泛应用于自动驾驶汽车和许多其他令人兴奋的应用中！
- en: In the next chapter, [Chapter 7](6bcb3061-365e-4bce-bb8d-14525d8ada3d.xhtml), *Introduction
    to Object Detection*, object localization and classification problems are analyzed
    and a model able to localize objects in images is built from scratch using TensorFlow
    2.0.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，[第七章](6bcb3061-365e-4bce-bb8d-14525d8ada3d.xhtml)，*目标检测简介*，将分析物体定位和分类问题，并从零开始使用
    TensorFlow 2.0 构建一个能够在图像中定位物体的模型。
- en: Exercises
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: Describe the concept of transfer learning.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述迁移学习的概念。
- en: When can the transfer learning process bring good results?
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迁移学习过程何时能够带来良好的结果？
- en: What are the differences between transfer learning and fine-tuning?
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迁移学习和微调之间的区别是什么？
- en: If a model has been trained on a small dataset with low variance (similar examples),
    is it an excellent candidate to be used as a fixed-feature extractor for transfer
    learning?
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果一个模型已经在一个小数据集上进行了训练，并且数据集的方差较低（示例相似），它是否是作为固定特征提取器用于迁移学习的理想选择？
- en: 'The flower classifier built in the *transfer learning* section has no performance
    evaluation on the test dataset: add it.'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 *迁移学习* 部分构建的花卉分类器没有在测试数据集上进行性能评估：请为其添加评估功能。
- en: Extend the flower classifier source code, making it log the metrics on TensorBoard.
    Use the summary writers that are already defined.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩展花卉分类器源代码，使其能够在 TensorBoard 上记录指标。使用已定义的 summary writers。
- en: Extend the flower classifier to save the training status using a checkpoint
    (and its checkpoint manager).
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩展花卉分类器，以使用检查点（及其检查点管理器）保存训练状态。
- en: Create a second checkpoint for the model that reached the highest validation
    accuracy.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为达到了最高验证准确度的模型创建第二个检查点。
- en: Since the model suffers from overfitting, a good test is to reduce the number
    of neurons of the classification layer; try and see whether this reduces the overfitting
    problem.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于模型存在过拟合问题，可以通过减少分类层神经元的数量来进行测试；尝试一下，看看这是否能减少过拟合问题。
- en: Add a dropout layer after the first fully connected layer and measure the performance
    on several runs using different dropout keep probability. Select the model that
    reached the highest validation accuracy.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一个全连接层后添加一个丢弃层，并使用不同的丢弃保留概率进行多次运行，测量其性能。选择达到最高验证准确度的模型。
- en: 'Using the same model defined for the flower classifier, create a new training
    script that uses the Keras training loop: do not write the custom training loop,
    but use Keras instead.'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用为花卉分类器定义的相同模型，创建一个新的训练脚本，使用 Keras 训练循环：不要编写自定义训练循环，而是使用 Keras。
- en: Convert the Keras model created in the previous point (11) to an estimator.
    Train and evaluate the model.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将前面第 11 点创建的 Keras 模型转换为估算器（estimator）。训练并评估该模型。
- en: Use the TensorFlow Hub website to find a lightweight pre-trained model for image
    classification, trained on a high-variance dataset. Use the feature extractor
    version to build a fashion-MNIST classifier.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow Hub 网站查找一个轻量级的预训练模型，用于图像分类，且该模型是基于一个高方差数据集训练的。使用特征提取器版本来构建一个 fashion-MNIST
    分类器。
- en: Was the idea of using a model trained on a complex dataset as the feature extractor
    for a fashion-MNIST classifier a good one? Are the extracted features meaningful?
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用在复杂数据集上训练的模型作为 fashion-MNIST 分类器的特征提取器的想法是一个好主意吗？提取的特征有意义吗？
- en: Apply fine-tuning to the previously built fashion-MNIST classifier.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对之前构建的 fashion-MNIST 分类器进行微调。
- en: Did the process of fine-tuning a complex dataset to a simple one help us to
    achieve better results with respect to the ones obtained using transfer learning?
    If yes, why? If not, why?
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将复杂数据集微调为简单数据集的过程是否帮助我们在迁移学习中获得了更好的结果？如果是，为什么？如果不是，为什么？
- en: What happens if a higher learning rate is used to fine-tune a model? Try it.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果使用更高的学习率来微调模型，会发生什么？尝试一下。
