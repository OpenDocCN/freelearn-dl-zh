- en: Sequence Synthesis with GANs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GAN进行序列合成
- en: In this chapter, we will work on GANs that directly generate sequential data,
    such as text and audio. While doing so, we will go back to the previous image-synthesizing
    models we've looked at so that you can become familiar with NLP models quickly.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究能够直接生成序列数据（如文本和音频）的GAN。与此同时，我们将回顾之前所学的图像生成模型，以便让你更快地熟悉NLP模型。
- en: Throughout this chapter, you will get to know the commonly used techniques of
    the NLP field, such as RNN and LSTM. You will also get to know some of the basic
    concepts of **reinforcement learning** (**RL**) and how it differs from supervised
    learning (such as SGD-based CNNs). Later on, we will learn how to build a custom
    vocabulary from a collection of text so that we can train our own NLP models and
    learn how to train SeqGAN so that it can generate short English jokes. You will
    also learn how to use SEGAN to remove background noise and enhance the quality
    of speech audio.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将了解NLP领域常用的技术，如RNN和LSTM。你还将了解**强化学习**（**RL**）的一些基本概念，以及它与监督学习（如基于SGD的CNN）的区别。接下来，我们将学习如何从文本集合中构建自定义词汇表，以便训练自己的NLP模型，并学习如何训练SeqGAN，使其能够生成简短的英语笑话。你还将学习如何使用SEGAN去除背景噪音并增强语音音频的质量。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Text generation via SeqGAN – teaching GANs how to tell jokes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过SeqGAN进行文本生成 – 教授GAN如何讲笑话
- en: Speech quality enhancement with SEGAN
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SEGAN进行语音质量增强
- en: Text generation via SeqGAN – teaching GANs how to tell jokes
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过SeqGAN进行文本生成 – 教授GAN如何讲笑话
- en: In the previous chapter, we learned how to generate high-quality images based
    on description text with GANs. Now, we will move on and look at sequential data
    synthesis, such as text and audio, using various GAN models.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何通过GAN根据描述文本生成高质量图像。现在，我们将继续研究如何使用各种GAN模型进行序列数据合成，如文本和音频。
- en: When it comes to the generation of text, the biggest difference in terms of
    image generation is that text data is discrete while image pixel values are more
    continuous, though digital images and text are both essentially discrete. A pixel
    typically has 256 values and slight changes in the pixels won't necessarily affect
    the image's meaning to us. However, a slight change in the sentence – even a single
    letter (for example, turning *we* into *he*) – may change the whole meaning of
    the sentence. Also, we tend to have a higher tolerance bar for synthesized images
    compared to text. For example, if 90% of the pixels in the generated image of
    a dog are nearly perfect, we may have little trouble recognizing the dog because
    our brains are smart enough to automatically fill in the missing pixels. However,
    if you are reading a piece of news in which every one out of 10 words doesn't
    make any sense, you will definitely find it hard to enjoy reading it. This is
    why text generation is hard and there's less remarkable progress in text generation
    than image synthesis.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本生成方面，与图像生成的最大区别在于，文本数据是离散的，而图像像素值则更为连续，尽管数字图像和文本本质上都是离散的。一个像素通常有256个值，而像素的微小变化通常不会影响我们对图像的理解。然而，句子中的微小变化——即使是一个字母（例如，将*we*改成*he*）——也可能改变整个句子的意思。而且，我们通常对合成图像的容忍度要高于文本。例如，如果生成的狗的图像中有90%的像素几乎完美无缺，我们通常能轻松识别出狗，因为我们的大脑足够聪明，能自动填补缺失的像素。然而，如果你阅读的新闻中每10个单词中就有一个不合逻辑，你肯定会觉得很难享受阅读。这就是为什么文本生成很困难，而且相较于图像合成，文本生成的进展较慢的原因。
- en: 'SeqGAN was one of the first successful attempts of text generation with adversarial
    learning. It was proposed by Lantao Yu, Weinan Zhang, and Jun Wang, et. al. in
    their paper, *SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient*.
    In this section, we will walk you through the design of SeqGAN, how to create
    your own vocabulary for NLP tasks, and how to train SeqGAN so that it can generate
    short jokes.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 'SeqGAN是首批成功尝试使用对抗学习生成文本的模型之一。它由Lantao Yu、Weinan Zhang、Jun Wang等人在他们的论文《*SeqGAN:
    Sequence Generative Adversarial Nets with Policy Gradient*》中提出。在这一节中，我们将带你了解SeqGAN的设计，如何为NLP任务创建自己的词汇表，以及如何训练SeqGAN，使其能够生成简短的笑话。'
- en: Design of SeqGAN – GAN, LSTM, and RL
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SeqGAN的设计 – GAN、LSTM和RL
- en: Like other GAN models, SeqGAN is built upon the idea of adversarial learning.
    Some major changes have to be made so that it can accommodate NLP tasks. For example,
    the generation network is built with LSTM instead of CNNs, similar to some of
    the other GANs we looked at in the previous chapters. Also, reinforcement learning
    is used to optimize discrete objectives, unlike the SGD-family methods that were
    used in previous GAN models.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他 GAN 模型类似，SeqGAN 基于对抗学习的思想构建。为了使其适应 NLP 任务，需要进行一些重大更改。例如，生成网络是用 LSTM 而不是
    CNNs 构建的，类似于我们在前几章中看到的一些其他 GAN。此外，强化学习被用来优化离散目标，这与之前 GAN 模型中使用的 SGD 系列方法不同。
- en: Here, we will provide a quick introduction to LSTM and RL. However, we won't
    go too deep into these topics since we want to focus on the adversarial learning
    part of the model.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将简要介绍 LSTM 和 RL。但由于我们希望专注于模型的对抗学习部分，因此不会深入探讨这些话题。
- en: A quick introduction to RNN and LSTM
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速介绍 RNN 和 LSTM
- en: '**Recurrent neural networks** (**RNNs**) are designed to process sequential
    data such as text and audio. Their biggest difference to CNNs is that the weights
    in the hidden layers (that is, certain functions) are used repeatedly on multiple
    inputs and the order of the inputs affects the final results of the functions.
    The typical design of an RNN can be seen in the following diagram:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**递归神经网络**（**RNNs**）被设计用来处理顺序数据，如文本和音频。它们与 CNNs 的最大区别在于，隐藏层中的权重（即某些函数）在多个输入上反复使用，并且输入的顺序会影响函数的最终结果。RNN
    的典型设计可以在下图中看到：'
- en: '![](img/59435150-acdf-4e3b-99c8-68dd0f502411.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/59435150-acdf-4e3b-99c8-68dd0f502411.png)'
- en: Figure 10.1 Basic computational units of a recurrent neural network
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 递归神经网络的基本计算单元
- en: 'As we can see, the most distinctive characteristic of an RNN unit is that the
    hidden state, ![](img/54184b1f-1edb-4bf2-a92f-130f4bfc14b4.png), has an outgoing
    connection pointing to itself. This self-loop is where the name "recurrent" comes
    from. Let''s say the self-loop is performed three times. The extended version
    of this computational unit is shown on the right in the preceding diagram. The
    computational process is expressed as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，RNN 单元最显著的特点是隐藏状态 ![](img/54184b1f-1edb-4bf2-a92f-130f4bfc14b4.png)
    有一个指向自身的输出连接。这种自环是“递归”一词的来源。假设自环执行了三次，扩展版的计算单元如右图所示。计算过程如下：
- en: '![](img/8ffcd1a0-c001-48f7-a31b-da950dd05d5a.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8ffcd1a0-c001-48f7-a31b-da950dd05d5a.png)'
- en: '![](img/bd4676e8-94ff-4550-9319-f85aad178b67.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd4676e8-94ff-4550-9319-f85aad178b67.png)'
- en: Thus, after proper training, this RNN unit is capable of handling sequential
    data with a maximum length of 3.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在适当训练后，这个 RNN 单元能够处理最大长度为 3 的顺序数据。
- en: RNNs are widely used in voice recognition, natural language translation, language
    modeling, and image captioning. However, a critical flaw remains in RNN that we
    need to address with LSTM.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: RNNs 广泛应用于语音识别、自然语言翻译、语言建模和图像标注。然而，RNN 仍然存在一个关键缺陷，我们需要通过 LSTM 来解决。
- en: An RNN model assumes that a strong connection only exists between the neighboring
    inputs (for example, ![](img/3b929bf1-1c43-45d5-96f2-0c8b330bdc0c.png) and ![](img/2e5776b3-de79-4395-b77d-e941cba14a75.png), as
    shown in the preceding diagram) and that the connections between the inputs that
    are far apart from each other are ignored (for example, ![](img/f60506e1-eeb9-4c81-9a89-d56b18043f1c.png) and
    ![](img/8baa2dde-5c82-4cf0-afb4-4b797035ef16.png)). This becomes troublesome when
    we try to translate a long sentence into another language that has totally different grammatical
    rules and we need to look through all the parts of the sentence to make sense
    of it.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: RNN 模型假设只有相邻的输入之间存在强连接（例如，![](img/3b929bf1-1c43-45d5-96f2-0c8b330bdc0c.png)
    和 ![](img/2e5776b3-de79-4395-b77d-e941cba14a75.png)，如上图所示），并且输入之间的远距离连接被忽略（例如，![](img/f60506e1-eeb9-4c81-9a89-d56b18043f1c.png)
    和 ![](img/8baa2dde-5c82-4cf0-afb4-4b797035ef16.png)）。当我们试图将一个长句子翻译成具有完全不同语法规则的另一种语言时，就会变得麻烦，这时我们需要浏览句子的所有部分才能理解其含义。
- en: '**LSTM** (**Long Short-Term Memory**) was proposed by Sepp Hochreiter and Jürgen
    Schmidhuber in 1997 to preserve the long-term memory of sequential data and address
    the gradient explosion and vanishing issues in RNNs. Its computational process
    is illustrated in the following diagram:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**LSTM**（**长短期记忆**）是由 Sepp Hochreiter 和 Jürgen Schmidhuber 于 1997 年提出的，用于保留顺序数据的长期记忆并解决
    RNN 中的梯度爆炸和梯度消失问题。其计算过程在下图中展示：'
- en: '![](img/d7025e9b-c99f-41e3-b7ba-93443626748e.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d7025e9b-c99f-41e3-b7ba-93443626748e.png)'
- en: Figure 10.2 Computational process of LSTM
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 LSTM 的计算过程
- en: 'As we can see, an addition term, ![](img/3f4f4e24-7a3e-401e-93f8-457cb2e03a18.png),
    is included to help us choose what long-term information should be memorized.
    The detailed computational process is as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，一个附加项 ![](img/3f4f4e24-7a3e-401e-93f8-457cb2e03a18.png) 被引入，以帮助我们选择应该记住的长期信息。详细的计算过程如下：
- en: '![](img/2dfda1e3-d735-4bf0-9784-8bea0de02215.png) and ![](img/15c720a7-08a8-45e7-8ba8-ef713ce6eca4.png) are
    passed through the Forget Gate to decide what information should be forgotten:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/2dfda1e3-d735-4bf0-9784-8bea0de02215.png) 和 ![](img/15c720a7-08a8-45e7-8ba8-ef713ce6eca4.png)
    被传递通过忘记门，用来决定应该忘记哪些信息：'
- en: '![](img/c75f9a60-d34c-48f0-add0-b9b3c60d463c.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c75f9a60-d34c-48f0-add0-b9b3c60d463c.png)'
- en: 'The same inputs are also passed through the Input Gate so that we can calculate
    the updated ![](img/2c9501bf-f00a-4967-a448-ff5210863135.png) at the next step:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相同的输入也通过输入门，以便我们在下一步计算更新后的 ![](img/2c9501bf-f00a-4967-a448-ff5210863135.png)：
- en: '![](img/8ad3118d-ae7c-4b58-bd9d-dab83283b4b3.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8ad3118d-ae7c-4b58-bd9d-dab83283b4b3.png)'
- en: 'The updated ![](img/f6adc698-8d81-4745-ba20-f770ee4c1205.png) and ![](img/38a54135-0454-41f2-92c6-242b2ad566be.png) are
    calculated by the Output Gate:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新后的 ![](img/f6adc698-8d81-4745-ba20-f770ee4c1205.png) 和 ![](img/38a54135-0454-41f2-92c6-242b2ad566be.png)
    通过输出门计算得出：
- en: '![](img/5991df60-f54b-4c6b-a98f-94a18ed6137f.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5991df60-f54b-4c6b-a98f-94a18ed6137f.png)'
- en: Then, the new ![](img/2d0aaa6b-e7ba-4a49-a362-8018613c4751.png) and ![](img/3f4f4e24-7a3e-401e-93f8-457cb2e03a18.png) are
    used to calculate the next pair of ![](img/d77ae7d9-a5b5-43f0-872e-da13bf39d901.png) and
    ![](img/7555bd34-4191-4e83-8ddc-4a3ae8084bcc.png). Although the structure of an
    LSTM cell is much more complicated than the vanilla RNN cell, thanks to the delicate
    design of the three gates (Forget, Input, and Output), LSTM can be seen in almost
    every milestone NLP model in the past few years. If you want to find out more
    about LSTM and its variants, check out [https://colah.github.io/posts/2015-08-Understanding-LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs)
    and [https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，新的 ![](img/2d0aaa6b-e7ba-4a49-a362-8018613c4751.png) 和 ![](img/3f4f4e24-7a3e-401e-93f8-457cb2e03a18.png)
    被用来计算下一对 ![](img/d77ae7d9-a5b5-43f0-872e-da13bf39d901.png) 和 ![](img/7555bd34-4191-4e83-8ddc-4a3ae8084bcc.png)。虽然
    LSTM 单元的结构比普通的 RNN 单元复杂得多，但由于三大门（忘记门、输入门和输出门）的精妙设计，LSTM 可以在过去几年几乎所有的里程碑式 NLP 模型中看到。如果你想深入了解
    LSTM 及其变体，可以查看 [https://colah.github.io/posts/2015-08-Understanding-LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs)
    和 [https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)。
- en: Reinforcement learning versus supervised learning
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习与监督学习
- en: Reinforcement learning is another optimization method family in machine learning.
    It is often used when it's hard to provide standard correct answers for the tasks
    that the model is trying to solve, especially when the solution involves *free
    exploration* and the end goal of the task is somewhat *vague* compared to the
    specific decisions the model needs to make.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习 是机器学习中的另一种优化方法。它通常用于模型试图解决的任务很难提供标准的正确答案，特别是当解决方案涉及 *自由探索* 并且任务的最终目标相比模型需要做出的具体决策更为
    *模糊* 时。
- en: For example, if we want to teach a robot to walk, we can use reinforcement learning
    to let the robot teach itself to walk. We don't need to tell the robot how to
    move which body part at what time. We only tell it that its final goal is to *take
    yourself to that location 10 meters in front of you* and let it randomly move
    its limbs. At some point, a certain combination of movements for the robot's legs
    will bring the robot a step forward and a certain combination of movements for
    the robot's arms makes sure it won't fall out of balance. Similarly, reinforcement
    learning is also used to teach machines to play Go ([https://www.alphago-games.com](https://www.alphago-games.com))
    and video games ([https://openai.com/blog/openai-five](https://openai.com/blog/openai-five)).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们想教一个机器人走路，我们可以使用强化学习让机器人自己学会走路。我们不需要告诉机器人在什么时间如何移动哪个身体部位。我们只告诉它，最终目标是*把自己带到前方10米的那个位置*，然后让它随机地移动四肢。某个时刻，机器人的腿部某种组合的动作会让机器人前进一步，而机器人手臂的某种动作组合则确保它不会失去平衡。同样，强化学习也被用来教机器玩围棋（[https://www.alphago-games.com](https://www.alphago-games.com)）和视频游戏（[https://openai.com/blog/openai-five](https://openai.com/blog/openai-five)）。
- en: SGD-based optimization methods are often used in supervised learning (they were
    used in the models in the previous chapters where real data is always used to
    measure the quality of synthesized data), whereas, in unsupervised learning, the
    optimization strategies are totally different.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 基于SGD的优化方法通常用于监督学习（它们曾用于前几章的模型，在这些模型中总是使用真实数据来衡量合成数据的质量），而在无监督学习中，优化策略则完全不同。
- en: 'Currently, Policy Gradients and Q-Learning are two of the most commonly used
    methods in RL. Let''s explain them in brief:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，策略梯度（Policy Gradients）和Q学习（Q-Learning）是强化学习（RL）中最常用的两种方法。我们简要解释一下它们：
- en: '**Policy Gradient** is a policy-based method. The model directly gives actions
    (output) based on the current states (input). It alternates between evaluating
    the policy (takes actions based on states) and updating the policy (updates the
    mappings between states and actions). It is often used in large and continuous
    action spaces.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**策略梯度（Policy Gradient）**是一种基于策略的方法。模型直接根据当前状态（输入）给出动作（输出）。它在评估策略（基于状态采取行动）和更新策略（更新状态和动作之间的映射）之间交替进行。它通常用于大的连续动作空间。'
- en: '**Q-Learning** is a value-based method. It maintains a Q-table that keeps track
    of the rewards of various actions. It chooses the action that leads to the maximum
    reward value and then updates the Q-table, based on the new environment as a result
    of the action. It can be trained faster than the Policy Gradient method and is
    often used for simple tasks with small action spaces.'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Q学习（Q-Learning）**是一种基于价值的方法。它维护一个Q表，记录各种动作的奖励。它选择导致最大奖励值的动作，然后根据该动作带来的新环境更新Q表。与策略梯度方法相比，它的训练速度较快，通常用于简单任务和小的动作空间。'
- en: So, how can we choose between reinforcement learning and supervised learning
    (such as SGD methods in CNNs) when both of them are available? A simple rule of
    thumb is the **continuity** of the search space and the **differentiability**
    of the objective function. If the objective function is differentiable and the
    search space is continuous, it's better to use SGD methods. If the search space
    is discrete or the objective function is nondifferentiable, we need to stick to
    reinforcement learning. However, if the search space isn't very large and you
    have extra computing power to spare, **Evolutionary Search** (**ES**) methods
    are also a good option. When your variables are assumed to obey Gaussian distribution,
    you can always give the CMA-ES ([http://cma.gforge.inria.fr](http://cma.gforge.inria.fr))
    method a try.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，当强化学习和监督学习（如CNN中的SGD方法）都可用时，我们该如何选择呢？一个简单的经验法则是**搜索空间的连续性**和目标函数的**可微性**。如果目标函数是可微的，并且搜索空间是连续的，那么最好使用SGD方法。如果搜索空间是离散的，或者目标函数是不可微的，我们需要坚持使用强化学习。然而，如果搜索空间不是特别大，并且你有多余的计算能力，那么**进化搜索（Evolutionary
    Search，ES）**方法也是一个不错的选择。当你的变量假定服从高斯分布时，你可以尝试CMA-ES方法（[http://cma.gforge.inria.fr](http://cma.gforge.inria.fr)）。
- en: 'Here are two extra reading materials if you want to learn more about Policy
    Gradients:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想深入了解策略梯度，这里有两篇额外的阅读材料：
- en: '[https://medium.com/@jonathan_hui/rl-policy-gradients-explained-9b13b688b146](https://medium.com/@jonathan_hui/rl-policy-gradients-explained-9b13b688b146)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://medium.com/@jonathan_hui/rl-policy-gradients-explained-9b13b688b146](https://medium.com/@jonathan_hui/rl-policy-gradients-explained-9b13b688b146)'
- en: '[https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html](https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html](https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html)'
- en: Architecture of SeqGAN
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SeqGAN 的架构
- en: The idea behind SeqGAN is to get it to solve problems that vanilla GANs can't,
    since they are good at synthesizing discrete data, and discriminator networks
    can't, since they can't evaluate sequential data with various lengths. To solve
    the first problem, Policy Gradients are used for updating the generator network.
    The second problem is addressed by generating the remaining data with the **Monte
    Carlo Tree Search** (**MCTS**) method.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: SeqGAN 的核心思想是让它解决原始 GAN 无法解决的问题，因为原始 GAN 擅长合成离散数据，而判别器网络无法处理具有不同长度的序列数据。为了解决第一个问题，使用了策略梯度方法来更新生成器网络。第二个问题则通过
    **蒙特卡洛树搜索**（**MCTS**）方法生成剩余数据来解决。
- en: 'The reinforcement learning strategy in SeqGAN is designed as follows. Let''s
    assume that at time ![](img/968d471c-2b1b-42a8-9c28-ad6358aa650f.png), the generated
    sequence is denoted as ![](img/6cc4ad05-2814-4019-827b-9c763601285a.png) and that
    the current action, ![](img/fecafdf9-7338-4c4b-9d12-8cb53b5d2d35.png), needs to
    be given by the generator network, ![](img/d3cc5c60-c47a-47a8-aacd-68b41d882508.png),
    in which ![](img/555b91db-e108-404f-a68b-5e0b61d13df5.png) is the initial state.
    The generation of ![](img/43f5aadd-a184-4c99-a92f-3951ac78e84a.png) based on ![](img/fef5a57f-bb22-48a5-9a1b-92290afb70e9.png) is
    done by LSTM (or any of its variants). The objective of the generator is to maximize
    the cumulative rewards:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: SeqGAN 中的强化学习策略设计如下。假设在时刻 ![](img/968d471c-2b1b-42a8-9c28-ad6358aa650f.png)，生成的序列表示为 ![](img/6cc4ad05-2814-4019-827b-9c763601285a.png)，当前的动作 ![](img/fecafdf9-7338-4c4b-9d12-8cb53b5d2d35.png)
    需要由生成器网络 ![](img/d3cc5c60-c47a-47a8-aacd-68b41d882508.png) 给出，其中 ![](img/555b91db-e108-404f-a68b-5e0b61d13df5.png)
    为初始状态。基于 ![](img/fef5a57f-bb22-48a5-9a1b-92290afb70e9.png) 生成 ![](img/43f5aadd-a184-4c99-a92f-3951ac78e84a.png)
    是通过 LSTM（或其变体）完成的。生成器的目标是最大化累积奖励：
- en: '![](img/0b2631cf-8640-4697-9e51-9bc966795221.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0b2631cf-8640-4697-9e51-9bc966795221.png)'
- en: Here, ![](img/e6c5ed41-a6a3-4921-95c1-a83888146822.png) is the cumulative rewards, ![](img/bc008ce8-371b-4d4b-9eca-189aad473605.png) is
    the parameters to be optimized (that is, parameters in ![](img/66c2b854-dc58-45e0-970c-e555c8362e9a.png)),
    and ![](img/db34895b-1687-40ee-ad8c-b8090906a2c1.png) is called the **action-value
    function**. The action-value function, ![](img/26713f87-4914-4848-a523-a54070d61713.png), gives
    us the reward of taking the action, ![](img/1e773778-6365-4fe5-abe8-6146c0cd9943.png), by
    following policy, ![](img/c826ad81-ef12-430c-aedc-59d6b1608688.png), starting
    from the initial state, ![](img/e5f6cb1c-7e78-41e1-bc98-c7aaeabcceff.png).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里， ![](img/e6c5ed41-a6a3-4921-95c1-a83888146822.png) 为累积奖励， ![](img/bc008ce8-371b-4d4b-9eca-189aad473605.png)
    为待优化的参数（即 ![](img/66c2b854-dc58-45e0-970c-e555c8362e9a.png) 中的参数）， ![](img/db34895b-1687-40ee-ad8c-b8090906a2c1.png)
    被称为 **动作价值函数**。动作价值函数 ![](img/26713f87-4914-4848-a523-a54070d61713.png) 给出了通过遵循策略 ![](img/c826ad81-ef12-430c-aedc-59d6b1608688.png)
    从初始状态 ![](img/e5f6cb1c-7e78-41e1-bc98-c7aaeabcceff.png) 开始采取动作 ![](img/1e773778-6365-4fe5-abe8-6146c0cd9943.png)
    时的奖励。
- en: Normally, we would expect to use the discriminator network to give us reward
    values. However, the discriminator cannot be used directly to calculate the cumulative
    rewards because it can only evaluate a full-length sequence, ![](img/be89d748-38d2-4897-b0ec-506ae4cd6f31.png).
    At time ![](img/9e8f42b8-3dfc-4277-b2a6-c46e8e71f07b.png), all we have is ![](img/b50d186b-900f-4e29-bdad-8ecb9903eddf.png).
    How do we get the rest of the sequence?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们期望使用判别器网络来给出奖励值。然而，判别器不能直接用于计算累积奖励，因为它只能评估完整的序列 ![](img/be89d748-38d2-4897-b0ec-506ae4cd6f31.png)。在时刻 ![](img/9e8f42b8-3dfc-4277-b2a6-c46e8e71f07b.png)，我们只有 ![](img/b50d186b-900f-4e29-bdad-8ecb9903eddf.png)。那么，我们如何获得剩余的序列呢？
- en: 'In SeqGAN, the remaining sequence, ![](img/2aec922b-2d4a-45d9-a159-7fa86af0acb2.png), is
    generated by the MCTS method. MCTS is a tree-based search method and widely used
    in chess- and poker-playing programs and video game AI algorithms. All the actions
    that can be made are represented by nodes in a very large tree. It takes four
    steps to do a complete search in the Monte Carlo tree, as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在 SeqGAN 中，剩余的序列 ![](img/2aec922b-2d4a-45d9-a159-7fa86af0acb2.png) 是通过 MCTS
    方法生成的。MCTS 是一种基于树的搜索方法，广泛应用于象棋和扑克程序以及视频游戏 AI 算法中。所有可以执行的动作都由树中非常大的节点表示。要在蒙特卡洛树中完成一次完整的搜索，需经过以下四个步骤：
- en: '**Selection**, which is where you select a path from the root node to a leaf
    node. Normally, the selection of the existing nodes is based on **Upper Confidence
    Bounds** (**UCB**). Nodes with high scores are more likely to be chosen and nodes
    that haven''t been chosen that many times before are more likely to be selected.
    It is a balance between **exploration and exploitation**.'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择**，即从根节点到叶节点选择一条路径。通常，现有节点的选择是基于**上置信界限**（**UCB**）。得分较高的节点更有可能被选择，而那些之前没有被选择过很多次的节点更有可能被选中。这是**探索与利用**之间的平衡。'
- en: '**Expansion**, which is where you add new child nodes to the selected leaf
    node.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**扩展**，即在选定的叶节点上添加新的子节点。'
- en: '**Simulation**, which is where you evaluate the newly added nodes and get the
    final results (rewards).'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模拟**，即评估新添加的节点并获得最终结果（奖励）。'
- en: '**Backpropagation**, which is where you update the scores and counts statistics
    of all the nodes on the selected path.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**反向传播**，即更新所选路径上所有节点的得分和计数统计。'
- en: In fact, only the third step, simulation, is used to generate the remaining
    sequence, where it performs the simulation (generating the remaining sequence
    with ![](img/d8b164aa-836e-4c56-898c-e5ba4f5d43fe.png)) multiple times generate
    and get the averaged reward.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，只有第三步——模拟，才是用来生成剩余序列的，它通过多次执行模拟（生成剩余序列，使用 ![](img/d8b164aa-836e-4c56-898c-e5ba4f5d43fe.png)）来生成并获得平均奖励。
- en: 'Therefore, the definition of ![](img/68e90681-3d82-4476-84d9-ec342c6a7d4f.png) is
    as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，![](img/68e90681-3d82-4476-84d9-ec342c6a7d4f.png) 的定义如下：
- en: '![](img/5716dd43-c145-4ce2-9891-57ac1383612d.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5716dd43-c145-4ce2-9891-57ac1383612d.png)'
- en: 'The generator network is an LSTM network with an embedding layer as an input
    layer and a linear layer as an output layer. The discriminator network consists
    of an embedding layer, a convolution layer, a max-pooling layer, and a softmax
    layer. The code that was published by the authors of this paper was written for
    TensorFlow. Luckily, a PyTorch version can be found on GitHub at [https://github.com/suragnair/seqGAN](https://github.com/suragnair/seqGAN).
    In this version, two differences should be noted: first, the Monte Carlo simulation
    is only performed once, and second, the discriminator network is also a recurrent
    network and a variant of LSTM called **Gated Recurrent Unit** (**GRU**) is used
    in both networks. Feel free to adjust the network architectures and try out the
    tricks and techniques we have learned in the previous chapters of this book. Our
    modified code is also available under the `seqgan` folder in the code repository
    for this chapter.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器网络是一个 LSTM 网络，输入层是一个嵌入层，输出层是一个线性层。判别器网络由一个嵌入层、一个卷积层、一个最大池化层和一个 softmax 层组成。本文作者发布的代码是为
    TensorFlow 编写的。幸运的是，在 GitHub 上可以找到 PyTorch 版本，链接为 [https://github.com/suragnair/seqGAN](https://github.com/suragnair/seqGAN)。在这个版本中，有两个需要注意的区别：首先，蒙特卡洛模拟只执行一次；其次，判别器网络也是一个递归网络，并且在两个网络中使用了一种叫做
    **门控递归单元**（**GRU**）的 LSTM 变体。您可以自由地调整网络架构，尝试我们在本书前几章中学到的技巧和方法。我们修改后的代码也可以在本章的代码库中的
    `seqgan` 文件夹下找到。
- en: Creating your own vocabulary for training
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建您自己的词汇表用于训练
- en: Reading code that's been written by someone else in GitHub is easy. The most
    important thing we need to do is apply the models we know to new applications
    and create our own samples. Here, we will walk through the basic steps of creating
    a vocabulary from a huge collection of text and use it to train our NLP models.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读别人写的 GitHub 上的代码是很容易的。我们需要做的最重要的事情是将我们已知的模型应用到新的应用中，并创建我们自己的样本。在这里，我们将通过一些基本步骤来创建一个从大量文本中提取的词汇表，并用它来训练我们的
    NLP 模型。
- en: In the NLP model, a vocabulary set is normally a table that maps each word or
    symbol to a unique token (typically, an `int` value) so that any sentence can
    be represented by a vector of `int`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在 NLP 模型中，词汇集通常是一个表，将每个单词或符号映射到一个唯一的标记（通常是 `int` 值），这样任何句子都可以通过一个 `int` 向量来表示。
- en: First, let's find some data to play with. To get started, here's a list of NLP
    datasets available on GitHub: [https://github.com/niderhoff/nlp-datasets](https://github.com/niderhoff/nlp-datasets).
    From this list, you will find an English joke dataset ([https://github.com/taivop/joke-dataset](https://github.com/taivop/joke-dataset))
    that contains more than 200,000 jokes parsed from Reddit ([https://www.reddit.com/r/jokes](https://www.reddit.com/r/jokes)),
    Stupid Stuff ([stupidstuff.org](http://stupidstuff.org/)), and Wocka ([wocka.com](http://wocka.com/)). 
    The joke text will be in three different files (`reddit_jokes.json`, `stupidstuff.json`,
    and `wocka.json`). Please don't hold us responsible for the content of these jokes!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们找一些数据来处理。为了开始，以下是GitHub上可用的NLP数据集列表：[https://github.com/niderhoff/nlp-datasets](https://github.com/niderhoff/nlp-datasets)。在这个列表中，你会找到一个包含英语笑话数据集（[https://github.com/taivop/joke-dataset](https://github.com/taivop/joke-dataset)），该数据集包含超过200,000条从Reddit（[https://www.reddit.com/r/jokes](https://www.reddit.com/r/jokes)）、Stupid
    Stuff（[stupidstuff.org](http://stupidstuff.org/)）和Wocka（[wocka.com](http://wocka.com/)）提取的笑话。笑话文本会分布在三个不同的文件中（`reddit_jokes.json`、`stupidstuff.json`和`wocka.json`）。请注意，我们对这些笑话的内容不负任何责任！
- en: Now, let's create our vocabulary. First, create a folder named `data` in the
    project code folder and copy the aforementioned files into it.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建我们的词汇表。首先，在项目的代码文件夹中创建一个名为`data`的文件夹，并将之前提到的文件复制到其中。
- en: 'Now, let''s create a small program so that we can parse the JSON files and
    put them in CSV format. Let''s call it `parse_jokes.py`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个小程序，以便我们能解析JSON文件并将其转换为CSV格式。我们称之为`parse_jokes.py`：
- en: '[PRE0]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: I'm sure that the import section entries are obvious. The definitions of the
    constants should be fairly obvious as well. The headers variable is simply a list
    of the column names that will be used when we create the CSV file.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信导入部分的条目是显而易见的。常量的定义也应该相当清晰。`headers`变量只是我们在创建CSV文件时使用的列名列表。
- en: 'We want all of the jokes that will be stored in our files to be in plain text.
    To do this, get rid of all the non-letter symbols. This is done by cleaning the
    text using `clean_str()`, which uses Python''s `str_translate` parameter, as shown
    here:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望将所有的笑话存储为纯文本格式。为此，首先去除所有非字母符号。这个操作是通过使用`clean_str()`来清理文本完成的，`clean_str()`使用了Python的`str_translate`参数，具体如下所示：
- en: '[PRE1]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Feel free to tweak the `filters` string so that you can add or remove any special
    characters. The next function will read one of our three JSON files and return
    it as a JSON object. I''ve made it rather generic, so that the only thing it needs
    to know about is the filename to deal with:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 随意调整`filters`字符串，以便可以添加或删除任何特殊字符。下一个函数将读取我们三个JSON文件中的一个，并将其返回为JSON对象。我将其做得相当通用，因此它只需要知道要处理的文件名：
- en: '[PRE2]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, we''ll create three functions that will handle converting the three JSON
    objects into CSV files. It is important to remember that none of the three JSON
    files have the same structure. Due to this, we''ll make all three handler functions
    fairly similar and handle the differences between them at the same time. Each
    of the functions will take the JSON object that was created by the `get_data`
    function, as well as an integer value called `startcount`. This will provide a
    row number for the CSV file.  This value will be incremented for each line in
    the JSON object. Then, we will create a dictionary out of each piece of data and
    write it to the CSV file.  Finally, we will return our counter so that the next
    function knows what the row value should be. This is the function that will handle
    the Reddit file:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建三个函数，用来处理将这三个JSON对象转换为CSV文件。需要注意的是，三个JSON文件的结构都不同。因此，我们会让这三个处理函数大致相似，并在处理它们之间的差异时同时进行调整。每个函数都会接收由`get_data`函数创建的JSON对象以及一个名为`startcount`的整数值。这个值为CSV文件提供行号，并会在每一行中递增。然后，我们会将每一条数据转换为字典，并写入CSV文件。最后，我们会返回计数器，以便下一个函数知道行号应该是多少。这是处理Reddit文件的函数：
- en: '[PRE3]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we have the other two functions: one for the `StupidStuff` file and the
    other for the `Wocka` file:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有另外两个函数：一个用于处理`StupidStuff`文件，另一个用于处理`Wocka`文件：
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The second to last function will create the actual CSV file and write the header:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 倒数第二个函数将创建实际的CSV文件并写入表头：
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, we have the main function and the entry point for the program. Here,
    we will call the preceding functions in any order we like:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有程序的主函数和入口点。在这里，我们可以按任何顺序调用之前的函数：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, all we have to do is run the script:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们要做的就是运行脚本：
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: When we're finished, the joke text will be stored in the `jokes.csv` file. Now,
    we need to use TorchText to build the vocabulary. TorchText ([https://github.com/pytorch/text](https://github.com/pytorch/text))
    is a data loading tool for NLP that works directly with PyTorch.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，笑话文本将存储在`jokes.csv`文件中。现在，我们需要使用TorchText来构建词汇表。TorchText（[https://github.com/pytorch/text](https://github.com/pytorch/text)）是一个直接与PyTorch配合使用的NLP数据加载工具。
- en: '**Note for Windows 10 users**:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**Windows 10用户注意**：'
- en: At the time of writing this book, there appears to be an issue in `torchtext\utils.py`.
    If you install the `torchtext` package directly from PyPi, you could run into
    an error while trying to execute some of the code.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在写这本书时，`torchtext\utils.py`似乎存在一个问题。如果你直接从PyPi安装`torchtext`包，你可能会在执行某些代码时遇到错误。
- en: 'The best way around this is to head over to the GitHub source repository ([https://github.com/pytorch/text](https://github.com/pytorch/text))
    and download the source code. Then, unpack the code into a safe folder. In Command
    Prompt, navigate to the folder that contains the source code and enter the following
    command to install the library:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的解决方法是访问GitHub源代码仓库（[https://github.com/pytorch/text](https://github.com/pytorch/text)），并下载源代码。然后，将代码解压到一个安全的文件夹中。在命令提示符中，导航到包含源代码的文件夹，并输入以下命令安装库：
- en: '`pip install -e .`'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`pip install -e .`'
- en: This will install torchtext directly from the source code.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这将直接从源代码安装torchtext。
- en: 'For other OS, you can install it with the following command:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他操作系统，你可以使用以下命令安装：
- en: '[PRE8]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Please make sure that you have installed the latest version of `torchtext` (0.4.0,
    at the time of writing this book); otherwise, the code we will use later may not
    work for you. If `pip` doesn't install the latest version for you, you can find
    the `whl` file at [https://pypi.org/project/torchtext/#files](https://pypi.org/project/torchtext/#files)
    and install it manually.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保你已安装`torchtext`的最新版本（本书撰写时为0.4.0）；否则，我们稍后使用的代码可能无法正常工作。如果`pip`无法为你安装最新版本，你可以在[https://pypi.org/project/torchtext/#files](https://pypi.org/project/torchtext/#files)找到`whl`文件，并手动安装。
- en: 'We will use the default vocab tool provided by `torchtext` for this. You can
    also try using `spaCy` ([https://spacy.io](https://spacy.io)) if you want to build
    vocab for more complex NLP tasks. Create a new file and call it `mymain.py`. Start
    by adding the following code to it:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`torchtext`提供的默认词汇工具来实现这一点。如果你希望为更复杂的NLP任务构建词汇表，也可以尝试使用`spaCy`（[https://spacy.io](https://spacy.io)）。创建一个新文件并命名为`mymain.py`。首先在其中添加以下代码：
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `datafields` structure describes the CSV file we just created. Each column
    in the file is described and the only column we want the `torchtext` library to
    be concerned with is the `'Joke'` column, so we mark that as `'src'` and all the
    other columns as `'None'`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`datafields`结构描述了我们刚刚创建的CSV文件。文件中的每一列都会被描述，而我们希望`torchtext`库关注的唯一列是`''Joke''`列，因此我们将其标记为`''src''`，其他所有列标记为`''None''`。'
- en: 'Now, we will create the dataset object and start to build a vocabulary object:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将创建数据集对象并开始构建词汇表对象：
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We''ll use the `torchtext` library''s `BucketIterator` to go through the data
    in the dataset and create sequences of equal length:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`torchtext`库中的`BucketIterator`来遍历数据集中的数据，并创建相同长度的序列：
- en: '[PRE11]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now that we''ve built our vocabulary, we need to build a small data loader
    that will feed the batch data into SeqGAN during training:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经构建了词汇表，接下来我们需要构建一个小型数据加载器，在训练过程中将批量数据输入到SeqGAN中：
- en: '[PRE12]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We also need a mapping from tokens back to words so that we can see the generated
    text when the training process is complete:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一个从标记到单词的映射，以便在训练过程完成后看到生成的文本：
- en: '[PRE13]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, our vocabulary is stored in `src.vocab`. `src.vocab.stoi` is a Python
    `defaultdict` that maps words to `int` values. The last line in the preceding
    code snippet inverses the dictionary and stores the mappings from the `int` values
    as words in `inv_vocab`.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们的词汇表存储在`src.vocab`中。`src.vocab.stoi`是一个Python的`defaultdict`，它将单词映射到`int`值。在前面的代码片段中的最后一行，字典被反转，并将从`int`值到单词的映射存储在`inv_vocab`中。
- en: 'You can test the vocabulary with the following code:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下代码测试词汇表：
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If you''re curious, you can view the contents of `inv_vocab` by adding the
    following code after the preceding code:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣，可以通过在前面代码后添加以下代码来查看`inv_vocab`的内容：
- en: '[PRE15]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'However, remember that around 5,000 lines will be printed, so it will be a
    long list:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，记住大约会打印出5000行，所以它将是一个很长的列表：
- en: '[PRE16]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now, we need to work on the rest of the SeqGAN program. This includes the generator
    and the discriminator. As we mentioned in the *Architecture of SeqGAN* section,
    these modules can be found at [https://github.com/suragnair/seqGAN](https://github.com/suragnair/seqGAN).
    Download the source code and unpack it into a folder in your working directory.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要处理SeqGAN程序的其余部分。这包括生成器和判别器。正如我们在*SeqGAN架构*部分提到的，这些模块可以在[https://github.com/suragnair/seqGAN](https://github.com/suragnair/seqGAN)找到。下载源代码并将其解压到工作目录中的一个文件夹里。
- en: 'To train SeqGAN, run the following script under the code folder:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要训练SeqGAN，请在代码文件夹下运行以下脚本：
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The generator network is pretrained with **Maximum Likelihood Estimation** (**MLE**)
    against the real data for 100 epochs so that it will be trained faster later.
    Then, the discriminator network is pretrained against real data and some generated
    data for 150 epochs, in which the generated data is kept the same for every three
    epochs so that the discriminator becomes familiar with fake data. Finally, both
    networks are trained together in an adversarial fashion for 50 epochs, in which
    the discriminator network is trained 15 times more than the generator network.
    On a single GTX 1080Ti graphics card, the pretraining process takes about **33
    hours**, and 17 epochs of the final training can take long as **48 hours** to
    complete. GPU memory consumption is about 4,143 MB.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器网络通过**最大似然估计**（**MLE**）与真实数据进行预训练，训练100个周期，以便它在后续训练中更快。然后，判别器网络对真实数据和一些生成的数据进行150个周期的预训练，其中生成的数据每三个周期保持相同，以便判别器熟悉假数据。最后，两个网络以对抗方式共同训练50个周期，在这个过程中，判别器网络的训练次数是生成器网络的15倍。在一张GTX
    1080Ti显卡上，预训练过程大约需要**33小时**，最终训练的17个周期可能需要**48小时**才能完成。GPU内存消耗大约是4,143 MB。
- en: The following are some of the jokes that were generated by SeqGAN. Unfortunately,
    most of the sentences don't make sense due to mode collapse (which means that
    the same random word will appear anywhere in the sentences in one batch).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些由SeqGAN生成的笑话。不幸的是，由于模式崩溃（这意味着在一个批次的句子中，相同的随机单词会出现在任何地方），大多数句子都没有意义。
- en: 'Still, let''s take a look. Note that sentences shorter than `MAX_SEQ_LEN` are
    filled with `<pad>` at the end and have been omitted here:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一下。请注意，短于`MAX_SEQ_LEN`的句子会在末尾填充`<pad>`，并在此处省略：
- en: '"have you ever make like a tomato of jokes ? . there d call out of vegetables
    !"'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '"你有没有像番茄一样讲笑话？。他们会把蔬菜叫出来！"'
- en: '"the patriots weren''t invited camping ! . because i can rather have been born
    in tents ."'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '"爱国者队没有被邀请去露营！因为我宁愿出生在帐篷里。"'
- en: '"trainees. it is a train for christmas pockets"'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '"学员们。它是为圣诞口袋准备的火车"'
- en: '"what do you get when you cross a kangaroo and a rhino ? . spanish"'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '"当你把袋鼠和犀牛混在一起会得到什么？。西班牙语"'
- en: 'The following sentences were generated by the model:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下句子是由模型生成的：
- en: '"i can''t stop a joke . . . . it''s all ."'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '"我忍不住笑话。。。这都是。。。"'
- en: '"i can''t see a new joke ."'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '"我看不见一个新笑话。"'
- en: Our model also created some jokes that were too inappropriate to print, which
    is an interesting demonstration of its attempt to emulate human humor!
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型还生成了一些过于不合适的笑话，无法发布，这也有趣地展示了它模仿人类幽默的尝试！
- en: Speech quality enhancement with SEGAN
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SEGAN进行语音质量增强
- en: In [Chapter 7](c9fec01a-2b58-4de3-a62d-da11928e5afe.xhtml), *Image Restoration
    with GANs*, we explored how GANs can restore some of the pixels in images. Researchers
    have found a similar application in NLP where GANs can be trained to get rid of
    the noises in audio in order to enhance the quality of the recorded speeches.
    In this section, we will learn how to use SEGAN to reduce background noise in
    the audio and make the human voice in the noisy audio more audible.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](c9fec01a-2b58-4de3-a62d-da11928e5afe.xhtml)，*使用GAN进行图像恢复*中，我们探讨了GAN如何恢复图像中的一些像素。研究人员在自然语言处理领域发现了类似的应用，GAN可以训练去除音频中的噪声，从而增强录音演讲的质量。在本节中，我们将学习如何使用SEGAN减少音频中的背景噪声，并使嘈杂音频中的人声更加清晰可听。
- en: SEGAN architecture
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SEGAN架构
- en: '**Speech Enhancement GAN** (**SEGAN**) was proposed by Santiago Pascual, Antonio
    Bonafonte, and Joan Serrà in their paper, *SEGAN: Speech Enhancement Generative
    Adversarial Network*. It uses 1D convolutions to successfully remove noise from
    speech audio. You can check out the noise removal results compared to other methods
    here at [http://veu.talp.cat/segan](http://veu.talp.cat/segan). There''s also
    an upgraded version, which can be found at [http://veu.talp.cat/seganp](http://veu.talp.cat/seganp).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**语音增强 GAN** (**SEGAN**) 是由 Santiago Pascual、Antonio Bonafonte 和 Joan Serrà
    在他们的论文《*SEGAN: 语音增强生成对抗网络*》中提出的。它使用一维卷积成功去除语音音频中的噪声。你可以在这里查看与其他方法相比的噪声去除结果：[http://veu.talp.cat/segan](http://veu.talp.cat/segan)。此外，还有一个升级版，可以在[http://veu.talp.cat/seganp](http://veu.talp.cat/seganp)找到。'
- en: Images are two-dimensional, while sounds are one-dimensional. Considering GANs
    are so good at synthesizing 2D images, it is rather obvious to consider using
    1D convolution layers instead of 2D convolutions in order to harness the power
    of GANs when it comes to synthesizing audio data. This is exactly how SEGAN is
    built.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图像是二维的，而声音是一维的。考虑到 GAN 在合成二维图像方面非常出色，因此显而易见的是，为了利用 GAN 在音频数据合成方面的优势，应考虑使用一维卷积层而非二维卷积层。这正是
    SEGAN 的构建方式。
- en: 'The generator network in SEGAN employs an architecture of **Encoder-Decoder** with
    skip connections, which you may be familiar with since we have already met other
    GANs that use a similar architecture (such as `pix2pixHD`). The architecture of
    the generator network is as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: SEGAN 中的生成器网络采用带有跳跃连接的**编码器-解码器**架构，你可能已经对这种架构比较熟悉，因为我们之前遇到过使用类似架构的其他 GAN（如
    `pix2pixHD`）。生成器网络的架构如下所示：
- en: '![](img/193453c0-4b63-4017-9e2a-53f9ef467039.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/193453c0-4b63-4017-9e2a-53f9ef467039.png)'
- en: Figure 10.3 Architecture of the generator network in SEGAN
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 SEGAN 中生成器网络的架构
- en: First, the audio samples are cropped to a fixed length of 16,384 and are passed
    through five of the layers of the 1D convolution with a kernel size of 31 and
    a stride size of 4\. The compressed 1,024 x 16 vector (ignoring the batch channel)
    is concatenated with the latent vector (that's 1,024 x 16 in size) so that it
    can be fed through another five transposed convolution layers. The feature maps
    with the same shape in the mirrored convolution and transposed convolution layers
    are connected with skip connections. This is because the basic structures of noisy
    and clean audio are pretty much the same and skip connections help the generator
    reconstruct the structure of enhanced audio a lot faster. Finally, a denoised
    audio sample with a length of 16,384 is generated.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，音频样本被裁剪为固定长度 16,384，并通过五个一维卷积层进行处理，卷积核大小为 31，步幅大小为 4。压缩后的 1,024 x 16 向量（忽略批次通道）与潜在向量（大小为
    1,024 x 16）连接在一起，以便通过另外五个反卷积层进行处理。镜像卷积层和反卷积层中形状相同的特征图通过跳跃连接连接在一起。这是因为噪声音频和干净音频的基本结构非常相似，跳跃连接可以帮助生成器更快地重构增强后的音频结构。最后，生成一个长度为
    16,384 的去噪音频样本。
- en: 'However, the discriminator network of SEGAN is a single encoder network since
    all we need from the discriminator is the fidelity score of the input audio. The
    architecture of the discriminator network is as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，SEGAN 的判别器网络是一个单一的编码器网络，因为我们从判别器中需要的只是输入音频的保真度得分。判别器网络的架构如下所示：
- en: '![](img/6800dd57-6543-465b-ad22-4184f8b5544f.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6800dd57-6543-465b-ad22-4184f8b5544f.png)'
- en: Figure 10.4 Architecture of the discriminator network in SEGAN
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4 SEGAN 中判别器网络的架构
- en: The noisy audio and the clean (real data or synthesized data) audio are concatenated
    together to form a 2 x 16,384 tensor, which is passed through five convolution
    layers and three fully-connected layers to get the final output, which indicates
    whether the clean audio is real or synthesized. In both networks, **Parametric
    ReLU** (**PReLU**) is used as an activation function in hidden layers.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声音频和干净（真实数据或合成数据）音频被连接在一起，形成一个 2 x 16,384 的张量，然后通过五个卷积层和三个全连接层得到最终输出，指示干净音频是来自真实数据还是合成数据。在两个网络中，**参数化
    ReLU** (**PReLU**) 被用作隐藏层的激活函数。
- en: Training SEGAN to enhance speech quality
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练 SEGAN 提升语音质量
- en: 'Training SEGAN isn''t much different from training a normal image-synthesizing
    GAN. The training process of SEGAN is as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 SEGAN 与训练普通的图像合成 GAN 并没有太大区别。SEGAN 的训练过程如下：
- en: '![](img/b81b6510-8f7b-4cae-8bb6-8a469e0d2c59.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b81b6510-8f7b-4cae-8bb6-8a469e0d2c59.png)'
- en: Figure 10.5 The training process of SEGAN. Networks that are updated in each
    stage are marked with red boundaries. Here, `c*` denotes real clean audio, `n`
    denotes noisy audio, and `c` denotes synthesized clean audio.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 SEGAN的训练过程。每个阶段更新的网络用红色边框标出。这里，`c*`表示真实的清晰音频，`n`表示噪声音频，`c`表示合成的清晰音频。
- en: First, the clean audio and the noisy audio from the training data are fed into
    the discriminator network to calculate MSE loss. The synthesized audio that's
    generated by the generator, as well as the noisy audio, are also fed into the
    discriminator network. In this stage, the discriminator network is trained to
    be better at knowing the difference between real and synthesized clean audio.
    Then, the generated audio is used to fool the discriminator (by minimizing the
    MSE loss against 1) so that our generator network will get better at synthesizing
    realistic clean audio. Also, the L1 loss between the synthesized audio (`c*`)
    and real audio is calculated (with a scale factor of 100) to force the two to
    have similar basic structures. RMSprop is used as an optimization method in which
    the learning rate is set to a very small value (for example, ![](img/6e06c8fc-847e-4e9f-ad07-156b2dd74463.png)).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，将来自训练数据的清晰音频和噪声音频输入到判别网络中以计算MSE损失。由生成器生成的合成音频以及噪声音频也会输入到判别网络。在这一阶段，判别网络将被训练得更好，以便区分真实音频和合成的清晰音频。然后，生成的音频被用来欺骗判别器（通过最小化MSE损失以接近1），以使得我们的生成器网络在合成真实清晰音频方面表现得更好。同时，计算合成音频(`c*`)和真实音频之间的L1损失（乘以100的缩放因子），以强制这两者具有相似的基本结构。使用RMSprop作为优化方法，并将学习率设置为非常小的值（例如，![](img/6e06c8fc-847e-4e9f-ad07-156b2dd74463.png))。
- en: Now, let's get some audio data and see what SEGAN can do. A paired clean-noisy
    audio dataset is available here: [https://datashare.is.ed.ac.uk/handle/10283/1942](https://datashare.is.ed.ac.uk/handle/10283/1942).
    We need to download both the clean and noisy 48 kHz speech training sets. The
    `clean` dataset is about 822 MB in size while the `noisy` dataset is about 913
    MB in size. There are 11,572 pieces of speech inside both sets, most of which
    are single lines of English spoken by humans. The `noisy` audio is contaminated
    by several people speaking simultaneously.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们获取一些音频数据，看看SEGAN能做什么。这里有一个配对的清晰-噪声音频数据集：[https://datashare.is.ed.ac.uk/handle/10283/1942](https://datashare.is.ed.ac.uk/handle/10283/1942)。我们需要下载清晰和噪声的48
    kHz语音训练集。`clean`数据集大小约为822 MB，而`noisy`数据集大小约为913 MB。两个数据集内共有11,572段语音，大多数是人类说的单句英语。`noisy`音频是由几个人同时说话造成的噪音污染。
- en: 'The source code of SEGAN for PyTorch has been kindly provided by the authors
    of the paper: [https://github.com/santi-pdp/segan_pytorch](https://github.com/santi-pdp/segan_pytorch).
    Follow these steps to prepare your code and start training SEGAN:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: SEGAN的PyTorch源代码已由论文的作者提供：[https://github.com/santi-pdp/segan_pytorch](https://github.com/santi-pdp/segan_pytorch)。按照以下步骤准备代码并开始训练SEGAN：
- en: 'Run the following script to get the code and install the prerequisites:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下脚本以获取代码并安装所需的依赖：
- en: '[PRE18]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'An additional tool called `ahoproc_tools` ([https://github.com/santi-pdp/ahoproc_tools](https://github.com/santi-pdp/ahoproc_tools))
    is also required. We need to download the source code of `ahoproc_tools` and copy
    the `ahoproc_tools` inside it into the root folder of `segan_pytorch`. Alternatively,
    you can access the full source code inside the code repository for this chapter
    directly. You need to run the following script to make sure that all the submodules
    have been downloaded:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还需要一个额外的工具`ahoproc_tools`（[https://github.com/santi-pdp/ahoproc_tools](https://github.com/santi-pdp/ahoproc_tools)）。我们需要下载`ahoproc_tools`的源代码，并将其中的`ahoproc_tools`复制到`segan_pytorch`的根文件夹中。或者，你也可以直接访问本章代码库中的完整源代码。你需要运行以下脚本以确保所有子模块已被下载：
- en: '[PRE19]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Extract the `.wav` files from the downloaded `.zip` dataset files and move them
    into the `data/clean_trainset_wav` and `data/noisy_trainset_wav` folders, respectively.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从下载的`.zip`数据集文件中提取`.wav`文件，并将它们分别移动到`data/clean_trainset_wav`和`data/noisy_trainset_wav`文件夹中。
- en: 'Finally, run the following script to start the training process:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，运行以下脚本以开始训练过程：
- en: '[PRE20]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: First, the training script will create a cache folder (`data/cache`) where it
    will temporarily store the slicing results of the audio files (because we want
    the inputs of both networks to be 16,384 in length).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，训练脚本将创建一个缓存文件夹（`data/cache`），并将音频文件的切片结果临时存储在其中（因为我们希望两个网络的输入长度为16,384）。
- en: With a batch size of 300, it takes about 10.7 hours to finish 100 epochs of
    training on a single GTX 1080Ti graphics card and costs about 10,137 MB of GPU
    memory.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在批量大小为300时，使用一块GTX 1080Ti显卡完成100个epoch的训练大约需要10.7小时，并消耗约10,137 MB的GPU内存。
- en: 'Once the training process has finished, run the following script to test the
    trained model and remove the background noises from any audio file that''s put
    inside the `data/noisy_testset` folder:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程完成后，运行以下脚本测试训练好的模型，并从放入 `data/noisy_testset` 文件夹中的任何音频文件中去除背景噪声：
- en: '[PRE21]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Summary
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned how to generate plain text with SeqGAN and remove
    background noises in speech audio with SEGAN. We also experimented with how to
    build a custom vocabulary from a collection of sentences for NLP tasks.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们学习了如何使用SeqGAN生成纯文本，并使用SEGAN去除语音音频中的背景噪声。我们还尝试了如何从一组句子中构建自定义词汇表，以应对NLP任务。
- en: In the next chapter, we will learn how to train GANs so that we can directly
    generate 3D models.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何训练GANs，以便直接生成3D模型。
- en: Further reading
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Yu L, Zhang W, Wang J. (2017). *SeqGAN: Sequence Generative Adversarial Nets
    with Policy Gradient*. AAAI.'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Yu L, Zhang W, Wang J. (2017). *SeqGAN：带策略梯度的序列生成对抗网络*. AAAI。
- en: Hochreiter S and Schmidhuber J. (1997). *Long Short-Term Memory. Neural computation*.
    9\. 1735-80\. 10.1162/neco.1997.9.8.1735.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hochreiter S 和 Schmidhuber J. (1997). *长短期记忆。神经计算*. 9. 1735-80. 10.1162/neco.1997.9.8.1735。
- en: Olah C. (Aug 27, 2015). *Understanding LSTM Networks*. Retrieved from [https://colah.github.io/posts/2015-08-Understanding-LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs).
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Olah C. (2015年8月27日). *理解LSTM网络*. 取自 [https://colah.github.io/posts/2015-08-Understanding-LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs)。
- en: 'Nguyen M. (Sep 25, 2018). *Illustrated Guide to LSTMs and GRUs: A step by step
    explanation*. Retrieved from [https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21).'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Nguyen M. (2018年9月25日). *LSTMs和GRUs插图指南：一步一步的解释*. 取自 [https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)。
- en: Hui J. (Sep 12, 2018). *RL – Policy Gradient Explained*. Retrieved from [https://medium.com/@jonathan_hui/rl-policy-gradients-explained-9b13b688b146](https://medium.com/@jonathan_hui/rl-policy-gradients-explained-9b13b688b146).
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hui J. (2018年9月12日). *RL - 策略梯度解释*. 取自 [https://medium.com/@jonathan_hui/rl-policy-gradients-explained-9b13b688b146](https://medium.com/@jonathan_hui/rl-policy-gradients-explained-9b13b688b146)。
- en: Weng L. (Apr 8, 2018). *Policy Gradient Algorithms*. Retrieved from [https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html](https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html).
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Weng L. (2018年4月8日). *策略梯度算法*. 取自 [https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html](https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html)。
- en: 'Pascual S, Bonafonte A and Serrà J. (2017). *SEGAN: Speech Enhancement Generative
    Adversarial Network*. INTERSPEECH.'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pascual S, Bonafonte A 和 Serrà J. (2017). *SEGAN：语音增强生成对抗网络*. INTERSPEECH。
