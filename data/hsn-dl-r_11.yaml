- en: Generative Adversarial Networks for Faces
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于面部的生成对抗网络
- en: In the last chapter, we used a **long short-term memory** (**LSTM**) model on
    a time-series forecasting task. In this chapter, we will create a generator model,
    which means the model will not output predictions but rather files (in this case,
    images). We created a generator model in [Chapter 7](a000fdb8-7d3e-436b-abd9-9fbc9b3c33f0.xhtml), *Deep
    Learning for Natural Language Processing*; however, in that case, we just generated
    latent features. Here, we will describe the main components and applications of
    **generative adversarial networks** (**GANs**). You will learn about the common
    applications of GANs and how to build a face generation model using a GAN.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们在时间序列预测任务中使用了**长短期记忆**（**LSTM**）模型。在本章中，我们将创建一个生成器模型，这意味着该模型将不会输出预测结果，而是输出文件（在此案例中为图像）。我们在[第7章](a000fdb8-7d3e-436b-abd9-9fbc9b3c33f0.xhtml)，*深度学习与自然语言处理*中创建了生成器模型；然而，在那个案例中，我们仅生成了潜在特征。在这里，我们将描述**生成对抗网络**（**GANs**）的主要组件和应用。你将了解GAN的常见应用，并学习如何使用GAN构建面部生成模型。
- en: Over the course of this chapter, we will investigate the architecture of a GAN.
    A GAN is composed of two competing neural networks, one of which is known as the
    **generator model**. It takes random data and creates synthetic target data. The
    other part of a GAN is the **discriminator model**. This model takes two pieces
    of input—the synthetic target data and the real target data—and it determines
    which is the real target data. After understanding this process, we will code
    our own GAN model for face recognition and generation using the Keras package
    and images from the *labeled faces in the wild* dataset.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨GAN的架构。GAN由两个相互竞争的神经网络组成，其中一个被称为**生成器模型**。它接受随机数据并生成合成目标数据。GAN的另一个部分是**判别器模型**。该模型接受两种输入——合成目标数据和真实目标数据——并判断哪一个是真实的目标数据。理解这一过程后，我们将使用Keras包和来自*标注面孔数据集*的图像来编写我们自己的面部识别和生成的GAN模型代码。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: An overview of GANs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GAN概述
- en: Defining the generator model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义生成器模型
- en: Defining the discriminator model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义判别器模型
- en: Preparing and preprocessing a dataset
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备和预处理数据集
- en: Training and evaluating a model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和评估模型
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You can find the code files used in this chapter at the following GitHub link:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下GitHub链接中找到本章使用的代码文件：
- en: '[https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R](https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R](https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R)'
- en: An overview of GANs
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN概述
- en: A GAN is a modeling algorithm that pits two neural networks against each other.
    One of them uses random data to create output. The other evaluates the real target
    data and the generated output and determines which is real. Over time, the first
    neural network creates better fake target data and the second neural network continues
    to try and determine which is the real target data. The two neural networks continue
    to compete and the models both improve to create increasingly realistic synthetic
    data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: GAN是一种将两个神经网络相互对抗的建模算法。其中一个使用随机数据生成输出，另一个评估真实目标数据与生成的输出，并判断哪一个是实际的。随着时间的推移，第一个神经网络生成更好的伪目标数据，而第二个神经网络则继续尝试判断哪个是真实的目标数据。这两个神经网络不断竞争，模型也不断改进，以生成越来越逼真的合成数据。
- en: Breaking down the term, we can see how this modeling technique differs from
    others. First, it is generative, which means that the goal is to generate data.
    This is in contrast to other models, such as classification or regression, that
    predict probabilities or values. Next, it is adversarial. That is, there are two
    models that are set to compete against each other. Generally, we have one model
    and it trains on data that can be evaluated and improved using a variety of metrics.
    However, in this case, we have one model that seeks to improve prediction performance
    and that is the discriminator model. In addition, we have another model that creates
    fake images to try to reduce the performance of the discriminator model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 解析这个术语，我们可以看到这种建模技术与其他技术的区别。首先，它是生成性的，这意味着目标是生成数据。这与其他模型（如分类或回归模型）不同，后者预测概率或数值。接下来，它是对抗性的。也就是说，存在两个模型，它们彼此对抗。通常，我们有一个模型，它在可评估的数据上进行训练，并使用各种度量来改进性能。然而，在这种情况下，我们有一个模型，旨在提高预测性能，它是判别器模型。此外，我们还有另一个模型，它创建虚假图像，试图降低判别器模型的性能。
- en: 'We generally think of two main categories for machine learning:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常将机器学习分为两大类：
- en: '**Supervised learning**: Where the model uses labeled target data to make predictions'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**：模型使用标注的目标数据来进行预测'
- en: '**Unsupervised learning**: Where the model identifies patterns without any
    labeled target data'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**：模型在没有任何标注目标数据的情况下识别模式'
- en: However, we can get even more granular with unsupervised learning. GANs belong
    to a special subset of unsupervised learning that uses learned patterns from unlabeled
    data to generate synthetic data, rather than just classifying the data. However,
    this introduces a problem for us. Since the goal is to generate data, there are
    no direct metrics we can use to evaluate the performance. The relative success
    or failure of a GAN model is based largely on the subjective interpretation of
    the output.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们可以通过无监督学习进一步细化。GAN属于无监督学习的一个特殊子集，它使用从未标注数据中学到的模式来生成合成数据，而不仅仅是对数据进行分类。然而，这为我们带来了一个问题。由于目标是生成数据，因此没有直接的度量可以用来评估性能。GAN模型的相对成功或失败主要取决于对输出的主观解释。
- en: 'For this GAN, we will use images as our input. All images can be represented
    as a matrix of values for grayscale images, or three matrices of values for color
    images. The values of the matrix range from `0` to `255` and correspond with the
    intensity of the pixel value at that location. For example, a pixel value of `255`
    means high intensity or black for a grayscale image and a value of `0` means low
    intensity or white. The dimensions of the matrix correspond with the pixel width
    and height of the image. Color images are represented as a three-dimensional array.
    This can be thought of as three matrices overlapping, with each corresponding
    to the intensity of the red, green, and blue pixel values for the image. Let''s
    take a look at a sample image and see how it is represented as a matrix of values.
    To do this, we will read in the following shape:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个GAN，我们将使用图像作为输入。所有图像都可以表示为灰度图像的值矩阵，或者彩色图像的三个值矩阵。这些矩阵的值范围从`0`到`255`，对应于该位置像素值的强度。例如，像素值为`255`表示高强度或黑色（对于灰度图像），而`0`表示低强度或白色。矩阵的维度对应于图像的像素宽度和高度。彩色图像表示为三维数组。这可以看作是三个矩阵重叠，每个矩阵对应于图像的红色、绿色和蓝色像素值的强度。让我们来看一张示例图像，并查看它如何表示为值的矩阵。为此，我们将读取以下形状：
- en: '![](img/87a19f79-255f-4257-8689-28a682e5f076.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/87a19f79-255f-4257-8689-28a682e5f076.png)'
- en: 'To read in this shape, we will use the `OpenImageR` package. This package reads
    the file in as a four-dimensional array. In this case, we only want the fourth
    dimension, which contains the grayscale values. To read in this file and then
    look at a small segment, we run the following code:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要以这种形状读取，我们将使用`OpenImageR`包。这个包将文件读取为一个四维数组。在这种情况下，我们只需要第四维，它包含灰度值。为了读取这个文件并查看一个小片段，我们运行以下代码：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After running this code, we will see the following printed to the console:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码后，我们将看到以下内容打印到控制台：
- en: '![](img/5f0f973f-de91-4e56-b295-b0d5e639b42b.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f0f973f-de91-4e56-b295-b0d5e639b42b.png)'
- en: We can see how these values represent the top of the left bell on the alarm
    clock. The zeroes are the white space and we see a gradient in the second rows
    and the top rows, showing the curve. In this way, we can see how images can be
    expressed as a matrix of values between `0` and `1`.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这些值表示了闹钟左侧铃铛的顶部。零值是白色空间，第二行和顶行显示出梯度，呈现曲线。通过这种方式，我们可以看到图像如何作为一个介于 `0` 和
    `1` 之间的值矩阵来表示。
- en: Defining the generator model
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义生成器模型
- en: 'The generator model is the neural network that creates synthetic target data
    out of random inputs. In this case, we will use a **convolutional neural network**
    (**CNN**) in reverse. What this means is that we will start with a vector of data
    points and create a fully connected layer, then reshape the data into the size
    that we want it to be. As a middle step, we will make the target shape only half
    the size and then we will upsample using a transposed convolution layer. In the
    end, we have an array of normalized pixel values that is the same shape as our
    target array. This then becomes the data object that will be used to try to fool
    the discriminator model. This array of synthetic values will, over time, be trained
    to resemble the values in the target data object so that the discriminator model
    cannot predict, with a high probability, which is the true data image. We will
    define the discriminator model using the following steps:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器模型是创建合成目标数据的神经网络，通过随机输入生成。在这种情况下，我们将反向使用 **卷积神经网络** (**CNN**) 。这意味着我们将从一个数据点向量开始，创建一个全连接层，然后将数据重塑为我们希望的尺寸。作为中间步骤，我们将目标形状设为原来的一半大小，然后使用转置卷积层进行上采样。最终，我们得到一个归一化的像素值数组，其形状与我们的目标数组相同。这个数组将成为用于试图欺骗判别器模型的数据对象。这个合成值的数组将随着时间的推移被训练，使其更像目标数据对象中的值，以至于判别器模型无法以高概率预测哪个是真实的数据图像。我们将使用以下步骤定义判别器模型：
- en: First, we will define that our entry point will be a 100-dimensional vector.
    Everything we do to define our models will be done with Keras. So, we load the
    Keras model at this step. We then define our input shape as a vector with 100
    values.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将定义我们的入口点是一个 100 维的向量。我们定义模型的所有操作都将使用 Keras 完成。所以，在此步骤中，我们加载 Keras 模型。接下来，我们将输入形状定义为一个包含
    100 个值的向量。
- en: 'Then, we will pass a vector to this model. In this step, we tell the model
    what we will be passing in the later step. Using the following code, we declare
    that the input to this model will be a vector with 100 values that we will later
    populate with random values:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将传递一个向量到这个模型中。在这个步骤中，我们告诉模型我们将在后续步骤中传递的内容。使用以下代码，我们声明该模型的输入将是一个包含 100 个值的向量，稍后我们会用随机值填充它：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After running this step, we can see that we have a special data object, called
    `Tensor`, in our data environment. The object contains the type, name, shape,
    and data type of the layer. Your data environment will look as in the following
    screenshot:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此步骤后，我们可以看到在数据环境中有一个特殊的数据对象，称为`Tensor`。该对象包含了层的类型、名称、形状和数据类型。你的数据环境将如下图所示：
- en: '![](img/b1b1edff-a48c-4d71-9b2c-596f14425005.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b1b1edff-a48c-4d71-9b2c-596f14425005.png)'
- en: 'After this, we define how our random values will be processed, transformed,
    and reshaped to create a synthetic array that matches our target arrays. The code
    to do this is long, but many of the parts are repeated. There are a few lines
    that are required while others can be modified. The `layer_dense` layer needs
    to contain the number of units that will appear later in the `layer_reshape` layer.
    In this case, we will create a shape that has a width and height of `25` and a
    depth of `128`. The depth is modifiable; however, the width and height must be
    set at half the size of the final image''s dimensions when using one transposed
    convolution layer, as follows:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此之后，我们定义如何处理、转换和重塑我们的随机值，以创建一个与目标数组匹配的合成数组。实现这一点的代码比较长，但其中许多部分是重复的。有一些行是必需的，而其他的可以修改。`layer_dense`
    层需要包含稍后在 `layer_reshape` 层中出现的单元数量。在这种情况下，我们将创建一个宽度和高度为 `25`、深度为 `128` 的形状。深度是可以修改的，但在使用一个转置卷积层时，宽度和高度必须设置为最终图像尺寸的一半，具体如下：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The `layer_conv_2d_transpose` layer uses a 2 x 2 stride to upsample and double
    the shape of the layer. In this step, the shape changes from 25 x 25 to 50 x 50:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`layer_conv_2d_transpose` 层使用 2 x 2 的步幅进行上采样，并将层的形状加倍。在此步骤中，形状从 25 x 25 变为
    50 x 50：'
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The convolution applies filters that look for patterns and the normalization
    takes the results of the convolution step and normalizes the values. So the mean
    is close to 0 and the standard deviation is close to 1, and ReLU is used as our
    activation function. We will add these layers after our dense layer and our convolution
    layer using the following code:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卷积层应用了寻找模式的过滤器，而归一化步骤则对卷积结果进行标准化处理。因此，均值接近0，标准差接近1，ReLU作为我们的激活函数。我们将在全连接层和卷积层后添加这些层，使用以下代码：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After this, we can continue to add additional convolution layers using the
    same pattern of convolution, normalization, and activation. Here, we will add
    four additional series of layers using the pattern we just described:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此之后，我们可以继续使用相同的卷积、归一化和激活模式，添加额外的卷积层。在这里，我们将添加四组额外的层，使用我们刚才描述的模式：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In the very last step, the `filters` argument needs to be set to the number
    of channels for the image—in this case, three for the red, green, and blue channels
    of a color image. This completes the definition of our generator model. The entire
    generator model is defined using the following code:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在最后一步，`filters`参数需要设置为图像的通道数——在这个例子中，对于彩色图像，它是三个通道：红色、绿色和蓝色。这完成了我们生成器模型的定义。整个生成器模型使用以下代码定义：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'After running this code, we will now see two objects in our environment. We
    have defined the connected tensors for input and the connected input for the output.
    Setting up our tensors in this way allows data to be input in batches using the
    `keras_model` function. Your data environment should look like the following now:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码后，我们将看到环境中出现两个对象。我们已经定义了输入的连接张量和输出的连接张量。以这种方式设置张量，使得数据可以通过`keras_model`函数批量输入。此时，您的数据环境应该如下所示：
- en: '![](img/e3087f68-2aa2-43f0-a2f2-8165b8996a54.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e3087f68-2aa2-43f0-a2f2-8165b8996a54.png)'
- en: After, we define that the input will be 100 random values and the output will
    be random values mapped to a data object with the same dimensions as our target
    image.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义输入为100个随机值，输出为映射到与目标图像尺寸相同的数据对象的随机值。
- en: We can then define `keras_model`, which takes the input and output as arguments,
    specifically. We pass in these defined tensor layers, at this point, to complete
    the definition of our model.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们可以定义`keras_model`，它专门接收输入和输出作为参数。此时，我们传入已定义的张量层，以完成模型的定义。
- en: 'After defining the model, we can run the `summary` function on the generator
    model to helpfully see what is happening to the data at each layer. We define
    our generator and view the summary using the following code:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在定义完模型后，我们可以在生成器模型上运行`summary`函数，帮助我们清楚地看到每一层的数据变化。我们使用以下代码定义生成器并查看其摘要：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After running the `summary` function, we will see details about our model printed
    to our console, which looks like this:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`summary`函数后，我们将看到模型的详细信息打印在控制台上，内容如下所示：
- en: '![](img/dbfce84e-5c01-4adc-a852-90182cc49caf.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dbfce84e-5c01-4adc-a852-90182cc49caf.png)'
- en: From the console output, we can see that we start with one fully connected layer
    and after numerous intermediate layers, we end up with a final layer that matches
    the shape of our target image data.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从控制台输出中，我们可以看到，首先是一个全连接层，经过若干中间层后，我们最终得到了一个与目标图像数据形状匹配的最后一层。
- en: We now have our generator completely defined. We have seen how we can insert
    random values and how those random values are then transformed to produce a synthetic
    image. The process of passing data to this model occurs later in the process.
    With a system in place to produce fake images, we now move on to defining the
    discriminator model, which will determine whether a given array of pixel data
    is a real or fake image.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经完全定义了我们的生成器。我们看到如何插入随机值，并且这些随机值如何转化为合成图像。将数据传递给此模型的过程稍后会进行。现在，已经有了生成假图像的系统，我们接下来定义判别器模型，判别器模型将确定给定的像素数据数组是真实图像还是假图像。
- en: Defining the discriminator model
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义判别器模型
- en: The discriminator model is the neural network that evaluates the synthetic target
    data and the real target data to determine which is the real one.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器模型是神经网络，用于评估合成目标数据和真实目标数据，从而确定哪个是真实的。
- en: 'The discriminator, in this case, is a CNN model; it takes a three-dimensional
    array as input. Often with CNNs, convolving layers and pooling layers are used
    to reshape the dimensions of the input—ultimately, to a fully connected layer.
    However, when using these layers to define a discriminator model in the context
    of creating a GAN, we instead use 2 x 2 strides in the convolving layers to reshape
    the input dimensions. In the end, a fully connected layer with one unit is passed
    through the sigmoid activation function to calculate the probability that a given
    input is real or fake. Let''s follow the following lines of code to define the
    discriminator model:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，判别器是一个 CNN 模型；它接受一个三维数组作为输入。通常，CNN 会使用卷积层和池化层来调整输入的维度——最终连接到一个全连接层。然而，在创建
    GAN 时，使用这些层来定义判别器模型时，我们在卷积层中使用 2 x 2 的步幅来调整输入的维度。最终，一个包含一个单元的全连接层会通过 sigmoid 激活函数，计算给定输入为真或假的概率。让我们按照以下代码行来定义判别器模型：
- en: 'As we did in the generator model, let''s start by defining the input shape.
    While the generator model started with a vector of 100 random values, our discriminator
    starts with input in the shape of our image data as that is what will be passed
    to the model. The dimensions for the image are used as arguments to define the
    input shape using the following code:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与生成器模型一样，我们先定义输入的形状。虽然生成器模型从一个包含 100 个随机值的向量开始，但我们的判别器从形状为图像数据的输入开始，因为这将被传递给模型。使用以下代码，通过图像的维度来定义输入形状：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Running this code adds another object to our data environment. Your Environment
    pane will now look as in the following screenshot:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行这段代码会向我们的数据环境中添加一个对象。你的环境面板现在会显示如下截图：
- en: '![](img/3f436752-c3cf-4c52-9257-e6e721ded803.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f436752-c3cf-4c52-9257-e6e721ded803.png)'
- en: 'Next, we process and transform our data. While the generator took a one-dimensional
    vector and created a three-dimensional array in the size of our image data, here
    we will do the opposite. We start with data that is in the shape of our image
    data as the first layer, as in the following code:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们处理并转换我们的数据。生成器将一维向量转换为我们图像数据大小的三维数组，而在这里我们将做相反的操作。我们从形状与图像数据相同的数据开始作为第一层，如以下代码所示：
- en: '[PRE9]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The next layer that we will add to the discriminator is an activation layer.
    For the discriminator, we will use a Leaky ReLU activation function. The activation
    layer is added after our first convolution layer so that our code now looks like
    the following:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将添加到判别器的下一个层是一个激活层。对于判别器，我们将使用 Leaky ReLU 激活函数。激活层在第一个卷积层之后添加，因此我们的代码现在如下所示：
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In our next convolution layer, we use strides of `2` to halve the height and
    width while doubling the depth:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的下一个卷积层中，我们使用 `2` 的步幅来减半高度和宽度，同时加倍深度：
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can now continue to add more layers, using the same sequence of convolution
    layers, to the Leaky ReLU activation layer. The constraint is that—as mentioned—at
    each layer, the height and width are halved and the depth is doubled, so the height
    and width dimensions need to be such that they can be halved, with the output
    containing whole numbers, or you will receive an error. In our case, we will add
    three more sequences of layers so that our code now looks like this:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以继续向 Leaky ReLU 激活层添加更多的层，使用相同的卷积层序列。约束条件是——如前所述——在每一层中，高度和宽度都会减半，而深度会加倍，因此高度和宽度的维度必须满足可以被减半且输出为整数，否则你将收到错误信息。在我们的例子中，我们将再添加三组层，因此我们的代码现在看起来如下所示：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We now need to add a layer to flatten our values to one dimension in preparation
    for our final output layer. When we add this layer, our code will look like the
    following:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要添加一个层，将我们的值展平成一维，为最终的输出层做准备。当我们添加此层时，我们的代码将如下所示：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'After this, we add a `dropout` layer that removes some data at random, which
    forces the model to work harder and slows down training, which produces a better
    generalizer. Adding this layer results in the following code:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们添加了一个 `dropout` 层，它随机删除一些数据，这迫使模型更加努力地工作，并且减缓了训练速度，从而产生更好的泛化能力。添加此层后的代码如下所示：
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Lastly, we add a `dense` layer with just `1` unit, representing the probability
    that an image is real or fake. Adding this last layer will complete our discriminator
    model. The final discriminator model is defined with the following code:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们添加了一个只有 `1` 个单元的 `dense` 层，表示图像是真实还是假的概率。添加此最后一层将完成我们的判别器模型。最终的判别器模型通过以下代码定义：
- en: '[PRE15]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'After running the code, there are now four defined tensors in our data environment.
    Your data environment will look as in the following screenshot:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 运行代码后，在数据环境中现在有四个已定义的张量。您的数据环境将像以下截图所示：
- en: '![](img/15ca4d53-c985-4a9a-86ce-ea978a3f6b8f.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/15ca4d53-c985-4a9a-86ce-ea978a3f6b8f.png)'
- en: 'After defining the input and output, both objects are passed as arguments to
    the `keras_model` function, as before, with the generator model. We define the
    discriminator model using the input and output definitions from the previous steps
    and then run the `summary` function to see the details of the model, using the
    following code:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在定义输入和输出后，这两个对象作为参数传递给`keras_model`函数，就像之前的生成器模型一样。我们使用来自前面步骤的输入和输出定义来定义判别器模型，然后运行`summary`函数查看模型的详细信息，使用以下代码：
- en: '[PRE16]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'After running the preceding code, you will have details about the model printed
    to your console. The output to your console will look as in the following screenshot:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行上述代码后，您将在控制台中看到模型的详细信息。控制台输出将像以下截图所示：
- en: '![](img/bdeb4ba8-60d2-492d-9077-403ea27f4b69.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bdeb4ba8-60d2-492d-9077-403ea27f4b69.png)'
- en: To view the details of our model, we can see the dimensions shifting as the
    input passes through convolution layers. We start with the input in the shape
    of our image data and at each layer, two dimensions are reduced while the third
    dimension is increased. In the end, we have one fully connected layer. We see
    that if we had added a few more convolution layers, we would have gotten to a
    point where we could no longer halve our data and still have a whole unit remaining.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了查看我们模型的详细信息，我们可以看到输入通过卷积层时，维度发生了变化。我们从形状与我们的图像数据相同的输入开始，在每一层，两个维度被减少，而第三个维度则增加。最终，我们得到一个全连接层。我们可以看到，如果我们再添加几个卷积层，我们将达到一个无法继续将数据减半而仍能保留完整单元的程度。
- en: 'During this step, we will also define our optimizer, which is how the model
    will pass data back to improve future iterations of the model. We will calculate
    performance using `binary_crossentropy` and then use the `adam` optimizer to feed
    data back to the model from the error rate gradients. We define how we evaluate
    and incrementally improve our discriminator model using the following code:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步中，我们还将定义优化器，优化器决定了模型如何通过反向传递数据来改进模型的未来迭代。我们将使用`binary_crossentropy`来计算性能，然后使用`adam`优化器将数据从误差率梯度反馈到模型中。我们使用以下代码定义如何评估并逐步改进我们的判别器模型：
- en: '[PRE17]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We now have our generator model and discriminator defined. These are the two
    main building blocks for our GAN. In the next step, we will load in the real images
    and show you how to convert the images to numeric data. This is the third and
    final piece that we need before we assemble everything together to train our GAN
    and begin generating synthetic images.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了生成器模型和判别器模型。这是我们GAN的两个主要构建块。在下一步中，我们将加载真实图像，并向您展示如何将图像转换为数字数据。这是我们组装所有内容并开始训练GAN，生成合成图像之前需要的第三个也是最后一个步骤。
- en: Preparing and preprocessing a dataset
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备和预处理数据集
- en: For this chapter, we will use a small subset of images from the labeled faces
    in the wild dataset. Specifically, we will use images of former United States
    president George W. Bush, since this is the image object that occurs most often
    in the dataset. Using the following code, we will bring in the image data and
    convert it to a format that can be inputted into our model. We start by loading
    the libraries and data files required.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将使用标注的“野外面部”数据集中一小部分的图像。具体来说，我们将使用前美国总统乔治·W·布什的图像，因为这是数据集中最常出现的图像对象。使用以下代码，我们将导入图像数据，并将其转换为可以输入到模型中的格式。我们首先加载所需的库和数据文件。
- en: Loading the libraries and data files
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载库和数据文件
- en: 'We will begin by using the following steps:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过以下步骤开始：
- en: 'First, we load all the libraries that we will use. We will use just one function
    from each of these libraries but we need each one to get our data in the proper
    format. The `jpeg` library will be used to read in the image data and store it
    as a matrix. The `purrr` package will be used to apply a function to our list
    of arrays. The `abind` package will be used to convert the list of arrays into
    one array. Finally, `OpenImageR` will be used to resize our data. We load all
    the libraries needed to bring in images and convert them to the proper format
    using the following code:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们加载所有需要使用的库。我们将从这些库中使用每个库的一个函数，但每个库都需要加载才能使我们的数据格式正确。`jpeg`库将用于读取图像数据并将其存储为矩阵。`purrr`包将用于对我们的数组列表应用函数。`abind`包将用于将数组列表转换为一个数组。最后，`OpenImageR`将用于调整我们的数据大小。我们通过以下代码加载所有必要的库，以便导入图像并将其转换为正确的格式：
- en: '[PRE18]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: After loading the libraries, the next step is to bring over all the image files.
    The first step in this process is to change the working directory, for convenience,
    to the folder containing all the image files.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载完库之后，接下来的步骤是导入所有图像文件。这个过程的第一步是将工作目录更改为包含所有图像文件的文件夹，以方便操作。
- en: Once you have navigated to this folder, use the `list.files` function to bring
    over a vector of all the filenames. Lastly, we use the `map()` function from the
    `purrr` package to perform functions on every element in our vector and pass the
    results to a list.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你进入到这个文件夹，使用`list.files`函数获取所有文件名的向量。最后，我们使用`purrr`包中的`map()`函数对向量中的每个元素执行函数，并将结果传递给列表。
- en: 'In this case, every element in our vector is a file path. We pass each file
    path as an argument to the `readJPEG` function from the `jpeg` package. This function
    returns an array for every image, with all the pixel values represented as normalized
    values between `0` and `1`. This is convenient because this is the format we want
    for our neural networks. As noted before, the pixel values are ordinarily stored
    as integers between `0` and `255`; however, values bound between `0` and `1` work
    better when planning to pass data through a neural network. We import our images,
    convert all the pixel values to normalized values between `0` and `1`, and store
    all the formatted image data in a list of arrays using the following code:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这种情况下，我们向量中的每个元素都是一个文件路径。我们将每个文件路径作为参数传递给`readJPEG`函数，该函数来自`jpeg`包。这个函数会为每个图像返回一个数组，所有的像素值都表示为介于`0`和`1`之间的归一化值。这非常方便，因为这是我们希望神经网络使用的格式。如前所述，像素值通常以`0`到`255`之间的整数存储；然而，将值限定在`0`和`1`之间，在将数据传递给神经网络时效果更好。我们导入图像，将所有的像素值转换为介于`0`和`1`之间的归一化值，并使用以下代码将所有格式化后的图像数据存储在一个数组列表中：
- en: '[PRE19]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After running the code, we now have the list of arrays in our data environment.
    If we expand the object, we can see a sample of pixel values for the images in
    this set. After expanding the data object in your environment, it will look as
    in the following screenshot:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行代码后，我们现在已经在数据环境中拥有了数组列表。如果我们展开该对象，我们可以看到该数据集中图像的像素值示例。展开数据对象后，它将在你的环境中呈现如下截图：
- en: '![](img/691d240f-f9c3-4e69-9a66-26e846a541a6.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/691d240f-f9c3-4e69-9a66-26e846a541a6.png)'
- en: Resizing our images
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整图像大小
- en: 'We will resize the images using the following steps:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过以下步骤来调整图像大小：
- en: 'This step is done for the purposes of this book to speed up the model execution
    time. In a real-world example, this step may not be necessary or desirable. However,
    knowing how to resize images is helpful in any case. We can resize every image
    by once again using the `map` function from the `purrr` package and also the `resizeImage`
    function from the `OpenImageR` package. In this case, `map` takes every element
    from the `image_list` object and passes it as an argument through the `resizeImage`
    function. So, every array will change from having dimensions of 250 x 250 to 50
    x 50\. We resize every image by running the following code:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这一步是为了加速模型执行时间，特意在本书中完成的。在实际应用中，这一步可能不必要或不理想。然而，了解如何调整图像大小在任何情况下都很有帮助。我们可以通过再次使用`purrr`包中的`map`函数和`OpenImageR`包中的`resizeImage`函数来调整每个图像的大小。在这种情况下，`map`会从`image_list`对象中获取每个元素，并将其作为参数传递给`resizeImage`函数。因此，每个数组的尺寸将从250
    x 250变为50 x 50。我们通过运行以下代码来调整每个图像的大小：
- en: '[PRE20]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After running this code, we can see the dimensions of our images have changed.
    If `image_list` is still expanded in the data Environment pane, then it will now
    look as in the following screenshot:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码后，我们可以看到图像的维度发生了变化。如果`image_list`仍然在数据环境窗格中展开，那么它现在将显示如下截图：
- en: '![](img/f5a164a7-3a67-43fe-ad90-4410f8363095.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f5a164a7-3a67-43fe-ad90-4410f8363095.png)'
- en: Merging arrays
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合并数组
- en: 'Now that we are done resizing, we will start merging the arrays:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在调整大小的工作完成了，我们将开始合并数组：
- en: 'After our images are resized, there is just one last step to get the data in
    the proper format. The data is currently stored in a list of arrays; however,
    we need the data to all be in one four-dimensional array. The following code takes
    all our three-dimensional arrays and combines them along a new fourth dimension.
    We can combine all of our three-dimensional arrays into one four-dimensional array
    and then view the dimensions using the following code:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在调整图像大小后，最后一步是将数据转换为正确的格式。目前，数据存储在一个数组列表中；然而，我们需要将所有数据合并为一个四维数组。以下代码将所有三维数组沿着一个新的第四维度进行合并。我们可以将所有三维数组合并为一个四维数组，然后使用以下代码查看维度：
- en: '[PRE21]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This code will print details about our image dimensions to the console, so
    we can now see the new shape of our four-dimensional array and how the fourth
    dimension corresponds with the number of image objects we have. You will see the
    following printed to your console:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此代码将在控制台打印有关图像维度的详细信息，我们现在可以看到四维数组的新形状以及第四维度如何对应于我们拥有的图像对象数量。您将看到以下内容打印到控制台：
- en: '![](img/fde30a9a-28fa-4888-8a89-90c90ba806ca.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fde30a9a-28fa-4888-8a89-90c90ba806ca.png)'
- en: 'Our data is now in the proper format and we can just do two last clean-up steps.
    We remove the list of arrays and the vector of file path names, since we no longer
    need these, and reset our working directory back to the root for our project:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据现在已经是正确格式，我们只需要执行最后两步清理工作。我们将移除数组列表和文件路径名称向量，因为这些数据已经不再需要，并将工作目录重置回项目的根目录：
- en: '[PRE22]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'After running this code, we have all the objects that we need to begin assembling
    our GAN model. Your data environment will look as in the following screenshot:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码后，我们得到了开始组装GAN模型所需的所有对象。您的数据环境将显示如下截图：
- en: '![](img/9aba0a85-13f3-4f1e-99bf-5413760b9499.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9aba0a85-13f3-4f1e-99bf-5413760b9499.png)'
- en: With the data now imported to the environment and converted into the proper
    format, we are now ready to put everything together to create our GAN model. The
    data we just loaded is used with the discriminator model, along with the array
    created by the generator model. We will now write the code that combines the data,
    generator, and discriminator to create our GAN model.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 数据现在已经导入到环境中并转换为正确格式，我们现在准备将所有内容结合起来创建GAN模型。我们刚刚加载的数据将与判别器模型一起使用，生成器模型创建的数组也将被使用。我们现在将编写代码，将数据、生成器和判别器结合起来创建GAN模型。
- en: Training and evaluating the model
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练与评估模型
- en: Now that the data is in the proper format and we have our discriminator and
    generator defined, we can put it all together to train our GAN. The final GAN
    model takes input from our target image dataset and the output is the probability
    that this is a real image after the real image data and the fake image data have
    been passed as input to the discriminator. We train our GAN model by running the
    following sections.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已经是正确格式，并且我们已经定义了判别器和生成器，我们可以将所有部分结合起来训练我们的GAN。最终的GAN模型将从目标图像数据集中获取输入，输出是输入真实图像数据和伪造图像数据到判别器后，判断这张图片是否为真实图像的概率。我们通过运行以下部分来训练我们的GAN模型。
- en: Defining the GAN model
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义GAN模型
- en: 'We define the GAN model as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义GAN模型的代码如下：
- en: 'The first step that we will perform is calling the `freeze_weights` function
    on the discriminator model. This is so that the weights for the discriminator
    model do not update during the training process. We want the weights to update
    for the generator and not for the discriminator:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将执行的第一步是对判别器模型调用`freeze_weights`函数。这是为了确保判别器模型的权重在训练过程中不会更新。我们希望更新生成器的权重，而不是判别器的权重：
- en: '[PRE23]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The next step is to define the input and output for `keras_model`, as we did
    with the generator and the discriminator. In this case, `keras_model` will be
    our final GAN model. Note here that the input will contain 100 values, which is
    the same as our generator, since the input to our GAN model will pass through
    our generator model and then continue through to our discriminator model, which
    will then produce the output for our model. We define the GAN model using the
    following code:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是定义`keras_model`的输入和输出，正如我们在生成器和鉴别器中所做的那样。在这种情况下，`keras_model`将是我们的最终GAN模型。请注意，输入将包含100个值，这与我们的生成器相同，因为输入到GAN模型的数据将通过生成器模型，然后继续传递给鉴别器模型，最后生成我们的模型输出。我们使用以下代码来定义GAN模型：
- en: '[PRE24]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'After running this code, we now have the following objects in our data environment.
    We can see in all the details about the different tensor layers the path of the
    data through the entire GAN model pipeline. Your Environment pane will look like
    the following:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码后，我们现在在数据环境中拥有以下对象。我们可以看到关于不同张量层的所有细节，这些细节展示了数据在整个GAN模型管道中的流动路径。你的**环境面板**将如下所示：
- en: '![](img/c9a7ab3f-43a1-4c3c-af50-c7e686700261.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9a7ab3f-43a1-4c3c-af50-c7e686700261.png)'
- en: 'Similar to the discriminator model, we need to define the compile step. We
    set it up in the same way that we did with the discriminator. The error is computed
    using the `binary_crossentropy` loss function and `adam` is used to iteratively
    improve the model. Defining how the final GAN model is compiled is done using
    the following code:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与鉴别器模型类似，我们需要定义编译步骤。我们以与鉴别器相同的方式设置它。使用`binary_crossentropy`损失函数计算误差，并使用`adam`优化器来迭代改进模型。定义最终GAN模型的编译方式通过以下代码完成：
- en: '[PRE25]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Passing data to the GAN model
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据传递给GAN模型
- en: 'Now, we will pass data to the model as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将数据传递给模型，具体如下：
- en: 'With this, our model is ready and we can begin to pass data through to generate
    synthetic images. In order to store these data objects, we will need to create
    a directory within our project folder. We create a directory to hold our real
    and fake images by using the following code:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这样，我们的模型就准备好了，可以开始传递数据以生成合成图像。为了存储这些数据对象，我们需要在项目文件夹中创建一个目录。我们使用以下代码创建一个目录来存放我们的真实图像和假图像：
- en: '[PRE26]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: After running this code, you will see a new folder in your main project folder
    with the name `gan_images`.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码后，你将在主项目文件夹中看到一个名为`gan_images`的新文件夹。
- en: Training the GAN model
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练GAN模型
- en: 'Now that we have prepared our model, it is time to train it, using the following
    steps:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了模型，是时候使用以下步骤对其进行训练：
- en: Training our GAN model is an iterative process and we will need to create a
    loop that selects and creates image arrays and then passes them through our GAN,
    which will calculate the probability that each image array belongs to the target
    class. However, if we start a loop here, then the effects on every line of code
    will not be seen until the entire code completes. For that reason, we will first
    walk through every line of code inside the loop and then, we will show the entire
    code wrapped in the `for` loop.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练我们的GAN模型是一个迭代过程，我们需要创建一个循环来选择并创建图像数组，然后将它们传递给我们的GAN模型，GAN模型将计算每个图像数组属于目标类别的概率。然而，如果我们从这里开始一个循环，那么每行代码的效果直到整个代码执行完毕后才会看到。为此，我们将首先遍历循环中的每一行代码，然后展示完整的`for`循环代码。
- en: 'Before entering the loop, we declare one variable that we will need inside
    our loop. The following code sets a value for the `first_row` variable. This will
    be used later when we subset our array. We start with the first three-dimensional
    array within our four-dimensional array. Later, when the following code is run
    in a loop, the value for `first_row` will change during every iteration to ensure
    a different subset of real images is passed to the discriminator model. We set
    the value of `first_row` for the first iteration of the loop by running the following
    code:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在进入循环之前，我们声明一个将在循环内使用的变量。以下代码为`first_row`变量设置了一个值。稍后，当我们对数组进行子集操作时，将使用这个变量。我们从四维数组中的第一个三维数组开始。当以下代码在循环中运行时，`first_row`的值将在每次迭代时变化，以确保将不同的真实图像子集传递给鉴别器模型。我们通过运行以下代码设置第一次迭代时`first_row`的值：
- en: '[PRE27]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Generating random images
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成随机图像
- en: 'After training, we will use the model to create random images, as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，我们将使用模型生成随机图像，具体如下：
- en: 'The next step is to create a matrix of random variables. The number of random
    variables should be set at the batch size times the size of the input shape for
    our generator model. The dimensions are then set so that the number of rows is
    equal to the batch size and the number of columns is equal to the length of the
    input shape defined here. In this case, `20` is used as the batch size and `100`
    is used as the length of the vector to be passed to the generator model. Both
    of these values are modifiable. Increasing either or both provides more data to
    the model, which could improve performance but will also increase runtime. We
    create our matrix of random values from a normal distribution by using the following
    code:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是创建一个随机变量矩阵。随机变量的数量应设置为批量大小乘以我们生成器模型的输入形状的大小。然后设置维度，使得行数等于批量大小，列数等于这里定义的输入形状的长度。在这种情况下，`20`用作批量大小，`100`用作传递给生成器模型的向量的长度。这两个值都是可修改的。增加其中一个或两个值会为模型提供更多的数据，可能会提高性能，但也会增加运行时间。我们通过以下代码从正态分布中创建我们的随机值矩阵：
- en: '[PRE28]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'After running the code, a matrix will be created consisting of values selected
    from a normal (Gaussian) distribution. Every row in the matrix will be used to
    generate an image. The images are created by using random values. By selecting
    the object in our data environment, we can view it. After selecting the data object
    from the environment, you will see something like the following:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行代码后，将创建一个矩阵，其中包含从正态（高斯）分布中选择的值。矩阵中的每一行将用于生成一张图像。这些图像是通过使用随机值创建的。通过在数据环境中选择对象，我们可以查看它。选择数据对象后，你将看到类似以下的内容：
- en: '![](img/45add777-2b12-486f-94d5-48a4a7cd804a.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/45add777-2b12-486f-94d5-48a4a7cd804a.png)'
- en: 'Next, using our matrix of random values, we will generate fake images. These
    fake images are created using the generator model that we defined earlier. The
    model takes the random values as input and the output is a four-dimensional array. The
    first dimension of the array corresponds with the batch size, which in this case
    is `20`, and the other three dimensions correspond to the dimensions of our image
    data. After generating synthetic data, we will sample a few values to show that
    the arrays have been created and populated with the random values. We create the
    array and view a portion of it by running the following code:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用我们的随机值矩阵，我们将生成假图像。这些假图像是通过我们之前定义的生成器模型创建的。模型将随机值作为输入，输出是一个四维数组。数组的第一维对应批量大小，在本例中为`20`，其他三维对应于我们图像数据的维度。生成合成数据后，我们将抽取一些值，以展示数组已经创建并填充了随机值。我们通过运行以下代码创建数组并查看其中的一部分：
- en: '[PRE29]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'After running the preceding code, we see a small section of the array that
    we created. Since this has a value of `1` for the first dimension and a value
    of `1` for the fourth dimension, then we know that the values will be used to
    represent the intensity of the red values for the first image. The preceding code
    prints values to the console. You will see something like the following printed
    to your console:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行前面的代码后，我们看到我们创建的数组的一小部分。由于第一维的值为`1`，第四维的值为`1`，因此我们知道这些值将用于表示第一张图像的红色强度。前面的代码会将值打印到控制台。你将看到类似以下的内容打印到控制台：
- en: '![](img/94cfbdcc-0b4b-42fc-ae4a-ea688b87d4d6.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/94cfbdcc-0b4b-42fc-ae4a-ea688b87d4d6.png)'
- en: 'Earlier, we set the `first_row` value to indicate where we would like row-wise
    subsets to begin for every iteration. Next, we need to define the last row, which
    is equal to the value of the first row plus one less than the batch size. In this
    case, the batch size is `20`, so we use `19`. Also, while the `first_row` value
    begins at `1`, it will change dynamically throughout the iterations. We set the
    value of the last row for subsetting our data by running the following code:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之前，我们将`first_row`值设置为指示我们希望每次迭代开始时的行子集的位置。接下来，我们需要定义最后一行，它等于第一行的值加上比批量大小少一个的值。在这种情况下，批量大小是`20`，因此我们使用`19`。另外，虽然`first_row`的值从`1`开始，但它会在每次迭代中动态变化。通过运行以下代码，我们设置了用于子集数据的最后一行值：
- en: '[PRE30]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Selecting real images
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择真实图像
- en: 'Now, we select the real images, as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们选择真实图像，如下所示：
- en: 'Next, we use the values for `first_row` and `last_row` to create a subset of
    the array containing our real target images. We will also run two lines to remove
    attributes from our data objects. This is not strictly necessary and at times,
    you may want data that is stored here. However, for demonstration purposes, we
    will remove it now so we can see the dimensions of all the arrays in the data
    environment window. The array of real images equal to the batch size to be used
    in an iteration of the model is created using the following line of code:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用`first_row`和`last_row`的值来创建一个包含真实目标图像的数组子集。我们还将运行两行代码来从数据对象中移除属性。这不是绝对必要的，有时候你可能希望保留这里存储的数据。然而，为了演示目的，我们现在将其移除，这样我们就能在数据环境窗口中看到所有数组的维度。使用以下代码行创建一个等于批次大小的真实图像数组，该数组将在模型的一个迭代中使用：
- en: '[PRE31]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'After running these lines, we can now see that `real_images` and `fake_images`
    are arrays of the same size. Expand both data objects in your Environment pane
    and you will see that your environment now looks like the following:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行这些代码行后，我们现在可以看到`real_images`和`fake_images`是相同大小的数组。在您的环境窗格中展开这两个数据对象，您会看到您的环境现在看起来如下所示：
- en: '![](img/af9057de-5c7e-4eda-81e8-3256ba26e4f1.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/af9057de-5c7e-4eda-81e8-3256ba26e4f1.png)'
- en: Combining real and fake images
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结合真实和假图像
- en: 'After differentiating the real and fake images, we will now merge them using
    the following steps:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在区分了真实和假图像后，我们将使用以下步骤将它们合并：
- en: 'In our next step, we create an array with all the `0` values in the shape of
    our real images stacked on top of our fake images. That is to say, the first dimension
    is equal to twice the batch size, which in this case is `40`, and the remaining
    three dimensions are equal to the size of our image arrays. We create this placeholder
    array of zeroes by running the following code:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一步中，我们创建一个包含所有`0`值的数组，其形状为真实图像堆叠在假图像上。也就是说，第一维等于批次大小的两倍，这里是`40`，其余三个维度等于我们图像数组的大小。我们通过运行以下代码创建这个零值占位符数组：
- en: '[PRE32]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'After running this code, we will see a new object in our Environment window
    and we can see that it does have a first dimension that is twice the size of the
    other two arrays that we created. Your environment will now look like this:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行这段代码后，我们将在环境窗口中看到一个新对象，并且可以看到它的第一维是其他两个我们创建的数组大小的两倍。此时，您的环境窗口将如下所示：
- en: '![](img/0f485eeb-0b22-4568-99cb-cd01482d1e38.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0f485eeb-0b22-4568-99cb-cd01482d1e38.png)'
- en: 'Next, we will populate our placeholder array. For the top half of this array,
    we assign the values from the fake images that we generated and for the bottom
    half, we assign the values for the real images. We populate our array with values
    from the fake and real image data using the following code:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将填充我们的占位符数组。对于数组的上半部分，我们赋值为我们生成的假图像，而对于下半部分，我们赋值为真实图像的值。我们使用以下代码将假图像和真实图像数据填充到数组中：
- en: '[PRE33]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'After running this code, we will see that even for the small sample of data
    available in the Environment window, the values for `combined_images` have changed
    from all the zeroes, as seen earlier, to random values from our `fake_images`
    array. Your Environment window will now look as in the following screenshot:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行这段代码后，我们会看到即使对于环境窗口中小样本数据，`combined_images`的值也已经从之前的零值变化为我们`fake_images`数组中的随机值。此时，您的环境窗口将如下所示：
- en: '![](img/aef705b9-a007-49ad-adef-40b8d38aed97.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aef705b9-a007-49ad-adef-40b8d38aed97.png)'
- en: Creating target labels
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建目标标签
- en: 'Now, we create target labels for all the images using the following steps:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用以下步骤为所有图像创建目标标签：
- en: 'We need to create a matrix of labels; this is simply a matrix of binary values.
    We add `20` rows with values of `1` to label the fake images and `20` rows with
    values of `0` to label the real images. We create our matrix of label data using
    the following code:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要创建一个标签矩阵；这只是一个二进制值矩阵。我们添加`20`行值为`1`的行来标记假图像，并添加`20`行值为`0`的行来标记真实图像。我们使用以下代码创建标签数据矩阵：
- en: '[PRE34]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'After running this code, let''s click on the `labels` object to view it. We
    can see that it does contain 20 rows with a value of `1` and 20 rows with a value
    of `0`. The following is an image that you will see near the midpoint when viewing
    this matrix:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码后，让我们点击`labels`对象进行查看。我们可以看到，它确实包含了20行值为`1`的行和20行值为`0`的行。以下是您在查看此矩阵时将看到的图像：
- en: '![](img/0f5da36c-01d5-41d4-92bf-334ae969e1e7.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0f5da36c-01d5-41d4-92bf-334ae969e1e7.png)'
- en: 'The next step is to add some noise to the labels. Just like using the dropout
    layer earlier, we want to introduce some noise and randomness throughout the modeling
    process to try to force the discriminator to generalize more and avoid overfitting.
    We add noise by applying a constant value to an array of random values selected
    from a uniform distribution that is the same length as our labels object and then
    adding it to the current values in the labels matrix. We add noise to our labels
    using the following code:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是为标签添加一些噪声。就像之前使用dropout层时一样，我们希望在建模过程中引入一些噪声和随机性，迫使判别器进行更多的泛化，以避免过拟合。我们通过应用一个常数值到从均匀分布中选择的随机值数组（该数组与我们的标签对象长度相同），然后将其加到标签矩阵中的当前值来添加噪声。我们使用以下代码向标签中添加噪声：
- en: '[PRE35]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'After we do this, we can look at the same subset of rows from the `labels`
    object and see that the values are now all slightly modified. The values in your
    `labels` object will be similar to the following screenshot:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成上述操作后，我们可以查看`labels`对象中的相同行子集，发现其值现在已略有修改。`labels`对象中的值将类似于以下截图所示：
- en: '![](img/74a808fc-90be-49a2-b0d5-194c90fca2aa.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/74a808fc-90be-49a2-b0d5-194c90fca2aa.png)'
- en: Passing input to the discriminator model
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将输入传递给判别器模型
- en: 'Now, we will pass the inputs to the discriminator model using the following
    steps:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将通过以下步骤将输入传递给判别器模型：
- en: 'Next, we pass our combined images, containing a mix of real and fake images,
    as input to our discriminator model and we pass along the labels as the target
    variable for the model. We feed our independent and dependent variables to the
    input and output layers of our discriminator model using the following code:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将混合了真实和伪造图像的组合图像传递给判别器模型，标签作为模型的目标变量。我们使用以下代码将独立变量和因变量传递给判别器模型的输入层和输出层：
- en: '[PRE36]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The result of running this code is the error rate for the discriminator. We
    can just run the name of the object to have this value printed to our console.
    After running the preceding code, your console will look as in the following screenshot,
    though the value may be slightly different:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码的结果是判别器的误差率。我们只需运行对象名称，就可以将该值打印到控制台。运行上述代码后，您的控制台将显示如下截图，尽管值可能略有不同：
- en: '![](img/e2ac21a8-ec92-44d7-b6c9-c716fb2c7642.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e2ac21a8-ec92-44d7-b6c9-c716fb2c7642.png)'
- en: 'Our next step will be to create another random matrix, which we will use as
    input to our GAN. It goes to the generator and in turn, the discriminator, as
    defined in our GAN model definition. We create the input for our GAN model using
    the following code:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的下一步是创建另一个随机矩阵，作为我们GAN模型的输入。它会传递给生成器，再传递给判别器，按照我们在GAN模型定义中的设定进行处理。我们使用以下代码为GAN模型创建输入：
- en: '[PRE37]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'After this, we create an array that is the size of our batch. It is set to
    state that all the data objects are true:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此之后，我们创建一个大小与批量相同的数组。该数组被设置为所有数据对象为真：
- en: '[PRE38]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We pass this matrix of random variables and the array to the GAN model:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将这个随机变量矩阵和数组传递给GAN模型：
- en: '[PRE39]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The result of running this code is a calculation of the error rate for the
    GAN. If many of the true target images were correctly identified, then the generator
    will make larger changes and if the generator creates images that are selected
    as real images, then fewer changes will be made during future iterations. If we
    run the line that only contains the object name, then we will receive a print
    out to our console. Your console will look similar to the following screenshot:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码的结果是计算GAN的误差率。如果许多真实的目标图像被正确识别，那么生成器将做出更大的变化；如果生成器创建的图像被选为真实图像，则在未来的迭代中会做出较少的变化。如果我们运行仅包含对象名称的行，则会在控制台打印输出。你的控制台将类似于以下截图：
- en: '![](img/6f89a105-6861-47b9-9c2f-3a45d1386007.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f89a105-6861-47b9-9c2f-3a45d1386007.png)'
- en: Updating the row selector
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新行选择器
- en: 'Next, we will update the row selector with the following steps:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过以下步骤更新行选择器：
- en: 'Our next step will be to reset the `first_row` value to get a different subset
    of the `real_image` data during the subsequent iteration. We reset the `first_row`
    value using the following code:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的下一步是重置`first_row`值，以便在后续迭代中获取不同的`real_image`数据子集。我们使用以下代码重置`first_row`值：
- en: '[PRE40]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'After this code is run, the `first_row` value will either be set to the previous
    value plus the batch size of `20`, or if that number would result in a subset
    that is out of bounds, then the `first_row` value is set to a randomly drawn value
    between `1` and `10`. In this case, the value will be set to `21`. You will see
    a printout to your console, as in the following screenshot:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行此代码后，`first_row`的值将设置为前一个值加上批次大小`20`，或者如果该数值会导致子集超出范围，则`first_row`的值会设置为1到10之间的随机值。在这种情况下，值将设置为`21`。你将看到控制台输出，如下截图所示：
- en: '![](img/34464036-eea3-4a6f-92df-a02a058af701.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/34464036-eea3-4a6f-92df-a02a058af701.png)'
- en: Evaluating the model
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型
- en: 'Finally, we will evaluate the model using the following steps:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将通过以下步骤评估模型：
- en: 'The last step is to periodically print model diagnostics along with real and
    generated images for comparison and to track whether the synthetic images are
    being generated as expected. We print the model iteration and error rates and
    also save one real and one fake image in the directory that we created earlier
    using the following code:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一步是定期打印模型诊断信息，并展示真实图像和生成图像进行对比，以跟踪合成图像是否按预期生成。我们打印模型的迭代次数和误差率，并使用以下代码将一张真实图像和一张伪造图像保存在我们之前创建的目录中：
- en: '[PRE41]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'After running the code, we can see model diagnostics printed to our console.
    Your console will look as in the following screenshot:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行代码后，我们可以看到模型诊断信息打印在控制台中。你的控制台将显示如下截图：
- en: '![](img/8e4daa10-1762-4266-8d32-5ebbbf154a2e.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8e4daa10-1762-4266-8d32-5ebbbf154a2e.png)'
- en: 'In addition, we can see generated and real images in the folder we created
    earlier. It will take quite a large number of rounds or epochs for any images
    to look like realistic faces, as in our real images set. However, even in earlier
    rounds, we can see the GAN begin to find features. The following is an original
    photo from our dataset:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，我们可以在之前创建的文件夹中看到生成的图像和真实图像。任何图像要像我们真实图像集中的面孔一样逼真，需要经历大量的轮次或周期。然而，即使在早期的轮次中，我们也能看到生成对抗网络（GAN）开始识别特征。以下是我们数据集中一张原始照片：
- en: '![](img/36581ad9-524e-4454-9e30-065b97f2ee50.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36581ad9-524e-4454-9e30-065b97f2ee50.png)'
- en: 'This is a generated image:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是一张生成的图像：
- en: '![](img/b5ea8b24-34c5-43a9-9b96-ba939b117169.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b5ea8b24-34c5-43a9-9b96-ba939b117169.png)'
- en: This early synthetic image has captured a number of features already.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这张早期的合成图像已经捕捉到了一些特征。
- en: For convenience, the entire `for` loop for iteratively training our model is
    included in the GitHub repository.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便起见，用于迭代训练模型的整个`for`循环已包含在GitHub存储库中。
- en: Our GAN model is complete. You can continue to make a number of adjustments
    to see how it affects the synthetic images created. All through the model pipeline
    creation, we noted the values that need to be present in order to make the model
    work. However, huge portions can be modified. All modifications will result in
    different generated images. As noted before, there is no metric for a successful
    GAN. It will all depend on the end user's interpretation of the generated data.
    Adding more layers to the generator or discriminator, as well as adjusting the
    filter size, layer parameters, and learning rate, are all good options for modification
    as you continue to explore developing this particular type of deep learning model.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的GAN模型已经完成。你可以继续进行多次调整，看看它如何影响生成的合成图像。在整个模型管道创建过程中，我们记录了需要存在的值，以使模型正常工作。然而，许多部分是可以修改的。所有的修改都会导致不同的生成图像。如前所述，GAN没有一个成功的标准。最终的效果将完全取决于最终用户对生成数据的解读。增加生成器或判别器的层数，以及调整滤波器大小、层参数和学习率，都是继续探索开发这种深度学习模型的不错选择。
- en: Summary
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we created a model that can take images of faces as input and
    generate faces as output. We used images from the labeled faces in the wild dataset.
    Using a GAN model, we generated an image with random values and then sampled an
    actual image. To generate an image, we took random values and reshaped them to
    the dimensions of the images in our dataset. We then fed this image—composed of
    random values—along with an actual image, to a model that reshaped the data down
    to a simple probability score, representing the likelihood that an image is real
    or fake. Through multiple iterations, the generator was trained to create images
    that were increasingly likely to be classified as real by the discriminator model.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章，我们创建了一个模型，可以将面部图像作为输入并生成面部图像作为输出。我们使用了“野外标注面孔”数据集中的图像。使用GAN模型，我们先生成一个随机值图像，然后采样得到一个实际图像。为了生成图像，我们将随机值重塑为与数据集中图像相同的尺寸。接着，我们将由随机值组成的图像与实际图像一起输入到一个模型中，该模型将数据重塑为一个简单的概率得分，表示图像是“真实”还是“伪造”的可能性。通过多次迭代，生成器被训练得能够生成更容易被判别模型分类为“真实”的图像。
- en: In our next chapter, we will learn about another unsupervised deep learning
    technique called **reinforcement learning**. It is similar to GANs in that an
    agent performs a task and continually learns from failing until it can perform
    the task successfully. We will dive into the details of reinforcement learning
    in the next chapter.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习另一种无监督深度学习技术——**强化学习**。它与生成对抗网络（GANs）类似，都是通过一个代理执行任务，并不断从失败中学习，直到能够成功完成任务。在下一章中，我们将深入探讨强化学习的细节。
