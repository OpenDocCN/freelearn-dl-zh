- en: Going Further - 21 Problems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更深入 - 21 个问题
- en: In this chapter, we are going to introduce 21 real life problems that you can
    use deep learning and TensorFlow to tackle. We will start by talking about some
    public large-scale datasets and competitions. Then, we will show some awesome
    TensorFlow projects on Github. We will also introduce some interesting projects
    that have been done in other deep learning frameworks so that you can get inspired
    and implement your own TensorFlow solution. Finally, we will work through a simple
    technique to convert a Caffe model to a TensorFlow model and introduce using a
    high-level TensorFlow library, TensorFlow-Slim.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍 21 个实际生活中的问题，您可以使用深度学习和 TensorFlow 来解决。我们将从讨论一些公共的大规模数据集和竞赛开始。然后，我们将展示一些精彩的
    TensorFlow 项目。我们还将介绍一些在其他深度学习框架中完成的有趣项目，以便您获得灵感并实现自己的 TensorFlow 解决方案。最后，我们将介绍一种简单的技术，将
    Caffe 模型转换为 TensorFlow 模型，并介绍如何使用高级 TensorFlow 库 TensorFlow-Slim。
- en: 'In this chapter, we will look into the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Large-scale, public datasets and competitions
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大规模公共数据集和竞赛
- en: Awesome TensorFlow projects
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精彩的 TensorFlow 项目
- en: Some inspired deep learning projects from other frameworks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些其他框架的深度学习启发项目
- en: Converting a Caffe model to TensorFlow
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 Caffe 模型转换为 TensorFlow 模型
- en: Introducing TensorFlow-Slim
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 TensorFlow-Slim
- en: Dataset and challenges
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集和挑战
- en: In this section, we will show you some popular datasets and competitions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向您展示一些流行的数据集和竞赛。
- en: Problem 1 - ImageNet dataset
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 1 - ImageNet 数据集
- en: 'Project link: [http://image-net.org/](http://image-net.org/)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '项目链接: [http://image-net.org/](http://image-net.org/)'
- en: '**ImageNet** is a large scale visual recognition challenge that has runs annually
    since 2010\. The dataset is organized according to the WorkNet hierarchy. There
    are over ten million URLs of images with hand-annotated labels to indicate what
    objects are in the picture. There are at least one million images that have bounding
    boxes included.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**ImageNet** 是一个大型视觉识别挑战赛，自 2010 年以来每年举办一次。数据集按照 WorkNet 层级结构进行组织。数据集中包含超过一千万个带有手动标注标签的图像
    URL，以指示图片中的物体。至少有一百万张图像包括了边界框。'
- en: 'The ImageNet challenge is held every year to evaluate algorithms for the following
    three problems:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ImageNet 挑战赛每年举办一次，评估算法在以下三个问题中的表现：
- en: Object localization for 1,000 categories.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1,000 个类别的物体定位。
- en: Object detection for 200 fully-labeled categories.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 200 个完全标注类别的目标检测。
- en: Object detection from video for 30 fully labeled categories. In July 17, 2017,
    the results of the 2017 challenge were announced with many advanced and interesting
    algorithms.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 30 个完全标注类别的视频目标检测。2017 年 7 月 17 日，2017 年挑战赛的结果公布，出现了许多先进且有趣的算法。
- en: Problem 2 - COCO dataset
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 2 - COCO 数据集
- en: 'Project link: [http://mscoco.org/](http://mscoco.org/)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '项目链接: [http://mscoco.org/](http://mscoco.org/)'
- en: COCO is a dataset for image recognition, segmentation, and captioning sponsored
    by Microsoft. There are 80 object categories in this dataset with more than 300,000
    images and two million instances. There are also challenges for detections, captions,
    and key-points every year.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: COCO 是一个用于图像识别、分割和标注的数据集，由微软赞助。该数据集中有 80 个对象类别，包含超过 300,000 张图片和 200 万个实例。每年还会举办检测、标注和关键点的挑战赛。
- en: Problem 3 - Open Images dataset
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 3 - Open Images 数据集
- en: 'Project link: [https://github.com/openimages/dataset](https://github.com/openimages/dataset)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '项目链接: [https://github.com/openimages/dataset](https://github.com/openimages/dataset)'
- en: Open Images is a new dataset from Google, with over nine million URLs spanning
    over 6000 categories. Each image is processed by Google's vision model and verified
    by a human. As of July 20, 2017, there are also over two million bounding box
    annotations spanning over 600 objects.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Open Images 是谷歌推出的一个新数据集，包含超过九百万个 URL，涵盖超过 6000 个类别。每张图像都经过谷歌的视觉模型处理，并由人工验证。截至
    2017 年 7 月 20 日，该数据集还包含超过两百万个边界框标注，涵盖 600 多个物体。
- en: The difference is that Open Images covers more real-life objects than others,
    which can be very useful when developing real-life applications.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 不同之处在于，Open Images 涵盖了比其他数据集更多的现实生活中的物体，这在开发现实应用时非常有用。
- en: Problem 4 - YouTube-8M dataset
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 4 - YouTube-8M 数据集
- en: 'Project link: [https://research.google.com/youtube8m/](https://research.google.com/youtube8m/)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '项目链接: [https://research.google.com/youtube8m/](https://research.google.com/youtube8m/)'
- en: YouTube-8M is a large-scale video dataset from Google with 7 million video URLs
    over 4,716 classes and 450,000 hours of video. Google also provides pre-computed,
    state-of-the-art audio-visual features, so that one can build their model based
    on these features with ease. Training from raw videos may take weeks, which is
    not reasonable in normal situations. This dataset's goal is to achieve video understanding,
    representation learning, noisy data modeling, transfer learning, and domain adaptation
    for videos.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: YouTube-8M是谷歌提供的一个大规模视频数据集，包含700万个视频URL，涵盖4,716个类别和450,000小时的视频。谷歌还提供了预计算的先进音视频特征，可以让你基于这些特征轻松构建模型。从原始视频进行训练可能需要数周，这在正常情况下是不现实的。该数据集的目标是实现视频理解、表示学习、噪声数据建模、迁移学习和视频领域适应。
- en: Problem 5 - AudioSet dataset
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题5 - AudioSet数据集
- en: 'Project link: [https://research.google.com/audioset/](https://research.google.com/audioset/)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[https://research.google.com/audioset/](https://research.google.com/audioset/)
- en: AudioSet is a large-scale audio events dataset from Google with 632 audio event
    classes and a collection of over 2.1 million manually annotated sound clips. Audio
    classes span from human and animal sounds to musical instruments and common, everyday
    environmental sounds. Using this dataset, you can create a system to recognize
    audio events for audio understanding, security applications, and much more.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: AudioSet是谷歌提供的一个大规模音频事件数据集，包含632个音频事件类别，并收录了超过210万条人工标注的音频片段。音频类别涵盖了从人类和动物的声音到乐器声以及常见的日常环境声音。利用该数据集，你可以构建一个系统，用于音频事件识别，支持音频理解、安全应用等众多领域。
- en: Problem 6 - LSUN challenge
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题6 - LSUN挑战赛
- en: 'Project link: [http://lsun.cs.princeton.edu/2017/](http://lsun.cs.princeton.edu/2017/)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[http://lsun.cs.princeton.edu/2017/](http://lsun.cs.princeton.edu/2017/)
- en: 'LSUN challenge provides a large scale scene understanding dataset covering
    three major problems:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: LSUN挑战赛提供了一个大规模的场景理解数据集，涵盖了三个主要问题：
- en: Scene classification
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 场景分类
- en: Segmentation task on street images
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 街景图像的分割任务
- en: Saliency prediction
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显著性预测
- en: In scene classification problems, the expected output of the algorithm is the
    top most likely scene category in the image. At the time of writing, there are
    10 different classes such as bedroom, classroom, and restaurant. In the segmentation
    problem, you can try to solve the pixel-level segmentation and instance-specific
    segmentation. In saliency prediction problems, the goal is to predict where a
    human looks in a scene image.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在场景分类问题中，算法的预期输出是图像中最可能的场景类别。撰写时，有10个不同的类别，如卧室、教室和餐厅。在分割问题中，你可以尝试解决像素级分割和特定实例的分割。在显著性预测问题中，目标是预测人在场景图像中的注视位置。
- en: Problem 7 - MegaFace dataset
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题7 - MegaFace数据集
- en: 'Project link: [http://megaface.cs.washington.edu/](http://megaface.cs.washington.edu/)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[http://megaface.cs.washington.edu/](http://megaface.cs.washington.edu/)
- en: 'MegaFace provides a large scale dataset for face recognition. The MegaFace
    dataset is divided into three parts:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: MegaFace提供了一个大规模的人脸识别数据集。MegaFace数据集分为三部分：
- en: Training set
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练集
- en: Test set
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试集
- en: Distractors
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 干扰样本
- en: The **Training set** contains 4.7 million photos of over 672,057 unique identities.
    The **test set** contains the images from the FaceScrub and FGNet dataset. The
    **distractors** contain one million photos of 690,572 unique users. Currently,
    there are two challenges in the MegaFace website. In challenge 1, you can train
    using any dataset and test your method with the one million distractors. Your
    method needs to discriminate between a set of known people while classifying the
    distractors as unknown people. In challenge 2, you will train using the training
    set with 672K unique identities and test with 1 million distractors. MegaFace
    is currently the largest dataset for face recognition at the time of writing.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练集**包含470万张照片，涵盖672,057个独特身份。**测试集**包含来自FaceScrub和FGNet数据集的图像。**干扰集**包含100万张照片，来自690,572个独特用户。目前，MegaFace网站上有两个挑战。在挑战1中，你可以使用任何数据集进行训练，并通过100万个干扰样本来测试你的方法。你的方法需要区分一组已知的人，并将干扰样本分类为未知的人。在挑战2中，你将使用包含672K独特身份的训练集进行训练，并通过100万个干扰样本进行测试。MegaFace是目前（撰写时）最大的人脸识别数据集。'
- en: Problem 8 - Data Science Bowl 2017 challenge
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题8 - 2017数据科学大赛挑战
- en: 'Project link: [https://www.kaggle.com/c/data-science-bowl-2017](https://www.kaggle.com/c/data-science-bowl-2017)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[https://www.kaggle.com/c/data-science-bowl-2017](https://www.kaggle.com/c/data-science-bowl-2017)
- en: Data Science Bowl 2017 is a one million dollar challenge focused on lung cancer
    detection. In the dataset, you will be given over a thousand CT images of high-risk
    patients. The goal of this challenge is to create an automatic system that can
    determine whether a patient will be diagnosed with lung cancer within one year.
    This is a very interesting and important project to work on that will save thousands
    of people in the near future.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Data Science Bowl 2017 是一个价值百万美元的挑战，专注于肺癌检测。在数据集中，您将获得超过一千张高风险患者的 CT 图像。此挑战的目标是创建一个自动化系统，能够判断患者是否会在一年内被诊断为肺癌。这是一个非常有趣且重要的项目，未来能够拯救成千上万的人。
- en: Problem 9 - StarCraft Game dataset
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 9 - 星际争霸游戏数据集
- en: 'Project link: [https://github.com/TorchCraft/StarData](https://github.com/TorchCraft/StarData)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '项目链接: [https://github.com/TorchCraft/StarData](https://github.com/TorchCraft/StarData)'
- en: This is the largest StarCraft--Brood War replay dataset at the time of writing
    this book. This dataset contains more than 60,000 games in 365GB, 1535 million
    frames, and 496 million player actions. This dataset is best suit for those who
    want to research about AI game playing.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这是截至本书写作时最大的《星际争霸——母巢之战》重放数据集。该数据集包含了超过 60,000 场游戏，大小为 365GB，1535 百万帧，496 百万玩家动作。这个数据集最适合那些想要研究
    AI 游戏玩法的人。
- en: TensorFlow-based Projects
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于 TensorFlow 的项目
- en: In this section, we will introduce you to several problems that are implemented
    in TensorFlow and open-source on Github. We suggest that you take a look at these
    projects and learn how to improve your TensorFlow skills.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍几个在 TensorFlow 中实现并开源在 Github 上的问题。我们建议你看看这些项目，学习如何提升你的 TensorFlow
    技能。
- en: Problem 10 - Human Pose Estimation
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 10 - 人体姿态估计
- en: 'Project Link: [https://github.com/eldar/pose-tensorflow](https://github.com/eldar/pose-tensorflow)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '项目链接: [https://github.com/eldar/pose-tensorflow](https://github.com/eldar/pose-tensorflow)'
- en: This project is the open-source implementation of Deep Cut and ArtTrack in human
    body pose estimation. The goal of this project is to jointly solve the tasks of
    detection and pose estimation. We can use this method for various applications
    such as person detection in security or human action understanding. This project
    also provides great starting points for a lot of further research on human shape
    estimation with applications for virtual-try-on or garment recommendation.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目是人类姿态估计中 Deep Cut 和 ArtTrack 的开源实现。该项目的目标是共同解决检测和姿态估计任务。我们可以将这种方法应用于各种场景，如安防中的人脸检测或人体动作理解。该项目还为进一步的人体形状估计研究提供了很好的起点，应用领域包括虚拟试穿或服装推荐。
- en: Problem 11 - Object Detection - YOLO
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 11 - 目标检测 - YOLO
- en: 'Project link: [https://github.com/thtrieu/darkflow](https://github.com/thtrieu/darkflow)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '项目链接: [https://github.com/thtrieu/darkflow](https://github.com/thtrieu/darkflow)'
- en: Object detection is an interesting problem in Computer Vision. There are lots
    of methods to solve this problem. YOLO, by Joseph Redmon and others, is one of
    the state-of-the-art techniques. YOLO provides real-time object detection using
    deep neural networks. Version 2 of YOLO can recognize up to 9,000 different objects
    with high accuracy in real time. The original YOLO project is programmed in the
    darknet framework.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 目标检测是计算机视觉中的一个有趣问题。解决这个问题的方法有很多。YOLO，由 Joseph Redmon 等人提出，是其中一种最先进的技术。YOLO 使用深度神经网络实现实时目标检测。YOLO
    的第 2 版可以实时识别多达 9,000 种不同的物体，并具有很高的准确性。原始的 YOLO 项目是用 darknet 框架编写的。
- en: In TensorFlow, there is a great implementation of YOLO, called **darkflow**.
    The darkflow repository even has the utility that can allow you to export the
    model and serve on mobile devices.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中，有一个很棒的 YOLO 实现，叫做 **darkflow**。darkflow 仓库甚至提供了一个工具，可以让你将模型导出并在移动设备上部署。
- en: Problem 12 - Object Detection - Faster RCNN
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 12 - 目标检测 - Faster RCNN
- en: 'Project link: [https://github.com/smallcorgi/Faster-RCNN_TF](https://github.com/smallcorgi/Faster-RCNN_TF)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '项目链接: [https://github.com/smallcorgi/Faster-RCNN_TF](https://github.com/smallcorgi/Faster-RCNN_TF)'
- en: Faster RCNN is another state-of-the-art method for Object Detection. This method
    offers high precision on the result and also inspires lots of methods for many
    other problems. The inference speed of Faster RCNN is not as fast as YOLO. However,
    if you need high precision on the detection results, you may want to consider
    Faster RCNN.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Faster RCNN 是另一种用于目标检测的最先进方法。该方法提供了高精度的结果，并且激发了许多其他问题的方法。Faster RCNN 的推理速度不如
    YOLO 快。然而，如果你需要高精度的检测结果，可能会想要考虑使用 Faster RCNN。
- en: Problem 13 - Person Detection - tensorbox
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 13 - 人物检测 - tensorbox
- en: 'Project link: [https://github.com/Russell91/TensorBox](https://github.com/Russell91/TensorBox)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[https://github.com/Russell91/TensorBox](https://github.com/Russell91/TensorBox)
- en: Tensorbox is a TensorFlow implementation of the method by Russell Stewart and
    Mykhaylo Andriluka. The goal of this method is a bit different from the preceding
    methods. Tensorbox focuses on solving the problem of crowd person detection. They
    use a recurrent LSTM layer for sequence generation of the bounding boxes and define
    a new loss function that operates of the set of detection results.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Tensorbox 是 Russell Stewart 和 Mykhaylo Andriluka 提出的一个方法的 TensorFlow 实现。这个方法的目标与前面提到的几种方法稍有不同。Tensorbox
    侧重于解决人群人物检测的问题。它们使用一个递归的 LSTM 层来生成边界框的序列，并定义了一种新的损失函数，这个损失函数作用于检测结果集合。
- en: Problem 14 - Magenta
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 14 - Magenta
- en: 'Project link: [https://github.com/tensorflow/magenta](https://github.com/tensorflow/magenta)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[https://github.com/tensorflow/magenta](https://github.com/tensorflow/magenta)
- en: 'Magenta is a project from the Google Brain team that focuses on Music and Art
    Generation using Deep Learning. This is a very active repository with many implementations
    of interesting problems such as image stylization, melody generation, or generating
    sketches. You can visit the following link to have access to Magenta''s models:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Magenta 是 Google Brain 团队的一个项目，专注于使用深度学习进行音乐和艺术生成。这是一个非常活跃的代码库，涵盖了许多有趣问题的实现，比如图像风格化、旋律生成或生成草图。你可以访问以下链接，获取
    Magenta 的模型：
- en: '[https://github.com/tensorflow/magenta/tree/master/magenta/models](https://github.com/tensorflow/magenta/tree/master/magenta/models)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/tensorflow/magenta/tree/master/magenta/models](https://github.com/tensorflow/magenta/tree/master/magenta/models)'
- en: Problem 15 - Wavenet
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 15 - Wavenet
- en: 'Project link: [https://github.com/ibab/tensorflow-wavenet](https://github.com/ibab/tensorflow-wavenet)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[https://github.com/ibab/tensorflow-wavenet](https://github.com/ibab/tensorflow-wavenet)
- en: WaveNet is a neural network architecture for audio generation from Google Deep
    Mind. WaveNet is trained to generate raw audio waveform and has shown good results
    for text-to-speech and audio generation. According to Deep Mind, WaveNet reduced
    the gap between the previous methods and human-level performance by over 50% in
    text-to-speech problems for both US English and Mandarin Chinese.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: WaveNet 是 Google Deep Mind 提出的用于音频生成的神经网络架构。WaveNet 被训练生成原始音频波形，并在语音合成和音频生成中取得了良好的结果。根据
    Deep Mind 的说法，WaveNet 在英语和普通话的语音合成任务中，将传统方法和人类水平表现之间的差距缩小了超过 50%。
- en: Problem 16 - Deep Speech
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 16 - Deep Speech
- en: 'Project link: [https://github.com/mozilla/DeepSpeech](https://github.com/mozilla/DeepSpeech)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[https://github.com/mozilla/DeepSpeech](https://github.com/mozilla/DeepSpeech)
- en: Deep Speech is an open source speech-to-text engine, based on a research paper
    from Baidu. Speech-to-text is a very interesting problem and Deep Speech is one
    of the state-of-the-art methods for solving it. With the TensorFlow implementation
    of Mozilla, you can even learn how to use TensorFlow across more than one machine.
    However, there is still a problem that personal researchers can't access the same
    large scale speech-to-text datasets as a large company. So, even though we can
    use Deep Speech or implement it ourselves, it is still hard to have a good model
    for production.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Deep Speech 是一个开源的语音转文本引擎，基于百度的研究论文。语音转文本是一个非常有趣的问题，Deep Speech 是解决这一问题的最先进方法之一。通过
    Mozilla 提供的 TensorFlow 实现，你甚至可以学习如何在多台机器上使用 TensorFlow。然而，仍然存在一个问题，即个人研究人员无法访问与大公司相同的大规模语音转文本数据集。因此，尽管我们可以使用
    Deep Speech 或自己实现它，但仍然很难为生产环境提供一个良好的模型。
- en: Interesting Projects
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有趣的项目
- en: In this section, we will show you some interesting projects that are implemented
    in other deep learning frameworks. These projects give significant results over
    very difficult problems. You may want to challenge yourself to implement these
    methods in TensorFlow.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向你展示一些在其他深度学习框架中实现的有趣项目。这些项目在解决非常困难的问题上取得了显著的成果。你可能会想挑战自己，将这些方法实现到 TensorFlow
    中。
- en: Problem 17 - Interactive Deep Colorization - iDeepColor
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 17 - 交互式深度着色 - iDeepColor
- en: 'Project link: [https://richzhang.github.io/ideepcolor/](https://richzhang.github.io/ideepcolor/)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[https://richzhang.github.io/ideepcolor/](https://richzhang.github.io/ideepcolor/)
- en: Interactive Deep Colorization is research being carried out by Richard Zhang
    and Jun-Yan Zun, and others, for user-guided image colorization. In this system,
    users can give the network a few hints of colors for some points in the image
    and the network will propagate user inputs along with semantic information learned
    from large scale data. The colorization can be performed in real time with one
    single forward pass.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 互动深度图像着色是Richard Zhang、Jun-Yan Zun等人正在开展的研究，旨在实现用户引导的图像着色。在该系统中，用户可以为图像中的某些点提供几种颜色提示，网络将根据用户的输入以及从大规模数据中学到的语义信息传播颜色。这种着色可以通过单次前向传播实时执行。
- en: Problem 18 - Tiny face detector
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 18 - 微小面部检测器
- en: 'Project link: [https://github.com/peiyunh/tiny](https://github.com/peiyunh/tiny)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[https://github.com/peiyunh/tiny](https://github.com/peiyunh/tiny)
- en: This project is a face detector that focuses on finding the small faces in the
    image by Peiyun Hu and Deva Ramanan. While most face detectors only focus on large
    objects in the image, this tiny face detector method can work with very small
    faces, but still, reduce the error by a factor of two compared with prior methods
    on the WIDER FACE dataset.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目是由Peiyun Hu和Deva Ramanan提出的面部检测器，专注于识别图像中的小面部。虽然大多数面部检测器只关注图像中的大物体，但这一微小面部检测方法能够处理非常小的面部，并且与之前的方法相比，在WIDER
    FACE数据集上减少了两倍的错误率。
- en: Problem 19 - People search
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 19 - 人物搜索
- en: 'Project link: [https://github.com/ShuangLI59/person_search](https://github.com/ShuangLI59/person_search)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[https://github.com/ShuangLI59/person_search](https://github.com/ShuangLI59/person_search)
- en: This project is the implementation of the paper by Tong Xiao, and others that
    focuses on the problem of person detection and re-identification. This project
    can be used in video surveillance. The existing person re-identification methods
    mainly assume that the person is cropped and aligned. However, in real-world scenarios,
    the person detection algorithm may fail to extract the perfect crop region of
    the person and lower the identification accuracy. In this project, the authors
    solve detection and identification jointly in a novel architecture inspired by
    Faster RCNN. The current project is implemented in the Caffe Deep Learning Framework.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目是Tong Xiao等人提出的论文的实现，专注于人物检测和重新识别问题。该项目可用于视频监控。现有的人物重新识别方法主要假设人物已经被裁剪并对齐。然而，在现实场景中，人物检测算法可能无法完美地提取人物的裁剪区域，从而降低识别准确性。在本项目中，作者在受Faster
    RCNN启发的全新架构中联合解决检测和识别问题。当前项目使用Caffe深度学习框架实现。
- en: Problem 20 - Face Recognition - MobileID
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 20 - 面部识别 - MobileID
- en: 'Project link: [https://github.com/liuziwei7/mobile-id](https://github.com/liuziwei7/mobile-id)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[https://github.com/liuziwei7/mobile-id](https://github.com/liuziwei7/mobile-id)
- en: This project provides an extremely fast face recognition system that can run
    in 250 FPS with high accuracy. The model is learned by using the output of the
    state-of-the-art face recognition DeepID. However, the mobile ID model can perform
    so fast that it can be used in situations where processing and memory are limited.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目提供了一种极快的面部识别系统，能够以250帧每秒的速度运行，同时保持高准确性。该模型通过使用最先进的面部识别系统DeepID的输出进行训练。然而，移动ID模型的运算速度极快，适用于处理能力和内存受限的情况。
- en: Problem 21 - Question answering - DrQA
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题 21 - 问答系统 - DrQA
- en: 'Project link: [https://github.com/facebookresearch/DrQA](https://github.com/facebookresearch/DrQA)'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 项目链接：[https://github.com/facebookresearch/DrQA](https://github.com/facebookresearch/DrQA)
- en: DrQA is a system for open-domain question answering from Facebook. DrQA focuses
    on solving the task of *machine reading* where the model will try to understand
    the Wikipedia documents and give the answer for any question from users. The current
    project is implemented in PyTorch. You may find it interesting to implement our
    own solution in TensorFlow.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: DrQA 是Facebook推出的一个开放领域问答系统。DrQA专注于解决*机器阅读*任务，在该任务中，模型会试图理解维基百科文档，并为用户的任何问题提供答案。当前项目是用PyTorch实现的。你可能会对在TensorFlow中实现我们自己的解决方案感兴趣。
- en: Caffe to TensorFlow
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Caffe到TensorFlow
- en: In this section, we will show you how to take advantage of many pre-trained
    models from Caffe Model Zoo ([https://github.com/BVLC/caffe/wiki/Model-Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo)).
    There are lots of Caffe models for different tasks with all kinds of architectures.
    After converting these models to TensorFlow, you can use it as a part of your
    architectures or you can fine-tune our model for different tasks. Using these
    pre-trained models as initial weights is an effective approach for training instead
    of training from scratch. We will show you how to use a `caffe-to-tensorflow` approach
    from Saumitro Dasgupta at [https://github.com/ethereon/caffe-tensorflow](https://github.com/ethereon/caffe-tensorflow).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将向你展示如何利用来自Caffe Model Zoo的多个预训练模型([https://github.com/BVLC/caffe/wiki/Model-Zoo](https://github.com/BVLC/caffe/wiki/Model-Zoo))。这里有许多适用于不同任务的Caffe模型，涵盖各种架构。将这些模型转换为TensorFlow后，你可以将其作为你架构的一部分，或者可以针对不同任务微调我们的模型。使用这些预训练模型作为初始权重是训练的有效方法，而不是从头开始训练。我们将展示如何使用Saumitro
    Dasgupta提供的`caffe-to-tensorflow`方法，详见[https://github.com/ethereon/caffe-tensorflow](https://github.com/ethereon/caffe-tensorflow)。
- en: However, there are lots of differences between Caffe and TensorFlow. This technique
    only supports a subset of layer types from Caffe. Even though there are some Caffe
    architectures that are verified by the author of this project such as ResNet,
    VGG, and GoogLeNet.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Caffe和TensorFlow之间有很多差异。这项技术仅支持Caffe中一部分层类型。即便如此，仍有一些Caffe架构，如ResNet、VGG和GoogLeNet，已被该项目的作者验证。
- en: 'First, we need to clone the `caffe-tensorflow` repository using the `git clone` command:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要使用`git clone`命令克隆`caffe-tensorflow`仓库：
- en: '[PRE0]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we need to change the directory to the `caffe-to-tensorflow` directory
    and run the convert python script to see some help messages:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要切换到`caffe-to-tensorflow`目录，并运行转换的Python脚本，以查看一些帮助消息：
- en: '[PRE1]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: According to this help message, we can know the parameters of the `convert.py`
    script. In summary, we will use this `convert.py` to create the network architecture
    in TensorFlow with the flag code-output-path and convert the pre-trained weights
    with the flag data-output-path.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 根据此帮助消息，我们可以了解`convert.py`脚本的参数。总结来说，我们将使用这个`convert.py`脚本，通过标志`code-output-path`在TensorFlow中创建网络架构，并通过标志`data-output-path`转换预训练权重。
- en: 'Before we start converting the models, we need to get some pull requests from
    contributors of this project. There are some issues with the current master branch
    that we can''t use the latest TensorFlow (version 1.3 at the time of writing)
    and python-protobuf (version 3.4.0 at the time of writing). Therefore, we will
    get the code using the following pull requests:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始转换模型之前，我们需要从该项目的贡献者那里获取一些拉取请求。当前的主分支存在一些问题，我们无法使用最新版本的TensorFlow（本文写作时为1.3版）和python-protobuf（本文写作时为3.4.0版）。因此，我们将通过以下拉取请求获取代码：
- en: '[https://github.com/ethereon/caffe-tensorflow/pull/105](https://github.com/ethereon/caffe-tensorflow/pull/105)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/ethereon/caffe-tensorflow/pull/105](https://github.com/ethereon/caffe-tensorflow/pull/105)'
- en: '[https://github.com/ethereon/caffe-tensorflow/pull/133](https://github.com/ethereon/caffe-tensorflow/pull/133)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/ethereon/caffe-tensorflow/pull/133](https://github.com/ethereon/caffe-tensorflow/pull/133)'
- en: You need to open the preceding links to see if the pull requests are merged
    or not. If it is still in `open` status, you will need to follow the next part.
    Otherwise, you can skip the merged `pull` requests.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要打开上述链接查看拉取请求是否已合并。如果它仍然处于`open`状态，你需要遵循下一部分。否则，你可以跳过已合并的`pull`请求。
- en: 'First, we will get the code from pull request `105`:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将获取拉取请求`105`中的代码：
- en: '[PRE2]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, from pull request `133`:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，从拉取请求`133`开始：
- en: '[PRE3]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As you can see, there are some conflicts in the `kaffe/tensorflow/network.py`
    file. We will show you how to resolve these `conflicts`, as follows.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，`kaffe/tensorflow/network.py`文件中存在一些冲突。我们将向你展示如何解决这些`冲突`，如下所示。
- en: 'First, we will solve the conflict at line 137:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将在第137行解决冲突：
- en: '![](img/8cbf68bc-d3f7-4fb7-997b-3f6daa91a467.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8cbf68bc-d3f7-4fb7-997b-3f6daa91a467.png)'
- en: 'We remove the HEAD part from line 137 to line 140\. The final result will look
    like this:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从第137行到第140行删除HEAD部分。最终结果将如下所示：
- en: '![](img/24ec3b97-1597-4c60-87e7-ea065ad10bcc.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/24ec3b97-1597-4c60-87e7-ea065ad10bcc.png)'
- en: 'Next, we will solve the conflict at line 185:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在第185行解决冲突：
- en: '![](img/e98bcebb-7236-47f4-8628-55673a01f83a.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e98bcebb-7236-47f4-8628-55673a01f83a.png)'
- en: 'We also remove the HEAD part from line 185 to line 187\. The final result will
    look like this:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要从第185行到第187行删除HEAD部分。最终结果将如下所示：
- en: '![](img/699ebeba-5219-4f3e-851c-c7970784f55e.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/699ebeba-5219-4f3e-851c-c7970784f55e.png)'
- en: In the `caffe-to-tensorflow` directory, there is a directory named examples
    that contains the code and data for the MNIST and ImageNet challenge. We will
    show you how to work with the MNIST model. The ImageNet challenge is not much
    different.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在`caffe-to-tensorflow`目录中，有一个名为 examples 的目录，包含了 MNIST 和 ImageNet 挑战的代码和数据。我们将向您展示如何使用
    MNIST 模型。ImageNet 挑战与之大致相同。
- en: 'First, we will convert the MNIST architecture from Caffe to TensorFlow using
    the following command:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用以下命令将 MNIST 架构从 Caffe 转换为 TensorFlow：
- en: '[PRE4]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, we will convert the MNIST pre-trained Caffe model at `examples/mnist/lenet_iter_10000.caffemodel`
    using the following command:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用以下命令将预训练的 MNIST Caffe 模型`examples/mnist/lenet_iter_10000.caffemodel`转换为
    TensorFlow：
- en: '[PRE5]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The result will look like this:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '[PRE6]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As you can see, these commands will create a python file named `mynet.py` and
    a `numpy` file named `mynet.npy` in the current directory. We also need to add
    the current directory to the `PYTHONPATH` to allow the further code to import
    `mynet.py`:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这些命令将在当前目录中创建一个名为`mynet.py`的 Python 文件和一个名为`mynet.npy`的`numpy`文件。我们还需要将当前目录添加到`PYTHONPATH`，以便后续代码可以导入`mynet.py`：
- en: '[PRE7]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The last two numbers in each line is the loss and accuracy of the fine-tune
    process. You can see that the fine-tune process can easily achieve 100% accuracy
    with the pre-trained weights from the Caffe model.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 每行中的最后两个数字是微调过程的损失和准确率。您可以看到，使用来自 Caffe 模型的预训练权重，微调过程可以轻松达到 100% 的准确率。
- en: Now, we will take a look at the `finetune_mnist.py` file to see how the pre-trained
    weights are used.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将查看`finetune_mnist.py`文件，看看如何使用预训练权重。
- en: 'First, they import the `mynet` python with the following code:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，他们使用以下代码导入`mynet` python：
- en: '[PRE8]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, they create some placeholders for `images` and `labels` and compute the
    `loss` using the layers `ip2` as follows:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，他们为`images`和`labels`创建了一些占位符，并使用层`ip2`计算`loss`，如下所示：
- en: '[PRE9]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: After that, the fine-tune process is independent from the Caffe framework.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，微调过程将独立于 Caffe 框架进行。
- en: TensorFlow-Slim
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow-Slim
- en: 'TensorFlow-Slim is a light-weight library for defining, training, and evaluating
    complex models in TensorFlow. With the TensorFlow-Slim library, we can build,
    train, and evaluate the model easier by providing lots of high-level layers, variables,
    and regularizers. We recommend that you take a look at the TensorFlow-Slim library
    at the following link: [https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow-Slim 是一个轻量级库，用于在 TensorFlow 中定义、训练和评估复杂模型。使用 TensorFlow-Slim 库，我们可以通过提供许多高级层、变量和正则化器，轻松构建、训练和评估模型。我们建议您查看以下链接中的
    TensorFlow-Slim 库：[https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)
- en: 'There are also lots of pre-trained models that are provided using TensorFlow-Slim.
    You can take advantage of high-level TensorFlow layers and models at the following
    link:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 还提供了许多使用 TensorFlow-Slim 的预训练模型。您可以通过以下链接利用高级 TensorFlow 层和模型：
- en: '[https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)'
- en: Summary
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have provided lots of interesting challenges and problems
    that you can try to solve and learn from to improve your TensorFlow skills. At
    the end of this chapter, we also guided you to convert the Caffe model to TensorFlow and
    introduced you to the high-level TensorFlow library, TensorFlow-Slim.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们提供了许多有趣的挑战和问题，您可以尝试解决并从中学习，以提升您的 TensorFlow 技能。在本章末尾，我们还指导您将 Caffe 模型转换为
    TensorFlow，并向您介绍了高级 TensorFlow 库 TensorFlow-Slim。
