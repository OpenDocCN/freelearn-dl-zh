- en: Building a Machine Vision Mobile App to Classify Flower Species
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个机器视觉移动应用程序来分类花的种类
- en: In this chapter, we are going to use the theoretical knowledge we have learned
    in previous chapters to create a mobile application that will classify a specific
    species of flower. By utilizing use your mobile camera and pointing it at a flower,
    the application will analyze the image and make its best educated guess as to
    the species of that flower. This is where we put to work the understanding we
    have gained about the workings of a **convolutional neural network** (**CNN**).
    We will also learn a bit more about using TensorFlow as well as some tools such
    as TensorBoard. But before we dive in too deep, let’s talk about a few things
    first.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将利用我们在前几章中学到的理论知识来创建一个可以分类特定花种的移动应用程序。通过使用您的移动摄像头对着花拍照，该应用程序将分析图像并尽力猜测出那种花的种类。这是我们把对卷积神经网络（**CNN**）的理解付诸实践的地方。我们还将学习更多关于使用TensorFlow以及一些工具如TensorBoard的内容。但在我们深入研究之前，让我们先谈谈一些事情。
- en: Throughout this chapter we use terms that may not be familiar to all, so let’s
    make sure we’re all on the same page as to what they mean.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用一些可能不为所有人熟悉的术语，因此让我们确保我们对它们的含义有一致的理解。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: CoreML versus TensorFlow Lite
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CoreML与TensorFlow Lite的对比
- en: What is MobileNet
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是MobileNet
- en: Datasets for image classification
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于图像分类的数据集
- en: Creating your own image dataset
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建您自己的图像数据集
- en: Using TensorFlow to build the model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorFlow构建模型
- en: Running TensorBoard
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行TensorBoard
- en: CoreML versus TensorFlow Lite
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CoreML与TensorFlow Lite的对比
- en: In the machine learning world, there are two efforts (as of the time of this
    writing) taking place in order to improve the mobile AI experience. Instead of
    offloading AI or ML processing to the cloud and a data center, the faster option
    would be to process data on the device itself. In order to do this, the model
    must already be pre-trained, which means that there is a chance that it is not
    trained for exactly what you are going to use it for.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习领域，有两个努力（截至撰写本文时）正在进行，旨在改善移动AI体验。而不是将AI或ML处理转移到云端和数据中心，更快的选择是在设备本身上处理数据。为了做到这一点，模型必须已经预先训练好，这意味着它可能并不完全训练用于您要使用的目的。
- en: In this space, Apple’s effort (iOS) is called **Core ML**, and Google’s (Android)
    is called **TensorFlow Lite**. Let’s talk briefly about both.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个领域，苹果的努力（iOS）称为**Core ML**，而谷歌的（Android）称为**TensorFlow Lite**。让我们简要讨论一下两者。
- en: CoreML
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CoreML
- en: The CoreML framework from Apple provides a large selection of neural network
    types. This allows developers to be able to experiment with different designs
    when developing their apps. Camera and microphone data are just two area which
    can be leveraged for things like image recognition, natural language processing,
    and more. There are several pre-trained models that developers can use straight
    out of the box, and tweak as necessary for their application.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Apple的CoreML框架提供了大量的神经网络类型。这使得开发人员可以在开发应用程序时尝试不同的设计。摄像头和麦克风数据只是可以用于诸如图像识别、自然语言处理等领域的两个可以利用的区域。有几个预训练模型开发人员可以直接使用，并根据需要进行调整。
- en: TensorFlow Lite
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow Lite
- en: TensorFlow Lite is what is known as a local-device version of TensorFlow, meaning
    it is designed to run on your mobile device itself. As of the time of this writing
    it is still in pre-release status, so an exact comparison to CoreML is difficult.
    We will have to wait and see what the final offering provides. For now, simply
    be aware there are two options for mobile device-local AI and machine learning.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Lite是TensorFlow的本地设备版本，意味着它设计用于在您的移动设备上运行。截至撰写本文时，它仍处于预发布状态，因此很难与CoreML进行直接比较。我们需要等待并看看最终提供的功能。目前，只需知道在移动设备上有两个选项可供选择的本地AI和机器学习。
- en: What is MobileNet?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是MobileNet？
- en: Before we dive in too deep, let us first talk about a term you will hear used
    quite a bit in this chapter, **MobileNets**. What is a MobileNet you might ask?
    Simply put, it’s an architecture which is designed specifically for mobile and
    embedded vision-based applications. On such devices there is a lack of computing
    power available for such processing, which therefore increases the need for a
    better solution that one used on a desktop environment.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入之前，我们先来谈谈你在本章中会经常听到的一个术语——**MobileNets**。你可能会问，什么是MobileNet？简而言之，它是一种专门为移动设备和嵌入式视觉应用设计的架构。在这些设备上，处理这类任务的计算能力有限，因此迫切需要一种比桌面环境中使用的解决方案更好的方法。
- en: 'The **MobileNet** architecture was proposed by Google, and briefly:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**MobileNet**架构由Google提出，简要来说：'
- en: Uses depth-wise separable convolutions. This significantly reduces the number
    of parameters when compared to a neural network using normal convolutions with
    the same depth. The result is what is known as a **light-weight deep neural network**.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用深度可分离卷积。与使用普通卷积的神经网络相比，这显著减少了参数的数量，结果就是所谓的**轻量级深度神经网络**。
- en: '**Depth-wise convolution**, followed by **Pointwise convolution**, replaces
    the normal convolution process.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**深度卷积**，随后是**点卷积**，替代了正常的卷积过程。'
- en: 'In order to simplify things, we are going to break down this chapter into the
    following two sections:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化问题，我们将本章分为以下两个部分：
- en: '**Datasets for Image Classification**: In this section we will explore the
    various datasets (all of which are available online) that can be used for image
    classification. We will also address the issue of how to create our own datasets,
    if necessary.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像分类数据集**：在这一节中，我们将探索可用于图像分类的各种数据集（所有这些数据集都可以在线获得）。我们还将讨论如何在必要时创建我们自己的数据集。'
- en: '**Using TensorFlow to Build the Model**: In this section we will use TensorFlow
    to train our classification model. We do this by using a pretrained model called
    **MobileNet**. MobileNets are a family of mobile-first computer vision models
    for TensorFlow, designed to maximize accuracy while considering the restricted
    resources available for an on-device or embedded application.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用TensorFlow构建模型**：在这一节中，我们将使用TensorFlow来训练我们的分类模型。我们通过使用一个名为**MobileNet**的预训练模型来实现这一点。MobileNets是一系列为TensorFlow设计的移动优先计算机视觉模型，旨在在考虑设备上有限资源的情况下最大化准确性。'
- en: In addition, we will look at converting the output model into a `.tflite` format,
    which can be used within other mobile or embedded devices. TFLite stands for TensorFlow
    Lite. You can learn more about TensorFlow Lite via any internet search engine.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，我们将研究如何将输出模型转换为 `.tflite` 格式，该格式可用于其他移动或嵌入式设备。TFLite代表TensorFlow Lite。你可以通过任何互联网搜索引擎了解更多关于TensorFlow
    Lite的信息。
- en: Datasets for image classification
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像分类数据集
- en: For our flower classification example, we will be using the University of Oxford's **Visual
    Geometry Group** (**VGG**) image dataset collection. The collection can be accessed
    at [http://www.robots.ox.ac.uk/~vgg/data/](http://www.robots.ox.ac.uk/~vgg/data/).
    [](http://www.robots.ox.ac.uk/~vgg/data/)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的花卉分类示例，我们将使用牛津大学的**视觉几何组**（**VGG**）图像数据集。该数据集可以通过以下链接访问：[http://www.robots.ox.ac.uk/~vgg/data/](http://www.robots.ox.ac.uk/~vgg/data/)。
- en: The VGG is the same department that won previous ImageNet competitions. The
    pretrained models, such as VGG14 and VGG16, were built by this department and
    they won in 2014 and 2016, respectively. These datasets are used by the VGG to
    train and evaluate the models that they build.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: VGG是曾在以往的ImageNet竞赛中获胜的部门。像VGG14和VGG16这样的预训练模型是由该部门构建的，它们分别在2014年和2016年获得了胜利。这些数据集被VGG用于训练和评估他们所构建的模型。
- en: The flower dataset can be found in the Fine-Grain Recognition Datasets section
    of the page, along with textures and pet datasets. Click on Flower Category Datasets,
    or use the following link to access the flower datasets from VGG, [http://www.robots.ox.ac.uk/~vgg/data/flowers/](http://www.robots.ox.ac.uk/~vgg/data/flowers/).
    [](http://www.robots.ox.ac.uk/~vgg/data/flowers/)
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 花卉数据集可以在页面的精细识别数据集部分找到，此外还有纹理和宠物数据集。点击“Flower Category Datasets”，或使用以下链接访问VGG的花卉数据集，[http://www.robots.ox.ac.uk/~vgg/data/flowers/](http://www.robots.ox.ac.uk/~vgg/data/flowers/)。
- en: Here, you can find two datasets, one with 17 different species of flowers, and
    the other with 102 different species of flowers. You can choose either one based
    on their ease of use for the tutorial, or based on the kind of processing that
    is available at your disposal.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以找到两个数据集，一个包含17种不同的花卉，另一个包含102种不同的花卉。你可以根据它们在教程中的易用性，或者根据你所能使用的处理方法选择其中的一个。
- en: Using a larger dataset means that the training will take longer, and so will
    the data processing before training; therefore, we recommend that you choose wisely.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用更大的数据集意味着训练时间会更长，训练前的数据处理时间也会更长；因此，我们建议你谨慎选择。
- en: 'Here is a subset of the images you will find here. As you will see, the folder
    names match up identically with those we will use a bit later on in this chapter:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是你将在此处找到的图像子集。正如你所看到的，文件夹名称与我们在本章稍后会用到的完全一致：
- en: '![](img/390e5a15-74f2-47e8-801f-91e7d469466f.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](img/390e5a15-74f2-47e8-801f-91e7d469466f.png)'
- en: 'Aside from the images we talked about above, here are several additional links
    that you can use to get image data for similar classification use cases should
    you ever desire to use them:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 除了我们上面提到的图像外，下面是一些额外的链接，若你将来需要类似分类用途的图像数据，可以使用它们：
- en: '**CVonline datasets**: [http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm](http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CVonline数据集**: [http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm](http://homepages.inf.ed.ac.uk/rbf/CVonline/Imagedbase.htm)'
- en: '**CVpapers datasets**: [http://www.cvpapers.com/datasets.html](http://www.cvpapers.com/datasets.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CVpapers数据集**: [http://www.cvpapers.com/datasets.html](http://www.cvpapers.com/datasets.html)'
- en: '**Image datasets**: [http://wiki.fast.ai/index.php/Image_Datasets](http://wiki.fast.ai/index.php/Image_Datasets)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像数据集**: [http://wiki.fast.ai/index.php/Image_Datasets](http://wiki.fast.ai/index.php/Image_Datasets)'
- en: '**Deep learning datasets**: [http://deeplearning.net/datasets/](http://deeplearning.net/datasets/)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度学习数据集**: [http://deeplearning.net/datasets/](http://deeplearning.net/datasets/)'
- en: '**COCO datsets**: [http://cocodataset.org/#home](http://cocodataset.org/#home)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**COCO数据集**: [http://cocodataset.org/#home](http://cocodataset.org/#home)'
- en: '**ImageNet datasets**: [http://www.image-net.org/](http://www.image-net.org/)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ImageNet数据集**: [http://www.image-net.org/](http://www.image-net.org/)'
- en: '**Open Images datasets**: [https://storage.googleapis.com/openimages/web/index.html](https://storage.googleapis.com/openimages/web/index.html)'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开放图像数据集**: [https://storage.googleapis.com/openimages/web/index.html](https://storage.googleapis.com/openimages/web/index.html)'
- en: '**Kaggle datasets**: [https://www.kaggle.com/datasets?sortBy=relevance&group=featured&search=image](https://www.kaggle.com/datasets?sortBy=relevance&group=featured&search=image)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kaggle数据集**: [https://www.kaggle.com/datasets?sortBy=relevance&group=featured&search=image](https://www.kaggle.com/datasets?sortBy=relevance&group=featured&search=image)'
- en: '**Open datasets**: [https://skymind.ai/wiki/open-datasets](https://skymind.ai/wiki/open-datasets)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开放数据集**: [https://skymind.ai/wiki/open-datasets](https://skymind.ai/wiki/open-datasets)'
- en: '**Wikipedia**: [https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#Object_detection_and_recognition](https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#Object_detection_and_recognition)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维基百科**: [https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#Object_detection_and_recognition](https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#Object_detection_and_recognition)'
- en: Creating your own image dataset using Google images
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Google图片创建你自己的图像数据集
- en: Let’s say, for whatever reason, we need to determine what kind of dog a picture
    is of, but we do not have any pictures readily available on our computer. What
    can we do? Well, perhaps the easiest approach is to open Google Chrome and search
    for the images online.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 假设因为某种原因，我们需要确定一张图片是什么狗，但电脑上没有现成的图片。我们该怎么办呢？或许最简单的方法是打开Google Chrome并在线搜索图片。
- en: 'As an example, let’s say we are interested in Doberman dogs. Just open Google
    Chrome and search for **doberman** pictures as shown below:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以Doberman犬为例，假设我们对Doberman犬感兴趣。只需打开Google Chrome并搜索**doberman**的图片，如下所示：
- en: '**Perform a search for Doberman pictures**: On searching, following the result were
    obtained:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**搜索Doberman犬的图片**: 搜索后，得到以下结果：'
- en: '![](img/49739228-8671-4818-9de8-7aaadbb7b33a.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/49739228-8671-4818-9de8-7aaadbb7b33a.png)'
- en: '**Open the JavaScript console**: You can find the JavaScript Console in Chrome
    in the top-right menu:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**打开JavaScript控制台**: 你可以在Chrome的右上角菜单中找到JavaScript控制台：'
- en: '![](img/95960d28-7610-4dc0-9354-dd2383ef520a.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/95960d28-7610-4dc0-9354-dd2383ef520a.png)'
- en: 'Click on More tools and then Developer tools:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“更多工具”，然后选择“开发者工具”：
- en: '![](img/21a212a0-9ecb-4c29-b2c0-c3ffff13b4c6.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/21a212a0-9ecb-4c29-b2c0-c3ffff13b4c6.png)'
- en: 'Make sure that you select the Console tab, as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 确保选择“控制台”标签页，如下所示：
- en: '![](img/741be916-0f66-4f48-b82f-2c6a18247ca8.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/741be916-0f66-4f48-b82f-2c6a18247ca8.png)'
- en: '**Using JavaScript**: Continue to scroll down until you think you have enough
    images for your use case. Once this is done, go back to the Console tab in Developer
    tools, and then copy and paste the following script:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用JavaScript**：继续向下滚动，直到你认为已经有足够的图像用于你的用例。完成后，返回到开发者工具中的Console标签，然后复制并粘贴以下脚本：'
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This code snippet collects all the image URLs and saves them to a file called
    `urls.txt` in your default `Downloads` directory.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码会收集所有图像的URL，并将它们保存到名为`urls.txt`的文件中，该文件位于你的默认`Downloads`目录。
- en: '**Use Python to download the images**: Now, we will use Python to read the
    URLs of the images from `urls.txt` and download all the images into a folder:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用Python下载图像**：现在，我们将使用Python从`urls.txt`读取图像的URL，并将所有图像下载到一个文件夹中：'
- en: '![](img/bfeb9d0e-f904-4a4b-9ab9-f98a96ce1561.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bfeb9d0e-f904-4a4b-9ab9-f98a96ce1561.png)'
- en: 'This can be done easily by following the following steps:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过以下步骤轻松完成：
- en: 'Open a Python notebook and copy and paste the following code to download the
    images:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Python笔记本，复制并粘贴以下代码以下载图像：
- en: '[PRE1]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After importing, start constructing the arguments, and after constructing parsing
    the arguments is important:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入后，开始构造参数，并且构造后解析参数非常重要：
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The next step includes grabbing the list of URLs from the input file counting
    total number of images downloaded:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步包括从输入文件中获取URL列表，并计算下载的图像总数：
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'During the download process, the exceptions that are thrown need to be handled:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下载过程中，需要处理抛出的异常：
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The image paths that are downloaded need to be looped over:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载的图像路径需要循环遍历：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, decide whether the image should be deleted or not and accordingly initialize:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，决定图像是否应该被删除，并据此初始化：
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The image needs to be loaded. Let''s try to do that:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要加载图像。让我们尝试执行此操作：
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If we weren''t able to load the image properly, since the image is `None`,
    then it should be deleted from the disk:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们未能正确加载图像，由于图像为`None`，则应该将其从磁盘中删除：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Also, if OpenCV was unable to load the image, it means the image is corrupt
    and should be deleted:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，如果OpenCV无法加载图像，这意味着图像已损坏，应当删除该图像：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Give a final check and see whether the image was deleted:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后进行检查，查看图像是否已被删除：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: With that complete, let’s download this notebook as a Python file and name it `image_download.py`.
    Make sure that you place the `urls.txt` file in the same folder as the Python
    file that you just created. This is very important.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，让我们将此笔记本下载为Python文件并命名为`image_download.py`。确保将`urls.txt`文件放置在与你刚刚创建的Python文件相同的文件夹中。这一点非常重要。
- en: 'Next, we need to execute the Python file we just created. We will do so by
    using the command line as shown here (make sure your `path` variable points to
    your Python location):'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要执行刚刚创建的Python文件。我们将通过使用命令行来执行，如下所示（确保`path`变量指向你的Python位置）：
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'By executing this command, the images will be downloaded to the folder named Doberman.
    Once this has been completed, you should see all the images of the Doberman that
    you viewed in Google Chrome, like what is shown in the following image:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此命令后，图像将被下载到名为Doberman的文件夹中。完成后，你应该能看到所有在Google Chrome中查看到的杜宾犬图像，类似于以下所示的图像：
- en: '![](img/06057770-7f65-4faf-9b99-c9c6f2bdbb0c.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/06057770-7f65-4faf-9b99-c9c6f2bdbb0c.png)'
- en: 'Select the required folder for saving the images as shown:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 选择所需的文件夹以保存图像，如下所示：
- en: '![](img/8e2f30d2-cac4-4cba-8228-62723d73a617.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8e2f30d2-cac4-4cba-8228-62723d73a617.png)'
- en: That's it we now have a folder full of Doberman images. The same method can
    be applied to create a folder of any other type of category that we may need.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，我们现在拥有了一个充满杜宾犬图像的文件夹。相同的方法可以应用于创建任何其他类型类别的文件夹。
- en: There may be a number of images that are part of the Google image results that
    are not desirable. Ensure that you browse through the images and remove any unwanted
    images.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会有一些来自Google图像结果的图像是不需要的。确保浏览图像并移除任何不想要的图像。
- en: Alternate approach of creating custom datasets from videos
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从视频创建自定义数据集的替代方法
- en: There may be occasions when the images we find via the Internet do not satisfy
    our requirements or, we may find no images at all. This could be because of the
    uniqueness of the data, the use case at hand, copyright restrictions, the required
    resolution, etc. In this case, an alternative approach would be to record a video
    of the object you need, extract the frames of that video that meet your requirements,
    and save each frame as an individual image. How would we go about doing that?
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们通过互联网找到的图像可能无法满足我们的需求，或者我们根本找不到任何图像。这可能是由于数据的独特性、当前的用例、版权限制、所需分辨率等原因造成的。在这种情况下，另一种方法是记录需要的物体的视频，提取符合要求的视频帧，并将每一帧保存为单独的图像。我们该如何操作呢？
- en: Let's say that we have a skin condition that we are unable to find information
    about online. We need to somehow classify what this skin condition might be. However,
    in order to do this, we need to have an image of this condition. Accordingly,
    we could take a video of that skin condition and save the video file to a file.
    For the purposes of discussion, let’s say that we save the video with the filename `myvideo.mp4`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一种皮肤病，无法在网上找到相关信息。我们需要对这种皮肤病进行分类。然而，为了做到这一点，我们需要一张该皮肤病的图像。因此，我们可以拍摄这张皮肤病的录像，并将视频文件保存为一个文件。为了讨论的方便，我们假设我们将视频保存为文件名`myvideo.mp4`。
- en: 'Once this is complete, we could use the following Python script to break the
    video into images and save it into a folder. This function will take the path
    of the video file, break it into frames based on frequency, and save the corresponding
    images to a specified output location. Here is that function in its entirety:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们可以使用以下Python脚本将视频分解为图像，并将其保存到一个文件夹中。此函数将接受视频文件的路径，根据频率将视频分解为帧，并将相应的图像保存到指定的输出位置。以下是该函数的完整代码：
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This function takes the path of the video file, breaks it into frames based
    on frequency, and saves the corresponding images to a specified output location:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数接受视频文件的路径，根据频率将视频分解为帧，并将相应的图像保存到指定的输出位置：
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As mentioned above, this will save every frame of the video in the current folder
    based on the frequency set. After running this script, you now will have created
    your image dataset and be able to use the images you need.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，这将在当前文件夹中根据设置的频率保存视频的每一帧。运行此脚本后，您将创建好您的图像数据集，并可以使用所需的图像。
- en: Building your model using TensorFlow
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow构建模型
- en: 'Now that we have seen several methods of obtaining the images we need, or,
    in the absence of any, creating our own, we will now use TensorFlow to create
    the classification model for our flower use case:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经了解了获取所需图像的几种方法，或者在没有图像的情况下创建我们自己的图像，接下来我们将使用TensorFlow为我们的花卉用例创建分类模型：
- en: '**Creating the folder structure**: To start with, let''s create the folder
    structure that''s required for our flower classification use case. First, create
    a main folder called `image_classification`. Within the `image_classification`
    folder, create two folders: `images` and `tf_files`. The `images` folder will
    contain the images that are required for model training, and the `tf_files` folder
    will hold all the generated TensorFlow-specific files during runtime.'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创建文件夹结构**：首先，让我们为我们的花卉分类用例创建所需的文件夹结构。首先，创建一个名为`image_classification`的主文件夹。在`image_classification`文件夹内，创建两个文件夹：`images`和`tf_files`。`images`文件夹将包含模型训练所需的图像，而`tf_files`文件夹将在运行时保存所有生成的TensorFlow特定文件。'
- en: '**Downloading the images**: Next, we need to download the images that are specific
    to our use case. Using the example of **Flowers**, our images will come from the
    VGG datasets page we discussed earlier.'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**下载图像**：接下来，我们需要下载适用于我们用例的特定图像。以**花卉**为例，我们的图像将来自我们之前讨论过的VGG数据集页面。'
- en: Please feel free to use your own datasets, but make sure that each category
    is in its own separate folder. Place the downloaded image dataset within the `images`
    folder.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 请随意使用您自己的数据集，但请确保每个类别都有单独的文件夹。将下载的图像数据集放在`images`文件夹内。
- en: 'For example, the complete folder structure will look like this:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，完整的文件夹结构将如下所示：
- en: '![](img/2f389c5e-de53-43c8-b807-d68aacb9c7aa.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2f389c5e-de53-43c8-b807-d68aacb9c7aa.png)'
- en: '**Creating the Python script**: In this step, we will create the TensorFlow
    code that is required to build our model. Create a Python file named `retrain.py`
    within the main `image_classification` folder.'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**创建Python脚本**：在这一步，我们将创建构建模型所需的TensorFlow代码。在主`image_classification`文件夹中创建一个名为`retrain.py`的Python文件。'
- en: 'Once this is complete, the following code block should be copied and used.
    Below we have broken out the process into several steps in order to describe what
    is taking place:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些后，以下代码块应被复制并使用。我们将过程分解为几个步骤，以便描述发生了什么：
- en: 'The following code block is the complete script that goes into `retrain.py`:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码块是完整的脚本内容，应该放入`retrain.py`中：
- en: '[PRE14]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Next, we need to prepare the images so that they can be trained, validated,
    and tested:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要准备图像，以便它们可以进行训练、验证和测试：
- en: '[PRE15]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The first thing we are going to do is to retrieve the images from the directory
    path where they are stored. We will use the images to create the model graph using
    the model that you previously downloaded and installed.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的第一件事是从存储图像的目录路径中检索图像。我们将使用这些图像，通过您之前下载并安装的模型来创建模型图。
- en: The next step is to bottleneck the array initialization by creating what is
    known as **bottleneck files**. **Bottleneck** is an informal term used for the
    layer just before the final output layer that does the actual classification.
    (TensorFlow Hub calls this an **image feature vector**.) This layer has been trained
    to output a set of values that's good enough for the classifier to use in order
    to distinguish between all the classes it's been asked to recognize. This means
    that it must be a meaningful and compact summary of the images, since it must
    contain enough information for the classifier to make a good choice in a very
    small set of values.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是通过创建所谓的**瓶颈文件**来初始化瓶颈。**瓶颈**是一个非正式术语，用来指代最终输出层之前的那一层，该层负责实际的分类。（TensorFlow
    Hub将其称为**图像特征向量**。）这一层经过训练，输出的值足够让分类器使用，以便区分它被要求识别的所有类别。这意味着它必须是图像的有意义且紧凑的总结，因为它必须包含足够的信息，让分类器能够在一小组值中做出正确的选择。
- en: It's important that we have bottleneck values for each image. If the bottleneck
    values aren't available for each image, we will have to create them manually because
    these values will be required in the future when training the images. It is highly
    recommended to cache these values in order to speed up processing time later.
    Because every image is reused multiple times during training, and calculating
    each bottleneck takes a significant amount of time, it speeds things up to cache
    these bottleneck values on disk to avoid repeated recalculated. By default, bottlenecks
    are stored in the `/tmp/bottleneck` directory (unless a new directory was specified
    as an argument).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 每个图像都需要有瓶颈值，这是非常重要的。如果每个图像的瓶颈值不可用，我们将不得不手动创建它们，因为这些值在未来训练图像时会被需要。强烈建议缓存这些值，以便以后加快处理速度。因为每个图像在训练过程中都会被多次重复使用，并且计算每个瓶颈值会花费大量时间，所以将这些瓶颈值缓存到磁盘上可以避免重复计算，从而加速过程。默认情况下，瓶颈值会存储在`/tmp/bottleneck`目录中（除非作为参数指定了新的目录）。
- en: When we retrieve the bottleneck values, we will do so based upon the filenames
    of images that are stored in the cache. If distortions were applied to images,
    there might be difficulty in retrieving the bottleneck values. The biggest disadvantage
    of enabling distortions in our script is that the bottleneck caching is no longer
    useful, since input images are never reused exactly. This directly correlates
    to a longer training process time, so it is highly recommended this happens once
    you have a model that you are reasonably happy with. Should you experience problems,
    we have supplied a method of getting the values for images which have distortions
    supplied as a part of the GitHub repository for this book.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们检索瓶颈值时，我们将基于缓存中存储的图像文件名来检索它们。如果对图像进行了扭曲处理，可能会在检索瓶颈值时遇到困难。启用扭曲的最大缺点是瓶颈缓存不再有用，因为输入图像永远不会被完全重复使用。这直接导致了训练过程时间的延长，因此强烈建议在对模型基本满意时再启用扭曲处理。如果您遇到问题，我们已经在本书的GitHub仓库中提供了一种方法来获取带有扭曲的图像的瓶颈值。
- en: Please note that we materialize the distorted image data as a NumPy array first.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们首先将扭曲的图像数据转化为NumPy数组。
- en: Next, we need to send the running inference on the image. This requires a trained
    object detection model and is done by using two memory copies.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要对图像进行推理。这需要一个训练好的目标检测模型，并通过使用两个内存副本来完成。
- en: Our next step will be to apply distortion to the images. Distortions such as
    cropping, scaling and brightness are supplied as percentage values which control
    how much of each distortion is applied to each image. It's reasonable to start
    with values of 5 or 10 for each of them and then experiment from there to see
    which/what helps and what does not.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一步是对图像进行失真处理。失真处理如裁剪、缩放和亮度是以百分比的形式给出的，这些百分比值控制每种失真在每个图像上应用的程度。合理的做法是从每种失真值5或10开始，然后通过实验确定哪些对模型有帮助，哪些没有。
- en: 'We next need to summarize our model based on accuracy and loss. We will use
    TensorBoard visualizations to analyze it. If you do not already know, TensorFlow
    offers a suite of visualization tools called TensorBoard which allows you to visualize
    your TensorFlow graph, plot variables about the execution, and show additional
    data like images that pass through it. The following is an example TensorBoard
    dashboard:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要基于准确性和损失来总结我们的模型。我们将使用TensorBoard可视化工具进行分析。如果你还不知道，TensorFlow提供了一套名为TensorBoard的可视化工具，它可以帮助你可视化TensorFlow图，绘制执行过程中的变量，并展示其他数据，如通过图的图像。以下是一个TensorBoard仪表盘的示例：
- en: '![](img/be6eec08-7056-441f-b2e3-5263c485e200.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/be6eec08-7056-441f-b2e3-5263c485e200.png)'
- en: Our next step will be to save the model to a file, as well as setting up a directory
    path to write summaries for the TensorBoard.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一步是将模型保存到文件中，并设置一个目录路径，用于写入TensorBoard的摘要。
- en: 'At this point we should point out the `create_model_info` function, that will
    return the model information. In our example below, we handle both MobileNet and Inception_v3 architectures.
    You will see later how we handle any other architecture but these:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们需要指出`create_model_info`函数，它将返回模型信息。在下面的示例中，我们处理的是MobileNet和Inception_v3架构。稍后你将看到我们如何处理这些架构之外的其他架构：
- en: '[PRE16]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If the above argument turns out to be false, this means that we encountered
    an architecture which we were not expecting. If this happens, we will need to
    execute the following code block to obtain the result. In this instance we are
    not dealing with either MobileNet or Inception_V3 and will default to using version
    1 of MobileNet:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如果上述参数返回为false，意味着我们遇到了一个意外的架构。如果发生这种情况，我们需要执行以下代码块来获取结果。在此示例中，我们处理的既不是MobileNet也不是Inception_V3，默认将使用MobileNet的版本1：
- en: '[PRE17]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Another important point we should note is that we will need to decode the image
    JPEG data after processing. The following function, `add_jpeg_decoding`, is a
    complete code snippet which does this by calling the `tf.image.decode_jpeg` function:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的事项是，我们需要在处理后解码图像的JPEG数据。下面的`add_jpeg_decoding`函数是一个完整的代码片段，通过调用`tf.image.decode_jpeg`函数来实现这一功能：
- en: '[PRE18]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'And here, in all its glory is our `main` function. Basically we do the following:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们的`main`函数，展示了它的全部内容。基本上，我们做了以下操作：
- en: Set our logging level to `INFO`
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置我们的日志级别为`INFO`
- en: Prepare the file system for usage
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备文件系统以供使用
- en: Create our model information
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建我们的模型信息
- en: Download and extract our data
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载并提取我们的数据
- en: '[PRE19]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The preceding `retrain.py` file is available for download as part of the assets
    within this book.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 上述`retrain.py`文件可以作为本书附带资源进行下载。
- en: Running TensorBoard
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行TensorBoard
- en: 'To run TensorBoard, use the following command:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行TensorBoard，请使用以下命令：
- en: '[PRE20]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Where `logdir` points to the directory where serialized data is contained. If
    this directory contains subdirectories which also contain serialized data, TensorBoard
    will visualize the data from all of those runs. Once TensorBoard is running, navigate
    your web browser to `localhost:6006` to view the TensorBoard and its associated
    data.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 其中`logdir`指向存储序列化数据的目录。如果该目录包含子目录，并且这些子目录也包含序列化数据，TensorBoard将可视化所有这些运行的数据显示。一旦TensorBoard开始运行，请在浏览器中访问`localhost:6006`来查看TensorBoard及其相关数据。
- en: For those wanting or needing to learn more about TensorBoard, please check out
    the following tutorial at [https://www.tensorflow.org/tensorboard/r1/summaries](https://www.tensorflow.org/tensorboard/r1/summaries).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些想要深入了解TensorBoard的读者，请查看以下教程：[https://www.tensorflow.org/tensorboard/r1/summaries](https://www.tensorflow.org/tensorboard/r1/summaries)。
- en: Summary
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter we have accomplished a lot in this small chapter. We began the
    chapter with understanding the various datasets that are available for image classification,
    as well as how we could obtain or create images if we could not find any that
    met our requirements. Next, then divided the chapter into two distinct sections.
    In the first section we learned about creating our own image dataset. In the second
    section we learned how to use TensorFlow to build the model.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们在这个小章节中完成了很多内容。我们首先理解了可用于图像分类的各种数据集，以及如果我们找不到符合要求的图像时，如何获取或创建图像。接着，我们将章节分为两个不同的部分。在第一部分，我们学习了如何创建我们自己的图像数据集。在第二部分，我们学习了如何使用
    TensorFlow 构建模型。
- en: In the next chapter, we are going to extend our TensorFlow knowledge even further
    by using various TensorFlow libraries to build a machine learning model which
    will predict body damage done to a car.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将通过使用各种 TensorFlow 库来进一步扩展我们的 TensorFlow 知识，构建一个机器学习模型，该模型将预测汽车的车身损伤。
