- en: Model Accuracy Degradation and Feedback Loops
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型准确度退化与反馈循环
- en: In this chapter, we will learn about the concept of model performance deterioration
    using an example of ad-click conversion. Our goal is to identify ad-clicks that
    result in mobile app downloads. In this case, the ads are for marketing mobile
    apps.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将通过广告点击转化的示例来介绍模型性能退化的概念。我们的目标是识别那些导致移动应用下载的广告点击。在这种情况下，广告是用于推广移动应用的。
- en: To address the deterioration of model performance, we will learn about **feedback
    loops**, pipelines in which we retrain models as new data becomes available and
    assess model performance. Consequently, trained models are constantly kept up
    to date with the changing patterns in input or training data. The feedback loop
    is very important when it comes to making sound business decisions based on model
    output. If a trained model does not adequately capture patterns in dynamic data,
    it is likely to produce sub-optimal results.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对模型性能的退化，我们将学习关于**反馈循环**的内容，即当新数据可用时，我们重新训练模型并评估模型性能的管道。因此，训练后的模型会不断更新，以适应输入数据或训练数据中的变化模式。反馈循环在基于模型输出做出明智的商业决策时非常重要。如果训练后的模型无法充分捕捉动态数据中的模式，它可能会产生次优的结果。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Monitoring models for degraded performance
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控退化性能的模型
- en: Developing a use case for evolving training data—ad-click conversion
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发一个用于训练数据演变的案例——广告点击转化
- en: Creating a machine learning feedback loop
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建机器学习反馈循环
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This book's GitHub repository, which contains the source code for this chapter,
    can be found at [https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services](https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的 GitHub 仓库包含本章的源代码，可以在 [https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services](https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services)
    找到。
- en: Monitoring models for degraded performance
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控退化性能的模型
- en: 'In real-world scenarios, the performance of deployed machine learning models
    degrades over time. To explain this in the case of fraud detection, the models
    may not capture evolving fraudulent behaviors. Because fraudsters adapt their
    methods and processes over time to game systems, it is important to retrain fraud
    detection engines on the latest and greatest data (reflecting anomalous behavior)
    available. Take a look at the following diagram:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际场景中，部署的机器学习模型会随着时间的推移而退化性能。以欺诈检测为例，模型可能无法捕捉到不断变化的欺诈行为。由于欺诈者会随着时间的推移调整他们的方法和流程来规避系统，因此对于欺诈检测引擎来说，使用最新的反映异常行为的数据重新训练是非常重要的。请看下图：
- en: '![](img/32953d5b-29e3-4a6b-bd0a-5497eae93a7b.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/32953d5b-29e3-4a6b-bd0a-5497eae93a7b.png)'
- en: The preceding diagram shows how models degrade in terms of predictive performance
    when they are deployed in production. As another example, in the case of recommender
    systems, customer preferences keep changing based on a number of contextual and
    environmental factors. Therefore, it becomes important for personalization engines
    to capture such preferences and present the most relevant suggestions to customers.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 上图展示了模型在生产环境中部署后，如何在预测性能上发生退化。作为另一个例子，在推荐系统中，客户的偏好会根据多种上下文和环境因素不断变化。因此，个性化引擎需要捕捉这种变化的偏好，并向客户呈现最相关的建议。
- en: Developing a use case for evolving training data – ad-click conversion
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发一个用于训练数据演变的案例——广告点击转化
- en: Fraud risk is prevalent in almost every industry, for example, airlines, retail,
    financial services, and so on. The risk is especially high in online advertising.
    For companies investing in digital marketing, it is important to contain costs
    from fraudulent clicks on ads. Online advertising can become cost-prohibitive
    if fraudulent behavior is rampant across online ad channels. In this chapter,
    we will look at ad-click data for mobile apps and predict which clicks will likely
    yield app downloads. The outcome of this prediction exercise will allow mobile
    app developers to efficiently allocate online marketing dollars.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 欺诈风险几乎存在于每个行业，例如航空公司、零售、金融服务等。在在线广告中，欺诈风险尤其高。对于投资数字营销的公司来说，控制广告点击中的欺诈性点击非常重要。如果在线广告渠道中充斥着欺诈行为，广告成本可能变得不可承受。本章将通过移动应用的广告点击数据，预测哪些点击可能带来应用下载。通过这一预测，移动应用开发者能够更有效地分配在线营销预算。
- en: Ad-click behavior is very dynamic. This behavior changes across time, location,
    and ad channels. A fraudster can develop software to automate clicking on mobile
    app ads and conceal the identity of clicks—clicks can be generated from multiple
    IP addresses, devices, operating systems, and channels. To catch this dynamic
    behavior, it is important to retrain classification models to cover new and emerging
    patterns. Implementing a feedback loop becomes critical if we wish to accurately
    determine which clicks will result in app downloads. For instance, clicks on ads
    for the Helix Jump app may not result in app downloads if these clicks are generated
    during the eleventh hour, are from the same IP address, and are a few minutes
    apart. However, if these clicks are produced during business hours, are from different
    IP addresses, and are spread across the day, then they will result in app downloads.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 广告点击行为是非常动态的。这种行为随时间、地点和广告渠道的变化而变化。欺诈者可以开发软件来自动点击移动应用广告，并隐藏点击的身份——点击可能来自多个IP地址、设备、操作系统和渠道。为了捕捉这种动态行为，重新训练分类模型以涵盖新的和新兴的模式变得非常重要。如果我们希望准确确定哪些点击将导致应用下载，实现反馈回路至关重要。例如，如果某些点击发生在最后一刻，来自相同的IP地址，并且间隔几分钟，则这些点击可能不会导致应用下载。然而，如果这些点击发生在工作时间，来自不同的IP地址，并且分布在整天，那么它们将会导致应用下载。
- en: 'The following diagram describes ad-click behavior, along with a binary outcome—whether
    the mobile app is downloaded or not:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 下图描述了广告点击行为，以及二元结果——是否下载了移动应用：
- en: '![](img/0add18fb-1208-4d27-a39e-b35cc99141df.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0add18fb-1208-4d27-a39e-b35cc99141df.png)'
- en: Depending on how the ad is clicked by the user—whether a device, operating system,
    or a channel is used, when it is clicked, and for what app—the click may or may
    not convert into a mobile app download. We will use this dynamic click behavior
    to illustrate the importance of a feedback loop in machine learning.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 根据用户如何点击广告——使用了哪种设备、操作系统或渠道、点击时间以及所点击的应用，点击可能会或可能不会转化为移动应用下载。我们将利用这种动态点击行为来说明机器学习中反馈回路的重要性。
- en: Creating a machine learning feedback loop
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建机器学习反馈回路
- en: In this section, we will demonstrate how retraining a classification model as
    new data becomes available will enhance model performance; that is, it will predict
    which ad-clicks will result in mobile app downloads.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将演示随着新数据的到来，如何通过重新训练分类模型来提升模型性能；即预测哪些广告点击将导致移动应用下载。
- en: 'We have created a synthetic/artificial dataset simulating 2.4 million clicks
    across four days (Monday through Thursday; July 2 to July 5 of 2018). The dataset
    can be found here: [https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services/tree/master/Ch12_ModelPerformanceDegradation/Data](https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services/tree/master/Ch12_ModelPerformanceDegradation/Data)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经创建了一个合成/人工数据集，模拟了在四天（周一至周四；2018年7月2日至7月5日）内发生的240万个点击。数据集可以在此找到：[https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services/tree/master/Ch12_ModelPerformanceDegradation/Data](https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services/tree/master/Ch12_ModelPerformanceDegradation/Data)
- en: 'The dataset contains the following elements:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含以下元素：
- en: '`ip`: the IP address of the click'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ip`: 点击的IP地址'
- en: '`app`: The type of mobile app'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`app`: 移动应用类型'
- en: '`device`: The type of device the click is coming from (for example, iPhone
    6 plus, iPhone 7)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`device`: 点击来源的设备类型（例如，iPhone 6 Plus，iPhone 7）'
- en: '`os`: The type of operating system the click is coming from'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`os`: 点击来源的操作系统类型'
- en: '`channel`: The type of channel the click is coming from'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`channel`: 点击来源的渠道类型'
- en: '`click_time`: The timestamp of the click (UTC)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`click_time`: 点击的时间戳（UTC）'
- en: '`is_downloaded`: The target that is to be predicted, indicating the app was
    downloaded'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`is_downloaded`: 需要预测的目标，表示应用程序是否已下载'
- en: Having access to the latest and greatest data is a challenge. Data lake and
    data warehouse environments typically lag by a day (24 hours). When predicting
    whether clicks that occurred toward the end of the day on Thursday will result
    in app downloads, it is important to have current data up to and including Thursday,
    excluding the clicks that we are scoring, for model training.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 获取最新和最完整的数据是一个挑战。数据湖和数据仓库环境通常会滞后一天（24小时）。当预测周四接近结束时发生的点击是否会导致应用下载时，确保拥有截至周四的最新数据是至关重要的，且要排除我们正在评分的点击数据，以便进行模型训练。
- en: 'To understand the significance of a feedback loop, we will train a tree-based
    model (XGBoost) to predict the probability of an ad-click (related to an app)
    that results in the app being download. We will run three different experiments:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解反馈循环的意义，我们将训练一个基于树的模型（XGBoost）来预测导致应用下载的广告点击的概率。我们将进行三个不同的实验：
- en: '**Experiment 1**: Train on the click data for Monday and predict/score a portion
    of the clicks from Thursday (clicks from a later part of the day).'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验 1**：使用周一的点击数据进行训练，并预测/评分部分周四的点击数据（来自当天晚些时候的点击）。'
- en: '**Experiment 2**: Let''s assume that we have more data available in the data
    lake environment to retrain the classification model. We will train on the click
    data for Monday, Tuesday, and Wednesday and predict/score a portion of the clicks
    from Thursday.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验 2**：假设我们在数据湖环境中有更多数据可供使用，以重新训练分类模型。我们将使用周一、周二和周三的点击数据进行训练，并预测/评分部分周四的点击数据。'
- en: '**Experiment 3**: Similarly, we will train on click data for Monday, Tuesday,
    Wednesday and part of Thursday and predict/score a portion of the clicks from
    Thursday.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验 3**：类似地，我们将使用周一、周二、周三和部分周四的点击数据进行训练，并预测/评分部分周四的点击数据。'
- en: 'With each iteration or experiment, you will see the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次迭代或实验中，你将看到以下内容：
- en: The classification model's performance measured by **area under curve** (**AUC**)
    increases. AUC is measured by plotting the true positive rate against the false
    positive rate.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类模型的表现通过**曲线下面积**（**AUC**）来衡量，AUC通过绘制真正率与假正率来计算。
- en: That a random classifier has an AUC of 0.5.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机分类器的AUC为0.5。
- en: For an optimal model, the AUC should be closer to 1.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一个最佳模型，AUC应该接近1。
- en: In other words, the true positive rate (the proportion of the app downloads
    that you've correctly identified) should be higher than the false positive rate
    (the proportion of clicks that did not result in any app downloads but has been
    identified as yielding app downloads).
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 换句话说，真正率（你正确识别的应用下载比例）应当高于假正率（那些未导致应用下载的点击，但被错误识别为会导致应用下载的比例）。
- en: Now we need to load and explore the data to determine the best indicators for
    predicting app downloads.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要加载和探索数据，以确定预测应用下载的最佳指标。
- en: Exploring data
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索数据
- en: 'Amazon SageMaker offers built-in tools and capabilities for creating machine
    learning pipelines that incorporate feedback loops. Since machine learning pipelines
    were covered in [Chapter 8](16e50aca-401b-47b0-87c3-34cc0346e66e.xhtml), *Creating
    Machine Learning Inference Pipelines*, here, we will focus on the significance
    of incorporating a feedback loop. Let''s begin:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊SageMaker提供了内置工具和能力来创建包含反馈循环的机器学习管道。由于机器学习管道在[第8章](16e50aca-401b-47b0-87c3-34cc0346e66e.xhtml)中已经介绍过，*创建机器学习推理管道*，在这里我们将重点关注反馈循环的重要性。我们开始吧：
- en: 'Install the relevant Python packages and set the locations for the training,
    validation, and model outputs on the S3 bucket, as follows:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装相关的Python包，并设置S3存储桶中训练、验证和模型输出的路径，如下所示：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Read the prepared synthetic dataset from the local SageMaker instance, as shown
    in the following code:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从本地SageMaker实例读取准备好的合成数据集，如以下代码所示：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will now explore the data so that we can prepare features that indicate
    the following:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将现在探索数据，以便准备以下特征：
- en: '**Where** the ad-clicks are coming from, that is, `ip`, `device`, and `os`'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广告点击的来源，即** `ip`、`device` 和 `os`'
- en: '**When** they come, that is, `day` and `hr`'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**它们何时到达，即** `day` 和 `hr`'
- en: '**How** they come, that is, `channel`'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**它们是如何到达的，即** `channel`'
- en: A combination of where, when, and how
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合何时、何地和如何
- en: 'Create chunks of data for each of the experiments. We will use the `pandas`
    library to aggregate ad-clicks by days in the experiment, as shown in the following
    code:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个实验创建数据块。我们将使用`pandas`库按天汇总广告点击数据，如以下代码所示：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let's understand whether the most frequently occurring factors, such as the
    type of app, device, channel, operating system, and IP address the click is originating
    from, result in app downloads.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解最常见的因素，如应用类型、设备、渠道、操作系统和点击来源的IP地址，是否能导致应用下载。
- en: Popular apps, which are defined by the number of relevant ad-clicks, are not
    the same when an app is not downloaded as opposed to when it is downloaded. In
    other words, although certain mobile app ads are frequently clicked, they are
    not necessarily those that are downloaded.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 流行的应用（由相关广告点击数定义）在未下载与已下载时并不相同。换句话说，虽然某些移动应用广告经常被点击，但它们不一定是那些最终被下载的应用。
- en: '**Top Apps for Monday**: Let''s plot the distribution of the number of ad-clicks
    by app when apps are downloaded as opposed to when they aren''t, as shown in the
    following code:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**周一的热门应用**：让我们绘制应用下载与未下载时，广告点击数的分布，如下方代码所示：'
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'For the definition of the `plot_clickcnt_ftr()` function from this code, please
    refer to the associated source code for this chapter. The first bar chart shows
    when apps are not downloaded, while the second one reflects when apps are downloaded:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 关于此代码中`plot_clickcnt_ftr()`函数的定义，请参见本章相关的源代码。第一个条形图显示了应用未下载时的情况，而第二个条形图则反映了应用已下载时的情况：
- en: '![](img/c9781558-870a-43b9-9265-87981e467763.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9781558-870a-43b9-9265-87981e467763.png)'
- en: As we saw previously, apps 12, 3, 9, and 15 are the top 4 apps in terms of apps
    that aren't downloaded. On the other hand, apps 19, 34, 29, and 9 are popular
    apps when ad-clicks result in app downloads.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所见，应用12、3、9和15是在未下载时最受欢迎的前四个应用。另一方面，应用19、34、29和9是在广告点击导致下载时最受欢迎的应用。
- en: '**Top Devices for Monday**: Now let''s plot the distribution of the number
    of ad-clicks by device when apps are downloaded as opposed to when they aren''t,
    as shown in the following code:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**周一的热门设备**：现在让我们绘制设备在应用下载与未下载时的广告点击数分布，如下方代码所示：'
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The same theme holds true; popular devices when clicks do not result in app
    downloads are different from those when clicks result in app downloads, as shown
    in the following output:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的主题依然成立；在点击未导致应用下载和点击导致应用下载时，流行设备的差异，如以下输出所示：
- en: '![](img/1eaedb61-1d2b-4f07-a0cd-cc6fc496fc4a.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1eaedb61-1d2b-4f07-a0cd-cc6fc496fc4a.png)'
- en: Even in terms of the operating system and the channel, the same theme is sustained.
    Therefore, it seems reasonable to note that ad-clicks coming from certain devices,
    operating systems, and channels for certain apps are indicative of app downloads.
    It may also be possible that clicks originating from a popular channel, operating
    system, or device for popular apps may have a higher incidence of being converted
    into app downloads. Popular is synonymous with a high volume of clicks.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在操作系统和渠道方面，这一主题依然存在。因此，值得注意的是，某些设备、操作系统和渠道来源的广告点击可能会提示应用下载。也有可能的是，来自受欢迎渠道、操作系统或设备的点击，针对热门应用的下载转化率较高。受欢迎就意味着点击量大。
- en: Creating features
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建特征
- en: Now that we have explored the data, it is time to create some features. Let's
    begin by looking at categorical variables in the data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探索了数据，接下来是创建一些特征。让我们从查看数据中的分类变量开始。
- en: 'The unique IDs of each of the category columns, namely `app`, `device`, `os`,
    and `channel`, are not useful in and of themselves. For a tree-based model, for
    example, a lower app ID is not better than a higher app ID or vice versa in terms
    of predicting app downloads. Therefore, we will calculate the frequency of each
    of these categorical variables, as shown in the following code:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 每个类别列的唯一ID，即`app`、`device`、`os`和`channel`，本身并不有用。例如，对于基于树的模型而言，较低的应用ID并不优于较高的应用ID，反之亦然。因此，我们将计算这些分类变量的频率，如下代码所示：
- en: '[PRE5]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: First, we create a list of categorical variables called `cat_ftrs`*.* We do
    this for each of the categorical variables.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们创建一个名为`cat_ftrs`*.* 的分类变量列表。我们对每一个分类变量都这样做。
- en: We calculate the frequency by dividing the number of clicks originating from
    the variable by the total number of clicks in the dataset.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过将来自某一变量的点击数除以数据集中总的点击数来计算频率。
- en: 'For each of these experiments, we call the `encode_cat_ftrs()` function to
    create frequency-related features for all the categorical variables, as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些实验，我们调用`encode_cat_ftrs()`函数为所有分类变量创建与频率相关的特征，如下所示：
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now let's look at time-related features. From the `click_time` column, we'll
    create a variety of time-related features, that is, `day`, `hour`, `minute`, and
    `second`. These features may help uncover click patterns given the day of the
    week and hour of the day.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们来看一下与时间相关的特征。我们将从`click_time`列创建各种与时间相关的特征，即`day`、`hour`、`minute`和`second`。这些特征可能有助于根据星期几和一天中的小时来揭示点击模式。
- en: 'From the `datetime` column, we extract `day`, `hour`, `minute`, and `second`,
    as shown in the following code:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 从`datetime`列中，我们提取`day`、`hour`、`minute`和`second`，如下所示：
- en: '[PRE7]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We use the `dt` accessor object of the datetime column to obtain time-related
    features. As with calling `encode_cat_ftrs`on each of the datasets related to
    the experiments, we will call `create_date_ftrs` on each of them.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`datetime`列的`dt`访问器对象来获取与时间相关的特征。就像在每个与实验相关的数据集上调用`encode_cat_ftrs`一样，我们将在每个数据集上调用`create_date_ftrs`。
- en: 'Finally, let''s create features that reflect `when` and `where` the clicks
    are coming from. Therefore, we will count clicks via the following:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们创建反映点击来自`何时`和`何地`的特征。因此，我们将通过以下方式统计点击次数：
- en: IP Address, Day, and Hour
  id: totrans-79
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: IP 地址、日期和小时
- en: IP Address, Channel, and Hour
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: IP 地址、渠道和小时
- en: IP Address, Operating System, and Hour
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: IP 地址、操作系统和小时
- en: IP Address, App, and Hour
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: IP 地址、应用程序和小时
- en: IP Address, Device, and Hour
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: IP 地址、设备和小时
- en: For information on the function used to count clicks by each of the combinations,
    `count_clicks`, please refer to the source code associated with this chapter.
    `count_clicks`is called on each of the datasets pertaining to the experiments.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 关于用于按每种组合统计点击次数的函数`count_clicks`的详细信息，请参阅与本章相关的源代码。`count_clicks`在每个与实验相关的数据集上被调用。
- en: 'Now let''s take a look at the prepared dataset after feature engineering:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看经过特征工程处理后的准备数据集：
- en: '![](img/504c654d-6de0-4bc3-a0fd-b64c7a31ad15.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/504c654d-6de0-4bc3-a0fd-b64c7a31ad15.png)'
- en: 'As you can see, we have all the engineered features:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们已经拥有所有工程特征：
- en: '![](img/0022597d-d201-4c31-a608-a90ba71bdafd.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0022597d-d201-4c31-a608-a90ba71bdafd.png)'
- en: 'In the preceding screenshot, we have:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，我们有：
- en: '`day`, `hour`, `minute`, and `second` for each ad-click'
  id: totrans-90
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每次广告点击的`day`、`hour`、`minute`和`second`
- en: '`app`, `device`, operating system (`os`), and channel frequency'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`app`、`device`、操作系统（`os`）和渠道频率'
- en: Number of clicks by when (`time`), where (`os`, `device`, and `ip` address),
    and how (`channel`)
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按`时间`（`time`）、`地点`（`os`、`device`和`ip`地址）以及`方式`（`channel`）统计的点击次数
- en: 'Now let''s see how all of these features are related to each other. We will
    use a correlation matrix to view the relationship among all the attributes, as
    shown in the following code:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们看看这些特征之间是如何相互关联的。我们将使用相关矩阵来查看所有属性之间的关系，如下所示的代码所示：
- en: '[PRE8]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following is part of the correlation matrix generated by the `corr`function
    of the `pandas` DataFrame:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是通过`pandas` DataFrame的`corr`函数生成的相关矩阵的一部分：
- en: '![](img/daddaa01-eacf-4a4f-9b09-4788cb89961f.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/daddaa01-eacf-4a4f-9b09-4788cb89961f.png)'
- en: As we can see, the type of app, the proportion of clicks originating from the
    device and channel, and the proportion of clicks for an app are key indicators
    that are predictive of app downloads. Plotting a heatmap for each of the experiments
    also indicates that these observations are valid. Please refer to the source code
    associated with this chapter for more information.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，应用类型、来自设备和渠道的点击比例，以及某个应用的点击比例是预测应用下载的关键指标。为每个实验绘制热图也表明这些观察结果是有效的。有关更多信息，请参阅与本章相关的源代码。
- en: Using Amazon's SageMaker XGBoost algorithm to classify ad-click data
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用亚马逊的 SageMaker XGBoost 算法对广告点击数据进行分类
- en: To understand the significance of a feedback loop, we will train a tree-based
    model (XGBoost) to predict the probability that an ad-click results in an app
    download.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解反馈循环的意义，我们将训练一个基于树的模型（XGBoost），以预测广告点击是否会导致应用下载的概率。
- en: 'For all of these experiments, we have one test dataset. This contains ad-clicks,
    along with apps that were downloaded during the later part of the day on Thursday—the
    last 120,000 clicks from the day. Let''s get started:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有这些实验，我们有一个测试数据集。它包含广告点击数据，以及在星期四晚些时候下载的应用程序——当天最后的120,000次点击。让我们开始吧：
- en: 'We will select 5% of the clicks from the third dataset, which contains clicks
    from Monday, Tuesday, Wednesday, and Thursday. The third dataset is sorted by
    time, so we pick the last 120,000 clicks that were generated on Thursday, as shown
    in the following code:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将从第三个数据集中选择 5% 的点击数据，该数据集包含了周一、周二、周三和周四的点击数据。第三个数据集按时间排序，因此我们选择了周四生成的最后 120,000
    个点击，具体代码如下所示：
- en: '[PRE9]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We will also need to rearrange the datasets for all the experiments, so `is_downloaded`,
    our target variable, is the first column in the dataset. This format is required
    by the SageMaker XGBoost algorithm.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还需要重新排列所有实验的数据集，使得`is_downloaded`，我们的目标变量，成为数据集中的第一列。SageMaker XGBoost 算法要求这种格式。
- en: 'Now we need to rearrange the test dataset, as follows:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们需要重新排列测试数据集，如下所示：
- en: '[PRE10]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For each experiment, we will start by creating training and validation datasets.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个实验，我们将首先创建训练集和验证集。
- en: 'We will split the current experiment data into training and validation sets,
    as shown in the following code:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将把当前实验数据拆分为训练集和验证集，具体代码如下：
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We use NumPy's split function to do so. 70% of the data is allocated for training,
    while 30% is allocated for validation.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 NumPy 的 split 函数来完成此操作。70% 的数据用于训练，30% 的数据用于验证。
- en: Once we have the training, validation, and test datasets, we upload them to
    S3\. Please refer to the source code associated with this chapter for details.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们准备好训练集、验证集和测试集，我们将它们上传到 S3。有关详细信息，请参阅本章相关的源代码。
- en: 'It is time to prepare for model training. To train the XGBoost model, the following
    hyperparameters are defined (only a few are reported). For detailed information,
    please refer to the AWS docs ([https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html)):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是准备模型训练的时候了。为了训练 XGBoost 模型，定义了以下超参数（这里只报告了一部分）。详细信息请参阅 AWS 文档（[https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html)）：
- en: '`max_depth`: The maximum number of levels between the tree''s root and a leaf.'
  id: totrans-112
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_depth`：树的根节点与叶节点之间的最大层数。'
- en: '`eta`: Learning rate.'
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eta`：学习率。'
- en: '`gamma`: The node is only split when the resulting split gives a positive reduction
    in the loss function. Gamma specifies the minimum loss reduction required to make
    a split.'
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gamma`：只有当分裂后能显著减少损失函数时，节点才会被分裂。Gamma 指定了进行分裂所需的最小损失减少值。'
- en: '`min_child_weight`: This is used to control tree complexity and the minimum
    sum of instance weight needed in a child. If this threshold is not met, then tree
    partitioning will stop.'
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_child_weight`：用于控制树的复杂性和每个子节点所需的最小实例权重总和。如果未达到此阈值，则树的分裂将停止。'
- en: '`subsample`: The fraction of observations to be randomly sampled for each tree.'
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`subsample`：每棵树随机采样的观测值比例。'
- en: '`colsample_bytree`: The fraction of columns to be randomly sampled for each
    tree.'
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`colsample_bytree`：每棵树随机采样的列的比例。'
- en: '`scale_pos_weight`: The dataset is highly imbalanced, where we have a large
    number of clicks (> 90%) that did not result in app downloads. To account for
    this, the `scale_pos_weight` hyperparameter is used to give clicks that resulted
    in app downloads more weight. These clicks are heavily underrepresented in the
    dataset.'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scale_pos_weight`：数据集高度不平衡，其中有大量点击（> 90%）没有导致应用下载。为了解决这个问题，使用 `scale_pos_weight`
    超参数来给那些导致应用下载的点击赋予更大的权重。这些点击在数据集中被严重低估。'
- en: '`alpha`: A regularization parameter to prevent overfitting. Alpha is used to
    implement L1 regularization, where the sum of the weights of leaves is part of
    the regularization term (of the objective function).'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha`：正则化参数，用于防止过拟合。Alpha 用于实现 L1 正则化，其中叶节点权重的总和是正则化项（目标函数的一部分）。'
- en: '`lambda`: This is used to control L2 regularization, where the sum of the squares
    of weights is part of the regularization term.'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lambda`：用于控制 L2 正则化，其中权重的平方和是正则化项的一部分。'
- en: 'Then, we define some of the hyperparameters of the XGBoost algorithm, as follows:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义了一些 XGBoost 算法的超参数，如下所示：
- en: '[PRE12]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: While most of the default values for the hyperparameters are accepted, some
    are explicitly defined here. For instance, `min_child_weight` is set to `6`, while
    the default value is `1`. This means that a leaf node should have a sizeable number
    of instances or data points before it can be split further. These values can be
    tuned for the data in question. **Hyperparameter optimization** (**HPO**), from
    SageMaker, can be used to automate the process of finding optimal values for hyperparameters.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大多数超参数的默认值被接受，但有些在这里被显式定义。例如，`min_child_weight`被设置为`6`，而默认值是`1`。这意味着一个叶节点在进一步拆分之前，应该包含足够数量的实例或数据点。这些值可以根据特定数据进行调整。**超参数优化**（**HPO**）可以使用SageMaker来自动化寻找最优超参数值的过程。
- en: 'We will now fit the XGBoost algorithm to the experiment data (training and
    validation), as shown in the following code:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将拟合XGBoost算法到实验数据（训练数据和验证数据），如下所示的代码：
- en: '[PRE13]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `fit()`function of the XGBoost estimator module (SageMaker Python SDK) is
    invoked for model training. The location of both the training and validation datasets
    is passed as an input for model training.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 调用XGBoost估算器模块（SageMaker Python SDK）的`fit()`函数进行模型训练。训练和验证数据集的位置作为输入传递给模型训练。
- en: Once training concludes, the trained model will be persisted to the location
    specified (in the S3 bucket). We will need to repeat the same training steps for
    each of the experiments. In the end, we will have three trained models.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练完成，训练好的模型将保存到指定的位置（S3桶中）。我们需要为每个实验重复相同的训练步骤。最终，我们将得到三个训练好的模型。
- en: Evaluating model performance
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型性能
- en: In this section, we will evaluate the performance of the three trained models.
    Our hypothesis is that the first model, which was trained on clicks from Monday
    and Tuesday, is less predictive of app downloads on the later part of Thursday
    compared to the second and third models. Similarly, the performance of the second
    model, which was trained on clicks from Monday through Wednesday, should be less
    than that of the third model, which was trained on clicks from Monday through
    the majority of Thursday.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将评估三个训练模型的性能。我们的假设是，第一个模型在星期一和星期二的点击数据上训练，但对于星期四后期的应用下载预测能力较弱，相比之下第二和第三个模型的表现会更好。类似地，第二个模型（基于星期一到星期三的点击数据训练）的表现将不如第三个模型（基于星期一到大部分星期四的点击数据训练）。
- en: 'We will begin by analyzing the features that are deemed important for each
    of the models, as shown in the following code:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先分析每个模型认为重要的特征，如下所示的代码：
- en: '[PRE14]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The preceding code is explained as follows:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的解释如下：
- en: First, we retrieve the location of the trained model for each of the three experiments.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们检索每个实验的训练模型位置。
- en: 'Then, we pass the location to the `plot_ftr_imp()` function to create a diagram
    showing feature importance. To plot feature importance, the function does the
    following:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将位置传递给`plot_ftr_imp()`函数，以创建一个显示特征重要性的图表。为了绘制特征重要性，函数执行以下操作：
- en: Extracts the trained model from the `.tar` file
  id: totrans-135
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`.tar`文件中提取训练模型
- en: Loads the XGBoost model
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载XGBoost模型
- en: Calls the `plot_importance()` function on the loaded model
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对加载的模型调用`plot_importance()`函数
- en: 'The following diagram shows feature importance for the three trained models,
    starting with the first model on the left:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了三个训练模型的特征重要性，从左侧的第一个模型开始：
- en: '| ![](img/d4efc18f-145a-42f1-a0a9-174774a46d58.png) | ![](img/82248f02-45d1-45d2-8df7-332989aa7f6e.png)
    | ![](img/69c54e56-120d-47c4-851a-3c55e12d5ecc.png) |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| ![](img/d4efc18f-145a-42f1-a0a9-174774a46d58.png) | ![](img/82248f02-45d1-45d2-8df7-332989aa7f6e.png)
    | ![](img/69c54e56-120d-47c4-851a-3c55e12d5ecc.png) |'
- en: '| ![](img/6fc43f97-7778-4b7e-9f3e-01cfe317c2c5.png) | ![](img/a87d63c2-f943-4198-aca4-b02963191d94.png)
    | ![](img/82855b16-6eb2-4123-9bf4-4e4d2078aacb.png) |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| ![](img/6fc43f97-7778-4b7e-9f3e-01cfe317c2c5.png) | ![](img/a87d63c2-f943-4198-aca4-b02963191d94.png)
    | ![](img/82855b16-6eb2-4123-9bf4-4e4d2078aacb.png) |'
- en: 'As we can see, most key predictors have maintained their importance as more
    data became available, while the order of importance changed. To see how the features
    look when mapped, take a look at the following diagram:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，随着更多数据的加入，大多数关键预测因子的相对重要性保持不变，但它们的重要性顺序发生了变化。要查看映射后的特征，请查看以下图表：
- en: '![](img/3754c4e4-d804-42c7-b980-5f0b7b2aa52f.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3754c4e4-d804-42c7-b980-5f0b7b2aa52f.png)'
- en: XGBoost numbers the features from the input dataset, where the first column
    is the target variable, while features are ordered from the second column onward.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: XGBoost会对输入数据集中的特征进行编号，其中第一列是目标变量，而特征从第二列开始排序。
- en: 'Now we will evaluate performance across all three experiments. Let''s deploy
    all three trained models as endpoints as shown in the following code:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将评估三个实验的性能。让我们按照以下代码将所有三个训练好的模型作为端点进行部署：
- en: '[PRE15]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In the preceding code, for each of the experiments, to deploy a trained model
    as an endpoint, we will do the following:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码中，对于每个实验，要将训练后的模型部署为端点，我们将执行以下操作：
- en: First, we will retrieve the trained model from the location (S3 bucket) where
    it is saved.
  id: totrans-147
  prefs:
  - PREF_UL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将从存储位置（S3桶）中检索训练好的模型。
- en: Then, we will create a SageMaker model by passing the trained model, a Docker
    image of the XGBoost algorithm, and SageMaker's execution role.
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将通过传递训练好的模型、XGBoost算法的Docker镜像以及SageMaker的执行角色来创建一个SageMaker模型。
- en: Finally, we will invoke the `deploy` method of the newly created XGBoost Model
    object. We pass in the number of EC2 instances to provision, along with the type
    of instance, to the deploy function.
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将调用新创建的XGBoost模型对象的`deploy`方法。我们将传递EC2实例的数量以及实例类型给deploy函数。
- en: 'The following screenshot shows the endpoints that were created after the trained
    models were deployed:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了训练后的模型部署后创建的端点：
- en: '![](img/473a4807-67d2-41fc-bc96-66f1f5bc7963.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/473a4807-67d2-41fc-bc96-66f1f5bc7963.png)'
- en: To view the deployed models, navigate to SageMaker service and expand the Inference
    section. Under this section, click on Endpoints to view endpoint names, the creation
    time, the status, and the last updated time.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看已部署的模型，请导航到SageMaker服务并展开推理部分。在该部分下，点击端点（Endpoints）以查看端点名称、创建时间、状态和最后更新时间。
- en: Now it is time to predict app downloads for the last 120,000 clicks on Thursday.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候预测星期四最后120,000次点击的应用下载量了。
- en: 'We will create a `RealTimePredictor` object for this, as shown in the following
    code:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为此创建一个`RealTimePredictor`对象，如下代码所示：
- en: '[PRE16]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `RealTimePredictor` object is created by passing the name of the `endpoint`,
    the current `sagemaker` session, and the `content` type.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`RealTimePredictor`对象通过传递`endpoint`的名称、当前的`sagemaker`会话和`content`类型来创建。'
- en: 'Collect the `predictions` for the test data, as follows:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集测试数据的`predictions`，如下所示：
- en: '[PRE17]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: As we can see, we invoke the predict method of `RealTimePredictor` (the SageMaker
    Python SDK) by passing the first 10,000 data clicks.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如我们所见，我们通过传递前10,000个数据点击，调用`RealTimePredictor`（SageMaker Python SDK）的预测方法。
- en: We are now ready to compare the predicted results with the actual app downloads.
    We use the `confusion_matrix` module from the `sklearn` library to obtain the
    true positive rate and the false positive rate. We also use the `roc_auc_score`
    and `accuracy_score` modules from `sklearn` to compute the area under curve and
    accuracy, respectively.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备将预测结果与实际的应用下载量进行比较。我们使用`sklearn`库中的`confusion_matrix`模块来获取真正例率和假正例率。我们还使用`sklearn`中的`roc_auc_score`和`accuracy_score`模块分别计算曲线下面积和准确度。
- en: 'The following is the output for each of the experiments:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是每个实验的输出：
- en: '![](img/45690c8f-7dfd-4b86-9629-414f9fd6fbf6.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/45690c8f-7dfd-4b86-9629-414f9fd6fbf6.png)'
- en: 'The following is the AUC, which shows the performance of all the experiments:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是AUC，展示了所有实验的性能：
- en: '![](img/8250dcc2-b8fc-42ad-9370-750d81170f3c.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8250dcc2-b8fc-42ad-9370-750d81170f3c.png)'
- en: As we can see **Experiment2** performed better than **Experiment1**, while **Experiment3**
    performed the best since it had the highest **AUC**. In **Experiment3**, the true
    positive rate is higher than the false positive rate relative to **Experiment1**
    and **Experiment2**. Accuracy remained the same across all the experiments. Since
    AUC is independent of the underlying class distribution of the test dataset, it
    is an important and key metric when it comes to measuring the model's discriminative
    power. On the other hand, metrics such as accuracy, recall, and precision are
    likely to change as the test set changes.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，**Experiment2**的表现优于**Experiment1**，而**Experiment3**的表现最好，因为它具有最高的**AUC**。在**Experiment3**中，真正例率相对于**Experiment1**和**Experiment2**更高，假正例率较低。准确度在所有实验中保持不变。由于AUC不依赖于测试数据集的类分布，它是衡量模型区分能力的重要指标。另一方面，准确率、召回率和精度等指标可能会随着测试集的变化而变化。
- en: Therefore, after the trained model is deployed in production, it is important
    to seek feedback while the model is in operation. As patterns in data change and
    as new data becomes available, it becomes important to retrain and tune models
    for optimal performance.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在训练好的模型部署到生产环境后，在模型运行期间寻求反馈非常重要。随着数据模式的变化和新数据的出现，重新训练和调整模型以达到最佳性能变得尤为关键。
- en: Summary
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have learned why it is important to monitor models for degraded
    performance. To illustrate this idea, we used a synthetic dataset that captures
    ad-click behavior for mobile app downloads. First, we explored the data to understand
    the relationship between app downloads and ad-clicks. Then, we created features
    by aggregating existing click attributes in multiple dimensions. Next, we created
    three different datasets on which to run three experiments to explain the idea
    of model performance deterioration as new data becomes available. Next, we fitted
    the XGBoost model for each of the experiments. Finally, we evaluated performance
    across all the experiments to conclude that the model with the best performance
    is the one that took into account the latest and greatest click behavior.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了为何监控模型的性能下降至关重要。为说明这一观点，我们使用了一个合成数据集，该数据集捕捉了移动应用下载的广告点击行为。首先，我们探索了数据，以理解应用下载和广告点击之间的关系。然后，我们通过多维度聚合现有点击特征来创建特征。接下来，我们创建了三个不同的数据集，并在这些数据集上进行三次实验，以说明随着新数据的到来，模型性能的恶化问题。随后，我们为每个实验拟合了XGBoost模型。最后，我们评估了所有实验的性能，得出结论，表现最佳的模型是那个考虑了最新点击行为的模型。
- en: Consequently, implementing a feedback loop in a machine learning life cycle
    is critical to maintaining and enhancing model performance and adequately addressing
    business objectives, whether it is for fraud detection or capturing user preferences
    for recommendations.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在机器学习生命周期中实施反馈循环对于保持和提升模型性能，以及充分实现业务目标至关重要，无论是用于欺诈检测还是捕捉用户偏好以供推荐使用。
- en: In the next chapter, which is the final one, we'll summarize all the concepts
    we've learned about in this book and highlight some machine and deep learning
    services from Amazon Web Services that are worth exploring.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，也就是最后一章，我们将总结本书中学习的所有概念，并重点介绍一些来自亚马逊网络服务的机器学习和深度学习服务，值得进一步探索。
- en: Further reading
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Refer to the following link for more information on model accuracy degradation
    and feedback loops: [https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html).'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多有关模型准确性下降和反馈循环的信息，请参考以下链接：[https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html)。
