- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Limitations of Coding with LLMs
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LLMs编码的限制
- en: This chapter will help you learn about how **large language models** ( **LLMs**
    ) lack a perfect understanding of the nuances of human languages and find complex
    coding tasks beyond their abilities. We’ll be examining the inconsistencies and
    unpredictabilities of LLM chatbots. This chapter will also help you to integrate
    the LLM code into your code base. Hopefully, you’ll be informed and inspired by
    research into improving the state of the field, including moving toward constructing
    more complex code.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将帮助您了解**大型语言模型**（**LLMs**）如何缺乏对人类语言细微差别的完美理解，并且在面对复杂编码任务时超出了它们的能力范围。我们将探讨LLM聊天机器人中的不一致性和不可预测性。本章还将帮助您将LLM生成的代码整合到您的代码库中。希望通过对该领域改进状态的研究，您能获得启发，迈向构建更复杂代码的方向。
- en: 'In this chapter, you’ll have the opportunity to learn the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将有机会学习以下内容：
- en: Inherent limitations of LLMs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs的固有限制
- en: Challenges in integrating LLMs into coding workflows
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将LLMs整合到编码工作流中的挑战
- en: Future research directions to address limitations
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未来的研究方向以应对这些限制
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you may want to have the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，您可能需要具备以下内容：
- en: Access to an LLM/chatbot, such as GPT-4 or Gemini; each requires logins. For
    GPT-4, you’d need an OpenAI account and for Gemini, you’d need a Google account.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问LLM/chatbot，如GPT-4或Gemini；每种都需要登录。对于GPT-4，您需要一个OpenAI帐户，对于Gemini，您需要一个Google帐户。
- en: An internet browser for all the additional reading to get deeper into this.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一款互联网浏览器，用于进一步阅读以深入了解。
- en: Now, we’ll get into the first section of the chapter, which talks about the
    inherent limitations of all LLMs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将进入本章的第一部分，讨论所有LLMs的固有限制。
- en: Inherent limitations of LLMs
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs的固有限制
- en: LLMs have shown remarkable capabilities in generating code, but they also possess
    inherent limitations that can significantly impact the quality and reliability
    of the output.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）在生成代码方面展现出了显著的能力，但它们也具有固有的局限性，这些局限性可能会显著影响输出的质量和可靠性。
- en: Core limitations
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核心限制
- en: 'Here are some of the limitations that LLMs have:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是LLMs的一些限制：
- en: '**Lack of true understanding** : While LLMs can generate syntactically correct
    code, they lack a deep understanding of the underlying concepts, algorithms, and
    problem domains. This can lead to suboptimal or incorrect solutions.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏真正的理解**：虽然LLMs可以生成语法正确的代码，但它们缺乏对底层概念、算法和问题领域的深入理解。这可能导致次优或错误的解决方案。'
- en: '**Hallucinations** : LLMs can generate plausible-sounding but incorrect or
    nonsensical code, often referred to as “hallucinations.” This can be particularly
    problematic in critical applications.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**幻觉**：LLMs可能会生成看似合理但实际上是错误或荒谬的代码，通常称为“幻觉”。这在关键应用中尤为成问题。'
- en: '**Dependency on training data** : The quality of LLM-generated code is heavily
    reliant on the quality and diversity of the training data. Biases or limitations
    in the training data can be reflected in the generated code.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对训练数据的依赖**：LLM生成的代码质量在很大程度上依赖于训练数据的质量和多样性。训练数据中的偏见或限制可能会反映到生成的代码中。'
- en: '**Difficulty with complex logic** : LLMs often struggle with tasks requiring
    intricate logical reasoning or problem-solving, leading to suboptimal or incorrect
    code.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理复杂逻辑的困难**：LLMs在处理需要复杂逻辑推理或问题解决的任务时常常遇到困难，导致生成次优或错误的代码。'
- en: '**Lack of contextual understanding** : While LLMs can process information sequentially,
    they often lack a comprehensive understanding of the broader context, which can
    lead to inconsistencies or errors in code generation.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏上下文理解**：尽管LLMs可以顺序处理信息，但它们通常缺乏对更广泛上下文的全面理解，这可能导致生成的代码出现不一致或错误。'
- en: '**Limited context window or memory** : In the context windows of LLMs, the
    amount of information that can be entered in one prompt (query) or that can be
    delivered in a response is limited. These context windows are quickly increasing,
    but they now have big hardware requirements.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有限的上下文窗口或内存**：在LLMs的上下文窗口中，一次提示（查询）中可以输入的信息量或响应中可以传递的信息量是有限的。这些上下文窗口正在迅速增大，但它们目前有较大的硬件要求。'
- en: '**Limited debugging capabilities** : LLMs are generally poor at debugging their
    own generated code, making it necessary for human intervention to identify and
    correct errors.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有限的调试能力**：LLMs通常不擅长调试自己生成的代码，因此需要人工干预以识别和纠正错误。'
- en: '**Old training data** : LLMs cannot update their training data, so can be answering
    based on the past.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**旧的训练数据**：LLM无法更新其训练数据，因此其回答可能基于过时的信息。'
- en: 'There are also specific limitations in code generation, which are as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 代码生成中也存在一些特定的局限性，具体如下：
- en: '**Code quality and efficiency** : LLM-generated code can often be inefficient
    or suboptimal in terms of performance and resource utilization.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码质量和效率**：LLM生成的代码往往在性能和资源利用上不够高效或最优。'
- en: '**Security vulnerabilities** : There’s a risk of generating code with security
    vulnerabilities due to the LLM’s lack of security expertise.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全漏洞**：LLM由于缺乏安全专长，可能生成包含安全漏洞的代码。'
- en: '**Maintainability** : LLM-generated code can be difficult to maintain due to
    its potential complexity and lack of adherence to coding standards.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可维护性**：LLM生成的代码可能由于其潜在的复杂性和不符合编码标准，难以维护。'
- en: '**Reproducibility** : Generating the same code output multiple times can be
    challenging, as LLMs are stochastic systems.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可复现性**：多次生成相同的代码输出可能具有挑战性，因为LLM是随机系统。'
- en: '[ Prompt_Drive]'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[Prompt_Drive]'
- en: Other limitations to LLMs
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM的其他局限性
- en: Apart from the preceding, there might also be ethical and legal limitations.
    LLMs might inadvertently generate biased code or replicate existing code snippets
    verbatim from its training data, leading to potential issues with **intellectual
    property** ( **IP** ) or unintended ethical implications [Parth Santpurkar, Technical
    Reviewer for the book].
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 除了前述内容，LLM可能还会存在伦理和法律限制。LLM可能会无意中生成有偏见的代码，或者从训练数据中逐字复制现有的代码片段，从而引发**知识产权**（**IP**）或不当伦理问题。[Parth
    Santpurkar, 该书的技术审阅人]
- en: There is more on ethics and biases in [*Chapter 5*](B21009_05.xhtml#_idTextAnchor115)
    ; [*Chapter 6*](B21009_06.xhtml#_idTextAnchor137) goes over legal considerations
    and [*Chapter 7*](B21009_07.xhtml#_idTextAnchor180) attempts to handle most security
    threats with countermeasures.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 关于伦理和偏见的内容请参见[*第5章*](B21009_05.xhtml#_idTextAnchor115)；[*第6章*](B21009_06.xhtml#_idTextAnchor137)讨论了法律考虑，[*第7章*](B21009_07.xhtml#_idTextAnchor180)则尝试通过对策应对大多数安全威胁。
- en: Evaluating LLM performance
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估LLM性能
- en: LLM outputs are very difficult to evaluate, but there are many methods to do
    so. Some methods are neural network-based, and some are statistical analysis methods.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的输出非常难以评估，但有许多方法可以进行评估。一些方法基于神经网络，一些则是统计分析方法。
- en: 'What metrics can be used to evaluate LLMs and how do you calculate them? Here’s
    a very brief intro to some of them:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用哪些指标来评估LLM，它们是如何计算的？以下是一些指标的简要介绍：
- en: Is the generated code syntactically and semantically correct compared to a ground
    truth? Does the LLM-generated code solve the problem it was asked to?
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的代码在语法和语义上是否与标准答案一致？LLM生成的代码是否解决了所要求的问题？
- en: How similar is the generated code to the expected solution in terms of functionality
    and logic?
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成的代码在功能和逻辑上与预期解决方案有多相似？
- en: Does the LLM generate incorrect code?
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM会生成错误的代码吗？
- en: '**Contextual relevancy** : For **retrieval-augmented generation** ( **RAG**
    ) models, does the LLM extract and use the most relevant information from the
    provided context?'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文相关性**：对于**检索增强生成**（**RAG**）模型，LLM是否能够从提供的上下文中提取并使用最相关的信息？'
- en: '**Summarization** : Does the LLM give you concise and correct code snippets
    or documentation that is based on the source material?'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**总结能力**：LLM是否能够提供简洁且正确的代码片段或文档，并且这些内容是基于源材料的？'
- en: '**CodeBLEU (Bilingual Evaluation Understudy)** : This compares outputs with
    ground truth code using precision for each matching *n* -gram ( *n* consecutive
    words). BLEU itself is not so effective for code, so CodeBLEU has been for code
    synthesis [CodeBLEU].'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CodeBLEU（双语评估替代）**：通过每个匹配的*n*元组（*n*个连续的单词）的精确度来比较输出与标准答案代码。BLEU本身在代码评估中并不那么有效，因此CodeBLEU被用于代码合成。[CodeBLEU]'
- en: '**METEOR** : A metric that combines unigram matching, stemming, and synonymy
    to capture semantic similarity, which might be beneficial for code evaluation.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**METEOR**：一种结合了单词匹配、词干提取和同义词处理的指标，用以捕捉语义相似性，这对代码评估可能有帮助。'
- en: '[confident_ai, Stevens, CodeBLEU]'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[confident_ai, Stevens, CodeBLEU]'
- en: 'Learn more about metrics here: [https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation](https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation)
    .'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 了解更多关于指标的信息，请访问：[https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation](https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation)。
- en: 'You can also see what Jane Huang says about LLM metrics and best practices:
    [https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5](https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5)
    .'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以看看Jane Huang关于LLM度量标准和最佳实践的说法：[https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5](https://medium.com/data-science-at-microsoft/evaluating-llm-systems-metrics-challenges-and-best-practices-664ac25be7e5)。
- en: 'Learn about CodeBLEU, by Ren et al., here: [https://arxiv.org/abs/2009.10297](https://arxiv.org/abs/2009.10297)
    .'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 了解Ren等人提出的CodeBLEU，点击这里：[https://arxiv.org/abs/2009.10297](https://arxiv.org/abs/2009.10297)。
- en: Overcoming inherent limitations
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 克服固有的限制
- en: Let’s see what can already be done to improve LLM work and results.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看已经可以做些什么来提高LLM的工作和结果。
- en: Search the web
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 搜索网络
- en: 'LLMs are trained with data up to a point, then they are tested and deployed.
    So, their data is always out of date and always needs to be re-trained as the
    world changes. However, Gemini does search the internet and Serper is a low-cost
    API that helps LLMs, such as GPT-4, by searching the web for the latest information.
    Get Serper here: [https://serper.dev/](https://serper.dev/) . It’s very quick
    and easy to sign up for an API key and start using it on your agents. Serper comes
    with 2,500 free queries.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）是在一定数据集上训练的，然后进行测试和部署。因此，它们的数据总是过时的，随着世界的变化总是需要重新训练。然而，Gemini会搜索互联网，而Serper是一个低成本的API，帮助像GPT-4这样的LLMs，通过搜索最新的信息来更新它们。可以在这里获取Serper：[https://serper.dev/](https://serper.dev/)。注册API密钥并开始在你的代理中使用它非常快速且容易。Serper提供2,500次免费查询。
- en: AI agents
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AI代理
- en: An **intelligent agent** is something that operates in an environment, has a
    state, has sensors (with perception), and performs actions autonomously to achieve
    goals. A thermostat, a human, and a state are all examples of intelligent agents
    [Wiki_Agent].
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**智能代理**是在环境中操作的实体，具有状态、传感器（具有感知能力），并能够自主执行动作以实现目标。温控器、人类和状态都是智能代理的例子 [Wiki_Agent]。'
- en: Creating AI agents from LLMs can help to reduce some of the problems of LLMs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 从LLMs创建AI代理可以帮助减少一些LLMs的固有问题。
- en: When you input a prompt to get some code from GPT-4o, run it in an IDE, find
    it has an error, and enter another prompt to GPT-4o to correct this error, you
    are behaving like an agent, and feeding back the weaknesses to be improved.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当你输入一个提示词来从GPT-4o获取一些代码，运行它时发现有错误，然后再向GPT-4o输入另一个提示词来修正这个错误时，你的行为就像一个代理，并将反馈出需要改进的弱点。
- en: 'This can be automated: when applications behave like agents, they are called
    *agentic* .'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以被自动化：当应用程序表现得像代理时，它们被称为*代理性*。
- en: The AI agent does the whole running of the code, feedback, re-query process,
    and iterations itself.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: AI代理会自己完成整个代码运行、反馈、重新查询过程以及迭代。
- en: This way, the LLM agent can work to remove its own errors. If a human is checking,
    this process can be more exact, but the iterations will be slower.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，LLM代理可以自行处理并消除错误。如果是人工检查，这个过程可能更精确，但迭代速度会更慢。
- en: 'Devin is an agent that is a virtual software engineer and can be prompted to
    give you code. Unfortunately, as of writing, in July 2024, Cognition has not released
    Devin to the public; you’ll have to join the waiting list: [https://www.cognition.ai/blog/introducing-devin](https://www.cognition.ai/blog/introducing-devin)
    .'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Devin是一个虚拟的软件工程师代理，可以通过提示词生成代码。不幸的是，截止到2024年7月，Cognition尚未向公众发布Devin；你需要加入等待名单：[https://www.cognition.ai/blog/introducing-devin](https://www.cognition.ai/blog/introducing-devin)。
- en: If you have an agentic application that employs a few different LLMs as agents,
    then the blind spots and weaknesses of one LLM can be improved by other LLMs.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有一个代理性应用程序，使用几个不同的LLM作为代理，那么一个LLM的盲点和弱点可以通过其他LLMs得到改善。
- en: 'Agents and especially multi-agent applications can make the performance of
    LLMs much greater. Even agents powered by weaker LLMs can perform better than
    the latest and best LLMs in the world (at any point). Here is a study on multi-agent
    systems and how they improve the performance of LLMs: [https://arxiv.org/html/2402.05120v1](https://arxiv.org/html/2402.05120v1)
    . LLMs can also debate and vote.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 代理，特别是多代理应用程序，可以大大提升LLM的性能。即使是由较弱的LLMs驱动的代理，也能表现得比世界上最新最强的LLM更好（在任何时刻）。这里有一项关于多代理系统及其如何提升LLM性能的研究：[https://arxiv.org/html/2402.05120v1](https://arxiv.org/html/2402.05120v1)。LLMs也可以进行辩论和投票。
- en: 'Even human reasoning is vastly superior when in groups, rather than a single
    person reasoning alone [Mercier]; this is collective intelligence. Debate and
    being forced to provide good arguments and evidence greatly improve the chances
    of uncovering truth or avoiding mistakes. Groups of humans and AI agent groups
    share benefits:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是人类推理，在团队中也远远优于单个人独自推理[Mercier]；这就是集体智慧。辩论和被迫提供充分的论据和证据大大提高了揭示真相或避免错误的机会。人类群体和AI代理群体共享这些益处：
- en: Error correction
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误修正
- en: Diversity of experience or data
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经验或数据的多样性
- en: 'Knowledge sharing: members can learn from each other'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知识共享：成员可以互相学习
- en: 'More computational power: more speed'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多的计算能力：更快的速度
- en: So, working in groups can be very beneficial; this is probably why humans operate
    in groups of up to billions! Will there ever be groups of billions of AI agents?
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，团队合作可以非常有益；这可能也是人类组成最多可达数十亿人的群体的原因！是否会有由数十亿个AI代理组成的团队呢？
- en: 'Agents can be employed in groups to code, and one of these is called **ChatDev**
    . ChatDev is a virtual software company with a CEO, a developer, an architect,
    and a project manager. These are all agents that work together to make users the
    software requested in a prompt. Find out more about ChatDev here: [https://chatdev.toscl.com/](https://chatdev.toscl.com/)
    and here: [https://medium.com/@meirgotroot/chatdev-review-the-good-the-bad-and-the-ugly-469b5cb691d4](mailto:https://medium.com/@meirgotroot/chatdev-review-the-good-the-bad-and-the-ugly-469b5cb691d4)
    .'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 代理可以组成小组来编写代码，其中之一被称为**ChatDev**。ChatDev是一个虚拟软件公司，拥有CEO、开发者、架构师和项目经理。这些都是一起工作的代理，旨在根据提示帮助用户制作所请求的软件。了解更多关于ChatDev的信息请点击这里：[https://chatdev.toscl.com/](https://chatdev.toscl.com/)以及这里：[https://medium.com/@meirgotroot/chatdev-review-the-good-the-bad-and-the-ugly-469b5cb691d4](mailto:https://medium.com/@meirgotroot/chatdev-review-the-good-the-bad-and-the-ugly-469b5cb691d4)。
- en: Microsoft has developed a multi-agent application for automating complex LLM
    workflows; it’s called **AutoGen** .
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 微软已经开发出一个用于自动化复杂LLM工作流的多代理应用程序；它被称为**AutoGen**。
- en: 'In both AutoGen and ChatDev, the agents talk to each other and collaborate
    to produce a better solution. See a comparison between ChatDev and AutoGen here:
    [https://www.ikangai.com/autogen-vs-chatdev-pioneering-multi-agent-systems-in-the-llm-landscape/](https://www.ikangai.com/autogen-vs-chatdev-pioneering-multi-agent-systems-in-the-llm-landscape/)
    .'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在AutoGen和ChatDev中，代理彼此之间进行沟通并协作，生成更好的解决方案。查看ChatDev和AutoGen的对比，请点击这里：[https://www.ikangai.com/autogen-vs-chatdev-pioneering-multi-agent-systems-in-the-llm-landscape/](https://www.ikangai.com/autogen-vs-chatdev-pioneering-multi-agent-systems-in-the-llm-landscape/)。
- en: AutoGPT is an open source AI agent that you can query. It will break up the
    goal you give it into sub-tasks, and use tools such as the internet in an automatic
    loop ( [https://en.wikipedia.org/wiki/Auto-GPT](https://en.wikipedia.org/wiki/Auto-GPT)
    ).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: AutoGPT是一个开源AI代理，你可以向其查询。它会将你给定的目标分解为子任务，并使用互联网等工具进行自动循环（[https://en.wikipedia.org/wiki/Auto-GPT](https://en.wikipedia.org/wiki/Auto-GPT)）。
- en: 'Make your own AI agents with MetaGPT: [https://play.google.com/store/apps/details?id=com.metagpt.app&hl=en_US&pli=1](https://play.google.com/store/apps/details?id=com.metagpt.app&hl=en_US&pli=1)
    .'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用MetaGPT创建你自己的AI代理：[https://play.google.com/store/apps/details?id=com.metagpt.app&hl=en_US&pli=1](https://play.google.com/store/apps/details?id=com.metagpt.app&hl=en_US&pli=1)。
- en: AI agents are a key field of research at the moment, and the field shows a lot
    of promise. Much can be written about this topic, but we need to move on to the
    topics of this chapter.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: AI代理是目前的一个关键研究领域，并且该领域展现出很大的潜力。关于这个话题可以写很多内容，但我们需要继续讨论本章的主题。
- en: We’ve looked at inherent limitations, and we can learn about how difficult it
    can be to insert code into coding workflows in the next section.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了固有的局限性，接下来我们将学习将代码插入编码工作流中的困难。
- en: Challenges in integrating LLMs into coding workflows
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将LLM集成到编码工作流中的挑战
- en: 'First, we should look at what the challenges are with LLM-generated code and
    workflows. Here are some of them:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们应该看看LLM生成的代码和工作流中存在哪些挑战。以下是一些挑战：
- en: Code quality and reliability, security risks, and dependency management have
    already been mentioned.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码质量和可靠性、安全风险以及依赖管理已经被提到。
- en: '**Explainability** : Understanding the logic behind LLM-generated code can
    be difficult, making debugging and maintenance challenging'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性**：理解LLM生成代码背后的逻辑可能很困难，这使得调试和维护变得具有挑战性'
- en: '**Contextual understanding** : The LLM understands a small context but not
    the whole code base or project, so its use may lead to incompatibility with the
    other code or not generate co de that’s in the same style'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文理解**：LLM能够理解小范围的上下文，但无法理解整个代码库或项目，因此它的使用可能导致与其他代码不兼容，或无法生成与其他代码风格一致的代码。'
- en: '**Code snippet length** : LLMs may struggle to understand and process long
    code snippets, leading to incomplete or inaccurate responses'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码片段长度**：大型语言模型（LLMs）可能在理解和处理长代码片段时遇到困难，导致生成不完整或不准确的响应。'
- en: '**Specialized domains** : LLMs trained on general-purpose datasets might lack
    the deep domain-specific knowledge required for certain coding tasks, such as
    medical imaging or financial modeling'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专门领域**：在通用数据集上训练的LLM可能缺乏某些编码任务所需的深度领域知识，例如医学影像或金融建模。'
- en: '**Fixing complex errors** : While good at finding errors in code, LLMs usually
    don’t detect all errors and may also not identify and fix subtle or complex errors'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修复复杂错误**：虽然LLMs擅长发现代码中的错误，但通常不能检测到所有错误，也可能无法识别和修复微妙或复杂的错误。'
- en: '**Performance considerations** : An LLM might not prioritize code efficiency
    or optimization, potentially generating code that is suboptimal in terms of execution
    speed or resource usage'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能考虑**：LLM可能不会优先考虑代码效率或优化，可能生成在执行速度或资源使用方面不理想的代码。'
- en: '**Algorithm selection** : Choosing the most appropriate algorithms and data
    structures for a given task can be challenging for LLMs, as they might not have
    a deep understanding of algorithmic complexity or trade-offs'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**算法选择**：选择最适合给定任务的算法和数据结构对LLMs来说可能是一个挑战，因为它们可能没有深入理解算法复杂度或权衡。'
- en: Relevant workflow example
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 相关工作流示例
- en: A common workflow involving LLM-generated code is **automated code generation
    for software development** . This involves using an LLM to generate initial code
    snippets based on user requirements or code comments, followed by human review,
    testing, and integration into the main code base.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的LLM生成代码的工作流是**自动化代码生成用于软件开发**。该工作流包括使用LLM根据用户需求或代码注释生成初始代码片段，之后进行人工审查、测试，并将其集成到主代码库中。
- en: 'Here is a bit more detail on the integration process for LLM-generated code:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是有关LLM生成代码集成过程的更多细节：
- en: '**Code review and refinement** : The generated code undergoes a thorough review
    by human experts to ensure it aligns with coding standards, best practices, and
    project requirements. This may involve refactoring, debugging, and optimization.'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**代码审查和优化**：生成的代码会经过人类专家的严格审查，以确保其符合编码标准、最佳实践和项目需求。这可能包括重构、调试和优化。'
- en: '**Unit testing** : The integrated code undergoes rigorous unit testing to verify
    its functionality and correctness. This helps identify and address potential issues
    early in the development process.'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**单元测试**：集成后的代码会经过严格的单元测试，以验证其功能性和正确性。这有助于在开发过程中及早识别和解决潜在问题。'
- en: '**Integration testing** : The integrated code is tested in conjunction with
    other components of the system to ensure seamless integration and compatibility.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**集成测试**：集成后的代码与系统中的其他组件一起进行测试，以确保无缝集成和兼容性。'
- en: '**Version control** : The integrated code is properly managed using version
    control systems (e.g., Git or SVN) to track changes, facilitate collaboration,
    and enable rollback if necessary.'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**版本控制**：集成后的代码通过版本控制系统（如Git或SVN）进行适当管理，以跟踪更改、促进协作，并在必要时支持回滚。'
- en: '**Continuous integration and continuous delivery (CI/CD)** : The integrated
    code is incorporated into the CI/CD pipeline to automate testing, deployment,
    and monitoring.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**持续集成和持续交付（CI/CD）**：集成后的代码会被纳入CI/CD管道中，以自动化测试、部署和监控。'
- en: '**Monitoring and maintenance** : The performance and behavior of the integrated
    code are closely monitored to identify and address any issues that may arise.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**监控与维护**：集成后的代码的性能和行为会被密切监控，以识别并解决可能出现的任何问题。'
- en: '[ Liu_2024]'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[Liu_2024]'
- en: Security risks
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安全风险
- en: The preceding process didn’t mention security as a stage because security must
    be a concern throughout the process. We’ll briefly mention risks and measures
    to secure your systems, but [*Chapter 7*](B21009_07.xhtml#_idTextAnchor180) has
    much more on security.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 前述过程没有提到安全性作为一个阶段，因为安全性必须贯穿整个过程。我们将简要提到风险和保护系统的措施，但[*第七章*](B21009_07.xhtml#_idTextAnchor180)中有更多关于安全性的内容。
- en: There are various security risks; here are some that LLM-generated code may
    bring.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 存在各种安全风险；以下是LLM生成的代码可能带来的安全风险。
- en: Risks
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 风险
- en: 'While LLM-generated code offers potential benefits, it also presents several
    risks:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管LLM生成的代码提供了潜在的好处，但它也带来了若干风险：
- en: '**Code quality and** **reliability risks** :'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码质量与** **可靠性风险**：'
- en: '**Incorrect or inefficient code** : LLMs may generate code that is functionally
    incorrect, inefficient, or suboptimal'
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不正确或低效的代码**：LLM可能生成功能不正确、低效或次优的代码'
- en: '**Security vulnerabilities** : Generated code could introduce security vulnerabilities
    if not carefully reviewed'
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全漏洞**：如果没有经过仔细审查，生成的代码可能引入安全漏洞'
- en: '**Lack of adherence to coding standards** : Code might not conform to established
    coding standards, leading to maintainability issues'
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不遵守编码标准**：代码可能不符合既定的编码标准，从而导致可维护性问题'
- en: '**Operational risks** :'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**操作风险**：'
- en: '**Dependency issues** : The generated code might introduce dependencies that
    are incompatible with the existing environment'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**依赖问题**：生成的代码可能引入与现有环境不兼容的依赖项'
- en: '**Integration challenges** : Integrating LLM-generated code into existing systems
    can be complex and error-prone'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成挑战**：将LLM生成的代码集成到现有系统中可能既复杂又容易出错'
- en: Security measures
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安全措施
- en: 'Here are measures to secure your systems against the preceding risks:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一些针对前述风险保护系统的措施：
- en: '**Pre-integration security** :'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成前安全**：'
- en: '**LLM model security** : Ensure the LLM model used is secure and doesn’t expose
    sensitive data. Consider using models with robust security measures in place.'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLM模型安全**：确保使用的LLM模型是安全的，并且不会暴露敏感数据。考虑使用具备强大安全措施的模型。'
- en: '**Data privacy** : Protect sensitive data used to train the LLM and generate
    code. Implement data anonymization and encryption techniques.'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据隐私**：保护用于训练LLM并生成代码的敏感数据。实施数据匿名化和加密技术。'
- en: '**Code vulnerability scanning** : Conduct thorough vulnerability scans on the
    generated code before integration to identify potential security risks.'
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码漏洞扫描**：在集成前对生成的代码进行全面的漏洞扫描，以识别潜在的安全风险。'
- en: '**Integration and** **post-integration security** :'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成与** **后集成安全**：'
- en: '**Code review and security audit** : Employ security experts to review the
    integrated code for vulnerabilities and compliance with security standards'
  id: totrans-113
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码审查与安全审计**：聘请安全专家审查集成代码，检查漏洞并确保符合安全标准'
- en: '**Secure coding practices** : Adhere to strict secure coding practices throughout
    the integration process'
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全编码实践**：在整个集成过程中遵循严格的安全编码实践'
- en: '**Security testing** : Conduct comprehensive security testing, including penetration
    testing, to identify and address weaknesses'
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全测试**：进行全面的安全测试，包括渗透测试，以识别和解决弱点'
- en: '**Monitoring and threat detection** : Implement *continuous* monitoring and
    threat detection mechanisms to identify and respond to potential security incidents'
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控与威胁检测**：实施*持续*监控和威胁检测机制，以识别并响应潜在的安全事件'
- en: '**Specific** **security measures** :'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**具体的** **安全措施**：'
- en: '**Input validation and sanitization** : Validate and sanitize all inputs to
    the LLM to prevent injection attacks and other vulnerabilities'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入验证与清理**：验证并清理所有输入，以防止注入攻击和其他漏洞'
- en: '**Access control** : Implement strict access controls to protect the LLM and
    the integrated code from unauthorized access'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**访问控制**：实施严格的访问控制，以保护LLM和集成代码免受未经授权的访问'
- en: '**Encryption** : Encrypt sensitive data both at rest and in transit'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加密**：对敏感数据进行加密，无论是在静态存储还是在传输过程中'
- en: '**Incident response plan** : Develop a comprehensive incident response plan
    to address security breaches effectively'
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件响应计划**：制定全面的事件响应计划，以有效应对安全漏洞'
- en: '[*Chapter 7*](B21009_07.xhtml#_idTextAnchor180) has much more information on
    security, so we won’t repeat that here. [*Chapter 6*](B21009_06.xhtml#_idTextAnchor137)
    goes deep into the legal side of LLM code, so we won’t repeat that here either.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第7章*](B21009_07.xhtml#_idTextAnchor180)包含更多关于安全的信息，因此我们在此不再重复。[*第6章*](B21009_06.xhtml#_idTextAnchor137)深入探讨了LLM代码的法律方面，因此我们在此也不再重复。'
- en: IP concerns
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 知识产权问题
- en: 'The issue of IP with respect to LLM-generated code is complex and evolving.
    Here are some potential issues:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 关于LLM生成代码的知识产权问题复杂且不断发展。以下是一些潜在的问题：
- en: '**Copyright issues** :'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版权问题**：'
- en: '**Copyright infringement** : If the LLM was trained on copyrighted code, there’s
    a risk of the generated code infringing on those copyrights. This is particularly
    complex due to the nature of training data and the potential for unintentional
    copying.'
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版权侵权** ：如果LLM在受版权保护的代码上进行了训练，那么生成的代码可能会侵犯这些版权。由于训练数据的性质以及可能的无意复制，这一问题尤为复杂。'
- en: '**Ownership of generated code** : Who owns the copyright to the generated code?
    The LLM provider, the user, or a shared ownership model? This is an area with
    limited legal precedent.'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成代码的所有权** ：谁拥有生成代码的版权？是LLM提供者、用户，还是共享所有权模式？这是一个法律先例有限的领域。'
- en: '**Patent issues** :'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专利问题** ：'
- en: '**Patent infringement** : If the generated code implements a patented invention,
    it could constitute patent infringement'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专利侵权** ：如果生成的代码实施了某项专利发明，它可能构成专利侵权。'
- en: '**Patent eligibility** : Whether or not generated code can be patented is a
    complex legal question, as it involves determining if the code represents an inventive
    step'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专利资格** ：生成的代码是否能够获得专利是一个复杂的法律问题，因为它涉及到判断该代码是否代表了一项创造性步骤。'
- en: '**Trade** **secret issues** :'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**商业秘密问题** ：'
- en: '**Disclosure of trade secrets** : If the LLM was trained on proprietary code
    or data, there’s a risk of inadvertently disclosing trade secrets through the
    generated code'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**商业秘密披露** ：如果LLM是基于专有代码或数据进行训练的，那么通过生成的代码有可能无意中披露商业秘密。'
- en: '**Other concerns** :'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**其他问题** ：'
- en: '**Fair use** : The doctrine of fair use might be applicable in some cases,
    but its application to LLM-generated code is still unclear'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**合理使用** ：在某些情况下，合理使用原则可能适用，但其在LLM生成代码中的应用仍然不明确。'
- en: '**Licensing** : Understanding the licensing terms of the LLM and any underlying
    data is crucial to avoid IP issues'
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**许可** ：了解LLM及其底层数据的许可条款对避免知识产权问题至关重要。'
- en: It’s important to note that the legal landscape in this area is rapidly changing,
    and it’s advisable to consult with legal experts to assess specific risks and
    develop appropriate strategies to mitigate them.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，该领域的法律环境正在迅速变化，建议咨询法律专家，以评估具体风险并制定相应的策略以降低这些风险。
- en: Again, check out [*Chapter 6*](B21009_06.xhtml#_idTextAnchor137) for much more
    on legal concerns.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 再次查看[*第6章*](B21009_06.xhtml#_idTextAnchor137)，了解更多法律问题。
- en: Where to learn more about IP concerns of LLM-generated code
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多有关LLM生成代码的知识产权问题
- en: 'Check out these prominent legal sites for developments in LLM-generated code,
    a.k.a. AI-generated code:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 查看这些著名的法律网站，了解LLM生成代码（即AI生成代码）的最新发展：
- en: '**Harvard Law** **Review** : [https://harvardlawreview.org/](https://harvardlawreview.org/)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**哈佛法学评论** ：[https://harvardlawreview.org/](https://harvardlawreview.org/)'
- en: '**Stanford Law** **Review** : [https://www.stanfordlawreview.org/](https://www.stanfordlawreview.org/)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**斯坦福法学评论** ：[https://www.stanfordlawreview.org/](https://www.stanfordlawreview.org/)'
- en: '**Columbia Law** **Review** : [https://columbialawreview.org/](https://columbialawreview.org/)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**哥伦比亚法学评论** ：[https://columbialawreview.org/](https://columbialawreview.org/)'
- en: '**American Intellectual Property Law Association (AIPLA)** : [https://www.aipla.org/](https://www.aipla.org/)
    ( e.g., [https://www.aipla.org/detail/event/2024/04/23/default-calendar/aipla-cle-webinar-copyright-implications-in-generative-ai](https://www.aipla.org/detail/event/2024/04/23/default-calendar/aipla-cle-webinar-copyright-implications-in-generative-ai)
    )'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**美国知识产权法协会 (AIPLA)** ：[https://www.aipla.org/](https://www.aipla.org/)（例如，[https://www.aipla.org/detail/event/2024/04/23/default-calendar/aipla-cle-webinar-copyright-implications-in-generative-ai](https://www.aipla.org/detail/event/2024/04/23/default-calendar/aipla-cle-webinar-copyright-implications-in-generative-ai)）'
- en: '**International Trademark Association (** **INTA)** : [https://www.inta.org/](https://www.inta.org/)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**国际商标协会 (INTA)** ：[https://www.inta.org/](https://www.inta.org/)'
- en: '**European Patent Office (EPO)** : [https://www.epo.org/](https://www.epo.org/)
    ( e.g. [https://www.epo.org/en/about-us/statistics/patent-index-2023/insight-artificial-intelligence](https://www.epo.org/en/about-us/statistics/patent-index-2023/insight-artificial-intelligence)
    )'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欧洲专利局 (EPO)** ：[https://www.epo.org/](https://www.epo.org/)（例如：[https://www.epo.org/en/about-us/statistics/patent-index-2023/insight-artificial-intelligence](https://www.epo.org/en/about-us/statistics/patent-index-2023/insight-artificial-intelligence)）'
- en: '**United States Patent and Trademark Office (** **USPTO)** : [https://www.uspto.gov/](https://www.uspto.gov/)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**美国专利商标局 (USPTO)** ：[https://www.uspto.gov/](https://www.uspto.gov/)'
- en: '**World Intellectual Property Office (WIPO)** : [https://www.wipo.int/](https://www.wipo.int/)
    ( e.g., [https://www.wipo.int/export/sites/www/about-ip/en/frontier_technologies/pdf/generative-ai-factsheet.pdf](https://www.wipo.int/export/sites/www/about-ip/en/frontier_technologies/pdf/generative-ai-factsheet.pdf)
    )'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**世界知识产权组织（WIPO）**：[https://www.wipo.int/](https://www.wipo.int/)（例如，[https://www.wipo.int/export/sites/www/about-ip/en/frontier_technologies/pdf/generative-ai-factsheet.pdf](https://www.wipo.int/export/sites/www/about-ip/en/frontier_technologies/pdf/generative-ai-factsheet.pdf)）'
- en: '**LexisNexis** : [https://www.lexisnexis.com/](https://www.lexisnexis.com/)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LexisNexis**：[https://www.lexisnexis.com/](https://www.lexisnexis.com/)'
- en: '**Thomson** **Reuters** : [https://legal.thomsonreuters.com/en/search-results#q=LLM%20code&t=Legal&sort=relevancy](https://legal.thomsonreuters.com/en/search-results#q=LLM%20code&t=Legal&sort=relevancy)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**汤姆森** **路透社**：[https://legal.thomsonreuters.com/en/search-results#q=LLM%20code&t=Legal&sort=relevancy](https://legal.thomsonreuters.com/en/search-results#q=LLM%20code&t=Legal&sort=relevancy)'
- en: We cannot talk about the challenges of integrating LLM-generated code into workflows
    without mentioning dependency management, the backbone of code integration.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能谈论将LLM生成的代码集成到工作流程中的挑战，而不提及依赖管理，它是代码集成的支柱。
- en: Dependency management
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 依赖管理
- en: '**Dependency management** is the process of identifying, controlling, and managing
    the external software components (libraries, frameworks, or tools) that a software
    project relies on. These external components are called **dependencies** .'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**依赖管理**是识别、控制和管理软件项目所依赖的外部软件组件（如库、框架或工具）的过程。这些外部组件称为**依赖项**。'
- en: If these dependencies are not looked after and fail to work as expected, then
    the whole application may well stop working and disrupt the lives of many or all
    of its users. These failures can be very embarrassing and bad for business. If
    you have fewer dependencies, there will be less risk and maintenance.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些依赖项没有得到妥善管理，并且无法按预期工作，那么整个应用程序可能会停止工作，进而影响到许多或所有用户的使用。这些故障可能非常尴尬，并对业务造成不利影响。如果依赖项较少，风险和维护成本也会相应减少。
- en: Importance in LLM-generated code integration
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在LLM生成代码集成中的重要性
- en: 'When integrating code generated by LLMs, dependency management becomes even
    more critical for several reasons:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在集成LLM生成的代码时，依赖管理变得更加关键，原因有以下几点：
- en: '**Unpredictable dependencies** : LLMs might introduce dependencies that were
    not anticipated, leading to compatibility issues or security risks'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不可预测的依赖项**：LLM可能引入未预见的依赖项，导致兼容性问题或安全风险'
- en: '**Version conflicts** : Different dependencies may have conflicting version
    requirements, causing build failures or runtime errors'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版本冲突**：不同的依赖项可能有冲突的版本要求，导致构建失败或运行时错误'
- en: '**Security vulnerabilities** : Outdated or compromised dependencies can expose
    the entire application to security threats'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全漏洞**：过时或被破坏的依赖项可能会使整个应用程序暴露于安全威胁中'
- en: '**Performance impact** : Inefficient or bloated dependency trees can degrade
    application performance'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能影响**：低效或臃肿的依赖树可能会降低应用程序性能'
- en: '**Maintainability** : Proper dependency management is essential for understanding
    and modifying the code base in the future'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可维护性**：适当的依赖管理对未来理解和修改代码库至关重要'
- en: 'The best practices for dependency management are:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖管理的最佳实践包括：
- en: '**Dependency analysis** : Thoroughly analyze the dependencies introduced by
    the LLM-generated code to identify potential conflicts or issues'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**依赖分析**：彻底分析LLM生成的代码引入的依赖项，以识别潜在的冲突或问题'
- en: '**Version control** : Use a robust version control system to track changes
    in dependencies and revert to previous versions if necessary'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版本控制**：使用强大的版本控制系统来追踪依赖项的更改，并在必要时回退到先前的版本'
- en: '**Dependency management tools** : Employ tools such as npm, Apache Maven, Gradle,
    or pip to manage dependencies effectively'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**依赖管理工具**：使用npm、Apache Maven、Gradle或pip等工具来有效管理依赖项'
- en: '**Regular updates** : Keep dependencies up to date with the latest versions
    to benefit from bug fixes and security patches'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定期更新**：保持依赖项更新至最新版本，以便受益于错误修复和安全补丁'
- en: '**Dependency vulnerability scanning** : Regularly scan dependencies for known
    vulnerabilities and address them promptly'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**依赖漏洞扫描**：定期扫描依赖项中的已知漏洞，并及时解决'
- en: '**Dependency minimization** : Strive to minimize the number of dependencies
    to reduce complexity and potential issues'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**依赖最小化**：努力减少依赖项数量，以降低复杂性和潜在问题'
- en: By following the preceding practices, you can mitigate the risks associated
    with LLM-generated code and ensure the stability and security of your applications
    and systems [ QwietAI , Sonatype].
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循前述的实践，您可以减轻与LLM生成代码相关的风险，并确保您的应用程序和系统的稳定性与安全性[QwietAI, Sonatype]。
- en: Hopefully, automated tools for checking and correcting these things will soon
    be developed. Maybe they will use LLMs as part of their operations
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 希望用于检查和修正这些问题的自动化工具很快就会被开发出来。也许它们会在其操作中使用LLM。
- en: That’s all we’re going to talk about regarding dependency management. Next,
    we must cover explainability, because we want to ensure the code is understandable,
    does what we intend, and we can tell others about how it works, if need be.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 关于依赖管理，我们就讲到这里。接下来，我们必须讨论可解释性，因为我们希望确保代码是可以理解的，能够按我们预期的方式运行，并且在需要时能够向他人解释其工作原理。
- en: Explainability
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可解释性
- en: Sensibly, there is a movement toward having more explainable and transparent
    code, but using LLMs for code, often black-box code, might make this more difficult
    if we do it the wrong way. These AI-generated segments might deviate from established
    coding conventions, introduce unforeseen dependencies, or make assumptions incompatible
    with the existing code base. AI code that is explainable is called **XAI** .
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 合理地说，当前有朝着更具可解释性和透明度的代码发展的趋势，但如果我们采用错误的方法，使用LLM生成的代码（通常是黑箱代码）可能会使这变得更加困难。这些AI生成的代码片段可能会偏离已建立的编码惯例，产生不可预见的依赖关系，或者做出与现有代码库不兼容的假设。可解释的AI代码被称为**XAI**。
- en: AI or a human, integrating code generated by a different author, who doesn’t
    know everything about how the other scripts, functions, classes, and decorators
    of the code are written can follow a different approach and make different assumptions,
    so could introduce complexities that are hard to follow. This is even worse if
    the additional code doesn’t make sense given the overall software architecture.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是AI还是人类，整合由不同作者生成的代码时，由于不了解其他脚本、函数、类和装饰器的写法，可能会采取不同的方法并做出不同的假设，从而引入难以理解的复杂性。如果额外的代码与整体软件架构不符，这种情况甚至更糟。
- en: 'Issues when using LLM-generated code may include the following:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LLM生成的代码可能会遇到以下问题：
- en: '**Hidden assumptions and biases** : LLMs might incorporate hidden biases or
    assumptions from their training data, which can manifest in the generated code.
    These biases can be difficult to identify and can lead to unexpected behaviors
    or errors.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐藏的假设和偏见**：LLM可能会将训练数据中的隐藏偏见或假设融入到生成的代码中。这些偏见可能难以识别，并可能导致意外的行为或错误。'
- en: '**Lack of traceability** : Understanding the origin of specific code segments
    within the LLM-generated output can be challenging. This makes it difficult to
    pinpoint the source of errors or to modify the code effectively.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏可追溯性**：理解LLM生成输出中具体代码片段的来源可能具有挑战性。这使得定位错误源或有效修改代码变得困难。'
- en: '**Dynamic behavior** : LLMs can generate code that exhibits dynamic behavior,
    making it difficult to predict how the code will function under different conditions.
    This can lead to unexpected outcomes and challenges in debugging.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动态行为**：LLM能够生成表现出动态行为的代码，这使得难以预测代码在不同条件下的表现。这可能导致意外的结果，并增加调试的挑战。'
- en: '**Overreliance on comments** : While comments can improve code readability,
    excessive reliance on comments to explain LLM-generated code can be misleading.
    Comments might not accurately reflect the code’s actual behavior, especially if
    the code itself is complex or ambiguous.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过度依赖注释**：虽然注释可以提高代码可读性，但过度依赖注释来解释LLM生成的代码可能会产生误导。尤其当代码本身复杂或模糊时，注释可能无法准确反映代码的实际行为。'
- en: These challenges underscore the importance of *rigorous* testing, code reviews,
    and careful integration when incorporating LLM-generated code into software systems.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这些挑战凸显了*严格*测试、代码审查和在将LLM生成代码整合到软件系统时进行仔细集成的重要性。
- en: 'This is a good source to study XAI more: [ACM_DL].'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这是研究XAI的一个好来源：[ACM_DL]。
- en: Since we have an understanding of the challenges of integrating LLM-generated
    code into coding workflows, we can move on to thinking about the future and how
    researchers may work to ameliorate the LLM limitations.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经理解了将LLM生成的代码整合到编码工作流中的挑战，那么我们可以开始思考未来，研究人员可能会如何致力于改善LLM的局限性。
- en: Future research directions to address limitations
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决局限性的未来研究方向
- en: What might our human-machine civilization do to LLMs to remove and mitigate
    more of their limitations and drive technological advancements?
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的人工-机器文明能为大语言模型做些什么，以去除和减轻更多的限制并推动技术进步？
- en: Let’s consider a few ideas here.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这里考虑一些想法。
- en: Continuous learning
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 持续学习
- en: If we could enable LLMs to constantly take in new data and re-train frequently
    (e.g., every day), they would not be out of date for long and could go through
    many iterations of improvement in short time spans.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能够让大语言模型持续吸收新数据并频繁再训练（例如每天），它们就不会长时间过时，并且可以在短时间内经历多次改进的迭代。
- en: Novel architectures
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 新颖的架构
- en: Exploring new neural network architectures and hybrid models can lead to breakthroughs
    in LLM capabilities.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 探索新的神经网络架构和混合模型可能会在大语言模型的能力上带来突破。
- en: New hardware devices and coding and testing practices have always been important
    for machine learning advancement, but what really drives AI power is new neural
    network architecture.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 新的硬件设备、编码和测试实践一直对机器学习的进步至关重要，但真正推动人工智能力量的是新的神经网络架构。
- en: The neural network gave us the ability to train software to make its own decisions
    and be more adaptable, rather than every scenario being programmed and hardcoded
    in.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络让我们能够训练软件做出自己的决策并更具适应性，而不是将每种场景都编程并硬编码进去。
- en: 'Before deep learning, neural networks were weak and couldn’t solve complex
    problems: object detection, translation, object descriptions, and so on.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习之前，神经网络较为薄弱，无法解决复杂的问题：物体检测、翻译、物体描述等等。
- en: Before LLMs, the public couldn’t query an AI in a natural language (English,
    French, Japanese, etc.) to gain knowledge quickly and get text generation, AI
    art, AI music, AI movies, and AI-generated code.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在大语言模型（LLMs）之前，公众无法用自然语言（如英语、法语、日语等）快速查询人工智能，获取知识，生成文本、AI艺术、AI音乐、AI电影和AI生成的代码。
- en: Each new generation of ML architecture gives the world new abilities.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 每一代新的机器学习架构都为世界带来新的能力。
- en: Likely, some of the proposed new ML architectures will lead to advancements
    that the world can greatly benefit from.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能，一些提出的新机器学习架构将带来世界能够大大受益的进展。
- en: Computational efficiency
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算效率
- en: Optimizing model size and computational requirements can make LLMs more accessible
    and scalable.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 优化模型大小和计算需求可以让大语言模型（LLMs）更加可访问且具备更好的可扩展性。
- en: To approximate anything like human thinking and understand the context of a
    query or topic, LLMs take many billions of parameters (neural network training
    weights); the latest LLM from Meta, Llama 3.1, has a version with 405 billion
    parameters. GPT-4o has over 200 billion parameters. These models have enormous
    memory requirements (800 GB for Llama 3.1 400B), so average people cannot use
    these most powerful models. They use far too much money, space, energy, and time
    to order the hardware. The human brain, indeed the brain of any animal, is vastly
    more efficient when using energy and space, if not memory, directly. If we can
    make LLMs more efficient in these dimensions, then we can greatly democratize
    LLMs for the people. That would speed up technological development and help people
    not working for huge tech companies to have enough income to afford to live.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 为了模拟人类思维并理解查询或话题的上下文，大语言模型需要数十亿个参数（神经网络训练权重）；Meta的最新大语言模型Llama 3.1有一个版本拥有4050亿个参数。GPT-4o则有超过2000亿个参数。这些模型对内存的需求巨大（Llama
    3.1 400B需要800GB），因此普通人无法使用这些最强大的模型。它们消耗了过多的资金、空间、能量和时间来购买硬件。人类大脑，实际上任何动物的大脑，在能量和空间使用上的效率远高于直接使用内存。如果我们能在这些方面提高大语言模型的效率，就能大大实现大语言模型的普及，帮助普通人生活得更好，并加速技术发展。
- en: Ways to reduce the burden include using flash attention, lower precision, and
    the aforementioned architectural innovations [HuggingFace_Optimizing, Snowflake].
    Flash attention is an attention algorithm that is more memory-efficient and also
    uses GPU memory in a better way.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 减轻负担的方法包括使用闪存注意力、更低的精度以及前述的架构创新[HuggingFace_Optimizing, Snowflake]。闪存注意力是一种内存效率更高的注意力算法，并且在使用GPU内存时表现更好。
- en: 'Quantization or lower precision involves using less precise numbers; so, instead
    of using 16-bit numbers, the model can be stored in 8-bit numbers. 8-bit numbers
    are 2 8 = 256 digits in a number (such as RGB values in a picture: 0 to 255) and
    16-bit is 2^16, which is 65,536 different values in a number. So, if you’re storing
    the model with only 8-bit precision, you’ll save a lot of computation, time, and
    energy, but the model will be less precise. This is why there are Llama 8b and
    Llama 70b models; they are smaller and can run on more average computer hardware.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 量化或低精度涉及使用不太精确的数字；因此，模型可以使用 8 位数字代替 16 位数字进行存储。8 位数字是 2^8 = 256 个数字（例如图片中的 RGB
    值：0 到 255），而 16 位数字是 2^16，即 65,536 个不同的值。所以，如果你仅使用 8 位精度存储模型，你将节省大量的计算、时间和能源，但模型的精度会降低。这就是为什么会有
    Llama 8b 和 Llama 70b 模型的原因；它们更小，可以在更多普通计算机硬件上运行。
- en: Pruning can also reduce model size and inference time without significant performance
    degradation.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 剪枝也可以在不显著降低性能的情况下，减少模型的大小和推理时间。
- en: More specialized architectures, such as rotary embeddings, Alibi, Grouped-Query
    Attention, and Multi-Query Attention, can improve LLM efficiencies. You can learn
    more about those from [HuggingFace_Optimizing]. This is beyond the scope of this
    chapter; Hugging Face has more information on architectures.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 更加专业化的架构，如旋转嵌入、Alibi、分组查询注意力和多查询注意力，能够提升 LLM 的效率。你可以从 [HuggingFace_Optimizing]
    了解更多相关信息。这超出了本章的讨论范围，Hugging Face 提供了更多关于架构的信息。
- en: With LLMs, inference is when you give the LLM a prompt and get a response [Gemini,
    Symbli].
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 LLM，推理是指你给 LLM 提供一个提示并获得回应 [Gemini, Symbli]。
- en: If LLMs could be more efficient with energy usage, they wouldn’t take as much
    money to train, thus democratizing LLM training. There is work to make lighter
    LLMs that can be used on smaller and more mobile devices, so this issue is known.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 LLM 能够更加高效地使用能源，它们的训练成本就会降低，从而实现 LLM 训练的民主化。已经有工作致力于开发更轻量的 LLM，这些模型可以在更小和更移动的设备上运行，因此这个问题是已知的。
- en: More efficient LLMs could be able to understand the contexts of the scripts,
    classes, functions, and decorators better.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 更高效的 LLM 可能能够更好地理解脚本、类、函数和装饰器的上下文。
- en: If code operated more quickly, then vulnerabilities could be found more quickly.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如果代码运行得更快，那么漏洞也能更快速地被发现。
- en: Efficiency and better contextual awareness could also help with dependency understanding.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 更高效的模型和更好的上下文理解也可能有助于依赖关系的理解。
- en: Specialized training
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 专业化训练
- en: If you want an LLM with a great ability to give deep insights into the code
    needed for a specific problem or application, it’ll perform better with specific
    training on those problems and solutions. This is because it’ll be more familiar
    with that field of work and its best practices.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望 LLM 能够深入理解特定问题或应用所需的代码，它会通过针对这些问题和解决方案的特定训练表现得更好。这是因为它会更加熟悉该领域的工作和最佳实践。
- en: Hopefully, training LLMs will become more efficient and therefore cheaper and
    easier.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 希望 LLM 的训练能够变得更加高效，从而降低成本并简化过程。
- en: More security training may benefit the LLM and its users. This can be done with
    security datasets; datasets specifically designed to teach about vulnerabilities
    and best practices.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 更多的安全性训练可能对 LLM 及其用户有所帮助。可以通过安全数据集来实现；这些数据集专门设计用于教授漏洞和最佳实践。
- en: The LLM might be able to be trained with dependencies, the code libraries and
    versions that are needed, and the target hardware and use.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 可能能够通过依赖项、所需的代码库和版本以及目标硬件和使用场景进行训练。
- en: That’s all for continuous learning, new architectures, efficiencies, and specialized
    training; now, it’s time for a chapter summary.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 以上就是关于持续学习、新架构、效率和专业化训练的内容；现在，是时候进行本章总结了。
- en: Summary
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We thought and learned about the limitations of LLMs in this chapter, including
    the lack of understanding, lack of context, high computational requirements, dependency
    on their training data, and security risks. We’ve also touched on some metrics
    for judging LLM performance.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们思考并学习了 LLM 的限制，包括缺乏理解、缺乏上下文、高计算需求、对训练数据的依赖以及安全风险。我们还简要讨论了一些评估 LLM 性能的指标。
- en: We tried to overcome these limitations and looked at a few promising alleys
    for how to create greater LLMs.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试克服这些限制，并探讨了几条有前景的路径，旨在创造更强大的 LLM。
- en: This chapter also covered IP concerns, how LLMs need to be explainable, and
    where to learn more about these issues.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还讨论了 IP 问题、LLM 需要具备可解释性，以及从哪里可以了解更多关于这些问题的信息。
- en: In the next chapter, we will learn about collaboration and knowledge sharing
    in LLM-powered coding because this is how you make real changes to the world,
    help people, and get your name known more.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习关于基于 LLM 的编码中的协作和知识共享，因为这是你改变世界、帮助他人并让自己名声大噪的方式。
- en: Bibliography
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*ACM_DL* : “Investigating Explainability of Generative AI for Code through
    Scenario-based Design,” Jiao Sun, Q. Vera Liao, Michael Muller, Mayank Agarwal,
    Stephanie Houde, Karthik Talamadulupa, and Justin D. Weisz, [https://dl.acm.org/doi/fullHtml/10.1145/3490099.3511119](https://dl.acm.org/doi/fullHtml/10.1145/3490099.3511119)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ACM_DL* : “通过基于场景的设计探索生成 AI 解释性的调查”，Jiao Sun，Q. Vera Liao，Michael Muller，Mayank
    Agarwal，Stephanie Houde，Karthik Talamadulupa 和 Justin D. Weisz，[https://dl.acm.org/doi/fullHtml/10.1145/3490099.3511119](https://dl.acm.org/doi/fullHtml/10.1145/3490099.3511119)'
- en: '*CodeBLEU* : “CodeBLEU: a Method for Automatic Evaluation of Code Synthesis,”
    Shuo Ren, Daya Guo, Shuai Lu, Long Zhou, Shujie Liu, Duyu Tang, Neel Sundaresan,
    Ming Zhou, Ambrosio Blanco, and Shuai Ma, [https://arxiv.org/abs/2009.10297](https://arxiv.org/abs/2009.10297)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*CodeBLEU* : “CodeBLEU：代码合成的自动评估方法”，Shuo Ren，Daya Guo，Shuai Lu，Long Zhou，Shujie
    Liu，Duyu Tang，Neel Sundaresan，Ming Zhou，Ambrosio Blanco 和 Shuai Ma，[https://arxiv.org/abs/2009.10297](https://arxiv.org/abs/2009.10297)'
- en: '*confident_ai* : “LLM Evaluation Metrics: The Ultimate LLM Evaluation Guide,”
    Jeffrey Ip, [https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation](https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*confident_ai* : “LLM 评估指标：终极 LLM 评估指南”，Jeffrey Ip，[https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation](https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation)'
- en: '*Gemini: Gemini,* *Alphabet* : https://gemini.google.com/'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Gemini: Gemini,* *Alphabet* : https://gemini.google.com/'
- en: '**HuggingFace_Optimizing** : “Optimizing your LLM in production,” Patrick von
    Platen, https://huggingface.co/blog/optimize-llm'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HuggingFace_Optimizing** : “在生产中优化你的 LLM”，Patrick von Platen，https://huggingface.co/blog/optimize-llm'
- en: '*Liu_2024* : “Large Language Models for Networking: Workflow, Advances and
    Challenges,” Chang Liu, Xiaohui Xie, Xinggong Zhang, and Yong Cui, [https://arxiv.org/html/2404.12901v1](https://arxiv.org/html/2404.12901v1)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Liu_2024* : “网络中的大型语言模型：工作流程、进展和挑战”，Chang Liu，Xiaohui Xie，Xinggong Zhang 和
    Yong Cui，[https://arxiv.org/html/2404.12901v1](https://arxiv.org/html/2404.12901v1)'
- en: '*Mercier* : “The Enigma of Reason,” Hugo Mercier and Dan Sperber, https://www.hup.harvard.edu/books/9780674237827'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Mercier* : “理性的谜团”，Hugo Mercier 和 Dan Sperber，https://www.hup.harvard.edu/books/9780674237827'
- en: '*Prompt_Drive* : “What Are the Limitations of Large Language Models (LLMs)?”
    Jay, [https://promptdrive.ai/llm-limitations/](https://promptdrive.ai/llm-limitations/)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Prompt_Drive* : “大型语言模型（LLMs）的限制是什么？”，Jay，[https://promptdrive.ai/llm-limitations/](https://promptdrive.ai/llm-limitations/)'
- en: '*QwietAI* : “AppSec 101 – Dependency Management,” QweitAI, https://qwiet.ai/appsec-101-dependency-management/#:~:text=Dependency%20Management%20Tools,-The%20software%20development&text=These%20tools%20are%20the%20backbone,ensure%20compatibility%20across%20the%20board
    .'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*QwietAI* : “AppSec 101 – 依赖管理”，QweitAI，https://qwiet.ai/appsec-101-dependency-management/#:~:text=Dependency%20Management%20Tools,-The%20software%20development&text=These%20tools%20are%20the%20backbone,ensure%20compatibility%20across%20the%20board
    .'
- en: '*Snowflake* : “Achieve Low-Latency and High-Throughput Inference with Meta’s
    Llama 3.1 405B using Snowflake’s Optimized AI Stack,” Aurick Qiao, Reza Yazdani,
    Hao Zhang, Jeff Rasley, Flex Wang, Gabriele Oliaro, Yuxiong He, and Samyam Rajbhandari,
    [https://www.snowflake.com/engineering-blog/optimize-llms-with-llama-snowflake-ai-stack](https://www.snowflake.com/engineering-blog/optimize-llms-with-llama-snowflake-ai-stack)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Snowflake* : “使用 Meta 的 Llama 3.1 405B 和 Snowflake 优化 AI 栈实现低延迟和高吞吐量推理”，Aurick
    Qiao，Reza Yazdani，Hao Zhang，Jeff Rasley，Flex Wang，Gabriele Oliaro，Yuxiong He 和
    Samyam Rajbhandari，[https://www.snowflake.com/engineering-blog/optimize-llms-with-llama-snowflake-ai-stack](https://www.snowflake.com/engineering-blog/optimize-llms-with-llama-snowflake-ai-stack)'
- en: '*Sonatype* : “What are Software Dependencies?” Sonatype, https://www.sonatype.com/resources/articles/what-are-software-dependencies'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Sonatype* : “什么是软件依赖？”，Sonatype，https://www.sonatype.com/resources/articles/what-are-software-dependencies'
- en: '*Stevens* : “What is Semantic Similarity: An Explanation in the Context of
    Retrieval Augmented Generation (RAG),” Ingrid Stevens, [https://ai.gopubby.com/what-is-semantic-similarity-an-explanation-in-the-context-of-retrieval-augmented-generation-rag-78d9f293a93b](https://ai.gopubby.com/what-is-semantic-similarity-an-explanation-in-the-context-of-retrieval-augmented-generation-rag-78d9f293a93b)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Stevens* : “什么是语义相似性：在检索增强生成（RAG）背景下的解释”，Ingrid Stevens，[https://ai.gopubby.com/what-is-semantic-similarity-an-explanation-in-the-context-of-retrieval-augmented-generation-rag-78d9f293a93b](https://ai.gopubby.com/what-is-semantic-similarity-an-explanation-in-the-context-of-retrieval-augmented-generation-rag-78d9f293a93b)'
- en: '*Symbli* : “A Guide to LLM Inference Performance Monitoring,” Kartik Talamadupula'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Symbli* : “LLM推理性能监控指南，”Kartik Talamadupula'
- en: https://symbl.ai/developers/blog/a-guide-to-llm-inference-performance-monitoring
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: https://symbl.ai/developers/blog/a-guide-to-llm-inference-performance-monitoring
- en: '*Wiki_Agent* : “Intelligent Agent,” Wikipedia, https://en.wikipedia.org/wiki/Intelligent_agent'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Wiki_Agent* : “智能体，”维基百科，https://en.wikipedia.org/wiki/Intelligent_agent'
