- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Understanding Convolutional Neural Networks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解卷积神经网络
- en: An MLP is structured to accept one-dimensional data and cannot directly work
    with two-dimensional data or higher-dimensional data without preprocessing. One-dimensional
    data is also called tabular data, which commonly includes categorical data, numerical
    data, and maybe text data. Two-dimensional data, or data with higher dimensions,
    is some form of image data. Image data can be in two-dimensional format when it
    is a grayscale formatted image, in three-dimensional format when it has RGB layers
    that closely represent what humans see, or in more than three dimensions with
    hyperspectral images. Usually, to make MLP work for images, you would have to
    flatten the data and effectively represent the same data in a one-dimensional
    format. Flattening the data might work well in some cases, but throwing away the
    spatial characteristics that define that image removes the potential of capturing
    that relationship to your target. Additionally, flattening the data doesn’t scale
    properly to large images. An important characteristic of image data is that the
    target to be identified can be present in any spatial position of the image. Simple
    MLPs are highly dependent on the position of the data input and won’t be able
    to adapt to the ever-changing positions and orientation of the target in an image.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: MLP（多层感知器）结构设计用于处理一维数据，无法直接处理二维或更高维度的数据，除非进行预处理。一维数据也叫做表格数据，通常包括分类数据、数值数据，甚至可能是文本数据。二维数据或更高维度的数据通常是图像数据。当图像为灰度格式时，它是二维的；当图像有
    RGB 层并且能较好地表现人类视觉时，它是三维的；而多于三维的图像则是高光谱图像。通常，为了让 MLP 能够处理图像，你需要将数据展平，并有效地以一维格式表示相同的数据。展平数据在某些情况下可能是可行的，但舍弃了定义图像的空间特征，丧失了捕捉该关系到目标的潜力。此外，展平数据在处理大图像时并不合适。图像数据的一个重要特征是，目标可以出现在图像的任何空间位置。简单的
    MLP 对数据输入的位置高度依赖，无法适应图像中目标的不断变化的位置和方向。
- en: 'This is where the **convolutional neural network** (**CNN**) layer shines and
    is often the go-to method for experts dealing with image data using machine learning.
    To date, top convolutional architectures always exceed the performance of MLP
    architectures for image datasets. In this chapter, we will cover the following
    topics while focusing on CNNs:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是 **卷积神经网络**（**CNN**）层的强项，通常是处理图像数据时机器学习专家的首选方法。迄今为止，顶尖的卷积架构始终在图像数据集上超过 MLP
    架构的性能。在本章中，我们将涵盖以下内容，并重点讨论 CNN：
- en: Understanding the convolutional neural network layer
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解卷积神经网络层
- en: Understanding the pooling layer
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解池化层
- en: Building a CNN architecture
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建 CNN 架构
- en: Designing a CNN architecture for practical usage
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个用于实际应用的 CNN 架构
- en: Exploring the CNN architecture families
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索 CNN 架构家族
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter includes some practical implementations in the **Python** programming
    language. To complete it, you will need to have a computer with the following
    libraries installed:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包括一些在 **Python** 编程语言中的实际实现。要完成这些任务，你需要一台安装了以下库的计算机：
- en: '`pandas`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas`'
- en: '`matplotlib`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib`'
- en: '`seaborn`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`seaborn`'
- en: '`scikit-learn`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scikit-learn`'
- en: '`numpy`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy`'
- en: '`keras`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keras`'
- en: '`pytorch`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pytorch`'
- en: 'The code files for this chapter are available on GitHub: [https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_2](https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_2).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可在 GitHub 上找到：[https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_2](https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_2)。
- en: Understanding the convolutional neural network layer
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解卷积神经网络层
- en: 'Now, let’s focus on the foundations of the convolutional layer, starting with
    *Figure 3**.1*, which shows the operational process of a convolutional filter.
    A filter is a small matrix of weights that’s used to extract features or patterns
    from an input array. A convolutional filter is a type of filter that slides over
    an image, performing convolution operations to extract features by calculating
    dot products:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们专注于卷积层的基础知识，从 *图 3.1* 开始，它展示了卷积滤波器的操作过程。滤波器是一个小的权重矩阵，用于从输入数组中提取特征或模式。卷积滤波器是一种滑动图像的滤波器，执行卷积操作，通过计算点积来提取特征：
- en: "![Figure 3.1 – Operation of a convolutional filter on an image of a \uFEFF\
    t-shirt from the Fashion MNIST dataset](img/B18187_03_1.jpg)"
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.1 – 卷积滤波器在 Fashion MNIST 数据集中 T 恤图像上的操作](img/B18187_03_1.jpg)'
- en: Figure 3.1 – Operation of a convolutional filter on an image of a t-shirt from
    the Fashion MNIST dataset
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1 – 卷积滤波器在 Fashion MNIST 数据集中 T 恤图像上的操作
- en: Convolutional layers are made out of multiple convolutional filters of the same
    sizes. Convolutional filters are the main pattern detectors in a CNN, where each
    filter will learn to identify multidimensional patterns that exist in an image.
    The patterns can range from low-level patterns such as lines and edges to mid-level
    patterns such as circles or squares and finally to high-level patterns such as
    specific t-shirt types or shoe types depending on the deepness level of the convolutional
    layer in a CNN. In [*Chapter 12*](B18187_12.xhtml#_idTextAnchor184), *Interpreting
    Neural Networks*, we will explore the patterns that are learned and evaluate the
    patterns qualitatively and objectively.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层由多个大小相同的卷积滤波器构成。卷积滤波器是 CNN 中主要的模式检测器，每个滤波器都会学习识别图像中存在的多维模式。这些模式可以从低级模式，如线条和边缘，到中级模式，如圆形或方形，再到高级模式，如特定款式的
    T 恤或鞋子，具体取决于卷积层在 CNN 中的深度。在 [*第12章*](B18187_12.xhtml#_idTextAnchor184)《解读神经网络》中，我们将探讨所学习的模式，并对这些模式进行定性和客观评估。
- en: Convolutional filters can be in multiple dimensions but for plain images, two-dimensional
    convolution filters are more commonly used. Kernels are analogous to filters in
    terms of a CNN layer. These two-dimensional filters have the same number of weights
    as their size and apply a dot product on a part of the input image data with the
    same size to obtain a single value; subsequently, these are added with a bias
    term. By operating on the same operation using the filter in a sliding window
    manner systematically, from top to bottom and left to right with a defined stride,
    the convolutional filter will complete a forward pass and obtain a two-dimensional
    output with smaller dimensions. Here, stride means the number of pixel steps taken
    when sliding the filter systematically from left to right and top to bottom where
    the minimum has to be at least 1 pixel. This operation builds on the fact that
    the target can be present in any spatial position in an image and uses the same
    pattern identification method across the entire image.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积滤波器可以是多维的，但对于普通图像来说，二维卷积滤波器更常用。核在 CNN 层中类似于滤波器。这些二维滤波器的权重数量与其大小相同，并在与输入图像数据相同大小的部分上进行点积操作，以得到一个单一的值；随后，这些值会加上一个偏置项。通过以滑动窗口的方式，按照定义的步幅，从上到下、从左到右系统地对同一操作进行处理，卷积滤波器将完成一次前向传播，得到一个维度较小的二维输出。在这里，步幅指的是滑动滤波器时每次移动的像素步数，最小步幅至少为
    1 像素。此操作基于目标可能出现在图像中的任意空间位置，并在整个图像中使用相同的模式识别方法。
- en: '*Figure 3**.1* shows a two-dimensional convolutional filter with the size of
    5x5 pixels, where there are 25 weight components and one bias component that could
    be learned, and the input image of a t-shirt, which has a size of 28x28 pixels.
    The filter size is something that can be configured to other values that typically
    range from 1 to 7 and is commonly a square but can be set to be irregular rectangular
    shapes. The typical filter size values might seem too small of a **receptive field**
    to identify high-level features that are capable of predicting a shirt in this
    picture, but when multiple filters are applied one after another in a non-cyclical
    manner, the filters at the end of the operation have the receptive field of a
    larger part of the image. Receptive field refers to the region of the input space
    that a convolutional filter can “see” or respond to. It determines the spatial
    extent of the input that influences a particular output unit. To capture low-level
    patterns, the filter must have a small receptive field, and to capture high-level
    patterns, the filter must have a large receptive field. *Figure 3**.2* depicts
    this concept for three filters applied one after another:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3.1* 显示了一个二维卷积滤波器，大小为5x5像素，其中包含25个可学习的权重组件和一个偏置组件，以及一个28x28像素大小的T恤输入图像。滤波器的大小是可以配置为其他值的，通常范围在1到7之间，通常是正方形，但也可以设置为不规则的矩形形状。典型的滤波器大小值可能看起来太小，无法识别图像中预测T恤的高阶特征，但当多个滤波器按非周期性顺序一个接一个地应用时，操作结束时的滤波器会有更大部分图像的感受野。感受野是指卷积滤波器可以“看到”或响应的输入空间的区域。它决定了影响特定输出单元的输入的空间范围。为了捕捉低级特征，滤波器必须具有较小的感受野，而为了捕捉高级特征，滤波器必须具有较大的感受野。*图
    3.2* 描述了三个滤波器按顺序应用时的这一概念：'
- en: '![Figure 3.2 – The second convolutional filter has a receptive field size of
    3x3 of the input data, even when it has only a 2x2 convolutional filter size](img/B18187_03_2.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.2 – 第二个卷积滤波器的感受野大小为3x3，尽管其卷积滤波器大小仅为2x2](img/B18187_03_2.jpg)'
- en: Figure 3.2 – The second convolutional filter has a receptive field size of 3x3
    of the input data, even when it has only a 2x2 convolutional filter size
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 – 第二个卷积滤波器的感受野大小为3x3，尽管其卷积滤波器大小仅为2x2
- en: 'Now, the sliding window from left to right and top to bottom is just a good
    way to visualize the process. However, in reality, this process can be done in
    parallel in one go to take advantage of GPU parallel processing. *Figure 3**.3*
    shows all the window positions of a convolutional filter with a 4x4-pixel dimension
    with a stride of 4 applied on the same 28x28 t-shirt image. This would result
    in a 7x7 data output size:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，从左到右、从上到下的滑动窗口只是一个很好地可视化过程的方法。然而，实际上，这个过程可以一次性并行处理，以利用GPU的并行处理能力。*图 3.3*
    显示了一个4x4像素维度的卷积滤波器，步长为4，在同一28x28 T恤图像上应用的所有窗口位置。这将导致7x7的数据输出大小：
- en: '![Figure 3.3 – All window positions using a 4x4 convolutional filter on a 28x28
    image with a stride of 4 pixels in both dimensions](img/B18187_03_3.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.3 – 在28x28图像上，使用4x4卷积滤波器，步长为4像素，进行所有窗口位置的操作](img/B18187_03_3.jpg)'
- en: Figure 3.3 – All window positions using a 4x4 convolutional filter on a 28x28
    image with a stride of 4 pixels in both dimensions
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3 – 在28x28图像上，使用4x4卷积滤波器，步长为4像素，进行所有窗口位置的操作
- en: 'Consider a CNN layer with 16 filters with a size of 5x5 pixels with a stride
    of 1 pixel. Running a forward pass of the t-shirt image with this layer configuration
    will result in a total of 16x26x26 (depth x width x height) pixels of output.
    In the case where the image is an RGB image with three channels colored red, green,
    and blue, since the convolutional filters are two-dimensional, the same filter
    would be applied similarly to each of the three channels using a standard convolutional
    layer. The three-dimensional outputs from the filters, applied separately on the
    three channels, will then be added up. The number of convolutional filters will
    be the output data channel size and will serve as the input channel size for the
    subsequent convolutional layers. *Figure 3**.4* depicts this channel-wise addition
    process for a 3x3 output from a convolutional filter. Note that the bias is only
    added once per filter across the channels and not by channel:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个CNN层，包含16个5x5像素的滤波器，步长为1像素。使用这种层配置对T恤图像进行前向传递时，输出的总像素数为16x26x26（深度 x 宽度
    x 高度）。在图像为RGB图像且有红、绿、蓝三个通道的情况下，由于卷积滤波器是二维的，相同的滤波器将以类似方式应用于三个通道，每个通道使用标准卷积层处理。对三个通道分别应用的滤波器产生的三维输出将被加总起来。卷积滤波器的数量将是输出数据通道的大小，并且将作为后续卷积层的输入通道大小。*图3.4*展示了卷积滤波器的3x3输出在通道方向上的加和过程。请注意，偏置仅在每个滤波器跨越通道时添加一次，而不是按通道添加：
- en: '![Figure 3.4 – Aggregation of a multichannel 3x3 output from a convolution
    filter](img/B18187_03_4.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图3.4 – 多通道3x3卷积滤波器输出的聚合](img/B18187_03_4.jpg)'
- en: Figure 3.4 – Aggregation of a multichannel 3x3 output from a convolution filter
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 – 多通道3x3卷积滤波器输出的聚合
- en: 'In the preceding figure, **Conv** is short for *convolutional layer* and will
    be a convention that will be used in the rest of this chapter to simplify figures.
    Since it is beneficial to be aware of the size of your neural network to ensure
    you have the computational resources to hold and process the network, let’s also
    compute the number of parameters that will be held by this convolutional layer.
    The number of parameters can be computed as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，**Conv** 是 *卷积层* 的缩写，并将在本章的其余部分作为简化图示的约定使用。由于了解神经网络的大小对于确保拥有足够的计算资源以容纳和处理网络是有益的，接下来我们也将计算该卷积层将包含的参数数量。参数的数量可以通过以下方式计算：
- en: number of input channels x number of filters x ((width of filter x height of
    filter) + 1)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 输入通道数 x 过滤器数量 x （（过滤器宽度 x 过滤器高度） + 1）
- en: By putting the respective numbers into the equation, you will obtain 416 parameters.
    If these weights are stored as a **floating-point 32** (**fp32**) format, in bytes,
    this would mean 416x32 bits/8=1,664 bytes. With an output data size of 16x26x26,
    the data size in spatial dimension is decreasing at a very slow rate and since
    the end goal will be to reduce these values to the size of the target data, we
    need something to reduce the size of the data. This is where another layer, called
    the **pooling layer**, comes into play.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 将相应的数字代入公式，你将得到416个参数。如果这些权重以**浮动点32**（**fp32**）格式存储，则以字节为单位，意味着416x32位/8=1,664字节。由于输出数据的大小为16x26x26，在空间维度上的数据大小以非常缓慢的速度减少，且由于最终目标是将这些值减少到目标数据的大小，因此我们需要一些方法来减小数据的尺寸。这里引入了另一层，叫做**池化层**，来实现这一目标。
- en: Understanding the pooling layer
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解池化层
- en: With just a forward pass from a CNN layer of an image, the size of the two-dimensional
    output data is likely reduced but is still a substantial size. To reduce the size
    of the data further, a layer type called a pooling layer is used to aggregate
    and consolidate the values strategically while still maintaining useful information.
    Think of this operation as an image-resizing method while maintaining as much
    information as possible. This layer has no parameters for learning and is mainly
    added to simply and meaningfully reduce the output data. The pooling layer works
    by applying a similar sliding window filter process with similar configurations
    as the convolutional layers but instead of applying a dot product and adding a
    bias, a type of aggregation is done. The aggregation function can be either maximum
    aggregation, minimum aggregation, or average aggregation. The layers that apply
    these aggregations are called max pooling, min pooling, and average pooling, respectively.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 仅通过从图像的CNN层进行前向传播，二维输出数据的大小可能会减少，但仍然是一个相当大的尺寸。为了进一步减少数据的大小，使用了一种叫做池化层的层类型来战略性地聚合和整合值，同时保持有用的信息。可以将这个操作看作是一种图像调整大小的方法，同时尽可能保持更多的信息。该层没有学习的参数，主要是为了简化且有意义地减少输出数据。池化层通过应用类似滑动窗口滤波器的过程来工作，配置与卷积层相似，但它不是应用点积和加偏置，而是进行一种聚合。聚合函数可以是最大聚合、最小聚合或平均聚合。应用这些聚合的层分别称为最大池化、最小池化和平均池化。
- en: Consider an average pooling layer with a filter size of 4 and a stride of 2
    applied after the first CNN layer. A forward pass of the 16x26x26 output will
    result in a data size of 16x12x12\. That reduces the size considerably!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑在第一个CNN层后应用一个滤波器大小为4、步幅为2的平均池化层。经过一次前向传播，16x26x26的输出将变成16x12x12的数据大小。这大大减少了数据的尺寸！
- en: Another type of pooling layer applies the aggregation function globally. This
    means that the entire two-dimensional width and height component of the data will
    be aggregated into a single value. This variation of the pooling layer is commonly
    known as the global pooling layer. This layer is applied to completely break down
    the data into a one-dimensional structure so that it can be compatible with one-dimensional
    targets. This layer is directly available in the `keras` library but only available
    in `pytorch` indirectly through setting the pooling filter size to the same as
    the size of the input feature map.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种类型的池化层应用全局聚合函数。这意味着数据的整个二维宽度和高度组件将被聚合成一个单一的值。这种池化层的变种通常被称为全局池化层。该层应用于将数据完全转化为一维结构，以便它可以与一维目标兼容。该层在`keras`库中直接可用，但在`pytorch`中则需要通过将池化滤波器的大小设置为与输入特征图的大小相同间接实现。
- en: Building a CNN architecture
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建CNN架构
- en: CNN architectures are commonly made by stacking multiple conceptual logical
    blocks of layers one after another. These logical blocks are all structured the
    same way, with the same type of layer and layer connections, but they can be different
    in terms of their parameter configurations, such as the size of the filters, the
    stride, the type of padding used, and the amount of padding used. The simplest
    logical convolutional block is a convolutional layer, pooling layer, and activation
    function, in that order. **Padding** is a term that’s used to refer to any extra
    pixels that are added around the input image to preserve its spatial dimensions
    after convolution. Logical blocks are a way for you to describe and reference
    the architecture simply and efficiently. They also allow you to build CNN architectures
    in a depth-wise scalable way without the need to create and set the settings of
    each layer one by one. Depth is the same as deepness and refers to the number
    of neural network layers.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: CNN架构通常是通过一个个堆叠的概念逻辑块构建的。这些逻辑块的结构方式相同，具有相同类型的层和层连接，但在参数配置上可能有所不同，比如滤波器的大小、步幅、所使用的填充类型以及填充的数量。最简单的逻辑卷积块是卷积层、池化层和激活函数，按此顺序排列。**填充**是指在卷积操作后，为了保持输入图像的空间维度而在图像周围添加的额外像素。逻辑块是用来简洁而高效地描述和引用架构的一种方式。它们还使你能够以深度可扩展的方式构建CNN架构，而无需逐一创建和设置每个层的参数。深度与深度度相同，指的是神经网络层的数量。
- en: 'The parameters can be designed depending on whether the goal is to gradually
    scale down the feature maps or to scale up the feature maps. For the case of one-dimensional
    targets, the goal is likely to slowly scale down the features into one-dimensional
    features so that the features can be passed into fully connected layers. These
    fully connected layers can then further map the (still large) dimensions to the
    dimensions that are suitable for the targets. You can see a simple design of such
    an architecture in *Figure 3**.5*:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 可以根据目标是逐渐缩小特征图还是扩大特征图来设计参数。对于一维目标的情况，目标可能是将特征逐渐缩小为一维特征，以便将特征传递给全连接层。然后，这些全连接层可以进一步将（仍然很大的）维度映射到适合目标的维度。你可以在*图
    3.5*中看到这样的架构的简单设计：
- en: '![Figure 3.5 – A simple CNN architecture from scratch while following the logical
    block analogy](img/B18187_03_5.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.5 – 从零开始构建的简单 CNN 架构，同时遵循逻辑块类比](img/B18187_03_5.jpg)'
- en: Figure 3.5 – A simple CNN architecture from scratch while following the logical
    block analogy
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5 – 从零开始构建的简单 CNN 架构，同时遵循逻辑块类比。
- en: 'In the code for `pytorch`, this example would look like this:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `pytorch` 的代码中，这个例子看起来是这样的：
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Again, the backpropagation of a CNN architecture will be handled automatically
    by the deep learning libraries.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，CNN 架构的反向传播将由深度学习库自动处理。
- en: The architecture we built was based on the basic classification problem type,
    which justifies the need to have a fully connected network at the end of the network;
    this is commonly known as the head. The set of logical blocks with convolutional
    layers that were used is called the backbone of the network. The head of the network
    can be switched out with other structures, depending on the problem type, but
    the backbone can be completely adapted into most architectures for any problem
    type, such as object detection, image generation, image captioning, or image recognition
    by representation learning. Some of these problem types will be discussed in [*Chapter
    8*](B18187_08.xhtml#_idTextAnchor125), *Exploring Supervised* *Deep Learning*.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建的架构是基于基本的分类问题类型，这也证明了在网络末尾需要一个全连接网络的必要性；这通常被称为“头”。使用的卷积层逻辑块集被称为网络的“主干”。网络的头部可以根据问题类型替换为其他结构，但主干可以完全适配到大多数架构中，适用于任何问题类型，如目标检测、图像生成、图像描述或通过表征学习的图像识别。关于这些问题类型的讨论会在[*第
    8 章*](B18187_08.xhtml#_idTextAnchor125)，*探索有监督深度学习*中进一步展开。
- en: Now that we have successfully made a simple CNN manually, we have grounded and
    synced our theories toward the core algorithm of convolutional networks and will
    be ready to have more advanced CNN backbone architecture designs at our fingertips.
    But before that, this begs the question, how do we design a CNN for our use case?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经成功手动创建了一个简单的 CNN，我们的理论已经与卷积网络的核心算法相契合并同步，接下来我们将能够轻松设计更先进的 CNN 主干架构。但在此之前，这就引出了一个问题：我们如何为我们的使用场景设计
    CNN？
- en: Designing a CNN architecture for practical usage
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为实际使用设计 CNN 架构
- en: 'For real-world use cases, CNNs should not be designed similarly to how an MLP
    is designed. Practical usage means that the goal is not to research a new innovative
    architecture for an unexplored problem type. Many advancements have been made
    today based on CNNs. Advancements usually come in one of two flavors:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实际的使用场景，CNN 不应像 MLP 那样设计。实际使用意味着目标不是为未探索的问题类型研究一个新的创新架构。今天，基于 CNN 已经取得了许多进展。这些进展通常有两种形式：
- en: It sets a new baseline that completely redesigned the way CNN architectures
    are made
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它设定了一个全新的基准，彻底重新设计了 CNN 架构的构建方式。
- en: It’s built on top of existing baseline CNN architectures while complementing
    and improving the performance of the baseline architecture
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是建立在现有基准 CNN 架构的基础上，同时补充和提升了基准架构的性能。
- en: The key difference between the ideal design approach of a CNN compared to an
    MLP is that the structures of published CNN architectures should be used instead
    of designing the architecture from scratch. The structures of CNN architectures
    define the type of layers and the way the different types of layers connect; they
    are usually implemented using logical blocks. Additionally, the uniqueness of
    a certain structure defines the family of CNN architecture. A new CNN research
    advancement usually comes in different size configurations so that architectures
    of suitable sizes can be chosen based on either the compute resource limitations,
    runtime requirements, or the dataset and problem complexity. Similar to the design
    of MLP, if resources and runtime are not a limitation, after choosing a CNN architecture
    structure, start with a reasonably small-sized CNN based on the complexity of
    the problem and the dataset’s size. You can gradually test bigger CNNs to see
    if the performance improves when you increase the size, or vice versa if the performance
    decreases.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 与多层感知机（MLP）的理想设计方法相比，卷积神经网络（CNN）的关键区别在于，应该使用已发布的CNN架构结构，而不是从零开始设计架构。CNN架构的结构定义了层的类型以及不同类型的层如何连接；它们通常通过逻辑块实现。此外，特定结构的独特性定义了CNN架构的家族。新的CNN研究进展通常会以不同的尺寸配置出现，以便根据计算资源限制、运行时要求或数据集和问题复杂性选择合适的架构尺寸。与MLP设计类似，如果资源和运行时不是限制条件，在选择了CNN架构结构后，应该根据问题的复杂性和数据集的大小，从一个合理小的CNN开始。你可以逐渐测试更大的CNN，看看当增加大小时，性能是否有所提升，反之如果性能下降。
- en: Different CNN architecture structures or architecture families are usually meant
    to capture different inherent architectural issues of the network. Some architectural
    families are designed in a way that they leverage better hardware resources, without
    which it wouldn’t have been even possible to execute the architecture. A good
    practice to achieve good performance is to diversify the type of architectural
    structures you are using in the initial stage. Pick size variants of architectural
    structures with similar sizes in terms of the floating-point operation per second
    and run your experiments to obtain performance scores, ideally with a small size
    to maximize the efficiency of the exploration. Instead of the number of parameters
    of the model, it is more relevant to consider the floating-point operation per
    second as an indicator of the complexity of the model; parameter count doesn’t
    consider the actual runtime of the model, which could benefit from parallelization.
    Once you’ve obtained these numbers, pick the top model families and try bigger
    size variants to benchmark with to find the best model variant for your use case.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的CNN架构结构或架构家族通常用于捕捉网络固有的不同架构问题。有些架构家族的设计方式是利用了更好的硬件资源，否则就无法执行这些架构。为了获得良好的性能，一个好的做法是在初始阶段多样化你使用的架构结构类型。选择具有相似浮点运算每秒（FLOP）的架构结构尺寸变体，并运行实验以获得性能得分，理想情况下，选择较小的尺寸以最大化探索效率。与模型的参数数量相比，考虑每秒浮点运算作为模型复杂度的指标更为相关；因为参数数量没有考虑模型的实际运行时，而模型的运行时可能会受益于并行化。一旦获得了这些数字，就选择顶尖的模型家族，并尝试更大的尺寸变体进行基准测试，以找到最适合你使用案例的模型变体。
- en: Most research improvements on CNNs are based on a simple baseline architecture.
    This means that all the other individual improvements that are made on the same
    baseline architecture are not benchmarked together. Testing these improvements
    together can often be complementary but sometimes, it can be detrimental to the
    metric performance of the model. Iteratively benchmarking the different configurations
    will likely be the most systematic and grounded way to obtain a satisfactory performance
    improvement on your model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数CNN的研究改进都基于一个简单的基线架构。这意味着对同一个基线架构所做的所有其他改进并没有一起进行基准测试。将这些改进一起测试往往是互补的，但有时也可能对模型的度量性能产生不利影响。迭代地基准测试不同的配置，可能是获得令人满意的性能提升的最系统、最扎实的方法。
- en: How do researchers grade their improvements? To design a CNN architecture for
    practical usage, knowing how to evaluate your architecture will help you slowly
    work toward an acceptable metric performance. In [*Chapter 10*](B18187_10.xhtml#_idTextAnchor161),
    *Exploring Model Evaluation Methods*, we will discuss the strategies for evaluation
    more extensively. One of the main evaluation methods for improvements that’s used
    for CNN improvements is the top-1 predicted accuracy performance on a massive
    publicly available image dataset called `ImageNet`, which consists of millions
    of images with many classes. `ImageNet` is considered to be a highly complex problem-type
    use case, where each class has an infinite amount of variations possible in the
    wild, from indoors to outdoors and from real to synthetic data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员如何评估他们的改进呢？为了设计出适用于实际场景的CNN架构，了解如何评估架构将帮助你逐步朝着可接受的度量性能目标前进。在[*第10章*](B18187_10.xhtml#_idTextAnchor161)，《探索模型评估方法》中，我们将更详细地讨论评估策略。用于评估CNN改进的主要方法之一是通过在名为`ImageNet`的公开图像数据集上的top-1预测准确率，该数据集包含数百万张图像，并有多个类别。`ImageNet`被认为是一个高度复杂的案例，每个类别都有无限种可能的变体，从室内到室外，从真实数据到合成数据都有涵盖。
- en: So, how do we consider whether improvements are valuable? Improvements are made
    to either improve performance in the top-1 accuracy, based on the `ImageNet` dataset,
    to improve the efficiency of running a forward pass of the model, or to specifically
    improve the training time of the network.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何判断改进是否具有价值呢？改进的目标通常是提高基于`ImageNet`数据集的top-1准确率，提升模型前向传递的效率，或是专门优化网络的训练时间。
- en: Ranking architectures by their top-1 accuracy metric performance improvements
    on `ImageNet` alone, however, is a biased evaluation as, more often than not,
    the absolute ranking of models differs when applying the same architectures on
    a separate image dataset. Using it as a starting point to choose ready-made architectures
    is wise, but make sure you evaluate a few of the top-performing `ImageNet` architectures
    to figure out which works the best. Furthermore, while `ImageNet` was curated
    with manual effort, involving querying search engines and passing candidate images
    through a validation step on Amazon Mechanical Turk, it still contains some label
    noise that can obfuscate the meaning behind the metric’s performance.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅仅按照`ImageNet`上的top-1准确率性能改进对架构进行排名，这种评估方式是有偏的，因为在大多数情况下，模型的绝对排名在应用相同架构到不同的图像数据集时会有所不同。将其作为选择现成架构的起点是明智的，但一定要确保评估一些`ImageNet`上表现最佳的架构，以找出最适合的方案。此外，虽然`ImageNet`是通过手动努力构建的，包括查询搜索引擎并将候选图像通过Amazon
    Mechanical Turk进行验证，但它仍然包含一些标签噪声，这可能会混淆度量性能背后的含义。
- en: As for the improvement direction of increasing the efficiency of running a forward
    pass of the model, this is usually done either by reducing the number of parameters
    of the architecture, breaking down a compute-intensive logical component into
    multiple components that reduces the amount of operations, or switching out layers
    for layers that have higher parallelism potential. The improvements that are made
    in this direction either maintain or improve the metric performance score on the
    validation dataset of `ImageNet`. This line of improvement is a main focus for
    the family of CNN architectures that have been built to run in low-resource edge
    devices. We will dive into this later.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 至于提高模型前向传递效率的改进方向，通常是通过减少架构的参数数量、将计算密集型的逻辑组件分解成多个组件来减少操作量，或者用具有更高并行性潜力的层来替换原有层。在这一方向上进行的改进，通常会保持或提高在`ImageNet`验证数据集上的度量性能得分。这个方向的改进是针对一系列设计用于低资源边缘设备上运行的卷积神经网络（CNN）架构的主要关注点，我们稍后会深入探讨。
- en: An efficient way to explore different CNN architecture families in your use
    case to achieve better metric performance is to pick model families that have
    a publicly available implementation complete with pre-trained weights trained
    on `ImageNet`. Initializing your architecture using pre-trained weights presents
    a bunch of benefits that include faster training, less overfitting, and increased
    generalization, even when the dataset that was used to pre-train the weights is
    part of a different problem subset. This process is called transfer learning and
    we will learn about it in more detail in [*Chapter 8*](B18187_08.xhtml#_idTextAnchor125),
    *Exploring Supervised Deep Learning*, and [*Chapter 9*](B18187_09.xhtml#_idTextAnchor149),
    *Exploring Unsupervised* *Deep Learning*.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 探索不同CNN架构家族以获得更好的指标性能的一个高效方法是，选择那些有公开实现的模型家族，且这些实现包括了在`ImageNet`上训练的预训练权重。通过使用预训练权重初始化你的架构，可以带来一系列好处，包括更快的训练、更少的过拟合，以及即使使用的数据集与预训练权重的训练数据集属于不同的问题子集，依然能提高泛化能力。这个过程叫做迁移学习，我们将在[*第8章*](B18187_08.xhtml#_idTextAnchor125)《探索监督式深度学习》和[*第9章*](B18187_09.xhtml#_idTextAnchor149)《探索无监督深度学习》中详细学习。
- en: Exploring the CNN architecture families
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索CNN架构家族
- en: Now, instead of going through the history of CNN through the years, let’s look
    at a list of the different handpicked model architecture families. These architecture
    families are selectively chosen to be sufficiently different and diverse from
    each other. One thing to note is that neural networks are advancing at an astounding
    pace. With that in mind, the architecture families that will be introduced here
    are ensured to be relevant today. Additionally, only the most important information
    you need to know about the architecture family will be presented, simplifying
    the many pages of research papers in concise but sufficient detail.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们不再回顾CNN多年来的发展历史，而是来看一下经过精心挑选的不同模型架构家族。这些架构家族的选择是基于它们之间有足够的差异和多样性。需要注意的一点是，神经网络正在以惊人的速度进步。考虑到这一点，本文将介绍的架构家族是确保今天依然相关的。此外，本文将只呈现架构家族中最重要的信息，将研究论文中的大量内容简化成简洁而充分的细节。
- en: Another thing to note before diving into this topic is that the metric performance
    on a dataset will often be the main comparison method among different architectures,
    so be aware that the metric performance of a model is achieved by the collective
    contribution of the training method and the architecture. The training method
    includes details not specifically related to the architecture of the model, such
    as the loss used, data augmentation strategy, and data resolution. These topics
    will be covered in [*Chapter 8*](B18187_08.xhtml#_idTextAnchor125), *Exploring
    Supervised Deep Learning*. The architecture families we’ll introduce here are
    **ResNet**, **DenseNet**, **MobileNet**, **EfficientNet**, **ShuffleNet**, and
    **MicroNet**.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨这个话题之前，另一个需要注意的事情是，数据集上的指标性能通常是不同架构之间的主要比较方法，因此请注意，模型的指标性能是通过训练方法和架构的集体贡献来实现的。训练方法包括与模型架构无直接关系的细节，如所使用的损失函数、数据增强策略和数据分辨率。这些主题将在[*第8章*](B18187_08.xhtml#_idTextAnchor125)《探索监督式深度学习》中讲解。我们将在这里介绍的架构家族有**ResNet**、**DenseNet**、**MobileNet**、**EfficientNet**、**ShuffleNet**和**MicroNet**。
- en: Understanding the ResNet model family
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解ResNet模型家族
- en: The ResNet architecture, from 2015, was made based on the pretext that deep
    networks are hard to train and aimed to change that. The vanishing gradient is
    a widely known problem that neural networks face, where the information from the
    data diminishes the deeper the network is. Plain deep CNN architectures, however,
    were identified to *not* suffer from vanishing gradients, with proof from verifying
    gradient information. The key cause of vanishing gradients is when we use too
    many activation functions that squish the data into very small value ranges. An
    example of this is the sigmoid function, which maps data from 0 to 1\. So, when
    in doubt, use ReLU in your architecture!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: ResNet架构，始于2015年，是基于深度网络训练困难的前提提出的，并旨在解决这一问题。梯度消失是神经网络面临的一个广泛已知的问题，即网络越深，来自数据的信息越少。然而，普通的深度CNN架构并未出现梯度消失的问题，这通过验证梯度信息得到了证明。梯度消失的主要原因是我们使用了过多的激活函数，将数据压缩到非常小的值范围内。例如，sigmoid函数就是一个典型，它将数据映射从0到1。所以，如果不确定，建议在架构中使用ReLU！
- en: 'The *Res* part of ResNet is named after the term **residuals**. The idea was
    that learning from residuals is much easier than learning from unmodified feature
    maps. Residuals are achieved by adding skip connections from the earlier layers
    to later layers. In layman’s terms, that means adding (not concatenating) feature
    maps from earlier parts of the network to feature maps of later parts of the network.
    The result of this addition creates the residuals that will be learned by subsequent
    convolutional layers, which again apply more skip connections and create more
    residuals. Residuals can be easily applied to any CNN architecture with different
    configurations and can be considered an improvement on top of older baseline architectures.
    However, the authors also presented multiple variations of an architecture that
    utilized skip connections with a different number of convolutional layers, including
    ResNet-18, ResNet-34, ResNet-50, ResNet-101, and ResNet-152\. The ResNet architecture
    family serves as a boilerplate for easy usage of residual networks and eventually
    led to it becoming the most popular baseline for research on new advancements.
    The actual architecture designs are not presented here formally as memorizing
    those designs won’t have any impact on your grasp of CNN knowledge. Instead, *Figure
    3**.6* shows the residual computation of a single logical block:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ResNet 的 *Res* 部分是以**残差**（residuals）一词命名的。其理念是，从残差中学习比从未经修改的特征图中学习要容易得多。残差是通过添加来自早期层到后期层的跳跃连接（skip
    connections）来实现的。通俗来说，这意味着将早期部分的特征图（而非拼接）添加到网络后期部分的特征图中。这种加法的结果创建了将由后续卷积层学习的残差，后续卷积层再次应用更多跳跃连接并创建更多残差。残差可以轻松地应用于任何具有不同配置的
    CNN 架构，并且可以被视为对较旧基线架构的改进。然而，作者还提出了多种利用不同数量卷积层的跳跃连接的架构变体，包括 ResNet-18、ResNet-34、ResNet-50、ResNet-101
    和 ResNet-152。ResNet 架构家族为残差网络的简单使用提供了一个模板，并最终使其成为研究新进展的最流行基线。实际的架构设计在这里没有正式展示，因为记住这些设计对于掌握
    CNN 知识没有任何影响。相反，*图 3.6* 显示了单个逻辑块的残差计算：
- en: '![Figure 3.6 – Example of the actual residual connection method in the ResNet
    model family](img/B18187_03_6.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.6 – ResNet 模型家族中实际残差连接方法的示例](img/B18187_03_6.jpg)'
- en: Figure 3.6 – Example of the actual residual connection method in the ResNet
    model family
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6 – ResNet 模型家族中实际残差连接方法的示例
- en: 'To summarize the entire baseline ResNet size variants, the following table
    shows a summary configuration of all the different size variants:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为总结整个基线 ResNet 尺寸变体，以下表格显示了所有不同尺寸变体的配置摘要：
- en: '![Figure 3.7 – Base ResNet different size variants](img/B18187_03_7.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.7 – 基础 ResNet 不同尺寸变体](img/B18187_03_7.jpg)'
- en: Figure 3.7 – Base ResNet different size variants
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7 – 基础 ResNet 不同尺寸变体
- en: The brackets denoted in the table are meant to signify the set of serial convolutional
    layers that are defined as the logical blocks. ResNet has also gone the extra
    mile to group multiple base logical blocks to a higher-level category they call
    “layer name.” The layer name has the same number of groups across different size
    variants. Logical blocks and higher-level grouping methods are just a way for
    you to describe and reference the complicated architecture simply and efficiently.
    The first two numbers, which with multiplication in between in the logical block,
    define the convolution filter size; the number that comes after it with a comma
    defines the number of filters.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 表格中标注的括号表示定义为逻辑块的串行卷积层的集合。ResNet 还额外做了一个改进，将多个基础逻辑块归为一个更高层次的类别，称为“层名称”（layer
    name）。不同尺寸变体中，层名称的分组数目是相同的。逻辑块和更高层次的分组方法仅仅是为了让你能够简单有效地描述和引用复杂的架构。逻辑块中的前两个数字，通过乘法连接，定义了卷积滤波器的大小；紧随其后的数字和逗号定义了滤波器的数量。
- en: 'Skip connections were found to smoothen the loss landscape of any neural network,
    making the learning process much easier and stabler. This allows for the neural
    network to converge to the optimum more easily. *Figure 3**.8* shows how the loss
    landscape for a neural network without skip connections has an uneven terrain
    with many hills and valleys on the left. It becomes a smooth terrain with an obvious
    single valley when skip connections are added using a variant of ResNet:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 研究发现，跳跃连接可以使任何神经网络的损失景观更加平滑，从而使学习过程变得更加容易和稳定。这使得神经网络更容易收敛到最优解。*图 3**.8* 显示了没有跳跃连接的神经网络的损失景观，左侧地形起伏不平，充满了许多山丘和山谷；而右侧则是通过使用
    ResNet 的变种添加跳跃连接后，地形变得平滑，且明显形成一个单一的山谷：
- en: '![Figure 3.8 – Loss landscape with no skip connections on the left and with
    skip connections on the right](img/B18187_03_8.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.8 – 左侧为没有跳跃连接的损失景观，右侧为带有跳跃连接的损失景观](img/B18187_03_8.jpg)'
- en: Figure 3.8 – Loss landscape with no skip connections on the left and with skip
    connections on the right
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.8 – 左侧为没有跳跃连接的损失景观，右侧为带有跳跃连接的损失景观
- en: One notable piece of information you can derive from the table is that, starting
    from ResNet-50 onwards, the architecture utilizes 1x1 convolutional filters. As
    this filter operates exclusively with a single-dimensional filter weight across
    the channel dimension, the operation is equivalent to applying a fully connected
    layer in a windowing fashion in the channel dimension. Since the fully connected
    layer is a network itself, along with the convolutional network, this operation
    is often called a **network in a network**. Next, let’s explore the different
    improvements with the ResNet architecture as a base.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 从表格中可以得出的一个显著信息是，从 ResNet-50 开始，该架构采用了 1x1 卷积滤波器。由于该滤波器仅在通道维度上操作一个单维滤波器权重，因此该操作相当于在通道维度上以窗口方式应用全连接层。由于全连接层本身就是一个网络，再加上卷积网络，这种操作通常被称为
    **网络中的网络**。接下来，我们将探讨以 ResNet 架构为基础的不同改进。
- en: Improving ResNets
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 改进 ResNets
- en: 'As mentioned previously, ResNet is considered a model family and contains many
    different varieties, not just by size but with different architectural improvements.
    Any CNN architecture that is based on the ResNet belongs to this model family.
    Here, we have mentioned some of the few notable architectural advancements and
    provided descriptions of their main advancements based on ResNet; they are ordered
    by the year they were made:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，ResNet 被认为是一个模型家族，包含了许多不同的变种，不仅在规模上有所不同，还具有不同的架构改进。任何基于 ResNet 的 CNN 架构都属于这个模型家族。这里，我们提到了一些值得注意的架构进展，并根据
    ResNet 提供了它们的主要改进描述；它们按年份排序：
- en: '`ImageNet` compared to ResNet variants, even when the number of parameters
    is the same and also in general.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ImageNet` 与 ResNet 各变种相比，即使在参数数量相同的情况下，仍有明显差异，通常也有优势。'
- en: '**Squeeze-and-Excitation Networks** (**SE-ResNet**) (2017): Since two-dimensional
    convolutions don’t consider the inter-channel relationships and only consider
    the local and spatial (width and height) information of the feature maps, a method
    to leverage the channel relationships was made that includes a squeeze block and
    an excitation block. This is a method that can be repeatedly applied to many parts
    of an existing CNN architecture. *Figure 3**.9* shows the structure of this method,
    where a global average pooling is applied in the width and height dimensions and,
    subsequently, two fully connected networks are applied to scale down and scale
    up the features back to the same size to allow channel information to be combined:'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**挤压与激励网络** (**SE-ResNet**)（2017年）：由于二维卷积操作没有考虑通道之间的关系，仅仅考虑特征图的局部和空间（宽度和高度）信息，因此提出了一种利用通道关系的方法，该方法包括挤压模块和激励模块。这是一种可以重复应用于现有CNN架构多个部分的方法。*图
    3**.9* 显示了该方法的结构，其中在宽度和高度维度上应用了全局平均池化，随后使用两个全连接网络进行特征缩放和恢复至相同的尺寸，以便将通道信息进行组合：'
- en: '![Figure 3.9 – Squeeze and excitation structure](img/B18187_03_9.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.9 – 挤压与激励结构](img/B18187_03_9.jpg)'
- en: Figure 3.9 – Squeeze and excitation structure
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.9 – 挤压与激励结构
- en: The scaling part of the structure is where the values are multiplied together.
    When combined with ResNet, the architecture is called SE-ResNet.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 该结构的缩放部分是值的相乘。当与 ResNet 结合使用时，架构被称为 SE-ResNet。
- en: '**ResNet-D** (2019): This advancement made simple architecture parameter tweaks
    to improve metric performance while maintaining the number of parameters, albeit
    at the slightly justifiable increase of the FLOP specification. As some path of
    ResNet utilizes 1x1 convolutions with a stride of 2, ¾ of the information is discarded
    and one of the tweaks was to the stride sizes to ensure no information gets removed
    explicitly. They also reduced computational load by changing a 7x7 convolution
    to three separate 3x3 convolutions serially.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ResNet-D**（2019年）：这一进展对架构参数进行了简单的调整，以提高度量性能，同时保持参数数量，尽管在FLOP规范略有增加。由于ResNet的某些路径使用步长为2的1x1卷积，舍弃了3/4的信息，而调整步幅大小以确保不会明确删除任何信息是其中的一种调整。他们还通过将7x7卷积变为三个串行的3x3卷积来减少计算负载。'
- en: '**ResNet-RS** (2021): This advancement combines ResNet-D and the squeeze and
    excitation network and uses an image size that depends on the size of the network.
    However, it grows slower than EfficientNets (these will be introduced later).'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ResNet-RS**（2021年）：这一进展结合了ResNet-D和压缩激励网络，并使用依赖于网络大小的图像尺寸。然而，它的增长速度比EfficientNets（稍后会介绍）慢。'
- en: Understanding the DenseNet architecture family
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解DenseNet架构系列
- en: '**DenseNet** is an architecture family that was introduced in the early months
    of 2018\. The architecture is based on the idea of skip connections, similar to
    the ResNet architecture family but on steroids, which means it uses a lot of skip
    connections. The skip connections in this family of architecture differ in that
    they use **concatenation** instead of residual connections by **summation**. Summation
    allows earlier information to be directly encoded into the outputs of future layers
    without the need to modify the number of neurons, albeit at the slight informational
    disadvantage of needing the future layers to learn to decode this information.
    Concatenation adds to the size of the architecture as you need to create extra
    neurons to account for the extra information, allowing the model to work on the
    raw data. Both provide similar advantages to using skip connections. Logical blocks
    are created called **dense blocks**, where each subsequent layer in the block
    has access to all the outputs of the layers before it in the block by feature
    map concatenation. In these blocks, **zero-padding** is used to ensure that the
    spatial dimensions of the outputs of each layer are maintained so that feature
    maps can be concatenated. This setup promotes a lot of feature reuse between layers
    in the same block and allows the number of model parameters to stay the same while
    increasing the model’s learning capacity. The number of filters for each subsequent
    layer in a block for all blocks is fixed at a constant number called the **growth
    rate**, as there needs to be a structured way to add layers to not exponentially
    increase the number of channels. Taking a constant of 32 filters, the input of
    the second layer in the block will be a feature map with 32 channels, the input
    of the third layer in the block will be 64 and concatenated, and so on.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**DenseNet** 是一种架构系列，最早于2018年初提出。这种架构基于跳跃连接的思想，类似于ResNet架构系列，但更加强大，意味着它使用大量的跳跃连接。这些架构系列中的跳跃连接不同之处在于它们使用**串联**而不是通过**求和**的残差连接。求和允许较早的信息直接编码到未来层的输出中，无需修改神经元的数量，尽管稍微降低了信息的优势，需要未来层学习解码这些信息。串联增加了架构的大小，因为你需要创建额外的神经元来容纳额外的信息，从而使模型能够处理原始数据。两者都提供了使用跳跃连接的类似优势。逻辑块称为**稠密块**，其中块中每个后续层通过特征图串联可以访问块中它之前所有层的所有输出。在这些块中，使用**零填充**以确保每层输出的空间尺寸保持不变，以便可以串联特征图。这种设置促进了同一块中层之间的大量特征重用，并允许模型参数数量保持不变，同时增加了模型的学习能力。对于所有块中的每个后续层，每个块中的过滤器数量均固定为称为**增长率**的常数值，因为需要一种结构化的方式来添加层，以避免指数增加通道数。以32个过滤器为常量，块中第二层的输入将是具有32个通道的特征图，块中第三层的输入将是64个并串联，依此类推。'
- en: 'To create a full network architecture, multiple dense blocks were stacked one
    after another with a separate convolutional layer and pooling layer in between
    the dense blocks to gradually reduce the spatial dimensions of the feature map.
    *Figure 3**.10* shows the network structure of the four different DenseNet model
    architectures under the DenseNet model family:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建一个完整的网络架构，多个密集块依次堆叠，中间插入单独的卷积层和池化层，以逐渐减少特征图的空间维度。*图 3**.10* 显示了 DenseNet
    模型家族下四种不同 DenseNet 模型架构的网络结构：
- en: '![Figure 3.10 – The DenseNet model family where “conv” corresponds to sequential
    layers of batch normalization, ReLU, and the convolutional layer](img/B18187_03_10.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.10 – DenseNet 模型家族，其中“conv”对应于批量归一化、ReLU 和卷积层的顺序层](img/B18187_03_10.jpg)'
- en: Figure 3.10 – The DenseNet model family where “conv” corresponds to sequential
    layers of batch normalization, ReLU, and the convolutional layer
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.10 – DenseNet 模型家族，其中“conv”对应于批量归一化、ReLU 和卷积层的顺序层
- en: This allows DenseNet to improve upon its predecessor network architectures in
    terms of top-1 `ImageNet` accuracy.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得 DenseNet 能够在 top-1 `ImageNet` 精度方面超越其前身网络架构。
- en: Understanding the EfficientNet architecture family
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 EfficientNet 架构家族
- en: Made in 2020, EfficientNet created a family of architectures by using an automated
    **neural architecture search** (**NAS**) method to create a small base efficient
    architecture and utilize an easy-to-use compound scaling method to scale the depth
    and width of the architecture, as well as the resolution of the image. The neural
    architecture search is searched in a way that it balances FLOPS and accuracy.
    The NAS method that's used is from another research called **MnasNet** and will
    be introduced properly in [*Chapter 7*](B18187_07.xhtml#_idTextAnchor107)*, Deep
    Neural* *Architecture Search*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: EfficientNet 于 2020 年推出，通过使用自动化 **神经架构搜索** (**NAS**) 方法，创建了一个高效的小基础架构，并利用易于使用的复合缩放方法来缩放架构的深度、宽度和图像分辨率。神经架构搜索是以平衡
    FLOPS 和精度的方式进行的。使用的 NAS 方法来源于另一项研究 **MnasNet**，将在[*第7章*](B18187_07.xhtml#_idTextAnchor107)中详细介绍，深度神经*架构搜索*。
- en: 'The compound scaling method is simple and can be extended to any other network,
    though ResNet-RS demonstrates that scaling resolution slower provides more value.
    The scaling method for depth, width, and resolution is defined in the following
    equation, where the result will be multiplied by the original base architecture
    parameters to scale up the architecture:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 复合缩放方法简单且可以扩展到任何其他网络，尽管 ResNet-RS 表明，缩放分辨率较慢提供了更多的价值。深度、宽度和分辨率的缩放方法定义在以下方程式中，其中结果将与原始基础架构的参数相乘，以放大架构：
- en: depth = α φ , width = β φ, resolution = γ φ
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: depth = α φ , width = β φ, resolution = γ φ
- en: 'Here, φ is the coefficient that can be scaled to different values based on
    requirements and the other variables are constants that should be set to optimize
    something such as the FLOPS increase rate when we change the coefficient. For
    EfficientNet, the constants are constrained to satisfy the following condition:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，φ 是可以根据需求调整为不同值的系数，其他变量是常数，应设置为优化某些内容，如我们改变系数时 FLOPS 增加率的常数。对于 EfficientNet，这些常数被限制为满足以下条件：
- en: α ∙ β 2 ∙ γ 2 ≈ 2
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: α ∙ β 2 ∙ γ 2 ≈ 2
- en: 'This will constrain the increase of the coefficient to approximately increase
    the FLOPS by 2 φ. EfficientNet sets this to α = 1.2, β = 1.1, γ = 1.15 . This
    compound scaling strategy allowed seven EfficientNets to be made, named B0 to
    B7\. *Figure 3**.11* shows the structure of the EfficientNet-B0:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这将限制系数的增加，使得 FLOPS 约增加 2 φ。EfficientNet 设置为 α = 1.2，β = 1.1，γ = 1.15。这一复合缩放策略使得可以创建七个
    EfficientNet 模型，命名为 B0 到 B7。*图 3**.11* 显示了 EfficientNet-B0 的结构：
- en: '![Figure 3.11 – EfficientNet-B0 architecture structure](img/B18187_03_11.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.11 – EfficientNet-B0 架构结构](img/B18187_03_11.jpg)'
- en: Figure 3.11 – EfficientNet-B0 architecture structure
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.11 – EfficientNet-B0 架构结构
- en: Note that **MBConv** is also known as an inverted residual block and will be
    properly introduced in another network later in the *Understanding* *MobileNetV2*
    section.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，**MBConv** 也被称为反向残差块，将在稍后的 *理解* *MobileNetV2* 部分中对其进行详细介绍。
- en: '**EfficientNetV2**, made in 2021, identified that large image resolution slows
    down training time, where depthwise convolutions are slow in early layers, and
    scaling up depth, width, and resolution at the same time is not optimal. EfficientNetV2
    also uses NAS to find a base architecture but with the addition of a modification
    of an MBConv block that has more parameters and operations with the reason that
    it can be faster sometimes, depending on the input and output data shape, where
    they are in the entire architecture, and how the data is transferred to the computing
    processer. This will be explained in more detail when we formally introduce MBConv
    later. EfficientNetV2 also utilizes the original compound scaling method but adds
    a few improvements by setting a maximum image resolution to 480 and adding extra
    layers to the last few stages of the architecture when it wants to increase the
    network capacity to higher proportions. A new training method was added to reduce
    training time; we’ll discuss this in more detail in the next chapter. These improvements
    resulted in four different EfficientNetV2 models called **EfficientNetV2-S**,
    **EfficientNetV2-M**, **EfficientNetV2-L**, and **EfficientNetV2-XL**. These exceeded
    the top-1 accuracy compared to the original EfficientNet at similar FLOP values:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**EfficientNetV2**，于2021年发布，发现大图像分辨率会减慢训练时间，其中深度卷积在早期层较慢，且同时扩展深度、宽度和分辨率并非最优。EfficientNetV2还使用了NAS（神经架构搜索）来找到基础架构，但对MBConv块进行了修改，增加了更多的参数和操作，原因是它在某些情况下可以更快，具体取决于输入和输出数据的形状、它们在整个架构中的位置以及数据如何传输到计算处理器。稍后我们正式介绍MBConv时会详细解释这一点。EfficientNetV2还使用了原始的复合缩放方法，但通过将最大图像分辨率设置为480并在架构的最后几个阶段添加额外层来提高网络容量。还增加了一种新的训练方法来减少训练时间；我们将在下一章详细讨论这些内容。这些改进使得四种不同的EfficientNetV2模型诞生，分别为**EfficientNetV2-S**、**EfficientNetV2-M**、**EfficientNetV2-L**和**EfficientNetV2-XL**。与原始的EfficientNet在相似FLOP值下，这些模型的top-1准确率超越了原有的EfficientNet：'
- en: '![Figure 3.12 – EfficientNetV2-S architecture structure](img/B18187_03_12.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.12 – EfficientNetV2-S 架构结构](img/B18187_03_12.jpg)'
- en: Figure 3.12 – EfficientNetV2-S architecture structure
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.12 – EfficientNetV2-S 架构结构
- en: EfficientNetV2-S served as the base architecture, similar to how EfficientNetB0
    was the base, where the architecture structure is shown in *Figure 3**.12*.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: EfficientNetV2-S作为基础架构，类似于EfficientNetB0作为基础架构，架构结构如*图3.12*所示。
- en: Understanding small and fast CNN architecture families for small-scale edge
    devices
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解适用于小型边缘设备的小型和快速CNN架构系列
- en: 'One of the clear groups of architectures that holds a place in the world of
    CNN architectures is the group that is built not for scalability purposes or beating
    the `ImageNet` benchmark, but to be used for small devices. Small devices are
    usually called **edge devices** as they are small and compact enough to be mobile
    or to be physically deployed with actual data processing capabilities where the
    data originated. Our mobile smartphones are examples of mobile devices that are
    capable of producing images. Examples of edge devices that *aren’t* mobile include
    CCTV video cameras and doorbell cameras. Some of the key benefits of deploying
    models to the edge are listed here:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一类明确的架构组在CNN架构的世界中占有一席之地，这些架构并非为了可扩展性或打破`ImageNet`基准而设计，而是为了小型设备而建造。小型设备通常被称为**边缘设备**，因为它们足够小巧和紧凑，可以移动，或可以物理部署并具备数据处理能力，数据就是在其产生的地方进行处理的。我们的智能手机就是能够生成图像的移动设备的例子。不是移动设备的边缘设备包括闭路电视视频摄像头和门铃摄像头。将模型部署到边缘的关键好处如下所示：
- en: '**Reduced communication latency**: Images and real-time video feeds are large
    compared to simple numerical or categorical data. By using computation at the
    edge, less data needs to be transferred to a centralized server, thus reducing
    the time needed to transfer data. Sometimes, the need for a transfer can be eliminated
    when computation is done at the edge, thus significantly simplifying a system.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少通信延迟**：与简单的数值或类别数据相比，图像和实时视频流的数据量较大。通过在边缘进行计算，减少了需要传输到集中式服务器的数据量，从而减少了数据传输所需的时间。有时，当计算在边缘进行时，可以完全消除传输需求，从而显著简化系统。'
- en: '**Reduced bandwidth requirements**: When the images are processed where they
    are produced, only simple data formats such as numerical or categorical will need
    to be returned, thus removing the need to have expensive equipment for high bandwidth
    requirements.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少带宽需求**：当图像在产生的地方进行处理时，只需返回简单的数据格式，如数值型或类别型数据，从而避免了对高带宽设备的需求。'
- en: '**Increased redundancy**: A centralized server also means a single point of
    failure. Distributing processing to the individual edge devices makes sure the
    failure of any one device won’t affect the entire system.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增加冗余**：集中式服务器意味着单点故障。将处理分配到各个边缘设备可以确保任何一个设备的故障不会影响整个系统。'
- en: Small CNN architectures meant for edge devices typically engineer the entire
    structure of a model without a single notable baseline, so there isn’t a proper
    model family to categorize each of these architectures. For ease of referencing
    architectures meant for this purpose, it is recommended to think of the following
    architectures as under *architecture for the edge.* There are other techniques
    that can be applied architecture-wide to further optimize the efficiency of the
    model that we will explore in [*Chapter 15*](B18187_15.xhtml#_idTextAnchor217)*,
    Deploying Deep Learning Models in Production*, but for now let’s explore two of
    these architectures, namely **SqueezeNet** and **MobileNet**.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 针对边缘设备的小型 CNN 架构通常在没有单一显著基准的情况下设计整个模型结构，因此没有一个合适的模型家族来对这些架构进行分类。为了方便引用这些专为此目的设计的架构，建议将以下架构视为*面向边缘的架构*。还有其他可以应用于整个架构的技术，用以进一步优化模型的效率，我们将在[*第15章*](B18187_15.xhtml#_idTextAnchor217)《在生产中部署深度学习模型》中进行探讨，但目前我们先来看看其中的两个架构，即**SqueezeNet**和**MobileNet**。
- en: Understanding SqueezeNet
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 SqueezeNet
- en: 'SqueezeNet was developed in 2016 to build small and fast CNNs with the benefits
    described in the previous section but with an emphasis on deploying to hardware
    with limited memory. The three strategies that can be employed are as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: SqueezeNet 于 2016 年开发，旨在构建小型且快速的 CNN，并具备前一节所描述的优势，同时强调部署到内存有限的硬件上。可以采用的三种策略如下：
- en: For a convolutional layer with 3x3 filters, replace the filters partially with
    1x1 filters. This means that the 1x1 filter and 3x3 filters co-exist theoretically
    in a single layer applied to the same input. However, the implementation details
    will differ as parallel branch paths for the 1x1 filters and 3x3 filters are applied
    on the same input. This is called the expand layer.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于一个具有 3x3 滤波器的卷积层，部分使用 1x1 滤波器来替代。这意味着 1x1 滤波器和 3x3 滤波器在理论上可以共存于一个单独的层，并应用于相同的输入。然而，具体实现会有所不同，因为
    1x1 滤波器和 3x3 滤波器会在同一输入上应用并行分支路径。这被称为扩展层（expand layer）。
- en: Decrease the data input channels that are passed into the parallel 1x1 and 3x3
    filters by using a small number of 1x1 filters. This is called the squeeze layer.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用少量 1x1 滤波器来减少传递到并行 1x1 和 3x3 滤波器的数据输入通道数量。这被称为 squeeze 层。
- en: Downsample the feature maps late in the architecture so that the majority of
    the convolutional layers have access to large feature maps based on findings and
    improve metric performance. This is done by using pooling layers with strides
    of 2 pixels less frequently in earlier stages and more frequently in later stages
    and larger intervals. Pooling layers are not used after every convolutional layer.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在架构的后期阶段对特征图进行下采样，以便大多数卷积层可以访问基于发现的较大特征图，从而提高指标性能。通过在早期阶段较少使用步幅为 2 像素的池化层，而在后期阶段及较大间隔时更多使用，从而实现这一点。在每个卷积层后并不总是使用池化层。
- en: 'A logical block called `Fire` was made that provides the ease of creating multiple
    blocks to create architectures. This block enabled the configuration of the number
    of 1x1-sized filters in the squeeze layer, 1x1 filters in the expand layer, and
    3x3 filters in the expand layer. This is depicted in *Figure 3**.13*. Note that
    padding is applied to the outputs of the 3x3 convolutional layer to ensure it
    can be concatenated with the outputs from the 1x1 convolutional layer in the expand
    layer:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了一个逻辑块叫做 `Fire`，它提供了便于创建多个模块以构建架构的功能。该模块使得在 squeeze 层中配置 1x1 大小滤波器的数量、在扩展层中的
    1x1 滤波器和 3x3 滤波器成为可能。这在*图 3.13*中有所展示。请注意，针对 3x3 卷积层的输出应用了填充操作，以确保其可以与扩展层中 1x1
    卷积层的输出进行连接：
- en: '![Figure 3.13 – The Fire module/logical block](img/B18187_03_13.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.13 – 火焰模块/逻辑块](img/B18187_03_13.jpg)'
- en: Figure 3.13 – The Fire module/logical block
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.13 – 火焰模块/逻辑块
- en: Eight `Fire` blocks were used to build an architecture called SqueezeNet that
    maintained the performance of `ImageNet` from the historical architecture known
    as **AlexNet** (not introduced in this book as it is not practically useful nowadays)
    while being 50x smaller.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用了八个`Fire`模块构建了一个叫做SqueezeNet的架构，它保持了从历史架构**AlexNet**（本书中未介绍，因为如今已不再实际使用）中传承下来的`ImageNet`性能，同时体积缩小了50倍。
- en: Understanding MobileNet
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解MobileNet
- en: The first MobileNet version, called MobileNetV1, was introduced in 2017 for
    mobile and embedded devices by focusing on optimizing latency issues and getting
    small-sized networks as a side effect instead of vice versa.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个MobileNet版本，称为MobileNetV1，于2017年推出，专为移动和嵌入式设备设计，重点优化延迟问题，并通过这一过程使得网络尺寸较小，而不是反过来。
- en: 'The depthwise separable convolutional layer was used extensively in the entire
    architecture except in the first layer in the first iteration of MobileNet, which
    consisted of 28 layers. This layer is built on factorizing the standard convolutional
    layer into two layers called the depthwise convolution and the pointwise convolution.
    This new two-layer setup is based on the idea that using a standard convolutional
    filter is expensive to compute. The depthwise convolutional layer uses one unique
    filter for one unique input channel, where each input channel has only one filter.
    Having one filter per channel is a unique case of `ImageNet` by 1%. This breakdown
    also reduces the number of parameters by around 5 times. This process is essentially
    a kind of factorization. The depthwise convolutional logical block is depicted
    in the following figure:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个架构中，除了第一层之外，深度可分离卷积层被广泛使用，这一版本的MobileNet包含28层。该层通过将标准卷积层分解为两层——深度卷积层和点卷积层——来构建。这种两层的设计理念是，使用标准卷积滤波器计算代价较高。深度卷积层为每个输入通道使用一个独特的滤波器，每个输入通道只有一个滤波器。这种每个通道一个滤波器的设计，使得`ImageNet`中只有1%的独特案例。该分解也使得参数数量减少了约5倍。这一过程本质上是一种因式分解。深度卷积逻辑模块如下图所示：
- en: '![Figure 3.14 – Depthwise separable convolutional layer as a logical block](img/B18187_03_14.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图3.14 – 深度可分离卷积层作为逻辑模块](img/B18187_03_14.jpg)'
- en: Figure 3.14 – Depthwise separable convolutional layer as a logical block
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.14 – 深度可分离卷积层作为逻辑模块
- en: 'MobileNet also made two parameters that can be configured to reduce the model’s
    size and computational requirements while trading off some metric performance.
    The first is a width multiplier that can configure the input and output channels
    across the entire architecture. The second is a resolution multiplier between
    0 and 1 that applies to the original 224x224 image size to reduce the input and
    output feature map sizes when passing the image into the network. These parameters
    can also be adapted to other architectures if a faster runtime is needed. *Figure
    3**.15* shows the MobileNetV1 architecture’s structure and layer configurations:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: MobileNet还提供了两个可配置的参数，用以减少模型的大小和计算需求，同时在一定程度上牺牲性能。第一个是宽度倍增器，用于配置整个架构中的输入和输出通道。第二个是介于0和1之间的分辨率倍增器，适用于原始的224x224图像尺寸，当图像输入网络时可减小输入和输出特征图的尺寸。如果需要更快的运行时，这些参数还可以适配其他架构。*图3.15*显示了MobileNetV1架构的结构和层配置：
- en: '![Figure 3.15 – MobileNetV1 architecture](img/B18187_03_15.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图3.15 – MobileNetV1架构](img/B18187_03_15.jpg)'
- en: Figure 3.15 – MobileNetV1 architecture
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15 – MobileNetV1架构
- en: MobileNet is considered to be a unique model family with two improvements that
    are based on the first version. They are named MobileNetv2 and MobileNetv3-small
    and both were introduced in 2019.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: MobileNet被认为是一个独特的模型家族，基于第一个版本进行了两项改进。它们分别是MobileNetv2和MobileNetv3-small，二者都在2019年推出。
- en: Understanding MobileNetV2
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解MobileNetV2
- en: 'Before we go through MobileNetV2, let’s define what a **bottleneck layer**
    is, a core idea that’s utilized in advancement. A bottleneck layer is generally
    a layer with fewer output feature maps compared to the layers before and after
    the layer. MobileNetV2 is built upon the idea that bottlenecks are where the information
    of interest will exist; nonlinearities destroy too much information in bottleneck
    layers, so a linear layer is applied, finally applying residuals using shortcut
    connections on the bottleneck layers. MobileNetV2 builds upon the base depthwise
    separable building block, adds a linear bottleneck layer without ReLU, and adds
    residuals to the bottleneck layers. This building block is depicted in the following
    figure. This is called the **bottleneck inverted** **residual block**:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解MobileNetV2之前，先定义一下**瓶颈层**是什么，这是该进展中使用的核心思想。瓶颈层通常是一个输出特征图较少的层，且相对于前后层有较少的输出。MobileNetV2建立在瓶颈层是信息所在的思想上；非线性激活会在瓶颈层破坏过多的信息，因此应用了线性层，最终通过捷径连接对瓶颈层进行残差运算。MobileNetV2基于深度可分离卷积构建，添加了没有ReLU的线性瓶颈层，并在瓶颈层上应用残差。这一构建模块如下图所示。它被称为**瓶颈反向残差块**：
- en: '![Figure 3.16 – The bottleneck inverted residual block for MobileNetV2, also
    called MBConv](img/B18187_03_16.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图3.16 – MobileNetV2的瓶颈反向残差块，也称为MBConv](img/B18187_03_16.jpg)'
- en: Figure 3.16 – The bottleneck inverted residual block for MobileNetV2, also called
    MBConv
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.16 – MobileNetV2的瓶颈反向残差块，也称为MBConv
- en: As for the entire network architecture-wise, all depthwise separable layers
    from the first MobileNet were replaced with the new block except for the first
    convolution layer with a 3x3 kernel size and 32 filters, as shown in *Figure 3**.16*.
    One small extra detail is that they used the **ReLU6** activation function, which
    is robust to low-precision computation. The MobileNetV2 architecture used the
    depicted logical block to create many repeated layer blocks with different settings.
    This architecture allowed for an improvement in the performance curve on ImageNet
    compared to MobileNetV2 at around 5% to 10% at the same FLOPs. Remember that EfficientNetV2
    uses this block and also another version of this block that fuses back the linear
    bottleneck layer with the filtering layer together. The purpose of having two
    layers instead of one was to reduce the number of operations needed but again,
    for edge devices, the actual latency might differ due to the bottleneck in memory
    access cost. Sometimes, using a fused version might result in a faster runtime
    with the benefits of having more parameters to learn more information from.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 至于整个网络架构，第一版MobileNet中的所有深度可分离层都被新模块替换，唯一没有替换的是第一个具有3x3卷积核和32个滤波器的卷积层，如*图3.16*所示。一个小的额外细节是，它们使用了**ReLU6**激活函数，这在低精度计算中表现良好。MobileNetV2架构使用所示的逻辑块来创建多个具有不同设置的重复层块。这一架构使得在相同FLOPs下，ImageNet上的性能曲线比MobileNetV2提高了约5%到10%。请记住，EfficientNetV2使用了这个块，并且还有一个版本的块将线性瓶颈层和过滤层重新融合在一起。使用两个层而不是一个层的目的是减少所需的操作次数，但对于边缘设备来说，由于内存访问的瓶颈，实际的延迟可能会有所不同。有时，使用融合版本可能会在具有更多参数的情况下提高运行时速度，从而能从中学习更多信息。
- en: Understanding MobileNetV3-small
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解MobileNetV3-small
- en: 'For **MobileNetV3-small**, a few changes were made to MobileNetV2:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**MobileNetV3-small**，对MobileNetV2进行了几处修改：
- en: It used a more advanced non-linearity called `ImageNet`.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用了一种更先进的非线性函数，称为`ImageNet`。
- en: Expensive computation was reduced even further in the initial and last few layers.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在初始层和最后几层，计算量被进一步减少。
- en: For the first layer, as shown in *Figure 3**.15*, 32 filters was reduced to
    16 and hard-swish nonlinearity was used to get 2 milliseconds runtime and 10 million
    FLOPS savings.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于第一层，如*图3.15*所示，32个滤波器被减少到16个，并使用了硬切换非线性函数，实现了2毫秒的运行时间和1000万FLOPS的节省。
- en: For the last few layers, the last 1x1 bottleneck convolution layer is moved
    to after the final average pooling layer, and the previous bottleneck (1x1) and
    filtering (3x3) layer are also removed.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于最后几层，最后一个1x1的瓶颈卷积层被移至最终平均池化层之后，同时前面的瓶颈（1x1）层和过滤（3x3）层也被移除。
- en: It used a modified version of network architecture search that is platform-aware
    called **Mnasnet** and a post-search layer reduction for latency reduction called
    **NetAdapt** to automatically find an optimized architecture based on the building
    blocks from the MobileNetV1, MobileNetV2, and squeeze and excitation networks
    while considering latency and accuracy performance. NetAdapt and MnasNet will
    be introduced in [*Chapter 7*](B18187_07.xhtml#_idTextAnchor107), *Deep Neural*
    *Architecture Search*.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用了一种平台感知的网络架构搜索的修改版本，称为 **Mnasnet**，以及一种称为 **NetAdapt** 的后搜索层减少方法来减少延迟，自动找到基于
    MobileNetV1、MobileNetV2 以及 squeeze 和 excitation 网络的优化架构，同时考虑延迟和精度表现。NetAdapt 和
    MnasNet 会在 [*第 7 章*](B18187_07.xhtml#_idTextAnchor107)，*深度神经* *架构搜索* 中介绍。
- en: MobileNetV3-small ended up achieving a higher top-1 `ImageNet` accuracy with
    the same parameters and FLOPS compared to MobileNetV2.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: MobileNetV3-small 最终在相同的参数和 FLOPS 下，取得了比 MobileNetV2 更高的 top-1 `ImageNet` 精度。
- en: Understanding the ShuffleNet architecture family
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 了解 ShuffleNet 架构系列
- en: ShuffleNet has two versions, ShuffleNetV1 and ShuffleNetV2, which we will discuss
    separately.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: ShuffleNet 有两个版本，ShuffleNetV1 和 ShuffleNetV2，我们将分别讨论这两个版本。
- en: ShuffleNetV1, from 2017, reuses a known variant of convolution called **grouped
    convolutions**, where each convolutional filter is responsible only for a subset
    of input data channels. MobileNet uses a special variant of this by using one
    filter for each channel. Grouped convolutions save computation costs by operating
    only on a small subset of input channel features. However, when stacked together
    one after another, the information between channels doesn’t interact – ultimately
    causing accuracy degradation. ShuffleNetV1 uses channel shuffling as an operation
    in between stacking multiple grouped convolutional layers to manually shift information
    without sacrificing FLOPs. This allows for an efficient and small network.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ShuffleNetV1，发布于 2017 年，重用了已知的卷积变种——**组卷积**，其中每个卷积滤波器仅负责输入数据通道的一个子集。MobileNet
    通过为每个通道使用一个滤波器，采用了这一特殊的变种。组卷积通过仅在输入通道特征的小子集上操作，节省了计算成本。然而，当多个组卷积层依次堆叠时，通道间的信息不会相互作用——最终导致精度下降。ShuffleNetV1
    使用通道洗牌操作，在多个组卷积层堆叠之间手动传递信息，而不牺牲 FLOPs。这使得网络既高效又小巧。
- en: 'ShuffleNetV2, from 2018, builds upon ShuffleNetV1 and focuses on the practical
    runtime efficiency of the architecture in real life while considering factors
    such as memory access cost, data **input-output** (**I/O**), and the degree of
    network parallelism. The following four design strategies were used to craft the
    new architecture:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ShuffleNetV2，发布于 2018 年，基于 ShuffleNetV1，并专注于在实际应用中架构的运行时效率，同时考虑诸如内存访问成本、数据**输入输出**（**I/O**）以及网络并行度等因素。以下四种设计策略被用于打造这一新架构：
- en: Equal channel width from input to output to minimize memory access cost.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从输入到输出保持相等的通道宽度，以最小化内存访问成本。
- en: Decrease group convolution to minimize memory access cost.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降低组卷积以最小化内存访问成本。
- en: Reduce network fragmentation to increase parallelism. One example is the number
    of convolutional and pooling operations in a single building block.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少网络碎片化以增加并行性。例如，单个构建模块中的卷积和池化操作的数量。
- en: 'Reduce element-wise operations such as ReLU as they have heavy memory access
    costs:'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少诸如 ReLU 等逐元素操作，因为它们有较高的内存访问成本：
- en: '![Figure 3.17 – Two building blocks of ShuffleNetv1 on the left and two building
    blocks of ShuffleNetv2 on the right](img/B18187_03_17.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.17 – 左侧为 ShuffleNetV1 的两个构建模块，右侧为 ShuffleNetV2 的两个构建模块](img/B18187_03_17.jpg)'
- en: Figure 3.17 – Two building blocks of ShuffleNetv1 on the left and two building
    blocks of ShuffleNetv2 on the right
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.17 – 左侧为 ShuffleNetV1 的两个构建模块，右侧为 ShuffleNetV2 的两个构建模块
- en: In *Figure 3**.17*, the first two structures on the left show the two building
    blocks of ShuffleNetV1, while the last two structures on the right show the two
    building blocks of ShuffleNetV2.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 3.17* 中，左侧的前两个结构显示了 ShuffleNetV1 的两个构建模块，而右侧的最后两个结构则显示了 ShuffleNetV2 的两个构建模块。
- en: Understanding MicroNet, the current state-of-the-art architecture for the edge
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解 MicroNet，这是当前边缘计算领域的最先进架构
- en: 'Created in 2021, MicroNet is the current state of the art in terms of latency
    and achievable top-1 `ImageNet` accuracy performance, for a very low FLOP range
    of 4 million to 21 million. The novelty of MicroNet is two-fold:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 创建于 2021 年的 MicroNet，是在延迟和可实现的 top-1 `ImageNet` 精度表现方面的当前最先进技术，适用于 400 万到 2100
    万 FLOP 范围内。MicroNet 的创新性体现在两个方面：
- en: It introduced factorized versions of the bottleneck/pointwise convolution layer
    and depthwise convolutional layers from MobileNet, called **micro-factorized convolutions**,
    in a way that the number of connections/paths for input data to output data is
    reduced. This is achieved by using multiple grouped convolutions and some dilated
    convolutions. Dilated convolutions are simply convolutions with fixed spacing
    in the kernels. Take these techniques as a form of sparse computation and only
    compute what’s needed most efficiently to ensure minimal input-to-output path
    redundancy.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它引入了来自 MobileNet 的瓶颈/逐点卷积层和深度卷积层的因式分解版本，称为**微因式分解卷积**，其方式是减少输入数据到输出数据的连接/路径数量。这是通过使用多个分组卷积和一些膨胀卷积来实现的。膨胀卷积仅仅是内核中具有固定间距的卷积。将这些技术视为一种稀疏计算，只计算最需要的部分，以确保最小的输入到输出路径冗余。
- en: 'It introduced a new activation function called **dynamic shift-max** that leverages
    the output of the grouped convolutions in a way that it applies a higher order
    of non-linearity (two times) and strengthens connections between groups at the
    same time. This is implemented by using the grouped outputs of the blocks of squeeze
    and excitation (produce a single value per channel) as a weighting mechanism to
    obtain the maximum of a group-based weighted addition. Take this as an improvement
    on top of channel shuffling in ShuffleNet. *Figure 3**.18* shows the operation
    structure of dynamic shift-max for a single example feature map of 12 channels
    from the output of four groups using the grouped convolution operation:'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它引入了一种新的激活函数，称为**动态 shift-max**，该函数利用分组卷积的输出，通过应用更高阶的非线性（两次），同时增强组间的连接。这是通过使用挤压和激励块的分组输出（每个通道生成一个单一值）作为加权机制，来获得基于组加权和的最大值。将此视为对
    ShuffleNet 中通道洗牌的改进。*图 3**.18* 显示了动态 shift-max 操作结构的示意图，展示了一个来自四个组、使用分组卷积操作的 12
    通道的单一示例特征图：
- en: '![Figure 3.18 – Dynamic shift-max general operation flow](img/B18187_03_18.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.18 – 动态 shift-max 一般操作流程](img/B18187_03_18.jpg)'
- en: Figure 3.18 – Dynamic shift-max general operation flow
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.18 – 动态 shift-max 一般操作流程
- en: 'MicroNet utilizes concepts from ShuffleNet (the channel shuffling mechanism),
    ResNet (skip connections), SENet (squeeze and excitation networks), and MobileNet
    (create factorized versions out of the already factorized convolutions) on top
    of its novelties to create networks that are highly efficient by focusing on the
    concept of sparsity and improvements in efficient information flow. The specifics
    of this network can be overwhelming and, frankly, hard to comprehend, so the information
    presented here does not contain all the details:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: MicroNet 利用了 ShuffleNet（通道洗牌机制）、ResNet（跳跃连接）、SENet（挤压和激励网络）和 MobileNet（从已因式分解的卷积中创建因式分解版本）等概念，并在其创新之上，创造了通过聚焦稀疏性概念和高效信息流改进的高效网络。该网络的具体细节可能令人不知所措，坦白说，也很难理解，因此此处提供的信息并不包含所有细节：
- en: "![Figure 3.19 – Diagram of three logical blocks, called micro-blocks, that\
    \ \uFEFFare used to build different size variants of MicroNets](img/B18187_03_19.jpg)"
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.19 – 三个逻辑块的示意图，这些块被称为微块，用于构建不同大小的 MicroNet 变体](img/B18187_03_19.jpg)'
- en: Figure 3.19 – Diagram of three logical blocks, called micro-blocks, that are
    used to build different size variants of MicroNets
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.19 – 三个逻辑块的示意图，这些块被称为微块，用于构建不同大小的 MicroNet 变体
- en: However, *Figure 3**.19* shows how logical blocks are, again, in the most advanced
    network today to build networks with different sizes based on the same ideas.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，*图 3**.19* 显示了逻辑块如何在今天最先进的网络中，基于相同的思想构建不同规模的网络。
- en: Summarizing CNN architectures for the edge
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结用于边缘计算的 CNN 架构
- en: 'To summarize the architectures for the edge, you now have the intuitive knowledge
    that was used by experts in the field to build highly effective CNN architectures
    capable of running at an amazingly tiny footprint compared to large models such
    as GPT-3 today. The following figure shows the overall top-1 `ImageNet` accuracy
    performance versus FLOPS graph of multiple different architecture families for
    edge computation:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了总结边缘计算的架构，现在你已经拥有了专家在该领域中用来构建高度有效的 CNN 架构的直观知识，这些架构相比今天的大型模型，如 GPT-3，能够以极小的占用空间运行。下图展示了不同架构家族在边缘计算中的总体
    top-1 `ImageNet` 精度表现与 FLOPS 图：
- en: '![Figure 3.20 – Top-1 accuracy performance for edge architecture families below
    400 million FLOPS](img/B18187_03_20.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.20 – 低于4亿FLOPS的边缘架构系列的top-1准确率性能](img/B18187_03_20.jpg)'
- en: Figure 3.20 – Top-1 accuracy performance for edge architecture families below
    400 million FLOPS
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.20 – 低于4亿FLOPS的边缘架构系列的top-1准确率性能
- en: Take these results with a pinch of salt; training strategies might differ between
    the models and can affect the achievable top-1 `ImageNet` accuracy considerably,
    along with giving possibly differing results between different random initializations
    of the different model runs. Additionally, latency is not directly represented
    purely by the number of parameters nor the FLOPS but is additionally affected
    by the memory access cost of individual operations, I/O access cost, and the degree
    of parallelism of the different operations.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 对这些结果应保持谨慎态度；模型之间的训练策略可能不同，会显著影响可实现的`ImageNet` top-1准确率，同时在不同模型运行的随机初始化之间可能会得到不同的结果。此外，延迟并不完全由参数数量或FLOPS直接表示，还受到各个操作的内存访问成本、I/O访问成本以及不同操作的并行程度的影响。
- en: 'To recap, *Figure 3**.21* shows the overall performance plots based on the
    FLOPS of all the CNN model families that were introduced in this chapter:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，*图 3.21* 显示了本章介绍的所有CNN模型系列在FLOPS基础上的整体性能图：
- en: '![Figure 3.21 – Overall CNN model family performance in terms of ImageNet top-1
    accuracy based on FLOPS](img/B18187_03_21.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.21 – 基于FLOPS的ImageNet top-1准确率的整体CNN模型系列性能](img/B18187_03_21.jpg)'
- en: Figure 3.21 – Overall CNN model family performance in terms of ImageNet top-1
    accuracy based on FLOPS
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.21 – 基于FLOPS的ImageNet top-1准确率的整体CNN模型系列性能
- en: Again, note that we should take the results presented here with a pinch of salt
    as the training techniques that were performed against the `ImageNet` dataset
    are not exactly standardized across different benchmarks. Variation in the training
    technique can result in widely different results and will be covered more extensively
    in [*Chapter 8*](B18187_08.xhtml#_idTextAnchor125), *Exploring Supervised Deep
    Learning*, and [*Chapter 9*](B18187_09.xhtml#_idTextAnchor149), *Exploring Unsupervised
    Deep Learning*. Another important thing to note is that even though `ImageNet`
    is considered to be a large enough image dataset to be considered as a benchmark,
    maintain a level of skepticism toward the results as the data itself has been
    proven to have noisy labels with systematic errors in some cases. A corrected
    form of `ImageNet` has been published called `ImageNet Real` but not all models
    are benchmarked or pre-trained against it. Train it on your dataset to be 100%
    sure which architecture, when pre-trained on certain datasets, performs better!
    Additionally, the FLOPS indicator does not fully represent the actual latency
    of the model, which can vary widely based on how the code is structured, how the
    model is distributed through multiple devices, how many GPUs or CPUs are available,
    and how parallel the model architecture is.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，我们应对这里呈现的结果保持谨慎，因为在`ImageNet`数据集上执行的训练技术并未在不同的基准测试中完全标准化。训练技术的差异可能导致结果差异巨大，且将在[*第8章*](B18187_08.xhtml#_idTextAnchor125)，《探索监督深度学习》和[*第9章*](B18187_09.xhtml#_idTextAnchor149)，《探索无监督深度学习》中更为详细地讨论。另一个重要的注意点是，尽管`ImageNet`被认为是一个足够大的图像数据集，可以作为基准使用，但由于数据本身在某些情况下已被证明存在噪声标签和系统性错误，保持一定的怀疑态度是必要的。`ImageNet`的修正版`ImageNet
    Real`已经发布，但并非所有模型都以此为基准进行测试或预训练。为了100%确定哪种架构在特定数据集上预训练后表现更好，请在你的数据集上进行训练！此外，FLOPS指标并不能完全代表模型的实际延迟，实际延迟可能会因代码结构、模型如何分布在多个设备上、可用的GPU或CPU数量，以及模型架构的并行程度而产生较大差异。
- en: Summary
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: CNNs are the go-to model for capturing patterns in image data. The handpicked
    architectures that were introduced in this chapter are the core backbones that
    can be subsequently utilized as a base for solving more custom downstream tasks
    such as image object detection and image generation.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: CNN是捕捉图像数据模式的首选模型。本章介绍的精选架构是核心骨干网络，可以作为基础，进一步用于解决更多定制化的下游任务，如图像目标检测和图像生成。
- en: The CNNs that were covered here will be used practically in later chapters as
    a basis to help you learn other deep learning-based knowledge. Take your time
    and look into how different architectures are implemented in a deep learning library
    offline in this book’s GitHub repository; we won’t be presenting the actual implementation
    code here. Now that we have covered CNNs in intermediate to low-level detail,
    in the next chapter, we’ll shift gears and look at recurrent neural networks.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖的卷积神经网络（CNN）将在后续章节中作为基础，帮助你学习其他基于深度学习的知识。请慢慢消化，并查看本书 GitHub 仓库中离线实现的深度学习库中不同架构的实现；我们这里不会呈现实际的实现代码。既然我们已经详细讲解了中低级的卷积神经网络，接下来我们将切换话题，探讨递归神经网络。
