- en: Autoencoders for CNN
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自编码器在卷积神经网络（CNN）中的应用
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将覆盖以下主题：
- en: Introducing to Autoencoders
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自编码器介绍
- en: Convolutional Autoencoder
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积自编码器
- en: Applications of Autoencoders
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自编码器的应用
- en: An example of compression
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个压缩的例子
- en: Introducing to autoencoders
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自编码器介绍
- en: 'An autoencoder is a regular neural network, an unsupervised learning model
    that takes an input and produces the same input in the output layer. So, there
    is no associated label in the training data. Generally, an autoencoder consists
    of two parts:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是一个普通的神经网络，是一种无监督学习模型，它接受输入并在输出层产生相同的输入。因此，训练数据中没有相关标签。一般来说，自编码器由两个部分组成：
- en: Encoder network
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码器网络
- en: Decoder network
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解码器网络
- en: It learns all the required features from unlabeled training data, which is known
    as lower dimensional feature representation. In the following figure, the input
    data (*x*) is passed through an encoder that produces a compressed representation
    of the input data. Mathematically, in the equation, *z = h(x)*,*z* is a feature
    vector, and is usually a smaller dimension than *x*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 它从无标签的训练数据中学习所有必需的特征，这被称为低维特征表示。在下图中，输入数据（*x*）通过编码器传递，编码器生成输入数据的压缩表示。从数学角度来看，在方程式中，*z
    = h(x)*，*z*是特征向量，通常比*x*的维度更小。
- en: Then, we take these produced features from the input data and pass them through
    a decoder network to reconstruct the original data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将从输入数据中生成的特征传递通过解码器网络，以重建原始数据。
- en: 'An encoder can be a fully connected neural network or a **convolutional neural
    network** (**CNN**). A decoder also uses the same kind of network as an encoder. Here,
    we''ve explained and implemented the encoder and decoder function using ConvNet:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器可以是一个全连接神经网络，也可以是一个**卷积神经网络**（**CNN**）。解码器也使用与编码器相同类型的网络。在这里，我们通过卷积神经网络（ConvNet）解释并实现了编码器和解码器功能：
- en: '![](img/7c90369e-7ca4-48a3-b473-30c24faaecd6.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7c90369e-7ca4-48a3-b473-30c24faaecd6.png)'
- en: 'Loss function: *||x - x||²*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数：*||x - x||²*
- en: In this network, the size of the input and the output layers is the same.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个网络中，输入层和输出层的尺寸相同。
- en: Convolutional autoencoder
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积自编码器
- en: A convolutional autoencoder is a neural network (a special case of an unsupervised
    learning model) that is trained to reproduce its input image in the output layer.
    An image is passed through an encoder, which is a ConvNet that produces a low-dimensional
    representation of the image. The decoder, which is another sample ConvNet, takes
    this compressed image and reconstructs the original image.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积自编码器是一个神经网络（无监督学习模型的特殊情况），经过训练后能够在输出层重建输入图像。图像通过编码器传递，编码器是一个卷积神经网络（ConvNet），它生成图像的低维表示。解码器是另一个样本卷积神经网络，它接收这个压缩后的图像并重建原始图像。
- en: 'The encoder is used to compress the data and the decoder is used to reproduce
    the original image. Therefore, autoencoders may be used for data, compression.
    Compression logic is data-specific, meaning it is learned from data rather than
    predefined compression algorithms such as JPEG, MP3, and so on. Other applications
    of autoencoders can be image denoising (producing a cleaner image from a corrupted
    image), dimensionality reduction, and image search:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器用于压缩数据，解码器用于重建原始图像。因此，自编码器可以用于数据压缩。压缩逻辑是特定于数据的，这意味着它是从数据中学习的，而不是预定义的压缩算法，如JPEG、MP3等。自编码器的其他应用包括图像去噪（从损坏的图像中生成更清晰的图像）、降维和图像搜索：
- en: '![](img/9a8a64d7-7d61-446e-96ac-808858df19af.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9a8a64d7-7d61-446e-96ac-808858df19af.png)'
- en: This differs from regular ConvNets or neural nets in the sense that the input
    size and the target size must be the same.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这与普通的卷积神经网络（ConvNets）或神经网络的不同之处在于，输入尺寸和目标尺寸必须相同。
- en: Applications
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用
- en: Autoencoders are used for dimensionality reduction, or data compression, and
    image denoising. Dimensionality reduction, in turn, helps in improving runtime
    performance and consumes less memory. An image search can become highly efficient
    in low-dimension spaces.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器用于降维或数据压缩，以及图像去噪。降维反过来有助于提高运行时性能并减少内存消耗。图像搜索在低维空间中可以变得非常高效。
- en: An example of compression
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个压缩的例子
- en: The Network architecture comprises of an encoder network, which is a typical
    convolutional pyramid. Each convolutional layer is followed by a max-pooling layer;
    this reduces the dimensions of the layers.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 网络架构包括一个编码器网络，这是一个典型的卷积金字塔。每个卷积层后面跟着一个最大池化层；这减少了层的维度。
- en: 'The decoder converts the input from a sparse representation to a wide reconstructed
    image. A schematic of the network is shown here:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器将输入从稀疏表示转换为宽度较大的重建图像。网络的示意图如下所示：
- en: '![](img/6c58f5c9-4f78-423e-a375-4e94c7b5a9e3.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6c58f5c9-4f78-423e-a375-4e94c7b5a9e3.png)'
- en: The encoder layer output image size is 4 x 4 x 8 = 128\. The original image
    size was 28 x 28 x 1 = 784, so the compressed image vector is roughly 16% of the
    size of the original image.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器层的输出图像大小为4 x 4 x 8 = 128。原始图像大小为28 x 28 x 1 = 784，因此压缩后的图像向量大约是原始图像大小的16%。
- en: Usually, you'll see transposed convolution layers used to increase the width
    and height of the layers. They work almost exactly the same as convolutional layers
    but in reverse. A stride in the input layer results in a larger stride in the
    transposed convolution layer. For example, if you have a 3 x 3 kernel, a 3 x 3
    patch in the input layer will be reduced to one unit in a convolutional layer.
    Comparatively, one unit in the input layer will be expanded into a 3 x 3 path
    in a transposed convolution layer. The TensorFlow API provides us with an easy
    way to create the layers: `tf.nn.conv2d_transpose`, click here, [https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你会看到使用反卷积（transposed convolution）层来增加层的宽度和高度。它们的工作方式与卷积层几乎完全相同，只不过是反向的。输入层的步幅（stride）在反卷积层中会变得更大。例如，如果你有一个3
    x 3的卷积核，输入层的3 x 3区域在卷积层中将被缩小为一个单位。相比之下，输入层的一个单位在反卷积层中将被扩展成一个3 x 3的区域。TensorFlow
    API为我们提供了一个简单的方式来创建这些层：`tf.nn.conv2d_transpose`，点击这里，[https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d_transpose)。
- en: Summary
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We began this chapter with a short introduction to autoencoders, and we implemented
    the encoder and decoder function with the help of ConvNets.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以简短的自编码器介绍开始了本章，并在卷积神经网络（ConvNets）的帮助下实现了编码器和解码器功能。
- en: We then moved to convolutional autoencoders and learned how they are different
    from regular ConvNets and neural nets.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们转向卷积自编码器，并学习它们与常规卷积神经网络和神经网络的不同之处。
- en: We walked through the different applications of autoencoders, with an example,
    and saw how an autoencoder enhances the efficiency of image searches in low-dimension
    spaces.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过一个例子详细讲解了自编码器的不同应用，并展示了自编码器如何提高低维空间中图像搜索的效率。
- en: In the next chapter, we will study object detection with CNNs and learn the
    difference between object detection and object classification.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将研究使用卷积神经网络（CNNs）进行物体检测，并了解物体检测与物体分类的区别。
