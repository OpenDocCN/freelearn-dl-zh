- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Incorporating Additional Features from the OpenAI API
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入 OpenAI API 的附加功能
- en: The OpenAI API offers additional features beyond the standard endpoints and
    parameters that we learned about in the previous chapter. These provide additional
    customizability to the existing model and enable far more use cases by linking
    the model to other methods.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API 提供了比我们在上一章中学到的标准端点和参数更多的功能。这些功能为现有模型提供了更多自定义选项，并通过将模型与其他方法连接，拓展了更多的应用场景。
- en: In particular, the OpenAI API contains a robust embedding model, enabling users
    to vectorize text to perform typical NLP functions such as text clustering, text
    classification, text comparison, and more. This is the same technology that search
    engines such as Google use, for example, to return relevant search results. Now,
    with the OpenAI API, it is available at your fingertips.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，OpenAI API 包含一个强大的嵌入模型，使用户能够将文本向量化，执行典型的 NLP 功能，如文本聚类、文本分类、文本比较等。这是与 Google
    等搜索引擎使用的相同技术，例如，搜索引擎使用它来返回相关的搜索结果。现在，通过 OpenAI API，它触手可及。
- en: The API also contains a method to *fine-tune* or customize a model for a particular
    use case. Instead of the fine-tuning we did earlier, which required *priming*
    the model with several examples, this is a better and typically cheaper alternative.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: API 还包含一个方法来 *微调* 或定制某个模型以适应特定的应用场景。与我们之前所做的微调（需要通过多个示例来 *引导* 模型）不同，这是一种更好且通常更便宜的替代方案。
- en: Finally, the API also possesses the ability to create **function calls**. This
    enables you to provide the API with a set of functions and their descriptions,
    and the model in turn intelligently creates a JSON object containing arguments
    to call that function, enabling you to link the OpenAI API to any user-defined
    functions.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，API 还具备创建 **函数调用** 的能力。这使你能够向 API 提供一组函数及其描述，模型则智能地生成一个包含调用该函数所需参数的 JSON
    对象，从而使你能够将 OpenAI API 与任何用户定义的函数连接。
- en: However, in order to use these features, we need to call the API through a programmatic
    language such as *Python* instead of through one-time HTTP requests such as Postman.
    As a result, we will first cover how to use the OpenAI API with Python instead
    of Postman, and then learn about the benefits that this change in methodology
    enables.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了使用这些功能，我们需要通过编程语言（如 *Python*）而非通过一次性的 HTTP 请求（如 Postman）来调用 API。因此，我们将首先介绍如何使用
    Python 而非 Postman 调用 OpenAI API，并了解这种方法变更所带来的好处。
- en: By the end of this chapter, you will know how to use these features in your
    applications. This is important because understanding these features will open
    up a plethora of other use cases that would otherwise not be possible to execute.
    Additionally, we will cover applications of each feature beyond what is covered
    within each recipe.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够在应用程序中使用这些功能。这很重要，因为理解这些功能将为你打开一扇门，使你能够执行大量其他本来无法实现的应用场景。此外，我们还将探讨每个功能在各个食谱之外的应用。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: Using the Python library to call the OpenAI API
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Python 库调用 OpenAI API
- en: Using the embedding model for text comparison and other use cases
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用嵌入模型进行文本比较和其他应用场景
- en: Fine-tuning a completion model and relevant applications
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调完成模型及其相关应用
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the recipes in this chapter require you to have access to the OpenAI API
    (via a generated API key) and have an API client installed. In case you don’t
    recall how to do this, you can refer to the [*Chapter 1*](B21007_01.xhtml#_idTextAnchor021)
    recipe *Making OpenAI API requests* *with Postman*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有食谱都需要你可以访问 OpenAI API（通过生成的 API 密钥）并且已经安装了 API 客户端。如果你不记得如何操作，可以参考 [*第
    1 章*](B21007_01.xhtml#_idTextAnchor021) 食谱 *使用 Postman 发起 OpenAI API 请求*。
- en: In previous chapters, we have used Postman as our API client. In this case,
    we will use the programmatic language Python instead. Specifically, the recipes
    will use the OpenAI Python library to make calls to the OpenAI API.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们使用了 Postman 作为 API 客户端。在本章中，我们将改用编程语言 Python。具体来说，本章的食谱将使用 OpenAI
    Python 库来调用 OpenAI API。
- en: We will run Python in a service called **Google Colab**. Colab is an online
    hosted **Jupyter Notebook** service by Google, that requires no setup to use and
    can run Python code within the browser. The Jupyter Notebook is an open sourced
    web application that allows you to create and share documents and contains live
    code that can be run step by step. This is the environment we will use to run
    our Python code.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在一个叫做 **Google Colab** 的服务中运行 Python。Colab 是由 Google 提供的在线托管 **Jupyter Notebook**
    服务，使用时无需设置，并且可以在浏览器中运行 Python 代码。Jupyter Notebook 是一个开源的 Web 应用程序，允许您创建和共享文档，并包含可以逐步运行的实时代码。这就是我们将用来运行
    Python 代码的环境。
- en: To use Google Colab, you need to create and be signed in to a valid Google account,
    which is completely free. Follow the steps to create a new Google account at [https://accounts.google.com/](https://accounts.google.com/).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Google Colab，您需要创建并登录有效的 Google 账户，这是完全免费的。按照以下步骤创建新的 Google 账户：[https://accounts.google.com/](https://accounts.google.com/)。
- en: Using the Python library to call the OpenAI API
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 库调用 OpenAI API
- en: Previously, we used HTTP requests and Postman to call the OpenAI API. Now, we
    are transferring to another method of calling the API, through Python with the
    dedicated OpenAI Python library. Why does this matter and why is this important?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们使用 HTTP 请求和 Postman 来调用 OpenAI API。现在，我们转向通过 Python 和专用的 OpenAI Python
    库来调用 API。为什么这很重要？
- en: Utilizing the Python library for OpenAI API calls offers a significant advantage
    over manual HTTP requests in tools such as Postman, especially for developers
    looking to integrate ChatGPT functionality into their applications seamlessly.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Python 库调用 OpenAI API 相比于在 Postman 等工具中手动发起 HTTP 请求，具有显著优势，尤其对于那些希望将 ChatGPT
    功能无缝集成到其应用程序中的开发者来说。
- en: Python’s library simplifies the intricacies involved in making direct HTTP requests
    by offering a more user-friendly and intuitive interface. This facilitates quick
    prototyping, streamlined error management, and efficient parsing of responses.
    The library wraps the fundamental details of the protocol, allowing developers
    to concentrate on their application’s essential functionality without being bogged
    down by the specifics of request headers, query strings, and HTTP methods.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Python 的库通过提供更友好和直观的接口，简化了直接发起 HTTP 请求的复杂性。这促进了快速原型开发、简化的错误管理和高效的响应解析。该库封装了协议的基本细节，使开发人员能够专注于应用程序的核心功能，而不必被请求头、查询字符串和
    HTTP 方法的具体细节所困扰。
- en: Furthermore, Python’s extensive package ecosystem readily supports the integration
    of the OpenAI API with other services and systems, allowing for a scalable and
    maintainable code base.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Python 广泛的包生态系统能够轻松支持将 OpenAI API 与其他服务和系统集成，从而实现可扩展和可维护的代码库。
- en: Overall, if you are serious about building intelligent applications with the
    OpenAI API, you need to call the API with a programmatic language that enables
    complex logic and tie-ins to other systems. Python, through the OpenAI library,
    is one way to accomplish that.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，如果您认真考虑使用 OpenAI API 构建智能应用程序，您需要使用一种能够实现复杂逻辑和与其他系统连接的编程语言来调用 API。通过 OpenAI
    库，Python 是实现这一目标的途径之一。
- en: 'In this recipe, we will create some simple API calls using Python and the OpenAI
    library. More information on the library can be found here: [https://github.com/openai/openai-python](https://github.com/openai/openai-python).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将使用 Python 和 OpenAI 库创建一些简单的 API 调用。有关该库的更多信息，请参见：[https://github.com/openai/openai-python](https://github.com/openai/openai-python)。
- en: Getting ready
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Ensure you have an OpenAI platform account with available usage credits. If
    you don’t, please follow the *Setting up your OpenAI Playground environment* recipe
    in [*Chapter 1*](B21007_01.xhtml#_idTextAnchor021).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您有一个 OpenAI 平台账户并拥有可用的使用积分。如果没有，请参阅 [*第 1 章*](B21007_01.xhtml#_idTextAnchor021)
    中的 *设置 OpenAI Playground 环境* 食谱。
- en: Furthermore, ensure you are logged in to a Google account and have access to
    a notebook. You can verify this by going to [https://colab.google/](https://colab.google/)
    and selecting **New Notebook** at the top right. After that, you should have a
    blank screen with an empty notebook open.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，请确保您已登录 Google 账户并能访问笔记本。您可以通过访问 [https://colab.google/](https://colab.google/)
    并在右上角选择 **New Notebook** 来验证这一点。之后，您应该会看到一个空白屏幕，并打开一个空的笔记本。
- en: All the recipes in this chapter have the same requirements.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有食谱都具有相同的要求。
- en: How to do it…
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In your Google Colab notebook, click the first empty cell, and type in the
    following code to download and install the OpenAI Python library. After you have
    typed the code in, press *Shift* + *Enter* to run the code inside the cell. Alternatively,
    you can run the code inside the cell by clicking the **Play** button to the left
    of the cell. This code will attempt to install the OpenAI Python library and all
    its dependencies. You may see output such as **Requirements already satisfied**
    or **Installing httpcore**. This is Google attempting to install the libraries
    that OpenAI depends on to run its own library, and is perfectly normal:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的 Google Colab notebook 中，点击第一个空白单元格，输入以下代码来下载并安装 OpenAI Python 库。输入完代码后，按
    *Shift* + *Enter* 运行该单元格中的代码。或者，你也可以通过点击单元格左侧的 **播放** 按钮来运行代码。此代码将尝试安装 OpenAI
    Python 库及其所有依赖项。你可能会看到类似 **Requirements already satisfied** 或 **Installing httpcore**
    的输出。这是 Google 在尝试安装 OpenAI 运行所需的库，这是完全正常的：
- en: '[PRE0]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Ensure that the words **Successfully installed openai-X.XX.X** are visible,
    as seen in *Figure 4**.1*.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保你能看到 **Successfully installed openai-X.XX.X** 字样，如 *图 4.1* 中所示。
- en: '![Figure 4.1 – Output of Jupyter notebook after installing the OpenAI library](img/B21007_04_01.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1 – 安装 OpenAI 库后 Jupyter notebook 的输出](img/B21007_04_01.jpg)'
- en: Figure 4.1 – Output of Jupyter notebook after installing the OpenAI library
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – 安装 OpenAI 库后 Jupyter notebook 的输出
- en: 'Next, we need to perform authentication. This is similar to the previous chapters
    where we had to authenticate our Postman requests by putting our API key in a
    **Header** parameter called *Authorization*. In Python, it’s much simpler. In
    the cell below the one you used in *step 1*, write the following code and press
    *Shift* + *Enter*. Note, replace **<api-key>** with the API key that you generated
    in the last recipe in [*Chapter 1*](B21007_01.xhtml#_idTextAnchor021):'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要进行身份验证。这与前几章类似，我们必须通过将 API 密钥放入一个名为 *Authorization* 的 **Header** 参数来验证
    Postman 请求。在 Python 中，这要简单得多。在你在 *步骤 1* 中使用的单元格下方，写入以下代码并按 *Shift* + *Enter*。注意，将
    **<api-key>** 替换为你在 [*第 1 章*](B21007_01.xhtml#_idTextAnchor021) 的最后一个食谱中生成的 API
    密钥：
- en: '[PRE1]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will now make a chat completion request to the OpenAI API. Similar to Postman,
    we can use different endpoints and define a variety of different parameters within
    the request in Python. Type the following code into a new cell below and press
    *Shift* + *Enter*, which runs the code and saves the output in a variable called
    **completion**:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将向 OpenAI API 发起聊天完成请求。与 Postman 类似，我们可以使用不同的端点，并在请求中定义各种不同的参数。在下方的一个新单元格中输入以下代码并按
    *Shift* + *Enter*，这将运行代码并将输出保存在一个名为 **completion** 的变量中：
- en: '[PRE2]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Output the **completion** variable, which is a **ChatCompletion** object. We
    can convert this into the more familiar JSON format (exactly as in Postman) by
    typing the following in the cell below and running the code by pressing *Shift*
    + *Enter*:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出 **completion** 变量，它是一个 **ChatCompletion** 对象。我们可以通过输入以下代码并按 *Shift* + *Enter*
    运行代码，将其转换为更熟悉的 JSON 格式（与 Postman 中完全相同）：
- en: '[PRE3]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '*Figure 4**.2* shows the output that you will see after running this code.'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*图 4.2* 显示了你运行此代码后将看到的输出。'
- en: '![Figure 4.2 – JSON output of the Python OpenAI completion request](img/B21007_04_02.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 – Python OpenAI 完成请求的 JSON 输出](img/B21007_04_02.jpg)'
- en: Figure 4.2 – JSON output of the Python OpenAI completion request
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – Python OpenAI 完成请求的 JSON 输出
- en: 'Using Python, we can parse through the JSON and only output the part of the
    JSON that contains the company slogan. We can do this by typing the following
    code into the cell below and pressing *Shift* + *Enter* to run the code:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Python，我们可以解析 JSON，并仅输出包含公司标语的 JSON 部分。我们可以通过在下方的单元格中输入以下代码并按 *Shift* + *Enter*
    来运行代码：
- en: '[PRE4]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Figure 4.3 – Input and output of step 6](img/B21007_04_03.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3 – 第六步的输入和输出](img/B21007_04_03.jpg)'
- en: Figure 4.3 – Input and output of step 6
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – 第六步的输入和输出
- en: You now have a working Python Jupyter notebook that calls the OpenAI API, makes
    a chat completion request, and outputs the result.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你已经有了一个可以调用 OpenAI API、发起聊天完成请求并输出结果的工作 Python Jupyter notebook。
- en: How it works…
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: In this recipe, we performed the same actions as we have done in previous recipes,
    the difference being that we used the OpenAI Python library instead of invoking
    HTTP requests through Postman. We authenticated using our API key, made a chat
    completion request, and adjusted several parameters (such as *Model*, *Messages*,
    *N*, and *Temperature*), and printed the output result.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们进行了与之前相同的操作，不同之处在于我们使用了 OpenAI Python 库，而不是通过 Postman 发起 HTTP 请求。我们通过
    API 密钥进行了身份验证，发起了聊天完成请求，并调整了几个参数（如 *Model*、*Messages*、*N* 和 *Temperature*），并打印了输出结果。
- en: Code walk-through
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码讲解
- en: 'The code that was run within the recipe can be explained in four parts:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中运行的代码可以分为四个部分进行解释：
- en: '*Library installation*: The first line – **!pip install openai; import openai**
    – is a command that installs the OpenAI library as a package in Python. The second
    line imports it into the current Python namespace, enabling the use of the library’s
    functions and classes.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*库安装*：第一行 – **!pip install openai; import openai** – 是一个命令，用于将 OpenAI 库作为 Python
    中的包安装。第二行将其导入当前 Python 命名空间，使得可以使用该库的函数和类。'
- en: '*Authentication*: The **openai.api_key = "sk-..."** line sets the API key for
    authenticating requests to the OpenAI API.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*身份验证*：**openai.api_key = "sk-..."** 这一行设置了用于验证请求的 OpenAI API 密钥。'
- en: '*API call*: The **openai.ChatCompletion.create()** line calls the API and makes
    a chat completion request. As you can see, it contains the typical parameters
    that we have discussed in previous chapters.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*API 调用*：**openai.ChatCompletion.create()** 这一行调用 API 并发起聊天完成请求。如你所见，它包含了我们在前几章中讨论过的典型参数。'
- en: '*Output*: The **print(completion); print(completion[''choices''][0][''message''][''content''])**
    line prints out the raw response from the API call. The response includes not
    only the content of the completion but also some metadata, similar to when we
    make HTTP requests with Postman. This second line digs into the response object
    to extract and print only the content of the message.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*输出*：**print(completion); print(completion[''choices''][0][''message''][''content''])**
    这一行打印出来自 API 调用的原始响应。响应不仅包括完成的内容，还包含一些元数据，类似于我们使用 Postman 发起 HTTP 请求时的情况。第二行深入响应对象，提取并仅打印消息的内容。'
- en: Most API calls in Python follow these steps. It should be noted that *steps
    1 and 2* (i.e., library installation and authentication) only need to be performed
    once. This is because once a library is installed, it becomes a part of your Python
    environment, ready to be used in any program without needing to be reinstalled
    each time. Similarly, authentication, which is often a process of verifying credentials
    to gain access to the API, is typically required only once per session or configuration,
    as your credentials are then stored and reused for subsequent API calls.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 API 调用在 Python 中遵循以下步骤。需要注意的是，*步骤 1 和 2*（即库安装和身份验证）只需要执行一次。这是因为一旦库安装完成，它将成为
    Python 环境的一部分，可以在任何程序中使用，而无需每次都重新安装。同样，身份验证通常是验证凭证以获取访问 API 的权限的过程，通常每个会话或配置只需要执行一次，因为凭证会被存储并在后续的
    API 调用中重复使用。
- en: Overall, we delved into using the OpenAI Python library for interacting with
    the OpenAI API, transitioning from the HTTP requests method in Postman. We will
    continue following this process in future recipes.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们深入探讨了如何使用 OpenAI Python 库与 OpenAI API 进行交互，逐步过渡到之前使用 Postman 中 HTTP 请求的方法。我们将在未来的教程中继续沿着这个过程进行。
- en: Components of the Python library
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Python 库的组成部分
- en: The endpoints and parameters that we have discussed in previous chapters are
    all available within the OpenAI Python library. The syntax is slightly different,
    as we are now using Python code rather than JSON (through Postman) to make API
    requests, but the fundamental idea is the same. Here is a table that compares
    endpoint calls between Postman and Python libraries.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前几章讨论过的端点和参数，都可以在 OpenAI Python 库中使用。语法上稍有不同，因为我们现在使用的是 Python 代码，而不是 JSON（通过
    Postman）来发起 API 请求，但基本的思路是一样的。以下是一个表格，比较了 Postman 和 Python 库中端点调用的区别。
- en: '| **Endpoint** | **HTTP request in Postman through JSON (the** **Body component)**
    | **Python** **OpenAI Library** |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| **端点** | **Postman 中通过 JSON 的 HTTP 请求（Body 组件）** | **Python** **OpenAI 库**
    |'
- en: '| --- | --- | --- |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Chat completions** |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| **聊天完成** |'
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '|'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE18]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '|'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Images** |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| **图片** |'
- en: '[PRE25]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '|'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE30]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '|'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Audio** |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| **音频** |'
- en: '[PRE35]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '|'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE37]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '|'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Table 4.1 – Comparing endpoint calls between Postman and Python libraries
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.1 – 比较 Postman 和 Python 库中端点调用的区别
- en: Benefits and drawbacks of using the Python library
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Python 库的优缺点
- en: 'There are several benefits to doing this, aside from it just being a pre-requisite
    to future recipes. It provides abstraction over the API request itself, leading
    to the following benefits:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 除了它只是未来工作流的前提条件外，这种做法还有几个好处。它对 API 请求本身提供了抽象，带来了以下好处：
- en: '*Simplified authentication*: The library handles API key and token management,
    abstracting away the details of the authentication process from the user. For
    example, in this case, we did not need to create a new parameter for *Bearer*,
    unlike within HTTP. Furthermore, unlike HTTP requests, we do not need to declare
    our API key for every single request.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*简化认证*：该库处理 API 密钥和令牌管理，将认证过程的细节抽象化，免去了用户的操作。例如，在这种情况下，我们不需要为 *Bearer* 创建新的参数，这与
    HTTP 不同。此外，与 HTTP 请求不同，我们不需要为每一个请求都声明我们的 API 密钥。'
- en: '*Ease of use*: It provides a high-level interface with methods and classes
    that represent API endpoints, making it easier to understand and implement; the
    library takes care of constructing the correct HTTP requests, encoding parameters,
    and parsing the responses.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*易用性*：它提供了一个高层接口，方法和类代表 API 端点，使得理解和实现更加容易；库会自动处理正确的 HTTP 请求构造、参数编码和响应解析。'
- en: '*Do more*: The library often includes convenience features that are not available
    with simple HTTP requests, such as pagination helpers, streaming, session management,
    embeddings, function calls, and more (which is why we switched over to the Python
    library in this chapter – the subsequent recipes cover these features).'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*做更多的事情*：该库通常包含一些方便的特性，这些特性在简单的 HTTP 请求中不可用，如分页辅助、流式处理、会话管理、嵌入、函数调用等（这也是我们在这一章切换到
    Python 库的原因——后续的工作流涵盖了这些特性）。'
- en: '*Programmability*: The Python OpenAI library leverages the full programming
    capabilities of Python, enabling variables, logical conditioning, and functions
    (i.e., all the benefits of a programming language that you don’t get with Postman).'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可编程性*：Python OpenAI 库充分利用了 Python 的编程能力，支持变量、逻辑条件和函数（即，你可以使用编程语言的所有优势，而 Postman
    无法提供这些）。'
- en: 'There are, however, some specific downsides to using the Python library as
    well:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用 Python 库也有一些特定的缺点：
- en: '*Limited customization*: High-level abstraction may limit direct access to
    certain API functionalities'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*定制性有限*：高级抽象可能限制了对某些 API 功能的直接访问。'
- en: '*Maintenance and compatibility*: There is a dependency on library updates and
    potential conflicts with different Python versions'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*维护和兼容性*：依赖于库的更新，且可能与不同的 Python 版本发生冲突。'
- en: '*Performance overheads*: Additional abstraction layers can lead to slower performance
    in resource-critical applications'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*性能开销*：额外的抽象层可能导致在资源紧张的应用中性能变慢。'
- en: '*Reduced control*: It offers less flexibility for users needing detailed control
    over API interactions'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*控制力降低*：它对需要对 API 交互进行详细控制的用户提供的灵活性较低。'
- en: Using the embedding model for text comparisons and other use cases
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用嵌入模型进行文本比较及其他应用场景
- en: OpenAI has a model and endpoint that enables users to create **embeddings**.
    It’s a lesser-known feature of the API but has vast applications in enabling plenty
    of use cases (searching through text, text classification, and much more).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 提供了一个模型和端点，允许用户创建**嵌入**。 这是 API 中一个较少为人知的功能，但在实现许多应用场景（如文本搜索、文本分类等）方面具有广泛的应用。
- en: What are embeddings? **Text embedding** is a sophisticated technique employed
    in NLP that transforms text into a numerical format that machines can understand.
    Essentially, embeddings are high-dimensional vectors that capture the essence
    of words, sentences, or even entire documents, encapsulating not just their individual
    meanings but also the nuances and relationships between them.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是嵌入？**文本嵌入**是自然语言处理（NLP）中一种复杂的技术，它将文本转换为机器能够理解的数值格式。 本质上，嵌入是高维向量，捕捉了单词、句子甚至整个文档的精髓，概括了它们的单独意义以及它们之间的细微差别和关系。
- en: 'Mathematically, a vector is a point in an n-dimensional vector space, but for
    our purposes, you can think of a vector as just a list of numbers. However, the
    recipes discussed in this chapter do not require you to work with the process
    and science behind converting words to numbers. For more information on the science
    behind embeddings, you can find a great introductory article here: [https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/](https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/).'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学角度来看，向量是一个 n 维向量空间中的点，但为了简化，你可以把向量看作只是一个数字列表。然而，本章讨论的配方不要求你了解将单词转换为数字的过程和背后的科学原理。想了解更多关于嵌入背后的科学，可以阅读一篇很好的入门文章：[https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/](https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/)。
- en: In this recipe, we will use the OpenAI API to convert various texts into embeddings
    and use those embeddings for the use case of text comparison.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将使用 OpenAI API 将各种文本转换为嵌入，并将这些嵌入用于文本比较的应用场景。
- en: How to do it…
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: Open up a new notebook by navigating to [https://colab.google/](https://colab.google/)
    and selecting **New Notebook** at the top right.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的笔记本，导航到 [https://colab.google/](https://colab.google/) 并选择右上角的 **新建笔记本**。
- en: 'In the first cell, type in the following code and press *Shift* + *Enter* to
    run the code. This will install the OpenAI library and import the required modules
    for this recipe:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一个单元格中，输入以下代码并按 *Shift* + *Enter* 来运行代码。这将安装 OpenAI 库并导入本配方所需的模块：
- en: '[PRE39]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Similar to the previous recipe, type the following code into the cell below,
    replacing **<api-key>** with your OpenAI API Key. Hit *Shift* + *Enter* to run
    the code:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与前面的配方类似，将以下代码输入下面的单元格，并将**<api-key>**替换为你的 OpenAI API 密钥。按 *Shift* + *Enter*
    来运行代码：
- en: '[PRE40]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Next, we will create two functions in Python. The first function will create
    an embedding given a text string. To do this, we will use the **Embeddings** endpoint
    from the OpenAI API. The next function takes two embeddings and calculates the
    difference between them using **cosine similarity**, a concept that we will discuss
    in the next section. To do this, type the following code in the cell below and
    press *Shift* + *Enter*:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将用 Python 创建两个函数。第一个函数将根据文本字符串创建一个嵌入。为此，我们将使用 OpenAI API 的 **Embeddings**
    端点。下一个函数接受两个嵌入，并使用 **余弦相似度** 计算它们之间的差异，这一概念我们将在下一节讨论。为此，输入以下代码并按 *Shift* + *Enter*：
- en: '[PRE41]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now, we have everything we need to start comparing texts by creating embeddings
    and calculating the difference between them. Let’s start with two pieces of text
    that are semantically very similar: *I like apples* and *I like bananas*. Type
    in the following code, hit *Shift* + *Enter*, and note the output result:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好通过创建嵌入并计算它们之间的差异来开始比较文本。我们从两段语义上非常相似的文本开始：*I like apples* 和 *I like
    bananas*。输入以下代码，按 *Shift* + *Enter*，并注意输出结果：
- en: '[PRE42]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![Figure 4.4 – Output of cosine similarity for similar texts](img/B21007_04_04.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4 – 相似文本的余弦相似度输出](img/B21007_04_04.jpg)'
- en: Figure 4.4 – Output of cosine similarity for similar texts
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – 相似文本的余弦相似度输出
- en: 'Next, let’s compare two pieces of text that are not similar: *I like apples*
    and the first section of Article 1 of the US Constitution: *All legislative Powers
    herein granted shall be vested in a Congress of the United States, which shall
    consist of a Senate and House of Representatives* ([https://www.archives.gov/founding-docs/constitution-transcript](https://www.archives.gov/founding-docs/constitution-transcript)).
    Type in the following code, hit *Shift* + *Enter*, and note the output result:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们比较两段不相似的文本：*I like apples* 和美国宪法第一条的第一部分：*All legislative Powers herein
    granted shall be vested in a Congress of the United States, which shall consist
    of a Senate and House of Representatives* ([https://www.archives.gov/founding-docs/constitution-transcript](https://www.archives.gov/founding-docs/constitution-transcript))。输入以下代码，按
    *Shift* + *Enter*，并注意输出结果：
- en: '[PRE43]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '![Figure 4.5 – Output of cosine similarity for similar texts](img/B21007_04_05.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.5 – 相似文本的余弦相似度输出](img/B21007_04_05.jpg)'
- en: Figure 4.5 – Output of cosine similarity for similar texts
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5 – 相似文本的余弦相似度输出
- en: Note the similarity between the first set of texts (**0.90**) was higher than
    for the next set of texts (**0.70**). This means that the first set of texts is
    more semantically similar than the next two texts, which makes sense given the
    language.
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注意，第一组文本的相似度（**0.90**）高于下一组文本（**0.70**）。这意味着第一组文本在语义上比后两组文本更相似，这在语言上是有道理的。
- en: 'Let’s take this one step further. Repeat *steps 5-7* with the following texts.
    I’ve also noted the output similarities I got:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们更进一步。用以下文本重复*步骤 5-7*。我也记录了得到的输出相似度：
- en: '[PRE44]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: How it works…
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理……
- en: In this recipe, we converted texts into embeddings and then compared the embeddings.
    The results showed us that, when comparing it to *I like applies*, the text *I
    like bananas* is more semantically similar to the first section of the US Constitution.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将文本转换为嵌入向量，并进行比较。结果表明，与*I like applies*相比，文本*I like bananas*在语义上更接近美国宪法的第一部分。
- en: Furthermore, it demonstrated that the text *Birds like to fly* is more semantically
    similar to *Airplanes can soar above the ground* than *A fly can irritate me*.
    This makes sense as in the first two pieces of text, the sentences were about
    objects flying.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，它还展示了文本*Birds like to fly*与*Airplanes can soar above the ground*在语义上比与*A
    fly can irritate me*更为相似。这是有道理的，因为前两段文本的句子都与飞行物体有关。
- en: Embedding 101
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 嵌入基础
- en: As mentioned before, the process of embedding turns text into a list of numbers.
    This is imperative in NLP, as now machines can work with these lists of numbers
    instead of text.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，嵌入过程将文本转换为数字列表。这在自然语言处理（NLP）中至关重要，因为现在机器可以处理这些数字列表，而不是文本。
- en: The key feature of OpenAI’s embedding model is that it captures linguistic properties
    and semantic meaning. This means that two pieces of text that are semantically
    similar will have similar vectors (i.e., a similar list of numbers). **Semantically
    similar** means that two pieces of text convey the same or related meanings, concepts,
    or ideas, even if they use different words or structures.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI嵌入模型的关键特性是它能够捕捉语言特性和语义含义。这意味着两个语义相似的文本会有相似的向量（即相似的数字列表）。**语义相似**意味着两段文本传达相同或相关的意义、概念或思想，即使它们使用了不同的词语或结构。
- en: Code structure
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码结构
- en: 'We used OpenAI’s embedding model to create these vectors, using the Embeddings
    endpoint. The endpoint can be called with the `openai.Embedding.create()` function,
    and takes in two arguments:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了OpenAI的嵌入模型来创建这些向量，通过Embedding端点来实现。可以通过`openai.Embedding.create()`函数调用该端点，传入两个参数：
- en: '**input**: This argument represents the text that you want to create embeddings
    for.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入**：此参数代表你想要创建嵌入的文本。'
- en: '**model**: This is the ID of the model you want to use for the embeddings.
    This is similar to the **model** parameter in other endpoints. In this example,
    we used the standard **ada** model, which was **text-embedding-ada-002**. OpenAI
    recommends using this as the starting embedding model as it’s quite affordable
    and still has excellent performance.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型**：这是你想要用来创建嵌入的模型ID。它与其他端点中的**模型**参数类似。在这个示例中，我们使用了标准的**ada**模型，即**text-embedding-ada-002**。OpenAI建议使用这个作为起始嵌入模型，因为它非常实惠，且性能优秀。'
- en: The function call returns an embedding object in JSON format, which we then
    parse through to get the embedding itself (which again is a list of numbers in
    Python). The parsing is done via the `["``data"][0]["embedding"]` code.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 函数调用返回一个JSON格式的嵌入对象，我们通过解析它来获取嵌入本身（这仍然是Python中的一个数字列表）。解析是通过`["``data"][0]["embedding"]`代码完成的。
- en: After we have the embeddings from two sets of text, we then need to compare
    them. How do you compare two vectors (i.e., how do you compare two lists of numbers?)?
    The most common method used is called **cosine similarity**. Cosine similarity
    measures the cosine of the angle between two vectors, resulting in a number between
    0 and 1.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在得到两组文本的嵌入后，我们需要对它们进行比较。如何比较两个向量（即如何比较两个数字列表）？最常用的方法叫做**余弦相似度**。余弦相似度衡量两个向量之间夹角的余弦值，结果是一个介于0和1之间的数值。
- en: Cosine similarity is often chosen over other similarity measuring techniques
    because it is particularly effective in high-dimensional spaces, such as text
    data, where it emphasizes the orientation rather than the magnitude of vectors.
    This approach allows it to focus on the directional alignment of the vectors,
    making it more robust in assessing the semantic similarity between texts, even
    when they vary in length or word frequency.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似度常被选用而非其他相似度测量方法，因为它在高维空间中（例如文本数据）特别有效，强调的是向量的方向而非大小。这种方法使它能够专注于向量的方向对齐，从而在评估文本之间的语义相似性时更加稳健，即使它们的长度或词频不同。
- en: 'The math does not matter here – the implication is that the higher the cosine
    similarity, the more closely the two texts are semantically related:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的数学细节不重要——其含义是余弦相似度越高，两个文本在语义上就越相关：
- en: '*Cosine similarity close to 1*: The texts are very similar or have similar
    context or meaning'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*余弦相似度接近 1*：文本非常相似或具有相似的上下文或含义'
- en: '*Cosine similarity close to 0*: The texts are unrelated'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*余弦相似度接近 0*：文本无关'
- en: '*Cosine similarity close to -1*: The texts are semantically opposite, which
    is rare in NLP because most text embeddings are designed to have non-negative
    components'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*余弦相似度接近 -1*：文本在语义上是相反的，这在自然语言处理（NLP）中很少见，因为大多数文本嵌入是设计成具有非负成分的'
- en: 'In Python, this is achieved through the following code, which takes the dot
    product of the two vectors and divides it by the product of the two vectors’ Euclidean
    norm:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，可以通过以下代码实现，它计算两个向量的点积，并将其除以这两个向量的欧几里得范数的乘积：
- en: '[PRE45]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: After we set up a function to return the embeddings for each text, and the function
    to compute the cosine similarity between two embeddings, we had all the tools
    we needed to compare two pieces of text.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们设置好一个函数来返回每个文本的嵌入，并计算两个嵌入之间的余弦相似度后，我们拥有了所有必要的工具来比较两段文本。
- en: The normalization in this formula (`norm`) ensures that we’re comparing the
    direction, rather than the magnitude, of the two vectors. This means we are focusing
    on how similar the two vectors are in terms of orientation, regardless of their
    length, which is essential for measuring similarity in many applications such
    as comparing sentences.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式中的归一化（`norm`）确保我们在比较的是两个向量的方向，而不是它们的大小。这意味着我们关注的是两个向量在方向上的相似度，而不考虑它们的长度，这在许多应用中非常重要，比如比较句子的相似性。
- en: Applications in text comparison
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本比较的应用
- en: 'Embeddings are an efficient way to compare two pieces of text, opening lots
    of different real-world applications. Recall the similarity scores that were computed
    in the recipe, described in the table that follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入是比较两段文本的高效方式，开启了许多不同的现实世界应用。回想一下在食谱中计算出的相似度得分，如下表所示：
- en: '| **Test** | **Base text** | **Comparison text** | **Cosine similarity** **of
    embeddings** |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| **测试** | **基础文本** | **比较文本** | **嵌入的余弦相似度** |'
- en: '| --- | --- | --- | --- |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **1** | I like apples | I like bananas | 0.90 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| **1** | 我喜欢苹果 | 我喜欢香蕉 | 0.90 |'
- en: '| All legislative Powers herein granted shall be vested in a Congress of the
    United States, which shall consist of a Senate and House of Representatives |
    0.71 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 所有在此授予的立法权力应由美国国会行使，该国会应由参议院和众议院组成 | 0.71 |'
- en: '| **2** | Birds like to *fly* | Airplanes can soar above the ground | 0.88
    |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| **2** | 鸟类喜欢*飞翔* | 飞机可以飞越地面 | 0.88 |'
- en: '| A *fly* can irritate me | 0.84 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 一只*苍蝇*能让我感到恼火 | 0.84 |'
- en: Table 4.2 – Cosine similarities between OpenAI embeddings for various sets of
    texts
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.2 – OpenAI 嵌入对不同文本集的余弦相似度
- en: The OpenAI API enables you to compute and rank the semantic similarity between
    different sets of text. Note that semantic similarity understands the nuances
    of the meaning of the text. In *Test 2*, the semantic similarity to *Airplanes
    can soar above the ground* was greater than *A fly can* *irritate me*.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI API 使你能够计算并排名不同文本集之间的语义相似度。请注意，语义相似度理解文本意义的细微差别。在*测试 2*中，*飞机可以飞越地面*与*一只苍蝇能让我感到恼火*的语义相似度更高。
- en: This is counterintuitive because you would assume that the text that shares
    the word *fly* would be more similar. However, the embeddings recognize that the
    word *fly* is used in a different context in *Birds like to fly* versus *A fly
    can irritate me*. In this case, embeddings are powerful mechanisms to compare
    the meanings of texts.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这有悖直觉，因为你可能会认为共享单词*苍蝇*的文本应该更为相似。然而，嵌入模型识别到单词*苍蝇*在*鸟类喜欢飞翔*和*一只苍蝇能让我感到恼火*中的使用上下文是不同的。在这种情况下，嵌入是比较文本意义的强大工具。
- en: 'There are other applications of embeddings that, thanks to OpenAI API, you
    can explore when building apps. This is not an exhaustive list but should be a
    good start for you to get some idea about the API’s potential:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入还有其他应用，得益于 OpenAI API，你可以在构建应用时进行探索。这不是一个详尽的列表，但应该能帮助你对 API 的潜力有所了解：
- en: '*Information retrieval with search engines*: Enhancing search algorithms to
    return results that are semantically related to the query, not just textually
    ([https://www.mage.ai/blog/building-semantic-search-engine-with-dual-space-word-embeddings](https://www.mage.ai/blog/building-semantic-search-engine-with-dual-space-word-embeddings))'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*搜索引擎中的信息检索*：增强搜索算法，使其返回与查询在语义上相关的结果，而不仅仅是文本上匹配的结果 ([https://www.mage.ai/blog/building-semantic-search-engine-with-dual-space-word-embeddings](https://www.mage.ai/blog/building-semantic-search-engine-with-dual-space-word-embeddings))'
- en: '*Document retrieval*: Finding documents that cover similar topics even if they
    don’t share the same keywords ([https://arxiv.org/pdf/1810.10176v2.pdf](https://arxiv.org/pdf/1810.10176v2.pdf))'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文档检索*：即使文档没有共享相同的关键词，也能找到涉及类似主题的文档 ([https://arxiv.org/pdf/1810.10176v2.pdf](https://arxiv.org/pdf/1810.10176v2.pdf))'
- en: '*Content recommendation systems*: Recommending articles, products, or media
    to users based on semantic similarity to items they have liked before ([https://towardsdatascience.com/introduction-to-embedding-based-recommender-systems-956faceb1919](https://towardsdatascience.com/introduction-to-embedding-based-recommender-systems-956faceb1919))'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*内容推荐系统*：根据用户之前喜欢的项目与当前项目在语义上的相似性，推荐文章、产品或媒体给用户 ([https://towardsdatascience.com/introduction-to-embedding-based-recommender-systems-956faceb1919](https://towardsdatascience.com/introduction-to-embedding-based-recommender-systems-956faceb1919))'
- en: '*Text classification*: Automatically classifying documents into predefined
    categories based on their semantic content ([https://realpython.com/python-keras-text-classification/](https://realpython.com/python-keras-text-classification/))'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文本分类*：根据语义内容自动将文档分类到预定义类别中 ([https://realpython.com/python-keras-text-classification/](https://realpython.com/python-keras-text-classification/))'
- en: Overall, the embeddings feature of the OpenAI API opens a plethora of other
    use cases, from text comparison to information retrieval. Another key benefit
    is that these endpoints are far cheaper than the Completions or Images endpoint,
    making it a powerful and efficient tool in your arsenal.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，OpenAI API 的嵌入功能开启了许多其他的使用案例，从文本比较到信息检索。另一个关键的好处是，这些端点比 Completions 或 Images
    端点便宜得多，成为了你工具库中强大而高效的工具。
- en: Fine-tuning a completion model
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调一个完成模型
- en: '**Fine-tuning** is the process of taking a pre-trained model and further adapting
    it to a specific task or dataset. The goal is typically to take an original model
    that has been trained on a large, general dataset and apply it to a more specialized
    domain or to improve its performance on a specific type of data.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**微调**是将一个预训练模型进一步适应特定任务或数据集的过程。其目标通常是将一个已经在大型通用数据集上训练的原始模型应用到更为专业的领域，或者提升其在特定类型数据上的表现。'
- en: We previously saw a version of fine-tuning in the first recipe within [*Chapter
    1*](B21007_01.xhtml#_idTextAnchor021), where we added examples of outputs in the
    `messages` parameter to *fine-tune* the output response. In this case, the model
    had not technically been fine-tuned – we instead performed **few-shot learning**,
    where we gave examples of the output within the prompt itself to the Chat Completion
    model. Fine-tuning, however, is a process where a whole new subset Chat Completion
    model is created with training data (inputs and outputs).
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前在 [*第一章*](B21007_01.xhtml#_idTextAnchor021) 的第一个食谱中看到过微调的一个版本，在那里我们通过 `messages`
    参数添加了输出示例来 *微调* 输出响应。在这个例子中，模型并没有真正地进行微调——我们实际上执行了 **少量学习**，即在提示中直接提供了输出示例给 Chat
    Completion 模型。然而，微调是一个过程，其中会创建一个全新的子集 Chat Completion 模型，并使用训练数据（输入和输出）进行训练。
- en: In this recipe, we will explore how to fine-tune a model and execute that fine-tuned
    model. Then, we will discuss the benefits and drawbacks of fine-tuning a model
    with the OpenAI API.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将探索如何微调一个模型并执行该微调后的模型。接着，我们将讨论使用 OpenAI API 微调模型的优缺点。
- en: How to do it…
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: Open up a new notebook by navigating to [https://colab.google/](https://colab.google/)
    and selecting **New Notebook** at the top right.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的笔记本，访问 [https://colab.google/](https://colab.google/) 并在右上角选择 **新建笔记本**。
- en: 'In the first cell, type in the following code and press *Shift* + *Enter* to
    run the code. This will install the OpenAI library and import the required modules
    for this recipe:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一个单元格中，输入以下代码并按 *Shift* + *Enter* 来运行代码。这将安装 OpenAI 库并导入本教程所需的模块：
- en: '[PRE46]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Similar to the previous recipe, type the following code into the cell below,
    replacing **<api-key>** with your OpenAI API key. Hit *Shift* + *Enter* to run
    the code:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似于前面的操作，输入以下代码到下方的单元格中，并将**<api-key>**替换为你的 OpenAI API 密钥。按 *Shift* + *Enter*
    来运行代码：
- en: '[PRE47]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Import the training data into Google Colab. The training data file can be found
    here: [https://drive.google.com/file/d/1x0ciWtW3phjPHAosiCL90qsQY--ZoxsV/view?usp=sharing](https://drive.google.com/file/d/1x0ciWtW3phjPHAosiCL90qsQY--ZoxsV/view?usp=sharing).
    To upload the file into Google Colab, select the *Files* icon on the left and
    select the **Upload File** button at the top of that menu. Both these icons have
    been highlighted in *Figure 4**.6*. Note that the training data includes several
    examples of where the prompt is a scenario (such as *A student in a library*)
    and the completion is a one-liner joke followed by *Haha* (such as *Why did the
    student bring a ladder to the library? Because they heard the knowledge was on
    the top* *shelf! Haha*).'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练数据导入到 Google Colab 中。训练数据文件可以在此找到：[https://drive.google.com/file/d/1x0ciWtW3phjPHAosiCL90qsQY--ZoxsV/view?usp=sharing](https://drive.google.com/file/d/1x0ciWtW3phjPHAosiCL90qsQY--ZoxsV/view?usp=sharing)。要将文件上传到
    Google Colab，请选择左侧的*文件*图标，并选择该菜单顶部的**上传文件**按钮。这两个图标在*图 4.6*中已被突出显示。请注意，训练数据包含多个示例，其中提示是一个场景（例如*图书馆里的学生*），而补全是一个单行笑话，后面跟着*Haha*（例如*为什么学生带梯子去图书馆？因为他们听说知识在最上层的*
    *书架*上！Haha*）。
- en: '![Figure 4.6 – How to add a file to Google Colab](img/B21007_04_06.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6 – 如何将文件添加到 Google Colab](img/B21007_04_06.jpg)'
- en: Figure 4.6 – How to add a file to Google Colab
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 如何将文件添加到 Google Colab
- en: 'Next, upload the training dataset to the OpenAI API, by typing in the following
    code and hitting *Shift* + *Enter*. We will also retrieve **file_id** from the
    upload:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，通过输入以下代码并按 *Shift* + *Enter*，将训练数据集上传到 OpenAI API。我们还将通过上传获取**file_id**：
- en: '[PRE48]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'After that, we will begin fine-tuning the model, by typing in the following
    code and hitting *Shift* + *Enter*. This will begin the fine-tuning process, by
    instructing OpenAI to use the file that we had previously uploaded through the
    **file_id** variable:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，我们将开始微调模型，通过输入以下代码并按 *Shift* + *Enter*。这将开始微调过程，指示 OpenAI 使用我们通过**file_id**变量上传的文件：
- en: '[PRE49]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Fine-tuning can take several minutes to finish. We can check the status of
    the job by typing in the following code and hitting *Shift* + *Enter*. If the
    output is *running*, that means the fine-tuning is still in process. Wait until
    the following code returns **succeeded**:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 微调可能需要几分钟时间才能完成。我们可以通过输入以下代码并按 *Shift* + *Enter* 来检查任务的状态。如果输出是*running*，意味着微调仍在进行中。等待直到代码返回**succeeded**：
- en: '[PRE50]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now that the fine-tuning job has been completed, we need the name of the fine-tuned
    model, which we can get by typing in the following code and hitting *Shift* +
    *Enter*. We will save this to the **fine_tuned_model** variable:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在微调任务已经完成，我们需要微调模型的名称，我们可以通过输入以下代码并按 *Shift* + *Enter* 来获得。我们将把它保存到**fine_tuned_model**变量中：
- en: '[PRE51]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Next, let’s use our fine-tuned model. Let’s create a simple chat completion
    request, but we will modify the **model** parameter to use the **fine_tuned_model**
    object that we had just created:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们使用我们微调过的模型。我们将创建一个简单的聊天补全请求，但我们会修改**model**参数，使用我们刚刚创建的**fine_tuned_model**对象：
- en: '[PRE52]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '![Figure 4.7 – Chat completion request and output when using a fine-tuned model](img/B21007_04_07.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7 – 使用微调模型时的聊天补全请求与输出](img/B21007_04_07.jpg)'
- en: Figure 4.7 – Chat completion request and output when using a fine-tuned model
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – 使用微调模型时的聊天补全请求与输出
- en: Note that without providing any examples, the completion output is a one-liner
    joke followed by the word **Haha**. We successfully fine-tuned a model and then
    used the fine-tuned model.
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，在没有提供任何示例的情况下，补全输出是一个单行笑话，后面跟着单词**Haha**。我们成功地微调了一个模型，并且使用了这个微调后的模型。
- en: How it works…
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In this recipe, we created a fine-tuned model by providing the OpenAI API with
    training data that taught the model how it should respond to prompts. In this
    case, we trained it so that its output should be a one-liner joke followed by
    the word `Haha`. We then changed the `model` parameter to the ID of the model
    we just created, and made a *chat completion* request. After that, we noted that
    the output we received on a prompt it had never seen before also resulted in a
    one-liner joke followed by the word `Haha`. In essence, we had successfully fine-tuned
    the *gpt-3.5-turbo* model to tell one-liner jokes given any prompt.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方案中，我们通过向 OpenAI API 提供训练数据来创建了一个微调后的模型，这些数据教会模型如何响应提示。在这个案例中，我们训练它使得它的输出应该是一个笑话，并紧接着是词语
    `Haha`。然后，我们将 **model** 参数更改为我们刚刚创建的模型 ID，并进行了一次 *聊天完成* 请求。之后，我们注意到，模型对从未见过的提示生成的输出，也同样是一个笑话，后面跟着
    `Haha`。从本质上讲，我们成功地微调了 *gpt-3.5-turbo* 模型，使其能够在给定任何提示时讲一个笑话。
- en: Fine-tuning steps
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微调步骤
- en: 'There are five steps that need to be followed when fine-tuning a model and
    then using that fine-tuned model:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 微调模型并使用该微调模型时需要遵循五个步骤：
- en: '*Prepare a training data file*: The training data consists of examples or prompts
    and desired completions. You need at least 10 examples to successfully train a
    model. Each example looks very similar (with purposeful intent) to the **messages**
    parameter when making a chat completion request. The difference, however, is that
    it also includes the completion (also known as the output from the assistant).
    Here is an example:'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*准备训练数据文件*：训练数据由示例或提示和期望的完成组成。至少需要 10 个示例才能成功训练模型。每个示例看起来非常相似（有明确的意图），与进行聊天完成请求时的
    **messages** 参数类似。不同之处在于，它还包括完成部分（也就是助手的输出）。以下是一个示例：'
- en: '[PRE53]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: These examples can be added to a JSON file, with each line representing one
    example.
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些示例可以添加到 JSON 文件中，每行代表一个示例。
- en: '![Figure 4.8 – Image of JSON file containing training data](img/B21007_04_08.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.8 – 包含训练数据的 JSON 文件图像](img/B21007_04_08.jpg)'
- en: Figure 4.8 – Image of JSON file containing training data
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – 包含训练数据的 JSON 文件图像
- en: '*Import to OpenAI*: After the training file has been made, it needs to be uploaded
    to OpenAI’s servers, which is what we did with the following code:'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*导入到 OpenAI*：训练文件制作完成后，需要将其上传到 OpenAI 的服务器，这就是我们使用以下代码所做的：'
- en: '[PRE54]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '*Assign an ID*: After uploading the file, the API assigns it an ID. This ID
    can be determined by looking at the response JSON from the preceding code, and
    parsing for the **id** parameter:'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*分配 ID*：上传文件后，API 会分配一个 ID。可以通过查看前面的代码响应 JSON，并解析 **id** 参数来确定该 ID：'
- en: '[PRE55]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '*Fine-tune the model*: After that, we need to instruct the API to fine-tune
    the model using the uploaded training data. We will put the response that we get
    from the API in a variable:'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*微调模型*：之后，我们需要指示 API 使用上传的训练数据来微调模型。我们会将从 API 获取的响应存储在一个变量中：'
- en: '[PRE56]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'After the fine-tuning job is complete, the API will assign a `fine_tuned_model`
    parameter, giving the fine-tuned model a particular identifier, which we can store
    in a variable:'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 微调任务完成后，API 将分配一个 `fine_tuned_model` 参数，给微调后的模型一个特定的标识符，我们可以将其存储在一个变量中：
- en: '[PRE57]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '*Use the fine-tuned model*: The last step is fairly easy – call the Chat Completions
    API as normal but modify the **model** parameter to the newly fine-tuned model
    that was just created:'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用微调后的模型*：最后一步相对简单——像平常一样调用聊天完成 API，但将 **model** 参数修改为刚刚创建的微调模型：'
- en: '[PRE58]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Benefits of fine-tuning
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微调的好处
- en: Fine-tuning improves few-shot learning by allowing you to train on many more
    examples than what would fit in a typical prompt context window. Once a model
    has been tuned, these examples are not needed every single time when making a
    completions request, thereby saving tokens (and costs) and resulting in lower
    latency (i.e., faster speed). Recall that tokens are the smallest units of meaning
    in a piece of text (typically words, punctuation marks, or other elements) used
    in NLP and often form the basis of how OpenAI charges chat completion requests.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 微调通过允许你在比典型提示上下文窗口所能容纳的更多示例上进行训练，来改善少量样本学习。一旦模型被调优，这些示例在每次进行完成请求时就不再需要，从而节省了
    token（和费用），并降低了延迟（即更快的速度）。请记住，token 是文本中最小的语义单位（通常是单词、标点符号或其他元素），在自然语言处理（NLP）中常常构成
    OpenAI 收费的基础。
- en: For example, let’s go through the number of tokens for two models (i) one that
    uses the *gpt-3.5* base model without any fine-tuning, but we need to include
    examples in the prompt every time, and (ii) a fine-tuned model.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们来比较两种模型的token数量：(i)一个使用*Gpt-3.5*基础模型且没有微调，但每次都需要在提示中加入示例的模型，和(ii)一个微调后的模型。
- en: '| **Model** | **Gpt-3.5** | **Gpt-3.5 that has** **been fine-tuned** |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **Gpt-3.5** | **已微调的Gpt-3.5** |'
- en: '| --- | --- | --- |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Prompt** | You are an assistant who creates funny one-line jokes based
    on a given scenario. Here are 10 examples:A knight getting ready for a battle
     Why was the knight always calm before battle? Because he was good at keeping
    his “armor” cool! Haha… [9 more examples] …Scenario: A penguin in the Arctic |
    You are an assistant who creates funny one-line jokes based on a given scenario.Scenario:
    A penguin in the Arctic |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| **提示** | 你是一个基于给定场景创作幽默单句笑话的助手。这里有10个例子：一位骑士准备上战场  为什么骑士在战斗前总是很冷静？因为他擅长保持他的“盔甲”冷静！哈哈……[还有9个例子]……场景：北极的一只企鹅
    | 你是一个基于给定场景创作幽默单句笑话的助手。场景：北极的一只企鹅 |'
- en: '| **Number of tokens in** **prompt (estimated)** | 400 | 36 |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| **提示中的token数量（估算）** | 400 | 36 |'
- en: Table 4.3 – Comparison of prompt examples and number of tokens between a non-fine-tuned
    and a fine-tuned GPT-3.5 model
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.3 – 非微调与微调后的GPT-3.5模型之间的提示示例和token数量比较
- en: A fine-tuned model uses about one-tenth of the number of tokens as the few-shot
    base model. This means that using a fine-tuned model can result in 90% cost savings,
    which can be very high if you deploy these models to heavily used applications.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 微调后的模型使用的token数量约为少量学习基础模型的十分之一。这意味着，使用微调后的模型可以节省90%的成本，如果将这些模型部署到高频使用的应用中，这个节省是非常可观的。
- en: Other benefits of fine-tuning include higher-quality results by being able to
    train on thousands of examples, which is not possible using few-shot learning
    as there is a maximum length for the prompt.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 微调的其他好处包括通过能够在数千个示例上进行训练，从而获得更高质量的结果，而这在使用少量学习时是无法实现的，因为提示词的长度有限。
- en: Note
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: Fine-tuning a model to get better-quality results should only be done after
    sufficient attempts at prompt engineering and prompt chaining have been made.
    Fine-tuning a model requires significant resources and effort, so it’s more efficient
    to first exhaust the potential of prompt engineering and prompt chaining, which
    can often achieve desired results without additional training. **Prompt engineering**
    refers to creating more detailed and structured prompts to yield better completions.
    **Prompt chaining** is the idea of breaking down more complex prompts into simpler
    tasks.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 微调模型以获得更高质量的结果应该仅在充分尝试过提示工程和提示链的优化之后进行。微调模型需要大量资源和精力，因此首先最大化提示工程和提示链的潜力更为高效，因为它们通常能够在不需要额外训练的情况下实现预期的结果。**提示工程**是指创建更详细和结构化的提示，以获得更好的完成效果。**提示链**是将更复杂的提示分解为更简单任务的理念。
- en: Applications of fine-tuning
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微调的应用
- en: 'When would you resort to fine-tuning a model rather than (i) using the base
    *gpt-3.5* or *gpt4* model, or (ii) using few-shot learning to prime the model
    instead? In general, here are some of the common use cases where you would need
    to fine-tune the model:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 什么时候你会选择微调模型，而不是(i)使用基础的 *gpt-3.5* 或 *gpt4* 模型，或(ii)使用少量学习来预先训练模型呢？一般来说，以下是一些常见的需要微调模型的使用场景：
- en: '*Enhancement of desired outputs*: Fine-tuning is crucial when there’s a need
    for more reliability in generating specific types of responses. By training the
    model on a specialized dataset, you can increase the chances that it will produce
    the desired output consistently. This is common in content creation for a particular
    brand voice, creating educational resources that must follow a specific language,
    and so on.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*增强期望输出*：当需要在生成特定类型的响应时获得更高的可靠性时，微调至关重要。通过在专门的数据集上训练模型，您可以增加模型一致性地产生期望输出的机会。这在特定品牌语音的内容创作、必须遵循特定语言的教育资源创建等方面非常常见。'
- en: '*Complex prompt compliance*: In instances where the model consistently fails
    to adhere to complex prompts or instructions, fine-tuning can help correct these
    shortcomings. This ensures that the model better understands and follows detailed
    or multifaceted instructions. This is very common when creating programming assistants,
    for example.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*复杂提示遵从性*：当模型在多次尝试后仍无法始终遵循复杂的提示或指令时，微调可以帮助纠正这些不足。这可以确保模型更好地理解和遵循详细或多层次的指令。例如，在创建编程助手时，这种情况非常常见。'
- en: '*Specialized style and tone adjustments*: When a certain style, tone, or format
    is required – for example, legal language, a comedic tone, or a journalistic style
    – fine-tuning adjusts the model to capture these qualitative aspects more accurately.
    This is common when developing *customer service bots* – where the bots need to
    maintain a kind but firm tone.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*专门化风格和语气调整*：当需要特定风格、语气或格式时——例如法律语言、幽默语气或新闻风格——微调能帮助模型更准确地捕捉这些定性方面。这在开发*客户服务机器人*时非常常见，因为这些机器人需要保持既友善又坚定的语气。'
- en: '*Custom task performance*: For teaching the model a new skill or task that
    is difficult to convey through a prompt alone, fine-tuning allows the model to
    learn from examples. This is particularly useful for niche applications or innovative
    tasks that the base model may not have been exposed to during its initial training,
    or more complex tasks such as *dictating a* *medical diagnosis*.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*定制任务性能*：对于教授模型一项新技能或任务，如果单靠提示无法传达，微调让模型可以通过示例学习。这对一些特定领域的应用或创新任务尤其有用，这些任务可能在模型初始训练时没有接触过，或者像*医疗诊断*这样的更复杂任务。'
- en: Overall, fine-tuning a model is a great, cost-efficient way to get higher-quality,
    consistent results. This is especially useful if you intend to build applications
    where similar prompts and responses are expected, and where a particular tone
    and style is required.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，微调模型是一种非常好的、高性价比的方式，可以获得更高质量、一致性的结果。如果你打算构建一些预期类似提示和响应的应用程序，且需要特定的语气和风格，这种方法尤其有用。
