- en: '*Chapter 6*: Training Models with Visual Data'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第六章*：使用视觉数据训练模型'
- en: Deep learning has been successfully applied to many different types of data,
    including tabular data, text data, and recommender system data. You saw fastai's
    approach to these types of data in [*Chapter 3*](B16216_03_Final_VK_ePub.xhtml#_idTextAnchor083),
    *Training Models with Tabular Data*, [*Chapter 4*](B16216_04_Final_VK_ePub.xhtml#_idTextAnchor109),
    *Training Models with Text Data*, and [*Chapter 5*](B16216_05_Final_VK_ePub.xhtml#_idTextAnchor134),
    *Training Recommender Systems*. These types of data are all part of the story
    of deep learning, but **visual data** or **image data** is the type of data that
    is traditionally associated most closely with deep learning.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习已经成功应用于许多不同类型的数据，包括表格数据、文本数据和推荐系统数据。在[*第3章*](B16216_03_Final_VK_ePub.xhtml#_idTextAnchor083)
    *使用表格数据训练模型*、[*第4章*](B16216_04_Final_VK_ePub.xhtml#_idTextAnchor109) *使用文本数据训练模型*
    和 [*第5章*](B16216_05_Final_VK_ePub.xhtml#_idTextAnchor134) *训练推荐系统* 中，你已经见识过fastai对这些类型数据的处理方法。这些数据类型都是深度学习故事的一部分，但**视觉数据**或**图像数据**是传统上与深度学习最紧密相关的数据类型。
- en: Visual data is also the type of data that is most thoroughly supported by the
    fastai framework. The fastai high-level API is mostly developed for visual data,
    and 70% of the curated fastai datasets are visual datasets. In this chapter, we
    will explore some of the features that fastai provides for exploring visual datasets
    and building high-performance deep learning models with image datasets.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉数据也是fastai框架最全面支持的数据类型。fastai的高级API主要是为视觉数据开发的，70%的精选fastai数据集都是视觉数据集。在本章中，我们将探索fastai为探索视觉数据集和构建高性能深度学习图像模型所提供的一些功能。
- en: In this chapter, you will learn how to use the rich set of facilities available
    in fastai for preparing image datasets and using them to train deep learning models.
    In particular, you will learn how to create fastai deep learning models that classify
    images, that is, determine what objects are in images, and also how to use fastai
    to identify multiple objects in the same image.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何使用fastai提供的一套丰富功能来准备图像数据集，并使用这些数据集训练深度学习模型。特别是，你将学习如何创建fastai深度学习模型来分类图像，即确定图像中的对象是什么，同时也将学习如何使用fastai来识别同一图像中的多个对象。
- en: 'Here are the recipes that will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: Training a classification model with a simple curated vision dataset
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用简单精选视觉数据集训练分类模型
- en: Exploring a curated image location dataset
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索精选图像位置数据集
- en: Training a classification model with a standalone vision dataset
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用独立视觉数据集训练分类模型
- en: Training a multi-image classification model with a curated vision dataset
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用精选视觉数据集训练多图像分类模型
- en: Test your knowledge
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试你的知识
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Ensure that you have completed the setup sections from [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*, and have a working Gradient instance or Colab set
    up. The recipes described in this chapter assume that you are using Gradient.
    Ensure that you have cloned the repo for this book from [https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook](https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook)
    and have access to the `ch6` folder. This folder contains the code samples described
    in this chapter.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保你已经完成了[*第1章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019) *快速入门fastai*
    中的设置部分，并且已经成功设置了Gradient实例或Colab环境。本章中的食谱假设你正在使用Gradient。请确保你已经从[https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook](https://github.com/PacktPublishing/Deep-Learning-with-fastai-Cookbook)克隆了本书的代码库，并且能够访问`ch6`文件夹。该文件夹包含本章中描述的代码示例。
- en: Training a classification model with a simple curated vision dataset
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用简单精选视觉数据集训练分类模型
- en: You may recall the first fastai model that you trained back in [*Chapter 1*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019),
    *Getting Started with fastai*. That model was trained on the MNIST dataset of
    hand-written digits. Given an image of a hand-written digit, that model was able
    to classify the image, that is, determine which of the digits from 0 to 9 were
    shown in the image.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得你在[*第1章*](B16216_01_Final_VK_ePub.xhtml#_idTextAnchor019)中训练的第一个fastai模型，*快速入门fastai*。那个模型是使用MNIST手写数字数据集训练的。给定一张手写数字的图像，那个模型能够对图像进行分类，即确定图像中显示的是从0到9的哪个数字。
- en: 'In this recipe, you are going to apply the same approach you saw in the MNIST
    model to another fastai curated dataset: the CIFAR dataset. This dataset, which
    is a subset of a larger curated CIFAR_100 dataset, is made up of 6,000 images
    organized into 10 categories. The model that you train in this section will be
    able to determine the category that an image from this dataset belongs to.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，你将应用在 MNIST 模型中看到的相同方法，使用另一个 fastai 精选数据集：CIFAR 数据集。这个数据集是更大 CIFA_100
    数据集的一个子集，包含 6000 张图像，按 10 个类别进行组织。在本节中，你训练的模型将能够确定来自该数据集的图像所属的类别。
- en: Getting ready
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Confirm that you can open the `training_with_curated_image_datasets.ipynb` notebook
    in the `ch6` directory of your repo.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 确认你可以在仓库的 `ch6` 目录中打开 `training_with_curated_image_datasets.ipynb` 笔记本。
- en: Note
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 注意事项
- en: The images in the `CIFAR` dataset are quite small. In this section, we have
    rendered them in a larger size to make them easier to recognize in the context
    of the book, but the outcome is that they can look a bit blurry.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`CIFAR` 数据集中的图像相当小。在本节中，我们将它们以更大的尺寸呈现，以便在书中的上下文中更容易识别，但结果是它们看起来可能有些模糊。'
- en: The `CIFAR` dataset featured in this section is introduced in the paper *Learning
    Multiple Layers of Features from Tiny Image*, Krizhevsky, 2009\. I am grateful
    for the opportunity to include this dataset in this book.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中介绍的 `CIFAR` 数据集在论文 *Learning Multiple Layers of Features from Tiny Image*（Krizhevsky，2009）中有所介绍。我很感激能有机会将这个数据集包含在本书中。
- en: Dataset citation
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: 'Alex Krizhevsky. (2009). *Learning Multiple Layers of Features from Tiny Image*. University
    of Toronto: [https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 'Alex Krizhevsky. (2009). *Learning Multiple Layers of Features from Tiny Image*. University
    of Toronto: [https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf).'
- en: How to do it…
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In this section, you will be running through the `training_with_curated_image_datasets.ipynb`
    notebook. Once you have the notebook open in your fastai environment, complete
    the following steps:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将运行 `training_with_curated_image_datasets.ipynb` 笔记本。一旦你在 fastai 环境中打开该笔记本，请完成以下步骤：
- en: Run the cells in the notebook up to the `Ingest the dataset` cell to import
    the required libraries and set up your notebook.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行笔记本中的单元格，直到 `Ingest the dataset` 单元格，以导入所需的库并设置笔记本环境。
- en: 'Run the following cell to define the `path` object for this dataset:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以定义此数据集的 `path` 对象：
- en: '[PRE0]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Run the following cell to examine the directory structure of the dataset:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以检查数据集的目录结构：
- en: '[PRE1]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output shows the directory structure of the dataset, as shown in the following
    screenshot:'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示了数据集的目录结构，如下截图所示：
- en: '![Figure 6.1 – Output of path.ls()'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.1 – path.ls() 的输出'
- en: '](img/B16216_6_1.jpg)'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_1.jpg)'
- en: Figure 6.1 – Output of path.ls()
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.1 – path.ls() 的输出
- en: 'Run the following cell to define an `ImageDataLoaders` object for this dataset:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以为此数据集定义一个 `ImageDataLoaders` 对象：
- en: '[PRE2]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here are the arguments for the definition of the `ImageDataLoaders` object:'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是定义 `ImageDataLoaders` 对象的参数：
- en: 'a) `path`: Specifies that the `ImageDataLoaders` object is defined using the
    `path` object you created in the previous cell'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `path`：指定 `ImageDataLoaders` 对象是通过你在前一个单元格中创建的 `path` 对象定义的
- en: 'b) `train=''train''`: Specifies that the training data is in the `/storage/data/cifar10/train`
    directory'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `train='train'`：指定训练数据位于 `/storage/data/cifar10/train` 目录中
- en: 'c) `valid=''test''`: Specifies that the validation data is in the `/storage/data/cifar10/test`
    directory'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `valid='test'`：指定验证数据位于 `/storage/data/cifar10/test` 目录中
- en: 'Run the following cell to display a batch from the dataset:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以显示数据集中的一批图像：
- en: '[PRE3]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output of this cell is a set of `4` items from a batch, showing images
    along with their corresponding categories, as shown in the following figures:'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该单元格的输出是一组 `4` 项来自一批数据，显示图像及其对应的类别，如下图所示：
- en: '![Figure 6.2 – Output of show_batch()'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.2 – show_batch() 的输出'
- en: '](img/B16216_6_2.jpg)'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_2.jpg)'
- en: Figure 6.2 – Output of show_batch()
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.2 – show_batch() 的输出
- en: 'Run the following cell to examine the contents of the `train` subdirectory:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以检查 `train` 子目录的内容：
- en: '[PRE4]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output shows the structure of the `train` subdirectory, as shown in the
    following screenshot:'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示了 `train` 子目录的结构，如下截图所示：
- en: '![Figure 6.3 – Contents of the train subdirectory'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.3 – train 子目录的内容'
- en: '](img/B16216_6_3.jpg)'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_3.jpg)'
- en: Figure 6.3 – Contents of the train subdirectory
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.3 – train 子目录的内容
- en: 'Run the following cell to examine the contents of the `train/dog` subdirectory:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格检查`train/dog`子目录的内容：
- en: '[PRE5]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output shows the structure of the `train/dog` subdirectory:'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示了`train/dog`子目录的结构：
- en: '![Figure 6.4 – Contents of the train/dog subdirectory'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.4 – `train/dog`子目录的内容'
- en: '](img/B16216_6_4.jpg)'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_4.jpg)'
- en: Figure 6.4 – Contents of the train/dog subdirectory
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.4 – `train/dog`子目录的内容
- en: 'If you want to take a different perspective as regards the directory structure
    of this dataset, you can use the `tree` command. To do this, from the Gradient
    terminal, enter the following commands:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想从不同的角度查看该数据集的目录结构，可以使用`tree`命令。为此，在Gradient终端中输入以下命令：
- en: '[PRE6]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ├── test
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ├── test
- en: │   ├── airplane
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: │   ├── airplane
- en: │   ├── automobile
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: │   ├── automobile
- en: │   ├── bird
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: │   ├── bird
- en: │   ├── cat
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: │   ├── cat
- en: │   ├── deer
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: │   ├── deer
- en: │   ├── dog
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: │   ├── dog
- en: │   ├── frog
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: │   ├── frog
- en: │   ├── horse
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: │   ├── horse
- en: │   ├── ship
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: │   ├── ship
- en: │   └── truck
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: │   └── truck
- en: └── train
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: └── train
- en: ├── airplane
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ├── airplane
- en: ├── automobile
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ├── automobile
- en: ├── bird
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ├── bird
- en: ├── cat
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ├── cat
- en: ├── deer
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ├── deer
- en: ├── dog
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ├── dog
- en: ├── frog
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ├── frog
- en: ├── horse
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ├── horse
- en: ├── ship
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ├── ship
- en: └── truck
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: └── truck
- en: '[PRE7]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Run the following cell to view a single item in the dataset:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格查看数据集中的单个项目：
- en: '[PRE8]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here are the key elements of this cell:'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是该单元格的关键元素：
- en: 'a) `img_files = get_image_files(path)`: Specifies that `path` is recursively
    examined and returns all the image files in the path. If you want more details
    about `get_image_files`, you can check out the documentation at the following
    link: [https://docs.fast.ai/data.transforms.html#get_image_files](https://docs.fast.ai/data.transforms.html#get_image_files).'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `img_files = get_image_files(path)`：指定`path`将被递归地检查，并返回路径中所有的图片文件。如果你想了解更多关于`get_image_files`的细节，可以查看以下文档：[https://docs.fast.ai/data.transforms.html#get_image_files](https://docs.fast.ai/data.transforms.html#get_image_files)。
- en: 'b) `img = PILImage.create(img_files[100])`: Creates the image object, `img`,
    from a specific file returned by the previous statement.'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `img = PILImage.create(img_files[100])`：从先前语句返回的特定文件创建图像对象`img`。
- en: 'The output of this cell is one of the dataset files rendered as an image in
    the notebook, as shown here:'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该单元格的输出是数据集文件之一，在笔记本中呈现为图像，如下所示：
- en: '![Figure 6.5 – An image from the dataset'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.5 – 数据集中的一张图片'
- en: '](img/B16216_6_5.jpg)'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_5.jpg)'
- en: Figure 6.5 – An image from the dataset
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.5 – 数据集中的一张图片
- en: 'Run the following cell to display another image from the dataset:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格显示数据集中的另一张图片：
- en: '[PRE9]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output is another of the dataset files rendered as an image in the notebook
    as follows:'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出是数据集中的另一张图像，已在笔记本中呈现如下：
- en: '![Figure 6.6 – Another image from the dataset'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.6 – 数据集中的另一张图片'
- en: '](img/B16216_6_6.jpg)'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_6.jpg)'
- en: Figure 6.6 – Another image from the dataset
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.6 – 数据集中的另一张图片
- en: 'Run the following cell to define the model as a `cnn_learner` object:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格将模型定义为`cnn_learner`对象：
- en: '[PRE10]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here are the arguments for the definition of the `cnn_learner` object:'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是定义`cnn_learner`对象的参数：
- en: 'a) `dls`: Specifies that the model uses the `ImageDataLoaders` object, `dls`,
    that you defined in *Step 4*'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `dls`：指定模型使用你在*步骤 4*中定义的`ImageDataLoaders`对象`dls`。
- en: 'b) `resnet18`: Specifies the pre-trained model to use as a starting point for
    this model'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `resnet18`：指定使用预训练模型`resnet18`作为该模型的起点。
- en: 'c) `loss_func=LabelSmoothingCrossEntropy()`: Specifies the loss function to
    use in the training process'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `loss_func=LabelSmoothingCrossEntropy()`：指定训练过程中使用的损失函数。
- en: 'd) `metrics=accuracy`: Specifies that `accuracy` is the performance metric
    that will be optimized in the training process'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `metrics=accuracy`：指定`accuracy`为训练过程中优化的性能度量标准。
- en: 'Run the following cell to train the model:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格训练模型：
- en: '[PRE11]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The argument indicates that the training run will be for `5` epochs.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该参数表示训练将进行`5`个周期。
- en: 'The output displays the training loss, validation loss, and accuracy for each
    epoch, as shown in the following screenshot:'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示了每个周期的训练损失、验证损失和准确率，如下截图所示：
- en: '![Figure 6.7 – Output of training the model'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.7 – 模型训练输出'
- en: '](img/B16216_6_7.jpg)'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_7.jpg)'
- en: Figure 6.7 – Output of training the model
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.7 – 模型训练输出
- en: 'Let''s try out the trained model on some examples from the test dataset. First,
    run the following cell to define an object for one of the images in the test dataset:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们尝试使用训练好的模型对测试数据集中的一些示例进行预测。首先，运行以下单元格为测试数据集中的一张图片定义一个对象：
- en: '[PRE12]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here are the key elements of this cell:'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是该单元格的关键元素：
- en: 'a) `img_files = get_image_files(path/"test"))`: Returns all the image files
    under the `test` directory'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `img_files = get_image_files(path/"test")`：返回`test`目录下的所有图像文件
- en: 'b) `img = PILImage.create(img_files[700])`: Creates the image object, `img2`,
    from a specific file returned by the previous statement'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `img = PILImage.create(img_files[700])`：从前一个语句返回的特定文件创建图像对象`img2`
- en: 'The output of this cell is an image of a dog:'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个单元格的输出是一张狗的图像：
- en: '![Figure 6.8 – Dog image from the test dataset'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.8 – 测试数据集中的狗图像'
- en: '](img/B16216_6_8.jpg)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_8.jpg)'
- en: Figure 6.8 – Dog image from the test dataset
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.8 – 测试数据集中的狗图像
- en: 'Run the following cell to define an object for another one of the images in
    the test dataset:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格，为测试数据集中的另一张图像定义一个对象：
- en: '[PRE13]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output of this cell is an image of a bird:'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个单元格的输出是一张鸟类图像：
- en: '![Figure 6.9 – Bird image from the test dataset'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.9 – 测试数据集中的鸟类图像'
- en: '](img/B16216_6_9.jpg)'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_9.jpg)'
- en: Figure 6.9 – Bird image from the test dataset
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.9 – 测试数据集中的鸟类图像
- en: 'Now that we have defined objects for a couple of images from the test dataset,
    let''s exercise the trained image classification model on them. First, run the
    following cell to apply the model to the dog image:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经为测试数据集中的几张图像定义了对象，让我们在这些图像上运行训练好的图像分类模型。首先，运行以下单元格，将模型应用于狗的图像：
- en: '[PRE14]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The output of this cell is the model''s prediction, as shown in the following
    screenshot. Note that the model correctly predicts the category of the image:'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个单元格的输出是模型的预测，见下图。注意，模型正确地预测了图像的类别：
- en: '![Figure 6.10 – Image classification model''s prediction on the dog image'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.10 – 图像分类模型在狗图像上的预测'
- en: '](img/B16216_6_10.jpg)'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_10.jpg)'
- en: Figure 6.10 – Image classification model's prediction on the dog image
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.10 – 图像分类模型在狗图像上的预测
- en: 'Let''s now see how the model does with the image of a bird. Run the following
    cell to apply the model to the bird image:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们看看模型在鸟类图像上的表现。运行以下单元格来将模型应用于鸟类图像：
- en: '[PRE15]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output of this cell is the model''s prediction, as shown in the following
    screenshot. Note that the model correctly predicts that the image is a bird:'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个单元格的输出是模型的预测，见下图。注意，模型正确地预测了这张图像是鸟类：
- en: '![Figure 6.11 – Image classification model''s prediction on the bird image'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.11 – 图像分类模型在鸟类图像上的预测'
- en: '](img/B16216_6_11.jpg)'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_11.jpg)'
- en: Figure 6.11 – Image classification model's prediction on the bird image
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.11 – 图像分类模型在鸟类图像上的预测
- en: 'Now that we have successfully exercised the model, let''s save it. Run the
    following cell to save the model:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经成功地训练了模型，让我们保存它。运行以下单元格来保存模型：
- en: '[PRE16]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here is what the statements in this cell do:'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是这个单元格中语句的作用：
- en: 'a) `learn.path = Path(''/notebooks/temp'')`: Sets the path of the `learn` object
    to a directory that can be written to. Remember that in Gradient, by default,
    the path for the `learn` object is read-only, so you need to adjust the path to
    a writeable directory before you can save the model.'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `learn.path = Path('/notebooks/temp')`：将`learn`对象的路径设置为可以写入的目录。请记住，在Gradient中，默认情况下，`learn`对象的路径是只读的，因此你需要将路径调整为可写目录，才能保存模型。
- en: 'b) `learn.export(''cifar_apr20_2021.pkl'')`: Specifies that the name of the
    model to be saved is `cifar_apr20_2021.pkl`.'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `learn.export('cifar_apr20_2021.pkl')`：指定保存的模型名称为`cifar_apr20_2021.pkl`。
- en: After you have run this cell in Gradient, your model is saved in `/notebooks/temp/model/cifar_apr20_2021.pkl`.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在Gradient中运行此单元格后，你的模型将保存到`/notebooks/temp/model/cifar_apr20_2021.pkl`。
- en: Congratulations! You have trained and exercised a fastai image classification
    model using a curated image dataset.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经使用精心挑选的图像数据集，训练并执行了一个fastai图像分类模型。
- en: How it works…
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: Some important things are going on in the recipe in this section that are worth
    reviewing. In this section, we'll go over some of the details that might not have
    been evident in the main part of the recipe.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的配方中，有一些重要的内容值得回顾。在这一部分，我们将讨论一些在配方主干部分可能不太明显的细节。
- en: Labels are encoded in directory names and filenames
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标签在目录名和文件名中进行编码
- en: 'First, consider the names of the files that make up the dataset. The files
    in the `train/dog` subdirectory are shown here:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，考虑构成数据集的文件名。`train/dog`子目录中的文件如下所示：
- en: '![Figure 6.12 – Files in the train/dog subdirectory'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.12 – `train/dog`子目录中的文件'
- en: '](img/B16216_6_12.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_12.jpg)'
- en: Figure 6.12 – Files in the train/dog subdirectory
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.12 – `train/dog`子目录中的文件
- en: 'The files in the `train/cat` subdirectory are shown here:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`train/cat`子目录中的文件如下所示：'
- en: '![Figure 6.13 – Files in the train/cat subdirectory'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.13 – train/cat子目录中的文件'
- en: '](img/B16216_6_13.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_13.jpg)'
- en: Figure 6.13 – Files in the train/cat subdirectory
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.13 – train/cat子目录中的文件
- en: 'Let''s take a look at a sample file from each of these subdirectories. To display
    an image file from the `train/dog` subdirectory, run the following cell:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下这些子目录中每个目录的一个示例文件。要显示来自`train/dog`子目录的图像文件，请运行以下单元格：
- en: '[PRE17]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output of this cell is indeed an image of a dog, as shown here:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 该单元格的输出确实是一张狗的图像，如下所示：
- en: '![Figure 6.14 – A dog image from the training dataset'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.14 – 来自训练数据集的狗的图像'
- en: '](img/B16216_6_14.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_14.jpg)'
- en: Figure 6.14 – A dog image from the training dataset
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.14 – 来自训练数据集的狗的图像
- en: 'To display an image file from the `train/cat` subdirectory, run the following
    cell:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 要显示来自`train/cat`子目录的图像文件，请运行以下单元格：
- en: '[PRE18]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The output of this cell is, as expected, an image of a cat, as shown here:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 该单元格的输出，如预期所示，是一张猫的图像，如下所示：
- en: '![Figure 6.15 – A cat image from the training dataset'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.15 – 来自训练数据集的猫的图像'
- en: '](img/B16216_6_15.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_15.jpg)'
- en: Figure 6.15 – A cat image from the training dataset
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.15 – 来自训练数据集的猫的图像
- en: 'For this image classification problem, the model is trying to predict the label
    for an image, that is, the category, such as dog, deer, or bird, of the object
    that is shown in the image. For this dataset, the label is encoded in the following
    two ways:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个图像分类问题，模型正试图预测图像的标签，即图像中所示对象的类别，例如狗、鹿或鸟。对于这个数据集，标签以以下两种方式编码：
- en: '**The name of the directory containing the image file**. As you can see in
    *Figure 6.14* and *Figure 6.15*, the label for an image is encoded in the name
    of the subdirectory where the image is located.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**包含图像文件的目录名称**。如你在*图 6.14*和*图 6.15*中看到的那样，图像的标签是通过图像所在子目录的名称进行编码的。'
- en: '`xxxx_dog.png`, and the cat images have filenames of the form `xxxx_cat.png`.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xxxx_dog.png`的文件名，猫的图像文件名则为`xxxx_cat.png`。'
- en: You used transfer learning to train the image classification model
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你使用迁移学习训练了图像分类模型
- en: 'In [*Chapter 4*](B16216_04_Final_VK_ePub.xhtml#_idTextAnchor109), *Training
    Models with Text Data*, we used transfer learning to adapt an existing trained
    model to work with a dataset for a particular use case. You may not have noticed
    it, but we did the same thing in this recipe. There''s a clue in the cell where
    you defined the `cnn_learner` object as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第 4 章*](B16216_04_Final_VK_ePub.xhtml#_idTextAnchor109)中，*使用文本数据训练模型*，我们使用迁移学习将现有的训练模型调整为适应特定用例的数据集。你可能没有注意到，但我们在这个示例中做了同样的事情。线索就在定义`cnn_learner`对象的单元格中，具体如下：
- en: '[PRE19]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the definition of `cnn_learner`, the `resnet18` argument is the pre-trained
    model that is used as a basis for the image classification model. The first time
    you run this cell, you will see a message like the one shown in *Figure 6.16*,
    indicating that the model is being set up in your environment:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在`cnn_learner`的定义中，`resnet18`参数是作为图像分类模型基础的预训练模型。第一次运行此单元格时，你将看到类似*图 6.16*中显示的消息，指示模型正在你的环境中设置：
- en: '![Figure 6.16 – Message you get the first time you run the cnn_learner definition'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.16 – 第一次运行cnn_learner定义时你收到的消息'
- en: '](img/B16216_6_16.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_16.jpg)'
- en: Figure 6.16 – Message you get the first time you run the cnn_learner definition
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.16 – 第一次运行cnn_learner定义时你收到的消息
- en: 'The second clue is in the cell where you train the model, as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个线索在训练模型的单元格中，具体如下：
- en: '[PRE20]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: For most of the models you have seen so far in this book, you trained the model
    using `learn.fit_one_cycle()`. Here, because we want to update an existing model
    for our particular use case, we use `learn.fine_tune()` instead. This is exactly
    what we did in [*Chapter 4*](B16216_04_Final_VK_ePub.xhtml#_idTextAnchor109),
    *Training Models with Text Data*, for the language models we trained using transfer
    learning on top of the pre-trained `AWD_LSTM` model.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 对于到目前为止你在本书中看到的大多数模型，你使用了`learn.fit_one_cycle()`来训练模型。这里，由于我们想要更新一个现有的模型以适应我们的特定用例，因此我们使用`learn.fine_tune()`。这正是我们在[*第
    4 章*](B16216_04_Final_VK_ePub.xhtml#_idTextAnchor109)中所做的，*使用文本数据训练模型*，我们使用迁移学习在预训练的`AWD_LSTM`模型上训练语言模型。
- en: 'Why did we use transfer learning for this use case instead of training the
    model from scratch? The simple answer is that we get decent performance from the
    model faster by using transfer learning. You can try it out yourself by making
    two changes to the `training_with_curated_image_datasets.ipynb` notebook and rerunning
    it. Here are the steps to follow to do this:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们在这个用例中使用迁移学习而不是从头开始训练模型？简单的答案是，通过使用迁移学习，我们能够更快地获得模型的良好表现。你可以通过对 `training_with_curated_image_datasets.ipynb`
    笔记本做两个修改并重新运行来亲自试试看。以下是进行此操作的步骤：
- en: 'Update the definition of the `cnn_learner` object to include the `pretrained=False`
    argument, as shown here:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新 `cnn_learner` 对象的定义，添加 `pretrained=False` 参数，如下所示：
- en: '[PRE21]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This change means that the model will be trained from scratch with the `CIFAR`
    dataset rather than by taking advantage of the pre-trained model.
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这一更改意味着，模型将使用 `CIFAR` 数据集从头开始训练，而不是利用预训练模型。
- en: 'Change the training statement to the following:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练语句更改为以下内容：
- en: '[PRE22]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: When you run the notebook after making these changes, this new model will not
    do a very good job of classifying images. Transfer learning works, and as Howard
    and Gugger explain in their book, it doesn't get nearly enough attention in standard
    introductions to deep learning. It's lucky for us that fastai is designed to make
    it easy to exploit the power of transfer learning, as shown by the image classification
    model that you trained in the *How to do it…* section of this recipe.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在做出这些更改后重新运行笔记本时，这个新模型在分类图像时不会表现得很好。迁移学习是有效的，正如 Howard 和 Gugger 在他们的书中解释的那样，它在深度学习的标准介绍中并没有得到足够的关注。幸运的是，fastai
    被设计成易于利用迁移学习的强大功能，正如你在本食谱的 *How to do it…* 部分训练的图像分类模型所展示的那样。
- en: A closer look at the model
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更仔细地审视模型
- en: Before moving on to the next recipe, it's worth taking a closer look at the
    model from this recipe. A deeply detailed description of the model is beyond the
    scope of this book, so we will just focus on some highlights here.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续下一个食谱之前，值得更仔细地看看本食谱中的模型。由于本书的范围限制，模型的详细描述将超出本书内容，我们将在这里关注一些重点。
- en: 'As shown in the recipe, the model is defined as a `cnn_learner` object (documentation
    here: [https://docs.fast.ai/vision.learner.html#cnn_learner](https://docs.fast.ai/vision.learner.html#cnn_learner))
    that uses the pre-trained `resnet18` model (documentation here: [https://pytorch.org/vision/stable/models.html](https://pytorch.org/vision/stable/models.html)).
    The output of `learn.summary()` for this model shows that the model includes a
    series of convolutional layers and associated layers. For a description of convolutional
    neural networks (CNNs), see: [https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/](https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 如食谱中所示，模型被定义为 `cnn_learner` 对象（文档链接：[https://docs.fast.ai/vision.learner.html#cnn_learner](https://docs.fast.ai/vision.learner.html#cnn_learner)），使用的是预训练的
    `resnet18` 模型（文档链接：[https://pytorch.org/vision/stable/models.html](https://pytorch.org/vision/stable/models.html)）。`learn.summary()`
    输出显示该模型包括一系列卷积层及其相关层。有关卷积神经网络（CNN）的描述，请参见：[https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/](https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/)。
- en: Exploring a curated image location dataset
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索一个精心策划的图像位置数据集
- en: Back in [*Chapter 2*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057), *Exploring
    and Cleaning Up Data with fastai*, we went through the process of ingesting and
    exploring a variety of datasets using fastai.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第2章*](B16216_02_Final_VK_ePub.xhtml#_idTextAnchor057)《使用 fastai 探索和清理数据》中，我们介绍了使用
    fastai 导入和探索多种数据集的过程。
- en: 'In this section, we are going to explore a special curated image dataset called
    `COCO_TINY`. This is an `CIFAR` dataset that we used in the *Training a classification
    model with a simple curated vision dataset* recipe, which had a single labeled
    object in each image, the images in image location datasets are labeled with bounding
    boxes (which indicate where in the image a particular object occurs) as well as
    the name of the object. Furthermore, images in the `COCO_TINY` dataset can contain
    multiple labeled objects, as shown here:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探索一个特别策划的图像数据集，名为`COCO_TINY`。这是一个`CIFAR`数据集，我们在*使用简单策划视觉数据集训练分类模型*教程中使用过，它在每张图片中只有一个带标签的物体，而图像位置数据集中的图片则带有边界框（指示图片中物体的位置）以及物体的名称。此外，`COCO_TINY`数据集中的图片可以包含多个带标签的物体，如下所示：
- en: '![Figure 6.17 – Labeled image from an image location dataset'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.17 – 来自图像位置数据集的标注图片'
- en: '](img/B16216_6_17.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_17.jpg)'
- en: Figure 6.17 – Labeled image from an image location dataset
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.17 – 来自图像位置数据集的标注图片
- en: In the recipe in this section, we'll ingest the dataset and apply its annotation
    information to create a `dataloaders` object for the dataset. The annotation information
    for each image can be quite complex. Each image can depict multiple labeled objects.
    For each labeled object in an image, the annotation information includes the filename
    of the image, the *x* and *y* coordinates of the bounding box that surrounds the
    object, and the label for the category of the object. For example, the image shown
    in *Figure 6.17* contains several **couch** objects and a **chair** object.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的教程中，我们将引入数据集并应用其注释信息，创建该数据集的`dataloaders`对象。每张图片的注释信息可能相当复杂。每张图片可以包含多个带标签的物体。每个带标签的物体的注释信息包括图片的文件名、围绕物体的边界框的*x*和*y*坐标，以及物体类别的标签。例如，*图
    6.17*中展示的图片包含了几个**沙发**物体和一个**椅子**物体。
- en: 'Note that the images in the dataset don''t actually show the annotation. A
    typical image from the dataset looks as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，数据集中的图片实际上并不展示注释。数据集中的典型图片如下所示：
- en: '![Figure 6.18 – Raw image from the COCO_TINY dataset'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.18 – 来自COCO_TINY数据集的原始图片'
- en: '](img/B16216_6_18.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_18.jpg)'
- en: Figure 6.18 – Raw image from the COCO_TINY dataset
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.18 – 来自COCO_TINY数据集的原始图片
- en: There are no bounding boxes or labels in the image itself. That annotation information
    is contained in a separate file. The recipe in this section will show you how
    to combine the image files with the annotation information.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图片本身没有边界框或标签。这些注释信息包含在一个单独的文件中。本节的教程将展示如何将图片文件与注释信息结合起来。
- en: 'At the end of this recipe, when we use `show_batch()` to display samples from
    the batch that incorporates annotation, the bounding boxes and labels are shown
    in the images. For example, *Figure 6.19* shows how the image from *Figure 6.18*
    looks when it is displayed by `show_batch()` – now you can see the bounding box
    and label for the **vase** object in the image:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程的最后，当我们使用`show_batch()`显示包含注释的批次样本时，图片中会显示边界框和标签。例如，*图 6.19*展示了当通过`show_batch()`显示*图
    6.18*中的图片时的效果——现在你可以看到图片中的**花瓶**物体的边界框和标签：
- en: '![Figure 6.19 – Annotated version of the image in Figure 6.18'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.19 – 图 6.18中图片的注释版'
- en: '](img/B16216_6_19.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_19.jpg)'
- en: Figure 6.19 – Annotated version of the image in Figure 6.18
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.19 – 图 6.18中图片的注释版
- en: In the recipe in this section, you will combine the image files from the `COCO_TINY`
    dataset, such as the image shown in *Figure 6.18*, with the information from the
    annotation file to get a `dataloaders` object that includes the images along with
    bounding boxes and labels for all the labeled objects in each image, as shown
    in *Figure 6.19*.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的教程中，你将结合`COCO_TINY`数据集中的图片文件，例如*图 6.18*中展示的图片，与注释文件中的信息，以获得一个`dataloaders`对象，该对象包含所有带标签物体的图片、边界框和标签，如*图
    6.19*所示。
- en: Getting ready
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备开始
- en: Confirm that you can open the `exploring_image_location_datasets.ipynb` notebook
    in the `ch6` directory of your repository.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 确认你可以打开位于你的仓库中`ch6`目录下的`exploring_image_location_datasets.ipynb`笔记本。
- en: The approach to examining the dataset shown in this recipe includes approaches
    inspired by this Kaggle kernel, https://www.kaggle.com/jachen36/coco-tiny-test-prediction,
    which demonstrates how to use fastai to explore an image location dataset.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程中用于检查数据集的方法包括受这个Kaggle内核启发的方法，https://www.kaggle.com/jachen36/coco-tiny-test-prediction，演示了如何使用fastai探索图像位置数据集。
- en: 'The `COCO_TINY` dataset featured in this section is introduced in the paper
    *Microsoft COCO: Common Objects in Context*, Lin et al., 2014\. I am grateful
    for the opportunity to include an example using this dataset in this book.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '本节中介绍的`COCO_TINY`数据集出自论文《*Microsoft COCO: Common Objects in Context*》，Lin等人，2014年。我很感激能够在本书中使用这个数据集作为示例。'
- en: Dataset citation
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: 'Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick,
    James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick, and Piotr Dollár.
    (2014). *Microsoft COCO: Common Objects in Context*: [https://arxiv.org/abs/1405.0312](https://arxiv.org/abs/1405.0312).'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 'Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick,
    James Hays, Pietro Perona, Deva Ramanan, C. Lawrence Zitnick 和 Piotr Dollár. (2014).
    *Microsoft COCO: Common Objects in Context*: [https://arxiv.org/abs/1405.0312](https://arxiv.org/abs/1405.0312).'
- en: How to do it…
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In this section, you will be running through the `exploring_image_location_datasets.ipynb`
    notebook. Once you have the notebook open in your fastai environment, complete
    the following steps:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将运行`exploring_image_location_datasets.ipynb`笔记本。将该笔记本在您的fastai环境中打开后，完成以下步骤：
- en: Run the cells in the notebook up to the `Ingest the dataset` cell to import
    the required libraries and set up your notebook.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行笔记本中的单元，直到`导入数据集`单元，以导入所需的库并设置笔记本环境。
- en: 'Run the following cell to define the `path` object for this dataset:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元来为此数据集定义`path`对象：
- en: '[PRE23]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Run the following cell to examine the directory structure of the dataset:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元以检查数据集的目录结构：
- en: '[PRE24]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output shows the directory structure of the dataset, as shown in *Figure
    6.20*:'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示了数据集的目录结构，如*图 6.20*所示：
- en: '![Figure 6.20 – Output of path.ls()'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.20 – path.ls() 的输出'
- en: '](img/B16216_6_20.jpg)'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_20.jpg)'
- en: Figure 6.20 – Output of path.ls()
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.20 – path.ls() 的输出
- en: The dataset consists of a set of image files in the `train` subdirectory and
    the `train.json` annotation file. In the next few steps of this recipe, we will
    take a closer look at what's in the `train.json` file.
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集由`train`子目录中的一组图像文件和`train.json`注释文件组成。在本食谱的接下来的步骤中，我们将更详细地查看`train.json`文件的内容。
- en: 'Run the following cell to bring the `train.json` file into a series of Python
    dictionaries:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元将`train.json`文件导入为一系列Python字典：
- en: '[PRE25]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Here are the key parts of the code used in this cell:'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是该单元中使用的代码的关键部分：
- en: 'a) `data = json.load(json_file)`: Loads the contents of the whole `train.json`
    file into the `data` dictionary.'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `data = json.load(json_file)`：将整个`train.json`文件的内容加载到`data`字典中。
- en: 'b) `categories = data[''categories'']`: Creates a separate list of dictionaries
    just for the category definitions. This dictionary defines the objects in the
    images.'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `categories = data['categories']`：为类别定义创建一个单独的字典列表。该字典定义了图像中的对象。
- en: 'c) `images = data[''images'']`: Creates a separate list of dictionaries just
    for image files.'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `images = data['images']`：为图像文件创建一个单独的字典列表。
- en: 'd) `annotations = data[''annotations'']`: Creates a separate list of dictionaries
    just for the bounding boxes.'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `annotations = data['annotations']`：为边界框创建一个单独的字典列表。
- en: 'Run the following cell to see the structure of each of the dictionaries you
    created in the previous cell:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元查看前一个单元中创建的每个字典的结构：
- en: '[PRE26]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output of this cell shows samples of the contents of each of the three
    dictionaries, as shown in the following screenshot:'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该单元的输出显示了每个字典内容的示例，如下图所示：
- en: '![Figure 6.21 – Contents of annotation dictionaries'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.21 – 注释字典的内容'
- en: '](img/B16216_6_21.jpg)'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_21.jpg)'
- en: Figure 6.21 – Contents of annotation dictionaries
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.21 – 注释字典的内容
- en: 'The dictionaries that we created in the previous step aren''t quite what we
    need to get complete annotations for the images. What we want is a consolidated
    annotation for each image that lists the bounding boxes for each object in the
    image along with the object''s category. We could do this manually by manipulating
    the dictionaries we created in the previous step, but fastai provides a very handy
    function called `get_annotations` that does the work for us. Run the following
    cell to define the annotation structures:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在前一步创建的字典并不是我们所需要的，无法为图像提供完整的注释。我们需要的是每个图像的汇总注释，列出图像中每个对象的边界框及其类别。我们可以通过操作前面创建的字典手动完成这个任务，但fastai提供了一个非常方便的函数`get_annotations`，它可以为我们完成这个工作。运行以下单元来定义注释结构：
- en: '[PRE27]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Here are the key parts of the code in this cell:'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是该单元中代码的关键部分：
- en: 'a) `aget_annotations(path/''train.json'')`: Applies the `get_annotations` function
    to the `train.json` file to get an annotation structure. The output of this function
    is a list of filenames and a list of labeled bounding boxes.'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `aget_annotations(path/'train.json')`：对`train.json`文件应用`get_annotations`函数，以获取注释结构。该函数的输出是文件名列表和标记边界框列表。
- en: 'b) `dict(zip(image_files, bbox_lbl))`: Creates a dictionary that combines the
    file list and the labeled bounding box list output from the previous command.'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `dict(zip(image_files, bbox_lbl))`：创建一个字典，将文件列表和从前一个命令输出的标记边界框列表结合起来。
- en: 'Run the following cell to examine one of the elements of the annotation dictionary,
    `img_bbox_combo`, that you created in the previous cell:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以检查在前一个单元格中创建的注释字典元素之一，`img_bbox_combo`：
- en: '[PRE28]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The output of this cell, as shown in the following screenshot, shows that elements
    of the dictionary are tuples made up of a list of bounding boxes (sets of 2 *x*
    and *y* coordinates that define the top-left and bottom-right points of the box
    around the object) and a list of corresponding object categories:'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此单元格的输出，如下图所示，表明字典的元素是由包含边界框列表（定义对象周围区域的2个*x*和*y*坐标，分别表示左上角和右下角点）和对应对象类别的列表组成的元组：
- en: '![Figure 6.22 – An element of img_bbox_combo'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.22 – img_bbox_combo的一个元素'
- en: '](img/B16216_6_22.jpg)'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_22.jpg)'
- en: Figure 6.22 – An element of img_bbox_combo
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.22 – img_bbox_combo的一个元素
- en: 'Run the following cell to see the image associated with the annotation you
    examined in the previous cell:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以查看与前一个单元格中检查的注释相关的图像：
- en: '[PRE29]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The output of this cell is the following image:'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此单元格的输出是以下图像：
- en: '![Figure 6.23 – Example image'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.23 – 示例图像'
- en: '](img/B16216_6_23.jpg)'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_23.jpg)'
- en: Figure 6.23 – Example image
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.23 – 示例图像
- en: 'Run the following cell to define a function to return the bounding box associated
    with the input image file:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以定义一个函数，返回与输入图像文件相关的边界框：
- en: '[PRE30]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Run the following cell to define a function to return the label (that is, the
    category) associated with the input image file:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以定义一个函数，返回与输入图像文件相关的标签（即类别）：
- en: '[PRE31]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Run the following cell to define a function to return the image files in the
    dataset:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以定义一个函数，返回数据集中的图像文件：
- en: '[PRE32]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Run the following cell to define a `DataBlock` object for the dataset using
    the functions that you defined in the previous three cells:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以使用你在前面三个单元格中定义的函数，为数据集定义一个`DataBlock`对象：
- en: '[PRE33]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'For almost all of the recipes so far in this book, we have used the top-level
    fastai API, which means we would be defining some kind of `dataloaders` object
    at this step. For this dataset, however, we need more flexibility than we can
    get from a `dataloaders` object, which is why we have defined a `DataBlock` object
    here. For details on `DataBlock` objects, refer to the following documentation:
    https://docs.fast.ai/data.block.html#DataBlock.'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 迄今为止，在本书的几乎所有配方中，我们都使用了顶层的fastai API，这意味着在此步骤中我们会定义某种类型的`dataloaders`对象。然而，对于此数据集，我们需要比`dataloaders`对象提供的更大的灵活性，这就是为什么我们在这里定义了一个`DataBlock`对象。有关`DataBlock`对象的详细信息，请参考以下文档：https://docs.fast.ai/data.block.html#DataBlock。
- en: 'Here are the arguments for the definition of the `DataBlock` object:'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是`DataBlock`对象定义的参数：
- en: 'a) `blocks=(ImageBlock, BBoxBlock, BBoxLblBlock)`: Specifies that the input
    to the model is images (`ImageBlock`) and the target has two parts: bounding boxes
    for object in the images (`BBoxBlock`), and labels (categories) associated with
    each of the bounding boxes (`BBoxLblBlock`).'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `blocks=(ImageBlock, BBoxBlock, BBoxLblBlock)`：指定模型的输入是图像（`ImageBlock`），目标有两个部分：图像中对象的边界框（`BBoxBlock`），以及与每个边界框相关的标签（类别）（`BBoxLblBlock`）。
- en: 'b) `get_items=get_image_files`: Specifies that the `get_image_files` function
    is called to get the input to the `DataBlock` object.'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `get_items=get_image_files`：指定调用`get_image_files`函数以获取`DataBlock`对象的输入。
- en: 'c) `get_y=[get_bbox, get_lbl]`: Specifies the functions that are applied to
    the results of `get_items`. The image filenames are sent as arguments to each
    of these functions. The first function, `get_bbox`, returns the list of bounding
    boxes associated with the image file according to the annotation information we
    ingested from the `train.json` file. The second function, `get_lbl`, returns the
    list of labels (categories) for the bounding boxes associated with the image file,
    according to the annotation information we ingested from the `train.json` file.'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `get_y=[get_bbox, get_lbl]`：指定应用于`get_items`结果的函数。图像文件名作为参数传递给这些函数。第一个函数`get_bbox`根据我们从`train.json`文件中导入的注释信息，返回与图像文件关联的边界框列表。第二个函数`get_lbl`根据我们从`train.json`文件中导入的注释信息，返回与图像文件关联的边界框的标签（类别）列表。
- en: 'd) `n_inp=1`: Specifies the number of elements in the tuples specified in the
    `blocks` argument that should be considered part of the input, in our case, just
    the image files.'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `n_inp=1`：指定在`blocks`参数中定义的元组中应视为输入的元素数量，在我们的情况下，仅为图像文件。
- en: 'Run the following cell to define a `dataloaders` object using the `DataBlock`
    object, `db`, you created in the previous cell:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格，使用你在前一个单元格中创建的`DataBlock`对象`db`来定义`dataloaders`对象：
- en: '[PRE34]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Here are the arguments for the `dataloaders` definition:'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是`dataloaders`定义的参数：
- en: 'a) `path`: Specifies that the path to use for the `dataloaders` object is the
    `path` object you defined for the dataset at the beginning of the notebook'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `path`：指定用于`dataloaders`对象的路径是你在笔记本开始时为数据集定义的`path`对象
- en: 'b) `bs=32`: Specifies that the batch size is 32'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `bs=32`：指定批次大小为32
- en: 'Now it is finally time to see what batches for the `dataloaders` object look
    like. Run the following cell to see a sample of entries from a batch:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在终于可以看到`dataloaders`对象的批次样子了。运行以下单元格，查看一个批次中的条目示例：
- en: '[PRE35]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Here are the arguments for `show_batch()`:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是`show_batch()`的参数：
- en: 'a) `max_n=4`: Specifies the number of samples to show'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `max_n=4`：指定要显示的样本数量
- en: 'b) `figsize=(10,10)`: Specifies the dimensions of the samples'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `figsize=(10,10)`：指定样本的尺寸
- en: 'The output of `show_batch()` is shown in the following image. Note that you
    see the images with the labeled objects highlighted with bounding boxes and annotation
    text. Also note that you may see different sample images when you run `show_batch()`
    in your notebook:'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`show_batch()`的输出显示在下图中。注意，你会看到带有边界框和注释文本的标注物体的图像。同时注意，你可能会在笔记本中运行`show_batch()`时看到不同的示例图像：'
- en: '![Figure 6.24 – Sample image output by show_batch()'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.24 – show_batch()输出的示例图像](img/B16216_6_24.jpg)'
- en: '](img/B16216_6_24.jpg)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_24.jpg)'
- en: Figure 6.24 – Sample image output by show_batch()
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.24 – show_batch()输出的示例图像
- en: Congratulations! You have successfully ingested and prepared an image location
    dataset, one of the most complex data manipulation tasks that you will tackle
    in this book.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！你已经成功地导入并准备了图像位置数据集，这是本书中你将要处理的最复杂的数据操作任务之一。
- en: How it works…
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: After working through the recipe in this section, you may have some questions
    about the `COCO_TINY` dataset and the image location dataset in general. In this
    section, we will go through some of the questions that may have come up as you
    went through the recipe.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的操作中，可能会对`COCO_TINY`数据集和图像位置数据集的一般情况有一些问题。在本节中，我们将解答一些你在操作过程中可能会遇到的问题。
- en: What kinds of objects are annotated in the images in the dataset?
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集中的图像标注了哪些类型的物体？
- en: 'If you rerun the following cell several times, you will see a variety of annotated
    images:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你多次运行以下单元格，你会看到多种标注图像：
- en: '[PRE36]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'You can see an example of the output of this cell in *Figure 6.25*. Note that
    the annotations don''t cover every possible object in the images. For example,
    the animal in the first image isn''t annotated. Which objects are annotated for
    images in `COCO_TINY`? We''ll answer that question in this section:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在*图6.25*中看到此单元格输出的示例。注意，注释并没有覆盖图像中的每个可能物体。例如，第一个图像中的动物没有被注释。在`COCO_TINY`中的图像会注释哪些物体？我们将在本节中回答这个问题：
- en: '![Figure 6.25 – Output of show_batch()'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.25 – show_batch()的输出](img/B16216_6_25.jpg)'
- en: '](img/B16216_6_25.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_25.jpg)'
- en: Figure 6.25 – Output of show_batch()
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.25 – show_batch()的输出
- en: 'When you ran the following cell to bring the annotation file, `train.json`,
    into a Python dictionary, you created a sub-dictionary called `categories`, which
    contains all the categories of objects annotated in the `COCO_TINY` dataset as
    follows:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 当你运行以下单元格将注释文件`train.json`引入Python字典时，你创建了一个名为`categories`的子字典，其中包含`COCO_TINY`数据集中所有注释物体的类别，如下所示：
- en: '[PRE37]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'To see what''s in the `categories` dictionary, run the following cell:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看`categories`字典中的内容，请运行以下单元格：
- en: '[PRE38]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output of this cell is as follows:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 该单元格的输出如下：
- en: '![Figure 6.26 – The categories dictionary'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.26 – 类别字典'
- en: '](img/B16216_6_26.jpg)'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_26.jpg)'
- en: Figure 6.26 – The categories dictionary
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.26 – 类别字典
- en: 'From this dictionary, you can see that there are only six objects annotated
    for the images in the `COCO_TINY` dataset: **chair**, **couch**, **tv**, **remote**,
    **book**, and **vase**.'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个字典中，你可以看到`COCO_TINY`数据集中的图像只有六个注释物体：**椅子**，**沙发**，**电视**，**遥控器**，**书**，和**花瓶**。
- en: 'If you run `show_batch()` repeatedly, you will see that even objects that are
    only partially shown in an image are annotated. For example, the first image in
    *Figure 6.25* has an annotation for a chair, as shown in the following image,
    even though only part of the legs of the chair is shown in the image:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你反复运行`show_batch()`，你将看到即使是图像中仅部分显示的物体也会被注释。例如，*图 6.25*中的第一张图像就有一个椅子的注释，如下图所示，尽管图像中只显示了椅子部分的腿：
- en: '![Figure 6.27 – Close-up of the chair annotation'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.27 – 椅子注释的特写'
- en: '](img/B16216_6_27.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_27.jpg)'
- en: Figure 6.27 – Close-up of the chair annotation
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.27 – 椅子注释的特写
- en: 'You will also see that some images contain many annotated objects, and the
    bounding boxes for these objects can overlap, as shown in the following image:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 你还将看到一些图像包含许多注释物体，并且这些物体的边界框可能会重叠，如下图所示：
- en: '![Figure 6.28 – An image with multiple, overlapping bounding boxes'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.28 – 一张包含多个重叠边界框的图像'
- en: '](img/B16216_6_28.jpg)'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_28.jpg)'
- en: Figure 6.28 – An image with multiple, overlapping bounding boxes
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.28 – 一张包含多个重叠边界框的图像
- en: This subsection describes which objects are annotated in the images in `COCO_TINY`.
    As you rerun the `show_batch()` command repeatedly, you will see for yourself
    how complex the annotations can be for some objects.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 本小节描述了`COCO_TINY`中哪些物体被注释。在你多次运行`show_batch()`命令时，你将亲眼看到某些物体的注释是多么复杂。
- en: How are the bounding boxes for annotated objects defined?
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注释物体的边界框是如何定义的？
- en: 'While you were working through the recipe in this section, you may have asked
    yourself where the bounding boxes were defined. When you ran the following cell
    to bring the annotation file, `train.json`, into a Python dictionary, you created
    a sub-dictionary called `annotations` that contains all the annotations of objects
    annotated in the `COCO_TINY` dataset:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在本节中按步骤操作时，可能会问自己边界框是在哪里定义的。当你运行以下单元格将注释文件`train.json`引入Python字典时，你创建了一个名为`annotations`的子字典，其中包含`COCO_TINY`数据集中所有物体的注释：
- en: '[PRE39]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'You can run the following cell to see the contents of a subset of the `annotations`
    dictionary:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以运行以下单元格来查看`annotations`字典子集的内容：
- en: '[PRE40]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output of this cell shows examples of annotations for objects in a particular
    image, as shown in the following screenshot:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 该单元格的输出显示了特定图像中物体注释的示例，如下截图所示：
- en: '![Figure 6.29 – Example of annotations'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.29 – 注释示例'
- en: '](img/B16216_6_29.jpg)'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_29.jpg)'
- en: Figure 6.29 – Example of annotations
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.29 – 注释示例
- en: The values for the `bbox` keys in this dictionary define the bounding boxes
    for objects by specifying the *x* and *y* values at the extremes of the objects.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 该字典中`bbox`键的值通过指定物体边界的* x *和* y *值来定义物体的边界框。
- en: 'Consider the following image. This image has a single annotated object – let''s
    see how to view the coordinates of its bounding box:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 请看下图。这张图像包含一个注释的物体——让我们看看如何查看其边界框的坐标：
- en: '![Figure 6.30 – Example annotated image with a bounding box'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.30 – 带有边界框的注释示例图像'
- en: '](img/B16216_6_30.jpg)'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_30.jpg)'
- en: Figure 6.30 – Example annotated image with a bounding box
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.30 – 带有边界框的注释示例图像
- en: 'The filename for this image is `000000071159.jpg`. To see the bounding box
    for this image, run the following cell:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图像的文件名是`000000071159.jpg`。要查看此图像的边界框，请运行以下单元格：
- en: '[PRE41]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The output for this cell shows the bounding box coordinates from this image.
    If the image had multiple objects annotated in it, there would be a bounding box
    defined for each object:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 此单元格的输出显示了该图像的边界框坐标。如果图像中有多个对象被注释，那么每个对象都会定义一个边界框：
- en: '![Figure 6.31 – Bounding box for the object in the example image in Figure
    6.30'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.31 – 图 6.30 中示例图像的对象边界框'
- en: '](img/B16216_6_31.png)'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_31.png)'
- en: Figure 6.31 – Bounding box for the object in the example image in Figure 6.30
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.31 – 图 6.30 中示例图像的对象边界框
- en: In this section, we have reviewed some of the details of the bounding box annotations
    in the `COCO_TINY` dataset.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我们回顾了 `COCO_TINY` 数据集中边界框注释的一些细节。
- en: Why didn't we train a model using COCO_TINY?
  id: totrans-333
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么我们没有使用 COCO_TINY 来训练模型？
- en: Unlike most of the recipes in this book, the recipe in this section did not
    include model training. After the effort we put into creating a `dataloaders`
    object for the `COCO_TINY` dataset, why didn't we go all the way and train a model
    with it?
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 与本书中大多数食谱不同，本部分的食谱并没有包括模型训练。在我们为 `COCO_TINY` 数据集创建 `dataloaders` 对象之后，为什么我们没有继续训练模型呢？
- en: 'The simple answer is that the fastai framework does not currently incorporate
    a simple way to train a model on an image location dataset such as `COCO_TINY`.
    If you want to attempt to train such a model, you can check out this repo for
    an approach, but be prepared to get into details well beyond the high-level fastai
    API that we have been exploring in this book so far: [https://github.com/muellerzr/Practical-Deep-Learning-for-Coders-2.0/blob/master/Computer%20Vision/06_Object_Detection.ipynb](https://github.com/muellerzr/Practical-Deep-Learning-for-Coders-2.0/blob/master/Computer%20Vision/06_Object_Detection.ipynb).'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的答案是，fastai 框架目前并未提供一种简单的方法来训练像 `COCO_TINY` 这样的图像位置数据集。如果你想尝试训练这样的模型，可以参考这个仓库中的方法，但要准备好深入细节，超出我们在本书中探索的高层
    fastai API：[https://github.com/muellerzr/Practical-Deep-Learning-for-Coders-2.0/blob/master/Computer%20Vision/06_Object_Detection.ipynb](https://github.com/muellerzr/Practical-Deep-Learning-for-Coders-2.0/blob/master/Computer%20Vision/06_Object_Detection.ipynb)。
- en: Training a classification model with a standalone vision dataset
  id: totrans-336
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用独立视觉数据集训练分类模型
- en: In the *Training a classification model with a simple curated vision dataset*
    recipe, you went through the steps to ingest a fastai curated dataset and use
    it to train an image classification model.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *使用简单的策划视觉数据集训练分类模型* 这一食谱中，你学习了如何导入 fastai 策划数据集并使用它来训练图像分类模型。
- en: 'In this section, you will go through the same process for a standalone dataset
    called `fruits-360`. This dataset (described in more detail here: https://www.kaggle.com/moltean/fruits)
    contains over 90,000 images of fruits and vegetables organized into over 130 categories.'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，你将通过相同的过程处理一个独立的数据集，叫做 `fruits-360`。该数据集（详细描述见这里：https://www.kaggle.com/moltean/fruits）包含了超过
    90,000 张水果和蔬菜的图像，分为超过 130 个类别。
- en: In this recipe, we'll begin by bringing this dataset into Gradient. Then we
    will work through the `training_with_standalone_image_datasets.ipynb` notebook
    to ingest the dataset and use it to train a fastai image classification model.
    Finally, we will see how well the trained model classifies images from the test
    set and save the trained model.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将首先将该数据集导入 Gradient。然后，我们将通过 `training_with_standalone_image_datasets.ipynb`
    笔记本来导入数据集并用它来训练一个 fastai 图像分类模型。最后，我们将查看训练好的模型如何分类测试集中的图像，并保存训练好的模型。
- en: Getting ready
  id: totrans-340
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Ensure that you have uploaded the `fruits-360` dataset to your Gradient environment
    by following these steps:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已经按照以下步骤将 `fruits-360` 数据集上传到你的 Gradient 环境中：
- en: Download `archive.zip` from [https://www.kaggle.com/moltean/fruits](https://www.kaggle.com/moltean/fruits).
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [https://www.kaggle.com/moltean/fruits](https://www.kaggle.com/moltean/fruits)
    下载 `archive.zip`。
- en: 'Upload `archive.zip` to your Gradient environment. You can use the upload button
    in JupyterLab in Gradient to do the upload, but you need to do it in several steps
    as follows:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `archive.zip` 上传到你的 Gradient 环境中。你可以使用 Gradient 中 JupyterLab 的上传按钮进行上传，但需要按照以下几个步骤进行操作：
- en: 'a) From the terminal in your Gradient environment, make `/notebooks` your current
    directory:'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 在 Gradient 环境的终端中，将 `/notebooks` 设为当前目录：
- en: '[PRE42]'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: temp your current folder, select the upload button (see *Figure 6.32*), and
    select archive.zip from your local system folder where you downloaded it in *Step
    1*:![Figure 6.32 – Upload button in JupyterLab
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 临时切换到当前文件夹，选择上传按钮（参见 *图 6.32*），然后从你在 *步骤 1* 中下载的本地系统文件夹中选择 `archive.zip`：![图
    6.32 – JupyterLab 中的上传按钮
- en: '](img/B16216_6_32.jpg)Figure 6.32 – Upload button in JupyterLab'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_32.jpg)图6.32 – JupyterLab中的上传按钮'
- en: '[PRE43]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now that you have uploaded `archive.zip` to the `/notebooks/temp` directory
    in your Gradient environment, make that directory your current directory by running
    the following command in the Gradient terminal:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你已经将`archive.zip`上传至Gradient环境中的`/notebooks/temp`目录，通过在Gradient终端运行以下命令，将该目录设为当前目录：
- en: '[PRE44]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Unzip `archive.zip` into the `/storage/archive` directory by running the following
    command in the Gradient terminal:'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在Gradient终端运行以下命令，将`archive.zip`解压到`/storage/archive`目录：
- en: '[PRE45]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Confirm that you now have the dataset set up in your Gradient environment by
    running the following command from within the Gradient terminal:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在Gradient终端中运行以下命令，确认你现在已经在Gradient环境中设置了数据集：
- en: '[PRE46]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Then, run the following command to list the contents of the directory:'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，运行以下命令列出该目录的内容：
- en: '[PRE47]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output of this command should look like what is shown in the following
    screenshot:'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此命令的输出应与以下截图所示的内容类似：
- en: '![Figure 6.33 – Contents of the fruits-360 directory'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.33 – fruits-360目录的内容'
- en: '](img/B16216_6_33.jpg)'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_33.jpg)'
- en: Figure 6.33 – Contents of the fruits-360 directory
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.33 – fruits-360目录的内容
- en: With these preparation steps, you have moved the files that make up the `fruits-360`
    dataset to the correct location in your Gradient environment to be used by a fastai
    model.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些准备步骤，你已将`fruits-360`数据集的文件移动到Gradient环境中的正确位置，以便fastai模型使用。
- en: The `fruits-360` dataset featured in this section is introduced in the Kaggle
    competition **Fruits 360** from 2020 ([https://www.kaggle.com/moltean/fruits](https://www.kaggle.com/moltean/fruits)).
    I am grateful for the opportunity to include an example using this dataset in
    this book.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中展示的`fruits-360`数据集来源于2020年Kaggle比赛**Fruits 360**（[https://www.kaggle.com/moltean/fruits](https://www.kaggle.com/moltean/fruits)）。非常感谢有机会在本书中使用这个数据集作为示例。
- en: Dataset citation
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: Mihai Oltean (2017-2020). *Fruits 360 – A dataset with 90,380 images of 131
    fruits and vegetables* ([https://mihaioltean.github.io](https://mihaioltean.github.io)).
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: Mihai Oltean（2017-2020）。*Fruits 360 – 包含131种水果和蔬菜的90,380张图片的数据集* ([https://mihaioltean.github.io](https://mihaioltean.github.io))。
- en: How to do it…
  id: totrans-365
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In this section, you will be running through the `training_with_standalone_image_datasets.ipynb`
    notebook. Once you have the notebook open in your fastai environment, complete
    the following steps:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将运行`training_with_standalone_image_datasets.ipynb`笔记本。一旦在你的fastai环境中打开该笔记本，完成以下步骤：
- en: Run the cells in the notebook up to the `Ingest the dataset` cell to import
    the required libraries and set up your notebook.
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在笔记本中运行单元格，直到`Ingest the dataset`单元格，以导入所需的库并设置笔记本。
- en: 'Run the following cell to define the `path` object for this dataset:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格，为此数据集定义`path`对象：
- en: '[PRE48]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Run the following cell to examine the directory structure of the dataset:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格检查数据集的目录结构：
- en: '[PRE49]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output shows the directory structure of the dataset, as shown in the following
    screenshot:'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示数据集的目录结构，如以下截图所示：
- en: '![Figure 6.34 – Output of path.ls()'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.34 – path.ls()的输出'
- en: '](img/B16216_6_34.jpg)'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_34.jpg)'
- en: Figure 6.34 – Output of path.ls()
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.34 – path.ls()的输出
- en: 'Run the following cell to define an `ImageDataLoaders` object for this dataset:'
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格，为此数据集定义一个`ImageDataLoaders`对象：
- en: '[PRE50]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Here are the arguments for the definition of the `ImageDataLoaders` object:'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是`ImageDataLoaders`对象定义的参数：
- en: 'a) `path`: Specifies that the `ImageDataLoaders` object is defined using the
    `path` object you created in the previous cell'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `path`：指定使用你在前一个单元格中创建的`path`对象来定义`ImageDataLoaders`对象
- en: 'b) `train=''Training''`: Specifies that the training data is in the `/storage/archive/fruits-360/Training`
    directory'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `train='Training'`：指定训练数据位于`/storage/archive/fruits-360/Training`目录中
- en: 'c) `valid=''Test''`: Specifies that the validation data is in the `/storage/archive/fruits-360/Test`
    directory'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `valid='Test'`：指定验证数据位于`/storage/archive/fruits-360/Test`目录中
- en: 'Run the following cell to display a batch from the dataset:'
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格显示数据集的一批数据：
- en: '[PRE51]'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The output of this cell is a set of `4` items from a batch, showing images
    along with their corresponding categories, as shown in the following screenshot:'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此单元格的输出是一组来自一批的`4`个项目，显示了图片及其对应的类别，如以下截图所示：
- en: '![Figure 6.35 – Output of show_batch()'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.35 – show_batch()的输出'
- en: '](img/B16216_6_35.jpg)'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_35.jpg)'
- en: Figure 6.35 – Output of show_batch()
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.35 – show_batch()的输出
- en: 'Run the following cell to examine the contents of the `Training` subdirectory:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以检查`Training`子目录的内容：
- en: '[PRE52]'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The output shows the structure of the `Training` subdirectory, as shown in
    the following screenshot:'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示了`Training`子目录的结构，如下图所示：
- en: '![](img/B16216_6_36.jpg)'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B16216_6_36.jpg)'
- en: Figure 6.36 – Contents of the Training subdirectory
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.36 – `Training`子目录的内容
- en: 'Run the following cell to see a single item in the dataset:'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以查看数据集中的单个项目：
- en: '[PRE53]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Here are the key elements of this cell:'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是此单元格的关键要素：
- en: 'a) `img_files = get_image_files(path)`: Specifies that `path` is recursively
    examined and returns all the image files in the path'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'a) `img_files = get_image_files(path)`: 指定递归地检查`path`并返回该路径中的所有图像文件'
- en: 'b) `img = PILImage.create(img_files[100])`: Creates the image object, `img`,
    from a specific file returned by the previous statement'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'b) `img = PILImage.create(img_files[100])`: 从前述语句返回的特定文件创建图像对象`img`'
- en: 'The output of this cell is one of the dataset files rendered as an image in
    the notebook:'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该单元格的输出是数据集文件之一，并在笔记本中渲染为图像：
- en: '![Figure 6.37 – An image from the dataset'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.37 – 来自数据集的一张图像'
- en: '](img/B16216_6_37.jpg)'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_37.jpg)'
- en: Figure 6.37 – An image from the dataset
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.37 – 来自数据集的一张图像
- en: 'Run the following cell to define the model as a `cnn_learner` object:'
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格来将模型定义为一个`cnn_learner`对象：
- en: '[PRE54]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Here are the arguments for the definition of the `cnn_learner` object:'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是`cnn_learner`对象定义的参数：
- en: 'a) `dls`: Specifies that the `cnn_learner` object is defined using the `ImageDataLoaders`
    object you defined earlier in this notebook'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'a) `dls`: 指定使用你在本笔记本中之前定义的`ImageDataLoaders`对象来定义`cnn_learner`对象'
- en: 'b) `resnet18`: Specifies the pre-trained model to use as a starting point for
    this model'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'b) `resnet18`: 指定用于该模型的预训练模型作为起点'
- en: 'c) `loss_func=LabelSmoothingCrossEntropy()`: Specifies the loss function to
    use in the training process'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'c) `loss_func=LabelSmoothingCrossEntropy()`: 指定在训练过程中使用的损失函数'
- en: 'd) `metrics=accuracy`: Specifies that `accuracy` is the performance metric
    that will be optimized in the training process'
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'd) `metrics=accuracy`: 指定`accuracy`作为训练过程中优化的性能指标'
- en: 'Run the following cell to train the model:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格来训练模型：
- en: '[PRE55]'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: The argument indicates that the training run will be for `5` epochs.
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该参数表示训练将运行`5`个时期（epoch）。
- en: 'The output displays the training loss, validation loss, and accuracy for each
    epoch, as shown in the following screenshot:'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示每个时期的训练损失、验证损失和准确率，如下图所示：
- en: '![Figure 6.38 – Output of training the model'
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.38 – 训练模型的输出'
- en: '](img/B16216_6_38.jpg)'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_38.jpg)'
- en: Figure 6.38 – Output of training the model
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.38 – 训练模型的输出
- en: 'Let''s try out the trained model on some examples from the test dataset. First,
    run the following cell to define an object for one of the images in the test dataset:'
  id: totrans-416
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在测试数据集中的一些示例上尝试训练好的模型。首先，运行以下单元格为测试数据集中的一张图像定义一个对象：
- en: '[PRE56]'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Here are the key elements of this cell:'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是此单元格的关键要素：
- en: 'a) `img_files = get_image_files(path/"Test"))`: Returns all the image files
    under the `Test` directory'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'a) `img_files = get_image_files(path/"Test")`: 返回`Test`目录下的所有图像文件'
- en: 'b) `img = PILImage.create(img_files[700])`: Creates the image object, `img2`,
    from a specific file returned by the previous statement'
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'b) `img = PILImage.create(img_files[700])`: 从前述语句返回的特定文件创建图像对象`img2`'
- en: 'The output of this cell is an image of a strawberry, as shown in the following
    screenshot:'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该单元格的输出是草莓的图像，如下图所示：
- en: '![Figure 6.39 – An image of a strawberry from the test dataset'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.39 – 测试数据集中的一张草莓图像'
- en: '](img/B16216_6_39.jpg)'
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_39.jpg)'
- en: Figure 6.39 – An image of a strawberry from the test dataset
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.39 – 测试数据集中的一张草莓图像
- en: 'Run the following cell to define an object for another one of the images in
    the test dataset:'
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格为测试数据集中的另一张图像定义一个对象：
- en: '[PRE57]'
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The output of this cell is an image of a tomato, as shown in the following
    screenshot:'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该单元格的输出是番茄的图像，如下图所示：
- en: '![Figure 6.40 – An image of a tomato from the test dataset'
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.40 – 测试数据集中的一张番茄图像'
- en: '](img/B16216_6_40.jpg)'
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_40.jpg)'
- en: Figure 6.40 – An image of a tomato from the test dataset
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.40 – 测试数据集中的一张番茄图像
- en: 'Now that we have defined objects for a couple of images from the test dataset,
    let''s exercise the trained image classification model on them. First, run the
    following cell to apply the model to the strawberry image:'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经为测试数据集中的几张图像定义了对象，让我们在这些图像上测试训练好的图像分类模型。首先，运行以下单元格来应用模型到草莓图像：
- en: '[PRE58]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The output of this cell is the model''s prediction, as shown in the following
    screenshot. Note that the model correctly predicts the category of the image.
    The numbers shown in the `TensorImage` array correspond to the likelihood that
    the trained model ascribes to the image being in each of the categories:'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本单元格的输出是模型的预测结果，如下图所示。请注意，模型正确预测了图像的类别。`TensorImage` 数组中显示的数字对应训练模型认为该图像属于每个类别的可能性：
- en: '![Figure 6.41 – Image classification model''s prediction on the image of the
    strawberry'
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.41 – 图像分类模型对草莓图像的预测'
- en: '](img/B16216_6_41.jpg)'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_41.jpg)'
- en: Figure 6.41 – Image classification model's prediction on the image of the strawberry
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.41 – 图像分类模型对草莓图像的预测
- en: 'Let''s see how the model does on the tomato image. Run the following cell to
    apply the model to the image of the tomato:'
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看模型在番茄图像上的表现。运行以下单元格，将模型应用于番茄图像：
- en: '[PRE59]'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The output of this cell is the model''s prediction, as shown in the following
    screenshot. Note that the model correctly predicts that the image is a tomato:'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本单元格的输出是模型的预测结果，如下图所示。请注意，模型正确预测了图像是番茄：
- en: '![Figure 6.42 – Image classification model''s prediction on the image of a
    bird'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.42 – 图像分类模型对鸟类图像的预测'
- en: '](img/B16216_6_42.jpg)'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_42.jpg)'
- en: Figure 6.42 – Image classification model's prediction on the image of a bird
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.42 – 图像分类模型对鸟类图像的预测
- en: 'The trained model seems to be doing a good job of predicting the category of
    images from the test set, but there is still some ambiguity. The fruit and vegetable
    images can be ambiguous to a human, so let''s see how the trained model predicts
    the category of images where we know exactly what the category is. First, run
    the following cell to define an image of an avocado from the test dataset:'
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练好的模型似乎在预测测试集中的图像类别时表现良好，但仍然存在一些模糊性。水果和蔬菜的图像可能对人类来说是模糊的，因此让我们看看训练好的模型如何预测那些我们明确知道类别的图像。首先，运行以下单元格，定义来自测试数据集的鳄梨图像：
- en: '[PRE60]'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Here are the key elements of this cell:'
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是本单元格的关键元素：
- en: 'a) `avocado_files = get_image_files(path/"Test/Avocado"))`: Returns all the
    image files under the `Test/Avocado` directory'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `avocado_files = get_image_files(path/"Test/Avocado")`：返回 `Test/Avocado`
    目录下的所有图像文件
- en: 'b) `avocado_img = PILImage.create(avocado_files[30])`: Creates the image object,
    `avocado_img`, from a specific avocado image file from the file set returned by
    the previous statement'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `avocado_img = PILImage.create(avocado_files[30])`：从先前语句返回的文件集中的特定鳄梨图像文件创建图像对象
    `avocado_img`
- en: 'The output of this cell is an image of an avocado, as shown in the following
    screenshot:'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本单元格的输出是鳄梨的图像，如下图所示：
- en: '![Figure 6.43 – Image of an avocado from the test dataset'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.43 – 来自测试数据集的鳄梨图像'
- en: '](img/B16216_6_43.jpg)'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_43.jpg)'
- en: Figure 6.43 – Image of an avocado from the test dataset
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.43 – 来自测试数据集的鳄梨图像
- en: 'Let''s get another image from a different directory in the test dataset. Run
    the following cell to define an image of a walnut from the test dataset:'
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从测试数据集中的另一个目录获取一张图像。运行以下单元格，定义来自测试数据集的胡桃图像：
- en: '[PRE61]'
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Here are the key elements of this cell:'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是本单元格的关键元素：
- en: 'a) `walnut_files = get_image_files(path/"Test/Walnut")`: Returns all the image
    files under the `Test/Walnut` directory'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `walnut_files = get_image_files(path/"Test/Walnut")`：返回 `Test/Walnut` 目录下的所有图像文件
- en: 'b) `walnut_img = PILImage.create(walnut_files[30])`: Creates the image object,
    `walnut_img`, from a specific walnut image file from the file set returned by
    the previous statement'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `walnut_img = PILImage.create(walnut_files[30])`：从先前语句返回的文件集中的特定胡桃图像文件创建图像对象
    `walnut_img`
- en: 'The output of this cell is an image of a walnut, as shown in the following
    screenshot:'
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本单元格的输出是胡桃的图像，如下图所示：
- en: '![Figure 6.44 – Image of a walnut from the test dataset'
  id: totrans-458
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.44 – 来自测试数据集的胡桃图像'
- en: '](img/B16216_6_44.jpg)'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_44.jpg)'
- en: Figure 6.44 – Image of a walnut from the test dataset
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.44 – 来自测试数据集的胡桃图像
- en: 'Now that we have defined objects for a couple of images from specific directories
    in the test dataset, let''s exercise the trained image classification model on
    them. First, run the following cell to apply the model to the avocado image:'
  id: totrans-461
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经为来自测试数据集中某些特定目录的几张图像定义了对象，让我们在这些图像上运用训练好的图像分类模型。首先，运行以下单元格，将模型应用于鳄梨图像：
- en: '[PRE62]'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The output of this cell is the model''s prediction for the `avocado_img` image,
    as shown in the following screenshot. Note that the model correctly predicts the
    category of the image:'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该单元格的输出是模型对`avocado_img`图像的预测结果，如下截图所示。请注意，模型正确预测了图像的类别：
- en: '![Figure 6.45 – Image classification model''s prediction on the image of the
    avocado'
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.45 – 图像分类模型对鳄梨图像的预测'
- en: '](img/B16216_6_45.jpg)'
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_45.jpg)'
- en: Figure 6.45 – Image classification model's prediction on the image of the avocado
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.45 – 图像分类模型对鳄梨图像的预测
- en: 'Let''s see how the model does on the walnut image. Run the following cell to
    apply the model to the image of the walnut:'
  id: totrans-467
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看看模型在胡桃图像上的表现。运行以下单元格，将模型应用于胡桃图像：
- en: '[PRE63]'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The output of this cell is the model''s prediction, as shown in the following
    screenshot. Note that the model correctly predicts that the image is a walnut:'
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该单元格的输出是模型的预测结果，如下截图所示。请注意，模型正确预测了图像为胡桃：
- en: '![Figure 6.46 – Image classification model''s prediction on the image of the
    walnut'
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.46 – 图像分类模型对胡桃图像的预测'
- en: '](img/B16216_6_46.jpg)'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_46.jpg)'
- en: Figure 6.46 – Image classification model's prediction on the image of the walnut
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.46 – 图像分类模型对胡桃图像的预测
- en: 'Now that we have exercised the model to confirm that it makes good predictions
    for a small set of images, run the following cell to save the model:'
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经测试了模型，确认它能够对少量图像做出准确预测，运行以下单元格来保存模型：
- en: '[PRE64]'
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The output of this cell confirms that the model was saved in the `models` subdirectory
    of the dataset path, as shown in the following screenshot:'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该单元格的输出确认模型已保存在数据集路径的`models`子目录中，如下截图所示：
- en: '![Figure 6.47 – Output of saving the model'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.47 – 保存模型的输出'
- en: '](img/B16216_6_47.jpg)'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_47.jpg)'
- en: Figure 6.47 – Output of saving the model
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.47 – 保存模型的输出
- en: Congratulations! You have trained a fastai image classification model on a large
    standalone image dataset and exercised the trained model with a set of examples
    from the dataset.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你已经在一个大型独立图像数据集上训练了一个fastai图像分类模型，并使用该数据集中的一组示例对训练后的模型进行了测试。
- en: How it works…
  id: totrans-480
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'If you compare the *Training a classification model with a simple curated vision
    dataset* recipe with the recipe in this section, you will notice that the code
    is very similar. In fact, once you have brought the `fruits-360` dataset into
    your Gradient environment, the code in the `training_with_standalone_image_datasets.ipynb`
    notebook is very close to the code in the `training_with_curated_image_datasets.ipynb`
    notebook. There are, however, some differences, as shown in the following list:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将*使用简单整理的视觉数据集训练分类模型*的配方与本节中的配方进行对比，你会注意到代码非常相似。实际上，一旦你将`fruits-360`数据集导入到你的Gradient环境中，`training_with_standalone_image_datasets.ipynb`笔记本中的代码与`training_with_curated_image_datasets.ipynb`笔记本中的代码非常接近。然而，仍然有一些不同之处，如下所示：
- en: 'The path definition statement is different. For the curated dataset, the definition
    of the path statement has a `URLs` object as its argument:'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径定义语句有所不同。对于整理数据集，路径定义语句的参数是`URLs`对象：
- en: '[PRE65]'
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Whereas the path statement for the standalone dataset has the `fruits-360`
    directory as its argument:'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 而对于独立数据集，路径语句的参数是`fruits-360`目录：
- en: '[PRE66]'
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: The test and train directories have different names between the two datasets.
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试集和训练集目录在两个数据集之间有不同的名称。
- en: The standalone dataset is much bigger than the curated dataset, both in terms
    of the volume of images and the number of categories that the images are organized
    into.
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立数据集的规模远大于整理数据集，无论是在图像数量还是图像分类数目上。
- en: Out of the box, the trained model for the standalone dataset shows higher accuracy
    (over 95%) than the curated dataset (~80%).
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下，独立数据集的训练模型在准确度上（超过95%）要高于整理数据集（约80%）。
- en: Despite these differences, it is remarkable that fastai can train a model to
    categorize images in the `fruits-360` dataset so easily. As you saw in the recipe
    in this section, you were able to train the model on the `fruits-360` dataset
    and get great performance, with just a few lines of code. I think the model you
    created in this recipe is a great example of the power and flexibility of fastai.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些差异，但值得注意的是，fastai能够如此轻松地训练一个模型来对`fruits-360`数据集中的图像进行分类。正如你在本节中的配方所看到的那样，你能够在`fruits-360`数据集上训练模型，并且只用几行代码就能获得出色的性能。我认为你在本节中创建的模型是fastai强大灵活性的一个绝佳例子。
- en: Training a multi-image classification model with a curated vision dataset
  id: totrans-490
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用策划的视觉数据集训练多图像分类模型
- en: In the *Training a classification model with a simple curated vision dataset*
    recipe, you went through the steps to ingest a fastai curated dataset and used
    it to train an image classification model.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 在*使用简单策划的视觉数据集训练分类模型*食谱中，你已经完成了加载fastai策划数据集并使用它训练图像分类模型的步骤。
- en: 'In this section, you will go through the same process for another curated dataset
    called `PASCAL_2007`. This dataset (described in more detail here: http://host.robots.ox.ac.uk/pascal/VOC/)
    contains about 5,000 training images and the same number of test images. The dataset
    includes annotations that identify common objects that appear in each image. The
    identified objects are from 20 categories, including animals (cow, dog, cat, sheep,
    and horse), vehicles (boat, bus, train, airplane, bicycle, and car), and other
    items (person, sofa, bottle, and TV monitor).'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将为另一个名为`PASCAL_2007`的策划数据集进行相同的操作。这个数据集（在这里有更详细的描述：http://host.robots.ox.ac.uk/pascal/VOC/）包含大约5000张训练图像和相同数量的测试图像。该数据集包括标注，标识出每张图像中出现的常见物体。标识的物体来自20个类别，包括动物（牛、狗、猫、羊和马）、交通工具（船、公交车、火车、飞机、自行车和汽车）以及其他物品（人、沙发、瓶子和电视显示器）。
- en: The images in the `CIFAR` dataset introduced in the *Training a classification
    model with a simple curated vision dataset* recipe had a single labeled object.
    By contrast, the images in `PASCAL_2007` can have zero, one, or more labeled objects.
    As you will see in this section, there are some challenges with training a model
    to predict multiple objects in the same image.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 在*使用简单策划的视觉数据集训练分类模型*食谱中引入的`CIFAR`数据集中的图像只有一个标注的物体。相比之下，`PASCAL_2007`数据集中的图像可以包含零个、一个或多个标注的物体。正如你将在本节中看到的，训练一个能够预测同一图像中多个物体的模型是存在一些挑战的。
- en: In this section, we will ingest the `PASCAL_2007` dataset, including image annotations,
    explore the dataset, train a fastai model to categorize the images according to
    what objects are depicted in the images, and then exercise the trained model on
    some examples from the test dataset.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将加载`PASCAL_2007`数据集，包括图像注释，探索数据集，训练一个fastai模型，根据图像中描绘的物体对图像进行分类，然后在测试数据集中的一些示例上测试训练好的模型。
- en: Getting ready
  id: totrans-495
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Confirm that you can open the `training_with_curated_multi_image_classification_datasets.ipynb`
    notebook in the `ch6` directory of your repo.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 确认你可以在repo的`ch6`目录中打开`training_with_curated_multi_image_classification_datasets.ipynb`笔记本。
- en: 'The `PASCAL_2007` dataset featured in this section is introduced in this paper
    – *The PASCAL Visual Object Classes (VOC) Challenge*: http://host.robots.ox.ac.uk/pascal/VOC/pubs/everingham10.pdf.
    I am grateful for the opportunity to include an example using this dataset in
    this book.'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中介绍的`PASCAL_2007`数据集在以下文献中介绍：*PASCAL视觉物体类别（VOC）挑战*：http://host.robots.ox.ac.uk/pascal/VOC/pubs/everingham10.pdf。非常感谢能够在本书中包含使用该数据集的示例。
- en: Dataset citation
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集引用
- en: Mark Everingham, Luc Van Gool, Christopher K. I. Williams, John Winn, and Andrew
    Zisserman (2008). *The PASCAL Visual Object Classes (VOC) Challenge* (http://host.robots.ox.ac.uk/pascal/VOC/pubs/everingham10.pdf).
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: Mark Everingham、Luc Van Gool、Christopher K. I. Williams、John Winn和Andrew Zisserman（2008年）。*PASCAL视觉物体类别（VOC）挑战*
    (http://host.robots.ox.ac.uk/pascal/VOC/pubs/everingham10.pdf)。
- en: How to do it…
  id: totrans-500
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'In this section, you will be running through the `training_with_curated_multi_image_classification_datasets.ipynb`
    notebook. Once you have the notebook open in your fastai environment, complete
    the following steps:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将运行`training_with_curated_multi_image_classification_datasets.ipynb`笔记本。一旦你在fastai环境中打开了这个笔记本，完成以下步骤：
- en: Run the cells in the notebook up to the `Ingest the dataset` cell to import
    the required libraries and set up your notebook.
  id: totrans-502
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行笔记本中的代码单元，直到`加载数据集`单元，以导入所需的库并设置笔记本环境。
- en: 'Run the following cell to define the `path` object for this dataset:'
  id: totrans-503
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码单元，为此数据集定义`path`对象：
- en: '[PRE67]'
  id: totrans-504
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Run the following cell to examine the directory structure of the dataset:'
  id: totrans-505
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码单元，检查数据集的目录结构：
- en: '[PRE68]'
  id: totrans-506
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The output shows the directory structure of the dataset, as shown in the following
    screenshot:'
  id: totrans-507
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示了数据集的目录结构，如下图所示：
- en: '![Figure 6.48 – Output of path.ls()'
  id: totrans-508
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.48 – path.ls()的输出'
- en: '](img/B16216_6_48.jpg)'
  id: totrans-509
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_48.jpg)'
- en: Figure 6.48 – Output of path.ls()
  id: totrans-510
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.48 – path.ls()的输出
- en: 'Let''s now review the key items in the directory structure of the `PASCAL_2007`
    dataset that we will be using in this recipe:'
  id: totrans-511
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在让我们回顾一下`PASCAL_2007`数据集中我们将在本食谱中使用的目录结构中的关键项：
- en: 'a) `/storage/data/pascal_2007/train`: A directory containing images for training
    the model'
  id: totrans-512
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `/storage/data/pascal_2007/train`：包含用于训练模型的图像的目录
- en: 'b) `/storage/data/pascal_2007/test`: A directory containing images for testing
    the trained model'
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `/storage/data/pascal_2007/test`：包含用于测试训练模型的图像的目录
- en: 'c) `/storage/data/pascal_2007/train.json`: A file containing annotations for
    the training images'
  id: totrans-514
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `/storage/data/pascal_2007/train.json`：包含训练图像注释的文件
- en: 'd) `/storage/data/pascal_2007/test.json`: A file containing annotations for
    test images'
  id: totrans-515
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `/storage/data/pascal_2007/test.json`：包含测试图像注释的文件
- en: 'Run the following cell to bring the annotations in the `train.json` file into
    Python objects:'
  id: totrans-516
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格，将`train.json`文件中的注释转化为Python对象：
- en: '[PRE69]'
  id: totrans-517
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Here are the key parts of the code used in this cell:'
  id: totrans-518
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是此单元格中使用的代码的关键部分：
- en: 'a) `data = json.load(json_file)`: Loads the contents of the whole `train.json`
    file into the `data` dictionary.'
  id: totrans-519
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `data = json.load(json_file)`：将整个`train.json`文件的内容加载到`data`字典中。
- en: 'b) `categories = data[''categories'']`: Creates a separate list of dictionaries
    just for the category definitions. This dictionary defines the objects in the
    images in the dataset.'
  id: totrans-520
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `categories = data['categories']`：创建一个仅用于类别定义的字典列表。这个字典定义了数据集中图像中的对象。
- en: 'c) `images = data[''images'']`: Creates a separate list of dictionaries just
    for image files.'
  id: totrans-521
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `images = data['images']`：创建一个仅用于图像文件的字典列表。
- en: 'd) `annotations = data[''annotations'']`: Creates a separate list of dictionaries
    just for the annotations that specify the objects in the images and their bounding
    boxes.'
  id: totrans-522
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `annotations = data['annotations']`：创建一个仅用于图像中对象及其边界框的注释字典列表。
- en: As you will see in later steps in this recipe, we will not be using the `categories`,
    `images`, and `annotations` lists of dictionaries to extract the annotations to
    feed into the fastai model training process. Instead, we will be using the fastai
    built-in API, `get_annotations`, to work directly with the annotations. The dictionaries
    we define in this cell will, however, be useful to help us to understand the details
    regarding the annotations.
  id: totrans-523
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正如你将在本教程的后续步骤中看到的那样，我们不会使用`categories`、`images`和`annotations`字典列表来提取注释以供fastai模型训练过程使用。相反，我们将使用fastai的内置API，`get_annotations`，直接处理注释。然而，我们在这个单元格中定义的字典，将有助于我们理解关于注释的细节。
- en: 'Run the following cell to see some examples of annotations:'
  id: totrans-524
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格，查看一些注释示例：
- en: '[PRE70]'
  id: totrans-525
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'The output of this cell lists entries from each of the lists of dictionaries
    that you created in the previous cell. As shown in the following screenshot, the
    `categories` list of dictionaries contains the categories of objects that can
    appear in the images along with their IDs:'
  id: totrans-526
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本单元格的输出列出了你在前一个单元格中创建的每个字典列表的条目。如下面的截图所示，`categories`字典列表包含了图像中可能出现的对象类别及其对应的ID：
- en: '![Figure 6.49 – Entries from the categories list of dictionaries'
  id: totrans-527
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.49 – 类别字典列表的条目'
- en: '](img/B16216_6_49.jpg)'
  id: totrans-528
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_49.jpg)'
- en: Figure 6.49 – Entries from the categories list of dictionaries
  id: totrans-529
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.49 – 类别字典列表的条目
- en: 'The following screenshot shows that the `images` list of dictionaries lists
    the filenames of the image files in the training set along with their IDs and
    dimensions:'
  id: totrans-530
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图显示，`images`字典列表列出了训练集中的图像文件名，以及它们的ID和尺寸：
- en: '![Figure 6.50 – Entries from the images list of dictionaries'
  id: totrans-531
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.50 – 图像字典列表的条目'
- en: '](img/B16216_6_50.jpg)'
  id: totrans-532
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_50.jpg)'
- en: Figure 6.50 – Entries from the images list of dictionaries
  id: totrans-533
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.50 – 图像字典列表的条目
- en: 'The following screenshot shows that `annotations` lists the bounding boxes
    and category IDs of the objects that appear in the image with the given `image_id`:'
  id: totrans-534
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图显示，`annotations`列出了给定`image_id`的图像中出现的对象的边界框和类别ID：
- en: '![Figure 6.51 – Entries from the annotations list of dictionaries'
  id: totrans-535
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.51 – 注释字典列表的条目'
- en: '](img/B16216_6_51.jpg)'
  id: totrans-536
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_51.jpg)'
- en: Figure 6.51 – Entries from the annotations list of dictionaries
  id: totrans-537
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.51 – 注释字典列表的条目
- en: 'We will use the fastai function, `get_annotations`, to get all the annotation
    information that we need for a given image, that is, the categories for the objects
    that are depicted in the image. Run the following cell to define the required
    annotation structures:'
  id: totrans-538
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用fastai函数`get_annotations`来获取给定图像所需的所有注释信息，也就是图像中所描绘对象的类别。运行以下单元格以定义所需的注释结构：
- en: '[PRE71]'
  id: totrans-539
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Here are the key parts of the code used in this cell:'
  id: totrans-540
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是此单元格中使用的代码的关键部分：
- en: 'a) `get_annotations(path/''train.json'')`: Applies the `get_annotations` function
    to the `train.json` file to get an annotation structure. The output of this function
    is a list of filenames and a list containing bounding boxes and object categories
    for each object in the image. The following screenshot shows an example of the
    contents of `bbox_lbl`, specifying the bounding boxes and categories for three
    objects:'
  id: totrans-541
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `get_annotations(path/'train.json')`：将`get_annotations`函数应用于`train.json`文件以获取注释结构。此函数的输出是一个文件名列表，以及每个图像中每个对象的边界框和对象类别列表。以下截图显示了`bbox_lbl`的示例内容，指定了三个对象的边界框和类别：
- en: '![Figure 6.52 – Example bounding box and categories'
  id: totrans-542
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.52 – 示例边界框和类别'
- en: '](img/B16216_6_52.jpg)'
  id: totrans-543
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_52.jpg)'
- en: Figure 6.52 – Example bounding box and categories
  id: totrans-544
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.52 – 示例边界框和类别
- en: 'b) `dict(zip(image_files, bbox_lbl))`: Creates a dictionary that combines the
    file list and the labeled bounding box list output from the previous command.'
  id: totrans-545
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `dict(zip(image_files, bbox_lbl))`：创建一个字典，将文件列表和从前一个命令输出的标注边界框列表结合起来。
- en: 'Let''s now take a look at one of the image files from the training set along
    with its annotations. First, run the following cell to see the annotations for
    a specific image file:'
  id: totrans-546
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们来看看训练集中的一个图像文件及其注释。首先，运行以下单元格查看特定图像文件的注释：
- en: '[PRE72]'
  id: totrans-547
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The output shows the annotations associated with this image file:'
  id: totrans-548
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示与该图像文件相关联的注释：
- en: '![Figure 6.53 – Annotations for an image file'
  id: totrans-549
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.53 – 图像文件的注释'
- en: '](img/B16216_6_53.jpg)'
  id: totrans-550
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_53.jpg)'
- en: Figure 6.53 – Annotations for an image file
  id: totrans-551
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.53 – 图像文件的注释
- en: 'Run the following cell to take a look at the image whose annotations we examined
    in the previous cell:'
  id: totrans-552
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格查看我们在前一个单元格中检查过注释的图像：
- en: '[PRE73]'
  id: totrans-553
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The output shows the image associated with `image_files[5]`. As you can see
    in the following image, this image does indeed contain three planes, as indicated
    in the annotations you saw in the previous cell:'
  id: totrans-554
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示与`image_files[5]`相关联的图像。如以下图所示，该图像确实包含三架飞机，这也在前一个单元格中看到的注释中有所指示：
- en: '![Figure 6.54 – Image whose annotation indicates it contains three planes'
  id: totrans-555
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.54 – 标注表明包含三架飞机的图像'
- en: '](img/B16216_6_54.jpg)'
  id: totrans-556
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_54.jpg)'
- en: Figure 6.54 – Image whose annotation indicates it contains three planes
  id: totrans-557
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.54 – 标注表明包含三架飞机的图像
- en: 'Run the following cell to define the `get_category` function to get values
    out of the list of dictionaries you created earlier. We will use this function
    later to examine the annotations of images in the test set:'
  id: totrans-558
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以定义`get_category`函数，从您之前创建的字典列表中提取值。我们稍后将使用此函数来检查测试集中的图像注释：
- en: '[PRE74]'
  id: totrans-559
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Run the following cell to define the `get_lbl` function that takes a filename
    as input and returns the list of category names from the annotation structure
    for that file:'
  id: totrans-560
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以定义`get_lbl`函数，该函数以文件名为输入，并返回该文件注释结构中的类别名称列表：
- en: '[PRE75]'
  id: totrans-561
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Here are the key parts of this function:'
  id: totrans-562
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是这个函数的关键部分：
- en: 'a) `os.path.basename(filename)`: Returns the final part of the fully qualified
    `filename`. For example, if `filename` is the fully qualified name, `/storage/data/pascal_2007/train/006635.jpg`,
    `os.path.basename` returns `006635.jpg`. This conversion is required because the
    input image files will include fully qualified paths, but the `img_bbox_combo`
    structure is indexed with just the final part of the filename.'
  id: totrans-563
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `os.path.basename(filename)`：返回完整路径`filename`的最后部分。例如，如果`filename`是完整路径`/storage/data/pascal_2007/train/006635.jpg`，则`os.path.basename`返回`006635.jpg`。此转换是必需的，因为输入的图像文件将包含完整路径，但`img_bbox_combo`结构仅使用文件名的最后部分进行索引。
- en: 'b) `img_bbox_combo[os.path.basename(filename)][1]`: Returns the categories
    associated with the `filename` image file.'
  id: totrans-564
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `img_bbox_combo[os.path.basename(filename)][1]`：返回与`filename`图像文件相关联的类别。
- en: 'Run the following cell to see an example of how `get_lbl` works:'
  id: totrans-565
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格查看`get_lbl`如何工作的示例：
- en: '[PRE76]'
  id: totrans-566
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'The output, as shown in the following screenshot, is a NumPy array containing
    the categories associated with the `/storage/data/pascal_2007/train/006635.jpg`
    image file:'
  id: totrans-567
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出，如以下截图所示，是一个包含与`/storage/data/pascal_2007/train/006635.jpg`图像文件相关的类别的NumPy数组：
- en: '![Figure 6.55 – Sample output of get_lbl'
  id: totrans-568
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.55 – `get_lbl`的示例输出'
- en: '](img/B16216_6_55.jpg)'
  id: totrans-569
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_55.jpg)'
- en: Figure 6.55 – Sample output of get_lbl
  id: totrans-570
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.55 – `get_lbl`的示例输出
- en: 'It looks like a lot is going on in the image we used as an argument to `get_lbl`
    in the previous cell. Run the following cell to take a look at the image:'
  id: totrans-571
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 看起来我们在前一个单元格中作为`get_lbl`参数使用的图像上发生了很多事情。运行以下单元格查看图像：
- en: '[PRE77]'
  id: totrans-572
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'As shown in the following image, this image matches the annotation we saw in
    the previous cell. It does indeed contain a motorbike along with a bunch of people:'
  id: totrans-573
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如下图所示，这张图片与我们在前一个单元格中看到的注释相匹配。它确实包含了一辆摩托车和一群人：
- en: '![Figure 6.56 – Image with a motorbike and several people'
  id: totrans-574
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.56 – 一张包含摩托车和几个人的图片'
- en: '](img/B16216_6_56.jpg)'
  id: totrans-575
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_56.jpg)'
- en: Figure 6.56 – Image with a motorbike and several people
  id: totrans-576
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.56 – 一张包含摩托车和几个人的图片
- en: 'Run the following cell to examine the number of files in the training and test
    sets for this dataset:'
  id: totrans-577
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格来检查此数据集中训练集和测试集中文件的数量：
- en: '[PRE78]'
  id: totrans-578
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The output, shown in in the following screenshot, shows the number of files
    in each set:'
  id: totrans-579
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出，如下图所示，显示了每个集合中的文件数量：
- en: '![Figure 6.57 – Count of files in the training and test sets'
  id: totrans-580
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.57 – 训练集和测试集中文件数量'
- en: '](img/B16216_6_57.jpg)'
  id: totrans-581
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_57.jpg)'
- en: Figure 6.57 – Count of files in the training and test sets
  id: totrans-582
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.57 – 训练集和测试集中文件数量
- en: 'Run the following cells to see the number of categories in the dataset:'
  id: totrans-583
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格来查看数据集中的类别数量：
- en: '[PRE79]'
  id: totrans-584
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The output, shown in the following screenshot, shows the number of categories
    in the dataset:'
  id: totrans-585
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出，如下图所示，显示了数据集中的类别数量：
- en: '![Figure 6.58 – Number of categories in the dataset'
  id: totrans-586
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.58 – 数据集中的类别数量'
- en: '](img/B16216_6_58.jpg)'
  id: totrans-587
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_58.jpg)'
- en: Figure 6.58 – Number of categories in the dataset
  id: totrans-588
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.58 – 数据集中的类别数量
- en: 'Run the following cell to define the `get_items` function that will be used
    in the `DataBlock` definition to get the input data files:'
  id: totrans-589
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格来定义`get_items`函数，该函数将在`DataBlock`定义中用于获取输入数据文件：
- en: '[PRE80]'
  id: totrans-590
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Here are the key items in this function''s definition:'
  id: totrans-591
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是此函数定义中的关键项：
- en: 'a) `return_list = []`: Initializes the list of image files in the training
    set that have annotations.'
  id: totrans-592
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `return_list = []`：初始化一个包含带注释的训练集图像文件的列表。
- en: 'b) `empty_list = []`: Initializes the list of image files in the training set
    that do not have annotations.'
  id: totrans-593
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `empty_list = []`：初始化一个包含没有注释的训练集图像文件的列表。
- en: 'c) `for file_path in get_image_files(path/''train'')`: Iterates through the
    files in the training set.'
  id: totrans-594
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `for file_path in get_image_files(path/'train')`：遍历训练集中的文件。
- en: 'd) `file_id_list`: Is the list of file IDs in the annotation corresponding
    with the current `file_path`.'
  id: totrans-595
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `file_id_list`：是与当前`file_path`对应的注释中的文件ID列表。
- en: 'e) `if len(file_id_list) > 0`: Checks to see whether `file_id_list` has any
    entries. If it does, the function appends the current `file_path` to `return_list`.
    Otherwise, the function appends the current `file_path` to `empty_list`.'
  id: totrans-596
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e) `if len(file_id_list) > 0`：检查`file_id_list`是否有条目。如果有，函数将当前`file_path`添加到`return_list`中。否则，函数将当前`file_path`添加到`empty_list`中。
- en: 'f) `return(return_list)`: This only returns the subset of image files that
    have annotations associated with them. If you include any of the image files that
    have no annotations associated with them, you will get an error in the step where
    you define a `dataloaders` object.'
  id: totrans-597
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: f) `return(return_list)`：此函数只返回带注释的图像文件子集。如果包括任何没有注释的图像文件，在定义`dataloaders`对象的步骤中会发生错误。
- en: 'Run the following cell to define a `DataBlock` object for the dataset:'
  id: totrans-598
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格来为数据集定义一个`DataBlock`对象：
- en: '[PRE81]'
  id: totrans-599
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Here are the key items in the definition of the `DataBlock` object:'
  id: totrans-600
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是`DataBlock`对象定义中的关键项：
- en: 'a) `blocks=(ImageBlock, MultiCategoryBlock)`: Specifies the type of the input
    data (image files) and that the dataset has multi-category labels, that is, each
    image can have multiple annotated objects in it.'
  id: totrans-601
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `blocks=(ImageBlock, MultiCategoryBlock)`：指定输入数据的类型（图像文件），并表明数据集具有多类别标签，即每张图片可以包含多个标注对象。
- en: 'b) `get_items = get_items`: Specifies the function to apply to get the input
    items; in this case, the `get_items` function we defined in the previous cell
    that returns all the files in the training set that have annotations associated
    with them.'
  id: totrans-602
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `get_items = get_items`：指定用于获取输入项的函数；在此情况下，是我们在前一个单元格中定义的`get_items`函数，它返回所有带有注释的训练集文件。
- en: 'c) `splitter=RandomSplitter()`: Tells fastai to create a validation set from
    randomly selected items from the training set, by default using 20% of the items
    in the training set.'
  id: totrans-603
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) `splitter=RandomSplitter()`：告诉fastai从训练集中随机选择项目来创建验证集，默认使用训练集中的20%的项目。
- en: 'd) `get_y=[get_lbl]`: Specifies the function to get labels for the input, in
    this case, the `get_lbl` function. This function takes a filename as input and
    returns the list of categories from the annotations for that file.'
  id: totrans-604
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `get_y=[get_lbl]`：指定获取输入标签的函数，在此情况下为`get_lbl`函数。该函数以文件名为输入，返回该文件注释中的类别列表。
- en: 'e) `item_tfms = RandomResizedCrop(168, min_scale=0.3)`: Specifies a transformation
    to apply during training. Because the image files in the training set are different
    sizes, we need to transform them all to a common size or we will get errors in
    `show_batch`. This transformation resizes the images by cropping them so they
    are all a common size.'
  id: totrans-605
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e) `item_tfms = RandomResizedCrop(168, min_scale=0.3)`：指定训练过程中应用的转换。由于训练集中的图像文件大小不同，我们需要将它们转换为统一的大小，否则会在`show_batch`中出现错误。此转换通过裁剪图像来调整其大小，使其具有相同的尺寸。
- en: 'f) `n_inp=1`: Specifies which of the elements defined in the `blocks` clause
    of the definition should be considered inputs, in this case, `1` or just `ImageBlock`.'
  id: totrans-606
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: f) `n_inp=1`：指定在定义的`blocks`子句中应视为输入的元素，在此情况下是`1`，即仅为`ImageBlock`。
- en: 'Run the following cell to define a `dataloaders` object using the `DataBlock`
    object, `db`, that you created in the previous cell:'
  id: totrans-607
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以使用你在前一个单元格中创建的`DataBlock`对象`db`来定义`dataloaders`对象：
- en: '[PRE82]'
  id: totrans-608
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Here are the arguments to the `dataloaders` definition:'
  id: totrans-609
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是`dataloaders`定义的参数：
- en: 'a) `path`: Specifies that the source for the `dataloaders` object is the `path`
    object you created earlier in the notebook'
  id: totrans-610
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `path`：指定`dataloaders`对象的源是你在笔记本中之前创建的`path`对象。
- en: 'b) `bs=32`: Specifies that the batch size is `32`'
  id: totrans-611
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `bs=32`：指定批处理大小为`32`。
- en: 'The output of this cell, as shown in the following screenshot, shows the count
    of elements in `return_list` (the list of image files with valid annotations)
    and `empty_list` (the list of image files without valid annotations):'
  id: totrans-612
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此单元格的输出，如下图所示，显示了`return_list`（包含有效注释的图像文件列表）和`empty_list`（没有有效注释的图像文件列表）中元素的数量：
- en: '![Figure 6.59 – Output of the dataloader definition'
  id: totrans-613
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.59 – dataloader定义输出'
- en: '](img/B16216_6_59.jpg)'
  id: totrans-614
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_59.jpg)'
- en: Figure 6.59 – Output of the dataloader definition
  id: totrans-615
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.59 – dataloader定义输出
- en: 'Run the following cell to display a set of samples from a batch:'
  id: totrans-616
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以显示一组来自批次的样本：
- en: '[PRE83]'
  id: totrans-617
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'The output shows a selection of images from the training set along with the
    categories for the objects in the images that are described in the annotation
    corresponding to the image files, as shown in the following screenshot:'
  id: totrans-618
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示来自训练集的图像及其对应图像文件注释中描述的物体类别，如下图所示：
- en: '![Figure 6.60 – Results of show_batch'
  id: totrans-619
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.60 – show_batch的结果'
- en: '](img/B16216_6_60.jpg)'
  id: totrans-620
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_60.jpg)'
- en: Figure 6.60 – Results of show_batch
  id: totrans-621
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.60 – show_batch的结果
- en: 'Run the following cell to define the model by specifying a `cnn_learner` object:'
  id: totrans-622
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以通过指定`cnn_learner`对象来定义模型：
- en: '[PRE84]'
  id: totrans-623
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Here are the arguments to the `cnn_learner` definition:'
  id: totrans-624
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是`cnn_learner`定义的参数：
- en: 'a) `dls`: Specifies that the model is trained using the `dataloaders` object
    you defined in the previous cell'
  id: totrans-625
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `dls`：指定模型使用你在前一个单元格中定义的`dataloaders`对象进行训练。
- en: 'b) `resnet18`: Specifies that the model is based on the pre-trained `resnet18`
    mode.'
  id: totrans-626
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `resnet18`：指定模型基于预训练的`resnet18`模型。
- en: 'Run the following cell to train the model for `10` epochs:'
  id: totrans-627
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以训练模型`10`个epoch：
- en: '[PRE85]'
  id: totrans-628
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'The output lists the training and validation loss for each epoch, as shown
    in the following screenshot. The performance of the model improves as the validation
    loss decreases:'
  id: totrans-629
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出列出了每个epoch的训练和验证损失，如下图所示。随着验证损失的降低，模型的性能得到了提升：
- en: '![Figure 6.61 – Output of training the multi-category image classification
    model'
  id: totrans-630
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.61 – 多类别图像分类模型训练输出'
- en: '](img/B16216_6_61.jpg)'
  id: totrans-631
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_61.jpg)'
- en: Figure 6.61 – Output of training the multi-category image classification model
  id: totrans-632
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.61 – 多类别图像分类模型训练输出
- en: 'Now that we have trained the model, let''s exercise it on some images from
    the test set. To start with, run the following cell to prepare and display one
    of the images from the test set:'
  id: totrans-633
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经训练好了模型，让我们用一些来自测试集的图像来测试它。首先，运行以下单元格以准备并显示测试集中的一张图像：
- en: '[PRE86]'
  id: totrans-634
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'This cell displays the following image:'
  id: totrans-635
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此单元格显示以下图像：
- en: '![Figure 6.62 – Image from the test set'
  id: totrans-636
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.62 – 来自测试集的图像'
- en: '](img/B16216_6_62.jpg)'
  id: totrans-637
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_62.jpg)'
- en: Figure 6.62 – Image from the test set
  id: totrans-638
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.62 – 来自测试集的图像
- en: 'Run the following cell to apply the trained model to the image displayed in
    the previous cell:'
  id: totrans-639
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格，将训练好的模型应用于上一单元格中显示的图像：
- en: '[PRE87]'
  id: totrans-640
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'From the output, as shown in the following screenshot, you can see that the
    model gets the right category for one of the objects in the image, but is wrong
    about the second object in the image:'
  id: totrans-641
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从输出结果中，如下截图所示，你可以看到模型正确地分类了图像中的一个物体，但对图像中的第二个物体的分类是错误的：
- en: '![Figure 6.63 – Model prediction on the image of the horse'
  id: totrans-642
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.63 – 模型对马图像的预测'
- en: '](img/B16216_6_63.jpg)'
  id: totrans-643
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_63.jpg)'
- en: Figure 6.63 – Model prediction on the image of the horse
  id: totrans-644
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.63 – 模型对马图像的预测
- en: 'Run the following cell to prepare and display another image from the test set:'
  id: totrans-645
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格来准备并显示来自测试集的另一张图像：
- en: '[PRE88]'
  id: totrans-646
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'This cell displays the following image:'
  id: totrans-647
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个单元格显示了以下图像：
- en: '![Figure 6.64 – Image from the test set'
  id: totrans-648
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.64 – 来自测试集的图像'
- en: '](img/B16216_6_64.jpg)'
  id: totrans-649
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_64.jpg)'
- en: Figure 6.64 – Image from the test set
  id: totrans-650
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.64 – 来自测试集的图像
- en: 'Run the following cell to apply the trained model to the image displayed in
    the previous cell:'
  id: totrans-651
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格，将训练好的模型应用于上一单元格中显示的图像：
- en: '[PRE89]'
  id: totrans-652
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'From the output, as shown in the following screenshot, you can see that the
    model gets the correct category for the object in the image:'
  id: totrans-653
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从输出结果中，如下截图所示，你可以看到模型正确地分类了图像中的物体：
- en: '![Figure 6.65 – Model prediction on the image of the cat'
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.65 – 模型对猫图像的预测'
- en: '](img/B16216_6_65.jpg)'
  id: totrans-655
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_65.jpg)'
- en: Figure 6.65 – Model prediction on the image of the cat
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.65 – 模型对猫图像的预测
- en: Congratulations! You have trained a fastai model that categorizes multiple objects
    in images.
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！你已经训练了一个fastai模型，能够对图像中的多个物体进行分类。
- en: How it works…
  id: totrans-658
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The recipe in this section is one of the longest, most complex recipes in this
    book. The following are some aspects of the recipe that may not have been evident
    to you as you worked through the steps.
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中的配方是本书中最长、最复杂的配方之一。以下是一些你在完成步骤时可能没有注意到的配方方面。
- en: This recipe uses transfer learning
  id: totrans-660
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本配方使用了迁移学习
- en: If you look at the code from *Step 19* and *Step 20* of the recipe, you will
    see a pattern similar to the model definition and training steps from the recipes
    in the *Training a classification model with a simple curated vision dataset*
    recipe and the *Training a classification model with a standalone vision dataset*
    recipe.
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看*步骤 19*和*步骤 20*中的代码，你会看到一个类似于模型定义和训练步骤的模式，跟*使用简单精心策划的视觉数据集训练分类模型*配方和*使用独立视觉数据集训练分类模型*配方中的步骤相似。
- en: In all of these recipes, you specified a pre-trained model in the model definition
    and then trained the model using a `fine_tune` statement. Taking advantage of
    the pre-trained vision classification model for this recipe makes a lot of sense
    because we had a fairly small training set, as you will see in the following section.
  id: totrans-662
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些配方中，你在模型定义中指定了一个预训练模型，然后使用`fine_tune`语句对模型进行训练。利用这个预训练的视觉分类模型对于本配方是非常合理的，因为我们的训练集相对较小，正如你将在下一部分看到的那样。
- en: This recipe has a small training set for a deep learning model
  id: totrans-663
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本配方的训练集对于深度学习模型来说比较小
- en: 'How big was the training set for this recipe? The initial training set is a
    little over 5,000 images, as you can see in the count of the training set from
    *Step 13* of the recipe:'
  id: totrans-664
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方的训练集有多大？初始训练集稍微超过了5,000张图像，如你在*步骤 13*中看到的训练集数量：
- en: '![Figure 6.66 – Count of items in the training and test sets'
  id: totrans-665
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.66 – 训练集和测试集中项目的数量'
- en: '](img/B16216_6_66.jpg)'
  id: totrans-666
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_66.jpg)'
- en: Figure 6.66 – Count of items in the training and test sets
  id: totrans-667
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.66 – 训练集和测试集中项目的数量
- en: 'However, in *Step 15*, where we defined the `get_items` function, we had to
    filter the list of training images to only include those that had valid category
    annotations. As you can see from the output of *Step 17*, where we define the
    `dataloaders` object and invoke the `get_items` function, less than half of the
    input training images have valid annotations:'
  id: totrans-668
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在*步骤 15*中，我们定义了`get_items`函数时，必须过滤训练图像列表，只保留那些具有有效类别标注的图像。从*步骤 17*的输出中可以看到，我们定义了`dataloaders`对象并调用了`get_items`函数，输入的训练图像中不到一半具有有效的标注：
- en: '![Figure 6.67 – Count of items in return_list and empty_list'
  id: totrans-669
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.67 – return_list和empty_list中的项目数量'
- en: '](img/B16216_6_67.jpg)'
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_67.jpg)'
- en: Figure 6.67 – Count of items in return_list and empty_list
  id: totrans-671
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.67 – return_list和empty_list中的项目数量
- en: What does this mean? It means that we have 2,500 images to train our model.
    Having only 2,500 images to train a complex model has consequences, as we will
    see in the next section.
  id: totrans-672
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着什么？这意味着我们有2,500张图像来训练我们的模型。只有2,500张图像来训练一个复杂的模型，会产生影响，正如我们将在下一节看到的那样。
- en: The trained model from this recipe does not have great performance
  id: totrans-673
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 这个配方训练的模型表现并不出色
- en: The model we trained in the recipe in this section does not have outstanding
    performance. It usually identifies one object in an image correctly, but it often
    doesn't identify more than one object, and when it does identify a second or third
    object, it often assigns these objects to an incorrect category. Why is the performance
    of this model not so good?
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中的配方中训练的模型表现并不突出。它通常能正确识别图像中的一个物体，但往往无法识别多个物体，而且当它能识别第二个或第三个物体时，通常会将这些物体分配到错误的类别。为什么这个模型的表现不好呢？
- en: 'In this recipe, we used only 2,500 images to train a complex model to categorize
    multiple objects in images into 20 categories. Compare this to the `fruits-360`
    dataset used in the *Training a classification model with a standalone vision
    dataset* recipe. The `fruits-360` dataset has over 90,000 images. To see how many
    files there are in the training set, run the following command in your Gradient
    environment:'
  id: totrans-675
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们只使用了2,500张图像来训练一个复杂的模型，将图像中的多个物体分类为20个类别。与*使用独立视觉数据集训练分类模型*配方中使用的`fruits-360`数据集相比，后者有超过90,000张图像。要查看训练集中有多少文件，可以在你的Gradient环境中运行以下命令：
- en: '[PRE90]'
  id: totrans-676
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'The following screenshot shows the output of this command:'
  id: totrans-677
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了该命令的输出：
- en: '![Figure 6.68 – Count of images in the fruits-360 training set'
  id: totrans-678
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.68 – `fruits-360`训练集中的图像数量](img/B16216_6_68.jpg)'
- en: '](img/B16216_6_68.jpg)'
  id: totrans-679
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16216_6_68.jpg)'
- en: Figure 6.68 – Count of images in the fruits-360 training set
  id: totrans-680
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.68 – `fruits-360`训练集中的图像数量
- en: There are over 67,500 files in the training set for the `fruits-360` dataset.
    This means that for the first curated image dataset problem we saw in this chapter,
    we had 25 times as many training samples as we had for the recipe in this section,
    and in the first instance, we applied the model to the simpler problem of identifying
    a single object in each image. The relative lack of training images in the `PASCAL_2007`
    dataset could partially explain the mediocre performance of the model we trained
    with this dataset.
  id: totrans-681
  prefs: []
  type: TYPE_NORMAL
  zh: '`fruits-360`数据集的训练集包含超过67,500个文件。这意味着，在本章中我们看到的第一个精心策划的图像数据集问题中，我们的训练样本是本节配方的25倍，并且在第一个实例中，我们将模型应用于识别每张图像中的单一物体这一相对简单的问题。`PASCAL_2007`数据集中训练图像的相对不足，可能部分解释了我们用这个数据集训练的模型表现平平。'
- en: Test your knowledge
  id: totrans-682
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试你的知识
- en: Of the four application areas that fastai explicitly supports (tabular, text,
    recommender systems, and image/vision), fastai provides the most thorough support
    for creating models that work with image datasets. In this chapter, we have just
    scratched the surface of what you can do with fastai and image datasets. In this
    section, you will get a chance to dig a bit deeper into one of the fastai image
    dataset recipes from this chapter.
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: 在fastai明确支持的四个应用领域（表格、文本、推荐系统和图像/视觉）中，fastai为使用图像数据集创建模型提供了最全面的支持。在本章中，我们仅仅触及了fastai和图像数据集的部分应用。接下来，你将有机会更深入地了解本章中的fastai图像数据集配方。
- en: Getting ready
  id: totrans-684
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Ensure that you have followed the *Training a multi-image classification model
    with a curated vision dataset* recipe. In this section, you will be adapting the
    notebook you worked through in that recipe to try some new variations on deep
    learning with image datasets.
  id: totrans-685
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已经完成了*使用精心策划的视觉数据集训练多图像分类模型*配方。在本节中，你将根据该配方中的笔记本，尝试对图像数据集进行深度学习的新的变动。
- en: How to do it…
  id: totrans-686
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做……
- en: 'You can follow the steps in this section to try some variations on the image
    classification model that you trained with the `PASCAL_2007` dataset in the *Training
    a multi-image classification model with a curated vision dataset* recipe:'
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按照本节中的步骤，尝试对你用`PASCAL_2007`数据集训练的图像分类模型做一些变动，参考*使用精心策划的视觉数据集训练多图像分类模型*配方：
- en: 'Make a copy of the `training_with_curated_multi_image_classification_datasets.ipynb`
    notebook that you worked through in the *Training a multi-image classification
    model with a curated vision dataset* recipe. Give your new copy of the notebook
    the following name: `training_with_curated_multi_image_classification_datasets_variations.ipynb`.'
  id: totrans-688
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`training_with_curated_multi_image_classification_datasets.ipynb`笔记本的副本，这是你在*使用精选视觉数据集训练多图像分类模型*食谱中使用过的。将新副本命名为：`training_with_curated_multi_image_classification_datasets_variations.ipynb`。
- en: 'Run the notebook up to and including the model definition cell:'
  id: totrans-689
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行笔记本，直到并包括模型定义单元：
- en: '[PRE91]'
  id: totrans-690
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Add the following cell immediately after this cell and run it:'
  id: totrans-691
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此单元后立即添加以下单元并运行它：
- en: '[PRE92]'
  id: totrans-692
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'The output of this cell lists the structure of the model. Note the summary
    of trainable and non-trainable parameters at the end of the output, as shown in
    the following screenshot:'
  id: totrans-693
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此单元的输出列出了模型的结构。请注意输出末尾的可训练和非可训练参数的总结，如下图所示：
- en: '![Figure 6.69 – Trainable parameter description at the end of the summary output
    before fine-tuning'
  id: totrans-694
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.69 – 微调前总结输出末尾的可训练参数描述'
- en: '](img/B16216_6_69.jpg)'
  id: totrans-695
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_69.jpg)'
- en: Figure 6.69 – Trainable parameter description at the end of the summary output
    before fine-tuning
  id: totrans-696
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.69 – 微调前总结输出末尾的可训练参数描述
- en: 'Update the model training cell to train for 20 epochs and then run it:'
  id: totrans-697
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新模型训练单元，将训练次数设置为20个周期，然后运行它：
- en: '[PRE93]'
  id: totrans-698
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: The output of this cell, as shown in the following screenshot, shows how the
    training loss and validation loss develop through the epochs. Note how the training
    loss decreases steadily right up to the 20th epoch, while the validation loss
    decreases up to the 10th epoch, after which it goes up and down. What problem
    is evident in a situation like this, where the training loss keeps dropping but
    the validation loss stops dropping?
  id: totrans-699
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此单元的输出，如下图所示，显示了训练损失和验证损失在各个周期中的变化情况。注意训练损失在第20个周期之前稳步下降，而验证损失在第10个周期之后下降，然后开始波动。在这种情况下，训练损失不断下降，但验证损失停止下降，这表明了什么问题？
- en: '![Figure 6.70 – Results of a 20-epoch training run'
  id: totrans-700
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.70 – 20个周期训练运行的结果'
- en: '](img/B16216_6_70.jpg)'
  id: totrans-701
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_70.jpg)'
- en: Figure 6.70 – Results of a 20-epoch training run
  id: totrans-702
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.70 – 20个周期训练运行的结果
- en: The previous step shows us that training for more epochs won't improve the model's
    performance. You can validate this for yourself by running the rest of the notebook
    and comparing how well the model trained with 20 epochs predicts the objects in
    the selected test images.
  id: totrans-703
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上一步显示训练更多周期并不会改善模型性能。你可以通过运行笔记本的其余部分并比较使用20个周期训练的模型如何预测所选测试图像中的物体来验证这一点。
- en: 'Add the following immediately after the model training cell and run it:'
  id: totrans-704
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在模型训练单元后立即添加以下内容并运行它：
- en: '[PRE94]'
  id: totrans-705
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: The output of this cell lists the structure of the model. Note the summary of
    trainable and non-trainable parameters at the end of the output, as shown in the
    following screenshot. Compare this output to the output from `summary()` prior
    to fine-tuning the model, as shown in *Step 3*. What has changed to explain the
    difference in the output of `summary()` between *Step 3* and this step?
  id: totrans-706
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此单元的输出列出了模型的结构。请注意输出末尾的可训练和非可训练参数的总结，如下图所示。将此输出与微调模型前`summary()`的输出进行比较，如*步骤3*所示。输出中`summary()`的差异变化有什么解释？
- en: '![Figure 6.71 – Trainable parameter description at the end of the summary output
    after fine-tuning'
  id: totrans-707
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.71 – 微调后总结输出末尾的可训练参数描述'
- en: '](img/B16216_6_71.jpg)'
  id: totrans-708
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16216_6_71.jpg)'
- en: Figure 6.71 – Trainable parameter description at the end of the summary output
    after fine-tuning
  id: totrans-709
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.71 – 微调后总结输出末尾的可训练参数描述
- en: 'In the *How it works…* section of the previous recipe, we looked at the size
    of the training set for `PASCAL_2007` and suggested that its small size could
    be a reason for the unimpressive performance of the model. One other potential
    culprit is the way that we are resizing the images in the definition of the `DataBlock`
    object, shown in the following cell:'
  id: totrans-710
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在之前食谱的*工作原理...*部分中，我们查看了`PASCAL_2007`的训练集大小，并提出其较小的大小可能是模型性能不理想的原因之一。另一个潜在原因是我们在定义`DataBlock`对象时调整图像大小的方式，如下单元所示：
- en: '[PRE95]'
  id: totrans-711
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: The transformation that resizes the images is `RandomResizedCrop(168, min_scale=0.3)`.
    Update the `DataBlock` definition cell to try different image transformations.
    First, update the `RandomResizedCrop` function call to try a different image size
    and a different `min_scale` value. Train and exercise the model again on samples
    from the test set to see whether the performance changes for different image sizes
    and `min_scale` values.
  id: totrans-712
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用于调整图像大小的转换是`RandomResizedCrop(168, min_scale=0.3)`。更新`DataBlock`定义单元格，尝试不同的图像转换。首先，更新`RandomResizedCrop`函数调用，尝试不同的图像大小和`min_scale`值。然后再次训练并在测试集的样本上测试模型，查看不同图像大小和`min_scale`值是否会改变性能。
- en: 'Try using `Resize` rather than `RandomResizedCrop` as the transformation function
    (as shown in the following cell) and train the model again. See whether you get
    better results when you exercise the trained model on sample images from the training
    set:'
  id: totrans-713
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试使用`Resize`而不是`RandomResizedCrop`作为转换函数（如下面的单元格所示），然后重新训练模型。查看在训练集的样本图像上使用训练好的模型时，是否能获得更好的结果：
- en: '[PRE96]'
  id: totrans-714
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: Congratulations! You have completed a review of training the fastai model on
    image datasets.
  id: totrans-715
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！你已经完成了在图像数据集上训练 fastai 模型的复习。
