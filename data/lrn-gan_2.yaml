- en: Chapter 2. Unsupervised Learning with GAN
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章：使用GAN进行无监督学习
- en: Recently, with the progress of generative models, neural networks can not only
    recognize images but they can be used to generate audio and realistic images as
    well.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，随着生成模型的进步，神经网络不仅能识别图像，还能用来生成音频和逼真的图像。
- en: In this chapter, we will deep dive into the creative nature of deep learning
    through the latest state of the art algorithm of **Generative Adversarial Network**,
    commonly known as **GAN**. You will learn through hands-on examples to use the
    generative ability of the neural networks in generating realistic images from
    various real-world datasets (such as `MNIST` and `CIFAR`). Also, you will understand
    how to overcome the major challenge of unsupervised learning with deep networks
    using semi-supervised approach and apply it to your own problem domain. In the
    final section of this chapter, you will learn some of the training obstacles followed
    by practical tips and tricks of working with GAN models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将通过**生成对抗网络**（Generative Adversarial Network），也就是通常所说的**GAN**，深入探讨深度学习的创造性特点。你将通过动手实例学习如何利用神经网络的生成能力，从各种现实世界的数据集（如`MNIST`和`CIFAR`）中生成逼真的图像。同时，你将理解如何通过半监督学习方法克服深度网络在无监督学习中的主要挑战，并将其应用到自己的问题领域。在本章的最后，你将学习一些训练中遇到的障碍，并获得一些实用的GAN模型工作技巧和窍门。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将覆盖以下主题：
- en: What is GAN? its application, tips, and tricks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是GAN？它的应用、技巧与窍门
- en: Explaining the concept of GAN through two-layer neural network image generation
    with TensorFlow
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过TensorFlow解释GAN的概念，使用双层神经网络生成图像
- en: Image generation with **Deep Convolutional GAN** (**DCGAN**) using Keras
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Keras生成**深度卷积GAN**（**DCGAN**）的图像
- en: Implementation of semi-supervised learning using TensorFlow
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorFlow实现半监督学习
- en: Automating human tasks with deep neural networks
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用深度神经网络自动化人类任务
- en: In the last few years, there has been an explosion of deep neural networks that
    can perform image classification, voice recognition, and understanding natural
    language with good accuracy.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几年里，深度神经网络的爆炸式发展使得它们能够在图像分类、语音识别和自然语言理解方面取得良好的准确性。
- en: The current state of the art algorithms within the field of deep neural network
    are able to learn highly complex models of the patterns inherent in a set of data.
    While the capabilities are impressive, human beings are capable of doing much
    more than just image recognition or understanding what people are talking about
    and automating those tasks through machines seems far-fetched.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当前深度神经网络领域的先进算法能够学习数据集中的高度复杂的模式模型。虽然这些能力令人印象深刻，但人类能够做的远不止图像识别或理解人们在说什么，自动化这些任务通过机器实现似乎仍然遥不可及。
- en: 'Let us see some use cases where we need human creativity (at least as of now):'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些需要人类创造力的应用场景（至少目前是这样）：
- en: Training an artificial author that can write an article and explain data science
    concepts to a community in a very simplistic manner by learning from past articles
    from Wikipedia
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练一个人工作者，能够写文章并以非常简单的方式向社区解释数据科学概念，通过学习Wikipedia中过去的文章
- en: Creating an artificial painter that can paint like any famous artist by learning
    from his/her past collections
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个人工画家，能够通过学习某位著名艺术家的过去作品来像他/她一样作画
- en: Do you believe that machines are capable of accomplishing these tasks? To your
    surprise the answer is "YES".
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你相信机器能够完成这些任务吗？令你惊讶的是，答案是“YES”。
- en: Of course, these are difficult tasks to automate, but GANs have started making
    some of these tasks possible.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这些任务很难自动化，但GAN已经开始让其中一些任务成为可能。
- en: 'Yann LeCun, a prominent figure in the deep learning domain (Director of Facebook
    AI) said that:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Yann LeCun，深度学习领域的知名人物（Facebook AI的总监）曾说：
- en: Generative Adversarial Network (GANs), and the variations that are now being
    proposed is the most interesting idea in the last 10 years in Machine Learning.
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 生成对抗网络（GANs）及其目前提出的各种变体是过去10年中机器学习领域最有趣的想法。
- en: If you feel intimidated by the name GAN, don't worry! You will master this technique
    and apply it to real-world problems yourself by the end of this book.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你觉得GAN这个名字让你感到害怕，别担心！到本书结束时，你将掌握这项技术，并能将其应用于现实问题。
- en: The purpose of GAN
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GAN的目的
- en: Some generative models are able to generate samples from model distribution.
    GANs are an example of generative models. GAN focuses primarily on generating
    samples from distribution.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一些生成模型能够从模型分布中生成样本。GAN是生成模型的一个例子。GAN主要集中在从分布中生成样本。
- en: You might be wondering why generative models are worth studying, especially
    generative models that are only capable of generating data rather than providing
    an estimate of the density function.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道为什么生成模型值得研究，尤其是那些只能生成数据，而不是提供密度函数估计的生成模型。
- en: 'Some of the reasons to study generative models are as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 学习生成模型的一些原因如下：
- en: Sampling (or generation) is straightforward
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 采样（或生成）是直接的
- en: Training doesn't involve maximum likelihood estimation
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练不涉及最大似然估计
- en: Robust to overfitting since the generator never sees the training data
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对过拟合具有鲁棒性，因为生成器从不接触训练数据
- en: GANs are good at capturing the modes of distribution
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GAN擅长捕捉分布的模式
- en: An analogy from the real world
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现实世界的类比
- en: 'Let''s consider the real-world relationship between a money counterfeiting
    criminal and the police. Let''s enumerate the objective of the criminal and the
    police in terms of money:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑现实世界中，一个伪造货币的罪犯和警察之间的关系。让我们从金钱的角度列举罪犯和警察的目标：
- en: '![An analogy from the real world](img/B08086_02_1.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![现实世界的类比](img/B08086_02_1.jpg)'
- en: 'Figure1a: GAN real world analogy'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图1a：GAN的现实世界类比
- en: To become a successful money counterfeiter, the criminal needs to fool the police
    so that the police can't tell the difference between the counterfeit/fake money
    and real money
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要成为一名成功的伪造货币者，罪犯需要欺骗警察，使警察无法分辨伪造/假币和真币之间的区别。
- en: As a paragon of justice, the police want to detect fake money as effectively
    as possible
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为正义的典范，警察希望尽可能有效地检测假币。
- en: 'This can be modeled as a minimax game in game theory. This phenomenon is called
    **adversarial process**. GAN, introduced by Ian Goodfellow in 2014 at *arXiv:
    1406.2661*, is a special case of an adversarial process where two neural networks
    compete against each other. The first network generates data and the second network
    tries to find the difference between the real data and the fake data generated
    by the first network. The second network will output a scalar [0, 1], which represents
    a probability of real data.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '这可以被建模为博弈论中的极小化最大化博弈。这种现象被称为**对抗过程**。GAN，由Ian Goodfellow于2014年在*arXiv: 1406.2661*中提出，是对抗过程的一个特例，其中两个神经网络相互竞争。第一个网络生成数据，第二个网络尝试找出真实数据和第一个网络生成的假数据之间的差异。第二个网络将输出一个标量[0,
    1]，表示真实数据的概率。'
- en: The building blocks of GAN
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GAN的构建模块
- en: 'In GAN, the first network is called generator and is often represented as *G(z)*
    and the second network is called discriminator and is often represented as *D(x)*:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在GAN中，第一个网络被称为生成器，通常表示为*G(z)*，第二个网络被称为判别器，通常表示为*D(x)*：
- en: '![The building blocks of GAN](img/B08086_02_2.png.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![GAN的构建模块](img/B08086_02_2.png.jpg)'
- en: 'Figure 1b: Generative adversarial network'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图1b：生成对抗网络
- en: 'At the equilibrium point, which is the optimal point in the minimax game, the
    first network will model the real data and the second network will output a probability
    of 0.5 as the output of the first network = real data:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在平衡点上，这是极小化最大化博弈中的最优点，第一个网络将建模真实数据，第二个网络将输出一个概率0.5，作为第一个网络 = 真实数据的输出：
- en: '![The building blocks of GAN](img/B08086_02_3.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![GAN的构建模块](img/B08086_02_3.jpg)'
- en: 'Sometimes the two networks eventually reach equilibrium, but this is not always
    guaranteed and the two networks can continue learning for a long time. An example
    of learning with both generator and discriminator loss is shown in the following
    figure:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有时两个网络最终达到平衡，但这并不总是保证的，两个网络可能会继续学习很长时间。下面的图示展示了生成器和判别器损失的学习过程：
- en: '![The building blocks of GAN](img/B08086_02_4.png.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![GAN的构建模块](img/B08086_02_4.png.jpg)'
- en: 'Figure 1c: Loss of two networks, generator and discriminator'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图1c：两个网络的损失，生成器和判别器
- en: Generator
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成器
- en: The generator network takes as input random noise and tries to generate a sample
    of data. In the preceding figure, we can see that generator *G(z)* takes an input
    *z* from probability distribution *p(z)* and generates data that is then fed into
    a discriminator network *D(x)*.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器网络以随机噪声作为输入，尝试生成一个数据样本。在前面的图中，我们可以看到生成器*G(z)*从概率分布*p(z)*中获取输入*z*，然后生成数据，数据随后被输入到判别器网络*D(x)*。
- en: Discriminator
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 判别器
- en: The discriminator network takes input either from the real data or from the
    generator's generated data and tries to predict whether the input is real or generated.
    It takes an input *x* from real data distribution *P* *[data]* *(x)* and then
    solves a binary classification problem giving output in the scalar range 0 to
    1.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器网络输入可以来自真实数据或生成器生成的数据，并试图预测输入是否为真实数据还是生成数据。它从真实数据分布 *P* *[data]* *(x)* 中获取输入
    *x*，然后解决一个二分类问题，输出在 0 到 1 的标量范围内。
- en: GANs are gaining lot of popularity because of their ability to tackle the important
    challenge of unsupervised learning, since the amount of available unlabeled data
    is much larger than the amount of labeled data. Another reason for their popularity
    is that GANs are able to generate the most realistic images among generative models.
    Although this is subjective, it is an opinion shared by most practitioners.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 正在获得大量的关注，因为它们能够解决无监督学习中的重要挑战，毕竟可用的无标签数据远远大于有标签数据的数量。另一个它们受欢迎的原因是 GANs
    能够生成在生成模型中最真实的图像。虽然这是主观的，但这是大多数从业者的共同观点。
- en: '![Discriminator](img/B08086_02_5.png.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![判别器](img/B08086_02_5.png.jpg)'
- en: 'Figure-1d: Vector arithmetic in GANs'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图-1d：GAN 中的向量算术
- en: 'Beside this, GAN is often very expressive: it can perform arithmetic operations
    in the latent space, that is the space of the z vectors, and translate into corresponding
    operations in feature space. As shown in *Figure 1d*, if you take the representation
    of a man with glasses in latent space, subtract the `neutral man` vector and add
    back the `neutral woman` vector, you end up with a picture of a woman with glasses
    in feature space. This is truly amazing.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，GAN 通常非常具有表现力：它能够在潜在空间中执行算术操作，即 z 向量的空间，并将这些操作转换为特征空间中的相应操作。如 *图 1d* 所示，如果你在潜在空间中取一个戴眼镜的男人的表示，减去
    `中性男人` 向量并加上 `中性女人` 向量，你会在特征空间中得到一个戴眼镜的女人的图像。这真是令人惊叹。
- en: Implementation of GAN
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN 实现
- en: 'As per the definition of GAN, we basically require two networks, be it a sophisticated
    network such as ConvNet or a simple two-layer neural network. Let''s use a simple
    two-layer neural network with the `MNIST` dataset using TensorFlow for implementation
    purposes. `MNIST` is a dataset of handwritten digits where each image is gray
    scale of dimension 28x28 pixel:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 GAN 的定义，我们基本上需要两个网络，无论是像 ConvNet 这样的复杂网络，还是简单的两层神经网络。为了实现目的，让我们使用简单的两层神经网络和
    `MNIST` 数据集来进行 TensorFlow 的实现。`MNIST` 是一个手写数字数据集，每个图像是 28x28 像素的灰度图：
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `generator(z)` takes as input a 100-dimensional vector from a random distribution
    (in this case we are using uniform distribution) and returns a 786-dimensional
    vector, which is a `MNIST` image (28x28). The `z` here is the prior for the *G(z)*.
    In this way, it learns a mapping between the prior space to *p* [*data*] (real
    data distribution):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`generator(z)` 接受一个来自随机分布的 100 维向量（在这种情况下我们使用均匀分布）作为输入，并返回一个 786 维的向量，这就是一个
    `MNIST` 图像（28x28）。这里的 `z` 是 *G(z)* 的先验。通过这种方式，它学习了先验空间到 *p* [*数据*]（真实数据分布）之间的映射关系：'
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Whereas the `discriminator(x)` takes `MNIST` image(s) as input and returns
    a scalar that represents a probability of real image. Now, let''s discuss an algorithm
    for training GAN. Here''s the pseudo code for a training algorithm from the paper
    *arXiv: 1406.2661, 2014*:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`discriminator(x)` 将 `MNIST` 图像作为输入并返回一个标量，表示真实图像的概率。现在，让我们讨论一个训练 GAN 的算法。以下是论文
    *arXiv: 1406.2661, 2014* 中的训练算法伪代码：'
- en: '![Implementation of GAN](img/B08086_02_6.png.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![GAN 实现](img/B08086_02_6.png.jpg)'
- en: 'Figure 1e: GAN training algorithm pseudo-code'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1e：GAN 训练算法伪代码
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The TensorFlow optimizer can only do minimization, so in order to maximize
    the `loss` function, we are using a negative sign for the loss as seen previously.
    Also, as per the paper''s pseudo algorithm, it''s better to maximize `tf.reduce_mean(tf.log(D_fake))`
    instead of minimizing `tf.reduce_mean(1 - tf.log(D_fake)`. Then we train the networks
    one by one with those preceding `loss` functions:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 优化器只能进行最小化操作，因此为了最大化 `loss` 函数，我们使用负号来表示损失函数，如前所述。此外，根据论文的伪算法，最好最大化
    `tf.reduce_mean(tf.log(D_fake))`，而不是最小化 `tf.reduce_mean(1 - tf.log(D_fake))`。然后，我们逐个训练这些网络，并使用前述的
    `loss` 函数进行训练：
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: After that we start with random noise and as the training continues, `G(Z)`
    starts moving towards *p* [*data*]. This is proved by the more similar samples
    generated by `G(Z)` compared to original MNIST images.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们从随机噪声开始，随着训练的进行，`G(Z)` 开始向 *p* [*数据*] 移动。这一点可以通过 `G(Z)` 生成的样本与原始 MNIST
    图像的相似度来证明。
- en: 'Some of the output generated after 60,000 iterations is shown as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 以下展示了经过60,000次迭代后生成的一些输出：
- en: '![Implementation of GAN](img/B08086_02_7.png.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![GAN实现示意图](img/B08086_02_7.png.jpg)'
- en: 'Figure 1f: GAN implementation of a generated output image'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图1f：GAN生成输出图像的实现
- en: Applications of GAN
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GAN的应用
- en: 'GAN is generating lots of excitement in a wide variety of fields. Some of the
    exciting applications of GAN in recent years are listed as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: GAN在多个领域引起了广泛的关注。近年来，GAN的一些令人兴奋的应用如下所示：
- en: Translating one image to another (such as horse to zebra) with CycleGAN and
    performing image editing through Conditional GAN. Details will be covered in [Chapter
    3](ch03.html "Chapter 3. Transfer Image Style Across Various Domains"), *Transfer
    Image Style Across Various Domains*.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CycleGAN将一种图像转换为另一种图像（例如从马到斑马），并通过条件GAN进行图像编辑。具体内容将在[第3章](ch03.html "第3章.
    跨领域转移图像风格")，*跨领域转移图像风格*中介绍。
- en: Automatic synthesis of realistic images from a textual sentence using StackGAN.
    And transferring style from one domain to another domain using **Discovery GAN**
    (**DiscoGAN**). Details will be covered in [Chapter 4](ch04.html "Chapter 4. Building
    Realistic Images from Your Text"), *Building Realistic Images from Your Text*.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用StackGAN从文本句子自动合成逼真的图像，并使用**Discovery GAN**（**DiscoGAN**）将一种风格转移到另一个领域。具体内容将在[第4章](ch04.html
    "第4章. 从文本生成逼真的图像")，*从文本生成逼真的图像*中介绍。
- en: Enhancing image quality and generating high resolution images with pre-trained
    models using SRGAN. Details will be covered in [Chapter 5](ch05.html "Chapter 5. Using
    Various Generative Models to Generate Images"), *Using Various Generative Models
    to Generate Images*.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预训练模型通过SRGAN提高图像质量并生成高分辨率图像。具体内容将在[第5章](ch05.html "第5章. 使用各种生成模型生成图像")，*使用各种生成模型生成图像*中介绍。
- en: '**Generating realistic a image from attributes**: Let''s say a burglar comes
    to your apartment but you don''t have a picture of him/her. Now the system at
    the police station could generate a realistic image of the thief based on the
    description provided by you and search a database. For more information refer
    to *arXiv: 1605.05396, 2016*.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**根据属性生成逼真图像**：假设一个小偷闯入你的公寓，但你没有他的照片。现在，警察局的系统可以根据你提供的描述生成小偷的逼真图像，并在数据库中进行搜索。更多信息请参考*arXiv:
    1605.05396, 2016*。'
- en: 'Predicting the next frame in a video or dynamic video generation: ([http://carlvondrick.com/tinyvideo/](http://carlvondrick.com/tinyvideo/)).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测视频中的下一帧或动态视频生成：（[http://carlvondrick.com/tinyvideo/](http://carlvondrick.com/tinyvideo/)）。
- en: Image generation with DCGAN using Keras
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Keras实现DCGAN生成图像
- en: 'The **Deep Convolutional Generative Adversarial Networks** (**DCGAN**) are
    introduced in the paper: *Unsupervised Representation Learning with Deep Convolutional
    Generative Adversarial Networks*, by *A. Radford, L. Metz, and S. Chintala, arXiv:1511.06434,
    2015*.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中介绍了**深度卷积生成对抗网络**（**DCGAN**）：*无监督表示学习与深度卷积生成对抗网络*，由*A. Radford, L. Metz,
    和 S. Chintala，arXiv:1511.06434, 2015*。
- en: 'The generator uses a 100-dimensional, uniform distribution space, *Z*, which
    is then projected into a smaller space by a series of convolution operations.
    An example is shown in the following figure:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器使用一个100维的均匀分布空间，*Z*，然后通过一系列卷积操作将其映射到一个更小的空间。以下图示为例：
- en: '![Image generation with DCGAN using Keras](img/B08086_02_8.png.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![使用Keras实现DCGAN生成图像](img/B08086_02_8.png.jpg)'
- en: 'Figure 2: DCGAN architecture of the generator'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：生成器的DCGAN架构
- en: 'Source: arXiv, 1511.06434,2015'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：arXiv, 1511.06434, 2015
- en: 'DCGAN stabilizes the networks with the following architectural constraints:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: DCGAN通过以下架构约束来稳定网络：
- en: Replace any pooling layers with strided convolutions in the discriminator and
    fractional-strided convolutions in the generator
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在鉴别器中用步长卷积替换所有池化层，在生成器中用分数步长卷积替换
- en: Use batchnorm in both the generator and the discriminator
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生成器和鉴别器中都使用批量归一化（batchnorm）
- en: Remove fully connected hidden layers for deeper architectures and simply use
    average pooling at the end
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除深层架构中的全连接隐藏层，只在末尾使用平均池化
- en: Use ReLU activation in the generator for all layers except for the output, which
    uses `tanh`
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生成器的所有层中使用ReLU激活函数，输出层使用`tanh`
- en: Use leaky ReLU activation in the discriminator for all layers
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在鉴别器的所有层中使用leaky ReLU激活函数
- en: 'A DCGAN generator can be described by the following code implemented in Keras,
    available at: [https://github.com/jacobgil/keras-dcgan](https://github.com/jacobgil/keras-dcgan).'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Keras 中实现的 DCGAN 生成器可以通过以下代码描述，代码位于：[https://github.com/jacobgil/keras-dcgan](https://github.com/jacobgil/keras-dcgan)。
- en: 'Start the training/generation process with the following command:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令启动训练/生成过程：
- en: '[PRE4]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Image generation with DCGAN using Keras](img/B08086_02_9.png.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Keras 的 DCGAN 进行图像生成](img/B08086_02_9.png.jpg)'
- en: Note that the number of batches printed previously is calculated based on input
    image shape/batch size (provided).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，先前打印的批次数是基于输入图像形状/批次大小（提供的）计算的。
- en: 'Now let''s jump into the code. The generator can be described with the following:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看代码。生成器可以通过以下方式描述：
- en: '[PRE5]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The first dense layer of the generator takes as input a vector of 100 dimensions
    and it produces output of 1,024 dimensions with the activation function `tanh`.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器的第一个密集层接受一个100维向量作为输入，并使用 `tanh` 激活函数生成 1,024 维的输出。
- en: 'The next dense layer in the network produces data of 128 x 7 x 7 in the output
    using batch normalization (refer to *Batch Normalization Accelerating Deep Network
    Training by Reducing Internal Covariate Shift*, by *S. Ioffe* and *C.Szegedy*,
    *arXiv: 1502.03167*, 2014), a technique that often helps to stabilize learning
    by normalizing the input with zero mean and unit variance. Batch normalization
    has been empirically proven to speed up training in many situations, reduce the
    problems of poor initialization, and in general produce more accurate results.
    There is also a `Reshape()` module that produces data of 128 x 7 x 7 (128 channels,
    7 width, and 7 height), `dim_ordering` to `tf`, and a `UpSampling()` module that
    produces a repetition of each one into a 2 x 2 square. After that, we have a convolutional
    layer that produces 64 filters on 5 x 5 convolutional kernels/patches with `tanh`
    activation having same padding followed by a new `UpSampling()` and a final convolution
    with one filter, and on 5 x 5 convolutional kernels with the activation as `tanh`.
    Note that there are no pooling operations in the ConvNet.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '网络中的下一个稠密层通过批量归一化生成 128 x 7 x 7 的输出数据（参考*S. Ioffe*和*C.Szegedy*的文章*《Batch Normalization
    Accelerating Deep Network Training by Reducing Internal Covariate Shift》*，*arXiv:
    1502.03167*，2014），这种技术通常通过将输入归一化为零均值和单位方差来帮助稳定学习。经验表明，批量归一化在许多情况下可以加快训练速度，减少糟糕初始化的问题，并且通常产生更精确的结果。还有一个
    `Reshape()` 模块生成了 128 x 7 x 7（128 个通道，7 宽，7 高）的数据，`dim_ordering` 设置为 `tf`，并且 `UpSampling()`
    模块将每个数据重复成一个 2 x 2 的方块。随后是一个卷积层，使用 5 x 5 的卷积核生成 64 个滤波器，激活函数为 `tanh`，具有相同填充，然后是一个新的
    `UpSampling()` 和一个最终的卷积层，使用一个滤波器，大小为 5 x 5，激活函数为 `tanh`。请注意，在 ConvNet 中没有池化操作。'
- en: 'The discriminator can be described with the following code:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码描述了判别器：
- en: '[PRE6]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The discriminator takes a standard MNIST image with the shape (`1, 28, 28`)
    and applies a convolution with 64 filters of size 5 x 5 with `tanh` as the activation
    function. It is then followed by a max-pooling operation of size 2 x 2 and by
    a further convolution max-pooling operation.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器使用形状为(`1, 28, 28`)的标准 MNIST 图像，并应用了包含 64 个 5 x 5 大小滤波器和 `tanh` 激活函数的卷积。接着是一个大小为
    2 x 2 的最大池化操作，然后是进一步的卷积最大池化操作。
- en: 'The last two stages are dense, with the final one being the prediction for
    forgery, which consists of only a single neuron with a `sigmoid` activation function.
    For a given number of epochs, the generator and discriminator are trained by using
    `binary_crossentropy` as a `loss` function. At each epoch, the generator makes
    a prediction of a number (for example, it creates forged MNIST images) and the
    discriminator tries to learn after mixing the prediction with real MNIST images.
    After a few epochs, the generator automatically learns to forge this set of handwritten
    numbers:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两个阶段是密集的，最后一个是关于伪造预测的，仅包含一个使用 `sigmoid` 激活函数的神经元。对于给定的周期数，生成器和判别器使用 `binary_crossentropy`
    作为 `loss` 函数进行训练。在每个周期中，生成器预测一个数字（例如，创建伪造的 MNIST 图像），判别器试图在将预测与真实的 MNIST 图像混合后进行学习。经过几个周期，生成器自动学习伪造这组手写数字：
- en: '![Image generation with DCGAN using Keras](img/B08086_02_10.png.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Keras 的 DCGAN 进行图像生成](img/B08086_02_10.png.jpg)'
- en: 'Figure-3: Deep convolutional GAN generated handwritten digit output'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图-3：深度卷积 GAN 生成的手写数字输出
- en: Note that training GANs could be very difficult because it is necessary to find
    the equilibrium between two players and hence some of the valuable techniques
    and tips used by practitioners are given in the final section of this chapter.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，训练GAN可能非常困难，因为需要在两个参与者之间找到平衡，因此，实践者使用的一些有价值的技术和提示将在本章的最后部分给出。
- en: Implementing SSGAN using TensorFlow
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用TensorFlow实现SSGAN
- en: The basic intuition of **Semi-Supervised Learning Generative Adversarial Network**
    (**SSGAN**) is to exploit the samples generated by generators to enhance the performance
    of image classification tasks of the discriminator by improving generalization.
    The key idea is to train one of the networks as both image classifier and discriminator
    (to identify generated images from real images).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**半监督学习生成对抗网络**（**SSGAN**）的基本直觉是利用生成器生成的样本，通过提高泛化能力，增强判别器在图像分类任务中的表现。关键思想是将其中一个网络训练为图像分类器和判别器（用于区分生成的图像与真实图像）。'
- en: 'For a dataset having *n* classes, the dual trained (discriminator/classifier)
    network will take an image as input and classify the real images into the first
    *n* classes and generated images into the *n+1-th* class, as shown in the following
    figure:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个具有*n*类的数据集，经过双重训练（判别器/分类器）的网络将图像作为输入，真实图像分类为前*n*类，生成图像分类为*n+1*类，如下图所示：
- en: '![Implementing SSGAN using TensorFlow](img/B08086_02_11.png.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![使用TensorFlow实现SSGAN](img/B08086_02_11.png.jpg)'
- en: 'Source: [https://github.com/gitlimlab/SSGAN-Tensorflow/blob/master/figure/ssgan.png](https://github.com/gitlimlab/SSGAN-Tensorflow/blob/master/figure/ssgan.png)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：[https://github.com/gitlimlab/SSGAN-Tensorflow/blob/master/figure/ssgan.png](https://github.com/gitlimlab/SSGAN-Tensorflow/blob/master/figure/ssgan.png)
- en: 'This multi-tasking learning framework consists of two losses, first the supervised
    loss:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这个多任务学习框架由两个损失组成，第一个是监督损失：
- en: '![Implementing SSGAN using TensorFlow](img/B08086_02_12.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![使用TensorFlow实现SSGAN](img/B08086_02_12.jpg)'
- en: 'and second the GAN loss of a discriminator:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 其次是判别器的GAN损失：
- en: '![Implementing SSGAN using TensorFlow](img/B08086_02_13.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![使用TensorFlow实现SSGAN](img/B08086_02_13.jpg)'
- en: During the training phase, both these losses are jointly minimized.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练阶段，这两个损失函数将一起最小化。
- en: Setting up the environment
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 环境设置
- en: 'Perform the following steps to execute SSGAN on Cifar-10 datasets:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以在Cifar-10数据集上运行SSGAN：
- en: 'Clone the `git` repo: [https://github.com/gitlimlab/SSGAN-Tensorflow](https://github.com/gitlimlab/SSGAN-Tensorflow):![Setting
    up the environment](img/B08086_02_14.png.jpg)'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆`git`仓库：[https://github.com/gitlimlab/SSGAN-Tensorflow](https://github.com/gitlimlab/SSGAN-Tensorflow)：![环境设置](img/B08086_02_14.png.jpg)
- en: 'Change the directory:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更改目录：
- en: '[PRE7]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Download the `CIFAR-10` dataset:![Setting up the environment](img/B08086_02_15.png.jpg)
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载`CIFAR-10`数据集：![环境设置](img/B08086_02_15.png.jpg)
- en: Train the model:![Setting up the environment](img/B08086_02_16.png.jpg)
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型：![环境设置](img/B08086_02_16.png.jpg)
- en: 'Test or evaluate the model:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试或评估模型：
- en: '[PRE8]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now let''s dive into the code. The generator takes random noise from the uniform
    distribution:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们深入代码。生成器从均匀分布中获取随机噪声：
- en: '[PRE9]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then the generator model flattens the input noise to 1 dimensional vector using
    the `reshape` method. It then applies three layers of deconvolution on the input
    noise having `ReLU` activation and then applies one more deconvolution with `tanh`
    activation to generate the output image of dimension [*h*=height, *w*=width, *c*],
    where *c* is the number of channels (grayscale images: 1, color images: 3):'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，生成器模型使用`reshape`方法将输入噪声展平为一维向量。接着，它对输入噪声应用三层反卷积，激活函数为`ReLU`，然后再应用一次反卷积，激活函数为`tanh`，以生成输出图像，尺寸为[*h*=高度,
    *w*=宽度, *c*]，其中*c*为通道数（灰度图像：1，彩色图像：3）：
- en: '[PRE10]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The discriminator takes images as input and tries to output into a `n+1` class
    label. It applies some layers of convolution having leaky ReLU with batch normalization,
    followed by dropout on the input images, and finally outputs the class `label`
    using the `softmax` function:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器将图像作为输入，并尝试输出`n+1`类标签。它应用一些具有泄漏ReLU和批归一化的卷积层，接着对输入图像进行dropout，最后使用`softmax`函数输出类`label`：
- en: '[PRE11]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The discriminator network has two `loss` functions, one (`s_loss`) for the
    supervise classification of real data from CIFAR-10 images using huber loss (Huber
    loss is robust to outliers compared to squared error loss) and the other (`d_loss`)
    loss to classify the generated images by the generator as real/fake in scalar
    form using `softmax` function with cross entropy:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器网络有两个`loss`函数，一个（`s_loss`）用于使用Huber损失对CIFAR-10图像中的真实数据进行监督分类（Huber损失比平方误差损失更能抵抗异常值），另一个（`d_loss`）用于使用`softmax`函数和交叉熵对生成的图像进行真/假分类，以标量形式表示：
- en: '[PRE12]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Setting up the environment](img/B08086_02_17.png.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![设置环境](img/B08086_02_17.png.jpg)'
- en: 'Figure: 4a: Supervise loss of discriminator'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图：4a：监督判别器的损失
- en: '[PRE13]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![Setting up the environment](img/B08086_02_18.png.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![设置环境](img/B08086_02_18.png.jpg)'
- en: 'Figure: 4b: Total discriminator loss (real + fake loss)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图：4b：总判别器损失（真实 + 假损失）
- en: '[PRE14]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注释
- en: 'Note: Weight annealing is done as an auxiliary loss to help the generator get
    rid of the initial local minimum.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 注：权重退火作为辅助损失帮助生成器摆脱初始的局部最小值。
- en: '![Setting up the environment](img/B08086_02_19.png.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![设置环境](img/B08086_02_19.png.jpg)'
- en: 'Figure: 4c: Generator loss'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图：4c：生成器损失
- en: 'The `loss` function of both the generator and discriminator network is optimized
    with `AdamOptimizer` and gradient clipping (`clip_gradients`) is applied with
    it to stabilize the training:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器和判别器网络的`loss`函数使用`AdamOptimizer`进行优化，并且应用梯度裁剪（`clip_gradients`）来稳定训练过程：
- en: '[PRE15]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, both the supervised loss (`s_loss`) and generative adversarial loss
    (which is the combination of discriminator loss (`d_loss`) and generator loss
    (`g_loss`)) are trained jointly to minimize the total loss:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，监督损失（`s_loss`）和生成对抗损失（即判别器损失（`d_loss`）和生成器损失（`g_loss`）的组合）一起训练，以最小化总损失：
- en: '[PRE16]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The output of generated samples after 150 epochs is as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 经过150个epochs后生成的样本输出如下：
- en: '![Setting up the environment](img/B08086_02_20.png.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![设置环境](img/B08086_02_20.png.jpg)'
- en: Challenges of GAN models
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN模型的挑战
- en: Training a GAN is basically about two networks, generator *G(z)* and discriminator
    *D(z)*, trying to race against each other and trying to reach an optimum, more
    specifically a nash equilibrium. The definition of nash equilibrium as per Wikipedia
    (in economics and game theory) is a stable state of a system involving the interaction
    of different participants, in which no participant can gain by a unilateral change
    of strategy if the strategies of the others remain unchanged.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 训练GAN基本上是两个网络，生成器*G(z)*和判别器*D(z)*，相互竞争，试图达到最优解，更具体地说，是达到纳什均衡。根据维基百科（在经济学和博弈论中），纳什均衡的定义是：一个系统的稳定状态，涉及不同参与者之间的相互作用，在这种状态下，如果其他参与者的策略保持不变，则没有参与者能够通过单方面改变策略来获益。
- en: Setting up failure and bad initialization
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置失败和坏的初始化
- en: If you think about it, this is exactly what GAN is trying to do; the generator
    and discriminator reach a state where they cannot improve any further given the
    other is kept unchanged. Now the setup of gradient descent is to take a step in
    a direction that reduces the loss measure defined on the problem—but we are by
    no means enforcing the networks to reach Nash equilibrium in GAN, which have non-convex
    objective with continuous high dimensional parameters. The networks try to take
    successive steps to minimize a non-convex objective and end up in an oscillating
    process rather than decreasing the underlying true objective.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细想一想，这正是GAN试图做的事情；生成器和判别器达到一种状态，即在另一个保持不变的情况下，它们无法进一步改进。现在，梯度下降的设置是沿着一个方向迈出一步，从而减少定义在问题上的损失度量——但是我们并不强迫网络在GAN中达到纳什均衡，毕竟GAN具有非凸目标且包含连续的高维参数。网络试图通过连续的步骤来最小化一个非凸目标，结果进入了一个振荡过程，而不是减少潜在的真实目标。
- en: In most cases, when your discriminator attains a loss very close to zero, then
    right away you can figure out something is wrong with your model. But the biggest
    difficulty is figuring out what is wrong.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，当判别器的损失接近零时，你可以立刻发现模型存在问题。但最大的问题是弄清楚问题出在哪里。
- en: Another practical thing done during the training of GAN is to purposefully make
    one of the networks stall or learn slower, so that the other network can catch
    up. And in most scenarios, it's the generator that lags behind so we usually let
    the discriminator wait. This might be fine to some extent, but remember that for
    the generator to get better, it requires a good discriminator and vice versa.
    Ideally the system would want both the networks to learn at a rate where both
    get better over time. The ideal minimum loss for the discriminator is close to
    0.5— this is where the generated images are indistinguishable from the real images
    from the perspective of the discriminator.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 训练GAN时，另一个常见的做法是故意让其中一个网络停滞或学习得更慢，以便另一个网络能够赶上。在大多数情况下，落后的通常是生成器，因此我们通常让判别器等待。这在一定程度上可能是可以接受的，但请记住，为了让生成器变得更好，它需要一个好的判别器，反之亦然。理想情况下，系统希望两个网络都以一种互相促进的速度学习，让两者随时间不断进步。判别器的理想最小损失接近0.5——这意味着从判别器的角度看，生成的图像与真实图像无法区分。
- en: Mode collapse
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模式崩溃
- en: One of the main failure modes with training a generative adversarial network
    is called mode collapse or sometimes the helvetica scenario. The basic idea is
    that the generator can accidentally start to produce several copies of exactly
    the same image, so the reason is related to the game theory setup. We can think
    of the way that we train generative adversarial networks as first maximizing with
    respect to the discriminator and then minimizing with respect to the generator.
    If we fully maximize with respect to the discriminator before we start to minimize
    with respect to the generator, everything works out just fine. But if we go the
    other way around and we minimize with respect to the generator and then maximize
    with respect to the discriminator, everything will actually break and the reason
    is that if we hold the discriminator constant, it will describe a single region
    in space as being the point that is most likely to be real rather than fake and
    then the generator will choose to map all noise input values to that same most
    likely to be real point.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 训练生成对抗网络时的主要失败模式之一叫做模式崩溃，或者有时称为Helvetica情境。基本思想是生成器可能会不小心开始生成完全相同的多个副本，原因与博弈论的设定有关。我们可以把训练生成对抗网络的方式看作是先相对于判别器进行最大化，然后再相对于生成器进行最小化。如果我们在开始最小化生成器之前，完全相对于判别器进行最大化，一切都会顺利进行。但如果我们反过来，先最小化生成器，再最大化判别器，一切就会崩溃。原因是，如果我们保持判别器不变，它会将空间中的单一区域描述为最可能是真实的点，而不是虚假的点，然后生成器会选择将所有噪声输入值映射到那个最可能是真实的点。
- en: Problems with counting
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计数问题
- en: 'GANs can sometimes be far-sighted and fail to differentiate the number of particular
    objects that should occur at a location. As we can see, it gives more numbers
    of eyes in the head than originally present:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: GAN有时会出现远视现象，无法区分某个位置应出现的特定物体数量。如我们所见，它给头部生成了比原本更多的眼睛：
- en: '![Problems with counting](img/B08086_02_21.png.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![计数问题](img/B08086_02_21.png.jpg)'
- en: 'Source: NIPS 2016- arXiv: 1701.00160, 2017'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '来源：NIPS 2016- arXiv: 1701.00160, 2017'
- en: Problems with perspective
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 透视问题
- en: 'GANs sometimes are not capable of differentiating between front and back view
    and hence fail to adapt well with 3D objects while generating 2D representations
    from it, as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: GAN有时无法区分前后视角，因此在从3D物体生成2D表示时，未能很好地适应，如下所示：
- en: '![Problems with perspective](img/B08086_02_22.png.jpg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![透视问题](img/B08086_02_22.png.jpg)'
- en: 'Source: NIPS 2016- *arXiv: 1701.00160, 2017*'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '来源：NIPS 2016- *arXiv: 1701.00160, 2017*'
- en: Problems with global structures
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全球结构问题
- en: GANs do not understand holistic structures, similar to problems with perspective.
    For example, in the bottom left image, it generates an image of a quadruple cow,
    that is, a cow standing on its hind legs and simultaneously on all four legs.
    That is definitely unrealistic and not possible in real life!
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: GAN（生成对抗网络）无法理解整体结构，类似于透视问题。例如，在左下方的图像中，它生成了一只四条腿的牛，也就是一只同时用后腿站立并且四条腿都着地的牛。这显然是不现实的，现实生活中是无法做到的！
- en: '![Problems with global structures](img/B08086_02_23.png.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![全球结构问题](img/B08086_02_23.png.jpg)'
- en: 'Source: NIPS 2016- *arXiv: 1701* *.00160, 2017*'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '来源：NIPS 2016- *arXiv: 1701* *.00160, 2017*'
- en: Improved training approaches and tips for GAN
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进的GAN训练方法和技巧
- en: In order to overcome the difficulties of GAN models, deep learning practitioners
    carry out various hacks depending on the nature of the problem. Some of the improvisation
    techniques are mentioned in the following sections.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服GAN模型的困难，深度学习实践者根据问题的性质采取各种方法。一些改进技巧将在以下部分中提到。
- en: Feature matching
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征匹配
- en: The instability of GANs is addressed by specifying a new objective for the generator
    that prevents it from overtraining on the current discriminator.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的不稳定性通过为生成器指定一个新的目标来解决，该目标防止生成器在当前判别器上过度训练。
- en: The idea is to use the features at the intermediate layers in the discriminator
    to match for real and fake images and make this as a supervisory signal to train
    the generator.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是使用判别器中间层的特征来匹配真实和虚假图像，并将其作为监督信号来训练生成器。
- en: Specifically, we train the generator to generate data that matches the statistics
    of the real data, and match the expected value of the features on an intermediate
    layer of the discriminator. By training the discriminator, we ask it to find those
    features that are most discriminative of real data versus data generated by the
    current model.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们训练生成器生成与真实数据统计特征匹配的数据，并匹配判别器中间层特征的期望值。通过训练判别器，我们要求它找到最能区分真实数据与当前模型生成数据的特征。
- en: Mini batch
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小批量
- en: The problem of mode collapse can be addressed by adding some extra features
    to the discriminator where the discriminator actually looks at an entire "mini
    batch of samples" at a time rather than looking at a single sample. If those features
    measure things such as distance to other samples, then the discriminator can detect
    if the generator is starting to collapse in this way instead of encouraging every
    sample from the generator to move towards the single most likely point. The mini
    batch as a whole has to look realistic and have the correct amount of spacing
    between different samples.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 模式崩塌问题可以通过向判别器添加一些额外的特征来解决，其中判别器实际上一次查看一个完整的“样本小批量”，而不是只查看单个样本。如果这些特征测量的是与其他样本的距离，那么判别器就能检测到生成器是否开始以这种方式崩塌，而不是鼓励生成器的每个样本都向最可能的单一点逼近。小批量整体必须看起来真实，并且不同样本之间要有适当的间隔。
- en: Historical averaging
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 历史平均
- en: 'The idea of historical averaging is to add a penalty term that punishes weights
    that are rather far away from their historical average values. For example, the
    cost is:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 历史平均的思想是添加一个惩罚项，惩罚那些远离其历史平均值的权重。例如，损失函数是：
- en: '[PRE17]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: One-sided label smoothing
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单边标签平滑
- en: Usually one would use the labels 0 (image is real) and 1 (image is fake). Instead
    using some smoother labels (0.1 and 0.9) seems to make networks more resistant
    to adversarial examples.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 通常会使用标签0（图像为真实）和1（图像为虚假）。然而，使用一些更平滑的标签（0.1和0.9）似乎能使网络更能抵抗对抗样本。
- en: Normalizing the inputs
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输入归一化
- en: Most of the time it is good to normalize the images between -1 and 1 and use
    `tanh` as the last layer of the generator output.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，将图像归一化到-1和1之间，并使用`tanh`作为生成器输出的最后一层是一个不错的选择。
- en: Batch norm
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 批量归一化
- en: The idea is to construct different mini batches for real and fake, that is,
    each mini batch needs to contain only all real images or all generated images.
    But when batch norm is not an option, you can use instance normalization (for
    each sample, subtract mean and divide by standard deviation).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是为真实和虚假数据构建不同的小批量，即每个小批量只包含所有真实图像或所有生成图像。但当批量归一化不可用时，可以使用实例归一化（对于每个样本，减去均值并除以标准差）。
- en: Avoiding sparse gradients with ReLU, MaxPool
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 避免使用ReLU、MaxPool时的稀疏梯度
- en: The stability of the GAN game suffers if you have sparse gradients. Leaky ReLU
    is a good fit for both generator and discriminator.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果梯度稀疏，GAN的稳定性会受到影响。Leaky ReLU对于生成器和判别器都是一个不错的选择。
- en: 'In case of down-sampling, use a combination of average pooling, `Conv2d + stride`,
    whereas for up-sampling, use the combination of `PixelShuffle`, `ConvTranspose2d
    + stride`:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在下采样时，使用平均池化和`Conv2d + stride`的组合，而在上采样时，使用`PixelShuffle`、`ConvTranspose2d +
    stride`的组合：
- en: '[PRE18]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Optimizer and noise
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化器与噪声
- en: Use the ADAM optimizer for generators and SGD for discriminators. And provide
    noise in the form of dropout to several layers of generator.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 使用ADAM优化器用于生成器，使用SGD用于判别器。同时，在生成器的多个层中引入dropout形式的噪声。
- en: Don't balance loss through statistics only
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不要仅通过统计量来平衡损失
- en: 'Instead have a principled approach to it, rather than intuition:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，采用有原则的方法，而非直觉：
- en: '[PRE19]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Note: Despite all these tips and training enhancement steps, the Generative
    Adversarial model is still relatively new in the field of AI and deep learning
    and so like any other fast growing field, it too requires a lot of improvement.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：尽管有这些技巧和训练增强步骤，生成对抗模型在人工智能和深度学习领域仍然相对较新，因此像任何其他快速发展的领域一样，它也需要大量的改进。
- en: Summary
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: So far you have learned how deep learning made its progress into the unsupervised
    arena through the concepts of GAN. You have already generated some realistic images
    such as handwritten digits, airplanes, cars, birds, and so on using `MNIST`, `CIFAR`
    datasets. Also, you have understood various challenges related to Generative Adversarial
    Network and how to overcome it with practical tuning tips.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经了解了深度学习是如何通过GAN的概念进入无监督学习领域的。你已经使用`MNIST`、`CIFAR`数据集生成了一些逼真的图像，比如手写数字、飞机、汽车、鸟类等。此外，你还了解了与生成对抗网络相关的各种挑战，并学会了如何通过实际的调整技巧克服这些挑战。
- en: In the next few chapters, we will continue our journey with a different variety
    of GAN-based architecture to perform some magnificent tasks with real datasets.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几章中，我们将继续探索基于GAN的不同架构，利用真实数据集执行一些令人惊叹的任务。
