- en: 'Section 3 –     Running Deep Learning Pipelines at Scale'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3节 – 在大规模下运行深度学习管道
- en: In this section, we will learn how to run **deep learning** (**DL**) pipelines
    in different execution environments and perform hyperparameter tuning, or **hyperparameter
    optimization** (**HPO**), at scale. We will start with an overview of the scenarios
    and requirements for executing DL pipelines in different environments. We will
    then learn how to use MLflow's **command-line interface** (**CLI**) to run in
    four different execution scenarios in a distributed environment. From there on,
    we will learn how to choose the best HPO framework by comparing **Ray Tune**,
    **Optuna**, and **HyperOpt** for tuning hyperparameters of a DL pipeline. Finally,
    we will concentrate on how to implement and run HPO for DL at scale using state-of-the-art
    HPO frameworks such as Ray Tune and MLflow.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何在不同的执行环境中运行**深度学习**（**DL**）管道，并进行超参数调优，或**超参数优化**（**HPO**），以实现大规模处理。我们将从概述执行DL管道的场景和要求开始。接着，我们将学习如何使用MLflow的**命令行接口**（**CLI**）在分布式环境中运行四种不同的执行场景。之后，我们将通过比较**Ray
    Tune**、**Optuna**和**HyperOpt**，学习如何选择最佳的HPO框架来调优DL管道的超参数。最后，我们将重点讨论如何利用最新的HPO框架，如Ray
    Tune和MLflow，实施并运行大规模的DL超参数优化。
- en: 'This section comprises the following chapters:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包括以下章节：
- en: '[*Chapter 5*](B18120_05_ePub.xhtml#_idTextAnchor060), *Running DL Pipelines
    in Different Environments*'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第5章*](B18120_05_ePub.xhtml#_idTextAnchor060)，*在不同环境中运行深度学习管道*'
- en: '[*Chapter 6*](B18120_06_ePub.xhtml#_idTextAnchor069), *Running Hyperparameter
    Tuning at Scale*'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B18120_06_ePub.xhtml#_idTextAnchor069)，*大规模运行超参数调优*'
