- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: 'Developing and Operationalizing LLM-based Apps: Exploring Dev Frameworks and
    LLMOps'
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于 LLM 的应用的开发与实施：探索开发框架和 LLMOps
- en: Have you heard about GitHub Copilot? Claude by Anthropic? Jasper?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你听说过 GitHub Copilot、Anthropic 的 Claude 还是 Jasper 吗？
- en: If not, these solutions are all applications that have integrated generative
    AI. That is, they have taken the next step in our AI journey by using LLMs to
    create more engaging and meaningful interactions with users and other applications.
    These are just a few examples, with many, many more generative AI-infused applications
    coming to the market every day!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有，这些解决方案都是集成了生成式 AI 的应用程序。也就是说，他们通过使用 LLM 来创建与用户和其他应用程序的更具吸引力和更有意义的交互，在我们的
    AI 之旅中迈出了下一步。这只是几个例子，每天都有许多、许多新的生成式 AI 应用程序进入市场！
- en: As you have content already learned from the start of this book, generative
    AI is a branch of AI that focuses on creating new or enhancing content using existing
    data. Of course, generative AI can produce text, images, audio, video, or any
    other type of data that can be represented digitally, and you know that there
    are countless generative AI **large language models** (**LLMs**) already available,
    with new ones being added each day. Some models are very specific to certain tasks,
    such as DALL-E, which simply takes your text prompt input and generates an actual
    image based on that prompt input.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你已经从本书的开头学到了一些内容，生成式 AI 是一种关注使用现有数据创建新内容或增强内容的 AI 分支。当然，生成式 AI 可以生成文本、图像、音频、视频或任何其他可以数字表示的数据，你知道已经有无数可用的生成式
    AI **大型语言模型**（**LLMs**），每天都有新的模型被添加。一些模型非常特定于某些任务，例如 DALL-E，它只是根据你的文本提示输入生成基于该提示输入的实际图像。
- en: However, for almost all companies, universities, government entities, or organizations
    of any size, their business requirements and technical requirements are beyond
    just a simple text input to then generate an image or use a simple playground
    to cut and paste some prompts to see their completions.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于几乎所有的公司、大学、政府实体或任何规模的组织来说，他们的业务需求和技术需求远不止于简单的文本输入来生成图像，或者使用简单的沙盒来剪切粘贴一些提示以查看它们的完成情况。
- en: This chapter is mainly focused on how the development and operationalization
    of a generative AI application may contain many new concepts and techniques, especially
    for those not in software development. We will first cover some of the concepts,
    such as copilots and agents. Then, we will discuss how to convert these concepts
    into tactical solutions using popular application programming frameworks related
    to generative AI, such as **Semantic Kernel** (**SK**), **LangChain**, and **LlamaIndex**.
    These programming frameworks enable additional LLM tooling using agents and workflows,
    allowing developers to build generative AI-aware, intelligent applications and
    services in a much simpler yet much more powerful way. We will then cover a very
    exciting topic that we think will take AI to the next level, which is agent collaboration
    frameworks that help you build **autonomous agents**, such as **Autogen**, **Taskweaver**,
    and **AutoGPT**.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章主要关注生成式 AI 应用的发展与实施可能包含许多新的概念和技术，尤其是对于那些不从事软件开发的人来说。我们首先将介绍一些概念，例如协同编程器和代理。然后，我们将讨论如何使用与生成式
    AI 相关的流行应用程序编程框架，如 **语义内核**（**SK**）、**LangChain** 和 **LlamaIndex**，将这些概念转化为战术解决方案。这些编程框架通过代理和工作流程使额外的
    LLM 工具化成为可能，允许开发者以更简单、更强大的方式构建感知生成式 AI 的智能应用程序和服务。然后，我们将介绍一个非常激动人心的主题，我们认为这将把
    AI 推向下一个水平，即代理协作框架，这些框架可以帮助你构建 **自主代理**，例如 **Autogen**、**Taskweaver** 和 **AutoGPT**。
- en: The final section will focus on operationalizing generative AI applications
    in production. We will outline a systematic approach to harness the extensive
    capabilities of generative AI, which fulfills the complex requirements of organizations,
    utilizing a process known as **large language model operations** (**LLMOps**).
    Understanding the necessity of adopting LLMOps is crucial; it’s a key element
    for streamlined operations and a pathway to successfully developing generative
    AI-aware applications. This section will reiterate the systematic method to leverage
    generative AI’s broad capabilities and meet organizational needs, highlighting
    the importance of LLMOps for efficient operations and the development of successful
    applications.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一节将重点关注在生产中实施生成式AI应用。我们将概述一种系统方法来利用生成式AI的广泛能力，满足组织的复杂需求，利用一种称为**大型语言模型操作**（**LLMOps**）的过程。理解采用LLMOps的必要性至关重要；它是简化操作和成功开发生成式AI感知应用的关键要素。本节将重申利用生成式AI广泛能力并满足组织需求的方法，强调LLMOps对高效操作和成功应用开发的重要性。
- en: 'We will cover the following main topics in this book:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将涵盖以下主要主题：
- en: Copilots and agents
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 共同飞行员和代理
- en: Generative AI application development frameworks
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI应用开发框架
- en: Autonomous agents
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自主代理
- en: Agent collaboration frameworks
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理协作框架
- en: LLM LLMOps – Operationalizing LLM apps in production
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM LLMOps – 在生产中实施LLM应用
- en: LLMOps – Case study and best practices
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMOps – 案例研究和最佳实践
- en: '![Figure 6.1 – Relationships in an autonomous world](img/B21443_06_1.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图6.1 – 自主世界中的关系](img/B21443_06_1.jpg)'
- en: Figure 6.1 – Relationships in an autonomous world
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 – 自主世界中的关系
- en: 'Before we dive into the modern AI application development frameworks, we need
    to understand two concepts that haven’t been touched on in the previous chapters:
    agents and copilots.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入现代AI应用开发框架之前，我们需要了解两个在前几章中未涉及的概念：代理和共同飞行员。
- en: Copilots and agents
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 共同飞行员和代理
- en: Traditional chatbots have undergone significant evolution, transitioning into
    more sophisticated forms such as copilots, agents, and autonomous agents. In this
    section, we aim to compare and contrast these advanced chatbot types, exploring
    their roles and utilization in contemporary applications.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的聊天机器人经历了显著的演变，过渡到更复杂的形态，如共同飞行员、代理和自主代理。在本节中，我们旨在比较和对比这些高级聊天机器人类型，探讨它们在当代应用中的作用和利用。
- en: '![Figure 6.2 – Evolution from chatbots to autonomous agents](img/B21443_06_02.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图6.2 – 从聊天机器人到自主代理的演变](img/B21443_06_02.jpg)'
- en: Figure 6.2 – Evolution from chatbots to autonomous agents
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 – 从聊天机器人到自主代理的演变
- en: '**Agents** are skilled assistants and, in the context described, are pieces
    of code equipped with AI capabilities. They are designed to complete tasks by
    interacting with users through applications or other interfaces. Initially, they
    gather information from users and subsequently utilize this data to **execute
    actions**, which may include feeding it into LLMs or a sequence of LLMs, among
    other possibilities.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**代理**是熟练的助手，在所描述的上下文中，它们是具备AI能力的代码片段。它们被设计成通过与用户通过应用程序或其他界面交互来完成任务。最初，它们从用户那里收集信息，随后利用这些数据**执行动作**，这可能包括将其输入到LLM或一系列LLM中，以及其他可能性。'
- en: For example, a data analyst agent can analyze your Excel sheets by asking for
    your raw Excel file and any other questions it may have; then, it will generate
    its own plan of action intelligently, execute those actions, and provide you the
    final insights on your data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个数据分析代理可以通过请求您的原始Excel文件和可能的其他问题来分析您的Excel表格；然后，它将智能地生成自己的行动计划，执行这些行动，并为您提供关于您数据的最终见解。
- en: '**Copilots** are collaboration tools in the form of chatbots integrated into
    applications, and they use LLM to assist users to perform a task specific to that
    application and get an instant productivity boost. They represent a specialized
    subset within the broader category of agents.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**共同飞行员**是集成到应用程序中的聊天机器人形式的协作工具，它们使用LLM协助用户执行特定于该应用程序的任务，并获得即时生产力提升。它们代表了代理更广泛类别中的一个专业子集。'
- en: Copilots, such as GitHub Copilot and Power BI Copilot, are integrated into applications
    to assist users in completing tasks, such as generating code or offering troubleshooting
    recommendations based on natural language queries.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 共同飞行员，如GitHub Copilot和Power BI Copilot，被集成到应用程序中以协助用户完成任务，例如根据自然语言查询生成代码或提供故障排除建议。
- en: Microsoft employs copilots extensively, integrating them into their next-generation
    AI-integrated products, such as Microsoft 365 apps. These copilots combine LLMs
    with user data and other Microsoft applications using the semantic kernel (SK)
    framework that we discuss in the next section. Copilots work alongside users,
    providing AI-powered assistance in tasks such as drafting documents or generating
    code. Imagine them as helpful copilots in the cockpit of a plane, assisting the
    pilot. By using a semantic kernel framework, developers can access the same AI
    integration and orchestration patterns used by Microsoft’s copilots in their own
    applications. For more information on how Microsoft utilizes AI models and SK
    in Copilots, refer to Kevin Scott’s Microsoft Build 2023 talk, *The Era of the*
    *AI Copilot*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 微软广泛地使用共飞行员，将它们集成到下一代AI集成产品中，如Microsoft 365应用。这些共飞行员结合了LLM、用户数据和微软的其他应用，使用我们在下一节中讨论的语义内核（SK）框架。共飞行员与用户并肩工作，在诸如起草文档或生成代码等任务中提供AI辅助。想象一下，它们就像飞机驾驶舱中的有益共飞行员，协助飞行员。通过使用语义内核框架，开发者可以访问与微软共飞行员在他们的应用中使用相同的AI集成和编排模式。有关微软如何利用AI模型和SK在共飞行员中的更多信息，请参阅Kevin
    Scott在2023年Microsoft Build会议上的演讲，*AI共飞行员时代*。
- en: Now, let’s understand how to convert these concepts (agents, copilots, RAG (this
    was discussed in [*Chapter 4*](B21443_04.xhtml#_idTextAnchor070))) into tactical
    solutions using frameworks such as Semantic Kernel, Langchain, and Llamaindex.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们了解如何使用诸如语义内核、Langchain和Llamaindex等框架将这些概念（代理、共飞行员、RAG[这在第4章中讨论过](B21443_04.xhtml#_idTextAnchor070)）转化为战术解决方案。
- en: Generative AI application development frameworks
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式人工智能应用开发框架
- en: In this section, we will focus on the popular generative AI-based app development
    frameworks used by developers today in their applications, as they add functionality
    and extensibility to LLMs.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将关注开发者今天在他们的应用中使用的一些流行的基于生成式人工智能的应用开发框架，因为它们为大型语言模型添加了功能性和可扩展性。
- en: But why do we need to modernize existing ML applications to use intelligent
    generative AI in the first place? Let’s compare and contrast application characteristics
    without generative AI and the modernized applications infused with generative
    AI.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 但为什么我们首先需要将现有的机器学习应用现代化，以便使用智能生成式人工智能呢？让我们比较和对比没有生成式人工智能的应用特性和融入生成式人工智能的现代化应用。
- en: 'Current ML applications have some of these common characteristic limitations:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的机器学习应用有一些常见的特性限制：
- en: They are **constrained with their interactions**, especially with generative
    AI services.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们在交互上**受限**，尤其是与生成式人工智能服务交互时。
- en: They are **hard-coded** and usually have a **fixed dataset**. For example, one
    can leverage certain datasets to train certain ML models, and those models are
    fixed.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们是**硬编码**的，通常有一个**固定数据集**。例如，可以利用某些数据集来训练某些机器学习模型，而这些模型是固定的。
- en: If they then want to change a model within an application or if they want to
    **change the dataset entirely**, they will need to again retrain the model, which
    is a challenge because of increased costs and increased time to completion.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果他们想要在应用中更改模型，或者他们想要**完全更改数据集**，他们需要再次重新训练模型，这由于成本增加和完成时间延长而成为一个挑战。
- en: Retraining the model involves adding **enhancements or features**, which is
    **quite complex** and also **time-consuming** and **costly**.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新训练模型涉及添加**增强或功能**，这**相当复杂**，而且也**耗时**且**昂贵**。
- en: 'However, with intelligent generative AI applications that use the techniques
    described in this chapter, you can do the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用本章中描述的技术构建的智能生成式人工智能应用，你可以做到以下事情：
- en: '**Use natural language interactions**. We have seen this in ChatGPT and other
    applications, where one can begin chatting as if there is an actual human or assistant.
    In addition to just using natural language to interact with generative AI applications,
    you can easily have your own personalized experiences based on human-like characteristics,
    such as personas and emotional tones, within an interactive session.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用自然语言交互**。我们在ChatGPT和其他应用中看到了这一点，在那里人们可以开始聊天，就像有一个真实的人类或助手一样。除了仅仅使用自然语言与生成式人工智能应用交互之外，你还可以在交互会话中轻松地根据自己的个性化体验，如角色和情感调调。'
- en: '**Generate data-driven** and **personalized experiences** tailored to a user
    or set of users. Additionally, these applications can improve over time, autonomously
    using past experiences.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成数据驱动**和**个性化体验**，这些体验针对用户或一组用户量身定制。此外，这些应用可以随着时间的推移而改进，自主地使用过去的经验。'
- en: Instead of a longer, time-consuming process of traditional software development,
    you can **quickly deliver new features and** **product enhancements**.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与传统软件开发中更长、耗时更长的过程相比，您可以**快速交付新功能和****产品增强**。
- en: As you can see, intelligent generative AI applications are enabling us to create
    solutions and address problems never before and at a pace we have also never seen
    before. Now let’s turn our attention to some modern App Dev frameworks that can
    help us implement the new and sophisticated features.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，智能生成式AI应用正在使我们能够创造前所未有的解决方案并解决以前从未遇到的问题，而且是以我们以前从未见过的速度。现在让我们将注意力转向一些现代的应用开发框架，这些框架可以帮助我们实现新的和复杂的功能。
- en: Semantic Kernel
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语义内核
- en: Semantic kernel, or SK, is a lightweight, open-source **software development
    kit** (**SDK**); it is a modern AI application development framework that enables
    software developers to build an AI orchestration to build agents, write code that
    can interact with agents, and also support generative AI tooling and concepts,
    such as **natural language processing** (**NLP**), which we covered in [*Chapter
    2*](B21443_02.xhtml#_idTextAnchor036).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 语义内核，或SK，是一个轻量级、开源的**软件开发工具包**（**SDK**）；它是一个现代的AI应用开发框架，使软件开发者能够构建AI编排以构建代理，编写可以与代理交互的代码，并支持生成式AI工具和概念，例如**自然语言处理**（**NLP**），这在[*第2章*](B21443_02.xhtml#_idTextAnchor036)中有所介绍。
- en: “Kernel” is at the core of everything!
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: “内核”是所有事物的核心！
- en: Semantic Kernel revolves around the concept of a “kernel,” which is pivotal
    and is equipped with the necessary services and plugins to execute both native
    code and AI services, making it a central element for nearly all SDK components.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 语义内核围绕“内核”这一概念展开，这一概念至关重要，并配备了执行本地代码和AI服务所需的服务和插件，使其成为几乎所有SDK组件的核心元素。
- en: Every prompt or code executed within the semantic kernel passes through this
    kernel, granting developers a unified platform for configuring and monitoring
    their AI applications.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在语义内核中执行的每个提示或代码都会通过这个内核，为开发者提供了一个统一的平台来配置和监控他们的AI应用程序。
- en: For instance, when a prompt is invoked through the kernel, it undertakes the
    process of selecting the optimal AI service, constructing the prompt based on
    a prompt template, dispatching the prompt to the service, and processing the response
    before delivering it back to the application. Additionally, the kernel allows
    for the integration of events and middleware at various stages, facilitating tasks
    such as logging, user updates, and the implementation of responsible AI practices,
    all from a single, centralized location called “kernel.”
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当通过内核调用提示时，它承担了选择最佳AI服务的流程，根据提示模板构建提示，将提示派发到服务，并在将其返回给应用程序之前处理响应。此外，内核允许在各个阶段集成事件和中间件，从而简化诸如日志记录、用户更新和实施负责任AI实践等任务，所有这些都可以从称为“内核”的单个集中位置完成。
- en: Moreover, SK allows developers to define the syntax and semantics of natural
    language expressions and use them as variables, functions, or data structures
    in their code. SK also provides tools for parsing, analyzing, and generating natural
    language from code and, vice-versa, generating code from NLP.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，SK允许开发者定义自然语言表达式的语法和语义，并将它们用作代码中的变量、函数或数据结构。SK还提供了从代码解析、分析和生成自然语言的工具，反之亦然，从NLP生成代码。
- en: '**You can build sophisticated and complex agents without having to be an AI
    expert by using semantic kernel SDK!** The fundamental building blocks in semantic
    kernels for building agents are **plugins, planners,** **and personas**.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**您可以使用语义内核SDK构建复杂和复杂的代理，而无需成为AI专家！**在语义内核中构建代理的基本构建块是**插件、规划器和****角色**。'
- en: Fundamental components
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本组件
- en: Let’s dive into each one of them and understand what each one means.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一深入了解它们，并理解每个的含义。
- en: '**Plugins** enhance your agent’s functionality by allowing you to incorporate
    additional code. This enables the integration of new functions into plugins, utilizing
    native programming languages such as C# or Python. Additionally, plugins can facilitate
    interaction with LLMs through prompts or connect to external services via REST
    API calls. As an example, consider a plugin for a virtual assistant for a calendar
    application that allows it to schedule appointments, remind you of upcoming events,
    or cancel meetings. If you have used ChatGPT, you may be familiar with the concept
    of plugins, as they are integrated into it (namely, “Code Interpreter” or “Bing
    Search Plugin”).'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**插件**通过允许您集成额外的代码来增强您的代理功能。这使得将新功能集成到插件中成为可能，可以使用如C#或Python等本地编程语言。此外，插件可以通过提示与LLMs交互或通过REST
    API调用连接到外部服务。例如，考虑一个用于日历应用的虚拟助手插件，它允许它安排约会、提醒即将发生的事件或取消会议。如果您使用过ChatGPT，您可能熟悉插件的概念，因为它们已经集成其中（例如，“代码解释器”或“必应搜索插件”）。'
- en: '**Planners**: In order to effectively utilize the plugin and integrate it with
    subsequent actions, the system must initially design a plan, a process that is
    facilitated by planners. This is where the planners help. Planners are sophisticated
    instructions that enable an agent to formulate a strategy for accomplishing a
    given task, often encapsulated in a simple prompt that guides the agent through
    function calling to achieve the objective.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规划者**：为了有效地利用插件并将其与后续操作集成，系统必须首先设计一个计划，这是一个规划者帮助的过程。这就是规划者发挥作用的地方。规划者是一组复杂的指令，使代理能够为完成特定任务制定策略，通常封装在一个简单的提示中，引导代理通过函数调用来实现目标。'
- en: As an example, take the development of a MeetingEventPlanner. This planner would
    guide the agent through the detailed process of organizing a meeting. It includes
    steps such as reviewing the availability of attendees’ calendars, sending out
    confirmation emails, drafting an agenda, and, finally, scheduling the meeting.
    Each step is carefully outlined to ensure the agent comprehensively addresses
    all the necessary actions for successful meeting preparation.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 例如，以开发MeetingEventPlanner为例。这个规划者将引导代理通过组织会议的详细过程。它包括审查与会者日历的可用性、发送确认电子邮件、起草议程，最后安排会议等步骤。每个步骤都经过精心规划，以确保代理全面处理所有必要的会议准备工作。
- en: '**Personas**: Personas are sets of instructions that shape the behavior of
    agents by imbuing them with distinct personalities. Often referred to as “meta
    prompts,” these guidelines endow agents with characters that can range from friendly
    and professional to humorous, and so forth. Additionally, they direct agents on
    the type of response to generate, which can vary from verbose to concise. We have
    explored meta prompts in great detail in [*Chapter 5*](B21443_05.xhtml#_idTextAnchor098);
    this concept is closely related.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**角色**：角色是一组指令，通过赋予它们独特的个性来塑造代理的行为。通常被称为“元提示”，这些指南赋予代理从友好和专业到幽默等不同的人物角色。此外，它们指导代理生成何种类型的响应，这可以从冗长到简洁不等。我们在[*第五章*](B21443_05.xhtml#_idTextAnchor098)中详细探讨了元提示；这个概念与之密切相关。'
- en: However, now let’s take a step back and understand why we want to use SK and
    do such things as create natural language interfaces, chatbots, or natural language
    programming systems in the first place. Consider LLMs as the engine powering generative
    AI applications, and SKs act as the assembly line, integrating various generative
    AI services. For software developers, the reusability of code—be it functions
    or snippets—is crucial to streamline development processes. Furthermore, for expansive
    organizational applications, the efficient management of prompts, completions,
    and other agent-specific data is not just an operational preference but a fundamental
    business necessity. SK emerges as a pivotal framework, enabling the construction
    of durable and comprehensive generative AI applications by seamlessly integrating
    these essential facets.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现在让我们退一步，理解为什么我们要使用SK以及为什么要创建自然语言界面、聊天机器人或自然语言编程系统。将LLMs视为推动生成式AI应用的引擎，而SK则充当装配线，整合各种生成式AI服务。对于软件开发者来说，代码的可重用性——无论是函数还是代码片段——对于简化开发流程至关重要。此外，对于广泛的组织应用，高效管理提示、完成和其他代理特定数据不仅是一种操作偏好，而且是基本业务需求。SK作为一个关键框架，通过无缝集成这些基本要素，使构建耐用和全面的生成式AI应用成为可能。
- en: Important note
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: For LLMs, the engine alone is not able to meet these business requirements any
    more than an engine without oil, gasoline, or electricity is able to meet a driver’s
    requirements of providing transportation. You need additional software code to
    provide a solution, not just the LLMs, and generative AI programming frameworks,
    such as SK, allow you to accomplish this. You are building around the engine to
    provide transportation, and you are building around LLMs to provide a generative
    AI solution.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于LLM来说，仅仅依靠引擎本身已经无法满足这些商业需求，就像没有油、汽油或电的引擎无法满足驾驶员提供交通的需求一样。您需要额外的软件代码来提供解决方案，而不仅仅是LLM和生成式AI编程框架，如SK，允许您实现这一点。您是在围绕引擎构建以提供交通，您是在围绕LLM构建以提供生成式AI解决方案。
- en: For a real-world example, let’s use the company Microsoft. As mentioned earlier,
    Microsoft itself has embraced the SK framework across its organization, exemplifying
    its wide applicability and effectiveness. This integration is particularly evident
    in their next-generation AI-integrated offerings, called “Copilots.” These Copilots
    harness the capabilities of LLMs, alongside your data and other Microsoft applications,
    including the Microsoft 365 suite (Word, Excel, and more). All of these components
    are seamlessly integrated using the SK framework, showcasing a sophisticated and
    powerful example of AI-enhanced productivity tools.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 以微软公司为例，作为一个现实世界的例子。如前所述，微软本身在其整个组织中采用了SK框架，展示了其广泛的应用性和有效性。这种集成在他们下一代AI集成产品“Copilots”中尤为明显。这些Copilots利用了LLM的能力，以及您的数据和微软的其他应用程序，包括Microsoft
    365套件（Word、Excel等）。所有这些组件都通过SK框架无缝集成，展示了AI增强型生产力工具的复杂和强大示例。
- en: Additionally, later in this chapter, we’ll show an actual use case of how a
    Fortune 500 company transformed their development team and, thus, their applications
    into state-of-the-art, modern, generative AI-ready applications and solutions
    using SK.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在本章的后面部分，我们将展示一个实际的案例，说明一家财富500强公司如何将他们的开发团队及其应用程序转变为最先进、现代、适用于生成式AI的应用程序和解决方案，使用的是SK。
- en: 'If you would like to see more details on SK, you can visit the following link:
    *microsoft/semantic-kernel: Integrate cutting-edge LLM technology quickly and
    easily into your apps (*[github.com](http://github.com)*)*, [https://github.com/microsoft/semantic-kernel](https://github.com/microsoft/semantic-kernel).'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '如果您想了解更多关于SK的详细信息，您可以访问以下链接：*microsoft/semantic-kernel: 快速轻松地将最前沿的LLM技术集成到您的应用程序中
    (*[github.com](http://github.com)*)*，[https://github.com/microsoft/semantic-kernel](https://github.com/microsoft/semantic-kernel)。'
- en: '*Figure 6**.3* provides a high-level visual description demonstration of the
    role of SK as an AI orchestrator between LLMs, AI infrastructure, copilots, and
    plugins in the Microsoft Copilot system:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.3* 提供了SK作为AI编排者在微软Copilot系统中在LLM、AI基础设施、Copilots和插件之间角色的高级视觉描述演示：'
- en: '![Figure 6.3 – Role of SK as an AI orchestrator in Microsoft Copilot system](img/B21443_06_3.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图6.3 – SK在微软Copilot系统中的AI编排角色](img/B21443_06_3.jpg)'
- en: Figure 6.3 – Role of SK as an AI orchestrator in Microsoft Copilot system
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 – SK在微软Copilot系统中的AI编排角色
- en: Assistants API
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 助手API
- en: The Assistants API (introduced by Open AI in late 2023) allows you to build
    AI agents with minimal code on OpenAI’s chat completion models. This is an API
    that will soon be integrated into Semantic Kernel to build agent-like experiences,
    as mentioned in a blog by Microsoft ([https://devblogs.microsoft.com/semantic-kernel/assistants-the-future-of-semantic-kernel/](https://devblogs.microsoft.com/semantic-kernel/assistants-the-future-of-semantic-kernel/)).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 助手API（由Open AI于2023年底推出）允许您在OpenAI的聊天完成模型上用最少的代码构建AI代理。这是一个即将集成到语义内核的API，以构建类似代理的体验，正如微软在一篇博客中提到的（[https://devblogs.microsoft.com/semantic-kernel/assistants-the-future-of-semantic-kernel/](https://devblogs.microsoft.com/semantic-kernel/assistants-the-future-of-semantic-kernel/))。
- en: This API helps developers build high-quality copilot-like experiences in their
    own applications. As discussed earlier, copilots are AI assistants integrated
    into applications to help address questions or provide instructional steps to
    help the user achieve more complex tasks.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此API帮助开发者在其自己的应用程序中构建高质量的类似Copilot的体验。如前所述，Copilots是集成到应用程序中的AI助手，用于帮助解决疑问或提供指导步骤，以帮助用户完成更复杂的任务。
- en: Before, creating custom AI assistants required a lot of work, even for skilled
    developers. The chat completions API from OpenAI is easy to use and powerful,
    but it is not stateful (does not have state), which meant developers and/or operations
    had to manage conversation state and chat threads, tool integrations, the retrieval
    of documents, and also managing indexes, all while running code manually. In OpenAI’s
    evolution, the Assistants API is the stateful version of the chat completion API,
    and it offers a solution to address these problems.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，创建定制的AI助手需要大量的工作，即使是对于熟练的开发者来说也是如此。OpenAI的聊天完成API易于使用且功能强大，但它不是有状态的（没有状态），这意味着开发人员和/或运维人员必须管理会话状态和聊天线程、工具集成、文档检索以及管理索引，所有这些都要在手动运行代码的同时完成。在OpenAI的演变过程中，助手API是聊天完成API的有状态版本，并提供了解决这些问题的方案。
- en: 'It is now easier than ever to build customizable, specific generative AI applications
    and services that can search through data, propose solutions, and automate tasks.
    Assistants API supports persistent and unlimited (infinitely long) threads. This
    means that you do not need to create a thread state management system or deal
    with a model’s context window limitations as developers. You can just add new
    messages to a thread, and users reply (prompt/completions). The Assistants API
    can also access files in different formats, either when creating an assistant
    or as part of threads. Assistants can also access multiple tools as needed. Some
    example tools include the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在构建可定制的、特定的生成式AI应用程序和服务比以往任何时候都要容易，这些应用程序和服务可以搜索数据、提出解决方案并自动化任务。助手API支持持久和无限（无限长）的线程。这意味着您不需要创建线程状态管理系统或处理模型上下文窗口的限制，作为开发者。您只需向线程添加新消息，用户就会回复（提示/完成）。助手API还可以在创建助手或作为线程的一部分时访问不同格式的文件。助手还可以根据需要访问多个工具。以下是一些示例工具：
- en: '**Function calling**: The Assistants API can call an existing function or code
    subroutine. With the Assistants API, your assistant can learn what your app or
    external APIs do, choose the right time to call those functions, and use the function(s)
    in response to messages or other behavior.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**函数调用**：助手API可以调用现有的函数或代码子程序。通过助手API，您的助手可以学习您的应用程序或外部API的功能，选择合适的时机调用这些函数，并使用这些函数作为对消息或其他行为的响应。'
- en: '**Code interpreter**: With the code interpreter tool from OpenAI/Azure OpenAI
    Service, you can write and execute code, such as Python code, in a separate environment.
    You can use it for various purposes, such as finding solutions to difficult code
    and math problems step by step, doing advanced data analysis on user-added files
    in different formats, and creating data visualization such as reports, charts,
    and graphs. The Assistants API can integrate and run code interpreters as they
    may deem necessary or as directed.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码解释器**：使用来自OpenAI/Azure OpenAI服务的代码解释器工具，您可以在单独的环境中编写和执行代码，例如Python代码。您可以用它来完成各种目的，例如逐步解决困难的代码和数学问题、对用户添加的不同格式的文件进行高级数据分析，以及创建数据可视化，如报告、图表和图形。助手API可以根据需要或根据指示集成和运行代码解释器。'
- en: LangChain
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain
- en: Like SK, LangChain is another open-source SDK application development framework
    and toolkit for building modern AI applications with LLMs. It provides out-of-the-box
    libraries and templates to develop, productionalize, and deploy your applications.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 与SK一样，LangChain是另一个开源的SDK应用程序开发框架和工具包，用于使用LLMs构建现代AI应用程序。它提供了现成的库和模板，以开发、生产化和部署您的应用程序。
- en: LangChain revolves around the concept of “**chaining**”
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain围绕“**链式**”的概念展开
- en: A distinctive feature of LangChain is its use of “**chains**,” setting it apart
    from SK, which is centered around a kernel, as previously discussed. In LangChain,
    the output from one component serves as the input for the next, allowing elements
    such as prompts, models, and parsers to be connected in sequence before activation.
    Developers can harness LangChain to assemble new prompt chains, enabling the integration
    of multiple LLMs in a sequential manner, where the output from one LLM feeds into
    the next; hence, the term LangChain. Additionally, LangChain includes features
    that permit LLMs to incorporate new datasets without requiring retraining, similar
    to SK.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain的一个显著特点是它使用“**链**”，这与之前讨论的以内核为中心的SK形成对比。在LangChain中，一个组件的输出作为下一个组件的输入，允许在激活之前按顺序连接提示、模型和解析器等元素。开发者可以利用LangChain组装新的提示链，使多个LLM能够按顺序集成，其中一个LLM的输出流入下一个；因此，术语LangChain。此外，LangChain还包括允许LLM在不重新训练的情况下纳入新数据集的功能，类似于SK。
- en: Benefits for app developers
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序开发者的好处
- en: 'We have mentioned a few of the myriad benefits that LangChain provides in the
    following list:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在以下列表中提到了LangChain提供的众多好处中的一些：
- en: '**Link LLMs with data sources**: Finally, LangChain provides AI developers
    with tools to link language models with any data sources. It consists of different
    types of parsers and document loader functionalities that help connect to any
    data source seamlessly.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将LLM与数据源链接**：最后，LangChain为AI开发者提供了将语言模型与任何数据源链接的工具。它包括不同类型的解析器和文档加载功能，有助于无缝连接到任何数据源。'
- en: '**Simplifies RAG implementations**: Development teams can build complex applications
    that access internal company information and data to improve model responses.
    In other words, you can create a **retrieval-augmented generation** (**RAG**)
    workflow that adds context information to the language model during prompting.
    As you learned in [*Chapter 4*](B21443_04.xhtml#_idTextAnchor070), using context-aware
    workflows, such as RAG, reduces model errors and improves response quality.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简化RAG实现**：开发团队可以构建复杂的应用程序，访问公司内部信息和数据以改进模型响应。换句话说，您可以在提示过程中为语言模型添加上下文信息的**检索增强生成**（**RAG**）工作流程。正如您在[*第4章*](B21443_04.xhtml#_idTextAnchor070)中学习的，使用如RAG的上下文感知工作流程可以减少模型错误并提高响应质量。'
- en: '**Accelerates development with libraries and templates**: Developers customize
    sequences to build complex applications easily. Instead of coding business logic,
    software teams can modify existing templates and libraries that LangChain provides
    to reduce development time.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用库和模板加速开发**：开发者可以自定义序列以轻松构建复杂的应用程序。软件团队无需编写业务逻辑，可以修改LangChain提供的现有模板和库，以减少开发时间。'
- en: While both Semantic Kernel and LangChain are open source and free to use, LangChain
    is more widely used at the time of this writing, and LangChain does offer more
    compatibility with many open source models available on public model repositories,
    such as Hugging Face. On the flip side, based on the experience and testing by
    some using real-world applications, Semantic Kernel performs much better in large-scale
    business applications. We are not suggesting using one service over the other,
    but understanding that each framework has its benefits and some drawbacks is useful.
    Both are equally critical in your journey of creating the next-generation generative
    AI apps.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Semantic Kernel和LangChain都是开源的且免费使用，但截至本文撰写时，LangChain的使用更为广泛，LangChain确实提供了与许多公开模型存储库上可用的开源模型更好的兼容性，例如Hugging
    Face。另一方面，根据一些使用真实世界应用的经验和测试，Semantic Kernel在大型商业应用中表现更好。我们并不是建议使用一个服务而不是另一个，但了解每个框架都有其优点和缺点是有用的。两者在您创建下一代生成式AI应用的旅程中同样关键。
- en: 'If you would like to get more details on LangChain and the plethora of benefits
    it provides to developers, we suggest checking out the following links:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解更多关于LangChain及其为开发者提供的众多好处，我们建议查看以下链接：
- en: 'langchain-ai/langchain: Building applications with LLMs through composability
    (github.com) – [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: langchain-ai/langchain：通过可组合性构建LLM应用程序（github.com） – [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)
- en: '[https://python.langchain.com/docs/expression_language/get_started/](https://python.langchain.com/docs/expression_language/get_started/)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://python.langchain.com/docs/expression_language/get_started/](https://python.langchain.com/docs/expression_language/get_started/)'
- en: LlamaIndex
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LlamaIndex
- en: Similar to Semantic Kernel and LangChain, LlamaIndex is a programming data framework
    for applications that use LLMs, allowing one to ingest, manage, and retrieve not
    only domain-specific data (such as industry-specific) but also private data using
    natural language. LlamaIndex is Python-based.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 与语义内核和 LangChain 类似，LlamaIndex 是一个用于使用 LLM 的应用程序的编程数据框架，允许用户使用自然语言摄取、管理和检索不仅限于特定领域的数据（如行业特定数据），还可以是私有数据。LlamaIndex
    基于 Python。
- en: 'LlamaIndex has two main stages: the indexing stage and the querying stage,
    which can be incorporated into an LLMOps process, and we will cover this a bit
    later:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: LlamaIndex 有两个主要阶段：索引阶段和查询阶段，它们可以集成到 LLMOps 流程中，我们将在稍后进行介绍：
- en: '**Indexing stage**: In this stage, LlamaIndex creates a vector index of your
    private data. This makes it possible to search through your own organization’s
    domain-specific knowledge base. You can input text documents, database records,
    knowledge graphs, and other data types.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**索引阶段**：在这个阶段，LlamaIndex 为您的私有数据创建一个向量索引。这使得您能够搜索自己组织的特定领域知识库。您可以输入文本文档、数据库记录、知识图谱和其他数据类型。'
- en: '**Querying stage**: In this stage, the RAG pipeline finds the most relevant
    information based on the user’s query. This information is then passed to the
    LLM, along with the query, to generate a more accurate response.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询阶段**：在这个阶段，RAG 管道根据用户的查询找到最相关的信息。然后，将此信息连同查询一起传递给 LLM，以生成更准确的响应。'
- en: 'Finally, LlamaIndex has three main components:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，LlamaIndex 有三个主要组件：
- en: '**Data connectors**: They allow you to pull data from wherever it is stored,
    such as APIs, PDFs, databases, or external apps, such as Meta or X.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据连接器**：它们允许您从数据存储的任何地方提取数据，例如 API、PDF、数据库或外部应用程序，如 Meta 或 X。'
- en: '**Data indexes**: The data index component organizes your data so that they
    are readily available.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据索引**：数据索引组件组织您的数据，以便它们随时可用。'
- en: '**Engines**: The heart of this is the engine component, which enables you to
    use natural language to interact with your data and create applications, agents,
    and workflows. We will cover exactly what agents and workflows are in the next
    section.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**引擎**：这是核心的引擎组件，它使您能够使用自然语言与数据交互并创建应用程序、代理和工作流程。我们将在下一节中详细说明代理和工作流程是什么。'
- en: 'Now, the question arises: **when should each be used?** SK, Langchain, and
    LlamaIndex are architecturally distinct. SK and Langchain are broader frameworks
    that excel in scenarios requiring more complex interactions with agents and adding
    that AI orchestration layer when building chatbots.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，问题来了：**何时应该使用哪一个？**SK、Langchain 和 LlamaIndex 在架构上各不相同。SK 和 Langchain 是更广泛的框架，在需要与代理进行更复杂交互以及构建聊天机器人时添加
    AI 编排层方面表现出色。
- en: Conversely, LlamaIndex stands out in RAG-based search-focused applications due
    to its optimization for swift and efficient search capabilities. Employing unique
    indexing methods significantly improves the pace of data retrieval.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，LlamaIndex 在基于 RAG 的搜索重点应用程序中脱颖而出，因为它针对快速和高效的搜索能力进行了优化。采用独特的索引方法显著提高了数据检索的速度。
- en: 'If you would like to see more details on LlamaIndex, you can visit the following
    link: [https://docs.llamaindex.ai/en/stable/](https://docs.llamaindex.ai/en/stable/).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解更多关于 LlamaIndex 的详细信息，您可以访问以下链接：[https://docs.llamaindex.ai/en/stable/](https://docs.llamaindex.ai/en/stable/)。
- en: Autonomous agents
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自主代理
- en: '**Autonomous agents** are a more advanced implementation of standard agents
    (mentioned in previous section) and are evolving at a rapid pace. Autonomous agents
    take the concept of agents a little further. These agents could be a team of agents
    that can perform various tasks and manage other agents automatically, collaborating
    autonomously without requiring user input or direction. They possess the ability
    to provide self-feedback and autonomously improve over time.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**自主代理**是标准代理（在上一节中提到）的更高级实现，并且正在快速发展。自主代理将代理的概念推进了一步。这些代理可以是能够执行各种任务并自动管理其他代理的代理团队，它们可以自主协作，无需用户输入或指导。它们具有提供自我反馈并自主改进的能力。'
- en: For instance, within a creative company, the concept of autonomous agents collaborating
    as a team can be leveraged to streamline and enhance the creative process.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在一家创意公司中，可以利用自主代理作为团队协作的概念来简化和增强创意过程。
- en: 'The following is a sample scenario:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例场景：
- en: '![Figure 6.4 – Team of AI autonomous agents](img/B21443_06_4.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.4 – AI 自主代理团队](img/B21443_06_4.jpg)'
- en: Figure 6.4 – Team of AI autonomous agents
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.4 – AI 自主代理团队
- en: 'Imagine a scenario where a creative agency is charged with creating an innovative
    advertising campaign. The team consists of six members, all autonomous agents
    organized in a hierarchy, managed by a manager who is also an autonomous agent.
    Here’s an overview of how various AI agents could work together to accomplish
    this goal. The process would begin with a human user presenting the initial topic,
    which then triggers the subsequent steps as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个场景，一家创意机构被委托创建一个创新的广告活动。团队由六名成员组成，所有成员都是组织在等级制度中的自主代理，由一位也是自主代理的经理管理。以下是各种AI代理如何共同工作以实现这一目标的概述。过程将从人类用户提出初始主题开始，然后触发以下后续步骤：
- en: '**Trend Analysis Agent**: This AI agent autonomously analyzes the internet,
    social media, and data sources to detect current consumer trends, popular culture,
    and industry movements, identifying themes that resonate with the target audience
    to guide the campaign’s creative direction.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**趋势分析代理**：这个AI代理自主分析互联网、社交媒体和数据源，以检测当前消费者趋势、流行文化和行业动态，识别与目标受众产生共鸣的主题，从而指导活动的创意方向。'
- en: '**Concept Generation Agent**: Leveraging insights from the Trend Analysis Agent,
    this AI generates a range of creative concepts for the campaign. It uses generative
    AI models trained on successful advertising campaigns, art, literature, and film
    to propose original and engaging ideas that align with the identified trends.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概念生成代理**：利用趋势分析代理的洞察力，这个AI为活动生成一系列创意概念。它使用在成功的广告活动、艺术、文学和电影上训练的生成式AI模型，提出与识别的趋势相一致的创新和吸引人的想法。'
- en: '**Design and Visualization Agent**: Once a concept is selected, this agent
    creates visual mockups of the advertising materials. Using generative AI models
    trained in graphic design and multimedia production produces high-quality images,
    videos, and other creative assets that bring the concept to life.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设计和可视化代理**：一旦选定了概念，这个代理就会创建广告材料的视觉草图。使用在图形设计和多媒体制作上训练的生成式AI模型产生高质量的图像、视频和其他创意资产，使概念栩栩如生。'
- en: '**Copywriting Agent**: In parallel, a copywriting AI agent generates compelling
    copy for the campaign. It crafts messages that capture the campaign’s essence,
    ensuring they are tailored to the target audience’s language and emotional triggers.
    This agent uses natural language generation technologies to produce a variety
    of copy options, from headlines to detailed product descriptions.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文案代理**：同时，一个文案AI代理为活动生成引人入胜的文案。它构建能够捕捉活动精髓的信息，确保它们针对目标受众的语言和情感触发点进行定制。这个代理使用自然语言生成技术来产生各种文案选项，从标题到详细的产品描述。'
- en: '**Feedback and Iteration Agent**: This agent collects feedback on the creative
    outputs from the team, stakeholders, and potentially a selected audience sample.
    It uses sentiment analysis and feedback loops to understand reactions and suggests
    modifications to the concept, design, or copy to improve the campaign’s effectiveness.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反馈和迭代代理**：这个代理收集来自团队、利益相关者和可能选定的受众样本对创意输出的反馈。它使用情感分析和反馈循环来了解反应，并建议对概念、设计或文案进行修改，以提高活动的有效性。'
- en: '**Integration and Strategy Agent** (manager): Finally, an integration agent
    oversees the assembly of all creative elements into a cohesive campaign. It ensures
    that the strategy aligns with the company’s branding and marketing goals, adjusting
    the campaign’s deployment across various channels for maximum impact.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**整合和策略代理**（经理）：最后，一个整合代理负责将所有创意元素组装成一个统一的广告活动。它确保策略与公司的品牌和营销目标一致，调整活动在各个渠道的部署以实现最大影响。'
- en: In this creative company scenario, autonomous AI agents bring efficiency and
    innovation to the creative process. By leveraging their specialized skills in
    trend analysis, concept generation, design, copywriting, and strategy, they enable
    the company to rapidly develop and iterate groundbreaking advertising campaigns
    that resonate deeply with the target audience.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个创意公司场景中，自主AI代理为创意过程带来了效率和创新。通过利用他们在趋势分析、概念生成、设计、文案和策略方面的专业技能，他们使公司能够快速开发并迭代与目标受众产生深刻共鸣的突破性广告活动。
- en: Now that we have learned about the concepts of agents, let’s us understand how
    to make it a reality with application development frameworks and multi-conversation
    agent frameworks in the next section.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了代理的概念，让我们在下一节中了解如何通过应用开发框架和多对话代理框架将其变为现实。
- en: Agent collaboration frameworks
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代理协作框架
- en: In this chapter, we have covered generative AI from the perspectives of developers
    and operations by introducing programming development frameworks and many of the
    concepts related to this, including the concept of agents. We feel agents are
    a very exciting field of focus, where a brand new revolution, the generative AI
    revolution, will catapult humanity to heights we have not seen before and could
    only have dreamed of (perhaps in science fiction books!) only a year or two ago.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们通过介绍编程开发框架以及与这一概念相关的许多概念，从开发者和运维的角度介绍了生成式AI，包括智能体的概念。我们认为智能体是一个非常令人兴奋的研究领域，一个全新的革命，即生成式AI革命，将把人类带到我们以前从未见过的高度，甚至只能梦想（也许在科幻小说中！）一年或两年前。
- en: In [*Chapter 2*](B21443_02.xhtml#_idTextAnchor036), we very briefly touched
    on the exciting concept of autonomous agents, and in this section, we will cover
    this concept further, but first, let’s revisit what an ‘agent’ is. Recall that
    an “agent,” when used in the generative AI context, is software code that is AI-aware,
    and that can complete tasks, such as retrieving and gathering information from
    the user via an application or other model; it then uses this information to perform
    an action, such as input this into an LLM or a series of LLMs, to name just one
    action.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第2章*](B21443_02.xhtml#_idTextAnchor036)中，我们简要地提到了令人兴奋的自主智能体概念，在本节中，我们将进一步探讨这个概念，但首先，让我们回顾一下“智能体”是什么。回想一下，在生成式AI的语境中，“智能体”是指具有AI意识的软件代码，它可以完成诸如通过应用程序或其他模型从用户那里检索和收集信息等任务；然后它使用这些信息执行某些操作，例如将其输入到LLM或一系列LLMs中，仅举一个例子。
- en: 'Let’s visually describe what an agent is beyond just pieces of code, as there
    are a few essential components that are needed for an agent to do its job:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直观地描述一下智能体是什么，而不仅仅是代码片段，因为智能体完成其工作需要一些基本组件：
- en: '![Figure 6.5 – What makes an agent?](img/B21443_06_5.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图6.5 – 什么造就了一个智能体？](img/B21443_06_5.jpg)'
- en: Figure 6.5 – What makes an agent?
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 – 什么造就了一个智能体？
- en: According to Ben Tossell, Founder of Ben’s Bites AI Newsletter, “*AI agents
    will be everywhere. Billion-dollar companies will come from a small team that
    deploys* *ai agents*.”
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Ben Tossell，Ben’s Bites AI Newsletter的创始人所说，“*AI智能体将无处不在。价值数十亿美元的公司将来自一个小团队，该团队部署了*
    *ai智能体*。”
- en: This is quite a statement! However, we feel it to be very accurate and agree
    with this statement. However, let’s take this one more step. In the general term
    of an agent, this agent must wait for some sort of interaction or direction by
    a human, likely via code. This limits any agent in terms of waiting (precious
    time is wasted) and following whatever only a human knows.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这真是一个相当的说法！然而，我们认为它非常准确，并同意这个说法。然而，让我们再进一步。在智能体的通用术语中，这个智能体必须等待某种由人类发起的交互或指示，很可能是通过代码。这限制了智能体在等待（宝贵的时间被浪费）和遵循只有人类知道的事情方面的能力。
- en: With “autonomous agents,” as the name suggests, this AI-powered code can now
    do things by themselves on their own, from completing tasks by taking action to
    creating new tasks, and they continue doing so until the task is complete. Furthermore,
    autonomous agents can provide self-feedback and subsequently improve autonomously,
    allowing for self-growth and improvement! All the while, these autonomous agents
    can communicate and collaborate with other autonomous agents to build a network
    of autonomous and tackle the most complex tasks, all with almost no human interaction!
    Of course, this will require all the guardrails and protection in place to prevent
    harm to society.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如同其名“自主智能体”所暗示的，这种由AI驱动的代码现在可以自行完成事情，从通过采取行动完成任务到创建新任务，并且它们会一直这样做，直到任务完成。此外，自主智能体可以提供自我反馈，并随后自主改进，允许自我成长和提升！与此同时，这些自主智能体可以与其他自主智能体进行通信和协作，构建一个自主网络并解决最复杂的任务，几乎不需要任何人类交互！当然，这需要所有必要的护栏和保护措施，以防止对社会造成伤害。
- en: 'Now let’s take a look at two popular frameworks: AutoGen by Microsoft and AutoGPT
    by Mindstream.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看两个流行的框架：微软的AutoGen和Mindstream的AutoGPT。
- en: AutoGen
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoGen
- en: '**Autogen**, an agent collaboration framework introduced by Microsoft Research,
    is another major breakthrough in AI. It is an open source platform for building
    multi-agent systems that work autonomously using LLMs, and we feel this will have
    one of the most significant impacts in the generative AI space in the upcoming
    months and years ([https://arxiv.org/abs/2308.08155](https://arxiv.org/abs/2308.08155)).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**Autogen**，由微软研究院引入的智能体协作框架，是AI领域的又一重大突破。它是一个开源平台，用于构建使用LLMs自主工作的多智能体系统，我们相信这将在未来几个月和几年内在生成式AI领域产生最显著的影响([https://arxiv.org/abs/2308.08155](https://arxiv.org/abs/2308.08155)).'
- en: AutoGen can help build agents that perform tasks such as reasoning, planning,
    task decomposition, reflection, self-critique, self-improvement, self-evaluation,
    memory, personalization, and communication by using various prompt engineering
    techniques, just to name a few areas. Of course, as mentioned above, autonomous
    agents can call on other autonomous agents to help address the most complex of
    problems or situations.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: AutoGen可以帮助构建通过使用各种提示工程技术执行推理、规划、任务分解、反思、自我批评、自我改进、自我评估、记忆、个性化以及通信等任务的智能体，仅举几个领域为例。当然，如上所述，自主智能体可以调用其他自主智能体来帮助解决最复杂的问题或情况。
- en: How exciting is it if an Autogen created autonomous agents to collaborate with
    other specialized agents when a task is quite complex and extremely large, say,
    the task of building a warp drive; although this is a tongue-in-cheek scenario
    (or perhaps it’s not), humanity alone cannot tackle these extreme, vastly complex
    use cases, as in the example of building a warp drive for an engine to propel
    a craft faster than the speed of light!
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当一项任务非常复杂且规模极大时，例如建造曲速驱动器这样的任务，如果AutoGen创建的自主智能体与其他专业智能体协作将多么令人兴奋；尽管这是一个玩笑般的场景（或者也许不是），仅凭人类自身是无法应对这些极端、极其复杂用例的，就像为推进器建造曲速驱动器以使飞船超过光速的例子一样！
- en: However, as you might be able to conclude, the possibilities are endless once
    we understand how multiple large language models + AutoGen can work together in
    different ways, e.g., aligned in a hierarchical way, networked together in an
    orderly fashion, or swarm together, all with the goal of increasing the computing
    and reasoning power to solve extremely complex problems, including complex problems
    that may not even exist today!
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如你可能已经得出的结论，一旦我们理解了多个大型语言模型与AutoGen以不同方式协同工作，例如以分层方式对齐、有序地网络化或集群在一起，所有这些都有助于提高计算和推理能力以解决极其复杂的问题，包括可能今天甚至不存在的问题，那么可能性将是无限的！
- en: 'Some tasks Autogen can perform autonomously include automated task solving
    with code generation, execution and debugging, and automated data visualization
    from a group chat. More exciting examples can be seen here: [https://microsoft.github.io/autogen/docs/Examples#automated-multi-agent-chat](https://microsoft.github.io/autogen/docs/Examples#automated-multi-agent-chat).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Autogen可以自主执行的某些任务包括代码生成、执行和调试的自动化任务解决，以及从群聊中自动进行数据可视化。更多令人兴奋的例子可以在以下链接中看到：[https://microsoft.github.io/autogen/docs/Examples#automated-multi-agent-chat](https://microsoft.github.io/autogen/docs/Examples#automated-multi-agent-chat).
- en: 'If you want to test out Autogen, check out the Autogen studio developed by
    Microsoft: [https://autogen-studio.com/autogen-studio-ui](https://autogen-studio.com/autogen-studio-ui).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要测试Autogen，可以查看微软开发的Autogen studio：[https://autogen-studio.com/autogen-studio-ui](https://autogen-studio.com/autogen-studio-ui).
- en: 'Moreover, to learn more about Autogen, we suggest checking out this link: AutoGen
    | AutoGen (microsoft.github.io) – [https://microsoft.github.io/autogen/](https://microsoft.github.io/autogen/).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了了解更多关于AutoGen的信息，我们建议查看这个链接：AutoGen | AutoGen (microsoft.github.io) – [https://microsoft.github.io/autogen/](https://microsoft.github.io/autogen/).
- en: TaskWeaver
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TaskWeaver
- en: '**TaskWeaver** is yet another framework developed by Microsoft for building
    autonomous agents, but it uses a code-first approach as opposed to the template-based
    approach taken by Autogen.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**TaskWeaver**是微软开发的另一个用于构建自主智能体的框架，但它采用代码优先的方法，而不是Autogen采用的基于模板的方法。'
- en: TaskWeaver distinguishes itself by transforming user requests into actionable
    code and treating the plugins defined by users as if they were callable functions.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: TaskWeaver通过将用户请求转换为可执行代码，并将用户定义的插件视为可调用的函数来区别于其他产品。
- en: 'To learn more about TaskWeaver, we suggest reading this research paper: [https://arxiv.org/pdf/2311.17541.pdf](https://arxiv.org/pdf/2311.17541.pdf).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于TaskWeaver的信息，我们建议阅读这篇研究论文：[https://arxiv.org/pdf/2311.17541.pdf](https://arxiv.org/pdf/2311.17541.pdf).
- en: AutoGPT
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AutoGPT
- en: Another application that has received a lot of attention in the autonomous agent
    world is **AutoGPT** from Mindstream. AutoGPT is an open source application that
    aims to make AI available to everyone. Currently, it uses the GPT-4 model and
    is also designed to complete autonomous tasks using autonomous agents, similar
    to AutoGen. A few examples of tasks that AutoGPT can complete include research,
    coding, or content creation.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在自主代理领域受到广泛关注的应用之一是Mindstream的**AutoGPT**。AutoGPT是一个开源应用，旨在让AI对每个人开放。目前，它使用GPT-4模型，并且也被设计用来通过自主代理完成自主任务，类似于AutoGen。AutoGPT可以完成的任务示例包括研究、编码或内容创作。
- en: AutoGPT (driven by GPT-4) chains together LLM thoughts to achieve its goals
    and also allows extensibility. An example of extensibility is where one can extend
    the functionality of these autonomous agents with plugins or software add-ons,
    enhancing the capabilities of autonomous agents even further, which allows for
    variety in data collection, interaction with web platforms, and multi-modal functions.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 由GPT-4驱动的AutoGPT将LLM的思想串联起来以实现其目标，同时也允许扩展性。扩展性的一个例子是，可以通过插件或软件附加组件来扩展这些自主代理的功能，进一步增强自主代理的能力，这允许在数据收集、与网络平台的交互和多模态功能方面有更多样性。
- en: AutoGPT is a significant improvement in the field of autonomous agents, enriching
    AI applications and agents when compared to non-autonomous agents.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 与非自主代理相比，AutoGPT在自主代理领域是一个重大进步，丰富了AI应用和代理。
- en: 'While the concept of autonomous agents may cause some anxiety, this is no longer
    a concept but a reality. It has already started and is happening now. Some fear
    the use of autonomous agents may cause a technological singularity, “*a hypothetical
    future point in time at which technological growth becomes uncontrollable and
    irreversible, resulting in unforeseeable consequences for human civilization*,”
    as defined by Wikipedia: [https://en.wikipedia.org/wiki/Technological_singularity](https://en.wikipedia.org/wiki/Technological_singularity).'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然自主代理的概念可能会引起一些焦虑，但这已经不再是一个概念，而是一个现实。它已经开始了，现在正在发生。一些人担心自主代理的使用可能会导致技术奇点，“*一个假设的未来时间点，届时技术增长变得无法控制且不可逆转，对人类文明产生不可预见的影响*”，正如维基百科所定义的：[https://en.wikipedia.org/wiki/Technological_singularity](https://en.wikipedia.org/wiki/Technological_singularity)。
- en: However, we feel there will be significant safeguards in place to avoid such
    a singularity. A delightful concept we came up with is having a “foreman” autonomous
    agent, or agents, which oversee the tasks of other autonomous agents, or their
    “crew,” monitoring their activity and taking necessary disciplinary action to
    prevent any maliciousness. This foreman would be “in charge” of all the other
    agents, which is no different from a foreman on a construction site overseeing
    the activities of the construction workers and crew.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们感觉将会有重大的安全措施来避免这样的奇点。我们想到的一个令人愉快的概念是有一个“工头”自主代理，或者代理们，它们监督其他自主代理的任务，或者它们的“船员”，监控它们的活动并采取必要的纪律措施来防止任何恶意行为。这个工头将负责所有其他代理，这与建筑工地上工头监督建筑工人和船员的活动并无不同。
- en: 'If you would like to get more information on AutoGPT, we suggest checking out
    the following two links:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于AutoGPT的信息，我们建议查看以下两个链接：
- en: 'Significant-Gravitas/AutoGPT: AutoGPT is the vision of accessible AI for everyone,
    to use and to build on. Our mission is to provide the tools, so that you can focus
    on what matters. (github.com) - [https://github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Significant-Gravitas/AutoGPT：AutoGPT是让每个人都能使用和基于其构建的通用AI的愿景。我们的使命是提供工具，让你能专注于重要的事情。（github.com）
    - [https://github.com/Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT)
- en: 'AutoGPT documentation: [https://docs.agpt.co/](https://docs.agpt.co/)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoGPT文档：[https://docs.agpt.co/](https://docs.agpt.co/)
- en: Up to this point in our exploration, we’ve delved into a variety of concepts,
    such as RAG, fine-tuning, prompt engineering, and agents, which serve as the building
    blocks for crafting cutting-edge generative AI applications. Let’s now shift our
    focus towards the operationalization aspect, aiming to unpack how we can seamlessly
    transition these concepts into production. Our goal is to enhance efficiency and
    automation, ensuring that the theoretical foundations we’ve laid can be applied
    in practical, real-world scenarios.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探索的这一阶段，我们已经深入探讨了各种概念，例如RAG、微调、提示工程和代理，这些概念是构建前沿生成式AI应用的基石。现在，让我们将注意力转向运营方面，旨在探讨如何将这些概念无缝地过渡到生产环境中。我们的目标是提高效率和自动化，确保我们建立的理论基础可以在实际、现实场景中得到应用。
- en: LLMOps – Operationalizing LLM apps in production
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMOps – 在生产中运营LLM应用
- en: 'In this section, we aim to comprehend what LLMOps entails. We will then explore
    the lifecycle of LLMs, the fundamental components of LLMOps, its benefits, and
    how it compares to traditional MLOps practices. Additionally, we will discuss
    Azure’s Prompt Flow platform, which facilitates the transformation of this concept
    into a tactical solution:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们旨在理解LLMOps的含义。然后我们将探讨LLM的生命周期、LLMOps的基本组件、其优势以及它与传统MLOps实践的对比。此外，我们还将讨论Azure的Prompt
    Flow平台，它有助于将这一概念转化为战术解决方案：
- en: What is LLMOps?
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是LLMOps？
- en: '**Definition**: LLMOps or large language model operations is a collection of
    tools and practices focused on managing the lifecycle of generative AI models,
    including LLMs, small language models (SLMs), and related artifacts in a production
    environment.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定义**：LLMOps或大型语言模型运营是一系列工具和实践的集合，专注于管理生成式AI模型的生命周期，包括LLM、小型语言模型（SLM）以及生产环境中的相关工件。'
- en: The **goal** of LLMOps is to ensure continuous quality, reliability, security,
    and ethical standards of generative AI models and their applications in production
    with enhanced efficiency and automation.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMOps的**目标是确保生成式AI模型及其在生产中的应用的持续质量、可靠性、安全性和道德标准，同时提高效率和自动化**。
- en: '**LLM Lifecycle activities**: It encompasses a comprehensive workflow that
    includes a series of critical activities such as initial data preparation, model
    creation and tuning, prompt engineering, setting up evaluation frameworks, deploying,
    monitoring, updating, and eventually retiring Large Language Models (LLMs) when
    they are deprecated. It is designed to be a scalable and efficient method for
    managing LLMs.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLM生命周期活动**：它包含一个全面的流程，包括一系列关键活动，如初始数据准备、模型创建和调整、提示工程、设置评估框架、部署、监控、更新，以及最终在LLM（大型语言模型）被弃用时退役。它旨在成为一个可扩展且高效的LLM管理方法。'
- en: '**Orchestration and automation**: These activities are typically executed through
    independent, repeatable pipelines that are then systematically integrated using
    a process known as orchestration. This orchestration ensures that each component
    of the workflow communicates effectively with the others, allowing for a seamless
    transition from one stage to the next. By doing so, it enables a more structured
    and efficient approach to managing the lifecycle of LLMs, from development through
    to deployment and beyond.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编排和自动化**：这些活动通常通过独立的、可重复的管道执行，然后通过称为编排的过程系统地整合。这种编排确保工作流程的每个组件都能有效地与其他组件通信，从而实现从一个阶段到下一个阶段的无缝过渡。通过这样做，它使得对LLM的生命周期进行管理的方法更加结构化和高效，从开发到部署以及更远。'
- en: '**Deployment**: LLMOps automates such orchestration with CI/CD practices that
    entails the integration of code and trained/fine-tuned models to production, testing,
    release, and monitoring of LLM-based applications in a systematic manner, incorporating
    both automated and manual processes depending on the maturity of the tools, processes,
    and specific requirements of the applications.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署**：LLMOps通过CI/CD实践自动化编排，涉及将代码和训练/微调的模型集成到生产中，以系统化的方式进行LLM应用的测试、发布和监控，根据工具、流程的成熟度和应用的具体要求，结合自动和手动流程。'
- en: Why do we need LLMOps?
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们为什么需要LLMOps？
- en: The need for LLMOps arises from the complexity and scale of deploying and managing
    generative AI models.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMOps的需求源于部署和管理生成式AI模型的复杂性和规模。
- en: 'Drawing parallels with its predecessors—machine learning operations (MLOps)
    and developer operations (DevOps)—LLMOps aims to simplify the integration of the
    critical aspects of deployment: people, processes, and technology.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其前辈——机器学习操作（MLOps）和开发者操作（DevOps）——进行类比，LLMOps旨在简化部署关键方面的集成：人员、流程和技术。
- en: This integration aims to automate complex manual processes across to accelerate
    the delivery of LLM-infused software and maximize value to an organization. LLMOps
    serves as the bridge that combines tools and processes to manage the end-to-end
    lifecycle of creating, launching, and maintaining applications based on generative
    AI and LLMs.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个集成旨在自动化复杂的手动过程，以加速LLM注入软件的交付，并最大化对组织的价值。LLMOps作为桥梁，结合工具和流程来管理基于生成AI和LLM的创建、发布和维护的全生命周期。
- en: To grasp the essence of LLMOps, it’s essential to first acquaint ourselves with
    the processes involved in managing the lifecycle of LLMs. This overarching process
    lays the groundwork for enabling LLMOps, providing a structured framework through
    which we can understand the intricate steps of development, deployment, and maintenance
    of LLMs.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 要掌握LLMOps的精髓，首先了解管理LLM生命周期的相关过程是至关重要的。这个总体过程为LLMOps的启用奠定了基础，提供了一个结构化的框架，通过这个框架我们可以理解LLM开发、部署和维护的复杂步骤。
- en: LLM lifecycle management
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM生命周期管理
- en: 'LLM lifecycle management is a fairly young concept; however, one fact remains,
    the LLM lifecycle covers quite a few discipline areas. It is an iterative process
    and not a linear process, reflecting the multi-faceted nature of real-world applications
    with these key ingredients: ideation, development, deployment, and management.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: LLM生命周期管理是一个相对较新的概念；然而，有一点是事实，LLM生命周期涵盖了相当多的学科领域。它是一个迭代过程，而不是线性过程，反映了现实世界应用的多面性，这些关键要素包括：构思、开发、部署和管理。
- en: 'Here is a visual diagram to aid our discussion as we view the process flow;
    this relates to LLM and, ultimately, LLMOps:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个视觉图表，有助于我们讨论过程流程；这与LLM和最终LLMOps相关：
- en: '![Figure 6.6 – LLM lifecycle in the real world](img/B21443_06_6.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图6.6 – 真实世界中的LLM生命周期](img/B21443_06_6.jpg)'
- en: Figure 6.6 – LLM lifecycle in the real world
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 – 真实世界中的LLM生命周期
- en: In the preceding image above, the three larger circles represent the end-to-end
    lifecycle phases in managing/developing LLMs, similar to what we might see in
    traditional application lifecycles. As stated earlier, these phases are not linear,
    so let us describe what is occurring here, with each circle representing a phase,
    moving left to right.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图像中，三个较大的圆圈代表了管理/开发LLM的端到端生命周期阶段，类似于我们在传统应用生命周期中可能看到的。如前所述，这些阶段不是线性的，所以让我们描述一下这里发生的情况，每个圆圈代表一个阶段，从左到右移动。
- en: '**Phase 1**: On the far left, we first try to understand **BUSINESS REQUIREMENTS**
    and begin the exploring and ideation steps in this initial phase. In this phase,
    let’s call it phase one, some of the tasks we will complete include finding some
    foundational or other LLMs using benchmarks, model cards, etc., and running a
    few prompts against this to test some basic business requirements and also test
    some hypotheses we believe based on our understanding of the business requirements.
    Usually, in this initial phase, we may also be able to modify the business requirements
    based on early exploration.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第一阶段**：在最左边，我们首先尝试理解**业务需求**，并在这一初始阶段开始探索和构思。在这个阶段，我们可以称之为第一阶段，我们将完成的一些任务包括使用基准、模型卡片等找到一些基础或其他LLM，并对这些LLM运行一些提示以测试一些基本业务需求，并测试一些基于我们对业务需求理解的假设。通常，在这个初始阶段，我们还可以根据早期探索修改业务需求。'
- en: '**Phase 2**: As we advance to the next phase, phase 2, we are now building
    and augmenting our LLM, using the techniques covered earlier in this book, such
    as RAG, prompt engineering, or fine-tuning. If there are any errors within our
    LLM lifecycle processes in the second phase or if RAG is not optimized and fine-tuning
    is not providing us with the correct results, we can then revert back to the first
    phase to try to find other existing LLMs or retry a different hypothesis (or even
    alter our existing hypothesis), and start the LLM lifecycle again. We will also
    employ the comprehensive evaluation techniques that we discussed *in* [*Chapter
    5*](B21443_05.xhtml#_idTextAnchor098) to evaluate the model.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第二阶段**：当我们进入下一个阶段，即第二阶段时，我们现在正在构建和增强我们的LLM，使用本书前面介绍的技术，如RAG、提示工程或微调。如果在第二阶段的LLM生命周期过程中存在任何错误，或者RAG没有优化，微调没有提供正确的结果，我们就可以回退到第一阶段，尝试找到其他现有的LLM或重试不同的假设（甚至改变我们现有的假设），并重新开始LLM生命周期。我们还将采用我们在[*第5章*](B21443_05.xhtml#_idTextAnchor098)中讨论的全面评估技术来评估模型。'
- en: '**Phase 3**: Once we are successful in completing phase 2, we can move on to
    the third and final phase of our LLM lifecycle, which is operationalizing the
    LLM, deploying it as an app, or integrating the LLM app into an existing service.
    Moreover, within this lifecycle, we have additional operational areas we need
    to address: monitoring, quota and cost management, safe rollout/staging, and content
    filtering (we will cover the monitoring, content safety, and quota aspects in
    further detail in the upcoming chapters). We can also consider any additional
    feedback from the end users and take this back to phase two, where we may need
    to conduct additional fine-tuning or additional grounding on our data with RAG.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第三阶段**：一旦我们成功完成第二阶段，我们就可以进入LLM生命周期的第三和最终阶段，即运营LLM，将其作为应用程序部署，或将LLM应用程序集成到现有服务中。此外，在这个生命周期中，我们还需要解决额外的运营领域：监控、配额和成本管理、安全推出/分阶段以及内容过滤（我们将在接下来的章节中更详细地介绍监控、内容安全和配额方面）。我们还可以考虑来自最终用户的任何额外反馈，并将其带回到第二阶段，在那里我们可能需要进行额外的微调或使用RAG对我们的数据进行更多的基础训练。'
- en: Overarching all these phases and activities is the managing/management loop,
    which focuses on governance, security, and compliance, which we will cover in
    the next two chapters. To wrap up this part, as we understand the preceding LLM
    lifecycle stages, we understand how to balance agility with adherence to standards
    while meeting business requirements.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些阶段和活动都受管理/管理循环的总体管理，该循环侧重于治理、安全和合规性，我们将在下一两章中介绍。为了总结这部分内容，当我们理解了前面的LLM生命周期阶段，我们就理解了如何在满足业务需求的同时，在敏捷性和遵守标准之间取得平衡。
- en: Important note
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: An emerging fourth phase in the lifecycle of LLMs addresses the end-of-life
    stage when an LLM no longer meets business requirements or becomes obsolete. This
    phase involves safely decommissioning the outdated LLM, potentially replacing
    it with a newer, more advanced model. The key actions include migrating APIs and
    other integrations to the new model, ensuring a seamless transition. This addition
    marks the beginning of a cyclical process, restarting with the initial phase of
    deploying a fresh LLM.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的生命周期中出现的第四个阶段解决了LLM不再满足业务需求或变得过时的生命终结阶段。这个阶段包括安全地退役过时的LLM，可能用更新、更先进的模型来替换它。关键行动包括将API和其他集成迁移到新模型，确保无缝过渡。这一增加标志着循环过程的开始，重新从部署全新LLM的初始阶段开始。
- en: Let’s take a look at the key activities that make up an LLMOps strategy.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看构成LLMOps策略的关键活动。
- en: Essential components of LLMOps
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMOps的基本组成部分
- en: 'In this section, we will discuss some of the key components of LLMOps that
    entail the process explained previously:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论LLMOps的一些关键组成部分，这些组成部分涉及之前解释的过程：
- en: '![Figure 6.7 – The flow of an LLM lifecycle](img/B21443_06_07.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图6.7 – LLM生命周期的流程](img/B21443_06_07.jpg)'
- en: Figure 6.7 – The flow of an LLM lifecycle
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 – LLM生命周期的流程
- en: 'The enterprise LLMOps strategy must include the following steps as a minimum:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 企业LLMOps策略必须包括以下基本步骤：
- en: Data preparation
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据准备
- en: '**Initialization and data curation**: This step facilitates the creation of
    reproducible and versioned datasets. It involves transforming, aggregating, and
    de-duplicating data, as well as developing structured and reliable prompts for
    querying LLMs. Additionally, exploratory analysis is performed to understand the
    nature of the data and enrich it with any necessary information.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**初始化和数据整理**：这一步骤有助于创建可重复和版本化的数据集。它包括转换、聚合和去重数据，以及开发用于查询LLMs的结构化和可靠的提示。此外，还会进行探索性分析，以了解数据的性质，并添加任何必要的信息。'
- en: Discover and tune
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发现和调整
- en: '**Experimentation**: This step focuses on identifying the most suitable LLM
    solutions by researching and discovering LLMs that could match your use case.
    It involves auditing through rapid iterations of testing various techniques, including
    prompt engineering, information retrieval optimization, relevance enhancement,
    model selection, fine-tuning, and hyperparameter adjustments.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验**：这一步骤侧重于通过研究和发现可能符合您用例的LLMs来识别最合适的LLM解决方案。它涉及通过快速迭代测试各种技术，包括提示工程、信息检索优化、相关性增强、模型选择、微调和超参数调整进行审计。'
- en: '**Evaluation and refinement**: This is the process that defines tailored metrics,
    and selecting methods of comparing results to them at key points that contribute
    to overall solution performance. This is an iterative process to see how changes
    impact solution performance such as optimizing a search index during information
    retrieval for RAG implementations or refining few-shot examples through prompt
    engineering.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估和改进**：这是一个定义定制指标的过程，并在关键点选择方法来比较结果与这些指标，从而对整体解决方案性能做出贡献。这是一个迭代过程，以查看变化如何影响解决方案性能，例如在RAG实现的信息检索过程中优化搜索索引，或通过提示工程改进少样本示例。'
- en: Deployment
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署
- en: '**Validation and deployment**: This step includes rigorous model validation
    to evaluate performance in production environments and A/B testing to evaluate
    new and existing solutions before deploying the most performant ones into various
    environments.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证和部署**：这一步骤包括严格的模型验证，以评估在生产环境中的性能，以及A/B测试，以评估新和现有解决方案，然后在各种环境中部署性能最佳的解决方案。'
- en: '**Inferencing and serving**: This step involves providing an optimized model
    tailored for consistent, reliable, low-latency, and high-throughput responses,
    with batch processing support. Enabling CI/CD to automate the preproduction pipeline.
    Serving is usually done with a REST API call.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理和服务**：这一步骤涉及提供针对一致、可靠、低延迟和高吞吐量响应进行优化的模型，并支持批量处理。启用CI/CD来自动化预生产流程。服务通常通过REST
    API调用完成。'
- en: Monitoring with human feedback
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工反馈监控
- en: '**Monitor models**: Monitoring within an LLM or LLMOps, is a critical component
    to ensure the overall health of your LLM over a continued period of time. Items
    such as **model data drift**, which occurs when the distribution of the datasets
    used with LLM changes over time, can lead to model degradation and performance.
    This is especially true when doing any predictive analytics, as the input data
    may be incorrect, thus having a false outcome. Fortunately, there are features
    within commercial services, such as Azure Machine Learning, which help account
    for and monitor data drift.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控模型**：在LLM或LLMOps中进行监控是确保LLM在一段时间内整体健康的关键组成部分。例如，**模型数据漂移**，当与LLM一起使用的数据集的分布随时间变化时发生，可能导致模型退化并影响性能。这在进行任何预测分析时尤其如此，因为输入数据可能是不正确的，从而导致错误的结果。幸运的是，商业服务中存在一些功能，例如Azure机器学习，可以帮助处理和监控数据漂移。'
- en: 'The image below, sourced from Microsoft’s blog on LLMOps, depicts a dashboard
    that monitors a few evaluation metrics related to quality, such as groundedness,
    relevance, fluency, similarity, and coherence for generative AI applications,
    illustrating their changes over time:'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面的图像来自微软关于LLMOps的博客，展示了一个仪表板，该仪表板监控与质量相关的几个评估指标，例如对于生成式AI应用的基础性、相关性、流畅性、相似性和连贯性，说明了它们随时间的变化：
- en: '![Figure 6.8 – An overview of LLMOps dashboard on Azure Prompt Flow](img/B21443_06_8.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图6.8 – Azure Prompt Flow上LLMOps仪表板的概述](img/B21443_06_8.jpg)'
- en: Figure 6.8 – An overview of LLMOps dashboard on Azure Prompt Flow
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8 – Azure Prompt Flow上LLMOps仪表板的概述
- en: '**Infra-monitoring**: With any comprehensive operational plan, monitoring is
    always an included critical component.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施监控**：在任何综合运营计划中，监控始终是一个关键组成部分。'
- en: The monitoring procedures cover tools and practices to assess and report on
    system and solution performance and health. Monitored areas include API latency
    and throughput (Requests per second and Tokens Per second) to ensure optimal user
    experience. This can be achieved through Azure API Management, which we discuss
    in the next chapter.
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 监控程序涵盖了评估和报告系统性能和健康状况的工具和实践。监控区域包括API延迟和吞吐量（每秒请求数和每秒令牌数），以确保最佳用户体验。这可以通过我们在下一章中讨论的Azure
    API Management实现。
- en: Metrics to track resource utilization, raising real-time alerts for issues or
    anomalies or for any data privacy breaches like jailbreak attacks, prompt injections,
    etc, and evaluating queries and responses for issues such as inappropriate responses.
    We discuss such metrics related to safe, secure, and responsible AI, in *Chapters*
    *8* and *9*.
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 跟踪资源利用的指标，对问题或异常或任何数据隐私泄露（如越狱攻击、注入攻击等）发出实时警报，并评估问题（如不适当的响应）的查询和响应。我们在第 *8* 章和第
    *9* 章讨论了与安全、安全和负责任的AI相关的此类指标。
- en: Finally, most modern monitoring systems can also automatically raise trouble
    and support tickets, for human intervention and review, for any alerts, anomalies,
    or issues.
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，大多数现代监控系统还可以自动提出故障和工单，以便于人类干预和审查，对于任何警报、异常或问题。
- en: Retraining
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重新训练
- en: '**Collecting feedback**: This critical step enables seamless mechanism for
    collecting user feedback or capturing user-provided data for insights, which is
    then used to enrich the validation datasets to improve the LLM solution’s performance.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收集反馈**：这一关键步骤使得收集用户反馈或捕获用户提供的用于洞察的数据的机制更加无缝，这些数据随后被用于丰富验证数据集，以改进LLM解决方案的性能。'
- en: The components and activities identified in the preceding list can be developed
    into repeatable pipelines. These pipelines can then be efficiently orchestrated
    into a coherent workflow, as previously discussed. By further enhancing operational
    efficiency, this orchestrated workflow can be automated and seamlessly integrated
    with **continuous integration/continuous deployment** (**CI/CD**) workflows. Such
    pipelines can be easily developed in Python using frameworks, such as Langchain
    or Semantic Kernel, and then orchestrated and automated on Azure Prompt Flow.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 前面列出的组件和活动可以被开发成可重复的管道。然后，这些管道可以像之前讨论的那样高效地编排成一个连贯的工作流程。通过进一步提高运营效率，这个编排的工作流程可以自动化，并无缝集成到**持续集成/持续部署**（**CI/CD**）工作流程中。这些管道可以使用Python和框架（如Langchain或Semantic
    Kernel）轻松开发，然后在Azure Prompt Flow上编排和自动化。
- en: Benefits of LLMOps
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMOps的益处
- en: '**Automation and Efficiency**: Automation significantly reduces the duplication
    of efforts when introducing a new use case into production. The workflow, encompassing
    data ingestion, preparation, fine-tuning, deployment, and monitoring, is automatically
    triggered. This streamlining makes the entire process of integrating another use
    case much more efficient.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动化和效率**：在将新用例引入生产时，自动化显著减少了重复劳动。包括数据摄入、准备、微调、部署和监控在内的整个工作流程会自动触发。这种简化使得整合另一个用例的整个过程更加高效。'
- en: '**Agility**: LLMOps accelerates model and pipeline development, enhances the
    quality of models, and speeds up deployment to production, fostering a more agile
    environment for data teams.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**敏捷性**：LLMOps加速了模型和管道的开发，提高了模型的质量，并加快了部署到生产，为数据团队营造了一个更加敏捷的环境。'
- en: '**Reproducibility**: It facilitates the reproducibility of LLM pipelines, ensuring
    seamless collaboration across data teams, minimizing conflicts with DevOps and
    IT, and enhancing release velocity.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可重现性**：它促进了LLM管道的可重现性，确保数据团队之间协作的无缝性，最小化与DevOps和IT的冲突，并提高发布速度。'
- en: '**Risk mitigation**: LLMOps enhances transparency and responsiveness to regulatory
    scrutiny, ensuring greater compliance with policies and thereby mitigating risks.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**风险缓解**：LLMOps增强了透明度和对监管审查的响应能力，确保政策遵守度更高，从而降低风险。'
- en: '**Scalability management**: Enables extensive scalability and management capabilities,
    allowing for the oversight, control, management, and monitoring of thousands of
    models for continuous integration, delivery, and deployment.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性管理**：提供广泛的可扩展性和管理能力，允许对数千个模型进行监督、控制、管理和监控，以实现持续集成、交付和部署。'
- en: Comparing MLOps and LLMOps
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较MLOps和LLMOps
- en: While it is evident that MLOps is to machine learning as LLMOps is to LLMs,
    LLMOps shares many similarities **and has some differences** with MLOps. While
    some of our readers may already be familiar with machine learning and using MLOPs,
    with LLMOps, we do not have to go through expensive model training, as the LLM
    models are already pretrained. However, in our LLMOps process, as described in
    the “discover and tune” section, we still have the discovery process (to determine
    which LLM model, or models, would fit our use case), the tuning of the prompts
    using prompt engineering or prompt tuning, and, if necessary, and the fine-tuning
    of our models for domain-specific grounding.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然很明显，MLOps是机器学习的，LLMOps是LLMs的，但LLMOps与MLOps有很多相似之处**并且有一些不同之处**。虽然一些读者可能已经熟悉机器学习和使用MLOps，但在LLMOps中，我们不必经历昂贵的模型训练，因为LLM模型已经预训练。然而，在我们的LLMOps过程中，如“发现和调整”部分所述，我们仍然有发现过程（以确定哪个LLM模型或模型适合我们的用例），使用提示工程或提示调整调整提示，以及在必要时，对模型进行领域特定微调。
- en: 'Later in this chapter, we will look at a real-life use case where LLMOps played
    a critical role in a large organization’s management of LLMs; however, for now,
    it may be beneficial to do a side-by-side comparison of the two in a chart (*Figure
    6**.9*) to understand how the two relate and where they differ:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后面，我们将探讨一个真实世界的用例，其中LLMOps在一个大型组织管理LLMs中发挥了关键作用；然而，目前，在图表（*图6.9*）中并列比较这两个可能是有益的，以了解它们如何相关以及它们在哪里有所不同：
- en: '|  | **Traditional MLOps** | **LLMOps** |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '|  | **传统MLOps** | **LLMOps** |'
- en: '| --- | --- | --- |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Typical target audience | ML EngineersData ScientistsOperational Staff |
    ML EngineersApplication DevelopersOperational StaffData Engineers |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| 典型目标受众 | 机器学习工程师数据科学家运营人员 | 机器学习工程师应用开发者运营人员数据工程师 |'
- en: '| Assets to share, or the “deliverables.” | Model, data, environments, features
    | The actual LLM model, agents, plugins, prompts, chains, and APIs |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 要共享的资产，或“交付成果” | 模型、数据、环境、特征 | 实际的LLM模型、代理、插件、提示、链和API |'
- en: '| Model selection | Select a model version or let an **automated ML** (**AutoML**)
    select oneSee reference link at the end of this chapter on *What* *is AutoML?*
    | Select a pretrained foundation model thatcan be adapted to youruse case based
    on model cards, benchmarks, quick evaluations, etc. |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 模型选择 | 选择模型版本或让**自动机器学习（AutoML**）选择一个参见本章末尾的参考链接*什么是AutoML？* | 根据模型卡片、基准、快速评估等选择可以适应您用例的预训练基础模型
    |'
- en: '| Model training | Train the model against selected ML algorithm(s) | Fine-tune
    an existing foundation model, use a RAG pattern, and ground against your own data
    or perform prompt engineering |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 模型训练 | 使用选定的机器学习算法(s)训练模型 | 微调现有的基础模型，使用RAG模式，并针对您自己的数据或执行提示工程 |'
- en: '| Model validation and metrics | Evaluate and validate the ML models using
    metrics such as Accuracy, AUC, and F1 scoresTwo NLP evaluation and metrics examples
    include BLEU or ROUGE | Use human feedback and/or other LLMs to evaluate prompt
    responses:Quality: accuracy, similarity.Harm: bias, toxicityCorrectness: groundednessCost:
    token per requestLatency: response timePerplexityMetrics such as BLEU or ROUGE
    discussed in [*Chapter 3*](B21443_03.xhtml#_idTextAnchor052)Popular evaluation
    benchmarks such as MMLU, Perplexity, ARC, HellaSwag, TruthfulQA, etc. |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 模型验证和指标 | 使用准确率、AUC和F1分数等指标评估和验证机器学习模型 | 使用人类反馈和/或其他LLMs评估提示响应：质量：准确性、相似性。危害：偏见、毒性。正确性：扎根性。成本：每请求的令牌数。延迟：响应时间。困惑度：如*第3章*（B21443_03.xhtml#_idTextAnchor052）中讨论的BLEU或ROUGE等指标。流行的评估基准，如MMLU、困惑度、ARC、HellaSwag、TruthfulQA等。
    |'
- en: '| Model deployment | Allows for the packaging and deploying of an ML model
    via automated processes and pipelines | Deployments are packaged within the application
    and include additional components such as a vector database with the incorporation
    of LLM lifecycle techniques |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 模型部署 | 允许通过自动化流程和管道打包和部署机器学习模型 | 部署打包在应用程序中，并包括额外的组件，如包含LLM生命周期技术的向量数据库 |'
- en: '| Model monitoring | Monitor for model performanceMonitor for any drift in
    the ML model | Monitor the actual prompt and completions, content filtering for
    harmful content, prompt injection attacks, or jailbreaks (Reference [*Chapter
    8*](B21443_08.xhtml#_idTextAnchor163) for additional details regarding such attacks).Also,
    monitor for performance and model drift |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 模型监控 | 监控模型性能监控ML模型中的任何漂移 | 监控实际提示和完成情况，内容过滤以防止有害内容，提示注入攻击或越狱（参考[*第8章*](B21443_08.xhtml#_idTextAnchor163)以获取有关此类攻击的更多详细信息）。此外，监控性能和模型漂移
    |'
- en: Figure 6.9 – Comparing MLOps and LLMOps
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9 – 比较MLOps和LLMOps
- en: Hopefully, this summarized table provides some insights into which components
    of MLOps and LLMOps are similar and where there are differences.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 希望这个总结表格能为您提供一些关于MLOps和LLMOps哪些组件相似以及存在差异的见解。
- en: You should now have a foundational knowledge of LLMOps and it’s core component,
    the LLM lifecycle. As mentioned earlier, while these processes and procedures
    may seem a bit tedious, the benefits reaped are repeatable, safe generative AI
    practices within your organization. Teams can achieve faster model and pipeline
    deployments while providing higher-quality generative AI applications and services.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您应该已经对LLMOps及其核心组件——LLM生命周期有了基础的了解。如前所述，尽管这些流程和程序可能看起来有些繁琐，但从中获得的收益是可重复的、安全的人工智能实践。团队可以实现更快的模型和管道部署，同时提供更高品质的生成式AI应用和服务。
- en: For that “tedious” part, there are services that can streamline the LLMOps process.
    One such service is known as Azure Prompt Flow.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那部分“繁琐”的部分，有一些服务可以简化LLMOps流程。其中一种服务被称为Azure Prompt Flow。
- en: Platform – using Prompt Flow for LLMOps
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平台 – 使用Prompt Flow进行LLMOps
- en: 'Microsoft’s **Azure Prompt Flow** facilitates LLMOps integration for your organization,
    streamlining the operationalization of LLM applications and copilot development.
    It offers customers secure access to private data with robust controls, prompt
    engineering, continuous integration and deployment (CI/CD), and iterative experimentation.
    Additionally, it supports versioning, reproducibility, deployment, and incorporates
    a layer for safe and responsible AI. In this section, we will cover how Azure
    Prompt Flow can help you implement LLMOps processes:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的**Azure Prompt Flow**简化了您组织的LLMOps集成，流线化了LLM应用和协作者开发的运营。它为客户提供对私有数据的稳健控制和安全访问，包括提示工程、持续集成和部署（CI/CD）、迭代实验。此外，它支持版本控制、可重复性、部署，并包含一个用于安全且负责任的人工智能层。在本节中，我们将介绍Azure
    Prompt Flow如何帮助您实施LLMOps流程：
- en: '![Figure 6.10 – LLMOps Azure AI Prompt Flow diagram](img/B21443_06_10.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图6.10 – LLMOps Azure AI Prompt Flow图](img/B21443_06_10.jpg)'
- en: Figure 6.10 – LLMOps Azure AI Prompt Flow diagram
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.10 – LLMOps Azure AI Prompt Flow图
- en: 'Let’s describe the preceding, *Figure 6**.10*, to describe the Prompt Flow
    stages:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们描述一下前面的，*图6.10*，来描述Prompt Flow的阶段：
- en: In the top-most section, the **Design and Development** stage is where machine
    learning professionals and application developers create and develop prompts.
    Within this area, you work with LLMs by testing and trying out different prompts
    and using advanced logic and control flow to make effective prompts. With Prompt
    Flow, developers can make executable flows that connect LLMs, prompts, and Python
    tools through a clear, visualized graph.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在最顶部的部分，**设计和开发**阶段是机器学习专业人士和应用开发者创建和开发提示的地方。在这个区域，您通过与LLM进行测试和尝试不同的提示，并使用高级逻辑和控制流来制作有效的提示来与LLM合作。使用Prompt
    Flow，开发者可以通过清晰的、可视化的图表连接LLM、提示和Python工具，创建可执行的流程。
- en: In the intermediate (middle) **Evaluation and Refinement** stage, you assess
    the prompts for factors such as usefulness, fairness, groundedness, and content
    safety. Here, you also establish and measure prompt quality and effectiveness
    using standardized metrics. Prompt flow allows you to build prompt variants and
    assess and compare their results through large-scale testing, using pre-built
    and custom evaluations.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在中间的**评估和改进**阶段，您会评估提示的实用性、公平性、扎根性和内容安全性等因素。在这里，您还会使用标准化的指标建立和衡量提示的质量和有效性。Prompt
    flow允许您通过大规模测试构建提示变体，并评估和比较它们的结果，使用预构建和自定义评估。
- en: At the final stage at the bottom of the image, in the **Optimization and Production**
    stage, you can track and optimize your prompts for security and performance. You
    will also need to collaborate with others to get feedback. Prompt Flow can assist
    by launching your flow as an endpoint for real-time inference, test that endpoint
    with sample data, monitor telemetry for latency and continuously track performance
    against key evaluation metrics.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在图像底部的最终阶段，在**优化和生产**阶段，你可以跟踪和优化你的提示以实现安全和性能。你还需要与他人合作以获取反馈。Prompt Flow可以通过将你的流程作为实时推理的端点来协助，使用样本数据测试该端点，监控遥测以检测延迟，并持续跟踪与关键评估指标的性能。
- en: While the preceding image is a simplified view on how to approach Prompt Flow
    and understand it, let’s look at Prompt Flow and trace the steps through its deployment
    within an organization. In the following informational graphic image, taken from
    the Microsoft public website, *LLMOps with Prompt Flow and GitHub* (reference
    link at the end of this chapter), there is a graphical description of Prompt Flow
    deployment activities.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前面的图像是对如何接近Prompt Flow和了解它的简化视图，但让我们看看Prompt Flow，并追踪其在一个组织内部的部署步骤。在以下来自微软公共网站的信息图形图像中，*LLMOps与Prompt
    Flow和GitHub*（本章末尾的参考链接），有一个Prompt Flow部署活动的图形描述。
- en: There are quite a few steps involved in Prompt Flow, and we will not go into
    too much detail here, leaving you with a link to explore this further (there is
    both a link to the main Microsoft website for additional documentation and the
    GitHub site, which has a compelling hand-on exercise in which you can follow along
    and learn).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: Prompt Flow中涉及到的步骤相当多，这里不会过多详细说明，留给你一个链接去进一步探索（这里有一个链接到微软官方网站以获取更多文档，以及GitHub网站，其中有一个引人入胜的动手练习，你可以跟随学习）。
- en: '![Figure 6.11 – A summary of the Prompt Flow CI/CD deployment sequence](img/B21443_06_11.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![图6.11 – Prompt Flow CI/CD部署序列概览](img/B21443_06_11.jpg)'
- en: Figure 6.11 – A summary of the Prompt Flow CI/CD deployment sequence
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.11 – Prompt Flow CI/CD部署序列概览
- en: As you can tell from the robustness of the preceding image, Prompt Flow empowers
    you and your organization to confidently develop, rigorously test, fine-tune,
    and deploy CI/CD flows, allowing for the creation of reliable and advanced generative
    AI solutions, aligned to LLMOps.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如从前面图像的健壮性中可以看出，Prompt Flow使你和你所在的组织能够自信地开发、严格测试、微调和部署CI/CD流程，从而创建与LLMOps一致的可靠和高级生成式AI解决方案。
- en: 'In the preceding image, there are three main environments: **PR**, **Dev**
    and **Prod**. A **PR** environment, or **pull request**, is a short-lived environment
    containing changes that require review before being merged into the **Dev** and/or
    **Prod** environments. Oftentimes, the PR environment is called a **test** environment.
    You can get more detailed information on setting up PR and other environments
    at Review pull requests in pre-production environments.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图像中，有三个主要环境：**PR**、**Dev**和**Prod**。**PR**环境，或**pull request**，是一个短暂存在的环境，包含需要审查才能合并到**Dev**和/或**Prod**环境中的更改。通常，PR环境被称为**测试**环境。你可以在预生产环境中的审查拉取请求中获取有关设置PR和其他环境的更详细信息。
- en: 'There are a number of steps in LLMOps Prompt Flow deployment:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: LLMOps Prompt Flow部署涉及多个步骤：
- en: The initialization stage is where the LLMOps data are prepared in a stage/test
    environment, such as data preparation and the entire environment setup.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化阶段是在一个阶段/测试环境中准备LLMOps数据的地方，例如数据准备和整个环境设置。
- en: As with any developer tools that help author CI/CD pipelines, you can then pull
    requests from the feature branch to the development branch, which will then execute
    the experimentation flow, as described in the preceding image.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与任何帮助创建CI/CD管道的开发者工具一样，然后你可以从功能分支拉取请求到开发分支，这将执行前面图像中描述的实验流程。
- en: Once approved, the generative AI code is merged from the Dev branch into the
    main branch, and the same process repeats both for the Dev environments and the
    Prod environment, in the middle and right of the image above.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦获得批准，生成式AI代码将从Dev分支合并到主分支，上述图像中间和右侧的Dev环境和Prod环境也会重复相同的过程。
- en: All of the CI/CD processing is facilitated with the Azure Machine Learning model
    registry environment, which makes it easy to keep track of and organize various
    models, from generative AI models to traditional ML models, and this also connects
    to other model registries/repositories such as Hugging Face.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有CI/CD处理都通过Azure Machine Learning模型注册环境进行，这使得跟踪和组织各种模型变得容易，从生成式AI模型到传统ML模型，这还连接到其他模型注册库/存储库，如Hugging
    Face。
- en: 'The LLMOps CI/CD steps can all be managed using Azure DevOps or GitHub. There
    are a number of steps and details which are better understood with practice. Building
    this process flow using the Prompt Flow hands-on lab on our GitHub repo will give
    you the practice, better understanding, and experience you may need. Check out
    this accelerator on deploying your Prompt Flow CICD pipelines: [https://github.com/microsoft/llmops-promptflow-template](https://github.com/microsoft/llmops-promptflow-template).'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: LLMOps CI/CD步骤都可以使用Azure DevOps或GitHub进行管理。有许多步骤和细节需要通过实践来更好地理解。在我们的GitHub存储库上使用Prompt
    Flow动手实验室构建此流程将为您提供所需的实践、更好的理解和经验。查看部署您的Prompt Flow CICD管道的此加速器：[https://github.com/microsoft/llmops-promptflow-template](https://github.com/microsoft/llmops-promptflow-template)。
- en: Important note
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: While we have discussed various LLMOps practices, we have not delved into the
    integration of autonomous agents due to the novelty of this field and the limited
    number of agent-based applications currently in production. Many such applications
    are still in the research phase. However, we anticipate that autonomous agents
    will soon become a significant aspect of LLMOps practices.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经讨论了各种LLMOps实践，但由于该领域的创新性和目前生产中基于代理的应用数量有限，我们尚未深入探讨自主代理的集成。许多此类应用仍处于研究阶段。然而，我们预计自主代理将很快成为LLMOps实践的一个重要方面。
- en: Putting it all together
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整合一切
- en: Before we arrive at the last major section of this chapter to look at an actual
    case study and best practices, we felt it is helpful to put all the generative
    AI categories together and understand how data flows from one into another and
    vice-versa.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们到达本章的最后一大节，查看实际案例研究和最佳实践之前，我们认为将所有生成式AI类别放在一起，了解数据如何从一个流向另一个，反之亦然，是有帮助的。
- en: Earlier, we shared the CI/CD pipeline flow using Prompt Flow within the LLMOps
    construct. Now, we will take a macro look, beyond just the LLM, at how the LLM
    application development stack messages would flow across the generative AI ecosystem,
    using categories to organize the products and services.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们分享了在LLMOps结构中使用Prompt Flow的CI/CD管道流程。现在，我们将从宏观角度审视，而不仅仅是LLM，LLM应用程序开发堆栈的消息如何在生成式AI生态系统中流动，使用类别来组织产品和服务。
- en: 'While we do not endorse any specific services or technology, except our employer,
    our goal here is to show how a typical LLM flow would appear using various generative
    AI toolsets/products/services. We have organized each of the workloads by category,
    represented in the light gray boxes, along with a few of the products or services,
    as examples within each category. Then, we use arrows to show how typical traffic
    flow would occur, from queries submitted by users to the output returned to the
    users, and the contextual data provided by developers to the conditioned LLM outputs.
    The contextual data may include fine-tuning, RAG, and other techniques that you
    have learned in this book, such as single-shot, few-shot, etc.:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们不推荐任何特定的服务或技术，除了我们的雇主，我们的目标在这里是展示如何使用各种生成式AI工具集/产品/服务来呈现典型的LLM流程。我们已按类别组织每个工作负载，以浅灰色框表示，并在每个类别中提供一些产品或服务作为示例。然后，我们使用箭头显示典型的流量流向，从用户提交的查询到返回给用户的输出，以及开发者提供的上下文数据到条件化LLM输出。上下文数据可能包括微调、RAG和其他技术，例如单次、少量等：
- en: '![Figure 6.12 – LLM end-to-end flow with services](img/B21443_06_12.jpg)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![图6.12 – 带服务的LLM端到端流程](img/B21443_06_12.jpg)'
- en: Figure 6.12 – LLM end-to-end flow with services
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.12 – 带服务的LLM端到端流程
- en: LLMOps – case study and best practices
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMOps – 案例研究和最佳实践
- en: 'With a Fortune 50 company based in the US, in the professional services industry,
    they had already been working with AI tools and using both Azure OpenAI and Azure
    ML in the cloud for almost a year. This organization was expanding its successful
    generative AI pilot worldwide and needed a repeatable way to develop, test, and
    deploy LLMs for its internal employees. Below are steps we wanted to share so
    others can know what to expect when applying an LLMOps strategy to an already
    existing generative AI ecosystem within an organization:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在美国的一家财富50强公司，该公司的业务领域是专业服务，他们已经与AI工具合作，并在云中使用Azure OpenAI和Azure ML大约一年了。该组织正在全球范围内扩大其成功的生成式AI试点项目，并需要一个可重复的方式来开发、测试和部署LLM，供其内部员工使用。以下是我们想要分享的步骤，以便其他人知道在将LLMOps策略应用于组织内现有的生成式AI生态系统时可以期待什么：
- en: LLMOps field case study
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMOps领域案例研究
- en: '**Executive vision and LLMOps strategy**: For any organization to use LLMOps/generative
    AI/AI successfully, leadership buy-in and support are essential for the business
    groups and teams to then build out a repeatable framework. We had already gone
    through the journey of manually deploying models, and so next, we helped the CIO
    and his direct staff create a solid LLMOps strategy using the guidelines that
    we described earlier in this chapter. We helped review the company’s most beneficial
    generative AI projects and provide suggestions on automating most of their processes
    using LLMOps to boost business performance and achievement.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行愿景和LLMOps策略**：对于任何组织来说，要成功使用LLMOps/生成式AI/AI，领导层的认可和支持对于业务部门和团队构建可重复的框架至关重要。我们之前已经经历了手动部署模型的旅程，因此接下来，我们帮助CIO及其直接团队根据本章前面描述的指南制定了一个稳固的LLMOps策略。我们帮助审查公司最有益的生成式AI项目，并提供建议，通过使用LLMOps自动化大部分流程来提升业务绩效和成就。'
- en: '**Demos, demos and more demos**: To help create the vision and ideation, we
    went through a number of demos which included generative AI and playing with a
    number of LLM models for those newer to the technology and demos on LLMOps using
    Prompt Flow for their ML data scientists and software developers.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**演示、演示和更多演示**：为了帮助创建愿景和创意，我们进行了一系列演示，包括生成式AI和与一些新技术的LLM模型互动，以及为他们的ML数据科学家和软件开发人员进行的LLMOps演示，使用Prompt
    Flow进行演示。'
- en: '**Training**: In order to fully grasp the concepts of using generative AI tools
    and help improve the client’s knowledge and skills, we recommended both generative
    AI and Azure OpenAI training for those newer to generative AI subject and help
    ensure this customer’s internal teams are skilled and informed about the technologies
    they will be using, operationalizing and managing. This also included custom-created
    LLMOps training as well for the developer teams and training on Microsoft Semantic
    Kernel, as both LLMOps and SK were very new to the organization. They were eager
    to use an orchestration platform to be more agile in their generative AI approach
    while reducing the cumbersome management of the large technical stack they had
    already deployed. Semantic Kernel and LLMOps allowed for a more refined generative
    AI deployment methodology.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**培训**：为了全面理解使用生成式AI工具的概念，并帮助提高客户的知识和技能，我们建议对那些对生成式AI主题较新的人来说进行生成式AI和Azure
    OpenAI的培训，并确保这个客户的内部团队具备使用、实施和管理这些技术的技能和知识。这也包括为开发团队定制的LLMOps培训，以及Microsoft Semantic
    Kernel的培训，因为LLMOps和SK对于该组织来说都非常新。他们渴望使用一个编排平台来使他们的生成式AI方法更加敏捷，同时减少他们已经部署的大型技术堆栈的繁琐管理。Semantic
    Kernel和LLMOps允许采用更精细的生成式AI部署方法。'
- en: '**Hands-on hackathon**: To establish comfort in the tools and technologies,
    a hands-on “hackathon” was set up, where we took a few existing business challenges
    where their current processes were not working on non-existing and addressed them
    in a large group setting over multiple days.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**动手黑客马拉松**：为了在工具和技术上建立信心，我们设立了一个动手的“黑客马拉松”，我们选取了一些现有的业务挑战，其中他们的当前流程在非现有情况下不起作用，并在多天的集体设置中解决了这些问题。'
- en: '**LLMOps pilots**: We next assisted two different teams responsible for the
    development and operational support for the organization to help pilot the LLMOps
    strategy and processes. We took a lot of the learning, behavior and feedback and
    refined the process. Recall LLMOps is not only the people and technology/platforms,
    it is also about processes. In order to successfully implement LLMOps, we needed
    these various teams within the organization to define and adopt these newly agreed
    upon processes. Fortunately, this organization already had a well-established
    DevOps and Mops process in place, so adopting an LLMOps strategy and applying
    the processes was not a drastic disruption in business.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLMOps试点**：接下来，我们协助了两个不同团队，他们负责组织的发展和运营支持，以帮助试点LLMOps策略和流程。我们吸取了很多学习经验、行为和反馈，并改进了流程。回想一下，LLMOps不仅仅是人员和技术/平台，它还关乎流程。为了成功实施LLMOps，我们需要组织内的这些不同团队定义和采用这些新达成的流程。幸运的是，这个组织已经建立了一个良好的DevOps和Mops流程，因此采用LLMOps策略并应用这些流程并没有对业务造成剧烈的干扰。'
- en: In summary, this Fortune 500 organization has enjoyed the streamlined processes
    that LLMOps has to offer from the first design and development stage during the
    hackathon event to the evaluation and refinement in the final stage during the
    pilots
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，这家财富500强组织从黑客松活动中的首次设计和开发阶段，到试点阶段的最终评估和改进，一直享受着LLMOps提供的流程简化服务。
- en: LLMOps best practices
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMOps最佳实践
- en: 'As we wrap up this final section, we know that successfully navigating the
    generative AI and LLM landscape requires effective practice. As this generative
    AI space is still fairly new and ever-growing, so are the lessons learned and
    the list of best practices being enhanced. We provide some guidelines to follow
    for some effective LLMOps practices:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束这个最后的部分时，我们知道成功导航生成式AI和LLM领域需要有效的实践。由于生成式AI空间仍然相对较新且不断增长，因此学到的经验和最佳实践列表也在不断丰富。我们提供了一些遵循有效LLMOps实践的指南：
- en: '**Build for the enterprise and build for scalability**: To ensure smooth deployment
    and growth, organizations should build around enterprise-ready tooling and enterprise-class
    infrastructure for their LLMOps requirements. Fortunately, many hyperscale cloud
    vendors make this very simple, as you can build your generative AI applications
    and services using tested and proven methodologies. Additionally, these hyperscale
    cloud vendors provide the proper security and guardrails to make your generative
    AI project a success. We will be going into the enterprise-ready, scalable environments
    in the next chapter.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**为企业和可扩展性而构建**：为了确保平稳部署和增长，组织应该围绕适用于企业的工具和企业级基础设施来构建他们的LLMOps需求。幸运的是，许多超大规模云服务提供商使这一点变得非常简单，因为你可以使用经过测试和验证的方法来构建你的生成式AI应用程序和服务。此外，这些超大规模云服务提供商还提供适当的安全性和护栏，以确保你的生成式AI项目取得成功。我们将在下一章中详细介绍适用于企业的、可扩展的环境。'
- en: '**Remain flexible and use agility**: The world’s journey into LLMOps has just
    started. We did provide details of this in this chapter, yet with new innovations
    and challenges, it is essential to remain flexible and evolve as we have this
    major paradigm shift. Develop an LLMOps strategy, based on the concepts and techniques
    you have learned in this chapter, yet do not remain rigid as this strategy will
    also need to evolve as the LLM/generative AI technology evolves.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**保持灵活并使用敏捷性**：世界进入LLMOps的旅程才刚刚开始。我们已经在本章中提供了这方面的详细信息，但随着新的创新和挑战的出现，保持灵活并随着这一主要范式转变而发展是至关重要的。根据你在本章中学到的概念和技术，制定LLMOps策略，但不要僵化，因为这个策略也需要随着LLM/生成式AI技术的发展而发展。'
- en: '**Focus on data quality**: A data quality focus means putting resources into
    reliable data, applying solid data management practices, and adopting solid review
    practices. Organizations need to use high-quality data that is relevant, accurate,
    and unbiased to train and fine-tune LLMs properly. This is also incorporated into
    the LLM lifecycle phases you learned earlier in this chapter. Also, it is almost
    given that organizations use version control and deploy using standardized development
    tooling and clean data pipelines to prepare and manage the data, so having quality
    data is a must.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关注数据质量**：关注数据质量意味着将资源投入到可靠的数据中，应用坚实的数据管理实践，并采用坚实的审查实践。组织需要使用相关、准确且无偏见的优质数据来正确训练和微调LLM。这一点也融入了本章前面学到的LLM生命周期阶段。几乎可以肯定的是，组织会使用版本控制和标准化的开发工具以及清洁的数据管道来准备和管理数据，因此拥有高质量的数据是必须的。'
- en: '**Improve experimentation while making enhancements**: The LLMOps lifecycle,
    including LLM development and deployment, is ongoing. There is a constant demand
    for new data and behavior improvements and enhancements. Most all of the tooling
    for experimentation and making enhancements can be automated, however always keep
    a human-in-the-loop for the quality control and alignment with business outcomes.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在增强的同时改进实验**：LLMOps生命周期，包括LLM开发和部署，是持续的。对新数据和改进行为的需求是持续的。几乎所有用于实验和改进的工具都可以自动化，但始终要有人工智能在回路中，以确保质量控制与业务成果保持一致。'
- en: Summary
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we covered the basis of generative AI intersecting with software
    development. We covered three popular programming generative AI application frameworks:
    Semantic Kernel, LangChain, and LlamaIndex. We also introduced LLMOps, a comprehensive
    framework for managing the lifecycle of a generative AI ecosystem and how Prompt
    Flow can simplify the management of an LLMOps strategy; together, all of these
    components form a comprehensive framework for developing and deploying generative
    AI applications and services.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了生成式AI与软件开发交叉的基础知识。我们介绍了三个流行的编程生成式AI应用框架：Semantic Kernel、LangChain和LlamaIndex。我们还介绍了LLMOps，这是一个用于管理生成式AI生态系统生命周期的全面框架，以及如何通过Prompt
    Flow简化LLMOps策略的管理；所有这些组件共同构成了一个用于开发和部署生成式AI应用程序和服务的全面框架。
- en: We also described the lifecycle of an LLM model itself to round out the lifecycle
    discussion.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还描述了LLM模型本身的生命周期，以完善生命周期讨论。
- en: As we look at extensibility and automating, we delved into the world of agents
    and autonomous agents, such as AutoGen and AutoGPT, which can work autonomously
    to address extremely complex problems by using a few techniques such as chaining
    or networking LLMs together in collaboration.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们关注可扩展性和自动化时，我们深入研究了代理和自主代理的世界，例如AutoGen和AutoGPT，它们可以通过使用一些技术如链式或网络化LLM进行协作来自主地解决极其复杂的问题。
- en: Finally, we looked at an actual case study of a large organization and how they
    adopted LLMOps. From this, we wrapped up the chapter with some LLMOps best practices.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们研究了一个大型组织及其如何采用LLMOps的实际案例研究。据此，我们以一些LLMOps最佳实践结束了本章。
- en: While the landscapes of programming language frameworks, tools, and agents are
    constantly being enhanced on an almost daily basis, we can all agree that the
    concepts you have learned thus far pave the way for enterprises to embrace generative
    AI and LLMs and be able to manage and operationalize the tooling and process easily
    and at scale.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管编程语言框架、工具和代理的景观几乎每天都在不断得到增强，但我们可以一致认为，您迄今为止学到的概念为企业拥抱生成式AI和LLM铺平了道路，并能够轻松且大规模地管理和操作工具和流程。
- en: Now that we have a clearer picture of how LLM models and LLM-based applications
    are created using programming language frameworks and made more efficient by using
    LLMOps, let’s slightly change our focus for the next chapter. In the next chapter,
    let’s expand more on the operational side of the cloud and expand our understanding
    of how LLM models, such as ChatGPT, are deployed at a large scale from an architecture
    design perspective. We will also understand the scaling strategies used in the
    cloud for such large deployments.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对如何使用编程语言框架创建LLM模型以及如何通过LLMOps使其更高效有了更清晰的了解，让我们稍微改变一下下一章的焦点。在下一章中，让我们更深入地探讨云的运营方面，并从架构设计角度扩展我们对LLM模型（如ChatGPT）如何大规模部署的理解。我们还将了解在云中用于此类大规模部署的扩展策略。
- en: References
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Microsoft Build Session: Kevin Scott’s talk *The era of the AI* *Copilot:*
    [https://build.microsoft.com/en-US/sessions/bb8f9d99-0c47-404f-8212-a85fffd3a59d](https://build.microsoft.com/en-US/sessions/bb8f9d99-0c47-404f-8212-a85fffd3a59d)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软构建会议：凯文·斯科特的演讲 *AI时代协作伙伴*：[https://build.microsoft.com/en-US/sessions/bb8f9d99-0c47-404f-8212-a85fffd3a59d](https://build.microsoft.com/en-US/sessions/bb8f9d99-0c47-404f-8212-a85fffd3a59d)
- en: '*What is automated machine learning (**AutoML)?* [https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml](https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*什么是自动化机器学习（**AutoML**）？* [https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml](https://learn.microsoft.com/en-us/azure/machine-learning/concept-automated-ml)'
- en: '*LLMOps with prompt flow on* *GitHub* [https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/how-to-end-to-end-llmops-with-prompt-flow](https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/how-to-end-to-end-llmops-with-prompt-flow)'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在 *GitHub* 上使用 *prompt flow* 进行 *LLMOps*：[https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/how-to-end-to-end-llmops-with-prompt-flow](https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/how-to-end-to-end-llmops-with-prompt-flow)'
- en: '*Review pull requests in pre-production* *environments:* [https://learn.microsoft.com/en-us/azure/static-web-apps/review-publish-pull-requests](https://learn.microsoft.com/en-us/azure/static-web-apps/review-publish-pull-requests)'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在预生产环境中* *审查拉取请求*：[https://learn.microsoft.com/en-us/azure/static-web-apps/review-publish-pull-requests](https://learn.microsoft.com/en-us/azure/static-web-apps/review-publish-pull-requests)'
- en: '*Technological singularity* *defined*, Wikipedia.[https://en.wikipedia.org/wiki/Technological_singularity](https://en.wikipedia.org/wiki/Technological_singularity)'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*技术奇点* *定义*，维基百科。[https://zh.wikipedia.org/wiki/技术奇点](https://zh.wikipedia.org/wiki/技术奇点)'
- en: '*Architecting AI Apps with Semantic* *Kernel*: [https://devblogs.microsoft.com/semantic-kernel/architecting-ai-apps-with-semantic-kernel/](https://devblogs.microsoft.com/semantic-kernel/architecting-ai-apps-with-semantic-kernel/)'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用语义内核构建 AI 应用程序*：[https://devblogs.microsoft.com/semantic-kernel/architecting-ai-apps-with-semantic-kernel/](https://devblogs.microsoft.com/semantic-kernel/architecting-ai-apps-with-semantic-kernel/)'
- en: '*Azure OpenAI Assistants function* *calling*: [https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/assistant-functions](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/assistant-functions)'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Azure OpenAI 助手功能* *调用*：[https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/assistant-functions](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/assistant-functions)'
- en: '*An Introduction to LLMOps: Operationalizing and Managing Large Language Models
    using Azure ML (**microsoft.com)*: [https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/an-introduction-to-llmops-operationalizing-and-managing-large/ba-p/3910996](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/an-introduction-to-llmops-operationalizing-and-managing-large/ba-p/3910996)'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*LLMOps 简介：使用 Azure ML 运营和管理大型语言模型（**microsoft.com**）：[https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/an-introduction-to-llmops-operationalizing-and-managing-large/ba-p/3910996](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/an-introduction-to-llmops-operationalizing-and-managing-large/ba-p/3910996)'
- en: '*What is* *LLMOPs?* [https://www.databricks.com/glossary/llmops](https://www.databricks.com/glossary/llmops)'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*什么是* *LLMOPs*？ [https://www.databricks.com/glossary/llmops](https://www.databricks.com/glossary/llmops)'
- en: '*Azure Prompt Flow CICD* *Template*: [https://github.com/microsoft/llmops-promptflow-template](https://github.com/microsoft/llmops-promptflow-template)'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Azure Prompt Flow CICD 模板*：[https://github.com/microsoft/llmops-promptflow-template](https://github.com/microsoft/llmops-promptflow-template)'
