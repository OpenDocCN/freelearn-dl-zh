- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Conceptual Representation Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概念表征学习
- en: Understanding cutting-edge machine learning and deep learning theory only marks the
    beginning of your adventure. The knowledge you have acquired should help you become
    an AI visionary. Take everything you see as opportunities and see how AI can fit
    into your projects. Reach the limits and skydive beyond them.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 理解前沿的机器学习和深度学习理论仅标志着你冒险的开始。你所获得的知识应该帮助你成为AI的远见者。把你所看到的一切都当作机会，看看AI如何融入你的项目。挑战极限并超越它们。
- en: This chapter focuses on decision-making through visual representations and explains
    the motivation that led to **conceptual representation learning** (**CRL**) and
    **metamodels** (**MM**), which form **CRLMMs**.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章侧重于通过视觉表征进行决策，并解释导致**概念表征学习**（**CRL**）和**元模型**（**MM**）的动机，二者共同构成了**CRLMMs**。
- en: 'Concept learning is our human ability to partition the world from chaos to
    categories, classes, sets, and subsets. As a child and young adult, we acquire
    many classes of things and concepts. For example, once we understand what a "hole"
    is, we can apply it to anything we see that is somewhat empty: a black hole, a
    hole in the wall, a hole in a bank account if money is missing or overspent, and
    hundreds of other cases.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 概念学习是我们人类将世界从混乱分割为类别、类、集合和子集的能力。作为一个孩子和年轻人，我们获取了许多事物和概念的类别。例如，一旦我们理解了“洞”是什么，我们就可以将其应用于任何我们看到的某种空洞的事物：黑洞、墙上的洞、银行账户中的洞（如果钱丢失或透支了），以及数百种其他情况。
- en: By performing concept learning, we humans do not have to learn the same concept
    over and over again for each case. For example, a hole is a hole. So when we see
    a new situation such as a crater, we know it's just a "big" hole. I first registered
    a word2vector patent early in my career. Then I rapidly applied it to concept2vector
    algorithms. I then designed and developed the CRLMM method successfully for **automatic
    planning and scheduling** (**APS**) software, cognitive chatbots, and more, as
    we will see in the following chapters. The metamodel term means that I applied
    one single model to many different domains, just as we humans do.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 通过进行概念学习，我们人类不必在每种情况中反复学习相同的概念。例如，洞就是洞。所以当我们看到一个新的情况，比如火山口时，我们知道它只是一个“大的”洞。我在职业生涯初期就注册了一个word2vector专利。然后，我迅速将其应用到concept2vector算法中。随后，我成功设计并开发了CRLMM方法，用于**自动规划和调度**（**APS**）软件、认知聊天机器人等，正如我们将在接下来的章节中看到的那样。元模型一词意味着我将一个单一模型应用于多个不同领域，就像我们人类做的那样。
- en: Conceptual representations also provide visual images of concepts. To plan,
    humans need to visualize necessary information (events, locations, and so on)
    and more critical *visual dimensions* such as *image concepts*. A human being
    thinks in *mental images*. When we think, mental images flow through our minds
    with numbers, sounds, odors, and sensations, transforming our environment into
    fantastic multidimensional representations similar to video clips.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 概念表征还提供了概念的视觉图像。为了进行规划，人类需要可视化必要的信息（事件、位置等）以及更关键的*视觉维度*，比如*图像概念*。人类思维通过*心理图像*进行。当我们思考时，心理图像与数字、声音、气味和感觉一起流经我们的思维，将我们的环境转化为类似视频片段的奇妙多维表征。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涉及以下主题：
- en: 'An approach to CRLMM in three steps:'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CRLMM方法的三步法：
- en: Transfer learning to avoid developing a new program for each variation of a
    similar case
  id: totrans-9
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转移学习以避免为每个类似案例的变化开发新程序
- en: Domain learning to avoid developing a new program each time the domain changes
  id: totrans-10
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 域学习，以避免每次域发生变化时都开发一个新程序
- en: The motivation for using CRLMM
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CRLMM的动机
- en: Over the years, I've successfully implemented CRL in C++, Java, and logic programming
    (Prolog) in various forms on corporate sites. In this chapter, I'll use Python
    to illustrate the approach with TensorFlow 2.x with the **convolutional neural
    network (CNN)** built in *Chapter 9*, *Abstract Image Classification with Convolutional
    Neural Networks (CNNs)*.
  id: totrans-12
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多年来，我已经成功地在C++、Java和逻辑编程（Prolog）中以多种形式在企业网站上实现了CRL。在本章中，我将使用Python通过TensorFlow
    2.x来说明这一方法，使用在*第9章*，*使用卷积神经网络（CNNs）进行抽象图像分类*中构建的**卷积神经网络（CNN）**。
- en: Transfer learning using a CNN model trained to generalize image recognition
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CNN模型的转移学习来泛化图像识别
- en: Domain learning to extend image recognition trained in one field to another field
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 域学习，将在一个领域训练的图像识别扩展到另一个领域
- en: We'll begin this chapter by looking at the benefits of transfer learning and
    how concept learning can boost this process.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从本章开始，探讨迁移学习的好处，以及概念学习如何促进这一过程。
- en: Generating profit with transfer learning
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过迁移学习创造利润
- en: Transfer learning means that we can use a model we designed and trained in another
    similar case. This will make the model very profitable since we do not have to
    design a new model and write a new program for every new case. You will thus generate
    profit for your company or customer by lowering the cost of new implementations
    of your trained model. Think of a good AI model as a reusable tool when applied
    to similar cases. This is why concept learning, being more general and abstract,
    is profitable. That is how we humans adapt.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习意味着我们可以在另一个类似的案例中使用我们设计和训练过的模型。这会使模型非常有利可图，因为我们不需要为每个新案例设计一个新模型或编写一个新的程序。这样，你就能通过降低新实现你训练过的模型的成本，为公司或客户创造利润。把一个好的AI模型看作是一个在类似案例中可以重复使用的工具。这就是为什么概念学习更具普遍性和抽象性且有利可图的原因。这是我们人类适应的方式。
- en: When it comes to reasoning and thinking in general, we use mental images with
    some words. Our thoughts contain concepts, on which we build solutions.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理和思考方面，我们通常会使用一些词语配合心象。我们的思维包含概念，我们基于这些概念构建解决方案。
- en: The trained model from *Chapter 9*, *Abstract Image Classification with Convolutional
    Neural Networks (CNNs)*, can now classify images of a certain type. In this section,
    the trained model will be loaded and then generalized through transfer learning
    to classify similar images.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 来自*第9章*的训练模型，*基于卷积神经网络（CNNs）的抽象图像分类*，现在可以对某一类型的图像进行分类。在本节中，训练过的模型将被加载，并通过迁移学习进行泛化，以便分类类似的图像。
- en: You will notice that I did not use many images for the example. My goal was
    to explain the process, not to go into building large datasets, which is a task
    in itself. The primary goal is to *understand* CNNs and conceptual learning representations.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到，我在例子中没有使用太多的图像。我的目标是解释过程，而不是深入讨论如何构建大规模数据集，因为那本身就是一个任务。主要目标是*理解*CNNs和概念学习表示。
- en: The motivation behind transfer learning
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迁移学习背后的动机
- en: Transfer learning provides a cost-effective way of using trained models for
    other purposes within the same company, such as the food processing company described
    in *Chapter 9*, *Abstract Image Classification with Convolutional Neural Networks
    (CNNs)*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习提供了一种成本效益高的方式，可以在同一公司内部将训练好的模型用于其他目的，例如在*第9章*中描述的食品加工公司，*基于卷积神经网络（CNNs）的抽象图像分类*。
- en: This chapter describes how the food processing company used the model for other
    similar purposes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本章描述了食品加工公司如何将模型用于其他类似的目的。
- en: The company that succeeds in doing this will progressively generalize the use
    of the solution. By doing so, inductive abstraction will take place and lead to
    other AI projects, which will prove gratifying to the management of a corporation
    and the teams providing the solutions.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 成功做到这一点的公司将逐步推广解决方案的应用。通过这样做，演绎抽象将发生，并推动其他AI项目，这将为公司的管理层和提供解决方案的团队带来丰硕的成果。
- en: Inductive thinking
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 演绎思维
- en: Induction uses inferences to reach a conclusion. For example, a food processing
    conveyor belt with missing products will lead to packaging productivity problems.
    If an insufficient amount of products reaches the packaging section, this will
    slow down the whole production process.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 演绎使用推论来得出结论。例如，食品加工传送带上缺少产品将导致包装生产力问题。如果不足够的产品到达包装环节，整个生产过程将会放慢。
- en: By observing similar problems in other areas of the company, inferences from
    managers will come up, such as *if insufficient amounts of products flow through
    the process, production will slow down*.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通过观察公司其他领域的相似问题，管理人员会得出推论，例如*如果产品流经工艺流程的数量不足，生产将会放慢*。
- en: Inductive abstraction
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 演绎抽象
- en: The project team in charge of improving efficiency in any company needs to find
    an *abstract representation* of a problem to implement a solution through organization
    or software. This book deals with the AI side of solving problems. Organizational
    processes need to define how AI will fit in, with several on-site meetings.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 负责提升公司效率的项目团队需要找到问题的*抽象表示*，以通过组织或软件实施解决方案。本书主要讨论解决问题的AI方面。组织过程需要定义AI如何融入其中，并进行多次现场会议。
- en: The problem AI needs to solve
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AI需要解决的问题
- en: 'In this particular example, each section of the factory has an **optimal production
    rate** (**OPR**) defined per hour or per day, for example. The equation of an
    OPR per hour can be summed up as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定的例子中，工厂的每个部门都有一个每小时或每天定义的**最优生产速率**（**OPR**）。每小时的OPR方程可以总结如下：
- en: 'OPR : min(*p*(*s*)) <= OPR <= max(*p*(*s*))'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 'OPR : min(*p*(*s*)) <= OPR <= max(*p*(*s*))'
- en: 'Where:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 其中：
- en: '*p* is the production rate of a given section (the different production departments
    of a factory) *s*.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p*是给定部门的生产速率（工厂的不同生产部门）*s*。'
- en: '*p*(*s*) is the production rate of the section.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p*(*s*)是该部门的生产速率。'
- en: min(*p*(*s*)) is the historical minimum (trial and error over months of analysis).
    Under that level, the whole production process will slow down.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: min(*p*(*s*))是历史最低值（经过几个月的反复试验和分析）。低于该水平，整个生产过程将减速。
- en: max(*p*(*s*)) is the historical maximum. Over that level, the whole production
    process will slow down as well.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: max(*p*(*s*))是历史上的最大值。超过该水平，整个生产过程也会减速。
- en: OPR is the optimal production rate.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OPR是最优生产速率。
- en: The first time somebody sees this equation, it seems difficult to understand.
    The difficulty arises because you have to visualize the process, which is the
    goal of this chapter. Every warehouse, industry, and service uses production rates
    as a constraint to reach profitable levels.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次看到这个方程时，它看起来很难理解。困难之处在于你需要将过程可视化，而这正是本章的目标。每个仓库、行业和服务都使用生产速率作为约束，以达到盈利水平。
- en: 'Visualization requires representation at two levels:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化要求在两个层次上进行表示：
- en: Ensuring that if a packaging department is not receiving enough products, it will
    have to slow down or even stop sometimes.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保如果包装部门没有收到足够的产品，它将不得不减慢生产速度，甚至有时停止生产。
- en: Ensuring that if a packaging department receives too many products, it will
    not be able to package them. If the input is a conveyor belt with no intermediate
    storage (present-day trends), then it will have to be slowed down, slowing down
    or stopping the processes before that point.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保如果包装部门收到过多的产品，它将无法进行包装。如果输入是没有中间存储的传送带（现代趋势），那么必须减慢速度，从而减缓或停止之前阶段的生产过程。
- en: In both cases, slowing down production leads to bad financial results and critical
    sales problems through late deliveries.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，减慢生产将导致糟糕的财务结果和通过延迟交付造成的严重销售问题。
- en: 'In both cases, an OPR gap is a problem. To solve this problem, another level
    of abstraction is required. First, let''s break down the OPR equation into two
    parts:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，OPR差距是一个问题。为了解决这个问题，需要另一个层次的抽象。首先，让我们把OPR方程分成两部分：
- en: OPR >= min(*p*(*s*))
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: OPR >= min(*p*(*s*))
- en: OPR <= max(*p*(*s*))
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: OPR <= max(*p*(*s*))
- en: 'Now let''s find a higher control level through variance variable *v*:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过方差变量*v*来找到一个更高的控制水平：
- en: '*v*[min] = |OPR – min(*p*(*s*))|'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*v*[min] = |OPR – min(*p*(*s*))|'
- en: '*v*[max] = |OPR – max(*p*(*s*))|'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*v*[max] = |OPR – max(*p*(*s*))|'
- en: '*v*[min] and *v*[max] are the absolute values of the variance in both situations
    (not enough products to produce and too many to produce respectively).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*v*[min]和*v*[max]分别是两种情况下方差的绝对值（分别是产品不足以生产和生产过多的情况）。'
- en: 'The final representation is through a single control, detection, and learning
    rate (the Greek letter gamma):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的表示是通过一个控制、检测和学习速率来完成的（希腊字母gamma）：
- en: '![](img/B15438_10_001.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_10_001.png)'
- en: The variance between the optimal production rate of a given section of a company
    and its minimum speed (products per hour) will slow the following section down.
    If too few cakes (*v*[min]), for example, are produced, then the cake packaging
    department will be waiting and will have to stop. If too many cakes are produced
    (*v*[max]), then the section will have to slow down or stop. Both variances would
    create problems in a company that cannot manage intermediate storage easily, which
    is the case with the food processing industry.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 给定公司某一部门的最优生产速率与其最小速度（每小时产品数）之间的方差将导致下游部门的减速。例如，如果生产的蛋糕太少（*v*[min]），蛋糕包装部门将会等待并不得不停止生产。如果生产的蛋糕过多（*v*[max]），该部门将不得不减慢生产速度或停止生产。两者都会在无法轻松管理中间存储的公司中造成问题，这对于食品加工行业来说尤其如此。
- en: 'With this single ![](img/B15438_10_002.png) concept, introduced in *Chapter
    9*, *Abstract Image Classification with Convolutional Neural Networks (CNNs)*,
    the TensorFlow 2.x CNN can start learning a fundamental production concept: what
    a physical gap is. Let''s go back to humans. Once we understand that a gap is
    some kind of hole or empty space, we can identify and represent thousands of situations
    with that one gap concept that is here converted into a parameter named gamma
    (![](img/B15438_10_003.png)). Let''s explore the concept and then implement it.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这一单一的![](img/B15438_10_002.png)概念，正如在*第9章*中介绍的*卷积神经网络（CNN）在图像分类中的应用*，TensorFlow
    2.x CNN可以开始学习一个基本的生产概念：什么是物理差距。让我们回到人类身上。一旦我们理解了“差距”是某种洞或空白空间，我们就能通过这个差距概念识别并表示数千种情况，这里我们把它转换成一个名为gamma的参数（![](img/B15438_10_003.png)）。让我们先探索这个概念，然后进行实现。
- en: The ![](img/B15438_10_004.png) gap concept
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '![](img/B15438_10_004.png)差距概念'
- en: 'Teaching the CNN the gap concept will help it extend its thinking power to
    many fields:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 教授CNN差距概念将有助于它将思维能力扩展到许多领域：
- en: A gap in production, as explained before
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如前所述的生产中的空隙
- en: A gap in a traffic lane for a self-driving vehicle to move into
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自驾车可进入的车道上的空隙
- en: Any incomplete, deficient area
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何不完整或有缺陷的区域
- en: Any opening or window
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何开启或窗口
- en: Let's teach a CNN the ![](img/B15438_10_005.png) gap concept, or simply, ![](img/B15438_10_006.png).
    The symbol ![](img/B15438_10_007.png) of a gap is the Greek letter "gamma," so
    it is simply pronounced "gamma." We thus lead to teaching a CNN how to recognize
    a gap we will call gamma (![](img/B15438_10_005.png)). The goal is for a CNN to
    understand the abstract concept of an empty space, a hole represented by the word
    *gap* and the Greek letter gamma (![](img/B15438_10_005.png)).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们教给CNN![](img/B15438_10_005.png)差距概念，或者简单来说，![](img/B15438_10_006.png)。差距的符号![](img/B15438_10_007.png)是希腊字母“gamma”，所以它简单地发音为“gamma”。因此，我们引导CNN学习如何识别一个我们称之为gamma的差距（![](img/B15438_10_005.png)）。目标是让CNN理解抽象概念——一个空白空间或洞，表示为*gap*（差距）和希腊字母gamma（![](img/B15438_10_005.png)）。
- en: To achieve that goal, the CNN model that was trained and saved in *Chapter 9*,
    *Abstract Image Classification with Convolutional Neural Networks (CNNs)*, now
    needs to be loaded and used. To grasp the implications of the ![](img/B15438_10_010.png)
    concept, imagine the cost of not producing enough customer orders or having piles
    of unfinished products everywhere. The financial transposition of the physical
    gap is a profit **variance** on set goals. We all know the pain those variances
    lead to.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这个目标，*第9章*中训练并保存的CNN模型——*卷积神经网络（CNN）在图像分类中的应用*——现在需要被加载并使用。为了理解![](img/B15438_10_010.png)概念的含义，可以想象一下，如果没有足够的客户订单，或者到处堆满了未完成的产品，所带来的成本。物理差距的财务转化表现为设定目标上的利润**差异**。我们都知道，这些差异会带来多么大的痛苦。
- en: Loading the trained TensorFlow 2.x model
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载训练好的TensorFlow 2.x模型
- en: The technical goal is to load and use the trained CNN model and then use the
    same model for other similar areas. The practical goal is to teach the CNN how
    to use the ![](img/B15438_10_011.png) **concept** to enhance the thinking abilities
    of the scheduling, chatbot, and other applications.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 技术目标是加载并使用训练好的CNN模型，然后将相同的模型应用于其他类似的领域。实践目标是教会CNN如何使用![](img/B15438_10_011.png)
    **概念**来增强调度、聊天机器人及其他应用程序的思维能力。
- en: 'Loading the model has two main functions:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 加载模型有两个主要功能：
- en: Loading the model to compile and classify new images without training the model
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载模型以编译并分类新的图像，而不进行模型训练
- en: Displaying the parameters used layer by layer and displaying the weights reached
    during the learning and training phase
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层层显示所用的参数，并展示在学习和训练阶段达到的权重
- en: In the following section, we will load and display the model without training
    it.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将加载并显示模型，而不进行训练。
- en: Loading and displaying the model
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载并显示模型
- en: 'A limited number of headers suffice to read a saved model with `READ_MODEL.py`,
    as implemented in the following lines:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`READ_MODEL.py`读取保存的模型时，只需要有限数量的头文件，如下所示：
- en: '[PRE0]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `model3.h5` model saved is now loaded from its file, as shown here:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在从文件中加载已保存的`model3.h5`模型，如下所示：
- en: '[PRE1]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The loaded model needs to be compiled:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 加载的模型需要进行编译：
- en: '[PRE2]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Reading and displaying the model is not a formality.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 读取并显示模型并非一项形式主义操作。
- en: 'Printing the structure provides useful information:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 打印结构提供了有用的信息：
- en: '[PRE3]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The trained model might or might not work on all datasets. In that case, the
    following output would point to problems that can be fixed through its structure,
    for example, as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后的模型可能在所有数据集上都能或不能正常工作。在这种情况下，以下输出将指示可以通过其结构修复的问题，例如如下所示：
- en: '[PRE4]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once the global structure has been displayed, it is possible to look into the
    structure of each layer. For example, we can peek into the `conv2d` layer:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦展示了全局结构，就可以查看每一层的结构。例如，我们可以查看`conv2d`层：
- en: '[PRE5]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Each parameter contains very useful information. For example, `''padding'':''valid''`
    means that padding has not been applied. In this model, the number and size of
    the kernels provide satisfactory results without padding, and the shape decreases
    to the final status layer (classification), as shown here:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 每个参数都包含非常有用的信息。例如，`'padding':'valid'`表示未应用填充。在此模型中，卷积核的数量和大小在没有填充的情况下提供了令人满意的结果，形状逐渐减小直到最终的状态层（分类），如下所示：
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: However, suppose you want to control the output shape of a layer so that the
    spatial dimensions do not decrease faster than necessary. One reason could be
    that the next layer will explore the edges of the image and that we need to explore
    them with kernels that fit the shape.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，假设你想控制某一层的输出形状，以便空间维度不会比必要的更快地减小。一个原因可能是下一层将探索图像的边缘，我们需要使用适合形状的卷积核来进行探索。
- en: 'In that case, padding of size 1 can be added with `0` values, as shown in the
    following matrix:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，可以通过`0`值添加大小为1的填充，如以下矩阵所示：
- en: '| 0 | 0 | 0 | 0 | 0 | 0 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 0 | 0 | 0 | 0 |'
- en: '| 0 | **1** | **3** | **24** | **4** | 0 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 0 | **1** | **3** | **24** | **4** | 0 |'
- en: '| 0 | **3** | **7** | **8** | **5** | 0 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 0 | **3** | **7** | **8** | **5** | 0 |'
- en: '| 0 | **6** | **4** | **5** | **4** | 0 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 0 | **6** | **4** | **5** | **4** | 0 |'
- en: '| 0 | **5** | **4** | **3** | **1** | 0 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 0 | **5** | **4** | **3** | **1** | 0 |'
- en: '| 0 | 0 | 0 | 0 | 0 | 0 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0 | 0 | 0 | 0 | 0 |'
- en: A padding of size 2 would add two rows and columns around the initial shape.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 大小为2的填充会在初始形状的周围添加两行和两列。
- en: 'With that in mind, fine-tuning your training model by adding as many options
    as necessary will improve the quality of the results. The weights can be viewed
    by extracting them from the saved model file layer by layer, as shown in the following
    code snippet:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，通过添加尽可能多的选项来微调训练模型，将提高结果的质量。可以通过逐层提取已保存模型文件中的权重来查看权重，如以下代码片段所示：
- en: '[PRE7]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Analyzing the weights used by the program will provide useful information about
    the way the optimization process was carried out by the program. Sometimes, a
    program will get stuck, and the weights might seem off track. After all, a CNN
    can contain imperfections like any other program.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 分析程序使用的权重将提供有关优化过程如何进行的有用信息。有时，程序可能会卡住，权重看起来可能不太对劲。毕竟，CNN和其他程序一样，可能包含一些不完美的地方。
- en: 'A look at the following output, for example, can help understand where the
    system went wrong:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下输出，例如，可以帮助理解系统出错的地方：
- en: '[PRE8]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We can now use the loaded and checked model.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用已加载并检查过的模型。
- en: Loading the model to use it
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载模型以便使用
- en: 'Loading the model with `CNN_CONCEPT_STRATEGY.py` requires a limited number
    of headers, as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`CNN_CONCEPT_STRATEGY.py`加载模型需要有限数量的头文件，如下所示：
- en: '[PRE9]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Loading the model is done by using the same code as in `READ_MODEL.py`, described
    previously. Once you load it, compile the model with the `model.compile` function,
    as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 加载模型是通过使用与之前描述的`READ_MODEL.py`相同的代码完成的。一旦加载模型，使用`model.compile`函数编译模型，如下所示：
- en: '[PRE10]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The model used for this example and the image identification function has been
    implemented in two parts. First, we''re loading and resizing the image with the
    following function, for example:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 用于此示例的模型和图像识别功能已分为两部分实现。首先，我们使用以下函数加载和调整图像的大小，例如：
- en: '[PRE11]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The model expects another dimension in the input array to predict, so one is
    added to fit the model. In this example, one image at a time needs to be identified.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 模型期望输入数组中有一个额外的维度来进行预测，因此需要添加一个维度以适应模型。在此示例中，需要一次识别一张图像。
- en: 'I added the following two prediction methods and returned one:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我添加了以下两个预测方法，并返回其中一个：
- en: '[PRE12]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: There are two prediction methods because, basically, every component needs to
    be checked in a CNN during a project's implementation phase, to choose the best
    and fastest ones. To test `prediction2`, just change the `return` instruction.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种预测方法，因为基本上，在项目实施阶段，CNN中的每个组件都需要进行检查，以选择最佳和最快的组件。要测试`prediction2`，只需更改`return`指令。
- en: Once a CNN is running, it can prove difficult to find out what went wrong. Checking
    the output of each layer and component while building the network saves fine-tuning
    time once the full-blown model produces thousands of results.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦CNN开始运行，可能会很难发现问题所在。在构建网络时检查每一层和组件的输出，可以在完整模型生成成千上万的结果后节省微调时间。
- en: 'The following example detects product ![](img/B15438_10_012.png) **gaps** on
    a conveyor belt in a food processing factory. The program loads the first image
    stored in the `classify` directory to predict its value. The program describes
    the prediction:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例检测了食品加工厂中传送带上的产品 ![](img/B15438_10_012.png) **空隙**。该程序加载存储在`classify`目录中的第一张图像并预测其值。程序描述了预测结果：
- en: '[PRE13]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The program displays (optional) the shaped image, as follows, which shows that
    the conveyor belt has a sufficient number of products at that point:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序显示（可选）如下所示的形状图像，表示传送带在该点上有足够数量的产品：
- en: '![](img/B15438_10_01.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_10_01.png)'
- en: 'Figure 10.1: Output (shaped image)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1：输出（形状图像）
- en: 'The program then makes and displays its prediction `0`, meaning no real gap
    has been found on the conveyor belt on this production line:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 程序随后做出并显示预测`0`，这意味着在该生产线的传送带上没有发现实际的空隙：
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '`Seeking...` means it is going to analyze the second image in the classify
    direction. It loads, displays, and predicts its value as shown in the following
    frame:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`Seeking...`表示程序将在分类方向分析第二张图像。它加载、显示并预测其值，如下所示：'
- en: '![](img/B15438_10_02.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_10_02.png)'
- en: 'Figure 10.2: Output (shaped image)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2：输出（形状图像）
- en: 'The prediction (*value* = 1) correctly detected gaps on the conveyor belt,
    as shown in the following output:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 预测（*值* = 1）正确检测到了传送带上的空隙，如下所示的输出：
- en: '[PRE15]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now that the predictions of the CNN have been verified, the implementation strategy
    needs approval. A CNN contains marvels of applied mathematics. CNNs epitomize
    deep learning themselves. A researcher could easily spend hundreds of hours studying
    them.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，CNN的预测结果已被验证，实施策略需要获得批准。CNN包含了应用数学的奇迹。CNN本身就是深度学习的代表。研究人员可能会花费数百小时研究它们。
- en: However, applied mathematics in the business world requires profitability. As
    such, the components of CNNs appear to be ever-evolving concepts. Added kernels,
    activation functions, pooling, flattening, dense layers, and compiling and training
    methods act as a starting point for architectures, not as a finality.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，商业世界中的应用数学需要考虑盈利。因此，CNN的各个组件似乎是不断发展的概念。添加的卷积核、激活函数、池化、扁平化、全连接层以及编译和训练方法，作为架构的起点，而非最终结果。
- en: Using transfer learning to be profitable or see a project stopped
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用迁移学习实现盈利或看到一个项目被停止
- en: At some point, a company will demand results and may shelve a project if those
    results are not delivered. If a spreadsheet represents a faster sufficient solution,
    a deep learning project will face potential competition and rejection. Many engineers
    learning artificial intelligence have to assume the role of standard SQL reporting
    experts before accessing real AI projects. Transfer learning is a profitable solution
    that can boost the credibility of an IT department.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些时刻，公司将要求成果，并可能在未能交付这些成果时搁置项目。如果电子表格能够提供更快速且足够的解决方案，深度学习项目将面临潜在的竞争和拒绝。许多学习人工智能的工程师在接触真正的AI项目之前，必须先担任标准SQL报告专家的角色。迁移学习是一个有利可图的解决方案，可以提高IT部门的可信度。
- en: Transfer learning appears to be a solution to the present cost of building and
    training a CNN program. Your model might just pay off that way. The idea is to
    get a basic AI model rolling profits in fast for your customer and management.
    Then, you will have everybody's attention. To do that, you must define a strategy.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习似乎是目前构建和训练CNN程序的成本问题的解决方案。你的模型可能通过这种方式带来回报。其思想是让一个基础的AI模型为你的客户和管理层快速带来利润。然后，你将获得大家的关注。为此，你必须定义一个策略。
- en: Defining a strategy
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义策略
- en: If a deep learning CNN expert comes to a top manager saying that this CNN model
    can classify CIFAR-10 images of dogs, cats, cars, plants, and more, the answer
    will be, *so what? My 3-year-old child can too. In fact, so can my dog!*
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一位深度学习CNN专家对高级经理说这个CNN模型可以分类CIFAR-10图像中的狗、猫、汽车、植物等，那么答案可能是，*那又怎样？我的三岁孩子也能做到。事实上，我的狗也能！*
- en: The IT manager in that meeting might even blurt out something like, "We have
    all the decision tools we need right now, and our profits are increasing. Why
    would we invest in a CNN?"
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 会议中的IT经理甚至可能脱口而出，“我们现在已经拥有所有决策工具了，而且我们的利润在增长。为什么还要投资CNN？”
- en: The core problem of marketing AI to real-world companies is that it relies upon
    a belief in the necessity of a CNN in the first place. Spreadsheets, SQL queries,
    standard automation, and software do 99% of the job. Most of the time, it does
    not take a CNN to replace many jobs; just an automated spreadsheet, a query, or
    standard, straightforward software is enough. Jobs have been sliced into simple-enough
    parts to replace humans with basic software for decades.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 向现实世界公司营销AI的核心问题在于，它首先依赖于对CNN必要性的信仰。电子表格、SQL查询、标准自动化和软件完成了99%的工作。大多数时候，许多工作并不需要CNN来替代；仅仅是自动化的电子表格、查询或标准的软件就足够了。几十年来，工作已经被分解成足够简单的部分，可以用基础软件取代人类。
- en: Before presenting a CNN, a data scientist has to find out how much the company
    can earn using it.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在展示CNN之前，数据科学家必须先了解公司通过使用CNN能够赚取多少利润。
- en: Understanding, designing, building, and running a CNN does not mean much regarding
    business. All the hard work we put into understanding and running these complex
    programs will add up to nothing if we cannot prove that a solution will generate
    profit. Without profit, the implementation costs cannot be recovered, and nobody
    will listen to a presentation about even a fantastic program.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 理解、设计、构建和运行CNN（卷积神经网络）与业务并没有太大关系。我们在理解和运行这些复杂程序上投入的所有努力，如果不能证明解决方案能产生利润，最终将毫无意义。没有利润，实施成本无法回收，没人会听一个关于即使是非常优秀的程序的演示。
- en: Applying a model efficiently means implementing it in one area of a company
    and then other domains for a good return on investment.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 高效应用模型意味着先在公司一个领域实施，然后再扩展到其他领域，以实现良好的投资回报。
- en: Applying the model
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 应用模型
- en: 'In a food processing company, for example, one of the packaging lines has a
    performance problem. Sometimes, randomly, some of the cakes are missing on the
    conveyor belt, as shown in the following frame:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 以食品加工公司为例，其中一个包装生产线存在性能问题。有时，随机地，传送带上会缺少一些蛋糕，如下图所示：
- en: '![](img/B15438_10_03.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_10_03.png)'
- en: 'Figure 10.3: Food processing company example'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3：食品加工公司示例
- en: To start a cost-effective project, a cheap webcam could be installed over the
    conveyor belt. It'll take a random sample picture every 10 seconds and process
    it to find the holes shown in the interval in the center of the image. We can
    clearly see an empty space, a gap, a hole. If a hole is detected, it means some
    cakes have not made it to the conveyor belt (production errors).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启动一个具有成本效益的项目，可以在传送带上方安装一个便宜的网络摄像头。它每10秒钟拍摄一张随机样本图片，并处理它，以找出图像中央区域内的空隙。我们可以清楚地看到一个空白、缝隙或洞。如果检测到孔洞，意味着有些蛋糕未能成功进入传送带（生产错误）。
- en: A 2% to 5% productivity rate increase could be obtained by automatically sending
    a signal to the production robot when some cakes are missing. The production robot
    will then send a signal to the production line to increase production to compensate
    for the missing units in real-time. This type of automatic control already exists
    in various forms of automated food production lines. However, this provides a
    low-cost way to start implementing this on a production line.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在某些蛋糕缺失时自动向生产机器人发送信号，可以提高2%到5%的生产率。生产机器人随后会向生产线发送信号，实时增加生产以弥补缺失的单位。这种类型的自动控制在各种自动化食品生产线上已有应用。然而，这为在生产线实施这一方法提供了一个低成本的起点。
- en: Making the model profitable by using it for another problem
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过将模型用于其他问题来实现盈利
- en: Let's say that the food processing experiment on the conveyor belt turns out
    to work well enough with dataset type *d*[1] and the CNN model *M* to encourage
    generalization to another dataset, *d*[2], in the same company.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 假设食品加工实验在传送带上使用数据集类型*d*[1]和CNN模型*M*运作良好，这足以鼓励在同一公司中将其推广到另一个数据集*d*[2]。
- en: 'Transfer learning consists of going from *M*(*d*[1]) to *M*(*d*[2]) using the
    same CNN model *M*, with some limited, cost-effective additional training. Variations
    will appear, but they can be solved by shifting a few parameters and working on
    the input data following some basic dataset preparation rules:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是指通过有限且具有成本效益的附加训练，从*M*(*d*[1])到*M*(*d*[2])，使用相同的CNN模型*M*。虽然会出现一些变化，但可以通过调整几个参数并根据一些基本的数据集准备规则处理输入数据来解决：
- en: '**Overfitting**: When the model fits the training data quickly with 100% accuracy,
    this may or may not be a problem. In the case of classifying holes on the conveyor
    belt, overfitting might not prove critical. The shapes are always the same, and
    the environment remains stable. However, in an unstable situation with all sorts
    of different images or products, then overfitting will limit the effectiveness
    of a system.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过拟合**：当模型迅速适应训练数据，并且准确率达到100%时，这可能是问题也可能不是问题。在传送带上分类孔的情况下，过拟合可能不会造成严重影响。形状总是相同的，环境保持稳定。然而，在不稳定的情况下，面对各种不同的图像或产品，过拟合会限制系统的有效性。'
- en: '**Underfitting**: If the accuracy drops down to low levels, such as 20%, then
    the CNN will not work. The datasets and parameters need optimizing. Maybe the
    number of samples needs to be increased for *M*(*d*[2]), or reduced, or split
    into different groups.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欠拟合**：如果准确率降到较低的水平，例如20%，那么CNN将无法工作。数据集和参数需要优化。也许需要增加*M*(*d*[2])的样本数量，或减少，或者将其分成不同的组。'
- en: '**Regularization**: Regularization, in general, involves the process of finding
    how to fix the generalization problem of *M*(*d*[2]), not the training errors
    of *M*(*d*[2]). Maybe an activation function needs some improvements, or the way
    the weights have been implemented requires attention.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正则化**：正则化通常涉及到解决*M*(*d*[2])的泛化问题，而不是*M*(*d*[2])的训练误差。可能需要改进激活函数，或者实现权重的方式需要关注。'
- en: There is no limit to the number of methods you can apply to find a solution,
    just like standard software program improvements.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以应用任意数量的方法来找到解决方案，就像标准软件程序的改进一样。
- en: Where transfer learning ends and domain learning begins
  id: totrans-149
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 迁移学习的结束和领域学习的开始
- en: Transfer learning can be used for similar types of objects or images in this
    example, as explained. The more similar images you can train within a company
    with the same model, the more return on investment (ROI) it will produce, and
    the more this company will ask you for more AI innovations.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习可以用于此示例中的类似类型的物体或图像，如上所述。在同一公司内，使用相同模型训练越多相似的图像，将产生越高的投资回报率（ROI），并且这家公司会要求你提供更多的AI创新。
- en: Domain learning takes a model such as the one described in *Chapter 9*, *Abstract
    Image Classification with Convolutional Neural Networks (CNNs)*, and can generalize
    it. The generalization process will lead us to domain learning.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 领域学习以*第9章*中描述的模型为基础，*卷积神经网络（CNNs）在抽象图像分类中的应用*，并能够对其进行泛化。泛化过程将引领我们进入领域学习。
- en: Domain learning
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 领域学习
- en: 'This section on domain learning builds a bridge between classic transfer learning,
    as described previously, and another use of domain learning I have found profitable
    on corporate projects: teaching a machine a concept (CRLMM). In this chapter,
    we are focusing on teaching a machine to learn how to recognize a gap in situations
    other than at the food processing company.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 本节关于领域学习的内容架起了经典迁移学习（如前所述）与我在企业项目中发现的另一种领域学习应用之间的桥梁：教机器学习一个概念（CRLMM）。本章重点讲述的是如何教机器识别除食品加工公司外的其他情况中的空缺。
- en: How to use the programs
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用这些程序
- en: You can read this whole chapter first to grasp the concepts or play with the
    programs first. Do as you feel is best for you. In any case, `CNN_TDC_STRATEGY.py`
    loads trained models (you do not have to train them again for this chapter) and
    `CNN_CONCEPT_STRATEGY.py` trains the models.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以先阅读本章内容以理解概念，或先尝试运行程序。按你觉得最适合的方式进行。无论如何，`CNN_TDC_STRATEGY.py`加载训练好的模型（你无需在本章中重新训练），而`CNN_CONCEPT_STRATEGY.py`则用于训练模型。
- en: The trained models used in this section
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本节中使用的训练好的模型
- en: 'This section uses `CNN_TDC_STRATEGY.py` to apply the trained models to the
    target concept images. `READ_MODEL.py` (as shown previously) was converted into
    `CNN_TDC_STRATEGY.py` by adding variable directory paths (for the `model3.h5`
    files and images) and classification messages, as shown in the following code:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 本节使用`CNN_TDC_STRATEGY.py`将训练好的模型应用于目标概念图像。`READ_MODEL.py`（如前所示）通过添加变量目录路径（用于`model3.h5`文件和图像）以及分类消息，已转换为`CNN_TDC_STRATEGY.py`，如下所示的代码：
- en: '[PRE16]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The loaded model now targets the images to classify:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 加载的模型现在针对待分类的图像：
- en: '[PRE17]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Each subdirectory of the model contains four subdirectories:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的每个子目录包含四个子目录：
- en: '`classify`: Contains the images to classify'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`classify`: 包含待分类的图像'
- en: '`model`: The trained `model3.h5` used to classify the images'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`: 用于分类图像的训练好的`model3.h5`模型'
- en: '`test_set`: The test set of conceptual images'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test_set`: 概念图像的测试集'
- en: '`training_set`: The training set of conceptual images'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`training_set`：概念图像的训练集'
- en: Now that we have explored the directory structure of our model, let's see how
    to use it in different situations.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了模型的目录结构，接下来让我们看看如何在不同情况下使用它。
- en: The trained model program
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练后的模型程序
- en: 'For this chapter, you do not need to train a model. It was already trained
    in *Chapter 9*, *Abstract Image Classification with Convolutional Neural Networks
    (CNNs)*. The directory paths have become variables to access the subdirectories
    described previously. The paths can be called, as shown in the following code:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，你不需要训练模型。它已经在*第九章*《使用卷积神经网络（CNN）进行抽象图像分类》中训练好。目录路径已经变成了变量，可以访问之前描述的子目录。路径可以像下面的代码那样调用：
- en: '[PRE18]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You do not need to run training for this chapter. The models were trained and
    automatically stored in their respective subdirectories on the virtual machine
    delivered with the book. This means that when you need to detect gaps for various
    types of images, you can simply change the scenario to fit the type of images
    you will be receiving from the frames of a webcam: cakes, cars, fabric, or abstract
    symbols.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你无需为本章运行训练。模型已经在*第九章*《使用卷积神经网络（CNN）进行抽象图像分类》中训练好，并自动存储在书中提供的虚拟机的各自子目录中。这意味着当你需要检测各种类型图像的空隙时，你只需更改场景以适应你将从摄像头帧接收的图像类型：蛋糕、汽车、面料或抽象符号。
- en: For this chapter, focus on understanding the concepts. You can read the chapter
    without running the programs, open them without running them, or run them—whatever
    makes you comfortable. The main goal is to grasp the concepts to prepare for the
    subsequent chapters.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的重点是理解概念。你可以在不运行程序的情况下阅读本章，或者可以打开程序而不运行它们，或者运行它们——只要你觉得舒服。主要目标是掌握这些概念，为后续章节做准备。
- en: We have loaded the model and a scenario. Now, we are going to use our trained
    model to detect if a production line is loaded or underloaded.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经加载了模型和场景。接下来，我们将使用训练好的模型来检测生产线是加载还是未加载。
- en: Gap – loaded or underloaded
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 空隙 – 已加载或未加载
- en: The gap concept has just become a polysemy image-concept (polysemy means different
    meanings, as explained in *Chapter 6*, *Innovating AI with Google Translate*).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 空隙概念刚刚变成了一个多义性图像概念（多义性意味着不同的含义，如*第六章*《使用谷歌翻译创新 AI》所解释的那样）。
- en: 'In the cake situation, the ![](img/B15438_10_013.png) gap was negative in its
    *g*[1] subset of meaning and concepts applied to a CNN, relating it to negative
    images *n* + *g*[1]:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在蛋糕的情况下，![](img/B15438_10_013.png) 空隙在其 *g*[1] 子集的意义和概念中是负面的，并且应用于卷积神经网络（CNN），将其与负面图像
    *n* + *g*[1] 联系起来：
- en: '*ng*[1] = {missing, not enough, slowing production down … bad}'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '*ng*[1] = {缺失、不足、降低生产效率...不好}'
- en: 'The full-of-products image was positive, *p* + *g*[2]:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 充满产品的图像是正面的，*p* + *g*[2]：
- en: '*pg*[2] = {good production flow, no gap}'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '*pg*[2] = {良好的生产流，无空隙}'
- en: In this example, the CNN is learning how to distinguish an abstract representation,
    not simply an image, like for the cakes. Another subset of ![](img/B15438_10_010.png)
    (the conceptual gap dataset) is loaded/underloaded. A "gap" is not a specific
    object but a general concept that can be applied to hundreds of different cases.
    This is why I use the term "conceptual gap dataset."
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，CNN 学会了如何区分抽象表示，而不仅仅是像蛋糕那样的图像。另一个 ![](img/B15438_10_010.png)（概念空隙数据集）子集是已加载/未加载的。“空隙”不是一个特定的对象，而是一个可以应用于数百种不同情况的普遍概念。这就是我使用“概念空隙数据集”一词的原因。
- en: The following abstract image is loaded. The squares represent production machines,
    and the arrows represent the load-in time.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是已加载的抽象图像。方框代表生产机器，箭头表示加载时间。
- en: 'This means that the *x* axis represents time and the *y* axis represents machine
    production resources:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着 *x* 轴代表时间，*y* 轴代表机器生产资源：
- en: '![](img/B15438_10_04.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_10_04.png)'
- en: 'Figure 10.4: Abstract image 1'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4：抽象图像 1
- en: 'The CNN model runs and produces the following result:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 模型运行并产生以下结果：
- en: '[PRE19]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The CNN recognizes this as a correctly loaded model. The task goes beyond classifying.
    The system needs to recognize this to make a decision.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 将其识别为正确加载的模型。任务超出了简单的分类。系统需要识别它以做出决策。
- en: 'Another image produces a different result. In this case, an underloaded gap
    appears in the following screenshot:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 另一张图像产生了不同的结果。在这种情况下，以下截图中出现了一个负载不足的空隙：
- en: '![](img/B15438_10_05.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_10_05.png)'
- en: 'Figure 10.5: Abstract image 2'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5：抽象图像 2
- en: 'And the CNN has a different output, as shown here:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 并且 CNN 输出不同的结果，如下所示：
- en: '[PRE20]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Read "unloaded" as "underloaded." Unloaded or underloaded represents empty
    spaces in any case. The gap concept ![](img/B15438_10_015.png) has added two other
    subsets, *g*[3] and *g*[4], to its dataset. We now have:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 将“未装载”视为“欠载”。无论如何，未装载或欠载代表空的空间。空隙概念![](img/B15438_10_015.png)已将*g*[3]和*g*[4]添加到其数据集中。现在我们有：
- en: '![](img/B15438_10_016.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_10_016.png)'
- en: 'The four *g*[1] to *g*[4] subsets of ![](img/B15438_10_005.png) are:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B15438_10_005.png)中的四个*g*[1]到*g*[4]子集是：'
- en: '*ng*[1] = {missing, not enough, slowing production down … bad}'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '*ng*[1] = {缺失、不足、生产缓慢……不好}'
- en: '*pg*[2] = *pg*[2] = {good production flow, no gap}'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '*pg*[2] = *pg*[2] = {良好的生产流动，无空隙}'
- en: '*g*[3] = {loaded}'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '*g*[3] = {已装载}'
- en: '*g*[4] = {unloaded}'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '*g*[4] = {未装载}'
- en: The remaining problem will take some time to solve. *g*[4] (gap) can sometimes
    represent an opportunity for a machine that does not have a good workload to be open
    to more production. In some cases, *g*[4] becomes *pg*[4] (*p* = positive). In
    other cases, it will become *ng*[4] (*n* = negative) if production rates go down.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的问题将需要一些时间才能解决。*g*[4]（空隙）有时可以代表一个机器的机会，尤其是当它的工作负载不佳时，可能会有更多生产空间。在某些情况下，*g*[4]会变成*pg*[4]（*p*
    = 正面）。在其他情况下，如果生产速度下降，它将变成*ng*[4]（*n* = 负面）。
- en: In this section, we saw how to identify a "gap" in production lines. As explained,
    a "gap" is a generic concept for spaces everywhere. We will now explore jammed
    or "open" traffic lanes.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解了如何识别生产线中的“空隙”。如前所述，“空隙”是一个通用概念，指的是任何地方的空白区域。接下来，我们将探索堵塞或“畅通”交通车道。
- en: Gap – jammed or open lanes
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 空隙 – 堵塞或畅通车道
- en: The model in this chapter can be extended to other domains. A self-driving car
    needs to recognize whether it is in a traffic jam or not. Also, a self-driving
    car has to know how to change lanes when it detects enough space (a gap) to do
    that.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的模型可以扩展到其他领域。自动驾驶汽车需要识别自己是否处于交通堵塞中。此外，自动驾驶汽车还必须知道在检测到足够空间（空隙）时，如何变换车道。
- en: 'This produces two new subsets:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成两个新的子集：
- en: '*g*[5] = {traffic jam, heavy traffic … too much traffic}'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '*g*[5] = {交通堵塞、交通繁忙……交通过多}'
- en: '*g*[6] = {open lane, light traffic … normal traffic}'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '*g*[6] = {畅通车道、交通轻微……正常交通}'
- en: 'The model now detects *g*[5] (a traffic jam), as shown in the following screenshot:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型现在能够检测到*g*[5]（交通堵塞），如下图所示：
- en: '![](img/B15438_10_06.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_10_06.png)'
- en: 'Figure 10.6: Traffic jam example'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6：交通堵塞示例
- en: 'The following output appears correctly:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示正确：
- en: '[PRE21]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '*g*[6] comes out right as well, as shown in this screenshot:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '*g*[6]也显示正确，如下图所示：'
- en: '![](img/B15438_10_07.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_10_07.png)'
- en: 'Figure 10.7: Traffic jam example'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7：交通堵塞示例
- en: 'A potential lane change has become possible, as detected by the following code:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在的车道变换已经变得可能，如下代码所示：
- en: '[PRE22]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We have applied our CNN "gap" detection model to several types of images. We
    can now go deeper into the theory of conceptual datasets using "gaps" as an example.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将CNN“空隙”检测模型应用于几种类型的图像。现在，我们可以更深入地探讨使用“空隙”作为示例的概念数据集理论。
- en: Gap datasets and subsets
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 空隙数据集和子集
- en: 'At this point, the ![](img/B15438_10_005.png) (the gap conceptual dataset)
    has begun to learn several subsets:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，![](img/B15438_10_005.png)（空隙概念数据集）已经开始学习多个子集：
- en: '![](img/B15438_10_019.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_10_019.png)'
- en: 'In which:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在其中：
- en: '*ng*[1] = {missing, not enough, slowing production down … bad}'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '*ng*[1] = {缺失、不足、生产缓慢……不好}'
- en: '*pg*[2] = *pg*[2] = {good production flow, no gap}'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '*pg*[2] = *pg*[2] = {良好的生产流动，无空隙}'
- en: '*g*[2] = {loaded}'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '*g*[2] = {已装载}'
- en: '*g*[3] = {unloaded}'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '*g*[3] = {未装载}'
- en: '*pg*[4] = {traffic jam, heavy traffic … too much traffic}'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '*pg*[4] = {交通堵塞、交通繁忙……交通过多}'
- en: '*ng*[5] = {open lane, light traffic … normal traffic}'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '*ng*[5] = {畅通车道、交通轻微……正常交通}'
- en: Notice that *g*[2] and *g*[3] do not have labels yet. The food processing context
    provided the labels. Concept detection requires a context, which CRLMMs will provide.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，*g*[2]和*g*[3]尚未有标签。食品加工上下文提供了这些标签。概念检测需要一个上下文，CRLMM将提供这一点。
- en: Generalizing the ![](img/B15438_10_020.png) (the gap conceptual dataset)
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一般化![](img/B15438_10_020.png)（空隙概念数据集）
- en: The generalization of ![](img/B15438_10_015.png) (the gap conceptual dataset)
    will provide a conceptual tool for metamodels.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B15438_10_015.png)（空隙概念数据集）的一般化将为元模型提供一个概念工具。'
- en: '![](img/B15438_10_022.png) (the gap conceptual dataset) refers to negative,
    positive, or undetermined space between two elements (objects, locations, or products
    on a production line).'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B15438_10_022.png)（空隙概念数据集）指的是两元素（对象、位置或生产线上的产品）之间的负面、正面或未确定空间。'
- en: '![](img/B15438_10_023.png) (gamma) also refers to a gap in time: too long,
    not long enough, too short, or not short enough.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B15438_10_023.png)（gamma）也指时间中的空隙：过长、不过长、过短或不够短。'
- en: '![](img/B15438_10_023.png) represents the distance between two locations: too
    far or too close.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B15438_10_023.png)代表两个位置之间的距离：过远或过近。'
- en: '![](img/B15438_10_025.png) can represent a misunderstanding or an understanding
    between two parties: a divergence of opinions or a convergence.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B15438_10_025.png)可以表示两方之间的误解或理解：意见的分歧或趋同。'
- en: All of these examples refer to gaps in space and time viewed as space.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些示例都指的是将空间和时间视为空间的空隙。
- en: The motivation of conceptual representation learning metamodels applied to dimensionality
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用于维度的概念表示学习元模型的动机
- en: A CRLMM converts images into concepts. These abstract concepts will then be
    embedded in vectors that become logits for a softmax function, and in turn, will
    be converted into parameters for complex artificial intelligence programs' automatic
    scheduling, cognitive chatbots, and more.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: CRLMM将图像转换为概念。这些抽象概念随后会嵌入到向量中，成为softmax函数的logits，进而转化为复杂人工智能程序的自动调度、认知聊天机器人等的参数。
- en: The advantage of a concept is that it can apply to many different areas. With
    just one concept, "gap" (a hole, empty space, and so on), you can describe hundreds
    if not thousands of cases.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 概念的优势在于它可以应用于许多不同的领域。仅凭一个概念，“空隙”（一个洞，空白空间，等等），你就可以描述成百上千的情况。
- en: In some artificial intelligence projects, dimensionality reduction does not
    produce good results at all. When scheduling maintenance of airplanes, rockets,
    and satellite launchers, for example, thousands of features enter the system without
    leaving any out. A single missing screw in a rocket in the wrong place could cause
    a disaster. A single mistake in the engine of an airplane can cause an accident,
    a single component of a satellite can impair its precision.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些人工智能项目中，降维根本无法产生良好的结果。例如，在飞机、火箭和卫星发射器的维修调度中，成千上万的特征进入系统，没有任何遗漏。在火箭上，某个地方一个遗漏的螺丝可能导致灾难；在飞机的引擎中，一次错误可能引发事故；卫星的单一部件故障会影响其精度。
- en: Dimensionality must be taken into account. Some use the expression "curse of
    dimensionality" and I often prefer the "blessing" of dimensionality. Let's have
    a look at both approaches.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 必须考虑维度问题。有些人使用“维度灾难”这个表达，而我更倾向于称之为“维度的祝福”。让我们来看看这两种方式。
- en: The curse of dimensionality
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 维度灾难
- en: 'The number of features for a given project can reach large numbers. The following
    example contains 1,024 dimensions:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 给定项目的特征数可能达到非常大的数量。以下示例包含1,024个维度：
- en: '![](img/B15438_10_08.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_10_08.png)'
- en: 'Figure 10.8: The curse of dimensionality'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8：维度灾难
- en: Each dot in the preceding representation represents a dimension that can be
    the features in an image for example.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 上述表示中的每个点代表一个维度，比如图像中的特征。
- en: Asking a CNN to analyze thousands of features in an image, for example, might
    make it impossible to reach an accurate result. Since each layer is supposed to
    reduce the size of the data analyzed to extract important features, too many dimensions
    might make the training of the model impossible. Remember, each dimension can
    contain a feature that requires weights to be trained. If there are too many,
    the training becomes either too long or too difficult to calculate.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，要求CNN分析图像中的成千上万个特征，可能会导致无法得到准确的结果。由于每一层本应减少分析数据的规模以提取重要特征，过多的维度可能会使模型的训练变得不可能。记住，每个维度都可以包含需要训练的特征权重。如果维度过多，训练将变得既漫长又难以计算。
- en: Following standard CNN designs provides a good starting point. The limit of
    this approach occurs when the result does not meet expectations, such as in some
    of the cases we will look at in the upcoming chapters. In those cases, CRLMMs
    will increase the productivity of the solution, providing a useful abstract model.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 遵循标准的CNN设计提供了一个良好的起点。这种方法的局限性出现在结果未达到预期时，例如在接下来的章节中我们将要探讨的一些案例中。在这些情况下，CRLMMs将提高解决方案的生产力，提供一个有用的抽象模型。
- en: When a solution requires a large number of unreduced dimensions, kernels, pooling,
    and other dimension reduction methods cannot be applied, CRLMMs will provide a
    *pair of glasses* for the system. That's when the "blessing" of dimensionality
    comes in handy.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个解决方案需要大量未减少的维度时，卷积核、池化和其他维度减少方法无法应用，CRLMM将为系统提供一副*眼镜*。这时，维度的“福音”就变得非常有用。
- en: The blessing of dimensionality
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 维度的福音
- en: In some projects, when the model reaches limits that comprise a project, dimensionality
    is a blessing.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些项目中，当模型达到项目的极限时，维度性反而是一种福音。
- en: Let's take an example of rocket manufacturing using our CNN model. We want to
    identify gaps on a surface. This surface contains tiles to protect the rocket
    from overheating when it goes through the atmosphere. A gap in those tiles could
    cause a fatal accident.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以使用我们的CNN模型制造火箭为例。我们想要识别表面上的裂缝。这些表面上有瓦片，用于保护火箭在穿越大气层时免于过热。瓦片之间的裂缝可能导致致命事故。
- en: If we take a few tiles out, take a picture and run it through our CNN model,
    it will *probably* detect a gap. The difference between that probability and an
    error could mean a critical failure of the rocket.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们取出几块瓦片，拍一张照片并通过我们的CNN模型处理，它*可能*会检测到裂缝。这个概率与错误之间的差异可能意味着火箭的严重故障。
- en: This means that we might not want to reduce the number of features, which in
    turn need weights and add up to high numbers of dimensions.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们可能不希望减少特征的数量，这样就需要权重，并增加维度的高数字。
- en: We could decide not to use pooling, which groups several dimensions into one
    as we saw. That could create calculations problems as we saw in the previous paragraph.
    Either there would be too many weights to calculate or the calculation could take
    too long.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以决定不使用池化（如我们所见，将多个维度合并为一个）。这可能会导致计算问题，正如我们在上一段所见。要么会有过多的权重需要计算，要么计算可能会花费太长时间。
- en: In that case, we could reduce the size of the frame to the smallest portion
    of the rocket component we are examining. We could decide that our camera will
    only scan the smallest surface possible at a time sending minimal-sized frames
    to our CNN.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以将框架的大小缩小到我们正在检查的火箭部件的最小部分。我们可以决定让我们的相机一次只扫描最小的表面，将最小尺寸的框架发送给我们的CNN。
- en: In that case, even with no pooling, the layers would contain more data, but
    the calculation would remain reasonable.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，即使没有池化，层中也会包含更多的数据，但计算仍然是合理的。
- en: The "blessing" of dimensionality, in this case, resides in the fact that by
    avoiding pooling (grouping), we are examining more details that can make our model
    much more reliable to detect small cracks since we would train it to see very
    small gaps.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，维度的“福音”在于，避免池化（分组）后，我们检查更多的细节，这可以使我们的模型在检测微小裂缝时更加可靠，因为我们将其训练成能够看到非常小的裂缝。
- en: The curse of dimensionality usually leads to dimensionality reduction. But as
    we have just seen, it doesn't have to be so.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 维度的诅咒通常导致维度减少。但正如我们刚才看到的，情况不一定是这样。
- en: Summary
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, the CNN architecture built in *Chapter 9*, *Abstract Image
    Classification with Convolutional Neural Networks (CNNs)*, was loaded to classify
    physical gaps in a food processing company. The model uses image concepts, taking
    CNNs to another level. Neural networks can tap into their huge cognitive potential,
    opening the doors to the future of AI.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，*第9章*中构建的CNN架构，*使用卷积神经网络（CNN）进行抽象图像分类*，被加载用于分类食品加工公司中的物理裂缝。该模型使用图像概念，将CNN推向另一个层次。神经网络可以发挥其巨大的认知潜力，开启人工智能未来的大门。
- en: Then, the trained models were applied to transfer learning by identifying similar
    types of images. Some of those images represented concepts that led the trained
    CNN to identify ![](img/B15438_10_026.png) concept gaps. Image concepts represent
    an avenue of innovative potential adding cognition to neural networks.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，训练好的模型通过识别相似类型的图像来应用迁移学习。其中一些图像代表了导致训练好的CNN识别概念差距的概念。图像概念代表了一种创新潜力的途径，将认知引入神经网络中。
- en: '![](img/B15438_10_006.png) concept gaps were applied to different fields using
    the CNN as a training and classification tool in domain learning.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B15438_10_006.png) 概念差距被应用到不同领域，使用CNN作为训练和分类工具进行领域学习。'
- en: '![](img/B15438_10_028.png) concept gaps have two main properties: negative
    n-gaps and positive p-gaps. To distinguish one from the other, a CRLMM provides
    a useful add-on. In the food processing company, installing a webcam on the right
    food processing conveyor belt provided a context for the system to decide whether
    a gap was positive or negative.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B15438_10_028.png) 概念差距有两个主要特征：负n差距和正p差距。为了区分这两者，CRLMM提供了一个有用的附加工具。在食品加工公司中，在右侧的食品加工输送带上安装网络摄像头，为系统提供了判断差距是正向还是负向的背景。'
- en: With these concepts in mind, let's build a solution for **advanced planning
    and scheduling** (**APS**) in the next chapter.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 牢记这些概念，让我们在下一章构建**高级规划与调度**（**APS**）的解决方案。
- en: Questions
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: The curse of dimensionality leads to reducing dimensions and features in machine
    learning algorithms. (Yes | No)
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 维度灾难导致在机器学习算法中减少维度和特征。（是 | 否）
- en: Transfer learning determines the profitability of a project. (Yes | No)
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迁移学习决定了一个项目的盈利能力。（是 | 否）
- en: Reading `model.h5` does not provide much information. (Yes | No)
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取`model.h5`并不会提供太多信息。（是 | 否）
- en: Numbers without meaning are enough to replace humans. (Yes | No)
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 没有意义的数字足以取代人类。（是 | 否）
- en: Chatbots prove that body language doesn't mean that much. (Yes | No)
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聊天机器人证明了肢体语言并没有那么重要。（是 | 否）
- en: Present-day ANNs provide enough theory to solve all AI requests. (Yes | No)
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目前的人工神经网络提供了足够的理论来解决所有的AI需求。（是 | 否）
- en: Chatbots can now replace humans in all situations. (Yes | No)
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 聊天机器人现在可以在所有情况下取代人类。（是 | 否）
- en: Self-driving cars have been approved and do not need conceptual training. (Yes
    | No)
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自动驾驶汽车已获得批准，不需要概念训练。（是 | 否）
- en: Industries can implement AI algorithms for all of their needs. (Yes | No)
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 各行业可以实现AI算法来满足他们的所有需求。（是 | 否）
- en: Further reading
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'More on Keras layers: [https://keras.io/layers/about-keras-layers/](https://keras.io/layers/about-keras-layers/)'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多关于Keras层的内容：[https://keras.io/layers/about-keras-layers/](https://keras.io/layers/about-keras-layers/)
- en: 'More on concept learning: [https://www.sciencedirect.com/topics/psychology/concept-learning](https://www.sciencedirect.com/topics/psychology/concept-learning)'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多关于概念学习的内容：[https://www.sciencedirect.com/topics/psychology/concept-learning](https://www.sciencedirect.com/topics/psychology/concept-learning)
- en: 'More on cognitive sciences, the brain, and the mind for conceptual models:
    [http://catalog.mit.edu/schools/science/brain-cognitive-sciences/](http://catalog.mit.edu/schools/science/brain-cognitive-sciences/),
    [https://symsys.stanford.edu/undergraduatesconcentrations/cognitive-science-cogsci-concentration](https://symsys.stanford.edu/undergraduatesconcentrations/cognitive-science-cogsci-concentration)'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多关于认知科学、大脑和思维的概念模型：[http://catalog.mit.edu/schools/science/brain-cognitive-sciences/](http://catalog.mit.edu/schools/science/brain-cognitive-sciences/),
    [https://symsys.stanford.edu/undergraduatesconcentrations/cognitive-science-cogsci-concentration](https://symsys.stanford.edu/undergraduatesconcentrations/cognitive-science-cogsci-concentration)
