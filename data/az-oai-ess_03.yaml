- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Azure OpenAI Advanced Topics
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure OpenAI 高级主题
- en: In the preceding chapters, we’ve covered the basics of **Azure OpenAI** (**AOAI**)
    service, including model deployment and various pricing structures. Now, our attention
    will turn to exploring more advanced topics within AOAI.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们已经介绍了**Azure OpenAI**（**AOAI**）服务的基础知识，包括模型部署和各种定价结构。现在，我们将转向深入探讨AOAI中的更多高级主题。
- en: 'In this chapter, we will delve into the following advanced AOAI topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨以下高级AOAI主题：
- en: AOAI model context window
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AOAI 模型上下文窗口
- en: AOAI Embedding models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AOAI 嵌入模型
- en: Azure vector databases
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure 向量数据库
- en: AOAI On Your Data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AOAI 在您的数据上
- en: AOAI multimodal model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AOAI 多模态模型
- en: AOAI function calling
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AOAI 函数调用
- en: AOAI Assistants API
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AOAI 助理 API
- en: AOAI Batch API
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AOAI 批量 API
- en: AOAI fine-tuning
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AOAI 微调
- en: AOAI model context window
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AOAI 模型上下文窗口
- en: In the world of **Large Language Models** (**LLMs**), a context window defines
    the amount of text a model can process at once, impacting how it generates and
    comprehends language. This window is measured by the number of tokens (either
    whole words or fragments), directly affecting how much information the model uses
    to predict the next token. In simple terms, it dictates how much context the model
    takes into account when forming predictions or crafting responses.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在**大型语言模型**（**LLMs**）的世界中，上下文窗口定义了模型一次可以处理的文本量，影响模型如何生成和理解语言。这个窗口通过令牌的数量来衡量（可以是完整的单词或碎片），直接影响模型用于预测下一个令牌的信息量。简单来说，它决定了模型在形成预测或生成响应时，考虑了多少上下文信息。
- en: For example, the GPT-3.5-Turbo (0125) model context has 16,385 input tokens
    and 4,096 output tokens, while the GPT-4o and GPT-4o mini models have a much larger
    number at 128,000 input tokens and 16,384 output tokens. For information about
    the context window of AOAI models, visit [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models?#gpt-4-and-gpt-4-turbo-models](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models?#gpt-4-and-gpt-4-turbo-models).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，GPT-3.5-Turbo（0125）模型的上下文具有16,385个输入令牌和4,096个输出令牌，而GPT-4o和GPT-4o mini模型的上下文则大得多，拥有128,000个输入令牌和16,384个输出令牌。有关AOAI模型上下文窗口的信息，请访问[https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models?#gpt-4-and-gpt-4-turbo-models](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models?#gpt-4-and-gpt-4-turbo-models)。
- en: 'The trend in LLMs is moving toward bigger context windows, which enable more
    detailed and coherent outputs. However, this comes at a cost: larger context windows
    require more computational power and memory. In practical terms, the context window
    defines how much of the prior conversation the model can “remember” during an
    interaction. When the conversation surpasses the context window, the model loses
    the earliest parts of the dialogue, potentially affecting its consistency in lengthy
    interactions or intricate tasks. As a result, the context window size is a crucial
    factor to consider when building applications that utilize LLMs.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的趋势正在向更大的上下文窗口发展，这使得输出更为详细和连贯。然而，这也带来了代价：更大的上下文窗口需要更多的计算能力和内存。实际上，上下文窗口定义了模型在交互过程中能够“记住”多少先前的对话内容。当对话超过上下文窗口时，模型将丢失最早的部分对话，这可能影响它在长时间交互或复杂任务中的一致性。因此，上下文窗口大小是构建使用LLM的应用程序时需要考虑的一个关键因素。
- en: While larger context windows enable LLMs to handle more data, they also come
    with substantial computational and financial costs. Processing extensive context
    lengths is extremely expensive and incredibly slow, which is only acceptable in
    limited cases. For instance, a context window of a million tokens could take nearly
    a minute to produce a single response when working with several million tokens.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然更大的上下文窗口使得LLMs能够处理更多的数据，但它们也伴随着巨大的计算和财务成本。处理大量上下文长度非常昂贵且极其缓慢，这只在有限的情况下是可以接受的。例如，当处理数百万个令牌时，百万令牌的上下文窗口可能需要近一分钟才能生成一个响应。
- en: In contrast, **Retrieval-Augmented Generation** (**RAG**) is more efficient
    because it fetches only the most relevant information for each query, reducing
    the number of tokens the model needs to process. This efficiency makes RAG a more
    cost-effective solution, particularly for applications requiring frequent or high-volume
    queries and data-intensive tasks. We’ll explain RAG in detail in a later chapter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，**检索增强生成**（**RAG**）更加高效，因为它仅获取每个查询最相关的信息，从而减少了模型需要处理的令牌数量。这种高效性使得RAG成为一种更具成本效益的解决方案，尤其适用于需要频繁查询或高频数据密集型任务的应用。我们将在后面的章节中详细解释RAG。
- en: After text is split into tokens, each token is converted into a numerical form
    called an embedding. Embeddings are dense vector representations designed to capture
    the meaning of tokens. These vectors exist in a high-dimensional space, where
    the distance and direction between vectors can represent semantic and syntactic
    relationships between the words they represent.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本被拆分为标记后，每个标记都会转换为一种称为嵌入的数字形式。嵌入是旨在捕捉标记意义的密集向量表示。这些向量存在于一个高维空间中，其中向量之间的距离和方向可以表示它们所代表的词语之间的语义和句法关系。
- en: In the next section, we’ll discuss the embedding model that AOAI uses to convert
    tokens into embedding vectors.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将讨论 AOAI 使用的嵌入模型，该模型将标记转换为嵌入向量。
- en: AOAI embedding models
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AOAI 嵌入模型
- en: 'AOAI has four different embedding models, and each model has specific limits
    for input tokens and output dimensions:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI 拥有四种不同的嵌入模型，每种模型都有特定的输入标记数和输出维度限制：
- en: '**text-embedding-ada-002 (****version 2)**:'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**text-embedding-ada-002（****版本 2）**：'
- en: '**Max input** **tokens**: 8,191'
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大输入** **标记数**：8,191'
- en: '**Output** **dimensions**: 1,536'
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出** **维度**：1536'
- en: '**text-embedding-ada-002 (****version 1)**:'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**text-embedding-ada-002（****版本 1）**：'
- en: '**Max input** **tokens**: 2046'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大输入** **标记数**：2046'
- en: '**Output** **Dimensions**: 1536'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出** **维度**：1536'
- en: '**text-embedding-3-large**:'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**text-embedding-3-large**：'
- en: '**Max input** **tokens**: 8191'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大输入** **标记数**：8191'
- en: '**Output** **Dimensions**: 3072'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出** **维度**：3072'
- en: '**text-embedding-3-small**:'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**text-embedding-3-small**：'
- en: '**Max input** **tokens**: 8191'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大输入** **标记数**：8191'
- en: '**Output** **Dimensions**: 1536'
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出** **维度**：1536'
- en: text-embedding-3-small and text-embedding-3-large are the newest and most performant
    embedding models. They are now available in AOAI.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: text-embedding-3-small 和 text-embedding-3-large 是最新且最强大的嵌入模型。它们现在已在 AOAI 上可用。
- en: text-embedding-ada-002 (version 2)
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: text-embedding-ada-002（版本 2）
- en: The text-embedding-ada-002 model consolidates the functions of five different
    models used for searching text, comparing text similarity, and searching code.
    It performs better than our previous top model, Davinci, in most tasks and is
    99.8% less expensive. This model has a longer context length of 8,192 compared
    to the previous version of text-embedding-ada-002.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: text-embedding-ada-002 模型整合了五种不同模型的功能，用于搜索文本、比较文本相似性和搜索代码。它在大多数任务中比我们之前的顶级模型
    Davinci 表现更好，并且便宜 99.8%。此模型的上下文长度为 8,192，比之前的 text-embedding-ada-002 版本更长。
- en: 'You can use this embedding model using just a few lines of code, as you did
    with the previous version, by using our OpenAI Python library:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以像使用之前的版本一样，使用几行代码调用此嵌入模型，方法是使用我们的 OpenAI Python 库：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: text-embedding-3-small
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: text-embedding-3-small
- en: text-embedding-3-small is a new, highly efficient embedding model, offering
    a significant upgrade over text-embedding-ada-002 (version 2), released in December
    2022.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: text-embedding-3-small 是一种全新的、高效的嵌入模型，相比于 2022 年 12 月发布的 text-embedding-ada-002（版本
    2）提供了显著的升级。
- en: 'It boasts improved performance:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 它具有改进的性能：
- en: text-embedding-3-small outperforms text-embedding-ada-002 in **multilingual
    retrieval** (**MIRACL**), increasing the average score from 31.4% to 44.0%.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: text-embedding-3-small 在 **多语言检索** (**MIRACL**) 上表现优于 text-embedding-ada-002，平均得分从
    31.4% 提升至 44.0%。
- en: For **English tasks** (**MTEB**), the average score has improved from 61.0%
    to 62.3%
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 **英语任务** (**MTEB**)，平均得分从 61.0% 提升至 62.3%
- en: It also comes with lower costs. text-embedding-3-small is five times more cost-efficient
    than text-embedding-ada-002, reducing the price per 1,000 tokens from $0.0001
    to $0.00002.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 它还具有更低的成本。text-embedding-3-small 比 text-embedding-ada-002 的成本效率高五倍，将每千个标记的价格从
    $0.0001 降低到 $0.00002。
- en: text-embedding-3-large
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: text-embedding-3-large
- en: text-embedding-3-large is another new, next-generation embedding model, producing
    embeddings with up to 3,072 dimensions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: text-embedding-3-large 是另一种新型、下一代的嵌入模型，生成的嵌入具有最多 3,072 个维度。
- en: 'It comes with improved performance:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 它具有改进的性能：
- en: text-embedding-3-large is the best-performing model
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: text-embedding-3-large 是表现最好的模型
- en: On MIRACL, it improves the average score from 31.4% (text-embedding-ada-002)
    to 54.9%
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 MIRACL 上，它将平均得分从 31.4%（text-embedding-ada-002）提升至 54.9%
- en: On MTEB, the average score increases from 61.0% to 64.6%
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 MTEB 上，平均得分从 61.0% 增加到 64.6%
- en: As for the cost, text-embedding-3-large is slightly higher cost than text-embedding-3-small,
    with the price per 1,000 tokens set at $0.00013.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 就成本而言，text-embedding-3-large 的成本略高于 text-embedding-3-small，每千个标记的价格为 $0.00013。
- en: AOAI is not discontinuing text-embedding-ada-002 (version 2), so customers can
    continue using it if they prefer. However, it’s recommended to switch to the newer
    model for better price performance.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI并不会停止提供text-embedding-ada-002（版本2），因此客户如果更喜欢，仍然可以继续使用它。然而，推荐切换到更新的模型，以获得更好的性价比。
- en: Both new embedding models use a technique called `dimensions` API parameter,
    you can reduce the size of the embeddings without losing their meaning.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 两种新的嵌入模型都使用一种叫做`dimensions` API参数的技术，你可以在不丢失含义的情况下减少嵌入的大小。
- en: For instance, on the MTEB benchmark, a text-embedding-3-large embedding can
    be shortened to 256 dimensions while still outperforming an unshortened text-embedding-ada-002
    embedding with 1,536 dimensions.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在MTEB基准测试中，一个text-embedding-3-large嵌入可以缩短至256维，同时仍然优于一个未缩短的text-embedding-ada-002嵌入（1,536维）。
- en: 'In general, it’s best to use the `dimensions` parameter when creating the embedding.
    If you need to change the dimensions afterward, ensure that the embedding is normalized,
    as shown here:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在创建嵌入时最好使用`dimensions`参数。如果之后需要更改维度，请确保嵌入已标准化，如下所示：
- en: '[PRE1]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Changing dimensions dynamically allows for flexible usage. For example, if a
    vector DB only supports embeddings up to 1,536 dimensions, developers can still
    use the best model, text-embedding-3-large, by setting the `dimensions` API parameter
    to `1536`. This reduces the embedding from 3,072 dimensions, sacrificing some
    accuracy for a smaller vector size. This leads us perfectly into discussing the
    vector search feature in the Azure AI Search service in the next section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 动态变化维度允许灵活使用。例如，如果一个向量数据库仅支持最多1,536维的嵌入，开发者仍然可以通过将`dimensions` API参数设置为`1536`，使用最好的模型text-embedding-3-large。这样可以将嵌入从3,072维缩减，牺牲一些准确度换取更小的向量大小。这为我们在下一节讨论Azure
    AI Search服务中的向量搜索功能奠定了基础。
- en: Azure vector databases
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure 向量数据库
- en: In the previous section, we explored various AOAI embedding models for generating
    vector embeddings. After creating these vectors, it’s essential to have a database
    optimized for storing and managing them effectively. The key distinction between
    a vector database and other types of databases is its capability to handle high-dimensional
    data. A vector database is specifically engineered to store data as high-dimensional
    vectors, which are mathematical representations of various features or attributes.
    Each vector comprises multiple dimensions, ranging from tens to thousands, depending
    on the data’s complexity and detail. These vectors are usually generated by applying
    transformation or embedding functions to raw data sources such as text, images,
    audio, video, and more. This type of database enables the indexing and querying
    of embeddings using vector search algorithms that assess vector distance or similarity.
    To ensure accurate retrieval of relevant information, a robust mechanism is necessary.
    Prominent vector search algorithms include **Hierarchical Navigable Small World**
    (**HNSW**), **Inverted File** (**IVF**), and DiskANN, among others.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们探讨了多种AOAI嵌入模型用于生成向量嵌入。创建这些向量后，必须拥有一个优化过的数据库来有效存储和管理它们。向量数据库与其他类型数据库的关键区别在于其能够处理高维数据。向量数据库专门设计用于将数据存储为高维向量，这些向量是各种特征或属性的数学表示。每个向量包含多个维度，数量从几十到上千不等，具体取决于数据的复杂性和细节。这些向量通常是通过将转换或嵌入函数应用于原始数据源（如文本、图像、音频、视频等）生成的。此类数据库使得可以使用向量搜索算法进行嵌入的索引和查询，评估向量的距离或相似度。为了确保准确检索相关信息，必须有一个强大的机制。主要的向量搜索算法包括**层次可导航小世界**（**HNSW**）、**倒排文件**（**IVF**）和DiskANN等。
- en: 'The primary benefit of a vector database is its ability to conduct rapid and
    precise similarity searches and data retrieval based on vector distance or similarity.
    Unlike traditional databases that depend on exact matches or predefined criteria
    for queries, a vector database allows for the identification of the most similar
    or relevant data based on semantic or contextual meanings. Here are some practical
    applications:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库的主要优势在于它能够基于向量距离或相似度进行快速且精确的相似性搜索和数据检索。与依赖精确匹配或预定义查询标准的传统数据库不同，向量数据库可以根据语义或上下文意义识别最相似或最相关的数据。以下是一些实际应用：
- en: '**Search engines**: Vector databases transform search engines by enabling efficient
    similarity-based searches. They help find similar items, improve search relevance,
    and enhance user experiences.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**搜索引擎**：向量数据库通过支持基于相似性的高效搜索，改变了搜索引擎的运作方式。它们帮助查找相似的项目，提高搜索相关性，并增强用户体验。'
- en: '**Image retrieval**: Identify images that are similar to a given image based
    on visual content and style.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像检索**：根据视觉内容和风格，识别与给定图像相似的图像。'
- en: '**Document search**: Locate documents similar to a given document, considering
    factors such as topic and sentiment.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档搜索**：根据主题和情感等因素，定位与给定文档相似的文档。'
- en: '**Product recommendations**: Discover products that are similar to a given
    product based on features and ratings.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**产品推荐**：根据特征和评分，发现与给定产品相似的产品。'
- en: '**Semantic search**: Vector databases enhance semantic search capabilities,
    allowing applications to find contextually related content. This makes them valuable
    for information retrieval, chatbots, and question-answering systems.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义搜索**：向量数据库增强了语义搜索能力，使应用能够找到具有上下文相关性的内容。这使得它们在信息检索、聊天机器人和问答系统中具有重要价值。'
- en: '**Recommender systems**: These systems benefit from vector databases by providing
    personalized product recommendations or content suggestions based on user preferences,
    thereby improving recommendation accuracy.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推荐系统**：推荐系统通过利用向量数据库，根据用户的偏好提供个性化的产品推荐或内容建议，从而提高推荐的准确性。'
- en: '**Medical and scientific research**: In fields such as genomics and chemistry,
    vector databases facilitate the analysis of genomic data, identification of chemical
    compound similarities, and acceleration of scientific discoveries.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医学和科学研究**：在基因组学和化学等领域，向量数据库促进了基因数据分析、化学化合物相似性的识别，以及科学发现的加速。'
- en: To perform similarity search and retrieval in a vector database, a query vector
    encapsulating your desired information or criteria is needed. This query vector
    can originate from the same type of data as the stored vectors (e.g., using an
    image to query an image database) or from different types of data (e.g., using
    text to query an image database). The next step involves using a similarity measure
    to determine the proximity or distance between two vectors within the vector space.
    Various metrics can be employed for this purpose, such as cosine similarity, Euclidean
    distance, Hamming distance, and Jaccard index. The result of the similarity search
    and retrieval process is typically a ranked list of vectors that exhibit the highest
    similarity scores to the query vector. Subsequently, you can retrieve the associated
    data for each vector from the original source or index.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要在向量数据库中执行相似性搜索和检索，需要一个封装了您期望信息或标准的查询向量。这个查询向量可以来自与存储向量相同类型的数据（例如，使用图像查询图像数据库），也可以来自不同类型的数据（例如，使用文本查询图像数据库）。下一步是使用相似性度量来确定两个向量在向量空间中的接近度或距离。为此目的，可以采用各种度量标准，如余弦相似度、欧几里得距离、汉明距离和杰卡德指数。相似性搜索和检索过程的结果通常是一个按与查询向量相似度得分排序的向量列表。随后，您可以从原始源或索引中检索与每个向量相关联的数据。
- en: 'Azure provides six varieties of vector database options tailored to diverse
    needs and use cases:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Azure 提供六种不同种类的向量数据库选项，旨在满足多样化的需求和使用场景：
- en: '**Azure AI Search**: Azure AI Search is a powerful tool that features vector
    search capabilities. It utilizes the HNSW algorithm for vector searches and the
    **Best Match 25** (**BM25**) algorithm for full-text searches. Additionally, it
    offers a hybrid search option that merges the results from both full-text and
    vector queries, each using different ranking methodologies such as BM25 and HNSW.
    The **Reciprocal Rank Fusion** (**RRF**) algorithm is employed to consolidate
    these results, ensuring a single, cohesive result set that highlights the most
    relevant matches from the search index. In fact, OpenAI leverages Azure AI Search
    to enhance the capabilities of its ChatGPT application. By integrating Azure AI
    Search, OpenAI benefits from advanced search functionalities such as vector search,
    full-text search, and hybrid search, which combine the strengths of the BM25 and
    HNSW algorithms. This integration allows ChatGPT to deliver more accurate and
    relevant responses by efficiently retrieving and ranking information from a search
    index.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure AI Search**：Azure AI Search 是一个强大的工具，具有向量搜索功能。它利用 HNSW 算法进行向量搜索，使用
    **Best Match 25**（**BM25**）算法进行全文搜索。此外，它还提供了一种混合搜索选项，结合了全文搜索和向量查询的结果，每种查询使用不同的排序方法，例如
    BM25 和 HNSW。**Reciprocal Rank Fusion**（**RRF**）算法用于整合这些结果，确保生成一个统一、连贯的结果集，突出显示搜索索引中最相关的匹配项。实际上，OpenAI
    利用 Azure AI Search 来增强其 ChatGPT 应用的功能。通过集成 Azure AI Search，OpenAI 受益于先进的搜索功能，如向量搜索、全文搜索和混合搜索，这些功能结合了
    BM25 和 HNSW 算法的优势。这种集成使 ChatGPT 能够通过高效地检索和排序来自搜索索引的信息，提供更准确和相关的响应。'
- en: However, it is important to note that Azure AI Search does not generate vector
    embeddings for your content; you are required to provide these embeddings yourself.
    One viable option for generating these embeddings is through AOAI embedding models.
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 但是，需要注意的是，Azure AI Search 不会为您的内容生成向量嵌入；您需要自己提供这些嵌入。生成这些嵌入的一个可行选项是使用 AOAI 嵌入模型。
- en: From an architectural standpoint, the AI Search service functions as an intermediary
    between external data stores that house your un-indexed data and the client application
    that sends query requests to a search index and manages the responses.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从架构角度来看，AI Search 服务充当外部数据存储和客户端应用之间的中介，外部数据存储存放您的未索引数据，而客户端应用则发送查询请求到搜索索引并管理响应。
- en: '![Figure 3.1: Azure AI Search application architecture](img/B21019_03_1.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.1：Azure AI Search 应用架构](img/B21019_03_1.jpg)'
- en: 'Figure 3.1: Azure AI Search application architecture'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：Azure AI Search 应用架构
- en: Within your client application, the search experience is crafted using Azure
    AI Search APIs, which can include features such as relevance tuning, semantic
    ranking, autocomplete, synonym matching, fuzzy matching, pattern matching, filtering,
    and sorting.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的客户端应用中，搜索体验是通过 Azure AI Search API 打造的，这些 API 可以包括相关性调整、语义排名、自动完成、同义词匹配、模糊匹配、模式匹配、筛选和排序等功能。
- en: Azure AI Search also offers seamless integration with other Azure services.
    This is facilitated through indexers that automate data ingestion and retrieval
    from various azure data sources, as well as skillsets that incorporate AI functionalities
    from Azure AI services. These skillsets can include image and natural language
    processing, or custom code encapsulated within Azure Functions.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Azure AI Search 还提供与其他 Azure 服务的无缝集成。这通过索引器得以实现，索引器自动从各种 Azure 数据源中提取和检索数据，以及结合
    Azure AI 服务的技能集，这些技能集可以包括图像和自然语言处理，或者封装在 Azure Functions 中的自定义代码。
- en: '`WHERE` clauses. This enables your vector searches to yield the most relevant
    data to your applications.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WHERE` 子句。这使得您的向量搜索能够为您的应用提供最相关的数据。'
- en: This feature enhances the core capabilities of Azure Cosmos DB, making it more
    versatile for handling vector data and search requirements in AI applications.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该功能增强了 Azure Cosmos DB 的核心能力，使其在处理 AI 应用中的向量数据和搜索需求时更加多样化。
- en: '**Azure Cosmos DB for MongoDB**: Azure Cosmos DB for MongoDB also offers integrated
    vector database capabilities, allowing embeddings to be stored, indexed, and queried
    alongside other relational data. This feature enables efficient management and
    retrieval of vector data within MongoDB collections, enhancing the versatility
    of Azure Cosmos DB for diverse application needs.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure Cosmos DB for MongoDB**：Azure Cosmos DB for MongoDB 还提供集成的向量数据库功能，允许将嵌入存储、索引并与其他关系数据一起查询。此功能使得在
    MongoDB 集合中高效管理和检索向量数据成为可能，从而增强了 Azure Cosmos DB 在多种应用需求中的适用性。'
- en: 'MongoDB vCore provides two types of vector indexing methods:'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MongoDB vCore 提供了两种类型的向量索引方法：
- en: '**IVF**: IVF indexing is a method used in vector search to efficiently organize
    and manage large sets of vectors by clustering them into groups. Each cluster
    is represented by a centroid, or center point. During a search, the query vector
    is first compared to these centroids to identify the closest cluster. The search
    is then conducted within this specific cluster, significantly reducing the search
    space and improving retrieval times. This method balances speed and accuracy,
    making it ideal for applications requiring rapid and efficient vector searches.'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IVF**：IVF 索引是一种在向量搜索中使用的方法，通过将向量分组进行聚类，有效组织和管理大量向量。每个聚类由一个质心或中心点表示。在搜索过程中，查询向量首先与这些质心进行比较，以确定最接近的聚类。然后，在该特定聚类内进行搜索，显著减少搜索空间并提高检索速度。此方法平衡了速度和准确性，非常适合需要快速且高效向量搜索的应用。'
- en: '**HNSW**: This is an advanced algorithm for **approximate nearest neighbor**
    (**ANN**) search in high-dimensional spaces, utilizing a multi-layer graph structure
    to organize data points. Each layer represents a different level of proximity,
    with higher layers containing fewer, more broadly representative points and lower
    layers containing more detailed points. This navigable graph supports efficient
    search by starting from the top layer and moving downward to find closer neighbors,
    leveraging “small world” properties for quick access across the dataset. HNSW
    provides fast and accurate ANN searches, making it ideal for applications such
    as recommendation systems, image retrieval, and natural language processing.'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HNSW**：这是一种用于高维空间中**近似最近邻**（**ANN**）搜索的先进算法，利用多层图结构组织数据点。每一层代表不同的接近度级别，较高的层包含较少、代表性更广的点，而较低的层包含更为详细的点。这个可导航的图通过从顶部层开始，向下移动以找到更近的邻居，利用“随机小世界”属性快速访问整个数据集。HNSW
    提供了快速且准确的 ANN 搜索，非常适用于推荐系统、图像检索和自然语言处理等应用。'
- en: '`pgvector` extension available on Azure PostgreSQL flexible servers, you can
    seamlessly integrate vector capabilities into your PostgreSQL environment. `pgvector`
    is an open source extension tailored for PostgreSQL, enabling the storage and
    retrieval of vectors from natural language processing or deep learning models
    directly within PostgreSQL. What makes `pgvector` particularly appealing is its
    familiar SQL-based interface, mirroring traditional PostgreSQL operations for
    tasks such as creating vector columns, defining tables with vector columns, and
    performing nearest neighbor searches using L2 distance. Whether you’re developing
    AI applications, creating recommendation systems, or handling high-dimensional
    data, `pgvector` simplifies vector management within a familiar database framework,
    eliminating the need for specialized storage solutions and extensive vector database
    expertise.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Azure PostgreSQL 灵活服务器上提供 `pgvector` 扩展，您可以将向量功能无缝集成到您的 PostgreSQL 环境中。`pgvector`
    是一个为 PostgreSQL 定制的开源扩展，能够直接在 PostgreSQL 中存储和检索来自自然语言处理或深度学习模型的向量。`pgvector` 特别吸引人的地方在于其熟悉的基于
    SQL 的接口，类似于传统 PostgreSQL 操作，用于创建向量列、定义包含向量列的表以及使用 L2 距离执行最近邻搜索等任务。无论您是开发 AI 应用、创建推荐系统，还是处理高维数据，`pgvector`
    都简化了在熟悉的数据库框架中进行向量管理，免去了专门的存储解决方案和深入了解向量数据库的需求。
- en: '**Azure SQL**: Azure SQL Database now supports vector operations directly within
    the database, enabling efficient vector similarity searches. This capability,
    combined with full-text search and BM25 ranking, allows for the development of
    powerful search engines suitable for various applications. There are two methods
    to perform vector operations: the native option and the classic option:'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure SQL**：Azure SQL 数据库现在支持直接在数据库中执行向量操作，能够高效地进行向量相似度搜索。结合全文搜索和 BM25 排序，这一功能使得开发适用于各种应用的强大搜索引擎成为可能。执行向量操作有两种方法：本地选项和经典选项：'
- en: '**Native option**: Utilize the newly introduced Vector Functions in Azure SQL
    Database. These functions are designed to perform vector operations directly within
    the database, providing a streamlined and efficient approach.'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地选项**：利用 Azure SQL 数据库中新引入的向量函数。这些函数旨在直接在数据库中执行向量操作，提供简化且高效的方法。'
- en: '**Classic option**: Use traditional T-SQL for vector operations, leveraging
    columnstore indexes to achieve high performance.'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**经典选项**：使用传统的 T-SQL 进行向量操作，利用列存储索引实现高性能。'
- en: Both options offer robust solutions for implementing vector searches, making
    Azure SQL Database a versatile tool for advanced search scenarios.
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这两种选项都为实现向量搜索提供了强大的解决方案，使得Azure SQL数据库成为一个适用于高级搜索场景的多功能工具。
- en: Microsoft’s recent announcement of *SQL Server 2025* marks a significant step
    in database evolution, introducing it as an enterprise-ready *vector database*.
    This release integrates *built-in security and compliance*, emphasizing its focus
    on supporting enterprise-grade *AI solutions*. A standout feature is the *native
    vector store and index*, which is powered by DiskANN and leverages disk storage
    to execute high-performance searches across vast datasets. This functionality
    underpins semantic searching, enabling efficient chunking and accurate data retrieval
    – a critical feature for AI-driven insights. This advancement enables efficient
    handling of high-dimensional data, making it well-suited for AI workloads such
    as recommendation systems, natural language processing, and image search.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 微软最近宣布的*SQL Server 2025*标志着数据库演变的重要一步，将其推出为企业级*向量数据库*。这一版本集成了*内置安全性和合规性*，强调其支持企业级*AI解决方案*的重点。一个突出特点是*原生向量存储和索引*，由DiskANN提供支持，利用磁盘存储执行高性能搜索，适用于大规模数据集。这个功能支撑语义搜索，使得高效的分块和准确的数据检索成为可能——这是AI驱动的洞察所必需的关键功能。这一进展使得高维数据的高效处理成为可能，非常适合AI工作负载，如推荐系统、自然语言处理和图像搜索。
- en: '`RediSearch` module offers comprehensive search capabilities, including various
    distance metrics such as Euclidean, cosine, and Inner Product, and supports both
    KNN with FLAT indexing and ANNs using HNSW indexing. It allows vector storage
    in hash or JSON formats and supports top-K and vector range queries to find items
    within a specific vector distance. Additionally, Redis enhances search functionalities
    with advanced features such as geospatial filtering, numeric and text filters,
    prefix and fuzzy matching, phonetic matching, and Boolean queries. Often considered
    a cost-effective solution, Redis is widely used for caching or session storage,
    enabling it to handle both traditional caching roles and vector search applications
    concurrently.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RediSearch`模块提供了全面的搜索功能，包括多种距离度量方法，如欧几里得距离、余弦相似度和内积，并支持使用FLAT索引的KNN和使用HNSW索引的ANNs。它支持以哈希或JSON格式存储向量，并支持通过top-K和向量范围查询来查找位于特定向量距离内的项。此外，Redis通过高级功能增强了搜索功能，如地理空间过滤、数值和文本过滤、前缀和模糊匹配、语音匹配和布尔查询。Redis通常被认为是一种具有成本效益的解决方案，广泛用于缓存或会话存储，使其能够同时处理传统的缓存角色和向量搜索应用。'
- en: Most Azure vector databases, such as AI Search, CosmosDB, and Azure Managed
    Redis, are integrated with LLM frameworks such as Semantic Kernel, LangChain,
    and LlamaIndex to facilitate easy vector creation and ingestion into their respective
    services. These integrations streamline the process of embedding generation, storage,
    and retrieval, enabling efficient handling of vector data and enhancing the capabilities
    of GenAI applications.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数Azure向量数据库，如AI Search、CosmosDB和Azure托管Redis，都与LLM框架如Semantic Kernel、LangChain和LlamaIndex集成，以便轻松创建向量并将其导入到各自的服务中。这些集成简化了嵌入生成、存储和检索的过程，使得向量数据的高效处理成为可能，并增强了GenAI应用的能力。
- en: Azure also offers a no-code solution for creating vector embeddings and automatically
    ingesting them into Azure AI Search or Cosmos DB as part of its native features.
    In the next section, we will explore this capability as part of *AOAI On* *Your
    Data*.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Azure还提供了一种无需编码的解决方案，用于创建向量嵌入并将其自动导入到Azure AI Search或Cosmos DB，作为其原生功能的一部分。在接下来的部分，我们将探索这个能力，作为*AOAI
    On* *Your Data*的一部分。
- en: AOAI On Your Data
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AOAI On Your Data
- en: A common application in various industries is the creation of personalized chatbots
    utilizing their own enterprise data through generative AI. Traditionally, this
    required customers to manually code processes for extracting text from unstructured
    data, generate embeddings, and store them in a vector database, which was both
    time-consuming and labor-intensive for developers. However, the Azure OpenAI On
    Your Data feature significantly simplifies this workflow, allowing developers
    to achieve the same results with minimal or no coding. This means that building
    a chatbot application can now be accomplished with just a few clicks.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在各行各业中，一个常见的应用是利用生成性 AI 创建个性化聊天机器人，通过使用自身的企业数据。传统上，这要求客户手动编写代码，从非结构化数据中提取文本，生成嵌入，并将其存储在向量数据库中，这对开发者来说既耗时又劳动密集。然而，Azure
    OpenAI 的 On Your Data 功能显著简化了这一工作流程，使开发者能够在几乎不编写任何代码的情况下实现相同的结果。这意味着，构建一个聊天机器人应用程序现在只需几次点击即可完成。
- en: This functionality operates behind the scenes using a RAG technique, as illustrated
    in *Figure 3**.2*.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能在后台使用 RAG 技术，如*图 3.2*所示。
- en: '![Figure 3.2: AOAI On Your Data RAG architecture](img/B21019_03_2.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.2：AOAI 在您的数据中的 RAG 架构](img/B21019_03_2.jpg)'
- en: 'Figure 3.2: AOAI On Your Data RAG architecture'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2：AOAI 在您的数据中的 RAG 架构
- en: When you upload a collection of documents in various formats, those are then
    divided into smaller chunks. Each chunk is converted into an embedding, such as
    *text-embedding-ada-002*, using AOAI’s embedding model. These embeddings are stored
    in an AI search vector database, utilizing an HNSW index, which is configured
    for semantic search. Users can input queries through GPT4-o chat, which are also
    transformed into embeddings using the same embedding model. Then a similarity
    search is conducted to find the most relevant document vectors using ANN techniques
    on the HNSW index. Next, the retrieved context and the raw user query are provided
    to the GPT models to generate responses to user questions.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当你上传各种格式的文档集合时，这些文档会被拆分成更小的块。每个块会被转换为嵌入，例如 *text-embedding-ada-002*，并使用 AOAI
    的嵌入模型进行处理。这些嵌入会存储在 AI 搜索向量数据库中，利用 HNSW 索引进行语义搜索。用户可以通过 GPT4-o 聊天输入查询，这些查询也会使用相同的嵌入模型转换为嵌入。然后，使用
    ANN 技术在 HNSW 索引上进行相似性搜索，找到最相关的文档向量。接着，将检索到的上下文和原始用户查询提供给 GPT 模型，以生成对用户问题的回答。
- en: Additionally, Azure RBAC ensures secure access and permissions throughout the
    system. The entire process is streamlined and user-friendly, allowing you to focus
    on utilizing the insights without dealing with the technical complexities.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Azure RBAC 确保整个系统的安全访问和权限控制。整个过程简化且用户友好，让你可以专注于利用洞察，而不必处理技术复杂性。
- en: Important note
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Ensure that the Azure AI Search resource is set up before utilizing the On your
    Data feature. To set up Azure AI Search resource, refer to the instructions provided
    at [https://learn.microsoft.com/en-us/azure/search/search-create-service-portal](https://learn.microsoft.com/en-us/azure/search/search-create-service-portal).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用“On your Data”功能之前，请确保已设置 Azure AI Search 资源。要设置 Azure AI Search 资源，请参考 [https://learn.microsoft.com/en-us/azure/search/search-create-service-portal](https://learn.microsoft.com/en-us/azure/search/search-create-service-portal)
    中提供的说明。
- en: 'Now, let’s demonstrate how you can utilize this feature effortlessly without
    needing to write any code:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们演示如何在不编写任何代码的情况下轻松使用此功能：
- en: Log in to the Azure AI Foundry Portal.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到 Azure AI Foundry 门户。
- en: If you haven’t set up a chat model and an embedding model yet, go to the `text-embedding-ada-002`.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你还没有设置聊天模型和嵌入模型，前往 `text-embedding-ada-002`。
- en: Navigate to **Chat** from the **Playgrounds** menu and select the **Add your**
    **data** tab.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 **Playgrounds** 菜单中导航到 **Chat**，然后选择 **Add your** **data** 标签。
- en: Click on **Add a** **data source**.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Add a** **data source**。
- en: You have several choices for data sources. In this demonstration, we’re uploading
    the file manually. Alternatively, you can opt for a direct blob storage account
    if you have existing data there. If you have an AI search index where data is
    pre-indexed and vectorized, you can connect to that index as well.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以选择多种数据源。在本演示中，我们手动上传文件。你也可以选择直接使用 Blob 存储帐户，如果你的数据已经在那里。如果你有一个 AI 搜索索引，数据已经预先索引并向量化，你也可以连接到该索引。
- en: Select the appropriate subscriptions and the blob storage account where your
    uploaded data will be stored. Next, choose the **Azure AI Search resource** option
    you’ll use for storing the vector index, and finally, specify the index name.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择适当的订阅和您上传数据将存储的 blob 存储账户。接下来，选择用于存储向量索引的**Azure AI 搜索资源**选项，最后指定索引名称。
- en: Tick the checkbox to enable vector search for this AI search resource. Refer
    to *Figure 3**.3* for details.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 勾选复选框以启用此 AI 搜索资源的向量搜索功能。有关详细信息，请参见*图 3.3*。
- en: '![Figure 3.3: AOAI On Your Data settings](img/B21019_03_3.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.3：AOAI On Your Data 设置](img/B21019_03_3.jpg)'
- en: 'Figure 3.3: AOAI On Your Data settings'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3：AOAI On Your Data 设置
- en: Click on **Next**.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**下一步**。
- en: On the next screen, upload a PDF file. You also have the option to upload files
    in `.txt`, `.md`, `.html`, `.pdf`, `.docx`, or `.pptx` formats. In this instance,
    I’m uploading a hotel invoice PDF receipt. Refer to *Figure 3**.4* for a sample
    view of the receipt.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在接下来的屏幕上，上传一个 PDF 文件。您还可以上传 `.txt`、`.md`、`.html`、`.pdf`、`.docx` 或 `.pptx` 格式的文件。在此示例中，我上传的是一张酒店发票的
    PDF 收据。有关收据的示例视图，请参见*图 3.4*。
- en: '![Figure 3.4: Sample data for AOAI On Your Data](img/B21019_03_4.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.4：AOAI On Your Data 的示例数据](img/B21019_03_4.jpg)'
- en: 'Figure 3.4: Sample data for AOAI On Your Data'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4：AOAI On Your Data 的示例数据
- en: Click on **Next**.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**下一步**。
- en: 'Select the **Search type** option you’d like to use. You have three options
    to choose from:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择您想要使用的**搜索类型**选项。您可以从以下三种选项中进行选择：
- en: '**Vector**: This finds documents similar to a query using vector embeddings.'
  id: totrans-118
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量**：该选项通过向量嵌入查找与查询相似的文档。'
- en: '**Hybrid** (vector + keyword): This combines similarity search over vector
    fields with keyword-based full-text search.'
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合**（向量 + 关键词）：该选项结合了基于向量字段的相似性搜索和基于关键词的全文搜索。'
- en: '**Hybrid + semantic**: This utilizes vector embeddings, language understanding,
    and flexible query parsing for advanced search experiences. This option is highly
    recommended due to its superior search quality.'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合 + 语义**：该选项利用向量嵌入、语言理解和灵活的查询解析，提供高级搜索体验。由于其卓越的搜索质量，强烈推荐此选项。'
- en: Selecting the right type enhances your search capabilities based on your specific
    needs.
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 选择正确的类型可以根据您的具体需求增强搜索能力。
- en: Select the chunk size. Chunking involves dividing documents into smaller segments
    for efficient search and retrieval, with chunk size measured in tokens.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择块大小。分块涉及将文档拆分为更小的部分，以提高搜索和检索效率，块大小以标记为单位进行测量。
- en: Click **Next**. On the following screen, choose the type of authentication.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**下一步**。在接下来的屏幕上，选择认证类型。
- en: The time required for indexing may increase with document size.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 索引所需的时间可能会随着文档大小的增加而增加。
- en: Select the **Deployment** option to use and fill in the **System message** field
    as shown in *Figure 3**.5*. Then click **Apply changes**.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择要使用的**部署**选项，并填写**系统消息**字段，如*图 3.5*所示。然后点击**应用更改**。
- en: '![Figure 3.5: On Your Data settings](img/B21019_03_5.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.5：On Your Data 设置](img/B21019_03_5.jpg)'
- en: 'Figure 3.5: On Your Data settings'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5：On Your Data 设置
- en: Now you are all set to start the chat from **Chat playground**.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您已准备好从**Chat playground**开始聊天。
- en: Refer to *Figure 3**.6* for a sample question. You can ask questions based on
    the document provided to receive accurate answers. You can click on the references
    to view the citations for the answers.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请参见*图 3.6*了解示例问题。您可以根据提供的文档提问并获得准确的答案。点击参考文献查看答案的引用。
- en: '![Figure 3.6: Sample questions and answers, with references](img/B21019_03_6.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.6：带参考的示例问题和答案](img/B21019_03_6.jpg)'
- en: 'Figure 3.6: Sample questions and answers, with references'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6：带参考的示例问题和答案
- en: You’ve observed how the answer is grounded on your data using the AOAI On Your
    Data feature. If you’re looking to develop a web application and deploy it to
    production, simply click **Deploy as a web app** and fill in the app service details
    as shown in *Figure 3**.7*. Then click on **Deploy** to create a web application
    for users.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经观察到答案是如何基于您的数据使用 AOAI On Your Data 功能生成的。如果您打算开发一个 Web 应用并将其部署到生产环境，只需点击**作为
    Web 应用部署**，并按照*图 3.7*所示填写应用服务详情。然后点击**部署**，为用户创建一个 Web 应用。
- en: '![Figure 3.7: Chat On Your Data web app settings](img/B21019_03_7.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.7：Chat On Your Data 网络应用设置](img/B21019_03_7.jpg)'
- en: 'Figure 3.7: Chat On Your Data web app settings'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7：Chat On Your Data 网络应用设置
- en: 'After deployment, you’ll receive a public URL for the application, enabling
    end users to interact with the document they uploaded, as shown here:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 部署后，您将收到应用程序的公共 URL，允许最终用户与他们上传的文档进行互动，如下所示：
- en: '![Figure 3.8: Web application view](img/B21019_03_8.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.8：Web 应用视图](img/B21019_03_8.jpg)'
- en: 'Figure 3.8: Web application view'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.8：Web 应用视图
- en: This simplifies the process, allowing you to make your chat application available
    to end users with just a few clicks without needing to write any code. It’s an
    efficient way to deploy and share your application quickly. However, it’s important
    to note that while this feature works well for small **proofs of concept**, developing
    a robust production application requires careful consideration of various factors
    for improved accuracy. These include strategies for chunking, query rewriting,
    and designing custom prompt templates. These capabilities are somewhat limited
    in this regard, often necessitating a code-first approach to create a more sophisticated
    and tailored solution.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程简化了应用部署，使你只需几次点击就能将聊天应用提供给最终用户，无需编写代码。这是一个快速部署和共享应用的高效方式。然而，需要注意的是，虽然该功能非常适合小规模的**概念验证**，但开发一个健壮的生产应用仍需要仔细考虑各个因素，以提高准确性。这些因素包括分块策略、查询重写以及定制提示模板的设计。鉴于这些能力的局限性，通常需要采用代码优先的方法来创建更复杂和量身定制的解决方案。
- en: Up to this point, we’ve utilized AOAI models for text-related scenarios. However,
    there are instances where image understanding is required. In the next section,
    we’ll explore AOAI multimodal capabilities, where the input is an image and the
    output is text. This approach broadens the applicability of AOAI by incorporating
    visual data analysis.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经将 AOAI 模型应用于文本相关的场景。然而，也有一些场景需要理解图像。在接下来的部分，我们将探索 AOAI 的多模态能力，其中输入是图像，输出是文本。通过结合视觉数据分析，这种方法拓宽了
    AOAI 的应用范围。
- en: AOAI multimodal model
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AOAI 多模态模型
- en: 'AOAI multimodal capabilities can be applied in various real-world scenarios,
    such as the following:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI 多模态能力可以应用于各种现实世界场景，具体如下：
- en: '**Image captioning**: Automatically generating descriptive text for images,
    which is useful in organizing digital photo collections or assisting visually
    impaired users'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像标注**：自动生成图像的描述性文本，适用于组织数字照片集或帮助视障用户'
- en: '**Audio processing**: Low-latency conversational use cases requiring real-time
    engagement between a user and a model, such as customer support chatbots, voice
    assistants, and live translation services'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**音频处理**：低延迟对话场景，要求用户与模型之间实时互动，例如客户支持聊天机器人、语音助手和实时翻译服务'
- en: '**Visual question answering**: Responding to questions about an image, which
    can enhance interactive educational tools or customer support systems'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视觉问答**：回答关于图像的问题，可以增强互动教育工具或客户支持系统'
- en: '**Content moderation**: Analyzing images to detect inappropriate or harmful
    content, improving safety on social media platforms'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容审查**：分析图像以检测不当或有害内容，提高社交媒体平台的安全性'
- en: '**E-commerce**: Providing product descriptions from images, aiding in cataloging
    and improving user search experiences'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电子商务**：从图像中提供产品描述，帮助目录管理并改善用户搜索体验'
- en: '**Healthcare**: Assisting in medical diagnostics by interpreting medical images
    and providing preliminary reports'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医疗健康**：通过解读医学图像并提供初步报告来辅助医学诊断'
- en: 'These use cases demonstrate the versatility of integrating both visual and
    textual data processing. To enable such functionalities, AOAI provides a GPT-4
    category model with built-in multimodal features. Presently, AOAI offers three
    distinct models within the GPT-4 family that support these native multimodal capabilities:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这些应用场景展示了集成视觉和文本数据处理的多样性。为了实现这些功能，AOAI 提供了一个带有内建多模态特性的 GPT-4 类别模型。目前，AOAI 在
    GPT-4 系列中提供了三种不同的模型，支持这些原生的多模态能力：
- en: GPT4-Turbo
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT4-Turbo
- en: GPT4-o
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT4-o
- en: GPT4-o-mini
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT4-o-mini
- en: 'Now, let’s test the multimodal capability of GPT4-o from **Chat playground**:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们测试 GPT4-o 的多模态能力，来自**Chat playground**：
- en: Log in to the Azure AI Foundry Portal.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到 Azure AI Foundry 门户。
- en: Navigate to the **Chat from** **Playgrounds** menu.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到**Playgrounds**菜单中的**Chat from**。
- en: Upload an image to the chat and ask a question about it. Alternatively, you
    can achieve this through the SDK by providing a base64-encoded image as input
    to the model. For illustration purposes, I’ve used *Figure 3**.9*.
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上传图片到聊天中并提问。或者，你可以通过 SDK 提供一个 base64 编码的图像作为输入，以便模型处理。为了说明，我使用了*图 3.9*。
- en: '![Figure 3.9: GPT4-o sample image](img/B21019_03_9.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.9：GPT4-o 示例图](img/B21019_03_9.jpg)'
- en: 'Figure 3.9: GPT4-o sample image'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.9：GPT4-o 示例图
- en: 'You can ask questions such as the following:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以提问如下问题：
- en: '`"What is the dimension of the` `CB line?"`'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '`"CB 线的尺寸是多少？"`'
- en: 'While AOAI GPT4-o’s vision capabilities are highly versatile and useful across
    various applications, it is crucial to recognize its limitations. Here are several
    key constraints to be aware of:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 AOAI GPT4-o 的视觉能力在各类应用中非常多样且有用，但必须认识到它的局限性。以下是需要注意的几个关键限制：
- en: '**Medical images**: The model is not designed for interpreting specialized
    medical images such as CT scans and should not be used for medical advice'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医学图像**：模型并不适用于解释专门的医学图像，如 CT 扫描，因此不应用于医学建议'
- en: '**Non-English text**: Performance may decline when dealing with images containing
    text in non-Latin alphabets, such as Japanese or Korean'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非英语文本**：处理包含非拉丁字母文本的图像（如日语或韩语）时，性能可能会下降'
- en: '**Small text**: To improve readability, enlarge small text within images, but
    ensure that no important details are cropped out'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**小文本**：为了提高可读性，放大图像中的小文本，但要确保没有重要细节被裁剪掉'
- en: '**Rotation issues**: The model may misinterpret text or images that are rotated
    or upside down'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**旋转问题**：模型可能会误解被旋转或倒置的文本或图像'
- en: '**Visual elements**: Understanding graphs or text with varying colors or styles,
    such as solid, dashed, or dotted lines, can be challenging for the model'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视觉元素**：理解带有不同颜色或样式的图表或文本，如实线、虚线或点线，对于模型来说可能是具有挑战性的'
- en: '**Spatial reasoning**: Tasks requiring precise spatial localization, such as
    identifying chess positions, are difficult for the model'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**空间推理**：需要精确空间定位的任务，如识别国际象棋位置，对于模型来说是困难的'
- en: '**Accuracy**: In certain situations, the model may produce incorrect descriptions
    or captions'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确性**：在某些情况下，模型可能会生成不准确的描述或说明'
- en: '**Image shape**: Panoramic and fisheye images pose difficulties for the model'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像形状**：全景图和鱼眼图像对模型来说存在困难'
- en: '**Metadata and resizing**: The model does not process original file names or
    metadata, and images are resized before analysis, potentially affecting their
    original dimensions'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元数据和调整大小**：模型不会处理原始文件名或元数据，图像会在分析前调整大小，这可能会影响其原始尺寸'
- en: '**Counting**: The model may provide approximate counts of objects in images'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计数**：模型可能会提供图像中物体的近似计数'
- en: '**CAPTCHAs**: For safety reasons, the system is configured to block the submission
    of CAPTCHAs'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证码**：出于安全原因，系统配置为阻止提交验证码'
- en: Understanding these limitations can help customers set realistic expectations
    and ensure the model is applied appropriately.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 了解这些限制有助于客户设定现实的期望，并确保模型的正确应用。
- en: Now that we have seen the capabilities and limitations of GPT4-o’s vision feature,
    let’s understand the cost model for image inputs.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了 GPT4-o 视觉功能的能力和局限性，让我们来看看图像输入的成本模型。
- en: Image token cost
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像的 token 成本
- en: 'Image inputs are measured and charged in tokens, much like text inputs. The
    token cost for an image is influenced by two main factors: its dimensions and
    the detail level specified for each image URL block. Here is a detailed breakdown:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图像输入与文本输入一样，都是按 tokens 计费。图像的 token 成本受两个主要因素的影响：图像的尺寸和为每个图像 URL 块指定的细节级别。以下是详细的分解：
- en: '**Low detail**: Each image with **Detail** set to **Low** costs 85 tokens.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**低细节**：每张设置为**低**细节的图像需要 85 个 tokens。'
- en: '**High detail**: For high-detail images, the process is more complex. First,
    the image is scaled to fit within a 2,048 x 2,048 square while maintaining its
    aspect ratio. Then, it is scaled again so that its shortest side is 768 pixels
    long. The number of 512-pixel squares that make up the image is then counted,
    and each of these squares costs 170 tokens. An additional 85 tokens are always
    added to the final total.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高细节**：对于高细节图像，处理过程较为复杂。首先，图像被缩放至 2,048 x 2,048 的正方形，并保持其长宽比。接着，图像再次缩放，使其最短边为
    768 像素。然后，计算构成图像的 512 像素方块数量，每个方块需要 170 个 tokens。最终，额外增加 85 个 tokens。'
- en: 'Let’s look at some examples:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些例子：
- en: '**1,024 x 1,024 image in** **high detail**:'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1,024 x 1,024 高细节图像**：'
- en: No initial resizing is needed since 1,024 is less than 2,048
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于 1,024 小于 2,048，因此不需要初步调整大小
- en: The image is scaled down to 768 x 768, as the shortest side is 1,024
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像被缩小至 768 x 768，因为最短边为 1,024
- en: This requires four tiles of 512 pixels each
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这需要四个 512 像素的块
- en: 'The token cost calculation is as follows: 170 tokens/tile * 4 tiles + 85 tokens
    = 765 tokens.'
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: token 成本计算如下：170 tokens/块 * 4 块 + 85 tokens = 765 tokens。
- en: '**2,048 x 4,096 image in** **high detail**:'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2,048 x 4,096 高细节图像**：'
- en: The image is first scaled to 1,024 x 2,048 to fit within the 2,048 square
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像首先被缩放到1,024 x 2,048，以适应2,048平方的范围
- en: The shortest side is then 1,024, so it is further scaled to 768 x 1,536
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最短边为1,024，因此进一步缩放至768 x 1,536
- en: This requires 6 tiles of 512 pixels each
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这需要6个512像素的瓦片
- en: 'The token cost calculation is as follows: 170 tokens/tile * 6 tiles + 85 tokens
    = 1,105 tokens'
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 令牌成本计算如下：170令牌/瓦片 * 6个瓦片 + 85令牌 = 1,105令牌
- en: '**4,096 x 8,192 image in** **low detail**:'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**4,096 x 8,192图像的** **低细节**：'
- en: Regardless of the input size, low-detail images have a fixed cost
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无论输入大小如何，低细节图像具有固定成本
- en: The token cost is 85 tokens
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 令牌成本为85个令牌
- en: Understanding this token cost structure can help manage resource usage effectively
    when working with image inputs.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这个令牌成本结构可以帮助有效管理图像输入时的资源使用。
- en: So far, we’ve explored the self-contained capabilities of AOAI models. However,
    there are enterprise use cases where customers need to integrate LLMs with external
    systems or tools. This allows for the conversion of natural language queries into
    executable structured inputs for those systems. In the next section, we will discuss
    how developers can achieve this functionality using AOAI’s function calling feature.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探讨了AOAI模型的自包含功能。然而，企业中有一些用例需要客户将LLM与外部系统或工具集成。这允许将自然语言查询转换为这些系统可执行的结构化输入。在下一部分，我们将讨论开发人员如何通过使用AOAI的函数调用功能来实现这一功能。
- en: AOAI function calling
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AOAI函数调用
- en: AOAI function calling allows you to connect models such as GPT-4o and other
    GPT models to external tools and systems. This is beneficial for tasks such as
    enhancing AI assistants’ abilities or creating seamless integrations between your
    applications and the models.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI函数调用允许你将GPT-4o等模型与外部工具和系统连接。这对于增强AI助手的能力或在应用程序与模型之间创建无缝集成非常有利。
- en: This feature doesn’t directly run functions for you. Instead, you define the
    functions in the API call, and the model figures out how to create the needed
    arguments. After these arguments are generated, you can use them to execute functions
    within your code.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能并不会直接为你运行函数。相反，你在API调用中定义函数，模型会弄清楚如何生成所需的参数。在这些参数生成后，你可以用它们在代码中执行函数。
- en: 'Function calling is beneficial for numerous applications, such as the following:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 函数调用对许多应用程序有益，例如：
- en: '**Allowing assistants to retrieve information**: An AI assistant might need
    to access the latest customer data from an internal system (such as Azure Cosmos
    DB or Azure SQL) to answer a user’s query about recent orders'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**允许助手检索信息**：AI助手可能需要访问来自内部系统（例如Azure Cosmos DB或Azure SQL）的最新客户数据，以回答用户关于近期订单的查询'
- en: '**Enabling assistants to execute tasks**: An AI assistant can arrange meetings
    by considering user preferences and calendar availability'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使助手执行任务**：AI助手可以根据用户偏好和日历可用性安排会议'
- en: '**Assisting with computations**: A math tutor assistant can perform calculations
    as needed'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协助计算**：数学辅导助手可以根据需要执行计算'
- en: '**Creating complex workflows**: For instance, a data extraction process can
    gather raw text, convert it to structured data, and store it in a database'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创建复杂工作流**：例如，数据提取过程可以收集原始文本，将其转换为结构化数据，并将其存储在数据库中'
- en: '**Altering your application’s user interface**: Function calls can update the
    UI based on user actions, such as displaying a pin on a map'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修改应用程序的用户界面**：函数调用可以根据用户的操作更新UI，例如在地图上显示一个图钉'
- en: Now, let’s talk about the life cycle of the AOAI function call.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论一下AOAI函数调用的生命周期。
- en: Function call life cycle
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 函数调用生命周期
- en: 'There are five different stages of function calls, as can be seen in *Figure
    3**.10*:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 函数调用有五个不同的阶段，如*图3.10*所示：
- en: Your code initiates the process by calling the API with a prompt and the functions
    the LLM can access.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你的代码通过调用API并提供提示和LLM可以访问的函数来启动该过程。
- en: The model evaluates whether to respond directly to the user or whether one or
    more functions need to be invoked.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型评估是否直接响应用户，还是需要调用一个或多个函数。
- en: The API replies to your application, specifying which function should be called
    and what the necessary arguments are.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: API回复你的应用程序，指定应该调用哪个函数以及所需的参数是什么。
- en: Your application runs the specified function using the provided arguments.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你的应用程序使用提供的参数运行指定的函数。
- en: Your application communicates back to the API with the initial prompt and the
    outcome of the executed function.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的应用程序将与 API 进行通信，发送初始提示以及已执行函数的结果。
- en: '![Figure 3.10: Function call life cycle](img/B21019_03_10.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.10：函数调用生命周期](img/B21019_03_10.jpg)'
- en: 'Figure 3.10: Function call life cycle'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.10：函数调用生命周期
- en: When using the OpenAI API with function calling, the model itself doesn’t execute
    the functions. Instead, in *Step 3*, the model generates parameters for your function,
    which your application can use. Your code decides how to handle these parameters,
    typically by calling the specified function. This ensures that your application
    retains complete control over the execution process.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 OpenAI API 进行函数调用时，模型本身并不会执行这些函数。相反，在*步骤 3*中，模型生成函数的参数，供您的应用程序使用。您的代码决定如何处理这些参数，通常通过调用指定的函数。这确保了您的应用程序对执行过程保持完全控制。
- en: Function calling is supported in the Chat Completions, Assistants, and Batch
    APIs. This section focuses on function calling using the Chat Completions API.
    The Assistant and Batch APIs will be covered in the next section.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 函数调用支持在 Chat Completions、Assistants 和 Batch APIs 中。本节重点介绍使用 Chat Completions
    API 进行函数调用。Assistant 和 Batch APIs 将在下一节中讨论。
- en: Let’s get started.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Step 1 – Define the function
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 1 – 定义函数
- en: Start by specifying the function you intend to invoke. This function should
    be a Python function capable of accepting inputs and providing outputs. The inputs
    of the function will be generated by the model.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，指定您打算调用的函数。该函数应为一个 Python 函数，能够接受输入并提供输出。函数的输入将由模型生成。
- en: 'For this example, suppose you wish to enable the model to execute the `get_weather`
    function within your codebase. This function takes a city as an argument to retrieve
    weather information from a weather API. Your function might look like the following:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，假设您希望启用模型在您的代码库中执行 `get_weather` 函数。该函数将城市作为参数，以从天气 API 检索天气信息。您的函数可能如下所示：
- en: '![Figure 3.11: get_weather function definition](img/B21019_03_11.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.11：get_weather 函数定义](img/B21019_03_11.jpg)'
- en: 'Figure 3.11: get_weather function definition'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.11：get_weather 函数定义
- en: Step 2 – Describe the function for model use
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 2 – 为模型使用描述函数
- en: Now that we have identified the function we want the model to call, we will
    develop a *function definition*. This will explain what the function accomplishes,
    when it might be used, and what parameters are needed to invoke it.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确定了要让模型调用的函数，我们将开发一个*函数定义*。它将解释函数的功能、何时使用以及调用该函数所需的参数。
- en: The parameters section in your function definition should be outlined using
    JSON Schema. When the model generates a function call, it will refer to this schema
    to create arguments appropriately.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 函数定义中的参数部分应使用 JSON Schema 进行概述。当模型生成函数调用时，它将参考此模式以适当创建参数。
- en: In this example, it may look like *Figure 3**.12.*
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，它可能看起来像*图 3.12*。
- en: '![Figure 3.12: JSON schema of the function](img/B21019_03_12.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.12：函数的 JSON Schema](img/B21019_03_12.jpg)'
- en: 'Figure 3.12: JSON schema of the function'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.12：函数的 JSON Schema
- en: Step 3 – Provide function definitions as “tools” to the model
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 3 – 将函数定义作为“工具”提供给模型
- en: Next, we need to include our function definitions within an array of available
    *tools* when using the Chat Completions API. As usual, we’ll provide an array
    of *messages*, which might include your prompt or an entire dialogue between the
    user and an assistant.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要在使用 Chat Completions API 时，将我们的函数定义包含在可用的*工具*数组中。像往常一样，我们会提供一个*消息*数组，可能包括您的提示或用户与助手之间的完整对话。
- en: This example, as shown in *Figure 3**.13*, illustrates how you might call the
    Chat Completions API, supplying relevant functions and messages to properly generate
    the function call with a unique ID.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 3.13*所示，本示例演示了如何调用 Chat Completions API，提供相关的函数和消息，以便正确生成带有唯一 ID 的函数调用。
- en: '![Figure 3.13: Generating the function call](img/B21019_03_13.jpg)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.13：生成函数调用](img/B21019_03_13.jpg)'
- en: 'Figure 3.13: Generating the function call'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.13：生成函数调用
- en: 'By default, the model is set to automatically decide which functions to invoke,
    based on the `tool_choice`: “`auto`” configuration.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型设置为自动决定调用哪些函数，基于 `tool_choice`：“`auto`” 配置。
- en: 'We provide three options to modify this default behavior:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了三种选项来修改此默认行为：
- en: 'To mandate the model to always call one or more functions, you can set `tool_choice:
    "required"`. This ensures that the model will always select at least one function
    to execute, which can be useful when you want the model to choose between various
    actions.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '要强制模型始终调用一个或多个函数，你可以设置`tool_choice: "required"`。这确保模型总是会选择至少一个函数来执行，在你希望模型在多种操作之间做出选择时，这会非常有用。'
- en: 'To direct the model to use a specific function, you can define `tool_choice:
    {"type": "function", "function": {"name": "my_function"}}`. This will force the
    model to only call the specified function.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '要指示模型使用特定的函数，你可以定义`tool_choice: {"type": "function", "function": {"name": "my_function"}}`。这将强制模型只调用指定的函数。'
- en: 'To prevent any function calls and have the model respond with only a user-facing
    message, you can either omit tools entirely or set `tool_choice: "none"`.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '为了防止任何函数调用并使模型只返回面向用户的消息，你可以完全省略工具，或者设置`tool_choice: "none"`。'
- en: Step 4 – Making the actual function call
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 4 步 - 进行实际的函数调用
- en: As previously discussed, the AOAI function call doesn’t automatically trigger
    the actual function. Instead, you must add the code to trigger the call based
    on the input parameters generated by the model. To do this, refer to the code
    shown in *Figure 3**.14*.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，AOAI函数调用不会自动触发实际的函数。相反，你必须根据模型生成的输入参数添加代码来触发调用。为此，请参考*图 3.14*中所示的代码。
- en: '![Figure 3.14: Making the function call](img/B21019_03_14.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.14：进行函数调用](img/B21019_03_14.jpg)'
- en: 'Figure 3.14: Making the function call'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.14：进行函数调用
- en: When you include a function in your request, the function’s details (such as
    its definition and parameters) become part of the system message, which is then
    processed by the model along with the user input. This integration enables the
    model to assess whether the function should be invoked based on the prompt context.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在请求中包含一个函数时，函数的详细信息（如定义和参数）会成为系统消息的一部分，然后与用户输入一起由模型处理。这种集成使得模型能够根据提示上下文评估是否应该调用该函数。
- en: This process does use tokens, as the function definition and parameters contribute
    to the overall token count. Therefore, employing prompt engineering strategies
    such as being concise, excluding unnecessary details, and focusing on essential
    parts of the prompt can improve function call efficiency.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程确实会使用到令牌，因为函数定义和参数会影响总体令牌计数。因此，采用提示工程策略，例如简洁明了、去除不必要的细节以及专注于提示的关键部分，可以提高函数调用的效率。
- en: 'Here are some more ways to optimize function call efficiency:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有一些优化函数调用效率的方法：
- en: '**Add more detail to your function definition**: Including detailed function
    definitions with meaningful descriptions is crucial for clarity and efficient
    function invocation. When defining a function, each parameter should be described
    in a way that both the model and any human reviewing the code can easily understand.
    Here’s a breakdown of how to make function definitions more comprehensive.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增加更多的函数定义细节**：包括详细的函数定义和有意义的描述对于清晰度和高效的函数调用至关重要。定义函数时，每个参数应以便于模型和任何审查代码的人员理解的方式进行描述。以下是如何使函数定义更全面的详细说明。'
- en: '`search_hotels`, you could set a system message such as the following:'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`search_hotels`，你可以设置如下的系统消息：'
- en: '[PRE2]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This informs the model when to invoke the function based on user input.
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可以根据用户输入通知模型何时调用函数。
- en: '`search_hotels`, ask for location details if the user request is missing them.
    Include instructions such as this in your system message to guide the model:'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`search_hotels`，如果用户请求中缺少位置详情，询问相关信息。在你的系统消息中包括类似的指示，以指导模型：'
- en: '[PRE3]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Error handling**: Another key aspect of prompt engineering is minimizing
    errors in function calls. While models are trained to generate function calls
    according to your defined schema, they may sometimes create calls that don’t align
    with it or attempt to invoke functions that aren’t included.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误处理**：提示工程中的另一个关键方面是最小化函数调用中的错误。尽管模型经过训练能够根据你定义的模式生成函数调用，但有时它们可能会创建与模式不匹配的调用，或者尝试调用未包含的函数。'
- en: 'To address this, you can add a statement such as the following in the system
    message:'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了解决这个问题，你可以在系统消息中加入如下语句：
- en: '[PRE4]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This helps ensure that the model adheres strictly to the functions you’ve defined.
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这有助于确保模型严格遵守你定义的函数。
- en: Now that you understand how to call AOAI functions, the next section will focus
    on the AOAI Assistants API, which simplifies the application development process
    for developers.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解如何调用 AOAI 函数，接下来的部分将重点介绍 AOAI 助手 API，它简化了开发人员的应用开发过程。
- en: AOAI Assistants API
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AOAI 助手 API
- en: 'The AOAI Assistants API enables the creation of AI-powered assistants that
    can be integrated directly into your own applications. These assistants operate
    based on a set of predefined instructions and can interact with users by utilizing
    various capabilities such as models, tools, and files. Currently, the Assistants
    API supports three key types of tools:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI 助手 API 支持创建可以直接集成到你自己应用中的 AI 助手。这些助手基于一套预定义的指令操作，并可以通过利用各种功能，如模型、工具和文件，来与用户互动。目前，助手
    API 支持三种主要类型的工具：
- en: '**Code Interpreter**: This feature empowers the assistant to handle user requests
    for computations or script execution by allowing it to write and run Python code
    in a secure, multi-tenant Kubernetes environment. The Kubernetes sandbox uses
    nested hypervisor technology to isolate each container, offering a unique user-space
    kernel rather than a traditional kernel. This setup enhances security by isolating
    environments, reduces risks by preventing cross-container interference, and improves
    system flexibility. By facilitating code execution within a safe, virtualized
    environment, the assistant can dynamically respond to complex calculations, data
    processing, and file handling.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码解释器**：此功能使得助手能够处理用户对计算或脚本执行的请求，通过允许助手在安全的、多租户的 Kubernetes 环境中编写和运行 Python
    代码。Kubernetes 沙箱利用嵌套虚拟化技术来隔离每个容器，提供独特的用户空间内核，而非传统的内核。这种设置通过隔离环境来增强安全性，减少通过防止容器间干扰来降低风险，并提高系统灵活性。通过在安全的虚拟化环境中促进代码执行，助手能够动态应对复杂的计算、数据处理和文件处理。'
- en: With support for diverse data formats ([https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/code-interpreter?tabs=python#supported-file-types](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/code-interpreter?tabs=python#supported-file-types)),
    this tool can process files of various structures, extracting information as needed.
    Code Interpreter enables iterative code execution, making it possible for the
    assistant to adjust code and retry execution if initial attempts fail, which is
    particularly helpful for complex coding and mathematical problems. Common use
    cases include extracting data from CSV files, creating structured data visualizations
    such as charts and graphs, and solving math problems.
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该工具支持多种数据格式（[https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/code-interpreter?tabs=python#supported-file-types](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/code-interpreter?tabs=python#supported-file-types)），可以处理各种结构的文件，根据需要提取信息。代码解释器支持迭代代码执行，使得助手在初次执行失败时能够调整代码并重新执行，这对于复杂的编码和数学问题特别有帮助。常见的应用场景包括从
    CSV 文件中提取数据、创建结构化数据可视化（如图表和图形）以及解决数学问题。
- en: '**File Search**: The AOAI File Search tool allows the assistant to enhance
    file-based query handling by accessing and retrieving information from user-provided
    documents. Acting as an external knowledge base, it lets the assistant search
    beyond model-trained data to include proprietary content or other document-based
    information. AOAI’s system automatically chunks down as per chunking strategies
    and indexes documents by creating vector embeddings and storing them within a
    managed vector store powered by Azure AI Search. This enables both vector-based
    and keyword searches, facilitating more precise, context-driven information retrieval
    that supports diverse formats, as detailed at [https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/file-search?tabs=python#supported-file-types](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/file-search?tabs=python#supported-file-types).
    By transforming document content into vector embeddings, File Search allows searches
    to understand context and meaning instead of simply matching exact keywords. This
    capability is especially useful for tasks such as detailed Q&A, summarization,
    and data extraction where nuanced understanding and quick retrieval are required.
    The tool is also versatile, handling a wide array of document formats to enable
    easy integration into workflows requiring complex document interactions.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文件搜索**：AOAI文件搜索工具允许助理通过访问和检索用户提供的文档中的信息来增强基于文件的查询处理。作为一个外部知识库，它让助理能够超越模型训练数据，检索专有内容或其他基于文档的信息。AOAI的系统会自动按切块策略将文档拆分，并通过创建向量嵌入并将其存储在由Azure
    AI Search支持的管理向量存储中来索引文档。这使得基于向量和关键词的搜索都可以进行，从而支持更精确、基于上下文的信息检索，支持各种格式，详情请见[https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/file-search?tabs=python#supported-file-types](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/file-search?tabs=python#supported-file-types)。通过将文档内容转化为向量嵌入，文件搜索使得搜索能够理解上下文和意义，而不仅仅是匹配确切的关键词。这一功能特别适用于需要细致理解和快速检索的任务，如详细的问答、总结和数据提取。该工具也非常灵活，可以处理各种文档格式，便于集成到需要复杂文档交互的工作流中。'
- en: '**Function calling**: This tool allows the assistant to invoke specific functions
    within an application, enabling it to execute tasks or retrieve data through API
    interfaces. We previously covered function calling in detail, highlighting its
    role in enhancing the assistant’s interactive capabilities.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**函数调用**：此工具允许助理调用应用程序中的特定函数，使其能够通过API接口执行任务或检索数据。我们之前已经详细介绍了函数调用，突出了它在增强助理互动能力方面的作用。'
- en: These tools make it easier to build dynamic and responsive AI assistants tailored
    to specific use cases within an application.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具使得构建针对应用程序中具体用例的动态和响应性AI助理变得更加容易。
- en: Now, let’s discuss the process flow assistants.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论助理的流程。
- en: Assistant process flow
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 助理流程
- en: 'Setting up and running an AI assistant such as a finance bot generally involves
    four key steps. Using the finance bot as an example, and as shown in *Figure 3**.15,*
    the steps are as follows:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 设置和运行一个AI助理（如财务机器人）通常涉及四个关键步骤。以财务机器人为例，如*图3.15*所示，步骤如下：
- en: '![Figure 3.15: AOAI assistants’ process flow](img/B21019_03_15.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图3.15：AOAI助理的流程](img/B21019_03_15.jpg)'
- en: 'Figure 3.15: AOAI assistants’ process flow'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.15：AOAI助理的流程
- en: Step 1 – create Assistants
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第1步——创建助理
- en: An Assistant is an entity that can be tailored to respond to user inputs using
    various parameters such as models, instructions, and tools. Assistants can use
    OpenAI models via AOAI and can be customized to suit different personalities or
    capabilities based on provided instructions. You can equip the Assistant with
    tools, either pre-built ones such as `code_interpreter` and `file_search`, or
    custom ones via function calling. These tools help the Assistant perform specific
    tasks based on the user’s queries. The Assistants API has support for several
    parameters that let you customize the Assistants’ output. The `tool_choice` parameter
    lets you force the Assistant to use a specified tool.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 助理是一个实体，可以通过各种参数（如模型、指令和工具）进行定制，以响应用户输入。助理可以通过AOAI使用OpenAI模型，并可以根据提供的指令定制以适应不同的个性或能力。你可以为助理配备工具，既可以是预先构建的工具，如`code_interpreter`和`file_search`，也可以通过函数调用提供自定义工具。这些工具帮助助理根据用户的查询执行特定任务。Assistants
    API支持多个参数，允许你定制助理的输出。`tool_choice`参数允许你强制助理使用指定的工具。
- en: Step 2 – create a Thread
  id: totrans-269
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第2步——创建线程
- en: A Thread acts as a record of the conversation between the user and one or more
    Assistants. When a user (or AI application) initiates a conversation, a new Thread
    is created. The assistant can access persistent Threads, enabling continuous conversation
    without losing context. This simplifies AI application development by retaining
    message history and managing memory efficiently by truncating older data when
    the conversation exceeds the model’s context window. A Thread is created once
    and updated as new messages are exchanged.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 线程（Thread）是用户与一个或多个助手之间对话的记录。当用户（或AI应用程序）发起对话时，会创建一个新的线程。助手可以访问持久化的线程，从而在不丢失上下文的情况下进行连续对话。这简化了AI应用程序的开发，通过保留消息历史并通过在对话超出模型的上下文窗口时截断较旧的数据，有效管理内存。线程一旦创建，就会随着新消息的交换而更新。
- en: Step 3 – add a message to the Thread
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 3 – 向线程添加一条消息
- en: The messages exchanged during the conversation, whether from the user or the
    application, are stored as **Message** objects within the Thread. These messages
    can include both text and files. While a Thread can store up to 100,000 messages,
    the system intelligently manages the conversation by automatically truncating
    any content that exceeds the model’s context window. Assistants are designed to
    truncate text automatically to ensure that the conversation stays within the model’s
    maximum token limit. However, you can adjust this behavior by specifying how many
    tokens or recent messages should be included in each Run.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在对话过程中交换的消息，无论是来自用户还是应用程序，都会作为**消息**对象存储在线程中。这些消息可以包含文本和文件。虽然线程可以存储最多100,000条消息，但系统通过智能管理对话，在超出模型上下文窗口时自动截断任何内容，确保助手自动截断文本以保证对话保持在模型的最大令牌限制内。然而，您可以通过指定每次运行应包含多少令牌或最近消息来调整此行为。
- en: To manage token usage during a single Run, you can set `max_prompt_tokens` and
    `max_completion_tokens` at the start. These limits apply to all completions made
    throughout the Run. For instance, if `max_prompt_tokens` is set to `500` and `max_completion_tokens`
    to `1000`, the assistant will first truncate the prompt to fit within 500 tokens
    and cap the output at 1,000 tokens. If only 200 tokens are used for the prompt
    and 300 tokens for the completion, the next completion will have 300 prompt tokens
    and 700 completion tokens available.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在单次运行中管理令牌使用量，可以在开始时设置`max_prompt_tokens`和`max_completion_tokens`。这些限制适用于整个运行过程中所有的补全。例如，如果将`max_prompt_tokens`设置为`500`，将`max_completion_tokens`设置为`1000`，助手首先会截断提示词，使其适应500个令牌，并将输出限制为1000个令牌。如果提示词只用了200个令牌，补全用了300个令牌，下一次补全将有300个提示词令牌和700个补全令牌可用。
- en: If the completion hits the `max_completion_tokens` limit, the Run will stop
    with an incomplete status, and the reason will be included in the `incomplete_details`
    field of the `Run` object.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 如果补全达到了`max_completion_tokens`的限制，运行将以不完整状态停止，并且原因将包含在`Run`对象的`incomplete_details`字段中。
- en: When using the File Search tool, it’s recommended to set `max_prompt_tokens`
    to no fewer than `20000`. For more extensive conversations or multiple interactions
    using File Search, consider increasing this limit to `50000` or even removing
    it entirely for optimal results.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用文件搜索工具时，建议将`max_prompt_tokens`设置为不少于`20000`。对于更大规模的对话或使用文件搜索的多个交互，考虑将此限制提高到`50000`，甚至完全去除该限制以获得最佳效果。
- en: 'You can also define a **truncation strategy** to control how the Thread should
    fit within the model’s context window:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以定义一个**截断策略**来控制线程如何适应模型的上下文窗口：
- en: Using the `auto` truncation strategy will apply OpenAI’s default truncation
    behavior
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`auto`截断策略将应用OpenAI的默认截断行为
- en: Using the `last_messages` strategy lets you specify how many of the most recent
    messages should be included in the context
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`last_messages`策略可以指定在上下文中包含多少条最近的消息。
- en: This approach gives you more control over managing conversation length and ensuring
    optimal performance in each Run.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法让你在管理对话长度和确保每次运行的最佳性能方面有更多控制权。
- en: Step 4 – create a Run
  id: totrans-280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 4 – 创建一个运行
- en: After all user messages are added to the Thread, the conversation is processed
    by initiating a Run. The Run utilizes the models and tools defined for the Assistant
    to generate a response. The assistant’s response is then added to the Thread as
    a new message, continuing the flow of conversation.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有用户消息添加到线程后，启动一个运行来处理对话。该运行利用为助手定义的模型和工具生成回应。然后，助手的回应作为新消息添加到线程中，继续对话的流程。
- en: Now that we’ve covered the assistant’s API process flow, let’s proceed with
    setting up the assistant.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经涵盖了助手的 API 流程，让我们继续设置助手。
- en: AOAI Assistants – code interpreter
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AOAI 助手 - 代码解释器
- en: 'In this section, we’ll guide you through the step-by-step process of setting
    up an assistant in the Azure AI Foundry Portal and demonstrate how to use the
    code interpreter tool to handle user queries on CSV data. You can achieve the
    same functionality with an API-based approach:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将指导您逐步完成在 Azure AI Foundry 门户中设置助手的过程，并演示如何使用代码解释器工具处理 CSV 数据上的用户查询。您也可以通过基于
    API 的方法实现相同的功能：
- en: Log in to the Azure AI Foundry Portal.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录 Azure AI Foundry 门户。
- en: If you haven’t yet set up a chat model, go to the **Deployments** section in
    the **Shared resources** menu. From there, initiate the deployment of a new chat
    model such as **GPT4-o**.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您尚未设置聊天模型，请转到 **共享资源** 菜单中的 **部署** 部分。从那里启动新聊天模型的部署，例如 **GPT4-o**。
- en: Navigate to the **Assistants from Playgrounds** menu, choose the **GPT4-o**
    deployment, and click **Create** **an assistant**.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到 **来自 Playground 的助手** 菜单，选择 **GPT4-o** 部署，并点击 **创建助手**。
- en: 'On the **Setup** page, you’ll see that an assistant ID has been created. Here,
    you can assign a name to the assistant and write custom instructions to clearly
    define its objectives, as shown here:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **设置** 页面，您会看到已经创建了一个助手 ID。在这里，您可以为助手指定名称并编写自定义指令，以明确其目标，如下所示：
- en: '![Figure 3.16: Assistant setup](img/B21019_03_16.jpg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.16：助手设置](img/B21019_03_16.jpg)'
- en: 'Figure 3.16: Assistant setup'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.16：助手设置
- en: 'In the **Tools** section, enable **Code Interpreter** and upload a CSV file
    to query. For this example, we’ll use a sample CSV file containing retail order
    data. A snippet of this file is shown here:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **工具** 部分，启用 **代码解释器** 并上传 CSV 文件以查询。对于此示例，我们将使用一个包含零售订单数据的示例 CSV 文件。该文件的一部分如下所示：
- en: '![Figure 3.17: Sample CSV file](img/B21019_03_17.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.17：CSV 文件示例](img/B21019_03_17.jpg)'
- en: 'Figure 3.17: Sample CSV file'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.17：CSV 文件示例
- en: 'Once the CSV data is uploaded, you can start by asking relevant queries. For
    example, you could ask: `"How many orders have been shipped so far?"`. Alternatively,
    you can also use the following prompt: `"Create a chart with order status on the
    x-axis and quantity on` `the y-axis."`.'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上传 CSV 数据后，您可以开始询问相关查询。例如，您可以询问：“`到目前为止已发货多少订单？`”。或者，您也可以使用以下提示：“`创建一个图表，横轴为订单状态，纵轴为数量。`”。
- en: 'For this type of question, the Code Interpreter tool will execute Python code
    within a Microsoft-managed sandbox environment and provide you with the results,
    as shown here:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种类型的问题，代码解释器工具将在 Microsoft 管理的沙箱环境中执行 Python 代码，并为您提供结果，如下所示：
- en: '![Figure 3.18: Output of Code Interpreter](img/B21019_03_18.jpg)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.18：代码解释器输出](img/B21019_03_18.jpg)'
- en: 'Figure 3.18: Output of Code Interpreter'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.18：代码解释器输出
- en: In the next section, we will cover how you can integrate File Search capabilities
    into the assistant using the SDK approach.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将介绍如何使用 SDK 方法将文件搜索功能集成到助手中。
- en: AOAI Assistants – File Search
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AOAI 助手 - 文件搜索
- en: 'Using the OpenAI SDK, you can directly program the assistant to search documents
    and extract specific function signatures as needed. File Search will let the Assistant
    parse, chunk, and index documents for efficient retrieval by leveraging the SDK.
    You can configure these tools seamlessly within your application, enhancing the
    assistant’s data retrieval and interactive capabilities:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 OpenAI SDK，您可以直接编程助手以搜索文档并根据需要提取特定的函数签名。文件搜索将使助手能够解析、分块并索引文档，以便通过 SDK 高效地检索。您可以在应用程序中无缝配置这些工具，从而增强助手的数据检索和交互能力：
- en: 'First, we need to create a new assistant with File Search as part of its set
    of tools, as shown here:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个新的助手，并将文件搜索作为其工具集的一部分，如下所示：
- en: '![Figure 3.19: Creating the Assistant](img/B21019_03_19.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.19：创建助手](img/B21019_03_19.jpg)'
- en: 'Figure 3.19: Creating the Assistant'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.19：创建助手
- en: 'Upload your files to enable automated chunking (with a chunk size of 800 tokens
    and a chunk overlap of 400 tokens). Embed and create a vector store that powers
    the file search tool, as shown here:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上传您的文件以启用自动分块（分块大小为 800 个标记，分块重叠为 400 个标记）。嵌入并创建一个向量存储，驱动文件搜索工具，如下所示：
- en: '![Figure 3.20: Vector store creation](img/B21019_03_20.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.20：向量存储创建](img/B21019_03_20.jpg)'
- en: 'Figure 3.20: Vector store creation'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.20：向量存储创建
- en: 'Attach the vector store to the assistant to give access to the files, as shown
    here:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将向量存储附加到助手上，以便访问文件，如下所示：
- en: '![Figure 3.21: Attaching vector store to the assistant](img/B21019_03_21.jpg)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![图3.21：将向量存储附加到助手](img/B21019_03_21.jpg)'
- en: 'Figure 3.21: Attaching vector store to the assistant'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.21：将向量存储附加到助手
- en: 'Create a thread and run the assistant, as shown here:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建线程并运行助手，如下所示：
- en: '![Figure 3.22: Create a thread and run](img/B21019_03_22.jpg)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![图3.22：创建线程并运行](img/B21019_03_22.jpg)'
- en: 'Figure 3.22: Create a thread and run'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.22：创建线程并运行
- en: 'Display the assistant response with citations, as shown here:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示带引用的助手响应，如下所示：
- en: '![Figure 3.23: Assistant response with citations](img/B21019_03_23.jpg)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![图3.23：带引用的助手响应](img/B21019_03_23.jpg)'
- en: 'Figure 3.23: Assistant response with citations'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.23：带引用的助手响应
- en: Now, you can see how simple it is to call the Assistant API with various tools
    such as File Search and Code Interpreter. Additionally, you can use the Assistant
    API to interact with external systems through the function calling feature. These
    assistants can take advantage of OpenAI’s advanced language models, utilize tools
    such as Code Interpreter and File Search, and retain context throughout conversations.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以看到如何使用各种工具（如文件搜索和代码解释器）简单地调用助手API。此外，你还可以通过函数调用功能使用助手API与外部系统进行交互。这些助手能够利用OpenAI的先进语言模型，使用如代码解释器和文件搜索等工具，并在整个对话过程中保持上下文。
- en: In the next section, we will discuss AOAI Batch, which is designed for use cases
    that do not require real-time processing.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将讨论AOAI批处理，它是为不需要实时处理的用例设计的。
- en: AOAI Batch API
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AOAI批处理API
- en: 'Some applications require synchronous request handling, also known as real-time
    inferencing, where immediate responses are necessary. However, there are numerous
    situations wherein responses can be deferred or rate limits may restrict the speed
    at which multiple queries can be processed. In such cases, batch processing jobs
    prove useful, particularly for tasks such as the following:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 一些应用需要同步请求处理，也叫实时推理，要求立即响应。然而，也有许多情况下响应可以延迟，或者速率限制可能会限制多个查询处理的速度。在这种情况下，批处理作业显得特别有用，尤其是在以下任务中：
- en: Large-scale data processing
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大规模数据处理
- en: Generating large volumes of content transforming data at scale
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成大量内容并进行大规模数据转换
- en: Evaluating LLM models and assess comprehensive performance
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估LLM模型并全面评估性能
- en: The AOAI Batch API provides a user-friendly suite of endpoints. These allow
    you to bundle multiple requests into a single file, initiate a batch job to process
    these requests asynchronously, check the batch’s status as the tasks run, and,
    finally, retrieve the consolidated results once processing is complete.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI批处理API提供了一套用户友好的端点。这些端点允许你将多个请求打包成一个文件，启动一个批处理作业以异步处理这些请求，检查批处理的状态并运行任务，最后在处理完成后获取合并的结果。
- en: 'Compared to traditional PAUG deployments, the Batch API offers the following:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 相较于传统的PAUG部署，批处理API提供了以下优势：
- en: '**Cost efficiency**: Provides a 50% cost reduction relative to standard PAUG
    deployment'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本效益**：相对于标准的PAUG部署，提供50%的成本减少'
- en: '**Dedicated quota**: Operates with a separate enqueued token quota, distinct
    from the online endpoint quota, ensuring that online workloads remain unaffected;
    the batch quota is also significantly larger'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专用配额**：使用单独排队的令牌配额，与在线端点配额不同，确保在线工作负载不受影响；批处理配额也显著更大'
- en: '**24-hour turnaround**: Each batch completes within 24 hours, often achieving
    results even faster'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**24小时周转**：每个批处理在24小时内完成，通常能更快地获得结果'
- en: 'Submitting a batch and retrieving the results involves a six-step process.
    Let’s go through each step in detail:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 提交批处理并获取结果涉及六个步骤。让我们详细了解每个步骤：
- en: '**Batch deployment creation**: You need to first create a separate deployment
    for the batch. To do that, follow these steps:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**批处理部署创建**：你需要首先为批处理创建一个单独的部署。为此，请按照以下步骤操作：'
- en: Log in to Azure AI Foundry.
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到Azure AI Foundry。
- en: Navigate to **Deployments** under **Shared resources**.
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航至**部署**下的**共享资源**。
- en: Click on **Deploy model** and choose **Deploy** **base model**.
  id: totrans-332
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**部署模型**并选择**部署基础模型**。
- en: Choose any chat completion model such as gpt-4o-mini and click **Confirm**.
  id: totrans-333
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择任何聊天完成模型，如gpt-4o-mini，并点击**确认**。
- en: Provide a value under **Deployment name**, set the **Deployment** type to **Global
    Batch**, adjust the **Enqueued tokens** value to the max limit, and click **Deploy**.
  id: totrans-334
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**部署名称**下提供一个值，将**部署**类型设置为**全局批处理**，将**排队令牌**值调整为最大限制，然后点击**部署**。
- en: '![Figure 3.24: Batch deployment](img/B21019_03_24.jpg)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.24：批处理部署](img/B21019_03_24.jpg)'
- en: 'Figure 3.24: Batch deployment'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.24：批处理部署
- en: You can also toggle **Enable dynamic quota**, which allows you to utilize additional
    quota when extra capacity is available.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以切换**启用动态配额**，当有额外容量可用时，它允许您使用更多配额。
- en: After completing the preceding steps, your **Global Batch** deployment will
    be created. This deployment will then be used to run the batch job.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 完成前面的步骤后，您的**全局批处理**部署将会创建。然后，这个部署将用于运行批处理任务。
- en: '`.jsonl` file, where each line specifies the details of an individual API request.
    Currently, the supported endpoints are `/chat/completions` (for the Chat Completions
    API).'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`.jsonl` 文件，其中每一行指定一个单独 API 请求的详细信息。目前，支持的端点是`/chat/completions`（用于聊天完成 API）。'
- en: In this input file, the parameters in the body field of each line should match
    the parameters for the corresponding endpoint. Each request must include a unique
    `custom_id` value, which will help reference the results once processing is complete.
    The `model` name in the file should match the deployment name you created in the
    previous step.
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在此输入文件中，每行的正文字段中的参数应与相应端点的参数匹配。每个请求必须包含一个唯一的`custom_id`值，该值有助于在处理完成后引用结果。文件中的`model`名称应与您在前一步骤中创建的部署名称匹配。
- en: 'The following is an example of an input file, as shown below, containing three
    requests. Each input file must be limited to requests for a single model only:'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是一个输入文件的示例，如下所示，包含三个请求。每个输入文件必须仅限于单一模型的请求：
- en: '![Figure 3.25: Batch input .jsonl file](img/B21019_03_25.jpg)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.25：批处理输入 .jsonl 文件](img/B21019_03_25.jpg)'
- en: 'Figure 3.25: Batch input .jsonl file'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.25：批处理输入 .jsonl 文件
- en: '**Upload a batch input file**: After preparing your input file, you’ll need
    to upload it before starting a batch job. You can upload the file either programmatically
    or through the **Studio** interface. In this example, we are using the Python
    SDK approach to upload the file from the local drive. See *Figure 3**.26* for
    reference.'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**上传批处理输入文件**：在准备好输入文件后，您需要上传它才能启动批处理任务。您可以通过编程方式或通过**Studio**界面上传文件。在此示例中，我们使用
    Python SDK 方法从本地驱动器上传文件。请参见*图 3.26*以获取参考。'
- en: '![Figure 3.26: Batch file upload](img/B21019_03_26.jpg)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.26：批处理文件上传](img/B21019_03_26.jpg)'
- en: 'Figure 3.26: Batch file upload'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.26：批处理文件上传
- en: '`File` object to initiate a batch. In this example, the file ID is `file-0a27a5cd4d94440789971497e6d80391`.
    Currently, the completion window is fixed at 24 hours. You can also include custom
    metadata using the optional `metadata` parameter, as shown in *Figure 3**.27*.'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`File` 对象用于启动批处理。在此示例中，文件 ID 为`file-0a27a5cd4d94440789971497e6d80391`。目前，完成窗口固定为
    24 小时。您还可以使用可选的`metadata`参数包含自定义元数据，如*图 3.27*所示。'
- en: This will return a batch object with a batch ID and status field. You can find
    the complete details of the batch object at [https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch?tabs=standard-input%2Cpython-key&pivots=programming-language-python#batch-object](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch?tabs=standard-input%2Cpython-key&pivots=programming-language-python#batch-object).
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将返回一个批处理对象，包含批处理 ID 和状态字段。您可以在[https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch?tabs=standard-input%2Cpython-key&pivots=programming-language-python#batch-object](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch?tabs=standard-input%2Cpython-key&pivots=programming-language-python#batch-object)中查看批处理对象的完整详情。
- en: '![Figure 3.27: Batch job submission](img/B21019_03_27.jpg)'
  id: totrans-349
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.27：批处理任务提交](img/B21019_03_27.jpg)'
- en: 'Figure 3.27: Batch job submission'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.27：批处理任务提交
- en: '**Track the batch job status**: After successfully creating the batch job,
    you can monitor its progress either through **Studio** or programmatically. When
    checking the status, it is recommended to wait at least 60 seconds between each
    status call, as shown in *Figure 3**.28*.'
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**跟踪批处理任务状态**：成功创建批处理任务后，您可以通过**Studio**或编程方式监控其进度。在检查状态时，建议每次状态调用之间等待至少 60
    秒，如*图 3.28*所示。'
- en: '![Figure 3.28: Batch job status check](img/B21019_03_28.jpg)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.28：批处理任务状态检查](img/B21019_03_28.jpg)'
- en: 'Figure 3.28: Batch job status check'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.28：批处理任务状态检查
- en: The status of a given Batch object can be any of the following shown in *Table
    3.1*.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 给定批处理对象的状态可以是下表中显示的任何一种状态，见*表 3.1*。
- en: '| **Status** | **Description** |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| **Status** | **Description** |'
- en: '| --- | --- |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `validating` | The input file is being validated before the batch can start
    |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| `validating` | 输入文件正在验证中，批处理才能开始 |'
- en: '| `failed` | The input file failed the validation process |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
  zh: '| `failed` | 输入文件未通过验证过程 |'
- en: '| `in_progress` | The input file was validated successfully, and the batch
    is running |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| `in_progress` | 输入文件已成功验证，批处理正在运行 |'
- en: '| `finalizing` | The batch has finished, and the results are being prepared
    |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| `finalizing` | 批处理已完成，结果正在准备中 |'
- en: '| `completed` | The batch has been completed, and the results are ready |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| `completed` | 批处理已完成，结果已准备好 |'
- en: '| `expired` | The batch was not completed within the 24-hour time frame |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| `expired` | 批处理未在 24 小时内完成 |'
- en: '| `cancelling` | The batch is in the process of being canceled (may take up
    to 10 minutes) |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| `cancelling` | 批处理正在取消中（可能需要最多 10 分钟） |'
- en: '| `cancelled` | The batch was canceled |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| `cancelled` | 批处理已取消 |'
- en: 'Table 3.1: Batch job status table'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.1：批处理作业状态表
- en: '`output_file_id` from the `Batch` object. Then save it to a file on your machine,
    such as `batch_output.jsonl`. The `output .jsonl` file will contain one response
    per successful request from the input file. Any failed requests will include their
    error details in a separate error file, accessible via the batch’s `error_file_id`.'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `Batch` 对象中获取 `output_file_id`。然后将其保存为您计算机上的文件，例如 `batch_output.jsonl`。`output.jsonl`
    文件将包含每个成功请求的响应。任何失败的请求将在单独的错误文件中包含其错误详情，该文件可以通过批处理的 `error_file_id` 访问。
- en: Important note
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The order of output lines may not match the input order. Instead of relying
    on the sequence, use the `custom_id` field present in each output line to correlate
    input requests with their corresponding results.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 输出行的顺序可能与输入顺序不匹配。请不要依赖顺序，而应使用每个输出行中的 `custom_id` 字段，将输入请求与其对应的结果关联。
- en: '![Figure 3.29: Retrieving the output file](img/B21019_03_29.jpg)'
  id: totrans-369
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.29：检索输出文件](img/B21019_03_29.jpg)'
- en: 'Figure 3.29: Retrieving the output file'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.29：检索输出文件
- en: By following the steps outlined, you can submit batch jobs manually.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 通过按照上述步骤操作，您可以手动提交批处理作业。
- en: 'While these steps are suitable for demonstration purposes, enterprises with
    millions of files in a blob storage account will require an automated solution
    to submit batches and retrieve results efficiently. For such cases, you can use
    the following solution accelerator:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些步骤适用于演示目的，但对于存储帐户中有数百万个文件的企业来说，仍然需要一个自动化解决方案来有效地提交批处理并检索结果。在这种情况下，您可以使用以下解决方案加速器：
- en: '[https://github.com/Azure-Samples/aoai-batch-api-accelerator](https://github.com/Azure-Samples/aoai-batch-api-accelerator)'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/Azure-Samples/aoai-batch-api-accelerator](https://github.com/Azure-Samples/aoai-batch-api-accelerator)'
- en: The AOAI Batch API has certain service limits, which can be found at [https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch?tabs=standard-input%2Cpython-key&pivots=programming-language-python#global-batch-limits](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch?tabs=standard-input%2Cpython-key&pivots=programming-language-python#global-batch-limits).
    Quota limits are outlined at [https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch?tabs=standard-input%2Cpython-key&pivots=programming-language-python#global-batch-quota](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch?tabs=standard-input%2Cpython-key&pivots=programming-language-python#global-batch-quota).
    These limits can be increased based on your workload; to request an increase,
    you will need to contact Microsoft.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI 批处理 API 有一定的服务限制，可以在 [https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch?tabs=standard-input%2Cpython-key&pivots=programming-language-python#global-batch-limits](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch?tabs=standard-input%2Cpython-key&pivots=programming-language-python#global-batch-limits)
    查找。配额限制详见 [https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch?tabs=standard-input%2Cpython-key&pivots=programming-language-python#global-batch-quota](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/batch?tabs=standard-input%2Cpython-key&pivots=programming-language-python#global-batch-quota)。这些限制可以根据您的工作负载进行增加；如果需要增加配额，请联系微软。
- en: You can also process images in bulk using the AOAI Batch API. This feature is
    available with specific multi-modal models, and currently, only GPT-4o supports
    images in batch requests. Images can be provided either as a URL or as base64-encoded
    data. Note that GPT-4 Turbo does not support image inputs for batch processing
    at this time.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用 AOAI 批处理 API 批量处理图像。此功能适用于特定的多模态模型，目前只有 GPT-4o 支持批量请求中的图像。图像可以通过 URL
    或 Base64 编码的数据提供。请注意，GPT-4 Turbo 当前不支持批处理中的图像输入。
- en: AOAI batch processing is global by nature, meaning data processing could occur
    anywhere in the world. This may raise concern for industries with strict regulatory
    requirements. However, you can select a data zone for the AOAI Batch, which restricts
    data processing to specific geos. By choosing the US data zone, processing will
    occur in one of the US regions, and by selecting the EU data zone, processing
    will take place in one of the EU regions. This ensures enterprises can comply
    with data compliance and regulatory requirements.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI批处理具有全球性质，这意味着数据处理可能发生在世界任何地方。这可能会引发那些有严格法规要求的行业的关注。然而，你可以为AOAI批处理选择数据区域，限制数据处理仅在特定地区进行。通过选择美国数据区，处理将在美国的某个区域进行；选择欧盟数据区，处理则会在欧盟的某个区域进行。这确保了企业可以遵守数据合规和监管要求。
- en: Now that we’ve covered the AOAI Batch API, the next section will focus on fine-tuning,
    which allows you to customize your model for specific tasks.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讲解了AOAI批量API，接下来的部分将聚焦于微调，它使你能够根据特定任务定制模型。
- en: AOAI fine-tuning
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AOAI微调
- en: 'Fine-tuning allows you to maximize the potential of models available through
    the Azure AI Foundry or API by providing the following:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 微调使你能够通过以下方式最大化Azure AI Foundry或API提供的模型潜力：
- en: Improved response quality compared to basic prompting alone
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与仅使用基本提示相比，响应质量得到改进
- en: The capability to train on larger datasets, surpassing the limitations model
    context window
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 能够在更大的数据集上进行训练，突破了模型上下文窗口的限制
- en: Reduced token usage by minimizing the prompt length
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过最小化提示长度减少令牌使用
- en: Faster response times with lower-latency requests
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更快速的响应时间和更低延迟的请求
- en: AOAI’s text generation models are pre-trained on an extensive corpus of text
    data. To use them effectively, users often include instructions and example cases
    in prompts—a method known as **few-shot learning**. Few-shot learning demonstrates
    how to complete a task by showing a small number of examples within the prompt
    itself.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI的文本生成模型是基于大量文本数据预训练的。为了有效使用这些模型，用户通常会在提示中加入指令和示例案例——这种方法被称为**少量示例学习**。少量示例学习通过在提示中展示少量示例来演示如何完成任务。
- en: Fine-tuning enhances the few-shot approach by training the model on significantly
    more examples than could fit into a single prompt, thereby improving performance
    across a wider range of tasks. After a model is fine-tuned, fewer examples are
    typically needed in the prompt, which reduces token costs and further lowers response
    latency.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 微调通过在模型上训练更多的示例数据来增强少量示例法，从而在更广泛的任务中提升性能，而这些数据无法完全包含在单个提示中。经过微调后，通常在提示中所需的示例较少，这样不仅减少了令牌使用量，还进一步降低了响应延迟。
- en: Ideal situation to leverage fine-tuning
  id: totrans-386
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 利用微调的理想情况
- en: 'When evaluating whether fine-tuning is the appropriate approach for a specific
    use case, it’s beneficial to understand some foundational concepts:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估微调是否适用于特定用例时，理解一些基础概念是有益的：
- en: '**Prompt engineering**: This technique involves crafting prompts for natural
    language processing models with precision. By designing prompts carefully, users
    can improve the accuracy and relevance of model responses, enhancing overall performance.
    Chapter 13 provides an in-depth exploration of various prompt engineering techniques.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示工程**：该技术涉及精确地为自然语言处理模型设计提示。通过仔细设计提示，用户可以提高模型响应的准确性和相关性，从而提升整体性能。第13章深入探讨了各种提示工程技术。'
- en: '**RAG**: RAG enhances the effectiveness of LLMs by integrating external data
    into the prompt. By retrieving relevant information from outside sources, RAG
    enables businesses to create tailored solutions that are both cost-effective and
    contextually accurate.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RAG**：RAG通过将外部数据集成到提示中，增强了LLM的效果。通过从外部来源检索相关信息，RAG使企业能够创造量身定制的解决方案，这些解决方案既具有成本效益，又在上下文上更加准确。'
- en: '**Fine-tuning**: Fine-tuning involves adapting an existing LLM by retraining
    it on specific example data, resulting in a *custom* model that is fine-tuned
    to reflect the nuances and requirements of the provided examples data set.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微调**：微调是通过在特定示例数据上重新训练现有的LLM，从而调整其以反映提供的示例数据集的细微差别和要求，结果是一个*定制化*的模型。'
- en: AOAI fine-tuning is a **supervised fine-tuning** process, as opposed to continuous
    pre-training or **Reinforcement Learning Through Human Feedback** (**RLHF**).
    Supervised fine-tuning involves retraining pre-trained models on carefully selected
    datasets to enhance performance on particular tasks. We recommend starting with
    techniques such as prompt engineering, prompt chaining (dividing complex tasks
    into smaller, manageable prompts), and utilizing function calling to achieve optimal
    results.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI微调是一个**监督微调**过程，与持续预训练或**通过人类反馈强化学习**（**RLHF**）不同。监督微调涉及在精心选择的数据集上重新训练预训练模型，以提高在特定任务上的表现。我们建议从提示工程、提示链（将复杂任务分解为更小、更易管理的提示）和利用函数调用等技术开始，以实现最佳效果。
- en: AOAI uses **Low-Rank Approximation** (**LoRA**) to fine-tune models efficiently
    by lowering their complexity with minimal impact on performance. This approach
    approximates the model’s original high-dimensional matrix using a lower-dimensional
    one, allowing only a subset of key parameters to be fine-tuned during supervised
    training. By focusing on these *essential* parameters, the model remains both
    efficient and easier to manage. For users, this results in faster training and
    more cost-effective fine-tuning compared to traditional methods.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI使用**低秩近似**（**LoRA**）通过降低模型复杂度，且对性能影响最小，来高效地微调模型。该方法通过使用低维矩阵来近似模型原始的高维矩阵，允许在监督训练过程中仅对部分关键参数进行微调。通过专注于这些*关键*参数，模型保持了高效性并更易于管理。对于用户而言，与传统方法相比，这将带来更快速的训练和更具成本效益的微调。
- en: 'Fine-tuning is a sophisticated process that demands a solid domain and data
    understanding to apply effectively. The five common questions that follow are
    designed to help you assess your readiness for fine-tuning, guiding you through
    key considerations and helping you decide whether fine-tuning is the best approach
    or whether alternative methods may be more suitable:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 微调是一个复杂的过程，要求有扎实的领域和数据理解才能有效应用。接下来五个常见问题旨在帮助您评估是否准备好进行微调，指导您考虑关键因素，并帮助您决定微调是否是最佳方法，或是否有更适合的替代方法：
- en: '**Why fine-tune** **a model?**'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**为什么微调** **一个模型？**'
- en: To proceed effectively with fine-tuning, you should clearly define a specific
    use case and identify the model you intend to fine-tune. Good candidates for fine-tuning
    include situations where you need the model to produce outputs in a particular
    style, tone, or format or when the instructions or data needed to guide the model
    are too complex or lengthy to fit into a standard prompt.
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了有效进行微调，您应该清晰定义具体的应用场景，并识别您打算微调的模型。适合微调的情况包括需要模型以特定风格、语气或格式输出，或者当用于指导模型的指令或数据过于复杂或冗长，无法放入标准提示中时。
- en: 'Here are some indicators that you may not be ready for fine-tuning yet:'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是一些表明您可能还没有准备好进行微调的指标：
- en: '**Unclear use case**: If you can’t articulate a clear purpose beyond *I want
    to improve a model*, fine-tuning may not be the right next step.'
  id: totrans-397
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用例不明确**：如果您无法清楚地表达出一个明确的目的，除了*我想要改进模型*之外，微调可能不是下一步正确的选择。'
- en: '**Cost-driven motivation**: Fine-tuning can reduce costs in cases where it
    allows for shorter prompts or smaller model usage. However, it also involves an
    upfront cost for training and hosting a custom model. Be mindful of these expenses
    and refer to AOAI’s pricing page for more detail on fine-tuning costs.'
  id: totrans-398
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本驱动的动机**：微调可以在允许使用更短提示或更小模型的情况下减少成本。然而，它也涉及到为训练和托管定制模型的前期成本。请留意这些费用，并参考AOAI的定价页面，了解更多关于微调成本的细节。'
- en: '**Out-of-domain knowledge needs**: If your primary goal is to incorporate information
    beyond the model’s original training scope, consider starting with RAG. AOAI’s
    RAG features, such as embedding-based retrieval on your data, can offer a more
    flexible and often more affordable solution depending on your specific data and
    objectives.'
  id: totrans-399
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超出领域的知识需求**：如果您的主要目标是将超出模型原始训练范围的信息整合进来，考虑从RAG开始。AOAI的RAG功能，例如基于嵌入的检索，可以根据您的具体数据和目标提供更加灵活且通常更具成本效益的解决方案。'
- en: '**What have you tried** **so far?**'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**您到目前为止** **尝试了什么？**'
- en: Fine-tuning is an advanced capability and is not typically the first step in
    working with generative AI. It’s essential to be familiar with the fundamentals
    of LLMs and to start by testing the model’s performance with prompt engineering
    and/or RAG. These techniques help you establish a baseline performance level,
    which is critical for evaluating whether fine-tuning has genuinely improved your
    model.
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 微调是一项高级功能，通常不是与生成性AI合作的第一步。你需要熟悉LLM的基础知识，并从测试模型性能、使用提示工程和/或RAG开始。这些技术帮助你建立一个基准性能水平，这对于评估微调是否真正提升了模型非常重要。
- en: 'A performance baseline without fine-tuning also serves as a safeguard: it helps
    detect any negative impacts from fine-tuning, as poorly prepared training data
    can degrade model quality.'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 没有微调的性能基准也起到了保障作用：它有助于检测微调带来的负面影响，因为准备不充分的训练数据可能会降低模型质量。
- en: 'Let’s look at some key indicators that you’re ready for fine-tuning:'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们来看一些你准备好进行微调的关键指标：
- en: '**Experience with prompt engineering and RAG**: You should be able to demonstrate
    knowledge and results from prompt engineering or RAG-based approaches'
  id: totrans-404
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有提示工程和RAG经验**：你应该能够展示来自提示工程或基于RAG方法的知识和结果'
- en: '**Documented challenges and use case testing**: Have specific examples of where
    prompt engineering or RAG fell short in your use case'
  id: totrans-405
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文档化的挑战和应用案例测试**：有具体的例子表明在你的应用案例中，提示工程或RAG未能达到预期效果'
- en: '**Quantitative baseline assessments**: Whenever possible, have measurable benchmarks
    of model performance without fine-tuning'
  id: totrans-406
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**量化基准评估**：在可能的情况下，确保有可衡量的模型性能基准，且没有微调'
- en: 'Next, let’s look at some common signs fine-tuning may not be suitable yet:'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 接下来，让我们看看一些常见的微调可能还不适合的迹象：
- en: Starting with fine-tuning without testing other available techniques
  id: totrans-408
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从没有测试其他可用技术的微调开始
- en: Lacking a clear understanding of how fine-tuning specifically enhances LLMs
  id: totrans-409
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏对微调如何具体增强LLM的清晰理解
- en: No benchmark data to measure the impact of fine-tuning
  id: totrans-410
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有基准数据来衡量微调的影响
- en: '`Always return SQL` in the prompt and used RAG to retrieve the database schema,
    the model often produced incorrect syntax, particularly in edge cases. To address
    this, they gathered thousands of examples of questions and their equivalent database
    queries, including previous model failures, and used this data to fine-tune the
    model. The resulting fine-tuned model, combined with their engineered prompt and
    retrieval setup, achieved the accuracy needed for real-world application.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在提示中`始终返回SQL`并使用RAG来检索数据库架构时，模型常常产生不正确的语法，尤其是在边缘案例中。为了解决这个问题，他们收集了数千个问题及其等效的数据库查询的示例，包括先前模型的失败，并用这些数据来微调模型。结果，经过微调的模型，结合他们工程化的提示和检索设置，达到了实际应用所需的准确性。
- en: 'Here are some indicators that you’re ready for fine-tuning:'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里有一些你准备好进行微调的指标：
- en: '**Documented examples of previous attempts**: You have tested various prompt
    engineering or RAG solutions and documented specific limitations.'
  id: totrans-413
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**先前尝试的文档化示例**：你已经测试了各种提示工程或RAG解决方案，并记录了具体的限制。'
- en: '**Identified model shortcomings**: These could include inconsistent handling
    of edge cases, an inability to include enough few-shot prompts within the context
    window, or issues with latency'
  id: totrans-414
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**识别模型短板**：这些可能包括边缘案例处理不一致、无法在上下文窗口内包含足够的少量提示，或延迟问题'
- en: 'On the other hand, here are some signs that you may need to wait before fine-tuning:'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另一方面，这里有一些迹象表明你可能需要等一等，才能进行微调：
- en: Lack of in-depth understanding of the model’s limitations or the data needed
  id: totrans-416
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏对模型限制或所需数据的深入理解
- en: Difficulty identifying suitable data to train the model effectively
  id: totrans-417
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 难以识别合适的数据来有效地训练模型
- en: '**What data will you use** **for fine-tuning?**'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**你将使用什么数据** **进行微调？**'
- en: Even with a strong use case, the success of fine-tuning largely depends on the
    quality of the data you provide. It’s crucial to invest the necessary time and
    resources into gathering high-quality, curated data. Different models may require
    varying volumes of data, but in most cases, you will need to provide a large quantity
    of well-curated examples to achieve meaningful improvements.
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 即使有强有力的应用案例，微调的成功在很大程度上取决于你提供的数据质量。必须投入必要的时间和资源来收集高质量、精心整理的数据。不同的模型可能需要不同量的数据，但在大多数情况下，你需要提供大量精心整理的示例，以实现有意义的改进。
- en: In addition to data quality, the format of the data is equally important. Even
    high-quality data may require significant effort to format properly for fine-tuning.
    This may involve allocating engineering resources to ensure the data is structured
    correctly.
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 除了数据质量外，数据格式同样重要。即使是高质量的数据，也可能需要付出大量努力才能正确格式化以进行微调。这可能需要分配工程资源以确保数据结构正确。
- en: 'Some indicators that you’re ready for fine-tuning include the following:'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一些你已准备好进行微调的迹象包括：
- en: '**Identified dataset**: You have already selected the dataset you intend to
    use for fine-tuning'
  id: totrans-422
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**已选择数据集**：你已经选择了打算用于微调的数据集。'
- en: '**Correct format**: The dataset is structured in the appropriate format for
    the chosen model'
  id: totrans-423
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正确格式**：数据集按选定模型的要求正确构建。'
- en: '**Curation effort**: Some level of dataset curation has been applied to ensure
    the data’s quality'
  id: totrans-424
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据策划工作**：已经对数据进行了一定程度的策划，以确保数据的质量。'
- en: 'On the other hand, here are some common signs you may not be ready for fine-tuning:'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另一方面，以下是一些你可能还没有准备好进行微调的常见迹象：
- en: '**No dataset identified**: You have not yet chosen the dataset for fine-tuning'
  id: totrans-426
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未选择数据集**：你还没有选择用于微调的数据集。'
- en: '**Incorrect format**: The dataset format does not align with the requirements
    of the model you intend to fine-tune.'
  id: totrans-427
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**格式不正确**：数据集格式与您打算微调的模型要求不符。'
- en: '**How will you measure the quality of your** **fine-tuned model?**'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**你将如何衡量你的** **微调模型的质量？**'
- en: There’s no one-size-fits-all approach to measuring the success of a fine-tuned
    model, but it’s essential to have clear, well-defined goals. Success should not
    only be evaluated qualitatively but also include quantitative metrics. A good
    approach is to use a *holdout validation dataset* to assess performance objectively.
    Additionally, you can enhance your evaluation by conducting *user acceptance testing*
    or performing *A/B testing*, comparing the fine-tuned model to the base model
    to see whether the improvements meet your expectations.
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 没有一种通用的方法来衡量微调模型的成功，但明确且清晰的目标是至关重要的。成功不仅应该进行定性评估，还应包括定量指标。一种好的方法是使用*保留验证数据集*来客观评估性能。此外，你还可以通过进行*用户接受度测试*或执行*A/B测试*，将微调模型与基础模型进行比较，看看改进是否达到了预期。
- en: To optimize the model’s context, you should explore techniques such as prompt
    engineering and RAG. For optimizing the LLM itself, focus on prompt engineering
    followed by fine-tuning, as illustrated in *Figure 3**.30*.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化模型的上下文，你应探索如提示工程和RAG等技术。对于优化LLM本身，重点应放在提示工程和随后的微调上，如*图3.30*所示。
- en: '![Figure 3.30: Optimizing LLM accuracy](img/B21019_03_30.jpg)'
  id: totrans-431
  prefs: []
  type: TYPE_IMG
  zh: '![图3.30：优化LLM准确度](img/B21019_03_30.jpg)'
- en: 'Figure 3.30: Optimizing LLM accuracy'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.30：优化LLM准确度
- en: Once you’ve identified fine-tuning as the appropriate strategy, you can follow
    the steps detailed in the subsequent section to effectively fine-tune the model.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定微调是合适的策略，你可以按照后续章节中详细的步骤来有效地微调模型。
- en: Fine-tuning steps
  id: totrans-434
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微调步骤
- en: 'At a high level, the fine-tuning process includes the following steps:'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，微调过程包括以下步骤：
- en: Prepare and upload training data.
  id: totrans-436
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备并上传训练数据。
- en: Train a new fine-tuned model.
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练一个新的微调模型。
- en: Conduct a safety evaluation.
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行安全评估。
- en: Conduct a model performance evaluation.
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进行模型性能评估。
- en: Deploy the fine-tuned model.
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署微调后的模型。
- en: 'Let’s go through each step in detail:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细了解每个步骤：
- en: '**Preparing and uploading training data**: Your training and validation datasets
    should include input and output examples that demonstrate the desired model behavior.
    These datasets must be formatted as **JSON Lines** (**JSONL**) documents. For
    models such as gpt-3.5-turbo (all versions), gpt-4, gpt-4o, and gpt-4o-mini, the
    fine-tuning data should adhere to the conversational format used by the Chat completions
    API. Here is the sample format:'
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准备并上传训练数据**：你的训练和验证数据集应包含能够展示所需模型行为的输入和输出示例。这些数据集必须采用**JSON Lines**（**JSONL**）文档格式。对于如gpt-3.5-turbo（所有版本）、gpt-4、gpt-4o和gpt-4o-mini等模型，微调数据应遵循Chat
    completions API使用的对话格式。以下是示例格式：'
- en: '| {“messages“: [{“role”: “system”, “content”: “You are an Ontoso customer support
    agent who helps customers with issues related to their Ontoso accounts and services.
    You are friendly and concise. You only provide factual answers to queries related
    to Ontoso.”}, {“role”: “user”, “content”: “I need help with my Ontoso account.
    I forgot my password.”}, {“role”: “assistant”, “content”: “Hi! I’m happy to help.
    Please provide your registered email address, and I’ll guide you through resetting
    your password.”}]}{“messages”: [{“role”: “system”, “content”: “You are an Ontoso
    customer support agent who helps customers with issues related to their Ontoso
    accounts and services. You are friendly and concise. You only provide factual
    answers to queries related to Ontoso.”}, {“role”: “user”, “content”: “Can I track
    my order on Ontoso?”}, {“role”: “assistant”, “content”: “Yes, you can track your
    order by logging into your Ontoso account and checking the ‘Order History’ section.
    There, you can see the status of your current and past orders.”}]} |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| {“messages“: [{“role”: “system”, “content”: “你是 Ontoso 客户支持代理，帮助客户解决与 Ontoso
    账户和服务相关的问题。你友好且简洁，只提供与 Ontoso 相关的事实性答案。”}, {“role”: “user”, “content”: “我需要帮助恢复我的
    Ontoso 账户。我忘记了密码。”}, {“role”: “assistant”, “content”: “你好！我很高兴为你提供帮助。请提供你的注册邮箱地址，我将引导你重置密码。”}]}{“messages”:
    [{“role”: “system”, “content”: “你是 Ontoso 客户支持代理，帮助客户解决与 Ontoso 账户和服务相关的问题。你友好且简洁，只提供与
    Ontoso 相关的事实性答案。”}, {“role”: “user”, “content”: “我可以在 Ontoso 上追踪我的订单吗？”}, {“role”:
    “assistant”, “content”: “是的，你可以通过登录 Ontoso 账户并查看‘订单历史’部分来追踪订单。在那里，你可以查看当前和过去订单的状态。”}]}
    |'
- en: 'Table 3.2: Sample training data JSONL format'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.2：示例训练数据 JSONL 格式
- en: Besides being in JSONL format, the training and validation data files must be
    encoded in UTF-8 with a **byte-order mark** (**BOM**). Additionally, the file
    size must not exceed 512 MB.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 除了采用 JSONL 格式，训练和验证数据文件必须使用带有**字节顺序标记**（**BOM**）的 UTF-8 编码。此外，文件大小不得超过 512 MB。
- en: 'You can also include multiple turns of a conversation in a single line of your
    JSONL training file. To exclude specific assistant messages from fine-tuning,
    you can add the optional weight key-value pair. Currently, the weight can be set
    to either `0` or `1`. Here is another multiturn sample format:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在 JSONL 训练文件的单一行中包含多轮对话。要排除特定的助手消息不参与微调，你可以添加可选的 weight 键值对。目前，weight 可以设置为
    `0` 或 `1`。以下是另一个多轮示例格式：
- en: '| {“messages”: [{“role”: “system”, “content”: “You are a Contoso customer support
    agent who is friendly and concise, but also has a sarcastic tone.”}, {“role”:
    “user”, “content”: “What are your business hours?”}, {“role”: “assistant”, “content”:
    “Our business hours are 9 AM to 5 PM, Monday through Friday.”, “weight”: 0}, {“role”:
    “user”, “content”: “Can you be more sarcastic?”}, {“role”: “assistant”, “content”:
    “Sure, we’re open during the highly unconventional hours of 9 AM to 5 PM, Monday
    through Friday. A real shocker, right?”, “weight”: 1}]}{“messages”: [{“role”:
    “system”, “content”: “You are a Contoso customer support agent who is friendly
    and concise, but also has a sarcastic tone.”}, {“role”: “user”, “content”: “How
    do I reset my password?”}, {“role”: “assistant”, “content”: “You can reset your
    password by clicking the ‘Forgot Password’ link on the login page.”, “weight”:
    0}, {“role”: “user”, “content”: “Can you be more sarcastic?”}, {“role”: “assistant”,
    “content”: “Oh, you just click the ‘Forgot Password’ link. It’s a groundbreaking
    feature that’s been around for ages.”, “weight”: 1}]} |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '| {“messages”: [{“role”: “system”, “content”: “你是 Contoso 客户支持代理，友好且简洁，但有点讽刺的语气。”},
    {“role”: “user”, “content”: “你们的营业时间是什么？”}, {“role”: “assistant”, “content”: “我们的营业时间是周一至周五，上午
    9 点至下午 5 点。”，“weight”: 0}, {“role”: “user”, “content”: “你能再讽刺一点吗？”}, {“role”:
    “assistant”, “content”: “当然，我们的营业时间是从早上 9 点到下午 5 点，周一至周五。真是一个让人吃惊的时间吧？”, “weight”:
    1}]}{“messages”: [{“role”: “system”, “content”: “你是 Contoso 客户支持代理，友好且简洁，但有点讽刺的语气。”},
    {“role”: “user”, “content”: “我该如何重置密码？”}, {“role”: “assistant”, “content”: “你可以点击登录页面上的‘忘记密码’链接来重置密码。”，“weight”:
    0}, {“role”: “user”, “content”: “你能再讽刺一点吗？”}, {“role”: “assistant”, “content”:
    “哦，你只需点击‘忘记密码’链接。这可是一个革命性的功能，已经存在了很久。”，“weight”: 1}]} |'
- en: 'Table 3.3: sample multiturn training data JSONL format'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.3：示例多轮训练数据 JSONL 格式
- en: The more training examples you provide, the better the fine-tuning results will
    be. While fine-tuning requires at least 10 training examples to proceed, this
    minimal number is usually insufficient to have a meaningful impact on the model’s
    performance. Ideally, you should provide hundreds or even thousands of examples
    for optimal results.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的训练示例越多，微调的结果就越好。虽然微调至少需要 10 个训练示例才能进行，但这个最小数量通常不足以对模型的性能产生有意义的影响。理想情况下，应该提供数百甚至数千个示例，以获得最佳效果。
- en: Generally, increasing the dataset size can lead to a proportional improvement
    in model quality. However, it’s important to note that low-quality examples can
    harm the model’s performance. If you train the model with a large amount of internal
    data without carefully curating it to include only high-quality examples, the
    model’s performance may end up being worse than anticipated.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，增加数据集的大小可以带来模型质量的成比例提升。然而，值得注意的是，低质量的示例可能会影响模型的性能。如果你在没有精心筛选数据的情况下，用大量的内部数据训练模型，且数据只包含低质量示例，那么模型的表现可能会比预期更差。
- en: '**Training a new fine-tuned model**: Training a new fine-tuned model can be
    done either through Azure AI Foundry or using the API. For this demonstration,
    we will use Azure AI Foundry to illustrate how you can easily fine-tune a base
    chat completion model. AOAI supports a range of models for fine-tuning. To view
    the complete list of supported models, please refer to [https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?tabs=azure-openai%2Ccompletionfinetuning%2Cpython-new&pivots=programming-language-studio#models](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?tabs=azure-openai%2Ccompletionfinetuning%2Cpython-new&pivots=programming-language-studio#models):'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练新的微调模型**：训练新的微调模型可以通过 Azure AI Foundry 或使用 API 完成。在本次演示中，我们将使用 Azure AI
    Foundry 来展示如何轻松地微调基础聊天完成功能模型。AOAI 支持多种模型进行微调。要查看完整的支持模型列表，请参考 [https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?tabs=azure-openai%2Ccompletionfinetuning%2Cpython-new&pivots=programming-language-studio#models](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?tabs=azure-openai%2Ccompletionfinetuning%2Cpython-new&pivots=programming-language-studio#models)：'
- en: To begin, open Azure AI Foundry at [https://oai.azure.com/](https://oai.azure.com/)
    and sign in using credentials that have access to your AOAI resource. During the
    sign-in process, ensure you select the correct directory, Azure subscription,
    and AOAI resource associated with your account.
  id: totrans-452
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，打开 Azure AI Foundry 网站 [https://oai.azure.com/](https://oai.azure.com/)，并使用具有
    AOAI 资源访问权限的凭据登录。在登录过程中，确保选择正确的目录、Azure 订阅以及与你的帐户关联的 AOAI 资源。
- en: In Azure AI Foundry, navigate to the **Tools** section in the left-hand menu,
    then select the **Fine-tuning** pane. From there, click on the **Fine-tune model**
    option to begin the fine-tuning process.
  id: totrans-453
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Azure AI Foundry 中，导航到左侧菜单中的 **工具** 部分，然后选择 **微调** 面板。接着，点击 **微调模型** 选项以开始微调过程。
- en: '![Figure 3.31: AOAI fine-tuning wizard](img/B21019_03_31.jpg)'
  id: totrans-454
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.31：AOAI 微调向导](img/B21019_03_31.jpg)'
- en: 'Figure 3.31: AOAI fine-tuning wizard'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.31：AOAI 微调向导
- en: 'The first step in creating a custom model is to select a base model. In the
    **Base model** pane, you can choose a base model from the **Base model type**
    drop-down menu. Your choice will impact both the performance and the cost of the
    custom model you’re creating. Once you’ve selected the base model, click **Next**
    to proceed with the fine-tuning process, as shown in *Figure 3**.31*:'
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建自定义模型的第一步是选择一个基础模型。在 **基础模型** 面板中，你可以从 **基础模型类型** 下拉菜单中选择一个基础模型。你的选择将影响你所创建的自定义模型的性能和成本。选择好基础模型后，点击
    **下一步** 继续微调过程，如 *图 3.31* 所示：
- en: '![Figure 3.32: Selecting base model to fine-tune](img/B21019_03_32.jpg)'
  id: totrans-457
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.32：选择基础模型进行微调](img/B21019_03_32.jpg)'
- en: 'Figure 3.32: Selecting base model to fine-tune'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.32：选择基础模型进行微调
- en: AOAI also supports incremental fine-tuning, meaning you can fine-tune a model
    that has already been fine-tuned. This allows you to continue improving the model’s
    performance by further training it on new or updated datasets, enhancing its ability
    to handle more specific tasks or respond to evolving needs.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI 还支持增量微调，这意味着你可以对已经进行过微调的模型进行再次微调。这样，你可以通过在新的或更新的数据集上进一步训练模型，持续提升其性能，增强模型处理更具体任务或响应不断变化需求的能力。
- en: To proceed, you can select from your previously uploaded training datasets or
    upload new ones, based on your specific customization needs. The **Training Data**
    section will show all available datasets, allowing you to review and choose from
    existing options or upload fresh data for training purposes. In this example,
    we demonstrate the process of uploading a new dataset directly from the local
    drive, as illustrated in *Figure 3**.32*.
  id: totrans-460
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续操作时，您可以根据具体的定制需求，选择之前上传的训练数据集，或上传新的数据集。**训练数据**部分将显示所有可用的数据集，您可以查看并选择现有选项，或上传新的数据进行训练。在此示例中，我们演示了如何直接从本地驱动器上传新的数据集，过程如*图
    3.32*所示。
- en: For handling large data files, it’s advisable to import them directly from Azure
    Blob Storage. Uploading sizable files through multipart forms can lead to instability,
    as these uploads rely on atomic requests, which means they cannot be resumed or
    retried if interrupted. Using Azure Blob Storage for such transfers ensures greater
    reliability and fault tolerance, especially when dealing with larger datasets.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 对于处理大型数据文件，建议直接从 Azure Blob 存储导入。通过多部分表单上传大型文件可能导致不稳定，因为这些上传依赖于原子请求，这意味着如果上传中断，无法恢复或重试。使用
    Azure Blob 存储进行此类传输可确保更高的可靠性和容错能力，尤其是在处理大型数据集时。
- en: '![Figure 3.33: Training data upload](img/B21019_03_33.jpg)'
  id: totrans-462
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.33：训练数据上传](img/B21019_03_33.jpg)'
- en: 'Figure 3.33: Training data upload'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.33：训练数据上传
- en: In the next step, you’ll find options to set up validation data for your model
    training process. If validation data is not required, simply select **Next** to
    proceed directly to the advanced configuration settings. However, if you wish
    to incorporate validation data, you can either select from your existing datasets
    or upload a new validation dataset specifically prepared for this purpose.
  id: totrans-464
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一步中，您将找到设置验证数据的选项，适用于您的模型训练过程。如果不需要验证数据，只需选择**下一步**，直接进入高级配置设置。然而，如果您希望使用验证数据，可以从现有数据集中选择，或者上传专门为此目的准备的新验证数据集。
- en: 'The **Validation Data** section displays all available training and validation
    datasets, providing flexibility to either use existing data or add new validation
    data as needed for model customization. In this example, we demonstrate the process
    of uploading a new validation dataset directly from the local drive, as illustrated
    here:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: '**验证数据**部分显示所有可用的训练和验证数据集，提供灵活性，可以使用现有数据或根据需要添加新的验证数据以进行模型定制。在此示例中，我们演示了如何直接从本地驱动器上传新的验证数据集，过程如下：'
- en: '![Figure 3.34: Validation data upload](img/B21019_03_34.jpg)'
  id: totrans-466
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.34：验证数据上传](img/B21019_03_34.jpg)'
- en: 'Figure 3.34: Validation data upload'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.34：验证数据上传
- en: 'The `batch_size` (integer): This specifies the number of training examples
    processed in a single forward and backward pass. Generally, larger batch sizes
    are recommended for larger datasets, as they tend to stabilize the training process.
    Higher batch sizes reduce the frequency of model parameter updates, leading to
    lower variance in updates.'
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`batch_size`（整数）：指定在单次前向和反向传播过程中处理的训练示例数量。通常，对于较大的数据集，推荐使用较大的批次大小，因为它们有助于稳定训练过程。较大的批次大小减少了模型参数更新的频率，从而降低了更新的方差。'
- en: '`learning_rate_multiplier` (number): This is a multiplier applied to the pre-training
    learning rate to set the fine-tuning learning rate. Larger values can improve
    training efficiency with larger batch sizes but may risk overfitting if they’re
    too high. It’s often effective to experiment with values between `0.02` and `0.2`
    to find an optimal rate.'
  id: totrans-469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`learning_rate_multiplier`（数值）：这是应用于预训练学习率的乘数，用于设置微调学习率。较大的值可以提高较大批次大小的训练效率，但如果值过大，可能会导致过拟合。通常可以尝试在`0.02`和`0.2`之间的值，以找到最佳学习率。'
- en: '`n_epochs` (integer): This refers to the number of epochs, or complete passes
    through the dataset, for which the model is trained. Each epoch represents one
    full cycle of learning from the dataset.'
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`n_epochs`（整数）：指模型训练的轮次数，即完整地通过数据集的次数。每一轮表示从数据集中学习的一个完整周期。'
- en: '`seed` (integer): This controls the reproducibility of training runs. Setting
    a specific seed value ensures that the training results are consistent across
    runs, assuming the same job parameters. If left unspecified, a seed will automatically
    be generated.'
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`seed`（整数）：控制训练过程的可复现性。设置特定的种子值可确保训练结果在相同作业参数下具有一致性。如果未指定种子，则会自动生成一个种子。'
- en: 'Select **Default** to use the default values for the fine-tuning job or select
    **Custom** to display and edit the hyperparameter values. When **Default** is
    selected, Microsoft determines the correct value algorithmically based on your
    training data, as shown here:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 选择**默认**使用精细调优任务的默认值，或选择**自定义**显示并编辑超参数值。当选择**默认**时，微软会根据你的训练数据通过算法确定正确的值，如下所示：
- en: '![Figure 3.35: Hyperparameter selection](img/B21019_03_35.jpg)'
  id: totrans-473
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.35：超参数选择](img/B21019_03_35.jpg)'
- en: 'Figure 3.35: Hyperparameter selection'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.35：超参数选择
- en: After you configure the advanced options, select **Next** to review your choices
    and train your fine-tuned model.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 配置完高级选项后，选择**下一步**来检查你的选择并训练你精细调优后的模型。
- en: In the **Review** pane of the wizard, you can view a summary of your selected
    configuration settings. Once you’ve verified that all configurations are correct,
    click **Submit** to initiate the finetuning job. After submission, you’ll be redirected
    to the **Models** pane, where you can monitor the status and progress of your
    fine-tuning task. This final step confirms your setup and starts the model training
    process.
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在向导的**审查**窗格中，你可以查看所选配置设置的摘要。确认所有配置正确后，点击**提交**以启动精细调优任务。提交后，你将被重定向到**模型**窗格，在那里你可以监控精细调优任务的状态和进度。最后一步确认你的设置并启动模型训练过程。
- en: The **Models** pane provides a detailed overview of your custom model’s fine-tuning
    process, displaying key information about the fine-tuning job’s status and results,
    as shown in *Figure 3**.36*. Once you initiate a fine-tuning job, it may take
    some time to finish. Your job could be placed in a queue behind other jobs in
    the system. The duration of the training process can vary, taking anywhere from
    a few minutes to several hours, depending on the size of the model and dataset.
    Click **Refresh** to update the information on the status page.
  id: totrans-477
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型**窗格提供了你自定义模型精细调优过程的详细概览，显示了精细调优任务状态和结果的关键信息，如*图 3.36*所示。一旦你启动精细调优任务，可能需要一些时间才能完成。你的任务可能会排在系统中其他任务的队列后面。训练过程的持续时间可能会有所不同，从几分钟到几个小时不等，这取决于模型和数据集的大小。点击**刷新**以更新状态页面上的信息。'
- en: '![Figure 3.36: Fine Tuning Status](img/B21019_03_36.jpg)'
  id: totrans-478
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.36：精细调优状态](img/B21019_03_36.jpg)'
- en: 'Figure 3.36: Fine Tuning Status'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.36：精细调优状态
- en: After completing the seven steps mentioned here, you will have a fine-tuned
    model. During the training process, a checkpoint is generated at the end of each
    training epoch. A checkpoint represents a fully functional version of the model
    that can be deployed and used as the base model for future fine-tuning jobs. These
    checkpoints are valuable because they offer a snapshot of your model before overfitting
    may occur. Upon completion of a fine-tuning job, you will have access to the three
    most recent versions of the model, which can be deployed as needed.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此处提到的七个步骤后，你将拥有一个精细调优的模型。在训练过程中，每个训练周期结束时会生成一个检查点。检查点代表了一个功能完整的模型版本，可以部署并作为未来精细调优任务的基础模型。这些检查点非常有价值，因为它们提供了在过拟合发生之前的模型快照。在精细调优任务完成后，你将可以访问模型的三个最新版本，可以根据需要进行部署。
- en: GPT-4o and GPT-4o-mini are our most advanced models, designed to be fine-tuned
    to meet your specific needs. However, as with all AOAI models, fine-tuned versions
    of these models come with added responsible AI challenges, including risks related
    to harmful content, manipulation, human-like behavior, privacy concerns, and more.
  id: totrans-481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPT-4o 和 GPT-4o-mini 是我们最先进的模型，旨在根据你的特定需求进行精细调优。然而，和所有AOAI模型一样，这些模型的精细调优版本也面临着更多负责任的人工智能挑战，包括与有害内容、操控、人类行为、隐私问题等相关的风险。
- en: To mitigate these risks, additional evaluation steps have been implemented to
    detect and prevent harmful content in the training and outputs of fine-tuned models.
    These measures are aligned with the Microsoft Responsible AI Standard and AOAI
    Service content filtering policies.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少这些风险，已实施额外的评估步骤，以检测和防止精细调优模型的训练和输出中有害内容。这些措施符合微软负责任的人工智能标准以及AOAI服务的内容过滤政策。
- en: 'Key evaluation features include the following :'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的评估功能包括以下内容：
- en: '**Dedicated private workspaces** for each customer to ensure security and privacy
    during evaluations'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专用的私人工作空间**为每个客户提供，确保在评估过程中安全性和隐私。'
- en: '**Evaluation endpoints** located within the same geographic region as the AOAI
    resource to maintain compliance with regional data policies'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估端点**位于与AOAI资源相同的地理区域内，以确保遵守地区数据政策。'
- en: '**Training data privacy** is ensured because data used in evaluations is not
    stored; only the final model assessment (whether deployable or not) is retained'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练数据隐私**得到了保障，因为用于评估的数据不会被存储；仅保留最终模型评估结果（是否可以部署）。'
- en: '**Predefined evaluation filters**: The filters for GPT-4o, GPT-4o-mini, and
    GPT-4 fine-tuned models are set to fixed thresholds and cannot be altered by customers;
    these filters are independent of any custom content filtering configurations you
    may have set up'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预定义评估过滤器**：GPT-4o、GPT-4o-mini 和 GPT-4 微调模型的过滤器设置为固定的阈值，客户无法更改；这些过滤器独立于您可能已设置的任何自定义内容过滤配置。'
- en: These steps are designed to help ensure that the fine-tuned models adhere to
    responsible AI practices and minimize the risk of generating harmful or inappropriate
    content.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤旨在帮助确保微调后的模型遵循负责任的 AI 实践，并尽量减少生成有害或不当内容的风险。
- en: 'The AOAI fine-tuning service incorporates two key safeguards to promote the
    responsible and ethical use of the AOAI fine-tuning service during the training
    process:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI 微调服务在训练过程中结合了两项关键的保障措施，以促进 AOAI 微调服务的负责任和伦理使用：
- en: '`The provided training data failed RAI checks for harm types: [hate_fairness,
    self_harm, violence]. Please fix the data and` `try again.`'
  id: totrans-490
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`提供的训练数据未通过 RAI 检查，存在以下危害类型：[仇恨公平性、自残、暴力]。请修复数据并` `重试。`'
- en: 'Table 3.3: Training data evaluation notification'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.3：训练数据评估通知
- en: Your training data is automatically assessed during the data import process
    as part of enabling the fine-tuning feature. If harmful content is detected in
    the training data, causing the fine-tuning job to fail, you will not incur any
    charges.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据导入过程中，您的训练数据会自动评估，作为启用微调功能的一部分。如果在训练数据中检测到有害内容，导致微调任务失败，您将不会产生任何费用。
- en: '**Model evaluation**: Once training is finished, before the fine-tuned model
    is deployed, it undergoes an evaluation to assess the potential for harmful responses
    using Azure’s built-in risk and safety metrics. This evaluation mirrors the testing
    process applied to base LLMs. It simulates a conversation with the fine-tuned
    model to determine whether it could produce harmful content based on predefined
    categories (violence, sexual content, hate speech, fairness issues, and self-harm).
    If the model generates harmful content at a rate above an acceptable threshold,
    you will be notified, as shown in *Table 3.5*, that the model is not ready for
    deployment. You’ll also be given details about the specific harmful content categories
    identified.'
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**模型评估**：训练完成后，在微调模型部署之前，模型将接受评估，以评估其潜在的有害响应，使用 Azure 内置的风险和安全度量标准。这一评估过程与对基础
    LLM 的测试过程相同。它模拟与微调模型的对话，评估模型是否会根据预定义类别（暴力、色情内容、仇恨言论、公平性问题和自残）生成有害内容。如果模型生成有害内容的比例超过可接受阈值，您将收到通知，如*表
    3.5*所示，表示该模型无法部署。同时，您还会收到关于具体有害内容类别的详细信息。'
- en: '| This model is unable to be deployed. Model evaluation identified that this
    fine-tuned model scores above acceptable thresholds for [Violence, Self Harm].
    Please retrain your model with a safe dataset. |'
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 此模型无法部署。模型评估发现该微调模型在[暴力、自残]方面的得分超过了可接受的阈值。请使用安全数据集重新训练您的模型。 |'
- en: 'Table 3.4: Model evaluation notification'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.4：模型评估通知
- en: Similar to data evaluation, the model is automatically assessed during the fine-tuning
    job as part of the fine-tuning process. Only the final assessment—whether the
    model is deployable or not—is recorded by the service. If the deployment of the
    fine-tuned model fails due to harmful content detected in the model’s outputs,
    you will not be charged for the training session.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于数据评估，模型在微调过程中会自动评估。这是微调过程的一部分。只有最终评估结果——模型是否可以部署——会被服务记录。如果由于模型输出中检测到有害内容导致微调模型无法部署，您将不会被收取训练费用。
- en: '`results.csv` for each job. This file helps you analyze the performance of
    your custom model during training and validation. You can find the file ID for
    the result file under the `Result file id` column on the **Models** pane in Azure
    AI Foundry, which allows you to download the file from the **Data** **files**
    pane.'
  id: totrans-497
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个任务的 `results.csv` 文件。该文件帮助您分析自定义模型在训练和验证过程中的表现。您可以在 Azure AI Foundry 的 **模型**
    面板下找到结果文件的文件 ID，从而在 **数据** **文件** 面板中下载该文件。
- en: 'The `results.csv` file contains the following columns, as shown in *Table 3.5*:'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '`results.csv` 文件包含以下列，如*表 3.5*所示：'
- en: '![Table: 3.5: Model training and validation performance](img/B21019_03_Table_3.5.jpg)'
  id: totrans-499
  prefs: []
  type: TYPE_IMG
  zh: '![表格：3.5：模型训练和验证性能](img/B21019_03_Table_3.5.jpg)'
- en: 'Table: 3.5: Model training and validation performance'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 表格：3.5：模型训练和验证性能
- en: 'In Azure AI Foundry, you can visualize the data from your `results.csv` file
    as graphs. By selecting the link for your trained model, you will be able to view
    two key charts: **Loss** and **Token accuracy**. If you’ve provided validation
    data, the results for both the training and validation datasets will be displayed
    on the same plot, as shown here:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Azure AI Foundry 中，你可以将 `results.csv` 文件中的数据可视化为图表。通过选择你的训练模型链接，你将能够查看两个关键图表：**损失**和**标记准确率**。如果你提供了验证数据，那么训练和验证数据集的结果将显示在同一图表中，如下所示：
- en: '![Figure 3.37: Fine Tuning metrics](img/B21019_03_37.jpg)'
  id: totrans-502
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.37：微调指标](img/B21019_03_37.jpg)'
- en: 'Figure 3.37: Fine Tuning metrics'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.37：微调指标
- en: 'Here’s what to watch for in the plots:'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你在图表中需要关注的内容：
- en: '*Loss should decrease over time*, indicating that the model is improving as
    it learns.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*损失应随时间减少*，这表示模型随着学习的进行在不断改进。'
- en: '*Accuracy should increase*, showing that the model is getting better at predicting
    tokens.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*准确率应提高*，这表明模型在预测标记时变得更加准确。'
- en: 'If you notice a *divergence* between the training and validation data (i.e.,
    training loss continues to decrease while validation loss increases or plateaus),
    this could be a sign of *overfitting*. In such cases, you may want to: do the
    following:'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你注意到训练数据和验证数据之间存在*发散*（即训练损失继续减少，而验证损失增加或保持平稳），这可能是*过拟合*的信号。在这种情况下，你可能需要做以下几件事：
- en: Train the model with fewer epochs
  id: totrans-508
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用更少的训练轮次来训练模型
- en: Use a smaller learning rate multiplier to prevent the model from fitting too
    closely to the training data
  id: totrans-509
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用较小的学习率倍增器，防止模型过度拟合训练数据
- en: 'When fine-tuning a model, there are several important considerations to ensure
    optimal performance:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调模型时，有几个重要的考虑因素，以确保最佳性能：
- en: '**Missing system message**: It’s crucial to provide a consistent system message
    during fine-tuning and when using the fine-tuned model. If the system message
    changes, the model may produce results that differ from what you intended during
    fine-tuning. Therefore, the system message you use for deployment should match
    the one you used in the training process to maintain consistency.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺失系统消息**：在微调和使用微调模型时，提供一致的系统消息非常重要。如果系统消息发生变化，模型可能会生成与微调时不同的结果。因此，部署时使用的系统消息应与训练过程中使用的消息保持一致，以确保一致性。'
- en: '**Not enough data**: While the minimum required data for the fine-tuning pipeline
    to run is 10 examples, using hundreds or even thousands of data points is recommended
    for teaching the model new skills. With too few data points, there is a risk of
    overfitting, whereby the model memorizes specific examples rather than generalizing
    patterns. This can lead to poor performance when applied to real-world, unseen
    data. To achieve the best results, aim to prepare a dataset with hundreds or thousands
    of diverse data points.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据不足**：虽然微调管道运行所需的最小数据量为10个示例，但建议使用数百甚至数千个数据点来教会模型新技能。数据点太少，存在过拟合的风险，模型会记住特定的示例，而不是泛化模式。这可能导致在应用到真实世界、未见过的数据时表现不佳。为了取得最佳结果，目标应是准备一个包含数百或数千个多样化数据点的数据集。'
- en: '**Bad data**: The quality of your training data directly impacts the quality
    of your fine-tuned model. A poorly curated or biased dataset can lead the model
    to learn inaccurate patterns. For instance, if you train a customer service chatbot
    only with data for one scenario (e.g., returns), it will struggle to handle other
    situations. Additionally, if the training data contains incorrect or misleading
    information, the model will learn to generate faulty or biased responses. Always
    ensure that your dataset is diverse, accurate, and representative of the tasks
    you expect the model to handle.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**糟糕的数据**：训练数据的质量直接影响到微调模型的质量。一个精心策划或存在偏见的数据集可能导致模型学习到不准确的模式。例如，如果你只用一个场景（例如退货）的数据来训练一个客服聊天机器人，它将难以应对其他情况。此外，如果训练数据包含不正确或误导性的信息，模型将学会生成错误或有偏见的响应。始终确保你的数据集是多样化的、准确的，并且能代表你希望模型处理的任务。'
- en: '**Deploying the fine-tuned model**: Once the fine-tuning job is successful,
    you can deploy your custom model through the **Models** pane in Azure AI Foundry.
    Deployment is necessary for making the fine-tuned model available for use in completion
    calls. To deploy the model, simply select the custom model and click **Deploy
    model**, as shown here:'
  id: totrans-514
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**部署微调后的模型**：一旦微调任务成功，您可以通过Azure AI Foundry中的**Models**面板部署您的自定义模型。部署是使微调后的模型能够在完成调用中使用的必要步骤。要部署模型，只需选择自定义模型并点击**Deploy
    model**，如下所示：'
- en: '![Figure 3.38: Fine-tuned model deployment](img/B21019_03_38.jpg)'
  id: totrans-515
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.38：微调模型部署](img/B21019_03_38.jpg)'
- en: 'Figure 3.38: Fine-tuned model deployment'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.38：微调模型部署
- en: When you open the **Deploy model** dialog box, you will need to enter a deployment
    name for your custom model. After entering the name, click **Deploy** to initiate
    the deployment process for your fine-tuned model. You can track the deployment
    progress in the **Deployments** pane of Azure AI Foundry.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 当您打开**Deploy model**对话框时，您需要为您的自定义模型输入一个部署名称。输入名称后，点击**Deploy**以启动微调模型的部署过程。您可以在Azure
    AI Foundry的**Deployments**面板中跟踪部署进度。
- en: AOAI fine-tuning also supports the flexibility to deploy your custom model to
    a different region from where it was originally fine-tuned, including across different
    subscriptions and regions.
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI微调还支持将您的自定义模型部署到与原始微调位置不同的区域，包括跨订阅和区域的部署。
- en: 'However, there are a few key limitations to consider:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，需要考虑一些关键的限制：
- en: The target region must support fine-tuning
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标区域必须支持微调
- en: If deploying across subscriptions, the account generating the authorization
    token must have access to both the source and destination subscription
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果跨订阅部署，生成授权令牌的账户必须同时具有源订阅和目标订阅的访问权限
- en: Important note
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Once you deploy a customized model, if it remains inactive for more than *15
    days*, the deployment will automatically be deleted. A deployment is considered
    inactive if no *completion* or *chat completion* calls are made to the model over
    a continuous 15-day period. It’s important to note that the deletion of an inactive
    deployment does not affect the underlying customized model. The model itself is
    preserved and can be redeployed at any time. Additionally, each deployed fine-tuned
    model incurs an *hourly hosting cost*, even if no calls are made to the model
    during that time.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您部署了自定义模型，如果它在*15天*内没有任何活动，部署将自动被删除。如果在连续的15天内没有对模型进行任何*完成*或*聊天完成*调用，则该部署将被视为非活动状态。需要注意的是，删除非活动部署不会影响底层的自定义模型。模型本身将被保留，可以随时重新部署。此外，每个已部署的微调模型都会产生*按小时计算的托管费用*，即使在该时间段内没有调用该模型。
- en: 'Once your custom model is deployed, you can use it just like any other deployed
    model. You can experiment with your new deployment using `temperature` and `max_tokens`,
    can be applied to your custom model, just like with other deployed models:'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的自定义模型部署完成，您可以像使用任何其他已部署的模型一样使用它。您可以通过调整`temperature`和`max_tokens`等参数来测试新的部署，就像对其他已部署的模型一样：
- en: For fine-tuned `babbage-002` and `davinci-002` models, you will use the **Completions**
    playground and the Completions API
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于微调后的`babbage-002`和`davinci-002`模型，您将使用**Completions**沙盒和Completions API
- en: For fine-tuned gpt-4o models, you will use the **Chat** playground and the Chat
    Completion API
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于微调后的gpt-4o模型，您将使用**Chat**沙盒和Chat Completion API
- en: These tools allow you to interact with and test the customizations made to your
    fine-tuned models.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具允许您与微调后的自定义模型互动并进行测试。
- en: Summary
  id: totrans-528
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we focused on AOAI, which provides a comprehensive set of tools
    and services designed to enhance AI model capabilities and integration. At the
    core of these offerings is the AOAI model context window, which defines the amount
    of information the models can process at once. We learned that it’s crucial for
    maintaining coherence and understanding in complex tasks. We also learned that
    AOAI embedding models facilitate the conversion of text into numerical vectors,
    enabling better semantic understanding and similarity searches. These embeddings
    can efficiently be stored and queried using Azure vector databases, which are
    optimized for handling high-dimensional data, thereby enhancing the performance
    of AI applications. We also discussed the standard RAG pattern, outlining its
    step-by-step process flow. Furthermore, we learned that AOAI On Your Data allows
    organizations to do quick a prototype and leverage these models on their proprietary
    datasets, ensuring the AI solutions are tailored to specific business needs.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们重点介绍了 AOAI，它提供了一整套旨在增强 AI 模型能力和集成的工具和服务。这些服务的核心是 AOAI 模型上下文窗口，它定义了模型一次可以处理的信息量。我们了解到，这对于维持复杂任务中的连贯性和理解力至关重要。我们还了解到，AOAI
    嵌入模型有助于将文本转化为数值向量，从而实现更好的语义理解和相似性搜索。这些嵌入向量可以通过 Azure 向量数据库高效存储和查询，而这些数据库已经针对高维数据的处理进行了优化，从而提高了
    AI 应用的性能。我们还讨论了标准 RAG 模式，概述了其逐步流程。此外，我们了解到，AOAI On Your Data 允许组织快速原型化，并在其专有数据集上利用这些模型，确保
    AI 解决方案能够根据特定的业务需求进行定制。
- en: AOAI capabilities extend into multimodal models, which can process and integrate
    information from multiple data types, such as text and images, broadening the
    scope of AI applications. We learned that the function calling feature allows
    seamless integration of AI models with Azure’s robust ecosystem, facilitating
    the execution of predefined functions based on AI outputs. Developers can leverage
    the AOAI Assistants API to create sophisticated, context-aware conversational
    agents, enhancing user interactions. For operations requiring high throughput,
    the AOAI Batch API provides a scalable solution for processing large volumes of
    data efficiently, as we learned in this chapter. Finally, we learned that AOAI
    fine-tuning empowers users to customize pre-trained models to better align with
    specific tasks or domains, improving performance and accuracy in specialized applications.
    Together, these tools offer a powerful and flexible platform for developing advanced
    AI solutions tailored to diverse business requirements, as we learned in this
    chapter.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI 的功能扩展到多模态模型，这些模型能够处理和整合来自多种数据类型的信息，如文本和图像，从而拓宽了人工智能应用的范围。我们了解到，功能调用特性允许
    AI 模型与 Azure 强大的生态系统无缝集成，便于根据 AI 输出执行预定义函数。开发者可以利用 AOAI Assistants API 创建复杂的、具备上下文意识的对话代理，提升用户交互体验。对于需要高吞吐量的操作，AOAI
    Batch API 提供了一个可扩展的解决方案，能够高效地处理大量数据，正如我们在本章中学到的那样。最后，我们了解到，AOAI 微调功能使用户能够定制预训练模型，以更好地适应特定任务或领域，从而提升在专业应用中的性能和准确性。所有这些工具共同提供了一个强大且灵活的平台，用于开发针对多样化商业需求的先进
    AI 解决方案，正如我们在本章中学到的那样。
- en: In the following chapters, we will focus on practical examples of generative
    AI applications, accompanied by coding exercises to help you build these applications
    effortlessly. Through hands-on implementations, you’ll develop a comprehensive
    understanding of how to apply generative AI technologies to real-world use cases.
    Topics will include various scenarios such as document-based question answering
    and contact center analytics, as well as querying structured data, generating
    code using AOAI, creating recommender systems, generating text-to-video content,
    and building a multimodal multi-agent system using the Assistant API. Each example
    will include step-by-step guidance and code snippets to support you in integrating
    these features into your projects.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将重点关注生成型 AI 应用的实际示例，并附有编码练习，帮助你轻松构建这些应用。通过动手实现，你将全面理解如何将生成型 AI 技术应用于现实世界的用例。内容将涵盖各种场景，如基于文档的问答和联络中心分析，以及查询结构化数据、使用
    AOAI 生成代码、创建推荐系统、生成文本到视频的内容，并通过 Assistant API 构建多模态多代理系统。每个示例都将包括逐步指导和代码片段，帮助你将这些功能集成到你的项目中。
- en: 'Part 2: Practical Applications of Azure OpenAI: Real-World Use Cases'
  id: totrans-532
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分：Azure OpenAI 的实际应用：真实世界用例
- en: In Part 2, we transition from foundational concepts to hands-on implementations,
    exploring practical use cases that demonstrate the transformative potential of
    Azure OpenAI in solving real-world challenges. Each chapter presents a distinct
    application, offering detailed insights into the problem context, technical architecture,
    and step-by-step solution development. From creating enterprise-level document
    question-answering systems to building multimodal, multi-agent frameworks, this
    section equips readers with the knowledge and tools to harness Azure OpenAI for
    diverse and impactful applications.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二部分中，我们从基础概念过渡到实际操作，探索展示Azure OpenAI在解决现实世界挑战中的变革潜力的实际用例。每一章都介绍一个独特的应用，提供有关问题背景、技术架构以及逐步解决方案开发的详细见解。从创建企业级文档问答系统到构建多模态、多智能体框架，本部分将帮助读者掌握Azure
    OpenAI的知识和工具，以应对各种具有影响力的应用。
- en: 'This part has the following chapters:'
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 4*](B21019_04.xhtml#_idTextAnchor059), Developing an Enterprise Document
    Question-Answer Solution'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第4章*](B21019_04.xhtml#_idTextAnchor059)，开发企业文档问答解决方案'
- en: '[*Chapter 5*](B21019_05.xhtml#_idTextAnchor067), Building a Contact Center
    Analytics Solution'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第5章*](B21019_05.xhtml#_idTextAnchor067)，构建联络中心分析解决方案'
- en: '[*Chapter 6*](B21019_06.xhtml#_idTextAnchor077), *Querying From a Structured
    Database*'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B21019_06.xhtml#_idTextAnchor077)，*从结构化数据库中查询*'
- en: '[*Chapter 7*](B21019_07.xhtml#_idTextAnchor088), *Code Generation and Documentation*'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B21019_07.xhtml#_idTextAnchor088)，*代码生成与文档编写*'
- en: '[*Chapter 8*](B21019_08.xhtml#_idTextAnchor095), *Creating a Basic Recommender
    Solution with Azure OpenAI*'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第8章*](B21019_08.xhtml#_idTextAnchor095)，*使用Azure OpenAI创建基础推荐系统*'
- en: '[*Chapter 9*](B21019_09.xhtml#_idTextAnchor101), *Transforming Text to Video*'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B21019_09.xhtml#_idTextAnchor101)，*将文本转化为视频*'
- en: '[*Chapter 10*](B21019_10.xhtml#_idTextAnchor109), *Creating a Multimodal Multi-Agent
    Framework with the Azure OpenAI Assistant API*'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B21019_10.xhtml#_idTextAnchor109)，*使用Azure OpenAI助手API创建多模态多智能体框架*'
