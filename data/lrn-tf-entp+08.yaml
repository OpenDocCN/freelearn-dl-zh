- en: 'Chapter 5:'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第五章：
- en: Training at Scale
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大规模训练
- en: When we build and train more complex models or use large amounts of data in
    an ingestion pipeline, we naturally want to make better use of all the compute
    time and memory resources at our disposal in a more efficient way. This is the
    major purpose of this chapter, as we are going to integrate what we learned in
    previous chapters with techniques for distributed training running in a cluster
    of compute nodes.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们构建和训练更复杂的模型，或在数据摄取管道中使用大量数据时，我们自然希望更高效地利用我们所拥有的所有计算时间和内存资源。这就是本章的主要目的，我们将把前几章学到的内容与在计算节点集群中运行的分布式训练技术结合起来。
- en: TensorFlow has developed a high-level API for distributed training. Furthermore,
    this API integrates with the Keras API very well. As it turns out, the Keras API
    is now a first-class citizen in the TensorFlow ecosystem. Compared to the estimator
    API, Keras receives the most support when it comes to a distributed training strategy.
    Therefore, this chapter will predominantly focus on using the Keras API with a
    distributed training strategy. We will leverage Google Cloud resources to demonstrate
    how to make minimal changes to the Keras API code we are already familiar with
    and integrate it with the distributed training strategy.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 已经为分布式训练开发了一个高级 API。此外，这个 API 与 Keras API 的集成非常良好。事实证明，Keras API
    现在已经成为 TensorFlow 生态系统中的一等公民。与估算器 API 相比，在分布式训练策略方面，Keras 获得了最多的支持。因此，本章将主要集中在如何使用
    Keras API 和分布式训练策略。我们将利用 Google Cloud 资源，演示如何对我们已经熟悉的 Keras API 代码进行最小改动，并将其与分布式训练策略集成。
- en: In this chapter, we will learn how to leverage Google Cloud's AI Platform and
    use the `TFRecordDataset` into the model training workflow, and designate a distributed
    training strategy for the TPU and GPU accelerators. All the code for this chapter
    can be found at [https://github.com/PacktPublishing/learn-tensorflow-enterprise/tree/master/chapter_05](https://github.com/PacktPublishing/learn-tensorflow-enterprise/tree/master/chapter_05).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们将学习如何利用 Google Cloud 的 AI Platform，并将 `TFRecordDataset` 融入模型训练工作流，指定用于
    TPU 和 GPU 加速器的分布式训练策略。本章的所有代码都可以在 [https://github.com/PacktPublishing/learn-tensorflow-enterprise/tree/master/chapter_05](https://github.com/PacktPublishing/learn-tensorflow-enterprise/tree/master/chapter_05)
    找到。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Using the Cloud TPU through AI Platform
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 AI Platform 使用 Cloud TPU
- en: Using the Cloud GPU through AI Platform
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 AI Platform 使用 Cloud GPU
- en: Using the Cloud TPU through AI Platform
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过 AI Platform 使用 Cloud TPU
- en: 'Before we begin, let''s briefly discuss the possible costs you might incur
    in the **Google Cloud Platform** (**GCP**). All the scripts and examples here
    are catered to didactic purposes. Therefore, training epochs are usually set to
    minimally reasonable values. With that in mind, it is still worth noting that
    as we start to leverage cloud resources, we need to keep in mind the compute cluster''s
    cost. You will find more information on AI Platform training charges here: [https://cloud.google.com/ai-platform/training/pricing#examples_calculate_training_cost_using_price_per_hour](https://cloud.google.com/ai-platform/training/pricing#examples_calculate_training_cost_using_price_per_hour).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们简要讨论一下你可能会在**Google Cloud Platform**（**GCP**）上产生的费用。这里的所有脚本和示例都是为了教学目的而设定的。因此，训练周期通常会设置为合理的最小值。考虑到这一点，仍然值得注意的是，当我们开始利用云资源时，我们需要牢记计算集群的成本。你可以在这里找到关于
    AI Platform 训练费用的更多信息：[https://cloud.google.com/ai-platform/training/pricing#examples_calculate_training_cost_using_price_per_hour](https://cloud.google.com/ai-platform/training/pricing#examples_calculate_training_cost_using_price_per_hour)。
- en: The examples in this book typically use the predefined scale tiers. In the predefined
    scale tiers listing at the preceding link, you will see the price per hour for
    different tiers. For example, `BASIC_TPU` is much more expensive than `BASIC_GPU`.
    We will use both in this chapter, as we will learn how to submit a training job
    to either the TPU or GPU. In my experience, each example in this book should complete
    its run between 20 to 60 minutes, with the parameters set either here in the book
    or in the GitHub repo. Your experience may vary, depending on your region and
    the availability of the compute resources.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的示例通常使用预定义的规模层级。在前述链接中的预定义规模层级列表中，你将看到不同层级的每小时价格。例如，`BASIC_TPU` 的价格远高于 `BASIC_GPU`。我们将在本章中同时使用这两者，因为我们将学习如何向
    TPU 或 GPU 提交训练任务。根据我的经验，本书中的每个示例通常会在 20 到 60 分钟内完成运行，所使用的参数在书中或 GitHub 仓库中已有说明。你的体验可能会有所不同，这取决于你的区域和计算资源的可用性。
- en: This cost does not include the cost of cloud storage, where you will read and
    write data or model artifacts. Remember to delete cloud storage when you are not
    using it. FYI, the cloud storage cost for the content and work related to this
    book is a very small fraction of the overall cost.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 该费用不包括云存储的费用，云存储用于读取和写入数据或模型文件。请记得在不使用时删除云存储。供参考，与本书相关的内容和工作所需的云存储费用仅占整体费用的一小部分。
- en: Tip
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Sometimes, when the GPU is in high demand, you may want to use the TPU, which
    is the fastest cluster that GCP offers. It may reduce the training time significantly,
    and likewise your expenses.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，当GPU需求量很大时，你可能想使用TPU，TPU是GCP提供的最快集群。它可能显著减少训练时间，从而减少你的开支。
- en: 'If you haven''t done so already, go ahead and clone the repo:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有这样做，请立即克隆这个仓库：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As we have seen in previous chapters, Google's AI Platform offers a convenient
    development environment known as JupyterLab. It integrates with other Google Cloud
    services, such as BigQuery or cloud storage buckets, through SDKs. In this section,
    we are going to leverage Google Cloud's TPU for a distributed training workload.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前几章中所看到的，Google的AI平台提供了一个便捷的开发环境，称为JupyterLab。它可以通过SDK与其他Google Cloud服务（如BigQuery或云存储桶）集成。在本节中，我们将利用Google
    Cloud的TPU进行分布式训练工作负载。
- en: The TPU is a custom-built ASIC per Google's specification and design. It is
    an accelerator that is specifically optimized to handle deep learning calculations
    and algorithms. For this reason, a TPU is ideally suited for training complex
    neural networks and machine learning models with a virtually unlimited amount
    of training data. It completes a training routine in minutes where it would have
    taken hours in a single node machine.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: TPU是根据Google的规格和设计定制的ASIC加速器。它是专门优化用于处理深度学习计算和算法的加速器。因此，TPU非常适合训练复杂的神经网络和机器学习模型，能够处理几乎无限量的训练数据。它可以在几分钟内完成训练过程，而在单节点机器上可能需要几个小时。
- en: 'Currently, there are four types of TPU offerings: **V2**, **V2 Pod**, **V3**,
    and **V3 Pod**. For more details, refer to the official link, which includes Google
    Cloud''s description of the benefits of the Cloud TPU: [https://cloud.google.com/tpu/?_ga=2.138028336.-1825888872.1592693180](https://cloud.google.com/tpu/?_ga=2.138028336.-1825888872.1592693180)).
    For AI Platform instances that run TensorFlow Enterprise 2.1 or above, V3 is the
    preferred choice. With either V2 or V3, a **TPU pod** consists of multiple TPUs.
    A pod is basically a cluster of TPUs. For more details about the TPU and TPU pods,
    the following link describes the different versions of TPU pods and their runtimes
    for different machine learning training jobs: [https://cloud.google.com/tpu/docs/system-architecture#configurations](https://cloud.google.com/tpu/docs/system-architecture#configurations).
    Each pod, whether it''s V2 or V3, can perform up to 100 petaFLOPS. This performance
    is reported at this link: [https://techcrunch.com/2019/05/07/googles-newest-cloud-tpu-pods-feature-over-1000-tpus/](https://techcrunch.com/2019/05/07/googles-newest-cloud-tpu-pods-feature-over-1000-tpus/).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当前，有四种TPU配置：**V2**、**V2 Pod**、**V3** 和 **V3 Pod**。更多细节，请参考官方链接，其中包含了Google Cloud对Cloud
    TPU的优势描述：[https://cloud.google.com/tpu/?_ga=2.138028336.-1825888872.1592693180](https://cloud.google.com/tpu/?_ga=2.138028336.-1825888872.1592693180)。对于运行TensorFlow
    Enterprise 2.1或更高版本的AI Platform实例，V3是首选配置。无论是V2还是V3，**TPU pod**都由多个TPU组成。Pod基本上是TPU集群。有关TPU和TPU
    pod的更多信息，请参考以下链接，描述了不同版本TPU pod的配置及其在不同机器学习训练任务中的运行时：[https://cloud.google.com/tpu/docs/system-architecture#configurations](https://cloud.google.com/tpu/docs/system-architecture#configurations)。每个Pod，无论是V2还是V3，都能达到100
    petaFLOPS的性能。此性能数据可以在此链接中查看：[https://techcrunch.com/2019/05/07/googles-newest-cloud-tpu-pods-feature-over-1000-tpus/](https://techcrunch.com/2019/05/07/googles-newest-cloud-tpu-pods-feature-over-1000-tpus/)。
- en: The benefit of a pod over a single TPU is the training speed and memory at your
    disposal for the training workflow. Compared to a V2 pod (512 cores = eight cores
    per TPU multiplied by 64 TPUs), each V2 TPU consists of eight cores, and each
    core is the basic unit for training data parallelism. At the core level, the TensorFlow
    distributed training strategy is executed. For demonstration and didactic purposes,
    all the examples in this section distribute a training strategy among eight cores
    within a TPU. The `tf.distribute.TPUStrategy` API is the means to distribute training
    in the TPU. This strategy implements synchronous distributed training coupled
    with the TPU's all-reduce operations across multiple TPU cores.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Pod 相较于单个 TPU 的好处在于训练速度和你在训练流程中可用的内存。与 V2 Pod（512 个核心 = 每个 TPU 8 个核心 × 64
    个 TPU）相比，每个 V2 TPU 由 8 个核心组成，每个核心是训练数据并行性的基本单元。在核心级别上，执行 TensorFlow 分布式训练策略。为了演示和教学目的，本节中的所有示例都会在
    TPU 内部的 8 个核心之间分配训练策略。`tf.distribute.TPUStrategy` API 是在 TPU 中分配训练的手段。该策略实现了同步分布式训练，并结合了
    TPU 在多个 TPU 核心之间的全归约操作。
- en: We will use a Cloud TPU and submit a training job. In this example, we are going
    to see how to submit such a training job using the `tfrecord` format with the
    images' original dimensions. The `tfrecord` images are stored in a Google Cloud
    storage bucket (it is assumed that your `tfrecord` is ready; generating `tfrecord`
    formatted data from raw images is not covered in this chapter).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Cloud TPU 并提交一个训练任务。在这个例子中，我们将展示如何使用 `tfrecord` 格式提交训练任务，图像保持原始尺寸。`tfrecord`
    格式的图像存储在 Google Cloud 存储桶中（假设你的 `tfrecord` 已准备好；从原始图像生成 `tfrecord` 格式数据不在本章范围内）。
- en: The training workflow will generate checkpoints and save model artifacts when
    the training is complete. These items are likewise saved in the storage bucket.
    Therefore, we will have to grant the TPU read and write access to our working
    storage bucket.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 训练工作流将在训练完成时生成检查点并保存模型工件。这些项也会保存在存储桶中。因此，我们必须授予 TPU 对工作存储桶的读写权限。
- en: Before we begin using the TPU, there are a few administrative items in Google
    Cloud to take care of. Let's get started.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始使用 TPU 之前，需要处理 Google Cloud 中的一些管理事项。让我们开始吧。
- en: Installing the Cloud SDK
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Cloud SDK
- en: 'To install the Cloud SDK in the client node, download and install Google Cloud
    SDK. There is a good instruction page about how to install the Cloud SDK for different
    types of systems, be it Mac, Linux, or Windows. It is strongly recommended to
    follow the instructions at this link to install Google Cloud SDK: [https://cloud.google.com/sdk/docs#install_the_latest_cloud_sdk_version](https://cloud.google.com/sdk/docs#install_the_latest_cloud_sdk_version).
    Once the installation is done, you can verify it with the following command:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要在客户端节点上安装 Cloud SDK，请下载并安装 Google Cloud SDK。Google Cloud SDK 提供了关于如何在不同操作系统（如
    Mac、Linux 或 Windows）上安装的详细说明页面。强烈建议你按照此链接中的说明安装 Google Cloud SDK：[https://cloud.google.com/sdk/docs#install_the_latest_cloud_sdk_version](https://cloud.google.com/sdk/docs#install_the_latest_cloud_sdk_version)。安装完成后，你可以使用以下命令进行验证：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The preceding command will return the following output:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将返回以下输出：
- en: '![Figure 5.1 – gcloud SDK verification'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.1 – gcloud SDK 验证'
- en: '](img/image0011.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image0011.jpg)'
- en: Figure 5.1 – gcloud SDK verification
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1 – gcloud SDK 验证
- en: '*Figure 5.1* shows the general format of the `gcloud` command. Use *Ctrl* +
    *C* to exit this mode and recover your Command Prompt.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5.1* 显示了 `gcloud` 命令的一般格式。使用 *Ctrl* + *C* 退出此模式并恢复命令提示符。'
- en: Granting the Cloud TPU access to your project
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 授予 Cloud TPU 访问你的项目权限
- en: 'From here, the setup instructions are from Google Cloud''s own documentation
    site at this URL: [https://cloud.google.com/ai-platform/training/docs/using-tpus#tpu-runtime-versions](https://cloud.google.com/ai-platform/training/docs/using-tpus#tpu-runtime-versions):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始，设置说明来自 Google Cloud 自己的文档网站，网址是：[https://cloud.google.com/ai-platform/training/docs/using-tpus#tpu-runtime-versions](https://cloud.google.com/ai-platform/training/docs/using-tpus#tpu-runtime-versions)：
- en: 'In this step, we are going to retrieve a cloud TPU service account name per
    our project ID. We can use the following command:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此步骤中，我们将根据我们的项目 ID 检索云 TPU 服务账户名称。可以使用以下命令：
- en: '[PRE2]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding command will return the following output:'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述命令将返回以下输出：
- en: '![Figure 5.2 – TPU service account retrieval'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.2 – TPU 服务账户检索'
- en: '](img/image0031.jpg)'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/image0031.jpg)'
- en: Figure 5.2 – TPU service account retrieval
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.2 – TPU 服务账户检索
- en: Make a note of the `serviceAccountProject` and `tpuServiceAccount` details.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 记下 `serviceAccountProject` 和 `tpuServiceAccount` 的详细信息。
- en: 'Once we know our TPU service account, we will have to initialize it as per
    the following command:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们知道 TPU 服务账户的信息，我们需要根据以下命令进行初始化：
- en: '[PRE3]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The preceding command generates a Cloud TPU service account for you. Make sure
    you put your `<serviceAccountProject>` details in the URL.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 前述命令会为你生成一个 Cloud TPU 服务账户。确保在 URL 中填写 `<serviceAccountProject>` 的详细信息。
- en: Adding a TPU service account as a member of the project
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 将 TPU 服务账户添加为项目成员
- en: 'The project we use must also know about the TPU service account. In *step 3*
    of the previous section, we passed our project''s Bearer Token to our TPU service
    account so the TPU can access our project. Basically, it is similar to adding
    another member to this project, and in this case, the new member is the TPU service
    account:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的项目也必须知道 TPU 服务账户。在上一节的 *第 3 步* 中，我们将项目的 Bearer Token 传递给 TPU 服务账户，以便 TPU
    可以访问我们的项目。基本上，这就像是将另一个成员添加到该项目中，在这种情况下，新的成员是 TPU 服务账户：
- en: We can use Google Cloud Console to achieve this, as shown in *Figure 5.**3*:![Figure
    5.3 – The IAM & Admin entry
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用 Google Cloud Console 来实现这一点，如 *图 5.3* 所示：![图 5.3 – IAM & 管理入口
- en: '](img/image0051.jpg)'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/image0051.jpg)'
- en: Figure 5.3 – The IAM & Admin entry
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.3 – IAM & 管理入口
- en: On the **IAM** screen, click the **ADD** button to add our TPU to this project,
    as in *Figure 5.4*:![Figure 5.4 – Adding a member to a project
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **IAM** 屏幕上，点击 **添加** 按钮，将 TPU 添加到该项目，如 *图 5.4* 所示：![图 5.4 – 向项目中添加成员
- en: '](img/image0071.jpg)'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/image0071.jpg)'
- en: Figure 5.4 – Adding a member to a project
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.4 – 向项目中添加成员
- en: Then, fill in the TPU service account details in the **New members** box. Under
    **Select a role**, find **Service Agent Roles**, and then find **Cloud ML Service
    Agent**. This is shown in *Figure 5.5*:![Figure 5.5 – Assigning the Cloud ML Service
    Agent role to the TPU service account
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在 **新成员** 框中填写 TPU 服务账户的详细信息。在 **选择角色** 下，找到 **服务代理角色**，然后找到 **Cloud ML 服务代理**。如
    *图 5.5* 所示：![图 5.5 – 为 TPU 服务账户分配 Cloud ML 服务代理角色
- en: '](img/image0091.jpg)'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/image0091.jpg)'
- en: Figure 5.5 – Assigning the Cloud ML Service Agent role to the TPU service account
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.5 – 为 TPU 服务账户分配 Cloud ML 服务代理角色
- en: We are not done with the TPU service account yet. We also have to let it access
    our training data and our storage to write the training results to, such as checkpoints
    and model assets. This means adding a couple of new roles for our TPU service
    account.
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还没有完成 TPU 服务账户的配置。我们还需要让它访问我们的训练数据，并将训练结果（如检查点和模型资产）写入存储。这意味着我们需要为 TPU 服务账户添加几个新的角色。
- en: Let's click **Add another role** and proceed to look for **Project**, as in
    *Figure 5.6*:![Figure 5.6 – Assigning the Project Viewer role to the TPU service
    account
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们点击 **添加另一个角色**，然后继续寻找 **项目**，如 *图 5.6* 所示：![图 5.6 – 为 TPU 服务账户分配项目查看者角色
- en: '](img/image0111.jpg)'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/image0111.jpg)'
- en: Figure 5.6 – Assigning the Project Viewer role to the TPU service account
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.6 – 为 TPU 服务账户分配项目查看者角色
- en: Likewise, we also add the **Cloud Storage Admin** role, as in *Figure 5.7*:![Figure
    5.7 – Assigning the Storage Admin role to the TPU service account
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，我们还需要添加 **Cloud Storage Admin** 角色，如 *图 5.7* 所示：![图 5.7 – 为 TPU 服务账户分配存储管理员角色
- en: '](img/image0131.jpg)'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/image0131.jpg)'
- en: Figure 5.7 – Assigning the Storage Admin role to the TPU service account
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.7 – 为 TPU 服务账户分配存储管理员角色
- en: Once you have all three roles set up, click **Save**.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦设置好所有三个角色，点击 **保存**。
- en: Whitelisting access for reading training data and writing artifacts (alternative)
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 白名单访问以读取训练数据并写入工件（替代方案）
- en: 'The previous method grants rather broad permissions to the TPU service. It
    allows the TPU to have an admin credential to all of your storage buckets. If
    you''d prefer to limit the TPU service to only certain buckets, then you can put
    the TPU service account in each bucket''s **access control list** (**ACL**). You
    can do this for your training data bucket and if you want the training job to
    write to another bucket, then do the same for that as well:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 前述方法赋予 TPU 服务较为广泛的权限，允许 TPU 拥有对所有存储桶的管理员权限。如果你希望将 TPU 服务的权限限制为仅限某些存储桶，可以将 TPU
    服务账户放入每个存储桶的 **访问控制列表**（**ACL**）中。你可以为训练数据存储桶执行此操作，如果希望训练任务将结果写入另一个存储桶，则也可以为该存储桶执行相同操作：
- en: We can start by editing the bucket permissions, as shown in *Figure 5.8*. Select
    the **PERMISSIONS** tab:![Figure 5.8 – Editing the storage bucket permissions
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以从编辑存储桶权限开始，如 *图 5.8* 所示。选择 **权限** 标签页：![图 5.8 – 编辑存储桶权限
- en: '](img/image0151.jpg)'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/image0151.jpg)'
- en: Figure 5.8 – Editing the storage bucket permissions
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.8 – 编辑存储桶权限
- en: Then, click on **ADD**, as shown in *Figure 5.**9*:![Figure 5.9 – Adding the
    TPU service account to the bucket ACL
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，点击 **添加**，如*图 5.9*所示：![图 5.9 – 将 TPU 服务账户添加到存储桶 ACL
- en: '](img/image0171.jpg)'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/image0171.jpg)'
- en: Figure 5.9 – Adding the TPU service account to the bucket ACL
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.9 – 将 TPU 服务账户添加到存储桶 ACL
- en: 'Then, add two new roles to the TPU service account by filling in the service
    account name, as in *Figure 5.10*. In this example, we will use the same bucket
    for hosting training data and writing training artifacts. Therefore, we need to
    add two roles from **Cloud Storage Legacy**: **Storage Legacy Bucket Reader**
    and **Storage Legacy Bucket Writer**:![Figure 5.10 – Whitelisting the TPU service
    account for two roles in the storage bucket'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，通过填写服务账户名称，向 TPU 服务账户添加两个新角色，如*图 5.10*所示。在这个例子中，我们将使用相同的存储桶来托管训练数据和写入训练产物。因此，我们需要添加两个来自
    **Cloud Storage Legacy** 的角色：**Storage Legacy Bucket Reader** 和 **Storage Legacy
    Bucket Writer**：![图 5.10 – 将 TPU 服务账户列入存储桶的两个角色白名单
- en: '](img/image0192.jpg)'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/image0192.jpg)'
- en: Figure 5.10 – Whitelisting the TPU service account for two roles in the storage
    bucket
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.10 – 将 TPU 服务账户列入存储桶的两个角色白名单
- en: Once these roles are added, click **Save**.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦添加了这些角色，点击 **保存**。
- en: We have completed the minimum administrative work in order to use the Cloud
    TPU for our model training workflow. In the next section, we are going to see
    how to refactor our code and set up the distributed training strategy for the
    TPU.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了使用 Cloud TPU 进行模型训练工作流所需的最基本管理工作。在接下来的部分，我们将看到如何重构代码并设置 TPU 的分布式训练策略。
- en: Execution command and format
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行命令及格式
- en: 'AI Platform also provides model training as a service. It enables users to
    submit a training job from their local environment''s command line. The job will
    run on Google Cloud''s compute cluster (with options for the CPU, TPU, or GPU
    in different pricing tiers). If you are new to the concept of training-as-a-service,
    refer to this link for details: [https://cloud.google.com/ai-platform/training/docs/training-jobs](https://cloud.google.com/ai-platform/training/docs/training-jobs).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: AI 平台还提供作为服务的模型训练功能。它允许用户从本地环境的命令行提交训练任务。该任务将在 Google Cloud 的计算集群上运行（提供不同定价层级的
    CPU、TPU 或 GPU 选项）。如果你不熟悉作为服务的训练概念，可以参考此链接了解更多详情：[https://cloud.google.com/ai-platform/training/docs/training-jobs](https://cloud.google.com/ai-platform/training/docs/training-jobs)。
- en: 'Besides cloud training jobs, AI Platform can also do cloud inferencing jobs.
    The command we are going to run is for submitting a cloud training job. You can
    keep this link as a reference as you follow along with this chapter''s exercises:
    [https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training](https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training).
    Since the approach is to keep the training script in a client node (that is, a
    local computer with Google Cloud SDK installed), we need to let the Google Cloud
    runtime know, when executing `gcloud ai-platform jobs submit training`, where
    all the training scripts are. Also, because there are libraries that will be imported
    in our script, we need to specify the information, such as their versions and
    the library names and versions, in a file named `setup.py`. In order to accomplish
    this, it is necessary to create a small `setup.py` file in your working directory:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 除了云端训练任务，AI 平台还可以执行云推理任务。我们即将运行的命令用于提交云端训练任务。你可以在跟随本章节的练习时保留这个链接作为参考：[https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training](https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training)。由于方法是将训练脚本保存在客户端节点（即安装了
    Google Cloud SDK 的本地计算机）中，我们需要在执行 `gcloud ai-platform jobs submit training` 时，让
    Google Cloud 运行时知道所有训练脚本的位置。此外，因为脚本中会导入一些库，我们还需要在名为 `setup.py` 的文件中指定信息，例如库的版本、名称等。为此，必须在工作目录中创建一个小的
    `setup.py` 文件：
- en: 'In the command terminal (for Mac OS X or Linux) of your working directory,
    type the following:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的工作目录中的命令终端（对于 Mac OS X 或 Linux）中，输入以下内容：
- en: '[PRE4]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now that we are ready to set up the command for distributed training in the
    Cloud TPU, let''s first take a look at the command and execution format. Recall
    that we stated earlier that this task will be executed using the Cloud SDK running
    in a client. In general, the client node will issue the `gcloud` command with
    input flags, such as this:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们准备设置用于 Cloud TPU 的分布式训练命令，让我们首先看看命令及执行格式。回想一下，我们之前提到过，这个任务将在客户端运行的 Cloud
    SDK 中执行。一般来说，客户端节点将使用输入标志发出 `gcloud` 命令，格式如下：
- en: '[PRE5]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: There are many more flags (user input parameters) available than shown here.
    For detailed descriptions of all the possible input parameters, refer to the TensorFlow
    Google Cloud AI Platform reference ([https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training](https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training))
    and the Cloud SDK documentation ([https://cloud.google.com/sdk/gcloud/reference/ai-platform](https://cloud.google.com/sdk/gcloud/reference/ai-platform)).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 有比这里显示的更多标志（用户输入参数）。有关所有可能的输入参数的详细描述，请参阅TensorFlow Google Cloud AI平台参考文档([https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training](https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training))和Cloud
    SDK文档([https://cloud.google.com/sdk/gcloud/reference/ai-platform](https://cloud.google.com/sdk/gcloud/reference/ai-platform))。
- en: Cloud command arguments
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云命令参数
- en: 'The example command (discussed ahead in this section), illustrates a directory
    structure as shown in *Figure 5.11*:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 示例命令（在本节后面讨论），说明了如图*5.11*所示的目录结构：
- en: '![Figure 5.11 – Directory structure and file organization in a local client
    for an example training run'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.11 – 本地客户端示例训练运行的目录结构和文件组织'
- en: '](img/image0211.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image0211.jpg)'
- en: Figure 5.11 – Directory structure and file organization in a local client for
    an example training run
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.11 – 本地客户端示例训练运行的目录结构和文件组织
- en: 'Some of the folder names in the preceding figure are personal choices: `vs_code`,
    `python`, `ScriptProject`. You can name these folders to your preference. The
    training script named `traincloudtpu_resnet_cache` is also a personal choice.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述图中的某些文件夹名称是个人选择：`vs_code`、`python`、`ScriptProject`。您可以根据自己的喜好命名这些文件夹。名为`traincloudtpu_resnet_cache`的训练脚本也是个人选择。
- en: 'Let''s take a look at this example command. This example command can be divided
    into two parts based on `-- \`. The first part of the command includes the following:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这个示例命令。这个示例命令可以基于`-- \`分为两部分。命令的第一部分包括以下内容：
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This command is executed in the `vs_code` directory shown in *Figure 5.11*.
    In this directory, you will find `setup.py`. This is the file that tells the `gcloud`
    runtime about the dependencies or packages required for the training script. `cloudtpu`
    is just a name we provided for this training run. We also need to specify a staging
    bucket (a cloud storage bucket) for serialization of model artifacts during and
    after training.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令在*图5.11*中显示的`vs_code`目录中执行。在这个目录中，您会找到`setup.py`。这个文件告诉`gcloud`运行时有关训练脚本所需的依赖项或包。`cloudtpu`只是我们为这次训练运行提供的一个名称。我们还需要指定一个临时存储桶（云存储桶），用于在训练期间和训练后序列化模型工件。
- en: '`package-path` is the folder for organizing projects. In this case, within
    this package, we are interested in executing a training script, `traincloudtpu_resnet_cache.py`.
    In order for the `gcloud` runtime to find it, we need to specify the following:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`package-path`是组织项目的文件夹。在这种情况下，在此包中，我们有兴趣执行一个训练脚本，`traincloudtpu_resnet_cache.py`。为了让`gcloud`运行时找到它，我们需要指定以下内容：'
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We then specify the TensorFlow Enterprise version to be 2.1 and the Python interpreter
    version to be 3.7, and a scale tier of `BASIC_TPU` should suffice for this example.
    We also set the region to be `us-central1`. The `BASIC_TPU` scale tier provides
    us with a master VM and a TPU VM with eight TPU V2 cores.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们指定TensorFlow Enterprise版本为2.1，Python解释器版本为3.7，这个示例应该足够使用`BASIC_TPU`规模级别。我们还将区域设置为`us-central1`。`BASIC_TPU`规模级别为我们提供了一个主VM和一个具有八个TPU
    V2核心的TPU VM。
- en: As stated earlier, `-- \` separates the `gcloud` system flags from any other
    user-defined flags that are specified and serve as input parameters to the training
    script. This separation is necessary and by design. Do not mix system flags with
    user-defined flags. See the SDK reference ([https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training](https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training))
    for details about positional arguments.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面所述，`-- \`将`gcloud`系统标志与指定的任何其他用户定义的标志分隔开，并作为训练脚本的输入参数。这种分隔是必要且设计良好的。请勿混合系统标志和用户定义的标志。有关位置参数的详细信息，请参阅SDK参考文档([https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training](https://cloud.google.com/sdk/gcloud/reference/ai-platform/jobs/submit/training))。
- en: 'Now, let''s take a look at the second half of this command, which consists
    of user-defined flags:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看这个命令的后半部分，其中包含用户定义的标志：
- en: '[PRE15]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We specify `distribution_strategy=tpu` as a user-defined flag because we may
    use this value in conditional logic to select the proper distribution strategy.
    We also specify `model_dir`, which is a cloud storage path that we grant write
    permissions to the TPU service in order to serialize checkpoints and model assets.
    Then, for the remaining flags, we specify the number of epochs for training in
    `train_epochs`, and the path to the training data indicated by `data_dir`, which
    is also a cloud storage path that we grant read permissions to the TPU service.
    The TPU's distributed training strategy ([https://www.tensorflow.org/guide/distributed_training#tpustrategy](https://www.tensorflow.org/guide/distributed_training#tpustrategy))
    implements all necessary operations across multiple cores.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将 `distribution_strategy=tpu` 指定为用户定义的标志，因为我们可能会在条件逻辑中使用这个值来选择适当的分发策略。我们还指定了
    `model_dir`，这是一个云存储路径，我们授予TPU服务写权限以序列化检查点和模型资源。然后，对于剩余的标志，我们指定了在 `train_epochs`
    中进行训练的时期数，并指定了 `data_dir` 指示的训练数据路径，这也是一个云存储路径，我们授予TPU服务读权限。TPU的分布式训练策略（[https://www.tensorflow.org/guide/distributed_training#tpustrategy](https://www.tensorflow.org/guide/distributed_training#tpustrategy)）实现了跨多个核心的所有必要操作。
- en: Organizing the training script
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组织训练脚本
- en: 'The general structure of the training script for this example follows a minimalist
    style. In practice, it is common to organize Python code into multiple files and
    modules. Therefore, we will have everything we need in one Python script, `train.py`.
    Its pseudo-code is as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 本示例的训练脚本的一般结构采用了极简风格。在实践中，将Python代码组织到多个文件和模块中是很常见的。因此，我们将所有需要的内容放在一个Python脚本
    `train.py` 中。其伪代码如下：
- en: '[PRE18]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Once the `main()` routine is run, it will invoke `run()`, where a training strategy
    is defined, then a data pipeline is built, followed by building and training a
    model, then finally, it saves the results to cloud storage.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦运行了 `main()` 程序，它将调用 `run()`，在其中定义训练策略，然后构建数据流水线，接着构建和训练模型，最后将结果保存到云存储。
- en: Next, we will dive into the actual code for `train.py`. Let's start with the
    data streaming pipeline.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入研究 `train.py` 的实际代码。让我们从数据流水线开始。
- en: Data streaming pipeline
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据流水线
- en: Currently, the only way to stream a dataset when using Google Cloud AI Platform
    is through `tf.io` and `tf.dataTFRecordDataset`.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用 Google Cloud AI Platform 时，目前唯一的数据流方式是通过 `tf.io` 和 `tf.dataTFRecordDataset`。
- en: 'Our dataset (TFRecord) is already in a storage bucket. It is organized as shown
    in *Figure 5.12*:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据集（TFRecord）已经在一个存储桶中。其组织结构如 *图 5.12* 所示：
- en: '![Figure 5.12 – Cloud storage for the flower image classification dataset'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.12 – 用于花卉图像分类数据集的云存储'
- en: '](img/image023.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image023.jpg)'
- en: Figure 5.12 – Cloud storage for the flower image classification dataset
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 – 用于花卉图像分类数据集的云存储
- en: 'In our training script''s `run` function, we need to specify the path to the
    cloud storage for the training data. We can leverage `tf.io.gfile` to encode the
    filename pattern for multiple parts. Then, we use `tf.data.TFRecordDataset` to
    instantiate a dataset object:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们训练脚本的 `run` 函数中，我们需要指定训练数据的云存储路径。我们可以利用 `tf.io.gfile` 对多个部分的文件名模式进行编码。接着，我们使用
    `tf.data.TFRecordDataset` 实例化一个数据集对象：
- en: '[PRE35]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: As the preceding code indicates, after we encode the dataset name patterns,
    we then use `tf.data.Dataset.list_files` to encode a list of all the filenames
    that follow the pattern. Then, `tf.data.TFRecordDataset` instantiates a dataset
    reader object. Once these lines are executed during runtime, it effectively establishes
    the connection between the TPU and cloud storage. The dataset object streams the
    data into the model during the training workflow.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正如前面的代码所示，在编码数据集名称模式后，我们使用 `tf.data.Dataset.list_files` 来编码符合模式的所有文件名列表。然后，`tf.data.TFRecordDataset`
    实例化一个数据集读取器对象。一旦在运行时执行了这些行，它有效地建立了TPU与云存储之间的连接。数据集对象在训练工作流中向模型流送数据。
- en: Why don't we use a `tf.keras` generator pattern, such as `ImageDataGenerator`
    or `flow_from_directory`? Well, it turns out this is not yet supported by the
    `gcloud ai-platform jobs submit training` command. This pattern is very convenient
    when the data is mounted or directly available in the filesystem, and it also
    easily takes care of the one-hot encoding of labels for classification problems,
    image normalization, and standardization processes via optional arguments through
    user input.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为什么我们不使用`tf.keras`生成器模式，比如`ImageDataGenerator`或`flow_from_directory`？实际上，这是因为`gcloud
    ai-platform jobs submit training`命令目前还不支持这种模式。这个模式在数据挂载或直接存储在文件系统中时非常方便，且通过用户输入的可选参数，能够轻松处理分类问题中的标签一热编码、图像归一化和标准化等过程。
- en: 'We have to handle image standardization (resampling to a different height and
    width) by writing our own function. Here is a function that performs these operations
    on `TFRecordDataset`:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们必须通过编写自己的函数来处理图像标准化（调整为不同的高度和宽度）。以下是一个在`TFRecordDataset`上执行这些操作的函数：
- en: '[PRE36]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'This `decode_and_resize` function parses the dataset to a JPEG image with the
    corresponding color value range, then parse the labels, one-hot encodes the image,
    and resizes the image using the nearest neighbor method in order to standardize
    it to 224 by 224 pixels for our model of choice (ResNet). This function also provides
    different ways to return the label, whether it is as plain text or an integer.
    If you wish, you can return labels in different notations and styles by simply
    adding the notations of your interest to the `return` tuple:'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个`decode_and_resize`函数解析数据集中的JPEG图像，并调整相应的颜色值范围，然后解析标签，对图像进行一热编码，并使用最近邻方法对图像进行调整大小，以将其标准化为224×224像素，适应我们选择的模型（ResNet）。该函数还提供了不同的方式返回标签，无论是纯文本还是整数。如果需要，你可以通过将感兴趣的标注添加到`return`元组中，返回不同格式和风格的标签：
- en: '[PRE37]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Then, unpack the return tuple according to their position (the order as indicated
    in the preceding `return` statement) in the caller function.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，根据返回元组在调用函数中的位置（如前述`return`语句所示的顺序）解包返回值。
- en: 'Now that we have the `decode_and_resize` function ready, this is how we apply
    it to every element in our `dataset` object:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 既然我们已经准备好了`decode_and_resize`函数，接下来就是如何将它应用到`dataset`对象中的每个元素：
- en: '[PRE38]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Then, we rescale or normalize the pixel values to be in a range of `[0, 1]`
    in each image so that all the images are within same pixel range for training.
    Let''s create a `normalize` function:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将每张图像的像素值重新缩放或归一化到`[0, 1]`范围内，以便所有图像的像素值范围一致，适合进行训练。让我们来创建一个`normalize`函数：
- en: '[PRE39]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We need to prepare the training data by applying a batch operation. We use
    the following function to achieve this:'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们需要通过应用批处理操作来准备训练数据。我们使用以下函数来实现这一点：
- en: '[PRE40]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The preceding function accepts a dataset, then shuffles it and batches it based
    on a global variable, `BATCH_SIZE`, and prefetches it for the training pipeline.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述函数接受一个数据集，然后根据全局变量`BATCH_SIZE`对其进行洗牌和批处理，并为训练管道预取数据。
- en: 'We use the `map` method again to apply the `normalize` operation to our training
    and validation datasets:'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们再次使用`map`方法，将`normalize`操作应用到我们的训练集和验证集：
- en: '[PRE41]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This is the data pipeline part of the `run` function. We are not done with the
    `run` function yet.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是`run`函数的数据管道部分。我们还没有完成`run`函数。
- en: 'Next, we are going to set up the model and conduct the training. We will leverage
    the popular transfer learning technique, where a prebuilt model is applied and
    trained with our own training dataset. The prebuilt model of interest here is
    the ResNet-50 image classification model. Remember how we already specified our
    TPU-based distributed strategy for training? We can simply wrap the model definition
    and optimizer choice here with the strategy:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将设置模型并进行训练。我们将利用流行的迁移学习技术，在我们的训练数据集上应用并训练一个预构建的模型。这里感兴趣的预构建模型是ResNet-50图像分类模型。记得我们之前已经为训练指定了基于TPU的分布式策略吗？我们可以在这里简单地将模型定义和优化器选择与该策略结合：
- en: '[PRE42]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The preceding code describes the model architecture, designates the optimization
    strategy for training, and compiles the model. We use the ResNet-50 feature vector
    as our base model for the classification of the five flower types.
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码描述了模型架构，指定了训练的优化策略，并编译了模型。我们使用ResNet-50特征向量作为分类五种花卉类型的基础模型。
- en: 'Then, we set up the checkpoint and callbacks with the help of the following
    code:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们通过以下代码来设置检查点和回调函数：
- en: '[PRE43]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Callbacks will save the model weights and biases for each epoch of training
    separately as checkpoints.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 回调函数将在每个 epoch 训练过程中分别保存模型的权重和偏置作为检查点。
- en: 'Next, we need to set up sample sizes at each epoch for training and cross validation:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要在每个 epoch 设置训练和交叉验证的样本大小：
- en: '[PRE44]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Then, at last, this is the code for the training process:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，这里是训练过程的代码：
- en: '[PRE45]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: This concludes the `run` function. This is a rather long function. Make sure
    you observe all the proper indentation demarcation. This is just a minimalist
    example for Google Cloud AI Platform. It includes all the necessary code and patterns
    for a scalable data pipeline, distributed training workflow, and TPU utilization.
    In your practice, you can organize and refactor your code to best suit your needs
    for clarity and maintainability.
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这就是 `run` 函数的结束。这个函数比较长，请确保注意所有正确的缩进标识。这只是 Google Cloud AI Platform 的一个最小示例。它包含了一个可扩展数据管道、分布式训练工作流和
    TPU 使用的所有必要代码和模式。在实际应用中，您可以根据需要组织和重构代码，以提高代码的清晰性和可维护性。
- en: Submitting the training script
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提交训练脚本
- en: Now is the time to submit our training script. We submit it from the `vs_code`
    directory according to the local directory organization mentioned in *Figure 5.11*.
    The TensorFlow runtime version in Cloud AI Platform is not necessarily most up
    to date with respect to the TensorFlow stable release in Cloud AI Notebook. As
    we know, the current stable release in Cloud Notebook is TFE 2.3\. However, in
    Cloud AI Platform, the most recent release is 2.2\. Therefore we use `--runtime-version=2.2`.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是提交我们训练脚本的时候了。我们根据 *图 5.11* 中提到的本地目录结构，从 `vs_code` 目录提交它。Cloud AI Platform
    中的 TensorFlow 运行时版本不一定是最新的，跟 Cloud AI Notebook 中的 TensorFlow 稳定版本相比。如我们所知，目前 Cloud
    Notebook 中的稳定版本是 TFE 2.3\，然而在 Cloud AI Platform 中，最新的版本是 2.2\。因此我们使用 `--runtime-version=2.2`。
- en: 'You can check this link to ascertain the latest runtime: [https://cloud.google.com/ai-platform/prediction/docs/runtime-version-list](https://cloud.google.com/ai-platform/prediction/docs/runtime-version-list).'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下链接查看最新的运行时版本：[https://cloud.google.com/ai-platform/prediction/docs/runtime-version-list](https://cloud.google.com/ai-platform/prediction/docs/runtime-version-list)。
- en: 'The following is the command and terminal output:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是命令和终端输出：
- en: '[PRE46]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '[PRE58]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Your job is still active. You can view the status of your job with the following
    command:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 您的作业仍然处于活动状态。您可以使用以下命令查看作业的状态：
- en: '[PRE60]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Or, you can continue streaming the logs with the following command:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以使用以下命令继续流式传输日志：
- en: '[PRE61]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '[PRE62]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: The preceding command submits a piece of training code to the Cloud TPU. From
    the current directory (`vs_code`), there is a subfolder (`python`), which contains
    a `ScriptProject` module. In `ScriptProject`, there is a part of the script named
    `trainer.py`. You can see the content of `trainer.py` in the GitHub repo at [https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/cnn_on_tpu/custom_model_on_tpu/trainer.py](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/cnn_on_tpu/custom_model_on_tpu/trainer.py).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令将一段训练代码提交到 Cloud TPU。从当前目录（`vs_code`）来看，有一个子文件夹（`python`），其中包含一个 `ScriptProject`
    模块。在 `ScriptProject` 中，有一部分脚本名为 `trainer.py`。您可以在 GitHub 仓库中查看 `trainer.py` 的内容，链接为：[https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/cnn_on_tpu/custom_model_on_tpu/trainer.py](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/cnn_on_tpu/custom_model_on_tpu/trainer.py)。
- en: 'We also have to specify the following parameters, which are used in `trainer.py`
    ([https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/cnn_on_tpu/custom_model_on_tpu/trainer.py](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/cnn_on_tpu/custom_model_on_tpu/trainer.py)):'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还必须指定以下参数，这些参数在 `trainer.py` 中使用（[https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/cnn_on_tpu/custom_model_on_tpu/trainer.py](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/cnn_on_tpu/custom_model_on_tpu/trainer.py)）：
- en: '[PRE64]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '[PRE67]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'As soon as we submit the preceding command, it will be in the queue for execution
    in your Cloud AI Platform instance. To find out where we can monitor the training
    process, we can run `gcloud ai-platform` `jobs describe traincloudtpu_tfk_resnet50`
    to retrieve a URL to the running log:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们提交前面的命令，它将进入您的 Cloud AI Platform 实例队列中等待执行。要查看我们可以在哪里监控训练过程，可以运行`gcloud
    ai-platform` `jobs describe traincloudtpu_tfk_resnet50` 来获取正在运行日志的 URL：
- en: '[PRE68]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '[PRE77]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '[PRE85]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '[PRE86]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: You can view job in Cloud Console at [https://console.cloud.google.com/mlengine/jobs/traincloudtpu_tfk_resnet50?project=project1-190517](https://console.cloud.google.com/mlengine/jobs/traincloudtpu_tfk_resnet50?project=project1-190517).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 Cloud Console 中查看作业 [https://console.cloud.google.com/mlengine/jobs/traincloudtpu_tfk_resnet50?project=project1-190517](https://console.cloud.google.com/mlengine/jobs/traincloudtpu_tfk_resnet50?project=project1-190517)。
- en: You can view the logs at [https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2Ftraincloudtpu_tfk_resnet50&project=project1-190517](https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2Ftraincloudtpu_tfk_resnet50&project=project1-190517).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2Ftraincloudtpu_tfk_resnet50&project=project1-190517](https://console.cloud.google.com/logs?resource=ml_job%2Fjob_id%2Ftraincloudtpu_tfk_resnet50&project=project1-190517)
    查看日志。
- en: 'As per the preceding code the preceding highlighted output, we can go to the
    logs URL in a browser and observe the training progress. The following are some
    example excerpts (see *Figure 5.13* and *Figure 5.14*):'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的代码和高亮输出，我们可以在浏览器中访问日志 URL，并观察训练进度。以下是一些示例摘录（参见 *图 5.13* 和 *图 5.14*）：
- en: '![Figure 5.13 – Google Cloud AI Platform TPU training log example excerpt 1'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.13 – Google Cloud AI Platform TPU 训练日志示例摘录 1'
- en: '](img/image025.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image025.jpg)'
- en: Figure 5.13 – Google Cloud AI Platform TPU training log example excerpt 1
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13 – Google Cloud AI Platform TPU 训练日志示例摘录 1
- en: 'This is a lengthy log that will run until the training job is complete. Toward
    the end of the training run, the log will look like this:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个较长的日志，直到训练作业完成才会停止。接近训练结束时，日志看起来像这样：
- en: '![Figure 5.14 – Google Cloud AI Platform TPU training log example excerpt 2'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.14 – Google Cloud AI Platform TPU 训练日志示例摘录 2'
- en: '](img/image027.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image027.jpg)'
- en: Figure 5.14 – Google Cloud AI Platform TPU training log example excerpt 2
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.14 – Google Cloud AI Platform TPU 训练日志示例摘录 2
- en: 'In the storage bucket, we see the folder created by the training workflow (*Figure
    5.15*):'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在存储桶中，我们看到由训练工作流创建的文件夹（*图 5.15*）：
- en: '![Figure 5.15 – Folder created by the TPU training workflow'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.15 – TPU 训练工作流创建的文件夹'
- en: '](img/image029.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image029.jpg)'
- en: Figure 5.15 – Folder created by the TPU training workflow
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.15 – TPU 训练工作流创建的文件夹
- en: 'Inside this bucket, we see the checkpoints and model assets (*Figure 5.16*):'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个存储桶里，我们看到了检查点和模型资产（*图 5.16*）：
- en: '![Figure 5.16 – Model checkpoints and assets after the training workflow is
    completed by the TPU'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.16 – TPU 完成训练工作流后的模型检查点和资产'
- en: '](img/image031.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image031.jpg)'
- en: Figure 5.16 – Model checkpoints and assets after the training workflow is completed
    by the TPU
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.16 – TPU 完成训练工作流后的模型检查点和资产
- en: It is exactly the same as if the training is done on a local standalone machine.
    The complete `trainer.py` is available at [https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/cnn_on_tpu/custom_model_on_tpu/trainer.py](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/cnn_on_tpu/custom_model_on_tpu/trainer.py).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 它与在本地独立机器上训练时完全相同。完整的 `trainer.py` 文件可在 [https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/cnn_on_tpu/custom_model_on_tpu/trainer.py](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/cnn_on_tpu/custom_model_on_tpu/trainer.py)
    获取。
- en: Next, we are going to take a look at how to reuse what we have learned here.
    As it turns out, if we want to use a model available in TensorFlow Hub, we can
    reuse the training patterns, file organization, and workflow. However, a slight
    change is required. This is because currently, the TPU has no direct access to
    TensorFlow Hub's module URL.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看如何重用我们在这里学到的内容。事实证明，如果我们想要使用 TensorFlow Hub 中可用的模型，我们可以重用训练模式、文件组织和工作流。但是，稍微需要进行一些调整。这是因为目前
    TPU 无法直接访问 TensorFlow Hub 的模块 URL。
- en: Working with models in TensorFlow Hub
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 TensorFlow Hub 中使用模型
- en: 'TensorFlow Hub hosts a huge collection of pre-trained models. However, in order
    to use them, the user or client code must be able to connect to the hub and download
    the model via the RESTful API to the client''s TensorFlow runtime. Currently,
    this cannot be done with the TPU. Therefore, we have to download the model we
    are interested in from TensorFlow Hub to our local computer, then upload it to
    cloud storage, where it can be accessed by the TPU. Typically, the following is
    how you would implement a pre-trained model from TensorFlow Hub using the `tf.keras`
    API:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Hub 托管了大量预训练模型。然而，要使用这些模型，用户或客户端代码必须能够连接到 Hub 并通过 RESTful API 下载模型到客户端的
    TensorFlow 运行时。目前，TPU 无法直接进行此操作。因此，我们必须先从 TensorFlow Hub 下载我们感兴趣的模型到本地计算机，然后将其上传到云存储，以便
    TPU 可以访问。通常情况下，以下是使用 `tf.keras` API 从 TensorFlow Hub 实现预训练模型的步骤：
- en: '[PRE87]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: '[PRE89]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'As shown in the preceding lines of code, the URL to a pre-trained model is
    passed into `KerasLayer`. However, currently, the TPU running in Cloud AI Platform
    has no direct access to TensorFlow Hub''s URL. To download the model, follow the
    simple instructions from TensorFlow Hub''s site, as shown in *Figure 5.17*:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述代码所示，预训练模型的 URL 会传递给 `KerasLayer`。然而，目前，运行在 Cloud AI Platform 上的 TPU 无法直接访问
    TensorFlow Hub 的 URL。为了下载模型，请按照 TensorFlow Hub 网站上的简单说明操作，如*图 5.17*所示：
- en: '![Figure 5.17 – Downloading a pre-trained model from TensorFlow Hub'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.17 – 从 TensorFlow Hub 下载预训练模型'
- en: '](img/image033.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image033.jpg)'
- en: Figure 5.17 – Downloading a pre-trained model from TensorFlow Hub
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.17 – 从 TensorFlow Hub 下载预训练模型
- en: 'The model is compressed. Once it is extracted, you will see the content, as
    shown in *Figure 5.18*:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 模型已被压缩。解压后，您将看到如*图 5.18*所示的内容：
- en: '![Figure 5.18 – Downloaded pre-trained model from TensorFlow Hub'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.18 – 从 TensorFlow Hub 下载的预训练模型'
- en: '](img/image035.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image035.jpg)'
- en: Figure 5.18 – Downloaded pre-trained model from TensorFlow Hub
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.18 – 从 TensorFlow Hub 下载的预训练模型
- en: 'Once the model is downloaded and extracted, let''s upload it to a storage bucket
    accessible by the TPU service account, as in *Figure 5.19*:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 下载并解压模型后，让我们将其上传到 TPU 服务帐户可以访问的存储桶，如*图 5.19*所示：
- en: '![Figure 5.19 – Uploading the pre-trained model to cloud storage'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.19 – 将预训练模型上传至云存储'
- en: '](img/image037.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/image037.jpg)'
- en: Figure 5.19 – Uploading the pre-trained model to cloud storage
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.19 – 将预训练模型上传至云存储
- en: Notice that we created a `model-cache-dir` folder in our storage bucket, then
    selected **UPLOAD FOLDER**, and the model folder is now available for the TPU
    to use.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在存储桶中创建了一个`model-cache-dir`文件夹，然后选择了**上传文件夹**，现在该模型文件夹已可供 TPU 使用。
- en: 'Then, inside the `run` function, we need to leverage an environmental variable
    to tell the TPU where to find this model:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在 `run` 函数内部，我们需要利用环境变量来告诉 TPU 在哪里找到这个模型：
- en: '[PRE92]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'This line can be inserted before the model definition in the `run` function.
    In the model definition, we will specify the model architecture by using `hub.KerasLayer`,
    as usual:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这行代码可以插入到 `run` 函数中的模型定义之前。在模型定义中，我们将像往常一样使用 `hub.KerasLayer` 来指定模型架构：
- en: '[PRE93]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: '[PRE95]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: '[PRE96]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: '[PRE97]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: '[PRE98]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: '[PRE99]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '[PRE100]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'Because we have the `TFHUB_CACHE_DIR` environmental variable already defined
    with our cloud storage name and path, when the TPU executes the `hub.KerasLayer`
    part of the model architecture code, the TPU runtime will look for the model from
    `TFHUB_CACHE_DIR` first instead of attempting to go through a RESTful API call
    to retrieve the model. After these small modifications are made to the training
    script, we can rename it as `trainer_hub.py`. The training work can be launched
    with a similar invocation style:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经在环境变量中定义了`TFHUB_CACHE_DIR`，并指定了云存储名称和路径，因此当 TPU 执行模型架构代码中的`hub.KerasLayer`部分时，TPU
    运行时会首先从`TFHUB_CACHE_DIR`查找模型，而不是尝试通过 RESTful API 调用来获取模型。对训练脚本进行这些小的修改后，我们可以将其重命名为`trainer_hub.py`。训练工作可以通过类似的调用方式启动：
- en: '[PRE101]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '[PRE102]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: '[PRE103]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '[PRE104]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '[PRE105]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '[PRE106]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: '[PRE107]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: '[PRE108]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: '[PRE109]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '[PRE110]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '[PRE111]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: '[PRE112]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: '[PRE113]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: Your job is still active. You may view the status of your job with the command
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 您的任务仍在进行中。您可以使用以下命令查看任务的状态
- en: '[PRE115]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: or continue streaming the logs with the command
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 或继续使用命令流式传输日志
- en: '[PRE116]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: '[PRE117]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: '[PRE118]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: The complete `trainer_hub.py` code is in [https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/tfhub_on_tpu/tfhub_resnet_fv_on_tpu/trainer_hub.py](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/tfhub_on_tpu/tfhub_resnet_fv_on_tpu/trainer_hub.py).
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的 `trainer_hub.py` 代码可在 [https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/tfhub_on_tpu/tfhub_resnet_fv_on_tpu/trainer_hub.py](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/tfhub_on_tpu/tfhub_resnet_fv_on_tpu/trainer_hub.py)
    查阅。
- en: Next, we are going to take a look at how to use the `gcloud ai-platform` command
    to leverage the GPU for a similar training job.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看看如何使用`gcloud ai-platform`命令利用GPU进行类似的训练工作。
- en: Using the Google Cloud GPU through AI Platform
  id: totrans-289
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过AI Platform使用Google Cloud GPU
- en: Having worked through the previous section for utilizing Cloud TPU with AI Platform,
    we are ready to do the same with the GPU. As it turns out, the formats of training
    script and invocation commands are very similar. With the exception of a few more
    parameters and slight differences in the distributed strategy definition, everything
    else remains the same.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成了上一节中关于使用AI Platform的Cloud TPU的部分后，我们准备好使用GPU进行同样的操作。事实证明，训练脚本和调用命令的格式非常相似。除了增加一些参数和在分布式策略定义上有些许差异外，其他一切都保持不变。
- en: 'There are several distributed strategies ([https://www.tensorflow.org/guide/distributed_training#types_of_strategies](https://www.tensorflow.org/guide/distributed_training#types_of_strategies))
    currently available. For a TensorFlow Enterprise distribution in Google AI Platform,
    `MirroredStrategy` and `TPUStrategy` are the only two that are fully supported.
    All the others are experimental. Therefore, in this section''s example, we will
    use `MirroredStrategy`. This strategy creates copies of all the variables in the
    model on each GPU. As these variables are updated at each gradient decent step,
    the value updates are copied to each GPU synchronously. By default, this strategy
    uses an `NVIDIA NCCL` all-reduce implementation. Now, we are going to start with
    the following steps:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 目前有几种分布式策略（[https://www.tensorflow.org/guide/distributed_training#types_of_strategies](https://www.tensorflow.org/guide/distributed_training#types_of_strategies)）可供选择。对于Google
    AI Platform中的TensorFlow Enterprise版本，`MirroredStrategy`和`TPUStrategy`是唯一完全支持的策略。其他策略都处于实验阶段。因此，在本节的示例中，我们将使用`MirroredStrategy`。该策略在每个GPU上创建模型中所有变量的副本。由于这些变量在每次梯度下降步骤时都会更新，值的更新会同步复制到每个GPU。默认情况下，该策略使用`NVIDIA
    NCCL`的全归约实现。现在，我们将从以下步骤开始：
- en: 'We can start with small modifications to the TPU training script used in the
    previous section. Let''s implement a condition for selecting a distributed strategy
    based on the choice of TPU or GPU:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以从对上一节使用的TPU训练脚本进行小的修改开始。让我们实现一个条件，根据选择TPU或GPU来选择分布式策略：
- en: '[PRE119]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: The full implementation of the training script for using `MirroredStrategy`
    with the GPU can be found at [https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/tfhub_on_gpu/tfhub_resnet_fv_on_gpu/trainer_hub_gpu.py](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/tfhub_on_gpu/tfhub_resnet_fv_on_gpu/trainer_hub_gpu.py).
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用`MirroredStrategy`与GPU一起使用的训练脚本的完整实现可以在[https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/tfhub_on_gpu/tfhub_resnet_fv_on_gpu/trainer_hub_gpu.py](https://github.com/PacktPublishing/learn-tensorflow-enterprise/blob/master/chapter_05/tfhub_on_gpu/tfhub_resnet_fv_on_gpu/trainer_hub_gpu.py)找到。
- en: 'For `MirroredStrategy`, we will set `scale-tier` to `BASIC_GPU`. This will
    give us a single worker instance with one NVIDIA Tesla K80 GPU. The command to
    invoke training with `trainer_hub_gpu.py` is as follows:'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于`MirroredStrategy`，我们将`scale-tier`设置为`BASIC_GPU`。这将为我们提供一个包含一块NVIDIA Tesla
    K80 GPU的单个工作实例。使用`trainer_hub_gpu.py`启动训练的命令如下：
- en: '[PRE120]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE120]'
- en: Your job is still active. You may view the status of your job with the command
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 您的工作仍在进行中。您可以使用命令查看工作状态
- en: '[PRE121]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: or continue streaming the logs with the command
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 或者使用命令继续流式传输日志
- en: '[PRE122]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: '[PRE123]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: '[PRE124]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: Notice that we changed `scale-tier` to `BASIC_GPU`. We set our script-specific
    `distribution_strategy` flag to `gpu`. This is how we specify what compute instance
    we want and the distribution strategy.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到我们将`scale-tier`更改为`BASIC_GPU`。我们将特定于脚本的`distribution_strategy`标志设置为`gpu`。这就是我们指定所需计算实例和分发策略的方式。
- en: Summary
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: From all the examples that we have covered in this chapter, we learned how to
    leverage a distributed training strategy with the TPU and GPU through AI Platform,
    which runs on TensorFlow Enterprise 2.2 distributions. AI Platform is a service
    that wraps around TPU or GPU accelerator hardware and manages the configuration
    and setup for your training job.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们在本章中涵盖的所有示例中，我们学会了如何通过AI Platform利用TPU和GPU的分布式训练策略，该平台运行在TensorFlow Enterprise
    2.2版本上。AI Platform是一个封装TPU或GPU加速硬件的服务，并管理您的训练作业的配置和设置。
- en: Currently, in Google AI Platform, the data ingestion pipeline relies on `TFRecordDataset`
    to stream training data in batches into the model training workflow. We also learned
    how to leverage a prebuilt model downloaded from TensorFlow Hub through the use
    of the `TFHUB_CACHE_DIR` environment variable. This is also the means to import
    your own saved model from an offline estate into Google AI Platform. Overall,
    in this platform, we used a TensorFlow Enterprise 2.2 distribution to achieve
    scalable data streaming and distributed training on Google Cloud's TPU or GPU
    and serialized all the model checkpoints and assets back to cloud storage.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，在 Google AI Platform 中，数据摄取管道依赖于`TFRecordDataset`将训练数据批量流式传输到模型训练工作流中。我们还学习了如何通过使用`TFHUB_CACHE_DIR`环境变量来利用从
    TensorFlow Hub 下载的预构建模型。这也是将自己保存的模型从离线环境导入到 Google AI Platform 的方式。总体来说，在该平台上，我们使用
    TensorFlow Enterprise 2.2 发行版来实现可扩展的数据流和在 Google Cloud 的 TPU 或 GPU 上进行分布式训练，并将所有模型检查点和资产序列化并回传至云存储。
- en: In the next chapter, we will use Cloud AI Platform to submit a hyperparameter
    tuning job. Hyperparameter tuning is typically very time-consuming and resource-intensive.
    We will see how to take advantage of the compute power of the Cloud TPU for this
    process.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将使用 Cloud AI Platform 提交一个超参数调优作业。超参数调优通常非常耗时且资源密集。我们将看到如何利用 Cloud TPU
    的计算能力来加速这个过程。
