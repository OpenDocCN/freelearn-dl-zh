- en: 7\. Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7\. 卷积神经网络
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, you will learn how **convolutional neural networks** (**CNNs**)
    process image data. You will also learn how to correctly use a CNN on image data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章你将学习**卷积神经网络**（**CNNs**）如何处理图像数据。你还将学习如何在图像数据上正确使用 CNN。
- en: By the end of the chapter, you will be able to create your own CNN for classification
    and object identification on any image dataset using TensorFlow.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，你将能够使用 TensorFlow 为任何图像数据集创建自己的 CNN，用于分类和物体识别。
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: This chapter covers CNNs. CNNs use convolutional layers that are well-suited
    to extracting features from images. They use learning filters that correlate with
    the task at hand. Simply put, they are very good at finding patterns in images.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讲解的是 CNN。CNN 使用卷积层，这些卷积层非常适合从图像中提取特征。它们使用与任务相关的学习滤波器。简单来说，它们非常擅长在图像中找到模式。
- en: In the previous chapter, you explored regularization and hyperparameter tuning.
    You used L1 and L2 regularization and added dropout to a classification model
    to prevent overfitting on the `connect-4` dataset.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你探讨了正则化和超参数调整。你使用了 L1 和 L2 正则化，并为分类模型添加了 dropout，防止在 `connect-4` 数据集上发生过拟合。
- en: You will now be shifting gears quite a bit as you dive into deep learning with
    CNNs. In this chapter, you will learn the fundamentals of how CNNs process image
    data and how to apply those concepts to your own image classification problem.
    This is truly where TensorFlow shines.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在你深入了解深度学习与 CNN 的过程中，你将经历很大的转变。在本章中，你将学习 CNN 如何处理图像数据，并学会如何将这些概念应用到你自己的图像分类问题中。这里正是
    TensorFlow 大显身手的地方。
- en: CNNs
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CNN
- en: 'CNNs share many common components with the ANNs you have built so far. The
    key difference is the inclusion of one or more convolutional layers within the
    network. Convolutional layers apply convolutions of input data with filters, also
    known as kernels. Think of a **convolution** as an **image transformer**. You
    have an input image, which goes through the CNN and gives you an output label.
    Each layer has a unique function or special ability to detect patterns such as
    curves or edges in an image. CNNs combine the power of deep neural networks and
    kernel convolutions to transform images and make these image edges or curves easy
    for the model to see. There are three key components in a CNN:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 与你迄今为止构建的人工神经网络（ANNs）有许多共同的组成部分。关键的区别是网络中包含了一个或多个卷积层。卷积层通过滤波器，也叫做核，对输入数据进行卷积操作。可以把**卷积**看作是**图像转换器**。你有一个输入图像，这个图像经过
    CNN 处理后会得到一个输出标签。每一层都有独特的功能或特殊能力，能够在图像中检测出如曲线或边缘等模式。CNN 将深度神经网络的强大功能与核卷积结合，能够转换图像，使得这些图像的边缘或曲线对模型来说更加容易识别。CNN
    中有三个关键组件：
- en: '**Input image**: The raw image data'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入图像**：原始图像数据'
- en: '**Filter/kernel**: The image transformation mechanism'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**滤波器/核**：图像转换机制'
- en: '**Output label**: The image classification'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出标签**：图像分类'
- en: The following figure is an example of a CNN in which the image is input into
    the network on the left-hand side and the output is generated on the right-hand
    side. The image components are identified throughout the hidden layers with more
    basic components, such as edges, identified in earlier hidden layers. Image components
    combine in the hidden layers to form recognizable features from the dataset. For
    example, in a CNN to classify images into planes or cars, the recognizable features
    may be filters that resemble a wheel or propellor. Combinations of these features
    will be instrumental in determining whether the image is a plane or a car.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示为例，展示了 CNN 的工作原理：图像从左侧输入网络，右侧生成输出。在隐藏层中，图像的组件被识别出来，较早的隐藏层识别的是更基础的组件，如边缘。图像组件在隐藏层中结合，形成来自数据集的可识别特征。例如，在一个
    CNN 中，用于将图像分类为飞机或汽车时，可识别的特征可能是类似于轮子或螺旋桨的滤波器。这些特征的组合将帮助判断图像是飞机还是汽车。
- en: Finally, the output layer is a dense layer used to determine the specific output
    of the model. For a binary classification model, this may be a dense layer with
    one unit with a sigmoid activation function. For a more complex multi-class classification,
    it may be a dense layer with many units, determined by the number of classes,
    and a softmax activation function to determine one output label for each image
    presented to the model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，输出层是一个密集层，用于确定模型的具体输出。对于二分类模型，这可能是一个带有一个单元的密集层，使用sigmoid激活函数。对于更复杂的多类别分类，这可能是一个带有多个单元的密集层，单元的数量由类别数决定，并且使用softmax激活函数来为每个输入图像确定一个输出标签。
- en: '![Figure 7.1: CNN'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.1：CNN'
- en: '](img/B16341_07_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_01.jpg)'
- en: 'Figure 7.1: CNN'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：CNN
- en: A common CNN configuration includes a convolutional layer followed by a pooling
    layer. These layers are often used together in this order, as pairs (convolution
    and pooling). We'll get into the reason for this later in the chapter, but for
    now, think of these pooling layers as decreasing the size of input images by summarizing
    the filter results.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的CNN配置包括一个卷积层，后面跟着一个池化层。这些层通常以这种顺序（卷积和池化）一起使用，我们稍后会探讨这样做的原因，但目前，你可以把这些池化层看作是通过总结过滤器的结果来减少输入图像的大小。
- en: Before you move deeper into convolutional layers, you first need to understand
    what the data looks like from the computer's perspective.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解卷积层之前，首先需要理解计算机视角下的数据是怎样的。
- en: Image Representation
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像表示
- en: First, consider how a computer processes an image. To a computer, images are
    numbers. To be able to work with images for classification or object identification,
    you need to understand how a model transforms an image input into data. A **pixel**
    in an image file is just a piece of data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，考虑计算机如何处理图像。对计算机来说，图像就是数字。为了能够处理图像进行分类或物体识别，你需要理解模型如何将图像输入转化为数据。图像文件中的**像素**只是数据的一部分。
- en: In the following figure, you can see an example of pixel values for a grayscale
    image of the number eight. For the `28x28`-pixel image, there are a total of `784`
    pixels. Each pixel has a value between `0` and `255` identifying how light or
    dark the pixel is. On the right side, there is one large column vector with each
    pixel value listed. This is used by the model to identify the image.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，你可以看到一个灰度图像中数字八的像素值示例。对于`28x28`像素的图像，共有`784`个像素。每个像素的值在`0`到`255`之间，表示该像素的亮度或暗度。在右侧，有一个大的列向量，其中列出了每个像素的值。这个向量被模型用来识别图像。
- en: '![Figure 7.2: Pixel values'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.2：像素值'
- en: '](img/B16341_07_02.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_02.jpg)'
- en: 'Figure 7.2: Pixel values'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2：像素值
- en: Now that you know what the input data looks like, it's time to get a closer
    look at the convolutional process—more specifically, the convolutional layer.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了输入数据的样子，接下来是时候更仔细地看看卷积过程——更具体地说，是卷积层。
- en: The Convolutional Layer
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积层
- en: Think of a convolution as nothing more than an image transformer with three
    key elements. First, there is an input image, then a filter, and finally, a feature
    map.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 把卷积看作是一个图像变换器，包含三个关键元素。首先是输入图像，然后是过滤器，最后是特征图。
- en: This section will cover each of these in turn to give you a solid idea of how
    images are filtered in a convolutional layer. The convolution is the process of
    passing a filter window over the input data, which will result in a map of activations
    known as a `3x3` for two-dimensional data, in which the specific values of the
    filter are learned during the training process. The filter passes across the input
    data with a window size equal to the size of the filter, then, the scalar product
    of the filter and section of the input data is applied, producing what's known
    as an **activation**. As this process continues across the entire input data using
    the same filter, the map of activations is produced, also known as the **feature
    map**.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将依次介绍这些内容，帮助你深入了解图像在卷积层中的过滤过程。卷积是将过滤窗口应用到输入数据的过程，最终得到一个激活图，这个激活图对于二维数据来说是一个`3x3`的映射，其中过滤器的具体值在训练过程中被学习到。过滤器以与过滤器大小相同的窗口尺寸在输入数据上滑动，然后计算过滤器与输入数据片段的标量积，得到所谓的**激活值**。随着该过程在整个输入数据上重复进行，使用相同的过滤器，最终生成激活图，也称为**特征图**。
- en: 'This concept is illustrated in the following figure, which has two convolutional
    layers, producing two sets of feature maps. After the feature maps are produced
    from the first convolutional layer, they are passed into the second convolutional
    layer. The feature map of the second convolutional layer is passed into a classifier:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概念在以下图中得到说明，其中有两个卷积层，产生两组特征图。在第一个卷积层生成特征图后，它们会传递到第二个卷积层。第二个卷积层的特征图将传递到分类器中：
- en: '![Figure 7.3: Convolution for classification'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.3：用于分类的卷积](img/B16341_07_03.jpg)'
- en: '](img/B16341_07_03.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_03.jpg)'
- en: 'Figure 7.3: Convolution for classification'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：用于分类的卷积
- en: The distance, or number of steps, the filter moves with each operation is known
    as the `0`. This is known as **valid padding**.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波器每次操作的移动距离或步数称为`0`。这就是**有效填充**。
- en: Let's recap some keywords. There's a `2x2` kernel. There's **stride**, which
    is the number of pixels that you move the kernel by. Lastly, there's **padding
    with zeros** around the image, whether or not you add pixels. This ensures that
    the output is the same size as the input.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下几个关键词。这里有一个`2x2`的卷积核。还有**步长**，即卷积核每次移动的像素数。最后，有**零填充**，即在图像周围是否添加像素。这样可以确保输出与输入的尺寸相同。
- en: Creating the Model
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建模型
- en: From the very first chapter, you encountered different types of dimensional
    tensors. One important thing to note is that you will only be working with `Conv2D`.
    The layer name `Conv2D` refers only to the movement of a **filter** or **kernel**.
    So, if you recall the description of what the convolutional process is doing,
    it's simply sliding a kernel across a 2D space. So, for a flat, square image,
    the kernel only slides in two dimensions.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 从第一章开始，你接触到过不同类型的维度张量。需要注意的一点是，你将只使用`Conv2D`。`Conv2D`的层名称仅指卷积核或**滤波器**的移动。所以，如果你回忆一下卷积过程的描述，它就是简单地在二维空间中滑动卷积核。所以，对于一个平的、方形的图像，卷积核只会在两个维度中滑动。
- en: 'When you implement `Conv2D`, you need to pass in certain parameters:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现`Conv2D`时，你需要传入一些参数：
- en: The first parameter is `filter`. The filters are the dimensionality of the output space.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个参数是`filter`。滤波器是输出空间的维度。
- en: Specify `strides`, which is how many pixels will move the kernel across.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定`strides`，即卷积核在每次操作中移动的像素数。
- en: Then, specify `padding`, which is usually `valid` or `same` depending on whether
    you want an output that is of the same dimension as the input.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，指定`padding`，这通常是`valid`或`same`，取决于你是否希望输出与输入具有相同的维度。
- en: Finally, you can also have `activation`. Here, you will specify what sort of
    activation you would like to apply to the outputs. If you don't specify an activation,
    it's simply a linear activation.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，你还可以指定`activation`。在这里，你将指定希望应用于输出的激活函数。如果不指定激活函数，它就是一个线性激活。
- en: Before you continue, recall from *Chapter 4*, *Regression and Classification
    Models*, that a dense layer is one in which every neuron is connected to every
    neuron in the previous layer. As you can see in the following code, you can easily
    add a dense layer with `model.add(Dense(32))`. `32` is the number of neurons,
    followed by the input shape. **AlexNet** is an example of a CNN with multiple
    convolution kernels that extracts interesting information from an image.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，回顾一下*第4章*，*回归与分类模型*，其中提到密集层是每个神经元都与前一层中的每个神经元相连的层。正如你在以下代码中看到的，你可以通过`model.add(Dense(32))`轻松添加一个密集层。`32`是神经元的数量，后面跟着输入形状。**AlexNet**是一个CNN的例子，具有多个卷积核，从图像中提取有趣的信息。
- en: '![Figure 7.4: AlexNet consists of five convolution layers and three connected
    layers'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.4：AlexNet 由五个卷积层和三个连接层组成](img/B16341_07_04.jpg)'
- en: '](img/B16341_07_04.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_04.jpg)'
- en: 'Figure 7.4: AlexNet consists of five convolution layers and three connected
    layers'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4：AlexNet 由五个卷积层和三个连接层组成
- en: Note
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: AlexNet is the name of a CNN designed by Alex Krizhevsky.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet 是由 Alex Krizhevsky 设计的CNN的名称。
- en: 'A sequential model can be used to build a CNN. Different methods can be used
    to add a layer; here, we will use the framework of sequentially adding layers
    to the model using the model''s `add` method or passing in a list of all layers
    when the model is instantiated:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用顺序模型来构建CNN。可以使用不同的方法添加层；在这里，我们将使用顺序添加层到模型的框架，通过模型的`add`方法或在实例化模型时传入所有层的列表：
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following is a code block showing the code that you''ll be using later
    in the chapter:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个代码块，展示了你将在本章后续使用的代码：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Use the `Conv2D` layer when working with data that you want to convolve in two
    dimensions, such as images. For parameters, set the number of filters to `32`,
    followed by the kernel size of `3x3` pixels (`(3, 3)` in the example). In the
    first layer, you will always need to specify the `input_shape` dimensions, the
    height, width, and depth. `input_shape` is the size of the images you will be
    using. You can also select the activation function to be applied at the end of
    the layer.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理你想在二维中进行卷积的数据（如图像）时，使用`Conv2D`层。对于参数，设置滤波器的数量为`32`，然后是`3x3`像素的内核大小（在示例中是`(3,
    3)`）。在第一层中，你总是需要指定`input_shape`的维度，包括高度、宽度和深度。`input_shape`是你将使用的图像的大小。你还可以选择应用于层末端的激活函数。
- en: Now that you have learned how to build a CNN layer in your model, you will practice
    doing so in your first exercise. In this exercise, you will build the first constructs
    of a CNN, initialize the model, and add a single convolutional layer to the model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何在模型中构建CNN层，你将在第一个练习中练习此操作。在这个练习中，你将构建CNN的第一个构建块，初始化模型，并向模型添加一个卷积层。
- en: 'Exercise 7.01: Creating the First Layer to Build a CNN'
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习7.01：创建第一层以构建CNN
- en: As a TensorFlow freelancer, you've been asked to show your potential employer
    a few lines of code that demonstrate how you might build the first layer in a
    CNN. They ask that you keep it simple but provide the first few steps to create
    a CNN layer. In this exercise, you will complete the first step in creating a
    CNN—that is, adding the first convolutional layer.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个TensorFlow自由职业者，你被要求向潜在的雇主展示几行代码，演示如何构建CNN的第一层。他们要求你保持简洁，但提供创建CNN层的前几步。在这个练习中，你将完成创建CNN的第一步——即添加第一层卷积层。
- en: 'Follow these steps to complete this exercise:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成本练习：
- en: Open a new Jupyter notebook.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Jupyter笔记本。
- en: 'Import the TensorFlow library and the `models` and `layers` classes from `tensorflow.keras`:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入TensorFlow库以及`tensorflow.keras`中的`models`和`layers`类：
- en: '[PRE2]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Check the TensorFlow version:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查TensorFlow版本：
- en: '[PRE3]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You should get the following output:'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该会得到以下输出：
- en: '[PRE4]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, use `models.Sequential` to create your model. The first layer (`Conv2D`)
    will require the number of nodes (`filters`), the filter size (`3,3`), and the
    shape of the input. `input_shape` for your first layer will determine the shape
    of your input images. Add a ReLU activation layer:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`models.Sequential`创建你的模型。第一层（`Conv2D`）将需要节点数（`filters`）、滤波器大小（`3,3`）以及输入的形状。你第一层的`input_shape`将决定输入图像的形状。添加一个ReLU激活层：
- en: '[PRE5]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Simple enough. You have just taken the first steps in creating your first CNN.
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 很简单。你刚刚迈出了创建第一个CNN的第一步。
- en: You will now move on to the type of layer that usually follows a convolutional
    layer—the pooling layer.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你将继续学习通常跟随在卷积层后的层——池化层。
- en: Pooling Layer
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 池化层
- en: Pooling is an operation that is commonly added to a CNN to reduce the dimensionality
    of an image by reducing the number of pixels in the output from the convolutional
    layer it follows. **Pooling layers** shrink the input image to increase computational
    efficiency and reduce the number of parameters to limit the risk of **overfitting**.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 池化是一种常常添加到CNN中的操作，用于通过减少卷积层输出中的像素数量来减少图像的维度。**池化层**会将输入图像缩小，从而提高计算效率，并减少参数数量，限制**过拟合**的风险。
- en: 'A **pooling layer** immediately follows a convolution layer and is considered
    another important part of the CNN structure. This section will focus on two types
    of pooling:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**池化层**紧跟在卷积层后面，是CNN结构中另一个重要部分。本节将重点介绍两种池化类型：'
- en: Max pooling
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大池化
- en: Average pooling
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均池化
- en: Max Pooling
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最大池化
- en: With max pooling, a filter or kernel only retains the largest pixel value from
    an input matrix. To get a clearer idea of what is happening, consider the following
    example. Say you have a `4x4` input. This first step in max pooling would be to
    divide the `4x4` matrix into four quadrants. Each quadrant will be of the size
    `2x2`. Apply a filter of size `2`. This means that your filter will look exactly
    like a `2x2` matrix.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最大池化（max pooling）中，滤波器或内核仅保留输入矩阵中最大的像素值。为了更清楚地理解发生了什么，考虑以下示例。假设你有一个`4x4`的输入。最大池化的第一步是将`4x4`矩阵划分为四个象限。每个象限的大小为`2x2`。应用一个`2`大小的滤波器。这意味着你的滤波器将完全像一个`2x2`矩阵。
- en: Begin by placing the filter on top of your input. For max pooling, this filter
    will look at all values within the `2x2` area that it covers. It will find the
    largest value, send that value to your output, and store it there in the upper-left
    corner of the feature map.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，将滤波器放置在输入的顶部。对于最大池化，这个滤波器会查看它覆盖的`2x2`区域内的所有值。它会找到最大值，将该值发送到输出，并将其存储在特征图的左上角。
- en: '![Figure 7.5: Max pooling'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.5：最大池化](img/B16341_07_05.jpg)'
- en: '](img/B16341_07_05.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_05.jpg)'
- en: 'Figure 7.5: Max pooling'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5：最大池化
- en: Then, the filter will move over to the right and repeat the same process, storing
    the value in the upper-right corner of the `2x2` matrix. Once this operation is
    complete, the filter will slide down and start at the far left, again repeating
    the same process, looking for the largest (or maximum) value, and then storing
    it in the correct place on the `2x2` matrix.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，滤波器将向右移动并重复相同的过程，将值存储在 `2x2` 矩阵的右上角。一旦这个操作完成，滤波器将向下滑动并从最左边开始，再次重复相同的过程，查找最大值，然后将其存储在
    `2x2` 矩阵的正确位置。
- en: Recall that the sliding movement is referred to as `2`. This process is repeated
    until the maximum values in each of the four quadrants are `8`, `5`, `7`, and
    `5`, respectively. Again, to get these numbers, you used a filter of `2x2` and
    filtered for the largest number within that `2x2` matrix.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，滑动步幅被称为 `2`。这个过程会一直重复，直到每个四个象限中的最大值分别为 `8`、`5`、`7` 和 `5`。再次，为了得到这些数字，你使用了
    `2x2` 的滤波器，并在该 `2x2` 矩阵内筛选出最大值。
- en: So, in this case, you had a stride of two because you moved two pixels. These
    are the `filter` and `stride` are `2`. *Figure 7.6* shows what an implementation
    of max pooling might look like with a filter size of 3 x 3 and a `stride` of `1`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这种情况下，你的步幅为2，因为你移动了两个像素。这些是`filter`和`stride`的值都是`2`。*图 7.6* 显示了使用 3 x 3
    滤波器和步幅 `1` 时，最大池化的实现可能是什么样的。
- en: There are two steps shown in *Figure 7.6*. Start at the upper left of the feature
    map. With the `3x3` filter, you would look at the following numbers, `2`, `8`,
    `2`, `5`, `4`, `9`, `8`, `4`, and `6`, and choose the largest value, `9`. The
    `9` would be placed in the upper-left box of our pooled feature map. With a stride
    of `1`, you would slide the filter one place to the right, as shown in gray.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.6* 中显示了两个步骤。首先从特征图的左上角开始。使用 `3x3` 滤波器，你将查看以下数字：`2`、`8`、`2`、`5`、`4`、`9`、`8`、`4`
    和 `6`，并选择最大值 `9`。`9` 将被放置在池化特征图的左上角。使用步幅 `1`，你会将滤波器滑动一个位置向右，如灰色所示。'
- en: Now, look for the largest values from `8`, `2`, `1`, `4`, `9`, `6`, `4`, `6`,
    and `4`. Again, `9` is the largest value, so add a `9` to the middle place in
    the top row of the pooled feature map (shown in gray).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，查找 `8`、`2`、`1`、`4`、`9`、`6`、`4`、`6` 和 `4` 中的最大值。再次，`9` 是最大值，因此在池化特征图的顶行中间位置添加
    `9`（如灰色所示）。
- en: '![Figure 7.6: Pooled feature map'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.6：池化特征图](img/B16341_07_06.jpg)'
- en: '](img/B16341_07_06.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_06.jpg)'
- en: 'Figure 7.6: Pooled feature map'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.6：池化特征图
- en: 'The preceding pool size is `(2, 2)`. It specifies factors that you will downscale
    with. Here''s a more detailed look at what you could do to implement `MaxPool2D`:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 上述池化大小为 `(2, 2)`。它指定了你将使用的下采样因子。以下是你可以用来实现 `MaxPool2D` 的更详细步骤：
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '`MaxPool2D` instance. The code snippet initializes a max pooling layer with
    a pool size of `2x2` and the `stride` value is not specified, so it will default
    to the pool size value. The `padding` parameter is set to `valid`, meaning there
    is no padding added. The following code snippet demonstrates its use within a
    CNN:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`MaxPool2D` 实例。代码片段初始化了一个池化大小为 `2x2` 的最大池化层，`stride` 的值未指定，因此它将默认为池化大小值。`padding`
    参数设置为 `valid`，意味着没有添加填充。以下代码片段演示了它在 CNN 中的使用。'
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In the preceding example, a sequential model is created with two convolutional
    layers, after each layer is a ReLU activation function, and after the activation
    function of the first convolutional layer is a max pooling layer.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的例子中，创建了一个包含两个卷积层的顺序模型，每个层后面跟着一个 ReLU 激活函数，而第一个卷积层的激活函数后跟着一个最大池化层。
- en: 'Now that you have explored max pooling, let''s look at the other type of pooling:
    average pooling.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了最大池化，让我们来看另一种池化方法：平均池化。
- en: Average Pooling
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平均池化
- en: '**Average pooling** operates in a similar way to max pooling, but instead of
    extracting the largest weight value within the filter, it calculates the average.
    It then passes along that value to the feature map. *Figure 7.7* highlights the
    difference between max pooling and average pooling.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**平均池化** 的操作方式与最大池化类似，但它不是提取滤波器内的最大权重值，而是计算平均值。然后它将该值传递给特征图。*图 7.7* 突出了最大池化和平均池化之间的区别。'
- en: 'In *Figure 7.7*, consider the `4x4` matrix on the left. The average of the
    numbers in the upper-left quadrant is `13`. This would be the average pooling
    value. The same upper-left quadrant would output `20` to its feature map if it
    were max pooled because `20` is the largest value within the filter frame. This
    is a comparison between max pooling and average pooling with hyperparameters,
    with the `filter` and `stride` parameters both set to `2`:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 7.7*中，考虑左侧的 `4x4` 矩阵。左上象限中的数字平均值为 `13`。这就是平均池化值。如果进行最大池化，左上象限将输出 `20` 到其特征图，因为
    `20` 是滤波器框内的最大值。这是最大池化与平均池化之间的比较，`filter` 和 `stride` 参数都设置为 `2`：
- en: '![Figure 7.7: Max versus average pooling'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.7：最大池化与平均池化'
- en: '](img/B16341_07_07.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_07.jpg)'
- en: 'Figure 7.7: Max versus average pooling'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7：最大池化与平均池化
- en: For average pooling, you would use `AveragePooling2D` in place of `MaxPool2D`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 对于平均池化，您将使用 `AveragePooling2D` 替代 `MaxPool2D`。
- en: 'To implement the average pooling code, you could use the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现平均池化代码，您可以使用以下代码：
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`AveragePooling2D` layer. In a similar manner to max pooling, the `pool_size`,
    `strides`, and `padding` parameters can be modified. The following code snippet
    demonstrates its use within a CNN:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`AveragePooling2D` 层。与最大池化类似，`pool_size`、`strides` 和 `padding` 参数可以进行修改。以下代码片段演示了它在
    CNN 中的使用：'
- en: '[PRE9]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: It's a good idea to keep in mind the benefits of using pooling layers. One of
    these benefits is that if you down-sample the image, the *image shrinks*. This
    means that you have *less data to process* and fewer multiplications to do, which,
    of course, speeds things up.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 记住使用池化层的好处是一个好主意。其一是，如果您对图像进行下采样，*图像会缩小*。这意味着您将拥有 *更少的处理数据* 和更少的乘法运算，从而加快速度。
- en: Up to this point, you've created your first CNN layer and learned how to use
    pooling layers. Now you'll use what you've learned so far to build a pooling layer
    for the CNN in the following exercise.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经创建了第一个 CNN 层，并学会了如何使用池化层。现在，您将利用迄今为止学到的知识，为以下练习构建 CNN 的池化层。
- en: 'Exercise 7.02: Creating a Pooling Layer for a CNN'
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 7.02：为 CNN 创建池化层
- en: 'You receive an email from your potential employer for the TensorFlow freelancing
    job that you applied for in *Exercise 7.01*, *Creating the First Layer to Build
    a CNN*. The email asks whether you can show how you would code a pooling layer
    for a CNN. In this exercise, you will build your base model by adding a pooling
    layer, as requested by your potential employer:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 您收到了来自潜在雇主的电子邮件，关于您申请的 TensorFlow 自由职业职位，该职位是在 *练习 7.01* 中的 *创建 CNN 的第一层*。邮件询问您是否能展示如何为
    CNN 编写池化层的代码。在本练习中，您将通过添加池化层来构建您的基础模型，正如潜在雇主所要求的那样：
- en: 'Open a new Jupyter notebook and import the TensorFlow library:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter notebook，并导入 TensorFlow 库：
- en: '[PRE10]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Create your model using `models.Sequential`. The first layer, `Conv2D`, will
    require the number of nodes, the filter size, and the shape of the tensor, as
    in the previous exercise. It will be followed by an activation layer, a node at
    the end of the neural network:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `models.Sequential` 创建您的模型。第一个层，`Conv2D`，将需要节点数、滤波器大小以及张量的形状，和前一个练习一样。接下来是一个激活层，最后是神经网络的一个节点：
- en: '[PRE11]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, add a `MaxPool2D` layer by using the model''s `add` method:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，通过使用模型的 `add` 方法，添加一个 `MaxPool2D` 层：
- en: '[PRE12]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this model, you have created a CNN with a convolutional layer, followed by
    a ReLU activation function then a max pooling layer. The models take images of
    size `300x300` with three color channels.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个模型中，您已经创建了一个带有卷积层的 CNN，之后是 ReLU 激活函数，然后是最大池化层。该模型接收尺寸为 `300x300` 且有三个颜色通道的图像。
- en: Now that you have successfully added a `MaxPool2D` layer to your CNN, the next
    step is to add a **flattening layer** so that your model can use all the data.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经成功地向 CNN 添加了一个 `MaxPool2D` 层，接下来的步骤是添加一个 **展平层**，以便您的模型可以使用所有数据。
- en: Flattening Layer
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 展平层
- en: 'Adding a flattening layer is an important step as you will need to provide
    the neural network with data in a form that it can process. Remember that after
    you perform the convolution operation, it will still be multi-dimensional. So,
    to change your data back into one-dimensional form, you will use a flattening
    layer. To achieve this, you take the pooled feature map and flatten it into a
    column, as shown in the following figure. In *Figure 7.8*, you can see that you
    start with the input matrix on the left side of the diagram, use a final pooled
    feature map, and stretch it out into a single column vector:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 添加展平层是一个重要步骤，因为您需要将数据提供给神经网络以便其处理。请记住，在执行卷积操作后，数据仍然是多维的。因此，为了将数据转换回一维形式，您将使用展平层。为此，您将池化后的特征图展平为一列，如下图所示。在*图
    7.8*中，您可以看到，从图表左侧的输入矩阵开始，使用最终池化的特征图，并将其拉伸成一个单列向量：
- en: '![Figure 7.8: Flattening layer'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.8：展平层'
- en: '](img/B16341_07_08.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_08.jpg)'
- en: 'Figure 7.8: Flattening layer'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.8：展平层
- en: 'The following is an implemented flattening layer:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是实现的展平层：
- en: '[PRE13]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, a flatten layer is added as the final layer to this model. Now that you've
    created your first CNN and pooling layers, you will put all the pieces together
    and build a CNN in the upcoming exercise.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，作为此模型的最终层，添加了一个展平层。现在您已经创建了第一层 CNN 和池化层，接下来将把所有部分拼接在一起，并在接下来的练习中构建完整的 CNN。
- en: 'Exercise 7.03: Building a CNN'
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 7.03：构建 CNN
- en: You were hired as a freelancer from your work in *Exercise 7.01*, *Creating
    the First Layer to Build a CNN*, and *Exercise 7.02*, *Creating a Pooling Layer
    for a CNN*. Now that you've got the job, your first assignment is to help your
    start-up company build its prototype product to show to investors and raise capital.
    The company is trying to develop a horse or human classifier app, and they want
    you to get started right away. They tell you that they just need the classifier
    to work for now and that there will be room for improvements on it soon.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 您是作为自由职业者被聘用的，您的工作来源于*练习 7.01*，*创建 CNN 的第一层*，以及*练习 7.02*，*为 CNN 创建池化层*。现在您已经获得了这份工作，您的第一个任务是帮助您的初创公司构建原型产品，向投资者展示并筹集资金。该公司正在开发一个马匹或人类分类应用程序，他们希望您立刻开始。他们告诉您现在只需要分类器能够正常工作，之后会有改进的空间。
- en: In this exercise, you will build a convolutional base layer for your model using
    the `horses_or_humans` dataset. In this dataset, the images aren't centered. The
    target images are displayed at all angles and at different positions in the frame.
    You will continue to build on this foundation throughout the chapter, adding to
    it piece by piece.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，您将使用 `horses_or_humans` 数据集为模型构建卷积基础层。在此数据集中，图像没有居中。目标图像以不同角度和不同位置显示在框架中。您将在本章中继续在此基础上构建，逐步完善。
- en: Note
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The dataset can be downloaded using the `tensorflow_datasets` package.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以通过 `tensorflow_datasets` 包下载。
- en: 'Import all the necessary libraries:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必要的库：
- en: '[PRE14]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: First, you need to import the TensorFlow library. You will use `tensorflow_datasets`
    to load your dataset, `tensorflow.keras.models` to build a sequential TensorFlow
    model, `tensorflow.keras.layers` to add layers to your CNN model, `RMSprop` as
    your optimizer, and `matplotlib.pyplot` and `matplotlib.image` for some quick
    visualizations.
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，您需要导入 TensorFlow 库。您将使用 `tensorflow_datasets` 加载数据集，使用 `tensorflow.keras.models`
    构建一个顺序 TensorFlow 模型，使用 `tensorflow.keras.layers` 为 CNN 模型添加层，使用 `RMSprop` 作为优化器，并使用
    `matplotlib.pyplot` 和 `matplotlib.image` 进行一些快速可视化。
- en: 'Load your dataset from the `tensorflow_datasets` package:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `tensorflow_datasets` 包中加载您的数据集：
- en: '[PRE15]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here, you used the `tensorflow_datasets` package imported as `tfds`. You used
    the `tfds.load()` function to load the `horses_or_humans` dataset. It is a binary
    image classification dataset with two classes: horses and humans.'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，您使用了以 `tfds` 导入的 `tensorflow_datasets` 包。您使用 `tfds.load()` 函数加载了 `horses_or_humans`
    数据集。这是一个二分类图像数据集，包含两个类别：马和人。
- en: Note
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: More information on the dataset can be found at [https://laurencemoroney.com/datasets.html](https://laurencemoroney.com/datasets.html).
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更多关于数据集的信息可以在 [https://laurencemoroney.com/datasets.html](https://laurencemoroney.com/datasets.html)
    找到。
- en: More information on the `tensorflow_datasets` package can be found at [https://www.tensorflow.org/datasets](https://www.tensorflow.org/datasets).
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更多关于 `tensorflow_datasets` 包的信息可以在 [https://www.tensorflow.org/datasets](https://www.tensorflow.org/datasets)
    找到。
- en: The `split = ['train', 'test']` argument specifies which split of the data you
    want to load. In this example, you are loading the train and test splits into
    `our_train_dataset` and `our_test_dataset`, respectively. Specify `with_info =
    True` to load the metadata about the dataset into the `dataset_info` variable.
    After loading, use `assert` to make sure that the loaded dataset is an instance
    of the `tf.data.Dataset` object class.
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`split = [''train'', ''test'']`参数指定了要加载的数据分割。在这个例子中，你将训练集和测试集分别加载到`our_train_dataset`和`our_test_dataset`中。指定`with_info
    = True`以将数据集的元数据加载到`dataset_info`变量中。加载后，使用`assert`来确保加载的数据集是`tf.data.Dataset`对象类的实例。'
- en: 'View information about the dataset using the loaded metadata in `dataset_info`:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看使用加载的元数据`dataset_info`中的数据集信息：
- en: '[PRE16]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You should get the following output:'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 7.9: horses_or_humans dataset information'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.9：horses_or_humans数据集信息'
- en: '](img/B16341_07_09.jpg)'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_09.jpg)'
- en: 'Figure 7.9: horses_or_humans dataset information'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.9：horses_or_humans数据集信息
- en: 'Now, view the number of images in the dataset and its distribution of classes:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，查看数据集中图像的数量及其类别分布：
- en: '[PRE17]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You should get the following output:'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 7.10: horses_or_humans dataset distribution'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.10：horses_or_humans数据集分布'
- en: '](img/B16341_07_10.jpg)'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_10.jpg)'
- en: 'Figure 7.10: horses_or_humans dataset distribution'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.10：horses_or_humans数据集分布
- en: 'Now, view some sample images in the training dataset, using the `tfds.show_examples()`
    function:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`tfds.show_examples()`函数查看训练数据集中的一些样本图像：
- en: '[PRE18]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This function is for interactive use, and it displays and returns a plot of
    images from the training dataset.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该功能用于交互式使用，它显示并返回训练数据集中的图像绘图。
- en: 'Your output should be something like the following:'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的输出应该类似于以下内容：
- en: '![Figure 7.11: Sample training images'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.11：样本训练图像'
- en: '](img/B16341_07_11.jpg)'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_11.jpg)'
- en: 'Figure 7.11: Sample training images'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.11：样本训练图像
- en: 'View some sample images in the test dataset:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看测试数据集中的一些样本图像：
- en: '[PRE19]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You will get the following output:'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将得到以下输出：
- en: '![Figure 7.12: Sample test images'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.12：样本测试图像'
- en: '](img/B16341_07_12.jpg)'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_12.jpg)'
- en: 'Figure 7.12: Sample test images'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.12：样本测试图像
- en: 'Finally, create your model with `our_model = models.Sequential`. Set up the
    first `Conv2D` layer and set `filters` to `16`. The kernel is `3x3`. Use ReLU
    activation. Because this is the first convolutional layer, you also need to set
    `input_shape` to `image_shape`, the dimensions of the color images you''re working
    with. Now, add the `MaxPool2D` pooling layer. Then, add another `Conv2D` and `MaxPool2D`
    pair for more model depth, followed by the flatten and dense layers:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用`our_model = models.Sequential`创建模型。设置第一个`Conv2D`层，并将`filters`设置为`16`。卷积核为`3x3`。使用ReLU激活函数。由于这是第一个卷积层，你还需要将`input_shape`设置为`image_shape`，即你正在处理的彩色图像的维度。接下来，添加`MaxPool2D`池化层。然后，再添加一个`Conv2D`和`MaxPool2D`层对，增加模型深度，接着添加展平层和全连接层：
- en: '[PRE20]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Compile the model with `RMSProp` for `optimizer` set to the recommended default
    of `0.001`, `loss` as `binary_crossentropy`, and `metrics` set to `acc` for accuracy.
    Print the model summary using the `summary()` method:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`RMSProp`编译模型，将`optimizer`设置为推荐的默认值`0.001`，`loss`设置为`binary_crossentropy`，并将`metrics`设置为`acc`以衡量准确率。使用`summary()`方法打印模型摘要：
- en: '[PRE21]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This will print the model summary with details on the layer type, output shape,
    and parameters:'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将打印出模型摘要，详细说明每个层的类型、输出形状和参数：
- en: '![Figure 7.13: Model summary'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.13：模型摘要'
- en: '](img/B16341_07_13.jpg)'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_13.jpg)'
- en: 'Figure 7.13: Model summary'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.13：模型摘要
- en: In the preceding screenshot, you can see that there are layers and types listed
    on the left side. The layers are listed in order from first to last, top to bottom.
    The output shape is shown in the middle. There are several parameters for each
    layer listed alongside the assigned layer. At the bottom, you'll see a count of
    the total parameters, trainable parameters, and non-trainable parameters.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的截图中，你可以看到左侧列出了各个层和类型。各层按从上到下的顺序排列。输出形状显示在中间。每个层旁边列出了多个参数。在底部，你会看到总参数数、可训练参数数和不可训练参数数。
- en: 'You''ve been able to explore the convolutional layer and pooling layers quite
    a bit. Let''s now dive into another important component when using image data:
    image augmentation.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经能够深入了解卷积层和池化层了。现在，让我们来探讨在使用图像数据时的另一个重要组成部分：图像增强。
- en: Image Augmentation
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像增强
- en: 'Augmentation is defined as making something better by making it greater in
    size or amount. This is exactly what data or image augmentation does. You use
    augmentation to provide the model with more versions of your image training data.
    Remember that the more data you have, the better the model''s performance will
    be. By *augmenting* your data, you can transform your images in a way that makes
    the model generalize better on real data. To do this, you *transform* the images
    that you have at your disposal so that you can use your augmented images alongside
    your original image dataset to train with a greater variation and variety than
    you would have otherwise. This improves results and prevents overfitting. Take
    a look at the following three images:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 增强定义为通过增大尺寸或数量使某物变得更好。这正是数据或图像增强的作用。你通过增强为模型提供更多版本的图像训练数据。记住，数据越多，模型的性能就越好。通过*增强*你的数据，你可以以一种方式转换你的图像，使得模型在真实数据上的泛化能力更强。为此，你需要*转换*现有的图像，以便你能将增强后的图像与原始图像数据集一起使用，从而训练出比原先更多样化的模型。这改善了结果并防止了过拟合。看看以下三张图片：
- en: '![Figure 7.14: Augmented leopard images'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.14：增强后的豹子图像'
- en: '](img/B16341_07_14.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_14.jpg)'
- en: 'Figure 7.14: Augmented leopard images'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14：增强后的豹子图像
- en: It's clear that this is the same leopard in all three images. They're just in
    different positions. Neural networks can still make sense of this due to convolution.
    However, with the use of image augmentation, you can improve the model's ability
    to learn **translational invariance**.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，这三张图中的豹子是同一只，它们只是处于不同的姿势。由于卷积，神经网络仍然能够理解这一点。然而，利用图像增强，你可以提高模型学习**平移不变性**的能力。
- en: 'Unlike most other types of data with images, you can shift, rotate, and move
    the images around to make variations of the original image. This creates more
    data, and with CNNs, more data and data variation will create a better-performing
    model. To be able to create these image augmentations, take a look at how you
    would do this in TensorFlow with the loaded `tf.data.Dataset` object. You will
    use the `dataset.map()` function to map preprocessing image augmentation functions
    to your dataset, that is, `our_train_dataset`:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数其他类型的数据不同，图像可以进行平移、旋转和移动，从而产生原始图像的变体。这会产生更多的数据，而对于卷积神经网络（CNNs），更多的数据和数据变化将创造出表现更好的模型。为了能够创建这些图像增强操作，看看如何在TensorFlow中使用加载的`tf.data.Dataset`对象。你将使用`dataset.map()`函数将图像增强的预处理函数映射到你的数据集上，也就是`our_train_dataset`：
- en: '[PRE22]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'You will use the `tensorflow.image` and `tensorflow.keras.preprocessing.image`
    packages for this purpose. These packages have a lot of image manipulation functions
    that can be used for image data augmentation:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用`tensorflow.image`和`tensorflow.keras.preprocessing.image`包来实现这个目的。这些包提供了许多图像处理函数，可以用于图像数据增强：
- en: '[PRE23]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Additional functions include the following:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 其他函数包括以下内容：
- en: '`kimage.random_rotation`: This function allows you to rotate an image randomly
    between specified degrees.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kimage.random_rotation`：此函数允许你在指定的角度范围内随机旋转图像。'
- en: '`kimage.random_brightness`: This function randomly adjusts the brightness level.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kimage.random_brightness`：此函数随机调整亮度级别。'
- en: '`kimage.random_shear`: This function applies shear transformations.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kimage.random_shear`：此函数应用剪切变换。'
- en: '`kimage.random_zoom`: This function randomly zooms images.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kimage.random_zoom`：此函数随机缩放图像。'
- en: '`tfimage.random_flip_left_right`: This function randomly flips images horizontally.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tfimage.random_flip_left_right`：此函数随机左右翻转图像。'
- en: '`tfimage.random_flip_up_down`: This function randomly flips images vertically.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tfimage.random_flip_up_down`：此函数随机上下翻转图像。'
- en: 'In the next step, you will pass in the data that you want to augment with the
    `tf.data.Dataset.map()` function:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一步，你将使用`tf.data.Dataset.map()`函数传入你想要增强的数据：
- en: '[PRE24]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the preceding code block, with `fit()`, you just need to pass the generator
    that you have already created. You need to pass in the `epochs` value. If you
    don't do this, the generator will never stop. The `fit()` function returns the
    history (plots loss per iteration and so on).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，使用`fit()`时，你只需传入你已经创建的生成器。你需要传入`epochs`值。如果不这样做，生成器将永远不会停止。`fit()`函数返回历史记录（每次迭代绘制损失等）。
- en: 'You need some more functions to add to `our_train_dataset` before you can train
    the model on it. With `batch()` function, you specify how many images per batch
    you will train. With `cache()` function, you fit your dataset in memory to improve
    performance. With `shuffle()` function, you set the shuffle buffer of your dataset
    to the entire length of the dataset, for true randomness. `prefetch()` function
    is also used for good performance:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在您开始训练模型之前，您还需要为`our_train_dataset`添加一些功能。使用`batch()`函数，您可以指定每个批次将训练多少张图像。使用`cache()`函数，您可以将数据集缓存到内存中以提高性能。使用`shuffle()`函数，您可以将数据集的洗牌缓冲区设置为数据集的整个长度，从而实现真正的随机性。`prefetch()`函数也有助于提高性能：
- en: '[PRE25]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Now that you've seen how you would implement augmentation in your training model,
    take a closer look at what some of those transformations are doing.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了如何在训练模型中实现数据增强，接下来仔细看看这些变换所做的工作。
- en: 'Here''s an example of `random_rotation`, `random_shift`, and `random_brightnes`
    implementation. Use the following code to randomly rotate an image up to an assigned
    value:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`random_rotation`、`random_shift`和`random_brightness`实现的一个例子。使用以下代码可以将图像随机旋转到指定值：
- en: '[PRE26]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In *Figure 7.15*, you can see the outcome of `random_rotation`.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图7.15*中，您可以看到`random_rotation`的效果。
- en: '![Figure 7.15: Rotation range'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.15：旋转范围'
- en: '](img/B16341_07_15.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_15.jpg)'
- en: 'Figure 7.15: Rotation range'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.15：旋转范围
- en: The images were randomly rotated up to 135 degrees.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图像被随机旋转了最多135度。
- en: '`random_shift` is used to randomly shift the pixels width-wise. Notice the
    `.15` in the following code, which means the image can be randomly shifted up
    to 15 pixels:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '`random_shift`用于随机在宽度上偏移像素。请注意以下代码中的`.15`，这意味着图像最多可以随机偏移15像素：'
- en: '[PRE27]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The following figure shows the random adjustment of an image''s width by up
    to 15 pixels:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了图像宽度最多可随机调整15像素：
- en: '![Figure 7.16: Width shift range'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.16：宽度偏移范围'
- en: '](img/B16341_07_16.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_16.jpg)'
- en: 'Figure 7.16: Width shift range'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.16：宽度偏移范围
- en: 'Again, `random_shift` is used here, which randomly adjusts the height by 15
    pixels:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 再次使用`random_shift`，它随机调整高度15像素：
- en: '[PRE28]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '*Figure 7.17* shows the random adjustment of an image''s height by up to 15
    pixels:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.17*展示了图像高度最多可以随机调整15像素：'
- en: '![Figure 7.17: Height shift range'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.17：高度偏移范围'
- en: '](img/B16341_07_17.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_17.jpg)'
- en: 'Figure 7.17: Height shift range'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.17：高度偏移范围
- en: 'For random brightness levels using `random_brightness`, you will use a float
    value range to lighten or darken the image by percentage. Anything below `1.0`
    will darken the image. So, in this example, the images are being darkened randomly
    between 10% and 90%:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`random_brightness`进行随机亮度调整时，您将使用一个浮动值范围按百分比调节图像的亮度或暗度。低于`1.0`的任何值都会使图像变暗。所以，在这个例子中，图像的亮度会在10%到90%之间随机变暗：
- en: '[PRE29]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'In the following figure, you''ve adjusted the brightness with `random_brightness`:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，您已经使用`random_brightness`调整了亮度：
- en: '![Figure 7.18: Brightness range'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.18：亮度范围'
- en: '](img/B16341_07_18.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_18.jpg)'
- en: 'Figure 7.18: Brightness range'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.18：亮度范围
- en: Now that you've been exposed to some of the image augmentation options, take
    a look at how you can use batch normalization to drive performance improvement
    in models.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了其中一些图像增强选项，接下来看看如何利用批量归一化来提高模型的性能。
- en: Batch Normalization
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 批量归一化
- en: 'In 2015, **batch normalization**, also called **batch norm**, was introduced
    by *Christian Szegedy* and *Sergey Ioffe*. Batch norm is a technique that reduces
    the number of training epochs to improve performance. Batch norm standardizes
    the inputs for a mini-batch and "normalizes" the input layer. It is most commonly
    used following a convolutional layer, as shown in the following figure:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在2015年，**批量归一化**（Batch Normalization），也叫**批归一化**（Batch Norm），由*Christian Szegedy*和*Sergey
    Ioffe*提出。批归一化是一种减少训练周期数、提高性能的技术。批归一化对一个小批量的输入进行标准化，并“归一化”输入层。它通常在卷积层后使用，如下图所示：
- en: '![Figure 7.19: Batch norm'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.19：批量归一化'
- en: '](img/B16341_07_19.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_19.jpg)'
- en: 'Figure 7.19: Batch norm'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.19：批量归一化
- en: 'The following figure shows one common way that batch normalization is implemented.
    In the following example, you can see that you have a batch norm layer following
    a convolutional layer three times. Then you have a flattening layer, followed
    by two dense layers:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了批量归一化的一种常见实现方式。在以下例子中，您可以看到在卷积层后面有一个批量归一化层，且重复了三次。然后是一个展平层，接着是两个全连接层：
- en: '![Figure 7.20: Layer sequences'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.20：层序列'
- en: '](img/B16341_07_20.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_07_20.jpg)'
- en: 'Figure 7.20: Layer sequences'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.20：层序列
- en: Batch norm helps the model generalize better. With each batch that batch norm
    trains, the model has a different mean and standard deviation. Because the batch
    means and standard deviations each vary slightly from the true overall mean and
    standard deviation, these changes act as noise that you are training with, making
    the model perform better overall.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 批归一化有助于模型更好地泛化。在每个批次进行训练时，模型具有不同的均值和标准差。由于批次均值和标准差与真实的总体均值和标准差略有不同，这些变化充当噪声，使模型整体表现更好。
- en: 'The following is an example of `BatchNormalization` implementation. You can
    simply add a batch norm layer, followed by an activation layer:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`BatchNormalization`实现的示例。你可以简单地添加一个批归一化层，然后跟随一个激活层：
- en: '[PRE30]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: So far, you've created a CNN model and learned how to utilize image augmentation.
    Now you will bring everything together and build a CNN with some additional convolutional
    layers in the following exercise.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经创建了一个 CNN 模型并学习了如何使用图像增强。现在你将把所有内容结合起来，并在接下来的练习中构建一个具有额外卷积层的 CNN。
- en: 'Exercise 7.04: Building a CNN with Additional Convolutional Layers'
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 7.04：构建一个带有额外卷积层的 CNN
- en: Your new employers were happy with what you were able to make in *Exercise 7.03*,
    *Building a CNN*. Now that the **Minimal Viable Product** (**MVP**), or prototype,
    is complete, it's time to build a better model.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 你的新雇主对你在*练习 7.03*中完成的工作非常满意，*构建一个 CNN*。现在，**最小可行产品**（**MVP**）或原型已经完成，是时候构建一个更好的模型了。
- en: In this exercise, you will add additional ANN layers to your model. You will
    be adding additional layers to your convolutional base layer that you created
    earlier. You will be using the `horses_or_humans` dataset again.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，你将向模型中添加额外的 ANN 层。你将向之前创建的卷积基础层中添加额外的层。你将再次使用`horses_or_humans`数据集。
- en: Let's get started.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: 'Because you''re expanding on *Exercise 7.03*, *Building a CNN*, and using the
    same data, begin from where you left off with the last step in the previous exercise:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 因为你在*练习 7.03*中扩展了*构建一个 CNN*并使用相同的数据，所以从上一个练习的最后一步继续开始：
- en: 'Create a function to rescale the images then apply the function to the train
    and test datasets using the `map` method. Continue building your train and test
    dataset pipelines using the `cache`, `shuffle`, `batch`, and `prefetch` methods
    of the dataset:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数来重新缩放图像，然后使用`map`方法将该函数应用于训练集和测试集。继续使用数据集的`cache`、`shuffle`、`batch`和`prefetch`方法来构建训练和测试数据集管道：
- en: '[PRE31]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Fit the model. Specify the values of `epochs` and `validation_steps` and set
    `verbose` equal to `1`:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合模型。指定`epochs`和`validation_steps`的值，并将`verbose`设置为`1`：
- en: '[PRE32]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The output looks like this:'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出看起来像这样：
- en: '![Figure 7.21: Model fitting process'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.21：模型拟合过程'
- en: '](img/B16341_07_21.jpg)'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_21.jpg)'
- en: 'Figure 7.21: Model fitting process'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.21：模型拟合过程
- en: 'Take a batch from the test dataset and plot the first image from the batch.
    Convert the image to an array, then use the model to predict what the image shows:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从测试数据集中获取一批数据并绘制该批次中的第一张图片。将图片转换为数组，然后使用模型预测图片显示的内容：
- en: '[PRE33]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The output will have the following details:'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将包含以下细节：
- en: '![Figure 7.22: Output of image test with its metadata'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.22：带有元数据的图像测试输出'
- en: '](img/B16341_07_22.jpg)'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_22.jpg)'
- en: 'Figure 7.22: Output of image test with its metadata'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.22：带有元数据的图像测试输出
- en: For prediction, you have a picture of a person from the test set to see what
    the classification would be.
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于预测，你有一张来自测试集的人物图片，用来查看分类结果是什么。
- en: 'Take a look at what''s happening with each successive layer. Do this by creating
    a list containing all names of the layers within the CNN and another list containing
    predictions on a random sample from each of the layers in the list created previously.
    Next, iterate through the list of names of the layers and their respective predictions
    and plot the features:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 看一下每一层的变化情况。通过创建一个包含 CNN 中所有层名称的列表，以及另一个包含每一层的随机样本预测的列表来查看这一过程。接下来，迭代层名称列表及其相应的预测，并绘制特征：
- en: '[PRE34]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You should get something like the following:'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到如下结果：
- en: '![Figure 7.23: Transformation at different layers'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.23：不同层的转换'
- en: '](img/B16341_07_23.jpg)'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_23.jpg)'
- en: 'Figure 7.23: Transformation at different layers'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.23：不同层的转换
- en: Now that you have created your own CNN model and used it to determine whether
    an image was a horse or a human, you're now going to focus on how you can classify
    whether an image is or isn't a specific class.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经创建了自己的 CNN 模型，并用它来判断一张图像是马还是人，接下来你将专注于如何分类图像是否属于某个特定类别。
- en: Binary Image Classification
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二分类图像分类
- en: Binary classification is the simplest approach for classification models as
    it classifies images into just two categories. In this chapter, we started with
    the convolutional operation and discussed how you use it as an image transformer.
    Then, you learned what a pooling layer does and the differences between max and
    average pooling. Next, we also looked at how a flattening layer converts a pooled
    feature map into a single column. Then, you learned how and why to use image augmentation,
    and how to use batch normalization. These are the key components that differentiate
    CNNs from other ANNs.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类是分类模型中最简单的方法，因为它将图像分类为两个类别。在这一章中，我们从卷积操作开始，讨论了如何将其用作图像转换器。接着，你了解了池化层的作用，以及最大池化和平均池化之间的区别。然后，我们还探讨了如何通过平坦层将池化特征图转换为单列。接下来，你学习了如何以及为什么使用图像增强，以及如何使用批量归一化。这些都是区分
    CNN 和其他 ANN 的关键组件。
- en: After convolutional base layers, pooling, and normalization layers, CNNs are
    often structured like many ANNs you've built thus far, with a series of one or
    more dense layers. Much like other binary classifiers, binary image classifiers
    terminate with a dense layer with one unit and a sigmoid activation function.
    To provide more utility, image classifiers can be outfitted to classify more than
    two objects. Such classifiers are known generally as object classifiers, which
    you will learn about in the next section.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积基础层、池化层和归一化层之后，CNN 通常像你迄今为止构建的许多 ANN 一样，结构包括一个或多个全连接层。与其他二分类器类似，二分类图像分类器以一个单元和一个
    sigmoid 激活函数的全连接层结束。为了提供更多的实用性，图像分类器可以被配置为分类两个以上的对象。此类分类器通常称为对象分类器，关于这一点，你将在下一节中学习。
- en: Object Classification
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对象分类
- en: 'In this section, you will learn about object detection and classification.
    The next step involves image classification for a dataset with more than two classes.
    The three different types of models for object classification we will cover are
    **image classification**, **classification with localization**, and **detection**:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习对象检测和分类。接下来的步骤包括对一个包含多个类别的数据集进行图像分类。我们将介绍的三种不同类型的对象分类模型是**图像分类**、**带定位的分类**和**检测**：
- en: '**Image classification**: This involves training with a set number of classes
    and then trying to determine which of those classes is shown in the image. Think
    of the MNIST handwriting dataset. For these problems, you''ll use a traditional
    CNN.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像分类**：这包括用固定数量的类别进行训练，然后尝试确定图像中展示的是哪个类别。想想 MNIST 手写数据集。对于这些问题，你将使用传统的 CNN。'
- en: '**Classification with localization**: With this type, the model tries to predict
    where the object is in the image space. For these models, you use a simplified
    **You Only Look Once** (**YOLO**) or R-CNN.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**带定位的分类**：这种类型的模型尝试预测图像中对象所在的位置。对于这些模型，你可以使用简化版的**You Only Look Once**（**YOLO**）或
    R-CNN。'
- en: '**Detection**: The last type is detection. This is where your model can detect
    several different objects and where they are located. For this, you use YOLO or
    an R-CNN:![Figure 7.24: Object classification types'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检测**：最后一种类型是检测。这是指模型能够检测出多个不同的对象，并且确定它们的位置。为此，你可以使用 YOLO 或 R-CNN：[图 7.24：对象分类类型'
- en: '](img/B16341_07_24.jpg)'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_24.jpg)'
- en: 'Figure 7.24: Object classification types'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.24：对象分类类型
- en: Now, you'll take a brief look at image classification with the `Fashion-MNIST`
    dataset. `Fashion-MNIST` was compiled from a dataset of Zalando's article images.
    Zalando is a fashion-focused e-commerce company based in Berlin, Germany. The
    dataset consists of 10 classes with a training set of 60,000 `28x28` grayscale
    images and 10,000 test images.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将简要了解使用 `Fashion-MNIST` 数据集进行图像分类。`Fashion-MNIST` 数据集来自 Zalando 的商品图片。Zalando
    是一家总部位于德国柏林的以时尚为主的电子商务公司。该数据集包含 10 个类别，训练集有 60,000 张 `28x28` 的灰度图像，测试集有 10,000
    张图像。
- en: 'Import TensorFlow:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 TensorFlow：
- en: '[PRE35]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Next, make some additional imports, such as for NumPy, Matplotlib, and of course,
    layers and models. You''ll notice here that you will be using additional dropout
    layers. If you recall, dropout layers help prevent overfitting:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，进行一些额外的导入，例如 NumPy、Matplotlib，以及当然的层和模型。你会注意到这里会使用额外的 dropout 层。如果你还记得，dropout
    层有助于防止过拟合：
- en: '[PRE36]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Load the `Fashion-MNIST` dataset using `tdfs` in any one of the datasets that
    they have decided to include. Others include `CIFAR-10` and `CIFAR-100`, just
    to name a couple:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `tdfs` 加载 `Fashion-MNIST` 数据集，这是他们决定包含的其中一个数据集。其他的还包括 `CIFAR-10` 和 `CIFAR-100`，仅举几个例子：
- en: '[PRE37]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Check the data for its properties:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查数据的属性：
- en: '[PRE38]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This will give you the following output:'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 7.25: Details of properties for data'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.25：数据属性详情'
- en: '](img/B16341_07_25.jpg)'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_25.jpg)'
- en: 'Figure 7.25: Details of properties for data'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.25：数据属性详情
- en: 'Now, print the total examples of the train and test data:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，打印训练集和测试集的总示例数：
- en: '[PRE39]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This will give you the following output:'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 7.26: Details of train and test datasets'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.26：训练集和测试集的详细信息'
- en: '](img/B16341_07_26.jpg)'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_26.jpg)'
- en: 'Figure 7.26: Details of train and test datasets'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.26：训练集和测试集的详细信息
- en: 'Build your model with the functional API:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用功能 API 构建你的模型：
- en: '[PRE40]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Compile and fit your model. With `compile()` method, use `adam` as your optimizer,
    set the loss to `sparse_categorical_crossentropy`, and set the `accuracy` metric.
    Then, call `model.fit()` on your training and validation sets:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译并拟合你的模型。使用 `compile()` 方法，选择 `adam` 作为优化器，将损失设置为 `sparse_categorical_crossentropy`，并设置
    `accuracy` 作为评估指标。然后，在你的训练集和验证集上调用 `model.fit()`：
- en: '[PRE41]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This will give the following as output:'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 7.27: Function returning history'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.27：返回历史记录的函数'
- en: '](img/B16341_07_27.jpg)'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_27.jpg)'
- en: 'Figure 7.27: Function returning history'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.27：返回历史记录的函数
- en: 'Use `matplotlib.pyplot` to plot the loss and accuracy:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `matplotlib.pyplot` 绘制损失和准确率：
- en: '[PRE42]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'This will give the following plot as output:'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将产生以下绘图作为输出：
- en: '![Figure 7.28: Accuracy plot using matplotlib.pyplot'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.28：使用 matplotlib.pyplot 绘制的准确率图'
- en: '](img/B16341_07_28.jpg)'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_28.jpg)'
- en: 'Figure 7.28: Accuracy plot using matplotlib.pyplot'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.28：使用 matplotlib.pyplot 绘制的准确率图
- en: 'Plot the validation loss and training loss. Use the following code:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制验证损失和训练损失。使用以下代码：
- en: '[PRE43]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'This will give the following plot as output:'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将产生以下绘图作为输出：
- en: '![Figure 7.29: Validation loss and training loss'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.29：验证损失和训练损失'
- en: '](img/B16341_07_29.jpg)'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_29.jpg)'
- en: 'Figure 7.29: Validation loss and training loss'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.29：验证损失和训练损失
- en: As you can see from the accuracy and loss curves as a function of epochs, the
    accuracy increases, and loss decreases. On the validation set, both begin to plateau,
    which is a good signal to stop training to prevent overfitting to the training
    dataset.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你从准确率和损失曲线相对于周期的变化中看到的，准确率在增加，损失在减少。在验证集上，两者开始趋于平稳，这是停止训练的良好信号，以防止过拟合训练数据集。
- en: In the next exercise, you will build a CNN to classify images into 10 distinct
    classes from the `CIFAR-10` dataset.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，你将构建一个 CNN，用来将图像分类为 `CIFAR-10` 数据集中的 10 个不同类别。
- en: 'Exercise 7.05: Building a CNN'
  id: totrans-315
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 7.05：构建 CNN
- en: The start-up now wants to expand its capabilities and to work with more classes
    and larger image datasets. Your challenge is to accurately predict the class of
    an image.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 该初创公司现在希望扩大其能力，并与更多的类别和更大的图像数据集合作。你的挑战是准确预测图像的类别。
- en: 'The dataset you will be using is the `CIFAR-10` dataset, a dataset containing
    60,000 `32x32` color images across 10 classes: airplanes, automobiles, birds,
    cats, deer, dogs, frogs, horses, ships, and trucks. Each class has 6,000 images
    and the entire dataset contains 50,000 training images and 10,000 test images.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用的数据集是 `CIFAR-10` 数据集，该数据集包含 60,000 张 `32x32` 彩色图像，分为 10 类：飞机、汽车、鸟类、猫、鹿、狗、青蛙、马、船和卡车。每个类别有
    6,000 张图像，整个数据集包含 50,000 张训练图像和 10,000 张测试图像。
- en: 'More info on the dataset can be found at *Learning Multiple Layers of Features
    from Tiny Images* ([http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf](http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf)),
    *Alex Krizhevsky*, *2009*:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 有关数据集的更多信息，请参阅 *学习小图像中的多个特征层*（[http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf](http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf)），*Alex
    Krizhevsky*，*2009*：
- en: 'Start a new Jupyter notebook and import the TensorFlow library:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动一个新的 Jupyter 笔记本并导入 TensorFlow 库：
- en: '[PRE44]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Import the other additional libraries that are needed:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入其他必要的附加库：
- en: '[PRE45]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Load the `CIFAR-10` dataset directly from `tfds` as follows:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tfds`直接加载`CIFAR-10`数据集，如下所示：
- en: '[PRE46]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Print the properties of your dataset using the following code:'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码打印数据集的属性：
- en: '[PRE47]'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'This will give the following output with the properties and the number of classes:'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将输出以下结果，包括属性和类别数量：
- en: '![Figure 7.30: Number of classes'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.30：类别数量'
- en: '](img/B16341_07_30.jpg)'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_30.jpg)'
- en: 'Figure 7.30: Number of classes'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.30：类别数量
- en: 'Build the train and test data pipelines, as shown in *Exercise 7.03*, *Building
    a CNN*:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建训练和测试数据管道，如*练习7.03*，*构建CNN*所示：
- en: '[PRE48]'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Build the model using the functional API. Set the shape, layer types, strides,
    and activation functions:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用功能式API构建模型。设置形状、层类型、步长和激活函数：
- en: '[PRE49]'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Compile and fit your model. Be sure to use your GPU for this, if possible,
    as it will speed up the process quite a bit. If you decide not to use the GPU
    and your machine has difficulty in terms of computation, you can decrease the
    number of epochs accordingly:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译并拟合你的模型。如果可能，请确保使用GPU，因为这将显著加速过程。如果你决定不使用GPU，而你的计算机在计算方面有困难，你可以相应地减少训练轮数（epochs）的数量：
- en: '[PRE50]'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The function will return the following history:'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该函数将返回以下历史记录：
- en: '![Figure 7.31: Fitting the model'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.31：拟合模型'
- en: '](img/B16341_07_31.jpg)'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_31.jpg)'
- en: 'Figure 7.31: Fitting the model'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.31：拟合模型
- en: 'Get a visual representation of the model''s performance by plotting your loss
    and accuracy per epoch:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过绘制每个epoch的损失和准确率，获得模型性能的可视化表示：
- en: '[PRE51]'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'This will produce the following plot:'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将产生以下图：
- en: '![Figure 7.32: Loss plot'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.32：损失图'
- en: '](img/B16341_07_32.jpg)'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_32.jpg)'
- en: 'Figure 7.32: Loss plot'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.32：损失图
- en: 'Next, get an accuracy plot by using the following code:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用以下代码获取准确率图：
- en: '[PRE52]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'This will give the following plot:'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将生成如下图：
- en: '![Figure 7.33: Accuracy plot'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.33：准确率图'
- en: '](img/B16341_07_33.jpg)'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_33.jpg)'
- en: 'Figure 7.33: Accuracy plot'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.33：准确率图
- en: 'Plot the confusion matrix without normalization:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制未标准化的混淆矩阵：
- en: '[PRE53]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'This will give the following output:'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将输出以下结果：
- en: '![Figure 7.34: Confusion matrix without normalization'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.34：未标准化的混淆矩阵'
- en: '](img/B16341_07_34.jpg)'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_34.jpg)'
- en: 'Figure 7.34: Confusion matrix without normalization'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.34：未标准化的混淆矩阵
- en: 'Use the following code to plot the confusion matrix with normalization:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码绘制带标准化的混淆矩阵：
- en: '[PRE54]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output will look like this:'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下所示：
- en: '![Figure 7.35: Confusion matrix with normalization'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.35：带标准化的混淆矩阵'
- en: '](img/B16341_07_35.jpg)'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_35.jpg)'
- en: 'Figure 7.35: Confusion matrix with normalization'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.35：带标准化的混淆矩阵
- en: 'Take a look at one of the images that the model got wrong. Plot one of the
    incorrect predictions with the following code:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看模型预测错误的其中一张图片。使用以下代码绘制其中一个错误预测的图像：
- en: '[PRE55]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output will look like this:'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下所示：
- en: '![Figure 7.36: True versus predicted results'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.36：真实结果与预测结果'
- en: '](img/B16341_07_36.jpg)'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_36.jpg)'
- en: 'Figure 7.36: True versus predicted results'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.36：真实结果与预测结果
- en: 'You''ll notice it says `True label: bird` and `Predicted label: cat`. This
    means that the model predicted that this image was a cat, but it was a bird. The
    image is blurry since the resolution is only `32x32`; however, the results are
    not bad. It would be fair to say that it is difficult for a human to identify
    whether the image was a dog or a cat.'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到它显示`真实标签：鸟`和`预测标签：猫`。这意味着模型预测这张图片是猫，但实际是鸟。图片模糊，因为分辨率只有`32x32`；然而，结果还不错。可以公平地说，对于人类来说，很难判断这张图片是狗还是猫。
- en: Now that you have completed this chapter, it's time to put everything that you've
    learned to the test with *Activity 7.01*, *Building a CNN with More ANN Layers*,
    where you'll be building a CNN with additional ANN layers.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经完成了本章内容，是时候通过*活动7.01*，*构建一个包含更多ANN层的CNN*，来检验你所学到的一切，其中你将构建一个包含更多ANN层的CNN。
- en: 'Activity 7.01: Building a CNN with More ANN Layers'
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动7.01：构建一个包含更多ANN层的CNN
- en: The start-up that you've been working for has loved your work so far. They have
    tasked you with creating a new model that is capable of classifying images from
    100 different classes.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 你所在的初创公司很喜欢你到目前为止的工作。他们已将你指派去创建一个新的模型，能够对100个不同类别的图像进行分类。
- en: In this activity, you'll be putting everything that you've learned to use as
    you build your own classifier with `CIFAR-100`. `CIFAR-100` is a more advanced
    version of the `CIFAR-10` dataset, with 100 classes, and is commonly used for
    benchmarking performance in machine learning research.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，你将把你所学的一切付诸实践，构建自己的分类器，并使用 `CIFAR-100` 数据集。`CIFAR-100` 是 `CIFAR-10` 数据集的更高级版本，包含
    100 个类别，广泛用于机器学习研究中的性能基准测试。
- en: Start a new Jupyter notebook.
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动一个新的 Jupyter notebook。
- en: Import the TensorFlow library.
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 TensorFlow 库。
- en: Import the additional libraries that you will need, including NumPy, Matplotlib,
    Input, Conv2D, Dense, Flatten, Dropout, GlobalMaxPooling2D, Activation, Model,
    confusion_matrix, and itertools.
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入你需要的额外库，包括 NumPy、Matplotlib、Input、Conv2D、Dense、Flatten、Dropout、GlobalMaxPooling2D、Activation、Model、confusion_matrix
    和 itertools。
- en: 'Load the `CIFAR-100` dataset directly from `tensorflow_datasets` and view its
    properties from the metadata, and build a train and test data pipeline:![Figure
    7.37: Properties of the CIFAR-100 dataset'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接从 `tensorflow_datasets` 加载 `CIFAR-100` 数据集，并查看其元数据中的属性，构建训练和测试数据管道：![图 7.37：CIFAR-100
    数据集的属性
- en: '](img/B16341_07_37.jpg)'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_37.jpg)'
- en: 'Figure 7.37: Properties of the CIFAR-100 dataset'
  id: totrans-381
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.37：CIFAR-100 数据集的属性
- en: Create a function to rescale images. Then, build a test and train data pipeline
    by rescaling, caching, shuffling, batching, and prefetching the images.
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数来重新缩放图像。然后，通过重新缩放、缓存、打乱、批处理和预取图像，构建测试和训练数据管道。
- en: Build the model using the functional API using `Conv2D` and `Flatten`, among others.
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用功能性 API 构建模型，使用 `Conv2D` 和 `Flatten` 等层。
- en: 'Compile and fit the model using `model.compile` and `model.fit`:![Figure 7.38:
    Model fitting'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`model.compile`和`model.fit`编译并训练模型：![图 7.38：模型拟合
- en: '](img/B16341_07_38.jpg)'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_38.jpg)'
- en: 'Figure 7.38: Model fitting'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.38：模型拟合
- en: 'Plot the loss with `plt.plot`. Remember to use the history collected during
    the `model.fit()` procedure:![Figure 7.39: Loss versus epochs'
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`plt.plot`绘制损失图。记得使用在 `model.fit()` 过程中收集的历史数据：![图 7.39：损失与迭代次数
- en: '](img/B16341_07_39.jpg)'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_39.jpg)'
- en: 'Figure 7.39: Loss versus epochs'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.39：损失与迭代次数
- en: 'Plot the accuracy with `plt.plot`:![Figure 7.40: Accuracy versus epochs'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`plt.plot`绘制准确率：![图 7.40：准确率与迭代次数
- en: '](img/B16341_07_40.jpg)'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_40.jpg)'
- en: 'Figure 7.40: Accuracy versus epochs'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.40：准确率与迭代次数
- en: Specify the labels for the different classes in your dataset.
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为数据集中的不同类别指定标签。
- en: 'Display a misclassified example with `plt.imshow`:![Figure 7.41: Wrong classification
    example'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`plt.imshow`显示一个误分类的示例：![图 7.41：错误分类示例
- en: '](img/B16341_07_41.jpg)'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_07_41.jpg)'
- en: 'Figure 7.41: Wrong classification example'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.41：错误分类示例
- en: Note
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor272).
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以通过[这个链接](B16341_Solution_ePub.xhtml#_idTextAnchor272)找到。
- en: Summary
  id: totrans-399
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter covered CNNs. We reviewed core concepts such as neurons, layers,
    model architecture, and tensors to understand how to create effective CNNs.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了卷积神经网络（CNN）。我们回顾了神经元、层、模型架构和张量等核心概念，帮助理解如何创建有效的 CNN。
- en: You learned about the convolution operation and explored kernels and feature
    maps. We analyzed how to assemble a CNN, and then explored the different types
    of pooling layers and when to apply them.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 你学习了卷积操作，并探索了卷积核和特征图。我们分析了如何组装一个 CNN，并探讨了不同类型的池化层及其应用时机。
- en: You then learned about the stride operation and how padding is used to create
    extra space around images if needed. Then, we delved into the flattening layer
    and how it is able to convert data into a 1D array for the next layer. You put
    everything that you learned to the test in the final activity, as you were presented
    with several classification problems, including `CIFAR-10` and even `CIFAR-100`.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 你还学习了步幅操作以及如何使用填充来在图像周围创建额外的空间。然后，我们深入研究了 flatten 层，它如何将数据转换为 1D 数组以供下一层使用。在最后的活动中，你将学到的所有知识付诸实践，面临多个分类问题，包括
    `CIFAR-10` 甚至 `CIFAR-100`。
- en: In completing this chapter, you are now well on your way to being able to implement
    CNNs to confront image classification problems head-on and with confidence.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章后，你现在已经能够自信地实现 CNN，并直接应对图像分类问题。
- en: In the next chapter, you'll learn about pre-trained models and how to utilize
    them for your own applications by adding ANN layers on top of the pre-trained
    model and fine-tuning the weights given your own training data.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，你将学习预训练模型，并了解如何通过在预训练模型上添加 ANN 层并根据自己的训练数据微调权重，来将其用于自己的应用程序。
