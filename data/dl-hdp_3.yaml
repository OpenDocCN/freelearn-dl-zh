- en: Chapter 3.  Convolutional Neural Network
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章 卷积神经网络
- en: '|   | *"The question of whether a computer can think is no more interesting
    than the question of whether a submarine can swim."* |   |'
  id: totrans-1
  prefs: []
  type: TYPE_TB
  zh: '|   | *“一个计算机是否能够思考的问题，并不比潜水艇是否能游泳的问题更有趣。”* |   |'
- en: '|   | --*Edsger W. Dijkstra* |'
  id: totrans-2
  prefs: []
  type: TYPE_TB
  zh: '|   | --*埃兹赫尔·W·代克斯特拉* |'
- en: '**Convolutional neural network (CNN)**--doesn''t it give an uncanny feeling
    about the combination of mathematics and biology with some negligible amount of
    computer science added? However, these type of networks have been some of the
    most dominant and powerful architectures in the field of computer vision. CNN
    started to gain its popularity after 2012, when there were huge improvements in
    the precision of classification, credit to some pioneer in the field of deep learning.
    Ever since then, a bunch of high-tech companies have been using deep CNN for various
    services. Amazon uses CNN for their product recommendations, Google uses it for
    their photo search, and Facebook primarily uses it for its automatic tagging algorithms.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络（CNN）**——它是否让你有一种数学与生物学相结合，并且加入了一些微不足道的计算机科学元素的奇特感觉？然而，这类网络一直是计算机视觉领域中最具主导地位和强大功能的架构之一。自2012年以来，随着深度学习领域的一些先驱者的贡献，CNN在分类精度上取得了巨大的进展，开始获得广泛关注。自那时以来，许多高科技公司开始使用深度CNN提供各种服务。亚马逊利用CNN进行产品推荐，谷歌用它来进行照片搜索，Facebook则主要用于其自动标记算法。'
- en: CNN [89] is a type of feed-forward neural network comprised of neurons, which
    have learnable weights and biases. These types of networks are basically used
    to process data, having the grid-like topology form. CNNs, as the name suggests,
    are a type of neural network where, unlike the general matrix multiplication,
    a special type of linear mathematical operation, convolution, is used in at least
    one of the subsequent layers. The architecture of CNN is designed to take the
    benefit of input with multidimensional structure. These include the 2D structure
    of an input image, speech signal, or even one-dimensional time series data. With
    all these advantages, CNN has been really successful with many practical applications.
    CNN is thus tremendously successful, specifically in fields such as natural language
    processing, recommender systems, image recognition, and video recognition.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: CNN [89] 是一种前馈神经网络，由具有可学习权重和偏置的神经元组成。这类网络主要用于处理具有网格状拓扑结构的数据。正如其名称所示，CNN是一种神经网络，其中与普通的矩阵乘法不同，至少在后续的某一层中，使用了一种特殊的线性数学运算——卷积。CNN的架构旨在利用具有多维结构的输入。包括输入图像的二维结构、语音信号，甚至是一维时间序列数据。凭借这些优势，CNN在许多实际应用中都取得了巨大的成功。因此，CNN在自然语言处理、推荐系统、图像识别和视频识别等领域特别成功。
- en: Note
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: A bias unit is an *extra* neuron that has a value of 1 and is added to each
    pre-output layer. These units are not connected to the previous layer and so do
    not represent any *activity* in a real sense.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 偏置单元是一个*额外的*神经元，它的值为1，并被添加到每个预输出层。这些单元与前一层没有连接，因此在真实意义上并不代表任何*活动*。
- en: In this chapter, we will discuss the building block of CNN in-depth. We will
    initially discuss what convolution is and the need of convolution operations in
    the neural network. Under that topic, we will also address pooling operation,
    which is the most important component of CNN. The next topic of this chapter will
    point out the major challenges of CNN while dealing with large-scale data. The
    last part of this chapter will help the reader to learn how to design CNN using
    Deeplearning4j.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入讨论CNN的构建模块。我们将首先讨论什么是卷积以及卷积操作在神经网络中的必要性。在这一主题下，我们还将涉及池化操作，它是CNN中最重要的组成部分。本章的下一个主题将指出CNN在处理大规模数据时面临的主要挑战。本章的最后部分将帮助读者学习如何使用Deeplearning4j设计CNN。
- en: 'The main topics of the chapter are listed as follows:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要内容如下：
- en: Understanding convolution
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解卷积
- en: Background of a CNN
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN的背景
- en: Basic layers of CNN
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN的基本层
- en: Distributed deep CNN
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式深度CNN
- en: CNN with Deeplearning4j
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Deeplearning4j实现CNN
- en: Understanding convolution
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解卷积
- en: To understand the concept of convolution, let us take an example to determine
    the position of a lost mobile phone with the help of a laser sensor. Let's say
    the current location of the mobile phone at time *t* can be given by the laser
    as *f (t)*. The laser gives different readings of the location for all the values
    of *t*. The laser sensors are generally noisy in nature, which is undesirable
    for this scenario. Therefore, to derive a less noisy measurement of the location
    of the phone, we need to calculate the average various measurements. Ideally,
    the more the measurements, the greater the accuracy of the location. Hence, we
    should undergo a weighted average, which provides more weight to the measurements.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解卷积的概念，假设我们通过激光传感器来定位丢失的手机。假设在时间 *t* 时，手机的位置可以由激光传感器提供，即 *f (t)*。激光传感器会为所有
    *t* 的值给出不同的位置读数。激光传感器通常会受到噪声的干扰，这在这个场景中是不可取的。因此，为了获得更少噪声的手机位置测量，我们需要计算各种测量的平均值。理想情况下，测量次数越多，位置的准确性就越高。因此，我们应该进行加权平均，以赋予测量值更多的权重。
- en: A weighted function can be given by the function *w (b)*, where *b* denotes
    the age of the measurement. To derive a new function that will provide a better
    estimate of the location of the mobile phone, we need to take the average of the
    weight at every moment.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 加权函数可以由函数 *w (b)* 给出，其中 *b* 表示测量的时间。这时，为了推导出一个新的函数，从而更好地估计手机的位置，我们需要在每个时刻对权重进行平均。
- en: 'The new function can be given as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 新的函数可以表示如下：
- en: '![Understanding convolution](img/image_03_001.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![理解卷积](img/image_03_001.jpg)'
- en: 'The preceding operation is termed as convolution. The conventional method of
    representing convolution is denoted by an asterisk or star, ''*'':'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 上述操作被称为卷积。卷积的传统表示方法使用星号或星号符号 '*' 来表示：
- en: '![Understanding convolution](img/image_03_002.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![理解卷积](img/image_03_002.jpg)'
- en: Formally, convolution can be defined as an integral of the product of two functions,
    where one of the functions is reversed and shifted. Besides, taking the weighted
    averages, it may also be used for other purposes.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 正式而言，卷积可以定义为两个函数的乘积的积分，其中一个函数被反转并移动。此外，通过加权平均，卷积还可以用于其他目的。
- en: 'In terms of convolutional network terminology, the function *f* in our example
    is referred to as the input and the function *w*, the second parameter is called
    the kernel of the operation. The kernel is composed of a number of filters, which
    will be used on the input to get the output, referred to as *feature maps*. In
    a more convenient way, the kernel can be seen as a membrane, which will allow
    only the desirable features of the input to pass through it. *Figure 3.1* shows
    a pictorial view of the operation:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 从卷积网络的术语来看，我们示例中的函数 *f* 被称为输入函数，而函数 *w*，即第二个参数，被称为操作的核心（kernel）。该核心由多个滤波器组成，这些滤波器将用于输入数据以获得输出，即
    *特征图*。更直观地说，核心可以看作是一个膜，只允许输入的期望特征通过它。*图 3.1* 展示了该操作的示意图：
- en: '![Understanding convolution](img/image_03_003.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![理解卷积](img/image_03_003.jpg)'
- en: 'Figure 3.1: The figure shows a simple representation of a convolutional network
    where the input has to pass through the kernel to provide the feature map.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：该图展示了卷积网络的简单表示，其中输入必须通过核心才能提供特征图。
- en: 'In a practical scenario, as our example shows, the laser sensor cannot really
    provide the measurements at every given instant of time. Ideally, when a computer
    works on data, it only works at some regular intervals; hence, the time will be
    discrete. So, the sensor will generally provide the results at some defined interval
    of time. If we assume that the instrument provides output once/second, then the
    parameter *t* will only take integer values. With these assumptions, the functions
    *f* and *w* will only be defined for integer values of *t*. The modified equation
    for discrete convolution can now be written as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际场景中，如我们的示例所示，激光传感器并不能在每个时间点提供测量值。理想情况下，当计算机处理数据时，它只能在某些固定的时间间隔内工作，因此时间是离散的。因此，传感器通常会在某些定义的时间间隔内提供结果。如果我们假设仪器每秒提供一次输出，那么参数
    *t* 将只取整数值。基于这些假设，函数 *f* 和 *w* 将仅在 *t* 的整数值下定义。离散卷积的修改方程可以写成如下形式：
- en: '![Understanding convolution](img/image_03_004.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![理解卷积](img/image_03_004.jpg)'
- en: 'In case of machine learning or deep learning applications, the inputs are generally
    a multidimensional array of data, and the kernel uses multidimensional arrays
    of different parameters taken by the algorithm. The basic assumption is that the
    values of the functions are non-zero only for a finite set of points for which
    we store the values, and zero elsewhere. So, the infinite summation can be represented
    as the summation for a range of a finite number of array elements. For example,
    for a 2D image *I* as an input and a corresponding 2D kernel *K*, the convolution
    function can be written as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习或深度学习应用中，输入通常是一个多维数据数组，而卷积核使用算法获取的不同参数的多维数组。基本假设是函数的值仅对一组有限的点为非零，且我们仅存储这些点的值，其他地方为零。因此，无限求和可以表示为一组有限数组元素的求和。例如，对于一个二维图像
    *I* 作为输入和一个对应的二维卷积核 *K*，卷积函数可以表示如下：
- en: '![Understanding convolution](img/image_03_005.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![理解卷积](img/image_03_005.jpg)'
- en: So, with this, you have already got some background of convolution. In the next
    section of this chapter, we will discuss the application of convolution in a neural
    network and the building blocks of CNN.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，通过这一部分，你已经了解了一些卷积的背景知识。在本章的下一部分，我们将讨论卷积在神经网络中的应用以及卷积神经网络的构建模块。
- en: Background of a CNN
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络的背景
- en: CNN, a particular form of deep learning models, is not a new concept, and they
    have been widely adopted by the vision community for a long time. The model worked
    well in recognizing the hand-written digit by LeCun et al in 1998 [90]. But unfortunately,
    due to the inability of CNNs to work with higher resolution images, its popularity
    has diminished with the course of time. The reason was mostly due to hardware
    and memory constraints, and also the lack of availability of large-scale training
    datasets. As the computational power increases with time, mostly due to the wide
    availability of CPUs and GPUs and with the generation of big data, various large-scale
    datasets, such as the MIT Places dataset (see Zhou et al., 2014), ImageNet [91]
    and so on. it became possible to train larger and complex models. This is initially
    shown by Krizhevsky et al [4] in their paper, *Imagenet classification using deep
    convolutional neural networks*. In that paper, they brought down the error rate
    with half-beating traditional approaches. Over the next few years, their paper
    became one of the most substantial papers in the field of computer vision. This
    popular network trained by Alex Krizhevsky, called AlexNet, could well have been
    the starting point of using deep networks in the field of computer vision.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）作为深度学习模型的一种特殊形式，并不是一个新概念，它们已经被计算机视觉领域广泛采用了很长时间。该模型在1998年由LeCun等人成功应用于手写数字识别[90]。但不幸的是，由于CNN无法处理高分辨率图像，它的流行度随着时间的推移有所下降。其原因主要是由于硬件和内存的限制，以及大规模训练数据集的缺乏。随着计算能力的不断提高，尤其是CPU和GPU的广泛普及以及大数据的产生，各种大型数据集（如MIT
    Places数据集（参见Zhou等，2014）、ImageNet[91]等）使得训练更大、更复杂的模型成为可能。这一点最早在Krizhevsky等人[4]的论文《使用深度卷积神经网络进行Imagenet分类》中得到了展示。在这篇论文中，他们通过将错误率降低到传统方法的一半，取得了突破。接下来的几年里，他们的论文成为计算机视觉领域最重要的论文之一。由Alex
    Krizhevsky训练的这个流行网络，名为AlexNet，可能是计算机视觉领域使用深度网络的起点。
- en: Architecture overview
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构概述
- en: We assume that the readers are already familiar with the traditional neural
    network. In this section, we will look at the general building blocks of CNN.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设读者已经熟悉传统的神经网络。在本节中，我们将探讨卷积神经网络（CNN）的一般构建模块。
- en: 'The traditional neural network receives a single vector as input, and reaches
    the intermediate states through a series of latent (hidden) layers. Each hidden
    layer is composed of several neurons, where each neuron is fully connected to
    every other neuron of the previous layer. The last layer, called the ''output
    layer'', is fully-connected, and it is responsible for the class scores. A regular
    neural network composed of three layers is shown in *Figure 3.2*:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的神经网络接收一个单一的向量作为输入，并通过一系列潜在（隐藏）层达到中间状态。每个隐藏层由多个神经元组成，每个神经元与前一层的每个神经元完全连接。最后一层，称为“输出层”，是完全连接的，它负责类别分数。一个由三层组成的常规神经网络如*图3.2*所示：
- en: '![Architecture overview](img/image_03_006.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![架构概述](img/image_03_006.jpg)'
- en: 'Figure 3.2: The figure shows the block diagram of a three-layer regular neural
    network. The neurons of every layer are fully-connected to every other layer of
    the previous layer.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2：该图展示了一个三层常规神经网络的框图。每一层的神经元都与上一层的所有其他层神经元完全连接。
- en: 'Regular neural networks face tremendous challenges while dealing with large-scale
    images. For example, in the CIFAR-10 RGB database, the dimension of the images
    are *32x32x3*, hence, a single fully-connected neuron in a first hidden layer
    of the traditional neural network will have *32*32*3= 3072* number of weights.
    The number of weights, although seems to be reasonable at the outset, would really
    be a cumbersome task to manage with the increasing number of dimensions. For another
    RGB image, if the dimension becomes (*300x300x3*), the total number of weights
    of the neurons will result in *300*300*3 = 270000* weights. Also, as the number
    of layers will increase, this number will also increase drastically, and would
    quickly lead to overfitting. Moreover, visualization of an image completely neglects
    the complex 2D spatial structure of the image. Therefore, the fully-connected
    concept of the neural network, right from the initial phase, does not seem to
    work with the larger dimensional datasets. So, we need to build a model that will
    overcome both of these limitations:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 常规神经网络在处理大规模图像时面临巨大挑战。例如，在CIFAR-10 RGB数据库中，图像的尺寸为*32x32x3*，因此，传统神经网络中第一隐藏层的单个全连接神经元将具有*32*32*3=3072*个权重。虽然权重的数量在一开始看起来似乎是合理的，但随着维度数量的增加，管理这些权重将变得非常繁琐。对于另一个RGB图像，如果尺寸变为（*300x300x3*），那么神经元的总权重数将达到*300*300*3=270000*个权重。此外，随着层数的增加，这个数字也将急剧增加，很快会导致过拟合。此外，图像的可视化完全忽视了图像的复杂二维空间结构。因此，神经网络的全连接概念从一开始就似乎无法适应更大维度的数据集。因此，我们需要构建一个能够克服这两种限制的模型：
- en: '![Architecture overview](img/image_03_007.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![架构概览](img/image_03_007.jpg)'
- en: 'Figure 3.3: The arrangement of CNN in 3D (width, height, and depth) is represented
    in the figure. Every layer converts the 3D input volume to the corresponding 3D
    output volume of neuron activations. The red input layer keeps the image, hence,
    its width and height would be the dimensions of the image, where the depth would
    be three (Red, Green, and Blue). Image sourced from Wikipedia.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3：图中展示了CNN在三维（宽度、高度和深度）中的排列方式。每一层将三维输入体积转换为相应的三维输出体积，输出的是神经元激活值。红色输入层保持图像，因此其宽度和高度将是图像的尺寸，而深度则为三（红色、绿色和蓝色）。图像来源于Wikipedia。
- en: 'One way to solve this problem is to use convolution in place of matrix multiplication.
    Learning from a set of convolutional filters (kernel) is much easier than learning
    from the whole matrix (*300x300x3*). Unlike the traditional neural network, the
    layers of a CNN have their neurons arranged in three dimensions: width, height,
    and depth. *Figure 3.3* shows the representation for this. For example, in the
    previous example of CIFAR-10, the image has a dimension of *32x32x3*, which is
    width, depth, and height respectively. In a CNN, instead of the neurons in a fully-connected
    nature, the neurons in a layer will only be connected to a subset of neurons in
    the previous layer. Details of this will be explained in the subsequent portion
    of this section. Moreover, the final output layer CIFAR-10 image will have the
    dimension *1x1x10*, because the CNN will diminish the full image into a single
    vector of class score, placed along with the depth dimension.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的一种方法是用卷积代替矩阵乘法。学习一组卷积滤波器（核）比从整个矩阵（*300x300x3*）中学习要容易得多。与传统神经网络不同，CNN的每一层的神经元排列在三维空间中：宽度、高度和深度。*图3.3*展示了这一表示方式。例如，在前面提到的CIFAR-10示例中，图像的尺寸为*32x32x3*，这分别是宽度、深度和高度。在CNN中，每一层的神经元不会像全连接网络那样与上一层的所有神经元相连，而是仅与上一层中某一子集的神经元相连。该部分的详细内容将在本节后续部分中解释。此外，最终输出层的CIFAR-10图像将具有*1x1x10*的尺寸，因为CNN会将完整的图像缩减为一个类别分数的单一向量，并与深度维度一起放置。
- en: Basic layers of CNN
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CNN的基本层
- en: 'A CNN is composed of a sequence of layers, where every layer of the network
    goes through a differentiable function to transform itself from one volume of
    activation to another. Four main types of layers are used to build a CNN: Convolutional
    layer, Rectified Linear Units layer, Pooling layer, and Fully-connected layer.
    All these layers are stacked together to form a full CNN.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络由一系列层组成，其中网络的每一层都通过一个可微分的函数将自己从一个激活体积转换到另一个激活体积。构建CNN时使用四种主要类型的层：卷积层、修正线性单元层、池化层和全连接层。所有这些层堆叠在一起，形成一个完整的CNN。
- en: 'A regular CNN could have the following architecture:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常规的CNN可能具有以下架构：
- en: '[INPUT - CONV - RELU - POOL - FC]'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[输入 - 卷积 - ReLU - 池化 - 全连接]'
- en: However, in a deep CNN, there are generally more layers interspersed between
    these five basic layers.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在深度卷积神经网络中，通常会在这五个基本层之间插入更多的层。
- en: 'A classic deep neural network will have the following structure:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一个经典的深度神经网络将具有以下结构：
- en: Input -> Conv->ReLU->Conv->ReLu->Pooling->ReLU->Conv->ReLu->Pooling->Fully Connected
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 输入 -> 卷积 -> ReLU -> 卷积 -> ReLU -> 池化 -> ReLU -> 卷积 -> ReLU -> 池化 -> 全连接
- en: AlexNet, as mentioned in the earlier section, can be taken as a perfect example
    for this kind of structure. The architecture of AlexNet is shown in *Figure 3.4*.
    After every layer, an implicit ReLU non-linearity has been added. We will explain
    this in detail in the next section.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如前文所述，AlexNet可以作为这种结构的完美示例。AlexNet的架构如*图 3.4*所示。在每一层之后，都会添加一个隐式的ReLU非线性函数。我们将在下一节中详细解释这一点。
- en: 'One might wonder, why do we need multiple layers in a CNN? The next section of
    this chapter shall explain this as well:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，为什么CNN中需要多层？本章的下一节将为你解释这一点：
- en: '![Basic layers of CNN](img/image_03_008.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![CNN的基本层](img/image_03_008.jpg)'
- en: 'Figure 3.4: An illustration of the depth and weight of the AlexNet is shown
    in the figure. The number inside the curly braces denotes the number of filters
    with dimensions written above.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4：图中展示了AlexNet的深度和权重的示意图。花括号内的数字表示上方写明的滤波器数量。
- en: Importance of depth in a CNN
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CNN中深度的重要性
- en: In the paper [96], the author has put forward a few statistics, to show how
    deep networks help in gaining more accuracy of the output. As noted, the Architecture
    of Krizhevsky et al. model uses eight layers, which are trained on ImageNet. When
    the fully connected top layer (7th layer) is removed, it drops approximately 16
    million parameters with a performance drop of 1.1%. Furthermore, when the top
    two layers (6th and 7th) are removed, nearly 50 million parameters get reduced
    along with a 5.7% drop in performance. Similarly, when the upper feature extractor
    layers (3rd and 4th) are removed, it results in a drop of around 1 million parameters
    with a performance drop of 3.0%. To get a better insight of the scenario, when
    the upper feature extractor layers and the fully connected (3rd, 4th, 6th, and
    7th) layers are removed, the model was left with only four layers. In that case,
    a 33.5% drop in performance is experienced.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文[96]中，作者提出了一些统计数据，展示了深度网络如何帮助提高输出的准确性。如前所述，Krizhevsky等人的架构使用了八层，并在ImageNet上进行训练。当移除最上层的全连接层（第7层）时，约有1600万个参数被移除，性能下降了1.1%。此外，当移除最上面的两层（第6层和第7层）时，减少了近5000万个参数，并且性能下降了5.7%。类似地，当移除上面的特征提取层（第3层和第4层）时，减少了约100万个参数，性能下降了3.0%。为了更好地理解这一情况，当移除上面的特征提取层和全连接层（第3、4、6和7层）时，模型仅剩下四层。在这种情况下，性能下降了33.5%。
- en: Therefore, it can be easily concluded that we need deep convolutional network
    to increase the performance of the model. However, as already stated, a deep network
    is extremely difficult to manage in a centralized system due to limitations of
    memory and performance management. So, a distributed way of implementing deep
    CNN is required. In the subsequent sections of this chapter, we will explain how
    to implement this with the help of Deeplearning4j, and integrating the processing
    with Hadoop's YARN.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，可以轻松得出结论：我们需要深度卷积网络来提高模型的性能。然而，正如前面所说，深度网络在集中式系统中非常难以管理，因为受限于内存和性能管理的局限性。因此，需要一种分布式的方法来实现深度卷积神经网络。在本章的后续部分，我们将解释如何借助Deeplearning4j实现这一点，并将处理过程与Hadoop的YARN集成。
- en: Convolutional layer
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积层
- en: 'As illustrated in the architecture overview, the main purpose of convolution
    is to allow the model to work with a limited number of inputs at a particular
    time. Moreover, convolution supports three most important features, which substantially
    help in improving the performance of a deep learning model. The features are listed
    as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如架构概述中所示，卷积的主要目的是使模型在特定时间内仅处理有限数量的输入。此外，卷积支持三项最重要的特性，这些特性在显著提高深度学习模型性能方面起着关键作用。以下列出了这些特性：
- en: Sparse connectivity
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稀疏连接
- en: Parameter sharing
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数共享
- en: Equivariant representations
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等变表示
- en: We will now describe each of these features in turn.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将依次描述这些特性。
- en: Sparse connectivity
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 稀疏连接
- en: As already explained, the traditional network layers use matrix multiplication
    by a matrix of parameters with a different parameter describing the interaction
    between each output unit and input unit. On the other hand, CNNs use sparse connectivity,
    sometimes referred to as sparse interactions or sparse weights, for this purpose.
    This idea is attained by keeping the size of the kernel smaller than the input,
    which helps in reducing the time complexity of the algorithm. For example, for
    a large image dataset, the image could have thousands or millions of pixels; however,
    we can identify the small, significant features of the image, such as edges and
    contours from the kernels, which only have hundreds or tens of the whole pixels.
    Therefore, we need to keep only a small number of parameters, which, in turn,
    helps in the reduction of memory requirements of the models and datasets. The
    idea also alleviates the number of operations, which could enhance the overall
    computing power. This, in turn, decreases the running time complexity of the computation
    in a huge manner, which eventually ameliorates its efficiency. *Figure 3.5* diagrammatically
    shows, how with the sparse connectivity approach, we can reduce the number of
    receptive fields of each neuron.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，传统网络层通过一个包含不同参数的矩阵进行矩阵乘法，这些参数描述了每个输出单元与输入单元之间的相互作用。另一方面，卷积神经网络（CNN）采用稀疏连接，有时也称为稀疏交互或稀疏权重。这个想法通过保持卷积核的大小小于输入来实现，这有助于降低算法的时间复杂度。例如，对于一个大型图像数据集，图像可能包含成千上万或数百万个像素；然而，我们可以通过卷积核识别出图像中的小而重要的特征，比如边缘和轮廓，而这些卷积核只包含几百个或几十个像素。因此，我们只需要保持少量的参数，从而帮助减少模型和数据集的内存需求。这个想法还缓解了操作次数，能够增强整体的计算能力。这反过来大大降低了计算的运行时间复杂度，最终提高了效率。*图3.5*
    以图示的方式展示了如何通过稀疏连接方法减少每个神经元的感受野数量。
- en: Note
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Each neuron in a Convolutional layer renders the response of the filters applied
    in the previous layer. The main purpose of these neurons is to pass the responses
    through some non-linearity. The total area of the previous layers, where that
    filter was applied, is termed as the receptive field of that neuron. So, the receptive
    field is always equivalent to the size of the filter.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层中的每个神经元都会呈现前一层应用的滤波器的响应。这些神经元的主要作用是将响应传递通过某些非线性函数。前一层中应用该滤波器的总区域称为该神经元的感受野。因此，感受野的大小始终等于滤波器的大小。
- en: '![Sparse connectivity](img/B05883_03_05.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![稀疏连接](img/B05883_03_05.jpg)'
- en: 'Figure 3.5: The figure shows how the input units of M affect the output unit
    N3 with sparse connectivity.Unlike matrix multiplication, the number of receptive
    fields in the sparse connectivity approach reduce from five to three (M2, M3,
    and M4). The arrows indicate the parameter sharing approach too. The connections
    from one neuron are shared with two neurons in the model'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5：该图展示了稀疏连接下，M的输入单元如何影响输出单元N3。与矩阵乘法不同，稀疏连接方法中，感受野的数量从五个减少到三个（M2、M3和M4）。箭头还表示了参数共享的方法。来自一个神经元的连接与模型中的两个神经元共享。
- en: 'Therefore, with the sparse connectivity approach, the receptive fields for
    each layer are smaller than the receptive fields using the matrix multiplication
    approach. However, it is to be noted that for deep CNNs, the receptive field of
    the units is virtually larger than the receptive fields of the corresponding shallow
    networks. The reason is that all the units in the deep networks are indirectly
    connected to almost all the neurons of the network. *Figure 3.6* shows a visual
    representation of such a scenario:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用稀疏连接方法时，每层的感受野比使用矩阵乘法方法时的感受野要小。然而，值得注意的是，对于深度卷积神经网络（CNN），单元的感受野实际上比相应的浅层网络的感受野要大。原因是深度网络中的所有单元几乎都间接连接到网络中的几乎所有神经元。*图3.6*展示了这种情况的可视化表示：
- en: '![Sparse connectivity](img/B05883_03_06.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![稀疏连接](img/B05883_03_06.jpg)'
- en: 'Figure 3.6: Representation of sparse connectivity for deep layers of convolution
    neural networks. Unlike Figure 3.5, where unit N3 had three receptive fields,
    here the number of receptive fields of N3 has increased to five.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6：深度卷积神经网络稀疏连接的表示。与图3.5不同，图中单元N3有三个感受野，而这里N3的感受野数量增加到了五个。
- en: Improved time complexity
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 改进的时间复杂度
- en: Similar to the example given in the previous section, if there are *p* inputs
    and *q* outputs in a layer, then the matrix multiplication will require *(p*q)*
    number of parameters. The running time complexity of the algorithm will become
    *O (p*q)*. With the sparsely connected approach, if we limit the number of upper
    limit connections associated with each output to *n*, then it will need only *n*q*
    parameters, and the runtime complexity will reduce to *O (n*q)*. For many real-life
    applications, the sparse connectivity approach provides good performance for the
    deep learning tasks while keeping the size of *n <<p*.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于上一节中给出的例子，如果在某一层有*p*个输入和*q*个输出，那么矩阵乘法将需要*(p*q)*个参数。算法的运行时间复杂度将变为*O(p*q)*。使用稀疏连接方法时，如果我们将与每个输出相关联的上限连接数限制为*n*，则只需要*n*q*个参数，运行时复杂度将减少到*O(n*q)*。对于许多实际应用，稀疏连接方法在深度学习任务中提供了良好的性能，同时保持了*n
    << p*的参数规模。
- en: Parameter sharing
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 参数共享
- en: Parameter sharing can be defined as the process by which the same parameter
    for a function can be used for multiple functions in the model. In regular neural
    networks, each element of the weight matrix is applied exactly once, when calculating
    the output of a layer. The weight is multiplied by one element of the input, but
    never revisited. Parameter sharing can also be referred to as tied weights, as
    the value of the weight used to one input is tied to the value weight used for
    others. *Figure 3.5* can also be viewed as an example for parameter sharing. For
    example, a particular parameter from **M2** is used with both **N1** and **N3**.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 参数共享可以定义为在模型中，函数的相同参数可以被多个函数使用的过程。在常规神经网络中，权重矩阵的每个元素仅在计算层的输出时使用一次。权重与输入的一个元素相乘，但不会被再次访问。参数共享也可以称为绑定权重，因为用于一个输入的权重值与用于其他输入的权重值是绑定的。*图3.5*也可以作为参数共享的一个例子。例如，**M2**中的某个特定参数同时被**N1**和**N3**使用。
- en: The main purpose of the operation is to control the number of free parameters
    in the Convolutional layer. In a CNN, each element of the kernel is used at almost
    every position of the input. One logical assumption for this is that if one of
    the features is desirable at some spatial position, then it should also be necessary
    to calculate the other positions.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 操作的主要目的是控制卷积层中自由参数的数量。在CNN中，卷积核的每个元素几乎在输入的每个位置上都被使用。对此的一个合理假设是，如果某个特征在某个空间位置上是需要的，那么它也应该在其他位置上进行计算。
- en: Since all the elements of a single depth slice share the same type of parametrization,
    the forward pass in each depth slice of the Convolutional layer can be measured
    as a convolutional of input volume with the weights of the neurons. The outcome
    of this convolution is an activation map. These collections of activation maps
    are stacked together with the association of depth dimension to result the output
    volume. Although the parameter sharing approach bestows the translation invariance
    of the CNN architecture, it does not enhance the runtime of forward propagation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 由于单个深度切片中的所有元素共享相同的参数化类型，因此卷积层中每个深度切片的前向传递可以视为输入体积与神经元权重的卷积。此卷积的结果是激活图。这些激活图集合与深度维度的关联被堆叠在一起，最终形成输出体积。尽管参数共享方法赋予了CNN架构平移不变性，但它并未提高前向传播的运行时间。
- en: Improved space complexity
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 改进的空间复杂度
- en: In parameter sharing, the runtime of the model still remains *O (n*q)*. However,
    it helps to reduce the overall space complexity in a significant way, as the storage
    requirement of the model reduces to n number of parameters. Since *p* and *q*
    are generally of similar sizes, the value of *n* becomes almost negligible as
    compared to *p*q*.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在参数共享中，模型的运行时间仍然保持为 *O (n*q)*。然而，它有助于显著减少整体空间复杂度，因为模型的存储需求减少到n个参数。由于*p*和*q*通常是相似大小的，*n*的值与*p*q*相比几乎可以忽略不计。
- en: Note
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Convolution is considerably more productive than the traditional dense matrix
    multiplication approach, both in terms of time complexity as well as space complexity.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积在时间复杂度和空间复杂度上都比传统的稠密矩阵乘法方法更高效。
- en: Equivariant representations
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 等变表示
- en: In the convolution layer, due to parameter sharing, the layers possess a property
    termed as equivariance to translation. An equivariant function is defined as a
    function whose output changes in the same way the input does.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积层中，由于参数共享，层具有一种称为平移等变性的特性。一个等变函数被定义为其输出以与输入相同的方式变化的函数。
- en: "Mathematically, if X and Y both belong to a same group G, then a function *f:\
    \ X ![Equivariant representations](img/Arrow.jpg) \x86\x92 Y* is said to be equivariant\
    \ if *f (g.x) = g.f(x) for* all *g* *![Equivariant representations](img/Belongs-t0.jpg)\
    \ G* and all *x* in *X*."
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: "从数学角度看，如果X和Y都属于同一群G，则一个函数*f: X ![等变表示](img/Arrow.jpg) \x86\x92 Y* 被称为等变的，如果对于所有*g*\
    \ *![等变表示](img/Belongs-t0.jpg) G*和所有*x* ∈ *X*，都有*f (g.x) = g.f(x)*。"
- en: 'In case of convolution, if we take *g* to be any function, which shifts the
    input in equal magnitude, then the convolution function is equivariant to *g*.
    For example, let *I* be a function that gives the image color for any even coordinate.
    Let *h* be another function, which maps one image function to another image function,
    given by the following equation:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积的情况下，如果我们将*g*视为任何一个函数，它以相同的幅度移动输入，那么卷积函数对*g*是等变的。例如，设*I*是一个函数，对于任何偶坐标，它给出图像的颜色。设*h*是另一个函数，它将一个图像函数映射到另一个图像函数，给定如下方程：
- en: '![Equivariant representations](img/image_03_011.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![等变表示](img/image_03_011.jpg)'
- en: '*I^/* is an image function that moves every pixel of *I* five units to the
    right. Therefore, we have the following:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*I^/* 是一个图像函数，将*I*的每个像素向右移动五个单位。因此，我们得到以下结果：'
- en: '![Equivariant representations](img/image_03_012.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![等变表示](img/image_03_012.jpg)'
- en: Now, if we apply this translation to *I*, followed by the convolution, the result
    would be exactly the same when we apply convolution to *I^/*, followed by the
    transformation function *h* to the output.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们对*I*应用这个平移操作，然后进行卷积，结果将与我们先对*I^/*应用卷积，再对输出应用变换函数*h*时的结果完全相同。
- en: In case of images, a convolution operation generates a two-dimensional map of
    all the definite features present in the input. So, similar to the earlier example,
    if we shift the object in the output by some fixed scale, the output representation
    will also move in the same scale. This concept is useful for some cases; for example,
    consider a group photo of cricket players of two different teams. We can find
    some common feature of the jersey in the image to detect some players. Now, the
    similar feature will obviously be present in others' t-shirts as well. So, it
    is quite practical to share the parameter across the entire image.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像，卷积操作生成一个二维的特征图，显示输入中所有明确的特征。因此，类似于前面的例子，如果我们将输出中的物体按某个固定比例进行平移，输出表示也会以相同的比例移动。这个概念在某些情况下是有用的；例如，考虑一张包含两支不同球队的板球运动员的合影。我们可以在图像中找到球衣的某些共同特征来识别一些运动员。现在，类似的特征显然也会出现在其他人的T恤上。所以，将参数共享到整个图像是相当实际的。
- en: Convolution also helps to process some special kinds of data, which are difficult,
    or rather not even possible, with the traditional fixed-shape matrix multiplication
    approach.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积还有助于处理一些特殊类型的数据，这些数据对于传统的固定形状矩阵乘法方法来说是困难的，甚至可以说是无法处理的。
- en: Choosing the hyperparameters for Convolutional layers
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择卷积层的超参数
- en: So far we have explained how each neuron in the convolution layers is connected
    to the input volume. In this section, we will discuss the ways of controlling
    the size of the output volume. In other words, controlling the number of neurons
    in the output volume, and how they are arranged.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经解释了卷积层中的每个神经元是如何连接到输入体积的。在这一部分，我们将讨论控制输出体积大小的方法。换句话说，控制输出体积中神经元的数量，以及它们的排列方式。
- en: 'Basically, there are three hyperparameters, which control the size of the output
    volume of the Convolutional layers. They are: the depth, stride, and zero-padding.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，有三个超参数控制卷积层输出体积的大小。它们是：深度、步幅和零填充。
- en: How do we know how many Convolutional layers should we use, what should be the
    size of the filters, or the values of stride and padding? These are extremely
    subjective questions, and their solutions are not at all trivial in nature. No
    researchers have set any standard parameter to choose these hyperparameters. A
    neural network generally and largely depends on the type of data used for training.
    This data can vary in size, complexity of the input raw image, type of image processing
    tasks, and many other criteria. One general line of thought by looking at the
    big dataset, is that one has to think how to choose the hyperparameters to deduce
    the correct combination, which creates abstractions of the images at proper scale.
    We'll discuss all these in this subsection.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何知道应该使用多少卷积层，过滤器的大小应该是多少，步幅和填充的值应该是多少？这些问题非常主观，其解决方案本质上并不简单。没有研究人员为这些超参数设定任何标准参数。神经网络通常在很大程度上依赖于用于训练的数据类型。这些数据的大小、输入原始图像的复杂性、图像处理任务的类型以及许多其他标准可能有所不同。根据大数据集的普遍思路，我们必须思考如何选择超参数，以推导出正确的组合，从而在适当的尺度上对图像进行抽象。我们将在这一小节中讨论所有这些内容。
- en: Depth
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度
- en: In the output volume, depth is considered as an important parameter. The depth
    corresponds to the number of filters we would like to apply for each learning
    iteration on some changes in the input. If the first Convolutional layer takes
    a raw image as the input, then multiple neurons along the depth dimension might
    activate in the presence of various blobs of colors or different oriented edges.
    The set of neurons in the same regions of input are termed as a depth column.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在输出体积中，深度被视为一个重要参数。深度对应于我们希望对输入的某些变化应用的过滤器数量。如果第一个卷积层以原始图像作为输入，那么在颜色斑块或不同方向的边缘出现时，沿深度维度的多个神经元可能会被激活。同一区域中的神经元集称为深度列。
- en: Stride
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步幅
- en: Stride specifies the policy of allocation of depth columns around the spatial
    dimension (width and height). It basically controls how the filter convolves around
    the input volume. Stride can be formally defined as the amount by which the filter
    shifts during the convolution. Ideally, the value of stride should be an integer
    and not a fraction. Conceptually, this amount helps in deciding how much of the
    input image information one wants to retain before proceeding to the next layer.
    The more the stride, the more information that will be retained for the next layer.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 步幅指定了在空间维度（宽度和高度）周围分配深度列的策略。它基本上控制了滤波器如何围绕输入体积进行卷积。步幅可以正式定义为滤波器在卷积过程中移动的量。理想情况下，步幅的值应该是整数，而非分数。从概念上讲，这个量有助于决定在进入下一层之前，我们希望保留多少输入图像信息。步幅越大，保留的信息就越多，供下一层使用。
- en: For example, when the stride is *1*, a new depth column is allocated to spatial
    positions, one spatial unit apart. This produces large output volumes due to heavily
    overlapping receptive fields in between the columns. On the other hand, if the
    value of stride is increased, there will be less overlapping among the receptive
    fields, which results in spatially smaller dimensional output volume.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当步幅为*1*时，一个新的深度列分配到空间位置，且相邻的空间单位之间有一个单位的间隔。由于列之间的感受野重叠较多，这会产生较大的输出体积。另一方面，如果步幅值增加，感受野之间的重叠会减少，从而导致输出体积的空间维度变小。
- en: 'We will take an example to simplify the concept a bit more. Let us imagine
    a *7*7* input volume and a *3*3* filter (we will ignore the third dimension for
    the sake of simplicity), with a stride of *1*. The output volume in this case
    would be of dimension *5*5*, as shown in *Figure 3.7*. However, this looks somewhat
    straightforward. Now, with stride *2*, keeping the other parameters the same,
    the output volume would have less dimensionality of the order *3*3*. In this case,
    the receptive field will shift by *2* units, and hence, the volume will shrink
    to a dimension of *3*3*:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过一个例子来进一步简化这个概念。假设我们有一个*7*7*的输入体积和一个*3*3*的滤波器（为了简便起见，我们忽略第三维度），步幅为*1*。在这种情况下，输出体积的维度将是*5*5*，如*图
    3.7*所示。然而，这看起来相对简单。现在，步幅为*2*，保持其他参数不变，输出体积的维度将会缩小为*3*3*。在这种情况下，感受野会移动*2*单位，因此，体积会缩小到*3*3*的维度：
- en: '![Stride](img/image_03_013.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![步幅](img/image_03_013.jpg)'
- en: 'Figure 3.7: Illustration of how the filter convolves around the input volume
    of 7x7 with stride 1 resulting in 5x5 output volume.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7：说明了滤波器如何以步幅 1 卷积 7x7 的输入体积，从而得到 5x5 的输出体积。
- en: 'This is illustrated in *Figure 3.8*. All these calculations are based on some
    formula mentioned in the next topic of this section. Now, if we want to increase
    the stride further to *3*, we will have difficulties with spacing and making sure
    the receptive field fits on the input volume. Ideally, a programmer will raise
    the value of the stride only if lesser overlapping of the receptive fields is
    required, and if they need smaller spatial dimensions:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这在*图 3.8*中有进一步说明。所有这些计算基于本节下一个主题中提到的一些公式。现在，如果我们希望进一步增加步幅到*3*，我们将会面临空间安排的困难，并且需要确保感受野能够适应输入体积。理想情况下，程序员只有在需要更少重叠的感受野并且需要更小的空间维度时，才会增加步幅的值：
- en: '![Stride](img/image_03_014.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![步幅](img/image_03_014.jpg)'
- en: 'Figure 3.8: Illustration of how the filter convolves around the input volume
    of 7x7 with stride 2 resulting in 3x3 output volume.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.8：说明了滤波器如何以步幅 2 卷积 7x7 的输入体积，从而得到 3x3 的输出体积。
- en: Zero-padding
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 零填充
- en: We've already got enough information to infer that, as we keep applying more
    convolution layers to the input volume, the size of the output volume decreases
    further. However, in some cases, we might want to preserve almost all the information
    about the original input volume so that we can also extract the low-level features.
    In such scenarios, we pad the input volume with zeroes around the borders of the
    input volume.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有足够的信息推断出，当我们继续向输入体积应用更多的卷积层时，输出体积的大小会进一步减小。然而，在某些情况下，我们可能希望保留关于原始输入体积的几乎所有信息，以便我们还能够提取低级特征。在这种情况下，我们会在输入体积的边缘周围使用零填充。
- en: This size of zero-padding is considered as a hyperparameter. It can be defined
    as a hyperparameter, which is directly used to control the spatial size of the
    output volume in scenarios where we want to exactly preserve the spatial size
    of input volume.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这种零填充的大小被视为超参数。它可以定义为超参数，直接用于控制输出体积的空间大小，在我们希望精确保持输入体积的空间大小时。
- en: 'For example, if we apply a *5*5*3* filter to a *32*32*3* input volume, the
    output volume will reduce to *28*28*3*. However, let''s say we want to use the
    same Convolutional layer, but need to keep the output volume to *32*32*3*. We
    will use a zero-padding of size *2* to this layer. This will give us an output
    volume of *36*36*3*, as shown in the following figure. Now, if we apply three
    convolution layers with a *5*5*3* filter, it will produce an output volume of
    *32*32*3*, hence maintaining the exact spatial size of the input volume. *Figure
    3.9* represents the pictorial views of the scenario:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们对一个*32*32*3*的输入体积应用一个*5*5*3*的滤波器，输出体积将减小为*28*28*3*。然而，假设我们希望使用相同的卷积层，但需要保持输出体积为*32*32*3*，我们将在该层使用大小为*2*的零填充。这样，我们将得到一个*36*36*3*的输出体积，如下图所示。如果我们应用三个卷积层，每个滤波器的大小为*5*5*3*，则输出体积将为*32*32*3*，因此保持输入体积的空间大小不变。*图3.9*展示了这种情况的图示：
- en: '![Zero-padding](img/image_03_015.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![零填充](img/image_03_015.jpg)'
- en: 'Figure 3.9: The input volume has a dimension of 32*32*3\. The two borders of
    zeros will generate an input volume of 36*36*3\. Further application of the Convolution
    layer, with three filters of size 5*5*3, having stride 1, will result in an output
    volume of 32*32*3.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9：输入体积的维度为32*32*3。两个零边界将生成一个36*36*3的输入体积。进一步应用卷积层，使用三个大小为5*5*3的滤波器，步幅为1，将得到一个32*32*3的输出体积。
- en: Mathematical formulation of hyperparameters
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 超参数的数学公式
- en: This part of the chapter will introduce an equation to calculate the spatial
    size of the output volume based on the hyperparameters that we have discussed
    so far. The equation is extremely useful to choose the hyperparameter for the
    CNN, as these are the deciding factors to 'fit' the neurons in the network. The
    spatial size of the output volume can be written as a function of the input volume
    size (*W*), the receptive field size, or the filter size of the Convolutional
    layer neurons(*K*), value of the applied stride(*S*), and the amount of zero-padding
    used (*P*) on the border.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 本章这一部分将介绍一个方程，用于根据我们到目前为止讨论的超参数计算输出体积的空间大小。这个方程对于选择CNN的超参数非常有用，因为这些是决定神经元“适配”网络的因素。输出体积的空间大小可以作为输入体积大小（*W*）、感受野大小或卷积层神经元的滤波器大小（*K*）、应用的步幅值（*S*）以及在边缘使用的零填充量（*P*）的函数来表示。
- en: 'The equation to compute the spatial size of output volume can be written as
    follows:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 计算输出体积空间大小的方程可以写成如下形式：
- en: '![Mathematical formulation of hyperparameters](img/image_03_016.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![超参数的数学公式](img/image_03_016.jpg)'
- en: 'Considering the examples given in *Figure 3.7* and *Figure 3.8*, where *W=7*,
    *K=3*, and with no padding, *P =0*. For stride *1*, we have *S=1*, and this will
    give the following:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑*图3.7*和*图3.8*中给出的例子，其中*W=7*，*K=3*，且没有填充，*P =0*。对于步幅*1*，我们有*S=1*，这将给出以下结果：
- en: '![Mathematical formulation of hyperparameters](img/image_03_017.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![超参数的数学公式](img/image_03_017.jpg)'
- en: 'Similarly for stride **2**, the equation will give a value of **2**:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，对于步幅**2**，该方程会给出**2**的值：
- en: '![Mathematical formulation of hyperparameters](img/image_03_018.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![超参数的数学公式](img/image_03_018.jpg)'
- en: 'Hence, as shown in *Figure 3.7*, we would get an output of a spatial size of
    **3**. However, with this configuration, when a stride of **3 **is applied, it
    will not fit across the input volume, as this equation will return a fractional
    value **2.333** for the output volume:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如*图3.7*所示，我们会得到一个空间大小为**3**的输出。然而，在这种配置下，当应用步幅**3**时，它将无法适应输入体积，因为这个方程会返回一个分数值**2.333**作为输出体积：
- en: '![Mathematical formulation of hyperparameters](img/image_03_019.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![超参数的数学公式](img/image_03_019.jpg)'
- en: This also signifies that the values of the hyperparameter have mutual constraints.
    The preceding example returns a fractional value, hence, the hyperparameters would
    be considered as invalid. However, we might resolve the issue by adding some zero-padding
    around the border.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这也意味着超参数的值之间存在相互约束。前面的例子返回了一个分数值，因此超参数会被视为无效。然而，我们可以通过在边缘添加一些零填充来解决这个问题。
- en: Note
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注
- en: The spatial arrangements of hyperparameters have mutual constraints.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数的空间排列具有相互约束关系。
- en: Effect of zero-padding
  id: totrans-124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 零填充的影响
- en: 'As mentioned in the zero-padding section, its main purpose is to preserve the
    information of input volume to the next layer. To ensure same spatial size of
    input and output volume, the conventional formula for zero-padding, with a stride,
    *S=1*, is as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如零填充部分所述，其主要目的是保持输入体积的信息传递到下一层。为了确保输入和输出体积具有相同的空间尺寸，传统的零填充公式，步幅*S=1*，如下所示：
- en: '![Effect of zero-padding](img/image_03_020.jpg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![零填充的影响](img/image_03_020.jpg)'
- en: 'Taking the example given in *Figure 3.9*, we can verify the authenticity of
    the formula. In the example, *W = 32*, *K=5*, and *S=1*. Therefore, to ensure
    the spatial output volume to be equal to 32, we choose the number of zero-padding
    as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 以*图3.9*中的示例为例，我们可以验证公式的正确性。在该示例中，*W = 32*，*K=5*，*S=1*。因此，为了确保空间输出体积等于32，我们选择的零填充数量如下：
- en: '![Effect of zero-padding](img/image_03_021.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![零填充的影响](img/image_03_021.jpg)'
- en: 'So, with *P=2*, the spatial size of the output volume is given as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，若*P=2*，输出体积的空间尺寸如下所示：
- en: '![Effect of zero-padding](img/image_03_022.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![零填充的影响](img/image_03_022.jpg)'
- en: So, this equation worked out well to preserve the same spatial dimension for
    the input volume and output volume.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个方程式很好地保持了输入体积和输出体积的空间尺寸相同。
- en: ReLU (Rectified Linear Units) layers
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReLU（修正线性单元）层
- en: In the convolution layer, the system basically computes the linear operations
    by doing element-wise multiplication and summations. Deep convolution usually
    performs the convolution operations followed by a non-linear operation after each
    layer. This is essential, because cascading linear operations produce another
    linear system. Adding non-linearity in between the layers corroborates a more
    expressive nature of the model than a linear model.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积层中，系统基本上通过逐元素的乘法和求和来计算线性操作。深度卷积通常在每层之后执行卷积操作，并在每层之后进行非线性操作。这是必需的，因为级联的线性操作会产生另一个线性系统。层与层之间添加非线性增强了模型的表达能力，优于线性模型。
- en: Therefore, after each convolution layer, an activation layer is applied on the
    current output. So, the main objective of this activation layer is to introduce
    some non-linearity to the system. Modern CNNs use **Rectified Linear Unit** (**ReLu**)
    as the activation function.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在每个卷积层之后，会对当前输出应用一个激活层。因此，该激活层的主要目标是为系统引入一些非线性。现代卷积神经网络（CNN）使用**修正线性单元**（**ReLu**）作为激活函数。
- en: 'In artificial neural networks, the activation function, the rectifier, is defined
    as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工神经网络中，激活函数——整流器，定义如下：
- en: '![ReLU (Rectified Linear Units) layers](img/image_03_023.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![ReLU（修正线性单元）层](img/image_03_023.jpg)'
- en: where *x* is the input to a neuron.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*x*是神经元的输入。
- en: A unit operating the rectifier is termed as ReLU. Earlier, many non-linear functions
    such as *tan h*, sigmoid, and the like were used in the network, but in the last
    few years, researchers have identified that ReLU layers work much better, because
    they help the network to train a lot faster, without compromising the accuracy
    of the outcome. A significant improvement in the computational efficiency is a
    major factor for this.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 一个操作整流器的单元称为ReLU。早期，许多非线性函数如*tan h*、sigmoid等被用于网络中，但近年来，研究人员发现ReLU层效果更好，因为它们帮助网络更快地训练，同时不影响结果的准确性。计算效率的显著提升是其中的一个重要因素。
- en: Furthermore, this layer enhances the non-linear properties of the model and
    other overall networks without having any impact on the receptive fields of the
    Convolutional layer.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该层增强了模型和其他整体网络的非线性特性，而不会对卷积层的感受野产生任何影响。
- en: 'Recently, in 2013, Mass et al. [94] introduced a new version of non-linearity,
    termed as leaky-ReLU. Leaky-ReLU can be defined as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，在2013年，Mass等人[94]提出了一种新的非线性版本，称为leaky-ReLU。Leaky-ReLU定义如下：
- en: '![ReLU (Rectified Linear Units) layers](img/image_03_024.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![ReLU（修正线性单元）层](img/image_03_024.jpg)'
- en: where *Î±* is a predetermined parameter. Later, in 2015, He et al [95] updated
    this equation by suggesting that the parameter Î± can also be trained, which leads
    to a much-improved model.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*Î±*是预设参数。后来，在2015年，He等人[95]更新了该方程，提出参数Î±也可以进行训练，从而大幅改进了模型。
- en: Advantages of ReLU over the sigmoid function
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ReLU相较于sigmoid函数的优势
- en: 'ReLU helps to alleviate the vanishing gradient problem, which is explained
    in detail in [Chapter 1](ch01.html "Chapter 1. Introduction to Deep Learning")
    , *Introduction to Deep Learning*. ReLU applies the aforementioned function *f(x)*
    to all the values of the input volume, and transforms all the negative activations
    to **0**. For max function, the gradient is defined as follows:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ReLU 有助于缓解梯度消失问题，这在[第 1 章](ch01.html "第 1 章 深度学习简介") *深度学习简介*中有详细解释。ReLU 将前述函数
    *f(x)* 应用到输入值的所有数据，并将所有负激活值转换为**0**。对于最大值函数，梯度定义如下：
- en: '![Advantages of ReLU over the sigmoid function](img/image_03_025.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![ReLU 优势相对于 Sigmoid 函数](img/image_03_025.jpg)'
- en: However, for the Sigmoid function, the gradient tends to vanish as we increase
    or decrease the value of *x*.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于 Sigmoid 函数，当我们增加或减少 *x* 的值时，梯度往往会消失。
- en: 'The Sigmoid function is given as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid 函数如下所示：
- en: '![Advantages of ReLU over the sigmoid function](img/image_03_026.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![ReLU 优势相对于 Sigmoid 函数](img/image_03_026.jpg)'
- en: "The Sigmoid function has a range of [*0, 1*], whereas the ReLU function has\
    \ the range [*0, ![Advantages of ReLU over the sigmoid function](img/Infinity.jpg)\
    \ \x88\x9E*]. Therefore, the Sigmoid function is applied to model the probability,\
    \ while ReLU can be used to model all the positive numbers."
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: "Sigmoid 函数的值域为[*0, 1*]，而 ReLU 函数的值域为[*0, ![ReLU 优势相对于 Sigmoid 函数](img/Infinity.jpg)\
    \ \x88\x9E*]。因此，Sigmoid 函数通常用于建模概率，而 ReLU 可以用来建模所有正数。"
- en: Pooling layer
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 池化层
- en: This layer is the third stage of a CNN. After applying some Rectified Linear
    Units later, the programmer might choose to apply a Pooling layer. The layer can
    also be referred to as a down-sampling layer.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 该层是卷积神经网络（CNN）的第三阶段。经过若干次线性整流单元（ReLU）后，程序员可能会选择应用池化层。该层也可以被称为降采样层。
- en: 'The pooling function is basically used to further modify the output of the
    layer. The primary function of the layer is to replace the output of the network
    at a certain location with a summarized statistics of the neighboring outputs.
    There are multiple options for this layer, Max-pooling being the most popular
    one. Max pooling operation [93] operates within a rectangular neighborhood, and
    reports the maximum output from it. Max-pooling basically takes a filter (generally
    of size *2x2*) and stride of the same length, that is, **2**. The filter is then
    applied to the input volume, and it outputs the maximum number in every region
    where the filter convolves around. *Figure 3.10* shows a representation of the
    same thing. Other popular options for Pooling layers are the average of an *L2*
    normal of a rectangular neighborhood, average of a rectangular neighborhood or
    a weighted average, which is based on the distance from the central pixel:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 池化函数基本上用于进一步修改层的输出。该层的主要功能是用邻域输出的总结统计信息替换网络中某一位置的输出。该层有多种选项，其中最大池化（Max-pooling）是最常用的。最大池化操作[93]在矩形邻域内进行，并报告其中的最大输出。最大池化基本上使用一个大小为*2x2*的滤波器和相同长度的步幅，即**2**。然后，将该滤波器应用于输入体积，在滤波器卷积经过的每个区域输出最大值。*图
    3.10* 展示了相同内容的表示。池化层的其他常见选项包括矩形邻域的*L2* 正常化的平均值、矩形邻域的平均值或基于与中心像素的距离的加权平均。
- en: '![Pooling layer](img/B05883_03_10.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![池化层](img/B05883_03_10.jpg)'
- en: 'Figure 3.10: Example of Max-pool with a 2*2 filter and stride 2\. Image sourced
    from Wikipedia.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.10：带有 2*2 滤波器和步幅为 2 的最大池化示例。图像来源于维基百科。
- en: Note
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Invariance to local translation is extremely beneficial if we are interested
    in the neighboring features, rather than the exact position of the feature.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们关注的是邻域特征，而不是特征的精确位置，那么局部平移不变性是极为有益的。
- en: Where is it useful, and where is it not?
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 它在哪里有用，在哪里没有用？
- en: The intuitive reason behind the Pooling layer is that once some specific feature
    of the original input volume is known, its exact location becomes trivial as compared
    to its location relative to the other features. With the help of pooling, the
    representation becomes almost invariant to small translations of the input. Invariance
    to translation signifies that for a small amount of translation on the input,
    the values of most of the pooled output do not vary significantly.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层的直观原因是，一旦知道了原始输入体积的某个特定特征，其精确位置相较于与其他特征的相对位置变得无关紧要。借助池化，表示几乎对输入的微小平移保持不变。平移不变性意味着，对于输入的微小平移，大多数池化输出的值不会发生显著变化。
- en: Invariance to local translation is extremely beneficial if we are interested
    in the neighboring features rather than the exact position of the feature. However,
    while dealing with computer vision tasks, it is required to be careful in the
    use of Pooling layer. Although pooling extensively helps in the reduction of complexity
    of the model, it might end up losing the location sensitivity of the model.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 对局部平移的不变性在我们更关注邻近特征而非特征的准确位置时极为有益。然而，在处理计算机视觉任务时，使用池化层需要小心。虽然池化有助于大幅降低模型的复杂性，但它可能最终会丧失模型的位置敏感性。
- en: Let us take an example of image processing, which involves identifying a box
    in an image. Pooling layer in this case will help if we simply target to determine
    the existence of the box in the image. However, if the problem statement is more
    concerned with locating the exact position of the box, we will have to be careful
    enough while using the Pooling layer. As another example, let us say we are working
    on a language model, and are interested in identifying the contextual similarity
    between two words. In this case, the use of Pooling layer is not advisable, as
    it will lose out on some valuable feature information.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以图像处理为例，涉及到识别图像中的一个框。池化层在这种情况下会有帮助，如果我们只是简单地想要确定图像中是否存在这个框。然而，如果问题陈述更关心框的准确位置，我们在使用池化层时需要特别小心。再举一个例子，假设我们正在处理一个语言模型，且关心识别两个单词之间的语境相似性。在这种情况下，不建议使用池化层，因为它会丧失一些有价值的特征信息。
- en: Therefore, it can be concluded that Pooling layer is basically used for reducing
    the computational complexity of the model. The Pooling layer is more like an averaging
    process, where we are more interested in a group of neighboring features. The
    layer can be applied in scenarios where we can afford to let go of some of the
    localized information.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，可以得出结论，池化层基本上用于减少模型的计算复杂性。池化层更像是一个平均过程，我们更关注一组邻近的特征。该层可以应用于我们可以舍弃一些局部信息的场景中。
- en: Fully connected layer
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全连接层
- en: The fully connected layer is the final layer of a CNN. The input volume for
    this layer comes from the output of the preceding Convolutional layer, ReLU, or
    Pooling layer. The fully connected layer takes this input and outputs an *N* dimensional
    vector, where *N* is the number of different classes present in the initial input
    datasets. The basic idea on which a fully connected layer works is that it works
    on the output received from the preceding layer, and identifies the specific feature
    that mostly correlates to a particular class. For example, if the model is predicting
    whether an image contains a cat or bird, it will have high values in the activation
    maps, which will represent some high-level features such as four legs or wings,
    respectively.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 全连接层是卷积神经网络（CNN）的最终层。该层的输入来自前一层卷积层、ReLU层或池化层的输出。全连接层接收该输入并输出一个*N*维向量，其中*N*是初始输入数据集中的不同类别数量。全连接层的基本工作原理是，它基于从前一层接收到的输出，识别与特定类别最相关的特征。例如，如果模型正在预测一张图片中是否包含猫或鸟，它会在激活图中具有较高的值，这些值代表一些高级特征，如四条腿或翅膀。
- en: Distributed deep CNN
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式深度CNN
- en: This section of the chapter will introduce some extremely aggressive deep CNN architecture,
    associated challenges for these networks, and the need of much larger distributed
    computing to overcome this. This section will explain how Hadoop and its YARN
    can provide a sufficient solution for this problem.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 本章这一部分将介绍一些极具挑战性的深度CNN架构，相关的网络挑战，以及为克服这些挑战而需要的大规模分布式计算。此部分还将解释Hadoop及其YARN如何为这个问题提供足够的解决方案。
- en: Most popular aggressive deep neural networks and their configurations
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最流行的激进深度神经网络及其配置
- en: 'CNNs have shown stunning results in image recognition in recent years. However,
    unfortunately, they are extremely expensive to train. In the case of a sequential
    training process, the convolution operation takes around 95% of the total running
    time. With big datasets, even with low-scale distributed training, the training
    process takes many days to complete. The award winning CNN, AlexNet with ImageNet
    in 2012, took nearly an entire week to train on with two GTX 580 3 GB GPUs. The
    following table displays few of the most popular distributed deep CNNs with their
    configuration and corresponding time taken for the training process to complete:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，CNN在图像识别方面展示了惊人的成果。然而，不幸的是，它们的训练成本非常高。以顺序训练过程为例，卷积操作大约占据了总运行时间的95%。在大规模数据集的情况下，即使是低规模的分布式训练，训练过程也需要几天时间才能完成。2012年获得大奖的CNN，AlexNet，使用两个GTX
    580 3 GB GPU，在ImageNet数据集上进行训练，几乎花费了一整周的时间。以下表格列出了几种最受欢迎的分布式深度CNN，它们的配置和训练过程所花费的时间：
- en: '| **Models** | **Computing power** | **Datasets** | **Number of depth** | **Time
    taken for the training process** |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **计算能力** | **数据集** | **层数** | **训练过程所需时间** |'
- en: '| AlexNet | Two NVIDIA GTX 580 3 GB GPUs | Trained the network on ImageNet
    data, which contained over 15 million high-resolution images from a total of over
    22,000 categories. | eight layers | Five to six days. |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| AlexNet | 两个NVIDIA GTX 580 3 GB GPU | 在ImageNet数据集上训练，该数据集包含来自超过22,000个类别的1500万张高分辨率图像。
    | 八层 | 五到六天。 |'
- en: '| ZFNet [97] | GTX 580 GPU | 1.3 million images, spread over 1000 different
    classes. | eight layers | Twelve days. |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| ZFNet [97] | GTX 580 GPU | 130万张图像，覆盖1000个不同的类别。 | 八层 | 十二天。 |'
- en: '| VGG Net [98] | 4 Nvidia Titan Black GPUs | The dataset includes images of
    1000 classes, and is split into three sets: training (1.3 M images), validation
    (50 K images), and testing (100 K images with held out class labels). | 19 layers
    | Two to three weeks. |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| VGG Net [98] | 4个Nvidia Titan Black GPU | 数据集包含1000个类别的图像，分为三部分：训练集（130万图像）、验证集（5万图像）和测试集（10万图像，部分类别标签被排除）。
    | 19层 | 两到三周。 |'
- en: '| GoogLeNet [99] | A few high-end GPUs | 1.2 millionimages for training. |
    The network is 22 layers deep when counting only layers with parameters (or 27
    layers if we also count pooling). The overall number of layers (independent building
    blocks) used for the construction of the network is about 100. | Within a week.
    |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| GoogLeNet [99] | 一些高端GPU | 120万张训练图像。 | 网络深度为22层（仅计算具有参数的层，若包括池化层则为27层）。该网络的总层数（独立构建模块）大约为100层。
    | 一周内。 |'
- en: '| Microsoft ResNet [100] | 8 GPU machine | Trained on the 1.28 million training
    images, and evaluated on the 50k validation images. | 152 layers. | Two to three
    weeks. |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| Microsoft ResNet [100] | 8 GPU机器 | 在128万张训练图像上进行训练，并在5万张验证图像上进行评估。 | 152层。
    | 两到三周。 |'
- en: Training time - major challenges associated with deep neural networks
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练时间 - 深度神经网络面临的主要挑战
- en: From the preceding table, it can be surely inferred that there have been loads
    of efforts made by researchers to increase the accuracy of the outcome. One key
    point that comes out from the table is that the numbers of layers have been one
    of the major criteria to improve the accuracy. Microsoft's Resnet uses a neural
    network, as deep as 152 layers, which turns to be an extremely aggressive deep
    neural network. This architecture has set many new records in 2015 in classification,
    localization, and detection through the deep CNN. Apart from this, ResNet has
    also won the ILSVRC 2015 with an incredible improvement in the error rate of only
    3.6%.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的表格可以明确推断出，研究人员在提高结果准确性方面付出了大量努力。表格中突出的一点是，网络层数已成为提高准确性的主要标准之一。微软的ResNet使用了一个深度达152层的神经网络，这成为了一个极具攻击性的深度神经网络架构。该架构在2015年通过深度卷积神经网络（CNN）在分类、定位和检测等领域创下了许多新纪录。此外，ResNet还凭借惊人的错误率改进，仅为3.6%，赢得了2015年ILSVRC（ImageNet
    Large Scale Visual Recognition Challenge）。
- en: Although deep convolutional networks are almost about to reach the expected
    mark of accuracy, the major concern in almost all these deep CNNs is the rightmost
    column of the table. Hence, it shows that the current challenge for training deep
    CNNs is to build a large-scale distributed framework to parallelize the training
    across many CPUs and GPUs over a fast interconnected network.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度卷积神经网络几乎达到了预期的准确率，几乎所有这些深度CNN的主要问题仍然是表格中最右侧的那一列。因此，这表明当前训练深度CNN的挑战在于构建一个大规模的分布式框架，以便通过快速互联的网络将训练过程并行化，分配到多个CPU和GPU上。
- en: Hadoop for deep CNNs
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hadoop用于深度CNN
- en: In this section, we will explain how Hadoop can be used to distribute the deep
    models at a large scale for faster processing.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将解释如何使用Hadoop在大规模上分发深度模型以加速处理。
- en: 'The running times of CNNs can be divided into two major categories:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: CNN的运行时间可以分为两大类：
- en: All the Convolutional layers present in the network consume around 90-95% of
    the computation. They use approximately 5% of the parameters, and have large representations.
    [101]
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络中所有的卷积层消耗了大约90-95%的计算。它们使用了大约5%的参数，并且有较大的表示形式。[101]
- en: The rest of the computation, around 5-10%, is taken by the fully connected layers.
    They use almost 95% of the parameters, and have small representations.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 剩余的计算大约占5-10%，由全连接层处理。它们使用了大约95%的参数，并且表示形式较小。
- en: Alex Krizhevsky in [101] has proposed an algorithm for training of CNN using
    distributed architecture. In a traditional CNN, the convolution operation itself
    consumes nearly the entire running time of the whole process; hence, data parallelism
    should be used for faster training. However, for a fully connected layer, it is
    advisable to use the model parallelism approach. We'll explain the algorithm using
    Hadoop and its YARN in this section of the chapter.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Alex Krizhevsky在[101]中提出了一种使用分布式架构训练卷积神经网络（CNN）的算法。在传统的CNN中，卷积操作本身几乎占用了整个过程的全部运行时间；因此，应该使用数据并行性来加速训练。然而，对于全连接层，建议使用模型并行性的方法。本节将通过Hadoop及其YARN来解释该算法。
- en: 'In Hadoop, the distributed system workers sit on each of the blocks of HDFS,
    and process the data synchronously in parallel. We will use a small batch size
    of 1024 numbers of examples from the raw input image, which will be split into
    N multiple blocks of **Hadoop Distributed File System** (**HDFS**). So, total
    *N* workers will be working for each small batch of data. The block size of HDFS
    would be kept as size *K*. Now, what should be the size of *K*? Although, a small
    size of *K* will increase the number of blocks and help to make the training even
    faster, a large number of *N* will also eventually increase the volume of metadata
    that resides in the NameNode. One major drawback in this case, is **Single Point
    of Failure** (**SPOF**) for Hadoop [81], which is more prone to smaller size of
    main memory for NameNode. However, with a bigger value of *K*, we will get a small
    number of blocks of HDFS, and hence, the number of workers working in parallel
    will be lesser in number. This will again make the training process slower. So,
    a better approach to choose the size of *K* will primarily depend on the following
    three factors:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在Hadoop中，分布式系统的工作节点位于每个HDFS块上，并同步并行处理数据。我们将使用一个小批量大小，1024个来自原始输入图像的示例，这些示例将被拆分为N个多个**Hadoop分布式文件系统**（**HDFS**）的块。因此，总共有*N*个工作节点将为每个小批量数据进行工作。HDFS的块大小将保持为大小*K*。那么，*K*的大小应该是多少呢？虽然较小的*K*将增加块的数量，并有助于加快训练，但较大的*N*也最终会增加在NameNode中存储的元数据量。在这种情况下，一个主要的缺点是Hadoop的**单点故障**（**SPOF**）问题，且更容易出现NameNode的主内存较小。然而，使用较大的*K*，我们将得到较少数量的HDFS块，因此，平行工作的节点数量将减少。这又会使训练过程变慢。因此，选择*K*的最佳方法将主要取决于以下三个因素：
- en: The availability of the primary memory's size of your NameNode.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的NameNode的主内存大小可用性。
- en: The size of the input batch and the complexity of operations performed on each
    block of data.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入批量的大小以及对每个数据块执行的操作的复杂性。
- en: How important or valuable your intermediate outcome of the data is. Based on
    these criteria, we can set the replication factor. However, the higher the replication
    factor, the higher the load of the NameNode.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的中间结果有多重要或有价值。根据这些标准，我们可以设置复制因子。然而，复制因子越高，NameNode的负载就越大。
- en: The blocks of HDFS are distributed across all the DataNodes of Hadoop where
    YARN will operate directly on them in parallel.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: HDFS的块分布在Hadoop的所有DataNode上，YARN将在这些DataNode上并行运行。
- en: 'The steps for distributed training of the Convolutional layer are as follows:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 分布式训练卷积层的步骤如下：
- en: Each of the *N* blocks is given a different small data batch of 1024 examples
    from the raw input image.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个*N*块都分配了来自原始输入图像的不同小数据批量，共1024个示例。
- en: The same size of filter and stride is applied on each of the N numbers of blocks,
    which results in individual spatial output based on the values of the inputs.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相同大小的滤波器和步幅应用于每个N个块，这将基于输入的值生成单独的空间输出。
- en: ReLU is applied on all of these, synchronously, in parallel to get some non-linearity
    in the outcome.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ReLU会在所有这些上并行、同步地应用，以在结果中引入一定的非线性。
- en: Max-pooling, or any other down-sampling algorithm, if desired, is applied on
    these separate chunks of data based on the necessity of the outcome.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据结果的需求，可以在这些独立的数据块上应用最大池化或任何其他下采样算法。
- en: The outputs (transformed parameters) for each iteration of the *N* blocks are
    sent back to the master-node called Resource Manager, where their parameters are
    averaged. The newly updated parameter is sent back to each of the *N* blocks to
    perform the actions again.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每次迭代的输出（转化后的参数）会被发送回名为资源管理器的主节点，在那里它们的参数会被平均。更新后的新参数会被发送回每个*N*块，再次执行相应的操作。
- en: Steps 2 to 5 are repeated for a predefined number of epochs.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 步骤2到步骤5会为预定的周期数重复执行。
- en: For a Fully-connected layer, one of the *N* number of workers working on any
    of the *N* blocks of data for a small batch of input image will send the last-stage
    convolutional activities to all other (*N-1*) numbers of workers. The workers
    will then perform the fully-connected operation on this batch of 1024 examples,
    then initiate to back-propagate the gradients for these 1024 examples. The next
    worker, in parallel to this operation, will then send its last-stage Convolutional
    layer activities to the other workers similar to the earlier situation. The workers
    will again work on the fully-connected activities for the second batch of 1024
    examples. The process will iterate until we get the outcome with the desired minimal
    error.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 对于全连接层，任何一个正在处理*N*个数据块中一个小批量输入图像的*N*个工作节点中的一个，会将最后一阶段的卷积活动发送给其他所有的(*N-1*)个工作节点。然后，工作节点会对这批1024个样本执行全连接操作，随后开始反向传播这些1024个样本的梯度。接下来的工作节点与此操作并行，会将其最后一阶段的卷积层活动发送给其他工作节点，类似于之前的情况。工作节点将再次对第二批1024个样本执行全连接活动。此过程会迭代，直到我们得到具有所需最小误差的结果。
- en: In this method, the workers broadcast their last-stage Convolutional layer's
    information to all other workers. The main benefit of this approach is that a
    large proportion (*(N-1)/N*) of the communication can be suppressed, and it can
    be run in parallel with the calculation of the Fully-connected layer. The approach
    is extremely advantageous in terms of communication of the network.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，工作节点将它们的最后一阶段卷积层信息广播给所有其他工作节点。这种方法的主要优势是，通信的大部分部分（*(N-1)/N*）可以被抑制，并且可以与全连接层的计算并行执行。这种方法在网络通信方面具有极大的优势。
- en: Therefore, it is very clear that Hadoop can be highly beneficial for providing
    a distributed environment for a CNN with the help of HDFS and Hadoop YARN.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，很明显，Hadoop在HDFS和Hadoop YARN的帮助下，对于提供分布式环境给CNN具有极大的好处。
- en: So, now that we are familiar with the approach of distributing the model in
    parallel with Hadoop, the next part of the section will discuss the coding part
    that each of the workers will be operating on each block of HDFS.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经熟悉了通过Hadoop并行分布模型的方法，本节的下一部分将讨论每个工作节点在HDFS的每个数据块上进行操作的编码部分。
- en: Convolutional layer using Deeplearning4j
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Deeplearning4j的卷积层
- en: This section of the chapter will provide the basic idea on how to write the
    code for CNN using Deeplearning4j. You'll be able to learn the syntax for using
    the various hyperparameters mentioned in this chapter.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 本章这一部分将提供如何使用Deeplearning4j编写CNN代码的基本思路。你将能够学习本章中提到的各种超参数的语法。
- en: 'To implement CNN using Deeplearning4j, the whole idea can be split into three
    core phases: loading data or preparation of the data, network configuration, and
    training and evaluation of the model.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Deeplearning4j实现CNN的整个思路可以分为三个核心阶段：加载数据或数据准备、网络配置以及模型的训练与评估。
- en: Loading data
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据
- en: "For CNNs, generally, we only work on the image data to train the model. In\
    \ Deeplearning4j, the images can be read using `ImageRecordReader`. The following\
    \ code snippet shows how to load *16Ã\x9716* color images for the model:"
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 对于CNN，一般来说，我们只处理图像数据来训练模型。在Deeplearning4j中，图像可以通过`ImageRecordReader`读取。以下代码片段展示了如何加载*16×16*的彩色图像进行模型训练：
- en: '[PRE0]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After that, using `CSVRecordReader`, we can load all the image labels from
    the input CSV files, as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，使用`CSVRecordReader`，我们可以从输入的CSV文件中加载所有的图像标签，方法如下：
- en: '[PRE1]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To combine both the images and labels data, we can use `ComposableRecordReader`.
    `ComposableRecordReader` can also be beneficial in cases where we need to merge
    data from multiple sources:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将图像和标签数据结合在一起，我们可以使用`ComposableRecordReader`。`ComposableRecordReader`在需要合并来自多个源的数据时也非常有用：
- en: '[PRE2]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Similarly, instead of imageset, in some cases, if someone needs to load MNIST
    datasets into the model; for that, we can use the following part. This example
    uses a random number seed of `12345`:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，在某些情况下，如果需要将MNIST数据集加载到模型中，而不是使用imageset，我们可以使用以下部分。此示例使用了一个随机数种子`12345`：
- en: '[PRE3]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Model configuration
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型配置
- en: 'The next part of the operation is to configure the CNN. Deeplearning4j provides
    a simple builder to define the deep neural network layer by layer, setting the
    different desired hyperparameters:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 操作的下一部分是配置CNN。Deeplearning4j提供了一个简单的构建器，可以逐层定义深度神经网络，设置不同的超参数：
- en: '[PRE4]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The first layer, Convolutional layer, can be called using the `ConvolutionLayer.Builder`
    method. The `.build()` function is used to build the layer. `.stride()` is used
    to set the amount of stride for this Convolutional layer:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个层次，卷积层，可以使用`ConvolutionLayer.Builder`方法来调用。`.build()`函数用于构建该层。`.stride()`用于设置该卷积层的步幅大小：
- en: '[PRE5]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`nIn` and `nOut` signify the depth. `nIn` here is `nChannels`, and `nOut` is
    the number of filters to be applied for the convolution:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`nIn`和`nOut`表示深度。这里的`nIn`是`nChannels`，`nOut`是应用于卷积的过滤器数量：'
- en: '[PRE6]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To add the identity function as the activation function, we will define it
    in this way:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将恒等函数添加为激活函数，我们将以这种方式定义它：
- en: '[PRE7]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To add a Pooling layer of type Max-pooling, we will call the `SubsamplingLayer.Builder()`
    method after the first layer:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 为了添加一个类型为最大池化的Pooling层，我们将在第一个层之后调用`SubsamplingLayer.Builder()`方法：
- en: '[PRE8]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The **Rectifier Linear Unit** (**ReLU**) layer can be added by calling new
    `DenseLayer.Builder().activation("relu")`:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '**修正线性单元**（**ReLU**）层可以通过调用新的`DenseLayer.Builder().activation("relu")`来添加：'
- en: '[PRE9]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The model can be initialized by calling the `init()` method as follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过调用`init()`方法来初始化模型，如下所示：
- en: '[PRE10]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Training and evaluation
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练与评估
- en: 'As mentioned in the earlier section, for the training part, we need to divide
    the whole big dataset into a number of batches. The model will then work on those
    batches one by one in Hadoop. Let''s say we divide the dataset into 5,000 batches,
    each batch of size 1024 examples. The 1024 examples will then split into multiple
    numbers of blocks where the workers will work in parallel. The split operation
    of the big dataset is done using the `RecordReaderDataSetIterator()` method. Let''s
    first initialize the parameters needed to call the method as follows:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面所述，在训练阶段，我们需要将整个大数据集分成多个批次。然后，模型将在Hadoop中逐个处理这些批次。假设我们将数据集分成5000个批次，每个批次包含1024个示例。1024个示例将被拆分成多个块，工人将在并行处理。这种大数据集的拆分操作是通过`RecordReaderDataSetIterator()`方法完成的。让我们首先初始化需要调用该方法的参数，如下所示：
- en: '[PRE11]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let the total number of classes in the image be `10`:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 假设图像中的类别总数为`10`：
- en: '[PRE12]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, as we have set the number of parameters for `RecordReaderDataSetIterator()`,
    we can call the method to set up the training platform:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，既然我们已经为`RecordReaderDataSetIterator()`设置了参数数量，我们可以调用该方法来设置训练平台：
- en: '[PRE13]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In the training phase, we can randomly split the batch into train and test
    datasets. If we want 70 samples for the training set and the rest 30 for the test
    set, we can set this configuration by using the following:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练阶段，我们可以将批次随机拆分为训练集和测试集。如果我们希望70个样本用于训练集，剩余的30个样本用于测试集，我们可以通过以下配置来设置：
- en: '[PRE14]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'When the model is fully trained, for each batch, the test data can be saved
    so as to validate the model. Hence, by defining only one object of the `Evaluation`
    class, we will be able to collect the statistics of the entire dataset:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型完全训练完成后，对于每个批次，可以保存测试数据以验证模型。因此，通过定义一个`Evaluation`类的对象，我们将能够收集整个数据集的统计信息：
- en: '[PRE15]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The model is now completely ready to be trained. This can be done by calling
    the `fit()` method as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，模型已经完全准备好进行训练。这可以通过调用`fit()`方法来完成，如下所示：
- en: '[PRE16]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Summary
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: CNNs, although not a new concept, has gained immense popularity in the last
    half a decade. The network primarily finds its application in the field of vision.
    The last few years have seen some major research on CNN by various technological
    companies such as Google, Microsoft, Apple, and the like, and also from various
    eminent researchers. Starting from the beginning, this chapter talked about the
    concept of convolution, which is the backbone of this type of network. Going forward,
    the chapter introduced the various layers of this network. Then it provided in-depth
    explanations for every associated layer of the deep CNN. After that, the various
    hyperparameters and their relations with the network were explained, both theoretically
    and mathematically. Later, the chapter talked about the approach of how to distribute
    the deep CNN across various machines with the help of Hadoop and its YARN. The
    last part discussed how to implement this network using Deeplearning4j for every
    worker working on each block of Hadoop.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: CNNs，虽然不是一个新概念，但在过去的半个世纪获得了巨大的流行。该网络主要应用于视觉领域。过去几年中，谷歌、微软、苹果等技术公司以及各大著名研究者对
    CNN 进行了重大研究。本章从开始就讨论了卷积的概念，这是这种类型网络的核心。继而介绍了这个网络的各种层。接着，为深度 CNN 的每一层提供了深入的解释。之后，理论上和数学上解释了各种超参数及其与网络的关系。随后，本章讨论了如何借助
    Hadoop 及其 YARN 将深度 CNN 分布到各个机器上的方法。最后部分讨论了如何利用 Deeplearning4j 在每个处理 Hadoop 每个块的工作人员上实现此网络。
- en: In the next chapter, we will discuss another popular deep neural network called
    recurrent neural network. Recurrent neural network has recently gained immense
    popularity mainly for its ability to model the sequences of variable length. Till
    now, this network is successfully implemented in different problems such as language
    modeling, handwriting recognition, speech recognition, and so on.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论另一种流行的深度神经网络，称为循环神经网络。近年来，循环神经网络因其能够建模可变长度序列而广受欢迎。到目前为止，这种网络已成功应用于语言建模、手写识别、语音识别等不同问题。
