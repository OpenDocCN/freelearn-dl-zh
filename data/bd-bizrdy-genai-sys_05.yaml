- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Adding Multimodal, Multifunctional Reasoning with Chain of Thought
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加基于思维链的多模态、多功能推理
- en: At this point in our journey, we’ve built the core framework of our GenAISys.
    We have a responsive, small-scale, ChatGPT-like interactive interface. We expanded
    beyond typical one-to-one copilot interactions, creating a collaborative multi-user
    environment where an AI agent actively participates in discussions. We further
    extended this human-centric design by integrating RAG, giving our AI agent access
    to a Pinecone index capable of managing both instruction scenarios and data. Finally,
    we built a flexible GenAISys that allows users to activate or deactivate the AI
    agent during collaborative meetings. In short, we have created a human-centric
    AI system that augments human teams rather than attempting to replace people with
    machine intelligence.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们旅程的这个阶段，我们已经构建了GenAISys的核心框架。我们有一个响应式的、小规模的、类似ChatGPT的交互界面。我们超越了典型的点对点协同助手交互，创造了一个多用户协作环境，其中人工智能代理积极参与讨论。我们通过集成RAG进一步扩展了以人为中心的设计，使我们的AI代理能够访问一个能够管理指令场景和数据的Pinecone索引。最后，我们构建了一个灵活的GenAISys，允许用户在协作会议期间激活或停用AI代理。简而言之，我们创造了一个以人为中心的AI系统，它增强而不是试图用机器智能取代人类团队。
- en: However, despite its human-centric nature, the exponential growth of global
    transcontinental supply chains and the vast daily flow of goods, services, and
    digital content require significant levels of automation. For example, we cannot
    realistically expect social media platforms such as Meta, X, or LinkedIn to employ
    millions of people to moderate billions of messages—including images, audio, and
    video files—every day. Similarly, companies such as Amazon cannot manage millions
    of online transactions and physical deliveries exclusively through human efforts.
    Automation is essential to augment human decision-making and reasoning, particularly
    for critical tasks at scale. Therefore, in this chapter, we will extend the GenAISys
    framework by adding multimodal capabilities and reasoning functionalities. To
    address the challenges of cross-domain automation, we will implement image generation
    and analysis and begin integrating machine learning. Our objective is to build
    a new agentic AI layer into our GenAISys.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管其以人为中心的特点，全球跨大陆供应链的指数级增长以及大量日常商品、服务和数字内容的流动，需要显著程度的自动化。例如，我们无法合理地期望像Meta、X或LinkedIn这样的社交媒体平台每天雇佣数百万人来审核数十亿条消息——包括图像、音频和视频文件。同样，像亚马逊这样的公司不能仅通过人力来管理数百万在线交易和实物配送。自动化对于增强人类决策和推理至关重要，尤其是在大规模的关键任务中。因此，在本章中，我们将通过添加多模态能力和推理功能来扩展GenAISys框架。为了解决跨领域自动化的挑战，我们将实施图像生成和分析，并开始集成机器学习。我们的目标是构建一个新的代理人工智能层到我们的GenAISys中。
- en: We will begin by outlining features that we are integrating into our existing
    GenAISys framework. Given the broadening scope of our GenAISys, we will introduce
    **chain-of-thought** (**CoT**) reasoning processes to orchestrate and manage complex
    tasks effectively. We will then incorporate computer vision capabilities. This
    includes building an image generation function with DALL-E and an image analysis
    function using GPT-4o. Next, we will add audio functionality for those who prefer
    voice interactions—using **speech to text** (**STT**) for input prompts and **text
    to speech** (**TTS**) for responses. Lastly, we’ll introduce a decision tree classifier
    as a machine learning endpoint within the GenAISys, capable of predicting activities.
    By the end of this chapter, we will have successfully extended the GenAISys into
    a fully interactive, multimodal reasoning platform ready to tackle complex cross-domain
    use cases.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先概述我们将集成到现有GenAISys框架中的功能。鉴于GenAISys范围的扩大，我们将引入**思维链（CoT**）推理过程，以有效地编排和管理复杂任务。然后，我们将引入计算机视觉能力。这包括使用DALL-E构建图像生成功能和使用GPT-4o进行图像分析功能。接下来，我们将为偏好语音交互的用户添加音频功能——使用**语音转文本（STT**）作为输入提示和**文本转语音（TTS**）作为响应。最后，我们将在GenAISys中引入一个决策树分类器，作为机器学习端点，能够预测活动。到本章结束时，我们将成功将GenAISys扩展为一个完全交互的多模态推理平台，准备好应对复杂的跨领域用例。
- en: 'In all, this chapter covers the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，本章涵盖了以下主题：
- en: The architecture of the additional functions for our GenAISys
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为我们的GenAISys添加附加功能架构
- en: Implementing a widget image file processing
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现小部件图像文件处理
- en: Implementing a widget to enable voice dialogues
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现小部件以启用语音对话
- en: Image generation with DALL-E
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用DALL-E进行图像生成
- en: Image analysis with GPT-4o
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GPT-4o进行图像分析
- en: Building an endpoint for machine learning with a decision tree classifier
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立决策树分类器的机器学习端点
- en: Implementing CoT reasoning
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施CoT推理
- en: Let’s begin by designing an enhanced interface for our GenAISys with additional
    AI capabilities.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从为我们的GenAISys设计一个具有额外AI能力的增强界面开始。
- en: Enhancing the event-driven GenAISys interface
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 增强事件驱动的GenAISys界面
- en: 'So far, the GenAISys framework we’ve developed is event-driven, activated by
    user inputs (human- or system-generated) that trigger specific AI agent functions.
    In this chapter, we’ll expand the GenAISys by adding several new capabilities:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们开发的GenAISys框架是事件驱动的，由用户输入（人工或系统生成）触发特定AI代理功能激活。在本章中，我们将通过添加几个新功能来扩展GenAISys：
- en: '**Voice interaction**, allowing users to manage the GenAISys through speech'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音交互**，允许用户通过语音管理GenAISys'
- en: A new **machine learning endpoint** using a decision tree classifier for predictive
    tasks
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用决策树分类器进行预测任务的新**机器学习端点**
- en: '**Multimodal functionality**, including image generation with DALL-E and image
    analysis using GPT-4o'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多模态功能**，包括使用DALL-E进行图像生成和使用GPT-4o进行图像分析'
- en: A **CoT** reasoning orchestrator to coordinate sophisticated, self-reflective
    instruction scenarios
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个用于协调复杂、自我反思指令场景的**CoT**推理协调器
- en: 'Let’s start by examining the expanded GenAISys architecture shown in *Figure
    5.1*:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从检查*图5.1*中显示的扩展GenAISys架构开始：
- en: '![Figure 5.1: Architecture of the enhanced GenAISys interface](img/B32304_05_1.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1：增强的GenAISys界面架构](img/B32304_05_1.png)'
- en: 'Figure 5.1: Architecture of the enhanced GenAISys interface'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1：增强的GenAISys界面架构
- en: 'This figure (which is an extended version of *Figure 4.1* from the previous
    chapter) highlights the new capabilities we’ll integrate into our GenAISys:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 此图（是前一章中*图4.1*的扩展版本）突出了我们将集成到我们的GenAISys中的新功能：
- en: '**I1** – **AI controller**: Enhanced with CoT reasoning, enabling automated
    sequences of tasks as needed and incorporating a widget to manage voice-based
    user interactions'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**I1** – **AI控制器**：通过CoT推理增强，能够根据需要自动执行任务序列，并包含一个用于管理基于语音的用户交互的小部件'
- en: '**I2** – **Multi-user chatbot**: Maintained exactly as designed in previous
    chapters'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**I2** – **多用户聊天机器人**：与之前章节中设计保持完全一致'
- en: '**F1** – **Generative AI model**: Extended to handle multimodal tasks'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**F1** – **生成式AI模型**：扩展以处理多模态任务'
- en: '**F2** – **Memory retention**: Continues unchanged from earlier chapters'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**F2** – **记忆保留**：与早期章节保持不变'
- en: '**F3** – **Modular RAG**: Continues unchanged from earlier chapters'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**F3** – **模块化RAG**：与早期章节保持不变'
- en: '**F4** – **Multifunctional capabilities**: New additions covering audio and
    image processing, including a decision tree classifier for making predictions'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**F4** – **多功能能力**：新增涵盖音频和图像处理的功能，包括用于预测的决策树分类器'
- en: '**Reminder**'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**提醒**'
- en: 'The decision to present the main components of the GenAISys architecture without
    arrows is a deliberate choice designed to convey a core concept: modularity and
    architectural flexibility. The figure is not a rigid blueprint but rather a conceptual
    toolkit. It shows you the powerful components at your disposal—**I1\. AI controller**,
    **I2\. Multi-user chatbot**, **F1\. Generative AI model**, **F2\. Memory retention**,
    **F3\. Modular RAG**, and **F4\. Multifunctional capabilities**—as independent,
    interoperable blocks.'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 决定不使用箭头展示GenAISys架构的主要组件是一个旨在传达核心概念的故意选择：模块化和架构灵活性。此图不是一个刚性的蓝图，而是一个概念工具包。它展示了您可用的强大组件——**I1.
    AI控制器**、**I2. 多用户聊天机器人**、**F1. 生成式AI模型**、**F2. 记忆保留**、**F3. 模块化RAG**和**F4. 多功能能力**——作为独立、可互操作的块。
- en: 'We are expanding the functionality of GenAISys as built in [*Chapter 4*](Chapter_4.xhtml#_idTextAnchor110)
    by adding new layers rather than replacing existing components. Our emphasis here
    is on enhancement and seamless integration. The following figure provides a high-level
    flowchart demonstrating how the additional capabilities will integrate into our
    existing GenAISys architecture:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过添加新层而不是替换现有组件来扩展GenAISys的功能，正如在[*第4章*](Chapter_4.xhtml#_idTextAnchor110)中构建的那样。我们在这里的重点是增强和无缝集成。以下图提供了一个高级流程图，展示了附加功能将如何集成到我们现有的GenAISys架构中：
- en: '![Figure 5.2: Flowchart of additional functions to the GenAISys](img/B32304_05_2.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图5.2：GenAISys附加功能的流程图](img/B32304_05_2.png)'
- en: 'Figure 5.2: Flowchart of additional functions to the GenAISys'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2：GenAISys附加功能的流程图
- en: 'The following additional functions will be integrated into our existing GenAISys
    interface:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 以下附加功能将集成到我们现有的 GenAISys 接口中：
- en: '**Start**: Initializes two new widgets—one for TTS functionality and another
    to handle image files'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**启动**：初始化两个新的小部件——一个用于 TTS 功能，另一个用于处理图像文件'
- en: '**User Input**: Now includes optional voice input, enabled if the user chooses'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户输入**：现在包括可选的语音输入，如果用户选择则启用'
- en: '**Generate Bot** and **Generate Bot Response**: These processes connect directly
    to the existing `VBox` interface, displaying reasoning steps clearly whenever
    the AI agent utilizes CoT logic'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成机器人** 和 **生成机器人响应**：这些过程直接连接到现有的 `VBox` 接口，当 AI 代理使用 CoT 逻辑时，会清晰地显示推理步骤。'
- en: 'To achieve this expanded functionality, we will develop the following key features:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一扩展功能，我们将开发以下关键特性：
- en: '**STT and TTS**: Integrated using **Google Text-to-Speech** (**gTTS**)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语音识别和语音合成**：集成使用 **Google Text-to-Speech** (**gTTS**)'
- en: '**Machine learning endpoint**: Implementing a decision tree classifier for
    predictive capabilities'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习端点**：实现决策树分类器以提供预测能力'
- en: '**Image generation and analysis**: Powered by OpenAI’s DALL-E and GPT-4o models'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像生成和分析**：由 OpenAI 的 DALL-E 和 GPT-4o 模型提供支持'
- en: '**CoT reasoning**: Orchestrating tasks, functions, and extensions, thus providing
    GenAISys with explicit machine (not human) reasoning abilities'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CoT 推理**：协调任务、功能和扩展，从而为 GenAISys 提供明确的机器（而非人类）推理能力'
- en: Although we are adding several new functions, including reasoning functionality
    (CoT), we will introduce only a single new package installation, gTTS, to minimize
    complexity in this chapter. Our primary focus remains on building a reliable architecture
    with optimal dependency management. To begin, let’s explore the updated elements
    of the IPython interface and the enhancements to the AI agent.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们添加了包括推理功能（CoT）在内的几个新功能，但我们只引入了一个新的包安装，即 gTTS，以最小化本章的复杂性。我们主要关注构建一个可靠的架构，并实现最佳的依赖关系管理。首先，让我们探索
    IPython 接口的更新元素和 AI 代理的增强。
- en: IPython interface and AI agent enhancements
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IPython 接口和 AI 代理增强
- en: 'The GenAISys architecture we’ve developed can now be viewed as comprising three
    interconnected layers, as shown in *Figure 5.3*. These enhancements blur the lines
    between orchestration, control, and agent functionality, as these roles are now
    distributed across multiple layers:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发的 GenAISys 架构现在可以看作由三个相互连接的层组成，如 *图 5.3* 所示。这些增强模糊了协调、控制和代理功能之间的界限，因为这些角色现在分布在多个层中：
- en: '**Layer 1 (IPython interface)** manages user and system inputs through event-driven
    widgets, orchestrating tasks based on user interactions (inputs and checkboxes).'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第一层（IPython 接口）** 通过事件驱动的小部件管理用户和系统输入，根据用户交互（输入和复选框）协调任务。'
- en: '**Layer 2 (AI agent)** controls the generative AI models (in our case, OpenAI
    models) and can trigger a CoT reasoning sequence.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第二层（AI 代理）** 控制生成式 AI 模型（在我们的案例中是 OpenAI 模型）并可以触发 CoT 推理序列。'
- en: '**Layer 3 (functions and agents)** contains functions triggered by the AI agent.
    Notably, the CoT function itself acts as an agent, capable of orchestrating generative
    AI tasks, machine learning, and additional functions as needed.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第三层（功能和代理）** 包含由 AI 代理触发的功能。值得注意的是，CoT 功能本身作为一个代理，能够协调生成式 AI 任务、机器学习以及所需的其他功能。'
- en: '![Figure 5.3: The three layers of the event-driven GenAISys](img/B32304_05_3.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.3：事件驱动的 GenAISys 的三层结构](img/B32304_05_3.png)'
- en: 'Figure 5.3: The three layers of the event-driven GenAISys'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3：事件驱动的 GenAISys 的三层结构
- en: This high-level architecture integrates orchestrators, controllers, and agents,
    each broken down into specific Python functionalities. Let’s start by exploring
    **Layer 1**, the IPython interface, from a functional standpoint.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这种高级架构集成了协调器、控制器和代理，每个部分都分解为特定的 Python 功能。让我们从功能角度开始探索 **第一层**，即 IPython 接口。
- en: 'Layer 1: IPython interface'
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第一层：IPython 接口
- en: 'The IPython interface now incorporates three new features (highlighted in yellow
    in *Figure 5.4*): a voice widget, a file-handling widget, and a dedicated reasoning
    interface triggered by user inputs and AI agent activities. These enhancements
    bring the interface total to six interactive widgets and functions.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: IPython 接口现在集成了三个新特性（在 *图 5.4* 中以黄色突出显示）：一个语音小部件、一个文件处理小部件以及由用户输入和 AI 代理活动触发的专用推理接口。这些增强使得接口总共有六个交互式小部件和功能。
- en: '![Figure 5.4: Voice, file, and reasoning features are added to the IPython
    interface](img/B32304_05_4.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.4：语音、文件和推理功能添加到 IPython 接口](img/B32304_05_4.png)'
- en: 'Figure 5.4: Voice, file, and reasoning features are added to the IPython interface'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4：将语音、文件和推理功能添加到IPython界面
- en: 'Let’s go through each widget and function:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一查看每个小部件和功能：
- en: '**User selection** remains as designed in [*Chapter 4*](Chapter_4.xhtml#_idTextAnchor110).
    It is central to the collaborative design of the GenAISys and remains unchanged.'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**用户选择**在[*第4章*](Chapter_4.xhtml#_idTextAnchor110)中按原设计保留。它是GenAISys协作设计的关键，且保持不变。'
- en: '**User input** is also retained from [*Chapter 4*](Chapter_4.xhtml#_idTextAnchor110)
    without modification; this widget remains central for capturing user prompts.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**用户输入**未经修改地保留自[*第4章*](Chapter_4.xhtml#_idTextAnchor110)；此小部件仍然是捕获用户提示的中心。'
- en: The **AI agent**, as described in [*Chapter 4*](Chapter_4.xhtml#_idTextAnchor110),
    activates or deactivates the generative AI agent (`chat_with_gpt`).
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如[*第4章*](Chapter_4.xhtml#_idTextAnchor110)所述，**AI代理**激活或停用生成式AI代理（`chat_with_gpt`）。
- en: 'The **voice widget** enables voice-based interactions through STT and TTS.
    We’re using cost-free, built-in functionality for STT:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**语音小部件**通过STT和TTS实现基于语音的交互。我们使用的是免费的内置STT功能：'
- en: '**Windows**: Press the Windows key + *H*'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Windows**：按Windows键 + *H*'
- en: '**macOS**: Enable **Dictation** under **Keyboard settings** and choose a custom
    shortcut'
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**macOS**：在**键盘设置**下启用**语音输入**并选择一个自定义快捷键'
- en: 'For TTS, the gTTS service is utilized and controlled via a checkbox set to
    `False` by default:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 对于语音合成（TTS），使用的是gTTS服务，默认通过一个设置为`False`的复选框进行控制和利用：
- en: '[PRE0]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If the AI agent’s checkbox is checked, then the TTS function is called:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果AI代理的复选框被勾选，则调用TTS函数：
- en: '[PRE1]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The resulting MP3 file (`response.mp3`) is automatically played in the `update_display()`
    function:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的MP3文件（`response.mp3`）在`update_display()`函数中自动播放：
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**The files widget** is a new widget that activates file management. It will
    display images generated and saved by the generative AI model (DALL-E) triggered
    in the AI agent function, `chat_with_gpt`. It is controlled via another checkbox,
    initially set to `False`:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文件小部件**是一个新的小部件，用于激活文件管理。它将显示在AI代理功能`chat_with_gpt`中触发的生成式AI模型（DALL-E）生成的和保存的图像。它通过另一个复选框进行控制，初始设置为`False`：'
- en: '[PRE3]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'If an image exists, it is displayed with the **Python Image Library** (**PIL**)
    in the `update_display()` function:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果存在图像，它将在`update_display()`函数中使用**Python图像库**（**PIL**）显示：
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Reasoning activated** is another new widget of the GenAISys. The user input
    will trigger an event in the AI agent, and that, in turn, will trigger a CoT reasoning
    process. The reasoning interface will display the thought process of the CoT in
    real time. The reasoning output widget is created at the start of a session:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**推理激活**是GenAISys的另一个新小部件。用户输入将触发AI代理中的事件，进而触发CoT推理过程。推理界面将实时显示CoT的思考过程。推理输出小部件在会话开始时创建：'
- en: '[PRE5]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The widget will receive outputs from the CoT process and display them independently
    from `VBox` and persistently in the `update_display()` function:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 该小部件将从CoT过程中接收输出，并在`update_display()`函数中独立显示，并持久化：
- en: '[PRE6]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The `VBox` interface now contains all interactive widgets, including the newly
    added TTS and files widgets:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`VBox`界面现在包含所有交互式小部件，包括新添加的TTS和文件小部件：'
- en: '[PRE7]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Given the length and complexity of responses from the AI agent (especially
    during CoT processes), we introduced an enhanced formatting feature using Markdown.
    The `update_display()` function now formats entries clearly, calling a dedicated
    formatting function:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 由于AI代理（特别是在CoT过程中）的响应长度和复杂性，我们引入了使用Markdown的增强格式化功能。`update_display()`函数现在格式化条目清晰，调用专门的格式化函数：
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `format_entry(entry)` function formats the user’s (blue) and assistant’s
    (green) responses, ensuring readability:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`format_entry(entry)`函数格式化用户的（蓝色）和助手的（绿色）响应，确保可读性：'
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This design emphasizes that the IPython interface (**Layer 1**) is purely to
    orchestrate user interactions and trigger underlying layers of functions and agents.
    This architecture ensures that you have the flexibility you need if you want to
    call the functions and agents directly without a user interface.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 此设计强调IPython界面（**层1**）纯粹是为了编排用户交互并触发底层函数和代理。这种架构确保了如果您想直接调用函数和代理而不使用用户界面，您将拥有所需的灵活性。
- en: With the IPython interface described, let’s explore the enhanced capabilities
    in **Layer 2**, the AI agent.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在描述了IPython界面后，让我们探索**层2**，即AI代理的增强功能。
- en: 'Layer 2: AI agent'
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 层2：AI代理
- en: The AI agent invoked by the IPython interface in **Layer 1** remains the `chat_with_gpt`
    function, reinforcing the conversational nature of GenAISys. With the introduction
    of reasoning capabilities, the conversation can now occur directly between AI
    agents as well.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在**层1**中由IPython接口调用的AI代理仍然是`chat_with_gpt`函数，这加强了GenAISys的对话性质。随着推理能力的引入，现在AI代理之间可以直接进行对话。
- en: The `chat_with_gpt` function has been expanded with several new features. If
    necessary, review the core functionalities described in [*Chapter 4*](Chapter_4.xhtml#_idTextAnchor110).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`chat_with_gpt`函数已添加了几个新功能。如有必要，请回顾第[*第4章*](Chapter_4.xhtml#_idTextAnchor110)中描述的核心功能。'
- en: 'Let’s explore the new enhancements added to the AI agent:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索添加到AI代理中的新增强功能：
- en: '`continue_functions=True` has been introduced at the beginning of the function
    to ensure that only one requested task is executed at a time.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在函数开头引入了`continue_functions=True`，以确保一次只执行一个请求的任务。
- en: '`continue_functions` is set to `False` at the end of the Pinecone query process,
    triggered by the presence of the `Pinecone` keyword in the user message. This
    stops any additional unintended task executions.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Pinecone查询过程的末尾将`continue_functions`设置为`False`，这是由用户消息中出现的`Pinecone`关键字触发的。这停止了任何额外的未预期任务执行。
- en: 'The new function, `reason.chain_of_thought_reasoning`, described later, in
    the *Reasoning with CoT* section, is called under specific conditions:'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在后续的*使用CoT进行推理*部分中描述的新功能`reason.chain_of_thought_reasoning`在特定条件下被调用：
- en: '[PRE10]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `continue_functions==True` condition ensures the reasoning function is
    called with the initial user query. A sample customer activities file is also
    downloaded as part of this process:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`continue_functions==True`条件确保推理函数使用初始用户查询进行调用。作为此过程的一部分，还下载了一个样本客户活动文件：'
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'In the example use case for this chapter, a team can automatically access and
    query a regularly updated customer activity data source. The sample file provided
    contains 10,000 records of historical customer activities, including customer
    IDs, locations, activity types, and activity ratings:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的示例用例中，一个团队可以自动访问和查询一个定期更新的客户活动数据源。提供的样本文件包含10,000条历史客户活动记录，包括客户ID、位置、活动类型和活动评分：
- en: '![Figure 5.5: The customer ratings of historical sites](img/B32304_05_5.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图5.5：历史地点的客户评分](img/B32304_05_5.png)'
- en: 'Figure 5.5: The customer ratings of historical sites'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5：历史地点的客户评分
- en: 'A decision tree classifier later utilizes this dataset within the CoT reasoning
    function to predict the most popular customer activity. Once the response is generated,
    it is added to the output, and `continue` is set to `False`:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 后续的决策树分类器在CoT推理函数中使用此数据集来预测最受欢迎的客户活动。一旦生成响应，它就被添加到输出中，并将`continue`设置为`False`：
- en: '[PRE12]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The new function, `reason.generate_image`, that we will implement in the *Image
    generation and analysis* section has also been integrated. It is called as follows:'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将在*图像生成和分析*部分中实现的`reason.generate_image`新功能也已集成。它的调用方式如下：
- en: '[PRE13]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The generated image URL is returned, and the image itself is downloaded and
    saved locally for display or further processing:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 返回生成的图像URL，并将图像本身下载并保存在本地以供显示或进一步处理：
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'A corresponding message is added to the output, and the `continue` flag is
    set to `False`:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在输出中添加了相应的消息，并将`continue`标志设置为`False`：
- en: '[PRE15]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The function previously known as `openai_api.make_openai_api_call` is now renamed
    `reason.make_openai_api_call`. It maintains the same functionality as in [*Chapter
    4*](Chapter_4.xhtml#_idTextAnchor110) but is now part of the GenAISys reasoning
    library. The memory management `if user_memory…else` condition, which takes the
    complete user history or just the present user message into account, has been
    updated with explicit conditions that check both the state of `user_memory` and
    the `continue_functions` flag:'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 之前称为`openai_api.make_openai_api_call`的函数现在重命名为`reason.make_openai_api_call`。它保持了与[*第4章*](Chapter_4.xhtml#_idTextAnchor110)中相同的函数性，但现在它是GenAISys推理库的一部分。内存管理`if
    user_memory…else`条件，该条件考虑了完整用户历史或仅考虑当前用户消息，已更新为具有显式条件，这些条件检查`user_memory`的状态和`continue_functions`标志：
- en: '[PRE16]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The AI agent thus acts as an intermediate orchestrator, calling and managing
    the execution of lower-layer functions rather than executing them directly. The
    Pinecone interface remains the top layer that invokes the AI agent, which in turn
    interacts with the specific functions within **Layer 3**.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，AI代理充当中间编排者，调用和管理低层函数的执行，而不是直接执行它们。Pinecone接口仍然是顶层，它调用AI代理，AI代理随后与**第3层**中的特定函数进行交互。
- en: 'Layer 3: Functions'
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第3层：函数
- en: 'In this layer, our focus is on the new functionalities introduced to enable
    advanced reasoning through the CoT cognitive agent. Pinecone indexing and standard
    OpenAI calls remain as implemented in [*Chapter 4*](Chapter_4.xhtml#_idTextAnchor110).
    The primary additions in this chapter are as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一层，我们的重点是引入的新功能，通过CoT认知代理实现高级推理。Pinecone索引和标准的OpenAI调用保持与[*第4章*](Chapter_4.xhtml#_idTextAnchor110)中实现的方式相同。本章的主要新增内容如下：
- en: '**Image generation and analysis** using DALL-E and GPT-4o, respectively'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用DALL-E和GPT-4o进行图像生成和分析**'
- en: '**CoT reasoning**, which introduces a cognitive agent capable of orchestrating
    tasks'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CoT推理**，它引入了一个能够编排任务的认知代理'
- en: '**Voice interaction capabilities** enabled through gTTS'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过gTTS启用语音交互功能**'
- en: '**A machine learning endpoint** leveraging a decision tree classifier'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**利用决策树分类器的机器学习端点**'
- en: 'We will explore these functionalities in the upcoming sections of this chapter,
    as follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章接下来的部分中探索这些功能，如下所示：
- en: The environment setup and initialization for gTTS and machine learning are detailed
    in the *Setting up the environment* section
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: gTTS和机器学习的环境设置和初始化在*设置环境*部分中详细说明
- en: Image functionalities are covered in the *Image generation and analysis* section
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像功能在*图像生成和分析*部分进行介绍
- en: The reasoning orchestration is built in the *Reasoning with CoT* section
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推理编排构建在*使用CoT进行推理*部分
- en: By the end of this chapter, our enhanced three-layer GenAISys will have new,
    robust capabilities designed to expand even further in subsequent chapters. Let’s
    now dive deeper into these enhancements, beginning with the environment setup.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，我们的增强型三层GenAISys将拥有新的、强大的功能，这些功能旨在在后续章节中进一步扩展。现在让我们深入探讨这些增强，从环境设置开始。
- en: Setting up the environment
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置环境
- en: In this section, we will enhance, expand, and rearrange the environment previously
    built to finalize the GenAISys framework. These changes are essential for the
    upcoming use cases in subsequent chapters. Open the `Multimodal_reasoning_with_Chain_of_Thought.ipynb`
    notebook within the Chapter05 directory on GitHub ([https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main)).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将增强、扩展和重新排列之前构建的环境，以最终确定GenAISys框架。这些更改对于后续章节中的用例至关重要。在GitHub的Chapter05目录中打开`Multimodal_reasoning_with_Chain_of_Thought.ipynb`笔记本([https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main))。
- en: 'Regarding package installations, the *Setting up the environment* section in
    the notebook remains largely unchanged from the previous chapter (`Event-driven_GenAISys_framework.ipynb`),
    with just one new addition: *Google Text-to-Speech (gTTS)*.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 关于包安装，笔记本中的*设置环境*部分与上一章（`Event-driven_GenAISys_framework.ipynb`）基本保持不变，仅增加了一个新项：*Google
    Text-to-Speech (gTTS)*。
- en: However, several significant updates have been made to support the CoT generative
    AI reasoning features. Let’s examine each of these updates, starting with the
    *OpenAI* section.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了支持CoT生成式AI推理功能，已经进行了几个重大更新。让我们逐一检查这些更新，从*OpenAI*部分开始。
- en: OpenAI
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenAI
- en: 'The first two files we download remain the same as in previous chapters. The
    third and fourth files, however, are new and have been added to support advanced
    functionality:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下载的前两个文件与之前章节相同。然而，第三和第四个文件是新的，已被添加以支持高级功能：
- en: '[PRE17]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '`reason.py` now contains the generative AI library with the functions built
    in the previous chapters and the ones we are adding in this chapter. These functions
    in the generative AI library and their status are as follows:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`reason.py`现在包含生成式AI库，其中包含之前章节中构建的函数以及本章中添加的函数。生成式AI库中的这些函数及其状态如下：'
- en: '`make_openai_api_call(input, mrole,mcontent,user_role)` is a general-purpose
    OpenAI API call described in the *Setting up the environment* section of [*Chapter
    1*](Chapter_1.xhtml#_idTextAnchor021). It is now imported as follows:'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`make_openai_api_call(input, mrole,mcontent,user_role)` 是在 *第1章* 的 *设置环境* 部分描述的通用OpenAI
    API调用。现在它如下导入：'
- en: '[PRE18]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '`image_analysis` is the image analysis function that can describe an image
    or use the image as a starting point to generate content such as a story. This
    function is described in the *Image generation and analysis* section of this chapter.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_analysis` 是一个图像分析函数，它可以描述图像或使用图像作为起点生成内容，如故事。该函数在本章的 *图像生成和分析* 部分有描述。'
- en: '`generate_image` is a new function that generates images with DALL-E, detailed
    in the *Image generation and analysis* section of this chapter.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generate_image` 是一个新函数，它使用DALL-E生成图像，在本章的 *图像生成和分析* 部分有详细说明。'
- en: '`chain_of_thought_reasoning` is a new CoT logic function of the GenAISys we
    are building. We will implement it in the *Reasoning with CoT* section of this
    chapter. It can call functions from other libraries, such as `machine_learning`.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`chain_of_thought_reasoning` 是我们正在构建的GenAISys的新CoT逻辑函数。我们将在本章的 *使用CoT进行推理*
    部分实现它。它可以调用来自其他库的函数，例如 `machine_learning`。'
- en: '`machine_learning.py` will now contain a decision tree classifier in a function
    named `ml_agent`. The function takes two arguments:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`machine_learning.py` 现在将包含一个名为 `ml_agent` 的函数中的决策树分类器。该函数接受两个参数：'
- en: '[PRE19]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: In our example use case, `feature1_value` will represent a customer location,
    and `feature2_column` will represent customer activities. The `ml_agent` classifier
    will predict the most popular customer activity for a specific location based
    on historical data.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例用例中，`feature1_value` 将代表客户位置，而 `feature2_column` 将代表客户活动。基于历史数据，`ml_agent`
    分类器将预测特定位置的最受欢迎的客户活动。
- en: 'We import `ml_agent` from `machine_learning.py` as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如下从 `machine_learning.py` 导入 `ml_agent`：
- en: '[PRE20]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The remaining OpenAI setup subsections, including package installation and API
    key initialization, remain identical to previous chapters. Let’s now initialize
    our new functionalities.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余的OpenAI设置子部分，包括包安装和API密钥初始化，与前面的章节相同。现在让我们初始化我们的新功能。
- en: Initializing gTTS, machine learning, and CoT
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始化 gTTS、机器学习和CoT
- en: 'We will initialize the following new functions:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将初始化以下新函数：
- en: '**gTTS** is installed with `!pip install gTTS==2.5.4`, which is an open source,
    free TTS library that fits prototyping purposes: [https://pypi.org/project/gTTS/](https://pypi.org/project/gTTS/).
    `` `click` ``, a command-line library, is required for gTTS. The first cell checks
    if we wish to use gTTS by setting `use_gtts` to `True`:'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**gTTS** 使用 `!pip install gTTS==2.5.4` 安装，这是一个开源、免费的TTS库，适用于原型设计目的：[https://pypi.org/project/gTTS/](https://pypi.org/project/gTTS/).
    `` `click` ``, 一个命令行库，是gTTS所必需的。第一个单元检查我们是否希望使用gTTS，通过将 `use_gtts` 设置为 `True`：'
- en: '[PRE21]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The second cell of the notebook will check for and set up the correct `` `click`
    `` version if `use_gtts` is set to `True`. If an update is needed, it will then
    display a clear message in the notebook output prompting you to manually restart
    the runtime. After restarting, simply click `` `Run All` `` to continue. The code
    will display an HTML message to restart if the version is updated:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本的第二个单元将检查并设置正确的 `` `click` `` 版本，如果 `use_gtts` 设置为 `True`。如果需要更新，它将在笔记本输出中显示一个清晰的提示信息，提示您手动重新启动运行时。重启后，只需点击
    `` `Run All` `` 继续即可。如果版本已更新，代码将显示一个HTML消息以重启：
- en: '[PRE22]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If `use_gtts` is set to `True`, we install gTTS and define a TTS conversion
    function:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `use_gtts` 设置为 `True`，我们将安装gTTS并定义一个TTS转换函数：
- en: '[PRE23]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This function will be activated in the IPython interface when the AI agent
    returns a response, as explained earlier in the *Layer 1: IPython interface* section.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 当AI代理返回响应时，该函数将在IPython界面中激活，如前文在 *层1：IPython界面* 部分所述。
- en: '**The ml_agent algorithm endpoint** is imported from `machine_learning.py`:'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ml_agent算法端点** 从 `machine_learning.py` 导入：'
- en: '[PRE24]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This decision tree classifier function will predict popular customer activities
    based on historical data, enhancing our GenAISys’s predictive capabilities.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 此决策树分类器函数将根据历史数据预测流行的客户活动，增强我们GenAISys的预测能力。
- en: '**The CoT reasoning** framework is imported from `reason.py`:'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CoT推理** 框架从 `reason.py` 导入：'
- en: '[PRE25]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The Pinecone installation, initialization, and queries are then defined as explained
    in *Chapters 3* and *4*. Take some time to revisit those chapters if needed, as
    we will reuse the functions previously developed. We’re now prepared to build
    the image generation and analysis functions.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 然后如*第3章*和*第4章*中所述，定义Pinecone的安装、初始化和查询。如有需要，请花些时间回顾这些章节，因为我们将会重用之前开发的函数。我们现在已经准备好构建图像生成和分析功能。
- en: Image generation and analysis
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像生成和分析
- en: 'In this section, we will begin by creating a flexible image generation function
    using OpenAI’s DALL-E model. Following that, we’ll build a function for image
    analysis. The objective is to enhance GenAISys with computer vision capabilities
    while preserving its responsive, event-driven functionality, as illustrated in
    *Figure 5.6*:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将首先创建一个使用OpenAI的DALL-E模型的可灵活图像生成函数。随后，我们将构建一个图像分析函数。目标是增强GenAISys的计算机视觉能力，同时保留其响应式、事件驱动的功能，如图*图5.6*所示：
- en: '![Figure 5.6: Generating images with flexible event-driven triggers](img/B32304_05_6.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图5.6：使用灵活的事件驱动触发生成图像](img/B32304_05_6.png)'
- en: 'Figure 5.6: Generating images with flexible event-driven triggers'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6：使用灵活的事件驱动触发生成图像
- en: 'The preceding figure is an evolution of the architecture we first developed
    in [*Chapter 4*](Chapter_4.xhtml#_idTextAnchor110). It has been augmented to include
    new capabilities: activation of speech (voice) features, management of image files,
    enhanced display functionality, and reasoning through CoT. In this section, our
    focus will specifically be on integrating and demonstrating computer vision capabilities
    alongside the enhanced display functionality.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图是我们在[*第4章*](Chapter_4.xhtml#_idTextAnchor110)中首先开发的架构的演变。它已经增加了新的功能：激活语音（声音）功能、管理图像文件、增强显示功能以及通过CoT进行推理。在本节中，我们将特别关注将计算机视觉能力与增强的显示功能相结合。
- en: 'The image generation and analysis processes are designed to be flexible:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图像生成和分析过程被设计成灵活的：
- en: No mandatory selection or explicit widget activation is required for image generation
    or analysis. We could easily add explicit widgets labeled **Image Generation**
    or **Image Analysis** if a use case demands it. However, the approach we’re adopting
    here is intentionally flexible, paving the way for integration within more complex,
    automated reasoning workflows such as CoT.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于图像生成或分析，不需要进行强制选择或显式小部件激活。如果用例需要，我们可以轻松添加标记为**图像生成**或**图像分析**的显式小部件。然而，我们这里采用的方法是有意为之的灵活，为在更复杂的自动化推理工作流程（如CoT）中集成铺平道路。
- en: 'The **Files** checkbox widget serves two distinct purposes:'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文件**复选框小部件有两个不同的用途：'
- en: If *unchecked*, an image is generated by DALL-E, saved to a file, but not displayed.
    This allows images to be generated quietly in the background for later use or
    storage.
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果*未勾选*，DALL-E将生成图像，保存到文件中，但不会显示。这允许图像在后台安静地生成，以供以后使用或存储。
- en: If *checked*, the generated or analyzed image will be displayed in the user
    interface, as illustrated in *Figure 5.7*.
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果*勾选*，生成的或分析后的图像将在用户界面中显示，如图*图5.7*所示。
- en: The AI conversational agent automatically activates image generation or analysis
    based on user prompts. These vision capabilities can also trigger automated reasoning
    processes, enabling the system to execute comprehensive CoT tasks seamlessly.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能对话代理会根据用户提示自动激活图像生成或分析。这些视觉能力还可以触发自动化推理过程，使系统能够无缝执行综合CoT任务。
- en: 'Note that the display will only display image files if the **Files** widget
    is checked. Let’s now dive deeper into how these vision features are integrated
    within the GenAISys interface. Specifically, we’ll demonstrate the scenario where
    the **Files** checkbox is activated (checked), as depicted in *Figure 5.7*:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，只有当**文件**小部件被勾选时，显示才会显示图像文件。现在让我们深入了解这些视觉功能如何在GenAISys界面中集成。具体来说，我们将演示**文件**复选框被激活（勾选）的情景，如图*图5.7*所示：
- en: '![Figure 5.7: The files checkbox is checked so that the image will be displayed](img/B32304_05_7.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图5.7：文件复选框被勾选，以便显示图像](img/B32304_05_7.png)'
- en: 'Figure 5.7: The files checkbox is checked so that the image will be displayed'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7：文件复选框被勾选，以便显示图像
- en: 'With the **Files** checkbox selected, the image generated by DALL-E in response
    to the user’s prompt will be immediately displayed, as shown in *Figure 5.8*:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 当选择**文件**复选框时，DALL-E根据用户提示生成的图像将立即显示，如图*图5.8*所示：
- en: '![Figure 5.8: Entering a prompt and displaying the image generated](img/B32304_05_8.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图5.8：输入提示并显示生成的图像](img/B32304_05_8.png)'
- en: 'Figure 5.8: Entering a prompt and displaying the image generated'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8：输入提示并显示生成的图像
- en: If the **Files** option is not checked, the image will be generated and saved
    but not displayed. Similarly, image display functionality also applies to analyzing
    images downloaded from external sources. When the **Files** checkbox is unchecked,
    the analysis runs without visually displaying the image. We are now ready to examine
    the implementation details of the image generation function.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如果未勾选**文件**选项，图像将被生成并保存，但不会显示。同样，图像显示功能也适用于从外部来源下载的图像分析。当**文件**复选框未勾选时，分析将运行而不显示图像。我们现在可以检查图像生成函数的实现细节。
- en: Image generation
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像生成
- en: 'The function to generate an image is located in the custom generative AI library,
    `reason.py`, in the `commons` directory. A user prompt or a CoT framework can
    trigger this function. The name of the function is `generate_image`, and it takes
    five arguments:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 生成图像的函数位于自定义生成式AI库`reason.py`中的`commons`目录。用户提示或CoT框架可以触发此函数。该函数的名称为`generate_image`，并接受五个参数：
- en: '[PRE26]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The five arguments are as follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 五个参数如下：
- en: '`prompt`: The query related to the image that is provided by the user or the
    system.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prompt`: 用户或系统提供的与图像相关的查询。'
- en: '`model`: The OpenAI model to use. In this case, the default value is `gpt-4o`.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model`: 要使用的OpenAI模型。在这种情况下，默认值为`gpt-4o`。'
- en: '`size`: The size of the image. The default size of the image is `1024x1024`.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size`: 图像的大小。图像的默认大小为`1024x1024`。'
- en: '`quality`: Defines the quality of the image. The default value is `standard`,
    which costs less than the higher-quality `hd` option.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`quality`: 定义图像的质量。默认值是`standard`，其成本低于更高品质的`hd`选项。'
- en: '`n`: Defines the number of images to generate. The default value is `1`.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n`: 定义要生成的图像数量。默认值为`1`。'
- en: 'The function returns the URL of the generated image. The code first initializes
    the OpenAI client:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 函数返回生成图像的URL。代码首先初始化OpenAI客户端：
- en: '[PRE27]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The DALL-E model is then called via the OpenAI API with the specified parameters:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然后通过OpenAI API调用DALL-E模型，并使用指定的参数：
- en: '[PRE28]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The parameters are described in detail in [*Chapter 1*](Chapter_1.xhtml#_idTextAnchor021)
    in the *Setting up the environment* section.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 参数在*设置环境*部分的[*第1章*](Chapter_1.xhtml#_idTextAnchor021)中详细描述。
- en: 'Once the content, messages, and parameters are defined, the OpenAI API is called:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了内容、消息和参数，就调用OpenAI API：
- en: '[PRE29]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The URL of the image is extracted from `response` and returned:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 从`response`中提取图像的URL并返回：
- en: '[PRE30]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Once an image has been generated or retrieved, we can choose to display or analyze
    it, depending on our needs.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦生成或检索到图像，我们可以根据需要选择显示或分析它。
- en: Image analysis
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像分析
- en: 'The function to analyze an image is also located in the custom generative AI
    library, `reason.py`, in the `commons` directory. This function, named `image_analysis`,
    is defined as follows, and takes three arguments:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 分析图像的函数也位于自定义生成式AI库`reason.py`中的`commons`目录。该函数名为`image_analysis`，如下定义，并接受三个参数：
- en: '[PRE31]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The three arguments are as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 三个参数如下：
- en: '`image_path_or_url (str)`: The path to access a local image file or the URL
    of the image.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_path_or_url (str)`: 访问本地图像文件的路径或图像的URL。'
- en: '`query_text (str)`: The query related to the image that is provided by the
    user or the system'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`query_text (str)`: 用户或系统提供的与图像相关的查询'
- en: '`model (str)`: The OpenAI model to use. In this case, the default value is
    `gpt-4o`, which possesses vision capabilities(generation and analysis).'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model (str)`: 要使用的OpenAI模型。在这种情况下，默认值为`gpt-4o`，它具有视觉能力（生成和分析）。'
- en: 'The function initializes the content structure for the API call with the provided
    query text:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 函数使用提供的查询文本初始化API调用的内容结构：
- en: '[PRE32]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The function then searches for the image in a URL or a local file:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数随后在URL或本地文件中搜索图像：
- en: '[PRE33]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'If the image is in a URL, it is appended to the content. If the image is a
    local file, it is encoded in Base64 and formatted as a UTF-8 string. This format
    enables embedding the image data within text-based systems (such as JSON or HTML).
    A data URL is then created and appended to the content:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果图像在URL中，则将其附加到内容中。如果图像是本地文件，则将其编码为Base64并格式化为UTF-8字符串。这种格式使得可以在基于文本的系统（如JSON或HTML）中嵌入图像数据。然后创建一个数据URL并将其附加到内容中：
- en: '[PRE34]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The OpenAI message is created with the context that contains the query information
    and the image:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI消息是在包含查询信息和图像的上下文中创建的：
- en: '[PRE35]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The API call includes a set of standard parameters, detailed in [*Chapter 1*](Chapter_1.xhtml#_idTextAnchor021)
    (in the *Setting up the environment* section):'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: API调用包括一组标准参数，在[*第一章*](Chapter_1.xhtml#_idTextAnchor021)（在*设置环境*部分）中详细说明：
- en: '[PRE36]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Once the content, messages, and parameters are defined, the OpenAI API is called:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了内容、消息和参数，就调用OpenAI API：
- en: '[PRE37]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'For further integration, particularly with RAG using Pinecone in [*Chapter
    6*](Chapter_6.xhtml#_idTextAnchor166), the response is saved as text in a file.
    This enables subsequent use and retrieval:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步集成，特别是与[*第六章*](Chapter_6.xhtml#_idTextAnchor166)中使用的Pinecone结合RAG，将响应保存为文件中的文本。这使后续使用和检索成为可能：
- en: '[PRE38]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This `image_analysis` function will also be called by the CoT reasoning process
    built later in this chapter, where `query_text` will be dynamically created and
    passed into the function:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 此`image_analysis`函数也将被本章后面构建的CoT推理过程调用，其中`query_text`将动态创建并传递到该函数中：
- en: '[PRE39]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: We now have fully functional computer vision components integrated into our
    GenAISys. With these capabilities, we are ready to build the CoT reasoning process.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经将功能齐全的计算机视觉组件集成到我们的GenAISys中。有了这些功能，我们准备构建CoT推理过程。
- en: Reasoning with CoT
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用CoT进行推理
- en: The exponential acceleration of global markets has led to billions of micro-tasks
    being generated daily across platforms such as social media, e-marketing sites,
    production lines, and SaaS platforms. Without robust automation, keeping pace
    with these real-time demands is impossible. Speed and efficiency have become paramount,
    requiring tasks to be executed in real time or near-real time. Recent advances
    in AI have significantly helped us adapt to these market paradigms, where we must
    handle an increasing volume of tasks in increasingly shorter timeframes. However,
    as we increase the number and scope of AI functions to solve problems, it is becoming
    confusing for users to run complex scenarios with copilots. It is also quite challenging
    for a team of developers to create a GenAISys that contains the functions they
    need and includes a clear and intuitive sequence of operations for problem-solving.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 全球市场的指数级加速导致每天在社交媒体、电子商务网站、生产线和SaaS平台等平台上产生数十亿个微任务。没有强大的自动化，跟上这些实时需求是不可能的。速度和效率变得至关重要，需要实时或接近实时地执行任务。最近在AI方面的进步显著帮助我们适应这些市场范式，在这些范式中，我们必须在越来越短的时间内处理越来越多的任务。然而，随着我们将AI功能的数量和范围增加以解决问题，用户运行复杂场景与共飞行员一起变得令人困惑。对于开发团队来说，创建包含他们需要的功能并包含清晰直观的操作序列以解决问题的GenAISys也相当具有挑战性。
- en: In this section, we address these challenges by implementing CoT reasoning.
    CoT reasoning breaks complex tasks into smaller, more manageable steps where the
    output of one step becomes the input for the next. This process mimics (without
    replacing) human-like reasoning. It reduces cognitive overload for users, allowing
    them to focus primarily on decision-making. Additionally, CoT reasoning makes
    the AI agent’s internal thought process transparent, providing real-time explainability
    of each reasoning step.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们通过实现CoT推理来解决这些挑战。CoT推理将复杂任务分解成更小、更易于管理的步骤，其中一步的输出成为下一步的输入。这个过程模仿（而不是取代）类似人类的推理。它减少了用户的认知负荷，使他们能够主要专注于决策。此外，CoT推理使AI代理的内部思维过程变得透明，提供了每个推理步骤的实时可解释性。
- en: The goal of this section is to build a CoT reasoning process using Python, leveraging
    the flexible and interactive GenAISys framework we’ve developed. Specifically,
    we will apply CoT to simulate customer-preference analysis for an online travel
    platform, generate creative suggestions for activities, produce images using DALL-E,
    and create storytelling narratives based on these images with GPT-4o.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是使用Python构建一个CoT推理过程，利用我们开发的灵活和交互式的GenAISys框架。具体来说，我们将应用CoT来模拟在线旅游平台的客户偏好分析，生成活动创意建议，使用DALL-E生成图像，以及基于这些图像使用GPT-4o创建叙事叙述。
- en: At first glance, a CoT cognitive agent might seem similar to traditional sequences
    of functions found in classical software development. Hence, let’s first clarify
    the important distinctions between them before we dive into the code.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 初看之下，CoT认知代理可能看起来与传统软件开发中发现的函数序列相似。因此，在我们深入代码之前，让我们首先明确它们之间的重要区别。
- en: CoT in GenAISys versus traditional software sequences
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GenAISys中的CoT与传统的软件序列
- en: 'Seasoned software developers are used to implementing complex sequences of
    functions. To bridge the conceptual gap between traditional software sequences
    and cognitive CoT reasoning (which mimics rather than replaces human cognition),
    let’s first distinguish their purposes clearly:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 经验丰富的软件开发者习惯于实现复杂的函数序列。为了弥合传统软件序列和认知CoT推理（它模仿而不是取代人类认知）之间的概念差距，让我们首先明确它们的用途：
- en: A **traditional sequence** of non-AI or AI functions consists of a series of
    steps executed independently, following a black-box model in which the output
    of one function serves as the static input of the next.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**传统序列**的非AI或AI函数由一系列独立执行的步骤组成，遵循一个黑盒模型，其中一个函数的输出作为下一个函数的静态输入。'
- en: In a **CoT reasoning process**, the steps mimic human-like reasoning. Each step
    goes beyond a simple function and follows a logical progression. Each new process
    builds on the output of the previous step, as we will see when we implement CoT.
    We will observe the GenAISys’s “thinking process” displayed in real time through
    our interactive interface. The process is transparent and explainable, as it is
    visualized in real time within the IPython interface. We can see what the system
    is doing and isolate any function to investigate the process if necessary.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**CoT推理过程**中，步骤模仿人类的推理方式。每个步骤都超越了一个简单的函数，并遵循逻辑的进展。每个新的过程都建立在之前步骤的输出之上，正如我们在实现CoT时将看到的。我们将通过我们的交互界面实时观察GenAISys的“思考过程”。这个过程是透明的且可解释的，因为它在IPython界面中实时可视化。我们可以看到系统正在做什么，并在必要时隔离任何功能以调查过程。
- en: 'Another critical aspect of CoT is its *intermediate reasoning*:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: CoT的另一个关键方面是其**中间推理**：
- en: Each step in a CoT process builds on the previous one, but not all steps are
    static. For instance, when DALL·E generates an image, it creates something entirely
    new—not retrieved from a database. This relies on a generative AI model, not pre-programmed
    content.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CoT过程中的每一步都建立在之前的基础上，但并非所有步骤都是静态的。例如，当DALL·E生成一个图像时，它创造了一些全新的东西——而不是从数据库中检索出来的。这依赖于一个生成式AI模型，而不是预先编程的内容。
- en: The next step in the process isn’t pre-generated, like a fixed list of messages.
    For example, when DALL-E generates an image, we will ask GPT-4o to perform a storytelling
    task that it will invent *ex nihilo* based on the input it received. Alternatively,
    we could ask GPT-4o to simply describe the image—without needing to change or
    fine-tune the model.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过程的下一步不是预先生成的，而是一个固定的消息列表。例如，当DALL-E生成一个图像时，我们将要求GPT-4o执行一个基于它接收到的输入**从无到有**创造的故事讲述任务。或者，我们也可以要求GPT-4o简单地描述图像——无需更改或微调模型。
- en: CoT reasoning offers *cognitive alignment* closer to human thinking patterns.
    We humans break monolithic problems into smaller parts, process each part, and
    then assemble the intermediate conclusions to reach a global solution. The human-like
    framework of the CoT process we are building in this chapter makes the GenAISys
    more intuitive and creative, mimicking (not replacing) human problem-solving methods.
    In the following chapters, notably in [*Chapter 6*](Chapter_6.xhtml#_idTextAnchor166),
    we’ll further expand and enhance the CoT reasoning capabilities. The takeaway
    here is that CoT involves sequences of tasks, but in a more flexible and creative
    way than classical non-AI or AI sequences. Let’s move on and define the cognitive
    flow of CoT reasoning.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: CoT推理提供了更接近人类思维模式的**认知对齐**。我们人类将单一问题分解成更小的部分，处理每个部分，然后将中间结论组装起来以得出全局解决方案。我们在本章中构建的CoT过程的类似人类框架使GenAISys更加直观和富有创造力，模仿（而不是取代）人类的问题解决方法。在接下来的章节中，特别是在[第6章](Chapter_6.xhtml#_idTextAnchor166)中，我们将进一步扩展和增强CoT推理能力。这里的要点是，CoT涉及一系列任务，但比经典的非AI或AI序列更加灵活和富有创造力。让我们继续前进，并定义CoT推理的认知流程。
- en: Cognitive flow of CoT reasoning
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CoT推理的认知流程
- en: Instead of the traditional term flowchart, we’ll use the term *cognitive flow*
    to describe the CoT process we are implementing. This term emphasizes the human-like
    reasoning and dynamic problem-solving capabilities of our AI agent, differentiating
    clearly from classical software flowcharts. A classic flowchart provides a visual
    representation of a sequence of functions. A reasoning CoT cognitive flow or cognitive
    workflow maps the logical progression of the AI agent’s thought process from one
    step to another. The cognitive flow shows how the AI agent mimics human reasoning.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用术语 *认知流程* 而不是传统的术语流程图来描述我们正在实现的 CoT 过程。这个术语强调了我们的 AI 代理类似人类的推理和动态问题解决能力，与经典的软件流程图有明显的区别。一个经典的流程图提供了函数序列的视觉表示。推理
    CoT 认知流程或认知工作流程映射了 AI 代理从一步到另一步的思维过程的逻辑进展。认知流程显示了 AI 代理如何模仿人类推理。
- en: Let’s first walk through the cognitive flow we will implement in Python, visualized
    in *Figure 5.9*. The Python functions we’ll use reside in `reason.py`, located
    in the `commons` directory, and are described in detail in the *OpenAI* subsection
    of this chapter’s *Setting up the environment* section.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先了解一下我们将在 Python 中实现的认知流程，如图 5.9 所示。我们将使用的 Python 函数位于 `commons` 目录下的 `reason.py`
    文件中，并在本章的 *设置环境* 部分的 *OpenAI 子节* 中详细描述。
- en: '![Figure 5.9: Cognitive flow of the CoT process](img/B32304_05_9.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.9：CoT 过程的认知流程](img/B32304_05_9.png)'
- en: 'Figure 5.9: Cognitive flow of the CoT process'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9：CoT 过程的认知流程
- en: The cognitive flow for our CoT reasoning process consists of five main phases,
    orchestrated by the `chain_of_thought_reasoning()` function. This sequence begins
    with **Start**.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们 CoT 推理过程的认知流程由五个主要阶段组成，由 `chain_of_thought_reasoning()` 函数编排。这个序列从 **开始**
    开始。
- en: Start
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开始
- en: 'The CoT reasoning process begins when it receives input text provided by the
    AI agent. The AI agent analyzes the user input and then triggers the CoT function,
    as described earlier in the *Layer 2: AI agent* section. At the start of the CoT
    function, two key initializations occur: the reasoning memory (`steps = []`) is
    initialized, and the reasoning display widget is activated within the IPython
    interactive interface:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 当 CoT 推理过程接收到 AI 代理提供的输入文本时，它开始。AI 代理分析用户输入，然后触发 CoT 函数，如前文在 *层 2：AI 代理* 部分所述。在
    CoT 函数的开始，发生两个关键初始化：推理记忆（`steps = []`）被初始化，并在 IPython 交互式界面中激活推理显示小部件：
- en: '[PRE40]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '`display(reasoning_output)` triggers the `display` widget, which enables real-time
    updates in the interactive IPython interface, ensuring the CoT process remains
    transparent and easily interpretable by users.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '`display(reasoning_output)` 触发 `display` 小部件，它使交互式 IPython 接口能够实时更新，确保 CoT
    过程对用户保持透明且易于理解。'
- en: 'Step 1: ML-baseline'
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第一步：ML 基准
- en: 'The first step, **ML-baseline**, activates the machine learning endpoint (`machine_learning.ml_agent()`).
    It utilizes a decision tree classifier to analyze customer data dynamically and
    predict activities of interest. The function takes a location (for example, `"Rome"`)
    and `"ACTIVITY"` as the target column for the prediction:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步，**ML 基准**，激活机器学习端点 (`machine_learning.ml_agent()`)。它使用决策树分类器动态分析客户数据并预测感兴趣的活动。该函数接受一个位置（例如，`"Rome"`）和
    `"ACTIVITY"` 作为预测的目标列：
- en: '[PRE41]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This block of code is repeated for each reasoning step:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码会为每个推理步骤重复：
- en: 'Each part of the thought process begins with a comment like so: `# Step 1:
    Analysis of the customer database and prediction`'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 思维过程的每一部分都以类似这样的注释开始：`# 第一步：分析客户数据库和预测`
- en: '`steps.append("Process: Performing machine learning analysis of the customer
    database. \n")` appends a description of the step to the reasoning memory step
    list'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`steps.append("Process: Performing machine learning analysis of the customer
    database. \n")` 将步骤描述追加到推理记忆步骤列表中'
- en: '`with reasoning_output` initiates a code block for the display widget'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`with reasoning_output` 为显示小部件启动代码块'
- en: '`reasoning_output.clear_output(wait=True)` clears `reasoning_output t`'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`reasoning_output.clear_output(wait=True)` 清除 `reasoning_output t`'
- en: '`print(steps[-1]) # Print the current step` prints the most recent step added'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`print(steps[-1]) # 打印当前步骤` 打印最近添加的步骤'
- en: '`time.sleep(2) # processing time` introduces a two-second delay'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time.sleep(2) # 处理时间` 引入两秒延迟'
- en: '`result_ml =machine_learning.ml_agent("Rome", "ACTIVITY")` calls `ml_agent`'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`result_ml =machine_learning.ml_agent("Rome", "ACTIVITY")` 调用 `ml_agent`'
- en: '`steps.append(f"Machine learning analysis result: {result_ml}")` appends the
    result returned by the machine learning function to the list of steps'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`steps.append(f"Machine learning analysis result: {result_ml}")` 将机器学习函数返回的结果追加到步骤列表中'
- en: The output from `machine_learning.ml_agent`, which predicts the top customer-preferred
    activity for the location `"Rome"`, becomes the input for the subsequent step,
    suggesting creative activities.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 `machine_learning.ml_agent` 的输出，该输出预测了位于 `"Rome"` 的顶级客户偏好活动，成为后续步骤的输入，暗示了创意活动。
- en: Before moving on to the next step, let’s briefly explore the underlying decision
    tree classifier inside `machine_learning.py`.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行下一步之前，让我们简要探索 `machine_learning.py` 内部的底层决策树分类器。
- en: Decision tree classifier
  id: totrans-253
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 决策树分类器
- en: A decision tree classifier is well suited for our task because it is a machine
    learning model that makes predictions by splitting data into a tree-like structure
    based on feature values. It works by recursively choosing the optimal feature
    at each split until it reaches a defined stopping condition, such as a maximum
    depth or a minimum sample size per leaf. At each step, the possibilities narrow
    down until a single prediction emerges.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树分类器非常适合我们的任务，因为它是一种通过根据特征值将数据分割成树状结构进行预测的机器学习模型。它通过在每次分割时递归地选择最优特征，直到达到定义的停止条件（如最大深度或每个叶子的最小样本大小）来工作。在每一步，可能性会缩小，直到出现单个预测。
- en: 'To run it, we first import the required libraries for handling data and building
    the decision tree. We also disable warnings to avoid cluttering the IPython output:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行它，我们首先导入处理数据和构建决策树所需的库。我们还禁用了警告以避免 cluttering IPython 输出：
- en: '[PRE42]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Next, we define our classifier function, `ml_agent()`, with two parameters:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义我们的分类器函数 `ml_agent()`，它有两个参数：
- en: '[PRE43]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The two parameters are the following:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 两个参数如下：
- en: '`feature1_value`: The value of the location we want to predict activities for.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature1_value`：我们想要预测活动位置的价值。'
- en: '`feature2_column`: The target column (`"ACTIVITY"`) we want to predict.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feature2_column`：我们想要预测的目标列（`"ACTIVITY"`）。'
- en: 'The function starts by loading the customer activities dataset into a pandas
    DataFrame:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 函数首先将客户活动数据集加载到 pandas DataFrame 中：
- en: '[PRE44]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Then, we encode the categorical variables (`LOCATION` and `ACTIVITY`) for processing:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将分类变量（`LOCATION` 和 `ACTIVITY`）进行编码以进行处理：
- en: '[PRE45]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'If no specific location (`feature1_value`) is provided, the function selects
    the most frequent location by default:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有提供特定位置（`feature1_value`），则函数默认选择最频繁的位置：
- en: '[PRE46]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We then prepare the features (`X`) and the target variable (`y`) from our encoded
    data:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们从编码的数据中准备特征（`X`）和目标变量（`y`）：
- en: '[PRE47]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'With our data prepared, we train the decision tree model:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据准备就绪后，我们训练决策树模型：
- en: '[PRE48]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Setting `random_state=42` ensures consistent results each time we run the code.
    Now, we encode the provided (or default) location input to prepare it for prediction:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 `random_state=42` 确保每次运行代码时结果一致。现在，我们将提供的（或默认的）位置输入编码以准备预测：
- en: '[PRE49]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The Python `.transform` method on the `le_location` object converts the categorical
    string into its unique integer code.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: Python 的 `.transform` 方法在 `le_location` 对象上将分类字符串转换为唯一的整数代码。
- en: 'The function is now ready to predict the most probable activity and convert
    it back to its original label. We will use the Python `.predict` method of our
    trained model to see what it predicts for this new data point:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 函数现在已准备好预测最可能的活动并将其转换回其原始标签。我们将使用训练模型的 Python `.predict` 方法来查看它对这个新数据点的预测：
- en: '[PRE50]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Finally, the function constructs a customer’s descriptive output message tailored
    to the predicted activity:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，该函数构建一个针对预测活动的客户描述性输出消息：
- en: '[PRE51]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'This descriptive output is returned to the CoT function:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 此描述性输出返回到 CoT 函数：
- en: '[PRE52]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'To invoke the classifier from the CoT function, we use the following:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 要从 CoT 函数调用分类器，我们使用以下方法：
- en: '[PRE53]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We’re letting the classifier find the location and activity. The expected output,
    in this case, will be the following:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们让分类器找到位置和活动。在这种情况下，预期的输出将是以下内容：
- en: '[PRE54]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Let’s now use the output of this step to suggest activities.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用此步骤的输出建议活动。
- en: 'Step 2: Suggest activities'
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 2 步：建议活动
- en: 'This step follows the same logic and structure as *Step 1*. The name of the
    process is as follows:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤遵循与 *步骤 1* 相同的逻辑和结构。该过程的名称如下：
- en: '[PRE55]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output from *Step 1* (`result_ml`) becomes part of the instruction sent
    to GPT-4o to augment the input context. The combined query (`umessage`) for GPT-4o
    becomes as follows:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤 1* 的输出 (`result_ml`) 成为发送给 GPT-4o 以增强输入上下文的指令的一部分。GPT-4o 的组合查询 (`umessage`)
    如下所示：'
- en: '[PRE56]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'At this stage, the instructions are tailored specifically for our travel-focused
    domain. In [*Chapter 6*](Chapter_6.xhtml#_idTextAnchor166), we’ll evolve these
    instructions to become dynamic event-based variables. Here, we continue using
    the established GenAISys OpenAI API call we built in earlier chapters:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，指令专门针对我们的以旅行为重点的领域。在 [*第 6 章*](Chapter_6.xhtml#_idTextAnchor166) 中，我们将这些指令演变为动态的事件驱动变量。在这里，我们继续使用我们在早期章节中构建的
    GenAISys OpenAI API 调用：
- en: '[PRE57]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The output received from GPT-4o (`task_response`) will serve as the input for
    the next step (*Step 3*). The method of appending and displaying the reasoning
    steps remains consistent with *Step 1*.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 从 GPT-4o 收到的输出 (`task_response`) 将作为下一步 (*步骤 3*) 的输入。添加和显示推理步骤的方法与 *步骤 1* 保持一致。
- en: 'Step 3: Generate image'
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 3 步：生成图像
- en: 'This step begins by taking the detailed suggestion received from the previous
    step (`task_response`) and passing it directly as the prompt to DALL-E’s image
    generation function. The structure and logic here are consistent with the previous
    steps, now focused on generating images:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 此步骤首先从上一步收到的详细建议 (`task_response`) 中获取，并将其直接作为提示传递给 DALL-E 的图像生成函数。这里的结构和逻辑与之前的步骤一致，现在专注于生成图像：
- en: '[PRE58]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Once generated, the image is downloaded and saved locally as `c_image.png`.
    This image file will then be displayed through the IPython interface if the **Files**
    widget is checked, as explained in the *Layer 1: IPython interface* section:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦生成，该图像将被下载并保存在本地，文件名为 `c_image.png`。如果检查了 **文件** 小部件，该图像文件将通过 IPython 接口显示，如
    *层 1：IPython 接口* 部分所述：
- en: '[PRE59]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: With the image now generated and saved, the CoT process advances to analyzing
    this newly created image.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图像生成并保存后，CoT 流程将推进到分析这个新创建的图像。
- en: 'Step 4: Analyze image'
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 4 步：分析图像
- en: The input for this analysis step is the URL of the image generated in *Step
    3*, stored as `image_url`. As mentioned earlier, in this notebook, the query text
    is currently set as a generic, yet travel-specific, request to GPT-4o. In subsequent
    chapters, this query text will become event-driven and more dynamic.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 此分析步骤的输入是 *步骤 3* 中生成的图像的 URL，存储为 `image_url`。如前所述，在这个笔记本中，查询文本目前被设置为针对 GPT-4o
    的一个通用、但特定于旅行的请求。在随后的章节中，此查询文本将变为事件驱动和更动态。
- en: 'For our image analysis, we instruct the generative AI model to craft an engaging
    story based on the generated image:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的图像分析，我们指示生成式 AI 模型根据生成的图像编写一个引人入胜的故事：
- en: '[PRE60]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The code encapsulating the instructions is the same as in the previous steps.
    The CoT function now activates the `image_analysis` function as described previously
    in the *Image generation and analysis* section:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 包含指令的代码与之前的步骤相同。CoT 函数现在激活了在 *图像生成和分析* 部分之前描述的 `image_analysis` 函数：
- en: '[PRE61]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: The output is returned to the `response` variable and saved in the `image_text.txt`
    file for further use. This marks the completion of the CoT reasoning steps.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 输出返回到 `response` 变量，并保存在 `image_text.txt` 文件中供进一步使用。这标志着 CoT 推理步骤的完成。
- en: End
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结束
- en: 'Upon completing all reasoning tasks, the CoT function signals the end of the
    process by clearing and updating the IPython display:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 完成所有推理任务后，CoT 函数通过清除和更新 IPython 显示来表示过程的结束。
- en: '[PRE62]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The IPython interface takes over from here. Let’s now run the CoT from a user
    perspective.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里开始，IPython 接口接管。现在让我们从用户角度运行 CoT。
- en: Running CoT reasoning from a user perspective
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从用户角度运行 CoT 推理
- en: In this section, we’ll seamlessly run the complex GenAISys we’ve been building
    since the beginning of the book. A single prompt will trigger the entire CoT process.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将无缝运行自本书开头以来一直在构建的复杂 GenAISys。一个提示将触发整个 CoT 流程。
- en: We’ll simulate a user activating the reasoning capabilities of the GenAISys
    to obtain comprehensive ideation for an online travel agency. Specifically, we
    aim to predict customer-preferred activities, generate engaging images, and create
    storytelling narratives to evoke customers’ episodic memories. These episodic
    memories might be real-world experiences or dreams of visiting a place and engaging
    in particular activities.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将模拟一个用户激活 GenAISys 的推理能力，以获得在线旅行社的综合构思。具体来说，我们旨在预测客户偏好的活动，生成吸引人的图像，并创建讲述故事性的叙述来唤起客户的情景记忆。这些情景记忆可能是现实世界的经历或访问某个地方并参与特定活动的梦想。
- en: 'To run this scenario, make sure to check the **AI Agent** and **Files** checkboxes
    and enter the following prompt carefully:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此场景，请确保勾选**AI 代理**和**文件**复选框，并仔细输入以下提示：
- en: '[PRE63]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: The `Use`, `reasoning`, `customer`, and `activities` keywords will be recognized
    by the AI agent and trigger the CoT process we built in this chapter. Alternatively,
    we could have implemented a drop-down menu or performed a similarity search in
    the Pinecone index to retrieve specific instruction scenarios. STT input is also
    possible. In this chapter, however, we’ll use typed prompts with keywords to clearly
    illustrate the CoT process.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '`使用`、`推理`、`客户`和`活动`关键词将被 AI 代理识别并触发本章构建的 CoT 流程。或者，我们可以在 Pinecone 索引中实现下拉菜单或执行相似性搜索以检索特定的指令场景。STT
    输入也是可能的。然而，在本章中，我们将使用带有关键词的输入提示来清楚地说明 CoT 流程。'
- en: In [*Chapter 7*](Chapter_7.xhtml#_idTextAnchor191), we’ll build a central keyword
    registry and an orchestrator to further optimize the AI agent’s decision-making
    process.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第 7 章*](Chapter_7.xhtml#_idTextAnchor191)中，我们将构建一个中心关键词注册表和一个协调器，以进一步优化 AI
    代理的决策过程。
- en: Once the user presses *Enter*, all we have to do is sit back and watch just
    as we would with online ChatGPT-like copilots. The first process is to analyze
    the customer base to find the top-ranking activity based on daily data, as shown
    here.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦用户按下 *Enter*，我们只需坐下来观看，就像我们与在线 ChatGPT 类的共飞行员一样。第一个过程是分析客户基础，根据每日数据找到排名靠前的活动，如图所示。
- en: '![Figure 5.10: Searching for activities](img/B32304_05_10.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.10：寻找活动](img/B32304_05_10.png)'
- en: 'Figure 5.10: Searching for activities'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10：寻找活动
- en: 'Once the whole process is complete, the decision tree classifier returns the
    results:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦整个流程完成，决策树分类器将返回结果：
- en: '[PRE64]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The next stage involves searching for suitable activities matching customer
    preferences:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个阶段涉及搜索适合客户偏好的合适活动：
- en: '![Figure 5.11: Searching for activities matching customer needs](img/B32304_05_11.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.11：寻找符合客户需求的活动](img/B32304_05_11.png)'
- en: 'Figure 5.11: Searching for activities matching customer needs'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11：寻找符合客户需求的活动
- en: 'The creative output from GPT-4o provides structured steps to enhance the online
    offerings:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4o 的创意输出提供了结构化步骤来增强在线产品：
- en: '[PRE65]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Next, the CoT instructs DALL-E to generate an engaging image based on these
    suggested activities:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，CoT 指示 DALL-E 根据这些建议的活动生成一个吸引人的图像：
- en: '![Figure 5.12: Image generation based on the output of the previous step](img/B32304_05_12.png)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.12：基于前一步输出的图像生成](img/B32304_05_12.png)'
- en: 'Figure 5.12: Image generation based on the output of the previous step'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12：基于前一步输出的图像生成
- en: 'Because the **Files** checkbox is checked, the generated image is displayed.
    This image is a rather creative one and will vary with each run:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 因为勾选了**文件**复选框，所以生成的图像会显示出来。这个图像相当有创意，并且每次运行都会有所不同：
- en: '![Figure 5.13: A cultural and historical image](img/B32304_05_13.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.13：一幅文化和历史图像](img/B32304_05_13.png)'
- en: 'Figure 5.13: A cultural and historical image'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13：一幅文化和历史图像
- en: In this case, the image contains text such as `…understanding of history and
    its impact on modern life.`, which perfectly fits our request.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，图像包含诸如`…对历史及其对现代生活的影响的理解。`之类的文本，这与我们的请求完美契合。
- en: Note that each run might produce a different output due to context variations
    and the stochastic (probabilistic) nature of generative AI models such as GPT-4o.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，由于上下文变化和生成式 AI 模型（如 GPT-4o）的随机（概率）性质，每次运行可能会产生不同的输出。
- en: 'The next process involves asking GPT-4o to create a narrative for a storytelling
    promotion that leverages episodic memory of past real-life experiences or imagined
    trips:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个过程涉及要求 GPT-4o 为一个利用过去真实生活经历或想象之旅的情景记忆的故事性促销创建叙述：
- en: '![Figure 5.14: Creating an engaging story based on the image generated](img/B32304_05_14.png)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![图5.14：基于生成的图像创建引人入胜的故事](img/B32304_05_14.png)'
- en: 'Figure 5.14: Creating an engaging story based on the image generated'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14：基于生成的图像创建引人入胜的故事
- en: 'The narrative output from GPT-4o, shown, is illustrative and will vary, as
    noted earlier:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，GPT-4o生成的叙事输出是说明性的，并将有所不同：
- en: '[PRE66]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Once the CoT sequence concludes, the GenAISys maintains its reasoning state,
    waiting for new standalone prompts or further CoT runs:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦CoT序列结束，GenAISys将保持其推理状态，等待新的独立提示或进一步的CoT运行：
- en: '![Figure 5.15: Reasoning is persistently activated in the GenAISys](img/B32304_05_15.png)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![图5.15：在GenAISys中持续激活推理](img/B32304_05_15.png)'
- en: 'Figure 5.15: Reasoning is persistently activated in the GenAISys'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.15：在GenAISys中持续激活推理
- en: The *Load and display the conversation history* and *Load and summarize the
    conversation history* sections in the notebook utilize the same functions detailed
    in [*Chapter 4*](Chapter_4.xhtml#_idTextAnchor110).
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本中的*加载并显示对话历史*和*加载并总结对话历史*部分使用了详细说明的相同功能[*第4章*](Chapter_4.xhtml#_idTextAnchor110)。
- en: We’ve now successfully built a small-scale ChatGPT-like GenAISys equipped with
    custom features, including multi-user support, domain-specific RAG, and tailored
    CoT capabilities. In the upcoming chapters, we’ll apply this GenAISys framework
    across several practical business domains.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经成功构建了一个小型ChatGPT-like GenAISys，它配备了自定义功能，包括多用户支持、特定领域的RAG和定制的CoT能力。在接下来的章节中，我们将把这个GenAISys框架应用于几个实际的商业领域。
- en: Summary
  id: totrans-346
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have completed the basic framework of the GenAISys, consisting
    of three layers. The first layer is an IPython interactive interface that acts
    as an orchestrator. It now includes voice capability, file display, and CoT features,
    alongside user inputs, user selections, and the AI agent widget.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们已经完成了GenAISys的基本框架，由三层组成。第一层是一个IPython交互式界面，充当协调器。现在它包括语音功能、文件显示和CoT功能，以及用户输入、用户选择和AI代理小部件。
- en: The second layer is the AI agent orchestrator, triggered by user prompts. This
    demonstrates that within the GenAISys, the boundaries between orchestration and
    control functions are somewhat blurred due to the interactive nature of these
    components. The AI agent distributes tasks between the Pinecone index for querying
    and the OpenAI API agent for generative tasks, such as content and image generation.
    The AI agent can also trigger the CoT process, and we will further enhance its
    capabilities in the following chapters.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 第二层是AI代理协调器，由用户提示触发。这表明在GenAISys中，由于这些组件的交互性质，协调和控制功能之间的界限有些模糊。AI代理在Pinecone索引查询和OpenAI
    API代理生成任务（如内容生成和图像生成）之间分配任务。AI代理还可以触发CoT过程，我们将在下一章进一步增强其功能。
- en: The third and final layer contains the core functionality of the GenAISys, which
    involves AI workers powered by GPT-4o and DALL-E. In this chapter, we introduced
    DALL-E for image generation and utilized GPT-4o to provide insightful comments
    on these images. Additionally, we implemented a decision tree classifier to predict
    customer activities, incorporating machine learning capabilities into our GenAISys.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 第三层和最后一层包含GenAISys的核心功能，涉及由GPT-4o和DALL-E驱动的AI工作者。在本章中，我们介绍了DALL-E用于图像生成，并利用GPT-4o对这些图像提供有洞察力的评论。此外，我们还实现了一个决策树分类器来预测客户活动，将机器学习能力纳入我们的GenAISys。
- en: Introducing the CoT feature marked our initial step toward creating seamless
    reasoning capabilities from an end user perspective. Complex tasks require sophisticated
    AI systems that can emulate human reasoning. Therefore, we will expand upon the
    reasoning abilities of the GenAISys, among other features, in the next chapter.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 引入CoT功能标志着我们从用户角度创建无缝推理能力的初步步骤。复杂任务需要能够模拟人类推理的复杂人工智能系统。因此，在下一章中，我们将扩展GenAISys的推理能力，以及其他功能。
- en: Questions
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: The seamless interface of an online generative AI system shows that the system
    is easy to build. (True or False)
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在线生成式AI系统的无缝界面表明，构建该系统是容易的。（对或错）
- en: Selecting a **large language model** (**LLM**) is sufficient to build a GenAISys.
    (True or False)
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个**大型语言模型**（**LLM**）就足以构建一个GenAISys。（对或错）
- en: A generative AI application requires an event-driven interactive interface.
    (True or False)
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成式AI应用程序需要一个事件驱动的交互式界面。（对或错）
- en: An AI system can mimic human reasoning. (True or False)
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个AI系统可以模仿人类推理。（对或错）
- en: A **chain-of-thought** (**CoT**) process is just a sequence of classical functions.
    (True or False)
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CoT过程只是一个经典函数的序列。（对或错）
- en: A CoT can process natural language but not computer vision. (True or False)
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CoT可以处理自然语言，但不能处理计算机视觉。（对或错）
- en: A CoT is a cognitive agent that can include non-AI or AI functions. (True or
    False)
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CoT是一个认知代理，可以包括非AI或AI功能。（对或错）
- en: Reasoning GenAISys can group a set of tasks for an end user. (True or False)
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 推理GenAISys可以为最终用户分组一系列任务。（对或错）
- en: The continual acceleration of the economy requires more automation, including
    AI. (True or False)
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 经济的持续加速需要更多的自动化，包括AI。（对或错）
- en: A human-centric reasoning GenAISys can boost the productivity of a team. (True
    or False)
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以人为中心的推理GenAISys可以提升团队的效率。（对或错）
- en: References
  id: totrans-362
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Chan, Andy, Cassidy Ezell, Michael Kaufmann, Kevin Wei, Laurel Hammond, Hunter
    Bradley, Elliot Bluemke, Nandhini Rajkumar, David Krueger, Nikita Kolt, Lukas
    Heim, and Markus Anderljung. “Visibility into AI Agents.” In Proceedings of the
    2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT ‘24),
    Rio de Janeiro, Brazil, June 3–6, 2024\. New York: ACM, 2024\. [https://arxiv.org/pdf/2401.13138](https://arxiv.org/pdf/2401.13138).'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查恩，安迪，凯西迪·埃泽尔，迈克尔·考夫曼，凯文·韦，劳拉尔·哈蒙德，亨特·布拉德利，埃利奥特·布卢姆克，南迪尼·拉贾库马尔，大卫·克鲁格，尼基塔·科尔特，卢卡斯·海姆，以及马克斯·安德尔容。
    “AI代理的可见性。” 在2024年ACM公平、问责和透明度会议（FAccT ‘24）论文集中，里约热内卢，巴西，2024年6月3日至6日。纽约：ACM，2024年。[https://arxiv.org/pdf/2401.13138](https://arxiv.org/pdf/2401.13138).
- en: 'Putta, Praveen, Eric Mills, Naman Garg, Soham Motwani, Chelsea Finn, Divyansh
    Garg, and Rohan Rafailov. “Agent Q: Advanced Reasoning and Learning for Autonomous
    AI Agents.” Last modified 2024\. [https://arxiv.org/abs/2408.07199](https://arxiv.org/abs/2408.07199).'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 普塔，普拉文，埃里克·米尔斯，纳曼·加尔，索汉·莫特万尼，切尔西·芬恩，迪维亚恩什·加尔，以及罗汉·拉菲洛夫。 “Agent Q：为自主AI代理的高级推理和学习。”
    最后修改于2024年。[https://arxiv.org/abs/2408.07199](https://arxiv.org/abs/2408.07199).
- en: Wiesinger, Jannis, Peter Marlow, and Vladimir Vuskovic. “Agents.” Kaggle Whitepaper.
    Accessed July 8, 2025\. [https://www.kaggle.com/whitepaper-agents](https://www.kaggle.com/whitepaper-agents).
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 魏辛格，贾尼斯，彼得·马尔洛，以及弗拉基米尔·弗斯克维奇。 “代理。” Kaggle白皮书。2025年7月8日访问。[https://www.kaggle.com/whitepaper-agents](https://www.kaggle.com/whitepaper-agents).
- en: OpenAI. OpenAI API Documentation. Accessed July 8, 2025\. [https://platform.openai.com/docs/api-reference/introduction](https://platform.openai.com/docs/api-reference/introduction).
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI. OpenAI API文档。2025年7月8日访问。[https://platform.openai.com/docs/api-reference/introduction](https://platform.openai.com/docs/api-reference/introduction).
- en: '|'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Unlock this book’s exclusive benefits now
  id: totrans-368
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 现在解锁这本书的独家优惠
- en: Scan this QR code or go to [packtpub.com/unlock](http://packtpub.com/unlock),
    then search for this book by name. | ![A qr code on a white background  AI-generated
    content may be incorrect.](img/Unlock.png) |
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 扫描此二维码或访问[packtpub.com/unlock](http://packtpub.com/unlock)，然后通过书名搜索此书。 | ![白色背景上的二维码
    AI生成的内容可能不正确。](img/Unlock.png) |
- en: '| *Note: Keep your purchase invoice ready before you start.* |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| *注意：在开始之前准备好您的购买发票。* |'
