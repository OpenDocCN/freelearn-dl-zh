- en: Generative Adversarial Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: '**Generative Adversarial Networks** (**GANs**) are deep neural net architectures
    that consist of two networks pitted against each other (hence the name **adversarial**).'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成对抗网络**（**GANs**）是深度神经网络架构，由两个相互对立的网络组成（因此得名**对抗**）。'
- en: GANs were introduced in a paper ([https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661))
    by Ian Goodfellow and other researchers, including Yoshua Bengio, at the University
    of Montreal in 2014\. Referring to GANs, Facebook's AI research director, Yann
    LeCun, called **adversarial training** the most interesting idea in the last 10
    years in machine learning.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: GANs是在2014年由Ian Goodfellow和其他研究人员，包括Yoshua Bengio，在蒙特利尔大学的一篇论文中提出的（[https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)）。Facebook的AI研究总监Yann
    LeCun曾提到，**对抗训练**是过去10年中在机器学习领域最有趣的想法。
- en: 'The potential of GANs is huge, because they can learn to mimic any distribution
    of data. That is, GANs can be taught to create worlds eerily similar to our own
    in any domain: images, music, speech, or prose. They are robot artists in a sense,
    and their output is impressive ([https://www.nytimes.com/2017/08/14/arts/design/google-how-ai-creates-new-music-and-new-artists-project-magenta.html](https://www.nytimes.com/2017/08/14/arts/design/google-how-ai-creates-new-music-and-new-artists-project-magenta.html))—and
    poignant too.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: GANs的潜力巨大，因为它们可以学习模仿任何数据分布。也就是说，GANs可以被训练生成在任何领域与我们现实世界极为相似的世界：图像、音乐、语音或散文。从某种意义上说，它们是机器人艺术家，它们的输出令人印象深刻（[https://www.nytimes.com/2017/08/14/arts/design/google-how-ai-creates-new-music-and-new-artists-project-magenta.html](https://www.nytimes.com/2017/08/14/arts/design/google-how-ai-creates-new-music-and-new-artists-project-magenta.html))——并且也令人感动。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: An intuitive introduction
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直观介绍
- en: Simple implementation of GANs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GANs的简单实现
- en: Deep convolutional GANs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度卷积GANs
- en: An intuitive introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 直观介绍
- en: In this section, we are going to introduce GANs in a very intuitive way. To
    get an idea of how GANs work, we will adopt a fake scenario of getting a ticket
    for a party.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将以非常直观的方式介绍GANs。为了理解GANs的工作原理，我们将采用一个虚拟情境——获得一张派对门票的过程。
- en: 'The story starts with a very interesting party or event being held somewhere,
    and you are very interested in attending it. You hear about this event very late
    and all the tickets are sold out, but you will do anything to get into the party.
    So you come up with an idea! You will try to fake a ticket that needs to be exactly
    the same as the original one, or very, very similar to it. But because life is
    not easy, there''s another challenge: you don''t know what the original ticket
    looks like. So from your experience of going to such parties, you start to imagine
    what the ticket might look like and start to design the ticket based on your imagination.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 故事从一个非常有趣的派对或活动开始，这个活动在某个地方举行，你非常想参加。你听说这个活动时已经很晚了，所有的门票都卖光了，但你会不惜一切代价进入派对。所以，你想到了一个主意！你将尝试伪造一张与原始门票完全相同或者非常相似的票。但因为生活总是充满挑战，还有一个难题：你不知道原始门票长什么样子。所以，根据你参加过类似派对的经验，你开始想象这张门票可能是什么样子的，并开始根据你的想象设计这张票。
- en: You will try to design the ticket and then go to the event and show the ticket
    to the security guys. Hopefully, they will be convinced and will let you in. But
    you don't want to show your face multiple times to the security guards, so you
    decide to get help from your friend, who will take your initial guess about the
    original ticket and show it to the security guards. If they don't let him in,
    he will get some information for you about what the ticket might look like, based
    on seeing some people getting in with the actual ticket. You will refine the ticket
    based on your friend's comments until the security guards let him in. At this
    point—and at this point only—you will design another one that has exactly the
    same look and get yourself in.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你将尝试设计这张票，然后去活动现场，向保安展示这张票。希望他们会被说服，并让你进去。但你不想多次向保安展示自己的脸，于是你决定寻求朋友的帮助，朋友会拿着你对原始门票的初步猜测去向保安展示。如果他们没有让他进去，他会根据看到其他人用真正的门票进入的情况，给你一些信息，告诉你这张票可能是什么样的。你会根据朋友的反馈不断完善门票，直到保安允许他进入。到那时——只有到那时——你才会设计出一张完全相同的票，并让自己也顺利进入。
- en: Do, think too much about how unrealistic this story is, but the way GANs work
    is very similar to this story. GANs are very trendy nowadays, and people are using
    them for many applications in the field of computer vision.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 不要过多思考这个故事有多不现实，但GAN的工作原理与这个故事非常相似。如今GAN非常流行，人们将其用于计算机视觉领域的许多应用。
- en: There are many interesting applications that you can use GANs for, and we will
    implement and mention some of them.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将GAN用于许多有趣的应用，我们将在实现并提到其中的一些应用。
- en: 'In GANs, there are two main components that have made a breakthrough in many
    computer vision fields. The first component is called **Generator** and the second
    one is called **Discriminator**:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在GAN中，有两个主要组成部分在许多计算机视觉领域中取得了突破。第一个组件被称为**生成器**，第二个组件被称为**判别器**：
- en: The Generator will try to generate data samples out of a specific probability
    distribution, which is very similar to the guy who was trying to replicate a ticket
    for the event
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器将尝试从特定的概率分布中生成数据样本，这与那个试图复制活动票的人的行为非常相似。
- en: 'The Discriminator will judge (like the security guys who are trying to find
    flaws in the ticket to decide whether it''s original or fake) whether its input
    is coming from the original training set (an original ticket) or from the generator
    part (designed by the guy who''s trying to replicate the original ticket):'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器将判断（就像安保人员试图找出票上的缺陷，以决定它是原始的还是伪造的）输入是来自原始训练集（原始票）还是来自生成器部分（由试图复制原始票的人设计）：
- en: '![](img/4961129f-2166-4bfd-9304-70a05d5d46c8.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4961129f-2166-4bfd-9304-70a05d5d46c8.png)'
- en: 'Figure 1: GANs – general architecture'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：GAN——通用架构
- en: Simple implementation of GANs
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单的GAN实现
- en: From the story of faking a ticket to an event, the idea of GANs seems to be
    very intuitive. So to get a clear understanding of how GANs work and how to implement
    them, we are going to demonstrate a simple implementation of a GAN on the MNIST
    dataset.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从伪造活动票的故事来看，GAN的概念似乎非常直观。为了清楚地理解GAN如何工作以及如何实现它们，我们将展示一个在MNIST数据集上实现简单GAN的例子。
- en: 'First, we need to build the core of the GAN network, which is comprised of
    two major components: the generator and the discriminator. As we said, the generator
    will try to imagine or fake data samples from a specific probability distribution;
    the discriminator, which has access to and sees the actual data samples, will
    judge whether the generator''s output has any flaws in the design or it''s very
    close to the original data samples. Similar to the scenario of the event, the
    whole purpose of the generator is to try to convince the discriminator that the
    generated image is from the real dataset and hence try to fool him.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要构建GAN网络的核心，主要由两个部分组成：生成器和判别器。正如我们所说，生成器将尝试从特定的概率分布中生成或伪造数据样本；判别器则能够访问和看到实际的数据样本，它将判断生成器的输出是否在设计上存在缺陷，或者它与原始数据样本有多么接近。类似于事件的场景，生成器的整个目的是尽力说服判别器，生成的图像来自真实数据集，从而试图欺骗判别器。
- en: 'The training process has a similar end to the event story; the generator will
    finally manage to generate images that look very similar to the original data
    samples:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程的结果类似于活动故事的结局；生成器最终将成功生成看起来与原始数据样本非常相似的图像：
- en: '![](img/45302309-65dd-4e06-96f8-c1c5ca5d1569.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/45302309-65dd-4e06-96f8-c1c5ca5d1569.png)'
- en: 'Figure 2: GAN general architecture for the MNIST dataset'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：MNIST数据集的GAN通用架构
- en: The typical structure of any GAN is shown in *Figure 2*, which will be trained
    on the MNIST dataset. The `Latent sample` part in this figure is a random thought
    or vector that the generator uses to replicate the real images with fake ones.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 任何GAN的典型结构如*图2*所示，将会在MNIST数据集上进行训练。图中的`潜在样本`部分是一个随机的思维或向量，生成器利用它来用假图像复制真实图像。
- en: As we mentioned, the discriminator works as a judge and it will try to separate
    the real images from the fake ones that were designed by the generator. So the
    output of this network will be binary, which can be represented by a sigmoid function
    with 0 (meaning the input is a fake image) and 1 (meaning that the input is a
    real image).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所述，判别器充当一个判断者，它会尝试将生成器设计的假图像与真实图像区分开来。因此，这个网络的输出将是二值的，可以通过一个sigmoid函数表示，0表示输入是一个假图像，1表示输入是一个真实图像。
- en: Let's go ahead and start implementing this architecture to see how it performs
    on the MNIST dataset.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续并开始实现这个架构，看看它在MNIST数据集上的表现。
- en: 'Let''s start of by importing the required libraries for this implementation:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从导入实现所需的库开始：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We will be using the MNIST dataset, so we are going to use TensorFlow helpers
    to get the dataset and store it somewhere:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 MNIST 数据集，因此我们将使用 TensorFlow 辅助工具获取数据集并将其存储在某个地方：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Model inputs
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型输入
- en: 'Before diving into building the core of the GAN, which is represented by the
    generator and discriminator, we are going to define the inputs of our computational
    graph. As shown in *Figure 2*, we need two inputs. The first one will be the real
    images, which will be fed to the discriminator. The other input is called **latent
    space**, which will be fed to the generator and used to generate its fake images:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入构建 GAN 的核心部分（由生成器和鉴别器表示）之前，我们将定义计算图的输入。如 *图 2* 所示，我们需要两个输入。第一个是实际图像，将传递给鉴别器。另一个输入称为
    **潜在空间**，它将传递给生成器并用于生成假图像：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](img/c738df95-3bb7-40dd-9862-b5d6f2d3292a.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c738df95-3bb7-40dd-9862-b5d6f2d3292a.png)'
- en: 'Figure 3: Architecture of the MNIST GAN implementation'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：MNIST GAN 实现的架构
- en: Now it's time to dive into building the two core components of our architecture.
    We will start by building the generator part. As shown in *Figure 3*, the generator
    will consist of at least one hidden layer, which will work as an approximator.
    Also, instead of using the normal ReLU activation function, we will use something
    called a leaky ReLU. This will allow the gradient values to flow through the layer
    without any constraints (more in the next section about leaky RelU).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候开始构建我们架构的两个核心组件了。我们将从构建生成器部分开始。如 *图 3* 所示，生成器将包含至少一个隐藏层，该层将作为近似器工作。此外，我们将使用一种称为
    leaky ReLU 的激活函数，而不是使用普通的 ReLU 激活函数。这样，梯度值就可以在层之间流动，而没有任何限制（关于 leaky ReLU 的更多内容将在下一节介绍）。
- en: Variable scope
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变量作用域
- en: 'Variable scope is a feature of TensorFlow that helps us to do the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 变量作用域是 TensorFlow 的一个功能，帮助我们完成以下任务：
- en: Make sure that we have some naming conventions to retrieve them later, for example,
    by making them start with the word generator or discriminator, which will help
    us during the training of the network. We could have used the name scope feature,
    but this feature won't help us for the second purpose.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保我们有一些命名约定以便稍后能检索它们，例如，可以让它们以“generator”或“discriminator”开头，这将帮助我们在训练网络时。我们本可以使用作用域命名功能，但这个功能对第二个目的帮助不大。
- en: To be able to reuse or retrain the same network but with different inputs. For
    example, we are going to sample fake images from the generator to see how good
    the generator is for replicating the original ones. Also, the discriminator will
    have access to the real and fake images, which will make it easy for us to reuse
    the variables instead of creating new ones while building the computational graph.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了能够重用或重新训练相同的网络，但使用不同的输入。例如，我们将从生成器中采样假图像，以查看生成器在复制原始图像方面的表现如何。另外，鉴别器将能够访问真实图像和假图像，这将使我们能够重用变量，而不是在构建计算图时创建新变量。
- en: 'The following statement will show how to use the variable scope feature of
    TensorFlow:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下语句将展示如何使用 TensorFlow 的变量作用域功能：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can read more about the benefits of using the variable scope feature at
    [https://www.tensorflow.org/programmers_guide/variable_scope#the_problem](https://www.tensorflow.org/programmers_guide/variable_scope#the_problem).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://www.tensorflow.org/programmers_guide/variable_scope#the_problem](https://www.tensorflow.org/programmers_guide/variable_scope#the_problem)阅读更多关于使用变量作用域功能的好处。
- en: Leaky ReLU
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Leaky ReLU
- en: We mentioned that we will be using a different version than the ReLU activation
    function, which is called leaky ReLU. The traditional version of the ReLU activation
    function will just take the maximum between the input value and zero, by other
    means truncating negative values to zero. Leaky ReLU, which is the version that
    we will be using, allows some negative values to exist, hence the name **leaky
    ReLU**.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到过，我们将使用一个不同版本的 ReLU 激活函数，称为 leaky ReLU。传统版本的 ReLU 激活函数会选择输入值与零的最大值，换句话说，将负值截断为零。而
    leaky ReLU，即我们将使用的版本，允许某些负值存在，因此得名 **leaky ReLU**。
- en: Sometimes, if we use the traditional ReLU activation function, the network gets
    stuck in a popular state called the dying state, and that's because the network
    produces nothing but zeros for all the outputs.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，如果我们使用传统的 ReLU 激活函数，网络会陷入一个叫做“死亡状态”的常见状态，这时网络对于所有输出都会产生零值。
- en: The idea of using leaky ReLU is to prevent this dying state by allowing some
    negative values to pass through.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Leaky ReLU 的目的是通过允许一些负值通过，防止出现“死亡”状态。
- en: The whole idea behind making the generator work is to receive gradient values
    from the discriminator, and if the network is stuck in a dying situation, the
    learning process won't happen.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 使生成器正常工作的整个思路是接收来自判别器的梯度值，如果网络处于“死亡”状态，则学习过程无法发生。
- en: 'The following figures illustrate the difference between traditional ReLU and
    its leaky version:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了传统 ReLU 和其 Leaky 版本之间的区别：
- en: '![](img/282a88ea-0437-4ea8-b383-342103b56ce6.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/282a88ea-0437-4ea8-b383-342103b56ce6.png)'
- en: 'Figure 4: ReLU function'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：ReLU 函数
- en: '![](img/1138c8e8-e7cd-47a0-b5d0-7a899bc7e5e9.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1138c8e8-e7cd-47a0-b5d0-7a899bc7e5e9.png)'
- en: 'Figure 5: Leaky ReLU activation functions'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：Leaky ReLU 激活函数
- en: The leaky ReLU activation function is not implemented in TensorFlow, so we need
    to implement it ourselves. The output of this activation function will be positive
    if the input is positive, and will be a controlled negative value if the input
    is negative. We will control the negative value by a parameter called **alpha**,
    which will introduce tolerance of the network by allowing some negative values
    to pass.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Leaky ReLU 激活函数在 TensorFlow 中没有实现，因此我们需要自己实现。该激活函数的输出如果输入为正，则为正值，如果输入为负，则为一个受控的负值。我们将通过一个名为
    **alpha** 的参数来控制负值的大小，从而通过允许一些负值通过来为网络引入容忍度。
- en: 'The following equation represents the leaky ReLU that we will be implementing:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下方程表示我们将要实现的 Leaky ReLU：
- en: '![](img/87b4a5a5-f789-4a60-b7a6-30053c8fb0cd.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/87b4a5a5-f789-4a60-b7a6-30053c8fb0cd.png)'
- en: Generator
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成器
- en: 'The MNIST images are normalized between 0 and 1, where the `sigmoid` activation
    function can work best. But in practice, the `tanh` activation function is found
    to give better performance than any other function. So, in order to use the `tanh`
    activation function, we will need to re-scale the range of the pixel values of
    these images to be between -1 and 1:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST 图像的值已归一化在 0 和 1 之间，在这个范围内，`sigmoid` 激活函数表现最佳。但是，实际上，发现 `tanh` 激活函数的性能优于其他任何函数。因此，为了使用
    `tanh` 激活函数，我们需要将这些图像的像素值范围重新缩放到 -1 和 1 之间：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now we have the generator part ready. Let's go ahead and define the second component
    of the network.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在生成器部分已经准备好了，让我们继续定义网络的第二个组件。
- en: Discriminator
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 判别器
- en: 'Next up, we will build the second main component in the generative adversarial
    network, which is the discriminator. The discriminator is pretty much the same
    as the generator, but instead of using the `tanh` activation function, we will
    be using the `sigmoid` activation function; it will produce a binary output that
    will represent the judgment of the discriminator on the input image:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将构建生成对抗网络中的第二个主要组件，即判别器。判别器与生成器非常相似，但我们将使用 `sigmoid` 激活函数，而不是 `tanh` 激活函数；它将输出一个二进制结果，表示判别器对输入图像的判断：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Building the GAN network
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建 GAN 网络
- en: After defining the main functions that will build the generator and discriminator
    parts, it's time to stack them up and define the model losses and optimizers for
    this implementation.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了构建生成器和判别器部分的主要函数后，接下来是将它们堆叠起来，并定义模型的损失函数和优化器进行实现。
- en: Model hyperparameters
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型超参数
- en: 'We can fine-tune the GANs by changing the following set of hyperparameters:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过更改以下超参数集来微调 GAN：
- en: '[PRE7]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Defining the generator and discriminator
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义生成器和判别器
- en: 'After defining the two main parts of our architecture that will be used to
    generate fake MNIST images (which will look exactly the same as the real ones),
    it''s time to build the network using the functions that we have defined so far.
    In order to build the network, we are going to follow these steps:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义了生成虚假 MNIST 图像的架构的两个主要部分后（这些图像看起来和真实的完全一样），现在是时候使用我们目前定义的函数来构建网络了。为了构建网络，我们将按照以下步骤进行：
- en: Defining the inputs for our model, which will consist of two variables. One
    of these variables will be the real images, which will be fed to the discriminator,
    and the second will be the latent space to be used by the generator to replicate
    the original images.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义我们的模型输入，这将由两个变量组成。其中一个变量是真实图像，将被输入到判别器中，另一个是潜在空间，将被生成器用于复制原始图像。
- en: Calling the defined generator function to build the generator part of the network.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用定义好的生成器函数来构建网络的生成器部分。
- en: Calling the defined discriminator function to build the discriminator part of
    the network, but we are going to call this function twice. One call will be for
    the real data and the second call will be for the fake data from the generator.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用定义的判别器函数来构建网络的判别器部分，但我们将调用这个函数两次。第一次调用将用于真实数据，第二次调用将用于来自生成器的假数据。
- en: 'Keeping the weights of real and fake images the same by reusing the variables:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过重用变量保持真实图像和假图像的权重相同：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Discriminator and generator losses
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 判别器和生成器的损失
- en: In this part, we need to define the discriminator and generator losses, and
    this can be considered to be the most tricky part of this implementation.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们需要定义判别器和生成器的损失，这可以看作是该实现中最棘手的部分。
- en: We know that the generator tries to replicate the original images and that the
    discriminator works as a judge, receiving both images from the generator and the
    original input images. So while designing our loss for each part, we need to target
    two things.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道生成器试图复制原始图像，而判别器充当一个判断者，接收来自生成器和原始输入图像的两种图像。所以，在设计每个部分的损失时，我们需要关注两个方面。
- en: First, we need the discriminator part of the network to be able to distinguish
    between the fake images generated by the generator and the real images coming
    from the original training examples. During training time, we will feed the discriminator
    part with a batch that is divided into two categories. The first category will
    be images from the original input and the second category will be images from
    the fake ones that got generated by the generator.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要网络的判别器部分能够区分由生成器生成的假图像和来自原始训练示例的真实图像。在训练时，我们将为判别器部分提供一个批次，该批次分为两类。第一类是来自原始输入的图像，第二类是生成器生成的假图像。
- en: 'So the final general loss of the discriminator will be the sum of its ability
    to accept the real ones as real and detect the fake ones as fake; then the final
    total loss will be:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，判别器的最终总损失将是其将真实样本识别为真实和将假样本识别为假的能力之和；然后最终的总损失将是：
- en: '![](img/85448d3e-1c11-4804-a615-f1b6463e6b26.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/85448d3e-1c11-4804-a615-f1b6463e6b26.png)'
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: So we need to calculate two losses to come up with the final discriminator loss.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们需要计算两个损失来得出最终的判别器损失。
- en: 'The first loss, `disc_loss_real`, will be calculated based on the `logits`
    values that we will get from the discriminator and the `labels`, which will be
    all ones in this case since we know that all the images in this mini-batch are
    all coming from the real input images of the MNIST dataset. To enhance the ability
    of the model to generalize on the test set and give better results, people have
    found that practically changing the value of 1 to 0.9 is better. This kind of
    change to the label introduces something called **label smooth**:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个损失，`disc_loss_real`，将根据我们从判别器得到的`logits`值和`labels`计算，这里标签将全部为1，因为我们知道这个小批次中的所有图像都来自MNIST数据集的真实输入图像。为了增强模型在测试集上的泛化能力并提供更好的结果，实践中发现将1的值改为0.9更好。对标签值进行这样的修改引入了**标签平滑**：
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For the second part of the discriminator loss, which is the ability of the discriminator
    to detect fake images, the loss will be between the logits values that we will
    get from the discriminator and labels; all of these are zeros since we know that
    all the images in this mini-batch are coming from the generator, and not from
    the original input.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于判别器损失的第二部分，即判别器检测假图像的能力，损失将是判别器从生成器得到的logits值与标签之间的差异；这些标签全为0，因为我们知道这个小批次中的所有图像都是来自生成器，而不是来自原始输入图像。
- en: 'Now that we have discussed the discriminator loss, we need to calculate the
    generator loss as well. The generator loss will be called `gen_loss`, which will
    be the loss between `disc_logits_fake` (the output of the discriminator for the
    fake images) and the labels (which will be all ones since the generator is trying
    to convince the discriminator with its design of the fake image):'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了判别器损失，我们还需要计算生成器的损失。生成器损失将被称为`gen_loss`，它是`disc_logits_fake`（判别器对于假图像的输出）和标签之间的损失（由于生成器试图通过其设计的假图像来说服判别器，因此标签将全部为1）：
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Optimizers
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化器
- en: Finally, the optimizers part! In this section, we will define the optimization
    criteria that will be used during the training process. First off, we are going
    to update the variables of the generator and discriminator separately, so we need
    to be able to retrieve the variables of each part.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 最后是优化器部分！在这一部分，我们将定义训练过程中使用的优化标准。首先，我们将分别更新生成器和鉴别器的变量，因此我们需要能够获取每部分的变量。
- en: For the first optimizer, the generator one, we will retrieve all the variables
    that start with the name `generator` from the trainable variables of the computational
    graph; then we can check which variable is which by referring to its name.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个优化器，即生成器优化器，我们将从计算图的可训练变量中获取所有以`generator`开头的变量；然后，我们可以通过变量的名称来查看每个变量代表什么。
- en: We'll do the same for the discriminator variables as well, by letting in all
    variables that start with `discriminator`. After that, we can pass the list of
    variables that we want to be optimized to the optimizer.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对鉴别器的变量也做相同的处理，允许所有以`discriminator`开头的变量。之后，我们可以将需要优化的变量列表传递给优化器。
- en: 'So the variable scope feature of TensorFlow gave us the ability to retrieve
    variables that start with a certain string, and then we can have two different
    lists of variables, one for the generator and another one for the discriminator:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，TensorFlow的变量范围功能使我们能够获取以特定字符串开头的变量，然后我们可以得到两份不同的变量列表，一份是生成器的，一份是鉴别器的：
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Model training
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练
- en: 'Now let''s kick off the training process and see how GANs will manage to generate
    images similar to the MNIST ones:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始训练过程，看看GAN是如何生成与MNIST图像相似的图像的：
- en: '[PRE13]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'After running the model for 100 epochs, we have a trained model that will be
    able to generate images similar to the original input images that we fed to the
    discriminator:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行模型100个周期后，我们得到了一个训练好的模型，它能够生成与我们输入给鉴别器的原始图像相似的图像：
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Output:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '![](img/f56c476d-c084-4820-81e9-d1571c8a5033.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f56c476d-c084-4820-81e9-d1571c8a5033.png)'
- en: 'Figure 6: Discriminator and Generator Losses'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：鉴别器和生成器的损失
- en: As shown in the preceding figure, you can see that the model losses, which are
    represented by the Discriminator and Generator lines, are converging.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，可以看到模型的损失（由鉴别器和生成器的曲线表示）正在收敛。
- en: Generator samples from training
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成器从训练中获得的样本
- en: 'Let''s test the performance of the model and even see how the generation skills
    (designing tickets for the event) of the generator got enhanced while approaching
    the end of the training process:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试一下模型的表现，甚至看看生成器在接近训练结束时，生成技能（为活动设计票据）是如何增强的：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Before plotting some generated images from the last epoch in the training process,
    we need to load the persisted file that contains generated samples at each epoch
    during the training process:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在绘制训练过程中最后一个周期生成的一些图像之前，我们需要加载包含每个周期生成样本的持久化文件：
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, let''s plot the 16 generated images from the last epoch of the training
    process and see how the generator was able to generate meaningful numbers such
    as 3, 7, and 2:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们绘制出训练过程中最后一个周期生成的16张图像，看看生成器是如何生成有意义的数字（如3、7和2）的：
- en: '[PRE18]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](img/2e23c0b1-d92c-4a30-8967-03d5a3da995e.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2e23c0b1-d92c-4a30-8967-03d5a3da995e.png)'
- en: 'Figure 7: Samples from the final training epoch'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：最终训练周期的样本
- en: 'We can even see the designing skills of the generator over different epochs.
    So let''s visualize the images that are generated by it in every 10 epochs:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以看到生成器在不同周期中的设计能力。所以，让我们可视化它在每10个周期生成的图像：
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](img/0f84e24e-868e-4667-a52c-52afb81d2dc9.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0f84e24e-868e-4667-a52c-52afb81d2dc9.png)'
- en: 'Figure 8: Images generated as the network was training, for every 10 epochs'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：网络训练过程中每10个周期生成的图像
- en: As you can see, the designing skills of the generator and its ability to generate
    fake images were very limited at first, and then it was enhanced towards the end
    of the training process.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，生成器的设计能力以及其生成假图像的能力在最开始时非常有限，之后随着训练过程的进行有所增强。
- en: Sampling from the generator
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从生成器采样
- en: 'In the previous section, we went through some examples that were generated
    during the training process of this GAN architecture. We can also generate completely
    new images from the generator by loading the checkpoints that we have saved and
    feeding the generator with a new latent space that it can use to generate new
    images:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们展示了一些在这个GAN架构训练过程中生成的示例图像。我们还可以通过加载我们保存的检查点，并给生成器提供一个新的潜在空间，让它用来生成全新的图像：
- en: '[PRE20]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![](img/a01f9682-b0f7-4eff-8906-4baaacce3ec9.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a01f9682-b0f7-4eff-8906-4baaacce3ec9.png)'
- en: 'Figure 9: Samples from the generator'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：来自生成器的样本
- en: There are some observations that you can come up with while implementing this
    example. During the first epochs of the training process, the generator doesn't
    have any skills to produce similar images to the real one because it doesn't know
    what they look like. Even the discriminator doesn't know how to distinguish between
    fake images made by the generator and the. At the beginning of training, two interesting
    situations occur. First, the generator does not know how to create images like
    the real ones that we fed originally to the network. Second, the discriminator
    doesn't know the difference between the real and fake images.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现这个例子时，你可以得出一些观察结果。在训练过程的最初几个周期里，生成器没有能力生成与真实图像相似的图像，因为它不知道这些图像是什么样子的。即使是判别器也不知道如何区分由生成器生成的假图像和真实图像。在训练开始时，会出现两种有趣的情况。首先，生成器不知道如何创建像我们最初输入到网络中的真实图像一样的图像。第二，判别器不知道真实图像和假图像之间的区别。
- en: Later on, the generator starts to fake images that make sense to some extent,
    and that's because the generator will learn the data distribution that the original
    input images are coming from. In parallel, the discriminator will be able to distinguish
    between fake and real images and it will be fooled by the end of the training
    process.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 随着训练的进行，生成器开始生成一定程度上有意义的图像，这是因为生成器会学习到原始输入图像的来源数据分布。与此同时，判别器将能够区分真假图像，最终在训练结束时被生成器所欺骗。
- en: Summary
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: GANs are being used nowadays for lots of interesting applications. GANs can
    be used for different setups such as semi-supervised and unsupervised tasks. Also,
    because of the huge number of researchers working on GANs, these models are progressing
    day by day and their ability to generate images or videos is getting better and
    better.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，GANs已经被应用于许多有趣的领域。GANs可以用于不同的设置，例如半监督学习和无监督学习任务。此外，由于大量研究人员正在致力于GANs，这些模型日益进步，生成图像或视频的能力越来越强。
- en: These kinds of models can be used for many interesting commercial applications,
    such as adding a plugin to Photoshop that can take commands like `make my smile
    more appealing`. They can also be used for image denoising.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型可以用于许多有趣的商业应用，比如为Photoshop添加一个插件，可以接受像`让我的笑容更迷人`这样的命令。它们还可以用于图像去噪。
