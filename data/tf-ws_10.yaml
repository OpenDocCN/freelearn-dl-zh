- en: 10\. Custom TensorFlow Components
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10. 自定义 TensorFlow 组件
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, you will dive a level deeper into the TensorFlow framework
    and build custom modules. By the end of it, you will know how to create custom
    TensorFlow components to use within your models, such as loss functions and layers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将更深入地了解 TensorFlow 框架，并构建自定义模块。到本章结束时，您将学会如何创建自定义的 TensorFlow 组件，并将其用于模型中，例如损失函数和层。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapters, you learned how to build CNN or RNN models from predefined
    TensorFlow modules. You have been using one of the APIs offered by TensorFlow
    called the sequential API. This API is a great way to start building "simple"
    deep learning architecture with few lines of code. But if you want to achieve
    higher performance, you may want to build your own custom architecture. In this
    case, you will need to use another API called the functional API. Researchers
    use functional APIs while defining their model architecture. By learning how to
    use it, you will be able to create custom loss functions or modules, such as a
    residual block from the ResNet architecture.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，您学习了如何从预定义的 TensorFlow 模块构建 CNN 或 RNN 模型。您一直在使用 TensorFlow 提供的 API 之一——顺序
    API。这个 API 是开始构建 "简单" 深度学习架构的一个好方法，几行代码就可以实现。但如果您想要获得更高的性能，可能需要构建自己的自定义架构。在这种情况下，您将需要使用另一个叫做函数式
    API 的 API。研究人员在定义模型架构时会使用函数式 API。通过学习如何使用它，您将能够创建自定义损失函数或模块，例如来自 ResNet 架构的残差块。
- en: TensorFlow APIs
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow APIs
- en: When using TensorFlow, you can choose from the sequential, functional, or subclassing
    APIs to define your models. For most, the sequential API will be the go-to option.
    However, as time goes by and you are exposed to more complexity, your needs will
    expand as well.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 TensorFlow 时，您可以从顺序 API、函数式 API 或子类 API 中选择来定义模型。对于大多数人来说，顺序 API 是首选。然而，随着时间的推移，当您接触到更多的复杂性时，您的需求也会扩展。
- en: The **sequential API** is the simplest API used for creating TensorFlow models.
    It works by stacking different layers one after the other. For example, you will
    create a sequential model with a first layer that's a convolution layer, followed
    by a dropout layer, and then a fully connected layer. This model is sequential
    as the input data will be passed to each defined layer sequentially.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**顺序 API** 是用于创建 TensorFlow 模型的最简单 API。它通过将不同的层一个接一个地堆叠来工作。例如，您将创建一个顺序模型，首先是卷积层，然后是
    dropout 层，最后是全连接层。这个模型是顺序的，因为输入数据将按顺序传递到每一层。'
- en: The **functional API** provides more flexibility. You can define models with
    different layers that interact with each other not in a sequential manner. For
    instance, you can create two different layers both of which will feed into a third
    one. This can be easily achieved with the functional API.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**函数式 API** 提供了更大的灵活性。您可以定义不同的层，这些层相互之间不按顺序交互。例如，您可以创建两个不同的层，它们都会输入到第三个层。这可以通过函数式
    API 轻松实现。'
- en: '`Layer` or `Model`. You can define your own custom layers or models, but this
    means you will need to comply with all the requirements of the inherited TensorFlow
    classes, such as coding mandatory methods.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '`Layer` 或 `Model`。您可以定义自己的自定义层或模型，但这意味着您需要遵守继承的 TensorFlow 类的所有要求，例如编写强制性的函数。'
- en: 'The following diagram provides a quick overview of the three different APIs
    offered by TensorFlow:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表提供了 TensorFlow 提供的三种不同 API 的快速概述：
- en: '![Figure 10.1: Diagram showing a comparison of all three APIs'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.1：显示所有三种 API 比较的图示'
- en: '](img/B16341_10_01.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_10_01.jpg)'
- en: 'Figure 10.1: Diagram showing a comparison of all three APIs'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1：显示所有三种 API 比较的图示
- en: In the section ahead, you will learn how to define a custom loss function.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，您将学习如何定义自定义损失函数。
- en: Implementing Custom Loss Functions
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现自定义损失函数
- en: 'There are several types of loss functions that are commonly used for machine
    learning. In *Chapter 5*, *Classification*, you studied different types of loss
    functions and used them with different classification models. TensorFlow has quite
    a few built-in loss functions to choose from. The following are just a few of
    the more common loss functions:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中有几种常用的损失函数。在*第 5 章*，*分类*中，您学习了不同类型的损失函数，并在不同的分类模型中使用它们。TensorFlow 提供了许多内置的损失函数可供选择。以下是一些更常见的损失函数：
- en: Mean Absolute Error (MAE)
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均绝对误差（MAE）
- en: Mean Squared Error (MSE)
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均方误差（MSE）
- en: Binary cross-entropy
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二进制交叉熵
- en: Categorical cross-entropy
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类交叉熵
- en: Hinge
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinge
- en: Huber
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huber
- en: Mean Squared Logarithmic Error (MSLE)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 均方对数误差（MSLE）
- en: As a quick reminder, you can think of loss functions as a kind of compass that
    allows you to clearly see what is working in an algorithm and what isn't. The
    higher the loss, the less accurate the model, and so on.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下，你可以将损失函数视为一种指南针，它可以帮助你清晰地了解算法中哪些部分是有效的，哪些部分是无效的。损失值越高，模型的准确度越低，反之亦然。
- en: Although TensorFlow has several loss functions available, at some point, you
    will most likely need to create your own loss function for your specific needs.
    For instance, if you are building a model that is predicting stock prices, you
    want to define a loss function that will penalize substantially incorrect values.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 TensorFlow 提供了多种现成的损失函数，但在某些情况下，你很可能需要为特定需求创建自己的损失函数。例如，如果你正在构建一个预测股票价格的模型，你可能需要定义一个损失函数，以显著惩罚那些大幅错误的预测值。
- en: The following section will show you how to build a custom loss function.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分将向你展示如何构建自定义损失函数。
- en: Building a Custom Loss Function with the Functional API
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用函数式 API 构建自定义损失函数
- en: 'You saw in the previous chapters how to use predefined loss functions from
    TensorFlow. But if you want to build your own custom functions, you can use either
    the functional API or model subclassing. Let''s say you want to build a loss function
    that will raise the difference between the predictions and the actual values to
    the power of 4:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你在前几章中看到过如何使用 TensorFlow 提供的预定义损失函数。但如果你想构建自己的自定义函数，可以使用函数式 API 或者模型子类化方法。假设你想创建一个损失函数，它将预测值与实际值之间的差异的四次方作为误差：
- en: '![Figure 10.2: Formula for custom loss'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.2：自定义损失函数的公式'
- en: '](img/B16341_10_02.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_10_02.jpg)'
- en: 'Figure 10.2: Formula for custom loss'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2：自定义损失函数的公式
- en: 'While creating a custom loss function, you will always need two arguments:
    `y_true` (actual values) and `y_pred` (predictions). A loss function will calculate
    the difference between these two values and return an error value that represents
    how far the predictions of your model are from the actual values. In the case
    of MAE, this loss function will return the absolute value of this error. On the
    other hand, MSE will square the difference between the actual value and the predicted
    value. But in the preceding example, the error should be raised to the power of
    `4`.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建自定义损失函数时，你总是需要两个参数：`y_true`（实际值）和`y_pred`（预测值）。损失函数会计算这两个值之间的差异，并返回一个误差值，表示模型的预测值与实际值之间的距离。在
    MAE 的情况下，损失函数将返回这个误差的绝对值。另一方面，MSE 会将实际值和预测值之间的差值平方。但在前面的例子中，误差应该被提升到 `4` 次方。
- en: 'Let''s see how you can implement this using the functional API. Firstly, you
    will need to import the TensorFlow library using the following command:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用函数式 API 来实现这一点。首先，你需要通过以下命令导入 TensorFlow 库：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, you will have to create a function called `custom_loss` that takes as
    input the `y_true` and `y_pred` arguments. You will then use the `pow` function
    to raise the calculated error to the power of `4`. Finally, you will return the
    calculated error:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你需要创建一个名为`custom_loss`的函数，该函数接收`y_true`和`y_pred`作为输入参数。接下来，你将使用`pow`函数将计算得到的误差的四次方。最后，你将返回计算得到的误差：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You have created your own custom loss function using the functional API. You
    can now pass it to the `compile` method, instead of the predefined loss functions,
    before training your model:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经使用函数式 API 创建了自己的自定义损失函数。现在，你可以在训练模型之前，将它传递给`compile`方法，而不是使用预定义的损失函数：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: After this, you can train your model exactly the same way as you did in previous
    chapters. TensorFlow will use your custom loss function to optimize the learning
    process of your model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些步骤后，你可以像在前几章中那样训练你的模型。TensorFlow 会使用你自定义的损失函数来优化模型的学习过程。
- en: Building a Custom Loss Function with the Subclassing API
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用子类化 API 构建自定义损失函数
- en: 'There is another way to define a custom loss function: using the subclassing
    API. In this case, rather than building a function, you will define a custom class
    for it. This is quite useful if you want to extend it with additional custom attributes
    or methods. With subclassing, you can create a custom class that will inherit
    attributes and methods from the `Loss` class of the `keras.losses` module. You
    will then need to define the `__init__()` and `call()` methods, which are required
    in the `Loss` class. The `__init__` method is where you will define all the attributes
    of your custom class, and the `call()` method is where you will specify the logic
    for calculating the loss.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另一种定义自定义损失函数的方法：使用子类化API。在这种情况下，你将定义一个自定义类，而不是创建一个函数。如果你希望添加更多自定义属性或方法，这种方法非常有用。通过子类化，你可以创建一个自定义类，该类将继承`keras.losses`模块中的`Loss`类的属性和方法。然后，你需要定义`__init__()`和`call()`方法，这是`Loss`类要求的方法。`__init__`方法是定义自定义类所有属性的地方，而`call()`方法则是你定义计算损失逻辑的地方。
- en: 'The following is a brief example of how you can implement your custom loss,
    using the subclassing API, where the error should be raised to the power of `4`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何使用子类化API实现自定义损失函数的简要示例，其中误差应提升到`4`的幂：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the preceding example, you have reimplemented the same loss function as previously
    (power of 4) but used subclassing from `keras.losses.Loss`. You started by initializing
    the attributes of your class in the `__init__()` method using the `self` parameter,
    which refers to the object itself.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，你重新实现了之前相同的损失函数（4的幂），但使用了从`keras.losses.Loss`进行子类化的方法。你首先通过`__init__()`方法初始化了类的属性，并使用`self`参数，这指向类的实例。
- en: Then, in the `call()` method, you defined the logic of your loss function, which
    calculated the error and raised it to the power of 4.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在`call()`方法中，你定义了损失函数的逻辑，它计算了误差并将其提升到4的幂。
- en: Now that you're up to speed with loss functions, it's time for you to build
    one in the next exercise.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经掌握了损失函数的基础知识，接下来是时候在下一个练习中自己动手构建一个损失函数了。
- en: 'Exercise 10.01: Building a Custom Loss Function'
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 10.01：构建自定义损失函数
- en: In this exercise, you will create your own custom loss function to train a CNN
    model to distinguish between images of apples and tomatoes.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你将创建一个自定义损失函数，用于训练一个卷积神经网络（CNN）模型，以区分苹果和西红柿的图片。
- en: You will use the `Apple-or-Tomato` dataset for this exercise. The dataset is
    a subset of the `Fruits 360` dataset on GitHub. The `Fruits 360` dataset consists
    of 1,948 total color images with dimensions of 100 by 100 pixels. The `Apple-or-Tomato`
    dataset has 992 apple images with 662 in the training set and 330 in the test
    dataset. There are a total of 956 tomato images, with 638 in the training dataset
    and 318 in the test dataset.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在本次练习中使用`Apple-or-Tomato`数据集。该数据集是GitHub上的`Fruits 360`数据集的一个子集。`Fruits 360`数据集包含1,948张总色彩图像，图像尺寸为100x100像素。`Apple-or-Tomato`数据集包含992张苹果图像，其中662张在训练集中，330张在测试集中。番茄图像总数为956张，其中638张在训练集中，318张在测试集中。
- en: '**Note**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: 'You can get the `Apple-or-Tomato` dataset at the following link: [https://packt.link/28kZY](https://packt.link/28kZY).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下链接获取`Apple-or-Tomato`数据集：[https://packt.link/28kZY](https://packt.link/28kZY)。
- en: 'You can find the `Fruits 360` dataset here: [https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip](https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到`Fruits 360`数据集：[https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip](https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip)。
- en: 'To get started, open a new Colab or Jupyter Notebook. If you are using Google
    Colab, you will need to download the dataset into your Google Drive first:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，打开一个新的Colab或Jupyter Notebook。如果你使用的是Google Colab，你需要先将数据集下载到Google Drive中：
- en: Open a new Jupyter notebook or Google Colab notebook.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Jupyter Notebook或Google Colab笔记本。
- en: 'If you are using Google Colab, upload your dataset locally with the following
    code. Otherwise, go to *step 4*. Click on `Choose Files` to navigate to the CSV
    file and click `Open`. Save the file as `uploaded`. Then, go to the folder where
    you have saved the dataset:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你使用的是Google Colab，请使用以下代码将数据集本地上传。否则，请跳到*步骤4*。点击`Choose Files`选择CSV文件并点击`Open`。保存文件为`uploaded`。然后，进入你保存数据集的文件夹：
- en: '[PRE4]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Unzip the dataset in the current folder:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在当前文件夹中解压数据集：
- en: '[PRE5]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Create a variable, `directory`, that contains the path to the dataset:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量`directory`，它包含数据集的路径：
- en: '[PRE6]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Import the `pathlib` library:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pathlib`库：
- en: '[PRE7]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Create a variable, `path`, that contains the full path to the dataset using
    `pathlib.Path`:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量`path`，该变量使用`pathlib.Path`包含数据集的完整路径：
- en: '[PRE8]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Create two variables, `train_dir` and `validation_dir`, that take the full
    paths to the train and validation folders, respectively:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个变量，`train_dir`和`validation_dir`，并分别赋予训练和验证文件夹的完整路径：
- en: '[PRE9]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Create four variables, `train_apple_dir`, `train_tomato_dir`, `validation_apple_dir`,
    and `validation_tomato_dir`, that take the full paths to the `apple` and `tomato`
    folders for the train and validation sets, respectively:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建四个变量，分别为`train_apple_dir`、`train_tomato_dir`、`validation_apple_dir`和`validation_tomato_dir`，它们将分别获取训练和验证集中的`apple`和`tomato`文件夹的完整路径：
- en: '[PRE10]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Import the `os` package:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`os`包：
- en: '[PRE11]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Create two variables, called `total_train` and `total_val`, that will get the
    number of images for the training and validation sets, respectively:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个变量，分别为`total_train`和`total_val`，它们将获取训练集和验证集中的图像数量：
- en: '[PRE12]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Import `ImageDataGenerator` from the `tensorflow.keras.preprocessing` module:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tensorflow.keras.preprocessing`模块导入`ImageDataGenerator`：
- en: '[PRE13]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Instantiate two `ImageDataGenerator` classes, `train_image_generator` and `validation_image_generator`,
    that will rescale the images by dividing by 255:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化两个`ImageDataGenerator`类，分别为`train_image_generator`和`validation_image_generator`，它们将通过除以255来重新缩放图像：
- en: '[PRE14]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create three variables, called `batch_size`, `img_height`, and `img_width`,
    that take the values `32`, `224`, and `224`, respectively:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建三个变量，分别为`batch_size`、`img_height`和`img_width`，并将它们的值设置为`32`、`224`和`224`：
- en: '[PRE15]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create a data generator called `train_data_gen`, using `     flow_from_directory()`, and specify the batch size, the path to the training folder,
    the value of the `shuffle` parameter, the size of the target, and the class mode:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`flow_from_directory()`创建一个名为`train_data_gen`的数据生成器，并指定批量大小、训练文件夹的路径、`shuffle`参数的值、目标的大小和类模式：
- en: '[PRE16]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create a data generator called `val_data_gen` using `     flow_from_directory()` and specify the batch size, the path to the validation
    folder, the size of the target, and the class mode:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`flow_from_directory()`创建一个名为`val_data_gen`的数据生成器，并指定批量大小、验证文件夹的路径、目标大小和类模式：
- en: '[PRE17]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Import `matplotlib` and create a `for` loop that will iterate through five
    images from `train_data_gen` and plot them:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`matplotlib`并创建一个`for`循环，该循环将遍历`train_data_gen`中的五张图像并绘制它们：
- en: '[PRE18]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You should get the following output:'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 10.3: Sample of images from the dataset'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 10.3：数据集中的图像样本'
- en: '](img/B16341_10_03a.jpg)![10.3 b](img/B16341_10_03b.jpg)![Figure 10.3: Sample
    of images from the dataset'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_10_03a.jpg)![10.3 b](img/B16341_10_03b.jpg)![图 10.3：数据集中的图像样本'
- en: '](img/B16341_10_03c.jpg)'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_10_03c.jpg)'
- en: 'Figure 10.3: Sample of images from the dataset'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.3：数据集中的图像样本
- en: The preceding results show some examples of the images contained in this dataset.
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述结果展示了该数据集中一些包含的图像示例。
- en: 'Import the TensorFlow library:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入TensorFlow库：
- en: '[PRE19]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Create your custom loss function that will square the calculated error:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建自定义损失函数，该函数将计算误差的平方：
- en: '[PRE20]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Import the `NASNetMobile` model from the `tensorflow.keras.applications` module:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tensorflow.keras.applications`模块导入`NASNetMobile`模型：
- en: '[PRE21]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Instantiate this model with the ImageNet weights, remove the top layer, and
    specify the right input dimensions:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用ImageNet权重实例化此模型，移除顶部层，并指定正确的输入维度：
- en: '[PRE22]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Freeze all the layers of this model so that you are not going to update the
    model weights of `NASNetMobile`:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 冻结此模型的所有层，以确保不会更新`NASNetMobile`的模型权重：
- en: '[PRE23]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Import the `Flatten` and `Dense` layers from the `tensorflow.keras.layers`
    module:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tensorflow.keras.layers`模块导入`Flatten`和`Dense`层：
- en: '[PRE24]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Create a new model that combines the `NASNetMobile` model with two new top
    layers (with 500 and 1 units, respectively) and ReLu and sigmoid as activation functions:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新模型，将`NASNetMobile`模型与两个新的顶部层（分别有500个和1个单元）以及ReLu和sigmoid作为激活函数进行组合：
- en: '[PRE25]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Print the summary of your model:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印你的模型摘要：
- en: '[PRE26]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You will get the following output:'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将得到以下输出：
- en: '![Figure 10.4: Model summary'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 10.4：模型总结'
- en: '](img/B16341_10_04.jpg)'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_10_04.jpg)'
- en: 'Figure 10.4: Model summary'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.4：模型总结
- en: 'Here, you can see the layers on the left-hand side. You have `Output Shape`
    shown—for example, `(None, 224, 224, 3)`. Then, the number of parameters is shown
    under `Param #`. At the bottom, you will find the summary, including trainable
    and non-trainable parameters.'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '在这里，你可以看到左侧的层。你会看到`Output Shape`—例如，`(None, 224, 224, 3)`。接下来，`Param #`下方显示了参数的数量。在底部，你将找到摘要，包括可训练和不可训练的参数。'
- en: 'Compile this model by providing your custom loss function, with Adam as the
    optimizer and accuracy as the metric to be displayed:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过提供自定义损失函数、Adam优化器和精度度量，来编译此模型并显示结果：
- en: '[PRE27]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Fit the model and provide the train and validation data generators, the number
    of steps per epoch, and the number of validation steps:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合模型并提供训练和验证数据生成器、每个epoch的步数以及验证步骤的数量：
- en: '[PRE28]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You should get the following output:'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 10.5: Screenshot of training progress'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图10.5：训练进度截图'
- en: '](img/B16341_10_05.jpg)'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_10_05.jpg)'
- en: 'Figure 10.5: Screenshot of training progress'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5：训练进度截图
- en: The preceding screenshot shows the information displayed by TensorFlow during
    the training of your model. You can see the accuracy achieved on the training
    and validation sets for each epoch. On the fifth epoch, the model is `96%` accurate
    on both the training set and the validation set.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的截图显示了TensorFlow在训练模型期间显示的信息。你可以看到每个epoch在训练集和验证集上达到的准确度。在第五个epoch时，模型在训练集和验证集上的准确度均为`96%`。
- en: In this exercise, you have successfully built your own loss function and trained
    a binary classifier with it to recognize images of apples or tomatoes. In the
    following section, you will take it a step further and build your own custom layers.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你已经成功地构建了自己的损失函数，并用它训练了一个二分类器，识别苹果或番茄的图像。在接下来的章节中，你将更进一步，构建你自己的自定义层。
- en: Implementing Custom Layers
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现自定义层
- en: Previously, you looked at implementing your own custom loss function with either
    the TensorFlow functional API or the subclassing approach. These concepts can
    also be applied to creating custom layers for a deep learning model. In this section,
    you will build a ResNet module from scratch.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，你已经学习了如何使用TensorFlow的功能性API或子类化方法实现自定义损失函数。这些概念也可以应用于为深度学习模型创建自定义层。在本节中，你将从零开始构建一个ResNet模块。
- en: Introduction to ResNet Blocks
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ResNet块简介
- en: '**Residual neural network**, or **ResNet**, was first proposed by *Kaiming
    He* in his paper *Deep Residual Learning for Image Recognition* in 2015\. He introduced
    a new concept called a residual block that tackles the problem of vanishing gradients,
    which limits the ability of training very deep networks (with a lot of layers).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**残差神经网络**，或称**ResNet**，最早由*何恺明*在2015年的论文《深度残差学习用于图像识别》中提出。他引入了一个新的概念——残差块，用以解决梯度消失问题，这一问题限制了训练非常深的网络（具有大量层）的能力。'
- en: A residual block is composed of multiple layers. But instead of having a single
    path where each layer is stacked and executed sequentially, a residual block contains
    two different paths. The first path has two different convolution layers. The
    second path, called the **skip connection**, takes the input and forwards it to
    the last layer of the first path. So, the input of a residual block will go through
    the first path with the sequence of convolution layers, and its result will be
    combined with the original input coming from the second path (skip connection),
    as shown in *Figure 10.6*. Without going too much into the mathematical details,
    this extra path allows the architecture to pass through the gradients in a deeper
    layer without impacting the overall performance.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 一个残差块由多个层组成。但不同于将每一层堆叠并顺序执行的单一路径，残差块包含两条不同的路径。第一条路径有两个不同的卷积层。第二条路径，称为**跳跃连接**，将输入传递给第一条路径的最后一层。因此，残差块的输入将经过第一条路径的卷积层序列，结果将与来自第二条路径（跳跃连接）的原始输入结合，如*图10.6*所示。简言之，这条额外的路径允许架构在更深层次上传递梯度，而不会影响整体性能。
- en: '![Figure 10.6: Skip connection'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.6：跳跃连接'
- en: '](img/B16341_10_06.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_10_06.jpg)'
- en: 'Figure 10.6: Skip connection'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6：跳跃连接
- en: As you can see, if you want to build an architecture for the preceding residual
    block, it will be quite hard with the TensorFlow sequential API. Here, you need
    to build a very customized layer. This is the reason why you need to use either
    the functional API or model subclassing instead.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，如果你想为前面的残差块构建一个架构，使用TensorFlow的顺序API会相当困难。这里，你需要构建一个非常定制化的层。这就是为什么你需要使用功能性API或模型子类化的方法。
- en: Building Custom Layers with the Functional API
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用功能性API构建自定义层
- en: In this section, you will see how to use the TensorFlow functional API to build
    a custom layer.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何使用TensorFlow的功能性API来构建自定义层。
- en: 'To start, you will build a function that takes your input as a tensor and adds
    ReLU and batch normalization to it. For example, in the following code snippet,
    the `relu_batchnorm_layer` function takes input and then returns a tensor. This
    makes a composite layer with ReLU activation and batch normalization in succession:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你将构建一个函数，该函数将输入作为张量并对其添加 ReLU 激活和批量归一化。例如，在下面的代码片段中，`relu_batchnorm_layer`
    函数接收输入并返回一个张量。这将创建一个包含 ReLU 激活和批量归一化的复合层：
- en: '[PRE29]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, create a function for your residual block. You''ll need to take a tensor
    as input and pass it to two Conv2D layers. Then, you will add the output of the
    second Conv2D layer to the original input, which represents the skip connection.
    The output of this addition will then be passed to the `relu_batchnorm_layer()`
    function that you defined in the preceding code snippet. The output will be given
    to another Conv2D layer:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，创建一个函数来实现你的残差块。你需要接收一个张量作为输入，并将其传递给两个 Conv2D 层。然后，你将第二个 Conv2D 层的输出与原始输入相加，这代表了跳跃连接。该加法的输出将传递给你在前面代码片段中定义的
    `relu_batchnorm_layer()` 函数。最后，输出将传递给另一个 Conv2D 层：
- en: '[PRE30]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, you can use this custom layer in your model. In the following code snippet,
    you will define a simple model with a Conv2D layer followed by a residual block:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以在模型中使用这个自定义层。在以下代码片段中，你将定义一个简单的模型，其中包含一个 Conv2D 层，后跟一个残差块：
- en: '[PRE31]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Let's now build custom layers using subclassing in the following section.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在下面的章节中使用子类化来构建自定义层。
- en: Building Custom Layers with Subclassing
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用子类化构建自定义层
- en: Previously, you looked at how to create a simplified version of a residual block
    using the functional API. Now, you will see how to use model subclassing to create
    a custom layer.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，你已经学习了如何使用函数式 API 创建简化版的残差块。现在，你将看到如何使用模型子类化来创建自定义层。
- en: 'To begin, you need to import the `Model` class together with a few layers:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要导入 `Model` 类和一些层：
- en: '[PRE32]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Then, you use model subclassing to create a model with two dense layers. Firstly,
    define a model subclass denoted as `MyModel`. The objects that you will generate
    from this class are models with two dense layers.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你将使用模型子类化来创建一个包含两个全连接层的模型。首先，定义一个名为 `MyModel` 的模型子类。从这个类生成的对象将是具有两个全连接层的模型。
- en: 'Define the two dense layers within the `init` method. For instance, the first
    one can have `64` units and the ReLU activation function, while the second one
    can have `10` units without an activation function (in this case, the default
    activation function used is the linear one). After this, in the `call` method,
    you set up the forward pass by calling the previously defined dense layers. Firstly,
    you can place the `dense_1` layer to take the inputs and after it, the `dense_2`
    layer that returns the outputs of the layer:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `init` 方法中定义两个全连接层。例如，第一个可以有 `64` 个单元并使用 ReLU 激活函数，而第二个可以有 `10` 个单元并且没有激活函数（在这种情况下，默认的激活函数是线性函数）。之后，在
    `call` 方法中，通过调用之前定义的全连接层来设置前向传播。首先，你可以放置 `dense_1` 层来接收输入，接着是 `dense_2` 层，它返回层的输出：
- en: '[PRE33]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The next step is to instantiate the model. For this, just call the class with
    no argument inside the brackets. Next, call the model on a random input to create
    the weights. For the input, this example uses a one-dimensional vector with `10`
    elements, but feel free to use a different input. You can then print the summary
    of the model where you can see the dense layers that you defined before.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是实例化模型。为此，只需在括号内调用类，不带参数。接下来，用随机输入调用模型以创建权重。对于输入，本例使用一个包含 `10` 个元素的一维向量，但你也可以使用不同的输入。然后，你可以打印模型的摘要，查看之前定义的全连接层。
- en: 'Consider the following model summary:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下模型摘要：
- en: '[PRE34]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The resulting output should be like the following:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的输出应如下所示：
- en: '![Figure 10.7: Model summary'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.7：模型概述'
- en: '](img/B16341_10_07.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_10_07.jpg)'
- en: 'Figure 10.7: Model summary'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7：模型概述
- en: 'Now, you can modify the `call` method by including a keyword argument called
    `training`. This is useful if you want to have different behaviors in training
    and inference. For example, you can create a dropout layer that will be activated
    only if `training` is `true`. Firstly, you need to define a dropout layer within
    the `init` method, given your learning rate of `0.4`. Then, in the `call` method,
    write an `if` clause with the `training` keyword is set to `true` by default.
    Inside it, just call the dropout layer:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以通过添加一个名为 `training` 的关键字参数来修改 `call` 方法。如果你希望在训练和推理时有不同的行为，这将非常有用。例如，你可以创建一个只有在
    `training` 为 `true` 时才会激活的 dropout 层。首先，你需要在 `init` 方法中定义一个 dropout 层，并设置学习率为
    `0.4`。然后，在 `call` 方法中，写一个 `if` 语句，默认情况下 `training` 为 `true`。在其中，调用 dropout 层：
- en: '[PRE35]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, consider the model summary:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑模型总结：
- en: '[PRE36]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The summary is displayed as follows, upon running the preceding command:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 执行上述命令后，模型总结将如下所示：
- en: '![Figure 10.8: Model summary'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.8：模型总结'
- en: '](img/B16341_10_08.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_10_08.jpg)'
- en: 'Figure 10.8: Model summary'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8：模型总结
- en: In the following exercise, you will build a custom layer.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下练习中，你将构建一个自定义层。
- en: 'Exercise 10.02: Building a Custom Layer'
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 10.02：构建自定义层
- en: The `Healthy-Pneumonia` dataset is a subset of the `National Institute for Health
    NIH` dataset. The dataset consists of 9,930 total color images with dimensions
    of 100 by 100 pixels. The `pneumonia-or-healthy` dataset has 1,965 total healthy
    images with 1,375 images in the training dataset and 590 images in the test dataset.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '`Healthy-Pneumonia` 数据集是 `National Institute for Health NIH` 数据集的一个子集。该数据集包含
    9,930 张总共 100x100 像素的彩色图像。`pneumonia-or-healthy` 数据集包含 1,965 张健康图像，其中训练集有 1,375
    张图像，测试集有 590 张图像。'
- en: You will create a custom ResNet block that consists of a Conv2D layer, a batch
    normalization layer, and a ReLU activation function. You will perform binary classification
    on the images to distinguish between healthy and pneumonic images.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 你将创建一个自定义的 ResNet 块，包含一个 Conv2D 层、一个批归一化层和一个 ReLU 激活函数。你将对图像进行二分类，以区分健康图像和肺炎图像。
- en: Note
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can get the `pneumonia-or-healthy` dataset here: [https://packt.link/IOpUX](https://packt.link/IOpUX).'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里获取 `pneumonia-or-healthy` 数据集：[https://packt.link/IOpUX](https://packt.link/IOpUX)。
- en: 'To get started, open a new Colab or Jupyter Notebook. If you are using Google
    Colab, you will need to download the dataset into your Google Drive first:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，打开一个新的 Colab 或 Jupyter Notebook。如果你使用的是 Google Colab，你需要先将数据集下载到你的 Google
    Drive 中：
- en: Open a new Jupyter notebook or Google Colab.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter notebook 或 Google Colab。
- en: 'If you are using Google Colab, you can upload your dataset locally with the
    following code. Otherwise, go to *step 4*. Click on `Choose Files` to navigate
    to the CSV file and click `Open`. Save the file as `uploaded`. Then, go to the
    folder where you saved the dataset:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你使用的是 Google Colab，可以使用以下代码在本地上传数据集。否则，请转到 *第 4 步*。点击 `Choose Files`，找到 CSV
    文件并点击 `Open`。将文件保存为 `uploaded`，然后进入你保存数据集的文件夹：
- en: '[PRE37]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Unzip the dataset in the current folder:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在当前文件夹中解压数据集：
- en: '[PRE38]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Create a variable, `directory`, that contains the path to the dataset:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量 `directory`，它包含数据集的路径：
- en: '[PRE39]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Import the `pathlib` library:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pathlib` 库：
- en: '[PRE40]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Create a variable, `path`, that contains the full path to the data using `pathlib.Path`:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量 `path`，它使用 `pathlib.Path` 包含数据的完整路径：
- en: '[PRE41]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Create two variables, called `train_dir` and `validation_dir`, that take the
    full paths to the train and validation folders, respectively:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个变量，分别为 `train_dir` 和 `validation_dir`，它们分别存储训练集和验证集文件夹的完整路径：
- en: '[PRE42]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Create four variables, called `train_healthy_dir`, `train_pneumonia_dir`, `validation_healthy_dir`,
    and `validation_pneumonia_dir`, that take the full paths to the healthy and pneumonia
    folders for the train and validation sets, respectively:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建四个变量，分别为 `train_healthy_dir`、`train_pneumonia_dir`、`validation_healthy_dir`
    和 `validation_pneumonia_dir`，它们分别存储训练集和验证集的健康和肺炎文件夹的完整路径：
- en: '[PRE43]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Import the `os` package:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `os` 包：
- en: '[PRE44]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Create two variables, called `total_train` and `total_val`, to get the number
    of images for the training and validation sets, respectively:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个变量，分别为 `total_train` 和 `total_val`，用来获取训练集和验证集中的图像数量：
- en: '[PRE45]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Import `ImageDataGenerator` from `tensorflow.keras.preprocessing`:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `tensorflow.keras.preprocessing` 导入 `ImageDataGenerator`：
- en: '[PRE46]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Instantiate two `ImageDataGenerator` classes and call them `train_image_generator`
    and `validation_image_generator`, which will rescale the images by dividing by
    255:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化两个 `ImageDataGenerator` 类，并分别命名为 `train_image_generator` 和 `validation_image_generator`，它们将通过除以
    255 来重新缩放图像：
- en: '[PRE47]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Create three variables, called `batch_size`, `img_height`, and `img_width`,
    that take the values `32`, `100`, and `100`, respectively:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建三个变量，分别命名为`batch_size`、`img_height`和`img_width`，其值分别为`32`、`100`和`100`：
- en: '[PRE48]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Create a data generator called `train_data_gen` using `     flow_from_directory()` and specify the batch size, the path to the training folder,
    the value of the `shuffle` parameter, the size of the target, and the class mode:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`flow_from_directory()`创建一个名为`train_data_gen`的数据生成器，并指定批量大小、训练文件夹的路径、`shuffle`参数的值、目标大小和类别模式：
- en: '[PRE49]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Create a data generator called `val_data_gen` using `     flow_from_directory()` and specify the batch size, the path to the validation
    folder, the size of the target, and the class mode:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`flow_from_directory()`创建一个名为`val_data_gen`的数据生成器，并指定批量大小、验证文件夹的路径、目标大小和类别模式：
- en: '[PRE50]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Import `matplotlib` and create a `for` loop that will iterate through five
    images from `train_data_gen` and plot them:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`matplotlib`并创建一个`for`循环，该循环将遍历`train_data_gen`中的五张图像并绘制它们：
- en: '[PRE51]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'You should see the following output:'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该看到以下输出：
- en: '![Figure 10.9: Sample of images from the dataset'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 10.9：数据集中样本图像'
- en: '](img/B16341_10_09a.jpg)![10.9 b](img/B16341_10_09b.jpg)![10.9 c](img/B16341_10_09c.jpg)'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_10_09a.jpg)![10.9 b](img/B16341_10_09b.jpg)![10.9 c](img/B16341_10_09c.jpg)'
- en: 'Figure 10.9: Sample of images from the dataset'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.9：数据集中样本图像
- en: The preceding results show some examples of the images contained in this dataset.
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述结果展示了该数据集中包含的部分图像示例。
- en: 'Import the TensorFlow library:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入TensorFlow库：
- en: '[PRE52]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Import `Input`, `Conv2D`, `ReLU`, `BatchNormalization`, `Add`, `AveragePooling2D`,
    `Flatten`, and `Dense`:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`Input`、`Conv2D`、`ReLU`、`BatchNormalization`、`Add`、`AveragePooling2D`、`Flatten`和`Dense`：
- en: '[PRE53]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Build a function that takes your input as a tensor and adds ReLU and batch
    normalization to it:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个函数，该函数将输入作为张量并向其添加ReLU和批量归一化：
- en: '[PRE54]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Create a function to build your residual block. You will need to take a tensor
    (`input`) as your input and pass it to two Conv2D layers with a stride of `2`.
    Next, add the input to the output, followed by ReLU and batch normalization, returning
    a tensor. Add another Conv2D layer with `kernel_size=1`. Add its result to the
    output of the previous Conv2D layer. Finally, apply `relu_batchnorm_layer()` and
    return its value. You will apply the exact same filters (numbers and dimensions
    are defined by two input parameters of the construction function) to all Conv2D
    layers:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数来构建残差块。你需要将一个张量（`input`）作为输入，并将其传递给两个步幅为`2`的Conv2D层。接下来，将输入添加到输出中，然后进行ReLU和批量归一化，返回一个张量。再添加一个`kernel_size=1`的Conv2D层。将其结果添加到前一个Conv2D层的输出中。最后，应用`relu_batchnorm_layer()`并返回其值。你将对所有Conv2D层应用完全相同的滤波器（数量和维度由构造函数的两个输入参数定义）：
- en: '[PRE55]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Import the `Model` module:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`Model`模块：
- en: '[PRE56]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Use `keras.layers.Input()` to define the input layer to the model. Here, your
    shape is 100 pixels by 100 pixels and has three colors (RGB):'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`keras.layers.Input()`定义模型的输入层。这里，输入的形状为100像素×100像素，并且有三种颜色（RGB）：
- en: '[PRE57]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Apply batch normalization to the input, followed by a Conv2D layer with `32`
    filters of size `3*3`, stride `1`, and `same` padding. Finally, apply the `relu_batchnorm_layer()`
    function to its output:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对输入应用批量归一化，接着应用一个`32`个滤波器、大小为`3*3`、步幅为`1`、填充为`same`的Conv2D层。最后，对其输出应用`relu_batchnorm_layer()`函数：
- en: '[PRE58]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Provide the output of the previous layer to the `residual_block()` function
    with `32` filters. Then, pass its output an average pooling layer with four units
    and then flatten its results before feeding it to a fully connected layer of `1`
    unit with sigmoid as the activation function:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将前一层的输出传递给`residual_block()`函数，使用`32`个滤波器。然后，传递其输出到一个具有四个单元的平均池化层，接着将其结果展平，并将其传递给一个包含`1`个单元的全连接层，激活函数为sigmoid：
- en: '[PRE59]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Instantiate a `Model()` class with the original input and the output of the
    fully connected layer:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个`Model()`类，使用原始输入和全连接层的输出：
- en: '[PRE60]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Get the summary of your model:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取模型的摘要：
- en: '[PRE61]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'You will see a summary, including trainable and non-trainable parameters, as follows:'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将看到一个摘要，包含可训练和不可训练的参数，如下所示：
- en: '![Figure 10.10: Model summary'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 10.10：模型摘要'
- en: '](img/B16341_10_10.jpg)'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_10_10.jpg)'
- en: 'Figure 10.10: Model summary'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 10.10：模型摘要
- en: 'Compile the model by providing binary cross-entropy as the loss function, Adam
    as the optimizer, and accuracy as the metric to be displayed:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译模型，提供二元交叉熵作为损失函数，Adam作为优化器，并将准确度作为显示的度量：
- en: '[PRE62]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Fit the model and provide the train and validation data generators, the number
    of epochs, the steps per epoch, and the validation steps:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型并提供训练和验证数据生成器、训练周期数、每周期的步骤数和验证步骤：
- en: '[PRE63]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'You should get output like the following:'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该获得如下输出：
- en: '![Figure 10.11: Screenshot of training progress'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 10.11：训练进度截图'
- en: '](img/B16341_10_11.jpg)'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_10_11.jpg)'
- en: 'Figure 10.11: Screenshot of training progress'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.11：训练进度截图
- en: The preceding screenshot shows the information displayed by TensorFlow during
    the training of your model. You can see the accuracy achieved on the training
    and validation sets for each epoch.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的截图展示了 TensorFlow 在训练模型过程中显示的信息。你可以看到每个 epoch 在训练集和验证集上达成的准确度。
- en: In this exercise, you created your own custom layer for the network. Now, let's
    test the knowledge you have gained so far in the following activity.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，你为网络创建了自己的自定义层。现在，让我们通过以下活动来测试你迄今为止学到的知识。
- en: 'Activity 10.01: Building a Model with Custom Layers and a Custom Loss Function'
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 10.01：构建带有自定义层和自定义损失函数的模型
- en: The `table-or-glass` dataset is a subset of images taken from the `Open Images
    V6` dataset. The `Open Images V6` dataset has around 9 million images. The `table-or-glass`
    dataset consists of 7,484 total color images with dimensions of 100 by 100 pixels.
    The `table-or-glass` dataset has 3,741 total glass images with 2,618 in the training
    and 1,123 in the test dataset. There are a total of 3,743 table images with 2,618
    in the training and 1,125 in the test dataset. You are required to train a more
    complex model that can distinguish images of glasses and tables using custom ResNet
    blocks and a custom loss function.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '`table-or-glass` 数据集是从 `Open Images V6` 数据集中提取的一部分图像。`Open Images V6` 数据集包含约
    900 万张图像。`table-or-glass` 数据集由 7,484 张总颜色图像组成，每张图像的尺寸为 100×100 像素。`table-or-glass`
    数据集包含 3,741 张玻璃图像，其中 2,618 张在训练集，1,123 张在测试集中。总共有 3,743 张桌面图像，其中 2,618 张在训练集，1,125
    张在测试集中。你需要训练一个更复杂的模型，能够使用自定义的 ResNet 块和自定义损失函数区分玻璃和桌面图像。'
- en: Note
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find the dataset here: [https://packt.link/bE5F6](https://packt.link/bE5F6).'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到数据集：[https://packt.link/bE5F6](https://packt.link/bE5F6)。
- en: 'The following steps will help you to complete this activity:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成本次活动：
- en: Import the dataset and unzip the file into a local folder.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入数据集并将文件解压到本地文件夹。
- en: Create the list of images for both the training and testing sets.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为训练集和测试集创建图像列表。
- en: Analyze the distribution of the target variable.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析目标变量的分布。
- en: Preprocess the images (standardization and reshaping).
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对图像进行预处理（标准化和重塑）。
- en: Create a custom loss function that will calculate the average squared error.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个自定义损失函数，用于计算平均平方误差。
- en: Create a custom residual block constructor function.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个自定义的残差块构造函数。
- en: Train your model.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练你的模型。
- en: Print the learning curves for accuracy and loss.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印准确度和损失的学习曲线。
- en: Note
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor283).
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本次活动的解决方案可以通过[此链接](B16341_Solution_ePub.xhtml#_idTextAnchor283)找到。
- en: Summary
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter demonstrated how to build and utilize custom TensorFlow components.
    You learned how to design and implement custom loss functions, layers, and residual
    blocks. Using the TensorFlow functional API or model subclassing allows you to
    build more complex deep learning models that may be a better fit for your projects.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 本章展示了如何构建和利用自定义的 TensorFlow 组件。你学会了如何设计和实现自定义损失函数、层和残差块。使用 TensorFlow 的功能性 API
    或模型子类化，使你能够构建更复杂的深度学习模型，这些模型可能更适合你的项目。
- en: In the next and final chapter, you will explore and build generative models
    that can learn patterns and relationships within data, and use those relationships
    to generate new, unique data.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，也是最后一章中，你将探索并构建生成模型，这些模型能够学习数据中的模式和关系，并利用这些关系生成新的、独特的数据。
