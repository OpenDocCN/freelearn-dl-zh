- en: '*Chapter 4*'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 4 章*'
- en: Foundations of Convolutional Neural Network
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络的基础
- en: Learning Objectives
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习目标
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Describe the inspiration for CNNs in neural science
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述 CNN 在神经科学中的灵感来源
- en: Describe the convolution operations
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述卷积操作
- en: Describe a basic CNN architecture for a classification task
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述一个基本的 CNN 架构用于分类任务
- en: Implement a simple CNN for image and text classification tasks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现一个简单的 CNN 用于图像和文本分类任务
- en: Implement a CNN for a sentiment analysis of text
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现一个用于文本情感分析的 CNN
- en: In this chapter, we aim to cover the architecture of convolutional neural networks
    (CNNs) and gain an intuition of CNNs based on their applications on image data,
    before delving into their applications in natural language processing.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们旨在涵盖卷积神经网络（CNN）的架构，并通过其在图像数据上的应用来获得对 CNN 的直觉，随后再深入探讨它们在自然语言处理中的应用。
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: Neural networks, as a broad field, borrow a lot from biological systems, particularly
    the brain. Advances in neural science have directly influenced research in to
    neural networks.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络作为一个广泛的领域，从生物系统，特别是大脑中汲取了很多灵感。神经科学的进展直接影响了神经网络的研究。
- en: CNNs are inspired by the work of two neural scientists, D.H. Hubel and T.N.
    Wiesel. Their research focused on the mammalian visual cortex, which is the part
    of the brain responsible for vision. Through their research back in the sixties,
    they found that the visual cortex is composed of layers of neurons. Furthermore,
    these layers are arranged in a hierarchical structure. This hierarchy ranges from
    simple-to hypercomplex neurons. They also advanced the notion of a 'receptive
    field,' which is the space within which certain stimuli activate or fire a neuron,
    with a degree of spatial invariance. Spatial or shift invariance allows animals
    to detect objects regardless of whether they are rotated, scaled, transformed,
    or partially obscured.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 的灵感来源于两位神经科学家的研究，D.H. Hubel 和 T.N. Wiesel。他们的研究集中在哺乳动物的视觉皮层，这是大脑中负责视觉的部分。在上世纪六十年代的研究中，他们发现视觉皮层由多层神经元组成。此外，这些层次是以一种层级结构排列的。这个层级从简单的神经元到超复杂的神经元都有。他们还提出了“感受野”的概念，即某些刺激能够激活或触发一个神经元的空间范围，具有一定的空间不变性。空间或位移不变性使得动物能够识别物体，无论它们是旋转、缩放、变换，还是部分遮挡。
- en: '![Figure 4.1: Examples of spatial variance'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.1：空间变化的示例'
- en: '](img/C13783_04_01.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_04_01.jpg)'
- en: 'Figure 4.1: Examples of spatial variance'
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.1：空间变化的示例
- en: Inspired by neural concepts of how animals see, computer vision scientists have
    modelled neural networks that adhere to the same principles of locality, hierarchy,
    and spatial invariance. We will dive deeper into the architecture of CNNs in the
    next section.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 受到动物视觉神经概念的启发，计算机视觉科学家们构建了遵循局部性、层次性和空间不变性相同原则的神经网络。我们将在下一节深入探讨 CNN 的架构。
- en: CNNs are a subset of neural networks that contain one or more 'convolution'
    layers. Typical neural networks are fully connected, which means every neuron
    is connected to every neuron in the next layer. When dealing with high-dimensional
    data such as images, sound, and so on, typical neural networks are slow and tend
    to overfit as there are too many weights being learned. Convolutional layers solve
    this problem by connecting a neuron to a region of the input in lower layers.
    We will discuss convolution layers in greater detail in the next section.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 是神经网络的一个子集，包含一个或多个“卷积”层。典型的神经网络是全连接的，意味着每个神经元都与下一层中的每个神经元连接。当处理高维数据（如图像、声音等）时，典型的神经网络运行较慢，并且容易过拟合，因为学习的权重太多。卷积层通过将神经元与低层输入的一个区域连接来解决这个问题。我们将在下一节中更详细地讨论卷积层。
- en: To understand the general architecture of CNNs, we will first apply them to
    the task of image classification and then, subsequently, to natural language processing.
    To begin, we'll do a small exercise to understand how computers see images.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解 CNN 的一般架构，我们将首先将其应用于图像分类任务，然后再应用于自然语言处理。首先，我们将做一个小练习来理解计算机是如何看待图像的。
- en: 'Exercise 18: Finding Out How Computers See Images'
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 18：了解计算机如何看待图像
- en: Images and text share an important similarity. The location of a pixel in an
    image, or a word in text, matters. This spatial significance makes applying convolutional
    neural networks possible for both text and images.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图像和文本有一个重要的相似性。图像中一个像素的位置，或文本中的一个单词位置，都很重要。这种空间上的意义使得卷积神经网络可以同时应用于文本和图像。
- en: In this exercise, we want to determine how computers interpret images. We will
    do this by using the **MNIST** dataset, which contains a repository of handwritten
    digits perfect for demonstrating CNNs.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们希望确定计算机如何解读图像。我们将使用 **MNIST** 数据集，它包含手写数字，非常适合演示 CNN。
- en: Note
  id: totrans-22
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: MNIST is a built-in Keras dataset.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST 是一个内置的 Keras 数据集。
- en: 'You will need to have both Python and Keras installed. For easier visualization,
    you can run your code in a Jupyter notebook:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要安装 Python 和 Keras。为了更方便地可视化，你可以在 Jupyter notebook 中运行代码：
- en: 'Start by importing the necessary classes:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先导入必要的类：
- en: '[PRE0]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Since we''ll be using this dataset throughout the chapter, we will import the
    training and test sets as shown here:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们将在整个章节中使用该数据集，因此我们将按如下方式导入训练集和测试集：
- en: '[PRE1]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Visualize the first image in the dataset:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化数据集中的第一张图像：
- en: '[PRE2]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Running the preceding code should result in an image being visualized, as shown
    here:'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行前面的代码应该会显示出图像，如下所示：
- en: '![Figure 4.2: Visualization of an image](img/C13783_04_02.jpg)'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.2: 图像的可视化](img/C13783_04_02.jpg)'
- en: 'Figure 4.2: Visualization of an image'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 4.2: 图像的可视化'
- en: 'The images are 28 by 28 pixels, with each pixel being a number between 0 and
    255\. Try playing around with different indices to display their values as follows.
    You can do this by putting arbitrary numbers between `0` and `255` as `x` and
    `y` in:'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些图像为 28x28 像素，每个像素的值在 0 到 255 之间。尝试修改不同的索引来显示它们的值，如下所示。你可以通过将任意数字在 `0` 和 `255`
    之间作为 `x` 和 `y` 来实现：
- en: '[PRE3]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When you run the print code as follows, expect to see numbers between 0 and
    255:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你运行以下打印代码时，应该会看到 0 到 255 之间的数字：
- en: '[PRE4]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Expected Output:**'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**预期输出：**'
- en: '![Figure 4.3: Numerical representation of an image](img/C13783_04_03.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3: 图像的数字表示](img/C13783_04_03.jpg)'
- en: 'Figure 4.3: Numerical representation of an image'
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 4.3: 图像的数字表示'
- en: This exercise is meant to help you appreciate how image data is processed with
    each pixel as a number between **0** and **255**. This understanding is essential
    as we'll feed these images into a CNN as input in the next section.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习旨在帮助你理解图像数据如何被处理，其中每个像素作为一个在 **0** 到 **255** 之间的数字。这一理解至关重要，因为我们将在下一部分将这些图像输入到
    CNN 中作为输入。
- en: Understanding the Architecture of a CNN
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 CNN 的架构
- en: Let's assume we have the task of classifying each of the **MNIST** images as
    a number between 0 and 9\. The input in the previous example is an image matrix.
    For a colored image, each pixel is an array with three values corresponding to
    the **RGB** color scheme. For grayscale images, each pixel is just one number,
    as we saw earlier.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个任务，将每个 **MNIST** 图像分类为 0 到 9 之间的数字。前面示例中的输入是一个图像矩阵。对于彩色图像，每个像素是一个包含三个值的数组，分别对应
    **RGB** 颜色模式。对于灰度图像，每个像素仅是一个数字，就像我们之前看到的那样。
- en: To understand the architecture of a CNN, it is best to separate it into two
    sections as visualized in the image that follows.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解 CNN 的架构，最好将其分为两个部分，如下图所示。
- en: A forward pass of the CNN involves a set of operations in the two sections.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 的前向传播涉及在两个部分中进行一系列操作。
- en: '![Figure 4.4: Application of convolution and ReLU operations](img/C13783_04_04.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4: 卷积和 ReLU 操作的应用](img/C13783_04_04.jpg)'
- en: 'Figure 4.4: Application of convolution and ReLU operations'
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '图 4.4: 卷积和 ReLU 操作的应用'
- en: 'The figure is explained in the following sections:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 该图在以下部分中解释：
- en: Feature extraction
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征提取
- en: Neural network
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络
- en: Feature Extraction
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征提取
- en: The first section of a CNN is all about feature extraction. Conceptually, it
    can be interpreted as the model's attempt to learn which features distinguish
    one class from another. In the task of classifying images, these features might
    include unique shapes and colors.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 的第一部分是特征提取。从概念上讲，可以理解为模型尝试学习哪些特征可以区分不同的类别。在图像分类任务中，这些特征可能包括独特的形状和颜色。
- en: CNNs learn the hierarchical structure of these features. The lower layers of
    a CNN abstract features such as edges, while the higher layers learn more defined
    features such as shapes.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 学习这些特征的层次结构。CNN 的低层抽象特征如边缘，而高层则学习更明确的特征，如形状。
- en: 'Feature learning occurs through a set of three operations repeated a number
    of times, as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 特征学习通过重复一系列三个操作进行，如下所示：
- en: Convolution
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卷积
- en: An activation function (the application of the ReLU activation function to achieve
    non-linearity)
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 激活函数（应用 ReLU 激活函数以实现非线性）
- en: Pooling
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 池化
- en: Convolution
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卷积
- en: Convolution is the an operation that distinguishes CNNs from other neural networks.
    The convolution operation is not unique to machine learning; it is applied in
    many other fields, such as electrical engineering and signal processing.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积是将 CNN（卷积神经网络）与其他神经网络区分开来的操作。卷积操作不仅仅是机器学习中的特有操作，它还广泛应用于其他领域，如电气工程和信号处理。
- en: Convolution can be thought of as looking through a small window as we move the
    window to the right and down. Convolution, in this context, involves iteratively
    sliding a "filter" across an image, while applying a dot product as we move left
    and down.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积可以理解为通过一个小窗口查看，当我们将窗口向右和向下移动时。卷积在这个上下文中意味着反复滑动一个“滤波器”跨越图像，同时在移动时应用点积操作。
- en: 'This window is called a "*filter*" or a "*kernel*". In the actual sense, a
    filter or kernel is a matrix of preferably smaller dimensions than the input.
    To better understand how filters are applied to images, consider the following
    example. After calculating the dot product on the area covered by the filter,
    we take a step to the right and calculate the dot product:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这个窗口被称为“*滤波器*”或“*卷积核*”。在实际操作中，滤波器或卷积核是一个矩阵，通常比输入的尺寸小。为了更好地理解滤波器如何应用于图像，考虑以下示例。在计算滤波器覆盖区域的点积后，我们向右移动一步，再次计算点积：
- en: '![Figure 4.5: Filter application to images'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.5：滤波器应用于图像'
- en: '](img/C13783_04_05.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_04_05.jpg)'
- en: 'Figure 4.5: Filter application on images'
  id: totrans-64
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.5：滤波器应用于图像
- en: The result of this convolution is known as a feature map or an activation map.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积的结果称为特征图或激活图。
- en: The size of the filter needs to be defined as a hyperparameter. This size can
    also be considered the area for which a neuron can "see" the input. This is called
    a neuron's *receptive field*. Additionally, we need to define the stride size,
    that is, the number of steps we need to take before applying the filter. Pixels
    at the center have the filters passing through several times compared with those
    at the edges. To avoid losing information at the corners, it is advisable to add
    an extra layer of zeros as padding.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波器的大小需要定义为超参数。这个大小也可以看作是神经元能够“看到”输入的区域。这个区域被称为神经元的*感受野*。此外，我们需要定义步幅大小，即在应用滤波器之前需要进行的步数。位于中心的像素相比位于边缘的像素，滤波器会经过多次。为了避免在角落处丢失信息，建议添加一层零填充。
- en: The ReLU Activation Function
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ReLU 激活函数
- en: Activation functions are used all across machine learning. They are useful for
    introducing non-linearity and allowing the a model to learn non-linear functions.
    In this particular context, we apply the **Rectified Linear Unit** (**ReLU**).
    It basically replaces all the negative values with zero.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数在整个机器学习中都被广泛使用。它们有助于引入非线性，使得模型能够学习非线性函数。在这个特定的上下文中，我们应用了**修正线性单元**（**ReLU**）。它的基本原理是将所有负值替换为零。
- en: The following image demonstrates the change in an image after ReLU is applied.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了应用 ReLU 后图像的变化。
- en: '![Figure 4.6: Image after applying ReLU function'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.6：应用 ReLU 函数后的图像'
- en: '](img/C13783_04_06.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_04_06.jpg)'
- en: 'Figure 4.6: Image after applying ReLU function'
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.6：应用 ReLU 函数后的图像
- en: 'Exercise 19: Visualizing ReLU'
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 19：可视化 ReLU
- en: In this exercise we will visualize the Rectified Linear Unit function. The ReLU
    function will be plotted on an X-Y axis, where X is numbers in the range of -15
    to 15 and Y is the output after applying the ReLU function. The goal of this exercise
    is to visualize ReLU.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将可视化修正线性单元（ReLU）函数。ReLU 函数将在 X-Y 坐标轴上绘制，其中 X 轴是从 -15 到 15 范围内的数字，Y 轴是应用
    ReLU 函数后的输出值。此练习的目标是可视化 ReLU。
- en: 'Import the required Python packages:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的 Python 包：
- en: '[PRE5]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Define the ReLU function:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 ReLU 函数：
- en: '[PRE6]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Specify the input and output references:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指定输入和输出参考：
- en: '[PRE7]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Plot the input against the output:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制输入与输出的关系：
- en: '[PRE8]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '**Expected Output:**'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**预期输出：**'
- en: '![Figure 4.7: Graph plot for ReLU'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.7：ReLU 的图形绘制'
- en: '](img/C13783_04_07.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_04_07.jpg)'
- en: 'Figure 4.7: Graph plot for ReLU'
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.7：ReLU 的图形绘制
- en: Pooling
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 池化
- en: Pooling is a downsampling process that involves reducing dimensionality from
    a higher to a lower dimensional space. In machine learning, pooling is applied
    as a way to reduce the spatial complexity of the layers. This allows for fewer
    weights to be learned and consequently faster training times.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 池化是一个降采样过程，它涉及将数据从更高维度空间减少到更低维度空间。在机器学习中，池化通常用于减少层的空间复杂性。这可以让我们学习更少的权重，从而加快训练速度。
- en: 'Historically, different techniques have been used to perform pooling, such
    as average pooling and L2-norm pooling. The most preferred pooling technique is
    max pool. Max pooling involves taking the largest element within a defined window
    size. The following is an example of max pooling on a matrix:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 历史上，曾使用不同的技术来执行池化操作，比如平均池化和 L2 范数池化。最常用的池化技术是最大池化。最大池化涉及在定义的窗口大小内取最大的元素。下面是一个对矩阵进行最大池化的例子：
- en: '![Figure 4.8: Max pool'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.8：最大池化](img/C13783_04_08.jpg)'
- en: '](img/C13783_04_08.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_04_08.jpg)'
- en: 'Figure 4.8: Max pool'
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.8：最大池化
- en: If we apply max pooling to the preceding example, the section that has 2, 6,
    3, and 7 is reduced to 7\. Similarly, the section with 1, 0, 9, and 2 is reduced
    to 9\. With max pooling, we pick the largest number in a section.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对前面的例子应用最大池化，那么包含 2、6、3 和 7 的区域将被缩减为 7。同样，包含 1、0、9 和 2 的区域将被缩减为 9。通过最大池化，我们选择一个区域中的最大值。
- en: Dropout
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Dropout
- en: 'A common problem encountered in machine learning is overfitting. Overfitting
    occurs when a model "memorizes" the training data and is unable to generalize
    when presented with different examples in testing. There are several ways to avoid
    overfitting, particularly through regularization:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中一个常见的问题是过拟合。过拟合发生在模型“记住”了训练数据，并且在测试时面对不同的示例时无法进行泛化。避免过拟合有几种方法，特别是通过正则化：
- en: '![Figure 4.9: Regularization](img/C13783_04_09.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.9：正则化](img/C13783_04_09.jpg)'
- en: 'Figure 4.9: Regularization'
  id: totrans-97
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.9：正则化
- en: Regulation is the process of constraining coefficients toward zero. Regularization
    can be summarized as techniques used to penalize learned coefficients so that
    they tend towards zero. Dropout is a common regularization technique that is applied
    by randomly "dropping" some neurons during both the forward and backward passes.
    To implement dropout, we specify the probability of a neuron being dropped as
    a parameter. By randomly dropping neurons, we ensure that the model is able to
    generalize better and therefore be a little more flexible.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化是约束系数趋近于零的过程。正则化可以总结为一种技术，用于惩罚已学习的系数，使它们趋向于零。Dropout 是一种常见的正则化技术，在前向和反向传播过程中，通过随机“丢弃”一些神经元来实现。为了实现
    dropout，我们将神经元被丢弃的概率指定为一个参数。通过随机丢弃神经元，我们确保模型能够更好地泛化，因此更加灵活。
- en: Classification in Convolutional Neural Network
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卷积神经网络中的分类
- en: The second section of a CNN is more task-specific. For the task of classification,
    this section is basically a fully connected neural network. A neural network is
    regarded as fully connected when every neuron in one layer is connected to all
    the neurons in the next layer. The input to the fully connected layer is a flattened
    vector that is the output of section one. Flattening converts the matrix into
    a 1D vector.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 的第二部分更具任务特定性。对于分类任务，这一部分基本上是一个全连接的神经网络。当神经网络中的每个神经元都与下一层的所有神经元连接时，神经网络被认为是全连接的。全连接层的输入是展平后的向量，这个向量是第一部分的输出。展平操作将矩阵转换为
    1D 向量。
- en: The number of hidden layers in the fully connected layer is a hyperparameter
    that can be optimized and fine-tuned.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 全连接层中隐藏层的数量是一个超参数，可以优化和微调。
- en: 'Exercise 20: Creating a Simple CNN Architecture'
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习 20：创建一个简单的 CNN 架构
- en: In this exercise, you will construct a simple CNN model using Keras. This exercise
    will entail creating a model with the layers discussed so far. In the first section
    of the model, we will have two convolutional layers with the ReLU activation function,
    a pooling layer, and a dropout layer. In the second section, we will have a flattened
    layer and a fully connected layer.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你将使用 Keras 构建一个简单的 CNN 模型。这个练习将包括创建一个包含到目前为止讨论的层的模型。在模型的第一部分，我们将有两个卷积层，使用
    ReLU 激活函数，一个池化层和一个 dropout 层。在第二部分，我们将有一个展平层和一个全连接层。
- en: 'First, we import the necessary classes:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入必要的类：
- en: '[PRE9]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, define the variables used:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，定义所使用的变量：
- en: '[PRE10]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s now define the model. Keras''s Sequential model allows you to stack
    layers as you go:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来定义模型。Keras 的 Sequential 模型允许你按顺序堆叠层：
- en: '[PRE11]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We can now add section one layers. The convolution and ReLU layers are defined
    together. We have two convolutional layers. We define a kernel size of 3 for each.
    The first layer of the model receives the input. We need to define how it should
    expect that input to be structured. In our case, the input is in the form of 28
    by 28 images. We also need to specify the number of neurons for each layer. In
    our case, we define 64 neurons for the first layer and 32 neurons for the second
    layer. Please note that these are hyperparameters that can be optimized:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以添加第一节的层。卷积层和ReLU层一起定义。我们有两个卷积层。每个层的卷积核大小都定义为3。模型的第一层接收输入。我们需要定义它期望输入的结构方式。在我们的案例中，输入是28x28的图像形式。我们还需要指定每一层的神经元数量。在我们的案例中，我们为第一层定义了64个神经元，为第二层定义了32个神经元。请注意，这些是可以优化的超参数：
- en: '[PRE12]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We then add a pooling layer, followed by a dropout layer with a 25% probability
    of neurons being ''dropped'':'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们添加一个池化层，接着是一个丢弃层，丢弃层以25%的概率“丢弃”神经元：
- en: '[PRE13]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The section one layers are done. Please note that the number of layers is also
    a hyperparameter that can be optimized.
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第一节的层已经完成。请注意，层的数量也是一个可以优化的超参数。
- en: 'For section two, we first flatten the input. We then add a fully connected
    or dense layer. Using the softmax activation function, we can calculate the probability
    for each of the 10 classes:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于第二节，我们首先将输入展平。然后我们添加一个完全连接层或密集层。使用softmax激活函数，我们可以计算10个类别的每个类别的概率：
- en: '[PRE14]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To visualize the model architecture so far, we can print out the model as follows:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了可视化到目前为止的模型架构，我们可以按照以下方式打印出模型：
- en: '[PRE15]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**Expected Output**:'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**预期输出**：'
- en: '![Figure 4.10: Model summary](img/C13783_04_10.jpg)'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.10：模型摘要](img/C13783_04_10.jpg)'
- en: 'Figure 4.10: Model summary'
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.10：模型摘要
- en: 'You can also run the following code to export the image to a file:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你也可以运行以下代码将图像导出到文件：
- en: '[PRE16]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Figure 4.11: Visualized architecture of a simple CNN'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.11：简单CNN的可视化架构'
- en: '](img/C13783_04_11.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_04_11.jpg)'
- en: 'Figure 4.11: Visualized architecture of a simple CNN'
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.11：简单CNN的可视化架构
- en: In the preceding exercise, we created a simple CNN with two convolutional layers
    for the task of classification. In the preceding output image, you'll notice how
    the layers are stacked – starting from the input layer, then the two convolutional
    layers, the pooling, dropout, and flattening layers, and the fully connected layer
    at the end.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的练习中，我们创建了一个简单的卷积神经网络（CNN），包含两个卷积层，用于分类任务。在前面的输出图像中，你会注意到这些层是如何堆叠的——从输入层开始，然后是两个卷积层、池化层、丢弃层和展平层，最后是完全连接层。
- en: Training a CNN
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练CNN
- en: 'During the training of a CNN, the model tries to learn the weights of the filters
    in feature extraction and the weights at the fully connected layers in the neural
    network. To understand how a model is trained, we''ll discuss how the probability
    of each output class is calculated, how we calculate the error or the loss, and
    finally, how we optimize or minimize that loss while updating the weights:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练CNN时，模型尝试学习特征提取中的滤波器权重以及神经网络中完全连接层的权重。为了理解模型是如何训练的，我们将讨论如何计算每个输出类别的概率，如何计算误差或损失，最后，如何优化或最小化该损失，并在更新权重时进行调整：
- en: Probabilities
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 概率
- en: 'Recall that in the last layer of the neural network section, we used a softmax
    function to calculate the probability of each output class. This probability is
    calculated by dividing the exponent of that class score by the sum of the exponents
    of all scores:'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 回想一下，在神经网络的最后一层，我们使用了softmax函数来计算每个输出类别的概率。这个概率是通过将该类别分数的指数除以所有分数的指数总和来计算的：
- en: '![Figure 4.12: Expression to calculate probability](img/C13783_04_12.jpg)'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.12：计算概率的表达式](img/C13783_04_12.jpg)'
- en: 'Figure 4.12: Expression to calculate probability'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.12：计算概率的表达式
- en: Loss
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 损失
- en: 'We need to be able to quantify how well the calculated probabilities predict
    the actual class. This is done by calculating a loss, which in the case of classification
    probability is best done through the categorical cross-entropy loss function.
    The categorical cross-entropy loss function takes in two vectors, the predicted
    classes (let''s call that y'') and the actual classes (say y), and outputs the
    overall loss. Cross-entropy loss is calculated as the sum of the negative log
    likelihoods of the class probabilities. It can be represented as the H function
    here:'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们需要能够量化计算出的概率如何预测实际类别。这是通过计算损失来实现的，在分类概率的情况下，最好通过类别交叉熵损失函数来完成。类别交叉熵损失函数接受两个向量，预测的类别（我们称之为
    y'）和实际的类别（称之为 y），并输出整体损失。交叉熵损失是类别概率的负对数似然之和。它可以用H函数表示：
- en: '![](img/C13783_04_13.jpg)'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/C13783_04_13.jpg)'
- en: 'Figure 4.13: Expression to calculate loss'
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.13：计算损失的表达式
- en: Optimization
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 优化
- en: 'Consider the sketch of cross-entropy loss that follows. By minimizing the loss,
    we can predict the correct class with a higher probability:'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 考虑以下交叉熵损失的示意图。通过最小化损失，我们可以以更高的概率预测正确的类别：
- en: '![Figure 4.14: Cross-entropy loss vs. predicted probability](img/C13783_04_14.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图4.14：交叉熵损失与预测概率](img/C13783_04_14.jpg)'
- en: 'Figure 4.14: Cross-entropy loss versus predicted probability'
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.14：交叉熵损失与预测概率
- en: Gradient descent is an optimization algorithm for finding the minimum of a function,
    such as the loss function described earlier. Although the overall error is calculated,
    we need to go back and calculate how much of that loss was contributed by each
    node. Consequently, we can update the weights, so as to minimize the overall error.
    Backpropagation applies the chain rule of calculus to calculate the update for
    each weight. This is done by taking the partial derivative of the error or loss
    relative to the weights.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是一种优化算法，用于寻找函数的最小值，例如前面描述的损失函数。虽然计算了整体误差，但我们需要回过头来计算每个节点对损失的贡献。因此，我们可以更新权重，以最小化整体误差。反向传播应用了微积分中的链式法则来计算每个权重的更新。这是通过求误差或损失相对于权重的偏导数来完成的。
- en: 'To better visualize these steps, consider the following diagram, which summarizes
    the three steps. For the classification task, the first step involves the calculation
    of probabilities for each output class. We then apply a loss function to quantify
    how well the probabilities predict the actual class. In order to make a better
    prediction going forward, we then update our weights by performing backpropagation
    through gradient descent:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地可视化这些步骤，考虑以下图示，概括了这三个步骤。在分类任务中，第一步涉及计算每个输出类别的概率。然后，我们应用损失函数来量化概率预测实际类别的效果。为了在未来做出更好的预测，我们通过梯度下降进行反向传播，更新权重：
- en: '![Figure 4.15: Steps for task of classification'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.15：分类任务的步骤'
- en: '](img/C13783_04_15.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_04_15.jpg)'
- en: 'Figure 4.15: Steps for the classification task'
  id: totrans-146
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.15：分类任务的步骤
- en: 'Exercise 21: Training a CNN'
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习21：训练CNN
- en: In this exercise, we will train the model we created in exercise 20\. The following
    steps will help you with the solution. Recall that this is for the overall task
    of classification.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将训练在练习20中创建的模型。以下步骤将帮助您解决这个问题。请记住，这适用于整个分类任务。
- en: 'We start by defining the number of epochs. An epoch is a common hyperparameter
    used in deep neural networks. One epoch is when the entire dataset is passed through
    a complete forward and backward pass. As training data is usually a lot, data
    can be divided into several batches:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先定义训练的轮数。一个轮次是深度神经网络中的常见超参数。一个轮次表示整个数据集经过完整的前向传播和反向传播。当训练数据量很大时，数据可以分成多个批次：
- en: '[PRE17]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Recall that we imported the MNIST dataset by running the following command:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回想一下，我们通过运行以下命令导入了MNIST数据集：
- en: '[PRE18]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We first reshape the data to fit the model:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先重新调整数据以适应模型：
- en: '[PRE19]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The to_categorical function changes a vector of integers to a matrix of one-hot
    encoded vectors. Given the following example, the function returns the array shown:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: to_categorical函数将整数向量转换为一热编码的矩阵。给定以下示例，函数返回如下数组：
- en: '[PRE20]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The array would be as follows:'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数组将如下所示：
- en: '![Figure 4.16: Array output](img/C13783_04_16.jpg)'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图4.16：数组输出](img/C13783_04_16.jpg)'
- en: 'Figure 4.16: Array output'
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.16：数组输出
- en: 'We apply it to the target column as shown:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将其应用于目标列，如下所示：
- en: '[PRE21]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We then define the loss function as a categorical cross-entropy loss function.
    Additionally, we define the optimizer and the metrics. The Adam(Adaptive Moment)
    optimizer is an optimization algorithm often used in place of stochastic gradient
    descent. It defines an adaptive learning rate for each parameter of the model:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们随后将损失函数定义为分类交叉熵损失函数。此外，我们定义优化器和度量标准。Adam（自适应矩估计）优化器是一种经常用于替代随机梯度下降的优化算法。它为模型的每个参数定义了自适应学习率：
- en: '[PRE22]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'To train the model, run the .fit method:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要训练模型，请运行`.fit`方法：
- en: '[PRE23]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output should be as follows:'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应如下所示：
- en: '![Figure 4.17: Training the model'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.17：训练模型'
- en: '](img/C13783_04_17.jpg)'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/C13783_04_17.jpg)'
- en: 'Figure 4.17: Training the model'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.17：训练模型
- en: 'To evaluate the model''s performance, you can run the following:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要评估模型的性能，您可以运行以下命令：
- en: '[PRE24]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'For this task, we expect a fairly high accuracy after a number of epochs:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于这个任务，我们预计在若干个周期后会有相当高的准确率：
- en: '![Figure 4.18: Accuracy and loss output](img/C13783_04_18.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.18：准确率和损失输出](img/C13783_04_18.jpg)'
- en: 'Figure 4.18: Accuracy and loss output'
  id: totrans-174
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.18：准确率和损失输出
- en: Applying CNNs to Text
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用CNN到文本
- en: Now that we have a general intuition of how CNNs work using images, let's look
    at how they can be applied in natural language processing. Just like images, text
    has spatial qualities that make it ideal for CNN usage. However, there is one
    main change to the architecture that we introduce when dealing with text. Instead
    of having two-dimensional convolutional layers, text is one-dimensional, as shown
    here.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对CNN如何在图像中使用有了一般直觉，让我们看看它们如何应用在自然语言处理中。与图像类似，文本具有使其在CNN使用中成为理想选择的空间特性。但是，当我们处理文本时，架构上有一个主要变化。文本不再具有二维卷积层，而是一维的，如下所示。
- en: '![Figure 4.19: One-dimensional convolution](img/C13783_04_19.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.19：一维卷积](img/C13783_04_19.jpg)'
- en: 'Figure 4.19: One-dimensional convolution'
  id: totrans-178
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.19：一维卷积
- en: It is important to note that the preceding input sequence can be either the
    character sequence or the word sequence. The application of CNNs on text, at the
    character level, can be visualized as shown in the following figure. CNNs have
    6 convolutional layers and 3 fully connected layers as shown here.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，前述输入序列可以是字符序列或单词序列。在字符级别上应用CNNs到文本的应用可以如下图所示。CNN具有6个卷积层和3个全连接层，如下所示。
- en: '![Figure 4.20: CNN with 6 convolutional and 3 fully connected layers'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.20：CNN具有6个卷积和3个全连接层'
- en: '](img/C13783_04_20.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_04_20.jpg)'
- en: 'Figure 4.20: CNN with 6 convolutional and 3 fully connected layers'
  id: totrans-182
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.20：CNN具有6个卷积和3个全连接层
- en: Character-level CNNs were shown to perform well when applied to large noisy
    data. They are also simpler than word-level applications because they require
    no preprocessing (such as stemming) and the characters are represented as one-hot
    encoding representations.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用于大型嘈杂数据时，字符级CNN表现良好。它们与单词级应用相比较简单，因为它们不需要预处理（如词干处理），并且字符被表示为一热编码表示。
- en: In the following example, we will demonstrate the application of CNNs to text
    at a word level. We will therefore need to perform some vectorization and padding
    before feeding the data into the CNN architecture.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将演示如何将CNN应用于单词级别的文本。因此，在将数据输入CNN架构之前，我们需要执行一些向量化和填充操作。
- en: 'Exercise 22: Application of a Simple CNN to a Reuters News Topic for Classification'
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 练习22：将简单的CNN应用于Reuters新闻主题分类
- en: In this exercise, we will be applying a CNN model to the built-in Keras Reuters
    dataset.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将应用CNN模型到内置的Keras Reuters数据集中。
- en: Note
  id: totrans-187
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: If you are using Google Colab, you need to downgrade your version of `numpy`
    to 1.16.2 by running
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用Google Colab，需要通过运行以下命令将您的`numpy`版本降级到1.16.2：
- en: '`!pip install numpy==1.16.1`'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`!pip install numpy==1.16.1`'
- en: '`import numpy as np`'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '`import numpy as np`'
- en: This downgrade is necessary since this version of `numpy` has the default value
    of `allow_pickle` as `True`.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 由于此版本的`numpy`将`allow_pickle`的默认值设置为`True`，因此需要进行此降级。
- en: 'Start by importing the necessary classes:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先导入必要的类：
- en: '[PRE25]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Define the variables:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义变量：
- en: '[PRE26]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Load the Reuters dataset:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载Reuters数据集：
- en: '[PRE27]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Prepare the data:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备数据：
- en: '[PRE28]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Tokenize the input data:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对输入数据进行标记化：
- en: '[PRE29]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Define the model:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义模型：
- en: '[PRE30]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Train and evaluate the model. Print the accuracy score:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练和评估模型。打印准确率分数：
- en: '[PRE31]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '**Expected output**:'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**预期输出**：'
- en: '![Figure 4.21: Accuracy score](img/C13783_04_21.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.21：准确率分数](img/C13783_04_21.jpg)'
- en: 'Figure 4.21: Accuracy score'
  id: totrans-208
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.21：准确率分数
- en: We have thus created a model and trained it on a dataset.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经创建了一个模型，并在数据集上进行了训练。
- en: Application Areas of CNNs
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CNN的应用领域
- en: Now that we understand the architecture of CNNs, let's look at some applications.
    In general, CNNs are great for data that has a spatial structure. Examples of
    types of data that has a spatial structure are sound, images, video, and text.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了CNN的架构，让我们来看看一些应用。通常，CNN非常适合具有空间结构的数据。具有空间结构的数据类型示例包括声音、图像、视频和文本。
- en: In natural language processing, CNNs are used for various tasks such as sentence
    classification. One example is the task of sentiment classification, where a sentence
    is classified as belonging to a predetermined group of classes.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然语言处理领域，CNNs被用于各种任务，如句子分类。一个例子是情感分类任务，其中一个句子被分类为属于预定的类别之一。
- en: As discussed earlier, CNNs are applied at the character level to classification
    tasks such as sentiment classification, especially on noisy datasets such as social
    media posts.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，CNNs被应用于字符级别的分类任务，如情感分类，尤其是在社交媒体帖子等嘈杂数据集上。
- en: 'CNNs are more commonly applied in computer vision. Here are some applications
    in this area:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: CNNs更常应用于计算机视觉。以下是该领域的一些应用：
- en: '*Facial recognition*'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*面部识别*'
- en: Most social networking sites employ CNNs to detect faces and subsequently perform
    tasks such as tagging.
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大多数社交网络网站使用CNN来检测面部并随后执行诸如标签标注等任务。
- en: '![Figure 4.22: Facial recognition](img/C13783_04_22.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![图4.22：面部识别](img/C13783_04_22.jpg)'
- en: 'Figure 4.22: Facial recognition'
  id: totrans-218
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.22：面部识别
- en: '*Object detection*'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*物体检测*'
- en: Similarly, CNNs are able to detect objects in images. There are several CNN-based
    architectures that are used to detect objects, one of the most popular being R-CNN.
    (R-CNN stands for Region CNN.) An R-CNN works by applying a selective search to
    come up with regions and subsequently use using CNNs to perform classification,
    one region at a time.
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 类似地，CNN能够在图像中检测物体。有几种基于CNN的架构用于检测物体，其中最流行的之一是R-CNN。（R-CNN代表区域卷积神经网络。）R-CNN的工作原理是应用选择性搜索来生成区域，然后使用CNN进行分类，每次处理一个区域。
- en: '![Figure 4.23: Object detection'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.23：物体检测](img/C13783_04_23.jpg)'
- en: '](img/C13783_04_23.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_04_23.jpg)'
- en: 'Figure 4.23: Object detection'
  id: totrans-223
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.23：物体检测
- en: '*Image captioning*'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图像标注*'
- en: This task involves creating a textual description for an image. One way to perform
    image captioning is to replace the fully connected layer in section two with a
    recurrent neural network (RNN).
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该任务涉及为图像创建文本描述。执行图像标注的一种方式是将第二部分的全连接层替换为递归神经网络（RNN）。
- en: '![Figure 4.24: Image captioning'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.24：图像标注](img/C13783_04_24.jpg)'
- en: '](img/C13783_04_24.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/C13783_04_24.jpg)'
- en: 'Figure 4.24: Image captioning'
  id: totrans-228
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.24：图像标注
- en: '*Semantic segmentation*'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*语义分割*'
- en: Semantic segmentation is the task of segmenting an image into more meaningful
    parts. Each pixel in an image is classified as belonging to a class.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 语义分割是将图像划分为更有意义部分的任务。图像中的每个像素都会被分类为属于某个类别。
- en: '![Figure 4.25: Semantic segmentation](img/C13783_04_25.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![图4.25：语义分割](img/C13783_04_25.jpg)'
- en: 'Figure 4.25: Semantic segmentation'
  id: totrans-232
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.25：语义分割
- en: 'An architecture that can be used to perform semantic segmentation is a **Fully**
    **Convoluted** **Network** (**FCN**). The architecture of FCNs is slightly different
    from the preceding one in two ways: it has no fully connected layer and it has
    upsampling. Upsampling is the process of making the output image larger preferably
    the same size as the input image.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 一种可以用于执行语义分割的架构是**全卷积网络**（**FCN**）。FCN的架构与之前的架构在两方面略有不同：它没有全连接层，并且具有上采样。上采样是将输出图像放大到与输入图像大小相同的过程。
- en: 'Here is a sample architecture:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例架构：
- en: '![Figure 4.26: Sample architecture of semantic segmentation](img/C13783_04_26.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![图4.26：语义分割的示例架构](img/C13783_04_26.jpg)'
- en: 'Figure 4.26: Sample architecture of semantic segmentation'
  id: totrans-236
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图4.26：语义分割的示例架构
- en: Note
  id: totrans-237
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: For more on FCNs, refer to the paper by Jonathan Long, Evan Shelhamer, and Trevor
    Darrell titled Fully Convolutional Networks for Semantic Segmentation.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解更多关于FCN的信息，请参考Jonathan Long、Evan Shelhamer和Trevor Darrell的论文《Fully Convolutional
    Networks for Semantic Segmentation》。
- en: 'Activity 5: Sentiment Analysis on a Real-life Dataset'
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 活动5：在实际数据集上进行情感分析
- en: Imagine that you are tasked with creating a model to classify the reviews from
    a dataset. In this activity, we will build a CNN that performs the binary classification
    task of sentiment analysis. We will be using a real-life dataset from UCI's repository.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你被要求创建一个模型来分类数据集中的评论。在本活动中，我们将构建一个执行情感分析二分类任务的CNN。我们将使用来自UCI数据集库的实际数据集。
- en: Note
  id: totrans-241
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: This dataset is downloaded from https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集可从 https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences
    下载
- en: 'From Group to Individual Labels using Deep Features, Kotziaa et al., KDD 2015
    UCI machine learning Repository [http://archive.ics.uci.edu.ml]. Irvine, CA: University
    of California, School of Information and Computer Science'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 从组标签到个体标签，基于深度特征，Kotziaa 等，KDD 2015 UCI 机器学习库 [http://archive.ics.uci.edu.ml]。加利福尼亚州欧文市：加利福尼亚大学信息与计算机科学学院
- en: 'You can also download it from our GitHub repository link:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以通过我们的 GitHub 仓库链接下载它：
- en: https://github.com/TrainingByPackt/Deep-Learning-for-Natural-Language-Processing/tree/master/Lesson%2004
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: https://github.com/TrainingByPackt/Deep-Learning-for-Natural-Language-Processing/tree/master/Lesson%2004
- en: The following steps will help you with the solution.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你解决问题。
- en: Download the Sentiment Labelled Sentences dataset.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载 Sentiment Labelled Sentences 数据集。
- en: Create a directory labelled 'data' within your working directory and unzip the
    downloaded folder within the directory.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的工作目录中创建一个名为 'data' 的文件夹，并将下载的文件夹解压到该目录中。
- en: Create and run your working script (for example, sentiment.ipynb) on Jupyter
    Notebook.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Jupyter Notebook 上创建并运行你的工作脚本（例如，sentiment.ipynb）。
- en: Import your data using pandas read_csv method. Feel free to use one or all of
    the files in the dataset.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 的 read_csv 方法导入数据。可以随意使用数据集中的一个或所有文件。
- en: Split your data into training and test sets by using scikit learn's train_test_split.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 的 train_test_split 将数据拆分为训练集和测试集。
- en: Tokenize using Keras's tokenizer.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Keras 的 tokenizer 进行分词。
- en: Convert the text into sequences using the texts_to_sequences method.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 texts_to_sequences 方法将文本转换为序列。
- en: Ensure that all sequences have the same length by padding them. You can use
    Keras's pad_sequences function.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过填充确保所有序列具有相同的长度。你可以使用 Keras 的 pad_sequences 函数。
- en: Define the model with a minimum of one convolutional layer and one fully connected
    layer. As this is a binary classification, we use a sigmoid activation function
    and calculate the loss through binary cross-entropy loss.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义模型，至少包含一层卷积层和一层全连接层。由于这是二分类问题，我们使用 sigmoid 激活函数，并通过二元交叉熵损失函数计算损失。
- en: Train and test the model.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练和测试模型。
- en: Note
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for the activity can be found on page 305.
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以在第 305 页找到。
- en: '**Expected output:**'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**预期输出：**'
- en: '![Figure 4.27: Accuracy scores](img/C13783_04_27.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.27：准确度分数](img/C13783_04_27.jpg)'
- en: 'Figure 4.27: Accuracy scores'
  id: totrans-261
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4.27：准确度分数
- en: Summary
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we studied the architecture and applications of convolutional
    neural networks (CNNs). CNNs are applied not just to text and images but also
    to datasets that have some form of spatial structure. In the upcoming chapters,
    you will explore how to apply other forms of neural networks to various natural
    language tasks.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了卷积神经网络（CNN）的架构和应用。CNN 不仅应用于文本和图像，还应用于具有某种空间结构的数据集。在接下来的章节中，你将探索如何将其他形式的神经网络应用于各种自然语言任务。
