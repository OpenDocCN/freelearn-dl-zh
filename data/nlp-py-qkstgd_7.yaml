- en: Building your Own Chatbot
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建自己的聊天机器人
- en: Chatbots, better referred to as conversation software, are amazing tools for
    a lot of businesses. They help businesses serve their client's server 24/7 without
    increasing effort, with consistent quality, and the built-in option to defer to
    a human when bots are not enough.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人，更确切地说是对话软件，对于许多企业来说都是惊人的工具。它们帮助企业在24/7不间断的服务中服务客户，无需增加工作量，保持一致的质量，并在机器人不足以应对时内置将任务转交给人类的选项。
- en: They are a great example of where technology and AI has come together to improve
    the impact of human effort.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 它们是技术和人工智能结合以改善人力影响的绝佳例子。
- en: They range from voice-based solutions such as Alexa, to text-based Intercom
    chat boxes, to menu-based navigation in Uber.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 它们从基于语音的解决方案，如Alexa，到基于文本的Intercom聊天框，再到Uber中的基于菜单的导航，种类繁多。
- en: A common misconception is that building chatbots needs large teams and a lot
    of machine learning expertise, though this is true if you are trying to build
    a *generic* chatbot platform like Microsoft or Facebook (or even Luis, Wit.ai,
    and so on).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的误解是构建聊天机器人需要大量团队和大量的机器学习专业知识，尽管如果你试图构建像微软或Facebook（甚至Luis、Wit.ai等）这样的**通用**聊天机器人平台，这确实是正确的。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将涵盖以下主题：
- en: Why build a chatbot?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么构建聊天机器人？
- en: Figuring out the right user intent
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定正确的用户意图
- en: Bot responses
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人响应
- en: Why chatbots as a learning example?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么以聊天机器人作为学习示例？
- en: 'So far, we have built an application for every NLP topic that we have seen:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经为每一个我们看到的NLP主题构建了一个应用程序：
- en: Text cleaning using grammar and vocabulary insights
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用语法和词汇洞察进行文本清理
- en: Linguistics (and statistical parsers), to mine questions from text
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言学（和统计解析器），从文本中挖掘问题
- en: Entity recognition for information extraction
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实体识别用于信息提取
- en: Supervised text classification using both machine learning and deep learning
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用机器学习和深度学习进行监督文本分类
- en: Text similarity using text-based vectors such as GloVe/word2vec
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基于文本的向量，如GloVe/word2vec进行文本相似度
- en: We will now combine all of them into a much more complicated setup and write
    our own chatbot from scratch. But, before you build anything from scratch, you
    should ask why.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将把它们组合成一个更复杂的设置，并从头开始编写我们自己的聊天机器人。但在你从头开始构建任何东西之前，你应该问自己为什么。
- en: Why build a chatbot?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么构建聊天机器人？
- en: A related questions is why should we build our own chatbots? **Why can't I use
    FB/MSFT/some other cloud service?**
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 相关的问题是为什么我们应该构建自己的聊天机器人？**为什么我不能使用FB/MSFT/其他云服务？**
- en: 'Perhaps, a better question to ask is *when* to build on your own? These are
    the factors to keep in mind when making this decision:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 可能，一个更好的问题是要问自己**何时**开始构建自己的东西？在做出这个决定时，以下是一些需要考虑的因素：
- en: '**Privacy and competition**:As a business, is it a good idea to share information
    about your users with Facebook or Microsoft? Or even a smaller company?'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**隐私和竞争**：作为一个企业，与Facebook或Microsoft（甚至更小的公司）分享有关用户的信息是个好主意吗？ '
- en: '**Cost and constraints**: Your funky cloud limits your design choices that
    are made by a particular intelligence provider to those that are made by the likes
    of Google or Facebook. Additionally, you are now paying for each HTTP call you
    make, which is slower than running code locally.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**成本和限制**：你那奇特的云服务限制了特定智能提供商做出的设计选择，这些选择类似于谷歌或Facebook。此外，你现在需要为每个HTTP调用付费，这比在本地运行代码要慢。'
- en: '**Freedom to customize and extend**: You can develop a solution that performs
    better for you! You don''t have to cure world hunger –just keep shipping an everi-ncreasing
    business value via quality software. If you are at a big company, you have all
    the more reason to invest in extendible software.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**自由定制和扩展**：你可以开发一个更适合你的解决方案！你不必解决世界饥饿——只需通过高质量的软件不断提供越来越多的商业价值。如果你在大公司工作，你更有理由投资于可扩展的软件。'
- en: Quick code means word vectors and heuristics
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速代码意味着词向量和方法
- en: For the sake of simplicity, we will assume that our bot does not need to remember
    the context of any question. Therefore it sees input, responds to it, and is done.
    No links are established with the previous input.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化起见，我们将假设我们的机器人不需要记住任何问题的上下文。因此，它看到输入，对其做出响应，然后完成。与之前的输入不建立任何链接。
- en: 'Let''s start by simply loading the word vectors using `gensim`:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先简单地使用`gensim`加载词向量：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Phew, this might take a minute depending on your download speed. Once this
    is done, let''s unzip the file, get it to the data directory, and convert it into
    `word2vec` format:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 呼吸，这可能会根据你的下载速度而花费一分钟。一旦完成，让我们解压缩文件，将其放入数据目录，并将其转换为`word2vec`格式：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: By the end of the preceding code block, we have the 300-dimension GloVe embedding
    from the official Stanford source converted into the word2vec format.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 到前一个代码块结束时，我们已经将来自官方斯坦福源的300维GloVe嵌入转换成了word2vec格式。
- en: 'Let''s load this into our working memory:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将这个加载到我们的工作记忆中：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let''s quickly check whether we can vectorize any word by checking for word
    embeddings for any word, for example, `awesome`:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速检查我们是否可以通过检查任何单词的词嵌入来矢量化任何单词，例如，`awesome`：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`awesome`, this works!'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`awesome`，这行得通！'
- en: Now, let's take a look at our first challenge.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们的第一个挑战。
- en: Figuring out the right user intent
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定正确的用户意图
- en: This is commonly referred to as the problem of intent categorization.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常被称为意图分类问题。
- en: As a toy example, we will try to build an order bot that someone like DoorDash/Swiggy/Zomato
    might use.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 作为玩具示例，我们将尝试构建一个DoorDash/Swiggy/Zomato等可能使用的订单机器人。
- en: Use case – food order bot
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用例 - 食物订单机器人
- en: 'Consider the following sample sentence: *I''m looking for a cheap Chinese place
    in Indiranagar*.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下示例句子：*我在Indiranagar找一个便宜的中国餐馆*。
- en: We want to pick out Chinese as a cuisine type in the sentence. We can obviously
    take simple approaches, like exact substring matching (search *Chinese*) or TF-IDF-based
    matches.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想在句子中挑选出中国作为一个菜系类型。显然，我们可以采取简单的办法，比如精确子串匹配（搜索*Chinese*）或基于TF-IDF的匹配。
- en: Instead, we will generalize the model to discover cuisine types that we might
    not have identified yet, but that can learn about via the GloVe embedding.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们将泛化模型以发现我们可能尚未识别但可以通过GloVe嵌入学习的菜系类型。
- en: 'We''ll keep it as simple as possible: we''ll provide some example cuisine types
    to tell the model that we need cuisines, and look for the most similar words in
    the sentence.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尽可能简单：我们将提供一些示例菜系类型来告诉模型我们需要菜系，并寻找句子中最相似的单词。
- en: We'll loop through the words in the sentence and pick out the ones whose similarity
    to the reference words is above a certain threshold.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将遍历句子中的单词，并挑选出与参考单词相似度高于某个阈值的单词。
- en: '**Do word vectors even work for this?**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**词向量真的适用于这种情况吗？**'
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: For simplicity's sake, the following code is written as `for` loops, but can
    be vectorized for speed.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简单起见，以下代码以`for`循环的形式编写，但可以矢量化以提高速度。
- en: We iterate over each word in the input sentence and find the similarity score
    with respect to known cuisine words.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将遍历输入句子中的每个单词，并找到与已知菜系单词的相似度得分。
- en: 'The higher the value, the more likely the word is to be something related to
    our cuisine references or `cuisine_refs`:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 值越高，这个词就越有可能与我们的菜系参考或`cuisine_refs`相关：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following is the corresponding output:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对应的输出：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The threshold is determined empirically. Notice that we are able to infer *Indian*
    and *Chinese* as cuisines, even if they are not part of the original set.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值是通过经验确定的。注意，我们能够推断出*印度*和*中国*作为菜系，即使它们不是原始集合的一部分。
- en: Of course, exact matches will have a much higher score.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，精确匹配将会有更高的分数。
- en: This is a good example where there's a better problem formulation in terms of
    the *generic* cuisine type that can be learned. This is more helpful than a dictionary-based
    cuisine type. This also proves that we can rely on word-vector-based approaches.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的例子，其中在*通用*菜系类型方面有更好的问题表述，这比基于字典的菜系类型更有帮助。这也证明了我们可以依赖基于词向量的方法。
- en: Can we extend this for user intent classification? Let's try this next.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能否将此扩展到用户意图分类？让我们尝试下一步。
- en: Classifying user intent
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类用户意图
- en: We want to be able to put sentences into categories by user *intents*. Intents
    are a generic mechanism that combine multiple individual examples into one semantic
    umbrella. For example, *hi*, *hey*, *good morning*, and *wassup!* are all examples
    of the `_greeting_` intent.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望能够通过用户的*意图*将句子分类。意图是一种通用机制，它将多个个别示例组合成一个语义伞。例如，*hi*，*hey*，*早上好*和*wassup!*都是`_greeting_`意图的例子。
- en: Using *greeting* as an input, the backend logic can then determine how to respond
    to the user.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 使用*问候*作为输入，后端逻辑可以确定如何响应用户。
- en: 'There are many ways we could combine word vectors to represent a sentence,
    but again we''re going to do the simplest thing possible: add them up.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有很多种方法可以将词向量组合起来表示一个句子，但同样，我们将采取最简单的方法：将它们相加。
- en: 'This is definitely a less-than-ideal solution, but works in practice because
    of the simple, unsupervised approach we use with this:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这绝对不是一个理想的解决方案，但由于我们使用简单、无监督的方法，它在实践中是可行的：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Let's define a data dictionary with some examples for each intent.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个数据字典，为每个意图提供一些示例。
- en: We will be using the data dictionary written by [Alan at the Rasa Blog](https://medium.com/rasa-blog/do-it-yourself-nlp-for-bot-developers-2e2da2817f3d)
    for this.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用由[Alan在Rasa博客](https://medium.com/rasa-blog/do-it-yourself-nlp-for-bot-developers-2e2da2817f3d)编写的数据字典来完成这项工作。
- en: 'This dictionary can be updated since we have more user input:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有更多的用户输入，这个字典可以被更新：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The approach we have is simple: we find the centroid of each *user intent*.
    A centroid is just a central point to denote each intent. Then, the incoming text
    is assigned to the user intent that''s nearest to the corresponding cluster.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的方法很简单：我们找到每个*用户意图*的重心。重心只是一个表示每个意图的中心点。然后，将传入的文本分配给最接近相应聚类的用户意图。
- en: 'Let''s write a simple function to find the centroid and update the dictionary:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们写一个简单的函数来找到重心并更新字典：
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let''s add the centroid to the data dictionary:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把这个重心加到数据字典里：
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s write a simple function to find the nearest user intent cluster now.
    We will use the L2 norm that we already implemented in `np.linalg`:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在写一个简单的函数来找到最近的用户意图聚类。我们将使用已经在`np.linalg`中实现的L2范数：
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s run this on some user text that is **not** in the **data dictionary**:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一些用户文本上运行这个，这些文本**不在**数据字典中：
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The corresponding code generalizes well, and is convincing regarding the fact
    that this is good enough for the roughly 10-15 minutes it took for us to get to
    this point:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 相应的代码很好地推广了，并且令人信服地表明，这对于我们花了大约10-15分钟到达这个点来说已经足够好了：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Bot responses
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器人回应
- en: 'We now know how to understand and categorize user intent. We now need to simply
    respond to each user intent with some corresponding responses. Let''s get these
    *template* bot responses in one place:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在知道了如何理解和分类用户意图。我们现在需要简单地用一些相应的回应来响应每个用户意图。让我们把这些*模板*机器人回应放在一个地方：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Storing the `Response` map in a separate entity is helpful. This means that
    you can generate responses at a separate service from your intent understanding
    module and then glue them together:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 将`Response`映射存储在单独的实体中很有帮助。这意味着你可以从你的意图理解模块中生成回应，然后将它们粘合在一起：
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If we think about this a little bit more, there is no need for the response
    map to be depend only on the intent that's categorized. You can convert this response
    map into a separate function that generates the map using related context and
    then picks a bot template.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们再深入思考一下，就没有必要让回应映射仅仅依赖于被分类的意图。你可以将这个回应映射转换成一个单独的函数，该函数使用相关上下文生成映射，然后选择一个机器人模板。
- en: But here, for simplicity, let's keep it as a dictionary/JSON-style structure.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 但在这里，为了简单起见，让我们保持字典/JSON风格的格式。
- en: 'Let''s write a simple `get_bot_response` function that takes in the response
    mapping, templates, and the intent as input and returns the actual bot response:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们写一个简单的`get_bot_response`函数，它接受回应映射、模板和意图作为输入，并返回实际的机器人回应：
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Let''s quickly try this with one sentence:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速尝试一句话：
- en: '[PRE17]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The code is free of syntax errors at this point. This seems good to go for more
    performance testing. But before that, how can we make this better?
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 代码目前没有语法错误。这似乎可以进行更多的性能测试。但在那之前，我们如何使它更好？
- en: Better response personalization
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更好的回应个性化
- en: You'll notice that the function picks one template at random for any particular
    *bot intent*, so to say. While this is for simplicity here, in practice, you can
    train an ML model to pick a response that's personalized to a user.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到，该函数会随机选择一个模板来响应任何特定的*机器人意图*。虽然这里是为了简单起见，但在实践中，你可以训练一个机器学习模型来选择一个针对用户的个性化回应。
- en: A simple personalization to make is to adapt with the talking/typing of the
    user's style. For example, one user might be formal with, *Hello, how are you
    today?*, while another might be more informal with, *Y**o*.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的个性化调整是适应用户的说话/打字风格。例如，一个用户可能会用正式的方式，*你好，今天过得怎么样？*，而另一个用户可能会用更非正式的方式，*Y**o*。
- en: Therefore, *Hello* gets *Goodbye!* in response while *Yo!* gets *Bye bye* or
    even *TTYL* in the same conversation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，*Hello*会得到*Goodbye!*的回应，而*Yo!*在同一对话中可能会得到*Bye bye*甚至*TTYL*。
- en: 'For now, let''s go ahead and check the bot response for the sentences that
    we have already seen:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，让我们检查一下我们已经看到的句子的机器人回应：
- en: '[PRE18]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The responses can vary due to randomness; here is an example:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 由于随机性，回应可能会有所不同；这里是一个例子：
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Summary
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter on chatbots, we learned about *intent*, which usually refers
    to the user input, *response*, which is via the bot, *templates*, which defines
    the nature of bot responses, and *entities*, such as cuisine type, in our example.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章关于聊天机器人的内容中，我们学习了*意图*，通常指的是用户输入，*响应*，通过机器人进行，*模板*，定义了机器人响应的性质，以及*实体*，例如在我们的例子中是菜系类型。
- en: Additionally, to understand the user intent—and even find entities—we used **unsupervised
    approaches** , that is, we did not have training examples this time. In practice,
    most commercial systems use a hybrid system, combining supervised and unsupervised
    systems.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了理解用户意图——甚至找到实体——我们使用了**无监督方法**，也就是说，这次我们没有训练示例。在实践中，大多数商业系统使用混合系统，结合了监督和无监督系统。
- en: The one thing you should take away from here is that we don't need a lot of
    training data to make the first usable version of a bot for a specific use case.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该从这里带走的一点是，我们不需要大量的训练数据来制作特定用例的第一个可用的聊天机器人版本。
