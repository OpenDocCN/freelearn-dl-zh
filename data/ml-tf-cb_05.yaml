- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Boosted Trees
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度提升树
- en: 'In this chapter, we describe boosted trees: the **TensorFlow** (**TF**) approach
    to gradient boosting. It is a class of ML algorithms that produce a prediction
    model in the form of an ensemble of weak prediction models, typically decision
    trees. The model is constructed in a stage-wise fashion and generalized by utilizing
    an arbitrary (differentiable) loss function. Gradient boosted trees are an extremely
    popular class of algorithms, as they can be parallelized (at the tree construction
    stage), can natively handle missing values and outliers, and require minimal data
    preprocessing.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了梯度提升树：**TensorFlow**（**TF**）的方法。它是一类机器学习算法，通过一组弱预测模型（通常是决策树）生成预测模型。该模型以阶段性方式构建，并通过使用任意（可微）损失函数来进行泛化。梯度提升树是一类非常流行的算法，因为它们可以并行化（在树构建阶段），本地处理缺失值和异常值，并且需要最少的数据预处理。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: 'In this chapter, we briefly demonstrate how to approach a binary classification
    problem using `BoostedTreesClassifier`. We will apply the technique to solve a
    realistic business problem using a popular educational dataset: predicting which
    customers are likely to cancel their bookings. The data for this problem – and
    several other business problems – comes in tabular format, and typically contains
    a mixture of different feature types: numeric, categorical, dates, and so on.
    In the absence of sophisticated domain knowledge, gradient boosting methods are
    a good first choice for creating an interpretable solution that works out of the
    box. In the next section, the relevant modeling steps will be demonstrated with
    code: data preparation, structuring into functions, fitting a model through the
    `tf.estimator` functionality, and interpretation of results.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们简要展示了如何使用`BoostedTreesClassifier`处理二分类问题。我们将应用这种技术解决一个实际的商业问题，使用一个流行的教育数据集：预测哪些顾客可能会取消他们的预订。这个问题的数据——以及其他几个商业问题——以表格格式存在，通常包含多种不同的特征类型：数值型、类别型、日期等。在缺乏复杂领域知识的情况下，梯度提升方法是创建一个可解释的、即开即用的解决方案的不错选择。在接下来的部分，将通过代码演示相关的建模步骤：数据准备、结构化为函数、通过`tf.estimator`功能拟合模型，以及结果的解释。
- en: How to do it...
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'We begin by loading the necessary packages:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先加载必要的包：
- en: '[PRE0]'
  id: totrans-7
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In principle, categorical variables could be simply recoded into integers (using
    a function such as `LabelEncoder` from scikit-learn) and a gradient boosting model
    would work just fine – these minimal requirements on data preprocessing are one
    of the reasons behind the popularity of ensembles of trees. However, in this recipe,
    we want to focus on demonstrating the interpretability of the model and therefore
    we want to analyze individual indicator values. For that reason, we create a function
    performing one-hot encoding in a TF-friendly format:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 原则上，类别变量可以简单地重新编码为整数（使用如`LabelEncoder`之类的函数），而梯度提升模型也能很好地工作——数据预处理的这些最小要求是树集成方法流行的原因之一。然而，在本案例中，我们希望集中展示模型的可解释性，因此我们要分析各个指标的值。基于这个原因，我们创建了一个在TF友好的格式中执行独热编码的函数：
- en: '[PRE1]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As mentioned in the introduction, for this recipe we will be using the hotel
    cancellations dataset available from the following URL:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如引言中所述，在这个案例中，我们将使用以下网址提供的酒店取消数据集：
- en: '[https://www.sciencedirect.com/science/article/pii/S2352340918315191](https://www.sciencedirect.com/science/article/pii/S2352340918315191)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.sciencedirect.com/science/article/pii/S2352340918315191](https://www.sciencedirect.com/science/article/pii/S2352340918315191)'
- en: 'We choose this dataset because it is fairly realistic for a typical business
    prediction problem a reader might encounter: there''s a time dimension present,
    and a mixture of numeric and categorical features. At the same time, it is fairly
    clean (no missing values), which means we can focus on the actual modeling and
    not on data wrangling:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择这个数据集是因为它对于读者可能遇到的典型商业预测问题来说相当现实：数据中包含时间维度，并且有数值型和类别型特征。同时，它也相当干净（没有缺失值），这意味着我们可以专注于实际的建模，而不是数据处理：
- en: '[PRE2]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The dataset has a time dimension, so a natural training/validation split can
    be made on `reservation_status_date`:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集有时间维度，因此可以基于`reservation_status_date`进行自然的训练/验证集划分：
- en: '[PRE3]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Separate the features from the target:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 将特征与目标分开：
- en: '[PRE4]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We separate the columns into numerical and categorical ones and encode them
    in the TF-expected format. We skip some columns that could perhaps improve the
    model performance, but due to their nature they introduce a risk of leakage: introducing
    information that might improve the model performance in training but will fail
    when predicting on unseen data. In our situation, one such variable is `arrival_date_year`:
    if the model uses this variable very strongly, it will fail if we present it with
    a dataset further into the future (where a specific value of the variable will
    obviously be absent).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将列分为数值型和类别型，并以 TF 期望的格式进行编码。我们跳过一些可能改善模型性能的列，但由于它们的特性，它们引入了泄露的风险：在训练中可能改善模型性能，但在对未见数据进行预测时会失败。在我们的案例中，其中一个变量是
    `arrival_date_year`：如果模型过于依赖这个变量，当我们提供一个更远未来的数据集时（该变量的特定值显然会缺失），模型将会失败。
- en: 'We remove some additional variables from our training data – this step can
    either be conducted based on expert judgment prior to the modeling procedure,
    or it can be automated. The latter approach would involve running a small model
    and examining the global feature importance: if the results show one very important
    feature dominating over others, it is a potential source of leakage:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从训练数据中去除一些额外的变量——这个步骤可以在建模过程之前基于专家判断进行，或者可以通过自动化方法进行。后一种方法将包括运行一个小型模型并检查全局特征的重要性：如果结果显示某一个非常重要的特征主导了其他特征，它可能是信息泄露的潜在来源：
- en: '[PRE5]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The next step required is creating the input functions for the boosted trees
    algorithm: we specify how data will be read into our model for both training and
    inference. We use the `from_tensor_slices` method in the `tf.data` API to read
    in data directly from pandas:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是为提升树算法创建输入函数：我们指定如何将数据读入模型，用于训练和推理。我们使用 `tf.data` API 中的 `from_tensor_slices`
    方法直接从 pandas 读取数据：
- en: '[PRE6]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can now build the actual BoostedTrees model. We set up a minimal list of
    parameters (`max_depth` being one of the most important ones) – the ones not specified
    in the definition are left at their default values, which can be found through
    the help functions in the documentation:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以构建实际的 BoostedTrees 模型。我们设置了一个最小的参数列表（`max_depth` 是其中一个最重要的参数）——在定义中没有指定的参数将保持默认值，这些可以通过文档中的帮助函数查找。
- en: '[PRE7]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Once we have trained a model, we can evaluate the performance with respect
    to different metrics. `BoostedTreesClassifier` contains an `evaluate` method and
    the output covers a wide range of possible metrics; which ones are used for guidance
    depends on the specific application, but those outputted by default already allow
    us to evaluate the model from various angles (for example, if we are dealing with
    a highly imbalanced dataset, `auc` can be somewhat misleading and we should evaluate
    the loss as well). For a more detailed explanation, the reader is referred to
    documentation at [https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesClassifier):'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们训练好一个模型，就可以根据不同的评估指标来评估其性能。`BoostedTreesClassifier` 包含一个 `evaluate` 方法，输出涵盖了广泛的可能指标；使用哪些指标进行指导取决于具体应用，但默认输出的指标已经能让我们从多个角度评估模型（例如，如果我们处理的是一个高度不平衡的数据集，`auc`
    可能会有些误导，此时我们应该同时评估损失值）。更详细的说明，请参考文档：[https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesClassifier)：
- en: '[PRE8]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The results you see should look like this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你看到的结果应该是这样的：
- en: '![Obraz zawierający stół  Opis wygenerowany automatycznie](img/B16254_05_01.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![Obraz zawierający stół  Opis wygenerowany automatycznie](img/B16254_05_01.png)'
- en: '[PRE9]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can evaluate the results at different levels of generality – details of
    the difference between global and local are given as follows. Let''s start with
    the **receiver operating characteristic** (**ROC**) curve: a graph showing the
    performance of a classification model at all possible classification thresholds.
    We plot the false positive rate versus the true positive rate: a random classifier
    would be a diagonal line from (0,0) to (1,1), and the further away we move from
    that scenario toward the upper-left corner, the better our classifier is:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在不同的泛化层次上评估结果——以下给出全球性和局部性差异的具体说明。我们从**接收者操作特征**（**ROC**）曲线开始：这是一种图形，显示了分类模型在所有可能分类阈值下的性能。我们绘制假阳性率与真正阳性率的关系：一个随机分类器会表现为从
    (0,0) 到 (1,1) 的对角线，越远离这种情况，朝左上角移动，我们的分类器就越好：
- en: '[PRE10]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](img/B16254_05_02.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16254_05_02.png)'
- en: 'Figure 5.1: ROC for the trained classifier'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1：训练分类器的ROC曲线
- en: 'Local interpretability refers to an understanding of a model''s predictions
    at the individual example level: we will create and visualize per-instance contributions.
    This is particularly useful if model predictions need to be explained to audiences
    exhibiting technical cognitive diversity. We refer to these values as **directional
    feature contributions** (**DFCs**):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 局部可解释性指的是对模型在单个示例层面的预测的理解：我们将创建并可视化每个实例的贡献。这对于需要向具有技术认知多样性的观众解释模型预测时尤其有用。我们将这些值称为**方向性特征贡献**（**DFC**）：
- en: '[PRE11]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Obraz zawierający stół  Opis wygenerowany automatycznie](img/B16254_05_03.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![Obraz zawierający stół  Opis wygenerowany automatycznie](img/B16254_05_03.png)'
- en: The complete summary of the complete DFC DataFrame can be somewhat overwhelming
    at first glance, and in practice, one is most likely to focus on a subset of the
    columns. What we get in each row are summary statistics (`mean`, `std`, and so
    on) of the directional contributions of a feature (`arrival_date_week_number`
    in the first row, `arrival_date_day_of_month` for the second, and so on) across
    all observations in the validation set.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的DFC数据框的总结初看起来可能有些让人不知所措，实际上，通常我们会关注某些列的子集。每一行展示的是特征（第一行的`arrival_date_week_number`，第二行的`arrival_date_day_of_month`，依此类推）在验证集中的所有观测值的方向性贡献的汇总统计（如`mean`、`std`等）。
- en: How it works...
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'The following code block demonstrates the steps necessary to extract the feature
    contributions to a prediction for a particular record. For convenience and reusability,
    we define a function plotting a chosen record first (for easier interpretation,
    we want to plot feature importances using different colors, depending on whether
    their contribution is positive or negative):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块演示了提取某个记录的预测特征贡献所需的步骤。为了方便和可重用，我们首先定义了一个绘制选定记录的函数（为了更容易解释，我们希望使用不同的颜色绘制特征重要性，具体取决于它们的贡献是正向还是负向）：
- en: '[PRE12]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'With the boilerplate code defined, we plot the detailed graph for a specific
    record in a straightforward manner:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 定义好样板代码后，我们可以以一种直接的方式绘制特定记录的详细图表：
- en: '[PRE13]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Which delivers the following output:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![](img/B16254_05_04.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16254_05_04.png)'
- en: 'Figure 5.2: How different features contribute to predicted probabilities'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2：不同特征对预测概率的贡献
- en: 'Besides analyzing the feature relevance on the level of individual observation,
    we can also take a global (aggregate) view. Global interpretability refers to
    an understanding of the model as a whole: we will retrieve and visualize gain-based
    feature importances and permutation feature importances and also show aggregated
    DFCs.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 除了分析单个观测值的特征相关性外，我们还可以从全局（聚合）角度进行分析。全局可解释性指的是对模型整体的理解：我们将提取并可视化基于增益的特征重要性和置换特征重要性，同时也会展示聚合的DFC。
- en: Gain-based feature importances measure the loss change when splitting on a particular
    feature, while permutation feature importances are computed by evaluating the
    model performance on the evaluation set by shuffling each feature one by one and
    attributing the change in model performance to the shuffled feature.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 基于增益的特征重要性衡量在对特定特征进行切分时损失变化，而置换特征重要性是通过评估模型在评估集上的表现来计算的，方法是将每个特征依次打乱，并将模型表现的变化归因于被打乱的特征。
- en: In general, permutation feature importance is preferred to gain-based feature
    importance, though both methods can be unreliable in situations where potential
    predictor variables vary in their scale of measurement or their number of categories
    and when features are correlated.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，置换特征重要性比基于增益的特征重要性更为优选，尽管在潜在预测变量的度量尺度或类别数量不同，以及特征之间存在相关性时，二者的方法都可能不可靠。
- en: 'The function calculating permutation importances is as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 计算置换特征重要性的函数如下：
- en: '[PRE14]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We use the following function to display the most relevant columns:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下函数来显示最相关的列：
- en: '[PRE15]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Which gives you the following output:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为你输出如下结果：
- en: '![](img/B16254_05_05.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16254_05_05.png)'
- en: 'Figure 5.3: The permutation feature importance of different features'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3：不同特征的置换特征重要性
- en: 'And we use the following function to display the gain feature importance columns
    in the same way:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下函数以相同的方式显示增益特征重要性列：
- en: '[PRE16]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Which gives you the following output:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为你输出如下结果：
- en: '![](img/B16254_05_06.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16254_05_06.png)'
- en: 'Figure 5.4: The gain feature importance of different features'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4：不同特征的增益特征重要性
- en: 'The absolute values of DFCs can be averaged to understand the impact at a global
    level:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: DFCs 的绝对值可以被平均，以理解全局层面的影响：
- en: '[PRE17]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Which gives you the following output:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出以下结果：
- en: '![](img/B16254_05_07.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B16254_05_07.png)'
- en: 'Figure 5.5: The mean directional feature contributions of different features'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5.5: 不同特征的平均方向性特征贡献'
- en: 'In this recipe, we have introduced the TF implementation of `GradientBoostingClassifier`:
    a flexible model architecture applicable to a wide range of tabular data problems.
    We built a model to solve a real business problem: predicting the probability
    that a customer might cancel their hotel booking and, in the process, we introduced
    all the relevant components of the TF Boosted Trees pipeline:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们介绍了 `GradientBoostingClassifier` 的 TensorFlow 实现：一种灵活的模型架构，适用于广泛的表格数据问题。我们构建了一个模型来解决一个实际的业务问题：预测客户可能会取消酒店预订的概率，在这个过程中，我们介绍了
    TF Boosted Trees 管道的所有相关组件：
- en: Prepare the data for use with the model
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为模型准备数据
- en: Configure the `GradientBoostingClassifier` with `tf.estimator`
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `tf.estimator` 配置 `GradientBoostingClassifier`
- en: Evaluate the feature importance and model interpretability, both on a global
    and local level
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估特征重要性和模型可解释性，既要从全局层面，也要从局部层面
- en: See also
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'There is a plethora of articles introducing the gradient boosting family of
    algorithms:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 有大量文章介绍梯度提升算法家族：
- en: An excellent Medium post at [https://medium.com/analytics-vidhya/introduction-to-the-gradient-boosting-algorithm-c25c653f826b](https://medium.com/analytics-vidhya/introduction-to-the-gradient-boosting-algorithm-c25c653f826b)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一篇精彩的 Medium 博文：[https://medium.com/analytics-vidhya/introduction-to-the-gradient-boosting-algorithm-c25c653f826b](https://medium.com/analytics-vidhya/introduction-to-the-gradient-boosting-algorithm-c25c653f826b)
- en: 'The official XGBoost documentation: [https://xgboost.readthedocs.io/en/latest/tutorials/model.html](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '官方 XGBoost 文档: [https://xgboost.readthedocs.io/en/latest/tutorials/model.html](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)'
- en: 'The LightGBM documentation: [https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf](https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'LightGBM 文档: [https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf](https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree.pdf)'
