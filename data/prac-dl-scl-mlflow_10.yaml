- en: 'Section 4 –     Deploying a Deep Learning Pipeline at Scale'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '第4节 –     大规模部署深度学习管道'
- en: In this section, we will learn how to implement and deploy a multi-step inference
    pipeline for production usage. We will start with an overview of four patterns
    of inference workflows in production. We will then learn how to implement a multi-step
    inference pipeline with preprocessing and postprocessing steps around a fine-tuned
    **deep learning** (**DL**) model using MLflow **PyFunc** APIs. With a ready-to-deploy
    MLflow PyFunc-compatible DL inference pipeline, we will learn about different
    deployment tools and hosting environments to decide which tool to use for a specific
    deployment scenario. We will then implement and deploy a batch inference pipeline
    using MLflow's Spark **user-defined function** (**UDF**). From there on, we will
    focus on deploying a web service using either MLflow's built-in model serving
    tool or Ray Serve's MLflow deployment plugin. Finally, we will show a complete
    step-by-step guide to deploying a DL inference pipeline to a managed AWS SageMaker
    instance for production usage.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何实现和部署一个多步骤推理管道，以便用于生产环境。我们将从生产环境中四种推理工作流模式的概述开始。接着，我们将学习如何使用 MLflow
    **PyFunc** API，围绕一个经过微调的**深度学习**（**DL**）模型，实施一个包含预处理和后处理步骤的多步骤推理管道。在这个准备好部署的 MLflow
    PyFunc 兼容的深度学习推理管道上，我们将了解不同的部署工具和托管环境，以便选择适合特定部署场景的工具。然后，我们将使用 MLflow 的 Spark
    **用户定义函数**（**UDF**）实现并部署一个批量推理管道。之后，我们将专注于使用 MLflow 内置的模型服务工具或 Ray Serve 的 MLflow
    部署插件，部署一个 Web 服务。最后，我们将展示一个完整的逐步指南，介绍如何将一个深度学习推理管道部署到管理的 AWS SageMaker 实例中，以便用于生产环境。
- en: 'This section comprises the following chapters:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包括以下章节：
- en: '[*Chapter 7*](B18120_07_ePub.xhtml#_idTextAnchor083), *Multi-Step Deep Learning
    Inference Pipeline*'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B18120_07_ePub.xhtml#_idTextAnchor083)，*多步骤深度学习推理管道*'
- en: '[*Chapter 8*](B18120_08_ePub.xhtml#_idTextAnchor095), *Deploying a DL Inference
    Pipeline at Scale*'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第8章*](B18120_08_ePub.xhtml#_idTextAnchor095)，*大规模部署深度学习推理管道*'
