- en: Bibliography
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[Sut88]'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sut88]'
- en: 'Richard S Sutton. “Learning to predict by the methods of temporal differences”.
    In: Machine learning 3 (1988), pp. 9–44.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Richard S Sutton. “通过时间差方法学习预测”。发表于：机器学习 3 (1988)，第9–44页。
- en: '[HS96]'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[HS96]'
- en: 'Sepp Hochreiter and Jürgen Schmidhuber. “LSTM can solve hard long time lag
    problems”. In: Advances in neural information processing systems 9 (1996).'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Sepp Hochreiter 和 Jürgen Schmidhuber. “LSTM可以解决难度较大的长时延问题”。发表于：神经信息处理系统进展 9
    (1996)。
- en: '[RK04]'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[RK04]'
- en: 'Reuven Y Rubinstein and Dirk P Kroese. The cross-entropy method: a unified
    approach to combinatorial optimization, Monte-Carlo simulation, and machine learning.
    Vol. 133\. Springer, 2004.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Reuven Y Rubinstein 和 Dirk P Kroese. 《交叉熵方法：组合优化、蒙特卡洛模拟与机器学习的统一方法》。第133卷，Springer出版社，2004年。
- en: '[SL08]'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[SL08]'
- en: 'Alexander L Strehl and Michael L Littman. “An analysis of model-based interval
    estimation for Markov decision processes”. In: Journal of Computer and System
    Sciences 74.8 (2008), pp. 1309–1331.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Alexander L Strehl 和 Michael L Littman. “基于模型的马尔科夫决策过程区间估计分析”。发表于：计算机与系统科学杂志
    74.8 (2008)，第1309–1331页。
- en: '[Kro+11]'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kro+11]'
- en: 'Dirk P Kroese et al. “Cross-entropy method’”. In: European Journal of Operational
    Research 31 (2011), pp. 276–283.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Dirk P Kroese等. “交叉熵方法”。发表于：欧洲运筹学杂志 31 (2011)，第276–283页。
- en: '[LS11]'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[LS11]'
- en: 'Joel Lehman and Kenneth O Stanley. “Abandoning objectives: Evolution through
    the search for novelty alone”. In: Evolutionary computation 19.2 (2011), pp. 189–223.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Joel Lehman 和 Kenneth O Stanley. “放弃目标：仅通过寻找新奇性进化”。发表于：进化计算 19.2 (2011)，第189–223页。
- en: '[Mni13]'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mni13]'
- en: 'Volodymyr Mnih. “Playing atari with deep reinforcement learning”. In: arXiv
    preprint arXiv:1312.5602 (2013).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Volodymyr Mnih. “通过深度强化学习玩Atari游戏”。发表于：arXiv预印本 arXiv:1312.5602 (2013)。
- en: '[Sil+14]'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sil+14]'
- en: 'David Silver et al. “Deterministic policy gradient algorithms”. In: International
    conference on machine learning. Pmlr. 2014, pp. 387–395.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: David Silver等. “确定性策略梯度算法”。发表于：国际机器学习会议。PMLR。2014年，第387–395页。
- en: '[Lil15]'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[Lil15]'
- en: 'TP Lillicrap. “Continuous control with deep reinforcement learning”. In: arXiv
    preprint arXiv:1509.02971 (2015).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: TP Lillicrap. “通过深度强化学习进行连续控制”。发表于：arXiv预印本 arXiv:1509.02971 (2015)。
- en: '[MG15]'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[MG15]'
- en: 'James Martens and Roger Grosse. “Optimizing neural networks with kronecker-factored
    approximate curvature”. In: International conference on machine learning. PMLR.
    2015, pp. 2408–2417.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: James Martens 和 Roger Grosse. “通过克罗内克分解近似曲率优化神经网络”。发表于：国际机器学习会议。PMLR。2015年，第2408–2417页。
- en: '[Mni+15]'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mni+15]'
- en: 'Volodymyr Mnih et al. “Human-level control through deep reinforcement learning”.
    In: nature 518.7540 (2015), pp. 529–533.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Volodymyr Mnih等. “通过深度强化学习实现人类级控制”。发表于：自然期刊 518.7540 (2015)，第529–533页。
- en: '[Sch+15]'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sch+15]'
- en: 'Tom Schaul et al. “Prioritized Experience Replay”. In: (2015). arXiv: [1511.05952
    [cs.LG]](https://arxiv.org/abs/1511.05952). url: [https://arxiv.org/abs/1511.05952](https://arxiv.org/abs/1511.05952).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 'Tom Schaul等. “优先经验回放”。发表于：(2015)。arXiv: [1511.05952 [cs.LG]](https://arxiv.org/abs/1511.05952)。网址:
    [https://arxiv.org/abs/1511.05952](https://arxiv.org/abs/1511.05952)。'
- en: '[Sch15]'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sch15]'
- en: 'John Schulman. “Trust Region Policy Optimization”. In: arXiv preprint arXiv:1502.05477
    (2015).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: John Schulman. “信任区域策略优化”。发表于：arXiv预印本 arXiv:1502.05477 (2015)。
- en: '[VGS16]'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[VGS16]'
- en: 'Hado Van Hasselt, Arthur Guez, and David Silver. “Deep reinforcement learning
    with double q-learning”. In: Proceedings of the AAAI conference on artificial
    intelligence. Vol. 30\. 1\. 2016.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Hado Van Hasselt, Arthur Guez, 和 David Silver. “基于双Q学习的深度强化学习”。发表于：人工智能AAAI会议论文集。第30卷，1号，2016年。
- en: '[Wan+16]'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[Wan+16]'
- en: 'Ziyu Wang et al. “Dueling network architectures for deep reinforcement learning”.
    In: International conference on machine learning. PMLR. 2016, pp. 1995–2003.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Ziyu Wang等. “用于深度强化学习的对抗性网络架构”。发表于：国际机器学习会议。PMLR。2016年，第1995–2003页。
- en: '[BDM17]'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[BDM17]'
- en: 'Marc G Bellemare, Will Dabney, and Rémi Munos. “A distributional perspective
    on reinforcement learning”. In: International conference on machine learning.
    PMLR. 2017, pp. 449–458.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Marc G Bellemare, Will Dabney, 和 Rémi Munos. “从分布视角看强化学习”。发表于：国际机器学习会议。PMLR。2017年，第449–458页。
- en: '[Chr+17]'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[Chr+17]'
- en: 'Paul Christiano et al. Deep reinforcement learning from human preferences.
    2017\. eprint: [arXiv:1706.03741](#).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 'Paul Christiano等. 《基于人类偏好的深度强化学习》。2017年。电子印本: [arXiv:1706.03741](#)。'
- en: '[For+17]'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[For+17]'
- en: 'Meire Fortunato et al. “Noisy Networks for Exploration”. In: (2017). arXiv:
    [1706.10295 [cs.LG]](https://arxiv.org/abs/1706.10295). url: [https://arxiv.org/abs/1706.10295](https://arxiv.org/abs/1706.10295).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 'Meire Fortunato等. “探索中的噪声网络”。发表于：(2017)。arXiv: [1706.10295 [cs.LG]](https://arxiv.org/abs/1706.10295)。网址:
    [https://arxiv.org/abs/1706.10295](https://arxiv.org/abs/1706.10295)。'
- en: '[Mar+17]'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[Mar+17]'
- en: 'Jarryd Martin et al. “Count-based exploration in feature space for reinforcement
    learning”. In: arXiv preprint arXiv:1706.08090 (2017).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Jarryd Martin 等人。“基于计数的特征空间探索用于强化学习”。收录于：arXiv 预印本 arXiv:1706.08090 (2017)。
- en: '[Ost+17]'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ost+17]'
- en: 'Georg Ostrovski et al. “Count-based exploration with neural density models”.
    In: International conference on machine learning. PMLR. 2017, pp. 2721–2730.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Georg Ostrovski 等人。“基于计数的探索与神经密度模型”。收录于：国际机器学习会议。PMLR。2017年，页码：2721–2730。
- en: '[Sal+17]'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sal+17]'
- en: 'Tim Salimans et al. “Evolution strategies as a scalable alternative to reinforcement
    learning”. In: arXiv preprint arXiv:1703.03864 (2017).'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Tim Salimans 等人。“进化策略：作为强化学习的可扩展替代方法”。收录于：arXiv 预印本 arXiv:1703.03864 (2017)。
- en: '[Sch+17]'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sch+17]'
- en: 'John Schulman et al. “Proximal policy optimization algorithms”. In: arXiv preprint
    arXiv:1707.06347 (2017).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: John Schulman 等人。“近端策略优化算法”。收录于：arXiv 预印本 arXiv:1707.06347 (2017)。
- en: '[SSa17]'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[SSa17]'
- en: 'David Silver, Julian Schrittwieser, and Karen Simonyan et al. Mastering the
    game of Go without human knowledge. 2017\. eprint: [10.1038/nature24270](#).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 'David Silver、Julian Schrittwieser 和 Karen Simonyan 等人。无需人类知识的围棋游戏掌握。2017\.
    eprint: [10.1038/nature24270](#)。'
- en: '[Sil+17]'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sil+17]'
- en: 'David Silver et al. Mastering Chess and Shogi by Self-Play with a General Reinforcement
    Learning Algorithm. 2017\. arXiv: [1712.01815 [cs.AI]](https://arxiv.org/abs/1712.01815).
    url: [https://arxiv.org/abs/1712.01815](https://arxiv.org/abs/1712.01815).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 'David Silver 等人。通过自我对弈与通用强化学习算法掌握国际象棋和将棋。2017\. arXiv: [1712.01815 [cs.AI]](https://arxiv.org/abs/1712.01815)。网址：[https://arxiv.org/abs/1712.01815](https://arxiv.org/abs/1712.01815)。'
- en: '[Suc+17]'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '[Suc+17]'
- en: 'Felipe Petroski Such et al. “Deep neuroevolution: Genetic algorithms are a
    competitive alternative for training deep neural networks for reinforcement learning”.
    In: arXiv preprint arXiv:1712.06567 (2017).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Felipe Petroski Such 等人。“深度神经进化：遗传算法是训练深度神经网络进行强化学习的竞争性替代方法”。收录于：arXiv 预印本 arXiv:1712.06567
    (2017)。
- en: '[Vas17]'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[Vas17]'
- en: 'A Vaswani. “Attention is all you need”. In: Advances in Neural Information
    Processing Systems (2017).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: A Vaswani。“注意力即你所需要的”。收录于：神经信息处理系统进展 (2017)。
- en: '[Wu+17]'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[Wu+17]'
- en: 'Yuhuai Wu et al. “Scalable trust-region method for deep reinforcement learning
    using kronecker-factored approximation”. In: Advances in neural information processing
    systems 30 (2017).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Yuhuai Wu 等人。“基于克罗内克近似的可扩展信任域方法用于深度强化学习”。收录于：神经信息处理系统进展 30 (2017)。
- en: '[Bar+18]'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[Bar+18]'
- en: 'Gabriel Barth-Maron et al. “Distributed distributional deterministic policy
    gradients”. In: arXiv preprint arXiv:1804.08617 (2018).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Gabriel Barth-Maron 等人。“分布式分布式确定性策略梯度”。收录于：arXiv 预印本 arXiv:1804.08617 (2018)。
- en: '[Bur+18]'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[Bur+18]'
- en: 'Yuri Burda et al. “Exploration by random network distillation”. In: arXiv preprint
    arXiv:1810.12894 (2018).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Yuri Burda 等人。“通过随机网络蒸馏进行探索”。收录于：arXiv 预印本 arXiv:1810.12894 (2018)。
- en: '[Haa+18]'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[Haa+18]'
- en: 'Tuomas Haarnoja et al. “Soft actor-critic: Off-policy maximum entropy deep
    reinforcement learning with a stochastic actor”. In: International conference
    on machine learning. PMLR. 2018, pp. 1861–1870.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Tuomas Haarnoja 等人。“软演员-评论家：具有随机演员的非策略最大熵深度强化学习”。收录于：国际机器学习会议。PMLR。2018年，页码：1861–1870。
- en: '[Hes+18]'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '[Hes+18]'
- en: 'Matteo Hessel et al. “Rainbow: Combining improvements in deep reinforcement
    learning”. In: Proceedings of the AAAI conference on artificial intelligence.
    Vol. 32\. 1\. 2018.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Matteo Hessel 等人。“彩虹：结合深度强化学习的改进”。收录于：人工智能学会年会论文集。第32卷，第1期，2018年。
- en: '[McA+18]'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[McA+18]'
- en: 'Stephen McAleer et al. “Solving the Rubik’s cube without human knowledge”.
    In: arXiv preprint arXiv:1805.07470 (2018).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Stephen McAleer 等人。“无需人类知识解决魔方”。收录于：arXiv 预印本 arXiv:1805.07470 (2018)。
- en: '[Bak+20]'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[Bak+20]'
- en: 'Bowen Baker et al. Emergent Tool Use From Multi-Agent Autocurricula. 2020\.
    arXiv: [1909.07528 [cs.LG]](https://arxiv.org/abs/1909.07528). url: [https://arxiv.org/abs/1909.07528](https://arxiv.org/abs/1909.07528).'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 'Bowen Baker 等人。来自多智能体自动课程的工具使用演化。2020\. arXiv: [1909.07528 [cs.LG]](https://arxiv.org/abs/1909.07528)。网址：[https://arxiv.org/abs/1909.07528](https://arxiv.org/abs/1909.07528)。'
- en: '[FS20]'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[FS20]'
- en: 'Alexander H Frey Jr and David Singmaster. “Handbook of cubik math”. In: (2020).'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Alexander H Frey Jr 和 David Singmaster。“立方体数学手册”。出版于：（2020）。
- en: '[Sch+20]'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sch+20]'
- en: 'Julian Schrittwieser et al. “Mastering Atari, Go, chess and shogi by planning
    with a learned model”. In: Nature 588.7839 (Dec. 2020), pp. 604–609\. issn: 1476-4687\.
    doi: [10.1038/s41586-020-03051-4](https://doi.org/10.1038/s41586-020-03051-4).
    url: [http://dx.doi.org/10.1038/s41586-020-03051-4](http://dx.doi.org/10.1038/s41586-020-03051-4).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 'Julian Schrittwieser 等人。“通过规划与学习的模型掌握Atari、围棋、国际象棋和将棋”。发表于：Nature 588.7839
    (2020年12月)，页码：604–609\. issn: 1476-4687\. doi: [10.1038/s41586-020-03051-4](https://doi.org/10.1038/s41586-020-03051-4)。网址：[http://dx.doi.org/10.1038/s41586-020-03051-4](http://dx.doi.org/10.1038/s41586-020-03051-4)。'
- en: '[BDR23]'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[BDR23]'
- en: Marc G Bellemare, Will Dabney, and Mark Rowland. Distributional reinforcement
    learning. MIT Press, 2023.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Marc G Bellemare, Will Dabney, and Mark Rowland. 分布式强化学习. MIT Press, 2023.
- en: '![PIC](img/file0.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file0.png)'
- en: '[www.packt.com](https://www.packt.com)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[www.packt.com](https://www.packt.com)'
- en: Subscribe to our online digital library for full access to over 7,000 books
    and videos, as well as industry leading tools to help you plan your personal development
    and advance your career. For more information, please visit our website.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 订阅我们的在线数字图书馆，全面访问超过7,000本书籍和视频，以及行业领先的工具，帮助您规划个人发展并推动职业发展。如需更多信息，请访问我们的网站。
- en: Why subscribe?
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要订阅？
- en: Spend less time learning and more time coding with practical eBooks and Videos
    from over 4,000 industry professionals
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少学习时间，更多时间编码，享受来自4000多位行业专家的实用电子书和视频
- en: Improve your learning with Skill Plans built especially for you
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过为您量身定制的技能计划提升学习效果
- en: Get a free eBook or video every month
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每月获取一本免费的电子书或视频
- en: Fully searchable for easy access to vital information
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全可搜索，轻松访问关键信息
- en: Copy and paste, print, and bookmark content
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复制、粘贴、打印和收藏内容
- en: At [www.packt.com](https://www.packt.com), you can also read a collection of
    free technical articles, sign up for a range of free newsletters, and receive
    exclusive discounts and offers on Packt books and eBooks.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在[www.packt.com](https://www.packt.com)，您还可以阅读一系列免费的技术文章，订阅各种免费的新闻通讯，并获得Packt图书和电子书的独家折扣和优惠。
- en: Other Books You May Enjoy
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 您可能会喜欢的其他书籍
- en: 'If you enjoyed this book, you may be interested in these other books by Packt:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您喜欢这本书，您可能会对Packt的这些其他书籍感兴趣：
- en: '[![PIC](img/file350.png)](https://www.packtpub.com/en-us/product/mastering-pytorch-9781801074308)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[![图片](img/file350.png)](https://www.packtpub.com/en-us/product/mastering-pytorch-9781801074308)'
- en: Mastering PyTorch
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 《掌握PyTorch》
- en: Ashish Ranjan Jha
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Ashish Ranjan Jha
- en: 'ISBN: 9781801074308'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 'ISBN: 9781801074308'
- en: Implement text, vision, and music generation models using PyTorch
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PyTorch实现文本、视觉和音乐生成模型
- en: Build a deep Q-network (DQN) model in PyTorch
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在PyTorch中构建深度Q网络（DQN）模型
- en: Deploy PyTorch models on mobile devices (Android and iOS)
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在移动设备（Android和iOS）上部署PyTorch模型
- en: Become well versed in rapid prototyping using PyTorch with fastai
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 熟练使用PyTorch和fastai进行快速原型设计
- en: Perform neural architecture search effectively using AutoML
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用AutoML高效进行神经网络架构搜索
- en: Easily interpret machine learning models using Captum
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Captum轻松解读机器学习模型
- en: Design ResNets, LSTMs, and graph neural networks (GNNs)
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计ResNets、LSTMs和图神经网络（GNNs）
- en: Create language and vision transformer models using Hugging Face
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Hugging Face创建语言和视觉转换器模型
- en: '[![PIC](img/file351.png)](https://www.packtpub.com/en-us/product/python-for-algorithmic-trading-cookbook-9781835084700)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[![图片](img/file351.png)](https://www.packtpub.com/en-us/product/python-for-algorithmic-trading-cookbook-9781835084700)'
- en: Python for Algorithmic Trading Cookbook
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 《算法交易食谱中的Python》
- en: Jason Strimpel
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Jason Strimpel
- en: 'ISBN: 9781835084700'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 'ISBN: 9781835084700'
- en: Acquire and process freely available market data with the OpenBB Platform
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用OpenBB平台获取并处理自由可用的市场数据
- en: Build a research environment and populate it with financial market data
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个研究环境，并用金融市场数据填充它
- en: Use machine learning to identify alpha factors and engineer them into signals
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用机器学习识别阿尔法因子并将其转化为信号
- en: Use VectorBT to find strategy parameters using walk-forward optimization
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用VectorBT通过步进优化找到策略参数
- en: Build production-ready backtests with Zipline Reloaded and evaluate factor performance
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Zipline Reloaded构建生产级回测并评估因子表现
- en: Set up the code framework to connect and send an order to Interactive Brokers
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置代码框架以连接并向Interactive Brokers发送订单
- en: Packt is searching for authors like you
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Packt正在寻找像您这样的作者
- en: If you’re interested in becoming an author for Packt, please visit [authors.packtpub.com](https://authors.packtpub.com)
    and apply today. We have worked with thousands of developers and tech professionals,
    just like you, to help them share their insight with the global tech community.
    You can make a general application, apply for a specific hot topic that we are
    recruiting an author for, or submit your own idea.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣成为Packt的作者，请访问[authors.packtpub.com](https://authors.packtpub.com)并立即申请。我们与成千上万的开发人员和技术专业人士合作，帮助他们与全球技术社区分享见解。您可以进行一般申请，申请特定的热门话题，或提交您自己的创意。
