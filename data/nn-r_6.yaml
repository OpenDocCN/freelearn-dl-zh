- en: Recurrent and Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 循环神经网络与卷积神经网络
- en: Until now, we have been studying feed-forward networks, where the data moves
    in one direction and there is no interconnection of nodes in each layer. In the
    presence of basic hypotheses that interact with some problems, the intrinsic unidirectional
    structure of feed-forward networks is strongly limiting. However, it is possible
    to start from it and create networks in which the results of computing one unit
    affect the computational process of the other. It is evident that algorithms that
    manage the dynamics of these networks must meet new convergence criteria.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在研究前馈网络，其中数据单向流动，每一层中的节点没有相互连接。面对与某些问题交互的基本假设，前馈网络固有的单向结构显得尤为局限。然而，我们可以从前馈网络出发，构建结果计算会影响到其他计算过程的网络。显然，管理这些网络动态的算法必须满足新的收敛标准。
- en: 'In this chapter, we will introduce **Recurrent Neural Networks** (**RNN**),
    which are networks with cyclic data flows. We will also see **Convolutional Neural
    Networks** (**CNN**), which are standardized neural networks mainly used for image
    recognition. For both of these types of networks, we will do some sample implementations
    in R. The following topics are covered:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍**循环神经网络**（**RNN**），它是具有循环数据流的网络。我们还将介绍**卷积神经网络**（**CNN**），这是一种主要用于图像识别的标准化神经网络。对于这两种类型的网络，我们将在
    R 中做一些示例实现。以下是本章涵盖的主题：
- en: RNN
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RNN
- en: The `rnn` package
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rnn` 包'
- en: '**Long Short-Term Memory** (**LSTM**) model'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**长短期记忆**（**LSTM**）模型'
- en: CNN
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN
- en: Common CNN architecture--**LeNet**
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的 CNN 架构——**LeNet**
- en: At the end of the chapter, we will understand training, testing, and evaluating
    an RNN. We will learn how to visualize the RNN model in R environment. We will
    also be able to train an LSTM model. We will cover the concepts as CNN and common
    CNN architecture--LeNet.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，我们将理解如何训练、测试和评估一个 RNN。我们将学习如何在 R 环境中可视化 RNN 模型。我们还将能够训练一个 LSTM 模型。我们将涵盖
    CNN 的概念和常见的 CNN 架构——LeNet。
- en: Recurrent Neural Network
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 循环神经网络
- en: 'Within the set of **Artificial Neural Networks** (**ANN**), there are several
    variants based on the number of hidden layers and data flow. One of the variants
    is RNN, where the connections between neurons can form a cycle. Unlike feed-forward
    networks, RNNs can use internal memory for their processing. RNNs are a class
    of ANNs that feature connections between hidden layers that are propagated through
    time in order to learn sequences. RNN use cases include the following fields:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在**人工神经网络**（**ANN**）的范畴内，基于隐藏层数量和数据流的不同，有几种变体。其中一种变体是 RNN，其中神经元之间的连接可以形成一个循环。与前馈网络不同，RNN
    可以利用内部记忆进行处理。RNN 是一类具有隐藏层连接并且这些连接通过时间传播以学习序列的 ANN。RNN 的应用场景包括以下领域：
- en: Stock market predictions
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 股票市场预测
- en: Image captioning
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像标注
- en: Weather forecast
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 天气预报
- en: Time-series-based forecasts
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于时间序列的预测
- en: Language translation
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言翻译
- en: Speech recognition
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语音识别
- en: Handwriting recognition
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手写识别
- en: Audio or video processing
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频或视频处理
- en: Robotics action sequencing
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器人动作序列
- en: The networks we have studied so far (feed-forward networks) are based on input
    data that is powered to the network and converted into output. If it is a supervised
    learning algorithm, the output is a label that can recognize the input. Basically,
    these algorithms connect raw data to specific categories by recognizing patterns.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们研究的网络（前馈网络）基于输入数据，这些数据被输入到网络中并转换为输出。如果是监督学习算法，输出是一个标签，用来识别输入数据。基本上，这些算法通过识别模式将原始数据与特定类别连接起来。
- en: Recurrent networks, on the other hand, take as their input not only current
    input data that is powered to the network but also what they have experienced
    over time.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 循环网络则不同，它们不仅接受当前输入数据，还会结合它们随着时间积累的经验进行处理。
- en: The decision made by a recurrent network at a specific instant affects the decision
    it will reach immediately afterwards. So, recurrent networks have two input sources--the
    present and the recent past--that combine to determine how they respond to new
    data, just as people do in life everyday.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 循环网络在特定时刻做出的决策会影响它随后的决策。因此，循环网络有两个输入源——现在和最近的过去——它们结合起来决定如何响应新数据，就像人们每天生活中一样。
- en: 'Recurrent networks are distinguished from feed-forward networks thanks to the
    feedback loop linked to their past decisions, thus accepting their output momentarily
    as inputs. This feature can be emphasized by saying that recurrent networks have
    memory. Adding memory to neural networks has a purpose: there is information in
    the sequence itself and recurrent networks use it to perform the tasks that feed-forward
    networks cannot.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 循环网络与前馈网络的区别在于，它们通过反馈环路与过去的决策相联系，因此会暂时将其输出作为输入。这个特性可以通过说循环网络具有记忆来加以强调。向神经网络添加记忆是有目的的：序列本身包含信息，而循环网络利用这些信息完成前馈网络无法完成的任务。
- en: 'RNN is a class of neural network where there are connections between neurons
    that form a directed cycle. A typical RNN is represented in the following figure:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: RNN是一类神经网络，其中神经元之间的连接形成一个有向循环。一个典型的RNN如下图所示：
- en: '![](img/00120.gif)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00120.gif)'
- en: Here, the output of one instance is taken as input for the next instance for
    the same neuron. The way the data is kept in memory and flows at different time
    periods makes RNNs powerful and successful.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，一个实例的输出作为下一个实例的输入，应用于同一个神经元。数据如何在不同时间点保持在记忆中并流动，使得RNN强大而成功。
- en: 'Under RNNs, there are more variants in the way the data flows backwards:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在RNN中，数据向后流动的方式有更多变种：
- en: Fully recurrent
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全循环
- en: Recursive
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 递归
- en: Hopfield
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 霍普菲尔德（Hopfield）
- en: Elman and Jordan networks
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 埃尔曼（Elman）和乔丹（Jordan）网络
- en: Neural history compressor
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经历史压缩器
- en: LSTM
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 长短期记忆（LSTM）
- en: '**Gated Recurrent Unit** (**GRU**)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**门控循环单元（GRU）**'
- en: Bidirectional
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 双向
- en: Recurrent MLP
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 循环多层感知机（Recurrent MLP）
- en: 'Recurrent networks are designed to recognize patterns as a sequence of data
    and are helpful in prediction and forecasting. They can work on text, images,
    speech, and time series data. RNNs are among the powerful ANNs and represent the
    biological brain, including memory with processing power. Recurrent networks take
    inputs from the current input (like a feed-forward network) and the output that
    was calculated previously:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 循环网络旨在识别作为数据序列的模式，对预测和预测任务非常有帮助。它们可以应用于文本、图像、语音和时间序列数据。RNN是强大的人工神经网络（ANN）之一，代表了生物大脑，包括具有处理能力的记忆。循环网络从当前输入（像前馈网络一样）和先前计算的输出中获取输入：
- en: '![](img/00121.gif)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00121.gif)'
- en: To understand this better, we consider the RNN as a network of neural networks,
    and the cyclic nature is **unfolded** in the following manner. The state of a
    neuron *h* is considered at different time periods (*-t-1*, *t*, *t+1* and so
    on) until convergence or the total number of epochs is reached.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这一点，我们将RNN看作是一个神经网络的网络，其循环特性以以下方式**展开**。神经元*h*的状态会在不同的时间段（*t-1*、*t*、*t+1*等）被考虑，直到收敛或达到总的训练轮数。
- en: 'Vanilla is the first model of recurrent ANNs that was introduced. A vanilla
    RNN is shown in the following figure:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Vanilla是最早提出的循环ANN模型。一个vanilla RNN如下图所示：
- en: '![](img/00122.gif)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00122.gif)'
- en: Other variants such as GRU or LSTM networks are more widespread given the simplicity
    of implementation, and they have demonstrated remarkable performance in a wide
    range of applications involving sequences such as language modeling, speech recognition,
    image captioning, and automatic translation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于实现的简便性，其他变种如GRU或LSTM网络更为广泛，并且它们在语言建模、语音识别、图像字幕生成和自动翻译等涉及序列的广泛应用中表现出色。
- en: 'RNNs can be implemented in R through the following packages:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: RNN可以通过以下包在R中实现：
- en: '`rnn`'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rnn`'
- en: '`MxNetR`'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MxNetR`'
- en: '`TensorFlow` for R'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorFlow` for R'
- en: RNNs are mainly used for sequence modeling. The inputs and outputs are treated
    as vectors (a matrix of numbers). For another level of understanding of RNNs,
    I advise you to go through the character sequencing example by Andrej Karpathy.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 循环神经网络（RNN）主要用于序列建模。输入和输出被视为向量（数字矩阵）。为了更深入理解RNN，我建议你学习Andrej Karpathy的字符序列示例。
- en: The features of RNN make it like an ANN with memory. The ANN memory is more
    like the human brain. With memory, we can make machines think from scratch and
    learn from their "memory." RNNs are basically ANNs with loops that allow information
    to persist in the network. The looping allows information to be passed from state
    t to state *t+1*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: RNN的特点使其像一个带记忆的ANN。ANN的记忆更像是人类的大脑。有了记忆，我们可以让机器从零开始思考并从它们的“记忆”中学习。RNN基本上是带有循环的ANN，这些循环允许信息在网络中保持。循环允许信息从状态t传递到状态*t+1*。
- en: As seen in the preceding diagram, RNNs can be thought of as multiple copies
    of the same ANN, with the output of one passing on as input to the next one. When
    we persist the information, as the patterns change, RNN is able to predict the
    *t+1* value. This is particularly useful for analyzing time-series-based problems.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，RNN可以被看作是相同ANN的多个副本，其中一个的输出作为输入传递给下一个。当我们保存信息时，随着模式的变化，RNN能够预测*t+1*的值。这对于分析基于时间序列的问题尤其有用。
- en: There is no specific labeling required; the value that is part of the input
    forms the time series variable, and RNN can learn the pattern and do the prediction.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 无需特别标注；输入的一部分值形成时间序列变量，RNN能够学习模式并进行预测。
- en: The internal state of the RNN is updated for every time step of the learning
    process. The feed-forward mechanism in RNN is similar to ANN; however, the backpropagation
    is an error term correction following something called **Backpropagation Through
    Time** (**BPTT**).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: RNN的内部状态在每个学习过程的时间步长中更新。RNN中的前馈机制类似于ANN；然而，反向传播则是通过所谓的**时间反向传播**（**BPTT**）进行误差项修正。
- en: 'Backpropagation through time follows this pseudocode:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 时间反向传播遵循以下伪代码：
- en: Unfold the RNN to contain *n* feed-forward networks.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 展开RNN以包含*n*个前馈网络。
- en: Initialize the weights *w* to random values.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将权重*w*初始化为随机值。
- en: Perform the following until the stopping criteria is met or you are done with
    the required number of epochs.
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下操作，直到满足停止条件或完成所需的训练周期数。
- en: Set inputs to each network with values as *x[i.]*
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '将输入设置为每个网络的值，作为*x[i.]* '
- en: Forward-propagate the inputs over the whole unfolded network.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入在整个展开的网络上进行前向传播。
- en: Back-propagate the error over the unfolded network.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将误差反向传播到展开的网络中。
- en: Update all the weights in the network.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新网络中的所有权重。
- en: Average out the weights to find the final weight in the folded network.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将权重平均化，以找到折叠网络中的最终权重。
- en: The rnn package in R
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: R中的rnn包
- en: 'To implement RNN in an R environment, we can use the `rnn` package available
    through CRAN. This package is widely used to implement an RNN. A brief description
    of the `rnn` package, extracted from the official documentation, is shown in the
    following table:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在R环境中实现RNN，我们可以使用通过CRAN提供的`rnn`包。该包广泛用于实现RNN。以下表格展示了从官方文档中提取的`rnn`包的简要描述：
- en: '| **rnn**: Recurrent Neural Network |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| **rnn**：递归神经网络 |'
- en: '| **Description**: |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| **描述**： |'
- en: '| Implementation of an RNN in R |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| R中实现RNN |'
- en: '| **Details**: |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| **详细信息**： |'
- en: '| Package: `rnn` Type: Package'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '| 包：`rnn` 类型：包'
- en: 'Version: 0.8.0'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 版本：0.8.0
- en: 'Date: 2016-09-11'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2016-09-11
- en: 'License: GPL-3 |'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 许可证：GPL-3 |
- en: '| **Authors**: |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| **作者**： |'
- en: '| Bastiaan Quast Dimitri Fichou |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| Bastiaan Quast Dimitri Fichou |'
- en: 'The main functions used from the `rnn` package are shown in this table:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 从`rnn`包中使用的主要函数显示在下表中：
- en: '| `predict_rnn` | Predicts the output of an RNN model:`predict_rnn(model, X,
    hidden = FALSE, real_output = T, ...)` |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| `predict_rnn` | 预测RNN模型的输出：`predict_rnn(model, X, hidden = FALSE, real_output
    = T, ...)` |'
- en: '| `run.rnn_demo` | A function to launch the `rnn_demo` app:`run.rnn_demo(port
    = NULL)` |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| `run.rnn_demo` | 启动`rnn_demo`应用程序的函数：`run.rnn_demo(port = NULL)` |'
- en: '| `trainr` | This trains the RNN. The model is used by the `predictr` function.
    |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| `trainr` | 训练RNN的函数。该模型由`predictr`函数使用。 |'
- en: '| `predictr` | This predicts the output of an RNN model:`predictr(model, X,
    hidden = FALSE, real_output = T, ...)` |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| `predictr` | 预测RNN模型的输出：`predictr(model, X, hidden = FALSE, real_output =
    T, ...)` |'
- en: As always, to be able to use a library, we must first install and then load
    it into our script.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，要使用一个库，必须先安装并将其加载到我们的脚本中。
- en: Remember, to install a library that is not present in the initial distribution
    of R, you must use the `install.package` function. This is the main function to
    install packages. It takes a vector of names and a destination library, downloads
    the packages from the repositories and installs them. This function should be
    used only once and not every time you run the code.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，要安装在R初始分发中不存在的库，必须使用`install.package`函数。这是安装包的主要功能。它接受一个名称向量和一个目标库，从仓库下载包并进行安装。此函数应只使用一次，而不是每次运行代码时都使用。
- en: 'So let''s install and load the library:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们来安装并加载库：
- en: '[PRE0]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we load the library (`library("rnn")`), we may receive the following error:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们加载库（`library("rnn")`）时，可能会收到以下错误：
- en: '[PRE1]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Do not worry, as it''s nothing serious! R is just saying that, in order to
    run the `rnn` library, you also need to install the `digest` library. Remember
    it; in future, if such a problem happens, you now know how to solve it. Just add
    the following command:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 别担心，这没什么大不了的！R 只是告诉你，为了运行 `rnn` 库，你还需要安装 `digest` 库。记住这一点；以后如果出现类似问题，你就知道怎么解决了。只需添加以下命令：
- en: '[PRE2]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now we can launch the demo:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以启动演示：
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When we run `run.rnn_demo()` after installing the `rnn` package, we can access
    a web page through `127.0.0.1:5876`, which allows us to run a demo of an RNN with
    preset values and also visually see how the parameters influence an RNN, as shown
    in the following figure:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们安装了 `rnn` 包并运行 `run.rnn_demo()` 后，可以通过 `127.0.0.1:5876` 访问一个网页，网页上可以运行一个具有预设值的
    RNN 演示，同时可以直观地看到参数如何影响 RNN，如下图所示：
- en: '![](img/00123.jpeg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00123.jpeg)'
- en: 'At this point, we will be able to set the parameters of our network and choose
    the appropriate values to be inserted into the boxes via its labels. The following
    parameters must be set correctly:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，我们可以设置网络的参数，并通过标签选择合适的值填入框中。以下参数必须正确设置：
- en: '`time dimension`'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time dimension`'
- en: '`training sample dimension`'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`training sample dimension`'
- en: '`testing sample dimension`'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`testing sample dimension`'
- en: '`number of hidden layers`'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`number of hidden layers`'
- en: '`Number of unit in the layer number 1`'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`层数1中的单元数`'
- en: '`Number of unit in the layer number 2`'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`层数2中的单元数`'
- en: '`learningrate`'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learningrate`'
- en: '`batchsize`'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batchsize`'
- en: '`numepochs`'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numepochs`'
- en: '`momentum`'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`momentum`'
- en: '`learningrate_decay`'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learningrate_decay`'
- en: After doing this, we just have to click on the train button and the command
    will be built and trained.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 做完这些后，我们只需点击训练按钮，命令就会被构建并进行训练。
- en: 'The following figure shows the results of the simulation:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了模拟的结果：
- en: '![](img/00124.jpeg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00124.jpeg)'
- en: 'The `trainr` and `predictr` functions are the most important functions in the
    `rnn` package. The `trainr()` function trains a model with the set of `X` and
    `Y` parameters, which can be used for prediction using the `predictr()` function:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`trainr` 和 `predictr` 函数是 `rnn` 包中最重要的函数。`trainr()` 函数使用 `X` 和 `Y` 参数集来训练模型，训练后的模型可以通过
    `predictr()` 函数进行预测：'
- en: '[PRE4]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `trainr()` function takes the following parameters. The output is a model
    that can be used for prediction:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`trainr()` 函数接受以下参数。输出为一个可以用于预测的模型：'
- en: '| `Y` | Array of output values:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '| `Y` | 输出值数组：'
- en: '`dim 1`: Samples (must be equal to dim 1 of `X`)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim 1`：样本（必须等于 `X` 的 dim 1）'
- en: '`dim 2`: Time (must be equal to dim 2 of `X`)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim 2`：时间（必须等于 `X` 的 dim 2）'
- en: '`dim 3`: Variables (could be one or more, if a matrix, will be coerced to an
    array)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim 3`：变量（可以是一个或多个，如果是矩阵，将被强制转换为数组）'
- en: '|'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| `X` | Array of input values:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '| `X` | 输入值数组：'
- en: '`dim 1`: Samples'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim 1`：样本'
- en: '`dim 2`: Time'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim 2`：时间'
- en: '`dim 3`: Variables (could be one or more; if it is a matrix, will be coerced
    to an array)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim 3`：变量（可以是一个或多个；如果是矩阵，将被强制转换为数组）'
- en: '|'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| `learningrate` | Learning rate to be applied for weight iteration. |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| `learningrate` | 应用于权重迭代的学习率。 |'
- en: '| `learningrate_decay` | Coefficient to apply to the learning rate at each
    epoch via the `epoch_annealing` function. |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| `learningrate_decay` | 通过 `epoch_annealing` 函数在每个 epoch 应用到学习率的系数。 |'
- en: '| `momemtum` | The coefficient of the last weight iteration to keep for faster
    learning. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| `momentum` | 用于加速学习的最后一次权重迭代的系数。 |'
- en: '| `hidden_dim` | The dimensions of the hidden layers. |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| `hidden_dim` | 隐藏层的维度。 |'
- en: '| `network_type` | The type of network, which could be `rnn`, `gru` or `lstm`.
    |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| `network_type` | 网络类型，可以是 `rnn`、`gru` 或 `lstm`。 |'
- en: '| `numepochs` | The number of iterations, that is, the number of times the
    whole dataset is presented to the network |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `numepochs` | 迭代次数，即整个数据集被网络呈现的次数 |'
- en: '| `sigmoid` | Method to be passed to the `sigmoid` function. |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| `sigmoid` | 传递给 `sigmoid` 函数的方法。 |'
- en: '| `batch size` | Number of samples used at each weight iteration. Only one
    is supported for the moment. |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| `batch size` | 每次权重迭代使用的样本数量。当前仅支持一个。 |'
- en: '| `epoch_function` | Vector of functions to be applied at each epoch loop.
    Use it to interact with the objects inside the list model or to print and plot
    at each epoch. It should return the model. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| `epoch_function` | 在每个 epoch 循环中应用的函数向量。用它与模型中的对象进行交互，或者在每个 epoch 打印和绘图。它应该返回模型。
    |'
- en: '| `loss function` | Applied in each sample loop, vocabulary to verify. |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| `loss function` | 应用于每个样本循环，词汇表用于验证。 |'
- en: '| `...` | Arguments to be passed to methods, to be used in user defined functions.
    |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| `...` | 传递给方法的参数，用于用户定义的函数中。 |'
- en: Now let's look at a simple example. This example included is in the official
    documentation of the CRAN `rnn` package to demonstrate the `trainr` and `predictr`
    functions and see the accuracy of the predictions.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一个简单的例子。这个例子包含在CRAN `rnn`包的官方文档中，用于演示`trainr`和`predictr`函数，并查看预测的准确性。
- en: We have `X1` and `X` with random numbers in the range *0-127*. `Y` is initialized
    as `X1+X2`. After converting `X1`, `X2`, and `Y` to binary values, we use `trainr`
    to train `Y` based on `X(array of X1 and X2)`.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有`X1`和`X`，其中的随机数在*0-127*范围内。`Y`被初始化为`X1+X2`。在将`X1`、`X2`和`Y`转换为二进制值后，我们使用`trainr`根据`X`（由`X1`和`X2`组成的数组）训练`Y`。
- en: 'Using the model, we predict `B` based on another sample of `A1+A2`. The difference
    of errors is plotted as a histogram:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 使用模型，我们根据另一组`A1+A2`样本预测`B`。错误的差异绘制为直方图：
- en: '[PRE5]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As usual, we will analyze the code line by line, explaining in detail all the
    features applied to capture the results:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，我们将逐行分析代码，详细解释应用于捕获结果的所有特性：
- en: '[PRE6]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The first line of the initial code are used to load the library needed to run
    the analysis. Let''s go to the following commands:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 初始代码的第一行用于加载运行分析所需的库。接下来我们来看以下命令：
- en: '[PRE7]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: These lines create training response numbers; these two vectors will be the
    inputs of the network we are about to build. We have used the `sample()` function
    to take a sample of the specified size from the elements of `x` either with or
    without replacement. The two vectors contain 7,000 random integer values between
    `1` and `127`.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这些行创建训练响应数字；这两个向量将成为我们即将构建的网络的输入。我们使用了`sample()`函数，从`x`的元素中按指定大小取样，既可以有放回也可以没有放回。两个向量包含7,000个在`1`和`127`之间的随机整数值。
- en: '[PRE8]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This command creates training response numbers; this is our target, or what
    we want to predict with the help of the network.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令创建训练响应数字；这是我们的目标，或者说是我们希望通过网络来预测的内容。
- en: '[PRE9]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'These three lines of code convert integers into binary sequences. We need to
    transform numbers into binaries before adding bit by bit. In the end, we get a
    sequence of eight values for each value, these values being `0` or `1`. To understand
    the transformation we analyze a preview of one of these variables:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这三行代码将整数转换为二进制序列。我们需要在逐位相加之前将数字转换为二进制。最终，每个值会得到一个由八个值组成的序列，这些值为`0`或`1`。为了理解这个转换，我们分析这些变量之一的预览：
- en: '[PRE10]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s go back to analyze the code:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回过头来分析代码：
- en: '[PRE11]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This code creates a 3D array as required by the `trainr()` function. In this
    array, we have the following:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码创建了一个3D数组，这是`trainr()`函数所要求的。在这个数组中，我们有以下内容：
- en: '`dim 1`: Samples (must be equal to `dim 1` of inputs)'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim 1`：样本（必须等于输入的`dim 1`）'
- en: '`dim 2`: Time (must be equal to `dim 2` of inputs)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim 2`：时间（必须等于输入的`dim 2`）'
- en: '`dim 3`: Variables (could be one or more; if it is a matrix, this will be coerced
    to the array)'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dim 3`：变量（可以是一个或多个；如果是矩阵，将被强制转换为数组）'
- en: '[PRE12]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `trainr()` function trains an RNN in native R. It takes a few minutes as
    the training happens based on `X` and `Y`. The following code shows the last 10
    trained epoch results displayed on the R prompt:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '`trainr()`函数在本地R中训练RNN。由于训练是基于`X`和`Y`进行的，所以需要几分钟时间。以下代码展示了在R提示符上显示的最后10次训练周期结果：'
- en: '[PRE13]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can see the evolution of the algorithm by charting the error made by the
    algorithm to subsequent epochs:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过绘制算法在后续周期中的错误来查看算法的演变：
- en: '[PRE14]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This graph shows the epoch versus error:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 该图显示了周期与错误之间的关系：
- en: '![](img/00125.gif)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00125.gif)'
- en: 'Now the model is ready and we can use it to test the network. But first, we
    need to create some test data:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已经准备好，我们可以使用它来测试网络。但首先，我们需要创建一些测试数据：
- en: '[PRE15]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, let us run the prediction for new data:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们运行对新数据的预测：
- en: '[PRE16]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Convert back to integers:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 转换回整数：
- en: '[PRE17]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Finally, plot the differences as a histogram:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将差异绘制为直方图：
- en: '[PRE18]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The histogram of errors is shown as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 错误的直方图如下所示：
- en: '![](img/00126.gif)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00126.gif)'
- en: As can be seen here, the bin with more frequent is near zero to indicate that
    in most cases, the predictions coincide with the current values. All the other
    bins are related to the errors. We can therefore say that the network simulates
    the system with good performance.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，频率较高的区间靠近零，表明在大多数情况下，预测值与当前值一致。所有其他区间与误差相关。因此，我们可以说网络以良好的性能模拟了系统。
- en: LSTM model
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LSTM模型
- en: We have seen that RNNs have a memory that uses persistent previous information
    to be used in the current neural network processing. The previous information
    is used in the present task. However, the memory is short-term and we do not have
    a list of all of the previous information available for the neural node.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，RNN具有一种记忆，利用持续的先前信息来处理当前神经网络的计算任务。之前的信息会在当前任务中被使用。然而，这种记忆是短期的，神经节点无法访问所有的历史信息。
- en: When we introduce a long-term memory into the RNN, we are able to remember a
    lot of previous information and use it for the current processing. This concept
    is called LSTM model of RNN, which has numerous use cases in video, audio, text
    prediction, and various other applications.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在RNN中引入长期记忆时，就能记住大量的历史信息并在当前处理时使用。这一概念被称为LSTM模型，它在视频、音频、文本预测及其他各种应用中有着广泛的使用场景。
- en: LSTMs were introduced by Hochreiter & Schmidhuber in 1997.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM由Hochreiter和Schmidhuber于1997年提出。
- en: The LSTM network is trained using **BPTT** and diminishes the vanishing gradient
    problem. LSTMs have powerful applications in time series predictions and can create
    large, recurrent networks to address difficult sequence problems in machine learning.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM网络使用**BPTT**进行训练，并减轻了消失梯度问题。LSTM在时间序列预测中有强大的应用，并能够创建大型递归网络来解决机器学习中的复杂序列问题。
- en: 'LSTM have **gates** that make the long/short term memory possible. These are
    contained in memory blocks connected through layers:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM具有**门**，使得长短期记忆成为可能。这些门包含在通过层连接的记忆块中：
- en: '![](img/00127.gif)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00127.gif)'
- en: 'There are three types of gates within a unit:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 单元内有三种类型的门：
- en: '**Input Gate:** Scales input to cell (write)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入门**：将输入缩放到单元（写入）'
- en: '**Output Gate**: Scales output to cell (read)'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出门**：将输出缩放到单元（读取）'
- en: '**Forget Gate**: Scales old cell value (reset)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遗忘门**：将旧的单元值缩放（重置）'
- en: Each gate is like a switch that controls the read/write, thus incorporating
    the long-term memory function into the LSTM model.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 每个门就像一个开关，控制读/写，从而将长期记忆功能整合到LSTM模型中。
- en: 'LSTMs can be used to solve the following sequence prediction problems:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM可以用于解决以下序列预测问题：
- en: Direct sequence prediction
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接序列预测
- en: Sequence classification
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列分类
- en: Sequence generation
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列生成
- en: Sequence to sequence prediction
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 序列到序列的预测
- en: 'The key differences between GRU and LSTM are:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: GRU和LSTM之间的关键区别是：
- en: A GRU has two gates, whereas an LSTM has three gates.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GRU有两个门，而LSTM有三个门。
- en: GRUs don't possess any internal memory that is different from the exposed hidden
    state. They don't have the output gate, which is present in LSTMs.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GRU没有任何不同于暴露的隐藏状态的内部记忆。它们没有LSTM中存在的输出门。
- en: There is no second nonlinearity applied when computing the output in GRU.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在计算GRU的输出时没有应用第二个非线性操作。
- en: Convolutional Neural Networks
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: Another important set of neural networks in deep learning is CNN. They are designed
    specifically for image recognition and classification. CNNs have multiple layers
    of neural networks that extract information from images and determine the class
    they fall into.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习中另一个重要的神经网络是CNN。它们专门用于图像识别和分类。CNN有多个神经网络层，能够从图像中提取信息并判断其属于哪个类别。
- en: For example, a CNN can detect whether the image is a cat or not if it is trained
    with a set of images of cats. We will see the architecture and working of CNN
    in this section.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果CNN经过一组猫的图像训练，它就能检测图像中是否为猫。在这一部分，我们将了解CNN的架构和工作原理。
- en: For a program, any image is a just a set of RGB numbers in a vector format.
    If we can make a neural network understand the pattern, it can form a CNN and
    detect images.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个程序，任何图像都只是以向量格式表示的一组RGB数字。如果我们能够让神经网络理解这个模式，它就能形成CNN并检测图像。
- en: Regular neural nets are universal mathematical approximators that take an input,
    transform it through a series of functions, and derive the output. However, these
    regular neural networks do not scale well for an image analysis. For a 32 x 32
    pixel RGB image, the hidden layer would have *32*32*3=3072* weights. The regular
    neural nets work fine for this case. However, when the RGB image is scaled to
    size *200 x 200* pixel, the number of weights required in the hidden layer is
    *200*200*3=120,000* and the network does not perform well.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 普通神经网络是通用的数学近似器，它接受输入，通过一系列函数进行转换，并得出输出。然而，这些普通神经网络对于图像分析的扩展性不好。对于一个32 x 32像素的RGB图像，隐藏层需要*32*32*3=3072*个权重。对于这种情况，普通神经网络运行良好。然而，当RGB图像扩展到*200
    x 200*像素时，隐藏层所需的权重数是*200*200*3=120,000*，此时网络表现不佳。
- en: Enter CNN to solve this scalability problem. In CNN, the layers of a CNN have
    neurons arranged in three dimensions (**height**, **width**, and **depth**).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 输入CNN以解决这个可扩展性问题。在CNN中，CNN的各层神经元在三维中排列（**高度**，**宽度**和**深度**）。
- en: 'The following diagram shows a neural net and a CNN:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了神经网络和卷积神经网络（CNN）：
- en: '![](img/00128.gif)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00128.gif)'
- en: 'CNN is a sequence of layers of neural nets, wherein each layer transforms one
    volume of activations to another through a differentiable function. There are
    three types of layers that build the CNN:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）是由神经网络层组成的序列，其中每一层通过可微分函数将一个激活值的体积转换为另一个激活值。CNN包含三种类型的层：
- en: Convolutional layer
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积层
- en: Pooling layer
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 池化层
- en: Fully connected layer
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全连接层
- en: 'Step #1 – filtering'
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第#1步 – 滤波
- en: 'The convolutional layer does the heavy math operations. In computer vision,
    a typical approach to processing an image is to convolute it with a filter to
    extract only the salient features in it. This is the first operation in a CNN.
    The input image is applied a filter logic to create an **activation map** or **feature
    map**:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层执行繁重的数学运算。在计算机视觉中，处理图像的典型方法是用滤波器进行卷积，只提取其中的显著特征。这是CNN中的第一步操作。输入图像应用滤波器逻辑，创建**激活图**或**特征图**：
- en: '![](img/00129.gif)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00129.gif)'
- en: The convoluted feature vector is created by applying the kernel vector on each
    3 x 3 vector of the image.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积特征向量是通过将卷积核向量应用到图像的每个3 x 3向量上创建的。
- en: 'The mathematical steps for filtering are as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波的数学步骤如下：
- en: Line up the feature and the image patch.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将特征与图像补丁对齐。
- en: Multiply each image pixel by the corresponding feature pixel.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个图像像素与相应的特征像素相乘。
- en: Add them up.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将它们加起来。
- en: Divide each sum by the total number of pixels in the feature.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将每个求和结果除以特征中像素的总数。
- en: Once the filtering is done, the next step is to compress the filtered pixels.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波完成后，下一步是压缩已滤波的像素。
- en: 'Step #2 – pooling'
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第#2步 – 池化
- en: 'In this step, we shrink the image stack. For each feature obtained in the convolutional
    step, we build up a matrix and now find the maximum in each chosen matrix to shrink
    the entire input. The steps are below:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们缩小图像堆栈。对于卷积步骤中获得的每个特征，我们建立一个矩阵，并在每个选择的矩阵中找到最大值，从而缩小整个输入。步骤如下：
- en: Pick a window size (usually 2 or 3).
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个窗口大小（通常为2或3）。
- en: Pick a stride moving range of pixels (usually 2).
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个步幅移动像素范围（通常为2）。
- en: Slide the window across the filtered images.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在已滤波的图像上滑动窗口。
- en: For each window, we take the maximum value.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个窗口，我们取最大值。
- en: If the slid window does not have the required number of cells as in the previous
    windows, we take whatever values are available.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果滑动窗口没有与之前的窗口相同数量的单元，我们取所有可用的值。
- en: 'Step #3 – ReLU for normalization'
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第#3步 – ReLU归一化
- en: In this step, we take the pooling output and for each pixel and apply the ReLU
    normalization to tweak the values. If any of the values is negative, we make it
    zero.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们采用池化输出，并对每个像素应用ReLU归一化以调整值。如果任何值为负数，我们将其设为零。
- en: 'Step #4 – voting and classification in the fully connected layer'
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第#4步 – 在完全连接层进行投票和分类
- en: The final layer is the fully connected layer and there is voting by the set
    of values to determine the class of the output. The fully connected layer is just
    a merged matrix of all the previous outputs.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一层是完全连接层，通过一组值进行投票，确定输出的类别。完全连接层只是所有先前输出的合并矩阵。
- en: This is the final layer and the output is determined based on the highest voted
    category.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最后一层，输出根据最高票选类别确定。
- en: By stacking up the layers in steps 1, 2, and 3, we form the convolution network,
    which can reduce the error term with backpropagation to give us the best prediction.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将第1、2、3步中的层叠加，我们形成了卷积网络，利用反向传播减少误差项，从而为我们提供最佳预测。
- en: The layers can be repeated multiple times and each layer output forms an input
    to the next layer.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 层次可以重复多次，每个层的输出会作为下一个层的输入。
- en: 'A classical CNN architecture would look like this:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的CNN架构将如下所示：
- en: '![](img/00130.jpeg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00130.jpeg)'
- en: 'An example classification prediction using CNN is shown in the following figure:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图例展示了使用CNN进行分类预测的示例：
- en: '![](img/00131.jpeg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00131.jpeg)'
- en: We will see an implementation of CNN using R in [Chapter 7](part0123.html#3L9L60-263fb608a19f4bb5955f37a7741ba5c4),
    *Use Cases of Neural Networks – Advanced Topics*.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第7章](part0123.html#3L9L60-263fb608a19f4bb5955f37a7741ba5c4)中看到使用R实现CNN的案例，*神经网络的应用案例
    - 高级话题*。
- en: Common CNN architecture - LeNet
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见的CNN架构 - LeNet
- en: LeNet-5 is a convolutional network designed by Le Cun in the 1990s for handwritten
    and machine-printed character recognition.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet-5是Le Cun在1990年代为手写和机器印刷字符识别设计的卷积网络。
- en: 'It is the first successful application of convolutional networks. It has the
    following architecture:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这是卷积网络的第一次成功应用。它具有以下架构：
- en: '![](img/00132.jpeg)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00132.jpeg)'
- en: Humidity forecast using RNN
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用RNN进行湿度预测
- en: As the first use case of RNNs, we see how we can train and predict an RNN using
    the `trainr()` function*.* Our purpose is to forecast the humidity of a certain
    location as a function of the day. The input file contains daily weather observations
    from multiple Australian weather stations. These observations are obtained from
    the Australian Commonwealth Bureau of Meteorology and are subsequently processed
    to create a relatively large sample dataset for illustrating analytics, data mining,
    and data science using R and the rattle.data package. The `weatherAUS` dataset
    is regularly updated and updates of this package usually correspond to updates
    to this dataset. The data is updated from the Bureau of Meteorology website. The
    `locationsAUS` dataset records the location of each weather station. The source
    dataset is copyrighted by the Australian Commonwealth Bureau of Meteorology and
    is used with permission.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 作为RNN的第一个应用案例，我们将看到如何使用`trainr()`函数训练并预测RNN*.*我们的目标是预测某一地点的湿度与日期的关系。输入文件包含来自多个澳大利亚气象站的每日气象观测数据。这些观测数据来自澳大利亚联邦气象局，并经过处理后创建了一个相对较大的样本数据集，用于展示使用R和rattle.data包进行分析、数据挖掘和数据科学。`weatherAUS`数据集会定期更新，该数据包的更新通常对应于此数据集的更新。数据来自气象局官网。`locationsAUS`数据集记录了每个气象站的地点。源数据集由澳大利亚联邦气象局拥有版权，并经许可使用。
- en: 'A CSV version of this dataset is available at the following link:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 此数据集的CSV版本可通过以下链接获得：
- en: '[https://rattle.togaware.com/weatherAUS.csv](https://rattle.togaware.com/weatherAUS.csv)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://rattle.togaware.com/weatherAUS.csv](https://rattle.togaware.com/weatherAUS.csv)'
- en: 'The `weatherAUS` dataset is a dataframe containing over 140,000 daily observations
    from over 45 Australian weather stations. This dataset contains the following
    variables:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '`weatherAUS`数据集是一个数据框，包含来自45个以上澳大利亚气象站的超过14万个每日观测数据。该数据集包含以下变量：'
- en: '`Date`: The date of observation (a `Date` object).'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Date`：观测日期（`Date`对象）。'
- en: '`Location`: The common name of the location of the weather station.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Location`：气象站地点的常用名称。'
- en: '`MinTemp`: The minimum temperature in degrees celsius.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MinTemp`：摄氏度下的最低温度。'
- en: '`MaxTemp`: The maximum temperature in degrees celsius.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MaxTemp`：摄氏度下的最高温度。'
- en: '`Rainfall`: The amount of rainfall recorded for the day in mm.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Rainfall`：当天记录的降水量（mm）。'
- en: '`Evaporation`: The so-called class a pan evaporation (mm) in the 24 hours to
    9 a.m.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Evaporation`：到上午9点的24小时内的蒸发量（mm）。'
- en: '`Sunshine`: The number of hours of bright sunshine in the day.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Sunshine`：白天的明媚阳光时数。'
- en: '`WindGustDir`: The direction of the strongest wind gust in the 24 hours to
    midnight.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WindGustDir`：午夜前24小时内最强风速的方向。'
- en: '`WindGustSpeed`: The speed (km/h) of the strongest wind gust in the 24 hours
    to midnight.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WindGustSpeed`：午夜前24小时内最强风速的速度（km/h）。'
- en: '`Temp9am`: Temperature (degrees C) at 9 a.m.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Temp9am`：上午9点的温度（摄氏度）。'
- en: '`RelHumid9am`: Relative humidity (percent) at 9 a.m.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RelHumid9am`：上午9点的相对湿度（百分比）。'
- en: '`Cloud9am`: Fraction of the sky obscured by clouds at 9 a.m. This is measured
    in oktas, which are a unit of eighths. It records how many eighths of the sky
    are obscured by cloud. A zero measure indicates completely clear sky whilst an
    8 indicates that it is completely overcast.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Cloud9am`：上午9点时，云层遮挡的天空比例。这个比例是以 oktas 为单位的，oktase 是以八分之一为单位的度量。它记录了有多少八分之一的天空被云层遮挡。0
    表示完全晴朗的天空，而 8 则表示完全阴天。'
- en: '`WindSpeed9am`: Wind speed (km/hr) averaged over 10 minutes prior to 9 a.m.
    6 `weatherAUS`.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WindSpeed9am`：上午9点前10分钟的平均风速（公里/小时）。'
- en: '`Pressure9am`: Atmospheric pressure (hpa) reduced to mean sea level at 9 a.m.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pressure9am`：上午9点的气压（hpa），经过海平面标准化。'
- en: '`Temp3pm`: Temperature (degrees C) at 3 p.m.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Temp3pm`：下午3点的温度（摄氏度）。'
- en: '`RelHumid3pm`: Relative humidity (percent) at 3 p.m.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RelHumid3pm`：下午3点的相对湿度（百分比）。'
- en: '`Cloud3pm`: Fraction of sky obscured by cloud (in oktas: eighths) at 3 p.m.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Cloud3pm`：下午3点时，云层遮挡的天空比例（以 oktas 为单位：八分之一）。'
- en: '`WindSpeed3pm`: Wind speed (km/hr) averaged over 10 minutes prior to 3 p.m.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WindSpeed3pm`：下午3点前10分钟的平均风速（公里/小时）。'
- en: '`Pressure3pm`: Atmospheric pressure (hpa) reduced to mean sea level at 3 p.m.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pressure3pm`：下午3点的气压（hpa），经过海平面标准化。'
- en: '`ChangeTemp`: Change in temperature.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChangeTemp`：温度变化。'
- en: '`ChangeTempDir`: Direction of change in temperature.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChangeTempDir`：温度变化的方向。'
- en: '`ChangeTempMag`: Magnitude of change in temperature.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChangeTempMag`：温度变化的幅度。'
- en: '`ChangeWindDirect`: Direction of wind change.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ChangeWindDirect`：风向变化的方向。'
- en: '`MaxWindPeriod`: Period of maximum wind.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MaxWindPeriod`：最大风速的周期。'
- en: '`RainToday`: Integer 1 if precipitation (mm) in the 24 hours to 9 a.m. exceeds
    1 mm, and 0 otherwise.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RainToday`：如果在9点之前的24小时内降水量（mm）超过1mm，则为整数1，否则为0。'
- en: '`TempRange`: Difference between minimum and maximum temperatures (degrees C)
    in the 24 hours to 9 a.m.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TempRange`：到上午9点的24小时内，最低温度与最高温度之间的差值（摄氏度）。'
- en: '`PressureChange`: Change in pressure.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PressureChange`：气压变化。'
- en: '`RISK_MM`: The amount of rain. A kind of measure of the risk.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RISK_MM`：降水量，某种风险的度量。'
- en: '`RainTomorrow`: The target variable. Will it rain tomorrow?'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RainTomorrow`：目标变量。明天会下雨吗？'
- en: 'In our case, we will use only two of the many variables contained in it:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，我们将只使用其中的两个变量：
- en: '`Date`: The date of observation (a `Date` object)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Date`：观察日期（`Date` 对象）'
- en: '`RelHumid9am`: Relative humidity (percent) at 9 a.m'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RelHumid9am`：上午9点的相对湿度（百分比）。'
- en: 'As said previously, the objective of this example is to forecast the humidity
    of a certain location as a function of the day. Here is the code that we will
    use in this example:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，本示例的目标是预测某个地点的湿度与日期的关系。这里是我们将在本示例中使用的代码：
- en: '[PRE19]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We begin analyzing the code line by line, explaining in detail all the features
    applied to capture the results:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始逐行分析代码，详细解释所有应用的特性，以捕获结果：
- en: '[PRE20]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The first two lines of the initial code are used to load the libraries needed
    to run the analysis.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 初始代码的前两行用于加载分析所需的库。
- en: Remember that to install a library that is not present in the initial distribution
    of R, you must use the `install.package` function. This is the main function to
    install packages. It takes a vector of names and a destination library, downloads
    the packages from the repositories and installs them. This function should be
    used only once and not every time you run the code.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，要安装一个在 R 的初始发行版中没有的库，必须使用 `install.package` 函数。这是安装包的主要函数。它接收一个包含名称的向量和一个目标库，从仓库中下载包并安装它们。这个函数应该仅使用一次，而不是每次运行代码时都使用。
- en: The `rattle.data` library contains the datasets used as default examples by
    the `rattle` package. The datasets themselves can be used independently of the
    `rattle` package to illustrate analytics, data mining, and data science tasks.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '`rattle.data` 库包含由 `rattle` 包默认使用的数据集。可以独立于 `rattle` 包使用这些数据集来展示分析、数据挖掘和数据科学任务。'
- en: 'The `rnn` library contains several functions for implementing an RNN in R:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '`rnn` 库包含用于在 R 中实现 RNN 的多个函数。'
- en: '[PRE21]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'With this command, we upload the dataset named `weatherAUS`, as mentioned,
    contained in the `rattle.data` library. In the second line, the `view` function
    is used to invoke a spreadsheet-style data viewer on the dataframe object, as
    shown in the following figure:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此命令，我们上传名为 `weatherAUS` 的数据集，该数据集包含在 `rattle.data` 库中。如第二行所示，`view` 函数用于在数据框对象上调用类似电子表格的数据查看器，如下图所示：
- en: '![](img/00133.jpeg)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00133.jpeg)'
- en: 'Returning to the code, as before, we use only two variables. In addition, the
    dataset contains data from different locations in Australia. We will limit our
    study to the first location (`Albury`):'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 回到代码，如前所述，我们只使用了两个变量。此外，数据集包含来自澳大利亚不同位置的数据。我们将把研究范围限制在第一个位置（`Albury`）：
- en: '[PRE22]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let''s get a preliminary data analysis using the `summary()` function:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`summary()`函数进行初步数据分析：
- en: '[PRE23]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `summary()` function returns a set of statistics for each variable. In
    particular, it is useful to highlight the result provided for the `Humidity9am`
    variable; this represents our target. For this variable, nine cases of missing
    value were detected. To remove the missing values, we will use the `na.omit()`
    function; it drops any rows with missing values and forgets them forever:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '`summary()`函数返回每个变量的一组统计信息。特别地，突出显示`Humidity9am`变量的结果很有用；它代表我们的目标。对于这个变量，检测到了九个缺失值。为了删除这些缺失值，我们将使用`na.omit()`函数；它会删除任何包含缺失值的行，并永久忘记它们：'
- en: '[PRE24]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'With the second line of code, we limit our analysis to the first `3000` observations.
    Now we must set the input and the output data to the format required by the `trainr()`
    function:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 使用第二行代码，我们将分析限制在前`3000`个观察值内。现在，我们必须将输入和输出数据设置为`trainr()`函数所需的格式：
- en: '[PRE25]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In this way, `x` will represent our input and `y` our target:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，`x`将代表我们的输入，`y`将代表我们的目标：
- en: '[PRE26]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'With this piece of code we construct a matrix of `30` lines and `100` columns
    with the data available. Recall is a size setting required for the function we
    will use for model building. We can now standardize this:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这段代码，我们构建了一个包含`30`行和`100`列的矩阵，使用现有数据。回忆一下，回忆（recall）是我们将在模型构建中使用的一个大小设置。现在我们可以对其进行标准化：
- en: '[PRE27]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'For this example, we have used the min-max method (usually called feature scaling)
    to get all the scaled data in the range *[0,1]*. The formula for this is as follows:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我们使用了最小-最大方法（通常称为特征缩放）来将所有缩放数据映射到* [0,1] *范围内。其公式如下：
- en: '![](img/00134.gif)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00134.gif)'
- en: 'During the normalization, we must calculate the minimum and maximum values
    of each database column. Then we transpose the matrix obtained:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在归一化过程中，我们必须计算每一列数据库的最小值和最大值。然后，我们将转置得到的矩阵：
- en: '[PRE28]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'In these lines of code, the dataset is split into `70:30`, with the intention
    of using `70` percent of the data at our disposal to train the network and the
    remaining `30` percent to test the network. Now is the time to build and train
    the model:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些代码行中，数据集被分割为`70:30`，目的是使用`70`百分比的数据来训练网络，剩下的`30`百分比用于测试网络。现在是时候构建并训练模型了：
- en: '[PRE29]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The `trainr()` function trains an RNN in R environment. We have used `16` neurons
    in the hidden layer and the number of epochs is `1,000`. The `trainr()` function
    takes a few minutes as the training happens based on `X` and `Y`. Here are the
    last 10 `Trained epoch` results as displayed on the R prompt:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '`trainr()`函数在R环境中训练RNN。我们在隐藏层中使用了`16`个神经元，训练周期为`1,000`次。`trainr()`函数需要几分钟时间，因为训练是基于`X`和`Y`进行的。以下是R提示符显示的最后10个`训练周期`结果：'
- en: '[PRE30]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can see the evolution of the algorithm by charting the error made by the
    algorithm to subsequent epochs:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过绘制算法在随后的周期中所犯错误的图表，查看算法的演变：
- en: '[PRE31]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This graph shows the **epoch** versus **error**:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图展示了**周期**与**错误**之间的关系：
- en: '![](img/00135.gif)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00135.gif)'
- en: 'We finally have the network trained and ready for use; now we can use it to
    make our predictions. Remember, we''ve set aside 30 percent of the available data
    to test the network. It''s time to use it:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于训练好了网络并准备好使用它；现在我们可以用它来进行预测。记住，我们已经将30%的可用数据留出来用于测试网络。是时候使用它了：
- en: '[PRE32]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Finally, to compare the results, let''s plot a graph showing the moisture content
    in the test set and the predicted results in order:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了比较结果，我们绘制一个图表，按顺序显示测试集中的湿度含量和预测结果：
- en: '[PRE33]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The following figure shows the actual values and predicted values:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了实际值和预测值：
- en: '![](img/00136.gif)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00136.gif)'
- en: 'From the analysis of the figure, it is possible to note one thing: the data
    is adapted to a good approximation to indicate that the model is able to predict
    the humidity conditions with good performance.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表分析中，我们可以注意到一件事：数据经过良好的调整，表明模型能够较好地预测湿度条件。
- en: Summary
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we saw RNNs and how to use internal memory for their processing.
    We also covered CNNs, which are standardized neural networks mainly used for image
    recognition. For RNNs, we studied some sample implementations in R.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了 RNN 以及如何利用内部记忆进行处理。我们还介绍了 CNN，它是一种主要用于图像识别的标准化神经网络。对于 RNN，我们研究了一些
    R 中的示例实现。
- en: 'We learned how to train, test, and evaluate an RNN. We also learned how to
    visualize the RNN model in an R environment. We discovered the LSTM model. We
    introduced the concepts as CNN and a common CNN architecture: LeNet.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学习了如何训练、测试和评估 RNN。我们还学习了如何在 R 环境中可视化 RNN 模型。我们发现了 LSTM 模型，并介绍了 CNN 的概念以及一种常见的
    CNN 架构：LeNet。
- en: In the next chapter, we will see more use cases involving R implementations
    of neural networks and deep learning.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将看到更多涉及神经网络和深度学习的 R 实现的应用案例。
