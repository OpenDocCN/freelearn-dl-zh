- en: 'Appendix A: Mathematical Foundations and Advanced TensorFlow'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录 A：数学基础与高级 TensorFlow
- en: Here we will discuss some concepts that will be useful for helping you to understand
    certain details provided in the chapters. First, we will discuss several mathematical
    data structures found throughout the book, followed by a description of the various
    operations performed on those data structures. After that, we will discuss the
    concept of probabilities. Probabilities play a vital role in machine learning,
    as they usually give insights into how uncertain a model is about its prediction.
    Finally, we will conclude this appendix with a guide on how to use TensorBoard
    as a visualization tool for word embeddings.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将讨论一些概念，这些概念将帮助你理解本书中提供的某些细节。首先，我们将讨论书中常见的几种数学数据结构，然后介绍对这些数据结构执行的各种操作。接下来，我们将讨论概率的概念。概率在机器学习中起着至关重要的作用，因为它通常提供有关模型对其预测的不确定性的见解。最后，我们将以如何使用
    TensorBoard 作为词嵌入的可视化工具的指南结束本附录。
- en: Basic data structures
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本数据结构
- en: Scalar
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标量
- en: 'A scalar is a single number, unlike a matrix or a vector. For example, 1.3
    is a scalar. A scalar can be mathematically denoted as follows: ![](img/B14070_12_001.png).'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 标量是一个单一的数字，不像矩阵或向量。例如，1.3 是一个标量。标量可以在数学上表示如下：![](img/B14070_12_001.png)。
- en: Here, *R* is the real number space.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*R* 是实数空间。
- en: Vectors
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量
- en: 'A vector is an array of numbers. Unlike a set, where there is no order to the
    elements, a vector has a certain order to the elements. An example vector is `[1.0,
    2.0, 1.4, 2.3]`. Mathematically, it can be denoted as follows:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 向量是一个数字数组。与集合不同，集合中的元素没有顺序，而向量的元素是有顺序的。一个示例向量是 `[1.0, 2.0, 1.4, 2.3]`。在数学上，它可以表示为：
- en: '![](img/B14070_12_002.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_002.png)'
- en: '![](img/B14070_12_003.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_003.png)'
- en: Here, *R* is the real number space and *n* is the number of elements in the
    vector.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*R* 是实数空间，*n* 是向量中的元素个数。
- en: Matrices
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵
- en: 'A matrix can be thought of as a two-dimensional arrangement of a collection
    of scalars. In other words, a matrix can be thought of as a vector of vectors.
    An example matrix is shown as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵可以被看作是一组标量的二维排列。换句话说，矩阵可以被看作是一个向量的向量。一个示例矩阵如下所示：
- en: '![](img/B14070_12_004.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_004.png)'
- en: 'A more general matrix of size ![](img/B14070_12_005.png) can be mathematically
    defined like this:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更一般的矩阵，其大小为 ![](img/B14070_12_005.png)，可以在数学上定义如下：
- en: '![](img/B14070_12_006.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_006.png)'
- en: 'And:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 并且：
- en: '![](img/B14070_12_007.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_007.png)'
- en: Here, *m* is the number of rows of the matrix, *n* is the number of columns
    in the matrix, and *R* is the real number space.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*m* 是矩阵的行数，*n* 是矩阵的列数，*R* 是实数空间。
- en: Indexing of a matrix
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵索引
- en: We will be using zero-indexed notation (that is, indexes that start with 0).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用零索引表示法（即，索引从 0 开始）。
- en: 'To index a single element from a matrix at the *(i, j)*^(th) position, we use
    the following notation:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要从矩阵中索引单个元素，位于 *(i, j)*^(th) 位置，我们使用以下表示法：
- en: '![](img/B14070_12_008.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_008.png)'
- en: 'Referring to the previously defined matrix, we get the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 参考之前定义的矩阵，我们得到如下结果：
- en: '![](img/B14070_12_004.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_004.png)'
- en: 'We index an element from *A* like this:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们像这样从 *A* 中索引一个元素：
- en: '![](img/B14070_12_010.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_010.png)'
- en: 'We denote a single row of any matrix *A* as shown here:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们表示任何矩阵 *A* 的一行，如下所示：
- en: '![](img/B14070_12_011.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_011.png)'
- en: 'For our example matrix, we can denote the second row (indexed as 1) of the
    matrix as shown here:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的示例矩阵，我们可以表示矩阵的第二行（索引为 1），如下所示：
- en: '![](img/B14070_12_012.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_012.png)'
- en: 'We denote the slice starting from the *(i, k)*^(th) index to the *(j, l)*^(th)
    index of any matrix *A* as shown here:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们表示从矩阵 *A* 的 *(i, k)*^(th) 索引到 *(j, l)*^(th) 索引的切片，如下所示：
- en: '![](img/B14070_12_013.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_013.png)'
- en: 'In our example matrix, we can denote the slice from first row third column
    to second row fourth column as shown here:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例矩阵中，我们可以表示从第一行第三列到第二行第四列的切片，如下所示：
- en: '![](img/B14070_12_014.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_014.png)'
- en: Special types of matrices
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特殊类型的矩阵
- en: Identity matrix
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单位矩阵
- en: 'An identity matrix is a square matrix where values are equal to 1 on the diagonal
    of the matrix and 0 everywhere else. Mathematically, it can be shown as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 单位矩阵是一个方阵，其中对角线上的值为 1，其他位置的值为 0。在数学上，它可以表示为：
- en: '![](img/B14070_12_015.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_015.png)'
- en: 'This would look like the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来如下所示：
- en: '![](img/B14070_12_016.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_016.png)'
- en: Here, ![](img/B14070_12_017.png).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B14070_12_017.png)。
- en: 'The identity matrix gives the following nice property when multiplied with
    another matrix *A*:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 单位矩阵与另一个矩阵 *A* 相乘时，具有以下良好的性质：
- en: '![](img/B14070_12_018.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_018.png)'
- en: Square diagonal matrix
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方阵对角矩阵
- en: 'A square diagonal matrix is a more general case of the identity matrix, where
    the values along the diagonal can take any value and the off-diagonal values are
    zeros:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 方阵对角矩阵是单位矩阵的一个更一般的情况，其中对角线上的值可以取任意值，而非对角线上的值为零：
- en: '![](img/B14070_12_019.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_019.png)'
- en: Tensors
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量
- en: 'An *n*-dimensional matrix is called a **tensor**. In other words, a matrix
    with an arbitrary number of dimensions is called a tensor. For example, a four-dimensional
    tensor can be denoted as shown here:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 *n* 维矩阵被称为 **张量**。换句话说，一个具有任意维数的矩阵被称为张量。例如，一个四维张量可以表示如下：
- en: '![](img/B14070_12_020.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_020.png)'
- en: Here, *R* is the real number space.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*R* 是实数空间。
- en: Tensor/matrix operations
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 张量/矩阵操作
- en: Transpose
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 转置
- en: 'Transpose is an important operation defined for matrices or tensors. For a
    matrix, the transpose is defined as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 转置是一个重要的操作，适用于矩阵或张量。对于矩阵，转置定义如下：
- en: '![](img/B14070_12_021.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_021.png)'
- en: Here, *A*^T denotes the transpose of *A*.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*A*^T 表示 *A* 的转置。
- en: 'An example of the transpose operation can be illustrated as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 转置操作的一个例子可以如下说明：
- en: '![](img/B14070_12_004.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_004.png)'
- en: 'After the transpose operation:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 经过转置操作后：
- en: '![](img/B14070_12_023.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_023.png)'
- en: 'For a tensor, transpose can be seen as permuting the dimensions order. For
    example, let’s define a tensor *S*, as shown here:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于张量，转置可以看作是对维度顺序的重新排列。例如，我们定义一个张量 *S*，如下所示：
- en: '![](img/B14070_12_024.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_024.png)'
- en: 'Now one transpose operation (out of many) can be defined as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在可以定义一个转置操作（多次转置中的一种），如下所示：
- en: '![](img/B14070_12_025.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_025.png)'
- en: Matrix multiplication
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 矩阵乘法
- en: Matrix multiplication is another important operation that appears quite frequently
    in linear algebra.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵乘法是另一个在线性代数中非常常见的重要操作。
- en: 'Given the matrices ![](img/B14070_12_026.png) and ![](img/B14070_12_027.png),
    the multiplication of *A* and *B* is defined as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 给定矩阵 ![](img/B14070_12_026.png) 和 ![](img/B14070_12_027.png)，*A* 和 *B* 的乘法定义如下：
- en: '![](img/B14070_12_028.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_028.png)'
- en: Here, ![](img/B14070_12_029.png).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B14070_12_029.png)。
- en: 'Consider this example:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这个例子：
- en: '![](img/B14070_12_030.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_030.png)'
- en: '![](img/B14070_12_031.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_031.png)'
- en: 'This gives ![](img/B14070_12_032.png), and the value of *C* is as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了 ![](img/B14070_12_032.png)，并且 *C* 的值如下：
- en: '![](img/B14070_12_033.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_033.png)'
- en: Element-wise multiplication
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 元素级乘法
- en: 'Element-wise matrix multiplication (or the **Hadamard product**) is computed
    for two matrices that have the same shape. Given the matrices ![](img/B14070_12_034.png)
    and ![](img/B14070_12_035.png), the element-wise multiplication of *A* and *B*
    is defined as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 元素级矩阵乘法（或 **Hadamard 乘积**）是对形状相同的两个矩阵进行计算的。给定矩阵 ![](img/B14070_12_034.png) 和
    ![](img/B14070_12_035.png)，*A* 和 *B* 的元素级乘法定义如下：
- en: '![](img/B14070_12_036.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_036.png)'
- en: Here, ![](img/B14070_12_037.png).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B14070_12_037.png)。
- en: 'Consider this example:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这个例子：
- en: '![](img/B14070_12_038.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_038.png)'
- en: 'This gives ![](img/B14070_12_039.png), and the value of *C* is as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了 ![](img/B14070_12_039.png)，并且 *C* 的值如下：
- en: '![](img/B14070_12_040.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_040.png)'
- en: Inverse
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逆
- en: 'The inverse of the matrix *A* is denoted by *A*^(-1), where it satisfies the
    following condition:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵 *A* 的逆矩阵表示为 *A*^(-1)，它满足以下条件：
- en: '![](img/B14070_12_041.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_041.png)'
- en: 'Inverse is very useful if we are trying to solve a system of linear equations.
    Consider this example:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 逆矩阵在我们试图解线性方程组时非常有用。考虑这个例子：
- en: '![](img/B14070_12_042.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_042.png)'
- en: 'We can solve for ![](img/B14070_12_043.png) like this:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过如下方式解出 ![](img/B14070_12_043.png)：
- en: '![](img/B14070_12_044.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_044.png)'
- en: This can be written as ![](img/B14070_12_045.png), using the associative law
    – that is, ![](img/B14070_12_046.png).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以写作 ![](img/B14070_12_045.png)，利用结合律——即，![](img/B14070_12_046.png)。
- en: Next, we will get, where ![](img/B14070_12_049.png) is the identity matrix.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将得到，其中 ![](img/B14070_12_049.png) 是单位矩阵。
- en: Lastly, ![](img/B14070_12_050.png) because ![](img/B14070_12_051.png).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，![](img/B14070_12_050.png)，因为 ![](img/B14070_12_051.png)。
- en: 'For example, polynomial regression, one of the regression techniques, uses
    a linear system of equations to solve the regression problem. Regression is similar
    to classification, but instead of outputting a class, regression models output
    a continuous value. Let’s look at an example problem: given the number of bedrooms
    in a house, we’ll calculate the real-estate value of the house. Formally, a polynomial
    regression problem can be written as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，多项式回归是回归技术之一，使用线性方程组来解决回归问题。回归类似于分类，但与分类输出一个类别不同，回归模型输出一个连续值。让我们看一个示例问题：给定一所房子的卧室数量，我们将计算这所房产的价值。形式上，一个多项式回归问题可以写成如下：
- en: '![](img/B14070_12_052.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_052.png)'
- en: 'Here,![](img/B14070_12_053.png) is the *i*^(th) data input, where ![](img/B14070_12_054.png)
    is the input, ![](img/B14070_12_055.png)is the label, and ![](img/B14070_12_056.png)
    is the noise in data. In our example, ![](img/B14070_12_057.png) is the number
    of bedrooms and ![](img/B14070_12_058.png) is the price of the house. This can
    be written as a system of linear equations as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B14070_12_053.png) 是第*i*个数据输入，其中 ![](img/B14070_12_054.png) 是输入，![](img/B14070_12_055.png)
    是标签，![](img/B14070_12_056.png) 是数据中的噪声。在我们的例子中，![](img/B14070_12_057.png) 是卧室的数量，![](img/B14070_12_058.png)
    是房子的价格。这可以写成如下的线性方程组：
- en: '![](img/B14070_12_059.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_059.png)'
- en: However, *A*^(-1) does not exist for all *A*. There are certain conditions that
    need to be satisfied in order for the inverse to exist for a matrix. For example,
    to define the inverse, *A* needs to be a square matrix (that is, ![](img/B14070_12_060.png)).
    Even when the inverse exists, we cannot always find it in the closed form; sometimes
    it can only be approximated with finite-precision computers. If the inverse exists,
    there are several algorithms for finding it, which we will discuss next.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，并非所有的*A*都存在逆。为了矩阵有逆，需要满足一定的条件。例如，为了定义逆矩阵，*A*需要是一个方阵（即，![](img/B14070_12_060.png)）。即使逆矩阵存在，我们也并不总能以封闭形式找到它；有时它只能通过有限精度计算机进行近似。如果逆矩阵存在，那么有几种算法可以找到它，我们将在接下来的内容中讨论。
- en: '**Note**'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: When it is said that *A* needs to be a square matrix for the inverse to exist,
    we refer to the standard inversion. There exist variants of the inverse operation
    (for example, the **Moore-Penrose inverse**, also known as pseudoinverse) that
    can perform matrix inversion on general ![](img/B14070_12_061.png) matrices.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们说*要*矩阵是方阵才能有逆时，指的是标准的逆运算。也存在逆运算的变种（例如，**摩尔-彭若斯逆**，也称为伪逆），它可以对一般的 ![](img/B14070_12_061.png)
    矩阵进行矩阵求逆操作。
- en: Finding the matrix inverse – Singular Value Decomposition (SVD)
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 求解矩阵逆——奇异值分解（SVD）
- en: 'Let’s now see how we can use SVD to find the inverse of a matrix *A*. SVD factorizes
    *A* into three different matrices, as shown here:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用SVD求解矩阵*A*的逆。SVD将*A*分解为三个不同的矩阵，如下所示：
- en: '![](img/B14070_12_062.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_062.png)'
- en: 'Here the columns of *U* are known as left singular vectors, columns of *V*
    are known as right singular vectors, and diagonal values of *D* (a diagonal matrix)
    are known as singular values. Left singular vectors are the eigenvectors of ![](img/B14070_12_063.png)
    and the right singular vectors are the eigenvectors of ![](img/B14070_12_064.png).
    Finally, the singular values are the square roots of the eigenvalues of ![](img/B14070_12_065.png)
    and ![](img/B14070_12_066.png). The eigenvector ![](img/B14070_12_067.png) and
    its corresponding eigenvalue ![](img/B14070_12_068.png) of the square matrix *A*
    satisfy the following condition:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*U*的列被称为左奇异向量，*V*的列被称为右奇异向量，*D*（一个对角矩阵）的对角值被称为奇异值。左奇异向量是矩阵 ![](img/B14070_12_063.png)
    的特征向量，右奇异向量是矩阵 ![](img/B14070_12_064.png) 的特征向量。最后，奇异值是矩阵 ![](img/B14070_12_065.png)
    和 ![](img/B14070_12_066.png) 的特征值的平方根。矩阵*A*的特征向量 ![](img/B14070_12_067.png) 及其对应的特征值
    ![](img/B14070_12_068.png) 满足以下条件：
- en: '![](img/B14070_12_069.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_069.png)'
- en: 'Then, if the SVD exists, the inverse of *A* is given by this:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果SVD存在，矩阵*A*的逆由以下公式给出：
- en: '![](img/B14070_12_070.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_070.png)'
- en: 'Since *D* is diagonal, *D*^(-1) is simply the element-wise reciprocal of the
    nonzero elements of *D*. SVD is an important matrix factorization technique that
    appears on many occasions in machine learning. For example, SVD is used for calculating
    **Principal Component Analysis** (**PCA**), which is a popular dimensionality
    reduction technique for data (a purpose similar to that of t-SNE, which we saw
    in *Chapter 4**, Advanced Word Vector Algorithms*). Another, more NLP-oriented
    application of SVD is document ranking. That is, when you want to get the most
    relevant documents (and rank them by relevance to some term, for example, *football*),
    SVD can be used to achieve this. To learn more about SVD, you can consult this
    blog post, which provides a geometric intuition on SVD, as well as showing how
    it’s applied in PCA: [https://gregorygundersen.com/blog/2018/12/10/svd/](https://gregorygundersen.com/blog/2018/12/10/svd/).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 由于*D*是对角矩阵，*D*^(-1)只是*D*中非零元素的逐元素倒数。SVD（奇异值分解）是机器学习中一个重要的矩阵分解技术。例如，SVD被用于计算**主成分分析**（**PCA**），这是一种流行的数据降维技术（其目的类似于我们在*第4章，先进的词向量算法*中看到的t-SNE）。SVD在自然语言处理（NLP）中的另一个应用是文档排名。即，当你想获取最相关的文档（并根据与某个术语的相关性对它们进行排名，例如*足球*），可以使用SVD来实现这一目标。想要了解更多关于SVD的信息，可以参考这篇博客文章，它提供了SVD的几何直觉，并展示了它在PCA中的应用：[https://gregorygundersen.com/blog/2018/12/10/svd/](https://gregorygundersen.com/blog/2018/12/10/svd/)。
- en: Norms
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 范数
- en: 'A norm is used as a measure of the *size* of the vector (that is, of the values
    in the vector). The *p*^(th) norm is calculated and denoted as shown here:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 范数用作衡量向量*大小*（即向量中的值）的标准。*p*^(th)范数的计算和表示如下所示：
- en: '![](img/B14070_12_071.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_071.png)'
- en: 'For example, the *L2* norm would be this:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，*L2*范数是这样的：
- en: '![](img/B14070_12_072.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_072.png)'
- en: Determinant
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 行列式
- en: The determinant of a square matrix is denoted by ![](img/B14070_12_073.png).
    The determinant is very useful in many ways. For example, *A* is invertible if,
    and only if, the determinant is nonzero. The determinant is also interpreted as
    the product of all the eigenvalues of the matrix. The determinant of a *2*x*2*
    matrix *A*,
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 方阵的行列式表示为![](img/B14070_12_073.png)。行列式在许多方面都非常有用。例如，*A*仅当且仅当行列式不为零时才是可逆的。行列式也可以被解释为矩阵所有特征值的乘积。*2*x*2*矩阵*A*的行列式表示为
- en: '![](img/B14070_12_075.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_075.png)'
- en: is denoted as
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示
- en: '![](img/B14070_12_076.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_076.png)'
- en: and computed as
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 计算方法为
- en: '![](img/B14070_12_077.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_077.png)'
- en: 'The following equation shows the calculations for the determinant of a *3x3*
    matrix:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下方程展示了*3x3*矩阵行列式的计算：
- en: '![](img/B14070_12_078.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_078.png)'
- en: '![](img/B14070_12_079.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_079.png)'
- en: '![](img/B14070_12_080.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_080.png)'
- en: Probability
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概率
- en: Next, we will discuss the terminology related to probability theory. Probability
    theory is a vital part of machine learning, as modeling data with probabilistic
    models allows us to draw conclusions about how uncertain a model is about some
    predictions. Consider a use case of sentiment analysis. We want to output a prediction
    (positive/negative) for a given movie review. Though the model outputs some value
    between 0 and 1 (0 for negative and 1 for positive) for any sample we input, the
    model doesn’t know how *uncertain* it is about its answer.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论与概率论相关的术语。概率论是机器学习的一个重要部分，因为使用概率模型建模数据可以帮助我们得出关于模型在某些预测上不确定性的结论。以情感分析的使用案例为例，我们想为给定的电影评论输出一个预测（正面/负面）。尽管模型对于我们输入的每一个样本都输出一个介于0和1之间的值（0表示负面，1表示正面），但模型并不知道它对其答案的*不确定性*有多大。
- en: Let’s understand how uncertainty helps us to make better predictions. For example,
    a deterministic model (i.e. a model that outputs an exact value instead of a distribution
    for the value) might incorrectly say the positivity of the review *I never lost
    interest* is 0.25 (that is, it’s more likely to be a negative comment). However,
    a probabilistic model will give a mean value and a standard deviation for the
    prediction. For example, it will say, this prediction has a mean of 0.25 and a
    standard deviation of 0.5\. With the second model, we know that the prediction
    is likely to be wrong due to the high standard deviation. However, in the deterministic
    model, we don’t have this luxury. This property is especially valuable for critical
    machine systems (for example, a terrorism risk assessment model).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们理解不确定性如何帮助我们做出更好的预测。例如，一个确定性模型（即输出确切值而非值的分布的模型）可能会错误地说评论 “我从未失去兴趣” 的正向概率是
    0.25（也就是说，它更可能是负面评论）。然而，概率模型将为预测提供一个均值和一个标准差。例如，它可能会说，这个预测的均值为 0.25，标准差为 0.5。在第二种模型下，我们知道由于标准差较大，预测很可能是错误的。然而，在确定性模型中，我们没有这种奢侈的选择。这一特性对于关键的机器系统（例如，恐怖主义风险评估模型）尤其有价值。
- en: To develop such probabilistic machine learning models (for example, Bayesian
    logistic regression, Bayesian neural networks, or Gaussian processes), you should
    be familiar with basic probability theory. Therefore, we will provide some basic
    probability information here.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开发这样的概率机器学习模型（例如，贝叶斯逻辑回归、贝叶斯神经网络或高斯过程），你应该熟悉基本的概率理论。因此，我们将在这里提供一些基本的概率信息。
- en: Random variables
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 随机变量
- en: 'A random variable is a variable that can take some value at random. Also, random
    variables are represented as *x*[1], *x*[2], and so on. Random variables can be
    of two types: discrete and continuous.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量是一个可以随机取值的变量。此外，随机变量通常表示为 *x*[1]、*x*[2] 等。随机变量可以分为两种类型：离散型和连续型。
- en: Discrete random variables
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 离散随机变量
- en: A discrete random variable is a variable that can take discrete random values.
    For example, trials of flipping a coin can be modeled as a random variable; that
    is, the side a coin lands on when you flip it is a discrete variable as the value
    can only be *heads* or *tails*. Alternatively, the value you get when you roll
    a die is discrete, as well, as the values can only come from the set `{1,2,3,4,5,6}`.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 离散随机变量是指可以取离散随机值的变量。例如，掷硬币的试验可以被建模为一个随机变量；即，硬币掷出的正面或反面是一个离散变量，因为结果只能是*正面*或*反面*。另外，掷骰子的结果也是离散的，因为其值只能来自集合
    `{1,2,3,4,5,6}`。
- en: Continuous random variables
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 连续随机变量
- en: 'A continuous random variable is a variable that can take any real value, that
    is, if *x* is a continuous random variable:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 连续随机变量是一个可以取任何实数值的变量，也就是说，如果 *x* 是一个连续随机变量：
- en: '![](img/B14070_12_081.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_081.png)'
- en: Here, *R* is the real number space.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*R* 表示实数空间。
- en: For example, the height of a person is a continuous random variable as it can
    take any real value.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个人的身高是一个连续随机变量，因为它可以取任何实数值。
- en: The probability mass/density function
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概率质量/密度函数
- en: 'The **probability mass function** (**PMF**) or the **probability density function**
    (**PDF**) is a way of showing the probability distribution over different values
    a random variable can take. For discrete variables, a PMF is defined, and for
    continuous variables, a PDF is defined. *Figure A.1* shows an example PMF:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**概率质量函数**（**PMF**）或**概率密度函数**（**PDF**）是一种展示随机变量在不同值上概率分布的方式。对于离散变量，定义了PMF；对于连续变量，定义了PDF。*图
    A.1* 显示了一个PMF的例子：'
- en: '![The probability mass/density function](img/B14070_12_01.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![概率质量/密度函数](img/B14070_12_01.png)'
- en: 'A.1: Probability mass function (PMF) discrete'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 'A.1: 概率质量函数（PMF）离散型'
- en: 'The preceding PMF might be achieved by a *biased* die. In this graph, we can
    see that there is a high probability of getting a 3 with this die. Such a graph
    can be obtained by running a number of trials (say, 100) and then counting the
    number of times each face fell on top. Finally, you would divide each count by
    the number of trials to obtain the normalized probabilities. Note that all the
    probabilities should add up to 1, as shown here:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 上述的概率质量函数（PMF）可能是通过一个*偏*骰子实现的。在这张图中，我们可以看到，掷这个骰子时，出现 3 的概率很高。这样的图形可以通过进行多次试验（比如
    100 次）并统计每个面朝上的次数得到。最后，你需要将每个计数除以试验次数，以获得标准化后的概率。请注意，所有的概率总和应为 1，正如这里所示：
- en: '![](img/B14070_12_082.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_082.png)'
- en: 'The same concept is extended to a continuous random variable to obtain a PDF.
    Say that we are trying to model the probability of a certain height given a population.
    Unlike the discrete case, we do not have individual values to calculate the probability
    for, but rather a continuous spectrum of values (in the example, it extends from
    *0* to *2.4 m*). If we are to draw a graph for this example like the one in *Figure
    A.1*, we need to think of it in terms of infinitesimally small bins. For example,
    we find out the probability density of a person’s height being between *0.0 m-0.01
    m, 0.01-0.02 m, ..., 1.8 m-1.81 m, …*, and so on. The probability density can
    be calculated using the following formula:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的概念被扩展到连续随机变量，以获得一个 PDF。假设我们试图建模给定人群的某个身高的概率。与离散情况不同，我们没有个别的值来计算概率，而是一个连续的值范围（在本例中，它从
    *0* 到 *2.4 m*）。如果我们像 *图 A.1* 中的示例一样绘制图表，我们需要以无穷小区间来考虑它。例如，我们找出一个人身高在 *0.0 m-0.01
    m, 0.01-0.02 m, ..., 1.8 m-1.81 m, …* 等范围内的概率密度。概率密度可以使用以下公式计算：
- en: '![](img/B14070_12_083.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_083.png)'
- en: 'Then, we will plot those bars close to each other to obtain a continuous curve,
    as shown in *Figure A.2*. Note that the probability density for a given bin can
    be greater than *1* (since it’s density), but the area under the curve must be
    1:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将这些条形图画得靠近彼此，从而获得一个连续的曲线，如*图 A.2*所示。请注意，给定的区间的概率密度可以大于 *1*（因为它是密度），但是曲线下的面积必须为
    1：
- en: '![The probability mass/density function](img/B14070_12_02.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![概率质量/密度函数](img/B14070_12_02.png)'
- en: 'Figure A.2: Probability density function (PDF) continuous'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.2：概率密度函数（PDF）连续
- en: The shape shown in *Figure A.2* is known as the normal (or Gaussian) distribution.
    It is also called the *bell curve*. We previously gave just an intuitive explanation
    of how to think about a continuous probability density function.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 A.2*中显示的形状被称为正态分布（或高斯分布）。它也被称为*钟形曲线*。我们之前给出的是关于如何理解连续概率密度函数的直观解释。
- en: 'More formally, a continuous PDF of the normal distribution has an equation
    and is defined as follows. Let’s assume that a continuous random variable *X*
    has a normal distribution with mean ![](img/B14070_12_084.png) and standard deviation
    ![](img/B14070_12_085.png). The probability of *X = x* for any value of *x* is
    given by this formula:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，正态分布的连续 PDF 有一个公式，定义如下。假设连续随机变量 *X* 具有均值 ![](img/B14070_12_084.png) 和标准差
    ![](img/B14070_12_085.png) 的正态分布。对于任何 *x* 的值，*X = x* 的概率由以下公式给出：
- en: '![](img/B14070_12_086.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_086.png)'
- en: 'You should get the area (which needs to be 1 for a valid PDF) if you integrate
    this quantity over all possible infinitesimally small *dx* values, as denoted
    by this formula:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对所有可能的无穷小 *dx* 值进行积分，应该得到区域（有效的 PDF 需要为 1），如以下公式所示：
- en: '![](img/B14070_12_087.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_087.png)'
- en: 'The integral of the normal for the arbitrary *a*, *b* values is given by the
    following formula:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 任意 *a* 和 *b* 值的正态分布积分通过以下公式给出：
- en: '![](img/B14070_12_088.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_088.png)'
- en: 'Using this, we can get the integral of the normal distribution, where ![](img/B14070_12_089.png)
    and ![](img/B14070_12_090.png):'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个公式，我们可以得到正态分布的积分，其中 ![](img/B14070_12_089.png) 和 ![](img/B14070_12_090.png)：
- en: '![](img/B14070_12_091.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_091.png)'
- en: This gives the accumulation of all the probability values for all the values
    of *x* and gives you a value of 1\.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这给出了所有 *x* 值的概率值的累积，并给出了一个值为 1 的结果。
- en: You can find more information at [http://mathworld.wolfram.com/GaussianIntegral.html](http://mathworld.wolfram.com/GaussianIntegral.html),
    or for a less complex discussion, refer to [https://en.wikipedia.org/wiki/Gaussian_integral](https://en.wikipedia.org/wiki/Gaussian_integral).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [http://mathworld.wolfram.com/GaussianIntegral.html](http://mathworld.wolfram.com/GaussianIntegral.html)
    查找更多信息，或者参考 [https://en.wikipedia.org/wiki/Gaussian_integral](https://en.wikipedia.org/wiki/Gaussian_integral)
    进行更简单的讨论。
- en: Conditional probability
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 条件概率
- en: 'Conditional probability represents the probability of an event happening given
    the occurrence of another event. For example, given two random variables, *X*
    and *Y*, the conditional probability of *X = x*, given that *Y = y*, is denoted
    by this formula:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 条件概率表示在一个事件发生的前提下，另一个事件发生的概率。例如，给定两个随机变量，*X* 和 *Y*，在 *Y = y* 的条件下，*X = x* 的条件概率可以用以下公式表示：
- en: '![](img/B14070_12_092.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_092.png)'
- en: 'A real-world example of such a probability would be as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这种概率的一个实际例子如下所示：
- en: '![](img/B14070_12_093.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_093.png)'
- en: Joint probability
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 联合概率
- en: 'Given two random variables, *X* and *Y*, we will refer to the probability of
    *X = x* together with *Y = y* as the joint probability of *X = x* and *Y = y*.
    This is denoted by the following formula:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 给定两个随机变量*X*和*Y*，我们将*X = x*和*Y = y*的概率称为*X = x*和*Y = y*的联合概率。其公式表示如下：
- en: '![](img/B14070_12_094.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_094.png)'
- en: 'If *X* and *Y* are mutually exclusive events, this expression reduces to this:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果*X*和*Y*是互斥事件，则此表达式将简化为：
- en: '![](img/B14070_12_095.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_095.png)'
- en: 'A real-world example of this is as follows:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 一个现实世界中的例子如下：
- en: '![](img/B14070_12_096.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_096.png)'
- en: Marginal probability
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 边际概率
- en: 'A marginal probability distribution is the probability distribution of a subset
    of random variables, given the joint probability distribution of all variables.
    For example, consider that two random variables, *X* and *Y*, exist, and we already
    know ![](img/B14070_12_097.png) and we want to calculate *P(x)*:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 边际概率分布是给定所有变量的联合概率分布时，某一随机变量子集的概率分布。例如，假设存在两个随机变量*X*和*Y*，且我们已经知道![](img/B14070_12_097.png)，我们想要计算*P(x)*：
- en: '![](img/B14070_12_098.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_098.png)'
- en: Intuitively, we are taking the sum over all possible values of *Y*, effectively
    making the probability of *Y = 1*.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，我们正在对所有可能的*Y*值求和，实际上是在计算*Y = 1*的概率。
- en: Bayes’ rule
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 贝叶斯定理
- en: 'Bayes’ rule gives us a way to calculate ![](img/B14070_12_099.png) if we already
    know ![](img/B14070_12_100.png), and ![](img/B14070_12_101.png). We can easily
    arrive at Bayes’ rule as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯定理为我们提供了一种计算![](img/B14070_12_099.png)的方法，前提是我们已经知道![](img/B14070_12_100.png)和![](img/B14070_12_101.png)。我们可以通过以下方式轻松推导出贝叶斯定理：
- en: '![](img/B14070_12_102.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_102.png)'
- en: 'Now let’s take the middle and right parts:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看中间和右边的部分：
- en: '![](img/B14070_12_103.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_103.png)'
- en: '![](img/B14070_12_104.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_104.png)'
- en: 'This is Bayes’ rule. Let’s put it simply, as shown here:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是贝叶斯定理。简单来说，就是这样：
- en: '![](img/B14070_12_105.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_105.png)'
- en: Visualizing word embeddings with TensorBoard
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorBoard可视化词嵌入
- en: When we wanted to visualize word embeddings in *Chapter 3*, *Word2vec – Learning
    Word Embeddings,* we manually implemented the visualization with the t-SNE algorithm.
    However, you also could use TensorBoard to visualize word embeddings. TensorBoard
    is a visualization tool provided with TensorFlow. You can use TensorBoard to visualize
    the TensorFlow variables in your program. This allows you to see how different
    variables behave over time (for example, model loss/accuracy), so you can identify
    potential issues in your model.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在*第3章*“Word2vec——学习词嵌入”中想要可视化词嵌入时，我们是通过手动实现t-SNE算法来进行可视化的。然而，你也可以使用TensorBoard来可视化词嵌入。TensorBoard是TensorFlow提供的一个可视化工具。你可以用TensorBoard来可视化程序中的TensorFlow变量。这让你可以看到不同变量随着时间的变化（例如，模型的损失/准确度），从而帮助你识别模型中的潜在问题。
- en: TensorBoard enables you to visualize scalar values (e.g. loss values over training
    iterations) and vectors as histograms (e.g. model’s layer node activations). Apart
    from this, TensorBoard also allows you to visualize word embeddings. Therefore,
    it takes all the required code implementation away from you, if you need to analyze
    what the embeddings look like. Next, we will see how we can use TensorBoard to
    visualize word embeddings. The code for this exercise is provided in `tensorboard_word_embeddings.ipynb`
    in the `Appendix` folder.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard使你能够可视化标量值（例如，训练迭代中的损失值）和向量作为直方图（例如，模型层节点的激活）。除此之外，TensorBoard还允许你可视化词嵌入。因此，如果你需要分析嵌入的样子，TensorBoard为你提供了所有所需的代码实现。接下来，我们将看到如何使用TensorBoard来可视化词嵌入。本练习的代码在`Appendix`文件夹中的`tensorboard_word_embeddings.ipynb`里提供。
- en: Starting TensorBoard
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动TensorBoard
- en: 'First, we will list the steps for starting TensorBoard. TensorBoard acts as
    a service and runs on a specific port (by default, on `6006`). To start TensorBoard,
    you will need to follow these steps:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将列出启动TensorBoard的步骤。TensorBoard作为一个服务运行，并使用特定的端口（默认情况下是`6006`）。要启动TensorBoard，你需要按照以下步骤操作：
- en: Open up Command Prompt (Windows) or Terminal (Ubuntu/macOS).
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开命令提示符（Windows）或终端（Ubuntu/macOS）。
- en: Go into the project home directory.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入项目的主目录。
- en: If you are using the python `virtualenv`, activate the virtual environment where
    you have installed TensorFlow.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你使用的是python的`virtualenv`，请激活你已安装TensorFlow的虚拟环境。
- en: 'Make sure that you can see the TensorFlow library through Python. To do this,
    follow these steps:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保你能通过Python看到TensorFlow库。为此，按照以下步骤操作：
- en: Type in `python3`; you will get a `>>>` looking prompt
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`python3`；你将看到一个类似`>>>`的提示符。
- en: Try `import tensorflow as tf`
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尝试`import tensorflow as tf`
- en: If you can run this successfully, you are fine
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你能够成功运行此操作，那么你就没问题了
- en: Exit the `python` prompt (that is, `>>>`) by typing `exit()`
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过输入`exit()`退出`python`提示符（即`>>>`）
- en: 'Type in `tensorboard --logdir=models`:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`tensorboard --logdir=models`：
- en: The `--logdir` option points to the directory where you will create data to
    visualize
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`--logdir`选项指向你将创建数据以供可视化的目录'
- en: Optionally, you can use `--port=<port_you_like>` to change the port TensorBoard
    runs on
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，你可以使用`--port=<port_you_like>`来更改TensorBoard运行的端口
- en: 'You should now get the following message:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你现在应该能看到以下消息：
- en: '[PRE0]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Enter the `<url>:6006` into the web browser. You should be able to see an orange
    dashboard at this point. You won’t have anything to display because we haven’t
    generated any data.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在网页浏览器中输入`<url>:6006`。此时，你应该能够看到一个橙色的仪表盘。由于我们还没有生成任何数据，所以不会显示任何内容。
- en: Saving word embeddings and visualizing via TensorBoard
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保存词嵌入并通过TensorBoard进行可视化
- en: 'First, we will download and load the 50-dimensional GloVe embeddings file (`glove.6B.zip`)
    from [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)
    and place it in the `Appendix` folder. We will load the first 50,000 word vectors
    in the file and later use these to initialize a TensorFlow variable. We will also
    record the word strings of each word, as we will later provide these as labels
    for each point to display on TensorBoard:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将从[https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)下载并加载50维的GloVe词向量文件（`glove.6B.zip`），并将其放入`Appendix`文件夹中。我们将加载文件中的前50,000个词向量，稍后将这些词向量用于初始化TensorFlow变量。同时，我们还将记录每个词的字符串，因为稍后我们会将这些字符串作为标签，在TensorBoard中显示每个点：
- en: '[PRE1]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We have defined our embeddings as a pandas DataFrame. It has the vector values
    as columns and words as the index.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已将嵌入定义为一个pandas DataFrame。它将词向量作为列，将词作为索引。
- en: '![](img/B14070_12_03.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_03.png)'
- en: 'Figure A.3: GloVe vectors presented as a pandas DataFrame'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图A.3：以pandas DataFrame形式呈现的GloVe向量
- en: 'We will need to define TensorFlow-related variables and operations. Before
    doing this, we will create a directory called `embeddings`, which will be used
    to store the variables:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要定义与TensorFlow相关的变量和操作。在此之前，我们将创建一个名为`embeddings`的目录，用于存储这些变量：
- en: '[PRE2]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, we will define a variable that will be initialized with the word embeddings
    we copied from the text file earlier:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将定义一个变量，该变量将用我们之前从文本文件中复制的词嵌入进行初始化：
- en: '[PRE3]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We also need to save a metadata file. A metadata file contains labels/images
    or other types of information associated with the word embeddings, so that when
    you hover over the embedding visualization, the corresponding points will show
    the word/label they represent. The metadata file should be of the `.tsv` (tab-separated
    values) format and should contain `vocabulary_size` rows in it, where each row
    contains a word in the order they appear in the embeddings matrix:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要保存一个元数据文件。元数据文件包含与词嵌入相关的标签/图像或其他类型的信息，以便当你悬停在嵌入可视化上时，相应的点将显示它们所代表的词/标签。元数据文件应为`.tsv`（制表符分隔值）格式，且应包含`vocabulary_size`行，其中每行包含一个词，按它们在词嵌入矩阵中出现的顺序排列：
- en: '[PRE4]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, we will need to tell TensorFlow where it can find the metadata for the
    embedding data we saved to the disk. For this, we need to create a `ProjectorConfig`
    object, which maintains various configuration details about the embedding we want
    to display. The details stored in the `ProjectorConfig` folder will be saved to
    a file called `projector_config.pbtxt` in the `models` directory:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要告诉TensorFlow它在哪里可以找到我们保存到磁盘的嵌入数据的元数据。为此，我们需要创建一个`ProjectorConfig`对象，该对象保存有关我们要显示的嵌入的各种配置信息。存储在`ProjectorConfig`文件夹中的详细信息将保存在`models`目录中的`projector_config.pbtxt`文件中：
- en: '[PRE5]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here, we will populate the required fields of the `ProjectorConfig` object
    we created. First, we will tell it the name of the variable we’re interested in
    visualizing. Then, we will tell it where it can find the metadata corresponding
    to that variable:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将填写我们创建的`ProjectorConfig`对象的必填字段。首先，我们将告诉它我们感兴趣的变量名称。然后，我们将告诉它在哪里可以找到与该变量对应的元数据：
- en: '[PRE6]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Note that we are adding the suffix `/.ATTRIBUTES/VARIABLE_VALUE` to the name
    `embedding`. This is required for TensorBoard to find this tensor. TensorBoard
    will read the necessary files at startup:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在`embedding`名称后添加了后缀`/.ATTRIBUTES/VARIABLE_VALUE`。这是TensorBoard找到此张量所必需的。TensorBoard将在启动时读取必要的文件：
- en: '[PRE7]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now if you load TensorBoard, you should see something similar to *Figure A.4*:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你加载TensorBoard，你应该能看到类似*图A.4*的内容：
- en: '![](img/B14070_12_04.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_04.png)'
- en: 'Figure A.4: TensorBoard view of the embeddings'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.4：TensorBoard 可视化的嵌入
- en: 'When you hover over the displayed point cloud, it will show the label of the
    word you’re currently hovering over, as we provided this information in the `metadata.tsv`
    file. Furthermore, you have several options. The first option (shown with a dotted
    line and marked as **1**) will allow you to select a subset of the full embedding
    space. You can draw a bounding box over the area of the embedding space you’re
    interested in, and it will look as shown in *Figure A.5*. I have selected the
    embeddings from the right side of the visualization. You can see the full list
    of selected words on the right:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将鼠标悬停在显示的点云上时，系统会显示您当前悬停的单词标签，因为我们在 `metadata.tsv` 文件中提供了这些信息。此外，您还有几个选项。第一个选项（如虚线框所示，标记为
    **1**）允许您选择嵌入空间的一个子集。您可以在感兴趣的嵌入空间区域画出一个边界框，效果如 *图 A.5* 所示。我选择了可视化中右侧的嵌入。您可以在右侧看到选定单词的完整列表：
- en: '![](img/B14070_12_05.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_05.png)'
- en: 'Figure A.5: Selecting a subset of the embedding space'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.5：选择嵌入空间的一个子集
- en: 'Another option you have is the ability to view words themselves, instead of
    dots. You can do this by selecting the second option in *Figure A.4* (shown inside
    a solid box and marked as **2**). This would look as shown in *Figure A.6*. Additionally,
    you can pan/zoom/rotate the view to your liking. If you click on the help button
    (shown within a solid box and marked as **1** in *Figure A.6*), it will show you
    a guide for controlling the view:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是查看单词本身，而非点。您可以通过选择 *图 A.4* 中的第二个选项（标记为 **2** 的实心框）来实现。这将显示如 *图 A.6* 所示的效果。此外，您可以根据需要平移/缩放/旋转视图。如果点击帮助按钮（如
    *图 A.6* 中标记为 **1** 的实心框所示），将显示一个控制视图的指南：
- en: '![](img/B14070_12_06.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B14070_12_06.png)'
- en: 'Figure A.6: Embedding vectors displayed as words instead of dots'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图 A.6：以单词形式显示的嵌入向量，而非点
- en: Finally, you can change the visualization algorithm from the panel on the left-hand
    side (shown with a dashed line and marked with **3** in *Figure A.4*).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以通过左侧面板更改可视化算法（如 *图 A.4* 中所示，标记为 **3** 的虚线框）。
- en: Summary
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Here we discussed some of the mathematical background as well as some implementations
    we did not cover in the other chapters. First, we discussed the mathematical notation
    for scalars, vectors, matrices, and tensors. Then, we discussed various operations
    performed on these data structures such as matrix multiplication and inversion.
    After that, we discussed various terminology that is useful for understanding
    probabilistic machine learning, such as probability density functions, joint probability,
    marginal probability, and Bayes’ rule. Finally, we ended the appendix with a guide
    to visualizing word embeddings using TensorBoard, a visualization platform that
    comes with TensorFlow.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们讨论了一些数学背景知识，以及我们在其他章节中没有涉及的一些实现。首先，我们讨论了标量、向量、矩阵和张量的数学符号。接着，我们讨论了对这些数据结构进行的各种操作，例如矩阵乘法和矩阵求逆。之后，我们讨论了一些有助于理解概率机器学习的术语，如概率密度函数、联合概率、边际概率和贝叶斯规则。最后，我们在附录中以如何使用
    TensorFlow 附带的可视化平台 TensorBoard 来可视化词嵌入的指南结束。
- en: '![](img/New_Packt_Logo1.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](img/New_Packt_Logo1.png)'
- en: packt.com
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: packt.com
- en: Subscribe to our online digital library for full access to over 7,000 books
    and videos, as well as industry leading tools to help you plan your personal development
    and advance your career. For more information, please visit our website.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 订阅我们的在线数字图书馆，您将可以访问超过 7,000 本书籍和视频，此外还可以使用行业领先的工具帮助您规划个人发展并推动职业进步。欲了解更多信息，请访问我们的网站。
- en: Why subscribe?
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么订阅？
- en: Spend less time learning and more time coding with practical eBooks and Videos
    from over 4,000 industry professionals
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花更少的时间学习，花更多的时间编码，利用来自超过 4,000 名行业专业人士的实用电子书和视频
- en: Improve your learning with Skill Plans built especially for you
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过为您量身定制的技能计划提高您的学习效率
- en: Get a free eBook or video every month
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每月获取免费的电子书或视频
- en: Fully searchable for easy access to vital information
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完全可搜索，方便快速访问重要信息
- en: Copy and paste, print, and bookmark content
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复制和粘贴、打印和收藏内容
- en: At www.packt.com, you can also read a collection of free technical articles,
    sign up for a range of free newsletters, and receive exclusive discounts and offers
    on Packt books and eBooks.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在 www.packt.com，您还可以阅读一系列免费的技术文章，订阅各种免费的电子邮件通讯，并获得 Packt 图书和电子书的独家折扣和优惠。
- en: Other Books You May Enjoy
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他您可能喜欢的书籍
- en: 'If you enjoyed this book, you may be interested in these other books by Packt:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您喜欢本书，您可能对Packt出版的其他书籍感兴趣：
- en: '[![](img/9781803247335.png)](https://www.packtpub.com/product/transformers-for-natural-language-processing/9781803247335?_ga=2.5602675.1586621222.1658751433-1060321437.1657688636)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](img/9781803247335.png)](https://www.packtpub.com/product/transformers-for-natural-language-processing/9781803247335?_ga=2.5602675.1586621222.1658751433-1060321437.1657688636)'
- en: '**Transformers for Natural Language Processing, Second Edition**'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '**自然语言处理的变压器模型（第二版）**'
- en: Denis Rothman
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 丹尼斯·罗斯曼（Denis Rothman）
- en: 'ISBN: 9781803247335'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: ISBN：9781803247335
- en: Find out how ViT and CLIP label images (including blurry ones!) and create images
    from a sentence using DALL-E
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解ViT和CLIP如何为图像（包括模糊图像！）打标签，并使用DALL-E根据句子生成图像
- en: Discover new techniques to investigate complex language problems
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索新的技术以研究复杂的语言问题
- en: Compare and contrast the results of GPT-3 against T5, GPT-2, and BERT-based
    transformers
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对比和分析GPT-3与T5、GPT-2和BERT模型的结果
- en: Carry out sentiment analysis, text summarization, casual speech analysis, machine
    translations, and more using TensorFlow, PyTorch, and GPT-3
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorFlow、PyTorch和GPT-3进行情感分析、文本摘要、口语分析、机器翻译等任务
- en: Measure the productivity of key transformers to define their scope, potential,
    and limits in production
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 衡量关键变压器的生产力，以定义它们的范围、潜力和生产限制
- en: '[![](img/9781801819312.png)](https://www.packtpub.com/product/machine-learning-with-pytorch-and-scikit-learn/9781801819312?_ga=2.204407376.1586621222.1658751433-1060321437.1657688636)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](img/9781801819312.png)](https://www.packtpub.com/product/machine-learning-with-pytorch-and-scikit-learn/9781801819312?_ga=2.204407376.1586621222.1658751433-1060321437.1657688636)'
- en: '**Machine Learning with PyTorch and Scikit-Learn**'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用PyTorch和Scikit-Learn进行机器学习**'
- en: Sebastian Raschka
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 塞巴斯蒂安·拉施卡（Sebastian Raschka）
- en: Yuxi (Hayden) Liu
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 刘宇熙（Hayden Liu）
- en: Vahid Mirjalili
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 瓦希德·米尔贾利利（Vahid Mirjalili）
- en: 'ISBN: 9781801819312'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: ISBN：9781801819312
- en: Explore frameworks, models, and techniques for machines to ‘learn’ from data
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索框架、模型和技术，让机器从数据中“学习”
- en: Use scikit-learn for machine learning and PyTorch for deep learning
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用scikit-learn进行机器学习，使用PyTorch进行深度学习
- en: Train machine learning classifiers on images, text, and more
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在图像、文本等数据上训练机器学习分类器
- en: Build and train neural networks, transformers, and boosting algorithms
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建和训练神经网络、变压器模型和提升算法
- en: Discover best practices for evaluating and tuning models
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现评估和调优模型的最佳实践
- en: Predict continuous target outcomes using regression analysis
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用回归分析预测连续的目标结果
- en: Dig deeper into textual and social media data using sentiment analysis
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入挖掘文本和社交媒体数据，使用情感分析
- en: Packt is searching for authors like you
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Packt正在寻找像您这样的作者
- en: If you’re interested in becoming an author for Packt, please visit authors.packtpub.com
    and apply today. We have worked with thousands of developers and tech professionals,
    just like you, to help them share their insight with the global tech community.
    You can make a general application, apply for a specific hot topic that we are
    recruiting an author for, or submit your own idea.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣成为Packt的作者，请访问authors.packtpub.com并今天就申请。我们与成千上万的开发者和技术专家合作，帮助他们与全球技术社区分享见解。您可以提交一般申请，申请我们正在招聘作者的特定热门话题，或者提交您自己的创意。
- en: Share your thoughts
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分享您的想法
- en: Now you’ve finished *Natural Language Processing with TensorFlow, Second Edition*,
    we’d love to hear your thoughts! If you purchased the book from Amazon, please
    [click here to go straight to the Amazon review page](https://packt.link/r/1838641351)
    for this book and share your feedback or leave a review on the site that you purchased
    it from.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经完成了*使用TensorFlow进行自然语言处理（第二版）*，我们很想听听您的想法！如果您从Amazon购买了本书，请[点击这里直接进入Amazon的书评页面](https://packt.link/r/1838641351)，分享您的反馈或在您购买的站点上留下评论。
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 您的评价对我们以及技术社区非常重要，将帮助我们确保提供优质的内容。
