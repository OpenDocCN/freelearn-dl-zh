- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Understanding Differentiable Volumetric Rendering
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解可微体积渲染
- en: In this chapter, we are going to discuss a new way of differentiable rendering.
    We are going to use a voxel 3D data representation, unlike the mesh 3D data representation
    we used in the last chapter. Voxel 3D data representation has certain advantages
    compared to mesh models. For example, it is more flexible and highly structured.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将讨论一种新的可微渲染方式。我们将使用体素3D数据表示方式，不同于上一章使用的网格3D数据表示。与网格模型相比，体素3D数据表示具有某些优势。例如，它更灵活，结构更清晰。
- en: To understand volumetric rendering, we need to understand several important
    concepts, such as ray sampling, volumes, volume sampling, and ray marching. All
    these concepts have corresponding PyTorch3D implementations. We will discuss each
    of these concepts using explanations and coding exercises.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解体积渲染，我们需要了解一些重要的概念，如光线采样、体积、体积采样和光线行进。所有这些概念都有对应的PyTorch3D实现。我们将通过解释和编码练习讨论这些概念。
- en: After we understand the preceding basic concepts of volumetric rendering, we
    can then see easily that all the operations mentioned already are already differentiable.
    Volumetric rendering is naturally differentiable. Thus, by then, we will be ready
    to use differentiable volumetric rendering for some real applications. We are
    going to go over a coding example of reconstructing 3D voxel models from multiple
    images by using differentiable volumetric rendering.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们理解了前面提到的体积渲染基本概念后，我们可以轻松地看到，所有提到的操作已经是可微的。体积渲染天生就是可微的。因此，到那时，我们将准备好使用可微的体积渲染进行一些实际应用。我们将通过一个编码示例，展示如何利用可微的体积渲染从多张图像中重建3D体素模型。
- en: We will first understand volumetric rendering on a high level. We will then
    dive into the basic concepts, such as ray sampling, volumes, volume sampling,
    and ray marching. We will then present a coding example of reconstructing 3D object
    shapes from a collection of images taken from different views of the object.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先高层次地理解体积渲染。然后我们将深入探讨一些基本概念，如光线采样、体积、体积采样和光线行进。接下来，我们将展示一个通过从不同视角拍摄的图像集合重建3D物体形状的编码示例。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要主题：
- en: A high-level description of volumetric rendering
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 体积渲染的高层次描述
- en: Understanding ray sampling
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解光线采样
- en: Using volume sampling
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用体积采样
- en: Understanding ray marching
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解光线行进
- en: Reconstructing 3D objects and colors from multi-view images
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从多视角图像重建3D物体和颜色
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In order to run the example code snippets in this book, you need to have a computer,
    ideally with a GPU. However, running the code snippets with only CPUs is not impossible.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行本书中的示例代码片段，您需要一台计算机，最好配备GPU。然而，仅使用CPU运行代码片段也是可以的。
- en: 'The recommended computer configuration includes the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐的计算机配置包括以下内容：
- en: A GPU for example, the NVIDIA GTX series or RTX series with at least 8 GB of
    memory
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一张GPU，例如，NVIDIA GTX系列或RTX系列，至少具有8GB内存
- en: Python 3
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3
- en: PyTorch library and PyTorch3D libraries
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch库和PyTorch3D库
- en: The code snippets with this chapter can be found at [https://github.com/PacktPublishing/3D-Deep-Learning-with-Python.](https://github.com/PacktPublishing/3D-Deep-Learning-with-Python)
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码片段可以在[https://github.com/PacktPublishing/3D-Deep-Learning-with-Python.](https://github.com/PacktPublishing/3D-Deep-Learning-with-Python)找到。
- en: Overview of volumetric rendering
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 体积渲染概述
- en: Volumetric rendering is a collection of techniques used to generate a 2D view
    of discrete 3D data. This 3D discrete data could be a collection of images, voxel
    representation, or any other discrete representation of data. The main goal of
    volumetric rendering is to render a 2D projection of 3D data since that is what
    our eyes can perceive on a flat screen. This method generated such projections
    without any explicit conversion to a geometric representation (such as meshes).
    Volumetric rendering is typically used when generating surfaces is difficult or
    can lead to errors. It can also be used when the content (and not just the geometry
    and surface) of the volume is important. It is typically used for data visualization.
    For example, in brain scans, a visualization of the content of the interior of
    the brain is typically very important.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 体积渲染是一种用于生成离散三维数据二维视图的技术集合。这些三维离散数据可以是图像集合、体素表示，或任何其他离散的数据表示。体积渲染的主要目标是呈现三维数据的二维投影，因为这正是我们的眼睛在平面屏幕上能够感知到的。这种方法生成这样的投影，而无需显式地转换为几何表示（如网格）。体积渲染通常在生成表面困难或可能导致错误时使用。当体积的内容（而不仅仅是几何形状和表面）很重要时，也可以使用这种方法。它通常用于数据可视化。例如，在脑部扫描中，通常非常重要的是对大脑内部内容的可视化。
- en: 'In this section, we will explore the volumetric rendering of a volume. We will
    get a high-level overview of volumetric rendering as shown in *Figure 5**.1*:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨体积的体积渲染。我们将对体积渲染进行高层次的概述，如*图 5.1*所示：
- en: 'First, we represent the 3D space and objects in it by using a **volume**, which
    is a 3D grid of regularly spaced nodes. Each node has two properties: density
    and color features. The density typically ranges from 0 to 1\. Density can also
    be understood as the probability of occupancy. That is, how sure we think that
    the node is occupied by a certain object. In some cases, the probability can also
    be opacity.'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们通过使用**体积**来表示三维空间和其中的物体，体积是一个规则间隔的三维网格。每个节点有两个属性：密度和颜色特征。密度通常在0到1之间。密度也可以理解为占用的概率。也就是说，我们对某个节点是否被某个物体占据的确信程度。在某些情况下，概率也可以是透明度。
- en: We need to define one or multiple cameras. The rendering is the process that
    determines what the cameras can observe from their views.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要定义一个或多个相机。渲染是确定相机从其视角所能观察到的内容的过程。
- en: To determine the RGB values at each pixel of the preceding cameras, a ray is
    generated from the projection center going through each image pixel of the cameras.
    We need to check the probability of occupancy or opacity and colors along this
    ray to determine RGB values for the pixel. Note there are infinitely many points
    on each such ray. Thus, we need to have a sampling scheme to select a certain
    number of points along this ray. This sampling operation is called **ray sampling**.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了确定前述相机中每个像素的RGB值，首先从投影中心生成一条射线，通过相机的每个图像像素。我们需要检查沿射线的占用概率或不透明度和颜色，以确定该像素的RGB值。请注意，每条射线上有无数个点。因此，我们需要有一种采样方案来选择沿射线的若干个点。这一采样操作称为**射线采样**。
- en: Note that we have densities and colors defined on the nodes of the volume but
    not on the points on the rays. Thus, we need to have a way to convert densities
    and colors of volumes to points on rays. This operation is called **volume sampling**.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，我们在体积的节点上定义了密度和颜色，但在射线上的点上没有定义。因此，我们需要一种方法将体积的密度和颜色转换为射线上的点。这一操作称为**体积采样**。
- en: Finally, from the densities and colors of the rays, we need to determine the
    RGB values of each pixel. In this process, we need to compute how many incident
    lights can arrive at each point along the ray and how many lights are reflected
    to the image pixel. We call this process **ray marching**.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，根据射线的密度和颜色，我们需要确定每个像素的RGB值。在这个过程中，我们需要计算沿射线每个点上能够到达的入射光线数量，以及反射到图像像素的光线数量。我们将这个过程称为**射线行进**。
- en: '![Figure 5.1: Volumetric rendering ](img/B18217_05_001.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.1：体积渲染](img/B18217_05_001.jpg)'
- en: 'Figure 5.1: Volumetric rendering'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1：体积渲染
- en: 'Having understood the basic process of volumetric rendering, let us dive deeper
    into the first concept: ray sampling.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解了体积渲染的基本过程后，让我们更深入地探讨第一个概念：射线采样。
- en: Understanding ray sampling
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解射线采样
- en: Ray sampling is the process of emitting rays from the camera that goes through
    the image pixels and sampling points along these rays. The ray sampling scheme
    depends on the use case. For example, sometimes we might want to randomly sample
    rays that go through some random subset of image pixels. Typically, we need to
    use such a sampler during training since we only need a representative sample
    from the full data. In such cases, we can use `MonteCarloRaysampler` in Pytorch3D.
    In other cases, we want to get the pixel values for each pixel on the image and
    maintain a spatial order. This is useful for rendering and visualization. For
    such use cases, PyTorch3D provides `NDCMultiNomialRaysampler`.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 光线采样是从相机发射光线，穿过图像像素并沿着这些光线采样点的过程。光线采样方案取决于具体应用。例如，有时我们可能希望随机采样穿过一些图像像素的光线。通常在训练时，我们只需要从完整数据中提取一个代表性样本，这时可以使用
    Pytorch3D 中的 `MonteCarloRaysampler`。在其他情况下，我们希望获取图像中每个像素的像素值并保持空间顺序，这对于渲染和可视化非常有用。对于这种应用，PyTorch3D
    提供了 `NDCMultiNomialRaysampler`。
- en: 'In the following, we will demonstrate how to use one of the PyTorch3D ray samplers,
    `NDCGridRaysampler`. This is like `NDCMultiNomialRaysampler`, where pixels are
    sampled along a grid. The codes can be found in the GitHub repository named `understand_ray_sampling.py`:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的示例中，我们将演示如何使用 PyTorch3D 中的一个光线采样器 `NDCGridRaysampler`。它类似于 `NDCMultiNomialRaysampler`，即沿着网格采样像素。相关代码可以在
    GitHub 仓库 `understand_ray_sampling.py` 中找到：
- en: 'First, we need to import all the Python modules, including the definition of
    `NDCGridRaysampler`:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要导入所有的 Python 模块，包括 `NDCGridRaysampler` 的定义：
- en: '[PRE0]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Set up the devices for use in the following steps. If we have GPUs, then we
    are going to use the first GPU. Otherwise, we are going to use the CPU:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置设备以供后续步骤使用。如果我们有 GPU，那么我们将使用第一块 GPU；否则，我们将使用 CPU：
- en: '[PRE1]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We define a batch of 10 cameras. Here, `num_views` is the number of views,
    which is 10 in this case. The `elev` variable denotes the elevation angle, and
    `azim` denotes the azimuth angle. The rotation, `R`, and translation, `T`, can
    thus be determined using the PyTorch3D `look_at_view_transform` function. The
    10 cameras then can be defined by using rotations and translations. The 10 cameras
    all point at an object located at the center of the world coordinates:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了一批 10 个相机。这里，`num_views` 表示视图的数量，在本例中为 10。`elev` 变量表示仰角，`azim` 表示方位角。旋转矩阵
    `R` 和平移矩阵 `T` 可以通过 PyTorch3D 的 `look_at_view_transform` 函数来确定。然后，通过旋转和平移定义 10
    个相机，这 10 个相机都指向位于世界坐标系中心的物体：
- en: '[PRE2]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, we can define the ray sampler, which is the `raysampler` variable.
    We need to specify the image size of the camera. We also need to specify the minimum
    and maximum depths that the ray ranges from. The `n_pts_per_ray` input is the
    number of points along the ray:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以定义光线采样器，也就是 `raysampler` 变量。我们需要指定相机的图像大小，还需要指定光线采样的最小深度和最大深度。`n_pts_per_ray`
    输入参数表示每条光线上的点数：
- en: '[PRE3]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In the preceding step, we have already defined a ray sampler. To make the ray
    sampler samples rays and points for use, we need to let the ray sampler know where
    our cameras are and in what directions they are pointing. This can be easily achieved
    by passing the cameras defined in step 3 to `raysampler`. What we obtain is then
    a `ray_bundle` variable:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在前面的步骤中，我们已经定义了一个光线采样器。为了让光线采样器能够采样光线和点供后续使用，我们需要告知光线采样器我们的相机位置以及它们的指向方向。这可以通过将第
    3 步中定义的相机传递给 `raysampler` 来轻松实现。然后我们得到一个 `ray_bundle` 变量：
- en: '[PRE4]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `ray_bundle` variable contains a collection of different PyTorch tensors
    that specify the sampled rays and points. We can print these member variables
    to check their shapes and verify their contents:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ray_bundle` 变量包含一组不同的 PyTorch 张量，指定了采样的光线和点。我们可以打印这些成员变量来检查它们的形状并验证它们的内容：'
- en: '[PRE5]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The codes should run and print the following information:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些代码应该运行并打印以下信息：
- en: We can see that `ray_bundle.origins` is a tensor about the origins of the rays,
    and the batch size is 10\. Because the image size is 64 by 64, the size of the
    second and third dimensions are both 64\. For each origin, we need three numbers
    to specify its 3D location.
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以看到 `ray_bundle.origins` 是一个张量，包含了光线的起点，批量大小为 10。由于图像大小为 64×64，第二维和第三维的大小都是
    64。对于每个起点，我们需要三个数字来指定其三维位置。
- en: '`ray_bundle.directions` is a tensor about the directions of the ray. Again,
    the batch size is 10 and the image size is 64 by 64\. These explain the size of
    the first three dimensions of the tensor. We need three numbers to specify a direction
    in 3D spaces.'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ray_bundle.directions` 是一个关于射线方向的张量。这里批次大小为 10，图像大小为 64x64。这解释了张量前面三个维度的大小。我们需要三个数字来指定
    3D 空间中的一个方向。'
- en: '`ray_bundle.lengths` is a tensor about the depths of each point on the rays.
    There are 10x64x64 rays and there are 50 points on each ray.'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ray_bundle.lengths` 是一个关于射线每个点深度的张量。共有 10x64x64 条射线，每条射线有 50 个点。'
- en: '`ray_bundle.xys` is a tensor about the x and y locations on the image plane
    corresponding to each ray. There are 10x64x64 rays. We need one number to represent
    the x location and one number to represent the y location:'
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ray_bundle.xys` 是一个关于图像平面上每条射线的 x 和 y 位置的张量。共有 10x64x64 条射线。我们需要一个数字表示 x 位置，一个数字表示
    y 位置：'
- en: '[PRE6]'
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Finally, we save `ray_bundle` to a `ray_sampling.pt` file. These rays are useful
    for our coding exercises in the following sections:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将 `ray_bundle` 保存到 `ray_sampling.pt` 文件中。这些射线对我们接下来的编码练习很有用：
- en: '[PRE7]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: By now, we understand what ray samplers do. Ray samplers give us a batch of
    rays and discrete points on the rays. However, we still do not have densities
    and colors defined on these points and rays. Next, we are going to learn how to
    get these densities and colors from the volumes.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了射线采样器的作用。射线采样器给我们提供了一批射线和射线上的离散点。然而，我们仍然没有在这些点和射线上定义密度和颜色。接下来，我们将学习如何从体积中获取这些密度和颜色。
- en: Using volume sampling
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用体积采样
- en: 'Volume sampling is the process of getting color and occupancy information along
    the points provided by the ray samples. The volume representation we are working
    with is discrete. Therefore, the points defined in the ray sampling step might
    not fall exactly on a point. The nodes of the volume grids and points on rays
    typically have different spatial locations. We need to use an interpolation scheme
    to interpolate the densities and colors at points of rays from the densities and
    colors at volumes. We can do that by using `VolumeSampler` implemented in PyTorch3D.
    The following code can be found in the GitHub repository in the `understand_volume_sampler.py`
    file:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 体积采样是通过射线样本提供的点获取颜色和占用信息的过程。我们处理的体积表示是离散的。因此，在射线采样步骤中定义的点可能并不完全落在某个节点上。体积网格的节点和射线上的点通常具有不同的空间位置。我们需要使用插值方案来从体积的密度和颜色推算射线上的密度和颜色。我们可以使用
    PyTorch3D 中实现的 `VolumeSampler` 来做到这一点。以下代码可以在 GitHub 仓库中的 `understand_volume_sampler.py`
    文件中找到：
- en: 'Import the Python modules that we need:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入我们需要的 Python 模块：
- en: '[PRE8]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Set up the devices:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置设备：
- en: '[PRE9]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Load `ray_bundle`, which was computed in the last section:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载在上一节中计算的 `ray_bundle`：
- en: '[PRE10]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We then define a volume. The densities tensor has a shape of [10, 1, 64, 64,
    50], where we have a batch of 10 volumes, and each volume is a grid of 64x64x50
    nodes. Each node has one number to represent the density at the node. On the other
    hand, the colors tensor has a shape of [10, 3, 64, 64, 50], because each color
    needs three numbers to represent the RGB values:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个体积。密度张量的形状是 [10, 1, 64, 64, 50]，这里有 10 个体积批次，每个体积是一个 64x64x50 的节点网格。每个节点有一个数字表示该节点的密度。另一方面，颜色张量的形状是
    [10, 3, 64, 64, 50]，因为每种颜色需要三个数字来表示 RGB 值：
- en: '[PRE11]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We need to define `volume_sampler` based on the volumes. Here, we use bilinear
    interpolation for the volume sampling. The densities and colors of points on the
    rays can then be easily obtained by passing `ray_bundle` to `volume_sampler`:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要根据体积定义 `volume_sampler`。在这里，我们使用双线性插值进行体积采样。然后，可以通过将 `ray_bundle` 传递给 `volume_sampler`
    来轻松获取射线上的点的密度和颜色：
- en: '[PRE12]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can print out the shape of the densities and colors:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以打印出密度和颜色的形状：
- en: '[PRE13]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output is as follows. Note that we have a batch size of 10 cameras, which
    explains the size of the first dimension of the tensors. We have one ray for each
    image pixel and our camera image resolution is 64 by 64\. The number of points
    on each ray is 50, which explains the size of the fourth dimension of the tensors.
    Each density can be represented by one number and each color needs three numbers
    to represent the RGB values:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出如下。注意，我们有 10 个相机的批次大小，这解释了张量第一维的大小。每个图像像素对应一条射线，我们的相机图像分辨率是 64x64。每条射线上的点数为
    50，这解释了张量第四维的大小。每个密度可以用一个数字表示，每种颜色需要三个数字来表示 RGB 值：
- en: '[PRE14]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Finally, let us save the densities and colors because we need to use them in
    the next section:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们保存密度和颜色，因为我们需要在下一部分使用它们：
- en: '[PRE15]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We now have an overview of volume sampling. We know what it is and why it is
    useful. In the next section, we will learn about how to use these densities and
    colors to generate the RGB image values on the batch of cameras.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经概览了体积采样。我们知道它是什么以及为什么它有用。在接下来的部分，我们将学习如何使用这些密度和颜色来生成批量相机的RGB图像值。
- en: Exploring the ray marcher
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索射线行进器
- en: Now that we have the color and density values for all the points sampled with
    the ray sampler, we need to figure out how to use it to finally render the pixel
    value on the projected image. In this section, we are going to discuss the process
    of converting the densities and colors on points of rays to RGB values on images.
    This process models the physical process of image formation.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经获得了所有通过射线采样器采样的点的颜色和密度值，我们需要弄清楚如何利用它来最终在投影图像上渲染像素值。在这一部分，我们将讨论如何将射线点上的密度和颜色转换为图像上的RGB值的过程。这个过程模拟了图像形成的物理过程。
- en: In this section, we discuss a very simple model, where the RGB value of each
    image pixel is a weighted sum of the colors on the points of the corresponding
    ray. If we consider the densities as probabilities of occupancy or opacity, then
    the incident light intensity at each point of the ray is a = product of (1-p_i),
    where p_i are the densities. Given the probability that this point is occupied
    by a certain object is p_i, the expected light intensity reflected from this point
    is w_i = a p_i. We just use w_i as the weights for the weighted sum of colors.
    Usually, we normalize the weights by applying a softmax operation, such that the
    weights all sum up to one.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们讨论一个非常简单的模型，其中每个图像像素的RGB值是相应射线上的点的颜色的加权和。如果我们将密度视为占据或不透明的概率，那么射线上每个点的入射光强度a
    = (1 - p_i)的乘积，其中p_i是密度。假设该点被某个物体占据的概率为p_i，那么从该点反射的期望光强度为w_i = a p_i。我们将w_i作为加权和的颜色的权重。通常，我们通过应用softmax操作来对权重进行归一化，使得所有权重的总和为1。
- en: 'PyTorch3D contains multiple implementations of ray marchers. The following
    codes can be found in `understand_ray_marcher.py` in the GitHub repository:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch3D包含多种射线行进器的实现。以下代码可以在GitHub仓库中的`understand_ray_marcher.py`找到：
- en: 'In this first step, we will import all the required packages:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一步中，我们将导入所有所需的包：
- en: '[PRE16]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Next, we load the densities and colors on rays from the last section:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们加载上一部分中射线上的密度和颜色：
- en: '[PRE17]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We define `ray_marcher` and pass the densities and colors on rays to `ray_marcher`.
    This gives us `image_features`, which are exactly rendered RGB values:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了`ray_marcher`并将射线上的密度和颜色传递给`ray_marcher`。这将给我们`image_features`，即渲染后的RGB值：
- en: '[PRE18]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can print the image feature shape:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以打印图像特征的形状：
- en: '[PRE19]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'As we have expected, the shape is [10, 64, 64, 4], where 10 is the batch size,
    and 64 is the image width and height. The outputs have four channels, the first
    three are RGBs. The last channel is the alpha channel, which represents whether
    the pixel is in the foreground or the background:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如我们所预期的，形状是[10, 64, 64, 4]，其中10是批量大小，64是图像的宽度和高度。输出有四个通道，前三个是RGB，最后一个通道是alpha通道，表示像素是前景还是背景：
- en: '[PRE20]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We have now gone through some of the main components of volumetric rendering.
    Note that the computation process from the volume densities and colors to image
    pixel RGB values is already differentiable. So, volumetric rendering is naturally
    differentiable. Given that all the variables in the preceding examples are PyTorch
    tensors, we can compute gradients on these variables.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经了解了一些体积渲染的主要组成部分。注意，从体积密度和颜色到图像像素RGB值的计算过程已经是可微分的。因此，体积渲染自然是可微分的。考虑到前面的所有变量都是PyTorch张量，我们可以对这些变量计算梯度。
- en: In the next section, we will learn about differentiable volume rendering and
    see an example of using volumetric rendering for reconstructing 3D models from
    multi-view images.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将学习可微分的体积渲染，并查看一个使用体积渲染从多视角图像重建3D模型的示例。
- en: Differentiable volumetric rendering
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可微分体积渲染
- en: 'While standard volumetric rendering is used to render 2D projections of 3D
    data, differentiable volume rendering is used to do the opposite: construct 3D
    data from 2D images. This is how it works: we represent the shape and texture
    of the object as a parametric function. This function can be used to generate
    2D projections. But, given 2D projections (this is typically multiple views of
    the 3D scene), we can optimize the parameters of these implicit shape and texture
    functions so that its projections are the multi-view 2D images. This optimization
    is possible since the rendering process is completely differentiable, and the
    implicit functions used are also differentiable.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然标准的体积渲染用于渲染 3D 数据的 2D 投影，但可微分体积渲染则用于做相反的事情：从 2D 图像构建 3D 数据。它的工作原理是：我们将物体的形状和纹理表示为一个参数化的函数。这个函数可以用来生成
    2D 投影。然而，给定 2D 投影（通常是多视角的 3D 场景图像），我们可以优化这些隐式形状和纹理函数的参数，使其投影是多视角的 2D 图像。由于渲染过程是完全可微分的，且所使用的隐式函数也可微分，因此这种优化是可行的。
- en: Reconstructing 3D models from multi-view images
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从多视角图像重建 3D 模型
- en: In this section, we are going to show an example of using differentiable volumetric
    rendering for reconstructing 3D models from multi-view images. Reconstructing
    3D models is a frequently sought problem. Usually, the direct ways of measuring
    the 3D world are difficult and costly, for example, LiDAR and Radar are typically
    expensive. On the other hand, 2D cameras have much lower costs, which makes reconstructing
    the 3D world from 2D images incredibly attractive. Of course, to reconstruct the
    3D world, we need multiple images from multiple views.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将展示一个使用可微分体积渲染从多视角图像中重建 3D 模型的示例。重建 3D 模型是一个常见的难题。通常，直接测量 3D 世界的方法既困难又昂贵，例如，LiDAR
    和雷达通常很昂贵。另一方面，2D 相机的成本要低得多，这使得从 2D 图像重建 3D 世界变得极具吸引力。当然，为了重建 3D 世界，我们需要来自多个视角的多张图像。
- en: 'The following `volume_renderer.py` code can be found in the GitHub repository
    and it is modified from a tutorial of PyTorch3D. We will use this coding example
    to show how the real-world application of volumetric rendering can be:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下的 `volume_renderer.py` 代码可以在 GitHub 仓库中找到，并且它是从 PyTorch3D 的教程中修改而来。我们将使用这个代码示例展示体积渲染在实际应用中的运作方式：
- en: 'First, we need to import all the Python modules:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要导入所有的 Python 模块：
- en: '[PRE21]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next, we need to set up the device:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要设置设备：
- en: '[PRE22]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Using the provided function from the PyTorch3D tutorial, we generate 40 cameras,
    images, and silhouette images with different angles. We will consider these images
    as the given ground-truth images, and we will fit a 3D volumetric model to these
    observed ground-truth images:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 PyTorch3D 教程提供的函数，我们生成 40 个不同角度的相机、图像和轮廓图像。我们将这些图像视为给定的真实图像，并拟合一个 3D 体积模型到这些观察到的真实图像：
- en: '[PRE23]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next, we define a ray sampler. As we have discussed in the previous sections,
    the ray sampler is for sample rays, and points per rays for us:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个光线采样器。正如我们在前面几节中讨论的，光线采样器用于为我们采样光线及每条光线的采样点：
- en: '[PRE24]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next, we create the ray marcher as before. Note, this time, we define a variable
    renderer of the `VolumeRenderer` type. `VolumeRenderer` is just a nice interface,
    where ray samplers and ray marchers do all the heavy-lifting work under the hood:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们像之前一样创建光线行进器。注意，这次我们定义了一个 `VolumeRenderer` 类型的变量渲染器。`VolumeRenderer` 只是一个很好的接口，光线采样器和光线行进器在背后做所有繁重的工作：
- en: '[PRE25]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, we define a `VolumeModel` class. This class is just for encapsulating
    a volume so that the gradients can be computed in the forward function and the
    volume densities and colors can be updated by the optimizer:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个 `VolumeModel` 类。这个类的作用仅仅是封装一个体积，以便在前向函数中计算梯度，并且通过优化器更新体积密度和颜色：
- en: '[PRE26]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Define a Huber loss function. The Huber loss function is a robust loss function
    to prevent a small number of outliers from dragging the optimization away from
    the true optimal solutions. Minimizing this loss function will move x closer to
    y:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个 Huber 损失函数。Huber 损失函数是一种鲁棒的损失函数，用于防止少数异常值使优化偏离真实的最优解。最小化这个损失函数将使 x 更接近
    y：
- en: '[PRE27]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Move everything to the right device:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有内容移动到正确的设备上：
- en: '[PRE28]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Define an instance of `VolumeModel`:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个 `VolumeModel` 的实例：
- en: '[PRE29]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now let’s set up the optimizer. The learning rate, `lr`, is set to 0.1\. We
    use an Adam optimizer, and the number of optimization iterations will be 300:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们来设置优化器。学习率 `lr` 设置为 0.1。我们使用 Adam 优化器，优化迭代次数为 300 次：
- en: '[PRE30]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Next, we have the main optimization loop. The densities and colors of the volume
    are rendered, and the resulting colors and silhouettes are compared with the observed
    multi-view images. The Huber loss between the rendered images and observed ground-truth
    images is minimized:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们进行主要的优化循环。体积的密度和颜色被渲染出来，得到的颜色和轮廓与观察到的多视图图像进行比较。通过最小化渲染图像和观察到的真实图像之间的Huber损失：
- en: '[PRE31]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'After the optimization is finished, we take the final resulting volumetric
    model and render images from new angles:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在优化完成后，我们将最终得到的体积模型从新的角度渲染图像：
- en: '[PRE32]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Finally, the rendered new images are shown in Figure 5.2:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，渲染出来的新图像显示在图5.2中：
- en: '![Figure 5.2: Rendered images from the fitted 3D model ](img/B18217_05_002.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.2：来自拟合3D模型的渲染图像](img/B18217_05_002.jpg)'
- en: 'Figure 5.2: Rendered images from the fitted 3D model'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2：来自拟合3D模型的渲染图像
- en: By now, we have an overview of some of the main concepts in differentiable volumetric
    rendering. We have also learned a concrete example of using differentiable volumetric
    rendering for reconstructing 3D models from multiview images. You should be able
    to master the skills already and be able to use the technique for your own problems.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经概述了可微分体积渲染中的一些主要概念。我们还学习了一个具体的例子，展示了如何利用可微分体积渲染从多视图图像中重建3D模型。你应该已经掌握了这些技巧，并能够将其应用于自己的问题。
- en: Summary
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we started with a high-level description of differentiable
    volumetric rendering. We then dived deep into several important concepts of differentiable
    volumetric rendering, including ray sampling, volume sampling, and the ray marcher,
    but only by explanations and coding examples. We walked through a coding example
    of using differentiable volumetric rendering for reconstructing 3D models from
    multi-view images.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们首先对可微分体积渲染进行了高层次的描述。接着，我们深入探讨了可微分体积渲染中的几个重要概念，包括射线采样、体积采样和射线步进器，但仅通过解释和编码示例来进行讲解。我们还走过了一个使用可微分体积渲染从多视图图像中重建3D模型的编码示例。
- en: Using volumes for 3D deep learning has become an interesting direction in recent
    years. As many innovative ideas come out following this direction, many breakthroughs
    are emerging. One of the breakthroughs, called **Neural Radiance Fields** (**NeRF**),
    will be the topic of our next chapter.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 使用体积数据进行3D深度学习近年来已经成为一个有趣的方向。随着这一方向上涌现出许多创新思想，许多突破也在不断出现。其中一个突破被称为**神经辐射场**（**NeRF**），它将成为我们下一章的主题。
