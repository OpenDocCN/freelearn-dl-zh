- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: '**Artificial intelligence** (**AI**) has come a long way since its inception,
    transforming from a futuristic concept into a ubiquitous technology that permeates
    every aspect of our lives. From healthcare and finance to decision-making processes
    in both the public and private sectors, AI systems have become integral to our
    daily existence. As AI-powered applications such as ChatGPT become essential tools
    for individuals and businesses alike, it is of utmost importance that we address
    the ethical, social, and technical challenges that accompany this progress.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能**（**AI**）自诞生以来已经走过了漫长的历程，从一个未来主义的概念转变为渗透我们生活方方面面的普及技术。从医疗健康、金融到公共和私人部门的决策过程，AI系统已成为我们日常生活中不可或缺的一部分。随着以ChatGPT为代表的AI驱动应用成为个人和企业的基本工具，我们必须高度重视随之而来的伦理、社会和技术挑战。'
- en: The motivation behind this book is rooted in our belief that now, more than
    ever, we must lay the groundwork for a future where AI serves as a force for good.
    As AI continues to shape our world, this book seeks to provide AI engineers, business
    leaders, policymakers, and other stakeholders with comprehensive guidance on the
    development and implementation of responsible, trustworthy AI systems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的动机源于我们的信念：现在，比任何时候都更需要为一个AI能够成为推动社会进步的积极力量的未来打下基础。随着AI不断塑造我们的世界，本书旨在为AI工程师、商业领袖、政策制定者以及其他利益相关者提供关于负责任且值得信赖的AI系统开发与实施的全面指导。
- en: In this comprehensive book, we will explore various facets of Responsible AI,
    including the vulnerabilities of **Machine Learning** (**ML**) models, susceptibility
    to adversarial attacks, and the importance of robust security measures. We will
    delve into risk-averse methodologies that prioritize safety and reliability, minimizing
    potential harm and unintended consequences. The book examines policy frameworks
    and strategies adopted by various countries to ensure ethical AI development and
    deployment, as well as the crucial aspects of data privacy, with techniques and
    best practices to protect user information and maintain trust in AI systems. Additionally,
    we will cover approaches to AI model evaluation, uncertainty, and validation;
    the roles of MLOps and AutoML in fostering efficient, scalable, and responsible
    AI practices in enterprise settings; and the importance of fairness in AI, addressing
    challenges in data collection, preprocessing, and model optimization to reduce
    biases and ensure equitable outcomes. We will also discuss the need for transparency
    and explainability in AI systems, ethical governance, and oversight, and cover
    techniques to build adaptable, calibrated AI models that can respond effectively
    to changing environments and requirements. Moreover, we will delve into the concept
    of sustainable feature stores to promote efficiency and consistency in the development
    of responsible AI models and present real-world case studies and applications,
    demonstrating the impact and benefits of responsible AI across various industries.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本全面的书籍中，我们将探讨负责任AI的各个方面，包括**机器学习**（**ML**）模型的脆弱性、对抗性攻击的易受性以及强有力安全措施的重要性。我们将深入研究以安全性和可靠性为优先的风险规避方法，尽量减少潜在的危害和意外后果。本书还将探讨各国采取的政策框架和策略，以确保AI的伦理开发与部署，并涉及数据隐私的关键问题，提供保护用户信息的技术和最佳实践，以维护对AI系统的信任。此外，我们将讨论AI模型评估、不可预见性和验证的方法；MLOps和AutoML在企业环境中推动高效、可扩展且负责任的AI实践的作用；以及AI公平性的重要性，解决数据收集、预处理和模型优化中的挑战，减少偏差，确保公正的结果。我们还将讨论AI系统中的透明度和可解释性的必要性，伦理治理和监督，并介绍构建适应性强、经过校准的AI模型的技术，使其能够有效应对不断变化的环境和需求。此外，我们将深入探讨可持续特征库的概念，促进在负责任AI模型开发中的效率和一致性，并展示多个行业中负责任AI的实际案例研究和应用，展示其影响和好处。
- en: This book aims to serve as a comprehensive resource for those seeking to harness
    the power of AI while addressing the critical ethical and social challenges it
    presents. We hope this book inspires you to join the movement toward responsible
    AI and apply its principles and practices in your own professional and personal
    endeavors.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在成为一本全面的资源，帮助那些希望利用人工智能（AI）力量的读者，同时应对其所带来的关键伦理和社会挑战。我们希望本书能激励你加入负责任的AI发展行列，并在自己的职业和个人事业中应用其原则和实践。
- en: Who this book is for
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书的目标读者
- en: This book is for experienced ML professionals looking to understand the risks
    and data leakages of ML models and frameworks, incorporate fairness by design
    in both models and platforms, and learn how to develop and use reusable components
    to reduce effort and cost when setting up and maintaining an AI ecosystem.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本书面向有经验的机器学习专业人士，帮助他们了解机器学习模型和框架的风险及数据泄露，如何通过设计实现公正，并学习如何开发和使用可复用组件，从而减少设置和维护AI生态系统的工作量和成本。
- en: What this book covers
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书内容概述
- en: '[*Chapter 1*](B18681_01.xhtml#_idTextAnchor014), *Risks and Attacks on ML Models*,
    presents a detailed overview of key terms related to different types of attacks
    possible on ML models, creating a basic understanding of how ML attacks are designed
    by attackers. In this chapter, you will get familiar with the attacks, both direct
    and indirect, that compromise the privacy of a system. In this context, this chapter
    highlights losses incurred by organizations due to the loss of sensitive information
    and how individuals remain vulnerable to losing confidential information into
    the hands of adversaries.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第1章*](B18681_01.xhtml#_idTextAnchor014)，*机器学习模型的风险与攻击*，详细概述了与机器学习模型可能遭遇的不同类型攻击相关的关键术语，帮助读者初步理解攻击者如何设计机器学习攻击。本章中，你将了解直接和间接的攻击，这些攻击会危及系统的隐私。在此背景下，本章突出了由于敏感信息丧失给组织带来的损失，以及个人如何容易将机密信息暴露给对手。'
- en: '[*Chapter 2*](B18681_02.xhtml#_idTextAnchor040), *The* *Emergence of Risk-Averse
    Methodologies and Frameworks*, presents an overall detailed overview of risk assessment
    frameworks, tools, and methodologies that can be directly applied to evaluate
    model risk. In this chapter, you will get familiar with the tools included in
    data platforms and model design techniques that will help to reduce the risk at
    scale. The primary objective of this chapter is to create awareness of data anonymization
    and validation techniques, in addition to the introduction of different terms
    and measures related to privacy.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第2章*](B18681_02.xhtml#_idTextAnchor040)，*风险规避方法学与框架的出现*，全面介绍了风险评估框架、工具和方法学，这些可以直接应用于评估模型风险。本章中，你将了解数据平台中包含的工具和模型设计技术，帮助降低大规模应用中的风险。本章的主要目标是提高数据匿名化和验证技术的意识，同时介绍与隐私相关的不同术语和措施。'
- en: '[*Chapter 3*](B18681_03.xhtml#_idTextAnchor066), *Regulations and Policies
    Surrounding Trustworthy AI*, introduces different laws being passed across nations
    to protect and prevent the loss of sensitive information of customers. You will
    get to know the formation of different ethics expert groups, government initiatives,
    and policies being drafted to ensure the ethics and compliance of all AI solutions.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第3章*](B18681_03.xhtml#_idTextAnchor066)，*关于可信AI的法规与政策*，介绍了各国通过的不同法律，以保护和防止客户敏感信息的丧失。你将了解不同伦理专家小组的形成、政府举措以及正在制定的政策，以确保所有AI解决方案的伦理性与合规性。'
- en: '[*Chapter 4*](B18681_04.xhtml#_idTextAnchor093), *Privacy Management in Big
    Data and Model Design Pipelines*, presents a detailed overview of different components
    associated with a big data system, which serves as a building block atop which
    we can effectively deploy AI models. This chapter brings into the picture how
    compliance-related issues can be handled at a component level in a microservice-based
    architecture so that there is no information leakage. In this chapter, you get
    familiar with different security principles needed in individual microservices,
    as well as security measures that need to be incorporated in the cloud when deploying
    ML models at scale.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第4章*](B18681_04.xhtml#_idTextAnchor093)，*大数据与模型设计管道中的隐私管理*，详细介绍了与大数据系统相关的不同组件，这些组件作为构建块，帮助我们有效部署AI模型。本章介绍了如何在基于微服务的架构中处理合规性问题，以确保没有信息泄露。本章中，你将了解单个微服务中所需的不同安全原则，以及在大规模部署机器学习模型时需要在云中纳入的安全措施。'
- en: '[*Chapter 5*](B18681_05.xhtml#_idTextAnchor110), *ML Pipeline, Model Evaluation,
    and Handling Uncertainty*, introduces the AI/ML workflow. The chapter then delves
    into different ML algorithms used for classification, regression, generation,
    and reinforcement learning. The chapter also discusses issues related to the reliability
    and trustworthiness of these algorithms. We start by introducing the various components
    of an ML pipeline. The chapter then briefly explores the important AI/ML algorithms
    for the tasks of classification, regression, and clustering. Further, we discuss
    various types of uncertainties, their causes, and the techniques to quantify uncertainty.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第五章*](B18681_05.xhtml#_idTextAnchor110)，*机器学习管道、模型评估与不确定性处理*，介绍了人工智能/机器学习工作流。该章节深入探讨了用于分类、回归、生成和强化学习的不同机器学习算法。章节还讨论了与这些算法的可靠性和可信度相关的问题。我们从介绍机器学习管道的各种组件开始。接着，章节简要探索了分类、回归和聚类任务中重要的人工智能/机器学习算法。此外，我们还讨论了各种类型的不确定性、其成因及量化不确定性的技术。'
- en: '[*Chapter 6*](B18681_06.xhtml#_idTextAnchor126), *Hyperparameter Tuning, MLOPs,
    and AutoML*, continues from the previous chapter and explains the need for continuous
    training in an ML pipeline. Building an ML model is an iterative process, and
    the presence of so many models, each with a large number of hyperparameters, complicates
    things for beginners. This chapter provides a glimpse into the present AutoML
    options for your ML workflow. It expands on the situations where no-code/low-code
    solutions are useful. It explores the solutions provided by major cloud providers
    in terms of ease, features, and model explainability. Additionally, the chapter
    also covers orchestration tools, such as Kubeflow and Vertex AI, to manage the
    continuous training and deployment of your ML models.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第六章*](B18681_06.xhtml#_idTextAnchor126)，*超参数调优、MLOps与AutoML*，在上一章的基础上继续讲解了机器学习管道中持续训练的必要性。构建机器学习模型是一个迭代过程，且由于存在如此多的模型，每个模型都有大量的超参数，这对初学者来说无疑增加了复杂性。本章简要介绍了当前的AutoML选项，适用于你的机器学习工作流。它扩展了无代码/低代码解决方案的适用场景。还探讨了主要云服务提供商在易用性、功能和模型可解释性方面提供的解决方案。此外，本章还涉及了编排工具，如Kubeflow和Vertex
    AI，用于管理机器学习模型的持续训练和部署。'
- en: '[*Chapter 7*](B18681_07.xhtml#_idTextAnchor146), *Fairness Notions and Fair
    Data Generation*, presents problems pertaining to unfair data collection for different
    types of data, ontologies, vocabularies, and so on, due to the lack of standardization.
    The primary objective of this chapter is to stress the importance of the quality
    of data, as biased datasets can introduce hidden biases in ML models. This chapter
    focuses on the guiding principles for better data collection, management, and
    stewardship that need to be practiced globally. You will further see how evaluation
    strategies initial steps can help to build unbiased datasets, enabling new AI
    analytics and digital transformation journeys for ML-based predictions.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第七章*](B18681_07.xhtml#_idTextAnchor146)，*公平性概念与公平数据生成*，提出了由于缺乏标准化，针对不同类型数据、知识本体、词汇等的非公平数据收集问题。本章的主要目的是强调数据质量的重要性，因为偏见数据集可能会在机器学习模型中引入隐性偏见。该章重点介绍了全球范围内需要实践的更好的数据收集、管理和监控指导原则。你还将进一步了解评估策略的初步步骤如何帮助构建无偏数据集，从而为基于机器学习的预测提供新的人工智能分析和数字化转型之旅。'
- en: '[*Chapter 8*](B18681_08.xhtml#_idTextAnchor176), *Fairness in Model Optimization*,
    presents different optimization constraints and techniques that are essential
    to optimize and obtain fair ML models. The focus of this chapter is to enlighten
    you with different, new customized optimizers, unveiled by research, that can
    serve to build supervised, unsupervised, and semi-supervised fair ML models. The
    chapter, in a broader sense, prepares you with the foundational steps to create
    and define model constraints that can be used by different optimizers during the
    training process. You will also gain an understanding of how to evaluate such
    constraint-based models with proper metrics and the extra training overheads incurred
    during the optimization techniques, which will enable the models to design their
    own algorithms.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第8章*](B18681_08.xhtml#_idTextAnchor176)，*模型优化中的公平性*，介绍了优化和获得公平机器学习模型所必需的不同优化约束和技术。本章的重点是通过研究揭示的不同新定制优化器，帮助你构建监督式、无监督式和半监督式的公平机器学习模型。从更广泛的角度来看，本章为你准备了创建和定义模型约束的基础步骤，这些约束可以在训练过程中被不同的优化器使用。你还将理解如何通过适当的度量评估这些基于约束的模型，以及优化技术所产生的额外训练开销，这些都将使得模型能够设计出自己的算法。'
- en: '[*Chapter 9*](B18681_09.xhtml#_idTextAnchor198), *Model Explainability*, introduces
    you to different methods that can be used to unravel the mystery of black boxes
    in ML models. We will talk about the need to be able to explain a model prediction.
    This chapter covers various algorithms and techniques, such as SHAP and LIME,
    to add an explainability component to existing models. We will explore the libraries,
    such as DoWhy and CausalNex, to see the explainability features available to an
    end user. We will also delve into the explainability features provided by Vertex
    AI, SageMaker, and H2O.ai.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第9章*](B18681_09.xhtml#_idTextAnchor198)，*模型可解释性*，介绍了可以用来揭开机器学习模型“黑箱”之谜的不同方法。我们将讨论为什么需要能够解释模型的预测结果。本章涵盖了诸如SHAP和LIME等算法和技术，以便为现有模型增加可解释性组件。我们还将探索像DoWhy和CausalNex这样的库，来查看最终用户可用的可解释性功能。我们还将深入研究Vertex
    AI、SageMaker和H2O.ai提供的可解释性功能。'
- en: '[*Chapter 10*](B18681_10.xhtml#_idTextAnchor218), *Ethics and Model Governance*,
    emphasizes the ethical governance processes that need to be established with models
    in production, for quick identification of all risks related to the development
    and deployment of a model. This chapter also covers best practices for monitoring
    all models, including those in an inventory. You will get more insights into the
    practical nuances of risks that emerge in different phases of a model life cycle
    and how these risks can be mitigated when models reside in the inventory. Here,
    you will also understand the different risk classification procedures and how
    they can help minimize the business loss resulting from low-performance models.
    Further, you will also get detailed insights into how to establish proper governance
    in data aggregation, iterative rounds of model training, and the hyperparameter
    tuning process.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第10章*](B18681_10.xhtml#_idTextAnchor218)，*伦理与模型治理*，强调了在生产环境中需要建立的伦理治理流程，以便快速识别与模型开发和部署相关的所有风险。本章还涵盖了监控所有模型的最佳实践，包括那些处于库存中的模型。你将深入了解模型生命周期不同阶段出现的风险的实际细微差别，以及这些风险在模型存放于库存中时如何得到缓解。在这里，你还将了解不同的风险分类程序，以及它们如何帮助最小化由低性能模型导致的业务损失。此外，你还将详细了解如何在数据聚合、模型训练的迭代轮次和超参数调优过程中建立适当的治理。'
- en: '[*Chapter 11*](B18681_11.xhtml#_idTextAnchor232), *The Ethics of Model Adaptability*,
    focuses on establishing ethical governance processes for models in production,
    with the aim of quickly detecting any signs of model failure or bias in output
    predictions. By reading this chapter, you will gain a deeper understanding of
    the practical details involved in monitoring the performance of models and contextual
    model predictions, by reviewing the data constantly and benchmarking against the
    past in order to draft proper actionable short-term and long-term plans. Further,
    you will also get a detailed understanding of the conditions leading to model
    retraining and the importance of having a perfectly calibrated model. This chapter
    also highlights the trade-offs associated with fairness and model calibration.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第11章*](B18681_11.xhtml#_idTextAnchor232)，*模型适应性的伦理学*，重点讨论了为生产中的模型建立伦理治理流程，旨在快速检测模型失败或输出预测中的任何偏差迹象。通过阅读本章，您将更深入地理解监控模型性能和上下文模型预测的实际细节，方法是通过不断审查数据并与过去进行基准对比，从而制定适当的可操作的短期和长期计划。此外，您还将详细了解导致模型重训练的条件以及拥有完美校准模型的重要性。本章还突出了公平性和模型校准之间的权衡。'
- en: '[*Chapter 12*](B18681_12.xhtml#_idTextAnchor243), *Building Sustainable Enterprise-Grade
    AI Platforms*, focuses on how organizational goals, initiatives, and support from
    leadership can enable us to build sustainable ethical AI platforms. The goal of
    this chapter is to stress the importance of organizations contextualizing and
    linking ethical AI principles to reflect the local values, human rights, social
    norms, and behaviors of the community in which the solutions operate. In this
    context, the chapter highlights the impact of large-scale AI solutions on the
    environment and the right procedures that need to be incorporated for model training
    and deployment, using federated learning. This chapter further delves into important
    concepts that strongly emphasize the need to stay socially responsible, as well
    as being able to design software, models, and platforms.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第12章*](B18681_12.xhtml#_idTextAnchor243)，*构建可持续的企业级AI平台*，重点讨论了组织目标、举措以及领导层支持如何帮助我们构建可持续的伦理AI平台。本章的目标是强调组织将伦理AI原则与本地价值观、人权、社会规范和解决方案所运行社区的行为相联系的重要性。在此背景下，本章突出了大规模AI解决方案对环境的影响，以及在使用联邦学习进行模型训练和部署时需要纳入的正确程序。本章进一步深入探讨了重要概念，强烈强调了保持社会责任感的必要性，以及能够设计软件、模型和平台的重要性。'
- en: '[*Chapter 13*](B18681_13.xhtml#_idTextAnchor267), *Sustainable Model Life Cycle
    Management, Feature Stores, and Model Calibration*, explores the best practices
    that need to be followed during the model development life cycle, which can lead
    to the creation of sustainable feature stores. In this chapter, we will highlight
    the importance of implementing privacy so that reusing stores and collaboration
    among teams are maximized, without compromising security and privacy aspects.
    This chapter further provides a deep dive into different model calibration techniques,
    which are essential in building scalable sustainable ML platforms. Here, you will
    also understand how to design adaptable feature stores and how best we can incorporate
    monitoring and governance in federated learning.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第13章*](B18681_13.xhtml#_idTextAnchor267)，*可持续模型生命周期管理、特征库和模型校准*，探讨了在模型开发生命周期中需要遵循的最佳实践，这些实践有助于创建可持续的特征库。本章将强调实施隐私保护的重要性，以便在不妥协安全和隐私方面的前提下，最大化特征库的重用和团队之间的协作。本章还深入探讨了不同的模型校准技术，这些技术对于构建可扩展的可持续机器学习平台至关重要。在这里，您还将了解如何设计适应性强的特征库，以及我们如何在联邦学习中最好地融入监控和治理。'
- en: '[*Chapter 14*](B18681_14.xhtml#_idTextAnchor292), *Industry-Wide Use Cases*,
    presents a detailed overview of the different use cases across various industries.
    The primary aim of this is to inform readers coming from different industry domains
    on how ethics and compliance can be integrated into their systems, in order to
    build a fair and equitable AI system and win the confidence and trust of end users.
    You will also get a chance to apply algorithms and tools studied in previous chapters
    to different business problems. Further, you will gain an understanding of how
    ethical design patterns can be reused across different industry domains.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第14章*](B18681_14.xhtml#_idTextAnchor292)，*行业广泛的应用案例*，提供了各行业不同应用案例的详细概述。此章节的主要目的是向来自不同行业领域的读者介绍如何将伦理和合规性集成到他们的系统中，以构建公平公正的人工智能系统，并赢得最终用户的信任与信心。您还将有机会将前几章学习的算法和工具应用于不同的业务问题。此外，您将了解如何在不同的行业领域中重复使用伦理设计模式。'
- en: To get the most out of this book
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最大化利用本书
- en: Each chapter has different requirements, which have been specified in their
    respective chapters.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 每章有不同的要求，已经在各自的章节中说明。
- en: You should have basic knowledge of ML, Python, scikit-learn, PyTorch, and TensorFlow
    to better understand the concepts of this book.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该具备基本的机器学习（ML）、Python、scikit-learn、PyTorch 和 TensorFlow 知识，以更好地理解本书中的概念。
- en: Download the example code files
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Platform-and-Model-Design-for-Responsible-AI](https://github.com/PacktPublishing/Platform-and-Model-Design-for-Responsible-AI).
    If there’s an update to the code, it will be updated in the GitHub repository.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从 GitHub 上下载本书的示例代码文件，网址为 [https://github.com/PacktPublishing/Platform-and-Model-Design-for-Responsible-AI](https://github.com/PacktPublishing/Platform-and-Model-Design-for-Responsible-AI)。如果代码有更新，将会在
    GitHub 仓库中进行更新。
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在我们的丰富书籍和视频目录中提供其他代码包，您可以访问 [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)
    查看！
- en: Conventions used
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用了多种文本约定。
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “Atlas offers great flexibility in dynamically creating
    classifications, such as PII, `EXPIRES_ON`, `DATA_QUALITY`, and `SENSITIVE`, with
    support for the `expiry_date` attribute in the `EXPIRES_ON` classification.”'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '`文本中的代码`：表示文本中的代码词汇、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟 URL、用户输入和 Twitter 用户名。例如：“Atlas
    提供了在动态创建分类时的巨大灵活性，如 PII、`EXPIRES_ON`、`DATA_QUALITY` 和 `SENSITIVE`，并支持 `EXPIRES_ON`
    分类中的 `expiry_date` 属性。”'
- en: 'A block of code is set as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 所有命令行输入或输出按如下格式书写：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see on
    screen. For instance, words in menus or dialog boxes appear in **bold**. Here
    is an example: “Moreover, we can see the sequential security controls that we
    can follow to enhance our security stack by going to **RBAC** | **Policy Management**
    | **Discovery** | **Settings** | **Real-Time Controls**.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示新术语、重要单词或屏幕上的词汇。例如，菜单或对话框中的词语通常以 **粗体** 显示。以下是一个例子：“此外，我们可以通过进入 **RBAC**
    | **策略管理** | **发现** | **设置** | **实时控制** 来查看可以遵循的顺序安全控制，以增强我们的安全堆栈。”'
- en: Tips or important notes
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 提示或重要说明
- en: Appear like this.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如此显示。
- en: Get in touch
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们非常欢迎读者的反馈。
- en: '**General feedback**: If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](mailto:customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**：如果您对本书的任何部分有疑问，请通过电子邮件联系我们，地址是 [customercare@packtpub.com](mailto:customercare@packtpub.com)，并在邮件主题中注明书名。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**：尽管我们已经尽力确保内容的准确性，但错误仍然会发生。如果您在本书中发现任何错误，我们将非常感激您能向我们报告。请访问 [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    并填写表格。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](mailto:copyright@packt.com)
    with a link to the material.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果您在互联网上发现我们作品的任何非法版本，我们将非常感激您提供其位置地址或网站名称。请通过[版权@packt.com](mailto:copyright@packt.com)联系我们，并附上该材料的链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您在某个领域有专业知识，并有兴趣撰写或为书籍贡献内容，请访问[authors.packtpub.com](http://authors.packtpub.com)。'
- en: Share Your Thoughts
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分享您的想法
- en: Once you’ve read *Platform and Model Design for Responsible AI*, we’d love to
    hear your thoughts! Please [click here to go straight to the Amazon review page](https://packt.link/r/1803237074)
    for this book and share your feedback.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完*负责任的AI平台和模型设计*后，我们很想听听您的想法！请[点击此处直接访问亚马逊评论页面](https://packt.link/r/1803237074)并分享您的反馈。
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 您的评论对我们和技术社区都非常重要，并将帮助我们确保提供优质内容。
- en: Download a free PDF copy of this book
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载本书的免费PDF副本
- en: Thanks for purchasing this book!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您购买本书！
- en: Do you like to read on the go but are unable to carry your print books everywhere?
    Is your eBook purchase not compatible with the device of your choice?
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 您是否喜欢随时随地阅读，但又无法携带纸质书籍？您的电子书购买是否与您选择的设备不兼容？
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 不用担心，现在每本Packt书籍都提供无DRM的PDF版本，您可以免费获取。
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何地方、任何设备上随时阅读。直接从您最喜欢的技术书籍中搜索、复制并粘贴代码到您的应用程序中。
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 福利不仅仅到此为止，您还可以获得独家折扣、新闻简报以及每天送到您收件箱的精彩免费内容。
- en: 'Follow these simple steps to get the benefits:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下简单步骤即可享受这些福利：
- en: Scan the QR code or visit the link below
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扫描二维码或访问以下链接
- en: '![](img/B18681_QR_Free_PDF.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18681_QR_Free_PDF.jpg)'
- en: '[https://packt.link/free-ebook/9781803237077](https://packt.link/free-ebook/9781803237077)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/free-ebook/9781803237077](https://packt.link/free-ebook/9781803237077)'
- en: Submit your proof of purchase
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交您的购买证明
- en: That’s it! We’ll send your free PDF and other benefits to your email directly
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就是这样！我们将直接把您的免费PDF和其他福利发送到您的电子邮件。
- en: 'Part 1: Risk Assessment Machine Learning Frameworks in a Global Landscape'
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1部分：全球环境下的风险评估与机器学习框架
- en: This part provides a detailed introduction to the risks, threats, and challenges
    that machine learning models in production are vulnerable to. In this part, you
    will learn about different types of attacks that can be carried out by adversaries
    and the importance of protecting your models from such attacks. This part also
    covers the guidelines and standards set by different committees across the world,
    to facilitate various actions and initiatives at both a national and organizational
    level.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分详细介绍了生产中的机器学习模型所面临的风险、威胁和挑战。在本部分中，您将了解对手可以实施的各种攻击类型，以及保护模型免受此类攻击的重要性。本部分还涵盖了全球各大委员会设立的指南和标准，以促进国家和组织层面的各种行动和倡议。
- en: 'This part is made up of the following chapters:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分由以下章节组成：
- en: '[*Chapter 1*](B18681_01.xhtml#_idTextAnchor014), *Risks and Attacks on ML Models*'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第一章*](B18681_01.xhtml#_idTextAnchor014)，*机器学习模型的风险与攻击*'
- en: '[*Chapter 2*](B18681_02.xhtml#_idTextAnchor040), *The Emergence of Risk-Averse
    Methodologies and Frameworks*'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第二章*](B18681_02.xhtml#_idTextAnchor040)，*风险规避方法论和框架的出现*'
- en: '[*Chapter 3*](B18681_03.xhtml#_idTextAnchor066), *Regulations and Policies
    Surrounding Trustworthy AI*'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第三章*](B18681_03.xhtml#_idTextAnchor066)，*可信AI的监管与政策*'
