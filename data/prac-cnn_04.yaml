- en: Popular CNN Model Architectures
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 流行的 CNN 模型架构
- en: 'In this chapter, will introduce the ImageNet image database and also cover
    the architectures of the following popular CNN models:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍 ImageNet 图像数据库，并讨论以下流行 CNN 模型的架构：
- en: LeNet
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeNet
- en: AlexNet
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AlexNet
- en: VGG
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VGG
- en: GoogLeNet
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GoogLeNet
- en: ResNet
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ResNet
- en: Introduction to ImageNet
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ImageNet 介绍
- en: ImageNet is a database of over 15 million hand-labeled, high-resolution images
    in roughly 22,000 categories. This database is organized just like the WordNet
    hierarchy, where each concept is also called a **synset** (that is, **synonym
    set**). Each synset is a node in the ImageNet hierarchy. Each node has more than
    500 images.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ImageNet 是一个包含超过 1500 万张手工标注的高分辨率图像的数据库，涵盖大约 22,000 个类别。该数据库的组织结构类似于 WordNet
    层次结构，其中每个概念也被称为 **同义集**（即 **synset**）。每个同义集都是 ImageNet 层次结构中的一个节点。每个节点包含超过 500
    张图像。
- en: 'The **ImageNet Large Scale Visual Recognition Challenge** (**ILSVRC**) was
    founded in 2010 to improve state-of-the-art technology for object detection and
    image classification on a large scale:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**ImageNet 大规模视觉识别挑战赛** (**ILSVRC**) 于2010年成立，旨在大规模提升物体检测和图像分类的最先进技术：'
- en: '![](img/20756743-ac07-44cb-a804-05763571d81d.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](img/20756743-ac07-44cb-a804-05763571d81d.png)'
- en: Following this overview of ImageNet, we will now take a look at various CNN
    model architectures.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在概述了 ImageNet 之后，我们将进一步介绍各种 CNN 模型架构。
- en: LeNet
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LeNet
- en: 'In 2010, a challenge from ImageNet (known as **ILSVRC 2010**) came out with
    a CNN architecture, LeNet 5, built by Yann Lecun. This network takes a 32 x 32
    image as input, which goes to the convolution layers (**C1**) and then to the
    subsampling layer (**S2**). Today, the subsampling layer is replaced by a pooling
    layer. Then, there is another sequence of convolution layers (**C3**) followed
    by a pooling (that is, subsampling) layer (**S4**). Finally, there are three fully
    connected layers, including the **OUTPUT** layer at the end. This network was
    used for zip code recognition in post offices. Since then, every year various
    CNN architectures were introduced with the help of this competition:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 2010年，ImageNet 发起了一项挑战（称为 **ILSVRC 2010**），该挑战使用了 Yann Lecun 构建的 CNN 架构 LeNet
    5。该网络以 32 x 32 的图像作为输入，图像经过卷积层（**C1**），然后进入子采样层（**S2**）。今天，子采样层已被池化层替代。接着，又有一系列卷积层（**C3**），然后是一个池化（即子采样）层（**S4**）。最后，网络有三个全连接层，其中包括最后的
    **OUTPUT** 层。该网络曾用于邮局的邮政编码识别。从那时起，每年都有不同的 CNN 架构通过这一竞赛得以推出：
- en: '![](img/cb2b54bf-cb43-4e1f-897c-862f85f06423.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cb2b54bf-cb43-4e1f-897c-862f85f06423.png)'
- en: LeNet 5 – CNN architecture from Yann Lecun's article in 1998
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: LeNet 5 – 来自 Yann Lecun 1998 年文章的 CNN 架构
- en: 'Therefore, we can conclude the following points:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以得出以下几点结论：
- en: The input to this network is a grayscale 32 x 32 image
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该网络的输入为一张灰度 32 x 32 的图像
- en: The architecture implemented is a CONV layer, followed by POOL and a fully connected
    layer
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现的架构是一个 CONV 层，接着是 POOL 层和一个全连接层
- en: CONV filters are 5 x 5, applied at a stride of 1
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CONV 滤波器为 5 x 5，以步幅为 1 应用
- en: AlexNet architecture
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AlexNet 架构
- en: The first breakthrough in the architecture of CNN came in the year 2012\. This
    award-winning CNN architecture is called **AlexNet**. It was developed at the
    University of Toronto by Alex Krizhevsky and his professor, Jeffry Hinton.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 架构的第一个突破发生在2012年。这一获奖的 CNN 架构被称为 **AlexNet**，由多伦多大学的 Alex Krizhevsky 和他的教授
    Jeffry Hinton 开发。
- en: 'In the first run, a ReLU activation function and a dropout of 0.5 were used
    in this network to fight overfitting. As we can see in the following image, there
    is a normalization layer used in the architecture, but this is not used in practice
    anymore as it used heavy data augmentation. AlexNet is still used today even though
    there are more accurate networks available, because of its relative simple structure
    and small depth. It is widely used in computer vision:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次运行时，该网络使用了 ReLU 激活函数和 0.5 的 dropout 来抵抗过拟合。如以下图所示，架构中使用了一个归一化层，但由于使用了大量的数据增强技术，这在实际应用中已不再使用。尽管如今已有更为精确的网络，但由于其相对简单的结构和较小的深度，AlexNet
    仍然在今天被广泛使用，尤其是在计算机视觉领域：
- en: '![](img/dd1ba84c-d1ae-4f6f-87b6-0e641600eab4.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dd1ba84c-d1ae-4f6f-87b6-0e641600eab4.png)'
- en: 'AlexNet is trained on the ImageNet database using two separate GPUs, possibly
    due to processing limitations with inter-GPU connections at the time, as shown
    in the following figure:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet 使用两个独立的 GPU 在 ImageNet 数据库上进行训练，可能是由于当时 GPU 间连接的处理限制，正如下图所示：
- en: '![](img/1100c791-9be1-4e7b-8039-3172ad50606d.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1100c791-9be1-4e7b-8039-3172ad50606d.png)'
- en: Traffic sign classifiers using AlexNet
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 AlexNet 的交通标志分类器
- en: In this example, we will use transfer learning for feature extraction and a
    German traffic sign dataset to develop a classifier. Used here is an AlexNet implementation
    byMichael Guerzhoy and Davi Frossard, and AlexNet weights are from the Berkeley
    vision and Learning center. The complete code and dataset can be downloaded from here.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用迁移学习进行特征提取，并使用一个德国交通标志数据集来开发分类器。这里使用的是 Michael Guerzhoy 和 Davi Frossard
    实现的 AlexNet，AlexNet 的权重来自伯克利视觉与学习中心。完整的代码和数据集可以从 [这里](https://example.org)下载。
- en: 'AlexNet expects a 227 x 227 x 3 pixel image, whereas the traffic sign images
    are 32 x 32 x 3 pixels. In order to feed the traffic sign images into AlexNet,
    we''ll need to resize the images to the dimensions that AlexNet expects, that
    is, 227 x 227 x 3:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet 期望输入的是227 x 227 x 3像素的图像，而交通标志图像的尺寸是32 x 32 x 3像素。为了将交通标志图像输入到 AlexNet
    中，我们需要将图像调整为 AlexNet 所期望的尺寸，即 227 x 227 x 3：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can do so with the help of the `tf.image.resize_images` method by TensorFlow.
    Another issue here is that AlexNet was trained on the ImageNet dataset, which
    has 1,000 classes of images. So, we will replace this layer with a 43-neuron classification
    layer. To do this, figure out the size of the output from the last fully connected
    layer; since this is a fully connected layer and so is a 2D shape, the last element
    will be the size of the output. `fc7.get_shape().as_list()[-1]` does the trick;
    combine this with the number of classes for the traffic sign dataset to get the
    shape of the final fully connected layer: `shape = (fc7.get_shape().as_list()[-1],
    43)`. The rest of the code is just the standard way to define a fully connected
    layer in TensorFlow. Finally, calculate the probabilities with `softmax`:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以借助 TensorFlow 的 `tf.image.resize_images` 方法来实现。另一个问题是，AlexNet 是在 ImageNet
    数据集上训练的，该数据集有1,000个类别的图像。因此，我们将用一个43神经元的分类层替换这一层。为此，首先计算最后一个全连接层输出的大小；由于这是一个全连接层，因此它的输出是一个2D形状，最后一个元素就是输出的大小。`fc7.get_shape().as_list()[-1]`
    完成了这个任务；然后将其与交通标志数据集的类别数结合，得到最终全连接层的形状：`shape = (fc7.get_shape().as_list()[-1],
    43)`。其余代码只是 TensorFlow 中定义全连接层的标准方式。最后，通过 `softmax` 计算概率：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: VGGNet architecture
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VGGNet 架构
- en: 'The runner-up in the 2014 ImageNet challenge was VGGNet from the visual geometric
    group at Oxford University. This convolutional neural network is a simple and
    elegant architecture with a 7.3% error rate. It has two versions: VGG16 and VGG19.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 2014年ImageNet挑战赛的亚军是来自牛津大学视觉几何小组的 VGGNet。这个卷积神经网络架构简单而优雅，错误率为7.3%。它有两个版本：VGG16
    和 VGG19。
- en: VGG16 is a 16-layer neural network, not counting the max pooling layer and the
    softmax layer. Hence, it is known as VGG16\. VGG19 consists of 19 layers. A pre-trained
    model is available in Keras for both Theano and TensorFlow backends.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: VGG16 是一个16层神经网络，不包括最大池化层和softmax层。因此，它被称为 VGG16。VGG19 由19层组成。Keras中有一个预训练模型，适用于
    Theano 和 TensorFlow 后端。
- en: 'The key design consideration here is depth. Increases in the depth of the network
    were achieved by adding more convolution layers, and it was done due to the small
    3 x 3 convolution filters in all the layers. The default input size of an image
    for this model is 224 x 224 x 3\. The image is passed through a stack of convolution
    layers with a stride of 1 pixel and padding of 1\. It uses 3 x 3 convolution throughout
    the network. Max pooling is done over a 2 x 2 pixel window with a stride of 2,
    then another stack of convolution layers followed by three fully connected layers.
    The first two fully connected layers have 4,096 neurons each, and the third fully
    connected layers are responsible for classification with 1,000 neurons. The final
    layer is a softmax layer. VGG16 uses a much smaller 3 x 3 convolution window,
    compared to AlexNet''s much larger 11 x 11 convolution window. All hidden layers
    are built with the ReLU activation function. The architecture looks like this:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键设计考虑因素是网络的深度。通过增加更多的卷积层来增加网络的深度，这样做是因为所有层中的卷积滤波器大小都为3 x 3。该模型的默认输入图像大小为224
    x 224 x 3。图像通过一系列卷积层进行处理，步幅为1个像素，填充为1。整个网络使用3 x 3卷积。最大池化在一个2 x 2像素窗口中进行，步幅为2，然后是另一组卷积层，接着是三个全连接层。前两个全连接层每个有4,096个神经元，第三个全连接层负责分类，包含1,000个神经元。最后一层是softmax层。与
    AlexNet 的11 x 11卷积窗口相比，VGG16 使用了更小的3 x 3卷积窗口。所有隐藏层都使用 ReLU 激活函数。网络架构如下所示：
- en: '![](img/0a1c03f6-5c37-4e49-9b3d-ef56e005b84d.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0a1c03f6-5c37-4e49-9b3d-ef56e005b84d.png)'
- en: VGG16 network architecture
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: VGG16 网络架构
- en: Due to the small 3 x 3 convolution filter, the depth of VGGNet is increased.
    The number of parameters in this network is approximately 140 million, mostly
    from the first fully connected layer. In latter-day architectures, fully connected
    layers of VGGNet are replaced with **global average pooling** (**GAP**) layers
    in order to minimize the number of parameters.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于小型的 3 x 3 卷积滤波器，VGGNet 的深度得以增加。该网络的参数数量大约为 1.4 亿，主要来自于第一个全连接层。在后来的架构中，VGGNet
    的全连接层被**全局平均池化**（**GAP**）层替代，以减少参数数量。
- en: Another observation is that the number of filters increases as the image size
    decreases.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个观察是，随着图像尺寸的减小，滤波器的数量会增加。
- en: VGG16 image classification code example
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VGG16 图像分类代码示例
- en: 'The Keras Applications module has pre-trained neural network models, along
    with its pre-trained weights trained on ImageNet. These models can be used directly for
    prediction, feature extraction, and fine-tuning:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 应用模块包含了预训练的神经网络模型，以及基于 ImageNet 训练的预训练权重。这些模型可以直接用于预测、特征提取和微调：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The first time it executes the preceding script, Keras will automatically download
    and cache the architecture weights to disk in the `~/.keras/models` directory.
    Subsequent runs will be faster.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当第一次执行上述脚本时，Keras 会**自动**下载并将架构权重缓存到磁盘中的`~/.keras/models`目录。随后的运行会更快。
- en: GoogLeNet architecture
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GoogLeNet 架构
- en: In 2014, ILSVRC, Google published its own network known as **GoogLeNet**. Its
    performance is a little better than VGGNet; GoogLeNet's performance is 6.7% compared
    to VGGNet's performance of 7.3%. The main attractive feature of GoogLeNet is that
    it runs very fast due to the introduction of a new concept called **inception
    module**, thus reducing the number of parameters to only 5 million; that's 12
    times less than AlexNet. It has lower memory use and lower power use too.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 2014 年，在 ILSVRC 比赛中，Google 发布了自己的网络，名为**GoogLeNet**。它的表现比 VGGNet 略好；GoogLeNet
    的表现为 6.7%，而 VGGNet 的表现为 7.3%。GoogLeNet 的主要吸引力在于它运行非常快速，因为引入了一种叫做**inception 模块**的新概念，从而将参数数量减少到仅为
    500 万；这是 AlexNet 的 12 倍还少。它的内存使用和功耗也更低。
- en: It has 22 layers, so it is a very deep network. Adding more layers increases
    the number of parameters and it is likely that the network overfits. There will
    be more computation, because a linear increase in filters results in a quadratic
    increase in computation. So, the designers use the inception module and GAP. The
    fully connected layer at the end of the network is replaced with a GAP layer because
    fully connected layers are generally prone to overfitting. GAP has no parameters
    to learn or optimize.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 它有 22 层，因此是一个非常深的网络。添加更多层会增加参数数量，并且可能导致网络过拟合。计算量也会增加，因为滤波器数量的线性增长会导致计算量的平方增长。因此，设计者使用了
    inception 模块和 GAP。网络末端的全连接层被 GAP 层替代，因为全连接层通常容易导致过拟合。GAP 没有需要学习或优化的参数。
- en: Architecture insights
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 架构洞察
- en: Instead of choosing a particular filter size as in the previous architectures,
    the GoogLeNet designers applied all the three filters of sizes 1 x 1, 3 x 3, and
    5 x 5 on the same patch, with a 3 x 3 max pooling and concatenation into a single
    output vector.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 与以前的架构选择特定滤波器大小不同，GoogLeNet 设计者将 1 x 1、3 x 3 和 5 x 5 三种不同大小的滤波器应用到同一图像块上，再通过
    3 x 3 最大池化和连接操作将它们合并为一个输出向量。
- en: The use of 1 x 1 convolutions decreases the dimensions wherever the computation
    is increased by the expensive 3 x 3 and 5 x 5 convolutions. 1 x 1 convolutions
    with the ReLU activation function are used before the expensive 3 x 3 and 5 x
    5 convolutions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 1 x 1 卷积可以减少在计算量增加的地方，替代了昂贵的 3 x 3 和 5 x 5 卷积。在昂贵的 3 x 3 和 5 x 5 卷积之前，使用了带有
    ReLU 激活函数的 1 x 1 卷积。
- en: 'In GoogLeNet, inception modules are stacked one over the other. This stacking
    allows us to modify each module without affecting the later layers. For example,
    you can increase or decrease the width of any layer:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GoogLeNet 中，inception 模块一个接一个地堆叠。这种堆叠方式使得我们可以修改每个模块，而不会影响后面的层。例如，你可以增加或减少任何层的宽度：
- en: '![](img/2636db13-c7fb-49c9-b20d-544287eacf55.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2636db13-c7fb-49c9-b20d-544287eacf55.png)'
- en: GoogLeNet architecture
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: GoogLeNet 架构
- en: Deep networks also suffer from the fear of what is known as the **vanishing
    gradient** problem during backpropagation. This is avoided by adding auxiliary
    classifiers to intermediate layers. Also, during training, the intermediate loss
    was added to the total loss with a discounted factor of 0.3.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 深度网络也面临着所谓的**梯度消失**问题，尤其是在反向传播时。通过向中间层添加辅助分类器，可以避免这一问题。此外，在训练过程中，将中间损失与折扣因子0.3相加，纳入总损失。
- en: Since fully connected layers are prone to overfitting, it is replaced with a
    GAP layer. Average pooling does not exclude use of dropout, a regularization method
    for overcoming overfitting in deep neural networks. GoogLeNet added a linear layer
    after 60, a GAP layer to help others swipe for their own classifier using transfer
    learning techniques.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 由于全连接层容易发生过拟合，因此被替换为GAP层。平均池化并不排除使用dropout，这是一种用于克服深度神经网络中过拟合的正则化方法。GoogLeNet在60层后添加了一个线性层，使用GAP层帮助其他人通过迁移学习技术为自己的分类器进行优化。
- en: Inception module
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Inception模块
- en: 'The following image is an example of an inception module:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了一个Inception模块的例子：
- en: '![](img/ac511227-54cd-4a2a-a9ef-077ec291ec0f.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ac511227-54cd-4a2a-a9ef-077ec291ec0f.png)'
- en: ResNet architecture
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ResNet架构
- en: 'After a certain depth, adding additional layers to feed-forward convNets results
    in a higher training error and higher validation error. When adding layers, performance
    increases only up to a certain depth, and then it rapidly decreases. In the **ResNet**
    (**Residual Network**) paper, the authors argued that this underfitting is unlikely
    due to the vanishing gradient problem, because this happens even when using the
    batch normalization technique. Therefore, they have added a new concept called
    **residual block**. The ResNet team added connections that can skip layers:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在达到一定深度后，向前馈卷积网络添加额外的层会导致训练误差和验证误差增加。增加层数时，性能只会在一定深度内提升，然后会迅速下降。在**ResNet**（**残差网络**）论文中，作者认为这种欠拟合不太可能是由于梯度消失问题引起的，因为即使使用批量归一化技术，这种情况仍然会发生。因此，他们提出了一个新的概念——**残差块**。ResNet团队添加了可以跳过层的连接：
- en: ResNet uses standard convNet and adds connections that skip a few convolution
    layers at a time. Each bypass gives a residual block.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ResNet使用标准卷积神经网络，并添加了可以一次跳过几个卷积层的连接。每个跳跃都形成一个残差块。
- en: '![](img/c7c96246-7f86-4e6c-89d0-22a25e655493.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c7c96246-7f86-4e6c-89d0-22a25e655493.png)'
- en: Residual block
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 残差块
- en: In the 2015 ImageNet ILSVRC competition, the winner was ResNet from Microsoft,
    with an error rate of 3.57%. ResNet is a kind of VGG in the sense that the same
    structure is repeated again and again to make the network deeper. Unlike VGGNet,
    it has different depth variations, such as 34, 50, 101, and 152 layers. It has
    a whopping 152 layers compared to AlexNet 8, VGGNet's 19 layers, and GoogLeNet's
    22 layers. The ResNet architecture is a stack of residual blocks. The main idea
    is to skip layers by adding connections to the neural network. Every residual
    block has 3 x 3 convolution layers. After the last conv layer, a GAP layer is
    added. There is only one fully connected layer to classify 1,000 classes. It has
    different depth varieties, such as 34, 50, 101, or 152 layers for the ImageNet
    dataset. For a deeper network, say more than 50 layers, it uses the **bottleneck** features
    concept to improve efficiency. No dropout is used in this network.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在2015年ImageNet ILSVRC竞赛中，微软的ResNet以3.57%的错误率赢得了冠军。ResNet在某种意义上类似于VGG，因为它的结构会不断重复，从而使网络变得更深。与VGGNet不同，ResNet有不同的深度变种，例如34层、50层、101层和152层。相比于AlexNet的8层、VGGNet的19层和GoogLeNet的22层，它有着惊人的152层。ResNet架构是由残差块堆叠而成。其主要思想是通过向神经网络添加连接来跳过某些层。每个残差块包含3x3的卷积层。最后的卷积层后面添加了一个GAP层。只有一个全连接层用于分类1000个类别。它有不同的深度变种，例如34层、50层、101层或152层，用于ImageNet数据集。对于更深的网络，比如超过50层的网络，使用了**瓶颈**特征概念来提高效率。这个网络没有使用dropout。
- en: 'Other network architectures to be aware of include:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其他需要注意的网络架构包括：
- en: Network in Network
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络中的网络
- en: Beyond ResNet
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超越ResNet
- en: FractalNet, an ultra-deep neural network without residuals
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FractalNet，一个没有残差的超深神经网络
- en: Summary
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the different CNN architectures. These models
    are pre-trained existing models and differ in network architecture. Each of these
    networks is designed to solve a problem specific to its architecture. So, here
    we described their architectural differences.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们学习了不同的CNN架构。这些模型是预训练的现有模型，在网络架构上有所不同。每个网络都是为了针对其架构特定的问题而设计的。因此，我们在此描述了它们的架构差异。
- en: We also understood how our own CNN architecture, as defined in the previous
    chapter, differs from these advanced ones.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还理解了我们自己定义的 CNN 架构（在上一章中提到的）与这些先进架构之间的区别。
- en: In the next chapter, we will learn how these pre-trained models can be used
    for transfer learning.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习如何将这些预训练模型用于迁移学习。
