- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: RAG for Video Stock Production with Pinecone and OpenAI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Pinecone 和 OpenAI 进行视频库存生产的 RAG
- en: Human creativity goes beyond the range of well-known patterns due to our unique
    ability to break habits and invent new ways of doing anything, anywhere. Conversely,
    Generative AI relies on our well-known established patterns across an increasing
    number of fields without really “creating” but rather replicating our habits.
    In this chapter, therefore, when we use the term “create” as a practical term,
    we only mean “generate.” Generative AI, with its efficiency in automating tasks,
    will continue its expansion until it finds ways of replicating any human task
    it can. We must, therefore, learn how these automated systems work to use them
    for the best in our projects. Think of this chapter as a journey into the architecture
    of RAG in the cutting-edge hybrid human and AI agent era we are living in. We
    will assume the role of a start-up aiming to build an AI-driven downloadable stock
    of online videos. To achieve this, we will establish a team of AI agents that
    will work together to create a stock of commented and labeled videos.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们独特的打破习惯和发明任何事物的新方法的能力，人类的创造力超越了已知模式的范围。相反，生成式 AI 依赖于我们在越来越多的领域内已知的建立模式，而没有真正“创造”而是复制我们的习惯。因此，在本章中，当我们使用“创造”这个词作为实用术语时，我们仅意味着“生成”。生成式
    AI，凭借其在自动化任务中的效率，将继续其扩张，直到找到复制任何它能执行的人类任务的方法。因此，我们必须学习这些自动化系统的工作原理，以便在我们的项目中发挥它们的最大作用。将本章视为一次探索我们生活在这个尖端混合人类和
    AI 代理时代的 RAG 架构的旅程。我们将扮演一个旨在构建由 AI 驱动的可下载在线视频库存的初创企业的角色。为了实现这一目标，我们将建立一个 AI 代理团队，他们将共同努力创建一个带有评论和标签的视频库存。
- en: 'Our journey begins with the Generator agent in *Pipeline 1: The Generator and
    the Commentator*. The Generator agent creates world simulations using Sora, an
    OpenAI text-to-video model. You’ll see how the *inVideo* AI application, powered
    by Sora, engages in “ideation,” transforming an idea into a video. The Commentator
    agent then splits the AI-generated videos into frames and generates technical
    comments with an OpenAI vision model. Next, in *Pipeline 2: The Vector Store Administrator,*
    we will continue our journey and build the Vector Store Administrator that manages
    Pinecone. The Vector Store Administrator will embed the technical video comments
    generated by the Commentator, upsert the vectorized comments, and query the Pinecone
    vector store to verify that the system is functional. Finally, we will build the
    Video Expert that processes user inputs, queries the vector store, and retrieves
    the relevant video frames. Finally, in *Pipeline 3: The Video Expert*, the Video
    Expert agent will augment user inputs with the raw output of the query and activate
    its expert OpenAI GPT-4o model, which will analyze the comment, detect imperfections,
    reformulate it more efficiently, and provide a label for the video.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的旅程从“管道 1：生成器和评论员”中的生成器代理开始。生成器代理使用 Sora，一个 OpenAI 的文本到视频模型，创建世界模拟。您将看到由 Sora
    驱动的 *inVideo* 人工智能应用如何参与“创意”，将一个想法转化为视频。然后，评论员代理将 AI 生成的视频分割成帧，并使用 OpenAI 的视觉模型生成技术评论。接下来，在“管道
    2：向量存储管理员”中，我们将继续我们的旅程，构建管理 Pinecone 的向量存储管理员。向量存储管理员将嵌入评论员生成的技术视频评论，更新向量化的评论，并查询
    Pinecone 向量存储以验证系统是否正常工作。最后，我们将构建视频专家，该专家处理用户输入，查询向量存储，并检索相关的视频帧。最后，在“管道 3：视频专家”中，视频专家代理将使用查询的原始输出增强用户输入，并激活其专家
    OpenAI GPT-4o 模型，该模型将分析评论，检测不完美之处，更有效地重新表述，并为视频提供标签。
- en: By the end of the chapter, you will know how to automatically generate a stock
    of short videos by automating the process of going from raw footage to videos
    with descriptions and labels. You’ll be able to offer a service where users can
    simply type a few words and obtain a video with a custom, real-time description
    and label.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将了解如何通过自动化从原始素材到带有描述和标签的视频的过程来自动生成短视频库存。您将能够提供一项服务，用户只需输入几个词，就能获得一个具有定制、实时描述和标签的视频。
- en: 'Summing that up, this chapter covers the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本章涵盖了以下主题：
- en: Designing Generative AI videos and comments
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计生成式 AI 视频和评论
- en: Splitting videos into frames for OpenAI’s vision analysis models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将视频分割成帧以供 OpenAI 的视觉分析模型使用
- en: Embedding the videos and upserting the vectors to a Pinecone index
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将视频嵌入并更新向量到 Pinecone 索引
- en: Querying the vector store
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询向量存储
- en: Improving and correcting the video comments with OpenAI GPT-4o
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OpenAI GPT-4o 改进和纠正视频评论
- en: Automatically labeling raw videos
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动标记原始视频
- en: Displaying the full result of the raw video process with a commented and labeled
    video
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示原始视频处理的全结果，包括评论和标记的视频
- en: Evaluating outputs and implementing metric calculations
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估输出并实施指标计算
- en: Let’s begin by defining the architecture of RAG for video production.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义RAG视频生产的架构开始。
- en: The architecture of RAG for video production
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视频生产的RAG架构
- en: Automating the process of real-world video generation, commenting, and labeling
    is extremely relevant in various industries, such as media, marketing, entertainment,
    and education. Businesses and creators are continuously seeking efficient ways
    to produce and manage content that can scale with growing demand. In this chapter,
    you will acquire practical skills that can be directly applied to meet these needs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化现实世界视频生成、评论和标记的过程在媒体、营销、娱乐和教育等各个行业中极为相关。企业和创作者持续寻求高效的方法来生产和管理工作内容，以满足不断增长的需求。在本章中，你将获得可以直接应用于满足这些需求的实际技能。
- en: 'The goal of our RAG video production use case in this chapter is to process
    AI-generated videos using AI agents to create a video stock of labeled videos
    to identify them. The system will also dynamically generate custom descriptions
    by pinpointing AI-generated technical comments on specific frames within the videos
    that fit the user input. *Figure 10.1* illustrates the AI-agent team that processes
    RAG for video production:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们RAG视频生产用例的目标是使用AI代理处理AI生成的视频，创建一个标记视频库以识别它们。系统还将通过定位视频中的特定帧上的AI生成技术评论来动态生成自定义描述。*图10.1*展示了处理视频生产的RAG的AI代理团队：
- en: '![A diagram of a video production process  Description automatically generated](img/B31169_10_01.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![一个视频生产流程图，描述自动生成](img/B31169_10_01.png)'
- en: 'Figure 10.1: From raw videos to labeled and commented videos'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1：从原始视频到标记和评论的视频
- en: 'We will implement AI agents for our RAG video production pipeline that will:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为我们的RAG视频生产流程实现AI代理，它们将：
- en: Generate raw videos automatically and download them
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动生成原始视频并下载它们
- en: Split the videos into frames
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将视频分割成帧
- en: Analyze a sample of frames
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析一组帧
- en: Activate an OpenAI LLM model to generate technical comments
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激活一个OpenAI LLM模型以生成技术评论
- en: Save the technical comments with a unique index, the comment itself, the frame
    number analyzed, and the video file name
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用唯一的索引、评论本身、分析的帧号和视频文件名保存技术评论
- en: Upsert the data in a Pinecone index vector store
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Pinecone索引向量存储中更新数据
- en: Query the Pinecone vector store with user inputs
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用用户输入查询Pinecone向量存储
- en: Retrieve the specific frame within a video that is most similar to its technical
    comment
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索与视频技术评论最相似的特定帧
- en: Augment the user input with the technical comment of the retrieved frame
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将检索到的帧的技术评论添加到用户输入中
- en: Ask the OpenAI LLM to analyze the logic of the technical comment that may contain
    contradictions and imperfections detected in the video and then produce a dynamic,
    well-tailored description of the video with the frame number and the video file
    name
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要求OpenAI LLM分析可能包含在视频中检测到的矛盾和不完善的技术评论的逻辑，然后根据帧号和视频文件名生成动态、定制的视频描述
- en: Display the selected video
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示选定的视频
- en: Evaluate the outputs and apply metric calculations
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估输出并应用指标计算
- en: 'We will thus go from raw videos to labeled videos with tailored descriptions
    based on the user input. For example, we will be able to ask precise questions
    such as the following:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将从原始视频过渡到标记视频，并基于用户输入提供定制描述。例如，我们能够提出如下精确的问题：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This means that the system will be able to find a frame (image) within the
    initially unlabeled video, select the video, display it, and generate a tailored
    comment dynamically. To attain our goal, we will implement AI agents in three
    pipelines, as illustrated in the following figure:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着系统将能够在最初未标记的视频中找到一个帧（图像），选择视频，显示它，并动态生成定制的评论。为了达到我们的目标，我们将在以下图中所示的三条管道中实现AI代理：
- en: '![A diagram of a process  Description automatically generated](img/B31169_10_02.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![一个流程图，描述自动生成](img/B31169_10_02.png)'
- en: 'Figure 10.2: The RAG for Video Production Ecosystem with Generative AI agents'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2：具有生成式AI代理的视频生产生态系统中的RAG
- en: 'Now, what you see in the figure above is:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你上面看到的图示是：
- en: '**Pipeline 1**: The **Generator** and the **Commentator**'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道1**：**生成器**和**评论者**'
- en: The **Generator** produces AI-generated videos with OpenAI Sora. The **Commentator**
    splits the videos into frames that are commented on by one of OpenAI’s vision
    models. The **Commentator** agent then saves the comments.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成器**使用 OpenAI Sora 生成 AI 视频的生成器。**评论员**将视频分割成由 OpenAI 的某个视觉模型注释的帧。然后，**评论员**代理保存评论。'
- en: '**Pipeline 2**: **The Vector Store Administrator**'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pipeline 2**: **向量存储管理员**'
- en: This pipeline will embed and upsert the comments made by *Pipeline 1* to a Pinecone
    index.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 此流程将嵌入并更新由 *Pipeline 1* 制作的评论到 Pinecone 索引中。
- en: '**Pipeline 3**: **The Video Expert**'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pipeline 3**: **视频专家**'
- en: This pipeline will query the Pinecone vector store based on user input. The
    query will return the most similar frame within a video, augment the input with
    the technical comment, and ask OpenAI GPT-4o to find logic imperfections in the
    video, point them out, and then produce a tailored comment of the video for the
    user and a label. This section also contains evaluation functions (the Evaluator)
    and metric calculations.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此流程将根据用户输入查询 Pinecone 向量存储。查询将返回视频中最相似的帧，用技术评论增强输入，并让 OpenAI GPT-4o 寻找视频中的逻辑缺陷，指出它们，然后为用户生成定制的视频评论和标签。本节还包含评估函数（评估器）和指标计算。
- en: Time measurement functions are encapsulated in several of the key functions
    of the preceding ecosystem.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 时间测量函数封装在前面生态系统的一些关键函数中。
- en: The RAG video production system we will build allows indefinite scaling by processing
    one video at a time, using only a CPU and little memory, while leveraging Pinecone’s
    storage capacity. This effectively demonstrates the concept of automated video
    production, but implementing this production system in a real-life project requires
    hard work. However, the technology is there, and the future of video production
    is undergoing a historical evolution. Let’s dive into the code, beginning with
    the environment.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将构建的 RAG 视频制作系统可以通过一次处理一个视频来实现无限扩展，仅使用 CPU 和少量内存，同时利用 Pinecone 的存储能力。这有效地展示了自动化视频制作的概念，但在实际项目中实施此生产系统需要大量工作。然而，技术是存在的，视频制作的未来正在经历历史性的演变。让我们开始编写代码，从环境开始。 '
- en: The environment of the video production ecosystem
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视频制作生态系统的环境
- en: 'The `Chapter10` directory on GitHub contains the environment for all four notebooks
    in this chapter:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub 上的 `Chapter10` 目录包含本章中所有四个笔记本的环境：
- en: '`Videos_dataset_visualization.ipynb`'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Videos_dataset_visualization.ipynb`'
- en: '`Pipeline_1_The_Generator_and_the_Commentator.ipynb`'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pipeline_1_The_Generator_and_the_Commentator.ipynb`'
- en: '`Pipeline_2_The_Vector_Store_Administrator.ipynb`'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pipeline_2_The_Vector_Store_Administrator.ipynb`'
- en: '`Pipeline_3_The_Video_Expert.ipynb`'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pipeline_3_The_Video_Expert.ipynb`'
- en: 'Each notebook includes an *Installing the environment* section, including a
    set of the following sections that are identical across all notebooks:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 每个笔记本都包含一个 *安装环境* 部分，包括以下所有笔记本中相同的以下部分：
- en: '*Importing modules and libraries*'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*导入模块和库*'
- en: '*GitHub*'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*GitHub*'
- en: '*Video download and display functions*'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*视频下载和显示功能*'
- en: '*OpenAI*'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*OpenAI*'
- en: '*Pinecone*'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Pinecone*'
- en: This chapter aims to establish a common pre-production installation policy that
    will focus on the pipelines’ content once we dive into the RAG for video production
    code. This policy is limited to the scenario described in this chapter and will
    vary depending on the requirements of each real-life production environment.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 本章旨在建立一种通用的预生产安装策略，一旦我们深入研究视频生产的 RAG 代码，我们将专注于流程的内容。此策略仅限于本章中描述的场景，并且将根据每个实际生产环境的要求而变化。
- en: The notebooks in this chapter only require a CPU, limited memory, and limited
    disk space. As such, the whole process can be streamlined indefinitely one video
    at a time in an optimized, scalable environment.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的笔记本仅需要 CPU、有限的内存和有限的磁盘空间。因此，整个流程可以在优化的、可扩展的环境中一次处理一个视频，无限期地流线化。
- en: Let’s begin by importing the modules and libraries we need for our project.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先导入我们项目所需的模块和库。
- en: Importing modules and libraries
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 导入模块和库
- en: 'The goal is to prepare a pre-production global environment common to all the
    notebooks. As such, the modules and libraries are present in all four notebooks
    regardless of whether they are used or not in a specific program:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是准备一个预生产环境，该环境对所有笔记本都是通用的。因此，无论是否在特定程序中使用，模块和库都存在于所有四个笔记本中：
- en: '[PRE1]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Each of the four notebooks contains these modules and libraries, as shown in
    the following table:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 每个笔记本都包含以下模块和库，如下表所示：
- en: '| **Code** | **Comment** |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| **代码** | **注释** |'
- en: '| `from IPython.display import HTML` | To display videos |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| `from IPython.display import HTML` | 用于显示视频 |'
- en: '| `import base64` | To encode videos as `base64` |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| `import base64` | 用于将视频编码为 `base64` |'
- en: '| `from base64 import b64encode` | To encode videos as `base64` |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| `from base64 import b64encode` | 用于将视频编码为 `base64` |'
- en: '| `import os` | To interact with the operating system |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| `import os` | 用于与操作系统交互 |'
- en: '| `import subprocess` | To run commands |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| `import subprocess` | 用于运行命令 |'
- en: '| `import time` | To measure execution time |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| `import time` | 用于测量执行时间 |'
- en: '| `import csv` | To save comments |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| `import csv` | 用于保存评论 |'
- en: '| `import uuid` | To generate unique IDs |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| `import uuid` | 用于生成唯一ID |'
- en: '| `import cv2` | To split videos (open source computer vision library) |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| `import cv2` | 用于分割视频（开源计算机视觉库）|'
- en: '| `from PIL import Image` | To display videos |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| `from PIL import Image` | 用于显示视频 |'
- en: '| `import pandas as pd` | To display comments |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| `import pandas as pd` | 用于显示评论 |'
- en: '| `import numpy as np` | To use Numerical Python |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| `import numpy as np` | 用于使用数值Python |'
- en: '| `from io import BytesIO` | For a binary stream of data in memory |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| `from io import BytesIO` | 用于内存中的二进制数据流 |'
- en: 'Table 10.1: Modules and libraries for our video production system'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 表10.1：我们的视频制作系统所需的模块和库
- en: The `Code` column contains the module or library name, while the `Comment` column
    provides a brief description of their usage. Let’s move on to GitHub commands.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`Code` 列包含模块或库的名称，而 `Comment` 列提供了它们用法的简要描述。让我们继续到GitHub命令。'
- en: GitHub
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GitHub
- en: '`download(directory, filename)` is present in all four notebooks. The main
    function of `download(directory, filename)` is to download the files we need from
    the book’s GitHub repository:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`download(directory, filename)` 函数存在于所有四个笔记本中。`download(directory, filename)`
    函数的主要功能是从书籍的GitHub仓库下载我们需要的文件：'
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding function takes two arguments:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的函数接受两个参数：
- en: '`directory`, which is the GitHub directory that the file we want to download
    is located in'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`directory`，这是我们想要下载的文件所在的GitHub目录'
- en: '`filename`, which is the name of the file we want to download'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filename`，这是我们想要下载的文件名'
- en: OpenAI
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OpenAI
- en: 'The OpenAI package is installed in all three pipeline notebooks but not in
    `Video_dataset_visualization.ipynb`, which doesn’t require an LLM. You can retrieve
    the API key from a file or enter it manually (but it will be visible):'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI包安装在前三个管道笔记本中，但在不需要LLM的 `Video_dataset_visualization.ipynb` 中没有安装。你可以从文件中检索API密钥或手动输入（但它是可见的）：
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You will need to sign up at `www.openai.com` before running the code and obtain
    an API key. The program installs the `openai` package:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行代码之前，你需要在 `www.openai.com` 上注册并获取一个API密钥。程序安装 `openai` 包：
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, we set an environment variable for the API key:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们为API密钥设置一个环境变量：
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Pinecone
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pinecone
- en: 'The *Pinecone* section is only present in `Pipeline_2_The_Vector_Store_Administrator.ipynb`
    and `Pipeline_3_The_Video_Expert.ipynb` when the Pinecone vector store is required.
    The following command installs Pinecone, and then Pinecone is imported:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*Pinecone* 部分仅在需要Pinecone向量存储的 `Pipeline_2_The_Vector_Store_Administrator.ipynb`
    和 `Pipeline_3_The_Video_Expert.ipynb` 中存在。以下命令安装Pinecone，然后导入Pinecone：'
- en: '[PRE6]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The program then retrieves the key from a file (or you can enter it manually):'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 程序随后从文件中检索密钥（或者你可以手动输入）：
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In production, you can set an environment variable or implement the method that
    best fits your project so that the API key is never visible.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中，你可以设置一个环境变量或实现最适合你项目的方案，以确保API密钥永远不会可见。
- en: The *Evaluator* section of `Pipeline_3_The_Video_Expert.ipynb` contains its
    own requirements and installations.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`Pipeline_3_The_Video_Expert.ipynb` 的 *Evaluator* 部分包含其自身的需求和安装。'
- en: With that, we have defined the environment for all four notebooks, which contain
    the same sub-sections we just described in their respective *Installing the environment*
    sections. We can now fully focus on the processes involved in the video production
    programs. We will begin with the Generator and Commentator.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们已经为所有四个笔记本定义了环境，这些笔记本在其各自的 *安装环境* 部分中包含我们刚刚描述的相同子部分。我们现在可以完全专注于视频制作程序中的过程。我们将从生成器和评论员开始。
- en: 'Pipeline 1: Generator and Commentator'
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道1：生成器和评论员
- en: A revolution is on its way in computer vision with automated video generation
    and analysis. We will introduce the Generator AI agent with Sora in *The AI-generated
    video dataset* section. We will explore how OpenAI Sora was used to generate the
    videos for this chapter with a text-to-video diffusion transformer. The technology
    itself is something we have expected and experienced to some extent in professional
    film-making environments. However, the novelty relies on the fact that the software
    has become mainstream in a few clicks, with inVideo, for example!
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 自动视频生成和分析正在计算机视觉领域引发一场革命。我们将在*AI生成的视频数据集*部分介绍带有Sora的生成器AI代理。我们将探讨OpenAI的Sora是如何使用文本到视频扩散变换器生成本章视频的。这项技术本身是我们已经在专业电影制作环境中预期并有所体验的。然而，新意在于软件只需几点击就能成为主流，例如inVideo！
- en: In the *The Generator and the Commentator* section, we will extend the scope
    of the Generator to collecting and processing the AI-generated videos. The Generator
    splits the videos into frames and works with the Commentator, an OpenAI LLM, to
    produce comments on samples of video frames.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在*生成器和评论员*部分，我们将扩展生成器的范围，以收集和处理AI生成的视频。生成器将视频分割成帧，并与评论员（一个OpenAI LLM）合作，对视频帧样本进行评论。
- en: The Generator’s task begins by producing the AI-generated video dataset.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器的任务是从产生AI生成的视频数据集开始。
- en: The AI-generated video dataset
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI生成的视频数据集
- en: The first AI agent in this project is a text-to-video diffusion transformer
    model that generates a video dataset we will implement. The videos for this chapter
    were specifically generated by Sora, a text-to-video AI model released by OpenAI
    in February 2024\. You can access Sora to view public AI-generated videos and
    create your own at [https://ai.invideo.io/](https://ai.invideo.io/). AI-generated
    videos also allow for free videos with flexible copyright terms that you can check
    out at [https://invideo.io/terms-and-conditions/](https://invideo.io/terms-and-conditions/).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目中的第一个AI代理是一个文本到视频扩散变换器模型，它将生成我们将实施的视频数据集。本章的视频是由Sora生成的，这是OpenAI于2024年2月发布的一个文本到视频AI模型。你可以访问Sora来查看公开的AI生成的视频并创建自己的视频，请访问[https://ai.invideo.io/](https://ai.invideo.io/)。AI生成的视频还允许你获得具有灵活版权条款的免费视频，你可以在[https://invideo.io/terms-and-conditions/](https://invideo.io/terms-and-conditions/)查看这些条款。
- en: Once you have gone through this chapter, you can also create your own video
    dataset with any source of videos, such as smartphones, video stocks, and social
    media.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你通读了这一章，你也可以使用任何视频来源创建自己的视频数据集，例如智能手机、视频股票和社交媒体。
- en: AI-generated videos enhance the speed of creating video datasets. Teams do not
    have to spend time finding videos that fit their needs. They can obtain a video
    quickly with a prompt that can be an idea expressed in a few words. AI-generated
    videos represent a huge leap into the future of AI applications. Sora’s potential
    applies to many industries, including filmmaking, education, and marketing. Its
    ability to generate nuanced video content from simple text prompts opens new avenues
    for creative and educational outputs.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的视频提高了创建视频数据集的速度。团队不必花费时间寻找符合他们需求的视频。他们可以通过一个提示快速获得视频，这个提示可以是用几句话表达的一个想法。AI生成的视频代表了向AI应用未来的巨大飞跃。Sora的潜力适用于许多行业，包括电影制作、教育和营销。它从简单的文本提示中生成细微的视频内容的能力为创意和教育输出开辟了新的途径。
- en: Although AI-generated videos (and, in particular, diffusion transformers) have
    changed the way we create world simulations, this represents a risk for jobs in
    many areas, such as filmmaking. The risk of deep fakes and misinformation is real.
    At a personal level, we must take ethical considerations into account when we
    implement Generative AI in a project, thus producing constructive, ethical, and
    realistic content.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管AI生成的视频（尤其是扩散变换器）改变了我们创建世界模拟的方式，但这在许多领域，如电影制作，代表了就业的风险。深度伪造和虚假信息的风险是真实的。在个人层面，当我们在一个项目中实施生成式AI时，我们必须考虑道德因素，从而产生建设性、道德和现实的内容。
- en: Let’s see how a diffusion transformer can produce realistic content.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看扩散变换器如何产生逼真的内容。
- en: How does a diffusion transformer work?
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 扩散变换器是如何工作的？
- en: At the core of Sora, as described by Liu et al., 2024 (see the *References*
    section), is a diffusion transformer model that operates between an encoder and
    a decoder. It uses user text input to guide the content generation, associating
    it with patches from the encoder. The model iteratively refines these noisy latent
    representations, enhancing their clarity and coherence. Finally, the refined data
    is passed to the decoder to reconstruct high-fidelity video frames. The technology
    involved includes vision transformers such as CLIP and LLMs such as GPT-4, as
    well as other components OpenAI continually includes in its vision model releases.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如刘等人2024年所述（见*参考文献*部分），Sora的核心是一个在编码器和解码器之间运行的扩散变换器模型。它使用用户文本输入来引导内容生成，将其与编码器中的补丁相关联。该模型迭代地细化这些噪声潜在表示，提高其清晰度和连贯性。最后，经过细化的数据被传递到解码器以重建高保真视频帧。涉及的技术包括视觉变换器，如CLIP，以及LLMs，如GPT-4，以及其他OpenAI持续包含在其视觉模型发布中的组件。
- en: 'The encoder and decoder are integral components of the overall diffusion model,
    as illustrated in *Figure 10.3*. They both play a critical role in the workflow
    of the transformer diffusion model:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器和解码器是整体扩散模型的基本组成部分，如图10.3所示。它们在变换器扩散模型的工作流程中都发挥着关键作用：
- en: '**Encoder**: The encoder’s primary function is to compress input data, such
    as images or videos, into a lower-dimensional latent space. The encoder thus transforms
    high-dimensional visual data into a compact representation while preserving crucial
    information. A lower-dimensional latent space obtained is a compressed representation
    of high-dimensional data, retaining essential features while reducing complexity.
    For example, a high-resolution image (1024x1024 pixels, 3 color channels) can
    be compressed by an encoder into a vector of 1000 values, capturing key details
    like shape and texture. This makes processing and manipulating images more efficient.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编码器**：编码器的主要功能是将输入数据，如图像或视频，压缩到低维潜在空间。因此，编码器将高维视觉数据转换为紧凑的表示，同时保留关键信息。获得的低维潜在空间是高维数据的压缩表示，在减少复杂性的同时保留基本特征。例如，高分辨率图像（1024x1024像素，3个颜色通道）可以通过编码器压缩成一个包含1000个值的向量，捕捉形状和纹理等关键细节。这使得图像的处理和操作更加高效。'
- en: '**Decoder**: The decoder reconstructs the original data from the latent representation
    produced by the encoder. It performs the encoder’s reverse operation, transforming
    the low-dimensional latent space back into high-dimensional pixel space, thus
    generating the final output, such as images or videos.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解码器**：解码器从编码器产生的潜在表示中重建原始数据。它执行编码器的逆操作，将低维潜在空间转换回高维像素空间，从而生成最终输出，例如图像或视频。'
- en: '![A diagram of a workflow  Description automatically generated](img/B31169_10_03.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![工作流程图  描述自动生成](img/B31169_10_03.png)'
- en: 'Figure 10.3: The encoding and decoding workflow of video diffusion models'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3：视频扩散模型的编码和解码工作流程
- en: 'The process of a diffusion transformer model goes through five main steps,
    as you can observe in the previous figure:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 扩散变换器模型的过程经过五个主要步骤，如前图所示：
- en: The visual encoder transforms datasets of images into a lower-dimensional latent
    space.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 视觉编码器将图像数据集转换为低维潜在空间。
- en: The visual encoder splits the lower-dimensional latent space into patches that
    are like words in a sentence.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 视觉编码器将低维潜在空间分割成类似于句子中单词的补丁。
- en: The diffusion transformer associates user text input with its dictionary of
    patches.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩散变换器将用户文本输入与其字典中的补丁相关联。
- en: The diffusion transformer iteratively refines noisy image representations generated
    to produce coherent frames.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扩散变换器迭代地细化生成的噪声图像表示，以产生连贯的帧。
- en: The visual decoder reconstructs the refined latent representations into high-fidelity
    video frames that align with the user’s instructions.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 视觉解码器将细化的潜在表示重建为与用户指令一致的高保真视频帧。
- en: The video frames can then be played in a sequence. Every second of a video contains
    a set of frames. We will be deconstructing the AI-generated videos into frames
    and commenting on these frames later. But for now, we will analyze the video dataset
    produced by the diffusion transformer.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，视频帧可以按顺序播放。视频的每一秒都包含一系列帧。我们将分解AI生成的视频为帧，并对这些帧进行评论。但就目前而言，我们将分析扩散变换器产生的视频数据集。
- en: Analyzing the diffusion transformer model video dataset
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析扩散变换器模型视频数据集
- en: Open the `Videos_dataset_visualization.ipynb` notebook on GitHub. Hopefully,
    you have installed the environmentas described earlier in this chapter. We will
    move on to writing the download and display functions we need.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在GitHub上打开`Videos_dataset_visualization.ipynb`笔记本。希望您已经按照本章前面描述的方式安装了环境。我们将继续编写我们需要的下载和显示函数。
- en: Video download and display functions
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 视频下载和显示函数
- en: The three main functions each use `filename` (the name of the video file) as
    an argument. The three main functions download and display videos, and display
    frames in the videos.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 三个主要函数每个都使用`filename`（视频文件名）作为参数。三个主要函数用于下载和显示视频，并在视频中显示帧：
- en: '`download_video` downloads one video at a time from the GitHub dataset, calling
    the `download` function defined in the *GitHub* subsection of *The environment*:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`download_video`函数从GitHub数据集中一次下载一个视频，调用在*环境*部分的*GitHub*子部分中定义的`download`函数：'
- en: '[PRE8]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`display_video(file_name)` displays the video file downloaded by first encoding
    in `base64`, a binary-to-text encoding scheme that represents binary data in ASCII
    string format. Then, the encoded video is displayed in HTML:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`display_video(file_name)`函数显示下载的视频文件，首先使用`base64`进行编码，这是一种二进制到文本的编码方案，它以ASCII字符串格式表示二进制数据。然后，编码后的视频以HTML格式显示：'
- en: '[PRE9]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`display_video_frame` takes `file_name`, `frame_number`, and `size` (the image
    size to display) as arguments to display a frame in the video. The function first
    opens the video file and then extracts the frame number set by `frame_number`:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`display_video_frame`函数接受`file_name`、`frame_number`和`size`（要显示的图像大小）作为参数，以在视频中显示一个帧。该函数首先打开视频文件，然后提取由`frame_number`设置的帧号：'
- en: '[PRE10]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The function converts the file from the BGR (blue, green, and red) to the RGB
    (red, green, and blue) channel, converts it to PIL, an image array (such as one
    handled by OpenCV), and resizes it with the `size` parameters:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数将文件从BGR（蓝、绿、红）通道转换为RGB（红、绿、蓝）通道，将其转换为PIL图像数组（例如OpenCV处理的图像数组），并使用`size`参数进行缩放：
- en: '[PRE11]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Finally, the function encodes the image in string format with `base64` and
    displays it in HTML:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，该函数使用`base64`将图像编码为字符串格式，并在HTML中显示它：
- en: '[PRE12]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Once the environment is installed and the video processing functions are ready,
    we will display the introduction video.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装了环境并且视频处理函数就绪，我们将显示介绍视频。
- en: Introduction video (with audio)
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 介绍视频（带音频）
- en: 'The following cells download and display the introduction video using the functions
    we created in the previous section. A video file is selected and downloaded with
    the `download_video` function:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下单元格使用我们在上一节中创建的函数下载并显示介绍视频。使用`download_video`函数选择并下载视频文件：
- en: '[PRE13]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output confirms the selection and download status:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认了选择和下载状态：
- en: '[PRE14]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can choose to display only a single frame of the video as a thumbnail with
    the `display_video_frame` function by providing the file name, the frame number,
    and the image size to display. The program will first compute `frame_count` (the
    number of frames in the video), `frame_rate` (the number of frames per second),
    and `video_duration` (the duration of the video). Then, it will make sure `frame_number`
    (the frame we want to display) doesn’t exceed `frame_count`. Finally, it displays
    the frame as a thumbnail:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`display_video_frame`函数通过提供文件名、帧号和要显示的图像大小来选择只显示视频的单个帧作为缩略图。程序首先计算`frame_count`（视频中的帧数）、`frame_rate`（每秒帧数）和`video_duration`（视频持续时间）。然后，它将确保`frame_number`（我们想要显示的帧）不超过`frame_count`。最后，它将帧作为缩略图显示：
- en: '[PRE15]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here, `frame_number` is set to `5`, but you can choose another value. The output
    shows the information on the video and the thumbnail:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`frame_number`设置为`5`，但您可以选择另一个值。输出显示了视频和缩略图的信息：
- en: '[PRE16]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can also display the full video if needed:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，我们也可以显示整个视频：
- en: '[PRE17]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The video will be displayed and can be played with the audio track:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 视频将显示，并且可以播放音频轨道：
- en: '![A person sitting in a chair  Description automatically generated](img/B31169_10_05.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![一个坐在椅子上的人物  自动生成的描述](img/B31169_10_05.png)'
- en: 'Figure 10.4: AI-generated video'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4：AI生成视频
- en: 'Let’s describe and display AI-generated videos in the `/videos` directory of
    this chapter’s GitHub directory. You can host this dataset in another location
    and scale it to the volume that meets your project’s specifications. The educational
    video dataset of this chapter is listed in `lfiles`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们描述并显示本章GitHub目录的`/videos`目录中的AI生成视频。您可以将此数据集托管在另一个位置，并将其扩展到满足项目规格的量级。本章的教育视频数据集列在`lfiles`中：
- en: '[PRE18]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can now move on and display any video we wish.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以继续并显示我们想要的任何视频。
- en: Displaying thumbnails and videos in the AI-generated dataset
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在AI生成数据集中显示缩略图和视频
- en: This section is a generalization of the *Introduction video (with audio)* section.
    This time, instead of downloading one video, it downloads all the videos and displays
    the thumbnails of all the videos. You can then select a video in the list and
    display it.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 本节是对*介绍视频（带音频）*部分的推广。这次，它不是下载一个视频，而是下载所有视频并显示所有视频的缩略图。然后您可以在列表中选择一个视频并显示它。
- en: 'The program first collects the video dataset:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 程序首先收集视频数据集：
- en: '[PRE19]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output shows the file names of the downloaded videos:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了下载视频的文件名：
- en: '[PRE20]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The program calculates the number of videos in the list:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 程序计算列表中的视频数量：
- en: '[PRE21]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The program goes through the list and displays the information for each video
    and displays its thumbnail:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 程序遍历列表，显示每个视频的信息并显示其缩略图：
- en: '[PRE22]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The information on the video and its thumbnail is displayed:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 显示视频及其缩略图的信息：
- en: '[PRE23]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You can select a video in the list and display it:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在列表中选择一个视频并显示它：
- en: '[PRE24]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You can click on the video and watch it:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以点击视频并观看它：
- en: '![A person in a football uniform pointing at a football  Description automatically
    generated](img/B31169_10_07.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![身穿足球服的人指着足球  描述自动生成](img/B31169_10_07.png)'
- en: 'Figure 10.5: Video of a football player'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5：足球运动员的视频
- en: We have explored how the AI-generated videos were produced and visualized the
    dataset. We are now ready to build the Generator and the Commentator.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探讨了AI生成视频的产生和可视化数据集。我们现在准备好构建生成器和评论员。
- en: The Generator and the Commentator
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成器和评论员
- en: 'The dataset of AI-generated videos is ready. We will now build the Generator
    and the Commentator, which processes one video at a time, making scaling seamless.
    An indefinite number of videos can be processed one at a time, requiring only
    a CPU and limited disk space. The Generator and the Commentator work together,
    as shown in *Figure 10.8*. These AI agents will produce raw videos from text and
    then split them into frames that they will comment on:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成视频的数据集已准备就绪。我们现在将构建生成器和评论员，它们一次处理一个视频，使扩展无缝。可以一次处理不定数量的视频，只需要CPU和有限的磁盘空间。生成器和评论员协同工作，如图*图10.8*所示。这些AI代理将从文本生成原始视频，然后将它们分割成它们将评论的帧：
- en: '![A diagram of a sports game  Description automatically generated with medium
    confidence](img/B31169_10_08.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![体育比赛的示意图  描述自动生成，置信度中等](img/B31169_10_08.png)'
- en: 'Figure 10.6: The Generator and the Commentator work together to comment on
    video frames'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6：生成器和评论员共同对视频帧进行评论
- en: 'The Generator and the Commentator produce the commented frames required in
    four main steps that we will build in Python:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器和评论员通过以下四个主要步骤产生所需的评论帧，我们将用Python构建：
- en: The **Generator** generates the text-to-video inVideo video dataset based on
    the video production team’s text input. In this chapter, it is a dataset of sports
    videos.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**生成器**根据视频制作团队的文字输入生成文本到视频的inVideo视频数据集。在本章中，它是一个体育视频数据集。'
- en: The **Generator** runs a scaled process by selecting one video at a time.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**生成器**通过每次选择一个视频来运行扩展过程。'
- en: The **Generator** splits the video into frames (images)
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**生成器**将视频分割成帧（图像）'
- en: 'The **Commentator** samples frames (images) and comments on them with an OpenAI
    LLM model. Each commented frame is saved with:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评论员**使用OpenAI LLM模型对帧（图像）进行采样并对其评论。每个评论过的帧都保存有：'
- en: Unique ID
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 唯一标识符
- en: Comment
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评论
- en: Frame
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帧数
- en: Video file name
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频文件名
- en: 'We will now build the Generator and the Commentator in Python, starting with
    the AI-generated videos. Open `Pipeline_1_The_Generator_and_the_Commentator.ipynb`
    in the chapter’s GitHub directory. See the *The environment* section of this chapter
    for a description of the *Installing the environment* section of this notebook.
    The process of going from a video to comments on a sample of frames only takes
    three straightforward steps in Python:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用Python构建生成器和评论员，从AI生成视频开始。在章节的GitHub目录中打开`Pipeline_1_The_Generator_and_the_Commentator.ipynb`。参见本章的*环境*部分，了解笔记本*安装环境*部分的描述。从视频到样本帧评论的过程在Python中只需三个简单的步骤：
- en: Displaying the video
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示视频
- en: Splitting the video into frames
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将视频分割成帧
- en: Commenting on the frames
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对帧进行评论
- en: We will define functions for each step and call them in the `Pipeline-1 Controller`
    section of the program. The first step is to define a function to display a video.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为每个步骤定义函数，并在程序的“Pipeline-1 控制器”部分调用它们。第一步是定义一个显示视频的函数。
- en: Step 1\. Displaying the video
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 1 步：显示视频
- en: The `download` function is in the *GitHub* subsection of the *Installing the
    environment* section of this notebook. It will be called by the *Vector Store
    Administrator-Pipeline 1* in the *Administrator-Pipeline 1* section of this notebook
    on GitHub.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`download` 函数位于本笔记本“安装环境”部分的 *GitHub* 子部分。它将在 GitHub 笔记本“管理员-管道 1”部分的 *Vector
    Store Administrator-Pipeline 1* 中被调用。'
- en: '`display_video(file_name)` is the same as defined in the previous section,
    *The AI-generated video dataset*:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '`display_video(file_name)` 与上一节“AI 生成的视频数据集”中定义的相同：'
- en: '[PRE25]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The downloaded video will now be split into frames.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 下载的视频现在将被分割成帧。
- en: Step 2\. Splitting video into frames
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 2 步：将视频分割成帧
- en: 'The `split_file(file_name)` function extracts frames from a video, as in the
    previous section, *The AI-generated video dataset*. However, in this case, we
    will expand the function to save frames as JPEG files:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`split_file(file_name)` 函数从视频中提取帧，如前节“AI 生成的视频数据集”中所述。然而，在这种情况下，我们将扩展该函数以保存帧为
    JPEG 文件：'
- en: '[PRE26]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We have split the video into frames and saved them as JPEG images with their
    respective frame number, `frame_number`. The Generator’s job finishes here and
    the Commentator now takes over.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将视频分割成帧，并以各自的帧数 `frame_number` 将其保存为 JPEG 图像。生成器的任务在这里完成，评论员现在接管。
- en: Step 3\. Commenting on the frames
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 3 步：对帧进行评论
- en: 'The Generator has gone from text-to-video to splitting the video and saving
    the frames as JPEG frames. The Commentator now takes over to comment on the frames
    with three functions:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器已经从文本到视频，再到分割视频并将帧保存为 JPEG 帧的过程。现在评论员接管，使用三个函数对帧进行评论：
- en: '`generate_openai_comments(filename)` asks the GPT-4 series vision model to
    analyze a frame and produce a response that contains a comment describing the
    frame'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generate_openai_comments(filename)` 请求 GPT-4 系列视觉模型分析一个帧并生成包含描述该帧的评论的响应'
- en: '`generate_comment(response_data)` extracts the comment from the response'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generate_comment(response_data)` 从响应中提取评论'
- en: '`save_comment(comment, frame_number, file_name)` saves the comment'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`save_comment(comment, frame_number, file_name)` 保存评论'
- en: 'We need to build the Commentator’s extraction function first:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要构建评论员的提取函数：
- en: '[PRE27]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We then write a function to save the extracted comment in a CSV file that bears
    the same name as the video file:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们编写一个函数将提取的评论保存到与视频文件同名的 CSV 文件中：
- en: '[PRE28]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The goal is to save the comment in a format that can directly be upserted to
    Pinecone:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是将评论保存为可以直接上传到 Pinecone 的格式：
- en: '`ID`: A unique string ID generated with `str(uuid.uuid4())`'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ID`：使用 `str(uuid.uuid4())` 生成的唯一字符串 ID'
- en: '`FrameNumber`: The frame number of the commented JPEG'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FrameNumber`：注释的 JPEG 图像的帧数'
- en: '`Comment`: The comment generated by the OpenAI vision model'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Comment`：由 OpenAI 视觉模型生成的评论'
- en: '`FileName`: The name of the video file'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FileName`：视频文件的名称'
- en: 'The Commentator’s main function is to generate comments with the OpenAI vision
    model. However, in this program’s scenario, we will not save all the frames but
    a sample of the frames. The program first determines the number of frames to process:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 评论员的主要功能是使用 OpenAI 视觉模型生成评论。然而，在这个程序的场景中，我们不会保存所有帧，而只保存帧的样本。程序首先确定要处理的帧数：
- en: '[PRE29]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then, a sample frequency is set that can be modified along with a counter:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，设置一个可以修改的样本频率以及一个计数器：
- en: '[PRE30]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The Commentator will then go through the sampled frames and request a comment:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 评论员接下来将遍历采样帧并请求评论：
- en: '[PRE31]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The message is very concise: `"What is happening in this image?"` The message
    also includes the image of the frame:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 消息非常简洁：“这张图片中发生了什么？” 消息还包括该帧的图像：
- en: '[PRE32]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Once a response is returned, the `generate_comment` and `save_comment` functions
    are called to extract and save the comment, respectively:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦返回响应，将调用 `generate_comment` 和 `save_comment` 函数分别提取和保存评论：
- en: '[PRE33]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The final function we require of the Commentator is to display the comments
    by loading the CSV file produced in a pandas DataFrame:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 评论员需要我们提供的最后一个功能是加载生成的 CSV 文件并在 pandas DataFrame 中显示评论：
- en: '[PRE34]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The function returns the DataFrame with the comments. An administrator controls
    *Pipeline 1*, the Generator, and the Commentator.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 函数返回包含评论的 DataFrame。管理员控制 *Pipeline 1*、生成器和评论员。
- en: Pipeline 1 controller
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管道 1 控制器
- en: 'The controller runs jobs for the preceding three steps of the Generator and
    the Commentator. It begins with *Step 1*, which includes selecting a video, downloading
    it, and displaying it. In an automated pipeline, these functions can be separated.
    For example, a script would iterate through a list of videos, automatically select
    each one, and encapsulate the controller functions. In this case, in a pre-production
    and educational context, we will collect, download, and display the videos one
    by one:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器为生成器和评论员的先前三个步骤运行作业。它从**步骤1**开始，包括选择视频、下载并显示视频。在一个自动化的管道中，这些功能可以被分离。例如，一个脚本会遍历视频列表，自动选择每个视频，并封装控制器功能。在这种情况下，在一个预生产和教育环境中，我们将逐个收集、下载和显示视频：
- en: '[PRE35]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The controller then splits the video into frames and comments on the frames
    of the video:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器随后将视频分割成帧，并对视频的帧进行评论：
- en: '[PRE36]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The controller activates the Generator to produce comments on frames of the
    video:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器激活生成器，对视频的帧生成评论：
- en: '[PRE37]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The response time is measured as well. The controller then adds additional
    outputs to display the number of frames, the comments, the content generation
    time, and the total controller processing times:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 还测量了响应时间。然后控制器添加额外的输出以显示帧数、评论、内容生成时间和总控制器处理时间：
- en: '[PRE38]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The controller has completed its task of producing content. However, depending
    on your project, you can introduce dynamic RAG for some or all the videos. If
    you need this functionality, you can apply the process described in *Chapter 5*,
    *Boosting RAG Performance with Expert Human Feedback*, to the Commentator’s outputs,
    including the cosine similarity quality control metrics, as we will in the *Pipeline
    3: The Video Expert* section of this chapter.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器已完成其生成内容的工作。然而，根据您的项目，您可以为某些或所有视频引入动态RAG。如果您需要此功能，可以将第5章中描述的过程应用于评论员的输出，包括余弦相似度质量控制指标，正如我们在本章的**管道3：视频专家**部分所做的那样。
- en: The controller can also save the comments and frames.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器还可以保存评论和帧。
- en: Saving comments
  id: totrans-242
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 保存评论
- en: 'To save the comments, set `save=True`. To save the frames, set `save_frames=True`.
    Set both values to `False` if you just want to run the program and view the outputs,
    but, in our case, we will set them as `True`:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 要保存评论，设置`save=True`。要保存帧，设置`save_frames=True`。如果您只想运行程序并查看输出，可以将这两个值都设置为`False`，但在此情况下，我们将它们设置为`True`：
- en: '[PRE39]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The comment is saved in CSV format in `cpath` and contains the file name with
    the `.csv` extension and in the location of your choice. In this case, the files
    are saved on Google Drive (make sure the path exists):'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 评论以CSV格式保存在`cpath`中，包含具有`.csv`扩展名的文件名和您选择的位置。在这种情况下，文件保存在Google Drive上（请确保路径存在）：
- en: '[PRE40]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The output confirms that a file is saved:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认文件已保存：
- en: '[PRE41]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The frames are saved in a root name direction, for which we remove the extension
    with `root_name = root_name + extension.strip(''.'')`:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 帧保存在以根名称命名的目录中，我们使用`root_name = root_name + extension.strip('.')`来移除扩展名：
- en: '[PRE42]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The output is a directory with all the frames generated in it. We should delete
    the files if the controller runs in a loop over all the videos in a single session.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是一个包含所有生成帧的目录。如果控制器在一个会话中循环运行所有视频，我们应该删除这些文件。
- en: Deleting files
  id: totrans-252
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 删除文件
- en: 'To delete the files, just set `delf=True`:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除文件，只需设置`delf=True`：
- en: '[PRE43]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: You can now process an unlimited number of videos one by one and scale to whatever
    size you wish, as long as you have disk space and a CPU!
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以逐个处理无限数量的视频，并扩展到您希望的大小，只要您有足够的磁盘空间和CPU！
- en: 'Pipeline 2: The Vector Store Administrator'
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道2：向量存储管理员
- en: 'The Vector Store Administrator AI agent performs the tasks we implemented in
    *Chapter 6*, *Scaling RAG Bank Customer Data with Pinecone.* The novelty in this
    section relies on the fact that all the data we upsert for RAG is AI-generated.
    Let’s open `Pipeline_2_The_Vector_Store_Administrator.ipynb` in the GitHub repository.
    We will build the Vector Store Administrator on top of the Generator and the Commentator
    AI agents in four steps, as illustrated in the following figure:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储管理员AI代理执行我们在**第6章**中实现的任务，即**使用Pinecone扩展RAG银行客户数据**。本节的新颖之处在于，我们为RAG上载的所有数据都是AI生成的。让我们在GitHub仓库中打开`Pipeline_2_The_Vector_Store_Administrator.ipynb`。我们将分四个步骤在生成器和评论员AI代理的基础上构建向量存储管理员，如图所示：
- en: '![A diagram of a video expert  Description automatically generated](img/B31169_10_09.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![视频专家的示意图  描述由系统自动生成](img/B31169_10_09.png)'
- en: 'Figure 10.7: Workflow of the Vector Store Administrator from processing to
    querying video frame comments'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7：向量存储管理员从处理到查询视频帧评论的工作流程
- en: '**Processing the video comments**: The Vector Store Administrator will load
    and prepare the comments for chunking as in the *Pipeline 2: Scaling a Pinecone
    Index (vector store)* section of *Chapter 6*. Since we are processing one video
    at a time in a pipeline, the system deletes the files processed, which keeps disk
    space constant. You can enhance the functionality and scale this process indefinitely.'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**处理视频评论**：向量存储管理员将像*第6章*的*Pipeline 2：扩展Pinecone索引（向量存储）*部分中所述那样加载和准备评论以进行分块。由于我们在管道中一次处理一个视频，系统会删除已处理的文件，从而保持磁盘空间恒定。您可以增强功能并无限扩展此过程。'
- en: '**Chunking and embedding the dataset**: The column names `(''ID'', ''FrameNumber'',
    ''Comment'', ''FileName'')` of the dataset have already been prepared by the Commentator
    AI agent in *Pipeline 1*. The program chunks and embeds the dataset using the
    same functionality as in *Chapter 6* in the *Chunking and embedding the dataset*
    section.'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据集的分块和嵌入**：数据集的列名`(''ID'', ''FrameNumber'', ''Comment'', ''FileName'')`已经在*Pipeline
    1*中的评论员AI代理中准备好。程序使用与*第6章*中*数据集的分块和嵌入*部分相同的函数分块和嵌入数据集。'
- en: '**The Pinecone index**: The Pinecone Index is created, and the data is upserted
    as in the *Creating the Pinecone Index* and *Upserting* sections of *Chapter*
    6.'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Pinecone索引**：Pinecone索引被创建，数据如*第6章*的*创建Pinecone索引*和*Upserting*部分中所述进行更新。'
- en: '**Querying the vector store after upserting the dataset**: This follows the
    same process as in *Chapter 6*. However, in this case, the retrieval is hybrid,
    using both the Pinecone vector store and a separate file system to store videos
    and video frames.'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在更新数据集后查询向量存储**：这遵循与*第6章*中相同的流程。然而，在这种情况下，检索是混合的，使用Pinecone向量存储和单独的文件系统来存储视频和视频帧。'
- en: Go through *Steps 1* to *3* in the notebook to examine the Vector Store Administrator’s
    functions. After *Step 3*, the Pinecone index is ready for hybrid querying.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中通过*步骤1*到*步骤3*来检查向量存储管理员的函数。在*步骤3*之后，Pinecone索引就准备好进行混合查询。
- en: Querying the Pinecone index
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询Pinecone索引
- en: 'In the notebook on GitHub, *Step 4: Querying the Pinecone index* implements
    functions to find a comment that matches user input and trace it to the frame
    of a video. This leads to the video source and frame, which can be displayed.
    We can display the videos and frames from the location we wish. This hybrid approach
    thus involves querying the Pinecone Index to retrieve information and also retrieve
    media files from another location.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在GitHub上的笔记本中，*步骤4：查询Pinecone索引*实现了查找与用户输入匹配的评论并将其追踪到视频帧的功能。这导致视频源和帧，可以显示出来。我们可以从我们希望的位置显示视频和帧。这种混合方法因此涉及查询Pinecone索引以检索信息，并从另一个位置检索媒体文件。
- en: We saw that a vector store can contain images that are queried, as implemented
    in *Chapter 4*, *Multimodal Modular RAG for Drone Technology*. In this chapter,
    the video production use case videos and frame files are stored separately. In
    this case, it is in the GitHub repository. In production, the video and frame
    files can be retrieved from any storage system we need, which may or may not prove
    to be more cost-effective than storing data on Pinecone. The decision to store
    images in a vector store or a separate location will depend on the project’s needs.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，向量存储可以包含查询到的图像，正如在*第4章*，*多模态模块化RAG用于无人机技术*中实现的那样。在这一章中，视频制作用例的视频和帧文件被分别存储。在这种情况下，它们存储在GitHub仓库中。在生产中，视频和帧文件可以从我们需要的任何存储系统中检索，这可能或可能不会证明比在Pinecone上存储数据更具有成本效益。是否在向量存储或单独的位置存储图像将取决于项目的需求。
- en: 'We begin by defining the number of top-k results we wish to process:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义我们希望处理的top-k结果的数量：
- en: '[PRE44]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We then design a rather difficult prompt:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们设计了一个相当困难的提示：
- en: '[PRE45]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Only a handful of frames in the whole video dataset contain an image of a basketball
    player jumping to score a slam dunk. Can our system find it? Let’s find out.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 整个视频数据集中只有少数几个帧包含一个篮球运动员跳起来扣篮的图像。我们的系统能够找到它吗？让我们来看看。
- en: 'We first embed our query to match the format of the data in the vector store:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将查询嵌入以匹配向量存储中的数据格式：
- en: '[PRE46]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Then we run a similarity vector search between the query and the dataset:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们在查询和数据集之间运行相似度向量搜索：
- en: '[PRE47]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Finally, we display the content of the response and the response time:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们显示响应的内容和响应时间：
- en: '[PRE48]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The output contains the ID of the comment retrieved and its score:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 输出包含检索到的评论的ID及其评分：
- en: '[PRE49]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output also contains the comment generated by the OpenAI LLM (the Commentator
    agent):'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 输出还包含由OpenAI LLM（评论者代理）生成的评论：
- en: '[PRE50]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The final output contains the frame number that was commented, the video file
    of the frame, and the retrieval time:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 最终输出包含评论的帧号、视频文件和检索时间：
- en: '[PRE51]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We can display the video by downloading it based on the file name:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过根据文件名下载来显示视频：
- en: '[PRE52]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Then, use a standard Python function to display it:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用标准的Python函数来显示它：
- en: '[PRE53]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The video containing a basketball player performing a dunk is displayed:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 显示了篮球运动员扣篮的视频：
- en: '![A basketball hoop with net  Description automatically generated](img/B31169_10_10.png)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![带有网篮的篮球架  自动生成的描述](img/B31169_10_10.png)'
- en: 'Figure 10.8: Video output'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8：视频输出
- en: 'We can take this further with more precision by displaying the frame of the
    comment retrieved:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过显示检索到的帧来进一步精确地这样做：
- en: '[PRE54]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output shows the exact frame that corresponds to the user input:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了与用户输入相对应的确切帧：
- en: '![A person holding a ball  Description automatically generated](img/B31169_10_11.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![手持篮球的人  自动生成的描述](img/B31169_10_11.png)'
- en: 'Figure 10.9: Video frame corresponding to our input'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9：对应我们输入的视频帧
- en: Only the frames of `basketball3.mp4` were saved in the GitHub repository for
    disk space reasons for this program. In production, all the frames you decide
    you need can be stored and retrieved.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 由于磁盘空间原因，仅保存了`basketball3.mp4`的帧到GitHub仓库中。在生产中，您可以存储和检索您决定需要的所有帧。
- en: 'The team of AI agents in this chapter worked together to generate videos (the
    Generator), comment on the video frames (the Commentator), upsert embedded comments
    in the vector store (the Vector Store Administrator), and prepare the retrieval
    process (the Vector Store Administrator). We also saw that the retrieval process
    already contained augmented input and output thanks to the OpenAI LLM (the Commentator)
    that generated natural language comments. The process that led to this point will
    definitely be applied in many domains: firefighting, medical imagery, marketing,
    and more.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的AI代理团队共同工作，生成视频（生成器）、评论视频帧（评论者）、在向量存储中更新嵌入的评论（向量存储管理员）以及准备检索过程（向量存储管理员）。我们还看到，由于OpenAI
    LLM（评论者）生成了自然语言评论，检索过程已经包含了增强的输入和输出。导致这一点的过程肯定会在许多领域得到应用：消防、医学影像、营销等等。
- en: What more can we expect from this system? The Video Expert AI agent will answer
    that.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还能从这个系统中期待什么？视频专家AI代理将回答这个问题。
- en: 'Pipeline 3: The Video Expert'
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道3：视频专家
- en: The role of the OpenAI GPT-4o Video Expert is to analyze the comment made by
    the Commentator OpenAI LLM agent, point out the cognitive dissonances (things
    that don’t seem to fit together in the description), rewrite the comment, and
    provide a label. The workflow of the Video Expert, as illustrated in the following
    figure, also includes the code of the *Metrics calculations and display* section
    of *Chapter 7*, *Building Scalable Knowledge-Graph-Based RAG with Wikipedia API
    and LlamaIndex*.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI GPT-4o 视频专家的角色是分析评论者OpenAI LLM代理的评论，指出认知失调（描述中看起来不协调的事物），重写评论并提供标签。视频专家的工作流程，如图所示，还包括第7章“使用Wikipedia
    API和LlamaIndex构建可扩展的知识图谱RAG”中“*度量计算和显示*”部分的代码。
- en: The Commentator’s role was only to describe what it saw. The Video Expert is
    there to make sure it makes sense and also label the videos so they can be classified
    in the dataset for further use.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 评论者的角色仅仅是描述所看到的内容。视频专家的存在是为了确保其有意义，并给视频贴标签，以便它们可以在数据集中分类并进一步使用。
- en: '![A diagram of a video expert  Description automatically generated](img/B31169_10_12.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![视频专家的示意图  自动生成的描述](img/B31169_10_12.png)'
- en: 'Figure 10.10: Workflow of the Video Expert for automated dynamics descriptions
    and labeling'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10：视频专家自动化动态描述和标签的工作流程
- en: '**The Pinecone index** will connect to the Pinecone index as described in the
    *Pipeline 2\. The Vector Store Administrator* section of this chapter. This time,
    we will not upsert data but connect to the vector store.'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Pinecone索引**将连接到本章中“*管道2*”的“*向量存储管理员*”部分所描述的Pinecone索引。这次，我们不会更新数据，而是连接到向量存储。'
- en: '**Define the RAG functions** utilizing the straightforward functions we built
    in *Pipeline 1* and *Pipeline 2* of this chapter.'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**定义RAG函数**，利用本章“管道1”和“管道2”中构建的简单函数。'
- en: '**Querying the vector store** is nothing but querying the Pinecone Index as
    described in *Pipeline 2* of this chapter.'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**查询向量存储**不过是查询本章中*管道2*所描述的Pinecone索引。'
- en: '**Retrieval augmented generation** finally determines the main role of Video
    Expert GPT-4o, which is to analyze and improve the vector store query responses.
    This final step will include evaluation and metric functions.'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检索增强生成**最终确定了Video Expert GPT-4o的主要角色，即分析和改进向量存储查询响应。这一最终步骤将包括评估和度量函数。'
- en: 'There are as many strategies as projects to implement the video production
    use case we explored in this chapter, but the Video Expert plays an important
    role. Open `Pipeline_3_The_Video_Expert.ipynb` on GitHub and go to the *Augmented
    Retrieval Generation* section in *Step 2: Defining the RAG functions*.'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 实现本章中探讨的视频生产用例的策略与项目一样多，但Video Expert扮演着重要的角色。在GitHub上打开`Pipeline_3_The_Video_Expert.ipynb`，并转到*步骤2：定义RAG函数*中的*增强检索生成*部分。
- en: 'The function makes an OpenAI GPT-4o call, like for the Commentator in *Pipeline
    1*. However, this time, the role of the LLM is quite different:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数调用OpenAI GPT-4o，就像*管道1*中的评论员一样。然而，这次，LLM的角色相当不同：
- en: '[PRE55]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The instructions for GPT-4o are:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4o的指令是：
- en: '`You will be provided with comments of an image frame taken from a video`:
    This instructs the LLM to analyze the AI-generated comments. The Commentator had
    to remain neutral and describe the frame as it saw it. The role of the Video Expert
    agent is different: it has to analyze and enhance the comment.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`您将提供从视频中截取的图像帧的评论`: 这指示LLM分析AI生成的评论。评论员必须保持中立并描述框架，就像它看到的那样。Video Expert代理的角色不同：它必须分析和增强评论。'
- en: '`1\. Point out the cognitive dissonances`: This instructs the model to find
    contradictions or discrepancies in the comment that can come from the way the
    AI-generated video was produced as well (lack of logic in the video).'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1. 指出认知失调`: 这指示模型找到来自AI生成视频生产方式（视频中的逻辑缺失）的评论中的矛盾或差异。'
- en: '`2\. Rewrite the comment in a logical engaging style`: This instructs the Video
    Expert agent to rewrite the comment going from a technical comment to a description.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`2. 以逻辑吸引人的风格重写注释`: 这指示Video Expert代理将注释从技术评论重写为描述。'
- en: '`3\. Provide a label for this image such as Label: basketball, football, soccer
    or other label`: This instructs the model to provide a label for further use.
    On GitHub, *Step 3: Querying the Vector Store* reproduces the query and output
    described in *Pipeline 2* for a basketball player scoring with a dunk, with the
    corresponding video and frame. The output is:'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`3. 为此图像提供标签，例如：Label: basketball, football, soccer或其他标签`: 这指示模型提供标签以供进一步使用。在GitHub上，*步骤3：查询向量存储*重现了*管道2*中描述的篮球运动员扣篮的查询和输出，以及相应的视频和帧。输出是：'
- en: '[PRE56]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The comment provided seems acceptable. However, let’s see what GPT-4o thinks
    of it. The *Step 4: Retrieval Augmented Generation* section on GitHub takes the
    output and submits it as the user prompt to the Video Expert agent:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 提供的评论似乎是可以接受的。然而，让我们看看GPT-4o对它的看法。GitHub上的*步骤4：检索增强生成*部分将输出作为用户提示提交给Video Expert代理：
- en: '[PRE57]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We then call the Video Expert agent to obtain its expertise:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后调用Video Expert代理以获取其专业知识：
- en: '[PRE58]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The output provides the Video Expert’s insights:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 输出提供了Video Expert的见解：
- en: '[PRE59]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The response is well-structured and acceptable. The output may vary from one
    run to another due to the stochastic “creative” nature of Generative AI agents.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 响应结构良好且可以接受。由于生成式AI代理的随机“创造性”本质，输出可能因运行而异。
- en: 'The *Evaluator* section that follows *Step 4* runs ten examples using the same
    process as the basketball request we just made. Each example thus contains:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在*步骤4*之后的*评估器*部分使用与刚才我们提出的篮球请求相同的过程运行十个示例。因此，每个示例都包含：
- en: A user prompt
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户提示
- en: The comment returned by the vector store query
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量存储查询返回的评论
- en: The enhanced comment made by the GPT-4o model
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT-4o模型制作的增强评论
- en: Each example also contains the same evaluation process as in *Chapter 7, Building
    Scalable Knowledge-Graph-Based RAG with Wikipedia API and LlamaIndex,* in the
    *Examples for metrics* section. However, in this case, the human evaluator suggests
    content instead of a score (0 to 1). The human content becomes the ground truth,
    the expected output.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 每个示例还包含与*第7章，使用Wikipedia API和LlamaIndex构建可扩展的知识图谱RAG*中*度量示例*部分相同的评估过程。然而，在这种情况下，人工评估者建议内容而不是分数（0到1）。人工内容成为地面真相，预期的输出。
- en: Before beginning the evaluation, the program creates scores to keep track of
    the original response made by the query.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始评估之前，程序创建分数以跟踪查询做出的原始响应。
- en: 'The human evaluator rewrites the output provided by the Video Expert:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 人类评估者重写了视频专家提供的输出：
- en: '[PRE60]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The content rewritten by the Video Expert is extracted from the response:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 视频专家重写的内容是从响应中提取的：
- en: '[PRE61]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The human comment (ground truth, the reference output) and the LLM comments
    are displayed:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 人类评论（真实情况，参考输出）和LLM评论显示：
- en: '[PRE62]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Then, the cosine similarity score between the human and LLM comments is calculated
    and appended to `scores`:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，计算人类和LLM评论之间的余弦相似度分数并将其附加到`scores`：
- en: '[PRE63]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The original score provided with the query is appended to the query’s retrieval
    score, `rscores`:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 与查询一起提供的原始分数附加到查询的检索分数`rscores`：
- en: '[PRE64]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'The output displays the human feedback, the comment rewritten by GPT-4o (the
    Video Expert), and the similarity score:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了人类反馈，GPT-4o（视频专家）重写的评论以及相似度分数：
- en: '[PRE65]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: This program contains ten examples, but we can enter a corpus of as many examples
    as we wish to evaluate the system. The evaluation of each example applies the
    same choice of metrics as in *Chapter 7**.* After the examples have been evaluated,
    the *Metrics calculations and display* section in the program also runs the metric
    calculations defined in the section of the same name in *Chapter 7*.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序包含十个示例，但我们可以输入任意数量的示例语料库来评估系统。每个示例的评估都应用与*第七章*中相同的指标选择。在评估完示例后，程序中的*指标计算和显示*部分也会运行*第七章*中同名部分定义的指标计算。
- en: 'We can use all the metrics to analyze the performance of the system. The time
    measurements throughout the program also provide insights. The first metric, accuracy,
    is a good metric to start with. In this case, it shows that there is room for
    progress:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用所有指标来分析系统的性能。程序中的时间测量也提供了洞察。第一个指标，准确率，是一个很好的起点。在这种情况下，它表明还有进步的空间：
- en: '[PRE66]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Some requests and responses were challenging and required further work to improve
    the system:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 一些请求和响应具有挑战性，需要进一步工作来改进系统：
- en: Checking the quality of the videos and their content
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查视频的质量及其内容
- en: Checking the comments and possibly modifying them with human feedback, as we
    did in *Chapter 5*, *Boosting RAG Performance with Expert Human Feedback*
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查评论并可能根据人类反馈进行修改，就像我们在*第五章*中做的，*通过专家人类反馈提升RAG性能*
- en: 'Fine-tuning a model with images and text as we did in *Chapter 9*, *Empowering
    AI Models: Fine-Tuning RAG Data and Human Feedback*'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 就像我们在*第九章*中做的，使用图像和文本微调模型，*赋予AI模型力量：微调RAG数据和人类反馈*
- en: Designing any other constructive idea that the video production team comes up
    with
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计视频制作团队提出的任何其他建设性想法
- en: We can see that RAG-driven Generative AI systems in production are very effective.
    However, the road from design to production requires hard human effort! Though
    AI technology has made tremendous progress, it still requires humans to design,
    develop, and implement it in production.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在生产中的RAG驱动的生成式AI系统非常有效。然而，从设计到生产的道路需要艰苦的人类努力！尽管AI技术取得了巨大进步，但它仍然需要人类来设计、开发和在生产中实施它。
- en: Summary
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored the hybrid era of human and AI agents, focusing
    on the creation of a streamlined process for generating, commenting, and labeling
    videos. By integrating cutting-edge Generative AI models, we demonstrated how
    to build an automated pipeline that transforms raw video inputs into structured,
    informative, and accessible video content.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了人类和AI代理的混合时代，重点关注创建一个简化的流程来生成、评论和标记视频。通过集成最先进的生成式AI模型，我们展示了如何构建一个自动化的管道，将原始视频输入转换为结构化、信息丰富且易于访问的视频内容。
- en: 'Our journey began with the **Generator** agent in *Pipeline 1*: *The Generator
    and the Commentator*, which was tasked with creating video content from textual
    ideas. We can see that video generation processes will continue to expand through
    seamless integration ideation and descriptive augmentation generative agents.
    In *Pipeline 2*: *The Vector Store Administrator*, we focused on organizing and
    embedding the generated comments and metadata into a searchable vector store.
    In this pipeline, we highlighted the optimization process of building a scalable
    video content library with minimal machine resources using only a CPU and no GPU.
    Finally, in *Pipeline 3*: *The Video Expert*, we introduced the Expert AI agent,
    a video specialist designed to enhance and label the video content based on user
    inputs. We also implemented evaluation methods and metric calculations.'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的旅程始于“管道 1”中的**生成器**代理：**生成器和评论员**，其任务是创建从文本想法生成的视频内容。我们可以看到，视频生成过程将通过无缝集成创意和描述性增强生成代理而继续扩展。在“管道
    2”中：**向量存储管理员**，我们专注于将生成的注释和元数据组织并嵌入到可搜索的向量存储中。在这个管道中，我们强调了仅使用 CPU 而不使用 GPU，以最小化机器资源构建可扩展视频内容库的优化过程。最后，在“管道
    3”中：**视频专家**，我们引入了专家 AI 代理，这是一种视频专家，旨在根据用户输入增强和标记视频内容。我们还实施了评估方法和指标计算。
- en: By the end of this chapter, we had constructed a comprehensive, automated RAG-driven
    Generative AI system capable of generating, commenting on, and labeling videos
    with minimal human intervention. This journey demonstrated the power and potential
    of combining multiple AI agents and models to create an efficient pipeline for
    video content creation.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，我们已经构建了一个综合的、自动的 RAG 驱动的生成式 AI 系统，该系统能够在最小的人为干预下生成、注释和标记视频。这段旅程展示了将多个
    AI 代理和模型结合以创建高效视频内容创建流程的强大和潜力。
- en: The techniques and tools we explored can revolutionize various industries by
    automating repetitive tasks, enhancing content quality, and making information
    retrieval more efficient. This chapter not only provided a detailed technical
    roadmap but also underscored the transformative impact of AI in modern content
    creation and management. You are now all set to implement RAG-driven Generative
    AI in real-life projects.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 我们探索的技术和工具可以通过自动化重复性任务、提高内容质量和使信息检索更高效来彻底改变各个行业。本章不仅提供了一个详细的技术路线图，而且还强调了 AI
    在现代内容创作和管理中的变革性影响。现在，你们都已经准备好在现实生活中的项目中实施 RAG 驱动的生成式 AI。
- en: Questions
  id: totrans-357
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Answer the following questions with yes or no:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 用是或否回答以下问题：
- en: Can AI now automatically comment and label videos?
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AI 现在能否自动对视频进行注释和标记？
- en: Does video processing involve splitting the video into frames?
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 视频处理是否涉及将视频分割成帧？
- en: Can the programs in this chapter create a 200-minute movie?
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本章的程序能否创建一部 200 分钟的电影？
- en: Do the programs in this chapter require a GPU?
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本章的程序是否需要 GPU？
- en: Are the embedded vectors of the video content stored on disk?
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 视频内容嵌入的向量是否存储在磁盘上？
- en: Do the scripts involve querying a database for retrieving data?
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些脚本是否涉及查询数据库以检索数据？
- en: Is there functionality for displaying images in the scripts?
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在脚本中是否有显示图片的功能？
- en: Is it useful to have functions that specifically check file existence and size
    in any of the scripts?
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在任何脚本中拥有专门检查文件存在性和大小的函数是否有用？
- en: Is there a focus on multimodal data in these scripts?
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些脚本是否关注多模态数据？
- en: Do any of the scripts mention applications of AI in real-world scenarios?
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些脚本中是否提到了 AI 在现实场景中的应用？
- en: References
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Sora video generation model information and access:'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sora 视频生成模型信息和访问：
- en: '**Sora** | **OpenAI**: [https://ai.invideo.io/](https://ai.invideo.io/)'
  id: totrans-371
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sora** | **OpenAI**: [https://ai.invideo.io/](https://ai.invideo.io/)'
- en: '[https://openai.com/index/video-generation-models-as-world-simulators/](https://openai.com/index/video-generation-models-as-world-simulators/)'
  id: totrans-372
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://openai.com/index/video-generation-models-as-world-simulators/](https://openai.com/index/video-generation-models-as-world-simulators/)'
- en: '*Sora: A Review on Background, Technology, Limitations, and Opportunities of
    Large Vision Models* by Yixin Liu, Kai Zhang, Yuan Li, et al.: [https://arxiv.org/pdf/2402.17177](https://arxiv.org/pdf/2402.17177)'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '由 Yixin Liu、Kai Zhang、Yuan Li 等人撰写的《Sora：关于大型视觉模型背景、技术、局限性和机会的综述》: [https://arxiv.org/pdf/2402.17177](https://arxiv.org/pdf/2402.17177)'
- en: Further reading
  id: totrans-374
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'OpenAI, ChatGPT: [https://openai.com/chatgpt/](https://openai.com/chatgpt/)'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenAI, ChatGPT: [https://openai.com/chatgpt/](https://openai.com/chatgpt/)'
- en: 'OpenAI, Research: [https://openai.com/research/](https://openai.com/research/)'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI，研究：[https://openai.com/research/](https://openai.com/research/)
- en: 'Pinecone: [https://docs.pinecone.io/home](https://docs.pinecone.io/home)'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pinecone: [https://docs.pinecone.io/home](https://docs.pinecone.io/home)'
- en: Join our community on Discord
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://www.packt.link/rag](https://www.packt.link/rag)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.packt.link/rag](https://www.packt.link/rag)'
- en: '![](img/QR_Code50409000288080484.png)'
  id: totrans-381
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code50409000288080484.png)'
