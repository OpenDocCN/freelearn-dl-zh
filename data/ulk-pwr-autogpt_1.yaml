- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Introducing Auto-GPT
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Auto-GPT
- en: In the *Preface*, I wrote about what Auto-GPT is and where it came from, but
    I was asking myself, “*Why would anyone read* *this book?*”
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在*前言*中，我写了关于Auto-GPT是什么以及它的来源，但我问自己，“*为什么会有人阅读* *这本书？*”
- en: I mean, it is what it is – an automated form of **artificial intelligence**
    (**AI**) that may or may not help you do some tasks or be a fun toy that can be
    very spooky sometimes, right?
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我的意思是，它就是它——一种自动化的**人工智能**（**AI**），它可能帮助你完成一些任务，也可能是一个有时非常神秘的有趣玩具，对吧？
- en: I want you to have a clear understanding of what you can or cannot do with it.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你清楚了解你可以或不可以用它做什么。
- en: Of course, the more creative you get, the more it can do, but sometimes the
    boundaries appear to be more or less random. For example, let’s say you just built
    a house-building robot that for no apparent reason refuses to make the front door
    blue, even though you really want a blue door; it keeps going off-topic or even
    starts explaining what doors are.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你越有创意，它能做的事情就越多，但有时这些边界看起来更多是随机的。例如，假设你刚刚建造了一个房屋建造机器人，它无缘无故拒绝把前门涂成蓝色，尽管你真的想要一个蓝色的门；它总是偏离主题，甚至开始解释什么是门。
- en: Auto-GPT can be very frustrating when it comes to these limitations as they
    come from a combination of OpenAI’s restrictions (which they give in their GPT
    model) and the humans who write and edit Auto-GPT (along with you – the user who
    gives it instructions). What first appears to be a clear instruction can result
    in a very different outcome just by changing one single character.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到这些局限性时，Auto-GPT可能会非常令人沮丧，因为这些限制来源于OpenAI的限制（它们在其GPT模型中给出）以及编写和编辑Auto-GPT的人类（还有你——作为提供指令的用户）。最初看似明确的指令，通过改变一个字符，就可能导致完全不同的结果。
- en: For me, this is what makes it fascinating – you can always expect it to behave
    like a living being that can randomly choose to do otherwise and have its own
    mind.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，这就是它迷人的地方——你总是可以期待它像一个活生生的存在，随机选择做出不同的决定，拥有自己的思想。
- en: Note
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Always keep in mind that this is a fast-moving project, so code can and will
    be changed until this book is released. It may also be the case that you bought
    this book much later and Auto-GPT is completely different. Most of the content
    in this book focuses on version 0.4.1, but changes have been made and considered
    regarding version 0.5.0 as well.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 始终记住，这是一个快速发展的项目，因此代码可能会在本书发布之前发生变化。也可能是你很晚才买这本书，而Auto-GPT已经完全不同。本书的大部分内容集中在0.4.1版本，但也考虑到了0.5.0版本的变化。
- en: For example, once I finished the draft of this book, the “Forge” (an idea we
    had at a team meeting) had already been implemented. This was an experiment that
    allowed other developers to build their own Auto-GPT variation.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一旦我完成了这本书的草稿，“Forge”（我们在团队会议上提出的一个想法）已经实现了。这是一个实验，允许其他开发者构建他们自己的Auto-GPT变种。
- en: The Auto-GPT project is a framework that contains Auto-GPT, which we’ll be working
    with in this book, and can start other agents made by other developers. Those
    agents are in the repositories of the programmers who added them, so we won’t
    dive into them here.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT项目是一个框架，包含了我们在本书中将使用的Auto-GPT，并且可以启动其他由开发者创建的代理。这些代理存放在添加它们的程序员的仓库中，因此我们在这里不会深入探讨这些内容。
- en: In this chapter, we aim to introduce you to Auto-GPT, including its history
    and development, as well as LangChain. This chapter will help you understand what
    Auto-GPT is, its significance, and how it has evolved. By the end of this chapter,
    you will have a solid foundation to build upon as we explore more advanced topics
    in the subsequent chapters.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍Auto-GPT，包括它的历史和发展，以及LangChain。本章将帮助你了解Auto-GPT是什么，它的意义，以及它是如何发展的。在本章结束时，你将拥有坚实的基础，作为后续章节探索更高级主题的起点。
- en: 'We will cover the following main topics in this chapter:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖以下主要主题：
- en: Overview of Auto-GPT
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Auto-GPT概述
- en: History and development of Auto-GPT
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Auto-GPT的历史与发展
- en: Introduction to LangChain
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LangChain介绍
- en: Overview of Auto-GPT
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Auto-GPT概述
- en: '**Auto-GPT** is more or less a category of what it already describes:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**Auto-GPT**或多或少是对它已经描述的内容的一个分类：'
- en: “An automated generative pretrained transformer”
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: “一种自动化生成预训练变换器”
- en: This means it automates GPT or ChatGPT. However, in this book, the main focus
    is on Auto-GPT by name. If you haven’t heard of it and just grabbed this book
    out of curiosity, then you’re in the right place!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着它自动化了GPT或ChatGPT。然而，在本书中，主要关注的是名为Auto-GPT的部分。如果你从未听说过它并且只是出于好奇拿起这本书，那你来对地方了！
- en: '**Auto-GPT** started as an experimental self-prompting AI application that
    is an attempt to create an autonomous system capable of creating “agents” to perform
    various specialized tasks to achieve larger objectives with minimal human input.
    It is based on OpenAI’s GPT and was developed by *Toran Bruce Richards*, who is
    better known by his GitHub handle *Significant Gravitas*.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**Auto-GPT**最初作为一个实验性的自我提示AI应用程序，试图创建一个自主系统，能够创建“代理”来执行各种专业任务，以最少的人类输入来实现更大的目标。它基于OpenAI的GPT，由*Toran
    Bruce Richards*开发，他在GitHub上更为人知的名字是*Significant Gravitas*。'
- en: Now, how does Auto-GPT think? Auto-GPT creates prompts that are fed to **large
    language models** (**LLMs**) and allows AI models to generate original content
    and execute command actions such as browsing, coding, and more. It represents
    a significant step forward in the development of autonomous AI, making it the
    fastest-growing open source project in GitHub’s history (at the time of writing).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，Auto-GPT是如何思考的呢？Auto-GPT创建了输入给**大语言模型**（**LLMs**）的提示，并允许AI模型生成原创内容和执行命令操作，如浏览、编码等。这代表着自主AI发展的重要一步，使它成为GitHub历史上增长最快的开源项目（截至本文写作时）。
- en: Auto-GPT strings together multiple instances of OpenAI’s language model – **GPT**
    – and by doing so creates so-called “agents” that are tasked with simplified tasks.
    These agents work together to accomplish complex goals, such as writing a blog,
    with minimal human intervention.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT将多个OpenAI语言模型——**GPT**——串联起来，通过这样做，它创建了所谓的“代理”，这些代理负责简化任务。这些代理共同协作，以最小的人类干预来完成复杂目标，例如撰写博客。
- en: Now, let’s talk about how it rose to fame.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来谈谈它是如何崭露头角的。
- en: From an experiment to one of the fastest-growing GitHub projects
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从一个实验到成为GitHub上增长最快的项目之一
- en: Auto-GPT was initially named **Entrepreneur-GPT** and was released on March
    16, 2023\. The initial goal of the project was to give GPT-4 autonomy to see if
    it could thrive in the business world and test its capability to make real-world
    decisions.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT最初被命名为**Entrepreneur-GPT**，并于2023年3月16日发布。该项目的初衷是赋予GPT-4自主权，看看它能否在商业领域中茁壮成长，并测试其做出现实决策的能力。
- en: For some time, the development of Auto-GPT remained mostly unnoticed until late
    March 2023\. However, on March 30, 2023, Significant Gravitas tweeted about the
    latest demo of Auto-GPT and posted a demo video, which began to gain traction.
    The real surge in interest came on April 2, 2023, when computer scientist Andrej
    Karpathy quoted one of Significant Gravitas’ tweets, saying that the next frontier
    of prompt engineering was Auto-GPT.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一段时间以来，Auto-GPT的开发几乎没有引起注意，直到2023年3月下旬。然而，2023年3月30日，Significant Gravitas在推特上发布了Auto-GPT最新演示的相关信息，并上传了一个演示视频，随后开始获得关注。真正引发关注的时刻是在2023年4月2日，计算机科学家Andrej
    Karpathy转发了Significant Gravitas的一条推文，并表示下一代提示工程的前沿就是Auto-GPT。
- en: This tweet went viral, and Auto-GPT became a subject of discussion on social
    media. One of the agents that was created by Auto-GPT, known as **ChaosGPT**,
    became particularly famous when it was humorously assigned the task of “destroying
    humanity,” which contributed to the viral nature of Auto-GPT ([https://decrypt.co/126122/meet-chaos-gpt-ai-tool-destroy-humanity](https://decrypt.co/126122/meet-chaos-gpt-ai-tool-destroy-humanity)).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这条推文迅速传播，Auto-GPT成为社交媒体讨论的话题。由Auto-GPT创建的一个代理，名为**ChaosGPT**，因被幽默地分配了“摧毁人类”的任务而特别出名，这也促使了Auto-GPT的病毒式传播（[https://decrypt.co/126122/meet-chaos-gpt-ai-tool-destroy-humanity](https://decrypt.co/126122/meet-chaos-gpt-ai-tool-destroy-humanity)）。
- en: 'Of course, we don’t want to destroy humanity; for a reference on what Entrepreneur-GPT
    can do, take a look at the old logs of Entrepreneur-GPT here:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们并不想摧毁人类；若想了解Entrepreneur-GPT能做什么，可以查看此处的Entrepreneur-GPT旧日志：
- en: '[https://github.com/Significant-Gravitas/Auto-GPT/blob/c6f61db06cde7bd766e521bf7df1dc0c2285ef73/](https://github.com/Significant-Gravitas/Auto-GPT/blob/c6f61db06cde7bd766e521bf7df1dc0c2285ef73/).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/Significant-Gravitas/Auto-GPT/blob/c6f61db06cde7bd766e521bf7df1dc0c2285ef73/](https://github.com/Significant-Gravitas/Auto-GPT/blob/c6f61db06cde7bd766e521bf7df1dc0c2285ef73/)'
- en: The more creative you are with your prompts and configuration, the more creative
    Auto-GPT will be. This will be covered in [*Chapter 2*](B21128_02.xhtml#_idTextAnchor028)
    when we run our first Auto-GPT instance together.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你在提示和配置上越有创意，Auto-GPT也会越具创造力。这部分将在[*第二章*](B21128_02.xhtml#_idTextAnchor028)中详细讲解，我们将一起运行第一个Auto-GPT实例。
- en: LLMs – the core of AI
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMs —— AI的核心
- en: Although Auto-GPT can be used with other LLMs, it best leverages the power of
    GPT-4, a state-of-the-art language model by OpenAI.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Auto-GPT 可以与其他 LLM 一起使用，但它最能发挥 GPT-4 的强大功能，GPT-4 是 OpenAI 的一款最先进的语言模型。
- en: It offers a huge advantage for users who don’t own a graphics card that can
    hold models such as GPT-4 equivalents. Although there are many 7-B and 13-B LLMs
    (**B** stands for **billion parameters**) that do compete with ChatGPT, they cannot
    hold enough context in each prompt to be useful or are just not stable enough.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于没有图形卡且无法容纳像 GPT-4 等模型的用户来说，它提供了巨大的优势。尽管有许多 7-B 和 13-B 的 LLMs（**B** 代表 **十亿参数**）与
    ChatGPT 相竞争，但它们无法在每个提示中保持足够的上下文，或者稳定性不足，无法实用。
- en: 'At the time of writing, GPT-4 and GPT-3.5-turbo are both used with Auto-GPT
    by default. Depending on the complexity of the situation, Auto-GPT differs between
    two types of models:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，GPT-4 和 GPT-3.5-turbo 都是 Auto-GPT 的默认设置。根据情况的复杂性，Auto-GPT 在两种模型之间做出选择：
- en: Smart model
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 智能模型
- en: Fast model
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速模型
- en: When does Auto-GPT use GPT-3.5-turbo and not GPT-4 all the time?
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在什么情况下，Auto-GPT 会使用 GPT-3.5-turbo 而不是一直使用 GPT-4？
- en: When Auto-GPT goes through its thought process, it uses the *fast model*. For
    example, as Auto-GPT loops through its thoughts, it uses the configured fast model,
    but when it summarizes the content of a website or writes code, it will decide
    to use the smart model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Auto-GPT 进行思考时，它使用 *快速模型*。例如，当 Auto-GPT 循环思考时，它使用配置好的快速模型，但在总结网站内容或编写代码时，它会选择使用智能模型。
- en: The default for the fast model is GPT-3.5-turbo. Although it isn’t as precise
    as GPT-4, its response time is much better, leading to a more fluent response
    time; GPT-4 can seem stuck if it thinks for too long.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 快速模型的默认设置是 GPT-3.5-turbo。尽管它不如 GPT-4 精确，但它的响应时间更快，从而导致更流畅的响应时间；而 GPT-4 如果思考时间过长，可能会卡住。
- en: OpenAI has also added new functionalities to assist applications such as Auto-GPT.
    One of them is the *ability to call functions*. Before this new feature, Auto-GPT
    had to explain to GPT what a command is and how to formulate it correctly in text.
    This resulted in many errors as GPT sometimes decides to change the syntax of
    the output that’s expected. This was a huge step forward as this feature now reduces
    the complexity of how commands are communicated and executed. This empowers GPT
    to better understand what the context of each task is.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI 还为 Auto-GPT 等应用程序添加了新功能。其中之一是 *调用函数的能力*。在这个新功能出现之前，Auto-GPT 必须向 GPT 解释命令是什么以及如何正确地以文本形式表达它。这样就会出现许多错误，因为
    GPT 有时会决定更改预期的输出语法。这是一个巨大的进步，因为这个功能现在减少了命令的沟通和执行的复杂性，使得 GPT 更好地理解每个任务的上下文。
- en: 'So, why don’t we use an LLM directly? Because LLMs are only responsive:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么我们不直接使用 LLM 呢？因为 LLM 只是响应型的：
- en: They cannot fulfill any tasks
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们不能执行任何任务。
- en: Their knowledge is fixed, and they cannot update it themselves
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们的知识是固定的，无法自我更新。
- en: They don’t remember anything; only frameworks that run them can do it
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们不会记住任何事情；只有运行它们的框架可以做到这一点。
- en: How does Auto-GPT make use of LLMs?
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Auto-GPT 如何利用 LLM？
- en: 'Auto-GPT is structured in a way that it takes in an initial prompt from the
    user via the terminal:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT 的结构是通过终端从用户那里获取初始提示：
- en: '![Figure 1.1 – Letting Auto-GPT define its role](img/B21128_01_1.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.1 – 让 Auto-GPT 定义其角色](img/B21128_01_1.jpg)'
- en: Figure 1.1 – Letting Auto-GPT define its role
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1 – 让 Auto-GPT 定义其角色
- en: 'Here, you can either define a main task or enter `–-manual` to then answer
    questions, as shown here:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以定义一个主要任务，或者输入 `–-manual` 然后回答问题，如下所示：
- en: '![Figure 1.2 – Setting Auto-GPT’s main goals](img/B21128_01_2.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.2 – 设置 Auto-GPT 的主要目标](img/B21128_01_2.jpg)'
- en: Figure 1.2 – Setting Auto-GPT’s main goals
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2 – 设置 Auto-GPT 的主要目标
- en: 'The main prompt is then saved as an `ai_settings.yaml` file that may look like
    this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将主要提示保存为 `ai_settings.yaml` 文件，内容可能如下所示：
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let’s look at some of the AI components in the preceding file:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看前面文件中的一些 AI 组件：
- en: First, we have `ai_goals`, which specifies the main tasks that Auto-GPT must
    undertake. It will use those to decide which individual steps to take. Each iteration
    will decide to follow one of the goals.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们有 `ai_goals`，它指定了 Auto-GPT 必须承担的主要任务。它将使用这些任务来决定采取哪些具体步骤。每次迭代时，Auto-GPT
    会选择一个目标来执行。
- en: Then, we have `ai_name`, which is also taken as a reference and defines parts
    of the behavior or character of the bot. This means that if you call it *AuthorGPT*,
    it will play the role of a GPT-based author, while if you call it *Author*, it
    will try to behave like a person. It is generally hard to tell how it will behave
    because GPT mostly decides what it puts out on its own.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接着，我们有了`ai_name`，它也被作为参考来定义机器人行为或个性的一部分。这意味着，如果你称它为*AuthorGPT*，它将扮演一个基于GPT的作者角色，而如果你称它为*Author*，它将尝试像一个人一样表现。通常很难判断它会如何表现，因为GPT大多数时候是根据自己的决定来生成内容的。
- en: Finally, we have `ai_role`, which can be viewed as a more detailed role description.
    However, in my experience, it only nudges the thoughts slightly. Goals are more
    potent here.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们有了`ai_role`，可以将其视为更详细的角色描述。然而，根据我的经验，它只会稍微推动思维。目标在这里更具影响力。
- en: 'Once this is done, it summarizes what it’s going to do and starts thinking
    correctly:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成，它会总结要做的事情并开始正确思考：
- en: '![Figure 1.3 – Example of Auto-GPT’s thought process](img/B21128_01_3.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图1.3 – Auto-GPT思维过程示例](img/B21128_01_3.jpg)'
- en: Figure 1.3 – Example of Auto-GPT’s thought process
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3 – Auto-GPT思维过程示例
- en: Thinking generally means that it is sending a chat completion request to the
    LLM.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 思考通常意味着它正在向LLM发送聊天完成请求。
- en: This process can be slow – the more tokens that are used, the more processing
    that’s needed. In the *Understanding tokens in LLMs* section, we will take a look
    at what this means.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可能很慢——使用的令牌越多，需要的处理时间越长。在*理解LLM中的令牌*一节中，我们将看看这意味着什么。
- en: Once Auto-GPT has started “thinking,” it initiates a sequence of AI “conversations.”
    During these conversations, it forms a query, sends it to the LLM, and then processes
    the response. This process repeats until it finds a satisfactory solution or reaches
    the end of its thinking time.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦Auto-GPT开始“思考”，它就会启动一系列的AI“对话”。在这些对话中，它形成一个查询，发送给LLM，然后处理回应。这个过程会不断重复，直到找到一个满意的解决方案或达到思考时间的上限。
- en: 'This entire process produces thoughts. These fall into the following categories:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程产生了思维，这些思维可以分为以下几类：
- en: Reasoning
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推理
- en: Planning
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规划
- en: Criticism
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批评
- en: Speak
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 说话
- en: Command
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命令
- en: These individual thoughts are then displayed in the terminal and the user is
    asked whether they want to approve the command or not – it’s that simple.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，这些独立的思维会显示在终端上，用户会被询问是否批准该命令——就是这么简单。
- en: Of course, a lot more goes on here, including a prompt being built to create
    that response.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这里发生了更多的事情，包括构建一个提示语来生成回应。
- en: 'Simply put, Auto-GPT passes the name, role, goals, and some background information.
    You can see an example here: [https://github.com/PacktPublishing/Unlocking-the-Power-of-Auto-GPT-and-Its-Plugins/blob/main/Auto-GPT_thoughts_example.md](https://github.com/PacktPublishing/Unlocking-the-Power-of-Auto-GPT-and-Its-Plugins/blob/main/Auto-GPT_thoughts_example.md).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，Auto-GPT传递了名称、角色、目标和一些背景信息。你可以在这里看到一个示例：[https://github.com/PacktPublishing/Unlocking-the-Power-of-Auto-GPT-and-Its-Plugins/blob/main/Auto-GPT_thoughts_example.md](https://github.com/PacktPublishing/Unlocking-the-Power-of-Auto-GPT-and-Its-Plugins/blob/main/Auto-GPT_thoughts_example.md)。
- en: Auto-GPT’s thought process – understanding the one-shot action
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Auto-GPT的思维过程——理解一-shot动作
- en: 'Let’s understand the thought process behind this one-shot action:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们理解一下这个一-shot动作背后的思维过程：
- en: '**Overview of the thought process**: Auto-GPT operates on a one-shot action
    basis. This approach involves processing each data block that’s sent to OpenAI
    as a single chat completion action. The outcome of this process is that a response
    text from GPT is generated that’s crafted based on a specified structure.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**思维过程概述**：Auto-GPT基于一-shot动作进行操作。这个方法涉及将发送给OpenAI的每一个数据块作为一个单独的聊天完成动作进行处理。这个过程的结果是生成一个基于指定结构的GPT响应文本。'
- en: '**Structure and task definition for GPT**: The structure that’s provided to
    GPT encompasses both the task at hand and the format for the response. This dual-component
    structure ensures that GPT’s responses are not only relevant but also adhere to
    the expected conversational format.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT的结构和任务定义**：提供给GPT的结构既包括当前任务，也包括响应格式。这个双重组件的结构确保了GPT的回应不仅相关，而且遵循预期的对话格式。'
- en: '**Role assignment in Auto-GPT**: There are two role assignments here:'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Auto-GPT中的角色分配**：这里有两个角色分配：'
- en: '**System role**: The “system” role is crucial in providing context. It functions
    as a vessel for information delivery and maintains the historical thread of the
    conversation with the LLM.'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统角色**：“系统”角色在提供上下文中起着关键作用。它充当信息传递的载体，并维护与LLM的对话历史。'
- en: '**User role**: Toward the end of the process, a “user” role is assigned. This
    role is pivotal in guiding GPT to determine the subsequent command to execute.
    It adheres to a predefined format, ensuring consistency in interactions.'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户角色**：在过程的末尾，分配了一个“用户”角色。这个角色在引导GPT确定接下来的命令执行时至关重要。它遵循预定义的格式，确保交互的一致性。'
- en: '`ask_user`)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ask_user`)'
- en: Sending messages (`send_message`)
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发送消息（`send_message`）
- en: Browsing (`browse`)
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 浏览（`browse`）
- en: Executing code (`execute_code`)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行代码（`execute_code`）
- en: In some instances, Auto-GPT may opt not to select any command. This typically
    occurs in situations of confusion, such as when the provided task is unclear or
    when Auto-GPT completes a task and requires user feedback for further action.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，Auto-GPT可能选择不选择任何命令。这通常发生在困惑的情况下，例如当提供的任务不清楚，或者当Auto-GPT完成任务并需要用户反馈以采取进一步行动时。
- en: Either way, each response is only one text and just a text that is being autocompleted,
    meaning the LLM only responds once with such a response.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，每个回应只是一次文本，而且仅仅是正在自动完成的文本，意味着LLM仅在一次回应中提供这样的答案。
- en: 'In the following example, I have the planner plugin activated; more on plugins
    later:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我启用了规划插件；稍后会详细介绍插件：
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Each thought property is then displayed to the user and the “speak” output
    is read aloud if text-to-speech is enabled:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 每个思考属性随后会显示给用户，并且如果启用了语音合成，“说话”输出会被朗读出来：
- en: '[PRE2]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The user can now respond in one of the following ways:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 用户现在可以通过以下方式之一进行回应：
- en: '`y`: To accept the execution.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y`：接受执行。'
- en: '`n`: To decline the execution and close Auto-GPT.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n`：拒绝执行并关闭Auto-GPT。'
- en: '`s`: To let Auto-GPT re-evaluate its decisions.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s`：让Auto-GPT重新评估其决定。'
- en: '`y -n`: To tell Auto-GPT to just keep going for the number of steps (for example,
    enter `y -5` to allow it to run on its own for 5 steps). Here, `n` is always a
    number.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y -n`：告诉Auto-GPT继续进行若干步骤（例如，输入`y -5`，允许它自行运行5步）。其中，`n`始终是一个数字。'
- en: 'If the user confirms, the command is executed and the result of that command
    is added as system content:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用户确认，命令将被执行，并且该命令的结果将作为系统内容添加：
- en: '[PRE3]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: At this point, you’re probably wondering what history is in this context and
    why `self`?
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你可能会想知道在这个上下文中“历史”是什么，为什么是`self`？
- en: Auto-GPT uses agents and the instance of the agent has its own history that
    acts as a short-term memory. It contains the context of what the previous messages
    and results were.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT使用代理，并且代理的实例拥有自己的历史，这充当短期记忆。它包含了之前消息和结果的上下文。
- en: The history is trimmed down on every run cycle of the agent to make sure it
    doesn’t reach its token limit.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 每次运行代理时，历史记录会被精简，以确保它不会超过令牌限制。
- en: 'So, why not directly ask the LLM for a solution? There are several reasons
    for this:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么不直接要求LLM提供解决方案呢？这样做有几个原因：
- en: While LLMs are incredibly sophisticated, they cannot solve complex, multi-step
    problems in a single query. Instead, they need to be asked a series of interconnected
    questions that guide them toward a final solution. This is where Auto-GPT shines
    – it can strategically ask these questions and digest the responses.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管大语言模型（LLMs）非常复杂，但它们无法在一次查询中解决复杂的多步骤问题。相反，它们需要通过一系列相互关联的问题来引导它们走向最终解决方案。这就是Auto-GPT的优势所在——它可以战略性地提出这些问题并处理答案。
- en: LLMs can’t maintain their context. They don’t remember previous queries or answers,
    which means they cannot build on past knowledge to answer future questions. Auto-GPT
    compensates for this by maintaining a history of the conversation, allowing it
    to understand the context of previous queries and responses and use that information
    to craft new queries.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs无法保持上下文。它们不会记住之前的查询或答案，这意味着它们无法基于过去的知识回答未来的问题。Auto-GPT通过维护对话历史来弥补这一点，使其能够理解先前查询和回应的上下文，并利用这些信息来构建新的查询。
- en: While LLMs are powerful tools for generating human-like text, they cannot take
    initiative. They respond to prompts but don’t actively seek out new tasks or knowledge.
    Auto-GPT, on the other hand, is designed to be more proactive. It not only responds
    to the tasks that have been assigned to it but also proactively explores diverse
    ways to accomplish those tasks, making it a true autonomous agent.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然LLM是生成类人文本的强大工具，但它们不能主动行动。它们响应提示，但不会主动寻找新的任务或知识。而Auto-GPT则被设计得更加主动。它不仅响应已分配给它的任务，还主动探索完成这些任务的多种方式，使其成为真正的自主代理。
- en: 'Before we delve deeper into how Auto-GPT utilizes LLMs, it’s important to understand
    a key component of how these models process information: **tokens**.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解Auto-GPT如何利用LLM之前，理解这些模型如何处理信息的一个关键组成部分非常重要：**令牌**。
- en: Understanding tokens in LLMs
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解LLM中的令牌
- en: Tokens are the fundamental building blocks in LLMs such as GPT-3 and GPT-4\.
    They are pieces of knowledge that vary in proximity to each other based on the
    given context. A token can represent a word, a symbol, or even fragments of words.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌是LLM（如GPT-3和GPT-4）中的基本构建块。它们是知识的单元，基于给定的上下文，它们之间的接近程度可能有所不同。一个令牌可以表示一个单词、一个符号，甚至是单词的碎片。
- en: Tokenization in language processing
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言处理中的分词
- en: 'When training LLMs, text data is broken down into smaller units, or tokens.
    For instance, the sentence “ChatGPT is great!” would be divided into tokens such
    as `["ChatGPT", "is", "great", "!"]`. The nature of a token can differ significantly
    across languages and coding paradigms:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练LLM时，文本数据被分解为更小的单元，或称为令牌。例如，句子“ChatGPT is great!”会被分解为`["ChatGPT", "is",
    "great", "!"]`等令牌。令牌的性质在不同语言和编码范式之间可能有很大不同：
- en: In English, a token typically signifies a word or part of a word
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在英语中，令牌通常表示一个单词或部分单词。
- en: In other languages, a token may represent a syllable or a character
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在其他语言中，令牌可能表示音节或字符。
- en: In programming languages, tokens can include keywords, operators, or variables
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在编程语言中，令牌可以包括关键字、运算符或变量。
- en: 'Let’s look at some examples of tokenization:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些分词的例子：
- en: '`["ChatGPT", "is", "``great", "!"]`.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`["ChatGPT", "is", "``great", "!"]`。'
- en: '`print("Hello, World!")` is tokenized as `["print", "(", " ", "Hello", ","
    , " ", "World", "!"", ")"]`.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`print("Hello, World!")` 被分词为 `["print", "(", " ", "Hello", "," , " ", "World",
    "!"", ")"]`。'
- en: Balancing detail and computational resources
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平衡细节与计算资源
- en: Tokenization strategies aim to balance detail and computational efficiency.
    More tokens provide greater detail but require more resources for processing.
    This balance is crucial for the model’s ability to understand and generate text
    at a granular level.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 分词策略旨在平衡细节与计算效率。更多的令牌提供更大的细节，但需要更多的资源来处理。这种平衡对模型在更细致的层面上理解和生成文本至关重要。
- en: Token limits in LLMs
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LLM中的令牌限制
- en: The token limit signifies the maximum number of tokens that a model such as
    GPT-3 or GPT-4 can handle in a single interaction. This limit is in place due
    to the computational resources needed to process large numbers of tokens.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌限制表示模型（如GPT-3或GPT-4）在一次交互中可以处理的最大令牌数。设定此限制是因为处理大量令牌所需的计算资源。
- en: The token limit also influences the model’s “attention” capability – its ability
    to prioritize different parts of the input during output generation.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌限制还会影响模型的“注意力”能力——它在输出生成过程中优先处理输入的不同部分的能力。
- en: Implications of token limits
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 令牌限制的影响
- en: A model with a token limit may not fully process inputs that exceed this limit.
    For example, with a 20-token limit, a 30-token text would need to be broken into
    smaller segments for the model to process them effectively.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 一个具有令牌限制的模型可能无法完全处理超过该限制的输入。例如，若令牌限制为20，30个令牌的文本需要分成更小的片段才能有效地处理。
- en: In programming, tokenization aids in understanding code structure and syntax,
    which is vital for tasks such as code generation or interpretation.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在编程中，分词有助于理解代码结构和语法，这对于代码生成或解释等任务至关重要。
- en: In summary, tokenization is a critical component in **natural language processing**
    (**NLP**), enabling LLMs to interpret and generate text in a meaningful and contextually
    accurate manner.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，分词是**自然语言处理**（**NLP**）中的一个关键组成部分，使大语言模型能够以有意义且上下文准确的方式解读和生成文本。
- en: For instance, if you’re using the model to generate Python code and you input
    `["print", "("]` as a token, you’d expect the model to generate tokens that form
    a valid argument to the print function – for example, `[""Hello,` `World!"", ")"]`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你使用该模型来生成 Python 代码，并将`["print", "("]`作为输入令牌，你会期望模型生成一个有效的参数，以便传递给 `print`
    函数——例如，`[""Hello,` `World!"", ")"]`。
- en: In the following chapters, we will delve deeper into how Auto-GPT works, its
    capabilities, and how you can use it to solve complex problems or automate tasks.
    We will also cover its plugins, which extend its functionality and allow it to
    interact with external systems so that it can order a pizza, for instance.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将深入探讨 Auto-GPT 的工作原理、其能力，以及如何使用它来解决复杂问题或自动化任务。我们还将介绍它的插件，扩展了其功能，并使其能够与外部系统互动，例如它能够点外卖披萨。
- en: In a nutshell, Auto-GPT is like a very smart, very persistent assistant that
    leverages the power of the most advanced AI to accomplish the goals you set for
    it. Whether you’re an AI researcher, a developer, or simply someone who is fascinated
    by the potential of AI, I hope this book will provide you with the knowledge and
    inspiration you need to make the most of Auto-GPT.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，Auto-GPT 就像一个非常智能、非常执着的助手，利用最先进的 AI 技术来完成你为它设定的目标。无论你是 AI 研究员、开发者，还是单纯对
    AI 潜力感到着迷的人，我希望这本书能为你提供你需要的知识和灵感，帮助你最大限度地利用 Auto-GPT。
- en: At the time of writing (June 1, 2023), Auto-GPT can give you feedback not only
    through the terminal. There are a variety of text-to-speech engines that are currently
    built into Auto-GPT. Depending on what you prefer, you can either use the default,
    which is Google’s text-to-speech option, ElevenLabs, macOS’ `say` command (a low-quality
    Siri voice pack), or Silero TTS.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在写作时（2023年6月1日），Auto-GPT 不仅可以通过终端提供反馈。现在有多种文本转语音引擎已内置于 Auto-GPT 中。根据你的喜好，你可以选择默认的
    Google 文本转语音选项、ElevenLabs、macOS 的 `say` 命令（一个低质量的 Siri 语音包），或 Silero TTS。
- en: When it comes to plugins, Auto-GPT becomes even more powerful. Currently, there
    is an official repository for plugins that contains a list of awesome plugins
    such as Planner Plugin, Discord, Telegram, Text Generation for local or different
    LLMs, and more.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在插件方面，Auto-GPT 变得更加强大。目前，官方插件仓库中列出了许多令人赞叹的插件，如 Planner 插件、Discord、Telegram、本地或不同
    LLM 的文本生成插件等。
- en: This modularity makes Auto-GPT the most exciting thing I’ve ever laid my hands
    on.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模块化使得 Auto-GPT 成为我接触过的最令人兴奋的事物。
- en: Launching and advancing Auto-GPT – a story of innovation and community
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推出并推进 Auto-GPT——创新与社区的故事
- en: Auto-GPT’s development began with a bold vision to make the sophisticated technology
    of GPT-4 accessible and user-friendly. This initiative marked the start of an
    ongoing journey, with the project continually evolving through the integration
    of new features and improvements. At its core, Auto-GPT is a collaborative effort,
    continuously shaped by the input of a dedicated community of developers and researchers.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT 的开发始于一个大胆的愿景：使 GPT-4 的复杂技术变得更加易于访问和用户友好。这一举措标志着一个持续不断的旅程的开始，该项目通过不断整合新特性和改进而不断发展。在其核心，Auto-GPT
    是一个合作性的努力，持续受到开发者和研究人员社区贡献的推动。
- en: The genesis of Auto-GPT can be traced back to the discovery of GPT-4’s potential
    for autonomous task completion. This breakthrough was the catalyst for creating
    a platform that could fully utilize GPT-4’s capabilities, offering users extensive
    control and customization options.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT 的起源可以追溯到发现 GPT-4 在自动任务完成方面的潜力。这一突破成为创建一个能够充分利用 GPT-4 能力的平台的催化剂，提供给用户广泛的控制和自定义选项。
- en: 'The project gained initial popularity with an early version known as *Entrepreneur-GPT*,
    a key milestone that showcased Auto-GPT’s capabilities at the time. This phase
    of the project (documented here:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 该项目最初通过一个早期版本 *Entrepreneur-GPT* 获得了关注，这是一个关键的里程碑，展示了当时 Auto-GPT 的能力。项目的这一阶段（详见：
- en: '[https://github.com/PacktPublishing/Unlocking-the-Power-of-Auto-GPT-and-Its-Plugins/blob/main/Entrepreneur-GPT.md](https://github.com/PacktPublishing/Unlocking-the-Power-of-Auto-GPT-and-Its-Plugins/blob/main/Entrepreneur-GPT.md))
    indicates the differences in prompts and functionalities compared to later stages.
    A review of the git history reveals Auto-GPT’s early abilities, including online
    research and using a local database for long-term memory.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Unlocking-the-Power-of-Auto-GPT-and-Its-Plugins/blob/main/Entrepreneur-GPT.md](https://github.com/PacktPublishing/Unlocking-the-Power-of-Auto-GPT-and-Its-Plugins/blob/main/Entrepreneur-GPT.md)
    显示了与后期阶段相比，提示和功能的差异。通过回顾 Git 历史，可以了解 Auto-GPT 早期的功能，包括在线研究和使用本地数据库进行长期记忆。'
- en: The ascent of Auto-GPT was swift, attracting contributors – including myself
    – early in its development. My experience with this open source project was transformative,
    offering an addictive blend of passion and excitement for innovation. The dedication
    of the contributors brought a sense of pride, especially when you can see your
    work recognized by a wider audience, including popular YouTubers.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT 的崛起非常迅速，吸引了许多贡献者——包括我自己——在其开发的早期阶段就参与其中。我在这个开源项目中的经历是变革性的，提供了一种令人上瘾的激情与创新兴奋的结合。贡献者们的奉献精神带来了自豪感，尤其是当你看到自己的工作被更广泛的受众认可时，包括一些流行的
    YouTube 博主。
- en: As an open source project, Auto-GPT thrived on voluntary contributions, leading
    to the formation of a team that significantly enhanced its structure. This team
    played a crucial role in managing incoming pull requests and guiding the development
    paths, thereby continually improving Auto-GPT’s core.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个开源项目，Auto-GPT 依赖于志愿者的贡献，形成了一个显著增强其结构的团队。这个团队在管理传入的拉取请求和指导开发路径方面发挥了重要作用，从而不断改进
    Auto-GPT 的核心。
- en: Despite its growing popularity, each new release of Auto-GPT brought enhanced
    power and functionality. These releases are stable versions that are meticulously
    tested by the community to ensure they are bug-free and ready for public use.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管其人气不断上升，但每次 Auto-GPT 发布的新版本都带来了更强大的功能。这些版本是经过社区精心测试的稳定版本，确保没有 bug，并准备好供公众使用。
- en: A critical component of Auto-GPT’s evolution is its plugins. These play a major
    role in the customization of the platform, allowing users to tailor it to their
    specific needs. Future discussions will delve deeper into these plugins and will
    explore their installation, usage, and impact on enhancing Auto-GPT’s capabilities.
    This exploration is vital as most customization happens through plugins unless
    significant contributions are made directly to the core platform through pull
    requests.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: Auto-GPT 进化的一个关键组成部分是其插件。这些插件在平台的定制中起着重要作用，使用户能够根据自身需求进行调整。未来的讨论将深入探讨这些插件，并将探索其安装、使用以及对提升
    Auto-GPT 功能的影响。这一探索至关重要，因为大多数定制工作都是通过插件实现的，除非通过拉取请求对核心平台做出重大贡献。
- en: Introduction to LangChain
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangChain简介
- en: Although *LangChain* itself is not part of Auto-GPT, it is a crucial component
    of Auto-GPT’s development as it focuses on the process using control. This is
    in contrast to Auto-GPT’s emphasis on results without control.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 *LangChain* 本身并不是 Auto-GPT 的一部分，但它是 Auto-GPT 开发中的关键组成部分，因为它专注于使用控制的过程。这与
    Auto-GPT 强调没有控制的结果相对立。
- en: LangChain is a powerful tool that enables users to build implementations of
    their own Auto-GPT using LLM primitives. It allows for explicit reasoning and
    the potential for Auto-GPT to become an autonomous agent.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 是一个强大的工具，使用户能够利用 LLM 原语构建自己的 Auto-GPT 实现。它支持显式推理，并使 Auto-GPT 有可能成为一个自主代理。
- en: With multiple alternatives of Auto-GPT arising, LangChain has become a part
    of many of them. One such example is AgentGPT.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 随着多个 Auto-GPT 替代方案的出现，LangChain 已成为其中许多方案的一部分。其中一个例子是 AgentGPT。
- en: LangChain’s unique approach to language processing and control makes it an essential
    part of AgentGPT’s functionality. By combining the strengths of LangChain and
    Auto-GPT, users can create powerful, customized solutions that leverage the full
    potential of GPT.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 在语言处理和控制方面的独特方法使其成为 AgentGPT 功能的重要组成部分。通过将 LangChain 和 Auto-GPT 的优势结合起来，用户可以创建强大且定制的解决方案，充分发挥
    GPT 的潜力。
- en: The intersection of LangChain and Auto-GPT
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LangChain与Auto-GPT的交集
- en: LangChain and Auto-GPT may have different areas of focus, but their shared goal
    of enhancing the capabilities of LLMs creates a natural synergy between them.
    LangChain’s ability to provide a structured, controllable process pairs well with
    Auto-GPT’s focus on autonomous task completion. Together, they provide an integrated
    solution that both controls the method and achieves the goal, striking a balance
    between the process and the result.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 和 Auto-GPT 可能有不同的侧重点，但它们共同的目标是增强 LLM（大语言模型）的能力，这种目标使得它们之间形成了天然的协同作用。LangChain
    提供结构化、可控的过程，与 Auto-GPT 专注于自动化任务完成相得益彰。二者结合，提供了一个集成的解决方案，既控制了方法，又实现了目标，在过程和结果之间取得了平衡。
- en: LangChain enables the explicit reasoning potential within Auto-GPT. It provides
    a pathway to transition the model from being a tool for human-directed tasks to
    a self-governing agent capable of making informed, reasoned decisions.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain 使得在 Auto-GPT 中明确推理的潜力得以实现。它提供了一条路径，将模型从一个由人类指引的工具，转变为一个能够做出明智且有理性决策的自主管理代理。
- en: In addition, LangChain’s control over language processing enhances Auto-GPT’s
    ability to communicate user-friendly information in JSON format, making it an
    even more accessible platform for users. By optimizing language processing and
    control, LangChain significantly improves Auto-GPT’s interaction with users.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，LangChain 对语言处理的控制增强了 Auto-GPT 在 JSON 格式中传达用户友好信息的能力，使其成为一个对用户更为友好的平台。通过优化语言处理和控制，LangChain
    显著提高了 Auto-GPT 与用户的互动体验。
- en: 'You can read more about it: [https://docs.langchain.com/docs/](https://docs.langchain.com/docs/).'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以阅读更多内容：[https://docs.langchain.com/docs/](https://docs.langchain.com/docs/)。
- en: Summary
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we embarked on the exciting journey of exploring Auto-GPT,
    an innovative AI application that leverages the power of GPT-4 to autonomously
    solve tasks and operate in a browser environment. We delved into the history of
    Auto-GPT, understanding how it evolved from an ambitious experiment to a powerful
    tool that’s transforming the way we interact with AI.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们开始了探索 Auto-GPT 这一创新 AI 应用的激动人心的旅程。Auto-GPT 利用 GPT-4 的强大能力，能够自主解决任务并在浏览器环境中运行。我们深入了解了
    Auto-GPT 的历史，理解了它如何从一个雄心勃勃的实验演变成一个正在改变我们与 AI 互动方式的强大工具。
- en: We also explored the concept of tokens, which play a crucial role in how LLMs
    such as GPT-4 process information. Understanding this fundamental concept will
    help us better comprehend how Auto-GPT interacts with LLMs to generate meaningful
    and contextually relevant responses.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还探讨了令牌（tokens）的概念，令牌在像 GPT-4 这样的 LLM 处理信息时起着至关重要的作用。理解这个基本概念将帮助我们更好地理解 Auto-GPT
    如何与 LLM 交互，从而生成有意义且符合上下文的响应。
- en: Furthermore, we touched on the role of LangChain, a tool that complements Auto-GPT
    by providing structured control over language processing. The intersection of
    LangChain and Auto-GPT creates a powerful synergy, enhancing the capabilities
    of Auto-GPT and paving the way for more advanced AI applications.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还讨论了 LangChain 的角色，这是一种通过提供对语言处理的结构化控制，来补充 Auto-GPT 的工具。LangChain 和 Auto-GPT
    的交集创造了强大的协同效应，增强了 Auto-GPT 的能力，并为更高级的 AI 应用铺平了道路。
- en: As we move forward, we will dive deeper into the workings of Auto-GPT, exploring
    its plugins, installation process, and how to craft effective prompts. We will
    also delve into more advanced topics, such as integrating your own LLM with Auto-GPT,
    setting up Docker, and safely and effectively using continuous mode.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续前进，我们将深入研究 Auto-GPT 的工作原理，探索它的插件、安装过程以及如何制定有效的提示语。我们还将深入探讨更高级的话题，例如如何将你自己的
    LLM 集成到 Auto-GPT 中，如何设置 Docker，以及如何安全有效地使用持续模式。
- en: Whether you’re an AI enthusiast, a developer, or simply someone curious about
    the potential of AI, this journey promises to be a fascinating one. So, buckle
    up, and let’s continue to unravel the immense potential of Auto-GPT together!
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是 AI 爱好者、开发者，还是仅仅对 AI 潜力充满好奇的人，这段旅程都将会是一次引人入胜的经历。所以，系好安全带，让我们继续一起揭开 Auto-GPT
    巨大潜力的面纱！
