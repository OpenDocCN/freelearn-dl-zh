- en: '*Chapter 3*: Contextual Bandits'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第3章*：上下文赌博机'
- en: A more advanced version of the multi-armed bandit is the **contextual bandit**
    (**CB**) problem, where decisions are tailored to the context they are made in.
    In the previous chapter, we identified the best-performing ad in an online advertising
    scenario. In doing so, we did not use any information about, for instance, the
    user persona, age, gender, location, or previous visits, which would have increased
    the likelihood of a click. CBs allow us to leverage this information, which means,
    they play a role in central role in commercial personalization and recommendation
    applications.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 多臂赌博机的一个更高级版本是**上下文赌博机**（**CB**）问题，在这种问题中，决策是根据所处的上下文量身定制的。在上一章中，我们识别了在线广告场景中表现最佳的广告。在此过程中，我们没有使用任何关于用户的人物特征、年龄、性别、位置或之前访问的信息，而这些信息本应增加点击的可能性。CB允许我们利用这些信息，这意味着它们在商业个性化和推荐应用中起着核心作用。
- en: Context is similar to state in a multi-step **reinforcement** **learning** (**RL**)
    problem, with one key difference. In a multi-step RL problem, the action an agent
    takes, affects the states it is likely to visit in the subsequent steps. For example,
    when playing tic-tac-toe, an agent's action in the current state changes the board
    configuration (state) in a particular way, which then affects what actions the
    opponent can take, and so on. In CB problems, however, the agent simply observes
    the context, makes a decision, and observes the reward. The next context the agent
    will observe does not depend on the current context/action. This setup, although
    simpler than multi-step RL, occurs in a very broad set of applications. So, you
    will add a key tool to your arsenal with what we cover in this chapter.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文类似于多步**强化学习**（**RL**）问题中的状态，唯一的区别是。在多步RL问题中，智能体采取的动作会影响它在后续步骤中可能访问的状态。例如，在玩井字棋时，智能体在当前状态下的动作会以某种方式改变棋盘配置（状态），这会影响对手可以采取的动作，依此类推。然而，在CB问题中，智能体只是观察上下文，做出决策，并观察奖励。智能体接下来会观察到的上下文并不依赖于当前的上下文/动作。这个设置虽然比多步RL简单，但在许多应用中都有出现。因此，本章内容将为你添加一个重要的工具。
- en: 'We will continue to solve different versions of the online advertising problem,
    using more advanced tools, such as neural networks, together with CB models. Specifically,
    in this chapter, you will learn about the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续解决不同版本的在线广告问题，使用更先进的工具，如神经网络，与CB模型一起使用。具体而言，在本章中，你将学习以下内容：
- en: Why we need function approximations
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么我们需要函数逼近
- en: Using function approximations for context
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用函数逼近来处理上下文
- en: Using function approximations for actions
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用函数逼近来处理动作
- en: Other applications of multi-armed bandits and CBs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多臂赌博机和CB的其他应用
- en: Why we need function approximations
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么我们需要函数逼近
- en: 'While solving (contextual) multi-armed bandit problems, our goal is to learn
    action values for each arm (action) from our observations, which we have denoted
    by ![](img/Formula_03_001.png). In the online advertising example, it represented
    our estimate for the probability of a user clicking the ad if we displayed ![](img/Formula_03_002.png).
    Now, assume that we have two pieces of information about the user seeing the ad,
    namely the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决（上下文）多臂赌博机问题时，我们的目标是从观察中学习每个臂（动作）的行动值，我们将其表示为 ![](img/Formula_03_001.png)。在在线广告的例子中，它代表了我们对用户点击广告的概率的估计，如果我们展示了
    ![](img/Formula_03_002.png)。现在，假设我们对看到广告的用户有两条信息，分别如下：
- en: Device type (mobile or desktop)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设备类型（手机或台式机）
- en: Location (domestic/US or international/non-US)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 位置（国内/美国或国际/非美国）
- en: It is quite likely that ad performances will differ by device type and location,
    which make up the context in this example. A CB model will therefore leverage
    this information, estimate the action values for each context, and choose the
    actions accordingly.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 广告表现很可能会因设备类型和位置的不同而有所差异，这些差异构成了这个例子中的上下文。因此，CB模型将利用这些信息，估计每个上下文的行动值，并相应地选择行动。
- en: 'This would look like filling in a table for each ad similar to the following:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来像是为每个广告填写一个类似于以下内容的表格：
- en: '![Table 3.1 – Sample action values for ad D'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '![表格 3.1 – 广告D的样本行动值'
- en: '](img/Table_3.1.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Table_3.1.jpg)'
- en: Table 3.1 – Sample action values for ad D
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 表格3.1 – 广告D的样本行动值
- en: 'This means solving four MAB problems, one for each context:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着解决四个MAB问题，每个上下文一个：
- en: Mobile – Domestic
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手机 – 国内
- en: Mobile – International
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手机 – 国际
- en: Desktop – Domestic
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 台式机 – 国内
- en: Desktop – International
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 台式机 – 国际
- en: 'While this could work fine in this simple example, think about what happens
    when you add additional information to the context, for example, age. This introduces
    a number of challenges:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在这个简单的例子中可以正常工作，但考虑到当你将额外的信息（例如年龄）添加到上下文中时会发生什么，这就引入了许多挑战：
- en: First, we may not have enough observations to (accurately) learn action values
    for each context (Mobile, International, 57). However, we want to be able to cross-learn
    and estimate the action values (or improve the estimate) for a 57-year-old user
    if we have data on users of close ages.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们可能没有足够的观察数据来（准确地）学习每个上下文的动作值（例如：移动设备、国际、57岁）。然而，我们希望能够进行跨学习，并且如果我们有接近年龄的用户数据，就可以估计57岁用户的动作值（或者改进该估计）。
- en: Second, the number of possible contexts increases by a factor of 100\. We could
    of course mitigate this problem by defining age groups, but then we would have
    to spend time and data on calibrating the groups, which is not a trivial undertaking.
    In addition, the growth of the context space would be more limited (growth by
    a factor of 10 instead of 100), but still exponential. As we add more and more
    dimensions to the context, which is very likely in any realistic implementation,
    the problem could easily become intractable.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二，可能的上下文数量增加了100倍。当然，我们可以通过定义年龄组来缓解这个问题，但这样我们就需要花时间和数据来校准这些组，这并不是一件简单的事。此外，上下文空间的增长将会更受限制（增长系数为10而不是100），但仍然是指数级的。随着我们向上下文中添加越来越多的维度，这在任何现实的实现中都是非常可能的，问题可能很容易变得无法处理。
- en: Next, we address this problem using function approximations. This will allow
    us to work with very complex and high-dimensional contexts. Later, we will also
    use function approximations for actions, which will enable us to work with changing
    and/or high-dimensional action spaces.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用函数逼近来解决这个问题。这将使我们能够处理非常复杂和高维的上下文。稍后，我们还将使用函数逼近来处理动作，这将使我们能够处理变化和/或高维的动作空间。
- en: Using function approximations for context
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用函数逼近处理上下文
- en: 'Function approximations allow us to model the dynamics of a process from which
    we have observed data, such as contexts and ad clicks. As in the previous chapter,
    consider an online advertising scenario with five different ads (A, B, C, D, and
    E), with the context comprising user device, location, and age. In this section,
    our agent will learn five different Q functions, one per ad, each receiving a
    context of ![](img/Formula_03_004.png), and return the action value estimate.
    This is illustrated in *Figure 3.1*:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 函数逼近使我们能够从我们已经观察到的数据（如上下文和广告点击）中建模过程的动态。像上一章一样，考虑一个在线广告场景，其中有五个不同的广告（A、B、C、D
    和 E），上下文包括用户设备、位置和年龄。在本节中，我们的智能体将学习五个不同的Q函数，每个广告一个，每个广告接收一个上下文 ![](img/Formula_03_004.png)，并返回动作值估计。这在*图
    3.1* 中进行了说明：
- en: '![Figure 3.1 – We learn a function for each action that receives the context
    and returns the action value'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.1 – 我们为每个动作学习一个函数，接收上下文并返回动作值'
- en: '](img/B14160_03_01.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14160_03_01.jpg)'
- en: Figure 3.1 – We learn a function for each action that receives the context and
    returns the action value
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1 – 我们为每个动作学习一个函数，接收上下文并返回动作值
- en: At this point, we have a supervised machine learning problem to solve for each
    action. We can use different models to obtain the Q functions, such as logistic
    regression or a neural network (which actually allows us to use a single network
    that estimates values for all actions). Once we choose the type of function approximation,
    we can use the exploration strategies that we covered in the previous chapter
    to determine the ad to display given the context. But first, let's create a synthetic
    process to generate click data mimicking user behavior for our example.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们需要解决一个有监督的机器学习问题，针对每个动作。我们可以使用不同的模型来获得Q函数，例如逻辑回归或神经网络（实际上，这允许我们使用一个单一的网络来估计所有动作的值）。一旦我们选择了函数逼近的类型，就可以使用我们在上一章中介绍的探索策略，来确定在给定上下文下要展示的广告。但首先，我们先创建一个合成过程来生成模仿用户行为的点击数据。
- en: Case study – contextual online advertising with synthetic user data
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 案例研究 – 使用合成用户数据的上下文在线广告
- en: 'Assume that the true user click behavior follows a logistic function:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 假设用户的真实点击行为遵循逻辑函数：
- en: '![](img/Formula_03_005.jpg)![](img/Formula_03_006.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_03_005.jpg)![](img/Formula_03_006.jpg)'
- en: 'Here, ![](img/Formula_03_007.png) is the probability of a user click when the
    context is ![](img/Formula_03_008.png) and ad ![](img/Formula_03_009.png) is shown.
    Also, let''s assume that *device* is 1 for mobile and 0 otherwise; and *location*
    is 1 for US and 0 otherwise. There are two important things to note here:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/Formula_03_007.png) 是用户在上下文 ![](img/Formula_03_008.png) 和广告 ![](img/Formula_03_009.png)
    展示时点击的概率。另假设 *device* 对于移动设备为 1，其他设备为 0；*location* 对于美国为 1，其他地区为 0。这里有两个需要注意的重要事项：
- en: This behavior, particularly the ![](img/Formula_03_010.png) parameters, is unknown
    to the advertiser, which they will try to uncover.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这种行为，特别是 ![](img/Formula_03_010.png) 参数，对于广告商来说是未知的，他们将尝试揭示这些信息。
- en: Note the ![](img/Formula_03_011.png) superscript in ![](img/Formula_03_012.png),
    which denotes that the impact of these factors on user behavior is potentially
    different for each ad.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请注意 ![](img/Formula_03_011.png) 上标在 ![](img/Formula_03_012.png) 中，表示这些因素对用户行为的影响可能因广告而异。
- en: 'Let''s now implement this in Python, using the following steps:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在 Python 中实现这一点，按照以下步骤：
- en: Chapter03/Contextual Bandits.ipynb
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Chapter03/Contextual Bandits.ipynb
- en: 'First, let''s import the Python packages we will need:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要导入所需的 Python 包：
- en: '[PRE0]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: These include libraries for scientific computation, such as NumPy and SciPy,
    and Plotly, a powerful visualization tool.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些包括用于科学计算的库，如 NumPy 和 SciPy，以及强大的可视化工具 Plotly。
- en: 'Now, we create a class, `UserGenerator`, to simulate the user dynamics. Set
    some true ![](img/Formula_03_013.png) parameters here, which the advertiser (the
    agent) will try to learn:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们创建一个 `UserGenerator` 类来模拟用户动态。在这里设置一些真实的 ![](img/Formula_03_013.png) 参数，广告商（代理）将尝试学习这些参数：
- en: '[PRE1]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s define the methods to generate a click or no clicks given the user context:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义生成点击或无点击的方法，给定用户的上下文：
- en: '[PRE2]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that each ad has a different set of ![](img/Formula_03_014.png) values.
    When an ad is displayed to a user, the `logistic` method calculates the probability
    of a click and the `display_ad` method generates a click with that probability.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，每个广告都有一组不同的 ![](img/Formula_03_014.png) 值。当广告展示给用户时，`logistic` 方法会计算点击的概率，而
    `display_ad` 方法会根据这个概率生成一个点击。
- en: 'We define a method that will generate users with different contexts randomly:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了一个方法，将随机生成不同上下文的用户：
- en: '[PRE3]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As you can see, the `generate_user_with_context` method generates a US user
    with 60% chance. Also, with 80% chance, the ad is displayed on a mobile device.
    Finally, the user ages vary between 10 and 70, with a mean age of 34\. These are
    some numbers we set somewhat arbitrarily for the sake of the example. For simplicity,
    we don't assume any correlations between these user attributes. You can modify
    these parameters and introduce correlations to create more realistic scenarios.
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，`generate_user_with_context` 方法生成一个60%概率的美国用户。此外，广告有80%的概率在移动设备上展示。最后，用户年龄范围为10到70岁，平均年龄为34岁。这些数字是为了示例目的我们设定的，具有一定的随意性。为了简化，我们不假设这些用户属性之间存在任何相关性。你可以修改这些参数并引入相关性，以创建更现实的场景。
- en: 'We can create some functions (outside of the class) to visualize, for our own
    intuition, the relationship between the context and the probability of a click
    associated with it. To this end, we need a function to create a scatter plot for
    a given ad type and data:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以创建一些函数（在类外部）来可视化，直观地展示上下文与与之相关的点击概率之间的关系。为此，我们需要一个函数来为给定的广告类型和数据创建散点图：
- en: '[PRE4]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we define a function to plot how the click probabilities change with age,
    shown in different subplots for each device type and location pair:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们定义一个函数来绘制点击概率如何随年龄变化，在不同的子图中展示每种设备类型和位置的组合：
- en: '[PRE5]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, let''s create an object instance to generate users and visualize user
    behavior:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们创建一个对象实例来生成用户并可视化用户行为：
- en: '[PRE6]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output is shown in *Figure 3.2*:'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如 *图 3.2* 所示：
- en: '![Figure 3.2 – Comparison of the true ad click probabilities given the context'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.2 – 给定上下文的真实广告点击概率比较'
- en: '(x axis: age, y axis: click probability)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: （x 轴：年龄，y 轴：点击概率）
- en: '](img/B14160_03_02.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14160_03_02.jpg)'
- en: 'Figure 3.2 – Comparison of the true ad click probabilities given the context
    (x axis: age, y axis: click probability)'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 – 给定上下文的真实广告点击概率比较（x 轴：年龄，y 轴：点击概率）
- en: Looking at the plots in *Figure 3.2*, we should expect our algorithms to figure
    out, for example, to display ad E for users aged around 40, who connect from the
    US on a mobile device. Also, note that these probabilities are unrealistically
    high. More realistic `p` calculation in the `logistic` class by 0.05\. We will
    keep this as it is for now to make the problem easier.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 看着*图3.2*中的图表，我们应该期望我们的算法能够识别出，例如，对于大约40岁、来自美国并使用移动设备的用户，展示广告E。同时，请注意，这些概率不现实地偏高。为了使`logistic`类中的`p`计算更为现实，我们将调整其值为0.05。为了简化问题，暂时保持这种方式。
- en: 'Now, we have implemented a process to generate user clicks. Here is how the
    scenario will flow:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经实现了一个生成用户点击的过程。以下是这一场景的流程：
- en: We will generate a user and get the associated context using the `generate_user_with_context`
    method in the `ug` object.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将生成一个用户，并使用`ug`对象中的`generate_user_with_context`方法获取相关的上下文信息。
- en: 'A CB model will use the context to display one of the five ads: A, B, C, D,
    or E.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个CB模型将利用上下文来展示五个广告中的一个：A、B、C、D或E。
- en: The chosen ad will be passed to the `display_ad` method in the `ug` object,
    giving a reward of 1 (click) or 0 (no click).
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选定的广告将传递给`ug`对象中的`display_ad`方法，给予奖励1（点击）或0（未点击）。
- en: The CB model will be trained based on the reward, and this cycle will go on.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CB模型将根据奖励进行训练，并且这一循环将不断进行。
- en: Before actually implementing this flow, let's dive into the CB approaches we
    will use.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际实现这个流程之前，让我们深入了解将要使用的CB方法。
- en: Function approximation with regularized logistic regression
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用正则化逻辑回归的函数逼近
- en: 'We want our CB algorithms to observe the user responses to the ads, update
    the models that estimate the action values (function approximations), and determine
    which ad to display given the context, the action value estimates, and the exploration
    strategy. Note that in most realistic settings where the user traffic is high,
    the models would be updated not after every observation but after a batch of observations.
    With that, let''s start by discussing what kind of function approximator to use.
    There are numerous options, including many custom and sophisticated algorithms
    designed for CBs. Many of these models are based on the following:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望我们的CB算法能够观察用户对广告的反应，更新估计行动值的模型（函数逼近），并根据上下文、行动值估计以及探索策略来决定展示哪个广告。需要注意的是，在大多数现实设置中，用户流量较高，模型通常不会在每次观察后更新，而是在一批观察之后更新。因此，让我们先讨论使用哪种函数逼近器。我们有许多选择，包括许多为CB设计的定制和复杂算法。这些模型大多数基于以下几种方法：
- en: Logistic regression
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Decision trees/random forest
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树/随机森林
- en: Neural networks
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络
- en: 'In terms of the exploration strategy, we''ll continue to focus on the following
    three fundamental approaches:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索策略方面，我们将继续关注以下三种基本方法：
- en: ε-greedy
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ε-贪心算法（ε-greedy）
- en: Upper confidence bounds
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上置信界（Upper Confidence Bounds）
- en: Thompson/Bayesian sampling
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 汤普森/贝叶斯采样
- en: 'Now, let''s assume that, as subject matter experts, we know that the CTR can
    be modeled using logistic regression. We also mentioned that it is not practical
    to update the model after every single observation, so we prefer batch updates
    to our models. Finally, we would like to have Thompson sampling in our exploration
    toolbox, therefore we need posterior distributions on the parameters of the logistic
    regression models. To this end, we use a regularized logistic regression algorithm
    with batch updates provided by the agent(Chapelle et al., 2011). The algorithm
    does the following:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设作为主题专家，我们知道CTR可以通过逻辑回归来建模。我们还提到过，更新模型在每次观察后进行并不实际，因此我们更倾向于对模型进行批量更新。最后，我们希望在探索工具箱中加入汤普森采样（Thompson
    sampling），因此我们需要获得逻辑回归模型参数的后验分布。为此，我们使用一种正则化逻辑回归算法，并由代理提供批量更新（Chapelle等，2011）。该算法执行以下操作：
- en: Approximates the posterior distribution on the model weights by a Gaussian distribution.
    This allows us to use the posterior distribution as the prior in the next batch,
    and also use Gaussian for the likelihood function, since the Gaussian family is
    conjugate to itself.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过高斯分布来近似模型权重的后验分布。这样，我们可以在下一个批次中将后验分布作为先验，并且可以使用高斯分布作为似然函数，因为高斯族是自共轭的。
- en: Uses a diagonal covariance matrix for the weights, meaning we assume the weights
    are not correlated.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用对角协方差矩阵表示权重，这意味着我们假设权重之间不相关。
- en: Uses Laplace approximation to obtain the mean and the variance estimates of
    the weight distributions, one of the common methods in statistics to estimate
    the posterior parameters from observed data if the posterior is assumed to be
    Gaussian.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用拉普拉斯近似来获取权重分布的均值和方差估计，这是统计学中常用的估计后验参数的方法之一，假设后验是高斯分布。
- en: Info
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 信息
- en: You can learn more about Laplace approximation for computing the posterior mean
    at [https://bookdown.org/rdpeng/advstatcomp/laplace-approximation.html](https://bookdown.org/rdpeng/advstatcomp/laplace-approximation.html).
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在[https://bookdown.org/rdpeng/advstatcomp/laplace-approximation.html](https://bookdown.org/rdpeng/advstatcomp/laplace-approximation.html)了解更多关于拉普拉斯近似计算后验均值的内容。
- en: Let's see this algorithm in action next.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来看看这个算法的实际应用。
- en: Implementing regularized logistic regression
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现正则化逻辑回归
- en: 'We will follow these steps to implement the regularized logistic regression,
    which we will use later:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照以下步骤实现正则化逻辑回归，之后将用它：
- en: 'First, we create a class and initialize the parameters we will keep track of:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们创建一个类并初始化我们将跟踪的参数：
- en: '[PRE7]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let''s better understand what these parameters are:'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们更好地理解这些参数是什么：
- en: a) `name` is to identify which ad an object instance is estimating the action
    value of. Again, we have a separate model for each of the ads and they are updated
    separately based on their own click data.
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) `name` 用于识别对象实例正在估算的广告动作值。我们为每个广告都有一个单独的模型，并且根据各自的点击数据分别更新它们。
- en: b) The `alpha` hyperparameter controls the exploration and exploitation trade-off.
    Smaller values reduce the variance (for example, 0.25), which therefore encourages
    exploitation.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) `alpha`超参数控制探索与利用之间的权衡。较小的值减少方差（例如，0.25），从而鼓励利用。
- en: c) This is a regularized regression, meaning that we have a regularization term,
    λ. This is a hyperparameter to be tuned. We also use it to initialize the `q`
    array.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 这是一种正则化回归，意味着我们有一个正则化项，λ。它是一个需要调整的超参数。我们也用它来初始化`q`数组。
- en: d) `n_dim` is to indicate the dimension of the ![](img/Formula_03_015.png) parameter
    vector, one for each element of the context input and a bias term.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: d) `n_dim`表示![](img/Formula_03_015.png)参数向量的维度，每个上下文输入的元素对应一个，以及一个偏置项。
- en: e) The weights of the logistic function are denoted by the array of `w`, such
    that `w[i]` corresponds to ![](img/Formula_03_016.png) in our bandit dynamics
    model.
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: e) 逻辑函数的权重由`w`数组表示，其中`w[i]`对应我们赌博机动态模型中的![](img/Formula_03_016.png)。
- en: f) The mean estimate of `w[i]` is given by `m[i]`, and the variance estimate
    is the inverse of `q[i]`.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: f) `w[i]`的均值估计由`m[i]`给出，方差估计由`q[i]`的倒数给出。
- en: 'Then, we define a method to sample the parameters of the logistic regression
    function:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义一个方法来对逻辑回归函数的参数进行采样：
- en: '[PRE8]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note that we need this to use Thompson sampling, which requires sampling the
    `w` array parameters from the posterior, rather than using the mean values. Again,
    the posterior is a normal distribution here.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，我们需要这个方法来使用汤普森采样，它要求从后验中对`w`数组参数进行采样，而不是使用均值。这里的后验是一个正态分布。
- en: 'Define the loss function and a fit function, which will carry out the training:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义损失函数和拟合函数，后者将执行训练：
- en: '[PRE9]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let''s elaborate on how the fitting part works:'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们详细说明拟合部分是如何工作的：
- en: a) We update the model using the `fit` method and the `loss` function with a
    given set of contexts and associated click data (1 for a click, 0 for no click).
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 我们使用`fit`方法和`loss`函数通过给定的上下文和相关的点击数据（点击为1，未点击为0）来更新模型。
- en: b) We use SciPy's minimize function for the model training. To prevent numerical
    overflows in the exponential terms, we impose bounds on `w`. These bounds need
    to be adjusted depending on the range of the input values. For the binary features
    of device type and the age input, location [-10, +10] and [-1, +1], respectively,
    are reasonable ranges for our use case.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 我们使用SciPy的minimize函数进行模型训练。为了防止指数项中的数值溢出，我们对`w`施加了边界。根据输入值的范围，这些边界需要进行调整。对于设备类型的二进制特征和年龄输入，位置[-10,
    +10]和[-1, +1]分别是我们用例中的合理范围。
- en: c) In each model update with a new batch of data, the previous `w` values serve
    as the prior.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 在每次使用新一批数据更新模型时，之前的`w`值作为先验。
- en: 'Implement the upper confidence bounds on predictions, which is one of the exploration
    methods we will experiment with:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现预测的上置信界限，这是我们将在实验中使用的探索方法之一：
- en: '[PRE10]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Implement two types of prediction methods, one using the mean values parameter
    estimates and the other using the sampled parameters to be used with Thompson
    sampling:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现两种预测方法，一种使用均值参数估计，另一种使用采样参数，并与汤普森采样结合使用：
- en: '[PRE11]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now, before actually diving into solving the problem, we will define a metric
    to compare the alternative exploration strategies.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在实际开始解决问题之前，我们将定义一个度量标准来比较不同的探索策略。
- en: Objective – regret minimization
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目标——遗憾最小化
- en: 'A common metric that is used to compare MAB and CB algorithms is called **regret**.
    We define the total regret by the time we have observed the ![](img/Formula_03_017.png)
    user as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 用于比较多臂老虎机（MAB）和上下文绑定（CB）算法的一个常见指标叫做**遗憾**。我们通过以下公式定义总遗憾，直到我们观察到![](img/Formula_03_017.png)用户：
- en: '![](img/Formula_03_018.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_03_018.jpg)'
- en: Here, ![](img/Formula_03_019.png) is the context for the ![](img/Formula_03_020.png)
    user, ![](img/Formula_03_021.png) is the best action (ad) to take that gives the
    highest expected CTR, and ![](img/Formula_03_022.png) is the expected CTR for
    the selected action (ad). Note that we are able to calculate the regret because
    we have access to the true action values (expected CTRs), which would not be the
    case in reality (although regret can still be estimated). Note that the minimum
    possible regret at any step is zero.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/Formula_03_019.png)是![](img/Formula_03_020.png)用户的上下文，![](img/Formula_03_021.png)是应该采取的最佳行动（广告），它能带来最高的预期点击率（CTR），而![](img/Formula_03_022.png)是所选行动（广告）的预期点击率。需要注意的是，我们能够计算遗憾是因为我们可以访问真实的行动值（预期CTR），而在现实中并不具备这一条件（尽管遗憾仍然可以被估计）。请注意，任何步骤中的最小遗憾值为零。
- en: Tip
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: With a good exploration strategy, we should see a decelerating cumulative regret
    over time as the algorithm discovers the best actions.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 使用良好的探索策略，我们应该看到随着算法发现最佳行动，累积遗憾会随着时间的推移而逐渐减缓。
- en: 'We will use the following code to calculate the regret given the context and
    the selected ad:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下代码根据上下文和选择的广告来计算遗憾：
- en: '[PRE12]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Finally, let's write the code to actually solve the problem using different
    exploration strategies.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们编写代码，使用不同的探索策略来实际解决这个问题。
- en: Solving the online advertising problem
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决在线广告问题
- en: 'As we have already defined all the auxiliary methods to use the three exploration
    strategies we mentioned earlier, selecting the actions accordingly will be trivial.
    Now, let''s implement the functions for these strategies:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经定义了所有辅助方法来使用之前提到的三种探索策略，按策略选择行动将变得非常简单。现在，我们来实现这些策略的相关函数：
- en: 'We start with writing a function to implement the ε-greedy actions, which selects
    the best action most of the time and explores a random action otherwise:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从编写一个函数开始，来实现ε-贪心策略，该策略大多数时候选择最佳行动，其他时候则探索随机行动：
- en: '[PRE13]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next, we write a function to implement action selection using the upper confidence
    bounds:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们编写一个函数，使用上置信度界限进行行动选择：
- en: '[PRE14]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, we define a function to implement action selection using Thompson sampling:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义一个函数来实现使用汤普森采样的行动选择：
- en: '[PRE15]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, we perform the actual experiment, which will run and compare each
    strategy sequentially. We start with initializing the ad names, the experiment
    names, and the necessary data structures:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们进行实际的实验，依次运行并比较每种策略。我们从初始化广告名称、实验名称和必要的数据结构开始：
- en: '[PRE16]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We need to implement an outer `for` loop to kick off a clean experiment with
    each of the exploration strategies. We initialize all the algorithm parameters
    and data structures:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要实现一个外部的`for`循环来启动一个干净的实验，针对每一种探索策略。我们初始化所有算法参数和数据结构：
- en: '[PRE17]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we implement an inner loop to run the active strategy for 10K user impressions:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们实现一个内部循环，用于在10K次用户展示中运行活跃的策略：
- en: '[PRE18]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s unpack this:'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们逐步分析一下：
- en: a) We generate a user and use the context to decide which ad to display given
    the exploration strategy in each iteration.
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 我们生成一个用户，并根据上下文来决定在每次迭代中展示哪个广告，依据的是探索策略。
- en: b) We observe and record the outcome. We also calculate the regret after each
    impression to be able to compare the strategies.
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 我们观察并记录结果。我们还会在每次展示后计算遗憾，以便比较不同策略的效果。
- en: c) We update the logistic regression models in batches, namely after every 500
    ad impressions.
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: c) 我们以批量的方式更新逻辑回归模型，也就是每当有500次广告展示后进行一次更新。
- en: 'After executing this code block, we can visualize the results using the following
    code:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行完此代码块后，我们可以使用以下代码来可视化结果：
- en: '[PRE19]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This gives the plot that is shown in Figure 3.3:'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将生成图3.3中所示的图表：
- en: '![Figure 3.3 – Comparison of exploration strategies in the online advertising
    example'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.3 – 在线广告示例中探索策略的比较'
- en: '](img/B14160_03_03.jpg)'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14160_03_03.jpg)'
- en: Figure 3.3 – Comparison of exploration strategies in the online advertising
    example
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.3 – 在线广告示例中探索策略的比较
- en: 'We clearly see that Thompson sampling is outperforming the ε-greedy and `alpha`
    for UCB, which could have led to better performances. But this is exactly the
    point: Thompson sampling provides a very effective exploration strategy pretty
    much out of the box. This is what *Chapelle et al., 2011* empirically showed and
    helped the method gain popularity nearly a century after it was introduced.'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们清楚地看到，汤普森采样优于ε-贪婪和UCB的`alpha`，后者可能会导致更好的表现。但这正是重点：汤普森采样提供了一种非常有效的探索策略，几乎可以开箱即用。这是*Chapelle
    等人，2011*通过实验证明的，并帮助该方法在它被提出近一个世纪后获得了广泛的关注。
- en: Tip
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提示
- en: In a real production system, it makes more sense to use well-maintained libraries
    for the supervised learning portion in CBs rather than a custom implementation
    as we did here. One such library for probabilistic programming is PyMC3 ([https://docs.pymc.io/](https://docs.pymc.io/)).
    Using PyMC3, you can fit supervised learning models to your data and then sample
    the model parameters. As an exercise, consider implementing Thompson sampling
    using a logistic regression model in PyMC3.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在实际生产系统中，使用维护良好的库来处理CB中的监督学习部分，比我们这里做的自定义实现要更为合理。一个用于概率编程的库是PyMC3（[https://docs.pymc.io/](https://docs.pymc.io/)）。使用PyMC3，你可以将监督学习模型拟合到你的数据上，然后对模型参数进行采样。作为一个练习，考虑在PyMC3中使用逻辑回归模型实现汤普森采样。
- en: 'Let''s close this section by visualizing the parameter estimates of the models.
    For example, when we used the ε-greedy strategy, the ![](img/Formula_03_023.png)
    coefficients for ad A were estimated as follows:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过可视化模型的参数估计来结束这一部分。例如，当我们使用ε-贪婪策略时，广告A的![](img/Formula_03_023.png)系数被估计如下：
- en: '[PRE20]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This results in the following output:'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这会生成以下输出：
- en: '![Figure 3.4 – Visualization of the posterior distribution of  for ad A at
    the end of the experiment with ε-greedy exploration'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.4 – 实验结束时，使用ε-贪婪探索的广告A的后验分布可视化'
- en: '](img/B14160_03_04.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14160_03_04.jpg)'
- en: Figure 3.4 – Visualization of the posterior distribution of ![](img/Formula_03_024.png)
    for ad A at the end of the experiment with ε-greedy exploration
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 – 实验结束时，使用ε-贪婪探索的广告A的后验分布可视化
- en: The logistic regression model estimates the coefficients as ![](img/Formula_03_025.png)
    whereas the actual coefficients are ![](img/Formula_03_026.png). The model is
    especially certain about its estimate for ![](img/Formula_03_027.png), which is
    indicated by a very narrow distribution in the plot.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型的系数估计为![](img/Formula_03_025.png)，而实际的系数为![](img/Formula_03_026.png)。该模型对于![](img/Formula_03_027.png)的估计特别确定，这在图中的分布非常狭窄。
- en: Terrific job! This was a rather long exercise, but one that will set you up
    for success in your real-life implementations. Take a deep breath and a break,
    and next, we will look at an even more realistic version of online advertising
    where the ad inventory changes over time.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 做得非常好！这是一个相当长的练习，但它将为你在实际应用中的成功奠定基础。深呼吸一下，休息片刻，接下来我们将看看一个更为现实的在线广告版本，其中广告库存随时间变化。
- en: Using function approximations for actions
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用函数逼近来处理行动
- en: 'In our online advertising examples so far, we have assumed that we have a fixed
    set of ads (actions/arms) to choose from. However, in many applications of CBs,
    the set of available actions changes over time. Take the example of a modern advertising
    network that uses an ad server to match ads to websites/apps. This is a very dynamic
    operation that involves, leaving the pricing aside, three major components:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们到目前为止的在线广告示例中，我们假设有一组固定的广告（行动/臂）可供选择。然而，在许多CB的应用中，可用的行动集合是随着时间变化的。以一个现代广告网络为例，该网络使用广告服务器将广告匹配到网站/应用。这是一个非常动态的操作，涉及到的，抛开定价不谈，主要有三个组成部分：
- en: Website/app content
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网站/应用内容
- en: Viewer/user profile
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观众/用户画像
- en: Ad inventory
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广告库存
- en: 'Previously, we considered only the user profile for the context. An ad server
    needs to take the website/app content into account additionally, but this does
    not really change the structure of the problem we solved before. However, now,
    we cannot use a separate model for each ad since the ad inventory is dynamic.
    We handle this by using a single model to which we feed ad features. This is illustrated
    in *Figure 3.5*:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们只考虑了用户配置文件作为上下文。广告服务器需要额外考虑网站/应用内容，但这并没有真正改变我们之前解决的问题结构。然而，现在，由于广告库存是动态的，我们不能为每个广告使用单独的模型。我们通过将广告特征输入单一模型来处理这个问题。这在*图3.5*中有所说明：
- en: '![Figure 3.5 – Function approximation of action values with context and action
    inputs in the ad network example'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.5 – 在广告网络示例中，带有上下文和动作输入的行动值的函数近似'
- en: '](img/B14160_03_05.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14160_03_05.jpg)'
- en: Figure 3.5 – Function approximation of action values with context and action
    inputs in the ad network example
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5 – 在广告网络示例中，带有上下文和动作输入的行动值的函数近似
- en: While making a decision, we take the context as given. So, the decision is about
    which ad to display from the ad inventory that is available at the time. So, to
    make this decision, we generate action values for all available ads using this
    single model.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在做出决策时，我们将上下文视为已知条件。因此，决策是关于从当前可用广告库存中展示哪个广告。因此，为了做出这个决定，我们使用这个单一模型为所有可用广告生成行动值。
- en: 'Now it is time to talk about what kind of model to use in this situation:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候谈谈在这种情况下使用什么样的模型了：
- en: 'Remember what the model does: it learns how a given user would react to a given
    ad that they see on a given website/app and estimates the probability of a click.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记住模型的作用：它学习了给定用户在给定网站/应用上看到的给定广告后的反应，并估计点击的概率。
- en: When you think about all possible user and website/app contexts, and all possible
    ads, this is a very complicated relationship to figure out.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你考虑所有可能的用户和网站/应用上下文，以及所有可能的广告时，这是一个非常复杂的关系需要弄清楚。
- en: Such a model needs to be trained on a lot of data and it should be sophisticated
    enough to be able to come up with a good approximation of the true dynamics of
    a click.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这样的模型需要在大量数据上进行训练，并且应足够复杂，以能够提供真实点击动态的良好近似。
- en: 'When we have this much complexity, and hopefully enough data, there is one
    obvious choice: **deep neural networks** (**DNNs**).'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们面对如此复杂性，并希望有足够的数据时，有一个明显的选择：**深度神经网络**（**DNNs**）。
- en: In the previous section, we compared different exploration strategies and showed
    that Thompson sampling is a very competitive choice. However, Thompson sampling
    requires us to be able to sample from the posterior of the model parameters; this
    is often intractable for complex models such as neural networks. To overcome this
    challenge, we rely on approximate Bayesian methods available in the literature.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们比较了不同的探索策略，并展示了汤普森抽样是一个非常有竞争力的选择。然而，汤普森抽样要求我们能够从模型参数的后验分布中进行采样；对于诸如神经网络之类的复杂模型，这通常是不可行的。为了克服这一挑战，我们依赖于文献中提供的近似贝叶斯方法。
- en: Info
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 信息
- en: There are many approximation methods and their comparison is beyond the scope
    here. *Riquelme et al., 2018* provide a great comparison along with code in the
    TensorFlow repository.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多近似方法，它们的比较超出了这里的范围。*Riquelme等人，2018*在TensorFlow存储库中提供了一个很好的比较及其代码。
- en: One of these approximations involves using dropout regularization in the DNN
    and keeping it active during inference time. As a reminder, dropout regularization
    deactivates each neuron in the DNN with respect to a given probability and increases
    generalization. Typically, dropout is only used during training. When it is kept
    active during inference, since neurons are disabled probabilistically, the output
    varies accordingly. *Gal et al., 2015* have shown that this works as an approximate
    Bayesian inference, which we need for Thompson sampling.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 一个这些近似方法包括在深度神经网络中使用辍学正则化，并在推断时保持其活跃。作为提醒，辍学正则化会以给定概率停用DNN中的每个神经元，并增加泛化能力。通常，辍学仅在训练期间使用。当推断时保持其活跃时，由于神经元以概率方式被禁用，输出相应变化。*Gal等人，2015*显示，这类似于近似贝叶斯推断，这是我们用于汤普森抽样所需的。
- en: Case study – contextual online advertising with user data from the US Census
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 案例研究 – 利用来自美国人口普查的用户数据进行上下文在线广告投放
- en: Now, let's talk about the example we will use in this section. Previously, we
    crafted our own examples. This time, we'll use a dataset that is modified from
    the 1994 US Census and adapt it to an online advertising setting. The dataset
    is known as the Census Income dataset and is available at [https://archive.ics.uci.edu/ml/datasets/Census+Income](https://archive.ics.uci.edu/ml/datasets/Census+Income).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来谈谈这一部分将使用的示例。之前，我们设计了自己的示例。这一次，我们将使用一个经过修改的数据集，该数据集来源于1994年的美国人口普查，并将其调整为在线广告场景。这个数据集被称为人口普查收入数据集，可以在[https://archive.ics.uci.edu/ml/datasets/Census+Income](https://archive.ics.uci.edu/ml/datasets/Census+Income)找到。
- en: 'In this dataset, we use the following information on the individuals who participated
    in the census: age, work class, education, marital status, occupation, relationship,
    race, gender, work hours per week, native country, and income level.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据集中，我们使用了参与普查的个人的以下信息：年龄、工作类别、教育、婚姻状况、职业、关系、种族、性别、每周工作小时数、原籍国和收入水平。
- en: With that, let's discuss how to turn this data into an online advertising scenario.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们讨论如何将这些数据转化为在线广告场景。
- en: The scenario
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 场景描述
- en: Consider an ad server that knows all of the preceding information about a user,
    except the education level. On the other hand, the ad network is managing ads
    that address a specific education level. For example, at any given time, the ad
    server has one ad that is targeting users with a college education and one ad
    that is targeting users with elementary school education. If the target audience
    of the ad that is shown to a user matches the user's education level, there is
    a high probability of a click. If not, the probability of a click decreases gradually
    as the discrepancy between the target education level and the user's education
    level grows. In other words, the ad server is implicitly trying to predict users'
    education levels as close as possible.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有一个广告服务器，它知道用户的所有前述信息，除了教育水平。另一方面，广告网络管理着针对特定教育水平的广告。例如，在任何给定时刻，广告服务器可能有一则广告针对接受过大学教育的用户，另一则广告则针对接受过小学教育的用户。如果展示的广告目标用户的教育水平与用户的实际教育水平相匹配，则点击的概率很高。如果不匹配，随着目标教育水平与用户教育水平之间的差距增大，点击的概率会逐渐下降。换句话说，广告服务器在隐式地尝试尽可能准确地预测用户的教育水平。
- en: Next, let's prepare the dataset for our scenario.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们准备为这个场景提供数据集。
- en: Preparing the data
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据准备
- en: 'Follow these steps to clean and prepare the data:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤清理和准备数据：
- en: 'We start with importing the necessary packages to use later:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先导入稍后将使用的必要包：
- en: '[PRE21]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next, we need to download the data and select the columns of interest:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要下载数据并选择感兴趣的列：
- en: '[PRE22]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Let''s drop the rows with missing data, marked by `?` entries:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们删除包含缺失数据的行，这些行用`?`标记：
- en: '[PRE23]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Normally, a missing entry could itself be a valuable indicator that the model
    could use. In addition, it is a bit wasteful to drop a whole record just because
    of a single missing entry. However, data imputation is beyond our scope here,
    so let's keep focusing on the CB problem.
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通常，一个缺失的条目本身可能是一个有价值的指示，模型可以使用它。此外，仅因为某个条目缺失而删除整行数据也有些浪费。然而，数据插补超出了本讨论的范围，所以我们继续专注于CB问题。
- en: 'Let''s also collapse the different education levels to four categories: `Elementary`,
    `Middle`, `Undergraduate`, and `Graduate`:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还将不同的教育水平合并为四个类别：`小学`、`中学`、`本科`和`研究生`：
- en: '[PRE24]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next, we convert categorical data into one-hot vectors to be able to feed into
    a DNN. We preserve the education column as is, since that is not part of the context:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将分类数据转换为独热编码（one-hot vectors），以便输入到DNN中。我们保留教育列不变，因为它不是上下文的一部分：
- en: '[PRE25]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: By doing this conversion at the beginning, we assume that we know all possible
    work class categories and native countries.
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过在开始时进行此转换，我们假设我们知道所有可能的工作类别和原籍国类别。
- en: That's it! We have the data ready. Next, we implement logic to simulate an ad
    click based on the actual education level of the user and the education level
    that the ad displayed targets.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们已经准备好数据。接下来，我们实现逻辑，通过用户的实际教育水平和广告所针对的教育水平来模拟广告点击。
- en: Simulating ad clicks
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模拟广告点击
- en: 'In this example, the availability of ads is random and the ad clicks are stochastic.
    We need to come up with some logic to simulate this behavior:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，广告的可用性是随机的，广告点击是随机的。我们需要设计一些逻辑来模拟这种行为：
- en: 'Let''s start with determining the ad availability probabilities for each education
    category and implement the sampling of ads:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们先确定每个教育类别的广告可用性概率，并实现广告的抽样：
- en: '[PRE26]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: As mentioned, the ad server will have at most one ad for each target group.
    We also ensure that there is at least one ad in the inventory.
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如前所述，广告服务器每个目标组最多只有一个广告。我们还确保库存中至少有一个广告。
- en: 'Then, we define a function to generate a click probabilistically, where the
    likelihood of a click increases to the degree that the user''s education level
    and the ad''s target match:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义一个函数，通过概率生成一个点击，其中点击的可能性随着用户教育水平和广告目标匹配的程度而增加：
- en: '[PRE27]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: So, when an ad is shown to a user, if the ad's target matches the user's education
    level, there will be ![](img/Formula_03_028.png) chance of a click. This probability
    decreases by ![](img/Formula_03_029.png) for each level of mismatch. For example,
    a person with a high school diploma has a ![](img/Formula_03_030.png) chance of
    clicking on an ad that targets a user group of elementary school graduates (or
    college graduates). Note that this information is not known to the CB algorithm.
    It will be used only to simulate the clicks.
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所以，当一个广告展示给用户时，如果广告的目标匹配用户的教育水平，则点击概率为 ![](img/Formula_03_028.png)。每当不匹配一个级别时，这个概率会减少
    ![](img/Formula_03_029.png)。例如，一个拥有高中学历的人点击一个针对小学毕业生（或大学毕业生）用户组的广告的概率为 ![](img/Formula_03_030.png)。注意，CB
    算法并不知道这些信息，它只会用于模拟点击。
- en: We have the problem set up. Next, we'll turn to implementing a CB model.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经设置好了问题。接下来，我们将转向实现一个 CB 模型。
- en: Function approximation using a neural network
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用神经网络的函数逼近
- en: As mentioned, we use a (not so) DNN, which will estimate the action value, given
    the context and the action. The DNN we'll use has two layers, with 256 hidden
    units in each layer. This model is pretty easy to create using Keras, TensorFlow's
    high-level API.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们使用一个（并不那么）DNN，它将在给定上下文和行动的情况下估计行动值。我们将使用的 DNN 有两层，每层有 256 个隐藏单元。这个模型使用
    Keras——TensorFlow 的高级 API——来创建相当简单。
- en: Tip
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Note that in our model, we use dropout that we leave active for the inference
    time as a Bayesian approximation that we need for Thompson sampling. This is configured
    by setting `training=True` in the dropout layer.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在我们的模型中，我们使用了 dropout，并且在推理时将其保持激活状态，作为我们为 Thompson 采样所需的贝叶斯近似。这是通过在 dropout
    层设置 `training=True` 来配置的。
- en: The network outputs a scalar, which is an estimate for the action value given
    the context and the action feature (target user group). Using binary cross-entropy
    suits such an output the best, so we'll use it in our model. Finally, we'll use
    the popular Adam optimizer.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 网络输出一个标量，这是给定上下文和行动特征（目标用户组）下的行动值估计。使用二元交叉熵最适合这种输出，所以我们将在模型中使用它。最后，我们将使用流行的
    Adam 优化器。
- en: Info
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 信息
- en: Visit [https://www.tensorflow.org/guide/keras](https://www.tensorflow.org/guide/keras)
    if you need to get started with Keras or to refresh your memory. It is very simple
    to build the standard DNN models with it.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要开始使用 Keras 或者回顾一下，访问 [https://www.tensorflow.org/guide/keras](https://www.tensorflow.org/guide/keras)。使用它构建标准的
    DNN 模型非常简单。
- en: 'Now, let''s create the functions for model creation and updates:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建用于模型创建和更新的函数：
- en: 'We create a function that returns a compiled DNN model with given input dimensions
    and a dropout rate:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个函数，返回一个已编译的 DNN 模型，给定输入维度和一个 dropout 比率：
- en: '[PRE28]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We will update this model in batches as data becomes available. Next, write
    a function to train the model for 10 epochs with each batch:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当数据可用时，我们将按批次更新这个模型。接下来，编写一个函数，用每个批次训练模型 10 个周期：
- en: '[PRE29]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We then define a function that returns a one-hot representation for a specified
    ad based on the education level it targets:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义一个函数，返回基于目标教育水平的指定广告的一-hot 表示：
- en: '[PRE30]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We implement the Thompson sampling to select an ad given the context and the
    ad inventory at hand:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们实现了 Thompson 采样来根据上下文和手头的广告库存选择一个广告：
- en: '[PRE31]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The ad to be displayed is chosen based on the largest action value estimate
    that we obtain from the DNN. We obtain this by trying all available ads in the
    inventory – and remember, we have at most one ad per target user group – with
    the context of the user. Note that the target user group is equivalent to `action`,
    which we feed to the DNN in the format of a one-hot vector.
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要显示的广告是基于我们从 DNN 获得的最大行动值估计来选择的。我们通过尝试库存中所有可用的广告来获得这一点——请记住，我们每个目标用户组最多只有一个广告——并结合用户的上下文。注意，目标用户组等同于`action`，我们以一-hot
    向量的格式将其输入到 DNN。
- en: 'Finally, we write a function to generate users through a random selection from
    the dataset. The function will return the user data as well as the derived context:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们编写一个函数，通过从数据集中随机选择来生成用户。该函数将返回用户数据以及派生的上下文：
- en: '[PRE32]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This concludes what we need to decide on the ad to display using Thompson sampling.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了我们使用汤普森采样来决定展示广告所需的步骤。
- en: Calculating the regret
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算后悔值
- en: 'We''ll continue to use regret for comparing various versions of the CB algorithm.
    We calculate it as follows:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续使用后悔值来比较CB算法的不同版本。计算方法如下：
- en: '[PRE33]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: With the regret calculation also in place, let's now actually solve the problem.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在后悔值计算也完成后，让我们现在实际解决问题。
- en: Solving the online advertising problem
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决在线广告问题
- en: 'Now we are ready to put all these components together. We''ll try this algorithm
    with different dropout probabilities over 5,000 impressions. We''ll update the
    DNN parameters after every 500 iterations. Here is the implementation in Python
    for various dropout rates:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备将所有这些组件整合在一起。我们将在5,000次展示中尝试使用不同的丢弃概率的算法。每进行500次迭代后，我们会更新DNN参数。以下是Python中不同丢弃率的实现：
- en: '[PRE34]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The cumulative regrets over time are stored in the `df_cbandits` `pandas` DataFrame.
    Let''s visualize how they compare:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 累积后悔值随时间的变化存储在`df_cbandits` `pandas` DataFrame中。让我们来可视化它们的比较：
- en: '[PRE35]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This results in the following output:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 3.6 – Comparison of cumulative regret with various dropout rates'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.6 – 不同丢弃率下累积后悔的比较'
- en: '](img/B14160_03_06.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14160_03_06.jpg)'
- en: Figure 3.6 – Comparison of cumulative regret with various dropout rates
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6 – 不同丢弃率下累积后悔的比较
- en: The results in *Figure 3.6* show that our bandit models learn after some observation
    on how to select the ads given the user characteristics. As various dropout rates
    have led to different algorithm performances, an important question again becomes
    how to select the dropout rate. One obvious answer is to try different rates over
    time to identify what works best in similar online advertising problems. This
    approach usually works if the business has to solve similar problems again and
    again over a long time period. A better approach, though, is to learn the optimal
    dropout rate.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3.6*中的结果显示，我们的赌徒模型在经过一些观察后，学会了如何根据用户特征选择广告。由于不同的丢弃率导致了不同的算法表现，一个重要的问题再次出现，那就是如何选择丢弃率。一个明显的答案是，随着时间的推移，尝试不同的丢弃率，以确定在类似的在线广告问题中最有效的丢弃率。这个方法通常适用于业务需要长期解决类似问题的情况。然而，更好的方法是学习最优的丢弃率。'
- en: Tip
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: '**Concrete dropout** is a variant that tunes the dropout probabilities automatically.
    (Collier & Llorens, 2018) have successfully used this method on CB problems and
    reported superior performance over fixed dropout selections. For a TensorFlow
    implementation of concrete dropout, see [https://github.com/Skydes/Concrete-Dropout](https://github.com/Skydes/Concrete-Dropout).'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '**Concrete dropout**是一种变体，能够自动调节丢弃概率。（Collier & Llorens, 2018）成功地在CB问题中使用了这种方法，并报告了比固定丢弃选择更优的性能。关于Concrete
    dropout的TensorFlow实现，参见[https://github.com/Skydes/Concrete-Dropout](https://github.com/Skydes/Concrete-Dropout)。'
- en: 'With this, we conclude our discussion on CBs. Note that we focused on two components
    while formulating the CB problem:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，我们的CB讨论已结束。请注意，在制定CB问题时，我们主要关注了两个组件：
- en: Function approximation
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数逼近
- en: Exploration strategy
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索策略
- en: You can often mix and match different function approximations with various exploration
    techniques. While Thompson sampling with DNNs is probably the most common choice,
    we encourage you to take a look at the literature for other approaches.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以经常将不同的函数逼近与各种探索技术混合使用。虽然汤普森采样与DNN的组合可能是最常见的选择，但我们鼓励你参考文献，了解其他方法。
- en: Other applications of multi-armed bandits and CBs
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多臂老虎机和CB的其他应用
- en: 'So far, we have focused on online advertising as our running example. If you
    are wondering how common bandit algorithms are in practice in this field, they
    are actually quite common. For example, Microsoft has a service, called Personalizer,
    based on bandit algorithms (disclaimer: the author is a Microsoft employee at
    the time of writing this book). The example here is itself inspired by the work
    at HubSpot – a marketing solutions company (Collier & Llorens, 2018). Moreover,
    bandit problems have a vast array of practical applications other than advertising.
    In this section, we''ll briefly go over some of those applications.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直将在线广告作为我们的示例。如果你在想这种带有赌博算法的应用在这个领域的普及程度如何，其实它们相当常见。例如，微软有一个基于赌博算法的服务，叫做Personalizer（免责声明：作者在写这本书时是微软的员工）。这里的示例本身受到HubSpot（一个营销解决方案公司）的工作的启发（Collier
    & Llorens, 2018）。此外，赌博问题在广告以外有许多实际应用。在本节中，我们将简要介绍其中一些应用。
- en: Recommender systems
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐系统
- en: 'The bandit problems we formulated and solved in this chapter are a type of
    recommender system: they recommend which ad to display, potentially leveraging
    information available about users. There are many other recommender systems that
    use bandits in a similar way, such as the following:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们所定义并解决的赌博问题是一种推荐系统：它们推荐应该显示哪个广告，可能会利用关于用户的信息。还有许多其他推荐系统也以类似的方式使用赌博算法，诸如：
- en: Artwork selection for movie titles, as Netflix famously implements (Chandrashekar,
    Amat, Basilico, & Jebara, 2017)
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电影标题的艺术作品选择，正如Netflix著名的实现方式（Chandrashekar, Amat, Basilico, & Jebara, 2017）
- en: Article recommendations on a news portal
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新闻门户的文章推荐
- en: Post recommendations on a social media platform
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社交媒体平台上的帖子推荐
- en: Product/service recommendations on an online retail platform
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线零售平台上的产品/服务推荐
- en: Tailoring search results to the user on a search engine
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据用户在搜索引擎上的行为定制搜索结果
- en: Web page/app feature design
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网页/应用功能设计
- en: Most famous websites and apps that we visit every day decide which design to
    use for different features after extensive tests. For example, they create different
    designs of the "buy" button on the shopping cart and observe which design generates
    the most sales. These experiments are conducted nonstop for hundreds of features.
    An efficient way of conducting these experiments is to use multi-armed bandits.
    This way, bad feature designs could be identified early on and eliminated to minimize
    the user disturbance throughout these experiments (Lomas et al., 2016).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们每天访问的大多数著名网站和应用，都会在经过大量测试后决定使用哪种设计。例如，他们会为购物车中的“购买”按钮设计不同的版本，并观察哪种设计带来最多的销售量。这些实验会不间断地进行，涵盖数百个功能。进行这些实验的一种高效方式是使用多臂赌博算法。通过这种方式，可以尽早识别出差的功能设计，并将其淘汰，从而最小化这些实验对用户的干扰（Lomas
    et al., 2016）。
- en: Healthcare
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 医疗保健
- en: Bandit problems have important applications in healthcare. Especially with the
    increasing availability of patient data, through well-maintained patient databases
    and data collection via mobile devices, many treatments can now be personalized
    to individuals. CBs are therefore an important tool to use when deciding which
    treatment to apply to a patient in randomized controlled trials. Another application
    in which CBs have successfully been used is for deciding the treatment dose of
    drugs, such as Warfarin, which regulates blood coagulation (Bastani and Bayati,
    2015). One more application is related to the optimal allocation of data sampling
    to various animal models to assess the effectiveness of a treatment. CBs have
    proven to increase the efficiency of this process by identifying promising treatments
    better than conventional methods (Durand et al., 2018).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 赌博问题在医疗保健中有重要应用。尤其是随着患者数据的增加，通过维护良好的患者数据库和通过移动设备收集数据，现在许多治疗方法都可以个性化地应用于个人。因此，在随机对照试验中决定应用哪种治疗方法时，CB是一个重要工具。CB成功应用的另一个例子是决定药物的治疗剂量，比如调节血液凝固的华法林（Bastani
    and Bayati, 2015）。另一个应用是与最优分配数据采样到不同动物模型以评估治疗效果相关。CB通过比传统方法更好地识别有前景的治疗方式，证明了能提高这一过程的效率（Durand
    et al., 2018）。
- en: Dynamic pricing
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动态定价
- en: An important challenge for online retailers is to dynamically adjust their prices
    on millions of products. This can be modeled as a CB problem where the context
    could include product demand forecasts, inventory levels, product cost, and location.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 对在线零售商来说，一个重要的挑战是如何在数百万种商品上动态调整价格。这可以建模为一个上下文带宽（CB）问题，其中上下文可能包括产品需求预测、库存水平、产品成本和位置。
- en: Finance
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 财务
- en: CBs are used in literature for optimal portfolio construction through mixing
    passive and active investments to achieve a balance between the risk and expected
    return.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: CBs 在文献中用于通过混合被动和主动投资，构建最佳投资组合，以实现风险和预期回报之间的平衡。
- en: Control systems tuning
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制系统调节
- en: Many mechanical systems use variants of **proportional-integral-derivative**
    (**PID**) controllers to control the system. PID controllers require tuning, which
    is often done by subject matter experts for each system separately. This is because
    optimal gains for the controller depend on the specifics of the equipment, such
    as the material, temperature, and wear and tear. This manual process can be automated
    using a CB model that assesses system characteristics and tunes the controller
    accordingly.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 许多机械系统使用 **比例-积分-微分** (**PID**) 控制器的变体来控制系统。PID 控制器需要调节，通常由相关领域的专家分别为每个系统进行调节。这是因为控制器的最佳增益取决于设备的具体情况，如材料、温度和磨损。这一手动过程可以通过使用
    CB 模型来自动化，CB 模型评估系统特性并相应地调节控制器。
- en: Summary
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we concluded our discussion on bandit problems with CBs. As
    we mentioned, bandit problems have many practical applications. So, it would not
    be a surprise if you already had a problem in your business or research that can
    be modeled as a bandit problem. Now that you know how to formulate and solve one,
    go out and apply what you have learned! Bandit problems are also important to
    develop an intuition on how to solve an exploration-exploitation dilemma, which
    will exist in almost every RL setting.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们结束了关于带有 CBs 的强盗问题的讨论。正如我们所提到的，强盗问题有许多实际应用。因此，如果你已经在自己的业务或研究中遇到一个可以建模为强盗问题的情况，也不会感到惊讶。现在你知道如何构造和解决一个强盗问题，去应用你所学的知识吧！强盗问题对于发展解决探索与利用困境的直觉非常重要，这一困境几乎会出现在每个强化学习场景中。
- en: Now that you have a solid understanding of how to solve one-step RL, it is time
    to move on to full-blown multi-step RL. In the next chapter, we will go into the
    theory behind multi-step RL with Markov decision processes, and build the foundation
    for modern deep RL methods, which we will cover in the subsequent chapters.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经深入理解了如何解决单步强化学习，接下来是时候进入完整的多步强化学习了。在下一章中，我们将深入探讨与多步强化学习相关的马尔科夫决策过程理论，并为现代深度强化学习方法打下基础，这些方法将在随后的章节中讨论。
- en: References
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Bouneffouf, D., & Rish, I. (2019). *A Survey on Practical Applications of Multi-Armed
    and Contextual Bandits*. Retrieved from arXiv: [https://arxiv.org/abs/1904.10040](https://arxiv.org/abs/1904.10040)'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bouneffouf, D., & Rish, I. (2019). *多臂和情境强盗的实际应用调查*. 取自 arXiv: [https://arxiv.org/abs/1904.10040](https://arxiv.org/abs/1904.10040)'
- en: 'Chandrashekar, A., Amat, F., Basilico, J., & Jebara, T. (2017, December 7).
    Netflix Technology Blog. Retrieved from Artwork Personalization at Netflix: [https://netflixtechblog.com/artwork-personalization-c589f074ad76](https://netflixtechblog.com/artwork-personalization-c589f074ad76)'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chandrashekar, A., Amat, F., Basilico, J., & Jebara, T. (2017年12月7日). Netflix
    技术博客. 取自 Netflix 的艺术作品个性化: [https://netflixtechblog.com/artwork-personalization-c589f074ad76](https://netflixtechblog.com/artwork-personalization-c589f074ad76)'
- en: Chapelle, O., & Li, L. (2011). *An Empirical Evaluation of Thompson Sampling.
    Advances in Neural Information Processing Systems*, 24, (pp. 2249-2257)
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chapelle, O., & Li, L. (2011). *汤普森采样的实证评估. 神经信息处理系统进展*, 24, (第2249-2257页)
- en: 'Collier, M., & Llorens, H. U. (2018). *Deep Contextual Multi-armed Bandits*.
    Retrieved from arXiv: [https://arxiv.org/abs/1807.09809](https://arxiv.org/abs/1807.09809)'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Collier, M., & Llorens, H. U. (2018). *深度情境多臂强盗*. 取自 arXiv: [https://arxiv.org/abs/1807.09809](https://arxiv.org/abs/1807.09809)'
- en: Gal, Y., Hron, J., & Kendall, A. (2017). *Concrete Dropout. Advances in Neural
    Information Processing Systems*, 30, (pp. 3581-3590)
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gal, Y., Hron, J., & Kendall, A. (2017). *具体丢弃法. 神经信息处理系统进展*, 30, (第3581-3590页)
- en: 'Marmerola, G. D. (2017, November 28). *Thompson Sampling for Contextual bandits*.
    Retrieved from Guilherme''s blog: [https://gdmarmerola.github.io/ts-for-contextual-bandits](https://gdmarmerola.github.io/ts-for-contextual-bandits)'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Marmerola, G. D. (2017年11月28日). *情境强盗的汤普森采样*. 取自 Guilherme 的博客: [https://gdmarmerola.github.io/ts-for-contextual-bandits](https://gdmarmerola.github.io/ts-for-contextual-bandits)'
- en: 'Riquelme, C., Tucker, G., & Snoek, J. (2018). *Deep Bayesian Bandits Showdown:
    An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling*. International
    Conference on Learning Representations (ICLR)'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Riquelme, C., Tucker, G., & Snoek, J. (2018). *深度贝叶斯强盗对决：汤普森采样的贝叶斯深度网络实证比较*.
    国际学习表征会议（ICLR）
- en: Russo, D., Van Roy, B., Kazerouni, A., Osband, I., & Wen, Z. (2018). *A Tutorial
    on Thompson Sampling. Foundations and Trends in Machine Learning*, (pp. 1-96)
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russo, D., Van Roy, B., Kazerouni, A., Osband, I., & Wen, Z. (2018). *Thompson
    Sampling 教程。机器学习基础与趋势*，（第1-96页）
- en: Lomas, D., Forlizzi, J., Poonawala, N., Patel, N., Shodhan, S., Patel, K., Koedinger,
    K., & Brunskill, E. (2016). *Interface Design Optimization as a Multi-Armed Bandit
    Problem*. (pp. 4142-4153). 10.1145/2858036.2858425
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lomas, D., Forlizzi, J., Poonawala, N., Patel, N., Shodhan, S., Patel, K., Koedinger,
    K., & Brunskill, E. (2016). *作为多臂 bandit 问题的界面设计优化*。（第4142-4153页）。10.1145/2858036.2858425
- en: Durand, A., Achilleos, C., Iacovides, D., Strati, K., Mitsis, G.D., & Pineau,
    J. (2018). *Contextual Bandits for Adapting Treatment in a Mouse Model of de Novo
    Carcinogenesis*. Proceedings of the 3rd Machine Learning for Healthcare Conference,
    in PMLR 85:67-82
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Durand, A., Achilleos, C., Iacovides, D., Strati, K., Mitsis, G.D., & Pineau,
    J. (2018). *用于在小鼠新生致癌模型中适应性治疗的上下文 bandit 方法*。第三届医疗健康机器学习会议论文集，PMLR 85:67-82
- en: Bastani, H. & Bayati, M. (2015). *Online decision-making with high-dimensional
    covariates*. Available at SSRN 2661896
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bastani, H. & Bayati, M. (2015). *具有高维协变量的在线决策制定*。可在 SSRN 2661896 上获得
