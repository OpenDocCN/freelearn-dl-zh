- en: Creating a Movie Recommendation Engine with Keras
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Keras创建电影推荐引擎
- en: 'The following recipes will be covered in this chapter:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: Downloading MovieLens datasets
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载MovieLens数据集
- en: Manipulating and merging the MovieLens datasets
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作和合并MovieLens数据集
- en: Exploring the MovieLens datasets
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索MovieLens数据集
- en: Preparing dataset for the deep learning pipeline
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为深度学习管道准备数据集
- en: Applying the deep learning pipeline with Keras
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Keras应用深度学习管道
- en: Evaluating the recommendation engine's accuracy
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估推荐引擎的准确性
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In 2006, a small DVD rental company set out to make their recommendation engine
    10% better. That company was Netflix and The Netflix Prize was worth $1M. This
    competition attracted many engineers and scientists from some of the largest tech
    companies around the world. The recommendation engine for the winning participant
    was built with machine learning. Netflix is now one of the leading tech giants
    when it comes to streaming data and recommending to its customers what they should
    watch next.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 2006年，一家小型DVD租赁公司开始致力于让他们的推荐引擎提升10%。这家公司就是Netflix，而Netflix奖的奖金为100万美元。这个竞赛吸引了来自全球一些最大科技公司的工程师和科学家。获胜者的推荐引擎是用机器学习构建的。如今，Netflix已经成为流媒体数据和向客户推荐下一部观看内容的科技巨头之一。
- en: Ratings are everywhere these days, no matter what you are doing. If you are
    looking for a recommendation to go out to eat at a new restaurant, to order some
    clothing online, to watch a new movie at your local theater, or to watch a new
    series on television or online, there is most likely a website or a mobile application
    that will give you some type of rating along with feedback on the product or service
    you are looking to purchase. It is because of this immediate increase in feedback
    that recommendation algorithms have become more in demand over the last couple
    of years. This chapter will focus on building a movie recommendation engine for
    users, using the deep learning library Keras.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，评分无处不在，不管你在做什么。如果你正在寻找推荐去新餐馆吃饭、在线购买衣物、在当地影院观看新电影，或者在电视或网络上观看新剧集，极有可能会有一个网站或移动应用提供一些评分以及你所要购买的产品或服务的反馈。正是因为这种即时反馈的增加，推荐算法在过去几年变得更加受欢迎。本章将重点讲解如何使用深度学习库Keras为用户构建一个电影推荐引擎。
- en: Downloading MovieLens datasets
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载MovieLens数据集
- en: There is a great research lab center that began in 1992 in Minneapolis, MN called
    **GroupLens**, whichfocuses on recommendation engines and has graciously put together
    millions of rows of data over several years from the MovieLens website. We will
    use its dataset as our data source for training our recommendation engine model.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个很棒的研究实验室，成立于1992年，位于美国明尼阿波利斯市，名为**GroupLens**，专注于推荐引擎，并慷慨地从MovieLens网站收集了数百万行数据。我们将使用它的数据集作为训练我们推荐引擎模型的数据源。
- en: Getting ready
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The MovieLens dataset is housed and maintained by GroupLens on the following
    website:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: MovieLens数据集由GroupLens托管和维护，网址如下：
- en: '[https://grouplens.org/datasets/movielens/](https://grouplens.org/datasets/movielens/).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://grouplens.org/datasets/movielens/](https://grouplens.org/datasets/movielens/)。'
- en: 'It is important to note that the dataset we will use will come directly from
    their website and not from a third-party intermediary or repository. Additionally,
    there are two different datasets that are available for us to query:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，我们将使用的数据集将直接来自他们的网站，而不是来自第三方中介或仓库。此外，有两个不同的数据集供我们查询：
- en: Recommended for new research
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐用于新研究
- en: Recommended for education and development
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐用于教育和开发
- en: 'The purpose of using this dataset is purely for educational purposes, so we
    will download the data from the education and development section of the website.
    The educational data still contains a significant number of rows for our model,
    as it contains 100,000 ratings, as seen in the following screenshot:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个数据集的目的是纯粹为了教育目的，因此我们将从网站的教育和开发部分下载数据。教育数据仍包含足够多的行供我们的模型使用，因为它包含了100,000条评分，如下图所示：
- en: '![](img/fab49ebd-7fe9-4090-9a3b-8156637c0290.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fab49ebd-7fe9-4090-9a3b-8156637c0290.png)'
- en: Additionally, this dataset has information regarding over 600 anonymous users
    collected over a period of several years between 1/9/1995 and 3/31/2015\. The
    dataset was last updated in October 2017.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，该数据集包含了超过600个匿名用户的信息，这些信息是从1995年1月9日到2015年3月31日这段时间内收集的。数据集最后一次更新是在2017年10月。
- en: 'F Maxwell Harper and Joseph A Konstan, 2015\. *The MovieLens Datasets: History
    and Context*. ACM **Transactions on Interactive Intelligent Systems** (**TiiS**)
    5, 4, Article 19 (December 2015), 19 pages. DOI: [http://dx.doi.org/10.1145/2827872](http://dx.doi.org/10.1145/2827872)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: F Maxwell Harper 和 Joseph A Konstan, 2015\. *The MovieLens 数据集：历史与背景*。ACM **交互智能系统期刊**
    (**TiiS**) 5, 4, 文章 19（2015年12月），第19页。DOI：[http://dx.doi.org/10.1145/2827872](http://dx.doi.org/10.1145/2827872)
- en: How to do it...
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'This section will cover downloading and unzipping the MovieLens dataset:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍如何下载并解压 MovieLens 数据集：
- en: Download the research version of the smaller MovieLens dataset, which is available
    for public download at the following website: [https://grouplens.org/datasets/movielens/latest/](https://grouplens.org/datasets/movielens/latest/).
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载 MovieLens 数据集的研究版本，该版本可从以下网址公开下载：[https://grouplens.org/datasets/movielens/latest/](https://grouplens.org/datasets/movielens/latest/)。
- en: 'Download the `ZIP` file called `ml-latest-small.zip` to one of our local folders,
    as seen in in the following screenshot:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将名为 `ml-latest-small.zip` 的 `ZIP` 文件下载到我们本地的某个文件夹中，如以下截图所示：
- en: '![](img/96e7ba85-7262-4431-bcb2-1efb3b9a4332.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96e7ba85-7262-4431-bcb2-1efb3b9a4332.png)'
- en: 'When `ml-latest-small.zip` is downloaded and unzipped, the following four files
    should be extracted:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当 `ml-latest-small.zip` 被下载并解压时，应该提取以下四个文件：
- en: '`links.csv`'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`links.csv`'
- en: '`movies.csv`'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`movies.csv`'
- en: '`ratings.csv`'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ratings.csv`'
- en: '`` `tags.csv` ``'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`` `tags.csv` ``'
- en: 'Execute the following script to begin our `SparkSession`:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本来启动我们的 `SparkSession`：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Confirm the following six files are available for access by executing the following
    script:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下脚本，确认以下六个文件可以访问：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Load each dataset into a Spark dataframe using the following script:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本将每个数据集加载到 Spark 数据框中：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Confirm the row counts for each dataset by executing the following script:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下脚本，确认每个数据集的行数：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: How it works...
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'This section will focus on explaining the fields in each of the datasets available
    in the MovieLens 100K dataset. Take a look at these steps:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将重点解释 MovieLens 100K 数据集中每个数据集中的字段。请查看以下步骤：
- en: 'The datasets are all available in the zipped file, `ml-latest-small.zip`, where
    the `ratings.csv` dataset will serve as the pseudo-fact table of our data, since
    it has transactions for each movie that is rated. The dataset, `ratings`, has
    the four column names shown in the following screenshot:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集都可以在压缩文件 `ml-latest-small.zip` 中找到，其中 `ratings.csv` 数据集将作为我们数据的伪事实表，因为它包含每个评分电影的交易记录。数据集
    `ratings` 有以下四个列名，见下图：
- en: '![](img/0694eb08-d2d3-4314-b351-c58bf888f100.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0694eb08-d2d3-4314-b351-c58bf888f100.png)'
- en: 'The dataset shows the rating selected by each userId over the course of their
    time, from the earliest rating to the latest rating. The range of a rating can
    vary from 0.5 to 5.0 stars, as seen by `userId = 1` in the following screenshot:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集展示了每个 userId 在其使用期间的评分，从最早的评分到最新的评分。评分范围从 0.5 到 5.0 星，以下截图显示了 `userId = 1`
    的评分：
- en: '![](img/46bff071-431b-47ef-bdd6-f6d0696be41a.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/46bff071-431b-47ef-bdd6-f6d0696be41a.png)'
- en: 'The `tags` dataset contains a tag column that contains a specific word or phrase
    used by that user to describe a specific movieId at a specific timestamp. As can
    be seen in the following screenshot, userId 15 was not particularly fond of Sandra
    Bulluck in one of her movies:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`tags` 数据集包含一个标签列，其中包含用户用来描述特定 movieId 在特定时间戳下的特定单词或短语。如下图所示，userId 15 对 Sandra
    Bullock 在其一部电影中的表现并不特别喜爱：'
- en: '![](img/7ae51ecd-e9ce-4675-bbec-503239ddd17a.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7ae51ecd-e9ce-4675-bbec-503239ddd17a.png)'
- en: 'The `movies` dataset is primarily a lookup table for the genre of films that
    have ratings. There are 19 unique genres that can be associated with a film; however,
    it is important to note that a film can be affiliated with more than one genre
    at a time, as seen in the following screenshot:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`movies` 数据集主要是一个查找表，用于电影类型与评分之间的关联。电影可以关联 19 种独特的类型；然而，需要注意的是，一部电影可以同时关联多种类型，如以下截图所示：'
- en: '![](img/1d6b42d9-ac4b-43d2-80bc-a98199959546.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d6b42d9-ac4b-43d2-80bc-a98199959546.png)'
- en: 'The final dataset is the `links` dataset, which also functions as a lookup
    table. It connects movies from MovieLens to data available for those same movies
    on popular film database sites such as [http://www.imdb.com](http://www.imdb.com),
    as well as [https://www.themoviedb.org](https://www.themoviedb.org). Links to
    IMDB are under the column called imdbId, and links to the MovieDB are under the
    column called tmdbId, as seen in the following screenshot:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终的数据集是`links`数据集，它也充当一个查找表。它将MovieLens中的电影与这些电影在流行电影数据库网站上的相关数据连接起来，比如[http://www.imdb.com](http://www.imdb.com)，以及[https://www.themoviedb.org](https://www.themoviedb.org)。IMDB的链接位于名为imdbId的列下，MovieDB的链接位于名为tmdbId的列下，如下图所示：
- en: '![](img/0b327b48-7367-4dbe-a908-f1af5c8d6a3f.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0b327b48-7367-4dbe-a908-f1af5c8d6a3f.png)'
- en: 'Before we finish, it is always a good idea to confirm that we are truly experiencing
    the expected row counts from all of the datasets. This helps to ensure that we
    did not encounter any issues with uploading the files to the notebook. We should
    expect to see around 100k rows for the ratings dataset, as seen in the following
    screenshot:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们完成之前，确认我们确实得到了期望的行数总是一个好主意，这有助于确保我们在上传文件到笔记本时没有遇到任何问题。我们应该期望看到约10万行的评分数据集，如下图所示：
- en: '![](img/2984e7d6-e073-4bd9-ae06-2c20c2518f64.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2984e7d6-e073-4bd9-ae06-2c20c2518f64.png)'
- en: There's more...
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'While we are not going to use the 20 million-row dataset version of MovieLens
    for this chapter, you could elect to use it for this recommendation engine. You
    will still have the same four datasets, but with much more data, especially for
    the `ratings` dataset. If you choose to go with this approach, the full zipped
    dataset can be downloaded from the following website:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们在本章中不会使用MovieLens的2000万行数据集版本，但你可以选择在此推荐引擎中使用它。你仍然会有相同的四个数据集，只是数据量更大，尤其是`ratings`数据集。如果你选择这种方法，可以从以下网站下载完整的压缩数据集：
- en: '[http://files.grouplens.org/datasets/movielens/ml-latest.zip](http://files.grouplens.org/datasets/movielens/ml-latest.zip)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://files.grouplens.org/datasets/movielens/ml-latest.zip](http://files.grouplens.org/datasets/movielens/ml-latest.zip)'
- en: See also
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'To learn more about the metadata behind the MovieLens dataset used in this
    chapter, visit the following website:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于本章使用的MovieLens数据集背后的元数据，请访问以下网站：
- en: '[http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html](http://files.grouplens.org/datasets/movielens/ml-latest-small-README.html)'
- en: 'To learn more about the history and context of the MovieLens dataset used in
    this chapter, visit the following website:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于本章使用的MovieLens数据集的历史和背景，请访问以下网站：
- en: '[https://www.slideshare.net/maxharp3r/the-movielens-datasets-history-and-context](https://www.slideshare.net/maxharp3r/the-movielens-datasets-history-and-context)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.slideshare.net/maxharp3r/the-movielens-datasets-history-and-context](https://www.slideshare.net/maxharp3r/the-movielens-datasets-history-and-context)'
- en: 'To learn more about *The Netflix Prize*, visit the following website:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于*Netflix大奖*的信息，请访问以下网站：
- en: '[https://www.netflixprize.com/](https://www.netflixprize.com/)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.netflixprize.com/](https://www.netflixprize.com/)'
- en: Manipulating and merging the MovieLens datasets
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作和合并MovieLens数据集
- en: We currently have four separate datasets that we are working with, but ultimately
    we would like to get it down to a single dataset. This chapter will focus on pairing
    down our datasets to one.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 目前我们有四个独立的数据集，但最终我们希望将它们整合成一个数据集。本章将专注于将数据集缩减为一个。
- en: Getting ready
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: This section will not require any import of PySpark libraries but a background
    in SQL joins will come in handy, as we will explore multiple approaches to joining
    dataframes.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本节不需要导入PySpark库，但了解SQL连接的背景知识会非常有帮助，因为我们将探索多种连接数据框的方法。
- en: How to do it...
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到……
- en: 'This section will walk through the following steps for joining dataframes in
    PySpark:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍以下步骤来连接PySpark中的数据框：
- en: 'Execute the following script to rename all field names in `ratings`, by appending
    a `_1` to the end of the name:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本将`ratings`中的所有字段名称重命名，在名称末尾附加一个`_1`：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Execute the following script to `inner join` the `movies` dataset to the `ratings`
    dataset, creating a new table called `temp1`:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本将`movies`数据集与`ratings`数据集进行`inner join`，创建一个新的表格，名为`temp1`：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Execute the following script to inner join the `temp1` dataset to the `links`
    dataset, creating a new table called `temp2`:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本将`temp1`数据集与`links`数据集进行内连接，创建一个新的表格，名为`temp2`：
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Create our final combined dataset, `mainDF`, by left-joining `temp2` to `tags`
    using the following script:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过以下脚本，将`temp2`与`tags`左连接，创建我们的最终合并数据集`mainDF`：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Select only the columns needed for our final `mainDF` dataset by executing
    the following script:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下脚本，仅选择我们最终`mainDF`数据集所需的列：
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: How it works...
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'This section will walk through our design process for joining tables together
    as well as which final columns will be kept:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍我们将表格连接在一起的设计过程，以及哪些最终列会被保留：
- en: 'As was mentioned in the previous section, the ratings dataframe will serve
    as our fact table, since it contains all the main transactions of ratings for
    each user over time. The columns in ratings will be used in each subsequent join
    with the other three tables, and to maintain a uniqueness of the columns, we will
    attach a _1 to the end of each column name, as seen in the following screenshot:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如前一节中提到的，`ratings`数据框将作为我们的事实表，因为它包含每个用户随着时间推移的所有主要评分交易。`ratings`中的列将用于与其他三个表的每次后续连接，为了保持列的唯一性，我们将给每个列名后加上`_1`，如以下截图所示：
- en: '![](img/4b7f411f-5d3c-4e7d-b168-31fff520c535.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4b7f411f-5d3c-4e7d-b168-31fff520c535.png)'
- en: 'We can now join the three lookup tables to the ratings table. The first two
    joins to ratings are inner joins, as the row counts for temp1 and temp2 are still
    100,004 rows. The third join to ratings from tags needs to be an outer join to
    avoid dropping rows. Additionally, the join needs to be applied to both movieId
    as well as userId, as a tag is unique to both a specific user and a specific movie
    at any given time. The row counts for the three tables temp1, temp2, and mainDF
    can be seen in the following screenshot:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在可以将三个查找表与评分表连接。前两个与评分表的连接是内连接，因为`temp1`和`temp2`的行数仍为100,004行。从`tags`表连接的第三个连接需要是外连接，以避免丢失行。此外，连接需要应用于`movieId`和`userId`，因为一个标签在任何给定时间都是特定用户和特定电影唯一的。三个表`temp1`、`temp2`和`mainDF`的行数可以在下图中看到：
- en: '![](img/a4d62f47-77b8-4443-ac41-4c9dcbe4a47b.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a4d62f47-77b8-4443-ac41-4c9dcbe4a47b.png)'
- en: 'Often times when working with joins between datasets, we encounter three types
    of joins: inner, left, and right. An inner join will only produce a result set
    when both join keys are available from dataset 1 and dataset 2\. A left join will
    produce all of the rows from dataset 1 and only the rows with matching keys from
    dataset 2\. A right join will produce all of the rows from dataset 2 and only
    the rows from the matching keys from dataset 1\. Later on in this section, we
    will explore SQL joins within Spark.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理数据集之间的连接时，我们经常会遇到三种类型的连接：内连接（inner）、左连接（left）和右连接（right）。内连接只有在数据集1和数据集2的连接键都可用时，才会生成结果集。左连接将生成数据集1中的所有行，以及仅包含与数据集2中的匹配键的行。右连接将生成数据集2中的所有行，以及仅包含与数据集1中的匹配键的行。稍后在本节中，我们将探索Spark中的SQL连接。
- en: 'It is interesting to note that our newly created dataset, mainDF, has 100,441
    rows, instead of the 100,004 rows that are in the original dataset for ratings,
    as well as temp1 and temp2\. There are 437 ratings that have more than one tag
    associated with them. Additionally, we can see that the majority of ratings_1 have
    a null tag value affiliated with them, as seen in the following screenshot:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有趣的是，我们新创建的数据集`mainDF`有100,441行，而不是原始`ratings`数据集中的100,004行，以及`temp1`和`temp2`。其中有437个评分与多个标签相关联。此外，我们还可以看到，大多数`ratings_1`的`tag`值为null，如下图所示：
- en: '![](img/8a98e621-ab31-4307-ad13-356e3ce4a70e.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8a98e621-ab31-4307-ad13-356e3ce4a70e.png)'
- en: 'We have accumulated additional duplicative columns that will no longer be needed.
    There are 14 columns in total, as seen in the following screenshot:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们积累了不再需要的重复列。共有14列，如下图所示：
- en: '![](img/02801672-6ad8-41ee-a068-550a76eb103b.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/02801672-6ad8-41ee-a068-550a76eb103b.png)'
- en: 'Additionally, we have determined that the tags field is relatively useless
    as it has over 99k null values. Therefore, we will use the `select()` function
    on the dataframe to pull in only the eight columns that we will use for our recommendation
    engine. We can then confirm that our final new dataframe, mainDF, has the correct
    amount of rows, 100,004, as seen in the following screenshot:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，我们已经确定，`tags`字段相对没有用，因为它有超过99k的空值。因此，我们将使用`select()`函数从数据框中仅提取我们将用于推荐引擎的八列。然后，我们可以确认我们的最终新数据框`mainDF`具有正确的行数100,004，如下图所示：
- en: '![](img/46d3d417-ff51-4850-8611-2d86851293a9.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/46d3d417-ff51-4850-8611-2d86851293a9.png)'
- en: There's more...
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'While we did do our joins using functions within a Spark dataframe using PySpark,
    we could have also done it by registering the dataframes as temporary tables and
    then joining them using `sqlContext.sql()`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们通过在Spark dataframe中使用PySpark的函数进行了连接，但我们也可以通过将数据框注册为临时表，然后使用`sqlContext.sql()`进行连接：
- en: 'First, we would register each of our datasets as temporary views using `creatorReplaceTempView()`,
    as seen in the following script:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将使用`creatorReplaceTempView()`将每个数据集注册为临时视图，如下脚本所示：
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we would write our SQL script just as we would do with any other relational
    database using the `sqlContext.sql()` function, as seen in the following script:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将像操作任何其他关系数据库一样，使用`sqlContext.sql()`函数编写SQL脚本，如下脚本所示：
- en: '[PRE10]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Finally, we can profile the new dataframe, mainDF_SQL, and observe that it
    looks the same as our other dataframe, mainDF, while also keeping the exact same
    row count, as seen in the following screenshot:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以对新的数据框`mainDF_SQL`进行分析，观察其与另一个数据框`mainDF`相同，且行数保持一致，如下截图所示：
- en: '![](img/bf1bd64c-b1d0-40d1-b786-ed4c8b99ca41.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bf1bd64c-b1d0-40d1-b786-ed4c8b99ca41.png)'
- en: See also
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'To learn more about SQL programming within Spark, visit the following website:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于Spark中SQL编程的信息，请访问以下网站：
- en: '[https://spark.apache.org/docs/latest/sql-programming-guide.html](https://spark.apache.org/docs/latest/sql-programming-guide.html)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/docs/latest/sql-programming-guide.html](https://spark.apache.org/docs/latest/sql-programming-guide.html)'
- en: Exploring the MovieLens datasets
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索MovieLens数据集
- en: Before any modeling takes place, it is important to get familiar with the source
    dataset and perform some exploratory data analysis.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行任何建模之前，熟悉源数据集并进行一些探索性数据分析是非常重要的。
- en: Getting ready
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We will import the following library to assist with visualizing and exploring
    the MovieLens dataset: `matplotlib`.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将导入以下库来帮助可视化和探索MovieLens数据集：`matplotlib`。
- en: How to do it...
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'This section will walk through the steps to analyze the movie ratings in the
    MovieLens database:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将逐步讲解如何分析MovieLens数据库中的电影评分：
- en: 'Retrieve some summary statistics on the `rating_1` column by executing the
    following script:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下脚本，获取`rating_1`列的一些汇总统计数据：
- en: '[PRE11]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Build a histogram of the distribution of ratings by executing the following
    script:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下脚本，构建评分分布的直方图：
- en: '[PRE12]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Execute the following script to view the values of the histogram in a spreadsheet
    dataframe:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，以在电子表格数据框中查看直方图的值：
- en: '[PRE13]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'A unique count of user selections of ratings can be stored as a dataframe, `userId_frequency`,
    by executing the following script:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户对评分选择的唯一计数可以通过执行以下脚本存储为数据框`userId_frequency`：
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Plot a histogram of `userID_frequency` using the following script:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本绘制`userID_frequency`的直方图：
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: How it works...
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'This section will discuss how the ratings and user activities are distributed
    in the MovieLens database. Take a look at these steps:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将讨论MovieLens数据库中评分和用户活动的分布。请查看以下步骤：
- en: 'We can see that the average movie rating made by a user is approximately 3.5,
    as seen in the following screenshot:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到，用户对电影的平均评分约为3.5，如下截图所示：
- en: '![](img/9bf2ee64-20b9-49c6-ac0d-7099c4beed8d.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9bf2ee64-20b9-49c6-ac0d-7099c4beed8d.png)'
- en: 'Even though the average rating is 3.54, we can see that the histogram shows
    that the median rating is 4, which indicates that the user ratings are heavily
    skewed towards higher ratings, as seen in the following screenshot:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽管平均评分为3.54，但我们可以看到直方图显示中位数评分为4，这表明用户评分明显偏向较高的评分，如下截图所示：
- en: '![](img/01032540-4b8b-4b6e-8038-830800a2aa5a.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/01032540-4b8b-4b6e-8038-830800a2aa5a.png)'
- en: 'Another look at the data behind the histogram shows that users select 4.0 most
    frequently, followed by 3.0, and then 5.0\. Additionally, it is interesting to
    note that users are more likely to give ratings that are at the 0.0 level and
    not at the 0.5 level, as seen in the following screenshot:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过对直方图背后的数据进行进一步分析，我们可以看到用户最常选择4.0评分，其次是3.0，再然后是5.0。此外，有趣的是，用户更倾向于给出0.0评分，而非0.5评分，如下图所示：
- en: '![](img/0e0481f0-b6f5-442c-90a4-a08c40ff4629.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0e0481f0-b6f5-442c-90a4-a08c40ff4629.png)'
- en: 'We can look at the distribution of user selection of ratings and see that some
    users are very active in expressing their opinions on the films they''ve seen.
    This is the case with anonymous user 547 who has posted 2391 ratings, as seen
    in the following screenshot:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以查看用户评分选择的分布，看到一些用户在表达他们对电影的看法时非常活跃。例如，匿名用户 547 就发布了 2391 条评分，以下截图为证：
- en: '![](img/f646edec-36fa-4edc-b64e-005cbf035ca5.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f646edec-36fa-4edc-b64e-005cbf035ca5.png)'
- en: 'However, when we look at the distribution of users making rating selections,
    we do see that while there are some instances of users making over a thousand
    selections on their own, the overwhelming majority of users have made less than
    250 selections, as seen in the following screenshot:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然而，当我们查看用户评分选择的分布时，我们确实发现，尽管有些用户自己做出了超过一千个选择，但绝大多数用户的选择次数少于 250 次，以下截图可见一斑：
- en: '![](img/32fd3b17-ec38-4450-83b8-fc1746b3b68b.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/32fd3b17-ec38-4450-83b8-fc1746b3b68b.png)'
- en: The distribution of the histogram is the previous screenshot is in a long-tail
    format which indicates that the majority of the occurrences are away from the
    center of the histogram. This is an indication that the overwhelming majority
    of ratings are defined by a few users.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上一张截图中直方图的分布呈长尾格式，表明大多数数据点位于直方图中心的两侧。这表明绝大多数评分是由少数用户定义的。
- en: There's more...
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: There are features that the `pyspark` dataframe that are similar to those of
    the `pandas` dataframe and can perform some summary statistics on specific columns.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyspark` 数据框架具有与 `pandas` 数据框架类似的特性，可以对特定列执行一些汇总统计。'
- en: 'In `pandas`, we perform summary statistics using the following script: `dataframe[''column''].describe()`.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `pandas` 中，我们使用以下脚本执行汇总统计：`dataframe['column'].describe()`。
- en: 'In `pyspark`, we perform summary statistics using the following script: `dataframe.describe(''column'').show()`.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `pyspark` 中，我们使用以下脚本执行汇总统计：`dataframe.describe('column').show()`。
- en: See also
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'To learn more about the `describe()` function in PySpark, visit the following
    website:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关 PySpark 中 `describe()` 函数的更多信息，请访问以下网站：
- en: '[http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.describe](http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.describe)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.describe](http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.describe)'
- en: Preparing dataset for the deep learning pipeline
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为深度学习管道准备数据集
- en: We are now ready to prepare our dataset to be fed into the deep learning model
    that we will build in Keras.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备将数据集准备好，以便输入到我们将在 Keras 中构建的深度学习模型中。
- en: Getting ready
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'While preparing the dataset for `Keras` we will import the following libraries
    into our notebook:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在为 `Keras` 准备数据集时，我们将导入以下库到我们的笔记本中：
- en: '`import pyspark.sql.functions as F`'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import pyspark.sql.functions as F`'
- en: '`import numpy as np`'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import numpy as np`'
- en: '`from pyspark.ml.feature import StringIndexer`'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from pyspark.ml.feature import StringIndexer`'
- en: '`import keras.utils`'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import keras.utils`'
- en: How to do it...
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'This section walks through the following steps to prepare the dataset for the
    deep learning pipeline:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 本节通过以下步骤讲解如何为深度学习管道准备数据集：
- en: 'Execute the following script to clean up the column names:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本来清理列名：
- en: '[PRE16]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `rating` column is currently divided into 0.5 increments. Tweak the ratings
    to be rounded to a whole integer using the following script:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`rating` 列目前按 0.5 的增量进行划分。使用以下脚本将评分调整为四舍五入到整数：'
- en: '[PRE17]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Convert the `genres` column from a string to an index with a name of `genreCount`
    based on the frequency of the `genres` labels as seen in the following script:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本将 `genres` 列从字符串转换为基于 `genres` 标签频率的索引，并命名为 `genreCount`：
- en: '[PRE18]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Pair down our dataframe using the following script:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本对我们的数据框进行精简：
- en: '[PRE19]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Split `mainDF` into a training and testing set for model-training purposes,
    using the following script:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本将 `mainDF` 分割为训练集和测试集，以便用于模型训练：
- en: '[PRE20]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Convert our two Spark dataframes, `trainDF` and `testDF`, into four `numpy`
    arrays for consumption within our deep learning model using the following script:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本将我们的两个 Spark 数据框 `trainDF` 和 `testDF` 转换为四个 `numpy` 数组，以供深度学习模型使用：
- en: '[PRE21]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Convert both `ytrain_array` and `ytest_array` into one-hot encoded labels,
    `ytrain_OHE` and `ytest_OHE`, using the following script:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本将 `ytrain_array` 和 `ytest_array` 转换为独热编码标签 `ytrain_OHE` 和 `ytest_OHE`：
- en: '[PRE22]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: How it works...
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'This section explains how we prepare the dataset for the deep learning pipeline:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 本节说明了如何为深度学习管道准备数据集：
- en: 'For ease of use inside the deep learning pipeline, it is best to clean up the
    column names and the order of the columns before the pipeline receives the data.
    After renaming the column headers, we can view the updated columns, as seen in
    the following script:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了在深度学习管道中更方便地使用，最好在数据传入管道之前清理列名和列的顺序。重命名列标题后，我们可以查看更新后的列，如以下脚本所示：
- en: '![](img/48d6fbb2-a88d-4f5d-8cc3-63d6d7c0a4e5.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/48d6fbb2-a88d-4f5d-8cc3-63d6d7c0a4e5.png)'
- en: A bit of manipulation is performed on the `ratings` column to round up values
    of 0.5 increments to the next-highest whole number. This will assist when we are
    doing our multi-class classification within Keras to group `ratings` into six
    categories, instead of 11 categories.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对 `ratings` 列进行了一些操作，将 0.5 的增量值向上舍入到下一个整数。这将有助于在 Keras 中进行多分类时，将 `ratings` 分为六个类别，而不是
    11 个类别。
- en: 'To consume the movie genre types into the deep learning model within, we need
    to convert the string values of `genres` into a numeric label. The most frequent
    genres type will get a value of 0, and the values increase for the next most frequent-
    type. In the following screenshot, we can see that Good Will Hunting has two genres
    associated with it (Drama | Romance), and that is the fourth most-frequent genreCount,
    with a value of 3.0:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了将电影类型传入深度学习模型，我们需要将 `genres` 的字符串值转换为数值标签。最常见的电影类型将被赋值为 0，其他类型依次增加值。在下图中，我们可以看到《心灵捕手》有两个关联的类型（剧情
    | 爱情），这两种类型是第四常见的电影类型，`genreCount` 的值为 3.0：
- en: '![](img/b2052136-259d-4c20-904f-0680d8578a04.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b2052136-259d-4c20-904f-0680d8578a04.png)'
- en: 'The genres column is no longer needed for the deep model, as it will be replaced
    by the genreCount column, as seen in the following screenshot:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于深度模型来说，`genres` 列不再需要，因为它将被 `genreCount` 列替代，如下图所示：
- en: '![](img/1f9e53cc-18c8-41fe-a5a3-84038f749771.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1f9e53cc-18c8-41fe-a5a3-84038f749771.png)'
- en: 'Our main dataframe, mainDF, is split into a trainDF and testDF for modeling,
    training, and evaluation purposes, using an 80/20 split. The row count for all
    three dataframes can be seen in the following screenshot:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的主要数据框 `mainDF` 被分割为 `trainDF` 和 `testDF`，用于建模、训练和评估，采用 80/20 的比例划分。三个数据框的行数可以从下图看到：
- en: '![](img/b24c2d12-6e5e-48a8-8908-9bde8ebf6140.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b24c2d12-6e5e-48a8-8908-9bde8ebf6140.png)'
- en: 'Data is passed into a Keras deep learning model, using matrices instead of
    dataframes. Therefore, our training and testing dataframes are converted into
    numpy arrays and split out into *x* and *y*. The features selected for `xtrain_array`
    and `xtest_array` are userid, movieid, and genreCount. These are the only features
    that will we will use to determine what a potential rating will be for a user.
    We are dropping `imdbid` and `tmdbid`, as they are directly tied to the `movieid`
    and therefore will not provide any additional value. `timestamp` will be removed
    to filter out any bias associated with frequency of voting. Finally, `ytest_array`
    and `ytrain_array` will contain the label value for rating. The `shape` of all
    four arrays can be seen in the following screenshot:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据被传入 Keras 深度学习模型，使用矩阵而非数据框。因此，我们的训练和测试数据框被转换为 numpy 数组，并被拆分为 *x* 和 *y*。`xtrain_array`
    和 `xtest_array` 选取的特征为 userid、movieid 和 genreCount。这些是我们用来预测用户可能评分的唯一特征。我们会丢弃
    `imdbid` 和 `tmdbid`，因为它们直接与 `movieid` 相关，因此不会提供额外的价值。`timestamp` 会被移除，以过滤与投票频率相关的偏差。最后，`ytest_array`
    和 `ytrain_array` 将包含评分的标签值。所有四个数组的 `shape` 如下图所示：
- en: '![](img/9de44283-57bc-48f3-9746-89d0c2f7e6b6.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9de44283-57bc-48f3-9746-89d0c2f7e6b6.png)'
- en: There's more...
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'While `ytrain_array` and `ytest_array` are both labels in a matrix format,
    they are not ideally encoded for deep learning. Since this is technically a classification
    model that we are building we need to encode our labels in a manner for them to
    be understood by the model. This means that our ratings of 0 through 5 should
    be encoded as 0 or 1 values, based on their value elements. Therefore, if a rating
    received the highest value of 5, it should be encoded as [0,0,0,0,0,1]. The first
    position is reserved for 0, and the sixth position is reserved for 1, indicating
    a value of 5\. We can make this conversion using `keras.utils` and convert our
    categorical variables to one-hot encoded variables. In doing this, the shape of
    our training label is converted from (80146,1) to (80146,6) as seen in the following
    screenshot:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 `ytrain_array` 和 `ytest_array` 都是矩阵格式的标签，但它们并未针对深度学习进行理想的编码。由于我们正在构建的是一个分类模型，因此我们需要将标签编码为模型可以理解的方式。这意味着我们将
    0 到 5 的评分编码为 0 或 1 的值，基于其值元素。因此，如果某个评分获得了最高值 5，则应将其编码为 [0,0,0,0,0,1]。第一个位置保留为
    0，第六个位置保留为 1，表示值为 5。我们可以使用 `keras.utils` 进行这种转换，并将分类变量转换为独热编码变量。这样，我们的训练标签的形状将从
    (80146,1) 转换为 (80146,6)，如下图所示：
- en: '![](img/021a737b-3d8e-4bad-a1ff-7e33f7ea4bfa.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/021a737b-3d8e-4bad-a1ff-7e33f7ea4bfa.png)'
- en: See also
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: To learn more about `keras.utils` visit the following website: [https://keras.io/utils/](https://keras.io/utils/)
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 `keras.utils` 的信息，请访问以下网站：[https://keras.io/utils/](https://keras.io/utils/)
- en: Applying the deep learning model with Keras
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Keras 应用深度学习模型
- en: At this point, we are ready to apply Keras to our data.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们已经准备好将 Keras 应用于我们的数据。
- en: Getting ready
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We will be using the following from Keras:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下来自 Keras 的功能：
- en: '`from keras.models import Sequential`'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from keras.models import Sequential`'
- en: '`from keras.layers import Dense, Activation`'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from keras.layers import Dense, Activation`'
- en: How to do it...
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'This section walks through the following steps to apply a deep learning model,
    using Keras on our dataset:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了使用 Keras 在数据集上应用深度学习模型的步骤：
- en: 'Import the following libraries to build a `Sequential` model from `keras`,
    using the following script:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下库，以从 `keras` 构建一个 `Sequential` 模型，使用以下脚本：
- en: '[PRE23]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Configure the `Sequential` model from `keras`, using the following script:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本从 `keras` 配置 `Sequential` 模型：
- en: '[PRE24]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We `fit` and train the model and store the results to a variable called `accuracy_history`,
    using the following script:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用以下脚本 `fit` 并训练模型，并将结果存储到一个名为 `accuracy_history` 的变量中：
- en: '[PRE25]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: How it works...
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: This section explains the configuration of the Keras model that is applied to
    the dataset to predict a rating based on the features selected.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了将 Keras 模型应用于数据集的配置，目的是根据选定的特征预测评分。
- en: In Keras, a `Sequential` model is simply a linear combination of layers, which
    are the following: `Dense` is used to define the layer types to a fully-connected
    layer within a deep neural network. Finally, `Activation` is used to convert the
    inputs from the features into an output that can be used as a prediction. There
    are many types of activation functions that can be used in a neural network; however,
    for this chapter, we will go with `relu` and `softmax`.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Keras 中，`Sequential` 模型只是各层的线性组合，具体如下：`Dense` 用于定义深度神经网络中的全连接层。最后，`Activation`
    用于将输入的特征转换为可以作为预测结果的输出。神经网络中可以使用许多类型的激活函数；然而，在本章中，我们将使用 `relu` 和 `softmax`。
- en: 'The `Sequential` model is configured to include three `Dense` layers:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Sequential` 模型被配置为包括三个 `Dense` 层：'
- en: The first layer has `input_dim` set to the number of features from `xtrain_array`.
    The `shape` feature pulls in the value of 3, using `xtrain_array.shape[1]`. Additionally,
    the first layer is set to have `32` neurons in the first layer of the neural network.
    Finally, the three input parameters are activated using the `relu` activation
    function. Only the first layer requires an explicit definition of the input dimensions.
    This is not required in subsequent layers, as they will be able to infer the number
    of dimensions from the previous layer.
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个层的 `input_dim` 设置为来自 `xtrain_array` 的特征数量。`shape` 特性使用 `xtrain_array.shape[1]`
    拉取值 3。此外，第一层设置为在神经网络的第一层中有 `32` 个神经元。最后，三个输入参数使用 `relu` 激活函数进行激活。只有第一层需要显式定义输入维度。后续层不需要，因为它们可以从前一层推断维度的数量。
- en: The second layer in the `Sequential` model has `10` neurons in the neural network
    along with an activation function set to `relu`. Rectified linear units are used
    early on in the neural network process because they are effective during the training
    process. This is due to the simplicity of the equation as any value less than
    0 is thrown out, which is not the case with other activation functions.
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Sequential`模型的第二层在神经网络中有`10`个神经元，并且激活函数设置为`relu`。修正线性单元（ReLU）通常在神经网络的早期阶段使用，因为它们在训练过程中非常有效。这是因为该函数的方程简单，任何小于0的值都会被抛弃，而其他激活函数并非如此。'
- en: The third and final layer of the `Sequential` model requires six outputs based
    on every possible scenario of a rating from 0 to 5\. This requires setting the
    output to the value of `ytrain_OHE.shape[1]`. The output is generated using a
    `softmax` function which is often the case at the end of a neural network, as
    it is very useful for classification purposes. At this point, we are looking to
    classify a value between 0 and 5.
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Sequential`模型的第三层和最后一层需要基于从0到5的评分所有可能的情况输出六个结果。这需要将输出设置为`ytrain_OHE.shape[1]`的值。输出通过`softmax`函数生成，这通常是在神经网络的最后一层，因为它在分类任务中非常有用。此时，我们的目标是对0到5之间的值进行分类。'
- en: Once the layers are specified, we must `compile` the model.
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦指定了各层，我们就必须`compile`模型。
- en: We optimize the model using `adam`, which stands for **Adaptive Moment Estimation**.
    Optimizers are great for configuring the learning rate of the gradient descent
    that the model uses to tweak and update the weights of the neural network. `adam`
    is a popular optimizer, as it is said to combine some of the best features from
    other common optimizers.
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`adam`优化模型，`adam`代表**自适应矩估计**。优化器对于配置模型使用的梯度下降学习率非常有效，梯度下降用来调整和更新神经网络的权重。`adam`是一种流行的优化器，据说它结合了其他常见优化器的一些最佳特性。
- en: Our loss function is set to `categorical_crossentroy`, which is often used when
    looking to predict a multi-class classification. The loss function evaluates the
    performance of the model as it is being trained.
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的损失函数设置为`categorical_crossentropy`，该损失函数通常用于多类分类预测。损失函数评估模型在训练过程中的表现。
- en: 'We train the model using the training features, `xtrain_array`, and the training
    labels `ytrain_OHE`. The model is trained over 20 epochs, each time with a batch_size
    set to 32\. The model output for `accuracy` and `loss` over each epoch are captured
    in a variable called `accuracy_history` and can be viewed as seen in the following
    screenshot:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用训练特征`xtrain_array`和训练标签`ytrain_OHE`训练模型。模型在20个训练周期内进行训练，每次批次大小(batch_size)设为32。每个训练周期的`accuracy`和`loss`输出被捕获在一个名为`accuracy_history`的变量中，可以在下图中看到：
- en: '![](img/6c24e056-9301-4c7d-b800-9d5a954ed55e.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6c24e056-9301-4c7d-b800-9d5a954ed55e.png)'
- en: There's more...
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'While we can print out the loss and accuracy scores over each epoch, it is
    always better to visualize both outputs over each of the 20 epochs. We can plot
    both by using the following script:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以在每个训练周期输出损失和准确率分数，但将这两个输出可视化展示在每个20个训练周期中会更好。我们可以使用以下脚本来绘制这两个图：
- en: '[PRE26]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output of the script can be seen in the following screenshot:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本的输出可以在以下截图中看到：
- en: '![](img/d20c1722-00a2-4606-86cc-f3e7b74e6436.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d20c1722-00a2-4606-86cc-f3e7b74e6436.png)'
- en: It appears that after the second epoch, both the loss and accuracy are stabilized
    in the model.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来在第二个训练周期（epoch）之后，模型的损失和准确率都已经稳定下来。
- en: See also
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: To learn more about getting started with the `Sequential` model from `keras`,
    visit the following website: [https://keras.io/getting-started/sequential-model-guide/](https://keras.io/getting-started/sequential-model-guide/).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于如何开始使用Keras中的`Sequential`模型，请访问以下网站：[https://keras.io/getting-started/sequential-model-guide/](https://keras.io/getting-started/sequential-model-guide/)。
- en: Evaluating the recommendation engine's accuracy
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估推荐引擎的准确性
- en: We can now calculate the accuracy rate of our deep learning model built on Keras.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以计算基于Keras构建的深度学习模型的准确率。
- en: Getting ready
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Evaluating a `Sequential` model for accuracy requires using the `model.evaluate()`
    function within Keras.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 评估`Sequential`模型的准确性需要使用Keras中的`model.evaluate()`函数。
- en: How to do it...
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'We can simply calculate the accuracy score, `accuracy_rate`, by executing the
    following script:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需执行以下脚本即可计算准确率分数`accuracy_rate`：
- en: '[PRE27]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: How it works...
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'Our model performance is based on evaluating our test features, `xtest_array`,
    with our test labels, `ytest_OHE`. We can use `model.evaluate()` and set the `batch_size`
    for evaluation at `128` elements. We can see that our accuracy is around 39%,
    as seen in the following screenshot:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型性能基于使用测试特征`xtest_array`和测试标签`ytest_OHE`进行评估。我们可以使用`model.evaluate()`并将`batch_size`设置为`128`元素进行评估。我们可以看到准确率大约为
    39%，如以下截图所示：
- en: '![](img/c18890b0-ca4a-4eaa-89f2-db7bfef8e4d5.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c18890b0-ca4a-4eaa-89f2-db7bfef8e4d5.png)'
- en: This means that we are able to determine the rating by a user between 0 and
    5 and at nearly a 39% accuracy rate.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们能够以约 39% 的准确率确定用户的评分，评分范围是 0 到 5。
- en: See also
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'To learn more about model performance with Keras metrics, visit the following
    website:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关使用 Keras 指标评估模型性能的更多信息，请访问以下网站：
- en: '[https://keras.io/metrics/](https://keras.io/metrics/)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://keras.io/metrics/](https://keras.io/metrics/)'
