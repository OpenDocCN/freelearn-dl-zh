- en: '*Chapter 7*: Sentiment Analysis Using AutoKeras'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第7章*：使用 AutoKeras 进行情感分析'
- en: Let's start by defining the unusual term in the title. **Sentiment analysis**
    is a term that's widely used in text classification and it is basically about
    using **natural language processing** (**NLP**) in conjunction with **machine
    learning** (**ML**) to interpret and classify emotions in text.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先定义标题中的不寻常术语。**情感分析**是文本分类中广泛使用的术语，基本上是通过使用**自然语言处理**（**NLP**）结合**机器学习**（**ML**）来解读和分类文本中的情感。
- en: To get an idea of this, let's imagine the task of determining whether a review
    for a film is positive or negative. You could do this yourself just by reading
    it, right? However, if our boss sends us a list of 1,000 movie reviews for tomorrow,
    things become complicated. That's where sentiment analysis becomes an interesting
    option.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这个概念，让我们假设任务是判断一篇电影评论是正面还是负面。您自己看完评论就能做出判断，对吧？然而，如果我们的老板发给我们1000条电影评论让我们明天完成，那事情就复杂了。这就是情感分析变得有趣的地方。
- en: In this chapter, we will use a text classifier to extract sentiments from text
    data. Most of the concepts of text classification were already explained in [*Chapter
    4*](B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063), *Image Classification and
    Regression Using AutoKeras*, so in this chapter, we will apply them in a practical
    way by implementing a sentiment predictor. However, before we do that, we will
    look at the technical requirements we'll need to start working on it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将使用文本分类器从文本数据中提取情感。文本分类的大部分概念已经在[*第4章*](B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063)，*使用
    AutoKeras 进行图像分类和回归*中解释过了，所以在本章中，我们将通过实现情感预测器以一种实际的方式来应用它们。然而，在我们开始之前，我们将首先了解开始工作所需的技术要求。
- en: 'Specifically, the following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将具体涵盖以下主题：
- en: Creating a sentiment analyzer
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建情感分析器
- en: Creating the classifier
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建分类器
- en: Evaluating the model
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估模型
- en: Visualizing the model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化模型
- en: Analyzing the sentiment in specific sentences
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析特定句子中的情感
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the code examples in this book are available as Jupyter notebooks that can
    be downloaded from [https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的所有代码示例都可以作为 Jupyter notebooks 下载，您可以从[https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras)获取。
- en: Since code cells can be executed, each notebook can be self-installed; you just
    need to add the code snippet with the requirements you need. For this reason,
    at the beginning of each notebook, there is a code cell for environment setup
    that installs AutoKeras and its dependencies.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于代码单元可以执行，因此每个 notebook 都可以自我安装；您只需要添加需要的依赖代码片段。因此，在每个 notebook 的开头都有一个用于环境设置的代码单元，它会安装
    AutoKeras 及其依赖项。
- en: 'So, to run the code examples for this chapter, you only need a computer with
    Ubuntu Linux as your OS and install the Jupyter Notebook with the following code:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，要运行本章的代码示例，您只需要一台操作系统为 Ubuntu Linux 的计算机，并用以下代码安装 Jupyter Notebook：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Alternatively, you can also run these notebooks using Google Colaboratory, in
    which case you will only need a web browser. See the *AutoKeras with Google Colaboratory*
    section of [*Chapter 2*](B16953_02_Final_PG_ePub.xhtml#_idTextAnchor029), *Getting
    Started with AutoKeras*, for more details. Furthermore, in the *Installing AutoKeras*
    section of that chapter, you will find other installation options.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您也可以使用 Google Colaboratory 运行这些 notebooks，这种情况下您只需要一个网页浏览器。更多细节请参见[*第2章*](B16953_02_Final_PG_ePub.xhtml#_idTextAnchor029)，*使用
    Google Colaboratory 进行 AutoKeras*部分。此外，在该章的*安装 AutoKeras*部分，您还可以找到其他安装选项。
- en: Now, let's put what we've learned into practice by looking at some practical
    examples.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过一些实际示例来实践我们所学的内容。
- en: Creating a sentiment analyzer
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建情感分析器
- en: 'The model we are going to create will be a binary classifier for sentiments
    (1=Positive/0=Negative) from the IMDb sentiments dataset. This is a dataset for
    binary sentiment classification that contains a set of 25,000 sentiment labeled
    movie reviews for training and 25,000 for testing:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要创建的模型将是一个用于情感的二分类器（1=正面/0=负面），数据集来自 IMDb 情感数据集。该数据集是一个二分类情感分类数据集，包含25,000条带情感标签的电影评论用于训练，另有25,000条用于测试：
- en: '![Figure 7.1 – Example of sentiment analysis being used on two samples](img/B16953_07_01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.1 – 情感分析在两个样本上的应用示例](img/B16953_07_01.jpg)'
- en: Figure 7.1 – Example of sentiment analysis being used on two samples
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – 在两个样本上使用情感分析的示例
- en: Similar to the Reuters example from [*Chapter 4*](B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063),
    *Image Classification and Regression Using AutoKeras*, each review is encoded
    as a list of word indexes (integers). For convenience, words are indexed by their
    overall frequency in the dataset. So, for instance, the integer *3* encodes the
    third most frequent word in the data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于[*第 4 章*](B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063)中的 Reuters 示例，*使用
    AutoKeras 进行图像分类和回归*，每个评论都被编码为一个单词索引列表（整数）。为了方便起见，单词根据其在数据集中的总体频率进行索引。例如，整数 *3*
    表示数据中第三频繁出现的单词。
- en: The notebook that contains the complete source code can be found at [https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter07/Chapter7_IMDB_sentiment_analysis.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter07/Chapter7_IMDB_sentiment_analysis.ipynb).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 包含完整源代码的笔记本可以在[https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter07/Chapter7_IMDB_sentiment_analysis.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter07/Chapter7_IMDB_sentiment_analysis.ipynb)找到。
- en: 'Now, let''s have a look at the relevant cells of the notebook in detail:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们详细查看笔记本中的相关单元格：
- en: '**Installing AutoKeras**: As we''ve mentioned in other examples, this snippet
    at the top of the notebook is responsible for installing AutoKeras and its dependencies
    using the pip package manager:'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安装 AutoKeras**：正如我们在其他示例中提到的，笔记本顶部的这段代码负责使用 pip 包管理器安装 AutoKeras 及其依赖项：'
- en: '[PRE1]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Importing the necessary packages**: The following lines load TensorFlow,
    the built-in Keras Reuters dataset, NumPy, and AutoKeras as needed dependencies
    for this project:'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**导入必要的包**：以下几行代码加载 TensorFlow、内置的 Keras Reuters 数据集、NumPy 和 AutoKeras，作为本项目所需的依赖项：'
- en: '[PRE2]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`imdb_sentiment_raw` function. Have a look at the code in the notebook for
    more details:'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`imdb_sentiment_raw` 函数。查看笔记本中的代码以获取更多细节：'
- en: '[PRE3]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here is the output:'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '[PRE4]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Showing some samples**: Next, we can print some words from the first sample
    to get an idea of what it contains:'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**展示一些样本**：接下来，我们可以打印出第一个样本中的一些单词，了解其包含的内容：'
- en: '[PRE5]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here is the output:'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '[PRE6]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To see this more clearly, let''s render a word cloud with the most frequent
    words. A word cloud (also known as a tag cloud) is a text-based data visualization
    technique, in which words are displayed in different sizes based on how often
    they appear in the text:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更清楚地看到这一点，让我们渲染一个包含最常见单词的词云。词云（也称为标签云）是一种基于文本的数据可视化技术，其中单词根据其在文本中出现的频率显示为不同的大小：
- en: '![Figure 7.2 – A word cloud containing the most frequent words of the dataset](img/B16953_07_02.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.2 – 包含数据集中最频繁单词的词云](img/B16953_07_02.jpg)'
- en: Figure 7.2 – A word cloud containing the most frequent words of the dataset
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 – 包含数据集中最频繁单词的词云
- en: Now, it's time to create the classifier model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候创建分类器模型了。
- en: Creating the sentiment predictor
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建情感预测器
- en: 'Now, we will use the AutoKeras `TextClassifier` to find the best classification
    model. Just for this example, we will set `max_trials` (the maximum number of
    different Keras models to try) to `2`; we do not need to set the epochs parameter;
    instead, we must define an `EarlyStopping` callback of `2` epochs so that the
    training process stops if the validation loss does not improve in two consecutive
    epochs:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用 AutoKeras `TextClassifier` 来找到最佳的分类模型。为了这个示例，我们将 `max_trials`（最大尝试的
    Keras 模型数量）设置为 `2`；我们不需要设置 epoch 参数；而是必须定义一个 `EarlyStopping` 回调，设置为 `2` 个 epoch，这样如果验证损失在连续两个
    epoch 中没有改善，训练过程将停止：
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let''s run the training process and search for the optimal classifier for the
    training dataset:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行训练过程并为训练数据集寻找最佳分类器：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here is the output:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '![Figure 7.3 – Notebook output of text classifier training](img/B16953_07_03.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.3 – 文本分类器训练的笔记本输出](img/B16953_07_03.jpg)'
- en: Figure 7.3 – Notebook output of text classifier training
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3 – 文本分类器训练的笔记本输出
- en: The previous output shows that the accuracy of the training dataset is increasing.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 上述输出显示训练数据集的准确率在提高。
- en: As we can see, we are getting a loss of `0.28` in the validation set. This isn't
    bad just for a few minutes of training. We have limited the search to two architectures
    (`max_trials = 2`). As with the rest of the examples, increasing this number would
    give us a more accurate model, although it would also take longer to finish.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们在验证集上得到了 `0.28` 的损失值。对于几分钟的训练来说，这还算不错。我们已经将搜索限制为两种架构（`max_trials = 2`）。像其他示例一样，增加此数字会给我们一个更准确的模型，但完成的时间也会更长。
- en: Evaluating the model
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型
- en: 'Now, it''s time to evaluate the best model with the testing dataset:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候使用测试数据集评估最佳模型了：
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here is the output:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '[PRE10]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As we can see, `0.8724` is a really good final prediction accuracy for the time
    we've invested.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，`0.8724` 是我们投入时间的一个非常好的最终预测准确度。
- en: Visualizing the model
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化模型
- en: 'Now, we can view a little summary of the architecture for the best generated
    model:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以查看最佳生成模型的架构简要概述：
- en: '[PRE11]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here is the output:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '![Figure 7.4 – Best model architecture summary](img/B16953_07_04.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.4 – 最佳模型架构摘要](img/B16953_07_04.jpg)'
- en: Figure 7.4 – Best model architecture summary
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4 – 最佳模型架构摘要
- en: As we can see, AutoKeras, as we did in the classification example in [*Chapter
    4*](B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063), *Image Classification and
    Regression Using AutoKeras*, has chosen a convolution model (Conv1D) for this
    task. As we explained in the beginning of that chapter, this kind of architecture
    works really well when the order of the input sentences is not important for the
    prediction; there are no correlations between the different movie reviews.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，AutoKeras 在[*第4章*](B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063)中所做的分类示例中，*使用
    AutoKeras 进行图像分类和回归*，也选择了卷积模型（Conv1D）来执行此任务。正如我们在该章开头所解释的，当输入句子的顺序对预测不重要时，这种架构表现得非常好；不同电影评论之间没有相关性。
- en: 'Here is a visual representation of this:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该架构的可视化表示：
- en: '![Figure 7.5 – Best model architecture visualization graph](img/B16953_07_05.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.5 – 最佳模型架构可视化图](img/B16953_07_05.jpg)'
- en: Figure 7.5 – Best model architecture visualization graph
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5 – 最佳模型架构可视化图
- en: As you already know, generating the models and choosing the best one is done
    by AutoKeras automatically, but let's explain these blocks in more detail.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，生成模型并选择最佳模型是由 AutoKeras 自动完成的，但让我们更详细地解释这些模块。
- en: Each block represents a layer and the output of each is connected to the input
    of the next except for the first block, whose input is the text, and the last
    block, whose output is the predicted number. The blocks before Conv1D are all
    data preprocessing blocks and they are in charge of vectorizing the text generating
    embeddings to feed this Conv1D block, as well as reducing the dimension of the
    filters through the max pooling layer. Notice that AutoKeras has also added several
    dropout blocks to reduce overfitting.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模块表示一个层，每个层的输出都连接到下一个层的输入，除了第一个模块，其输入是文本，以及最后一个模块，其输出是预测值。Conv1D 之前的模块都是数据预处理模块，负责将文本向量化生成嵌入，以便输入到
    Conv1D 模块，并通过最大池化层减少滤波器的维度。请注意，AutoKeras 还添加了几个 dropout 模块来减少过拟合。
- en: Analyzing the sentiment in specific sentences
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析特定句子的情感
- en: 'Now, let''s take a look at some predicted samples from the test set:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一下来自测试集的一些预测样本：
- en: '[PRE12]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here is the output of the preceding code:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这是前面代码的输出结果：
- en: '![Figure 7.6 – Some predictions based on the first 10 sentences of the test
    dataset'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.6 – 基于测试数据集前10个句子的某些预测'
- en: '](img/B16953_07_06.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16953_07_06.jpg)'
- en: Figure 7.6 – Some predictions based on the first 10 sentences of the test dataset
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.6 – 基于测试数据集前10个句子的某些预测
- en: As you can see, the model predictions match every label for the first 10 samples
    in the test dataset.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，模型预测与测试数据集前10个样本的标签完全匹配。
- en: Summary
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the importance of sentiment analysis in the
    real world, as well as how to extract sentiments from text data and how to implement
    a sentiment predictor in just a few lines of code.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了情感分析在现实世界中的重要性，以及如何从文本数据中提取情感并在几行代码中实现情感预测器。
- en: 'In the next chapter, we will cover a very interesting topic: we will use AutoKeras
    to classify news topics based on their content by using a text classifier.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将介绍一个非常有趣的话题：我们将使用 AutoKeras 通过文本分类器根据新闻内容来分类新闻话题。
