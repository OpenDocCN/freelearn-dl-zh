- en: Data Modeling in Action - The Titanic Example
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据建模实践——泰坦尼克号例子
- en: Linear models are the basic learning algorithms in the field of data science.
    Understanding how a linear model works is crucial in your journey of learning
    data science because it's the basic building block for most of the sophisticated
    learning algorithms out there, including neural networks.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型是数据科学领域的基本学习算法。理解线性模型的工作原理对你学习数据科学的旅程至关重要，因为它是大多数复杂学习算法（包括神经网络）的基础构建块。
- en: 'In this chapter, we are going to dive into a famous problem in the field of
    data science, which is the Titanic example. The purpose of this example is to
    introduce linear models for classification and see a full machine learning system
    pipeline, starting from data handling and exploration up to model evaluation.
    We are going to cover the following topics in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨数据科学领域的一个著名问题——泰坦尼克号例子。这个例子的目的是介绍用于分类的线性模型，并展示完整的机器学习系统管道，从数据处理与探索到模型评估。我们将在本章讨论以下主题：
- en: Linear models for regression
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归的线性模型
- en: Linear models for classification
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类的线性模型
- en: Titanic example—model building and training
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 泰坦尼克号例子——模型构建与训练
- en: Different types of errors
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同类型的误差
- en: Linear models for regression
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归的线性模型
- en: 'Linear regression models are the most basic type of regression models and are
    widely used in predictive data analysis. The overall idea of regression models
    is to examine two things:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型是最基本的回归模型类型，广泛应用于预测数据分析。回归模型的总体思想是研究两件事：
- en: Does a set of explanatory features / input variables do a good job at predicting
    an output variable? Is the model using features that account for the variability
    in changes to the dependent variable (output variable)?
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一组解释性特征/输入变量是否能很好地预测输出变量？模型是否使用了能够解释因变量（输出变量）变化的特征？
- en: Which features in particular are significant ones of the dependent variable?
    And in what way do they impact the dependent variable (indicated by the magnitude
    and sign of the parameters)? These regression parameters are used to explain the
    relationship between one output variable (dependent variable) and one or more
    input features (independent variables).
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些特征是因变量的重要特征？它们通过哪些方式影响因变量（由参数的大小和符号表示）？这些回归参数用于解释一个输出变量（因变量）与一个或多个输入特征（自变量）之间的关系。
- en: A regression equation will formulate the impact of the input variables (independent
    variables) on the output variable (dependent variable). The simplest form of this
    equation, with one input variable and one output variable, is defined by this
    formula *y = c + b*x.* Here, *y *= estimated dependent score, *c *= constant,
    *b *= regression parameter/coefficients, and *x *= input (independent) variable.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 回归方程将阐述输入变量（自变量）对输出变量（因变量）的影响。这个方程最简单的形式，只有一个输入变量和一个输出变量，由公式 *y = c + b*x* 定义。这里，*y*
    = 估计的因变量值，*c* = 常数，*b* = 回归参数/系数，*x* = 输入（自）变量。
- en: Motivation
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动机
- en: 'Linear regression models are the building blocks of many learning algorithms,
    but this is not the only reason behind their popularity. The following are the
    key factors behind their popularity:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型是许多学习算法的基础，但这并不是它们流行的唯一原因。以下是它们流行的关键因素：
- en: '**Widely used**: Linear regression is the oldest regression technique and it''s
    widely used in many applications, such as forecasting and financial analysis.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广泛应用**：线性回归是最古老的回归技术，广泛应用于许多领域，如预测和金融分析。'
- en: '**Runs fast**: Linear regression algorithms are very simple and don''t include
    mathematical computations which are too expensive.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运行速度快**：线性回归算法非常简单，不包括过于昂贵的数学计算。'
- en: '**Easy to use** (**not a lot of tuning required**): Linear regression is very
    easy to use, and mostly it''s the first learning method to learn about in the
    machine learning or data science class as you don''t have too many hyperparameters
    to tune in order to get better performance.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于使用**（**无需大量调优**）：线性回归非常容易使用，并且它通常是机器学习或数据科学课程中学习的第一个方法，因为你不需要调整过多的超参数来提高性能。'
- en: '**Highly interpretable**: Because of its simplicity and ease of inspecting
    the contribution of each predictor-coefficient pair, linear regression is highly
    interpretable; you can easily understand the model behavior and interpret the
    model output for non-technical guys. If a coefficient is zero, the associated
    predictor variable contributes nothing. If a coefficient is not zero, the contribution
    due to the specific predictor variable can easily be ascertained.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高度可解释**：由于线性回归的简单性以及检查每个预测变量与系数对的贡献的便捷性，它具有很高的可解释性；你可以轻松理解模型的行为，并为非技术人员解读模型输出。如果某个系数为零，那么相关的预测变量不做任何贡献。如果某个系数不为零，可以轻松确定该特定预测变量的贡献。'
- en: '**Basis for many other methods**: Linear regression is considered the underlying
    foundation for many learning methods, such as neural networks and its growing
    part, deep learning.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**许多方法的基础**：线性回归被认为是许多学习方法的基础，例如神经网络及其日益增长的部分——深度学习。'
- en: Advertising – a financial example
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 广告 – 一个财务示例
- en: In order to better understand linear regression models, we will go through an
    example advertisement. We will try to predict the sales of some companies given
    some factors related to the amount of money spent by these companies on advertising
    in TV, radio, and newspapers.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解线性回归模型，我们将通过一个广告示例来学习。我们将尝试预测一些公司在广告支出（包括电视、广播和报纸广告）方面的花费与其销售额之间的关系。
- en: Dependencies
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 依赖项
- en: To model our advertising data samples using linear regression, we will be using
    the Stats models library to get nice characteristics for linear models, but later
    on, we will be using scikit-learn, which has very useful functionality for data
    science in general.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用线性回归建模我们的广告数据样本，我们将使用 Statsmodels 库来获取线性模型的良好特性，但稍后我们将使用 scikit-learn，它提供了许多对数据科学非常有用的功能。
- en: Importing data with pandas
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 pandas 导入数据
- en: There are lots of libraries out there in Python that you can use to read, transform,
    or write data. One of these libraries is pandas ([http://pandas.pydata.org/](http://pandas.pydata.org/)).
    Pandas is an open source library and has great functionality and tools for data
    analysis as well as very easy-to-use data structures.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中有许多库可以用来读取、转换或写入数据。其中特别的一个库是 pandas：[http://pandas.pydata.org/](http://pandas.pydata.org/)。Pandas
    是一个开源库，提供强大的数据分析功能和工具，并且其数据结构非常易于使用。
- en: You can easily get pandas in many different ways. The best way to get pandas
    is to install it via `conda` ([http://pandas.pydata.org/pandas-docs/stable/install.html#installing-pandas-with-anaconda](http://pandas.pydata.org/pandas-docs/stable/install.html#installing-pandas-with-anaconda)).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过多种方式轻松获取 pandas。获取 pandas 的最佳方式是通过`conda`进行安装：[http://pandas.pydata.org/pandas-docs/stable/install.html#installing-pandas-with-anaconda](http://pandas.pydata.org/pandas-docs/stable/install.html#installing-pandas-with-anaconda)。
- en: “conda is an open source package management system and environment management
    system for installing multiple versions of software packages and their dependencies
    and switching easily between them. It works on Linux, OS X and Windows, and was
    created for Python programs but can package and distribute any software.” – conda
    website.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: “conda 是一个开源的包管理系统和环境管理系统，用于安装多个版本的软件包及其依赖项，并可以轻松地在它们之间切换。它支持 Linux、OS X 和 Windows
    操作系统，最初为 Python 程序设计，但也可以打包和分发任何软件。” – conda 网站。
- en: You can easily get conda by installing Anaconda, which is an open data science
    platform.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过安装 Anaconda 来轻松获得 conda，它是一个开源的数据科学平台。
- en: 'So, let''s have a look and see how to use pandas in order to read advertising
    data samples. First off, we need to import `pandas`:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们看一下如何使用 pandas 来读取广告数据样本。首先，我们需要导入`pandas`：
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next up, we can use the `pandas.read_csv` method in order to load our data
    into an easy-to-use pandas data structure called **DataFrame**. For more information
    about `pandas.read_csv` and its parameters, you can refer to the pandas documentation
    for this method ([https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)):'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以使用`pandas.read_csv`方法将数据加载到一个易于使用的 pandas 数据结构——**DataFrame**中。关于`pandas.read_csv`及其参数的更多信息，可以参考
    pandas 的文档：[https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)。
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The first argument passed to the `pandas.read_csv` method is a string value
    representing the file path. The string can be a URL that includes `http`, `ftp`,
    `s3`, and `file`. The second argument passed is the index of the column that will
    be used as a label/name for the data rows.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 传递给`pandas.read_csv`方法的第一个参数是表示文件路径的字符串值。该字符串可以是包含`http`、`ftp`、`s3`和`file`的URL。传递的第二个参数是作为数据行标签/名称的列的索引。
- en: Now, we have the data DataFrame, which contains the advertising data provided
    in the URL and each row is labeled by the first column. As mentioned earlier,
    pandas provides easy-to-use data structures that you can use as containers for
    your data. These data structures have some methods associated with them and you
    will be using these methods to transform and/or operate on your data.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了数据的DataFrame，其中包含URL中提供的广告数据，每一行通过第一列进行标记。如前所述，pandas提供了易于使用的数据结构，你可以将其作为数据容器。这些数据结构具有一些与之关联的方法，你将使用这些方法来转换和/或操作数据。
- en: 'Now, let''s have a look at the first five rows of the advertising data:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看广告数据的前五行：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Output:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '|  | **TV** | **Radio** | **Newspaper** | **Sales** |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '|  | **电视** | **广播** | **报纸** | **销售** |'
- en: '| 1 | 230.1 | 37.8 | 69.2 | 22.1 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 230.1 | 37.8 | 69.2 | 22.1 |'
- en: '| 2 | 44.5 | 39.3 | 45.1 | 10.4 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 44.5 | 39.3 | 45.1 | 10.4 |'
- en: '| 3 | 17.2 | 45.9 | 69.3 | 9.3 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 17.2 | 45.9 | 69.3 | 9.3 |'
- en: '| 4 | 151.5 | 41.3 | 58.5 | 18.5 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 151.5 | 41.3 | 58.5 | 18.5 |'
- en: '| 5 | 180.8 | 10.8 | 58.4 | 12.9 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 180.8 | 10.8 | 58.4 | 12.9 |'
- en: Understanding the advertising data
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解广告数据
- en: This problem falls into the supervised learning type, in which we have explanatory
    features (input variables) and the response (output variable).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题属于监督学习类型，其中我们有解释性特征（输入变量）和响应（输出变量）。
- en: What are the features/input variables?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 特征/输入变量是什么？
- en: '**TV**: Advertising dollars spent on TV for a single product in a given market
    (in thousands of dollars)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电视**：在给定市场上为单一产品在电视上花费的广告费用（单位：千美元）'
- en: '**Radio**: Advertising dollars spent on radio'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广播**：在广播上花费的广告费用'
- en: '**Newspaper**: Advertising dollars spent on newspapers'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**报纸**：在报纸上花费的广告费用'
- en: What is the response/outcome/output variable?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 响应/结果/输出变量是什么？
- en: '**Sales**: The sales of a single product in a given market (in thousands of
    widgets)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**销售**：在给定市场上单一产品的销售额（单位：千个商品）'
- en: 'We can also use the `DataFrame` method shape to know the number of samples/observations
    in our data:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`DataFrame`方法shape来了解数据中的样本/观测值数量：
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: So, there are 200 observations in the advertising data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，广告数据中有200个观测值。
- en: Data analysis and visualization
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析与可视化
- en: In order to understand the underlying form of the data, the relationship between
    the features and response, and more insights, we can use different types of visualization.
    To understand the relationship between the advertising data features and response,
    we are going to use a scatterplot.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解数据的潜在形式、特征与响应之间的关系，以及更多的见解，我们可以使用不同类型的可视化。为了理解广告数据特征与响应之间的关系，我们将使用散点图。
- en: In order to make different types of visualizations of your data, you can use
    Matplotlib ([https://matplotlib.org/](https://matplotlib.org/)), which is a Python
    2D library for making visualizations. To get Matplotlib, you can follow their
    installation instructions at: [https://matplotlib.org/users/installing.html](https://matplotlib.org/users/installing.html).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对数据进行不同类型的可视化，你可以使用Matplotlib（[https://matplotlib.org/](https://matplotlib.org/)），它是一个用于创建可视化的Python
    2D库。要获取Matplotlib，你可以按照他们的安装说明：[https://matplotlib.org/users/installing.html](https://matplotlib.org/users/installing.html)。
- en: 'Let''s import the visualization library Matplotlib:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们导入可视化库Matplotlib：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, let''s use a scatterplot to visualize the relationship between the advertising
    data features and response variable:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用散点图来可视化广告数据特征与响应变量之间的关系：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Output:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '![](img/45e7442f-7b9e-474c-836e-04228777d540.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/45e7442f-7b9e-474c-836e-04228777d540.png)'
- en: 'Figure 1: Scatter plot for understanding the relationship between the advertising
    data features and the response variable'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：用于理解广告数据特征与响应变量之间关系的散点图
- en: Now, we need to see how the ads will help increase the sales. So, we need to
    ask ourselves a couple of questions about that. Worthwhile questions to ask will
    be something like the relationship between the ads and sales, which kind of ads
    contribute more to the sales, and the approximate effect of each type of ad on
    the sales. We will try to answer such questions using a simple linear model.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要看看广告如何帮助增加销售。因此，我们需要就此提出几个问题给自己。有价值的问题可以是关于广告与销售之间的关系，哪种广告对销售的贡献更大，以及每种类型广告对销售的大致影响。我们将尝试使用简单线性模型来回答此类问题。
- en: Simple regression model
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单回归模型
- en: The linear regression model is a learning algorithm that is concerned with predicting
    a **quantitative **(also known as **numerical**) **response** using a combination
    of **explanatory** **features** (or **inputs** or **predictors**).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归模型是一种学习算法，用于预测**定量**（也称为**数值**）**响应**，其使用**解释性** **特征**（或**输入**或**预测器**）的组合。
- en: 'A simple linear regression model with only one feature takes the following
    form:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 只有一个特征的简单线性回归模型采用以下形式：
- en: '*y = beta[0] + beta[1]x*'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '*y = beta[0] + beta[1]x*'
- en: 'Here:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这里：
- en: '*y* is the predicted numerical value (response) → **sales**'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y*是预测的数值（响应） → **销售**'
- en: '*x* is the the feature'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x*是特征'
- en: '*beta[0]* is called the **intercept**'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*beta[0]*称为**截距**'
- en: '*beta[1]* is the coefficient of the feature *x* → **TV ad**'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*beta[1]*是特征*x* → **电视广告**的系数'
- en: Both *beta[0]* and *beta[1]* are considered as model **coefficients**. In order
    to create a model that can predict the value of sales in the advertising example,
    we need to learn these coefficients because *beta[1]* will be the learned effect
    of the feature *x* on the response *y*. For example, if *beta[1] = 0.04*, it means
    that an additional $100 spent on TV ads is **associated with** an increase in
    sales by four widgets. So, we need to go ahead and see how can we learn these
    coefficients.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*beta[0]*和*beta[1]*都被视为模型的**系数**。为了创建一个能够预测广告示例中销售值的模型，我们需要学习这些系数，因为*beta[1]*将是特征*x*对响应*y*的学习效果。例如，如果*beta[1]
    = 0.04*，这意味着额外投入100美元用于电视广告与销售增加四个小部件**相关**。因此，我们需要继续看看如何学习这些系数。'
- en: Learning model coefficients
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习模型系数
- en: 'In order to estimate the coefficients of our model, we need to fit the data
    with a regression line that gives a similar answer to the actual sales. To get
    a regression line that best fits the data, we will use a criterion called **least
    squares**. So, we need to find a line that minimizes the difference between the
    predicted value and the observed(actual) one. In other words, we need to find
    a regression line that minimizes the **sum of squared residuals** (**SSresiduals**).
    *Figure 2* illustrates this:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 为了估计我们模型的系数，我们需要用回归线拟合数据，以获得与实际销售类似的答案。为了获得最适合数据的回归线，我们将使用一个称为**最小二乘**的标准。因此，我们需要找到一条最小化预测值与观察值之间差异的线。*图2*说明了这一点：
- en: '![](img/7d507cac-b66c-4975-9771-a6e6f64f3732.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7d507cac-b66c-4975-9771-a6e6f64f3732.png)'
- en: 'Figure 2: Fitting the data points (sample of TV ads) with a regression line
    that minimizes the sum of the squared residuals (difference between the predicted
    and observed value)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：用最小化残差平方和（预测值与观察值之差）的回归线拟合数据点（电视广告样本）
- en: 'The following are the elements that exist in *Figure 2*:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 下列元素存在于*图2*中：
- en: '**Black dots** represent the actual or observed values of *x* (TV ad) and *y*
    (sales)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黑色点**表示*x*（电视广告）和*y*（销售）的实际或观察值'
- en: '**The blue line** represents the least squares line (regression line)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**蓝线**表示最小二乘线（回归线）'
- en: '**The red line** represents the residuals, which are the differences between
    the predicted and the observed (actual) values'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**红线**表示残差，即预测值与观察（实际）值之间的差异'
- en: 'So, this is how our coefficients relate to the least squares line (regression
    line):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这就是我们的系数与最小二乘线（回归线）的关系：
- en: '*beta[0]* is the **intercept**, which is the value of *y* when *x =0*'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*beta[0]*是**截距**，即*x =0*时*y*的值'
- en: '*beta[1]* is the **slope**, which represents the change in *y* divided by the
    change in *x*'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*beta[1]*是**斜率**，表示*y*相对于*x*的变化量'
- en: '*Figure 3* presents a graphical explanation of this:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*图3*展示了这个图形化解释：'
- en: '![](img/e2a18228-02ac-44bb-8be4-2a2c3b844def.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e2a18228-02ac-44bb-8be4-2a2c3b844def.png)'
- en: 'Figure 3: The relation between the least squares line and the model coefficients'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：最小二乘线与模型系数之间的关系
- en: 'Now, let''s go ahead and start to learn these coefficients using **Statsmodels**:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续使用**Statsmodels**来学习这些系数：
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Output:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE8]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As we mentioned, one of the advantages of linear regression models is that they
    are easy to interpret, so let's go ahead and interpret the model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所提到的，线性回归模型的一个优点是它们易于解释，所以我们继续解释该模型。
- en: Interpreting model coefficients
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释模型系数
- en: 'Let''s see how to interpret the coefficients of the model, such as the TV ad
    coefficient (*beta[1]*):'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何解释模型的系数，比如电视广告的系数 (*beta[1]*)：
- en: A unit increase in the input/feature (TV ad) spending is **associated** with
    a `0.047537` unit increase in Sales (response). In other words, an additional
    $100 spent on TV ads is **associated with** an increase in sales of 4.7537 widgets.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入/特征（电视广告）支出的单位增加**与**销售（响应）单位增加`0.047537`相关。换句话说，每额外花费 $100 在电视广告上**与**销售增加
    4.7537 单位相关。
- en: The goal of building a learned model from the TV ad data is to predict the sales
    for unseen data. So, let's see how we can use the learned model in order to predict
    the value of sales (which we don't know) based on a given value of a TV ad.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 从电视广告数据构建已学习模型的目标是预测未见数据的销售额。那么，让我们看看如何使用已学习的模型来预测销售值（我们不知道的）基于给定的电视广告值。
- en: Using the model for prediction
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用模型进行预测
- en: Let's say we have unseen data of TV ad spending and that we want to know their
    corresponding impact on the sales of the company. So, we need to use the learned
    model to do that for us. Let's suppose that we want to know how much sales will
    increase from $50000 of TV advertising.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有未见过的电视广告支出数据，并且我们想知道这些广告对公司销售的相应影响。那么，我们需要使用已学习的模型来为我们做这个预测。假设我们想知道 $50000
    的电视广告支出会使销售额增加多少。
- en: 'Let''s use our learned model coefficients to make such a calculation:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用已学习的模型系数来进行计算：
- en: '*y = 7.032594 + 0.047537 x 50*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*y = 7.032594 + 0.047537 x 50*'
- en: '[PRE9]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Output:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE10]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can also use Statsmodels to make the prediction for us. First, we need to
    provide the TV ad value in a pandas DataFrame since the Statsmodels interface
    expects it:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用 Statsmodels 来为我们做预测。首先，我们需要将电视广告值以 pandas DataFrame 的形式提供，因为 Statsmodels
    接口期望如此：
- en: '[PRE11]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Output:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '|  | **TV** |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|  | **电视广告** |'
- en: '| 0 | 50000 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 50000 |'
- en: 'Now, we can go ahead and use the predict function to predict the sales value:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用预测函数来预测销售值：
- en: '[PRE12]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Output:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE13]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s see how the learned least squares line looks. In order to draw the line,
    we need two points, with each point represented by this pair: (`x, predict_value_of_x`).'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看已学习的最小二乘法拟合直线是什么样子的。为了绘制这条线，我们需要两个点，每个点由以下一对值表示：（`x, predict_value_of_x`）。
- en: 'So, let''s take the minimum and maximum values for the TV ad feature:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们取电视广告特征的最小值和最大值：
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Output:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '|  | **TV** |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | **电视广告** |'
- en: '| 0 | 0.7 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.7 |'
- en: '| 1 | 296.4 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 296.4 |'
- en: 'Let''s get the corresponding predictions for these two values:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为这两个值获取相应的预测：
- en: '[PRE15]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Output:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE16]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, let''s plot the actual data and then fit it with the least squares line:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们绘制实际数据，并用最小二乘法拟合一条直线：
- en: '[PRE17]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Output:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '![](img/b2a7c8e3-54d6-4cf8-9b81-ec0167a4cd4a.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b2a7c8e3-54d6-4cf8-9b81-ec0167a4cd4a.png)'
- en: 'Figure 4: Plot of the actual data and the least squares line'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：实际数据与最小二乘法拟合直线的图示
- en: Extensions of this example and further explanations will be explained in the
    next chapter.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例的扩展及进一步的解释将在下一章中讲解。
- en: Linear models for classification
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于分类的线性模型
- en: In this section, we are going to go through logistic regression, which is one
    of the widely used algorithms for classification.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讲解逻辑回归，它是广泛使用的分类算法之一。
- en: What's logistic regression? The simple definition of logistic regression is
    that it's a type of classification algorithm involving a linear discriminant.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是逻辑回归？逻辑回归的简单定义是它是一种涉及线性判别的分类算法。
- en: 'We are going to clarify this definition in two points:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过两个要点来澄清这个定义：
- en: Unlike linear regression, logistic regression doesn't try to estimate/predict
    the value of the numeric variable given a set of features or input variables.
    Instead, the output of the logistic regression algorithm is the probability that
    the given sample/observation belongs to a specific class. In simpler words, let's
    assume that we have a binary classification problem. In this type of problem,
    we have only two classes in the output variable, for example, diseased or not
    diseased. So, the probability that a certain sample belongs to the diseased class
    is *P[0]* and the probability that a certain sample belongs to the not diseased
    class is *P[1] = 1 - P[0]*. Thus, the output of the logistic regression algorithm
    is always between 0 and 1.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与线性回归不同，逻辑回归并不试图在给定一组特征或输入变量的情况下估计/预测数值变量的值。相反，逻辑回归算法的输出是给定样本/观测值属于特定类别的概率。简单来说，假设我们有一个二分类问题。在这种问题中，输出变量中只有两个类别，例如，患病或未患病。那么，某个样本属于患病类别的概率是*P[0]*，而属于未患病类别的概率是*P[1]
    = 1 - P[0]*。因此，逻辑回归算法的输出始终介于0和1之间。
- en: 'As you probably know, there are a lot of learning algorithms for regression
    or classification, and each learning algorithm has its own assumption about the
    data samples. The ability to choose the learning algorithm that fits your data
    will come gradually with practice and good understanding of the subject. Thus,
    the central assumption of the logistic regression algorithm is that our input/feature
    space could be separated into two regions (one for each class) by a linear surface,
    which could be a line if we only have two features or a plane if we have three,
    and so on. The position and orientation of this boundary will be determined by
    your data. If your data satisfies this constraint that is separating them into
    regions corresponding to each class with a linear surface, then your data is said
    to be linearly separable. The following figure illustrates this assumption. In
    *Figure 5*, we have three dimensions, inputs, or features and two possible classes:
    diseased (red) and not diseased (blue). The dividing place that separates the
    two regions from each other is called a **linear discriminant**, and that’s because
    it''s linear and it helps the model to discriminate between samples belonging
    to different classes:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正如你可能知道的那样，有许多回归或分类的学习算法，每种学习算法对数据样本有自己的假设。选择适合你数据的学习算法的能力将随着实践和对该主题的深入理解而逐渐掌握。因此，逻辑回归算法的核心假设是，我们的输入/特征空间可以通过一个线性面将其分隔为两个区域（每个类别一个区域），如果我们只有两个特征，这个面就是一条线，若有三个特征，则是一个平面，依此类推。这个边界的位置和方向将由你的数据决定。如果你的数据满足这种约束，即通过一个线性面将它们分隔成对应每个类别的区域，那么这些数据就被称为线性可分的。下图展示了这一假设。在*图5*中，我们有三个维度的输入或特征和两个可能的类别：患病（红色）和未患病（蓝色）。分隔两个区域的边界称为**线性判别面**，因为它是线性的，并且有助于模型区分属于不同类别的样本：
- en: '![](img/16e03c8c-c3e2-4526-851c-0ead591812ed.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/16e03c8c-c3e2-4526-851c-0ead591812ed.png)'
- en: 'Figure 5: Linear decision surface separating two classes'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：分隔两个类别的线性决策面
- en: If your data samples aren't linearly separable, you can make them so by transforming
    your data into higher dimensional space, by adding more features.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的数据样本不是线性可分的，你可以通过将数据转化为更高维度的空间来实现线性可分，即通过添加更多特征。
- en: Classification and logistic regression
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类与逻辑回归
- en: In the previous section, we learned how to predict continuous quantities (for
    example, the impact of TV advertising on company sales) as linear functions of
    input values (for example, TV, Radio, and newspaper advertisements). But for other
    tasks, the output will not be continuous quantities. For example, predicting whether
    someone is diseased or not is a classification problem and we need a different
    learning algorithm to perform this. In this section, we are going to dig deeper
    into the mathematical analysis of logistic regression, which is a learning algorithm
    for classification tasks.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们学习了如何将连续量（例如，电视广告对公司销售的影响）预测为输入值（例如，电视、广播和报纸广告）的线性函数。但是，对于其他任务，输出将不是连续量。例如，预测某人是否患病是一个分类问题，我们需要一个不同的学习算法来完成这个任务。在本节中，我们将深入探讨逻辑回归的数学分析，它是一种用于分类任务的学习算法。
- en: In linear regression, we tried to predict the value of the output variable *y^((i))* for
    the *i^(th)* sample *x^((i))* in that dataset using a linear model function *y
    = h[θ](x)=θ^Τ x*. This is not really a great solution for classification tasks
    such as predicting binary labels *(y^((i)) ∈ {0,1})*.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归中，我们试图使用线性模型函数 *y = h[θ](x) = θ^Τ x* 来预测数据集中第 *i^(th)* 个样本 *x^((i))* 的输出变量
    *y^((i))* 的值。但这并不是分类任务的一个好方法，尤其是像预测二进制标签 *(y^((i)) ∈ {0,1})* 这样的任务。
- en: 'Logistic regression is one of the many learning algorithms that we can use
    for classification tasks, whereby we use a different hypothesis class while trying
    to predict the probability that a specific sample belongs to the one class and
    the probability that it belongs to the zero class. So, in logistic regression,
    we will try to learn the following functions:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是我们可以用于分类任务的众多学习算法之一，在这种方法中，我们使用不同的假设类来预测一个特定样本属于正类的概率和属于负类的概率。因此，在逻辑回归中，我们将尝试学习以下函数：
- en: '![](img/621ad68c-251e-4148-ab09-8075642e6eaa.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/621ad68c-251e-4148-ab09-8075642e6eaa.png)'
- en: The function ![](img/aae68862-cda0-4cec-abca-621bc46268f8.png) is often called
    a **sigmoid** or **logistic** function, which squashes the value of *θ^Τx* into
    a fixed range *[0,1]*, as shown in the following graph. Because the value will
    be squashed between [0,1], we can then interpret *h[θ](x)* as a probability.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数 ![](img/aae68862-cda0-4cec-abca-621bc46268f8.png) 通常被称为 **sigmoid** 或 **logistic**
    函数，它将 *θ^Τx* 的值压缩到一个固定范围 *[0,1]*，如下图所示。因为值会被压缩到 [0,1] 之间，所以我们可以将 *h[θ](x)* 解释为一个概率。
- en: 'Our goal is to search for a value of the parameters *θ* so that the probability
    *P(y = 1|x) = h[θ](x))* is large when the input sample *x* belongs to the one
    class and small when *x* belongs to the zero class:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是寻找参数 *θ* 的值，使得当输入样本 *x* 属于正类时，概率 *P(y = 1|x) = h[θ](x)* 较大，而当 *x* 属于负类时，概率较小：
- en: '![](img/e319d30b-e5e6-4b80-a840-02107358b9ba.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e319d30b-e5e6-4b80-a840-02107358b9ba.png)'
- en: 'Figure 6: Shape of the sigmoid function'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：Sigmoid 函数的形状
- en: 'So, suppose we have a set of training samples with their corresponding binary
    labels *{(x^((i)),y^((i))): i = 1,...,m}.* We will need to minimize the following
    cost function, which measures how good a given *h[θ]* does:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '所以，假设我们有一组训练样本及其对应的二进制标签 *{(x^((i)), y^((i))): i = 1,...,m}*。我们需要最小化以下代价函数，该函数衡量给定的
    *h[θ]* 的表现如何：'
- en: '![](img/57740d69-403e-45af-b411-841990cbbb5a.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/57740d69-403e-45af-b411-841990cbbb5a.png)'
- en: Note that we have only one of the two terms of the equation's summation as non-zero
    for each training sample (depending on whether the value of the label *y^((i))* is
    *0* or ). When *y^((i)) = 1*, minimizing the model cost function means we need
    to make *h[θ](x^((i)))* large, and when *y^((i)) = 0![](img/7851cec8-7d58-4c09-887f-6177ca8b48dc.png)*,
    we want to make *1-h[θ] large*.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于每个训练样本，方程求和的两个项中只有一个非零项（取决于标签 *y^((i))* 的值是 *0* 还是 *1*）。当 *y^((i)) = 1*
    时，最小化模型的代价函数意味着我们需要让 *h[θ](x^((i)))* 较大；而当 *y^((i)) = 0* 时 ![](img/7851cec8-7d58-4c09-887f-6177ca8b48dc.png)*，我们希望让
    *1 - h[θ]* 较大。
- en: Now, we have a cost function that calculates how well a given hypothesis *h[θ]* fits
    our training samples. We can learn to classify our training samples by using an
    optimization technique to minimize *J(θ)* and find the best choice of parameters *θ*.
    Once we have done this, we can use these parameters to classify a new test sample
    as 1 or 0, checking which of these two class labels is most probable. If *P(y
    = 1|x) < P(y = 0|x)* then we output 0, otherwise we output 1, which is the same
    as defining a threshold of 0.5 between our classes and checking whether *h[θ](x)
    > 0.5*.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个代价函数来计算给定假设 *h[θ]* 与训练样本的匹配程度。我们可以通过使用优化技术来最小化 *J(θ)*，从而找到最佳的参数选择 *θ*，进而学习如何对训练样本进行分类。一旦我们完成这一步骤，就可以利用这些参数将新的测试样本分类为
    1 或 0，查看哪一个类标签的概率较高。如果 *P(y = 1|x) < P(y = 0|x)*，则输出 0，否则输出 1，这与定义一个 0.5 的类间阈值并检查
    *h[θ](x) > 0.5* 是一致的。
- en: 'To minimize the cost function *J(θ),* we can use an optimization technique
    that finds the best value of *θ* that minimizes the cost function. So, we can
    use a calculus tool called **gradient**, which tries to find the greatest rate
    of increase of the cost function. Then, we can take the opposite direction to
    find the minimum value of this function; for example, the gradient of *J(θ)* is
    denoted by *∇[θ]J(θ),* which means taking the gradient for the cost function with
    respect to the model parameters. Thus, we need to provide a function that computes
    *J(θ)* and *∇[θ]J(θ)* for any requested choice of *θ*. If we derived the gradient
    or derivative of the cost function above *J(θ)* with respect to *θ[j]*, we will
    get the following results:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最小化代价函数 *J(θ)*，我们可以使用一种优化技术，寻找能够最小化代价函数的最佳 *θ* 值。因此，我们可以使用一种叫做**梯度**的微积分工具，它尝试找到代价函数的最大增加速率。然后，我们可以朝相反方向前进，以找到该函数的最小值；例如，*J(θ)*
    的梯度记作 *∇[θ]J(θ)*，这意味着对代价函数相对于模型参数的梯度进行求解。因此，我们需要提供一个函数，用来计算 *J(θ)* 和 *∇[θ]J(θ)*，以便根据任何给定的
    *θ* 值进行求解。如果我们已经推导出了代价函数 *J(θ)* 相对于 *θ[j]* 的梯度或导数，那么我们将得到以下结果：
- en: '![](img/bac9e1fa-8c45-49fa-81e4-0335d4c5c858.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bac9e1fa-8c45-49fa-81e4-0335d4c5c858.png)'
- en: 'Which can be written in a vector form as:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以写成向量形式：
- en: '![](img/d1fd5510-fc07-4c56-985b-b3a942947b8c.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d1fd5510-fc07-4c56-985b-b3a942947b8c.png)'
- en: Now, we have a mathematical understanding of the logistic regression, so let's
    go ahead and use this new learning method for solving a classification task.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们对逻辑回归有了数学上的理解，那么让我们继续使用这一新学习方法来解决分类任务。
- en: Titanic example – model building and training
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Titanic 示例 – 模型构建与训练
- en: The sinking of the ship, Titanic, is one of the most infamous events in history.
    This incident led to the deaths of 1,502 passengers and crew out of 2,224\. In
    this problem, we will use data science to predict whether the passenger will survive
    this tragedy or not and then test the performance of our model based on the actual
    statistics of the tragedy.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 泰坦尼克号沉船事件是历史上最臭名昭著的事件之一。此次事故导致 2,224 名乘客和船员中有 1,502 人死亡。在这个问题中，我们将利用数据科学来预测乘客是否能够幸存，并基于这次灾难的实际统计数据来测试我们模型的性能。
- en: 'To follow up with the Titanic example, you need to do the following:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要继续 Titanic 示例，你需要执行以下步骤：
- en: 'Download this repository in a ZIP file by clicking on [https://github.com/ahmed-menshawy/ML_Titanic/archive/master.zip](https://github.com/ahmed-menshawy/ML_Titanic/archive/master.zip)
    or execute from the terminal:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击 [https://github.com/ahmed-menshawy/ML_Titanic/archive/master.zip](https://github.com/ahmed-menshawy/ML_Titanic/archive/master.zip)
    下载该仓库的 ZIP 文件，或者从终端执行：
- en: Git clone: [https://github.com/ahmed-menshawy/ML_Titanic.git](https://github.com/ahmed-menshawy/ML_Titanic.git)
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Git 克隆：[https://github.com/ahmed-menshawy/ML_Titanic.git](https://github.com/ahmed-menshawy/ML_Titanic.git)
- en: 'Install `[virtualenv]`: ([http://virtualenv.readthedocs.org/en/latest/installation.html](http://virtualenv.readthedocs.org/en/latest/installation.html))'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 `[virtualenv]`：([http://virtualenv.readthedocs.org/en/latest/installation.html](http://virtualenv.readthedocs.org/en/latest/installation.html))
- en: Navigate to the directory where you unzipped or cloned the repo and create a
    virtual environment with `virtualenv ml_titanic`
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到你解压或克隆的代码库目录，并通过 `virtualenv ml_titanic` 创建一个虚拟环境
- en: Activate the environment with `source ml_titanic/bin/activate`
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `source ml_titanic/bin/activate` 激活虚拟环境
- en: Install the required dependencies with `pip install -r requirements.txt`
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pip install -r requirements.txt` 安装所需的依赖项
- en: Execute the `ipython notebook` from the command line or terminal
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从命令行或终端执行 `ipython notebook`
- en: Follow the example code in the chapter
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照本章中的示例代码操作
- en: When you're done, deactivate the virtual environment with `deactivate`
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，通过执行 `deactivate` 来停用虚拟环境
- en: Data handling and visualization
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据处理与可视化
- en: In this section, we are going to do some data preprocessing and analysis. Data
    exploration and analysis is considered one of the most important steps while applying
    machine learning and might also be considered as the most important one, because
    at this step, you get to know the friend, Data, which is going to stick with you
    during the training process. Also, knowing your data will enable you to narrow
    down the set of candidate algorithms that you might use to check which one is
    the best for your data.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将进行一些数据预处理和分析。数据探索与分析被认为是应用机器学习过程中的最重要步骤之一，甚至可能是最关键的一步，因为在这个阶段，你将了解将会陪伴你整个训练过程的“朋友”——数据。同时，了解你的数据能够帮助你缩小可能使用的候选算法范围，从而找到最适合你数据的算法。
- en: 'Let''s start off by importing the necessary packages for our implementation:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入实现所需的必要包：
- en: '[PRE18]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let’s read the Titanic passengers and crew data using Pandas:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 Pandas 读取泰坦尼克号乘客和船员数据：
- en: '[PRE19]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Next up, let''s check the dimensions of our dataset and see how many examples
    we have and how many explanatory features are describing our dataset:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们检查数据集的维度，看看我们有多少个样本，以及描述数据集的解释性特征有多少：
- en: '[PRE20]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'So, we have a total of 891 observations, data samples, or passenger/crew records,
    and 12 explanatory features for describing this record:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们一共有891个观察样本、数据样本或乘客/船员记录，以及12个解释性特征来描述这些记录：
- en: '[PRE21]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s see the data of some samples/observations:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些样本/观察数据：
- en: '[PRE22]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Output:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '![](img/185f0d5b-b29b-409a-b5a8-1f815ed60bc1.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/185f0d5b-b29b-409a-b5a8-1f815ed60bc1.png)'
- en: 'Figure 7: Samples from the titanic dataset'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：泰坦尼克号数据集的样本
- en: Now, we have a Pandas DataFrame that holds the information of 891 passengers
    that we need to analyze. The columns of the DataFrame represent the explanatory
    features about each passenger/crew, like name, sex, or age.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个 Pandas 数据框，包含了我们需要分析的891名乘客的信息。数据框的列表示每个乘客/船员的解释性特征，如姓名、性别或年龄。
- en: Some of these explanatory features are complete without any missing values,
    such as the survived feature, which has 891 entries. Other explanatory features
    contain missing values, such as the age feature, which has only 714 entries. Any
    missing value in the DataFrame is represented as NaN.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些解释性特征是完整的，没有任何缺失值，比如生还特征，拥有891个条目。其他解释性特征包含缺失值，比如年龄特征，只有714个条目。数据框中的任何缺失值都表示为NaN。
- en: If you explore all of the dataset features, you will find that the ticket and
    cabin features have many missing values (NaNs), and so they won't add much value
    to our analysis. To handle this, we will drop them from the DataFrame.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你探索所有的数据集特征，你会发现票务和船舱特征有很多缺失值（NaN），因此它们不会对我们的分析增加太多价值。为了解决这个问题，我们将从数据框中删除这些特征。
- en: 'Use the following line of code to drop the `ticket` and `cabin` features entirely
    from the DataFrame:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码删除数据框中`ticket`和`cabin`特征：
- en: '[PRE23]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: There are a lot of reasons to have such missing values in our dataset. But in
    order to preserve the integrity of the dataset, we need to handle such missing
    values. In this specific problem, we will choose to drop them.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中有很多原因可能会导致缺失值。但是，为了保持数据集的完整性，我们需要处理这些缺失值。在这个特定问题中，我们选择将其删除。
- en: 'Use the following line of code in order to remove all `NaN` values from all
    the remaining features:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码删除所有剩余特征中的`NaN`值：
- en: '[PRE24]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Now, we have a sort of compete dataset that we can use to do our analysis. If
    you decided to just delete all the NaNs without deleting the **ticket** and **cabin**
    features first, you will find that most of the dataset is removed, because the `.dropna()`
    method removes an observation from the DataFrame, even if it has only one NaN
    in one of the features.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了一个完整的数据集，可以用来进行分析。如果你决定删除所有 NaN，而不首先删除**票务**和**船舱**特征，你会发现大部分数据集会被删除，因为`.dropna()`方法会删除数据框中的一个观察值，即使它只在某个特征中有一个
    NaN。
- en: 'Let’s do some data visualization to see the distribution of some features and
    understand the relationship between the explanatory features:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一些数据可视化，看看某些特征的分布，并理解解释性特征之间的关系：
- en: '[PRE25]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](img/cdec217d-50f1-41fc-b1ef-bb9b49c18ead.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cdec217d-50f1-41fc-b1ef-bb9b49c18ead.png)'
- en: 'Figure 8: Basic visualizations for the Titanic data samples'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：泰坦尼克号数据样本的基本可视化
- en: As we mentioned, the purpose of this analysis is to predict if a specific passenger
    will survive the tragedy based on the available feature, such as traveling class
    (called `pclass` in the data), **Sex**, **Age**, and **Fare Price**. So, let's
    see if we can get a better visual understanding of the passengers who survived
    and died.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，本次分析的目的是根据可用特征预测特定乘客是否能在灾难中生还，比如旅行舱位（在数据中称为`pclass`）、**性别**、**年龄**和**票价**。因此，让我们看看能否更好地通过可视化来了解幸存和死亡的乘客。
- en: 'First, let''s draw a bar plot to see the number of observations in each class
    (survived/died):'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们绘制一个条形图，看看每个舱位（生还/死亡）中观察的数量：
- en: '[PRE26]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](img/2f98e69d-7965-40fa-b36b-c53188be57d4.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2f98e69d-7965-40fa-b36b-c53188be57d4.png)'
- en: 'Figure 9: Survival breakdown'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：生还情况分布
- en: 'Let''s get some more understanding of the data by breaking down the previous
    graph by gender:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过性别划分前面的图表，进一步了解数据：
- en: '[PRE27]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](img/c97d7af6-5437-4acf-ac37-66f45ed2462e.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c97d7af6-5437-4acf-ac37-66f45ed2462e.png)'
- en: 'Figure 10: Further breakdown for the Titanic data by the gender feature'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：基于性别特征的泰坦尼克号数据进一步拆解
- en: Now, we have more information about the two possible classes (survived and died).
    The exploration and visualization step is necessary because it gives you more
    insight into the structure of the data and helps you to choose the suitable learning
    algorithm for your problem. As you can see, we started with very basic plots and
    then increased the complexity of the plot to discover more about the data that
    we were working with.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了更多关于两个可能类别（生还和死亡）的信息。探索和可视化步骤是必要的，因为它能让你更深入了解数据的结构，并帮助你选择适合问题的学习算法。正如你所看到的，我们从非常基础的图表开始，然后逐步增加图表的复杂性，以便发现更多关于我们所处理数据的信息。
- en: Data analysis – supervised machine learning
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析 – 监督式机器学习
- en: The purpose of this analysis is to predict the survivors. So, the outcome will
    be survived or not, which is a binary classification problem; in it, you have
    only two possible classes.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 该分析的目的是预测幸存者。因此，结果将是生还或未生还，这是一个二元分类问题；在这个问题中，只有两个可能的类别。
- en: 'There are lots of learning algorithms that we can use for binary classification
    problems. Logistic regression is one of them. As explained by Wikipedia:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用许多学习算法来解决二元分类问题。逻辑回归就是其中之一。正如维基百科所解释的：
- en: '*In statistics, logistic regression or logit regression is a type of regression
    analysis used for predicting the outcome of a categorical dependent variable (a
    dependent variable that can take on a limited number of values, whose magnitudes
    are not meaningful but whose ordering of magnitudes may or may not be meaningful)
    based on one or more predictor variables. That is, it is used in estimating empirical
    values of the parameters in a qualitative response model. The probabilities describing
    the possible outcomes of a single trial are modeled, as a function of the explanatory
    (predictor) variables, using a logistic function. Frequently (and subsequently
    in this article) "logistic regression" is used to refer specifically to the problem
    in which the dependent variable is binary—that is, the number of available categories
    is two—and problems with more than two categories are referred to as multinomial
    logistic regression or, if the multiple categories are ordered, as ordered logistic
    regression. Logistic regression measures the relationship between a categorical
    dependent variable and one or more independent variables, which are usually (but
    not necessarily) continuous, by using probability scores as the predicted values
    of the dependent variable.[1] As such it treats the same set of problems as does
    probit regression using similar techniques.*'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '*在统计学中，逻辑回归或logit回归是一种回归分析方法，用于预测类别型因变量（可以取有限数量值的因变量，这些值的大小没有实际意义，但其大小的排序可能有意义，也可能没有意义）的结果，基于一个或多个预测变量。也就是说，它用于估计定性响应模型中参数的经验值。描述单次试验可能结果的概率是通过逻辑函数建模的，作为解释变量（预测变量）的函数。在本文中，"逻辑回归"通常特指因变量为二元的情况——即，类别数量为二——而具有多个类别的问题称为多项式逻辑回归，若类别是有序的，则称为有序逻辑回归。逻辑回归衡量类别型因变量与一个或多个自变量之间的关系，这些自变量通常（但不一定）是连续的，通过使用概率得分作为因变量的预测值。* '
- en: 'In order to use logistic regression, we need to create a formula that tells
    our model the type of features/inputs we''re giving it:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用逻辑回归，我们需要创建一个公式，告诉模型我们所提供的特征/输入类型：
- en: '[PRE28]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![](img/a2254f5c-9ef2-4f13-8658-962474fc88c5.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a2254f5c-9ef2-4f13-8658-962474fc88c5.png)'
- en: 'Figure 11: Logistic regression results'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：逻辑回归结果
- en: 'Now, let''s plot the prediction of our model versus actual ones and also the
    residuals, which is the difference between the actual and predicted values of
    the target variable:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们绘制模型的预测值与实际值，以及残差图，残差是目标变量的实际值与预测值之间的差异：
- en: '[PRE29]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![](img/c020d1bf-3a74-496d-9d74-4b581068d655.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c020d1bf-3a74-496d-9d74-4b581068d655.png)'
- en: 'Figure 12: Understanding the logit regression model'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：理解logit回归模型
- en: Now, we have built our logistic regression model, and prior to that, we have
    done some analysis and exploration of the dataset. The preceding example shows
    you the general pipelines for building a machine learning solution.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经构建了逻辑回归模型，并且在此之前，我们对数据集进行了分析和探索。上述示例向你展示了构建机器学习解决方案的一般流程。
- en: Most of the time, practitioners fall into some technical pitfalls because they
    lack experience of understanding the concepts of machine learning. For example,
    someone might get an accuracy of 99% over the test set, and then without doing
    any investigation of the distribution of classes in the data (such as how many
    samples are negative and how many samples are positive), they deploy the model.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，从业者会因为缺乏对机器学习概念的理解经验而陷入一些技术陷阱。例如，有人可能在测试集上获得了99%的准确率，但在没有调查数据中类别分布的情况下（例如，负样本和正样本的数量），他们就部署了模型。
- en: To highlight some of these concepts and differentiate between different kinds
    of errors that you need to be aware of and which ones you should really care about,
    we'll move on to the next section.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 为了突出这些概念，并区分你需要注意的不同类型的误差，以及你应该真正关心的误差，我们将进入下一部分。
- en: Different types of errors
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不同类型的误差
- en: In machine learning, there are two types of errors, and as a newcomer to data
    science, you need to understand the crucial difference between both of them. If
    you end up minimizing the wrong type of error, the whole learning system will
    be useless and you won’t be able to use it in practice over unseen data. To minimize
    this kind of misunderstanding between practitioners about these two types of errors,
    we are going to explain them in the following two sections.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，有两种类型的误差，作为数据科学的新人，你需要理解它们之间至关重要的区别。如果你最终最小化了错误的类型，整个学习系统将变得毫无用处，你将无法在未见过的数据上实践应用它。为了减少从业者对这两种误差的误解，我们将在接下来的两个部分中进行解释。
- en: Apparent (training set) error
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 表观（训练集）误差
- en: This the first type of error that you don't have to care about minimizing. Getting
    a small value for this type of error doesn't mean that your model will work well
    over the unseen data (generalize). To better understand this type of error, we'll
    give a trivial example of a class scenario. The purpose of solving problems in
    the classroom is not to be able to solve the same problem again in the exam, but
    to be able to solve other problems that won’t necessarily be similar to the ones
    you practiced in the classroom. The exam problems could be from the same family
    of the classroom problems, but not necessarily identical.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这是第一种你不必关心最小化的误差类型。这个误差类型的值小并不意味着你的模型在未见过的数据上能够很好地工作（泛化）。为了更好地理解这种误差类型，我们将举一个简单的课堂情境例子。解决课堂问题的目的并不是能够在考试中再次解决相同的问题，而是能够解决其他可能与课堂上练习的问题不完全相似的问题。考试题目可能来自与课堂问题同一类，但不一定是完全相同的。
- en: Apparent error is the ability of the trained model to perform on the training
    set for which we already know the true outcome/output. If you manage to get 0
    error over the training set, then it is a good indicator for you that your model
    (mostly) won't work well on unseen data (won't generalize). On the other hand,
    data science is about using a training set as a base knowledge for the learning
    algorithm to work well on future unseen data.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 表观误差是训练好的模型在我们已经知道真实结果/输出的训练集上的表现。如果你能够在训练集上得到0误差，那么它是一个很好的指示，表明你的模型（大多数情况下）在未见过的数据上（不会）表现良好（不会泛化）。另一方面，数据科学的核心在于使用训练集作为基础知识，使学习算法能够在未来的未见过数据上表现良好。
- en: 'In *Figure 3*, the red curve represents the **apparent** error. Whenever you
    increase the model''s ability to memorize things (such as increasing the model
    complexity by increasing the number of explanatory features), you will find that
    this apparent error approaches zero. It can be shown that if you have as many
    features as observations/samples, then the **apparent** error will be zero:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图3*中，红色曲线代表**表观**误差。每当你增加模型的记忆能力（例如，通过增加解释性特征的数量来增加模型复杂度），你会发现表观误差趋近于零。可以证明，如果你的特征数量与观测/样本数量相同，那么**表观**误差将为零：
- en: '![](img/04bc2373-a824-45fc-b4d1-7beb0ab33bfb.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![](img/04bc2373-a824-45fc-b4d1-7beb0ab33bfb.png)'
- en: 'Figure 13: Apparent error (red curve) and generalization/true error (light
    blue)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图13：表观误差（红色曲线）和泛化/真实误差（浅蓝色）
- en: Generalization/true error
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 泛化/真实误差
- en: This is the second and more important type of error in data science. The whole
    purpose of building learning systems is the ability to get a smaller generalization
    error on the test set; in other words, to get the model to work well on a set
    of observation/samples that haven't been used in the training phase. If you still
    consider the class scenario from the previous section, you can think of generalization
    error as the ability to solve exam problems that weren’t necessarily similar to
    the problems you solved in the classroom to learn and get familiar with the subject.
    So, generalization performance is the model's ability to use the skills (parameters)
    that it learned in the training phase in order to correctly predict the outcome/output
    of unseen data.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据科学中第二个也是更重要的错误类型。构建学习系统的整个目的是在测试集上获得更小的泛化误差；换句话说，让模型在一组没有在训练阶段使用的观测数据/样本上表现良好。如果你还记得上一节中的课堂情境，你可以把泛化误差看作是解决考试题目的一种能力，这些考试题目不一定和你在课堂上解决的题目类似，也不是你通过学习和熟悉科目所解决的题目。因此，泛化性能是指模型能够利用它在训练阶段学到的技能（参数），正确预测未见过数据的结果/输出。
- en: In *Figure 13*, the light blue line represents the generalization error. You
    can see that as you increase the model complexity, the generalization error will
    be reduced, until some point when the model will start to lose its increasing
    power and the generalization error will decrease. This part of the curve where
    you get the generalization error to lose its increasing generalization power,
    is called **overfitting**.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图13*中，浅蓝色的线表示泛化误差。你可以看到，随着模型复杂度的增加，泛化误差会减少，直到某个点，模型开始失去其增益能力，泛化误差会开始上升。这个曲线的部分，被称为**过拟合**，是指泛化误差失去增益能力的地方。
- en: The takeaway message from this section is to minimize the generalization error
    as much as you can.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的关键内容是尽量减少泛化误差。
- en: Summary
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: A linear model is a very powerful tool that you can use as an initial learning
    algorithm if your data matches its assumptions. Understanding linear models will
    help you to understand more sophisticated models that use linear models as building
    blocks.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型是一个非常强大的工具，如果你的数据符合其假设，它可以作为初始学习算法。理解线性模型将帮助你理解更复杂的模型，因为这些复杂模型以线性模型为构建模块。
- en: Next up, we will continue using the Titanic example by addressing model complexity
    and assessment in more detail. Model complexity is a very powerful tool and you
    need to use it carefully in order to enhance the generalization error. Misunderstanding
    it will lead to overfitting problems.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将继续使用泰坦尼克号例子，更详细地探讨模型复杂度和评估。模型复杂度是一个非常强大的工具，你需要小心使用它，以便提升泛化误差。误解它会导致过拟合问题。
