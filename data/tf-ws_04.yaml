- en: 4\. Regression and Classification Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. 回归与分类模型
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, you will learn how to build regression and classification models
    using TensorFlow. You will build models with TensorFlow utilizing Keras layers,
    which are a simple approach to model building that offer a high-level API for
    building and training models. You will create models to solve regression and classification
    tasks, including the classification of the binding properties of various molecules.
    You will also use TensorBoard to visualize the architecture of TensorFlow models
    and view the training process.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何使用TensorFlow构建回归和分类模型。你将利用TensorFlow中的Keras层来构建模型，Keras是一种简单的建模方法，提供了一个高级API来构建和训练模型。你将创建模型来解决回归和分类任务，包括分类不同分子结合特性的任务。你还将使用TensorBoard来可视化TensorFlow模型的架构并查看训练过程。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapter, you learned how to use some TensorFlow resources to
    aid in development. These included TensorBoard (for visualizing computational
    graphs), TensorFlow Hub (an online repository for machine learning modules), and
    Google Colab (an online Python development environment for running code on Google
    servers). All these resources help machine learning practitioners develop models efficiently.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了如何使用一些TensorFlow资源来帮助开发。这些资源包括TensorBoard（用于可视化计算图）、TensorFlow Hub（一个机器学习模块的在线仓库）和Google
    Colab（一个在线Python开发环境，用于在Google服务器上运行代码）。所有这些资源都帮助机器学习从业者高效地开发模型。
- en: In this chapter, you will explore how to create ANNs using TensorFlow. You will
    build ANNs with different architectures to solve regression and classification
    tasks. Regression tasks aim to predict continuous variables from the input training
    data, while classification tasks aim to classify the input data into two or more
    classes. For example, a model to predict whether or not it will rain on a given
    day is a classification task since the result of the model will be of two classes—rain
    or no rain. However, a model to predict the amount of rain on a given day would
    be an example of a regression task since the output of the model would be a continuous
    variable—the amount of rain.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将探索如何使用TensorFlow创建人工神经网络（ANNs）。你将构建具有不同架构的ANNs来解决回归和分类任务。回归任务旨在从输入的训练数据中预测连续变量，而分类任务则旨在将输入数据分类到两个或更多类别中。例如，预测某一天是否会下雨的模型是一个分类任务，因为模型的结果会有两个类别——下雨或不下雨。然而，预测某一天降水量的模型则是一个回归任务，因为模型的输出是一个连续变量——降水量。
- en: Models that are used to tackle these tasks represent a large class of machine
    learning models, and a huge amount of machine learning problems fall into these
    two categories. This chapter will demonstrate how regression and classification
    models can be created, trained, and evaluated in TensorFlow. You will use much
    of the learning covered in the previous chapters (including using TensorBoard
    to monitor the model training process) to understand how to build performant models.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 用于解决这些任务的模型代表了机器学习模型中的一大类，许多机器学习问题都属于这两大类。 本章将演示如何在TensorFlow中创建、训练和评估回归和分类模型。你将运用前几章所学的内容（包括使用TensorBoard来监控模型训练过程），了解如何构建高效的模型。
- en: This chapter introduces the various parameters used to build ANNs (known as
    **hyperparameters**), which include activation functions, loss functions, and
    optimizers. Other hyperparameters to select in the model-fitting process include
    the number of epochs and batch size, which vary the number of times the entire
    dataset is used to update the weights and the number of data points for each update,
    respectively. You will also learn how to log variables during the model-fitting
    process so that they can be visualized in TensorBoard. This allows you to determine
    whether the model is under- or overfitting the training data. Finally, after building
    your model, you will learn how to evaluate it on the dataset to see how well it
    performs.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了构建人工神经网络（ANNs）时使用的各种参数（称为**超参数**），这些参数包括激活函数、损失函数和优化器。模型拟合过程中的其他超参数包括训练轮次（epochs）和批量大小（batch
    size），它们分别决定了整个数据集用于更新权重的次数和每次更新时使用的数据点数量。你还将学习如何在模型拟合过程中记录变量，以便在TensorBoard中进行可视化。这样可以帮助你判断模型是欠拟合还是过拟合训练数据。最后，在构建模型后，你将学习如何在数据集上评估模型，看看它的表现如何。
- en: Sequential Models
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列模型
- en: A sequential model is used to build regression and classification models. In
    sequential models, information propagates through the network from the input layer
    at the beginning to the output layer at the end. Layers are stacked in the model
    sequentially, with each layer having an input and an output.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序模型用于构建回归和分类模型。在顺序模型中，信息从开始的输入层传播到结束的输出层。模型中的层是按顺序堆叠的，每一层都有输入和输出。
- en: 'Other types of ANN models exist, such as recurrent neural networks (in which
    the output feeds back into the input), which will be covered in later chapters.
    The difference between sequential and recurrent neural networks is shown in *Figure
    4.01*. In both the models, the information flows from the input layer through
    the hidden layers to the output layer, as indicated by the direction of the arrows.
    However, in recurrent architectures, the output of the hidden layers feeds back
    into the input of the hidden layers:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 存在其他类型的人工神经网络（ANN）模型，例如递归神经网络（其输出反馈到输入中），这些将在后续章节中介绍。顺序神经网络与递归神经网络的区别如*图 4.01*所示。在这两种模型中，信息从输入层通过隐藏层流向输出层，箭头的方向表示这一流向。然而，在递归结构中，隐藏层的输出会反馈到隐藏层的输入：
- en: '![Figure 4.1: The architectures of sequential and recurrent ANNs'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.1：顺序和递归人工神经网络的架构](img/B16341_04_01.jpg)'
- en: '](img/B16341_04_01.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_04_01.jpg)'
- en: 'Figure 4.1: The architectures of sequential and recurrent ANNs'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1：顺序和递归人工神经网络的架构
- en: In the following section, you will learn how to create sequential models in
    TensorFlow that form the basis of regression and classification models. You will
    utilize the Keras API, which is now included as part of the TensorFlow library
    for sequential models, since the high-level API provides a simple interface for
    creating these models. Using the API, you will find that adding more layers to
    a model is incredibly easy and is great for new practitioners learning the field.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，您将学习如何在 TensorFlow 中创建顺序模型，这些模型构成了回归和分类模型的基础。您将使用 Keras API，该 API 现在作为
    TensorFlow 库的一部分，专门用于顺序模型，因为这个高级 API 提供了一个简单的接口来创建这些模型。使用该 API，您会发现向模型中添加更多层非常容易，非常适合新手学习这个领域。
- en: 'A sequential model can be initialized as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 可以按如下方式初始化一个顺序模型：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once the model has been initialized, layers can be added to the model. In this
    section, you will also explore how to add Keras layers to the model.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型初始化完成，就可以向模型添加层。在本节中，您还将探讨如何向模型中添加 Keras 层。
- en: Keras Layers
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Keras 层
- en: Keras layers are included in the TensorFlow package. Keras layers are a collection
    of commonly used layers that can be added easily to your sequential models.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 层包含在 TensorFlow 包中。Keras 层是常用层的集合，可以轻松地添加到您的顺序模型中。
- en: Note
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can check out all the possible options for Keras layers here: [https://www.tensorflow.org/api_docs/python/tf/keras/layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在这里查看 Keras 层的所有可能选项：[https://www.tensorflow.org/api_docs/python/tf/keras/layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers)。
- en: 'To add layers to a model of the `Sequential` class, you can use the model''s
    `add` method. One optional layer that can be added to the beginning of a sequential
    model is an **input layer** as an entry point to the network. Input layers can
    take the following common input arguments:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要向 `Sequential` 类的模型添加层，可以使用模型的 `add` 方法。可以选择在顺序模型的开头添加一个**输入层**，作为网络的入口点。输入层可以接受以下常见的输入参数：
- en: '`input_shape` (required): The shape of the input tensor, not including the
    batch axis'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_shape`（必需）：输入张量的形状，不包括批处理轴'
- en: '`batch_size`: An optional argument indicating the input batch size'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size`：一个可选参数，表示输入的批处理大小'
- en: '`name`: Optional name of the input layer'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：输入层的可选名称'
- en: 'Input layers can be added to a model as follows. The following code snippet
    is used to add a layer, expecting inputs to have eight features:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 可以按如下方式向模型添加输入层。以下代码片段用于添加一个层，假设输入具有八个特征：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'By providing a `name` argument, you can label the layers, which will be useful
    when visualizing the model in TensorBoard. Another type of layer that is commonly
    used when building regression and classification models is the `input_shape` provided
    as an argument. The following are the common input arguments for layers of the
    `Dense` class:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 通过提供 `name` 参数，您可以给层命名，这在 TensorBoard 中可视化模型时会非常有用。另一种常用的层是提供为参数的 `input_shape`。以下是
    `Dense` 类层的常见输入参数：
- en: '`units` (required): This is a positive integer denoting the number of units
    in the layer.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`units`（必需）：这是一个正整数，表示该层中的单元数量。'
- en: '`input_shape`: This is the shape of the input tensor but is not required unless
    it is the first layer of the model.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input_shape`: 这是输入张量的形状，除非它是模型的第一层，否则不需要。'
- en: '`activation`: This is an optional argument indicating which activation function
    to apply to the output of the layer.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`activation`: 这是一个可选参数，指示要应用于该层输出的激活函数。'
- en: '`use_bias`: This is a Boolean argument indicating whether to use bias in the
    layer. The default is set to `True`.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_bias`: 这是一个布尔值参数，指示是否在层中使用偏置。默认值设置为 `True`。'
- en: '`name`: This refers to the name of the layer. One will be generated if this
    argument is not provided.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`: 这是该层的名称。如果未提供该参数，将会自动生成一个名称。'
- en: '`kernel_initializer`: This is the initializer for the kernel weights. The **Glorot
    uniform initializer**, which has a normal distribution centered on zero and a
    standard deviation that is dependent on the number of units in the layer, is used
    by default.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel_initializer`: 这是用于初始化核权重的初始化器。默认使用**Glorot 均匀初始化器**，它的分布以零为中心，标准差依赖于该层单元的数量。'
- en: '`bias_initializer`: This is the initializer for the bias. The default of this
    parameter is used to set the bias values to zero.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bias_initializer`: 这是偏置的初始化器。此参数的默认值将偏置值设置为零。'
- en: '`kernel_regularizer`: This is the regularizer to use on the kernel weights.
    There are none applied by default.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel_regularizer`: 这是用于核权重的正则化器，默认情况下没有应用任何正则化器。'
- en: '`bias_regularizer`: This is the regularizer to use on the bias. There are none
    applied by default.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bias_regularizer`: 这是用于偏置的正则化器，默认情况下没有应用任何正则化器。'
- en: 'The following is an example of adding a dense layer to a model with `12` units,
    adding a `sigmoid` activation function at the output of the layer, and naming
    the layer `Dense_layer_1`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将一个 `12` 单元的密集层（dense layer）添加到模型的示例，并在该层输出处添加 `sigmoid` 激活函数，同时将该层命名为 `Dense_layer_1`：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now that you understand how to initialize sequential models and add layers to
    them, you will create a Keras sequential model using TensorFlow in the first exercise.
    You will initialize a model, add layers to the model, add activation functions
    to the output of the model, and pass data through the model to simulate creating
    a prediction.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经理解了如何初始化序列型模型并向其中添加层，你将在第一个练习中使用 TensorFlow 创建一个 Keras 序列模型。你将初始化一个模型，向模型添加层，向模型的输出添加激活函数，并将数据通过模型来模拟创建一个预测。
- en: 'Exercise 4.01: Creating an ANN with TensorFlow'
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.01：使用 TensorFlow 创建人工神经网络（ANN）
- en: In this exercise, you will create your first sequential ANN in TensorFlow. You
    will have an input layer, a hidden layer with four units and a ReLU activation
    function, and an output layer with one unit. Then, you will create some simulation
    data by generating random numbers and passing it through the model, using the
    model's `predict` method to simulate a prediction for each data example.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，你将创建第一个 TensorFlow 序列型人工神经网络（ANN）。你将有一个输入层、一个具有四个单元和 ReLU 激活函数的隐藏层，以及一个具有一个单元的输出层。然后，你将通过生成随机数来创建一些模拟数据，并将其通过模型，使用模型的
    `predict` 方法模拟对每个数据示例的预测。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成本次练习：
- en: 'Open a Jupyter notebook and import the TensorFlow library:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Jupyter Notebook 并导入 TensorFlow 库：
- en: '[PRE3]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Initialize a Keras model of the sequential class:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个 Keras 序列模型：
- en: '[PRE4]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Add an input layer to the model using the model''s `add` method, and add the
    `input_shape` argument with size `(8,)` to represent input data with eight features:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型的 `add` 方法向模型添加一个输入层，并添加 `input_shape` 参数，大小为 `(8,)`，表示具有八个特征的输入数据：
- en: '[PRE5]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Add two layers of the `Dense` class to the model. The first will represent
    your hidden layer with four units and a ReLU activation function, and the second
    will represent your output layer with one unit:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向模型添加两个 `Dense` 类的层，第一个表示具有四个单元和 ReLU 激活函数的隐藏层，第二个表示具有一个单元的输出层：
- en: '[PRE6]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'View the weights by calling the `variables` attribute of the model:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用模型的 `variables` 属性查看权重：
- en: '[PRE7]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You should get the following output:'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该会看到以下输出：
- en: '![Figure 4.2: The variables of the ANN'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.2：人工神经网络的变量'
- en: '](img/B16341_04_02.jpg)'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_04_02.jpg)'
- en: 'Figure 4.2: The variables of the ANN'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.2：人工神经网络的变量
- en: This output shows all the variables that compose the model; they include the
    values for all weights and biases in each layer.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该输出显示了组成模型的所有变量；它们包括每一层中所有权重和偏置的值。
- en: 'Create a tensor of size `32x8`, which represents a tensor with 32 records and
    8 features:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个大小为`32x8`的张量，这表示一个包含32条记录和8个特征的张量：
- en: '[PRE8]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Call the `predict` method of the model and pass in the sample data:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用模型的`predict`方法并传入样本数据：
- en: '[PRE9]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You should get the following result:'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下结果：
- en: '![Figure 4.3: The output of the ANN after random inputs have been applied'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.3：应用随机输入后的人工神经网络（ANN）输出'
- en: '](img/B16341_04_03.jpg)'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_04_03.jpg)'
- en: 'Figure 4.3: The output of the ANN after random inputs have been applied'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3：应用随机输入后的人工神经网络（ANN）输出
- en: Calling the `predict()` method on the sample data will propagate the data through
    the network. In each layer, there will be a matrix multiplication of the data
    with the weights, and the bias will be added before the data is passed as input
    data to the next layer. This process continues until the final output layer.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在样本数据上调用`predict()`方法将数据传递通过网络。在每一层中，数据会与权重进行矩阵乘法，偏置将被加到数据中，然后数据作为输入传递到下一层。这个过程会持续，直到最终的输出层。
- en: In this exercise, you created a sequential model with multiple layers. You initialized
    a model, added an input layer to accept data with eight features, added a hidden
    layer with four units, and added an output layer with one unit. Before fitting
    a model to training data, you must first compile the model with an optimizer and
    choose a loss function to minimize the value it computes by updating weights in
    the training process.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你创建了一个包含多层的顺序模型。你初始化了一个模型，添加了一个输入层以接受具有八个特征的数据，添加了一个具有四个单元的隐藏层，并添加了一个具有一个单元的输出层。在将模型拟合到训练数据之前，必须首先通过优化器编译模型，并选择一个损失函数来最小化通过更新训练过程中的权重计算的值。
- en: In the next section, you will explore how to compile models, then fit them to
    training data.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，你将探索如何编译模型，然后将其拟合到训练数据中。
- en: Model Fitting
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型拟合
- en: 'Once a model has been initialized and layers have been added to the ANN, the
    model must be configured with an optimizer, losses, and any evaluation metrics
    through the compilation process. A model can be compiled using the model''s `compile`
    method, as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型被初始化并且层已经添加到人工神经网络（ANN）中，就必须通过编译过程使用优化器、损失函数和任何评估指标来配置模型。模型可以使用模型的`compile`方法进行编译，如下所示：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Optimizers can be chosen by simply naming the optimizer as the argument. The
    following optimizers are available as default for Keras models:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过简单地命名优化器作为参数来选择优化器。以下是Keras模型的默认可用优化器：
- en: '**Stochastic gradient descent** (**SGD**): This updates the weights for each
    example in the dataset. You can find more information about SGD here: [https://keras.io/api/optimizers/sgd/](https://keras.io/api/optimizers/sgd/).'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机梯度下降法**（**SGD**）：此方法更新数据集中每个示例的权重。你可以在这里找到有关SGD的更多信息：[https://keras.io/api/optimizers/sgd/](https://keras.io/api/optimizers/sgd/)。'
- en: '**RMSprop**: This is an adaptive optimizer that varies the weights during training
    by using a decaying average of the gradients at each update. You can find more
    information about RMSprop here: [https://keras.io/api/optimizers/rmsprop/](https://keras.io/api/optimizers/rmsprop/).'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RMSprop**：这是一种自适应优化器，在训练过程中通过使用梯度的衰减平均值来改变权重。你可以在这里找到有关RMSprop的更多信息：[https://keras.io/api/optimizers/rmsprop/](https://keras.io/api/optimizers/rmsprop/)。'
- en: '**Adam**: This is also an adaptive optimizer that implements the Adam algorithm,
    updating the learning rates based on the first- and second-order gradients. You
    can find more information about Adam here: [https://keras.io/api/optimizers/adam/](https://keras.io/api/optimizers/adam/).'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Adam**：这也是一个自适应优化器，实施了Adam算法，根据一阶和二阶梯度更新学习率。你可以在这里找到有关Adam的更多信息：[https://keras.io/api/optimizers/adam/](https://keras.io/api/optimizers/adam/)。'
- en: '**Adagrad**: This adaptive gradient optimizer adapts the learning rate at each
    weight update. The learning rate is adapted for each feature using the prior gradients
    and observations. You can find more information about Adagrad here: [https://keras.io/api/optimizers/adagrad/](https://keras.io/api/optimizers/adagrad/).'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Adagrad**：这种自适应梯度优化器在每次更新权重时调整学习率。每个特征的学习率会根据先前的梯度和观测值进行调整。你可以在这里找到有关Adagrad的更多信息：[https://keras.io/api/optimizers/adagrad/](https://keras.io/api/optimizers/adagrad/)。'
- en: '**Adadelta**: This is a more robust version of Adagrad that uses a sliding
    window of gradient updates to adapt the learning rate. You can find more information
    about Adadelta here: [https://keras.io/api/optimizers/adadelta/](https://keras.io/api/optimizers/adadelta/).'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Adadelta**：这是Adagrad的一个更强大的版本，通过使用梯度更新的滑动窗口来调整学习率。你可以在这里找到有关Adadelta的更多信息：[https://keras.io/api/optimizers/adadelta/](https://keras.io/api/optimizers/adadelta/)。'
- en: '**Adamax**: This is an adaptive optimizer that is a variant of the Adam optimizer. You
    can find more information about Adamax here: [https://keras.io/api/optimizers/adamax/](https://keras.io/api/optimizers/adamax/).'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Adamax**：这是一种自适应优化器，是Adam优化器的变种。 您可以在这里找到有关Adamax的更多信息：[https://keras.io/api/optimizers/adamax/](https://keras.io/api/optimizers/adamax/)。'
- en: '**Nadam**: This is another adaptive optimizer that is a variant of the Adam
    optimizer with Nesterov momentum. You can find more information about Nadam here:
    [https://keras.io/api/optimizers/Nadam/](https://keras.io/api/optimizers/Nadam/).'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Nadam**：这是Adam优化器的另一种自适应变种，具有Nesterov动量。 您可以在这里找到有关Nadam的更多信息：[https://keras.io/api/optimizers/Nadam/](https://keras.io/api/optimizers/Nadam/)。'
- en: '**Ftrl**: This is an optimizer that implements the FTRL algorithm. You can
    find more information about Ftrl here: [https://keras.io/api/optimizers/ftrl/](https://keras.io/api/optimizers/ftrl/).'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ftrl**：这是实施FTRL算法的优化器。 您可以在这里找到有关Ftrl的更多信息：[https://keras.io/api/optimizers/ftrl/](https://keras.io/api/optimizers/ftrl/)。'
- en: 'Custom optimizers can also be added to Keras models if the provided ones are
    not relevant. Selecting the most appropriate optimizer is often a matter of trying
    each and identifying which optimizer produces the lowest error. This process is
    known as **hyperparameter tuning** and will be covered in a later chapter. In
    the next section, you will uncover another option when compiling models: the loss
    function. The goal of training a model is to minimize the value computed by the
    loss function.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果提供的优化器不相关，则还可以将自定义优化器添加到Keras模型中。 选择最合适的优化器通常是尝试每个优化器并确定哪个优化器通过优化过程产生最低误差的问题。
    这个过程称为 **超参数调优**，将在后续章节中讨论。 在下一节中，您将了解在编译模型时的另一个选项：损失函数。 训练模型的目标是通过最小化损失函数计算的值来最小化损失函数。
- en: The Loss Function
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 损失函数
- en: The loss function is the measure of error between the predicted results and
    the true results. You use the loss function during the training process to determine
    whether varying any of the weights and biases will create a better model by minimizing
    the loss function's value through the optimization process.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数是预测结果与真实结果之间误差的度量。 您在训练过程中使用损失函数来确定通过优化过程中任何权重和偏差的变化是否能创建更好的模型，通过最小化优化过程中损失函数的值来实现这一目标。
- en: There are many different types of loss functions that can be used, and the specific
    one will depend on the problem and goal. In general, regression and classification
    tasks will have different loss functions. Since regression models predict continuous
    variables, loss functions for regression models typically aim to summarize how
    far, on average, the predictions are from the true values. For classification
    models, loss functions aim to determine how the quantity of true positive, true
    negative, false positive, and false negative classifications of the predicted
    classes vary compared to the true classes.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用许多不同类型的损失函数，具体选择将取决于问题和目标。 一般来说，回归和分类任务将使用不同的损失函数。 由于回归模型预测连续变量，回归模型的损失函数通常旨在总结预测与真实值之间的平均距离。
    对于分类模型，损失函数旨在确定预测类的真阳性、真阴性、假阳性和假阴性分类数量与真实类的差异程度。
- en: '**True positives** are defined as correct predictions labeled positive by the
    classifier; similarly, **true negatives** are correct predictions labeled negative.
    **False positives** are predictions labeled positive where the true value is negative,
    and **false negatives** are predictions labeled negative that are actually positive.
    Loss functions that are directly available to use in Keras sequential models for
    regression include the following:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**真阳性** 是分类器正确预测为阳性的标签; 同样地，**真阴性** 是正确预测为阴性的标签。**假阳性** 是被预测为阳性但实际为阴性的预测，而
    **假阴性** 是被预测为阴性但实际为阳性的预测。Keras顺序模型中用于回归的直接可用损失函数包括以下内容：'
- en: '`(true value – predicted value)^2`, and returns the average across the entire
    dataset. This loss function is primarily used for regression problems, and the
    squaring of the difference between the two values ensures the loss function results
    in a positive number.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`(真实值 – 预测值)^2`，并返回整个数据集的平均值。 此损失函数主要用于回归问题，两个值之间的平方差确保损失函数结果为正数。'
- en: '`|true value – predicted value|`, and returns the average across the dataset.
    This method also ensures that the result is a positive value.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`|真实值 – 预测值|`，并返回整个数据集的平均值。 此方法还确保结果为正值。'
- en: '`|(true value– predicted value) / true value|`, and returns the average across
    the dataset as a percentage.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`|(真实值 - 预测值) / 真实值|`，并返回数据集上的平均值，作为百分比表示。'
- en: 'For classification, loss functions that are available include the following:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类问题，可用的损失函数包括以下内容：
- en: '`0` and `1`, with values closer to `1` representing a greater number of true
    positive classifications.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0` 和 `1`，值越接近 `1` 表示真实正例分类的数量越多。'
- en: '`0` and `1`.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0` 和 `1`。'
- en: 'When compiling a model, other metrics can also be passed in as an argument
    to the method. They will be calculated after each epoch and saved during the training
    process. The metrics that are available to be calculated for Keras models include
    the following:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在编译模型时，其他指标也可以作为参数传递给方法。它们将在每个 epoch 后进行计算，并在训练过程中保存。可用于 Keras 模型计算的指标包括以下内容：
- en: '**Accuracy**: This is the proportion of correct results out of the total results.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确率**：这是正确结果占总结果的比例。'
- en: '**Precision**: This is the proportion of true positives out of the total positives predicted.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确度**：这是预测为正例的真实正例的比例。'
- en: '**Recall**: This is the proportion of true positives out of the actual positives.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率**：这是实际正例中真实正例的比例。'
- en: '**AUC**: This metric represents the area under the ROC curve.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AUC**：这个指标表示 ROC 曲线下的面积。'
- en: 'These metrics can be incredibly valuable in understanding the performance of
    the model during the training process. All the metrics have values between `0`
    and `1`, with higher values representing better performance. Once the model has
    been compiled, it can be fit to the training data. This can be accomplished by
    calling the `fit` method and passing in the following arguments:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标在理解模型在训练过程中的表现时非常有价值。所有指标的值都在 `0` 和 `1` 之间，值越高表示表现越好。一旦模型编译完成，就可以将其拟合到训练数据。这可以通过调用
    `fit` 方法并传入以下参数来实现：
- en: '`x`: This is the feature data as a TensorFlow tensor or NumPy array.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：这是特征数据，可以是一个 TensorFlow 张量或 NumPy 数组。'
- en: '`y`: This is the target data as a TensorFlow tensor or NumPy array.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y`：这是目标数据，可以是一个 TensorFlow 张量或 NumPy 数组。'
- en: '`epochs`: This refers to the number of epochs to run the model for. An epoch
    is an iteration over the entire training dataset.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epochs`：这是模型训练的 epoch 数量。一个 epoch 是对整个训练数据集的一个迭代。'
- en: '`batch_size`: This is the number of training data samples to use per gradient update.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size`：这是每次梯度更新时使用的训练数据样本数量。'
- en: '`validation_split`: This is the proportion of the training data to be used
    for validation that is evaluated after each epoch. This proportion of data is
    not used in the weight update process.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`validation_split`：这是用于验证的数据占训练数据的比例，在每个 epoch 后进行评估。此部分数据不会用于权重更新过程。'
- en: '`shuffle`: This indicates whether to shuffle the training data before each
    epoch.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shuffle`：这表示是否在每个 epoch 前对训练数据进行洗牌。'
- en: 'To fit the model to the training data, the `fit` method can be applied to a
    model in the following way:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 要将模型拟合到训练数据，可以通过以下方式将 `fit` 方法应用于模型：
- en: '[PRE11]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Once the `fit` method has been called, the model will begin fitting to the training
    data. After each epoch, the loss is returned for the training. If a validation
    split is defined, then the loss is also evaluated on the validation split.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦调用了 `fit` 方法，模型将开始拟合训练数据。每个 epoch 后，会返回训练的损失。如果定义了验证集，则验证集的损失也会被评估。
- en: Model Evaluation
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估
- en: 'Once models are trained, they can be evaluated by utilizing the model''s `evaluate`
    method. The `evaluate` method assesses the performance of the model according
    to the loss function used to train the model and any metrics that were passed
    to the model. The method is best used when determining how the model will perform
    on new, unseen data by passing in a feature and target dataset that has not been
    used in the training process or out-of-sample dataset. The method can be called
    as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，可以通过使用模型的 `evaluate` 方法来评估模型。`evaluate` 方法根据用于训练模型的损失函数以及传递给模型的任何指标来评估模型的性能。该方法最适合用来确定模型在新数据上的表现，可以通过传入未在训练过程中使用的特征和目标数据集，或者是超出样本的数据集来实现。该方法可以按如下方式调用：
- en: '[PRE12]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The result of the method is first the loss calculated on the input data, and
    then, if any metrics were passed in the model compilation process, they will also
    be calculated when the `evaluate` method is executed. Model evaluation is an important
    step in determining how well your model is performing. Since there is an enormous
    number of hyperparameters (such as the number of hidden layers, the number of
    units in each layer, and the choice of activation functions, to name a few), model
    evaluation is necessary to determine which combination of hyperparameters is optimal.
    Effective model evaluation can help provide an unbiased view on which model architecture
    will perform best overall.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的结果首先是对输入数据计算的损失，然后，如果在模型编译过程中传递了任何指标，它们也将在执行 `evaluate` 方法时计算。模型评估是确定模型表现如何的关键步骤。由于存在大量的超参数（例如隐藏层的数量、每层的单元数量以及激活函数的选择等），模型评估是确定哪些超参数组合最优的必要步骤。有效的模型评估有助于提供一个无偏的视角，帮助确定哪种模型架构在整体上表现最佳。
- en: In the following exercise, you will undertake the process of creating an ANN,
    compiling the model, fitting the model to training data, and finally, evaluating
    the model on the training data. You will recreate the linear regression algorithm
    with an ANN, which can be interpreted as an ANN with only one layer and one unit.
    Furthermore, you will view the architecture of the model and model training process
    in TensorBoard.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下练习中，您将进行创建 ANN、编译模型、将模型拟合到训练数据以及最终在训练数据上评估模型的过程。您将使用 ANN 重现线性回归算法，这可以被理解为一个只有一层和一个单元的
    ANN。此外，您将通过 TensorBoard 查看模型的架构和模型训练过程。
- en: 'Exercise 4.02: Creating a Linear Regression Model as an ANN with TensorFlow'
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.02：使用 TensorFlow 创建一个线性回归模型作为 ANN
- en: In this exercise, you will create a linear regression model as an ANN using
    TensorFlow. The dataset, `Bias_correction_ucl.csv`, describes the bias correction
    of air temperature forecasts of Seoul, South Korea. The fields represent temperature
    measurements of the given date, the weather station at which the metrics were
    measured, model forecasts of weather-related metrics such as humidity, and projections
    for the temperature the following day. You are required to predict the next maximum
    and minimum temperature given measurements of the prior timepoints and attributes
    of the weather station.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，您将使用 TensorFlow 创建一个线性回归模型作为 ANN。数据集 `Bias_correction_ucl.csv` 描述了韩国首尔空气温度预报的偏差修正。该数据字段表示给定日期的温度测量、测量数据的气象站、与天气相关的模型预报（如湿度）以及次日温度的预测。您需要根据先前时间点的测量值和气象站的属性来预测接下来的最大和最小温度。
- en: Note
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `Bias_correction_ucl.csv` file can be found here: [https://packt.link/khfeF](https://packt.link/khfeF).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`Bias_correction_ucl.csv` 文件可以在这里找到：[https://packt.link/khfeF](https://packt.link/khfeF)。'
- en: 'Perform the following steps to complete this exercise:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成本次练习：
- en: Open a new Jupyter notebook to implement this exercise.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter notebook 来实现本次练习。
- en: 'In a new Jupyter Notebook cell, import the TensorFlow and pandas libraries:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新的 Jupyter Notebook 单元格中，导入 TensorFlow 和 pandas 库：
- en: '[PRE13]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Load in the dataset using the pandas `read_csv` function:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 的 `read_csv` 函数加载数据集：
- en: '[PRE14]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Make sure you change the path (highlighted) to the CSV file based on its location
    on your system. If you're running the Jupyter notebook from the same directory
    where the CSV file is stored, you can run the preceding code without any modification.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保您根据系统中 CSV 文件的位置更改路径（高亮显示的部分）。如果您从与 CSV 文件存储在同一目录的 Jupyter notebook 中运行代码，您可以在不做任何修改的情况下运行之前的代码。
- en: 'Drop the `date` column and drop any rows that have null values since your model
    requires numerical values only:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除 `date` 列，并删除所有包含空值的行，因为您的模型只需要数值数据：
- en: '[PRE15]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create target and feature datasets. The target dataset will contain the columns
    named `Next_Tmax` and `Next_Tmin`, while the feature dataset will contain all
    columns except those named `Next_Tmax` and `Next_Tmin`:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建目标和特征数据集。目标数据集将包含名为 `Next_Tmax` 和 `Next_Tmin` 的列，而特征数据集将包含除 `Next_Tmax` 和
    `Next_Tmin` 外的所有列：
- en: '[PRE16]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Rescale the feature dataset:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对特征数据集进行重缩放：
- en: '[PRE17]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Initialize a Keras model of the `Sequential` class:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个 Keras 的 `Sequential` 类模型：
- en: '[PRE18]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Add an input layer to the model using the model''s `add` method, and set `input_shape`
    to be the number of columns in the feature dataset:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型的 `add` 方法为模型添加输入层，并将 `input_shape` 设置为特征数据集中的列数：
- en: '[PRE19]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Add the output layer of the `Dense` class to the model with a size of `2`,
    representing the two target variables:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `Dense` 类的输出层添加到模型中，大小为 `2`，表示两个目标变量：
- en: '[PRE20]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Compile the model with an RMSprop optimizer and a mean squared error loss:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 RMSprop 优化器和均方误差损失函数编译模型：
- en: '[PRE21]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Add a callback for TensorBoard:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 TensorBoard 添加回调：
- en: '[PRE22]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Fit the model to the training data:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据：
- en: '[PRE23]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You should get the following output:'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该会得到以下输出：
- en: '![Figure 4.4: The output of the fitting process showing the epoch, train time
    per sample, and loss after each epoch'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.4：拟合过程的输出，显示每个 epoch 的训练时间和损失'
- en: '](img/B16341_04_04.jpg)'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_04_04.jpg)'
- en: 'Figure 4.4: The output of the fitting process showing the epoch, train time
    per sample, and loss after each epoch'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.4：拟合过程的输出，显示每个 epoch 的训练时间和损失
- en: 'Evaluate the model on the training data:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据上评估模型：
- en: '[PRE24]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This results in the following output:'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE25]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'View the model architecture and model-fitting process on TensorBoard by calling
    the following on the command line:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在命令行中调用以下命令，在 TensorBoard 上查看模型架构和拟合过程：
- en: '[PRE26]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You can see its execution in a web browser by visiting the URL that is provided after
    launching TensorBoard. The default URL provided is `http://localhost:6006/`:'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以通过访问启动 TensorBoard 后提供的 URL，在网页浏览器中查看其执行情况。默认提供的 URL 是 `http://localhost:6006/`：
- en: '![Figure 4.5: A visual representation of the model architecture in TensorBoard'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.5：TensorBoard 中模型架构的可视化表示'
- en: '](img/B16341_04_05.jpg)'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_04_05.jpg)'
- en: 'Figure 4.5: A visual representation of the model architecture in TensorBoard'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5：TensorBoard 中模型架构的可视化表示
- en: 'The loss function can be visualized as shown in the following figure:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数可以通过以下图形进行可视化：
- en: '![Figure 4.6: A visual representation of the loss as a function of an epoch
    in TensorBoard'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.6：TensorBoard 中表示损失与每个 epoch 的关系的可视化图'
- en: '](img/B16341_04_06.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_04_06.jpg)'
- en: 'Figure 4.6: A visual representation of the loss as a function of an epoch in
    TensorBoard'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6：TensorBoard 中表示损失与每个 epoch 的关系的可视化图
- en: You can see the architecture of the model in the `GRAPHS` tab. The architecture
    shows the input layer and output layer in the model, as well as the calculated
    loss. During the model-fitting process, the loss is calculated after each epoch
    and is displayed in TensorBoard in the `SCALARS` tab. The loss is that which is
    defined in the compilation process; so, in this case, the loss is the mean squared
    error. From TensorBoard, you can see that the mean squared error reduces after
    each epoch, indicating that the model is learning from the training data, updating
    the weights in order to reduce the total loss.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 `GRAPHS` 标签页中看到模型的架构。架构显示了模型的输入层和输出层，以及计算出的损失。在模型拟合过程中，损失在每个 epoch 后都会被计算，并显示在
    TensorBoard 的 `SCALARS` 标签页中。损失是在编译过程中定义的；在这个例子中，损失是均方误差。从 TensorBoard 中，你可以看到均方误差在每个
    epoch 后减少，这表明模型正在从训练数据中学习，并且正在更新权重以减少总损失。
- en: In this exercise, you have learned how to create, train, and evaluate an ANN
    with TensorFlow by using Keras layers. You recreated the linear regression algorithm
    by creating an ANN with an input layer and an output layer that has one unit for
    each output. Here, there were two outputs representing the maximum and minimum
    values of the temperature; thus, the output layer has two units.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，你学习了如何使用 Keras 层通过 TensorFlow 创建、训练和评估一个 ANN。你通过创建一个包含输入层和输出层的 ANN 重建了线性回归算法，每个输出都有一个单元。在这里，有两个输出，分别表示温度的最大值和最小值；因此，输出层有两个单元。
- en: In *Exercise 4.01*, *Creating an ANN with TensorFlow*, you created an ANN with
    only one layer containing weights and the output layer. This is an example of
    a **shallow neural network**. ANNs that have many hidden layers containing weights
    are called **deep neural networks**, and the process of training them is called
    **deep learning**. By increasing the number of layers and making the ANN deeper,
    the model becomes more flexible and will be able to model more complex functions.
    However, to gain this increase in flexibility, you need more training data and
    more computation power to train the model.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *练习 4.01*，*使用 TensorFlow 创建人工神经网络（ANN）* 中，你创建了一个仅包含一个层（带有权重）和输出层的 ANN。这是一个
    **浅层神经网络** 的例子。具有多个隐藏层且包含权重的 ANN 被称为 **深度神经网络**，而训练它们的过程称为 **深度学习**。通过增加层数并使 ANN
    更深，模型变得更加灵活，能够建模更复杂的函数。然而，为了获得这种灵活性，你需要更多的训练数据和更强的计算能力来训练模型。
- en: In the next exercise, you will create and train ANNs that have multiple hidden
    layers.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，你将创建并训练具有多个隐藏层的ANN。
- en: 'Exercise 4.03: Creating a Multi-Layer ANN with TensorFlow'
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.03：使用TensorFlow创建多层ANN
- en: In this exercise, you will create a multi-layer ANN using TensorFlow. This model
    will have four hidden layers. You will add multiple layers to the model and activation
    functions to the output of the layers. The first hidden layer will have `16` units,
    the second will have `8` units, and the third will have `4` units. The output
    layer will have `2` units. You will utilize the same dataset as in *Exercise 4.02*,
    *Creating a Linear Regression Model as an ANN with TensorFlow*, which describes
    the bias correction of air temperature forecasts for Seoul, South Korea. The exercise
    aims to predict the next maximum and minimum temperature given measurements of
    the prior timepoints and attributes of the weather station.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你将使用TensorFlow创建一个多层人工神经网络（ANN）。这个模型将有四个隐藏层。你将向模型中添加多个层，并为每一层的输出添加激活函数。第一个隐藏层将有`16`个单元，第二个隐藏层将有`8`个单元，第三个隐藏层将有`4`个单元。输出层将有`2`个单元。你将使用与*练习4.02*相同的数据集，*使用TensorFlow创建线性回归模型作为ANN*，该数据集描述了韩国首尔的气温预报偏差修正。该练习旨在根据先前时间点的测量值和气象站的属性，预测下一个最大和最小气温。
- en: 'Perform the following steps to complete this exercise:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成此练习：
- en: Open a new Jupyter notebook to implement this exercise.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Jupyter笔记本以实现此练习。
- en: 'In a new Jupyter Notebook cell, import the TensorFlow and pandas libraries:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新的Jupyter Notebook单元格中，导入TensorFlow和pandas库：
- en: '[PRE27]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Load in the dataset using the pandas `read_csv` function:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用pandas的`read_csv`函数加载数据集：
- en: '[PRE28]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Make sure you change the path (highlighted) to the CSV file based on its location
    on your system. If you're running the Jupyter notebook from the same directory
    where the CSV file is stored, you can run the preceding code without any modification.
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保你根据文件在系统上的位置更改路径（高亮显示的部分）。如果你是从与CSV文件相同的目录运行Jupyter笔记本，你可以不做任何修改直接运行前面的代码。
- en: 'Drop the `Date` column and drop any rows that have null values:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除`Date`列并删除任何包含空值的行：
- en: '[PRE29]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Create target and feature datasets:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建目标和特征数据集：
- en: '[PRE30]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Rescale the feature dataset:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新缩放特征数据集：
- en: '[PRE31]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Initialize a Keras model of the `Sequential` class:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个`Sequential`类的Keras模型：
- en: '[PRE32]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Add an input layer to the model using the model''s `add` method, and set `input_shape`
    to the number of columns in the feature dataset:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型的`add`方法为模型添加一个输入层，并将`input_shape`设置为特征数据集中的列数：
- en: '[PRE33]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Add three hidden layers and an output layer of the `Dense` class to the model.
    The first hidden layer will have `16` units, the second will have `8` units, and
    the third will have `4` units. Label the layers appropriately. The output layer
    will have two units to match the target variable that has two columns:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向模型中添加三个隐藏层和一个`Dense`类的输出层。第一个隐藏层将有`16`个单元，第二个隐藏层将有`8`个单元，第三个隐藏层将有`4`个单元。为各个层适当命名。输出层将有两个单元，以匹配具有两列的目标变量：
- en: '[PRE34]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Compile the model with an RMSprop optimizer and mean squared error loss:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用RMSprop优化器和均方误差损失编译模型：
- en: '[PRE35]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Add a callback for TensorBoard:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为TensorBoard添加一个回调：
- en: '[PRE36]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Fit the model to the training data for `50` epochs and add a validation split
    equal to 20%:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据，训练`50`个周期，并添加一个验证拆分，比例为20%：
- en: '[PRE37]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'You should get the following output:'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 4.7: The output of the fitting process showing the epoch, training
    time per sample, and loss after each epoch](img/B16341_04_07.jpg)'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 4.7：拟合过程的输出，显示每个周期、每个样本的训练时间以及每个周期后的损失](img/B16341_04_07.jpg)'
- en: 'Figure 4.7: The output of the fitting process showing the epoch, training time
    per sample, and loss after each epoch'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.7：拟合过程的输出，显示每个周期、每个样本的训练时间以及每个周期后的损失
- en: 'Evaluate the model on the training data:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据上评估模型：
- en: '[PRE38]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This will display the following result:'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将显示以下结果：
- en: '[PRE39]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'View the model architecture and model-fitting process in TensorBoard:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在TensorBoard中查看模型架构和模型拟合过程：
- en: '[PRE40]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'You should get something like the following:'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到如下所示的结果：
- en: '![Figure 4.8: A visual representation of the model architecture in TensorBoard'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.8：TensorBoard中模型架构的可视化表示'
- en: '](img/B16341_04_08.jpg)'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_04_08.jpg)'
- en: 'Figure 4.8: A visual representation of the model architecture in TensorBoard'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8：TensorBoard中模型架构的可视化表示
- en: 'You can visualize the loss function as shown in the following screenshot:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以可视化损失函数，如下截图所示：
- en: '![Figure 4.9: A visual representation of the loss as a function of an epoch
    in TensorBoard'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.9：在TensorBoard中显示的损失与epoch的关系图'
- en: on the training and validation split
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练和验证集划分上
- en: '](img/B16341_04_09.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_04_09.jpg)'
- en: 'Figure 4.9: A visual representation of the loss as a function of an epoch in
    TensorBoard on the training and validation split'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.9：在训练和验证集划分上，损失随epoch变化的可视化表示
- en: The network architecture shows the input layer and the four hidden layers of
    the model as well as the calculated loss at the end. During the model-fitting
    process, the loss is calculated after each epoch and is displayed in TensorBoard
    in the `SCALARS` tab. Here, the loss is the mean squared error. From TensorBoard,
    you can see that the mean squared error reduces on the training set (the orange
    line) and the validation set (the blue line), after each epoch, indicating that
    the model is learning effectively from the training data.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 网络架构显示了模型的输入层和四个隐藏层，以及最终计算的损失。在模型拟合过程中，每个epoch后都会计算损失，并显示在TensorBoard的`SCALARS`选项卡中。在这里，损失是均方误差。从TensorBoard中，你可以看到每个epoch后，训练集（橙色线）和验证集（蓝色线）的均方误差在逐渐减少，表明模型正在有效地从训练数据中学习。
- en: In this exercise, you have created an ANN with multiple hidden layers. The loss
    you obtained was lower than that achieved using linear regression, which demonstrates
    the power of ANNs. With some tuning to the hyperparameters (such as varying the
    number of layers, the number of units within each layer, adding activation functions,
    and changing the loss and optimizer), the loss could be even lower. In the next
    activity, you will put your model-building skills into action on a new dataset.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，你已经创建了一个具有多个隐藏层的ANN。你获得的损失比使用线性回归时的损失要低，这展示了ANN的强大能力。通过调整超参数（例如，改变层数、每层的单元数、添加激活函数以及改变损失和优化器），损失可能会更低。在下一次活动中，你将把你的模型构建技能应用到一个新的数据集上。
- en: 'Activity 4.01: Creating a Multi-Layer ANN with TensorFlow'
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 4.01：使用TensorFlow创建多层感知器（ANN）
- en: The feature dataset, `superconductivity.csv`, contains the properties of superconductors
    including the atomic mass of the material and its density. Importantly, the dataset
    also contains the critical temperature of the material, which is the temperature
    at which the material exhibits superconductive properties. In this activity, you
    are tasked with finding the critical temperature of the material or the temperature
    at which the material gains superconductive properties.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 特征数据集`superconductivity.csv`包含超导体的属性，包括材料的原子质量和密度。重要的是，数据集还包含材料的临界温度，即材料表现出超导特性的温度。在本次活动中，你的任务是找出材料的临界温度，或者说材料获得超导特性的温度。
- en: Note
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `superconductivity.csv` file can be found here: [https://packt.link/sOCPh](https://packt.link/sOCPh).'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`superconductivity.csv`文件可以在这里找到：[https://packt.link/sOCPh](https://packt.link/sOCPh)。'
- en: 'Perform the following steps to complete this activity:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤完成本次活动：
- en: Open a new Jupyter notebook to implement this activity.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Jupyter笔记本来实现本次活动。
- en: Import the TensorFlow and pandas libraries.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入TensorFlow和pandas库。
- en: Load in the `superconductivity.csv` dataset.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载`superconductivity.csv`数据集。
- en: Drop any rows that have null values.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除包含空值的行。
- en: Set the target as the `critical_temp` column and the feature dataset as the
    remaining columns.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将目标设置为`critical_temp`列，将特征数据集设置为其余列。
- en: Rescale the feature dataset using a standard scaler.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用标准缩放器对特征数据集进行缩放。
- en: Initialize a model of the Keras `Sequential` class.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个Keras `Sequential`类的模型。
- en: Add an input layer, four hidden layers of sizes `64`, `32`, `16`, and `8`, and
    an output layer of size `1` to the model. Add a ReLU activation function to the
    first hidden layer.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向模型添加一个输入层，四个隐藏层，大小分别为`64`、`32`、`16`和`8`，以及一个大小为`1`的输出层。为第一个隐藏层添加ReLU激活函数。
- en: Compile the model with an RMSprop optimizer with a learning rate equal to `0.001`
    and the mean squared error for the loss.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用RMSprop优化器编译模型，学习率为`0.001`，并使用均方误差作为损失函数。
- en: Add a callback to write logs to TensorBoard.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加回调函数，将日志写入TensorBoard。
- en: Fit the model to the training data for `100` epochs, with a batch size equal
    to `32` and a validation split equal to 20%.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据，训练`100`个epochs，批量大小为`32`，验证集划分比例为20%。
- en: Evaluate the model on the training data.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据上评估模型。
- en: View the model architecture in TensorBoard.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在TensorBoard中查看模型架构。
- en: 'You should get an output like the following:'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到类似以下的输出：
- en: '![Figure 4.10: A visual representation of the model architecture in TensorBoard'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.10：在 TensorBoard 中，模型架构的可视化表示'
- en: '](img/B16341_04_10.jpg)'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_04_10.jpg)'
- en: 'Figure 4.10: A visual representation of the model architecture in TensorBoard'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.10：在 TensorBoard 中，模型架构的可视化表示
- en: 'Visualize the model-fitting process in TensorBoard. You should get the following output:![Figure
    4.11: A visual representation of the loss as a function of an epoch on the training
    and validation split in TensorBoard'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 TensorBoard 中可视化模型拟合过程。你应该会得到如下输出：![图 4.11：在 TensorBoard 中，损失随训练和验证拆分的轮次变化的可视化表示
- en: '](img/B16341_04_11.jpg)'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_04_11.jpg)'
- en: 'Figure 4.11: A visual representation of the loss as a function of an epoch
    on the training and validation split in TensorBoard'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.11：在 TensorBoard 中，损失随训练和验证拆分的轮次变化的可视化表示
- en: Note
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor262).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以通过[此链接](B16341_Solution_ePub.xhtml#_idTextAnchor262)找到。
- en: In the next section, you will explore classification models, which attempt to
    classify data into distinct classes. You will begin with binary classification
    models that classify data into just two classes. This is the simplest form of
    a classification model. Once binary classifiers are mastered, more complicated
    models can be tackled, such as multi-label and multi-class classification.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，你将探索分类模型，这些模型尝试将数据分类为不同的类别。你将从二分类模型开始，它将数据分类为仅两个类别。这是最简单的分类模型形式。一旦掌握了二分类器，就可以挑战更复杂的模型，如多标签分类和多类分类。
- en: Classification Models
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类模型
- en: The goal of classification models is to classify data into distinct classes.
    For example, a spam filter is a classification model that aims to classify emails
    into "spam" (referring to unsolicited and unwanted email) or "ham" (a legitimate
    email). Spam filters are an example of a binary classifier since there are two
    classes. The input to the filter may include the content of the email, the email
    address of the sender, and the subject line, among other features, and the output
    will be the predicted class, `spam` or `ham`. Classification models can classify
    data into more than two distinct classes (known as **multi-class classification**)
    or classify data with multiple positive labels (known as **multi-label classification**).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型的目标是将数据分类到不同的类别中。例如，垃圾邮件过滤器就是一个分类模型，它旨在将电子邮件分类为“垃圾邮件”（指未经请求的、不需要的邮件）或“正常邮件”（合法邮件）。垃圾邮件过滤器是一个二分类模型的例子，因为它有两个类别。输入到过滤器的内容可能包括电子邮件的内容、发件人的电子邮件地址和主题行等特征，输出将是预测的类别，`垃圾邮件`或`正常邮件`。分类模型可以将数据分类为两个以上的类别（称为**多类分类**），或者对数据进行多个正标签的分类（称为**多标签分类**）。
- en: There are several different algorithms that can be used for classification tasks.
    Some popular ones include logistic regression, decision trees, and ANNs. ANNs
    are a great choice for classification models since they can learn complex relationships
    between the features and the target, and results can be achieved with the appropriate
    activation function on the output layer of the ANN.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种不同的算法可以用于分类任务。一些流行的算法包括逻辑回归、决策树和人工神经网络（ANN）。ANN 是分类模型的一个不错选择，因为它们能够学习特征与目标之间的复杂关系，并且通过在
    ANN 输出层应用适当的激活函数可以获得结果。
- en: A common activation function to use for classification models is the sigmoid
    function, which is the same function used in logistic regression. In fact, a logistic
    regression model can be created by building an ANN with a single layer with one
    unit and a sigmoid activation function. The sigmoid function is a transformation
    in which the input is any real value, and the output is a number strictly between
    `0` and `1`. A visual representation is shown in the following figure.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的分类模型激活函数是 sigmoid 函数，它与逻辑回归中使用的函数相同。事实上，可以通过构建一个具有单层、一个单元和 sigmoid 激活函数的
    ANN 来创建一个逻辑回归模型。Sigmoid 函数是一种转换，其中输入是任意实数值，输出是一个严格介于 `0` 和 `1` 之间的数值。以下图示为例：
- en: 'The output of the sigmoid transformation can be interpreted as a probability
    of a value being in the positive class; a value closer to a value of `1` indicates
    a higher probability of being in the positive class:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid 转换的输出可以被解释为一个值属于正类的概率；接近 `1` 的值表示属于正类的概率较高：
- en: '![Figure 4.12: A visual representation of the sigmoid function'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.12：sigmoid 函数的可视化表示'
- en: '](img/B16341_04_12.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_04_12.jpg)'
- en: 'Figure 4.12: A visual representation of the sigmoid function'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.12：Sigmoid 函数的可视化表示
- en: After the sigmoid function has been applied, a threshold is applied, above which
    the data is classified as the positive class and below as the negative class.
    The default threshold for a sigmoid function is `0.5`, meaning that any value
    at or above `0.5` is classified as positive.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用了 sigmoid 函数后，会应用一个阈值，高于该阈值的数据将被归类为正类，低于该阈值的数据将被归类为负类。sigmoid 函数的默认阈值为 `0.5`，意味着任何值大于或等于
    `0.5` 的数据将被归类为正类。
- en: In the next exercise, you will create a logistic regression model with TensorFlow.
    You will achieve this by creating a single-layer ANN, the process of which is
    similar to that of the linear regression model in *Exercise 4.02*, *Creating a
    Linear Regression Model as an ANN with TensorFlow*. The difference is that you
    will add a sigmoid activation function to the output of the ANN. Another difference
    that separates the two exercises is the loss function that you will use to calculate
    the loss.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，你将使用 TensorFlow 创建一个逻辑回归模型。你将通过创建一个单层人工神经网络（ANN）来实现这一点，这一过程类似于 *练习 4.02*
    中的线性回归模型，*使用 TensorFlow 创建线性回归模型作为 ANN*。不同之处在于，你将在 ANN 的输出端添加一个 sigmoid 激活函数。另一个将这两个练习区分开的差异是你将使用不同的损失函数来计算损失。
- en: 'Exercise 4.04: Creating a Logistic Regression Model as an ANN with TensorFlow'
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 4.04：使用 TensorFlow 创建逻辑回归模型作为 ANN
- en: In this exercise, you will create a logistic regression model as an ANN using
    TensorFlow. The dataset, `qsar_androgen_receptor.csv`, is used to develop classification
    models for the discrimination of binder/non-binder molecules given various attributes
    of the molecules. Here, the molecule attributes represent the features of your
    dataset, and their binding properties represent the target variable, in which
    a positive value represents a binding molecule, and a negative value represents
    a non-binding molecule. You will create a logistic regression model to predict
    the binding properties of the molecule given attributes of the molecule provided
    in the dataset.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，你将使用 TensorFlow 将逻辑回归模型创建为 ANN。数据集 `qsar_androgen_receptor.csv` 用于开发分类模型，以区分具有不同分子属性的结合/非结合分子。在这里，分子属性代表数据集的特征，其结合属性代表目标变量，其中正值代表结合分子，负值代表非结合分子。你将创建一个逻辑回归模型，根据数据集中提供的分子属性预测分子的结合特性。
- en: Note
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `qsar_androgen_receptor.csv` file can be found here: [https://packt.link/hWvjc](https://packt.link/hWvjc).'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '`qsar_androgen_receptor.csv` 文件可以在这里找到：[https://packt.link/hWvjc](https://packt.link/hWvjc)。'
- en: 'Perform the following steps to complete this exercise:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤来完成本练习：
- en: Open a new Jupyter notebook to implement this exercise.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter notebook 来实现本练习。
- en: 'Import the TensorFlow and pandas libraries:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 TensorFlow 和 pandas 库：
- en: '[PRE41]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Load in the dataset using the pandas `read_csv` function:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 的 `read_csv` 函数加载数据集：
- en: '[PRE42]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Note
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Make sure you change the path (highlighted) to the CSV file based on its location
    on your system. If you're running the Jupyter notebook from the same directory
    where the CSV file is stored, you can run the preceding code without any modification.
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 确保根据 CSV 文件在系统上的位置更改路径（已突出显示）。如果你从存储 CSV 文件的同一目录运行 Jupyter notebook，则无需修改代码即可运行上述代码。
- en: 'Drop any rows that have null values:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 丢弃任何包含空值的行：
- en: '[PRE43]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Create target and feature datasets:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建目标和特征数据集：
- en: '[PRE44]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Initialize a Keras model of the `Sequential` class:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个 Keras `Sequential` 类的模型：
- en: '[PRE45]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Add an input layer to the model using the model''s `add` method and set `input_shape`
    to be the number of columns in the feature dataset:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型的 `add` 方法为模型添加输入层，并将 `input_shape` 设置为特征数据集中的列数：
- en: '[PRE46]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Add the output layer of the `Dense` class to the model with a size of `1`,
    representing the target variable:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `Dense` 类的输出层添加到模型中，大小为 `1`，表示目标变量：
- en: '[PRE47]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Compile the model with an RMSprop optimizer and binary cross-entropy for the
    loss, and compute the accuracy:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 RMSprop 优化器和二元交叉熵损失函数编译模型，并计算准确率：
- en: '[PRE48]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Create a TensorBoard callback:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 TensorBoard 回调：
- en: '[PRE49]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Fit the model to the training data for `50` epochs, adding the TensorBoard
    callback with a validation split of 20%:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过训练数据训练模型 `50` 个 epoch，并添加 TensorBoard 回调，验证集比例为 20%：
- en: '[PRE50]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Your output should be similar to the following figure:'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的输出应该类似于下图：
- en: '![Figure 4.13: The output of the fitting process showing the epoch, training
    time per sample, and loss after each epoch'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.13：拟合过程的输出，显示了每个 epoch 后的 epoch 数、每个样本的训练时间和损失'
- en: '](img/B16341_04_13.jpg)'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_04_13.jpg)'
- en: 'Figure 4.13: The output of the fitting process showing the epoch, training
    time per sample, and loss after each epoch'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.13：拟合过程的输出，显示每个 epoch、每个样本的训练时间，以及每个 epoch 后的损失
- en: 'Evaluate the model on the training data:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据上评估模型：
- en: '[PRE51]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'You should get output something like the following:'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到类似如下的输出：
- en: '[PRE52]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Visualize the model-fitting process in TensorBoard by calling the following
    command on the command line:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过在命令行中调用以下命令，在 TensorBoard 中可视化模型拟合过程：
- en: '[PRE53]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'You should get a screen similar to the following in the browser:'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该在浏览器中看到类似如下的界面：
- en: '![Figure 4.14: A visual representation of the model architecture in TensorBoard'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.14：在 TensorBoard 中的模型架构的可视化表示'
- en: '](img/B16341_04_14.jpg)'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_04_14.jpg)'
- en: 'Figure 4.14: A visual representation of the model architecture in TensorBoard'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.14：在 TensorBoard 中的模型架构的可视化表示
- en: 'The loss function can be represented as follows:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数可以表示为如下形式：
- en: '![Figure 4.15: A visual representation of the loss and accuracy as a function
    of an epoch evaluated on the training and validation split in TensorBoard'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.15：在 TensorBoard 中评估的训练和验证分割上，以一个 epoch 为函数的损失和准确度的可视化表示'
- en: '](img/B16341_04_15.jpg)'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_04_15.jpg)'
- en: 'Figure 4.15: A visual representation of the loss and accuracy as a function
    of an epoch evaluated on the training and validation split in TensorBoard'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.15：在 TensorBoard 中评估的训练和验证分割上，以一个 epoch 为函数的损失和准确度的可视化表示
- en: You can see from TensorBoard that, with the addition of the `metrics` argument
    that was added in the model compilation process, there is an additional node in
    the architecture for the calculation of the accuracy metric. There is also an
    additional chart in the `SCALARS` tab showing the accuracy metric as a function
    of the epoch for the training and validation split.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 从 TensorBoard 中可以看到，通过在模型编译过程中添加 `metrics` 参数，模型架构中有一个额外的节点用于计算准确度指标。此外，在 `SCALARS`
    标签页中，还显示了训练和验证分割的准确度指标，作为一个 epoch 的函数。
- en: You can see from the charts that, for the training set, the accuracy increases,
    and the loss decreases over time, which is a positive indication that the model
    is learning. However, on the validation split, the accuracy begins to decrease,
    and the loss begins to increase, which is a sign that the model may be overfitting
    to the training data.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中可以看出，对于训练集，准确度随着时间的推移增加，损失减少，这表明模型正在学习。然而，在验证集上，准确度开始下降，损失开始增加，这表明模型可能正在过拟合训练数据。
- en: In this exercise, you have learned how to build a classification model to discriminate
    between the binding properties of various molecules based on their other molecular
    attributes. The classification model was equivalent to a logistic regression model
    since it had only one layer and was preceded by a sigmoid activation function.
    With only one layer, there is a weight for each input feature and a single value
    for the bias. The sigmoid activation function transforms the output of the layer
    into a value between `0` and `1`, which is then rounded to represent your two
    classes. `0.5` and above represents one class, the molecule with binding properties,
    and below `0.5` represents the other class, molecules with non-binding properties.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你学会了如何构建一个分类模型，用于区分不同分子在其其他分子属性基础上的结合特性。该分类模型等同于逻辑回归模型，因为它只有一层，并且之前有一个
    sigmoid 激活函数。由于只有一层，每个输入特征都有一个权重，并且偏置只有一个值。sigmoid 激活函数将该层的输出转换为介于 `0` 和 `1` 之间的值，然后通过四舍五入表示你的两类。`0.5`
    及以上代表一类，具有结合特性的分子，而低于 `0.5` 代表另一类，即没有结合特性的分子。
- en: The next activity will summarize your learning in this chapter by combining
    your knowledge of creating multi-layer ANNs as you accomplished in *Exercise 4.03*,
    *Creating a Multi-Layer ANN with TensorFlow*, and *Activity 4.01*, *Creating a
    Multi-Layer ANN with TensorFlow*, with your knowledge of creating classification
    models from *Exercise 4.04*, *Creating a Logistic Regression Model as an ANN with
    TensorFlow*. You will use the same dataset as in the preceding activity but change
    the target variable to make it more suitable for a classification task.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的活动将通过结合你在*练习 4.03*（*使用 TensorFlow 创建多层感知机*）、*活动 4.01*（*使用 TensorFlow 创建多层感知机*）中学到的创建多层人工神经网络（ANN）的知识，以及你在*练习
    4.04*（*使用 TensorFlow 创建逻辑回归模型作为 ANN*）中学到的创建分类模型的知识，来总结你在本章的学习。你将使用与前一个活动相同的数据集，但会改变目标变量，使其更适合分类任务。
- en: 'Activity 4.02: Creating a Multi-Layer Classification ANN with TensorFlow'
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 4.02：使用 TensorFlow 创建多层分类 ANN
- en: The feature dataset, `superconductivity.csv`, contains the properties of superconductors
    including the atomic mass of the material and its density. Importantly, the dataset
    also contains the critical temperature of the material, which is the temperature
    at which the material exhibits superconductive properties. You are required to
    determine which superconductors will express superconductive properties above
    the boiling point of nitrogen (77.36 K), thereby allowing superconductivity using
    liquid nitrogen, which is readily available. Your target variable will have a
    `true` value when the critical temperature is above 77.36 K and `false` below,
    indicating whether the material expresses superconductive properties above the
    boiling point of nitrogen.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 特征数据集`superconductivity.csv`包含超导体的属性，包括材料的原子质量和密度。重要的是，数据集还包含材料的临界温度，即材料展现超导性特性的温度。你需要确定哪些超导体在氮气的沸点（77.36
    K）以上展现超导性，从而使得可以使用易得的液氮进行超导性实验。目标变量将在临界温度高于77.36 K时为`true`，低于该温度时为`false`，表示材料是否在氮气的沸点以上展现超导性。
- en: Note
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 注意事项
- en: 'The `superconductivity.csv` file can be found here: [http://packt.link/sOCPh](http://packt.link/sOCPh).'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '`superconductivity.csv` 文件可以在此找到：[http://packt.link/sOCPh](http://packt.link/sOCPh)。'
- en: 'Perform the following steps to complete this activity:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤来完成此活动：
- en: Open a Jupyter notebook to complete the activity.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个 Jupyter Notebook 来完成活动。
- en: Import the TensorFlow and pandas libraries.
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 TensorFlow 和 pandas 库。
- en: Load in the `superconductivity.csv` dataset.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载 `superconductivity.csv` 数据集。
- en: Drop any rows that have null values.
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除所有包含空值的行。
- en: Set the target values to `true` when values of the `critical_temp` column are
    above `77.36` and `false` when below. The feature dataset is the remaining columns
    in the dataset.
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当 `critical_temp` 列的值高于 `77.36` 时，将目标值设置为 `true`，低于时设置为 `false`。特征数据集是数据集中的其余列。
- en: Rescale the feature dataset using a standard scaler.
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用标准化缩放器对特征数据集进行重新缩放。
- en: Initialize a model of the Keras `Sequential` class.
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个 Keras `Sequential` 类的模型。
- en: Add an input layer, three hidden layers of sizes `32`, `16`, and `8`, and an
    output layer with a `sigmoid` activation function of size `1` to the model.
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向模型中添加一个输入层，三个隐藏层，大小分别为`32`、`16`、`8`，以及一个输出层，使用 `sigmoid` 激活函数，大小为`1`。
- en: Compile the model with an RMSprop optimizer with a learning rate equal to `0.0001`
    and binary cross-entropy for the loss and compute the accuracy metric.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 RMSprop 优化器编译模型，学习率为 `0.0001`，损失函数为二元交叉熵，并计算准确率指标。
- en: Add a callback to write logs to TensorBoard.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个回调函数，将日志写入 TensorBoard。
- en: Fit the model to the training data for `50` epochs and a validation split equal
    to 0%.
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据中，训练 `50` 个周期，验证集分割为 0%。
- en: Evaluate the model on the training data.
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据上评估模型。
- en: View the model architecture and model-fitting process in TensorBoard.
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 TensorBoard 中查看模型架构和模型拟合过程。
- en: Note
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意事项
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor263).
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以通过[此链接](B16341_Solution_ePub.xhtml#_idTextAnchor263)找到。
- en: In this section, you have begun your foray into building, training, and evaluating
    classification models using TensorFlow. You have seen that they are built in much
    the same way as ANNs for regression tasks with the primary difference being the
    activation function on the output layer.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你已经开始了使用 TensorFlow 构建、训练和评估分类模型的探索。你已经看到它们与回归任务的 ANN 构建方式非常相似，主要的区别在于输出层的激活函数。
- en: Summary
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you began your journey into creating ANNs in TensorFlow. You
    saw how simple it is to create regression and classification models by utilizing
    Keras layers. Keras layers are distinct classes that exist in a separate library
    that uses TensorFlow in the backend. Due to their popularity and ease of use,
    they are now included in TensorFlow and can be called in the same way as any other
    TensorFlow class.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你开始了在 TensorFlow 中创建人工神经网络（ANNs）的旅程。你了解了利用 Keras 层创建回归和分类模型是多么简单。Keras
    层是一个独立的类库，在后台使用 TensorFlow。由于其流行和易用性，它们现在已经包含在 TensorFlow 中，并可以像调用任何其他 TensorFlow
    类一样进行调用。
- en: You created ANNs with fully connected layers, varying layers, beginning with
    an ANN that resembles a linear regression algorithm, which is equivalent to a
    single-layer ANN. Then, you added layers to your ANN and added activation functions
    to the output of the layers. Activation functions can be used to determine whether
    a unit is fired or can be used to bind the value of the output from a given unit.
    Regression models aim to predict a continuous variable from the data provided.
    In the exercises and activities throughout this chapter, you attempted to predict
    the temperature in Seoul given data from weather stations, and the critical temperature
    of superconducting materials given various material properties.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 你创建了具有全连接层的人工神经网络（ANN），并且通过不同的层级进行变动，首先是一个类似于线性回归算法的ANN，这相当于一个单层ANN。然后，你向ANN中添加了更多层，并在各层的输出上添加了激活函数。激活函数可以用来判断某个单元是否激活，或者用来绑定某个单元输出的值。回归模型的目标是根据提供的数据预测一个连续变量。在本章的练习和活动中，你尝试预测了首尔的温度，给定来自气象站的数据，并预测了超导材料的临界温度，基于不同的材料特性。
- en: Finally, you explored classification models, which aim to classify data into
    distinct classes. These models are similar to regression models in the way they
    are set up; however, an activation is used on the final output to bind the output
    values between two numbers that represent whether or not the data point is classified
    into the class. You began with binary classification models, which aim to classify
    the data into two classes, and demonstrated the concept of binary classification
    with an exercise in which you classified molecules into classes that represent
    their binding properties based on other attributes of the molecules' properties.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你探讨了分类模型，这些模型旨在将数据分类到不同的类别中。这些模型与回归模型在设置方式上相似；然而，在最终输出上使用激活函数，将输出值限制在两个数字之间，这两个数字表示数据点是否被分类到某个类别中。你从二分类模型开始，这些模型旨在将数据分为两个类别，并通过一个练习演示了二分类的概念，在该练习中，你根据分子其他属性的特征将分子分类到代表其结合特性的类别中。
- en: In the next chapter, you will explore classification models in more depth. You
    will learn some of the intricacies and capabilities of classification models,
    including how to classify data that has more than two distinct classes (known
    as multi-class classification), and whether data points can have more than one
    positive label (known as multi-label classification). You will address how to
    structure the architecture to create these models, the appropriate loss functions
    to use when training, and the relevant metrics to calculate to understand whether
    models are performing well.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，你将更深入地探讨分类模型。你将学习一些分类模型的细节和功能，包括如何对具有多个类别的数据进行分类（即多类分类），以及数据点是否可以有多个正标签（即多标签分类）。你将探讨如何构建架构来创建这些模型，训练时使用的适当损失函数，以及如何计算相关的度量指标来评估模型的表现。
