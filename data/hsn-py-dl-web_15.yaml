- en: DIY - A Web DL Production Environment
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DIY - 一个Web DL生产环境
- en: In previous chapters, we saw how to use some notable **Deep Learning** (**DL**)
    platforms, such as **Amazon Web Services** (**AWS**), **Google Cloud Platform**
    (**GCP**), and Microsoft Azure, to enable DL in our web applications. We then
    saw how to make websites secure using DL. However, in production, the challenge
    is often not just building the predictive model—the real problems arise when you
    want to update a model that is already sending responses to users. How much time
    and business can you lose in the 30 seconds or 1 minute that it may take to replace
    the model file? What if there are models customized for each user? That might
    even mean billions of models for a platform such as Facebook.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们看到如何使用一些著名的**深度学习**（**DL**）平台，如**亚马逊网络服务**（**AWS**）、**谷歌云平台**（**GCP**）和微软Azure，在我们的Web应用中实现DL。接着，我们了解了如何使用DL使网站变得更加安全。然而，在生产环境中，挑战通常不仅仅是构建预测模型——真正的问题出现在你想要更新一个已经向用户发送响应的模型时。替换模型文件可能需要30秒或1分钟，那么你可能会损失多少时间和业务？如果每个用户都有定制的模型呢？这甚至可能意味着像Facebook这样的平台需要数十亿个模型。
- en: You need to have definite solutions for updating models in production. Also,
    since the ingested data may not be in the format that the training is performed
    in, you need to define flows of data, such that they are morphed in a seamless
    manner for usage.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要为生产环境中的模型更新制定明确的解决方案。此外，由于输入的数据可能不是训练时所用格式，你需要定义数据流，使其无缝地转换为可用格式。
- en: In this chapter, we will discuss the methods by which we update models in production
    and the thought that goes into choosing each method. We will begin with a brief
    overview and then demonstrate some famous tools for creating DL data flows. Finally,
    we will implement our own demonstration of online learning or incremental learning
    to establish a method for updating a model in production.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章节中，我们将讨论在生产环境中更新模型的方法，以及选择每种方法时的思考过程。我们将从简要概述开始，然后展示一些著名的工具，用于创建DL数据流。最后，我们将实现自己的在线学习或增量学习演示，以建立一种在生产环境中更新模型的方法。
- en: 'We will be covering the following topics in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节将涵盖以下主题：
- en: An overview of DL in production methods
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产中深度学习方法概览
- en: Popular tools for deploying ML in production
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生产中部署ML的流行工具
- en: Implementing a demonstration DL web production environment
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现一个演示型DL Web生产环境
- en: Deploying the project to Heroku
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将项目部署到Heroku
- en: Security, monitoring, and performance optimizations
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全性、监控和性能优化
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You can access the code for this chapter at [https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web/tree/master/Chapter11](https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web/tree/master/Chapter11).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web/tree/master/Chapter11](https://github.com/PacktPublishing/Hands-On-Python-Deep-Learning-for-Web/tree/master/Chapter11)访问本章节的代码。
- en: 'You''ll need the following software to run the code used in this chapter:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要以下软件来运行本章节中的代码：
- en: Python 3.6+
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3.6+
- en: Flask 1.1.12+
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flask 1.1.12+
- en: All other installations will be made during the course of this chapter.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所有其他安装将在本章节中完成。
- en: An overview of DL in production methods
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生产中深度学习方法概览
- en: Be it DL or classic **Machine Learning** (**ML**), when it comes to using models
    in production, things can get challenging. The main reason is that data fuels
    ML and data can change over time. When an ML model is deployed in production,
    it is re-trained at certain intervals as the data keeps changing over time. Therefore,
    re-training ML is not a luxury but a necessity when you are thinking of production-based
    purposes. DL is only a sub-field of ML and it is no exception to the previous
    statements. There are two popular methods that ML models are trained on—batch
    learning and online learning, especially when they are in production.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是**深度学习**（**DL**）还是经典的**机器学习**（**ML**），在生产中使用模型时都会面临挑战。主要原因是数据驱动着ML，而数据随着时间的推移可能会发生变化。当ML模型部署到生产环境中时，随着数据不断变化，模型需要在特定的时间间隔内重新训练。因此，在考虑生产应用时，重新训练ML不仅仅是一种奢侈，而是一种必要性。DL只是ML的一个子领域，因此它也不例外。ML模型的训练有两种常见方法——批量学习和在线学习，尤其是在生产环境中。
- en: We will be discussing online learning in the next section. For this section,
    let's introduce ourselves to the concept of batch learning. In batch learning,
    we start by training an ML model on a specific chunk of data and when the model
    is done training on that chunk, it is supplied with the next chunk of data and
    this process continues until all the chunks are exhausted. These chunks are referred
    to as batches.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中讨论在线学习。在本节中，让我们先介绍一下批量学习的概念。在批量学习中，我们首先在一块特定的数据上训练机器学习模型，当模型完成该块数据的训练后，便会输入下一块数据，并继续这个过程，直到所有数据块都被用完。这些数据块被称为批次。
- en: In real-life projects, you will be dealing with large volumes of data all the
    time. It would not be ideal to fit those datasets in memory at once. Batch learning
    comes to our aid in situations such as this one. There are disadvantages to using
    batch learning and we will get to them in the next section. You may wonder (or
    may not, as well), but yes, we perform batch learning whenever we train a neural
    network in this book.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际项目中，你会一直处理大量数据。将这些数据集一次性加载到内存中并不是理想的做法。批量学习在这种情况下就能派上用场。使用批量学习有其缺点，我们将在下一节讨论这些缺点。你可能会好奇（或者可能不会），但的确，在本书中，我们每次训练神经网络时都会进行批量学习。
- en: Just like training, the concepts of batches can be applied to serving ML models,
    as well. Serving ML models here means using machine models to make predictions
    on unseen data points. This is also known as inference. Now, model serving can
    be of two types—online serving, where the prediction needs to be made as soon
    as the model is met with the data point(s) (we cannot afford latency here), and
    offline serving, where a batch of data points is first gathered and the batch
    is run through the model to get predictions. Note that in the second case, we
    can opt in for a bit of latency.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 和训练一样，批次的概念也可以应用于服务机器学习（ML）模型。这里所说的“服务”机器学习模型，指的是使用机器模型对未见过的数据点进行预测。这也被称为推理。现在，模型服务可以分为两种类型——在线服务，即模型一旦接触到数据点就需要立即做出预测（在这里我们无法容忍延迟），以及离线服务，即先收集一批数据点，再通过模型对这批数据点进行预测。在第二种情况下，我们可以容忍一些延迟。
- en: Note that there are several engineering aspects as well that are directly attached
    to production ML systems. Discussing them is beyond the scope of this book, but
    you are encouraged to check online for courses by the GCP team.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，还有一些与生产机器学习系统直接相关的工程方面。讨论这些内容超出了本书的范围，但我们鼓励你查阅GCP团队的在线课程。
- en: 'Let''s try to summarize and further understand the preceding discussion with
    the following diagram:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试通过以下图表总结并进一步理解之前的讨论：
- en: '![](img/95a14b78-836f-49f9-9709-4c20f0a2152e.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/95a14b78-836f-49f9-9709-4c20f0a2152e.png)'
- en: This diagram depicts the requirements of your AI backend and the various parameters
    that can affect the choice of the solution that you make. We will discuss all
    of the aspects and choices available, as in this diagram, in the following section.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 该图表描述了你的AI后台需求及可能影响解决方案选择的各种参数。我们将在下一节中讨论与此图表相关的所有方面和可用的选择。
- en: 'So, we have four major types of solutions that you may usually find in implementations
    of DL in production:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们有四种主要的解决方案类型，通常可以在深度学习的生产环境中看到它们：
- en: A web API service
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个Web API服务
- en: Online learning
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线学习
- en: Batch forecasting
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量预测
- en: Auto ML
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化机器学习（Auto ML）
- en: Let's look at each of them in detail.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细地看一下每一种方法。
- en: A web API service
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个Web API服务
- en: We have a model that is trained by a separate script on the backend and is stored
    as a model and then deployed as an API-based service. Here, we're looking at a
    solution that produces results *on-demand* but the training occurs offline (not
    in the execution span of the portion of code responsible for responding to the
    client queries). Web APIs respond to a single query at a time and yield singular
    results.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个由后台独立脚本训练的模型，它被存储为一个模型并作为基于API的服务进行部署。在这里，我们看到的是一种按需生成结果的解决方案，但训练发生在离线（即不在负责响应客户端查询的代码部分的执行期间）。Web
    API一次响应一个查询，并产生单一的结果。
- en: This is by far the most commonly used method for deploying DL in production
    since it allows accurate training performed offline by data scientists and a short
    deployment script to create an API. In this book, we have mostly carried out deployments
    of this kind.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，这是在生产环境中部署深度学习（DL）最常用的方法，因为它允许数据科学家离线进行准确的训练，并且通过一个简短的部署脚本来创建API。在本书中，我们大多数情况下进行了这种类型的部署。
- en: Online learning
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在线学习
- en: Another form of on-demand predictions via the backend is online learning. However,
    in this methodology, the learning happens during the execution of the server script
    and so the model keeps changing with every relevant query. While such a method
    is dynamic and unlikely to become stale, it is often less accurate than its static
    counterpart—web APIs. Online learning, too, yields a single result at a time.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过后端实现按需预测的另一种形式是在线学习。然而，在这种方法中，学习发生在服务器脚本的执行过程中，因此模型随着每个相关查询而不断变化。虽然这种方法是动态的，不容易过时，但它通常比其静态对手——Web
    API 更不准确。在线学习同样每次产生一个结果。
- en: In this chapter, we have demonstrated an example of online learning. We will
    discuss the tools that are helpful for online learning in the coming sections.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们展示了在线学习的一个示例。我们将在接下来的章节中讨论对在线学习有帮助的工具。
- en: Batch forecasting
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批量预测
- en: In this method, a number of predictions are made at once and stored on the server,
    ready to be fetched and used when the user needs them. However, as a static training
    method, this method allows training the model offline and so offers greater accuracy
    to the training, similar to web APIs.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，会一次性做出多个预测，并将其存储在服务器上，随时准备在用户需要时提取和使用。然而，作为一种静态训练方法，这种方法允许离线训练模型，因此提供更高的训练准确性，类似于
    Web API。
- en: In other words, batch forecasting can be understood as a batch version of web
    APIs; however, the predictions are not served by an API. Rather, the predictions
    are stored and fetched from a database.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，批量预测可以理解为 Web API 的批量版本；然而，预测并不是通过 API 提供的，而是存储在数据库中并从中提取。
- en: Auto ML
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化机器学习（Auto ML）
- en: Making predictions is only one part of the entire process of having DL in production.
    A data scientist is also responsible for cleaning and organizing the data, creating
    a pipeline, and optimizations. Auto ML is a way of eliminating the need for such
    repetitive tasks.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 做出预测只是将深度学习（DL）应用于生产的整个过程中的一部分。数据科学家还负责清洗和整理数据，创建管道以及优化。自动化机器学习（Auto ML）是一种消除这些重复任务需求的方法。
- en: Auto ML is a batch forecasting method where the need for human intervention
    is removed. So, the data, as it comes, goes through a pipeline and the forecasts
    are regularly updated. So, this method provides more up-to-date predictions than
    the batch forecasting method.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化机器学习（Auto ML）是一种批量预测方法，消除了对人工干预的需求。因此，数据在到达时会经过一个管道，预测会定期更新。因此，这种方法比批量预测方法提供了更为及时的预测。
- en: Let's now discuss some tools for rapidly realizing some of the methods we have
    presented.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们讨论一些快速实现我们所展示的某些方法的工具。
- en: Popular tools for deploying ML in production
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署 ML 到生产环境中的流行工具
- en: In this section, we will be discussing some popular tools used for putting ML
    in production systems. The core utility provided by these tools is automating
    the learning-prediction-feedback pipeline and facilitating the monitoring of the
    model's quality and performance. While it is very much possible to create your
    own tools for this, it is highly recommended that you use any of the following
    tools, as per the requirements of your software.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论一些用于将机器学习（ML）应用于生产系统的流行工具。这些工具提供的核心功能是自动化学习-预测-反馈流程，并促进模型质量和性能的监控。虽然完全可以创建自己的工具来实现这些功能，但强烈推荐根据软件的需求使用以下任何一种工具。
- en: Let's begin by discussing `creme`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先讨论一下 `creme`。
- en: creme
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: creme
- en: '`creme` is a Python library that allows us to perform online learning efficiently.
    Before we look at `creme` in action, let''s have a brief discussion about online
    learning itself:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`creme` 是一个 Python 库，它使我们能够高效地进行在线学习。在我们实际操作 `creme` 之前，让我们简要讨论一下在线学习本身：'
- en: '![](img/adfb193f-163c-4f21-9dae-af3df778d861.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/adfb193f-163c-4f21-9dae-af3df778d861.png)'
- en: 'In online learning, ML models are trained on one instance at a time, instead
    of being trained on a batch of data (which is also known as batch learning). To
    be able to appreciate the use of online learning, it''s important to understand
    the cons of batch learning:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在在线学习中，ML 模型是逐个实例进行训练，而不是批量数据训练（这也被称为批量学习）。要理解在线学习的使用，首先要了解批量学习的缺点：
- en: In production, we need to re-train ML models on new data over time. Batch learning
    forces us to do this but this comes at a cost. The cost not only lies in computational
    resources but also the fact that the models are re-trained from scratch. Training
    models from scratch is not always useful in production environments.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在生产环境中，我们需要随着时间的推移在新数据上重新训练机器学习模型。批量学习迫使我们这样做，但这会带来成本。成本不仅体现在计算资源上，还体现在模型需要从头开始重新训练。重新从头训练模型在生产环境中并不总是有用的。
- en: The features and labels of data can change over time. Batch learning does not
    allow us to train ML models that can support dynamic features and labels.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据的特征和标签可能会随时间变化。批量学习不允许我们训练可以支持动态特征和标签的机器学习模型。
- en: 'This is exactly where we need to use online learning, which enables us to do
    the following:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是我们需要使用在线学习的地方，它使我们能够做到以下几点：
- en: Train ML models using only one instance at a time. So, we won't require a batch
    of data to train an ML model; it can be trained instantaneously using data as
    it becomes available.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用单个实例逐步训练机器学习模型。因此，我们无需一批数据来训练机器学习模型；可以在数据到达时即时训练模型。
- en: Train ML models with dynamic features and labels.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用动态特征和标签训练机器学习模型。
- en: 'Online learning has got several other names, but they all do the same thing:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在线学习有几个其他名称，但它们做的都是相同的事情：
- en: Incremental learning
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增量学习
- en: Sequential learning
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顺序学习
- en: Iterative learning
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代学习
- en: Out-of-core learning
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外部学习
- en: '`creme`, as mentioned earlier, is a Python library for performing online learning.
    It is an extremely useful thing to keep in your ML toolbox, especially when you
    are dealing with a production environment. `creme` is heavily inspired by scikit-learn
    (which is a very popular ML library in Python), which makes it very easy to use.
    To get a comprehensive introduction to `creme`, you are encouraged to check out
    the official GitHub repository for `creme` at [https://github.com/creme-ml/creme](https://github.com/creme-ml/creme).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`creme`是一个用于进行在线学习的Python库。在处理生产环境时，它是你机器学习工具箱中一个非常有用的工具。`creme`深受scikit-learn（一个非常流行的Python机器学习库）的启发，使得它非常易于使用。为了全面了解`creme`，建议你查看`creme`的官方GitHub仓库：[https://github.com/creme-ml/creme](https://github.com/creme-ml/creme)。
- en: 'Enough talking! Let''s go ahead and first install `creme`. It can be done by
    using the following command:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 够多的理论了！让我们先安装`creme`。可以使用以下命令完成：
- en: '[PRE0]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To get the latest version of `creme`, you can use the following commands:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取最新版本的`creme`，可以使用以下命令：
- en: '[PRE1]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s take a look at a quick example by following these steps:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下步骤来快速查看一个例子：
- en: 'We first make a few necessary imports from the `creme` module:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们首先从`creme`模块进行一些必要的导入：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Notice that the naming convention of `creme` is similar to that of the `sklearn`
    library for an easier migration experience.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`creme`的命名规范类似于`sklearn`库，便于迁移体验。
- en: 'We then fetch a dataset provided by the `creme` module itself to the data variable:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们从`creme`模块本身获取一个数据集，并将其赋值给变量data：
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We will be working on this dataset, which contains information about bike-ride
    sharing.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将处理一个包含共享骑行信息的数据集。
- en: While the dataset is included in the `creme` library, you can read more about
    it at [https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然数据集包含在`creme`库中，但你可以在[https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset](https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset)上阅读更多相关信息。
- en: 'Next, we build a pipeline using `creme`, as shown:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用`creme`构建一个管道，如下所示：
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Notice the use of the `|=` and `+=` operators. `creme` makes it possible to
    use these operators, which makes understanding the data pipeline very intuitive.
    We can obtain a detailed representation of the pipeline built in the previous
    code block by using the following command:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意`|=`和`+=`运算符的使用。`creme`使得这些运算符得以使用，这使得理解数据管道变得非常直观。我们可以通过使用以下命令，获取前一个代码块中构建的管道的详细表示：
- en: '[PRE5]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output of the previous command is as shown:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个命令的输出如下所示：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can also get a visual representation of this pipeline by using the following
    command:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过使用以下命令，获取该管道的可视化表示：
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This produces the following graph:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成以下图表：
- en: '![](img/385f0fc6-4b0a-46d6-8414-c73c8c3a4c38.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/385f0fc6-4b0a-46d6-8414-c73c8c3a4c38.png)'
- en: 'Finally, we run the training and obtain the scoring metric at an interval of
    every 30,000 row of the dataset. On the production server, this code will result
    in batch forecasting at every 1 minute:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们运行训练并每隔30,000行数据集计算一次评分指标。在生产服务器上，这段代码将在每分钟进行一次批量预测：
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: So, `creme` makes it very simple to create batch forecasting and online learning
    deployments in production with its lucid syntax and debugging facilities.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，`creme`通过其简洁的语法和调试功能，使得在生产环境中创建批量预测和在线学习部署变得非常简单。
- en: We'll now discuss another popular tool—Airflow.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来讨论另一个流行的工具——Airflow。
- en: Airflow
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Airflow
- en: As an effective ML practitioner, you will need to programmatically handle workflows
    such as the previous one and be able to automate them, as well. Airflow provides
    you with a platform to efficiently do this. This link—[https://airflow.apache.org](https://airflow.apache.org)—is
    an excerpt taken from Airflow's official website. Airflow is a platform used to
    programmatically author, schedule, and monitor workflows.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个有效的机器学习从业者，你需要通过编程的方式处理像上面那样的工作流，并且能够自动化它们。Airflow为你提供了一个平台，使得这一切变得高效。这个链接——[https://airflow.apache.org](https://airflow.apache.org)——摘自Airflow的官方网站。Airflow是一个用于以编程方式创建、调度和监控工作流的平台。
- en: The main advantage of this is that tasks represented on **Directed Acyclic Graphs**
    (**DAGs**) can easily be distributed across available resources (often known as
    workers). It also makes it easier to visualize your entire workflow and this turns
    out to be very helpful, especially when a workflow is very complicated. If you
    need a refresher on DAGs, the article at [https://cran.r-project.org/web/packages/ggdag/vignettes/intro-to-dags.html](https://cran.r-project.org/web/packages/ggdag/vignettes/intro-to-dags.html)
    can help. This will become much clearer when you see this implemented in a little
    while.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的主要优势是，**有向无环图**（**DAGs**）中表示的任务可以轻松地分配到可用资源（通常称为工作节点）上。它还使得可视化整个工作流变得更加容易，这对于工作流非常复杂时尤为有用。如果你需要复习DAGs的相关内容，可以参考这篇文章：[https://cran.r-project.org/web/packages/ggdag/vignettes/intro-to-dags.html](https://cran.r-project.org/web/packages/ggdag/vignettes/intro-to-dags.html)。当你看到实际的实现时，这一概念会变得更加清晰。
- en: 'When you are designing an ML workflow, you need to think of many different
    things, such as the following:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当你设计一个机器学习工作流时，需要考虑许多不同的因素，例如以下内容：
- en: The data collection pipeline
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据收集管道
- en: The data preprocessing pipeline
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据预处理管道
- en: Making the data available to the ML model
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使数据可供机器学习模型使用
- en: Training and evaluation pipelines for the ML model
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习模型的训练和评估管道
- en: The deployment of the model
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的部署
- en: Monitoring the model, along with other things
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控模型，以及其他事项
- en: 'For now, let''s go ahead and install Airflow by executing the following line:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们通过执行以下命令来安装Airflow：
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Although Airflow is Python-based, it is absolutely possible to use Airflow to
    define workflows that incorporate different languages for different tasks.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Airflow是基于Python的，但完全可以使用Airflow来定义包含不同任务语言的工作流。
- en: 'Once installed, you can invoke the admin panel of Airflow and view the list
    of DAGs on it, as well as manage them and trigger a lot of other useful functions,
    as shown:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，你可以调用Airflow的管理面板，查看其中DAG的列表，管理它们并触发其他许多有用的功能，如下所示：
- en: 'To do so, you must first initialize the database:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为此，你必须首先初始化数据库：
- en: '[PRE10]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You should see a number of tables being created on a `SQLite3` database. If
    successful, you will be able to start the web server by using the following command:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你应该能看到在`SQLite3`数据库上创建了多个表。如果成功，你将能够通过以下命令启动Web服务器：
- en: '[PRE11]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Open `http://localhost:8080` on your browser. You will be presented with a
    screen as in the following screenshot:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在浏览器中打开`http://localhost:8080`，你将看到如下截图所示的页面：
- en: '![](img/5f932f02-915b-4c68-84fc-1b54864cb4fe.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f932f02-915b-4c68-84fc-1b54864cb4fe.png)'
- en: A number of example DAGs are presented. You can try running them for a brief
    play!
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了多个示例DAG（有向无环图）。你可以尝试运行它们，快速体验一番！
- en: Let's now discuss a very popular tool called AutoML.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来讨论一个非常流行的工具——AutoML。
- en: AutoML
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AutoML
- en: DL or AI solutions are not limited to building cutting-edge accurate models
    in Jupyter Notebook when it comes to industrial usage. There are several steps
    in the formation of AI solutions, beginning with collecting raw data, converting
    the data into a format that can be used with predictive models, creating predictions,
    building an application around the model, and monitoring and updating the model
    in production. AutoML aims to automate this process by automating the pre-deployment
    tasks. Often, AutoML is mostly about orchestrating the data and Bayesian hyperparameter
    optimization. AutoML only sometimes means a fully automated learning pipeline.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在工业使用中，深度学习或人工智能解决方案不仅仅局限于在Jupyter Notebook中构建最先进的精确模型。形成AI解决方案有几个步骤，从收集原始数据、将数据转换为可用于预测模型的格式、创建预测、围绕模型构建应用程序，到在生产中监控和更新模型。AutoML旨在通过自动化部署前任务来自动化这一过程。通常，AutoML主要涉及数据编排和贝叶斯超参数优化。AutoML并不总是指完全自动化的学习管道。
- en: 'One famous library available for AutoML is provided by `H2O.ai` and it is called
    `H2O.AutoML`. To use it, we can install it using the following commands:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一个著名的AutoML库由`H2O.ai`提供，名为`H2O.AutoML`。要使用它，我们可以通过以下命令安装：
- en: '[PRE12]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`H2O.AutoML` is very simple to understand due to the similarity of its syntax
    with other popular ML libraries.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`H2O.AutoML`由于其语法与其他流行的机器学习库相似，因此非常容易理解。'
- en: Implementing a demonstration DL web environment
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现一个演示的深度学习Web环境
- en: We will now take a deep dive into building a sample production application that
    uses online learning on the backend. We will be creating an application that can
    predict heart diseases, based on the Cleveland dataset. We will then deploy this
    model to Heroku, which is a cloud container-based service. Finally, we will demonstrate
    the online learning feature of the application.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将深入研究如何构建一个使用在线学习作为后端的示例生产应用程序。我们将创建一个可以根据Cleveland数据集预测心脏病的应用程序。然后，我们将把这个模型部署到Heroku，它是一个基于云容器的服务。最后，我们将演示应用程序的在线学习功能。
- en: You can find out more about Heroku by going to [https://heroku.com](https://heroku.com).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过访问[https://heroku.com](https://heroku.com)了解更多关于Heroku的信息。
- en: 'Let''s list the steps that we will be covering:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们列出我们将要覆盖的步骤：
- en: Build a predictive model on Jupyter Notebook.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Jupyter Notebook上构建一个预测模型。
- en: Build a backend for the web application that predicts on the saved model.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为Web应用程序构建一个后端，用于对保存的模型进行预测。
- en: Build a frontend for the web application that invokes incremental learning on
    the model.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为Web应用程序构建一个前端，用于在模型上调用增量学习。
- en: Update the model on the server side incrementally.
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在服务器端逐步更新模型。
- en: Deploy the application to Heroku.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将应用程序部署到Heroku。
- en: We will begin with the zeroth step; that is, observing the dataset.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从零步骤开始；也就是观察数据集。
- en: 'The UCI Heart Disease dataset contains 303 samples, with 76 attributes in each.
    However, most of the research work on the dataset has been centered around a simplified
    version of the Cleveland dataset with 13 attributes, as defined here:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: UCI心脏病数据集包含303个样本，每个样本有76个属性。然而，大多数关于该数据集的研究工作集中在Cleveland数据集的简化版本上，该版本有13个属性，如下所示：
- en: Age
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年龄
- en: Sex
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性别
- en: 'Chest pain type:'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 胸痛类型：
- en: Typical angina
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 典型心绞痛
- en: Atypical angina
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非典型心绞痛
- en: Non-anginal pain
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非心绞痛性疼痛
- en: Asymptomatic
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无症状
- en: Resting blood pressure
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静息血压
- en: Serum cholesterol in mg/dl
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 血清胆固醇（mg/dl）
- en: Fasting blood sugar > 120 mg/dl
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空腹血糖 > 120 mg/dl
- en: 'Resting electrocardiographic results:'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静息心电图结果：
- en: Normal
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正常
- en: Having ST-T wave abnormality (T wave inversions and/or ST elevation or depression
    of > 0.05 mV)
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有ST-T波异常（T波倒置和/或ST段抬高或压低超过0.05 mV）
- en: Showing probable or definite left ventricular hypertrophy by Estes' criteria
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据Estes标准，显示可能或确诊的左心室肥大
- en: Maximum heart rate achieved
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 达到的最大心率
- en: Exercise-induced angina
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运动诱发的心绞痛
- en: Oldpeak = ST depression induced by exercise relative to rest
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oldpeak = 运动引起的ST压低与静息时相比
- en: The slope of the peak exercise ST segment
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 峰值运动ST段的坡度
- en: Number of major vessels (0-3) colored by fluoroscopy
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主要血管数（0-3），通过荧光透视着色
- en: 'Thal: 3 = normal; 6 = fixed defect; 7 = reversible defect'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Thal: 3 = 正常；6 = 固定缺陷；7 = 可逆缺陷'
- en: There will be a final column, which is the target we will be predicting. This
    will make the problem at hand a classification between normal and affected patients.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 将会有一个最终列，它是我们要预测的目标。这将使得当前问题成为对正常患者和受影响患者之间的分类。
- en: You can read more about the Cleveland dataset at [https://archive.ics.uci.edu/ml/datasets/Heart+Disease](https://archive.ics.uci.edu/ml/datasets/Heart+Disease).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://archive.ics.uci.edu/ml/datasets/Heart+Disease](https://archive.ics.uci.edu/ml/datasets/Heart+Disease)阅读更多关于Cleveland数据集的信息。
- en: Let's now begin building the heart disease detection model.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们开始构建心脏病检测模型。
- en: Building a predictive model
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建预测模型
- en: In this subsection, we will begin by building a simple neural network using
    Keras, which will classify, from a given input, the probability that a patient
    has heart disease.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一小节中，我们将首先使用Keras构建一个简单的神经网络，该网络将从给定的输入中分类预测患者是否患有心脏病的概率。
- en: Step 1 – Importing the necessary modules
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1步 – 导入必要的模块
- en: 'We begin by importing the required libraries:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先导入所需的库：
- en: '[PRE13]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We have imported the `pandas` and `numpy` modules. Along with these, we have
    imported the `train_test_split` method from the scikit-learn library to help us
    quickly split the dataset into training and testing parts.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经导入了`pandas`和`numpy`模块，并且还从scikit-learn库中导入了`train_test_split`方法，帮助我们快速将数据集拆分为训练集和测试集。
- en: Step 2 – Loading the dataset and observing
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2步 – 加载数据集并观察
- en: 'Let''s load the dataset, assuming it to be stored in a folder named `data`
    that is on the same directory level as that of the directory containing our Jupyter
    notebook:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 假设数据集存储在一个名为`data`的文件夹中，并且该文件夹与包含我们的Jupyter notebook的文件夹位于同一目录级别，我们将加载数据集：
- en: '[PRE14]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We''ll quickly observe the DataFrame to see whether all the columns have been
    imported correctly:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将快速观察DataFrame，查看所有列是否已正确导入：
- en: '[PRE15]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This produces the following output in the Jupyter notebook:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在Jupyter notebook中产生如下输出：
- en: '![](img/1f9f805b-e515-4714-9e23-d04c4b7fd49c.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1f9f805b-e515-4714-9e23-d04c4b7fd49c.png)'
- en: We can observe the 14 columns and see that they have been imported correctly.
    A basic **Exploratory Data Analysis** (**EDA**) would reveal that the dataset
    does not contain any missing values. However, the raw UCI Cleveland dataset does
    contain missing values contrary to the version we're using, which has been preprocessed
    and is readily available in this form on the internet. You can find a copy of
    it in the repository of this chapter on GitHub at [http://tiny.cc/HoPforDL-Ch-11](http://tiny.cc/HoPforDL-Ch-11).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以观察到14个列，并确认它们已经正确导入。一个基本的**探索性数据分析**（**EDA**）将揭示该数据集没有缺失值。然而，原始的UCI Cleveland数据集包含缺失值，这与我们使用的版本不同，后者已经过预处理并以这种形式在互联网上可以轻松获取。你可以在GitHub上本章的仓库中找到它，地址是[http://tiny.cc/HoPforDL-Ch-11](http://tiny.cc/HoPforDL-Ch-11)。
- en: Step 3 – Separating the target variable
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3步 – 分离目标变量
- en: 'We''ll now splice out the target variable from the dataset, as shown:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将从数据集中剔除目标变量，如下所示：
- en: '[PRE16]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Next, we will perform scaling on the features.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将对特征进行缩放。
- en: Step 4 – Performing scaling on the features
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4步 – 对特征进行缩放
- en: 'As you might have observed in the sample of the dataset in the preceding step,
    the values in the training columns are not in a common or comparable range. We
    will be performing scaling on the columns to bring them to a uniform range distribution,
    as shown:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在前一步中数据集的示例中所观察到的，训练列中的数值并不在统一的或可比较的范围内。我们将对这些列进行缩放，使它们达到一个统一的范围分布，如下所示：
- en: '[PRE17]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The target is in the range of `0` to `1` and so does not require scaling.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 目标变量的范围是`0`到`1`，因此不需要进行缩放。
- en: Step 5 – Splitting the dataset into test and train datasets
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5步 – 将数据集拆分为测试集和训练集
- en: 'We''ll then split the dataset into training and testing parts, using the following
    line of code:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将数据集拆分为训练部分和测试部分，使用以下代码行：
- en: '[PRE18]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We have allotted 20% of the dataset to testing purposes.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将20%的数据集分配用于测试。
- en: Step 6 – Creating a neural network object in sklearn
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6步 – 在sklearn中创建神经网络对象
- en: 'Next, we create an instance of the classifier model by instantiating a new
    object of the `MLPClassifier` object:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们通过实例化一个新的`MLPClassifier`对象来创建分类器模型的实例：
- en: '[PRE19]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We have arbitrarily set the maximum number of iterations to `200`. This may
    not be reached if the convergence happens earlier.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已将最大迭代次数随意设置为`200`。如果收敛发生得更早，可能不会达到这个次数。
- en: Step 7 – Performing the training
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7步 – 进行训练
- en: 'Finally, we perform the training and note the observed accuracy of the method:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们进行训练，并记录方法的观察准确率：
- en: '[PRE20]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output of the preceding block of code in Jupyter Notebook is as follows:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在Jupyter Notebook中，前一块代码的输出如下：
- en: '![](img/83f2a674-113d-4694-ba19-9ba8dc7cc57c.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](img/83f2a674-113d-4694-ba19-9ba8dc7cc57c.png)'
- en: We can see that after training on all of the 241 samples in the processed dataset,
    the accuracy is expected to reach 83.60%. Notice the `partial_fit` method in the
    preceding block of code. This is a method of the model that allows fitting a simple
    sample to the model. The more commonly used `fit` method is, in fact, a wrapper
    around the `partial_fit` method, iterating over the entire dataset and training
    one sample in each iteration. It is one of the most instrumental parts of our
    demonstration of incremental learning using the scikit-learn library.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在对所有241个处理过的样本进行训练后，模型的准确度预计将达到83.60%。注意前面代码块中的`partial_fit`方法。这是模型的一个方法，用于将一个简单的样本拟合到模型中。更常用的`fit`方法实际上是`partial_fit`方法的一个包装器，它遍历整个数据集并在每次迭代中训练一个样本。它是我们演示使用
    scikit-learn 库进行增量学习的最重要部分之一。
- en: 'To quickly see the format that the model provides an output in, we run the
    following block of code:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速查看模型输出的格式，我们运行以下代码块：
- en: '[PRE21]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following output is obtained:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是获得的输出：
- en: '![](img/7af1eb56-d3b4-4e26-a4fc-804077759dcd.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7af1eb56-d3b4-4e26-a4fc-804077759dcd.png)'
- en: Note that a sample with a predicted output of `0` means that the person does
    not have a heart disease, while a sample with an output of `1` means that the
    person is suffering from a heart disease.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，预测输出为`0`的样本表示此人没有心脏病，而输出为`1`的样本则表示此人患有心脏病。
- en: We will now begin to convert this Jupyter notebook into a script that can perform
    learning on-demand incrementally. However, we will first build the frontend of
    this project so that we can understand the requirements from the backend.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将开始将这个 Jupyter 笔记本转换成一个可以按需增量学习的脚本。不过，我们首先将构建该项目的前端，以便我们能从后端理解需求。
- en: Implementing the frontend
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现前端
- en: We will take a bottom-up approach here and design the frontend of our sample
    application first. This is merely done for the sake of understanding why we write
    a few methods in the backend script differently from how we did in previous chapters.
    You would obviously create the backend script first when developing the real application.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将采取自下而上的方法，首先设计我们示例应用程序的前端。这仅仅是为了理解为何我们在后端脚本中编写某些方法时与之前章节的做法不同。显然，在开发实际应用时你会首先创建后端脚本。
- en: We'll have a very stripped-down frontend, merely comprising a button that invokes
    incremental training of the application and a placeholder displaying the accuracy
    score of the model trained up to a given number of samples.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将有一个非常简化的前端，仅包含一个按钮，触发应用程序的增量训练，以及一个占位符，显示已训练至一定样本数量时的模型准确度。
- en: 'Let''s take a quick peek at what we are building:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速看一下我们将要构建的内容：
- en: '![](img/7e081a94-5c7d-4e85-a20a-e1576ec3cea9.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7e081a94-5c7d-4e85-a20a-e1576ec3cea9.png)'
- en: As you might interpret from the preceding screenshot of the application we will
    be building, we will have two buttons—one will add 25 samples from the training
    dataset to the partially trained model and the other will reset the training to
    0 samples (this is, actually, 1 sample in the implementation, to avoid common
    errors caused by 0; but this has minimal effect on the demonstration).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如你从我们将要构建的应用程序的前面截图中所见，我们将有两个按钮——一个按钮会将训练数据集中的25个样本添加到部分训练的模型中，另一个按钮会将训练重置为0个样本（实际上，在实现中这是1个样本，为了避免由0引起的常见错误；但这对演示的影响很小）。
- en: Let's create a Flask project folder named, say, `app`. We then create the `templates`
    folder and create `index.html` inside it. Another file, named `app.py`, is created
    in the `app` folder. We will create more files in this folder for deployment on
    Heroku.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建一个名为`app`的 Flask 项目文件夹。然后在其中创建`templates`文件夹，并在其中创建`index.html`。在`app`文件夹中创建另一个名为`app.py`的文件。我们将在这个文件夹中创建更多文件，以便部署到
    Heroku。
- en: We will not be writing the complete code of the `index.html` file, but we'll
    take a look at the two functions calling the API of the backend via Ajax triggers.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会编写完整的`index.html`文件代码，但我们会看一下这两个通过 Ajax 触发调用后端 API 的函数。
- en: You can find the entire code at [http://tiny.cc/HoPforDL-Ch-11-index](http://tiny.cc/HoPforDL-Ch-11-index).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[http://tiny.cc/HoPforDL-Ch-11-index](http://tiny.cc/HoPforDL-Ch-11-index)找到完整代码。
- en: 'Observe lines `109` to `116` in `index.html`:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 查看`index.html`中的第`109`行到第`116`行：
- en: '[PRE22]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The preceding piece of JavaScript (jQuery) code creates a `click` handler on
    a button with the `train-btn` ID. It calls the `/train_batch` API on the backend.
    We will be creating this API while we are developing the backend.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的这段JavaScript（jQuery）代码为一个ID为`train-btn`的按钮创建了一个`click`事件处理程序。它调用了后端的`/train_batch`
    API。我们将在开发后端时创建这个API。
- en: 'Another interesting block of code in this file is lines `138` to `145`:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件中另一个有趣的代码块是第`138`行到第`145`行：
- en: '[PRE23]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Here, we set a `click` handler on the button with a `reset-btn` ID to fire a
    request to the `/reset` API. This is an easily forgotten side of incremental learning,
    which asks for the decrement of the training; that is, it resets the trained model
    to an untrained state.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们为按钮设置了一个`click`事件处理程序，按钮的ID为`reset-btn`，该处理程序会触发对`/reset` API的请求。这是增量学习中一个容易被忽视的部分，它要求减少训练量；也就是说，它将训练过的模型重置为未训练的状态。
- en: We now know the APIs we will need to build on the backend. Let's build those
    in the next section!
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在知道了需要在后端构建的API。让我们在下一节中进行构建！
- en: Implementing the backend
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现后端
- en: 'In this section, we will work on creating the required APIs along with the
    server script for the demonstration. Edit the `app.py` file in the root folder
    of the project:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将着手创建所需的API以及演示的服务器脚本。编辑项目根目录中的`app.py`文件：
- en: 'First, we will make some necessary imports to the script:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将对脚本进行一些必要的导入：
- en: '[PRE24]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Notice that the imports here are very similar to the imports we made during
    model creation in the Jupyter notebook. This is explained due to the fact that
    we're only converting the Jupyter notebook code into a server script for the backend
    demonstration.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这里的导入与我们在Jupyter Notebook中创建模型时的导入非常相似。这是因为我们只是将Jupyter Notebook中的代码转换为用于后端演示的服务器脚本。
- en: 'We will then load the dataset onto a `pandas` DataFrame:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将数据集加载到一个`pandas` DataFrame中：
- en: '[PRE25]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We''ll quickly run through the rest of the code, where we will split the dataset,
    scale the columns, and train the model on a certain number of samples:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将快速浏览剩余的代码，其中我们将拆分数据集、缩放列，并在一定数量的样本上训练模型：
- en: '[PRE26]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Notice that in the preceding code, we train the model on `100` samples from
    the dataset. This would make the model fairly accurate, but obviously, with scope
    for improvement, which we will trigger using the `/train_batch` API, which adds
    25 samples to the training of the model.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在前面的代码中，我们在数据集的`100`个样本上训练模型。这将使模型相当准确，但显然仍有改进的空间，我们将在使用`/train_batch` API时触发该改进，它会将25个样本添加到模型的训练中。
- en: 'Let''s set a few variables to use the script, as well as instantiating the
    `Flask` server object:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置一些变量以供脚本使用，并实例化`Flask`服务器对象：
- en: '[PRE27]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We will now create the `/train_batch` API, as shown:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将创建`/train_batch` API，如下所示：
- en: '[PRE28]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `train_batch()` function increments the learning of the model by `25` samples
    or the remaining samples of the dataset. It returns the current score of the model
    on the 20% test split of the dataset. Notice again the usage of the `partial_fit`
    method used for 25 iterations.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '`train_batch()`函数通过`25`个样本或数据集中剩余的样本增加模型的学习量。它返回模型在数据集20%测试集上的当前得分。再次注意，`partial_fit`方法被用于25次迭代。'
- en: 'Next, we will create the `/reset` API, which will reset the model to an untrained
    state:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将创建`/reset` API，它将重置模型为未训练状态：
- en: '[PRE29]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This API, again, returns the score of the model after the reset. It should be
    as expected—very poor—assuming the dataset is balanced in its categories.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这个API再次返回重置后的模型得分。它应该如预期般——非常差——假设数据集在其类别中是平衡的。
- en: 'Let''s now write the code to start the Flask server for this app:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们编写代码以启动这个应用程序的Flask服务器：
- en: '[PRE30]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Once this is done, we''re ready to test whether the app works by running it
    from a console. To do so, open a new terminal window and enter the following command
    in the `app` directory:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成此操作后，我们准备通过从控制台运行应用程序来测试它是否正常工作。为此，请打开一个新的终端窗口，并在`app`目录中输入以下命令：
- en: '[PRE31]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Once the server is running, you can view the application at `http://localhost:5000`.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦服务器运行，您可以通过`http://localhost:5000`查看应用程序。
- en: Finally, we will deploy the project to Heroku.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将把项目部署到Heroku。
- en: Deploying the project to Heroku
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将项目部署到Heroku
- en: 'In this section, we will take a look at how we can deploy our demonstration
    app to Heroku. In the following steps, we will create an account on Heroku and
    add the modifications required to the code, which will make it eligible to host
    on the platform:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将了解如何将我们的演示应用程序部署到Heroku。在接下来的步骤中，我们将创建Heroku帐户并添加所需的代码修改，使其可以在该平台上托管：
- en: 'First, visit [https://id.heroku.com/login](https://id.heroku.com/login) to
    get the login screen for Heroku. If you do not have a user account already, you
    can go through the sign-up process to create one for free:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，访问 [https://id.heroku.com/login](https://id.heroku.com/login) 获取 Heroku 的登录界面。如果你还没有用户帐户，可以通过注册过程免费创建一个帐户：
- en: '![](img/ec63d54a-25e8-40aa-bd4c-c8b071847486.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec63d54a-25e8-40aa-bd4c-c8b071847486.png)'
- en: 'We will now create a `Procfile` file. In this step, we create a blank file
    called `Procfile` in the `app` directory. Once created, we add the following line
    to it:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将创建一个 `Procfile` 文件。在此步骤中，我们在 `app` 目录中创建一个名为 `Procfile` 的空文件。创建后，我们在其中添加以下一行：
- en: '[PRE32]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This file is used during the deployment of the project to Heroku. The preceding
    line instructs the Heroku system to use the `gunicorn` server and run the file
    called `app.py`.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件在将项目部署到 Heroku 时使用。前面的命令指示 Heroku 系统使用 `gunicorn` 服务器并运行名为 `app.py` 的文件。
- en: 'We then freeze the requirements of the project. Heroku looks for the `requirements.txt`
    file to automatically download and install the required packages for the project.
    To create the list of requirements, use the following command in the terminal:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将冻结项目的依赖关系。Heroku 会查找 `requirements.txt` 文件，以自动下载并安装项目所需的包。要创建依赖列表，请在终端中使用以下命令：
- en: '[PRE33]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: This creates a list of packages in a file named `requirements.txt` in the project's
    root folder.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在项目的根文件夹中创建一个名为 `requirements.txt` 的文件，列出所有包。
- en: You may want to leave some packages from being included in the `requirements.txt`
    file. A good method for working with projects such as this is to use virtual environments
    so that only the required packages are available in the environment and so `requirements.txt`
    only contains them. However, this solution might not always be feasible. In such
    cases, feel free to manually edit `requirements.txt` and remove the lines that
    include packages that are not relevant to the project.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能希望将某些包排除在 `requirements.txt` 文件之外。处理此类项目的好方法是使用虚拟环境，这样只有所需的包在环境中可用，`requirements.txt`
    中只包含它们。然而，这种解决方案并不总是可行。在这种情况下，可以手动编辑 `requirements.txt` 并删除不相关的包。
- en: 'The directory structure of the project should currently look as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 项目的目录结构当前应如下所示：
- en: '[PRE34]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Now, we'll need to install the Heroku CLI on our local system. Follow the instructions
    provided at [https://devcenter.heroku.com/articles/heroku-cli](https://devcenter.heroku.com/articles/heroku-cli)
    to install Heroku on your system.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要在本地系统上安装 Heroku CLI。请按照 [https://devcenter.heroku.com/articles/heroku-cli](https://devcenter.heroku.com/articles/heroku-cli)
    中提供的说明在系统上安装 Heroku。
- en: 'Next, we''ll initialize `git` on the directory. To do so, use the following
    command in the root directory of the project:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将在目录上初始化 `git`。为此，请在项目根目录中使用以下命令：
- en: '[PRE35]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We then initialize the Heroku version management on the project. We open a
    terminal window and navigate to the project directory. Use the following command
    to initialize the version manager provided by Heroku for this project and to register
    it with your currently logged-in user:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们初始化项目的 Heroku 版本管理。打开终端窗口并导航到项目目录。使用以下命令初始化 Heroku 提供的版本管理器，并将其与当前登录的用户注册：
- en: '[PRE36]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'This command will end by displaying the URL that your project will be hosted
    on. Along with that, a `.git` URL is displayed, which is used to track the versions
    of your project. You can push/pull from this `.git` URL to change your project
    and trigger redeployment. The output will be similar to the following:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将以显示项目将托管的网址结束。同时，还会显示一个 `.git` URL，用于跟踪项目的版本。你可以从这个 `.git` URL 推送/拉取以更改项目并触发重新部署。输出将类似于以下内容：
- en: '[PRE37]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Next, we add files to `git` and push to Heroku. You are now ready to push the
    files to the Heroku `git` item for deployment. We use the following commands:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将文件添加到 `git` 并推送到 Heroku。现在，你可以将文件推送到 Heroku 的 `git` 项目进行部署。我们使用以下命令：
- en: '[PRE38]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This will create the deployment and you will see a long output stream. The
    stream is a log of events happening during the deployment of your project—installing
    packages, determining the runtime, and starting the listening script. Once you
    get a successful deployment message, you will be able to view your application
    on the URL provided by Heroku in the previous step. If you are unable to remember
    it, you can use the following command to trigger it to open in a browser from
    the terminal:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建部署并显示一个长时间的输出流。该流是部署过程中发生事件的日志——安装包、确定运行时、启动监听脚本。一旦你看到成功部署的消息，你就可以通过 Heroku
    在上一阶段提供的 URL 查看你的应用。如果你记不住该 URL，你可以使用以下命令从终端触发它在浏览器中打开：
- en: '[PRE39]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'You should now see a new window or tab open in your default browser with the
    deployed code. If anything goes wrong, you''ll be able to see the deployment logs
    in the Heroku dashboard, as shown:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你应该在默认浏览器中看到一个新窗口或标签页打开，显示已部署的代码。如果出现问题，你可以在 Heroku 仪表盘中查看部署日志，如下所示：
- en: '![](img/11361907-2e81-41e5-ab97-90f7bd2cf2cf.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](img/11361907-2e81-41e5-ab97-90f7bd2cf2cf.png)'
- en: This is an actual screenshot from a failed build while deploying the code presented
    in this chapter. You should be able to make out the error at the end of the log.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个实际的截图，展示了在部署本章所示代码时构建失败的情况。你应该能够看到日志末尾的错误信息。
- en: If the build deploys successfully, you will see a successful deployment message
    at the end of the logs.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如果构建部署成功，你将在日志末尾看到成功部署的消息。
- en: Security measures, monitoring techniques, and performance optimization
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全措施、监控技术和性能优化
- en: In this section, we will talk about the security measures, monitoring techniques,
    and performance optimizations that can be integrated into a DL solution in production.
    These functionalities are essential to maintaining solutions that depend on AI
    backends. While we have discussed the security methods facilitated by DL in previous
    chapters, we will discuss the possible security threats that could be posed to
    an AI backend.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 本节我们将讨论可以集成到生产中的深度学习解决方案的安全措施、监控技术和性能优化。这些功能对维护依赖于 AI 后端的解决方案至关重要。虽然我们在前几章中讨论了深度学习所促进的安全方法，但我们将讨论可能对
    AI 后端构成的安全威胁。
- en: One of the largest security threats to AI backends is from noisy data. In most
    of the methodologies for having AI in production, it is important to regularly
    check for new types of noise in the dataset that it is trained on.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 对 AI 后端的最大安全威胁之一来自噪声数据。在大多数用于将 AI 投入生产的方法中，定期检查数据集中的新噪声类型非常重要，尤其是它所训练的数据集。
- en: 'Here is a very important message for all developers who love the Python `pickle`
    library:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这是给所有喜爱 Python `pickle` 库的开发者们的重要提示：
- en: '![](img/c8e91eed-3467-461c-8b35-17eaee574e35.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c8e91eed-3467-461c-8b35-17eaee574e35.png)'
- en: The preceding screenshot is taken from the official Python documentation at
    [https://docs.python.org/3/library/pickle.html](https://docs.python.org/3/library/pickle.html).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 上述截图来自官方 Python 文档，网址为 [https://docs.python.org/3/library/pickle.html](https://docs.python.org/3/library/pickle.html)。
- en: 'To demonstrate a simple example of why pickling in production might be dangerous,
    consider the following Python code:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示生产中使用 pickle 可能带来的危险，请考虑以下 Python 代码：
- en: '[PRE40]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: What the preceding code does is simple—it attempts to wipe out your home directory.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码所做的事情很简单——它试图清除你的主目录。
- en: 'Warning: anyone who runs the preceding code is solely responsible for the results
    of their actions.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：任何运行上述代码的人，须对其行为的结果承担全部责任。
- en: The preceding example and associated warning implicate a general security threat
    in AI backends and almost every automated system—the hazards of untrusted input.
    So, it is important that any data that might be put into the model, whether in
    training or testing, is properly validated to make sure it won't cause any critical
    issues with the system.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例及相关警告揭示了 AI 后端及几乎所有自动化系统中的一般安全威胁——不受信任输入的危害。因此，确保任何可能输入模型的数据，无论是在训练还是测试过程中，都经过适当验证，以确保它不会对系统造成任何严重问题，是非常重要的。
- en: 'It is also very important that continuous monitoring is carried out for models
    in production. Models often get stale and obsolete and run the risk of making
    outdated predictions after a while. It is important to keep a check on the relevance
    of the predictions made by the AI models. Consider a person who only knows about
    CD-ROMs and floppy disks. Over time, we came up with USB drives and solid-state
    disks. This person would not be able to make any intelligent decisions about recent
    devices. Similarly, a **Natural Language Processing** (**NLP**) model trained
    on text dumps from the early 2000s would not be able to understand a conversation
    where somebody asks *Can you please WhatsApp me the wiki link for Avengers: Endgame?*.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '同样，对于生产环境中的模型，进行持续监控也非常重要。模型常常会变得过时和陈旧，随着时间的推移，它们可能会做出过时的预测。重要的是要检查AI模型所做的预测是否仍然相关。想象一下，一个只了解CD-ROM和软盘的人。随着时间的推移，我们出现了USB驱动器和固态硬盘。这个人将无法就现代设备做出任何智能决策。类似地，一个**自然语言处理**（**NLP**）模型，如果是在2000年代初期的文本资料上训练的，就无法理解像*“你能不能通过WhatsApp给我发Avengers:
    Endgame的维基链接？”*这样的问题。'
- en: Finally, how can you come up with optimizations for the performance of the AI
    backend?
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如何为人工智能后端的性能优化提供解决方案？
- en: 'Web developers are mostly concerned with this question. Everything needs to
    be lightning-fast when in production. Some of the tricks to speed up AI models
    in production are as follows:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: Web开发人员通常最关心这个问题。一切在生产环境中都需要是闪电般的快速。加速生产环境中AI模型的一些技巧如下：
- en: Break down the dataset into the lowest number of features that you can make
    a fairly accurate prediction by. This is the core idea of feature selection performed
    by several algorithms, such as principal component analysis and other heuristic
    methods. Often, not all of the data that is fed into a system is relevant or is
    only slightly relevant to make the predictions based on it.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据集拆分为最低数量的特征，以便通过这些特征可以做出相对准确的预测。这是多个算法执行特征选择的核心思想，如主成分分析和其他启发式方法。通常，输入系统的所有数据并非都与预测相关，或者仅与预测的相关性很小。
- en: Consider hosting your model on a separate, powerful cloud server with autoscaling
    enabled on it. This will ensure that your model doesn't waste resources on serving
    the pages for the website and only handles the AI-based queries. Autoscaling will
    take care of the sudden increased or steeply decreased workloads on the backend.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑将你的模型托管在一个单独的、强大的云服务器上，并启用自动扩展功能。这将确保你的模型不会浪费资源来为网站服务页面，而只处理基于人工智能的查询。自动扩展将处理后端突增或剧烈减少的工作负载。
- en: Online learning and auto ML methods are subject to slowness induced by the size
    of the dataset. Make sure you have in place constraints that do not allow a blowup
    of the size of the data being churned by dynamically learning systems.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线学习和自动化机器学习方法会受到数据集大小引起的速度问题的影响。确保你已经设置了约束条件，以防止动态学习系统处理的数据量膨胀。
- en: Summary
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered the methodologies that we can use to deploy DL models
    in production. We looked at the different methods in detail and some famous tools
    that are useful in making it easier to deploy to production and manage the models
    there. We covered a demonstration of online learning using the Flask and `sklearn`
    libraries. We also discussed the post-deployment requisites and some examples
    for the most common tasks.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了可以用来将深度学习模型部署到生产环境中的方法。我们详细查看了不同的方法和一些有助于简化生产环境部署和模型管理的著名工具。我们展示了使用Flask和`sklearn`库进行在线学习的演示。我们还讨论了部署后的要求以及一些最常见任务的示例。
- en: In the next chapter, we will demonstrate an end-to-end sample application—a
    customer support chatbot—using Dialogflow integrated into a website.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将展示一个端到端的示例应用——一个客户支持聊天机器人——它通过集成到网站中的Dialogflow来实现。
