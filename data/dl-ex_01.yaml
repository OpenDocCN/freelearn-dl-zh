- en: Data Science - A Birds' Eye View
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学 - 鸟瞰图
- en: Data science or machine learning is the process of giving the machines the ability
    to learn from a dataset without being told or programmed. For instance, it is
    extremely hard to write a program that can take a hand-written digit as an input
    image and outputs a value from 0-9 according to the image that's written. The
    same applies to the task of classifying incoming emails as spam or non-spam. For
    solving such tasks, data scientists use learning methods and tools from the field
    of data science or machine learning to teach the computer how to automatically
    recognize digits, by giving it some explanatory features that can distinguish
    one digit from another. The same for the spam/non-spam problem, instead of using
    regular expressions and writing hundred of rules to classify the incoming email,
    we can teach the computer through specific learning algorithms how to distinguish
    between spam and non-spam emails.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学或机器学习是赋予机器从数据集中学习的能力，而无需明确告诉它或进行编程。例如，编写一个程序，能够接受手写数字作为输入图像，并根据图像输出一个0到9之间的值，这是极其困难的。对于将来来邮件分类为垃圾邮件或非垃圾邮件的任务也是如此。为了解决这些任务，数据科学家使用数据科学或机器学习领域的学习方法和工具，教计算机如何通过一些能区分不同数字的特征自动识别数字。垃圾邮件/非垃圾邮件问题也是如此，我们可以通过特定的学习算法教计算机如何区分垃圾邮件和非垃圾邮件，而不是使用正则表达式并编写成百上千条规则来分类来邮件。
- en: For the spam filtering application, you can code it by a rule-based approach,
    but it won't be good enough to be used in production, like the one in your mailing
    server. Building a learning system is an ideal solution for that.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 对于垃圾邮件过滤应用，你可以采用基于规则的方法进行编程，但这不足以用于生产环境，比如你的邮件服务器。构建一个学习系统是解决这个问题的理想方案。
- en: You are probably using applications of data science on a daily basis, often
    without knowing it. For example, your country might be using a system to detect
    the ZIP code of your posted letter in order to automatically forward it to the
    correct area. If you are using Amazon, they often recommend things for you to
    buy and they do this by learning what sort of things you often search for or buy.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能每天都在使用数据科学的应用，通常你甚至没有意识到。例如，你的国家可能使用一个系统来检测你寄出的信件的邮政编码，以便自动将其转发到正确的地区。如果你在使用亚马逊，他们通常会为你推荐商品，这通过学习你经常搜索或购买的物品来实现。
- en: Building a learned/trained machine learning algorithm will require a base of
    historical data samples from which it's going to learn how to distinguish between
    different examples and to come up with some knowledge and trends from that data.
    After that, the learned/trained algorithm could be used for making predictions
    on unseen data. The learning algorithm will be using raw historical data and will
    try to come up with some knowledge and trends from that data.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个经过学习/训练的机器学习算法需要基于历史数据样本，以便它能够学习如何区分不同的例子，并从这些数据中得出一些知识和趋势。之后，经过学习/训练的算法可以用来对未见过的数据进行预测。学习算法将使用原始的历史数据，并尝试从这些数据中得出一些知识和趋势。
- en: 'In this chapter, we are going to have a bird''s-eye view of data science, how
    it works as a black box, and the challenges that data scientists face on a daily
    basis. We are going to cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将从鸟瞰图的角度了解数据科学，了解它如何作为一个黑盒工作，以及数据科学家每天面临的挑战。我们将涵盖以下主题：
- en: Understanding data science by an example
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过一个例子来理解数据科学
- en: Design procedure of data science algorithms
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学算法设计流程
- en: Getting to learn
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始学习
- en: Implementing the fish recognition/detection model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现鱼类识别/检测模型
- en: Different learning types
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的学习类型
- en: Data size and industry needs
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据规模和行业需求
- en: Understanding data science by an example
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过一个例子来理解数据科学
- en: To illustrate the life cycle and challenges of building a learning algorithm
    for specific data, let us consider a real example. The Nature Conservancy is working
    with other fishing companies and partners to monitor fishing activities and preserve
    fisheries for the future. So they are looking to use cameras in the future to
    scale up this monitoring process. The amount of data that will be produced from
    the deployment of these cameras will be cumbersome and very expensive to process
    manually. So the conservancy wants to develop a learning algorithm to automatically
    detect and classify different species of fish to speed up the video reviewing
    process.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明构建针对特定数据的学习算法的生命周期和挑战，假设我们来看一个真实的例子。自然保护协会正在与其他渔业公司和合作伙伴合作，监控渔业活动并保护未来的渔场。因此，他们未来计划使用摄像头来扩大这一监控过程。这些摄像头部署后所产生的数据量将非常庞大，并且手动处理这些数据将非常昂贵。因此，保护协会希望开发一个学习算法，自动检测和分类不同种类的鱼类，以加快视频审核过程。
- en: '*Figure 1.1* shows a sample of images taken by conservancy-deployed cameras.
    These images will be used to build the system.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.1* 显示了自然保护协会部署的摄像头拍摄的样本图像。这些图像将用于构建系统。'
- en: '![](img/46235fa5-ee68-43a2-b668-04a2d869461b.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/46235fa5-ee68-43a2-b668-04a2d869461b.jpg)'
- en: 'Figure 1.1: Sample of the conservancy-deployed cameras'' output'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1：自然保护协会部署的摄像头输出样本
- en: So our aim in this example is to separate different species such as tunas, sharks,
    and more that fishing boats catch. As an illustrative example, we can limit the
    problem to only two classes, tuna and opah.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，本文的目标是区分渔船捕获的不同物种，如鲔鱼、鲨鱼等。作为一个示例，我们可以将问题限定为仅包含两类：鲔鱼和Opah鱼。
- en: '![](img/7ed0e228-c5ec-4727-a8be-5db5689cbdc0.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7ed0e228-c5ec-4727-a8be-5db5689cbdc0.png)'
- en: 'Figure 1.2: Tuna fish type (left) and opah fish type (right)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2：鲔鱼类型（左）与Opah鱼类型（右）
- en: 'After limiting our problem to contain only two types of fish, we can take a
    sample of some  random images from our collection and start to note some physical
    differences between the two types. For example, consider the following physical
    differences:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在将问题限制为仅包含两种鱼类后，我们可以从我们收集的图像中随机抽取一些样本，并开始注意这两种鱼类之间的一些物理差异。例如，考虑以下物理差异：
- en: '**Length**: You can see that compared to the opah fish, the tuna fish is longer'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**长度**：你可以看到，与鲔鱼相比，Opah鱼更长。'
- en: '**Width**: Opah is wider than tuna'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**宽度**：Opah鱼比鲔鱼更宽。'
- en: '**Color**: You can see that the opah fish tends to be more red while the tuna
    fish tends to be blue and white, and so on'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**颜色**：你可以看到，Opah鱼通常更红，而鲔鱼则趋向于蓝色和白色，等等。'
- en: We can use these physical differences as features that can help our learning
    algorithm(classifier) to differentiate between these two types of fish.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用这些物理差异作为特征，帮助我们的学习算法（分类器）区分这两种鱼类。
- en: Explanatory features of an object are something that we use in daily life to
    discriminate between objects that surround us. Even babies use these explanatory
    features to learn about the surrounding environment. The same for data science,
    in order to build a learned model that can discriminate between different objects
    (for example, fish type), we need to give it some explanatory features to learn
    from (for example, fish length). In order to make the model more certain and reduce
    the confusion error, we can increase (to some extent) the explanatory features
    of the objects.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 物体的解释性特征是我们日常生活中用来区分周围物体的特征。即使是婴儿，也会使用这些解释性特征来学习周围的环境。数据科学也是如此，为了构建一个可以区分不同物体（例如鱼类种类）的学习模型，我们需要给它一些解释性特征来学习（例如鱼类的长度）。为了使模型更具确定性并减少混淆错误，我们可以在某种程度上增加物体的解释性特征。
- en: Given that there are physical differences between the two types of fish, these
    two different fish populations have different models or descriptions. So the ultimate
    goal of our classification task is to get the classifier to learn these different
    models and then give an image of one of these two types as an input. The classifier
    will classify it by choosing the model (tuna model or opah model) that corresponds
    best to this image.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这两种鱼类之间存在物理差异，这两种不同的鱼群有不同的模型或描述。因此，我们分类任务的最终目标是让分类器学习这些不同的模型，然后将这两种鱼类之一的图像作为输入，分类器将通过选择最符合该图像的模型（鲔鱼模型或Opah模型）进行分类。
- en: 'In this case, the collection of tuna and opah fish will act as the knowledge
    base for our classifier. Initially, the knowledge base (training samples) will
    be labeled/tagged, and for each image, you will know beforehand whether it''s
    tuna or opah fish. So the classifier will use these training samples to model
    the different types of fish, and then we can use the output of the training phase
    to automatically label unlabeled/untagged fish that the classifier didn''t see
    during the training phase.  This kind of unlabeled data is often called **unseen**
    **data**. The training phase of the life cycle is shown in the following diagram:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个案例中，金枪鱼和大眼金枪鱼的集合将作为我们分类器的知识库。最初，知识库（训练样本）会被标注/标签化，并且你将事先知道每张图像是金枪鱼还是大眼金枪鱼。所以，分类器将使用这些训练样本来对不同类型的鱼进行建模，然后我们可以使用训练阶段的输出自动标记分类器在训练阶段未见过的未标记/未标签的鱼类数据。这类未标记的数据通常被称为**未见过的**
    **数据**。生命周期的训练阶段如图所示：
- en: Supervised data science is all about learning from historical data with known
    target or output, such as the fish type, and then using this learned model to
    predict cases or data samples, for which we don't know the target/output.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的数据科学就是从具有已知目标或输出的历史数据中学习，例如鱼的种类，然后使用这个学习到的模型来预测我们不知道目标/输出的数据样本或案例。
- en: '![](img/5b6e7bf3-3fdf-4d67-9489-e84b3579b323.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5b6e7bf3-3fdf-4d67-9489-e84b3579b323.png)'
- en: 'Figure 1.3: Training phase life cycle'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3：训练阶段生命周期
- en: 'Let''s have a look at how the training phase of the classifier will work:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看分类器的训练阶段如何进行：
- en: '**Pre-processing**: In this step, we will try to segment the fish from the
    image by using the relevant segmentation technique.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预处理**：在这一步，我们将尝试通过使用相关的分割技术将鱼从图像中分割出来。'
- en: '**Feature extraction**: After segmenting the fish from the image by subtracting
    the background, we will measure the physical differences (length, width, color,
    and so on) of each image. At the end, you will get something like *Figure 1.4*.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征提取**：通过减去背景将鱼从图像中分割出来后，我们将测量每张图像的物理差异（长度、宽度、颜色等）。最终，你将得到类似*图1.4*的内容。'
- en: Finally, we will feed this data into the classifier in order to model different
    fish types.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将把这些数据输入分类器，以便对不同的鱼类类型进行建模。
- en: As we have seen, we can visually differentiate between tuna and opah fish based
    on the physical differences (features) that we proposed, such as length, width,
    and color.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们可以通过我们提出的物理差异（特征），例如长度、宽度和颜色，来直观地区分金枪鱼和大眼金枪鱼。
- en: We can use the length feature to differentiate between the two types of fish.
    So we can try to differentiate between the fish by observing their length and
    seeing whether it exceeds some value (`length*`) or not.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用长度特征来区分这两种类型的鱼。所以我们可以通过观察鱼的长度并判断它是否超过某个值（`length*`）来尝试区分鱼类。
- en: 'So, based on our training sample, we can derive the following rule:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，根据我们的训练样本，我们可以推导出以下规则：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In order to find this `length*` we can somehow make length measurements based
    on our training samples. So, suppose we get these length measurements and obtain
    the histogram as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到这个`length*`，我们可以通过训练样本来某种方式进行长度测量。所以，假设我们获得这些长度测量值并得到如下的直方图：
- en: '![](img/4cb26cf7-26c3-4833-82ef-61e7e4d52aae.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4cb26cf7-26c3-4833-82ef-61e7e4d52aae.png)'
- en: 'Figure 1.4: Histogram of the length  measurements for the two types of fish'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4：两种类型鱼的长度测量直方图
- en: 'In this case, we can derive a rule based on the length feature and differentiate
    the tuna and opah fish. In this particular example, we can tell that `length*`
    is `7`. So we can update the preceding rule to be:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以根据长度特征推导出一条规则来区分金枪鱼和大眼金枪鱼。在这个特定的例子中，我们可以得出`length*`为`7`。因此，我们可以更新前面的规则为：
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As you may notice, this is not a promising result because of the overlap between
    the two histograms, as the length feature is not a perfect one to use solely for
    differentiating between the two types. So we can try to incorporate more features
    such as the width and then combine them. So, if we somehow manage to measure the
    width of our training samples, we might get something like the histogram as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能注意到的，这不是一个有前景的结果，因为两条直方图之间存在重叠，长度特征并不是一个完美的特征，不能单独用于区分这两种类型的鱼。所以我们可以尝试加入更多的特征，比如宽度，然后将它们结合起来。因此，如果我们能够某种方式测量训练样本的宽度，我们可能会得到如下的直方图：
- en: '![](img/0b538b23-036b-4def-8b53-49c40d475a53.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0b538b23-036b-4def-8b53-49c40d475a53.png)'
- en: 'Figure 5: Histogram of width  measurements for the two types of fish'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：两种类型鱼的宽度测量直方图
- en: As you can see, depending on one feature only will not give accurate results
    and the output model will do lots of misclassifications. Instead, we can somehow
    combine the two features and come up with something that looks reasonable.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，仅依赖一个特征不会给出准确的结果，输出模型将会产生大量的误分类。相反，我们可以通过某种方式将两个特征结合起来，得出一个看起来合理的结果。
- en: 'So if we combine both features, we might get something that looks like the
    following graph:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果我们将这两个特征结合起来，可能会得到如下图所示的图形：
- en: '![](img/63eb4b5d-7389-4bb0-9ebb-d4fd90b46a6f.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/63eb4b5d-7389-4bb0-9ebb-d4fd90b46a6f.png)'
- en: 'Figure 1.6 : Combination between the subset of the length and width measurements
    for the two types of fish'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6：金枪鱼和Opah鱼长度与宽度子集的组合
- en: Combining the readings for the **length** and **width** features, we will get
    a scatter plot like the one in the preceding graph. We have the red dots to represent
    the tuna fish and the green dots to represent the opah fish, and we can suggest
    this black line to be the rule or the decision boundary that will differentiate
    between the two types of fish.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 结合**长度**和**宽度**这两个特征的读数，我们将得到类似前面图表中的散点图。我们用红色点表示金枪鱼，用绿色点表示Opah鱼，并且可以建议这条黑线是区分两种鱼类的规则或决策边界。
- en: For example, if the reading of one fish is above this decision boundary, then
    it's a tuna fish; otherwise, it will be predicted as an opah fish.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果某条鱼的读数位于这个决策边界之上，那么它就是金枪鱼；否则，它将被预测为Opah鱼。
- en: 'We can somehow try to increase the complexity of the rule to avoid any errors
    and get a decision boundary like the one in the following graph:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过某种方式尝试增加规则的复杂性，以避免任何错误，并得到如下图所示的决策边界：
- en: '![](img/f5b4dead-79fb-454c-8d30-6efc5b2f8a66.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f5b4dead-79fb-454c-8d30-6efc5b2f8a66.png)'
- en: 'Figure 1.7: Increasing the complexity of the decision boundary to avoid misclassifications
    over the training data'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7：增加决策边界的复杂度，以避免对训练数据的误分类
- en: The advantage of this model is that we get almost 0 misclassifications over
    the training samples. But actually this is not the objective of using data science.
    The objective of data science is to build a model that will be able to generalize
    and perform well over the unseen data. In order to find out whether we built a
    model that will generalize or not, we are going to introduce a new phase called
    the **testing phase**, in which we give the trained model an unlabeled image and
    expect the model to assign the correct label (**Tuna** and **Opah**) to it.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型的优点是，在训练样本上几乎没有误分类。但实际上，这并不是使用数据科学的目标。数据科学的目标是建立一个能够在未见数据上进行泛化并且表现良好的模型。为了判断我们是否建立了一个能够泛化的模型，我们将引入一个新的阶段，叫做**测试阶段**，在这个阶段，我们会给训练好的模型一个未标记的图像，并期望模型为其分配正确的标签（**金枪鱼**和**Opah鱼**）。
- en: Data science's ultimate objective is to build a model that will work well in
    production, not over the training set. So don't be happy when you see your model
    is performing well on the training set, like the one in figure 1.7\. Mostly, this
    kind of model will fail to work well in recognizing the fish type in the image.
    This incident of having your model work well only over the training set is called
    **overfitting**, and most practitioners fall into this trap.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学的最终目标是建立一个在生产环境中能够良好工作的模型，而不是只在训练集上工作。所以，当你看到你的模型在训练集上表现良好时，不要太高兴，就像图1.7中的那样。通常，这种模型在识别图像中的鱼类时会失败。仅在训练集上表现良好的模型被称为**过拟合**，大多数实践者都会陷入这个陷阱。
- en: 'Instead of coming up with such a complex model, you can drive a less complex
    one that will generalize in the testing phase. The following graph shows the use
    of a less complex model in order to get fewer misclassification errors and to
    generalize the unseen data as well:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 与其构建如此复杂的模型，不如构建一个更简单的模型，使其能够在测试阶段进行泛化。以下图表展示了使用较简单模型，以减少误分类错误并同时泛化未见数据的情况：
- en: '![](img/aeb1ceb4-39eb-4769-8653-5f4bdd6d8d1e.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aeb1ceb4-39eb-4769-8653-5f4bdd6d8d1e.png)'
- en: 'Figure 1.8: Using a less complex model in order to be able to generalize over
    the testing samples (unseen data)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8：使用更简单的模型，以便能够对测试样本（未见数据）进行泛化
- en: Design procedure of data science algorithms
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学算法的设计流程
- en: Different learning systems usually follow the same design procedure. They start
    by acquiring the knowledge base, selecting the relevant explanatory features from
    the data, going through a bunch of candidate learning algorithms while keeping
    an eye on the performance of each one, and finally the evaluation process, which
    measures how successful the training process was.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的学习系统通常遵循相同的设计过程。它们首先获取知识库，从数据中选择相关的解释特征，经过一系列候选学习算法的尝试，并且密切关注每个算法的表现，最后进行评估过程，衡量训练过程的成功与否。
- en: 'In this section, we are going to address all these different design steps in
    more detail:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将更详细地介绍所有这些不同的设计步骤：
- en: '![](img/4e2ddd2f-0dc8-485a-9b33-324696efa48f.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4e2ddd2f-0dc8-485a-9b33-324696efa48f.png)'
- en: 'Figure 1.11: Model learning process outline'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.11：模型学习过程概述
- en: Data pre-processing
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: This component of the learning cycle represents the knowledge base of our algorithm.
    So, in order to help the learning algorithm give accurate decisions about the
    unseen data, we need to provide this knowledge base in the best form. Thus, our
    data may need a lot of cleaning and pre-processing (conversions).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这一组件代表了我们算法的知识库。因此，为了帮助学习算法对未见数据做出准确的决策，我们需要以最佳形式提供这些知识库。因此，我们的数据可能需要大量清理和预处理（转换）。
- en: Data cleaning
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据清理
- en: 'Most datasets require this step, in which you get rid of errors, noise, and
    redundancies. We need our data to be accurate, complete, reliable, and unbiased,
    as there are lots of problems that may arise from using bad knowledge base, such
    as:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据集都需要这一阶段，在此过程中，你将去除错误、噪声和冗余。我们需要确保数据准确、完整、可靠且无偏，因为使用糟糕的知识库可能会导致许多问题，例如：
- en: Inaccurate and biased conclusions
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不准确和有偏的结论
- en: Increased error
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加的错误
- en: Reduced generalizability, which is the model's ability to perform well over
    the unseen data that it didn't train on previously
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降低的泛化能力，即模型在未见过的数据上的表现能力，未训练过的数据
- en: Data pre-processing
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: 'In this step, we apply some conversions to our data to make it consistent and
    concrete. There are lots of different conversions that you can consider while
    pre-processing your data:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们对数据进行一些转换，使其一致且具体。数据预处理过程中有许多不同的转换方法可以考虑：
- en: '**Renaming** (**relabeling**): This means converting categorical values to
    numbers, as categorical values are dangerous if used with some learning methods,
    and also numbers will impose an order between the values'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重命名**（**重新标签化**）：这意味着将类别值转换为数字，因为如果与某些学习方法一起使用，类别值会带来危险，而数字则会在值之间强加顺序'
- en: '**Rescaling** (**normalization**): Transforming/bounding continuous values
    to some range, typically *[-1, 1]* or *[0, 1]*'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重缩放**（**归一化**）：将连续值转换/限定到某个范围，通常是 *[-1, 1]* 或 *[0, 1]*'
- en: '**New features**: Making up new features from the existing ones. For example,
    *obesity-factor = weight/height*'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新特征**：从现有特征中构造新的特征。例如，*肥胖因子 = 体重/身高*'
- en: Feature selection
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征选择
- en: The number of explanatory features (input variables) of a sample can be enormous
    wherein you get *x[i]=(x[i]¹, x[i]², x[i]³, ... , x[i]^d)* as a training sample
    (observation/example) and *d* is very large. An example of this can be a document
    classification task3, where you get 10,000 different words and the input variables
    will be the number of occurrences of different words.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 样本的解释特征（输入变量）数量可能非常庞大，导致你获得 *x[i]=(x[i]¹, x[i]², x[i]³, ... , x[i]^d)* 作为训练样本（观测值/示例），其中
    *d* 非常大。例如，在文档分类任务中，你可能得到10,000个不同的单词，输入变量将是不同单词的出现次数。
- en: 'This enormous number of input variables can be problematic and sometimes a
    curse because we have many input variables and few training samples to help us
    in the learning procedure. To avoid this curse of having an enormous number of
    input variables (curse of dimensionality), data scientists use dimensionality
    reduction techniques in order to select a subset from the input variables. For
    example, in the text classification task they can do the following:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这样庞大的输入变量数量可能会带来问题，有时甚至是诅咒，因为我们有很多输入变量，却只有少量训练样本来帮助学习过程。为了避免这种庞大输入变量数量带来的诅咒（维度灾难），数据科学家使用降维技术来从输入变量中选择一个子集。例如，在文本分类任务中，他们可以进行如下操作：
- en: Extracting relevant inputs (for instance, mutual information measure)
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取相关输入（例如，互信息度量）
- en: '**Principal component analysis** (**PCA**)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主成分分析**（**PCA**）'
- en: Grouping (cluster) similar words (this uses a similarity measure)
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分组（聚类）相似的词语（这使用相似度度量）
- en: Model selection
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型选择
- en: This step comes after selecting a proper subset of your input variables by using
    any dimensionality reduction technique. Choosing the proper subset of the input
    variable will make the rest of the learning process very simple.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步是在使用任何降维技术选择合适的输入变量子集之后进行的。选择合适的输入变量子集将使得后续的学习过程变得非常简单。
- en: In this step, you are trying to figure out the right model to learn.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，你需要弄清楚适合学习的模型。
- en: If you have any prior experience with data science and applying learning methods
    to different domains and different kinds of data, then you will find this step
    easy as it requires prior knowledge of how your data looks and what assumptions
    could fit the nature of your data, and based on this you choose the proper learning
    method. If you don't have any prior knowledge, that's also fine because you can
    do this step by guessing and trying different learning methods with different
    parameter settings and choose the one that gives you better performance over the
    test set.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有数据科学的先前经验，并将学习方法应用于不同领域和不同类型的数据，那么你会觉得这一步很容易，因为它需要你先了解数据的特征以及哪些假设可能适合数据的性质，基于这些你选择合适的学习方法。如果你没有任何先前的知识，这也没关系，因为你可以通过猜测并尝试不同的学习方法以及不同的参数设置，选择在测试集上表现更好的方法。
- en: Also, initial data analysis and visualization will help you to make a good guess
    about the form of the distribution and nature of your data.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，初步的数据分析和可视化将帮助你对分布的形式和数据的性质做出合理的猜测。
- en: Learning process
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习过程
- en: 'By learning, we mean the optimization criteria that you are going to use to
    select the best model parameters. There are various optimization criteria for
    that:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习中，我们指的是你将用来选择最佳模型参数的优化准则。为此有多种优化准则：
- en: '**Mean square error** (**MSE**)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**均方误差**（**MSE**）'
- en: '**Maximum likelihood** (**ML**) criterion'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大似然**（**ML**）准则'
- en: '**Maximum a posterior probability** (**MAP**)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大后验概率**（**MAP**）'
- en: The optimization problem may be hard to solve, but the right choice of model
    and error function makes a difference.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 优化问题可能很难解决，但正确选择模型和误差函数会带来不同的结果。
- en: Evaluating your model
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估你的模型
- en: 'In this step, we try to measure the generalization error of our model on the
    unseen data. Since we only have the specific data without knowing any unseen data
    beforehand, we can randomly select a test set from the data and never use it in
    the training process so that it acts like valid unseen data. There are different
    ways you can to evaluate the performance of the selected model:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一步，我们尝试衡量模型在未见数据上的泛化误差。由于我们只有特定的数据，且事先不知道任何未见数据，我们可以从数据中随机选择一个测试集，并且在训练过程中永远不使用它，以便它像未见的有效数据一样作用。你可以通过不同的方式来评估所选模型的表现：
- en: Simple holdout method, which is dividing the data into training and testing
    sets
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的保留法，即将数据分为训练集和测试集
- en: Other complex methods, based on cross-validation and random subsampling
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他基于交叉验证和随机子抽样的复杂方法
- en: Our objective in this step is to compare the predictive performance for different
    models trained on the same data and choose the one with a better (smaller) testing
    error, which will give us a better generalization error over the unseen data.
    You can also be more certain about the generalization error by using a statistical
    method to test the significance of your results.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这一步的目标是比较在相同数据上训练的不同模型的预测性能，选择测试误差更小的模型，它将给我们带来更好的未见数据泛化误差。你还可以通过使用统计方法来检验结果的显著性，从而更确定地评估泛化误差。
- en: Getting to learn
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始学习
- en: Building a machine learning system comes with some challenges and issues; we
    will try to address them in this section. Many of these issues are domain specific
    and others aren't.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个机器学习系统面临一些挑战和问题，我们将在本节中讨论这些问题。这些问题中有些是领域特定的，有些则不是。
- en: Challenges of learning
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习的挑战
- en: The following is an overview of the challenges and issues that you will typically
    face when trying to build a learning system.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是你在构建学习系统时通常会面临的挑战和问题的概述。
- en: Feature extraction – feature engineering
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征提取 – 特征工程
- en: Feature extraction is one of the crucial steps toward building a learning system.
    If you did a good job in this challenge by selecting the proper/right number of
    features, then the rest of the learning process will be easy. Also, feature extraction
    is domain dependent and it requires prior knowledge to have a sense of what features
    could be important for a particular task. For example, the features for our fish
    recognition system will be different from the ones for spam detection or identifying
    fingerprints.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提取是构建学习系统的关键步骤之一。如果你在这个挑战中通过选择适当的特征数量做得很好，那么接下来的学习过程将会变得轻松。此外，特征提取是依赖于领域的，它需要先验知识，以便了解哪些特征对于特定任务可能是重要的。例如，我们的鱼类识别系统的特征将与垃圾邮件检测或指纹识别的特征不同。
- en: The feature extraction step starts from the raw data that you have. Then build
    derived variables/values (features) that are informative about the learning task
    and facilitate the next steps of learning and evaluation (generalization).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提取步骤从你拥有的原始数据开始。然后构建派生变量/值（特征），这些特征应该能够为学习任务提供信息，并促进接下来的学习和评估（泛化）步骤。
- en: Some tasks will have a vast number of features and fewer training samples (observations)
    to facilitate the subsequent learning and generalization processes. In such cases,
    data scientists use dimensionality reduction techniques to reduce the vast number
    of features to a smaller set.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一些任务会有大量的特征和较少的训练样本（观测数据），这会影响后续的学习和泛化过程。在这种情况下，数据科学家使用降维技术将大量特征减少到一个较小的集合。
- en: Noise
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 噪声
- en: In the fish recognition task, you can see that the length, weight, fish color,
    as well as the boat color may vary, and there could be shadows, images with low
    resolution, and other objects in the image. All these issues affect the significance
    of the proposed explanatory features that should be informative about our fish
    classification task.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在鱼类识别任务中，你可以看到长度、重量、鱼的颜色以及船的颜色可能会有所不同，而且可能会有阴影、分辨率低的图像以及图像中的其他物体。所有这些问题都会影响我们提出的解释性特征的重要性，这些特征应该能为我们的鱼类分类任务提供信息。
- en: Work-arounds will be helpful in this case. For example, someone might think
    of detecting the boat ID and mask out certain parts of the boat that most likely
    won't contain any fish to be detected by our system. This work-around will limit
    our search space.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，解决方法将会很有帮助。例如，有人可能会想到检测船只的ID，并遮蔽出船上可能不会包含任何鱼的部分，以便我们的系统进行检测。这个解决方法会限制我们的搜索空间。
- en: Overfitting
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过拟合
- en: As we have seen in our fish recognition task, we have tried to enhance our model's
    performance by increasing the model complexity and perfectly classifying every
    single instance of the training samples. As we will see later, such models do
    not work over unseen data (such as the data that we will use for testing the performance
    of our model). Having trained models that work perfectly over the training samples
    but fail to perform well over the testing samples is called **overfitting**.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在鱼类识别任务中看到的，我们曾通过增加模型复杂度并完美地分类训练样本中的每一个实例来提高模型的表现。正如我们稍后将看到的，这种模型在未见过的数据（例如我们将用于测试模型表现的数据）上并不起作用。训练的模型在训练样本上表现完美，但在测试样本上表现不佳，这种现象称为**过拟合**。
- en: If you sift through the latter part of the chapter, we build a learning system
    with an objective to use the training samples as a knowledge base for our model
    in order to learn from it and generalize over the unseen data. Performance error
    of the trained model is of no interest to us over the training data; rather, we
    are interested in the performance (generalization) error of the trained model
    over the testing samples that haven't been involved in the training phase.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你浏览章节的后半部分，我们将构建一个学习系统，目的是将训练样本作为模型的知识库，让模型从中学习并对未见过的数据进行泛化。我们对训练数据上训练模型的表现误差不感兴趣；相反，我们关心的是训练模型在没有参与训练阶段的测试样本上的表现（泛化）误差。
- en: Selection of a machine learning algorithm
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习算法的选择
- en: Sometimes you are unsatisfied with the execution of the model that you have
    utilized for a particular errand and you need an alternate class of models. Each
    learning strategy has its own presumptions about the information it will utilize
    as a learning base. As an information researcher, you have to discover which suspicions
    will fit your information best; by this you will have the capacity to acknowledge
    to attempt a class of models and reject another.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，你对模型的执行结果不满意，需要切换到另一类模型。每种学习策略都有自己的假设，关于它将使用哪些数据作为学习基础。作为数据科学家，你需要找出哪种假设最适合你的数据；通过这样，你就能够决定尝试某一类模型并排除其他类。
- en: Prior knowledge
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 先验知识
- en: 'As discussed in the concepts of model selection and feature extraction, the
    two issues can be dealt with, if you have prior knowledge about:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在模型选择和特征提取的概念中讨论的那样，如果你有先验知识，两个问题都可以得到解决：
- en: The appropriate feature
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适当的特征
- en: Model selection parts
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型选择部分
- en: Having prior knowledge of the explanatory features in the fish recognition system
    enabled us to differentiate amid different types of fish. We can go promote by
    endeavoring to envision our information and get some feeling of the information
    types of the distinctive fish classifications. On the basis of this  prior knowledge,
    apt family of models can be chosen.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有鱼类识别系统的解释性特征的先验知识，使我们能够区分不同种类的鱼。我们可以通过尝试可视化我们的数据，获得不同鱼类分类数据类型的感性认识。在此基础上，可以选择合适的模型家族进行进一步探索。
- en: Missing values
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺失值
- en: Missing features mainly occur because of a lack of data or choosing the prefer-not-to-tell
    option. How can we handle such a case in the learning process? For example, imagine
    we find the width of specific a fish type is missing for some reason. There are
    many ways to handle these missing features.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失特征主要是由于数据不足或选择了“不愿透露”选项。我们如何在学习过程中处理这种情况呢？例如，假设由于某种原因，我们发现某种特定鱼类的宽度数据缺失。处理这些缺失特征的方法有很多种。
- en: Implementing the fish recognition/detection model
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现鱼类识别/检测模型
- en: To introduce the power of machine learning and deep learning in particular,
    we are going to implement the fish recognition example. No understanding of the
    inner details of the code will be required. The point of this section is to give
    you an overview of a typical machine learning pipeline.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示机器学习特别是深度学习的力量，我们将实现鱼类识别的例子。你不需要理解代码的内部细节。本节的目的是给你提供一个典型机器学习流程的概览。
- en: Our knowledge base for this task will be a bunch of images, each one of them
    is labeled as opah or tuna. For this implementation, we are going to use one of
    the deep learning architectures that made a breakthrough in the area of imaging
    and computer vision in general. This architecture is called **Convolution Neural
    Networks** (**CNNs**). It is a family of deep learning architectures that use
    the convolution operation of image processing to extract features from the images
    that can explain the object that we want to classify. For now, you can think of
    it as a magic box that will take our images, learn from it how to distinguish
    between our two classes (opah and tuna), and then we will test the learning process
    of this box by feeding it with unlabeled images and see if it's able to tell which
    type of fish is in the image.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的知识库将是一些图片，每张图片都被标记为 opah 或 tuna。为了实现这一目标，我们将使用一种在图像处理和计算机视觉领域取得突破的深度学习架构。这种架构被称为**卷积神经网络**（**CNNs**）。它是一个深度学习架构的家族，利用图像处理中的卷积操作从图片中提取特征，从而解释我们想要分类的物体。现在，你可以把它想象成一个神奇的盒子，它会接收我们的图片，学习如何区分我们的两类鱼（opah
    和 tuna），然后通过喂入未标记的图片来测试这个盒子的学习过程，看看它是否能够识别出图片中的鱼类。
- en: Different types of learning will be addressed in a later section, so you will
    understand later on why our fish recognition task is under the supervised learning
    category.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的学习将在后面的章节中讨论，因此你将会理解为什么我们的鱼类识别任务属于监督学习类别。
- en: 'In this example, we will be using Keras. For the moment, you can think of Keras
    as an API that makes building and using deep learning way easier than usual. So
    let''s get started! From the Keras website we have:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用 Keras。目前，你可以将 Keras 看作一个API，它使得构建和使用深度学习比以往更加简单。所以，让我们开始吧！从 Keras
    网站上，我们可以看到：
- en: Keras is a high-level neural networks API, written in Python and capable of
    running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on
    enabling fast experimentation. *Being able to go from idea to result with the
    least possible delay is key to doing good research.*
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 是一个高级神经网络 API，使用 Python 编写，并能够运行在 TensorFlow、CNTK 或 Theano 上。它的开发重点是使快速实验成为可能。*能够在最短的时间内从想法到结果是做出优秀研究的关键。*
- en: Knowledge base/dataset
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 知识库/数据集
- en: 'As we mentioned earlier, we need a historical base of data that will be used
    to teach the learning algorithm about the task that it''s supposed to do later.
    But we also need another dataset for testing its ability to perform the task after
    the learning process. So to sum up, we need two types of datasets during the learning
    process:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，我们需要一个历史数据集，用来教导学习算法完成它之后应执行的任务。但我们还需要另一个数据集来测试学习过程后它执行任务的能力。总而言之，在学习过程中我们需要两种类型的数据集：
- en: The first one is the knowledge base where we have the input data and their corresponding
    labels such as the fish images and their corresponding labels (opah or tuna).
    This data will be fed to the learning algorithm to learn from it and try to discover
    the patterns/trends that will help later on for classifying unlabeled images.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个是知识库，我们在其中拥有输入数据及其对应的标签，比如鱼的图像及其对应的标签（opah 或 tuna）。这些数据将被输入到学习算法中，供其学习并尝试发现将来有助于分类未标记图像的模式/趋势。
- en: The second one is mainly for testing the ability of the model to apply what
    it learned from the knowledge base to unlabeled images or unseen data, in general,
    and see if it's working well.
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个阶段主要是测试模型应用从知识库中学到的知识，处理未标记的图像或未见过的数据（通常是），并查看它是否表现良好。
- en: As you can see, we only have the data that we will use as a knowledge base for
    our learning method. All of the data we have at hand will have the correct output
    associated with it. So we need to somehow make up this data that does not have
    any correct output associated with it (the one that we are going to apply the
    model to).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们只有将作为学习方法的知识库使用的数据。我们手头所有的数据都将与正确的输出关联。因此，我们需要想办法生成这些没有正确输出关联的数据（即我们将应用模型的数据）。
- en: 'While performing data science, we''ll be doing the following:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行数据科学时，我们将进行以下操作：
- en: '**Training phase**: We present our data from our knowledge base and train our
    learning method/model by feeding the input data along with its correct output
    to the model.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练阶段**：我们从知识库中呈现我们的数据，并通过将输入数据及其正确输出输入到模型中来训练我们的学习方法/模型。'
- en: '**Validation/test phase**: In this phase, we are going to measure how well
    the trained model is doing. We also use different model property techniques in
    order to measure the performance of our trained model by using (R-square score
    for regression, classification errors for classifiers, recall and precision for
    IR models, and so on).'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证/测试阶段**：在此阶段，我们将衡量训练好的模型表现如何。我们还使用不同的模型属性技术，通过使用（回归的 R-squared 分数、分类器的分类错误、信息检索模型的召回率和精确度等）来衡量我们训练模型的性能。'
- en: 'The validation/test phase is usually split into two steps:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 验证/测试阶段通常分为两个步骤：
- en: In the first step, we use different learning methods/models and choose the best
    performing one based on our validation data (validation step)
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一步中，我们使用不同的学习方法/模型，并根据验证数据（验证步骤）选择表现最好的那个。
- en: Then we measure and report the accuracy of the selected model based on the test
    set (test step)
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们根据测试集（测试步骤）来衡量并报告所选模型的准确性。
- en: Now let's see how we get this data to which we are going to apply the model
    and see how well trained it is.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何获得这些我们将应用模型的数据，并查看模型训练得如何。
- en: 'Since we don''t have any training samples without the correct output, we can
    make up one from the original training samples that we will be using. So we can
    split our data samples into three different sets (as shown in *Figure 1.9*):'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有没有正确输出的训练样本，我们可以从将要使用的原始训练样本中生成一个。因此，我们可以将我们的数据样本拆分为三组（如 *图 1.9* 所示）：
- en: '**Train set**: This will be used as a knowledge base for our model. Usually,
    will be 70% from the original data samples.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练集**：这将作为我们模型的知识库。通常来自原始数据样本的 70%。'
- en: '**Validation set**: This will be used to choose the best performing model among
    a set of models. Usually this will be 10% of the original data samples.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证集**：这将用于在一组模型中选择表现最好的模型。通常，这将是原始数据样本的 10%。'
- en: '**Test set**: This will be used to measure and report the accuracy of the selected
    model. Usually, it will be as big as the validation set.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试集**：将用于衡量和报告所选模型的准确性。通常，它的大小与验证集相当。'
- en: '![](img/179a8f28-814b-41cc-bae1-e8629f3dac1a.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/179a8f28-814b-41cc-bae1-e8629f3dac1a.png)'
- en: 'Figure 1.9: Splitting data into train, validation, and test sets'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.9：将数据分割为训练集、验证集和测试集
- en: In case you have only one learning method that you are using, you can cancel
    the validation set and re-split your data to be train and test sets only. Usually,
    data scientists use 75/25 as percentages, or 70/30.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只使用一个学习方法，可以取消验证集，将数据重新分割为仅训练集和测试集。通常，数据科学家使用 75/25 或 70/30 的比例划分数据。
- en: Data analysis pre-processing
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析预处理
- en: In this section we are going to analyze and preprocess the input images and
    have it in an acceptable format for our learning algorithm, which is the convolution
    neural networks here.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将分析并预处理输入图像，并将其转换为适合我们学习算法的可接受格式，这里使用的是卷积神经网络（CNN）。
- en: 'So let''s start off by importing the required packages for this implementation:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们从导入实现所需的包开始：
- en: '[PRE2]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In order to use the images provided in the dataset, we need to get them to
    have the same size. OpenCV is a good choice for doing this, from the OpenCV website:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用数据集中提供的图像，我们需要将它们调整为相同的大小。OpenCV 是一个很好的选择，详情请见 OpenCV 官网：
- en: OpenCV (Open Source Computer Vision Library) is released under a BSD license
    and hence it’s free for both academic and commercial use. It has C++, C, Python
    and Java interfaces and supports Windows, Linux, Mac OS, iOS and Android. OpenCV
    was designed for computational efficiency and with a strong focus on real-time
    applications. Written in optimized C/C++, the library can take advantage of multi-core
    processing. Enabled with OpenCL, it can take advantage of the hardware acceleration
    of the underlying heterogeneous compute platform.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV（开源计算机视觉库）是根据 BSD 许可证发布的，因此它对学术和商业使用都是免费的。它支持 C++、C、Python 和 Java 接口，并支持
    Windows、Linux、Mac OS、iOS 和 Android 操作系统。OpenCV 设计时注重计算效率，并且强烈关注实时应用。它是用优化的 C/C++
    编写的，可以利用多核处理。启用了 OpenCL 后，它能够利用底层异构计算平台的硬件加速。
- en: You can install OpenCV by using the python package manager by issuing, `pip
    install` `opencv-python`
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用 Python 包管理器安装 OpenCV，命令为 `pip install` `opencv-python`
- en: '[PRE5]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now we need to load all the training samples of our dataset and resize each
    image, according to the previous function. So we are going to implement a function
    that will load the training samples from the different folders that we have for
    each fish type:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要加载数据集中的所有训练样本，并根据之前的函数调整每张图像的大小。所以我们将实现一个函数，从我们为每种鱼类类型准备的不同文件夹中加载训练样本：
- en: '[PRE6]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'As we discussed, we have a test set that will act as the unseen data to test
    the generalization ability of our model. So we need to do the same with testing
    images; load them and do the resizing processing:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们讨论的，我们有一个测试集，它将充当未见数据，以测试我们模型的泛化能力。因此，我们需要对测试图像做同样的处理；加载它们并进行调整大小处理：
- en: '[PRE7]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now we need to invoke the previous function into another one that will use
    the `load_training_samples()` function in order to load and resize the training
    samples. Also, it will add a few lines of code to convert the training data into
    NumPy format, reshape that data to fit into our classifier, and finally convert
    it to float:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要将之前的函数调用到另一个函数中，后者将使用 `load_training_samples()` 函数来加载并调整训练样本的大小。它还会增加几行代码，将训练数据转换为
    NumPy 格式，重新调整数据形状以适应我们的分类器，最后将其转换为浮动格式：
- en: '[PRE8]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We also need to do the same with the test:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也需要对测试进行相同的处理：
- en: '[PRE9]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Model building
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型构建
- en: Now it's time to create the model. As we mentioned, we are going to use a deep
    learning architecture called CNN as a learning algorithm for this fish recognition
    task. Again, you are not required to understand any of the previous or the upcoming
    code in this chapter as we are only demonstrating how complex data science tasks
    can be solved by using only a few lines of code with the help of Keras and TensorFlow
    as a deep learning platform.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是创建模型的时候了。正如我们所提到的，我们将使用一种深度学习架构叫做 CNN 作为此鱼类识别任务的学习算法。再次提醒，你不需要理解本章之前或之后的任何代码，因为我们仅仅是演示如何使用少量代码，借助
    Keras 和 TensorFlow 深度学习平台来解决复杂的数据科学任务。
- en: 'Also note that CNN and other deep learning architectures will be explained
    in greater detail in later chapters:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，CNN 和其他深度学习架构将在后续章节中更详细地解释：
- en: '![](img/ef917a6b-5415-4d98-8da6-070ebbdbd663.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef917a6b-5415-4d98-8da6-070ebbdbd663.png)'
- en: 'Figure 1.10: CNN architecture'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.10：CNN架构
- en: 'So let''s go ahead and create a function that will be responsible for creating
    the CNN architecture that will be used in our fish recognition task:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们继续创建一个函数，负责构建将在鱼类识别任务中使用的CNN架构：
- en: '[PRE10]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Before starting to train the model, we need to use a model assessment and validation
    method to help us assess our model and see its generalization ability. For this,
    we are going to use a method called **k-fold cross-validation**. Again, you are
    not required to understand this method or how it works as we are going to explain
    this method later in much detail.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练模型之前，我们需要使用一种模型评估和验证方法，帮助我们评估模型并查看其泛化能力。为此，我们将使用一种叫做**k折交叉验证**的方法。同样，您不需要理解这个方法或它是如何工作的，因为我们稍后将详细解释这一方法。
- en: 'So let''s start and and create a function that will help us assess and validate
    the model:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们开始创建一个帮助我们评估和验证模型的函数：
- en: '[PRE11]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now, after building the model and using k-fold cross-validation method in order
    to assess and validate the model, we need to report the results of the trained
    model over the test set. In order to do this, we are also going to use k-fold
    cross-validation but this time over the test to see how good our trained model
    is.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在构建模型并使用k折交叉验证方法来评估和验证模型之后，我们需要报告训练模型在测试集上的结果。为此，我们也将使用k折交叉验证，但这次是在测试集上进行，看看我们训练好的模型有多好。
- en: 'So let''s define the function that will take the trained CNN models as an input
    and then test them using the test set that we have:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们定义一个函数，该函数将以训练好的CNN模型为输入，然后使用我们拥有的测试集对其进行测试：
- en: '[PRE12]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Model training and testing
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练与测试
- en: 'Now we are ready to start the model training phase by calling the main function
    `create_model_with_kfold_cross_validation()` for building and training the CNN
    model using 10-fold cross-validation; then we can call the testing function to
    measure the model''s ability to generalize to the test set:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备通过调用主函数`create_model_with_kfold_cross_validation()`来开始模型训练阶段，该函数用于通过10折交叉验证构建并训练CNN模型；然后我们可以调用测试函数来衡量模型对测试集的泛化能力：
- en: '[PRE13]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Fish recognition – all together
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 鱼类识别——全部一起
- en: After explaining the main building blocks for our fish recognition example,
    we are ready to see all the code pieces connected together and see how we managed
    to build such a complex system with just a few lines of code. The full code is
    placed in the *Appendix* section of the book.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在解释了我们鱼类识别示例的主要构建模块之后，我们准备将所有代码片段连接起来，并查看我们如何通过几行代码构建如此复杂的系统。完整的代码可以在本书的*附录*部分找到。
- en: Different learning types
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不同的学习类型
- en: According to Arthur Samuel ([https://en.wikipedia.org/wiki/Arthur_Samuel](https://en.wikipedia.org/wiki/Arthur_Samuel)),
    *data science gives computers the ability to learn without being explicitly programmed*.
    So, any piece of software that will consume training examples in order to make
    decisions over unseen data without explicit programming is considered learning.
    Data science or learning comes in three different forms.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Arthur Samuel的说法（[https://en.wikipedia.org/wiki/Arthur_Samuel](https://en.wikipedia.org/wiki/Arthur_Samuel)），*数据科学赋予计算机在不需要显式编程的情况下学习的能力*。因此，任何能够使用训练样本做出决策并处理未见数据的程序，都被认为是学习。数据科学或学习有三种不同的形式。
- en: 'Figure 1.12 shows the commonly used types of data science/machine learning:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.12 展示了常用的数据科学/机器学习类型：
- en: '![](img/a11e2872-d4cf-49b7-bb27-ba07b7ab1fa8.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a11e2872-d4cf-49b7-bb27-ba07b7ab1fa8.png)'
- en: 'Figure 1.12: Different types of data science/machine learning.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.12：数据科学/机器学习的不同类型。
- en: Supervised learning
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监督学习
- en: 'The majority of data scientists use supervised learning. Supervised learning
    is where you have some explanatory features, which are called input variables
    (*X*), and you have the labels that are associated with the training samples,
    which are called output variables (*Y*). The objective of any supervised learning
    algorithm is to learn the mapping function from the input variables (*X*) to the
    output variables (*Y*):'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据科学家使用监督学习。监督学习是指您有一些解释性特征，称为输入变量(*X*)，并且您有与训练样本相关联的标签，称为输出变量(*Y*)。任何监督学习算法的目标都是学习从输入变量(*X*)到输出变量(*Y*)的映射函数：
- en: '![](img/103d2d2d-9b0c-4c73-bef8-bdc975e1be87.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/103d2d2d-9b0c-4c73-bef8-bdc975e1be87.png)'
- en: So the supervised learning algorithm will try to learn approximately the mapping
    from the input variables (*X*) to the output variables (*Y*), such that it can
    be used later to predict the *Y* values of an unseen sample.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有监督学习算法将尝试学习输入变量（*X*）到输出变量（*Y*）的映射关系，以便以后可以用来预测未见样本的*Y*值。
- en: '*Figure 1.13* shows a typical workflow for any supervised data science system:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.13* 显示了任何有监督数据科学系统的典型工作流：'
- en: '![](img/44109720-d5a2-4f63-a905-809aa5261c5a.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](img/44109720-d5a2-4f63-a905-809aa5261c5a.png)'
- en: 'Figure 1.13: A typical supervised learning workflow/pipeline. The top part
    shows the training process that starts with feeding the raw data into a feature
    extraction module where we will select meaningful explanatory feature to represent
    our data. After that, the extracted/selected explanatory feature gets combined
    with the training set and we feed it to the learning algorithm in order to learn
    from it. Then we do some model evaluation to tune the parameters and get the learning
    algorithm to get the best out of the data samples.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.13：一个典型的有监督学习工作流/流程。上部分显示了训练过程，首先将原始数据输入到特征提取模块，我们将在此选择有意义的解释性特征来表示数据。之后，提取/选择的解释性特征与训练集结合，并将其输入到学习算法中以便从中学习。接着，我们进行模型评估，以调整参数并使学习算法从数据样本中获得最佳效果。
- en: This kind of learning is called **supervised learning** because you are getting
    the label/output of each training sample associated with it. In this case, we
    can say that the learning process is supervised by a supervisor. The algorithm
    makes decisions on the training samples and is corrected by the supervisor, based
    on the correct labels of the data. The learning process will stop when the supervised
    learning algorithm achieves an acceptable level of accuracy.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这种学习被称为**有监督学习**，因为你会为每个训练样本提供标签/输出。在这种情况下，我们可以说学习过程受到监督者的指导。算法根据训练样本做出决策，并根据数据的正确标签由监督者进行纠正。当有监督学习算法达到可接受的准确度时，学习过程就会停止。
- en: 'Supervised learning tasks come in two different forms; regression and classification:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 有监督学习任务有两种不同的形式；回归和分类：
- en: '**Classification**: A classification task is when the label or the output variable
    is a category, such as *tuna* or *Opah* or *spam* and *non spam*'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：分类任务是当标签或输出变量是一个类别时，例如*tuna*或*Opah*或*垃圾邮件*和*非垃圾邮件*。'
- en: '**Regression**: A regression task is when the output variable is a real value,
    such as *house prices* or *height*'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**：回归任务是当输出变量是一个实际值时，例如*房价*或*身高*。'
- en: Unsupervised learning
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Unsupervised learning is viewed as the second most common kind of learning that
    is utilized by information researchers. In this type of learning, only the explanatory
    features or the input variables (*X*) are given, without any corresponding label
    or output variable.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习被认为是信息科学家使用的第二大常见学习类型。在这种学习中，只有解释性特征或输入变量（*X*）被给定，而没有任何对应的标签或输出变量。
- en: The target of unsupervised learning algorithms is to take in the hidden structures
    and examples in the information. This kind of learning is called **unsupervised**
    in light of the fact that there aren't marks related with the training samples.
    So it's a learning procedure without corrections, and the algorithm will attempt
    to find the basic structure on its own.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习算法的目标是获取数据中的隐藏结构和模式。这种学习被称为**无监督**，因为训练样本没有相关的标签。因此，这是一种没有指导的学习过程，算法会尝试自行发现基本结构。
- en: 'Unsupervised learning can be further broken into two forms—clustering and association
    tasks:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习可以进一步分为两种形式——聚类任务和关联任务：
- en: '**Clustering**: A clustering task is where you want to discover similar groups
    of training samples and group them together, such as grouping documents by topic'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**：聚类任务是你想要发现相似的训练样本组并将它们归为一类，例如按主题对文档进行分组。'
- en: '**Association**: An association rule learning task is where you want to discover
    some rules that describe the relationships in your training samples, such as people
    who watch movie *X* also tend to watch movie *Y*'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关联**：关联规则学习任务是你想要发现一些描述训练样本之间关系的规则，例如，喜欢看电影*X*的人通常也会看电影*Y*。'
- en: '*Figure 1.14* shows a trivial example of unsupervised learning where we have
    got scattered documents and we are trying to group *similar* ones together:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.14* 显示了一个无监督学习的简单例子，其中我们有散乱的文档，并试图将*相似*的文档聚在一起：'
- en: '![](img/4871de97-c0c1-4780-b921-56c7a8663f2e.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4871de97-c0c1-4780-b921-56c7a8663f2e.png)'
- en: 'Figure 1.14: Shows how unsupervised use similarity measure such as Euclidean
    distance to group similar documents to together and draw a decision boundaries
    for them'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.14：展示了无监督学习如何使用相似度度量（如欧几里得距离）将相似的文档聚集在一起，并为它们绘制决策边界。
- en: Semi-supervised learning
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 半监督学习
- en: Semi-supervised learning is a type of learning that sits in between supervised
    and unsupervised learning, where you have got training examples with input variables
    (*X*), but only some of them are labeled/tagged with the output variable (*Y*).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习是一种介于有监督学习和无监督学习之间的学习方式，在这种方式中，你有带输入变量（*X*）的训练样本，但只有一部分样本带有输出变量（*Y*）的标签。
- en: A good example of this type of learning is Flickr ([https://www.flickr.com/](https://www.flickr.com/)),
    where you have got lots of images uploaded by users but only some of them are
    labeled (such as sunset, ocean, and dog) and the rest are unlabeled.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这种学习方式的一个好例子是Flickr ([https://www.flickr.com/](https://www.flickr.com/))，在这里，用户上传了大量的图片，但只有一部分是带标签的（例如：日落、海洋和狗），其余的则没有标签。
- en: 'To solve the tasks that fall into this type of learning, you can use one of
    the following or a combination of them:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决属于这种类型的学习任务，你可以使用以下方法之一，或者它们的组合：
- en: '**Supervised learning**: Learn/train the learning algorithm to give predictions
    about the unlabeled data and then feed the entire training samples back to learn
    from it and predict the unseen data'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有监督学习**：学习/训练学习算法，针对未标记的数据进行预测，然后将所有训练样本反馈给算法，让其从中学习并预测未见过的数据。'
- en: '**Unsupervised learning**: Use the unsupervised learning algorithms to learn
    the underlying structure of the explanatory features or the input variables as
    if you don''t have any tagged training samples'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**：使用无监督学习算法来学习解释性特征或输入变量的潜在结构，就好像你没有任何标记的训练样本一样。'
- en: Reinforcement learning
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 强化学习
- en: The last type of learning in machine learning is reinforcement learning, in
    which there's no supervisor but only a reward signal.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的最后一种学习类型是强化学习，在这种学习方式中没有监督者，只有奖励信号。
- en: So the reinforcement learning algorithm will try to make a decision and then
    a reward signal will be there to tell whether this decision is right or wrong.
    Also, this supervision feedback or reward signal may not come instantaneously
    but get delayed for a few steps. For example, the algorithm will take a decision
    now, but only after many steps will the reward signal tell whether decision was
    good or bad.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，强化学习算法将尝试做出决策，然后奖励信号会告诉我们这个决策是否正确。此外，这种监督反馈或奖励信号可能不会立即到来，而是会延迟几步。例如，算法现在做出决策，但只有在多步之后，奖励信号才会告诉我们这个决策是好是坏。
- en: Data size and industry needs
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据规模与行业需求
- en: Data is the information base of our learning calculations; any uplifting and
    imaginative thoughts will be nothing with the absence of information. So in the
    event that you have a decent information science application with the right information,
    at that point you are ready to go.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是我们学习计算的基础；没有数据，任何激励和富有创意的想法都将毫无意义。因此，如果你有一个好的数据科学应用程序，并且数据正确，那么你就已经准备好开始了。
- en: Having the capacity to investigate and extricate an incentive from your information
    is obvious these days notwithstanding to the structure of your information, however
    since enormous information is turning into the watchword of the day then we require
    information science apparatuses and advancements that can scale with this immense
    measure of information in an unmistakable learning time. These days everything
    is producing information and having the capacity to adapt to it is a test. Huge
    organizations, for example, Google, Facebook, Microsoft, IBM, and so on, manufacture
    their own adaptable information science arrangements keeping in mind the end goal
    to deal with the tremendous amount of information being produced once a day by
    their clients.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 具备从数据中分析和提取价值的能力在当今时代已经变得显而易见，尽管这取决于数据的结构，但由于大数据正成为当今的流行词汇，我们需要能够与如此庞大的数据量相匹配并在明确的学习时间内进行处理的数据科学工具和技术。如今，一切都在产生数据，能够应对这些数据已成为一项挑战。像谷歌、Facebook、微软、IBM等大型公司都在构建自己的可扩展数据科学解决方案，以应对客户每天产生的大量数据。
- en: TensorFlow, is a machine intelligence/data science platform that was released
    as an open source library on November 9, 2016 by Google. It is a scalable analytics
    platform that enables data scientists to build complex systems with a vast amount
    of data in visible time and it also enables them to use greedy learning methods
    that require lots of data to get a good performance.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是一个机器智能/数据科学平台，于2016年11月9日由谷歌发布为开源库。它是一个可扩展的分析平台，使数据科学家能够利用大量数据在可视化的时间内构建复杂的系统，并且它还使得他们能够使用需要大量数据才能取得良好性能的贪心学习方法。
- en: Summary
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we went through building a learning system for fish recognition;
    we also saw how we can build complex applications, such as fish recognition, using
    a few lines of code with the help of TensorFlow and Keras. This coding example
    was not meant to be understood from your side, rather to demonstrate the visibility
    of building complex systems and how data science in general and specifically deep
    learning became an easy-to-use tool.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讲解了如何构建鱼类识别的学习系统；我们还展示了如何利用TensorFlow和Keras，通过几行代码构建复杂的应用程序，如鱼类识别。这个编程示例并非要你理解其中的代码，而是为了展示构建复杂系统的可视化过程，以及数据科学，特别是深度学习，如何成为一种易于使用的工具。
- en: We saw the challenges that you might encounter in your daily life as a data
    scientist while building a learning system.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到，在构建学习系统时，作为数据科学家，你可能会遇到的挑战。
- en: We also looked at the typical design cycle for building a learning system and
    explained the overall idea of each component involved in this cycle.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还了解了构建学习系统的典型设计周期，并解释了参与该周期的每个组件的整体概念。
- en: Finally, we went through different learning types, having big data generated
    daily by big and small companies, and how this vast amount of data raises a red
    alert to build scalable tools to be able to analyze and extract value from this
    data.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们讲解了不同的学习类型，探讨了大大小小公司每天生成的大数据，以及这些海量数据如何引发警报，迫使我们构建可扩展的工具，以便能够分析和从这些数据中提取价值。
- en: At this point, the reader may be overwhelmed by all the information mentioned
    so far, but most of what we explained in this chapter will be addressed in other
    chapters, including data science challenges and the fish recognition example.
    The whole purpose of this chapter was to get an overall idea about data science
    and its development cycle, without any deep understanding of the challenges and
    the coding example. The coding example was mentioned in this chapter to break
    the fear of most newcomers in the field of data science and show them how complex
    systems such as fish recognition can be done in a few lines of code.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，读者可能会被目前为止提到的所有信息所压倒，但本章中大部分内容将在其他章节中展开，包括数据科学挑战和鱼类识别示例。本章的整体目的是让读者对数据科学及其发展周期有一个总体的了解，而不需要深入理解挑战和编码示例。编程示例在本章中提到的目的是为了打破大多数数据科学新手的恐惧感，并向他们展示像鱼类识别这样复杂的系统如何仅用几行代码就能实现。
- en: Next up, we will start our *by example* journey, by addressing the basic concepts
    of data science through an example. The next part will mainly focus on preparing
    you for the later advanced chapters, by going through the famous Titanic example.
    Lots of concepts will be addressed, including different learning methods for regression
    and classification, different types of performance errors and which one to care
    about most, and more about tackling some of the data science challenges and handling
    different forms of the data samples.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将开始我们的*通过示例*之旅，通过一个示例来讲解数据科学的基本概念。接下来的部分将主要专注于为后续的高级章节做准备，通过著名的泰坦尼克号示例来进行讲解。我们将涉及许多概念，包括回归和分类的不同学习方法、不同类型的性能误差以及我们应该关注哪些误差，以及更多关于解决数据科学挑战和处理不同形式数据样本的内容。
