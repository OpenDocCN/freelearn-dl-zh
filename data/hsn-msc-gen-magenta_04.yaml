- en: Generating Drum Sequences with the Drums RNN
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Drums RNN生成鼓序列
- en: In this chapter, you'll learn what many consider the foundation of music—percussion.
    We'll show the importance of **Recurrent Neural Networks** (**RNNs**) for music
    generation. You'll then learn how to use the Drums RNN model using a pre-trained
    drum kit model, by calling it in the command-line window and directly in Python,
    to generate drum sequences. We'll introduce the different model parameters, including
    the model's MIDI encoding, and show how to interpret the output of the model.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，你将学习到许多人认为音乐的基础——打击乐。我们将展示**递归神经网络**（**RNNs**）在音乐生成中的重要性。然后，你将学习如何使用预训练的鼓套件模型，调用它在命令行窗口中以及直接在Python中使用Drums
    RNN模型，来生成鼓序列。我们将介绍不同的模型参数，包括模型的MIDI编码，并展示如何解读模型的输出。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The significance of RNNs in music generation
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RNN在音乐生成中的重要性
- en: Using the Drums RNN in the command line
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在命令行中使用Drums RNN
- en: Using the Drums RNN in Python
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Python中使用Drums RNN
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we''ll use the following tools:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下工具：
- en: The **command line** or **bash** to launch Magenta from the Terminal
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**命令行**或**bash**从终端启动Magenta
- en: '**Python** and its libraries to write music generation code using Magenta'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Python**及其库来编写使用Magenta生成音乐的代码
- en: '**Magenta** to generate music in MIDI'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**Magenta**生成MIDI格式的音乐
- en: '**MuseScore** or **FluidSynth** to listen to the generated MIDI'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**MuseScore**或**FluidSynth**来听生成的MIDI
- en: In Magenta, we'll make the use of the **Drums RNN** model. We'll be explaining
    this model in depth, but if you feel like you need more information, the model's
    README in Magenta's source code ([github.com/tensorflow/magenta/tree/master/magenta/models/drums_rnn](https://github.com/tensorflow/magenta/tree/master/magenta/models/drums_rnn))
    is a good place to start. You can also take a look at Magenta's code on GitHub,
    which is well documented. We also provide additional content in the last section,
    *Further reading*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在Magenta中，我们将使用**Drums RNN**模型。我们将深入解释这个模型，但如果你觉得需要更多信息，Magenta源代码中的模型README（[github.com/tensorflow/magenta/tree/master/magenta/models/drums_rnn](https://github.com/tensorflow/magenta/tree/master/magenta/models/drums_rnn)）是一个很好的起点。你也可以查看Magenta的GitHub代码，它有很好的文档。我们还在最后一节提供了额外的内容，*进一步阅读*。
- en: The code for this chapter is in this book's GitHub repository in the `Chapter02`
    folder, located at [github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter02](https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter02).
    For this chapter, you should run `cd Chapter02` in the command-line window before
    you start.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码位于本书的GitHub仓库中的`Chapter02`文件夹，位置在[github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter02](https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter02)。对于本章，你应该在命令行窗口中运行`cd
    Chapter02`，然后再开始。
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，查看代码如何运作：
- en: '[http://bit.ly/37G0mmW](http://bit.ly/37G0mmW)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/37G0mmW](http://bit.ly/37G0mmW)'
- en: The significance of RNNs in music generation
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RNN在音乐生成中的重要性
- en: Specific neural network architectures are designed for specific problems. It
    doesn't mean that one architecture is better than another one—it just means it
    is better at a specific task.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 特定的神经网络架构是为特定问题设计的。这并不意味着某一种架构比另一种更好——它只是更适合某一特定任务。
- en: In this section, we'll be looking at our specific problem, generating music,
    and see why RNNs are well suited for the task. We'll be building our knowledge
    of neural network architectures for music throughout this book, by introducing
    specific concepts in each chapter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将关注我们特定的问题——生成音乐，并了解为什么RNN非常适合这项任务。在本书中，我们将通过每一章介绍特定的概念，逐步构建关于音乐的神经网络架构的知识。
- en: For music generation, we are looking at two specific problems that RNNs solve—operating
    on sequences in terms of input and output and keeping an internal state of past
    events. Let's have a look at those properties.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对于音乐生成，我们关注的是RNN解决的两个具体问题——在输入和输出方面处理序列，以及保持过去事件的内部状态。让我们来看看这些特性。
- en: Musical score prediction is analogous to generating music. By predicting the
    next notes from an input sequence, you can iteratively generate a new sequence
    by choosing a prediction at each iteration. This process is described in the *Understanding
    the generation algorithm* section in this chapter.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 音乐谱预测类似于生成音乐。通过预测输入序列中的下一个音符，你可以通过在每次迭代中选择预测来逐步生成一个新的序列。这个过程在本章的*理解生成算法*部分进行了描述。
- en: Operating on a sequence of vectors
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作一个向量序列
- en: In many neural net architectures, **input size** and **output size** are fixed.
    Take a **Convolutional Neural Network** (**CNN**), for example. This neural net
    can be used for image classification, with the input being an array of pixels
    representing the image and the output the prediction for each element of a set
    of classes (for example, "cat," "dog," and so on). Notice the input and output
    are of fixed size.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多神经网络架构中，**输入大小**和**输出大小**是固定的。以**卷积神经网络**（**CNN**）为例。该神经网络可用于图像分类，输入是表示图像的像素数组，输出则是每个类别集的预测（例如，“猫”，“狗”等）。请注意，输入和输出的大小是固定的。
- en: What is nice about RNNs is that input and output size can be of arbitrary lengths.
    For a music score prediction network, an input could be an arbitrary length sequence
    of notes, and the output could be a sequence of predicted notes from that input.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: RNN的优点在于输入和输出的大小可以是任意长度。对于音乐谱预测网络，输入可以是一个任意长度的音符序列，输出则是基于该输入的预测音符序列。
- en: 'This is possible in an RNN because it works on a **sequence** of vectors. There
    are many ways of representing RNN types:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这在RNN中是可能的，因为它是基于**序列**向量进行操作的。表示RNN类型的方式有很多：
- en: '**One**-**to**-**one**: This is where there''s fixed input and output; an example
    is image classification.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一**-**对**-**一**：在这里，有固定输入和输出；一个例子是图像分类。'
- en: '**One**-**to**-**many**: This is where there''s fixed input to sequence output;
    an example is image captioning, where the network will generate a text based on
    the image content.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一**-**对**-**多**：在这里，有固定输入到序列输出；一个例子是图像标注，其中网络会基于图像内容生成文本。'
- en: '**Many**-**to**-**one**: Here, there''s sequence input to fixed output; an
    example is sentiment analysis, where the network will output a single word (sentiment)
    describing an input sentence.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多**-**对**-**一**：在这里，有序列输入到固定输出；一个例子是情感分析，其中网络会输出一个描述输入句子的单一词汇（情感）。'
- en: '**Many**-**to**-**many**: Here, there''s sequence input to sequence output;
    an example is language translation, where the network will output a full sentence
    in a language from a full sentence in another language.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多**-**对**-**多**：在这里，有序列输入到序列输出；一个例子是语言翻译，其中网络会根据另一种语言的完整句子输出一种语言的完整句子。'
- en: 'A classic way of representing an RNN is shown in the following diagram. On
    the left side of the diagram, you have a compact representation of the network—the
    hidden layer outputs the feeds into itself. On the right side, you have the detailed
    representation of the same network—at each step, the hidden layer takes an input
    and the previous state and produces an output:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 表示RNN的经典方式如下图所示。在图表的左侧，你可以看到网络的简洁表示——隐藏层输出馈送到自身。在右侧，你可以看到相同网络的详细表示——在每一步，隐藏层接收输入和前一个状态，并产生输出：
- en: '![](img/96ac9fbc-545c-46e4-abe0-5de6187303a3.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/96ac9fbc-545c-46e4-abe0-5de6187303a3.png)'
- en: 'The bottom row of the diagram shows the input vectors, the middle row of the
    diagram shows the hidden layers, and the upper row of the diagram shows the output
    layer. This representation shows how well an RNN can represent many-to-many inputs
    and outputs for the following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图表的底部行展示了输入向量，中间行展示了隐藏层，顶部行展示了输出层。这个表示展示了RNN如何表示多对多输入输出，如下所示：
- en: 'A sequence of vectors for the input: *{ ..., x(t - 1), x(t), x(t + 1), ...
    }*'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入的向量序列：*{ ..., x(t - 1), x(t), x(t + 1), ... }*
- en: 'A sequence of vectors for the output: *{ ..., y(t - 1), y(t), y(t + 1), ...
    }*'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出的向量序列：*{ ..., y(t - 1), y(t), y(t + 1), ... }*
- en: Remember the past to better predict the future
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 记住过去，以便更好地预测未来
- en: As we saw in the previous section, in RNNs, the input vector is combined with
    its state vector to produce the output, which is then used to update the state
    vector for the next step. This is different than feed-forward neural networks
    such as CNNs, where the network feeds information from the input to the output
    and only in that direction, meaning the output is a function of only its input,
    not previous events.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一部分所看到的，在 RNN 中，输入向量与其状态向量结合，产生输出，并用于更新下一个步骤的状态向量。这与卷积神经网络（CNN）等前馈神经网络不同，后者是将信息从输入传递到输出，并且只在那个方向上进行传播，意味着输出仅仅是输入的函数，而不是前一个事件的结果。
- en: Let's look at how we define a simple RNN. We implement a single operation, the
    `step` operation, that takes an input vector, `x`, and returns an output vector, `y`.
    Each time the step operation is called, the RNN needs to update its state, the
    hidden vector, `h`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下如何定义一个简单的 RNN。我们实现一个单一操作，`step` 操作，该操作接受一个输入向量 `x`，并返回一个输出向量 `y`。每次调用
    `step` 操作时，RNN 需要更新其状态，即隐向量 `h`。
- en: What is important to note here, is that we can **stack** as many RNNs as we
    want by taking the output of an RNN and feeding it in the next RNN, just like
    in the previous diagram. For example, we could go `y1 = rnn1.step(x1)`, `y2 =
    rnn2.step(y1)`, and so on.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，我们可以**堆叠**任意数量的 RNN，通过将一个 RNN 的输出作为下一个 RNN 的输入，就像前面的图示所示。例如，我们可以这样操作：`y1
    = rnn1.step(x1)`，`y2 = rnn2.step(y1)`，依此类推。
- en: 'When training the RNN, during the forward pass, we need to update the state,
    calculate the output vector, and update the loss. But how do we update the state?
    Let''s see the steps we need to follow:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练 RNN 时，在前向传播过程中，我们需要更新状态，计算输出向量，并更新损失。那么我们如何更新状态呢？让我们看看需要遵循的步骤：
- en: First, we do the matrix multiplication of the hidden state matrix (`Whh`) with
    the previous hidden state (`hs[t-1]`), `np.dot(Whh, hs[t-1])`.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们进行隐状态矩阵（`Whh`）与前一个隐状态（`hs[t-1]`）的矩阵乘法，即`np.dot(Whh, hs[t-1])`。
- en: Then, we sum it with the matrix multiplication of the current input matrix (`Wxh`)
    and the input vector (`xs[t]`), `np.dot(Wxh, xs[t])`.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将其与当前输入矩阵（`Wxh`）和输入向量（`xs[t]`）的矩阵乘法相加，即`np.dot(Wxh, xs[t])`。
- en: Finally, we use the `tanh` activation function on the resulting matrix to squash
    the activations between -1 and 1.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们对结果矩阵使用 `tanh` 激活函数，将激活值限制在 -1 到 1 之间。
- en: We do that at every step, meaning that, at every step of the training, the network
    has an **up-to-date** context in regards to the sequence it is handling.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在每一步都进行更新，这意味着，在训练的每一步，网络都能保持**最新的**上下文信息，以应对它正在处理的序列。
- en: To understand how an RNN handles sequential data, such as a note sequence, let's
    take the example of an RNN training on broken chords, which are chords broken
    down as a series of notes. We have the input data "A", "C", "E", and "G", which
    is encoded as a vector, for example *[1, 0, 0, 0]* for the first note (which corresponds
    to `x(t - 1)` in the previous diagram), *[0, 1, 0, 0]* for the second note (`x(t)`
    in the previous diagram), and so on.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解 RNN 如何处理序列数据，例如音符序列，我们以 RNN 在断开和弦上的训练为例，断开和弦是将和弦分解成一系列音符。我们有输入数据 "A"、"C"、"E"
    和 "G"，它们被编码为向量，例如，第一个音符的编码是 *[1, 0, 0, 0]*（对应于前图中的`x(t - 1)`），第二个音符的编码是 *[0, 1,
    0, 0]*（对应于前图中的`x(t)`），依此类推。
- en: During the first step, with the first input vector, the RNN outputs, for example,
    a confidence of the next note being 0.5 for "A", 1.8 for "C", -2.5 for "E", and
    3.1 for "G". Because our training data tells us that the correct next note is
    "C", we want to increase the confidence score of 1.8, and decrease the other scores.
    Similarly, for each of the 4 steps (for the 4 input notes), we have a correct
    note to predict. Remember, at each step, the RNN uses both the hidden vector and
    the input vector to make a prediction. During backpropagation, the parameters
    are nudged in the proper direction by a small amount, and by repeating this enough
    times, we get predictions that match the training data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步中，使用第一个输入向量时，RNN 输出的结果是，例如，"A"的下一个音符的置信度为0.5，"C"为1.8，"E"为-2.5，"G"为3.1。由于我们的训练数据告诉我们，正确的下一个音符是"C"，所以我们希望增加1.8的置信度，并减少其他音符的置信度。类似地，对于每一步（对于四个输入音符），我们都有一个正确的音符需要预测。记住，在每一步中，RNN
    都会使用隐向量和输入向量来进行预测。在反向传播过程中，参数会通过一个小的调整被推向正确的方向，经过多次重复训练后，我们得到的预测将与训练数据匹配。
- en: During inference, if the network first receives an input of "C", it won't necessarily
    predict "E" because it hasn't seen "A" yet, which doesn't match the example chord
    that was used to train the model. The RNN prediction is based on its **recurrent
    connection**, which keeps track of the context, and doesn't rely on the input
    alone.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理过程中，如果网络第一次接收到输入“C”，它不一定会预测“E”，因为它还没有看到“A”，这与用于训练模型的示例和弦不符。RNN的预测基于其**递归连接**，该连接跟踪上下文，而不仅仅依赖于输入。
- en: To sample from a trained RNN, we feed a note into the network, which outputs
    the distribution for the next note. By **sampling the distribution**, we get a
    probable next note that we can then feed back to the network. We can repeat the
    process until we have a long enough sequence. This generation process is described
    in more detail in the following section, *Understanding the generation algorithm*.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 要从训练好的RNN中进行采样，我们将一个音符输入到网络中，网络会输出下一个音符的分布。通过**从分布中采样**，我们得到一个可能的下一个音符，然后可以将其反馈回网络。我们可以重复这个过程，直到生成足够长的序列。这个生成过程将在下一节中详细描述，*理解生成算法*。
- en: 'During backpropagation, we saw that we update the parameters going backward
    in the network. Imagine the network is learning a long sequence of notes: how
    far can the gradients be backpropagated in the network so that the link between
    a note far in the sequence and a note at the beginning still holds? Well, it turns
    out that this is a difficult problem for vanilla RNNs. One answer to that is **Lo****ng**-**Short
    Term Memory** (**LSTM**) cell, which uses a different mechanism for keeping the
    current state.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在反向传播中，我们看到我们在网络中向后更新参数。假设网络正在学习一个很长的音符序列：梯度能在网络中反向传播多远，以便序列中很远的音符与序列开头的音符之间的联系仍然成立？事实证明，这是传统RNN的一个难题。为此，有一个答案是**长短期记忆**（**LSTM**）单元，它使用一种不同的机制来保持当前状态。
- en: Using the right terminology for RNNs
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用正确的RNN术语
- en: Now that we understand RNNs, we can say that most RNNs are using LSTM cells.
    Those RNNs are sometimes called **LSTM networks**, but more often than not, they
    are just called RNNs. Unfortunately, the two terms are often used interchangeably.
    In Magenta, all of the RNNs are LSTMs but aren't named as such. This is the case
    of the Drums RNN model we're looking at in this chapter and all of the models
    we're going to use in the next chapters.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经理解了RNN，我们可以说大多数RNN都使用LSTM单元。这些RNN有时被称为**LSTM网络**，但更常见的是直接称其为RNN。不幸的是，这两个术语经常互换使用。在Magenta中，所有的RNN都是LSTM，但并没有专门以此命名。这就是我们在本章中所看到的鼓乐RNN模型以及接下来章节中我们将使用的所有模型的情况。
- en: We'll be explaining LSTMs in [Chapter 3](48023567-4100-492a-a28e-53b18a63e01e.xhtml),
    *Generating Polyphonic Melodies*. For now, just remember that what we saw in the
    previous section still holds, but the hidden state update is more complex than
    what we described.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第3章](48023567-4100-492a-a28e-53b18a63e01e.xhtml)中解释LSTM，即*生成多声部旋律*。现在，只需要记住我们在前一部分所看到的内容仍然成立，但隐藏状态的更新比我们之前描述的要复杂。
- en: Using the Drums RNN on the command line
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在命令行中使用鼓乐RNN
- en: Now that we understand how RNNs make for powerful tools of music generation,
    we'll use the Drums RNN model to do just that. The pre-trained models in Magenta
    are a good way of starting music generation straightaway. For the Drums RNN model,
    we'll be using the `drum_kit` pre-trained bundle, which was trained on thousands
    of percussion MIDI files.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了RNN如何成为强大的音乐生成工具，我们将使用鼓乐RNN模型来实现这一点。Magenta中的预训练模型是直接开始音乐生成的好方法。对于鼓乐RNN模型，我们将使用`drum_kit`预训练包，它是基于成千上万的打击乐MIDI文件训练的。
- en: 'This section will provide insight into the usage of Magenta on the command
    line. We''ll be primarily using Python code to call Magenta, but using the command
    line has some advantages:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将深入讲解如何在命令行中使用Magenta。我们主要使用Python代码来调用Magenta，但使用命令行有一些优势：
- en: It is simple to use and useful for quick use cases.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用简单，适合快速使用的场景。
- en: It doesn't require writing any code or having any programming knowledge.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不需要编写任何代码或具备编程知识。
- en: It encapsulates parameters in helpful commands and flags.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将参数封装在有用的命令和标志中。
- en: In this section, we'll use the Drums RNN model in the command line and learn
    to configure the generation though flags. We'll explain how the generation algorithm
    works and look at its parameters and output.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用命令行中的鼓乐RNN模型，并学习通过标志来配置生成过程。我们将解释生成算法如何工作，并查看其参数和输出。
- en: Magenta's command-line utilities
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Magenta的命令行工具
- en: Magenta comes with multiple command-line utilities. These command-line utilities
    are Python scripts that can be called directly from the command line as console
    entry points and are installed in your Conda environment when you install Magenta
    (look in the `bin` folder of your Magenta environment or the `scripts` folder
    if using Windows). The complete list of command-line utilities is located in Magenta's
    source code, in `setup.py`, under `CONSOLE_SCRIPTS`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Magenta 配备了多个命令行工具。这些命令行工具是可以直接从命令行调用的 Python 脚本，作为控制台入口点，并在安装 Magenta 时被安装到你的
    Conda 环境中（如果使用 Windows，请查看 Magenta 环境中的`bin`文件夹或`scripts`文件夹）。命令行工具的完整列表位于 Magenta
    源代码中的`setup.py`文件内的`CONSOLE_SCRIPTS`部分。
- en: You can always checkout Magenta's source code and have a look at it. It might
    seem intimidating at first, but the source code is well documented and provides
    invaluable insight into the inner workings of the software. Using Git, execute
    `git clone https://github.com/tensorflow/magenta` in a Terminal and then open
    the repository in your favorite IDE. Another advantage of having the source code
    is to have a look at certain files that are not packaged with the app.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以随时查看 Magenta 的源代码并进行浏览。刚开始可能会觉得有些令人生畏，但源代码有很好的文档，并提供了关于软件内部工作原理的宝贵洞察。使用 Git，执行`git
    clone https://github.com/tensorflow/magenta`命令，并在你喜欢的 IDE 中打开该仓库。拥有源代码的另一个优势是，可以查看某些未打包在应用程序中的文件。
- en: 'For the Drums RNN model that we are going to use, we have three command-line
    utilities (like much of the models):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们将使用的鼓 RNN 模型，我们有三个命令行工具（就像大多数模型一样）：
- en: '`drums_rnn_create_dataset` will help to create a dataset for the training command.
    We''ll be looking into this command in [Chapter 6](1ca56e24-b4d2-40de-b4cf-ae6bbb3c0eef.xhtml),
    *Data Preparation for Training*.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`drums_rnn_create_dataset` 将帮助创建训练命令所需的数据集。我们将在[第 6 章](1ca56e24-b4d2-40de-b4cf-ae6bbb3c0eef.xhtml)，*训练数据准备*中进一步探讨这个命令。'
- en: '`drums_rnn_generate` will be used in this chapter to generate a musical score.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`drums_rnn_generate` 将在本章中用于生成乐谱。'
- en: '`drums_rnn_train` will train the model on an input dataset. We''ll be looking
    into this command in [Chapter 7](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml),
    *Training Magenta Models*.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`drums_rnn_train` 将在输入数据集上训练模型。我们将在[第 7 章](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml)，*训练
    Magenta 模型*中进一步探讨这个命令。'
- en: Generating a simple drum sequence
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成一个简单的鼓序列
- en: In the previous chapter, we generated a simple MIDI file to test our installation.
    We'll take that example and change it a bit.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章，我们生成了一个简单的 MIDI 文件来测试我们的安装。我们将使用这个示例并稍作修改。
- en: 'Before starting, go back on a terminal to the main book''s folder and then
    change directory to `Chapter02`. Make sure you are in your Magenta environment.
    If not, use `conda activate magenta` to do so:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，返回终端到主书籍文件夹，然后切换到`Chapter02`目录。确保你在 Magenta 环境中。如果不是，请使用`conda activate
    magenta`来激活环境：
- en: 'First, we download the Drums RNN bundle file, `drum_kit_rnn.mag`, in the `bundles`
    folder. You only need to do this once:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们下载鼓 RNN 捆绑文件`drum_kit_rnn.mag`，并将其放入`bundles`文件夹。你只需执行一次此操作：
- en: '[PRE0]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: A bundle file is a file containing the model checkpoint and metadata. This is
    a pre-trained model that contains the weights from the training phase, which will
    be used to initialize the RNN network. We'll be seeing this format in detail in
    [Chapter 7](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml), *Training Magenta Models*.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 捆绑文件是包含模型检查点和元数据的文件。这是一个预训练模型，包含来自训练阶段的权重，将用于初始化 RNN 网络。我们将在[第 7 章](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml)，*训练
    Magenta 模型*中详细介绍这种格式。
- en: 'Then, we can use the bundle to generate MIDI files in the output directory
    with `--output-dir`:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们可以使用捆绑文件通过`--output-dir`生成 MIDI 文件到输出目录：
- en: '[PRE1]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Open one of the generated files in the `output` folder in MuseScore or Visual
    MIDI. For the latter, you need to convert the MIDI file into a plot rendered in
    an HTML file, which you can then open in a browser. To convert the MIDI file into
    a plot, use the following command:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`output`文件夹中生成的一个文件，在 MuseScore 或 Visual MIDI 中查看。对于后者，你需要将 MIDI 文件转换为图表，并渲染为
    HTML 文件，然后可以在浏览器中打开。要将 MIDI 文件转换为图表，使用以下命令：
- en: '[PRE2]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, open the `output/GENERATED.html` HTML file, which contains the plot:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，打开`output/GENERATED.html` HTML文件，其中包含图表：
- en: '![](img/58c6a8a4-dff4-4e91-857c-d132239500ae.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/58c6a8a4-dff4-4e91-857c-d132239500ae.png)'
- en: 'To listen to the generated MIDI, use your software synthesizer or MuseScore.
    For the software synthesizer, refer to the following command depending on your
    platform and replace `PATH_TO_SF2` and `PATH_TO_MIDI` with the proper values:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要聆听生成的 MIDI，可以使用你的软件合成器或 MuseScore。对于软件合成器，根据你的平台使用以下命令，并将 `PATH_TO_SF2` 和 `PATH_TO_MIDI`
    替换为正确的值：
- en: 'Linux: `fluidsynth -a pulseaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Linux: `fluidsynth -a pulseaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
- en: 'macOS: `fluidsynth -a coreaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'macOS: `fluidsynth -a coreaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
- en: 'Windows: `fluidsynth -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Windows: `fluidsynth -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
- en: Understanding the model's parameters
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解模型的参数
- en: 'From the screenshot in the last section, you can already see that the model
    used some default configurations to generate the score: the number of steps to
    generate, the tempo, and so on. Now, let''s see what other flags are possible.
    To see what kind of flags the model takes, use the `--helpfull` flag:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 从上一节的截图中，你已经可以看到模型使用了一些默认配置来生成乐谱：生成的步数、节奏等等。现在，让我们看看还有哪些其他标志是可用的。要查看模型支持的标志，请使用
    `--helpfull` 标志：
- en: '[PRE3]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You will see a lot of possible flags showing. The sections that are of interest
    for us are `drums_rnn_config_flags` and `drums_rnn_generate`, which are flags
    specific for the Drums RNN model.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到许多可能的标志。我们感兴趣的部分是 `drums_rnn_config_flags` 和 `drums_rnn_generate`，这些标志是针对
    Drums RNN 模型的特定标志。
- en: The following subsections will explain the most important ones. Because most
    also apply to other models, you'll be able to apply what you learn to the next
    chapters as well. We'll explain other model-specific flags of the later chapters
    as we go.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下小节将解释最重要的部分。因为大多数内容也适用于其他模型，所以你可以将学到的内容应用到接下来的章节中。我们会在后续章节中根据需要解释其他模型特定的标志。
- en: Changing the output size
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更改输出大小
- en: 'A simple flag to change the number of generated samples is `--num_outputs`:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 更改生成样本数量的一个简单标志是 `--num_outputs`：
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You can also use the `--num_steps` flag to change the size of the generated
    samples:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用 `--num_steps` 标志来更改生成样本的大小：
- en: '[PRE5]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The last example we generated was 128 steps long because we generated it using
    the default value. By looking at the previous screenshot, you can count the vertical
    bar lines, which counts to 8 bars. This is because, with 128 steps at 16 steps
    per bar, you get *128/16 = 8* bars. If you want a 1 bar generation, you'll be
    asking for 16 steps, for example. You can see a single step as a single note slot,
    in the sense that generators will generate one note per step maximum. It is a
    convenient way of dividing time.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们生成的最后一个例子有 128 步长，因为我们使用默认值生成它。从之前的截图中，你可以数出竖条线的数量，共计 8 bars。这是因为，128 步，每
    bar 16 步，得到 *128/16 = 8* bars。如果你想生成 1 bar，你需要请求 16 步，例如。你可以将单个步骤视为一个音符插槽，因为生成器每个步骤最多生成一个音符。这是一种方便的时间划分方式。
- en: We'll be using the term **bar** in this book, which is more popular in British
    English, but readers might be used to the word **measure**, which is more popular
    in American English. There are some differences in their usage, and depending
    on the context, one or the other might be used more often. However, both words
    mainly have the same significance.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将使用术语 **bar**，这是英国英语中更为常用的词，但读者可能更习惯使用 **measure**，这是美国英语中更常见的说法。两者在使用上有一些差异，具体取决于上下文，可能会有一个词使用得更多。不过，两者主要具有相同的含义。
- en: The main reason to stick with bar throughout this book is to follow Magenta's
    code convention, where bar is used more consistently than measure.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 本书始终使用 bar 的主要原因是遵循 Magenta 的代码约定，在该约定中，bar 的使用比 measure 更为一致。
- en: 'We can show the steps by zooming on the last two bars of the previous example:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过放大之前例子的最后两 bars 来展示步骤：
- en: '![](img/565596cb-9b46-4e66-8c78-e8144626129c.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/565596cb-9b46-4e66-8c78-e8144626129c.png)'
- en: You can see in this diagram that there are 2 bars, each of 2 seconds (see the
    next section for information on the tempo), with a different background for each
    bar. You can also see that there are 16 steps per bar; we've marked one of those
    steps with a different background. A step can contain multiple notes if the model
    is polyphonic, like the Drums RNN model. Depending on the model, a note can spawn
    multiple steps, which is not the case here. For this model, the note will always
    start and stop exactly on the step start and end since the model outputs quantized
    sequences.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这个图示中看到，有 2 个小节，每个小节为 2 秒（参见下一节获取节奏信息），每个小节都有不同的背景。你还可以看到每个小节有 16 步长；我们已用不同的背景标记了其中的一步。如果模型是多音的（如鼓
    RNN 模型），则每个步长可以包含多个音符。根据模型的不同，一个音符可能会产生多个步长，但这里并非如此。对于这个模型，音符总是会在步长的开始和结束时准确起止，因为模型输出的是量化的序列。
- en: Changing the tempo
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更改节奏
- en: The tempo is the speed at which the score is played. Be aware that it won't
    change the number of notes or the generation length—it will only put the information
    in the generated MIDI so that the MIDI player will later be able to play it at
    the right speed.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 节奏是乐谱播放的速度。请注意，它不会改变音符的数量或生成时长——它只会将信息写入生成的 MIDI 中，以便 MIDI 播放器能够以正确的速度播放。
- en: The tempo in Magenta is expressed in **Quarter-notes Per Minute** (**QPM**).
    A **quarter** is a bar separated into four—if you have 16 steps in a bar, then
    a quarter contains 4 steps. So, if your tempo is 120 QPM, then you have *120 quarters/60
    seconds = 2* quarters per second. That means you play 1 bar per 2 seconds (see
    the previous diagram for an example of that).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Magenta 中的节奏以 **每分钟四分音符数**（**QPM**）表示。**四分音符**是一个小节划分为四个——如果你有 16 步长的小节，那么四分音符就包含
    4 步。因此，如果你的节奏是 120 QPM，那么你每秒播放 *120 四分音符/60 秒 = 2* 四分音符。这意味着每 2 秒播放 1 小节（参考之前的图示）。
- en: QPM is a measure of tempo similar but not to be confused with **BPM** (**Beats**
    **Per** **Minute**) since, in the latter, the meaning of a beat might change for
    some time signature. Also, the concept of a beat might change depending on the
    listener. QPM is well defined and used in the MIDI and MusicXML format.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: QPM 是一种与**BPM**（**每分钟拍数**）相似但不应混淆的节奏度量，因为在后者中，拍子的意义可能会随着某些节拍类型而改变。此外，拍子的概念可能会根据听众的不同而有所变化。QPM
    在 MIDI 和 MusicXML 格式中得到了明确定义和使用。
- en: 'To change the tempo, use the `--qpm` flag:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要更改节奏，请使用 `--qpm` 标志：
- en: '[PRE6]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the following diagram, we''ve generated a drum file at 150 QPM using `--qpm
    150`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图示中，我们使用 `--qpm 150` 生成了一个 150 QPM 的鼓文件：
- en: '![](img/60e478fe-9897-49f5-9793-c3b2488378a3.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/60e478fe-9897-49f5-9793-c3b2488378a3.png)'
- en: You can see the bars are not aligned with 2, 4, and more seconds anymore. This
    is because, at 120 QPM, a bar is exactly 2 seconds long, but it is now slightly
    less. Our generated sample still has `--num_steps 128` but now has a duration
    of 12.8 seconds (and still 8 bars) because we still have the same amounts of steps—they
    are just played faster.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到小节不再与 2 秒、4 秒等对齐。这是因为在 120 QPM 下，一个小节正好是 2 秒长，但现在稍微短了一点。我们生成的样本仍然有 `--num_steps
    128`，但现在时长为 12.8 秒（仍然是 8 小节），因为我们仍然有相同数量的步长——它们只是以更快的速度播放。
- en: To find the duration in seconds of a sequence for a specific QPM such as 150,
    we first calculate the length of a step in seconds, by taking the number of seconds
    in a minute (60), dividing by the QPM (150), and dividing by the number of steps
    per quarter (4). This gives us 0.1 seconds per step. For 128 steps, the sequence
    is 12.8 seconds long.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到特定 QPM（如 150）序列的时长（秒），我们首先计算每步长的时长（秒）。方法是将一分钟的秒数（60）除以 QPM（150），再除以每四分音符的步长数（4）。这样我们得到每步长
    0.1 秒。对于 128 步长，序列的时长为 12.8 秒。
- en: Changing the model type
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更改模型类型
- en: 'The `--config` flag changes the configuration of the model. With each configuration
    in Magenta comes a pre-trained model. In this chapter, we are using the `drum_kit_rnn.mag`
    pre-trained model (or bundle) for the `drum_kit` configuration. The chosen pre-trained
    model must match the configuration it was trained with:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`--config` 标志改变模型的配置。每个 Magenta 配置都附带一个预训练的模型。在本章节中，我们使用 `drum_kit_rnn.mag`
    预训练模型（或模型包）作为 `drum_kit` 配置。选择的预训练模型必须与其训练时的配置匹配：'
- en: '[PRE7]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: It won't be useful for us now, but it will come in handy in [Chapter 3](48023567-4100-492a-a28e-53b18a63e01e.xhtml),
    *Generating Polyphonic Melodies*. This also changes the mapping of the drums,
    where the resulting encoded vector is different in both cases. We'll be talking
    about vector encoding in the next section when we look at the Python code.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这对我们没有用处，但在[第3章](48023567-4100-492a-a28e-53b18a63e01e.xhtml)，*生成复调旋律*时它将派上用场。这还会改变鼓点的映射，其中生成的编码向量在两种情况下是不同的。当我们查看Python代码时，我们将在下一节讨论向量编码。
- en: Priming the model with Led Zeppelin
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用Led Zeppelin来引导模型
- en: A primer sequence can be given to the model to **prepare** it before the generation.
    This is used extensively with Magenta and is really useful if you want the model
    to generate something that is inspired by your primer. You can either prime the
    model with a hardcoded sequence or directly from a MIDI file. The priming sequence
    is fed to the model before the generation starts.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 可以给模型提供一个引导序列，以在生成之前**准备**它。这在Magenta中被广泛使用，如果你希望模型生成一些受到你提供的引导启发的内容，这非常有用。你可以用硬编码的序列或者直接从MIDI文件中引导模型。引导序列在生成开始前被输入到模型中。
- en: 'The string representation of the `--primer_drums`flag reads as follows: you
    enter a list of tuples, each tuple corresponding to a step, with each tuple containing
    the MIDI notes being played at the same time. In this example, on the first step,
    both MIDI notes, 36 and 42, are played at the same time, followed by 3 steps of
    silence, then MIDI note 42 is played alone in its own step:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`--primer_drums`标志的字符串表示如下：你输入一系列元组，每个元组对应一个步骤，每个元组包含在同一时刻播放的MIDI音符。在这个例子中，在第一步中，MIDI音符36和42同时播放，接着是3步的静默，然后MIDI音符42单独在其自己的步骤中播放：'
- en: '[PRE8]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you might remember from the previous chapter, a MIDI note also have velocity
    information, which is not given here. This is not necessary since the Drums RNN
    doesn't support velocity. Each generated note will have a default value of 100
    for velocity (on a maximum value of 127).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能还记得从上一章，MIDI音符也有音量信息，但这里没有给出。因为Drums RNN不支持音量，所以这不是必需的。每个生成的音符会默认音量值为100（最大值为127）。
- en: Some models in Magenta support velocity as we'll see in the next chapters. Since
    the velocities have to be encoded in the input vectors that are fed to the network
    during training, it is a design choice to include them or not. We'll also talk
    about encoding in the next chapters.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Magenta中的一些模型支持音量（velocity），正如我们在接下来的章节中将看到的那样。由于音量必须被编码到在训练过程中输入到网络的向量中，因此是否包含它们是一个设计选择。我们也将在接下来的章节中讨论编码问题。
- en: To give a primer corresponding to a bar, you'll have to provide 16 tuples, because
    there are 16 steps per bar. The previous primer is half a bar long.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 要提供一个与小节对应的引导序列，你需要提供16个元组，因为每小节有16步。之前的引导序列只有半小节长。
- en: 'You can also provide the path to a MIDI file with the `--primer_midi` flag:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用`--primer_midi`标志提供一个MIDI文件的路径：
- en: '[PRE9]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: A primer MIDI file gives the tempo and will override your `--qpm` flag if you
    also provide it.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 引导的MIDI文件会提供节奏，如果你同时提供`--qpm`标志，它将覆盖该标志。
- en: 'When initializing the model with a primer, you also get the primer in the resulting
    output sequence. That means `--num_steps` needs to be bigger than the primer''s
    length or else Magenta won''t have space left to generate. For example, this command
    will output an error because the number of steps is not high enough:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用引导初始化模型时，你还会在生成的输出序列中看到引导序列。这意味着`--num_steps`需要大于引导的长度，否则Magenta就没有足够的空间来生成。例如，下面的命令会报错，因为步数不足：
- en: '[PRE10]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This results in the following output:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这会生成以下输出：
- en: '[PRE11]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s generate something based on a small drum part of Jon Bonham''s (Led
    Zeppelin) *When The Levee Breaks* track. Here''s a two-bar primer:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们生成一些基于Jon Bonham（Led Zeppelin）*When The Levee Breaks*曲目的小鼓部分的内容。这里是一个两小节的引导序列：
- en: '![](img/da0a6c06-1fda-47b1-8e2f-d8281188d5eb.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/da0a6c06-1fda-47b1-8e2f-d8281188d5eb.png)'
- en: 'Then, we generate some MIDI files by setting the primer, the temperature, and
    the proper number of steps. Remember, the number of steps is the total number
    of steps, primer included:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们通过设置引导序列、温度和适当的步数来生成一些MIDI文件。记住，步数是总步数，包括引导部分：
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We get an interesting sequence shown in the following diagram:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了一个有趣的序列，如下图所示：
- en: '![](img/bbe135e5-4b35-4670-9db3-ce2ed58dfa05.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bbe135e5-4b35-4670-9db3-ce2ed58dfa05.png)'
- en: You can still find the primer in the first 3 seconds or so, then we notice that
    the model kept the musical structure of the track, but improvised over it, adding
    a few kick drums, hit hats, and snares here and there. We'll be looking at the
    MIDI mapping of percussion sequences, including the mapping of each pitch to their
    corresponding instrument, in the next section, *Mapping MIDI notes to the real
    world*.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你仍然可以在大约前3秒钟内找到前导音符，然后我们注意到模型保留了轨道的音乐结构，但在此基础上进行即兴创作，加入了几次低音鼓、镲片和小军鼓的音效。我们将在下一节中讨论打击乐序列的MIDI映射，包括每个音高与对应乐器的映射，*将MIDI音符映射到现实世界*。
- en: 'Now, we verify whether Magenta knows how to count: you have 16 steps of primer,
    1 step of silence, then 29 steps of generation for a total of 46, which is what
    we asked for. The step of silence comes from the way Magenta calculates the start
    of the generation. We''ll see in the Python code how to handle that in a better
    way.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们验证Magenta是否知道如何计数：你有16步前导音符，1步静音，然后是29步生成，总共46步，这是我们要求的。静音步长来自Magenta生成起始的方式。我们将在Python代码中看到如何更好地处理这一点。
- en: We also notice that the length of the notes in the primer are different in the
    generated score. You can see the same primer notes are present, but not with the
    same duration. This is because Magenta will **quantize the primer before feeding
    it to the model** and will generate quantized sequences. This depends on the model.
    **Quantization** is the process of moving the note's beginning and end so that
    they fall directly on some subdivisions of bars. In this case, Magenta moved the
    notes' end so that they fall on the closest step.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还注意到，前导音符在生成的乐谱中的音符时值不同。你可以看到相同的前导音符存在，但时长不同。这是因为Magenta会**在将前导音符输入到模型之前进行量化**，并生成量化后的序列。这取决于模型。**量化**是指将音符的开始和结束时间调整到某些小节的子分割点上。在这种情况下，Magenta将音符的结束位置调整到最接近的步骤上。
- en: Configuring the generation algorithm
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置生成算法
- en: 'The `--temperature` flag is important because it changes how random the generated
    sequence is:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`--temperature`标志非常重要，因为它决定了生成序列的随机性：'
- en: '[PRE13]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s try to generate a drum track with more randomness using `--temperature
    1.5`:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用`--temperature 1.5`生成一个更具随机性的鼓点轨道：
- en: '![](img/f9851eb7-dbee-49c1-a35b-be6a58a5465e.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f9851eb7-dbee-49c1-a35b-be6a58a5465e.png)'
- en: This is pretty wild! Remember a temperature of 1.5 is high, so you might have
    a more coherent sample with a more conservative value, like 1.1, for example.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这真是太疯狂了！记住，温度为1.5时比较高，因此你可以选择一个更保守的值，比如1.1，来生成一个更加一致的样本。
- en: 'Now, to generate a track with less randomness, use `--temperature 0.9`:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，要生成一个随机性较小的轨道，使用`--temperature 0.9`：
- en: '![](img/4bd4aa61-7b48-408a-bdfb-c9d0d678ec3e.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4bd4aa61-7b48-408a-bdfb-c9d0d678ec3e.png)'
- en: You can clearly see the generation is more conservative here. Choosing the temperature
    is up to taste and depends on what you are trying to achieve. Try different temperature
    values and see what fits best with the music you are trying to generate. Also,
    some models might sound better with wilder temperature values than others.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以明显看到，这里的生成结果更加保守。选择温度值取决于个人口味，并且与你想要实现的效果有关。尝试不同的温度值，看看哪些最适合你想要生成的音乐。此外，一些模型可能在较为极端的温度值下效果更好。
- en: Other Magenta and TensorFlow flags
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他Magenta和TensorFlow的标志
- en: There are other flags that we haven't talked about, such as the configuration
    of the hyperparameters of the model with `--hparams`, but we'll be looking into
    this when we train our own model in [Chapter 7](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml),
    *Training Magenta Models*.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些我们没有提到的标志，比如用`--hparams`配置模型的超参数，但我们会在[第7章](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml)《训练Magenta模型》中讨论这些内容，*训练Magenta模型*。
- en: Understanding the generation algorithm
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解生成算法
- en: In the previous sections, we introduced how the generation algorithm works—by
    predicting at each generation step what the next note in the sequence is, we can
    iteratively generate a full score. The resulting prediction depends on what the
    model has learned during the training phase. This section will delve deeper into
    the generation algorithm by showing it in action on an example being executed
    step by step.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们介绍了生成算法的工作原理——通过在每个生成步骤中预测序列中的下一个音符，我们可以迭代地生成完整的乐谱。生成的预测结果取决于模型在训练阶段学到的内容。本节将通过逐步执行的示例深入探讨生成算法的运作。
- en: 'We''ll also be explaining the parameters that modify the generation''s execution:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将解释一些修改生成执行过程的参数：
- en: '[PRE14]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Generating the sequence branches and steps
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成序列分支和步骤
- en: 'Let''s use this command to launch the generation:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用这个命令来启动生成：
- en: '[PRE15]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Magenta will do the following operations:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Magenta 将执行以下操作：
- en: It converts the primer sequence into a format that the model understands (this
    is called **encoding**—check the *Encoding percussion events as classes* section).
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它将启动器序列转换为模型能够理解的格式（这称为 **编码**——请参阅 *将打击乐事件编码为类别* 部分）。
- en: It uses that encoded primer to initialize the model state.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它使用该编码的启动器来初始化模型状态。
- en: 'It loops until all of the steps (`--num_steps 64`) have been generated:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它会循环直到生成所有步骤（`--num_steps 64`）：
- en: 'It loops to generate *N* branches (`--branch_factor 2`):'
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它会循环生成 *N* 个分支（`--branch_factor 2`）：
- en: It generates *X* steps (`--steps_per_iterations 1`) by running the model with
    its current state using the **temperature** (`--temperature 1.1`). This returns
    the predicted sequence as well as the resulting **softmax probabilities**. The
    softmax probabilities are the actual probability scores for each class (the encoded
    notes) at the final layer of the network.
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它通过使用 **温度**（`--temperature 1.1`）运行模型及其当前状态，生成 *X* 步（`--steps_per_iterations
    1`）。这会返回预测的序列以及结果的 **softmax 概率**。softmax 概率是每个类别（即编码音符）在网络最后一层的实际概率分数。
- en: It calculates the **negative log-likelihood** of the resulting sequence, which
    is a scoring evaluation of the entire sequence from the softmax probabilities.
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它计算结果序列的 **负对数似然值**，这是从 softmax 概率中得出的整个序列的评分评估。
- en: It updates the model state for the next iteration.
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它更新模型状态以便进行下一次迭代。
- en: It prunes the generated branches to best *K* branches (`--beam_size 1`) by using
    the calculated score.
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它通过使用计算得分来修剪生成的分支，保留最佳的 *K* 个分支（`--beam_size 1`）。
- en: 'This diagram shows the generation process with a final sequence of **36**,
    **38**, and **42**:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 该图展示了生成过程，最终序列为 **36**、**38** 和 **42**：
- en: '![](img/3a0ea9af-e3a2-469e-81c8-09ab5cb8656a.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3a0ea9af-e3a2-469e-81c8-09ab5cb8656a.png)'
- en: In the diagram, the **S** value denotes the calculated score of the entire sequence
    (see *steps 3.1.2* and *3.2*). The beam search algorithm shown here is linear
    in complexity on the output sequence length (which is the depth of the tree),
    so it is pretty fast. The default value of `--beam_size 1` is useful since the
    algorithm becomes a best-first search algorithm, where you don't actually do a
    breadth-first search since you are keeping only the best candidate.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，**S** 值表示整个序列的计算得分（见 *步骤 3.1.2* 和 *3.2*）。这里展示的束搜索算法在输出序列长度（即树的深度）上的复杂度是线性的，因此它相当快速。`--beam_size
    1` 的默认值是有用的，因为该算法变成了一个最佳优先搜索算法，你实际上并没有进行广度优先搜索，因为你只保留最好的候选。
- en: Making sense of the randomness
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解随机性
- en: 'When we launch a generation that uses the beam search, Magenta shows the resulting
    log-likelihood of the whole sequence:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们启动一个使用束搜索（beam search）的生成时，Magenta 会显示整个序列的对数似然值：
- en: '[PRE16]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'What happens with `--temperature 1.25` instead of 1.1? The log-likelihood will
    be smaller (further from zero) since the generation is more random:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用 `--temperature 1.25` 而不是 1.1 会发生什么？对数似然值会更小（远离零），因为生成过程更具随机性：
- en: '[PRE17]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'What if we generate only 1 branch with `--branch_factor 1` but keep the same
    temperature at 1.25? The log-likelihood will be smaller:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只生成 1 个分支，使用 `--branch_factor 1` 但保持温度为 1.25，会发生什么？对数似然值会更小：
- en: '[PRE18]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Why is the log-likelihood smaller? Because we've reduced the branch factor,
    the algorithm will generate fewer branches per iteration, meaning, at each iteration,
    it will have fewer branches to choose its best from, resulting in a globally more
    random sequence.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么对数似然值更小？因为我们减少了分支因子，算法每次迭代生成的分支会更少，这意味着每次迭代中可供选择的分支更少，从而导致全局上序列更随机。
- en: Let's now use what we've learned about the Drums RNN model and create a small
    Python application using those concepts.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们利用我们学到的 Drums RNN 模型的知识，创建一个使用这些概念的小型 Python 应用程序。
- en: Using the Drums RNN in Python
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Python 中使用 Drums RNN
- en: In the previous section, we've seen how much we can already do on the command
    line with the Drums RNN model. In this section, you'll get to create a small application
    that will use that model to generate music in Python.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们已经看到我们可以通过命令行使用 Drums RNN 模型做多少事情。在本节中，你将创建一个小应用程序，使用该模型在 Python 中生成音乐。
- en: 'Using Magenta in Python is a bit difficult because of the following reasons:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中使用 Magenta 有些困难，原因如下：
- en: It requires you to write code and understand Magenta's architecture.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它要求你编写代码并理解 Magenta 的架构。
- en: It requires more boilerplate code and is less straightforward.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它需要更多的样板代码，且不那么直观。
- en: 'But it also has advantages that we think are important:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 但它也有我们认为很重要的优点：
- en: You have more freedom in the usage of the models.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你在使用模型时有更多的自由度。
- en: You can create new models and modify existing ones.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以创建新的模型并修改现有的模型。
- en: You can go beyond generating single sequences.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以超越生成单一的序列。
- en: The last point is important for us because we'll be building a small music application
    that generates music autonomously. Calling Magenta's scripts on the command line
    is convenient, but you cannot build an app using only this. You'll be starting
    this in the last section of this chapter, *Creating a music generation application*,
    and building on it in the next chapters.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一项对我们很重要，因为我们将构建一个小型的音乐应用程序，该应用能够自主生成音乐。在命令行上调用 Magenta 的脚本非常方便，但仅凭这一点无法构建应用程序。你将在本章最后一节*创建音乐生成应用*中开始这个工作，并在后续章节中继续扩展它。
- en: Let's dive into the code by recreating what we've done on the command line and
    then building from there.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过重现我们在命令行中做的操作来深入了解代码，然后再从这里开始构建。
- en: Generating a drum sequence using Python
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Python 生成鼓序列
- en: We are going to generate a MIDI file from a primer in Python, much like we've
    done in the previous section.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Python 从引导生成一个 MIDI 文件，就像我们在上一节做的那样。
- en: You can follow this example in the `chapter_02_example_01.py` file in the source
    code of this chapter. There are more comments and content in the source code,
    so you should go check it out.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章的源代码中的 `chapter_02_example_01.py` 文件中查看这个示例。源代码中有更多的注释和内容，你应该去看看。
- en: 'Let''s start by downloading the bundle. There are a lot of useful tools in
    the `magenta.music` package, and we''ll be using it in many examples:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先下载捆绑包。`magenta.music` 包中有很多有用的工具，我们将在许多示例中使用它：
- en: '[PRE19]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We then use the drums generator to initialize the generator class with the
    `drum_kit` configuration. We are importing the Drums RNN models from its own package,
    and we''ll do the same for each model:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用鼓组生成器来初始化生成器类，并使用`drum_kit`配置。我们从自己的包中导入了鼓 RNN 模型，接下来我们会对每个模型做同样的操作：
- en: '[PRE20]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: By declaring the tempo, we can also calculate the length of a bar in seconds.
    We need this because the generation start and end is given in seconds to Magenta.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过声明节奏，我们还可以计算小节的长度（单位为秒）。我们需要这个值，因为生成的开始和结束时间是以秒为单位传递给 Magenta 的。
- en: 'We first calculate the seconds per step, which is equal to the number of seconds
    in a minute, divided by the quarter per minute (the tempo), divided by the number
    of steps per quarter. This last value is dependent on the generator, but it is
    mostly equal to 4:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先计算每步的秒数，这等于一分钟的秒数除以每分钟的四分音符数（即节奏），再除以每四分音符的步数。这个值依赖于生成器，但通常等于4：
- en: '[PRE21]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then, we calculate the seconds per bar, which is equal to the number of steps
    per bar multiplied by the seconds per step we previously calculated. The number
    of steps per bar changes depending on the time signature, but for now, we''ll
    just put the default value, which is 16, for 4/4 music sampled at 4 steps per
    quarter note:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，我们计算每小节的秒数，这等于每小节的步数乘以我们之前计算的每步的秒数。每小节的步数根据拍号有所不同，但目前我们将使用默认值16，用于以每四分音符四步采样的4/4拍音乐：
- en: '[PRE22]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We are now ready to initialize our primer sequence. We'll use a small jazz drum
    sequence of 1 bar for the primer (you can check it out in this book's source code
    in the `Chapter02` folder, `primers/Jazz_Drum_Basic_1_bar.mid`), so we'll need
    a list of 16 steps. We'll be explaining the primer definition in the next section.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在准备初始化我们的引导序列。我们将使用一个简单的1小节爵士鼓序列作为引导（你可以在本书的源代码中，`Chapter02` 文件夹中的 `primers/Jazz_Drum_Basic_1_bar.mid`
    文件中查看），因此我们需要一个包含16个步骤的列表。引导定义将在下一节解释。
- en: 'We convert that primer drum track into a primer sequence using the QPM we''ve
    already defined:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将已经定义的 QPM 用来将该引导鼓轨道转换为引导序列：
- en: '[PRE23]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can calculate the time of the primer in seconds, which is only the seconds
    per bar value since the primer is 1 bar:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以计算引导的时长（单位为秒），因为引导只有1小节，所以它的时长仅等于每小节的秒数：
- en: '[PRE24]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We now calculate the start and end time of the generator section. First, we
    define the number of generation bars, which is 3, then we start the generation
    at the end of the primer and extend it for a three-bars duration in seconds:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在计算生成器部分的开始和结束时间。首先，我们定义生成的节拍数为3，然后从引导的结束开始生成，并在秒数上扩展三小节的时长：
- en: '[PRE25]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can now configure our generator options with the start and end times. The
    generation options also take the temperature, which we''ll set to 1.1 for a bit
    of randomness. The generator interface is common for all models:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以使用开始和结束时间来配置我们的生成器选项。生成选项还包含温度，我们将其设置为1.1，以增加一些随机性。生成器接口对于所有模型都是通用的：
- en: '[PRE26]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'It is time to generate! You can now call the generate method on the generator
    with the primer sequence as input. The return value of this method is a `NoteSequence`
    instance:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是生成的时候了！你现在可以使用初始序列作为输入来调用生成器的生成方法。该方法的返回值是一个`NoteSequence`实例：
- en: '[PRE27]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'There are many utilities to then convert the resulting `NoteSequence` instance
    into other formats such as PrettyMidi. We''ll now convert the result, and write
    the file and the plot to disk:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有许多工具可以将生成的`NoteSequence`实例转换为其他格式，如PrettyMidi。我们现在将转换结果，并将文件和图表写入磁盘：
- en: '[PRE28]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let''s open the `output/out.html` file:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们打开`output/out.html`文件：
- en: '![](img/4b72ea6f-16e5-4ec6-a2d6-7e8534517d9a.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4b72ea6f-16e5-4ec6-a2d6-7e8534517d9a.png)'
- en: Notice that your primer at the beginning should be the same (because it is hardcoded),
    but your 3 generated bars should be different than these.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，你的初始序列应该保持不变（因为它是硬编码的），但你生成的3个小节应该与这些不同。
- en: 'To listen to the generated MIDI, use your software synthesizer or MuseScore.
    For the software synth, refer to the following command depending on your platform
    and replace `PATH_TO_SF2` and `PATH_TO_MIDI` with the proper values:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要听生成的MIDI，请使用你的软件合成器或MuseScore。对于软件合成器，请根据你的平台使用以下命令，并将`PATH_TO_SF2`和`PATH_TO_MIDI`替换为正确的值：
- en: 'Linux: `fluidsynth -a pulseaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Linux: `fluidsynth -a pulseaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
- en: 'macOS: `fluidsynth -a coreaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'macOS: `fluidsynth -a coreaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
- en: 'Windows: `fluidsynth -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Windows: `fluidsynth -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
- en: Packaging checkpoints as bundle files
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将检查点打包为捆绑文件
- en: In the last example, we saw the usage of a bundle. In Magenta, a bundle is a
    convenient way of packaging a **TensorFlow checkpoint** and metadata information
    into a single file. A checkpoint is used in TensorFlow to save the model state
    that occurs during training, making it easy to reload the model's state at a later
    time.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个示例中，我们看到了捆绑文件的使用。在Magenta中，捆绑文件是一种方便的方式，用于将**TensorFlow检查点**和元数据打包成一个单独的文件。检查点用于TensorFlow中保存训练过程中模型的状态，使得稍后能够轻松地重新加载模型状态。
- en: Another nice usage of a bundle is that it defines a **common interface** for
    multiple generators. You can check the `generator.proto` file in the Magenta's
    source code, in the `magenta/protobuf` folder, which defines that interface, including
    the generator `id` and `description`, as well as generator options such as `generate_sections`
    that we'll be using to provide the generation length in many examples.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 捆绑文件的另一个好处是，它为多个生成器定义了一个**通用接口**。你可以查看Magenta源代码中的`generator.proto`文件，该文件位于`magenta/protobuf`文件夹中，定义了该接口，包括生成器的`id`和`description`，以及生成器选项，如我们将在许多示例中使用的`generate_sections`，它用来提供生成长度。
- en: This common interface covers many models, including all of the models of Chapter
    2 and Chapter 3\. Unfortunately, bundles aren't used in Chapter 4 for the MusicVAE
    models, but we'll see more of them in [Chapter 7](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml),
    *Training Magenta Models*.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这个通用接口涵盖了许多模型，包括第2章和第3章中的所有模型。遗憾的是，第4章的MusicVAE模型没有使用捆绑文件，但我们将在[第7章](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml)
    *训练Magenta模型*中看到更多的捆绑文件。
- en: Encoding MIDI using Protobuf in NoteSequence
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Protobuf对MIDI进行编码在NoteSequence中
- en: In the last example, we saw the usage of a class named **`NoteSequence`**, which
    is an important part of Magenta, since every model working on the score will use
    it to represent a sequence of MIDI notes. `NoteSequence` and `GeneratorOptions`
    are Protobuf (Protocol Buffers), a language-neutral, platform-neutral extensible
    mechanism for serializing structured data. In Magenta's source code, in the `magenta/protobuf/music.proto` file, you
    can see the message definition of `NoteSequence`.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个示例中，我们看到了一个名为**`NoteSequence`**的类的使用，这是Magenta中的一个重要部分，因为每个处理乐谱的模型都会使用它来表示一系列MIDI音符。`NoteSequence`和`GeneratorOptions`是Protobuf（协议缓冲区）的一部分，Protobuf是一种语言中立、平台中立的可扩展机制，用于序列化结构化数据。在Magenta的源代码中，你可以在`magenta/protobuf/music.proto`文件中看到`NoteSequence`的消息定义。
- en: 'The definition of `NoteSequence` is based on a MIDI message content, so you
    have the following:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '`NoteSequence`的定义基于MIDI消息内容，因此你会看到以下内容：'
- en: 'A list of `TimeSignature` changes: By default, 4/4 is assumed per MIDI standard.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`TimeSignature`变化的列表：根据MIDI标准，默认假设为4/4。
- en: 'A list of `KeySignature` changes: By default, C Major is assumed per MIDI standard.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`KeySignature`变化的列表：根据MIDI标准，默认假设为C大调。
- en: 'A list of `Tempo` changes: By default, 120 QPM is assumed per MIDI standard.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`Tempo`变化的列表：根据MIDI标准，默认假设为120 QPM。
- en: A list of `Note` changes.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`Note`变化的列表。
- en: There's also much more including annotations, quantization information, pitch
    bend, and control changes, but we won't be looking into that in this book.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 还有更多内容，包括注释、量化信息、音高弯曲和控制变化，但在本书中我们不会深入探讨这些内容。
- en: The `Note` list is one we'll be mainly using, with the `pitch` (which is the
    MIDI note, based on the MIDI tuning standard), `start_time`, and `end_time` properties,
    representing a note.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '`Note`列表是我们主要使用的，它包含了`pitch`（即MIDI音符，基于MIDI音准标准）、`start_time`和`end_time`属性，表示一个音符。'
- en: 'Converting into and from `NoteSequence` is important. In the previous example,
    we''ve used the following functions:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 将`NoteSequence`转换为其他格式以及从其他格式转换为`NoteSequence`非常重要。在前面的示例中，我们使用了以下函数：
- en: '`magenta.music.midi_io.note_sequence_to_midi_file`: This is for converting
    from a note sequence into a MIDI file. You can also convert into `PrettyMIDI`,
    a useful format to edit MIDI in memory.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`magenta.music.midi_io.note_sequence_to_midi_file`：用于将音符序列转换为MIDI文件。你也可以转换为`PrettyMIDI`，这是一种在内存中编辑MIDI的有用格式。'
- en: '`magenta.music.midi_io.midi_file_to_note_sequence`: This is for converting
    from a MIDI file into a note sequence; this would have been useful in our previous
    example. Instead of hardcoding the primer in the Python code, we could have used
    `midi_file_to_note_sequence("primers/Jazz_Drum_Basic_1_bar.mid")`.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`magenta.music.midi_io.midi_file_to_note_sequence`：用于将MIDI文件转换为音符序列；在我们之前的示例中，这会非常有用。我们本可以使用`midi_file_to_note_sequence("primers/Jazz_Drum_Basic_1_bar.mid")`，而不是在Python代码中硬编码引导。'
- en: Another important point about `NoteSequence` is that it doesn't explicitly define
    a start and end; it just assumes it starts at the start of the first note and
    ends at the end of the last note. In other words, a sequence starting or ending
    with silence cannot be defined.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`NoteSequence`的另一个重要点是，它并没有明确地定义开始和结束；它只是假定从第一个音符的开始开始，到最后一个音符的结束结束。换句话说，不能定义以静音开始或结束的序列。
- en: 'In the following diagram, the sequence is expected to be of 2 bars, which is
    32 steps, but stops at the 31^(st) step, meaning the last note end time is 3.875
    seconds, not 4 seconds:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，预计序列为2小节，共32步，但在第31步时停止，这意味着最后一个音符的结束时间是3.875秒，而不是4秒：
- en: '![](img/5599fd77-4d46-4b29-bdc1-23b29dcbec34.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5599fd77-4d46-4b29-bdc1-23b29dcbec34.png)'
- en: Concatenating this sequence with another might yield unexpected resulting sequence
    length. Fortunately, methods that handle note sequences have options to make this
    work properly.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个序列与另一个序列连接可能会导致意外的结果序列长度。幸运的是，处理音符序列的方法有选项可以确保这正常工作。
- en: Mapping MIDI notes to the real world
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将MIDI音符映射到现实世界。
- en: 'In the previous example, we''ve shown the following 1-bar primer but we haven''t
    explained what those pitches correspond to:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们展示了以下的1小节引导，但我们并没有解释这些音高对应的内容：
- en: '[PRE29]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We won''t be going into detail in the MIDI specification since it is pretty
    big (you can check it out at [www.midi.org/specifications](https://www.midi.org/specifications)),
    but we''ll look at the parts that concern this book. Two specifications are interesting
    to us:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会详细讲解MIDI规范，因为它非常庞大（你可以在[www.midi.org/specifications](https://www.midi.org/specifications)查看），但我们会关注与本书相关的部分。有两个规范对我们来说非常有趣：
- en: The **MIDI specification** that defines the low-level protocol of communication
    and encoding between the different instruments
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MIDI规范**定义了不同乐器之间的低级通信和编码协议。'
- en: The **General MIDI specification** (**GM**) that defines a higher-level protocol,
    defining requirements for instruments to be compliant and specifying instrument
    sounds
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通用MIDI规范**（**GM**）定义了一个更高级别的协议，规定了符合要求的乐器标准，并指定了乐器的声音。'
- en: January 2019 marks the first major update of the MIDI specification since its
    standardization in 1983 with the release of MIDI 2.0 specification. That's after
    more than 25 years of usage by millions of devices and users.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 2019年1月标志着MIDI规范自1983年标准化以来的第一次重大更新，发布了MIDI 2.0规范。这是在超过25年的使用后，数百万设备和用户使用的成果。
- en: MIDI 2.0 introduces higher resolution values with 16 bits of precision instead
    of 7 and the addition of the MIDI Capability Inquiry, enabling better integration
    between tools. The new version of MIDI is completely backward compatible with
    the old version.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: MIDI 2.0引入了更高的分辨率值，精度为16位而非7位，并增加了MIDI能力查询功能，使得工具之间的集成更加顺畅。MIDI的新版本与旧版本完全向后兼容。
- en: The instrument sounds definition is interesting for us and we'll be looking
    into the **GM 1 Sound Set** specification, which defines the sound that should
    be played for each MIDI note. In GM 1 Sound Set, each MIDI Program Change (PC#)
    corresponds to a specific instrument in the synthesizer. For example, PC# 1 is
    **Acoustic Grand Piano** and PC# 42 is **Viola**. Remember, those sounds are defined
    by the synthesizer that implements the GM 1 specification and might change from
    synth to synth.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 乐器声音定义对我们来说很有趣，我们将研究**GM 1 音色集**规范，它定义了每个MIDI音符应该播放的声音。在GM 1音色集中，每个MIDI程序变化（PC#）对应合成器中的一个特定乐器。例如，PC#
    1是**原声大钢琴**，PC# 42是**中提琴**。记住，这些声音是由实现GM 1规范的合成器定义的，可能会因合成器不同而有所变化。
- en: 'The percussion keymap is a bit different. On MIDI Channel 10, each MIDI note
    number (pitch) corresponds to a specific drum sound. Our previous example can
    be read as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 打击乐键盘映射有些不同。在MIDI通道10上，每个MIDI音符编号（音高）对应一个特定的鼓声。我们之前的示例可以如下解读：
- en: '**36**: Bass Drum 1'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**36**：低音鼓1'
- en: '**38**: Acoustic Snare'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**38**：木质军鼓'
- en: '**44**: Pedal Hi-Hat'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**44**：踏板高帽'
- en: '**51**: Ride Cymbal 1'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**51**：踩镲1'
- en: You can always refer to the full table later at [www.midi.org/specifications-old/item/gm-level-1-sound-set](https://www.midi.org/specifications-old/item/gm-level-1-sound-set).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以随时参考[www.midi.org/specifications-old/item/gm-level-1-sound-set](https://www.midi.org/specifications-old/item/gm-level-1-sound-set)上的完整表格。
- en: Encoding percussion events as classes
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将打击乐事件编码为类别
- en: The last section explained percussion mapping in terms of MIDI mapping. But
    how do we encode the percussion for the Drums RNN model? To encode the MIDI mapping
    to a vector, we'll use what is called **one**-**hot encoding**, which basically
    maps every possible input events to classes then to a binary vector.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 上一部分解释了按MIDI映射的打击乐映射。那么，我们如何为鼓RNN模型编码打击乐呢？为了将MIDI映射编码为一个向量，我们将使用所谓的**独热编码**，这基本上是将每个可能的输入事件映射到类别，然后映射到二进制向量。
- en: For that to happen, we need to reduce the number of drum classes first, from
    all of the possible drums in MIDI (46 different drums is way too much) to a more
    manageable 9 classes. You can see the mapping in the `DEFAULT_DRUM_TYPE_PITCHES` property of
    the `magenta.music.drums_encoder_decoder` module. We then bit flip in a vector
    at the index defined by summing two to the power of the class index for each class
    in the set.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，我们需要首先减少鼓类的数量，将MIDI中所有可能的鼓（46种不同的鼓实在太多）减少到更易管理的9个类别。你可以在`DEFAULT_DRUM_TYPE_PITCHES`属性中看到该映射，它位于`magenta.music.drums_encoder_decoder`模块中。然后，我们在一个向量中进行按位翻转，索引由将类索引的2的幂相加所定义。
- en: For example, our set of pitches, *{51, 38}*, for the first step maps to classes
    *{8, 1}*. This value will bit flip index 258 in the vector, because *2⁸ + 2¹ =
    258*. The vector is of the size 2⁹ for each step, plus some binary counters and
    flags we won't talk about here.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们的音高集合*{51, 38}*，对于第一步映射到类别*{8, 1}*。这个值会在向量中的索引258处按位翻转，因为*2⁸ + 2¹ = 258*。该向量对于每一步的大小是2⁹，还包含一些二进制计数器和标志，我们在这里不讨论这些。
- en: 'This diagram shows the encoding part of the first step of the primer example
    as described:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图展示了初始示例第一步的编码部分，如所述：
- en: '![](img/b159a218-91b0-47dc-96c8-872cfb84fa5c.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b159a218-91b0-47dc-96c8-872cfb84fa5c.png)'
- en: In that specific encoding, some information is lost because there are less class
    then MIDI notes. This means that, for example, if both MIDI notes, 35 and 36,
    map to the same class index 0, then the difference between either 35 or 36 is
    lost. In that specific case, 36 is chosen arbitrarily (you can actually see that
    from the previous example in the section, *Priming the model with Led Zeppelin*,
    the MIDI note 35 is lost).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个特定的编码中，有些信息会丢失，因为类别比MIDI音符少。这意味着，例如，如果MIDI音符35和36都映射到相同的类别索引0，那么35和36之间的区别就丢失了。在这种特定情况下，36被任意选择（你实际上可以从上一篇文章《为模型做初步训练（Led
    Zeppelin）》中的示例看到，MIDI音符35丢失了）。
- en: This encoding is used for training when converting from the dataset into the
    sequences, and during generation, if a primer is used to initialize the model.
    When using a primer, the primer is encoded to produce input for the model. The
    model state is then initialized with that input.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 这种编码用于训练时将数据集转换为序列，在生成过程中，如果使用了引导序列来初始化模型时也会用到。使用引导序列时，引导序列会被编码为模型的输入。然后，模型状态会使用该输入进行初始化。
- en: 'The reverse of that operation is also important for a generation: when the
    model makes a new generation, it needs to be decoded to find the sequence it represents.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 该操作的逆过程对于生成同样重要：当模型进行新生成时，需要解码以找到它所代表的序列。
- en: There are different ways of encoding the events, and others are used in Magenta.
    This is the encoding for the "drum_kit" configuration for this model, which is `LookbackEventSequenceEncoderDecoder`,
    implementing the encoding of repeated events using binary counters. The encoding
    of the `one_drum` configuration is different and simpler; you can check it out
    in `OneHotEventSequenceEncoderDecoder`.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法用于编码事件，而 Magenta 中使用了不同的编码方式。这是该模型的 "drum_kit" 配置的编码方式，使用 `LookbackEventSequenceEncoderDecoder`，通过二进制计数器实现重复事件的编码。`one_drum`
    配置的编码方式则不同且更简单，你可以在 `OneHotEventSequenceEncoderDecoder` 中查看。
- en: The one-hot encoding of the drum classes is implemented in the `MultiDrumOneHotEncoding` class,
    which is used in other models as well, such as the MusicVAE model we'll see in
    Chapter 4\. When instantiated with no drum pitches, it will use the reduced drum
    encoding of 9 classes that we saw in this section, which is expressive enough
    to capture many instruments, while keeping the model at a manageable size.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓类的 one-hot 编码实现于 `MultiDrumOneHotEncoding` 类中，这个类也被其他模型使用，例如我们将在第 4 章中看到的 MusicVAE
    模型。当没有鼓音高被传入时，它将使用我们在本节中看到的 9 类简化鼓编码，这种编码足够表达多种乐器，同时保持模型的可管理性。
- en: We'll be seeing more on the subject of encoding in the following chapters.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中进一步讨论编码的相关内容。
- en: Sending MIDI files to other applications
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 MIDI 文件发送到其他应用程序
- en: While generating MIDI files and writing them on disk is nice, dynamically sending
    the MIDI notes to another piece of software would be more useful, so that our
    Python Magenta application could interact directly with other music software.
    We will dedicate a whole chapter to this topic since there is a lot to talk about.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然生成 MIDI 文件并将其写入磁盘是不错的，但是将 MIDI 音符动态地发送到另一个软件会更有用，这样我们的 Python Magenta 应用程序就能直接与其他音乐软件互动。我们将为此话题专门设立一个章节，因为有很多内容需要讨论。
- en: If you want to know more about this topic right now, you can go see [Chapter
    9](8018122a-b28e-44ff-8533-5061a0ad356b.xhtml), *Making Magenta Interact with
    Music Applications*, and come back here later.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在想了解更多关于这个话题的信息，可以去查看[第 9 章](8018122a-b28e-44ff-8533-5061a0ad356b.xhtml)，*让
    Magenta 与音乐应用程序互动*，然后再回来这里。
- en: Summary
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we introduced an RNN and the role it plays in music generation,
    by showing that operating on a sequence and remembering the past are mandatory
    properties for music generation.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了 RNN 以及它在音乐生成中的作用，展示了在处理序列和记忆过去信息方面，RNN 是音乐生成的必要属性。
- en: We also generated a MIDI file using the Drums RNN model on the command line.
    We've covered most of its parameters and learned how to configure the model's
    output. By looking at the generation algorithm, we explained how it worked and
    how the different flags can change its execution.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用命令行中的 Drums RNN 模型生成了一个 MIDI 文件。我们已经涵盖了大部分参数，并学习了如何配置模型的输出。通过查看生成算法，我们解释了它是如何工作的，以及不同的标志如何改变其执行过程。
- en: By using the Drums RNN model in Python, we've shown how we can build a versatile
    application. By doing that, we learned about the MIDI specification, how Magenta
    encodes `NoteSequence` using Protobuf, and how to encode a sequence as a one-hot
    vector. We've also introduced the idea of sending the generated MIDI to other
    applications, a topic we'll cover in [Chapter 9](8018122a-b28e-44ff-8533-5061a0ad356b.xhtml),
    *Making Magenta Interact with Music Applications*.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在 Python 中使用 Drums RNN 模型，我们展示了如何构建一个多功能的应用程序。通过这个过程，我们了解了 MIDI 规范、Magenta
    如何使用 Protobuf 编码 `NoteSequence`，以及如何将序列编码为 one-hot 向量。我们还介绍了将生成的 MIDI 发送到其他应用程序的概念，这个话题将在[第
    9 章](8018122a-b28e-44ff-8533-5061a0ad356b.xhtml)，*让 Magenta 与音乐应用程序互动*中进一步探讨。
- en: In the next chapter, we'll be using other models to generate melody. We'll also
    continue writing Python code by finishing our learning of RNNs.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将使用其他模型来生成旋律。我们还将继续编写 Python 代码，完成对 RNN 的学习。
- en: Questions
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: If you want to generate a musical score, what do you train your model to do?
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想生成一段乐谱，你需要训练你的模型去做什么？
- en: What are the properties that are interesting in RNNs concerning music prediction?
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在音乐预测中，RNN的哪些特性是有趣的？
- en: Given an RNN hidden layer with the notation *h(t + 2)*, what two inputs is the
    hidden layer getting?
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定一个RNN的隐藏层表示*h(t + 2)*，该隐藏层接收到的两个输入是什么？
- en: Given the following parameters for the generation, `--num_steps 32` and `--qpm
    80`, how long will the generated MIDI be in seconds? How many bars will it be?
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给定生成的以下参数，`--num_steps 32`和`--qpm 80`，生成的MIDI文件会有多长时间？它会有多少小节？
- en: What happens if you increase `--branch_factor` and increase `--temperature`
    during the generation phase?
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果在生成阶段增加`--branch_factor`并提高`--temperature`，会发生什么？
- en: How many nodes will the beam search algorithm go through at the last iteration
    for a generation of 3 steps with the `--branch_factor 4` and `--beam_size 2` parameters?
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在生成3步的过程中，使用`--branch_factor 4`和`--beam_size 2`参数，束搜索算法在最后一次迭代中会经过多少个节点？
- en: What is the Protobuf Message class that is used in Magenta to represent a sequence
    of MIDI notes? (NoteSequence)
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Magenta中用于表示MIDI音符序列的Protobuf消息类是什么？（NoteSequence）
- en: Using the one-hot encoding described in the encoding section, what is the encoded
    vector for a step playing the MIDI notes, *{36, 40, 42}*?
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用编码部分描述的独热编码，对于播放MIDI音符*{36, 40, 42}*的一个步骤，其编码向量是什么？
- en: Using the same encoding, what are the decoded MIDI notes from an encoded vector
    with index 131 at 1?
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用相同的编码，从一个索引为131的编码向量中，解码得到的MIDI音符是什么？
- en: Further reading
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '**The Unreasonable Effectiveness of Recurrent Neural Networks**: An excellent
    article on RNNs ([karpathy.github.io/2015/05/21/rnn-effectiveness/](https://karpathy.github.io/2015/05/21/rnn-effectiveness/))'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**循环神经网络的非凡效力**：关于RNN的优秀文章（[karpathy.github.io/2015/05/21/rnn-effectiveness/](https://karpathy.github.io/2015/05/21/rnn-effectiveness/))'
- en: '**Understanding softmax and the negative log-likelihood**: Complimentary information
    on log-likelihood ([ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/](https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/))'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**理解softmax和负对数似然**：关于对数似然的补充信息（[ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/](https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/))'
- en: '**Finding Structure in Time**: An original paper (1990) on RNNs ([crl.ucsd.edu/~elman/Papers/fsit.pdf)](https://crl.ucsd.edu/~elman/Papers/fsit.pdf)'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间中的结构发现**：关于RNN的原创论文（1990）（[crl.ucsd.edu/~elman/Papers/fsit.pdf](https://crl.ucsd.edu/~elman/Papers/fsit.pdf)）'
- en: '**Gradient-Based Learning Applied to Document Recognition**: An original paper
    (1998) on CNNs ([yann.lecun.com/exdb/publis/pdf/lecun-98.pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf))'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于梯度的学习在文档识别中的应用**：关于CNN的原创论文（1998）（[yann.lecun.com/exdb/publis/pdf/lecun-98.pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)）'
- en: '**The Neural Network Zoo**: An amazing list of neural network architectures
    that you can refer to throughout this book ([asimovinstitute.org/neural-network-zoo/](https://www.asimovinstitute.org/neural-network-zoo/))'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经网络动物园**：一个惊人的神经网络架构列表，你可以在整本书中参考（[asimovinstitute.org/neural-network-zoo/](https://www.asimovinstitute.org/neural-network-zoo/)）'
