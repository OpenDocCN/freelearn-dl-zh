- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Customizing Models for Enhanced Performance
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定制模型以提升性能
- en: When general-purpose models fall short of delivering satisfactory results for
    your domain-specific use case, customizing FMs becomes crucial. This chapter delves
    into the process of customizing FMs while using techniques such as fine-tuning
    and continued pre-training to enhance their performance. We’ll begin by examining
    the rationale behind customizing the base FM and exploring the mechanics of fine-tuning.
    Subsequently, we will delve into data preparation techniques to ensure our data
    is formatted appropriately for creating a custom model using both the AWS console
    and APIs. We will understand various components within model customization and
    different customization APIs that you can call from your application.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当通用模型无法满足你特定领域用例的满意结果时，定制 FM 就变得至关重要。本章将深入探讨定制 FM 的过程，同时使用微调和持续预训练等技术来提升其性能。我们将首先检查定制基础
    FM 的理由，并探讨微调的机制。随后，我们将深入研究数据准备技术，以确保我们的数据格式适当，以便使用 AWS 控制台和 API 创建自定义模型。我们将了解模型定制中的各种组件以及你可以从应用程序中调用的不同定制
    API。
- en: Furthermore, we will analyze the model’s behavior and perform inference. Finally,
    we will conclude this chapter by discussing guidelines and best practices for
    customizing Bedrock models.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将分析模型的行为并执行推理。最后，我们将通过讨论定制 Bedrock 模型的指南和最佳实践来结束本章。
- en: By the end of this chapter, you will be able to understand the importance and
    process of customizing a model for your domain-specific use case.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，你将能够理解为特定领域用例定制模型的重要性和过程。
- en: 'The following key topics will be covered in this chapter:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下关键主题：
- en: Why is customizing FMs important?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么定制 FM 很重要？
- en: Understanding model customization
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解模型定制
- en: Preparing the data
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备数据
- en: Creating a custom model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建自定义模型
- en: Analyzing the results
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析结果
- en: Guidelines and best practices
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指南和最佳实践
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you need to have access to an *AWS* account. If you don’t
    have one, you can go to [https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)
    and create an AWS account.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，你需要访问一个 *AWS* 账户。如果你没有，你可以访问 [https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)
    并创建一个 AWS 账户。
- en: Once you have access to an AWS account, you will need to install and configure
    the AWS CLI ([https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)) so that
    you can access Amazon Bedrock FMs from your local machine. In addition, you will
    need to set up the AWS Python SDK (Boto3) since the majority of the code cells
    we will be executing require it ([https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html)).
    You can set up Python by installing it on your local machine, using AWS Cloud9,
    utilizing AWS Lambda, or leveraging Amazon SageMaker.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了 AWS 账户，你需要安装和配置 AWS CLI ([https://aws.amazon.com/cli/](https://aws.amazon.com/cli/))，以便从你的本地机器访问
    Amazon Bedrock FM。此外，你还需要设置 AWS Python SDK (Boto3)，因为我们将执行的多数代码单元格都需要它 ([https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html))。你可以通过在你的本地机器上安装
    Python、使用 AWS Cloud9、利用 AWS Lambda 或利用 Amazon SageMaker 来设置 Python。
- en: Note
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: There will be a charge associated with invocating and customizing the FMs of
    Amazon Bedrock. Please refer to [https://aws.amazon.com/bedrock/pricing/](https://aws.amazon.com/bedrock/pricing/)
    to learn more.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 使用和定制 Amazon Bedrock 的 FM 将会产生费用。请参阅 [https://aws.amazon.com/bedrock/pricing/](https://aws.amazon.com/bedrock/pricing/)
    了解更多信息。
- en: Why is customizing FMs important?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么定制 FM 很重要？
- en: 'In the previous chapter, we looked at several prompt engineering techniques
    to improve the performance of a model. As we also saw in [*Chapter 1*](B22045_01.xhtml#_idTextAnchor014)
    (and shown in *Figure 4**.1*), these FMs are trained on massive amounts of data
    (GBs, TBs, or PBs) with millions to billions of parameters, allowing them to understand
    relationships between words in context to predict subsequent sequences:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们探讨了几个提示工程技术来提高模型性能。正如我们在 [*第 1 章*](B22045_01.xhtml#_idTextAnchor014)
    （如图 *4**.1* 所示）中看到的那样，这些 FM 在海量数据（GBs、TBs 或 PBs）上训练，拥有数百万到数十亿个参数，这使得它们能够理解上下文中词语之间的关系，以预测后续序列：
- en: '![Figure 4.1 – Training an FM](img/B22045_04_01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1 – 训练 FM](img/B22045_04_01.jpg)'
- en: Figure 4.1 – Training an FM
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – 训练 FM
- en: '*So, why do we need to customize* *these models?*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*那么，为什么我们需要定制这些模型呢？*'
- en: That’s a fair question since a lot of use cases can be directly solved by using
    prompt engineering and RAG techniques (which we will cover in [*Chapter 5*](B22045_05.xhtml#_idTextAnchor090)).
    However, consider a situation where you require the model to adhere to a particular
    writing style, output format, or domain-specific terminology. For instance, you
    may need the model to analyze financial earnings reports or medical records accurately.
    In such cases, the pre-trained models might not have been exposed to the desired
    writing style or specialized vocabularies, limiting their performance despite
    effective prompt crafting or RAG implementation.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个合理的问题，因为许多用例可以直接通过使用提示工程和 RAG 技术来解决（我们将在[*第五章*](B22045_05.xhtml#_idTextAnchor090)中介绍）。然而，考虑一种情况，你需要模型遵守特定的写作风格、输出格式或特定领域的术语。例如，你可能需要模型准确地分析财务收益报告或医疗记录。在这种情况下，预训练模型可能没有接触到所需的写作风格或专业词汇，尽管提示工程或
    RAG 的实施是有效的，但它们的性能仍然受限。
- en: 'To bridge this gap and enhance the model’s domain-specific language understanding
    and generation capabilities, customization becomes essential. By fine-tuning the
    pre-trained models on domain-specific data or adapting them to the desired writing
    style or output format, you can tailor their performance to meet your unique requirements,
    ensuring more accurate and relevant responses:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了弥合这一差距并增强模型在特定领域的语言理解和生成能力，定制变得至关重要。通过在特定领域数据上微调预训练模型或调整它们以适应所需的写作风格或输出格式，你可以调整其性能以满足你的独特需求，确保更准确和相关的响应：
- en: '![Figure 4.2 – Generative AI performance techniques](img/B22045_04_02.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 – 生成式 AI 性能技术](img/B22045_04_02.jpg)'
- en: Figure 4.2 – Generative AI performance techniques
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 生成式 AI 性能技术
- en: If you look at the spectrum of generative AI performance techniques shown in
    *Figure 4**.2* for improving the performance of FMs, it ranges from prompt engineering
    to training the model from scratch. For domain-specific data, prompt engineering
    techniques may provide low accuracy, but they involve less effort and are cost-effective.
    Prompt engineering is a better option if you have a simple task and don’t need
    a new domain-specific dataset. If you would like to understand how prompt engineering
    works, please go back to [*Chapter 3*](B22045_03.xhtml#_idTextAnchor053).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看 *图 4**.2* 中显示的生成式 AI 性能技术谱系，以改进 FM 的性能，它从提示工程到从头开始训练模型。对于特定领域的数据，提示工程技术可能提供较低的准确性，但它们涉及较少的努力且成本效益高。如果你有一个简单的任务且不需要新的特定领域数据集，提示工程是一个更好的选择。如果你想了解提示工程是如何工作的，请回到[*第三章*](B22045_03.xhtml#_idTextAnchor053)。
- en: Next on the spectrum with a little bit of increasing complexity, cost, and accuracy
    is RAG. This technique fetches data from outside the language model, such as from
    internal knowledge bases or external sources. It is a particularly useful technique
    when you have large corpora of documents that do not fit the context length of
    the model. We will discuss RAG in more detail in [*Chapter 5*](B22045_05.xhtml#_idTextAnchor090).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在谱系中，随着复杂度、成本和准确性的略微增加，接下来是 RAG 技术。这种技术从语言模型外部获取数据，例如从内部知识库或外部来源。当你拥有大量不适合模型上下文长度的文档语料库时，这是一个特别有用的技术。我们将在[*第五章*](B22045_05.xhtml#_idTextAnchor090)中更详细地讨论
    RAG。
- en: Further on the spectrum, customizing the model is essentially more time-consuming
    and costly. However, it provides greater accuracy to your specialized use case.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在谱系的进一步位置，定制模型本质上需要更多的时间和成本。然而，它为你的特定用例提供了更高的准确性。
- en: 'There are two customization techniques within Amazon Bedrock: fine-tuning and
    continued pretraining.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Amazon Bedrock 中有两种定制技术：微调和持续预训练。
- en: In *fine-tuning*, the model is trained with the labeled dataset – a supervised
    learning approach. The labeled dataset that you provide will be specific to your
    use case. Whether you’re working in healthcare, finance, or any other field, you
    can fine-tune your model to become an expert in that particular domain. In healthcare,
    for example, the model can be fine-tuned for medical specialization, allowing
    it to understand and interpret medical records with greater accuracy. Similarly,
    a financial analysis model can be fine-tuned for niche financial analysis, enabling
    it to identify patterns and trends in financial data that may be missed by traditional
    algorithms.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在**微调**中，模型使用带标签的数据集进行训练——这是一种监督学习方法。您提供的带标签数据集将针对您的特定用例。无论您在医疗保健、金融还是任何其他领域工作，您都可以微调您的模型，使其成为该特定领域的专家。例如，在医疗保健领域，模型可以针对医学专业进行微调，使其能够以更高的准确性理解和解释医疗记录。同样，一个财务分析模型可以针对特定领域的财务分析进行微调，使其能够识别出传统算法可能错过的金融数据中的模式和趋势。
- en: 'To fine-tune a model using your own data, you need to have a sufficient amount
    of high-quality data that is relevant to the task you want to perform. This data
    should be labeled and annotated to provide the model with the necessary information
    for training. As shown in *Figure 4**.3*, we can use this labeled dataset to fine-tune
    the base FM, which then generates a custom model. You can then use the custom
    model to generate responses that are tailored to your specific domain and use
    case:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用您自己的数据微调模型，您需要拥有足够数量的与您想要执行的任务相关的高质量数据。这些数据应该是标记和注释的，以便为模型提供训练所需的必要信息。如图*4.3*所示，我们可以使用这个标记数据集来微调基础FM，然后生成一个定制模型。然后，您可以使用这个定制模型生成针对您特定领域和用例的响应：
- en: '![Figure 4.3 – Fine-tuning](img/B22045_04_03.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图4.3 – 微调](img/B22045_04_03.jpg)'
- en: Figure 4.3 – Fine-tuning
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 – 微调
- en: For example, let’s say you work in the medical industry and would like to summarize
    a dialog between two doctors discussing the medical report of the patient, extract
    the information to be put into medical forms, and maybe write it in layman’s terms.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设您在医疗行业工作，并希望总结两位医生讨论患者医疗报告的对话，提取需要放入医疗表格的信息，也许还可以用通俗易懂的语言来撰写。
- en: In this case, the base FMs might not be trained on the domain-specific dataset.
    Hence, this is an example scenario where when we perform fine-tuning, we will
    provide the model with labeled examples of how the prompt and response should
    look like.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，基础FM可能没有在特定领域的数据集上进行训练。因此，这是一个示例场景，当我们进行微调时，我们将向模型提供标记示例，说明提示和响应应该如何呈现。
- en: 'In *continued pre-training*, we adapt to a new domain or train the model to
    learn the terminologies of an unfamiliar domain. This involves providing additional
    continuous training to an FM while utilizing large amounts of unlabeled data.
    When we say unlabeled data, we mean that there is no target label, and the model
    will learn the patterns from the provided texts. This contrasts with fine-tuning,
    which involves using smaller quantities of labeled data. *Figure 4**.4* highlights
    the difference between the labeled and unlabeled data that’s required for continued
    pre-training and fine-tuning, respectively:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在**持续预训练**中，我们适应新的领域或训练模型学习不熟悉领域的术语。这涉及到向FM提供额外的连续训练，同时利用大量未标记数据。当我们说未标记数据时，意味着没有目标标签，模型将从提供的文本中学习模式。这与微调形成对比，微调涉及使用较小量的标记数据。*图4.4*突出了持续预训练和微调所需的标记数据与未标记数据之间的差异：
- en: '![Figure 4.4 – Unlabeled versus labeled data](img/B22045_04_04.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图4.4 – 未标记数据与标记数据](img/B22045_04_04.jpg)'
- en: Figure 4.4 – Unlabeled versus labeled data
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4 – 未标记数据与标记数据
- en: 'Examples of continued pre-training can include training the model to learn
    the terminologies of the financial industry so that it can understand financial
    reports, or training the model to learn quantum physics by giving it abundant
    information from books so that it will be able to evaluate/predict the tokens
    associated with string theory with greater accuracy. Let’s say that two physicists
    are having a dialog around string theory, and we pass that dialog as a context
    to the base FM (as shown in *Figure 4**.5*):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 持续预训练的例子可能包括训练模型学习金融行业的术语，以便它能够理解财务报告，或者通过提供大量来自书籍的信息来训练模型学习量子物理学，这样它将能够以更高的准确性评估/预测与弦理论相关的标记。假设两位物理学家正在讨论弦理论，我们将这个对话作为上下文传递给基础FM（如图*4.5*所示）：
- en: '![Figure 4.5 – Quantum physicist dialog and question](img/B22045_04_05.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图4.5 – 量子物理学家对话和问题](img/B22045_04_05.jpg)'
- en: Figure 4.5 – Quantum physicist dialog and question
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 – 量子物理学家对话和问题
- en: It could be possible that the base FM we are using here isn’t familiar with
    quantum physics – that is, the base FM hasn’t been trained on a dataset related
    to quantum physics.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 可能的情况是，我们在这里使用的基FM对量子物理不熟悉——也就是说，基FM尚未在涉及量子物理的数据集上训练过。
- en: So, when we ask the model a question such as `What are E8 x E8 symmetry groups?`,
    the model hallucinates and doesn’t explain this concept since it doesn’t know
    about string theory.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当我们向模型提出诸如“E8 x E8对称群是什么？”这样的问题时，模型会幻想并无法解释这个概念，因为它不了解弦理论。
- en: 'With continued pre-training, we train the model on an unfamiliar domain by
    providing the base FM with a large amount of unlabeled datasets. For example,
    we could train the model on textbooks about quantum computing in the desired format,
    as explained in the *Preparing the data* section, which then creates a custom
    model (as shown in *Figure 4**.6*):'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通过持续的预训练，我们通过向基础FM提供大量未标记数据集来在未知领域训练模型。例如，我们可以在*准备数据*部分所述的期望格式上训练关于量子计算的书本模型，从而创建一个自定义模型（如图*图4**.6*所示）：
- en: '![Figure 4.6 – Continued pre-training](img/B22045_04_06.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图4.6 – 持续的预训练](img/B22045_04_06.jpg)'
- en: Figure 4.6 – Continued pre-training
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6 – 持续的预训练
- en: Continued pre-training presents certain challenges. As we are training the entire
    model, the weights and biases are what demand heavy computational resources and
    diverse unlabeled text data.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 持续的预训练带来了一定的挑战。由于我们正在训练整个模型，权重和偏差需要大量的计算资源和多样化的未标记文本数据。
- en: 'When you’re deciding whether to use custom models over other methods, such
    as prompt engineering and RAG, several factors come into play. These include the
    task that you are working on, the availability of data, computational resources,
    and cost. Here are some guidelines to help you make an informed decision:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当您决定是否使用自定义模型而不是其他方法，如提示工程和RAG时，有几个因素会发挥作用。这些包括您正在处理的任务、数据的可用性、计算资源和成本。以下是一些指导方针，以帮助您做出明智的决定：
- en: '**Complexity level**: Creating custom models is particularly useful when you
    have tasks that are complex and require the model to understand intricate details.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂度级别**：当您有复杂任务且需要模型理解复杂细节时，创建自定义模型特别有用。'
- en: '**Specialized data**: Having a sufficient amount of specialized data for creating
    custom models will provide remarkable results. Make sure your data is clean (free
    from errors, inconsistencies, and duplicates) and prepared (formatted, transformed,
    and split into appropriate subsets) before you start the training process.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专业数据**：在创建自定义模型时，拥有足够数量的专业数据将带来显著的结果。在开始训练过程之前，请确保您的数据是干净的（无错误、不一致和重复），并且已经准备好（格式化、转换并分成适当的子集）。'
- en: '**Computational resources and cost**: When you create custom models, you’ll
    need to purchase Provisioned Throughput, which gives you a dedicated capacity
    to deploy the model. Make sure you review the pricing based on the model type
    and commitment terms. We will discuss Provisioned Throughput in detail in the
    *Analyzing the results* section of this chapter.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算资源和成本**：当您创建自定义模型时，您需要购买预留吞吐量，这为您提供了部署模型的专用容量。请确保您根据模型类型和承诺条款审查价格。我们将在本章的*分析结果*部分详细讨论预留吞吐量。'
- en: In addition, creating custom models provides you with greater control over how
    you want the model to respond. You can customize it precisely to your needs, making
    it suitable for tasks that require fine-grained customization, such as responding
    in a specific tone, dialect, or inclusive language.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，创建自定义模型使您能够更好地控制模型如何响应。您可以精确地根据您的需求进行定制，使其适合需要精细定制的任务，例如以特定的语气、方言或包容性语言进行响应。
- en: Let’s understand some key concepts of model customization before we start our
    first model customization job.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始我们的第一个模型定制工作之前，让我们了解一些模型定制的关键概念。
- en: Understanding model customization
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解模型定制
- en: The principle behind fine-tuning and continued pre-training comes from the broad
    concept of **transfer learning**, which, as its name suggests, entails transferring
    knowledge that’s been acquired from one problem to other often related but distinct
    problems. This practice is widely employed in the field of **machine learning**
    (**ML**) to enhance the performance of models on new tasks or domains.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 微调和持续预训练背后的原理来自广泛的概念**迁移学习**，正如其名称所暗示的，它涉及将从一个问题获得的知识转移到其他通常相关但不同的问题上。这种做法在**机器学习**（**ML**）领域被广泛采用，以提高模型在新任务或领域上的性能。
- en: 'Model customization is a five-step process:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 模型定制是一个五步过程：
- en: '**Identify your use case and data**: Identifying the use case/task and how
    it solves your organization’s business objectives is a critical step. Do you want
    to summarize legal documents, perform Q&A on medical reports, or do something
    else? Once you’ve identified the use case, you must gather enough relevant datasets
    that you can use for model customization. The dataset should contain examples
    that the model can learn intricate details from. Remember, how your custom model
    performs on your task-specific use case depends on the quality of the dataset
    that you provide for training.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**确定你的用例和数据**：确定用例/任务以及它是如何解决你组织业务目标的，这是一个关键步骤。你是想总结法律文件，对医疗报告进行问答，还是做其他事情？一旦确定了用例，你必须收集足够的相关数据集，以便你可以用于模型定制。数据集应包含模型可以从中学习复杂细节的示例。记住，你的定制模型在特定任务用例上的表现取决于你为训练提供的训练数据集的质量。'
- en: '**Prepare the dataset**: Once you’ve gathered the dataset, you have to clean
    and preprocess it. For fine-tuning, you need to have labeled examples in **JSON
    lines** (**JSONL**) format. For continued pre-training, you need to have unlabeled
    examples in JSONL format. We will discuss this in more detail in the *Preparing
    the* *data* section.'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**准备数据集**：一旦收集了数据集，你必须对其进行清理和预处理。对于微调，你需要有**JSON行**（**JSONL**）格式的标记示例。对于持续预训练，你需要有JSONL格式的未标记示例。我们将在*准备数据*部分更详细地讨论这一点。'
- en: '**Select the base pre-trained model**: Once the dataset has been prepared,
    you have to select an existing base pretrained model that you would like to fine-tune.
    You can look at the website of the model provider to understand the model attributes.
    If it is fit for your use case, try prompt engineering techniques to check which
    model responds closest to what you are looking for, and also evaluate the FMs
    using **Model evaluation** within Amazon Bedrock or using **Model leaderboards**:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择基础预训练模型**：一旦准备好的数据集，你必须选择一个现有的基础预训练模型，你希望对其进行微调。你可以查看模型提供者的网站来了解模型属性。如果它适合你的用例，尝试提示工程技术来检查哪个模型最接近你想要的结果，并使用Amazon
    Bedrock中的**模型评估**或**模型排行榜**来评估FM：'
- en: '*Model evaluation*: Bedrock provides two distinct evaluation methods: automatic
    evaluation and human evaluation. Automatic evaluation utilizes predefined metrics
    such as accuracy, robustness, and toxicity screening, whereas with human evaluation,
    you can define custom metrics such as friendliness, stylistic adherence, or alignment
    with brand voice. We will have a more detailed discussion on model evaluation
    in [*Chapter 11*](B22045_11.xhtml#_idTextAnchor207).'
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型评估*：Bedrock提供了两种不同的评估方法：自动评估和人工评估。自动评估使用预定义的指标，如准确率、鲁棒性和毒性筛选，而人工评估则可以定义自定义指标，如友好性、风格遵循或与品牌声音的一致性。我们将在[*第11章*](B22045_11.xhtml#_idTextAnchor207)中对模型评估进行更详细的讨论。'
- en: '*Model leaderboards*: Several leaderboards are available that rank models based
    on their performance on various tasks, such as text generation, summarization,
    sentiment analysis, and more. Some of the most popular leaderboards include **General
    Language Understanding Evaluation** (**GLUE**), SuperGLUE, HELM, and OpenLLM by
    HuggingFace.'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型排行榜*：有多个排行榜可以根据模型在各项任务上的性能进行排名，例如文本生成、摘要、情感分析等。其中一些最受欢迎的排行榜包括**通用语言理解评估**（**GLUE**）、SuperGLUE、HELM和HuggingFace的OpenLLM。'
- en: Please note that although it’s good to understand the performance of the FM
    through leaderboards, for real-world use cases, you have to be cautious and not
    rely solely on leaderboards as they may lack the robustness required to mirror
    the complexity of real-world use.
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，虽然通过排行榜了解FM的性能是好的，但对于实际应用场景，你必须谨慎，不要仅仅依赖排行榜，因为它们可能缺乏反映现实世界复杂性的鲁棒性。
- en: '**Configure and start the fine-tuning job**: Once you’ve identified the base
    FM and the dataset is ready, you can configure the fine-tuning job by specifying
    hyperparameters, the input and output S3 path for the dataset and store metrics,
    respectively, and networking and security settings. We will discuss this in more
    detail in the *Creating a custom* *model* section.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**配置并启动微调作业**：一旦你确定了基础 FM 并且数据集准备就绪，你可以通过指定超参数、数据集的输入和输出 S3 路径以及存储指标，以及网络和安全设置来配置微调作业。我们将在“*创建自定义模型*”部分更详细地讨论这一点。'
- en: '**Evaluate and iterate**: Once the model is ready, you can evaluate and analyze
    it based on the metrics and logs stored by the model. To do so, you can put aside
    a validation set that provides the performance metric of the custom model you’ve
    created. We will discuss this in more detail in the *Analyzing the* *results*
    section.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估和迭代**：一旦模型准备就绪，你可以根据模型存储的指标和日志来评估和分析它。为此，你可以留出一个验证集，它提供了你创建的自定义模型的性能指标。我们将在“*分析结果*”部分更详细地讨论这一点。'
- en: When we are customizing a model, Amazon Bedrock creates a copy of the base FM,
    on which we essentially update its model weights. **Weights** are key components
    in **artificial neural networks** (**ANNs**) and are attached to the inputs (or
    features). These weights define which features are important in predicting the
    output and getting better at specific tasks. *Figure 4**.7* shows a simplified
    ANN architecture where these inputs, along with their weights, are processed by
    **summation** and the **activation function** (both defined in the model algorithm)
    to get the output (**Y**).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们定制模型时，Amazon Bedrock 会创建一个基础 FM 的副本，我们实际上是在更新其模型权重。**权重**是**人工神经网络**（**ANNs**）中的关键组件，它们附着在输入（或特征）上。这些权重定义了哪些特征在预测输出和提升特定任务方面是重要的。*图
    4.7* 展示了一个简化的 ANN 架构，其中这些输入及其权重通过**求和**和**激活函数**（两者均在模型算法中定义）进行处理，以获得输出（**Y**）。
- en: '![Figure 4.7 – Simplified ANN](img/B22045_04_07.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7 – 简化的人工神经网络](img/B22045_04_07.jpg)'
- en: Figure 4.7 – Simplified ANN
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – 简化的人工神经网络
- en: For a deeper dive into ANNs, there are numerous online tutorials and courses
    available that provide in-depth explanations and examples of neural network concepts,
    architectures, and training techniques. Additionally, textbook classics such as
    *Neural Networks and Deep Learning, Michael Nielsen, Determination Press* and
    *Deep Learning, Ian Goodfellow, Yoshua Bengio, and Aaron Courville, MIT Press*
    offer comprehensive theoretical and mathematical foundations.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 想要深入了解人工神经网络（ANNs），网上有大量的教程和课程可供选择，它们提供了关于神经网络概念、架构和训练技术的深入解释和示例。此外，像《神经网络与深度学习，迈克尔·尼尔森，
    Determination Press》和《深度学习，伊恩·古德费洛，约书亚·本吉奥，阿隆·库维尔，MIT Press》这样的教科书经典之作，提供了全面的理论和数学基础。
- en: When we perform model customization (fine-tuning or continued pre-training),
    we update the model weights. While updating the model weights, a common problem
    can occur called **catastrophic forgetting**. This is when the model starts to
    forget some information it was originally trained on due to weight modifications,
    which can lead to degraded performance on more generalized tasks. In general,
    this can happen due to overfitting the training data, which means the model provides
    an accurate response to the training data but can’t generalize well and provides
    degraded performance on new information. In addition, customizing the model can
    be costly and resource-intensive, something that requires extensive memory utilization.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们执行模型定制（微调或继续预训练）时，我们会更新模型权重。在更新模型权重时，可能会出现一个常见问题，称为**灾难性遗忘**。这是当模型由于权重修改开始忘记它最初训练的一些信息时，这可能导致在更通用的任务上性能下降。一般来说，这可能是由于训练数据过拟合，这意味着模型对训练数据提供了准确的响应，但不能很好地泛化，并在新信息上提供较差的性能。此外，定制模型可能成本高昂且资源密集，这需要大量的内存使用。
- en: To overcome these challenges, a technique called **Parameter-efficient Fine-tuning**
    (**PEFT**) was introduced in the paper *Parameter-Efficient Transfer Learning
    for* *NLP* ([https://arxiv.org/pdf/1902.00751](https://arxiv.org/pdf/1902.00751)).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这些挑战，论文《Parameter-Efficient Transfer Learning for NLP》（[https://arxiv.org/pdf/1902.00751](https://arxiv.org/pdf/1902.00751)）中引入了一种称为**参数高效微调**（**PEFT**）的技术。
- en: Note that at the time of writing, Bedrock does not support PEFT. However, it’s
    good to have an understanding of the PEFT technique.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在撰写本文时，Bedrock 不支持 PEFT。然而，了解 PEFT 技术是有益的。
- en: PEFT
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PEFT
- en: In PEFT, you don’t need to fine-tune all the model parameters, something that
    can be quite time-consuming, resource-intensive, and costly. Instead, it freezes
    much of the model weights and you only need to train a small number of them. This
    makes it memory and compute-efficient, less susceptible to catastrophic forgetting,
    and cheaper to store the model on the hardware.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在PEFT中，你不需要微调所有模型参数，这可能会非常耗时、资源密集且成本高昂。相反，它冻结了模型的大部分权重，而你只需要训练其中的一小部分。这使得它内存和计算效率高，更不容易发生灾难性遗忘，并且存储在硬件上的成本更低。
- en: 'When fine-tuning LLMs, various techniques can reduce the number of trainable
    parameters to improve efficiency. We can categorize these PEFT methods into three
    main classes:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调LLM时，各种技术可以减少可训练参数的数量以提高效率。我们可以将这些PEFT方法分为三个主要类别：
- en: '**Selective methods**: These update only certain components or layers of the
    original LLM during fine-tuning. This allows you to focus on the most relevant
    parts of the model. However, it can result in suboptimal performance compared
    to full fine-tuning.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选择性方法**：这些方法在微调过程中仅更新原始LLM的某些组件或层。这允许你专注于模型中最相关的部分。然而，与全量微调相比，它可能导致性能次优。'
- en: '**Reparameterization methods**: These introduce low-rank matrices to compress
    the original weights. Examples include such as **Low-Rank Adaptation of Large
    Language Models** (**LoRA**). This reduces parameters while still modifying the
    whole model. The trade-off is increased memory usage during training.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重新参数化方法**：这些方法引入低秩矩阵以压缩原始权重。例如，**大型语言模型的低秩适应**（LoRA）。这减少了参数数量，同时仍然修改了整个模型。权衡是训练期间内存使用增加。'
- en: '**Additive methods**: These keep the original weights of the LLM frozen and
    add new trainable layers for task-specific adaptation. Additive methods such as
    **adapters** add the trainable layer inside the encoder or decoder component of
    the transformer architecture.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加性方法**：这些方法保持LLM的原始权重不变，并为特定任务的适应添加新的可训练层。例如，**适配器**这样的加性方法会在transformer架构的编码器或解码器组件内部添加可训练层。'
- en: The choice of the PEFT approach involves balancing metrics such as parameter
    and memory efficiency against model quality, training speed, and cost. Selectively
    updating parts of a model offers one end of this trade-off, while adapters and
    prompts maximize parameter efficiency at the cost of some architectural changes.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 选择PEFT方法时，需要在参数和内存效率与模型质量、训练速度和成本之间进行权衡。选择性更新模型的一部分提供了这种权衡的一端，而适配器和提示则牺牲了一些架构变化以最大化参数效率。
- en: 'With that, we’ve covered PEFT and its techniques at a very high level. However,
    if you are interested in learning more about it, go to [https://github.com/huggingface/peft](https://github.com/huggingface/peft).
    In addition, the *Generative AI with Large Language Models* course provides in-depth
    information about PEFT methods: [https://www.deeplearning.ai/courses/generative-ai-with-llms/](https://www.deeplearning.ai/courses/generative-ai-with-llms/).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们已经从非常高的层次上涵盖了PEFT及其技术。然而，如果你对它感兴趣并想了解更多，请访问[https://github.com/huggingface/peft](https://github.com/huggingface/peft)。此外，*使用大型语言模型进行生成式AI*课程提供了关于PEFT方法的深入信息：[https://www.deeplearning.ai/courses/generative-ai-with-llms/](https://www.deeplearning.ai/courses/generative-ai-with-llms/)。
- en: Hyperparameter tuning
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超参数调整
- en: In addition to fine-tuning techniques such as PEFT, **hyperparameter tuning**
    also plays a big role in ensuring a model retains its pretrained knowledge. Hyperparameters
    are configuration settings that control the model training process, much like
    knobs that can be tweaked and tuned. Models have various hyperparameters, including
    the learning rate, number of epochs, batch size, beta, gamma, and more. Each model
    may require a different set of optimal hyperparameter values, found through experimentation,
    to achieve the best performance and accuracy.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 除了PEFT这样的微调技术之外，**超参数调整**在确保模型保留其预训练知识方面也起着重要作用。超参数是控制模型训练过程的配置设置，就像可以调整和微调的旋钮一样。模型有多种超参数，包括学习率、训练轮数、批量大小、beta、gamma等。每个模型可能需要通过实验找到不同的最佳超参数值集，以实现最佳性能和准确性。
- en: The **learning rate** hyperparameter controls how quickly the model is adapted
    to the task. It also controls how much the model’s parameters are adjusted during
    each iteration of the training process. It determines the step size at which the
    model’s parameters are updated based on the calculated gradients (which represent
    the direction and magnitude of the changes needed to minimize the loss function).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**学习率**超参数控制模型适应任务的速度。它还控制模型参数在训练过程中的每次迭代中调整的程度。它决定了模型参数根据计算出的梯度（代表最小化损失函数所需变化的方向和幅度）更新的步长。'
- en: Let’s consider an analogy that might help you visualize the learning rate.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个可能有助于你可视化学习率的类比。
- en: 'Imagine that you’re trying to find the lowest point in a hilly landscape, but
    you’re blindfolded. You can only sense the steepness of the slope you’re standing
    on (the gradient) and take steps accordingly. The learning rate determines how
    big or small those steps should be:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你正在尝试在一个多山的景观中找到最低点，但你被蒙上了眼睛。你只能感觉到你站立的斜坡的陡峭程度（梯度）并相应地迈步。学习率决定了这些步子应该有多大或有多小：
- en: If the learning rate is too high, you might overshoot the lowest point and end
    up on the other side of the hill, continually overshooting and never converging
    to the optimal solution
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果学习率太高，你可能会超出最低点，最终到达山的另一边，不断超出，永远不会收敛到最优解
- en: If the learning rate is too low, you might take tiny steps and get stuck on
    a plateau or make painfully slow progress toward the lowest point
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果学习率太低，你可能会迈出很小的步子，卡在高原上，或者以痛苦缓慢的速度向最低点前进
- en: The ideal learning rate allows you to take reasonably sized steps that bring
    you progressively closer to the lowest point (the optimal set of model parameters)
    without overshooting or getting stuck.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 理想的学习率允许你采取合理大小的步骤，逐渐接近最低点（最优模型参数集），而不会超出或陷入停滞。
- en: In practice, finding the optimal learning rate is often a matter of experimentation
    and tuning. Different models and datasets may require different learning rates
    for the training process to converge effectively.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，找到最佳学习率通常是一个实验和调整的问题。不同的模型和数据集可能需要不同的学习率才能有效地收敛。
- en: Now that we understand the concepts behind fine-tuning, let’s start the customization
    process by preparing the data.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经理解了微调背后的概念，让我们通过准备数据开始定制过程。
- en: Preparing the data
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备数据
- en: We’ve already seen why customizing the model is important to improve its accuracy
    and performance. We’ve also seen that continued pre-training is an unsupervised
    learning approach that needs unlabeled data, whereas fine-tuning is a supervised
    learning approach that needs labeled data.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到为什么定制模型对于提高其准确性和性能很重要。我们还看到，持续预训练是一种无监督学习方法，需要未标记的数据，而微调是一种监督学习方法，需要标记的数据。
- en: The type of data we provide to the model can change the way the model responds.
    If the data is biased or has highly correlated features, you might not get the
    right responses from the trained custom model. This is true for any ML models
    you are training, so it is essential to provide high-quality data. While I won’t
    cover data processing and feature engineering concepts in this book, I wanted
    to highlight their importance. If you wish to learn more about these concepts,
    you can go through any ML courses and books, such as *Hands-On Machine Learning
    with Scikit-Learn, Keras, and TensorFlow* by Aurélien Géron, and *Feature Engineering
    for Machine Learning* by Alice Zheng and Amanda Casari.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供给模型的数据类型可以改变模型响应的方式。如果数据有偏差或具有高度相关的特征，你可能无法从训练过的定制模型中获得正确的响应。这对于你正在训练的任何机器学习模型都是正确的，因此提供高质量的数据至关重要。虽然我不会在本书中涵盖数据处理和特征工程的概念，但我想要强调它们的重要性。如果你希望了解更多关于这些概念的信息，你可以通过任何机器学习课程和书籍来学习，例如Aurélien
    Géron的《动手机器学习：基于Scikit-Learn、Keras和TensorFlow》和Alice Zheng与Amanda Casari的《机器学习特征工程》。
- en: 'The dataset that you need for continued pre-training and fine-tuning should
    be in JSONL format. The following documentation explains what JSONL format is,
    its requirements, sample examples, and its validator: [https://jsonlines.org/](https://jsonlines.org/).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要用于持续预训练和微调的数据集应采用JSONL格式。以下文档解释了JSONL格式是什么，其要求，示例，以及验证器：[https://jsonlines.org/](https://jsonlines.org/)。
- en: Now, let’s look at the data preparation techniques we can use for both methods.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们可以用于这两种方法的准备数据技术。
- en: 'Continued pre-training expects the data to be in `{"input": "<raw_text>"}`
    format, whereas fine-tuning expects the data to be in `{"prompt": "<prompt text>",
    "completion": "<expected generated` `text>"}` format.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '持续预训练期望数据以`{"input": "<raw_text>"}`格式提供，而微调期望数据以`{"prompt": "<prompt text>",
    "completion": "<expected generated text>"}`格式提供。'
- en: 'Here are some examples:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些示例：
- en: '`{"input": "EBITDA stands for Earnings Before Interest, Tax, Depreciation`
    `and Amortization"}`'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{"input": "EBITDA stands for Earnings Before Interest, Tax, Depreciation and
    Amortization"}`'
- en: '`{"prompt": "What''s EBITDA?", "completion": "Earnings Before Interest, Tax,
    Depreciation` `and Amortization"}`'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`{"prompt": "What''s EBITDA?", "completion": "Earnings Before Interest, Tax,
    Depreciation and Amortization"}`'
- en: If your dataset comprises images, then you can fine-tune the text-to-image or
    image-to-embedding model using Titan Image Generator as the base model. At the
    time of writing, continued pre-training only supports text-to-text models, not
    image-generation models.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的数据集包含图像，则可以使用Titan Image Generator作为基础模型微调文本到图像或图像到嵌入模型。截至写作时，持续预训练仅支持文本到文本模型，不支持图像生成模型。
- en: 'For image data, fine-tuning expects the data to be in `{"image-ref": "s3://path/file1.png",
    "caption": "caption` `text"}` format.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '对于图像数据，微调期望数据以`{"image-ref": "s3://path/file1.png", "caption": "caption text"}`格式提供。'
- en: Once you’ve prepared the data, you must split it into train and validation datasets
    and store it in an Amazon S3 bucket. Once you’ve done this, you can create a custom
    model.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好数据后，您必须将其拆分为训练集和验证集，并将其存储在Amazon S3桶中。完成此操作后，您可以创建定制模型。
- en: Creating a custom model
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建定制模型
- en: 'To create a custom model via the AWS console, go to **Custom models** on the
    Amazon Bedrock console page ([https://console.aws.amazon.com/bedrock/home](https://console.aws.amazon.com/bedrock/home)).
    *Figure 4**.8* shows what the **Custom models** page looks like. It provides information
    on how the customization process works, as well as two tabs called **Models**
    and **Training jobs**:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 要通过AWS控制台创建定制模型，请转到Amazon Bedrock控制台页面上的**定制模型**（[https://console.aws.amazon.com/bedrock/home](https://console.aws.amazon.com/bedrock/home)）。*图4.8*显示了**定制模型**页面的外观。它提供了有关定制过程的信息，以及两个标签页**模型**和**训练作业**：
- en: '![Figure 4.8 – The Bedrock console – Custom models](img/B22045_04_08.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图4.8 – Bedrock控制台 – 定制模型](img/B22045_04_08.jpg)'
- en: Figure 4.8 – The Bedrock console – Custom models
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8 – Bedrock控制台 – 定制模型
- en: Under **Customize model** in the **Models** tab, you can select **Create Fine-tuning
    job** or **Create Continued Pre-training job**. When you select either of these
    options, you can view details about the job, including its status, under the **Training**
    **jobs** tab.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在**模型**标签页下的**定制模型**中，您可以选择**创建微调作业**或**创建持续预训练作业**。选择这两个选项中的任何一个时，您可以在**训练作业**标签页下查看作业的详细信息，包括其状态。
- en: Components of model customization
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型定制组件
- en: 'The main components of model customization (fine-tuning or continued pre-training)
    include the source model, hyperparameters, and input data, as demonstrated in
    *Figure 4**.9*. These inputs are used to create a training job, which outputs
    the custom model alongside its metrics and logs:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 模型定制的主体组件（微调或持续预训练）包括源模型、超参数和输入数据，如*图4.8*所示。这些输入用于创建训练作业，该作业将输出定制的模型及其指标和日志：
- en: '![Figure 4.9 – Components of customization job](img/B22045_04_09.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图4.9 – 定制作业组件](img/B22045_04_09.jpg)'
- en: Figure 4.9 – Components of customization job
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.9 – 定制作业组件
- en: 'Let’s learn more about these:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们了解更多关于这些内容：
- en: '**Source model**: A key component of any customization job is selecting the
    source model that you wish to customize. You can find a list of all the supported
    models under the **Model details** section of the **Create Fine-tuning job** and
    **Create Continued Pre-training job** pages, as shown in *Figure 4**.10*:'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**源模型**：任何定制作业的关键组件是选择您希望定制的源模型。您可以在“创建微调作业”和“创建持续预训练作业”页面上的“模型详情”部分找到所有支持模型的列表，如图*图4.10*所示：'
- en: '![Figure 4.10 – Selecting a model for a customization job](img/B22045_04_10.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图4.10 – 为定制作业选择模型](img/B22045_04_10.jpg)'
- en: Figure 4.10 – Selecting a model for a customization job
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.10 – 为定制作业选择模型
- en: '**Hyperparameters**: Along with the source models, you can specify a set of
    hyperparameters. These act like external knobs that control how the model is trained.
    These are different from inference parameters, which are set during the inference
    process.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超参数**：除了源模型外，您还可以指定一组超参数。这些参数就像外部旋钮，用于控制模型的训练方式。这些参数与推理参数不同，推理参数是在推理过程中设置的。'
- en: '**Input data**: The dataset that is used to train the model is in JSONL format,
    and it’s prepared and stored in an Amazon S3 bucket.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入数据**：用于训练模型的数据集以 JSONL 格式存在，并已准备并存储在 Amazon S3 存储桶中。'
- en: '**Training job**: The inputs (source model, hyperparameters, and input data)
    are used to create a training job. There are other configuration details, such
    as VPC settings, which you can use to securely control access to the data in an
    Amazon S3 bucket, an IAM service role, which provides access to Bedrock to write
    to an S3 bucket, and model encryption, which you can use encrypt the custom model
    at rest using a KMS key. We will cover security and privacy in Amazon Bedrock
    in [*Chapter 12*](B22045_12.xhtml#_idTextAnchor226).'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练作业**：输入（源模型、超参数和输入数据）用于创建训练作业。还有其他配置细节，例如 VPC 设置，您可以使用它来安全地控制对 Amazon S3
    存储桶中数据的访问，IAM 服务角色，它提供对 Bedrock 的访问权限以写入 S3 存储桶，以及模型加密，您可以使用 KMS 密钥加密静态的定制模型。我们将在
    [*第 12 章*](B22045_12.xhtml#_idTextAnchor226) 中介绍 Amazon Bedrock 的安全和隐私。'
- en: '**Custom model**: Once the training process is completed, the custom model
    is stored in the AWS account owned by the AWS Bedrock Service team.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定制模型**：一旦训练过程完成，定制模型将存储在 AWS Bedrock 服务团队拥有的 AWS 账户中。'
- en: '`step_wise_training_metrics.csv` and `validation_metrics.csv` files inside
    the S3 output path. We will learn how to evaluate and analyze results in the *Analyzing
    the* *results* section.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 S3 输出路径内的 `step_wise_training_metrics.csv` 和 `validation_metrics.csv` 文件。我们将在
    *分析结果* 部分学习如何评估和分析结果。
- en: For now, let’s look at the API calls we can use to create a custom model.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们可以使用的 API 调用来创建一个定制模型。
- en: APIs
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: APIs
- en: 'Amazon Bedrock provides several APIs that allow you to create, monitor, and
    stop customization jobs. This section will examine some of these key APIs: **CreateModelCustomizationJob**,
    **ListModelCustomizationJob**, **GetModelCustomizationJob**, and **StopModelCustomizationJob**.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Bedrock 提供了多个 API，允许您创建、监控和停止定制作业。本节将探讨其中一些关键 API：**CreateModelCustomizationJob**、**ListModelCustomizationJob**、**GetModelCustomizationJob**
    和 **StopModelCustomizationJob**。
- en: 'Let’s dive deeper into each of these API calls:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地了解每个 API 调用：
- en: '`customizationType` to `FINE_TUNING` or `CONTINUED_PRE_TRAINING`, `baseModelIdentifier`
    as the source model you wish to use, relevant hyperparameters, and the input data
    (training and validation dataset). Here’s an example of the job being used in
    the Python SDK (Boto3):'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`customizationType` 设置为 `FINE_TUNING` 或 `CONTINUED_PRE_TRAINING`，`baseModelIdentifier`
    为您希望使用的源模型，相关的超参数，以及输入数据（训练和验证数据集）。以下是在 Python SDK（Boto3）中使用作业的示例：'
- en: '[PRE0]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Once you run the preceding code, the training job will start.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦运行前面的代码，训练作业将开始。
- en: '**ListModelCustomizationJob**: You can use this API call to retrieve a list
    of all the customization jobs that you are running:'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ListModelCustomizationJob**：您可以使用此 API 调用来检索您正在运行的全部定制作业列表：'
- en: '[PRE25]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '`IN_PROGRESS`, `STOPPED`, `FAILED`, or `COMPLETE`. If the model has a status
    of `FAILED`, you will *not* be charged:'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IN_PROGRESS`、`STOPPED`、`FAILED` 或 `COMPLETE`。如果模型的状态为 `FAILED`，您将 *不会* 被收费：'
- en: '[PRE28]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Amazon Bedrock also has integration with Amazon EventBridge, where you can receive
    a notification whenever there is a status change. We will dive deeper into the
    EventBridge integration in [*Chapter 11*](B22045_11.xhtml#_idTextAnchor207).
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Amazon Bedrock 还与 Amazon EventBridge 集成，您可以在状态发生变化时接收通知。我们将在 [*第 11 章*](B22045_11.xhtml#_idTextAnchor207)
    中深入了解 EventBridge 集成。
- en: '`IN_PROGRESS`, and you would like to stop the job for any reason, you can run
    this API call:'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您想停止作业，无论出于什么原因，都可以运行此 API 调用：
- en: '[PRE32]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Once you start the customization job, the time it takes to complete will vary
    depending on the size of the training dataset you provide. If your dataset contains
    a few thousand records, the training job can take about an hour, while if the
    dataset contains millions of records, the training job can take a few days to
    complete.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦开始定制作业，完成所需的时间将根据您提供的训练数据集的大小而变化。如果您的数据集包含几千条记录，训练作业可能需要大约一个小时，而如果数据集包含数百万条记录，训练作业可能需要几天才能完成。
- en: Once the customization job has been completed and a custom model has been created,
    we can analyze the results and perform inference on our model.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定制作业完成并创建了一个定制模型，我们就可以分析结果并在我们的模型上执行推理。
- en: Analyzing the results
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析结果
- en: As mentioned previously, when creating a customization job, we provide an output
    S3 path, where the metrics and logs are stored by the training job. You will see
    the `step_wise_training_metrics.csv` and `validation_metrics.csv` files inside
    the S3 output path. Within these files, you will see information such as the step
    number, epoch number, loss, and perplexity. You will see these details in both
    the training and validation sets. Although providing a validation set is optional,
    doing so allows the performance metrics of the custom model that’s been created
    to be evaluated.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在创建定制作业时，我们提供了一个输出S3路径，其中训练作业存储了指标和日志。你将在S3输出路径中看到`step_wise_training_metrics.csv`和`validation_metrics.csv`文件。在这些文件中，你会看到诸如步骤编号、epoch编号、损失和复杂度等信息。你将在训练和验证集中看到这些详细信息。尽管提供验证集是可选的，但这样做可以评估创建的定制模型的性能指标。
- en: Depending on the size of the dataset, you can decide how much of the validation
    dataset you would like to hold. If your dataset is small (for example, it contains
    hundreds or thousands of records), you can use 90% as the training set and 10%
    as the validation set. If your dataset size is large (for example, it contains
    hundreds of thousands of records), you can reduce the validation set. So, if you
    have hundreds of thousands of records, you can use 99% of them as the training
    set and 1% as the validation set.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据集的大小，你可以决定保留多少验证数据集。如果你的数据集较小（例如，包含数百或数千条记录），你可以使用90%作为训练集，10%作为验证集。如果你的数据集很大（例如，包含数十万条记录），你可以减少验证集的大小。因此，如果你有数十万条记录，你可以使用其中的99%作为训练集，1%作为验证集。
- en: Metrics for training and validation
  id: totrans-170
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练和验证的指标
- en: 'There are two key types of metrics that provide valuable insights into how
    well the model is learning: loss and perplexity. Let’s take a closer look:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种关键的指标类型可以提供关于模型学习效果的宝贵见解：损失和复杂度。让我们更详细地看看：
- en: '**Loss**: This ranges from 0 to infinity. The loss value that’s calculated
    during training indicates how well the model fits the training data. Meanwhile,
    the validation loss shows how effectively the model generalizes to new, unseen
    examples after training is completed. Loss is one of the most commonly used metrics
    for evaluating the performance of a model during training. In general, lower loss
    values are preferable and indicate that the model is fitting the data well. Higher
    loss values suggest that the model’s prediction is far off from the actual response
    and it’s making a lot of errors.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**损失**: 这个值从0到无穷大不等。在训练过程中计算的损失值表示模型与训练数据的拟合程度。同时，验证损失显示模型在训练完成后对新、未见过的示例进行泛化的有效性。损失是评估模型在训练期间性能的最常用指标之一。一般来说，较低的损失值更可取，表明模型很好地拟合了数据。较高的损失值表明模型的预测与实际响应相差甚远，并且犯了很多错误。'
- en: '**Perplexity**: This ranges from 1 to infinity. It measures a language model’s
    ability to accurately predict the next token in a sequence. A lower perplexity
    score corresponds to better predictions and the model’s capabilities.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复杂度**: 这个值从1到无穷大不等。它衡量语言模型在序列中准确预测下一个标记的能力。较低的复杂度得分对应着更好的预测和模型的能力。'
- en: Both loss and perplexity are important metrics for data scientists to analyze
    when training models with Bedrock. A well-performing training run will show the
    training and validation loss values converging over time. This convergence indicates
    that the model is learning from the training data without overfitting.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用Bedrock训练模型时，损失和复杂度是数据科学家分析的重要指标。一次表现良好的训练运行将显示训练和验证损失值随时间收敛。这种收敛表明模型正在从训练数据中学习，而没有过拟合。
- en: Inference
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推理
- en: Once the job is successful and we’ve verified the training and validation metrics,
    we are ready to perform inference on our model. The first thing we need to do
    is purchase Provisioned Throughput, which gives us a dedicated capacity to deploy
    the model. At the time of writing, custom Bedrock models can only be deployed
    through Provisioned Throughput. However, you can also use Provisioned Throughput
    for base FMs supported by Bedrock.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦作业成功并且我们已经验证了训练和验证指标，我们就可以对模型进行推理。我们首先需要做的是购买预留吞吐量，这为我们提供了部署模型的专用容量。在撰写本文时，自定义Bedrock模型只能通过预留吞吐量进行部署。然而，你也可以使用预留吞吐量来部署Bedrock支持的基本FM。
- en: At the time of writing, three commitment terms are available with Bedrock.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Bedrock提供了三种承诺条款。
- en: '**No commitment** (priced hourly)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无长期承诺**（按小时计费）'
- en: '**1 month**'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**1个月**'
- en: '**6 months**:'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**6个月**:'
- en: '![Figure 4.11 – Model units & commitment term](img/B22045_04_11.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图4.11 – 模型单元 & 承诺条款](img/B22045_04_11.jpg)'
- en: Figure 4.11 – Model units & commitment term
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11 – 模型单元 & 承诺条款
- en: 'The `1`. **Model units** are a way to define a throughput that’s measured in
    terms of the maximum number of input and output tokens processed per minute:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '`1`。**模型单元**是一种定义吞吐量的方式，吞吐量以每分钟处理的最大输入和输出标记数来衡量：'
- en: '![Figure 4.12 – Provisioned Throughput](img/B22045_04_12.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图4.12 – 已配置吞吐量](img/B22045_04_12.jpg)'
- en: Figure 4.12 – Provisioned Throughput
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12 – 已配置吞吐量
- en: Once you’ve purchased Provisioned Throughput, you can see its details in the
    Bedrock console and via the **ListProvisionedModelThroughputs** and **GetProvisionedModelThroughput**
    APIs.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 购买已配置吞吐量后，您可以在Bedrock控制台中查看其详细信息，也可以通过**ListProvisionedModelThroughputs**和**GetProvisionedModelThroughput**
    API获取。
- en: Once Provisioned Throughput has an *Active* status, the custom model that you’ve
    created will be deployed to an endpoint. At this point, you can perform inference
    on the model using either the playground experience or through an API. Both options
    will be discussed next.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦已配置吞吐量达到**活动**状态，您创建的定制模型将被部署到端点。此时，您可以使用游乐场体验或通过API对模型进行推理。这两种选项将在下文中进行讨论。
- en: Amazon Bedrock playground
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon Bedrock游乐场
- en: Performing inference via the playground experience is pretty straightforward
    and similar to how you perform inference on base FMs.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 通过游乐场体验进行推理非常简单，与您对基础FM进行推理的方式相似。
- en: 'Instead of using the base model, you can select the custom model that you’ve
    created, at which point you’re ready to ask questions or provide a prompt to your
    model. *Figure 4**.13* depicts the process of selecting the **custom-titan-1705116361**
    model from the Bedrock playground, where it can be fine-tuned on user-provisioned
    training data:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择您创建的定制模型而不是使用基础模型，此时您就可以向模型提问或提供提示。*图4*.13展示了从Bedrock游乐场中选择**custom-titan-1705116361**模型的过程，该模型可以在用户提供的训练数据上进行微调：
- en: '![Figure 4.13 – Select model](img/B22045_04_13.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图4.13 – 选择模型](img/B22045_04_13.jpg)'
- en: Figure 4.13 – Select model
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13 – 选择模型
- en: Amazon Bedrock API
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon Bedrock API
- en: 'Bedrock also provides the `modelId`, we should provide the `arn` model of the
    provisioned endpoint. You can attain this from the **Bedrock Console – Provisioned
    Throughput** tab or via the **GetProvisionedModelThroughput** API:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Bedrock还提供了`modelId`，我们应该提供已配置端点的`arn`模型。您可以从**Bedrock控制台 – 已配置吞吐量**选项卡或通过**GetProvisionedModelThroughput**
    API获取：
- en: '[PRE35]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Now that we understand how to fine-tune models with Amazon Bedrock and leverage
    Provisioned Throughput, let’s learn how to import selective custom models.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了如何使用Amazon Bedrock微调模型并利用已配置吞吐量，让我们学习如何导入选定的定制模型。
- en: Importing custom models in Amazon Bedrock
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Amazon Bedrock中导入定制模型
- en: To leverage the **Import Models** capability within Amazon Bedrock, navigate
    to the Bedrock console. On the left-hand side panel, under **Foundation models**,
    click **Imported models**.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 要利用Amazon Bedrock中的**导入模型**功能，导航到Bedrock控制台。在左侧面板中，在**基础模型**下点击**导入的模型**。
- en: 'Once you land on the **Imported models** page, as shown in *Figure 4**.14*,
    you will be able to create a custom model by importing a model directly from Amazon
    SageMaker (where you might have customized FMs already) or by importing the model
    files from an Amazon S3 bucket:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您进入**导入的模型**页面，如图*图4*.14所示，您将能够通过直接从Amazon SageMaker（您可能已经自定义了FM）导入模型或从Amazon
    S3存储桶导入模型文件来创建一个定制模型：
- en: '![Figure 4.14 – Imported models](img/B22045_04_14.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![图4.14 – 导入的模型](img/B22045_04_14.jpg)'
- en: Figure 4.14 – Imported models
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.14 – 导入的模型
- en: 'At the time of writing, importing a model into Amazon Bedrock creates a custom
    model that supports the following patterns:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，将模型导入Amazon Bedrock会创建一个支持以下模式的定制模型：
- en: '**Continued pre-training or fine-tuned model**: As explained previously, you
    can refine the pre-trained model by utilizing proprietary data while the maintaining
    structural integrity of the original model configuration.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续预训练或微调模型**：如前所述，您可以通过使用专有数据来细化预训练模型，同时保持原始模型配置的结构完整性。'
- en: '**Domain adaptation**: You can tailor the custom-imported model to a specific
    domain. This adaptation process will enhance the model’s performance within a
    target domain by addressing domain-specific variations. For instance, language
    adaptation can be undertaken so that responses can be generated in regional dialects
    or languages, such as Tamil or Portuguese.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**领域自适应**: 你可以将自定义导入的模型调整到特定领域。通过解决领域特定的变化，这种自适应过程将提高模型在目标领域内的性能。例如，可以进行语言自适应，以便生成地区方言或语言，如泰米尔语或葡萄牙语。'
- en: '**Pre-training from scratch**: As you are aware by now, this approach extends
    beyond merely customizing weights and vocabulary. This approach provides you with
    the opportunity to modify fundamental model parameters, including the number of
    attention heads, hidden layers, or context length. Additionally, techniques such
    as post-training quantization or integrating base and adapter weights enable further
    refinement and optimization of the model’s architecture.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从头开始预训练**: 如你所知，这种方法不仅限于自定义权重和词汇表。这种方法为你提供了修改基本模型参数的机会，包括注意力头数量、隐藏层或上下文长度。此外，诸如训练后量化或集成基础和适配器权重等技术，可以进一步优化和改进模型的架构。'
- en: To initiate the **Import model** job, you can provide the model details, including
    a relevant model name, import job name, and model import settings.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动“导入模型”作业，你可以提供模型详细信息，包括相关的模型名称、导入作业名称和模型导入设置。
- en: At the time of writing this book, the imported model can support the Mistral,
    Flan, Llama2, and Llama3 architectures. As the generative AI landscape evolves,
    Bedrock may expand the list of supported architectures for model import in the
    future.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，导入的模型可以支持 Mistral、Flan、Llama2 和 Llama3 架构。随着生成式人工智能领域的演变，Bedrock 可能会在未来扩展支持模型导入的架构列表。
- en: Once a model import job has been completed successfully, the imported model
    will be listed on the **Models** tab of the **Imported models** page. Here, you
    can view key details about the imported model, such as its ARN, model ID, and
    status. From this page, you can also use the imported model for inference by invoking
    it through the Bedrock API.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型导入作业成功完成，导入的模型将列在“导入模型”页面的“模型”选项卡上。在这里，你可以查看导入模型的关键细节，如其 ARN、模型 ID 和状态。从该页面，你也可以通过
    Bedrock API 调用导入的模型进行推理。
- en: Detailed information regarding the different model types and open source architectures
    that Amazon Bedrock’s custom model capability supports can be found at [https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html#model-customization-import-model-architecture](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html#model-customization-import-model-architecture).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 Amazon Bedrock 的自定义模型功能支持的模型类型和开源架构的详细信息，可以在[https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html#model-customization-import-model-architecture](https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html#model-customization-import-model-architecture)找到。
- en: Note
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Please ensure that your account has sufficient quota limits to execute the
    **CreateModelImportJob** action. If it doesn’t, the following error will be displayed:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保您的账户有足够的配额限制来执行“创建模型导入作业”操作。如果没有，将显示以下错误：
- en: '![Figure 4.15 – Error](img/B22045_04_15.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.15 – 错误](img/B22045_04_15.jpg)'
- en: Figure 4.15 – Error
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.15 – 错误
- en: You can request for your quota limit to be increased by navigating to [https://us-east-1.console.aws.amazon.com/servicequotas/home/services/bedrock/quotas](https://us-east-1.console.aws.amazon.com/servicequotas/home/services/bedrock/quotas).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过访问[https://us-east-1.console.aws.amazon.com/servicequotas/home/services/bedrock/quotas](https://us-east-1.console.aws.amazon.com/servicequotas/home/services/bedrock/quotas)来请求增加配额限制。
- en: Throughout this chapter, we’ve learned how to prepare a dataset, customize an
    FM, and then check its performance and perform inference. Now, let’s look at some
    of the guidelines and best practices we need to consider while trying to customize
    a model.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何准备数据集、自定义 FM，然后检查其性能和执行推理。现在，让我们看看在尝试自定义模型时需要考虑的一些指南和最佳实践。
- en: Guidelines and best practices
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指南和最佳实践
- en: 'While customizing a model, it’s ideal to consider the following practices for
    optimal results:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在自定义模型时，为了获得最佳结果，应考虑以下实践：
- en: '**Providing the dataset**: The most important thing in ML is the dataset. Most
    of the time, how your model performs depends on the dataset you provide to train
    the model. So, providing quality data that’s aligned with your use case is important.
    If you’ve studied ML in university or worked in this field, you might have learned
    about various feature engineering and data processing techniques you can use to
    clean and process the data. For example, you can handle missing values in the
    dataset, make sure you don’t provide biased data, or ensure that the dataset follows
    the format that the model expects. If you would like to learn more about providing
    quality data, please read *Feature Engineering for Machine Learning* by Alice
    Zheng and Amanda Casari. This same principle applies to generative AI since it
    is essentially a subset of ML.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提供dataset**: 在机器学习中，最重要的是dataset。大多数情况下，您的模型表现如何取决于您提供给训练模型的dataset。因此，提供与您的用例一致的高质量数据非常重要。如果您在大学学习过机器学习或在这个领域工作过，您可能已经学到了各种特征工程和数据预处理技术，您可以使用这些技术来清理和处理数据。例如，您可以在dataset中处理缺失值，确保您不提供有偏见的data，或者确保dataset遵循模型期望的格式。如果您想了解更多关于提供高质量数据的信息，请阅读Alice
    Zheng和Amanda Casari的《机器学习特征工程》。这个原则同样适用于生成式AI，因为它本质上是机器学习的一个子集。'
- en: '**Choosing the right FM**: Next, you need to select the base FM that you are
    looking to customize. Make sure you look at its attributes, how many tokens it
    supports, what type of data it’s been trained on, and the size of the model. Go
    through the model cards in the Bedrock console, read through the websites of these
    models, and look at their performance by using standardized benchmarks such as
    GLUE, SuperGLUE, HELM, and OpenLLM by HuggingFace. However, keep in mind that
    you shouldn’t completely rely on these benchmark tools as they may not represent
    the complexity and diversity of real-world applications.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选择合适的FM**: 接下来，您需要选择您想要定制的基FM。确保您查看其属性，它支持多少个token，它训练过什么类型的数据，以及模型的大小。在Bedrock控制台中查看模型卡片，阅读这些模型的网站，并使用标准基准（如GLUE、SuperGLUE、HELMA和HuggingFace的OpenLLM）来查看它们的性能。然而，请记住，您不应完全依赖这些基准工具，因为它们可能无法代表真实世界应用的复杂性和多样性。'
- en: '**Identifying hyperparameters**: Once you have a quality dataset and the right
    base model has been selected, you need to identify the right hyperparameters for
    customization. Your goal should be to avoid overfitting; the model should be able
    to generalize well to the new unseen information. There are several hyperparameters
    that you can adjust, such as the number of epochs, batch size, learning rate,
    early stopping, and others. You can find a list of hyperparameters that all the
    Bedrock models support at [https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models-hp.html](https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models-hp.html).'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**确定超参数**: 一旦您有了高质量的dataset并且已经选择了正确的基模型，您需要确定定制的正确超参数。您的目标应该是避免过拟合；模型应该能够很好地泛化到新的未见信息。您可以调整几个超参数，例如epoch数量、批量大小、学习率、提前停止等。您可以在[https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models-hp.html](https://docs.aws.amazon.com/bedrock/latest/userguide/custom-models-hp.html)找到所有Bedrock模型支持的超参数列表。'
- en: '**Evaluating performance**: Once you’ve fine-tuned the model, evaluate its
    performance using the validation dataset. The **validation dataset** is the dataset
    that’s held back from training the model and is used for evaluating it instead.
    To learn more about data splitting, go to [https://mlu-explain.github.io/train-test-validation/](https://mlu-explain.github.io/train-test-validation/).
    Here, you can look at different metrics, such as loss and perplexity, or use techniques
    such as accuracy, **Bilingual Evaluation Understudy** (**BLEU**), and **Recall-Oriented
    Understudy for Gisting Evaluation** (**ROUGE**) scores. For context, BLEU scores
    indicate the quality assessment of machine-generated translations compared to
    reference translations set provided by human translators. The ROUGE score is useful
    for text summarization tasks, wherein evaluation is conducted based on the quality
    of machine-generated summaries compared to the respective reference summaries
    created by humans. If the model doesn’t provide the desired performance results,
    you have to readjust the hyperparameters or bring in more datasets. Once the model
    is ready to be used and provides the desired evaluation results, you can perform
    inference on the model.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估性能**：一旦你微调了模型，请使用验证数据集评估其性能。**验证数据集**是保留用于训练模型的数据集，用于评估模型。要了解更多关于数据拆分的信息，请访问[https://mlu-explain.github.io/train-test-validation/](https://mlu-explain.github.io/train-test-validation/)。在这里，你可以查看不同的指标，如损失和困惑度，或使用准确度、**双语评估助手**（**BLEU**）和**基于召回的摘要评估助手**（**ROUGE**）分数等技术。为了了解背景，BLEU分数表示机器生成的翻译与由人工翻译者提供的参考翻译集的质量评估。ROUGE分数在文本摘要任务中很有用，其中评估是基于机器生成的摘要与由人类创建的相应参考摘要的质量比较。如果模型没有提供期望的性能结果，你必须调整超参数或引入更多数据集。一旦模型准备好使用并提供所需的评估结果，你就可以在模型上执行推理。'
- en: '**Adapting the model for specific domains**: Customizing the model to a business
    domain is a promising approach for improving productivity and efficiency. By tailoring
    the model to the specific needs of a particular industry, we can enable it to
    perform tasks that were previously impossible or inefficient and create a more
    competitive and successful business.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**针对特定领域调整模型**：将模型定制到商业领域是一种提高生产力和效率的有前景的方法。通过将模型定制为满足特定行业的特定需求，我们可以使其执行以前不可能或效率低下的任务，并创造一个更具竞争力和成功的业务。'
- en: Adopting these practices can help you make the most of customizing an FM and
    harnessing the true power of generative AI.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这些实践可以帮助你充分利用定制FM并发挥生成式AI的真正力量。
- en: Summary
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored two model customization techniques, fine-tuning
    and continued pre-training, the need to customize a model, and understood the
    concepts behind fine-tuning and continued pre-training. Further, we prepared our
    dataset, created a custom model, evaluated the model, and performed inference.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了两种模型定制技术：微调和持续预训练，以及定制模型的需求，并理解了微调和持续预训练背后的概念。此外，我们准备了我们的数据集，创建了一个自定义模型，评估了模型，并进行了推理。
- en: Lastly, we discussed some of the guidelines and best practices you need to consider
    when customizing your FM.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们讨论了一些你在定制你的FM时需要考虑的指南和最佳实践。
- en: In the next chapter, we’re going to uncover the power of RAG in solving real-world
    business problems by using an external data source. We will delve into the various
    use cases and sample architectures and implement RAG with Amazon Bedrock.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将通过使用外部数据源来揭示RAG在解决现实世界商业问题中的力量。我们将深入研究各种用例和示例架构，并使用Amazon Bedrock实现RAG。
