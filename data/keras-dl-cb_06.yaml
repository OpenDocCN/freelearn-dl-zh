- en: Generative Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型
- en: Generative models are the family of machine learning models that are used to
    describe how data is generated. To train a generative model we first accumulate
    a vast amount of data in any domain and later train a model to create or generate
    data like it.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型是机器学习模型的一类，用于描述数据是如何生成的。为了训练一个生成模型，我们首先收集大量的领域数据，然后训练一个模型来生成类似的数据。
- en: In other words, these are the models that can learn to create data that is similar
    to data that we give them. One such approach is using **Generative Adversarial
    Networks (GANs)**, which will be discussed as part of this chapter in detail.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，这些模型可以学习生成与我们提供的数据相似的数据。一个这样的方式是使用**生成对抗网络（GANs）**，本章将详细讨论这一部分内容。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introduction to generative models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成模型简介
- en: GANs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GANs
- en: Generative models
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型
- en: 'There are two kinds of machine learning models: generative models and discriminative
    models. Let''s examine the following list of classifiers: decision trees, neural
    networks, random forests, generalized boosted models, logistic regression, naive
    bayes, and **Support Vector Machine** (**SVM**). Most of these are classifiers
    and ensemble models. The odd one out here is Naive Bayes. It''s the only generative
    model in the list. The others are examples of discriminative models.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型有两种类型：生成模型和判别模型。我们来看以下分类器的列表：决策树、神经网络、随机森林、广义增强模型、逻辑回归、朴素贝叶斯和**支持向量机（SVM）**。其中大多数是分类器和集成模型，唯一的例外是朴素贝叶斯，它是列表中的唯一生成模型。其他的则是判别模型的例子。
- en: The fundamental difference between generative and discriminative models lies
    in the underlying probability inference structure. In this chapter, we will study
    the key concepts of generative models like types and GANs, but before that, let's
    go through some of the key differences between generative and discriminative models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型和判别模型的根本区别在于它们的概率推理结构。在本章中，我们将学习生成模型的关键概念，如类型和 GANs，但在此之前，让我们先了解一下生成模型和判别模型之间的一些关键区别。
- en: Discriminative versus generative models
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 判别模型与生成模型的区别
- en: Discriminative models learn *P(Y|X),* which is the conditional relationship
    between the target variable *Y* and features *X*. This is how least squares regression
    works, and it is the kind of inference pattern that gets used. It is an approach
    to sort out the relationship among variables.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 判别模型学习 *P(Y|X)*，即目标变量 *Y* 和特征 *X* 之间的条件关系。这就是最小二乘回归的工作原理，也是使用的推理模式。它是一种用于解决变量之间关系的推理方法。
- en: Generative models aim for a complete probabilistic description of the dataset.
    With generative models, the goal is to develop the joint probability distribution
    *P(X, Y)*, either directly or by computing *P(Y | X)* and *P(X)* and then inferring
    the conditional probabilities required to classify newer data. This method requires
    more solid probabilistic thought than regression demands, but it provides a complete
    model of the probabilistic structure of the data. Knowing the joint distribution
    enables you to generate the data; hence, Naive Bayes is a generative model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型旨在对数据集进行完整的概率描述。使用生成模型时，目标是开发联合概率分布 *P(X, Y)*，可以直接计算 *P(Y | X)* 和 *P(X)*，然后推断分类新数据所需的条件概率。与回归模型相比，这种方法需要更为扎实的概率思维，但它提供了数据概率结构的完整模型。了解联合分布后，你可以生成数据；因此，朴素贝叶斯就是一个生成模型。
- en: Suppose we have a supervised learning task, where *x[i]* is the given features
    of the data points and *y[i]* is the corresponding labels. One way to predict
    *y* on future *x* is to learn a function *f()* from *(x[i],y[i])* that takes in
    *x* and outputs the most likely *y*. Such models fall in the category of discriminative
    models, as you are learning how to discriminate between *x*'s from different classes.
    Methods like SVMs and neural networks fall into this category. Even if you're
    able to classify the data very accurately, you have no notion of how the data
    might have been generated.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个监督学习任务，其中 *x[i]* 是数据点的给定特征，*y[i]* 是对应的标签。预测未来 *x* 上的 *y* 的一种方法是学习一个函数
    *f()*，它从 *(x[i], y[i])* 中获取 *x* 并输出最可能的 *y*。这样的模型属于判别模型，因为你正在学习如何区分来自不同类别的 *x*。像
    SVM 和神经网络这样的算法就属于这一类。即使你能够非常准确地分类数据，你也无法知道数据是如何生成的。
- en: The second approach is to model how the data might have been generated and learn
    a function *f(x,y)* that gives a score to the configuration determined by *x*
    and *y* together. Then you can predict *y* for a new *x* by finding the *y* for
    which the score *f(x,y)* is maximum. A canonical example of this is Gaussian mixture
    models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法是模拟数据可能是如何生成的，并学习一个函数 *f(x,y)*，为由 *x* 和 *y* 共同决定的配置打分。然后，你可以通过找到使得 *f(x,y)*
    得分最大的 *y* 来预测新的 *x* 的 *y*。高斯混合模型是这一方法的典型例子。
- en: 'Another example of this is: you can imagine *x* to be an image and *y* to be
    a kind of object like a dog, namely in the image. The probability written as *p(y|x)*
    tells us how much the model believes that there is a dog, given an input image
    compared to all possibilities it knows about. Algorithms that try to model this
    probability map directly are called **discriminative models**.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是：你可以将 *x* 想象成一张图像，将 *y* 想象成一个对象种类，如狗，即在图像中。写作 *p(y|x)* 的概率告诉我们，在给定输入图像的情况下，模型认为其中有一只狗的程度，相对于它所知道的所有可能性。尝试直接建模这个概率映射的算法被称为**判别模型**。
- en: Generative models, on the other hand, try to learn a function called the joint
    probability *p(y, x)*. We can read this as how much the model believes that *x*
    is an image and there is a dog *y* in it at the same time. These two probabilities
    are related and that could be written as *p(y, x) = p(x) p(y|x)*, with *p(x)*
    being how likely it is that the input *x* is an image. The *p(x)* probability
    is usually called a **density function** in literature.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，生成模型试图学习一个称为联合概率 *p(y, x)* 的函数。我们可以将其理解为模型在多大程度上相信 *x* 是一张图像并且其中有一只狗 *y*。这两个概率是相关的，可以写作
    *p(y, x) = p(x) p(y|x)*，其中 *p(x)* 是输入 *x* 为图像的可能性。*p(x)* 概率通常在文献中称为**密度函数**。
- en: The main reason to call these models generative ultimately connects to the fact
    that the model has access to the probability of both input and output at the same
    time. Using this, we can generate images of animals by sampling animal kinds *y*
    and new images *x* from *p(y, x)*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 之所以最终称这些模型为生成模型，主要是因为模型能够同时访问输入和输出的概率。利用这一点，我们可以通过从 *p(y, x)* 中采样动物种类 *y* 和新的图像
    *x* 来生成动物的图像。
- en: We can mainly learn the density function *p(x)* which only depends on the input
    space.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们主要可以学习密度函数 *p(x)*，它仅依赖于输入空间。
- en: Both models are useful; however, comparatively, generative models have an interesting
    advantage over discriminative models, namely, they have the potential to understand
    and explain the underlying structure of the input data even when there are no
    labels available. This is very desirable when working in the real world.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 两种模型都有用；然而，相对而言，生成模型相较于判别模型有一个有趣的优势，即它们有潜力理解和解释输入数据的潜在结构，即使在没有标签的情况下也能做到。这在实际工作中是非常需要的。
- en: Types of generative models
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型的类型
- en: Discriminative models have been at the forefront of the recent success in the
    field of machine learning. Models make predictions that depend on a given input,
    although they are not able to generate new samples or data.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 判别模型一直是最近在机器学习领域取得成功的前沿。模型根据给定输入进行预测，尽管它们不能生成新的样本或数据。
- en: The idea behind the recent progress of generative modeling is to convert the
    generation problem to a prediction one and use deep learning algorithms to learn
    such a problem.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最近生成模型进展背后的想法是将生成问题转换为预测问题，并使用深度学习算法来学习这种问题。
- en: Autoencoders
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自编码器
- en: One way to convert a generative to a discriminative problem can be by learning
    the mapping from the input space itself. For example, we want to learn an identity
    map that, for each image *x*, would ideally predict the same image, namely, *x
    = f(x)*, where *f* is the predictive model.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 将生成问题转化为判别问题的一种方式是通过学习从输入空间本身的映射。例如，我们希望学习一个恒等映射，对于每个图像 *x*，理想情况下预测相同的图像，即 *x
    = f(x)*，其中 *f* 是预测模型。
- en: This model may not be of use in its current form, but from this, we can create
    a generative model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在当前形式下可能没有什么用处，但我们可以从中创建一个生成模型。
- en: 'Here, we create a model formed of two main components: an encoder model *q(h|x)*
    that maps the input to another space, which is referred to as hidden or the latent
    space represented by *h*, and a decoder model *q(x|h)* that learns the opposite
    mapping from the hidden input space.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建一个由两个主要组件组成的模型：一个编码器模型 *q(h|x)*，它将输入映射到另一个空间，这个空间被称为隐藏空间或潜在空间，用 *h*
    表示，另一个是解码器模型 *q(x|h)*，它学习从隐藏输入空间到原输入空间的反向映射。
- en: These components--encoder and decoder--are connected together to create an end-to-end
    trainable model. Both the encoder and decoder models are neural networks of different
    architectures, for example, RNNs and Attention Nets, to get desired outcomes.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件——编码器和解码器——连接在一起，形成一个端到端可训练的模型。编码器和解码器模型都是具有不同架构的神经网络，例如RNN和注意力网络，以获得期望的结果。
- en: As the model is learned, we can remove the decoder from the encoder and then
    use them separately. To generate a new data sample, we can first generate a sample
    from the latent space and then feed that to the decoder to create a new sample
    from the output space.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型的学习，我们可以从编码器中移除解码器，然后单独使用它们。为了生成新的数据样本，我们可以首先从潜在空间生成一个样本，然后将其输入解码器，从输出空间创建一个新的样本。
- en: Autoencoders are covered in more detail in [Chapter 8](130cc1c9-51d3-4ba5-95d3-12bb53dee5bd.xhtml),
    *Autoencoders* .
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器在[第8章](130cc1c9-51d3-4ba5-95d3-12bb53dee5bd.xhtml)中有更详细的介绍，*自编码器*。
- en: GAN
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN
- en: As seen with autoencoders, we can think of a general concept to create networks
    that will work together in a relationship, and training them will help us learn
    the latent spaces that allow us to generate new data samples.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如自编码器所示，我们可以将创建可以在关系中共同工作的网络的概念作为一般思路，训练这些网络将帮助我们学习潜在空间，从而生成新的数据样本。
- en: Another type of generative network is GAN, where we have a generator model *q(x|h)*
    to map the small dimensional latent space of *h* (which is usually represented
    as noise samples from a simple distribution) to the input space of *x*. This is
    quite similar to the role of decoders in autoencoders.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种生成网络是GAN，其中我们有一个生成模型*q(x|h)*，它将小维度的潜在空间*h*（通常表示为来自简单分布的噪声样本）映射到输入空间*x*。这与自编码器中解码器的作用非常相似。
- en: The deal is now to introduce a discriminative model *p(y| x),* which tries to
    associate an input instance *x* to a yes/no binary answer *y*, about whether the
    generator model generated the input or was a genuine sample from the dataset we
    were training on.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的任务是引入一个判别模型*p(y| x)*，它试图将输入实例*x*与一个二元答案*y*关联起来，判断该输入是由生成器模型生成的，还是来自我们训练数据集中的真实样本。
- en: Let's use the image example done previously. Assume that the generator model
    creates a new image, and we also have the real image from our actual dataset.
    If the generator model was right, the discriminator model would not be able to
    distinguish between the two images easily. If the generator model was poor, it
    would be very simple to tell which one was a fake or fraud and which one was real.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用之前做的图像示例。假设生成器模型创建了一张新图像，我们也有来自实际数据集的真实图像。如果生成器模型做得正确，判别模型将难以区分这两张图像。如果生成器模型做得不好，判断哪张是假图像、哪张是真图像将变得非常简单。
- en: When both these models are coupled, we can train them end to end by assuring
    that the generator model is getting better over time to fool the discriminator
    model, while the discriminator model is trained to work on the harder problem
    of detecting frauds. Finally, we desire a generator model with outputs that are
    indistinguishable from the real data that we used for the training.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当这两个模型结合在一起时，我们可以通过确保生成模型随着时间的推移变得更强，从而欺骗判别模型，同时训练判别模型去处理更难的任务——检测欺诈。最终，我们希望生成器模型的输出与我们用来训练的真实数据无法区分。
- en: 'Through the initial parts of the training, the discriminator model can easily
    detect the samples coming from the actual dataset versus the ones generated synthetically
    by the generator model, which is just beginning to learn. As the generator gets
    better at modeling the dataset, we begin to see more and more generated samples
    that look similar to the dataset. The following example depicts the generated
    images of a GAN model learning over time:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练的初期，判别模型可以轻松区分实际数据集中的样本与生成模型刚开始学习时所生成的样本。随着生成器在建模数据集方面的能力逐渐提升，我们开始看到越来越多与数据集相似的生成样本。下面的例子展示了一个GAN模型随着时间推移学习的生成图像：
- en: '![](img/ba581ac8-3fa3-42cc-ac63-18e7597d0d06.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba581ac8-3fa3-42cc-ac63-18e7597d0d06.png)'
- en: In the upcoming sections, we will discuss GANs in detail.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将详细讨论GAN。
- en: Sequence models
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列模型
- en: If the data is temporal in nature, then we can use specialized algorithms called
    **Sequence Models**. These models can learn the probability of the form *p(y|x_n,
    x_1)*, where *i* is an index signifying the location in the sequence and *x_i*
    is the *i^(th)* input sample.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果数据具有时间性，我们可以使用专门的算法，称为**序列模型**。这些模型可以学习形式为*p(y|x_n, x_1)*的概率，其中*i*是表示序列中位置的索引，*x_i*是第*i*个输入样本。
- en: As an example, we can consider each word as a series of characters, each sentence
    as a series of words, and each paragraph as a series of sentences. Output *y*
    could be the sentiment of the sentence.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个例子，我们可以将每个单词看作是一系列字符，每个句子看作是一系列单词，每个段落看作是一系列句子。输出*y*可以是句子的情感。
- en: Using a similar trick from autoencoders, we can replace *y* with the next item
    in the series or sequence, namely *y =x_n + 1*, allowing the model to learn.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自编码器中的类似技巧，我们可以将*y*替换为序列或序列中的下一个项，即*y = x_n + 1*，从而让模型学习。
- en: GANs
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN
- en: 'GANs were introduced by a group of researchers at the University of Montreal
    led by *Ian Goodfellow*. The core idea behind a GAN model is to have two competing
    neural network models. One network takes the noise as input and generates samples
    (hence known as **generator**). The second model (known as **discriminator**)
    gets samples from both the generator and the actual training data, and should
    be able to differentiate between the two sources. Generative and discriminative
    networks are playing a continuous game, where the generator model is learning
    to generate more realistic samples or examples, and the discriminator is learning
    to get better and better at differentiating generated data from the real data.
    The two networks are trained simultaneously, and the goal is that the competition
    will make the generated samples indistinguishable from the real data:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: GAN是由蒙特利尔大学的一组研究人员提出的，该团队由*Ian Goodfellow*领导。GAN模型的核心思想是有两个相互竞争的神经网络模型。一个网络以噪声为输入并生成样本（因此被称为**生成器**）。第二个模型（称为**判别器**）从生成器和实际的训练数据中获取样本，并应能区分这两种来源。生成模型和判别模型在不断地进行博弈，生成器学习生成更真实的样本，而判别器则学习更好地区分生成的数据和真实数据。这两个网络同时训练，目标是通过这种竞争，使得生成的样本与真实数据无法区分：
- en: '![](img/746e5e26-9573-47b6-8569-d28866ce5966.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/746e5e26-9573-47b6-8569-d28866ce5966.png)'
- en: The analogy used to describe GANs is that the generator is like a forger that
    is attempting to produce some forged material, and the discriminator model is
    the police trying to detect the forged items. This may seem somewhat similar to
    reinforcement learning where the generator is getting a reward from the discriminator,
    allowing it to know whether the generated data is accurate or not. The key distinction
    with GANs is that we can backpropagate gradient information from the discriminator
    network back to the generator network, such that the generator knows how to adapt
    its parameters in order to generate output data that can fool the discriminator.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 用来描述GAN的类比是：生成器就像一个伪造者，试图制造一些伪造的物品，而判别器模型则像警察，试图检测伪造的物品。这可能看起来与强化学习有些相似，在强化学习中，生成器从判别器那里获得奖励，帮助它知道生成的数据是否准确。GAN的关键区别在于，我们可以将来自判别器网络的梯度信息反向传播到生成器网络，从而让生成器知道如何调整其参数，生成能够欺骗判别器的输出数据。
- en: As of today, GANs have been mainly applied to model natural images. They provide
    best results in image generation tasks and also in generating images that are
    sharper than the ones trained using other generative methods based on maximum
    likelihood training objectives.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 截至今天，GAN主要被应用于建模自然图像。它们在图像生成任务中提供了最佳的结果，且在生成比其他基于最大似然训练目标的生成方法更清晰的图像方面也表现出色。
- en: 'Here are some examples of images generated by GANs:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些由GAN生成的图像示例：
- en: '![](img/2a4a2461-6921-4252-ad7b-9bbc56cf8ce4.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a4a2461-6921-4252-ad7b-9bbc56cf8ce4.png)'
- en: GAN with an example
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN 示例
- en: For a deeper understanding of how GANs work, we'll use a GAN to solve a simple
    problem in TensorFlow, namely, learning to approximate a one-dimensional Gaussian
    distribution.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更深入理解GAN是如何工作的，我们将使用一个GAN在TensorFlow中解决一个简单的问题，即学习近似一维高斯分布。
- en: 'First, we will create the actual data distribution, a simple Gaussian with
    a mean of four and standard deviation of 0.5\. It has a sample function that returns
    a given number of samples (sorted by value) from the distribution. The data distribution
    that we learn will look like the following diagram:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将创建实际数据分布，这是一个简单的高斯分布，均值为4，标准差为0.5。它有一个样本函数，返回来自该分布的指定数量的样本（按值排序）。我们学习的数据分布将类似于以下图示：
- en: '![](img/066437dd-ffad-443b-8b62-c1429b9d428b.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/066437dd-ffad-443b-8b62-c1429b9d428b.png)'
- en: Generator input noise distribution is also defined with a similar sample function
    used for actual data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器输入的噪声分布也通过类似的样本函数定义，用于实际数据。
- en: Both generator and discriminator networks are very simple. Generator is a linear
    transformation passed through a non linearity (`softplus` function), followed
    by another linear transformation.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器和判别器网络都非常简单。生成器是一个线性变换，通过非线性函数（`softplus`函数）进行处理，随后是另一个线性变换。
- en: We kept the discriminator stronger than the generator; otherwise, it would not
    have enough capacity to learn to be able to differentiate accurately between generated
    and real samples. Hence, we made it a deeper neural network with a higher number
    of dimensions. We use *tanh* non linearities in all layers except the final one,
    which is a sigmoid (the output of which can be described as a probability).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们保持判别器比生成器更强，否则它将没有足够的能力准确区分生成的样本和真实样本。因此，我们将判别器设计为一个更深的神经网络，拥有更高的维度。除最后一层外，我们在所有层使用*tanh*非线性函数，最后一层使用的是sigmoid（其输出可以描述为概率）。
- en: We connect these networks as part of the TensorFlow graph and define loss functions
    for each of the networks so that the generator network will be simply fooling
    the discriminator network. The Gradient Descent Optimizer from TensorFlow with
    exponential learning rate decay is used as an optimizer.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些网络连接到TensorFlow图中，并为每个网络定义损失函数，以便生成器网络能轻松欺骗判别器网络。我们使用TensorFlow的梯度下降优化器，并配合指数学习率衰减作为优化器。
- en: To train the model, we draw samples from the data distribution and the noise
    distribution, and alternate between optimizing the parameters of the discriminator
    and the generator.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练模型，我们从数据分布和噪声分布中抽取样本，并交替优化判别器和生成器的参数。
- en: 'We will see that, at the start of the training method, the generator was generating
    a very different distribution to the real data. The network slowly learns to approximate
    it quite closely before converging to a narrower distribution focused on the mean
    of the input distribution. After training the networks, the two distributions
    look something like this:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会看到，在训练方法开始时，生成器生成的分布与真实数据非常不同。网络逐渐学习逼近真实数据，最终收敛到一个聚焦于输入分布均值的更窄分布。在训练完网络之后，两个分布大致如下图所示：
- en: '![](img/fdf1eb31-e0b5-4821-ab33-1801f9c0fd20.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fdf1eb31-e0b5-4821-ab33-1801f9c0fd20.png)'
- en: The problem of the generator network falling to a param setting where it generates
    a very narrow distribution or pattern of points is one of the major failures of
    GANs. The solution will be to allow the discriminator to look at multiple samples
    at once, a technique that we call minibatch discrimination. Minibatch discrimination
    is a method wherein the discriminator can glance at an entire batch of samples
    to determine whether they come from the generator network or from the actual data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器网络陷入一种参数设置，导致它生成一个非常狭窄的分布或点模式，是GANs的主要失败之一。解决方案是允许判别器一次查看多个样本，这种技术称为小批量判别。小批量判别是一种方法，判别器可以查看一个完整的批次样本，判断它们是来自生成器网络还是来自真实数据。
- en: 'A summary of the method is as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的总结如下：
- en: Take the output of any intermediate layer of the discriminator network
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取判别器网络任何中间层的输出。
- en: Multiply this output by a 3D tensor to generate a matrix of size *numOfKernels
    ** *kernelDim*
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将该输出乘以一个3D张量，生成一个大小为*numOfKernels ** *kernelDim*的矩阵。
- en: Calculate the L1-distance between rows in this matrix across all samples in
    a batch, and then apply a negative exponential
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算该矩阵中每一行之间的L1距离，并对批次中的所有样本应用负指数。
- en: Minibatch features or properties for a sample are then the sum of these exponentiated
    distances
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 样本的小批量特征或属性是这些指数距离的总和。
- en: Concatenate the actual input to the mini batch layer, that is, output of the
    previous or former discriminator layer with the created minibatch features, and
    then pass this as input to the next layer of the discriminator network
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将实际输入与小批量层连接，即将前一个判别器层的输出与创建的小批量特征进行合并，然后将其作为输入传递给判别器网络的下一个层。
- en: 'Minibatch discrimination makes the batch size as important as a hyperparameter:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 小批量判别使得批量大小变得和超参数一样重要：
- en: '[PRE0]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Output Listing:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 输出列表：
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Types of GANs
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN的类型
- en: The following section shows different types of GANs, for example, Vanilla GAN,
    Conditional GAN etc. Refer to [https://arxiv.org](https://arxiv.org) for further
    information on the papers. The following description about each GAN network is
    taken from the respective paper on [https://arxiv.org](https://arxiv.org).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下部分展示了不同类型的GAN，例如普通GAN、条件GAN等。欲了解更多论文信息，请参考[https://arxiv.org](https://arxiv.org)。以下每种GAN网络的描述均来自相应的论文，论文地址为[https://arxiv.org](https://arxiv.org)。
- en: Vanilla GAN
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 普通GAN
- en: Vanilla GANs has two networks called generator network and a discriminator network.
    Both the networks are trained at the same time and compete or battle against each
    other in a minimax play. Generator network is trained or prepared such that it
    can fool the discriminator network by creating the real images as per the input,
    and the discriminator is trained not to be fooled by the generator network.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 普通GAN（Vanilla GAN）有两个网络，分别是生成器网络和判别器网络。两个网络同时训练，并且相互竞争或对抗，进行极小极大博弈。生成器网络被训练为能够通过根据输入生成真实图像来欺骗判别器网络，而判别器网络则被训练为不被生成器网络所欺骗。
- en: For further reading on Vanilla GAN refer to [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如需进一步了解普通GAN，请参考[https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)。
- en: Conditional GAN
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条件GAN
- en: GANs was started as a novel way of generative training models. These are GAN
    networks that utilize extra label data. It results in excellent quality images
    and being able to control to an extent how generated images will look. This model
    can be used to learn a multi-modal model.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: GAN（生成对抗网络）最初是作为一种新颖的生成训练模型方式出现的。这些是利用额外标签数据的GAN网络。它能够生成高质量的图像，并且在一定程度上控制生成图像的外观。该模型可以用于学习多模态模型。
- en: For further reading on Conditional GAN refer to [https://arxiv.org/abs/1411.1784.](https://arxiv.org/abs/1411.1784.)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如需进一步了解条件GAN，请参考[https://arxiv.org/abs/1411.1784.](https://arxiv.org/abs/1411.1784.)
- en: Info GAN
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Info GAN
- en: GANs that can encode or learn important image features or disentangled representations
    in an unsupervised manner. An example is to encode the rotation of a digit. Info
    GANs also maximizes the mutual information between a small subset of the latent
    variables and the observation.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: GAN可以以无监督的方式编码或学习重要的图像特征或解耦表示。一个例子是编码数字的旋转。Info GAN还最大化潜在变量的小子集与观测值之间的互信息。
- en: For further reading on Info GAN refer to [https://arxiv.org/abs/1606.03657](https://arxiv.org/abs/1606.03657)
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如需进一步了解Info GAN，请参考[https://arxiv.org/abs/1606.03657](https://arxiv.org/abs/1606.03657)
- en: Wasserstein GAN
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Wasserstein GAN
- en: WGAN is an option to regular GAN training. WGANs have loss functions that correlate
    with image quality. Additionally, the stability of the training improves and is
    not as dependent on the architecture and provide significant learning curves useful
    for debugging.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: WGAN（Wasserstein生成对抗网络）是对常规GAN训练的一种选择。WGAN的损失函数与图像质量相关。此外，WGAN的训练稳定性提高，不那么依赖于架构，并且提供了有助于调试的显著学习曲线。
- en: For further reading on Wasserstein GAN refer to [https://arxiv.org/abs/1701.07875](https://arxiv.org/abs/1701.07875)
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如需进一步了解Wasserstein GAN，请参考[https://arxiv.org/abs/1701.07875](https://arxiv.org/abs/1701.07875)
- en: Coupled GAN
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联合GAN
- en: Coupled GANs is used for generating sets of like images in two separate domains.
    It consists of set of GANs each accountable for generating images in the single
    domain. The Coupled GANs learns a joint distribution from images in the two domains
    which are drawn separately from the marginal distributions of the unique domains.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 联合GAN（Coupled GANs）用于在两个独立领域中生成相似图像的集合。它由一组GAN组成，每个GAN负责在单一领域内生成图像。联合GAN学习两个领域中图像的联合分布，这些图像分别从各自领域的边缘分布中抽取。
- en: For further reading on Coupled GAN refer to [https://arxiv.org/abs/1606.07536](https://arxiv.org/abs/1606.07536)
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如需进一步了解联合GAN，请参考[https://arxiv.org/abs/1606.07536](https://arxiv.org/abs/1606.07536)
- en: Summary
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Generative models are a fast advancing area of study and research. As we proceed
    to advance these models and grow the training and datasets, we can expect to generate
    data examples that depict completely believable images, finally. This can be used
    in several applications such as image denoising, painting, structured prediction,
    and exploration in reinforcement learning.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型是一个快速发展的研究领域。随着我们推进这些模型并扩展训练和数据集，我们可以期待最终生成出完全可信的图像数据示例。这可以应用于多种场景，如图像去噪、绘画、结构化预测以及强化学习中的探索。
- en: The deeper promise of this effort is that, in the process of building generative
    models, we will enrich the computer with an understanding of the world and what
    elements it is made up of.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这项努力的更深层次承诺是，在构建生成模型的过程中，我们将赋予计算机对世界及其组成元素的理解。
