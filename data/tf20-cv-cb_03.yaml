- en: '*Chapter 3*: Harnessing the Power of Pre-Trained Networks with Transfer Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 3 章*：利用预训练网络的迁移学习威力'
- en: 'Despite the undeniable power deep neural networks bring to computer vision,
    they are very complex to tune, train, and make performant. This difficulty comes
    from three main sources:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度神经网络为计算机视觉带来了不可否认的强大力量，但它们在调整、训练和提高性能方面非常复杂。这种难度来自三个主要来源：
- en: Deep neural networks start to pay off when we have sufficient data, but more
    often than not, this is not the case. Furthermore, data is expensive and, sometimes,
    impossible to expand.
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度神经网络通常在数据充足时才会发挥作用，但往往并非如此。此外，数据既昂贵又有时难以扩展。
- en: Deep neural networks contain a wide range of parameters that need tuning and
    can affect the overall performance of the model.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度神经网络包含许多需要调节的参数，这些参数会影响模型的整体表现。
- en: Deep learning is very resource-intensive in terms of time, hardware, and effort.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习在时间、硬件和精力方面是非常资源密集型的。
- en: Do not be dismayed! With **transfer learning**, we can save ourselves loads
    of time and effort by leveraging the rich amount of knowledge present in seminal
    architectures that have been pre-trained on gargantuan datasets, such as ImageNet.
    And the best part? Besides being such a powerful and useful tool, transfer learning
    is also easy to apply. We'll learn how to do this in this chapter.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 别灰心！通过**迁移学习**，我们可以通过利用在庞大数据集（如 ImageNet）上预训练的经典架构中丰富的知识，节省大量时间和精力。而最棒的部分是？除了它是如此强大且有用的工具，迁移学习还很容易应用。在本章中，我们将学习如何做到这一点。
- en: 'In this chapter, we are going to cover the following recipes:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将覆盖以下食谱：
- en: Implementing a feature extractor using a pre-trained network
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预训练网络实现特征提取器
- en: Training a simple classifier on extracted features
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在提取的特征上训练一个简单的分类器
- en: Spot-checking extractors and classifiers
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查提取器和分类器的效果
- en: Using incremental learning to train a classifier
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用增量学习训练分类器
- en: Fine-tuning a network using the Keras API
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Keras API 微调网络
- en: Fine-tuning a network using TFHub
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 TFHub 微调网络
- en: Let's get started!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始吧！
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'It''s highly encouraged that you have access to a GPU since transfer learning
    tends to be quite computationally heavy. In the *Getting ready* section of each
    recipe, you''ll receive specific instructions – if they''re needed – on how to
    install the dependencies for that recipe. You can find all the code for this chapter
    here: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 强烈建议你拥有 GPU 访问权限，因为迁移学习通常计算密集型。在每个食谱的*准备工作*部分，你将收到有关如何安装该食谱所需依赖项的具体说明。如果需要，你可以在这里找到本章的所有代码：[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3)。
- en: 'Check out the following link to see the Code in Action video:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下链接，观看 Code in Action 视频：
- en: '[https://bit.ly/39wR6DT](https://bit.ly/39wR6DT).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://bit.ly/39wR6DT](https://bit.ly/39wR6DT)。'
- en: Implementing a feature extractor using a pre-trained network
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用预训练网络实现特征提取器
- en: One of the easiest ways to seize the power of transfer learning is to use pre-trained
    models as feature extractors. This way, we can combine both deep learning and
    machine learning, something that we normally cannot do, because traditional machine
    learning algorithms don't work with raw images. In this recipe, we'll implement
    a reusable `FeatureExtractor` class to produce a dataset of vectors from a set
    of input images, and then save it in the blazingly fast HDF5 format.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 利用迁移学习的最简单方法之一是将预训练模型用作特征提取器。这样，我们可以将深度学习和机器学习相结合，而这通常是我们做不到的，因为传统的机器学习算法无法处理原始图像。在这个示例中，我们将实现一个可重用的`FeatureExtractor`类，从一组输入图像中生成特征向量数据集，并将其保存在极速的
    HDF5 格式中。
- en: Are you ready? Let's get started!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你准备好了吗？我们开始吧！
- en: Getting ready
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'You''ll need to install `Pillow` and `tqdm` (which we''ll use to display a
    nice progress bar). Fortunately, this is very easy with `pip`:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要安装`Pillow`和`tqdm`（我们将用它来显示一个漂亮的进度条）。幸运的是，使用`pip`安装非常容易：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We''ll be using the `Stanford Cars` dataset, which you can download here: [http://imagenet.stanford.edu/internal/car196/car_ims.tgz](http://imagenet.stanford.edu/internal/car196/car_ims.tgz).
    Decompress the data to a location of your preference. In this recipe, we assume
    the data is inside the `~/.keras/datasets` directory, under the name `car_ims`.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`Stanford Cars`数据集，你可以在这里下载：[http://imagenet.stanford.edu/internal/car196/car_ims.tgz](http://imagenet.stanford.edu/internal/car196/car_ims.tgz)。将数据解压到你选择的位置。在本配方中，我们假设数据位于`~/.keras/datasets`目录下，名为`car_ims`。
- en: 'Here are some sample images from the dataset:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是数据集中的一些示例图像：
- en: '![Figure 3.1 – Sample images'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.1 – 示例图像'
- en: '](img/B14768_03_001.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_03_001.jpg)'
- en: Figure 3.1 – Sample images
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1 – 示例图像
- en: 'We''ll store the extracted features in HDF5 format, a binary, hierarchical
    protocol designed to store very large numerical datasets on disk, while keeping
    ease of access and computation on a row-wise level. You can read more about HDF5
    here: [https://portal.hdfgroup.org/display/HDF5/HDF5](https://portal.hdfgroup.org/display/HDF5/HDF5).'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把提取的特征以HDF5格式存储，HDF5是一种用于在磁盘上存储非常大的数值数据集的二进制分层协议，同时保持易于访问和按行级别计算。你可以在这里了解更多关于HDF5的内容：[https://portal.hdfgroup.org/display/HDF5/HDF5](https://portal.hdfgroup.org/display/HDF5/HDF5)。
- en: How to do it…
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'Follow these steps to complete this recipe:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成此配方：
- en: 'Import all the necessary packages:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必要的包：
- en: '[PRE1]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Define the `FeatureExtractor` class and its constructor:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`FeatureExtractor`类及其构造函数：
- en: '[PRE2]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We need to make sure the output path can be written:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要确保输出路径是可写的：
- en: '[PRE3]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, let''s store the input parameter as object members:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们将输入参数存储为对象成员：
- en: '[PRE4]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`self.buffer` will contain a buffer of both instances and labels, while `self.current_index`
    will point to the next free location within the datasets in the inner HDF5 database.
    We''ll create this now:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`self.buffer`将包含实例和标签的缓冲区，而`self.current_index`将指向HDF5数据库内数据集中的下一个空闲位置。我们现在将创建它：'
- en: '[PRE5]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Define a method that will extract features and labels from a list of image
    paths and store them in the `HDF5` database:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个方法，从图像路径列表中提取特征和标签，并将它们存储到`HDF5`数据库中：
- en: '[PRE6]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'After shuffling the image paths and their labels, as well as encoding and storing
    the latter, we''ll iterate over batches of images, passing them through the pre-trained
    network. Once we''ve done this, we''ll save the resulting features into the HDF5
    database (the helper methods we''ve used here will be defined shortly):'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在对图像路径及其标签进行洗牌，并对标签进行编码和存储后，我们将遍历图像的批次，将它们传递通过预训练的网络。一旦完成，我们将把结果特征保存到HDF5数据库中（我们在这里使用的辅助方法稍后会定义）：
- en: '[PRE7]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Define a private method that will add features and labels to the corresponding
    datasets:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个私有方法，将特征和标签添加到相应的数据集：
- en: '[PRE8]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Define a private method that will flush the buffers to disk:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个私有方法，将缓冲区刷新到磁盘：
- en: '[PRE9]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Define a private method that will store the class labels in the HDF5 database:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个私有方法，将类别标签存储到HDF5数据库中：
- en: '[PRE10]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Define a private method that will close the HDF5 dataset:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个私有方法，将关闭HDF5数据集：
- en: '[PRE11]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Load the paths to the images in the dataset:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集中图像的路径：
- en: '[PRE12]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Create the output directory. We''ll create a dataset of rotated car images
    so that a potential classifier can learn how to correctly revert the photos back
    to their original orientation, by correctly predicting the rotation angle:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建输出目录。我们将创建一个旋转车图像的数据集，以便潜在的分类器可以学习如何正确地将照片恢复到原始方向，通过正确预测旋转角度：
- en: '[PRE13]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create a copy of the dataset with random rotations performed on the images:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建数据集的副本，对图像进行随机旋转：
- en: '[PRE14]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Instantiate `FeatureExtractor` while using a pre-trained `VGG16` network to
    extract features from the images in the dataset:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化`FeatureExtractor`，并使用预训练的`VGG16`网络从数据集中的图像提取特征：
- en: '[PRE15]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Extract the features and labels:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取特征和标签：
- en: '[PRE16]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: After several minutes, there should be a file named `features.hdf5` in `~/.keras/datasets/car_ims_rotated`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，应该会在`~/.keras/datasets/car_ims_rotated`中生成一个名为`features.hdf5`的文件。
- en: How it works…
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In this recipe, we implemented a reusable component in order to use pre-trained
    networks on ImageNet, such as `Logistic Regression` and `Support Vector Machines`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们实现了一个可重用的组件，以便在ImageNet上使用预训练网络，如`逻辑回归`和`支持向量机`。
- en: Because image datasets tend to be too big to fit in memory, we resorted to the
    high-performance, user-friendly HDF5 format, which is perfect for storing large
    numeric data on disk, while also keeping the ease of access that's typical of
    `NumPy`. This means we can interact with HDF5 datasets *as if they were* regular
    `NumPy` arrays, making them compatible with the whole `SciPy` ecosystem.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图像数据集通常过大，无法全部载入内存，我们选择了高性能且用户友好的HDF5格式，这种格式非常适合将大规模数值数据存储在磁盘上，同时保留了`NumPy`典型的易访问性。这意味着我们可以像操作常规`NumPy`数组一样与HDF5数据集进行交互，使其与整个`SciPy`生态系统兼容。
- en: 'The result of `FeatureExtractor` is a hierarchical HDF5 file (think of it as
    a folder in a filesystem) containing three datasets: `features`, which contains
    the feature vectors, `labels`, which stores the encoded labels, and `label_names`,
    which holds the human-readable labels prior to encoding.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`FeatureExtractor`的结果是一个分层的HDF5文件（可以将其视为文件系统中的一个文件夹），包含三个数据集：`features`，包含特征向量；`labels`，存储编码后的标签；以及`label_names`，保存编码前的人类可读标签。'
- en: Finally, we used `FeatureExtractor` to create a binary representation of a dataset
    of car images rotated 0º, 90º, 180º, or 270º.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用`FeatureExtractor`创建了一个二进制表示的数据集，数据集包含了旋转了0º、90º、180º或270º的汽车图像。
- en: Tip
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: We'll use the modified version of the `Stanford Cars` dataset we just worked
    on in future recipes in this chapter.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章的后续教程中继续使用刚刚处理过的修改版`Stanford Cars`数据集。
- en: See also
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'For more information on the `Stanford Cars` dataset, you can visit the official
    page here: [https://ai.stanford.edu/~jkrause/cars/car_dataset.html](https://ai.stanford.edu/~jkrause/cars/car_dataset.html).
    To learn more about HDF5, head to the official HDF Group website: [https://www.hdfgroup.org/](https://www.hdfgroup.org/).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`Stanford Cars`数据集的更多信息，您可以访问官方页面：[https://ai.stanford.edu/~jkrause/cars/car_dataset.html](https://ai.stanford.edu/~jkrause/cars/car_dataset.html)。要了解更多关于HDF5的信息，请访问HDF
    Group的官方网站：[https://www.hdfgroup.org/](https://www.hdfgroup.org/)。
- en: Training a simple classifier on extracted features
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在提取特征后训练一个简单的分类器
- en: Machine learning algorithms are not properly equipped to work with tensors,
    which forbid them from learning directly from images. However, by using pre-trained
    networks as feature extractors, we close this gap, enabling us to access the power
    of widely popular, battle-tested algorithms such as **Logistic Regression**, **Decision
    Trees,** and **Support Vector Machines**.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习算法并不适合直接处理张量，因此它们无法直接从图像中学习。然而，通过使用预训练的网络作为特征提取器，我们弥补了这一差距，使我们能够利用广泛流行且经过实战验证的算法，如**逻辑回归**、**决策树**和**支持向量机**。
- en: In this recipe, we'll use the features we generated in the previous recipe (in
    HDF5 format) to train an image orientation detector to correct the degrees of
    rotation of a picture, to restore its original state.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用在前一个教程中生成的特征（以HDF5格式）来训练一个图像方向检测器，以修正图像的旋转角度，将其恢复到原始状态。
- en: Getting ready
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'As we mentioned in the introduction to this reipce, we''ll use the `features.hdf5`
    dataset we generated in the previous recipe, which contains encoded information
    about rotated images from the `Stanford Cars` dataset. We assume the dataset is
    in the following location: `~/.keras/datasets/car_ims_rotated/features.hdf5`.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本教程的介绍中提到的，我们将使用在前一个教程中生成的`features.hdf5`数据集，该数据集包含了来自`Stanford Cars`数据集的旋转图像的编码信息。我们假设该数据集位于以下位置：`~/.keras/datasets/car_ims_rotated/features.hdf5`。
- en: 'Here are some rotated samples:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些旋转的样本：
- en: '![Figure 3.2 – Example of a car rotated 180º (left), and another rotated 90º
    (right)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.2 – 一辆旋转了180º的汽车（左），以及另一辆旋转了90º的汽车（右）'
- en: '](img/B14768_03_002.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_03_002.jpg)'
- en: Figure 3.2 – Example of a car rotated 180º (left), and another rotated 90º (right)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 – 一辆旋转了180º的汽车（左），以及另一辆旋转了90º的汽车（右）
- en: Let's begin!
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: How to do it…
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Follow these steps to complete this recipe:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成本教程：
- en: 'Import the required packages:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的包：
- en: '[PRE17]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Load the dataset in HDF5 format:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载HDF5格式的数据集：
- en: '[PRE18]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Because the dataset is too big, we''ll only work with 50% of the data. The
    following block splits both the features and labels in half:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于数据集太大，我们只处理50%的数据。以下代码将特征和标签分成两半：
- en: '[PRE19]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Take the first 80% of the data to train the model, and the remaining 20% to
    evaluate it later on:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 取数据的前80%来训练模型，其余20%用于之后的评估：
- en: '[PRE20]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Train a cross-validated `LogisticRegressionCV` will find the best `C` parameter
    using cross-validation:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练一个交叉验证的`LogisticRegressionCV`，通过交叉验证找到最佳的`C`参数：
- en: '[PRE21]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Notice that `n_jobs=-1` means we'll use all available cores to find the best
    model in parallel. You can adjust this value based on the capacity of your hardware.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，`n_jobs=-1`意味着我们将使用所有可用的核心来并行寻找最佳模型。您可以根据硬件的性能调整此值。
- en: 'Evaluate the model on the test set. We''ll compute a classification report
    to get a fine-grained view of the model''s performance:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试集上评估模型。我们将计算分类报告，以获得模型性能的细节：
- en: '[PRE22]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This prints the following report:'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将打印以下报告：
- en: '[PRE23]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The model does a good job of discriminating between the four classes, achieving
    an overall accuracy of 99% on the test set!
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该模型在区分四个类别方面表现良好，在测试集上达到了99%的整体准确率！
- en: 'Finally, close the HDF5 file to free up any resources:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，关闭HDF5文件以释放任何资源：
- en: '[PRE24]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We'll understand how this all works in the next section.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中了解这一切如何工作。
- en: How it works…
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We just trained a very simple **Logistic Regression** model to detect the degree
    of rotation in an image. To achieve this, we leveraged the rich and expressive
    features we extracted using a pre-trained **VGG16** network on ImageNet (for a
    deeper explanation, refer to the first recipe of this chapter).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚训练了一个非常简单的**逻辑回归**模型，用于检测图像的旋转角度。为了实现这一点，我们利用了使用预训练**VGG16**网络在ImageNet上提取的丰富且富有表现力的特征（若需要更详细的解释，请参考本章的第一个食谱）。
- en: Because this data is too big, and **scikit-learn**'s machine learning algorithms
    work with the full data in one go (more specifically, most of them cannot work
    in batches), we only used 50% of the features and labels, due to memory constraints.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据量过大，而**scikit-learn**的机器学习算法一次性处理所有数据（更具体来说，大多数算法无法批处理数据），我们只使用了50%的特征和标签，因内存限制。
- en: After a couple of minutes, we obtained an incredible performance of 99% on the
    test set. Moreover, by analyzing the classification report, we can see that the
    model is very confident in its predictions, achieving an F1 score of at least
    0.99 in all four cases.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，我们在测试集上获得了惊人的99%的表现。此外，通过分析分类报告，我们可以看到模型对其预测非常有信心，在所有四个类别中F1分数至少达到了0.99。
- en: See also
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: For more information on how to extract features from pre-trained networks, refer
    to the *Implementing a feature extractor using a pre-trained network* recipe in
    this chapter.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有关如何从预训练网络中提取特征的更多信息，请参阅本章的*使用预训练网络实现特征提取器*一节。
- en: Spot-checking extractors and classifiers
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速检查提取器和分类器
- en: 'Often, when we are tackling a new project, we are victims of the Paradox of
    Choice: we don''t know where or how to start due to the presence of so many options
    to choose from. Which feature extractor is the best? What''s the most performant
    model we can train? How should we pre-process our data?'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理一个新项目时，我们常常成为选择悖论的受害者：由于有太多选择，我们不知道从哪里或如何开始。哪个特征提取器最好？我们能训练出最具性能的模型吗？我们应该如何预处理数据？
- en: In this recipe, we will implement a framework that will automatically spot-check
    feature extractors and classifiers. The goal is not to get the best possible model
    right away, but to narrow down our options so that we can focus on the most promising
    ones at a later stage.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将实现一个框架，自动快速检查特征提取器和分类器。目标不是立即获得最好的模型，而是缩小选择范围，以便在后期专注于最有前景的选项。
- en: Getting ready
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'First, we must install `Pillow` and `tqdm`:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要安装`Pillow`和`tqdm`：
- en: '[PRE25]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We''ll use a dataset called `17 Category Flower Dataset`, available here: [http://www.robots.ox.ac.uk/~vgg/data/flowers/17](http://www.robots.ox.ac.uk/~vgg/data/flowers/17).
    However, a curated version, organized into subfolders per class, can be downloaded
    here: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/flowers17.zip](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/flowers17.zip).
    Unzip it in a location of your preference. In this recipe, we assume the data
    is inside the `~/.keras/datasets` directory, under the name `flowers17`.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个名为`17 Category Flower Dataset`的数据集，下载地址：[http://www.robots.ox.ac.uk/~vgg/data/flowers/17](http://www.robots.ox.ac.uk/~vgg/data/flowers/17)。不过，也可以下载一个整理好的版本，该版本按照类别组织成子文件夹，下载地址：[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/flowers17.zip](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/flowers17.zip)。请将其解压到您喜欢的位置。在本食谱中，我们假设数据位于`~/.keras/datasets`目录下，名称为`flowers17`。
- en: Finally, we'll reuse the `FeatureExtractor()` class we defined in the *Implementing
    a feature extractor using a pre-trained network* recipe, at the start of this
    chapter. Refer to it if you want to learn more about it.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将重用在本章开头的*使用预训练网络实现特征提取器*食谱中定义的`FeatureExtractor()`类。如果你想了解更多，可以参考它。
- en: 'The following are some example images from the dataset for this recipe, `17
    Category Flower Dataset`:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是来自本食谱数据集`17类别花卉数据集`的一些示例图像：
- en: '![Figure 3.3 – Example images'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.3 – 示例图像'
- en: '](img/B14768_03_003.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_03_003.jpg)'
- en: Figure 3.3 – Example images
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3 – 示例图像
- en: With the preparation out of the way, let's get to it!
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 准备工作完成后，让我们开始吧！
- en: How to do it…
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何实现的……
- en: 'The following steps will allow us to spot-check several combinations of feature
    extractors and machine learning algorithms. Follow these steps to complete this
    recipe:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助我们对几种特征提取器和机器学习算法的组合进行抽查。按照以下步骤完成本食谱：
- en: 'Import the necessary packages:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包：
- en: '[PRE26]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Define the input size of all the feature extractors:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义所有特征提取器的输入大小：
- en: '[PRE27]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Define a function that will obtain a list of tuples of pre-trained networks,
    along with the dimensionality of the vectors they output:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，用于获取预训练网络的元组列表，以及它们输出的向量的维度：
- en: '[PRE28]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Define a function that returns a `dict` of machine learning models to spot-check:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个返回机器学习模型`dict`以进行抽查的函数：
- en: '[PRE29]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Define the path to the dataset, as well as a list of all image paths:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义数据集的路径，以及所有图像路径的列表：
- en: '[PRE30]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Load the labels into memory:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将标签加载到内存中：
- en: '[PRE31]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Define some variables in order to keep track of the spot-checking process.
    `final_report` will contain the accuracy of each classifier, trained on the features
    produced by different pre-trained networks. `best_model`, `best_accuracy`, and
    `best_features` will contain the name of the best model, its accuracy, and the
    name of the pre-trained network that produced the features, respectively:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一些变量以便跟踪抽查过程。`final_report`将包含每个分类器的准确率，分类器是在不同预训练网络提取的特征上训练的。`best_model`、`best_accuracy`和`best_features`将分别包含最佳模型的名称、准确率和生成特征的预训练网络的名称：
- en: '[PRE32]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Iterate over each pre-trained network, using it to extract features from the
    images in the dataset:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历每个预训练网络，使用它从数据集中的图像提取特征：
- en: '[PRE33]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Take 80% of the data to train, and 20% to test:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用80%的数据进行训练，20%的数据进行测试：
- en: '[PRE34]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Using the extracted features in the current iteration, go over all the machine
    learning models, training them on the training set and evaluating them on the
    test set:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用当前迭代中提取的特征，遍历所有机器学习模型，使用训练集进行训练，并在测试集上进行评估：
- en: '[PRE35]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Check if we have a new best model. If that''s the case, update the proper variables:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查是否有新的最佳模型。如果是，请更新相应的变量：
- en: '[PRE36]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Store the results of this iteration in `final_report` and free the resources
    of the HDF5 file:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将本次迭代的结果存储在`final_report`中，并释放HDF5文件的资源：
- en: '[PRE37]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Update `final_report` with the information of the best model. Finally, write
    it to disk:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新`final_report`，并写入最佳模型的信息。最后，将其写入磁盘：
- en: '[PRE38]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Examining the `final_report.json` file, we can see that the best model is a
    `PAClf` (`PassiveAggressiveClassifier`), which achieved an accuracy of 0.934 (93.4%)
    on the test set and was trained on the features we extracted from a **VGG19**
    network. You can check the full output here: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/final_report.json](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/final_report.json).
    Let''s head over to the next section to study the project we completed in this
    recipe in more detail.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 检查`final_report.json`文件，我们可以看到最好的模型是`PAClf`（`PassiveAggressiveClassifier`），它在测试集上的准确率为0.934（93.4%），并且是在我们从**VGG19**网络提取的特征上训练的。你可以在这里查看完整的输出：[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/final_report.json](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/final_report.json)。让我们进入下一部分，详细研究一下我们在本食谱中完成的项目。
- en: How it works…
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: In this recipe, we developed a framework that automatically enabled us to spot-check
    40 different machine learning algorithms by using the features produced by five
    different pre-trained networks, resulting in 200 experiments. Leveraging the results
    of this approach, we found that the best model combination for this particular
    problem was a `PassiveAggressiveClassifier` trained on vectors produced by a **VGG19**
    network.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们开发了一个框架，使我们能够自动抽查40种不同的机器学习算法，使用由五种不同的预训练网络生成的特征，最终进行了200次实验。通过这种方法的结果，我们发现，对于这个特定问题，最佳的模型组合是使用**VGG19**网络生成的向量训练`PassiveAggressiveClassifier`。
- en: Notice that we did not focus on achieving maximal performance, but rather on
    making an educated decision, based on hard evidence, on where to spend our time
    and resources if we were to optimize a classifier on this dataset. Now, we know
    that fine-tuning a **Passive Aggressive Classifier** will, most likely, pay off.
    How long would it have taken us to arrive at this conclusion? Hours or maybe days.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们并没有专注于实现最大性能，而是基于充分的证据做出明智的决策，决定在优化此数据集的分类器时如何合理地分配时间和资源。现在，我们知道微调**被动攻击性分类器**最有可能带来回报。那么，我们多久才能得出这个结论呢？几个小时，甚至几天。
- en: The power of letting the computer do the heavy lifting is that we don't have
    to guess and, at the same time, are free to spend our time on other tasks. It's
    great, isn't it?
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让计算机完成繁重工作的好处是，我们不必猜测，同时可以将时间自由地用于其他任务。这是不是很棒？
- en: Using incremental learning to train a classifier
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '使用增量学习训练分类器  '
- en: One of the problems of traditional machine learning libraries, such as **scikit-learn**,
    is that they seldom offer the possibility to train models on high volumes of data,
    which, coincidentally, is the best type of data for deep neural networks. What
    good is having large amounts of data if we can't use it?
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 传统机器学习库的一个问题，如**scikit-learn**，是它们很少提供在大规模数据上训练模型的可能性，而这恰好是深度神经网络最适合处理的数据。拥有大量数据又能有什么用，如果我们不能使用它呢？
- en: Fortunately, there is a way to circumvent this limitation, and it's called `creme`,
    to train a classifier on a dataset too big to fit in memory.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，有一种方法可以绕过这个限制，叫做`creme`，它可以在数据集过大无法加载到内存时训练分类器。
- en: Getting ready
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In this recipe, we''ll leverage `creme`, an experimental library specifically
    designed to train machine learning models on huge datasets that are too big to
    fit in memory. To install `creme`, execute the following command:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们将利用`creme`，这是一个专门设计用于在无法加载到内存的大数据集上训练机器学习模型的实验性库。要安装`creme`，请执行以下命令：
- en: '[PRE39]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We''ll use the `features.hdf5` dataset we generated in the *Implementing a
    feature extractor using a pre-trained network* recipe in this chapter, which contains
    encoded information about rotated images from the `Stanford Cars` dataset. We
    assume the dataset is in the following location: `~/.keras/datasets/car_ims_rotated/features.hdf5`.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章的*使用预训练网络实现特征提取器*配方中使用我们生成的`features.hdf5`数据集，该数据集包含来自`Stanford Cars`数据集中旋转图像的编码信息。我们假设数据集位于以下位置：`~/.keras/datasets/car_ims_rotated/features.hdf5`。
- en: 'The following are some sample images from this dataset:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是该数据集中的一些示例图像：
- en: '![Figure 3.4 – Example of a car rotated 90º (left), and another rotated 0º
    (right)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.4 – 旋转90º的汽车示例（左），和旋转0º的另一辆汽车（右）  '
- en: '](img/B14768_03_004.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_03_004.jpg)'
- en: Figure 3.4 – Example of a car rotated 90º (left), and another rotated 0º (right)
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4 – 旋转90º的汽车示例（左），和旋转0º的另一辆汽车（右）
- en: Let's begin!
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: How to do it…
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做……
- en: 'The following steps will guide us through how to incrementally train a classifier
    on big data:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将指导我们如何在大数据上逐步训练分类器：
- en: 'Import all the necessary packages:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必要的软件包：
- en: '[PRE40]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Define a function that will save a dataset as a CSV file:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，将数据集保存为CSV文件：
- en: '[PRE41]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We''ll have one column for the class of each feature, and as many columns of
    elements in each feature vector. Next, let''s write the contents of the CSV file
    in batches, starting with the header:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将为每个特征的类别设置一列，每个特征向量中的元素将设置多列。接下来，我们将批量写入CSV文件的内容，从头部开始：
- en: '[PRE42]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Extract the batch in this iteration:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取本次迭代中的批次：
- en: '[PRE43]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now, write all the rows in the batch:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，写入批次中的所有行：
- en: '[PRE44]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Load the dataset in HDF5 format:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载HDF5格式的数据集：
- en: '[PRE45]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Define the split index to separate the data into training (80%) and test (20%)
    chunks:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义分割索引，将数据分为训练集（80%）和测试集（20%）：
- en: '[PRE46]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Write the training and test subsets to disk as CSV files:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练集和测试集子集写入磁盘，保存为CSV文件：
- en: '[PRE47]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '`creme` requires us to specify the type of each column in the CSV file as a
    `dict`. instance The following block specifies that `class` should be encoded
    as `int`, while the remaining columns, corresponding to the features, should be
    of the `float` type:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`creme`要求我们将 CSV 文件中每一列的类型指定为`dict`实例。以下代码块指定了`class`应该编码为`int`类型，而其余列（对应特征）应该为`float`类型：'
- en: '[PRE48]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'In the following code, we are defining a `creme` pipeline, where each input
    will be standardized prior to being passed to the classifier. Because this is
    a multi-class problem, we need to wrap `LogisticRegression` with `OneVsRestClassifier`:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下代码中，我们定义了一个`creme`管道，每个输入在传递给分类器之前都会进行标准化。由于这是一个多类别问题，我们需要将`LogisticRegression`与`OneVsRestClassifier`包装在一起：
- en: '[PRE49]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Define `Accuracy` as the target metric and create an iterator over the `train.csv`
    dataset:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`Accuracy`定义为目标指标，并创建一个针对`train.csv`数据集的迭代器：
- en: '[PRE50]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Train the classifier, one example at a time. Print the running accuracy every
    100 examples:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一次训练一个样本的分类器。每训练 100 个样本时，打印当前准确率：
- en: '[PRE51]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Create an iterator over the `test.csv` file:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个针对`test.csv`文件的迭代器：
- en: '[PRE52]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Evaluate the model on the test set once more, one sample at a time:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次在测试集上评估模型，一次处理一个样本：
- en: '[PRE53]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: After several minutes, we should have a model with around 99% accuracy on the
    test set. We'll look at this in more detail in the next section.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，我们应该会得到一个在测试集上准确率约为 99% 的模型。我们将在下一部分详细查看这个过程。
- en: How it works…
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Often, even though we have massive amounts of data at our disposal, we are unable
    to use it all due to hardware or software limitations (in the *Training a simple
    classifier on extracted features* recipe, we had to use only 50%, because we couldn't
    keep it all in memory). However, with incremental learning (also known as online
    learning), we can train traditional machine learning models in batches, similar
    to what we can do with neural networks.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，尽管我们有大量的数据可用，但由于硬件或软件限制，我们无法使用所有数据（在*在提取特征上训练简单分类器*这一食谱中，我们只使用了 50% 的数据，因为无法将其全部保存在内存中）。然而，通过增量学习（也称为在线学习），我们可以像训练神经网络一样，以批处理的方式训练传统的机器学习模型。
- en: In this recipe, in order to seize the totality of the feature vector from our
    `Stanford Cars` dataset, we had to write both the training and test sets into
    CSV files. Next, we trained `LogisticRegression` and wrapped it inside `OneVsRestClassifier`,
    which learned to detect the degrees of rotation in the feature vectors of the
    images. Finally, we achieved a very satisfying 99% accuracy on the test set.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，为了捕获我们`Stanford Cars`数据集的特征向量的全部信息，我们不得不将训练集和测试集写入 CSV 文件。接下来，我们训练了`LogisticRegression`并将其包装在`OneVsRestClassifier`中，后者学习了如何检测图像特征向量中的旋转角度。最后，我们在测试集上达到了非常满意的
    99% 准确率。
- en: Fine-tuning a network using the Keras API
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Keras API 微调网络
- en: 'Perhaps one of the greatest advantages of transfer learning is its ability
    to seize the tailwind produced by the knowledge encoded in pre-trained networks.
    By simply swapping the shallower layers in one of these networks, we can obtain
    remarkable performance on new, unrelated datasets, even if our data is small.
    Why? Because the information in the bottom layers is virtually universal: It encodes
    basic forms and shapes that apply to almost any computer vision problem.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 或许迁移学习的最大优势之一就是能够利用预训练网络中所编码的知识带来的顺风。在这些网络中，只需交换较浅的层，我们就能在新的、无关的数据集上获得出色的表现，即使我们的数据量很小。为什么？因为底层的信息几乎是普遍适用的：它编码了适用于几乎所有计算机视觉问题的基本形式和形状。
- en: In this recipe, we'll fine-tune a pre-trained **VGG16** network on a tiny dataset,
    achieving an otherwise unlikely high accuracy score.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将对一个小型数据集微调预训练的**VGG16**网络，从而实现一个原本不太可能得到的高准确率。
- en: Getting ready
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We will need `Pillow` for this recipe. We can install it as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要`Pillow`来实现此食谱。可以按如下方式安装：
- en: '[PRE54]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We''ll be using a dataset known as `17 Category Flower Dataset`, which is available
    here: [http://www.robots.ox.ac.uk/~vgg/data/flowers/17](http://www.robots.ox.ac.uk/~vgg/data/flowers/17).
    A version of it that''s been organized into subfolders per class can be found
    here: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/flowers17.zip](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/flowers17.zip).
    Download and decompress it in a location of your choosing. From now on, we''ll
    assume the data is in `~/.keras/datasets/flowers17`.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个名为`17 Category Flower Dataset`的数据集，可以通过以下链接访问：[http://www.robots.ox.ac.uk/~vgg/data/flowers/17](http://www.robots.ox.ac.uk/~vgg/data/flowers/17)。该数据集的一个版本已经按照每个类的子文件夹进行组织，可以在此链接找到：[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/flowers17.zip](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/flowers17.zip)。下载并解压到您选择的位置。从现在起，我们假设数据存储在`~/.keras/datasets/flowers17`目录中。
- en: 'The following are some sample images from this dataset:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是来自该数据集的一些示例图像：
- en: '![Figure 3.5 – Example images'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.5 – 示例图像'
- en: '](img/B14768_03_005.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_03_005.jpg)'
- en: Figure 3.5 – Example images
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5 – 示例图像
- en: Let's begin!
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: How to do it…
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'Fine-tuning is easy! Follow these steps to complete this recipe:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 微调很简单！按照以下步骤完成这个食谱：
- en: 'Import the necessary dependencies:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的依赖项：
- en: '[PRE55]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Set the random seed:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置随机种子：
- en: '[PRE56]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Define a function that will build a new network from a pre-trained model, where
    the top fully connected layers will be brand new and adapted to the problem at
    hand:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，从预训练模型构建一个新的网络，其中顶部的全连接层将是全新的，并且针对当前问题进行了调整：
- en: '[PRE57]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Define a function that will load the images and labels in the dataset as `NumPy`
    arrays:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，将数据集中的图像和标签加载为`NumPy`数组：
- en: '[PRE58]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Load the image paths and extract the set of classes from them:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载图像路径并从中提取类集合：
- en: '[PRE59]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Load the images and normalize them, one-hot encode the labels with `LabelBinarizer()`,
    and split the data into subsets for training (80%) and testing (20%):'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载图像并对其进行归一化，使用`LabelBinarizer()`进行一热编码，并将数据拆分为训练集（80%）和测试集（20%）：
- en: '[PRE60]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Instantiate a pre-trained `VGG16`, without the top layers. Specify an input
    shape of 256x256x3:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个预训练的`VGG16`模型，去除顶部的全连接层。指定输入形状为256x256x3：
- en: '[PRE61]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Freeze all the layers in the base model. We are doing this because we don''t
    want to re-train them, but use their existing knowledge:'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 冻结基础模型中的所有层。我们这样做是因为我们不希望重新训练它们，而是使用它们已有的知识：
- en: '[PRE62]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Build the full network with a new set of layers on top using `build_network()`
    (defined in *Step 3*):'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`build_network()`（在*步骤 3*中定义）构建一个完整的网络，并在其上添加一组新层：
- en: '[PRE63]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Define the batch size and a set of augmentations to be applied through `ImageDataGenerator()`:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义批处理大小和一组要通过`ImageDataGenerator()`应用的增强方法：
- en: '[PRE64]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Warm up the network. This means we''ll only train the new layers (the rest
    are frozen) for 20 epochs, using **RMSProp** with a learning rate of 0.001\. Finally,
    we''ll evaluate the network on the test set:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预热网络。这意味着我们将只训练新添加的层（其余部分被冻结），训练20个周期，使用**RMSProp**优化器，学习率为0.001。最后，我们将在测试集上评估网络：
- en: '[PRE65]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Now that the network has been warmed up, we''ll fine-tune the final layers
    of the base model, specifically from the 16th onward (remember, zero-indexing),
    along with the fully connected layers, for 50 epochs, using **SGD** with a learning
    rate of 0.001:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，网络已经预热完毕，我们将微调基础模型的最终层，特别是从第16层开始（记住，索引从零开始），以及全连接层，训练50个周期，使用**SGD**优化器，学习率为0.001：
- en: '[PRE66]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: After warming up, the network achieved 81.6% accuracy on the test set. Then,
    when we fine-tuned it, after 50 epochs, the accuracy rose to 94.5% on the test
    set. We'll see how this all works in the next section.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在预热后，网络在测试集上的准确率达到了81.6%。然后，当我们进行了微调后，经过50个周期，测试集上的准确率提高到了94.5%。我们将在下一节看到这一过程的具体细节。
- en: How it works…
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We successfully harnessed the knowledge of a pre-trained **VGG16** on the massive
    ImageNet database. By replacing the top layers, which are fully connected and
    are in charge of the actual classification (the rest act as feature extractors),
    with our own set of deep layers suited to our problem, we managed to obtain a
    more than decent 94.5% accuracy on the test set.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们成功地利用了在庞大的ImageNet数据库上预训练的**VGG16**模型的知识。通过替换顶部的全连接层，这些层负责实际分类（其余部分充当特征提取器），我们使用自己的一组深度层来适应当前问题，从而在测试集上获得了超过94.5%的不错准确率。
- en: This result is a demonstration of the power of transfer learning, especially
    considering we only have 81 images per class in the dataset (81x17=1,377 in total),
    an insufficient amount for training a good performing deep learning model from
    scratch.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果展示了迁移学习的强大能力，特别是考虑到数据集中每个类别只有81张图片（81x17=1,377张图片），这对于从头开始训练一个表现良好的深度学习模型来说显然是不足够的。
- en: Tip
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Although not always required, when fine-tuning networks, it is a good idea to
    first *warm up* the *head* (the fully connected layers at the top) to give them
    time to get accustomed to the features coming from the pre-trained networks.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然并非总是必需的，但在微调网络时，最好先*热身*一下*头部*（顶部的全连接层），让它们有时间适应来自预训练网络的特征。
- en: See also
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'You can read more about Keras pre-trained models here: https://www.tensorflow.org/api_docs/python/tf/keras/applications.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里阅读更多关于Keras预训练模型的内容：https://www.tensorflow.org/api_docs/python/tf/keras/applications。
- en: Fine-tuning a network using TFHub
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TFHub微调网络
- en: One of the easiest ways to fine-tune a network is to rely on the wealth of pre-trained
    models that live in **TensorFlow Hub** (**TFHub**). In this recipe, we'll fine-tune
    a **ResNetV1152** feature extractor to classify flowers from a very small dataset.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 微调网络的最简单方法之一是依赖于**TensorFlow Hub**（**TFHub**）中丰富的预训练模型。在这个任务中，我们将微调一个**ResNetV1152**特征提取器，以便从一个非常小的数据集中分类花卉。
- en: Getting ready
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'We will need `tensorflow-hub` and `Pillow` for this recipe. Both can be installed
    easily, like this:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要`tensorflow-hub`和`Pillow`来完成这个任务。两者都可以很容易地安装，方法如下：
- en: '[PRE67]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'We''ll use a dataset known as `17 Category Flower Dataset`, which can be accessed
    at [http://www.robots.ox.ac.uk/~vgg/data/flowers/17](http://www.robots.ox.ac.uk/~vgg/data/flowers/17).
    I encourage you to get a re-organized copy of the data here: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/flowers17.zip](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/flowers17.zip).
    Download and decompress it in a location of your choosing. From now on, we''ll
    assume the data is in `~/.keras/datasets/flowers17`.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个名为`17类花卉数据集`的数据集，您可以通过[http://www.robots.ox.ac.uk/~vgg/data/flowers/17](http://www.robots.ox.ac.uk/~vgg/data/flowers/17)访问。建议你在这里获取数据的重组织版本：[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/flowers17.zip](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch3/recipe3/flowers17.zip)。下载并解压到您选择的位置。从现在开始，我们假设数据存储在`~/.keras/datasets/flowers17`。
- en: 'The following are some sample images from this dataset:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是该数据集的一些示例图片：
- en: '![Figure 3.6 – Example images'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.6 – 示例图片'
- en: '](img/B14768_03_006.jpg)'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_03_006.jpg)'
- en: Figure 3.6 – Example images
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6 – 示例图片
- en: Let's get started!
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: How to do it…
  id: totrans-260
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做……
- en: 'Follow these steps to successfully complete this recipe:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤成功完成这个任务：
- en: 'Import the required packages:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的包：
- en: '[PRE68]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Set the random seed:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置随机种子：
- en: '[PRE69]'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Define a function that will build a new network from a pre-trained model, where
    the top fully connected layer will be brand new and adapted to the number of categories
    in our data:'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，从预训练模型构建一个新的网络，其中顶部的全连接层将是全新的，并且会根据我们数据中的类别数量进行调整：
- en: '[PRE70]'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Define a function that will load the images and labels in the dataset as `NumPy`
    arrays:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，将数据集中的图片和标签加载为`NumPy`数组：
- en: '[PRE71]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Load the image paths and extract the set of classes from them:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载图片路径并从中提取类别集合：
- en: '[PRE72]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Load the images and normalize them, one-hot encode the labels with `LabelBinarizer()`,
    and split the data into subsets for training (80%) and testing (20%):'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载图片并进行归一化，使用`LabelBinarizer()`进行独热编码标签，然后将数据拆分为训练集（80%）和测试集（20%）：
- en: '[PRE73]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Instantiate a pre-trained `KerasLayer()` class, indicating an input shape of
    256x256x3:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个预训练的`KerasLayer()`类，指定输入形状为256x256x3：
- en: '[PRE74]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Make the base model untrainable:'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使基础模型不可训练：
- en: '[PRE75]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Build the full network while using the base model as a starting point:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在使用基础模型作为起点的基础上，构建完整的网络：
- en: '[PRE76]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Define the batch size and a set of augmentations to be applied through `ImageDataGenerator()`:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义批量大小以及通过`ImageDataGenerator()`应用的一组数据增强操作：
- en: '[PRE77]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Train the full model for 20 epochs and evaluate its performance on the test
    set:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练整个模型20个epoch，并评估其在测试集上的性能：
- en: '[PRE78]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: In a matter of minutes, we obtained a model with an accuracy of around 95.22%
    on the test set. Awesome, don't you think? Now, let's dive deeper.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 只需几分钟，我们就在测试集上获得了大约95.22%的准确率。太棒了，你不觉得吗？现在，让我们深入了解一下。
- en: How it works…
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: We leveraged the knowledge encoded in the pre-trained `17 Category Flower Dataset`.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用了预训练的`17类花卉数据集`中编码的知识。
- en: With just a quick top layer swap, we managed to obtain an impressive 95.22%
    accuracy on the test set, which is not a small feat, all constraints considered.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 通过简单地更换顶层，我们在测试集上达到了令人印象深刻的95.22%的准确率，考虑到所有的约束，这可是一个不小的成就。
- en: Unlike the *Fine-tuning a network using the Keras API* recipe, we didn't warm
    up the model's head this time. Again, this is not a hard rule, but yet another
    tool in our toolbox that we should try on a per-project basis.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 与*使用Keras API微调网络*的做法不同，这次我们没有对模型的头部进行预热。再次强调，这不是硬性规定，而是我们工具箱中的另一种方法，我们应该根据具体项目尝试使用。
- en: See also
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'You can read more about the pre-trained model we used in this recipe here:
    [https://tfhub.dev/google/imagenet/resnet_v1_152/feature_vector/4](https://tfhub.dev/google/imagenet/resnet_v1_152/feature_vector/4).'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里阅读更多关于我们在本教程中使用的预训练模型的信息：[https://tfhub.dev/google/imagenet/resnet_v1_152/feature_vector/4](https://tfhub.dev/google/imagenet/resnet_v1_152/feature_vector/4)。
