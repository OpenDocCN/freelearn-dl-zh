- en: Section 3 – Scaling and Tuning ML Works
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3节 – 扩展和调优机器学习工作
- en: Having covered how to set up a training job through various means of TensorFlow
    Enterprise model development, now is the time to scale the training process by
    using a cluster of GPUs or TPUs. You will learn how to leverage distributed training
    strategies and implement hyperparameter tuning to scale and improve your model
    training experiment.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在通过多种方式进行 TensorFlow 企业模型开发设置训练任务后，接下来是通过使用 GPU 或 TPU 集群来扩展训练过程。你将学习如何利用分布式训练策略，并实施超参数调优，以扩展并改进你的模型训练实验。
- en: In this part, you will learn about how to set up GPUs and TPUs in a GCP environment
    for submitting a model training job in GCP. You also will learn about the latest
    hyperparameter tuning API and run it at scale using GCP resources.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，你将学习如何在 GCP 环境中设置 GPU 和 TPU，以便提交模型训练任务。你还将了解最新的超参数调优 API，并利用 GCP 资源进行大规模运行。
- en: 'This section comprises the following chapters:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包括以下章节：
- en: '[*Chapter 5*](B16070_05_Final_JM_ePub.xhtml#_idTextAnchor145), *Training at
    Scale*'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第5章*](B16070_05_Final_JM_ePub.xhtml#_idTextAnchor145)，*大规模训练*'
- en: '[*Chapter 6*](B16070_06_Final_JM_ePub.xhtml#_idTextAnchor177), *Hyperparameter
    Tuning*'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B16070_06_Final_JM_ePub.xhtml#_idTextAnchor177)，*超参数调优*'
