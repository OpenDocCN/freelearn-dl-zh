- en: Transfer Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习
- en: In the previous chapter, we learned that a CNN consists of several layers. We
    also studied different CNN architectures, tuned different hyperparameters, and
    identified values for stride, window size, and padding. Then we chose a correct
    loss function and optimized it. We trained this architecture with a large volume
    of images. So, the question here is, how do we make use of this knowledge with
    a different dataset? Instead of building a CNN architecture and training it from
    scratch, it is possible to take an existing pre-trained network and adapt it to
    a new and different dataset through a technique called **transfer learning**. We
    can do so through feature extraction and fine tuning.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了卷积神经网络（CNN）由多个层组成。我们还研究了不同的CNN架构，调整了不同的超参数，并确定了步幅、窗口大小和填充的值。然后我们选择了一个合适的损失函数并进行了优化。我们用大量图像训练了这个架构。那么，问题来了，我们如何利用这些知识处理不同的数据集呢？与其从头构建CNN架构并进行训练，不如使用一个现有的预训练网络，通过一种叫做**迁移学习**的技术将其适配到新的不同数据集上。我们可以通过特征提取和微调来实现这一点。
- en: Transfer learning is the process of copying knowledge from an already trained
    network to a new network to solve similar problems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是将已经训练好的网络的知识复制到新网络中，以解决类似问题的过程。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Feature extraction approach
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征提取方法
- en: Transfer learning example
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迁移学习示例
- en: Multi-task learning
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多任务学习
- en: Feature extraction approach
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征提取方法
- en: In a feature extraction approach, we train only the top level of the network;
    the rest of the network remains fixed. Consider a feature extraction approach
    when the new dataset is relatively small and similar to the original dataset.
    In such cases, the higher-level features learned from the original dataset should
    transfer well to the new dataset.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在特征提取方法中，我们只训练网络的顶层；其余部分保持不变。当新的数据集相对较小且与原始数据集相似时，可以考虑采用特征提取方法。在这种情况下，从原始数据集中学到的高层次特征应能很好地迁移到新数据集。
- en: Consider a fine-tuning approach when the new dataset is large and similar to
    the original dataset. Altering the original weights should be safe because the
    network is unlikely to overfit the new, large dataset.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当新的数据集较大且与原始数据集相似时，可以考虑微调方法。修改原始权重是安全的，因为网络不太可能会对新的、大型数据集发生过拟合。
- en: 'Let us consider a pre-trained convolutional neural network, as shown in the
    following diagram. Using this we can study how the transfer of knowledge can be
    used in different situations:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个预训练的卷积神经网络，如下图所示。通过这个示例，我们可以研究如何在不同情况下使用知识迁移：
- en: '![](img/688a6ad3-849b-42f7-b371-4523211bfcbc.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/688a6ad3-849b-42f7-b371-4523211bfcbc.png)'
- en: 'When should we use transfer learning? Transfer learning can be applied in the
    following situations, depending on:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们什么时候使用迁移学习？迁移学习可以根据以下情况进行应用：
- en: The size of the new (target) dataset
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的（目标）数据集的大小
- en: Similarity between the original and target datasets
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始数据集和目标数据集之间的相似性
- en: 'There are four main use cases:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 主要有四种使用场景：
- en: '**Case 1**: New (target) dataset is small and is similar to the original training
    dataset'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例 1**：新的（目标）数据集较小，并且与原始训练数据集相似'
- en: '**Case 2**: New (target) dataset is small but is different from the original
    training dataset'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例 2**：新的（目标）数据集较小，但与原始训练数据集不同'
- en: '**Case 3**: New (target) dataset is large and is similar to the original training
    dataset'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例 3**：新的（目标）数据集较大，并且与原始训练数据集相似'
- en: '**Case 4**:New (target) dataset is large and is different from the original
    training dataset'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**案例 4**：新的（目标）数据集较大，并且与原始训练数据集不同'
- en: Let us now walk through each case in detail in the following sections.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们在接下来的章节中详细讲解每个案例。
- en: Target dataset is small and is similar to the original training dataset
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标数据集较小，并且与原始训练数据集相似
- en: 'If the target dataset is small and similar to the original dataset:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果目标数据集较小且与原始数据集相似：
- en: In this case, replace the last fully connected layer with a new fully connected
    layer that matches with the number of classes of the target dataset
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这种情况下，用一个新的全连接层替换最后一个全连接层，使其与目标数据集的类别数量匹配
- en: Initialize old weights with randomized weights
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用随机权重初始化旧的权重
- en: 'Train the network to update the weights of the new, fully connected layer:'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练网络以更新新的全连接层的权重：
- en: '![](img/daa1d1de-8117-4897-9afd-94588783b1d9.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/daa1d1de-8117-4897-9afd-94588783b1d9.png)'
- en: Transfer learning can be used as a strategy to avoid overfitting, especially
    when there is a small dataset.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 转移学习可以作为一种避免过拟合的策略，特别是在数据集较小的情况下。
- en: Target dataset is small but different from the original training dataset
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标数据集较小，但与原始训练数据集不同
- en: 'If the target dataset is small but of a different type to the original – for
    example, the original dataset is dog images and the new (target) dataset is flower
    images – then do the following:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果目标数据集较小，但与原始数据集类型不同——例如，原始数据集是狗的图像，而新的（目标）数据集是花卉的图像——那么应执行以下操作：
- en: Slice most of the initial layers of the network
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 切割网络的大部分初始层
- en: Add to the remaining pre-trained layers a new fully connected layer that matches
    the number of classes of the target dataset
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在其余的预训练层中添加一个新的全连接层，该层的节点数与目标数据集的类别数相匹配
- en: Randomize the weights of the new fully connected layer and freeze all the weights
    from the pre-trained network
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机化新全连接层的权重，并冻结预训练网络的所有权重
- en: Train the network to update the weights of the new fully connected layer
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练网络以更新新全连接层的权重
- en: 'Since the dataset is small, overfitting is still a concern here as well. To
    overcome this, we will keep the weights of the original pre-trained network the
    same and update only the weights of the new fully connected layer:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集较小，过拟合在这里仍然是一个问题。为了解决这个问题，我们将保持原始预训练网络的权重不变，只更新新全连接层的权重：
- en: '![](img/f7a1081a-47f5-4e46-937c-c84bf035dc03.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f7a1081a-47f5-4e46-937c-c84bf035dc03.png)'
- en: Only fine tune the higher level portion of the network. This is because the
    beginning layers are designed to extract more generic features. In general, the
    first layer of a convolutional neural network is not specific to a dataset.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 只需微调网络的高层部分。这是因为开始的层是用来提取更通用的特征的。通常，卷积神经网络的第一层并不特定于某个数据集。
- en: Target dataset is large and similar to the original training dataset
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标数据集较大并且与原始训练数据集相似
- en: 'Here we do not have an overfitting concern, as the dataset is large. So, in
    this case, we can retrain the entire network:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集很大，我们不需要担心过拟合。因此，在这种情况下，我们可以重新训练整个网络：
- en: Remove the last fully connected layer and replace it with a fully connected
    layer that matches the number of classes in the target dataset
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除最后一个全连接层，并用一个与目标数据集类别数匹配的全连接层替换它
- en: Randomly initialize the weights of this newly added, fully connected layer
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机初始化新添加的全连接层的权重
- en: Initialize the rest of the weights with pre-trained weights
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预训练的权重初始化其余的权重
- en: 'Train the entire network:'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练整个网络：
- en: '![](img/2df8e25a-0f59-43c8-85f6-4a9486cf6aa7.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2df8e25a-0f59-43c8-85f6-4a9486cf6aa7.png)'
- en: Target dataset is large and different from the original training dataset
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标数据集较大，并且与原始训练数据集不同
- en: 'If the target dataset is large and different from the original:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果目标数据集较大并且与原始数据集不同：
- en: Remove the last fully connected layer and replace it with a fully connected
    layer that matches the number of classes in the target dataset
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除最后一个全连接层，并用一个与目标数据集类别数匹配的全连接层替换它
- en: 'Train the entire network from scratch with randomly initialized weights:'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从头开始训练整个网络，并随机初始化权重：
- en: '![](img/76604751-43f7-4ae8-875d-66e44fa19053.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/76604751-43f7-4ae8-875d-66e44fa19053.png)'
- en: The `Caffe` library has ModelZoo, where one can share network weights.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`Caffe` 库有 ModelZoo，可以在其中共享网络权重。'
- en: Consider training from scratch when the dataset is large and completely different
    from the original dataset. In this case, we have enough data to train from scratch
    without the fear of overfitting. However, even in this case, it might be beneficial
    to initialize the entire network with pre-trained weights and fine tune it on
    the new dataset.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据集很大并且与原始数据集完全不同时，考虑从头开始训练。在这种情况下，我们有足够的数据来从头开始训练，而不必担心过拟合。然而，即便如此，使用预训练权重初始化整个网络并在新数据集上进行微调可能还是有益的。
- en: Transfer learning example
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转移学习示例
- en: 'In this example, we will take a pre-trained VGGNet and use transfer learning
    to train a CNN classifier that predicts dog breeds, given a dog image. Keras contains
    many pre-trained models, along with the code that loads and visualizes them. Another
    is a flower dataset that can be downloaded here. The Dog breed dataset has 133
    dog breed categories and 8,351 dog images. Download the Dog breed dataset here
    and copy it to your folder. VGGNet has 16 convolutional with pooling layers from
    beginning to end and three fully connected layers followed by a `softmax` function.
    Its main objective was to show how the depth of the network gives the best performance.
    It came from **Visual Geometric Group** (**VGG**) at Oxford. Their best performing
    network is VGG16\. The Dog breed dataset is relatively small and has a little
    overlap with the `imageNet` dataset. So, we can remove the last fully connected
    layer after the convolutional layer and replace it with our own. The weights of
    the convolutional layer are kept constant. An input image is passed through the
    convolutional layer and stops at the 16th layer:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将采用预训练的 VGGNet，并使用迁移学习训练一个 CNN 分类器，该分类器根据狗的图像预测狗的品种。Keras包含许多预训练模型，并提供加载和可视化这些模型的代码。另一个是可以在这里下载的花卉数据集。狗品种数据集有133个狗品种类别和8,351张狗的图像。请在这里下载狗品种数据集并将其复制到你的文件夹中。VGGNet
    从头到尾包含16层卷积池化层，以及三个全连接层，后接一个`softmax`函数。它的主要目标是展示网络深度如何带来最佳性能。它来自牛津的**视觉几何组**(**VGG**)。他们表现最佳的网络是
    VGG16。狗品种数据集相对较小，并与`imageNet`数据集有些重叠。所以我们可以去除卷积层之后的最后一个全连接层，并用我们自己的层替换它。卷积层的权重保持不变。输入图像通过卷积层并停留在第16层：
- en: '![](img/c6d97faf-9d6c-49ee-b829-2de1dd1da654.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6d97faf-9d6c-49ee-b829-2de1dd1da654.png)'
- en: VGGNet Architecture
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: VGGNet 架构
- en: We will use the bottleneck features of a pre-trained VGG16 network – such a
    network has already learned features from the `imageNet` dataset. Because the `imageNet`
    dataset already contains a few images of dogs, the VGG16 network model has already
    learned key features for classification. Similarly, other pre-trained CNN architectures
    can also be considered as an exercise to solve other image classification tasks.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用预训练的 VGG16 网络的瓶颈特征 —— 该网络已经从`imageNet`数据集中学习了特征。由于`imageNet`数据集已经包含了一些狗的图像，VGG16网络模型已学到了用于分类的关键特征。类似地，其他预训练的CNN架构也可以作为解决其他图像分类任务的练习。
- en: 'Download the `bottleneck_features` of VGG16 here, copy it to your own folder,
    and load it:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在此下载 VGG16的`bottleneck_features`，将其复制到你自己的文件夹中，然后加载：
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now define the model architecture:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在定义模型架构：
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Compile the model and train it:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 编译模型并训练：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Load the model and calculate the classification accuracy on the test set:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 加载模型并计算测试集上的分类准确度：
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Multi-task learning
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多任务学习
- en: In multi-task learning, transfer learning happens to be from one pre-trained
    model to many tasks simultaneously. For example, in self-driving cars, the deep
    neural network detects traffic signs, pedestrians, and other cars in front at
    the same time. Speech recognition also benefits from multi-task learning.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在多任务学习中，迁移学习是从一个预训练模型到多个任务的同时迁移。例如，在自动驾驶汽车中，深度神经网络同时检测交通标志、行人和前方的其他车辆。语音识别同样受益于多任务学习。
- en: Summary
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In a few specific cases, convolutional neural network architectures trained
    on images allow us to reuse learned features in a new network. The performance
    benefits of transferring features decrease the more dissimilar the base task and
    target task are. It is surprising to know that initializing a convolutional neural
    network with transferred features from almost any number of layers can produce
    a boost to generalization performance after fine-tuning to a new dataset.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些特定情况下，训练于图像上的卷积神经网络架构允许我们在新网络中重用已学到的特征。当基础任务和目标任务差异较大时，特征迁移的性能提升会减小。令人惊讶的是，几乎任何层数的卷积神经网络初始化，若采用转移过来的特征，在微调到新数据集后都能提升泛化性能。
