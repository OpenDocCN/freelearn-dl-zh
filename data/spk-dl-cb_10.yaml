- en: Face Recognition Using Deep Convolutional Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度卷积网络进行面部识别
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下几个教程：
- en: Downloading and loading the MIT-CBCL dataset into the memory
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载并将MIT-CBCL数据集加载到内存中
- en: Plotting and visualizing images from the directory
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从目录中绘制和可视化图像
- en: Preprocessing images
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像预处理
- en: Model building, training, and analysis
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型构建、训练和分析
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In today's world, the need to maintain the security of information is becoming
    increasingly important, as well as increasingly difficult. There are various methods
    by which this security can be enforced (passwords, fingerprint IDs, PIN numbers,
    and so on). However, when it comes to ease of use, accuracy, and low intrusiveness,
    face recognition algorithms have been doing very well. With the availability of
    high-speed computing and the evolution of deep convolutional networks, it has
    been made possible to further increase the robustness of these algorithms. They
    have gotten so advanced that they are now being used as the primary security feature
    in many electronic devices (for example, iPhoneX) and even banking applications.
    The goal of this chapter is to develop a robust, pose-invariant face recognition
    algorithm for use in security systems. For the purposes of this chapter, we will
    be using the openly available `MIT-CBCL` dataset of face images of 10 different
    subjects.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今世界，信息安全的维护变得越来越重要，同时也越来越困难。有多种方法可以加强这种安全性（如密码、指纹识别、PIN码等）。然而，在使用方便性、准确性和低干扰性方面，面部识别算法表现非常出色。随着高速计算的普及和深度卷积网络的发展，这些算法的鲁棒性得到了进一步提高。它们已经发展得如此先进，以至于现在在许多电子设备（例如iPhoneX）甚至银行应用中作为主要的安全特性。
    本章的目标是开发一个稳健的、对姿势不变的面部识别算法，用于安全系统。在本章中，我们将使用公开提供的`MIT-CBCL`数据集，其中包含10个不同主题的面部图像。
- en: Downloading and loading the MIT-CBCL dataset into the memory
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载并将MIT-CBCL数据集加载到内存中
- en: In this recipe, we will understand how to download the MIT-CBCL dataset and
    load it into the memory.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将了解如何下载MIT-CBCL数据集并将其加载到内存中。
- en: With a predicted worth of $15 billion by 2025, the biometrics industry is poised
    to grow like never before. Some of the examples of physiological characteristics
    used for biometric authentication include fingerprints, DNA, face, retina or ear
    features, and voice. While technologies such as DNA authentication and fingerprints
    are quite advanced, face recognition brings its own advantages to the table.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着到2025年预计价值达到150亿美元，生物识别行业正准备迎来前所未有的增长。一些用于生物识别认证的生理特征包括指纹、DNA、面部、视网膜或耳朵特征以及声音。虽然DNA认证和指纹技术已经相当先进，但面部识别也带来了其独特的优势。
- en: Ease of use and robustness due to recent developments in deep learning models
    are some of the driving factors behind face recognition algorithms gaining so
    much popularity.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于深度学习模型的最新发展，使用便捷性和鲁棒性是面部识别算法如此受欢迎的驱动因素之一。
- en: Getting ready
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The following key points need to be considered for this recipe:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下关键点需要在此教程中考虑：
- en: The `MIT-CBCL` dataset is composed of 3,240 images (324 images per subject).
    In our model, we will make arrangements to augment the data in order to increase
    model robustness. We will employ techniques such as shifting the subject, rotation,
    zooming, and shearing of the subject to obtain this augmented data.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MIT-CBCL` 数据集包含3,240张图片（每个主题324张图片）。在我们的模型中，我们将安排数据增强，以提高模型的鲁棒性。我们将采用诸如平移、旋转、缩放和剪切等技术来获得这些增强数据。'
- en: We will use 20% of the dataset to test our model (648 images) by randomly selecting
    these images from the dataset. Similarly, we randomly select 80% of the images
    in the dataset and use this as our training dataset (2,592 images).
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将使用20%的数据集来测试我们的模型（648张图片），通过从数据集中随机选择这些图片。类似地，我们随机选择数据集中80%的图片，并将其作为我们的训练数据集（2,592张图片）。
- en: The biggest challenge is cropping the images to the exact same size so that
    they can be fed into the neural network.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大的挑战是将图像裁剪成完全相同的大小，以便可以输入神经网络。
- en: It is a known fact that it is much easier to design a network when all the input
    images are of the same size. However, since some of the subjects in these images
    have a side profile or rotated/tilted profiles, we have to adapt our network to
    take input images of different sizes.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 众所周知，当所有输入图像的大小相同时，设计网络要容易得多。然而，由于这些图像中的一些主题有侧面或旋转/倾斜的侧面，我们必须调整我们的网络以接受不同大小的输入图像。
- en: How to do it...
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: The steps are as follows.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤如下。
- en: 'Download the `MIT-CBCL` dataset by visiting the FACE RECOGNITION HOMEPAGE,
    which contains a number of databases for face recognition experiments. The link,
    as well as a screenshot of the homepage, is provided as follows:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过访问 FACE RECOGNITION HOMEPAGE 下载 `MIT-CBCL` 数据集，其中包含多个用于人脸识别实验的数据库。以下提供了该主页的链接及截图：
- en: '[http://www.face-rec.org/databases/](http://www.face-rec.org/databases/):'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[http://www.face-rec.org/databases/](http://www.face-rec.org/databases/):'
- en: '![](img/dcf4205e-a1b1-4f44-8376-2232d9d0f29a.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dcf4205e-a1b1-4f44-8376-2232d9d0f29a.png)'
- en: 'Navigate down to the link that is named MIT-CBCL Face Recognition Database
    and click on it, as shown in the following screenshot:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到名为 MIT-CBCL 人脸识别数据库的链接并点击，如下图所示：
- en: '![](img/1519d67a-ca1b-4fde-9f75-b4ee218f11e5.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1519d67a-ca1b-4fde-9f75-b4ee218f11e5.png)'
- en: Once you have clicked on it, it will take you to a license page on which you
    are required to accept the license agreement and proceed to the download page.
    Once on the download page, click on `download now`. This downloads a zip file
    of about 116 MB. Go ahead and extract the contents into the working directory.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦点击它，您将进入一个许可页面，您需要接受许可协议并继续前往下载页面。在下载页面，点击 `download now`，下载一个约 116 MB 的 zip
    文件。然后解压该文件到工作目录中。
- en: How it works...
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The functionality is as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 功能如下：
- en: The license agreement requires the appropriate citation for the use of the database
    in any projects. This database was developed by the research team from the Massachusetts
    Institute of Technology.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 许可协议要求在任何项目中使用该数据库时进行适当引用。该数据库由麻省理工学院的研究团队开发。
- en: Credit is hereby given to the Massachusetts Institute of Technology and to the
    center for biological and computational learning for providing the database of
    facial images. The license also requires the mentioning of the paper titled *Component-based
    Face Recognition with 3D Morphable Models, First IEEE Workshop on Face Processing
    in Video,* Washington, D.C., 2004, B. Weyrauch, J. Huang, B. Heisele, and V. Blanz.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特此感谢麻省理工学院以及生物与计算学习中心提供的人脸图像数据库。许可协议还要求提及论文标题 *Component-based Face Recognition
    with 3D Morphable Models, First IEEE Workshop on Face Processing in Video,* Washington,
    D.C., 2004, B. Weyrauch, J. Huang, B. Heisele, 和 V. Blanz。
- en: 'The following screenshot describes the license agreement as well as the link
    to download the dataset:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下截图描述了许可协议以及下载数据集的链接：
- en: '![](img/9858e3c4-eb48-4590-92c2-bf365cc2a843.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9858e3c4-eb48-4590-92c2-bf365cc2a843.png)'
- en: Face Recognition Database Homepage
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸识别数据库主页
- en: Once the dataset is downloaded and extracted, you will see a folder titled MIT-CBCL-facerec-database.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并解压数据集后，您将看到一个名为 MIT-CBCL-facerec-database 的文件夹。
- en: 'For the purposes of this chapter, we will only be using the images in the **`training-synthetic`**
    folder, which contains all 3,240 images, as shown in the following screenshot:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于本章内容，我们只使用 **`training-synthetic`** 文件夹中的图像，该文件夹包含所有 3,240 张图像，如下图所示：
- en: '![](img/138da0da-a780-4240-a60e-2ff5f944cbd9.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/138da0da-a780-4240-a60e-2ff5f944cbd9.png)'
- en: There's more...
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'For this chapter, you will require the following libraries to be imported by
    Python:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容中，您需要通过 Python 导入以下库：
- en: '`os`'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`os`'
- en: '`matplotlib`'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib`'
- en: '`numpy`'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy`'
- en: '`keras`'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`keras`'
- en: '`TensorFlow`'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TensorFlow`'
- en: The following section of the chapter will deal with importing the necessary
    libraries and preprocessing the images before building the neural network model
    and loading them into it.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的以下部分将处理导入必要的库以及在构建神经网络模型并将其加载之前对图像进行预处理。
- en: See also
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'For complete information on the packages used in this chapter, visit the following
    links:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 有关本章中使用的包的完整信息，请访问以下链接：
- en: '[https://matplotlib.org/](https://matplotlib.org/)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://matplotlib.org/](https://matplotlib.org/)'
- en: '[https://docs.python.org/2/library/os.html](https://docs.python.org/2/library/os.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://docs.python.org/2/library/os.html](https://docs.python.org/2/library/os.html)'
- en: '[https://www.tensorflow.org/get_started/](https://www.tensorflow.org/get_started/)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.tensorflow.org/get_started/](https://www.tensorflow.org/get_started/)'
- en: '[https://keras.io/layers/about-keras-layers/](https://keras.io/layers/about-keras-layers/)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://keras.io/layers/about-keras-layers/](https://keras.io/layers/about-keras-layers/)'
- en: '[https://docs.scipy.org/doc/numpy-1.9.1/reference/](https://docs.scipy.org/doc/numpy-1.9.1/reference/)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://docs.scipy.org/doc/numpy-1.9.1/reference/](https://docs.scipy.org/doc/numpy-1.9.1/reference/)'
- en: Plotting and visualizing images from the directory
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从目录中绘制和可视化图像
- en: This section will describe how to read and visualize the downloaded images before
    they are preprocessed and fed into the neural network for training. This is an
    important step in this chapter because the images need to be visualized to get
    a better understanding of the image sizes so they can be accurately cropped to
    omit the background and preserve only the necessary facial features.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将描述如何在图像被预处理并输入神经网络进行训练之前，读取和可视化下载的图像。这是本章的重要步骤，因为需要可视化图像，以便更好地理解图像的大小，从而准确裁剪去除背景，仅保留必要的面部特征。
- en: Getting ready
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Before beginning, complete the initial setup of importing the necessary libraries
    and functions as well as setting the path of the working directory.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，完成导入必要库和函数的初始设置，并设置工作目录的路径。
- en: How to do it...
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The steps are as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤如下：
- en: 'Download the necessary libraries using the following lines of code. The output
    must result in a line that says `Using TensorFlow backend`, as shown in the screenshot
    that follows:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码行下载所需的库。输出应该显示一行 `Using TensorFlow backend`，如接下来的截图所示：
- en: '[PRE0]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The importing of the libraries is as shown:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 库的导入如图所示：
- en: '![](img/22238e64-6ac9-41c1-b103-7c46992e285e.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/22238e64-6ac9-41c1-b103-7c46992e285e.png)'
- en: 'Print and set the current working directory as shown in the following screenshot.
    In our case, the desktop was set as the working directory:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印并设置当前工作目录，如下图所示。在我们的例子中，桌面被设置为工作目录：
- en: '![](img/06db13f8-4651-4e03-9bba-45a894469c1a.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/06db13f8-4651-4e03-9bba-45a894469c1a.png)'
- en: 'Read all the images directly from the folder by using the commands illustrated
    in the following screenshot:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用下图所示的命令，直接从文件夹中读取所有图像：
- en: '![](img/e1bdd972-61a3-4a30-8463-afff8c8f6d86.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e1bdd972-61a3-4a30-8463-afff8c8f6d86.png)'
- en: 'Print a few random images from the dataset using the `plt.imshow (images[])`
    command, as shown in the following screenshots, to get a better idea of the face
    profiles in the images. This will also give an idea of the size of the image,
    which will be required at a later stage:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `plt.imshow(images[])` 命令打印数据集中的一些随机图像，如下图所示，以便更好地了解图像中的面部轮廓。这也有助于了解图像的大小，后续步骤中需要用到：
- en: '![](img/22170372-8478-4b66-a6ba-646c59aed38b.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/22170372-8478-4b66-a6ba-646c59aed38b.png)'
- en: Shown here are the images of different test subjects from the first image.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里展示的是来自第一张图片的不同测试对象的图像。
- en: '![](img/b7fd9236-5600-4f17-80c0-f1882d6d528f.png)![](img/4165425e-c59f-4eb3-bb12-457e8f5026ce.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b7fd9236-5600-4f17-80c0-f1882d6d528f.png)![](img/4165425e-c59f-4eb3-bb12-457e8f5026ce.png)'
- en: '![](img/895e8032-8b1c-4c90-944e-f3b210adc0af.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/895e8032-8b1c-4c90-944e-f3b210adc0af.png)'
- en: How it works...
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: 'The functionality is as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 功能如下：
- en: The `mypath` variable sets the path to read all the files from. The `training-synthetic`
    folder is specified in this step, as only the files in this folder are going to
    be used for this chapter.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`mypath` 变量设置了读取所有文件的路径。在这一步中，指定了 `training-synthetic` 文件夹，因为本章将只使用该文件夹中的文件。'
- en: The `onlyfiles` variable is used in order to count all the files under the folder
    whose path is provided in the previous step by looping through all the files contained
    in the folder. This will be required in the next step for reading and storing
    the images.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`onlyfiles` 变量用于计算在前一步提供的文件夹路径下的所有文件，通过遍历文件夹中的所有文件。这将在下一步中用于读取和存储图像。'
- en: The `images` variable is used to create an empty array of size 3,240 in order
    to store the images, which are all 200 x 200-pixels.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`images` 变量用于创建一个大小为 3,240 的空数组，用于存储图像，这些图像的大小为 200 x 200 像素。'
- en: Next, by looping through all the files using the `onlyfiles` variable as an
    argument in the for loop, each image contained in the folder is read and stored
    into the previously defined `images` array using the `matplotlib.image` function.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，通过在 for 循环中使用 `onlyfiles` 变量作为参数遍历所有文件，读取文件夹中包含的每个图像，并使用 `matplotlib.image`
    函数将其存储到之前定义的 `images` 数组中。
- en: Finally, on printing randomly chosen images by specifying different indices
    of the images you will notice that each image is a 200 x 200-pixel array and each
    subject may either be facing forward or rotated between zero and fifteen degrees
    on either side.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，通过指定不同的图像索引打印随机选择的图像时，您会注意到每张图像是一个200 x 200像素的数组，每个主体可能正面朝向，或者在左右两侧之间旋转零至十五度。
- en: There's more...
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'The following points are of note:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下几点需要注意：
- en: An interesting feature of this database is that the fourth digit of each filename
    describes which subject is in the respective image.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个数据库的一个有趣特征是，每个文件名的第四个数字描述了该图像中的主体。
- en: The names of the images are unique in the sense that the fourth digit represents
    the individual in the respective image. Two examples of image names are `0001_-4_0_0_60_45_1.pgm` and
    `0006_-24_0_0_0_75_15_1.pgm`. One can easily understand that the fourth digits
    represent the second and seventh individual respectively.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像的名称是唯一的，第四个数字表示该图像中的个人。两个图像名称的例子是`0001_-4_0_0_60_45_1.pgm`和`0006_-24_0_0_0_75_15_1.pgm`。可以很容易地理解，第四个数字分别代表第二个和第七个个体。
- en: We will need to store this information for later use while making predictions.
    This will help the neural network during training by knowing what subject's facial
    features it is learning.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要为后续预测存储这些信息。这将帮助神经网络在训练时知道它正在学习哪个主体的面部特征。
- en: 'The filenames of each image can be read into an array, and each of the ten
    subjects can be segregated by using the following lines of code:'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个图像的文件名可以读入一个数组中，并且通过以下代码行，可以将十个主体分开：
- en: '[PRE1]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The preceding code will initialize an empty one-dimensional `numpy` array of
    size 3,240 (the number of images in the `training-synthetic` folder) and store
    the relevant subjects in different arrays by looping through the whole set of
    files.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上述代码将初始化一个大小为3,240的空一维`numpy`数组（`training-synthetic`文件夹中的图像数量），并通过循环遍历整个文件集，将相关的主体存储在不同的数组中。
- en: The `if` statements are basically checking what the fourth digit is under each
    filename and storing that digit in the initialized `numpy` array.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`if`语句基本上是在检查每个文件名中的第四个数字，并将该数字存储在已初始化的`numpy`数组中。'
- en: 'The output in the iPython notebook for the same is shown in the following screenshot:'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下截图显示了iPython笔记本中的输出：
- en: '![](img/4a2396a6-3cea-4144-a3f4-c3089ae3beb7.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4a2396a6-3cea-4144-a3f4-c3089ae3beb7.png)'
- en: See also
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'The following blog describes a method of cropping images in Python and can
    be used for image preprocessing which will be required in the following section:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 以下博客描述了一种在 Python 中裁剪图像的方法，可以用于图像预处理，这在接下来的章节中会用到：
- en: '[https://www.blog.pythonlibrary.org/2017/10/03/how-to-crop-a-photo-with-python/](https://www.blog.pythonlibrary.org/2017/10/03/how-to-crop-a-photo-with-python/)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.blog.pythonlibrary.org/2017/10/03/how-to-crop-a-photo-with-python/](https://www.blog.pythonlibrary.org/2017/10/03/how-to-crop-a-photo-with-python/)'
- en: 'More information about the Adam Optimizer and its use cases can be found by
    visiting the following links:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Adam优化器及其使用案例的更多信息，可以通过访问以下链接找到：
- en: '[https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)'
- en: '[https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)'
- en: '[https://www.coursera.org/lecture/deep-neural-network/adam-optimization-algorithm-w9VCZ](https://www.coursera.org/lecture/deep-neural-network/adam-optimization-algorithm-w9VCZ)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.coursera.org/lecture/deep-neural-network/adam-optimization-algorithm-w9VCZ](https://www.coursera.org/lecture/deep-neural-network/adam-optimization-algorithm-w9VCZ)'
- en: Preprocessing images
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像预处理
- en: In the previous section, you may have noticed how all the images are not a front
    view of the face profiles, and that there are also slightly rotated side profiles.
    You may also have noticed some unnecessary background areas in each image that
    needs to be omitted. This section will describe how to preprocess and handle the
    images so that they are ready to be fed into the network for training.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，您可能已经注意到，并非所有图像都是面部的正面视图，还有些略微旋转的侧面轮廓。您可能还注意到每张图像中有些不必要的背景区域需要去除。本节将描述如何预处理和处理图像，使其准备好输入到网络中进行训练。
- en: Getting ready
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'Consider the following:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 请考虑以下内容：
- en: A lot of algorithms are devised to crop the significant part of an image; for
    example, SIFT, LBP, Haar-cascade filter, and so on.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有许多算法被设计用来裁剪图像的显著部分；例如，SIFT、LBP、Haar-cascade滤波器等等。
- en: We will, however, tackle this problem with a very simplistic naïve code to
    crop the facial portion from the image. This is one of the novelties of this algorithm.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，我们将通过一个非常简单的朴素代码来解决这个问题，从图像中裁剪出面部部分。这是这个算法的一大创新。
- en: We have found that the pixel intensity of the unnecessary background part is
    28.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们发现不必要的背景部分的像素强度为28。
- en: Remember that each image is a three-channel matrix of 200 x 200-pixels. This
    means that every image contains three matrices or Tensors of red, green, and blue
    pixels with an intensity ranging from 0 to 255.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记住，每个图像都是一个200 x 200像素的三通道矩阵。这意味着每个图像包含三个矩阵或张量，分别代表红色、绿色和蓝色的像素，强度范围从0到255。
- en: Therefore, we will discard any row or column of the images that contain only
    28s as the pixel intensities.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，我们将丢弃任何包含仅为28的像素强度的图像的行或列。
- en: We will also make sure that all the images have the same pixel size after the
    cropping action to achieve the highest parallelizability of the convolutional
    neural network.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还将确保在裁剪操作后，所有图像都具有相同的像素大小，以实现卷积神经网络的最高并行化能力。
- en: How to do it...
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'The steps are as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤如下：
- en: 'Define the `crop()` function to crop images to obtain only the significant
    part, as shown in the following lines of code:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`crop()`函数来裁剪图像，只保留显著部分，如以下代码所示：
- en: '[PRE2]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Use the following lines of code to loop through every image in the folder and
    crop it using the preceding defined function:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码行循环遍历文件夹中的每个图像，并使用前面定义的函数裁剪它：
- en: '[PRE3]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, randomly choose an image and print it to check that it has been cropped
    from a 200 x 200 sized image to a different size. We have chosen image 23 in our
    case. This can be done using the following lines of code:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，随机选择一张图像并打印出来，检查它是否已经从200 x 200大小的图像裁剪为不同的尺寸。我们在这个案例中选择了图像23。可以使用以下代码行完成此操作：
- en: '[PRE4]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, split the data into a test and train set using `80%` of the images in
    the folder as the training set and the remaining `20% `as the test set. This can
    be done with the following commands:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将数据拆分为测试集和训练集，使用文件夹中的`80%`图像作为训练集，剩余的`20%`作为测试集。可以使用以下命令完成此操作：
- en: '[PRE5]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once the data has finished splitting, segregate the training and test images
    using the following commands:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦数据完成拆分，使用以下命令将训练图像和测试图像分开：
- en: '[PRE6]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, reshape all the cropped images into sizes of 128 x 150, since this is
    the size that is to be fed into the neural network. This can be done using the
    following commands:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将所有裁剪后的图像调整为128 x 150的大小，因为这是要输入神经网络的大小。可以使用以下命令完成此操作：
- en: '[PRE7]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Once the data is done reshaping, convert it into `float32` type, which will
    make it easier to handle in the next step when it is normalized. Converting from
    int to float32 can be done using the following commands:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦数据完成调整形状，将其转换为`float32`类型，这将使得在下一个步骤进行归一化时更容易处理。从int类型转换为float32类型可以使用以下命令：
- en: '[PRE8]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'After reshaping and converting the data into the float32 type, it has to be
    normalized in order to adjust all the values to a similar scale. This is an important
    step in preventing data redundancy. Perform normalization using the following
    commands:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在重新调整形状并将数据转换为float32类型后，必须对其进行归一化，以便将所有值调整到相似的尺度。这是防止数据冗余的一个重要步骤。使用以下命令进行归一化：
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The final step is to convert the reshaped, normalized images into vectors,
    as this is the only form of input the neural network understands. Convert the
    images into vectors using the following commands:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一步是将调整形状并归一化后的图像转换为向量，因为这是神经网络能够理解的唯一输入形式。使用以下命令将图像转换为向量：
- en: '[PRE10]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: How it works...
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The functionality is as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 功能如下：
- en: 'The `crop()` function executes the following tasks:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`crop()`函数执行以下任务：'
- en: Multiplies all pixels with an intensity of 28 with a numpy array of 1s and stores
    in variable `a`.
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有强度为28的像素与一个全是1的numpy数组相乘，并存储在变量`a`中。
- en: Checks for all instances where an entire column consists of only pixel intensities
    of 28 and stores in variable `b`.
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查所有完全由像素强度为28的列组成的实例，并将其存储在变量`b`中。
- en: Deletes all columns (or *Y* axes) where pixel intensities are 28 for the entire
    column.
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除所有列（或*Y*轴），如果整个列的像素强度都是28。
- en: Plots the resulting image.
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制结果图像。
- en: Transposes the image in order to perform the preceding set of operations on
    all the rows (or *X* axes) in a similar manner.
  id: totrans-132
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转置图像，以便在所有行（或*X*轴）上执行前述一系列操作。
- en: Multiplies all pixels with an intensity of 28 with a `numpy` array of 1s and
    stores in variable `d`.
  id: totrans-133
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有像素强度为28的像素与1的`numpy`数组相乘，并将其存储在变量`d`中。
- en: Checks for all instances where an entire column consists of only pixel intensities
    of 28 and stores in variable `e`.
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查所有实例，其中整列仅由像素强度为28的像素组成，并将其存储在变量`e`中。
- en: Deletes all columns (from the transposed image) where pixel intensities are
    28 for the entire column.
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除所有列（来自转置图像），其中整列的像素强度为28。
- en: Transposes the image to get back the original image.
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转置图像，以恢复原始图像。
- en: Prints the shape of the image.
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印图像的形状。
- en: Wherever a pixel intensity of less than 29 is found, replaces those pixel intensities
    with zeros, which will result in the cropping of all those pixels by making them
    white.
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每当发现像素强度小于29时，将这些像素的强度替换为零，这将通过将它们变为白色来裁剪所有这些像素。
- en: Plots the resulting image.
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制结果图像。
- en: Reshapes the resulting image to a size of 150 x 128 pixels.
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将结果图像的尺寸调整为150 x 128像素。
- en: 'The output for the `crop()` function, as seen on the Jupyter notebook during
    execution, is shown in the following screenshot:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`crop()`函数的输出，如在Jupyter Notebook执行期间所见，展示在以下截图中：'
- en: '![](img/b7bfb81b-bb1a-4f8d-ace1-6a3350b8b618.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b7bfb81b-bb1a-4f8d-ace1-6a3350b8b618.png)'
- en: 'Next, the defined `crop()` function is applied to all the files contained in
    the `training-synthetic` folder by looping through every file. This will result
    in an output as shown in the following screenshots:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，定义的`crop()`函数将应用于`training-synthetic`文件夹中包含的所有文件，通过遍历每个文件。这将导致如下所示的输出：
- en: '![](img/659f69f2-71dc-47c8-a41d-8abaff1fbbce.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/659f69f2-71dc-47c8-a41d-8abaff1fbbce.png)'
- en: 'The output continues as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 输出继续如下：
- en: '![](img/33234eb4-b5c5-4825-a908-9b1a5f58455a.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/33234eb4-b5c5-4825-a908-9b1a5f58455a.png)'
- en: Notice that only the relevant facial features are preserved and the resulting
    shapes of all the cropped images are less than 200 x 200, which was the initial
    size.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，只有相关的面部特征被保留下来，所有裁剪后的图像的尺寸都小于200 x 200，这是最初的尺寸。
- en: On printing the image and shape of any random image, you will notice that every
    image is now resized to a 150 x 128-pixel array, and you will see the following
    output:![](img/82830a1d-393e-4620-9e03-fefd30f652fd.png)
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在打印任意图像及其形状时，你会注意到每个图像现在都已调整为150 x 128像素的数组，你将看到以下输出：![](img/82830a1d-393e-4620-9e03-fefd30f652fd.png)
- en: Splitting the images into test and train sets as well as segregating them into
    variables named `x_train`, `y1_train`, `x_test`, and `y1_test` will result in
    the output shown in the following screenshot:![](img/b6480e9c-aed7-44ed-aebf-d18dbfcfb3f2.png)
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像拆分为测试集和训练集，并将其划分为命名为`x_train`、`y1_train`、`x_test`和`y1_test`的变量，将得到以下截图所示的输出：![](img/b6480e9c-aed7-44ed-aebf-d18dbfcfb3f2.png)
- en: 'Segregating the data is done as follows:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据的分隔如下进行：
- en: '![](img/a8dbcce6-9e1e-495d-b135-e87c64fe5c58.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a8dbcce6-9e1e-495d-b135-e87c64fe5c58.png)'
- en: Reshaping the training and test images and converting the data type to float32
    will result in the output seen in the following screenshot:![](img/3ee9a218-e25c-4f53-bcfc-631ea9dc78ea.png)
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新调整训练和测试图像的形状，并将数据类型转换为float32，结果如以下截图所示：![](img/3ee9a218-e25c-4f53-bcfc-631ea9dc78ea.png)
- en: There's more...
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'Consider the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 请考虑以下内容：
- en: Once the images are done preprocessing they still need to be normalized and
    converted into vectors (in this case tensors) before being fed into the network.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦图像完成预处理，它们仍然需要标准化并转换为向量（在这种情况下是张量），然后才能输入到网络中。
- en: Normalization, in the simplest case, means adjusting values measured on different
    scales to a notionally common scale, often prior to averaging. It is always a
    good idea to normalize data in order to prevent gradients from exploding or vanishing
    as seen in the vanishing and exploding gradient problems during gradient descent.
    Normalization also ensures there is no data redundancy.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准化，在最简单的情况下，意味着将不同尺度上测量的值调整为一个公认的共同尺度，通常是在平均化之前。标准化数据始终是个好主意，因为它可以防止在梯度下降过程中出现梯度爆炸或消失问题，如梯度消失和爆炸问题所示。标准化还确保没有数据冗余。
- en: Normalization of the data is done by dividing each pixel in each image by `255`
    since the pixel values range between 0 and `255`. This will result in the output
    shown in the following screenshot:![](img/cfeaed2d-a914-4816-aecf-05d58a71e66b.png)
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据归一化是通过将每张图像中的每个像素值除以`255`来完成的，因为像素值范围是从0到`255`。这将产生如下所示的输出：![](img/cfeaed2d-a914-4816-aecf-05d58a71e66b.png)
- en: 'Next, the images are converted to input vectors with ten different classes
    using the `to_categorical()` function from `numpy_utils`, as shown in the following
    screenshot:'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，使用来自`numpy_utils`的`to_categorical()`函数，将图像转换为具有十个不同类别的输入向量，如下图所示：
- en: '![](img/4dc71bb9-c7cb-4cba-bae7-f2c5d78246e9.png)'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/4dc71bb9-c7cb-4cba-bae7-f2c5d78246e9.png)'
- en: See also
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'Additional resources are as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 其他资源如下：
- en: 'For more information on data normalization, check the following link:'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关数据归一化的更多信息，请查看以下链接：
- en: '[https://www.quora.com/What-is-normalization-in-machine-learning](https://www.quora.com/What-is-normalization-in-machine-learning)'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://www.quora.com/What-is-normalization-in-machine-learning](https://www.quora.com/What-is-normalization-in-machine-learning)'
- en: 'For information on overfitting and why data is split into test and training
    sets, visit the following link:'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关过拟合以及为什么数据需要分成测试集和训练集的更多信息，请访问以下链接：
- en: '[https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)'
- en: 'For more information on encoding variables and their importance, visit the
    following link:'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关编码变量及其重要性的更多信息，请访问以下链接：
- en: '[http://pbpython.com/categorical-encoding.html](http://pbpython.com/categorical-encoding.html)'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[http://pbpython.com/categorical-encoding.html](http://pbpython.com/categorical-encoding.html)'
- en: Model building, training, and analysis
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型构建、训练和分析
- en: We will use a standard sequential model from the `keras` library to build the
    CNN. The network will consist of three convolutional layers, two maxpooling layers,
    and four fully connected layers. The input layer and the subsequent hidden layers
    have 16 neurons, while the maxpooling layers contain a pool size of (2,2). The
    four fully connected layers consist of two dense layers and one flattened layer
    and one dropout layer. Dropout 0.25 was used to reduce the overfitting problem.
    Another novelty of this algorithm is the use of data augmentation to fight the
    overfitting phenomenon. Data augmentation is carried by rotating, shifting, shearing,
    and zooming the images to different extents to fit the model.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`keras`库中的标准顺序模型来构建CNN。该网络将包括三层卷积层、两层最大池化层和四层全连接层。输入层和后续的隐藏层有16个神经元，而最大池化层的池大小为(2,2)。四个全连接层由两层密集层、一层展平层和一层丢弃层组成。使用丢弃率0.25来减少过拟合问题。这个算法的另一个创新之处在于使用数据增强来对抗过拟合现象。数据增强通过旋转、平移、剪切和缩放图像到不同程度来适应模型。
- en: The `relu` function is used as the activation function in both the input and
    hidden layers, while the `softmax` classifier is used in the output layer to classify
    the test images based on the predicted output.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '`relu`函数作为输入层和隐藏层的激活函数，而`softmax`分类器则用于输出层，以根据预测输出对测试图像进行分类。'
- en: Getting ready
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备开始
- en: 'The network which will be constructed can be visualized as shown in the following
    diagram:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 将要构建的网络可以通过下图进行可视化：
- en: '![](img/93d4ebf3-1c06-4776-b868-dc7838a9294f.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/93d4ebf3-1c06-4776-b868-dc7838a9294f.png)'
- en: How to do it...
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The steps are as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤如下：
- en: 'Define the model using the `Sequential()` function in the Keras framework using
    the following commands:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令，在Keras框架中使用`Sequential()`函数定义模型：
- en: '[PRE11]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Print the summary of the model to get a better understanding of how the model
    is built and to ensure that it is built as per the preceding specifications. This
    can be done by using the `model.summary()` command.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印模型的摘要，以便更好地理解模型的构建方式，并确保它按照前面的规格构建。这可以通过使用`model.summary()`命令来完成。
- en: 'Next, compile the model using the following command:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用以下命令编译模型：
- en: '[PRE12]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In order to prevent overfitting and improve model accuracy further, implement
    some form of data augmentation. In this step, the images will be sheared, shifted
    on a horizontal as well as the vertical axis, zoomed in, and rotated. The ability
    of the model to learn and identify these anomalies will dictate how robust the
    model is. Augment the data using the following commands:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了防止过拟合并进一步提高模型的准确性，实现某种形式的数据增强。在此步骤中，图像将进行剪切、水平和垂直轴上的平移、缩放和旋转。模型学习并识别这些异常的能力将决定模型的鲁棒性。使用以下命令对数据进行增强：
- en: '[PRE13]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Finally, fit and evaluate the model after data augmentation using the following
    commands:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，使用以下命令在数据增强后拟合和评估模型：
- en: '[PRE14]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: How it works...
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The functionality is as follows:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 功能如下：
- en: 'By using the sequential function, a nine-layer convolutional neural network
    is defined with each layer performing the following functions:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用顺序函数，定义了一个九层的卷积神经网络，每一层执行以下功能：
- en: The first layer is a convolutional layer with 16 neurons and performs convolution
    on the input tensor/matrix. The size of the feature map is defined to be a 3 x
    3 matrix. The input shape needs to be specified for the first layer since the
    neural network needs to know what type of input to expect. Since all the images
    have been cropped to a size of 128 x 150 pixels, this will be the input shape
    defined for the first layer of the network as well. The activation function used
    in this layer is a **rectified linear unit** (**relu**).
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一层是一个卷积层，具有16个神经元，并对输入张量/矩阵进行卷积。特征图的大小定义为3 x 3的矩阵。需要为第一层指定输入形状，因为神经网络需要知道期望的输入类型。由于所有图像已被裁剪为128
    x 150像素的大小，因此这也将是定义第一层输入形状的标准。该层使用的激活函数是**修正线性单元**（**relu**）。
- en: The second layer of the network (first hidden layer) is another convolution
    layer with 16 neurons as well. Again, a `relu` will be used as the activation
    function for this layer.
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络的第二层（第一个隐藏层）是另一个卷积层，同样包含16个神经元。此层的激活函数也将使用`relu`。
- en: The third layer of the network (second hidden layer) is a max pooling layer
    with a pool size of 2 x 2\. The function of this layer is to extract all the valid
    features learned by performing convolution in the first two layers and reducing
    the size of the matrix with all the learned features. Convolution is nothing but
    a matrix multiplication between the feature map and the input matrix (in our case,
    an image). The resulting values, which form the convolution process, are stored
    by the network in a matrix. The maximum values from these stored values will define
    a certain feature in the input image. These maximum values are what will be preserved
    by the max pooling layer, which will omit the non-relevant features.
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络的第三层（第二个隐藏层）是一个最大池化层，池化大小为2 x 2。该层的功能是提取通过前两层卷积学习到的所有有效特征，并减少包含所有学习到的特征的矩阵的大小。卷积不过是特征图和输入矩阵之间的矩阵乘法（在我们的例子中是图像）。形成卷积过程的结果值会被网络存储在矩阵中。这些存储值中的最大值将定义输入图像中的某个特征。最大池化层将保留这些最大值，并丢弃与之无关的特征。
- en: The fourth layer of the network (third hidden layer) is another convolutional
    layer with a feature map of 3 x 3 again. The activation function used in this
    layer will again be a `relu` function.
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络的第四层（第三个隐藏层）是另一个卷积层，特征图大小再次为3 x 3。该层使用的激活函数仍然是`relu`函数。
- en: The fifth layer of the network (fourth hidden layer) is a max pooling layer
    with a pool size of 2 x 2.
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络的第五层（第四个隐藏层）是一个最大池化层，池化大小为2 x 2。
- en: The sixth layer of the network (fifth hidden layer) is a flatten layer that
    will convert the matrix containing all the learned features (stored in the form
    of numbers) into a single row instead of a multi-dimensional matrix.
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络的第六层（第五个隐藏层）是一个展平层，将包含所有学习到的特征（以数字形式存储）的矩阵转换为单行，而不是多维矩阵。
- en: The seventh layer in the network (sixth hidden layer) is a dense layer with
    512 neurons and a `relu` activation. Each neuron will basically process a certain
    weight and bias, which is nothing but a representation of all the learned features
    from a particular image. This is done in order to easily classify the image by
    using a `softmax` classifier on the dense layer.
  id: totrans-194
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络中的第七层（第六个隐藏层）是一个具有512个神经元的全连接层，并使用`relu`激活函数。每个神经元基本上会处理某个权重和偏置，这只是对特定图像所学习到的所有特征的表示。这样做是为了通过在全连接层上使用`softmax`分类器，轻松对图像进行分类。
- en: The eighth layer in the network (seventh hidden layer) is a dropout layer with
    a dropout probability of 0.25 or 25%. This layer will randomly `dropout` 25% of
    the neurons during the training process and help prevent overfitting by encouraging
    the network to learn a given feature using many alternative paths.
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络中的第八层（第七个隐藏层）是一个丢弃层，丢弃概率为0.25或25%。该层将在训练过程中随机`dropout` 25%的神经元，并通过鼓励网络使用多条替代路径来学习给定特征，从而帮助防止过拟合。
- en: The final layer in the network is a dense layer with just 10 neurons and the
    `softmax` classifier. This is the eighth hidden layer and will also serve as the
    output layer of the network.
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络中的最终层是一个密集层，只有10个神经元和`softmax`分类器。这是第八个隐藏层，也将作为网络的输出层。
- en: 'The output after defining the model must look like the one in the following
    screenshot:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义模型后的输出应该类似以下截图：
- en: '![](img/84106f1b-84f4-4055-8308-7482d1c56abc.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/84106f1b-84f4-4055-8308-7482d1c56abc.png)'
- en: On printing the `model.summary()` function, you must see an output like the
    one in the following screenshot:![](img/b68373e3-00ab-4a55-83cd-b797ac325262.png)
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印`model.summary()`函数时，您必须看到类似以下截图的输出：![](img/b68373e3-00ab-4a55-83cd-b797ac325262.png)
- en: 'The model is compiled using categorical crossentropy, which is a function to
    measure and compute the loss from the network while transferring information from
    one layer to the subsequent layers. The model will make use of the `Adam()` optimizer
    function from the Keras framework, which will basically dictate how the network
    optimizes the weights and biases while learning the features. The output of the
    `model.compile()` function must look like the following screenshot:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该模型使用类别交叉熵（categorical crossentropy）进行编译，这是一个衡量和计算网络损失的函数，用于在层与层之间传递信息。模型将使用Keras框架中的`Adam()`优化器函数，该函数将基本决定网络在学习特征时如何优化权重和偏差。`model.compile()`函数的输出应该类似以下截图：
- en: '![](img/f159955e-5e31-47ef-89bc-ee6d45165b31.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f159955e-5e31-47ef-89bc-ee6d45165b31.png)'
- en: 'Since the neural network is quite dense and the number of total images is only
    3,240, we devise a method to prevent overfitting. This is done by generating more
    images from the training set by performing data augmentation. In this step, the
    images are generated through the `ImageDataGenerator()` function. This function
    takes the training and test sets and augments images by:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于神经网络相当密集，并且总图像数量仅为3,240，我们设计了一种方法来防止过拟合。通过执行数据增强，从训练集生成更多图像来实现这一点。在此步骤中，图像通过`ImageDataGenerator()`函数生成。此函数将训练集和测试集作为输入，通过以下方式增强图像：
- en: Rotating them
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旋转它们
- en: Shearing them
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 剪切它们
- en: Shifting the width, which is basically widening the images
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 水平平移图像，实际上就是扩宽图像
- en: Shifting the images on a horizontal axis
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在水平方向上平移图像
- en: Shifting the images on a vertical axis
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在垂直方向上平移图像
- en: 'The output of the preceding function must look like the following screenshot:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的函数的输出应该类似以下截图：
- en: '![](img/dbfa63f1-cb81-4f83-a17b-4e7356ad096e.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dbfa63f1-cb81-4f83-a17b-4e7356ad096e.png)'
- en: 'Finally, the model is fitted to the data and evaluated after training over
    5 epochs. The output we obtained is shown in the following screenshot:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，模型在训练5个epoch后被拟合到数据并评估。我们得到的输出如以下截图所示：
- en: '![](img/92f8e4d9-e9f4-4c41-bf72-f6ad2cb50118.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](img/92f8e4d9-e9f4-4c41-bf72-f6ad2cb50118.png)'
- en: As you can see, we obtained an accuracy of 98.46%, which resulted in an error
    rate of 1.54%. This is pretty good, but convolutional networks have advanced so
    much that we can improve this error rate by tuning a few hyperparameters or using
    a deeper network.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如您所见，我们获得了98.46%的准确率，导致了1.54%的误差率。这个结果相当不错，但卷积网络已经取得了很大进展，我们可以通过调优一些超参数或使用更深的网络来改善这个误差率。
- en: There's more...
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Using a deeper CNN with 12 layers (one extra convolution and one extra max
    pooling layer) resulted in an improvement of accuracy to 99.07%, as shown in the
    following screenshot:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 使用更深的CNN，增加了12层（多了一层卷积层和一层最大池化层），将准确率提升至99.07%，如以下截图所示：
- en: '![](img/44198743-7e72-4c9d-a09f-48339f26cebf.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](img/44198743-7e72-4c9d-a09f-48339f26cebf.png)'
- en: 'Using data normalization after every two layers during model building, we were
    further able to improve the accuracy to 99.85%, as shown in the following screenshot:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在每两层后使用数据归一化，进一步提高了准确率，达到了99.85%，如以下截图所示：
- en: '![](img/72303ea6-b9b5-4037-978c-64b9e1812be1.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](img/72303ea6-b9b5-4037-978c-64b9e1812be1.png)'
- en: 'You may obtain different results, but feel free to run the training step a
    few times. The following are some of the steps you can take to experiment with
    the network in the future to understand it better:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会得到不同的结果，但可以多次运行训练步骤。以下是一些你可以在未来进行实验的步骤，以更好地理解网络：
- en: Try to tune hyperparameters better and implement a higher dropout percentage
    and see how the network responds.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试更好地调整超参数，并实施更高的丢弃率，看看网络如何响应。
- en: The accuracy greatly reduced when we tried using different activation functions
    or a smaller (less dense) network.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们尝试使用不同的激活函数或较小（较稀疏）的网络时，准确性大幅下降。
- en: Also, change the size of the feature maps and max pooling layer and see how
    this influences training time and model accuracy.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同时，改变特征图和最大池化层的大小，观察这如何影响训练时间和模型准确性。
- en: Try including more neurons in a less dense CNN and tune it to improve accuracy.
    This may also result in a faster network that trains in less time.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试在一个较稀疏的卷积神经网络中增加更多的神经元，并调整它以提高准确性。这也可能导致更快的网络，在更短的时间内完成训练。
- en: Use more training data. Explore other online repositories and find larger databases
    to train the network. Convolutional neural networks usually perform better when
    the size of the training data is increased.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用更多的训练数据。探索其他在线仓库，找到更大的数据库来训练网络。卷积神经网络通常在训练数据量增大时表现更好。
- en: See also
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'The following published papers are good resources to obtain a better understanding
    of convolutional neural networks. They may be used as further reading in order
    to gain more understanding of various applications of convolutional neural networks:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 以下已发布的论文是了解卷积神经网络的好资源。它们可以作为进一步阅读材料，帮助你更深入地了解卷积神经网络在各类应用中的应用：
- en: '[http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)'
- en: '[https://arxiv.org/abs/1408.5882](https://arxiv.org/abs/1408.5882)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/abs/1408.5882](https://arxiv.org/abs/1408.5882)'
- en: '[https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.pdf](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.pdf)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.pdf](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.pdf)'
- en: '[http://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/pdfs/Simard.pdf](http://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/pdfs/Simard.pdf)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/pdfs/Simard.pdf](http://www.cs.cmu.edu/~bhiksha/courses/deeplearning/Fall.2016/pdfs/Simard.pdf)'
- en: '[https://dl.acm.org/citation.cfm?id=2807412](https://dl.acm.org/citation.cfm?id=2807412)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://dl.acm.org/citation.cfm?id=2807412](https://dl.acm.org/citation.cfm?id=2807412)'
- en: '[https://ieeexplore.ieee.org/abstract/document/6165309/](https://ieeexplore.ieee.org/abstract/document/6165309/)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://ieeexplore.ieee.org/abstract/document/6165309/](https://ieeexplore.ieee.org/abstract/document/6165309/)'
- en: '[http://openaccess.thecvf.com/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://openaccess.thecvf.com/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf](http://openaccess.thecvf.com/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf)'
- en: '[http://www.aaai.org/ocs/index.php/IJCAI/IJCAI11/paper/download/3098/3425](http://www.aaai.org/ocs/index.php/IJCAI/IJCAI11/paper/download/3098/3425)'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.aaai.org/ocs/index.php/IJCAI/IJCAI11/paper/download/3098/3425](http://www.aaai.org/ocs/index.php/IJCAI/IJCAI11/paper/download/3098/3425)'
- en: '[https://ieeexplore.ieee.org/abstract/document/6288864/](https://ieeexplore.ieee.org/abstract/document/6288864/)'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://ieeexplore.ieee.org/abstract/document/6288864/](https://ieeexplore.ieee.org/abstract/document/6288864/)'
