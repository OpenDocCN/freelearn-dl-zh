- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: '*Deep Learning with TensorFlow and Keras, Third Edition*, is a concise yet
    thorough introduction to modern neural networks, artificial intelligence, and
    deep learning technologies designed especially for software engineers and data
    scientists. The book is the natural follow-up of the books *Deep Learning with
    Keras* [1] and *TensorFlow 1.x Deep Learning Cookbook* [2] previously written
    by the same authors.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*深度学习与 TensorFlow 和 Keras，第3版* 是一本简明而全面的现代神经网络、人工智能和深度学习技术的介绍，专为软件工程师和数据科学家设计。本书是之前由同一作者编写的
    *深度学习与 Keras* [1] 和 *TensorFlow 1.x 深度学习实用手册* [2] 的自然延续。'
- en: This book provides a very detailed panorama of the evolution of learning technologies
    over the past six years. The book presents dozens of working deep neural networks
    coded in Python using TensorFlow 2.x, a modular network library based on Keras-like
    APIs [1].
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书提供了过去六年间学习技术演变的非常详细的全景图。书中展示了使用 TensorFlow 2.x 编写的几十个深度神经网络，这是一种基于 Keras 风格
    API 的模块化网络库 [1]。
- en: '**Artificial Intelligence** (**AI**) lays the ground for everything this book
    discusses. **Machine Learning** (**ML**) is a branch of AI, and **Deep Learning**
    (**DL**) is in turn a subset of ML. This section will briefly discuss these three
    concepts, which you will regularly encounter throughout the rest of this book.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能**（**AI**）为本书讨论的所有内容奠定了基础。**机器学习**（**ML**）是人工智能的一个分支，而**深度学习**（**DL**）又是机器学习的一个子集。本节将简要讨论这三个概念，您将在本书的其余部分中经常遇到它们。'
- en: AI denotes any activity where machines mimic intelligent behaviors typically
    shown by humans. More formally, it is a research field in which machines aim to
    replicate cognitive capabilities such as learning behaviors, proactive interaction
    with the environment, inference and deduction, computer vision, speech recognition,
    problem-solving, knowledge representation, and perception. AI builds on elements
    of computer science, mathematics, and statistics, as well as psychology and other
    sciences studying human behaviors. There are multiple strategies for building
    AI. During the 1970s and 1980s, “expert” systems became extremely popular. The
    goal of these systems was to solve complex problems by representing the knowledge
    with a large number of manually defined if-then rules. This approach worked for
    small problems on very specific domains, but it was not able to scale up for larger
    problems and multiple domains. Later, AI focused more and more on methods based
    on statistical methods that are part of ML.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能指的是机器模仿通常由人类展示的智能行为的任何活动。更正式地说，它是一个研究领域，旨在让机器复制认知能力，如学习行为、与环境的主动互动、推理和推断、计算机视觉、语音识别、问题解决、知识表示和感知。人工智能建立在计算机科学、数学、统计学，以及心理学和其他研究人类行为的科学的基础上。构建人工智能有多种策略。在20世纪70年代和80年代，“专家”系统变得非常流行。这些系统的目标是通过使用大量手动定义的“如果-那么”规则来表示知识，进而解决复杂问题。这种方法在特定领域的小问题中有效，但无法扩展到更大规模的问题和多个领域。后来，人工智能越来越多地转向基于统计方法的机器学习方法。
- en: 'ML is a subdiscipline of AI that focuses on teaching computers how to learn
    without the need to be programmed for specific tasks. The key idea behind ML is
    that it is possible to create algorithms that learn from, and make predictions
    on, data. There are three different broad categories of ML:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）是人工智能的一个子学科，专注于教会计算机如何学习，而无需为特定任务编写程序。机器学习背后的核心理念是，可以创建从数据中学习并进行预测的算法。机器学习有三种不同的广泛类别：
- en: '**Supervised learning**, in which the machine is presented with input data
    and the desired output, and the goal is to learn from those training examples
    in such a way that meaningful predictions can be made for data that the machine
    has never observed before.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**，其中机器会接收输入数据和期望的输出，目标是从这些训练样本中学习，以便对机器从未见过的数据做出有意义的预测。'
- en: '**Unsupervised learning**, in which the machine is presented with input data
    only, and the machine has to subsequently find some meaningful structure by itself,
    with no external supervision or input.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**，其中机器只接收输入数据，机器随后必须自己找到某些有意义的结构，没有外部监督或输入。'
- en: '**Reinforcement learning**, in which the machine acts as an agent, interacting
    with the environment. The machine is provided with “rewards” for behaving in a
    desired manner, and “penalties” for behaving in an undesired manner. The machine
    attempts to maximize rewards by learning to develop its behavior accordingly.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习**，在这种学习方式中，机器作为一个代理与环境进行交互。机器会根据预期的行为给予“奖励”，而不期望的行为则会受到“惩罚”。机器通过学习如何调整自己的行为来最大化奖励。'
- en: DL took the world by storm in 2012\. During that year, the ImageNet 2012 challenge
    was launched with the goal of predicting the content of photographs using a subset
    of a large hand-labeled dataset. A deep learning model named AlexNet achieved
    a top-5 error rate of 15.3%, a significant improvement with respect to previous
    state-of-the-art results. According to the Economist, *Suddenly people started
    to pay attention, not just within the AI community but across the technology industry
    as a whole*.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在2012年席卷全球。那一年，ImageNet 2012挑战赛启动，目标是通过一个大型人工标注数据集的子集来预测照片的内容。一种名为AlexNet的深度学习模型在此挑战中达到了15.3%的Top-5错误率，相比之前的最新技术成果取得了显著提升。据《经济学人》报道，*突然间，人们开始关注这个领域，不仅仅是人工智能社区，整个技术行业都开始关注它*。
- en: That was only the beginning. Today, DL techniques are successfully applied in
    heterogeneous domains including, but not limited to, healthcare, environment,
    green energy, computer vision, text analysis, multimedia, finance, retail, gaming,
    simulation, industry, robotics, and self-driving cars. In each of these domains,
    DL techniques can solve problems with a level of accuracy that was not possible
    using previous methods.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这仅仅是个开始。今天，深度学习技术已经成功应用于众多不同的领域，包括但不限于医疗、环境、绿色能源、计算机视觉、文本分析、多媒体、金融、零售、游戏、模拟、工业、机器人和自动驾驶汽车。在这些领域中，深度学习技术能够解决的问题，准确度远超过以往的方法。
- en: Looking back at the past eight years, it is fascinating and exciting to see
    the extent of the contributions that DL has made to science and industry. There
    is no reason to believe that the next eight years will see any less contribution;
    indeed, as the field of DL continues to advance, we anticipate that we’ll see
    even more exciting and fascinating contributions provided by DL.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾过去的八年，深度学习（DL）对科学和工业的贡献令人着迷且振奋人心。没有理由相信接下来的八年里，深度学习的贡献会减少；事实上，随着深度学习领域的不断进步，我们预期会看到深度学习带来更多令人兴奋和迷人的贡献。
- en: This book introduces you to the magic of deep learning. We will start with simple
    models and progressively will introduce increasingly sophisticated models. The
    approach will always be hands-on, with a healthy dose of code to work with.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将带你进入深度学习的魔力世界。我们将从简单的模型开始，逐步介绍越来越复杂的模型。整个过程将始终以实践为主，配以适量的代码供你操作。
- en: Who this book is for
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书适合人群
- en: If you are a data scientist with experience in ML or an AI programmer with some
    exposure to neural networks, you will find this book a useful entry point to DL
    with TensorFlow. If you are a software engineer with a growing interest in the
    DL tsunami, you will find this book a foundational platform to broaden your knowledge
    on the topic. Basic knowledge of Python is required for this book.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一个有机器学习经验的数据科学家，或是一个接触过神经网络的人工智能程序员，那么你会发现本书是一个很好的深度学习入门书籍。如果你是一个对深度学习浪潮日益感兴趣的软件工程师，本书将为你提供一个扎实的基础，帮助你拓宽相关知识。阅读本书需要具备一定的Python基础。
- en: What this book covers
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书内容涵盖
- en: '*Chapter 1*, *Neural Network Foundations with TF*, is where we learn the basics
    of TensorFlow, an open-source library developed by Google for machine learning
    and deep learning. In addition, we introduce the basics of neural networks and
    deep learning, two areas of machine learning that had incredible growth during
    the last few years. The idea behind this chapter is to provide all the tools needed
    to do basic but fully hands-on deep learning.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '*第1章*，*使用TensorFlow的神经网络基础*，我们将在这里学习TensorFlow的基础知识，这是Google为机器学习和深度学习开发的开源库。此外，我们还将介绍神经网络和深度学习的基础知识，这两者是近几年在机器学习领域取得巨大进展的方向。本章的目标是提供进行基础但完全实践的深度学习所需的所有工具。'
- en: '*Chapter 2*, *Regression and Classification*, focuses on the fundamental tasks
    in ML techniques: regression and classification. We will learn how to use TensorFlow
    to build simple, multiple, and multivariate regression models. We will use logistic
    regression to solve a multi-class classification problem.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*第2章*，*回归与分类*，集中讲解机器学习技术中的基本任务：回归和分类。我们将学习如何使用TensorFlow构建简单的单变量、多变量回归模型。我们还将使用逻辑回归解决多类别分类问题。'
- en: '*Chapter 3*, *Convolutional Neural Networks*, covers how to use deep learning
    ConvNets for recognizing MNIST handwritten characters with high accuracy. We use
    the CIFAR 10 dataset to build a deep learning classifier with 10 categories, and
    the ImageNet dataset to build an accurate classifier with 1,000 categories. In
    addition, we investigate how to use large deep learning networks such as VGG16
    and very deep networks such as InceptionV3\. We will conclude with a discussion
    on transfer learning'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*第3章*，*卷积神经网络*，讲解了如何使用深度学习卷积神经网络（ConvNets）高精度地识别MNIST手写字符。我们使用CIFAR 10数据集构建一个包含10个类别的深度学习分类器，并使用ImageNet数据集构建一个包含1,000个类别的高精度分类器。此外，我们还研究了如何使用大型深度学习网络，如VGG16，以及非常深的网络，如InceptionV3。最后，我们将讨论迁移学习。'
- en: '*Chapter 4*, *Word Embeddings*, is where we describe the origins of and theory
    behind distributed representations and word embeddings and chart the progress
    of word embeddings from static word-based embeddings more dynamic and expressive
    embeddings based on sentences and paragraphs. We also explore how the idea of
    word embeddings can be extended to include non-word sequences as well, such as
    nodes in a graph or user sessions in a web application. The chapter also contains
    multiple examples of using word embeddings of various kinds.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*第4章*，*词向量*，描述了分布式表示和词向量的起源与理论，并描绘了从静态的基于词的词向量到更动态且富有表现力的基于句子和段落的词向量的进展。我们还探讨了如何将词向量的理念扩展到包括非词序列，例如图中的节点或Web应用中的用户会话。本章还包含了多种类型的词向量使用示例。'
- en: '*Chapter 5*, *Recurrent Neural Networks*, describes an important architectural
    subclass of neural networks that are optimized for handling sequence data such
    as natural language or time series. We describe the important architectures in
    this genre, such as **LSTM** (**Long Short-Term Memory**) and **GRU** (**Gated
    Recurrent Unit**) and show how they can be extended to handle bidirectional states
    and states across batches. We also provide examples of using RNNs with various
    topologies for specific tasks, such as generating text, sentiment analysis, and
    part-of-speech tagging. We also describe the popular seq2seq architecture, which
    uses a pair of RNNs in an encoder-decoder pipeline to solve a variety of NLP tasks.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*第5章*，*递归神经网络*，描述了一个重要的神经网络架构子类，专门用于处理序列数据，如自然语言或时间序列。我们将介绍该领域的重要架构，例如**LSTM**（**长短期记忆网络**）和**GRU**（**门控递归单元**），并展示如何将它们扩展以处理双向状态和跨批次的状态。我们还提供了使用不同拓扑结构的RNN的示例，用于特定任务，如文本生成、情感分析和词性标注。我们还描述了流行的seq2seq架构，该架构使用一对RNN在编码器-解码器管道中解决多种NLP任务。'
- en: '*Chapter 6*, *Transformers*, covers transformers, a deep learning architecture
    that has revolutionized the traditional natural language processing field. We
    start by reviewing the key intuitions behind the architecture and various categories
    of transformers, together with a deep dive into the most popular models. Then,
    we focus on implementations both based on the vanilla architecture and on popular
    libraries, such as Hugging Face and TensorFlow Hub. After that, we briefly discuss
    evaluation, optimization, and some of the best practices commonly adopted when
    using transformers. The last section is devoted to reviewing how transformers
    can be used to perform computer vision tasks, a totally different domain from
    NLP. That requires a careful definition of the attention mechanism. In the end,
    attention is all you need! And at the core of attention, there is nothing more
    than the cosine similarity between vectors.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*第6章*，*变压器*，讲解了变压器，这是一种深度学习架构，彻底改变了传统的自然语言处理领域。我们首先回顾了该架构背后的关键直觉和各种变压器类别，并深入分析最流行的模型。接着，我们重点讨论了基于原始架构和流行库（如Hugging
    Face和TensorFlow Hub）的实现。之后，我们简要讨论了评估、优化以及使用变压器时常见的最佳实践。最后一部分专门讨论了如何将变压器应用于计算机视觉任务，这是一个与NLP完全不同的领域，这需要仔细定义注意力机制。最终，注意力就是你所需要的！而在注意力的核心，除了向量之间的余弦相似度，别无他物。'
- en: '*Chapter 7*, *Unsupervised Learning*, delves into unsupervised learning models.
    It will cover techniques required for clustering and dimensionality reduction
    like PCA, k-means, and self-organized maps. It will go into the details of Boltzmann
    machines and their implementation using TensorFlow. The concepts covered will
    be extended to build **Restricted Boltzmann Machines** (**RBMs**).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*第7章*，*无监督学习*，深入探讨无监督学习模型。将涵盖聚类和降维所需的技术，如PCA、k-means和自组织映射。还将详细讲解玻尔兹曼机及其在TensorFlow中的实现。所涵盖的概念将进一步扩展，构建**限制玻尔兹曼机**（**RBMs**）。'
- en: '*Chapter 8*, *Autoencoders*, describes autoencoders, a class of neural networks
    that attempt to recreate the input as its target. It will cover different varieties
    of autoencoders like sparse autoencoders, convolutional autoencoders, and denoising
    autoencoders. The chapter will train a denoising autoencoder to remove noise from
    input images. It will demonstrate how autoencoders can be used to create MNIST
    digits. It will also cover the steps involved in building an LSTM autoencoder
    to generate sentence vectors. Finally, we will learn how to build a variational
    autoencoder to generate images.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '*第8章*，*自编码器*，描述了自编码器，这是一类神经网络，试图将输入重建为目标。将介绍不同种类的自编码器，如稀疏自编码器、卷积自编码器和去噪自编码器。该章将训练一个去噪自编码器，从输入图像中去除噪声。将演示如何使用自编码器创建MNIST数字。还将介绍构建LSTM自编码器以生成句子向量的步骤。最后，我们将学习如何构建变分自编码器来生成图像。'
- en: '*Chapter 9*, *Generative Models*, focuses on **Generative Adversarial Networks**
    (**GANs**). We start with the first proposed GAN model and use it to forge MNIST
    characters. The chapter shows you how to use deep convolutional GANs to create
    celebrity images. The chapter discusses the various GAN architectures like SRGAN,
    InfoGAN, and CycleGAN. The chapter covers a range of cool GAN applications. Finally,
    the chapter concludes with a TensorFlow implementation of CycleGAN to convert
    winter-summer images.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*第9章*，*生成模型*，聚焦于**生成对抗网络**（**GANs**）。我们从第一个提出的GAN模型开始，利用它生成MNIST字符。该章展示了如何使用深度卷积GAN创建名人图像。还讨论了各种GAN架构，如SRGAN、InfoGAN和CycleGAN。该章介绍了各种有趣的GAN应用。最后，章节以TensorFlow实现的CycleGAN来转换冬夏图像作结。'
- en: '*Chapter 10*, *Sel**f-Supervised Learning*, provides an overview of various
    strategies used for self-supervised learning in computer vision, audio, and natural
    language processing. It covers self-prediction through strategies such as autoregressive
    generation, masked generation, relationship prediction, and hybrids of these approaches.
    It also covers contrastive learning, a popular technique for self-supervised learning,
    and its application to various pretext tasks in various application domains.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*第10章*，*自监督学习*，概述了在计算机视觉、音频和自然语言处理领域中用于自监督学习的各种策略。涵盖了通过自回归生成、掩码生成、关系预测等策略进行自预测，及其混合方法。还将介绍对比学习，这是一种流行的自监督学习技术，并将其应用于各种预设任务中的不同领域。'
- en: '*Chapter 11*, *Reinforcement Learning*, focuses on reinforcement learning,
    covering the Q-learning algorithm and the Bellman equation. The chapter covers
    discounted rewards, exploration and exploitation, and discount factors. It explains
    policy-based and model-based reinforcement learning. We will build a **Deep Q-learning
    Network** (**DQN**) to play an Atari game. And finally, we learn how to train
    agents using the policy gradient algorithm.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*第11章*，*强化学习*，聚焦于强化学习，涵盖Q学习算法和贝尔曼方程。该章讨论了折扣奖励、探索与开发、以及折扣因子。它解释了基于策略和基于模型的强化学习。我们将构建**深度Q学习网络**（**DQN**）来玩Atari游戏。最后，我们将学习如何使用策略梯度算法训练智能体。'
- en: '*Chapter 12*, *Probabilistic TensorFlow*, introduces TensorFlow Probability,
    the library built over TensorFlow to perform probabilistic reasoning and statistical
    analysis. The chapter demonstrates how to use TensorFlow Probability to generate
    synthetic data. We will build Bayesian networks and perform inference. The chapter
    also introduces the concept of uncertainty, aleatory and epistemic, and how to
    calculate the uncertainty of your trained models.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*第12章*，*概率TensorFlow*，介绍了TensorFlow Probability，这是一个建立在TensorFlow之上的库，用于执行概率推理和统计分析。该章演示了如何使用TensorFlow
    Probability生成合成数据。我们将构建贝叶斯网络并进行推理。该章还介绍了不确定性、偶然性和认知不确定性的概念，并讲解如何计算训练模型的不确定性。'
- en: '*Chapter 13*, *An Introduction to AutoML*, introduces AutoML, whose goal is
    to enable domain experts who are unfamiliar with machine learning technologies
    to use ML techniques easily. We will go through a practical exercise using Google
    Cloud Platform and do quite a bit of hands-on work after briefly discussing the
    fundamentals. The chapter covers automatic data preparation, automatic feature
    engineering, and automatic model generation. Then, we introduce AutoKeras and
    Google Cloud AutoML with its multiple solutions for table, vision, text, translation,
    and video processing.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*第13章*，*AutoML简介*，介绍了AutoML，其目标是让那些不熟悉机器学习技术的领域专家也能轻松使用ML技术。我们将在简要讨论基础知识后，进行一个使用Google
    Cloud Platform的实操练习，并做大量的动手操作。该章节涵盖了自动数据准备、自动特征工程和自动模型生成。然后，我们将介绍AutoKeras和Google
    Cloud AutoML，它提供了多种针对表格、视觉、文本、翻译和视频处理的解决方案。'
- en: '*Chapter 14*, *The Math Behind Deep Learning*, covers the math behind deep
    learning. This topic is quite advanced and not necessarily required for practitioners.
    However, it is recommended reading to understand what is going on “under the hood”
    when we play with neural networks. We start with a historical introduction, and
    then we will review the high school concept of derivatives and gradients and introduce
    the gradient descent and backpropagation algorithms commonly used to optimize
    deep learning networks.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*第14章*，*深度学习背后的数学*，讲解了深度学习背后的数学原理。这个话题相当高级，并不一定是从业者所必需的。然而，作为了解我们在操作神经网络时“引擎盖下”发生了什么的推荐阅读，它非常重要。我们从历史背景介绍开始，然后复习高中时学过的导数和梯度的概念，并介绍梯度下降法和反向传播算法，这两种通常用于优化深度学习网络的算法。'
- en: '*Chapter 15*, *Tensor Processing Unit*, discusses TPUs. TPUs are very special
    ASIC chips developed at Google for executing neural network mathematical operations
    in an ultra-fast manner. The core of the computation is a systolic multiplier
    that computes multiple dot products (row * column) in parallel, thus accelerating
    the computation of basic deep learning operations. Think of a TPU as a special-purpose
    co-processor for deep learning that is focused on matrix or tensor operations.
    We will review the four generations of TPUs so far, plus an additional Edge TPU
    for IoT.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*第15章*，*张量处理单元*，讨论了TPU。TPU是Google开发的专用ASIC芯片，用于以超快的速度执行神经网络的数学运算。其计算核心是一个流水线乘法器，可以并行计算多个点积（行
    * 列），从而加速基本深度学习操作的计算。可以把TPU看作是专门用于深度学习的协处理器，专注于矩阵或张量运算。我们将回顾迄今为止的四代TPU，以及针对物联网的Edge
    TPU。'
- en: '*Chapter 16*, *Other Useful Deep Learning Libraries*, introduces other deep
    learning frameworks. We will explore Hugging Face, OpenAI’s GPT3, and DALL-E 2\.
    The chapter introduces another very popular deep learning framework, PyTorch.
    We also cover H2O.ai and its AutoML module. The chapter also briefly discusses
    the ONNX open-source format for deep learning models.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*第16章*，*其他有用的深度学习库*，介绍了其他深度学习框架。我们将探索Hugging Face、OpenAI的GPT-3和DALL-E 2。该章节还介绍了另一种非常流行的深度学习框架——PyTorch。我们还会讨论H2O.ai及其AutoML模块。章节最后简要讨论了ONNX深度学习模型的开源格式。'
- en: '*Chapter 17*, *Graph Neura**l Networks*, introduces graphs and graph machine
    learning, with particular emphasis on graph neural networks and the popular **Deep
    Graph Library** (**DGL**). We describe the theory behind various commonly used
    graph layers used in GNNs (and available in DGL) and provide examples of GNNs
    used for node classification, link prediction, and graph classification. We also
    show how to work with your own graph dataset and customize graph layers to create
    novel GNN architectures. We then cover more cutting-edge advances in the field
    of Graph ML, such as heterogeneous graphs and temporal graphs.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*第17章*，*图神经网络*，介绍了图和图机器学习，特别强调了图神经网络和流行的**深度图库**（**DGL**）。我们描述了在图神经网络中常用的各种图层的理论（以及DGL中可用的图层），并提供了用于节点分类、链接预测和图分类的GNN示例。我们还展示了如何使用自己的图数据集并定制图层来创建新的GNN架构。接着，我们将讨论图机器学习领域的一些前沿进展，例如异构图和时序图。'
- en: '*Chapter 18*, *Machine Learning Best Practices*, focuses on strategies and
    practices to follow to get the best model in training and production. The chapter
    discusses the best practices from two different perspectives: the best practices
    for the data and the best practices with respect to models.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*第18章*，*机器学习最佳实践*，关注在训练和生产过程中获取最佳模型的策略和实践。该章节从两个不同的角度讨论最佳实践：数据最佳实践和模型最佳实践。'
- en: '*Chapter 19*, *TensorFlow 2 Ecosystem*, lays out the different components of
    the TensorFlow ecosystem. We introduce TensorFlow Hub, a repository for pretrained
    deep learning models. The chapter talks about TensorFlow Datasets – a collection
    of ready-to-use datasets. We will also talk about TensorFlow Lite and TensorFlow
    JS – the framework for mobile and embedded systems and the web. Finally, the chapter
    talks about federated learning, a decentralized machine learning framework.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*第19章*，*TensorFlow 2生态系统*，介绍了TensorFlow生态系统的不同组件。我们介绍了TensorFlow Hub，这是一个用于预训练深度学习模型的仓库。章节还讨论了TensorFlow
    Datasets —— 一个现成数据集的集合。我们还将讨论TensorFlow Lite和TensorFlow JS —— 针对移动和嵌入式系统以及Web的框架。最后，本章介绍了联邦学习，一种去中心化的机器学习框架。'
- en: '*Chapter 20*, *Advanced Convolutional Neural Networks*, shows more advanced
    uses for **convolutional neural networks** (**CNNs**). We will explore how CNNs
    can be applied within the areas of computer vision, video, textual documents,
    audio, and music. We’ll conclude with a section summarizing convolution operations.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*第20章*，*高级卷积神经网络*，展示了**卷积神经网络**（**CNNs**）的更多高级应用。我们将探索如何在计算机视觉、视频、文本文档、音频和音乐等领域应用CNN。最后，我们将总结卷积操作的部分内容。'
- en: Download the example code files
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: The code bundle for the book is hosted on GitHub at [https://packt.link/dltf](https://packt.link/dltf).
    We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的代码包托管在GitHub上，地址为[https://packt.link/dltf](https://packt.link/dltf)。我们还有来自丰富书籍和视频目录的其他代码包，您可以在[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)找到。快来看看吧！
- en: Download the color images
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下载彩色图像
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [https://static.packt-cdn.com/downloads/9781803232911_ColorImages.pdf](https://static.packt-cdn.com/downloads/9781803232911_ColorImages.pdf).'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一个PDF文件，包含本书中使用的截图/图表的彩色图像。您可以在此下载：[https://static.packt-cdn.com/downloads/9781803232911_ColorImages.pdf](https://static.packt-cdn.com/downloads/9781803232911_ColorImages.pdf)。
- en: Conventions used
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用了多种文本约定。
- en: '`CodeInText`: Indicates code words in the text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. For example: “Each neuron can be initialized with specific weights via
    the `''kernel_initializer''` parameter.”'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`CodeInText`：表示文本中的代码词汇、数据库表名、文件夹名称、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter用户名。例如：“每个神经元都可以通过`''kernel_initializer''`参数初始化特定的权重。”'
- en: 'A block of code is set as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一块代码设置如下：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are highlighted:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望引起您对代码块中特定部分的注意时，相关的行或项将被突出显示：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出如下所示：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see on
    the screen. For instance, words in menus or dialog boxes appear in the text like
    this. For example: “A **Deep Convolutional Neural Network** (**DCNN**) consists
    of many neural network layers.”'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示新术语、重要单词或您在屏幕上看到的单词。例如，菜单或对话框中的单词会以这种方式出现在文本中。例如：“一个**深度卷积神经网络**（**DCNN**）由多个神经网络层组成。”'
- en: Warnings or important notes appear like this.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要提示如下所示。
- en: Tips and tricks appear like this.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 提示和技巧如下所示。
- en: Get in touch
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。
- en: '**General feedback**: Email `feedback@packtpub.com` and mention the book’s
    title in the subject of your message. If you have questions about any aspect of
    this book, please email us at `questions@packtpub.com`.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**：请发送电子邮件至`feedback@packtpub.com`，并在邮件主题中注明书名。如果您对本书的任何内容有疑问，请通过`questions@packtpub.com`与我们联系。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you reported this to us. Please visit [http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    click **Submit Errata**, and fill in the form.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误表**：尽管我们已尽最大努力确保内容的准确性，但错误仍然会发生。如果您在本书中发现了错误，我们将非常感激您向我们报告。请访问[http://www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，点击**提交勘误**，并填写表单。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packtpub.com` with a
    link to the material.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果你在互联网上发现我们作品的任何非法复制品，请提供相关地址或网站名称。请通过 `copyright@packtpub.com` 与我们联系，并附上材料的链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [http://authors.packtpub.com](http://authors.packtpub.com).'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你有兴趣成为作者**：如果你在某个领域有专长，并且有兴趣写书或为书籍贡献内容，请访问 [http://authors.packtpub.com](http://authors.packtpub.com)。'
- en: References
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*Deep Learning with Keras: Implementing deep learning models and neural networks
    with the power of Python*, Paperback – 26 Apr 2017, Antonio Gulli, Sujit Pal'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*《用 Keras 深度学习：用 Python 的强大功能实现深度学习模型和神经网络》*，平装本 – 2017 年 4 月 26 日，安东尼奥·古利，苏吉特·帕尔'
- en: '*TensorFlow 1.x Deep Learning Cookbook*: *Over 90 unique recipes to solve artificial-intelligence
    driven problems with Python*, Antonio Gulli, Amita Kapoor'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*《TensorFlow 1.x 深度学习宝典》*：*通过 Python 解决人工智能驱动问题的 90 多个独特实例*，安东尼奥·古利，阿米塔·卡普尔'
- en: Share your thoughts
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分享你的想法
- en: Once you’ve read *Deep Learning with TensorFlow and Keras, Third Edition*, we’d
    love to hear your thoughts! Please [click here to go straight to the Amazon review
    page](https://packt.link/r/1803232919) for this book and share your feedback.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读完 *《用 TensorFlow 和 Keras 深度学习，第三版》* 后，我们很想听听你的想法！请 [点击这里直接访问亚马逊评论页面](https://packt.link/r/1803232919)
    并分享你的反馈。
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你的评论对我们和技术社区都很重要，它将帮助我们确保提供优质的内容。
