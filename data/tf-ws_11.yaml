- en: 11\. Generative Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11\. 生成模型
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter introduces you to generative models—their components, how they
    function, and what they can do. You will start with generative **long short-term
    memory** (**LSTM**) networks and how to use them to generate new text. You will
    then learn about **generative adversarial networks** (**GANs**) and how to create
    new data, before moving on to **deep convolutional generative adversarial networks**
    (**DCGANs**) and creating your own images.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将向你介绍生成模型——它们的组成部分、如何运作以及它们能做什么。你将从生成**长短期记忆**（**LSTM**）网络开始，学习如何使用它们生成新的文本。然后你将学习**生成对抗网络**（**GANs**）以及如何创建新数据，接着是**深度卷积生成对抗网络**（**DCGANs**）以及如何创建你自己的图像。
- en: By the end of the chapter, you will know how to effectively use different types
    of GANs and generate various types of new data.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将知道如何有效地使用不同类型的GANs并生成各种类型的新数据。
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In this chapter, you will explore generative models, which are types of unsupervised
    learning algorithms that generate completely new artificial data. Generative models
    differ from predictive models in that they aim to generate new samples from the
    same distribution of training data. While the purpose of these models may be very
    different from those covered in other chapters, you can and will use many of the
    concepts learned in prior chapters, including loading and preprocessing various
    data files, hyperparameter tuning, and building convolutional and **recurrent
    neural networks** (**RNNs**). In this chapter, you will learn about one way to
    generate new samples from a training dataset, which is to use LSTM models to complete
    sequences of data based on initial seed data.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将探索生成模型，它们是无监督学习算法的一种类型，可以生成全新的人工数据。生成模型与预测模型的不同之处在于，它们的目标是从与训练数据相同的分布中生成新的样本。尽管这些模型的目的可能与其他章节中介绍的模型非常不同，但你可以并且将会使用前面章节中学到的许多概念，包括加载和预处理各种数据文件、调整超参数以及构建卷积神经网络和**递归神经网络**（**RNNs**）。在本章中，你将学习如何使用LSTM模型基于初始种子数据生成新的数据样本，并完成数据序列的生成。
- en: Another way that you will learn about is the concept of two neural networks
    competing against one another in an adversarial way, that is, a generator generating
    samples and a discriminator trying to distinguish between the generated and real
    samples. As both models train simultaneously, the generator generates more realistic
    samples as the discriminator can more accurately distinguish between the "real"
    and "fake" data over time. These networks working together are called GANs. Generative
    models can be used to generate new text data, audio samples, and images.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你还将学习另一种方法，即两个神经网络以对抗的方式进行竞争的概念，也就是生成器生成样本，判别器试图区分生成样本和真实样本。随着两个模型的同时训练，生成器会生成更加真实的样本，而判别器随着时间的推移能够更准确地区分“真实”数据和“假”数据。这些协同工作的网络被称为GANs。生成模型可用于生成新的文本数据、音频样本和图像。
- en: In this chapter, you will focus primarily on three areas of generative models
    – text generation or language modeling, GANs, and DCGANs.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将主要集中在生成模型的三个领域——文本生成或语言建模、GANs和DCGANs。
- en: Text Generation
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本生成
- en: In *Chapter 9*, *Recurrent Neural Networks*, you were introduced to **natural
    language processing** (**NLP**) and text generation (also known as language modeling),
    as you worked with some sequential data problems. In this section, you will be
    extending your sequence model for text generation using the same dataset to generate
    extended headlines.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第9章*，*递归神经网络*中，你已经接触过**自然语言处理**（**NLP**）和文本生成（也称为语言建模），并解决了一些序列数据问题。在本节中，你将扩展你的序列模型，使用相同的数据集生成扩展的标题来进行文本生成。
- en: Previously in this book, you saw that sequential data is data in which each
    point in the dataset is dependent on the point prior and the order of the data
    is important. Recall the example with the bag of words from *Chapter 9*, *Recurrent
    Neural Networks*. With the *bag-of-words* approach, you simply used a set of word
    counts to derive meaning from their use. As you can see in *Figure 11.1*, these
    two sentences have completely opposite semantic meanings, but would be identical
    in a bag-of-words format. While this may be an effective strategy for some problems,
    it's not an ideal approach for predicting the next word or words.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书之前的内容中，你看到过序列数据，其中数据集中的每个点都依赖于前一个点，且数据的顺序很重要。回想一下*第9章*《循环神经网络》中的袋子词汇示例。在*袋子词汇*方法中，你只是使用一组词频来推导它们的含义。正如你在*图
    11.1*中看到的，这两句话的语义完全相反，但在袋子词汇格式中是相同的。虽然这种方法对于某些问题可能有效，但它并不是预测下一个词或词语的理想方法。
- en: '![Figure 11.1: An example of identical words with differing semantics'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.1：具有不同语义的相同单词的示例'
- en: '](img/B16341_11_01.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_01.jpg)'
- en: 'Figure 11.1: An example of identical words with differing semantics'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1：具有不同语义的相同单词的示例
- en: Consider the following example of a language model. You are given a sentence
    or a phrase, `yesterday I took my car out for a`, and are asked to predict the
    word that comes next in the sequence. Here, an appropriate word to complete the
    sequence would be `drive`.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下语言模型的例子。给定一个句子或短语，`yesterday I took my car out for a`，然后要求预测下一个词是什么。在这里，完成该序列的适当单词是`drive`。
- en: '![Figure 11.2: Sentence example'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.2：句子示例'
- en: '](img/B16341_11_02.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_02.jpg)'
- en: 'Figure 11.2: Sentence example'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2：句子示例
- en: To be successful in working with sequential data, you need a neural network
    capable of storing the value of the sequence. For this, you can use RNNs and LSTMs.
    LSTMs that are used for generating new sequences, such as text generation or language
    modeling, are known as generative LSTMs.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要成功地处理序列数据，你需要一个能够存储序列值的神经网络。为此，你可以使用 RNN 和 LSTM。用于生成新序列（例如文本生成或语言建模）的 LSTM
    被称为生成 LSTM。
- en: Let's do a simple review of RNNs and LSTMs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简单回顾一下 RNN 和 LSTM。
- en: Essentially, RNNs loop back on themselves, storing information and repeating
    the process, in a continuous cycle. Information is first transformed into vectors
    so that it can be processed by machines. The RNN then processes the vector sequence
    one at a time. As the RNN processes each vector, the vector gets passed through
    the previous hidden state. In this way, the hidden state retains information from
    the previous step, acting as a type of memory. It does this by combining the input
    and the previous hidden state with a tanh function that compresses the values
    between `-1` and `1`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，RNN 会自我回环，存储信息并重复这个过程，形成一个连续的循环。信息首先被转化为向量，以便机器进行处理。然后，RNN 按顺序逐一处理这些向量。每当
    RNN 处理一个向量时，这个向量会通过前一个隐藏状态传递。通过这种方式，隐藏状态保留了来自前一步的信息，充当了一种记忆。它通过将输入和前一个隐藏状态结合，并使用
    tanh 函数将值压缩到 `-1` 和 `1` 之间来实现这一点。
- en: Essentially, this is how the RNN functions. RNNs don't need a lot of computation
    and work well with short sequences. Simply put, RNNs are networks that have loops
    that allow information to persist over time.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，这就是 RNN 的工作原理。RNN 不需要大量的计算，并且在处理短序列时效果很好。简单来说，RNN 是一种具有回环的网络，可以使信息在时间中持续存在。
- en: '![Figure 11.3: RNN data flow'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.3：RNN 数据流'
- en: '](img/B16341_11_03.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_03.jpg)'
- en: 'Figure 11.3: RNN data flow'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3：RNN 数据流
- en: RNNs do come with a couple of challenges—most notably, the exploding and vanishing
    gradient problems.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: RNN 确实存在一些挑战——最显著的就是梯度爆炸和梯度消失问题。
- en: The **exploding gradient problem** is what happens when gradients become too
    large for optimization. The opposite problem may occur where your gradients are
    too small. This is what is known as the **vanishing gradient problem**. This happens
    when gradients become increasingly smaller as you make repeated multiplications.
    Since the size of the gradient determines the size of the weight updates, exploding
    or vanishing gradients mean that the network can no longer be trained. This is
    a very real problem when it comes to training RNNs since the output of the networks
    feeds back into the input. The vanishing and exploding gradient issues were covered
    in *Chapter 9*, *Recurrent Neural Networks*, and more details of how these issues
    are solved can be found there.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**梯度爆炸问题**指的是当梯度变得过大以至于无法进行优化时发生的情况。相反的情况可能是梯度过小，这就是所谓的**梯度消失问题**。当你进行多次乘法运算时，梯度变得越来越小。这发生时，梯度的大小决定了权重更新的大小，梯度爆炸或消失意味着网络无法再进行训练。当训练RNN时，这个问题特别严重，因为网络的输出会反馈到输入中。梯度爆炸和消失的问题已经在*第9章*，*循环神经网络*中讨论过，关于如何解决这些问题的更多细节可以在那里找到。'
- en: LSTMs can selectively control the flow of information within each LSTM node.
    With added control, you can more easily adjust the model to prevent potential
    problems with gradients.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM可以选择性地控制每个LSTM节点内信息的流动。通过增加控制，你可以更容易地调整模型，以防止梯度出现潜在问题。
- en: '![Figure 11.4: LSTM architecture'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.4：LSTM架构'
- en: '](img/B16341_11_04.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_04.jpg)'
- en: 'Figure 11.4: LSTM architecture'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4：LSTM架构
- en: So, what enables LSTMs to track and store information throughout many time steps?
    You'll recall from *Chapter 9*, *Recurrent Neural Networks*, that the key building
    block behind the LSTM is the structure called a *gate*, which allows the LSTM
    to selectively add or remove information to its cell state.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，是什么让LSTM能够在多个时间步长中跟踪和存储信息呢？你会从*第9章*，*循环神经网络*中回忆起，LSTM的关键构建块是一个叫做*门控*的结构，它使LSTM能够选择性地向其单元状态添加或移除信息。
- en: Gates consist of a bounding function such as sigmoid or tanh. For example, if
    the function were sigmoid, it would force its input to be between zero and one.
    Intuitively, you can think of this as capturing how much of the information passed
    through the gate should be retained. This should be between zero and one, effectively
    *gating* the flow of information.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 门控由边界函数组成，例如sigmoid或tanh。例如，如果函数是sigmoid，它会强制其输入保持在零和一之间。直观地理解，你可以将其视为捕获通过门控传递的信息应保留多少。这个值应在零和一之间，有效地*限制*信息的流动。
- en: LSTMs process information through four simple steps.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM通过四个简单的步骤处理信息。
- en: They first forget their irrelevant history. Second, they perform a computation
    to store relevant parts of new information, and thirdly, they use these two steps
    together to selectively update their internal state. Finally, they generate an
    output.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 它们首先忘记不相关的历史信息。其次，它们执行计算来存储新信息中相关的部分，第三，它们将这两步结合起来，选择性地更新它们的内部状态。最后，它们生成一个输出。
- en: '![Figure 11.5: LSTM processing steps'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.5：LSTM处理步骤'
- en: '](img/B16341_11_05.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_05.jpg)'
- en: 'Figure 11.5: LSTM processing steps'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5：LSTM处理步骤
- en: This was a bit of a refresher on LSTMs and how they can selectively control
    and regulate the flow of information. Now that you've reviewed LSTMs and their
    architecture, you can put some of these concepts to work by reviewing your code
    and LSTM model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这部分内容回顾了LSTM以及它们如何选择性地控制和调节信息流动。现在你已经复习了LSTM及其架构，可以通过回顾你的代码和LSTM模型，将这些概念付诸实践。
- en: 'You can create an LSTM model in the following manner using a sequential model.
    This LSTM contains four hidden layers, each with `50`, `60`, `80`, and `120` units
    and a ReLU activation function. The `return_sequences` parameter is set to `True`
    for all but the last layer since they are not the final LSTM layer in the network:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下方式使用顺序模型创建LSTM模型。该LSTM包含四个隐藏层，分别具有`50`、`60`、`80`和`120`个单元，并使用ReLU激活函数。`return_sequences`参数对于除最后一层之外的所有层都设置为`True`，因为它们不是网络中的最终LSTM层：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now that you've recalled how to create RNNs with LSTM layers, you'll next learn
    how to apply them to natural language text and generate new text in a sequence.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经回顾了如何创建带有LSTM层的RNN，接下来你将学习如何将它们应用于自然语言文本，并在一个序列中生成新文本。
- en: Extending NLP Sequence Models to Generate Text
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展NLP序列模型以生成文本
- en: '**NLP** takes data in the form of natural language that has traditionally been
    very difficult for machines to make sense of and turns it into data that can be
    useful for machine learning applications. This data can take the form of characters,
    words, sentences, or paragraphs. You will be focusing on text generation in this
    section.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**NLP** 接收自然语言形式的数据，传统上这些数据对机器来说非常难以理解，然后将其转换为可以用于机器学习应用的数据。这些数据可以是字符、单词、句子或段落的形式。本节将专注于文本生成。'
- en: 'As a quick review, *preprocessing* generally entails all the steps needed to
    train your model. Some common steps include *data cleaning*, *transformation*,
    and *data reduction*. For NLP, more specifically, the steps could be all or some
    of the following:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个快速的回顾，*预处理* 通常包括训练模型所需的所有步骤。一些常见的步骤包括*数据清洗*、*转换*和*数据减少*。对于NLP，更具体地说，步骤可能是以下全部或部分：
- en: '**Dataset cleaning** encompasses the conversion of the case to lowercase, removing
    punctuation.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集清理** 包括将大小写转换为小写，去除标点符号。'
- en: '**Tokenization** is breaking up a character sequence into specified units called tokens.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标记化** 是将字符序列分解为指定单元的过程，称为*token*。'
- en: '**Padding** is a way to make input sentences of different sizes the same by
    padding them.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**填充** 是一种通过填充使不同大小的输入句子相同的方法。'
- en: '**Padding the sequences** refers to making sure that the sequences have a uniform
    length.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**填充序列** 是确保序列具有统一长度的过程。'
- en: '`rainy` and `raining` both have the stem `rain`.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rainy`和`raining`都有词干`rain`。'
- en: Let's take a closer look at what the process looks like.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看一下这个过程是什么样子的。
- en: Dataset Cleaning
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集清洗
- en: 'Here, you create a function, `clean_text`, that returns a list of words after
    cleaning. Now, save all text as lowercase with `lower()` method, encoded with
    `utf8` for character standardization. Finally, output 10 headlines from your corpus:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你创建了一个名为`clean_text`的函数，它返回经过清洗后的单词列表。现在，使用`lower()`方法将所有文本保存为小写，用`utf8`编码进行字符标准化。最后，输出你的语料库中的10个标题：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Cleaning the text in this manner is a great way to standardize text to input
    into a model. Converting all words to lowercase in the same encoding ensures consistency
    of the text. It also ensures that capitalization or different encodings of the
    same words are not treated as different words by any model that is created.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以这种方式清理文本是将文本标准化以输入模型的绝佳方法。在相同编码中将所有单词转换为小写确保文本的一致性。它还确保模型不会将同一单词的大小写或不同编码视为不同的单词。
- en: Generating a Sequence and Tokenization
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成序列和标记化
- en: 'Neural networks expect input data in a consistent, numerical format. Much like
    how images are processed for image classification models, where each image is
    represented as a three-dimensional array, and are often resized to meet the expectations
    of the model, text must be processed similarly. Luckily, Keras has a number of
    utility classes and functions to aid with processing text data for neural networks.
    One such class is `Tokenizer`, which vectorizes a text corpus by converting the
    corpus into a sequence of integers. The following code imports the `Tokenizer`
    class from Keras:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络期望输入数据以一致的数值格式提供。就像处理图像分类模型的图像一样，其中每个图像表示为三维数组，并且通常调整大小以满足模型的期望一样，文本必须进行类似处理。幸运的是，Keras具有许多实用的类和函数来帮助处理神经网络的文本数据。其中一个类是从Keras导入的`Tokenizer`：
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Generating a Sequence of n-gram Tokens
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成n-gram Tokens的序列
- en: 'Here, you create a function named `get_seq_of_tokens`. With `tokenizer.fit_on_texts`,
    you extract tokens from the corpus. Each integer output corresponds with a specific
    word. The `input_seq` parameter is initialized as an empty list, `[]`. With `token_list
    =` `tokenizer.texts_to_sequences`, you convert text to the tokenized equivalent.
    With `n_gram_sequence` `= token_list`, you generate the n-gram sequences. Using
    `input_seq.append(n_gram_sequence)`, you append each sequence to the list of your
    features:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你创建了一个名为`get_seq_of_tokens`的函数。使用`tokenizer.fit_on_texts`，你从语料库中提取token。每个整数输出对应一个特定的单词。`input_seq`参数初始化为空列表，`[]`。使用`token_list
    =` `tokenizer.texts_to_sequences`，你将文本转换为token序列的等效形式。使用`n_gram_sequence = token_list`，你生成n-gram序列。通过`input_seq.append(n_gram_sequence)`，你将每个序列追加到特征列表中：
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`get_seq_of_tokens` ensures that a corpus is broken up into sequences of equal
    length. If a corpus is too short for the network''s expected input, the resultant
    sequence will have to be padded.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_seq_of_tokens` 确保语料库被拆分成等长的序列。如果语料库对于网络期望的输入来说太短，结果序列将需要填充。'
- en: Padding Sequences
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 填充序列
- en: 'Here, you create a `generate_padded_sequences` function that takes `input_seq`
    as input. The `pad_sequences` function is used to pad the sequences to make their
    lengths equal. In the function, first, the maximum sequence length is determined
    by calculating the length of each input sequence. Once the maximum sequence length
    is determined, all other sequences are padded to match. Next, the `predictors`
    and `label` parameters are created. The `label` parameter is the last word of
    the sequence, and the `predictors` parameter is all the preceding words. Finally,
    the `label` parameter is converted to a categorical array:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你创建一个 `generate_padded_sequences` 函数，接受 `input_seq` 作为输入。`pad_sequences`
    函数用于填充序列，使它们的长度相等。在函数中，首先通过计算每个输入序列的长度来确定最大序列长度。一旦确定了最大序列长度，所有其他序列将被填充以匹配。接下来，创建
    `predictors` 和 `label` 参数。`label` 参数是序列中的最后一个单词，`predictors` 参数是所有前面的单词。最后，`label`
    参数被转换为分类数组：
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Now that you have learned some preprocessing and cleaning steps for working
    with natural language, including cleaning, generating n-gram sequences, and padding
    sequences for consistent lengths, you are ready for your first exercise of the
    chapter, that is, text generation.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学习了处理自然语言的一些预处理和清理步骤，包括清理、生成 n-gram 序列以及填充序列以保持一致的长度，你已经准备好进行本章的第一个练习，即文本生成。
- en: 'Exercise 11.01: Generating Text'
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 11.01：生成文本
- en: In this exercise, you will use the LSTM model from *Exercise 9.02*, *Building
    an RNN with LSTM Layer Nvidia Stock Prediction*, to extend your prediction sequence
    and generate new text. In that exercise, you created an LSTM model to predict
    the stock price of Nvidia by feeding the historical stock prices to the model.
    The model was able to use LSTM layers to understand patterns in the historical
    stock prices for future predictions.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你将使用来自*练习 9.02*，*构建一个带有 LSTM 层的 RNN 用于 Nvidia 股票预测*，的 LSTM 模型来扩展你的预测序列并生成新文本。在那个练习中，你创建了一个
    LSTM 模型，通过将历史股价输入模型来预测 Nvidia 的股票价格。该模型能够使用 LSTM 层理解历史股价中的模式，以进行未来的预测。
- en: In this exercise, you will use the same principle applied to text, by feeding
    the historical headlines to the model. You will use the `articles.csv` dataset
    for this exercise. The dataset contains 831 news headlines from the New York Times
    in CSV format. Along with the headlines, the dataset also contains several attributes
    about the news article, including the publication date, print page, and keywords.
    You are required to generate new news headlines using the given dataset.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你将使用与文本相同的原理，通过将历史标题输入模型来进行预测。你将使用 `articles.csv` 数据集进行这个练习。数据集包含来自《纽约时报》的
    831 个新闻标题，格式为 CSV。除了标题，数据集还包含关于新闻文章的多个属性，包括出版日期、打印页码和关键词。你需要使用给定的数据集生成新的新闻标题。
- en: Note
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find `articles.csv` here: [http://packt.link/RQVoB](http://packt.link/RQVoB).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到 `articles.csv`：[http://packt.link/RQVoB](http://packt.link/RQVoB)。
- en: 'Perform the following steps to complete this exercise:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤完成本次练习：
- en: Open a new Jupyter or Colab notebook.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter 或 Colab 笔记本。
- en: 'Import the following libraries:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下库：
- en: '[PRE5]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You should get the following output:'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE6]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Load the dataset locally by setting `your_dir` to `content/`. Create a `your_headlines`
    parameter as an empty list and use a `for` loop to iterate over:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过将 `your_dir` 设置为 `content/`，本地加载数据集。创建一个空的 `your_headlines` 参数，并使用 `for` 循环遍历：
- en: '[PRE7]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output will represent the number of headlines in your dataset:'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将表示数据集中标题的数量：
- en: '[PRE8]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, create a `clean_text` function to return a list of cleaned words. Convert
    the text to lowercase with `lower()` method and encode it with `utf8` for character
    standardization. Finally, output 20 headlines from your corpus:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建一个 `clean_text` 函数来返回清理后的单词列表。使用 `lower()` 方法将文本转换为小写，并使用 `utf8` 编码进行字符标准化。最后，从你的语料库中输出
    20 个标题：
- en: '[PRE9]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You should get the following output:'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.6: Corpus'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.6：语料库'
- en: '](img/B16341_11_06.jpg)'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_11_06.jpg)'
- en: 'Figure 11.6: Corpus'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.6：语料库
- en: 'With `tokenizer.fit`, extract tokens from the corpus. Each integer output corresponds
    to a specific word. The `input_seq` parameter is initialized as an empty list,
    `[]`. With `token_list =` `tokenizer.texts_to_sequences`, you convert each sentence
    into its tokenized equivalent. With `n_gram_sequence = token_list`, you generate
    the n-gram sequences. Using `input_seq.append(n_gram_sequence)`, you append each
    sequence to a list of features:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`tokenizer.fit`从语料库中提取词元。每个整数输出对应一个特定的词。`input_seq`参数初始化为空列表`[]`。使用`token_list
    =` `tokenizer.texts_to_sequences`，将每个句子转换为其词元化的等效形式。使用`n_gram_sequence = token_list`，你可以生成n-gram序列。通过`input_seq.append(n_gram_sequence)`，将每个序列添加到特征列表中：
- en: '[PRE10]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You should get the following output:'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.7: n-gram tokens'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.7：n-gram 词元'
- en: '](img/B16341_11_07.jpg)'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_11_07.jpg)'
- en: 'Figure 11.7: n-gram tokens'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.7：n-gram 词元
- en: The output shows the n-gram tokens of the headlines. For each headline, the
    number of n-grams is determined by the length of the headline.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出显示了头条新闻的n-gram词元。对于每个头条新闻，n-gram的数量由头条新闻的长度决定。
- en: 'Pad the sequences and obtain the variables, `predictors` and `target`:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填充序列并获取变量`predictors`和`target`：
- en: '[PRE11]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Prepare your model for training. Add an input embedding layer with `model.add(Embedding)`,
    a hidden LSTM layer with `model.add(LSTM(100))`, and a dropout of 10%. Then, add
    the output layer with `model.add(Dense)` using the softmax activation function.
    With `compile()` method, configure your model for training, setting your loss
    function to `categorical_crossentropy`. Use the Adam optimizer:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备好你的模型进行训练。添加一个输入嵌入层，使用`model.add(Embedding)`，一个隐藏的LSTM层，使用`model.add(LSTM(100))`，并设置10%的dropout。然后，使用`model.add(Dense)`添加输出层，使用softmax激活函数。通过`compile()`方法配置模型进行训练，并将损失函数设置为`categorical_crossentropy`。使用Adam优化器：
- en: '[PRE12]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You should get the following output:'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.8: Model summary'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.8：模型概览'
- en: '](img/B16341_11_08.jpg)'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_11_08.jpg)'
- en: 'Figure 11.8: Model summary'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.8：模型概览
- en: 'Fit the model and set `epochs` to `200` and `verbose` to `5`:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型并将`epochs`设置为`200`，`verbose`设置为`5`：
- en: '[PRE13]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You should get the following output:'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.9: Training the model'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.9：训练模型'
- en: '](img/B16341_11_09.jpg)'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_11_09.jpg)'
- en: 'Figure 11.9: Training the model'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.9：训练模型
- en: 'Create a function that will generate a headline given a starting seed text,
    the number of words to generate, the model, and the maximum sequence length. The
    function will include a `for` loop to iterate over the number of words to generate.
    In each iteration, the tokenizer will tokenize the text, and then pad the sequence
    before predicting the next word in the sequence. Next, the iteration will convert
    the token back into a word and add it to the sentence. Once the `for` loop completes,
    the generated headline will be returned:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数，该函数将在给定的种子文本、生成单词的数量、模型和最大序列长度的基础上生成一个头条新闻。该函数将包括一个`for`循环来迭代生成单词的次数。在每次迭代中，tokenizer将对文本进行分词，然后对序列进行填充，并预测序列中的下一个单词。接着，迭代会将token转换回单词并将其添加到句子中。一旦`for`循环完成，生成的头条新闻将被返回：
- en: '[PRE14]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Finally, output some of your generated text with the `print` function by printing
    the output of the function you created in *Step 9*. Use the `10 ways`, `europe
    looks to`, `best way`, `homeless in`, `unexpected results`, and `critics warn`
    seed words with the corresponding number of words to generate; that is, `11`,
    `8`, `10`, `10`, `10`, and `10`, respectively:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，通过`print`函数输出一些生成的文本，打印你在*步骤 9*中创建的函数的输出。使用种子词`10 ways`、`europe looks to`、`best
    way`、`homeless in`、`unexpected results`和`critics warn`，以及对应生成的单词数，即`11`、`8`、`10`、`10`、`10`和`10`，来生成文本：
- en: '[PRE15]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'You should get the following output:'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 11.10: Generated text'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.10：生成的文本'
- en: '](img/B16341_11_10.jpg)'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_11_10.jpg)'
- en: 'Figure 11.10: Generated text'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.10：生成的文本
- en: The output shows the generated headlines with the seed text provided. The words
    generated are limited to what was included in the training dataset, which itself
    was fairly limited in size, leading to some nonsensical results.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了使用提供的种子文本生成的头条新闻。生成的词汇受限于训练数据集中包含的内容，而该数据集本身相对较小，导致了一些无意义的结果。
- en: Now that you've generated text with an LSTM in your first exercise, let's move
    on to working with images by using GANs to generate new images based on a given dataset.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经在第一个练习中使用LSTM生成了文本，接下来我们将通过使用GAN生成基于给定数据集的新图像来处理图像。
- en: Generative Adversarial Networks
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: GANs are networks that generate new, synthetic data by learning patterns and
    underlying representations from a training dataset. The GAN does this by using
    two networks that compete with one another in an adversarial fashion. These networks
    are called the **generator** and **discriminator**.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: GAN（生成对抗网络）是通过学习训练数据集中的模式和潜在表示来生成新的、合成数据的网络。GAN通过使用两个彼此对抗的网络来实现这一点。这些网络被称为**生成器**和**判别器**。
- en: To see how these networks compete with one another, consider the following example.
    The example will skip over a few details that will make more sense as you get
    to them later in the chapter.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解这些网络是如何相互竞争的，可以考虑以下示例。这个示例将跳过一些细节，这些细节将在后面的章节中更加清楚。
- en: 'Imagine two entities: a money counterfeiter and a business owner. The counterfeiter
    attempts to make a currency that looks authentic to fool the business owner into
    thinking the currency is legitimate. By contrast, the business owner tries to
    identify any fake bills, so that they don''t end up with just a piece of worthless
    paper instead of real currency.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有两个实体：一个伪造货币的人和一个商家。伪造者试图制造一种看起来真实的货币，以欺骗商家认为该货币是合法的。相比之下，商家则试图识别任何假币，以免自己拿到一张无价值的纸，而不是合法的货币。
- en: This is essentially what GANs do. The counterfeiter in this example is the generator,
    and the business owner is the discriminator. The generator creates an image and
    passes it to the discriminator. The discriminator checks whether the image is
    real or not, and both networks compete against each other, driving improvements
    within one another.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这基本上就是GAN的工作原理。在这个例子中，伪造者是生成器，而商家则是判别器。生成器创建一个图像并将其传递给判别器。判别器检查图像是否真实，然后两个网络相互竞争，推动彼此的改进。
- en: The generator's mission is to create a synthetic sample of data that can fool
    the discriminator. The generator will try to trick the discriminator into thinking
    that the sample is real. The discriminator's mission is to be able to correctly
    classify a synthetic sample created by the generator.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器的任务是创建一个可以欺骗判别器的合成数据样本。生成器将尝试欺骗判别器，让它认为样本是真实的。判别器的任务是能够正确地分类由生成器创建的合成样本。
- en: '![Figure 11.11: GAN-generated images'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.11：GAN生成的图像](img/B16341_11_12.jpg)'
- en: '](img/B16341_11_11.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_11.jpg)'
- en: 'Figure 11.11: GAN-generated images'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.11：GAN生成的图像
- en: The next sections will look a bit closer at the generator and discriminator
    and how they function individually, before considering both in combination in
    the *The Adversarial Network* section.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将更详细地讨论生成器和判别器以及它们各自的功能，随后再在*对抗网络*部分中讨论它们的结合。
- en: The Generator Network
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成器网络
- en: As discussed, GANs are utilized for unsupervised learning tasks in machine learning.
    GANs consist of two models (a generator and a discriminator) that automatically
    discover and learn the patterns in input data. The two models compete with one
    another to analyze, capture, and create variations within data. GANs can be used
    to generate new data that looks like it could have come from the original data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，GAN被用于机器学习中的无监督学习任务。GAN由两个模型（生成器和判别器）组成，这两个模型会自动发现并学习输入数据中的模式。两个模型相互竞争，分析、捕捉并创造数据中的变化。GAN可以用来生成看起来像是来自原始数据的新数据。
- en: First up is the generator model. How does the generator create synthetic data?
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 首先是生成器模型。生成器是如何创建合成数据的呢？
- en: The generator receives input as a *fixed-length random vector* called the **latent
    vector**, which goes into the generator network. This is sometimes referred to
    as the **random noise seed**. A new sample is generated from it. The generated
    instance is then sent to the discriminator for classification. Through random
    noise, the generator learns which outputs were more convincing and continues to
    improve in that direction.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器接收输入为一个*固定长度的随机向量*，称为**潜在向量**，它进入生成器网络。这有时被称为**随机噪声种子**。从中生成一个新的样本。生成的实例随后会被送到判别器进行分类。通过随机噪声，生成器学习哪些输出更具说服力，并在此方向上继续改进。
- en: '![Figure 11.12: Input and output model in the generator network'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.12：生成器网络中的输入输出模型
- en: '](img/B16341_11_12.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_12.jpg)'
- en: 'Figure 11.12: Input and output model in the generator network'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.12：生成器网络中的输入输出模型
- en: In the following figure, you can see that the discriminator takes input from
    both real data and the generator. The generator neural network attempts to generate
    data that looks real to the discriminator.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，你可以看到鉴别器从真实数据和生成器两者处获取输入。生成器神经网络试图生成看起来像真实数据的输出，以骗过鉴别器。
- en: The generator doesn't get to see what the real data is. The main goal of the
    generator is to convince the discriminator to classify its output as real.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器无法看到真实数据是什么。生成器的主要目标是让鉴别器将其输出分类为真实的。
- en: '![Figure 11.13: Two sources of data for the discriminator model'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.13：鉴别器模型的数据来源'
- en: '](img/B16341_11_13.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_13.jpg)'
- en: 'Figure 11.13: Two sources of data for the discriminator model'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.13：鉴别器模型的两个数据来源
- en: 'The GAN includes the following components:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: GAN包括以下组件：
- en: Noisy input vector
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 含噪输入向量
- en: Discriminator network
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鉴别器网络
- en: Generator loss
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器损失
- en: Backpropagation is used to adjust the weights in the optimal direction by calculating
    a weight's impact on the output. The backpropagation method is used to obtain
    gradients and these gradients can help change the generator weights.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播用于通过计算权重对输出的影响来调整权重的最优方向。反向传播方法用于获取梯度，这些梯度有助于改变生成器的权重。
- en: '![Figure 11.14: Backpropagation in GAN'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.14：GAN中的反向传播'
- en: '](img/B16341_11_14.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_14.jpg)'
- en: 'Figure 11.14: Backpropagation in GAN'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.14：GAN中的反向传播
- en: 'The basic procedure of a single generator iteration looks something like this:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 单次生成器迭代的基本过程如下所示：
- en: Based on real data from a dataset, *sample random noise* is used.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于数据集中的真实数据，使用*采样随机噪声*。
- en: The *generator* produces *output* from the noise.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*生成器*从噪声中生成*输出*。'
- en: The *discriminator* classifies the output as "*real*" or "*fake*."
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*鉴别器*将输出分类为“*真实*”或“*假*”。'
- en: The *loss* from this classification is calculated, followed by *backpropagation
    through the generator* and *discriminator* to obtain the *gradients*.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从此分类中计算出*损失*，然后通过*生成器*和*鉴别器*进行*反向传播*以获得*梯度*。
- en: The *gradients* are used to adjust the generator *weights*.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*梯度*用于调整生成器的*权重*。'
- en: 'Now, to code the generator, the first step is to define your generator model.
    You begin by creating your generator function with `define_your_gen`. The number
    of outputs of your generator should match the size of the data you are trying
    to synthesize. Therefore, the final layer of your generator should be a dense
    layer with the number of units equal to the expected size of the output:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，编写生成器的代码，第一步是定义生成器模型。你从使用`define_your_gen`创建生成器函数开始。生成器的输出数量应与您要合成的数据的大小匹配。因此，生成器的最后一层应该是一个密集层，其单元数等于期望的输出大小：
- en: '[PRE16]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The model will not compile because it does not directly fit the generator model.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 模型无法编译，因为它与生成器模型不完全匹配。
- en: 'The code block will look something like the following:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块看起来可能如下所示：
- en: '[PRE17]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The generator composes one half of the GAN; the other half is the discriminator.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器构成了GAN的一半；另一半是鉴别器。
- en: The Discriminator Network
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 鉴别器网络
- en: 'A **discriminator** is a neural network model that learns to identify real
    data from the fake data that the generator sends as input. The two sources of
    training data are the authentic data samples and the fake generator samples:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**鉴别器**是一个神经网络模型，学习从生成器输入的假数据中识别真实数据。训练数据的两个来源是：真实数据样本和假生成器样本：'
- en: Real data instances are used by the discriminator as positive samples during
    the training.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真实数据实例在训练过程中作为正样本被鉴别器使用。
- en: Synthetic data instances created by the generator are used as fake examples
    during the training process.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由生成器创建的合成数据实例在训练过程中作为假例使用。
- en: '![Figure 11.15: Inputs for the discriminator network'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.15：鉴别器网络的输入'
- en: '](img/B16341_11_15.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_15.jpg)'
- en: 'Figure 11.15: Inputs for the discriminator network'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.15：鉴别器网络的输入
- en: During the discriminator training process, the discriminator is connected to
    the generator and discriminator loss. It requires both real data and synthetic
    data from the generator, but only uses the discriminator loss for weight updates.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在鉴别器的训练过程中，鉴别器与生成器和鉴别器损失连接。它需要真实数据和生成器的合成数据，但仅使用鉴别器损失进行权重更新。
- en: '![Figure 11.16: Backpropagation with discriminator loss'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.16：带有鉴别器损失的反向传播'
- en: '](img/B16341_11_16.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_16.jpg)'
- en: 'Figure 11.16: Backpropagation with discriminator loss'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.16：带有鉴别器损失的反向传播
- en: Now let's take a look at how the discriminator works with some code.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看判别器如何与一些代码一起工作。
- en: Your first step is to define your discriminator model with `define_disc()`.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 你的第一步是通过`define_disc()`定义你的判别器模型。
- en: The model takes a vector from your generator and makes a prediction as to whether
    the sample is real or fake. Therefore, you use binary classification.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 模型接收来自生成器的一个向量，并预测该样本是真实的还是虚假的。因此，你使用二分类。
- en: You're creating a simple GAN, so you will only need one hidden layer. Use `model.add(Dense(25)`
    to create the hidden layer.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 你正在创建一个简单的GAN，因此只需要一个隐藏层。使用`model.add(Dense(25)`来创建隐藏层。
- en: Again, your activation function will be ReLU with `activation='relu'` and the
    `he_uniform` weight initialization with `kernel_initializer='he_uniform'`.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，你的激活函数将是ReLU，使用`activation='relu'`，权重初始化方式为`he_uniform`，即`kernel_initializer='he_uniform'`。
- en: 'Your output layer will only need a single node for binary classification. To
    ensure your output is zero or one, you will use the sigmoid activation function:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 你的输出层只需要一个节点来进行二分类。为了确保输出为零或一，你将使用sigmoid激活函数：
- en: '[PRE18]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The model will attempt to minimize your loss function. Use Adam for your stochastic
    gradient descent:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 模型将尝试最小化你的损失函数。使用Adam作为你的随机梯度下降法：
- en: '[PRE19]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here''s a look at your discriminator model code:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你的判别器模型代码：
- en: '[PRE20]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now that you know how to create both models that compose the GAN, you can learn
    how to combine them to create your GAN in the next section.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道如何创建组成GAN的两个模型，在下一节中，你可以学习如何将它们结合起来，创建你的GAN。
- en: The Adversarial Network
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对抗网络
- en: GANs consist of two networks, a generator, which is represented as ![16a](img/B16341_11_16a.png),
    and a discriminator, represented as ![16b](img/B16341_11_16b.png). Both networks
    play an adversarial game. The generator network tries to learn the underlying
    distribution of the training data and generates similar samples, while the discriminator
    network tries to catch the fake samples generated by the generator.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: GAN由两个网络组成，一个是生成器，表示为 ![16a](img/B16341_11_16a.png)，另一个是判别器，表示为 ![16b](img/B16341_11_16b.png)。这两个网络进行对抗性博弈。生成器网络试图学习训练数据的潜在分布并生成相似的样本，而判别器网络则试图识别生成器生成的虚假样本。
- en: The generator network takes a sample and generates a fake sample of data. The
    generator is trained to increase the probability of the discriminator network
    making mistakes. The discriminator network decides whether the data is generated
    or taken from the real sample using binary classification with the help of a sigmoid
    function. The sigmoid function ensures that the output is zero or one.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器网络接收一个样本并生成一个虚假的数据样本。生成器的训练目标是增加判别器网络犯错误的概率。判别器网络通过二分类来判断数据是生成的还是来自真实样本，并借助sigmoid函数来实现。sigmoid函数确保输出为零或一。
- en: 'The following list represents an overview of a typical GAN at work:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表概述了典型GAN的工作原理：
- en: First, a *noise vector* or the *input vector* is fed to the generator network.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，一个*噪声向量*或*输入向量*被输入到生成器网络中。
- en: The generator creates synthetic data samples.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成器创建合成数据样本。
- en: Authentic data is passed to the discriminator along with the synthetic data.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 真实数据和合成数据一起传递给判别器。
- en: The discriminator then identifies the data and classifies it as real or fake.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，判别器识别数据并将其分类为真实或虚假。
- en: The model is trained and the loss backpropagated into both the discriminator
    and generator networks.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型被训练，损失通过反向传播进入判别器和生成器网络。
- en: '![Figure 11.17: GAN model with input and output'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.17：具有输入和输出的GAN模型'
- en: '](img/B16341_11_17.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_17.jpg)'
- en: 'Figure 11.17: GAN model with input and output'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.17：具有输入和输出的GAN模型
- en: 'To code an adversarial network, the following steps are necessary. Each of
    these is described in detail in the following sections:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 要编写一个对抗网络，以下步骤是必要的。每个步骤将在后续章节中详细描述：
- en: Combine the generator and discriminator models in your GAN.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将生成器和判别器模型结合在你的GAN中。
- en: Generate real samples with class labels.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用类别标签生成真实样本。
- en: Create points in latent space to use as input for the generator.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在潜在空间中创建点，作为生成器的输入。
- en: Use the generator to create fake samples.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用生成器生成虚假样本。
- en: Evaluate the discriminator performance.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估判别器的性能。
- en: Train the generator and discriminator.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练生成器和判别器。
- en: Create the latent space, generator, discriminator, and GAN, and train the GAN
    on the training data.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建潜在空间、生成器、判别器和GAN，并在训练数据上训练GAN。
- en: Now that you've explored the inner workings of the generator and discriminator,
    take a look at how you can combine the models to compete with one another.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，既然你已经探索了生成器和判别器的内部工作原理，接下来看看如何将这两个模型组合起来相互竞争。
- en: Combining the Generative and Discriminative Models
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结合生成模型和判别模型
- en: The `define_your_gan()` function creates your combined model.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '`define_your_gan()`函数创建你的组合模型。'
- en: While creating the combined GAN model, freeze the weights of the discriminator
    model by specifying `discriminator.trainable = False`. This prevents the discriminator
    weights from getting updated while you update the generator weights.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建组合GAN模型时，通过指定`discriminator.trainable = False`来冻结判别器模型的权重。这可以防止在更新生成器权重时，判别器的权重被更新。
- en: Now, you can add both models with `model.add(generator)` and `model.add(discriminator)`.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以通过`model.add(generator)`和`model.add(discriminator)`将两个模型添加到组合模型中。
- en: 'Then, specify `binary_crossentropy` as the loss function and Adam as your optimizer
    while compiling your model:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在编译模型时指定`binary_crossentropy`作为损失函数，Adam作为优化器：
- en: '[PRE21]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Generating Real Samples with Class Labels
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用类别标签生成真实样本
- en: 'Now extract real samples from the dataset to inspect fake samples against them.
    You can use the `generate_real()` function defined previously. In the first line
    of the function, `rand(n) – 0.5`, create random numbers on `n` in the range of
    `-0.5` to `0.5`. Use `hstack` to stack your array. Now you can generate class
    labels with `y = ones((n, 1))`:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，从数据集中提取真实样本，并与假样本进行对比。你可以使用之前定义的`generate_real()`函数。在函数的第一行，`rand(n) - 0.5`，生成范围在`-0.5`到`0.5`之间的`n`个随机数。使用`hstack`来堆叠你的数组。现在，你可以使用`y
    = ones((n, 1))`来生成类别标签：
- en: '[PRE22]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Creating Latent Points for the Generator
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为生成器创建潜在点
- en: 'Next, use the generator model to create fake samples. You need to generate
    the same number of points in the latent space with your `gen_latent_points()`
    function. These latent points will be passed to the generator to create samples.
    This function generates uniformly random samples from NumPy''s `randn` function.
    The number will correspond to the latent dimension multiplied by the number of
    samples to generate. This array of random numbers will then be reshaped to match
    the expected input of the generator:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用生成器模型来创建假样本。你需要通过`gen_latent_points()`函数在潜在空间中生成相同数量的点。这些潜在点将被传递给生成器以创建样本。该函数使用NumPy的`randn`函数生成均匀随机样本。生成的数量将对应潜在维度与待生成样本数的乘积。然后，这个随机数数组将被重新调整形状以匹配生成器的预期输入：
- en: '[PRE23]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Using the Generator to Generate Fake Samples and Class Labels
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用生成器生成假样本和类别标签
- en: 'The `gen_fake()` function generates fake samples with a class label of zero.
    This function generates the latent points using the function created in the previous
    step. Then, the generator will generate samples based on the latent points. Finally,
    the class label, `y`,is generated as an array of zeros representing the fact that
    this is synthetic data:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '`gen_fake()`函数生成类别标签为零的假样本。该函数使用前一步创建的函数生成潜在点。然后，生成器将基于潜在点生成样本。最后，类别标签`y`将生成一个零的数组，表示这是合成数据：'
- en: '[PRE24]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Evaluating the Discriminator Model
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估判别模型
- en: 'The following `performance_summary()` function is used to plot both real and
    fake data points. The function generates real values and synthetic data and evaluates
    the performance of the discriminator via its accuracy in identifying the synthetic
    images. Then, it finally plots both the real and synthetic images for visual review:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 以下`performance_summary()`函数用于绘制真实和假数据点。该函数生成真实值和合成数据，并通过判别器在识别合成图像时的准确性来评估其性能。然后，最终将真实和合成图像绘制出来以进行视觉检查：
- en: '[PRE25]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Training the Generator and Discriminator
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练生成器和判别器
- en: 'Now, train your model with the `train()` function. This function contains a
    `for` loop to iterate through the epochs. At each epoch, real data is sampled
    with a size equal to half the batch, and then synthetic data is generated. Then,
    the discriminator trains on the real, followed by the synthetic, data. Then, the
    GAN model is trained. When the epoch number is a multiple of the input argument,
    `n_eval`, a performance summary is generated:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过`train()`函数训练你的模型。该函数包含一个`for`循环，用于迭代训练轮次。在每一轮中，真实数据的大小等于批次大小的一半，然后生成合成数据。接着，判别器在真实数据上进行训练，随后是在合成数据上的训练。然后，GAN模型也会进行训练。当训练轮次是输入参数`n_eval`的倍数时，将生成性能总结：
- en: '[PRE26]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Creating the Latent Space, Generator, Discriminator, GAN, and Training Data
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建潜在空间、生成器、判别器、GAN和训练数据
- en: 'You can combine all the steps to build and train the model. Here, `latent_dim`
    is set to `5`, representing five latent dimensions:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将所有步骤结合起来构建并训练模型。在这里，`latent_dim` 设置为 `5`，表示五个潜在维度：
- en: '[PRE27]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In this section, you learned about GANs, different components, the generator
    and discriminator, and how you combine them to create an adversarial network.
    You will now use these concepts to generate sequences with your own GAN.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，你了解了 GAN、不同的组成部分、生成器和判别器，以及如何将它们结合起来创建一个对抗网络。现在你将使用这些概念来生成你自己 GAN 的序列。
- en: 'Exercise 11.02: Generating Sequences with GANs'
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 11.02：使用 GAN 生成序列
- en: In this exercise, you will use a GAN to create a model that generates a quadratic
    function (`y=x`2) for values of `x` between `-0.5` and `0.5`. You will create
    a generator that will simulate the normal distribution and then square the values
    to simulate the quadratic function. You will also create a discriminator that
    will discriminate between a true quadratic function and the output from the generator.
    Next, you will combine them to create your GAN model. Finally, you will train
    your GAN model and evaluate your model, comparing the results from the generator
    against a true quadratic function.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你将使用 GAN 创建一个模型，该模型生成一个二次函数（`y=x^2`），`x` 的值在 `-0.5` 和 `0.5` 之间。你将创建一个生成器，它将模拟正态分布，然后对这些值进行平方运算以模拟二次函数。你还将创建一个判别器，它将区分真实的二次函数和生成器的输出。接下来，你将把它们结合起来创建你的
    GAN 模型。最后，你将训练你的 GAN 模型并评估模型，将生成器的结果与真实的二次函数进行比较。
- en: 'Perform the following steps to complete this exercise:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤来完成此练习：
- en: 'Open a new Jupyter or Colab notebook and import the following libraries:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter 或 Colab 笔记本，并导入以下库：
- en: '[PRE28]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Define the generator model. Begin by creating your generator function with `define_gen`.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义生成器模型。首先，通过 `define_gen` 创建你的生成器函数。
- en: 'Use Keras'' `linear` activation function for the last layer of the generator
    network because the output vector should consist of continuous real values as
    a normal distribution does. The first element of the output vector has a range
    of `[-0.5,0.5]`. Since you will only consider values of `x` between these two
    values, the second element has a range of `[0.0,0.25]`:'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于生成器网络的最后一层，使用 Keras 的 `linear` 激活函数，因为输出向量应包含连续的实数值，类似于正态分布。输出向量的第一个元素的范围是
    `[-0.5,0.5]`。由于你只会考虑这两个值之间的 `x` 值，第二个元素的范围是 `[0.0,0.25]`：
- en: '[PRE29]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Now, with `define_disc()`, define your discriminator. The discriminator network
    has a binary output that identifies whether the input is real or fake. For this
    reason, use sigmoid as the activation function and binary cross-entropy as your
    loss.
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 `define_disc()` 定义你的判别器。判别器网络有一个二进制输出，用于识别输入是真实的还是伪造的。因此，使用 sigmoid 作为激活函数，并使用二元交叉熵作为损失函数。
- en: 'You''re creating a simple GAN, so use one hidden layer with `25` nodes. Use
    ReLU activation and `he_uniform` weight initialization. Your output layer will
    only need a single node for binary classification. Use Adam as your optimizer.
    The model will attempt to minimize your loss function:'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你正在创建一个简单的 GAN，因此使用一个包含 `25` 个节点的隐藏层。使用 ReLU 激活函数和 `he_uniform` 权重初始化。你的输出层只需要一个节点用于二分类。使用
    Adam 作为优化器。模型将尝试最小化你的损失函数：
- en: '[PRE30]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, add both models with `model.add(generator)` and `model.add(discriminator)`.
    Then, specify binary cross-entropy as your loss function and Adam as your optimizer,
    while compiling your model:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用 `model.add(generator)` 和 `model.add(discriminator)` 将两个模型添加到一起。然后，在编译模型时指定二元交叉熵作为损失函数，Adam
    作为优化器：
- en: '[PRE31]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Extract real samples from your dataset to inspect fake samples against them.
    Use the `generate_real()` function defined previously. `rand(n) – 0.5` creates
    random numbers on `n` in the range of `-0.5` to `0.5`. Use `hstack` to stack your
    array. Now, generate class labels with `y = ones((n, 1))`:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从数据集中提取真实样本，以便与伪造样本进行比较。使用之前定义的 `generate_real()` 函数。`rand(n) – 0.5` 创建一个范围在
    `-0.5` 到 `0.5` 之间的 `n` 个随机数。使用 `hstack` 来堆叠你的数组。现在，使用 `y = ones((n, 1))` 生成类别标签：
- en: '[PRE32]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, set the generator model to create fake samples. Generate the same number
    of points in the latent space with your `gen_latent_points()` function. Then,
    pass them to the generator and use them to create samples:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，设置生成器模型来生成伪造样本。使用你的 `gen_latent_points()` 函数在潜在空间中生成相同数量的点。然后，将它们传递给生成器并用来创建样本：
- en: '[PRE33]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Use the generator to generate fake samples with class labels:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用生成器生成带有类别标签的伪造样本：
- en: '[PRE34]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Evaluate the discriminator model. The `performance_summary()` function will
    plot both real and fake data points:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估鉴别器模型。`performance_summary()`函数将绘制真实数据和虚假数据点：
- en: '[PRE35]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, train your model with the `train()` function:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`train()`函数训练你的模型：
- en: '[PRE36]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Create a parameter for the latent dimension and set it equal to `5`. Then,
    create a generator, discriminator, and GAN using the respective functions. Train
    the generator, discriminator, and GAN models using the `train` function:'
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个潜在维度的参数，并将其设置为`5`。然后，使用各自的函数创建生成器、鉴别器和GAN。使用`train`函数训练生成器、鉴别器和GAN模型：
- en: '[PRE37]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'You will get the following output:'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将得到以下输出：
- en: '![Figure 11.18: Distribution of real and fake data'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.18：真实数据与虚假数据的分布'
- en: '](img/B16341_11_18.jpg)'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_11_18.jpg)'
- en: 'Figure 11.18: Distribution of real and fake data'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.18：真实数据与虚假数据的分布
- en: The output shows the generator progressively improving by generating points
    that more closely resemble a quadratic function. In early epochs, the points generated
    by the generator, indicated by the blue dots, show little similarity to the true
    quadratic function, indicated by the red dots. However, by the final epoch, the
    points generated by the generator almost lie on top of the true points, demonstrating
    that the generator has almost captured the true underlying function – the quadratic.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示生成器通过生成越来越接近二次函数的点而逐步改进。在早期的训练过程中，生成器生成的点（以蓝色点表示）与真实的二次函数（以红色点表示）相似度较低。然而，在最后的训练周期中，生成器生成的点几乎与真实点重合，证明生成器几乎已经捕捉到了真实的底层函数——二次函数。
- en: In this exercise, you utilized the different components of a generative model
    to create data that fits a quadratic function. As you can see in *Figure 11.18*,
    by the final epoch, the fake data resembles the real data, showing that the generator
    can capture the quadratic function well.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你利用生成模型的不同组件生成符合二次函数的数据。如你在*图 11.18*中所见，到最后一个周期时，虚假数据与真实数据相似，表明生成器能够很好地捕捉到二次函数。
- en: Now it's time for the final section of the book, on DCGANs, where you'll be
    creating your own images.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是书籍的最后一部分，关于DCGANs，你将开始创建自己的图像。
- en: Deep Convolutional Generative Adversarial Networks (DCGANs)
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度卷积生成对抗网络（DCGANs）
- en: DCGANs use convolutional neural networks instead of simple neural networks for
    both the discriminator and the generator. They can generate higher-quality images
    and are commonly used for this purpose.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: DCGANs使用卷积神经网络而非简单神经网络来构建鉴别器和生成器。它们能够生成更高质量的图像，且常用于此目的。
- en: The generator is a set of convolutional layers with fractional stride convolutions,
    also known as transpose convolutions. Layers with transpose convolutions upsample
    the input image at every convolutional layer, which increases the spatial dimensions
    of the images after each layer.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器是一组具有分数步长卷积的卷积层，也称为转置卷积。具有转置卷积的层在每一层卷积中对输入图像进行上采样，这会增加每一层之后图像的空间维度。
- en: The discriminator is a set of convolutional layers with stride convolutions,
    so it downsamples the input image at every convolutional layer, decreasing the
    spatial dimensions of the images after each layer.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴别器是一组具有步长卷积的卷积层，因此在每一层卷积中都会对输入图像进行下采样，减少每一层之后图像的空间维度。
- en: Consider the following two images. Can you identify which one is fake and which
    one is real? Take a moment and look carefully at each of them.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 请看以下两张图片。你能分辨出哪一张是假图像，哪一张是真实图像吗？花点时间仔细观察每一张图。
- en: '![Figure 11.19: Face example'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.19：人脸示例'
- en: '](img/B16341_11_19.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_19.jpg)'
- en: 'Figure 11.19: Face example'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.19：人脸示例
- en: You may be surprised to find out that neither of the images shown is of real
    people. These images were created using images of real people, but they are not
    of real people. They were created by two competing neural networks.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会感到惊讶，发现展示的两张图片都不是现实中的人像。这些图像是通过使用真实人物的图像生成的，但它们并不代表真实的人物。它们是由两个相互竞争的神经网络生成的。
- en: 'As you know, a GAN is composed of two different neural networks: the discriminator
    and the generator. What looks different right away is that each of these networks
    has different inputs and outputs. This is key to understanding how GANs can do
    what they do.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所知，GAN由两个不同的神经网络组成：鉴别器和生成器。最明显的不同是，这两个网络的输入和输出是不同的。这是理解GAN如何运作的关键。
- en: For the discriminator, the input is an image—a 3D tensor (height, width, color).
    The output is a single number that is used to make the classification. In *Figure
    11.20*, you can see `[0.95]`. It implies there is a 95% chance that the tomato
    image is real.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 对于鉴别器，输入是一张图像——一个三维张量（高度、宽度、颜色）。输出是一个单一的数字，用于进行分类。在*图 11.20*中，你可以看到`[0.95]`。这意味着该番茄图像有95%的概率是真实的。
- en: For the generator, the input is a generated random seed vector of numbers. The
    output is an image.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生成器，输入是一个生成的随机种子向量。输出是一张图像。
- en: The generator network learns to generate images similar to the ones in the dataset,
    while the discriminator learns to discriminate the original images from the generated
    ones. In this competitive fashion, they learn to generate realistic images like
    the ones in the training dataset.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器网络学习生成与数据集中图像相似的图像，而鉴别器则学习区分原始图像和生成图像。在这种竞争的方式下，它们学习生成像训练数据集中一样逼真的图像。
- en: '![Figure 11.20: Discriminator and generator networks'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.20：鉴别器和生成器网络'
- en: '](img/B16341_11_20.jpg)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_20.jpg)'
- en: 'Figure 11.20: Discriminator and generator networks'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.20：鉴别器和生成器网络
- en: Let's take a look at how the generator trains. One of the key points to take
    away from *Figure 11.20* is that the generator network has *weights static*, while
    the discriminator network shows *weights trained*. This is important because this
    enables you to differentiate how the GAN loss function changes from updates to
    the weights on the generator and discriminator independently.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看生成器是如何训练的。从*图 11.20*中可以提取的一个关键点是，生成器网络的*权重是静态的*，而鉴别器网络的*权重是经过训练的*。这一点很重要，因为它使你能够区分GAN损失函数如何根据生成器和鉴别器的权重更新独立变化。
- en: Note that `X` (the random seed) is fed into the model to produce `y`. Your model
    outputs what you predict.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`X`（随机种子）被输入模型以产生`y`。你的模型输出的是你预测的结果。
- en: '![Figure 11.21: How the generator is trained'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.21：生成器是如何训练的'
- en: '](img/B16341_11_21.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_21.jpg)'
- en: 'Figure 11.21: How the generator is trained'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.21：生成器是如何训练的
- en: Another important point to keep in mind is that the generator trains without
    ever seeing any of the real data. The generator's only goal is to fool the discriminator.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要记住的重要点是，生成器在训练时从未接触过任何真实数据。生成器的唯一目标是欺骗鉴别器。
- en: Now, consider the training process of the discriminator network. The discriminator
    is trained on a training dataset consisting of an equal number of real and fake
    (generated) images. The real images are sampled randomly from the original dataset
    and are labeled as one. An equal number of fake images is generated using the
    generator network and are labeled as zero.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑一下鉴别器网络的训练过程。鉴别器在一个由真实和虚假（生成）图像组成的训练数据集上进行训练。真实图像是从原始数据集中随机抽取的，并标记为1。生成器网络生成相同数量的虚假图像，并标记为0。
- en: '![Figure 11.22: How the discriminator is trained'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.22：鉴别器是如何训练的'
- en: '](img/B16341_11_22.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_22.jpg)'
- en: 'Figure 11.22: How the discriminator is trained'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.22：鉴别器是如何训练的
- en: The core differences between the original "vanilla" GAN and DCGAN correspond
    to the differences in the architecture. Pooling layers of the vanilla GAN are
    replaced with transposed convolutions in the generator and stride convolutions
    in the discriminator of the DCGAN. The generator and discriminator of DCGANs both
    use batch normalization layers, except for the generator output layer and the
    discriminator input layer. Also, the fully connected hidden layers of DCGANs are
    removed. Finally, the activation functions in DCGANs are generally different to
    reflect the use of convolutional layers. In the generator, ReLU is used for all
    layers except for the output layer, where tanh is used, and for the discriminator,
    Leaky ReLU is used for all layers.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的“普通”GAN与DCGAN之间的核心区别在于架构的不同。普通GAN的池化层被DCGAN生成器中的转置卷积层和鉴别器中的步幅卷积层所替代。DCGAN的生成器和鉴别器都使用批量归一化层，生成器输出层和鉴别器输入层除外。此外，DCGAN的全连接隐藏层被移除。最后，DCGAN中的激活函数通常不同，以反映卷积层的使用。在生成器中，所有层使用ReLU，除输出层外，输出层使用tanh；在鉴别器中，所有层使用Leaky
    ReLU。
- en: Training a DCGAN
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练一个DCGAN
- en: To start, you're going to set all the constants that will define your DCGAN.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要设置所有定义你的DCGAN的常量。
- en: The resolution of the images that you want to generate is specified by the `gen_res`
    parameter. The final resolution will be `32*gen_res` for the height and width
    of the image. You will use `gen_res = 3`, which results in an image resolution
    of `96x96`.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 您想要生成的图像分辨率由`gen_res`参数指定。最终的分辨率将是图像的高度和宽度为`32*gen_res`。您将使用`gen_res = 3`，这将导致图像分辨率为`96x96`。
- en: 'Image channels, `img_chan`, are simply how many numbers per pixel the image
    has. For color, you need a pixel value for each of the three color channels: `3`.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 图像通道，`img_chan`，表示每个像素的数字数量。对于彩色图像，您需要为每个颜色通道提供一个像素值：`3`。
- en: Your preview image rows and columns (`img_rows` and `img_cols`) will be how
    many images you want to display in a row and a column. For example, if you were
    to choose a preview image row of `4`, and a preview column value of `4`, you would
    get a total of 16 images displayed.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 您的预览图像的行数和列数（`img_rows`和`img_cols`）将是您希望在每行和每列显示多少图像。例如，如果您选择预览图像的行数为`4`，预览列数为`4`，则总共会显示16张图像。
- en: '`data_path` is where your data is stored on your computer. This provides the
    path needed for the code to access and store data.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '`data_path`是数据存储在您计算机上的位置。这为代码提供了访问和存储数据所需的路径。'
- en: '`epoch` is the number of passes when training the data.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '`epoch`是训练数据时的迭代次数。'
- en: Batch size, `num_batch`, is the number of training samples per iteration.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 批大小，`num_batch`，是每次迭代时的训练样本数。
- en: Buffer size, `num_buffer`, is the random shuffle that is used. You will simply
    set this to your dataset size.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 缓冲区大小，`num_buffer`，是用于随机打乱的数据。您只需将其设置为您的数据集大小。
- en: Seed vector, `seed_vector`, is the size of the vector of seeds that will be
    used to generate images.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 种子向量，`seed_vector`，是用于生成图像的种子向量的大小。
- en: 'Consider the following sample to see how to initialize all the constants that
    define your DCGAN:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅以下示例，了解如何初始化定义您DCGAN的所有常量：
- en: '[PRE38]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now you can build the generator and the discriminator. Start by defining your
    generator function with `def create_generator`, using `seed_size` and `channels`
    as arguments:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以构建生成器和判别器。首先定义您的生成器函数，使用`def create_generator`，并将`seed_size`和`channels`作为参数：
- en: '[PRE39]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Now, you will create the generated image that is going to come from an *input
    seed*; different seed numbers will generate different images and your seed size
    will determine how many different images are generated.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您将创建由*输入种子*生成的图像；不同的种子编号将生成不同的图像，而您的种子大小将决定生成多少不同的图像。
- en: Next, add a dense layer with `4*4*256` as the dimensionality of your output
    space, and use the ReLU activation function. `input_dim` is an input shape, which
    you will have equal to `seed_size`.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，添加一个密集层，输出空间的维度为`4*4*256`，并使用ReLU激活函数。`input_dim`是输入形状，您将其设置为`seed_size`。
- en: 'Use the following code to add a layer that reshapes your inputs to match your
    output space of `4*4*256`:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码添加一个层，将您的输入重塑为匹配`4*4*256`的输出空间：
- en: '[PRE40]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Your `UpSampling2D` layer is a simple layer that doubles the dimensions of
    input. It must be followed by a convolutional layer (`Conv2D`):'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 您的`UpSampling2D`层是一个简单的层，它将输入的尺寸加倍。它必须跟随一个卷积层（`Conv2D`）：
- en: '[PRE41]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Add your `Conv2D` layer with `256` as your input. You can choose `kernel_size=3`
    for your `3x3` convolution filter. With `padding="same"`, you can ensure that
    the layer''s outputs will have the same spatial dimensions as its inputs:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 添加您的`Conv2D`层，并将输入设置为`256`。您可以为`3x3`的卷积滤波器选择`kernel_size=3`。通过`padding="same"`，您可以确保该层的输出与其输入具有相同的空间尺寸：
- en: '[PRE42]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Use batch normalization to normalize your individual layers and help prevent
    gradient problems. Momentum can be anywhere in the range of `0.0` to `0.99`. Here,
    use `momentum=0.8`:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 使用批量归一化来规范化您的各个层，并帮助防止梯度问题。动量可以在`0.0`到`0.99`之间选择。在这里，使用`momentum=0.8`：
- en: '[PRE43]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'On your final CNN layer, you will use the tanh activation function to ensure
    that your output images are in the range `-1` to `1`:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的最终CNN层，您将使用tanh激活函数，以确保输出图像的范围为`-1`到`1`：
- en: '[PRE44]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The complete code block should look like this:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码块应如下所示：
- en: '[PRE45]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Now you can define your discriminator:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以定义您的判别器：
- en: '[PRE46]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Here, use a `Conv2D` layer. You can choose `kernel_size=3` for your `3x3` convolution
    filter. With `strides=2`, you specify how many strides are for your "sliding window."
    Set `input_shape=image_shape` to ensure they match, and again, with `padding="same"`,
    you ensure that the layer''s outputs will have the same spatial dimensions as
    its inputs. Add a LeakyReLU activation function after the `Conv2D` layer for all
    discriminator layers:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，使用 `Conv2D` 层。你可以选择 `kernel_size=3` 来作为 `3x3` 卷积滤波器。通过 `strides=2`，你指定了“滑动窗口”的步幅。设置
    `input_shape=image_shape` 来确保它们匹配，再通过 `padding="same"` 来确保该层的输出与输入具有相同的空间维度。为所有判别器层添加
    LeakyReLU 激活函数：
- en: '[PRE47]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The `Flatten` layer converts your data into a single feature vector for input
    into your last layer:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '`Flatten` 层将你的数据转换成一个单一的特征向量，以便输入到最后一层：'
- en: '[PRE48]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'For your activation function, use sigmoid for binary classification output:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 对于你的激活函数，使用 sigmoid 作为二分类输出：
- en: '[PRE49]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The complete code block should look like this:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码块应如下所示：
- en: '[PRE50]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Next, create your loss functions. Since the outputs of the discriminator and
    generator networks are different, you need to define two separate loss functions
    for them. Moreover, they need to be trained separately in independent passes through
    the networks.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建你的损失函数。由于判别器和生成器网络的输出不同，你需要为它们定义两个独立的损失函数。此外，它们需要在独立的网络传递中分别训练。
- en: 'You can use `tf.keras.losses.BinaryCrossentropy` for `cross_entropy`. This
    calculates the loss between true and predicted labels. Then, define the `discrim_loss`
    function from your `real_output` and `fake_output` parameters using `tf.ones`
    and `tf.zeros` to calculate `total_loss`:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `tf.keras.losses.BinaryCrossentropy` 来计算 `cross_entropy`。这个函数计算真实标签与预测标签之间的损失。然后，使用
    `tf.ones` 和 `tf.zeros` 从 `real_output` 和 `fake_output` 参数定义 `discrim_loss` 函数，以计算
    `total_loss`：
- en: '[PRE51]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The Adam optimizer is used for the generator and discriminator, with the same
    learning rate and momentum:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器和判别器都使用 Adam 优化器，并且具有相同的学习率和动量：
- en: '[PRE52]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Here, you have your individual training step. It's very important that you only
    modify one network's weights at a time. With `tf.GradientTape()`, you can train
    the discriminator and generator at the same time, but separately from one another.
    This is how TensorFlow does automatic differentiation. It calculates the derivatives.
    You'll see that it creates two "tapes" – `gen_tape` and `disc_tape`.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你有了你单独的训练步骤。非常重要的是你每次只能修改一个网络的权重。使用 `tf.GradientTape()`，你可以同时训练判别器和生成器，但它们是独立进行的。这就是
    TensorFlow 自动微分的工作原理。它会计算导数。你将看到它创建了两个“带子”——`gen_tape` 和 `disc_tape`。
- en: 'Then, create `real_output` and `fake_output` for the discriminator. Use this
    for the generator loss (`g_loss`). Now, you can calculate the discriminator loss
    (`d_loss`), calculate the gradients of both the generator and discriminator with
    `gradients_of_generator` and `gradients_of_discriminator`, and apply them:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为判别器创建 `real_output` 和 `fake_output`。用这个来计算生成器的损失（`g_loss`）。现在，你可以计算判别器的损失（`d_loss`），计算生成器和判别器的梯度，分别使用
    `gradients_of_generator` 和 `gradients_of_discriminator`，并应用它们：
- en: '[PRE53]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Next, create a number of fixed seeds with `fixed_seeds`, a seed for each image
    displayed, and for each seed vector. This is done so you can track the same images,
    observing the changes over time. With `for epoch in range`, you are tracking your
    time. Loop through each batch with `for image_batch in dataset`. Now, continue
    to track your loss for both the generator and discriminator with `generator_loss`
    and `discriminator_loss`. Now you have a nice display of all this information
    as it trains:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用 `fixed_seeds` 创建一些固定的种子，每个图像显示一个种子，每个种子向量也是如此。这样做是为了你能跟踪相同的图像，观察随时间变化的变化。通过
    `for epoch in range`，你可以跟踪时间。通过 `for image_batch in dataset` 遍历每个批次。现在，继续通过 `generator_loss`
    和 `discriminator_loss` 跟踪生成器和判别器的损失。现在，你可以看到所有这些信息的良好展示，随着训练的进行：
- en: '[PRE54]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: In this last section, you took an additional step in using generative networks.
    You learned how to train a DCGAN and how to utilize the generator and discriminator
    together to create your very own images.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的最后，你迈出了使用生成网络的进一步一步。你学习了如何训练一个DCGAN，并且如何将生成器和判别器一起使用，以创造你自己的图像。
- en: In the next exercise, you will implement what you have learned so far in this
    section.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，你将实现本节到目前为止所学的内容。
- en: 'Exercise 11.03: Generating Images with DCGAN'
  id: totrans-338
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 11.03：使用 DCGAN 生成图像
- en: In this exercise, you will generate your own images from scratch using a DCGAN.
    You will build your DCGAN with a generator and discriminator that both have convolutional
    layers. Then, you will train your DCGAN on images of a tomato, and throughout
    the training process, you will output generated images from the generator to track
    the performance of the generator.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次练习中，你将使用DCGAN从头开始生成自己的图像。你将构建一个包含卷积层的生成器和判别器的DCGAN。然后，你将用番茄的图像训练你的DCGAN，并在训练过程中，定期从生成器输出生成的图像，以跟踪生成器的表现。
- en: Note
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find `tomato-or-apple` dataset here: [https://packt.link/6Z8vW](https://packt.link/6Z8vW).'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到`tomato-or-apple`数据集：[https://packt.link/6Z8vW](https://packt.link/6Z8vW)。
- en: 'For this exercise, it is recommended that you use Google Colab:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本次练习，建议你使用Google Colab：
- en: 'Load Google Colab and Google Drive:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载Google Colab和Google Drive：
- en: '[PRE55]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Your output should look something like this:'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的输出应该类似于这样：
- en: '[PRE56]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Import the relevant libraries:'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入相关库：
- en: '[PRE57]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Format a time string to track your time usage:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 格式化时间字符串以跟踪你的时间使用：
- en: '[PRE58]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Set the generation resolution to `3`. Also, set `img_rows` and `img_cols` to
    `5` and `img_margin` to `16` so that your preview images will be a `5x5` array
    (25 images) with a 16-pixel margin.
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将生成分辨率设置为`3`。同时，将`img_rows`和`img_cols`设置为`5`，将`img_margin`设置为`16`，这样你的预览图像将是一个`5x5`的数组（25张图像），并有16像素的边距。
- en: Set `seed_vector` equal to `200`. Set `data_path` to where you stored your image
    dataset. As you can see, you are using Google Drive here. If you don't know your
    data path, you can simply locate where your files are, right-click, and select
    `Copy Path`. Set your epochs to `1000`.
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将`seed_vector`设置为`200`。将`data_path`设置为你存储图像数据集的位置。正如你所看到的，你在这里使用的是Google Drive。如果你不知道数据路径，可以简单地找到文件的位置，右键点击并选择`复制路径`。将你的周期数设置为`1000`。
- en: 'Finally, print the parameters:'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，打印参数：
- en: '[PRE59]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Your output should look something like this:'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的输出应该类似于这样：
- en: '![Figure 11.23: Output showing parameters'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.23：显示参数的输出'
- en: '](img/B16341_11_23.jpg)'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_11_23.jpg)'
- en: 'Figure 11.23: Output showing parameters'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.23：显示参数的输出
- en: 'Load and preprocess the images. Here, you will save a NumPy preprocessed file.
    Load the previous training NumPy file. The name of the binary file of the images
    has the dimensions of the images encoded in it:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载并预处理图像。在这里，你将保存一个NumPy预处理文件。加载之前训练的NumPy文件。图像的二进制文件名包含图像的尺寸信息：
- en: '[PRE60]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Batch and shuffle the data. Use the `tensorflow.data.Dataset` object library
    to use its functions to shuffle the dataset and create batches:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 批处理并打乱数据。使用`tensorflow.data.Dataset`对象库及其功能来打乱数据集并创建批次：
- en: '[PRE61]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Build the generator:'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建生成器：
- en: '[PRE62]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Build the discriminator:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建判别器：
- en: '[PRE63]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'During the training process, display generated images to get some insight into
    the progress that''s been made. Save the images. At regular intervals of 100 epochs,
    save a grid of images to evaluate the progress:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练过程中，展示生成的图像以获得一些关于进展的见解。保存这些图像。在每100个周期时，保存一组图像，以评估进展：
- en: '[PRE64]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Now, create a generator that generates noise:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建一个生成噪声的生成器：
- en: '[PRE65]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Your output should look something like this:'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的输出应该类似于这样：
- en: '![Figure 11.24: Output showing noise'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.24：显示噪声的输出'
- en: '](img/B16341_11_24.jpg)'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_11_24.jpg)'
- en: 'Figure 11.24: Output showing noise'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.24：显示噪声的输出
- en: 'View one of the images generated by typing in the following commands:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下命令查看生成的图像之一：
- en: '[PRE66]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Your output should look something like this:'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的输出应该类似于这样：
- en: '[PRE67]'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Create your loss functions. Since the outputs of the discriminator and generator
    networks are different, you need to define two separate loss functions for them.
    Moreover, they need to be trained separately in independent passes through the
    networks. Use `tf.keras.losses.BinaryCrossentropy` for `cross_entropy`. This calculates
    the loss between true and predicted labels. Then, define the `discrim_loss` function
    from `real_output` and `fake_output` using `tf.ones` and `tf.zeros` to calculate
    `total_loss`:'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建你的损失函数。由于判别器和生成器网络的输出不同，你需要为它们定义两个独立的损失函数。此外，它们需要在通过网络的独立传递中分别训练。使用`tf.keras.losses.BinaryCrossentropy`作为`cross_entropy`。它计算真实标签与预测标签之间的损失。然后，使用`tf.ones`和`tf.zeros`从`real_output`和`fake_output`定义`discrim_loss`函数来计算`total_loss`：
- en: '[PRE68]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Create two Adam optimizers (one for the generator and one for the discriminator),
    using the same learning rate and momentum for each:'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个Adam优化器（一个用于生成器，一个用于判别器），为每个优化器使用相同的学习率和动量：
- en: '[PRE69]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Create a function to implement an individual training step. With `tf.GradientTape()`,
    train the discriminator and generator at the same time, but separately from one
    another.
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数来实现单独的训练步骤。使用`tf.GradientTape()`，同时训练鉴别器和生成器，但它们彼此分开进行。
- en: 'Then, create `real_output` and `fake_output` for the discriminator. Use this for
    the generator loss (`g_loss`). Then, calculate the discriminator loss (`d_loss`)
    and calculate the gradients of both the generator and discriminator with `gradients_of_generator`
    and `gradients_of_discriminator`, and apply them:'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，创建`real_output`和`fake_output`用于鉴别器。将其用于生成器的损失（`g_loss`）。接着，计算鉴别器的损失（`d_loss`），并计算生成器和鉴别器的梯度，分别使用`gradients_of_generator`和`gradients_of_discriminator`，并应用它们：
- en: '[PRE70]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Create an array number of fixed seeds with `fixed_seeds` equal to the number
    of images displayed along one dimension and the seed vector along the other dimension
    so that you can track the same images. This allows you to see how individual seeds
    evolve over time. Loop through each batch with `for image_batch in dataset`. Continue
    to track your loss for both the generator and discriminator with `generator_loss`
    and `discriminator_loss`. You get a nice display of all this information as it trains:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个固定种子的数组，`fixed_seeds`的数量等于沿一个维度显示的图像数，另一个维度则是种子向量，以便你能够跟踪相同的图像。这使你能够看到单个种子如何随时间变化。使用`for
    image_batch in dataset`循环遍历每个批次。继续跟踪生成器和鉴别器的损失，分别使用`generator_loss`和`discriminator_loss`。在训练过程中，你会得到一个很好的信息展示：
- en: '[PRE71]'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Train on your training dataset:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的训练数据集上进行训练：
- en: '[PRE72]'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Your output should look something like this:'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的输出应该类似于以下内容：
- en: '![Figure 11.25: Training output'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.25：训练输出'
- en: '](img/B16341_11_25.jpg)'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_11_25.jpg)'
- en: 'Figure 11.25: Training output'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 11.25：训练输出
- en: 'Take a closer look at the generated images, `train-0`, `train-100`, `train-250`,
    `train-500`, and `train-999`. These images were automatically saved during the
    training process, as specified in the `train` function:'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仔细观察生成的图像，`train-0`、`train-100`、`train-250`、`train-500`和`train-999`。这些图像是在训练过程中自动保存的，正如在`train`函数中指定的那样：
- en: '[PRE73]'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'You will get output like the following:'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将得到如下输出：
- en: '![Figure 11.26: Output images after first epoch completed'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 11.26：完成第一个周期后的输出图像'
- en: '](img/B16341_11_26.jpg)'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_11_26.jpg)'
- en: 'Figure 11.26: Output images after first epoch completed'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.26：完成第一个周期后的输出图像
- en: 'Now, run the following commands:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，运行以下命令：
- en: '[PRE74]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'You will get output like the following:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 你将得到如下输出：
- en: '![Figure 11.27: Output images after 101st epoch completed'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.27：完成第101个周期后的输出图像'
- en: '](img/B16341_11_27.jpg)'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_27.jpg)'
- en: 'Figure 11.27: Output images after 101st epoch completed'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.27：完成第101个周期后的输出图像
- en: 'Also, run the following commands:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，运行以下命令：
- en: '[PRE75]'
  id: totrans-407
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'You will get output like the following:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 你将得到如下输出：
- en: '![Figure 11.28: Output images after 501st epoch completed'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.28：完成第501个周期后的输出图像'
- en: '](img/B16341_11_28.jpg)'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_28.jpg)'
- en: 'Figure 11.28: Output images after 501st epoch completed'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.28：完成第501个周期后的输出图像
- en: 'Now, run the following commands:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，运行以下命令：
- en: '[PRE76]'
  id: totrans-413
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'You will get output like the following:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 你将得到如下输出：
- en: '![Figure 11.29: Output images after 1,000th epoch completed'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.29：完成第1,000个周期后的输出图像'
- en: '](img/B16341_11_29.jpg)'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_11_29.jpg)'
- en: 'Figure 11.29: Output images after 1,000th epoch completed'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.29：完成第1,000个周期后的输出图像
- en: The output shows that after 1,000 epochs, the images of the synthetic tomatoes
    generated by the generator look very similar to real tomatoes and the images improve
    during the training process.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，在经过1,000个周期后，生成器生成的合成番茄图像与真实番茄非常相似，并且图像在训练过程中逐步改善。
- en: In this exercise, you created your own images with a DCGAN. As you can see from
    *Figure 11.29*, the results are impressive. While some of the images are easy
    to determine as fake, others look very real.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你使用DCGAN生成了自己的图像。从*图 11.29*中可以看出，结果令人印象深刻。尽管有些图像很容易辨别为伪造的，但其他一些看起来非常真实。
- en: In the next section, you will complete a final activity to put all that you've
    learned in this chapter to work and generate your own images with a GAN.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，你将完成一个最终的活动，将本章学到的所有知识付诸实践，并使用GAN生成你自己的图像。
- en: 'Activity 11.01: Generating Images Using GANs'
  id: totrans-421
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 11.01：使用GAN生成图像
- en: In this activity, you will build a GAN to generate new images. You will then
    compare the results between a DCGAN and a vanilla GAN by creating one of each
    and training them on the same dataset for the same 500 epochs. This activity will
    demonstrate the difference that model architecture can have on the output and
    show why having an appropriate model is so important. You will use the `banana-or-orange`
    dataset. You'll only be using the banana training set images to train and generate
    new images.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次活动中，你将构建一个GAN来生成新图像。然后，通过分别创建经典GAN和DCGAN，并在相同数据集上训练它们500个周期，比较两者的结果。此活动将展示模型架构对输出的影响，并说明为什么选择合适的模型如此重要。你将使用`banana-or-orange`数据集。你将只使用香蕉训练集的图像进行训练并生成新图像。
- en: Note
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find `banana-or-orange` dataset here: [https://packt.link/z6TCy](https://packt.link/z6TCy).'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到`banana-or-orange`数据集：[https://packt.link/z6TCy](https://packt.link/z6TCy)。
- en: 'Perform the following steps to complete the activity:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤完成任务：
- en: Load Google Colab and Google Drive.
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载Google Colab和Google Drive。
- en: Import the relevant libraries, including `tensorflow`, `numpy`, `zipfile`, `tqdm`,
    `zipfile`, `skimage`, `time`, and `os`.
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 导入相关库，包括`tensorflow`、`numpy`、`zipfile`、`tqdm`、`zipfile`、`skimage`、`time`和`os`。
- en: Create a function to format a time string to track your time usage.
  id: totrans-428
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数来格式化时间字符串，以便跟踪你的时间使用情况。
- en: Set the generation resolution to `3`. Also, set `img_rows` and `img_cols` to
    `5` and `img_margin` to `16` so that your preview images will be a `5x5` array
    (25 images) with a 16-pixel margin. Set `seed_vector` equal to `200`, `data_path`
    to where you stored your image dataset, and `epochs` to `500`. Finally, print
    the parameters.
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将生成分辨率设置为`3`。同时，将`img_rows`和`img_cols`设置为`5`，并将`img_margin`设置为`16`，以便预览图像为`5x5`的数组（25张图像），并具有16像素的边距。将`seed_vector`设为`200`，`data_path`设为你存储图像数据集的位置，`epochs`设为`500`。最后，打印参数。
- en: If a NumPy preprocessed file exists from prior execution, then load it into
    memory; otherwise, preprocess the data and save the image binary.
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果存在先前执行时处理的NumPy文件，则将其加载到内存中；否则，预处理数据并保存图像二进制数据。
- en: Batch and shuffle the data. Use the `tensorflow.data.Dataset` object library
    to use its functions to shuffle the dataset and create batches.
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 批量处理并打乱数据。使用`tensorflow.data.Dataset`对象库，利用其功能来打乱数据集并创建批次。
- en: Build the generator for the DCGAN.
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建DCGAN的生成器。
- en: Build the discriminator for the DCGAN.
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建DCGAN的判别器。
- en: Build the generator for the vanilla GAN.
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建经典GAN的生成器。
- en: Build the discriminator for the vanilla GAN.
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建经典GAN的判别器。
- en: Create a function to generate and save images that can be used to view progress
    during the model's training.
  id: totrans-436
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数来生成并保存图像，可以在模型训练过程中查看进度。
- en: Next, initialize the generator for the DCGAN and view the output.
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，初始化DCGAN的生成器并查看输出。
- en: Initialize the generator for the vanilla GAN and view the output.
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化经典GAN的生成器并查看输出。
- en: Print the decision of the DCGAN discriminator evaluated on the seed image.
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印DCGAN判别器在种子图像上的决策结果。
- en: Print the decision of the vanilla GAN discriminator evaluated on the seed image.
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印经典GAN判别器在种子图像上的决策结果。
- en: Create your loss functions. Since the output of both the discriminator and generator
    networks is different, you can define two separate loss functions for them. Moreover,
    they need to be trained separately in independent passes through the networks.
    Both GANs can utilize the same loss functions for their discriminators and generators.
    You can use `tf.keras.losses.BinaryCrossentropy` for `cross_entropy`. This calculates
    the loss between true and predicted labels. Then, define the `discrim_loss` function
    from `real_output` and `fake_output` using `tf.ones` and `tf.zeros` to calculate
    `total_loss`.
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建你的损失函数。由于判别器和生成器网络的输出不同，你可以为它们定义两个独立的损失函数。此外，它们需要在网络中独立训练。两个GAN可以使用相同的损失函数来训练它们的判别器和生成器。你可以使用`tf.keras.losses.BinaryCrossentropy`来计算`cross_entropy`，该函数计算真实标签和预测标签之间的损失。然后，使用`tf.ones`和`tf.zeros`从`real_output`和`fake_output`定义`discrim_loss`函数来计算`total_loss`。
- en: Create two Adam optimizers, one for the generator and one for the discriminator.
    Use the same learning rate and momentum for each.
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个Adam优化器，一个用于生成器，一个用于判别器。为每个优化器使用相同的学习率和动量。
- en: Create `real_output` and `fake_output` for the discriminator. Use this for the
    generator loss (`g_loss`). Then, calculate the discriminator loss (`d_loss`) and
    the gradients of both the generator and discriminator with `gradients_of_generator`
    and `gradients_of_discriminator` and apply them. Encapsulate these steps within
    a function, passing in the generator, discriminator, and images and returning
    the generator loss (`g_loss`) and discriminator loss (`d_loss`).
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建判别器的`real_output`和`fake_output`。然后，使用这些计算生成器损失（`g_loss`）。接着，计算判别器损失（`d_loss`）以及生成器和判别器的梯度，使用`gradients_of_generator`和`gradients_of_discriminator`并应用这些梯度。将这些步骤封装在一个函数中，传入生成器、判别器和图像，并返回生成器损失（`g_loss`）和判别器损失（`d_loss`）。
- en: Next, create a number of fixed seeds with `fixed_seeds` equal to the number
    of images to display so that you can track the same images. This allows you to
    see how individual seeds evolve over time, tracking your time with `for epoch
    in range`. Now, loop through each batch with `for image_batch in dataset`. Continue
    to track your loss for both the generator and discriminator with `generator_loss`
    and `discriminator_loss`. Now, you have a nice display of all this information
    as it trains.
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建一定数量的固定种子，`fixed_seeds`的数量等于要显示的图像数，这样你就可以跟踪相同的图像。这让你可以看到每个种子随时间的演变，并通过`for
    epoch in range`跟踪你的训练进度。现在，通过`for image_batch in dataset`循环遍历每个批次，继续跟踪生成器和判别器的损失，使用`generator_loss`和`discriminator_loss`。现在，你已经有了一个很好的信息显示界面，展示了训练过程中的所有数据。
- en: Train the DCGAN model on your training dataset.
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的训练数据集上训练DCGAN模型。
- en: Train the vanilla model on your training dataset.
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的训练数据集上训练基础模型。
- en: View your images generated by the DCGAN model after the 100th epoch.
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看在第100次训练轮次（epoch）后由DCGAN模型生成的图像。
- en: View your images generated by the DCGAN model after the 500th epoch.
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看在第500次训练轮次（epoch）后由DCGAN模型生成的图像。
- en: View your images generated by the vanilla GAN model after the 100th epoch.
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看在第100次训练轮次（epoch）后由基础GAN模型生成的图像。
- en: View your images generated by the vanilla GAN model after the 500th epoch.
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看在第500次训练轮次（epoch）后由基础GAN模型生成的图像。
- en: Note
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor285).
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这项活动的解决方案可以通过[这个链接](B16341_Solution_ePub.xhtml#_idTextAnchor285)找到。
- en: Summary
  id: totrans-453
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned about a very exciting class of machine learning
    models called generative models. You discovered the amazing potential of this
    new and continually developing field in machine learning by using a generative
    LSTM on a language modeling challenge to generate textual output.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了一类非常激动人心的机器学习模型——生成模型。你通过使用生成LSTM（长短期记忆网络）在语言建模挑战中生成文本输出，发现了这一新兴且不断发展的机器学习领域的惊人潜力。
- en: Then, you learned about generative adversarial models. You implemented a GAN
    to generate data for a normal distribution of points. You also went even further
    into deep convolutional neural networks (DCGANS), discovering how to use one of
    the most powerful applications of GANs while creating new images of tomatoes and
    bananas that exhibited human-recognizable characteristics of the fruits on which
    they were trained.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你了解了生成对抗模型。你实现了一个生成对抗网络（GAN），用来生成符合正态分布的点数据。你还更进一步研究了深度卷积生成对抗网络（DCGAN），发现了如何使用GAN的一个强大应用，在训练的番茄和香蕉图像中创建出具有可被人类识别的水果特征的新图像。
- en: We hope you enjoyed the final chapter of *The TensorFlow Workshop* and the book
    as a whole.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望你喜欢《*TensorFlow工作坊*》的最后一章，并且享受了整本书的学习过程。
- en: Let's take a look back at the amazing journey that you have completed. First,
    you started by learning the basics of TensorFlow and how to perform operations
    on the building blocks of ANNs—tensors. Then, you learned how to load and preprocess
    a variety of data types in TensorFlow, including tabular data, images, audio files,
    and text.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下你完成的这段精彩旅程。首先，你通过学习TensorFlow的基础知识，了解了如何对人工神经网络（ANN）的基本构建块——张量（tensors）进行操作。然后，你学会了如何加载和预处理各种数据类型，包括表格数据、图像、音频文件和文本。
- en: Next, you learned about a variety of resources that can be used in conjunction
    with TensorFlow to aid in your development, including TensorBoard for visualizing
    important components of your model, TensorFlow Hub for accessing pre-trained models,
    and Google Colab for building and training models in a managed environment. Then,
    you dived into building sequential models to solve regression and classification.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你了解了与TensorFlow配合使用的各种资源，包括用于可视化模型重要组件的TensorBoard，访问预训练模型的TensorFlow Hub，以及在托管环境中构建和训练模型的Google
    Colab。然后，你深入了解了如何构建顺序模型来解决回归和分类问题。
- en: To improve model performance, you then learned about regularization and hyperparameter
    tuning, which are used to ensure that your models perform well not only on the
    data they are trained upon, but also on new, unseen data. From there, you explored
    convolutional neural networks, which are an excellent choice when working with
    image data. After that, you learned in-depth how to utilize pre-trained networks
    to solve your own problems and fine-tune them to your own data. Then, you learned
    how to build and train RNNs, which are best used when working with sequential
    data, such as stock prices or even natural language. In the later part of the
    book, you explored more advanced TensorFlow capabilities using the Functional
    API and how to develop anything you might need in TensorFlow, before finally learning
    how to use TensorFlow for more creative endeavors via generative models.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高模型性能，你学习了正则化和超参数调优，这些方法用于确保你的模型不仅能在训练数据上表现良好，还能在新的、未见过的数据上也表现优异。从那里，你探索了卷积神经网络，它们在处理图像数据时表现出色。之后，你深入学习了如何利用预训练网络来解决自己的问题，并根据自己的数据进行微调。接着，你学习了如何构建和训练RNN，这些网络在处理序列数据时非常有效，例如股票价格或自然语言。在书籍的后部分，你探索了使用功能性API的更高级的TensorFlow能力，并学习了如何在TensorFlow中开发你可能需要的任何东西，最后，你学会了如何通过生成模型使用TensorFlow进行更多创意性的工作。
- en: With this book, you have not only taken your first steps in TensorFlow, but
    also now learned how to create models and provide solutions to complex problems.
    It's been an exciting journey from beginning to end, and we wish you luck in your
    continuing progress.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这本书，你不仅迈出了使用TensorFlow的第一步，还学会了如何创建模型并为复杂问题提供解决方案。从头到尾的旅程充满了兴奋，我们祝愿你在未来的进步中好运。
