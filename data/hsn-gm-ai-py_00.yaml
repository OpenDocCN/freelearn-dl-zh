- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: This book is your one-stop shop for learning how various **reinforcement learning**
    (**RL**) techniques and algorithms play an important role in game development
    using Python.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书是学习各种**强化学习**（**RL**）技术和算法如何在使用Python进行游戏开发中发挥重要作用的一站式商店。
- en: The book will start with the basics to provide you with the necessary foundation
    to understand how RL is playing a major role in game development. Each chapter
    will help you implement various RL techniques, such as Markov decision processes,
    Q-learning, the actor-critic method, **state-action-reward-state-action** (**SARSA**),
    and the deterministic policy gradients algorithm, to build logical self-learning
    agents. You will use these techniques to enhance your game development skills
    and add various features to improve your overall productivity. Later in the book,
    you will learn how deep RL techniques can be used to devise strategies that enable
    agents to learn from their own actions so that you can build fun and engaging
    games.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将从基础知识开始，为你提供理解强化学习在游戏开发中扮演重要角色的必要基础。每一章都将帮助你实现各种强化学习技术，如马尔可夫决策过程、Q学习、演员-评论家方法、**状态-动作-奖励-状态-动作**（**SARSA**）和确定性策略梯度算法，以构建逻辑自学习智能体。你将使用这些技术来提高你的游戏开发技能，并添加各种功能以提高整体生产力。本书的后期，你将学习如何使用深度强化学习技术来制定策略，使智能体能够从自己的行动中学习，从而构建有趣且引人入胜的游戏。
- en: By the end of the book, you will be able to use RL techniques to build various
    projects and contribute to open source applications.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本书结束时，你将能够使用强化学习技术来构建各种项目，并为开源应用做出贡献。
- en: Who this book is for
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书面向的对象
- en: This book is for game developers who are looking to add to their knowledge by
    implementing RL techniques to build games from scratch. This book will also appeal
    to machine learning and deep learning practitioners, and RL researchers who want
    to understand how self-learning agents can be used in the game domain. Prior knowledge
    of game development and a working knowledge of Python programming are expected.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本书面向希望通过实现强化学习技术从头开始构建游戏来增加知识的游戏开发者。本书也将吸引机器学习和深度学习从业者，以及希望了解自我学习智能体如何在游戏领域应用的强化学习研究者。本书假定读者具备游戏开发的基础知识以及Python编程的实际操作能力。
- en: What this book covers
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书涵盖的内容
- en: '[Chapter 1](5553d896-c079-4404-a41b-c25293c745bb.xhtml), *Understanding Rewards-Based
    Learning*, explores the basics of learning, what it is to learn, and how RL differs
    from other, more classic learning methods. From there, we explore how the Markov
    decision process works in code and how it relates to learning. This leads us to
    the classic multi-armed and contextual bandit problems. Finally, we will learn
    about Q-learning and quality-based model learning.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[第一章](5553d896-c079-4404-a41b-c25293c745bb.xhtml)，*理解基于奖励的学习*，探讨了学习的基础，学习的本质，以及强化学习与其他更经典的学习方法的不同之处。从那里，我们探讨了马尔可夫决策过程在代码中的工作原理以及它与学习的关系。这引导我们进入经典的带臂机和上下文赌博机问题。最后，我们将了解Q学习和基于质量的模型学习。'
- en: '[Chapter 2](8237fd36-1edf-4da0-b271-9a50c5b8deb3.xhtml), *Dynamic Programming
    and the Bellman Equation*, digs deeper into dynamic programming and explores how
    the Bellman equation can be intertwined into RL. Here, you will learn how the
    Bellman equation is used to update a policy. We then go further into detail about
    policy iteration or value iteration methods using our understanding of Q-learning,
    by training an agent on a new grid-style environment.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[第二章](8237fd36-1edf-4da0-b271-9a50c5b8deb3.xhtml)，*动态规划和贝尔曼方程*，深入探讨了动态规划，并研究了贝尔曼方程如何与强化学习交织在一起。在这里，你将学习贝尔曼方程是如何用来更新策略的。然后，我们进一步详细介绍了策略迭代或价值迭代方法，通过我们对Q学习的理解，通过在一个新的网格式环境中训练智能体来实现。'
- en: '[Chapter 3](5f6ea967-ae50-426e-ad18-c8dda835a950.xhtml), *Monte Carlo Methods*, explores
    model-based methods and how they can be used to train agents on more classic board
    games.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[第三章](5f6ea967-ae50-426e-ad18-c8dda835a950.xhtml)，*蒙特卡洛方法*，探讨了基于模型的方法以及它们如何被用来训练智能体在更经典的棋盘游戏中。'
- en: '[Chapter 4](bb05e528-e21b-4753-9e4c-372b8ed11e96.xhtml), *Temporal Difference
    Learning*, explores the heart of RL and how it solves the temporal credit assignment
    problem often discussed in academia. We apply **temporal difference learning**
    (**TDL**) to Q-learning and use it to solve a grid world environment (such as
    FrozenLake).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[第四章](bb05e528-e21b-4753-9e4c-372b8ed11e96.xhtml)，*时间差分学习*，探讨了强化学习的核心以及它如何解决学术界经常讨论的时间信用分配问题。我们将时间差分学习（**TDL**）应用于Q学习，并使用它来解决网格世界环境（如FrozenLake）。'
- en: '[Chapter 5](3e0c16c5-2145-498c-8ba1-b917745e0ef0.xhtml), *Exploring SARSA*, goes
    deeper into the fundamentals of on-policy methods such as SARSA. We will explore
    policy-based learning through understanding the partially observable Markov decision
    process. Then, we''ll look at how we can implement SARSA with Q-learning. This
    will set the stage for the more advanced policy methods that we will explore in
    later chapters, called PPO and TRPO.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[第五章](3e0c16c5-2145-498c-8ba1-b917745e0ef0.xhtml)，*探索SARSA*，深入探讨了在线策略方法如SARSA的基本原理。我们将通过理解部分可观察马尔可夫决策过程来探索基于策略的学习。然后，我们将探讨如何使用Q-learning实现SARSA。这将为我们在后续章节中探讨的更高级策略方法奠定基础，称为PPO和TRPO。'
- en: '[Chapter 6](a9e9aefb-40af-4886-9b4f-94e725dd2f92.xhtml), *Going Deep with DQN*,
    takes the Q-learning model and integrates it with deep learning to create advanced
    agents known as **deep Q-learning networks** (**DQNs**). From this, we explain
    how basic deep learning models work for regression or, in this case, to solve
    the Q equation. We will use DQNs in the CartPole environment.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[第六章](a9e9aefb-40af-4886-9b4f-94e725dd2f92.xhtml)，*深入DQN*，将Q学习模型与深度学习相结合，创建了称为**深度Q学习网络**（**DQNs**）的高级智能体。从这一点出发，我们解释了基本的深度学习模型是如何用于回归的，或者在这种情况下，用于解决Q方程。我们将在CartPole环境中使用DQNs。'
- en: '[Chapter 7](42d53358-6f57-4f67-96ce-d8587cbe7cc5.xhtml), *Going Deeper with
    DDQNs*, looks at how extensions to **deep learning** (**DL**) called **convolutional
    neural networks** (**CNNs**) can be used to observe a visual state. We will then
    use that knowledge to play Atari games and look at further enhancements.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[第七章](42d53358-6f57-4f67-96ce-d8587cbe7cc5.xhtml)，*深入DDQNs*，探讨了深度学习扩展，称为**卷积神经网络**（**CNNs**），如何用于观察视觉状态。然后，我们将使用这些知识来玩Atari游戏，并探讨进一步的增强。'
- en: '[Chapter 8](42626cbd-87b8-428c-8f2a-ecc06f5e387c.xhtml), *Policy Gradient Methods*, delves
    into more advanced policy methods and how they integrate into deep RL agents.
    This is an advanced chapter as it covers higher-level calculus and probability
    concepts. You will get to experience the MuJoCo animation RL environment in this
    chapter as a reward for your hard work.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[第八章](42626cbd-87b8-428c-8f2a-ecc06f5e387c.xhtml)，*策略梯度方法*，深入探讨了更高级的策略方法以及它们如何集成到深度强化学习智能体中。这是一个高级章节，因为它涵盖了更高级的微积分和概率概念。你将在本章中获得MuJoCo动画强化学习环境作为你辛勤工作的回报。'
- en: '[Chapter 9](2f6812c0-fd1f-4eda-9df2-6c67c8077aec.xhtml), *Optimizing for Continuous
    Control*, looks at improving the policy methods we looked at previously for continuously
    controlling advanced environments. We start off by setting up and installing the
    MuJoCo environment. After that, we look at a novel improvement called recurrent
    networks for capturing context and see how recurrent networks are applied on top
    of PPO. Then we get back into the actor-critic method and this time look at asynchronous
    actor-critic in a couple of different configurations, before finally progressing
    to actor-critic with experience replay.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[第九章](2f6812c0-fd1f-4eda-9df2-6c67c8077aec.xhtml)，*优化连续控制*，探讨了如何改进之前用于连续控制高级环境的策略方法。我们首先设置并安装MuJoCo环境。之后，我们研究了一种新颖的改进方法，称为循环网络，用于捕捉上下文，并了解循环网络是如何在PPO之上应用的。然后，我们回到演员-评论家方法，这次在几种不同的配置下研究异步演员-评论家，最后进展到带有经验回放的演员-评论家。'
- en: '[Chapter 10](1fbfb255-7fd9-44ea-8d02-f385e95d88d2.xhtml), *All Together Rainbow
    DQN*, tells us all about Rainbow. Google DeepMind recently explored the combination
    of a number of RL enhancements all together in an algorithm called Rainbow. Rainbow
    is another advanced toolkit that you can explore and either borrow from or use
    to work with more advanced RL environments.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[第十章](1fbfb255-7fd9-44ea-8d02-f385e95d88d2.xhtml)，*彩虹DQN的全部内容*，告诉我们所有关于Rainbow的信息。Google
    DeepMind最近在一种称为Rainbow的算法中探索了将多个强化学习增强功能结合在一起。Rainbow是另一个你可以探索的工具包，你可以从中借用或使用它来与更高级的强化学习环境一起工作。'
- en: '[Chapter 11](ab9a7f4f-60d8-4643-8627-199cf95bcf55.xhtml), *Exploiting ML-Agents*, looks
    at how we can either use elements from the ML-Agents toolkit in our own agents
    or use the toolkit to get a fully developed agent.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[第十一章](ab9a7f4f-60d8-4643-8627-199cf95bcf55.xhtml)，*利用ML-Agents*，探讨了如何在我们自己的智能体中使用ML-Agents工具包的元素，或者使用工具包来获得一个完全开发的智能体。'
- en: '[Chapter 12](6d061d35-176a-421a-9b62-aed35f48a6b7.xhtml), *DRL Frameworks*,
    opens up the possibilities of playing with solo agents in various environments.
    We will explore various multi-agent environments as well.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[第十二章](6d061d35-176a-421a-9b62-aed35f48a6b7.xhtml)，*DRL框架*，开启了在多种环境中与单独智能体玩耍的可能性。我们还将探索各种多智能体环境。'
- en: '[Chapter 13](e54c6adf-d238-4f1e-8e32-7ba3c5da0f46.xhtml), *3D Worlds*, trains
    us to use RL agents effectively to tackle a variety of 3D environmental challenges.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[第13章](e54c6adf-d238-4f1e-8e32-7ba3c5da0f46.xhtml)，*3D世界*，训练我们有效地使用RL代理来应对各种3D环境挑战。'
- en: '[Chapter 14](a171ddfa-e639-4b4e-9652-4279b5ac872a.xhtml), *From DRL to AGI*, looks
    beyond DRL and into the realm of AGI, or at least where we hope we are going with
    AGI. We will also looks at various DRL algorithms that can be applied in the real
    world.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[第14章](a171ddfa-e639-4b4e-9652-4279b5ac872a.xhtml)，*从DRL到AGI*，超越了DRL，进入了AGI的领域，或者至少是我们希望AGI能去往的地方。我们还将探讨各种可以在现实世界中应用的DRL算法。'
- en: To get the most out of this book
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为了充分利用本书
- en: A working knowledge of Python and game development is essential. A good PC with
    a GPU would be beneficial.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 掌握Python和游戏开发的基本知识是必要的。拥有一台配备GPU的好PC将很有帮助。
- en: Download the example code files
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from your account at [www.packt.com](http://www.packt.com).
    If you purchased this book elsewhere, you can visit [www.packtpub.com/support](https://www.packtpub.com/support)
    and register to have the files emailed directly to you.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[www.packt.com](http://www.packt.com)上的账户下载本书的示例代码文件。如果您在其他地方购买了此书，您可以访问[www.packtpub.com/support](https://www.packtpub.com/support)并注册，以便将文件直接通过电子邮件发送给您。
- en: 'You can download the code files by following these steps:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下步骤下载代码文件：
- en: Log in or register at [www.packt.com](http://www.packt.com).
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[www.packt.com](http://www.packt.com)上登录或注册。
- en: Select the Support tab.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择“支持”选项卡。
- en: Click on Code Downloads.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“代码下载”。
- en: Enter the name of the book in the Search box and follow the onscreen instructions.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索框中输入书籍名称，并遵循屏幕上的说明。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 下载文件后，请确保使用最新版本的以下软件解压缩或提取文件夹：
- en: WinRAR/7-Zip for Windows
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Windows上的WinRAR/7-Zip
- en: Zipeg/iZip/UnRarX for Mac
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipeg/iZip/UnRarX for Mac
- en: 7-Zip/PeaZip for Linux
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 7-Zip/PeaZip for Linux
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Hands-On-Reinforcement-Learning-for-Games](https://github.com/PacktPublishing/Hands-On-Reinforcement-Learning-for-Games). In
    case there's an update to the code, it will be updated on the existing GitHub
    repository.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本书代码包也托管在GitHub上，网址为[https://github.com/PacktPublishing/Hands-On-Reinforcement-Learning-for-Games](https://github.com/PacktPublishing/Hands-On-Reinforcement-Learning-for-Games)。如果代码有更新，它将在现有的GitHub仓库中更新。
- en: We also have other code bundles from our rich catalog of books and videos available
    at **[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)**.
    Check them out!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还有其他来自我们丰富的图书和视频目录的代码包可供下载，网址为**[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)**。查看它们！
- en: Download the color images
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载彩色图像
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [http://www.packtpub.com/sites/default/files/downloads/9781839214936_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/9781839214936_ColorImages.pdf).'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一份包含本书中使用的截图/图表彩色图像的PDF文件。您可以从这里下载：[http://www.packtpub.com/sites/default/files/downloads/9781839214936_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/9781839214936_ColorImages.pdf)。
- en: Conventions used
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用了多种文本约定。
- en: '`CodeInText`: Indicates code words in text, database table names, folder names,
    filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles.
    Here is an example: "The three functions `make_atari`, `wrap_deepmind`, and `wrap_pytorch` are
    all located in the new `wrappers.py` file we imported earlier."'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`CodeInText`：表示文本中的代码单词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter昵称。以下是一个示例：“三个函数`make_atari`、`wrap_deepmind`和`wrap_pytorch`都位于我们之前导入的`wrappers.py`新文件中。”'
- en: 'A block of code is set as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块是这样设置的：
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望您注意代码块中的特定部分时，相关的行或项目将以粗体显示：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出都应如下编写：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For example, words in menus or dialog boxes appear in the text like this. Here
    is an example: "Building on that, we''ll look at a variant of the DQN called the **DDQN**,
    or **double (dueling) DQN**."'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示新术语、重要单词或屏幕上看到的单词。例如，菜单或对话框中的单词在文本中显示如下。以下是一个示例：“在此基础上，我们将探讨DQN的一个变体，称为**DDQN**，或**双（对抗）DQN**。”'
- en: Warnings or important notes appear like this.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要提示看起来是这样的。
- en: Tips and tricks appear like this.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士和技巧看起来是这样的。
- en: Get in touch
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。
- en: '**General feedback**: If you have questions about any aspect of this book,
    mention the book title in the subject of your message and email us at `customercare@packtpub.com`.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**：如果您对本书的任何方面有疑问，请在邮件主题中提及书名，并给我们发送邮件至 `customercare@packtpub.com`。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](https://www.packtpub.com/support/errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**：尽管我们已经尽一切努力确保内容的准确性，但错误仍然可能发生。如果您在这本书中发现了错误，我们将不胜感激，如果您能向我们报告这一错误。请访问
    [www.packtpub.com/support/errata](https://www.packtpub.com/support/errata)，选择您的书籍，点击勘误提交表单链接，并输入详细信息。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the Internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packt.com` with a link
    to the material.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果您在互联网上发现我们作品的任何非法副本，我们将不胜感激，如果您能提供位置地址或网站名称。请通过 `copyright@packt.com`
    联系我们，并提供材料的链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com/).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您想成为一名作者**：如果您在某个领域有专业知识，并且对撰写或参与一本书籍感兴趣，请访问 [authors.packtpub.com](http://authors.packtpub.com/)。'
- en: Reviews
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评论
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 请留下评论。一旦您阅读并使用了这本书，为何不在您购买它的网站上留下评论？潜在读者可以查看并使用您的客观意见来做出购买决定，我们Packt可以了解您对我们产品的看法，我们的作者也可以看到他们对书籍的反馈。谢谢！
- en: For more information about Packt, please visit [packt.com](http://www.packt.com/).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如需更多关于Packt的信息，请访问 [packt.com](http://www.packt.com/)。
