- en: Build Your First CNN and Performance Optimization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建你的第一个CNN并优化性能
- en: A **convolutional neural network** (**CNN**) is a type of **feed-forward neural
    network** (**FNN**) in which the connectivity pattern between its neurons is inspired
    by an animal's visual cortex. In the last few years, CNNs have demonstrated superhuman
    performance in image search services, self-driving cars, automatic video classification,
    voice recognition, and **natural language processing **(**NLP**).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络**（**CNN**）是一种**前馈神经网络**（**FNN**），其神经元之间的连接模式受到动物视觉皮层的启发。近年来，CNN在图像搜索服务、自动驾驶汽车、自动视频分类、语音识别和**自然语言处理**（**NLP**）中展现出了超越人类的表现。'
- en: 'Considering these motivations, in this chapter, we will construct a simple
    CNN model for image classification from scratch, followed by some theoretical
    aspects, such as convolutional and pooling operations. Then we will discuss how
    to tune hyperparameters and optimize the training time of CNNs for improved classification
    accuracy. Finally, we will build the second CNN model by considering some best
    practices. In a nutshell, the following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些动机，在本章中，我们将从零开始构建一个简单的CNN图像分类模型，并介绍一些理论方面的内容，如卷积操作和池化操作。然后，我们将讨论如何调整超参数并优化CNN的训练时间，以提高分类准确性。最后，我们将通过考虑一些最佳实践来构建第二个CNN模型。简而言之，本章将涵盖以下主题：
- en: CNN architectures and drawbacks of DNNs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN架构与DNN的缺点
- en: The convolution operations and pooling layers
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积操作与池化层
- en: Creating and training a CNN for image classification
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建并训练CNN进行图像分类
- en: Model performance optimization
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型性能优化
- en: Creating an improved CNN for optimized performance
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个优化性能的改进版CNN
- en: CNN architectures and drawbacks of DNNs
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CNN架构与DNN的缺点
- en: In [Chapter 2](00f0eb08-6d6c-48b7-8ffe-db69c7f90a73.xhtml), *Introduction to
    Convolutional Neural Networks*, we discussed that a regular multilayer perceptron
    works fine for small images (for example, MNIST or CIFAR-10). However, it breaks
    down for larger images because of the huge number of parameters it requires. For
    example, a 100 × 100 image has 10,000 pixels, and if the first layer has just
    1,000 neurons (which already severely restricts the amount of information transmitted
    to the next layer), this means 10 million connections; and that is just for the
    first layer.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第二章](00f0eb08-6d6c-48b7-8ffe-db69c7f90a73.xhtml)，《卷积神经网络简介》中，我们讨论了常规的多层感知器对于小图像（例如，MNIST或CIFAR-10）效果良好。然而，对于较大图像，它会因为所需的参数数量庞大而崩溃。例如，一张100
    × 100的图像有10,000个像素，如果第一层只有1,000个神经元（这已经严重限制了传递到下一层的信息量），这意味着10百万个连接；而这仅仅是第一层。
- en: CNNs solve this problem using partially connected layers. Because consecutive
    layers are only partially connected and because it heavily reuses its weights,
    a CNN has far fewer parameters than a fully connected DNN, which makes it much
    faster to train, reduces the risk of overfitting, and requires much less training
    data. Moreover, when a CNN has learned a kernel that can detect a particular feature,
    it can detect that feature anywhere on the image. In contrast, when a DNN learns
    a feature in one location, it can detect it only in that particular location.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: CNN通过使用部分连接的层来解决这个问题。由于连续层仅部分连接，并且由于它大量重用权重，CNN比全连接的DNN具有更少的参数，这使得它的训练速度更快，减少了过拟合的风险，并且需要更少的训练数据。此外，当CNN学会了一个可以检测特定特征的核时，它可以在图像的任何位置检测到该特征。相比之下，当DNN在某个位置学会了一个特征时，它只能在那个特定位置检测到该特征。
- en: 'Since images typically have very repetitive features, CNNs are able to generalize
    much better than DNNs for image processing tasks such as classification, using
    fewer training examples. Importantly, a DNN has no prior knowledge of how pixels
    are organized; it does not know that nearby pixels are close. A CNN''s architecture
    embeds this prior knowledge. Lower layers typically identify features in small
    areas of the images, while higher layers combine the lower-level features into
    larger features. This works well with most natural images, giving CNNs a decisive
    head start compared to DNNs:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图像通常具有非常重复的特征，卷积神经网络（CNN）在图像处理任务（如分类）中能比深度神经网络（DNN）更好地进行泛化，并且使用更少的训练样本。重要的是，DNN对像素如何组织没有先验知识；它并不知道相邻的像素是接近的。CNN的架构则嵌入了这种先验知识。较低层通常在图像的小区域内识别特征，而较高层将低层特征合并成更大的特征。这对大多数自然图像有效，赋予了CNN在与DNN的比较中决定性的优势：
- en: '![](img/685a8fc6-999c-4f76-92ef-0377bfa260f0.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/685a8fc6-999c-4f76-92ef-0377bfa260f0.png)'
- en: 'Figure 1: Regular DNN versus CNN, where each layer has neurons arranged in
    3D'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：常规DNN与CNN的对比，其中每一层的神经元按3D排列
- en: For example, in *Figure 1*, on the left, you can see a regular three-layer neural
    network. On the right, a ConvNet arranges its neurons in three dimensions (width,
    height, and depth) as visualized in one of the layers. Every layer of a ConvNet
    transforms the 3D input volume to a 3D output volume of neuron activations. The
    red input layer holds the image, so its width and height would be the dimensions
    of the image, and the depth would be three (red, green, and blue channels). Therefore,
    all the multilayer neural networks we looked at had layers composed of a long
    line of neurons, and we had to flatten input images or data to 1D before feeding
    them to the neural network.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在*图1*中，左侧展示了一个常规的三层神经网络。右侧则是一个卷积神经网络（ConvNet），它将神经元排列在三维空间（宽度、高度和深度）中，正如其中一层所示。ConvNet的每一层都将3D输入体积转化为3D输出体积的神经元激活。红色的输入层包含图像，因此它的宽度和高度就是图像的维度，而深度则是三（红色、绿色和蓝色通道）。因此，我们所讨论的所有多层神经网络都是由一长列神经元组成的，我们需要将输入的图像或数据扁平化为一维，再输入到神经网络中。
- en: However, what happens once you try to feed them a 2D image directly? The answer
    is that in CNNs, each layer is represented in 2D, which makes it easier to match
    neurons with their corresponding inputs. We will see examples of this in upcoming
    sections. Another important fact is that all the neurons in a feature map share
    the same parameters, so it dramatically reduces the number of parameters in the
    model; but more importantly, it means that once the CNN has learned to recognize
    a pattern in one location, it can recognize it in any other location.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一旦你尝试直接输入一张2D图像会发生什么呢？答案是，在CNN中，每一层都是以2D形式表示的，这使得神经元和其对应的输入更容易匹配。我们将在接下来的章节中看到这个例子的应用。另一个重要的事实是，特征图中的所有神经元共享相同的参数，因此大大减少了模型中的参数数量；但更重要的是，这意味着一旦CNN学会在一个位置识别某个模式，它就能在任何其他位置识别该模式。
- en: In contrast, once a regular DNN has learned to recognize a pattern in one location,
    it can recognize it only in that particular location. In multilayer networks such
    as MLP or DBN, the outputs of all neurons of the input layer are connected to
    each neuron in the hidden layer, and then the output will again act as the input
    to the fully connected layer. In CNN networks, the connection scheme that defines
    the convolutional layer is significantly different. The convolutional layer is
    the main type of layer in a CNN, where each neuron is connected to a certain region
    of the input area called the **receptive field**.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，一旦常规的DNN学习到识别一个位置的模式，它只能在该特定位置进行识别。在多层网络（如MLP或DBN）中，输入层所有神经元的输出都会连接到隐藏层中的每个神经元，然后输出将再次作为输入传递到全连接层。在CNN网络中，定义卷积层的连接方式则大不相同。卷积层是CNN中的主要层类型，其中每个神经元都连接到输入区域的某一特定区域，这个区域被称为**感受野**。
- en: In a typical CNN architecture, a few convolutional layers are connected in a
    cascade style. Each layer is followed by a **Rectified Linear Unit** (**ReLU**)
    layer, then a pooling layer, then one or more convolutional layers (+ReLU), then
    another pooling layer, and finally one or more fully connected layers. Pretty
    much depending on problem type, the network might be deep though. The output from
    each convolution layer is a set of objects called **feature maps**, generated
    by a single kernel filter. Then the feature maps can be used to define a new input
    to the next layer.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在典型的CNN架构中，几个卷积层是以级联的方式连接的。每一层后面都跟着一个**修正线性单元**（**ReLU**）层，接着是一个池化层，然后是一个或多个卷积层（+ReLU），再接一个池化层，最后是一个或多个全连接层。根据问题类型，网络的深度可能不同。每个卷积层的输出是由单个卷积核生成的一组对象，称为**特征图**。然后，这些特征图可以作为输入定义传递到下一层。
- en: 'Each neuron in a CNN network produces an output, followed by an activation
    threshold, which is proportional to the input and not bound:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: CNN网络中的每个神经元都会产生一个输出，后跟一个激活阈值，该阈值与输入成正比且没有限制。
- en: '![](img/03186daf-dff9-499d-ad13-731d480942fd.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/03186daf-dff9-499d-ad13-731d480942fd.png)'
- en: 'Figure 2: A conceptual architecture of a CNN'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：CNN的概念性架构
- en: 'As you can see in *Figure 2*, the pooling layers are usually placed after the
    convolutional layers (for example, between two convolutional layers). A pooling
    layer into subregions then divides the convolutional region. Then, a single representative
    value is selected, using either a max-pooling or an average pooling technique,
    to reduce the computational time of subsequent layers. This way, a CNN can be
    thought of as a feature extractor. To understand this more clearly, refer to the
    following figure:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 2*所示，池化层通常位于卷积层之后（例如，在两个卷积层之间）。池化层将卷积区域划分为子区域。然后，使用最大池化或平均池化技术选择一个代表性值，从而减少后续层的计算时间。这样，卷积神经网络（CNN）可以被看作是一种特征提取器。为了更清晰地理解这一点，请参见下图：
- en: '![](img/f6a1addd-d986-4e6a-b27b-388aa2bfd8f3.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f6a1addd-d986-4e6a-b27b-388aa2bfd8f3.png)'
- en: In this way, the robustness of the feature with respect to its spatial position
    is increased too. To be more specific, when feature maps are used as image properties
    and pass through the grayscale image, it gets smaller and smaller as it progresses
    through the network; but it also typically gets deeper and deeper, as more feature
    maps will be added.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，特征相对于其空间位置的鲁棒性也得到了提高。更具体来说，当特征图作为图像属性并通过灰度图像时，它在网络中逐步变小；但它通常会变得越来越深，因为将添加更多的特征图。
- en: We've already discussed the limitations of such FFNN - that is, a very high
    number of neurons would be necessary, even in a shallow architecture, due to the
    very large input sizes associated with images, where each pixel is a relevant
    variable. The convolution operation brings a solution to this problem as it reduces
    the number of free parameters, allowing the network to be deeper with fewer parameters.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论过这种前馈神经网络（FFNN）的局限性——也就是说，即使在一个浅层架构中，由于图像的输入规模非常大，其中每个像素都是一个相关变量，因此需要大量的神经元。卷积操作为这个问题提供了解决方案，因为它减少了自由参数的数量，使得网络可以更深，且参数更少。
- en: Convolutional operations
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积操作
- en: A convolution is a mathematical operation that slides one function over another
    and measures the integral of their pointwise multiplication. It has deep connections
    with the Fourier transformation and the Laplace transformation and is heavily
    used in signal processing. Convolutional layers actually use cross-correlations,
    which are very similar to convolutions.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积是一种数学运算，它将一个函数滑动到另一个函数上，并测量它们逐点乘积的积分。它与傅里叶变换和拉普拉斯变换有着深厚的联系，并且在信号处理领域中被广泛使用。卷积层实际上使用的是互相关，这与卷积非常相似。
- en: 'In mathematics, convolution is a mathematical operation on two functions that
    produces a third function—that is, the modified (convoluted) version of one of
    the original functions. The resulting function gives in integral of the pointwise
    multiplication of the two functions as a function of the amount that one of the
    original functions is translated. Interested readers can refer to this URL for
    more information: [https://en.wikipedia.org/wiki/Convolution](https://en.wikipedia.org/wiki/Convolution).'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学中，卷积是对两个函数进行的数学操作，产生一个第三个函数——即原始函数的修改版（卷积版）。结果函数给出了两个函数逐点乘积的积分，作为其中一个原始函数平移量的函数。感兴趣的读者可以参考此网址获取更多信息：[https://en.wikipedia.org/wiki/Convolution](https://en.wikipedia.org/wiki/Convolution)。
- en: 'Thus, the most important building block of a CNN is the convolutional layer.
    Neurons in the first convolutional layer are not connected to every single pixel
    in the input image (that is, like FNNs—for example, MLP and DBN) but only to pixels
    in their receptive fields. See *Figure 3*. In turn, each neuron in the second
    convolutional layer is connected only to neurons located within a small rectangle
    in the first layer:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，卷积神经网络（CNN）最重要的构建块是卷积层。第一卷积层中的神经元并不是与输入图像中的每个像素相连接（就像前馈神经网络（FNN）——例如多层感知机（MLP）和深度信念网络（DBN）那样），而是仅与其感受野中的像素相连接。请参见*图
    3*。反过来，第二卷积层中的每个神经元仅与第一层中位于小矩形内的神经元相连接：
- en: '![](img/e7c30e9b-9df7-4948-9dc4-617c8ef86b52.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7c30e9b-9df7-4948-9dc4-617c8ef86b52.png)'
- en: 'Figure 3: Each convolutional neuron processes data only for its receptive field'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：每个卷积神经元只处理其感受野中的数据
- en: In [Chapter 2](00f0eb08-6d6c-48b7-8ffe-db69c7f90a73.xhtml), *Introduction to
    Convolutional Neural Networks*, we have seen that all multilayer neural networks
    (for example, MLP) have layers composed of so many neurons, and we have to flatten
    input images to 1D before feeding them to the neural network. Instead, in a CNN,
    each layer is represented in 2D, which makes it easier to match neurons with their
    corresponding inputs.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第二章](00f0eb08-6d6c-48b7-8ffe-db69c7f90a73.xhtml)《卷积神经网络简介》中，我们已经看到所有的多层神经网络（例如，MLP）都由许多神经元组成的层构成，我们需要将输入的图像展平为1D，然后才能输入神经网络。相反，在CNN中，每一层都是以2D的形式表示，这使得将神经元与其对应的输入匹配变得更加容易。
- en: The receptive fields concept is used by CNNs to exploit spatial locality by
    enforcing a local connectivity pattern between neurons of adjacent layers.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 感受野的概念被CNN用来通过在相邻层的神经元之间强制局部连接模式，从而利用空间局部性。
- en: This architecture allows the network to concentrate on low-level features in
    the first hidden layer, and then assemble them into higher-level features in the
    next hidden layer, and so on. This hierarchical structure is common in real-world
    images, which is one of the reasons why CNNs work so well for image recognition.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构允许网络在第一隐藏层集中处理低级特征，然后在下一隐藏层将其组合成更高级的特征，依此类推。这种层次结构在真实世界的图像中很常见，这也是CNN在图像识别中表现良好的原因之一。
- en: Finally, it not only requires a low number of neurons but also reduces the number
    of trainable parameters significantly. For example, regardless of image size,
    building regions of size 5 x 5, each with the same-shared weights, requires only
    25 learnable parameters. In this way, it resolves the vanishing or exploding gradients
    problem in training traditional multilayer neural networks with many layers by
    using backpropagation.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，它不仅需要较少的神经元，而且显著减少了可训练参数的数量。例如，无论图像大小如何，构建大小为5 x 5的区域，每个区域使用相同的共享权重，仅需要25个可学习参数。通过这种方式，它解决了在使用反向传播训练传统多层神经网络时出现的梯度消失或爆炸问题。
- en: Pooling, stride, and padding operations
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 池化、步幅和填充操作
- en: 'Once you''ve understood how convolutional layers work, the pooling layers are
    quite easy to grasp. A pooling layer typically works on every input channel independently,
    so the output depth is the same as the input depth. You may alternatively pool
    over the depth dimension, as we will see next, in which case the image''s spatial
    dimensions (for example, height and width) remain unchanged but the number of
    channels is reduced. Let''s see a formal definition of pooling layers from the
    well-known TensorFlow website:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你理解了卷积层的工作原理，池化层就很容易理解。池化层通常独立地对每个输入通道进行处理，因此输出深度与输入深度相同。你也可以在深度维度上进行池化，正如我们接下来将看到的那样，在这种情况下，图像的空间维度（例如，高度和宽度）保持不变，但通道的数量减少。我们来看一下来自著名TensorFlow网站的池化层的正式定义：
- en: '"The pooling ops sweep a rectangular window over the input tensor, computing
    a reduction operation for each window (average, max, or max with argmax). Each
    pooling op uses rectangular windows of size called ksize separated by offset strides.
    For example, if strides are all ones, every window is used, if strides are all
    twos, every other window is used in each dimension, and so on."'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: “池化操作通过一个矩形窗口在输入张量上滑动，对每个窗口执行一个归约操作（平均、最大或带有argmax的最大值）。每个池化操作使用称为ksize的矩形窗口，窗口之间的偏移量由步幅决定。例如，如果步幅为1，则使用每个窗口；如果步幅为2，则每个维度使用每隔一个窗口，依此类推。”
- en: 'Therefore, in summary, just like convolutional layers, each neuron in a pooling
    layer is connected to the outputs of a limited number of neurons in the previous
    layer, located within a small rectangular receptive field. However, we must define
    its size, the stride, and the padding type. So in summary, the output can be computed
    as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总结来说，就像卷积层一样，池化层中的每个神经元都连接到前一层中一小部分神经元的输出，这些神经元位于一个小的矩形感受野内。然而，我们必须定义其大小、步幅和填充类型。因此，总结一下，输出可以通过以下方式计算：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, the indices also take the padding values into consideration.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，索引还考虑了填充值。
- en: A pooling neuron has no weights. Therefore, all it does is aggregate the inputs
    using an aggregation function such as max or mean.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 池化神经元没有权重。因此，它所做的就是使用聚合函数（如最大值或均值）聚合输入。
- en: In other words, the goal of using pooling is to subsample the input image in
    order to reduce the computational load, memory usage, and number of parameters.
    This helps to avoid overfitting in the training stage. Reducing the input image
    size also makes the neural network tolerate a little bit of image shift. The spatial
    semantics of the convolution ops depend on the padding scheme chosen.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，使用池化的目的是对输入图像进行子采样，以减少计算负担、内存使用量和参数数量。这有助于避免训练阶段的过拟合。减少输入图像的大小还使得神经网络能够容忍一定程度的图像偏移。卷积操作的空间语义依赖于所选择的填充方案。
- en: 'Padding is an operation to increase the size of the input data. In the case
    of one-dimensional data, you just append/prepend the array with a constant; in
    two-dimensional data, you surround the matrix with these constants. In n-dimensional,
    you surround your n-dimensional hypercube with the constant. In most of the cases,
    this constant is zero and it is called **zero padding**:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 填充是一种增加输入数据大小的操作。在一维数据的情况下，你只需在数组前后添加一个常数；在二维数据的情况下，你会在矩阵的周围添加这些常数。在 n 维数据中，你会在
    n 维超立方体的四周添加常数。在大多数情况下，这个常数是零，称为**零填充**：
- en: '**VALID padding**: Only drops the rightmost columns (or bottommost rows)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VALID 填充**：仅丢弃最右侧的列（或最底部的行）'
- en: '**SAME padding**: Tries to pad evenly left and right, but if the number of
    columns to be added is odd, it will add the extra column to the right, as is the
    case in this example'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SAME 填充**：尽量将左右填充均匀，但如果需要添加的列数为奇数，则会将多余的列添加到右侧，正如这个例子中所示。'
- en: Let's explain the preceding definition graphically, in the following figure.
    If we want a layer to have the same height and width as the previous layer, it
    is common to add zeros around the inputs, as shown in the diagram. This is called
    **SAME** or **zero** **padding**.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下图形来直观地解释前面的定义。如果我们希望某一层与前一层具有相同的高度和宽度，通常会在输入周围添加零，如图所示。这被称为**SAME**或**零填充**。
- en: The term **SAME** means that the output feature map has the same spatial dimensions
    as the input feature map.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**SAME** 这个术语表示输出特征图与输入特征图具有相同的空间维度。'
- en: 'On the other hand, zero padding is introduced to make the shapes match as needed,
    equally on every side of the input map. **VALID** means no padding and only drops
    the rightmost columns (or bottommost rows):'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，零填充被引入以使形状根据需要匹配，并且在输入图上每一侧的填充量相等。**VALID** 意味着没有填充，仅丢弃最右侧的列（或最底部的行）：
- en: '![](img/fdd19f4b-8552-4d31-8035-6101490b48c9.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fdd19f4b-8552-4d31-8035-6101490b48c9.png)'
- en: 'Figure 4: SAME versus VALID padding with CNN'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：CNN 中的 SAME 与 VALID 填充对比
- en: 'In the following example (*Figure 5*), we use a 2 × 2 pooling kernel and a
    stride of 2 with no padding. Only the **max** input value in each kernel makes
    it to the next layer since the other inputs are dropped (we will see this later
    on):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例（*图 5*）中，我们使用一个 2 × 2 的池化核，步长为 2，并且没有填充。每个池化核中的**最大**输入值进入下一层，因为其他输入会被丢弃（稍后我们将看到这一点）：
- en: '![](img/10a39cda-7b65-48aa-8ef5-1f412325d5c7.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/10a39cda-7b65-48aa-8ef5-1f412325d5c7.png)'
- en: 'Figure 5: An example using max pooling, that is, subsampling'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：使用最大池化的示例，即子采样
- en: Fully connected layer
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全连接层
- en: At the top of the stack, a regular fully connected layer (also known as **FNN**
    or **dense layer**) is added; it acts similar to an MLP, which might be composed
    of a few fully connected layers (+ReLUs). The final layer outputs (for example,
    softmax) the prediction. An example is a softmax layer that outputs estimated
    class probabilities for a multiclass classification.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在堆栈的顶部，添加了一个常规的全连接层（也称为**FNN**或**密集层**）；它的作用类似于多层感知器（MLP），该网络可能由若干个全连接层（加 ReLU
    激活函数）组成。最后一层输出（例如 softmax）为预测结果。一个例子是一个 softmax 层，它输出用于多分类任务的估计类别概率。
- en: Fully connected layers connect every neuron in one layer to every neuron in
    another layer. Although fully connected FNNs can be used to learn features as
    well as classify data, it is not practical to apply this architecture to images.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 全连接层将一层中的每个神经元与另一层中的每个神经元连接。尽管全连接的前馈神经网络（FNN）可以用于学习特征和分类数据，但将这种架构应用于图像并不实际。
- en: Convolution and pooling operations in TensorFlow
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 中的卷积和池化操作
- en: Now that we have seen how convolutional and pooling operations are performed
    theoretically, let's see how we can perform these operation hands-on using TensorFlow.
    So let's get started.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经理论上了解了卷积和池化操作的执行方式，接下来我们来看看如何在 TensorFlow 中实际操作这些操作。让我们开始吧。
- en: Applying pooling operations in TensorFlow
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中应用池化操作
- en: 'Using TensorFlow, a subsampling layer can normally be represented by a `max_pool`
    operation by maintaining the initial parameters of the layer. For `max_pool`,
    it has the following signature in TensorFlow:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorFlow时，子采样层通常通过保持该层初始参数来表示为`max_pool`操作。对于`max_pool`，它在TensorFlow中的签名如下：
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now let''s learn how to create a function that utilizes the preceding signature
    and returns a tensor with type `tf.float32`, that is, the max pooled output tensor:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们学习如何创建一个利用前面签名的函数，返回一个类型为`tf.float32`的张量，即最大池化输出张量：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the preceding code segment, the parameters can be described as follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码段中，参数可以描述如下：
- en: '`value`: This is a 4D tensor of `float32` elements and shape (batch length,
    height, width, and channels)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value`：这是一个4D的`float32`张量，形状为（批次长度，高度，宽度和通道数）。'
- en: '`ksize`: A list of integers representing the window size on each dimension'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ksize`：一个整数列表，表示每个维度上的窗口大小'
- en: '`strides`: The step of the moving windows on each dimension'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strides`：每个维度上滑动窗口的步长'
- en: '`data_format`: `NHWC`, `NCHW`, and `NCHW_VECT_C` are supported'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format`：支持`NHWC`、`NCHW`和`NCHW_VECT_C`'
- en: '`ordering`: `NHWC` or `NCHW`'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ordering`：`NHWC`或`NCHW`'
- en: '`padding`: `VALID` or `SAME`'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`：`VALID`或`SAME`'
- en: 'However, depending upon the layering structures in a CNN, there are other pooling
    operations supported by TensorFlow, as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，根据CNN中的层次结构，TensorFlow支持其他的池化操作，如下所示：
- en: '`tf.nn.avg_pool`: This returns a reduced tensor with the average of each window'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.nn.avg_pool`：返回一个包含每个窗口平均值的缩小张量'
- en: '`tf.nn.max_pool_with_argmax`: This returns the `max_pool` tensor and a tensor
    with the flattened index of `max_value`'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.nn.max_pool_with_argmax`：返回`max_pool`张量及其最大值的扁平化索引张量'
- en: '`tf.nn.avg_pool3d`: This performs an `avg_pool` operation with a cubic-like'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.nn.avg_pool3d`：执行一个类似立方体的`avg_pool`操作'
- en: window; the input has an added depth
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 窗口；输入增加了深度
- en: '`tf.nn.max_pool3d`: This performs the same function as (...) but applies the
    max operation'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.nn.max_pool3d`：执行与(...)相同的功能，但应用最大操作'
- en: 'Now let''s see a concrete example of how the padding thing works in TensorFlow.
    Suppose we have an input image `x` with shape `[2, 3]` and one channel. Now we
    want to see the effect of both `VALID` and `SAME` paddings:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一个具体示例，看看填充在TensorFlow中的作用。假设我们有一个形状为`[2, 3]`并且只有一个通道的输入图像`x`。现在我们想看看`VALID`和`SAME`填充的效果：
- en: '`valid_pad`: Max pool with 2 x 2 kernel, stride 2, and `VALID` padding'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`valid_pad`：使用2 x 2的内核，步幅为2，且采用`VALID`填充的最大池化操作'
- en: '`same_pad`: Max pool with 2 x 2 kernel, stride 2, and `SAME` padding'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`same_pad`：使用2 x 2的内核，步幅为2，且采用`SAME`填充的最大池化操作'
- en: 'Let''s see how we can attain this in Python and TensorFlow. Suppose we have
    an input image of shape `[2, 4]`, which is one channel:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在Python和TensorFlow中实现这一点。假设我们有一个形状为`[2, 4]`的输入图像，且只有一个通道：
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now let''s give it a shape accepted by `tf.nn.max_pool`:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们给出`tf.nn.max_pool`接受的形状：
- en: '[PRE4]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If we want to apply the `VALID` padding with the max pool with a 2 x 2 kernel,
    stride 2:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要应用使用2 x 2内核、步幅为2的最大池化，并采用`VALID`填充：
- en: '[PRE5]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'On the other hand, using the max pool with a 2 x 2 kernel, stride 2 and `SAME`
    padding:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，使用2 x 2内核、步幅为2并采用`SAME`填充的最大池化：
- en: '[PRE6]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'For `VALID` padding, since there is no padding, the output shape is `[1, 1]`.
    However, for the `SAME` padding, since we pad the image to the shape `[2, 4]`
    (with - `inf`) and then apply the max pool, the output shape is `[1, 2]`. Let''s
    validate them:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`VALID`填充，由于没有填充，输出形状为`[1, 1]`。然而，对于`SAME`填充，由于我们将图像填充为形状`[2, 4]`（使用-`inf`），然后应用最大池化，输出形状为`[1,
    2]`。让我们验证它们：
- en: '[PRE7]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Convolution operations in TensorFlow
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow中的卷积操作
- en: 'TensorFlow provides a variety of methods for convolution. The canonical form
    is applied by the `conv2d` operation. Let''s have a look at the usage of this
    operation:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow提供了多种卷积方法。经典的形式是通过`conv2d`操作来应用。让我们看看这个操作的用法：
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The parameters we use are as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的参数如下：
- en: '`input`: The operation will be applied to this original tensor. It has a definite
    format of four dimensions, and the default dimension order is shown next.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input`：该操作将应用于这个原始张量。它有四个维度的确定格式，默认的维度顺序如下所示。'
- en: '`filter`: This is a tensor representing a kernel or filter. It has a very generic
    method: (`filter_height`, `filter_width`, `in_channels`, and `out_channels`).'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filter`：这是一个表示内核或滤波器的张量。它有一个非常通用的方法：（`filter_height`，`filter_width`，`in_channels`和`out_channels`）。'
- en: '`strides`: This is a list of four `int` tensor datatypes, which indicate the
    sliding windows for each dimension.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strides`：这是一个包含四个`int`类型张量的数据列表，表示每个维度的滑动窗口。'
- en: '`padding`: This can be `SAME` or `VALID`. `SAME` will try to conserve the initial
    tensor dimension, but `VALID` will allow it to grow if the output size and padding
    are computed. We will see later how to perform padding along with the pooling
    layers.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`：可以是 `SAME` 或 `VALID`。`SAME` 会尽量保持初始张量维度不变，而 `VALID` 则允许其在输出大小和填充计算的情况下增长。稍后我们将看到如何在池化层中执行填充操作。'
- en: '`use_cudnn_on_gpu`: This indicates whether to use the `CUDA GPU CNN` library
    to accelerate calculations.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_cudnn_on_gpu`：这表示是否使用 `CUDA GPU CNN` 库来加速计算。'
- en: '`data_format`: This specifies the order in which data is organized (`NHWC`
    or `NCWH`).'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format`：指定数据组织的顺序（`NHWC` 或 `NCWH`）。'
- en: '`dilations`: This signifies an optional list of `ints`. It defaults to (1,
    1, 1, 1). 1D tensor of length 4\. The dilation factor for each dimension of input.
    If it is set to k > 1, there will be k-1 skipped cells between each filter element
    on that dimension. The dimension order is determined by the value of `data_format`;
    see the preceding code example for details. Dilations in the batch and depth dimensions
    must be 1.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dilations`：这表示一个可选的 `ints` 列表，默认为 (1, 1, 1, 1)。长度为 4 的 1D 张量，表示每个输入维度的扩张因子。如果设置为
    k > 1，则在该维度的每个滤波器元素之间会有 k-1 个跳过的单元。维度的顺序由 `data_format` 的值决定；有关详情，请参见前面的代码示例。批处理和深度维度的扩张因子必须为
    1。'
- en: '`name`: A name for the operation (optional).'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：操作的名称（可选）。'
- en: 'The following is an example of a convolutional layer. It concatenates a convolution,
    adds a bias parameter sum, and finally returns the activation function we have
    chosen for the whole layer (in this case, the ReLU operation, which is a frequently
    used one):'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个卷积层的示例。它将卷积操作连接起来，添加一个偏置参数的和，最后返回我们为整个层选择的激活函数（在本例中为 ReLU 操作，这是一个常用的操作）：
- en: '[PRE9]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here, x is the 4D tensor input (batch size, height, width, and channel). TensorFlow
    also offers a few other kinds of convolutional layers. For example:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，x 是 4D 张量输入（批处理大小、高度、宽度和通道）。TensorFlow 还提供了其他几种卷积层。例如：
- en: '`tf.layers.conv1d()` creates a convolutional layer for 1D inputs. This is useful,
    for example, in NLP, where a sentence may be represented as a 1D array of words,
    and the receptive field covers a few neighboring words.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.layers.conv1d()` 创建一个用于 1D 输入的卷积层。例如，在自然语言处理（NLP）中，句子可以表示为一个 1D 的单词数组，感受野覆盖几个相邻的单词。'
- en: '`tf.layers.conv3d()` creates a convolutional layer for 3D inputs.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.layers.conv3d()` 创建一个用于 3D 输入的卷积层。'
- en: '`tf.nn.atrous_conv2d()` creates an a trous convolutional layer (*a* tro*us*
    is French for with holes). This is equivalent to using a regular convolutional
    layer with a filter dilated by inserting rows and columns of zeros. For example,
    a 1 × 3 filter equal to (1, 2, 3) may be dilated with a dilation rate of 4, resulting
    in a dilated filter (1, 0, 0, 0, 2, 0, 0, 0, 3). This allows the convolutional
    layer to have a larger receptive field at no computational price and using no
    extra parameters.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.nn.atrous_conv2d()` 创建了一个空洞卷积层（*a* tro*us* 是法语中“带孔”的意思）。这相当于使用一个常规卷积层，并通过插入零行和零列来扩展滤波器。例如，一个
    1 × 3 的滤波器（1, 2, 3）可以通过扩张率为 4 来扩展，得到扩张后的滤波器（1, 0, 0, 0, 2, 0, 0, 0, 3）。这使得卷积层可以在不增加计算量和额外参数的情况下拥有更大的感受野。'
- en: '`tf.layers.conv2d_transpose ()` creates a transpose convolutional layer, sometimes
    called a **deconvolutional layer,** which up-samples an image. It does so by inserting
    zeros between the inputs, so you can think of this as a regular convolutional
    layer using a fractional stride.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.layers.conv2d_transpose()` 创建了一个转置卷积层，有时也称为 **反卷积层**，它用于上采样图像。它通过在输入之间插入零来实现，因此可以将其视为一个使用分数步幅的常规卷积层。'
- en: '`tf.nn.depthwise_conv2d()` creates a depth-wise convolutional layer that applies
    every filter to every individual input channel independently. Thus, if there are
    *f[n]* filters and *f[n]*[′] input channels, then this will output *f[n ]*× *f[n]*[′]
    feature maps.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.nn.depthwise_conv2d()` 创建了一个深度卷积层，它将每个滤波器独立应用于每个输入通道。因此，如果有 *f[n]* 个滤波器和
    *f[n]*[′] 个输入通道，那么这将输出 *f[n ]*× *f[n]*[′] 个特征图。'
- en: '`tf.layers.separable_conv2d()` creates a separable convolutional layer that
    first acts like a depth-wise convolutional layer and then applies a 1 × 1 convolutional
    layer to the resulting feature maps. This makes it possible to apply filters to
    arbitrary sets of inputs channels.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.layers.separable_conv2d()` 创建了一个可分离卷积层，首先像深度卷积层一样工作，然后对结果特征图应用 1 × 1 的卷积层。这使得可以将滤波器应用于任意输入通道的集合。'
- en: Training a CNN
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练 CNN
- en: In the previous section, we have seen how to construct a CNN and apply different
    operations on its different layers. Now when it comes to training a CNN, it is
    much trickier as it needs a lot of considerations to control those operations
    such as applying appropriate activation function, weight and bias initialization,
    and of course, using optimizers intelligently.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们已经看到如何构建CNN并在其不同层上应用不同操作。现在，当涉及训练CNN时，由于需要考虑控制这些操作（如应用适当的激活函数、权重和偏置初始化，当然还有智能使用优化器），这变得更加棘手。
- en: There are also some advanced considerations such as hyperparameter tuning for
    optimized too. However, that will be discussed in the next section. We first start
    our discussion with weight and bias initialization.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些高级考虑因素，如优化的超参数调整。然而，这将在下一节讨论。我们首先从权重和偏置初始化开始我们的讨论。
- en: Weight and bias initialization
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 权重和偏置初始化
- en: One of the most common initialization techniques in training a DNN is random
    initialization. The idea of using random initialization is just sampling each
    weight from a normal distribution of the input dataset with low deviation. Well,
    a low deviation allows you to bias the network towards the simple 0 solutions.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练DNN中，最常见的初始化技术之一是随机初始化。使用随机初始化的想法是从输入数据集的正态分布中抽样每个权重，具有低偏差。低偏差可以使网络偏向简单的0解决方案。
- en: 'But what does it mean? The thing is that, the initialization can be completed
    without the bad repercussions of actually initializing the weights to 0\. Secondly,
    Xavier initialization is often used to train CNNs. It is similar to random initialization
    but often turns out to work much better. Now let me explain the reason for this:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 但这意味着什么呢？事实是，初始化可以完成，而不会造成将权重初始化为0的坏影响。其次，Xavier初始化经常用于训练CNN。它类似于随机初始化，但通常效果要好得多。现在让我解释一下原因：
- en: Imagine that you initialize the network weights randomly but they turn out to
    start too small. Then the signal shrinks as it passes through each layer until
    it is too tiny to be useful.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想象一下，您随机初始化网络权重，但它们却开始太小。然后，信号通过每一层时会收缩，直到变得太微小而无用。
- en: On the other hand, if the weights in a network start too large, then the signal
    grows as it passes through each layer until it is too massive to be useful.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，如果网络中的权重开始过大，则信号在通过每一层时会增长，直到变得太大而无用。
- en: The good thing is that using Xavier initialization makes sure the weights are
    just right, keeping the signal in a reasonable range of values through many layers.
    In summary, it can automatically determine the scale of initialization based on
    the number of input and output neurons.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 好处在于使用Xavier初始化确保权重恰到好处，通过许多层保持信号在合理范围内的值。总结一下，它可以根据输入和输出神经元的数量自动确定初始化的比例。
- en: 'Interested readers should refer to this publication for detailed information:
    Xavier Glorot and Yoshua Bengio, *Understanding the difficulty of training deep
    FNNs*, Proceedings of the 13th International Conference on **Artificial Intelligence
    and Statistics** (**AISTATS**) 2010, Chia Laguna Resort, Sardinia, Italy. Volume
    9 of JMLR: W&CP.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 有兴趣的读者应参考这篇论文获取详细信息：Xavier Glorot 和 Yoshua Bengio，《*理解训练深度前馈神经网络的困难*》，第13届人工智能和统计学会议（**AISTATS**）2010年，位于意大利撒丁岛的Chia
    Laguna Resort。JMLR的第9卷：W&CP。
- en: 'Finally, you may ask an intelligent question, *Can''t I get rid of the random
    initialization while training a regular DNN (for example, MLP or DBN)*? Well,
    recently, some researchers have been talking about random orthogonal matrix initializations
    that perform better than just any random initialization for training DNNs:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可能会问一个聪明的问题，*在训练常规的DNN（例如MLP或DBN）时，我不能摆脱随机初始化吗*？嗯，最近，一些研究人员提到了随机正交矩阵初始化，这种初始化比单纯的任意随机初始化效果更好。
- en: '**When it comes to initializing the biases**, it is possible and common to
    initialize the biases to be zero since the asymmetry breaking is provided by the
    small random numbers in the weights. Setting the biases to a small constant value
    such as 0.01 for all biases ensures that all ReLU units can propagate some gradient.
    However, it neither performs well nor does consistent improvement. Therefore,
    sticking with zero is recommended.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**当涉及初始化偏置时**，将偏置初始化为零是可能且常见的，因为权重中的小随机数提供了不对称性破坏。将所有偏置设置为一个小常数值，如0.01，可以确保所有ReLU单元可以传播一些梯度。然而，它既表现不佳，也没有持续改进。因此，建议坚持使用零值。'
- en: Regularization
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则化
- en: 'There are several ways of controlling training of CNNs to prevent overfitting
    in the training phase. For example, L2/L1 regularization, max norm constraints,
    and drop out:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方法可以控制 CNN 的训练，以防止在训练阶段出现过拟合。例如，L2/L1 正则化、最大范数约束和 dropout：
- en: '**L2 regularization**: This is perhaps the most common form of regularization.
    It can be implemented by penalizing the squared magnitude of all parameters directly
    in the objective. For example, using the gradient descent parameter update, L2
    regularization ultimately means that every weight is decayed linearly: *W += -*lambda
    * *W* towards zero.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**L2 正则化**：这可能是最常见的正则化形式。它可以通过在目标函数中直接惩罚所有参数的平方大小来实现。例如，使用梯度下降更新参数时，L2 正则化最终意味着每个权重都以线性方式衰减：*W
    += -*lambda * *W* 向零靠拢。'
- en: '**L1 regularization**: This is another relatively common form of regularization,
    where for each weight *w* we add the term *λ∣w∣* to the objective. However, it
    is also possible to possible to combine the L1 regularization with the L2 regularization:
    *λ1∣w∣+λ2w2*, which is commonly known as **Elastic-net regularization**.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**L1 正则化**：这是另一种相对常见的正则化形式，对于每个权重 *w*，我们将项 *λ∣w∣* 加入到目标函数中。然而，也可以将 L1 正则化与
    L2 正则化结合起来：*λ1∣w∣+λ2w2*，这通常被称为 **弹性网正则化**。'
- en: '**Max-norm constraints**: Another form of regularization is to enforce an absolute
    upper bound on the magnitude of the weight vector for every neuron and use projected
    gradient descent to enforce the constraint.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大范数约束**：另一种正则化形式是对每个神经元的权重向量的绝对值设定上限，并使用投影梯度下降法来强制实施这一约束。'
- en: Finally, dropout is an advanced variant of regularization, which will be discussed
    later in this chapter.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，dropout 是正则化的一种高级变体，稍后将在本章中讨论。
- en: Activation functions
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 激活函数
- en: The activation ops provide different types of nonlinearities for use in neural
    networks. These include smooth nonlinearities, such as `sigmoid`, `tanh`, `elu`,
    `softplus`, and `softsign`. On the other hand, some continuous but not-everywhere-differentiable
    functions that can be used are `relu`, `relu6`, `crelu`, and `relu_x`. All activation
    ops apply component-wise and produce a tensor of the same shape as the input tensor.
    Now let us see how to use a few commonly used activation functions in TensorFlow
    syntax.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 激活操作提供了不同类型的非线性函数，用于神经网络中。这些包括平滑的非线性函数，如`sigmoid`、`tanh`、`elu`、`softplus`和`softsign`。另一方面，也可以使用一些连续但在某些点不可导的函数，如`relu`、`relu6`、`crelu`和`relu_x`。所有激活操作都是逐元素应用，并产生与输入张量形状相同的张量。现在，让我们看看如何在
    TensorFlow 语法中使用一些常见的激活函数。
- en: Using sigmoid
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 sigmoid
- en: 'In TensorFlow, the signature `tf.sigmoid(x, name=None)` computes sigmoid of
    `x` element-wise using *y = 1 / (1 + exp(-x))* and returns a tensor with the same
    type `x`. Here is the parameter description:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中，签名 `tf.sigmoid(x, name=None)` 按元素计算 `x` 的 sigmoid 函数，使用 *y =
    1 / (1 + exp(-x))*，并返回一个与 `x` 类型相同的张量。下面是参数的描述：
- en: '`x`: A tensor. This must be one of the following types: `float32`, `float64`,
    `int32`, `complex64`, `int64`, or `qint32`.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：一个张量。它必须是以下类型之一：`float32`、`float64`、`int32`、`complex64`、`int64` 或 `qint32`。'
- en: '`name`: A name for the operation (optional).'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：操作的名称（可选）。'
- en: Using tanh
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 tanh
- en: 'In TensorFlow, the signature `tf.tanh(x, name=None)` computes a hyperbolic
    tangent of `x` element-wise and returns a tensor with the same type `x`. Here
    is the parameter description:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中，签名 `tf.tanh(x, name=None)` 按元素计算 `x` 的双曲正切，并返回一个与 `x` 类型相同的张量。下面是参数的描述：
- en: '`x`: A tensor or sparse. This is a tensor with type `float`, `double`, `int32`,
    `complex64`, `int64`, or `qint32`.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：一个张量或稀疏张量。它的类型可以是 `float`、`double`、`int32`、`complex64`、`int64` 或 `qint32`。'
- en: '`name`: A name for the operation (optional).'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：操作的名称（可选）。'
- en: Using ReLU
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 ReLU
- en: 'In TensorFlow, the signature `tf.nn.relu(features, name=None)` computes a rectified
    linear using `max(features, 0)` and returns a tensor having the same type as features.
    Here is the parameter description:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中，签名 `tf.nn.relu(features, name=None)` 计算使用 `max(features, 0)`
    的修正线性函数，并返回一个与 features 类型相同的张量。下面是参数的描述：
- en: '`features`: A tensor. This must be one of the following types: `float32`, `float64`,
    `int32`, `int64`, `uint8`, `int16`, `int8`, `uint16`, and `half`.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`features`：一个张量。它必须是以下类型之一：`float32`、`float64`、`int32`、`int64`、`uint8`、`int16`、`int8`、`uint16`
    和 `half`。'
- en: '`name`: A name for the operation (optional).'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：操作的名称（可选）。'
- en: For more on how to use other activation functions, please refer to the TensorFlow
    website. Up to this point, we have the minimal theoretical knowledge to build
    our first CNN network for making a prediction.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何使用其他激活函数，请参考 TensorFlow 官网。到目前为止，我们已经具备了构建第一个 CNN 网络进行预测的最基础理论知识。
- en: Building, training, and evaluating our first CNN
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建、训练和评估我们的第一个 CNN
- en: In the next section, we will look at how to classify and distinguish between
    dogs from cats based on their raw images. We will also look at how to implement
    our first CNN model to deal with the raw and color image having three channels.
    This network design and implementation are not straightforward; TensorFlow low-level
    APIs will be used for this. However, do not worry; later in this chapter, we will
    see another example of implementing a CNN using TensorFlow's high-level contrib
    API. Before we formally start, a short description of the dataset is a mandate.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨如何基于原始图像对狗和猫进行分类和区分。我们还将学习如何实现我们的第一个 CNN 模型，以处理具有三个通道的原始彩色图像。这个网络设计和实现并不简单；我们将使用
    TensorFlow 的低级 API 来实现。然而，不用担心；在本章的后面，我们将看到如何使用 TensorFlow 的高级 contrib API 实现
    CNN 模型。正式开始之前，先简单介绍一下数据集。
- en: Dataset description
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集描述
- en: For this example, we will use the dog versus cat dataset from Kaggle that was
    provided for the infamous Dogs versus Cats classification problem as a playground
    competition with kernels enabled. The dataset can be downloaded from [https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用 Kaggle 提供的狗与猫数据集，它用于著名的“狗与猫分类”问题，这是一个提供内核支持的竞赛数据集。数据集可以从[https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data)下载。
- en: The train folder contains 25,000 images of dogs and cats. Each image in this
    folder has the label as part of the filename. The test folder contains 12,500
    images, named according to a numeric ID. For each image in the test set, you should
    predict a probability that the image is a dog (1 = dog, 0 = cat); that is, a binary
    classification problem. For this example, there are three Python scripts.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 训练文件夹包含 25,000 张狗和猫的图像。该文件夹中的每个图像的标签是文件名的一部分。测试文件夹包含 12,500 张图像，文件名是数字 ID。对于测试集中的每个图像，您应该预测该图像是狗的概率（1
    = 狗，0 = 猫）；也就是说，这是一个二分类问题。对于这个例子，有三个 Python 脚本。
- en: Step 1 – Loading the required packages
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤 1 – 加载所需的包
- en: 'Here we import the required packages and libraries. Note that depending upon
    the platform, your imports might be different:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们导入所需的包和库。请注意，您的导入可能会根据平台不同而有所不同：
- en: '[PRE10]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Step 2 – Loading the training/test images to generate train/test set
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤 2 – 加载训练/测试图像以生成训练/测试集
- en: 'We set the number of color channels as 3 for the images. In the previous section,
    we have seen that it should be 1 for grayscale images:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将图像的颜色通道数量设置为 3。在前面的章节中，我们已经看到，对于灰度图像，它的通道数量应为 1：
- en: '[PRE11]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'For the simplicity, we assume the image dimensions should be squares only.
    Let''s set the size to be `128`:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化问题，我们假设图像的尺寸应该是正方形的。我们将尺寸设置为`128`：
- en: '[PRE12]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now that we have the image size (that is, `128`) and the number of the channel
    (that is, 3), the size of the image when flattened to a single dimension would
    be the multiplication of the image dimension and the number of channels, as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了图像的大小（即 `128`）和通道的数量（即 3），图像展开为一维时，图像的大小将是图像尺寸与通道数量的乘积，如下所示：
- en: '[PRE13]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Note that, at a later stage, we might need to reshape the image for the max
    pooling and convolutional layers, so we need to reshape the image. For our case,
    it would be the tuple with height and width of images used to reshape arrays:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在后续步骤中，我们可能需要对图像进行重塑，以便适应最大池化层和卷积层，因此我们需要对图像进行重塑。对于我们的情况，它将是一个包含图像高度和宽度的元组，用于重塑数组：
- en: '[PRE14]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We should have explicitly defined the labels (that is, classes) since we only
    have the raw color image, and so the images do not have the labels like other
    numeric machine learning dataset, have. Let''s explicitly define the class info
    as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只有原始彩色图像，并且这些图像没有像其他数字机器学习数据集那样带有标签，因此我们应该明确地定义标签（即类）。让我们如下明确定义类信息：
- en: '[PRE15]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We need to define the batch size that needs to be trained on our CNN model
    later on:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要定义稍后在 CNN 模型上训练的批量大小：
- en: '[PRE16]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Note that we also can define what portion of the training set will be used
    as the validation split. Let''s assume that 16% will be used, for simplicity:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们还可以定义训练集的哪一部分将作为验证集。为了简便起见，假设使用16%的数据：
- en: '[PRE17]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'One important thing to set is how long to wait after the validation loss stops
    improving before terminating the training. We should use none if we do not want
    to implement early stopping:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的设置是，在验证损失停止改善后，等待多长时间再终止训练。如果我们不想实现早停，应该使用`none`：
- en: '[PRE18]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, download the dataset and you have to do one thing manually: separate the
    images of dogs and cats and place them in two separate folders. To be more specific,
    suppose you put your training set under the path `/home/DoG_CaT/data/train/`.
    In the train folder, create two separate folders `dogs` and `cats` but only show
    the path to `DoG_CaT/data/train/`. We also assume that our test set is in the
    `/home/DoG_CaT/data/test/` directory. In addition, you can define the checkpoint
    directory where the logs and model checkpoint files will be written:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，下载数据集后，你需要手动做一件事：将狗和猫的图片分开并放入两个不同的文件夹中。具体来说，假设你将训练集放在路径`/home/DoG_CaT/data/train/`下。在train文件夹中，创建两个单独的文件夹`dogs`和`cats`，但只显示`DoG_CaT/data/train/`的路径。我们还假设我们的测试集位于`/home/DoG_CaT/data/test/`目录中。此外，你可以定义检查点目录，在该目录中将写入日志和模型检查点文件：
- en: '[PRE19]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Then we start reading the training set and prepare it for the CNN model. For
    processing the test and train set, we have another script `Preprocessor.py`. Nonetheless,
    it would be better to prepare the test set as well**:**
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们开始读取训练集并为CNN模型做准备。处理测试集和训练集时，我们有另一个脚本`Preprocessor.py`。不过，最好也准备好测试集**：**
- en: '[PRE20]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The preceding line of code reads the raw images of cats and dogs and creates
    the training set. The `read_train_sets()` function goes as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码行读取猫和狗的原始图像并创建训练集。`read_train_sets()`函数的定义如下：
- en: '[PRE21]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In the previous code segment, we have used the method `load_train()` to load
    the images which is an instance of a class called `DataSet`:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码段中，我们使用了`load_train()`方法来加载图像，它是`DataSet`类的一个实例：
- en: '[PRE22]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `DataSet` class, which is used to generate the batches of the training
    set, is as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataSet`类用于生成训练集的批次，其定义如下：'
- en: '[PRE23]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, similarly, we prepare the test set from the test images that are mixed
    (dogs and cats):'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，类似地，我们从混合的测试图像（狗和猫）中准备测试集：
- en: '[PRE24]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We have the `read_test_set()` function for ease, as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有`read_test_set()`函数来简化此过程，代码如下：
- en: '[PRE25]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, similar to the training set, we have a dedicated function called `load_test
    ()` for loading the test set, which goes as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，和训练集类似，我们有一个专门的函数`load_test()`来加载测试集，代码如下：
- en: '[PRE26]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Well done! We can now see some randomly selected images. For this, we have
    the helper function called `plot_images()`; it creates a figure with 3 x 3 sub-plots.
    So, all together, nine images will be plotted, along with their true label. It
    goes as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 做得好！现在我们可以看到一些随机选取的图像。为此，我们有一个辅助函数`plot_images()`；它创建一个包含3 x 3子图的图形。总共会绘制九张图像，并显示它们的真实标签。其代码如下：
- en: '[PRE27]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let''s get some random images and their labels from the train set:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从训练集中随机获取一些图像及其标签：
- en: '[PRE28]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Finally, we plot the images and labels using our helper-function in the preceding
    code:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用前面代码中的辅助函数绘制图像和标签：
- en: '[PRE29]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The preceding line of code generates the true labels of the images that are
    randomly selected:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码行生成从训练集中随机选取的图像的真实标签：
- en: '![](img/c9839726-b1c1-4883-87a7-19b3883db8a9.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9839726-b1c1-4883-87a7-19b3883db8a9.png)'
- en: 'Figure 6: The true labels of the images that are randomly selected'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：从训练集中随机选取的图像的真实标签
- en: 'Finally, we can print the dataset statistics:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以打印数据集的统计信息：
- en: '[PRE30]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Step 3- Defining CNN hyperparameters
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3步 - 定义CNN超参数
- en: 'Now that we have the training and test set, it''s time to define the hyperparameters
    for the CNN model before we start constructing. In the first and the second convolutional
    layers, we define the width and height of each filter, that is, `3`, where the
    number of filters is `32`:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了训练集和测试集，是时候在开始构建CNN模型之前定义超参数了。在第一层和第二层卷积层中，我们定义了每个滤波器的宽度和高度，即`3`，而滤波器的数量是`32`：
- en: '[PRE32]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The third convolutional layer has equal dimensions but twice the filters; that
    is, `64` filters:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 第三层卷积层的维度相同，但滤波器数量是原来的两倍；也就是`64`个滤波器：
- en: '[PRE33]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The last two layers are fully connected layers, specifying the number of neurons:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两层是全连接层，指定神经元的数量：
- en: '[PRE34]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now let''s make the training slower for more intensive training by setting
    a lower value of the learning rate, as follows:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过设置较低的学习率来使训练变慢，以进行更为密集的训练，如下所示：
- en: '[PRE35]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Step 4 – Constructing the CNN layers
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4步 – 构建CNN层
- en: 'Once we have defined the CNN hyperparameters, the next task is to implement
    the CNN network. As you can guess, for our task, we will construct a CNN network
    having three convolutional layers, a flattened layer and two fully connected layers
    (refer to `LayersConstructor.py`). Moreover, we need to define the weight and
    the bias as well. Furthermore, we will have implicit max-pooling layers too. At
    first, let''s define the weight. In the following, we have the `new_weights()`
    method that asks for the image shape and returns the truncated normal shapes:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们定义了CNN的超参数，下一步就是实现CNN网络。正如你所猜测的，我们的任务将构建一个包含三个卷积层、一个展平层和两个全连接层的CNN网络（参见`LayersConstructor.py`）。此外，我们还需要定义权重和偏置。此外，我们还会有隐式的最大池化层。首先，让我们定义权重。在下面，我们有`new_weights()`方法，它需要图像形状并返回截断正态形状：
- en: '[PRE36]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Then we define the biases using the `new_biases()` method:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 接着我们使用`new_biases()`方法来定义偏置：
- en: '[PRE37]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now let''s define a method, `new_conv_layer()`, for constructing a convolutional
    layer. The method takes the input batch, number of input channels, filter size,
    and number of filters and it also uses the max pooling (if true, we use a 2 x
    2 max pooling) to construct a new convolutional layer. The workflow of the method
    is as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们定义一个方法，`new_conv_layer()`，用于构建卷积层。该方法接受输入批次、输入通道数、滤波器大小和滤波器数量，并且它还使用最大池化（如果为真，则使用2
    x 2的最大池化）来构建新的卷积层。该方法的工作流程如下：
- en: Define the shape of the filter weights for the convolution, which is determined
    by the TensorFlow API.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义卷积的滤波器权重的形状，这由TensorFlow API决定。
- en: Create the new weights (that is, filters) with the given shape and new biases,
    one for each filter.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建具有给定形状和新偏置的新权重（即滤波器），每个滤波器一个偏置。
- en: Create the TensorFlow operation for the convolution where the strides are set
    to 1 in all dimensions. The first and last stride must always be 1, because the
    first is for the image-number and the last is for the input channel. For example,
    strides= (1, 2, 2, 1) would mean that the filter is moved two pixels across the
    *x* axis and *y* axis of the image.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建卷积的TensorFlow操作，其中步幅在所有维度上都设置为1。第一个和最后一个步幅必须始终为1，因为第一个是为了图像编号，最后一个是为了输入通道。例如，strides=
    (1, 2, 2, 1)意味着滤波器在图像的*x*轴和*y*轴上各移动两个像素。
- en: Add the biases to the results of the convolution. Then a bias-value is added
    to each filter-channel.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将偏置添加到卷积的结果中。然后将偏置值添加到每个滤波器通道中。
- en: It then uses the pooling to downsample the image resolution. This is 2 x 2 max
    pooling, which means that we consider 2 x 2 windows and select the largest value
    in each window. Then we move two pixels to the next window.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它使用池化来下采样图像分辨率。这是2 x 2的最大池化，意味着我们考虑2 x 2的窗口，并在每个窗口中选择最大的值。然后我们将窗口移动两个像素。
- en: ReLU is then used to calculate the *max(x, 0)* for each input pixel *x*. As
    stated earlier, a ReLU is normally executed before the pooling, but since `relu(max_pool(x))
    == max_pool(relu(x))` we can save 75% of the relu-operations by max-pooling first.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后使用ReLU来计算每个输入像素*x*的*max(x, 0)*。如前所述，ReLU通常在池化之前执行，但由于`relu(max_pool(x)) ==
    max_pool(relu(x))`，我们可以通过先进行最大池化来节省75%的ReLU操作。
- en: Finally, it returns both the resulting layer and the filter-weights because
    we will plot the weights later.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，它返回结果层和滤波器权重，因为我们稍后会绘制权重。
- en: 'Now we define a function to construct the convolutional layer to be used:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们定义一个函数来构建要使用的卷积层：
- en: '[PRE38]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The next task is to define the flattened layer:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是定义展平层：
- en: Get the shape of the input layer.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取输入层的形状。
- en: The number of features is `img_height * img_width * num_channels`. The `get_shape()`
    function TensorFlow is used to calculate this.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特征数量为`img_height * img_width * num_channels`。`get_shape()`函数在TensorFlow中用于计算这一点。
- en: It will then reshape the layer to (`num_images` and `num_features`). We just
    set the size of the second dimension to `num_features` and the size of the first
    dimension to -1, which means the size in that dimension is calculated so the total
    size of the tensor is unchanged from the reshaping.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它将重塑该层为（`num_images` 和 `num_features`）。我们只需将第二维的大小设置为`num_features`，而第一维的大小设置为-1，这意味着在该维度中的大小会被计算出来，以便重塑后张量的总大小不变。
- en: Finally, it returns both the flattened layer and the number of features.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，它返回展平层和特征数量。
- en: 'The following code does exactly the same as described before `defflatten_layer(layer)`:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码与之前描述的`defflatten_layer(layer)`完全相同：
- en: '[PRE39]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Finally, we need to construct the fully connected layers. The following function,
    `new_fc_layer()`, takes the input batches, number of batches, and number of outputs
    (that is, predicted classes) and it uses the ReLU. It then creates the weights
    and biases based on the methods we define earlier in this step. Finally, it calculates
    the layer as the matrix multiplication of the input and weights, and then adds
    the bias values:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要构建全连接层。以下函数`new_fc_layer()`接受输入批次、批次数和输出数量（即预测的类别）。它使用ReLU，然后基于我们之前定义的方法创建权重和偏置。最后，它通过输入与权重的矩阵乘法计算该层，并加上偏置值：
- en: '[PRE40]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Step 5 – Preparing the TensorFlow graph
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5步 – 准备TensorFlow图
- en: 'We now create the placeholders for the TensorFlow graph:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们为TensorFlow图创建占位符：
- en: '[PRE41]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Step 6 – Creating a CNN model
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6步 – 创建CNN模型
- en: 'Now we have the input; that is, `x_image` is ready to feed to the convolutional
    layer. We formally create a convolutional layer, followed by the max pooling:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了输入；即`x_image`，它已经准备好输入到卷积层。我们正式创建卷积层，后接最大池化：
- en: '[PRE42]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We must have the second convolutional layer, where the input is the first convolutional
    layer, `layer_conv1`, followed by the max pooling:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须有第二个卷积层，其中输入是第一个卷积层`layer_conv1`，后接最大池化：
- en: '[PRE43]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We now have the third convolutional layer where the input is the output of
    the second convolutional layer, that is, `layer_conv2` followed by the max pooling:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了第三个卷积层，其中输入是第二个卷积层的输出，即`layer_conv2`，后面接着最大池化：
- en: '[PRE44]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Once the third convolutional layer is instantiated, we then instantiate the
    flattened layer as follows:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦第三个卷积层实例化，我们接着实例化平坦化层，如下所示：
- en: '[PRE45]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Once we have flattened the images, they are ready to be fed to the first fully
    connected layer. We use the ReLU:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将图像进行平坦化处理，它们就可以输入到第一个全连接层。我们使用ReLU：
- en: '[PRE46]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Finally, we have to have the second and the final fully connected layer where
    the input is the output of the first fully connected layer:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要第二个也是最后一个全连接层，其中输入是第一个全连接层的输出：
- en: '[PRE47]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Step 7 – Running the TensorFlow graph to train the CNN model
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7步 – 运行TensorFlow图以训练CNN模型
- en: 'The following steps are used to perform the training. The codes are self-explanatory,
    like the ones that we have already used in our previous examples. We use softmax
    to predict the classes by comparing them with true classes:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的步骤用于执行训练。代码与我们之前示例中使用的代码一样，易于理解。我们使用softmax通过与真实类别进行比较来预测类别：
- en: '[PRE48]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We define the `cost` function and then the optimizer (Adam optimizer in this
    case). Then we compute the accuracy:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义`cost`函数，然后是优化器（在这里使用Adam优化器）。接着我们计算准确率：
- en: '[PRE49]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Then we initialize all the ops using the `global_variables_initializer()` function
    from TensorFlow:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用TensorFlow的`global_variables_initializer()`函数初始化所有操作：
- en: '[PRE50]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Then we create and run the TensorFlow session to carry the training across
    the tensors:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建并运行TensorFlow会话，执行跨张量的训练：
- en: '[PRE51]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We then feed out training data so that the batch size to 32 (see *Step 2*):'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们输入训练数据，将批量大小设置为32（参见*步骤2*）：
- en: '[PRE52]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We maintain two lists to track the training and validation accuracy:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们保持两个列表来跟踪训练和验证的准确性：
- en: '[PRE53]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We then count the total number of iterations performed so far and create an
    empty list to keep track of all the iterations:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们计算到目前为止已执行的总迭代次数，并创建一个空列表来跟踪所有迭代：
- en: '[PRE54]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We formally start the training by invoking the `optimize()` function, which
    takes a number of iterations. It needs two:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过调用`optimize()`函数正式开始训练，该函数需要指定若干迭代次数。它需要两个参数：
- en: The `x_batch` of training examples that holds a batch of images and
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x_batch`是训练样本，其中包含一批图像'
- en: '`y_true_batch`, the true labels for those images'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_true_batch`，这些图像的真实标签'
- en: It then converts the shape of each image from (`num` examples, rows, columns,
    depth) to (`num` examples, flattened image shape). After that, we put the batch
    into a `dict` for placeholder variables in the TensorFlow graph. Later on, we
    run the optimizer on the batch of training data.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 它将每张图像的形状从（`num`个示例，行，列，深度）转换为（`num`个示例，平坦化图像形状）。之后，我们将批次放入TensorFlow图的`dict`占位符变量中。接下来，我们在训练数据批次上运行优化器。
- en: 'Then, TensorFlow assigns the variables in `feed_dict_train` to the placeholder
    variables. Optimizer is then executed to print the status at end of each epoch.
    Finally, it updates the total number of iterations that we performed:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，TensorFlow 将 `feed_dict_train` 中的变量分配给占位符变量。接着执行优化器，在每个 epoch 结束时打印状态。最后，更新我们已执行的总迭代次数：
- en: '[PRE55]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: We will show how our training went along in the next section.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一部分展示我们的训练进展。
- en: Step 8 – Model evaluation
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步骤 8 – 模型评估
- en: We have managed to finish the training. It is time to evaluate the model. Before,
    we start evaluating the model, let's implement some auxiliary functions for plotting
    the example errors and printing the validation accuracy. The `plot_example_errors()`
    takes two parameters. The first is `cls_pred`, which is an array of the predicted
    class-number for all images in the test set.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了训练。现在是时候评估模型了。在开始评估模型之前，我们先实现一些辅助函数，用于绘制示例错误并打印验证准确率。`plot_example_errors()`
    接受两个参数，第一个是 `cls_pred`，它是一个数组，包含测试集中所有图像的预测类别编号。
- en: 'The second parameter, `correct`, is a `boolean` array to predict whether the
    predicted class is equal to `true` class for each image in the test set. At first,
    it gets the images from the test set that have been incorrectly classified. Then
    it gets the predicted and the true classes for those images, and finally it plots
    the first nine images with their classes (that is, predicted versus true labels):'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个参数 `correct` 是一个 `boolean` 数组，用于预测每个测试集中的图像的预测类别是否与 `true` 类别相等。首先，它获取测试集中分类错误的图像。然后，它获取这些图像的预测类别和真实类别，最后绘制前九张图像及其类别（即，预测类别与真实标签的对比）：
- en: '[PRE56]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The second auxiliary function is called `print_validation_accuracy()`; it prints
    the validation accuracy. It allocates an array for the predicted classes, which
    will be calculated in batches and filled into this array, and then it calculates
    the predicted classes for the batches:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个辅助函数叫做 `print_validation_accuracy()`，它打印验证准确率。该函数为预测类别分配一个数组，这些预测类别将在批次中计算并填充到此数组中，接着计算每个批次的预测类别：
- en: '[PRE57]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Now that we have our auxiliary functions, we can start the optimization. At
    the first place, let''s iterate the fine-tuning 10,000 times and see the performance:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了辅助函数，可以开始优化。在第一步，先让我们对微调进行 10,000 次迭代，看看性能如何：
- en: '[PRE58]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'After 10,000 iterations, we observe the following result:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 经过 10,000 次迭代后，我们观察到以下结果：
- en: '[PRE59]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'This means the accuracy on the test set is about 79%. Also, let''s see how
    well our classifier performs on a sample image:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着测试集上的准确率大约为 79%。此外，让我们看看我们的分类器在一张示例图像上的表现如何：
- en: '![](img/0972b7f4-b784-4307-b74c-87f81c5a50d3.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0972b7f4-b784-4307-b74c-87f81c5a50d3.png)'
- en: 'Figure 7: Random prediction on the test set (after 10,000 iterations)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：在测试集上的随机预测（经过 10,000 次迭代）
- en: 'After that, we further iterate the optimization up to 100,000 times and observe
    better accuracy:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们进一步将优化迭代至 100,000 次，并观察到更好的准确率：
- en: '![](img/d5393dde-dbf3-406f-b795-50d28d431e2e.png)'
  id: totrans-282
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d5393dde-dbf3-406f-b795-50d28d431e2e.png)'
- en: 'Figure 8: Random prediction on the test set (after 100,000 iterations)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：在测试集上的随机预测（经过 100,000 次迭代）
- en: '[PRE60]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'So it did not improve that much but was a 2% increase on the overall accuracy.
    Now is the time to evaluate our model for a single image. For simplicity, we will
    take two random images of a dog and a cat and see the prediction power of our
    model:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 所以它的改进不大，但整体准确率提高了 2%。现在是时候对我们的模型进行单张图片的评估了。为了简单起见，我们将随机选取一只狗和一只猫的图片，看看我们的模型的预测能力：
- en: '![](img/45e9ed02-1b51-41d2-8f8a-e50e99679671.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![](img/45e9ed02-1b51-41d2-8f8a-e50e99679671.png)'
- en: 'Figure 9: Example image for the cat and dog to be classified'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：待分类的猫和狗的示例图像
- en: 'At first, we load these two images and prepare the test set accordingly, as
    we have seen in an earlier step in this example:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们加载这两张图片，并相应地准备测试集，正如我们在本示例的前面步骤中所看到的：
- en: '[PRE61]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Then we have the following function for making the prediction:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们有以下函数来进行预测：
- en: '[PRE62]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Finally, when we''re done, we close the TensorFlow session by invoking the
    `close()` method:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当我们完成后，通过调用 `close()` 方法关闭 TensorFlow 会话：
- en: '[PRE63]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Model performance optimization
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型性能优化
- en: Since CNNs are different from the layering architecture's perspective, they
    have different requirements as well as tuning criteria. How do you know what combination
    of hyperparameters is the best for your task? Of course, you can use a grid search
    with cross-validation to find the right hyperparameters for linear machine learning
    models.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 由于卷积神经网络（CNN）与传统的分层结构不同，它们有不同的要求和调优标准。那么，如何知道哪种超参数组合最适合你的任务呢？当然，你可以使用网格搜索和交叉验证来找到线性机器学习模型的最佳超参数。
- en: However, for CNNs, there are many hyperparameters to tune, and since training
    a neural network on a large dataset takes a lot of time, you will only be able
    to explore a tiny part of the hyperparameter space in a reasonable amount of time.
    Here are some insights that can be followed.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于CNN，存在许多需要调优的超参数，而且在大数据集上训练神经网络需要大量时间，因此你只能在合理的时间内探索超参数空间的一小部分。以下是一些可以遵循的见解。
- en: Number of hidden layers
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 隐藏层的数量
- en: For many problems, you can just begin with a single hidden layer and you will
    get reasonable results. It has actually been shown that an MLP with just one hidden
    layer can model even the most complex functions provided it has enough neurons.
    For a long time, these facts convinced researchers that there was no need to investigate
    any deeper neural networks. However, they overlooked the fact that deep networks
    have a much higher parameter efficiency than shallow ones; they can model complex
    functions using exponentially fewer neurons than shallow nets, making them much
    faster to train.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多问题，你可以从一个隐藏层开始，通常就能得到合理的结果。实际上，研究表明，仅有一个隐藏层的多层感知机（MLP）只要神经元足够多，甚至可以建模最复杂的函数。长时间以来，这些事实让研究人员相信不需要进一步研究更深层的神经网络。然而，他们忽略了深层网络比浅层网络具有更高的参数效率；深层网络能用指数级更少的神经元建模复杂的函数，使得训练速度大大加快。
- en: It is to be noted that this might not be always the case. However, in summary,
    for many problems, you can start with just one or two hidden layers. It will work
    just fine using two hidden layers with the same total amount of neurons, in roughly
    the same amount of training time. For a more complex problem, you can gradually
    ramp up the number of hidden layers, until you start overfitting the training
    set. Very complex tasks, such as large image classification or speech recognition,
    typically require networks with dozens of layers and a huge amount of training
    data.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，这并非总是适用。然而，总的来说，对于许多问题，你可以从一个或两个隐藏层开始。使用相同数量的神经元，两个隐藏层通常也能取得良好的效果，而且大致相同的训练时间。对于更复杂的问题，你可以逐步增加隐藏层的数量，直到开始过拟合训练集。非常复杂的任务，如大规模图像分类或语音识别，通常需要数十层的网络和大量的训练数据。
- en: Number of neurons per hidden layer
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 每个隐藏层的神经元数量
- en: Obviously, the number of neurons in the input and output layers is determined
    by the type of input and output your task requires. For example, if your dataset
    has the shape of 28 x 28 it should expect to have input neurons with size 784
    and the output neurons should be equal to the number of classes to be predicted.
    As for the hidden layers, a common practice is to size them to form a funnel,
    with fewer and fewer neurons at each layer, the rationale being that many low-level
    features can coalesce into far fewer high-level features. However, this practice
    is not as common now, and you may simply use the same size for all hidden layers.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，输入层和输出层的神经元数量由任务所需的输入和输出类型决定。例如，如果你的数据集形状为28 x 28，它应该有784个输入神经元，而输出神经元数量应等于要预测的类别数。至于隐藏层，一种常见的做法是将它们的规模设计成漏斗形状，每一层的神经元数量逐渐减少，理由是许多低级特征可以合并成更少的高级特征。然而，现在这种做法已经不再那么常见，你也可以简单地为所有隐藏层使用相同的大小。
- en: 'If there are four convolutional layers with 256 neurons, that''s just one hyperparameter
    to tune instead of one per layer. Just like the number of layers, you can try
    increasing the number of neurons gradually until the network starts overfitting.
    Another important question is: when would you want to add a max pooling layer
    rather than a convolutional layer with the same stride? The thing is that a max-pooling
    layer has no parameters at all, whereas a convolutional layer has quite a few.'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有四个卷积层，每个卷积层有256个神经元，那么就只有一个超参数需要调优，而不是每个层都调优一个。就像隐藏层的数量一样，你可以逐渐增加神经元数量，直到网络开始过拟合。另一个重要的问题是：你何时需要添加最大池化层，而不是使用步幅相同的卷积层？问题在于，最大池化层没有任何参数，而卷积层有很多参数。
- en: Sometimes, adding a local response normalization layer that makes the neurons
    that most strongly activate inhibit neurons at the same location but in neighboring
    feature maps, encourages different feature maps to specialize and pushes them
    apart, forcing them to explore a wider range of features. It is typically used
    in the lower layers to have a larger pool of low-level features that the upper
    layers can build upon.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，添加一个局部响应归一化层，可以使得最强激活的神经元抑制在同一位置但在相邻特征图中的神经元，从而鼓励不同的特征图进行专业化，并推动它们分开，迫使它们探索更广泛的特征范围。通常，它在较低层使用，以便有更多的低级特征供上层构建。
- en: Batch normalization
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批量归一化
- en: '**Batch normalization** (**BN**) is a method to reduce internal covariate shift
    while training regular DNNs. This can apply to CNNs too. Due to the normalization,
    BN further prevents smaller changes to the parameters to amplify and thereby allows
    higher learning rates, making the network even faster:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '**批量归一化**（**BN**）是一种在训练常规DNN时减少内部协变量偏移的方法。这也适用于CNN。由于归一化，BN进一步防止了参数的小变化被放大，从而允许更高的学习率，使网络更快：'
- en: '![](img/844dd566-706b-49c2-81d2-3d64964ff092.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![](img/844dd566-706b-49c2-81d2-3d64964ff092.png)'
- en: 'The idea is placing an additional step between the layers, in which the output
    of the layer before is normalized. To be more specific, in the case of non-linear
    operations (for example, ReLU), BN transformation has to be applied to the non-linear
    operation. Typically, the overall process has the following workflow:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是在各层之间加入一个额外的步骤，其中前一层的输出会被规范化。更具体来说，在非线性操作的情况下（例如，ReLU），必须对非线性操作应用BN变换。通常，整个过程的工作流如下：
- en: Transforming the network into a BN network (see *Figure 1*)
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将网络转换为BN网络（见*图1*）
- en: Then training the new network
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后训练新的网络
- en: Transforming the batch statistic into a population statistic
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将批量统计数据转换为总体统计数据
- en: This way, BN can fully partake in the process of backpropagation. As shown in
    *Figure 1*, BN is performed before the other processes of the network in this
    layer are applied. However, any kind of gradient descent (for example, **stochastic
    gradient descent** (**SGD**) and its variants) can be applied to train the BN
    network.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，BN可以充分参与反向传播过程。如*图1*所示，BN在应用该层网络的其他过程之前就已经执行。然而，任何类型的梯度下降（例如，**随机梯度下降**（**SGD**）及其变种）都可以应用于训练BN网络。
- en: 'Interested readers can refer to the original paper to get to more information:
    Ioffe, Sergey, and Christian Szegedy. *Batch normalization: Accelerating deep
    network training by reducing internal covariate shift*. arXiv preprint arXiv:1502.03167
    (2015).'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '感兴趣的读者可以参考原始论文以获取更多信息：Ioffe, Sergey, 和 Christian Szegedy. *Batch normalization:
    Accelerating deep network training by reducing internal covariate shift*. arXiv预印本
    arXiv:1502.03167 (2015).'
- en: 'Now a valid question would be: where to place the BN layer? Well, to know the
    answer, a quick evaluation of BatchNorm layer performance on ImageNet-2012 ([https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md](https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md))
    shows the following benchmark:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 现在一个合理的问题是：BN层应该放在哪里？好吧，为了知道答案，可以快速评估BatchNorm层在ImageNet-2012上的表现（[https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md](https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md)），得到如下基准测试结果：
- en: '![](img/2ea9e9c0-8cf4-42a0-a436-c50a531f1857.png)'
  id: totrans-314
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2ea9e9c0-8cf4-42a0-a436-c50a531f1857.png)'
- en: 'From the preceding table, it can be seen that placing BN after non-linearity
    would be the right way. The second question would be: what activation function
    should be used in a BN layer? Well, from the same benchmark, we can see the following
    result:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的表格可以看出，将BN放置在非线性操作之后是正确的做法。第二个问题是：BN层应该使用什么激活函数？好吧，从相同的基准测试中，我们可以看到以下结果：
- en: '![](img/71798011-3bf7-421a-a5dd-05a4786e3b4e.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![](img/71798011-3bf7-421a-a5dd-05a4786e3b4e.png)'
- en: 'From the preceding table, we can assume that using ReLU or its variants would
    be a better idea. Now, another question would be how to use these using deep learning
    libraries. Well, in TensorFlow, it is:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的表格来看，我们可以假设使用ReLU或其变种会是一个更好的选择。现在，另一个问题是如何在深度学习库中使用这些方法。在TensorFlow中，它是：
- en: '[PRE64]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'A general warning: set this to `True` for training and `False` for testing.
    However, the preceding addition introduces extra ops to be performed on the graph,
    which is updating its mean and variance variables in such a way that they will
    not be dependencies of your training op. To do it, we can just run the ops separately,
    as follows:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 一般警告：将此设置为`True`用于训练，设置为`False`用于测试。然而，前面的添加会引入额外的操作，这些操作会在图中更新其均值和方差变量，以确保它们不会成为训练操作的依赖项。为此，我们可以像下面这样单独运行这些操作：
- en: '[PRE65]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Advanced regularization and avoiding overfitting
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级正则化与避免过拟合
- en: As mentioned in the previous chapter, one of the main disadvantages observed
    during the training of large neural networks is overfitting, that is, generating
    very good approximations for the training data but emitting noise for the zones
    between single points. There are a couple of ways to reduce or even prevent this
    issue, such as dropout, early stop, and limiting the number of parameters.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章节所述，在训练大规模神经网络时观察到的主要缺点之一是过拟合，即对于训练数据生成了非常好的近似，但对于单个点之间的区域则发出噪声。减少或甚至避免这个问题有几种方法，比如dropout、提前停止和限制参数数量。
- en: 'In the case of overfitting, the model is specifically adjusted to the training
    dataset, so it will not be used for generalization. Therefore, although it performs
    well on the training set, its performance on the test dataset and subsequent tests
    is poor because it lacks the generalization property:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在过拟合的情况下，模型被特别调整以适应训练数据集，因此它不能用于泛化。因此，尽管它在训练集上表现良好，但在测试数据集及随后的测试中表现较差，因为它缺乏泛化能力。
- en: '![](img/a06dfa25-f5a6-4e97-bd16-c73552f1582a.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a06dfa25-f5a6-4e97-bd16-c73552f1582a.png)'
- en: 'Figure 10: Dropout versus without dropout'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：使用dropout与不使用dropout的对比
- en: The main advantage of this method is that it avoids holding all the neurons
    in a layer to optimize their weights synchronously. This adaptation made in random
    groups prevents all the neurons from converging to the same goals, thus de-correlating
    the adapted weights. A second property found in the dropout application is that
    the activation of the hidden units becomes sparse, which is also a desirable characteristic.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的主要优势在于，它避免了同步地优化层中所有神经元的权重。通过随机分组进行的这种适应性调整，防止了所有神经元趋向于相同的目标，从而去相关化了适应的权重。在dropout应用中发现的第二个特点是，隐藏单元的激活变得稀疏，这也是一个理想的特性。
- en: In the preceding figure, we have a representation of an original fully connected
    multilayer neural network and the associated network with the dropout linked.
    As a result, approximately half of the input was zeroed (this example was chosen
    to show that probabilities will not always give the expected four zeroes). One
    factor that could have surprised you is the scale factor applied to the non-dropped
    elements.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，我们展示了一个原始的全连接多层神经网络及其与dropout连接的相关网络。因此，大约一半的输入被置为零（此示例选择了这个情况，以展示概率并不总是给出预期的四个零）。一个可能让你感到意外的因素是，应用于未被丢弃元素的缩放因子。
- en: 'This technique is used to maintain the same network, and restore it to the
    original architecture when training, using `dropout_keep_prob` as 1\. A major
    drawback of using dropout is that it does not have the same benefits for convolutional
    layers, where the neurons are not fully connected. To address this issue, there
    are a few techniques can be applied, such as DropConnect and stochastic pooling:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 该技术用于保持相同的网络，在训练时将其恢复为原始架构，并使用`dropout_keep_prob`设置为1。使用dropout的一个主要缺点是，它对卷积层没有相同的效果，因为卷积层中的神经元不是全连接的。为了解决这个问题，可以应用一些技术，如DropConnect和随机池化：
- en: DropConnect is similar to dropout as it introduces dynamic sparsity within the
    model, but it differs in that the sparsity is on the weights, rather than the
    output vectors of a layer. The thing is that a fully connected layer with DropConnect
    becomes a sparsely connected layer in which the connections are chosen at random
    during the training stage.
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DropConnect与dropout类似，它在模型中引入了动态稀疏性，但不同之处在于，稀疏性作用于权重，而不是层的输出向量。关键是，带有DropConnect的全连接层变成了一个稀疏连接层，其中连接在训练阶段是随机选择的。
- en: In stochastic pooling, the conventional deterministic pooling operations are
    replaced with a stochastic procedure, where the activation within each pooling
    region is picked randomly according to a multinomial distribution, given by the
    activities within the pooling region. The approach is hyperparameter free and
    can be combined with other regularization approaches, such as dropout and data
    augmentation.
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在随机池化中，常规的确定性池化操作被一个随机过程所替代，在这个过程中，每个池化区域内的激活值都是根据池化区域内的活动，通过多项分布随机选择的。这种方法不依赖于超参数，可以与其他正则化方法结合使用，如
    dropout 和数据增强。
- en: '**Stochastic pooling versus standard max pooling:** Stochastic pooling is equivalent
    to standard max pooling but with many copies of an input image, each having small
    local deformations.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '**随机池化与标准最大池化：** 随机池化等价于标准的最大池化，但它使用了多个输入图像副本，每个副本具有小的局部变形。'
- en: Secondly, one of the simplest methods to prevent overfitting of a network is
    to simply stop the training before overfitting gets a chance to occur. This comes
    with the disadvantage that the learning process is halted. Thirdly, limiting the
    number of parameters is sometimes helpful and helps avoid overfitting. When it
    comes to CNN training, the filter size also affects the number of parameters.
    Thus, limiting this type of parameter restricts the predictive power of the network
    directly, reducing the complexity of the function that it can perform on the data,
    and that limits the amount of overfitting.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，防止网络过拟合的最简单方法之一是简单地在过拟合有机会发生之前停止训练。这样做的缺点是学习过程会被暂停。第三，限制参数的数量有时是有帮助的，有助于避免过拟合。对于
    CNN 训练来说，滤波器大小也会影响参数的数量。因此，限制这类参数直接限制了网络的预测能力，减少了它对数据执行的函数的复杂性，从而限制了过拟合的程度。
- en: Applying dropout operations with TensorFlow
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中应用 dropout 操作
- en: 'If we apply the dropout operation to a sample vector, it will work on transmitting
    the dropout to all the architecture-dependent units. In order to apply the dropout
    operation, TensorFlow implements the `tf.nn.dropout` method, which works as follows:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们对一个样本向量应用 dropout 操作，它将作用于将 dropout 传递给所有依赖于架构的单元。为了应用 dropout 操作，TensorFlow
    实现了 `tf.nn.dropout` 方法，其工作原理如下：
- en: '[PRE66]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Where `x` is the original tensor. The `keep_prob` means the probability of
    keeping a neuron and the factor by which the remaining nodes are multiplied. The
    `noise_shape` signifies a four-element list that determines whether a dimension
    will apply zeroing independently or not. Let''s have a look at this code segment:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 `x` 是原始张量。`keep_prob` 表示保留神经元的概率，以及剩余节点被乘的因子。`noise_shape` 表示一个四个元素的列表，用于确定某个维度是否会独立应用零化操作。让我们看一下这段代码：
- en: '[PRE67]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '[PRE68]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: In the preceding example, you can see the results of applying dropout to the
    *x* variable, with a 0.5 probability of zero; in the cases in which it didn't
    occur, the values were doubled (multiplied by 1/1.5, the dropout probability).
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，你可以看到将 dropout 应用到 *x* 变量的结果，零的概率为 0.5；在没有发生的情况下，值被加倍（乘以 1/1.5，dropout
    概率）。
- en: Which optimizer to use?
  id: totrans-340
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用哪个优化器？
- en: When using a CNN, since one of the objective functions is to minimize the evaluated
    cost, we must define an optimizer. Using the most common optimizer , such as SGD,
    the learning rates must scale with *1/T* to get convergence, where *T* is the
    number of iterations. Adam or RMSProp try to overcome this limitation automatically
    by adjusting the step size so that the step is on the same scale as the gradients.
    In addition, in the previous example, we have used Adam optimizer, which performs
    well in most cases.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 CNN 时，由于目标函数之一是最小化评估的成本，我们必须定义一个优化器。使用最常见的优化器，如 SGD，学习率必须按 *1/T* 的比例缩放才能收敛，其中
    *T* 是迭代次数。Adam 或 RMSProp 试图通过自动调整步长来克服这一限制，从而使步长与梯度的尺度相同。此外，在前面的示例中，我们使用了 Adam
    优化器，它在大多数情况下表现良好。
- en: 'Nevertheless, if you are training a neural network but computing the gradients
    is mandatory, using the `RMSPropOptimizer` function (which implements the `RMSProp`
    algorithm) is a better idea since it would be the faster way of learning in a
    mini-batch setting. Researchers also recommend using the momentum optimizer, while
    training a deep CNN or DNN. Technically, `RMSPropOptimizer` is an advanced form
    of gradient descent that divides the learning rate by an exponentially decaying
    average of squared gradients. The suggested setting value of the decay parameter
    is 0.9, while a good default value for the learning rate is 0.001\. For example,
    in TensorFlow, `tf.train.RMSPropOptimizer()` helps us to use this with ease:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你正在训练一个神经网络并且计算梯度是必需的，使用`RMSPropOptimizer`函数（该函数实现了`RMSProp`算法）是一个更好的选择，因为它是小批量设置下学习的更快速方法。研究人员还建议在训练深度CNN或DNN时使用动量优化器。技术上，`RMSPropOptimizer`是梯度下降的高级形式，它通过一个指数衰减的梯度平方均值来调整学习率。建议的衰减参数设置值是0.9，而学习率的一个良好默认值是0.001。例如，在TensorFlow中，`tf.train.RMSPropOptimizer()`帮助我们轻松使用此方法：
- en: '[PRE69]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Memory tuning
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存调优
- en: In this section, we try to provide some insights. We start with an issue and
    its solution; convolutional layers require a huge amount of RAM, especially during
    training, because the reverse pass of backpropagation requires all the intermediate
    values computed during the forward pass. During inference (that is, when making
    a prediction for a new instance), the RAM occupied by one layer can be released
    as soon as the next layer has been computed, so you only need as much RAM as required
    by two consecutive layers.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们尝试提供一些见解。我们从一个问题及其解决方案开始；卷积层需要大量的内存，尤其是在训练期间，因为反向传播的反向传递需要保留在前向传递中计算的所有中间值。在推理期间（即对新实例进行预测时），一个层占用的内存可以在下一个层计算完成后立即释放，因此你只需要两层连续层所需的内存。
- en: 'Nevertheless, during training, everything computed during the forward pass
    needs to be preserved for the reverse pass, so the amount of RAM needed is (at
    least) the total amount of RAM required by all layers. If your GPU runs out of
    memory while training a CNN, here are five things you can try to solve the problem
    (other than purchasing a GPU with more RAM):'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在训练期间，前向传递中计算的所有内容需要保留以供反向传递使用，因此所需的内存量（至少）是所有层所需的总内存。如果在训练CNN时GPU内存不足，这里有五个你可以尝试解决问题的方法（除了购买更大内存的GPU）：
- en: Reduce the mini-batch size
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减小小批量大小
- en: Reduce dimensionality using a larger stride in one or more layers
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用更大的步幅在一层或多层中降低维度
- en: Remove one or more layers
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除一层或多层
- en: Use 16-bit floats instead of 32-bit
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用16位浮点数而不是32位
- en: Distribute the CNN across multiple devices (see more at [https://www.tensorflow.org/deploy/distributed](https://www.tensorflow.org/deploy/distributed))
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将CNN分布到多个设备上（更多内容请见[https://www.tensorflow.org/deploy/distributed](https://www.tensorflow.org/deploy/distributed)）
- en: Appropriate layer placement
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 合适的层次放置
- en: 'Another important question would be: when do you want to add a max pooling
    layer rather than a convolutional layer with the same stride? The thing is that
    a max-pooling layer has no parameters at all, whereas a convolutional layer has
    quite a few.'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要问题是：你何时希望添加最大池化层，而不是具有相同步幅的卷积层？问题在于，最大池化层完全没有参数，而卷积层有相当多的参数。
- en: Even adding a local response normalization layer sometimes makes the neurons
    that most strongly activate inhibit neurons at the same location but in neighboring
    feature maps, which encourages different feature maps to specialize and pushes
    them apart, forcing them to explore a wider range of features. It is typically
    used in the lower layers to have a larger pool of low-level features that the
    upper layers can build upon.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 即使添加一个局部响应归一化层，有时也会导致最强激活的神经元抑制相同位置但在邻近特征图上的神经元，这鼓励不同的特征图进行专业化并将它们推开，迫使它们探索更广泛的特征。它通常用于低层，以便提供更大的低级特征池，供高层构建。
- en: Building the second CNN by putting everything together
  id: totrans-355
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过将所有内容组合起来构建第二个CNN
- en: Now we know how to optimize the layering structure in a CNN by adding dropout,
    BN, and biases initializers, such as Xavier. Let's try to apply these to a less
    complex CNN. Throughout this example, we will see how to solve a real-life classification
    problem. To be more specific, our CNN model will be able to classify the traffic
    sign from a bunch of images.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何通过添加 dropout、BN 和偏置初始化器（如 Xavier）来优化 CNN 中的分层结构。让我们尝试将这些应用于一个较简单的 CNN。在这个例子中，我们将看到如何解决一个实际的分类问题。更具体地说，我们的
    CNN 模型将能够从一堆图像中分类交通标志。
- en: Dataset description and preprocessing
  id: totrans-357
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集描述和预处理
- en: 'For this we will be using the Belgian traffic dataset (BelgiumTS for Classification
    (cropped images)). This dataset can be download from [http://btsd.ethz.ch/shareddata/](http://btsd.ethz.ch/shareddata/).
    Here are a quick glimpse about the traffic signs convention in Belgium:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将使用比利时交通数据集（比利时交通标志分类数据集，裁剪图像）。这个数据集可以从 [http://btsd.ethz.ch/shareddata/](http://btsd.ethz.ch/shareddata/)
    下载。以下是比利时交通标志的概览：
- en: Belgian traffic signs are usually in Dutch and French. This is good to know,
    but for the dataset that you'll be working with, it's not too important!
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比利时的交通标志通常使用荷兰语和法语。这是一个值得了解的信息，但对于你将要处理的数据集来说，这一点并不是特别重要！
- en: 'There are six categories of traffic signs in Belgium: warning signs, priority
    signs, prohibitory signs, mandatory signs, signs related to parking and standing
    still on the road and, lastly, designatory signs.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比利时的交通标志分为六类：警告标志、优先标志、禁止标志、强制标志、与停车和路面停靠相关的标志，以及最后的标识性标志。
- en: 'Once we download the aforementioned dataset, we will see the following directory
    structure (training left, test right):'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们下载了上述数据集，我们将看到以下的目录结构（左侧为训练集，右侧为测试集）：
- en: '![](img/ce5f8479-60f0-4703-8e95-c991d7d6b829.png)'
  id: totrans-362
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ce5f8479-60f0-4703-8e95-c991d7d6b829.png)'
- en: The images are in `.ppm` format; otherwise we could've used TensorFlow built-in
    image loader (example, `tf.image.decode_png`). However, we can use the `skimage`
    Python package.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图像是 `.ppm` 格式的；否则我们可以使用 TensorFlow 内置的图像加载器（例如 `tf.image.decode_png`）。不过，我们可以使用
    `skimage` Python 包。
- en: 'In Python 3, execute `$ sudo pip3 install scikit-image` for `skimage` to install
    and use this package. So let''s get started by showing the directory path as follows:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 3 中，执行 `$ sudo pip3 install scikit-image` 来安装 `skimage` 包并使用它。所以让我们从显示如下的目录路径开始：
- en: '[PRE70]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Then let''s write a function using the `skimage` library to read the images
    and returns two lists:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，让我们写一个使用 `skimage` 库的函数，读取图像并返回两个列表：
- en: '`images`: A list of Numpy arrays, each representing an image'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`images`: 一个包含 Numpy 数组的列表，每个数组表示一张图像'
- en: '`labels`: A list of numbers that represent the images labels'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`: 一个数字列表，表示图像的标签'
- en: '[PRE71]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The preceding code block is straightforward and contains inline comments. How
    about showing related statistics about images? However, before that, let''s invoke
    the preceding function:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码块很直观，并包含内联注释。如何显示与图像相关的统计信息呢？不过，在此之前，让我们调用上面的函数：
- en: '[PRE72]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Then let''s see some statistics:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 然后让我们查看一些统计信息：
- en: '[PRE73]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'So we have 62 classes to be predicted (that is, a multiclass image classification
    problem) and we have many images too that should be sufficient to satisfy a smaller
    CNN.Now let''s see the class distribution visually:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们有62个类别需要预测（也就是一个多类别图像分类问题），而且我们也有许多图像，这应该足以满足一个较小的 CNN。现在让我们来直观地查看类别分布：
- en: '[PRE75]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '![](img/03894908-617b-4b51-9011-b3d5f4a084e3.png)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![](img/03894908-617b-4b51-9011-b3d5f4a084e3.png)'
- en: 'Therefore, from the preceding figure, we can see that classes are very imbalanced.
    However, to make it simpler, we won''t take care of this but next, it would be
    great to visually inspect some files, say displaying the first image of each label:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从前面的图示中，我们可以看到类别非常不平衡。然而，为了简化问题，我们不打算处理这一点，接下来，我们可以通过可视化检查一些文件，例如显示每个标签的第一张图片：
- en: '[PRE76]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: '![](img/05a6bed9-b026-42a6-ac02-e2dc40663a60.png)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![](img/05a6bed9-b026-42a6-ac02-e2dc40663a60.png)'
- en: 'Now you can see from the preceding figure that the images come in different
    sizes and shapes. Moreover, we can see it using Python code, as follows:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以从前面的图示中看到，这些图像的大小和形状各不相同。此外，我们还可以通过 Python 代码看到这一点，如下所示：
- en: '[PRE77]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Therefore, we need to apply some pre-processing such as resizing, reshaping,
    and so on to each image. Let''s say each image will have size of 32 x 32:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要对每张图像进行一些预处理，比如调整大小、重塑等等。假设每张图像的大小为 32 x 32：
- en: '[PRE79]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Now, all of our images have same size. The next task would be to convert labels
    and image features as a `numpy` array:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的所有图像都有相同的大小。接下来的任务是将标签和图像特征转换为 `numpy` 数组：
- en: '[PRE81]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Fantastic! The next task would be creating our second CNN, but this time we
    will be using TensorFlow `contrib` package, which is a high-level API that supports
    layering ops.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！接下来的任务将是创建我们的第二个 CNN，但这次我们将使用 TensorFlow `contrib` 包，这是一个支持层操作的高级 API。
- en: Creating the CNN model
  id: totrans-391
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 CNN 模型
- en: We are going to construct a complex network. However, it has a straightforward
    architecture. At the beginning, we use Xavier as the network initializer. Once
    we initialize the network bias using the Xavier initializer. The input layer is
    followed by a convolutional layer (convolutional layer 1), which is again followed
    by a BN layer (that is, BN layer 1). Then there is a pooling layer with strides
    of two and a kernel size of two. Then another BN layer follows the second convolutional
    layer. Next, there is the second pooling layer with strides of two and kernel
    size of two. Well, then the max polling layer is followed by a flattening layer
    that flattens the input from (None, height, width, channels) to (None, height
    * width * channels) == (None, 3072).
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 我们即将构建一个复杂的网络。然而，它具有简单的架构。首先，我们使用 Xavier 初始化网络。初始化网络偏置后，输入层后跟卷积层（卷积层 1），然后是
    BN 层（即 BN 层 1）。然后是步幅为两个、核大小为两个的池化层。接着第二个卷积层后跟另一个 BN 层。接下来是步幅为两个、核大小为两个的第二个池化层。然后是最大池化层，后面是一个将输入从（None，高度，宽度，通道）扁平化为（None，高度
    * 宽度 * 通道）==（None，3072）的扁平化层。
- en: 'Once the flattening is completed, the input is fed into the first fully connected
    layer 1\. Then third BN is applied as a normalizer function. Then we will have
    a dropout layer before we feed the lighter network into the fully connected layer
    2 that generates logits of size (None, 62). Too much of a mouthful? Don''t worry;
    we will see it step by step. Let''s start the coding by creating the computational
    graph, creating both features, and labeling placeholders:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 扁平化完成后，输入被送入第一个全连接层 1。然后第三个 BN 被应用为正常化函数。然后在将轻网络馈送到生成大小为（None，62）的 logits 的第二个全连接层
    2 之前，我们将有一个 dropout 层。太多了吗？别担心，我们将一步步看到它。让我们从创建计算图开始编码，创建特征和标签占位符：
- en: '[PRE83]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Up to this point, we have managed to generate the logits of size (`None, 62`).
    Then we need to convert the logits to label indexes (`int`) with the shape (`None`),
    which is a 1D vector of `length == batch_size:predicted_labels = tf.argmax(logits,
    axis=1)`. Then we define cross-entropy as the `loss` function, which is a good
    choice for classification:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经成功生成了大小为（`None, 62`）的 logits。然后，我们需要将 logits 转换为标签索引（`int`），形状为（`None`），即一个长度为
    `batch_size` 的 1D 向量：`predicted_labels = tf.argmax(logits, axis=1)`。然后我们定义交叉熵作为
    `loss` 函数，这对于分类是一个不错的选择：
- en: '[PRE84]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Now one of the most important parts is updating the ops and creating an optimizer
    (Adam in our case):'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，其中一个最重要的部分是更新操作并创建优化器（在我们的案例中是 Adam）：
- en: '[PRE85]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Finally, we initialize all the ops:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们初始化所有操作：
- en: '[PRE86]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: Training and evaluating the network
  id: totrans-401
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练和评估网络
- en: 'We start by create a session to run the graph we created. Note that for faster
    training, we should use a GPU. However, if you do not have a GPU, just set `log_device_placement=False`:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始创建一个会话来运行我们创建的图形。请注意，为了更快地训练，我们应该使用 GPU。但如果您没有 GPU，只需设置 `log_device_placement=False`：
- en: '[PRE87]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: '[PRE88]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'Once the training is completed, let us pick 10 random images and see the predictive
    power of our model:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，让我们随机挑选 10 张图片，看看我们模型的预测能力：
- en: '[PRE89]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'Then let''s run the `predicted_labels op`:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 然后让我们运行 `predicted_labels op`：
- en: '[PRE90]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '[PRE91]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'So we can see that some images were correctly classified and some wrongly.
    However, visual inspection would be more helpful. So let''s display the predictions
    and the ground truth:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，一些图片被正确分类了，而一些则错误分类了。然而，视觉检查可能会更有帮助。因此，让我们显示预测和实际情况：
- en: '[PRE92]'
  id: totrans-411
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: '![](img/bc955eb3-eac0-47a3-b447-c0b6722c80cf.png)'
  id: totrans-412
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bc955eb3-eac0-47a3-b447-c0b6722c80cf.png)'
- en: 'Finally, we can evaluate our model using the test set. To see the predictive
    power, we compute the accuracy:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用测试集来评估我们的模型。为了看到预测能力，我们计算准确率：
- en: '[PRE93]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: '[PRE94]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: Not that bad in terms of accuracy. In addition to this, we can also compute
    other performance metrics such as precision, recall, f1 measure and also visualize
    the result in a confusion matrix to show the predicted versus actual labels count.
    Nevertheless, we can still improve the accuracy by tuning the network and hyperparameters.
    But I leave these up to the readers.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 就准确性而言，并不算糟糕。除此之外，我们还可以计算其他性能指标，如精确度、召回率、F1 值，并将结果可视化为混淆矩阵，以展示预测与实际标签的计数。不过，通过调整网络和超参数，我们仍然可以提高准确性。但这些工作留给读者来完成。
- en: 'Finally, we are done, so let''s close the TensorFlow session:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们完成了任务，接下来让我们关闭 TensorFlow 会话：
- en: '[PRE95]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: Summary
  id: totrans-419
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed how to use CNNs, which are a type of feed-forward
    artificial neural network in which the connectivity pattern between neurons is
    inspired by the organization of an animal's visual cortex. We saw how to cascade
    a set of layers to construct a CNN and perform different operations in each layer.
    Then we saw how to train a CNN. Later on, we discussed how to optimize the CNN
    hyperparameters and optimization.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了如何使用 CNN（卷积神经网络），它是一种前馈式人工神经网络，神经元之间的连接模式受到动物视觉皮层组织的启发。我们学习了如何级联一组层来构建
    CNN，并在每一层执行不同的操作。接着我们讲解了如何训练 CNN。随后，我们讨论了如何优化 CNN 的超参数和优化方法。
- en: Finally, we built another CNN, where we utilized all the optimization techniques.
    Our CNN models did not achieve outstanding accuracy since we iterated both of
    the CNNs a few times and did not even apply any grid searching techniques; that
    means we did not hunt for the best combinations of the hyperparameters. Therefore,
    the takeaway would be to apply more robust feature engineering in the raw images,
    iterate the training for more epochs with the best hyperparameters, and observe
    the performance.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们构建了另一个 CNN，并在其中应用了所有优化技术。我们的 CNN 模型未能达到出色的准确率，因为我们只对这两个 CNN 进行了几次迭代，甚至没有使用网格搜索技术；这意味着我们没有寻找超参数的最佳组合。因此，收获的经验是：需要在原始图像中应用更强大的特征工程，使用最佳超参数进行更多轮的训练，并观察性能表现。
- en: In the next chapter, we will see how to use some deeper and popular CNN architectures,
    such as ImageNet, AlexNet, VGG, GoogLeNet, and ResNet. We will see how to utilize
    these trained models for transfer learning.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何使用一些更深层次且流行的 CNN 架构，例如 ImageNet、AlexNet、VGG、GoogLeNet 和 ResNet。我们将了解如何利用这些训练好的模型进行迁移学习。
