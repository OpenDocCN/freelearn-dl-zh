- en: 3\. An Introduction to Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3. 分类简介
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter introduces you to classification. You will implement various techniques,
    such as k-nearest neighbors and SVMs. You will use the Euclidean and Manhattan
    distances to work with k-nearest neighbors. You will apply these concepts to solve
    intriguing problems such as predicting whether a credit card applicant has a risk
    of defaulting and determining whether an employee would stay with a company for
    more than two years. By the end of this chapter, you will be confident enough
    to work with any data using classification and come to a certain conclusion.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将带您了解分类。您将实现各种技术，如k近邻和支持向量机（SVM）。您将使用欧几里得距离和曼哈顿距离来处理k近邻算法。您将应用这些概念来解决一些有趣的问题，例如预测一个信用卡申请人是否有违约风险，或者判断一个员工是否会在公司工作超过两年。在本章结束时，您将足够自信使用分类来处理任何数据，并得出明确结论。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: In the previous chapter, you were introduced to regression models and learned
    how to fit a linear regression model with single or multiple variables, as well
    as with a higher-degree polynomial.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您了解了回归模型，并学习了如何拟合一个包含单一或多个变量的线性回归模型，以及如何使用高次多项式进行拟合。
- en: Unlike regression models, which focus on learning how to predict continuous
    numerical values (which can have an infinite number of values), classification,
    which will be introduced in this chapter, is all about splitting data into separate
    groups, also called classes.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 与回归模型不同，回归模型侧重于学习如何预测连续的数值（这些数值可以有无限多种可能性），而分类问题（将在本章中介绍）则是将数据划分成不同的组，也叫做类。
- en: For instance, a model can be trained to analyze emails and predict whether they
    are spam or not. In this case, the data is categorized into two possible groups
    (or classes). This type of classification is also called **binary classification**,
    which we will see a few examples of in this chapter. However, if there are more
    than two groups (or classes), you will be working on a **multi-class classification**
    (you will come across some examples of this in *Chapter 4*, *An Introduction to
    Decision Trees*).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，模型可以被训练来分析电子邮件，并预测它们是否是垃圾邮件。在这种情况下，数据被分类为两种可能的类别（或类）。这种分类类型也称为**二分类**，我们将在本章中看到一些例子。然而，如果有多个（超过两个）类别（或类），那么您将处理**多分类问题**（您将在*第4章，决策树简介*中遇到一些示例）。
- en: 'But what is a real-world classification problem? Consider a model that tries
    to predict a given user''s rating for a movie where this score can only take values:
    *like*, *neutral*, or *dislike*. This is a classification problem.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 那么什么是真实世界中的分类问题呢？考虑一个模型，试图预测一个用户对电影的评分，其中评分只能取以下值：*喜欢*、*中立*或*不喜欢*。这是一个分类问题。
- en: In this chapter, we will learn how to classify data using the k-nearest neighbors
    classifier and SVM algorithms. Just as we did for regression in the previous chapter,
    we will build a classifier based on cleaned and prepared training data and test
    the performance of our classifier using testing data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何使用k近邻分类器和SVM算法进行数据分类。就像我们在上一章中做的回归一样，我们将基于清理和准备好的训练数据来构建分类器，并使用测试数据来测试分类器的性能。
- en: We'll begin by looking at the fundamentals of classification.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从分类的基础知识开始。
- en: The Fundamentals of Classification
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类的基础
- en: As stated earlier, the goal of any classification problem is to separate the
    data into relevant groups accurately using a training set. There are a lot of
    applications of such projects in different industries, such as education, where
    a model can predict whether a student will pass or fail an exam, or healthcare,
    where a model can assess the level of severity of a given disease for each patient.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，任何分类问题的目标是使用训练集将数据准确地划分为相关的组。此类项目在不同行业中有很多应用，例如在教育行业中，模型可以预测学生是否通过考试；在医疗保健行业中，模型可以评估每位患者某种疾病的严重程度。
- en: A classifier is a model that determines the label (output) or value (class)
    of any data point that it belongs to. For instance, suppose you have a set of
    observations that contains credit-worthy individuals, and another one that contains
    individuals that are risky in terms of their credit repayment tendencies.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器是一个模型，用于确定任何数据点所属的标签（输出）或值（类）。例如，假设您有一组观察数据，包含信用良好的个人，另一组则包含信用偿还倾向上存在风险的个人。
- en: 'Let''s call the first group P and the second one Q. Here is an example of such
    data:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将第一组称为 P，第二组称为 Q。以下是此类数据的示例：
- en: '![Figure 3.1: Sample dataset'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.1：示例数据集](img/B16060_03_01.jpg)'
- en: '](img/B16060_03_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16060_03_01.jpg)'
- en: 'Figure 3.1: Sample dataset'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：示例数据集
- en: With this data, you will train a classification model that will be able to correctly
    classify a new observation into one of these two groups (this is binary classification).
    The model can find patterns such as a person with a salary above $60,000 being
    less risky or that having a mortgage/income ratio above ratio 10 makes an individual
    more at risk of not repaying their debts. This will be a **multi-class classification**
    exercise.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些数据，你将训练一个分类模型，该模型能够将新的观察结果正确分类到这两组之一（这是二分类问题）。模型可以找到一些模式，例如年薪超过 60,000 美元的人风险较低，或者拥有超过
    10 倍的按揭/收入比率使个人更有可能无法偿还债务。这将是一个**多类别分类**练习。
- en: 'Classification models can be grouped into different families of algorithms.
    The most famous ones are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型可以分为不同的算法家族。最著名的几种如下：
- en: Distance-based, such as **k-nearest neighbors**
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于距离的算法，如**k-近邻**
- en: Linear models, such as **logistic regression** or **SVMs**
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性模型，如**逻辑回归**或**支持向量机（SVM）**
- en: Tree-based, such as **random forest**
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于树的算法，如**随机森林**
- en: 'In this chapter, you will be introduced to two algorithms from the first two
    types of family: k-nearest neighbors (distance-based) and SVMs (linear models).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将接触到来自前两种类型家族的两种算法：k-近邻（基于距离的）和支持向量机（SVM）（线性模型）。
- en: Note
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We'll walk you through tree-based algorithms such as random forest in *Chapter
    4*, *An Introduction to Decision Trees*.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在*第 4 章*《决策树简介》中为你讲解基于树的算法，如随机森林。
- en: But before diving into the models, we need to clean and prepare the dataset
    that we will be using in this chapter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，在深入研究模型之前，我们需要清理并准备本章将要使用的数据集。
- en: In the following section, we will work on a German credit approvals dataset
    and perform all the data preparation required for the modeling stage. Let's start
    by loading the data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将使用德国信用批准数据集，并进行所有数据准备，以便进入建模阶段。我们先从加载数据开始。
- en: 'Exercise 3.01: Predicting Risk of Credit Card Default (Loading the Dataset)'
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.01：预测信用卡违约风险（加载数据集）
- en: In this exercise, we will be loading a dataset into a pandas DataFrame and exploring
    its contents. We will use the dataset of German credit approvals to determine
    whether an individual presents a risk of defaulting.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将数据集加载到 pandas DataFrame 中并探索其内容。我们将使用德国信用批准的数据集来判断一个人是否有违约风险。
- en: Note
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The CSV version of this dataset can be found on our GitHub repository:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集的 CSV 版本可以在我们的 GitHub 仓库中找到：
- en: '[https://packt.live/3eriWTr](https://packt.live/3eriWTr).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.live/3eriWTr](https://packt.live/3eriWTr)。'
- en: The original dataset and information regarding the dataset can be found at [https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集及其相关信息可以在 [https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29](https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29)
    找到。
- en: The data files are located at [https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/](https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据文件位于 [https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/](https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/german/)。
- en: Citation - *Dua, D., & Graff, C.. (2017). UCI Machine Learning Repository*.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 引用 - *Dua, D., & Graff, C.. (2017). UCI 机器学习库*。
- en: Open a new Jupyter Notebook file.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter Notebook 文件。
- en: 'Import the `pandas` package as `pd`:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas` 包并将其命名为 `pd`：
- en: '[PRE0]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create a new variable called `file_url`, which will contain the URL to the
    raw dataset file, as shown in the following code snippet:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新变量 `file_url`，它将包含原始数据集文件的 URL，如以下代码片段所示：
- en: '[PRE1]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Import the data using the `pd.read_csv()` method:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pd.read_csv()` 方法导入数据：
- en: '[PRE2]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Use `df.head()` to print the first five rows of the DataFrame:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `df.head()` 打印 DataFrame 的前五行：
- en: '[PRE3]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The expected output is this:'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 期望的输出是这样的：
- en: '![Figure 3.2: The first five rows of the dataset](img/B16060_03_02.jpg)'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.2：数据集的前五行](img/B16060_03_02.jpg)'
- en: 'Figure 3.2: The first five rows of the dataset'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.2：数据集的前五行
- en: As you can see, the output in the preceding screenshot shows us the features
    of the dataset, which can be either numerical or categorical (text).
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，前面的截图输出展示了数据集的特征，这些特征可以是数值型或类别型（文本）。
- en: 'Now, use `df.tail()` to print the last five rows of the DataFrame:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`df.tail()`打印DataFrame的最后五行：
- en: '[PRE4]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The expected output is this:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出是这样的：
- en: '![Figure 3.3: The last five rows of the dataset](img/B16060_03_03.jpg)'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 3.3：数据集的最后五行](img/B16060_03_03.jpg)'
- en: 'Figure 3.3: The last five rows of the dataset'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.3：数据集的最后五行
- en: The last rows of the DataFrame are very similar to the first ones we saw earlier,
    so we can assume the structure is consistent across the rows.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DataFrame的最后几行与我们之前看到的前几行非常相似，因此我们可以假设行间结构是一致的。
- en: 'Now, use `df.dtypes` to print the list of columns and their data types:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`df.dtypes`打印列及其数据类型的列表：
- en: '[PRE5]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The expected output is this:'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出是这样的：
- en: '![Figure 3.4: The list of columns and their data types'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.4：列及其数据类型的列表](img/B16060_03_04.jpg)'
- en: '](img/B16060_03_04.jpg)'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16060_03_04.jpg)'
- en: 'Figure 3.4: The list of columns and their data types'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4：列及其数据类型的列表
- en: Note
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3hQXJEs](https://packt.live/3hQXJEs).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/3hQXJEs](https://packt.live/3hQXJEs)。
- en: You can also run this example online at [https://packt.live/3fN0DrT](https://packt.live/3fN0DrT).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在线运行此示例，网址为[https://packt.live/3fN0DrT](https://packt.live/3fN0DrT)。你必须执行整个Notebook，才能获得期望的结果。
- en: From the preceding output, we can see that this DataFrame has some numerical
    features ( `int64`) but also text (`object`). We can also see that most of these
    features are either personal details for an individual, such as their age, or
    financial information such as credit history or credit amount.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中，我们可以看到该DataFrame有一些数值特征（`int64`），但也有文本特征（`object`）。我们还可以看到这些特征大多数是与个人相关的细节，如年龄，或财务信息，如信用历史或信用额度。
- en: By completing this exercise, we have successfully loaded the data into the DataFrame
    and had a first glimpse of the features and information it contains.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 通过完成这个练习，我们已经成功地将数据加载到DataFrame中，并且初步了解了它所包含的特征和信息。
- en: In the topics ahead, we will be looking at preprocessing this data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将讨论如何对这些数据进行预处理。
- en: Data Preprocessing
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: Before building a classifier, we need to format our data so that we can keep
    relevant data in the most suitable format for classification and remove all the
    data that we are not interested in.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建分类器之前，我们需要格式化数据，以便将相关数据保持在最适合分类的格式中，并删除我们不感兴趣的所有数据。
- en: 'The following points are the best ways to achieve this:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下几点是实现这一目标的最佳方法：
- en: '`N/A` (or `NA`) values in the dataset, we may be better off substituting these
    values with a numeric value we can handle. Recall from the previous chapter that
    `NA` stands for `NA` values or replace them with an outlier value.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集中的`N/A`（或`NA`）值，我们可能最好将这些值替换为我们可以处理的数值。回顾上一章，`NA`表示缺失值，或者将其替换为异常值。
- en: '[PRE6]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `fillna()` method changes all `NA` values into numeric values.
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`fillna()`方法将所有`NA`值更改为数值。'
- en: This numeric value should be far from any reasonable value in the DataFrame.
    Minus one million is recognized by the classifier as an exception, assuming that
    only positive values are there, as mentioned in the preceding note.
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个数值应该远离DataFrame中任何合理的值。负一百万被分类器识别为异常值，假设只有正值存在，如前面的说明所提到的。
- en: '`0`) specifies that we drop rows, not columns. The second argument (`inplace=True`)
    specifies that we perform the drop operation without cloning the DataFrame, and
    will save the result in the same DataFrame. This DataFrame doesn''t have any missing
    values, so the `dropna()` method didn''t alter the DataFrame.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0`) 指定我们删除行，而不是列。第二个参数（`inplace=True`）指定我们在不克隆DataFrame的情况下执行删除操作，并将结果保存在同一个DataFrame中。由于该DataFrame没有缺失值，因此`dropna()`方法没有改变DataFrame。'
- en: '[PRE7]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The second argument (value `1`) indicates that we are dropping columns, instead
    of rows. The first argument is an enumeration of the columns we would like to
    drop (here, this is `['telephone']`). The `inplace` argument is used so that the
    call modifies the original DataFrame.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二个参数（值为`1`）表示我们要删除列，而不是行。第一个参数是我们想要删除的列的枚举（在这里是`['telephone']`）。`inplace`参数用于让该操作修改原始的DataFrame。
- en: '`MinMaxScaler` method of the scikit-learn `preprocessing` utility, as shown
    in the following code snippet:'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MinMaxScaler`方法属于scikit-learn的`preprocessing`工具，代码片段如下所示：'
- en: '[PRE8]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The expected output is this:'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出是这样的：
- en: '[PRE9]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Binarization transforms data into ones and zeros based on a condition, as shown
    in the following code snippet:'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 二值化将数据基于条件转换为 1 和 0，如下代码片段所示：
- en: '[PRE10]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The expected output is this:'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出是这样的：
- en: '[PRE11]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the preceding example, we transformed the original data `([19, 65],[4, 52],[2,
    33])` into a binary form based on the condition of whether each value is greater
    than `10` or not (as defined by the `threshold=10` parameter). For instance, the
    first value, `19`, is above `10`, so it is replaced by `1` in the results.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的例子中，我们根据每个值是否大于 `10`（由 `threshold=10` 参数定义）将原始数据 `([19, 65],[4, 52],[2,
    33])` 转换为二进制形式。例如，第一个值 `19` 大于 `10`，因此在结果中被替换为 `1`。
- en: Label encoding is important for preparing your features (inputs) for the modeling
    stage. While some of your features are string labels, scikit-learn algorithms
    expect this data to be transformed into numbers.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 标签编码对于准备特征（输入）以进入建模阶段非常重要。尽管某些特征是字符串标签，scikit-learn 算法期望这些数据转换为数字。
- en: This is where the `preprocessing` library of scikit-learn comes into play.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这时，scikit-learn 的 `preprocessing` 库派上了用场。
- en: Note
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You might have noticed that in the credit scoring example, there were two data
    files. One contained labels in string form, while the other contained labels in
    integer form. We loaded the data with string labels so that you got some experience
    of how to preprocess data properly with the label encoder.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到，在信用评分的例子中，有两个数据文件。一个包含字符串形式的标签，另一个包含整数形式的标签。我们加载了带字符串标签的数据，以便你能体验如何使用标签编码器正确地预处理数据。
- en: 'Label encoding is not rocket science. It creates a mapping between string labels
    and numeric values so that we can supply numbers to scikit-learn, as shown in
    the following example:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 标签编码不是火箭科学。它创建了字符串标签和数值之间的映射，以便我们可以向 scikit-learn 提供数字，以下是一个示例：
- en: '[PRE12]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s enumerate the encoding:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们列举一下编码：
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The expected output is this:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出是这样的：
- en: '[PRE14]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The preceding result shows us that scikit-learn has created a mapping for each
    day of the week to a respective number; for example, `Friday` will be `0` and
    `Tuesday` will be `3`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的结果显示，scikit-learn 为每周的每一天创建了一个映射关系；例如，`Friday` 映射为 `0`，`Tuesday` 映射为 `3`。
- en: Note
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: By default, scikit-learn assigned the mapping number by sorting the original
    values alphabetically. This is why `Friday` is mapped to `0`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，scikit-learn 通过按字母顺序排序原始值来分配映射的数字。这就是为什么 `Friday` 被映射为 `0` 的原因。
- en: Now, we can use this mapping (also called an encoder) to transform data.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用这个映射（也叫做编码器）来转换数据。
- en: 'Let''s try this out on two examples, `Wednesday` and `Friday`, using the `transform()`
    method:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过 `transform()` 方法在两个例子上试试：`Wednesday` 和 `Friday`：
- en: '[PRE15]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The expected output is this:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出是这样的：
- en: '[PRE16]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As expected, we got the results `4` and `0`, which are the mapping values for
    `Wednesday` and `Friday`, respectively.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期所示，我们得到了 `4` 和 `0` 的结果，这分别是 `Wednesday` 和 `Friday` 的映射值。
- en: 'We can also use this encoder to perform the inverse transformation with the
    `inverse_transform` function. Let''s try this with the values `0` and `4`:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用这个编码器通过 `inverse_transform` 函数执行逆向转换。让我们用值 `0` 和 `4` 来试试：
- en: '[PRE17]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The expected output is this:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出是这样的：
- en: '[PRE18]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As expected, we got back the values `Friday` and `Wednesday`. Now, let's practice
    what we've learned here on the German dataset.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期所示，我们得到了 `Friday` 和 `Wednesday` 的值。现在，让我们在德国数据集上练习我们学到的内容。
- en: 'Exercise 3.02: Applying Label Encoding to Transform Categorical Variables into
    Numerical Variables'
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.02：应用标签编码将类别变量转换为数值变量
- en: In this exercise, we will use one of the preprocessing techniques we just learned,
    label encoding, to transform all categorical variables into numerical ones. This
    step is necessary before training any machine learning model.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用我们刚学到的一个预处理技术——标签编码，将所有类别变量转换为数值变量。在训练任何机器学习模型之前，这一步是必要的。
- en: Note
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'We will be using the same dataset that we used in the previous exercise: the
    German credit approval dataset: [https://packt.live/3eriWTr](https://packt.live/3eriWTr).'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与上一个练习中相同的数据集：德国信用审批数据集：[https://packt.live/3eriWTr](https://packt.live/3eriWTr)。
- en: 'The following steps will help you complete this exercise:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成此练习：
- en: Open a new Jupyter Notebook file.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter Notebook 文件。
- en: 'Import the `pandas` package as `pd`:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas` 包并命名为 `pd`：
- en: '[PRE19]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Create a new variable called `file_url`, which will contain the URL to the
    raw dataset:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的变量 `file_url`，其中将包含原始数据集的 URL：
- en: '[PRE20]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Load the data using the `pd.read_csv()` method:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pd.read_csv()` 方法加载数据：
- en: '[PRE21]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Import `preprocessing` from `scikit-learn`:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`scikit-learn`中的`preprocessing`：
- en: '[PRE22]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Define a function called `fit_encoder()` that takes a DataFrame and a column
    name as parameters and will fit a label encoder on the values of the column. You
    will use `.LabelEncoder()` and `.fit()` from `preprocessing` and `.unique()` from
    `pandas` (this will extract all the possible values of a DataFrame column):'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个名为`fit_encoder()`的函数，该函数接受一个DataFrame和列名作为参数，并在该列的值上拟合一个标签编码器。你将使用`preprocessing`中的`.LabelEncoder()`和`.fit()`以及`pandas`中的`.unique()`（它将提取DataFrame列中的所有可能值）：
- en: '[PRE23]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Define a function called `encode()` that takes a DataFrame, a column name,
    and a label encoder as parameters and will transform the values of the column
    using the label encoder. You will use the `.transform()` method to do this:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个名为`encode()`的函数，该函数接受一个DataFrame、列名和标签编码器作为参数，并使用标签编码器转换该列的值。你将使用`.transform()`方法来完成这项工作：
- en: '[PRE24]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Create a new DataFrame called `cat_df` that contains only non-numeric columns
    and print its first five rows. You will use the `.select_dtypes()` method from
    pandas and specify `exclude=''number''`:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`cat_df`的新DataFrame，其中只包含非数字列，并打印其前五行。你将使用pandas中的`.select_dtypes()`方法，并指定`exclude='number'`：
- en: '[PRE25]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The expected output (not all columns are shown) is this:'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出（并未显示所有列）如下：
- en: '![Figure 3.5: First five rows of the DataFrame containing only non-numeric
    columns'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.5：只包含非数字列的DataFrame前五行'
- en: '](img/B16060_03_05.jpg)'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16060_03_05.jpg)'
- en: 'Figure 3.5: First five rows of the DataFrame containing only non-numeric columns'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.5：只包含非数字列的DataFrame前五行
- en: 'Create a list called `cat_cols` that contains the column name of `cat_df` and
    print its content. You will use `.columns` from pandas to do this:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`cat_cols`的列表，其中包含`cat_df`的列名，并打印其内容。你将使用pandas中的`.columns`来完成：
- en: '[PRE26]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The expected output is this:'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '[PRE27]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Create a `for` loop that will iterate through each column from `cat_cols`,
    fit a label encoder using `fit_encoder()`, and transform the column with the `encode()`
    function:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`for`循环，迭代`cat_cols`中的每一列，使用`fit_encoder()`来拟合标签编码器，并用`encode()`函数转换该列：
- en: '[PRE28]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Print the first five rows of `df`:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印`df`的前五行：
- en: '[PRE29]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The expected output is this:'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '![Figure 3.6: First five rows of the encoded DataFrame'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.6：编码后的DataFrame前五行'
- en: '](img/B16060_03_06.jpg)'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16060_03_06.jpg)'
- en: 'Figure 3.6: First five rows of the encoded DataFrame'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6：编码后的DataFrame前五行
- en: Note
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2Njh57h](https://packt.live/2Njh57h).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/2Njh57h](https://packt.live/2Njh57h)。
- en: You can also run this example online at [https://packt.live/2YZhtx5](https://packt.live/2YZhtx5).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在网上运行这个示例，网址是[https://packt.live/2YZhtx5](https://packt.live/2YZhtx5)。你必须执行整个Notebook才能得到期望的结果。
- en: We have successfully encoded non-numeric columns. Now, our DataFrame contains
    only numeric values.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功编码了非数字列。现在，我们的DataFrame仅包含数字值。
- en: Identifying Features and Labels
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征和标签识别
- en: Before training our model, we still have to perform two final steps. The first
    one is to separate our features from the label (also known as a response variable
    or dependent variable). The `label` column is the one we want our model to predict.
    For the German credit dataset, in our case, it will be the column called `default`,
    which tells us whether an individual will present a risk of defaulting or not.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型之前，我们仍然需要执行两个最终步骤。第一个步骤是将特征与标签分开（也称为响应变量或因变量）。`label`列是我们希望模型预测的内容。对于德国信用数据集，在我们的案例中，它将是名为`default`的列，它告诉我们一个人是否存在违约风险。
- en: The features are all the other columns present in the dataset. The model will
    use the information contained in those columns and find the relevant patterns
    in order to accurately predict the corresponding label.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 特征是数据集中所有其他列。模型将使用这些列中的信息，找到相关的模式，以准确预测相应的标签。
- en: The scikit-learn package requires the labels and features to be stored in two
    different variables. Luckily, the pandas package provides a method to extract
    a column from a DataFrame called `.pop()`.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn包要求标签和特征存储在两个不同的变量中。幸运的是，pandas包提供了一个方法`.pop()`来提取DataFrame中的一列。
- en: 'We will extract the `default` column and store it in a variable called `label`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将提取`default`列，并将其存储在一个名为`label`的变量中：
- en: '[PRE30]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The expected output is this:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '[PRE31]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, if we look at the content of `df`, we will see that the `default` column
    is not present anymore:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们查看`df`的内容，我们会看到`default`列已经不再存在：
- en: '[PRE32]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The expected output is this:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 预期的输出结果是这样的：
- en: '[PRE33]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Now that we have our features and labels ready, we need to split our dataset
    into training and testing sets.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了特征和标签，接下来需要将数据集分成训练集和测试集。
- en: Splitting Data into Training and Testing Using Scikit-Learn
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Scikit-Learn拆分数据为训练集和测试集
- en: 'The final step that''s required before training a classifier is to split our
    data into training and testing sets. We already saw how to do this in *Chapter
    2*, *An Introduction to Regression*:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练分类器之前需要完成的最后一步是将数据拆分为训练集和测试集。我们已经在*第二章*，*回归简介*中看过如何做了：
- en: '[PRE34]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The `train_test_split` method shuffles and then splits our features and labels
    into a training dataset and a testing dataset.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '`train_test_split`方法会将我们的特征和标签打乱并拆分为训练集和测试集。'
- en: We can specify the size of the testing dataset as a number between `0` and `1`.
    A `test_size` of `0.1` means that `10%` of the data will go into the testing dataset.
    You can also specify a `random_state` so that you get the exact same split if
    you run this code again.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将测试集的大小指定为介于`0`和`1`之间的一个数字。`test_size`为`0.1`意味着`10%`的数据将进入测试数据集。你还可以指定`random_state`，这样如果再次运行这段代码，结果将是完全相同的。
- en: We will use the training set to train our classifier and use the testing set
    to evaluate its predictive performance. By doing so, we can assess whether our
    model is overfitting and has learned patterns that are only relevant to the training
    set.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用训练集来训练我们的分类器，并使用测试集来评估其预测性能。通过这种方式，我们可以评估我们的模型是否过拟合，并且是否学习到仅对训练集相关的模式。
- en: In the next section, we will introduce you to the famous k-nearest neighbors
    classifier.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将为你介绍著名的k-近邻分类器。
- en: The K-Nearest Neighbors Classifier
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K-近邻分类器
- en: Now that we have our training and testing data, it is time to prepare our classifier
    to perform k-nearest neighbor classification. After being introduced to the k-nearest
    neighbor algorithm, we will use scikit-learn to perform classification.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了训练数据和测试数据，接下来是准备我们的分类器来执行k-近邻分类。在介绍完k-近邻算法后，我们将使用scikit-learn来执行分类。
- en: Introducing the K-Nearest Neighbors Algorithm (KNN)
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍K-近邻算法（KNN）
- en: The goal of classification algorithms is to divide data so that we can determine
    which data points belong to which group.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 分类算法的目标是将数据划分，以便我们能够确定哪些数据点属于哪个组。
- en: Suppose that a set of classified points is given to us. Our task is to determine
    which class a new data point belongs to.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们给定了一组已分类的点。我们的任务是确定一个新的数据点属于哪个类别。
- en: In order to train a k-nearest neighbor classifier (also referred to as KNN),
    we need to provide the corresponding class for each observation on the training
    set, that is, which group it belongs to. The goal of the algorithm is to find
    the relevant relationship or patterns between the features that will lead to this
    class. The k-nearest neighbors algorithm is based on a proximity measure that
    calculates the distance between data points.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练一个k-近邻分类器（也称为KNN），我们需要为训练集中的每个观测值提供相应的类别，也就是它属于哪个组。该算法的目标是找出特征之间的相关关系或模式，这些关系或模式将引导至这个类别。k-近邻算法基于一种接近度度量，计算数据点之间的距离。
- en: The two most famous proximity (or distance) measures are the Euclidean and the
    Manhattan distance. We will go through more details in the next section.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 两种最著名的接近度（或距离）度量是欧几里得距离和曼哈顿距离。我们将在下一节中详细介绍。
- en: For any new given point, KNN will find its k nearest neighbor, see which class
    is the most frequent between those k neighbors, and assign it to this new observation.
    But what is k, you may ask? Determining the value of k is totally arbitrary. You
    will have to set this value upfront. This is not a parameter that can be learned
    by the algorithm; it needs to be set by data scientists. This kind of parameter
    is called a **hyperparameter**. Theoretically, you can set the value of k to between
    1 and positive infinity.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何新的给定点，KNN将找到它的k个最近邻，查看这k个邻居中哪个类别最频繁，并将其分配给这个新的观测值。但你可能会问，k是什么？确定k的值完全是任意的。你需要预先设置这个值。这不是一个可以由算法学习的参数；它需要由数据科学家设置。这类参数称为**超参数**。理论上，你可以将k的值设定为1到正无穷之间的任何数。
- en: 'There are two main best practices to take into consideration:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种主要的最佳实践需要考虑：
- en: k should always be an odd number. The reason behind this is that we want to
    avoid a situation that ends in a tie. For instance, if you set *k=4* and it so
    happens that two of the neighbors of a point are from class A and the other two
    are from class B, then KNN doesn't know which class to choose. To avoid this situation,
    it is better to choose *k=3* or *k=5*.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k 应该始终是一个奇数。这样做的原因是我们希望避免出现平局的情况。例如，如果你设置 *k=4*，恰好有两个邻居属于 A 类，另外两个邻居属于 B 类，那么
    KNN 就无法决定应该选择哪个类。为了避免这种情况，最好选择 *k=3* 或 *k=5*。
- en: 'The greater k is, the more accurate KNN will be. For example, if we compare
    the cases between *k=1* and *k=15*, the second one will give you more confidence
    that KNN will choose the right class as it will need to look at more neighbors
    before making a decision. On the other hand, with *k=1*, it only looks at the
    closest neighbor and assigns the same class to an observation. But how can we
    be sure it is not an outlier or a special case? Asking more neighbors will lower
    the risk of making the wrong decision. But there is a drawback to this: the higher
    k is, the longer it will take KNN to make a prediction. This is because it will
    have to perform more calculations to get the distance between all the neighbors
    of an observation. Due to this, you have to find the sweet spot that will give
    correct predictions without compromising too much on the time it takes to make
    a prediction.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k 越大，KNN 的准确度就越高。例如，如果我们比较 *k=1* 和 *k=15* 的情况，后者会让你更有信心，因为 KNN 在做出决策之前会查看更多邻居。另一方面，*k=1*
    只查看最接近的邻居，并将同一类分配给观测值。但我们怎么能确定它不是异常值或特殊情况呢？询问更多的邻居会降低做出错误决策的风险。不过，这也有一个缺点：k 越大，KNN
    做出预测的时间就越长。这是因为它需要执行更多计算，才能获得观测点所有邻居之间的距离。因此，你需要找到一个“甜蜜点”，既能给出正确的预测，又不至于在预测时间上妥协太多。
- en: Distance Metrics With K-Nearest Neighbors Classifier in Scikit-Learn
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 K 最近邻分类器的距离度量在 Scikit-Learn 中
- en: 'Many distance metrics could work with the k-nearest neighbors algorithm. We
    will present the two most frequently used ones: the Euclidean distance and the
    Manhattan distance of two data points.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 许多距离度量方法都可以与 k 最近邻算法一起使用。我们将介绍其中最常用的两种：欧几里得距离和曼哈顿距离。
- en: The Euclidean Distance
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 欧几里得距离
- en: 'The distance between two points, `A` and `B`, with the coordinates `A=(a1,
    a2, …, an)` and `B=(b1, b2, …, bn)`, respectively, is the length of the line connecting
    these two points. For example, if A and B are two-dimensional data points, the
    Euclidean distance, `d`, will be as follows:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 两个点 `A` 和 `B` 之间的距离，其中 `A=(a1, a2, …, an)` 和 `B=(b1, b2, …, bn)`，是连接这两个点的线段的长度。例如，如果
    A 和 B 是二维数据点，欧几里得距离 `d` 将如下所示：
- en: '![Figure 3.7: Visual representation of the Euclidean distance between A and
    B'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.7：A 点和 B 点之间的欧几里得距离的可视化表示'
- en: '](img/B16060_03_07.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16060_03_07.jpg)'
- en: 'Figure 3.7: Visual representation of the Euclidean distance between A and B'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7：A 点和 B 点之间的欧几里得距离的可视化表示
- en: 'The formula to calculate the Euclidean distance is as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 计算欧几里得距离的公式如下：
- en: '![Figure 3.8: Distance between points A and B'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.8：A 点和 B 点之间的距离'
- en: '](img/B16060_03_08.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16060_03_08.jpg)'
- en: 'Figure 3.8: Distance between points A and B'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.8：A 点和 B 点之间的距离
- en: As we will be using the Euclidean distance in this book, let's see how we can
    use scikit-learn to calculate the distance of multiple points.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 因为本书将使用欧几里得距离，接下来我们来看一下如何使用 scikit-learn 来计算多个点之间的距离。
- en: We have to import `euclidean_distances` from `sklearn.metrics.pairwise`. This
    function accepts two sets of points and returns a matrix that contains the pairwise
    distance of each point from the first and second sets of points.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要从 `sklearn.metrics.pairwise` 导入 `euclidean_distances`。这个函数接受两组点并返回一个矩阵，矩阵包含每个点与第一组和第二组点之间的成对距离。
- en: 'Let''s take the example of an observation, Z, with coordinates (`4, 4`). Here,
    we want to calculate the Euclidean distance with 3 others points, A, B, and C,
    with the coordinates (`2, 3`), (`3, 7`), and (`1, 6`), respectively:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个观测点 Z 为例，其坐标为 (`4, 4`)。在这里，我们希望计算与另外 3 个点 A、B 和 C 的欧几里得距离，这些点的坐标分别为 (`2,
    3`)、(`3, 7`) 和 (`1, 6`)：
- en: '[PRE35]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The expected output is this:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 预期的输出结果如下：
- en: '[PRE36]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Here, the distance of Z=(`4,4`) and B=(`3,7`) is approximately `3.162`, which
    is what we got in the output.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，Z=(`4,4`) 和 B=(`3,7`) 之间的距离大约为 `3.162`，这就是我们在输出中得到的结果。
- en: 'We can also calculate the Euclidean distances between points in the same set:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以计算同一组中各点之间的欧几里得距离：
- en: '[PRE37]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The expected output is this:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 预期的输出是这样的：
- en: '[PRE38]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The diagonal that contains value `0` corresponds to the Euclidean distance between
    each data point and itself. This matrix is symmetric from this diagonal as it
    calculates the distance of two points and its reverse. For example, the value
    `4.12310563` on the first row is the distance between A and B, while the same
    value on the second row corresponds to the distance between B and A.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 包含 `0` 值的对角线对应于每个数据点与自身的欧几里得距离。这个矩阵是关于对角线对称的，因为它计算了两个点之间的距离以及反向的距离。例如，第一行的值
    `4.12310563` 是 A 和 B 之间的距离，而第二行的相同值则是 B 和 A 之间的距离。
- en: The Manhattan/Hamming Distance
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 曼哈顿/汉明距离
- en: 'The formula of the Manhattan (or Hamming) distance is very similar to the Euclidean
    distance, but rather than using the square root, it relies on calculating the
    absolute value of the difference of the coordinates of the data points:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 曼哈顿（或汉明）距离的公式与欧几里得距离非常相似，但它并不使用平方根，而是依赖于计算数据点坐标差的绝对值：
- en: '![Figure 3.9: The Manhattan and Hamming distance'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.9：曼哈顿距离与汉明距离'
- en: '](img/B16060_03_09.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16060_03_09.jpg)'
- en: 'Figure 3.9: The Manhattan and Hamming distance'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.9：曼哈顿距离与汉明距离
- en: 'You can think of the Manhattan distance as if we''re using a grid to calculate
    the distance rather than using a straight line:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以把曼哈顿距离想象成我们在网格上计算距离，而不是使用直线：
- en: '![Figure 3.10: Visual representation of the Manhattan distance between A and
    B'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.10：曼哈顿距离在 A 和 B 之间的可视化表示'
- en: '](img/B16060_03_10.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16060_03_10.jpg)'
- en: 'Figure 3.10: Visual representation of the Manhattan distance between A and
    B'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.10：曼哈顿距离在 A 和 B 之间的可视化表示
- en: As shown in the preceding plot, the Manhattan distance will follow the path
    defined by the grid to point B from A.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，曼哈顿距离将遵循网格定义的路径，从 A 到达 B。
- en: Another interesting property is that there can be multiple shortest paths between
    A and B, but their Manhattan distances will all be equal to each other. In the
    preceding example, if each cell of the grid equals a unit of 1, then all three
    of the shortest paths highlighted will have a Manhattan distance of 9.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有趣的属性是，A 和 B 之间可能有多个最短路径，但它们的曼哈顿距离将相等。在上面的示例中，如果网格中的每个单元格表示 1 单位，那么所有三条突出显示的最短路径的曼哈顿距离将都是
    9。
- en: The Euclidean distance is a more accurate generalization of distance, while
    the Manhattan distance is slightly easier to calculate as you only need to find
    the difference between the absolute value rather than calculating the difference
    between squares and then taking the root.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 欧几里得距离是更准确的距离泛化方法，而曼哈顿距离稍微容易计算一些，因为你只需要计算绝对值之间的差异，而不是计算平方差后再取平方根。
- en: 'Exercise 3.03: Illustrating the K-Nearest Neighbors Classifier Algorithm in
    Matplotlib'
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.03：在 Matplotlib 中展示 K 最近邻分类器算法
- en: Suppose we have a list of employee data. Our features are the number of hours
    worked per week and the yearly salary. Our label indicates whether an employee
    has stayed with our company for more than 2 years. The length of stay is represented
    by zero if it is less than 2 years and one if it is greater than or equal to 2
    years.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一份员工数据列表。我们的特征是每周工作的小时数和年薪。我们的标签表示员工是否在公司工作超过 2 年。如果停留时间少于 2 年，则用零表示，若大于或等于
    2 年，则用一表示。
- en: We want to create a three-nearest neighbors classifier that determines whether
    an employee will stay with our company for at least 2 years.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望创建一个三近邻分类器，来判断一名员工是否会在公司待满至少 2 年。
- en: Then, we would like to use this classifier to predict whether an employee with
    a request to work 32 hours a week and earning 52,000 dollars per year is going
    to stay with the company for 2 years or not.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们希望使用这个分类器来预测一名要求每周工作32小时并且年收入52,000美元的员工是否会在公司工作2年或更长时间。
- en: 'Follow these steps to complete this exercise:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成本练习：
- en: Note
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The aforementioned dataset is available on GitHub at [https://packt.live/2V5VaV9](https://packt.live/2V5VaV9).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 上述数据集可以在 GitHub 上找到，链接为 [https://packt.live/2V5VaV9](https://packt.live/2V5VaV9)。
- en: Open a new Jupyter Notebook file.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter Notebook 文件。
- en: 'Import the `pandas` package as `pd`:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas` 包并命名为 `pd`：
- en: '[PRE39]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Create a new variable called `file_url()`, which will contain the URL to the
    raw dataset:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的变量，命名为 `file_url()`，它将包含原始数据集的 URL：
- en: '[PRE40]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Load the data using the `pd.read_csv()` method:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pd.read_csv()` 方法加载数据：
- en: '[PRE41]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Print the rows of the DataFrame:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印数据框的行：
- en: '[PRE42]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The expected output is this:'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出是这样的：
- en: '![Figure 3.11: DataFrame of the employees dataset'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.11：员工数据集的DataFrame'
- en: '](img/B16060_03_11.jpg)'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16060_03_11.jpg)'
- en: 'Figure 3.11: DataFrame of the employees dataset'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图3.11：员工数据集的DataFrame
- en: 'Import `preprocessing` from `scikit-learn`:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`scikit-learn`导入`preprocessing`：
- en: '[PRE43]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Instantiate a `MinMaxScaler` with `feature_range=(0,1)` and save it to a variable
    called `scaler`:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个`MinMaxScaler`，并设置`feature_range=(0,1)`，将其保存到名为`scaler`的变量中：
- en: '[PRE44]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Scale the DataFrame using `.fit_transform()`, save the results in a new variable
    called `scaled_employees`, and print its content:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.fit_transform()`缩放数据框，将结果保存到名为`scaled_employees`的新变量中，并打印其内容：
- en: '[PRE45]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The expected output is this:'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '[PRE46]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: In the preceding code snippet, we have scaled our original dataset so that all
    the values range between 0 and 1.
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们已经将原始数据集缩放，使得所有值都在0到1之间。
- en: 'From the scaled data, extract each of the three columns and save them into
    three variables called `hours_worked`, `salary`, and `over_two_years`, as shown
    in the following code snippet:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从缩放后的数据中提取每一列，并将它们保存到名为`hours_worked`、`salary`和`over_two_years`的三个变量中，如下所示的代码片段所示：
- en: '[PRE47]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Import the `matplotlib.pyplot` package as `plt`:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`matplotlib.pyplot`包，并命名为`plt`：
- en: '[PRE48]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Create two scatter plots with `plt.scatter` using `hours_worked` as the *x*-axis
    and `salary` as the *y*-axis, and then create different markers according to the
    value of `over_two_years`. You can add the labels for the *x* and *y* axes with
    `plt.xlabel` and `plt.ylabel`. Display the scatter plots with `plt.show()`:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`plt.scatter`创建两个散点图，`hours_worked`作为* x *轴，`salary`作为* y *轴，然后根据`over_two_years`的值创建不同的标记。你可以使用`plt.xlabel`和`plt.ylabel`添加*
    x *轴和* y *轴的标签。使用`plt.show()`显示散点图：
- en: '[PRE49]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The expected output is this:'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '![Figure 3.12: Scatter plot of the scaled data'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图3.12：缩放数据的散点图'
- en: '](img/B16060_03_12.jpg)'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16060_03_12.jpg)'
- en: '[PRE50]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Now, let's say we got a new observation and we want to calculate the Euclidean
    distance with the data from the scaled dataset.
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，假设我们有一个新的观察值，并且我们想计算与缩放数据集中的数据的欧几里得距离。
- en: 'Create a new variable called `observation` with the coordinates `[0.5, 0.26]`:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`observation`的新变量，坐标为`[0.5, 0.26]`：
- en: '[PRE51]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Import the `euclidean_distances` function from `sklearn.metrics.pairwise`:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn.metrics.pairwise`导入`euclidean_distances`函数：
- en: '[PRE52]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Create a new variable called `features`, which will extract the first two columns
    of the scaled dataset:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`features`的新变量，它将提取缩放数据集中的前两列：
- en: '[PRE53]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Calculate the Euclidean distance between `observation` and `features` using
    `euclidean_distances`, save it into a variable called `dist`, and print its value,
    as shown in the following code snippet:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`euclidean_distances`计算`observation`和`features`之间的欧几里得距离，将结果保存到名为`dist`的变量中，并打印其值，如下所示的代码片段所示：
- en: '[PRE54]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The expected output is this:'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '[PRE55]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Note
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3djY1jO](https://packt.live/3djY1jO).
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/3djY1jO](https://packt.live/3djY1jO)。
- en: You can also run this example online at [https://packt.live/3esx7HF](https://packt.live/3esx7HF).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在在线运行此示例，网址为[https://packt.live/3esx7HF](https://packt.live/3esx7HF)。你必须执行整个Notebook才能获得期望的结果。
- en: 'From the preceding output, we can see that the three nearest neighbors are
    as follows:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中，我们可以看到三个最近的邻居如下：
- en: '`0.1564897` for point `[0.6, 0.37037037, 1.]`'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于点`[0.6, 0.37037037, 1.]`，欧几里得距离是`0.1564897`。
- en: '`0.17114358` for point `[0.6, 0.11111111, 0.]`'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于点`[0.6, 0.11111111, 0.]`，欧几里得距离是`0.17114358`。
- en: '`0.32150303` for point `[0.6, 0.55555556, 1.]`'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于点`[0.6, 0.55555556, 1.]`，欧几里得距离是`0.32150303`。
- en: If we choose `k=3`, KNN will look at the classes for these three nearest neighbors
    and since two of them have a label of `1`, it will assign this class to our new
    observation, `[0.5, 0.26]`. This means that our three-nearest neighbors classifier
    will classify this new employee as being more likely to stay for at least 2 years.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 如果选择`k=3`，KNN将查看这三个最近邻居的类别，由于其中有两个的标签为`1`，它将把此类别分配给我们的新观察值`[0.5, 0.26]`。这意味着我们的三邻居分类器会将这个新员工分类为更有可能至少待满2年的员工。
- en: By completing this exercise, we saw how a KNN classifier will classify a new
    observation by finding its three closest neighbors using the Euclidean distance
    and then assign the most frequent class to it.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 通过完成此练习，我们了解了KNN分类器如何通过找到新观察值的三个最近邻居，并使用欧几里得距离将最频繁的类别分配给它来对新观察值进行分类。
- en: Parameterization of the K-Nearest Neighbors Classifier in scikit-learn
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在scikit-learn中对K-最近邻分类器进行参数化
- en: 'The parameterization of the classifier is where you fine-tune the accuracy
    of your classifier. Since we haven''t learned all of the possible variations of
    k-nearest neighbors, we will concentrate on the parameters that you will understand
    based on this topic:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器的参数化是你微调分类器准确度的地方。由于我们尚未学习所有可能的k近邻变种，我们将专注于你基于本主题能够理解的参数：
- en: Note
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can access the documentation of the k-nearest neighbors classifier here:
    [http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里访问k近邻分类器的文档：[http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)。
- en: '`n_neighbors`: This is the k value of the k-nearest neighbors algorithm. The
    default value is `5`.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_neighbors`：这是k近邻算法中的k值。默认值为`5`。'
- en: '`metric`: When creating the classifier, you will see a name – `Minkowski`.
    Don''t worry about this name – you have learned about the first- and second-order
    Minkowski metrics already. This metric has a `power` parameter. For `p=1`, the
    Minkowski metric is the same as the Manhattan metric. For `p=2`, the Minkowski
    metric is the same as the Euclidean metric.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metric`：在创建分类器时，你会看到一个名称——`Minkowski`。不要担心这个名字——你已经学过了第一阶和第二阶明可夫斯基度量。这个度量有一个`power`参数。对于`p=1`，明可夫斯基度量和曼哈顿度量相同；对于`p=2`，明可夫斯基度量和欧几里得度量相同。'
- en: '`p`: This is the power of the Minkowski metric. The default value is `2`.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`p`：这是明可夫斯基度量的幂次。默认值为`2`。'
- en: 'You have to specify these parameters once you create the classifier:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 创建分类器时，你必须指定以下这些参数：
- en: '[PRE56]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Then, you will have to fit the KNN classifier with your training data:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你需要使用训练数据来拟合KNN分类器：
- en: '[PRE57]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The `predict()` method can be used to predict the label for any new data point:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict()`方法可用于预测任何新数据点的标签：'
- en: '[PRE58]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: In the next exercise, we will be using the KNN implementation from scikit-learn
    to automatically find the nearest neighbors and assign corresponding classes.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，我们将使用scikit-learn的KNN实现，自动查找最近邻并分配相应的类别。
- en: 'Exercise 3.04: K-Nearest Neighbors Classification in scikit-learn'
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 3.04：在scikit-learn中进行K近邻分类
- en: In this exercise, we will use scikit-learn to automatically train a KNN classifier
    on the German credit approval dataset and try out different values for the `n_neighbors`
    and `p` hyperparameters to get the optimal output values. We will need to scale
    the data before fitting KNN.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将使用scikit-learn，自动训练一个KNN分类器，基于德国信用审批数据集，并尝试不同的`n_neighbors`和`p`超参数值，以获得最优的输出值。在拟合KNN之前，我们需要对数据进行缩放。
- en: 'Follow these steps to complete this exercise:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成本练习：
- en: Note
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This exercise is a follow up from *Exercise 3.02*, *Applying Label Encoding
    to Transform Categorical Variables into Numerical*. We already saved the resulting
    dataset from *Exercise 3.02*, *Applying Label Encoding to Transform Categorical
    Variables into Numerical* in the GitHub repository at [https://packt.live/2Yqdb2Q](https://packt.live/2Yqdb2Q).
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习是*练习 3.02*的延续，*应用标签编码将分类变量转化为数值型*。我们已经将*练习 3.02*的结果数据集保存到GitHub仓库：[https://packt.live/2Yqdb2Q](https://packt.live/2Yqdb2Q)。
- en: Open a new Jupyter Notebook.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Jupyter Notebook。
- en: 'Import the `pandas` package as `pd`:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`pandas`包并将其命名为`pd`：
- en: '[PRE59]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Create a new variable called `file_url`, which will contain the URL to the
    raw dataset:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`file_url`的新变量，该变量将包含原始数据集的URL：
- en: '[PRE60]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Load the data using the `pd.read_csv()` method:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pd.read_csv()`方法加载数据：
- en: '[PRE61]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Import `preprocessing` from `scikit-learn`:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`scikit-learn`导入`preprocessing`：
- en: '[PRE62]'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Instantiate `MinMaxScaler` with `feature_range=(0,1)` and save it to a variable
    called `scaler`:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`feature_range=(0,1)`实例化`MinMaxScaler`，并将其保存为名为`scaler`的变量：
- en: '[PRE63]'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Fit the scaler and apply the corresponding transformation to the DataFrame
    using `.fit_transform()` and save the results to a variable called `scaled_credit`:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拟合缩放器并使用`.fit_transform()`方法应用相应的转换到DataFrame，并将结果保存到名为`scaled_credit`的变量中：
- en: '[PRE64]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Extract the `response` variable (the first column) to a new variable called
    `label`:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`response`变量（第一列）提取到一个新的变量中，命名为`label`：
- en: '[PRE65]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Extract the features (all the columns except for the first one) to a new variable
    called `features`:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将特征（所有列，除了第一列）提取到一个名为`features`的新变量中：
- en: '[PRE66]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Import `model_selection.train_test_split` from `sklearn`:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn`导入`model_selection.train_test_split`：
- en: '[PRE67]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Split the scaled dataset into training and testing sets with `test_size=0.2`
    and `random_state=7` using `train_test_split`:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`train_test_split`将缩放后的数据集分成训练集和测试集，`test_size=0.2`，`random_state=7`：
- en: '[PRE68]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Import `neighbors` from `sklearn`:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn`导入`neighbors`：
- en: '[PRE69]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Instantiate `KNeighborsClassifier` and save it to a variable called `classifier`:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化`KNeighborsClassifier`并将其保存到名为`classifier`的变量中：
- en: '[PRE70]'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Fit the k-nearest neighbors classifier on the training set:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上拟合K最近邻分类器：
- en: '[PRE71]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Since we have not mentioned the value of k, the default is `5`.
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于我们没有提到k的值，默认值是`5`。
- en: 'Print the accuracy score for the training set with `.score()`:'
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.score()`打印训练集的准确率：
- en: '[PRE72]'
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'You should get the following output:'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE73]'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'With this, we''ve achieved an accuracy score of `0.78625` on the training set
    with the default hyperparameter values: *k=5* and the Euclidean distance.'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过这些操作，我们在训练集上获得了`0.78625`的准确率，使用的是默认的超参数值：*k=5* 和欧几里得距离。
- en: Let's have a look at the score for the testing set.
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们看一下测试集的得分。
- en: 'Print the accuracy score for the testing set with `.score()`:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.score()`打印测试集的准确率：
- en: '[PRE74]'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'You should get the following output:'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE75]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: The accuracy score dropped to `0.75` on the testing set. This means our model
    is overfitting and doesn't generalize well to unseen data. In the next activity,
    we will try different hyperparameter values and see if we can improve this.
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测试集的准确率降至`0.75`。这意味着我们的模型出现了过拟合，不能很好地对未见过的数据进行泛化。在下一个活动中，我们将尝试不同的超参数值，看看是否能改善这一点。
- en: Note
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2ATeluO](https://packt.live/2ATeluO).
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参见[https://packt.live/2ATeluO](https://packt.live/2ATeluO)。
- en: You can also run this example online at [https://packt.live/2VbDTKx](https://packt.live/2VbDTKx).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你还可以在线运行此示例，地址是[https://packt.live/2VbDTKx](https://packt.live/2VbDTKx)。你必须执行整个Notebook才能获得预期结果。
- en: In this exercise, we learned how to split a dataset into training and testing
    sets and fit a KNN algorithm. Our final model can accurately predict whether an
    individual is more likely to default or not 75% of the time.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们学习了如何将数据集划分为训练集和测试集，并拟合KNN算法。我们的最终模型可以准确预测一个人75%的概率是否会违约。
- en: 'Activity 3.01: Increasing the Accuracy of Credit Scoring'
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 3.01：提高信用评分的准确性
- en: In this activity, you will be implementing the parameterization of the k-nearest
    neighbors classifier and observing the end result. The accuracy of credit scoring
    is currently 75%. You need to find a way to increase it by a few percentage points.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，你将实现K最近邻分类器的参数化并观察最终结果。目前，信用评分的准确率是75%。你需要找到一种方法，将其提高几个百分点。
- en: You can try different values for k (`5`, `10`, `15`, `25`, and `50`) with the
    Euclidean and Manhattan distances.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以尝试不同的k值（`5`、`10`、`15`、`25`和`50`），以及欧几里得距离和曼哈顿距离。
- en: Note
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This activity requires you to complete *Exercise 3.04*, *K-Nearest Neighbors
    Classification in scikit-learn* first as we will be using the previously prepared
    data here.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 这项活动要求你首先完成*练习 3.04*，*scikit-learn中的K最近邻分类*，因为我们将在这里使用之前准备好的数据。
- en: 'The following steps will help you complete this activity:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成这项活动：
- en: Import `neighbors` from `sklearn`.
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn`导入`neighbors`。
- en: Create a function to instantiate `KNeighborsClassifier` with hyperparameters
    specified, fit it with the training data, and return the accuracy score for the
    training and testing sets.
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数来实例化指定超参数的`KNeighborsClassifier`，用训练数据拟合，并返回训练集和测试集的准确率。
- en: Using the function you created, assess the accuracy score for k = (`5`, `10`,
    `15`, `25`, `50`) for both the Euclidean and Manhattan distances.
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用你创建的函数，评估k =（`5`、`10`、`15`、`25`、`50`）时，欧几里得距离和曼哈顿距离的准确率。
- en: Find the best combination of hyperparameters.
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 寻找最佳的超参数组合。
- en: 'The expected output is this:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '[PRE76]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: Note
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution to this activity can be found on page 343.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以在第343页找到。
- en: 'In the next section, we will introduce you to another machine learning classifier:
    a **Support Vector Machine** (**SVM**).'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将介绍另一种机器学习分类器：**支持向量机**（**SVM**）。
- en: Classification with Support Vector Machines
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 支持向量机分类
- en: We first used SVMs for regression in *Chapter 2*, *An Introduction to Regression*.
    In this topic, you will find out how to use SVMs for classification. As always,
    we will use scikit-learn to run our examples in practice.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 *第 2 章*，*回归入门* 中首先使用了 SVM 进行回归。在本节中，你将学习如何使用 SVM 进行分类。和往常一样，我们将使用 scikit-learn
    来实践我们的示例。
- en: What Are Support Vector Machine Classifiers?
  id: totrans-353
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是支持向量机分类器？
- en: The goal of an SVM is to find a surface in an n-dimensional space that separates
    the data points in that space into multiple classes.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: SVM 的目标是找到一个 n 维空间中的表面，将该空间中的数据点分成多个类别。
- en: In two dimensions, this surface is often a straight line. However, in three
    dimensions, the SVM often finds a plane. These surfaces are optimal in the sense
    that they are based on the information available to the machine so that it can
    optimize the separation of the n-dimensional spaces.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在二维空间中，这个表面通常是直线。然而，在三维空间中，SVM 通常找到一个平面。这些表面是最优的，因为它们基于机器可以利用的信息，从而优化了 n 维空间的分隔。
- en: The optimal separator found by the SVM is called the best separating hyperplane.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: SVM 找到的最佳分隔面被称为最佳分隔超平面。
- en: An SVM is used to find one surface that separates two sets of data points. In
    other words, SVMs are **binary classifiers**. This does not mean that SVMs can
    only be used for binary classification. Although we were only talking about one
    plane, SVMs can be used to partition a space into any number of classes by generalizing
    the task itself.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: SVM 用于找到一个分隔两组数据点的表面。换句话说，SVM 是 **二分类器**。这并不意味着 SVM 只能用于二分类。尽管我们只讨论了一个平面，SVM
    可以通过对任务本身进行推广，将空间划分为任意数量的类别。
- en: The separator surface is optimal in the sense that it maximizes the distance
    of each data point from the separator surface.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 分隔面是最优的，因为它最大化了每个数据点与分隔面之间的距离。
- en: A vector is a mathematical structure defined on an n-dimensional space that
    has a magnitude (length) and a direction. In two dimensions, you draw the vector
    (*x, y*) from the origin to the point (x, y). Based on geometry, you can calculate
    the length of the vector using the Pythagorean theorem and the direction of the
    vector by calculating the angle between the horizontal axis and the vector.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 向量是定义在 n 维空间中的数学结构，具有大小（长度）和方向。在二维空间中，你可以从原点绘制向量 (*x, y*) 到点 (x, y)。基于几何学，你可以使用勾股定理计算向量的长度，并通过计算向量与水平轴之间的角度来确定向量的方向。
- en: 'For instance, in two dimensions, the vector (3, -4) has the following magnitude:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在二维空间中，向量 (3, -4) 的大小如下：
- en: '[PRE77]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The expected output is this:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '[PRE78]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'It has the following direction (in degrees):'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 它具有以下方向（以度为单位）：
- en: '[PRE79]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The expected output is this:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '[PRE80]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: Understanding Support Vector Machines
  id: totrans-368
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解支持向量机
- en: 'Suppose that two sets of points with two different classes, 0 and 1, are given.
    For simplicity, we can imagine a two-dimensional plane with two features: one
    mapped on the horizontal axis and one mapped on the vertical axis.'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 假设给定了两组具有不同类别（类别 0 和类别 1）的点。为了简单起见，我们可以想象一个二维平面，具有两个特征：一个映射在水平轴上，另一个映射在垂直轴上。
- en: 'The objective of the SVM is to find the best separating line that separates
    points `A`, `D`, `C`, `B`, and `H`, which all belong to class 0, from points `E`,
    `F`, and `G`, which are of class 1:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: SVM 的目标是找到最佳分隔线，将属于类别 0 的点`A`、`D`、`C`、`B`和`H`与属于类别 1 的点`E`、`F`和`G`分开：
- en: '![Figure 3.13: Line separating red and blue members'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.13：分隔红色和蓝色成员的线'
- en: '](img/B16060_03_13.jpg)'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16060_03_13.jpg)'
- en: 'Figure 3.13: Line separating red and blue members'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.13：分隔红色和蓝色成员的线
- en: 'But separation is not always that obvious. For instance, if there is a new
    point of class 0 in-between `E`, `F`, and `G`, there is no line that could separate
    all the points without causing errors. If the points from class 0 form a full
    circle around the class 1 points, there is no straight line that could separate
    the two sets:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，分隔并不总是那么明显。例如，如果类别 0 的新点位于 `E`、`F` 和 `G` 之间，就没有一条线能够分开所有的点而不导致错误。如果类别 0 的点围绕类别
    1 的点形成一个完整的圆圈，就没有直线能够分开这两组点：
- en: '![Figure 3.14: Graph with two outlier points'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.14：带有两个异常点的图'
- en: '](img/B16060_03_14.jpg)'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16060_03_14.jpg)'
- en: 'Figure 3.14: Graph with two outlier points'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.14：带有两个异常点的图
- en: For instance, in the preceding graph, we tolerate two outlier points, `O` and
    `P`.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在前面的图中，我们容忍了两个异常点，`O` 和 `P`。
- en: 'In the following solution, we do not tolerate outliers, and instead of a line,
    we create the best separating path consisting of two half-lines:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下解决方案中，我们不容忍异常值，而是通过两个半线来构建最佳分隔路径，代替使用一条线：
- en: '![Figure 3.15: Graph removing the separation of the two outliers'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.15：移除两个异常值的分隔图'
- en: '](img/B16060_03_15.jpg)'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16060_03_15.jpg)'
- en: 'Figure 3.15: Graph removing the separation of the two outliers'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.15：移除两个异常值的分隔图
- en: The perfect separation of all data points is rarely worth the resources. Therefore,
    the SVM can be regularized to simplify and restrict the definition of the best
    separating shape and allow outliers.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 完美分隔所有数据点通常并不值得投入过多资源。因此，支持向量机可以通过正则化来简化并限制最佳分隔形状的定义，从而允许异常值的存在。
- en: The regularization parameter of an SVM determines the rate of errors to allow
    or forbid misclassifications.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机的正则化参数决定了允许的误差率或禁止误分类的程度。
- en: An SVM has a kernel parameter. A linear kernel strictly uses a linear equation
    to describe the best separating hyperplane. A polynomial kernel uses a polynomial,
    while an exponential kernel uses an exponential expression to describe the hyperplane.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机有一个核函数参数。线性核使用线性方程来严格描述最佳分隔超平面。多项式核使用多项式，而指数核使用指数表达式来描述超平面。
- en: A margin is an area centered around the separator and is bounded by the points
    closest to the separator. A balanced margin has points from each class that are
    equidistant from the line.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 边距是围绕分隔超平面的一片区域，其边界由最靠近分隔超平面的点所限定。一个平衡的边距是从每个类别中选出的点，它们距离分隔线等远。
- en: When it comes to defining the allowed error rate of the best separating hyperplane,
    a gamma parameter decides whether only the points near the separator count in
    determining the position of the separator, or whether the points farthest from
    the line count, too. The higher the gamma, the lower the number of points that
    influence the location of the separator.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到定义最佳分隔超平面的允许误差率时，**gamma** 参数决定了在确定分隔超平面位置时，是仅考虑接近分隔超平面的点，还是考虑最远离分隔线的点。gamma
    值越高，影响分隔超平面位置的点数越少。
- en: Support Vector Machines in scikit-learn
  id: totrans-388
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: scikit-learn 中的支持向量机
- en: 'Our entry point is the end result of *Activity 3.02*, *Support Vector Machine
    Optimization in scikit-learn*. Once we have split the training and test data,
    we are ready to set up the classifier:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的切入点是*活动 3.02*，*scikit-learn 中的支持向量机优化*。一旦我们划分了训练数据和测试数据，就可以设置分类器了：
- en: '[PRE81]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Instead of using the k-nearest neighbors classifier, we will use the `svm.SVC()` classifier:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `svm.SVC()` 分类器，而不是使用 k 最近邻分类器：
- en: '[PRE82]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'The expected output is this:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 期望的输出是这样的：
- en: '[PRE83]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: It seems that the default SVM classifier of scikit-learn does a slightly better
    job than the k-nearest neighbors classifier.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来 scikit-learn 的默认支持向量机分类器比 k 最近邻分类器稍微更好。
- en: Parameters of the scikit-learn SVM
  id: totrans-396
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: scikit-learn 支持向量机的参数
- en: 'The following are the parameters of the scikit-learn SVM:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 scikit-learn 支持向量机的参数：
- en: '`kernel`: This is a string or callable parameter specifying the kernel that''s
    being used in the algorithm. The predefined kernels are `linear`, `poly`, `rbf`,
    `sigmoid`, and `precomputed`. The default value is `rbf`.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel`：这是一个字符串或可调用参数，用于指定算法中使用的核函数。预定义的核函数包括 `linear`、`poly`、`rbf`、`sigmoid`
    和 `precomputed`。默认值是 `rbf`。'
- en: '`degree`: When using a polynomial, you can specify the degree of the polynomial.
    The default value is `3`.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`degree`：当使用多项式核时，你可以指定多项式的度数。默认值是 `3`。'
- en: '`gamma`: This is the kernel coefficient for `rbf`, `poly`, and `sigmoid`. The
    default value is `auto`, which is computed as *1/number_of_features*.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gamma`：这是用于 `rbf`、`poly` 和 `sigmoid` 核函数的核系数。默认值是 `auto`，它的计算方式是 *1/特征数量*。'
- en: '`C`: This is a floating-point number with a default of `1.0` that describes
    the penalty parameter of the error term.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`C`：这是一个浮动数值，默认值为 `1.0`，表示误差项的惩罚参数。'
- en: Note
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: You can read about the parameters in the reference documentation at [http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在参考文档中阅读关于这些参数的详细信息，地址为 [http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)。
- en: 'Here is an example of an SVM:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个支持向量机的例子：
- en: '[PRE84]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Activity 3.02: Support Vector Machine Optimization in scikit-learn'
  id: totrans-406
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 3.02：scikit-learn 中的支持向量机优化
- en: In this activity, you will be using, comparing, and contrasting the different
    SVMs' classifier parameters. With this, you will find a set of parameters resulting
    in the highest classification data on the training and testing data that we loaded
    and prepared in *Activity 3.01,* *Increasing the Accuracy of Credit Scoring*.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，你将使用、比较和对比不同SVM分类器的参数。通过这些，你将找到一组在我们加载并准备好的训练和测试数据中，能够产生最高分类准确率的参数，这些数据在*活动
    3.01*中已经准备好，*提高信用评分的准确性*。
- en: 'You must different combinations of hyperparameters for SVM:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须使用不同的SVM超参数组合：
- en: '`kernel="linear"`'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel="linear"`'
- en: '`kernel="poly", C=1, degree=4, gamma=0.05`'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel="poly", C=1, degree=4, gamma=0.05`'
- en: '`kernel="poly", C=1, degree=4, gamma=0.05`'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel="poly", C=1, degree=4, gamma=0.05`'
- en: '`kernel="poly", C=1, degree=4, gamma=0.25`'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel="poly", C=1, degree=4, gamma=0.25`'
- en: '`kernel="poly", C=1, degree=4, gamma=0.5`'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel="poly", C=1, degree=4, gamma=0.5`'
- en: '`kernel="poly", C=1, degree=4, gamma=0.16`'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel="poly", C=1, degree=4, gamma=0.16`'
- en: '`kernel="sigmoid"`'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel="sigmoid"`'
- en: '`kernel="rbf", gamma=0.15`'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel="rbf", gamma=0.15`'
- en: '`kernel="rbf", gamma=0.25`'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel="rbf", gamma=0.25`'
- en: '`kernel="rbf", gamma=0.5`'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel="rbf", gamma=0.5`'
- en: '`kernel="rbf", gamma=0.35`'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kernel="rbf", gamma=0.35`'
- en: 'The following steps will help you complete this activity:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成本次活动：
- en: Open a new Jupyter Notebook file and execute all the steps mentioned in the
    previous, *Exercise 3.04*, *K-Nearest Neighbor Classification in scikit-learn*.
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Jupyter Notebook文件，并执行前面提到的所有步骤，*练习3.04*，*在scikit-learn中进行K近邻分类*。
- en: Import `svm` from `sklearn`.
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`sklearn`导入`svm`。
- en: Create a function to instantiate an SVC with the hyperparameters specified,
    fit with the training data, and return the accuracy score for the training and
    testing sets.
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数，用于实例化一个SVC模型，设置指定的超参数，使用训练数据进行拟合，并返回训练集和测试集的准确度评分。
- en: Using the function you created, assess the accuracy scores for the different
    hyperparameter combinations.
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用你创建的函数，评估不同超参数组合的准确度评分。
- en: Find the best combination of hyperparameters.
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到最佳的超参数组合。
- en: 'The expected output is this:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '[PRE85]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Note
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 347.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 本次活动的解答可以在第347页找到。
- en: Summary
  id: totrans-430
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned about the basics of classification and the difference
    between regression problems. Classification is about predicting a response variable
    with limited possible values. As for any data science project, data scientists
    need to prepare the data before training a model. In this chapter, we learned
    how to standardize numerical values and replace missing values. Then, you were
    introduced to the famous k-nearest neighbors algorithm and discovered how it uses
    distance metrics to find the closest neighbors to a data point and then assigns
    the most frequent class among them. We also learned how to apply an SVM to a classification
    problem and tune some of its hyperparameters to improve the performance of the
    model and reduce overfitting.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了分类的基础知识，以及回归问题之间的区别。分类是关于预测一个具有有限可能值的响应变量。对于任何数据科学项目，数据科学家都需要在训练模型之前准备好数据。在本章中，我们学习了如何标准化数值并替换缺失值。接着，你了解了著名的k近邻算法，并发现它如何使用距离度量来寻找与数据点最接近的邻居，并从中分配最常见的类别。我们还学习了如何将SVM应用于分类问题，并调优其一些超参数，以提高模型性能并减少过拟合。
- en: In the next chapter, we will walk you through a different type of algorithm,
    called decision trees.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将带你了解另一种类型的算法，叫做决策树。
