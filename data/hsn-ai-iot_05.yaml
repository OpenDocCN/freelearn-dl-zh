- en: Genetic Algorithms for IoT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 遗传算法在物联网中的应用
- en: 'In the previous chapter, we looked at different deep learning-based algorithms;
    these algorithms have shown their success in the fields of recognition, detection,
    reconstruction, and even in the generation of vision, speech, and text data. While,
    at present, **deep learning** (**DL**) is on top in terms of both application
    and employability, it has close competition with evolutionary algorithms. The
    algorithms are inspired by the natural process of evolution, the world''s best
    optimizers. Yes, even we are the result of years of genetic evolution. In this
    chapter, you will be introduced to the fascinating world of evolutionary algorithms
    and learn about a specific type of evolutionary algorithm, genetic algorithms,
    in more detail. In this chapter, you will learn about the following:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们研究了不同的基于深度学习的算法；这些算法在识别、检测、重建甚至在视觉、语音和文本数据生成领域取得了成功。目前，**深度学习**（**DL**）在应用和就业方面处于领先地位，但它与进化算法有着激烈的竞争。这些算法受自然进化过程的启发，是世界上最好的优化器。是的，连我们自己也是多年遗传进化的结果。在这一章中，你将进入迷人的进化算法世界，并更详细地了解一种特定类型的进化算法——遗传算法。在这一章中，你将学习到以下内容：
- en: What is optimization
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是优化
- en: Different methods to solve an optimization problem
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决优化问题的不同方法
- en: Understand the intuition behind genetic algorithms
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解遗传算法背后的直觉
- en: The advantages of genetic algorithms
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遗传算法的优点
- en: Understand and implement the processes of cross-over, mutation, and fitness
    function selection
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解并实现交叉、变异和适应度函数选择的过程
- en: Use a genetic algorithm to find a lost password
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用遗传算法找回丢失的密码
- en: Various uses of genetic algorithms in optimizing your models
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遗传算法在优化模型中的各种应用
- en: The Distributed Evolutionary Algorithms in the Python genetic algorithm library
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 遗传算法库中的分布式进化算法
- en: Optimization
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化
- en: Optimization is not a new word; we have used it earlier with respect to both
    machine learning and DL algorithms, where we used the TensorFlow auto differentiator
    to find the optimum model weights and biases using a form of gradient descent
    algorithm. In this section, we will learn a little more about optimization, optimization
    problems, and different techniques used to perform optimization.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 优化（Optimization）不是一个新词汇；我们之前已经在机器学习和深度学习（DL）算法中使用过它，当时我们使用了 TensorFlow 自动微分器，通过一种梯度下降算法找到最佳的模型权重和偏差。在本节中，我们将深入了解优化、优化问题以及执行优化的不同技术。
- en: In its most basic terms, **optimization** is the process of making something
    better. The idea is to find the best solution, and obviously when we talk about
    the best solution, it means there exists more than one solution. In optimization,
    we try to adjust our variable parameters/processes/inputs so that we can find
    the minimum or maximum output. Normally, the variables constitute the inputs,
    we have a function called an **objective** **function**, **loss** **function**,
    or **fitness** **function**, and as output we expect the cost/loss or fitness.
    The cost or loss should be minimized, and if we define fitness, then it should
    be maximized. Here, we vary the inputs (variables) to achieve a desired (optimized)
    output.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从最基本的角度来看，**优化**是使某物变得更好的过程。其核心思想是找到最佳的解决方案，显然，当我们谈论最佳解决方案时，意味着存在不止一个解决方案。在优化中，我们尝试调整我们的变量参数/过程/输入，以便找到最小或最大的输出。通常，这些变量构成输入，我们有一个称为**目标函数**、**损失函数**或**适应度函数**的函数，作为输出我们期望的是成本/损失或适应度。成本或损失应该最小化，如果我们定义适应度，那么它应该最大化。在这里，我们通过改变输入（变量）来实现所需的（优化的）输出。
- en: I hope you can appreciate that calling it loss/cost or fitness is just a matter
    of choice, the function which calculates the cost and needs to be minimized, if
    we just add a negative sign to it then we expect the modified function to be maximized. As
    an example, minimizing *2 - x²* over the interval *-2 < x< 2* is the same as maximizing *x*² -
    2 over the same interval.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你能理解，称其为损失/成本或适应度只是一个选择问题，计算成本并需要最小化的函数，如果我们给它加上一个负号，那么我们期望修改后的函数能够最大化。例如，最小化*2
    - x²*在区间*-2 < x < 2*上，和在相同区间内最大化*x*² - 2是一样的。
- en: 'Our daily lives are full of many such optimization tasks. What will be the
    best route to take to the office? Which project should I do first? Preparing for
    an interview what topics to read such that your success rate in the interview
    is maximized. The following diagram shows the basic relationship between **Input
    Variables**, the **Function** to be optimized, and the **Output/Cos****t**:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的日常生活中充满了许多这样的优化任务。到办公室的最佳路线应该是怎样的？我应该先做哪个项目？为面试做准备，应该阅读哪些主题以最大化面试成功率？下图展示了**输入变量**、**需要优化的函数**和**输出/成本**之间的基本关系：
- en: '![](img/5faa50e4-a362-4b51-9857-706e8d811926.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5faa50e4-a362-4b51-9857-706e8d811926.png)'
- en: Relationship between input, the function to be optimized, and the output
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 输入、需要优化的函数和输出之间的关系
- en: 'The aim is to minimize the cost, such that the constraints specified by the
    function are satisfied by the input variables. The mathematical relationship between
    the cost function, constraints, and input variables determines the complexity
    of the optimization problem. One of the key issues is whether the cost function
    and constraints are convex or non-convex. If the cost function and constraints
    are convex, we can be confident that there does exist a feasible solution, and
    if we search in a sufficiently large domain, we will find one. The following figure
    shows an example of a convex cost function:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是最小化成本，使得函数指定的约束条件通过输入变量得到满足。成本函数、约束条件和输入变量之间的数学关系决定了优化问题的复杂性。一个关键问题是成本函数和约束条件是凸的还是非凸的。如果成本函数和约束条件是凸的，我们可以确信确实存在可行解，并且如果我们在一个足够大的领域内进行搜索，我们一定能找到一个。下图展示了一个凸成本函数的示例：
- en: '![](img/2cccbeb8-8a44-49be-825a-d01a8de0aa69.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2cccbeb8-8a44-49be-825a-d01a8de0aa69.png)'
- en: A convex cost function. The one on the left is the surface plot and the one
    on the right shows the contour plot of the same cost function. The darkest red
    point in the image corresponds to the optimum solution point.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一个凸成本函数。左边是表面图，右边显示的是同一成本函数的等高线图。图像中最深的红色点对应于最优解点。
- en: If, on other hand, the cost function or constraints are non-convex, the optimization
    problem becomes harder and we cannot be sure that there does exist a solution,
    or that we can even find one.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果成本函数或约束条件是非凸的，优化问题会变得更加困难，我们无法确定是否确实存在解决方案，或者我们是否能够找到一个。
- en: There are various methods to solve optimization problems in mathematics and
    computer programming. Let's find out a little about each of them next.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学和计算机编程中，有多种方法可以解决优化问题。接下来让我们了解一下它们每一种方法。
- en: Deterministic and analytic methods
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定性和解析方法
- en: 'When the objective function is smooth with a continuous second derivative,
    then we know from the knowledge of calculus that at a local minimum the following
    are true:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当目标函数是平滑的并且具有连续的二阶导数时，根据微积分的知识，我们知道在局部最小值处，以下条件成立：
- en: The gradient of the objective function at minima *x**, that is, *f*'(*x**) = *0*
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在最小值处，目标函数的梯度是0，即*f*'(*x*) = *0*
- en: The second derivative (Hessian *H*(*x**) = ∇²*f*(*x*)) is positively definite
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二阶导数（Hessian *H*(*x*) = ∇²*f*(*x*)）是正定的
- en: In such conditions, for some problems, it is possible to find the solution analytically
    by determining the zeros of the gradient and verifying the positive definiteness
    of the Hessian matrix at the zeros. So, in these cases, we can explore the search
    space iteratively for the minima of the objective function. There are various
    search methods; let's see them.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，对于某些问题，可以通过确定梯度的零点并验证Hessian矩阵在零点处的正定性来解析地找到解决方案。因此，在这些情况下，我们可以通过迭代地探索搜索空间来找到目标函数的最小值。有多种搜索方法；让我们来看一看。
- en: Gradient descent method
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度下降法
- en: 'We learned about gradient descent and how it works in earlier chapters, and
    we saw that the search direction is the direction of the gradient descent, -∇*f*(*x*).
    It is also called the **Cauchy** **method** because it was given by Cauchy, in
    1847, and since then it has been very popular. We start from an arbitrary point
    on the objective function surface and change the variables (in earlier chapters,
    these were the weights and biases) along the direction of the gradient. Mathematically,
    it is represented as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面的章节中学习了梯度下降及其工作原理，看到搜索方向是梯度下降的方向，-∇*f*(*x*)。这也叫做**柯西方法**，因为它是由柯西于1847年提出的，从那时起就非常流行。我们从目标函数表面上的一个任意点开始，沿着梯度方向改变变量（在前面的章节中，这些是权重和偏置）。数学上，它表示为：
- en: '![](img/2a2c400a-a638-4540-80fe-16d068edddeb.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2a2c400a-a638-4540-80fe-16d068edddeb.png)'
- en: 'Here *α[n]* is the step size (variation/learning rate) at iteration *n*. Gradient
    descent algorithms have worked well in training DL models, but they have some
    severe drawbacks:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*α[n]*是迭代*n*时的步长（变化/学习率）。梯度下降算法在训练深度学习模型时效果良好，但也有一些严重的缺点：
- en: The performance of the optimizer used depends greatly on the learning rate and
    other constants. If you change them even slightly, there is a big possibility
    that the network may not converge. And it is because of this that sometimes researchers
    call training a model an art, or alchemy.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所使用的优化器性能在很大程度上取决于学习率和其他常数。如果稍微改变它们，网络很可能不会收敛。正因为如此，研究人员有时将训练模型称为一门艺术，或炼金术。
- en: Since these methods are based on derivatives, they do not work for discrete
    data.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于这些方法基于导数，它们不适用于离散数据。
- en: 'We cannot reliably apply it when the objective function is non-convex, which
    is the case in many DL networks (especially models using a non-linear activation
    function). The presence of many hidden layers can result in many local minima,
    and there is a strong possibility that the model gets stuck in a local minimum.
    Here, you can see an example of the objective function with many local minima:'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当目标函数是非凸时，我们无法可靠地应用该方法，这在许多深度学习网络中是常见的（尤其是使用非线性激活函数的模型）。许多隐藏层的存在可能导致多个局部最小值，模型很有可能陷入局部最小值中。这里，你可以看到一个具有多个局部最小值的目标函数示例：
- en: '![](img/461829bc-e0cd-4ba9-afb6-537412c2290b.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/461829bc-e0cd-4ba9-afb6-537412c2290b.png)'
- en: A cost function with many local minima. The one on the left is the surface plot
    and the one on the right shows the contour plot of the same cost function. The
    dark red points in the image correspond to minima.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 具有多个局部最小值的成本函数。左侧是表面图，右侧是相同成本函数的等高线图。图中的深红色点对应于最小值。
- en: 'There are many variants of the gradient descent method, and the most popular
    of them are available in the TensorFlow optimizers, including the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降法有许多变种，其中最流行的几种可以在TensorFlow优化器中找到，包括以下几种：
- en: Stochastic gradient optimizer
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机梯度优化器
- en: Adam optimizer
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adam优化器
- en: Adagrad optimizer
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adagrad优化器
- en: RMSProp optimizer
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RMSProp优化器
- en: You can learn more about the different optimizers available in TensorFlow from
    the TensorFlow documentation at [https://www.tensorflow.org/api_guides/python/train](https://www.tensorflow.org/api_guides/python/train).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过TensorFlow文档中的[https://www.tensorflow.org/api_guides/python/train](https://www.tensorflow.org/api_guides/python/train)了解更多有关TensorFlow中不同优化器的信息。
- en: A nice source is a blog ([http://ruder.io/optimizing-gradient-descent/index.html#gradientdescentoptimizationalgorithms](http://ruder.io/optimizing-gradient-descent/index.html#gradientdescentoptimizationalgorithms))
    by Sebastian Ruder based on his arXiv paper at [https://arxiv.org/abs/1609.04747](https://arxiv.org/abs/1609.04747).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一个不错的来源是Sebastian Ruder的博客（[http://ruder.io/optimizing-gradient-descent/index.html#gradientdescentoptimizationalgorithms](http://ruder.io/optimizing-gradient-descent/index.html#gradientdescentoptimizationalgorithms)），基于他在arXiv上的论文[https://arxiv.org/abs/1609.04747](https://arxiv.org/abs/1609.04747)。
- en: Newton-Raphson method
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 牛顿-拉夫森方法
- en: This method is based on the second order Taylor series expansion of the objective
    function, *f*(*x*), around the point *x^*:*
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法基于目标函数*f*(*x*)在点*x^*附近的二阶泰勒级数展开：
- en: '*![](img/a11222e4-a00f-4af3-a479-040ed79a23e1.png)*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](img/a11222e4-a00f-4af3-a479-040ed79a23e1.png)*'
- en: 'Here, *x** is the point about which the Taylor series is expanded, *x* is a
    point near *x**, the superscript *T* represents the transpose, and *H* is the
    Hessian matrix with elements given by the following:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*x**是泰勒级数展开的点，*x*是靠近*x**的点，超脚本*T*表示转置，*H*是Hessian矩阵，其元素如下所示：
- en: '*![](img/937ab061-0f44-4ee3-928f-32bcb2750d9f.png)*'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](img/937ab061-0f44-4ee3-928f-32bcb2750d9f.png)*'
- en: 'Taking the gradient of the Taylor series expansion and equating to **0**, we
    get this:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对泰勒级数展开式求梯度并使其等于**0**，我们得到：
- en: '*![](img/59bfab87-627a-4859-9628-f9b3601c22af.png)*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](img/59bfab87-627a-4859-9628-f9b3601c22af.png)*'
- en: 'Assuming the initial guess as *x*[0], the next point *x*[n+1] can be obtained
    from the previous point *x*[n] using this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 假设初始猜测为*x*[0]，下一个点*x*[n+1]可以通过以下公式从前一个点*x*[n]计算得到：
- en: '*![](img/015ff534-b7eb-48cc-85e1-e831ef67b9b5.png)*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](img/015ff534-b7eb-48cc-85e1-e831ef67b9b5.png)*'
- en: The method uses both the first and the second partial derivatives of the objective
    function to find the minima. At iteration *k*, it approximates the objective function
    by a quadratic function around *x*(*k*) and moves toward its minima.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法同时使用目标函数的一阶和二阶偏导数来寻找最小值。在第*k*次迭代时，它通过围绕*x*(*k*)的二次函数来逼近目标函数，并朝向最小值移动。
- en: 'Since computing the Hessian matrix is computationally expensive and not normally
    known, a large number of algorithms exist around approximating the Hessian; these
    techniques are called **quasi-Newton methods**. They can be represented as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于计算Hessian矩阵在计算上很昂贵且通常未知，因此有许多算法致力于逼近Hessian矩阵；这些技术被称为**拟牛顿方法**。它们可以表示如下：
- en: '*![](img/fd1156ee-4259-4c4f-b0c2-10b26246b773.png)*'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](img/fd1156ee-4259-4c4f-b0c2-10b26246b773.png)*'
- en: '*α[n]* is the step size (variation/learning rate) at iteration *n*, and *A[n]* is
    the approximation to the Hessian matrix at iteration *n*. We construct a sequence
    of approximations to the Hessian, such that the following is true:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '*α[n]*是第*n*次迭代中的步长（变化/学习率），*A[n]*是第*n*次迭代中的Hessian矩阵逼近值。我们构造一个Hessian的逼近序列，使得以下条件成立：'
- en: '*![](img/6b0712ed-5a5b-4685-b6d3-6f4ac7fa192e.png)*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](img/6b0712ed-5a5b-4685-b6d3-6f4ac7fa192e.png)*'
- en: 'Two popular quasi-Newton methods are as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 两种流行的拟牛顿方法如下：
- en: Davidon-Fletcher-Powell algorithm
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Davidon-Fletcher-Powell算法
- en: Broyden-Fletcher-Goldfarb-Shanno algorithm
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Broyden-Fletcher-Goldfarb-Shanno算法
- en: When the approximation *A[n]* to the Hessian is the identity matrix, the Newton
    method becomes the gradient descent method.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当Hessian的逼近*A[n]*是单位矩阵时，牛顿法变成了梯度下降法。
- en: The major disadvantage of the Newton method is that it is not scalable to problems
    with a high-dimensional input feature space.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 牛顿法的主要缺点是它无法扩展到具有高维输入特征空间的问题。
- en: Natural optimization methods
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然优化方法
- en: Natural optimization methods are inspired by some natural processes, that is,
    a process, existing in nature, that is remarkably successful at optimizing some
    natural phenomena. These algorithms do not require taking objective function derivatives,
    and thus can be employed even for discrete variables and non-continuous objective
    functions.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 自然优化方法受到一些自然过程的启发，即在自然界中存在的一些在优化某些自然现象上非常成功的过程。这些算法不需要求取目标函数的导数，因此即使是离散变量和非连续目标函数也能使用。
- en: Simulated annealing
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模拟退火
- en: Simulated annealing is a stochastic method. It is inspired by the physical process
    of annealing, in which a solid is first heated to a high enough temperature so
    that it melts, and then the temperature is decreased slowly; this allows the particles
    of the solid to arrange themselves in the lowest possible energy state and thus
    produce a highly structured lattice.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟退火是一种随机方法。它受到物理退火过程的启发，在该过程中，一个固体首先被加热到足够高的温度使其融化，然后温度慢慢降低；这使得固体的粒子能够以最低的能量状态重新排列，从而产生一个高度结构化的晶格。
- en: 'We start with some random values assigned to each variable; this represents
    the initial state. At each step, we pick a variable (or group of variables) at
    random and then select a random value. If, upon the assignment of that value to
    the variable, there is an improvement in the objective function, the algorithm
    accepts the assignment, there is a new current assignment, and the state of the
    system changes. Otherwise, it accepts the assignment with some probability *P*,
    which depends on the temperature *T* and the difference between the values of
    the objective function in the current state and the new state. If the change is
    not accepted, the current state remains unchanged. The probability *P* that we
    will change from state *i* to state *j* is as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从为每个变量分配一些随机值开始，这表示初始状态。在每一步中，我们随机选择一个变量（或一组变量），然后选择一个随机值。如果将该值分配给变量后，目标函数有所改善，则算法接受该赋值，形成新的当前赋值，系统状态发生变化。否则，它以一定的概率*P*接受该赋值，*P*的值依赖于温度*T*以及当前状态和新状态下目标函数值的差异。如果不接受变化，则当前状态保持不变。从状态*i*到状态*j*的转变概率*P*如下所示：
- en: '![](img/d5e95f0e-aad9-4b60-9300-738600d75d2f.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d5e95f0e-aad9-4b60-9300-738600d75d2f.png)'
- en: Here, *T* represents a variable analogous to temperature in the physical system.
    As the temperature approaches *0*, the simulated annealing algorithm reduces to
    the gradient descent algorithm.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*T*表示一个与物理系统中温度类似的变量。当温度趋近于*0*时，模拟退火算法就变成了梯度下降算法。
- en: Particle Swarm Optimization
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 粒子群优化
- en: '**Particle Swarm Optimization** (**PSO**) was developed by Edward and Kennedy
    in 1995\. It is based on the social behavior of animals, such as a flock of birds.
    You must have noticed in the sky, birds fly in a V shape. Those who have studied
    bird behavior tell us that birds fly like this when in search of food or a better
    location, with the one leading being nearest to the desired source.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**粒子群优化**（**PSO**）由爱德华和肯尼迪于1995年提出。它基于动物的社会行为，例如鸟群。你一定注意到，在天空中，鸟群飞行时呈V字形。研究鸟类行为的人告诉我们，当鸟群寻找食物或更好的栖息地时，它们会以这种方式飞行，队伍前面的鸟最接近目标源。'
- en: Now, when they fly, the leading bird does not remain the same; instead, it changes
    as they move. The bird in the flock that sees the food sends a sound signal, and
    all other birds then collect around that bird in a V fashion. This is a continuous
    repetitive process, and has served birds well for millions of years.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当它们飞行时，领头的鸟并不固定不变；相反，随着它们的移动，领头鸟会发生变化。看到食物的鸟会发出声音信号，其他鸟会围绕着它以V字形聚集。这是一个连续重复的过程，已经让鸟类受益了数百万年。
- en: PSO takes inspiration from this bird behavior and uses it to solve optimization
    problems. In PSO, every single solution is a bird (called a **particle**) in the
    search space. Each particle has a fitness value, which is evaluated by the fitness
    function to be optimized; they also have velocities, which direct the flying of
    the particles. The particles fly through the problem search space by following
    the current optimum particle.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: PSO从这种鸟类行为中汲取灵感，并利用它来解决优化问题。在PSO中，每个解决方案都是搜索空间中的一只鸟（称为**粒子**）。每个粒子都有一个适应度值，这个值通过待优化的适应度函数来评估；它们还有速度，决定了粒子的飞行方向。粒子通过跟随当前最优粒子飞行，通过问题的搜索空间。
- en: 'The particles are moved around in the search space guided by two best fitness
    values, one their own best known position in the search space (**pbest**: particle
    best), the other the entire swarm''s best known fitness value (**gbest**: global
    best). As improved positions are discovered, they are used to guide the movements
    of the particles of the swarm. This process is repeated and it is hoped that an
    optimum solution will eventually be discovered.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 粒子在搜索空间中根据两个最佳适应度值进行移动，一个是它们自己已知的最佳位置（**pbest**：粒子最佳），另一个是整个群体已知的最佳适应度值（**gbest**：全局最佳）。随着改进位置的发现，这些位置被用来指导粒子群体的运动。这个过程不断重复，期望最终能够找到一个最优解。
- en: Genetic algorithms
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 遗传算法
- en: 'When we look around the world and see different species, a question naturally
    arises: why are these sets of features stable and not others; why should the majority
    of animals have two legs or four legs, and why not three? Is it possible that
    the world that we see today is the result of many iterations in a grand optimization
    algorithm?'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们环顾四周，看到不同的物种时，一个问题自然会浮现：为什么这些特征组合能稳定存在，而其他特征不能？为什么大多数动物有两条腿或四条腿，而不是三条腿？我们今天看到的这个世界，是否是经过多次迭代优化算法的结果？
- en: Let's imagine there is a cost function that measures survivability, which should
    be maximized. The characteristics of the organisms of the natural world fit into
    a topological landscape. The level of survivability (measured through adaptation)
    represents the elevation of the landscape. The highest points correspond to the
    most-fit conditions, and the constraints are provided by the environment and through
    interaction between different species.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 设想有一个成本函数来衡量生存能力，并且该生存能力应该是最大化的。自然界生物的特性适应于一个拓扑景观。生存能力的水平（通过适应性来衡量）代表景观的高度。最高的点对应于最适合的条件，而限制条件则由环境以及不同物种之间的相互作用提供。
- en: Then, the process of evolution can be thought of as a grand optimization algorithm
    that selects which characteristics produce a species of organism fit for survival.
    The peaks of the landscape are populated by living organisms. Some peaks are broad
    and hold a wide range of characteristics encompassing many organisms, while other
    peaks are very narrow and allow only very specific characteristics.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，进化过程可以看作是一个庞大的优化算法，它选择哪些特征能产生适应生存的物种。景观的顶峰由生物体占据。有些顶峰非常广阔，容纳了多种特征，涵盖了许多物种，而另一些顶峰则非常狭窄，只允许具有非常特定特征的物种存在。
- en: We can extend this analogy to include valleys between the peaks separating different
    species. And, we can think that humankind might be at the global maximum peak
    of this landscape, since we have intelligence and the ability to alter the environment
    and ensure better survivability, even in extreme environments.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这一类比扩展到包括分隔不同物种的山谷。我们可以认为人类可能处于这个景观的全局最优峰值，因为我们拥有智慧和改变环境的能力，并能确保在极端环境下的更好生存能力。
- en: Thus, the world with different life forms can be thought of as a big search
    space, with different species as the result of many iterations of a grand optimization
    algorithm. This idea forms the basis of genetic algorithms.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，可以将这个拥有不同生命形式的世界视作一个巨大的搜索空间，而不同的物种则是许多次迭代优化算法的结果。这一思想构成了遗传算法的基础。
- en: Since the main theme of this chapter is genetic algorithms, let's dive into
    them.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主题是遗传算法，让我们深入探讨一下它们。
- en: Introduction to genetic algorithms
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 遗传算法简介
- en: According to the work of Charles Darwin, the famous biologist, the animal and
    plant species that we see today have emerged due to millions of years of evolution.
    The process of evolution is guided by the principle of *survival of the fittest*,
    selecting the organisms that have a better chance of survivability. The plants
    and animals that we see today are the results of millions of years of adaptation
    to the constraints imposed by the environment. At any given time, a large number
    of varied organisms may coexist and compete for the same environmental resources.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 根据著名生物学家查尔斯·达尔文的研究，我们今天看到的动物和植物物种是经过数百万年的进化而形成的。进化过程遵循**适者生存**的原则，选择那些拥有更好生存机会的生物。我们今天看到的植物和动物是数百万年适应环境约束的结果。在任何时候，许多不同的生物可能会共存并争夺相同的环境资源。
- en: The organisms that are most capable of both acquiring the resources and procreation
    are the ones whose descendants will have more chances of survival. Organisms that
    are less capable, on the other hand, will tend to have few or no descendants.
    Over time, the entire population will evolve, containing on average organisms
    that are more fit than the previous generations.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 那些最具资源获取能力和繁殖能力的生物，它们的后代将拥有更多的生存机会。另一方面，能力较弱的生物往往会有很少或没有后代。随着时间的推移，整个种群会发生演化，平均而言，新一代的生物会比前几代更具适应性。
- en: 'What makes this possible? What decides that a person will be tall, and a plant
    will have a particular shape of leaf? All this is encoded like a set of rules
    in the program on the blueprint of life itself—genes. Every living organism on
    Earth has this set of rules and they describe how that organism is designed (created).
    Genes reside in chromosomes. Each being has a different number of chromosomes
    and they contain thousands of genes. For example, we homo sapiens have 46 chromosomes
    and these chromosomes contain about 20,000 genes. Each gene represents a specific
    rule: a person will have blue eyes, will have brown hair, will be a female, and
    so on. These genes pass from parents to offspring through the process of reproduction.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 是什么使得这一切成为可能？是什么决定了一个人会很高，而一棵植物会有特定形状的叶子？这一切都被像一套规则一样编码在生命蓝图中的程序里——基因。地球上的每一个生物都拥有这套规则，它们描述了该生物是如何被设计（创造）的。基因存在于染色体中。每个生物都有不同数量的染色体，这些染色体包含数千个基因。例如，我们人类有46条染色体，这些染色体包含约20,000个基因。每个基因代表一个特定的规则：比如一个人会有蓝色的眼睛，棕色的头发，是女性，等等。这些基因通过繁殖过程从父母传递给后代。
- en: 'There are two ways by which genes pass from parents to offspring:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 基因从父母传递给后代的方式有两种：
- en: '**Asexual reproduction**: In this, the child is the duplicate copy of the parent.
    It happens during a biological process called **mitosis**; lower organisms such
    as bacteria and fungi reproduce via mitosis. Only one parent is needed in this:'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无性繁殖**：在这种情况下，子代是父代的完全复制。它发生在一个叫做**有丝分裂**的生物过程里；如细菌和真菌等低等生物通过有丝分裂繁殖。此过程中只需要一个父母：'
- en: '![](img/1008f76b-7eca-4a10-b1e9-8247fb6e530f.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1008f76b-7eca-4a10-b1e9-8247fb6e530f.png)'
- en: 'The process of mitosis: the chromosomes of the parent first double, and the
    cell divides into two'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 有丝分裂过程：父母的染色体首先翻倍，然后细胞分裂成两个子细胞
- en: '**Sexual reproduction**: This happens via a biological process called **meiosis**.
    In this, two parents are involved initially; each parent cell undergoes a process
    of crossover, where a part of one chromosome gets interchanged with a part of
    another chromosome. This modifies the genetic sequence; the cells then divide
    into two, but with only half the number of chromosomes each. The cells containing
    half the number of chromosomes (haploid) from the two parents then meet together
    to form a zygote, which later through mitosis and cell differentiation results
    in the production of an **offspring** similar to, yet different from, the parents:'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有性生殖**：这一过程通过一种叫做**减数分裂**的生物学过程完成。在这一过程中，最初涉及两个父母；每个父母的细胞经历交叉过程，其中一条染色体的一部分与另一条染色体的一部分交换位置。这样改变了遗传序列，细胞随后分裂为两部分，但每部分只包含一半的染色体数。来自两个父母的单倍体细胞最终结合，形成受精卵，后通过有丝分裂和细胞分化，最终产生一个与父母相似但又有所不同的**后代**。'
- en: '![](img/7af1402c-aac5-4760-a6ef-88500a7da4bf.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7af1402c-aac5-4760-a6ef-88500a7da4bf.png)'
- en: 'The process of meiosis: parents'' cell chromosomes undergo crossover, a part
    of one chromosome overlaps and changes position with part of another chromosome.
    The cells then divide into two, with each divided cell containing only one chromosome
    (haploids). The two haploids from two parents then meet together to complete the
    total number of chromosomes.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 细胞分裂过程：父母的细胞染色体发生交叉，一部分染色体与另一部分染色体交换位置。然后，细胞分裂为两部分，每个分裂的细胞只包含一条染色体（单倍体）。来自两个父母的两个单倍体细胞随后结合，完成染色体的总数。
- en: Another interesting thing that happens in the natural process of selection and
    evolution is the phenomenon of mutation. Here, the genes undergo a sudden change
    and generate a completely new gene, which was not present in either parent. This
    phenomenon generates further diversity.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 自然选择和进化过程中另一个有趣的现象是突变现象。在这里，基因发生突然变化，产生一个完全新的基因，这个基因在父母双方中都没有出现过。这个现象进一步增加了多样性。
- en: Sexual reproduction through generations is supposed to bring about evolution
    and ensure that organisms with the fittest characteristics have more descendants.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 通过世代间的有性生殖，应该带来进化，并确保具有最适应特征的生物拥有更多的后代。
- en: The genetic algorithm
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 遗传算法
- en: Let's now learn how can we implement the genetic algorithm. This method was
    developed by John Holland in 1975\. It was shown that it can be used to solve
    an optimization problem by his student Goldberg, who used genetic algorithms to
    control gas pipeline transmission. Since then, genetic algorithms have remained
    popular, and have inspired various other evolutionary programs.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来了解如何实现遗传算法。这一方法是由约翰·霍兰德于1975年提出的。他的学生戈德堡展示了这一方法可以用来解决优化问题，并且使用遗传算法来控制天然气管道的传输。此后，遗传算法一直广受欢迎，并启发了其他各种进化程序的研究。
- en: To apply genetic algorithms to solving optimization problems using the computer,
    as the first step we will need to **encode the problem variables into genes**.
    The genes can be a string of real numbers or a binary bit string (series of 0s
    and 1's). This represents a potential solution (individual) and many such solutions
    together form the population at time *t*. For instance, consider a problem where
    we need to find two variables, a and b, such that the two lie in the range (0,
    255). For binary gene representation, these two variables can be represented by
    a 16-bit chromosome, with the higher 8 bits representing gene a and the lower
    8 bits for b. The encoding will need to be later decoded to get the real values
    of the variables a and b.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将遗传算法应用于计算机优化问题的求解，第一步我们需要**将问题变量编码为基因**。这些基因可以是实数的字符串或二进制位串（0和1的序列）。这代表了一个潜在的解决方案（个体），而多个这样的解决方案一起构成了时间点*t*时的人口。例如，考虑一个需要找到两个变量a和b的问题，其中这两个变量的范围是(0,
    255)。对于二进制基因表示，这两个变量可以通过一个16位的染色体表示，其中高8位代表基因a，低8位代表基因b。编码之后需要解码才能获得变量a和b的实际值。
- en: The second important requirement for genetic algorithms is defining a proper **fitness
    function**, which calculates the fitness score of any potential solution (in the
    preceding example, it should calculate the fitness value of the encoded chromosome).
    This is the function that we want to optimize by finding the optimum set of parameters
    of the system or the problem at hand. The fitness function is problem-dependent.
    For example, in the natural process of evolution, the fitness function represents
    the organism's ability to operate and to survive in its environment.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 遗传算法的第二个重要要求是定义一个合适的**适应度函数**，该函数计算任何潜在解的适应度分数（在前面的示例中，它应该计算编码染色体的适应度值）。这是我们希望通过寻找系统或问题的最优参数集来优化的函数。适应度函数是与问题相关的。例如，在自然进化过程中，适应度函数代表生物体在其环境中生存和运作的能力。
- en: 'Once we have decided the encoding of the problem solution in genes and decided
    upon the fitness function, the genetic algorithm will then follow these steps:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们决定了问题解决方案在基因中的编码方式，并确定了适应度函数，遗传算法将遵循以下步骤：
- en: '**Population Initialization**: We need to create an initial population, where
    all chromosomes are (usually) randomly generated to yield an entire range of possible
    solutions (the search space). Occasionally, the solutions may be seeded in areas
    where optimal solutions are likely to be found. The population size depends on
    the nature of the problem, but typically contains several hundred potential solutions
    encoded into chromosomes.'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**种群初始化**：我们需要创建一个初始种群，其中所有染色体（通常）是随机生成的，以产生整个可能解的范围（搜索空间）。偶尔，解决方案可能会在最有可能找到最佳解的区域中进行初始化。种群的大小取决于问题的性质，但通常包含数百个潜在的解决方案，这些解决方案被编码成染色体。'
- en: '**Parent Selection**: For each successive generation, based on the fitness
    function (or randomly), we next select a certain proportion of the existing population.
    This selected proportion of the population will then breed to form a new generation.
    This is done by the method of tournament selection: a fixed number of individuals
    are randomly selected (tournament size) and the individual with the best fitness
    score is chosen as one of the parents.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**父代选择**：对于每一代，根据适应度函数（或随机选择），我们接下来选择现有种群中的一定比例。这些被选中的种群将通过繁殖形成新一代。这个过程是通过竞赛选择法来完成的：随机选择固定数量的个体（竞赛大小），然后选择适应度分数最好的个体作为父母之一。'
- en: '**Reproduction**: We next generate the successive generation from those selected
    in step 2, through genetic operators such as crossover and mutation. These genetic
    operators ultimately result in a child (next generation) population of chromosomes
    that is different from the initial generation but at the same time shares many
    of the characteristics of its parents.'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**繁殖**：接下来，我们通过在步骤2中选择的个体，通过遗传算子如交叉和变异来生成后代。最终，这些遗传算子会产生一个与初代不同但又在许多方面继承了父母特征的后代染色体种群。'
- en: '**Evaluation**: The offspring generated are then evaluated using the fitness
    function, and they replace the least-fit individuals in the population to keep
    the population size unchanged.'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估**：生成的后代将通过适应度函数进行评估，并且它们将替换种群中最不适应的个体，以保持种群大小不变。'
- en: '**Termination**: During the *Evaluation* step, if any of the offspring achieve
    the objective fitness score or the maximum number of generations is reached, then
    the genetic algorithm process is terminated. Otherwise, steps *2* to *4* are repeated
    to produce the next generation.'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**终止**：在*评估*步骤中，如果任何后代达到了目标适应度分数或达到最大代数，遗传算法过程将终止。否则，步骤*2*到*4*将重复进行，以产生下一代。'
- en: Two operators that are important for the success of genetic algorithms are crossover
    and mutation.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 两个对遗传算法成功至关重要的算子是交叉和变异。
- en: Crossover
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉
- en: 'To perform the crossover operation, we select a random position on the chromosome
    of two parents, then the genetic information is swapped between them about this
    point, with a probability *P[x]*. This results in two new offspring. When the
    crossover takes place over a random point, it is called a **one-point crossover** (or **Single
    Point Crossover**):'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行交叉操作，我们在两个父母的染色体上选择一个随机位置，然后基于这个点交换它们的遗传信息，交叉概率为*P[x]*。这将产生两个新的后代。当交叉发生在一个随机点时，称为**单点交叉**（或**Single
    Point Crossover**）：
- en: '![](img/66fa82f1-5570-4f15-83bf-c73111bfbaf2.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/66fa82f1-5570-4f15-83bf-c73111bfbaf2.png)'
- en: 'One-point crossover: a random point is selected in the parent''s chromosomes
    and the corresponding gene bits are swapped'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 单点交叉：随机选择父代染色体中的一个点，并交换相应的基因位。
- en: 'We can also have more than one point where parents'' genes are swapped; this
    is called a **Mult****i-Point Crossover**:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以在多个位置交换父代的基因；这称为**多点交叉**：
- en: '![](img/c0da5152-3b46-4ead-9037-328ce748624e.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c0da5152-3b46-4ead-9037-328ce748624e.png)'
- en: 'Multi-point crossover: there is more than one point where the genes of the
    parents are swapped. This is an example of a double-point crossover.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 多点交叉：在多个位置交换父代的基因。这是双点交叉的一个例子。
- en: There exist a lot of crossovers people have tried, for example, uniform crossover,
    order-based crossover, and cyclic crossover.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多不同的交叉方式，例如，均匀交叉、基于顺序的交叉和循环交叉。
- en: Mutation
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 变异
- en: While the crossover operation ensures variety and can help speed up the search,
    it does not generate new solutions. This is the work of the mutation operator,
    which helps in maintaining and introducing diversity in the population. The mutation
    operator is applied to certain genes (bits) of the child chromosomes with a probability, *P[m]*.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然交叉操作确保了多样性并且有助于加速搜索，但它并不产生新的解。这是变异操作符的工作，变异操作符帮助保持和引入种群中的多样性。变异操作符以概率*P[m]*应用于子代染色体的某些基因（位）。
- en: We can have a bit flip mutation; if we consider our earlier example, then in the
    16-bit chromosome, the bit flip mutation will cause a single bit to change its
    state (from *0* to* 1* or from *1* to *0*).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以进行位翻转变异；如果我们考虑之前的例子，那么在16位染色体中，位翻转变异将导致一个位的状态发生变化（从*0*变为*1*，或者从*1*变为*0*）。
- en: There is a possibility that we set the gene to a random value for all possible
    values. This is called **random resetting**.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有可能将基因设置为所有可能值中的一个随机值，这称为**随机重置**。
- en: The probability *P[m] *plays an important role; if we assign a very low value
    to *P[m]* it can lead to genetic drift, but on the other hand, a high *P[m]* may
    result in a loss of good solutions. We choose a mutation probability such that the algorithm
    learns to sacrifice short-term fitness in order to gain longer-term fitness.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 概率*P[m]*起着重要作用；如果我们给*P[m]*分配一个非常低的值，它可能导致遗传漂移，但另一方面，过高的*P[m]*可能会导致丧失好的解。我们选择一个变异概率，使得算法学会牺牲短期适应度来获得长期适应度。
- en: Pros and cons
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优缺点
- en: Genetic algorithms sound cool, right! Now, before we try and build a code around
    them, let's point out certain advantages and disadvantages of genetic algorithms.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 遗传算法听起来很酷，对吧！现在，在我们尝试围绕它们构建代码之前，让我们先指出遗传算法的一些优缺点。
- en: Advantages
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优势
- en: 'Genetic algorithms offer some intriguing advantages and can produce results
    when the tradition gradient-based approaches fail:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 遗传算法提供了一些令人着迷的优势，并且在传统的基于梯度的方法失败时也能产生结果。
- en: They can be used to optimize either continuous or discrete variables.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们可以用于优化连续变量或离散变量。
- en: Unlike gradient descent, we do not require derivative information, which also
    means that there is no need for the fitness function to be continuous and differentiable.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与梯度下降不同，我们不需要导数信息，这也意味着适应度函数不必是连续可微的。
- en: It can simultaneously search from a wide sampling of the cost surface.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以从广泛的成本表面进行同时搜索。
- en: We can deal with a large number of variables without a significant increase
    in computation time.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以处理大量变量，而不会显著增加计算时间。
- en: The generation of the population and calculating their fitness values can be
    performed in parallel, and hence genetic algorithms are well suited for parallel
    computers.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 种群的生成及其适应度值的计算可以并行进行，因此遗传算法非常适合并行计算机。
- en: They can work even when the topological surface is extremely complex because
    crossover and mutation operators help them in jumping out of a local minimum.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们即使在拓扑表面极其复杂时也能正常工作，因为交叉和变异操作符帮助它们跳出局部最小值。
- en: They can provide more than one optimum solution.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们可以提供多个最优解。
- en: We can use them with numerically generated data, experimental data, or even
    analytical functions. They specifically work well for large-scale optimization
    problems.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以将它们应用于数值生成的数据、实验数据，甚至是分析函数。它们特别适用于大规模优化问题。
- en: Disadvantages
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 劣势
- en: 'Despite the previously mentioned advantages, we still do not find genetic algorithms
    to be a ubiquitous solution to all optimization problems. This is for the following
    reasons:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管之前提到的优势存在，我们仍然不认为遗传算法是所有优化问题的普适解决方案。原因如下：
- en: If the optimization function is a well-behaved convex function, then gradient-based
    methods will give a faster convergence
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果优化函数是一个良性凸函数，那么基于梯度的方法将实现更快的收敛速度
- en: The large population of solutions that helps genetic algorithms cover the search
    space more extensively also results in slow convergence
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大量的解集帮助遗传算法更广泛地覆盖搜索空间，但也导致了收敛速度变慢
- en: Designing a fitness function can be a daunting task
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计一个适应度函数可能是一项艰巨的任务
- en: Coding genetic algorithms using Distributed Evolutionary Algorithms in Python
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python中的分布式进化算法编码遗传算法
- en: 'Now that we understand how genetic algorithms work, let''s try solving some
    problems with them. They have been used to solve NP-hard problems such as the
    traveling salesman problem. To make the task of generating a population, performing
    the crossover, and performing mutation operations easy, we will make use of **Distributed
    Evolutionary Algorithms in Python** (**DEAP**). It supports multiprocessing and
    we can use it for other evolutionary algorithms as well. You can download DEAP
    directly from PyPi using this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了遗传算法的工作原理，接下来我们可以尝试用它们解决一些问题。它们已经被用来解决NP难题，例如旅行推销员问题。为了简化生成种群、执行交叉操作和进行变异操作的任务，我们将使用**分布式进化算法在Python中**（**DEAP**）。它支持多进程，我们也可以用它来进行其他进化算法的应用。你可以通过PyPi直接下载DEAP，方法如下：
- en: '[PRE0]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It is compatible with Python 3.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 它与Python 3兼容。
- en: To learn more about DEAP, you can refer to its GitHub repository ([https://github.com/DEAP/deap](https://github.com/DEAP/deap))
    and its user's guide ([http://deap.readthedocs.io/en/master/](http://deap.readthedocs.io/en/master/)).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于DEAP的信息，可以参考其GitHub仓库([https://github.com/DEAP/deap](https://github.com/DEAP/deap))和用户指南([http://deap.readthedocs.io/en/master/](http://deap.readthedocs.io/en/master/))。
- en: Guess the word
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 猜测单词
- en: 'In this program, we use genetic algorithms to guess a word. The genetic algorithm
    will know the number of letters in the word and will guess those letters until
    it finds the right answer. We decide to represent the genes as a single alphanumeric
    character; strings of these characters thus constitute a chromosome. And our fitness
    function is the sum of the characters matching in the individual and the right
    word:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个程序中，我们使用遗传算法猜测一个单词。遗传算法知道单词中有多少个字母，并会一直猜这些字母，直到找到正确的答案。我们决定将基因表示为单个字母数字字符；这些字符的字符串构成了染色体。我们的适应度函数是个体与正确单词中匹配的字符数之和：
- en: 'As the first step, we import the modules we will need. We use the `string` module
    and the `random` module to generate random characters from (a—z*,* A—Z*,* and
    0—9). From the DEAP module, we use `creator`, `base`, and `tools`:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为第一步，我们导入所需的模块。我们使用`string`模块和`random`模块来生成随机字符（a—z、A—Z以及0—9）。从DEAP模块中，我们使用`creator`、`base`和`tools`：
- en: '[PRE1]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In DEAP, we start with creating a class that inherits from the `deep.base` module.
    We need to tell it whether we are going to have a minimization or maximization
    of the function; this is done using the weights parameter. A value of `+1` means
    we are maximizing (for minimizing, we give the value `-1.0`). The following code
    line will create a class, `FitnessMax`, that will maximize the function:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在DEAP中，我们首先创建一个继承自`deep.base`模块的类。我们需要告诉它我们是进行函数的最小化还是最大化；这通过权重参数来实现。`+1`表示我们在进行最大化（如果是最小化，则值为`-1.0`）。以下代码行将创建一个类`FitnessMax`，它将最大化该函数：
- en: '[PRE2]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We also define an `Individual` class, which will inherit the class list, and
    tell the DEAP creator module to assign `FitnessMax` as its `fitness` attribute:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还定义了一个`Individual`类，该类将继承列表类，并告诉DEAP创作者模块将`FitnessMax`分配为其`fitness`属性：
- en: '[PRE3]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, with the `Individual` class defined, we use the `toolbox` of DEAP defined
    in the base module. We will use it to create a population and define our gene
    pool. All the objects that we will need from now onward—an individual, the population,
    the functions, the operators, and the arguments—are stored in a container called `toolbox`. We
    can add or remove content to/from the `toolbox` container using the `register()` and `unregister()` methods:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，定义了`Individual`类后，我们使用DEAP在基础模块中定义的`toolbox`。我们将用它来创建种群并定义基因池。从现在开始，我们所需的所有对象——个体、种群、函数、算子和参数——都存储在一个叫做`toolbox`的容器中。我们可以使用`register()`和`unregister()`方法向`toolbox`容器中添加或删除内容：
- en: '[PRE4]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now that we have defined how the gene pool will be created, we create an individual
    and then a population by repeatedly using the `Individual` class. We will pass
    the class to the toolbox responsible for creating a `N` parameter , telling it
    how many genes to produce:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经定义了如何创建基因池，我们通过反复使用`Individual`类来创建个体和种群。我们将类传递给负责创建`N`参数的工具箱，告诉它需要生成多少个基因：
- en: '[PRE5]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We define the `fitness` function. Note the comma in the return statement. This
    is because the fitness function in DEAP is returned as a tuple to allow multi-objective `fitness` functions:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了`fitness`函数。注意返回语句中的逗号。这是因为DEAP中的适应度函数以元组的形式返回，以支持多目标的`fitness`函数：
- en: '[PRE6]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Add the fitness function to the container. Also, add the crossover operator,
    mutation operator, and parent selector operator. You can see that, for this, we
    are using the register function. In the first statement, we register the fitness
    function that we have defined, along with the additional arguments it will take.
    The next statement registers the crossover operation; it specifies that here we
    are using a two-point crossover (`cxTwoPoint`). Next, we register the mutation
    operator; we choose the `mutShuffleIndexes` option, which shuffles the attributes
    of the input individual with a probability `indpb=0.05`. And finally, we define
    how the parents are selected; here, we have defined the method of selection as
    tournament selection with a tournament size of `3`:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将适应度函数添加到容器中。同时，添加交叉算子、变异算子和父代选择算子。可以看到，为此我们使用了`register`函数。在第一行中，我们注册了已定义的适应度函数，并传入它将接受的额外参数。下一行注册了交叉操作；它指定我们这里使用的是双点交叉（`cxTwoPoint`）。接下来，我们注册了变异算子；我们选择了`mutShuffleIndexes`选项，它会以`indpb=0.05`的概率打乱输入个体的属性。最后，我们定义了父代选择的方式；在这里，我们定义了采用比赛选择的方法，比赛大小为`3`：
- en: '[PRE7]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now we have all the ingredients, so we will write down the code of the genetic
    algorithm, which will perform the steps we mentioned earlier in a repetitive manner:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经有了所有的组成部分，接下来我们将编写遗传算法的代码，它将按我们之前提到的步骤反复执行：
- en: '[PRE8]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here, you can see the result of this genetic algorithm. In seven generations,
    we reached the right word:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，你可以看到这个遗传算法的结果。在七代内，我们找到了正确的词：
- en: '![](img/7e2a7324-5c11-46c4-9a42-61c0ef909cf3.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7e2a7324-5c11-46c4-9a42-61c0ef909cf3.png)'
- en: DEAP has options to select various crossover tools, different mutation operators,
    and even how the tournament selection takes place. The complete list of all evolutionary
    tools offered by DEAP and their description is available at [http://deap.readthedocs.io/en/master/api/tools.html.](http://deap.readthedocs.io/en/master/api/tools.html#deap.tools.mutFlipBit)
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: DEAP提供了选择各种交叉工具、不同变异算子，甚至如何进行比赛选择的选项。DEAP提供的所有进化工具及其说明的完整列表可在[http://deap.readthedocs.io/en/master/api/tools.html.](http://deap.readthedocs.io/en/master/api/tools.html#deap.tools.mutFlipBit)查看。
- en: Genetic algorithm for CNN architecture
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CNN架构的遗传算法
- en: In [Chapter 4](cb9d27c5-e98d-44b6-a947-691b0bc64766.xhtml), *Deep Learning for
    IoT,* we learned about different DL models, such as MLP, CNN, RNN, and so on.
    Now, we will see how we can use genetic algorithms with these DL models. Genetic
    algorithms can be used to find the optimized weights and biases, and people have
    tried them. But the most common use of genetic algorithms in DL models has been
    to find optimum hyperparameters.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](cb9d27c5-e98d-44b6-a947-691b0bc64766.xhtml)《物联网中的深度学习》中，我们了解了不同的深度学习模型，如MLP、CNN、RNN等。现在，我们将看到如何将遗传算法应用于这些深度学习模型。遗传算法可以用来找到优化的权重和偏差，已经有人尝试过了。但在深度学习模型中，遗传算法最常见的应用是寻找最优超参数。
- en: Here, we use genetic algorithms to find the optimum CNN architecture. The solution
    here is based on the paper *Genetic CNN* by Lingxi Xie and Alan Yuille ([https://arxiv.org/abs/1703.01513](https://arxiv.org/abs/1703.01513)).
    The first step will be finding the right representation of the problem. The authors
    presented a binary string representation for the network architecture. The family
    of the network is encoded into fixed-length binary strings. The network is composed
    of *S* stages where the *s-th* stage *s*= *1*, *2*,....*S*, contains *K[s]* nodes
    denoted by ![](img/25dcaeb0-a94e-4f85-a30a-48c678a8912f.png), here *k[s]* = *1*, *2*,..., *K[s][.]* The
    nodes in each stage are ordered and for proper representation they allow only
    connections from a lower-numbered node to a higher-numbered node. Each node represents
    a convolution layer operation, followed by batch normalization and ReLU activation.
    Each bit of the bit string represents the presence or absence of the connection
    between one convolution layer (node) and the other, the ordering of bits being
    as follows: the first bit represents the connection between (*v*[*s*,1], *v*[*s*,2]),
    the following two bits represent the connection between (*v*[*s*,1], *v*[*s*,3])
    and (*v*[*s*,2], *v*[*s*,3]), the following three bits will be (*v*[*s*,1], *v*[*s*,3]), (*v*[*s*,1], *v*[*s*,4]),
    and (*v*[*s*,2], *v*[*s*,4]), and so on.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用遗传算法来寻找最优的CNN架构。该方案基于Lingxi Xie 和 Alan Yuille 发表的论文 *Genetic CNN*（[https://arxiv.org/abs/1703.01513](https://arxiv.org/abs/1703.01513)）。第一步是找到问题的正确表示方法。作者提出了网络架构的二进制串表示。网络的家族被编码成固定长度的二进制串。网络由
    *S* 个阶段组成，其中第 *s* 阶段 *s* = *1*, *2*,....*S*，包含 *K[s]* 个节点，表示为 ![](img/25dcaeb0-a94e-4f85-a30a-48c678a8912f.png)，这里
    *k[s]* = *1*, *2*,..., *K[s][.* 每个阶段的节点是有序的，并且为了正确表示，只允许从较低编号的节点连接到较高编号的节点。每个节点表示一个卷积层操作，随后是批量归一化和ReLU激活。位串的每一位表示一个卷积层（节点）与另一个卷积层之间连接的存在或不存在，位的顺序如下：第一位表示
    (*v*[*s*,1]，*v*[*s*,2]) 之间的连接，接下来的两位表示 (*v*[*s*,1]，*v*[*s*,3]) 和 (*v*[*s*,2]，*v*[*s*,3])
    之间的连接，接下来的三位表示 (*v*[*s*,1]，*v*[*s*,3])，(*v*[*s*,1]，*v*[*s*,4]) 和 (*v*[*s*,2]，*v*[*s*,4])
    之间的连接，依此类推。
- en: 'To understand it better, let''s consider a two-stage network (each stage will
    have the same number of filters and filter size). Stage *S*[1] let''s say consists
    of four nodes (that is *K[s]* = 4), thus the total number of bits required to
    encode it is (*4×3×½ =*) 6\. The number of convolutional filters in stage *1* is
    3*2;* also we ensure that convolutional operation does not change the spatial
    dimensions of the image (for example, padding is the same). The following diagram
    shows the respective bit string encoded and corresponding convolution layer connections.
    The connections in red are default connections and are not encoded in the bit
    string. The first bit encodes the connection between (*a1*, *a2*), the next two
    bits encode the connection between (*a1*, *a3*) and (*a2*, *a3*), and the last
    three bits encode the connection between (*a1*, *a4*), (*a2*, *a4*), and (*a3*, *a4*):'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解它，我们考虑一个两阶段的网络（每个阶段将具有相同数量的滤波器和滤波器大小）。假设阶段 *S*[1] 包含四个节点（即 *K[s]* = 4），因此需要编码的位数总共为
    (*4×3×½ =*) 6。阶段 *1* 中的卷积滤波器数量是 3*2；同时我们确保卷积操作不会改变图像的空间维度（例如，填充保持一致）。下图显示了相应的位串编码及对应的卷积层连接。红色连接是默认连接，不在位串中编码。第一位编码了
    (*a1*，*a2*) 之间的连接，接下来的两位编码了 (*a1*，*a3*) 和 (*a2*，*a3*) 之间的连接，最后三位编码了 (*a1*，*a4*)，(*a2*，*a4*)
    和 (*a3*，*a4*) 之间的连接：
- en: '![](img/c83c821a-18a1-4f98-aab2-18f165068aee.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c83c821a-18a1-4f98-aab2-18f165068aee.png)'
- en: Bit string encoded and corresponding convolution layer connections
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 位串编码及对应的卷积层连接
- en: Stage *1* takes a **32 × 32 × 3** input; all the convolution nodes in this stage
    have 32 filters. The red connections are default connections not encoded in the
    bit string. The green connection represents the connections according to the encoded
    bit string 1-00-111\. The output of stage *1* goes to the pooling layer and reduces
    by half in the spatial dimension.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 阶段 *1* 接受一个 **32 × 32 × 3** 的输入；该阶段的所有卷积节点都有32个滤波器。红色连接表示默认连接，不在位串中编码。绿色连接表示根据编码的位串
    1-00-111 所表示的连接。阶段 *1* 的输出将传递到池化层，并在空间维度上减半。
- en: Stage 2 has five nodes, and thus will need (5×4×½ =) 10 bits. It will take the
    input from stage *1* with dimensions **16 × 16 × 32**. Now, if we take the number
    of convolution filters in stage *2* as *64*, then after the pooling the output
    would be 8 × 8 × 64.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 第二阶段有五个节点，因此需要（5×4×½ =) 10 位。它将从第一阶段*1*接收输入，维度为**16 × 16 × 32**。现在，如果我们将第二阶段*2*中的卷积滤波器数量设为*64*，那么池化后的输出将是
    8 × 8 × 64。
- en: The code presented here is taken from [https://github.com/aqibsaeed/Genetic-CNN](https://github.com/aqibsaeed/Genetic-CNN).
    Since we need to represent a graph structure, the network is built using **directed
    acyclic graph** (**DAG**). To represent DAG, we define a class, DAG, in which
    we define methods for adding a new node, deleting an existing node, adding an
    edge (connection) between two nodes, and deleting an edge between two nodes. Besides
    these, the methods are defined to find a node predecessor, the nodes it is connected
    to, and a list of leaves of the graph. The complete code is in `dag.py`, which
    you can access from the GitHub link.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这里呈现的代码来自[https://github.com/aqibsaeed/Genetic-CNN](https://github.com/aqibsaeed/Genetic-CNN)。由于我们需要表示图结构，因此网络是使用**有向无环图**（**DAG**）构建的。为了表示DAG，我们定义了一个类DAG，其中定义了添加新节点、删除现有节点、在两个节点之间添加边（连接）和删除两个节点之间的边的方法。除此之外，还定义了查找节点前驱节点、连接到该节点的节点以及图的叶子节点列表的方法。完整代码位于`dag.py`中，可以通过GitHub链接访问。
- en: 'The main code is given in the `Genetic_CNN.ipynb` Jupyter Notebook. We use
    the DEAP library to run the genetic algorithm, and TensorFlow to construct a CNN
    from the graph constructed by the genetic algorithm. The fitness function is the
    accuracy. The code is built to find the CNN that will give the highest accuracy
    on the MNIST dataset (the handwritten digits, which we used in [Chapter 4](cb9d27c5-e98d-44b6-a947-691b0bc64766.xhtml), *Deep
    Learning for IoT*; here, we access them directly from the TensorFlow library):'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 主要代码在`Genetic_CNN.ipynb` Jupyter笔记本中给出。我们使用DEAP库来运行遗传算法，并使用TensorFlow根据遗传算法构建的图来构建CNN。适应度函数是准确度。代码旨在找到在MNIST数据集上能够给出最高准确度的CNN（我们在[第4章](cb9d27c5-e98d-44b6-a947-691b0bc64766.xhtml)《物联网深度学习》中使用了手写数字，这里我们直接从TensorFlow库中获取它们）：
- en: 'The first step is to import the modules. Here, we will need DEAP and TensorFlow,
    and we also will import the DAG class we created in `dag.py` and the standard
    Numpy and Random modules:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是导入模块。这里，我们将需要DEAP和TensorFlow，还将导入我们在`dag.py`中创建的DAG类，以及标准的Numpy和Random模块：
- en: '[PRE9]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We read the data directly from the TensorFlow examples library:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们直接从TensorFlow示例库中读取数据：
- en: '[PRE10]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, we build the bit data structure that will hold the network information.
    The network we are designing is a three-stage network, with three nodes in stage
    1 (3 bits), four nodes in stage 2 (6 bits), and five nodes in stage 3 (10 bits).
    Thus, one Individual will be represented by a binary string of *3 + 6 + 10 = 19* bits:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们构建将保存网络信息的比特数据结构。我们设计的网络是一个三阶段网络，第一个阶段有三个节点（3位），第二个阶段有四个节点（6位），第三个阶段有五个节点（10位）。因此，一个个体将由一个二进制字符串表示，长度为*3
    + 6 + 10 = 19* 位：
- en: '[PRE11]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now comes the part where we build the graph according to the encoded bit string.
    This will help build the population for the genetic algorithm. First, we define
    the functions we will need to build a CNN (`weight_variable`: creates the weight
    variable for a convolutional node; `bias_variable`: creates the bias variable for
    a convolutional node; `apply_convolution`: the function that performs the convolution
    operation; `apply_pool`: the function that will perform the pooling operation
    after each stage; and finally the last fully connected layer using the `linear_layer` function):'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是根据编码后的比特串构建图的部分。这将有助于为遗传算法构建种群。首先，我们定义构建CNN所需的函数（`weight_variable`：为卷积节点创建权重变量；`bias_variable`：为卷积节点创建偏置变量；`apply_convolution`：执行卷积操作的函数；`apply_pool`：在每个阶段之后执行池化操作的函数；最后，使用`linear_layer`函数构建最后的全连接层）：
- en: '[PRE12]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, we can build the network based on the encoded bit string. So, we generate
    the DAG using the `generate_dag` function:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以基于编码后的比特串构建网络。所以，我们使用`generate_dag`函数生成DAG：
- en: '[PRE13]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The graph generated is used to build the TensorFlow graph using the `generate_tensorflow_graph` function.
    This function makes use of the `add_node` function to add a convolution layer,
    and the `sum_tensors` function to combine the input of more than one convolution
    layer:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成的图用于使用`generate_tensorflow_graph`函数构建TensorFlow图。该函数利用`add_node`函数添加卷积层，使用`sum_tensors`函数将多个卷积层的输入合并：
- en: '[PRE14]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The fitness function evaluates the accuracy of the generated CNN architecture:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 适应度函数评估生成的 CNN 架构的准确性：
- en: '[PRE15]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'So, now we are ready to implement the genetic algorithm: our fitness function
    will be a max function (`weights=(1.0,)`), we initialize the binary string using
    Bernoulli''s distribution (`bernoulli.rvs`), the individuals are created of length `L=
    19`, and the population is generated with each population consisting of `20` individuals.
    This time, we chose an ordered crossover, where a substring is selected from the
    first parent and copied into the offspring in the same location; the remaining
    positions are filled from the second parent, ensuring the nodes in the sub-string
    are not repeated. We kept the same mutation operator as before, `mutShuffleIndexes`;
    the tournament selection method is `selRoulette`, which makes the selection using the roulette
    wheel selection method (we choose `k` individuals and from them select the ones
    with the highest fitness). This time, instead of coding the genetic algorithm,
    we make use of the DEAP eaSimple algorithm, which is the basic genetic algorithm:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所以，现在我们准备实现遗传算法：我们的适应度函数将是一个最大值函数（`weights=(1.0,)`），我们使用伯努利分布（`bernoulli.rvs`）初始化二进制字符串，个体的长度为
    `L= 19`，种群由 `20` 个个体组成。这一次，我们选择了有序交叉，其中从第一个父代选择一个子串并将其复制到子代的相同位置；剩余位置由第二个父代填充，确保子串中的节点不重复。我们保留了之前的变异操作符
    `mutShuffleIndexes`；锦标赛选择方法为 `selRoulette`，它通过轮盘选择方法进行选择（我们选择 `k` 个个体，并从中选择适应度最高的个体）。这一次，我们没有自己编码遗传算法，而是使用了
    DEAP 的 eaSimple 算法，这是基本的遗传算法：
- en: '[PRE16]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The algorithm will take some time; on i7 with NVIDIA 1070 GTX GPU it took about
    1.5 hours. The best three solutions are the following:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 算法将需要一些时间；在 i7 配备 NVIDIA 1070 GTX GPU 的机器上，大约需要 1.5 小时。最好的三个解决方案如下：
- en: '[PRE17]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](img/df1133c2-6bcc-49c0-9f8e-cb070b515cd3.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/df1133c2-6bcc-49c0-9f8e-cb070b515cd3.png)'
- en: Genetic algorithm for LSTM optimization
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LSTM 优化的遗传算法
- en: In a genetic CNN, we use genetic algorithms to estimate the optimum CNN architecture;
    in genetic RNN, we will now use a genetic algorithm to find the optimum hyperparameters
    of the RNN, the window size, and the number of hidden units. We will find the
    parameters that reduce the **root-mean-square error** (**RMSE**) of the model.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在遗传 CNN 中，我们使用遗传算法来估计最佳的 CNN 架构；在遗传 RNN 中，我们将使用遗传算法来寻找 RNN 的最佳超参数、窗口大小和隐藏单元数。我们将找到能够减少
    **均方根误差** (**RMSE**) 的参数。
- en: The hyperparameters window size and number of units are again encoded in a binary
    string with 6 bits for window size and 4 bits for the number of units. Thus, the
    complete encoded chromosome will be of 10 bits. The LSTM is implemented using
    Keras.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数窗口大小和单元数再次被编码为二进制字符串，窗口大小使用 6 位，单元数使用 4 位。因此，完整编码的染色体将是 10 位。LSTM 使用 Keras
    实现。
- en: 'The code we implement is taken from [https://github.com/aqibsaeed/Genetic-Algorithm-RNN](https://github.com/aqibsaeed/Genetic-Algorithm-RNN):'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现的代码来自 [https://github.com/aqibsaeed/Genetic-Algorithm-RNN](https://github.com/aqibsaeed/Genetic-Algorithm-RNN)：
- en: 'The necessary modules are imported. This time, we are using Keras to implement the LSTM
    model:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 必要的模块已导入。这一次，我们使用 Keras 来实现 LSTM 模型：
- en: '[PRE18]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The dataset we need for LSTM has to be time series data; we use the wind-power
    forecasting data from Kaggle ([https://www.kaggle.com/c/GEF2012-wind-forecasting/data](https://www.kaggle.com/c/GEF2012-wind-forecasting/data)):'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要的 LSTM 数据集必须是时间序列数据；我们使用来自 Kaggle 的风力发电预测数据 ([https://www.kaggle.com/c/GEF2012-wind-forecasting/data](https://www.kaggle.com/c/GEF2012-wind-forecasting/data))：
- en: '[PRE19]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Define a function to prepare the dataset depending upon the chosen `window_size`:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，根据选定的 `window_size` 准备数据集：
- en: '[PRE20]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The `train_evaluate` function creates the LSTM network for a given individual
    and returns its RMSE value (fitness function):'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`train_evaluate` 函数为给定个体创建 LSTM 网络并返回其 RMSE 值（适应度函数）：'
- en: '[PRE21]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next, we use DEAP tools to define Individual (again, since the chromosome is
    represented by a binary encoded string (10 bits), we use Bernoulli''s distribution),
    create the population, use ordered crossover, use mutShuffleIndexes mutation,
    and use the roulette wheel selection for selecting the parents:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们使用 DEAP 工具定义个体（由于染色体是通过二进制编码的字符串（10位）表示的，所以我们使用伯努利分布），创建种群，使用有序交叉，使用 mutShuffleIndexes
    变异，并使用轮盘选择法来选择父代：
- en: '[PRE22]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We get the best solution, as follows:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们得到最佳解决方案，如下所示：
- en: '[PRE23]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'And finally, we implement the best LSTM solution:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们实现了最佳 LSTM 解决方案：
- en: '[PRE24]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Yay! Now, you have the best LSTM network for predicting wind power.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 耶！现在，你已经拥有了最好的LSTM网络来预测风能。
- en: Summary
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'This chapter introduced an interesting nature-inspired algorithm family: genetic
    algorithms. We covered various standard optimization algorithms, varying from
    deterministic models, to gradient-based algorithms, to evolutionary algorithms.
    The biological process of evolution through natural selection was covered. We
    then learned how to convert our optimization problems into a form suitable for
    genetic algorithms. Crossover and mutation, two very crucial operations in genetic
    algorithms, were explained. While it is not possible to extensively cover all
    the crossover and mutation methods, we did learn about the popular ones.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了一种有趣的自然启发算法家族：遗传算法。我们涵盖了各种标准优化算法，涵盖了从确定性模型到基于梯度的算法，再到进化算法。我们讨论了自然选择的生物学过程。接着，我们学习了如何将优化问题转换为适合遗传算法的形式。遗传算法中的两个关键操作——交叉和变异也得到了阐述。虽然无法广泛涵盖所有交叉和变异方法，但我们学习了其中一些流行的方式。
- en: We applied what we learned on three very different optimization problems. We
    used it to guess a word. The example was of a five-letter word; had we used simple
    brute force, it would take a search of a *61⁵* search space. We used genetic algorithms
    to optimize the CNN architecture; again note that, with *19* possible bits, the
    search space is *2^(19)*. Then, we used it to find the optimum hyperparameters
    for an LSTM network.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将所学应用于三种非常不同的优化问题。我们用它来猜一个单词。例子是一个五个字母的单词；如果我们使用简单的暴力搜索，搜索空间会是*61⁵*。我们使用遗传算法优化了CNN架构；同样注意，假设有*19*个可能的位，搜索空间是*2^(19)*。然后，我们用它来寻找LSTM网络的最优超参数。
- en: 'In the next chapter, we will talk about another intriguing learning paradigm:
    reinforcement learning. This is another natural learning paradigm, in the sense
    that in nature we normally do not have supervised learning; rather, we learn through
    our interactions with the environment. In the same manner, here the agent is not
    told anything except the rewards and punishments it receives from the environment
    after its action.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论另一个引人入胜的学习范式：强化学习。这是另一种自然的学习范式，因为在自然界中，我们通常没有监督学习；相反，我们通过与环境的互动来学习。同样，在这里，智能体除了从环境中获得的奖励和惩罚外，什么也不被告知。
