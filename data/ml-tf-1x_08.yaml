- en: The Doctor Will See You Now
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现在医生来接诊
- en: We have, so far, used deep networks for image, text, and time series processing.
    While most of our examples were interesting and relevant, they weren't enterprise-grade.
    Now, we'll tackle an enterprise-grade problem—medical diagnosis. We make the enterprise-grade
    designation because medical data has attributes one does not typically deal with
    outside large enterprises, namely proprietary data formats, large native sizes,
    inconvenient class data, and atypical features.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经使用深度网络处理了图像、文本和时间序列数据。虽然大多数示例都很有趣且相关，但它们并不具备企业级的标准。现在，我们将挑战一个企业级问题——医学诊断。我们之所以称之为企业级问题，是因为医学数据具有一些在大型企业外部不常见的属性，比如专有数据格式、大规模原生数据、不方便的类别数据和非典型特征。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Medical imaging files and their peculiarities
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 医学影像文件及其特性
- en: Dealing with large image files
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理大规模图像文件
- en: Extracting class data from typical medical files
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从典型医学文件中提取类别数据
- en: Applying networks "pre-trained" with non-medical data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用“预训练”的网络进行非医学数据的应用
- en: Scaling training to accommodate the scale typically with medical data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展训练以适应医学数据的规模
- en: Obtaining medical data is a challenge on its own, so we'll piggyback on a popular
    site all readers should become familiarized with—Kaggle. While there are a good
    number of medical datasets freely available, most require an involved sign-up
    process to even access them. Many are only publicized in specific sub-communities
    of the medical image processing field, and most have bespoke submission procedures.
    Kaggle is probably the most normalized source for a significant medical imaging
    dataset as well as non-medical ones you can try your hand on. We'll focus specifically
    on Kaggle's Diabetic Retinopathy Detection challenge.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 获取医学数据本身就是一项挑战，因此我们将依赖于一个受欢迎的网站，所有读者都应该熟悉——Kaggle。虽然有许多医学数据集可以免费访问，但大多数都需要繁琐的注册过程才能访问它们。许多数据集仅在医学影像处理领域的特定子社区中公开，而且大多数都需要特定的提交流程。Kaggle
    可能是最规范化的医学影像数据集来源，同时也有非医学数据集供你尝试。我们将特别关注 Kaggle 的糖尿病视网膜病变检测挑战。
- en: 'You can view the dataset here: [https://www.kaggle.com/c/diabetic-retinopathy-detection/data](https://www.kaggle.com/c/diabetic-retinopathy-detection/data)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以在此查看数据集：[https://www.kaggle.com/c/diabetic-retinopathy-detection/data](https://www.kaggle.com/c/diabetic-retinopathy-detection/data)
- en: The dataset has a training set and a blind test set. The training set is used
    for, of course, training our network, and the test set is used to submit our results
    using our network on the Kaggle website.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含训练集和盲测集。训练集用于训练我们的网络，测试集则用于在Kaggle网站上提交我们的网络结果。
- en: As the data is quite large (32 GB for the training set and 49 GB for the test
    set), both of them are divided into multiple ZIP files of about 8 GB.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据量相当大（训练集为32GB，测试集为49GB），它们都被划分成多个约8GB的ZIP文件。
- en: The test set here is blind—we don't know their labels. This is for the purpose
    of having fair submissions of the test set results from our trained network.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的测试集是盲测集——我们不知道它们的标签。这是为了确保我们的网络训练结果在提交测试集时具有公平性。
- en: As far as the training set goes, its labels are present in the `trainLabels.csv`
    file.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 就训练集而言，其标签存储在`trainLabels.csv`文件中。
- en: The challenge
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 挑战
- en: 'Before we deep-dive into the code, remember how most machine learning efforts
    involve one of two simple goals—classification or ranking. In many cases, the
    classification is itself a ranking because we end up choosing the classification
    with the greatest rank (often a probability). Our foray into medical imaging will
    be no different—we will be classifying images into either of these binary categories:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入代码之前，请记住，大多数机器学习的工作都有两个简单的目标之一——分类或排序。在许多情况下，分类本身也是一种排序，因为我们最终选择排名最高的分类（通常是概率）。我们在医学影像方面的探索也不例外——我们将把图像分类为以下两个二元类别之一：
- en: Disease state/positive
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 疾病状态/阳性
- en: Normal state/negative
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正常状态/阴性
- en: 'Or, we will classify them into multiple classes or rank them. In the case of
    the diabetic retinopathy, we''ll rank them as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们将把它们分类为多个类别，或者对它们进行排序。在糖尿病视网膜病变的情况下，我们将按以下方式对其进行排名：
- en: 'Class 0: No Diabetic Retinopathy'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '类别 0: 无糖尿病视网膜病变'
- en: 'Class 1: Mild'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '类别 1: 轻度'
- en: 'Class 2: Moderate'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '类别 2: 中度'
- en: 'Class 3: Severe'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '类别 3: 严重'
- en: 'Class 4: Widespread Diabetic Retinopathy'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '类别 4: 广泛的糖尿病视网膜病变'
- en: 'Often, this is called scoring. Kaggle kindly provides participants over 32
    GB of training data, which includes over 35,000 images. The test data is even
    larger—49 GB. The goal is to train on the 35,000+ images using the known scores
    and propose scores for the test set. The training labels look like this:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这被称为评分。Kaggle 友好地为参与者提供了超过 32 GB 的训练数据，其中包含超过 35,000 张图片。测试数据集甚至更大——达到了 49
    GB。目标是使用已知评分对这 35,000+ 张图像进行训练，并为测试集提出评分。训练标签看起来是这样的：
- en: '| **Image** | **Level** |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| **图像** | **级别** |'
- en: '| `10_left` | 0 |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| `10_left` | 0 |'
- en: '| `10_right` | 0 |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| `10_right` | 0 |'
- en: '| `13_left` | 0 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| `13_left` | 0 |'
- en: '| `13_right` | 0 |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| `13_right` | 0 |'
- en: '| `15_left` | 1 |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| `15_left` | 1 |'
- en: '| `15_right` | 2 |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| `15_right` | 2 |'
- en: '| `16_left` | 4 |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| `16_left` | 4 |'
- en: '| `16_right` | 4 |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| `16_right` | 4 |'
- en: '| `17_left` | 0 |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| `17_left` | 0 |'
- en: '| `17_right` | 1 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| `17_right` | 1 |'
- en: Some context here—diabetic retinopathy is a disease of the retina, inside the
    eye, so we have scores for the left and right eye. We can treat them as independent
    training data, or we can get creative later and consider them in the larger context
    of a single patient. Let's start simple and iterate.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有些背景——糖尿病视网膜病变是一种眼内视网膜的疾病，因此我们有左眼和右眼的评分。我们可以将它们视为独立的训练数据，或者我们可以稍后发挥创意，将它们考虑在一个更大的单一患者的背景下。让我们从简单的开始并逐步迭代。
- en: By now, you are probably familiar with taking a set of data and segmenting out
    chunks for training, validation, and testing. That worked well for some of the
    standard datasets we've used, but this dataset is part of a competition and one
    that is publicly audited, so we don't know the answers! This is a pretty good
    reflection of real life. There is one wrinkle—most Kaggle competitions let you
    propose an answer and tell you your aggregate score, which helps with learning
    and direction-setting. It also helps them and the community know which users are
    doing well.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你可能已经熟悉了将一组数据划分为训练集、验证集和测试集的过程。这对我们使用过的一些标准数据集来说效果不错，但这个数据集是一个竞赛的一部分，并且是公开审计的，所以我们不知道答案！这很好地反映了现实生活。有一个小问题——大多数
    Kaggle 竞赛允许你提出答案并告诉你你的总评分，这有助于学习和设定方向。它也有助于他们和社区了解哪些用户表现良好。
- en: 'Since the test labels are blinded, we''ll need to change two things we''ve
    done before:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 由于测试标签是盲测的，我们需要改变之前做过的两件事：
- en: We will need to have one procedure for internal development and iteration (we'll
    likely chunk our training set into a training, validation, and test set). We will
    need another procedure for external testing (we may settle upon a promising setup
    that works well, and then we may either run it on the blind test set or we may
    retrain on the entire training set first).
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将需要一个用于内部开发和迭代的流程（我们可能会将训练集分成训练集、验证集和测试集）。我们将需要另一个用于外部测试的流程（我们可能会找到一个有效的设置，运行它在盲测集上，或者首先重新训练整个训练集）。
- en: 'We will need to make a formal proposal in a very specific format, submit it
    to the independent auditor (Kaggle, in this case), and gauge the progress accordingly.
    Here is what a sample submission may look like:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要以非常特定的格式提交正式提案，将其提交给独立审计员（在此案例中为 Kaggle），并根据进展情况进行评估。以下是一个示例提交的样式：
- en: '| **Image** | **Level** |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| **图像** | **级别** |'
- en: '| `44342_left` | 0 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `44342_left` | 0 |'
- en: '| `44342_right` | 1 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| `44342_right` | 1 |'
- en: '| `44344_left` | 2 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| `44344_left` | 2 |'
- en: '| `44344_right` | 2 |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `44344_right` | 2 |'
- en: '| `44345_left` | 0 |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| `44345_left` | 0 |'
- en: '| `44345_right` | 0 |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| `44345_right` | 0 |'
- en: '| `44346_left` | 4 |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| `44346_left` | 4 |'
- en: '| `44346_right` | 3 |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| `44346_right` | 3 |'
- en: '| `44350_left` | 1 |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| `44350_left` | 1 |'
- en: '| `44350_right` | 1 |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| `44350_right` | 1 |'
- en: '| `44351_left` | 4 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| `44351_left` | 4 |'
- en: '| `44351_right` | 4 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| `44351_right` | 4 |'
- en: 'Not surprisingly, it looks very much like the training label file. You can
    make your submission here:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，它看起来和训练标签文件非常相似。你可以在这里提交你的内容：
- en: '[https://www.kaggle.com/c/diabetic-retinopathy-detection/submithttps://www.kaggle.com/c/diabetic-retinopathy-detection/submit](https://www.kaggle.com/c/diabetic-retinopathy-detection/submit%20%20)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/c/diabetic-retinopathy-detection/submithttps://www.kaggle.com/c/diabetic-retinopathy-detection/submit](https://www.kaggle.com/c/diabetic-retinopathy-detection/submit%20%20)'
- en: You need to login in order to open the preceding link.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要登录才能打开上述链接。
- en: The data
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据
- en: Let's start to peek at the data. Open up some of the sample files and be prepared
    for a shocker—these are neither 28x28 tiles of handwriting nor 64x64 icons with
    cat faces. This is a real dataset from the real world. In fact, not even the sizes
    are consistent across images. Welcome to the real world.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始看看数据。打开一些示例文件并准备好迎接惊讶——这些既不是 28x28 的手写字块，也不是带有猫脸的 64x64 图标。这是一个来自现实世界的真实数据集。事实上，图像的大小甚至不一致。欢迎来到现实世界。
- en: You'll find sizes ranging from 2,000 pixels per side to almost 5,000 pixels!
    This brings us to our first real-life task—creating a training **pipeline**. The
    pipeline will be a set of steps that abstract away the ugly realities of life
    and produce a set of clean and consistent data.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现图像的大小从每边 2,000 像素到接近 5,000 像素不等！这引出了我们第一个实际任务——创建一个训练**管道**。管道将是一组步骤，抽象掉生活中的艰难现实，并生成一组干净、一致的数据。
- en: The pipeline
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管道
- en: We will go about this intelligently. There are a lot of pipeline model structures
    made by Google using different networks in their `TensorFlow` library. What we'll
    do here is take one of those model structures and networks and modify the code
    to our needs.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将智能地进行处理。Google 使用其 `TensorFlow` 库中的不同网络制作了许多管道模型结构。我们要做的是从这些模型结构和网络中选择一个，并根据我们的需求修改代码。
- en: This is good because we won't waste our time building a pipeline from scratch
    and won't have to worry about incorporating the TensorBoard visualization stuff
    as it is already present in the Google pipeline models.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，因为我们不会浪费时间从零开始构建管道，也不必担心集成 TensorBoard 可视化工具，因为它已经包含在 Google 的管道模型中。
- en: 'We will use a pipeline model from here:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从这里使用一个管道模型：
- en: '[https://github.com/tensorflow/models/](https://github.com/tensorflow/models/)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/tensorflow/models/](https://github.com/tensorflow/models/)'
- en: As you can see, there are a lot of different models made in TensorFlow in this
    repository. You can dive deeper into some models that are related to natural language
    processing (NLP), recursive neural networks, and other topics. This is a really
    good place to start if you want to understand complex models.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这个仓库中有许多由 TensorFlow 制作的不同模型。你可以深入了解一些与自然语言处理（NLP）、递归神经网络及其他主题相关的模型。如果你想理解复杂的模型，这是一个非常好的起点。
- en: 'For this chapter, we will use the **Tensorflow-Slim image classification model
    library**. You can find the library here:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，我们将使用**Tensorflow-Slim 图像分类模型库**。你可以在这里找到这个库：
- en: '[https://github.com/tensorflow/models/tree/master/research/slim](https://github.com/tensorflow/models/tree/master/research/slim)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/tensorflow/models/tree/master/research/slim](https://github.com/tensorflow/models/tree/master/research/slim)'
- en: There are a lot of details already present on the website that explain how to
    use this library. They also tell you how to use this library in a distributed
    environment and also how to utilize multiple GPUs to get a faster training time
    and even deploy to production.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 网站上已经有很多详细信息，解释了如何使用这个库。他们还告诉你如何在分布式环境中使用该库，并且如何利用多 GPU 来加速训练时间，甚至部署到生产环境中。
- en: The best thing about using this is that they provide you with the pre-trained
    model snapshot, which you can use to dramatically reduce the training time of
    your network. So, even if you have slow GPUs, you won't have to train your network
    this large for weeks to get to a reasonable level of training.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个的最佳之处在于，他们提供了预训练的模型快照，你可以利用它显著减少训练网络的时间。因此，即使你有较慢的 GPU，也不必花费数周的时间来训练这么大的网络，便可达到一个合理的训练水平。
- en: This is called fine-tuning of the model, in which you just have to provide a
    different dataset and tell the network to reinitialize the final layers of the
    network in order to retrain them. Also, you tell it how many output label classes
    you have in your dataset. In our case, there are five unique classes to identify
    different levels of **diabetic retinopathy** (**DR**).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这叫做模型的微调，你只需要提供一个不同的数据集，并告诉网络重新初始化网络的最终层以便重新训练它们。此外，你还需要告诉它数据集中有多少个输出标签类。在我们的案例中，有五个独特的类别，用于识别不同等级的**糖尿病视网膜病变**（**DR**）。
- en: 'The pre-trained snapshot can be found here:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练的快照可以在这里找到：
- en: '[https://github.com/tensorflow/models/tree/master/research/slim#Pretrained](https://github.com/tensorflow/models/tree/master/research/slim#Pretrained)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/tensorflow/models/tree/master/research/slim#Pretrained](https://github.com/tensorflow/models/tree/master/research/slim#Pretrained)'
- en: 'As you can see in the preceding link, they provide many types of pre-trained
    models that we can leverage. They have used the `ImageNet` dataset to train these
    models. `ImageNet` is a standard dataset of 1,000 classes with dataset sizing
    almost 500 GB. You can find more about it here:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在上面的链接中所见，他们提供了许多可以利用的预训练模型。他们使用了`ImageNet`数据集来训练这些模型。`ImageNet`是一个标准数据集，包含
    1,000 个类别，数据集大小接近 500 GB。你可以在这里了解更多：
- en: '[http://image-net.org/](http://image-net.org/)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://image-net.org/](http://image-net.org/)'
- en: Understanding the pipeline
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解管道
- en: 'Let''s start by cloning the `models` repository into your computer:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，开始将`models`仓库克隆到你的计算机中：
- en: '[PRE0]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, let's dive into the pipeline that we got from Google's model repository.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入了解从Google模型仓库中获得的管道。
- en: If you look at the folder at this path prefix (`models/research/slim`) in the
    repository, you'll see folders named `datasets`, `deployment`, `nets`, `preprocessing`,
    and `scripts`; a bunch of files related to generating the model, plus training
    and testing pipelines and files related to training the `ImageNet` dataset, and
    a dataset named `flowers`**.**
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看仓库中这个路径前缀(`models/research/slim`)的文件夹，你会看到名为`datasets`、`deployment`、`nets`、`preprocessing`和`scripts`的文件夹；这些文件涉及生成模型、训练和测试管道，以及与训练`ImageNet`数据集相关的文件，还有一个名为`flowers`**的数据集**。
- en: We will use the `download_and_convert_data.py` to build our DR dataset. This
    `image classification model` library is built based on the `slim` library. In
    this chapter, we will fine-tune the inception network defined in `nets/inception_v3.py`
    (we'll talk more about the network specifications and its concept later in this
    chapter), which includes the calculation of the loss function, adding different
    ops, structuring the network, and more. Finally, the `train_image_classifier.py`
    and `eval_image_classifier.py` files contain the generalized procedures for making
    a training and testing pipeline for our network.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`download_and_convert_data.py`来构建我们的DR数据集。这个`图像分类模型`库是基于`slim`库构建的。在这一章中，我们将微调在`nets/inception_v3.py`中定义的Inception网络（稍后我们会详细讨论网络的规格和概念），其中包括计算损失函数、添加不同的操作、构建网络等内容。最后，`train_image_classifier.py`和`eval_image_classifier.py`文件包含了为我们的网络创建训练和测试管道的通用程序。
- en: For this chapter, due to the complex nature of the network, we are using a GPU-based
    pipeline to train the network. If you want to find out how to install TensorFlow
    for GPU in your machine, then refer to [Appendix A](8022db02-d24f-4620-9da7-ae53df279306.xhtml), *Advanced
    Installation*, in this book. Also, you should have about **120 GB** space inside
    your machine to be able to run this code. You can find the final code files in
    the `Chapter 8` folder of this book's code files.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这一章，由于网络的复杂性，我们使用基于GPU的管道来训练网络。如果你想了解如何在你的机器上安装适用于GPU的TensorFlow，请参考本书中的[附录A](8022db02-d24f-4620-9da7-ae53df279306.xhtml)，*高级安装*部分。此外，你的机器中应该有大约**120
    GB**的空间才能运行此代码。你可以在本书代码文件的`Chapter 8`文件夹中找到最终的代码文件。
- en: Preparing the dataset
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备数据集
- en: Now, let's start preparing the dataset of our network.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始准备网络的数据集。
- en: For this inception network, we'll use the `TFRecord` class to manage our dataset.
    The output dataset files after the preprocessing will be protofiles, which `TFRecord`
    can read, and it's just our data stored in a serialized format for faster reading
    speed. Each protofile has some information stored within it, which is information
    such as image size and format.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个Inception网络，我们将使用`TFRecord`类来管理我们的数据集。经过预处理后的输出数据集文件将是proto文件，`TFRecord`可以读取这些文件，它只是以序列化格式存储的我们的数据，以便更快的读取速度。每个proto文件内包含一些信息，如图像的大小和格式。
- en: The reason we are doing this is that the size of the dataset is too large and
    we cannot load the entire dataset into memory (RAM) as it will take up a huge
    amount of space. Therefore, to manage efficient RAM usage, we have to load the
    images in batches and delete the previously loaded images that are not being used
    right now.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这样做的原因是，数据集的大小太大，我们不能将整个数据集加载到内存（RAM）中，因为它会占用大量空间。因此，为了高效使用内存，我们必须分批加载图像，并删除当前没有使用的已经加载的图像。
- en: The input size the network will take is 299x299\. So, we will find a way to
    first reduce the image size to 299x299 to have a dataset of consistent images.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 网络将接收的输入大小是299x299。因此，我们将找到一种方法，首先将图像大小缩小到299x299，以便得到一致的图像数据集。
- en: After reducing the images, we will make protofiles that we can later feed into
    our network, which will get trained on our dataset.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在减少图像大小后，我们将制作proto文件，稍后可以将这些文件输入到我们的网络中，网络将对我们的数据集进行训练。
- en: 'You need to first download the five training ZIP files and the labels file
    from here:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要首先从这里下载五个训练ZIP文件和标签文件：
- en: '[https://www.kaggle.com/c/diabetic-retinopathy-detection/data](https://www.kaggle.com/c/diabetic-retinopathy-detection/data)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/c/diabetic-retinopathy-detection/data](https://www.kaggle.com/c/diabetic-retinopathy-detection/data)'
- en: Unfortunately, Kaggle only lets you download the training ZIP files through
    an account, so this procedure of downloading the dataset files (as in the previous
    chapters) can't be made automatic.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，Kaggle 仅允许通过账户下载训练的 ZIP 文件，因此无法像之前章节那样自动化下载数据集文件的过程。
- en: 'Now, let''s assume that you have downloaded all five training ZIP files and
    labels file and stored them in a folder named `diabetic`. The structure of the
    `diabetic` folder will look like this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设你已经下载了所有五个训练 ZIP 文件和标签文件，并将它们存储在名为 `diabetic` 的文件夹中。`diabetic` 文件夹的结构将如下所示：
- en: '`diabetic`'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`diabetic`'
- en: '`train.zip.001`'
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train.zip.001`'
- en: '`train.zip.002`'
  id: totrans-94
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train.zip.002`'
- en: '`train.zip.003`'
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train.zip.003`'
- en: '`train.zip.004`'
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train.zip.004`'
- en: '`train.zip.005`'
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train.zip.005`'
- en: '`trainLabels.csv.zip`'
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainLabels.csv.zip`'
- en: 'In order to simplify the project, we will do the extraction manually using
    the compression software. After the extraction is completed, the structure of
    the `diabetic` folder will look like this:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化项目，我们将手动使用压缩软件进行解压。解压完成后，`diabetic` 文件夹的结构将如下所示：
- en: '`diabetic`'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`diabetic`'
- en: '`train`'
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train`'
- en: '` 10_left.jpeg`'
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '` 10_left.jpeg`'
- en: '`10_right.jpeg`'
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`10_right.jpeg`'
- en: '...'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '...'
- en: '`trainLabels.csv`'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainLabels.csv`'
- en: '`train.zip.001`'
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train.zip.001`'
- en: '`train.zip.002`'
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train.zip.002`'
- en: '` train.zip.003`'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '` train.zip.003`'
- en: '` train.zip.004`'
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '` train.zip.004`'
- en: '`train.zip.005`'
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train.zip.005`'
- en: '`trainLabels.csv.zip`'
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainLabels.csv.zip`'
- en: In this case, the `train` folder contains all the images in the .zip files and `trainLabels.csv`
    contains the ground truth labels for each image.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`train` 文件夹包含所有 .zip 文件中的图像，而 `trainLabels.csv` 文件包含每张图像的真实标签。
- en: The author of the models repository has provided some example code to work with
    some popular image classification datasets. Our diabetic problem can be solved
    with the same approach. Therefore, we can follow the code that works with other
    datasets such as `flower` or `MNIST` dataset. We have already provided the modification
    to work with diabetic in the repository of this book at [https://github.com/mlwithtf/mlwithtf/](https://github.com/mlwithtf/mlwithtf/).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 模型库的作者提供了一些示例代码，用于处理一些流行的图像分类数据集。我们的糖尿病问题也可以用相同的方法来解决。因此，我们可以遵循处理其他数据集（如 `flower`
    或 `MNIST` 数据集）的代码。我们已经在本书的 [https://github.com/mlwithtf/mlwithtf/](https://github.com/mlwithtf/mlwithtf/)
    库中提供了修改代码，便于处理糖尿病数据集。
- en: 'You need to clone the repository and navigate to the `chapter_08` folder. You
    can run the `download_and_convert_data.py` file as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要克隆仓库并导航到 `chapter_08` 文件夹。你可以按照以下方式运行 `download_and_convert_data.py` 文件：
- en: '[PRE1]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this case, we will use `dataset_name` as `diabetic` and `dataset_dir` is
    the folder that contains the `trainLabels.csv` and `train` folder.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将使用 `dataset_name` 为 `diabetic`，而 `dataset_dir` 是包含 `trainLabels.csv`
    和 `train` 文件夹的文件夹。
- en: 'It should run without any issues, start preprocessing our dataset into a suitable
    (299x299) format, and create some `TFRecord` file in a newly created folder named `tfrecords`.
    The following figure shows the content of the `tfrecords` folder:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 它应该能够顺利运行，开始将数据集预处理成适合的 (299x299) 格式，并在新创建的 `tfrecords` 文件夹中生成一些 `TFRecord`
    文件。下图展示了 `tfrecords` 文件夹的内容：
- en: '![](img/e6e0c22a-1342-443c-85f0-aa66e157c294.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e6e0c22a-1342-443c-85f0-aa66e157c294.png)'
- en: Explaining the data preparation
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释数据准备过程
- en: Now let's get to the coding part for the data preprocessing. From now on, we
    will show you what we have changed from the original repository of the `tensorflow/models`.
    Basically, we take the code to the process `flowers` dataset as the starting point
    and modify them to suit our needs.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始编写数据预处理的代码。从现在开始，我们将展示我们对 `tensorflow/models` 原始库所做的修改。基本上，我们将处理 `flowers`
    数据集的代码作为起点，并对其进行修改以满足我们的需求。
- en: 'In the `download_and_convert_data.py` file, we have added a new line at the
    beginning of the file:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `download_and_convert_data.py` 文件中，我们在文件开头添加了一行新的代码：
- en: '[PRE2]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: With this code, we can call the run method in the `download_and_convert_diabetic.py`
    in the `datasets` folder. This is a really simple approach to separating the preprocessing
    code of multiple datasets, but we can still take advantage of the others parts
    of the `image classification` library.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这段代码，我们可以调用 `datasets` 文件夹中的 `download_and_convert_diabetic.py` 文件中的 `run`
    方法。这是一种非常简单的方法，用于分离多个数据集的预处理代码，但我们仍然可以利用 `image classification` 库的其他部分。
- en: The `download_and_convert_diabetic.py` file is a copy of the `download_and_convert_flowers.py`
    file with some modifications to prepare our diabetic dataset.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`download_and_convert_diabetic.py` 文件是对 `download_and_convert_flowers.py` 文件的复制，并对其进行了修改，以准备我们的糖尿病数据集。'
- en: 'In the run method of the `download_and_convert_diabetic.py` file, we made changes
    as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `download_and_convert_diabetic.py` 文件的 `run` 方法中，我们做了如下更改：
- en: '[PRE3]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In this code, we use the `prepare_dr_dataset` from the `data_utils` package
    that was prepared in the root of this book repository. We will look at that method
    later. Then, we changed the `_get_filenames_and_classes` method to return the
    `training` and `validation` filenames. The last few lines are the same as the
    `flowers` dataset example:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，我们使用了来自 `data_utils` 包的 `prepare_dr_dataset`，该包在本书仓库的根目录中准备好。稍后我们会看这个方法。然后，我们修改了
    `_get_filenames_and_classes` 方法，以返回 `training` 和 `validation` 的文件名。最后几行与 `flowers`
    数据集示例相同：
- en: '[PRE4]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the preceding method, we find all the filenames in the `processed_images/train`
    and `processed/validation` folder, which contains the images that were preprocessed
    in the `data_utils.prepare_dr_dataset` method.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的这个方法中，我们查找了 `processed_images/train` 和 `processed/validation` 文件夹中的所有文件名，这些文件夹包含了在
    `data_utils.prepare_dr_dataset` 方法中预处理过的图像。
- en: In the `data_utils.py` file, we have written the `prepare_dr_dataset(dataset_dir)`
    function, which is responsible for the entire preprocessing of the data.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `data_utils.py` 文件中，我们编写了 `prepare_dr_dataset(dataset_dir)` 函数，负责整个数据的预处理工作。
- en: 'Let''s start by defining the necessary variables to link to our data:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先定义必要的变量来链接到我们的数据：
- en: '[PRE5]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `num_of_processing_threads` variable is used to specify the number of threads
    we want to use while preprocessing our dataset, as you may have already guessed.
    We will use a multi-threaded environment to preprocess our data faster. Later
    on, we have specified some directory paths to contain our data inside different
    folders while preprocessing.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`num_of_processing_threads` 变量用于指定在预处理数据集时我们希望使用的线程数，正如你可能已经猜到的那样。我们将使用多线程环境来加速数据预处理。随后，我们指定了一些目录路径，用于在预处理时将数据存放在不同的文件夹中。'
- en: We will extract the images in their raw form and then preprocess them to get
    them into a suitable consistent format and size, and then we will generate the
    `tfrecords` files from the processed images with the `_convert_dataset` method
    in the `download_and_convert_diabetic.py` file. After that, we will feed these
    `tfrecords` files into the training and testing networks.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将提取原始形式的图像，然后对它们进行预处理，将其转换为适当的一致格式和大小，之后，我们将使用 `download_and_convert_diabetic.py`
    文件中的 `_convert_dataset` 方法从处理过的图像生成 `tfrecords` 文件。之后，我们将这些 `tfrecords` 文件输入到训练和测试网络中。
- en: 'As we said in the previous section, we have already extracted the `dataset`
    files and the labels files. Now, as we have all of the data extracted and present
    inside our machine, we will process the images. A typical image from the DR dataset
    looks like this:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前一部分所说的，我们已经提取了 `dataset` 文件和标签文件。现在，既然我们已经提取了所有数据并将其存储在机器中，我们将开始处理图像。来自
    DR 数据集的典型图像如下所示：
- en: '![](img/d8fd4a61-193c-420c-a0eb-fa2cf12a79a3.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d8fd4a61-193c-420c-a0eb-fa2cf12a79a3.png)'
- en: What we want is to remove this extra black space because it is not necessary
    for our network. This will reduce the unnecessary information inside the image.
    After this, we will scale this image into a 299x299 JPG image file.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要做的是去除这些多余的黑色空间，因为它对我们的网络来说并不必要。这将减少图像中的无关信息。之后，我们会将这张图像缩放成一个 299x299 的 JPG
    图像文件。
- en: We will repeat this process for all of the training datasets.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对所有训练数据集重复此过程。
- en: 'The function to crop the black image borders is as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 剪裁黑色图像边框的函数如下所示：
- en: '[PRE6]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This function takes the image and a threshold for a grayscale, below which it
    will remove the black borders around the image.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数接收图像和一个灰度阈值，低于此值时，它会去除图像周围的黑色边框。
- en: 'As we are doing all of this processing in a multithreaded environment, we will
    process the images in batches. To process an image batch, we will use the following
    function:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在多线程环境中执行所有这些处理，我们将按批次处理图像。要处理一个图像批次，我们将使用以下函数：
- en: '[PRE7]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The `thread_index`tells us the ID of the thread in which the function has been
    called. The threaded environment around processing the image batch is defined
    in the following function:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`thread_index` 告诉我们调用该函数的线程 ID。处理图像批次的多线程环境在以下函数中定义：'
- en: '[PRE8]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To get the final result from all of the threads, we use a `TensorFlow` class,
    `tf.train.Coordinator()`, whose `join` function is responsible for handling all
    of the threads' final approach point.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从所有线程中获取最终结果，我们使用一个 `TensorFlow` 类，`tf.train.Coordinator()`，它的 `join` 函数负责处理所有线程的最终处理点。
- en: For the threading, we use `threading.Thread`, in which the `target` argument
    specifies the function to be called and the `args` argument specifies the target
    function arguments.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线程处理，我们使用`threading.Thread`，其中`target`参数指定要调用的函数，`args`参数指定目标函数的参数。
- en: Now, we will process the training images. The training dataset is divided into
    a train set (30,000 images) and a validation set (5,126 images).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将处理训练图像。训练数据集分为训练集（30,000张图像）和验证集（5,126张图像）。
- en: 'The total preprocessing is handled as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 总的预处理过程如下所示：
- en: '[PRE9]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, we will look at the last method for preparing the dataset, the `_convert_dataset`
    method that is called in the `download_and_convert_diabetic.py` file:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将查看准备数据集的最后一个方法，即在`download_and_convert_diabetic.py`文件中调用的`_convert_dataset`方法：
- en: '[PRE10]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the preceding function, we will get the image filenames and then store them
    in the `tfrecord` files. We will also split the `train` and `validation` files
    into multiple `tfrecord` files instead of using only one file for each split set.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的函数中，我们将获取图像文件名，并将它们存储在`tfrecord`文件中。我们还会将`train`和`validation`文件拆分为多个`tfrecord`文件，而不是只使用一个文件来存储每个分割数据集。
- en: 'Now, as the data processing is out of the way, we will formalize the dataset
    into an instance of `slim.dataset`. Dataset from `Tensorflow Slim`. In the `datasets/diabetic.py`
    file, you will see a method named `get_split`, as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，数据处理已经完成，我们将正式将数据集形式化为`slim.dataset`的实例。数据集来自`Tensorflow Slim`。在`datasets/diabetic.py`文件中，你将看到一个名为`get_split`的方法，如下所示：
- en: '[PRE11]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The preceding method will be called during the training and evaluating routines.
    We will create an instance of `slim.dataset` with the information about our `tfrecord`
    files so that it can automatically perform the work to parse the binary files.
    Moreover, we can also use `slim.dataset.Dataset` with the support of `DatasetDataProvider`
    from Tensorflow Slim to read the dataset in parallel, so we can increase the training
    and evaluating routines.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的方法将在训练和评估过程中被调用。我们将创建一个`slim.dataset`的实例，包含关于我们的`tfrecord`文件的信息，以便它可以自动解析二进制文件。此外，我们还可以使用`slim.dataset.Dataset`，结合`DatasetDataProvider`，通过Tensorflow
    Slim来并行读取数据集，从而提高训练和评估的效率。
- en: Before we start training, we need to download the pre-trained model of Inception
    V3 from the `Tensorflow Slim image classification` library so we can leverage
    the performance of Inception V3 without training from scratch.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练之前，我们需要从`Tensorflow Slim 图像分类`库中下载Inception V3的预训练模型，这样我们就可以利用Inception
    V3的性能，而无需从头开始训练。
- en: 'The pre-trained snapshot can be found here:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练快照可以在这里找到：
- en: '[https://github.com/tensorflow/models/tree/master/research/slim#Pretrained](https://github.com/tensorflow/models/tree/master/research/slim#Pretrained)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/tensorflow/models/tree/master/research/slim#Pretrained](https://github.com/tensorflow/models/tree/master/research/slim#Pretrained)'
- en: In this chapter, we will use Inception V3, so we need to download the `inception_v3_2016_08_28.tar.gz`
    file and extract it to have the checkpoint file named `inception_v3.ckpt`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用Inception V3，因此我们需要下载`inception_v3_2016_08_28.tar.gz`文件，并解压缩它以获得名为`inception_v3.ckpt`的检查点文件。
- en: Training routine
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练过程
- en: Now let's move towards training and evaluating our model.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续进行模型的训练和评估。
- en: 'The training script is present inside `train_image_classifer.py`. Since we
    have followed the workflow of the library, we can leave this file untouched and
    run our training routine with the following command:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 训练脚本位于`train_image_classifer.py`文件中。由于我们遵循了该库的工作流程，因此可以保持该文件不变，并使用以下命令运行训练过程：
- en: '[PRE12]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In our setup, we have run the training process overnight. Now, we will run the
    trained model through the validation process to see how it works.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的设置中，我们已经让训练过程运行了一整夜。现在，我们将运行训练好的模型，通过验证过程来查看其效果。
- en: Validation routine
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证过程
- en: 'You can run the validation routine with the following command:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令运行验证过程：
- en: '[PRE13]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](img/e5a39134-d138-4657-b5b0-b0cdbf535885.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e5a39134-d138-4657-b5b0-b0cdbf535885.png)'
- en: As you can see, the current accuracy is about 75 percent. In the *Going further*
    section, we will give you some ideas to improve this accuracy.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，当前的准确率大约是75%。在*进一步探索*部分，我们将给出一些提高准确率的建议。
- en: Now, we will look at the TensorBoard to visualize the training process.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将查看TensorBoard，来可视化训练过程。
- en: Visualize outputs with TensorBoard
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorBoard可视化输出
- en: Now, we will visualize the training result with TensorBoard.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用TensorBoard来可视化训练结果。
- en: 'First, you need to change the `command-line` directory to the folder that contains
    the checkpoints. In our case, it is the `train_dir` parameter in the previous
    command, `D:\datasets\diabetic\checkpoints`. Then, you should run the following
    command:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要将`command-line`目录更改为包含检查点的文件夹。在我们的例子中，它是上一条命令中的`train_dir`参数，`D:\datasets\diabetic\checkpoints`。然后，你应该运行以下命令：
- en: '[PRE14]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here is some output when we run TensorBoard for our network:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们运行TensorBoard时的输出：
- en: '![](img/ef7909a6-8cb9-4a9e-8ce6-f3c1aedfa0ea.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef7909a6-8cb9-4a9e-8ce6-f3c1aedfa0ea.png)'
- en: 'The preceding image shows the nodes containing the RMS prop optimizer for the
    training network and some logits that it contains for the output of DR classification.
    The next screenshot shows the images coming as input, along with their preprocessing
    and modifications:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图像显示了包含RMSprop优化器的节点，用于训练网络以及它所包含的用于DR分类输出的一些logits。下一张截图展示了作为输入的图像及其预处理和修改：
- en: '![](img/0f3edeef-914b-49a9-ba3b-4c993b857449.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0f3edeef-914b-49a9-ba3b-4c993b857449.png)'
- en: 'In this screenshot, you can see the graph showing the network output during
    training:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在此截图中，你可以看到训练过程中网络输出的图形：
- en: '![](img/ac215a51-fc57-4826-81a0-3aa05b16bc2e.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ac215a51-fc57-4826-81a0-3aa05b16bc2e.png)'
- en: 'This screenshot depicts the total raw loss of the network during training:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这张截图显示了训练过程中网络的总原始损失：
- en: '![](img/10d1ce85-4786-4914-bb10-4f363202e7fa.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](img/10d1ce85-4786-4914-bb10-4f363202e7fa.png)'
- en: Inception network
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Inception网络
- en: The main concept behind the inception network is to combine different convolutions
    in a single layer. The combination is done by combining 7x7, 5x5, 3x3, and 1x1
    convolutions to give to the next layer. Through this, the network can extract
    more features of the network and thus give better accuracy. This is shown in the
    following image of the Google inception V3 network. You can try to access the
    code at `chapter_08/nets/inception_v3.py`.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Inception网络的主要概念是将不同的卷积操作结合在同一层中。通过将7x7、5x5、3x3和1x1的卷积组合在一起，传递给下一层。通过这种方式，网络可以提取更多的特征，从而提高准确性。以下是Google
    Inception V3网络的示意图。你可以尝试访问`chapter_08/nets/inception_v3.py`中的代码。
- en: '![](img/e3cb0bf3-f977-4546-9046-fc474ee35279.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e3cb0bf3-f977-4546-9046-fc474ee35279.png)'
- en: The image is taken from [https://github.com/tensorflow/models/blob/master/research/inception/g3doc/inception_v3_architecture.png](https://github.com/tensorflow/models/blob/master/research/inception/g3doc/inception_v3_architecture.png)
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 该图像来自[https://github.com/tensorflow/models/blob/master/research/inception/g3doc/inception_v3_architecture.png](https://github.com/tensorflow/models/blob/master/research/inception/g3doc/inception_v3_architecture.png)
- en: Going further
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 继续深入
- en: The result we got from running this network is 75 percent accurate on the validation
    set. This is not very good because of the criticality of the network usage. In
    medicine, there is not much room for error because a person's medical condition
    is on the line.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从运行该网络中得到的结果是在验证集上的准确率为75%。这并不算很好，因为该网络的使用非常关键。在医学中，错误的余地非常小，因为人的健康状况直接关系到生命。
- en: 'To make this accuracy better, we need to define a different criterion for evaluation.
    You can read more about it here:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高准确性，我们需要定义不同的评估标准。你可以在这里阅读更多内容：
- en: '[https://en.wikipedia.org/wiki/Confusion_matrix](https://en.wikipedia.org/wiki/Confusion_matrix)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://en.wikipedia.org/wiki/Confusion_matrix](https://en.wikipedia.org/wiki/Confusion_matrix)'
- en: Also, you can balance the dataset. What we have now is an unbalanced dataset
    in which the number of diseased patients is much lower than the number of normal
    patients. Thus, the network becomes more sensitive to normal patients' features
    and less sensitive to diseased patients' features.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，你可以平衡数据集。现在的数据集是不平衡的，病人数量远少于正常患者。因此，网络对正常患者特征更加敏感，而对病人特征较不敏感。
- en: To fix this problem, we can SMOTE our dataset. SMOTing is basically replicating
    the data of less frequent classes (flipping the image horizontally or vertically,
    changing saturation, and so on) to create a balanced dataset. SMOTE stands for
    **Synthetic Minority Over-sampling Technique**.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 为了修复这个问题，我们可以对数据集进行SMOTE处理。SMOTE基本上是通过复制较少频繁类别的数据（例如水平或垂直翻转图像、改变饱和度等）来创建一个平衡的数据集。SMOTE代表**合成少数类过采样技术**。
- en: 'Here is a good read on this topic:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一本关于该主题的优秀读物：
- en: '[https://www.jair.org/media/953/live-953-2037-jair.pdf](https://www.jair.org/media/953/live-953-2037-jair.pdf)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.jair.org/media/953/live-953-2037-jair.pdf](https://www.jair.org/media/953/live-953-2037-jair.pdf)'
- en: Other medical data challenges
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他医学数据挑战
- en: Understandably, medical data is not as easy to release as other datasets, so
    there are far fewer datasets in the public domain. This is changing slowly, but
    in the meantime, here are some datasets and associated challenges you can try
    your hand at. Note that many of these challenges have been overcome, but they
    have luckily continued to publish the datasets.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 可以理解的是，医疗数据不像其他数据集那样容易发布，因此公开领域的数据集要少得多。这一情况正在缓慢改变，但与此同时，以下是一些你可以尝试的公开数据集和相关挑战。需要注意的是，许多挑战已经被克服，但幸运的是，它们仍然继续发布数据集。
- en: The ISBI grand challenge
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ISBI大奖挑战
- en: ISBI is the International Symposium on Biomedical Imaging, a popular venue for
    furthering the type of work you're seeing in this chapter. Their annual conferences
    often feature multiple challenges posed to the academic community. They posed
    several challenges in 2016.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: ISBI是国际生物医学影像学大会，这是一个推动本章中所述工作的受欢迎的会议场所。他们的年度会议通常会向学术界提出多个挑战。2016年他们提出了几个挑战。
- en: 'One popular challenge was the AIDA-E: Analysis of Images to Detect Abnormalities
    in Endoscopy. The challenge website is [http://isbi-aida.grand-challenge.org/](http://isbi-aida.grand-challenge.org/).'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 一个受欢迎的挑战是AIDA-E：内窥镜图像分析检测异常。挑战网站是[http://isbi-aida.grand-challenge.org/](http://isbi-aida.grand-challenge.org/)。
- en: Another popular challenge was the Cancer Metastasis Detection in Lymph Nodes,
    which features pathology data. The challenge website is [http://camelyon16.grand-challenge.org/](http://camelyon16.grand-challenge.org/).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个受欢迎的挑战是淋巴结中的癌症转移检测，涉及病理数据。挑战网站是[http://camelyon16.grand-challenge.org/](http://camelyon16.grand-challenge.org/)。
- en: On the radiology side, a popular challenge in 2016 was the Data Science Bowl
    challenge on heart disease diagnosis. Titled *Transforming How We Diagnose Heart
    Disease*, the challenge sought to segment parts of the cardiac Magnetic Resonance
    Imaging data to gauge pump volume, which was then used as a proxy for heart health.
    The challenge website and dataset is [http://www.datasciencebowl.com/competitions/transforming-how-we-diagnose-heart-disease/](http://www.datasciencebowl.com/competitions/transforming-how-we-diagnose-heart-disease/).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在放射学方面，2016年一个受欢迎的挑战是数据科学碗挑战赛，聚焦心脏病诊断。该挑战名为*转变我们诊断心脏病的方式*，目标是对心脏磁共振成像（MRI）数据的部分进行分割，以衡量心脏泵血量，这一数据被用作心脏健康的代理指标。挑战网站及数据集为[http://www.datasciencebowl.com/competitions/transforming-how-we-diagnose-heart-disease/](http://www.datasciencebowl.com/competitions/transforming-how-we-diagnose-heart-disease/)。
- en: Another popular radiology dataset is the Lung Image Database Consortium's **computed
    tomography** (**CT**) data in the LIDC-IDRI image collection. This is a dataset
    of diagnostic and lung cancer screening thoracic CT scans. Interestingly, instead
    of image-level classes, this dataset annotates the actual locations of the lesions.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个受欢迎的放射学数据集是Lung Image Database Consortium（LIDC）中的**计算机断层扫描**（**CT**）数据，属于LIDC-IDRI图像集。这是一个诊断和肺癌筛查胸部CT扫描的数据集。有趣的是，除了图像级别的类别外，该数据集还标注了病变的实际位置。
- en: 'The two radiology competitions are interesting for two more reasons:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个放射学竞赛还有两个有趣的原因：
- en: They feature three-dimensional **volume** data, which is essentially an ordered
    stack of two-dimensional images that form an actual space.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们包括三维**体积**数据，本质上是由二维图像组成的有序堆叠，这些图像共同构成了一个实际的空间。
- en: They feature **segmentation** tasks where you want to classify parts of an image
    or volume into certain classes. This is a familiar classification challenge, except
    we're trying to also localize the feature on the image. In one case, we seek to
    localize the feature and point to it (rather than classify the entire image),
    and in another case, we seek to classify a section as a way to measure the size
    of a region.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们包括**分割**任务，在这些任务中，你需要将图像或体积的某些部分分类到特定类别。这是一个常见的分类挑战，不同之处在于我们还尝试对图像中的特征进行定位。在一种情况下，我们尝试定位特征并指出它的位置（而不是对整个图像进行分类），在另一种情况下，我们则尝试将一个区域进行分类，以此来衡量一个区域的大小。
- en: We'll speak more about dealing with volume data later, but for now, you've got
    some really interesting and varied datasets to work with.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后会更多地讨论如何处理体积数据，但目前你已经有了一些非常有趣和多样化的数据集可以使用。
- en: Reading medical data
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 阅读医疗数据
- en: The diabetic retinopathy challenge, despite the challenges, is not as complicated
    as it gets. The actual images were provided in JPEG format, but most medical data
    is not in JPEG format. They are usually within container formats such as DICOM.
    DICOM stands for **Digital Imaging and Communications in Medicine** and has a
    number of versions and variations. It contains the medical image, but also header
    data. The header data often includes general demographic and study data, but it
    can contain dozens of other custom fields. If you are lucky, it will also contain
    a diagnosis, which you can use as a label.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在挑战，但糖尿病视网膜病变挑战并不像想象中那么复杂。实际图像是以 JPEG 格式提供的，但大多数医学数据并非 JPEG 格式。它们通常是容器格式，如
    DICOM。DICOM 代表 **医学中的数字成像与通信**，并且有多个版本和变体。它包含医学图像，但也有头数据。头数据通常包括一般的病人和研究数据，但它还可以包含其他几十个自定义字段。如果你幸运的话，它也会包含诊断信息，你可以将其作为标签。
- en: DICOM data adds another step to the pipeline we discussed earlier because we
    now need to read the DICOM file, extract the header (and hopefully class/label
    data), and extract the underlying image. DICOM is not as easy to work with as
    JPEG or PNG, but it is not too difficult. It will require some extra packages.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: DICOM 数据为我们之前讨论的流程增加了一个步骤，因为现在我们需要读取 DICOM 文件，提取头信息（并希望包括类/标签数据），并提取底层图像。DICOM
    并不像 JPEG 或 PNG 那么容易使用，但也不算太复杂。它需要一些额外的包。
- en: Since we're writing almost everything in Python, let's use a `Python` library
    for DICOM processing. The most popular is **pydicom**, which is available at [https://github.com/darcymason/pydicom](https://github.com/darcymason/pydicom).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们几乎所有的工作都是用 Python 完成的，因此让我们使用一个用于 DICOM 处理的 `Python` 库。最流行的是 **pydicom**，可以在[https://github.com/darcymason/pydicom](https://github.com/darcymason/pydicom)找到。
- en: The documentation is available at [https://pydicom.readthedocs.io/en/stable/getting_started.html](https://pydicom.readthedocs.io/en/stable/getting_started.html).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 文档可以在[https://pydicom.readthedocs.io/en/stable/getting_started.html](https://pydicom.readthedocs.io/en/stable/getting_started.html)获取。
- en: It should be noted that the `pip` installation is currently broken, so it must
    be cloned from the source repository and installed via the setup script before
    it can be used.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 应注意，`pip` 安装当前存在问题，因此必须从源代码仓库克隆并通过设置脚本进行安装，才能使用。
- en: 'A quick excerpt from the documentation will help set the stage for understanding
    how to work with `DICOM` files:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 来自文档的一个简短摘录将有助于我们理解如何处理 `DICOM` 文件：
- en: '[PRE15]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This may seem a bit messy, but this is the type of interaction you should expect
    when working with medical data. Worse, each vendor often places the same data,
    even basic data, into slightly different tags. The typical industry practice is
    to simply look around! We do that by dumping the entire tag set as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来可能有些凌乱，但这正是你在处理医学数据时应该预期的交互方式。更糟糕的是，每个供应商通常将相同的数据，甚至是基本数据，放入略有不同的标签中。行业中的典型做法就是“到处看看！”我们通过以下方式转储整个标签集来做到这一点：
- en: '[PRE16]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Suppose we were seeking the diagnosis. We would look through several files of
    tags and try to see whether the diagnosis consistently shows up under tag `(0008,
    0018) Diagnosis`, and if so, we'd test our hypothesis by pulling out just this
    field from a large portion of our training set to see whether it is indeed consistently
    populated. If it is, we're ready for the next step. If not, we need to start again
    and look at other fields. Theoretically, the data provider, broker, or vendor
    can provide this information, but, practically speaking, it is rarely that simple.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们在寻找诊断信息。我们会查看几个标签文件，尝试看看诊断是否始终出现在标签`(0008, 0018) Diagnosis`下，如果是，我们通过从大部分训练集中提取这个字段来验证我们的假设，看它是否始终被填充。如果是的话，我们就可以进入下一步。如果不是，我们需要重新开始并查看其他字段。从理论上讲，数据提供者、经纪人或供应商可以提供这些信息，但从实际情况来看，这并不那么简单。
- en: 'The next step is to see the domain of values. This is very important because
    we want to see what our classes look like. Ideally, we will have a nice clean
    set of values such as {`Negative`, `Positive`}, but, in reality, we often get
    a long tail of dirty values. So, the typical approach is to loop through every
    single image and keep a count of each unique domain value encountered, as follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是查看值域。这一点非常重要，因为我们希望看到我们的类的表现。理想情况下，我们会得到一个干净的值集合，例如{`Negative`, `Positive`}，但实际上，我们通常会得到一条长尾的脏值。所以，典型的做法是遍历每一张图片，并统计每个遇到的唯一值域值，具体如下：
- en: '[PRE17]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: A very common finding at this point would be that 99 percent of domain values
    exist across a handful of domain values (such as *positive* and *negative*), and
    there is a long tail of 1% domain values that are dirty (such as *positive, but
    under review*, *@#Q#$%@#$%*, or *sent for re-read*). The easiest thing to do is
    throw out the long tail—just keep the good data. This is especially easy if there
    is plenty of training data.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，最常见的发现是，99%的领域值存在于少数几个领域值之间（如*正向*和*负向*），而剩下的1%的领域值是脏数据（如*正向，但待审阅*，*@#Q#$%@#$%*，或*已发送重新阅读*）。最简单的方法是丢弃这些长尾数据——只保留好的数据。如果有足够的训练数据，这尤其容易做到。
- en: 'OK, so we''ve extracted the class information, but we''ve still got to extract
    the actual image. We can do that as follows:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们已经提取了类信息，但我们仍然需要提取实际的图像。我们可以按照以下步骤进行：
- en: '[PRE18]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Unfortunately, this only gives us a raw matrix of pixel values. We still need
    to convert this into a readable format (ideally, JPEG or PNG.) We''ll achieve
    the next step as follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这仅仅给了我们一个原始的像素值矩阵。我们仍然需要将其转换为可读的格式（理想情况下是JPEG或PNG）。我们将按以下步骤进行下一步操作：
- en: '![](img/ec447807-fda1-4c53-a986-6834101d3663.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ec447807-fda1-4c53-a986-6834101d3663.png)'
- en: 'Next, we''ll scale the image to the bit length we desire and write the matrix
    to a file using another library geared to writing data in our destination format.
    In our case, we''ll use a PNG output format and write it using the `png` library.
    This means some extra imports:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将把图像缩放到我们需要的比特长度，并使用另一个库将矩阵写入文件，该库专门用于将数据写入目标格式。在我们的例子中，我们将使用PNG输出格式，并使用`png`库将其写入。这意味着需要额外的导入：
- en: '[PRE19]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We''ll export like this:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这样导出：
- en: '![](img/57b56d7d-07a9-4dfd-a369-80e391a0793e.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![](img/57b56d7d-07a9-4dfd-a369-80e391a0793e.png)'
- en: Skills Learned
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学到的技能
- en: 'You should have learned these skills in the chapter:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在本章中学到这些技能：
- en: Dealing with arcane and proprietary medical imaging formats
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理晦涩难懂且专有的医学影像格式
- en: Dealing with large image files, a common medical image hallmark
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理大型图像文件，这是医学图像的一个常见特征
- en: Extracting class data from medical files
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从医疗文件中提取类数据
- en: Extending our existing pipeline to deal with heterogeneous data inputs
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展我们现有的管道以处理异构数据输入
- en: Applying networks pre-trained with non-medical data
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用在非医学数据上预训练的网络
- en: Scaling training to accommodate new datasets.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展训练以适应新数据集。
- en: Summary
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we created a deep neural network for image classification problem
    in an enterprise-grade problem, medical diagnosis. Moreover, we also guided you
    through the process of reading DICOM digital medical image data for further researches.
    In the next chapter, we will build a production system that can self-improve by
    learning from users feedback.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们为医学诊断这一企业级问题创建了一个深度神经网络，用于图像分类问题。此外，我们还引导你完成了读取DICOM数字医学影像数据的过程，为进一步研究做准备。在下一章，我们将构建一个可以通过学习用户反馈自我改进的生产系统。
