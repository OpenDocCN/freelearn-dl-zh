- en: Chapter 2. Putting Data in Place – Supervised Learning for Predictive Analytics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章：将数据整理到位——用于预测分析的监督学习
- en: In this lesson, we will discuss supervised learning from the theoretical and
    practical perspective. In particular, we will revisit the linear regression model
    for regression analysis discussed in [Lesson 1](ch01.html "Chapter 1. From Data
    to Decisions – Getting Started with TensorFlow"), *From Data to Decisions – Getting
    Started with TensorFlow*, using a real dataset. Then we will see how to develop
    Titanic survival predictive models using **Logistic Regression** (**LR**), Random
    Forests, and **Support Vector Machines** (**SVMs**).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本课程中，我们将从理论和实践的角度讨论监督学习。特别是，我们将重新审视[第1章](ch01.html "第1章：从数据到决策——TensorFlow入门")中讨论的线性回归模型，通过使用真实数据集进行回归分析。然后，我们将看到如何使用**逻辑回归**（**LR**）、随机森林和**支持向量机**（**SVM**）来开发泰坦尼克号生存预测模型。
- en: 'In a nutshell, the following topics will be covered in this lesson:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，本课程将涵盖以下主题：
- en: Supervised learning for predictive analytics
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于预测分析的监督学习
- en: 'Linear regression for predictive analytics: revisited'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于预测分析的线性回归：重新审视
- en: Logistic regression for predictive analytics
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于预测分析的逻辑回归
- en: Random forests for predictive analytics
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于预测分析的随机森林
- en: SVMs for predictive analytics
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于预测分析的SVM
- en: A comparative analysis
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较分析
- en: Supervised Learning for Predictive Analytics
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于预测分析的监督学习
- en: 'Depending on the nature of the learning feedback available, the machine learning
    process is typically classified into three broad categories: supervised learning,
    unsupervised learning, and reinforcement learning—see figure 1\. A predictive
    model based on supervised learning algorithms can make predictions based on a
    labelled dataset that map inputs to outputs aligning with the real world.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 根据可用的学习反馈类型，机器学习过程通常被分为三大类：监督学习、无监督学习和强化学习——见图1。基于监督学习算法的预测模型可以根据标记数据集做出预测，该数据集将输入与现实世界中的输出相匹配。
- en: 'For example, a dataset for spam filtering usually contains spam messages as
    well as not-spam messages. Therefore, we could know which messages in the training
    set are spam and which are ham. Nevertheless, we might have the opportunity to
    use this information to train our model in order to classify new unseen messages:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，垃圾邮件过滤的数据集通常包含垃圾邮件和非垃圾邮件。因此，我们可以知道训练集中哪些消息是垃圾邮件，哪些是正常邮件。然而，我们可能有机会利用这些信息来训练我们的模型，以便对新的未见消息进行分类：
- en: '![Supervised Learning for Predictive Analytics](img/02_01.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![监督学习用于预测分析](img/02_01.jpg)'
- en: 'Figure 1: Machine learning tasks (containing a few algorithms only)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：机器学习任务（仅包含少数几个算法）
- en: 'The following figure shows the schematic diagram of supervised learning. After
    the algorithm has found the required patterns, those patterns can be used to make
    predictions for unlabeled test data:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了监督学习的示意图。当算法找到所需的模式后，这些模式可以用于对未标记的测试数据进行预测：
- en: '![Supervised Learning for Predictive Analytics](img/02_02.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![监督学习用于预测分析](img/02_02.jpg)'
- en: 'Figure 2: Supervised learning in action'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：监督学习的实际应用
- en: Examples include classification and regression for solving supervised learning
    problems so that predictive models can be built for predictive analytics based
    on them. We will provide several examples of supervised learning like linear regression,
    logistic regression, random forest, decision trees, Naive Bayes, multilayer perceptron,
    and so on.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 示例包括分类和回归，用于解决监督学习问题，从而可以基于它们建立预测模型进行预测分析。我们将提供几种监督学习的示例，如线性回归、逻辑回归、随机森林、决策树、朴素贝叶斯、多层感知机等。
- en: In this lesson, we will mainly focus on the supervised learning algorithms for
    predictive analytics. Let's start from the very simple linear regression algorithm.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本课程中，我们将主要关注用于预测分析的监督学习算法。让我们从非常简单的线性回归算法开始。
- en: Linear Regression – Revisited
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性回归——重新审视
- en: In [Lesson 1](ch01.html "Chapter 1. From Data to Decisions – Getting Started
    with TensorFlow"), *From Data to Decisions – Getting Started with TensorFlow*
    we have seen an example of linear regression. We have observed how to work TensorFlow
    on the randomly generated dataset, that is, fake data. We have seen that the regression
    is a type of supervised machine learning for predicting the continuous-valued
    output. However, running a linear regression on fake data is just like buying
    a new car and never driving it. This awesome machinery begs to manifest itself
    in the real world!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第一课](ch01.html "第一章 从数据到决策——TensorFlow 入门")《从数据到决策——TensorFlow 入门》中，我们看到了一个线性回归的例子。我们观察了如何在随机生成的数据集（即假数据）上使用
    TensorFlow。我们了解到，回归是一种监督学习，用于预测连续值输出。然而，在假数据上运行线性回归就像是买了一辆新车却从未开过它。这台令人惊叹的机器渴望在现实世界中发挥作用！
- en: 'Fortunately, many datasets are available online to test your new-found knowledge
    of regression:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，许多数据集可以在网上找到，用于测试你新学到的回归知识：
- en: 'The University of Massachusetts Amherst supplies small datasets of various
    types: [http://www.umass.edu/statdata/statdata/](http://www.umass.edu/statdata/statdata/)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马萨诸塞大学阿姆赫斯特分校提供了各种类型的小型数据集：[http://www.umass.edu/statdata/statdata/](http://www.umass.edu/statdata/statdata/)
- en: 'Kaggle contains all types of large-scale data for machine learning competitions:
    [https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaggle 包含各种大规模的机器学习竞赛数据集：[https://www.kaggle.com/datasets](https://www.kaggle.com/datasets)
- en: 'Data.gov is an open data initiative by the US government, which contains many
    interesting and practical datasets: [https://catalog.data.gov](https://catalog.data.gov)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Data.gov 是美国政府的一个开放数据计划，包含了许多有趣且实用的数据集：[https://catalog.data.gov](https://catalog.data.gov)
- en: Therefore, in this section, by defining a set of models, we will see how to
    reduce the search space of possible functions. Moreover, TensorFlow takes advantage
    of the differentiable property of the functions by running its efficient gradient
    descent optimizers to learn the parameters. To avoid overfitting our data, we
    regularize the cost function by penalizing larger valued parameters.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这一部分，通过定义一组模型，我们将看到如何减少可能函数的搜索空间。此外，TensorFlow 利用这些函数的可微分特性，运行高效的梯度下降优化器来学习参数。为了避免过拟合数据，我们通过对较大值的参数施加惩罚来正则化成本函数。
- en: The linear regression is shown in [Lesson 1](ch01.html "Chapter 1. From Data
    to Decisions – Getting Started with TensorFlow"), *From Data to Decision – Getting
    Started with TensorFlow*, shows some tensors that just contained a single scalar
    value, but you can, of course, perform computations on arrays of any shape. In
    TensorFlow, operations such as addition and multiplication take two inputs and
    produce an output. In contrast, constants and variables do not take any input.
    We will also see an example of how TensorFlow can manipulate 2D arrays to perform
    linear regression like operations.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归在[第一课](ch01.html "第一章 从数据到决策——TensorFlow 入门")《从数据到决策——TensorFlow 入门》中展示，其中有一些张量仅包含一个标量值，但你当然可以对任意形状的数组执行计算。在
    TensorFlow 中，诸如加法和乘法等操作需要两个输入，并生成一个输出。相反，常量和变量不需要任何输入。我们还将看到一个例子，展示 TensorFlow
    如何操作 2D 数组来执行类似线性回归的操作。
- en: Problem Statement
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题陈述
- en: Online movie ratings and recommendations have become a serious business around
    the world. For example, Hollywood generates about $10 billion at the U.S. box
    office each year. Websites like Rotten Tomatoes aggregates movie reviews into
    one overall rating and also reports poor opening weekends. Although a single movie
    critic or a single negative review can't make or break a film, thousands of reviews
    and critics do.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在线电影评分和推荐已成为全球重要的商业之一。例如，好莱坞每年在美国票房的收入约为 100 亿美元。像 Rotten Tomatoes 这样的电影网站将电影评论汇总成一个综合评分，并报告糟糕的首映周末。尽管单一的电影评论家或负面评论不能决定一部电影的成败，但成千上万的评论和评论家却能。
- en: Rotten Tomatoes, Metacritic, and IMDb have their own way of aggregating film
    reviews and distinct rating systems. On the other hand, Fandango, an NBCUniversal
    subsidiary uses a five-star rating system in which most of the movies get at least
    three stars, according to a FiveThirtyEight analysis.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Rotten Tomatoes、Metacritic 和 IMDb 有自己汇总电影评论和独特的评分系统。另一方面，Fandango，NBCUniversal
    的子公司，使用五颗星的评分系统，按照 FiveThirtyEight 的分析，大多数电影至少获得三颗星。
- en: 'An exploratory analysis of the dataset used by Fandango shows that out of 510
    films, 437 films got at least one review where, hilariously, 98% had a 3-star
    rating or higher and 75 percent had a 4-star rating or higher. This implies, that
    using Fandango''s standards it''s almost impossible for a movie to be a flop at
    the box office. Therefore, Fandango''s rating is biased and skewed:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 对 Fandango 使用的数据集进行的探索性分析显示，在 510 部电影中，437 部电影至少获得了一条评论，令人发笑的是，98% 的电影评分为 3
    星或更高，75% 的电影评分为 4 星或更高。这意味着，根据 Fandango 的标准，一部电影几乎不可能在票房上失败。因此，Fandango 的评分存在偏见和失真：
- en: '![Problem Statement](img/02_03.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![问题陈述](img/02_03.jpg)'
- en: 'Figure 3: Fandango''s lopsided ratings curve'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：Fandango 评分曲线的失衡现象
- en: '(Source: [https://fivethirtyeight.com/features/fandango-movies-ratings/](https://fivethirtyeight.com/features/fandango-movies-ratings/))'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: (来源：[https://fivethirtyeight.com/features/fandango-movies-ratings/](https://fivethirtyeight.com/features/fandango-movies-ratings/))
- en: Since the ratings from Fandango are unreliable, we will instead predict our
    own ratings based on IMDb ratings. More specifically, this is a multivariate regression
    problem, since our predictive model will use multiple features to make the rating
    prediction having many predictors.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Fandango 的评分不可靠，我们将根据 IMDb 评分来预测我们自己的评分。更具体地说，这是一个多元回归问题，因为我们的预测模型将使用多个特征来进行评分预测，拥有多个预测变量。
- en: Fortunately, the data is small enough to fit in memory, so plain batch learning
    should do just fine. Considering these factors and need, we will see that linear
    regression will meet our requirements. However, for more robust regression, you
    can still use deep neural network based regression techniques such as deep belief
    networks Regressor.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，数据集足够小，可以适应内存，因此普通的批量学习就能很好地完成任务。考虑到这些因素和需求，我们会发现线性回归能够满足我们的要求。然而，对于更强大的回归分析，你仍然可以使用基于深度神经网络的回归技术，比如深度置信网络回归器（Deep
    Belief Networks Regressor）。
- en: Using Linear Regression for Movie Rating Prediction
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用线性回归进行电影评分预测
- en: Now, the first task is downloading the Fandango's rating dataset from GitHub
    at [https://github.com/fivethirtyeight/data/tree/master/fandango](https://github.com/fivethirtyeight/data/tree/master/fandango).
    It contains every film that has a Rotten Tomatoes rating, an RT user rating, a
    Metacritic score, a Metacritic user score, IMDb score, and at least 30 fan reviews
    on Fandango.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，第一步是从 GitHub 下载 Fandango 的评分数据集，网址为 [https://github.com/fivethirtyeight/data/tree/master/fandango](https://github.com/fivethirtyeight/data/tree/master/fandango)。该数据集包含了所有拥有
    Rotten Tomatoes 评分、RT 用户评分、Metacritic 评分、Metacritic 用户评分、IMDb 评分，且在 Fandango 上至少有
    30 条影迷评论的电影。
- en: 'Table 1: Description of the columns in fandango_score_comparison.csv'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：fandango_score_comparison.csv 中各列的说明
- en: 'The dataset has 22 columns that can be described as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集有 22 列，具体说明如下：
- en: '| Column | Definition |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 列名 | 定义 |'
- en: '| --- | --- |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `FILM` | Name of the film. |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| `FILM` | 电影名称。 |'
- en: '| `RottenTomatoes` | Corresponding Tomatometer score for the film by Rotten
    Tomatoes. |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| `RottenTomatoes` | Rotten Tomatoes 为电影提供的对应番茄评分（Tomatometer score）。 |'
- en: '| `RottenTomatoes_User` | Rotten Tomatoes user score for the film. |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| `RottenTomatoes_User` | Rotten Tomatoes 用户评分。 |'
- en: '| `Metacritic` | Metacritic critic score for the film. |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| `Metacritic` | Metacritic 影评人评分。 |'
- en: '| `Metacritic_User` | Metacritic user score for the film. |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| `Metacritic_User` | Metacritic 用户评分。 |'
- en: '| `IMDB` | IMDb user score for the film. |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| `IMDB` | IMDb 用户评分。 |'
- en: '| `Fandango_Stars` | A number of stars the film had on its Fandango movie page.
    |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| `Fandango_Stars` | 电影在 Fandango 电影页面上的星级评分。 |'
- en: '| `Fandango_Ratingvalue` | The Fandango rating value for the film, as pulled
    from the HTML of each page. This is the actual average score the movie obtained.
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| `Fandango_Ratingvalue` | 从每个页面的 HTML 中提取出的 Fandango 评分值。即电影实际获得的平均分数。 |'
- en: '| `RT_norm` | Tomatometer score for the film. It is normalized to a 0 to 5
    point system. |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| `RT_norm` | 电影的番茄评分（Tomatometer score）。它被标准化为 0 到 5 分制。 |'
- en: '| `RT_user_norm` | Rotten Tomatoes user score for the film. It is normalized
    to a 0 to 5 point system. |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| `RT_user_norm` | Rotten Tomatoes 用户评分，已标准化为 0 到 5 分制。 |'
- en: '| `Metacritic_norm` | The Metacritic critic scores for the film. It is normalized
    to a 0 to 5 point system. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| `Metacritic_norm` | 电影的 Metacritic 影评人评分，已标准化为 0 到 5 分制。 |'
- en: '| `Metacritic_user_nom` | Metacritic user score for the film, normalized to
    a0 to 5 point system. |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| `Metacritic_user_nom` | Metacritic 用户评分，已标准化为 0 到 5 分制。 |'
- en: '| `IMDB_norm` | IMDb user score for the film which is normalized to a 0 to
    5 point system. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| `IMDB_norm` | IMDb 用户评分，已标准化为 0 到 5 分制。 |'
- en: '| `RT_norm_round` | Rotten Tomatoes Tomatometer score for the film which is
    normalized to a 0 to 5 point system and rounded to the nearest half-star. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| `RT_norm_round` | 电影的烂番茄Tomatometer评分，已规范化为0到5分的系统，并四舍五入至最接近的半颗星。 |'
- en: '| `RT_user_norm_round` | Rotten Tomatoes user score for the film, normalized
    to a 0 to 5 point system and rounded to the nearest half-star. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| `RT_user_norm_round` | 电影的烂番茄用户评分，已规范化为0到5分的系统，并四舍五入至最接近的半颗星。 |'
- en: '| `Metacritic_norm_round` | Metacritic critic score for the film, normalized
    to a 0 to 5 point system and rounded to the nearest half-star. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| `Metacritic_norm_round` | 电影的Metacritic评论员评分，已规范化为0到5分的系统，并四舍五入至最接近的半颗星。
    |'
- en: '| `Metacritic_user_norm_round` | Metacritic user score for the film, normalized
    to a 0 to 5 point system and rounded to the nearest half-star. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| `Metacritic_user_norm_round` | 电影的Metacritic用户评分，已规范化为0到5分的系统，并四舍五入至最接近的半颗星。
    |'
- en: '| `IMDB_norm_round` | IMDb user score for the film, normalized to a 0 to 5
    point system and rounded to the nearest half-star. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| `IMDB_norm_round` | 电影的IMDb用户评分，已规范化为0到5分的系统，并四舍五入至最接近的半颗星。 |'
- en: '| `Metacritic_user_vote_count` | A number of user votes the film had on Metacritic.
    |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| `Metacritic_user_vote_count` | 电影在Metacritic上的用户投票数量。 |'
- en: '| `IMDB_user_vote_count` | A number of user votes the film had on IMDb. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| `IMDB_user_vote_count` | 电影在IMDb上的用户投票数量。 |'
- en: '| `Fandango_votes` | A number of user votes the film had on Fandango. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| `Fandango_votes` | 电影在Fandango上的用户投票数量。 |'
- en: '| `Fandango_Difference` | Difference between the presented `Fandango_Stars`
    and the actual `Fandango_Ratingvalue`. |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| `Fandango_Difference` | 显示的`Fandango_Stars`与实际`Fandango_Ratingvalue`之间的差异。
    |'
- en: 'We have already seen that a typical linear regression problem using TensorFlow
    has the following workflow that updates the parameters to minimize the given cost
    function of Fandango''s lopsided rating curve:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，使用TensorFlow的典型线性回归问题具有以下工作流程，它更新参数以最小化Fandango的偏斜评分曲线的给定成本函数：
- en: '![Using Linear Regression for Movie Rating Prediction](img/02_04.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![使用线性回归进行电影评分预测](img/02_04.jpg)'
- en: 'Figure 4: The learning algorithm using linear regression in TensorFlow'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：使用TensorFlow进行线性回归的学习算法
- en: 'Now, let''s try to follow the preceding figure and reproduce the same for the
    linear regression:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试遵循前面的图示，并重新制作相同的线性回归：
- en: 'Import the required libraries:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库：
- en: '[PRE0]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Read the dataset and create a Panda DataFrame:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取数据集并创建一个Panda DataFrame：
- en: '[PRE1]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The output is as follows:'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Using Linear Regression for Movie Rating Prediction](img/02_05.jpg)'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用线性回归进行电影评分预测](img/02_05.jpg)'
- en: 'Figure 5: A snap of the dataset showing a typo in the Metacritic_user_nom'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5：展示Metacritic_user_nom中的错别字的数据集快照
- en: 'So, if you look at the preceding DataFrame carefully, there is a typo that
    could cause a disaster. From our intuition, it is clear that `Metacritic_user_nom`
    should have actually been `Metacritic_user_norm`. Let''s rename it to avoid further
    confusion:'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，如果你仔细查看前面的DataFrame，会发现一个可能导致灾难的错别字。从直觉来看，很明显`Metacritic_user_nom`应该是`Metacritic_user_norm`。我们将其重命名，以避免进一步的混淆：
- en: '[PRE2]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Moreover, according to a statistical analysis at [https://fivethirtyeight.com/features/fandango-movies-ratings](https://fivethirtyeight.com/features/fandango-movies-ratings)/,
    all the variables don''t contribute equally; the following columns have more importance
    in ranking the movies:'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，根据[https://fivethirtyeight.com/features/fandango-movies-ratings](https://fivethirtyeight.com/features/fandango-movies-ratings)/上的统计分析，所有变量并非等同贡献；以下列出的列对电影排名的影响更大：
- en: '[PRE3]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now we can check the correlation coefficients between variables before build
    the LR model. First, let''s create a ranking list for that:'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们可以在构建LR模型之前检查变量之间的相关系数。首先，让我们为此创建一个排名列表：
- en: '[PRE4]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following function computes the `Pearson` correlation coefficients and
    builds a full correlation matrix:'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下函数计算`Pearson`相关系数并构建完整的相关矩阵：
- en: '[PRE5]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let''s call the preceding method to plot the matrix as follows:'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以调用前述方法来绘制矩阵，如下所示：
- en: '[PRE6]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Pearson correlation coefficients**: A measure of the strength of the linear
    relationship between two variables. If the relationship between the variables
    is not linear, then the correlation coefficient cannot accurately and adequately
    represent the strength of the relationship between those two variables. It is
    often represented as "ρ" when measured on population and "r" when measured on
    a sample. Statistically, the range is -1 to 1, where -1 indicates a perfect negative
    linear relationship, an r of 0 indicates no linear relationship, and an r of 1
    indicates a perfect positive linear relationship between variables.'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**皮尔逊相关系数**：衡量两个变量之间线性关系强度的指标。如果变量之间的关系不是线性的，则相关系数不能准确而充分地表示这两个变量之间关系的强度。通常，当对总体进行测量时，它用“ρ”表示，而对样本进行测量时用“r”表示。从统计学角度看，相关系数的范围是-1到1，其中-1表示完全负线性关系，r为0表示没有线性关系，r为1表示完全正线性关系。'
- en: 'The following correlation matrix shows correlation between considered features
    using the Pearson correlation coefficients:'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下相关矩阵显示了使用皮尔逊相关系数的特征之间的相关性：
- en: '![Using Linear Regression for Movie Rating Prediction](img/02_06.jpg)'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用线性回归进行电影评分预测](img/02_06.jpg)'
- en: 'Figure 6: The correlation matrix on the ranking list movies'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6：排名电影的相关矩阵
- en: 'So, the correlation between Fandango and Metacritic is still positive. Now,
    let''s do another study by considering only the movies for which RT has provided
    at least a 4-star rating:'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所以，Fandango与Metacritic之间的相关性依然是正相关。接下来，让我们通过只考虑RT至少给出4星评分的电影来进行另一个研究：
- en: '[PRE7]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output is the correlation matrix on the ranked movies and RT movies having
    ratings of at least 4 showing a correlation between considered features using
    the Pearson correlation coefficients:'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出的是排名电影和RT评分至少为4的电影的相关矩阵，显示了使用皮尔逊相关系数的特征之间的相关性：
- en: '![Using Linear Regression for Movie Rating Prediction](img/02_07.jpg)'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用线性回归进行电影评分预测](img/02_07.jpg)'
- en: 'Figure 7: The correlation matrix on the ranked movies and RT movies having
    ratings at least 4'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7：排名电影和RT至少评分为4的电影的相关矩阵
- en: This time, we have obtained anticorrelation (that is, negative correlation)
    between Fandango and Metacritic, with the correlation coefficient-0.23\. This
    means that the correlation of Metacritic in terms of Fandango is significantly
    biased toward high ratings.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这次，我们发现Fandango与Metacritic之间存在反相关（即负相关），相关系数为-0.23。这意味着Metacritic在Fandango的评分上存在显著的偏向高分。
- en: Therefore, we can train our model without considering Fandango's rating, but
    before that let's build the LR model using this first. Later on, we will decide
    which option would produce a better result eventually.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，我们可以在不考虑Fandango评分的情况下训练我们的模型，但在此之前，我们先使用这个构建LR模型。之后我们将决定哪个选项最终会产生更好的结果。
- en: Preparing the training and test sets.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备训练集和测试集。
- en: 'Let''s create a feature matrix `X` by selecting two DataFrame columns:'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过选择两个数据框列来创建一个特征矩阵`X`：
- en: '[PRE8]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here, I have used only the selected column as features and now we need to create
    a response vector `y`:'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我只使用了选定的列作为特征，现在我们需要创建一个响应向量`y`：
- en: '[PRE9]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We are assuming that the IMDB is the most reliable and the baseline source of
    ratings. Our ultimate target is to predict the rating of each movie and compare
    the predicted ratings with the response column `IMDB_norm`.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们假设IMDB是最可靠的评分基准来源。我们的最终目标是预测每部电影的评分，并将预测评分与响应列`IMDB_norm`进行比较。
- en: 'Now that we have the features and the response columns, it''s time to split
    data into training and testing sets:'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们已经有了特征列和响应列，接下来是将数据划分为训练集和测试集：
- en: '[PRE10]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If you want to change the `random_state`, it helps you generate pseudo-random
    numbers for a random sampling value to obtain differentfinal results.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你想更改`random_state`，它将帮助你生成伪随机数，用于随机抽样，从而得到不同的最终结果。
- en: Note
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Random state**: As the name sounds can be used for initializing the internal
    random number generator, which will decide the splitting of data into train and
    test indices. This also signifies that every time you run it without specifying
    `random_state`, you will get a different result, this is expected behavior. So,
    we can have the following three options:'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**随机状态**：顾名思义，它可用于初始化内部随机数生成器，从而决定数据划分为训练集和测试集的方式。这也意味着每次运行时，如果不指定`random_state`，你将得到不同的结果，这是预期的行为。因此，我们可以有以下三种选择：'
- en: If `random_state` is None (or `np.random`), a randomly-initialized `RandomState`
    object is returned
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`random_state`为None（或`np.random`），将返回一个随机初始化的`RandomState`对象。
- en: If `random_state` is an integer, it is used to seed a new `RandomState` object
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`random_state`是一个整数，它将用于初始化一个新的`RandomState`对象。
- en: If `random_state` is a `RandomState` object, it is passed through
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果`random_state`是一个`RandomState`对象，它会被传递进去。
- en: 'Now, we need to have the dimension of the dataset to be passed through the
    tensors:'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们需要知道数据集的维度，以便将其传递给张量：
- en: '[PRE11]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We need to include an extra dimension for independent coefficient:'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们需要为独立系数添加一个额外的维度：
- en: '[PRE12]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'And so we need to create an extra column for the independent coefficient in
    the training set and test feature set as well:'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，我们还需要为训练集和测试特征集中的独立系数创建一个额外的列：
- en: '[PRE13]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'So far, we have used and utilized the panda DataFrames but converting it into
    tensors is troublesome so instead let''s convert them into a NumPy array:'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经使用并利用了Pandas DataFrame，但将其转换为张量很麻烦，因此我们改为将它们转换为NumPy数组：
- en: '[PRE14]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Creating a place holder for TensorFlow.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为TensorFlow创建占位符。
- en: 'Now that we have all the training and test sets, before initializing these
    variables, we have to create the place holder for TensorFlow to feed the training
    sets across the tensors:'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们已经有了所有的训练集和测试集，在初始化这些变量之前，我们需要为TensorFlow创建占位符，以便通过张量传递训练集：
- en: '[PRE15]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s add some bias to differing from the value in the case where both types
    are quantized as follows:'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们添加一些偏差，以区分在两种类型量化的情况下的值，如下所示：
- en: '[PRE16]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Creating an optimizer.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建优化器。
- en: 'Let''s create an optimizer for the objective function:'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们为目标函数创建一个优化器：
- en: '[PRE17]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Initializing global variables:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化全局变量：
- en: '[PRE18]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Training the LR model.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练LR模型。
- en: 'Here we are iterating the training 50,000 times and tracking several parameters,
    such as means square error that signifies how good the training is; we are keeping
    the cost history for future visualization, and so on:'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们将训练迭代50,000次，并跟踪多个参数，例如均方误差，它表示训练的好坏；我们保持成本历史记录，以便未来可视化，等等：
- en: '[PRE19]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Finally, we evaluate the `mse` to get the scalar value out of the training
    evaluation on the test set. Now, let''s compute the `mse` and `rmse` values, as
    follows:'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，我们评估`mse`，以便从测试集上的训练评估中得到标量值。现在，让我们计算`mse`和`rmse`值，如下所示：
- en: '[PRE20]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You can also change the feature column, as follows:'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以按如下方式更改特征列：
- en: '[PRE21]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now that we are not considering the Fandango''s stars, I experienced the following
    result of `mse` and `rmse` respectively:'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在我们不考虑Fandango的评分，我得到了`mse`和`rmse`的以下结果：
- en: '[PRE22]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Observing the training cost throughout iterations:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 观察整个迭代过程中的训练成本：
- en: '[PRE23]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The output is as follows:'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Using Linear Regression for Movie Rating Prediction](img/02_08.jpg)'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用线性回归进行电影评分预测](img/02_08.jpg)'
- en: 'Figure 8: The training and training cost become saturated after 10000 iterations'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图8：训练和训练成本在10000次迭代后变得饱和
- en: The preceding graph shows that the training cost becomes saturated after 10,000
    iterations. This also means that, even if you iterate the model more than 10,000
    times, the cost is not going to experience a significant decrease.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述图表显示训练成本在10,000次迭代后变得饱和。这也意味着，即使你将模型迭代超过10,000次，成本也不会出现显著下降。
- en: 'Evaluating the model:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型：
- en: '[PRE24]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following shows the predicted versus actual rating using LR:'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下显示了使用LR模型的预测与实际评分：
- en: '[PRE25]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can see that the prediction is a continuous value. Now it''s time to see
    how well the LR model generalizes and fits to the regression line:'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以看到，预测是一个连续的值。现在是时候看看LR模型如何推广并拟合回归线：
- en: '[PRE26]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The output is as follows:'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Using Linear Regression for Movie Rating Prediction](img/02_09.jpg)'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用线性回归进行电影评分预测](img/02_09.jpg)'
- en: 'Figure 9: Prediction made by the LR model'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9：LR模型的预测结果
- en: The graph does not tell us that the prediction made by the LR model is good
    or bad. But we can still improve the performance of such models using layer architectures
    such as deep neural networks.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图表没有告诉我们LR模型的预测是好是坏。但我们仍然可以通过使用像深度神经网络这样的层次结构来提高模型的性能。
- en: The next example is about applying other supervised learning algorithms such
    as logistic regression, support vector machines, and random forest for predictive
    analytics.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下一个例子是关于应用其他监督学习算法，如逻辑回归、支持向量机和随机森林进行预测分析。
- en: From Disaster to Decision – Titanic Example Revisited
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从灾难到决策——重新审视泰坦尼克号示例
- en: In [Lesson 1](ch01.html "Chapter 1. From Data to Decisions – Getting Started
    with TensorFlow"), *From Data to Decisions – Getting Started with TensorFlow*,
    we have seen a minimal data analysis of the Titanic dataset. Now it's our turn
    to do some analytics on top of the data. Let's look at what kinds of people survived
    the disaster.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1课](ch01.html "第1章 从数据到决策 - 使用TensorFlow入门")中，*从数据到决策 - 使用TensorFlow入门*，我们对泰坦尼克号数据集进行了最基本的数据分析。现在轮到我们基于数据做一些分析了。让我们来看看哪些人群在这场灾难中幸存了下来。
- en: Since we have enough data, but how could we do the predictive modeling so that
    we can draw some fairly straightforward conclusions from this data? For example,
    being a woman, being in first class, and being a child were all factors that could
    boost a passengers chances of survival during this disaster.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们有足够的数据，如何进行预测建模，以便从这些数据中得出一些相对直接的结论呢？例如，女性、头等舱乘客和儿童都是提高乘客在灾难中生存几率的因素。
- en: 'Using the brute-force approach such as if-else statements with some sort of
    weighted scoring system, you could write a program to predict whether a given
    passenger would survive the disaster. However, writing such a program in Python
    does not make much sense. Naturally, it would be very tedious to write, difficult
    to generalize, and would require extensive fine-tuning for each variable and samples
    (that is, each passenger):'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 使用像if-else语句这样简单的强力法（结合某种加权评分系统），你可以编写一个程序来预测一个给定的乘客是否会在灾难中幸存。然而，用Python编写这样一个程序没有太多意义。显然，这样的程序会非常繁琐，难以推广，并且需要对每个变量和样本（即每个乘客）进行广泛的微调：
- en: '![From Disaster to Decision – Titanic Example Revisited](img/02_10.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![从灾难到决策 - 泰坦尼克号示例重访](img/02_10.jpg)'
- en: 'Figure 10: A regression algorithm is meant to produce continuous output'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：回归算法的目的是产生连续的输出
- en: 'At this point, you might have confusion in your mind about what the basic difference
    between a classification and a regression problem is. Well, a regression algorithm
    is meant to produce continuous output. The input is allowed to be either discrete
    or continuous. In contrast, a classification algorithm is meant to produce discrete
    output from an input from a set of discrete or continuous values. This distinction
    is important to know because discrete-valued outputs are handled better by classification,
    which will be discussed in upcoming sections:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，你可能会对分类问题和回归问题之间的基本区别感到困惑。那么，回归算法的目的是产生连续的输出。输入可以是离散的，也可以是连续的。相比之下，分类算法的目的是从一组离散或连续值的输入中产生离散的输出。这一区别很重要，因为离散值的输出更适合由分类算法处理，接下来的章节将讨论这一点：
- en: '![From Disaster to Decision – Titanic Example Revisited](img/02_11.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![从灾难到决策 - 泰坦尼克号示例重访](img/02_11.jpg)'
- en: 'Figure 11: A classification algorithm is meant to produce discrete output'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：分类算法的目的是产生离散的输出
- en: In this section, we will see how we could develop several predictive models
    for Titanic survival prediction and do some analytics using them. In particular,
    we will discuss logistic regression, random forest, and linear SVM. We start with
    logistic regression. Then we go with SVM since the number of features is not that
    large. Finally, we will see how we could improve the performance using Random
    Forests. However, before diving in too deeply, a short exploratory analysis of
    the dataset is required.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到如何为泰坦尼克号生存预测开发几种预测模型，并使用它们进行一些分析。特别地，我们将讨论逻辑回归、随机森林和线性支持向量机（SVM）。我们从逻辑回归开始。然后使用SVM，因为特征数量并不多。最后，我们将看看如何利用随机森林提高性能。然而，在深入之前，我们需要对数据集进行一个简短的探索性分析。
- en: An Exploratory Analysis of the Titanic Dataset
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 泰坦尼克号数据集的探索性分析
- en: 'We will see how the variables contribute to survival. At first, we need to
    import the required packages:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到各个变量如何对生存率产生影响。首先，我们需要导入所需的包：
- en: '[PRE27]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now, let''s load the data and check what the features available to us are:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们加载数据并检查可以使用的特征：
- en: '[PRE28]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'So, the training dataset has `12` columns and `891` rows altogether. Also,
    the `Age`, `Cabin`, and `Embarked` columns have null or missing values. We will
    take care of the null values in the feature engineering section, but for the time
    being, let''s see how many have survived:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，训练数据集一共有`12`列和`891`行。此外，`Age`、`Cabin`和`Embarked`列存在空值或缺失值。我们将在特征工程部分处理这些空值，但目前，让我们看看有多少数据是有效的：
- en: '[PRE29]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: How many have survived?
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 有多少人幸存了下来？
- en: '[PRE30]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'So, approximately 61% died and only 39% of passengers managed to survive as
    shown in the following figure:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，约61%的乘客死亡，只有39%的乘客成功生还，如下图所示：
- en: '![An Exploratory Analysis of the Titanic Dataset](img/02_12.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![泰坦尼克号数据集的探索性分析](img/02_12.jpg)'
- en: 'Figure 12: Survived versus dead from the Titanic training set'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：泰坦尼克号训练集中生还者与死亡者的对比
- en: 'Now, what is the relationship between the class and the rate of survival? At
    first we should see the counts for each class:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，乘客的舱位与生存率之间有什么关系呢？首先我们应该查看每个舱位的计数：
- en: '[PRE31]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'As you may remember from the movie (that is, Titanic 1997), people from higher
    classes had better chances of surviving. So, you may assume that the title could
    be an important factor in survival, too. Another funny thing is that people with
    longer names have a higher probability of survival. This happens due to most of
    the people with longer names being married ladies whose husband or family members
    probably helped them to survive:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能记得的那样（即电影《泰坦尼克号》1997年版），来自较高阶层的人有更好的生还机会。所以，你可能会认为，乘客的头衔也可能是生还的重要因素。另一个有趣的现象是，名字较长的人生还的几率更高。这是因为大多数名字较长的人是已婚女士，可能得到了丈夫或家人帮助，从而增加了生还机会：
- en: '[PRE32]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Women and children had a higher chance to survive, since they are the first
    to evacuate the shipwreck:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 妇女和儿童的生还几率更高，因为他们是最先撤离船难的乘客：
- en: '[PRE33]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Cabin has the most nulls (almost 700), but we can still extract information
    from it, like the first letter of each cabin. Therefore, we can see that most
    of the cabin letters are associated with survival rate:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 舱位字段包含最多的空值（近700个），但我们仍然可以从中提取信息，比如每个舱位的首字母。因此，我们可以看到大多数舱位字母与生存率相关：
- en: '[PRE34]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Finally, it also seems that people who embarked at Cherbourg had a 20% higher
    survival rate than those embarked at other embarking locations. This is very likely
    due to the high percentage of upper-class passengers from that location:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，看起来在谢尔堡登船的人生还率比其他登船地点高出20%。这很可能是因为那个地方的上层阶级乘客比例较高：
- en: '[PRE35]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Graphically, the preceding result can be seen as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 从图形上看，前面的结果可以如下所示：
- en: '![An Exploratory Analysis of the Titanic Dataset](img/02_13.jpg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![泰坦尼克号数据集的探索性分析](img/02_13.jpg)'
- en: 'Figure 13: Survived by embarked'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13：按登船情况分组的生还者
- en: Thus, there were several important factors to people's survival. This means
    we need to consider these facts while developing our predictive models.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有几个重要因素影响了人们的生存。这意味着我们在开发预测模型时需要考虑这些因素。
- en: We will train several binary classifiers since this is a binary classification
    problem having two predictors, that is, 0 and 1 using the training set and will
    use the test set for making survival predictions.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将训练几个二分类器，因为这是一个二分类问题，预测值为0或1，使用训练集进行训练，并用测试集进行生存预测。
- en: But, before we even do that, let's do some feature engineering since you have
    seen that there are some missing or null values. We will either impute them or
    drop the entry from the training and test set. Moreover, we cannot use our datasets
    directly, but need to prepare them such that they could feed our machine learning
    models.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，在我们进行这一步之前，让我们先做一些特征工程，因为你已经看到有些数据缺失或为空。我们将通过填充这些空值或删除这些记录来处理训练集和测试集中的缺失值。此外，我们不能直接使用这些数据集，而需要对其进行处理，使其能够适应我们的机器学习模型。
- en: Feature Engineering
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程
- en: 'Since we are considering the length of the passenger''s name as an important
    feature, it would be better to remove the name itself and compute the corresponding
    length and also we extract only the title:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将乘客姓名的长度视为一个重要特征，最好将姓名本身去除，计算其对应的长度，并且提取出头衔：
- en: 'def create_name_feat(train, test):'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 'def create_name_feat(train, test):'
- en: '[PRE36]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'As there are 177 null values for Age, and those ones have a 10% lower survival
    rate than the non-nulls. Therefore, before imputing values for the nulls, we are
    including an Age_null flag, just to make sure we can account for this characteristic
    of the data:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 由于年龄字段有177个空值，而这些空值的生还率比非空值低10%。因此，在填充空值之前，我们将添加一个Age_null标志，以确保我们能够考虑数据的这一特征：
- en: '[PRE37]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We are imputing the null age values with the mean of that column. This will
    add some extra bias in the dataset. But, for the betterment of our predictive
    model, we will have to sacrifice something.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过用该列的平均值填充空缺的年龄数据。这样会在数据集中加入一些额外的偏差。但为了提高我们的预测模型，我们不得不做出一些牺牲。
- en: 'Then we combine the `SibSp` and `Parch` columns to create get family size and
    break it into three levels:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将`SibSp`和`Parch`列合并，创建家庭规模，并将其分为三个级别：
- en: '[PRE38]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We also need to extract the first letter of the `Cabin` column:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要提取`Cabin`列的第一个字母：
- en: '[PRE40]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Fill the null values in the `Embarked` column with the most commonly occurring
    value, which is `''S''`:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 用最常见的值`'S'`填充`Embarked`列中的空值：
- en: '[PRE41]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We now need to convert our categorical columns. So far, we have considered
    it important for the predictive models that we will be creating to have numerical
    values for string variables. The `dummies()` function below does a one-hot encoding
    to the string variables:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要转换我们的分类列。到目前为止，我们认为对我们将要创建的预测模型来说，字符串变量需要转换为数值。下面的`dummies()`函数对字符串变量进行一热编码：
- en: '[PRE42]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We have the numerical features, finally, we need to create a separate column
    for the predicted values or targets:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有了数值特征，最后，我们需要为预测值或目标创建一个单独的列：
- en: '[PRE43]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We have seen the data and its characteristics and done some feature engineering
    to construct the best features for the linear models. The next task is to build
    the predictive models and make a prediction on the test set. Let's start with
    the logistic regression.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看过数据及其特征，并进行了特征工程，构建了适合线性模型的最佳特征。接下来的任务是构建预测模型并在测试集上进行预测。让我们从逻辑回归开始。
- en: Logistic Regression for Survival Prediction
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生存预测的逻辑回归
- en: 'Logistic regression is one of the most widely used classifiers to predict a
    binary response. It is a linear machine learning method The `loss` function in
    the formulation given by the logistic loss:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归是最广泛使用的二元响应预测分类器之一。它是一种线性机器学习方法，`loss`函数由逻辑损失公式给出：
- en: '![Logistic Regression for Survival Prediction](img/02_14.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![Logistic Regression for Survival Prediction](img/02_14.jpg)'
- en: 'For the logistic regression model, the loss function is the logistic loss.
    For a binary classification problem, the algorithm outputs a binary logistic regression
    model such that, for a given new data point, denoted by **x**, the model makes
    predictions by applying the logistic function:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 对于逻辑回归模型，损失函数是逻辑损失。对于二元分类问题，该算法输出一个二元逻辑回归模型，给定一个新的数据点，记为**x**，模型通过应用逻辑函数来进行预测：
- en: '![Logistic Regression for Survival Prediction](img/02_15.jpg)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![Logistic Regression for Survival Prediction](img/02_15.jpg)'
- en: In the preceding equation, ![Logistic Regression for Survival Prediction](img/02_21.jpg)
    **and** if ![Logistic Regression for Survival Prediction](img/02_22.jpg), the
    outcome is positive; otherwise, it is negative. Note that the raw output of the
    logistic regression model, **f (z)**, has a probabilistic interpretation.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的方程中，![Logistic Regression for Survival Prediction](img/02_21.jpg) **并且**如果![Logistic
    Regression for Survival Prediction](img/02_22.jpg)，结果为正；否则，结果为负。注意，逻辑回归模型的原始输出**f
    (z)**具有概率解释。
- en: Well, if you now compare logistic regression with its predecessor linear regression,
    the former provides you with a higher accuracy of the classification result. Moreover,
    it is a flexible way to regularize a model for custom adjustment and overall the
    model responses are measures of probability. And, most importantly, whereas linear
    regression can predict only continuous values, logistic regression can be generalized
    enough to make it predict discrete values. From now on, we will often be using
    the TensorFlow contrib API. So let's have a quick look at it.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，如果现在将逻辑回归与其前身线性回归进行比较，前者提供了更高的分类准确率。此外，它是一种灵活的方式来对模型进行正则化，以便进行自定义调整，并且总的来说，模型的响应是概率的度量。最重要的是，尽管线性回归只能预测连续值，但逻辑回归可以广泛地推广到预测离散值。从现在起，我们将经常使用TensorFlow
    contrib API。那么，让我们快速了解一下它。
- en: Using TensorFlow Contrib
  id: totrans-219
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 TensorFlow Contrib
- en: 'The contrib is a high level API for learning with TensorFlow. It supports the
    following Estimators:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: contrib是一个用于TensorFlow学习的高级API。它支持以下估算器：
- en: '`tf.contrib.learn.BaseEstimator`'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.BaseEstimator`'
- en: '`tf.contrib.learn.Estimator`'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.Estimator`'
- en: '`tf.contrib.learn.Trainable`'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.Trainable`'
- en: '`tf.contrib.learn.Evaluable`'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.Evaluable`'
- en: '`tf.contrib.learn.KMeansClustering`'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.KMeansClustering`'
- en: '`tf.contrib.learn.ModeKeys`'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.ModeKeys`'
- en: '`tf.contrib.learn.ModelFnOps`'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.ModelFnOps`'
- en: '`tf.contrib.learn.MetricSpec`'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.MetricSpec`'
- en: '`tf.contrib.learn.PredictionKey`'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.PredictionKey`'
- en: '`tf.contrib.learn.DNNClassifier`'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.DNNClassifier`'
- en: '`tf.contrib.learn.DNNRegressor`'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.DNNRegressor`'
- en: '`tf.contrib.learn.DNNLinearCombinedRegressor`'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.DNNLinearCombinedRegressor`'
- en: '`tf.contrib.learn.DNNLinearCombinedClassifier`'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.DNNLinearCombinedClassifier`'
- en: '`tf.contrib.learn.LinearClassifier`'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.LinearClassifier`'
- en: '`tf.contrib.learn.LinearRegressor`'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.LinearRegressor`'
- en: '`tf.contrib.learn.LogisticRegressor`'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn.LogisticRegressor`'
- en: 'Thus, without developing the logistic regression, from scratch, we will use
    the estimator from the TensorFlow contrib package. When we are creating our own
    estimator from scratch, the constructor still accepts two high-level parameters
    for model configuration, `model_fn` and `params`:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们无需从头开发逻辑回归模型，而是使用 TensorFlow contrib 包中的估计器。当我们从头创建自己的估计器时，构造函数仍然接受两个高层次的参数来配置模型：`model_fn`
    和 `params`：
- en: '[PRE44]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'To instantiate an Estimator we need to provide two parameters such as `model_fn`
    and the `model_params` as follows:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 要实例化一个估计器，我们需要提供两个参数，如 `model_fn` 和 `model_params`，如下所示：
- en: '[PRE45]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: It is to be noted that the `model_fn()` function contains all the above mentioned
    TensorFlow logic to support the training, evaluation, and prediction. Thus, you
    only need to implement the functionality that could use it efficiently.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，`model_fn()` 函数包含了上述所有 TensorFlow 逻辑，以支持训练、评估和预测。因此，您只需要实现能高效使用它的功能。
- en: 'Now, upon invoking the `main()` method, `model_params` containing the learning
    rate, instantiates the Estimator. You can define the `model_params` as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，调用 `main()` 方法时，`model_params` 包含学习率，实例化估计器。您可以按如下方式定义 `model_params`：
- en: '[PRE46]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Note
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more information on the TensorFlow contrib, interested readers can refer
    to this URL at [https://www.tensorflow.org/extend/estimators](https://www.tensorflow.org/extend/estimators)
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多关于 TensorFlow contrib 的信息，感兴趣的读者可以访问此网址：[https://www.tensorflow.org/extend/estimators](https://www.tensorflow.org/extend/estimators)
- en: 'Well, so far we have acquired enough background knowledge to create an LR model
    with TensorFlow with our dataset. It''s time to implement it:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，到目前为止，我们已经掌握了足够的背景知识，可以用我们的数据集在 TensorFlow 中创建 LR 模型。是时候实现它了：
- en: 'Import required packages and modules:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的包和模块：
- en: '[PRE47]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Loading and preparing the dataset.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载和准备数据集。
- en: 'At first, we load both the datasets:'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，我们加载这两个数据集：
- en: '[PRE48]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Let''s do some feature engineering. We will invoke the function we defined
    in the feature engineering section, but will be provided as separate Python script
    with name `feature.py`:'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们做一些特征工程。我们将调用在特征工程部分定义的函数，但该函数将作为名为 `feature.py` 的独立 Python 脚本提供：
- en: '[PRE49]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'It is to be noted that the sequence of the above invocation is important to
    make the training and test set consistent. Now, we also need to create numerical
    values for categorical variables using the `dummies()` function from sklearn:'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 值得注意的是，上述调用的顺序对于确保训练集和测试集的一致性至关重要。现在，我们还需要使用 sklearn 的 `dummies()` 函数为分类变量创建数值：
- en: '[PRE50]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We need to prepare the training and test set:'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们需要准备训练集和测试集：
- en: '[PRE51]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We then convert the training and test set into a NumPy array since so far we
    have kept them in Pandas DataFrame format:'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后我们将训练集和测试集转换为 NumPy 数组，因为到目前为止我们一直将它们保存在 Pandas DataFrame 格式中：
- en: '[PRE52]'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Let''s prepare the target column for prediction:'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们准备目标列进行预测：
- en: '[PRE53]'
  id: totrans-261
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We also need to know the feature count to build the LR estimator:'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还需要知道特征数量，以便构建 LR 估计器：
- en: '[PRE54]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Preparing the LR estimator.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备 LR 估计器。
- en: 'We build the LR estimator. We will utilize the `LinearClassfier` estimator
    for it. Since this is a binary classification problem, we provide two classes:'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们构建 LR 估计器。我们将使用 `LinearClassfier` 估计器进行构建。由于这是一个二分类问题，我们提供了两个类别：
- en: '[PRE55]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Training the model.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型。
- en: 'Here, we train the above LR estimator for `10,000` iterations. The `fit()`
    method does the trick and the `predict()` method computes the prediction on the
    training set containing the feature, that is, `X_train` and the label, that is,
    `y_train`:'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们训练上述 LR 估计器`10,000`次迭代。`fit()` 方法完成了训练，而 `predict()` 方法计算训练集的预测结果，其中包含特征
    `X_train` 和标签 `y_train`：
- en: '[PRE56]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Model evaluation.
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型评估。
- en: 'We will evaluate the model seeing several classification performance metrics
    such as precision, recall, f1 score, and confusion matrix:'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将评估模型，查看几个分类性能指标，如精度、召回率、F1 分数和混淆矩阵：
- en: '[PRE57]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Since we trained the LR model with NumPy data, we now need to convert it back
    to a Panda DataFrame for confusion matrix creation:'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于我们用 NumPy 数据训练了 LR 模型，现在我们需要将其转换回 Pandas DataFrame 格式，以便创建混淆矩阵：
- en: '[PRE58]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Now, let''s see the count:'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，让我们看看计数：
- en: '[PRE59]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Since seeing the count graphically is awesome, let''s draw it:'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于以图形方式查看计数非常棒，我们来绘制一下它：
- en: '[PRE60]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The output is as follows:'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Using TensorFlow Contrib](img/02_16.jpg)'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![使用 TensorFlow Contrib](img/02_16.jpg)'
- en: 'Figure 14: Survival prediction using logistic regression with TensorFlow'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 14：使用 TensorFlow 进行逻辑回归的生存预测
- en: So, the accuracy we achieved with the LR model is 86% which is not that bad
    at all. But it can still be improved with better predictive models. In the next
    section, we will try to do that using linear **SVM** for survival prediction.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们使用 LR 模型获得的准确率是 86%，这已经算不错了。但它仍然可以通过更好的预测模型进行改进。在下一部分，我们将尝试使用线性 **SVM**
    来进行生存预测。
- en: Linear SVM for Survival Prediction
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于生存预测的线性 SVM
- en: 'The linear **SVM** is one of the most widely used and standard methods for
    large-scale classification tasks. Both the multiclass and binary classification
    problem can be solved using SVM with the loss function in the formulation given
    by the hinge loss:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 线性 **SVM** 是大规模分类任务中最广泛使用和标准的方法之一。多分类和二分类问题都可以通过使用 hinge loss 损失函数的 SVM 来解决：
- en: '![Linear SVM for Survival Prediction](img/02_17.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![Linear SVM for Survival Prediction](img/02_17.jpg)'
- en: Usually, linear SVMs are trained with L2 regularization. Eventually, the linear
    SVM algorithm outputs an SVM model that can be used to predict the label of unknown
    data.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，线性 SVM 使用 L2 正则化进行训练。最终，线性 SVM 算法会输出一个可以用来预测未知数据标签的 SVM 模型。
- en: Suppose you have an unknown data point, **x**, the SVM model makes predictions
    based on the value of ![Linear SVM for Survival Prediction](img/02_23.jpg). The
    outcome can be either positive or negative. More specifically, if ![Linear SVM
    for Survival Prediction](img/02_24.jpg), then the predicted value is positive;
    otherwise, it is negative.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个未知的数据点，**x**，SVM 模型根据 ![Linear SVM for Survival Prediction](img/02_23.jpg)
    的值进行预测。结果可以是正的或负的。更具体地说，如果 ![Linear SVM for Survival Prediction](img/02_24.jpg)，那么预测值为正；否则，预测值为负。
- en: The current version of the TensorFlow contrib package supports only the linear
    SVM. TensorFlow uses SDCAOptimizer for the underlying optimization. Now, the thing
    is that if you want to build an SVM model of your own, you need to consider the
    performance and convergence tuning issues. Fortunately, you can pass the `num_loss_partitions`
    parameter to the SDCAOptimizer function. But you need to set the **X** such that
    it converges to the concurrent train ops per worker.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 当前版本的 TensorFlow contrib 包仅支持线性 SVM。TensorFlow 使用 SDCAOptimizer 作为底层优化器。现在的问题是，如果你想要构建自己的
    SVM 模型，你需要考虑性能和收敛调整的问题。幸运的是，你可以将 `num_loss_partitions` 参数传递给 SDCAOptimizer 函数。但你需要设置
    **X**，使其在每个工作节点的并发训练操作中收敛。
- en: If you set the `num_loss_partitions` larger than or equal to this value, convergence
    is guaranteed, but this makes the overall training slower with the increase of
    `num_loss_partitions`. On the other hand, if you set its value to a smaller one,
    the optimizer is more aggressive in reducing the global loss, but convergence
    is not guaranteed.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将 `num_loss_partitions` 设置为大于或等于这个值，收敛是有保证的，但随着 `num_loss_partitions` 增加，整体训练会变得更慢。另一方面，如果你将其值设置得较小，优化器在减少全局损失时会更具攻击性，但收敛性无法保证。
- en: Note
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more on the implemented contrib packages, interested readers should refer
    to this URL at [https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/estimators](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/estimators).
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解更多实现的 contrib 包，感兴趣的读者可以参考这个网址 [https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/estimators](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/estimators)。
- en: 'Well, so far we have acquired enough background knowledge for creating an SVM
    model, now it''s time to implement it:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，到目前为止，我们已经掌握了创建 SVM 模型所需的足够背景知识，现在是时候实现它了：
- en: 'Import the required packages and modules:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的包和模块：
- en: '[PRE61]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Dataset preparation for building SVM model:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建 SVM 模型的数据集准备：
- en: 'Now, the data preparation for building an SVM model is more or less the same
    as an LR model, except that we need to convert the `PassengerId` to string which
    is required for the SVM:'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，构建 SVM 模型的数据准备工作与 LR 模型差不多，只是我们需要将 `PassengerId` 转换为字符串，因为 SVM 需要这个格式：
- en: '[PRE62]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Creating a dictionary for SVM for continuous feature column.
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为连续特征列创建一个 SVM 字典。
- en: Note
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: To feed the data to the SVM model, we further need to create a dictionary mapping
    from each continuous feature column name (k) to the values of that column stored
    in a constant Tensor. For more information on this issue, refer to this issue
    on TensorFlow GitHub repository at [https://github.com/tensorflow/tensorflow/issues/9505](https://github.com/tensorflow/tensorflow/issues/9505).
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了将数据传入 SVM 模型，我们需要进一步创建一个字典，将每个连续特征列的名称（k）映射到该列存储在常量张量中的值。有关此问题的更多信息，请参见 TensorFlow
    GitHub 仓库中的此问题 [https://github.com/tensorflow/tensorflow/issues/9505](https://github.com/tensorflow/tensorflow/issues/9505)。
- en: 'I have written two functions for both the feature and labels. Let''s see what
    the first one looks like:'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我为特征和标签都编写了两个函数。让我们看看第一个函数是什么样的：
- en: '[PRE63]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: The preceding function creates a dictionary mapping from each continuous feature
    column and then another for the `passengerId` column. Then I merged them into
    one. Since we want to target the 'Survived' column as the labels, I converted
    the label column into constant tensor. Finally, through this function, I returned
    both the feature column and the label.
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述函数创建了一个字典，将每个连续特征列映射到一个字典，然后又为 `passengerId` 列创建了一个字典。接着我将它们合并为一个字典。由于我们希望以
    'Survived' 列作为标签，我将标签列转换为常量张量。最后，通过这个函数，我返回了特征列和标签。
- en: 'Now, the second method does almost the same trick except that it returns only
    the feature columns as follows:'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，第二种方法几乎做了相同的操作，唯一的区别是它只返回特征列，如下所示：
- en: '[PRE64]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Training the SVM model.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练 SVM 模型。
- en: 'Now we will iterate the training 10,000 times over the real valued column only.
    Finally, it creates a prediction list containing all the prediction values:'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们将只对实值列进行 10,000 次迭代训练。最后，它会创建一个包含所有预测值的预测列表：
- en: '[PRE65]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Evaluation of the model:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型评估：
- en: '[PRE66]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Thus using SVM, the accuracy is only 79%, which is lower than that of an LR
    model. Well, similar to an LR model, draw and observe the confusion matrix:'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，使用 SVM 时，准确率仅为 79%，低于 LR 模型的准确率。与 LR 模型类似，绘制并观察混淆矩阵：
- en: '[PRE67]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Then, let''s draw the count plot to see the ratio visually:'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，我们绘制计数图，直观地查看比例：
- en: '[PRE68]'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The output is as follows:'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '![Linear SVM for Survival Prediction](img/02_18.jpg)'
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![线性 SVM 进行生存预测](img/02_18.jpg)'
- en: 'Figure 15: Survival prediction using linear SVM with TensorFlow'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 15：使用 TensorFlow 的线性 SVM 进行生存预测
- en: 'Now, the count:'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，计数：
- en: '[PRE69]'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Ensemble Method for Survival Prediction – Random Forest
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生存预测的集成方法 – 随机森林
- en: One of the most widely used machine learning techniques is using the ensemble
    methods, which are learning algorithms that construct a set of classifiers. It
    can then be used to classify new data points by taking a weighted vote of their
    predictions. In this section, we will mainly focus on the random forest that can
    be built by combining 100s of decision trees.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的机器学习技术之一是集成方法，它是通过构建一组分类器来进行学习的算法。然后可以通过对预测结果加权投票的方式来对新的数据点进行分类。在本节中，我们将主要关注通过组合数百棵决策树来构建的随机森林。
- en: '**Decision trees** (**DTs**) is a technique which is used in supervised learning
    for solving classification and regression tasks. Where a DT model learns simple
    decision rules that are inferred from the data features by utilizing a tree-like
    graph to demonstrate the course of actions. Each branch of a decision tree represents
    a possible decision, occurrence or reaction in terms of statistical probability:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '**决策树**（**DT**）是一种在监督学习中用于解决分类和回归任务的技术。决策树模型通过利用树状图来展示行动步骤，学习从数据特征中推断出的简单决策规则。决策树的每个分支表示一个可能的决策、事件或反应，基于统计概率：'
- en: '![Ensemble Method for Survival Prediction – Random Forest](img/02_19.jpg)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
  zh: '![生存预测的集成方法 – 随机森林](img/02_19.jpg)'
- en: 'Figure 16: A sample decision tree on the admission test dataset using the rattle
    package of R'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16：使用 R 的 rattle 包对入学测试数据集进行的样本决策树
- en: Compared to LR or SVM, the DTs are far more robust classification algorithms.
    The tree infers predicted labels or classes after splitting available features
    to the training data based to produce a good generalization. Most interestingly,
    the algorithm can handle both the binary as well as multiclass classification
    problems.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 与 LR 或 SVM 相比，决策树（DT）是更为稳健的分类算法。树根据训练数据中可用特征的划分推断预测标签或类别，从而产生良好的泛化效果。最有趣的是，该算法可以处理二分类和多分类问题。
- en: For instance, the decision trees in figure 16 learn from the admission data
    to approximate a sine curve with a set of `if...else` decision rules. The dataset
    contains the record of each student who applied for admission, say to an American
    university. Each record contains the graduate record exam score, CGPA score and
    the rank of the column. Now we will have to predict who is competent based on
    these three features (variables).
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，图16中的决策树从入学数据中学习，通过一组`if...else`决策规则来逼近正弦曲线。数据集包含每个申请入学学生的记录，比如申请美国大学的记录。每条记录包含研究生入学考试成绩、CGPA成绩以及列的排名。现在，我们需要基于这三项特征（变量）来预测谁是合格的。
- en: DTs can be utilized to solve this kind of problem after training the DT model
    and pruning the unwanted branch of the tree. In general, a deeper tree signifies
    more complex decision rules and a better-fitted model. Therefore, the deeper the
    tree, the more complex the decision rules, and the more fitted the model.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树（DTs）可以在训练DT模型并修剪掉不需要的树枝后用于解决这种问题。通常，较深的树表示更复杂的决策规则和更合适的模型。因此，树越深，决策规则越复杂，模型拟合度越高。
- en: Note
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: If you would like to draw the above figure, just use my R script and execute
    on RStudio and feed the admission dataset. The script and the dataset can be found
    in my GitHub repository at [https://github.com/rezacsedu/AdmissionUsingDecisionTree](https://github.com/rezacsedu/AdmissionUsingDecisionTree).
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想绘制上面的图形，只需使用我的R脚本并在RStudio中执行，输入入学数据集。脚本和数据集可以在我的GitHub仓库中找到，链接为：[https://github.com/rezacsedu/AdmissionUsingDecisionTree](https://github.com/rezacsedu/AdmissionUsingDecisionTree)。
- en: Well, so far we have acquired enough background knowledge for creating a Random
    Forest (RF) model, now it's time to implement it.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经获得了足够的背景知识来创建一个随机森林（RF）模型，现在是时候实现它了。
- en: 'Import the required packages and modules:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的包和模块：
- en: '[PRE70]'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Dataset preparation for building an RF model.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建RF模型的数据集准备。
- en: Now, the data preparation for building an RF model is more or less the same
    as an LR model. So please refer to the logistic regression section.
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，构建RF模型的数据准备与LR模型大致相同。因此，请参考逻辑回归部分。
- en: Building a random forest estimator.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建随机森林估计器。
- en: 'The following function builds a random forest estimator. It creates 1,000 trees
    with maximum 1,000 nodes and 10-fold cross-validation. Since it''s a binary classification
    problem, I put number of classes as 2:'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下函数构建了一个随机森林估计器。它创建了1,000棵树，最多1,000个节点，并进行了10倍交叉验证。由于这是一个二分类问题，我将类别数设为2：
- en: '[PRE71]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Training the RF model.
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练RF模型。
- en: 'Here, we train the above RF estimator. Once the `fit()` method does the trick
    and the `predict()` method computes the prediction on the training set containing
    the feature, that is, `x_train` and the label, that is, `y_train`:'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们训练上述RF估计器。一旦`fit()`方法完成工作，`predict()`方法便会计算在包含特征`x_train`和标签`y_train`的训练集上的预测结果：
- en: '[PRE72]'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Evaluating the model.
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型。
- en: 'Now let''s evaluate the performance of the RF model:'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在让我们评估RF模型的性能：
- en: '[PRE73]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Thus, using RF, the accuracy is 87% which is higher than that of the LR and
    SVM models. Well, similar to the LR and SVM model, we''ll draw and observe the
    confusion matrix:'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，使用RF时，准确率为87%，高于LR和SVM模型。与LR和SVM模型类似，我们将绘制并观察混淆矩阵：
- en: '[PRE74]'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Then, let''s draw the count plot to see the ratio visually:'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，让我们绘制计数图，直观地查看比例：
- en: '[PRE75]'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The output is as follows:'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Ensemble Method for Survival Prediction – Random Forest](img/02_20.jpg)'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![生存预测的集成方法 – 随机森林](img/02_20.jpg)'
- en: 'Figure 17: Titanic survival prediction using random forest with TensorFlow'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图17：使用TensorFlow的随机森林进行泰坦尼克号生存预测
- en: 'Now, the count for each one:'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，分别统计每个的数量：
- en: '[PRE76]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: A Comparative Analysis
  id: totrans-353
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一项比较分析
- en: From the classification reports, we can see that random forest has the best
    overall performance. The reason for this may be that it works better with categorical
    features than the other two methods. Also, since it uses implicit feature selection,
    overfitting was reduced significantly. Using logistic regression is a convenient
    probability score for observations. However, it doesn't perform well when feature
    space is too large that is, doesn't handle a large number of categorical features/variables
    well. It also solely relies on transformations for non-linear features.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 从分类报告中，我们可以看到随机森林具有最佳的整体表现。其原因可能是随机森林在处理分类特征时，比其他两种方法表现更好。同时，由于它使用隐式特征选择，过拟合问题得到了显著减轻。使用逻辑回归是为观察结果提供方便的概率评分。然而，当特征空间过大时，它的表现不佳，即不能很好地处理大量的分类特征/变量。它还完全依赖于非线性特征的转换。
- en: Finally, using SVM we can handle a large feature space with non-linear feature
    interactions without relying on the entire dataset. However, it is not very well
    with a large number of observations. Nevertheless, it can be tricky to find an
    appropriate kernel sometimes.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用SVM我们可以处理具有非线性特征交互的大规模特征空间，而不依赖于整个数据集。然而，它在大量观察数据的情况下表现不好。不过，有时找到合适的核函数可能会有些棘手。
- en: Summary
  id: totrans-356
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this lesson, we have discussed supervised learning from the theoretical and
    practical perspective. In particular, we have revisited the linear regression
    model for regression analysis. We have seen how to use regression for predicting
    continuous values. Later in this lesson, we have discussed some other supervised
    learning algorithms for predictive analytics. We have seen how to use logistic
    regression, SVM, and random forests for survival prediction on the Titanic dataset.
    Finally, we have seen a comparative analysis between these classifiers. We have
    also seen that random forest, which is based on decision trees ensembles, outperforms
    logistic regression and linear SVM models.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节课中，我们从理论和实践的角度讨论了监督学习。特别是，我们重新审视了用于回归分析的线性回归模型。我们了解了如何使用回归来预测连续值。随后，在本节课中，我们讨论了其他一些用于预测分析的监督学习算法。我们看到了如何使用逻辑回归、SVM和随机森林在泰坦尼克号数据集上进行生存预测。最后，我们还做了这些分类器的对比分析。我们还发现，基于决策树集成的随机森林优于逻辑回归和线性SVM模型。
- en: In [Lesson 3](ch03.html "Chapter 3. Clustering Your Data – Unsupervised Learning
    for Predictive Analytics"), *Clustering Your Data – Unsupervised Learning for
    Predictive Analytics*, we will provide some practical examples of unsupervised
    learning. Particularly, the clustering technique using TensorFlow will be provided
    for neighborhood clustering and audio clustering from audio features.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3课](ch03.html "第3章：聚类你的数据——用于预测分析的无监督学习")中，*聚类你的数据——用于预测分析的无监督学习*，我们将提供一些无监督学习的实际示例。特别地，我们将提供使用TensorFlow进行邻域聚类和音频特征聚类的聚类技术。
- en: More specifically, we will provide an exploratory analysis of the dataset then
    we will develop a cluster of the neighborhood using K-means, K-NN, and bisecting
    K-means with sufficient performance metrics such as cluster cost, accuracy, and
    so on. In the second part of the lesson, we will see how to do audio feature clustering.
    Finally, we will provide a comparative analysis of clustering algorithms.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，我们将提供数据集的探索性分析，然后我们将使用K-means、K-NN和二分K-means方法结合充分的性能指标（如聚类成本、准确性等）来开发邻域的聚类。在课程的第二部分，我们将学习如何进行音频特征聚类。最后，我们将提供聚类算法的对比分析。
- en: Assessments
  id: totrans-360
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估
- en: Depending on the nature of the learning feedback available, the machine learning
    process is typically classified into three broad categories. Name them.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据可用的学习反馈的性质，机器学习过程通常分为三大类。请列出它们。
- en: 'State whether the following statement is True or False: Using the brute-force
    approach such as if-else statements with some sort of weighted scoring system,
    you cannot write a program to predict whether a given passenger would survive
    the disaster.'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 判断以下陈述是对还是错：使用暴力法（如if-else语句与某种加权评分系统），你无法编写程序来预测给定乘客是否能够在灾难中幸存。
- en: Upon invoking the main() method, model_params containing the learning rate instantiates
    the Estimator. How can you define the model_params as?
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用main()方法时，包含学习率的model_params会实例化Estimator。你如何定义model_params？
- en: 'State whether the following statement is True or False: Each branch of a decision
    tree represents a possible decision, occurrence, or reaction in terms of statistical
    probability.'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 判断以下陈述是对还是错：决策树的每个分支代表一个可能的决策、事件或反应，从统计概率的角度来看。
- en: A predictive model based on supervised learning algorithms can make predictions
    based on a labeled _______ that maps inputs to outputs aligning with the real
    world.
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于监督学习算法的预测模型可以根据一个带标签的_______进行预测，该标签将输入映射到与现实世界对齐的输出。
- en: Dataflow graph
  id: totrans-366
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据流图
- en: Linear graph
  id: totrans-367
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性图
- en: Regression model
  id: totrans-368
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回归模型
- en: Dataset
  id: totrans-369
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集
