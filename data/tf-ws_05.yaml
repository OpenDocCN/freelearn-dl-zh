- en: 5\. Classification Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5. 分类模型
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, you will explore different types of classification models.
    You will gain hands-on experience of using TensorFlow to build binary, multi-class,
    and multi-label classifiers. Finally, you will learn the concepts of model evaluation
    and how you can use different metrics to assess the performance of a model.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将探索不同类型的分类模型。您将获得使用TensorFlow构建二元分类、多类别分类和多标签分类器的实际经验。最后，您将学习模型评估的概念，并了解如何使用不同的指标来评估模型的表现。
- en: By the end of this chapter, you will have a good understanding of what classification
    models are and how programming with TensorFlow works.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将对分类模型及使用TensorFlow编程有一个良好的理解。
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapter, you learned about regression problems where the target
    variable is continuous. A continuous variable can take any value between a minimum
    and maximum value. You learned how to train such models with TensorFlow.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您学习了回归问题，其中目标变量是连续的。连续变量可以取最小值和最大值之间的任何值。您已经学会了如何使用TensorFlow训练这样的模型。
- en: In this chapter, you will look at another type of supervised learning problem
    called classification, where the target variable is discrete — meaning it can
    only take a finite number of values. In industry, you will most likely encounter
    such projects where variables are aggregated into groups such as product tiers,
    or classes of users, customers, or salary ranges. The objective of a classifier
    is to learn the patterns from the data and predict the right class for observation.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将研究另一种监督学习问题，称为分类问题，其中目标变量是离散的——意味着它只能取有限数量的值。在行业中，您最有可能遇到这样的项目，其中变量被聚合为不同的组，如产品层次、用户类别、客户类别或薪资范围。分类器的目标是从数据中学习模式，并预测观察值的正确类别。
- en: For instance, in the case of a loan provider, a classification model will try
    to predict whether a customer is most likely to default in the coming year based
    on their profile and financial position. This outcome can only take two possible
    values (`yes` or `no`), which is a binary classification. Another classifier model
    could predict the ratings from 1 to 5 of a new movie for a user given their previous
    ratings and the information about this movie. When the outcome can be more than
    two possible values, you are dealing with a multi-class classification. Finally,
    there is a third type of classifier called multi-label where the model will predict
    more than a class. For example, a model will analyze an input image and predict
    whether there is a cat, a dog, or a mouse in the image. In such a case, the model
    will predict three different binary outputs (or labels).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在贷款提供商的情况下，分类模型将尝试根据客户的资料和财务状况预测他们在来年违约的可能性。该结果只能取两个可能的值（`是`或`否`），这就是二元分类。另一个分类器模型可能会根据用户之前的评分和这部新电影的信息，预测用户对该电影的评分，评分范围为1到5。当结果可以取两个以上的值时，您正在处理多类别分类。最后，还有第三种类型的分类器，称为多标签分类，其中模型将预测多个类别。例如，模型将分析一张输入图像，并预测图像中是否有猫、狗或老鼠。在这种情况下，模型将预测三个不同的二元输出（或标签）。
- en: You will go through each type of classifier in this chapter, detail their specificities,
    and explore how to measure the performance of these models.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍每种分类器，详细阐述其特点，并探讨如何衡量这些模型的表现。
- en: Binary Classification
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二元分类
- en: As mentioned previously, binary classification refers to a type of supervised
    learning where the target variable can only take two possible values (or classes)
    such as true/false or yes/no. For instance, in the medical industry, you may want
    to predict whether a patient is more likely to have a disease based on their personal
    information such as age, height, weight, and/or medical measurements. Similarly,
    in marketing, advertisers might utilize similar information to optimize email
    campaigns.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，二元分类指的是一种监督学习类型，其中目标变量只能取两个可能的值（或类别），例如真/假或是/否。例如，在医疗行业中，您可能想根据患者的个人信息（如年龄、身高、体重和/或医疗测量值）来预测他们是否更有可能患病。同样，在营销领域，广告商可能利用类似的信息来优化电子邮件活动。
- en: 'Machine learning algorithms such as the random forest classifier, support vector
    classifier, or logistic regression work well for classification. Neural networks
    can also achieve good results for binary classification. It is extremely easy
    to turn a regression model such as those in the previous chapter into a binary
    classifier. There are only two key changes required: the activation function for
    the last layer and the loss function.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如随机森林分类器、支持向量分类器或逻辑回归等机器学习算法在分类任务上表现良好。神经网络也可以为二元分类实现良好的结果。将回归模型转换为二元分类器非常简单，只需要两个关键的变化：最后一层的激活函数和损失函数。
- en: Logistic Regression
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: '`0` and `1`. The value `0` usually corresponds to `false` (or `no`) while the
    value `1` refers to `true` (or `yes`).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`0`和`1`。值`0`通常对应于`false`（或`no`），而值`1`则指`true`（或`yes`）。'
- en: 'In other terms, the output of logistic regression will be the probability of
    it being true. For example, if the output is `0.3`, you can say there is a probability
    of 30% that the result should be true (or yes). But as there are only two possible
    values, this will also mean there is a probability of 70% (100% – 30%) of having
    the outcome of false (or no):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，逻辑回归的输出将是其为真的概率。例如，如果输出为`0.3`，则可以说结果为真（或yes）的概率为30%。但由于只有两个可能的值，这也意味着有70%的概率（100%
    - 30%）结果为假（或no）：
- en: '![Figure 5.1: Output of logistic regression'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.1: 逻辑回归的输出'
- en: '](img/B16341_05_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_01.jpg)'
- en: 'Figure 5.1: Output of logistic regression'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5.1: 逻辑回归的输出'
- en: 'Now that you know what the output of logistic regression is, you just need
    to find a function that can transform an input value that is continuous into a
    value between `0` and `1`. Luckily, such a mathematical function does exist, and
    it is called the **sigmoid function**. The formula for this function is as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了逻辑回归的输出是什么，您只需找到一个可以将连续输入值转换为`0`和`1`之间值的函数。幸运的是，这样的数学函数确实存在，称为**sigmoid
    函数**。该函数的公式如下：
- en: '![Figure 5.2: Formula of the sigmoid function'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.2: Sigmoid 函数的公式'
- en: '](img/B16341_05_02.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_02.jpg)'
- en: 'Figure 5.2: Formula of the sigmoid function'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5.2: Sigmoid 函数的公式'
- en: '![Text'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![Text'
- en: 'Description automatically generated with medium confidence](img/B16341_05_02a.png)corresponds
    to the exponential function applied to `x`. The exponential function ranges from
    0 to positive infinity. So, if `x` has a value close to positive infinite, the
    value of sigmoid will tend to `1`. On the other hand, if `x` is very close to
    negative infinite, then the value of sigmoid will tend to `0`:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 自动以中等置信度生成的描述](img/B16341_05_02a.png)对应于应用于`x`的指数函数。指数函数的取值范围从`0`到正无穷。因此，如果`x`的值接近正无穷，sigmoid
    的值将趋向于`1`。另一方面，如果`x`非常接近负无穷，则 sigmoid 的值将趋向于`0`：
- en: '![Figure 5.3: Curve of the sigmoid function'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.3: Sigmoid 函数的曲线'
- en: '](img/B16341_05_03.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_03.jpg)'
- en: 'Figure 5.3: Curve of the sigmoid function'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5.3: Sigmoid 函数的曲线'
- en: 'So, applying the sigmoid function on the output of a linear regression model
    turns it into logistic regression. The same logic holds for neural networks: if
    you apply the sigmoid function on a perceptron model (linear regression), you
    will get a binary classifier. To do so, you just need to specify sigmoid as the
    activation function of the last fully connected layer of a perceptron model. In
    TensorFlow, you specify the `activation` parameter as:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，将线性回归模型的输出应用于 sigmoid 函数将其转换为逻辑回归。对于神经网络也是同样的逻辑：如果您将 sigmoid 函数应用于感知器模型（线性回归），则将获得二元分类器。要实现这一点，只需在感知器模型的最后一个全连接层中指定
    sigmoid 作为激活函数。在 TensorFlow 中，您可以将`activation`参数指定为:'
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The preceding code snippet shows how to define a fully connected layer with
    a single unit that can output any value and apply the sigmoid activation function
    to it. The result will then be within `0` and `1`. Now that you know how to modify
    a neural network's regression model to turn it into a binary classifier, you need
    to specify the relevant loss function.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段展示了如何定义一个具有单个单元的全连接层，该单元可以输出任何值，并对其应用 sigmoid 激活函数。结果将在`0`和`1`之间。现在，您已经了解如何修改神经网络的回归模型以将其转变为二元分类器，需要指定相关的损失函数。
- en: Binary Cross-Entropy
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二元交叉熵
- en: 'In the previous section, you learned how to turn a linear regression model
    into a binary classifier. With neural networks, it is as simple as adding sigmoid
    as the activation function for the last fully connected layer. But there is another
    consideration that will impact the training of this model: the choice of the loss function.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你学习了如何将一个线性回归模型转换为二分类器。使用神经网络，只需在最后的全连接层上添加 sigmoid 激活函数即可。但还有一个影响该模型训练的因素：损失函数的选择。
- en: 'For linear regression, the most frequently used loss functions are **mean squared
    error** and **mean absolute error** as seen in *Chapter 4*, *Regression and Classification
    Models*. These functions will calculate the difference between the predicted and
    the actual values, and the neural network model will update all its weights accordingly
    during backpropagation. For a binary classification, the typical loss function
    is **binary cross-entropy** (also called **log loss**). The formula for this function
    is as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线性回归，最常用的损失函数是**均方误差**和**平均绝对误差**，如在*第4章*《回归与分类模型》中所示。这些函数会计算预测值与实际值之间的差异，神经网络模型会在反向传播过程中相应地更新所有权重。对于二分类问题，典型的损失函数是**二元交叉熵**（也叫做**对数损失**）。该函数的公式如下：
- en: '![Figure 5.4: Formula of binary cross-entropy'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.4：二元交叉熵公式'
- en: '](img/B16341_05_04.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_04.jpg)'
- en: 'Figure 5.4: Formula of binary cross-entropy'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4：二元交叉熵公式
- en: '![A picture containing text'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![一张包含文本的图片'
- en: Description automatically generated](img/B16341_05_04a.png) represents the actual
    value for the observation `i`.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B16341_05_04a.png) 代表观测 `i` 的实际值。
- en: '![Formula](img/B16341_05_04b.png) represents the predicted probability for
    the observation `i`.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '![公式](img/B16341_05_04b.png) 代表观测 `i` 的预测概率。'
- en: '`N` represents the total number of observations.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`N` 代表观测的总数。'
- en: 'This formula looks quite complicated, but its logic is quite simple. Consider
    the following example of a single observation: the actual value is `1` and the
    predicted probability is `0.8`. If the preceding formula is applied, the result
    will be as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式看起来相当复杂，但其逻辑非常简单。考虑以下单个观测的例子：实际值为 `1`，预测概率为 `0.8`。如果应用上述公式，结果将如下：
- en: '![Formula](img/B16341_05_04c.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![公式](img/B16341_05_04c.png)'
- en: 'Notice that the right-hand side of the equation is approximately zero:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，方程式右侧的值大约为零：
- en: '![Formula](img/B16341_05_04d.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![公式](img/B16341_05_04d.png)'
- en: So, the loss value will be very small as the predicted value is very close to
    the actual one.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当预测值与实际值非常接近时，损失值会非常小。
- en: 'Now consider another example where the actual value is `0` and the predicted
    probability is `0.99`. The result will be as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑另一个例子，其中实际值为 `0`，预测概率为 `0.99`。结果如下：
- en: '![Formula](img/B16341_05_04e.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![公式](img/B16341_05_04e.png)'
- en: '![Formula](img/B16341_05_04f.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![公式](img/B16341_05_04f.png)'
- en: The loss will be high in this case as the prediction is very different from
    the actual value.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，损失会很高，因为预测值与实际值差异很大。
- en: 'The `BinaryCrossentropy` that computes this loss:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`BinaryCrossentropy` 用于计算这个损失：'
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Binary Classification Architecture
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二分类架构
- en: 'The architecture for binary classifiers is extremely similar to that of linear
    regression as seen in *Chapter 4*, *Regression and Classification Models*. It
    is composed of an input layer that reads each observation of the input dataset,
    an output layer responsible for predicting the response variable, and some hidden
    layers that learn the patterns leading to the correct predictions. The following
    diagram shows an example of such an architecture:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类器的架构与线性回归非常相似，如在*第4章*《回归与分类模型》中所示。它由一个输入层组成，该层读取输入数据集的每个观测值，一个输出层负责预测响应变量，以及一些隐藏层，学习导致正确预测的模式。以下图示展示了这种架构的一个例子：
- en: '![Figure 5.5: Architecture of the binary classifier'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.5：二分类器的架构'
- en: '](img/B16341_05_05.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_05.jpg)'
- en: 'Figure 5.5: Architecture of the binary classifier'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5：二分类器的架构
- en: The only difference compared to linear regression is the output, which is a
    probability value between `0` and `1`. This probability indicates the likelihood
    of the occurrence for one of the two possible values. As seen previously, this
    is achieved using the sigmoid activation function and binary cross-entropy for
    backpropagation.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 与线性回归的唯一区别是输出，它是一个介于`0`和`1`之间的概率值。这个概率值表示其中一个可能值发生的概率。如前所述，这通过使用sigmoid激活函数和二元交叉熵进行反向传播来实现。
- en: Now that you have seen all the elements to build a binary classifier, you can
    put this into practice with an exercise.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经看到了构建二分类器的所有元素，你可以通过一个练习将它付诸实践。
- en: 'Exercise 5.01: Building a Logistic Regression Model'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习5.01：构建逻辑回归模型
- en: In this exercise, you will build and train a logistic regression model in TensorFlow
    that will predict the winning team in a game of Dota 2 using some information
    about the game, such as the mode and type used.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你将使用TensorFlow构建并训练一个逻辑回归模型，预测Dota 2比赛中哪个队伍获胜，使用的输入信息包括游戏的模式和类型等。
- en: You will be working on the Dota 2 dataset. Dota 2 is a popular computer game.
    The dataset contains information related to the game and the target variable indicates
    which team won.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用Dota 2数据集进行工作。Dota 2是一款流行的电脑游戏。该数据集包含与游戏相关的信息，目标变量指示哪个队伍获胜。
- en: Note
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The training dataset can be accessed here: [https://packt.link/Tdvdj](https://packt.link/Tdvdj).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集可以在这里访问：[https://packt.link/Tdvdj](https://packt.link/Tdvdj)。
- en: 'The test dataset can be accessed here: [https://packt.link/4PsPN](https://packt.link/4PsPN).'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据集可以在这里访问：[https://packt.link/4PsPN](https://packt.link/4PsPN)。
- en: 'The original dataset can be found here: [https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results](https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results).'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集可以在这里找到：[https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results](https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results)。
- en: Open a new Jupyter notebook.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Jupyter笔记本。
- en: 'Import the pandas library and use `pd` as the alias:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入pandas库并使用`pd`作为别名：
- en: '[PRE2]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create a variable called `train_url` that contains the URL to the training
    set:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`train_url`的变量，包含训练集的URL：
- en: '[PRE3]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Load the training dataset into a `DataFrame()` function called `X_train` using
    `read_csv()` method, provide the URL to the CSV file, and set `header=None` as
    the dataset doesn''t provide column names. Print the first five rows of the DataFrame
    using `head()`method:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`read_csv()`方法将训练数据集加载到一个名为`X_train`的`DataFrame()`函数中，提供CSV文件的URL，并将`header=None`设置为数据集没有列名。使用`head()`方法打印DataFrame的前五行数据：
- en: '[PRE4]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The expected output will be as follows:'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 期望的输出如下所示：
- en: '![Figure 5.6: The first five rows of the Dota 2 training set'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.6：Dota 2训练集的前五行数据'
- en: '](img/B16341_05_06.jpg)'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_06.jpg)'
- en: 'Figure 5.6: The first five rows of the Dota 2 training set'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.6：Dota 2训练集的前五行数据
- en: 'You can see that the dataset contains 117 columns, and they are all numeric.
    Note also that the target variable (column `0`) contains two different values:
    `-1` and `1`. As you will train a logistic regression model, the possible values
    should be `0` and `1`. You will need to replace the `-1` values with `0`.'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以看到数据集包含117列，且它们都是数值型的。还需要注意的是，目标变量（第`0`列）包含两个不同的值：`-1`和`1`。由于你将训练一个逻辑回归模型，可能的值应该是`0`和`1`。你需要将`-1`的值替换为`0`。
- en: 'Extract the target variable (column 0) using the `pop()` method and save it
    in a variable called `y_train`:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pop()`方法提取目标变量（第0列），并将其保存在名为`y_train`的变量中：
- en: '[PRE5]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Replace all values with `-1` with `0` from the target variable using `replace()`,
    and print the first five rows using `head()` method:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`replace()`方法将目标变量中的所有`-1`值替换为`0`，并使用`head()`方法打印前五行数据：
- en: '[PRE6]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The expected output will be as follows:'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 期望的输出如下所示：
- en: '![Figure 5.7: The first five rows of the Dota 2 target variable from the training
    set'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.7：Dota 2训练集中目标变量的前五行数据'
- en: '](img/B16341_05_07.jpg)'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_07.jpg)'
- en: 'Figure 5.7: The first five rows of the Dota 2 target variable from the training
    set'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.7：Dota 2训练集中目标变量的前五行数据
- en: Now all the values from the target variable of the training set are either `0`
    or `1`.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，训练集的目标变量中的所有值都是`0`或`1`。
- en: 'Create a variable called `test_url` that contains the URL to the test set:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`test_url`的变量，包含测试集的URL：
- en: '[PRE7]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Load the test dataset into a `DataFrame()` function called `X_test` using `read_csv()`
    method, provide the URL to the CSV file, and set `header=None` as the dataset
    doesn''t provide column names. Print the first five rows using `head()` method:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`read_csv()`方法加载测试数据集到名为`X_test`的`DataFrame()`函数中，提供CSV文件的URL，并设置`header=None`，因为数据集没有提供列名。使用`head()`方法打印前五行：
- en: '[PRE8]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The expected output will be as follows:'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '![Figure 5.8: The first five rows of the Dota 2 test set'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.8：Dota 2测试集的前五行'
- en: '](img/B16341_05_08.jpg)'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_08.jpg)'
- en: 'Figure 5.8: The first five rows of the Dota 2 test set'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.8：Dota 2测试集的前五行
- en: The test set is very similar to the training one, and you will need to perform
    the same transformation on it.
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测试集与训练集非常相似，你需要对其进行相同的转换。
- en: 'Extract the target variable (column 0) using the `pop()` method and save it
    in a variable called `y_test`:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pop()`方法提取目标变量（第0列），并将其保存为名为`y_test`的变量：
- en: '[PRE9]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Replace all values with `-1` with `0` from the target variable using `replace()`
    method and print the first five rows using `head()` method:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`replace()`方法将目标变量中的所有`-1`值替换为`0`，并使用`head()`方法打印前五行：
- en: '[PRE10]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The expected output will be as follows:'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '![Figure 5.9: The first five rows of the Dota 2 target variable from the test
    set'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.9：Dota 2测试集中的目标变量前五行'
- en: '](img/B16341_05_09.jpg)'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_09.jpg)'
- en: 'Figure 5.9: The first five rows of the Dota 2 target variable from the test
    set'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.9：Dota 2测试集中的目标变量前五行
- en: 'Import TensorFlow library and use `tf` as the alias:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入TensorFlow库并使用`tf`作为别名：
- en: '[PRE11]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Set the seed for TensorFlow as `8`, using `tf.random.set_seed()` to get reproducible
    results:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`tf.random.set_seed()`设置TensorFlow的种子为`8`，以获得可重复的结果：
- en: '[PRE12]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Instantiate a sequential model using `tf.keras.Sequential()` and store it in
    a variable called `model`:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`tf.keras.Sequential()`实例化一个顺序模型，并将其保存为名为`model`的变量：
- en: '[PRE13]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Import the `Dense()` class from `tensorflow.keras.layers`:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tensorflow.keras.layers`导入`Dense()`类：
- en: '[PRE14]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create a fully connected layer of `512` units with `Dense()` and specify ReLu
    as the activation function and the input shape as `(116,)`, which corresponds
    to the number of features from the dataset. Save it in a variable called `fc1`:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Dense()`创建一个包含`512`个单元的全连接层，指定ReLu作为激活函数，并将输入形状设置为`(116,)`，这对应于数据集中的特征数量。将其保存为名为`fc1`的变量：
- en: '[PRE15]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create a fully connected layer of `512` units with `Dense()` and specify ReLu
    as the activation function. Save it in a variable called `fc2`:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Dense()`创建一个包含`512`个单元的全连接层，并指定ReLu作为激活函数。将其保存为名为`fc2`的变量：
- en: '[PRE16]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create a fully connected layer of `128` units with `Dense()` and specify ReLu
    as the activation function. Save it in a variable called `fc3`:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Dense()`创建一个包含`128`个单元的全连接层，并指定ReLu作为激活函数。将其保存为名为`fc3`的变量：
- en: '[PRE17]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Create a fully connected layer of `128` units with `Dense()` and specify ReLu
    as the activation function. Save it in a variable called `fc4`:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Dense()`创建一个包含`128`个单元的全连接层，并指定ReLu作为激活函数。将其保存为名为`fc4`的变量：
- en: '[PRE18]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Create a fully connected layer of `128` units with `Dense()` and specify sigmoid
    as the activation function. Save it in a variable called `fc5`:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Dense()`创建一个包含`128`个单元的全连接层，并指定sigmoid作为激活函数。将其保存为名为`fc5`的变量：
- en: '[PRE19]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Sequentially add all five fully connected layers to the model using `add()` method:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`add()`方法顺序添加所有五个全连接层到模型中：
- en: '[PRE20]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Print the summary of the model using `summary()` method:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`summary()`方法打印模型的摘要：
- en: '[PRE21]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The expected output will be as follows:'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '![Figure 5.10: Summary of the model architecture'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.10：模型架构摘要'
- en: '](img/B16341_05_10.jpg)'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_10.jpg)'
- en: 'Figure 5.10: Summary of the model architecture'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.10：模型架构摘要
- en: The preceding output shows that there are five layers in your model (as expected)
    and displays the number of parameters at each layer. For example, the first layer
    contains 59,904 parameters, and the total number of parameters for this model
    is 404,855\. All these parameters will be trained while fitting the model.
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述输出显示了模型中有五个层（如预期）并展示了每层的参数数量。例如，第一层包含59,904个参数，该模型的总参数数量为404,855。所有这些参数将在训练模型时进行训练。
- en: 'Instantiate a `BinaryCrossentropy()` function from `tf.keras.losses` and save
    it in a variable called `loss`:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tf.keras.losses`实例化一个`BinaryCrossentropy()`函数，并将其保存为名为`loss`的变量：
- en: '[PRE22]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Instantiate `Adam()` from `tf.keras.optimizers` with `0.001` as the learning
    rate and save it in a variable called `optimizer`:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tf.keras.optimizers`实例化`Adam()`，学习率设置为`0.001`，并将其保存为名为`optimizer`的变量：
- en: '[PRE23]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Compile the model using the `compile()` function and specify the optimizer
    and loss you just created in previous steps:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`compile()`函数编译模型，并指定在前面步骤中创建的优化器和损失函数：
- en: '[PRE24]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Start the model training process using `fit()` method on the training set for
    five epochs:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`fit()`方法在训练集上进行五个epoch的模型训练：
- en: '[PRE25]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The expected output will be as follows:'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '![Figure 5.11: Logs of the training process'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.11：训练过程的日志'
- en: '](img/B16341_05_11.jpg)'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_11.jpg)'
- en: 'Figure 5.11: Logs of the training process'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.11：训练过程的日志
- en: The preceding output shows the logs of each epoch during the training of the
    model. Note that it took around 15 seconds to process a single epoch and the loss
    value decreased from `0.6923` (first epoch) to `0.6650` (fifth epoch), so the model
    is slowly improving its performance by reducing the binary cross-entropy loss.
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述输出显示了每个epoch训练过程中记录的日志。请注意，处理单个epoch大约需要15秒，且损失值从`0.6923`（第一epoch）降到`0.6650`（第五epoch），这表明模型通过减少二元交叉熵损失正在缓慢改善其性能。
- en: 'Predict the results of the test set using `predict()` method. Save it in a
    variable called `preds` and display its first five values:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`predict()`方法预测测试集的结果。将结果保存到名为`preds`的变量中，并显示其前五个值：
- en: '[PRE26]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The expected output will be as follows:'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '![Figure 5.12: Predictions of the first five rows of the test set'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.12：测试集前五行的预测结果'
- en: '](img/B16341_05_12.jpg)'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_12.jpg)'
- en: 'Figure 5.12: Predictions of the first five rows of the test set'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.12：测试集前五行的预测结果
- en: The preceding output shows the probability of each prediction. Each value below
    `0.5` will be classified as `0` (first and last observation in this output) and
    all values greater than or equal to `0.5` will be `1` (second to fourth observations).
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述输出显示了每个预测的概率。小于`0.5`的值会被分类为`0`（该输出中的第一和最后一个观察结果），而大于或等于`0.5`的值会被分类为`1`（第二到第四个观察结果）。
- en: 'Display the first five true labels of the test set:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示测试集前五个真实标签：
- en: '[PRE27]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The expected output will be as follows:'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '![Figure 5.13: True labels of the first five rows of the test set'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.13：测试集前五行的真实标签'
- en: '](img/B16341_05_13.jpg)'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_13.jpg)'
- en: 'Figure 5.13: True labels of the first five rows of the test set'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13：测试集前五行的真实标签
- en: 'Comparing this output with the model predictions on the first five rows of
    the test set, there are some incorrect values: the third prediction (index `2`)
    should be a value of `0` and the last one should be `0`. So, out of these five
    observations, your binary classifiers made two mistakes.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 将该输出与模型在测试集前五行上的预测结果进行比较，发现存在一些错误值：第三个预测（索引为`2`）应为`0`，最后一个预测应为`0`。因此，在这五个观察值中，二分类器犯了两个错误。
- en: In the section ahead, you will see how to properly evaluate the performance
    of a model with different metrics.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，你将看到如何使用不同的指标正确评估模型的性能。
- en: Metrics for Classifiers
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类器的评估指标
- en: 'In the previous section, you learned how to train a binary classifier to predict
    the right output: either `0` or `1`. In *Exercise 5.01*, *Building a Logistic
    Regression Model*, you looked at a few samples to assess the performance of the
    models that were built. Usually, you would evaluate a model not just on a small
    subset but on the whole dataset using a performance metric such as accuracy or
    F1 score.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一部分中，你学习了如何训练一个二分类器来预测正确的输出：`0`或`1`。在*练习 5.01*中，*构建逻辑回归模型*，你查看了几个样本以评估所构建模型的性能。通常，你会使用像准确率或F1分数这样的性能指标对模型进行评估，而不仅仅是对一个小子集进行评估，而是对整个数据集进行评估。
- en: Accuracy and Null Accuracy
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准确率和空白准确率
- en: 'One of the most widely used metrics for classification problems is accuracy.
    Its formula is quite simple:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个最广泛使用的分类问题评估指标是准确率。它的公式非常简单：
- en: '![Figure 5.14: Formula of the accuracy metric'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.14：准确率指标的公式'
- en: '](img/B16341_05_14.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_14.jpg)'
- en: 'Figure 5.14: Formula of the accuracy metric'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.14：准确率指标的公式
- en: The maximum value for accuracy is `1`, which means the model correctly predicts
    100% of the cases. Its minimum value is `0`, where the model can't predict any
    case correctly.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率的最大值为`1`，表示模型正确预测了100%的案例。其最小值为`0`，表示模型无法正确预测任何案例。
- en: 'For a binary classifier, the number of correct predictions is the number of
    observations with a value of `0` or `1` as the correctly predicted value:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二分类器，正确预测的数量是指那些值为`0`或`1`的观察结果，且这些值为正确预测的值：
- en: '![Figure 5.15: Formula of the accuracy metric for a binary classifier'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.15：二分类器准确率指标的公式'
- en: '](img/B16341_05_15.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_15.jpg)'
- en: 'Figure 5.15: Formula of the accuracy metric for a binary classifier'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.15：二分类器的准确度指标公式
- en: 'Say you are assessing the performance of two different binary classifiers predicting
    the outcome on 10,000 observations on the test set. The first model correctly
    predicted 5,000 instances of value `0` and 3,000 instances of value `1`. Its accuracy
    score will be as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在评估两个不同的二分类器在测试集上对 10,000 个观察结果的预测表现。第一个模型正确预测了 5,000 个值为 `0` 的实例和 3,000
    个值为 `1` 的实例。其准确度得分将如下：
- en: '![Figure 5.16: Formula for the accuracy of model1'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.16：模型 1 准确度公式'
- en: '](img/B16341_05_16.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_16.jpg)'
- en: 'Figure 5.16: Formula for the accuracy of model1'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.16：模型 1 准确度公式
- en: 'The second model correctly predicted the value `0` for 500 cases and the value
    `1` for 1,500 observations. Its accuracy score will be as follows:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个模型正确预测了 500 个值为 `0` 的案例和 1,500 个值为 `1` 的案例。其准确度得分将如下：
- en: '![Figure 5.17: Formula for the accuracy of model2'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.17：模型 2 准确度公式'
- en: '](img/B16341_05_17.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_17.jpg)'
- en: 'Figure 5.17: Formula for the accuracy of model2'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.17：模型 2 准确度公式
- en: The first model predicts accurately 80% of the time, while the second model
    is only 20% accurate. In this case, you can say that model 1 is better than model
    2.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个模型在 80% 的情况下预测正确，而第二个模型仅在 20% 的情况下预测正确。在这种情况下，你可以说模型 1 比模型 2 更好。
- en: Even though `0.8` is usually a relatively good score, this does not necessarily
    mean your model is performing well. For instance, say your dataset contains 9,000
    cases of value `0` and 1,000 cases of value `1`. A very simple model that always
    predicts value `0` will achieve an accuracy score of 0.9\. In this case, the first
    model is performing even less well than this extremely simple model. This characteristic
    of such a model that always predicts the most frequent value of a dataset is called
    the `0.9` since the simple model predicts `0`, which is correct 90% of the time.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管`0.8`通常是一个相对较好的分数，但这并不一定意味着你的模型表现良好。例如，假设你的数据集中包含 9,000 个值为 `0` 的案例和 1,000
    个值为 `1` 的案例。一个非常简单的模型，如果总是预测值为 `0`，将会获得 0.9 的准确度。在这种情况下，第一个模型的表现甚至比这个极其简单的模型差。这种总是预测数据集中最频繁值的模型特性被称为
    `0.9`，因为简单模型预测 `0`，它在 90% 的情况下是正确的。
- en: Note
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The accuracy and null accuracy metrics are not specific to binary classification
    but can also be applied to other types of classification.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 准确度和空准确度指标不仅适用于二分类，还可以应用于其他类型的分类。
- en: 'TensorFlow provides a class, `tf.keras.metrics.Accuracy`, that can calculate
    the accuracy score from tensors. This class has a method called `update_state()`
    that takes two tensors as input parameters and will compute the accuracy score
    between them. You can access this score by calling the `result()` method. The
    output result will be a tensor. You can use the `numpy()` method to convert it
    into a NumPy array. Here is an example of how to calculate the accuracy score:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 提供了一个类 `tf.keras.metrics.Accuracy`，可以从张量中计算准确度得分。该类有一个名为 `update_state()`
    的方法，它接受两个张量作为输入参数，并计算它们之间的准确度得分。你可以通过调用 `result()` 方法来访问此得分。输出结果将是一个张量。你可以使用 `numpy()`
    方法将其转换为 NumPy 数组。以下是如何计算准确度得分的示例：
- en: '[PRE28]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'This will result in the following accuracy score:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致以下准确度得分：
- en: '[PRE29]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Note
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: TensorFlow doesn't provide a class for the null accuracy metric, but you can
    easily compute it using `Accuracy()` and provide a tensor with only `1` (or `0`)
    as the predictions.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 并没有为空准确度指标提供一个类，但你可以通过使用 `Accuracy()`，并提供一个仅包含 `1`（或 `0`）的预测张量，轻松计算它。
- en: Precision, Recall, and the F1 Score
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 精确度、召回率和 F1 分数
- en: In the previous section, you learned how to use the accuracy metric to assess
    the performance of a model and compare it against a baseline called the null accuracy.
    The accuracy score is widely used as it is well known to non-technical audiences,
    but it does have some limitations. Consider the following example.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你学习了如何使用准确度指标来评估模型的表现，并将其与称为“空准确度”的基准进行比较。准确度得分被广泛使用，因为它对于非技术性听众来说是熟知的，但它也有一些局限性。考虑以下示例。
- en: '![Figure 5.18: Example of model predictions versus actual values'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.18：模型预测与实际值的示例'
- en: '](img/B16341_05_18.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_18.jpg)'
- en: 'Figure 5.18: Example of model predictions versus actual values'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.18：模型预测与实际值的示例
- en: This model achieves an accuracy score of 0.981 ![Diagram
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的准确度得分为 0.981！![图示
- en: Description automatically generated](img/B16341_05_18a.png), which is quite
    high. But if this model is used to predict whether a person has a disease, it
    will only predict correctly in a single case. It incorrectly predicted in nine
    cases that these people are not sick while they actually have the given disease.
    At the same time, it incorrectly predicted sickness for 10 people who were actually
    healthy. This model's performance, then, is clearly unsatisfactory. Unfortunately,
    the accuracy score is simply an overall score, and it doesn't tell you where the
    model is performing badly.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B16341_05_18a.png)，这个值相当高。但如果这个模型用于预测一个人是否患有某种疾病，它只会在一个案例中预测正确。在其他九个案例中，它错误地预测这些人没有得病，而实际上他们有该疾病。同时，它错误地预测了10个实际上健康的人为患病。由此可见，这个模型的表现显然不令人满意。不幸的是，准确率得分只是一个整体得分，它并不能告诉你模型表现不好的地方。
- en: 'Luckily, other metrics provide a better assessment of a model, such as precision,
    recall, or F1 score. All three of these metrics have the same range of values
    as the accuracy score: `1` is the perfect score, wherein all observations are
    predicted correctly, and `0` is the worst, wherein there is no correct prediction
    at all.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，其他指标可以更好地评估模型，比如精确度、召回率或 F1 分数。这三项指标的取值范围与准确率得分相同：`1` 表示完美得分，所有观察值都预测正确，`0`
    是最差得分，意味着没有任何正确的预测。
- en: 'But before looking at them, you need to be familiar with the following definitions:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 但在查看它们之前，你需要了解以下定义：
- en: '**True Positive (TP)**: All the observations where the actual value and the
    corresponding prediction are both true'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真阳性（TP）**：所有实际值和相应预测都为真（即正类）的观察值'
- en: '**True Negative (TN)**: All the observations where the actual value and the
    corresponding prediction are both false'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真负（TN）**：所有实际值和相应预测都为假（即负类）的观察值'
- en: '**False Positive (FP)**: All the observations where the prediction is true,
    but the values are actually false'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性（FP）**：所有预测为真，但实际值为假的观察值'
- en: '**False Negative (FN)**: All the observations where the prediction is false,
    but the values are actually true'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阴性（FN）**：所有预测为假，但实际值为真的观察值'
- en: 'Taking the same example as *Figure 5.18*, you will get the following:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 以 *图 5.18* 为例，你将得到以下结果：
- en: TP = 1
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TP = 1
- en: TN = 980
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TN = 980
- en: FP = 10
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FP = 10
- en: FN = 9
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FN = 9
- en: 'This is seen in the following table:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这在下表中可以看到：
- en: '![Figure 5.19: Example of TP, TN, FP, and FN'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.19：TP、TN、FP 和 FN 示例'
- en: '](img/B16341_05_19.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_19.jpg)'
- en: 'Figure 5.19: Example of TP, TN, FP, and FN'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.19：TP、TN、FP 和 FN 示例
- en: 'The precision score is a metric that assesses whether a model has predicted
    a lot of FPs. Its formula is as follows:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度得分是一个评估模型是否预测了大量假阳性的指标。其公式如下：
- en: '![Figure 5.20: Formula of precision'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.20：精确度公式'
- en: '](img/B16341_05_20.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_20.jpg)'
- en: 'Figure 5.20: Formula of precision'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.20：精确度公式
- en: In the preceding example, the precision score will be ![A picture containing
    text
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，精确度得分为 ![A picture containing text
- en: Description automatically generated](img/B16341_05_20a.png). You can see this
    model is making a lot of mistakes and has predicted a lot of FPs compared to the
    actual TP.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成](img/B16341_05_20a.png)。你可以看到该模型犯了很多错误，并且预测了大量的假阳性（FP），而实际的真阳性（TP）则相对较少。
- en: 'Recall is used to assess the number of FNs compared to TPs. Its formula is
    as follows:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率用于评估假阴性（FN）与真阳性（TP）之比。其公式如下：
- en: '![Figure 5.21: Formula of recall'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.21：召回率公式'
- en: '](img/B16341_05_21.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_21.jpg)'
- en: 'Figure 5.21: Formula of recall'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.21：召回率公式
- en: In the preceding example, the recall score will be ![Text
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，召回率得分为 ![文本
- en: Description automatically generated with medium confidence](img/B16341_05_21a.png).
    With this metric, you can see that the model is not performing well and is predicting
    a lot of FNs.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成，信心中等](img/B16341_05_21a.png)。通过这个指标，你可以看到模型表现不好，预测了大量的假阴性（FN）。
- en: 'Finally, the F1 score is a metric that combines both precision and recall (it
    is the harmonic mean of precision and recall). Its formula is as follows:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，F1 分数是一个结合了精确度和召回率的指标（它是精确度和召回率的调和平均数）。其公式如下：
- en: '![Figure 5.22: Formula for the F1 score'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.22：F1 分数公式'
- en: '](img/B16341_05_22.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_22.jpg)'
- en: 'Figure 5.22: Formula for the F1 score'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.22：F1 分数的公式
- en: Taking the same example as the preceding, the F1 score will be ![Formula](img/B16341_05_22a.png)
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 以与前述相同的例子，F1 分数将为 ![公式](img/B16341_05_22a.png)
- en: The model has achieved an F1 score of `0.095`, which is very different from
    its accuracy score of `0.981`. So, the F1 score is a good performance metric when
    you want to emphasize the incorrect predictions—the score considers the number
    of FNs and FPs in the score, as well as the TPs and TNs.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 模型实现了`0.095`的F1分数，这与其`0.981`的准确度分数非常不同。因此，当你希望强调不正确的预测时，F1分数是一个很好的性能指标——该分数考虑了FN和FP的数量，以及TP和TN。
- en: Note
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: As with accuracy, precision, and recall performance metrics, the F1 score can
    also be applied to other types of classification.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 与准确度、精确度和召回率性能指标一样，F1分数也可应用于其他类型的分类。
- en: 'You can easily calculate precision and recall with TensorFlow by using the
    respective classes of `Precision()` and `Recall()`:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用`Precision()`和`Recall()`的相应类来轻松计算TensorFlow中的精确度和召回率：
- en: '[PRE30]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This results in the following output:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致以下输出：
- en: '![Figure 5.23: Precision and recall scores of the provided example'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.23：提供示例的精确度和召回率分数'
- en: '](img/B16341_05_23.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_23.jpg)'
- en: 'Figure 5.23: Precision and recall scores of the provided example'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.23：提供示例的精确度和召回率分数
- en: Note
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: TensorFlow doesn't provide a class to calculate the F1 score, but this can easily
    be done by creating a custom metric. This will be covered in *Exercise 5.02*,
    *Classification Evaluation Metrics*.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow并未提供用于计算F1分数的类，但可以通过创建自定义指标来轻松实现这一功能。这将在*练习 5.02*，*分类评估指标*中介绍。
- en: Confusion Matrices
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: A confusion matrix is not a performance metric *per se*, but more a graphical
    tool used to visualize the predictions of a model against the actual values. You
    have actually already seen an example of this in the previous section with *Figure
    5.18*.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵本身并不是一个性能指标，而更多是用于可视化模型预测与实际值之间关系的图形工具。在前一节中，你已经看到了*图 5.18* 的一个示例。
- en: A confusion matrix will show all the possible values of the predictions on one
    axis (for example, the horizontal axis) and the actual values on the other axis
    (the vertical axis). At the intersection of each combination of predicted and
    actual values, you will record the number of observations that fall under this
    case.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵将显示预测值（例如，水平轴）和实际值（例如，垂直轴）的所有可能值。在每个预测和实际值组合的交点处，你将记录属于此情况的观察数。
- en: 'For a binary classification, the confusion matrix will look like the following:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 对于二元分类，混淆矩阵如下所示：
- en: '![Figure 5.24: Confusion matrix for a binary classification'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.24：二元分类的混淆矩阵'
- en: '](img/B16341_05_24.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_24.jpg)'
- en: 'Figure 5.24: Confusion matrix for a binary classification'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.24：二元分类的混淆矩阵
- en: The ideal situation will be that all the values sit on the diagonal of this
    matrix. This will mean your model is correctly predicting all possible values.
    All values outside of this diagonal are where your model made some mistakes.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况是所有值都位于该矩阵的对角线上。这意味着你的模型正确预测了所有可能的值。在对角线之外的所有值是模型犯错的地方。
- en: Note
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Confusion matrices can also be used for multi-class classification and are not
    specific to binary classification only.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵也可用于多类分类，不仅限于二元分类。
- en: 'Run the code below to see the confusion matrix:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 运行下面的代码查看混淆矩阵：
- en: '[PRE31]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'This will display the following output:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示以下输出：
- en: '![Figure 5.25: TensorFlow confusion matrix'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.25：TensorFlow 混淆矩阵'
- en: '](img/B16341_05_25.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_25.jpg)'
- en: 'Figure 5.25: TensorFlow confusion matrix'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.25：TensorFlow 混淆矩阵
- en: 'The preceding output shows the confusion matrix. From it, you can see that
    the model has predicted the following results: two TPs, one TN, two FPs, and one
    FN.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 前述输出显示了混淆矩阵。从中可以看出，模型预测了以下结果：两个TP、一个TN、两个FP和一个FN。
- en: In the next exercise, you will apply these performance metrics to the same logistic
    regression model that you created in *Exercise 5.01*, *Building a Logistic Regression
    Model*.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一练习中，你将应用这些性能指标到与*练习 5.01*，*构建逻辑回归模型*相同的逻辑回归模型。
- en: 'Exercise 5.02: Classification Evaluation Metrics'
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 5.02：分类评估指标
- en: 'In this exercise, you will reuse the same logistic regression model as in *Exercise
    5.01*, *Building a Logistic Regression Model*, and assess its performance by looking
    at different performance metrics: accuracy, precision, recall, and F1 score.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，你将重复使用与*练习 5.01*，*构建逻辑回归模型*相同的逻辑回归模型，并通过查看不同的性能指标来评估其性能：准确度、精确度、召回率和F1分数。
- en: The original dataset was shared by Stephen Tridgell from the University of Sydney.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集由悉尼大学的Stephen Tridgell分享。
- en: Note
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The training dataset can be accessed here: [https://packt.link/QJGpA](https://packt.link/QJGpA).'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集可以通过以下链接访问：[https://packt.link/QJGpA](https://packt.link/QJGpA)。
- en: 'The test dataset can be accessed here: [https://packt.link/ix5rW](https://packt.link/ix5rW).'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据集可以通过以下链接访问：[https://packt.link/ix5rW](https://packt.link/ix5rW)。
- en: 'The model from *Exercise 5.01*, *Building a Logistic Regression Model*, can
    be found here: [https://packt.link/sSRQL](https://packt.link/sSRQL).'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '*练习5.01*中的模型，*构建逻辑回归模型*，可以通过以下链接找到：[https://packt.link/sSRQL](https://packt.link/sSRQL)。'
- en: 'Now, run the following instructions:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，运行以下指令：
- en: Open a new Jupyter notebook.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Jupyter笔记本。
- en: 'Import the pandas library and use `pd` as the alias:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入pandas库，并使用`pd`作为别名：
- en: '[PRE32]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Create a variable called `train_url` that contains the URL to the training
    set:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`train_url`的变量，包含训练集的URL：
- en: '[PRE33]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Load the training dataset into a `DataFrame()` function called `X_train` using
    `read_csv()` method, provide the URL to the CSV file, and set `header=None` as
    the dataset doesn''t provide column names:'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`read_csv()`方法将训练数据集加载到名为`X_train`的`DataFrame()`函数中，提供CSV文件的URL，并设置`header=None`，因为数据集没有提供列名：
- en: '[PRE34]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Extract the target variable (column `0`) using the `pop()` method and save
    it in a variable called `y_train`:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pop()`方法提取目标变量（第`0`列），并将其保存在名为`y_train`的变量中：
- en: '[PRE35]'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Create a variable called `test_url` that contains the URL to the test set:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`test_url`的变量，包含测试集的URL：
- en: '[PRE36]'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Load the test dataset into a `DataFrame()` function called `X_test` using `read_csv()`
    method, provide the URL to the CSV file, and set `header=None` as the dataset
    doesn''t provide column names:'
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`read_csv()`方法将测试数据集加载到名为`X_test`的`DataFrame()`函数中，提供CSV文件的URL，并设置`header=None`，因为数据集没有提供列名：
- en: '[PRE37]'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Extract the target variable (column `0`) using the `pop()` method and save
    it in a variable called `y_test`:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pop()`方法提取目标变量（第`0`列），并将其保存在名为`y_test`的变量中：
- en: '[PRE38]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Import the `tensorflow` library using `tf` as the alias and import the `get_file()`
    method from `tensorflow.keras.utils`:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`tf`作为别名导入`tensorflow`库，并从`tensorflow.keras.utils`导入`get_file()`方法：
- en: '[PRE39]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Create a variable called `model_url` that contains the URL to the model:'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`model_url`的变量，包含模型的URL：
- en: '[PRE40]'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Download the model locally using the `get_file()` method by providing the name
    (`exercise5_01_model.h5`) of the file and its URL. Save the output to a variable
    called `model_path`:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`get_file()`方法，通过提供文件名（`exercise5_01_model.h5`）及其URL将模型下载到本地。将输出保存到一个名为`model_path`的变量中：
- en: '[PRE41]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Load the model with `tf.keras.models.load_model()` and specify the local path
    to the model:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`tf.keras.models.load_model()`加载模型，并指定模型的本地路径：
- en: '[PRE42]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Print the model summary using the `summary()` method:'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`summary()`方法打印模型摘要：
- en: '[PRE43]'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The expected output will be as follows:'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '![Figure 5.26: Summary of the model'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.26：模型总结'
- en: '](img/B16341_05_26.jpg)'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_26.jpg)'
- en: 'Figure 5.26: Summary of the model'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.26：模型总结
- en: The preceding output shows the same architecture as the model from *Exercise 5.01*,
    *Building a Logistic Regression Model*.
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述输出展示了与*练习5.01*中相同的架构，即*构建逻辑回归模型*。
- en: 'Predict the results of the test set using `predict()` method. Save it in a
    variable called `preds_proba` and display its first five values:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`predict()`方法预测测试集的结果。将其保存在一个名为`preds_proba`的变量中，并显示其前五个值：
- en: '[PRE44]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The expected output will be as follows:'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '![Figure 5.27: Predicted probabilities of the test set'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.27：测试集的预测概率'
- en: '](img/B16341_05_27.jpg)'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_27.jpg)'
- en: 'Figure 5.27: Predicted probabilities of the test set'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.27：测试集的预测概率
- en: The outputs are the predicted probabilities of being `1` (or true) for each
    observation. You need to convert these probabilities into `0` and `1` only. To
    do so, you will need to consider all cases with a probability greater than or
    equal to `0.5` to be `1` (or true), and `0` (or false) for the records with a
    probability lower than `0.5`.
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出为每个观察值为`1`（或为真）的预测概率。你需要将这些概率转换为`0`和`1`。为此，你需要将所有概率大于或等于`0.5`的情况视为`1`（或为真），而对于概率小于`0.5`的记录则视为`0`（或为假）。
- en: 'Convert the predicted probabilities into `1` when the probability is greater
    than or equal to `0.5`, and `0` when below `0.5`. Save the results in a variable
    called `preds` and print its first five rows:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当预测概率大于或等于`0.5`时，将其转换为`1`，当小于`0.5`时转换为`0`。将结果保存在名为`preds`的变量中，并打印其前五行：
- en: '[PRE45]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The expected output will be as follows:'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '![Figure 5.28: Predictions of the test set'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.28：测试集的预测结果'
- en: '](img/B16341_05_28.jpg)'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_28.jpg)'
- en: 'Figure 5.28: Predictions of the test set'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.28：测试集的预测结果
- en: 'Now the predictions have been converted to binary values: true (which equals
    `1`) and false (which equals `0`).'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，预测结果已转换为二值：真（等于`1`）和假（等于`0`）。
- en: 'Import `Accuracy`, `Precision`, and `Recall` from `tensorflow.keras.metrics`:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tensorflow.keras.metrics`导入`Accuracy`、`Precision`和`Recall`：
- en: '[PRE46]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Instantiate `Accuracy`, `Precision`, and `Recall` objects and save them in
    variables called `acc`, `pres`, and `rec`, respectively:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化`Accuracy`、`Precision`和`Recall`对象，并将其保存在名为`acc`、`pres`和`rec`的变量中：
- en: '[PRE47]'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Calculate the accuracy score on the test set with the `update_state()`, `result()`,
    and `numpy()` methods. Save the results in a variable called `acc_results` and
    print its content:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`update_state()`、`result()`和`numpy()`方法计算测试集上的准确度分数。将结果保存在名为`acc_results`的变量中并打印其内容：
- en: '[PRE48]'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The expected output will be as follows:'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '[PRE49]'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: This model achieved an accuracy score of `0.597`.
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该模型的准确率为`0.597`。
- en: 'Calculate the precision score on the test set with the `update_state()`, `result()`,
    and `numpy()` methods. Save the results in a variable called `prec_results` and
    print its content:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`update_state()`、`result()`和`numpy()`方法计算测试集上的精确度分数。将结果保存在名为`prec_results`的变量中并打印其内容：
- en: '[PRE50]'
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The expected output will be as follows:'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '[PRE51]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: This model achieved a precision score of `0.596`.
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该模型的精确度为`0.596`。
- en: 'Calculate the recall score on the test set with the `update_state()`, `result()`,
    and `numpy()` methods. Save the results in a variable called `rec_results` and
    print its content:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`update_state()`、`result()`和`numpy()`方法计算测试集上的召回率分数。将结果保存在名为`rec_results`的变量中并打印其内容：
- en: '[PRE52]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The expected output will be as follows:'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '[PRE53]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: This model achieved a recall score of `0.629`.
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该模型的召回率为`0.629`。
- en: 'Calculate the F1 score by applying the formula shown in the previous section.
    Save the result in a variable called `f1` and print its content:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用上一节中显示的公式计算F1分数。将结果保存在名为`f1`的变量中并打印其内容：
- en: '[PRE54]'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The expected output will be as follows:'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '[PRE55]'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Overall, the model has achieved quite a low score close to `0.6` for all four
    different metrics: accuracy, precision, recall, and F1 score. So, this model is
    making almost as many correct predictions as bad ones. You may try on your own
    to build another model and see whether you can improve its performance.'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 总体而言，模型在准确率、精确度、召回率和F1分数这四个不同指标上都取得了接近`0.6`的较低分数。因此，该模型的正确预测和错误预测几乎一样多。你可以尝试自己构建另一个模型，看看是否能提高其表现。
- en: In the section ahead, you will be looking at expanding classification to more
    than two possible values with multi-class classification.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，你将学习如何通过多类分类将分类扩展到超过两个可能值。
- en: Multi-Class Classification
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多类分类
- en: 'With binary classification, you were limited to dealing with target variables
    that can only take two possible values: `0` and `1` (false or true). Multi-class
    classification can be seen as an extension of this and allows the target variable
    to have more than two values (or you can say binary classification is just a subset
    of multi-class classification). For instance, a model that predicts different
    levels of disease severity for a patient or another one that classifies users
    into different groups based on their past shopping behaviors will be multi-class
    classifiers.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 使用二分类时，你只能处理目标变量，它只能取两个可能的值：`0`和`1`（假或真）。多类分类可以看作是二分类的扩展，它允许目标变量拥有超过两个值（或者可以说，二分类是多类分类的一个子集）。例如，预测患者疾病严重程度的模型，或者根据用户过去的购物行为将其分类到不同组的模型，都属于多类分类器。
- en: In the next section, you will dive into the softmax function, which is used
    for multi-class classification.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将深入了解Softmax函数，它用于多类分类。
- en: The Softmax Function
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Softmax函数
- en: 'Binary classifiers require a specific activation function for the last fully
    connected layer of a neural network, which is sigmoid. The activation function
    specific to multi-class classifiers is different. It is softmax. Its formula is
    as follows:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 二分类器需要为神经网络的最后一个全连接层使用特定的激活函数，即sigmoid。多类分类器的激活函数不同，它是softmax。其公式如下：
- en: '![Figure 5.29: Formula of softmax function'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.29：Softmax函数公式'
- en: '](img/B16341_05_29.jpg)'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_29.jpg)'
- en: 'Figure 5.29: Formula of softmax function'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.29：Softmax函数公式
- en: '![Formula 1](img/B16341_05_29a.png) corresponds to the predicted value for
    class `i`.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '![公式 1](img/B16341_05_29a.png) 对应于类别`i`的预测值。'
- en: '![Formula 1](img/B16341_05_29b.png) corresponds to the predicted value for
    class `j`.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '![公式 1](img/B16341_05_29b.png) 对应于类别`j`的预测值。'
- en: This formula will be applied to each possible value of the target variable.
    If you have 10 possible values, then this activation function will calculate 10
    different softmax values.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 此公式将应用于目标变量的每个可能值。如果有 10 个可能的值，那么该激活函数将计算 10 个不同的 softmax 值。
- en: Note that softmax exponentiates the predicted values on both the numerator and
    the denominator. The reason behind this is that the exponential function magnifies
    small changes between predicted values and makes probabilities lie closer to `0`
    or `1` for the purpose of interpreting the resulting output. For instance, `exp(2)
    = 7.39` while `exp(2.2) = 9.03`. So, if two classes have predicted values close
    to each other, the difference between their exponentiated values will be much
    bigger and therefore it will be easier to select the higher one.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，softmax 会对分子和分母上的预测值进行指数运算。其背后的原因是，指数函数放大了预测值之间的微小变化，并使得概率更接近`0`或`1`，以便更好地解释最终的输出。例如，`exp(2)
    = 7.39`，而`exp(2.2) = 9.03`。因此，如果两个类别的预测值非常接近，它们的指数化值之间的差异将变得更大，从而更容易选择较大的一个。
- en: 'The result of the softmax function is between `0` and `1` as the method divides
    the value for one class by the sum of all the classes. So, the actual output of
    a softmax function is the probability of the relevant class being the final prediction:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: softmax 函数的结果介于`0`和`1`之间，因为该方法将一个类别的值除以所有类别值的总和。因此，softmax 函数的实际输出是相关类别为最终预测结果的概率：
- en: '![Figure 5.30: Example of softmax transformation'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.30：Softmax 转换示例'
- en: '](img/B16341_05_30.jpg)'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_30.jpg)'
- en: 'Figure 5.30: Example of softmax transformation'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.30：Softmax 转换示例
- en: In the preceding example, the target variable has five different values, and
    the softmax function transforms them into probabilities. The first class (`0`)
    is the one with the highest probability, and this will be the final prediction.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，目标变量有五个不同的值，softmax 函数将它们转换为概率。第一个类别（`0`）是具有最高概率的类别，这将是最终的预测结果。
- en: Categorical Cross-Entropy
  id: totrans-350
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 类别交叉熵
- en: 'Multi-class classification also requires a specific loss function that is different
    from the binary cross-entropy for binary classifiers. For multi-class classification,
    the loss function is categorical cross-entropy. Its formula is as follows:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 多类分类还需要一个特定的损失函数，这与二分类器使用的二元交叉熵不同。对于多类分类，损失函数是类别交叉熵。其公式如下：
- en: '![Figure 5.31: Formula of categorical cross-entropy'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.31：类别交叉熵的公式'
- en: '](img/B16341_05_31.jpg)'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_31.jpg)'
- en: 'Figure 5.31: Formula of categorical cross-entropy'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.31：类别交叉熵的公式
- en: '![Formula](img/B16341_05_31a.png) represents the probability of the actual
    value for the observation `i` to be of class `j`.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '![公式](img/B16341_05_31a.png) 表示观察值`i`属于类别`j`的实际值的概率。'
- en: '![Formula 1](img/B16341_05_31b.png)represents the predicted probability for
    the observation `i` to be of class `j`.'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: '![公式 1](img/B16341_05_31b.png) 表示观察值`i`属于类别`j`的预测概率。'
- en: 'TensorFlow provides two different classes for this loss function: `CategoricalCrossentropy()`
    and `SparseCategoricalCrossentropy()`:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 提供了两个不同的类别来计算这个损失函数：`CategoricalCrossentropy()` 和 `SparseCategoricalCrossentropy()`：
- en: '[PRE56]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The difference between them lies in the format of the target variable. If the
    actual values are stored as a one-hot encoding representing the actual class,
    then you will need to use `CategoricalCrossentropy()`. On the other hand, if the
    response variable is stored as integers for representing the actual classes, you
    will have to use `SparseCategoricalCrossentropy()`:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 它们之间的区别在于目标变量的格式。如果实际值以独热编码存储，表示实际类别，则需要使用 `CategoricalCrossentropy()`。另一方面，如果响应变量以整数形式存储，表示实际类别，则需要使用
    `SparseCategoricalCrossentropy()`：
- en: '![Figure 5.32: Loss function to be used depending on the format of the target
    variable'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.32：根据目标变量的格式使用的损失函数'
- en: '](img/B16341_05_32.jpg)'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_32.jpg)'
- en: 'Figure 5.32: Loss function to be used depending on the format of the target
    variable'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.32：根据目标变量的格式使用的损失函数
- en: 'The output of a multi-class model will be a vector containing probabilities
    for each class of the target variable, such as the following:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 多类模型的输出将是一个包含每个类别概率的向量，如下所示：
- en: '[PRE57]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The first value (`0.54`) corresponds to the probability of having the class
    at index 0, `0.016` is the probability of the class at index 1, while `0.09` corresponds
    to the probability for the class of index 2, and so on.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个值（`0.54`）对应于索引 0 类别的概率，`0.016` 是索引 1 类别的概率，而 `0.09` 对应于索引 2 类别的概率，依此类推。
- en: 'In order to get the final prediction (that is, the class with the highest probability),
    you need to use the `argmax()` function, which will look at all the values from
    a vector, find the maximum one, and return the index associated with it:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 为了得到最终的预测（即具有最高概率的类别），你需要使用 `argmax()` 函数，它会查看向量中的所有值，找到最大值并返回与其相关的索引：
- en: '[PRE58]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'This will display the following output:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 这将显示以下输出：
- en: '[PRE59]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: In the preceding example, the final prediction is `class 0`, which corresponds
    to the vector index with the highest probability (`0.54`).
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，最终的预测是 `类别 0`，这对应于具有最高概率（`0.54`）的向量索引。
- en: Multi-Class Classification Architecture
  id: totrans-371
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多类分类架构
- en: 'The architecture for a multi-class classifier is very similar to logistic regression,
    except that the last layer will contain more units. Each of them corresponds to
    a class of the target variable. For instance, if you are building a model that
    takes as input a vector of size 6 and predicts a response with three different
    values with a single hidden layer, its architecture will look like the following:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 多类分类器的架构与逻辑回归非常相似，区别在于最后一层将包含更多的单元。每个单元对应于目标变量的一个类。例如，如果你正在构建一个输入向量大小为 6 并使用单一隐藏层预测具有三种不同值的响应的模型，则其架构如下所示：
- en: '![Figure 5.33: Architecture of a multi-class classifier'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.33：多类分类器的架构'
- en: '](img/B16341_05_33.jpg)'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_33.jpg)'
- en: 'Figure 5.33: Architecture of a multi-class classifier'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.33：多类分类器的架构
- en: 'The softmax activation function at the last layer provides a probability of
    occurrence for each of the possible classes: `A`, `B`, and `C`. These probabilities
    are dependent on each other as there should be only one class predicted at the
    end. If class `A` is more likely to be the prediction (as in the preceding example),
    then the probabilities for the remaining classes (`B` and `C`) should be lower.
    Note that the sum of all the class probabilities equals `1`. So, they are indeed
    dependent on one another.'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一层的 softmax 激活函数为每个可能类别提供了发生的概率：`A`、`B` 和 `C`。这些概率是相互依赖的，因为最终应该只预测一个类别。如果类别
    `A` 更有可能成为预测（如前面的例子所示），那么其余类别（`B` 和 `C`）的概率应该较低。请注意，所有类别的概率总和为 `1`，因此它们确实是相互依赖的。
- en: Now that you know all the building blocks, you can build a multi-class classifier
    in the following exercise.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了所有的构建模块，可以在接下来的练习中构建一个多类分类器。
- en: 'Exercise 5.03: Building a Multi-Class Model'
  id: totrans-378
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 5.03：构建一个多类模型
- en: In this exercise, you will build and train a multi-class classifier in TensorFlow
    that will predict the radiator position of a space shuttle from eight different
    values using the nine different numerical features provided in this dataset.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，你将使用 TensorFlow 构建并训练一个多类分类器，该分类器将使用数据集中提供的九个不同的数值特征，从八个不同的值预测航天飞机的散热器位置。
- en: 'The target variable (last column) contains seven different levels: `Rad.Flow`,
    `Fpv.Close`, `Fpv.Open`, `High`, `Bypass`, `Bpv.Close`, and `Bpv.Open`. Your goal
    is to accurately predict one of these seven levels using the nine features from
    the dataset.'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 目标变量（最后一列）包含七个不同的级别：`Rad.Flow`、`Fpv.Close`、`Fpv.Open`、`High`、`Bypass`、`Bpv.Close`
    和 `Bpv.Open`。你的目标是使用数据集中提供的九个特征准确预测这七个级别中的一个。
- en: Note
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The training dataset can be accessed here: [https://packt.link/46iMY](https://packt.link/46iMY).'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集可以通过以下链接访问：[https://packt.link/46iMY](https://packt.link/46iMY)。
- en: 'The test dataset can be accessed here: [https://packt.link/dcNPt](https://packt.link/dcNPt).'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据集可以通过以下链接访问：[https://packt.link/dcNPt](https://packt.link/dcNPt)。
- en: 'The original dataset can be found here: [http://archive.ics.uci.edu/ml/datasets/Statlog+%28Shuttle%29](http://archive.ics.uci.edu/ml/datasets/Statlog+%28Shuttle%29).'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集可以通过以下链接找到：[http://archive.ics.uci.edu/ml/datasets/Statlog+%28Shuttle%29](http://archive.ics.uci.edu/ml/datasets/Statlog+%28Shuttle%29)。
- en: 'Perform the following steps to complete the exercise:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤以完成练习：
- en: Open a new Jupyter notebook.
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter 笔记本。
- en: 'Import the pandas library and use `pd` as the alias:'
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 pandas 库并使用 `pd` 作为别名：
- en: '[PRE60]'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Create a variable called `train_url` that contains the URL to the training
    set:'
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `train_url` 的变量，包含训练集的 URL：
- en: '[PRE61]'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Load the training dataset into a DataFrame called `X_train` using the `read_table()`
    method, provide the URL to the CSV file, use `header=None` as the dataset doesn''t
    provide column names, and use `sep='' ''` as each column is separated by spaces
    in this dataset. Print the first five rows using `head()` method:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `read_table()` 方法将训练数据集加载到名为 `X_train` 的 DataFrame 中，提供 CSV 文件的 URL，使用 `header=None`
    因为数据集没有列名，使用 `sep=' '` 因为数据集中的每一列是由空格分隔的。使用 `head()` 方法打印前五行：
- en: '[PRE62]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'The expected output will be as follows:'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出将如下所示：
- en: '![Figure 5.34: The first five rows of the training set'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.34：训练集的前五行'
- en: '](img/B16341_05_34.jpg)'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_34.jpg)'
- en: 'Figure 5.34: The first five rows of the training set'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.34：训练集的前五行
- en: You can see that the dataset contains 10 columns, and they are all numeric.
    Also, note that the target variable (column `9`) contains different class values.
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以看到数据集包含 10 列，且都是数字类型。另外，注意目标变量（第 `9` 列）包含不同的类别值。
- en: 'Extract the target variable (column `9`) using the `pop()` method and save
    it in a variable called `y_train`:'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pop()` 方法提取目标变量（第 `9` 列），并将其保存在名为 `y_train` 的变量中：
- en: '[PRE63]'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Create a variable called `test_url` that contains the URL to the test set:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `test_url` 的变量，包含测试集的 URL：
- en: '[PRE64]'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Load the test dataset into a DataFrame called `X_test` using `read_table()`,
    provide the URL to the CSV file, set `header=None` as the dataset doesn't provide
    column names, and use `sep=' '` as each column is separated by a space in this
    dataset. Print the first five rows using `head()` method.
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `read_table()` 方法将测试数据集加载到名为 `X_test` 的 DataFrame 中，提供 CSV 文件的 URL，设置 `header=None`
    因为数据集没有列名，使用 `sep=' '` 因为数据集中的每一列是由空格分隔的。使用 `head()` 方法打印前五行。
- en: '[PRE65]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The expected output will be as follows:'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出将如下所示：
- en: '![Figure 5.35: The first five rows of the test set'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.35：测试集的前五行'
- en: '](img/B16341_05_35.jpg)'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_35.jpg)'
- en: 'Figure 5.35: The first five rows of the test set'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.35：测试集的前五行
- en: You can see that the test set is very similar to the training one.
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以看到测试集与训练集非常相似。
- en: 'Extract the target variable (column `9`) using the `pop()` method and save
    it in a variable called `y_test`:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pop()` 方法提取目标变量（第 `9` 列），并将其保存在名为 `y_test` 的变量中：
- en: '[PRE66]'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Import the TensorFlow library and use `tf` as the alias:'
  id: totrans-411
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 TensorFlow 库并使用 `tf` 作为别名：
- en: '[PRE67]'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Set the seed for TensorFlow as `8` using `tf.random.set_seed()` to get reproducible
    results:'
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `tf.random.set_seed()` 将 TensorFlow 的种子设置为 `8`，以获得可重现的结果：
- en: '[PRE68]'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Instantiate a sequential model using `tf.keras.Sequential()` and store it in
    a variable called `model`:'
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `tf.keras.Sequential()` 实例化一个顺序模型，并将其保存在一个名为 `model` 的变量中：
- en: '[PRE69]'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Import the `Dense()` class from `tensorflow.keras.layers`:'
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `tensorflow.keras.layers` 导入 `Dense()` 类：
- en: '[PRE70]'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Create a fully connected layer of `512` units with `Dense()` and specify ReLu
    as the activation function and the input shape as `(9,)`, which corresponds to
    the number of features from the dataset. Save it in a variable called `fc1`:'
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `Dense()` 创建一个包含 `512` 单元的全连接层，并指定 ReLu 作为激活函数，同时将输入形状设置为 `(9,)`，这对应于数据集中的特征数量。将其保存在一个名为
    `fc1` 的变量中：
- en: '[PRE71]'
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Create a fully connected layer of `512` units with `Dense()` and specify ReLu
    as the activation function. Save it in a variable called `fc2`:'
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `Dense()` 创建一个包含 `512` 单元的全连接层，并指定 ReLu 作为激活函数。将其保存在一个名为 `fc2` 的变量中：
- en: '[PRE72]'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Create a fully connected layer of `128` units with `Dense()` and specify ReLu
    as the activation function. Save it in a variable called `fc3`:'
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `Dense()` 创建一个包含 `128` 单元的全连接层，并指定 ReLu 作为激活函数。将其保存在一个名为 `fc3` 的变量中：
- en: '[PRE73]'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Again, create a fully connected layer of `128` units with `Dense()` and specify
    ReLu as the activation function. Save it in a variable called `fc4`:'
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次使用 `Dense()` 创建一个包含 `128` 单元的全连接层，并指定 ReLu 作为激活函数。将其保存在一个名为 `fc4` 的变量中：
- en: '[PRE74]'
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Create a fully connected layer of 128 units with `Dense()` and specify softmax
    as the activation function. Save it in a variable called `fc5`:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `Dense()` 创建一个包含 128 单元的全连接层，并指定 softmax 作为激活函数。将其保存在一个名为 `fc5` 的变量中：
- en: '[PRE75]'
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: Sequentially add all five fully connected layers to the model using `add()` method.
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 顺序地将所有五个全连接层添加到模型中，使用 `add()` 方法。
- en: '[PRE76]'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Print the summary of the model using `summary()` method:'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `summary()` 方法打印模型的摘要：
- en: '[PRE77]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The expected output will be as follows:'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出将如下所示：
- en: '![Figure 5.36: Summary of the model architecture'
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.36：模型架构的总结'
- en: '](img/B16341_05_36.jpg)'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_36.jpg)'
- en: 'Figure 5.36: Summary of the model architecture'
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.36：模型架构的总结
- en: The preceding output shows that there are five layers in your model (as expected)
    and tells you the number of parameters at each layer. For example, the first layer
    contains `5,120` parameters and the total number of parameters for this model
    is `350,984`. All these parameters will be trained while fitting the model.
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述输出显示了模型中的五个层（如预期），并告知每个层的参数数量。例如，第一层包含`5,120`个参数，该模型的总参数数量为`350,984`。所有这些参数将在拟合模型时进行训练。
- en: 'Instantiate `SparseCategoricalCrossentropy()` from `tf.keras.losses` and save
    it in a variable called `loss`:'
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tf.keras.losses`中实例化`SparseCategoricalCrossentropy()`，并将其保存在名为`loss`的变量中：
- en: '[PRE78]'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Instantiate `Adam()` from `tf.keras.optimizers` with `0.001` as the learning
    rate and save it in a variable called `optimizer`:'
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tf.keras.optimizers`中实例化`Adam()`，将学习率设置为`0.001`，并将其保存在名为`optimizer`的变量中：
- en: '[PRE79]'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Compile the model using the `compile()` method and specify the optimizer and
    loss parameters, with accuracy as the metric to be reported:'
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`compile()`方法编译模型，指定优化器和损失参数，并将准确度作为需要报告的度量：
- en: '[PRE80]'
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Start the model training process using `fit()` method on the training set for
    five epochs:'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`fit()`方法在训练集上开始模型训练过程，训练五个epochs：
- en: '[PRE81]'
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'The expected output will be as follows:'
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下所示：
- en: '![Figure 5.37: Logs of the training process'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.37：训练过程的日志'
- en: '](img/B16341_05_37.jpg)'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_37.jpg)'
- en: 'Figure 5.37: Logs of the training process'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.37：训练过程的日志
- en: The preceding output shows the logs of each epoch during the training of the
    model. Note that it took around 7 seconds to process a single epoch, and the loss
    value decreased from `0.5859` (first epoch) to `0.0351` (fifth epoch).
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述输出显示了训练过程中每个epoch的日志。请注意，处理一个epoch大约需要7秒，损失值从`0.5859`（第一epoch）降至`0.0351`（第五epoch）。
- en: 'Evaluate the performance of the model on the test set using the `evaluate()` method:'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`evaluate()`方法评估模型在测试集上的表现：
- en: '[PRE82]'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'The expected output will be as follows:'
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下所示：
- en: '![Figure 5.38: Performance of the model on the test set'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.38：模型在测试集上的表现'
- en: '](img/B16341_05_38.jpg)'
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_38.jpg)'
- en: 'Figure 5.38: Performance of the model on the test set'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.38：模型在测试集上的表现
- en: In this exercise, you learned how to build and train a multi-class classifier
    to predict an outcome composed of eight different classes. Your model achieved
    an accuracy score close to `0.997` on both the training and test sets, which is
    quite remarkable. This implies that your model correctly predicts the right class
    in the majority of cases.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，你学习了如何构建和训练一个多类分类器，来预测由八个不同类别组成的结果。你的模型在训练集和测试集上的准确率接近`0.997`，这非常了不起。这意味着你的模型在大多数情况下能正确预测类别。
- en: Now, let's consolidate your learning in the following activity.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在下面的活动中巩固你的学习。
- en: 'Activity 5.01: Building a Character Recognition Model with TensorFlow'
  id: totrans-459
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 5.01：使用TensorFlow构建字符识别模型
- en: In this activity, you are tasked with building and training a multi-class classifier
    that will recognize the 26 letters of the alphabet from images. In this dataset,
    the images have been converted into 16 different statistical measures that will
    constitute our features. The goal of this model is to determine which of the 26
    characters each observation belongs to.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，你的任务是构建和训练一个多类分类器，该分类器能够识别图像中的26个字母。在这个数据集中，图像已经转换为16个不同的统计特征，这些特征将作为我们的输入。该模型的目标是确定每个观测值属于26个字母中的哪一个。
- en: 'The original dataset was shared by David J. Slate of the Odesta Corporation,
    and can be found here: [http://archive.ics.uci.edu/ml/datasets/Letter+Recognition](http://archive.ics.uci.edu/ml/datasets/Letter+Recognition).'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集由Odesta公司David J. Slate分享，数据集可以在此找到：[http://archive.ics.uci.edu/ml/datasets/Letter+Recognition](http://archive.ics.uci.edu/ml/datasets/Letter+Recognition)。
- en: 'The dataset can be accessed from here: [https://packt.link/j8m3L](https://packt.link/j8m3L).'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集可以从这里访问：[https://packt.link/j8m3L](https://packt.link/j8m3L)。
- en: 'The following steps will help you to complete the activity:'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成该活动：
- en: Load the data with `read_csv()` from pandas.
  id: totrans-464
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用pandas的`read_csv()`加载数据。
- en: Extract the target variable with `pop()` method from pandas.
  id: totrans-465
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用pandas的`pop()`方法提取目标变量。
- en: Split the data into training (the first 15,000 rows) and test (the last 5,000
    rows) sets.
  id: totrans-466
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分为训练集（前15,000行）和测试集（后5,000行）。
- en: Build the multi-class classifier with five fully connected layers of `512`,
    `512`, `128`, `128`, and `26` units, respectively.
  id: totrans-467
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用五个完全连接的层，分别为`512`、`512`、`128`、`128`和`26`个单元，来构建多类分类器。
- en: Train this model on the training set.
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上训练这个模型。
- en: Evaluate its performance on the test set with `evaluate()` method from TensorFlow.
  id: totrans-469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`evaluate()`方法从TensorFlow评估模型在测试集上的表现。
- en: Print the confusion matrix with `confusion_matrix()` from TensorFlow.
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`confusion_matrix()`方法从TensorFlow打印混淆矩阵。
- en: 'The expected output is as follows:'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '![Figure 5.39: Confusion matrix of the test set'
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.39：测试集的混淆矩阵'
- en: '](img/B16341_05_39.jpg)'
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16341_05_39.jpg)'
- en: 'Figure 5.39: Confusion matrix of the test set'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.39：测试集的混淆矩阵
- en: Note
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor265).
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 该活动的解决方案可以通过[这个链接](B16341_Solution_ePub.xhtml#_idTextAnchor265)找到。
- en: Multi-Label Classification
  id: totrans-477
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多标签分类
- en: Multi-label classification is another type of classification where you predict
    not only one target variable as in binary or multi-class classification, but several
    response variables at the same time. For instance, you can predict multiple outputs
    for the different objects present in an image (for instance, a model will predict
    whether there is a cat, a man, and a car in a given picture) or you can predict
    multiple topics for an article (such as whether the article is about the economy,
    international news, and manufacturing).
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 多标签分类是另一种分类类型，在这种类型中，你不仅预测一个目标变量（如二元分类或多类分类），而是同时预测多个响应变量。例如，你可以预测图像中不同物体的多个输出（例如，模型将预测给定图片中是否有猫、男人和汽车），或者你可以预测文章的多个主题（例如，文章是否涉及经济、国际新闻和制造业）。
- en: Implementing a multi-label classification with neural networks is extremely
    easy, and you have already learned everything required to build one. In TensorFlow,
    a multi-label classifier's architecture will look the same as for multi-class,
    with a final output layer with multiple units corresponding to the number of target
    variables you want to predict. But instead of using softmax as the activation
    function and categorical cross-entropy as the loss function, you will use sigmoid
    and binary cross-entropy as the activation and loss functions, respectively.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 使用神经网络实现多标签分类非常简单，你已经学会了构建它所需的一切。在TensorFlow中，多标签分类器的架构与多类分类器相同，最终的输出层有多个单元，对应于你要预测的目标变量的数量。但不同的是，你将使用sigmoid作为激活函数，binary
    cross-entropy作为损失函数，而不是使用softmax和categorical cross-entropy。
- en: 'The sigmoid function will predict the probability of occurrence for each target variable:'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: Sigmoid函数将预测每个目标变量的发生概率：
- en: '![Figure 5.40: Architecture of the multi-label classifier'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.40：多标签分类器的架构'
- en: '](img/B16341_05_40.jpg)'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16341_05_40.jpg)'
- en: 'Figure 5.40: Architecture of the multi-label classifier'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.40：多标签分类器的架构
- en: In the preceding example, you have three target variables and each of them has
    a probability of occurrence that is independent of the others (their sum will
    not equal 1). This model predicts that targets `2` and `3` are very likely to
    be the outputs for this observation.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，你有三个目标变量，每个目标变量的发生概率是相互独立的（它们的和不会等于1）。该模型预测目标`2`和`3`很可能是这个观测的输出。
- en: 'Conceptually, multi-label classification combines several logistic regression
    models. They will share the same parameters (weights and biases) but with independent
    binary outputs. The last layer of the example of a multi-class classifier in TensorFlow
    will look like this:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上讲，多标签分类结合了多个逻辑回归模型。它们将共享相同的参数（权重和偏差），但每个模型有独立的二进制输出。TensorFlow中多类分类器的最后一层将像这样：
- en: '[PRE83]'
  id: totrans-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'The loss function to be used will be binary cross-entropy:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 将要使用的损失函数是二元交叉熵：
- en: '[PRE84]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: Now, put into action what you have learned so far in the following activity.
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将你所学到的知识付诸实践，在以下活动中动手操作。
- en: 'Activity 5.02: Building a Movie Genre Tagging a Model with TensorFlow'
  id: totrans-490
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 5.02：使用TensorFlow构建电影类型标签模型
- en: In this activity, you are tasked with building and training a multi-label classifier
    that will predict the genre of a movie from 28 possible values. Each movie can
    be assigned to multiple genres at a time. The features are the top keywords extracted
    from its synopsis. The dataset used for this activity is a subset of the original
    one and contains only 20,000 rows.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，你的任务是构建并训练一个多标签分类器，该分类器将预测电影的类型，涵盖28种可能的类别。每部电影可以同时被分配到多个类型。特征是从电影简介中提取的主要关键词。该活动使用的数据集是原始数据集的一个子集，包含了20,000行数据。
- en: 'The original dataset was shared by IMDb and can be found here: [http://www.uco.es/kdis/mllresources/#ImdbDesc](http://www.uco.es/kdis/mllresources/#ImdbDesc).'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 原始数据集由 IMDb 提供，可以从这里找到：[http://www.uco.es/kdis/mllresources/#ImdbDesc](http://www.uco.es/kdis/mllresources/#ImdbDesc)。
- en: 'The features of the dataset can be accessed from here: [https://packt.link/yW5ru](https://packt.link/yW5ru).'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的特征可以从这里访问：[https://packt.link/yW5ru](https://packt.link/yW5ru)。
- en: 'The targets of the dataset can be accessed from here: [https://packt.link/8f1mb](https://packt.link/8f1mb).'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的目标可以从这里访问：[https://packt.link/8f1mb](https://packt.link/8f1mb)。
- en: 'The following steps will help you to complete the activity:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将帮助你完成该活动：
- en: Load the features and targets with `read_csv()` from pandas.
  id: totrans-496
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 的 `read_csv()` 加载特征和目标。
- en: Split the data into training (the first 15,000 rows) and test (the last 5,000
    rows) sets.
  id: totrans-497
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据分为训练集（前 15,000 行）和测试集（后 5,000 行）。
- en: Build the multi-class classifier with five fully connected layers of `512`,
    `512`, `128`, `128`, and `28` units, respectively.
  id: totrans-498
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个多类别分类器，包含五个全连接层，分别是 `512`、`512`、`128`、`128` 和 `28` 个单元。
- en: Train this model on the training set.
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上训练此模型。
- en: Evaluate its performance on the test set with `evaluate()` method from TensorFlow.
  id: totrans-500
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 的 `evaluate()` 方法在测试集上评估其性能。
- en: 'The expected output is as follows:'
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出如下：
- en: '![Formula](img/B16341_05_41.jpg)'
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![公式](img/B16341_05_41.jpg)'
- en: 'Figure 5.41: Expected output of Activity 5.02'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.41：活动 5.02 的预期输出
- en: Note
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution to this activity can be found via [this link](B16341_Solution_ePub.xhtml#_idTextAnchor267).
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以通过[此链接](B16341_Solution_ePub.xhtml#_idTextAnchor267)找到。
- en: Summary
  id: totrans-506
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: You started your journey in this chapter with an introduction to classification
    models and their differences compared with regression models. You learned that
    the target variable for classifiers can only contain a limited number of possible
    values.
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 本章开始时，你介绍了分类模型，并与回归模型进行了对比。你了解到，分类器的目标变量只能包含有限数量的可能值。
- en: 'You then explored binary classification, wherein the response variable can
    only be from two possible values: `0` or `1`. You uncovered the specificities
    for building a logistic regression model with TensorFlow using the sigmoid activation
    function and binary cross-entropy as the loss function, and you built your own
    binary classifier for predicting the winning team on the video game Dota 2.'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 接着你探索了二元分类，其中响应变量只能取两个可能的值：`0` 或 `1`。你深入了解了如何使用 TensorFlow 构建逻辑回归模型，采用 sigmoid
    激活函数和二元交叉熵作为损失函数，并为预测视频游戏《Dota 2》中的获胜队伍构建了自己的二元分类器。
- en: After this, you went through the different performance metrics that can be used
    to assess the performance of classifier models. You practiced calculating accuracy,
    precision, recall, and F1 scores with TensorFlow, and also plotted a confusion
    matrix, which is a visual tool to see where the model made correct and incorrect
    predictions.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，你了解了可以用来评估分类器模型性能的不同指标。你练习了使用 TensorFlow 计算准确率、精确度、召回率和 F1 分数，并绘制了混淆矩阵，这是一个用来查看模型正确与错误预测的可视化工具。
- en: Then you dove into the topic of multi-class classification. The difference between
    such models and binary classifiers is that their response variables can take more
    than two possible values. You looked at the softmax activation function and the
    categorical cross-entropy loss function, which are used for training such models
    in TensorFlow.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 接着你深入探讨了多类别分类的主题。这类模型与二元分类器的区别在于，它们的响应变量可以有两个以上的可能值。你研究了 softmax 激活函数和类别交叉熵损失函数，它们在
    TensorFlow 中用于训练这类模型。
- en: Finally, in the last section, you learned about multi-label classification,
    wherein the output can be multiple classes at the same time. In TensorFlow, such
    models can be easily built by constructing an architecture similar to multi-class
    classification but using sigmoid and binary cross-entropy, respectively, as the
    activation and loss functions.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一部分，你了解了多标签分类，其中输出可以同时是多个类别。在 TensorFlow 中，这样的模型可以通过构建类似于多类别分类的架构来轻松实现，但分别使用
    sigmoid 激活函数和二元交叉熵作为损失函数。
- en: In the next chapter, you will learn how to prevent model overfitting by applying
    some regularization techniques, which will help models to better generalize unseen
    data.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，你将学习如何通过应用一些正则化技术来防止模型过拟合，从而帮助模型更好地对未见数据进行泛化。
