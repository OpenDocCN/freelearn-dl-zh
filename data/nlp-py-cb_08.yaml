- en: Advanced NLP Recipes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级NLP示例
- en: 'In this chapter, we will go through the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将讨论以下几种方法：
- en: Creating an NLP pipeline
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个NLP管道
- en: Solving the text similarity problem
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决文本相似性问题
- en: Identifying topics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别话题
- en: Summarizing text
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 摘要文本
- en: Resolving anaphora
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决指代问题
- en: Disambiguating word sense
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决词义歧义
- en: Perform sentiment analysis
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行情感分析
- en: Exploring advanced sentiment analysis
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索高级情感分析
- en: Creating a conversational assistant or chatbot
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个对话助手或聊天机器人
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简介
- en: So far, we have seen how to process input text, identify parts of speech, and
    extract important information (named entities). We've learned a few computer science
    concepts also, such as grammars, parsers, and so on. In this chapter, we will
    dig deeper into advanced topics in **natural language processing** (**NLP**),
    which need several techniques to properly understand and solve them.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了如何处理输入文本、识别词性以及提取重要信息（命名实体）。我们还学到了一些计算机科学的概念，如语法、解析器等等。在本章中，我们将深入探讨**自然语言处理**（**NLP**）中的高级话题，这些话题需要多种技术才能正确理解和解决。
- en: Creating an NLP pipeline
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个NLP管道
- en: In computing, a pipeline can be thought of as a multi-phase data flow system
    where the output from one component is fed to the input of another component.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算中，管道可以被看作是一个多阶段的数据流系统，其中一个组件的输出作为另一个组件的输入。
- en: 'These are the things that happen in a pipeline:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是管道中发生的事情：
- en: Data is flowing all the time from one component to another
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据始终在一个组件到另一个组件之间流动
- en: The component is a black box that should worry about the input data and output
    data
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组件是一个黑箱，应该关注输入数据和输出数据
- en: A well-defined pipeline takes care of the following things.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 一个明确的管道需要处理以下几件事：
- en: The input format of the data that is flowing through each of the components
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个组件中流动的数据的输入格式
- en: The output format of the data that is coming out of each of the components
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个组件输出的数据格式
- en: Making sure that data flow is controlled between components by adjusting the
    velocity of data inflow and outflow
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保通过调整数据流入和流出速度来控制组件之间的数据流动
- en: For example, if you are familiar with Unix/Linux systems and have some exposure
    to working on a shell, you'd have seen the | operator, which is the shell's abstraction
    of a data pipe. We can leverage the | operator to build pipelines in the Unix
    shell.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你熟悉Unix/Linux系统，并且对在shell中工作有一些接触，你会看到|运算符，它是shell的数据管道抽象。我们可以利用|运算符在Unix
    shell中构建管道。
- en: 'Let''s take an example in Unix (for a quick understanding): how do I find the
    number of files in a given directory ?'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个Unix的例子来快速理解：如何在给定目录中查找文件数量？
- en: 'To solve this, we need the following things:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们需要以下几件事：
- en: We need a component (or a command in the Unix context) that reads the directory
    and lists all the files in it
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要一个组件（或在Unix中是一个命令），它读取目录并列出其中的所有文件
- en: We need another component (or a command in the Unix context) that reads the
    lines and prints the count of lines
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要另一个组件（或在Unix中是一个命令），它读取行并打印行数
- en: 'So, we have the solutions to these two requirements. Which are :'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们已经解决了这两个需求。它们是：
- en: The `ls` command
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ls` 命令'
- en: The `wc` command
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wc` 命令'
- en: If we can build a pipeline where we take the output from `ls` and feed it to
    `wc`, we are done.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们能构建一个管道，将`ls`的输出传递给`wc`，那么我们就完成了。
- en: In terms of Unix commands, `ls -l  | wc -l` is a simple pipeline that counts
    the files in a directory.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在Unix命令中，`ls -l | wc -l` 是一个简单的管道，用来计算目录中的文件数量。
- en: 'With this knowledge, let''s get back to the NLP pipeline requirements:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些知识，让我们回到NLP管道的需求：
- en: Input data acquisition
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入数据获取
- en: Breaking the input data into words
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将输入数据分割成单词
- en: Identifying the POS of words in the input data
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别输入数据中单词的词性
- en: Extracting the named entities from the words
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从单词中提取命名实体
- en: Identifying the relationships between named entities
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别命名实体之间的关系
- en: In this recipe, let's try to build the simplest possible pipeline; it acquires
    data from a remote RSS feed and then prints the identified named entities in each
    document.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将尝试构建一个最简单的管道；它从远程RSS源获取数据，并打印每个文档中识别出的命名实体。
- en: Getting ready
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: You should have Python installed, along with the `nltk`, `queue`, `feedparser`,
    and `uuid` libraries.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该安装Python，并且安装`nltk`、`queue`、`feedparser`和`uuid`库。
- en: How to do it...
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: Open Atom editor (or your favorite programming editor).
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Atom编辑器（或你喜欢的编程编辑器）。
- en: Create a new file called `PipelineQ.py`.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`PipelineQ.py`的新文件。
- en: 'Type the following source code:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/c2691bf7-2c41-45ec-b6fb-a508383a6e71.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c2691bf7-2c41-45ec-b6fb-a508383a6e71.png)'
- en: Save the file.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python解释器运行程序。
- en: 'You will see this output:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到这个输出：
- en: '![](img/2432e7f0-57ca-4b03-99d9-b1ac745705af.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2432e7f0-57ca-4b03-99d9-b1ac745705af.png)'
- en: How it works...
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s see how to build this pipeline:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何构建这个管道：
- en: '[PRE0]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'These five instructions import five Python libraries into the current program:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这五个指令将五个Python库导入当前程序：
- en: '`nltk`: Natural language toolkit'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nltk`: 自然语言工具包'
- en: '`threading`: A threading library used to create lightweight tasks within a
    single program'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`threading`: 用于在单个程序中创建轻量级任务的线程库'
- en: '`queue`: A queue library that can be used in a multi-threaded program'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`queue`: 可在多线程程序中使用的队列库'
- en: '`feedparser`: An RSS feed parsing library'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`feedparser`: 一个RSS源解析库'
- en: '`uuid`: An RFC-4122-based uuid version 1, 3, 4, 5-generating library'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`uuid`: 基于RFC-4122的uuid版本1、3、4、5生成库'
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Creating a new empty list to keep track of all the threads in the program:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的空列表，用于跟踪程序中的所有线程：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This instruction creates a list of two queues in a variable `queue`?
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令在变量`queue`中创建一个包含两个队列的列表？
- en: 'Why do we need two queues:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们需要两个队列：
- en: The first queue is used to store tokenized sentences
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个队列用于存储分词后的句子
- en: The second queue is used to store all the POS analyzed words
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个队列用于存储所有已分析的词性（POS）词语
- en: 'This instruction defines a new function, `extractWords()`, which reads a sample
    RSS feed from the internet and stores the words, along with a unique identifier
    for this text:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令定义了一个新函数`extractWords()`，该函数从互联网读取一个示例RSS源，并存储这些单词以及该文本的唯一标识符：
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We are defining a sample URL (entertainment news) from the India Times website:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在定义一个来自印度时报网站的示例URL（娱乐新闻）：
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This instruction invokes the `parse()` function of the `feedparser` library.
    This `parse()` function downloads the content of the URL and converts it into
    a list of news items. Each news item is a dictionary with title and summary keys:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令调用了`feedparser`库的`parse()`函数。这个`parse()`函数下载URL的内容并将其转换为新闻条目列表。每个新闻条目是一个包含标题和摘要键的字典：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We are taking the first five entries from the RSS feed and storing the current
    item in a variable called `entry`:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从RSS源中取出前五条条目，并将当前条目存储在一个名为`entry`的变量中：
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The title of the current RSS feed item is stored in a variable called `text`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当前RSS源条目的标题存储在一个名为`text`的变量中：
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This instruction skips the titles that contain sensitive words. Since we are
    reading the data from the internet, we have to make sure that the data is properly
    sanitized:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令跳过包含敏感词的标题。由于我们从互联网上读取数据，因此我们必须确保数据已正确清理：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Break the input text into words using the `word_tokenize()` function and store
    the result into a variable called `words`:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`word_tokenize()`函数将输入文本分解为单词，并将结果存储在一个名为`words`的变量中：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Create a dictionary called `data` with two key-value pairs, where we are storing
    the UUID and input words under the UUID and input keys respectively:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为`data`的字典，其中包含两个键值对，我们分别将UUID和输入词存储在UUID和input键下：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This instruction stores the dictionary in the first queue, `queues[0]`. The
    second argument is set to true, which indicates that if the queue is full, pause
    the thread:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令将字典存储在第一个队列`queues[0]`中。第二个参数设置为true，这表示如果队列已满，则暂停线程：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'A well-designed pipeline understands that it should control the inflow and
    outflow of the data according to the component''s computation capacity. If not,
    the entire pipeline collapses. This instruction prints the current RSS item that
    we are processing along with its unique ID:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一个设计良好的管道应该根据组件的计算能力来控制数据的流入和流出。如果不这样，整个管道会崩溃。此指令打印出我们正在处理的当前RSS项以及其唯一ID：
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This instruction defines a new function called `extractPOS()`, which reads
    from the first queue, processes the data, and saves the POS of the words in the
    second queue:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令定义了一个名为`extractPOS()`的新函数，该函数从第一个队列读取数据，处理数据，并将词性的词存储在第二个队列中：
- en: '[PRE13]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This is an infinite loop:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个无限循环：
- en: '[PRE14]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'These instructions check whether the first queue is empty. When the queue is
    empty, we stop processing:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指令检查第一个队列是否为空。当队列为空时，我们停止处理：
- en: '[PRE15]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In order to make this program robust, pass the feedback from the first queue.
    This is left as an exercise to the reader. This is the else part, which indicates
    there is some data in the first queue:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使程序更健壮，传递来自第一个队列的反馈。这个部分留给读者练习。这是`else`部分，表示第一个队列中有数据：
- en: '[PRE16]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Take the first item from the queue (in FIFO order):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从队列中取出第一个项目（按FIFO顺序）：
- en: '[PRE17]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Identify the parts of speech in the words:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 识别单词中的词性：
- en: '[PRE18]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Update the first queue, mentioning that we are done with processing the item
    that is just extracted by this thread:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 更新第一个队列，表明我们已完成处理刚刚由该线程提取的项目：
- en: '[PRE19]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Store the POS tagged word list in the second queue so that the next phase in
    the pipeline will execute things. Here also, we are using true for the second
    parameter, which will make sure that the thread will wait if there is no free
    space in the queue:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 将带有词性标注的单词列表存储到第二个队列中，以便管道的下一阶段执行。在这里，我们也使用了`true`作为第二个参数，这将确保如果队列中没有空闲空间，线程会等待：
- en: '[PRE20]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This instruction defines a new function, `extractNE()`, which reads from the
    second queue, processes the POS tagged words, and prints the named entities on
    screen:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令定义了一个新函数，`extractNE()`，它从第二个队列读取，处理带有词性标注的单词，并在屏幕上打印命名实体：
- en: '[PRE21]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This is an infinite loop instruction:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个无限循环指令：
- en: '[PRE22]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If the second queue is empty, then we exit the infinite loop:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果第二个队列为空，则退出无限循环：
- en: '[PRE23]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This instruction picks an element from the second queue and stores it in a data variable:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令从第二个队列中选取一个元素，并将其存储在一个数据变量中：
- en: '[PRE24]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This instruction marks the completion of data processing on the element that
    was just picked from the second queue:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令标记从第二个队列刚刚选取的元素的数据处理完成：
- en: '[PRE25]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This instruction extracts the named entities from the `postags` variable and
    stores it in a variable called `chunks`:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令从`postags`变量中提取命名实体，并将其存储在名为`chunks`的变量中：
- en: '[PRE26]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: These instructions do the following
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指令执行以下操作：
- en: Print the UUID from the data dictionary
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打印数据字典中的UUID
- en: Iterate over all chunks that are identified
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遍历所有已识别的语法块：
- en: We are using a try/except block because not all elements in the tree have the `label()`
    function (they are tuples when no NE is found)
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用了一个`try/except`块，因为树中的并非所有元素都有`label()`函数（当没有找到命名实体时，它们是元组）：
- en: Finally, we call a `print()` function, which prints a newline on screen
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们调用一个`print()`函数，它在屏幕上打印一个换行符：
- en: 'This instruction defines a new function, `runProgram`, which does the pipeline
    setup using threads:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令定义了一个新函数，`runProgram`，它使用线程进行管道设置：
- en: '[PRE27]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'These three instructions create a new thread with `extractWords()` as the function,
    start the thread and add the thread object (`e`) to the list called `threads`:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这三条指令使用`extractWords()`作为函数创建一个新线程，启动该线程并将线程对象（`e`）添加到名为`threads`的列表中：
- en: '[PRE28]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'These instructions create a new thread with `extractPOS()` as the function,
    start the thread, and add the thread object (`p`) to the list variable `threads`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指令使用`extractPOS()`作为函数创建一个新线程，启动该线程，并将线程对象（`p`）添加到列表变量`threads`中：
- en: '[PRE29]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'These instructions create a new thread using `extractNE()` for the code, start
    the thread, and add the thread object (`n`) to the list `threads`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指令使用`extractNE()`为代码创建一个新线程，启动该线程，并将线程对象（`n`）添加到列表`threads`中：
- en: '[PRE30]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'These two instructions release the resources that are allocated to the queues
    once all the processing is done:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这两条指令在所有处理完成后释放分配给队列的资源：
- en: '[PRE31]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'These two instructions iterate over the threads list, store the current thread
    object in a variable, `t`, call the `join()` function to mark the completion of
    the thread, and release resources allocated to the thread:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这两条指令遍历线程列表，将当前线程对象存储在变量`t`中，调用`join()`函数以标记线程完成，并释放分配给该线程的资源：
- en: '[PRE32]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This is the section of the code that is invoked when the program is run with
    the main thread. The `runProgram()` is called, which simulates the entire pipeline:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这是程序在主线程运行时调用的代码部分。调用`runProgram()`，它模拟整个管道：
- en: '[PRE33]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Solving the text similarity problem
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决文本相似性问题
- en: 'The text similarity problem deals with the challenge of finding how close given
    text documents are. Now, when we say close, there are many dimensions in which
    we can say they are closer or far:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 文本相似性问题涉及到找到给定文本文件之间的相似度。现在，当我们说它们相似时，我们可以从多个维度来判断它们是更接近还是更远：
- en: Sentiment/emotion dimension
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 情感/情绪维度
- en: Sense dimension
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 感知维度
- en: Mere presence of certain words
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 某些单词的存在
- en: There are many algorithms available for this; all of them vary in the degree
    of complexity, the resources needed, and the volume of data we are dealing with.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多可用的算法来解决这个问题；它们在复杂度、所需资源以及我们处理的数据量上各不相同。
- en: 'In this recipe, we will use the TF-IDF algorithm to solve the similarity problem.
    So first, let''s understand the basics:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将使用TF-IDF算法来解决相似度问题。所以首先，让我们理解基础知识：
- en: '**Term frequency (TF)**: This technique tries to find the relative importance
    (or frequency) of the word in a given document'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**词频（TF）**：该技术试图找到一个单词在给定文档中的相对重要性（或频率）'
- en: Since we are talking about relative importance, we generally normalize the frequency
    with respect to the total words that are present in the document to compute the
    TF value of a word.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们讨论的是相对重要性，通常会将词频归一化，以便与文档中出现的总词数相比，从而计算出单词的TF值。
- en: '**Inverse document frequency (IDF)** : This technique makes sure that words
    that are frequently used (a, the, and so on) should be given lower weight when
    compared to the words that are rarely used.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逆文档频率（IDF）**：该技术确保频繁使用的词（如 a、the 等）相对于那些很少使用的词，其权重应更低。'
- en: Since both TF and IDF values are decomposed to numbers (fractions), we will
    do a multiplication of these two values for each term against every document and
    build *M* vectors of *N* dimensions (where *N* is the total number of documents
    and *M* are the unique words in all the documents).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 由于TF和IDF值都被分解为数字（分数），我们将对每个词和每个文档的这两个值进行相乘，并构建*M*个*N*维度的向量（其中*N*是文档的总数，*M*是所有文档中的唯一词汇）。
- en: 'Once we have these vectors, we need to find the cosine similarity using the
    following formula on these vectors:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了这些向量，我们需要使用以下公式计算这些向量之间的余弦相似度：
- en: '![](img/4acc3f1a-3759-4c0a-acbe-2e297e6f41be.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4acc3f1a-3759-4c0a-acbe-2e297e6f41be.png)'
- en: Getting ready
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: You should have Python installed, along with the `nltk` and `scikit` libraries.
    Having some understanding of mathematics is helpful.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该安装Python，并且拥有`nltk`和`scikit`库。对数学有一定了解会更有帮助。
- en: How to do it...
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Open atom editor (or your favorite programming editor).
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Atom编辑器（或你最喜欢的编程编辑器）。
- en: Create a new file called `Similarity.py`.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`Similarity.py`的新文件。
- en: 'Type the following source code:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/21458fab-7f37-42a8-8e06-5e6a227a7eed.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/21458fab-7f37-42a8-8e06-5e6a227a7eed.png)'
- en: Save the file.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![](img/f9774ed3-f05c-43c4-9fb6-49a8bba75d10.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f9774ed3-f05c-43c4-9fb6-49a8bba75d10.png)'
- en: How it works...
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s see how we are solving the text similarity problem. These four instructions
    import the necessary libraries that are used in the program:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何解决文本相似度问题。这四个指令导入了程序中使用的必要库：
- en: '[PRE34]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We are defining a new class, `TextSimilarityExample`:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在定义一个新的类，`TextSimilarityExample`：
- en: '[PRE35]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This instruction defines a new constructor for the class:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令为类定义了一个新的构造函数：
- en: '[PRE36]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: This instruction defines sample sentences on which we want to find the similarity.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令定义了我们想要查找相似度的示例句子。
- en: '[PRE37]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We are defining the TF of all the words in a given sentence:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在定义给定句子中所有单词的TF：
- en: '[PRE38]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This function does the following things:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数执行以下操作：
- en: Converts the sentence to lower case and extracts all the words
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将句子转换为小写，并提取所有单词
- en: Finds the frequency distribution of these words using the nltk `FreqDist` function
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用nltk的`FreqDist`函数查找这些单词的频率分布
- en: Iterates over all the dictionary keys, builds the normalized floating values,
    and stores them in a dictionary
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遍历所有字典键，构建归一化的浮动值，并将它们存储在字典中
- en: Returns the dictionary that contains the normalized score for each word in the
    sentence
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 返回包含句子中每个单词归一化分数的字典。
- en: 'We are defining an IDF that finds the IDF value for all the words in all the
    documents:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个IDF，来查找所有文档中所有单词的IDF值：
- en: '[PRE39]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This function does the following things:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数执行以下操作：
- en: We define a local function called `idf()`, which is the formula to find the
    IDF of a given word
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们定义了一个名为`idf()`的局部函数，它是计算给定单词IDF值的公式。
- en: We iterate over all the statements and convert them to lowercase
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们遍历所有语句并将它们转换为小写
- en: Find how many times each word is present across all the documents
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找每个单词在所有文档中出现的次数
- en: Build the IDF value for all words and return the dictionary containing these
    IDF values
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为所有单词构建IDF值，并返回包含这些IDF值的字典
- en: We are now defining a `TF_IDF` (TF multiplied by IDF) for all the documents
    against a given search string.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在正在定义一个`TF_IDF`（TF乘以IDF），用于所有文档和给定的搜索字符串。
- en: '[PRE40]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Let''s see what we are doing here:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们在这里做了什么：
- en: Break the search string into tokens
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将搜索字符串拆分为词元
- en: Build `IDF()` for all sentences in the `self.statements` variable
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为`self.statements`变量中的所有句子构建`IDF()`。
- en: Iterate over all sentences and find the TF for all words in this sentence
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遍历所有句子，找到该句子中所有单词的TF
- en: Filter and use only the words that are present in the input search string and
    build vectors that consist of *tf*idf* values against each document
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤并只使用在输入搜索字符串中出现的单词，并构建包含*tf*idf*值的向量，针对每个文档
- en: Return the list of vectors for each word in the search query
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 返回搜索查询中每个单词的向量列表
- en: 'This function displays the contents of vectors on screen:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数在屏幕上显示向量的内容：
- en: '[PRE41]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Now, in order to find the similarity, as we discussed initially, we need to
    find the Cosine similarity on all the input vectors. We can do all the math ourselves.
    But this time, let's try to use scikit to do all the computations for us.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了找到相似度，正如我们最初讨论的，我们需要在所有输入向量上找到余弦相似度。我们可以自己做所有的数学运算。但这一次，让我们尝试使用scikit来为我们做所有的计算。
- en: '[PRE42]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: In the previous functions, we learned how to build TF and IDF values and finally
    get the TF x IDF values for all the documents.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的函数中，我们学习了如何构建TF和IDF值，并最终得到所有文档的TF x IDF值。
- en: 'Let''s see what we are doing here:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们在这里做了什么：
- en: Defining a new function: `cosineSimilarity()`
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义一个新函数：`cosineSimilarity()`
- en: Creating a new vectorizer object
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个新的向量化对象
- en: Building a matrix of TF-IDF values for all the documents that we are interested
    in, using the `fit_transform()` function
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`fit_transform()`函数构建我们感兴趣的所有文档的TF-IDF矩阵
- en: Later we compare each document with all other documents and see how close they
    are to each other
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们将每个文档与其他所有文档进行比较，看看它们之间的相似度如何
- en: 'This is the `demo()` function and it runs all the other functions we have defined
    before:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`demo()`函数，它运行我们之前定义的所有其他函数：
- en: '[PRE43]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Let's see what we are doing here
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们在这里做了什么
- en: We take the first statement as our input query.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将第一句话作为输入查询。
- en: We build vectors using our own handwritten `TF_IDF()` function.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用自己手写的`TF_IDF()`函数来构建向量。
- en: We display our TF x IDF vectors for all sentences on screen.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在屏幕上显示所有句子的TF x IDF向量。
- en: We print the cosine similarity computed for all the sentences using the `scikit`
    library by invoking the `cosineSimilarity()` function.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`scikit`库通过调用`cosineSimilarity()`函数计算并打印所有句子的余弦相似度。
- en: We are creating a new object for the `TextSimilarityExample()` class and then
    invoking the `demo()` function.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在创建一个新的`TextSimilarityExample()`类对象，然后调用`demo()`函数。
- en: '[PRE44]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Identifying topics
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 识别主题
- en: In the previous chapter, we learned how to do document classification. Beginners
    might think document classification and topic identification are the same, but
    there is a slight difference.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何进行文档分类。初学者可能认为文档分类和主题识别是相同的，但实际上它们有些微小的差别。
- en: Topic identification is the process of discovering topics that are present in
    the input document set. These topics can be multiple words that occur uniquely
    in a given text.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 主题识别是发现输入文档集中存在的主题的过程。这些主题可以是出现在给定文本中的多个唯一单词。
- en: Let's take an example. When we read arbitrary text that contains a mention of
    Sachin Tendulkar, score, win we can understand that the sentence is describing
    cricket. But we may be wrong as well.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举个例子。当我们阅读包含Sachin Tendulkar、score、win等词汇的任意文本时，我们可以理解这句话是在描述板球。然而，我们也可能错了。
- en: In order to find all these types of topics in a given input text, we use the Latent
    Dirichlet allocation algorithm (we could use TF-IDF as well, but since we have
    already explored it in a previous recipe, let's see how LDA works in identifying
    the topic).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在给定的输入文本中找到所有这些类型的主题，我们使用了潜在狄利克雷分配（Latent Dirichlet Allocation, LDA）算法（我们也可以使用TF-IDF，但由于我们在前面的例子中已经探索过它，让我们看看LDA在识别主题中的作用）。
- en: Getting ready
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备中
- en: You should have Python installed, along with the `nltk`, `gensim`, and `feedparser`
    libraries.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该已经安装了Python，以及`nltk`、`gensim`和`feedparser`库。
- en: How to do it...
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Open atom editor (or your favorite programming editor).
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Atom编辑器（或你喜欢的编程编辑器）。
- en: Create a new file called `IdentifyingTopic.py`.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`IdentifyingTopic.py`的新文件。
- en: 'Type the following source code:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/0b4aa55c-b327-4ad5-aa01-d0e95e7a21bd.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0b4aa55c-b327-4ad5-aa01-d0e95e7a21bd.png)'
- en: Save the file.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![](img/c3ba63c9-117a-4bb1-a6a1-0d78dfb1869f.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c3ba63c9-117a-4bb1-a6a1-0d78dfb1869f.png)'
- en: How it works...
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: Let's see how the topic identification program works. These five instructions
    import the necessary libraries into the current program.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看主题识别程序是如何工作的。这五条指令将必要的库导入到当前程序中。
- en: '[PRE45]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'This instruction defines a new class, `IdentifyingTopicExample`:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令定义了一个新类`IdentifyingTopicExample`：
- en: '[PRE46]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This instruction defines a new function, `getDocuments()`, whose responsibility
    is to download few documents from the internet using `feedparser`:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令定义了一个新函数`getDocuments()`，其责任是使用`feedparser`从互联网上下载少量文档：
- en: '[PRE47]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Download all the documents mentioned in the URL and store the list of dictionaries
    into a variable called `feed`:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 下载URL中提到的所有文档，并将字典列表存储在名为`feed`的变量中：
- en: '[PRE48]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Empty the list to keep track of all the documents that we are going to analyze
    further:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 清空列表，以跟踪我们将进一步分析的所有文档：
- en: '[PRE49]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Take the top five documents from the `feed` variable and store the current
    news item into a variable called `entry`:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 从`feed`变量中获取前五篇文档，并将当前新闻条目存储在名为`entry`的变量中：
- en: '[PRE50]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Store the news summary into a variable called `text`:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 将新闻摘要存储在名为`text`的变量中：
- en: '[PRE51]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'If the news article contains any sensitive words, skip those:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 如果新闻文章包含任何敏感词，则跳过这些词：
- en: '[PRE52]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Store the document in the `documents` variable:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 将文档存储在`documents`变量中：
- en: '[PRE53]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Display the current document on the screen:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在屏幕上显示当前文档：
- en: '[PRE54]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Display an informational message to the user that we have collected *N* documents
    from the given `url`:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 向用户显示一条信息，告知我们已从给定的`url`收集了*N*个文档：
- en: '[PRE55]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: This instruction defines a new function, `cleanDocuments()`, whose responsibility
    is to clean the input text (since we are downloading it from the internet, it
    can contain any type of data).
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令定义了一个新函数`cleanDocuments()`，其责任是清理输入文本（因为我们从互联网上下载它，可能包含任何类型的数据）。
- en: '[PRE56]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: We are interested in extracting words that are in the English alphabet. So,
    this tokenizer is defined to break the text into tokens, where each token consists
    of letters from a to z and A-Z. By doing so, we can be sure that punctuation and
    other bad data doesn't come into the processing.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感兴趣的是提取那些属于英语字母表的单词。因此，定义了这个分词器，将文本分解为标记，每个标记由a到z和A-Z的字母组成。通过这种方式，我们可以确保标点符号和其他不良数据不会进入处理。
- en: '[PRE57]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Store the stop words of English in a variable, `en_stop`:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 将英语停用词存储在变量`en_stop`中：
- en: '[PRE58]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Define a empty list called `cleaned`, which is used to store all the cleaned
    and tokenized documents:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个空列表`cleaned`，用于存储所有已清理和分词的文档：
- en: '[PRE59]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Iterate over all the documents we have collected using the `getDocuments()` function:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`getDocuments()`函数遍历我们收集的所有文档：
- en: '[PRE60]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Convert the document to lowercase to avoid treating the same word differently
    because they are case sensitive:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 将文档转换为小写字母，以避免由于大小写敏感而对相同的单词进行不同的处理：
- en: '[PRE61]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Break the sentence into words. The output is a list of words stored in a variable
    called `words`:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 将句子分解为单词。输出是一个存储在`words`变量中的单词列表：
- en: '[PRE62]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Ignore all the words from the sentence if they belong to the English stop word
    category and store all of them in the `non_stopped_words` variable:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 如果句子中的词属于英语停用词类别，则忽略所有这些词，并将它们存储在`non_stopped_words`变量中：
- en: '[PRE63]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Store the sentence that is tokenized and cleaned in a variable called `self.cleaned` (class
    member).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 将分词和清理后的句子存储在名为`self.cleaned`（类成员）的变量中。
- en: '[PRE64]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Show a diagnostic message to the user that we have finished cleaning the documents:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 向用户显示诊断消息，告知我们已完成文档清理：
- en: '[PRE65]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'This instruction defines a new function, `doLDA`, which runs the LDA analysis
    on the cleaned documents:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令定义了一个新函数`doLDA`，该函数在清理后的文档上运行LDA分析：
- en: '[PRE66]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Before we directly process the cleaned documents, we create a dictionary from
    these documents:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在直接处理已清理的文档之前，我们从这些文档创建一个字典：
- en: '[PRE67]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The input corpus is defined as a bag of words for each cleaned sentence:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 输入语料库被定义为每个清理过的句子的词袋：
- en: '[PRE68]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Create a model on the corpus with the number of topics defined as `2` and set
    the vocabulary size/mapping using the `id2word` parameter:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在语料库上创建一个模型，定义主题数量为`2`，并使用`id2word`参数设置词汇大小/映射：
- en: '[PRE69]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Print two topics, where each topic should contain four words on the screen:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在屏幕上打印两个主题，每个主题应包含四个单词：
- en: '[PRE70]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'This is the function that does all the steps in order:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 这是执行所有步骤的函数：
- en: '[PRE71]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: When the current program is invoked as the main program, create a new object
    called `topicExample` from the `IdentifyingTopicExample()` class and invoke the `run()` function
    on the object.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 当当前程序作为主程序被调用时，创建一个名为`topicExample`的新对象，该对象来自`IdentifyingTopicExample()`类，并在该对象上调用`run()`函数。
- en: '[PRE72]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Summarizing text
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文本总结
- en: In this information overload era, there is so much information that is available
    in print/text form. Its humanly impossible for us to consume all this data. In
    order to make the consumption of this data easier, we have been trying to invent
    algorithms that can help simplify large text into a summary (or a gist) that we
    can easily digest.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个信息过载的时代，信息的形式多种多样，且以印刷/文本的形式存在。对我们来说，想要全部消化这些信息几乎是不可能的。为了让我们更容易地消费这些数据，我们一直在尝试发明一些算法，能够将大量的文本简化成一个我们能轻松消化的摘要（或要点）。
- en: By doing this, we will save time and also make things easier for the network.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做，我们既节省时间，又能让网络变得更简单。
- en: In this recipe, we will use the gensim library, which has built-in support for
    this summarization using the TextRank algorithm ([https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将使用gensim库，它内建对基于TextRank算法的总结功能支持（[https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)）。
- en: Getting ready
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正在准备中
- en: You should have Python installed, along with the `bs4` and `gensim` libraries.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该已经安装了Python，并且安装了`bs4`和`gensim`库。
- en: How to do it...
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Open atom editor (or your favorite programming editor).
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开atom编辑器（或你最喜欢的编程编辑器）。
- en: Create a new file called `Summarize.py`.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`Summarize.py`的新文件。
- en: 'Type the following source code:'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/a95816f9-4168-4eb3-85ae-7e56797626ce.png)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a95816f9-4168-4eb3-85ae-7e56797626ce.png)'
- en: Save the file.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![](img/b7fa82ee-3668-4db0-98c8-b5d5b9571fc8.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b7fa82ee-3668-4db0-98c8-b5d5b9571fc8.png)'
- en: How it works...
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Let's see how we our summarization program works.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的总结程序是如何工作的。
- en: '[PRE73]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'These three instructions import the necessary libraries into the current program:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这三条指令将必要的库导入到当前程序中：
- en: '`gensim.summarization.summarize`: Text-rank-based summarization algorithm'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gensim.summarization.summarize`：基于TextRank算法的文本总结功能'
- en: '`bs4`: A `BeautifulSoup` library for parsing HTML documents'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bs4`：一个用于解析HTML文档的`BeautifulSoup`库'
- en: '`requests`: A library to download HTTP resources'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requests`：一个用于下载HTTP资源的库'
- en: 'We are defining a dictionary called URLs whose keys are the title of the paper
    that is auto generated and the value is the URL to the paper:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个名为URLs的字典，其键是自动生成的论文标题，值是论文的URL：
- en: '[PRE74]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Iterate through all the keys of the dictionary:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历字典的所有键：
- en: '[PRE75]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Store the URL of the current paper in a variable called `url`:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 将当前论文的URL存储在一个名为`url`的变量中：
- en: '[PRE76]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Download the content of the url using the `requests` library''s `get()` method
    and store the response object into a variable, `r`:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`requests`库的`get()`方法下载URL的内容，并将响应对象存储到变量`r`中：
- en: '[PRE77]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Use `BeautifulSoup()` to parse the text from the `r` object using the HTML
    parser and store the return object in a variable called `soup`:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`BeautifulSoup()`函数，通过HTML解析器解析`r`对象中的文本，并将返回的对象存储在一个名为`soup`的变量中：
- en: '[PRE78]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Strip out all the HTML tags and extract only the text from the document into
    the variable `data`:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 去除所有HTML标签，仅将文档中的文本提取到变量`data`中：
- en: '[PRE79]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: Find the position of the text `Introduction` and skip past towards end of string,
    to mark is as starting offset from which we want to extract the substring.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 找到文本`Introduction`的位置，并跳过直到字符串末尾，将其标记为我们提取子字符串的起始偏移量。
- en: '[PRE80]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Find the second position in the document, exactly at the beginning of the related
    work section:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 找到文档中的第二个位置，准确位于相关工作部分的开始：
- en: '[PRE81]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Now, extract the introduction of the paper, which is between these two offsets:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，提取论文的介绍部分，内容位于这两个偏移量之间：
- en: '[PRE82]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Display the URL and the title of the paper on the screen:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在屏幕上显示论文的URL和标题：
- en: '[PRE83]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Call the `summarize()` function on the text, which returns shortened text as
    per the text rank algorithm:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本上调用`summarize()`函数，该函数根据文本排序算法返回简短的文本：
- en: '[PRE84]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: Print an extra newline for more readability of the screen output.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 打印额外的换行符，以便提高屏幕输出的可读性。
- en: '[PRE85]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Resolving anaphora
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决指代问题
- en: In many natural languages, while forming sentences, we avoid the repeated use
    of certain nouns with pronouns to simplify the sentence construction.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多自然语言中，在构造句子时，我们避免重复使用某些名词，而是用代词来简化句子的结构。
- en: 'For example:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 例如：
- en: Ravi is a boy. He often donates money to the poor.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: Ravi是个男孩。他经常为穷人捐钱。
- en: 'In this example, there are two statements:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，有两个句子：
- en: Ravi is a boy.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ravi是个男孩。
- en: He often donates money to the poor.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他经常为穷人捐钱。
- en: When we start analyzing the second statement, we cannot make a decision about
    who is donating the money  without knowing about the first statement. So, we should
    associate He with Ravi to get the complete sentence meaning. All this reference
    resolution happens naturally in our mind.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始分析第二句话时，如果不知道第一句话，我们无法判断是谁在捐钱。因此，我们应该将“He”与Ravi关联起来，以获得完整的句子含义。所有这些引用消解在我们的大脑中自然发生。
- en: If we observe the previous example carefully, first the subject is present;
    then the pronoun comes up. So the direction of the flow is from left to right.
    Based on this flow, we can call these types of sentences anaphora.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们仔细观察前面的例子，首先是主语出现；然后是代词出现。所以，流动的方向是从左到右。根据这个流动，我们可以称这些句子为指代句（anaphora）。
- en: 'Let''s take another example:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一个例子：
- en: He was already on his way to airport. Realized Ravi
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 他已经在前往机场的路上。Ravi意识到这一点。
- en: This is another class of example where the direction of expression is the reverse
    order (first the pronoun and then the noun). Here too, He is associated with Ravi.
    These types of sentences are called as Cataphora.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一类例子，其中表达的方向是反向顺序（先是代词，再是名词）。在这里，He与Ravi相关联。这类句子被称为前指（Cataphora）。
- en: 'The earliest available algorithm for this anaphora resolution dates back to
    the 1970; Hobbs has presented a paper on this. An online version of this paper
    is available here: [https://www.isi.edu/~hobbs/pronoun-papers.html](https://www.isi.edu/~hobbs/pronoun-papers.html).'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 这个最早可用的指代消解算法可以追溯到1970年；Hobbs曾发表过一篇相关论文。该论文的在线版本可以在这里查看：[https://www.isi.edu/~hobbs/pronoun-papers.html](https://www.isi.edu/~hobbs/pronoun-papers.html)。
- en: In this recipe, we will try to write a very simple Anaphora resolution algorithm
    using what we have learned just now.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将尝试使用我们刚学到的知识编写一个非常简单的指代消解算法。
- en: Getting ready
  id: totrans-340
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: You should have python installed, along with the `nltk` library and `gender`
    datasets.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该安装Python，并配备`nltk`库和`gender`数据集。
- en: You can use `nltk.download()` to download the corpus.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`nltk.download()`来下载语料库。
- en: How to do it...
  id: totrans-343
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现它…
- en: Open atom editor (or your favorite programming editor).
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开atom编辑器（或你喜欢的编程编辑器）。
- en: Create a new file called `Anaphora.py`.
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`Anaphora.py`的新文件。
- en: 'Type the following source code:'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/2f596d1e-74a7-4788-bcf8-0db0cf82e547.png)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2f596d1e-74a7-4788-bcf8-0db0cf82e547.png)'
- en: Save the file.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![](img/7d6cf7f5-a322-479c-b628-5d50d524c98d.png)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7d6cf7f5-a322-479c-b628-5d50d524c98d.png)'
- en: How it works...
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Let see how our simple Anaphora resolution algorithm works.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们简单的指代消解算法是如何工作的。
- en: '[PRE86]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'These four instructions import the necessary modules and functions that are
    used in the program. We are defining a new class called `AnaphoraExample`:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 这四条指令导入了程序中所需的必要模块和函数。我们正在定义一个名为`AnaphoraExample`的新类：
- en: '[PRE87]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'We are defining a new constructor for this class, which doesn''t take any parameters:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为这个类定义了一个新的构造函数，该函数不接受任何参数：
- en: '[PRE88]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: These two instructions load all the male and female names from the `nltk.names` corpus
    and tag them as male/female before storing them in two lists called male/female.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 这两条指令从`nltk.names`语料库中加载所有的男性和女性名字，并在将它们存储在两个名为male/female的列表之前对其进行标记。
- en: '[PRE89]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'This instruction creates a unique list of males and females. `random.shuffle()` ensures
    that all of the data in the list is randomized:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 这条指令创建了一个独特的男性和女性名字列表。`random.shuffle()`确保列表中的所有数据都是随机的：
- en: '[PRE90]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'This instruction invokes the `feature()` function on the gender and stores
    all the names in a variable called `training`:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 这条指令在`gender`上调用`feature()`函数，并将所有名字存储在一个名为`training`的变量中：
- en: '[PRE91]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'We are creating a `NaiveBayesClassifier` object called `_classifier` using
    the males and females features that are stored in a variable called `training`:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用存储在名为`training`的变量中的男性和女性特征，创建一个名为`_classifier`的`NaiveBayesClassifier`对象：
- en: '[PRE92]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'This function defines the simplest possible feature, which categorizes the
    given name as male or female just by looking at the last letter of the name:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数定义了最简单的特征，只通过查看名字的最后一个字母就能将给定的名字分类为男性或女性：
- en: '[PRE93]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'This function takes a word as an argument and tries to detect the gender as
    male or female using the classifier we have built:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数接受一个单词作为参数，并尝试通过我们构建的分类器来检测该单词的性别是男性还是女性：
- en: '[PRE94]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'This is the main function that is of interest to us, as we are going to detect
    anaphora on the sample sentences:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们感兴趣的主要函数，因为我们将对示例句子进行指代检测：
- en: '[PRE95]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'These are four examples with mixed complexity expressed in anaphora form:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 这是四个具有不同复杂性的例子，以指代形式表达：
- en: '[PRE96]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'This instruction iterates over all the sentences by taking one sentence at
    a time to a local variable called `sent`:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令通过一次处理一个句子，将每个句子存储到一个名为`sent`的局部变量中：
- en: '[PRE97]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'This instruction tokenizes, assigns parts of speech, extracts chunks (named
    entities), and returns the chunk tree to a variable called `chunks`:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令对句子进行分词、赋予词性、提取块（命名实体），并将块树返回给一个名为`chunks`的变量：
- en: '[PRE98]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'This variable is used to store all the names and pronouns that help us resolve
    anaphora:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 这个变量用于存储所有帮助我们解决指代问题的名字和代词：
- en: '[PRE99]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'This instruction shows the current sentence that is being processed on the
    user''s screen:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令将在用户屏幕上显示当前正在处理的句子：
- en: '[PRE100]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'This instruction flattens the tree chunks to a list of items expressed in IOB
    format:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令将树结构的块展平为IOB格式表达的项目列表：
- en: '[PRE101]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'We are traversing through all chunked sentences that are in IOB format (tuple
    with three elements):'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在遍历所有以IOB格式表示的分块句子（每个元组包含三个元素）：
- en: '[PRE102]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'If the POS of the word is `NNP` and IOB letter for this word is `B-PERSON` or `O`,
    then we mark this word as a `Name`:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 如果单词的词性（POS）是`NNP`，并且该单词的IOB标签是`B-PERSON`或`O`，那么我们将此单词标记为`Name`：
- en: '[PRE103]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'If the POS of the word is `CC`, then also we will add this to the `stack` variable:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 如果单词的词性是`CC`，我们也会将其添加到`stack`变量中：
- en: '[PRE104]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'If the POS of the word is `PRP`, then we will add this to the `stack` variable:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 如果单词的词性是`PRP`，我们将把它添加到`stack`变量中：
- en: '[PRE105]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'Finally we print the stack on the screen:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在屏幕上打印栈：
- en: '[PRE106]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: We are creating a new object called `anaphora` from `AnaphoraExample()` and
    invoking the `learnAnaphora()` function on the anaphora object. Once this function
    execution completes, we see the list of words for every sentence.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在从`AnaphoraExample()`创建一个新的对象，调用`learnAnaphora()`函数，并在指代对象上执行此函数。一旦函数执行完毕，我们就可以看到每个句子的单词列表。
- en: '[PRE107]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: Disambiguating word sense
  id: totrans-397
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 词义歧义消解
- en: In previous chapters, we learned how to identify POS of the words, find named
    entities, and so on. Just like a word in English behaves as both a noun and a
    verb, finding the sense in which a word is used is very difficult for computer
    programs.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们学习了如何识别单词的词性、找到命名实体等等。就像英语中的单词既可以是名词也可以是动词一样，计算机程序很难准确找出一个单词在特定上下文中的语义。
- en: 'Let''s take a few examples to understand this sense portion:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过几个例子来理解这个语义部分：
- en: '| **Sentence** | **Description** |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| **句子** | **描述** |'
- en: '| *She is my date* | Here the sense of the word *date* is not the calendar
    date but expresses a human relationship. |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| *她是我的约会对象* | 这里单词*date*的意思不是日历日期，而是表达一种人际关系。 |'
- en: '| *You have taken too many leaves to skip cleaning leaves in the garden* |
    Here the word *leaves* has multiple senses:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: '| *你已经休息得太多，以至于忘记了清理花园里的叶子* | 这里单词*leaves*有多重含义：'
- en: The first word *leave* means taking a break
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个单词*leave*的意思是休息。
- en: The second one actually refers to tree leaves
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个意思实际上指的是树叶。
- en: '|'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Like this, there are many combinations of senses possible in sentences.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 就像这样，句子中可能有多种语义组合。
- en: One of the challenges we have faced for senses identification is to find a proper
    nomenclature to describe these senses. There are many English dictionaries available
    that describe the behavior of words and all possible combinations of those. Of
    them all, WordNet is the most structured, preferred, and widely accepted source
    of sense usage.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在进行语义识别时面临的挑战之一是找到一种合适的命名法来描述这些语义。市面上有很多英语词典可以描述单词的行为以及所有可能的组合。在所有这些词典中，WordNet是结构化最强、最受欢迎且被广泛接受的语义使用来源。
- en: In this recipe, we will see examples of senses from the WordNet library and
    use the built-in `nltk` library to find out the sense of words.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将展示来自WordNet库的语义示例，并使用内置的`nltk`库来找出单词的语义。
- en: Lesk is the oldest algorithm that was coined to tackle this sense detection.
    You will see, however, that this one too is not accurate in some cases.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: Lesk是最早提出用于处理语义检测的算法之一，然而你会发现，这个算法在某些情况下也不够准确。
- en: Getting ready
  id: totrans-410
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: You should have Python installed, along with the `nltk` library.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该安装Python，并安装`nltk`库。
- en: How to do it...
  id: totrans-412
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: Open atom editor (or your favorite programming editor).
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Atom编辑器（或你喜欢的编程编辑器）。
- en: Create a new file called `WordSense.py`.
  id: totrans-414
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`WordSense.py`的新文件。
- en: 'Type the following source code:'
  id: totrans-415
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/25897007-6789-40c0-b6b6-1ea605c35b4e.png)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
  zh: '![](img/25897007-6789-40c0-b6b6-1ea605c35b4e.png)'
- en: Save the file.
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-418
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![](img/984afb10-d504-4899-b396-6d0a1d9d7cdb.png)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
  zh: '![](img/984afb10-d504-4899-b396-6d0a1d9d7cdb.png)'
- en: How it works...
  id: totrans-421
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'Let''s see how our program works. This instruction imports the `nltk` library
    into the program:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下我们的程序是如何工作的。这个指令将`nltk`库导入到程序中：
- en: '[PRE108]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: We are defining a function with the name `understandWordSenseExamples()`, which
    uses the WordNet corpus to showcase the possible senses of the words that we are
    interested in.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个名为`understandWordSenseExamples()`的函数，它使用WordNet语料库展示我们感兴趣的单词可能的意义。
- en: '[PRE109]'
  id: totrans-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: These are the three words with different senses of expression. They are stored
    as a list in a variable called `words`.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是三个具有不同表达意义的单词。它们作为一个列表存储在一个名为`words`的变量中。
- en: '[PRE110]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'These instructions do the following:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指令执行以下操作：
- en: Iterate over all the words in the list by storing the current word in a variable
    called `word`.
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遍历列表中的所有单词，将当前单词存储在名为`word`的变量中。
- en: Invoke the `synsets()` function from the `wordne`t module and store the result
    in the `syns` variable.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从`wordnet`模块调用`synsets()`函数，并将结果存储在`syns`变量中。
- en: Take the first three synsets from the list, iterate through them, and take the
    current one in a variable called `syn`.
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从列表中取出前三个同义词集，遍历它们，并将当前同义词集存入名为`syn`的变量中。
- en: Invoke the `examples()` function on the `syn` object and take the first two
    examples as the iterator. The current value of the iterator is available in the
    variable example.
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`syn`对象上调用`examples()`函数，并将前两个示例作为迭代器。迭代器的当前值可以通过变量`example`获得。
- en: Print the word, synset's name, and example sentence finally.
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，打印出单词、同义词集的名称和示例句子。
- en: Define a new function, `understandBuiltinWSD()`, to explore the NLTK built-in
    lesk algorithm's performance on sample sentences.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个新函数`understandBuiltinWSD()`，以探索NLTK内置lesk算法在示例句子上的表现。
- en: '[PRE111]'
  id: totrans-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: Define a new variable called `maps`, a list of tuples.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个名为`maps`的新变量，一个包含元组的列表。
- en: '[PRE112]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'Each tuple consists of three elements:'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 每个元组由三个元素组成：
- en: The sentence we want to analyze
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要分析的句子
- en: The word in the sentence for which we want to find the sense
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要找出其意义的句子中的单词
- en: The POS of the word
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单词的词性（POS）
- en: In these two instructions, we are traversing through the `maps` variable, taking
    the current tuple into variable `m`, invoking the `nltk.wsd.lesk()` function,
    and displaying the formatted results on screen.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两个指令中，我们正在遍历`maps`变量，将当前元组存入变量`m`，调用`nltk.wsd.lesk()`函数，并在屏幕上显示格式化的结果。
- en: '[PRE113]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: When the program is run, call the two functions that show the results on the
    user's screen.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 当程序运行时，调用这两个函数将结果显示在用户的屏幕上。
- en: '[PRE114]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: Performing sentiment analysis
  id: totrans-446
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进行情感分析
- en: Feedback is one of the most powerful measures for understanding relationships.
    Humans are very good at understanding feedback in verbal communication as the
    analysis happens unconsciously. In order to write computer programs that can measure
    and find the emotional quotient, we should have some good understanding of the
    ways these emotions are expressed in these natural languages.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈是理解关系的最强有力手段之一。人类非常擅长理解口头交流中的反馈，因为分析过程是无意识进行的。为了编写能够衡量并找到情感商的计算机程序，我们应该对这些情感在自然语言中的表达方式有一定的理解。
- en: 'Let''s take a few examples:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举几个例子：
- en: '| **Sentence** | **Description** |'
  id: totrans-449
  prefs: []
  type: TYPE_TB
  zh: '| **句子** | **描述** |'
- en: '| *I am very happy* | Indicates a happy emotion |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
  zh: '| *我很开心* | 表示一种快乐的情感 |'
- en: '| *She is so :(* | We know there is an iconic sadness expression here |'
  id: totrans-451
  prefs: []
  type: TYPE_TB
  zh: '| *她好难过 :(* | 我们知道这里有一个经典的悲伤表情 |'
- en: With the increased use of text, icons, and emojis in written natural language
    communication, it's becoming increasingly difficult for computer programs to understand
    the emotional meaning of a sentence.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 随着文本、图标和表情符号在书面自然语言交流中的使用增加，计算机程序越来越难以理解句子的情感含义。
- en: Let's try to write a program to understand the facilities nltk provides to build
    our own algorithm.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试编写一个程序，以理解nltk提供的功能来构建我们自己的算法。
- en: Getting ready
  id: totrans-454
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备开始
- en: You should have Python installed, along with the `nltk` library.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该已经安装了Python，并且安装了`nltk`库。
- en: How to do it...
  id: totrans-456
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做……
- en: Open atom editor (or your favorite programming editor).
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 Atom 编辑器（或你最喜欢的编程编辑器）。
- en: Create a new file called `Sentiment.py`.
  id: totrans-458
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`Sentiment.py`的新文件。
- en: 'Type the following source code:'
  id: totrans-459
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/842ffb61-bece-46e2-9d4f-1db5e6c5ca33.png)'
  id: totrans-460
  prefs: []
  type: TYPE_IMG
  zh: '![](img/842ffb61-bece-46e2-9d4f-1db5e6c5ca33.png)'
- en: Save the file.
  id: totrans-461
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-462
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Python 解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到以下输出：
- en: '![](img/8487c0f4-10ac-4de5-b4f2-f61f307f889f.png)'
  id: totrans-464
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8487c0f4-10ac-4de5-b4f2-f61f307f889f.png)'
- en: How it works...
  id: totrans-465
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: Let's see how our sentiment analysis program works. These instructions import
    the `nltk` module and `sentiment_analyzer` module respectively.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们的情感分析程序是如何工作的。这些指令分别导入了`nltk`模块和`sentiment_analyzer`模块。
- en: '[PRE115]'
  id: totrans-467
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: We are defining a new function, `wordBasedSentiment()`, which we will use to
    learn how to do sentiment analysis based on the words that we already know and
    which mean something important to us.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个新函数，`wordBasedSentiment()`，我们将用它来学习如何基于我们已经知道且对我们有意义的单词进行情感分析。
- en: '[PRE116]'
  id: totrans-469
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: We are defining a list of three words that are special to us as they represent
    some form of happiness. These words are stored in the `positive_words` variable.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个包含三个特殊单词的列表，这些单词代表某种形式的幸福。这些单词存储在`positive_words`变量中。
- en: '[PRE117]'
  id: totrans-471
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: This is the sample text that we are going to analyze; the text is stored in
    a variable called `text`.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将要分析的示例文本；文本被存储在一个名为`text`的变量中。
- en: '[PRE118]'
  id: totrans-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: We are calling the `extract_unigram_feats()` function on the text using the words
    that we have defined. The result is a dictionary of input words that indicate
    whether the given words are present in the text or not.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在文本上调用了`extract_unigram_feats()`函数，使用我们已定义的单词。结果是一个字典，显示这些单词是否出现在文本中。
- en: '[PRE119]'
  id: totrans-475
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: This instruction displays the dictionary on the user's screen.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令将在用户的屏幕上显示字典。
- en: '[PRE120]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: This instruction defines a new function that we will use to understand whether
    some pairs of words occur in a sentence.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令定义了一个新函数，我们将用它来判断某些单词对是否出现在句子中。
- en: '[PRE121]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: This instruction defines a list of two-word tuples. We are interested in finding
    if these pairs of words occur together in a sentence.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令定义了一个包含双词元组的列表。我们感兴趣的是判断这些单词对是否一起出现在句子中。
- en: '[PRE122]'
  id: totrans-481
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: This is the sentence we are interested in processing and finding the features
    of.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们感兴趣的句子，旨在处理并找出其特征。
- en: '[PRE123]'
  id: totrans-483
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: We are calling the `extract_bigram_feats()` on the input sentence against the
    sets of words in the `word_sets` variable. The result is a dictionary that tells
    whether these pairs of words are present in the sentence or not.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在输入句子上调用了`extract_bigram_feats()`函数，对照`word_sets`变量中的单词集。结果是一个字典，告诉我们这些单词对是否出现在句子中。
- en: '[PRE124]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: This instruction displays the dictionary on screen.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令将在屏幕上显示字典。
- en: '[PRE125]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: We are defining a new function, `markNegativity()`, which helps us understand
    how we can find negativity in a sentence.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在定义一个新函数，`markNegativity()`，它帮助我们理解如何在句子中找出否定性。
- en: '[PRE126]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: Next is the sentence on which we want to run the negativity analysis. It's stored
    in a variable, `text`.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是我们希望进行否定性分析的句子，它存储在一个变量`text`中。
- en: '[PRE127]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: We are calling the `mark_negation()` function on the text. This returns a list
    of all the words in the sentence along with a special suffix `_NEG` for all the
    words that come under the negative sense. The result is stored in the `negation` variable.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在文本上调用了`mark_negation()`函数。此函数返回句子中所有单词的列表，并且对于所有具有否定意义的单词，会加上一个特殊后缀`_NEG`。结果存储在`negation`变量中。
- en: '[PRE128]'
  id: totrans-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: This instruction displays the list negation on screen.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 该指令在屏幕上显示列表的否定。
- en: '[PRE129]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: When the program is run, these functions are called and we see the output of
    three functions in the order they are executed (top-down).
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 当程序运行时，这些函数会被调用，我们将看到按执行顺序（自上而下）输出的三个函数结果。
- en: '[PRE130]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: Exploring advanced sentiment analysis
  id: totrans-498
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索高级情感分析
- en: We are seeing that more and more businesses are going online to increase their
    target customer base and the customers are given the ability to leave feedback
    via various channels. It's becoming more and more important for businesses to
    understand the emotional response of their customers with respect to the businesses
    they run.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到越来越多的企业走向线上，以增加目标客户群，并且顾客可以通过各种渠道留下反馈。企业越来越需要理解顾客对于其经营活动的情感反应。
- en: In this recipe, we will write our own sentiment analysis program based on what
    we have learned in the previous recipe. We will also explore the built-in vader
    sentiment analysis algorithm, which helps evaluate in finding the sentiment of
    complex sentences.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将根据前面学到的内容编写自己的情感分析程序。我们还将探索内置的vader情感分析算法，这有助于评估复杂句子的情感。
- en: Getting ready
  id: totrans-501
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: You should have Python installed, along with the `nltk` library.
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该安装了Python，以及`nltk`库。
- en: How to do it...
  id: totrans-503
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Open atom editor (or your favorite programming editor).
  id: totrans-504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Atom编辑器（或您喜欢的编程编辑器）。
- en: Create a new file called `AdvSentiment.py`.
  id: totrans-505
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`AdvSentiment.py`的新文件。
- en: 'Type the following source code:'
  id: totrans-506
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/b2a2b51b-c606-442c-8639-148cea230656.png)'
  id: totrans-507
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b2a2b51b-c606-442c-8639-148cea230656.png)'
- en: Save the file.
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-509
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将看到以下输出：
- en: '![](img/49f760f3-9ef7-4291-a3a7-f727caab0996.png)'
  id: totrans-511
  prefs: []
  type: TYPE_IMG
  zh: '![](img/49f760f3-9ef7-4291-a3a7-f727caab0996.png)'
- en: How it works...
  id: totrans-512
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Now, let's see how our sentiment analysis program works. These four instructions
    import the necessary modules that we are going to use as part of this program.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们的情感分析程序如何工作。这四条指令导入了我们在此程序中要使用的必要模块。
- en: '[PRE131]'
  id: totrans-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: 'Defining a new function, `mySentimentAnalyzer()`:'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个新函数，`mySentimentAnalyzer()`：
- en: '[PRE132]'
  id: totrans-516
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: This instruction defines a new subfunction, `score_feedback()`, which takes
    a sentence as input and returns the score for the sentence in terms of `-1` negative, `0` neutral,
    and `1` positive.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 此指令定义了一个新的子函数，`score_feedback()`，它接受一个句子作为输入，并根据`-1`负面、`0`中性和`1`积极返回句子的分数。
- en: '[PRE133]'
  id: totrans-518
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: Since we are just experimenting, we are defining the three words using which
    we are going to find the sentiment. In real-world use cases, we might use these
    from the corpus of a larger dictionary.
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们只是在做实验，所以我们定义了三个词语，用于找到情感。在实际应用中，我们可能会从更大的词典语料库中选择这些词语。
- en: '[PRE134]'
  id: totrans-520
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: This instruction breaks the input sentence into words. The list of words is
    fed to the `mark_negation()` function to identify the presence of any negativity
    in the sentence. Join the result from `mark_negation()` to the string and see
    if the `_NEG` suffix is present; then set the score as `-1`.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 此指令将输入的句子分解为单词。将单词列表提供给`mark_negation()`函数以识别句子中是否存在消极情绪。将来自`mark_negation()`的结果与字符串连接，并查看是否存在`_NEG`后缀；然后将分数设置为`-1`。
- en: '[PRE135]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: 'Here we are using `extract_unigram_feats()` on the input text against `positive_words` and
    storing the dictionary into a variable called `analysis`:'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们正在对输入文本使用`extract_unigram_feats()`，并根据`positive_words`进行分析，并将字典存储到名为`analysis`的变量中：
- en: '[PRE136]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: The value of score is decided to be `1` if there is a presence of the positive
    word in the input text.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 如果输入文本中存在积极词汇，则分数的值决定为`1`。
- en: '[PRE137]'
  id: totrans-526
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: 'Finally this `score_feedback()` function returns the computed score:'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这个`score_feedback()`函数会返回计算出的分数：
- en: '[PRE138]'
  id: totrans-528
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: These are the four reviews that we are interested in processing using our algorithm
    to print the score.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们有兴趣使用我们的算法处理的四篇评论，以打印分数。
- en: '[PRE139]'
  id: totrans-530
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: These instructions extract the sentences from the variable feedback by splitting
    on newline (`\n`) and calling the `score_feedback()` function on this text.
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指令通过在换行符（`\n`）上分割并调用`score_feedback()`函数来从变量feedback中提取句子。
- en: '[PRE140]'
  id: totrans-532
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: The result will be the score and sentence on the screen. This instruction defines
    the `advancedSentimentAnalyzer()` function, which will be used to understand the
    built-in features of NLTK sentiment analysis.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将显示在屏幕上的分数和句子。此指令定义了`advancedSentimentAnalyzer()`函数，用于理解NLTK情感分析的内置特性。
- en: '[PRE141]'
  id: totrans-534
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: We are defining five sentences to analyze. you'll note that we are also using
    emoticons (icons) to see how the algorithm works.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了五个句子来进行分析。请注意，我们还使用了表情符号（图标）来查看算法的工作原理。
- en: '[PRE142]'
  id: totrans-536
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: This instruction creates a new object for `SentimentIntensityAnalyzer()` and
    stores the object in the variable `senti`.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 此指令为`SentimentIntensityAnalyzer()`创建了一个新对象，并将对象存储在变量`senti`中。
- en: '[PRE143]'
  id: totrans-538
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: 'These instructions do the following things:'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指令执行以下操作：
- en: Iterate over all the sentences and store the current one in the variable `sentence`
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代所有句子，并将当前句子存储在变量`sentence`中。
- en: Display the currently processed sentence on screen
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在屏幕上显示当前处理的句子
- en: Invoke the `polarity_scores()` function on this sentence; store the result in
    a variable called `kvp`
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个句子上调用`polarity_scores()`函数；将结果存储在名为`kvp`的变量中。
- en: Traverse through the dictionary `kvp` and print the key (negativity, neutral,
    positivity, or compound types) and the score computed for these types
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遍历字典`kvp`，并打印出这些类型的键（消极、中立、积极或复合类型）及其计算出的分数。
- en: When the current program is invoked, call these two functions to display the results
    on screen.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 当当前程序被调用时，调用这两个函数以在屏幕上显示结果。
- en: '[PRE144]'
  id: totrans-545
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: Creating a conversational assistant or chatbot
  id: totrans-546
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个对话助手或聊天机器人
- en: Conversational assistants or chatbots are not very new. One of the foremost
    of this kind is ELIZA, which was created in the early 1960s and is worth exploring.
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 对话助手或聊天机器人并不算新颖。这个领域最早的代表之一是ELIZA，它是在1960年代初期创建的，值得一探。
- en: 'In order to successfully build a conversational engine, it should take care
    of the following things:'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 为了成功地构建一个对话引擎，它应该处理以下几个方面：
- en: Understand the target audience
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解目标受众
- en: Understand the natural language in which communication happens
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解自然语言中的交流
- en: Understand the intent of the user
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解用户的意图
- en: Come up with responses that can answer the user and give further clues
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供能回答用户问题并进一步提示的回应
- en: NLTK has a module, `nltk.chat`, which simplifies building these engines by providing
    a generic framework.
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: NLTK有一个模块`nltk.chat`，它通过提供一个通用框架来简化构建这些引擎的过程。
- en: 'Let''s see the available engines in NLTK:'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下NLTK中可用的引擎：
- en: '| **Engines** | **Modules** |'
  id: totrans-555
  prefs: []
  type: TYPE_TB
  zh: '| **引擎** | **模块** |'
- en: '| Eliza | `nltk.chat.eliza` Python module |'
  id: totrans-556
  prefs: []
  type: TYPE_TB
  zh: '| Eliza | `nltk.chat.eliza` Python模块 |'
- en: '| Iesha | `nltk.chat.iesha` Python module |'
  id: totrans-557
  prefs: []
  type: TYPE_TB
  zh: '| Iesha | `nltk.chat.iesha` Python模块 |'
- en: '| Rude | `nltk.chat.rudep` Python module |'
  id: totrans-558
  prefs: []
  type: TYPE_TB
  zh: '| 粗鲁 | `nltk.chat.rudep` Python模块 |'
- en: '| Suntsu | `nltk.chat.suntsu` module |'
  id: totrans-559
  prefs: []
  type: TYPE_TB
  zh: '| Suntsu | `nltk.chat.suntsu`模块 |'
- en: '| Zen | `nltk.chat.zen` module |'
  id: totrans-560
  prefs: []
  type: TYPE_TB
  zh: '| Zen | `nltk.chat.zen`模块 |'
- en: In order to interact with these engines we can just load these modules in our
    Python program and invoke the `demo()` function.
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与这些引擎交互，我们只需在Python程序中加载这些模块并调用`demo()`函数。
- en: This recipe will show us how to use built-in engines and also write our own
    simple conversational engine using the framework provided by the `nltk.chat` module.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 这个教程将展示如何使用内置引擎，并且还会教我们如何使用`nltk.chat`模块提供的框架编写我们自己的简单对话引擎。
- en: Getting ready
  id: totrans-563
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 做好准备
- en: You should have Python installed, along with the `nltk` library. Having an understanding
    of regular expressions also helps.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该已经安装了Python，以及`nltk`库。了解正则表达式也很有帮助。
- en: How to do it...
  id: totrans-565
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做到这一点...
- en: Open atom editor (or your favorite programming editor).
  id: totrans-566
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Atom编辑器（或你喜欢的编程编辑器）。
- en: Create a new file called `Conversational.py`.
  id: totrans-567
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`Conversational.py`的新文件。
- en: 'Type the following source code:'
  id: totrans-568
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下源代码：
- en: '![](img/1d727273-2841-4170-af3a-992ef49b141c.png)'
  id: totrans-569
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d727273-2841-4170-af3a-992ef49b141c.png)'
- en: Save the file.
  id: totrans-570
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存文件。
- en: Run the program using the Python interpreter.
  id: totrans-571
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Python解释器运行程序。
- en: 'You will see the following output:'
  id: totrans-572
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将看到如下输出：
- en: '![](img/f142875f-b0c3-4faf-b7e7-58ca26b1cbaa.png)'
  id: totrans-573
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f142875f-b0c3-4faf-b7e7-58ca26b1cbaa.png)'
- en: How it works...
  id: totrans-574
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Let's try to understand what we are trying to achieve here. This instruction
    imports the `nltk` library into the current program.
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试理解我们在这里想要实现的目标。这个指令将`nltk`库导入当前程序中。
- en: '[PRE145]'
  id: totrans-576
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: 'This instruction defines a new function called `builtinEngines` that takes
    a string parameter, `whichOne`:'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指令定义了一个名为`builtinEngines`的新函数，它接收一个字符串参数`whichOne`：
- en: '[PRE146]'
  id: totrans-578
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: These if, elif, else instructions are typical branching instructions that decide
    which chat engine's `demo()` function is to be invoked depending on the argument
    that is present in the `whichOne` variable. When the user passes an unknown engine
    name, it displays a message to the user that it's not aware of this engine.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 这些if, elif, else指令是典型的分支指令，它们根据`whichOne`变量中提供的参数来决定调用哪个聊天引擎的`demo()`函数。当用户传递一个未知的引擎名称时，它会显示一条信息，告诉用户该引擎并不在其了解范围内。
- en: '[PRE147]'
  id: totrans-580
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: It's a good practice to handle all known and unknown cases also; it makes our
    programs more robust in handling unknown situations.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 处理所有已知和未知情况是一个好习惯；这能让我们的程序在处理未知情况时更加稳健。
- en: This instruction defines a new function called `myEngine()`; this function does
    not take any parameters.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指令定义了一个名为`myEngine()`的新函数；这个函数不接收任何参数。
- en: '[PRE148]'
  id: totrans-583
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: This is a single instruction where we are defining a nested tuple data structure
    and assigning it to chat pairs.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个单一的指令，我们在其中定义了一个嵌套的元组数据结构，并将其分配给聊天对。
- en: '[PRE149]'
  id: totrans-585
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: 'Let''s pay close attention to the data structure:'
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细关注这个数据结构：
- en: We are defining a tuple of tuples
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们正在定义一个元组的元组
- en: 'Each subtuple consists of two elements:'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个子元组由两个元素组成：
- en: The first member is a regular expression (this is the user's question in regex
    format)
  id: totrans-589
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个成员是一个正则表达式（这是用户的问题，采用正则表达式格式）
- en: The second member of the tuple is another set of tuples (these are the answers)
  id: totrans-590
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元组的第二个成员是另一组元组（这些是答案）
- en: We are defining a subfunction called `chat()` inside the `myEngine()` function.
    This is permitted in Python. This `chat()` function displays some information
    to the user on the screen and calls the nltk built-in `nltk.chat.util.Chat()` class
    with the chatpairs variable. It passes `nltk.chat.util.reflections` as the second
    argument. Finally we call the `chatbot.converse()` function on the object that's
    created using the `chat()` class.
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`myEngine()`函数内部定义了一个名为`chat()`的子函数。在Python中这是允许的。这个`chat()`函数在屏幕上向用户显示一些信息，并调用nltk内置的`nltk.chat.util.Chat()`类，传入`chatpairs`变量。它将`nltk.chat.util.reflections`作为第二个参数。最后，我们在使用`chat()`类创建的对象上调用`chatbot.converse()`函数。
- en: '[PRE150]'
  id: totrans-592
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: 'This instruction calls the `chat()` function, which shows a prompt on the screen
    and accepts the user''s requests. It shows responses according to the regular
    expressions that we have built before:'
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: 这个指令调用了`chat()`函数，它在屏幕上显示一个提示，并接受用户的请求。根据我们之前构建的正则表达式，它会显示响应：
- en: '[PRE151]'
  id: totrans-594
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: These instructions will be called when the program is invoked as a standalone
    program (not using import).
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 当程序作为独立程序被调用时（不是通过导入），这些指令将被调用。
- en: '[PRE152]'
  id: totrans-596
  prefs: []
  type: TYPE_PRE
  zh: '[PRE152]'
- en: 'They do these two things:'
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: 它们完成了这两件事：
- en: Invoke the built-in engines one after another (so that we can experience them)
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 依次调用内置引擎（以便我们可以体验它们）
- en: Once all the five built-in engines are excited, they call our `myEngine()`,
    where our customer engine comes into play
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦所有五个内置引擎被激活，它们会调用我们的`myEngine()`，这时我们的客户引擎开始发挥作用
