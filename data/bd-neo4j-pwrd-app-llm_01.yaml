- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Introducing LLMs, RAGs, and Neo4j Knowledge Graphs
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍LLM、RAGs和Neo4j知识图谱
- en: '**Artificial Intelligence** (**AI**) is evolving beyond niche and specialized
    fields to become more accessible and able to assist with day-to-day tasks. One
    of the best examples is the explosive advent of **Generative AI** (**GenAI**).
    In the last few years, GenAI has created a lot of excitement both for technology
    builders and regular users with its ease of use and ability to understand and
    answer questions the way humans can. The breakthroughs in **Large Language Models**
    (**LLMs**) have propelled GenAI to the forefront. This has opened up a lot of
    opportunities for businesses to change how they interact with their customers.
    Customers can ask a question in natural language and get an answer without needing
    a human to be available to understand the question or understand the data to extract
    intelligence from it. While GenAI has taken big strides in different fields with
    different modalities, such as text, audio, and video, our focus throughout this
    book remains on LLMs and their applications in business and industry use cases.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能**（**AI**）正在从利基和专业化领域演变，变得更加易于访问，并能协助日常任务。最好的例子之一是**生成式人工智能**（**GenAI**）的爆炸性出现。在过去的几年里，GenAI凭借其易用性和理解并回答问题的能力，在技术构建者和普通用户中引起了极大的兴奋。**大型语言模型**（**LLMs**）的突破推动了GenAI的发展，这为企业在如何与客户互动方面开辟了许多机会。客户可以用自然语言提问，并获得答案，而无需有人类存在来理解问题或从数据中提取智能。尽管GenAI在文本、音频和视频等不同模态的不同领域取得了重大进展，但本书的重点始终是LLMs及其在商业和工业用例中的应用。'
- en: In this chapter, we will take a look at GenAI through the lens of LLMs, its
    impact, pitfalls, and ethical concerns. To set the stage for this book, we will
    briefly introduce techniques that can augment LLMs to make them more effective.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过LLM的视角来审视GenAI，探讨其影响、陷阱和伦理问题。为了为本书奠定基础，我们将简要介绍可以增强LLM以使其更有效的技术。
- en: 'In this chapter, we are going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Outlining the evolution of GenAI through the lens of LLMs
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过LLM的视角概述GenAI的演变
- en: Understanding the importance of RAGs and knowledge graphs in LLMs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解RAGs和知识图谱在LLMs中的重要性
- en: Introducing Neo4j knowledge graphs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍Neo4j知识图谱
- en: Outlining the evolution of GenAI through the lens of LLMs
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过LLM的视角概述GenAI的演变
- en: In late 2022, OpenAI took the world by storm by releasing an AI engine called
    ChatGPT that could understand language like humans and interact with users in
    natural language. This was the best representation of GenAI in a long time. AI
    concepts started as rules-based systems and evolved into machine learning algorithms
    in the ‘90s. With the rise of deep learning and LLMs, the concept of GenAI became
    more popular. These AI systems could generate new content after being trained
    using existing content. OpenAI’s GPT-3 LLM model was one of the first LLMs that
    captured the interest of the masses. GenAI can be used to get answers in a manner
    that feels like human interaction and it can also be used to generate images by
    providing a text description, describe an image as text content, generate videos
    using text content, and many other things. It can enhance creativity, accelerate
    research and development, enable a simple understanding of complex concepts, and
    improve personalization.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 到2022年底，OpenAI通过发布一个名为ChatGPT的人工智能引擎而震惊世界，该引擎能够像人类一样理解语言，并以自然语言与用户互动。这是很长时间以来GenAI的最佳代表。AI概念最初是规则系统，90年代演变为机器学习算法。随着深度学习和LLMs的兴起，GenAI的概念变得更加流行。这些AI系统在经过现有内容的训练后可以生成新的内容。OpenAI的GPT-3
    LLM模型是第一批引起大众兴趣的LLM之一。GenAI可以以类似人类互动的方式获取答案，也可以通过提供文本描述来生成图像，将图像描述为文本内容，使用文本内容生成视频，以及许多其他事情。它可以增强创造力，加速研发，使复杂概念易于理解，并提高个性化。
- en: The evolution of LLMs is at the heart of GenAI’s popularity. Let’s take a look
    at LLMs and how they have propelled GenAI.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的演变是GenAI受欢迎的核心。让我们来看看LLM以及它们是如何推动GenAI发展的。
- en: Introducing LLMs
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍LLM
- en: An LLM is a machine learning model that is built for natural language processing
    and can understand language constructs and generate content in that language based
    on the training.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: LLM是一种为自然语言处理而构建的机器学习模型，它可以理解语言结构，并根据训练在该语言中生成内容。
- en: Before the popularity of GPT-3, a considerable amount of research had been conducted
    on LLMs fover several years. Some of the notable works that pioneered LLMs include
    Google’s **Bidirectional Encoder Representations from Transformers** (**BERT**
    (https://github.com/google-research/bert)) and **Generative Pre-trained Transformer**
    (**GPT**) from OpenAI. LLM training requires a lot of parameters and computing
    power.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPT-3流行之前，关于LLMs的研究已经进行了几年。一些开创性工作包括谷歌的**双向编码器表示从Transformer**（**BERT** (https://github.com/google-research/bert)）和OpenAI的**生成预训练Transformer**（**GPT**）。LLM的训练需要大量的参数和计算能力。
- en: At their core, LLMs are a type of **Recurrent Neural Network** (**RNN**) architecture.
    Traditional RNNs struggle with long-term dependencies in sequential data. To address
    this, LLMs often leverage architectures such as **Long Short-Term Memory** (**LSTM**)
    networks or transformers. These architectures allow the model to learn complex
    relationships between words, even words that are separated by large distances
    within the training text.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本质上，LLMs是一种**循环神经网络**（**RNN**）架构。传统的RNN在处理序列数据中的长期依赖关系时存在困难。为了解决这个问题，LLMs通常利用如**长短期记忆**（**LSTM**）网络或Transformer等架构。这些架构允许模型学习单词之间的复杂关系，即使这些单词在训练文本中相隔很远。
- en: 'Here is a simple illustration of a basic LLM architecture:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是基本LLM架构的一个简单示意图：
- en: '![Figure 1.1 — Flowchart explaining a basic LLM architecture](img/B31107_01_1-01.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图1.1 — 解释基本LLM架构的流程图](img/B31107_01_1-01.png)'
- en: Figure 1.1 — Flowchart explaining a basic LLM architecture
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 — 解释基本LLM架构的流程图
- en: Let’s dissect this architecture
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们剖析这个架构
- en: '**Input layer**: This layer receives the initial text prompt or sequence'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入层**：这一层接收初始文本提示或序列'
- en: '**Embedding layer**: Words in the input sequence are converted into numerical
    vectors, capturing their semantic meaning'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入层**：输入序列中的单词被转换为数值向量，捕捉其语义意义'
- en: '**Encoder**: This is a multi-layered RNN (e.g., LSTM) or transformer that processes
    the sequence of embedded words, capturing contextual information'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编码器**：这是一个多层RNN（例如，LSTM）或Transformer，它处理嵌入单词的序列，捕捉上下文信息'
- en: '**Decoder**: The decoder utilizes the encoded representation to generate the
    output sequence one word at a time'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解码器**：解码器利用编码表示逐词生成输出序列'
- en: 'You can read more about LLMs in this paper: https://arxiv.org/pdf/2307.06435.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这篇论文中了解更多关于LLMs的信息：https://arxiv.org/pdf/2307.06435。
- en: 'Building an LLM requires a lot of effort and resources. Let’s look at the number
    of parameters used by OpenAI to train each GPT model:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个LLM需要大量的努力和资源。让我们看看OpenAI为训练每个GPT模型所使用的参数数量：
- en: '**GPT-1**: This is the first model and used 117 million parameters.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-1**：这是第一个模型，使用了1.17亿个参数。'
- en: '**GPT-2**: This model used 1.5 billion parameters to train.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-2**：该模型使用了15亿个参数进行训练。'
- en: '**GPT-3**: This model was the first general-purpose model released. 175 billion
    parameters were used to train this model.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-3**：这是第一个发布的通用模型。该模型使用了1750亿个参数进行训练。'
- en: '**GPT-4 series**: This is the latest model released by OpenAI. 170 trillion
    parameters were used to train this model.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-4系列**：这是OpenAI发布的最新模型。该模型使用了170万亿个参数进行训练。'
- en: These training figures demonstrate that with each new version, the number of
    parameters increased by several orders of magnitude. This means more and more
    computing power is needed to train these models. Similar training numbers can
    be observed for other LLM models too.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这些训练数据表明，随着每个新版本的发布，参数数量增加了几个数量级。这意味着训练这些模型需要越来越多的计算能力。其他LLM模型也有类似的训练数据。
- en: While GenAI is a great technology, there are pitfalls as well as legal and ethical
    concerns about the application of this technology. We will take a look at them
    next.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然生成人工智能是一项伟大的技术，但其应用也存在陷阱以及法律和伦理问题。我们将在下一节探讨这些问题。
- en: Understanding GenAI’s pitfalls and ethical concerns
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解生成人工智能的陷阱和伦理问题
- en: While LLMs are great at summarizing, generating context, and other use cases,
    they still do not understand the language per se. They recognize patterns based
    on the training text to generate new text. They also don’t understand facts or
    understand emotions or ethics. They are simply predicting the next token and generating
    text. Because of these pitfalls, content generated by GenAI can have huge consequences.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然LLM在总结、生成上下文和其他用例方面很出色，但它们本身并不理解语言。它们根据训练文本识别模式来生成新文本。它们也不理解事实，不理解情感或伦理。它们只是预测下一个标记并生成文本。正因为这些缺陷，由GenAI生成的内容可能产生巨大的后果。
- en: To understand and address these aspects, we need to first identify any harmful
    or inaccurate content that is being generated and address it either by retraining
    the model or adding separate checks and balances to make sure this content is
    not used as output.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解和解决这些方面，我们首先需要识别正在生成的任何有害或不准确的内容，并通过重新训练模型或添加单独的检查和平衡来处理这些问题，以确保这些内容不会被用作输出。
- en: For example, there have been recent cases about using LLMs to generate legal
    briefs, where LLMs have created non-existent cases and generated a legal brief
    based on these cases. While technically it might have generated a solution that
    is requested, this is legally not correct. There have also been cases where LLMs
    are used to generate offensive images and videos and shared on the internet. Since
    it is difficult to identify content generated by AI, it is easy to be fooled by
    this content. This is neither socially, legally, or ethically acceptable. There
    are quite a few examples where LLMs simply make up facts.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，最近有关于使用LLM生成法律摘要的案例，其中LLM创建了不存在的案例并基于这些案例生成了法律摘要。虽然技术上可能生成了所需解决方案，但这在法律上是不正确的。也有案例表明LLM被用来生成冒犯性的图像和视频并在互联网上分享。由于难以识别AI生成的内容，很容易被这种内容欺骗。这在社会、法律和伦理上都是不可接受的。有很多例子表明LLM只是编造事实。
- en: This tutorial on the Microsoft site (https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/)
    provides a detailed explanation of these concerns and how we can identify them.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 微软网站上的这个教程（https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/）提供了这些担忧的详细解释以及我们如何识别它们。
- en: '**Retrieval-Augmented Generation** (**RAG**) and **knowledge graphs** together
    can help address these issues, which we discuss next.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**检索增强生成**（**RAG**）和**知识图谱**结合可以帮助解决这些问题，我们将在下一节讨论。'
- en: Understanding the importance of RAGs and knowledge graphs in LLMs
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解RAG（检索增强生成）和知识图谱在LLM（大型语言模型）中的重要性
- en: To address the pitfalls of GenAI, we can either fine-tune the model or ground
    the responses using other sources.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决GenAI的缺陷，我们可以通过微调模型或使用其他来源来使响应归因。
- en: '**Fine-tuning** involves training an existing model with additional information,
    which can result in high-quality responses. But this can be a complex and time-consuming
    process.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**微调**涉及使用额外信息训练现有模型，这可能导致高质量的响应。但这个过程可能既复杂又耗时。'
- en: The **RAG approach** involves providing extra information when we are asking
    the LLM a question.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**RAG方法**涉及在我们向LLM提问时提供额外信息。'
- en: With this approach, you can integrate knowledge repositories into the generative
    process. In this scenario, LLM can leverage the extra information retrieved from
    other sources and tune the response to match the information provided, thus grounding
    the results.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方法，可以将知识库集成到生成过程中。在这种情况下，LLM可以利用从其他来源检索到的额外信息，调整响应以匹配提供的信息，从而使结果归因。
- en: 'These repositories and sources can include the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些存储库和来源可以包括以下内容：
- en: '**Publicly available structured datasets** (e.g., scientific databases such
    as PubMed or publicly accessible encyclopedic resources such as Wikipedia)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公开可用的结构化数据集**（例如，如PubMed这样的科学数据库或如维基百科这样的公开可访问的百科全书资源）'
- en: '**Enterprise knowledge bases** (e.g., internal company documentation, product
    catalogs, or compliance-related content with strict privacy and security requirements)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**企业知识库**（例如，内部公司文档、产品目录或具有严格隐私和安全要求的合规相关内容）'
- en: '**Domain-specific sources** (e.g., legal case records, medical guidelines,
    or technical manuals tailored to specific industries)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特定领域的来源**（例如，法律案例记录、医疗指南或针对特定行业的定制技术手册）'
- en: By incorporating relevant information from these repositories and sources, RAG
    empowers LLMs to generate output that is not only factually accurate but also
    contextually aligned with the task at hand. Unlike the static knowledge encoded
    in the LLM’s training data, these additional data sources allow real-time retrieval
    of up-to-date and specialized information, addressing challenges such as data
    freshness, accuracy, and specificity. We will cover RAG in detail in [*Chapter
    2*](Preface.xhtml#_idTextAnchor011).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通过整合这些存储库和来源的相关信息，RAG赋予LLMs生成既符合事实又与当前任务上下文一致输出的能力。与LLM训练数据中编码的静态知识不同，这些额外的数据源允许实时检索最新和专业的信息，解决数据新鲜度、准确性和特定性等挑战。我们将在[*第二章*](Preface.xhtml#_idTextAnchor011)中详细讨论RAG。
- en: Another source of information to enable RAG is knowledge graphs. Let’s briefly
    talk about them and their role in the LLM landscape.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个信息来源，使RAG成为可能的是知识图谱。让我们简要谈谈它们及其在LLM领域的角色。
- en: The role of knowledge graphs in LLMs
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 知识图谱在LLMs中的作用
- en: Knowledge graphs play a huge role in generating creative and contextually rich
    content for LLMs. They provide a structured, interconnected foundation and make
    information retrieval more
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱在为LLMs生成富有创造性和上下文丰富的内容方面发挥着巨大作用。它们提供了一个结构化、相互关联的基础，使信息检索更加相关。
- en: relevant and insightful by grounding the AI results in a complex and multi-layered
    understanding of the data.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在复杂和多层次的数据理解中定位AI结果，使其相关且富有洞察力。
- en: Representing the data as a graph opens up more avenues to understand the data.
    At the same time, a knowledge graph cannot be a static entity that represents
    data in only one dimension that’s fixed. Its true power lies in its ability to
    be dynamic and multi-dimensional. It can capture temporal, spatial, or contextual
    information in real time through live data feeds.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据表示为图，为理解数据开辟了更多途径。同时，知识图谱不能是一个静态实体，只能在一个固定维度上表示数据。它的真正力量在于其动态和多维的能力。它可以通过实时数据流实时捕捉时间、空间或上下文信息。
- en: Apart from being an important tool for storing information, knowledge graphs
    are the backbone of intelligent, context-aware AI.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 除了作为存储信息的重要工具外，知识图谱还是智能、上下文感知AI的骨架。
- en: 'There are several reasons why knowledge graphs are essential for GenAI:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个原因说明知识图谱对GenAI至关重要：
- en: '**Enhanced contextual understanding**: Knowledge graphs allow GenAI systems
    to retrieve relevant information based on relationships, not just isolated facts.
    For example, in healthcare, a knowledge graph could link symptoms, diseases, and
    treatments, enabling GenAI to suggest more accurate diagnostic insights based
    on interconnected medical knowledge.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强的上下文理解**：知识图谱允许GenAI系统根据关系而非孤立的事实检索相关信息。例如，在医疗保健领域，知识图谱可以将症状、疾病和治疗联系起来，使GenAI能够基于相互关联的医学知识提出更准确的诊断见解。'
- en: '**Efficient data retrieval**: Unlike traditional databases, knowledge graphs
    allow multi-hop reasoning, from which GenAI can draw insights across several degrees
    of separation. This is invaluable in fields such as finance, where GenAI can use
    knowledge graphs to reveal hidden relationships between entities such as customers,
    transactions, and market trends.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高效的数据检索**：与传统数据库不同，知识图谱允许多跳推理，这使得GenAI可以从几个分离度中提取见解。这在金融等领域非常有价值，GenAI可以使用知识图谱揭示客户、交易和市场趋势等实体之间的隐藏关系。'
- en: '**Integration of vector embeddings**: When combined with vector embeddings,
    knowledge graphs enable GenAI to understand and respond to more nuanced queries.
    Vector embeddings capture semantic similarities between data points, which knowledge
    graphs then contextualize, creating a powerful blend of accuracy and relevance
    in responses.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量嵌入的集成**：当与向量嵌入结合时，知识图谱使GenAI能够理解和回应更细微的查询。向量嵌入捕捉数据点之间的语义相似性，知识图谱随后将其语境化，在响应中创造准确性和相关性相结合的强大组合。'
- en: '**Real-world impact**: Major organizations are already harnessing the power
    of knowledge graphs to enhance GenAI applications. For instance, companies in
    e-commerce use knowledge graphs to provide product recommendations that are not
    just relevant but contextually rich, drawing from diverse data sources such as
    customer reviews, purchase history, and product features.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**现实世界的影响**：主要组织已经开始利用知识图谱的力量来增强GenAI应用。例如，电子商务公司使用知识图谱提供不仅相关而且上下文丰富的产品推荐，这些推荐来自客户评价、购买历史和产品特性等多样化的数据源。'
- en: By integrating knowledge graphs, GenAI models transcend traditional data limitations,
    helping to create smarter, more reliable applications across different fields.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 通过整合知识图谱，GenAI模型超越了传统数据限制，有助于在不同领域创建更智能、更可靠的应用。
- en: Let’s now talk about **Neo4j knowledge graphs**.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们谈谈**Neo4j知识图谱**。
- en: Introducing Neo4j knowledge graphs
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Neo4j知识图谱
- en: A knowledge graph is dynamic and continues to evolve based on how data and relationships
    within the data evolve with time.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱是动态的，并随着数据及其关系随时间演变而持续发展。
- en: Neo4j is a database that excels with its ability to store data in graphs. For
    example, in a store, most products are laid out in a certain grouping and stay
    in those groups. But there is an exception to this arrangement. When a store wants
    to promote some products, they are placed at the front of the store. This kind
    of flexible thought process should be adapted for our knowledge graph implementation.
    As the semantics of data evolves the knowledge graph should be able to capture
    this change.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j是一个擅长以图形式存储数据的数据库。例如，在存储中，大多数产品都按照一定的分组排列并保持在那些组中。但这种情况有一个例外。当商店想要推广某些产品时，它们会被放置在商店的前面。这种灵活的思维方式应该适用于我们的知识图谱实现。随着数据语义的演变，知识图谱应该能够捕捉这种变化。
- en: Neo4j, with its multiple labels for nodes and its optional schema approach,
    makes it easy to keep our graph relevant by helping us to persist (retain) our
    understanding of data as an extra label on the node, or a specific relationship
    that provides more relevant context between the nodes. We will take a deeper look
    at how we can build a Neo4j knowledge graph from the ground up in the upcoming
    chapters.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Neo4j，凭借其节点上的多个标签和可选的架构方法，通过帮助我们以额外的标签或提供更多相关上下文的具体关系来持久化（保留）我们对数据的理解，使得保持我们的图相关变得容易。我们将在接下来的章节中深入探讨如何从头开始构建Neo4j知识图谱。
- en: For now, let’s see how a Neo4j knowledge graph works to enhance an LLM’s response.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看Neo4j知识图谱是如何增强LLM的响应的。
- en: Using Neo4j knowledge graphs with LLMs
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Neo4j知识图谱与LLMs
- en: Suppose there is an LLM-based chatbot integrated with a Neo4j knowledge graph.
    This GenAI chatbot is designed to answer medical queries. *Figure 1.2* illustrates
    how a Neo4j knowledge graph can enhance this chatbot’s medical reasoning by linking
    structured patient symptom records with unstructured insights from medical research
    papers and clinical trials.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有一个基于LLM的聊天机器人与Neo4j知识图谱集成。这个GenAI聊天机器人旨在回答医疗查询。*图1.2*展示了Neo4j知识图谱如何通过将结构化的患者症状记录与医学研究论文和临床试验中的非结构化见解联系起来，增强这个聊天机器人的医疗推理能力。
- en: 'The unstructured text undergoes embedding-based processing using models from
    providers such as **Ollama**, **OpenAI**, and **Hugging Face**, followed by **Named
    Entity Recognition** (**NER**), to extract key entities such as symptoms and treatments.
    This data is integrated into a Neo4j knowledge graph, where documents mention
    symptoms and treatments, patients show symptoms, and symptoms are linked to potential
    treatments. This enables **multi-hop reasoning**, allowing a chatbot to efficiently
    answer complex queries such as the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 非结构化文本经过基于嵌入的模型处理，这些模型由**Ollama**、**OpenAI**和**Hugging Face**等提供商提供，然后进行**命名实体识别**（NER），以提取关键实体，如症状和治疗。这些数据被集成到一个Neo4j知识图谱中，其中文档提到症状和治疗，患者表现出症状，症状与潜在的治疗方法相联系。这使**多跳推理**成为可能，允许聊天机器人有效地回答如下复杂查询：
- en: '*Which patients are showing symptoms similar to flu and also showed symptoms
    of COVID-19 in the past?*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*哪些患者表现出与流感相似的症状，并且在过去也表现出COVID-19的症状？*'
- en: '![Figure 1.2 — Neo4j knowledge graph driven Gen-AI for healthcare](img/B31107_01_2.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图1.2 — 由Neo4j知识图谱驱动的医疗保健Gen-AI](img/B31107_01_2.png)'
- en: Figure 1.2 — Neo4j knowledge graph driven Gen-AI for healthcare
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 — 由Neo4j知识图谱驱动的医疗保健Gen-AI
- en: 'To retrieve the result of this query, a **multi-hop knowledge graph query path**
    (*Figure 1.2*) will be followed in this order:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检索此查询的结果，将按照以下顺序遵循**多跳知识图谱查询路径**（*图1.2*）：
- en: Retrieve symptoms linked to flu from research documents.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从研究文档中检索与流感相关的症状。
- en: Identify patients currently showing those symptoms.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别目前表现出这些症状的患者。
- en: Cross-reference past patient records for COVID-19 symptoms.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对比过去患者的COVID-19症状记录。
- en: Return patients who match both conditions with supporting document sources.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回同时符合两种条件并具有支持性文档来源的患者。
- en: With this approach, the LLM response can be grounded to generate factually correct,
    relevant, and up-to-date results to support medical decision-making.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 采用这种方法，LLM的响应可以基于事实正确、相关且最新的结果来支持医疗决策。
- en: A similar approach can be used to augment LLMs that support other applications.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 类似的方法也可以用来增强支持其他应用的LLMs。
- en: We have now looked at how knowledge graphs enhance GenAI’s ability to provide
    contextually rich, accurate insights. But how does this transformative power translate
    into concrete benefits in real life? We will continue this journey in the rest
    of the book.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经看到了知识图谱如何增强GenAI提供上下文丰富、准确洞察的能力。但是，这种变革力量如何转化为现实生活中的具体好处呢？我们将在本书的剩余部分继续这一旅程。
- en: Summary
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the evolution of GenAI in the context of LLMs.
    We also looked at how RAG and knowledge graphs are key enablers of this transformation
    and help provide structure and context, improving an LLM’s accuracy and reasoning.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了在LLMs背景下GenAI的演变。我们还探讨了RAG和知识图谱是如何成为这一变革的关键推动者，并有助于提供结构和上下文，从而提高LLM的准确性和推理能力。
- en: Looking ahead, the next chapter dives deep into RAG — a technique that significantly
    enhances GenAI’s accuracy by grounding responses in retrieved, verified information.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 展望未来，下一章将深入探讨RAG——一种通过在检索到的、验证过的信息中定位响应来显著提高GenAI准确性的技术。
