- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Azure OpenAI Fundamentals
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Azure OpenAI基础知识
- en: In the previous chapter, we talked about **large language models** (**LLMs**),
    LLM concepts, and different enterprise-ready LLM examples. We also talked about
    foundation model concepts and discussed different use cases for LLMs. In this
    chapter, we’re going to dive into **Azure OpenAI** (**AOAI**) Service, different
    model types, how to deploy models, and various pricing aspects.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了**大型语言模型**（**LLMs**）、LLM的概念以及不同的企业级LLM示例。我们还讨论了基础模型的概念，并探讨了LLM的不同应用场景。在本章中，我们将深入探讨**Azure
    OpenAI**（**AOAI**）服务、不同的模型类型、如何部署模型以及各种定价方面。
- en: 'We will navigate the following sections in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨以下内容：
- en: What is AOAI Service?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是AOAI服务？
- en: AOAI model types
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AOAI模型类型
- en: Accessing AOAI Service
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问AOAI服务
- en: Creating AOAI resources
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建AOAI资源
- en: Deploying AOAI models
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署AOAI模型
- en: Utilizing AOAI models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用AOAI模型
- en: Pricing
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定价
- en: But before we get into all that, let’s understand the Microsoft and OpenAI partnership
    a bit better.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨这些内容之前，让我们先更好地了解微软与OpenAI的合作关系。
- en: Microsoft has made a multi-billion-dollar investment into OpenAI to make sure
    they can develop advanced AI technology and share its benefits with everyone.
    This partnership builds upon Microsoft’s previous investments in 2019 and 2021\.
    This allows both Microsoft and OpenAI to use the advanced AI technology they create
    for their businesses. Microsoft is also invested in powerful supercomputers to
    help OpenAI with their important AI research.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 微软向OpenAI投资了数十亿美元，确保他们能够开发先进的AI技术，并与大家共享其成果。这一合作关系建立在微软2019年和2021年的先前投资基础上。这使得微软和OpenAI能够将他们所创造的先进AI技术应用于各自的业务中。微软还投资了强大的超级计算机，以帮助OpenAI进行重要的AI研究。
- en: Microsoft has formed a strategic partnership with OpenAI, integrating their
    advanced LLMs while doing so. They use OpenAI’s models in various products and
    are creating innovative digital experiences. Microsoft has a service called AOAI
    where developers can harness the power of cutting-edge models, combined with Microsoft’s
    robust tools. Microsoft is the only company providing cloud services for OpenAI,
    which means they will handle all the computing work for OpenAI’s research, products,
    and services to build sophisticated AI applications. This collaboration enables
    the creation of transformative solutions, unlocking new possibilities in AI-driven
    development. In the next section, we’ll dive deeper into AOAI Service and how
    to use it.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 微软与OpenAI建立了战略合作伙伴关系，并在此过程中整合了其先进的大型语言模型（LLM）。他们在多种产品中使用OpenAI的模型，并创造出创新的数字体验。微软有一项名为AOAI的服务，开发者可以利用前沿模型的强大功能，同时结合微软的强大工具。微软是唯一为OpenAI提供云服务的公司，这意味着他们将处理OpenAI的研究、产品和服务所需的所有计算工作，以便构建复杂的AI应用程序。此次合作促成了变革性解决方案的诞生，为基于AI的开发开启了新的可能性。在下一节中，我们将深入探讨AOAI服务以及如何使用它。
- en: What is AOAI Service?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是AOAI服务？
- en: 'Microsoft offers a wide range of AI tools and solutions to help customers at
    every stage of their AI journey, regardless of their team’s expertise. Whether
    you’re new to AI or have specific use cases in mind, Microsoft has you covered.
    They provide easy-to-use options for those starting while also supporting data
    scientists with more advanced needs. When you explore the Azure AI offerings,
    you have the freedom to start with high-level AI services and dig deeper into
    the Azure Machine Learning platform to build, train, tune, and deploy deep learning
    models at scale. The overall Azure AI stack is shown in the following diagram:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 微软提供了广泛的AI工具和解决方案，帮助客户在AI旅程的各个阶段取得进展，无论其团队的技术水平如何。无论你是AI的新手，还是已经有具体应用场景的用户，微软都能满足你的需求。对于初学者，他们提供了易于使用的选项；对于有更高需求的数据科学家，他们也提供了支持。探索Azure
    AI产品时，你可以自由地从高级AI服务入手，深入了解Azure机器学习平台，构建、训练、调优并大规模部署深度学习模型。整体Azure AI架构如下图所示：
- en: '![Figure 2.1 – Azure AI stack](img/B21019_02_1.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图2.1 – Azure AI架构](img/B21019_02_1.jpg)'
- en: Figure 2.1 – Azure AI stack
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 – Azure AI架构
- en: 'At the top layer, you have AI services for specific applications, such as **Cognitive
    Search**, **Bot Service**, and **Document Intelligence**. There are also domain-specific
    pretrained models such as **Vision**, **Speech**, **Language**, **Decision**,
    and **Azure OpenAI Service**. These are built on the foundation of Azure Machine
    Learning as a managed endpoint. If you’re using AI services, you don’t need to
    worry about the foundation layer. However, if you want to access the foundation
    layer so that you have control, you can use the bottom layer: **Azure Machine
    Learning**. It’s a managed end-to-end machine learning platform for building,
    training, deploying, and operating machine learning models responsibly and securely
    at scale.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在最上层，你可以找到针对特定应用的 AI 服务，如**认知搜索**、**机器人服务**和**文档智能**。还有一些领域特定的预训练模型，如**视觉**、**语音**、**语言**、**决策**和**Azure
    OpenAI 服务**。这些模型建立在 Azure 机器学习的基础上，作为一个托管端点。如果你使用 AI 服务，就不需要担心基础层。然而，如果你希望访问基础层并控制它，可以使用最底层：**Azure
    机器学习**。它是一个端到端托管的机器学习平台，旨在负责任且安全地大规模构建、训练、部署和操作机器学习模型。
- en: AOAI Service (marked in a red rectangular box in *Figure 2**.1*) is a new Azure
    AI Service that provides REST API access to OpenAI’s powerful language models,
    including the GPT-4 Turbo, GPT-4o, GPT4-o mini, GPT-3.5 Turbo, Whisper, DALL-E
    3, and Embeddings model series. They have enterprise capabilities such as security,
    private networking, compliance, regional availability, and responsible AI content
    filtering that are available only on Microsoft Azure. These models can be easily
    adapted for a variety of tasks, including but not limited to content generation,
    summarization, semantic search, and natural language to code translation. Users
    can access the various services through REST APIs, the Python SDK, or a web-based
    interface in Azure AI Foundry.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI 服务（在*图 2.1*中的红色矩形框内标记）是一个新的 Azure AI 服务，提供对 OpenAI 强大语言模型的 REST API 访问，包括
    GPT-4 Turbo、GPT-4o、GPT-4o mini、GPT-3.5 Turbo、Whisper、DALL-E 3 和 Embeddings 模型系列。它们具有企业级功能，如安全性、私有网络、合规性、区域可用性和负责任的
    AI 内容过滤，这些功能仅在 Microsoft Azure 上提供。这些模型可以轻松适应各种任务，包括但不限于内容生成、摘要、语义搜索和自然语言到代码的翻译。用户可以通过
    REST API、Python SDK 或 Azure AI Foundry 中的基于 Web 的界面访问各种服务。
- en: Now, let’s talk about the different model types in AOAI.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来讨论 AOAI 中的不同模型类型。
- en: AOAI model types
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AOAI 模型类型
- en: 'AOAI Service offers various models that can do different things and have different
    costs. Let’s dive into the different model types and their usability:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI 服务提供了多种不同的模型，它们可以做不同的事情，并且有不同的费用。让我们深入了解不同的模型类型及其可用性：
- en: '**GPT base**: GPT base models can comprehend and produce both natural language
    and code but lack specific training in following instructions. They’re designed
    to serve as alternatives to original GPT-3 base models and rely on the legacy
    Completions API. For most users, we recommend utilizing GPT-3.5 or GPT-4 for their
    tasks. These models come in two different variations:'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT 基础模型**：GPT 基础模型可以理解并生成自然语言和代码，但在遵循指令方面没有经过特别训练。它们设计为原始 GPT-3 基础模型的替代品，并依赖于传统的
    Completions API。对于大多数用户，我们建议使用 GPT-3.5 或 GPT-4 来完成他们的任务。这些模型有两种不同的变体：'
- en: '**Babbage-002**: Serves as a replacement for the GPT-3 ada and babbage base
    models. It can support up to 16,384 tokens and can be fine-tuned.'
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Babbage-002**：作为 GPT-3 的 Ada 和 Babbage 基础模型的替代品。它可以支持最多 16,384 个 token 并可以进行微调。'
- en: '**Davinci-002**: Serves as a replacement for the GPT-3 curie and davinci base
    models. It can support up to 16,384 tokens and can be fine-tuned.'
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Davinci-002**：作为 GPT-3 的 Curie 和 Davinci 基础模型的替代品。它可以支持最多 16,384 个 token
    并可以进行微调。'
- en: '**GPT-4**: This is the latest model and is used for solving complex problems.
    It’s even more accurate than any of OpenAI’s earlier models. GPT4 models are capable
    of understanding and producing both natural language and coden along with advanced
    reasoning capabilities. It’s an optimized chat completion model, which means it’s
    best suited for interactive chat applications and performs exceptionally well
    with regular completion tasks. Being a large, highly optimized model, GPT-4 is
    capable of excelling at both interactive chats as well as completion activities.
    The latest GPT-4 class has three types of flagship models:'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-4**：这是最新的模型，适用于解决复杂问题。它比 OpenAI 之前的任何模型都更准确。GPT-4 模型能够理解并生成自然语言和计算机代码，并具备高级推理能力。它是一个优化的聊天完成模型，意味着它最适合互动聊天应用，并且在常规的完成任务中表现优异。作为一个大型、高度优化的模型，GPT-4
    在互动聊天和完成任务方面都能出色地表现。最新的 GPT-4 类模型包括三种旗舰型号：'
- en: '**GPT-4 Turbo**: This model supports a maximum of 128,000 input tokens/context
    window and 4,096 output tokens'
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-4 Turbo**：此模型支持最多 128,000 个输入标记/上下文窗口和 4,096 个输出标记。'
- en: '**GPT-4o**: This model supports a maximum of 128,000 input tokens/context window
    and 4,096 output tokens'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-4o**：此模型支持最多 128,000 个输入标记/上下文窗口和 4,096 个输出标记。'
- en: '**GPT-4o mini**: This model supports a maximum of 128,000 input tokens/context
    window and 16,384 output tokens'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-4o mini**：此模型支持最多 128,000 个输入标记/上下文窗口和 16,384 个输出标记。'
- en: '**GPT-3.5**: GPT-3.5 represents a series of models that build upon the capabilities
    of GPT-3\. These models excel at comprehending and generating both human language
    and computer code. Among the GPT-3.5 models, the most capable and cost-efficient
    one is GPT-3.5 Turbo. It’s specifically fine-tuned for interactive conversations
    and performs well when it comes to regular completion tasks. The latest version
    of GPT-3.5 also comes in two different flavors:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-3.5**：GPT-3.5 代表一系列基于 GPT-3 能力的模型。这些模型在理解和生成自然语言以及计算机代码方面表现出色。在 GPT-3.5
    模型中，最强大且最具成本效益的是 GPT-3.5 Turbo。它专门为互动对话进行微调，在常规完成任务中表现良好。GPT-3.5 的最新版本还提供两种不同的版本：'
- en: '**gpt-35-turbo-1106**: This model supports a maximum of 16,385 input tokens/context
    window and 4,096 output tokens.'
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**gpt-35-turbo-1106**：此模型支持最多 16,385 个输入标记/上下文窗口和 4,096 个输出标记。'
- en: '**gpt-35-turbo-0125**: This model supports a maximum of 16,385 input tokens/context
    window and 4,096 output tokens.'
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**gpt-35-turbo-0125**：此模型支持最多 16,385 个输入标记/上下文窗口和 4,096 个输出标记。'
- en: '**isgpt-35-turbo-instruct**: This model supports a maximum of 4,097 input tokens/context
    window. This model cannot be fine-tuned.'
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**isgpt-35-turbo-instruct**：此模型支持最多 4,097 个输入标记/上下文窗口。此模型无法进行微调。'
- en: Important note
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: GPT-3.5 Turbo Instruct offers comparable capabilities to text-davinci-003 but
    utilizes the Completions API, not the Chat Completions API. We strongly advise
    utilizing GPT-3.5 Turbo and GPT-3.5 Turbo Instruct rather than the older GPT-3.5
    and GPT-3 models.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5 Turbo Instruct 提供的能力与 text-davinci-003 相当，但使用的是 Completions API，而非 Chat
    Completions API。我们强烈建议使用 GPT-3.5 Turbo 和 GPT-3.5 Turbo Instruct，而不是旧版本的 GPT-3.5
    和 GPT-3 模型。
- en: 'Here’s an interactive chat example that can employ either GPT-3.5 or GPT-4\.
    Typically, you input a prompt as the user, and the model responds to the completion
    (model output). This can be a continuous exchange in conversation:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个互动聊天示例，可以使用 GPT-3.5 或 GPT-4。通常，用户输入提示，模型生成完成（模型输出）。这可以是一个持续的对话交流：
- en: '![Figure 2.2: Basic prompt and completion example](img/B21019_02_2.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.2：基础提示和完成示例](img/B21019_02_2.jpg)'
- en: 'Figure 2.2: Basic prompt and completion example'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2：基础提示和完成示例
- en: Along with prompt completion, there’s one more concept you need to understand
    about tokens. When you send a prompt to GPT-3.5 or GPT-4, it undergoes tokenization
    through the embedding process, where words or – more commonly – parts of words
    are converted into numeric vector representations. Numeric tokens are used instead
    of full words or sentences to process the information. This design allows the
    GPT model to handle relatively large volumes of text. However, there is a constraint
    regarding tokens in GPT-3.5 and GPT-4 (depending on which model type you choose,
    as mentioned previously) for both the input prompt and the generated completion
    combined.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 除了提示完成，您还需要理解令牌的另一个概念。当您将提示发送到 GPT-3.5 或 GPT-4 时，它会通过嵌入过程进行分词，其中单词或—更常见的是—单词的一部分会转换为数字向量表示。数字令牌代替完整的单词或句子来处理信息。这种设计使得
    GPT 模型能够处理相对较大量的文本。然而，GPT-3.5 和 GPT-4（根据您选择的模型类型，如前所述）在输入提示和生成的完成内容上有令牌约束。
- en: 'To ensure you stay within the token limit, you can estimate the number of tokens
    required for your prompt and the resulting completion. As a rough guideline, in
    English, every four characters typically correspond to one token. Therefore, you
    can calculate the tokens needed by adding the character count of your prompt to
    the desired response length and dividing the total by four. This calculation provides
    you with a rough estimate of the token count required, which is valuable for planning
    tasks where token constraints must be kept in mind. *Figure 2**.3* shows an example
    of the tokens for a given sentence:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保您不超过令牌限制，您可以估算输入提示和生成结果所需的令牌数量。作为粗略指南，英语中每四个字符通常对应一个令牌。因此，您可以通过将提示的字符数与期望的回复长度相加，然后将总数除以四来计算所需的令牌数。这个计算可以为您提供一个大致的令牌数量估算，这对于需要考虑令牌约束的任务规划非常有价值。*图
    2.3*展示了给定句子的令牌示例：
- en: '![Figure 2.3: Token counter](img/B21019_02_3.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.3：令牌计数器](img/B21019_02_3.jpg)'
- en: 'Figure 2.3: Token counter'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3：令牌计数器
- en: In this example, there are a total of seven tokens. Notably, the word “generative”
    is represented by two distinct tokens, while the remaining words are each represented
    by a single token.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，总共有七个令牌。值得注意的是，“generative”一词由两个不同的令牌表示，而其余词汇则每个由一个令牌表示。
- en: '**Embedding models**: An embedding is a list of vectors of floating-point numbers.
    When we measure how far apart two of these vectors are, it tells us how similar
    or different they are. If the distance is small, it means they’re very similar,
    but if it’s large, it means they’re quite different. When you input raw text into
    an embedding model, it produces a list of vector representations for the provided
    text:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入模型**：嵌入是浮动点数字向量的列表。当我们衡量两个向量之间的距离时，它告诉我们它们的相似性或差异性。如果距离较小，表示它们非常相似；如果距离较大，则表示它们差异较大。当您将原始文本输入嵌入模型时，它会生成该文本的向量表示列表：'
- en: '![Figure 2.4: Basic embedding process](img/B21019_02_4.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.4：基本嵌入过程](img/B21019_02_4.jpg)'
- en: 'Figure 2.4: Basic embedding process'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4：基本嵌入过程
- en: In practice, you provide a collection of document words to an embedding model
    as input, which then uses them to create an embedding vector. This vector is usually
    stored in a vector database, such as Azure Cognitive Search or Azure Cosmos DB.
    Subsequently, when a user submits a query, it passes through the same embedding
    model to generate a query vector, which is used to search for similar vectors
    in the vector database. This pattern is called **retrieval-augmented** **generation**
    (**RAG**).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，您将一组文档词汇提供给嵌入模型作为输入，嵌入模型随后使用这些词汇生成嵌入向量。该向量通常存储在一个向量数据库中，如 Azure Cognitive
    Search 或 Azure Cosmos DB。随后，当用户提交查询时，它会通过相同的嵌入模型生成一个查询向量，该向量用于在向量数据库中搜索相似的向量。这种模式称为**检索增强生成**（**RAG**）。
- en: 'The following figure illustrates this process:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了这一过程：
- en: '![Figure 2.5: Document embedding process](img/B21019_02_5.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.5：文档嵌入过程](img/B21019_02_5.jpg)'
- en: 'Figure 2.5: Document embedding process'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5：文档嵌入过程
- en: 'At the time of writing, AOAI service offers four different types of embedding
    models:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，AOAI 服务提供了四种不同类型的嵌入模型：
- en: '**text-embedding-ada-002 (version 1)**: This version uses the GPT-2/GPT-3 tokenizer.
    It can handle a maximum of **2,046** input tokens and provides an output with
    **1,024** dimensions.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**text-embedding-ada-002（版本 1）**：此版本使用 GPT-2/GPT-3 分词器。它可以处理最多**2,046**个输入令牌，并提供**1,024**维度的输出。'
- en: '**text-embedding-ada-002 (version 2)**: This version uses the cl100k_base tokenizer.
    It supports a four times larger input with a maximum of **8,191** tokens and returns
    an output with **1,536** dimensions. This is the second-generation embedding model.
    We highly recommend using text-embedding-ada-002 version 2 as it provides parity
    with OpenAI’s text-embedding-ada-002 model in terms of its capabilities and performance.
    This model is not only more cost-effective but also simpler and more efficient.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**text-embedding-ada-002 (版本 2)**: 该版本使用cl100k_base分词器，支持四倍于前版本的输入，最多可处理**8,191**个令牌，并返回**1,536**维的输出。这是第二代嵌入模型。我们强烈推荐使用text-embedding-ada-002版本2，因为它在功能和性能上与OpenAI的text-embedding-ada-002模型相当。该模型不仅更加经济高效，而且更简单、更高效。'
- en: '**text-embedding-3-small**: The new text-embedding-3-small model significantly
    outperforms its predecessor, text-embedding-ada-002, with an increase in benchmark
    scores from 31.4% to 44.0% for multi-language retrieval and from 61.0% to 62.3%
    for English tasks. Additionally, it is five times more cost-effective, reducing
    the price from $0.0001 to $0.00002 per 1k tokens. While text-embedding-ada-002
    will remain available, text-embedding-3-small is recommended for its improved
    efficiency and performance. A new model, text-embedding-3-large, offers even greater
    capacity with embeddings for up to 3,072 dimensions.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**text-embedding-3-small**: 新的text-embedding-3-small模型显著优于其前身text-embedding-ada-002，在多语言检索的基准分数上从31.4%提高至44.0%，在英语任务上从61.0%提高至62.3%。此外，它在成本效益方面提高了五倍，将每千个令牌的价格从$0.0001降至$0.00002。虽然text-embedding-ada-002仍将保持可用，但由于其更高的效率和性能，推荐使用text-embedding-3-small。一款新模型text-embedding-3-large提供了更大的容量，支持最多3,072维度的嵌入。'
- en: '**text-embedding-3-large**: The new text-embedding-3-large model is the top-performing
    embedding model, showing substantial improvements over text-embedding-ada-002\.
    It achieves an average score of 54.9% on the MIRACL benchmark and 64.6% on the
    MTEB benchmark, up from 31.4% and 61.0%, respectively. Priced at $0.00013 per
    1k tokens, text-embedding-3-large offers the highest performance among other embedding
    models, surpassing both text-embedding-3-small and text-embedding-ada-002.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**text-embedding-3-large**: 新的text-embedding-3-large模型是性能最强的嵌入模型，较text-embedding-ada-002有了显著的提升。在MIRACL基准测试中，它的平均分为54.9%，在MTEB基准测试中的分数为64.6%，分别高于31.4%和61.0%。text-embedding-3-large的定价为每千个令牌$0.00013，在所有嵌入模型中提供了最高的性能，超越了text-embedding-3-small和text-embedding-ada-002。'
- en: To create a generative AI application, the key models you’ll primarily need
    are the ones mentioned here. It’s important to note that these models have only
    been trained on an extensive dataset that goes up to September 2021\. Therefore,
    they don’t possess any knowledge or information beyond that date. If you want
    to create a generative AI application that incorporates the most up-to-date information,
    you can explore a technique known as **RAG**. We’ll explore this technique in
    more detail later in this book, providing hands-on tutorials and in-depth discussions.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个生成式AI应用程序，您主要需要的关键模型就是此处提到的模型。值得注意的是，这些模型仅在一个截止到2021年9月的大型数据集上进行过训练。因此，它们不具备该日期之后的任何知识或信息。如果您想要创建一个包含最新信息的生成式AI应用，您可以探索一种被称为**RAG**的技术。我们将在本书后面详细探讨这一技术，提供实践教程和深入讨论。
- en: 'There are additional models available as part of AOAI Service, including the
    following:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI服务中还提供了其他模型，包括以下模型：
- en: '**DALL-E 3**: This model can generate realistic images and artwork based on
    a description provided in natural language.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DALL-E 3**: 该模型能够根据自然语言描述生成真实感的图像和艺术作品。'
- en: '**Whisper**: This is a general-purpose speech recognition (ASR) model. It has
    been trained on 680,000 hours of a vast and varied dataset containing both audio
    and text, and it can handle various tasks, such as recognizing speech in multiple
    languages, translating spoken words, and identifying languages. Whisper utilizes
    an encoder-decoder architecture based on Transformers, allowing it to convert
    spoken words into written text, and it can also handle special tokens to indicate
    the task or language involved. This model can be accessed through AOAI Service
    or Azure Speech.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Whisper**: 这是一个通用的语音识别（ASR）模型。它已经在包含音频和文本的680,000小时的庞大且多样化的数据集上进行训练，能够处理多种任务，例如识别多种语言的语音、翻译口语和识别语言。Whisper采用基于Transformer的编码器-解码器架构，能够将口语转化为书面文本，并且还可以处理特殊令牌来指示涉及的任务或语言。此模型可以通过AOAI服务或Azure语音访问。'
- en: Now that we’ve discussed various types of models, let’s discuss how to get access
    to AOAI Service.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了各种类型的模型，接下来我们来讨论如何获得AOAI服务的访问权限。
- en: Accessing AOAI Service
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问AOAI服务
- en: To access AOAI, you need to have an Azure account with an active subscription
    and AOAI access enabled. This section we will walk you through how to get AOAI
    Service access.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问AOAI，您需要拥有一个有效订阅和启用AOAI访问的Azure账户。本节将引导您如何获取AOAI服务访问权限。
- en: '*Step 1: Create an* *Azure account.*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤1：创建* *Azure账户*。'
- en: 'At the time of writing, AOAI access can only be approved for enterprise customers
    and partners. So, technically, you can create an Azure account using one of four
    options ([https://learn.microsoft.com/en-us/dotnet/azure/create-azure-account](https://learn.microsoft.com/en-us/dotnet/azure/create-azure-account)).
    However, when creating an account, you must use your company email address; personal
    email accounts will not be approved for AOAI access:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文写作时，AOAI的访问权限仅限于企业客户和合作伙伴。因此，技术上，您可以使用四种选项中的一种创建一个Azure账户（[https://learn.microsoft.com/en-us/dotnet/azure/create-azure-account](https://learn.microsoft.com/en-us/dotnet/azure/create-azure-account)）。但是，在创建账户时，您必须使用公司的电子邮件地址；个人邮箱将无法获得AOAI访问权限：
- en: '**Option 1**: Visual Studio subscribers can use monthly Azure credits. This
    option allows you to activate your credits and use them for AOAI.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选项1**：Visual Studio订阅者可以使用每月的Azure积分。此选项允许您激活积分并将其用于AOAI。'
- en: '**Option 2**: Sign up for a free Azure account. This option gives you 12 months
    of free services and $200 credit to explore Azure for 30 days. You can use this
    credit for AOAI if you’ve been approved.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选项2**：注册免费Azure账户。此选项为您提供12个月的免费服务和200美元的积分，您可以在30天内使用这些积分探索Azure。如果您已获得批准，可以使用这些积分用于AOAI。'
- en: '**Option 3**: Sign up for a pay-as-you-go account. This option charges you
    for what you use beyond the free limits. You can pay for AOAI with this option
    if you’ve been approved.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选项3**：注册按需付费账户。此选项会根据您超出免费额度的使用量收费。如果您已获得批准，您可以使用此选项为AOAI付费。'
- en: '**Option 4**: Use a corporate account. This option requires your company to
    have a cloud administrator who can grant you access to AOAI.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选项4**：使用企业账户。此选项要求您的公司有一个云管理员来授予您访问AOAI的权限。'
- en: 'Once you create an Azure account, you will get a default Azure subscription.
    You can use that or create a new one to access AOAI:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 创建Azure账户后，您将获得一个默认的Azure订阅。您可以使用该订阅，或者创建一个新的订阅来访问AOAI：
- en: 'You can find your subscription information under the **Subscriptions** resource:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以在**订阅**资源下找到您的订阅信息：
- en: '![Figure 2.6: Locating Subscriptions](img/B21019_02_6.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图2.6：查找订阅](img/B21019_02_6.jpg)'
- en: 'Figure 2.6: Locating Subscriptions'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6：查找订阅
- en: 'Note down the **Subscription ID** value; you’ll need it to apply for AOAI access:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 记下**订阅ID**值；您将需要它来申请AOAI访问权限：
- en: '![Figure 2.7: Retrieving subscriptions details](img/B21019_02_7.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图2.7：检索订阅详细信息](img/B21019_02_7.jpg)'
- en: 'Figure 2.7: Retrieving subscriptions details'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7：检索订阅详细信息
- en: '*Step 2: Apply* *AOAI access.*'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤2：申请* *AOAI访问权限*。'
- en: 'To apply AOAI access, follow these steps:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要申请AOAI访问权限，请按照以下步骤操作：
- en: AOAI is a restricted general availability service. Typically, you will have
    access to create AOAI resources in your subscriptions. If you don’t have access,
    you must complete the form provided at [https://aka.ms/oaiapply](https://aka.ms/oaiapply).
    Please ensure that you use your company email address when filling out this form.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AOAI是一个受限的通用可用性服务。通常，您可以在您的订阅中创建AOAI资源。如果您没有访问权限，必须填写[https://aka.ms/oaiapply](https://aka.ms/oaiapply)提供的表单。请确保在填写表单时使用公司的电子邮件地址。
- en: Upon completing the form, it will take approximately 3-4 days for it to be approved.
    Once your access is approved, you will receive an email from the Azure Cognitive
    Service Team.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填写表单后，大约需要3-4天才能批准。一旦您的访问权限获得批准，您将收到Azure认知服务团队的电子邮件。
- en: This approval will allow you to access and use AOAI models.
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此批准将允许您访问和使用AOAI模型。
- en: With that, we’ve covered how to obtain access to AOAI Service. Now, let’s turn
    our attention to how to utilize these models effectively.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，我们已经介绍了如何获得AOAI服务的访问权限。接下来，我们将重点讨论如何有效地利用这些模型。
- en: Creating AOAI resources
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建AOAI资源
- en: 'After gaining access to AOAI models, you can create an AOAI resource to deploy
    the models. This section will guide you through the process of creating AOAI resources:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 获得AOAI模型的访问权限后，您可以创建AOAI资源来部署模型。本节将指导您完成创建AOAI资源的过程：
- en: Log in to the Azure subscription that you created previously within the Azure
    portal ([https://portal.azure.com/](https://portal.azure.com/)).
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到您之前在Azure门户（[https://portal.azure.com/](https://portal.azure.com/)）中创建的Azure订阅。
- en: 'Navigate to `Azure OpenAI`. Once you find the service, click **Create**:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到`Azure OpenAI`。找到该服务后，点击**创建**：
- en: "![Figure 2.\uFEFF8: Creating an AOAI resource](img/B21019_02_8.jpg)"
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图2.8：创建AOAI资源](img/B21019_02_8.jpg)'
- en: 'Figure 2.8: Creating an AOAI resource'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8：创建AOAI资源
- en: 'On the AOAI **Creation** page, provide the subsequent details within the **Basics**
    tab’s fields:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AOAI**创建**页面中，在**基本**选项卡的字段中提供以下详细信息：
- en: '| **Field** | **Description** |'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| **字段** | **描述** |'
- en: '| **Subscriptions** | The Azure subscription mentioned in your application
    for onboarding AOAI Service. |'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| **订阅** | 在您的应用程序中提到的Azure订阅，用于接入AOAI服务。 |'
- en: '| **Resource Group** | The Azure resource group that will contain your AOAI
    resource. You can create a new group or use a pre-existing one. |'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| **资源组** | 包含您的AOAI资源的Azure资源组。您可以创建一个新的资源组或使用现有的资源组。 |'
- en: '| **Region** | The geographical location of your instance. Varying locations
    can potentially introduce latency but won’t impact the operational availability
    of your resource. |'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| **区域** | 您实例的地理位置。不同的区域可能会引入延迟，但不会影响资源的操作可用性。 |'
- en: '| **Name** | A descriptive name for your AOAI Service resource. |'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| **名称** | 为您的AOAI服务资源提供一个描述性的名称。 |'
- en: '| **Pricing Tier** | The pricing tier for the resource. At the time of writing,
    AOAI Service only offers the Standard tier. |'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| **定价层级** | 资源的定价层级。目前，AOAI服务仅提供标准层。 |'
- en: 'Table 2.1: AOAI resource creation details'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 表2.1：AOAI资源创建详细信息
- en: 'Now, let’s create the AOAI resource by providing these details in the **Basics**
    tab:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们通过在**基本**选项卡中提供以下详细信息来创建AOAI资源：
- en: "![Figure 2.\uFEFF9: Basic information to create an AOAI resource](img/B21019_02_9.jpg)"
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图2.9：创建AOAI资源的基本信息](img/B21019_02_9.jpg)'
- en: 'Figure 2.9: Basic information to create an AOAI resource'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9：创建AOAI资源的基本信息
- en: Click **Next**.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**下一步**。
- en: 'The **Network** tab offers three options for security. You can select option
    2 or 3 from within the **Network** tab if you require enhanced security during
    deployment. This choice allows you to configure AOAI for increased security, making
    it accessible through Azure Virtual Network integration and a private endpoint
    connection. Later in this book, we will focus on exploring options 2 and 3\. For
    now, choose option 1 (**All networks, including the internet, can access this
    resource.**) to access the resource:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**网络**选项卡提供三种安全选项。如果在部署过程中需要增强的安全性，您可以从**网络**选项卡中选择选项2或选项3。此选项允许您为AOAI配置更高的安全性，使其可以通过Azure虚拟网络集成和私有端点连接访问。本书稍后将重点介绍选项2和选项3。目前，选择选项1（**所有网络，包括互联网，都可以访问此资源。**）以访问资源：'
- en: "![Figure 2.1\uFEFF0: Public access network settings to create an AOAI resource](img/B21019_02_10.jpg)"
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图2.10：创建AOAI资源的公共访问网络设置](img/B21019_02_10.jpg)'
- en: 'Figure 2.10: Public access network settings to create an AOAI resource'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10：创建AOAI资源的公共访问网络设置
- en: Proceed by clicking **Next** and configure any tags for your resource as needed.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续点击**下一步**，根据需要为您的资源配置标签。
- en: 'Click **Next** to advance to the final stage of the process: **Review +** **submit**.'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**下一步**进入过程的最后阶段：**审阅+提交**。
- en: Verify your configuration settings, then click **Create** to initiate the process.
    Please be patient; this process may take 2-3 minutes to complete.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证您的配置设置，然后点击**创建**以启动过程。请耐心等待；该过程可能需要2-3分钟完成。
- en: The Azure portal will notify you once the new resource becomes available. Click
    **Go to resource** to access the newly created resource.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦新资源可用，Azure门户会通知您。点击**转到资源**以访问新创建的资源。
- en: So far, we’ve set up AOAI Service. In the next section, we’ll deploy the model.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经设置了AOAI服务。在下一节中，我们将部署模型。
- en: Deploying AOAI models
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署AOAI模型
- en: 'In the previous section, you created an AOAI resource. With this in hand, you
    can proceed to deploy and utilize your models through various means, such as Azure
    AI Foundry, REST APIs, or an SDK. This section will guide you through the process
    of deploying these models from Azure AI Foundry and accessing them via Studio
    and the Python SDK:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，您已经创建了一个AOAI资源。有了这个资源，您可以通过各种方式部署和使用模型，例如Azure AI Foundry、REST API或SDK。本节将指导您通过Azure
    AI Foundry部署这些模型，并通过Studio和Python SDK访问它们：
- en: Log in to your Azure subscription within the Azure portal ([https://portal.azure.com/](https://portal.azure.com/)).
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Azure门户内（[https://portal.azure.com/](https://portal.azure.com/)）登录到您的Azure订阅。
- en: 'In the resource search bar, search for `Azure OpenAI`. Locate the AOAI resource
    that you created in the previous section:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在资源搜索栏中，搜索`Azure OpenAI`。定位之前在上一节创建的AOAI资源：
- en: "![Figure 2.1\uFEFF1: Locating the AOAI resource created previously](img/B21019_02_11.jpg)"
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.11：定位之前创建的AOAI资源](img/B21019_02_11.jpg)'
- en: 'Figure 2.11: Locating the AOAI resource created previously'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11：定位之前创建的AOAI资源
- en: Click on the correct service name (highlighted by a red rectangle in the preceding
    figure).
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击正确的服务名称（在前述图中以红色矩形突出显示）。
- en: 'Navigate to Azure AI Foundry by clicking either **Explore Azure AI Foundry
    portal** or **Go to Azure AI** **Foundry portal**:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击**探索Azure AI Foundry门户**或**转到Azure AI Foundry门户**来导航到Azure AI Foundry：
- en: "![Figure 2.1\uFEFF2: Accessing \uFEFFAzure AI Foundry](img/B21019_02_12.jpg)"
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.12：访问Azure AI Foundry](img/B21019_02_12.jpg)'
- en: 'Figure 2.12: Accessing Azure AI Foundry'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12：访问Azure AI Foundry
- en: 'Within the **Management** section, choose **Deployments**:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**管理**部分，选择**部署**：
- en: "![Figure 2.1\uFEFF3: Creating a new AOAI model deployment](img/B21019_02_13.jpg)"
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.13：创建新的AOAI模型部署](img/B21019_02_13.jpg)'
- en: 'Figure 2.13: Creating a new AOAI model deployment'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.13：创建新的AOAI模型部署
- en: 'Choose **Deploy model** and proceed to configure the following fields:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**部署模型**并继续配置以下字段：
- en: '| **Fi****el****d** | **Description** |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| **Fi****el****d** | **描述** |'
- en: '| --- | --- |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Select** **a model** | Choose a model from the drop-down list. Model availability
    is subject to regional variations. To view a list of available models per region,
    please refer to the model summary table and region-specific availability provided
    at [https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability).
    |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| **选择一个模型** | 从下拉列表中选择一个模型。模型的可用性因地区而异。要查看每个地区可用模型的列表，请参阅[模型总结表格和地区可用性](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability)。'
- en: '| **Deployment name** | Be thoughtful in selecting a deployment name. The deployment
    name is crucial as it will be used in your code to invoke the model using client
    libraries and REST APIs. |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| **部署名称** | 在选择部署名称时要考虑周到。部署名称至关重要，因为它将用于通过客户端库和REST API调用模型。'
- en: '| **Advance Options**(optional) | You have the option to configure advanced
    settings as required for your resource, such as content filter, **tokens per minute**
    (**TPM**), and more. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| **高级选项**（可选） | 您可以根据资源的需要配置高级设置，例如内容过滤、**每分钟令牌**（TPM）等。'
- en: 'For your initial deployment, keep **Advanced options** as-is. Further details
    on content filtering and TPM will be provided in upcoming chapters:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 对于初始部署，将**高级选项**保持不变。关于内容过滤和TPM的更多详细信息将在接下来的章节中提供：
- en: "![Figure 2.1\uFEFF4: Deploying the gpt-35-turbo model](img/B21019_02_14.jpg)"
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.14：部署gpt-35-turbo模型](img/B21019_02_14.jpg)'
- en: 'Figure 2.14: Deploying the gpt-35-turbo model'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.14：部署gpt-35-turbo模型
- en: Click **Create** to proceed.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建**继续。
- en: 'The **Deployments** table will display a new entry corresponding to the model
    you just created with a status of **Succeeded**:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**部署**表将显示与刚刚创建的模型对应的新条目，状态为**成功**：'
- en: "![Figure 2.1\uFEFF5: The gpt-35-turbo model’s deployment status](img/B21019_02_15.jpg)"
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.15：gpt-35-turbo模型的部署状态](img/B21019_02_15.jpg)'
- en: 'Figure 2.15: The gpt-35-turbo model’s deployment status'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.15：gpt-35-turbo模型的部署状态
- en: '(**Optional**): If you have access to GPT-4, you can repeat all the previous
    steps to deploy the GPT-4 or GPT base model as well.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: （**可选**）：如果您可以访问GPT-4，您还可以重复所有先前的步骤来部署GPT-4或GPT基础模型。
- en: Now that you’ve successfully deployed the model using Azure AI Foundry, let’s
    explore how to utilize these models both within Azure AI Foundry and via the Python
    SDK.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已成功使用Azure AI Foundry部署了模型，请探索如何在Azure AI Foundry内和通过Python SDK中利用这些模型。
- en: Utilizing AOAI models
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用AOAI模型
- en: To make effective use of the model, it’s important to understand some basic
    elements associated with chat models. These concepts are essential for utilizing
    the model properly.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 要有效利用模型，了解与聊天模型相关的一些基本要素至关重要。这些概念对于正确利用模型是必不可少的。
- en: The GPT-3.5 Turbo and GPT-4 models are LLMs that have been optimized for conversational
    interfaces. They differ from the older GPT-3 models in how they operate. GPT-3
    models are text-in, text-out, meaning they accept an input (prompt) string and
    return an output (completion); the GPT-3.5 Turbo and GPT-4 models are designed
    for conversation-style interactions. These models expect input to be formatted
    in a chat-like transcript structure and return a completion that represents a
    message generated by the model in the chat. While this format was primarily designed
    for multi-turn conversations, it can also be effectively used in non-chat scenarios.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-3.5 Turbo 和 GPT-4 模型是经过优化的语言模型（LLMs），适用于对话接口。它们与旧版的 GPT-3 模型在操作方式上有所不同。GPT-3
    模型是基于文本输入输出的，即它们接受输入（提示）字符串并返回输出（完成内容）；而 GPT-3.5 Turbo 和 GPT-4 模型是为对话风格的互动而设计的。这些模型期望输入以类似聊天记录的结构格式呈现，并返回一个代表模型在聊天中生成的消息的完成内容。虽然这种格式主要是为多轮对话设计的，但它也可以有效地用于非聊天场景。
- en: 'In AOAI, there are two distinct options for interacting with models such as
    GPT-3.5 Turbo and GPT-4:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AOAI 中，与 GPT-3.5 Turbo 和 GPT-4 等模型互动有两种不同的选择：
- en: '`messages` parameter, which expects an array of message objects organized by
    role. When interacting with these models using the Python API, you typically provide
    a list of dictionaries to represent the conversation format effectively. Each
    dictionary in the list should include the role and content of a message, enabling
    you to have meaningful back-and-forth exchanges with the model.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`messages` 参数期望一个按角色组织的消息对象数组。在使用 Python API 与这些模型互动时，你通常提供一个字典列表，以有效表示对话格式。列表中的每个字典应该包括消息的角色和内容，使你能够与模型进行有意义的来回交换。'
- en: 'The format of a basic Chat Completion API is shown in the following code:'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基本的聊天完成 API 格式如下代码所示：
- en: '[PRE0]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The primary input for interacting with these models is the `messages` parameter,
    which expects an array of message objects. Each message object consists of a `role`
    type (either `system`, `user`, or `assistant`) and `content`. Conversations can
    be as brief as a single message or involve multiple back-and-forth exchanges.
    Let’s take a closer look at these different roles:'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与这些模型互动的主要输入是 `messages` 参数，它期望接收一个消息对象的数组。每个消息对象包含一个 `role` 类型（可以是 `system`、`user`
    或 `assistant`）和 `content`。对话可以简短至单条消息，也可以包括多个来回交换。让我们仔细看看这些不同的角色：
- en: '`system`: The `system` role, also referred to as the system message, is typically
    placed at the beginning of the message array. It serves as the initial instructions
    to the model to guide the model’s responses and interactions. These roles are
    set by the developers and can shape how the model handles various tasks and communicates
    with users. In the `system` role, you have the flexibility to provide various
    types of information:'
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`system`：`system` 角色，也称为系统消息，通常放在消息数组的开头。它作为向模型提供的初始指令，用于引导模型的响应和互动。这些角色由开发者设定，可以影响模型处理各种任务和与用户沟通的方式。在
    `system` 角色中，你可以灵活地提供多种类型的信息：'
- en: '`system` role defines how the model should interact with users. For instance,
    a model might have a role that prioritizes being helpful and informative or one
    that ensures it maintains a neutral and unbiased stance.'
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`system` 角色定义了模型应如何与用户互动。例如，某个模型可能有一个角色，优先考虑提供有用和信息丰富的回答，或者一个确保它保持中立和无偏见立场的角色。'
- en: '**Behavioral constraints**: The role establishes boundaries for what the model
    should and shouldn’t do. This can include avoiding certain topics, adhering to
    privacy guidelines, or refraining from giving medical or legal advice:'
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**行为约束**：该角色设定了模型应该做什么和不应该做什么的边界。这可以包括避免某些话题、遵守隐私指南，或避免提供医学或法律建议：'
- en: '`system` role can influence the tone and style of responses. For example, the
    model might be set to respond formally to professional contexts or adopt a casual
    tone for more relaxed interactions.'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`system` 角色可以影响响应的语气和风格。例如，模型可能被设置为在专业场合以正式的方式回应，或在更轻松的互动中采用随意的语气。'
- en: '`system` role is designed for customer support, the model might be optimized
    for troubleshooting and providing assistance related to specific products or services.'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`system` 角色设计用于客户支持，模型可能针对故障排除和提供与特定产品或服务相关的帮助进行了优化。'
- en: '`system` roles often include parameters to ensure that responses adhere to
    ethical guidelines and safety protocols, helping to prevent the generation of
    harmful or inappropriate content.'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`system`角色通常包括参数，以确保回应遵守伦理指南和安全协议，帮助防止生成有害或不当的内容。'
- en: Overall, the `system` role helps tailor the behavior of the LLM to better meet
    the needs of users and align with the intended use case, whether it’s for specific
    and detailed instructions or just basic guidance. While the `system` role is optional,
    it’s generally recommended to include at least a basic message to ensure you get
    the best results and guide the assistant’s behavior effectively.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，`system`角色有助于定制LLM的行为，以更好地满足用户需求并与预期的使用场景对接，无论是用于具体详细的指令，还是仅仅提供基本的指导。虽然`system`角色是可选的，但通常建议至少包含一个基本的消息，以确保获得最佳的结果，并有效地引导助手的行为。
- en: '`user`: The `user` role refers to the function or context that the user assumes
    during the interaction. It influences how the user frames questions and what they
    seek from the model, such as information, advice, or creative assistance. The
    `user` role affects the model’s responses by providing context for the interaction
    and shaping the style and detail of answers based on the user’s needs and expectations.
    It also impacts how the model adapts its responses to fit the user’s goals, whether
    it’s for educational purposes, technical support, or casual conversation. Overall,
    the `user` role helps tailor the interaction so that it’s more effective and relevant
    to the user’s specific needs.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`user`：`user`角色指的是用户在互动过程中所承担的功能或角色。它影响用户如何构建问题以及他们从模型中寻求什么，比如信息、建议或创意帮助。`user`角色通过为互动提供背景，进而影响模型的回应方式，并根据用户的需求和期望塑造回答的风格和细节。它还影响模型如何调整回答，以适应用户的目标，无论是用于教育目的、技术支持还是日常对话。总体来说，`user`角色有助于定制互动，使其更加有效并符合用户的具体需求。'
- en: '`assistant`: The `assistant` role represents the model that’s chatting with
    the user. It’s used to distinguish the messages that are written by the model
    from those that are written by the user. The `assistant` role is also used to
    indicate who the model is addressing in the chat. For example, if the last message
    in the chat transcript has the `assistant` role, then the model will generate
    a response as if it’s continuing the conversation with the user.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`assistant`：`assistant`角色代表的是与用户对话的模型。它用于区分模型所写的消息与用户所写的消息。`assistant`角色还用于指示模型在对话中是回应谁。例如，如果对话记录中的最后一条消息是`assistant`角色，那么模型将生成一个回应，仿佛它在继续与用户的对话。'
- en: 'Typically, a conversation is structured with a system message at the beginning,
    followed by alternating user and assistant messages. The system message plays
    a crucial role in setting the behavior of the assistant. It can be used to customize
    the assistant’s personality or provide specific instructions on how it should
    respond throughout the conversation. User messages are used to convey requests
    or comments for the assistant to address. Assistant messages not only store prior
    assistant responses but can also be authored by you to provide examples of the
    desired behavior you expect from the assistant during the conversation. This structured
    format allows for effective communication with the model, guiding its responses
    in a controlled manner. Figure 2.16 provides a clearer understanding of this structure:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，一个对话结构是先有系统消息，然后交替出现用户消息和助手消息。系统消息在设定助手的行为上起着至关重要的作用。它可以用于自定义助手的个性，或者提供特定的指令，指导助手如何在整个对话中作出回应。用户消息用于传达用户的请求或评论，供助手处理。助手消息不仅存储了之前的助手回应，还可以由你编写，用来提供期望助手在对话中表现的示例。这种结构化的格式允许与模型进行有效的沟通，控制地引导其回应。图2.16提供了这一结构的更清晰理解：
- en: "![Figure 2.1\uFEFF6: Skeleton of the system, user, and assistant roles/messages](img/B21019_02_16.jpg)"
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: "![图 2.1\uFEFF6：系统、用户和助手角色/消息的框架](img/B21019_02_16.jpg)"
- en: 'Figure 2.16: Skeleton of the system, user, and assistant roles/messages'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.16：系统、用户和助手角色/消息的框架
- en: The first square box represents the system message, where you set the meta prompt
    to guide the LLM’s responses. The second box is the user message, where users
    ask their questions. The last box shows the assistant message, which provides
    responses to the user’s queries.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个方框表示系统消息，在这里你设置元提示来引导LLM的回应。第二个方框是用户消息，用户在这里提出问题。最后一个方框展示了助手消息，即模型对用户问题的回应。
- en: '**Completion API with Chat Markup Language (ChatML)**: ChatML employs the same
    Completion API that you use for other GPT-3 models, such as davinci-002 or babbage-002,
    but it utilizes a distinct token-based prompt format. While ChatML offers lower-level
    access compared to the dedicated Chat Completion API, it comes with certain limitations
    and considerations:'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**带有Chat标记语言（ChatML）的完成API**：ChatML使用的是与你用于其他GPT-3模型（如davinci-002或babbage-002）相同的完成API，但它采用了不同的基于令牌的提示格式。虽然ChatML提供的访问级别低于专用的聊天完成API，但它也有一些限制和注意事项：'
- en: '**Input validation**: You must perform additional input validation when using
    ChatML to ensure the correct format and structure of your messages.'
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入验证**：在使用ChatML时，你必须进行额外的输入验证，以确保消息的格式和结构正确。'
- en: '**Model compatibility**: ChatML is only compatible with the GPT-3.5 Turbo models
    and doesn’t work with the new GPT-4 models.'
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型兼容性**：ChatML仅与GPT-3.5 Turbo模型兼容，无法与新的GPT-4模型一起使用。'
- en: '**Potential format changes**: The underlying format for ChatML may change over
    time'
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在格式变化**：ChatML的基础格式可能会随时间变化。'
- en: Therefore, while ChatML provides flexibility, it’s essential to be aware of
    these constraints and the potential for evolving formats when using it with GPT-3.5
    Turbo models.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 因此，虽然ChatML提供了灵活性，但在与GPT-3.5 Turbo模型一起使用时，了解这些约束条件以及格式可能会发生变化是非常重要的。
- en: Now that you have a fundamental understanding of the Chat Completion API and
    its structure, let’s explore how to use the model from both Azure AI Foundry and
    the Python SDK.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经对Chat Completion API及其结构有了基本了解，接下来我们将探索如何通过Azure AI Foundry和Python SDK来使用该模型。
- en: The Azure AI Foundry experience
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Azure AI Foundry体验
- en: 'To utilize the model in Azure AI Foundry, follow these steps:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Azure AI Foundry中使用该模型，请按照以下步骤操作：
- en: Log in to your Azure subscription within the Azure portal ([https://portal.azure.com/](https://portal.azure.com/)).
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Azure门户中登录你的Azure订阅 ([https://portal.azure.com/](https://portal.azure.com/))。
- en: 'In the resource search bar, search for `Azure OpenAI`. Locate the AOAI resource
    that you created in the previous section:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在资源搜索栏中，搜索`Azure OpenAI`。找到你在上一节中创建的AOAI资源：
- en: "![Figure 2.1\uFEFF7: Locating the AOAI instance created previously](img/B21019_02_17.jpg)"
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图2.17：定位之前创建的AOAI实例](img/B21019_02_17.jpg)'
- en: 'Figure 2.17: Locating the AOAI instance created previously'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.17：定位之前创建的AOAI实例
- en: Click on the service name highlighted within the red rectangle in the preceding
    figure.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击前面图中红色矩形框内的服务名称。
- en: 'Navigate to Azure AI Foundry by clicking either **Explore Azure AI Foundry
    portal** or **Go to Azure AI** **Foundry portal**:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击**探索Azure AI Foundry门户**或**前往Azure AI Foundry门户**来导航至Azure AI Foundry：
- en: "![Figure 2.1\uFEFF8: Launching \uFEFFAzure AI Foundry](img/B21019_02_18.jpg)"
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图2.18：启动Azure AI Foundry](img/B21019_02_18.jpg)'
- en: 'Figure 2.18: Launching Azure AI Foundry'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.18：启动Azure AI Foundry
- en: 'Within the **Playground** section, choose **Chat**:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**沙盒**部分，选择**聊天**：
- en: "![Figure 2.\uFEFF19: Testing a prompt with \uFEFFAzure AI Foundry's Chat playground](img/B21019_02_19.jpg)"
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图2.19：使用Azure AI Foundry的聊天沙盒测试提示](img/B21019_02_19.jpg)'
- en: 'Figure 2.19: Testing a prompt with Azure AI Foundry''s Chat playground'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.19：使用Azure AI Foundry的聊天沙盒测试提示
- en: In **Chat playground**, you have the flexibility to provide a custom **System
    message** tailored to your specific business requirements. We’ll delve into various
    prompting techniques in later chapters. However, for now, feel free to use the
    default system message provided.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在**聊天沙盒**中，你可以灵活地提供自定义的**系统消息**，以满足你的特定业务需求。我们将在后面的章节中深入探讨各种提示技术。但现在，你可以随意使用提供的默认系统消息。
- en: Navigate to the **Deployment** tab within the **Configuration** panel and select
    **Deployment name** (which you created in the previous section) from the **Deployment**
    dropdown. Here, you have the option to choose either the gpt-3.5 or gpt-4 model
    to interact with.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在**配置**面板中，导航到**部署**标签，并从**部署**下拉菜单中选择你在上一节中创建的**部署名称**。在这里，你可以选择与之互动的gpt-3.5或gpt-4模型。
- en: Opt for the default **Session settings**. This setting determines how many ongoing
    conversations you can retain in the model’s context to facilitate responses to
    user prompts. It serves to manage token limit restrictions, which we covered at
    the beginning of this chapter.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择默认的**会话设置**。此设置决定了你在模型上下文中可以保留多少个持续的对话，以便更好地响应用户的提示。它用于管理令牌限制，这是我们在本章开头所提到的。
- en: 'Next, select the **Parameters** tab within the **Configuration** panel. Select
    the default settings for the parameters:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，选择 **配置** 面板中的 **参数** 标签。选择参数的默认设置：
- en: "![Figure 2.\uFEFF20: Setting up parameters](img/B21019_02_20.jpg)"
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.20：设置参数](img/B21019_02_20.jpg)'
- en: 'Figure 2.20: Setting up parameters'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.20：设置参数
- en: 'There are several parameters to consider. Let’s look at each one by one:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 需要考虑几个参数。让我们逐一查看：
- en: '**Max response**: The maximum number of tokens to generate in the chat completion
    reply. The total length of input tokens and generated tokens is limited by the
    model’s context length.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大回复**：在聊天完成回复中生成的最大标记数。输入标记和生成标记的总长度受模型上下文长度的限制。'
- en: '**Temperature**: Which sampling temperature to employ, ranging from 0 to 1,
    is a crucial decision. Opting for higher values, such as 0.9, will introduce greater
    randomness into the output, whereas selecting lower values, such as 0.1, will
    enhance its focus and determinism. It’s important to note that a setting of 0
    will *not* make the model deterministic; instead, it will reduce the overall variability
    in replies.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**温度**：选择使用的采样温度，范围从 0 到 1，这是一个关键决定。选择较高的值（如 0.9）会使输出更加随机，而选择较低的值（如 0.1）则会增强其专注性和确定性。需要注意的是，设置为
    0 并*不会*使模型变得确定性；相反，它会减少回复的整体变异性。'
- en: '`0.1` would imply that only tokens within the top 10% probability mass are
    taken into consideration. It is generally advisable to adjust either the **Top
    P** parameter or the **Temperature** parameter, but not both simultaneously.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0.1` 意味着只考虑位于前 10% 概率质量范围内的标记。通常建议调整 **Top P** 参数或 **Temperature** 参数，但不要同时调整这两个参数。'
- en: '**Stop sequence**: This helps you conclude the model’s response at a specific
    point and ensure it doesn’t include the provided stop sequence text. By doing
    so, you can prevent the model from generating a follow-up user query. You have
    the option to include up to four different stop sequences for this purpose.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**停止序列**：这有助于您在特定点结束模型的回复，并确保它不包含提供的停止序列文本。通过这样做，您可以防止模型生成后续的用户查询。您可以选择最多包含四个不同的停止序列用于此目的。'
- en: '**Frequency penalty**: This number falls within the range of 0 to 2.0\. It
    lowers the likelihood of token repetition in proportion to its prior occurrence
    in the text, thus reducing the chances of reiterating identical text in response.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**频率惩罚**：该数字范围为 0 到 2.0。它会根据标记在文本中先前出现的频率降低标记重复的可能性，从而减少在回复中重复相同文本的几率。'
- en: '**Presence penalty**: This number falls within the range of 0 to 2.0\. It minimizes
    the probability of reusing any token that has already been used in the text, thereby
    enhancing the chances of introducing fresh topics in response.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**出现惩罚**：该数字范围为 0 到 2.0。它最小化了重复使用文本中已经出现的任何标记的概率，从而提高了在回复中引入新话题的可能性。'
- en: Among these parameters, the one you’re most likely to adjust according to your
    specific use cases is the **Temperature** parameter. When you’re working on use
    cases that demand creativity, such as content generation, it’s common to set this
    value closer to 1\. In contrast, for use cases that require factual and precise
    answers, you’d typically opt for a value closer to 0.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些参数中，您最有可能根据特定使用场景调整的是 **Temperature** 参数。当您处理需要创造性的用例（如内容生成）时，通常会将该值设置得接近
    1。相比之下，对于需要事实性和精确答案的用例，通常会选择接近 0 的值。
- en: 'Now, let’s use the GPT-3.5 model for chat interaction, as specified in *Figure
    2**.21*. In this instance, we’ll begin by posing the prompt, “Who emerged as the
    victor in the ICC World Cup series of 2011?” The model’s response is, “India emerged
    as the victor in the ICC World Cup series of 2011.” Subsequently, we pose a follow-up
    question, stating “Where was the final match held?” The model’s response is, “The
    final match of the ICC World Cup series in 2011 took place at the Wankhede Stadium
    in Mumbai, India.” This showcases the conversational-style interaction that can
    be sustained:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用 GPT-3.5 模型进行聊天交互，如*图 2.21*所示。在这个例子中，我们首先提出问题：“2011 年 ICC 世界杯系列赛的冠军是谁？”模型的回答是：“印度在
    2011 年 ICC 世界杯系列赛中获胜。”随后，我们提出跟进问题：“决赛在哪里举行？”模型的回答是：“2011 年 ICC 世界杯系列赛的决赛在印度孟买的万科德体育场举行。”这展示了可以持续进行的对话式交互：
- en: "![Figure 2.\uFEFF21: Describing agent and user chat interactions](img/B21019_02_21.jpg)"
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.21：描述代理和用户聊天交互](img/B21019_02_21.jpg)'
- en: 'Figure 2.21: Describing agent and user chat interactions'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.21：描述代理和用户聊天互动
- en: With that, you’ve effectively utilized AOAI models to engage in a ChatGPT-style
    conversation. In the next section, we’ll discuss how to utilize the same GPT-3.5
    Turbo or GPT-4 model using the Python SDK.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，您就已经有效地利用了AOAI模型进行类似ChatGPT的对话。在下一节中，我们将讨论如何使用Python SDK利用相同的GPT-3.5 Turbo或GPT-4模型。
- en: Programmatic experience
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编程体验
- en: 'In this section, we’ll guide you through the process of making your first call
    to AOAI using the Python SDK:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将引导您通过使用Python SDK进行首次调用AOAI的过程：
- en: Install Python version 3.7.1 or a more recent version on your machine. Alternatively,
    you can utilize an Azure Machine Learning notebook to obtain the Python environment.
    In this example, we’ve used Anaconda with Visual Studio Code as an IDE.
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的计算机上安装Python版本3.7.1或更高版本。或者，您可以使用Azure Machine Learning笔记本获取Python环境。在此示例中，我们使用了Anaconda和Visual
    Studio Code作为IDE。
- en: Install the OpenAI Python client library by running `pip` `install openai`.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行`pip` `install openai`安装OpenAI Python客户端库。
- en: 'To make a request to AOAI Service, you’ll require the following inputs:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要向AOAI服务发起请求，您需要以下输入：
- en: '| `ENDPOINT` | You can locate this value in the `API-KEY` | You can find this
    value in the `DEPLOYMENT-NAME` | This value will correspond to the custom name
    you selected for your deployment during the model deployment process in the *Deploying
    AOAI* *models* section. |'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| `ENDPOINT` | 您可以在`API-KEY`中找到此值 | 您可以在`DEPLOYMENT-NAME`中找到此值 | 此值对应您在*部署AOAI*
    *模型*部分中为部署选择的自定义名称。 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: 'To get the first two values, navigate to your resource within the Azure portal.
    You can find the **Keys and Endpoint** under the **Resource Management** section.
    Make sure you copy both your endpoint and access key; you’ll require both to authenticate
    your API calls. You have the option to use either **KEY 1** or **KEY 2**. The
    presence of two keys enables secure key rotation and regeneration without service
    interruptions being made:'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要获取前两个值，请导航到Azure门户中的资源。您可以在**资源管理**部分找到**密钥和终结点**。确保复制您的终结点和访问密钥；您需要这两个信息来验证API调用。您可以选择使用**KEY
    1**或**KEY 2**。这两个密钥的存在使得密钥轮换和再生在不中断服务的情况下进行：
- en: "![Figure 2.\uFEFF22: Retrieving AOAI keys and endpoint information](img/B21019_02_22.jpg)"
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![图2.22：检索AOAI密钥和终结点信息](img/B21019_02_22.jpg)'
- en: 'Figure 2.22: Retrieving AOAI keys and endpoint information'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.22：检索AOAI密钥和终结点信息
- en: 'In your preferred IDE, create a Python file called `quickstart.py` and execute
    the following code:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您偏好的IDE中，创建一个名为`quickstart.py`的Python文件，并执行以下代码：
- en: 'Import the necessary Python packages and set up the AOAI keys and endpoint
    information. Make sure you change the deployment name’s value to the custom name
    you provided while creating the deployment:'
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的Python包，并设置AOAI密钥和终结点信息。确保将部署名称的值更改为您在创建部署时提供的自定义名称：
- en: '[PRE1]'
  id: totrans-206
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Call the AOAI Chat Completion API and provide the AOAI deployment name, along
    with system and user message details:'
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调用AOAI聊天完成API，并提供AOAI部署名称，以及系统和用户消息详细信息：
- en: '[PRE2]'
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Print the final response from the model:'
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印模型的最终响应：
- en: '[PRE3]'
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The output should be similar to the following:'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出应该类似于以下内容：
- en: '[PRE4]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Important note
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In a production environment, it’s recommended to use a secure method for storing
    and accessing your credentials, such as Azure Key Vault. This ensures the highest
    level of security for your sensitive information.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中，建议使用安全的方法存储和访问凭据，例如Azure Key Vault。这确保了敏感信息的最高安全级别。
- en: With that, you understand how to utilize the AOAI GPT-3.5 and GPT-4 models.
    Something we haven’t discussed yet is how to use the embedding model; we’ll cover
    that in the next chapter. In the next section, we’ll talk about AOAI pricing.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，您已了解如何使用AOAI GPT-3.5和GPT-4模型。我们尚未讨论的是如何使用嵌入模型；我们将在下一章中进行介绍。在下一节中，我们将讨论AOAI定价。
- en: Pricing
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定价
- en: In this section, we’ll discuss the various AOAI pricing options and help you
    select the most suitable plan for your needs.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论各种AOAI定价选项，并帮助您选择最适合您需求的计划。
- en: 'AOAI has two distinct pricing plans:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: AOAI有两种不同的定价计划：
- en: '**Pay-As-You-Go**: Under this pricing model, you’re billed based on the consumption
    of 1,000 tokens for both prompts and completions. Note that each model has its
    distinct pricing for both prompts and completions. This plan is better suited
    for development and testing environments, as well as specific production workloads
    where the volume of API calls and processed tokens isn’t substantial. For the
    complete pricing table, please refer to [https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/).
    It’s important to note that these costs may change in the future, so it’s advisable
    to check the preceding link provided for the most up-to-date pricing information:'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**按需计费**：在此定价模型下，您将根据每1,000个标记的提示和完成的消耗量进行计费。请注意，每个模型在提示和完成方面有其独特的定价。此计划更适用于开发和测试环境，以及那些API调用和处理的标记量不大的特定生产工作负载。有关完整的定价表，请参阅[https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/](https://azure.microsoft.com/en-us/pricing/details/cognitive-services/openai-service/)。需要注意的是，这些费用可能会在未来发生变化，因此建议您检查提供的前述链接，以获取最准确的定价信息：'
- en: '| **Models** | **Context Window** | **Prompt****(per** **1,000 Tokens)** |
    **Completion****(er** **1,000 Tokens)** |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **上下文窗口** | **提示**（每**1,000个标记**）| **完成**（每**1,000个标记**）|'
- en: '| gpt-35-turbo | 4K | $0.0015 | $0.002 |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| gpt-35-turbo | 4K | $0.0015 | $0.002 |'
- en: '| gpt-35-turbo | 16K | $0.003 | $0.004 |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| gpt-35-turbo | 16K | $0.003 | $0.004 |'
- en: '| gpt-4 | 8K | $0.03 | $0.06 |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4 | 8K | $0.03 | $0.06 |'
- en: '| gpt-4 | 32K | $0.06 | $0.12 |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| gpt-4 | 32K | $0.06 | $0.12 |'
- en: '| text-embedding-ada-002 | 8K | $0.0001 |  |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| text-embedding-ada-002 | 8K | $0.0001 |  |'
- en: '**PAUG**: In this pricing plan, you’re initially provided with a default level
    of throughput, also known as a quota. This implies that the models will process
    a set number of tokens per minute based on your chosen region. You have the option
    to request an additional quota up to a certain threshold. If your needs exceed
    the predefined limit, you should consider the **Provisioned Throughput Unit**
    (**PTU**) pricing plan, which we’ll discuss shortly. We’ll delve into quota management
    in later chapters. For the most up-to-date quotas and limits, please refer to
    the following link:'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PAUG**：在此定价计划下，您将最初获得默认的吞吐量级别，也称为配额。这意味着模型将根据您选择的地区每分钟处理一定数量的标记。您可以选择请求额外的配额，直到达到一定的上限。如果您的需求超过预定的限制，您应考虑使用**预配置吞吐量单元**（**PTU**）定价计划，我们将稍后讨论。在后续章节中，我们将详细介绍配额管理。有关最新的配额和限制，请参考以下链接：'
- en: 'The following table will help you determine the amount of throughput each model
    can deliver:'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下表格将帮助您确定每个模型能够提供的吞吐量：
- en: '| **Models** | **Context Window** | **Default** **Throughput (Tokens/Minute)**
    |'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| **模型** | **上下文窗口** | **默认** **吞吐量（标记/分钟）** |'
- en: '| --- | --- | --- |'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| gpt-35-turbo | 4K | 240K |'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| gpt-35-turbo | 4K | 240K |'
- en: '| gpt-35-turbo | 16K | 240K |'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| gpt-35-turbo | 16K | 240K |'
- en: '| gpt-4 | 8K | 20K |'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| gpt-4 | 8K | 20K |'
- en: '| gpt-4 | 32K | 40K |'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| gpt-4 | 32K | 40K |'
- en: '| text-embedding-ada-002 | 8K | 240K |'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| text-embedding-ada-002 | 8K | 240K |'
- en: 'Please note that this information may change over time, so always consult the
    latest documentation for the most up-to-date information: [https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits](https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits).'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，这些信息可能会随时间变化，因此请始终查阅最新文档，以获取最准确的信息：[https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits](https://learn.microsoft.com/en-us/azure/ai-services/openai/quotas-limits)。
- en: '**Provisioned Throughput Unit - Managed (PTU-M)**: PTU-M is a new feature in
    AOAI Service that allows you to reserve processing capacity specifically tailored
    for high-volume or latency-critical workloads. PTU processing capacity delivers
    consistent levels of latency and throughput, which is ideal for workloads with
    stable characteristics, such as uniform prompt size, completion size, and concurrent
    API request numbers. PTUs can be procured hourly (no commitment) or monthly or
    yearly (commitment). In this pricing plan, you pay a fixed, flat rate, and you
    have the freedom to send an unlimited number of tokens throughout the commitment
    period. Additionally, this plan offers superior throughput compared to the standard
    pay-as-you-go option. PTU throughput can fluctuate based on factors such as input
    tokens, output tokens, and the number of API calls per minute. To accurately assess
    throughput for a specific PTU unit, you can utilize the benchmark script provided
    by Microsoft. You can access the benchmarking tool here: [https://github.com/Azure/azure-openai-benchmark](https://github.com/Azure/azure-openai-benchmark).'
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预配吞吐量单元 - 托管 (PTU-M)**：PTU-M 是 AOAI 服务中的一项新功能，允许您为高容量或对延迟敏感的工作负载预留专用的处理能力。PTU
    处理能力提供一致的延迟和吞吐量水平，非常适合具有稳定特征的工作负载，例如均匀的提示大小、完成大小和并发 API 请求数。PTU 可按小时（无承诺）、按月或按年（有承诺）购买。在此定价计划中，您支付固定的统一费率，在承诺期内可以自由发送无限数量的标记。此外，与标准按需支付选项相比，此计划提供更高的吞吐量。PTU
    吞吐量可能会根据输入标记、输出标记和每分钟 API 调用次数等因素波动。为了准确评估特定 PTU 单元的吞吐量，您可以使用微软提供的基准脚本。您可以在此处访问基准工具：[https://github.com/Azure/azure-openai-benchmark](https://github.com/Azure/azure-openai-benchmark)。'
- en: Let’s break down the pricing structure for PTU. For hourly PTU usage without
    any commitment, the cost is $2 per PTU per hour. For a monthly commitment, the
    rate is $260 per PTU per month, while for a yearly commitment, it’s $221 per PTU
    per year.
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们来解析一下 PTU 的定价结构。对于没有任何承诺的按小时使用 PTU，每小时每个 PTU 的费用为 2 美元。对于按月承诺的费用，每个 PTU 每月
    260 美元，而按年承诺则是每个 PTU 每年 221 美元。
- en: Each model has a minimum PTU requirement and minimum scaling increment. For
    example, GPT-4o requires a minimum of 50 PTUs to operate and 50 units for incremental
    scaling. Therefore, if you opt for a monthly commitment, GPT-4o will cost $260
    multiplied by 50 PTUs, totaling $13,000 per month. If you need to scale up your
    usage of GPT-4o, you will still need to add 50 PTUs as an increment.
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每个模型都有最低的 PTU 要求和最小的扩展增量。例如，GPT-4o 需要至少 50 个 PTU 才能运行，并且需要 50 个单位进行增量扩展。因此，如果选择按月承诺，GPT-4o
    每月的费用为 260 美元乘以 50 个 PTU，总计 13,000 美元。如果您需要扩展 GPT-4o 的使用量，仍然需要按增量添加 50 个 PTU。
- en: For detailed pricing information on various models, please refer to the table
    provided table. Now, let’s delve into how the pricing structure operates. Each
    PTU costs $312 per month. Different model types require varying amounts of PTUs
    to operate optimally. For instance, the GPT-35 Turbo with a 4K context window
    necessitates a minimum of 300 PTUs, providing a throughput ranging from 900K to
    2.7 million TPM. If you require additional throughput, you can incrementally add
    100 PTUs, resulting in an extra throughput of 300K to 900K TPM.
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有关各种模型的详细定价信息，请参阅所提供的表格。现在，让我们深入了解定价结构的运作方式。每个 PTU 每月的费用为 312 美元。不同的模型类型需要不同数量的
    PTU 才能最佳运行。例如，具有 4K 上下文窗口的 GPT-35 Turbo 至少需要 300 个 PTU，提供 90 万到 270 万 TPM 的吞吐量。如果需要额外的吞吐量，可以每次增加
    100 个 PTU，带来额外的 30 万到 90 万 TPM 的吞吐量。
- en: 'On the other hand, the GPT-35 Turbo with a 16K context window requires a minimum
    of 600 PTUs, offering a throughput between 1.8 million and 5.4 million TPM. To
    augment the throughput further, you can add 200 PTUs as an increment, resulting
    in an additional throughput of 600K to 1.8 million tokens per minute. For comprehensive
    details on the minimum PTU requirements, associated costs, and throughput capabilities
    for each model type, please refer to the following table:'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另一方面，GPT-35 Turbo 具有 16K 上下文窗口，最小需要 600 个 PTU，提供 180 万到 540 万 TPM 的吞吐量。为了进一步提升吞吐量，可以每次增加
    200 个 PTU，带来每分钟 60 万到 180 万个标记的额外吞吐量。有关每种模型类型的最低 PTU 要求、相关费用和吞吐能力的详细信息，请参见下表：
- en: "![Figure 2.\uFEFF23: PTU pricing information](img/B21019_02_23.jpg)"
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.23：PTU 定价信息](img/B21019_02_23.jpg)'
- en: 'Figure 2.23: PTU pricing information'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.23：PTU 定价信息
- en: Although AOAI offers a diverse set of LLMs, customers often choose different
    models based on their specific use cases to manage cost and accuracy. For complex
    tasks such as clinical protocol writing, drug discovery, and clinical trial matching,
    customers typically use GPT-4o due to its superior accuracy. For less complex
    tasks, such as customer support chatbots or entity extraction, customers might
    opt for GPT-3.5 or GPT-4o mini, which provide better price performance and are
    more economically feasible.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管AOAI提供了多种LLM，客户通常根据具体的使用场景选择不同的模型，以便平衡成本和精度。对于复杂任务，如临床协议编写、药物发现和临床试验匹配，客户通常选择GPT-4o，因为它具有更高的准确性。对于不那么复杂的任务，如客户支持聊天机器人或实体提取，客户可能会选择GPT-3.5或GPT-4o
    mini，这些模型提供了更好的性价比，更具经济可行性。
- en: Important note
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: It’s important to note that you cannot directly purchase PTUs from the Azure
    portal as you would with other services. To acquire PTUs for your subscription,
    you must reach out to a Microsoft account representative, who will assist you
    in gaining approval for PTUs within your subscription. Once approved, you can
    proceed with the purchase of PTUs. The price for PTUs is subject to change in
    the future. Therefore, it’s advisable to always consult with a Microsoft account
    representative for the most up-to-date pricing information.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，您不能像其他服务一样直接通过Azure门户购买PTU。要为您的订阅购买PTU，您必须联系微软账户代表，他们将帮助您获得在订阅中使用PTU的批准。批准后，您可以继续购买PTU。PTU的价格未来可能会有所变动。因此，建议您始终与微软账户代表咨询，以获取最新的定价信息。
- en: Summary
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter provided an in-depth exploration of AOAI Service. We began by defining
    what AOAI Service is and went on to discuss the various model types it offers.
    We also guided you through the steps to access this service, from creating an
    AOAI resource to deploying the models and utilizing them for practical applications.
    Lastly, we shed light on the pricing structure, ensuring you have a clear understanding
    of how to leverage this powerful AI service within the Azure ecosystem. With this
    knowledge, you’re well-equipped to harness the capabilities of AOAI Service for
    your AI and machine learning projects.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 本章深入探讨了AOAI服务。我们首先定义了AOAI服务是什么，接着讨论了它提供的各种模型类型。我们还指导您完成了访问此服务的步骤，从创建AOAI资源到部署模型并将其用于实际应用。最后，我们阐明了定价结构，确保您清楚了解如何在Azure生态系统中利用这一强大的AI服务。有了这些知识，您已具备了在AI和机器学习项目中利用AOAI服务的能力。
- en: Looking ahead to the next chapter, our attention will shift toward delving into
    advanced topics within AOAI. We’ll explore embedding models and discover how to
    store these embeddings within a vector database, empowered by the Azure Cognitive
    Search service. Additionally, we’ll delve into the concept of model grounding
    and the intricacies of fine-tuning models to meet specific requirements.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 展望下一章，我们的注意力将转向深入探讨AOAI中的高级主题。我们将探索嵌入模型，并学习如何将这些嵌入存储在向量数据库中，借助Azure Cognitive
    Search服务。此外，我们还将深入了解模型基础和微调模型的复杂性，以满足特定需求。
- en: Furthermore, we’ll engage in discussions about some of the latest features,
    such as function calling, assistant API, fine-tuning, and the Batch API. These
    advanced topics will provide a deeper understanding of AOAI’s capabilities and
    empower you to leverage its full potential. We’ll conclude by highlighting the
    significance of LLM application development frameworks such as LangChain and Semantic
    Kernel. These frameworks play a pivotal role in simplifying the creation of applications.
    By leveraging the capabilities of these frameworks, developers can streamline
    the development process, harnessing the power of LLMs to build innovative and
    intelligent applications with ease. As we move forward in the field of AI and
    language processing, these frameworks serve as essential tools in harnessing the
    full potential of LLMs for diverse applications.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还将讨论一些最新的功能，如函数调用、助手API、微调和批量API。这些高级主题将提供对AOAI功能的更深理解，使您能够充分利用其潜力。最后，我们将强调LLM应用开发框架的重要性，如LangChain和Semantic
    Kernel。这些框架在简化应用程序创建方面起着至关重要的作用。通过利用这些框架的能力，开发人员可以简化开发过程，充分利用LLM的力量，轻松构建创新和智能的应用程序。随着我们在AI和语言处理领域的前进，这些框架作为重要工具，帮助我们充分发挥LLM在各种应用中的潜力。
- en: Further reading
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解本章中涉及的更多内容，请查看以下资源：
- en: '*Introduction to AOAI* *Service* ([https://learn.microsoft.com/en-us/training/modules/explore-azure-openai/](https://learn.microsoft.com/en-us/training/modules/explore-azure-openai/))'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AOAI 服务简介* *([https://learn.microsoft.com/en-us/training/modules/explore-azure-openai/](https://learn.microsoft.com/en-us/training/modules/explore-azure-openai/))*'
- en: '*AOAI: Generative AI Models and How to Use* *Them* ([https://www.linkedin.com/learning/azure-openai-generative-ai-models-and-how-to-use-them](https://www.linkedin.com/learning/azure-openai-generative-ai-models-and-how-to-use-them))'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*AOAI：生成式 AI 模型及其使用方法* *（它们）* ([https://www.linkedin.com/learning/azure-openai-generative-ai-models-and-how-to-use-them](https://www.linkedin.com/learning/azure-openai-generative-ai-models-and-how-to-use-them))'
