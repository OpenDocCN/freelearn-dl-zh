- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: How LLMs Make Decisions
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs如何做出决策
- en: How LLMs make decisions is extremely complex, but it’s something you should
    be aware of. In this chapter, we will provide you with a comprehensive examination
    of the decision-making processes in LLMs, starting with an analysis of how these
    models use probability and statistics to process information and predict outcomes.
    We will then explore the complex methodology LLMs employ to interpret inputs and
    construct responses. Furthermore, we will address the challenges and limitations
    that are inherent in LLMs, such as bias and reliability issues. We will also touch
    upon the current state and potential difficulties in ensuring the accuracy and
    fairness of these models. In the concluding part of this chapter, we will discuss
    the progressive methods and prospective advancements in the field of LLMs, signifying
    a dynamic area of technological development.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs做出决策的过程极其复杂，但这是你应该了解的。在本章中，我们将为您提供对LLMs决策过程的全面考察，从分析这些模型如何使用概率和统计学来处理信息和预测结果开始。然后，我们将探讨LLMs在解释输入和构建响应时采用的复杂方法。此外，我们将讨论LLMs固有的挑战和限制，例如偏差和可靠性问题。我们还将简要提及确保这些模型准确性和公平性的当前状态和潜在困难。在本章的最后一部分，我们将讨论LLMs领域的渐进方法和发展前景，这标志着技术发展的一个动态领域。
- en: 'In this chapter, we’ll cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Decision-making in LLMs – probability and statistical analysis
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs中的决策 - 概率和统计分析
- en: From input to output – understanding LLM response generation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从输入到输出 - 理解LLMs的响应生成
- en: Challenges and limitations in LLM decision-making
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs决策中的挑战和限制
- en: Evolving decision-making – advanced techniques and future directions
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策制定演变 - 高级技术和未来方向
- en: By the end of this chapter, you will understand how the decision-making process
    is implemented in LLMs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将了解LLMs中决策过程的实现方式。
- en: Decision-making in LLMs – probability and statistical analysis
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs中的决策 - 概率和统计分析
- en: Decision-making in LLMs involves complex algorithms that process and generate
    language based on a variety of factors. These include the input data they were
    trained on, the specific instructions or prompts they receive, and the statistical
    models that underlie their programming.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs中的决策涉及复杂的算法，这些算法基于各种因素处理和生成语言。这些因素包括它们训练时所使用的输入数据、它们收到的具体指令或提示，以及它们编程背后的统计模型。
- en: In this section, we’ll provide an overview of how LLMs use probability and statistical
    analysis in decision-making.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将概述LLMs如何在决策中使用概率和统计分析。
- en: Probabilistic modeling and statistical analysis
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概率建模与统计分析
- en: 'Probabilistic modeling is a cornerstone of how LLMs such as GPT-4 function.
    This approach allows the model to process natural language so that it reflects
    the complexities and variances inherent in human language use. Let’s take a deeper
    look at several aspects of probabilistic modeling in LLMs:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 概率建模是LLMs如GPT-4功能的基础。这种方法允许模型处理自然语言，使其反映人类语言使用中固有的复杂性和变化。让我们更深入地了解LLMs中概率建模的几个方面：
- en: '**Fundamentals of probabilistic modeling** : Probabilistic modeling is based
    on the concept of probability theory, which is used to model uncertainty. In the
    context of LLMs, this means that the model doesn’t just learn fixed rules of language;
    instead, it learns the likelihood of certain words or phrases following others.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概率建模基础**：概率建模基于概率论的概念，该概念用于模拟不确定性。在LLMs的背景下，这意味着模型不仅学习固定的语言规则；相反，它学习某些单词或短语跟随其他单词或短语的可能性。'
- en: '**Sequence modeling with neural networks** : LLMs are a type of sequence model.
    They are designed to handle sequential data, such as text, where the order of
    the elements is crucial. For each potential next word in a sequence, the model
    generates a probability distribution while considering the words that have come
    before. This distribution reflects the model’s “belief” about which words are
    most likely to come next. When generating text, the model samples from this distribution.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用神经网络的序列建模**：LLMs是一种序列模型。它们被设计来处理序列数据，如文本，其中元素的顺序至关重要。对于序列中的每个可能的下一个单词，模型在考虑之前出现的单词的同时生成一个概率分布。这个分布反映了模型对其认为最有可能出现的单词的“信念”。在生成文本时，模型从这个分布中进行采样。'
- en: '**The Transformer architecture** : The Transformer, a type of neural network
    architecture, as discussed in the previous chapter, is particularly well-suited
    to this kind of probabilistic modeling because of its attention mechanisms. These
    mechanisms allow the model to weigh different parts of the input text when predicting
    the next word. It can “pay attention” to the entire context or focus on certain
    relevant parts, which is crucial for understanding the nuances of language.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Transformer 架构**：在前一章中讨论的 Transformer，作为一种神经网络架构，由于其注意力机制，特别适合这种概率建模。这些机制允许模型在预测下一个词时权衡输入文本的不同部分。它可以“关注”整个上下文或专注于某些相关部分，这对于理解语言的细微差别至关重要。'
- en: '**Training on data and patterns** : During training, LLMs are fed huge amounts
    of text and learn to predict the probability of a word given the previous words
    in a sentence. This process, which was covered in the previous chapter, is not
    just about the frequency of word sequences but also about their context and usage
    patterns.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据与模式训练**：在训练过程中，大型语言模型（LLMs）被输入大量文本，并学会根据句子中前一个词预测下一个词的概率。这一过程在前一章中已有介绍，它不仅涉及词序列的频率，还包括它们的上下文和用法模式。'
- en: '**Softmax function** : A key component of the probabilistic model in LLMs is
    the softmax function. It takes the raw outputs of the model (which can be thought
    of as scores) and turns them into a probability distribution over the potential
    next words.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Softmax 函数**：LLM 中概率模型的一个关键组件是 softmax 函数。它将模型的原始输出（可以将其视为分数）转换为潜在下一个词的概率分布。'
- en: '**Loss function and optimization** : During training, a loss function measures
    how well the model’s predictions match the actual outcomes. The model is optimized
    using algorithms such as stochastic gradient descent to minimize this loss, which
    involves adjusting the model’s parameters to improve its probability estimates.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**损失函数与优化**：在训练过程中，损失函数衡量模型的预测与实际结果之间的匹配程度。模型使用诸如随机梯度下降等算法进行优化，以最小化这种损失，这涉及到调整模型的参数以改进其概率估计。'
- en: '**Handling ambiguity** : One of the challenges in probabilistic modeling for
    language is handling ambiguity. Words can have multiple meanings, and phrases
    can be interpreted in different ways, depending on the context. LLMs use the statistical
    patterns learned from data to handle this ambiguity, choosing the most probable
    meaning based on the context.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理歧义**：在语言的概率建模中，一个挑战是处理歧义。单词可能有多种含义，短语可以根据上下文以不同的方式解释。LLMs 使用从数据中学习到的统计模式来处理这种歧义，根据上下文选择最可能的含义。'
- en: '**Model fine-tuning** : After its initial training, an LLM can be fine-tuned
    on more specific datasets. This allows the model to adjust its probabilistic predictions
    to better fit particular domains or styles of language.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型微调**：在初始训练之后，LLM 可以在更具体的数据集上进行微调。这允许模型调整其概率预测，以更好地适应特定的领域或语言风格。'
- en: '**Limitations and challenges** : While probabilistic modeling is powerful,
    it has its limitations. LLMs can sometimes generate text that is statistically
    probable but doesn’t make sense or is factually incorrect. This is an area of
    active research as developers seek to improve the model’s understanding and generation
    capabilities.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局限性与挑战**：虽然概率建模功能强大，但它有其局限性。LLMs 有时可能会生成在统计上可能是的但无意义或事实错误的文本。这是当前研究的一个活跃领域，开发者正在寻求提高模型的理解和生成能力。'
- en: Probabilistic modeling in LLMs represents a significant advancement in the field
    of NLP, enabling these models to generate text that is often indistinguishable
    from that written by humans. The continuous refinement of these probabilistic
    methods is a key area of development that aims to achieve ever-more sophisticated
    levels of language understanding and generation.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LLM 中的概率建模代表了自然语言处理（NLP）领域的一项重大进步，使得这些模型能够生成通常难以与人类写作区分的文本。这些概率方法的持续改进是关键的发展领域，旨在实现更高水平的语言理解和生成。
- en: Training on large datasets
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在大型数据集上进行训练
- en: As discussed previously, during training, LLMs are fed huge amounts of text
    and learn to predict the probability of a word given the previous words in a sentence.
    This process, which was covered in the previous chapter, is not just about the
    frequency of word sequences but also about their context and usage patterns.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在训练过程中，大型语言模型（LLMs）被输入大量文本，并学会根据句子中的前文预测单词的概率。这一过程在前一章中已有介绍，它不仅涉及单词序列的频率，还包括它们的上下文和用法模式。
- en: Contextual understanding
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上下文理解
- en: 'Contextual understanding in LLMs such as GPT-4 is one of the most critical
    aspects of their operation. It allows them to interpret and respond to inputs
    in a way that is relevant and coherent. Let’s take a closer look at how LLMs achieve
    this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPT-4等LLMs中的上下文理解是它们操作中最关键的部分之一。它允许它们以相关和连贯的方式解释和响应输入。让我们更深入地看看LLMs是如何实现这一点的：
- en: '**Understanding context through patterns** : As LLMs are trained on large amounts
    of text data, they learn patterns of language usage. This training enables them
    to pick up on the context in which words and phrases are typically used. For example,
    the word “apple” might be understood as a fruit in one context or as a technology
    company in another, depending on the surrounding words.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过模式理解上下文**：由于LLMs是在大量文本数据上训练的，它们学会了语言使用的模式。这种训练使它们能够识别单词和短语通常使用的上下文。例如，“apple”一词可能在一个上下文中被理解为水果，在另一个上下文中则被理解为科技公司，这取决于周围的词语。'
- en: '**Attention mechanisms** : The Transformer architecture employs attention mechanisms
    to enhance contextual understanding. These mechanisms allow the model to focus
    on different parts of the input sequence, weighing them according to their relevance
    to the current task. This is how the model can consider the entire context of
    a sentence or paragraph when deciding which words to generate next.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**注意力机制**：Transformer架构采用注意力机制来增强上下文理解。这些机制允许模型关注输入序列的不同部分，根据它们对当前任务的关联性进行加权。这就是模型在决定生成下一个单词时如何考虑整个句子或段落的上下文。'
- en: '**Embeddings and positional encodings** : As discussed previously, LLMs use
    embeddings to convert words and tokens into numerical vectors that capture their
    meaning. These embeddings are context-dependent and can change based on the position
    of a word in a sentence, thanks to positional encodings. This is how the word
    “bank” can have different meanings when used in different contexts – for example,
    “river bank” and “ money bank.”'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入和位置编码**：如前所述，LLMs使用嵌入将单词和标记转换为捕获其意义的数值向量。这些嵌入是上下文相关的，并且可以根据单词在句子中的位置通过位置编码而改变。这就是为什么“bank”一词在不同的上下文中可以有不同的含义——例如，“river
    bank”和“money bank”。'
- en: '**Layered understanding** : LLMs typically have multiple layers, with each
    layer capturing different aspects of language. Lower layers might focus on the
    syntax and grammar, while upper layers capture higher-level semantic meaning.
    This allows the model to process input at various levels of complexity, from basic
    word order to nuanced implications and inferences.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分层理解**：LLMs通常具有多个层级，每个层级捕捉语言的不同方面。底层可能关注句法和语法，而高层则捕捉更高级别的语义意义。这使得模型能够以不同复杂度处理输入，从基本的词序到细微的含义和推理。'
- en: '**Handling ambiguity and polysemy** : Ambiguity is a natural part of language,
    and words can have multiple meanings (polysemy). LLMs use the context provided
    by the user to disambiguate words and phrases. For instance, if a user asks about
    “taking a break,” the model understands this in the context of resting rather
    than “breaking something” due to the surrounding words that imply rest.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理歧义和多义性**：歧义是语言的自然部分，单词可以有多个含义（多义性）。LLMs使用用户提供的上下文来消除单词和短语的歧义。例如，如果用户询问“taking
    a break”，模型会根据周围暗示休息的词语，将这个短语理解为休息，而不是“打破某物”。'
- en: '**Calculating probabilities** : Statistical analysis in an LLM involves calculating
    probabilities for different potential outputs. The context is crucial for this
    process; for instance, if a user is discussing a topic such as climate change,
    the model uses the context to give higher probabilities to words and phrases related
    to that topic.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算概率**：在LLMs中的统计分析涉及计算不同潜在输出的概率。上下文对于这个过程至关重要；例如，如果用户正在讨论气候变化等话题，模型会利用上下文为与该话题相关的单词和短语赋予更高的概率。'
- en: '**Continuous learning** : While LLMs are not capable of learning in real-time
    post-deployment in the same way humans do, some systems are designed to update
    their models periodically with new data, allowing them to adapt to changes in
    language use over time.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续学习**：虽然LLMs在部署后不能像人类那样实时学习，但一些系统被设计成定期用新数据更新模型，使它们能够适应语言使用的变化。'
- en: '**Limitations and challenges** : Despite these sophisticated mechanisms, LLMs
    still face challenges in contextual understanding. They can misunderstand nuances,
    fail to grasp sarcasm or idiomatic expressions, and generate nonsensical or off-topic
    responses if the context is too complex or too subtle.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**局限性及挑战**：尽管这些机制相当复杂，但LLMs在上下文理解方面仍然面临挑战。它们可能会误解细微差别，无法理解讽刺或成语表达，如果上下文过于复杂或微妙，可能会生成无意义或不相关的回应。'
- en: '**Ethical considerations** : As mentioned previously, contextual understanding
    also brings ethical considerations. LLMs might inadvertently generate biased or
    sensitive content if the context cues are misinterpreted. It is an ongoing challenge
    to ensure that the models are as fair and unbiased as possible.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伦理考量**：如前所述，上下文理解也带来了伦理考量。如果上下文线索被误解，LLMs可能会无意中生成具有偏见或敏感的内容。确保模型尽可能公平和无偏见是一个持续性的挑战。'
- en: '**Applications** : In practical applications, contextual understanding is crucial.
    It enables LLMs to perform tasks such as translation, summarization, and question-answering
    with a high degree of accuracy and relevance.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用**：在实际应用中，上下文理解至关重要。它使得LLMs能够以高精度和相关性执行翻译、摘要和问答等任务。'
- en: The decision-making process in LLMs regarding contextual understanding is an
    active area of research and development, with each new model iteration bringing
    improvements that enable more sophisticated interactions with human users.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs在上下文理解方面的决策过程是研究和发展的活跃领域，每个新模型的迭代都带来了改进，使得与人类用户的交互更加复杂。
- en: Machine learning algorithms
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习算法
- en: '**Machine learning** ( **ML** ) algorithms form the backbone of LLMs, leveraging
    a variety of statistical techniques to process and generate language. Let’s take
    a closer look at the most pertinent algorithms and methods that are used:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）算法是LLMs的骨架，利用各种统计技术来处理和生成语言。让我们更详细地看看最相关的算法和方法，这些方法被使用：'
- en: '**Supervised learning** : LLMs often use supervised learning, where the model
    is trained on a labeled dataset. For language models, the “labels” are typically
    the next few words in a sequence. The model learns to predict these labels (words)
    based on the input it receives.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**：LLMs通常使用监督学习，其中模型在标记数据集上进行训练。对于语言模型，"标签"通常是序列中的下一几个单词。模型通过接收到的输入学习预测这些标签（单词）。'
- en: '**Regression analysis** : In the context of LLMs, regression analysis isn’t
    used in the traditional sense of fitting a line to data points. Instead, it’s
    a broader class of algorithms that the model uses to map input features (words
    or tokens) to continuous output variables (the embeddings or the logits that will
    be turned into probabilities for the next word).'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归分析**：在LLMs的上下文中，回归分析不是在传统意义上将线拟合到数据点上。相反，它是一类更广泛的算法，模型使用它将输入特征（单词或标记）映射到连续输出变量（嵌入或将成为下一个单词概率的logits）。'
- en: '**Bayesian inference** : Bayesian inference allows the model to update its
    predictions based on new data, incorporating the concept of probability to handle
    uncertainty. In LLMs, this method is not typically used in real time but can be
    a part of the training process, particularly in models that incorporate elements
    of unsupervised learning or reinforcement learning.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贝叶斯推理**：贝叶斯推理允许模型根据新数据更新其预测，结合概率概念来处理不确定性。在LLMs中，这种方法通常不在实时使用，但可以是训练过程的一部分，尤其是在包含无监督学习或强化学习元素的模型中。'
- en: '**Gradient descent and backpropagation** : These are the most common algorithms
    that are used to train neural networks, including LLMs. Gradient descent searches
    for the minimum value of the loss function – a measure of how far the model’s
    predictions are from the actual outcomes. Backpropagation is used to calculate
    the gradient of the loss function concerning each parameter in the model, allowing
    for efficient optimization.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度下降和反向传播**：这些是最常用的算法，用于训练神经网络，包括LLMs。梯度下降寻找损失函数的最小值——衡量模型预测与实际结果之间的距离。反向传播用于计算损失函数相对于模型中每个参数的梯度，从而实现高效的优化。'
- en: '**Stochastic gradient descent** ( **SGD** ): A variant of gradient descent,
    SGD updates the model’s parameters using only a small subset of the data at a
    time, which makes the training process much faster and more scalable for large
    datasets.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机梯度下降**（**SGD**）：梯度下降的一种变体，SGD通过每次只使用数据的一个小子集来更新模型的参数，这使得训练过程对于大数据集来说更快且更具可扩展性。'
- en: '**Transformer models** : The Transformer model, as covered previously, uses
    self-attention mechanisms to weigh the influence of different parts of the input
    data. This allows the model to focus more on certain parts of the input when making
    predictions.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Transformer模型**：正如之前所提到的，Transformer模型使用自注意力机制来权衡输入数据不同部分的影响。这使得模型在预测时能更多地关注输入数据的某些部分。'
- en: '**Regularization techniques** : To prevent overfitting – the phenomenon of
    a model performing well on the training data but poorly on that data it has not
    seen –LLMs employ regularization techniques. These include methods such as dropout,
    where random subsets of neurons are “dropped out” during training to increase
    the robustness of the model.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正则化技术**：为了防止过拟合——即模型在训练数据上表现良好但在未见过的数据上表现不佳的现象——LLMs采用了正则化技术。这些方法包括诸如dropout等，在训练过程中随机丢弃神经元子集，以提高模型的鲁棒性。'
- en: '**Transfer learning** : Transfer learning involves taking a model that has
    been trained on one task and fine-tuning it on a different, but related, task.
    This is common practice with LLMs, where a model that’s been pre-trained on a
    massive corpus of text is later fine-tuned for specific applications.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迁移学习**：迁移学习涉及从一个任务上训练好的模型中提取知识，并在不同的、但相关的任务上进行微调。这在LLMs中是一种常见的做法，其中，一个在大量文本语料库上预训练的模型随后被微调以适应特定的应用。'
- en: '**Reinforcement learning** ( **RL** ): Some LLMs integrate RL, where the model
    learns to make decisions by receiving rewards or penalties. This is less common
    in standard LLM training but can be used in specific scenarios, such as dialog
    systems, where user feedback is available.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习**（**RL**）：一些LLMs集成了RL，其中模型通过接收奖励或惩罚来学习做出决策。这在标准的LLMs训练中较为少见，但可以在特定场景中使用，例如在对话系统中，用户反馈可用。'
- en: '**Neural architecture search** ( **NAS** ): NAS is a process by which an ML
    algorithm searches for the best neural network architecture. This is an advanced
    technique that can be used to optimize LLMs for specific tasks or efficiency.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经架构搜索**（**NAS**）：NAS是一个ML算法搜索最佳神经网络架构的过程。这是一种高级技术，可用于针对特定任务或效率优化LLMs。'
- en: '**Data augmentation techniques** : These techniques involve creating additional
    training data from the existing data through various transformations, enhancing
    the model’s ability to generalize and perform better on unseen data.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据增强技术**：这些技术涉及通过各种变换从现有数据中创建额外的训练数据，增强模型泛化能力和在未见数据上的表现。'
- en: '**Attention techniques** : Various attention mechanisms, including self-attention
    and multi-head attention, allow the model to focus on different parts of the input
    data, enhancing its ability to understand and generate coherent and contextually
    relevant text.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**注意力技术**：包括自注意力和多头注意力在内的各种注意力机制，允许模型关注输入数据的不同部分，增强其理解和生成连贯且上下文相关的文本的能力。'
- en: '**Evaluation metrics** : Lastly, ML algorithms in LLMs rely on various evaluation
    metrics to measure their performance. These include perplexity, the BLEU score
    for translation tasks, the F1 score for classification tasks, and many others,
    depending on the specific application.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估指标**：最后，LLMs中的机器学习算法依赖于各种评估指标来衡量其性能。这些包括困惑度、翻译任务的BLEU分数、分类任务的F1分数以及许多其他指标，具体取决于特定的应用。'
- en: Collectively, these algorithms and techniques enable LLMs to process language
    at a high level, allowing them to generate text that is coherent, contextually
    relevant, and often indistinguishable from text written by humans. However, they
    also require careful tuning and a deep understanding of both the algorithms themselves
    and the language data they are trained on.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这些算法和技术使LLMs能够以高水平处理语言，使它们能够生成连贯、上下文相关且通常难以与人类撰写的文本区分开来的文本。然而，它们也需要仔细调整以及对算法本身以及它们所训练的语言数据的深入理解。
- en: Feedback loops
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反馈循环
- en: 'Feedback loops in ML, including in the context of LLMs, are mechanisms by which
    the model’s performance is assessed and improved over time through interaction
    with its environment or users. Let’s take a closer look at how feedback loops
    operate within LLMs:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在ML中，包括在LLMs的背景下，反馈循环是模型性能通过与其环境或用户的交互而评估和改进的机制。让我们更详细地看看反馈循环在LLMs中是如何运作的：
- en: '**Types of** **feedback loops** :'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反馈循环的类型**：'
- en: '**Supervised learning** **feedback loop** :'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习反馈循环**：'
- en: In a supervised learning setting, the feedback loop involves training the model
    on a dataset where the correct output is known (the “label”), and the model’s
    predictions are compared to these labels
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在监督学习环境中，反馈循环涉及在已知正确输出（即“标签”）的数据集上训练模型，并将模型的预测与这些标签进行比较。
- en: The model receives feedback in the form of loss gradients, which tell it how
    to adjust its parameters to make better predictions in the future
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型以损失梯度的形式接收反馈，这告诉它如何调整其参数以在将来做出更好的预测。
- en: '**RL** **feedback loop** :'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RL反馈循环**：'
- en: In RL, the feedback comes in the form of rewards or penalties, often referred
    to as positive or negative reinforcement.
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在RL中，反馈以奖励或惩罚的形式出现，通常被称为正强化或负强化。
- en: An LLM might be used in an interactive setting where it generates responses
    to user inputs. If the response leads to a successful outcome (for example, user
    satisfaction), the model receives positive feedback; if not, it receives negative
    feedback.
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个LLM可能被用于交互式环境中，生成对用户输入的响应。如果响应导致成功的结果（例如，用户满意），则模型收到正面反馈；如果不是，则收到负面反馈。
- en: '**Mechanisms** **of feedback** :'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反馈机制**：'
- en: '**Backpropagation** : In most neural network training, including LLMs, backpropagation
    is used to provide feedback. This is a method by which the model learns from errors
    by propagating them back through the network’s layers, adjusting the weights accordingly.'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反向传播**：在大多数神经网络训练中，包括LLMs，反向传播被用来提供反馈。这是一种通过将错误传播回网络的层来调整权重，从而使模型从错误中学习的方法。'
- en: '**Reward functions** : In RL, a reward function provides feedback to the model
    based on the actions it takes. For instance, in a conversational AI setting, longer
    user engagement might result in higher rewards.'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**奖励函数**：在RL中，奖励函数根据模型采取的行动向模型提供反馈。例如，在对话AI环境中，更长的用户参与度可能会导致更高的奖励。'
- en: '**User interaction** : As mentioned previously, user interaction can be a source
    of feedback, especially for models deployed in the real world. User corrections,
    time spent on a generated article, click-through rates, and other metrics can
    serve as feedback.'
  id: totrans-67
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户交互**：如前所述，用户交互可以是反馈的来源，尤其是在实际部署的模型中。用户的纠正、在生成文章上花费的时间、点击率和其他指标都可以作为反馈。'
- en: '**Continuous improvement** :'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续改进**：'
- en: '**Model retraining** : Models can be retrained with new data that includes
    past mistakes and successes, allowing them to update their parameters and improve
    over time'
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型重新训练**：模型可以使用包含过去错误和成功的新的数据重新训练，从而使它们能够更新其参数并在时间上改进。'
- en: '**Fine-tuning** : Models may also be fine-tuned on specific tasks or datasets
    based on feedback, which is a more targeted approach than full retraining'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微调**：模型也可以根据反馈在特定任务或数据集上进行微调，这比完全重新训练更具有针对性。'
- en: '**Active learning** : Some systems use active learning, where the model identifies
    areas where it is uncertain and requests feedback in the form of new data or human
    input to improve'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主动学习**：一些系统使用主动学习，其中模型识别出它不确定的领域，并请求以新数据或人类输入的形式提供反馈来改进。'
- en: '**Challenges** **and considerations** :'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**挑战和考虑因素**：'
- en: '**Feedback quality** : The quality of feedback is crucial. Poor feedback can
    lead to incorrect learning and reinforce biases or undesirable behaviors.'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反馈质量**：反馈的质量至关重要。差的反馈可能导致学习错误并加强偏差或不良行为。'
- en: '**Feedback loop dynamics** : Feedback loops can become problematic if they
    start to reinforce themselves in negative ways, such as amplifying biases or leading
    to echo chambers.'
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反馈循环动态**：如果反馈循环开始以负面方式自我强化，例如放大偏差或导致回声室效应，它们可能会变得有问题。'
- en: '**Ethical and safety concerns** : Ensuring that feedback doesn’t lead to the
    development of unsafe or unethical behaviors in LLMs is an ongoing challenge in
    AI safety and ethics.'
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伦理和安全问题**：确保反馈不会导致 LLMs 发展出不安全或不道德的行为是人工智能安全和伦理领域的一个持续挑战。'
- en: Feedback loops are essential for the adaptive and predictive capabilities of
    LLMs, allowing them to refine their decision-making and language understanding
    continually. They are particularly important in applications where LLMs interact
    with users in dynamic environments, such as chatbots, personal assistants, or
    interactive storytelling.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 反馈循环对于 LLMs 的自适应和预测能力至关重要，使它们能够不断改进其决策和语言理解。它们在 LLMs 与用户在动态环境中交互的应用中尤为重要，例如聊天机器人、个人助理或交互式故事讲述。
- en: Uncertainty and error
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不确定性和误差
- en: Uncertainty and error are intrinsic to any statistical model, including LLMs
    such as GPT-4. In this section, we’ll take an in-depth look at how LLMs deal with
    these issues.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定性和误差是任何统计模型，包括 GPT-4 这样的 LLMs 的固有属性。在本节中，我们将深入探讨 LLMs 如何处理这些问题。
- en: The nature of uncertainty in LLMs
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LLMs 中不确定性的本质
- en: 'In understanding the intricacies of LLMs, three fundamental concepts are pivotal:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解 LLMs 的复杂性时，三个基本概念是至关重要的：
- en: '**Probabilistic nature** : The core of LLMs is probabilistic; they generate
    language based on a distribution of possible next words or tokens. This means
    that the model’s output is inherently uncertain, and the model must estimate many
    possible outcomes.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**概率性质**：LLMs 的核心是概率性的；它们基于可能的下一个单词或标记的分布来生成语言。这意味着模型的输出本质上是不确定的，并且模型必须估计许多可能的结果。'
- en: '**Context sensitivity** : LLMs rely heavily on context to make predictions.
    If the context is unclear or ambiguous, the model’s uncertainty increases, which
    can lead to errors in the output.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文敏感性**：LLMs 极度依赖上下文来做出预测。如果上下文不明确或含糊不清，模型的确定性会增加，这可能导致输出错误。'
- en: '**Data sparsity** : No matter how large the training dataset is, there will
    always be gaps. When LLMs encounter scenarios that were underrepresented or not
    present in their training data, they may be less certain about the correct output.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据稀疏性**：无论训练数据集有多大，总会存在空白。当 LLMs 遇到在训练数据中未充分表示或不存在的情况时，它们可能对正确的输出不太确定。'
- en: How LLMs handle uncertainty
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: LLMs 如何处理不确定性
- en: 'To grasp how LLMs generate and refine their outputs, it’s essential to consider
    various key mechanisms:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解 LLMs 如何生成和改进其输出，考虑各种关键机制是至关重要的：
- en: '**Softmax function** : When generating text, the model uses a softmax function
    to convert the logits (the raw output from the last layer of the neural network)
    into a probability distribution. The word with the highest probability is typically
    selected as the next word in the sequence.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Softmax 函数**：在生成文本时，模型使用 softmax 函数将神经网络的最后一层的原始输出（logits）转换为概率分布。通常选择概率最高的单词作为序列中的下一个单词。'
- en: '**Sampling strategies** : Instead of always choosing the most likely next word,
    LLMs can use different sampling strategies to introduce variety into the text
    they generate or to explore less likely, but potentially more interesting, paths.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**采样策略**：LLMs 不总是选择最可能的下一个单词，它们可以使用不同的采样策略来使它们生成的文本多样化，或探索不太可能但可能更有趣的路径。'
- en: '**Beam search** : In tasks such as translation, LLMs might use a beam search
    algorithm to consider multiple potential translations at once and select the most
    probable overall sequence, rather than making decisions word by word.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**束搜索**：在翻译等任务中，LLMs 可能会使用束搜索算法同时考虑多个潜在的翻译，并选择最可能的整体序列，而不是逐词做出决定。'
- en: '**Uncertainty quantification** : Some models are capable of quantifying their
    uncertainty, which can be useful for flagging when the model’s output should be
    treated with caution.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不确定性量化**：一些模型能够量化其不确定性，这在标记模型输出时应谨慎处理时可能很有用。'
- en: '**Monte Carlo dropout** : This technique is used during inference to provide
    a measure of uncertainty in the model’s predictions. It does this by randomly
    dropping out different parts of the network and sampling multiple times, which
    helps in understanding the variability and reliability of the model’s output.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**蒙特卡洛dropout**：这种技术用于推理过程中，以提供模型预测的不确定性度量。它通过随机丢弃网络的不同部分并多次采样来实现，这有助于理解模型输出的可变性和可靠性。'
- en: Error types and sources
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 错误类型和来源
- en: 'Addressing the accuracy and reliability of LLMs involves understanding the
    following nuances:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 解决LLMs的准确性和可靠性问题需要理解以下细微差别：
- en: '**Systematic errors** : These occur when the model consistently misinterprets
    certain inputs due to biases or flaws in the training data.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统误差**：这些错误发生在模型由于偏差或训练数据中的缺陷而持续误解某些输入时。'
- en: '**Random errors** : These occur unpredictably and are usually due to the inherent
    randomness in the model’s probability estimates.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机错误**：这些错误不可预测地发生，通常是由于模型概率估计中的固有随机性。'
- en: '**Overfitting and underfitting** : Overfitting occurs when a model is too closely
    tailored to the training data and fails to generalize to new data. Underfitting
    occurs when the model is too simple to capture the complexity of the training
    data.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过拟合和欠拟合**：过拟合发生在模型过于紧密地适应训练数据，无法泛化到新数据时。欠拟合发生在模型过于简单，无法捕捉训练数据的复杂性时。'
- en: '**Model misinterpretation** : Errors can arise when users misinterpret the
    capabilities of the model, expecting it to have an understanding or abilities
    beyond its actual capacity.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型误解**：当用户误解了模型的能力，期望它具有超出其实际能力的理解或能力时，可能会出现错误。'
- en: Error mitigation strategies
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 错误缓解策略
- en: 'In the pursuit of optimizing LLMs, techniques such as the ones mentioned here
    play crucial roles in enhancing performance and maintaining relevance over time:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在追求优化LLMs的过程中，如上所述的技术在提升性能和保持长期相关性方面发挥着关键作用：
- en: '**Regularization** : Techniques such as dropout are used during training to
    prevent overfitting and help the model generalize better to new data'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正则化**：在训练过程中使用如dropout等技术来防止过拟合，并帮助模型更好地泛化到新数据'
- en: '**Ensemble methods** : Using a collection of models to make a decision can
    reduce the impact of errors as the models can correct each other’s mistakes'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成方法**：使用一系列模型来做出决策可以减少错误的影响，因为模型可以互相纠正错误'
- en: '**Human-in-the-loop** : For critical applications, human oversight can be used
    to review and correct the model’s output'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人机交互**：对于关键应用，可以使用人工监督来审查和纠正模型的输出'
- en: '**Continuous training** : Continually updating the model with new data can
    help it learn from past errors and adapt to changes in language use over time'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续训练**：持续用新数据更新模型可以帮助它从过去的错误中学习，并适应语言使用的变化'
- en: Ethical and practical implications
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 道德和实际影响
- en: 'The following aspects are fundamental in managing the deployment and user interaction
    process regarding LLMs:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在管理LLMs的部署和用户交互过程中，以下方面是基本要素：
- en: '**Trust** : Users need to understand the probabilistic nature of LLMs to set
    appropriate expectations for their reliability'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信任**：用户需要了解LLMs的概率性质，以设定适当的可靠性期望'
- en: '**Safety** : In high-stakes scenarios, the potential for error must be managed
    carefully to avoid harmful outcomes'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性**：在高风险场景中，必须谨慎管理错误的可能性，以避免有害的结果'
- en: '**Transparency** : Users must be aware of how LLMs make decisions and the potential
    for uncertainty and error in their outputs'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**透明度**：用户必须了解LLMs是如何做出决策的，以及它们输出中不确定性和错误的可能性'
- en: In summary, while LLMs have advanced considerably, they are not infallible and
    their outputs must be evaluated critically, especially when used in sensitive
    or impactful contexts. Understanding the nature of uncertainty and error in these
    models is crucial for both users and developers to use them effectively and ethically.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，尽管LLMs已经取得了显著的进步，但它们并非完美无缺，其输出必须进行批判性评估，尤其是在敏感或影响重大的环境中。理解这些模型中不确定性和错误的本性对于用户和开发者有效且道德地使用它们至关重要。
- en: From input to output – understanding LLM response generation
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从输入到输出——理解LLMs的响应生成过程
- en: The process of generating a response in an LLM such as GPT-4 is a complex journey
    from input to output. In this section, we’ll take a closer look at the steps that
    are involved.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM如GPT-4中生成响应的过程是一个从输入到输出的复杂旅程。在本节中，我们将更详细地探讨涉及到的步骤。
- en: Input processing
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输入处理
- en: 'The following are the key preprocessing steps in LLMs:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在LLM中的关键预处理步骤：
- en: '**Tokenization** : Splitting the text into tokens based on predefined rules
    or learned patterns.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分词**：根据预定义的规则或学习到的模式将文本分割成标记。'
- en: '**Embedding** : Sometimes, tokens are normalized to a standard form. For instance,
    “USA” and “U.S.A.” might be normalized to a single form.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**嵌入**：有时，标记会被归一化到标准形式。例如，“USA”和“U.S.A.”可能被归一化到单一形式。'
- en: '**Positional encoding** : Each unique token is associated with an index in
    a vocabulary list. The model will use these indices, not the text itself, to process
    the language.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**位置编码**：每个独特的标记都与词汇表中的一个索引相关联。模型将使用这些索引，而不是文本本身，来处理语言。'
- en: Model architecture
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型架构
- en: 'The following are central components in the architecture of LLMs:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在LLM架构中的核心组件：
- en: '**Transformer blocks** : Each Transformer block contains two main parts: a
    multi-head self-attention mechanism and a position-wise feed-forward network.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Transformer块**：每个Transformer块包含两个主要部分：一个多头自注意力机制和一个位置前馈网络。'
- en: '**Self-attention** : As mentioned previously, the attention mechanism allows
    the model to weigh the importance of different tokens when predicting the next
    word. It can focus on the entire input sequence and determine which parts are
    most relevant at any given time.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自注意力**：如前所述，注意力机制允许模型在预测下一个单词时权衡不同标记的重要性。它可以关注整个输入序列，并确定在任何给定时间哪些部分是最相关的。'
- en: Decoding and generation
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解码和生成
- en: The process of decoding and generation in the context of LLMs such as GPT-4
    involves several intricate steps that convert a given input into a coherent and
    contextually appropriate output. This process is the core of how these models
    communicate and generate text. Let’s take a closer look at each step.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM（如GPT-4）的上下文中，解码和生成过程涉及将给定输入转换为连贯且上下文适当的输出的几个复杂步骤。这个过程是这些模型沟通和生成文本的核心。让我们更详细地看看每个步骤。
- en: 'The probability distribution process involves the following aspects:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 概率分布过程涉及以下方面：
- en: '**Logits** : Splitting the text into tokens based on predefined rules or learned
    patterns.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对数概率**：根据预定义的规则或学习到的模式将文本分割成标记。'
- en: '**Softmax layer** : Sometimes, tokens are normalized to a standard form.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Softmax层**：有时，标记会被归一化到标准形式。'
- en: '**Temperature** : Each unique token is associated with an index in a vocabulary
    list. The model will use these indices, not the text itself, to process the language.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**温度**：每个独特的标记都与词汇表中的一个索引相关联。模型将使用这些索引，而不是文本本身，来处理语言。'
- en: 'Output selection is comprised of the following components:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 输出选择包括以下组件：
- en: '**Greedy decoding** : The most straightforward selection method is greedy decoding,
    where the model always picks the word with the highest probability as the next
    token. This approach is deterministic.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贪婪解码**：最直接的选择方法是贪婪解码，其中模型总是选择概率最高的单词作为下一个标记。这种方法是确定性的。'
- en: '**Beam search** : Beam search is a more nuanced technique where the model keeps
    track of multiple sequences (the “beam width”) and extends them one token at a
    time, ultimately choosing the sequence with the highest overall probability.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**束搜索**：束搜索是一种更精细的技术，其中模型跟踪多个序列（“束宽度”），一次扩展一个标记，最终选择整体概率最高的序列。'
- en: '**Random sampling** : The model can also randomly sample from the probability
    distribution, which introduces randomness into the output and can lead to more
    creative and less predictable text.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机采样**：模型还可以从概率分布中随机采样，这会将随机性引入输出，并可能导致更具创造性和不可预测的文本。'
- en: '**Top-k sampling** : This method restricts the sampling pool to the *k* most
    likely next words. The model then samples only from this subset, which can lead
    to a balance between variety and coherence.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Top-k采样**：这种方法将采样池限制在*k*个最可能的下一个单词。然后模型只从这个子集进行采样，这可能导致多样性和连贯性之间的平衡。'
- en: '**Top-p (nucleus) sampling** : Instead of picking a fixed number of words,
    top-p sampling chooses from the smallest set of words whose cumulative probability
    exceeds a threshold, *p* . This focuses on a “nucleus” of likely words, ignoring
    the long tail of the distribution.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Top-p（核）采样**：与选择固定数量的单词不同，top-p采样从累积概率超过阈值*p*的最小单词集中选择。这侧重于“核”中可能的单词，忽略了分布的长尾。'
- en: The challenges in decoding and generation
  id: totrans-132
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解码和生成中的挑战
- en: 'Let’s take a closer look at the challenges we must overcome:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看看我们必须克服的挑战：
- en: '**Repetitiveness** : Even sophisticated models can fall into repetitive loops,
    especially with greedy decoding methods'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重复性**：即使是复杂的模型也可能陷入重复循环，尤其是在使用贪婪解码方法时。'
- en: '**Coherence over long texts** : Maintaining coherence over longer texts is
    challenging as the model must remember and appropriately reference information
    that may have been introduced much earlier'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**长文本的连贯性**：在长文本中保持连贯性具有挑战性，因为模型必须记住并适当地引用可能早在很久以前就引入的信息。'
- en: '**Context limitations** : There is a limit to how much context the model can
    consider, known as the context window, which can affect the quality of the generated
    text for inputs that exceed this window'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文限制**：模型可以考虑的上下文量是有限的，称为上下文窗口，这可能会影响超出此窗口的输入生成文本的质量。'
- en: Future directions
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 未来方向
- en: 'Now, let’s consider some future directions:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们考虑一些未来的方向：
- en: '**Attention span** : Research is ongoing into models that can handle longer
    contexts, either through modifications to the attention mechanism or different
    approaches to memory'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**注意力跨度**：研究人员正在探索能够处理更长上下文的模型，这可以通过修改注意力机制或采用不同的记忆方法来实现。'
- en: '**Adaptive decoding** : Adapting the decoding strategy based on the type of
    text being generated (for example, creative writing versus technical instructions)
    could improve the quality of the generated text'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自适应解码**：根据生成的文本类型（例如，创意写作与技术说明）调整解码策略，可以提高生成文本的质量。'
- en: '**Feedback-informed generation** : Incorporating real-time feedback loops could
    help models adjust their generation process on the fly, leading to more interactive
    and adaptive communication'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于反馈的生成**：引入实时反馈循环可以帮助模型动态调整其生成过程，从而实现更互动和自适应的交流。'
- en: Decoding and generation is a field of active research, with each new model version
    aiming to produce more accurate, coherent, and contextually rich outputs. This
    not only involves improvements to the underlying algorithms but also a better
    understanding of how humans use language.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 解码和生成是一个活跃的研究领域，每个新版本的模型都旨在生成更准确、更连贯、上下文更丰富的输出。这不仅涉及对底层算法的改进，还涉及对人类如何使用语言的更好理解。
- en: Iterative generation
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迭代生成
- en: 'Iterativ e generation is a fundamental process that’s used by LLMs such as
    GPT-4 to produce text. This process is characterized by two main components: the
    autoregressive process and the establishment of a stop condition. Iterative generation
    is a multi-step process that may involve revisions, while decoding and generation
    are generally one-pass processes. Let’s take a closer look.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代生成是大型语言模型（如GPT-4）用于生成文本的基本过程。这个过程有两个主要组成部分：自回归过程和停止条件的建立。迭代生成是一个多步骤的过程，可能涉及修订，而解码和生成通常是单次过程。让我们更深入地了解一下。
- en: Autoregressive process
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自回归过程
- en: 'Over time, the following critical aspects dictate how LLMs process and generate
    language:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，以下关键方面决定了大型语言模型（LLM）处理和生成语言的方式：
- en: '**Sequential predictions** : In an autoregressive model, each output token
    (which could be a word or part of a word) is predicted sequentially. The prediction
    of each subsequent token is conditional on the tokens that have been generated
    so far.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**序列预测**：在自回归模型中，每个输出标记（可能是单词或单词的一部分）是按顺序预测的。后续标记的预测是基于迄今为止已生成的标记。'
- en: '**Dependency on previous tokens** : The model’s prediction at each step is
    based on all the previous tokens in the sequence, which means that the model “remembers”
    what it has already generated. This is crucial for maintaining coherence and context.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对先前标记的依赖**：模型在每个步骤的预测基于序列中的所有先前标记，这意味着模型“记得”它已经生成的内容。这对于保持连贯性和上下文至关重要。'
- en: '**Latent representations** : As tokens are generated, the model updates its
    representations of the sequence’s meaning internally. These representations are
    complex vectors in high-dimensional space that encode the semantic and syntactic
    nuances of the text.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**潜在表示**：随着标记的生成，模型会更新其对序列意义的内部表示。这些表示是高维空间中的复杂向量，编码了文本的语义和句法细微差别。'
- en: '**Complexity over time** : With each new token, the complexity of the text
    increases. The model must balance various factors, such as grammar, context, style,
    and the specific requirements of the task at hand.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随时间增加的复杂性**：随着每个新标记的生成，文本的复杂性增加。模型必须平衡各种因素，如语法、上下文、风格以及当前任务的具体要求。'
- en: Stop condition
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 停止条件
- en: 'These are mechanisms in LLMs that guide when and how to conclude the generation
    of text:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是LLM中的机制，指导何时以及如何结束文本的生成：
- en: '**End-of-sequence token** : Many LLMs use a special token to signify the end
    of a sequence, often referred to as **<EOS>** or **[end]** . When the model predicts
    this token, the iterative generation process stops.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**序列结束标记**：许多大型语言模型使用一个特殊的标记来表示序列的结束，通常被称为**<EOS>**或**[end]**。当模型预测这个标记时，迭代生成过程就会停止。'
- en: '**Maximum length** : To prevent runaway generation, a maximum sequence length
    is often set. Once the generated text reaches this length, the model will stop
    generating new tokens, regardless of whether it has reached a natural conclusion.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大长度**：为了防止生成失控，通常会设置最大序列长度。一旦生成的文本达到这个长度，无论是否达到自然结论，模型都会停止生成新的标记。'
- en: '**Task-specific conditions** : For certain applications, there might be other
    conditions that determine when the generation process should stop. For example,
    in a question-answering task, the model might be programmed to stop after generating
    a sentence that appears to answer the question.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务特定条件**：对于某些应用，可能存在其他条件来决定何时停止生成过程。例如，在问答任务中，模型可能被编程在生成一个看似回答问题的句子后停止。'
- en: Challenges in iterative generation
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 迭代生成中的挑战
- en: 'Here are some challenges you should consider:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些你应该考虑的挑战：
- en: '**Repetition** : Models may get stuck in loops, repeating the same phrase or
    structure. This can often be mitigated by modifying the sampling strategy or by
    using techniques such as deduplication post-generation.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重复**：模型可能会陷入循环，重复相同的短语或结构。这通常可以通过修改采样策略或使用如后生成去重等技术来缓解。'
- en: '**Context dilution** : As more tokens are generated, the influence of the initial
    context can diminish, potentially leading to a loss of coherence.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文稀释**：随着生成的标记越来越多，初始上下文的影响可能会减弱，这可能导致连贯性的丧失。'
- en: '**Computational efficiency** : Generating text token by token can be computationally
    intensive, particularly for longer sequences or when using sampling strategies
    that require many potential continuations to be evaluated.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算效率**：逐个生成文本标记的计算量可能很大，尤其是对于较长的序列或使用需要评估许多潜在延续的采样策略时。'
- en: Future directions
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 未来方向
- en: 'Advancements in the design of LLMs aim to improve the following areas:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: LLM设计方面的进步旨在改善以下领域：
- en: '**Longer context windows** : Researchers are working on expanding the context
    window that LLMs can consider, allowing for better maintenance of context over
    longer texts'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更长的上下文窗口**：研究人员正在努力扩大LLM可以考虑的上下文窗口，以便在较长的文本中更好地维护上下文。'
- en: '**Efficient decoding** : Newer models and techniques are being developed to
    generate text more efficiently, balancing the trade-offs between speed, coherence,
    and diversity'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高效解码**：正在开发新的模型和技术，以更高效地生成文本，平衡速度、连贯性和多样性的权衡。'
- en: '**Interactive generation** : Some research focuses on making the generation
    process interactive, allowing users to guide the generation in real time or provide
    feedback that the model can incorporate immediately'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交互式生成**：一些研究致力于使生成过程交互式，允许用户实时引导生成或提供模型可以立即采纳的反馈。'
- en: Iterative generation is at the core of how LLMs such as GPT-4 produce text,
    enabling them to create everything from simple sentences to complex narratives
    and technical documents. Despite its challenges, the autoregressive nature of
    LLMs is what allows text to be generated that is often indistinguishable from
    that written by humans. As research progresses, we can expect to see more sophisticated
    models that handle the complexities of language with even greater finesse.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代生成是LLM（如GPT-4）产生文本的核心，使它们能够从简单的句子到复杂的叙事和技术文档都能创建。尽管存在挑战，LLM的自回归特性使得生成的文本往往难以与人类写作区分开来。随着研究的进展，我们可以期待看到处理语言复杂性的更高级模型，它们将以更加精湛的方式处理这些复杂性。
- en: Post-processing
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 后处理
- en: Post-processing is a crucial step in the workflow of text generation with LLMs,
    which ensures that the raw output from the model is polished and made presentable
    for the intended audience or application. Let’s take a detailed look at the components
    of post-processing.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理是使用LLM进行文本生成工作流程中的关键步骤，它确保模型输出的原始文本经过打磨，并适合目标受众或应用。让我们详细了解一下后处理的组成部分。
- en: Detokenization
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解码
- en: 'After an LLM generates a sequence of tokens, they must be converted back into
    a format that can be understood and read by humans. This process is known as detokenization.
    Let’s take a look at what’s involved:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM生成一系列标记后，它们必须被转换回人类可以理解和阅读的格式。这个过程被称为标记化。让我们看看涉及的内容：
- en: '**Joining tokens** : Tokens that represent subparts of words or punctuation
    need to be joined together correctly. For example, “New,” “##York,” and “City”
    would need to be detokenized to “New York City.”'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**连接标记**：表示单词或标点符号子部分的标记需要正确连接。例如，“New,” “##York,” 和 “City” 需要标记化为 “New York
    City。”'
- en: '**Whitespace management** : Adding spaces between words is generally straightforward
    but can be complex with languages that don’t use whitespace in the same way as
    English or when dealing with special characters and punctuation.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**空白管理**：在单词之间添加空格通常很简单，但在不使用空格的方式与英语相同或处理特殊字符和标点符号时可能会很复杂。'
- en: '**Special tokens** : The model might generate special tokens that indicate
    formatting or other non-standard text elements. These need to be interpreted or
    removed during detokenization.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特殊标记**：模型可能会生成表示格式或其他非标准文本元素的特殊标记。这些需要在标记化过程中进行解释或删除。'
- en: Formatting
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 格式化
- en: 'Once the text has been detokenized, it may need additional formatting to ensure
    it meets the required standards for grammar, style, and coherence. This can involve
    several processes:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 文本经过标记化后，可能需要额外的格式化以确保其符合语法、风格和连贯性的要求。这可能涉及以下几个过程：
- en: '**Grammar checks** : Automated grammar checkers can identify and correct basic
    grammatical errors that the LLM may have produced.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语法检查**：自动语法检查器可以识别并纠正LLM可能产生的基本语法错误。'
- en: '**Style guides** : For certain applications, the text might need to adhere
    to specific style guides. This could involve adjusting word choice, sentence structure,
    or punctuation.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**风格指南**：对于某些应用程序，文本可能需要遵循特定的风格指南。这可能涉及调整措辞、句子结构或标点符号。'
- en: '**Custom rules** : Some applications may require specific formatting rules,
    such as capitalizing certain words, formatting dates and numbers, or adding hyperlinks.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自定义规则**：某些应用程序可能需要特定的格式化规则，例如首字母大写某些单词、格式化日期和数字或添加超链接。'
- en: '**Domain-specific adjustments** : Technical, legal, or medical texts might
    require additional checks to ensure terminology and formatting meet industry standards.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特定领域调整**：技术、法律或医学文本可能需要额外的检查，以确保术语和格式符合行业标准。'
- en: Challenges in post-processing
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 后处理挑战
- en: 'In managing the output quality of LLMs, the following issues are critical to
    address:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在管理LLM的输出质量时，以下问题至关重要，需要解决：
- en: '**Loss of meaning** : Incorrect detokenization can sometimes change the meaning
    of the text or render it nonsensical'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**意义丧失**：不正确的标记化有时会改变文本的意义或使其变得无意义'
- en: '**Overcorrection** : Automated grammar and style correction tools might “overcorrect”
    the text, making changes that don’t align with the intended meaning or style'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过度修正**：自动语法和风格修正工具可能会“过度修正”文本，做出与预期意义或风格不一致的更改'
- en: '**Scalability** : Post-processing needs to be efficient to handle large volumes
    of text without introducing significant delays'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：后处理需要高效，以便在不引入显著延迟的情况下处理大量文本'
- en: Future directions
  id: totrans-185
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 未来方向
- en: 'The following are essential strategies for elevating the quality and effectiveness
    of text generated by LLMs:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是将LLM生成的文本质量提升到更高水平和有效性的关键策略：
- en: '**ML in post-processing** : ML models specifically trained for post-processing
    tasks can improve the quality of the output text'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**后处理中的机器学习**：专门针对后处理任务训练的ML模型可以提高输出文本的质量'
- en: '**User feedback integration** : Incorporating user feedback into post-processing
    can help tailor the text to the preferences of the audience'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户反馈整合**：将用户反馈整合到后处理中可以帮助使文本符合受众的偏好'
- en: '**Adaptive formatting** : Developing systems that can adapt the formatting
    based on the context and intended use of the text can enhance the readability
    and impact of the generated content'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自适应格式化**：开发能够根据文本的上下文和预期用途调整格式的系统可以增强生成内容的可读性和影响力'
- en: Post-processing is the final touch that transforms the model’s output into polished,
    user-friendly content. It is an area where even small improvements can significantly
    enhance the usability of LLM-generated text, making it more accessible and effective
    for the task at hand.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 后处理是将模型输出转化为精致、用户友好的内容的最终修饰。这是一个即使微小改进也能显著提高LLM生成文本可用性的领域，使其更易于使用和更有效。
- en: Challenges and limitations in LLM decision-making
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM决策中的挑战和局限性
- en: 'LLMs such as GPT-4 are technological marvels, but they come with a set of challenges
    and limitations that impact their decision-making abilities. Here are some of
    the challenges and limitations we must consider:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4等LLM是技术奇迹，但它们带来了一系列挑战和局限性，这些局限性影响了它们的决策能力。以下是我们必须考虑的一些挑战和局限性：
- en: '**Understanding context** **and nuance** :'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**理解语境和细微差别**：'
- en: '**Ambiguity** : LLMs may struggle with ambiguity in language. They sometimes
    cannot determine the correct meaning of a word or phrase without clear context.'
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**歧义**：LLM可能在语言中的歧义上遇到困难。在没有明确上下文的情况下，他们有时无法确定一个词或短语的正确含义。'
- en: '**Sarcasm and irony** : Detecting sarcasm or irony is particularly challenging
    because it often requires understanding subtle cues and having a deep cultural
    context that LLMs may not have.'
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**讽刺和反语**：检测讽刺或反语特别具有挑战性，因为这通常需要理解细微的线索和拥有LLM可能不具备的深厚文化背景。'
- en: '**Long-term context** : Maintaining coherence over long conversations or documents
    is difficult as LLMs might lose track of earlier context.'
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**长期语境**：在长时间对话或文档中保持连贯性很困难，因为LLM可能会失去早期语境'
- en: '**Generalization** **versus specialization** :'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**泛化与专业化**：'
- en: '**Overfitting** : LLMs can become too specialized to the training data, making
    them less able to generalize to new types of data or problems'
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过拟合**：LLM可能过于专门化于训练数据，使其难以泛化到新的数据类型或问题'
- en: '**Underfitting** : Conversely, LLMs might not capture the specifics of certain
    tasks or domains if they generalize too much'
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欠拟合**：相反，如果LLM泛化过多，它们可能无法捕捉到某些任务或领域的具体细节'
- en: '**Data bias** **and fairness** :'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据偏差和公平性**：'
- en: '**Training data bias** : LLMs reflect the biases in their training data, which
    can lead to unfair or prejudiced outcomes'
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练数据偏差**：LLM反映了其训练数据中的偏差，可能导致不公平或偏见的结果'
- en: '**Representation** : If the training data doesn’t represent the diversity of
    language and communication styles, the LLM’s performance can be uneven across
    different user groups'
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代表性**：如果训练数据没有代表语言和交流风格的多样性，LLM在不同用户群体中的表现可能不均衡'
- en: '**Ethical and** **moral reasoning** :'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伦理和道德推理**：'
- en: '**Value alignment** : LLMs don’t possess human values and can generate ethically
    questionable content'
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价值一致性**：LLM不具有人类价值观，可能生成具有道德问题的内容'
- en: '**Moral decision-making** : LLMs cannot make moral decisions or understand
    ethical nuances in the way humans do'
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**道德决策**：LLM不能像人类那样做出道德决策或理解道德细微差别'
- en: '**Reliability and** **error rates** :'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可靠性和错误率**：'
- en: '**Inconsistencies** : LLMs might produce inconsistent or contradictory information,
    especially when generating information over multiple sessions'
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不一致性**：LLM可能会产生不一致或相互矛盾的信息，尤其是在多个会话中生成信息时'
- en: '**Factuality** : LLMs can confidently present incorrect information as fact,
    leading to misinformation if it’s not checked'
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事实性**：LLM可能会自信地将错误信息作为事实呈现，如果不进行检查，可能导致错误信息'
- en: '**Interpretability** **and transparency** :'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性和透明度**：'
- en: '**Black box nature** : An LLM’s decision-making process is complex and often
    not easily interpretable, which can make it hard to understand why it generates
    certain outputs'
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黑盒性质**：LLM的决策过程复杂且往往不易解释，这可能导致难以理解为什么它生成某些输出'
- en: '**Transparency** : It can be difficult to provide clear explanations for the
    model’s behavior, which is a significant issue for accountability'
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**透明度**：提供对模型行为的明确解释可能很困难，这是一个重大的责任问题'
- en: '**Computational and** **environmental costs** :'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算和环境成本**：'
- en: '**Resource intensive** : Training and running LLMs requires a considerable
    amount of computational resources, which leads to high energy consumption and
    environmental impact'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源密集型**：训练和运行LLM需要相当多的计算资源，这导致高能耗和环境影响'
- en: '**Scalability** : The computational cost also affects scalability as deploying
    LLMs to many users can be resource-prohibitive'
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：计算成本也影响可扩展性，因为将LLM部署给许多用户可能成本过高'
- en: '**Dependence on** **human oversight** :'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**依赖** **人类监督**：'
- en: '**Supervision needs** : Many LLM applications require human oversight to ensure
    the quality and appropriateness of outputs'
  id: totrans-216
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督需求**：许多 LLM 应用需要人类监督，以确保输出的质量和适宜性'
- en: '**Feedback loop limitations** : While feedback loops can improve LLMs, they
    can also perpetuate errors if they’re not managed carefully'
  id: totrans-217
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反馈循环限制**：虽然反馈循环可以提高 LLMs，但如果管理不当，它们也可能持续错误'
- en: '**Safety** **and security** :'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全** **与** **安全**：'
- en: '**Robustness** : LLMs can be sensitive to adversarial attacks where small,
    carefully crafted changes to the input can lead to incorrect outputs'
  id: totrans-219
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**鲁棒性**：LLMs 可能对对抗性攻击敏感，其中对输入的微小、精心设计的更改可能导致错误的输出'
- en: '**Manipulation** : There’s a risk of LLMs being used to generate manipulative
    content, such as deepfakes or spam'
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**操纵**：存在风险，即 LLMs 被用于生成操纵性内容，如深度伪造或垃圾邮件'
- en: '**Societal impact** :'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社会影响**：'
- en: '**Job displacement** : Automating tasks that LLMs can perform may lead to the
    displacement of jobs, raising societal and economic concerns'
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作替代**：自动化 LLMs 可以执行的任务可能导致工作替代，引发社会和经济担忧'
- en: '**Digital divide** : The benefits of LLMs may not be evenly distributed, potentially
    exacerbating the digital divide'
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数字鸿沟**：LLMs 的好处可能不会均匀分布，可能会加剧数字鸿沟'
- en: Despite these challenges and limitations, LLMs represent a significant step
    forward in AI and natural language processing. Continuous research is directed
    toward mitigating these issues, improving the models’ decision-making processes,
    and finding ways to use LLMs responsibly and effectively. It’s a dynamic field
    that requires not only technical innovation but also ethical and societal considerations.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些挑战和限制，LLMs 仍然是人工智能和自然语言处理领域的一大进步。持续的研究旨在减轻这些问题，改进模型的决策过程，并找到负责任和有效地使用
    LLMs 的方法。这是一个需要技术创新、道德和社会考量的动态领域。
- en: Evolving decision-making – advanced techniques and future directions
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决策能力的发展——高级技术和未来方向
- en: The field of AI, particularly the branch that deals with LLMs, is rapidly evolving.
    The decision-making capabilities of these models are constantly being enhanced
    through advanced techniques and research into future directions. Let’s explore
    some of these advancements and the potential paths that future developments might
    take.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能领域，尤其是处理大型语言模型（LLMs）的分支，正在迅速发展。这些模型的决策能力正通过高级技术和对未来方向的研究不断得到提升。让我们探索一些这些进步以及未来发展的潜在路径。
- en: Advanced techniques in LLM decision-making
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMs 决策的高级技术
- en: 'Advancements in these domains are driving the evolution of LLMs, each contributing
    to more nuanced text processing and enhanced model performance:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这些领域的进步正在推动 LLMs 的发展，每个领域都为更精细的文本处理和模型性能的提升做出了贡献：
- en: '**Transformer architecture** : The Transformer architecture has been pivotal
    in the recent successes of LLMs. Innovations continue to emerge in how these models
    handle long-range dependencies and contextual information.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Transformer 架构**：Transformer 架构在 LLMs 近期取得的成功中起到了关键作用。这些模型处理长距离依赖和上下文信息的方法仍在不断创新。'
- en: '**Sparse attention mechanisms** : To handle longer texts efficiently, researchers
    are developing sparse attention patterns that allow LLMs to focus on the most
    relevant parts of the input without being overwhelmed by data.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稀疏注意力机制**：为了有效地处理较长的文本，研究人员正在开发稀疏注意力模式，允许 LLMs 聚焦于输入中最相关的部分，而不会被数据淹没。'
- en: '**Capsule networks** : These are designed to enhance the model’s ability to
    understand hierarchical relationships in data, potentially improving the decision-making
    process by capturing more nuanced patterns.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**胶囊网络**：这些网络旨在增强模型理解数据中层次关系的能力，通过捕捉更细微的模式，可能改善决策过程。'
- en: '**Energy-based models** : By modeling decision-making as an energy minimization
    problem, these models can generate more coherent and contextually appropriate
    responses.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于能量的模型**：通过将决策建模为能量最小化问题，这些模型可以生成更连贯和上下文相关的响应。'
- en: '**Adversarial training** : This involves training models to resist adversarial
    attacks, which can improve their robustness and reliability.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对抗性训练**：这涉及训练模型抵抗对抗性攻击，可以提高其鲁棒性和可靠性。'
- en: '**Neuro-symbolic AI** : Combining deep learning with symbolic reasoning, neuro-symbolic
    AI could lead to models that have a better grasp of logic, causality, and common-sense
    reasoning.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经符号人工智能**：将深度学习与符号推理相结合，神经符号人工智能可能导致模型更好地掌握逻辑、因果关系和常识推理。'
- en: Future directions for LLM decision-making
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM决策的未来的发展方向
- en: 'The future of LLMs is poised to be shaped by the following advancements:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的未来将由以下进步塑造：
- en: '**Improved contextual understanding** : Future LLMs may incorporate mechanisms
    that allow for a more profound understanding of context, not just within a single
    conversation or document but across multiple interactions.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**改进的上下文理解**：未来的大型语言模型（LLM）可能会采用机制，以实现更深入的理解上下文，而不仅仅是单一对话或文档中的上下文，而是在多个交互中。'
- en: '**Continual learning** : Enabling LLMs to learn from new data continuously
    without forgetting previous knowledge is a significant goal. Techniques such as
    elastic weight consolidation are being explored to achieve this.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续学习**：使LLM能够持续地从新数据中学习而不忘记以前的知识是一个重要的目标。正在探索弹性权重巩固等技术来实现这一点。'
- en: '**Interpretable AI** : There is a push toward making AI decision-making more
    interpretable and transparent. This includes developing models that can explain
    their reasoning and choices in human-understandable terms.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释人工智能**：推动使人工智能决策更具可解释性和透明度。这包括开发能够用人类可理解的语言解释其推理和选择的模型。'
- en: '**Enhanced common sense and world knowledge** : Future models might integrate
    structured world knowledge and common-sense reasoning databases, improving their
    decision-making capabilities significantly.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强常识和世界知识**：未来的模型可能会整合结构化的世界知识和常识推理数据库，显著提高其决策能力。'
- en: '**Biologically inspired AI** : Drawing inspiration from neuroscience, future
    LLMs might mimic the human brain’s decision-making processes more closely, potentially
    leading to more natural and intuitive AI behavior.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**受生物启发的AI**：从神经科学中汲取灵感，未来的LLM可能会更接近地模仿人类大脑的决策过程，可能导致更自然和直观的人工智能行为。'
- en: '**Hybrid models** : Combining LLMs with other types of AI, such as reinforcement
    learning agents, could lead to systems that can both generate natural language
    and interact with the environment in sophisticated ways.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合模型**：将LLM与其他类型的AI（如强化学习代理）相结合，可能导致既能生成自然语言又能以复杂方式与环境交互的系统。'
- en: '**Ethical AI** : As LLMs become more advanced, ensuring they make decisions
    that align with human values and ethics becomes increasingly important. Research
    into ethical AI focuses on embedding moral decision-making processes within the
    model’s architecture.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**道德人工智能**：随着LLM的日益先进，确保它们做出的决策与人类价值观和道德相一致变得越来越重要。道德人工智能的研究集中在将道德决策过程嵌入到模型的架构中。'
- en: '**Personalization** : Personalizing responses based on user preferences and
    history, while maintaining privacy and security, is an area of active research.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个性化**：根据用户偏好和历史记录个性化响应，同时保持隐私和安全，是一个活跃的研究领域。'
- en: '**Multimodal AI** : Integrating LLMs with other types of data, such as visual
    or auditory information, could lead to richer decision-making capabilities and
    more versatile applications.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多模态人工智能**：将LLM与其他类型的数据（如视觉或听觉信息）集成，可能导致更丰富的决策能力和更广泛的应用。'
- en: '**Quantum computing** : Quantum algorithms have the potential to revolutionize
    LLMs by enabling them to process information in fundamentally new ways, though
    this is still in the exploratory stage.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**量子计算**：量子算法有可能通过使LLM能够以全新的方式处理信息来彻底改变LLM，尽管这仍处于探索阶段。'
- en: '**Multilingual and cross-lingual capabilities** : Future LLMs are expected
    to enhance their ability to understand and generate text across multiple languages
    and leverage cross-lingual information, improving global accessibility and usability.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多语言和跨语言能力**：预计未来的LLM将增强其理解和生成多语言文本的能力，并利用跨语言信息，从而提高全球可访问性和可用性。'
- en: '**Sustainability and efficiency** : There is a growing focus on making LLMs
    more energy-efficient and environmentally sustainable by optimizing algorithms,
    reducing computational requirements, and exploring greener AI technologies.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可持续性和效率**：越来越关注通过优化算法、减少计算需求以及探索更绿色的人工智能技术，使LLM更加节能和环保。'
- en: Challenges and considerations
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 挑战和考虑因素
- en: As LLMs and their decision-making processes evolve, there will be challenges,
    including computational demands, potential biases in AI behavior, privacy concerns,
    and the need for regulatory frameworks. There will also be a continuous need for
    multidisciplinary collaboration among computer scientists, ethicists, sociologists,
    and policymakers to guide the development of these advanced AI systems.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型（LLMs）及其决策过程的不断发展，将面临包括计算需求、AI行为中的潜在偏差、隐私问题以及需要监管框架等挑战。同时，计算机科学家、伦理学家、社会学家和政策制定者之间将需要持续的多学科合作，以指导这些先进AI系统的发展。
- en: The evolution of LLM decision-making is an exciting and active area of AI research,
    with many promising directions and techniques under exploration. The future of
    LLMs is likely to see models that are not only more powerful in terms of raw computational
    ability but also more nuanced, ethical, and aligned with human needs and values.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: LLM决策的演变是人工智能研究中的一个令人兴奋且活跃的领域，许多有前景的方向和技术正在被探索。LLMs的未来很可能看到不仅原始计算能力更强，而且更加细腻、符合伦理，并与人类需求和价值观相一致的模型。
- en: Summary
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we focused on the decision-making process of LLMs, which utilize
    a complex interplay of probabilistic modeling and statistical analysis to interpret
    and generate language. LLMs, such as GPT-4, are trained on extensive datasets,
    allowing them to predict the likelihood of word sequences within a given context.
    The Transformer architecture plays a crucial role in this process, with its attention
    mechanisms assessing different input text elements to produce relevant output.
    We further explored the nuances of LLM training, emphasizing the importance of
    context and patterns learned from data to refine the models’ predictive capabilities.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们专注于LLMs的决策过程，这些过程利用概率建模和统计分析的复杂相互作用来解释和生成语言。LLMs，如GPT-4，在庞大的数据集上进行训练，使它们能够预测给定上下文中文本序列的可能性。Transformer架构在这个过程中发挥着关键作用，其注意力机制评估不同的输入文本元素以产生相关输出。我们进一步探讨了LLM训练的细微差别，强调了上下文和数据中学习到的模式对提高模型预测能力的重要性。
- en: By addressing the challenges LLMs face, we provided insight into issues such
    as bias, ambiguity, and the balancing act between overfitting and underfitting.
    We also touched on the ethical implications of AI-generated content and the continuous
    need for model fine-tuning to achieve more sophisticated language understanding.
    Looking ahead, we anticipate advancements in LLM decision-making, highlighting
    ongoing research in areas such as improved contextual understanding, continuous
    learning, and the integration of multimodal data. The evolution of LLMs is portrayed
    as a dynamic and collaborative field requiring both technical innovation and a
    strong consideration of ethical and societal impacts. At this point, you should
    have a comprehensive understanding of how the decision-making process is implemented
    in LLMs.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 通过解决LLMs面临的挑战，我们深入探讨了诸如偏差、歧义以及过拟合与欠拟合之间的平衡等问题。我们还触及了AI生成内容的伦理影响以及持续微调模型以实现更高级语言理解的必要性。展望未来，我们预计LLM决策将取得进展，强调在改进上下文理解、持续学习和多模态数据集成等领域的持续研究。LLMs的演变被描绘为一个动态且协作的领域，需要技术创新以及对伦理和社会影响的深入考虑。在此阶段，您应该对LLMs中决策过程的实施有一个全面的理解。
- en: In the next chapter, we’ll guide you through the mechanics of training LLMs,
    giving you a thorough grounding in creating effective LLMs.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将向您介绍训练LLMs的机制，为您在创建有效的LLMs方面提供全面的基础。
- en: 'Part 2: Mastering LLM Development'
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二部分：掌握LLM开发
- en: In this part, you will learn about data, how to set up your training environment,
    hyperparameter tuning, and challenges in training LLMs. You will also learn about
    advanced training strategies, which entail transfer learning and fine-tuning,
    as well as curriculum learning, multitasking, and continual learning models. Instruction
    on fine-tuning LLMs for specific applications is also included; here, you will
    learn about the needs of NLP applications, tailoring LLMs for chatbots and conversational
    agents, customizing models for language translation, and fine-tuning for nuanced
    understanding. Finally, we will focus on testing and evaluation, which includes
    learning about metrics for measuring LLM performance, how to set up rigorous testing
    protocols, human-in-the-loop instances, ethical considerations, and bias mitigation.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分，你将了解数据、如何设置你的训练环境、超参数调整以及训练LLM的挑战。你还将学习高级训练策略，包括迁移学习与微调、课程学习、多任务学习和持续学习模型。还包括针对特定应用微调LLM的指导；在这里，你将了解NLP应用的需求，为聊天机器人和对话代理定制LLM，为语言翻译定制模型以及进行细微理解的微调。最后，我们将关注测试和评估，这包括了解衡量LLM性能的指标、如何设置严格的测试协议、闭环人类实例、伦理考量以及偏见缓解。
- en: 'This part contains the following chapters:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 3*](B21242_03.xhtml#_idTextAnchor058) , *The Mechanics of Training
    LLMs*'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第三章*](B21242_03.xhtml#_idTextAnchor058) ，*训练LLM的机制*'
- en: '[*Chapter 4*](B21242_04.xhtml#_idTextAnchor078) , *Advanced Training Strategies*'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第四章*](B21242_04.xhtml#_idTextAnchor078) ，*高级训练策略*'
- en: '[*Chapter 5*](B21242_05.xhtml#_idTextAnchor101) , *Fine-Tuning LLMs for Specific
    Applications*'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第五章*](B21242_05.xhtml#_idTextAnchor101) ，*针对特定应用的LLM微调*'
- en: '[*Chapter 6*](B21242_06.xhtml#_idTextAnchor140) , *Testing and Evaluating LLMs*'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第六章*](B21242_06.xhtml#_idTextAnchor140) ，*测试和评估LLM*'
