- en: The History of AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能的历史
- en: The term **Artificial Intelligence** (**AI**) carries a great deal of weight.
    AI has benefited from over 70 years of research and development. The history of
    AI is varied and winding, but one ground truth remains – tireless researchers
    have worked through funding growths and lapses, promise and doubt, to push us
    toward achieving ever more realistic AI.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能**（**AI**）这个术语承载着沉重的分量。人工智能已经受益于超过70年的研究与发展。人工智能的历史丰富而曲折，但有一个不变的事实——不知疲倦的研究人员通过资金的增长与波动、承诺与疑虑，推动着我们实现越来越现实的人工智能。'
- en: 'Before we begin, let''s weed through the buzzwords and marketing and establish
    what AI really is. For the purposes of this book, we will rely on this definition:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们先剔除流行词汇和营销术语，明确人工智能的真正含义。为了本书的目的，我们将依赖以下定义：
- en: '*AI is a system or algorithm that allows computers to perform tasks without
    explicitly being programmed to do so.*'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能是一个系统或算法，使计算机能够执行任务，而无需明确编程。*'
- en: AI is an interdisciplinary field. While we'll focus largely on utilizing deep
    learning in this book, the field also encompasses elements of robotics and IoT,
    and has a strong overlap (if it hasn't consumed it yet) with generalized natural
    language processing research. It's also intrinsically linked with fields such
    as **Human**-**Computer Interaction** (**HCI**) as it becomes increasingly important
    to integrate AI with our lives and the modern world around us.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能是一个跨学科的领域。虽然本书主要聚焦于深度学习的应用，但这一领域还涵盖了机器人学和物联网的元素，并且与广义自然语言处理研究有着紧密的重叠（如果它还没有完全吞并的话）。它还与**人机交互**（**HCI**）等领域密切相关，因为将人工智能融入我们的生活和现代世界变得越来越重要。
- en: AI goes through waves, and is bound to go through another (perhaps smaller)
    wave in the future. Each time, we push the limits of AI with the computational
    power that is available to us, and research and development stops. This day and
    age may be different, as we benefit from the confluence of increasingly large
    and efficient data stores, rapid fast and cheap computing power, and the funding
    of some of the most profitable companies in the world. To understand how we ended
    up here, let's start at the beginning.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能经历了几波浪潮，未来还会经历另一波（可能规模较小）。每次，我们都通过可用的计算能力推动人工智能的极限，而研究与开发会停滞不前。这个时代可能有所不同，因为我们受益于日益庞大且高效的数据存储、快速、廉价的计算能力以及一些世界上最赚钱的公司的资金支持。为了理解我们是如何走到今天这一步的，让我们从头开始。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: The beginnings of AI – 1950–1974
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能的起源 – 1950–1974
- en: Rebirth – 1980–1987
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重生 – 1980–1987
- en: The modern era takes hold – 1997–2005
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代时代的到来 – 1997–2005
- en: Deep learning and the future – 2012–Present
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习与未来 – 2012年至今
- en: The beginnings of AI –1950–1974
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能的起源 – 1950–1974
- en: Since some of the earliest mathematicians and thinkers, AI has been a long sought
    after concept. The ancient Greeks developed myths of the *automata*, a form of
    robot that would complete tasks for the Gods that they considered menial, and
    throughout early history thinkers pondered what it meant to human, and if the
    notion of human intelligence could be replicated. While it's impossible to pinpoint
    an exact beginning for AI as a field of research, its development parallels the
    early advances of computer science. One could argue that computer science as a
    field developed out of this early desire to create self-thinking machines.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 自最早的数学家和思想家开始，人工智能就是一个被长期追寻的概念。古希腊人创造了*自动机*的神话，一种机器人形式，负责完成他们认为琐碎的任务，而在历史的早期，思想家们思考着什么是人类，并且是否能够复制人类智能。虽然很难准确确定人工智能作为一门研究领域的起点，但它的发展与计算机科学的早期进展是相似的。可以说，计算机科学作为一门学科，正是源于这种早期的愿望，即创造能自我思考的机器。
- en: During the second world war, British mathematician and code breaker Alan Turing
    developed ...
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二次世界大战期间，英国数学家和密码破译专家艾伦·图灵开发了...
- en: Rebirth –1980–1987
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重生 – 1980–1987
- en: The 1980s saw the birth of deep learning, the brain of AI that has become the
    focus of most modern AI research. With the revival of neural network research
    by John Hopfield and David Rumelhart, and several funding initiatives in Japan,
    the United States, and the United Kingdom, AI research was back on track.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 1980年代，深度学习的诞生标志着人工智能的“大脑”，成为现代人工智能研究的焦点。随着约翰·霍普菲尔德和大卫·鲁梅尔哈特对神经网络研究的复兴，以及日本、美国和英国的多项资助计划，人工智能研究重新回到了正轨。
- en: In the early 1980s, while the United States was still toiling from the effects
    of the AI Winter, Japan was funding the fifth generation computer system project
    to advance AI research. In the US, DARPA once again ramped up funding for AI research,
    with business regaining interest in AI applications. IBM's T.J. Watson Research
    Center published a statistical approach to language translation ([https://aclanthology.info/pdf/J/J90/J90-2002.pdf](https://aclanthology.info/pdf/J/J90/J90-2002.pdf)),
    which replaced traditional rule-based NLP models with probabilistic models, the shepherding
    in the modern era of NLP.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 1980年代初，美国仍在忍受人工智能冬天的影响时，日本却资助了第五代计算机系统项目，旨在推动人工智能研究。在美国，国防高级研究计划局（DARPA）再次增加了对人工智能研究的资助，商业界也重新对人工智能应用产生了兴趣。IBM的T.J.沃森研究中心发布了语言翻译的统计方法（[https://aclanthology.info/pdf/J/J90/J90-2002.pdf](https://aclanthology.info/pdf/J/J90/J90-2002.pdf)），该方法用概率模型取代了传统的基于规则的自然语言处理模型，开创了现代自然语言处理（NLP）的时代。
- en: Hinton, the student from the University of Cambridge who persisted in his research,
    would make a name for himself by coining the term **deep learning**. He joined
    forces with Rumelhart to become one of the first researchers to introduce the
    backpropagation algorithm for training ANNs, which is the backbone of all of modern
    deep learning. Hinton, like many others before him, was limited by computational
    power, and it would take another 26 years before the weight of his discovery was
    really felt.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 来自剑桥大学的学生辛顿（Hinton）坚持自己的研究，最终通过创造**深度学习**这一术语成名。他与鲁梅哈特（Rumelhart）合作，成为首批引入反向传播算法用于训练人工神经网络（ANNs）的研究人员之一，这一算法是现代深度学习的基础。与许多早期的研究者一样，辛顿也受到计算能力的限制，直到26年后，他的发现才真正产生深远影响。
- en: By the late 1980s, the personal computing revolution and missed expectations
    threatened the field. Commercial development all but came to a halt, as mainframe
    computer manufacturers stopped producing hardware that could handle AI-oriented
    languages, and AI-oriented mainframe manufacturers went bankrupt. It had seemed
    as if all had come to a standstill.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 到1980年代末期，个人计算革命与未达成的预期威胁着人工智能领域。商业化发展几乎停滞，主机计算机制造商停止生产能够处理人工智能相关语言的硬件，而面向人工智能的主机计算机制造商也纷纷破产。似乎一切都陷入了停滞。
- en: The modern era takes hold – 1997-2005
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现代时代的到来——1997-2005年
- en: AI further entered the public discourse in 1997 when IBM's Deep Blue system
    beat world champion chess grandmaster Garry Kasparov. Within a year, a former
    student of Geoffrey Hinton's, Yann LeCun, developed the Convolutional Neural Network
    at Bell Labs, which was enabled by the backpropagation algorithm and years of
    research into computer vision tasks. Hochreiter and Schmidhuber invented the first
    memory unit, the **long short**-**term memory unit** (**LSTM**), which is still
    used today for sequence modeling.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 1997年，IBM的深蓝系统（Deep Blue）战胜了世界象棋冠军加里·卡斯帕罗夫（Garry Kasparov），人工智能再次进入了公众视野。不到一年后，辛顿的前学生扬·勒昆（Yann
    LeCun）在贝尔实验室（Bell Labs）开发了卷积神经网络（CNN），这一技术得益于反向传播算法和多年在计算机视觉任务上的研究。霍赫雷特（Hochreiter）和施密杜贝尔（Schmidhuber）发明了首个记忆单元——**长短期记忆单元**（**LSTM**），至今仍广泛用于序列建模。
- en: ANNs still had a way to go. Computing and storage limitations prevented these
    networks from scaling, and other methods such as **support vector machines** (**SVMs**)
    were developed as alternatives.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络（ANNs）仍然面临许多挑战。计算和存储的限制使得这些网络无法扩展，而**支持向量机**（**SVMs**）等其他方法应运而生，成为替代方案。
- en: Deep learning and the future – 2012-Present
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习与未来——2012年至今
- en: AI has made further strides in the past several years than in the 60-odd years
    since its birth. Its popularity has further been fueled by the increasingly public
    nature of its benefits – self-driving cars, personal assistants, and its ever-ubiquitous
    use in social media and advertising. For most of its history, AI was a field with
    little interaction with the average populace, but now it's come to the forefront
    of international discourse.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几年里，人工智能取得的进展超过了自其诞生以来60多年的所有发展。人工智能的普及得到了其日益显现的公共利益的进一步推动——自动驾驶汽车、个人助手，以及在社交媒体和广告中无处不在的应用。在大多数历史时期，人工智能是一个与普通大众几乎没有互动的领域，但现在它已经成为国际讨论的前沿话题。
- en: 'Today''s age of AI has been the result of three trends:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 今天的人工智能时代是三大趋势的结果：
- en: The increasing amount of data and computing power available to AI researchers
    and practitioners
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能研究人员和从业者可以获得的数据量和计算能力不断增加
- en: Ongoing research by Geoffrey Hinton and his lab at the University of Toronto
    into deep neural networks
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乔弗里·辛顿（Geoffrey Hinton）及其多伦多大学实验室正在进行关于深度神经网络的持续研究
- en: Increasingly public applications of AI that have driven adoption and further
    acceptance into mainstream technology culture
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能的日益普及的公共应用推动了人工智能的采纳并进一步融入主流技术文化
- en: Today, companies, governments, and other organizations have benefited from the
    big data revolution of the mid 2000s, which has brought us a plethora of data
    stores. At last, AI applications have the requisite data to train. Computational
    power is cheap and only getting cheaper.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，公司、政府和其他组织已经从2000年代中期的大数据革命中受益，这一革命带来了大量的数据存储。最终，人工智能应用拥有了所需的数据进行训练。计算能力变得廉价，并且只会变得更加便宜。
- en: On the research front, in 2012, Hinton and two of his students were finally
    able to show that deep neural networks were able to outperform all other methods
    in image recognition in the large-scale visual recognition challenge. The modern
    era of AI was born.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究方面，2012年，Hinton和他的两名学生终于证明了深度神经网络能够在大规模视觉识别挑战中超越所有其他方法，成为人工智能现代时代的起点。
- en: Interestingly enough, Hinton's team's work on computer vision also introduced
    the idea of utilizing **Graphics Processing Units** (**GPUs**) to train deep networks.
    It also introduced dropout and ReLu, which have become cornerstones of deep learning.
    We'll discuss these in the coming chapters. Today, Hinton is the most cited AI
    researcher on the planet. He is a lead data scientist at Google Brain and has
    been tied to many major developments in AI in the modern era.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，Hinton团队在计算机视觉方面的工作也引入了利用**图形处理单元**（**GPUs**）来训练深度网络的想法。它还引入了dropout和ReLu，这些已经成为深度学习的基石。我们将在接下来的章节中讨论这些内容。今天，Hinton是全球引用次数最多的人工智能研究员。他是谷歌大脑的首席数据科学家，并且与现代人工智能的许多重大进展息息相关。
- en: 'AI was further thrown into the public sphere when, in 2011, IBM Watson defeated
    the world Jeopardy champions, and in 2016 Google''s AlphaGo defeated the world
    grand champion at one of the most challenging games known to man: Go.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能在2011年IBM Watson击败世界“危险边缘”冠军，以及2016年谷歌的AlphaGo击败世界围棋冠军之后，进一步进入了公众视野。
- en: Today, we are closer than ever to having machines that can pass the Turing test.
    Networks are able to generate ever more realistic sounding imitations of speeches,
    images, and writing. Reinforcement learning methods and Ian Goodfellow's GANs
    have made incredible strides. Recently, there has been emerging research that
    is working to demystify the inner workings of deep neural networks. As the field
    progresses, however, we should all be mindful of overpromising. For most of its
    history, companies have often overpromised regarding what AI can do, and in turn,
    we've seen a consistent disappointment in its abilities. Focusing the abilities
    of AI on only certain applications, and continuing to view research in the field
    from a biological perspective, will only hurt its advancement going forward. In
    this book, however, we'll see that today's practical applications are directed
    and realistic, and that the field is making more strides toward true AI than ever
    before.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，我们比以往任何时候都更接近拥有能够通过图灵测试的机器。神经网络能够生成越来越真实的演讲、图像和写作模仿。强化学习方法和Ian Goodfellow的生成对抗网络（GANs）已经取得了令人难以置信的进展。最近，关于揭示深度神经网络内部工作原理的研究也在不断涌现。然而，随着这一领域的进展，我们也应当谨慎对待过度承诺。纵观人工智能历史，企业往往对人工智能的能力做出过高的承诺，结果我们经常看到能力上的持续失望。将人工智能的能力仅限于某些应用，并继续从生物学的角度来看待这一领域的研究，反而会阻碍其未来的发展。然而，在本书中，我们将看到今天的实际应用是有方向且现实的，人工智能领域正比以往任何时候都更接近实现真正的人工智能。
- en: Summary
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Since its beginnings in the 1940s and 1950s, AI has made great bounds. Many
    of the technologies and ideas that we are utilizing today are directly based on
    these early discoveries. Over the course of the latter half of the 20th century,
    pioneers such as Geoffrey Hinton have pushed AI forward through peaks and busts.
    Today, we are on track to achieve sustained AI development for the foreseeable
    future.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 自20世纪40年代和50年代起，人工智能取得了巨大的进展。我们今天所使用的许多技术和思想直接基于这些早期的发现。在20世纪后半叶，像Geoffrey Hinton这样的先驱者通过高潮与低谷推动了人工智能的发展。今天，我们正朝着实现持续的人工智能发展迈进，且前景可期。
- en: The development of AI technology has been closely aligned with the development
    of new hardware and increasingly large data sources. As we'll see throughout this
    book, great AI applications are built with data constraints and hardware optimization
    in mind. The next chapter will introduce you to the fundamentals of machine learning
    and ...
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能技术的发展与新硬件的进步以及越来越庞大的数据源密切相关。正如本书中所述，优秀的人工智能应用都是在考虑数据限制和硬件优化的基础上构建的。下一章将向您介绍机器学习的基本原理和……
