- en: Transfer Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习
- en: 'In this chapter, we will discuss the concept of Transfer Learning. The following
    are the topics that will be covered:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论迁移学习的概念。以下是将要涵盖的主题：
- en: Illustrating the use of a pretrained model
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 演示如何使用预训练模型
- en: Setting up the Transfer Learning model
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置迁移学习模型
- en: Building an image classification model
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建图像分类模型
- en: Training a deep learning model on a GPU
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GPU上训练深度学习模型
- en: Comparing performance using CPU and GPU
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较使用CPU和GPU的性能
- en: Introduction
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: A lot of development has happened within the deep learning domain in recent
    years, to enhance algorithmic efficacy and computational efficiency across different
    domains such as text, images, audio, and video. However, when it comes to training
    on new datasets, machine learning usually rebuilds the model from scratch, as
    is done in traditional data science problem solving. This becomes challenging
    when a new big dataset need to be trained as it will require very high computation
    power a lot of and time to reach the desired model efficacy.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，深度学习领域发生了许多发展，提升了算法的有效性和计算效率，涵盖了文本、图像、音频和视频等不同领域。然而，当涉及到在新数据集上进行训练时，机器学习通常会从零开始重建模型，就像在传统数据科学问题解决中所做的一样。当需要训练一个新的大数据集时，这会变得很具挑战性，因为它需要非常高的计算能力和大量时间才能达到预期的模型效果。
- en: Transfer Learning is a mechanism to learn new scenarios from existing models.
    This approach is very useful to train on big datasets, not necessarily from a
    similar domain or problem statement. For example, researchers have shown examples
    of Transfer Learning where they have trained Transfer Learning for completely
    different problem scenarios, such as when a model built using classifications
    of cat and dog is used for classifying objects such as aeroplane vs automobile.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是一种从现有模型中学习新场景的机制。这种方法对于在大数据集上训练非常有用，不一定来自相似的领域或问题描述。例如，研究人员展示了迁移学习的例子，其中他们在完全不同的问题场景下进行了迁移学习训练，例如使用分类猫和狗的模型来分类物体，如飞机与汽车。
- en: 'In terms of analogy, it''s more about passing the learned relationship to new
    architecture in order to fine-tune weights. An example of how Transfer Learning
    is used is shown in the following figure:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 从类比的角度来看，它更多的是将已学到的关系传递到新的架构中，以便微调权重。以下图示展示了迁移学习的应用示例：
- en: '![](img/00020.jpeg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00020.jpeg)'
- en: Illustration of Transfer Learning flow
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习流程示意图
- en: The figure shows the steps of Transfer Learning, where the weights/architectures
    from a predeveloped deep learning model are reused to predict a new problem statement.
    Transfer Learning helps provide a good starting point for deep learning architectures.
    There are different open source projects going on in different domains, which
    facilitate Transfer Learning, for example, ImageNet ([http://image-net.org/index](http://image-net.org/index))
    is an open source project for image classification where a lot of different architectures
    such as Alexnet, VGG16, and VGG19 have been developed. Similarly, in text mining,
    there is a Word2Vec representation of Google News trained using three billion
    running words.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图示展示了迁移学习的步骤，其中一个预先开发的深度学习模型的权重/架构被重用以预测一个新的问题。迁移学习有助于为深度学习架构提供一个良好的起点。不同领域的多个开源项目正在进行中，促进了迁移学习的应用，例如，ImageNet
    ([http://image-net.org/index](http://image-net.org/index))是一个用于图像分类的开源项目，许多不同的架构，如Alexnet、VGG16和VGG19，已经在该项目中得到了开发。同样，在文本挖掘领域，Google
    News的Word2Vec表示法已经通过三十亿个单词训练完成。
- en: Details on word2vec can be found at [https://code.google.com/archive/p/word2vec/.](https://code.google.com/archive/p/word2vec/)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有关word2vec的详细信息，请参见[https://code.google.com/archive/p/word2vec/.](https://code.google.com/archive/p/word2vec/)
- en: Illustrating the use of a pretrained model
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 演示如何使用预训练模型
- en: The current recipe will cover the set-up for using a pretrained model. We will
    use TensorFlow to demonstrate the recipe. The current recipe will use VGG16 architecture
    built using the ImageNet as dataset. The ImageNet is an open source image repository
    of images used for building image recognition algorithms. The database has more
    than 10 millions tagged images and more than 1 million images have bounding box
    to capture objects.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的配方将涵盖使用预训练模型的设置。我们将使用TensorFlow来演示该配方。当前的配方将使用基于ImageNet数据集构建的VGG16架构。ImageNet是一个开源图像库，旨在构建图像识别算法。该数据库拥有超过1000万张标记图像，且超过100万张图像包含了捕获物体的边界框。
- en: Lot of different deep learning architectures are developed using ImageNet dataset.
    Once of the popular one is VGG networks are convolution neural networks proposed
    by Zisserman and Simonyan (2014) and trained over ImageNet data with 1,000 classes.
    The current recipe will consider VGG16 variant of VGG architecture which is known
    for it's simplicity. The network uses input of 224 x 224 RGB image. The network
    utilizes 13 convolution layers with different width x height x depth. The maximum
    pooling layer is used to reduce volume size. The network uses 5 maxpooling layer.
    The output from convolution layer is passed through 3 fully connected layer. Outcome
    from fully connected layer go through softmax function to evaluate probability
    of 1000 classes.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ImageNet 数据集开发了许多不同的深度学习架构。一个受欢迎的架构是 VGG 网络，它是由 Zisserman 和 Simonyan（2014）提出的卷积神经网络，并在包含
    1,000 个类别的 ImageNet 数据集上进行训练。当前的方案将考虑 VGG 架构的 VGG16 变种，它因其简洁性而著名。该网络使用 224 x 224
    RGB 图像作为输入。网络使用了 13 个卷积层，具有不同的宽度 x 高度 x 深度。最大池化层用于减小卷积层输出的体积大小。该网络使用了 5 个最大池化层。卷积层的输出通过
    3 个全连接层。全连接层的输出通过 softmax 函数来评估 1,000 类的概率。
- en: 'The detailed architecture of VGG16 is shown in the following figure:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: VGG16 的详细架构如下图所示：
- en: '![](img/00122.jpeg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00122.jpeg)'
- en: VGG16 architecture
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: VGG16 架构
- en: Getting ready
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: The section covers required to use VGG16 pretrained model for classification.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分介绍了使用 VGG16 预训练模型进行分类所需的步骤。
- en: 'Download VGG16 weights from [http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz](http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz).
    The file can be downloaded using the following script:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz](http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz)
    下载 VGG16 权重文件。可以使用以下脚本下载文件：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Install TensorFlow in Python.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Python 中安装 TensorFlow。
- en: Install R and the `tensorflow` package in R.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 R 中安装 R 和 `tensorflow` 包。
- en: Download a sample image from [http://image-net.org/download-imageurls](http://image-net.org/download-imageurls).
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 [http://image-net.org/download-imageurls](http://image-net.org/download-imageurls)
    下载示例图像。
- en: How to do it...
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The current section provides steps to use pretrained models:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当前部分提供使用预训练模型的步骤：
- en: 'Load `tensorflow` in R:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 R 中加载 `tensorflow`：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Assign the `slim` library from TensorFlow:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 TensorFlow 中导入 `slim` 库：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `slim` library in TensorFlow is used to maintain complex neural network
    models in terms of definition, training, and evaluation.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 中的 `slim` 库用于维护复杂的神经网络模型，涵盖定义、训练和评估等方面。
- en: 'Reset graph in TensorFlow:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中重置图：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Define input images:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义输入图像：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Redefine the VGG16 network:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新定义 VGG16 网络：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding function defines the network architecture used for the VGG16
    network. The network can be assigned using the following script:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上面的函数定义了用于 VGG16 网络的网络架构。可以使用以下脚本来定义网络：
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Load the VGG16 weights `vgg_16_2016_08_28.tar.gz` downloaded in the *Getting
    started* section:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载 *入门指南* 部分中下载的 VGG16 权重 `vgg_16_2016_08_28.tar.gz`：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Download a sample test image. Let''s download an example image from a `testImgURL`
    location as shown in following script:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载示例测试图像。让我们根据以下脚本从 `testImgURL` 位置下载一个示例图像：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The preceding script downloads the following image from URL mention in variable
    `testImgURL`. The following is the downloaded image:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的脚本从变量 `testImgURL` 中提到的 URL 下载以下图片。以下是下载的图片：
- en: '![](img/00128.jpeg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00128.jpeg)'
- en: Sample image used to evaluate imagenet
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 用于评估 imagenet 的示例图像
- en: 'Determine the class using the VGG16 pretrained model:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 VGG16 预训练模型确定类别：
- en: '[PRE9]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The maximum probability achieved is 0.62 for class 672, which refers to the
    category--mountain bike, all-terrain bike, off-roader--in the VGG16 trained dataset.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 所达到的最大概率为 0.62，属于类别 672，该类别在 VGG16 训练数据集中对应的标签是——山地自行车，全地形自行车，越野车。
- en: Setting up the Transfer Learning model
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置迁移学习模型
- en: The current recipe will cover Transfer Learning using the CIFAR-10 dataset.
    The previous recipe presented how to use a pretrained model. The current recipe
    will demonstrate how to use a pretrained model for different problem statements.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当前方案将涵盖使用 CIFAR-10 数据集进行迁移学习。上一方案介绍了如何使用预训练模型。当前方案将展示如何将预训练模型应用于不同的问题陈述。
- en: 'We will use another very good deep learning package, MXNET, to demonstrate
    the concept with another architecture, Inception. To simplify the computation,
    we will reduce the problem complexity from 10 classes to two classes: aeroplane
    and automobile. The recipe focuses on data preparation for Transfer Learning using
    Inception-BN.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用另一个非常好的深度学习包，MXNET，通过另一种架构Inception来演示该概念。为了简化计算，我们将问题的复杂度从10个类别减少到两个类别：飞机和汽车。这个食谱的重点是使用Inception-BN进行迁移学习的数据准备。
- en: Getting ready
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 做好准备
- en: The section prepares for the upcoming section for setting-up Transfer Learning
    model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 本节为即将到来的迁移学习模型设置部分做准备。
- en: Download the CIFAR-10 dataset from [http://www.cs.toronto.edu/~kriz/cifar.html](http://www.cs.toronto.edu/~kriz/cifar.html).
    The `download.cifar.data` function from [Chapter 3](part0093.html#2OM4A1-a0a93989f17f4d6cb68b8cfd331bc5ab),
    *Convolution Neural Networks,* can be used to download the dataset.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[http://www.cs.toronto.edu/~kriz/cifar.html](http://www.cs.toronto.edu/~kriz/cifar.html)下载CIFAR-10数据集。可以使用[第3章](part0093.html#2OM4A1-a0a93989f17f4d6cb68b8cfd331bc5ab)中的`download.cifar.data`函数来下载数据集，*卷积神经网络*章节。
- en: 'Install the `imager` package:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装`imager`包：
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: How to do it...
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: The current part of the recipe will provide a step-by-step guide to prepare
    the dataset for the Inception-BN pretrained model.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分食谱将提供一步步的指南，准备数据集以用于Inception-BN预训练模型。
- en: 'Load the dependent packages:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载依赖包：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Read the downloaded CIFAR-10 dataset:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取下载的CIFAR-10数据集：
- en: '[PRE12]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Filter the dataset for aeroplane and automobile. This is an optional step and
    is done to reduce complexity later:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过滤数据集中的飞机和汽车。这是一个可选步骤，用于简化后续的复杂度：
- en: '[PRE13]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Transform to image. This step is required as the CIFAR-10 dataset is a 32 x
    32 x 3 image, which is flattened to a 1024 x 3 format:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换为图像。此步骤是必需的，因为CIFAR-10数据集是32 x 32 x 3的图像，需要将其展平为1024 x 3格式：
- en: '[PRE14]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The next step involve padding images with zeros:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是对图像进行零填充：
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Save the image to a specified folder:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像保存到指定文件夹：
- en: '[PRE16]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The preceding script saves the aeroplane images into the `aero` folder and the
    automobile images in the `auto` folder.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的脚本将把飞机图像保存到`aero`文件夹，将汽车图像保存到`auto`文件夹。
- en: 'Convert to the recording format `.rec` supported by MXNet. This conversion
    requires `im2rec.py` MXnet module from Python as conversion is not supported in
    R. However, it can be called from R once MXNet is installed in Python using the
    system command. The splitting of the dataset into train and test can be obtained
    using the following file:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换为MXNet支持的`.rec`记录格式。此转换需要Python中的`im2rec.py` MXNet模块，因为R不支持此转换。不过，一旦在Python中安装了MXNet，可以通过系统命令从R调用。数据集的划分可以使用以下文件：
- en: '[PRE17]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The preceding script will generate two list files: `pks.lst_train.lst` and
    `pks.lst_train.lst`. The splitting of train and validation is controlled by the
    `-train-ratio` parameter in the preceding script. The number of classes is based
    on the number of folders in the `trainf` directory. In this scenario, two classes
    are picked: automotive and aeroplane.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的脚本将生成两个列表文件：`pks.lst_train.lst`和`pks.lst_train.lst`。训练和验证的划分由前面脚本中的`-train-ratio`参数控制。类别的数量基于`trainf`目录中的文件夹数量。在这个场景中，选择了两个类别：汽车和飞机。
- en: 'Convert the `*.rec` file for training and validation dataset:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换用于训练和验证的数据集的`*.rec`文件：
- en: '[PRE18]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The preceding script will create the `pks.lst_train.rec` and `pks.lst_val.rec`
    files to be used in the next recipe to train the model using a pretrained model.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的脚本将创建`pks.lst_train.rec`和`pks.lst_val.rec`文件，这些文件将在下一个食谱中用于使用预训练模型训练模型。
- en: Building an image classification model
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建图像分类模型
- en: The recipe focuses on building an image classification model using Transfer
    Learning. It will utilize the dataset prepared in the previous recipes and use
    the Inception-BN architecture. The BN in Inception-BN stands for **batch normalization**.
    Details of the Inception model in computer vision can be found in Szegedy et al.
    (2015).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这个食谱的重点是使用迁移学习构建图像分类模型。它将利用前面食谱中准备的数据集，并使用Inception-BN架构。Inception-BN中的BN代表**批量归一化**。有关计算机视觉中Inception模型的详细信息，可以参考Szegedy等人（2015年）的论文。
- en: Getting ready
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 做好准备
- en: The section cover's the prerequisite to set-up a classification model using
    INCEPTION-BN pretrained model.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 本节内容涵盖了使用INCEPTION-BN预训练模型设置分类模型的前提条件。
- en: Convert images into `.rec` file for train and validation.
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像转换为用于训练和验证的`.rec`文件。
- en: Download the Inception-BN architecture from [http://data.dmlc.ml/models/imagenet/inception-bn/.](http://data.dmlc.ml/models/imagenet/inception-bn/)
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[http://data.dmlc.ml/models/imagenet/inception-bn/.](http://data.dmlc.ml/models/imagenet/inception-bn/)下载Inception-BN架构。
- en: Install R and the `mxnet` package in R.
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装R和R中的`mxnet`包。
- en: How to do it...
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Load the `.rec` file as iterators. The following is the function to load the
    `.rec` data as iterators:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`.rec`文件加载为迭代器。以下是将`.rec`数据作为迭代器加载的函数：
- en: '[PRE19]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: In the preceding function, `mx.io.ImageRecordIter` reads batches of images from
    the `RecordIO` (`.rec`) files*.*
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的函数中，`mx.io.ImageRecordIter`从`RecordIO`（`.rec`）文件中读取图像批次。
- en: 'Load data using the `data.iterator` function:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`data.iterator`函数加载数据：
- en: '[PRE20]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Load the Inception-BN pretrained model from the `Inception-BN` folder:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`Inception-BN`文件夹加载Inception-BN预训练模型：
- en: '[PRE21]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Get the layers of the Inception-BN model:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取Inception-BN模型的层：
- en: '[PRE22]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Define a new layer to replace the `flatten_output` layer:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个新的层来替换`flatten_output`层：
- en: '[PRE23]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Initialize weights for the newly defined layer. To retrain the last layer,
    weight initialization is performed using the following script:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为新定义的层初始化权重。为了重新训练最后一层，可以使用以下脚本进行权重初始化：
- en: '[PRE24]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the aforementioned layer, weights are assigned using uniform distribution
    between [*-0.2*, *0.2*]. The `ctx` define the device on which the execution is
    to be performed.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述层中，权重是通过在[*-0.2*，*0.2*]区间内使用均匀分布进行赋值的。`ctx`定义了执行操作的设备。
- en: 'Retrain the model:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新训练模型：
- en: '[PRE25]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The preceding model is set to run on CPU with five rounds, using accuracy as
    the evaluation metric. The following screenshot shows the execution of the described
    model:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 上述模型设置为在CPU上运行五轮，并使用准确度作为评估指标。以下截图显示了所描述模型的执行情况：
- en: '![](img/00134.jpeg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00134.jpeg)'
- en: Output from Inception-BN model, trained using CIFAR-10 dataset
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 从使用CIFAR-10数据集训练的Inception-BN模型输出：
- en: The trained model has produced a training accuracy of 0.97 and a validation
    accuracy of 0.95.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 训练后的模型产生了0.97的训练准确度和0.95的验证准确度。
- en: Training a deep learning model on a GPU
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在GPU上训练深度学习模型
- en: The **Graphical processing unit** (**GPU**) is hardware used for rendering images
    using a lot of cores. Pascal is the latest GPU micro architecture released by
    NVIDIA. The presence of hundreds of cores in GPU helps enhance the computation.
    This section provides the recipe for running a deep learning model using GPU.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**图形处理单元**（**GPU**）是用于使用大量核心进行图像渲染的硬件。Pascal是NVIDIA发布的最新GPU微架构。GPU中数百个核心的存在有助于提高计算效率。本节提供了使用GPU运行深度学习模型的配方。'
- en: Getting ready
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'This section provides dependencies required to run GPU and CPU:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了运行GPU和CPU所需的依赖项：
- en: The experiment performed in this recipe uses GPU hardware such as GTX 1070.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本实验使用了GTX 1070等GPU硬件。
- en: 'Install `mxnet` for GPU. To install `mxnet` for GPU for a specified machine,
    follow the installation instruction from `mxnet.io`. Select the requirement as
    shown in the screenshot, and follow the instructions:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装适用于GPU的`mxnet`。要为指定机器安装适用于GPU的`mxnet`，请按照`mxnet.io`上的安装说明进行操作。根据截图选择相应的需求，并按照说明进行操作：
- en: '![](img/00097.jpeg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00097.jpeg)'
- en: Steps to get installation instruction for MXNet
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 获取MXNet安装说明的步骤
- en: How to do it...
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Here is how you train a deep learning model on a GPU:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何在GPU上训练深度学习模型：
- en: 'The Inception-BN-transferred learning recipe discussed in the previous section
    can be made to run on the GPU installed and the configured machine by changing
    the device settings as shown in the following script:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上节讨论的Inception-BN迁移学习配方可以通过更改设备设置使其在已安装GPU并配置好的机器上运行，脚本如下所示：
- en: '[PRE26]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In the aforementioned model, the device setting is changed from `mx.cpu` to
    `mx.gpu`. The CPU for five iteration tools takes ~2 hours of computational effort,
    whereas the same iteration is completed in ~15 min with GPU.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述模型中，设备设置从`mx.cpu`更改为`mx.gpu`。使用CPU进行五次迭代的计算大约需要2小时，而同样的迭代使用GPU大约需要15分钟即可完成。
- en: Comparing performance using CPU and GPU
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较使用CPU和GPU的性能
- en: One of the questions with device change is why so much improvement is observed
    when the device is switched from CPU to GPU. As the deep learning architecture
    involves a lot of matrix computations, GPUs help expedite these computations using
    a lot of parallel cores, which are usually used for image rendering.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 设备切换时的一个问题是，为什么从CPU切换到GPU时会观察到如此大的改进。由于深度学习架构涉及大量的矩阵计算，GPU利用大量并行核心加速这些计算，这些核心通常用于图像渲染。
- en: The power of GPU has been utilized by a lot of algorithms to accelerate the
    execution. The following recipe provides some benchmarks of matrix computation
    using the `gpuR` package. The `gpuR` package is a general-purpose package for
    GPU computing in R.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 许多算法已经利用GPU的强大计算能力加速执行。以下配方提供了使用`gpuR`包进行矩阵计算的一些基准。`gpuR`包是一个用于R中GPU计算的通用包。
- en: Getting ready
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 做好准备
- en: The section covers requirement to set-up a comparison between GPU Vs CPU.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了设置GPU与CPU比较所需的要求。
- en: Use GPU hardware installed such as GTX 1070.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用已安装的GPU硬件，如GTX 1070。
- en: CUDA toolkit installation using URL [https://developer.nvidia.com/cuda-downloads.](https://developer.nvidia.com/cuda-downloads)
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用URL [https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads)
    安装CUDA工具包。
- en: 'Install the `gpuR` package:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装`gpuR`包：
- en: '[PRE27]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Test `gpuR`:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试`gpuR`：
- en: '[PRE28]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: How to do it...
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Let''s get started by loading the packages:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从加载包开始：
- en: 'Load the package, and set the precision to `float` (by default, the GPU precision
    is set to a single digit):'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载包，并将精度设置为`float`（默认情况下，GPU的精度设置为单精度）：
- en: '[PRE29]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Matrix assignment to GPU:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将矩阵分配给GPU：
- en: '[PRE30]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The output of the preceding command will contain details of the object. An
    illustration is shown in the following script:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令的输出将包含对象的详细信息。以下脚本展示了一个示例：
- en: '[PRE31]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Let''s consider the evaluation of CPU vs GPU*.* As most of the deep learning
    will be using GPUs for matrix computation, the performance is evaluated by matrix
    multiplication using the following script:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们考虑一下CPU与GPU的评估。由于大多数深度学习将使用GPU进行矩阵计算，性能通过矩阵乘法使用以下脚本进行评估：
- en: '[PRE32]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The preceding script computes the matrix multiplication using CPU and GPU;
    the time is stored for different dimensions of the matrix. The output from the
    preceding script is shown in the following diagram:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 上述脚本使用CPU和GPU进行矩阵乘法计算；时间会记录在不同维度的矩阵中。上面脚本的输出结果如下图所示：
- en: '![](img/00043.jpeg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00043.jpeg)'
- en: Comparison between CPU and GPU
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: CPU与GPU的比较
- en: The graph shows that the computation effort required by CPUs increases exponentially
    with the CPU. Thus, GPUs help expedite it drastically.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图表显示，CPU所需的计算工作量随着CPU的增加呈指数增长。因此，GPU极大地加速了这一过程。
- en: There's more...
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: The GPUs are new arena in machine learning computing, and a lot of packages
    have been developed in R to access GPUs while keeping you in a familiar R environment
    such as `gputools` , `gmatrix` , and `gpuR`. The other algorithms are also developed
    and implemented while accessing GPUs to enhance their computational power such
    as `RPUSVM`, which implements SVM using GPUs. Thus, the topic requires a lot of
    creativity with some exploration to deploy algorithms while utilizes full capability
    of hardware.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: GPU是机器学习计算中的新领域，许多包已经在R中开发，以便在保持熟悉的R环境中访问GPU，例如`gputools`、`gmatrix`和`gpuR`。其他算法也已经开发并实现，通过访问GPU来增强其计算能力，例如`RPUSVM`，它使用GPU实现SVM。因此，这个主题需要大量的创造力和一些探索，以便在利用硬件的全部能力时部署算法。
- en: See also
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: To learn more on parallel computing using R, go through *Mastering Parallel
    Programming with R* by Simon R. Chapple et al*.* (2016).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多使用R进行并行计算的信息，请阅读Simon R. Chapple等人的《Mastering Parallel Programming with
    R》（2016年）。
