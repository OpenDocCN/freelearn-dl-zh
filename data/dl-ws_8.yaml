- en: Appendix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录
- en: 1\. Building Blocks of Deep Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 深度学习的构建模块
- en: 'Activity 1.01: Solving a Quadratic Equation Using an Optimizer'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 1.01：使用优化器求解二次方程
- en: Solution
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Let''s solve the following quadratic equation:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来解以下二次方程：
- en: '![Figure 1.29: Quadratic equation to be solved'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.29：需要解的二次方程'
- en: '](img/B15385_01_29.jpg)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15385_01_29.jpg)'
- en: 'Figure 1.29: Quadratic equation to be solved'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.29：需要解的二次方程
- en: We already know that the solution to this quadratic equation is `x=5`.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道，这个二次方程的解是 `x=5`。
- en: 'We can use an optimizer to solve this. For the optimizer, `x` is the variable
    and the cost function is the left-hand side expression, which is as follows:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用优化器来解决这个问题。对于优化器，`x` 是变量，代价函数是左侧表达式，如下所示：
- en: '![Figure 1.30: Left-hand side expression'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.30：左侧表达式'
- en: '](img/B15385_01_30.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15385_01_30.jpg)'
- en: 'Figure 1.30: Left-hand side expression'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.30：左侧表达式
- en: 'The optimizer will find the value of `x` for which the expression is the minimum
    – in this case, it is `0`. Please note that this will work only for quadratic
    equations that are perfect squares, such as in this case. The left-hand side expression
    is a perfect square that can be explained with the following equation:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 优化器将找到 `x` 的值，使得表达式最小——在这种情况下是 `0`。请注意，这仅适用于像这种完美平方的二次方程。左侧的表达式是一个完美的平方，可以通过以下方程来解释：
- en: '![Figure 1.31: Perfect square'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.31：完美的平方'
- en: '](img/B15385_01_31.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15385_01_31.jpg)'
- en: 'Figure 1.31: Perfect square'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.31：完美的平方
- en: 'Now, let''s look at the code for solving this:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下解决这个问题的代码：
- en: Open a new Jupyter Notebook and rename it *Activity 1.01*.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter Notebook 并将其重命名为 *Activity 1.01*。
- en: 'Import `tensorflow`:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `tensorflow`：
- en: '[PRE0]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Create the variable `x` and initialize it to 0.0:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建变量 `x` 并将其初始化为 0.0：
- en: '[PRE1]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Construct the `loss` function as a `lambda` function:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `loss` 函数构建为一个 `lambda` 函数：
- en: '[PRE2]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create an instance of an optimizer with a learning rate of `.01`:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个学习率为 `.01` 的优化器实例：
- en: '[PRE3]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Run the optimizer through 10,000 iterations. You can start with a smaller number
    such as 1,000 and keep increasing the number of iterations until you get the solution:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行优化器进行 10,000 次迭代。您可以从较小的数字开始，如 1,000，然后逐渐增加迭代次数，直到得到解：
- en: '[PRE4]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Print the value of `x`:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印 `x` 的值：
- en: '[PRE5]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The output is as follows:'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE6]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This is the solution to our quadratic equation. It may be noted that, irrespective
    of the number of iterations, you will never get a perfect 5.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们二次方程的解。需要注意的是，无论迭代次数多少，您永远不会得到一个完美的5。
- en: Note
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3gBTFGA](https://packt.live/3gBTFGA).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问这个特定部分的源代码，请参考 [https://packt.live/3gBTFGA](https://packt.live/3gBTFGA)。
- en: You can also run this example online at [https://packt.live/2Dqa2Id](https://packt.live/2Dqa2Id).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在线运行此示例，网址是 [https://packt.live/2Dqa2Id](https://packt.live/2Dqa2Id)。您必须执行整个
    Notebook 才能获得预期的结果。
- en: 2\. Neural Networks
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 神经网络
- en: 'Activity 2.01: Build a Multilayer Neural Network to Classify Sonar Signals'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 2.01：构建一个多层神经网络来分类声呐信号
- en: Solution
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Let''s see how the solution looks. Remember—this is one solution, but there
    could be many variations:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看解决方案是怎样的。记住——这是一个解，但可能会有许多变种：
- en: 'Import all the required libraries:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有需要的库：
- en: '[PRE7]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Load and examine the data:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载并检查数据：
- en: '[PRE8]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The output is:'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '![Figure 2.37: Contents of sonar.csv'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 2.37：sonar.csv 的内容'
- en: '](img/B15385_02_37.jpg)'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_02_37.jpg)'
- en: 'Figure 2.37: Contents of sonar.csv'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.37：sonar.csv 的内容
- en: Observe that there are 60 features, and the target has two values—Rock and Mine.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可以观察到，有60个特征，目标变量有两个值——Rock 和 Mine。
- en: This means that this is a binary classification problem. Let's prepare the data
    before we build the neural network.
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这意味着这是一个二元分类问题。让我们在构建神经网络之前先准备数据。
- en: 'Separate the features and the labels:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分离特征和标签：
- en: '[PRE9]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this code, `X_input` is selecting all the rows of all the columns except
    the `Class` column, and `Y_label` is just selecting the `Class` column.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这段代码中，`X_input`选择了所有列中的所有行，除了`Class`列，而`Y_label`仅选择了`Class`列。
- en: 'Labels are in text format. We need to encode them as numbers before we can
    use them with our model:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标签是文本格式的。我们需要将它们编码为数字，然后才能在模型中使用：
- en: '[PRE10]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `reshape` function at the end will convert the labels into matrix format,
    which is expected by the model.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后的 `reshape` 函数会将标签转换为矩阵格式，这是模型所期望的。
- en: 'Build the multilayer model with Keras:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Keras 构建多层模型：
- en: '[PRE11]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You can experiment with the number of layers and neurons, but the last layer
    can only have one neuron with a sigmoid activation function, since this is a binary
    classifier.
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以尝试调整层数和神经元数量，但最后一层只能有一个神经元，并使用sigmoid激活函数，因为这是一个二分类器。
- en: 'Set the training parameters:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置训练参数：
- en: '[PRE12]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Train the model:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型：
- en: '[PRE13]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The truncated output will be somewhat similar to the following:'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 截断的输出结果大致如下：
- en: '[PRE14]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s evaluate the trained model and examine its accuracy:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们评估训练好的模型并检查其准确性：
- en: '[PRE15]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output is as follows:'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE16]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As you can see, we have been able to successfully train a multilayer binary
    neural network and get 100% accuracy within 30 epochs.
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如你所见，我们成功训练了一个多层二分类神经网络，并在30个周期内达到了100%的准确率。
- en: Note
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/38EMoDi](https://packt.live/38EMoDi).
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问该部分的源代码，请参考[https://packt.live/38EMoDi](https://packt.live/38EMoDi)。
- en: You can also run this example online at [https://packt.live/2W2sygb](https://packt.live/2W2sygb).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你还可以在线运行这个示例，网址为[https://packt.live/2W2sygb](https://packt.live/2W2sygb)。你必须执行整个Notebook才能获得预期的结果。
- en: 3\. Image Classification with Convolutional Neural Networks (CNNs)
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 使用卷积神经网络（CNN）进行图像分类
- en: 'Activity 3.01: Building a Multiclass Classifier Based on the Fashion MNIST Dataset'
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动3.01：基于Fashion MNIST数据集构建多分类器
- en: Solution
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Open a new Jupyter Notebook.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的Jupyter Notebook。
- en: 'Import `tensorflow.keras.datasets.fashion_mnist`:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tensorflow.keras.datasets.fashion_mnist`导入：
- en: '[PRE17]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Load the Fashion MNIST dataset using `fashion_mnist.load_data()` and save the
    results to `(features_train, label_train), (features_test, label_test)`:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`fashion_mnist.load_data()`加载Fashion MNIST数据集，并将结果保存到`(features_train, label_train),
    (features_test, label_test)`：
- en: '[PRE18]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Print the shape of the training set:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印训练集的形状：
- en: '[PRE19]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output will be as follows:'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE20]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The training set is composed of `60000` images of size `28` by `28`. We will
    need to reshape it and add the channel dimension.
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练集包含`60000`张大小为`28`乘`28`的图像。我们需要对其进行重塑并添加通道维度。
- en: 'Print the shape of the testing set:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印测试集的形状：
- en: '[PRE21]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output will be as follows:'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE22]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The testing set is composed of `10000` images of size `28` by `28`. We will
    need to reshape it and add the channel dimension
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 测试集包含`10000`张大小为`28`乘`28`的图像。我们需要对其进行重塑并添加通道维度。
- en: 'Reshape the training and testing sets with the dimensions `(number_rows, 28,
    28, 1)`:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将训练集和测试集重塑为维度`(number_rows, 28, 28, 1)`：
- en: '[PRE23]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Create three variables called `batch_size`, `img_height`, and `img_width` that
    take the values `16`, `28`, and `28`, respectively:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建三个变量`batch_size`、`img_height`和`img_width`，分别赋值为`16`、`28`和`28`：
- en: '[PRE24]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Import `ImageDataGenerator` from `tensorflow.keras.preprocessing`:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tensorflow.keras.preprocessing`导入`ImageDataGenerator`：
- en: '[PRE25]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Create an `ImageDataGenerator` called `train_img_gen` with data augmentation:
    `rescale=1./255, rotation_range=40, width_shift_range=0.1, height_shift_range=0.1,
    shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode=''nearest''`:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`train_img_gen`的`ImageDataGenerator`，并进行数据增强：`rescale=1./255, rotation_range=40,
    width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,
    horizontal_flip=True, fill_mode='nearest'`：
- en: '[PRE26]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Create an `ImageDataGenerator` called `val_img_gen` with rescaling (by dividing
    by 255):'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`val_img_gen`的`ImageDataGenerator`，进行重缩放（除以255）：
- en: '[PRE27]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Create a data generator called `train_data_gen` using `.flow()` and specify
    the batch size, features, and labels from the training set:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`train_data_gen`的数据生成器，使用`.flow()`并指定批量大小、特征和来自训练集的标签：
- en: '[PRE28]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Create a data generator called `val_data_gen` using `.flow()` and specify the
    batch size, features, and labels from the testing set:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`val_data_gen`的数据生成器，使用`.flow()`并指定批量大小、特征和来自测试集的标签：
- en: '[PRE29]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Import `numpy` as `np`, `tensorflow` as `tf`, and `layers` from `tensorflow.keras`:'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`为`np`，导入`tensorflow`为`tf`，并从`tensorflow.keras`导入`layers`：
- en: '[PRE30]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Set `8` as the seed for `numpy` and `tensorflow` using `np.random_seed()` and
    `tf.random.set_seed()`:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`np.random_seed()`和`tf.random.set_seed()`将`8`设置为`numpy`和`tensorflow`的随机种子：
- en: '[PRE31]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Instantiate a `tf.keras.Sequential()` class into a variable called `model`
    with the following layers: A convolution layer with `64` kernels of shape `3`,
    `ReLU` as the activation function, and the necessary input dimensions; a max pooling
    layer; a convolution layer with `128` kernels of shape `3` and `ReLU` as the activation
    function; a max pooling layer; a flatten layer; a fully connected layer with `128`
    units and `ReLU` as the activation function; a fully connected layer with `10`
    units and `softmax` as the activation function.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `tf.keras.Sequential()` 类实例化为名为 `model` 的变量，具有以下层：具有形状为 `3` 的 `64` 个核的卷积层，`ReLU`
    作为激活函数和必要的输入维度；一个最大池化层；具有形状为 `3` 的 `128` 个核的卷积层和 `ReLU` 作为激活函数；一个最大池化层；一个展平层；一个具有
    `128` 单元和 `ReLU` 作为激活函数的全连接层；一个具有 `10` 单元和 `softmax` 作为激活函数的全连接层。
- en: 'The code should be as follows:'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代码应如下所示：
- en: '[PRE32]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Instantiate a `tf.keras.optimizers.Adam()` class with `0.001` as the learning
    rate and save it to a variable called optimizer:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `tf.keras.optimizers.Adam()` 类实例化为名为 `optimizer` 的变量，并将学习率设置为 `0.001`：
- en: '[PRE33]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Compile the neural network using `.compile()` with `loss=''sparse_categorical_crossentropy'',
    optimizer=optimizer, metrics=[''accuracy'']`:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `.compile()` 编译神经网络，参数为 `loss='sparse_categorical_crossentropy', optimizer=optimizer,
    metrics=['accuracy']`：
- en: '[PRE34]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Fit the neural networks with `fit_generator()` and provide the train and validation
    data generators, `epochs=5`, the steps per epoch, and the validation steps:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `fit_generator()` 拟合神经网络，并提供训练和验证数据生成器，`epochs=5`，每个 epoch 的步数以及验证步数：
- en: '[PRE35]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The expected output will be as follows:'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期输出如下：
- en: '![Figure 3.30: Model training log'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.30：模型训练日志'
- en: '](img/B15385_03_30.jpg)'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![B15385_03_30.jpg'
- en: 'Figure 3.30: Model training log'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.30：模型训练日志
- en: We trained our CNN on five epochs, and we achieved accuracy scores of `0.8271`
    on the training set and `0.8334` on the validation set, respectively. Our model
    is not overfitting much and achieved quite a high score. The accuracy is still
    increasing after five epochs, so we may get even better results if we keep training
    it. This is something you may try by yourself.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在五个 epochs 上训练了我们的 CNN，在训练集和验证集上分别获得了 `0.8271` 和 `0.8334` 的准确度分数。我们的模型没有过拟合，并且取得了相当高的分数。在五个
    epochs 后，准确度仍在增加，所以如果继续训练，可能会获得更好的结果。这是您可以自行尝试的内容。
- en: Note
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2ObmA8t](https://packt.live/2ObmA8t).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/2ObmA8t](https://packt.live/2ObmA8t)。
- en: You can also run this example online at [https://packt.live/3fiyyJi](https://packt.live/3fiyyJi).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在 [https://packt.live/3fiyyJi](https://packt.live/3fiyyJi) 上在线运行此示例。必须执行整个
    Notebook 才能获得所需的结果。
- en: 'Activity 3.02: Fruit Classification with Transfer Learning'
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 3.02：使用迁移学习进行水果分类
- en: Solution
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: Open a new Jupyter Notebook.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter Notebook。
- en: 'Import `tensorflow` as `tf`:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `tensorflow` 并将其命名为 `tf`：
- en: '[PRE36]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Create a variable called `file_url` containing the link to the dataset:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `file_url` 的变量，其中包含指向数据集的链接：
- en: '[PRE37]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Note
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: In the aforementioned step, we are using the dataset stored at [https://packt.live/3eePQ8G](https://packt.live/3eePQ8G).
    If you have stored the dataset at any other URL, please change the highlighted
    path accordingly.
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在上述步骤中，我们使用的是存储在 [https://packt.live/3eePQ8G](https://packt.live/3eePQ8G) 的数据集。如果您将数据集存储在其他任何
    URL，请相应更改突出显示的路径。
- en: 'Download the dataset using `tf.keras.get_file` with `''fruits360.zip'', origin=file_url,
    extract=True` as parameters and save the result to a variable called `zip_dir`:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `tf.keras.get_file` 并将 `'fruits360.zip', origin=file_url, extract=True` 作为参数下载数据集，并将结果保存到名为
    `zip_dir` 的变量中：
- en: '[PRE38]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Import the `pathlib` library:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pathlib` 库：
- en: '[PRE39]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Create a variable called `path` containing the full path to the `fruits360_filtered`
    directory using `pathlib.Path(zip_dir).parent`:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `pathlib.Path(zip_dir).parent` 创建一个名为 `path` 的变量，其中包含到 `fruits360_filtered`
    目录的完整路径：
- en: '[PRE40]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Create two variables called `train_dir` and `validation_dir` that take the
    full paths to the train (`Training`) and validation (`Test`) folders, respectively:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个名为 `train_dir` 和 `validation_dir` 的变量，分别指向训练 (`Training`) 和验证 (`Test`) 文件夹的完整路径：
- en: '[PRE41]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Create two variables called `total_train` and `total_val` that will get the
    number of images for the training and validation sets, that is, `11398` and `4752`:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个名为 `total_train` 和 `total_val` 的变量，分别获取训练集和验证集的图像数量，即 `11398` 和 `4752`：
- en: '[PRE42]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Import `ImageDataGenerator` from `tensorflow.keras.preprocessing`:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `tensorflow.keras.preprocessing` 导入 `ImageDataGenerator`：
- en: '[PRE43]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Create an `ImageDataGenerator` called `train_img_gen` with data augmentation:
    `rescale=1./255, rotation_range=40, width_shift_range=0.1, height_shift_range=0.1,
    shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode=''nearest''`:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`train_img_gen`的`ImageDataGenerator`，并进行数据增强：`rescale=1./255, rotation_range=40,
    width_shift_range=0.1, height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,
    horizontal_flip=True, fill_mode='nearest'`：
- en: '[PRE44]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Create an `ImageDataGenerator` called `val_img_gen` with rescaling (by dividing
    by 255):'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`val_img_gen`的`ImageDataGenerator`，并进行重新缩放（通过除以255）：
- en: '[PRE45]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Create four variables called `batch_size`, `img_height`, `img_width`, and `channel`
    that take the values `16`, `100`, `100`, and `3`, respectively:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建四个变量，分别为`batch_size`、`img_height`、`img_width`和`channel`，其值分别为`16`、`100`、`100`和`3`：
- en: '[PRE46]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Create a data generator called `train_data_gen` using `.flow_from_directory()`
    and specify the batch size, training folder, and target size:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.flow_from_directory()`创建一个名为`train_data_gen`的数据生成器，并指定批量大小、训练文件夹和目标尺寸：
- en: '[PRE47]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Create a data generator called `val_data_gen` using `.flow_from_directory()`
    and specify the batch size, validation folder, and target size:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.flow_from_directory()`创建一个名为`val_data_gen`的数据生成器，并指定批量大小、验证文件夹和目标尺寸：
- en: '[PRE48]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Import `numpy` as `np`, `tensorflow` as `tf`, and `layers` from `tensorflow.keras`:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`为`np`，`tensorflow`为`tf`，以及从`tensorflow.keras`导入`layers`：
- en: '[PRE49]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Set `8` as the seed for `numpy` and `tensorflow` using `np.random_seed()` and
    `tf.random.set_seed()`:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`np.random_seed()`和`tf.random.set_seed()`将`8`设置为`numpy`和`tensorflow`的种子：
- en: '[PRE50]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Import `VGG16` from `tensorflow.keras.applications`:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`tensorflow.keras.applications`导入`VGG16`：
- en: '[PRE51]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Instantiate a `VGG16` model into a variable called `base_model` with the following
    parameters:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下参数将`VGG16`模型实例化为一个名为`base_model`的变量：
- en: '[PRE52]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Set this model to non-trainable using the `.trainable` attribute:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.trainable`属性将此模型设置为不可训练：
- en: '[PRE53]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Print the summary of this `VGG16` model:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印此`VGG16`模型的摘要：
- en: '[PRE54]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The expected output will be as follows:'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出将如下所示：
- en: '![Figure 3.31: Model summary'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.31：模型概述'
- en: '](img/B15385_03_31.jpg)'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_03_31.jpg)'
- en: 'Figure 3.31: Model summary'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.31：模型概述
- en: This output shows us the architecture of `VGG16`. We can see that there are
    `14,714,688` parameters in total, but there is no trainable parameter. This is
    expected as we have frozen all the layers of this model.
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此输出显示了`VGG16`的架构。我们可以看到总共有`14,714,688`个参数，但没有可训练的参数。这是预期的，因为我们已经冻结了模型的所有层。
- en: 'Create a new model using `tf.keras.Sequential()` by adding the base model to
    the following layers: `Flatten()`, `Dense(1000, activation=''relu'')`, and `Dense(120,
    activation=''softmax'')`. Save this model to a variable called `model`:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`tf.keras.Sequential()`创建一个新模型，通过添加基础模型和以下层：`Flatten()`、`Dense(1000, activation='relu')`以及`Dense(120,
    activation='softmax')`。将此模型保存到名为`model`的变量中：
- en: '[PRE55]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Instantiate a `tf.keras.optimizers.Adam()` class with `0.001` as the learning
    rate and save it to a variable called `optimizer`:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`0.001`作为学习率实例化`tf.keras.optimizers.Adam()`类，并将其保存到名为`optimizer`的变量中：
- en: '[PRE56]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Compile the neural network using `.compile()` with `loss=''categorical_crossentropy'',
    optimizer=optimizer, metrics=[''accuracy'']`:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.compile()`编译神经网络，设置`loss='categorical_crossentropy', optimizer=optimizer,
    metrics=['accuracy']`：
- en: '[PRE57]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Fit the neural networks with `fit_generator()` and provide the train and validation
    data generators, `epochs=5`, the steps per epoch, and the validation steps. This
    model may take a few minutes to train:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`fit_generator()`训练神经网络，并提供训练和验证数据生成器、`epochs=5`、每个epoch的步数以及验证步数。此模型的训练可能需要几分钟时间：
- en: '[PRE58]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The expected output will be as follows:'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出将如下所示：
- en: '![Figure 3.32: Expected output'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.32：预期输出'
- en: '](img/B15385_03_32.jpg)'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_03_32.jpg)'
- en: 'Figure 3.32: Expected output'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.32：预期输出
- en: Here, we used transfer learning to customize a pretrained `VGG16` model on ImageNet
    so that it fits our fruit classification dataset. We replaced the head of the
    model with our own fully connected layers and trained these layers on five epochs.
    We achieved an accuracy score of `0.9106` for the training set and `0.8920` for
    the testing set. These are quite remarkable results given the time and hardware
    used to train this model. You can try to fine-tune this model and see whether
    you can achieve an even better score.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用迁移学习对预训练的`VGG16`模型进行定制，以便其适应我们的水果分类数据集。我们用自己的全连接层替换了模型的头部，并在五个epoch上训练了这些层。我们在训练集上获得了`0.9106`的准确率，在测试集上获得了`0.8920`的准确率。考虑到训练此模型所用的时间和硬件，这些结果相当显著。你可以尝试微调此模型，看看是否能获得更好的分数。
- en: Note
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2DsVRCl](https://packt.live/2DsVRCl).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 若要访问此特定部分的源代码，请参阅[https://packt.live/2DsVRCl](https://packt.live/2DsVRCl)。
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 本节目前没有在线交互示例，需要在本地运行。
- en: 4\. Deep Learning for Text – Embeddings
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4. 深度学习文本 - 词嵌入
- en: 'Activity 4.01: Text Preprocessing of the ''Alice in Wonderland'' Text'
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 4.01：‘爱丽丝梦游仙境’文本的预处理
- en: Solution
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'You need to perform the following steps:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要执行以下步骤：
- en: Note
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Before commencing this activity, make sure you have defined the `alice_raw`
    variable as demonstrated in the section titled *Downloading Text Corpora Using
    NLTK*.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始这个活动之前，请确保你已经定义了`alice_raw`变量，正如在*使用NLTK下载文本语料库*这一节中所示。
- en: 'Change the data to lowercase and separate into sentences:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据转换为小写并拆分成句子：
- en: '[PRE59]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Tokenize the sentences:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对句子进行分词：
- en: '[PRE60]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Import `punctuation` from the `string` module and `stopwords` from NLTK:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`string`模块导入`punctuation`，从NLTK导入`stopwords`：
- en: '[PRE61]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Create a variable holding the contextual stop words `--` and `said`:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量来存储上下文停用词`--`和`said`：
- en: '[PRE62]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Create a master list for the stop words to remove words that contain terms
    from punctuation, NLTK stop words, and contextual stop words:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个主列表，用于去除包含标点符号、NLTK停用词和上下文停用词的词语：
- en: '[PRE63]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Define a function to drop these tokens from any input sentence (tokenized):'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，从任何输入句子（已分词）中删除这些标记：
- en: '[PRE64]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Remove the terms in `stop_final` from the tokenized text:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从分词后的文本中删除`stop_final`中的词语：
- en: '[PRE65]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Here''s what the first two sentences look like:'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是前两句的样子：
- en: '[PRE66]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Using the `PorterStemmer` algorithm from NLTK, perform stemming on the result.
    Print out the first five sentences of the result:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用NLTK的`PorterStemmer`算法，对结果进行词干提取。打印出前五个句子：
- en: '[PRE67]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The output will be as follows:'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE68]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Note
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2VVNEgf](https://packt.live/2VVNEgf).
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问这一部分的源代码，请参阅[https://packt.live/2VVNEgf](https://packt.live/2VVNEgf)。
- en: You can also run this example online at [https://packt.live/38Gr54r](https://packt.live/38Gr54r).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个示例，网址是[https://packt.live/38Gr54r](https://packt.live/38Gr54r)。你必须执行整个笔记本才能得到预期的结果。
- en: 'Activity 4.02: Text Representation for Alice in Wonderland'
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 4.02：‘爱丽丝梦游仙境’的文本表示
- en: Solution
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'You need to perform the following steps:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要执行以下步骤：
- en: 'From *Activity 4.01*, *Text Preprocessing Alice in Wonderland*, print the first
    three sentences from the result after stop word removal. This is the data you
    will work with:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从*活动 4.01*，*‘爱丽丝梦游仙境’文本预处理*中，打印删除停用词后的前三个句子。这是你将要处理的数据：
- en: '[PRE69]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The output is as follows:'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE70]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Import `word2vec` from Gensim and train your word embeddings with default parameters:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从Gensim导入`word2vec`并使用默认参数训练词向量：
- en: '[PRE71]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Find the `5` terms most similar to `rabbit`:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到与`rabbit`最相似的`5`个词：
- en: '[PRE72]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The output is as follows:'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE73]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Using a `window` size of `2`, retrain the word vectors:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`window`大小为`2`，重新训练词向量：
- en: '[PRE74]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Find the terms most similar to `rabbit`:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到与`rabbit`最相似的词：
- en: '[PRE75]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The output will be as follows:'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE76]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Retrain word vectors using the Skip-gram method with a window size of `5`:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用窗口大小为`5`的Skip-gram方法重新训练词向量：
- en: '[PRE77]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Find the terms most similar to `rabbit`:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到与`rabbit`最相似的词：
- en: '[PRE78]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'The output will be as follows:'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出结果如下：
- en: '[PRE79]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Find the representation for the phrase `white rabbit` by averaging the vectors
    for `white` and `rabbit`:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过平均`white`和`rabbit`的词向量，找到`white rabbit`的表示：
- en: '[PRE80]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Find the representation for `mad hatter` by averaging the vectors for `mad`
    and `hatter`:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过平均`mad`和`hatter`的词向量，找到`mad hatter`的表示：
- en: '[PRE81]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Find the cosine similarity between these two phrases:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算这两个短语之间的余弦相似度：
- en: '[PRE82]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'This gives us the following value:'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这给我们以下的值：
- en: '[PRE83]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Load the pre-trained GloVe embeddings of size 100D using the formatted keyed vectors:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用格式化的键值向量加载预训练的100维GloVe词向量：
- en: '[PRE84]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Find representations for `white rabbit` and `mad hatter`:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到`white rabbit`和`mad hatter`的表示：
- en: '[PRE85]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Find the `cosine` similarity between the two phrases. Has the cosine similarity changed?
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算这两个短语之间的`cosine`相似度。`cosine`相似度有变化吗？
- en: '[PRE86]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The following is the output of the preceding code:'
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是前面代码的输出结果：
- en: '[PRE87]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: Here, we can see that the cosine similarity between the two phrases "`mad hatter`"
    and "`white rabbit`" is far lower from the GloVe model. This is because the GloVe
    model hasn't seen the terms together in its training data as much as they appear
    in the book. In the book, the terms `mad` and `hatter` appear together a lot because
    they form the name of an important character. In other contexts, of course, we
    don't see `mad` and `hatter` together as often.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，两个短语 "`mad hatter`" 和 "`white rabbit`" 之间的余弦相似度在 GloVe 模型中较低。这是因为
    GloVe 模型在其训练数据中看到这些术语的次数没有书中那么多。在书中，`mad` 和 `hatter` 经常一起出现，因为它们组成了一个重要角色的名字。当然，在其他上下文中，我们不会经常看到
    `mad` 和 `hatter` 一起出现。
- en: Note
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2VVNEgf](https://packt.live/2VVNEgf).
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考 [https://packt.live/2VVNEgf](https://packt.live/2VVNEgf)。
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 本节目前没有在线互动示例，需在本地运行。
- en: 5\. Deep Learning for Sequences
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5. 深度学习与序列
- en: 'Activity 5.01: Using a Plain RNN Model to Predict IBM Stock Prices'
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 5.01：使用普通 RNN 模型预测 IBM 股票价格
- en: Solution
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Import the necessary libraries, load the `.csv` file, reverse the index, and
    plot the time series (the `Close` column) for visual inspection:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的库，加载 `.csv` 文件，反转索引，并绘制时间序列（`Close` 列）以进行可视化检查：
- en: '[PRE88]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'The output will be as follows, with the closing price plotted on the *Y-axis*:'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示，收盘价绘制在 *Y 轴* 上：
- en: '![Figure 5.40: The trend for IBM stock prices'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.40：IBM 股票价格趋势'
- en: '](img/B15385_05_40.jpg)'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_05_40.jpg)'
- en: 'Figure 5.40: The trend for IBM stock prices'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.40：IBM 股票价格趋势
- en: 'Extract the values for `Close` from the DataFrame as a `numpy` array and plot
    them using `matplotlib`:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 DataFrame 中提取 `Close` 值作为 `numpy` 数组，并使用 `matplotlib` 绘制它们：
- en: '[PRE89]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'The resulting trend is as follows, with the index plotted on the *X-axis*:'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果趋势如下，索引绘制在 *X 轴* 上：
- en: '![Figure 5.41: The stock price data visualized'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.41：股票价格数据可视化'
- en: '](img/B15385_05_41.jpg)'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_05_41.jpg)'
- en: 'Figure 5.41: The stock price data visualized'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.41：股票价格数据可视化
- en: 'Assign the final 25% data as test data and the first 75% as train data:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将最后 25% 的数据分配为测试数据，前 75% 的数据分配为训练数据：
- en: '[PRE90]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'The output will be as follows:'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE91]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'Using `MinMaxScaler` from `sklearn`, scale the train and test data:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `sklearn` 中的 `MinMaxScaler`，对训练数据和测试数据进行缩放：
- en: '[PRE92]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'Using the `get_lookback` function we defined earlier in this chapter (refer
    to the *Preparing the Data for Stock Price Prediction* section), get the lookback
    data for the train and test sets using a lookback period of 10:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们在本章前面定义的 `get_lookback` 函数（参见 *准备股票价格预测数据* 部分），使用 10 的回溯期获取训练集和测试集的回溯数据：
- en: '[PRE93]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'The output will be as follows:'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE94]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'From Keras, import all the necessary layers for employing plain RNNs (`SimpleRNN`,
    `Activation`, `Dropout`, `Dense`, and `Reshape`) and 1D convolutions (Conv1D).
    Also, import the `mean_squared_error` metric from `sklearn`:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Keras 中导入所有必要的层，用于使用普通 RNN（`SimpleRNN`、`Activation`、`Dropout`、`Dense` 和 `Reshape`）和
    1D 卷积（Conv1D）。同时从 `sklearn` 导入 `mean_squared_error` 度量：
- en: '[PRE95]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Build a model with a 1D convolution layer (5 filters of size 3) and an RNN
    layer with 32 neurons. Add 25% dropout after the RNN layer. Print the model''s summary:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用一个包含 5 个 3x3 卷积核的 1D 卷积层和一个包含 32 个神经元的 RNN 层构建模型。在 RNN 层后添加 25% 的 dropout。打印模型摘要：
- en: '[PRE96]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'The output will be as follows:'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 5.42: Summary of the model'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.42：模型摘要'
- en: '](img/B15385_05_42.jpg)'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_05_42.jpg)'
- en: 'Figure 5.42: Summary of the model'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.42：模型摘要
- en: 'Compile the model with the `mean_squared_error` loss and the `adam` optimizer.
    Fit this on the train data in five epochs, with a validation split of 10% and
    a batch size of 1:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `mean_squared_error` 损失函数和 `adam` 优化器编译模型。在训练数据上进行五个周期的训练，验证集占 10%，批量大小为
    1：
- en: '[PRE97]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'The output will be as follows:'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '![Figure 5.43: Training and validation loss'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.43：训练和验证损失'
- en: '](img/B15385_05_43.jpg)'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_05_43.jpg)'
- en: 'Figure 5.43: Training and validation loss'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.43：训练和验证损失
- en: 'Using the `get_model_perf` method, print the RMSE of the model:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `get_model_perf` 方法，打印模型的 RMSE：
- en: '[PRE98]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The output will be as follows:'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出将如下所示：
- en: '[PRE99]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Plot the predictions – the entire view, as well as the zoomed-in view:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制预测结果——整体视图和放大视图：
- en: '[PRE100]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'We should see the following plot of predictions (dotted lines) versus the actuals
    (solid lines):'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们应该看到以下的预测图（虚线）与实际值图（实线）对比：
- en: '![Figure 5.44: Predictions versus actuals'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.44：预测与实际值对比'
- en: '](img/B15385_05_44.jpg)'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_05_44.jpg)'
- en: 'Figure 5.44: Predictions versus actuals'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.44：预测值与实际值的对比
- en: 'The zoomed-in view is as follows:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 放大的视图如下：
- en: '![Figure 5.45: Predictions (dotted lines) versus actuals (solid lines) – detailed
    view'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.45：预测值（虚线）与实际值（实线）对比——详细视图'
- en: '](img/B15385_05_45.jpg)'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15385_05_45.jpg)'
- en: 'Figure 5.45: Predictions (dotted lines) versus actuals (solid lines) – detailed
    view'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.45：预测值（虚线）与实际值（实线）对比——详细视图
- en: We can see that the model does a great job of catching the finer patterns and
    does extremely well at predicting the daily stock price.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，模型在捕捉细微的模式上做得非常出色，并且在预测每日股票价格方面表现非常好。
- en: Note
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2ZctArW](https://packt.live/2ZctArW).
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 若要访问本节的源代码，请参阅 [https://packt.live/2ZctArW](https://packt.live/2ZctArW)。
- en: You can also run this example online at [https://packt.live/38EDOEA](https://packt.live/38EDOEA).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在线运行此示例，网址为 [https://packt.live/38EDOEA](https://packt.live/38EDOEA)。你必须执行整个
    Notebook 才能获得预期的结果。
- en: 6\. LSTMs, GRUs, and Advanced RNNs
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6. LSTM、GRU 及高级 RNN
- en: 'Activity 6.01: Sentiment Analysis of Amazon Product Reviews'
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 6.01：亚马逊产品评论的情感分析
- en: Solution
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Read in the data files for the `train` and `test` sets. Examine the shapes
    of the datasets and print out the top `5` records from the `train` data:'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 读取 `train` 和 `test` 数据集的文件。检查数据集的形状，并打印出 `train` 数据的前 `5` 条记录：
- en: '[PRE101]'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'The dataset''s shape and header are as follows:'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集的形状和头部信息如下：
- en: '![Figure 6.26: First five records from the train dataset'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.26：训练数据集中的前五条记录'
- en: '](img/B15385_06_26.jpg)'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_06_26.jpg)'
- en: 'Figure 6.26: First five records from the train dataset'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.26：训练数据集中的前五条记录
- en: 'For convenience, when it comes to processing, separate the raw text and the
    labels for the `train` and `test` sets. You should have `4` variables, as follows:
    `train_raw` comprising raw text for the train data, `train_labels` with labels
    for the train data, `test_raw` containing raw text for the test data, and `test_labels`
    comprising Labels for the test data. Print the first two reviews from the `train`
    text.'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了方便处理，在处理时将原始文本和标签从 `train` 和 `test` 数据集中分开。你应该有 `4` 个变量，如下：`train_raw` 包含训练数据的原始文本，`train_labels`
    包含训练数据的标签，`test_raw` 包含测试数据的原始文本，`test_labels` 包含测试数据的标签。打印出 `train` 文本中的前两条评论。
- en: '[PRE102]'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'The preceding code results in the following output:'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前述代码的输出结果如下：
- en: '![Figure 6.27: Raw text from the train dataset'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.27：来自训练数据集的原始文本'
- en: '](img/B15385_06_27.jpg)'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_06_27.jpg)'
- en: 'Figure 6.27: Raw text from the train dataset'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.27：来自训练数据集的原始文本
- en: 'Normalize the case and tokenize the test and train texts using NLTK''s `word_tokenize`
    (after importing it, of course – hint: use a list comprehension for cleaner code).
    Download `punkt` from `nltk` if you haven''t used the tokenizer before. Print
    the first review from the train data to check if the tokenization worked.'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 NLTK 的 `word_tokenize` 来规范化大小写并对测试和训练文本进行分词（当然，记得先导入它——提示：使用列表推导式使代码更简洁）。如果你之前没有使用过分词器，可以从
    `nltk` 下载 `punkt`。打印训练数据集中的第一条评论，检查分词是否正常工作。
- en: '[PRE103]'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: 'The tokenized data gets printed as follows:'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 分词后的数据如下所示：
- en: '![Figure 6.28: Tokenized review from the train dataset'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.28：来自训练数据集的分词评论'
- en: '](img/B15385_06_28.jpg)'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_06_28.jpg)'
- en: 'Figure 6.28: Tokenized review from the `train` dataset'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.28：来自 `train` 数据集的分词评论
- en: 'Import any stop words (built in to NLTK) and punctuation from the string module.
    Define a function (`drop_stop`) to remove these tokens from any input tokenized
    sentence. Download `stopwords` from NLTK if you haven''t used it before:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入任何停用词（内建于 NLTK）和来自 string 模块的标点符号。定义一个函数（`drop_stop`）来从任何输入的分词句子中移除这些标记。如果你之前没有使用过
    `stopwords`，可以从 NLTK 下载它：
- en: '[PRE104]'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'Using the defined function (`drop_stop`), remove the redundant stop words from
    the `train` and the `test` texts. Print the first review of the processed `train`
    texts to check whether the function worked:'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用定义的函数（`drop_stop`）从 `train` 和 `test` 文本中移除多余的停用词。打印出处理后的 `train` 文本中的第一条评论，检查该函数是否有效：
- en: '[PRE105]'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'We''ll get the following output:'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将得到如下输出：
- en: '[PRE106]'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'Using `PorterStemmer` from NLTK, stem the tokens for both the `train` and `test`
    data:'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 NLTK 的 `PorterStemmer` 对 `train` 和 `test` 数据的标记进行词干提取：
- en: '[PRE107]'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'The result should be printed as follows:'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果应按如下方式打印：
- en: '[PRE108]'
  id: totrans-352
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'Create the strings for each of the `train` and `text` reviews. This will help
    us work with the utilities in Keras to create and pad the sequences. Create the
    `train_texts` and `test_texts` variables. Print the first review from the processed
    `train` data to confirm this:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 `train` 和 `text` 评论创建字符串。这将帮助我们使用 Keras 中的工具来创建和填充序列。创建 `train_texts` 和 `test_texts`
    变量。打印处理后的 `train` 数据中的第一条评论，以确认这一点：
- en: '[PRE109]'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'The result of the preceding code is as follows:'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码的结果如下：
- en: '[PRE110]'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'From Keras'' preprocessing utilities for text (`keras.preprocessing.text`),
    import the `Tokenizer` module. Define a vocabulary size of `10000` and instantiate
    the tokenizer with this vocabulary:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Keras 的文本预处理工具（`keras.preprocessing.text`）中导入 `Tokenizer` 模块。定义一个 `10000`
    的词汇量大小，并使用此词汇量实例化 tokenizer：
- en: '[PRE111]'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'Fit the tokenizer on the `train` texts. This works just like `CountVectorizer`
    did in *Chapter 4, Deep Learning for Text – Embeddings*, and trains the vocabulary.
    After fitting, use the `texts_to_sequences` method of the tokenizer on the `train`
    and `test` sets to create the sequences for them. Print the sequence for the first
    review in the train data:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `train` 文本上拟合 tokenizer。这与 *第 4 章 深度学习用于文本 – 嵌入* 中的 `CountVectorizer` 类似，并训练词汇表。拟合后，使用
    tokenizer 的 `texts_to_sequences` 方法对 `train` 和 `test` 数据集进行处理，生成它们的序列。打印训练数据中第一条评论的序列：
- en: '[PRE112]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'The encoded sequence is as follows:'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编码后的序列如下：
- en: '[PRE113]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'We need to find the optimal length of the sequences to process the model. Get
    the length of the reviews from the `train` set into a list and plot a histogram
    of the lengths:'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要找到处理模型的序列的最佳长度。获取 `train` 数据集中评论的长度列表，并绘制长度的直方图：
- en: '[PRE114]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'The distribution of the lengths is as follows:'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 长度分布如下：
- en: '![Figure 6.29: Histogram of text lengths'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.29: 文本长度直方图'
- en: '](img/B15385_06_29.jpg)'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_06_29.jpg)'
- en: 'Figure 6.29: Histogram of text lengths'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '图 6.29: 文本长度直方图'
- en: 'The data is now in the same format as the IMDb data we used in this chapter.
    Using a sequence length of `100` (define the `maxlen = 100` variable), use the
    `pad_sequences` method from the `sequence` module in Keras'' preprocessing utilities
    (`keras.preprocessing.sequence`) to limit the sequences to `100` for both the
    `train` and `test` data. Check the shape of the result for the train data:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，数据与我们在本章中使用的 IMDb 数据格式相同。使用 `100` 的序列长度（定义 `maxlen = 100` 变量），并使用 Keras 的预处理工具（`keras.preprocessing.sequence`）中的
    `pad_sequences` 方法，将 `train` 和 `test` 数据的序列限制为 `100`。检查训练数据结果的形状：
- en: '[PRE115]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'The shape is as follows:'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 形状如下：
- en: '[PRE116]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: 'To build the model, import all the necessary layers from Keras (`embedding`,
    `spatial dropout`, `LSTM`, `dropout`, and `dense`) and import the `Sequential`
    model. Initialize the `Sequential` model:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要构建模型，从 Keras 导入所有必要的层（`embedding`，`spatial dropout`，`LSTM`，`dropout` 和 `dense`），并导入
    `Sequential` 模型。初始化 `Sequential` 模型：
- en: '[PRE117]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE117]'
- en: 'Add an embedding layer with `32` as the vector size (`output_dim`). Add a spatial
    dropout of `40%`:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个 `32` 维向量大小（`output_dim`）的嵌入层。添加一个 `40%` 丢弃率的空间丢弃层：
- en: '[PRE118]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'Build a stacked LSTM model with `2` layers that have `64` cells each. Add a
    dropout layer with `40%` dropout:'
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个具有 `2` 层，每层 `64` 个单元的堆叠 LSTM 模型。添加一个 `40%` 丢弃率的 dropout 层：
- en: '[PRE119]'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'Add a dense layer with `32` neurons with `relu` activation, then a `50%` dropout
    layer, followed by another dense layer of `32` neurons with `relu` activation,
    and follow this up with another dropout layer with `50%` dropout:'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个具有 `32` 个神经元的 dense 层，使用 `relu` 激活函数，然后是一个 `50%` 丢弃率的 dropout 层，接着是另一个具有
    `32` 个神经元的 dense 层，使用 `relu` 激活函数，最后再添加一个丢弃率为 `50%` 的 dropout 层：
- en: '[PRE120]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'Add a final dense layer with a single neuron with `sigmoid` `activation` and
    compile the model. Print the model summary:'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个最终的 dense 层，包含一个具有 `sigmoid` 激活函数的神经元，并编译模型。打印模型摘要：
- en: '[PRE121]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'The summary of the model will be as follows:'
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型的摘要如下：
- en: '![Figure 6.30: Stacked LSTM model summary'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.30: 堆叠 LSTM 模型摘要'
- en: '](img/B15385_06_30.jpg)'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_06_30.jpg)'
- en: 'Figure 6.30: Stacked LSTM model summary'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '图 6.30: 堆叠 LSTM 模型摘要'
- en: 'Fit the model on the training data with a `20%` validation split and a batch
    size of `128`. Train for `5` `epochs`:'
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `20%` 的验证集拆分和 `128` 的批量大小在训练数据上拟合模型。训练 `5` 个 `epochs`：
- en: '[PRE122]'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE122]'
- en: 'We will get the following training output:'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将获得以下训练输出：
- en: '![Figure 6.31: Stacked LSTM model training output'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.31: 堆叠 LSTM 模型训练输出'
- en: '](img/B15385_06_31.jpg)'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_06_31.jpg)'
- en: 'Figure 6.31: Stacked LSTM model training output'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '图 6.31: 堆叠 LSTM 模型训练输出'
- en: 'Make a prediction on the test set using the `predict_classes` method of the
    model. Then, print out the confusion matrix:'
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用模型的 `predict_classes` 方法对测试集进行预测。然后，打印混淆矩阵：
- en: '[PRE123]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE123]'
- en: 'We will get the following result:'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将获得以下结果：
- en: '[PRE124]'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE124]'
- en: Using the `accuracy_score` method from `scikit-learn`, calculate the accuracy
    of the test set.
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`scikit-learn`中的`accuracy_score`方法，计算测试集的准确率。
- en: '[PRE125]'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE125]'
- en: 'The accuracy we get is:'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们得到的准确率是：
- en: '[PRE126]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE126]'
- en: As we can see, the accuracy score is around `86%`, and looking at the confusion
    matrix (output of *step 18*), the model does a decent job of predicting both classes
    well. We got this accuracy without doing any hyperparameter tuning. You can tweak
    the hyperparameters to get significantly higher accuracy.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，准确率约为 `86%`，并且查看混淆矩阵（*步骤 18*的输出），模型在预测两类时都做得相当不错。我们在没有进行任何超参数调优的情况下得到了这个准确率。你可以调整超参数，以获得显著更高的准确率。
- en: Note
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3fpo0YI](https://packt.live/3fpo0YI).
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该特定部分的源代码，请参考[https://packt.live/3fpo0YI](https://packt.live/3fpo0YI)。
- en: You can also run this example online at [https://packt.live/2Wi75QH](https://packt.live/2Wi75QH).
    You must execute the entire Notebook in order to get the desired result.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 [https://packt.live/2Wi75QH](https://packt.live/2Wi75QH) 上在线运行这个例子。你必须执行整个
    Notebook，才能得到所需的结果。
- en: 7\. Generative Adversarial Networks
  id: totrans-405
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7. 生成对抗网络
- en: 'Activity 7.01: Implementing a DCGAN for the MNIST Fashion Dataset'
  id: totrans-406
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 7.01：为 MNIST 时尚数据集实现 DCGAN
- en: Solution
  id: totrans-407
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解决方案
- en: 'Open a new Jupyter Notebook and name it `Activity 7.01`. Import the following
    library packages:'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter Notebook，并将其命名为`Activity 7.01`。导入以下库包：
- en: '[PRE127]'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE127]'
- en: 'Create a function that will generate real data samples from the fashion MNIST data:'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个函数，用于从时尚 MNIST 数据中生成真实数据样本：
- en: '[PRE128]'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE128]'
- en: The output from this function is the batch of MNIST data. Please note that we
    normalize the input data by subtracting `127.5`, which is half the max pixel value,
    and dividing by the same value. This will help in converging the solution faster.
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该函数的输出是 MNIST 数据批次。请注意，我们通过减去`127.5`（这是最大像素值的一半）并除以相同的值来规范化输入数据。这有助于更快地收敛解决方案。
- en: 'Now, let''s generate a set of images from the MNIST dataset:'
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们从 MNIST 数据集生成一组图像：
- en: '[PRE129]'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE129]'
- en: 'You should get the following output:'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 7.36: Generating images from MNIST'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.36：从 MNIST 生成图像'
- en: '](img/B15385_07_36.jpg)'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_07_36.jpg)'
- en: 'Figure 7.36: Generating images from MNIST'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.36：从 MNIST 生成图像
- en: 'Now, let''s visualize the images with `matplotlib`:'
  id: totrans-419
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用`matplotlib`来可视化这些图像：
- en: '[PRE130]'
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE130]'
- en: 'You should get an output similar to the one shown here:'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到一个类似于这里所示的输出：
- en: '![Figure 7.37: Plotted images'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.37：绘制的图像'
- en: '](img/B15385_07_37.jpg)'
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_07_37.jpg)'
- en: 'Figure 7.37: Plotted images'
  id: totrans-424
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.37：绘制的图像
- en: From the output, we can see the visualization of several fashion articles. We
    can see that the images are centrally located within a white background. This
    are the images that we'll try to recreate.
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从输出中，我们可以看到几件时尚商品的可视化。我们可以看到这些图像位于白色背景的中央。这些图像就是我们将尝试重建的对象。
- en: 'Now, let''s define the function to generate inputs for the generator network.
    The inputs are random data points that are generated from a random uniform distribution:'
  id: totrans-426
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们定义生成生成器网络输入的函数。输入是从随机均匀分布中生成的随机数据点：
- en: '[PRE131]'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE131]'
- en: This function generates the fake data that was sampled from the random distribution
    as the output.
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个函数生成的是从随机分布中采样的假数据作为输出。
- en: 'Let''s define the function for building the generator network:'
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们定义一个构建生成器网络的函数：
- en: '[PRE132]'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE132]'
- en: Building the generator network is similar to building any CNN network. In this
    generator network, we will use the transpose convolution method for upsampling
    images. In this model, we can see the progressive use of the transpose convolution.
    The initial input starts with a dimension of 100, which is our input feature.
    The dimension of the MNIST dataset is batch size x 28 x 28\. Therefore, we have
    upsampled the data twice to get the output as batch size x 28 x 28.
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 构建生成器网络与构建任何 CNN 网络类似。在这个生成器网络中，我们将使用转置卷积方法来对图像进行上采样。在这个模型中，我们可以看到转置卷积的逐步使用。最初的输入维度是
    100，这就是我们的输入特征。MNIST 数据集的维度是批量大小 x 28 x 28。因此，我们已经对数据进行了两次上采样，以便得到输出为批量大小 x 28
    x 28。
- en: 'Next, we define the function that will be used to create fake samples:'
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个将用于创建假样本的函数：
- en: '[PRE133]'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE133]'
- en: In this function, we only return the `X` variable. The output from this function
    is the fake dataset.
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个函数中，我们只返回`X`变量。该函数的输出是假的数据集。
- en: 'Define the parameters that we will use in many of the functions, along with
    the summary of the generator network:'
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义我们将在许多函数中使用的参数，并附上生成器网络的摘要：
- en: '[PRE134]'
  id: totrans-436
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE134]'
- en: 'You should get the following output:'
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 7.38: Summary of the generative model'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.38：生成模型总结'
- en: '](img/B15385_07_38.jpg)'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_07_38.jpg)'
- en: 'Figure 7.38: Summary of the generative model'
  id: totrans-440
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.38：生成模型总结
- en: From the summary, please note how the dimension of the input noise changes with
    each transpose convolution operation. Finally, we get an output that is equal
    in dimension to the real dataset, `( None,28 ,28,1)`.
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从总结中可以看到，每次转置卷积操作时输入噪声的维度是如何变化的。最终，我们得到的输出维度与真实数据集相同，`(None, 28, 28, 1)`。
- en: 'Let''s use the generator function to generate a fake sample before training:'
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用生成器函数生成一个训练前的假样本：
- en: '[PRE135]'
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE135]'
- en: 'You should get the following output:'
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '[PRE136]'
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE136]'
- en: 'Now, let''s plot the generated fake sample:'
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们绘制生成的假样本：
- en: '[PRE137]'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE137]'
- en: 'You should get an output similar to the following:'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到类似以下的输出：
- en: '![Figure 7.39: Output of the fake sample'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.39：假样本的输出'
- en: '](img/B15385_07_39.jpg)'
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_07_39.jpg)'
- en: 'Figure 7.39: Output of the fake sample'
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.39：假样本的输出
- en: This is the plot of the fake sample before training. After training, we want
    samples like these to look like the MNIST fashion samples we visualized earlier
    in this activity.
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是训练前假样本的图像。在训练之后，我们希望这些样本看起来像我们在本活动中之前可视化的MNIST时尚样本。
- en: 'Build the discriminator model as a function. The network architecture will
    be similar to a CNN architecture:'
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将判别器模型构建为一个函数。网络架构将类似于CNN架构：
- en: '[PRE138]'
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE138]'
- en: In the discriminator network, we have included all the necessary layers, such
    as the convolutional operations and `LeakyReLU`. Please note that the last layer
    is a sigmoid layer as we want the output as a probability of whether the sample
    is real (1) or fake (0).
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在判别器网络中，我们已经包含了所有必要的层，如卷积操作和`LeakyReLU`。请注意，最后一层是sigmoid层，因为我们希望输出的是样本是否真实的概率（1表示真实，0表示假）。
- en: 'Print the summary of the discriminator network:'
  id: totrans-456
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印判别器网络的总结：
- en: '[PRE139]'
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE139]'
- en: 'You should get the following output:'
  id: totrans-458
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到以下输出：
- en: '![Figure 7.40: Discriminator model summary'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.40：判别器模型总结'
- en: '](img/B15385_07_40.jpg)'
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_07_40.jpg)'
- en: 'Figure 7.40: Discriminator model summary'
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.40：判别器模型总结
- en: 'Define the GAN model as a function:'
  id: totrans-462
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将GAN模型定义为一个函数：
- en: '[PRE140]'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE140]'
- en: The structure of the GAN model is similar to the one we developed in *Exercise
    7.05*, *Implementing the DCGAN*.
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GAN模型的结构与我们在*练习7.05*中开发的结构相似，*实现DCGAN*。
- en: 'Now, it''s time to invoke the GAN function:'
  id: totrans-465
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，是时候调用GAN函数了：
- en: '[PRE141]'
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE141]'
- en: 'Please note that the inputs to the GAN model are the previously defined generator
    model and the discriminator model. You should get the following output:'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，GAN模型的输入是之前定义的生成器模型和判别器模型。你应该得到以下输出：
- en: '![Figure 7.41: GAN model summary'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图7.41：GAN模型总结'
- en: '](img/B15385_07_41.jpg)'
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_07_41.jpg)'
- en: 'Figure 7.41: GAN model summary'
  id: totrans-470
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图7.41：GAN模型总结
- en: Please note that the parameters of each layer of the GAN model are equivalent
    to the parameters of the generator and discriminator models. The GAN model is
    just a wrapper around the two models we defined earlier.
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，GAN模型中每一层的参数等同于生成器和判别器模型的参数。GAN模型只是我们之前定义的两个模型的封装器。
- en: 'Define the number of epochs to train the network on using the following code:'
  id: totrans-472
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码定义训练网络的epoch数：
- en: '[PRE142]'
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE142]'
- en: 'Now, we can start the process of training the network:'
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以开始训练网络的过程：
- en: '[PRE143]'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE143]'
- en: It needs to be noted here that the training of the discriminator model with
    the fake and real samples and the training of the GAN model happens concurrently.
    The only difference is the training of the GAN model proceeds without updating
    the parameters of the discriminator model. The other thing to note is that, inside
    the GAN, the labels for the fake samples would be 1 to generate large loss terms
    that will be backpropagated through the discriminator network to update the generator
    parameters. We also display the predicted probability of the GAN for every 50
    epochs. When calculating the probability, we combine a sample of real data and
    a sample of fake data and then take the mean of the predicted probability. We
    also save a copy of the generated image.
  id: totrans-476
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里需要注意的是，判别器模型使用真实和假样本的训练与GAN模型的训练是同时进行的。唯一的区别是，GAN模型的训练不会更新判别器模型的参数。另一个需要注意的是，在GAN内部，假样本的标签将是1，以生成较大的损失项，这些损失项将通过判别器网络反向传播，以更新生成器参数。我们还会在每50个epochs时显示GAN的预测概率。在计算概率时，我们结合一个真实数据样本和一个假数据样本，然后取预测概率的均值。我们还会保存生成的图像副本。
- en: 'You should get an output similar to the following:'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到类似以下的输出：
- en: '[PRE144]'
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE144]'
- en: 'Let''s also look at some of the plots that were generated from the training
    process at various epochs:'
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还来看一下在不同训练周期生成的一些图表：
- en: '![Figure 7.42: Images generated during the training process'
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.42：训练过程中生成的图像'
- en: '](img/B15385_07_42.jpg)'
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_07_42.jpg)'
- en: 'Figure 7.42: Images generated during the training process'
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 7.42：训练过程中生成的图像
- en: From the preceding plots, we can see the progression of the training process.
    We can see that by epoch 100, the plots were mostly noise. By epoch 600, the forms
    of the fashion articles started to become more pronounced. At epoch 1,500, we
    can see that the fake images are looking very similar to the fashion dataset.
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从前面的图表中，我们可以看到训练过程的进展。我们看到在第100个周期时，图表大部分仍是噪声；到第600个周期时，时尚物品的形态开始变得更加明显；在第1,500个周期时，我们可以看到假图像与时尚数据集非常相似。
- en: 'Note:'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意：
- en: You can take a closer look at these images by going to [https://packt.live/2W1FjaI](https://packt.live/2W1FjaI).
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以通过访问[https://packt.live/2W1FjaI](https://packt.live/2W1FjaI)更仔细地查看这些图像。
- en: 'Now, let''s look at the images that were generated after training:'
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们看看训练后生成的图像：
- en: '[PRE145]'
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE145]'
- en: 'You should get an output similar to the following:'
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该得到类似以下的输出：
- en: '![Figure 7.43: Images generated after the training process'
  id: totrans-489
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 7.43：训练过程后生成的图像'
- en: '](img/B15385_07_43.jpg)'
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15385_07_43.jpg)'
- en: 'Figure 7.43: Images generated after the training process'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.43：训练过程后生成的图像
- en: From the training accuracy levels, you can see that the accuracy of the discriminator
    model hovers around the .50 range, which is the desired range. The purpose of
    the generator is to create fake images that look like real ones. When the generator
    generates images that look very similar to real images, the discriminator gets
    confused as to whether the image has been generated from the real distribution
    or fake distribution. This phenomenon manifests in an accuracy level of around
    50% for the discriminator, which is the desired level.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 从训练准确率水平可以看到，判别器模型的准确率大约在0.50左右，这就是理想的范围。生成器的目的是创造看起来像真实图像的假图像。当生成器生成的图像与真实图像非常相似时，判别器会混淆图像是来自真实分布还是假分布。这一现象体现在判别器的准确率大约为50%，这是理想的水平。
- en: Note
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：
- en: To access the source code for this specific section, please refer to [https://packt.live/3fpobDm](https://packt.live/3fpobDm).
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/3fpobDm](https://packt.live/3fpobDm)。
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 本节目前没有在线互动示例，需要在本地运行。
