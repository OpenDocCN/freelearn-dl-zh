- en: Finding Meaning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 寻找意义
- en: 'So far, we mostly used TensorFlow for image processing, and to a lesser extent,
    for text-sequence processing. In this chapter, we will revisit the written word
    to find meaning in text. This is part of an area that is commonly termed **Natural
    Language Processing** (**NLP**). Some of the activities in this area include the
    following:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们主要使用TensorFlow进行图像处理，在文本序列处理方面的使用较少。在本章中，我们将重新审视书面文字，寻找文本中的意义。这是通常被称为**自然语言处理**（**NLP**）的一个领域。该领域中的一些活动包括：
- en: '**Sentiment analysis**—This extracts a general sentiment category from text
    without extracting the subject or action of the sentence'
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**情感分析**—这从文本中提取出一般的情感类别，而不提取句子的主题或动作'
- en: '**Entity extraction**—This extracts the subject, for example, person, place,
    and event, from a piece of text'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实体提取**—这从一段文本中提取出主题，例如人、地点和事件'
- en: '**Keyword extraction**—This extracts key terms from a piece of text'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关键词提取**—这从一段文本中提取关键术语'
- en: '**Word-relation extraction**—This extracts not only entities but also the associated
    action and parts of speech of each'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**词语关系提取**—这不仅提取实体，还提取与每个实体相关的动作和词性'
- en: 'This is just scratching the surface of NLP—there are other techniques, as well
    as a range of sophistication across each technique. Initially, this seems somewhat
    academic, but consider what just these four techniques can enable. Some examples
    include the following:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这仅仅是自然语言处理（NLP）的冰山一角——还有其他技术，并且每种技术的复杂度不同。最初，这看起来有些学术，但考虑到仅这四种技术可以实现的功能，举例如下：
- en: Reading news and understanding the subject of the news (individual, company,
    location, and so on)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读新闻并理解新闻的主题（个人、公司、地点等等）
- en: Taking the preceding news and understanding the sentiment (happy, sad, angry,
    and so on)
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取前面的新闻并理解情感（高兴、伤心、愤怒等等）
- en: Parsing product reviews and understanding the user's sentiment toward the product
    (pleased, disappointed, and so on)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析产品评论并理解用户对产品的情感（满意、失望等等）
- en: Writing a bot to respond to user chat-box commands given in natural language
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写一个机器人，以自然语言响应用户的聊天框命令
- en: Much like the previous machine learning efforts we've explored, a decent bit
    of effort goes into setup. In this case, we'll spend some time writing scripts
    to actually grab text from sources of interest.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们之前探讨的机器学习工作一样，设置也需要相当大的努力。在这种情况下，我们将花时间编写脚本，实际从感兴趣的来源抓取文本。
- en: Additional setup
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 额外的设置
- en: 'Additional setup is required to include libraries required for text processing.
    Take a look at the following points:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 需要额外的设置来包含文本处理所需的库。请查看以下几点：
- en: 'First is **Bazel**. On Ubuntu, you will need to follow the official tutorial
    on this link to install Bazel. [https://docs.bazel.build/versions/master/install-ubuntu.html](https://docs.bazel.build/versions/master/install-ubuntu.html).
    On macOS, you can use HomeBrew to `install bazel` as follows:'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一个是**Bazel**。在Ubuntu上，你需要按照官方教程中的链接来安装Bazel。[https://docs.bazel.build/versions/master/install-ubuntu.html](https://docs.bazel.build/versions/master/install-ubuntu.html)。在macOS上，你可以使用HomeBrew来`install
    bazel`，如下所示：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, we will install `swig`, which will allow us to wrap C/C++ functions to
    allow calls in Python. On Ubuntu, you can install it using:'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将安装`swig`，它将允许我们包装C/C++函数，以便在Python中调用。在Ubuntu上，你可以使用以下命令安装它：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'On Mac OS, we will also install it using `brew`, as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在Mac OS上，我们也将按如下方式使用`brew`安装它：
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, we''ll install the protocol buffer support, which will allow us to store
    and retrieve serialized data in a more efficient manner than with XML. We specifically
    need version `3.3.0` to install it as follows:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将安装协议缓冲支持，它将使我们能够以比XML更高效的方式存储和检索序列化数据。我们特别需要版本`3.3.0`，可以按如下方式安装：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Our text classification will be represented as trees, so we''ll need a library
    to display trees on the command line. We will install it as follows:'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的文本分类将以树的形式表示，因此我们需要一个库来在命令行上显示树。我们将按如下方式安装：
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, we''ll need a scientific computing library. If you did image classification
    chapters, you are already familiar with this. But if not, install **NumPy** as
    follows:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们需要一个科学计算库。如果你做过图像分类章节，你已经熟悉这个。如果没有，请按如下方式安装**NumPy**：
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: With all this, we'll now install **SyntaxNet**, which does the heavy lifting
    for our NLP. SyntaxNet is an open source framework for TensorFlow ([https://www.tensorflow.org/](https://www.tensorflow.org/))
    that provides base functionality. Google trained a SyntaxNet model with English
    and named it **Parsey McParseface**, which will be included in our installation.
    We'll be able to either train our own, better or more specific, models in English
    or train in other languages altogether.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 完成所有这些之后，我们现在将安装**SyntaxNet**，它为我们的NLP工作提供了强大的支持。SyntaxNet是一个基于TensorFlow的开源框架（[https://www.tensorflow.org/](https://www.tensorflow.org/)），提供了基础功能。谷歌用英语训练了一个SyntaxNet模型，并命名为**Parsey
    McParseface**，该模型将包含在我们的安装中。我们将能够训练我们自己的、更好或更特定的英语模型，或者在其他语言中进行训练。
- en: Training data will pose a challenge, as always, so we'll start with just using
    the pre-trained English model, Parsey McParseface.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据始终是一个挑战，因此我们将从使用预训练的英语模型Parsey McParseface开始。
- en: 'So, let''s grab the package and configure it, as shown in the following command
    line:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们抓取该包并进行配置，命令行如下所示：
- en: '[PRE6]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Finally, let''s test the system as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们按如下方式测试系统：
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This will take a while. Have patience. If you followed all the instructions
    closely, all the tests will pass. There may be some errors that appeared on our
    computer as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这将需要一些时间，请耐心等待。如果你严格按照所有指示操作，所有测试都会通过。可能会出现一些如下的错误：
- en: 'If you find that `bazel` can''t download a package, you can try to use the
    following command and run the test command again:'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你发现`bazel`无法下载某个包，你可以尝试使用以下命令，并再次运行测试命令：
- en: '[PRE8]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you encounter some failed tests, we suggest that you add the following line
    into your `.bazelrc` in `home` directory in order to receive more error information
    to debug:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你遇到一些测试失败，我们建议你将以下内容添加到`home`目录中的`.bazelrc`文件，以便获得更多的错误信息用于调试：
- en: '[PRE9]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If you encounter the error `Tensor already registered`, you need to follow
    the solution on the Github issue: [https://github.com/tensorflow/models/issues/2355](https://github.com/tensorflow/models/issues/2355).'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你遇到错误`Tensor already registered`，你需要按照Github问题中的解决方案操作：[https://github.com/tensorflow/models/issues/2355](https://github.com/tensorflow/models/issues/2355)。
- en: 'Now, let''s perform a more run-of-the-mill test. Let''s provide an English
    sentence and see how it is parsed:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们进行一个更常规的测试。我们提供一个英文句子，看看它是如何被解析的：
- en: '[PRE10]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We are feeding in a sentence via the echo statement and piping it into the
    `syntaxnet` demo script that accepts standard input from the console. Note that
    to make the example more interesting, I will use an uncommon name, for example,
    `Faaris`. Running this command will produce a great deal of debugging information,
    shown as follows. I cut out stack traces with ellipses (`...`):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过echo语句输入一个句子，并将其传递到接受来自控制台标准输入的`syntaxnet`演示脚本中。请注意，为了让示例更有趣，我将使用一个不常见的名字，比如`Faaris`。运行这个命令将产生大量的调试信息，显示如下。我省略了堆栈跟踪，使用了省略号（`...`）：
- en: '[PRE11]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The final section, starting with `Input:`, is the most interesting part, and
    the output we will consume when we use this foundation programmatically. Notice
    how the sentence is broken down into parts of speech and entity-action-object
    pairs? Some of the word designations we see are—`nsubj`, `xcomp`, `aux`, `dobj`,
    `det`, and `punct`. Some of these designations are obvious, while others are not.
    If you are into deep dive, we suggest perusing the Stanford dependency hierarchy
    at [https://nlp-ml.io/jg/software/pac/standep.html](https://nlp-ml.io/jg/software/pac/standep.html).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一部分，从`Input:`开始，是最有趣的部分，也是我们在程序化使用这个基础时将消费的输出。注意这个句子是如何被分解为词性和实体-动作-对象的配对？我们看到的一些词性标记包括：`nsubj`、`xcomp`、`aux`、`dobj`、`det`和`punct`。其中一些标记是显而易见的，而另一些则不然。如果你喜欢深入研究，我们建议你查阅斯坦福依赖层次结构：[https://nlp-ml.io/jg/software/pac/standep.html](https://nlp-ml.io/jg/software/pac/standep.html)。
- en: 'Let''s try another sentence before we proceed:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，我们再尝试一个句子：
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Again, here, we will find the model performs pretty well in dissecting the phrase.
    Try some of your own.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在这里我们会发现模型在解析这个短语时表现得相当好。你也可以尝试自己的一些例子。
- en: Next, let's actually train a model. Training SyntaxNet is fairly trivial as
    it is a compiled system. So far, we've piped in data via standard input (STDIO),
    but we can also pipe in a corpus of text. Remember the protocol buffer library
    we installed? We will use it now to edit the source file—`syntaxnet/models/parsey_mcparseface/context.pbtxt`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们实际训练一个模型。训练SyntaxNet相对简单，因为它是一个已编译的系统。到目前为止，我们通过标准输入（STDIO）输入了数据，但我们也可以输入一份文本语料库。记得我们安装的协议缓冲库吗？现在我们将使用它来编辑源文件——`syntaxnet/models/parsey_mcparseface/context.pbtxt`。
- en: 'Additionally, we will change the source to other training sources, or our own,
    as shown in the following piece of code:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将根据以下代码段，改变数据源，使用其他训练源或我们自己的数据源：
- en: '[PRE13]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This is how we will train the set; however, it will be pretty challenging to
    do something better than the natively trained model, Parsey McParseface. So let's
    train on an interesting dataset using a new model—a **Convolutional neural network**
    (**CNN**) to process text.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们将训练的数据集；然而，做得比原生训练模型Parsey McParseface更好将是相当具有挑战性的。所以让我们使用一个有趣的数据集，训练一个新的模型——一个**卷积神经网络**（**CNN**）来处理文本。
- en: I'm a little biased in favor of my alma mater, so we'll use movie review data
    that Cornell University's department of computer science compiled. The dataset
    is available at
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我有点偏爱我的母校，所以我们将使用康奈尔大学计算机科学系编制的电影评论数据。数据集可以在以下网址获取：
- en: '[http://www.cs.cornell.edu/people/pabo/movie-review-data/](http://www.cs.cornell.edu/people/pabo/movie-review-data/).'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://www.cs.cornell.edu/people/pabo/movie-review-data/](http://www.cs.cornell.edu/people/pabo/movie-review-data/)。'
- en: We'll first download and process the movie reviews dataset, then train on it,
    and finally evaluate based on it.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先会下载并处理电影评论数据集，然后在其上进行训练，最后基于该数据集进行评估。
- en: All our code is available at— [https://github.com/dennybritz/cnn-text-classification-tf](https://github.com/dennybritz/cnn-text-classification-tf)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的所有代码都可以在以下链接找到—— [https://github.com/dennybritz/cnn-text-classification-tf](https://github.com/dennybritz/cnn-text-classification-tf)
- en: The code was inspired by Yoon Kim's paper on the subject, CNNs for sentence
    classification, implemented and maintained by Google's Denny Britz. Now, we will
    walk through the code to see how Danny Britz implemented the network
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的灵感来自于Yoon Kim关于CNN在句子分类中的应用的论文，由谷歌的Denny Britz实现并维护。接下来，我们将逐步解析代码，看看Denny
    Britz是如何实现该网络的。
- en: 'We start on figure 1 with the usual helpers. The only new entrant here is the
    data helper that downloads and prepares this particular dataset, as shown in the
    following figure:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从图1开始，使用常见的帮助程序。这里唯一的新成员是数据帮助程序，它会下载并准备这个特定的数据集，如下图所示：
- en: '![](img/ddac5b61-96db-4f10-9eaa-72db394f6813.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ddac5b61-96db-4f10-9eaa-72db394f6813.png)'
- en: 'We start defining parameters. The training parameters will be very familiar
    by now—these define the batch size that gets processed on each sweep and how many
    epochs or full runs we''ll undertake. We will also define how often we evaluate
    progress (100 steps here) and how often we save checkpoints for the model (to
    allow evaluation and recontinuation). ). Next, we have the code to load and prepare
    the dataset in figure 2, as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始定义参数。现在，训练参数应该非常熟悉——它们定义了每次遍历时处理的批次大小以及我们将进行的训练轮数或完整运行次数。我们还会定义评估进度的频率（这里是每100步）以及保存模型检查点的频率（以便评估和重新继续训练）。接下来，在图2中，我们有加载和准备数据集的代码，如下所示：
- en: '![](img/4e737d91-9797-4669-b073-43c45a94b20d.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4e737d91-9797-4669-b073-43c45a94b20d.png)'
- en: 'Then, we will take a look at the training part of the code:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将查看代码中的训练部分：
- en: '![](img/03caa6cb-ff5f-420b-b0c4-b414d66c788a.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/03caa6cb-ff5f-420b-b0c4-b414d66c788a.png)'
- en: Figure 3 shows us instantiating our CNN—a Natural Language CNN—with some of
    the parameters we defined earlier. We also set up the code to enable the TensorBoard
    visualization.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图3展示了我们实例化我们的CNN——一个自然语言CNN，并使用之前定义的部分参数。我们还设置了启用TensorBoard可视化的代码。
- en: 'Figure 4 shows more items we''re capturing for TensorBoard—loss, accuracy for
    the training, and evaluation sets:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图4展示了我们为TensorBoard捕获的更多项——训练集和评估集的损失和准确率：
- en: '![](img/32d4bb99-086c-46c6-9ae2-074920af7b60.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/32d4bb99-086c-46c6-9ae2-074920af7b60.png)'
- en: Next, in figure 5, we will define the training and evaluation methods, which
    are very similar to those we used for image processing. We will receive a set
    of training data and labels and house them in a dictionary. Then, we will run
    our TensorFlow session on the dictionary of data, capturing the performance metrics
    returned.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在图5中，我们将定义训练和评估方法，这些方法与我们在图像处理中的方法非常相似。我们将接收一组训练数据和标签，并将其存储在字典中。然后，我们将在数据字典上运行TensorFlow会话，捕获返回的性能指标。
- en: We will set up the methods at the top and then loop through the training data
    in batches, applying the training and evaluation methods to each batch of data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在顶部设置方法，然后按批次遍历训练数据，对每批数据应用训练和评估方法。
- en: 'At select intervals, we will also save checkpoints for optional evaluation:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在特定的间隔，我们还会保存检查点，以便进行可选的评估：
- en: '![](img/0482e7b5-a255-4640-8aaf-252d7682cdfd.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0482e7b5-a255-4640-8aaf-252d7682cdfd.png)'
- en: 'We can run this and end up with a trained model, after a good hour of training
    on a CPU-only machine. The trained model will be stored as a checkpoint file,
    which can then be fed into the evaluation program shown in figure 6:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以运行这个，并且在仅使用 CPU 的机器上经过一小时的训练后，得到一个训练好的模型。训练好的模型将被存储为一个检查点文件，然后可以输入到图 6 所示的评估程序中：
- en: '![](img/09400684-0fbf-4b9a-8faf-00671388e1a6.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/09400684-0fbf-4b9a-8faf-00671388e1a6.png)'
- en: The evaluation program is just an example of usage, but let's go through it.
    We will start with the typical imports and parameter settings. Here, we will also
    take the checkpoint directory as an input and we will load some test data; however,
    you should use your own data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 评估程序只是一个使用示例，但我们还是来了解一下它。我们将从典型的导入和参数设置开始。在这里，我们还将检查点目录作为输入，并加载一些测试数据；不过，您应该使用自己的数据。
- en: 'Next, let''s examine the following figure:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们查看以下图形：
- en: '![](img/47ccb93f-c1e1-4522-9e0a-65caecb20d66.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/47ccb93f-c1e1-4522-9e0a-65caecb20d66.png)'
- en: We will start with the checkpoint file by just loading it up and recreating
    a TensorFlow session from it. This allows us to evaluate against the model we
    just trained, and reuse it over and over.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从检查点文件开始，只需加载它并从中重新创建一个 TensorFlow 会话。这使我们能够针对刚刚训练的模型进行评估，并反复使用它。
- en: Next, we will run the test data in batches. In regular use, we will not use
    a loop or batches, but we have a sizeable set of test data, so we'll do it as
    a loop.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将批量运行测试数据。在常规使用中，我们不会使用循环或批次，但由于我们有一个相当大的测试数据集，因此我们将以循环方式进行处理。
- en: 'We will simply run the session against each set of test data and keep the returned
    predictions (negative versus positive.) The following is some sample positive
    review data:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将简单地对每一组测试数据运行会话，并保存返回的预测结果（负面与正面）。以下是一些示例正面评论数据：
- en: '[PRE14]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Similarly, we have negative data. They are all in the `data` folder as `rt-polarity.pos`
    and `rt-polarity.neg`.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们有负面数据。它们都位于 `data` 文件夹中，分别为 `rt-polarity.pos` 和 `rt-polarity.neg`。
- en: 'Here is the network architecture we used:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们使用的网络架构：
- en: '![](img/8ecb8737-7f33-43b1-ab6f-aa7dc5bc8f68.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8ecb8737-7f33-43b1-ab6f-aa7dc5bc8f68.png)'
- en: It is very similar to the architecture we used for images. In fact, the entire
    effort looks very similar, and it is. The beauty of many of these techniques is
    its generalizability.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 它与我们用于图像的架构非常相似。事实上，整个过程看起来非常相似，实际上也是如此。这些技术的美妙之处在于它们的广泛适用性。
- en: 'Let''s examine the output of training first, which is as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先查看训练输出，其结果如下：
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now let''s look at the evaluation step:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一下评估步骤：
- en: '[PRE16]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: That is pretty good accuracy on the dataset we have. The next step will be to
    apply the trained model to regular use. Some interesting experiments may be to
    obtain movie review data from another source, perhaps IMDB or Amazon. As the data
    will not necessarily be tagged, we can use % positive as a metric of general agreement
    across sites.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们所拥有的数据集上，这个准确度相当不错。下一步将是将训练好的模型应用于常规使用。可能有一些有趣的实验，可以从其他来源获取电影评论数据，比如 IMDB
    或 Amazon。由于数据未必已经标记，我们可以使用正面百分比作为网站之间的一般一致性指标。
- en: We can then use the model in the field. Consider you were a product manufacturer.
    You could track, in real time, all reviews from myriad sources and filter for
    just highly negative reviews. Then, your field-representatives could try and address
    such issues. The possibilities are endless, so we propose an interesting project
    you could undertake, combining the two items we've learned.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以将模型应用于实际场景。假设你是一个产品制造商，你可以实时追踪来自各种来源的所有评论，并筛选出高度负面的评论。然后，你的现场代表可以尝试解决这些问题。可能性是无限的，因此我们提出了一个有趣的项目，结合了我们学到的两项内容。
- en: Write a twitter stream reader that takes each tweet and extracts the subject
    of the tweet. For a specific set of subjects, say companies, evaluate whether
    the tweet is positive or negative. Create running metrics on percent positive
    and negative, which evaluates the subject on different time scales.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 编写一个 Twitter 流读取器，获取每条推文并提取推文的主题。对于特定的一组主题，比如公司，评估推文是积极的还是消极的。创建积极和消极百分比的运行指标，评估不同时间尺度下的主题。
- en: Skills learned
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学到的技能
- en: 'You should have learned the following skills in this chapter:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您应该已经学会了以下技能：
- en: Setting up more advanced TensorFlow libraries, including those requiring Bazel-driven
    compilation
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置更高级的 TensorFlow 库，包括那些需要 Bazel 驱动编译的库
- en: Working with text data
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理文本数据
- en: Applying RNNs and CNNs to text instead of images
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 RNN 和 CNN 应用于文本而非图像
- en: Evaluating text against saved models
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用保存的模型评估文本
- en: Using prebuilt libraries to extract sentence structure details
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预构建的库来提取句子结构细节
- en: Classifying text into buckets based on positive and negative sentiment
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于正面和负面情感将文本分类
- en: Summary
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Excellent! We just took our knowledge of neural networks and applied it to text
    to understand language. This is quite a feat because full automation leads to
    vast scale. Even if particular evaluations are not correct, statistically, we'll
    have a powerful tool in our hands, again, built using the same building blocks.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！我们刚刚将对神经网络的理解应用到文本中，以便理解语言。这是一个了不起的成就，因为完全自动化可以实现大规模处理。即使某些评估不完全正确，从统计学角度来看，我们依然手握一项强大的工具，这同样是使用相同的构建模块构建的。
