- en: Generating Polyphonic Melodies
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成和声旋律
- en: Building on the last chapter where we created drum sequences, we can now proceed
    to create the heart of music—its melody. In this chapter, you'll learn the importance
    of **Long Short-Term Memory** (**LSTM**) networks in generating longer sequences.
    We'll see how to use a monophonic Magenta model, the Melody RNN—an LSTM network
    with a loopback and attention configuration. You'll also learn to use two polyphonic
    models, the Polyphony RNN and Performance RNN, both LSTM networks using a specific
    encoding, with the latter having support for note velocity and expressive timing.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们创建了鼓序列，现在我们可以继续创作音乐的核心——旋律。在本章中，你将学习 **长短期记忆**（**LSTM**）网络在生成较长序列中的重要性。我们将学习如何使用一个单声部的
    Magenta 模型——Melody RNN，它是一个带有回环和注意力配置的 LSTM 网络。你还将学习如何使用两个和声模型：Polyphony RNN 和
    Performance RNN，它们都是使用特定编码的 LSTM 网络，后者支持音符的力度和表现力的时值。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将覆盖以下主题：
- en: LSTM for long-term dependencies
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于长期依赖的 LSTM
- en: Generating melodies with the Melody RNN
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Melody RNN 生成旋律
- en: Generating polyphony with the Polyphony RNN and Performance RNN
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Polyphony RNN 和 Performance RNN 生成和声
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we''ll use the following tools:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下工具：
- en: The **command line** or **bash** to launch Magenta from the Terminal
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动 Magenta 的 **命令行** 或 **bash** 来自终端
- en: '**Python** and its libraries to write music generation code using Magenta'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 **Python** 及其库来编写使用 Magenta 的音乐生成代码
- en: '**Magenta** to generate music in MIDI'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Magenta** 用于生成 MIDI 音乐'
- en: '**MuseScore** or **FluidSynth** to listen to the generated MIDI'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MuseScore** 或 **FluidSynth** 用于听生成的 MIDI'
- en: In Magenta, we'll make the use of the **Melody RNN**, **the Polyphony RNN**,
    and **Performance RNN** models. We'll be explaining those models in depth, but
    if you feel like you need more information, the model's README in Magenta's source
    code ([github.com/tensorflow/magenta/tree/master/magenta/models](https://github.com/tensorflow/magenta/tree/master/magenta/models))
    is a good place to start. You can also take a look at Magenta's code, which is
    well documented. We also provide additional content in the last section, *Further
    reading*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Magenta 中，我们将使用 **Melody RNN**、**Polyphony RNN** 和 **Performance RNN** 模型。我们将深入解释这些模型，但如果你需要更多信息，可以查看
    Magenta 源代码中的模型 README（[github.com/tensorflow/magenta/tree/master/magenta/models](https://github.com/tensorflow/magenta/tree/master/magenta/models)）。你也可以查看
    Magenta 的代码，它有很好的文档说明。我们还在最后一节提供了额外的内容，*进一步阅读*。
- en: The code for this chapter is in this book's GitHub repository in the `Chapter03` folder,
    located at [github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter03](https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter03).
    The examples and code snippets will presume you are located in the chapter folder.
    For this chapter, you should do `cd Chapter03` before you start.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码在本书的 GitHub 仓库中的 `Chapter03` 文件夹，位置在 [github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter03](https://github.com/PacktPublishing/hands-on-music-generation-with-magenta/tree/master/Chapter03)。示例和代码片段假设你位于该章节文件夹。在本章中，你在开始之前应该执行
    `cd Chapter03`。
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，查看代码实际应用：
- en: '[http://bit.ly/314KEzq](http://bit.ly/314KEzq)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/314KEzq](http://bit.ly/314KEzq)'
- en: LSTM for long-term dependencies
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于长期依赖的 LSTM
- en: In the previous chapter, we learned how **Recurrent Neural Networks** (**RNNs**)
    are essential for music generation because they make it possible to operate on
    a sequence of vectors and remember past events. This second part is really important
    in music generation since past events play an important role in defining the global
    musical structure. Let's consider the example of a broken minor ninth chord of
    "A," "C," "E," "G," "B." To predict the last note, "B," the network has to remember
    four events back to know that this is probably a minor ninth chord being played.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了 **递归神经网络**（**RNNs**）在音乐生成中的重要性，因为它们使得可以操作一系列向量并记住过去的事件。这个“记住过去事件”的部分在音乐生成中非常重要，因为过去的事件在定义全局音乐结构中起着重要作用。让我们考虑一个破碎的小九和弦例子，包括“A”、“C”、“E”、“G”和“B”五个音符。为了预测最后一个音符“B”，网络必须记住四个音符之前的事件，才能知道这很可能是一个小九和弦。
- en: Unfortunately, as the gap between the relevant information and the point where
    it is needed grows, RNNs become unable to learn the dependency. In theory, the
    network could be able to do it, but in practice, it is really difficult. Two common
    problems with vanilla RNNs are the vanishing gradient problem and the exploding
    gradient problem, which we'll get to see in this section.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，随着相关信息和需求点之间的间隔增大，RNN变得无法学习这些依赖关系。理论上，网络应该能够做到这一点，但实际上，确实很困难。传统RNN的两个常见问题是梯度消失问题和梯度爆炸问题，我们将在本节中看到这两个问题。
- en: Fortunately, LSTM networks, introduced in 1997, solve that problem. They are
    a special type of RNN where each neuron has a memory cell with special gates.
    As introduced in the previous chapter, the Drums RNN model is an LSTM network
    as are all of the models in this chapter. Now, let's have a look at how LSTMs
    work.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，1997年引入的LSTM网络解决了这个问题。它们是一种特殊类型的RNN，每个神经元都有一个带有特殊门控的记忆单元。正如前一章中介绍的，Drums
    RNN模型就是LSTM网络，本章中的所有模型也是如此。现在，让我们看看LSTM是如何工作的。
- en: Looking at LSTM memory cells
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看LSTM记忆单元
- en: 'LSTM networks have been popular since their invention and for a good reason:
    they were designed specifically to handle the long-term dependency problem we''ve
    been talking about. In Magenta, the RNN models are LSTM networks.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM网络自从发明以来一直很受欢迎，而且有充分的理由：它们是专门为解决我们一直讨论的长期依赖问题而设计的。在Magenta中，RNN模型就是LSTM网络。
- en: 'Let''s have a quick refresher with the RNN diagram from the previous chapter.
    We''ll take the same diagram but zoom in on one of the cells and add a bit of
    detail:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下前一章的RNN图示。我们将使用相同的图示，但放大其中一个单元并添加一些细节：
- en: '![](img/9bdbdd46-7734-433c-8e93-002d7318f688.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9bdbdd46-7734-433c-8e93-002d7318f688.png)'
- en: 'We see here that the repeated module is pretty simple: it takes the output
    from the previous layer, concatenates it with the current input, and uses an activation
    function (such as tanh, sigmoid, or ReLU) layer to produce both the layer''s output
    and the next layer''s input. We also remember that long-term information has to
    travel through all of the cells and layers in a sequential matter, meaning that
    information has to be multiplied at each step. This is where the vanishing gradient
    problem arrives: the values getting multiplied many times by small numbers tend
    to vanish.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，这里重复的模块非常简单：它从前一层获取输出，将其与当前输入进行连接，并使用激活函数（如tanh、sigmoid或ReLU）层来生成该层的输出和下一层的输入。我们还记得，长期信息必须通过所有单元和层按顺序传递，这意味着信息必须在每一步都进行乘法运算。这就是梯度消失问题出现的地方：被多个小数字乘积的值往往会消失。
- en: 'Let''s now see how an LSTM memory cell is designed:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看LSTM记忆单元是如何设计的：
- en: '![](img/5596566d-df05-4002-953c-3af38fe8f087.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5596566d-df05-4002-953c-3af38fe8f087.png)'
- en: The first thing to notice here is the added horizontal line, annotated { ...,
    *c(t-1)*, *c(t)* , *c(t+1), ...* }, that carries the cell state information forward.
    The cell state can be modified by three gates—**forget**, **input**, and **output**.
    We won't go into details on how those gates work since this is outside the scope
    of this book, but we'll be looking at an example of how it works for our use case.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这里首先要注意的是添加的水平线，注释为{ ..., *c(t-1)*, *c(t)* , *c(t+1), ...* }，它将单元状态信息传递到前面。单元状态可以通过三个门控来修改——**遗忘**、**输入**和**输出**。我们不会详细讨论这些门控的工作原理，因为它超出了本书的范围，但我们会看一个实例，展示它在我们用例中的工作方式。
- en: Check out the last section, *Further reading*, for references containing more
    information on LSTM.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 查看最后一节，*进一步阅读*，其中包含关于LSTM的更多参考资料。
- en: Let's take our example of a broken minor ninth chord to illustrate how the gate
    layers work. The network is training and has received so far "A", "C", "E", "G",
    "B", which is its current state. Now the LSTM sees a new note, "C", and what happens?
    First, let's have a look at the **forget gate layer**. The LSTM will look at *h(t-1)*,
    the previous layer output, and *x(t)*, the current input, which is "C", and output
    a number for each element in the previous cell state, *c(t-1)*. The state is then
    multiplied by that output, varying from 0 to 1, meaning a value closer to 0 will
    result in a state losing this value, and a value closer to 1 will result in a
    state keeping this value. Because the input is a "C", and in our state, we already
    saw a full chord, the network might learn to forget previous information because
    we are starting a new chord.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个破碎的小九和弦为例，来说明门层是如何工作的。网络正在训练，至今已经接收到 "A"、"C"、"E"、"G"、"B"，这就是它的当前状态。现在
    LSTM 看到了一个新的音符 "C"，会发生什么呢？首先，让我们看看 **遗忘门层**。LSTM 将查看 *h(t-1)*，即上一层的输出，以及 *x(t)*，即当前输入
    "C"，并为上一层的每个元素 *c(t-1)* 输出一个值。然后，状态会与该输出相乘，输出值范围在 0 到 1 之间，意味着接近 0 的值会导致该状态丢失这个值，而接近
    1 的值则会导致该状态保留这个值。由于输入是 "C"，而且在我们的状态中，已经看到了一个完整的和弦，因此网络可能会学习忘记之前的信息，因为我们开始了一个新的和弦。
- en: Next, the **input gate layer** will look at *h(t-1)* and *x(t)* and decide what
    additions are going to be made to the state. Using this, the forget gate output
    gets updated, producing *c(t)*. The cell state now has new content, meaning our
    input "C" is now added in the cell state, which will be useful for later layers
    to detect, for example, a potential start of a C major chord. At this point, the
    network might also learn other chords, depending on the training data. A properly
    trained network will learn about the different musical chords based on its training
    and will output predictions accordingly during inference.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，**输入门层**将查看 *h(t-1)* 和 *x(t)*，并决定对状态做出哪些添加。利用这些信息，遗忘门的输出被更新，产生 *c(t)*。此时，细胞状态已经有了新的内容，意味着我们的输入
    "C" 已经加入到细胞状态中，这对后续层来说是有用的，比如，检测到一个潜在的 C 大调和弦的开始。此时，网络也可能会学习到其他和弦，具体取决于训练数据。经过正确训练的网络将根据其训练学习不同的音乐和弦，并在推理过程中输出相应的预测。
- en: Finally, the **output gate layer** will produce the output, *h(t)*, by looking
    at the new state *c(t)*, *h(t-1)*, and *x(t)*. At this point, the state is already
    updated and doesn't need further updates. Since our model just saw a "C", it might
    want to output an "E" to constitute a C Major chord.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，**输出门层**将通过查看新的状态 *c(t)*、*h(t-1)* 和 *x(t)* 来产生输出 *h(t)*。此时，状态已经更新，不需要进一步的更新。由于我们的模型刚看到一个
    "C"，它可能会输出一个 "E" 来组成 C 大调和弦。
- en: This is a simplified explanation of LSTM but it serves the purpose of understanding
    how it works for our use case.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 LSTM 的简化解释，但它有助于理解其在我们使用场景中的工作原理。
- en: Looking at the code, you can see where the LSTM memory cell is used. In the
    `events_rnn_graph.py` module, the `make_rnn_cell` function uses `tf.contrib.rnn.BasicLSTMCell`.
    You can see that Magenta uses TensorFlow as a backing engine, as LSTM is not defined
    in Magenta.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 查看代码，你可以看到 LSTM 内存单元的使用。在 `events_rnn_graph.py` 模块中，`make_rnn_cell` 函数使用了 `tf.contrib.rnn.BasicLSTMCell`。你可以看到
    Magenta 使用了 TensorFlow 作为后台引擎，因为 LSTM 并没有在 Magenta 中定义。
- en: Exploring alternative networks
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索替代网络
- en: To summarize the last section, we have RNNs, which are capable of handling sequences
    and looking at past events, and LSTM, a specific memory cell implementation for
    an RNN. Often, a network might be called only RNN but actually uses LSTM memory
    cells.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 总结上一节内容，我们有 RNN，它能够处理序列并查看过去的事件，而 LSTM 是 RNN 的一种特定内存单元实现。通常，一个网络可能被称为仅仅是 RNN，但实际上使用了
    LSTM 内存单元。
- en: While LSTMs are a huge step forward for keeping long-term information, there
    are possible improvements. Another type of similar memory cell, **Gated Recurrent
    Units** (**GRU**), has gained popularity in recent years for its simpler design.
    Because of that, GRUs are also less expressive, which is a trade-off to look out
    for.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 LSTM 在保持长期信息方面迈出了重要一步，但仍然有可能的改进。另一种类似的记忆单元 **门控循环单元**（**GRU**）近年来因其更简洁的设计而获得了广泛关注。由于这一点，GRU
    的表达能力较弱，这是一个需要注意的权衡。
- en: A problem with LSTMs is that they use more resources to run because the memory
    cell takes more memory and more computation to operate. A popular idea for further
    improvement is the introduction of **attention**, where the RNN can look at a
    subset of past outputs, making it possible to look at past events without using
    too much cell memory. We'll be looking at attention in the *Having attention for
    specific steps *section.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM 的一个问题是它们运行时需要更多的资源，因为记忆单元需要更多的内存和计算来操作。一种受欢迎的改进方案是引入 **注意力机制**，使得 RNN 可以关注过去输出的子集，从而在不使用过多记忆单元的情况下查看过去的事件。我们将在
    *专注于特定步骤* 一节中讨论注意力机制。
- en: Generating melodies with the Melody RNN
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Melody RNN 生成旋律
- en: In this section, we'll be building on our previous chapter's knowledge by using
    our Python code to generate music with a new model, the Melody RNN. This section
    will show how to generate monophony and the next section will show how to handle
    polyphony.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将通过使用 Python 代码生成音乐，基于上一章的知识，使用新的模型——Melody RNN。本节将展示如何生成单旋律，下一节将展示如何处理多旋律。
- en: '**Monophony** is the simplest form of musical texture, where the notes, a **melody**,
    are played by a single instrument, one by one. Sometimes, a melody can be played
    by multiple instruments, or multiple singers, at a different octave (for example,
    in a choir), but are still considered monophonic because the backing score is.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**单旋律** 是最简单的音乐纹理形式，其中音符——**旋律**——由单一乐器逐个演奏。有时候，旋律可以由多个乐器或多个歌手在不同的八度音高上演奏（例如合唱团中），但仍然被视为单旋律，因为伴奏部分是单旋律的。'
- en: '**Polyphony,** on the other hand, consists of two or more melody lines played
    together. For example, a piano score played with two hands is polyphonic since
    there are two separate melodies to be played together.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**多旋律** 则由两个或更多旋律线一起演奏。例如，用两只手演奏的钢琴谱就是多旋律的，因为需要同时演奏两条独立的旋律。'
- en: An instrument can be monophonic or polyphonic. For example, a monophonic synthesizer
    will be able to play only one note at a time (so if you press two notes, only
    one will come out), and a polyphonic synthesizer or a classic piano will be able
    to play multiple notes at the same time.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 乐器可以是单旋律或多旋律。例如，单旋律的合成器一次只能演奏一个音符（如果你按下两个音符，只会有一个音符发出），而多旋律的合成器或经典钢琴则可以同时演奏多个音符。
- en: 'Here is a small monophonic example from the piano score of *Fur Elisa* from
    Beethoven, at bar #37:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这是贝多芬 *Für Elise* 钢琴谱中的一个小单旋律示例，出现在第37小节：
- en: '![](img/913a7d9b-fcc0-4081-abda-a187742ad89e.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/913a7d9b-fcc0-4081-abda-a187742ad89e.png)'
- en: 'You notice there''s only one melody and the notes are played one by one. And
    here is a small polyphonic example from the same score, at bar #25:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到这里只有一条旋律，音符是逐个演奏的。以下是同一谱子中的一个小多旋律示例，出现在第25小节：
- en: '![](img/137820cb-6808-4adc-8a01-fe8bd3ca0f5f.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/137820cb-6808-4adc-8a01-fe8bd3ca0f5f.png)'
- en: In this example, you have two melodies played at the same time, typically using
    both hands on the piano.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，你会看到两条旋律同时演奏，通常是用钢琴的双手演奏。
- en: Does polyphony sound familiar? It might, because percussion scores are polyphonic
    in essence, since multiple melodies (kick drum, hit hats, snare, and so on) are
    played together to form a complete rhythm. What we're going to see in the next
    section about polyphony is a bit different though, since we'll need a way to represent
    a note that spans longer than a single step's length, unlike the previous chapter.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 多旋律听起来是不是有点熟悉？它可能让你联想到打击乐谱，因为打击乐谱本质上是多旋律的，因为多个旋律（如低音鼓、踩镲、军鼓等）一起演奏，形成完整的节奏。然而，接下来我们将在多旋律部分看到的内容有些不同，因为我们需要一种方法来表示跨越多个时值的音符，这与上一章不同。
- en: Let's start by writing some code to generate melodies.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先写一些代码来生成旋律。
- en: Generating a song for Fur Elisa
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为 *Für Elise* 生成一首曲子
- en: 'For this example, we''ll be using a small primer from the piano score of *Fur
    Elisa* to generate melodies based on it. The primer looks like this:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用 *Für Elise* 钢琴谱中的一个小片段来生成基于该片段的旋律。这个片段如下所示：
- en: '![](img/c35cee40-f6be-436f-aa05-d833c79960a0.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c35cee40-f6be-436f-aa05-d833c79960a0.png)'
- en: Notice the time signature is 3/8\. We'll be looking into this in a later section,
    *Losing track of time*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意时间签名是 3/8。我们将在后面的 *时间的流逝* 部分探讨这个问题。
- en: Since you already know how to generate a sequence, we'll only provide what has
    changed from the previous code; you can reuse what you've written from the previous
    chapter. We'll be encapsulating the code in a `generate` function, making it easy
    to call with different models and configurations.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你已经知道如何生成一个序列，我们只会提供与之前代码不同的部分；你可以重用上一章写的代码。我们将代码封装在一个`generate`函数中，便于使用不同的模型和配置调用。
- en: You can follow this example in the `chapter_03_example_01.py` file in the source
    code of this chapter. There are more comments and content in the source code,
    so you should go check it out.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章源代码的`chapter_03_example_01.py`文件中跟随这个示例。源代码中有更多的注释和内容，所以你应该去查看一下。
- en: You can find the `generate` function in that file. We'll be making more versions
    of this method as we go. The primer for this example is located at `primers/Fur_Elisa_Beethoveen_Monophonic.mid`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在该文件中找到`generate`函数。随着进展，我们将会做更多版本的方法。本示例的引导文件位于`primers/Fur_Elisa_Beethoveen_Monophonic.mid`。
- en: 'We''ll go through the important changes in the `generate` function by explaining
    the new content step by step. The new function signature is as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐步解释`generate`函数中的重要变化。新的函数签名如下：
- en: '[PRE0]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'At the beginning of the function, we can keep the same code we previously had,
    changing the references to the Drums RNN bundle, generator, and configuration
    to the respective parameters—`bundle_name`, `sequence_generator`, and `generator_id`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数的开始部分，我们可以保留之前的代码，只需要将对Drums RNN包、生成器和配置的引用修改为相应的参数——`bundle_name`、`sequence_generator`和`generator_id`：
- en: 'First, we''ll handle the `primer_filename` parameter by using the MIDI file
    to note sequence function we previously saw, using an empty sequence if no primer
    is provided:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将处理`primer_filename`参数，通过之前看到的MIDI文件记谱序列函数来处理，如果没有提供引导，则使用空序列：
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, we''ll handle the `qpm` parameter. If a primer sequence has a tempo,
    we''ll use it. If not, we''ll use the provided `qpm` parameter:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，我们将处理`qpm`参数。如果引导序列有节奏，我们将使用它。如果没有，我们将使用提供的`qpm`参数：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This introduces the `tempos` attribute on the `NoteSequence` message, which
    contains a list of tempo changes. As in MIDI, a score can have multiple tempos,
    each of them starting and stopping at a specific time. We won't be handling multiple
    tempos for the sake of simplicity and because Magenta doesn't handle them.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这引入了`NoteSequence`消息中的`tempos`属性，该属性包含一个节奏变化列表。与MIDI一样，一个乐谱可以有多个节奏，每个节奏都有一个特定的开始和停止时间。为了简化处理，并且因为Magenta不处理多个节奏，我们不会处理多个节奏。
- en: 'We then change how we calculate the primer length. This used to be a fixed
    value, but now we take the end of the last note, given by `total_time`, a sequence
    attribute, and round it up to the closest step beginning. We then calculate the
    sequence length in seconds from that value:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们改变了计算引导长度的方法。以前这是一个固定值，但现在我们使用`total_time`（一个序列属性）给出的最后一个音符的结束时间，并将其向上取整到最接近的步长起点。然后，我们从该值开始计算序列长度（以秒为单位）：
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The resulting primer end time will be of `primer_sequence_length_time`. Remember
    Magenta handles sequences in seconds, so we always have to calculate timing in
    seconds.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 结果生成的引导结束时间将是`primer_sequence_length_time`。请记住，Magenta处理序列时是以秒为单位的，因此我们始终需要按秒计算时间。
- en: 'We also change how the generation length is calculated by subtracting the primer
    length by the provided `total_length_steps` value:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还通过从提供的`total_length_steps`值中减去引导长度来改变生成长度的计算方法：
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We've been using bars to calculate the primer and generation length in the previous
    chapter, and now, we are using steps to do the same thing. Both approaches are
    useful in different circumstances and we wanted to show both.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一章中使用小节来计算引导和生成长度，而现在，我们使用步长来做同样的事情。这两种方法在不同情况下都很有用，我们想展示这两者的不同。
- en: More often than not, using steps is easier to calculate because you don't need
    to worry about time signatures, which makes the number of steps per bar change.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，使用步长更容易计算，因为你不需要担心时间签名，这会导致每小节的步长数量发生变化。
- en: Using bars, on the other hand, makes it easier to make loops that start and
    stop with proper timing as we did in the previous chapter's exercises.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，使用小节使得制作具有正确时序的开始和结束循环变得更加容易，就像我们在上一章的练习中做的那样。
- en: 'We can also add `beam_size`, `branch_factor`, and `steps_per_iteration` to
    the generator options, as follows:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以将`beam_size`、`branch_factor`和`steps_per_iteration`添加到生成器选项中，如下所示：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, we''ll save the MIDI and plot to disk so that we can listen to the
    sequence and show it. It is the same code you saw previously with a bit more information
    in the filename, with the `<generator_name>_<generator_id>_<date_time>.<format>` pattern:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将保存 MIDI 和绘图到磁盘，以便我们可以听到这个序列并展示它。它是与以 `<generator_name>_<generator_id>_<date_time>.<format>` 模式命名的文件中稍微多一些信息的相同代码，你之前看到的。
- en: '[PRE6]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can now call our brand new `generate` method! Let''s do a simple example
    with the Melody RNN model:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以调用我们全新的 `generate` 方法！让我们用 Melody RNN 模型做一个简单的例子：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: So, we've used the `basic_rnn.mag` pre-trained bundle with the `basic_rnn` configuration
    and `melody_rnn_sequence_generator`. We've asked for 64 steps, which is 4 bars
    in 4/4 time. But didn't we say the primer has a 3/8 time signature? Yes, but the
    generated sequence will be in 4/4 time, so we have to make our calculations based
    on that. We'll be discussing this in a later section, *Losing track of time*.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们使用了 `basic_rnn.mag` 预训练的捆绑包与 `basic_rnn` 配置和 `melody_rnn_sequence_generator`。我们要求
    64 个步骤，这是 4/4 拍的 4 小节。但我们不是说 primer 有 3/8 拍的节拍吗？是的，但生成的序列将是 4/4 拍，因此我们必须基于这个来进行计算。我们将在后面的章节中讨论这个问题，*时间的流逝*。
- en: Calling the method will generate two files in the `output` directory, a MIDI
    `.mid` file and a plot `.html` file.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 调用该方法将在 `output` 目录中生成两个文件，一个是 MIDI `.mid` 文件，另一个是绘图 `.html` 文件。
- en: 'To listen to the generated MIDI, use your software synthesizer or MuseScore.
    For the software synth, refer to the following command depending on your platform
    and replace `PATH_TO_SF2` and `PATH_TO_MIDI` with the proper values:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要听生成的 MIDI，使用你的软件合成器或 MuseScore。对于软件合成器，请参考以下命令，根据你的平台更改 `PATH_TO_SF2` 和 `PATH_TO_MIDI`
    的正确值：
- en: 'Linux: `fluidsynth -a pulseaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linux：`fluidsynth -a pulseaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`
- en: 'macOS: `fluidsynth -a coreaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: macOS：`fluidsynth -a coreaudio -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI`
- en: 'Windows: `` `fluidsynth -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI` ``'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Windows：`` `fluidsynth -g 1 -n -i PATH_TO_SF2 PATH_TO_MIDI` ``
- en: 'Opening the plot file, we get something like this:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开绘图文件，我们会得到类似这样的结果：
- en: '![](img/fe689195-4587-4e81-9176-11fd328db9e3.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fe689195-4587-4e81-9176-11fd328db9e3.png)'
- en: If you listen to it, you'll hear that the generated sample is in the same key
    as the primer and with similar notes, but the global structure of the primer is
    lost. That is because the `basic_rnn` configuration doesn't learn musical structure
    as well as the lookback configuration since the encoded vector doesn't contain
    step positions and repeating musical steps.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你听一下，你会发现生成的样本与 primer 中相同调性和类似音符，但 primer 的全局结构丢失了。这是因为 `basic_rnn` 配置不像回顾配置那样能够学习音乐结构，因为编码的向量不包含步骤位置和重复的音乐步骤。
- en: Let's see how we can fix that by looking at the `attention_rnn` and `lookback_rnn` configurations,
    which are both LSTMs with specific encodings.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何通过查看 `attention_rnn` 和 `lookback_rnn` 配置来修复它，它们都是带有特定编码的 LSTM。
- en: Understanding the lookback configuration
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解回顾配置
- en: 'To see the lookback configuration in action, we''ll first generate a new sequence
    using the following parameters:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看回顾配置的效果，我们将首先使用以下参数生成一个新序列：
- en: '[PRE8]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can see we''re using the same `melody_rnn_sequence_generator` function
    but changing the configuration and bundle files. Let''s look at the generated
    sample for the **lookback** configuration:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我们正在使用相同的 `melody_rnn_sequence_generator` 函数，但是在配置和捆绑文件上有所更改。让我们看一下 **lookback**
    配置的生成样本：
- en: '![](img/aefd249b-b189-4ed5-b98d-511ef245995f.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aefd249b-b189-4ed5-b98d-511ef245995f.png)'
- en: You can see here that bar 1 and bar 3 have a repeating musical structure annotated
    with **s1** and **s2** in the diagram, with bar 0 and bar 2 also having a similar
    structure.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到这里的第 1 小节和第 3 小节在图表中用 **s1** 和 **s2** 注释有一个重复的音乐结构，第 0 小节和第 2 小节也有类似的结构。
- en: If repeating musical structures rings a bell, this is because we've already
    seen that concept—the Drums RNN uses a lookback encoder, namely, `LookbackEventSequenceEncoderDecoder`,
    the same as we are using here. In the section on encoding in the previous chapter,
    we saw that the drum notes are encoded into a one-hot vector for the input of
    the RNN. We have the same thing here, but instead, it's the melody that gets encoded
    as a one-hot vector.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果重复的音乐结构让你感到熟悉，这是因为我们已经见过这个概念——Drums RNN 使用了回顾编码器，即 `LookbackEventSequenceEncoderDecoder`，与我们在这里使用的相同。在上一章节的编码部分中，我们看到鼓音符被编码为用于
    RNN 输入的 one-hot 向量。这里也是同样的情况，但不同的是，这里是旋律被编码为一个 one-hot 向量。
- en: 'Let''s take the diagram we had in [Chapter 2](b60deee5-c58f-45eb-88a2-23718802e580.xhtml),
    *Generating Drum Sequences with Drums RNN*, and add more details:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以[第二章](b60deee5-c58f-45eb-88a2-23718802e580.xhtml)中提到的图示，*使用鼓RNN生成鼓序列*，并添加更多细节：
- en: '![](img/3cbcba20-c5ba-4ad9-a3a9-a32489c1f1de.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3cbcba20-c5ba-4ad9-a3a9-a32489c1f1de.png)'
- en: We provide a small example vector for the sake of the example. The index range
    for the one-hot encoding is 16, which means we can encode 16 classes only. Remember
    that the encoding for the drum classes had a length of 512\. The `basic_rnn` configuration of
    the Melody RNN model encodes the melody to 36 classes by mapping only a portion
    of the pitches. If we want the full pitch range of 127, we should use the `mono_rnn` configuration.
    The total length of the vector is 55 since we have 3 times a one-hot encoding
    of 16 classes, plus a binary counter of 5 bits, plus 2 lookback flags.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了一个小的示例向量作为例子。该一热编码的索引范围为16，这意味着我们只能编码16个类别。记住，鼓类的编码长度是512。Melody RNN模型的`basic_rnn`配置通过仅映射部分音高将旋律编码为36个类别。如果我们想要完整的127音高范围，则应使用`mono_rnn`配置。向量的总长度是55，因为我们有3次16类的一热编码，加上一个5位的二进制计数器，再加上2个回溯标志。
- en: 'Let''s break it down into five parts and explain the vector''s composition:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将其拆解成五个部分，并解释向量的组成：
- en: First, we encode the **event of the current step**, which is the part we've
    already explained in the previous chapter. In the example vector, the event class
    1 is encoded, meaning the lowest pitch is played at the current step.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们编码**当前步进的事件**，这是我们在上一章中已经解释过的部分。在示例向量中，编码了事件类别1，意味着当前步进时播放的是最低音高。
- en: Then, we encode the **event of the next step for the first lookback**. So, what
    is a lookback? When the encoder-decoder gets initialized, it takes by default
    the lookback distances of *[default steps per bar, default steps per bar * 2]*,
    namely, [16, 32], which corresponds to the last two bars in the 4/4 time signature.
    Now, we are looking at the first lookback, which is 16 steps, or 1 bar, before
    the current step. The encoded event is the next step of that first lookback. In
    the example vector, the event class 6 is encoded, meaning the corresponding pitch
    was played 15 steps ago.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们编码**下一个步进事件的第一次回溯**。那么，什么是回溯呢？当编码器-解码器初始化时，它默认使用*【默认每小节的步进数，默认每小节的步进数 *
    2】*的回溯距离，即[16, 32]，对应于4/4节拍中最后两个小节的位置。现在，我们正在查看第一次回溯，它是距离当前步进16步，或者说1个小节之前的步进。编码的事件是第一次回溯的下一个步进。在示例向量中，编码了事件类别6，意味着15步之前播放了相应的音高。
- en: Then, we encode the **event of the next step for the second lookback**, which
    is 31 steps, or 2 bars minus one step, before the current step. In the example
    vector, the event class 8 is encoded, meaning the corresponding pitch was played
    31 steps ago.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们编码**下一个步进事件的第二次回溯**，这是距离当前步进31步，或者说2个小节减去1步的位置。在示例向量中，编码了事件类别8，意味着31步之前播放了相应的音高。
- en: Then, we encode the **step position in the bar binary counter**. The 5-bit vector
    can encode values from 0 to 15, which is the range of steps we have in 4/4 music.
    This helps the model to learn musical structure by keeping track of its position
    inside a bar. In the example vector, the position in the bar is the third step.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们编码**小节内的步进位置二进制计数器**。这个5位向量可以编码从0到15的值，这就是我们在4/4音乐中所拥有的步进范围。这有助于模型通过追踪其在小节中的位置来学习音乐结构。在示例向量中，小节中的位置是第三步。
- en: Finally, we encode the **repeating lookback flags**, which encodes whether the
    current step is repeating the first lookback or second lookback. It helps to learn
    whether the event is new content or a repetition of previous content. In the example
    vector, there are no repetitions.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们编码**重复回溯标志**，它编码当前步进是否重复了第一次或第二次回溯。这有助于判断事件是新的内容还是先前内容的重复。在示例向量中，没有重复。
- en: Magenta's source code is well documented and you can see this code in the `encoder_decoder.py` file in
    the `magenta.music` module. The class we are looking at is `LookbackEventSequenceEncoderDecoder`
    and the method is `events_to_input`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Magenta的源代码有很好的文档记录，您可以在`magenta.music`模块的`encoder_decoder.py`文件中查看此代码。我们正在查看的类是`LookbackEventSequenceEncoderDecoder`，而方法是`events_to_input`。
- en: Also, if you are wondering how the models are configured, you can go find the
    configuration module. For the Melody RNN, search for the `melody_rnn_model.py`
    file; you'll find, in this module, the configurations we are talking about in
    this section.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想知道模型是如何配置的，可以去查找配置模块。对于 Melody RNN，搜索 `melody_rnn_model.py` 文件；你会在这个模块中找到我们在本节中讨论的配置。
- en: This is important information to feed the model because it enables it to keep
    the musical structure of the sequence. The model also uses custom labels to reduce
    the complexity of the information the model has to learn to represent. Since music
    often has repeating structures on one bar and two bars, the model will use custom
    labels as appropriate, for example, `repeat-1-bar-ago` and `repeat-2-bar-ago`.
    This makes it easier for the model to repeat such phrases without having to store
    them in its memory cell.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这是给模型输入的重要信息，因为它使模型能够保持序列的音乐结构。模型还使用自定义标签来减少模型必须学习表示的信息的复杂性。由于音乐中经常有一小节和两小节的重复结构，模型会根据需要使用自定义标签，例如
    `repeat-1-bar-ago` 和 `repeat-2-bar-ago`。这使得模型能够更容易地重复这些短语，而不必将它们存储在其记忆单元中。
- en: Understanding the attention mask
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解注意力掩码
- en: 'Now that we understand the lookback configuration, let''s have a look at the
    attention configuration. We''ll start by generating a sequence using the following:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了回顾配置，让我们来看看注意力配置。我们将从生成一个序列开始，使用以下配置：
- en: '[PRE9]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We''re generating a longer sequence of 128 steps to try and see the longer
    dependencies in the musical structure. Let''s look at the generated sample for
    the **attention** configuration:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在生成一个更长的 128 步的序列，以便尝试查看音乐结构中的长期依赖关系。让我们看看 **注意力** 配置生成的示例：
- en: '![](img/0035273a-8557-4892-8ba0-d7d1b8a04d22.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0035273a-8557-4892-8ba0-d7d1b8a04d22.png)'
- en: You can see here that, during the eight-bar generation, the model was able to
    keep track of the musical structure for six bars before wandering off. As previously
    stated in this chapter's first section, *Looking at an LSTM memory cell*, attention
    models are relatively new but powerful tools to remember long-term structures.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，在八小节的生成过程中，模型能够在偏离之前跟踪六小节的音乐结构。正如本章第一节中所述，*查看LSTM记忆单元*，注意力模型是相对较新的强大工具，能够记住长期结构。
- en: In Magenta, attention is implemented by looking at the previous *n* steps using
    an attention mechanism. The exact way the attention mechanism works is outside
    the scope of this book, but we'll show an example to have an idea of how it works.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Magenta 中，注意力是通过查看之前的 *n* 步骤来实现的，使用一种注意力机制。注意力机制的具体工作原理超出了本书的范围，但我们会展示一个示例，以便大致了解它是如何工作的。
- en: First, an *n* length vector is calculated using the previous *n* steps and the
    current cell state. This gives us how much attention each step should receive.
    By normalizing it, we get the **attention mask**. For example, it could be *[0.2,
    0.8, 0.5]* for *n* equals 3, with the first element (0.2) corresponding to the
    attention the previous step gets, the second element (0.8) the attention for the
    step before that, and so on.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，计算一个 *n* 长度的向量，使用之前的 *n* 步和当前的单元状态。这将告诉我们每一步应该接收多少注意力。通过对其进行归一化处理，我们得到 **注意力掩码**。例如，当
    *n* 等于 3 时，它可能是 *[0.2, 0.8, 0.5]*，其中第一个元素（0.2）对应于前一步得到的注意力，第二个元素（0.8）是前一步的注意力，依此类推。
- en: 'Then, we take the three previous steps'' output and apply the attention mask
    on them. The output of a step, for example *[0.0, 1.0, 1.0, 0.0]*, represents
    to the encoding of one step. Take a look at this example:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将前面三步的输出应用注意力掩码。一步的输出，例如 *[0.0, 1.0, 1.0, 0.0]*，表示对一步的编码。看看这个示例：
- en: '**Step 1**: *[0.0, 1.0, 1.0, 0.0]* becomes *[0.0, 0.2, 0.2, 0.0]* by applying
    0.2 (the first element of the attention mask) to each value.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 1**：* [0.0, 1.0, 1.0, 0.0] * 通过应用 0.2（注意力掩码的第一个元素）到每个值，变为 *[0.0, 0.2,
    0.2, 0.0]*。'
- en: '**Step 2**: *[0.0, 0.0, 1.0, 0.0]* becomes *[0.0, 0.0, 0.8, 0.0]* by applying
    0.8 (the second element of the attention mask) to each value.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 2**：* [0.0, 0.0, 1.0, 0.0] * 通过应用 0.8（注意力掩码的第二个元素）到每个值，变为 *[0.0, 0.0,
    0.8, 0.0]*。'
- en: '**Step 3**: *[0.5, 0.0, 0.0, 0.0]* becomes *[0.25, 0.0, 0.0, 0.0]* by applying
    0.5 (the third element of the attention mask) to each value.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 3**：* [0.5, 0.0, 0.0, 0.0] * 通过应用 0.5（注意力掩码的第三个元素）到每个值，变为 *[0.25, 0.0,
    0.0, 0.0]*。'
- en: Finally, we sum the resulting vectors and get *[0.25, 0.2, 1.0, 0.0]*, which
    corresponds to the *n* previous outputs, each contributing in a different proportion.
    That resulting vector is then combined with the RNN output for that current step
    and applied to the input of the next step.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将结果向量相加，得到 *[0.25, 0.2, 1.0, 0.0]*，它对应的是 *n* 个前期输出，每个输出在不同的比例下作出贡献。然后，将该结果向量与当前步骤的
    RNN 输出结合，并应用于下一个步骤的输入。
- en: By using attention, we can directly inject information of the previous outputs
    into the current step's calculation, without having to store all of the information
    about the cell's state. This is a powerful mechanism that has usage in many network
    types.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用注意力机制，我们可以直接将前面输出的信息注入当前步骤的计算中，而不必存储关于单元状态的所有信息。这是一个强大的机制，广泛应用于多种网络类型中。
- en: 'In Magenta, you can see when attention is used by searching for the `attn_length`
    argument in the model configuration. If that argument is provided, when the RNN
    cell is instantiated, an attention wrapper is used. You can see the code in `events_rnn_graph.py` in `make_rnn_cell`:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Magenta 中，你可以通过在模型配置中搜索 `attn_length` 参数来看到注意力机制的使用。如果提供了这个参数，当 RNN 单元被实例化时，会使用注意力包装器。你可以在
    `events_rnn_graph.py` 中的 `make_rnn_cell` 查看代码：
- en: '[PRE10]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The length of the attention will define the number of steps (*n*) of the previous
    outputs the attention will take into account during training. You can see that
    the Drums RNN, the Melody RNN, and Improv RNN have attention configurations.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力的长度将定义训练过程中注意力会考虑的前期输出的步数 (*n*)。你可以看到，Drums RNN、Melody RNN 和 Improv RNN 都有注意力配置。
- en: To change the attention configuration during training to 64 steps, for example,
    use the `attn_length=64` hyperparameter.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要在训练期间将注意力配置更改为 64 步，可以使用 `attn_length=64` 超参数。
- en: Losing track of time
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 忘记时间
- en: 'By now, you will have noticed that we lost the initial primer time signature
    of 3/8\. To understand what 3/8 means, let''s go back to what we''ve learned.
    First, let''s remember we have 4 steps per quarter note because this is mainly
    the sample rate in Magenta. Then, we have the following:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你应该注意到我们失去了初始的 3/8 拍拍号。为了理解 3/8 拍的含义，我们可以回顾一下我们学过的内容。首先，记住我们每个四分音符有 4
    步，因为这主要是 Magenta 中的采样率。然后，我们得到以下内容：
- en: In **4**/**4 time**, you have 4 steps per quarter notes times 4 quarter notes
    in a bar (numerator), which equals 16 steps per bar.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**4**/**4 拍**中，每小节有 4 步每四分音符，再乘以每小节的 4 四分音符（分子），等于每小节 16 步。
- en: In **3**/**4 time**, you have 4 steps per quarter notes times 3 quarter notes
    in a bar (numerator), which equals 12 steps per bar.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**3**/**4 拍**中，每小节有 4 步每四分音符，再乘以每小节的 3 四分音符（分子），等于每小节 12 步。
- en: In **3**/**8 time**, you have 2 steps per eight notes times 3 eight notes in
    a bar (numerator), which equals 6 steps per bar. This is because an eight note
    means it is half the time of a quarter note, so we have 2 steps per eight notes.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**3**/**8 拍**中，每小节有 2 步每八分音符，再乘以每小节的 3 八分音符（分子），等于每小节 6 步。这是因为八分音符是四分音符的一半时间，所以每八分音符有
    2 步。
- en: 'Why are we looking into this? We are doing so because time signature doesn''t
    change how many steps or notes we have in a score, but it does change its structure.
    Because the Melody RNN model supposes a certain structure, it won''t be able to
    adapt to a new one. In our case, the model assumes 4/4 time for two reasons:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要研究这个？我们这样做是因为拍号不会改变乐谱中的步骤数或音符数，但它确实会改变其结构。由于 Melody RNN 模型假定了一定的结构，它无法适应新的结构。在我们的例子中，模型假定
    4/4 拍有两个原因：
- en: The binary counter representing the position in the bar is defined for 4/4 time
    because it counts from 0 to 15 for one bar (instead of 0 to 5 in 3/8 time).
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于表示小节位置的二进制计数器是为 4/4 拍定义的，因为它计算的是从 0 到 15 的一个小节（而不是在 3/8 拍中从 0 到 5）。
- en: The default lookback in the model is configured to [16, 32] steps, which are
    the number of steps to lookback in 4/4 time for 1 and 2 bars respectively (instead
    of 6 and 12 in 3/8 time).
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型中的默认回顾长度配置为 [16, 32] 步，这是在 4/4 拍中，1 小节和 2 小节回顾的步数（而不是在 3/8 拍中回顾的 6 步和 12 步）。
- en: Those are the reasons why this model won't understand our primer's time signature,
    and finds structures and repetitions on 4/4 time instead of 3/8 time. You might
    also notice the generate sequence doesn't have a time signature, which, by default,
    we assume is 4/4.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这些就是为什么该模型无法理解我们初始音符的拍号，并且会在 4/4 拍中找到结构和重复模式，而不是 3/8 拍的原因。你可能还注意到生成的序列没有拍号，我们默认假设它是
    4/4 拍。
- en: A time signature is important for the global musical structure of a musical
    piece and for quantization. Different time signatures will change the way the
    notes are rounded to the closest steps since it makes the number of steps change.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 节拍对于音乐作品的全球结构和量化非常重要。不同的节拍会改变音符四舍五入到最近音符的方式，因为它会改变步伐的数量。
- en: You can always get the time signature by using `sequence.time_signatures` on
    a `NoteSequence` instance. This returns a list in Protobuf, on which you can use
    the `add` method, which adds and returns a new `TimeSignature` element.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过在`NoteSequence`实例上使用`sequence.time_signatures`随时获取节拍信息。它返回一个Protobuf列表，你可以在该列表上使用`add`方法，添加并返回一个新的`TimeSignature`元素。
- en: Magenta supports any time signature, but all of the models in Magenta were trained
    in 4/4 time. To generate sequences in another time signature, we'll have to build
    a proper dataset, create a new configuration, and train the model. Refer to [Chapter
    6](1ca56e24-b4d2-40de-b4cf-ae6bbb3c0eef.xhtml), *Data Preparation for Training*,
    and [Chapter 7](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml), *Training Magenta
    Models*, for information on how to do that.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Magenta支持任何节拍，但Magenta中的所有模型都是在4/4拍的节拍下训练的。要在其他节拍下生成序列，我们必须构建一个适当的数据集，创建一个新的配置，并训练模型。有关如何执行此操作的更多信息，请参阅[第6章](1ca56e24-b4d2-40de-b4cf-ae6bbb3c0eef.xhtml)，*训练数据准备*，以及[第7章](6f012812-5c24-44d4-b8cb-ddfd3ed78f5c.xhtml)，*Magenta模型训练*。
- en: Generating polyphony with the Polyphony RNN and Performance RNN
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Polyphony RNN和Performance RNN生成和声
- en: Now that we've talked in depth about melodies, their representation, encoding,
    and configuration, we can talk about polyphony. We'll use two models, the Polyphony
    RNN and Performance RNN, to generate polyphonic music. We'll also look into the
    encoding of such a musical structure since it is different than monophonic encoding.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经深入讨论了旋律、它们的表示、编码和配置，接下来可以讨论和声。我们将使用两个模型，Polyphony RNN和Performance RNN，来生成和声音乐。我们还将研究这种音乐结构的编码，因为它与单声部编码不同。
- en: 'Let''s start by reminding ourselves that we''ve used a primer from Beethoven''s *Fur
    Elise* composition in the last example. We''ll now use the polyphonic version
    of it, which looks like this:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们提醒自己，在上一个示例中，我们使用了贝多芬的*《致爱丽丝》*作为引子。现在我们将使用它的和声音版本，内容如下：
- en: '![](img/43e96a60-efdf-4491-a206-d2d18b43ae20.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/43e96a60-efdf-4491-a206-d2d18b43ae20.png)'
- en: 'You can see that indeed the primer is polyphonic since multiple notes are being
    played at the same time. You should know that using a polyphonic primer in a monophonic
    model will result in an error. You can verify that by calling our `generate` method
    from the previous section using the following parameters:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到引子确实是和声的，因为多个音符同时演奏。你应该知道，在单声部模型中使用和声引子会导致错误。你可以通过使用以下参数调用我们上一节中的`generate`方法来验证这一点：
- en: '[PRE11]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You''ll get the following error because there are too many extracted melodies:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 你会遇到以下错误，因为提取的旋律太多：
- en: '[PRE12]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Differentiating conditioning and injection
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 区分条件和注入
- en: 'Let''s now take the code we''ve already written, our `generate` function, and
    add some content so that we can call it with the Polyphony RNN model:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用我们已经编写的代码——`generate`函数，并添加一些内容，以便可以使用Polyphony RNN模型进行调用：
- en: You can follow this example in the `chapter_03_example_02.py` file in the source
    code of this chapter. There are more comments and content in the source code,
    so you should go check it out.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章的源代码中的`chapter_03_example_02.py`文件中查看这个示例。源代码中有更多的注释和内容，所以你应该去查看它。
- en: You can find the `generate` method in that file. We'll be making more versions
    of this method as we go. The primer for this example is located at `primers/Fur_Elisa_Beethoveen_Polyphonic.mid`.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在那个文件中找到`generate`方法。随着我们的深入，我们将不断创建这个方法的更多版本。这个示例的引子位于`primers/Fur_Elisa_Beethoveen_Polyphonic.mid`。
- en: 'First, we''ll add two new parameters that are specific to this model, `condition_on_primer`
    and `inject_primer_during_generation`. You can modify the generate method signature
    as follow:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将添加两个特定于此模型的新参数，`condition_on_primer`和`inject_primer_during_generation`。你可以按如下方式修改`generate`方法的签名：
- en: '[PRE13]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'And then add the parameters to the generator options:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，向生成器选项中添加参数：
- en: '[PRE14]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Be careful with `inject_primer_during_generation`; it is inverted in the arguments
    map.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 小心使用`inject_primer_during_generation`，它在参数映射中是反向的。
- en: 'We can now launch some generations:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以启动一些生成：
- en: '[PRE15]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: What we've done here is activated only one of the new parameters at a time to
    see its impact on the generated sequence.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里所做的是一次只激活一个新参数，以观察它对生成序列的影响。
- en: 'The `condition_on_primer` parameter is used to provide the primer sequence
    to the RNN before it begins its generation. This needs to be activated for the
    primer to be taken into account. It is useful to start a sequence with, on a certain
    key. You can see it in action in this generation:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`condition_on_primer` 参数用于在 RNN 开始生成之前提供引导序列。必须激活该参数才能使引导序列生效。它对于在某个特定的键上开始一个序列很有用。你可以在这个生成过程中看到它的作用：'
- en: '![](img/a80698da-0a11-483c-a1d7-25740fd4c9cf.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a80698da-0a11-483c-a1d7-25740fd4c9cf.png)'
- en: Notice the generated sequence is in key.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 注意生成的序列是按键生成的。
- en: 'The `inject_primer_during_generation` parameter will inject the primer in the
    generator''s output, which means we''ll basically have the full primer in the
    output. You can see it in action in this generation:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`inject_primer_during_generation` 参数会将引导序列注入生成器的输出，这意味着我们基本上会在输出中看到完整的引导序列。你可以在这个生成过程中看到它的作用：'
- en: '![](img/c80bf417-4f53-40c1-b812-49889ed67c1c.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c80bf417-4f53-40c1-b812-49889ed67c1c.png)'
- en: Notice the generated sequence has the full primer in it. You should try different
    values to see their impact on the generated sequence.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 注意生成的序列包含完整的引导序列。你应该尝试不同的值，看看它们对生成序列的影响。
- en: Explaining the polyphonic encoding
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释多声部编码
- en: Now that we saw a generated polyphonic sequence, let's look at how this type
    of sequence gets generated. First, let's look at the `PolyphonyRnnModel` model in
    the module, `polyphony_model.py`. We first notice that the model doesn't define
    anything new, which means the generation's code is the same as the previous chapter,
    defined in the *Understanding the generation algorithm* section.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们看到一个生成的多声部序列，接下来让我们看看这种类型的序列是如何生成的。首先，我们看一下模块 `polyphony_model.py` 中的 `PolyphonyRnnModel`
    模型。我们首先注意到该模型没有定义任何新的内容，这意味着生成代码与上一章中的代码是一样的，在 *理解生成算法* 部分中定义的。
- en: What is different is the way the model encodes its one-hot vector using `PolyphonyOneHotEncoding`.
    Now, multiple notes can be played at the same time and a single note can spawn
    multiple steps.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 不同之处在于模型使用 `PolyphonyOneHotEncoding` 对其独热向量的编码方式。现在，多个音符可以同时播放，并且一个音符可以生成多个步骤。
- en: In the Drums RNN encoding, multiples notes could be struck at the same time
    because it encoded a combination of multiple notes to a specific event, but it
    couldn't encode a note that spawned multiple steps since a note didn't have a
    specific marker for start and stop. The Melody RNN encoding is similar in that
    matter.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在鼓 RNN 编码中，可以同时敲击多个音符，因为它将多个音符的组合编码为一个特定的事件，但它无法编码生成多个步骤的音符，因为音符没有特定的开始和结束标记。旋律
    RNN 编码在这方面也类似。
- en: 'Let''s take the first four steps of our previously generated example to see
    how that polyphonic encoding works:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以之前生成的例子中的前四个步骤来查看这个多声部编码是如何工作的：
- en: '![](img/14f1f639-b427-4978-a5ee-94d4eb57377b.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](img/14f1f639-b427-4978-a5ee-94d4eb57377b.png)'
- en: Here, we see 5 notes of pitches, *{69, 45, 52, 57, 60}*, over 4 steps, with
    the first note, 69, spanning two steps. The Polyphony RNN uses five different
    event classes to encode this. For the classes without pitch, used to represent
    the structure of the sequence, you have `START`, `END`, and `STEP_END`. For the
    classes with a pitch, used to represent a note, you have `NEW_NOTE` and `CONTINUED_NOTE`.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到 5 个音高为 *{69, 45, 52, 57, 60}* 的音符，分布在 4 个步骤中，其中第一个音符 69 跨越了两个步骤。Polyphony
    RNN 使用五个不同的事件类来编码这个。对于没有音高的类，用于表示序列的结构，你有 `START`、`END` 和 `STEP_END`。对于带有音高的类，用于表示音符，你有
    `NEW_NOTE` 和 `CONTINUED_NOTE`。
- en: 'Let''s try to encode our sequence:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试编码我们的序列：
- en: '[PRE16]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: What is interesting here is to notice the note continuation on the second step.
    Also, note endings are not explicitly specified; a note will end if, at `CONTINUED_NOTE`, the
    event is not present in the following step. This is different to the encoding
    presented in the next section.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，在第二个步骤中要注意音符的延续。另外，音符的结束并没有明确指定；如果在 `CONTINUED_NOTE` 步骤中，后续步骤中没有出现该事件，音符会结束。这与下一节中介绍的编码方式不同。
- en: 'This sequence gets generated by multiple passes of an RNN generation. This
    is different than what we saw for a monophonic generation since, previously, it
    would take the RNN one step to generate one sequence step. Now, we need approximately
    5 RNN steps to generate one sequence step. You can see that in the console output.
    For this example, we have the following:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这个序列是通过 RNN 生成的多次传递生成的。这与我们之前看到的单声部生成有所不同，因为以前 RNN 生成一个序列步骤只需一步。现在，我们需要大约 5
    步 RNN 才能生成一个序列步骤。你可以在控制台输出中看到这一点。对于这个例子，我们有如下内容：
- en: '[PRE17]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Performance music with the Performance RNN
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Performance RNN 进行表现音乐生成。
- en: Now that we have a grip on the Polyphony RNN, we'll be looking into the Performance
    RNN, a powerful model with more options and pre-trained models than the Polyphony
    RNN. First, let's have a look at the different pre-trained bundles. Remember that
    a pre-trained bundle is associated with a specific configuration. This time, you
    can go see the different configurations in the `performance_model.py` module.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经掌握了 Polyphony RNN，接下来我们将探讨 Performance RNN，它是一个比 Polyphony RNN 更强大的模型，提供更多选项和预训练模型。首先，让我们来看看不同的预训练包。请记住，预训练包与特定的配置相关。这次，你可以在
    `performance_model.py` 模块中查看不同的配置。
- en: In the Performance RNN, a different encoding than the Polyphony RNN is used,
    with new event classes such as `NOTE_ON`  and `NOTE_OFF`. That might sound familiar
    because this is also how MIDI encodes its information.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Performance RNN 中，使用了一种不同于 Polyphony RNN 的编码方式，新的事件类包括 `NOTE_ON` 和 `NOTE_OFF`。这可能听起来很熟悉，因为
    MIDI 也是这样编码信息的。
- en: 'Let''s first look at a couple of configuration to start:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先看看几个配置：
- en: The `performance` configuration supports expressive timing, where the notes
    won't fall exactly on steps beginning and end, giving it a more "human" feel or
    "groove" (we'll be also looking into groove in the following chapter, *Latent
    Space Interpolation with Music VAE*). An event class, `TIME_SHIFT`, is used to
    represent that, which defines an advance in time.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`performance` 配置支持富有表现力的时序，其中音符不会精确地落在开始和结束的步骤上，从而赋予它更具“人性化”的感觉或“律动感”（我们将在下一章中探讨律动感，*使用音乐
    VAE 进行潜空间插值*）。一个事件类，`TIME_SHIFT`，用于表示这一点，它定义了时间上的提前。'
- en: The `performance_with_dynamics` configuration supports note velocity, where
    the notes aren't all played with the same force. An event class, `VELOCITY`, is
    used to represent that.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`performance_with_dynamics` 配置支持音符力度，其中音符不会都以相同的力度演奏。一个事件类，`VELOCITY`，用于表示这一点。'
- en: Those two additions are important in generating expressive sequences that are
    closer to what a human player would do.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个附加项在生成更接近人类演奏的富有表现力的序列时非常重要。
- en: 'Now, let''s look at two more configurations:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看两个更多的配置：
- en: The `density_conditioned_performance_with_dynamics` configuration supports density
    conditioning, where the quantity of generated notes can be modified.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`density_conditioned_performance_with_dynamics` 配置支持密度调节，其中可以修改生成音符的数量。'
- en: The `pitch_conditioned_performance_with_dynamics` configuration supports pitch
    conditioning, where the pitch distribution of the generated sequence can be controlled.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pitch_conditioned_performance_with_dynamics` 配置支持音高调节，其中可以控制生成序列的音高分布。'
- en: These configurations do not change the encoding but control how the generation
    is executed.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这些配置不会改变编码，但控制生成的执行方式。
- en: For the first configuration, we need to remember our previous example with the
    Polyphony RNN, where multiple RNN steps were needed to generate one sequence step.
    Changing the generation option, `notes_per_second`, will change the number of
    RNN steps for each sequence step, reducing or augmenting the generation density.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个配置，我们需要记住之前关于 Polyphony RNN 的示例，其中生成一个序列步骤需要多个 RNN 步骤。改变生成选项 `notes_per_second`
    将改变每个序列步骤的 RNN 步骤数，从而减少或增加生成的密度。
- en: 'For the second configuration, a histogram can be provided with the relative
    density of each pitch in an octave using the generator option, `pitch_class_histogram`. 
    The histogram is a list of 12 values (there are 12 notes per octave) with a value
    of frequency for each pitch, corresponding to *[C, C#, D, D#, E, F, F#, G, G#,
    A, A#, B]*. For an F Major scale, with F happening twice as much, you would have:
    *[1, 0, 1, 0, 1, 2, 0, 1, 0, 1, 0, 1]*.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个配置，可以通过生成选项 `pitch_class_histogram` 提供一个直方图，显示每个音高在一个八度音程中的相对密度。这个直方图是一个包含
    12 个值的列表（每个八度有 12 个音符），每个音符对应一个频率值，分别对应 *[C, C#, D, D#, E, F, F#, G, G#, A, A#,
    B]*。对于 F 大调音阶，由于 F 出现的频率是其他音符的两倍，直方图将是： *[1, 0, 1, 0, 1, 2, 0, 1, 0, 1, 0, 1]*。
- en: You can see this example in action in the `chapter_03_example_03.py` file in
    the source code of this chapter. We won't be looking at the code here since it
    is similar to the previous two examples.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本章源代码中的 `chapter_03_example_03.py` 文件中看到这个示例的实际应用。我们在这里不讨论代码，因为它与前两个示例类似。
- en: To learn expressive timing and dynamics, these models have been trained on real
    piano performances from the Yamaha e-Piano Competition (you can find them at [www.piano-e-competition.com/midiinstructions.asp](http://www.piano-e-competition.com/midiinstructions.asp)).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 为了学习表现力的时序和动态，这些模型已在雅马哈电子钢琴比赛的真实钢琴表演数据上进行了训练（你可以在[www.piano-e-competition.com/midiinstructions.asp](http://www.piano-e-competition.com/midiinstructions.asp)找到它们）。
- en: Generating expressive timing like a human
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成像人类一样的表现力时序
- en: 'Here is an example of a generation with the Performance RNN, with the pre-trained
    model, `density_conditioned_performance_with_dynamics`, with a parameter of `notes_per_second=8`.
    We''re showing only the generated part, which is four bars after the primer:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用Performance RNN的生成示例，使用了预训练模型`density_conditioned_performance_with_dynamics`，并且参数设置为`notes_per_second=8`。我们仅展示生成的部分，这是引导部分后的四小节：
- en: '![](img/3e75a3d8-12bc-454a-a514-cec205ac79d4.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3e75a3d8-12bc-454a-a514-cec205ac79d4.png)'
- en: 'You will notice a couple of things here:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到几点：
- en: First, the notes do not all have the same height. This is because we can ask
    Visual MIDI to scale the note height according to their velocity. The bigger the
    note, the louder it is. Remember, velocity in MIDI is from 0 to 127\. For example,
    the first note of pitch 71 has a velocity of 77.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，音符的高度并不完全相同。这是因为我们可以让Visual MIDI根据音符的力度来缩放音符的高度。音符越大，声音越响。请记住，MIDI中的力度范围是从0到127。例如，第一个音符的音高为71，力度为77。
- en: 'Second, the notes do not fall directly on bar subdivisions—they start and end
    a bit off, just before or after the steps boundaries. This is possible because
    the model uses a `TIME_SHIFT` event and was trained on a dataset that was played
    by human players, which contained such a groove. This is very interesting and
    different than what we were previously doing: we are not generating sheet music
    anymore; we are generating a performance.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，音符并不直接落在小节的划分上——它们开始和结束时略微偏离，稍早或稍晚于步伐的边界。这是因为模型使用了`TIME_SHIFT`事件，并且它在由人类演奏者演奏的数据集上进行了训练，该数据集包含了这种节奏感。这非常有趣，并且与我们之前的工作有所不同：我们不再生成乐谱；我们在生成的是一种演奏。
- en: Generating a quantized score or generating a groovy performance, both have their
    specific usage, so you'll need to decide which suits best your goals. Because
    of the performance nature of the generated sequence, opening the file in music
    notation software such as MuseScore might look a bit messy.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 生成量化的乐谱或生成有节奏感的演奏，各有其特定的用途，因此你需要根据目标来决定哪种方法最适合。由于生成序列的表演性质，将文件打开在音乐符号软件（如MuseScore）中可能会显得有些杂乱。
- en: Summary
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we looked at generating melodies, using both monophonic and
    polyphonic models.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们探讨了使用单声部和多声部模型生成旋律。
- en: We first started by looking at LSTM cells and their usage in RNNs to keep information
    for a long period of time, using forget, input, and output gates.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先从查看LSTM单元和它们在RNN中的应用开始，LSTM可以使用遗忘、输入和输出门长时间保持信息。
- en: Then, we generated melodies with the Melody RNN, using multiple pre-trained
    models such as basic, lookback, and attention. We saw that the basic model cannot
    learn repeating structure, because its input vector encoding do not contain such
    information. We then looked at the lookback encoding, where step position in bar
    and repeating structure are encoded into the input vector, making it possible
    for the model to learn such information. We finally saw the attention model, where
    the attention mechanism makes it possible to look at multiple previous steps,
    using an attention mask that gives a weight to each step.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用Melody RNN生成了旋律，使用了多个预训练模型，如基础模型、回溯模型和注意力模型。我们发现基础模型无法学习重复结构，因为它的输入向量编码中不包含此类信息。接着我们查看了回溯编码，其中小节中的步态位置和重复结构被编码进输入向量，从而使模型能够学习这些信息。最后，我们看到了注意力模型，在该模型中，注意力机制使得模型能够查看多个前置步骤，使用注意力掩码为每一步赋予权重。
- en: Finally, we generated polyphony using the Polyphony RNN and the Performance
    RNN. In the former model, we learned how polyphony can be encoded in a vector,
    using start and continue events. In the latter model, we learned another polyphony
    encoding, using note on and note off events, similar to what MIDI uses. In the
    Performance RNN, we also learned about expressive generation, both in terms of
    timing and velocity changes.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用Polyphony RNN和Performance RNN生成了多声部音乐。在前者模型中，我们学习了如何使用开始和持续事件将多声部音乐编码为向量。在后者模型中，我们学习了另一种多声部编码方法，使用音符开启和音符关闭事件，类似于MIDI使用的方式。在Performance
    RNN中，我们还学习了表现力的生成，包括时序和力度变化。
- en: As we now know, expressive timing is what gives the music a human feel, where
    the notes do not fall on predefined times. This is what we sometimes call groove,
    and we'll be looking more into this subject in the next chapter, *Latent Space
    Interpolation with Music VAE*. We'll also be looking at score interpolation, which
    makes it possible to gradually transition from one score to another.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们现在所知，表现性的时序感使得音乐具有人的感觉，其中音符不会落在预定的时间点上。这就是我们有时所说的 groove，我们将在下一章《使用音乐 VAE
    进行潜在空间插值》中进一步探讨这个主题。我们还将研究乐谱插值，它使得从一个乐谱平滑过渡到另一个乐谱成为可能。
- en: Questions
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are the main problems RNN suffers from when learning, and what are the
    solutions brought by LSTMs?
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RNN 在学习过程中遇到的主要问题是什么？LSTM 提供了哪些解决方案？
- en: What is a simpler alternative to LSTM memory cells? What are their advantages
    and disadvantages?
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LSTM 记忆单元的一个更简单的替代方案是什么？它们的优缺点是什么？
- en: You want to configure the lookback encoder-decoder from the Melody RNN to learn
    structures with a 3/4 time signature. How big is the binary step counter? How
    are the lookback distances configured for 3 lookback distances?
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你想配置 Melody RNN 的回溯编码器-解码器，以学习 3/4 拍子的结构。二进制步进计数器的大小是多少？对于 3 个回溯距离，回溯距离是如何配置的？
- en: You have the resulting vector, *[0.10, 0.50, 0.00, 0.25],* from the applied
    attention mask of *[0.1, 0.5]*, with *n = 2*, and the previous step 1 of *[1,
    0, 0, 0]* and step 2 of *[0, 1, 0, x].* What is the value of *x*?
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你得到了以下结果向量，* [0.10, 0.50, 0.00, 0.25]*，这是应用了注意力掩码 *[0.1, 0.5]* 后得到的，且 *n = 2*，之前的第
    1 步为 *[1, 0, 0, 0]*，第 2 步为 *[0, 1, 0, x]*。那么 *x* 的值是多少？
- en: 'You have the following the Polyphony RNN encoding: *{ (START), (NEW_NOTE, 67),
    (NEW_NOTE, 64), (NEW_NOTE, 60), (STEP_END), (CONTINUED_NOTE, 67), (CONTINUED_NOTE,
    64), (CONTINUED_NOTE, 60), (STEP_END), (CONTINUED_NOTE, 67), (CONTINUED_NOTE,
    64), (CONTINUED_NOTE, 60), (STEP_END), (CONTINUED_NOTE, 67), (CONTINUED_NOTE,
    64), (CONTINUED_NOTE, 60), (STEP_END), (END) }*. What is being played?'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你有以下的 Polyphony RNN 编码：*{ (START), (NEW_NOTE, 67), (NEW_NOTE, 64), (NEW_NOTE,
    60), (STEP_END), (CONTINUED_NOTE, 67), (CONTINUED_NOTE, 64), (CONTINUED_NOTE,
    60), (STEP_END), (CONTINUED_NOTE, 67), (CONTINUED_NOTE, 64), (CONTINUED_NOTE,
    60), (STEP_END), (CONTINUED_NOTE, 67), (CONTINUED_NOTE, 64), (CONTINUED_NOTE,
    60), (STEP_END), (END) }*。这里播放的是什么？
- en: What event would be used to end a note of pitch 56 in the Polyphony RNN encoding?
    And in the Performance RNN?
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Polyphony RNN 编码中，结束音高为 56 的音符会使用什么事件？在 Performance RNN 中又是怎样的？
- en: What are two components of a generated score that would give them a more human
    fell? What model and arguments would you use to achieve that?
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成的音符中，有哪两个组成部分能使其更具人类感觉？你会使用什么模型和参数来实现这一点？
- en: When using the `notes_per_seconds` parameter in the `density_conditioned_performance_with_dynamics` model,
    what is the impact on the generation algorithm?
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在使用 `notes_per_seconds` 参数时，`density_conditioned_performance_with_dynamics`
    模型会对生成算法产生什么影响？
- en: Further reading
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: '**Learning Long-Term Dependencies with Gradient Descent is Difficult**: A paper
    (1994) describing the difficulties of RNN to learn long-term dependencies in practice
    ([ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf](http://ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf))'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用梯度下降学习长期依赖关系是困难的**：一篇关于 RNN 学习长期依赖关系困难的论文（1994）（[ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf](http://ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf))'
- en: '**Long Short-Term Memory**: An original paper (1997) on LSTM ([www.bioinf.jku.at/publications/older/2604.pdf](http://www.bioinf.jku.at/publications/older/2604.pdf))'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**长短时记忆**：关于 LSTM 的原始论文（1997）（[www.bioinf.jku.at/publications/older/2604.pdf](http://www.bioinf.jku.at/publications/older/2604.pdf))'
- en: '**Understanding LSTM Networks**: An excellent article explaining in detail
    LSTM memory cells, which contains more information than this chapter ([colah.github.io/posts/2015-08-Understanding-LSTMs/](https://colah.github.io/posts/2015-08-Understanding-LSTMs/))'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**理解 LSTM 网络**：一篇优秀的文章，详细解释了 LSTM 记忆单元，包含的信息比这一章节更多（[colah.github.io/posts/2015-08-Understanding-LSTMs/](https://colah.github.io/posts/2015-08-Understanding-LSTMs/))'
- en: '**Illustrated Guide to LSTM''s and GRU''s: A step by step explanation**: an
    excellent in-depth article about LSTM and GRU ([towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21))'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LSTM 和 GRU 的插图指南：逐步解释**：一篇关于 LSTM 和 GRU 的优秀深度文章（[towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21))'
- en: '**Understanding LSTM and its diagrams**: Another excellent article on LSTMs
    ([medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714#.swstv6z61](https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714#.swstv6z61))'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**理解LSTM及其图示**：另一篇关于LSTM的优秀文章 ([medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714#.swstv6z61](https://medium.com/mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714#.swstv6z61))'
- en: '**Generating Long-Term Structure in Songs and Stories**: An excellent blog
    post from Magenta''s developers looking into the lookback and attention models
    of the Melody RNN ([magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn/](https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn/))'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成歌曲和故事中的长期结构**：来自Magenta开发者的一篇优秀博客文章，探讨了Melody RNN的回顾模型和注意力模型 ([magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn/](https://magenta.tensorflow.org/2016/07/15/lookback-rnn-attention-rnn/))'
- en: '**Attention Is All You Need**: A paper (2017) on the usage and performance
    of the attention mechanism ([arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Attention Is All You Need**：一篇关于注意力机制使用和性能的论文（2017年） ([arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762))'
