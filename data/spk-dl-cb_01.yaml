- en: Setting Up Spark for Deep Learning Development
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 Spark 进行深度学习开发
- en: 'In this chapter, the following recipes will be covered:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: Downloading an Ubuntu Desktop image
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载 Ubuntu Desktop 镜像
- en: Installing and configuring Ubuntu with VMWare Fusion on macOS
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 macOS 上使用 VMWare Fusion 安装和配置 Ubuntu
- en: Installing and configuring Ubuntu with Oracle VirtualBox on Windows
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Windows 上使用 Oracle VirtualBox 安装和配置 Ubuntu
- en: Installing and configuring Ubuntu Desktop for Google Cloud Platform
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Google Cloud Platform 上安装和配置 Ubuntu Desktop
- en: Installing and configuring Spark and prerequisites on Ubuntu Desktop
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Ubuntu Desktop 上安装和配置 Spark 及其先决条件
- en: Integrating Jupyter notebooks with Spark
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 Jupyter 笔记本与 Spark 集成
- en: Starting and configuring a Spark cluster
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动和配置 Spark 集群
- en: Stopping a Spark cluster
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 停止 Spark 集群
- en: Introduction
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Deep learning is the focused study of machine learning algorithms that deploy
    neural networks as their main method of learning. Deep learning has exploded onto
    the scene just within the last couple of years. Microsoft, Google, Facebook, Amazon,
    Apple, Tesla and many other companies are all utilizing deep learning models in
    their apps, websites, and products. At the same exact time, Spark, an in-memory
    compute engine running on top of big data sources, has made it easy to process
    volumes of information at record speeds and ease. In fact, Spark has now become
    the leading big data development tool for data engineers, machine learning engineers,
    and data scientists.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习算法的专注研究，采用神经网络作为其主要学习方法。深度学习在过去几年迅速崛起。微软、谷歌、Facebook、亚马逊、苹果、特斯拉及许多其他公司都在他们的应用程序、网站和产品中使用深度学习模型。与此同时，Spark，作为一个基于内存的大数据计算引擎，极大简化了以创纪录的速度和轻松度处理海量信息的过程。事实上，Spark
    已经成为数据工程师、机器学习工程师和数据科学家首选的大数据开发工具。
- en: Since deep learning models perform better with more data, the synergy between
    Spark and deep learning allowed for a perfect marriage. Almost as important as
    the code used to execute deep learning algorithms is the work environment that
    enables optimal development. Many talented minds are eager to develop neural networks
    to help answer important questions in their research. Unfortunately, one of the
    greatest barriers to the development of deep learning models is access to the
    necessary technical resources required to learn on big data. The purpose of this
    chapter is to create an ideal virtual development environment for deep learning
    on Spark.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于深度学习模型在处理更多数据时表现更好，Spark 与深度学习的协同作用促成了二者的完美结合。与执行深度学习算法的代码几乎同等重要的是，能够实现最佳开发的工作环境。许多才俊渴望开发神经网络，以帮助解答研究中的重要问题。不幸的是，深度学习模型开发面临的最大障碍之一是缺乏必要的技术资源来在大数据上进行学习。本章的目的是为在
    Spark 上进行深度学习开发创建一个理想的虚拟开发环境。
- en: Downloading an Ubuntu Desktop image
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载 Ubuntu Desktop 镜像
- en: Spark can be set up for all types of operating systems, whether they reside
    on-premise or in the cloud. For our purposes, Spark will be installed on a Linux-based
    virtual machine with Ubuntu as the operating system. There are several advantages
    to using Ubuntu as the go-to virtual machine, not least of which is cost. Since
    they are based on open source software, Ubuntu operating systems are free to use
    and do not require licensing. Cost is always a consideration and one of the main
    goals of this publication is to minimize the financial footprint required to get
    started with deep learning on top of a Spark framework.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Spark 可以为各种操作系统进行配置，无论它们是本地部署还是云端部署。对于我们的目的，Spark 将安装在基于 Linux 的虚拟机上，操作系统为 Ubuntu。选择
    Ubuntu 作为虚拟机的操作系统有几个优势，最重要的一个就是成本。由于 Ubuntu 基于开源软件，因此它是免费的，不需要许可费用。成本始终是一个考虑因素，本书的主要目标之一是尽量减少启动
    Spark 框架上深度学习所需的财务支出。
- en: Getting ready
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'There are some minimum recommendations required for downloading the image file:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 下载镜像文件需要满足一些最低推荐要求：
- en: Minimum of 2 GHz dual-core processor
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最低要求 2 GHz 双核处理器
- en: Minimum of 2 GB system memory
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最低要求 2 GB 系统内存
- en: Minimum of 25 GB of free hard drive space
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少 25 GB 的空闲硬盘空间
- en: How to do it...
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Follow the steps in the recipe to download an Ubuntu Desktop image:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤下载 Ubuntu Desktop 镜像：
- en: 'In order to create a virtual machine of Ubuntu Desktop, it is necessary to
    first download the file from the official website: [https://www.ubuntu.com/download/desktop.](https://www.ubuntu.com/download/desktop)'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了创建Ubuntu Desktop虚拟机，必须首先从官方网站下载该文件：[https://www.ubuntu.com/download/desktop.](https://www.ubuntu.com/download/desktop)
- en: As of this writing, Ubuntu Desktop 16.04.3 is the most recent available version
    for download.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 截至本文撰写时，Ubuntu Desktop 16.04.3是最新的可供下载版本。
- en: 'Access the following file in a `.iso` format once the download is complete:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载完成后，访问以下`.iso`格式的文件：
- en: '`ubuntu-16.04.3-desktop-amd64.iso`'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`ubuntu-16.04.3-desktop-amd64.iso`'
- en: How it works...
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Virtual environments provide an optimal development workspace by isolating the
    relationship to the physical or host machine. Developers may be using all types
    of machines for their host environments such as a MacBook running macOS, a Microsoft
    Surface running Windows or even a virtual machine on the cloud with Microsoft
    Azure or AWS; however, to ensure consistency within the output of the code executed,
    a virtual environment within Ubuntu Desktop will be deployed that can be used
    and shared among a wide variety of host platforms.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟环境通过隔离与物理或主机机器的关系，为开发者提供了一个理想的开发工作空间。开发者可能使用各种不同的机器作为主机环境，例如运行macOS的MacBook、运行Windows的Microsoft
    Surface，甚至是运行在云上的虚拟机，如Microsoft Azure或AWS；然而，为了确保代码执行的输出结果的一致性，将在Ubuntu Desktop中部署一个虚拟环境，该环境可以在多种主机平台上使用和共享。
- en: There's more...
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'There are several options for desktop virtualization software, depending on
    whether the host environment is on a Windows or a macOS. There are two common
    software applications for virtualization when using macOS:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 根据主机环境是Windows还是macOS，桌面虚拟化软件有几种选择。当使用macOS时，有两种常见的虚拟化软件应用：
- en: VMWare Fusion
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VMWare Fusion
- en: Parallels
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Parallels
- en: See also
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: To learn more about Ubuntu Desktop, you can visit [https://www.ubuntu.com/desktop](https://www.ubuntu.com/desktop).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于Ubuntu Desktop的信息，可以访问 [https://www.ubuntu.com/desktop](https://www.ubuntu.com/desktop)。
- en: Installing and configuring Ubuntu with VMWare Fusion on macOS
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在macOS上使用VMWare Fusion安装和配置Ubuntu
- en: This section will focus on building a virtual machine using an Ubuntu operating
    system with **VMWare Fusion**.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将重点介绍使用**VMWare Fusion**构建基于Ubuntu操作系统的虚拟机。
- en: Getting ready
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备中
- en: 'A previous installation of VMWare Fusion is required on your system. If you
    do not currently have this, you can download a trial version from the following
    website:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 你的系统中需要先安装VMWare Fusion。如果你目前没有安装，可以从以下网站下载试用版：
- en: '[https://www.vmware.com/products/fusion/fusion-evaluation.html](https://www.vmware.com/products/fusion/fusion-evaluation.html)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.vmware.com/products/fusion/fusion-evaluation.html](https://www.vmware.com/products/fusion/fusion-evaluation.html)'
- en: How to do it...
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Follow the steps in the recipe to configure Ubuntu with VMWare Fusion on macOS:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 按照下面的步骤，在macOS上使用VMWare Fusion配置Ubuntu：
- en: 'Once VMWare Fusion is up and running, click on the *+* button on the upper-left-hand
    side to begin the configuration process and select New..., as seen in the following
    screenshot:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦VMWare Fusion启动并运行，点击左上角的*+*按钮开始配置过程，选择“新建...”选项，如下图所示：
- en: '![](img/de3baeba-f285-420c-bb37-c88f4fe56c6b.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/de3baeba-f285-420c-bb37-c88f4fe56c6b.png)'
- en: 'Once the selection has been made, select the option to Install from Disk or
    Image, as seen in the following screenshot:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦选择完成，选择从磁盘或镜像安装的选项，如下图所示：
- en: '![](img/01d7eef1-bcf5-4e26-bbf6-112b89a9ed07.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/01d7eef1-bcf5-4e26-bbf6-112b89a9ed07.png)'
- en: 'Select the operating system''s `iso` file that was downloaded from the Ubuntu
    Desktop website, as seen in the following screenshot:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择从Ubuntu Desktop网站下载的操作系统`iso`文件，如下图所示：
- en: '![](img/c8da4a79-082f-40e7-91f7-4dc24cfc3723.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c8da4a79-082f-40e7-91f7-4dc24cfc3723.png)'
- en: 'The next step will ask whether you want to choose Linux Easy Install. It is
    recommended to do so, as well as to incorporate a Display Name/Password combination
    for the Ubuntu environment, as seen in the following screenshot:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步将询问你是否选择Linux Easy Install。建议选择此选项，并为Ubuntu环境设置显示名称/密码组合，如下图所示：
- en: '![](img/ad3cc8d3-194b-4985-b259-de865c1cd1b2.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad3cc8d3-194b-4985-b259-de865c1cd1b2.png)'
- en: 'The configuration process is almost complete. A Virtual Machine Summary is
    displayed with the option to Customize Settings to increase the Memory and Hard
    Disk, as seen in the following screenshot:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置过程几乎完成。显示虚拟机摘要，并提供自定义设置的选项，以增加内存和硬盘，如下图所示：
- en: '![](img/81476499-034d-4a51-9dc7-0694f7c89a21.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/81476499-034d-4a51-9dc7-0694f7c89a21.png)'
- en: 'Anywhere from 20 to 40 GB hard disk space is sufficient for the virtual machine;
    however, bumping up the memory to either 2 GB or even 4 GB will assist with the
    performance of the virtual machine when executing Spark code in later chapters.
    Update the memory by selecting Processors and Memory under the Settings of the
    virtual machine and increasing the Memory to the desired amount, as seen in the
    following screenshot:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虚拟机的硬盘空间从 20 GB 到 40 GB 都足够；然而，将内存提升至 2 GB 或 4 GB 将有助于提高虚拟机在后续章节中执行 Spark 代码时的性能。通过选择虚拟机设置中的处理器和内存选项，将内存更新为所需的大小，如下图所示：
- en: '![](img/ac19e635-36e1-493e-99ec-7e8c0f63c90d.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ac19e635-36e1-493e-99ec-7e8c0f63c90d.png)'
- en: How it works...
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The setup allows for manual configuration of the settings necessary to get Ubuntu
    Desktop up and running successfully on VMWare Fusion. The memory and hard drive
    storage can be increased or decreased based on the needs and availability of the
    host machine.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 该设置允许手动配置必要的设置，以便成功在 VMWare Fusion 上启动 Ubuntu Desktop。可以根据主机机器的需要和可用性增加或减少内存和硬盘存储。
- en: There's more...
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多内容...
- en: 'All that is remaining is to fire up the virtual machine for the first time,
    which initiates the installation process of the system onto the virtual machine.
    Once all the setup is complete and the user has logged in, the Ubuntu virtual
    machine should be available for development, as seen in the following screenshot:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的就是第一次启动虚拟机，这将启动系统的安装过程。一旦所有设置完成并且用户登录后，Ubuntu 虚拟机就可以用于开发了，如下图所示：
- en: '![](img/58e6f288-6ea4-45fa-995f-0000b1aaf28e.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/58e6f288-6ea4-45fa-995f-0000b1aaf28e.png)'
- en: See also
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'Aside from VMWare Fusion, there is also another product that offers similar
    functionality on a Mac. It is called Parallels Desktop for Mac. To learn more
    about VMWare and Parallels, and decide which program is a better fit for your
    development, visit the following websites:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 VMWare Fusion 外，Mac 上还有另一个提供类似功能的产品，叫做 Parallels Desktop for Mac。要了解有关 VMWare
    和 Parallels 的更多信息，并决定哪个程序更适合你的开发需求，请访问以下网站：
- en: '[https://www.vmware.com/products/fusion.html](https://www.vmware.com/products/fusion.html)
    to download and install VMWare Fusion for Mac'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.vmware.com/products/fusion.html](https://www.vmware.com/products/fusion.html)
    下载并安装 Mac 版 VMWare Fusion'
- en: '[https://parallels.com](https://parallels.com) to download and install the
    Parallels Desktop for Mac'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://parallels.com](https://parallels.com) 下载并安装 Mac 版 Parallels Desktop'
- en: Installing and configuring Ubuntu with Oracle VirtualBox on Windows
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Windows 上使用 Oracle VirtualBox 安装和配置 Ubuntu
- en: Unlike with macOS, there are several options to virtualize systems within Windows.
    This mainly has to do with the fact that virtualization on Windows is very common
    as most developers are using Windows as their host environment and need virtual
    environments for testing purposes without affecting any of the dependencies that
    rely on Windows.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 与 macOS 不同，Windows 有多个选项可以虚拟化系统。这主要是因为在 Windows 上进行虚拟化非常常见，因为大多数开发者使用 Windows
    作为主机环境，并需要虚拟环境进行测试，而不影响依赖 Windows 的任何依赖项。
- en: Getting ready
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: VirtualBox from Oracle is a common virtualization product and is free to use. Oracle
    VirtualBox provides a straightforward process to get an Ubuntu Desktop virtual
    machine up and running on top of a Windows environment.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Oracle 的 VirtualBox 是一种常见的虚拟化产品，可以免费使用。Oracle VirtualBox 提供了一个简单的流程，可以在 Windows
    环境中快速启动并运行 Ubuntu Desktop 虚拟机。
- en: How to do it...
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Follow the steps in this recipe to configure Ubuntu with **VirtualBox** on
    Windows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤使用 **VirtualBox** 在 Windows 上配置 Ubuntu：
- en: 'Initiate an Oracle VM VirtualBox Manager. Next, create a new virtual machine
    by selecting the New icon and specify the Name, Type, and Version of the machine,
    as seen in the following screenshot:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 Oracle VM VirtualBox 管理器。接下来，点击新建图标创建一个新的虚拟机，并指定虚拟机的名称、类型和版本，如下图所示：
- en: '![](img/bf279c58-86ff-4159-97af-87ede0451a29.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bf279c58-86ff-4159-97af-87ede0451a29.png)'
- en: 'Select Expert Mode as several of the configuration steps will get consolidated,
    as seen in the following screenshot:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择专家模式，因为在配置步骤中有几个步骤将被合并，如下图所示：
- en: '![](img/e7276b57-d427-46ff-8ee4-ab5fccf0dc49.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7276b57-d427-46ff-8ee4-ab5fccf0dc49.png)'
- en: Ideal memory size should be set to at least `2048` MB, or preferably `4096`
    MB, depending on the resources available on the host machine.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 理想的内存大小应至少设置为 `2048` MB，或者根据主机资源，最好设置为 `4096` MB。
- en: 'Additionally, set an optimal hard disk size for an Ubuntu virtual machine performing
    deep learning algorithms to at least 20 GB, if not more, as seen in the following
    screenshot:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，为执行深度学习算法的 Ubuntu 虚拟机设置一个至少为 20 GB 的最佳硬盘大小（如果不是更多），如下面的截图所示：
- en: '![](img/771301d8-e257-4669-9ea2-da6a1fe610b6.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/771301d8-e257-4669-9ea2-da6a1fe610b6.png)'
- en: 'Point the virtual machine manager to the start-up disk location where the Ubuntu
    `iso` file was downloaded to and then Start the creation process, as seen in the
    following screenshot:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将虚拟机管理器指向下载了 Ubuntu `iso` 文件的启动盘位置，然后开始创建过程，如下图所示：
- en: '![](img/b8ba0256-a82f-4945-be82-ebd713d814d9.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b8ba0256-a82f-4945-be82-ebd713d814d9.png)'
- en: 'After allotting some time for the installation, select the Start icon to complete
    the virtual machine and get it ready for development as seen in the following
    screenshot:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装完成后，选择开始图标以完成虚拟机并准备好进行开发，如下图所示：
- en: '![](img/accc7615-2469-412b-815a-dc5e57ca3773.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/accc7615-2469-412b-815a-dc5e57ca3773.png)'
- en: How it works...
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The setup allows for manual configuration of the settings necessary to get Ubuntu
    Desktop up and running successfully on Oracle VirtualBox. As was the case with
    VMWare Fusion, the memory and hard drive storage can be increased or decreased
    based on the needs and availability of the host machine.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 设置允许手动配置必要的设置，以便在 Oracle VirtualBox 上成功运行 Ubuntu 桌面。与 VMWare Fusion 一样，内存和硬盘存储可以根据主机的需要和可用性进行增加或减少。
- en: There's more...
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Please note that some machines that run Microsoft Windows are not set up by
    default for virtualization and users may receive an initial error indicating the
    VT-x is not enabled. This can be reversed and virtualization may be enabled in
    the BIOS during a reboot.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，一些运行 Microsoft Windows 的机器默认未设置为虚拟化，用户可能会收到一条初始错误提示，表明 VT-x 未启用。这个问题可以通过重新启动时进入
    BIOS 并启用虚拟化来解决。
- en: See also
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: To learn more about Oracle VirtualBox and decide whether or not it is a good
    fit, visit the following website and select Windows hosts to begin the download
    process: [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 Oracle VirtualBox 的信息并决定它是否适合使用，请访问以下网站并选择 Windows 主机以开始下载过程：[https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads)。
- en: Installing and configuring Ubuntu Desktop for Google Cloud Platform
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为 Google Cloud Platform 安装和配置 Ubuntu 桌面
- en: Previously, we saw how Ubuntu Desktop could be set up locally using VMWare Fusion.
    In this section, we will learn how to do the same on **Google Cloud Platform**.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们看到如何使用 VMWare Fusion 在本地设置 Ubuntu 桌面。在本节中，我们将学习如何在 **Google Cloud Platform**
    上执行相同的操作。
- en: Getting ready
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The only requirement is a Google account username. Begin by logging in to your
    Google Cloud Platform using your Google account. Google provides a free 12-month
    subscription with $300 credited to your account. The setup will ask for your bank
    details; however, Google will not charge you for anything without explicitly letting
    you know first. Go ahead and verify your bank account and you are good to go.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的要求是 Google 帐号用户名。首先，使用 Google 帐号登录到 Google Cloud Platform。Google 提供一个免费的
    12 个月订阅，并为您的账户充值 300 美元。设置过程中会要求您提供银行信息；但 Google 不会在未明确告知的情况下收费。请继续验证您的银行账户，然后就可以开始了。
- en: How to do it...
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Follow the steps in the recipe to configure Ubuntu Desktop for Google Cloud
    Platform:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 按照步骤配置 Ubuntu 桌面以适配 Google Cloud Platform：
- en: 'Once logged in to your Google Cloud Platform, access a dashboard that looks
    like the one in the following screenshot:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到 Google Cloud Platform 后，访问一个类似于以下截图的仪表板：
- en: '![](img/20aa4814-55f9-4f4d-9983-1f90bcacf666.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/20aa4814-55f9-4f4d-9983-1f90bcacf666.png)'
- en: Google Cloud Platform Dashboard
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud Platform 仪表板
- en: 'First, click on the product services button in the top-left-hand corner of
    your screen. In the drop-down menu, under Compute, click on VM instances, as shown
    in the following screenshot:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，点击屏幕左上角的产品服务按钮。在下拉菜单中，在计算下点击 VM 实例，如下图所示：
- en: '![](img/76ecccfc-6e47-4c0b-9f1f-7184d9a438da.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/76ecccfc-6e47-4c0b-9f1f-7184d9a438da.png)'
- en: Create a new instance and name it. We are naming it `ubuntuvm1` in our case.
    Google Cloud automatically creates a project while launching an instance and the
    instance will be launched under a project ID. The project may be renamed if required.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的实例并命名。我们在此案例中命名为 `ubuntuvm1`。在启动实例时，Google Cloud 会自动创建一个项目，实例将会在该项目 ID
    下启动。项目可以根据需要重新命名。
- en: After clicking on **Create Instance**, select the zone/area you are located
    in.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **创建实例** 后，选择您所在的区域。
- en: Select **Ubuntu 16.04LTS** under the boot disk as this is the operating system
    that will be installed in the cloud. Please note that LTS stands for version,
    and will have long-term support from Ubuntu’s developers.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在启动磁盘下选择 **Ubuntu 16.04LTS**，这是将在云中安装的操作系统。请注意，LTS 代表版本，并且会获得 Ubuntu 开发者的长期支持。
- en: 'Next, under the boot disk options, select SSD persistent disk and increase
    the size to 50 GB for some added storage space for the instance, as shown in the
    following screenshot:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在启动磁盘选项下，选择 SSD 持久磁盘，并将大小增加到 50 GB，为实例增加一些存储空间，如下截图所示：
- en: '![](img/83579b58-9f04-47bf-a163-122c32d5c7ab.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/83579b58-9f04-47bf-a163-122c32d5c7ab.png)'
- en: Next, set Access scopes to **Allow full access to all Cloud APIs**.
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将访问范围设置为 **允许对所有 Cloud API 的完全访问**。
- en: 'Under firewall, please check to **allow HTTP traffic** as well as **allow HTTPS
    traffic**, as shown in the following screenshot:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在防火墙下，请勾选 **允许 HTTP 流量** 和 **允许 HTTPS 流量**，如下面截图所示：
- en: '![](img/78a55da5-aaab-47a9-9b2a-ecce5f968e63.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/78a55da5-aaab-47a9-9b2a-ecce5f968e63.png)'
- en: Selecting options  Allow HTTP traffic and HTTPS Traffic
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 选择允许 HTTP 流量和 HTTPS 流量
- en: Once the instance is configured as shown in this section, go ahead and create
    the instance by clicking on the Create button.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦按照本节中所示配置完实例，点击创建按钮来创建实例。
- en: After clicking on the Create button, you will notice that the instance gets
    created with a unique internal as well as external IP address. We will require
    this at a later stage. SSH refers to secure shell tunnel, which is basically an
    encrypted way of communicating in client-server architectures. Think of it as
    data going to and from your laptop, as well as going to and from Google's cloud
    servers, through an encrypted tunnel.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 点击创建按钮后，您会发现实例被创建，且具有唯一的内部和外部 IP 地址。我们将在后续阶段使用这个 IP 地址。SSH 指的是安全的 shell 隧道，本质上是一种加密的客户端-服务器通信方式。可以把它想象成数据从您的笔记本到
    Google 的云服务器，经过加密隧道来回传输。
- en: 'Click on the newly created instance. From the drop-down menu, click on **open
    in browser window**, as shown in the following screenshot:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击新创建的实例。在下拉菜单中，点击 **在浏览器窗口中打开**，如下面截图所示：
- en: '![](img/ce7e2d0d-b7ab-43e3-bc6f-b704754b2e87.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ce7e2d0d-b7ab-43e3-bc6f-b704754b2e87.png)'
- en: 'You will see that Google opens up a shell/terminal in a new window, as shown
    in the following screenshot:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您会看到 Google 打开一个新的 shell/终端窗口，如下截图所示：
- en: '![](img/0bc13f24-6ab6-4142-af80-ec149762f03f.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0bc13f24-6ab6-4142-af80-ec149762f03f.png)'
- en: 'Once the shell is open, you should have a window that looks like the following
    screenshot:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦打开 shell，您应该看到如下截图所示的窗口：
- en: '![](img/0f75c9ed-6771-467c-90aa-a142fda0531d.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0f75c9ed-6771-467c-90aa-a142fda0531d.png)'
- en: 'Type the following commands in the Google cloud shell:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Google 云 Shell 中输入以下命令：
- en: '[PRE0]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When presented with a prompt to continue or not, type `y` and select ENTER, as
    shown in the following screenshot:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当提示是否继续时，输入 `y` 然后按 ENTER，如下截图所示：
- en: '![](img/5f678a2c-6ce3-4ce1-a8f2-d4e8e1d25159.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f678a2c-6ce3-4ce1-a8f2-d4e8e1d25159.png)'
- en: 'Once done with the preceding steps, type the following commands to set up the
    `vncserver` and allow connections to the local shell:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成前面的步骤后，输入以下命令来设置 `vncserver` 并允许连接到本地 shell：
- en: '[PRE1]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, launch the server by typing the following command:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，通过输入以下命令来启动服务器：
- en: '[PRE2]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will prompt you to enter a password, which will later be used to log in
    to the Ubuntu Desktop virtual machine. This password is limited to eight characters
    and needs to be set and verified, as shown in the following screenshot:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将提示您输入密码，该密码稍后将用于登录到 Ubuntu Desktop 虚拟机。密码限制为八个字符，并需要设置和验证，如下面截图所示：
- en: '![](img/3fd3e60e-3169-458d-b65c-9d7fd18d986f.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3fd3e60e-3169-458d-b65c-9d7fd18d986f.png)'
- en: 'A startup script is automatically generated by the shell, as shown in the following
    screenshot. This startup script can be accessed and edited by copying and pasting
    its `PATH` in the following manner:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: shell 会自动生成一个启动脚本，如下面截图所示。可以通过复制并粘贴其 `PATH` 来访问和编辑该启动脚本：
- en: '![](img/bf39c16f-7c13-4754-9580-00e19e8cd583.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bf39c16f-7c13-4754-9580-00e19e8cd583.png)'
- en: 'In our case, the command to view and edit the script is:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们的例子中，查看和编辑脚本的命令是：
- en: '[PRE3]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This `PATH` may be different in each case. Ensure you set the right `PATH`.
    The `vim` command opens up the script in the text editor on a Mac.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`PATH`在不同情况下可能不同，请确保设置正确的`PATH`。在Mac上，`vim`命令会在文本编辑器中打开脚本。
- en: The local shell generated a startup script as well as a log file. The startup
    script needs to be opened and edited in a text editor, which will be discussed
    next.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 本地终端生成了一个启动脚本和一个日志文件。需要在文本编辑器中打开并编辑该启动脚本，接下来将讨论这一过程。
- en: 'After typing the `vim` command, the screen with the startup script should look
    something like this screenshot:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`vim`命令后，启动脚本的界面应类似于以下截图：
- en: '![](img/7977693a-2615-449d-8586-da3e72be7ef3.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7977693a-2615-449d-8586-da3e72be7ef3.png)'
- en: 'Type `i` to enter `INSERT` mode. Next, delete all the text in the startup script.
    It should then look like the following screenshot:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`i`进入`INSERT`模式。接下来，删除启动脚本中的所有文本，界面应如以下截图所示：
- en: '![](img/1a731d52-da18-4838-b240-ed8541ce3ca5.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1a731d52-da18-4838-b240-ed8541ce3ca5.png)'
- en: 'Copy paste the following code into the startup script:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将以下代码复制粘贴到启动脚本中：
- en: '[PRE4]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The script should appear in the editor, as seen in the following screenshot:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动脚本应出现在编辑器中，如下截图所示：
- en: '![](img/5d563f4a-e5cd-4c69-b378-d830fbdc2d16.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5d563f4a-e5cd-4c69-b378-d830fbdc2d16.png)'
- en: Press Esc to exit out of `INSERT` mode and type `:wq` to write and quit the
    file.
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按`Esc`退出`INSERT`模式，并键入`:wq`保存并退出文件。
- en: 'Once the startup script has been configured, type the following command in
    the Google shell to kill the server and save the changes:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置完启动脚本后，在Google shell中输入以下命令以终止服务器并保存更改：
- en: '[PRE5]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This command should produce a process ID that looks like the one in the following
    screenshot:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该命令应产生一个进程ID，类似于以下截图所示：
- en: '![](img/3f1637f0-1ff1-44bc-9977-12b159852754.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f1637f0-1ff1-44bc-9977-12b159852754.png)'
- en: 'Start the server again by typing the following command:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过输入以下命令重新启动服务器：
- en: '[PRE6]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The next series of steps will focus on securing the shell tunnel into the Google
    Cloud instance from the local host. Before typing anything on the local shell/terminal,
    ensure that Google Cloud is installed. If not already installed, do so by following
    the instructions in this quick-start guide located at the following website:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的步骤将重点介绍如何确保从本地主机到Google Cloud实例的shell隧道安全。在本地shell/终端输入任何内容之前，请确保已经安装Google
    Cloud。如果尚未安装，请按照以下网址中的快速入门指南进行安装：
- en: '[https://cloud.google.com/sdk/docs/quickstart-mac-os-x](https://cloud.google.com/sdk/docs/quickstart-mac-os-x)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/sdk/docs/quickstart-mac-os-x](https://cloud.google.com/sdk/docs/quickstart-mac-os-x)'
- en: 'Once Google Cloud is installed, open up the terminal on your machine and type
    the following commands to connect to the Google Cloud compute instance:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装Google Cloud后，打开你机器上的终端并输入以下命令来连接到Google Cloud计算实例：
- en: '[PRE7]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Ensure that the instance name, project ID, and zone are specified correctly
    in the preceding commands. On pressing ENTER, the output on the local shell changes
    to what is shown in the following screenshot:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保在前面的命令中正确指定了实例名称、项目ID和区域。按下ENTER后，本地shell中的输出会变成以下截图所示：
- en: '![](img/224843c1-1ecf-4dd6-adbe-cd86313046a1.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/224843c1-1ecf-4dd6-adbe-cd86313046a1.png)'
- en: Once you see the name of your instance followed by `":~$"`, it means that a
    connection has successfully been established between the local host/laptop and
    the Google Cloud instance. After successfully SSHing into the instance, we require
    software called **VNC Viewer** to view and interact with the Ubuntu Desktop that
    has now been successfully set up on the Google Cloud Compute engine. The following
    few steps will discuss how this is achieved.
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦看到实例名称后跟`":~$"`，就表示本地主机/笔记本与Google Cloud实例之间的连接已成功建立。在成功SSH连接到实例后，我们需要一款名为**VNC
    Viewer**的软件来查看并与已经在Google Cloud Compute引擎上成功设置的Ubuntu桌面进行交互。接下来的步骤将讨论如何实现这一目标。
- en: 'VNC Viewer may be downloaded using the following link:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用以下链接下载VNC Viewer：
- en: '[https://www.realvnc.com/en/connect/download/viewer/](https://www.realvnc.com/en/connect/download/viewer/)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.realvnc.com/en/connect/download/viewer/](https://www.realvnc.com/en/connect/download/viewer/)'
- en: 'Once installed, click to open VNC Viewer and in the search bar, type in `localhost::5901`,
    as shown in the following screenshot:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装完成后，点击打开VNC Viewer，在搜索栏中输入`localhost::5901`，如以下截图所示：
- en: '![](img/3b2c57ec-d2d4-4125-9d39-531aade0352f.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3b2c57ec-d2d4-4125-9d39-531aade0352f.png)'
- en: 'Next, click on **continue** when prompted with the following screen:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在出现以下屏幕时点击**继续**：
- en: '![](img/59f9d2d6-3490-451c-bd76-ec7a39ace528.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/59f9d2d6-3490-451c-bd76-ec7a39ace528.png)'
- en: 'This will prompt you to enter your password for the virtual machine. Enter
    the password that you set earlier while launching the `tightvncserver` command
    for the first time, as shown in the following screenshot:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将提示您输入虚拟机的密码。请输入您在第一次启动`tightvncserver`命令时设置的密码，如下图所示：
- en: '![](img/0180764b-79ed-4f45-8b9f-3e8f0fd0beb4.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0180764b-79ed-4f45-8b9f-3e8f0fd0beb4.png)'
- en: 'You will finally be taken into the desktop of your Ubuntu virtual machine on
    Google Cloud Compute. Your Ubuntu Desktop screen must now look something like
    the following screenshot when viewed on VNC Viewer:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终，您将进入 Google Cloud Compute 上的 Ubuntu 虚拟机桌面。通过 VNC Viewer 查看时，您的 Ubuntu Desktop
    屏幕现在应显示如下截图所示的内容：
- en: '![](img/b8b46dba-ef51-4461-8370-582f5e3ac544.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b8b46dba-ef51-4461-8370-582f5e3ac544.png)'
- en: How it works...
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: You have now successfully set up VNC Viewer for interactions with the Ubuntu
    virtual machine/desktop. Anytime the Google Cloud instance is not in use, it is
    recommended to suspend or shut down the instance so that additional costs are
    not being incurred. The cloud approach is optimal for developers who may not have
    access to physical resources with high memory and storage.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已经成功设置了 VNC Viewer 以与 Ubuntu 虚拟机/桌面进行交互。每当 Google Cloud 实例未在使用时，建议暂停或关闭实例，以避免产生额外费用。云计算方法非常适合那些可能无法访问具有高内存和存储的物理资源的开发者。
- en: There's more...
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'While we discussed Google Cloud as a cloud option for Spark,  it is possible
    to leverage Spark on the following cloud platforms as well:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们讨论了将 Google Cloud 作为 Spark 的云选项，但也可以在以下云平台上使用 Spark：
- en: Microsoft Azure
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Microsoft Azure
- en: Amazon Web Services
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊网络服务
- en: See also
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'In order to learn more about Google Cloud Platform and sign up for a free subscription,
    visit the following website:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 若要了解更多有关 Google Cloud Platform 的信息并注册免费订阅，请访问以下网站：
- en: '[https://cloud.google.com/](https://cloud.google.com/)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/](https://cloud.google.com/)'
- en: Installing and configuring Spark and prerequisites on Ubuntu Desktop
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Ubuntu Desktop 上安装和配置 Spark 及其先决条件
- en: 'Before Spark can get up and running, there are some necessary prerequisites
    that need to be installed on a newly minted Ubuntu Desktop. This section will
    focus on installing and configuring the following on Ubuntu Desktop:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Spark 启动之前，需要在全新的 Ubuntu Desktop 上安装一些必要的先决条件。本节将重点介绍在 Ubuntu Desktop 上安装和配置以下内容：
- en: Java 8 or higher
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Java 8 或更高版本
- en: Anaconda
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda
- en: Spark
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Spark
- en: Getting ready
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: The only requirement for this section is having administrative rights to install
    applications onto the Ubuntu Desktop.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 本节唯一的要求是具有管理员权限，以便在 Ubuntu Desktop 上安装应用程序。
- en: How to do it...
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'This section walks through the steps in the recipe to install Python 3, Anaconda,
    and Spark on Ubuntu Desktop:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将通过以下步骤指导您在 Ubuntu Desktop 上安装 Python 3、Anaconda 和 Spark：
- en: 'Install Java on Ubuntu through the terminal application, which can be found
    by searching for the app and then locking it to the launcher on the left-hand
    side, as seen in the following screenshot:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过终端应用程序在 Ubuntu 上安装 Java，您可以通过搜索该应用程序并将其锁定到左侧的启动栏来找到它，如下图所示：
- en: '![](img/24db8263-019c-4cf5-a627-c589a21012c3.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/24db8263-019c-4cf5-a627-c589a21012c3.png)'
- en: 'Perform an initial test for Java on the virtual machine by executing the following
    command at the terminal:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在虚拟机上通过终端执行以下命令进行 Java 的初步测试：
- en: '[PRE8]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Execute the following four commands at the terminal to install Java:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中执行以下四个命令来安装 Java：
- en: '[PRE9]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After accepting the necessary license agreements for Oracle, perform a secondary
    test of Java on the virtual machine by executing `java -version` once again in
    the terminal. A successful installation for Java will display the following outcome
    in the terminal:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在接受 Oracle 的必要许可协议后，再次通过在终端中执行 `java -version` 来对虚拟机上的 Java 进行二次测试。Java 安装成功后，终端将显示以下结果：
- en: '[PRE10]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, install the most recent version of Anaconda. Current versions of Ubuntu
    Desktop come preinstalled with Python. While it is convenient that Python comes
    preinstalled with Ubuntu, the installed version is for Python 2.7, as seen in
    the following output:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，安装最新版本的 Anaconda。当前版本的 Ubuntu Desktop 已预装 Python。虽然 Ubuntu 中预装了 Python 非常方便，但所安装的版本是
    Python 2.7，如下所示：
- en: '[PRE11]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The current version of Anaconda is v4.4 and the current version of Python 3
    is v3.6\. Once downloaded, view the Anaconda installation file by accessing the
    `Downloads` folder using the following command:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当前Anaconda版本为v4.4，当前Python 3版本为v3.6。下载完成后，通过以下命令访问`Downloads`文件夹查看Anaconda安装文件：
- en: '[PRE12]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Once in the `Downloads` folder, initiate the installation for Anaconda by executing
    the following command:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入`Downloads`文件夹后，执行以下命令启动Anaconda的安装：
- en: '[PRE13]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Please note that the version of Anaconda, as well as any other software installed,
    may differ as newer updates are released to the public. The version of Anaconda
    that we are using in this chapter and in this book can be downloaded from [https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86.sh](https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86.sh)
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Anaconda的版本以及安装的其他软件可能会有所不同，因为更新版本会定期发布。我们在本章和本书中使用的Anaconda版本可以从[https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86.sh](https://repo.continuum.io/archive/Anaconda3-4.4.0-Linux-x86.sh)下载。
- en: 'Once the Anaconda installation is complete, restart the Terminal application
    to confirm that Python 3 is now the default Python environment through Anaconda
    by executing `python --version` in the terminal:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Anaconda安装完成后，重启终端应用程序，通过在终端中执行`python --version`命令来确认Python 3现在是默认的Python环境：
- en: '[PRE14]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The Python 2 version is still available under Linux, but will require an explicit
    call when executing a script, as seen in the following command:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Python 2版本仍然可以在Linux下使用，但在执行脚本时需要显式调用，如下命令所示：
- en: '[PRE15]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Visit the following website to begin the Spark download and installation process:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问以下网站，开始Spark的下载和安装过程：
- en: '[https://spark.apache.org/downloads.html](https://spark.apache.org/downloads.html)'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/downloads.html](https://spark.apache.org/downloads.html)'
- en: 'Select the download link. The following file will be downloaded to the `Downloads`
    folder in Ubuntu:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择下载链接。以下文件将被下载到Ubuntu的`Downloads`文件夹中：
- en: '`spark-2.2.0-bin-hadoop2.7.tgz`'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`spark-2.2.0-bin-hadoop2.7.tgz`'
- en: 'View the file at the terminal level by executing the following commands:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下命令在终端查看文件：
- en: '[PRE16]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Extract the `tgz` file by executing the following command:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下命令提取`tgz`文件：
- en: '[PRE17]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Another look at the Downloads directory using `ls` shows both the `tgz` file
    and the extracted folder:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ls`命令再次查看`Downloads`目录，显示了`tug`文件和提取后的文件夹：
- en: '[PRE18]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Move the extracted folder from the `Downloads` folder to the `Home` folder
    by executing the following command:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下命令，将提取的文件夹从`Downloads`文件夹移动到`Home`文件夹：
- en: '[PRE19]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, the `spark-2.2.0-bin-hadoop2.7` folder has been moved to the **Home**
    folder, which can be viewed when selecting the **Files** icon on the left-hand
    side toolbar, as seen in the following screenshot:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，`spark-2.2.0-bin-hadoop2.7`文件夹已经被移动到**Home**文件夹，可以通过点击左侧工具栏中的**Files**图标查看，如下图所示：
- en: '![](img/e0cfa68f-3713-472f-adfd-1d929b47b819.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e0cfa68f-3713-472f-adfd-1d929b47b819.png)'
- en: 'Spark is now installed. Initiate Spark from the terminal by executing the following
    script at the terminal level:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Spark现在已安装。通过在终端执行以下脚本，启动Spark：
- en: '[PRE20]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Perform a final test to ensure Spark is up and running at the terminal by executing
    the following command to ensure that the `SparkContext` is driving the cluster
    in the local environment:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下命令在终端进行最后测试，以确保`SparkContext`正在驱动本地环境中的集群，确保Spark已成功运行：
- en: '[PRE21]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: How it works...
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section explains the reasoning behind the installation process for Python,
    Anaconda, and Spark.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了安装Python、Anaconda和Spark过程背后的理由。
- en: Spark runs on the **Java virtual machine** (**JVM**), the Java **Software Development
    Kit** (**SDK**) is a prerequisite installation for Spark to run on an Ubuntu virtual
    machine.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Spark运行在**Java虚拟机**（**JVM**）上，Java **软件开发工具包**（**SDK**）是Spark在Ubuntu虚拟机上运行的前提安装条件。
- en: In order for Spark to run on a local machine or in a cluster, a minimum version
    of Java 6 is required for installation.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让Spark在本地机器或集群上运行，安装时需要最低版本的Java 6。
- en: Ubuntu recommends the `sudo apt install` method for Java as it ensures that
    packages downloaded are up to date.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ubuntu建议使用`sudo apt install`方法安装Java，因为它确保下载的包是最新的。
- en: 'Please note that if Java is not currently installed, the output in the terminal
    will show the following message:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，如果当前未安装Java，终端中将显示以下消息：
- en: '[PRE22]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: While Python 2 is fine, it is considered legacy Python. Python 2 is facing an
    end of life date in 2020; therefore, it is recommended that all new Python development
    be performed with Python 3, as will be the case in this publication. Up until
    recently, Spark was only available with Python 2\. That is no longer the case.
    Spark works with both Python 2 and 3. A convenient way to install Python 3, as
    well as many dependencies and libraries, is through Anaconda. Anaconda is a free
    and open source distribution of Python, as well as R. Anaconda manages the installation
    and maintenance of many of the most common packages used in Python for data science-related
    tasks.
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虽然 Python 2 仍然可用，但它已被视为遗留版本。Python 2 将于 2020 年停止支持；因此，建议所有新的 Python 开发都使用 Python
    3，正如本书中的示例一样。直到最近，Spark 只支持 Python 2。现在情况已经不同，Spark 支持 Python 2 和 3。安装 Python
    3 及其众多依赖库和工具包的一个便捷方法是通过 Anaconda。Anaconda 是一个免费的开源 Python 和 R 发行版，它负责管理数据科学相关任务中最常用的
    Python 包的安装和维护。
- en: 'During the installation process for Anaconda, it is important to confirm the
    following conditions:'
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在安装 Anaconda 过程中，确认以下条件是很重要的：
- en: Anaconda is installed in the `/home/username/Anaconda3` location
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda 安装在 `/home/username/Anaconda3` 位置
- en: The Anaconda installer prepends the Anaconda3 install location to a `PATH` in `/home/username/.bashrc`
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anaconda 安装程序会将 Anaconda3 的安装位置添加到 `/home/username/.bashrc` 中的 `PATH` 环境变量。
- en: After Anaconda has been installed, download Spark. Unlike Python, Spark does
    not come preinstalled on Ubuntu and therefore, will need to be downloaded and
    installed.
  id: totrans-227
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在安装了 Anaconda 之后，下载 Spark。与 Python 不同，Spark 在 Ubuntu 上没有预安装，因此需要手动下载并安装。
- en: 'For the purposes of development with deep learning, the following preferences
    will be selected for Spark:'
  id: totrans-228
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了进行深度学习开发，将为 Spark 选择以下偏好设置：
- en: '**Spark release**: **2.2.0** (Jul 11 2017)'
  id: totrans-229
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spark 版本**：**2.2.0**（2017年7月11日）'
- en: '**Package type**: Prebuilt for Apache Hadoop 2.7 and later'
  id: totrans-230
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**软件包类型**：预构建的 Apache Hadoop 2.7 及更高版本'
- en: '**Download type**: Direct download'
  id: totrans-231
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**下载类型**：直接下载'
- en: Once Spark has been successfully installed, the output from executing Spark
    at the command line should look something similar to that shown in the following
    screenshot:![](img/3c3ad567-d964-46d1-a678-5269c0d0f49b.png)
  id: totrans-232
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦 Spark 成功安装，执行 Spark 命令行后的输出应该类似于以下截图所示：![](img/3c3ad567-d964-46d1-a678-5269c0d0f49b.png)
- en: Two important features to note when initializing Spark are that it is under
    the `Python 3.6.1` | `Anaconda 4.4.0 (64-bit)` | framework and that the Spark
    logo is version 2.2.0.
  id: totrans-233
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化 Spark 时需要注意的两个重要特性是，它位于 `Python 3.6.1` | `Anaconda 4.4.0 (64-bit)` | 框架下，并且
    Spark 的版本为 2.2.0。
- en: Congratulations! Spark is successfully installed on the local Ubuntu virtual
    machine. But, not everything is complete. Spark development is best when Spark
    code can be executed within a Jupyter notebook, especially for deep learning.
    Thankfully, Jupyter has been installed with the Anaconda distribution performed
    earlier in this section.
  id: totrans-234
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 恭喜！Spark 已成功安装在本地 Ubuntu 虚拟机上。但是，并不是一切都完成了。Spark 开发最理想的方式是在 Jupyter notebook
    中执行 Spark 代码，特别是在深度学习的情况下。幸运的是，Jupyter 已经在本节早些时候通过 Anaconda 安装。
- en: There's more...
  id: totrans-235
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多内容...
- en: You may be asking why we did not just use `pip install pyspark` to use Spark
    in Python. Previous versions of Spark required going through the installation
    process that we did in this section. Future versions of Spark, starting with 2.2.0
    will begin to allow installation directly through the `pip` approach. We used
    the full installation method in this section to ensure that you will be able to
    get Spark installed and fully-integrated, in case you are using an earlier version
    of Spark.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可能会问，为什么我们不直接使用 `pip install pyspark` 来在 Python 中使用 Spark。之前的 Spark 版本需要通过本节中描述的安装过程。自
    Spark 2.2.0 起，未来版本将开始支持通过 `pip` 直接安装。我们在本节中使用完整的安装方法，以确保你能够正确安装并完全集成 Spark，尤其是如果你正在使用
    Spark 的早期版本。
- en: See also
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'To learn more about Jupyter notebooks and their integration with Python, visit
    the following website:'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要了解更多关于 Jupyter notebooks 及其与 Python 集成的信息，请访问以下网站：
- en: '[http://jupyter.org](http://jupyter.org)'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[http://jupyter.org](http://jupyter.org)'
- en: 'To learn more about Anaconda and download a version for Linux, visit the following
    website:'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要了解更多关于 Anaconda 的信息并下载 Linux 版本，请访问以下网站：
- en: '[https://www.anaconda.com/download/](https://www.anaconda.com/download/).'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://www.anaconda.com/download/](https://www.anaconda.com/download/)'
- en: Integrating Jupyter notebooks with Spark
  id: totrans-242
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 Jupyter notebooks 与 Spark 集成
- en: When learning Python for the first time, it is useful to use Jupyter notebooks
    as an **interactive developing environment** (**IDE**). This is one of the main
    reasons why Anaconda is so powerful. It fully integrates all of the dependencies
    between Python and Jupyter notebooks. The same can be done with PySpark and Jupyter
    notebooks. While Spark is written in Scala, PySpark allows for the translation
    of code to occur within Python instead.
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在第一次学习Python时，使用Jupyter笔记本作为**交互式开发环境**（**IDE**）非常有用。这也是Anaconda如此强大的主要原因之一。它完全整合了Python和Jupyter笔记本之间的所有依赖关系。同样的操作也可以通过PySpark和Jupyter笔记本来实现。尽管Spark是用**Scala**编写的，PySpark则允许代码在Python中进行转换。
- en: Getting ready
  id: totrans-244
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Most of the work in this section will just require accessing the `.bashrc` script
    from the terminal.
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本节的大部分工作只需要从终端访问`.bashrc`脚本。
- en: How to do it...
  id: totrans-246
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'PySpark is not configured to work within Jupyter notebooks by default, but
    a slight tweak of the `.bashrc` script can remedy this issue. We will walk through
    these steps in this section:'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 默认情况下，PySpark未配置为在Jupyter笔记本中工作，但稍微调整一下`.bashrc`脚本可以解决这个问题。我们将在本节中介绍这些步骤：
- en: 'Access the `.bashrc` script by executing the following command:'
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下命令来访问`.bashrc`脚本：
- en: '[PRE23]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Scrolling all the way to the end of the script should reveal the last command
    modified, which should be the `PATH` set by Anaconda during the installation earlier
    in the previous section. The `PATH` should appear as seen in the following:'
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到脚本的末尾应显示最后修改的命令，该命令应该是之前部分安装过程中Anaconda设置的`PATH`。`PATH`应如下所示：
- en: '[PRE24]'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Underneath, the `PATH` added by the Anaconda installer can include a custom
    function that helps communicate the Spark installation with the Jupyter notebook
    installation from Anaconda3\. For the purposes of this chapter and remaining chapters,
    we will name that function `sparknotebook`. The configuration should appear as
    the following for `sparknotebook()`:'
  id: totrans-252
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下面，Anaconda安装程序添加的`PATH`可以包括一个自定义函数，帮助将Spark安装与Anaconda3中的Jupyter笔记本安装进行通信。为了本章及后续章节的目的，我们将该函数命名为`sparknotebook`。对于`sparknotebook()`，配置应如下所示：
- en: '[PRE25]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The updated `.bashrc` script should look like the following once saved:![](img/8e10315b-22c1-42d2-a4cf-634a382cae47.png)
  id: totrans-254
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新后的`.bashrc`脚本保存后应如下所示：![](img/8e10315b-22c1-42d2-a4cf-634a382cae47.png)
- en: 'Save and exit from the `.bashrc` file. It is recommended to communicate that
    the `.bashrc` file has been updated by executing the following command and restarting
    the terminal application:'
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存并退出`.bashrc`文件。建议通过执行以下命令并重新启动终端应用程序来通知`.bashrc`文件已更新：
- en: '[PRE26]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: How it works...
  id: totrans-257
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Our goal in this section is to integrate Spark directly into a Jupyter notebook
    so that we are not doing our development at the terminal and instead utilizing
    the benefits of developing within a notebook. This section explains how the Spark
    integration within a Jupyter notebook takes place.
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本节的目标是将Spark直接集成到Jupyter笔记本中，以便我们不再在终端中进行开发，而是利用在笔记本中开发的优势。本节解释了如何将Spark集成到Jupyter笔记本中。
- en: 'We will create a command function, `sparknotebook`, that we can call from the
    terminal to open up a Spark session through Jupyter notebooks from the Anaconda
    installation. This requires two settings to be set in the `.bashrc` file:'
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将创建一个命令函数`sparknotebook`，可以通过终端调用它，从Anaconda安装中通过Jupyter笔记本打开Spark会话。这需要在`.bashrc`文件中设置两个配置：
- en: PySpark Python be set to python 3
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置PySpark的Python版本为Python 3
- en: PySpark driver for python to be set to Jupyter
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为Python设置PySpark驱动程序以在Jupyter中运行
- en: 'The `sparknotebook` function can now be accessed directly from the terminal
    by executing the following command:'
  id: totrans-262
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在可以通过执行以下命令直接从终端访问`sparknotebook`函数：
- en: '[PRE27]'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The function should then initiate a brand new Jupyter notebook session through
    the default web browser. A new Python script within Jupyter notebooks with a `.ipynb` extension
    can be created by clicking on the New button on the right-hand side and by selecting Python
    3 under Notebook: as seen in the following screenshot:![](img/759bfb12-f3d8-470b-a1b5-b5d6cfdb3508.png)
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，函数应通过默认的网页浏览器启动全新的Jupyter笔记本会话。可以通过点击右侧的**New**按钮并选择**Notebook**下的**Python
    3**来创建一个带有`.ipynb`扩展名的新的Python脚本，如下图所示：![](img/759bfb12-f3d8-470b-a1b5-b5d6cfdb3508.png)
- en: Once again, just as was done at the terminal level for Spark, a simple script
    of `sc` will be executed within the notebook to confirm that Spark is up and running
    through Jupyter:![](img/1fca9542-b5e1-4e76-8c72-63d72fcaa4ec.png)
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一如既往，就像在终端层面为 Spark 所做的那样，`sc` 的简单脚本将会在 notebook 中执行，以确认 Spark 已通过 Jupyter 启动：![](img/1fca9542-b5e1-4e76-8c72-63d72fcaa4ec.png)
- en: Ideally, the Version, Master, and AppName should be identical to the earlier
    output when `sc` was executed at the terminal. If this is the case, then PySpark
    has been successfully installed and configured to work with Jupyter notebooks.
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理想情况下，`Version`、`Master` 和 `AppName` 应该与执行 `sc` 命令时的输出相同。如果是这样，那么 PySpark 已经成功安装并配置好了，可以与
    Jupyter notebook 一起使用。
- en: There's more...
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: It is important to note that if we were to call a Jupyter notebook through the
    terminal without specifying `sparknotebook`, our Spark session will never be initiated
    and we will receive an error when executing the `SparkContext` script.
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 需要注意的是，如果我们通过终端调用 Jupyter notebook 时没有指定 `sparknotebook`，我们的 Spark 会话将无法启动，并且在执行
    `SparkContext` 脚本时会收到错误。
- en: 'We can access a traditional Jupyter notebook by executing the following at
    the terminal:'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以通过在终端执行以下命令来访问传统的 Jupyter notebook：
- en: '[PRE28]'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Once we start the notebook, we can try and execute the same script for `sc.master`
    as we did previously, but this time we will receive the following error:'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦我们启动 notebook，我们可以尝试执行与之前相同的 `sc.master` 脚本，但这次我们会收到以下错误：
- en: '![](img/fcbadbb7-4201-41b4-8440-6208053013ee.png)'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/fcbadbb7-4201-41b4-8440-6208053013ee.png)'
- en: See also
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'There are many managed offerings online of companies offering Spark through
    a notebook interface where the installation and configuration of Spark with a
    notebook have already been managed for you. These are the following:'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有许多在线管理的 Spark 服务，这些公司通过 notebook 接口提供 Spark，其中 Spark 的安装和配置已经为您管理好了。以下是这些服务：
- en: Hortonworks ([https://hortonworks.com/](https://hortonworks.com/))
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hortonworks ([https://hortonworks.com/](https://hortonworks.com/))
- en: Cloudera ([https://www.cloudera.com/](https://www.cloudera.com/))
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cloudera ([https://www.cloudera.com/](https://www.cloudera.com/))
- en: MapR ([https://mapr.com/](https://mapr.com/))
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: MapR ([https://mapr.com/](https://mapr.com/))
- en: DataBricks ([https://databricks.com/](https://mapr.com/))
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataBricks ([https://databricks.com/](https://mapr.com/))
- en: Starting and configuring a Spark cluster
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动和配置 Spark 集群
- en: For most chapters, one of the first things that we will do is to initialize
    and configure our Spark cluster.
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于大多数章节，我们首先要做的就是初始化并配置我们的 Spark 集群。
- en: Getting ready
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Import the following before initializing cluster.
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在初始化集群之前导入以下内容。
- en: '`from pyspark.sql import SparkSession`'
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from pyspark.sql import SparkSession`'
- en: How to do it...
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: This section walks through the steps to initialize and configure a Spark cluster.
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本节介绍了初始化和配置 Spark 集群的步骤。
- en: 'Import `SparkSession` using the following script:'
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本导入 `SparkSession`：
- en: '[PRE29]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Configure `SparkSession` with a variable named `spark` using the following
    script:'
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本配置名为 `spark` 的 `SparkSession`：
- en: '[PRE30]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: How it works...
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section explains how the `SparkSession` works as an entry point to develop
    within Spark.
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本节解释了 `SparkSession` 作为开发 Spark 应用程序的入口点的工作原理。
- en: Staring with Spark 2.0, it is no longer necessary to create a `SparkConf` and
    `SparkContext` to begin development in Spark. Those steps are no longer needed
    as importing `SparkSession` will handle initializing a cluster.  Additionally,
    it is important to note that `SparkSession` is part of the `sql` module from `pyspark`.
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Spark 2.0 开始，不再需要创建 `SparkConf` 和 `SparkContext` 来开始在 Spark 中的开发。这些步骤不再需要，因为导入
    `SparkSession` 就可以处理集群的初始化。此外，需要注意的是，`SparkSession` 是 `pyspark` 的 `sql` 模块的一部分。
- en: 'We can assign properties to our `SparkSession`:'
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以为 `SparkSession` 分配属性：
- en: '`master`: assigns the Spark master URL to run on our `local` machine with the
    maximum available number of cores.'
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`master`：将 Spark 主节点 URL 分配到我们 `local` 机器上，并使用最大可用核心数运行。'
- en: '`appName`: assign a name for the application'
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`appName`：为应用程序分配一个名称'
- en: '`config`: assign `6gb` to the `spark.executor.memory`'
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`config`：将 `6gb` 分配给 `spark.executor.memory`'
- en: '`getOrCreate`: ensures that a `SparkSession` is created if one is not available
    and retrieves an existing one if it is available'
  id: totrans-297
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`getOrCreate`：确保如果没有可用的 `SparkSession` 则创建一个，如果有现有的，则获取它。'
- en: There's more...
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: For development purposes, while we are building an application on smaller datasets,
    we can just use `master("local")`.  If we were to deploy on a production environment,
    we would want to specify `master("local[*]")` to ensure we are using the maximum
    cores available and get optimal performance.
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于开发目的，当我们在较小的数据集上构建应用时，可以使用 `master("local")`。如果我们要部署到生产环境中，我们则需要指定 `master("local[*]")`，以确保使用最大可用核心数并获得最佳性能。
- en: See also
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'To learn more about `SparkSession.builder`, visit the following website:'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要了解更多关于 `SparkSession.builder` 的信息，请访问以下网站：
- en: '[https://spark.apache.org/docs/2.2.0/api/java/org/apache/spark/sql/SparkSession.Builder.html](https://spark.apache.org/docs/2.2.0/api/java/org/apache/spark/sql/SparkSession.Builder.html)'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://spark.apache.org/docs/2.2.0/api/java/org/apache/spark/sql/SparkSession.Builder.html](https://spark.apache.org/docs/2.2.0/api/java/org/apache/spark/sql/SparkSession.Builder.html)'
- en: Stopping a Spark cluster
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 停止 Spark 集群
- en: Once we are done developing on our cluster, it is ideal to shut it down and
    preserve resources.
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一旦我们完成在集群上的开发，关闭集群以节省资源是理想的做法。
- en: How to do it...
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作…
- en: This section walks through the steps to stop the `SparkSession`.
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本节将演示如何停止 `SparkSession`。
- en: 'Execute the following script:'
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本：
- en: '`spark.stop()`'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`spark.stop()`'
- en: 'Confirm that the session has closed by executing the following script:'
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本来确认会话是否已关闭：
- en: '`sc.master`'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`sc.master`'
- en: How it works...
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: This section explains how to confirm that a Spark cluster has been shut down.
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本节解释如何确认 Spark 集群已被关闭。
- en: If the cluster has been shut down, you will receive the error message seen in
    the following screenshot when executing another Spark command in the notebook:![](img/803973af-d603-4362-a9bb-770ad84e903c.png)
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果集群已被关闭，当你在笔记本中执行另一个 Spark 命令时，将会收到以下截图中的错误信息：![](img/803973af-d603-4362-a9bb-770ad84e903c.png)
- en: There's more...
  id: totrans-314
  prefs:
  - PREF_IND
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: Shutting down Spark clusters may not be as critical when working in a local
    environment; however, it will prove costly when Spark is deployed in a cloud environment
    where you are charged for compute power.
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在本地环境中工作时，关闭 Spark 集群可能并不是那么重要；然而，当 Spark 部署在云环境中时，关闭集群就显得至关重要，因为在云环境中，你将为计算资源付费。
