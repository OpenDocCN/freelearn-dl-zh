- en: Pain Points of Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络的痛点
- en: 'In this chapter, the following recipes will be covered:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍以下内容：
- en: 'Pain Point #1: Importing MNIST images'
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '痛点 #1：导入MNIST图像'
- en: 'Pain Point #2: Visualizing MNIST images'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '痛点 #2：可视化MNIST图像'
- en: 'Pain Point #3: Exporting MNIST images as files'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '痛点 #3：将MNIST图像导出为文件'
- en: 'Pain Point #4: Augmenting MNIST images'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '痛点 #4：增强MNIST图像'
- en: 'Pain Point #5: Utilizing alternate sources for trained images'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '痛点 #5：利用其他来源的训练图像'
- en: 'Pain Point #6: Prioritizing high-level libraries for CNNs'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '痛点 #6：优先考虑CNN的高级库'
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '**Convolutional neural networks** (**CNNs**) have been enjoying a bit of resurgence
    in the last couple of years. They have shown great success when it comes to image
    recognition. This is quite relevant these days with the advent of modern smartphones
    as anyone now has the ability to take large volumes of pictures of objects and
    post them on social media sites. Just due to this phenomenon, convolutional neural
    networks are in high demand these days.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络**（**CNNs**）在过去几年里有了一定的复兴。它们在图像识别方面取得了巨大的成功。随着现代智能手机的普及，这一点变得尤其相关，因为现在任何人都可以轻松拍摄大量物体照片并将其发布在社交媒体网站上。正是因为这一现象，卷积神经网络现在需求量很大。'
- en: 'There are several features that make a CNN optimally perform. They require
    the following features:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个特性可以使CNN表现最佳。它们需要以下特性：
- en: A high volume of training data
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大量的训练数据
- en: Visual and spatial data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视觉和空间数据
- en: An emphasis on filtering (pooling), activation, and convoluting as opposed to
    a fully connected layer that is more apparent in a traditional neural network
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强调过滤（池化）、激活和卷积，而不是传统神经网络中更明显的全连接层。
- en: While CNNs have gained great popularity, there are some limitations in working
    with them primarily due to their computational needs as well as the volume of
    training data required to get a well-performing model. We will focus on techniques
    that can be applied to the data that will ultimately assist with the development
    of a convolutional neural network while addressing these limitations. In later
    chapters, we will apply some of these techniques when we develop models for image
    classification.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然CNNs获得了很大的流行，但在使用时仍然存在一些限制，主要是由于它们的计算需求以及获得良好性能模型所需的训练数据量。我们将专注于可以应用于数据的技术，这些技术将有助于卷积神经网络的开发，同时解决这些限制。在后续章节中，我们将在开发图像分类模型时应用其中一些技术。
- en: 'Pain Point #1: Importing MNIST images'
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '痛点 #1：导入MNIST图像'
- en: 'One of the most common datasets used for image classification is the `MNIST` dataset,
    which is composed of thousands of samples of handwritten digits. The **Modified
    National Institute of Standards and Technology** (**MNIST**) is, according to
    Yann LeCun, Corinna Cortes, and Christopher J.C. Burges, useful for the following
    reasons:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 用于图像分类的最常见数据集之一是`MNIST`数据集，它包含了成千上万的手写数字样本。**美国国家标准与技术研究院**（**MNIST**）根据Yann
    LeCun、Corinna Cortes和Christopher J.C. Burges的说法，具有以下几个优点：
- en: It is a good database for people who want to try learning techniques and pattern
    recognition methods on real-world data while spending minimal efforts on preprocessing
    and formatting.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些希望在真实世界数据上尝试学习技术和模式识别方法，同时在预处理和格式化方面花费最少精力的人来说，这是一个很好的数据库。
- en: 'There are several methods to import the MNIST images into our Jupyter notebook.
    We will cover the following two methods in this chapter:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以将MNIST图像导入到我们的Jupyter笔记本中。我们将在本章中介绍以下两种方法：
- en: Directly through the TensorFlow library
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过TensorFlow库直接导入
- en: Manually through the MNIST website
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过MNIST网站手动操作
- en: One thing to note is that we will be primarily using MNIST images as our example
    of how to improve performance within a convolutional neural network. All of these
    techniques that will be applied on MNIST images can be applied to any image that
    will be used to train a CNN.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，我们将主要使用MNIST图像作为改进卷积神经网络性能的示例。所有应用于MNIST图像的这些技术，也可以应用于任何用于训练CNN的图像。
- en: Getting ready
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The only requirement needed is to install `TensorFlow`. It will likely not
    come pre-installed with the anaconda3 packages; therefore, a simple `pip` install
    will either confirm the availability of `TensorFlow` or install it if not currently
    available. `TensorFlow` can be easily installed in the Terminal, as seen in the
    following screenshot:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的要求是安装`TensorFlow`。它可能不会随anaconda3包预安装；因此，通过简单的`pip`安装可以确认`TensorFlow`的可用性，或者在未安装时进行安装。`TensorFlow`可以在终端轻松安装，如下图所示：
- en: '![](img/32eb9853-862f-45e7-a53a-c61008231b04.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/32eb9853-862f-45e7-a53a-c61008231b04.png)'
- en: How to do it...
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作……
- en: The `TensorFlow` library has a conveniently built-in set of examples that can
    be used directly. One of those example datasets is `MNIST`. This section will
    walk through the steps of accessing those images.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`TensorFlow`库内置了一组可以直接使用的示例。这些示例数据集之一是`MNIST`。本节将演示如何访问这些图像。'
- en: 'Import `TensorFlow` into the library with an alias of `tf` using the following
    script:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本将`TensorFlow`导入库，并指定别名为`tf`：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Download and extract images from the library and save to a local folder using
    the following script:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本从库中下载并提取图像，并保存到本地文件夹：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Retrieve a final count of the training and testing datasets that will be used
    to evaluate the accuracy of the image classification using the following script:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本检索用于评估图像分类准确性的训练和测试数据集的最终计数：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: How it works...
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'This section explains the process used to access the MNIST datasets:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了用于访问MNIST数据集的过程：
- en: Once we receive a confirmation that the `TensorFlow` library has been properly
    installed, it is imported into the notebook.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们收到`TensorFlow`库已正确安装的确认，就可以将其导入到笔记本中。
- en: 'We can confirm the version of `TensorFlow` as well as extract the images to
    our local folder of `MNIST/`. The extraction process is visible in the output
    of the notebook, as seen in the following screenshot:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以确认`TensorFlow`的版本，并将图像提取到本地的`MNIST/`文件夹中。提取过程会显示在笔记本的输出中，如下图所示：
- en: '![](img/fe736aad-311b-4ecf-ba55-204923aff582.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fe736aad-311b-4ecf-ba55-204923aff582.png)'
- en: 'The four extracted files are named the following:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取出的四个文件命名如下：
- en: '`t10k-images-idx3-ubyte.gz`'
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`t10k-images-idx3-ubyte.gz`'
- en: '`t10k-labels-idx1-ubyte.gz`'
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`t10k-labels-idx1-ubyte.gz`'
- en: '`train-images-idx3-ubyte.gz`'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`train-images-idx3-ubyte.gz`'
- en: '`train-labels-idx1-ubyte.gz`'
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`train-labels-idx1-ubyte.gz`'
- en: 'They have been downloaded to the `MNIST/` subfolder as seen in the following
    screenshot:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们已被下载到`MNIST/`子文件夹中，如下图所示：
- en: '![](img/eae6887f-d725-4376-ae25-a3876d69a939.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eae6887f-d725-4376-ae25-a3876d69a939.png)'
- en: 'In addition, the four files can be viewed in our notebook, as seen in the following
    screenshot:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，四个文件也可以在我们的笔记本中查看，如下图所示：
- en: '![](img/5d23979c-afee-413f-8834-7d6c3f5f3f45.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5d23979c-afee-413f-8834-7d6c3f5f3f45.png)'
- en: The four files are the testing and training images along with the accompanying
    testing and training labels identifying each image in the testing and training
    datasets. Additionally, the `one_hot = True` feature is explicitly defined. This indicates
    that one-hot encoding is active with the labels, which assists with feature selection
    within modeling as each column value will be either 0 or 1.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这四个文件是测试和训练图像以及随附的测试和训练标签，用于标识测试和训练数据集中的每张图像。此外，明确地定义了`one_hot = True`特性。这表明标签使用了独热编码，这有助于在建模过程中进行特征选择，因为每一列的值要么是0，要么是1。
- en: 'A subclass of the library is also imported that stores the handwritten images
    of MNIST to the specified local folder. The folder containing all of the images
    should be approximately 12 MB in size for 55,000 training images and 10,000 testing
    images, as seen in the following screenshot:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 库的一个子类也被导入，用于将MNIST的手写图像存储到指定的本地文件夹中。包含所有图像的文件夹大小约为12MB，包含55,000张训练图像和10,000张测试图像，如下图所示：
- en: '![](img/102e5c7e-5458-4ada-9747-9346ffea364f.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/102e5c7e-5458-4ada-9747-9346ffea364f.png)'
- en: The 10,000 images will be used to test the accuracy of our model that will be
    trained on the 55,000 images.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这10,000张图像将用于测试我们模型的准确性，该模型将在55,000张图像上进行训练。
- en: There's more...
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'Occasionally, there may be errors or warnings when trying to access the MNIST
    datasets directly through `TensorFlow`. As was seen earlier on in the section,
    we received the following warning when importing MNIST:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，在尝试通过`TensorFlow`直接访问MNIST数据集时，可能会出现错误或警告。正如前面在本节中所看到的，当导入MNIST时，我们收到了以下警告：
- en: 'WARNING:tensorflow:From <ipython-input-3-ceaef6f48460>:2: read_data_sets (from
    tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be
    removed in a future version.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 'WARNING:tensorflow:From <ipython-input-3-ceaef6f48460>:2: read_data_sets (来自
    tensorflow.contrib.learn.python.learn.datasets.mnist) 已弃用，将在未来版本中移除。'
- en: 'Instructions for updating:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 更新说明：
- en: Please use alternatives such as official/mnist/dataset.py from tensorflow/models.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 请使用 tensorflow/models 中的官方/mnist/dataset.py 等替代方案。
- en: 'The dataset may become deprecated in a future release of `TensorFlow` and therefore,
    no longer be directly accessible. Sometimes we may just encounter a typical *HTTP 403
    error* when extracting the MNIST images through `TensorFlow`. This may be due
    to the website being temporarily unavailable. Have no fear in either case, there
    is a manual approach to downloading the four `.gz` files using the following link:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集可能会在未来的 `TensorFlow` 版本中被弃用，因此不再直接可用。有时我们在通过 `TensorFlow` 提取 MNIST 图像时可能会遇到典型的
    *HTTP 403 错误*，这可能是由于网站暂时不可用所致。无论哪种情况，都不必担心，有一种手动方法可以通过以下链接下载四个 `.gz` 文件：
- en: '[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)'
- en: 'The files are located on the website, as seen in the following screenshot:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 文件位于网站上，如下图所示：
- en: '![](img/a65f6b81-fc22-476b-9ebb-bf7ab594063c.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a65f6b81-fc22-476b-9ebb-bf7ab594063c.png)'
- en: Download the files and save them to an accessible local folder similar to what
    was done with the files that came directly from `TensorFlow`.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 下载文件并将其保存在可访问的本地文件夹中，类似于直接从 `TensorFlow` 获取的文件。
- en: See also
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: To learn more about the `MNIST` database of handwritten digits, visit the following
    website: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 `MNIST` 手写数字数据库的信息，请访问以下网站：[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)。
- en: To learn more about one-hot encoding, visit the following website: [https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f.](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于独热编码的信息，请访问以下网站：[https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f.](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f)
- en: 'Pain Point #2: Visualizing MNIST images'
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '痛点 #2：可视化 MNIST 图像'
- en: Plotting images is often a major pain point when dealing with graphics within
    a Jupyter notebook. Displaying the handwritten images from the training dataset
    is critical, especially when comparing the actual value of the label that is associated
    with the handwritten image.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Jupyter Notebook 中处理图形时，绘制图像通常是一个主要的痛点。显示来自训练数据集的手写图像至关重要，特别是在比较与手写图像相关联的标签的实际值时。
- en: Getting ready
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The only Python libraries that will be imported to visualize the handwritten
    images are `numpy` and `matplotlib`. Both should already be available through
    the packages in Anaconda. If for some reason they are not available, they can
    both be `pip` installed at the Terminal using the following commands:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化手写图像时，唯一需要导入的 Python 库是 `numpy` 和 `matplotlib`。这两个库应该已经通过 Anaconda 中的包可用。如果由于某种原因它们不可用，可以通过以下命令在终端使用
    `pip` 安装：
- en: '`pip install matplotlib`'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip install matplotlib`'
- en: '`pip install numpy`'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip install numpy`'
- en: How to do it...
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'This section will walk through the steps to visualize the MNIST handwritten
    images in a Jupyter notebook:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将逐步演示如何在 Jupyter Notebook 中可视化 MNIST 手写图像：
- en: 'Import the following libraries, `numpy` and `matplotlib`, and configure `matplotlib`
    to plot `inline` using the following script:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下库 `numpy` 和 `matplotlib`，并使用以下脚本配置 `matplotlib` 以 `inline` 方式绘制图像：
- en: '[PRE3]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Plot the first two sample images using the following script:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本绘制前两张示例图像：
- en: '[PRE4]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: How it works...
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'This section will walk through the process of how the MNIST handwritten images
    are viewed in a Jupyter notebook:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将讲解如何在 Jupyter Notebook 中查看 MNIST 手写图像的过程：
- en: A loop is generated in Python that will sample two images from the training
    dataset.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Python 中生成一个循环，将从训练数据集中抽取两张图像。
- en: 'Initially, the images are just a series of values in float format between 0
    and 1 that are stored in a `numpy` array. The value of the array is a labeled
    image called `image`. The `image` array is then reshaped into a 28 x 28 matrix
    called `pixels` that has a black color for any value at 0 and a gray shade color
    for any color that is not 0\. The higher the value, the lighter the gray shade
    of color. An example can be seen in the following screenshot for the digit 8:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最初，图像仅是介于 0 和 1 之间的浮动格式值，存储在 `numpy` 数组中。数组的值是一个带标签的图像，称为 `image`。然后，`image`
    数组被重塑为一个 28 x 28 的矩阵，称为 `pixels`，其中任何值为 0 的位置为黑色，任何非 0 的颜色位置则为灰色。值越高，灰色的阴影颜色就越浅。下图展示了数字
    8 的一个例子：
- en: '![](img/fe88bf0f-e733-4d79-b8d4-6e4619614ec6.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fe88bf0f-e733-4d79-b8d4-6e4619614ec6.png)'
- en: 'The output of the loop produces two handwritten images for the numbers 7 and
    3 along with their labels, as seen in the following screenshot:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 循环的输出生成了两个手写图像，分别为数字 7 和 3，以及它们的标签，如下图所示：
- en: '![](img/fe1e9692-b9e0-4732-b6b2-ebe49448854a.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fe1e9692-b9e0-4732-b6b2-ebe49448854a.png)'
- en: In addition to the images being plotted, the label from the training dataset
    is also printed above the image. The label is an array of length 10, with values
    of 0 or 1 only for all 10 digits. For digit 7, the 8th element in the array is
    of value 1 and for digit 3, the 4th element in the array is of value 1\. All other
    values are 0.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了绘制图像之外，训练数据集中的标签也会显示在图像上方。标签是一个长度为 10 的数组，所有 10 个数字的值仅为 0 或 1。对于数字 7，数组中的第
    8 个元素的值为 1；对于数字 3，数组中的第 4 个元素的值为 1。其他所有值均为 0。
- en: There's more...
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: It may not be immediately obvious what the numeric value of the image is. While
    most will be able to identify that the first image is a 7 and the second image
    is a 3, it would be helpful to have confirmation from the label array.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图像的数值可能并不立即显现出来。虽然大多数人能够识别出第一张图像是数字 7，第二张图像是数字 3，但从标签数组中确认这一点会更有帮助。
- en: There are 10 elements in the array, each referencing a value for labels 0 through
    9 in numeric order. Since the first array has a positive or 1 value in the 8th
    slot, that is an indication that the value of the image is a 7, as 7 in the 8th
    index in the array. All other values should be 0\. Additionally, the second image
    has a value of 1 in the 4th spot, indicating a positive value for 3.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 数组中有 10 个元素，每个元素表示标签 0 至 9 的值，按数字顺序排列。由于第一个数组在第 8 个位置具有正值或 1，这表示图像的值是 7，因为 7
    在数组中的第 8 个索引位置。其他所有值应为 0。此外，第二张图像在第 4 个位置的值为 1，表示图像值为 3。
- en: See also
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另见
- en: 'Leun, Cortes, and Burges discuss why the image pixelations were set at 28 x
    28 in the following statement:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Leun、Cortes 和 Burges 在以下声明中讨论了为什么图像像素设置为 28 x 28：
- en: he original black and white (bilevel) images from NIST were size normalized
    to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting
    images contain grey levels as a result of the anti-aliasing technique used by
    the normalization algorithm. The images were centered in a 28x28 image by computing
    the center of mass of the pixels, and translating the image so as to position
    this point at the center of the 28x28 field.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 来自 NIST 的原始黑白（二值）图像经过大小标准化，适应于一个 20x20 像素的框，同时保持其纵横比。标准化算法使用抗锯齿技术，使得图像包含灰度级。图像通过计算像素的质心，然后平移图像，使该点位于
    28x28 区域的中心，从而将图像居中。
- en: --Leun, Cortes, and Burges from [http://yann.lecun.com/exdb/mnist/.](http://yann.lecun.com/exdb/mnist/)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: --Leun、Cortes 和 Burges 来自 [http://yann.lecun.com/exdb/mnist/.](http://yann.lecun.com/exdb/mnist/)
- en: 'Pain Point #3: Exporting MNIST images as files'
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '痛点 #3：将 MNIST 图像导出为文件'
- en: We often need to work within the image directly and not as an array vector.
    This section will guide us through converting our arrays to `.png` images.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常需要直接在图像上工作，而不是作为数组向量。本节将引导我们将数组转换为 `.png` 图像。
- en: Getting ready
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Exporting the vectors to images requires importing the following library:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 导出向量为图像需要导入以下库：
- en: '`import image from matplotlib`'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import image from matplotlib`'
- en: How to do it...
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: This section walks through the steps to convert a sample of MNIST arrays to
    files in a local folder.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍如何将 MNIST 数组样本转换为本地文件夹中的文件。
- en: 'Create a subfolder to save our images to our main folder of `MNIST/` using
    the following script:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本创建一个子文件夹，将图像保存到 `MNIST/` 的主文件夹中：
- en: '[PRE5]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Loop through the first 10 samples of MNIST arrays and convert them to `.png`
    files using the following script:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 遍历 MNIST 数组的前 10 个样本，并使用以下脚本将它们转换为 `.png` 文件：
- en: '[PRE6]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Execute the following script to see the list of images from `image_no_1.png` to `image_no_9.png`:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本查看从`image_no_1.png`到`image_no_9.png`的图像列表：
- en: '[PRE7]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: How it works...
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: This section explains how the MNIST arrays are converted to images and saved
    to a local folder.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了如何将MNIST数组转换为图像，并保存到本地文件夹。
- en: We create a subfolder called `MNIST/images` to help us store our temporary `.png`
    images and separate them from the MNIST arrays and labels.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个名为`MNIST/images`的子文件夹，以帮助存储临时的`.png`图像，并将它们与MNIST数组和标签分开存储。
- en: Once again we loop through `data.train` images and obtain nine arrays that can
    be used for sampling. The images are then saved as `.png` files to our local directory
    with the following format: `'image_no_{}.png'.format(i), pixels, cmap = 'gray'`
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们再次遍历`data.train`中的图像，获取九个可以用于采样的数组。然后，这些图像会以`.png`文件格式保存到本地目录，格式为：`'image_no_{}.png'.format(i),
    pixels, cmap = 'gray'`
- en: 'The output of the nine images can be seen in our local directory, as seen in
    the following screenshot:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以在本地目录中看到九张图像的输出，正如以下截图所示：
- en: '![](img/755def3b-f925-46cd-9f1a-eaed32ab2651.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/755def3b-f925-46cd-9f1a-eaed32ab2651.png)'
- en: There's more...
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'In addition to seeing the list of images in our directory, we can also view
    the image in our directory within Linux, as seen in the following screenshot:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 除了查看目录中的图像列表，我们还可以在Linux中查看我们目录中的图像，正如以下截图所示：
- en: '![](img/36415522-ca99-46de-b043-a9d84796217d.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36415522-ca99-46de-b043-a9d84796217d.png)'
- en: See also
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'To learn more about `image.imsave` from `matplotlib` visit the following website:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于`matplotlib`中的`image.imsave`，请访问以下网站：
- en: '[https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imsave.html](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imsave.html)'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imsave.html](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imsave.html)'
- en: 'Pain Point #4: Augmenting MNIST images'
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '痛点 #4：增强MNIST图像'
- en: One of the main drawbacks of working with image recognition is the lack of variety
    in some of the images available. This may cause the convolutional neural network
    to not operate as optimally as we would like, and return less than ideal results
    due to the lack of variety in the training data. There are techniques available
    to bypass that shortcoming and we discuss one of them in this section.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 使用图像识别的主要缺点之一是一些可用图像的多样性不足。这可能导致卷积神经网络无法像我们希望的那样优化运行，且由于训练数据的多样性不足，结果可能不理想。针对这个缺点，有一些技术可以绕过，我们将在本节中讨论其中的一种。
- en: Getting ready
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备开始
- en: Once again much of the heavy lifting is already done for us. We will use a popular
    Python package, `augmentor`, that is frequently used with machine learning and
    deep learning modeling to generate additional versions of existing images distorted
    and augmented for variety.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 再次说明，大部分繁重的工作已经为我们完成。我们将使用一个流行的Python包`augmentor`，它经常用于机器学习和深度学习建模，用于生成现有图像的扭曲和增强版本，以增加图像的多样性。
- en: 'The package will first have to be `pip` installed using the following script:
    `pip install augmentor`'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，必须通过以下脚本使用`pip`安装该包：`pip install augmentor`
- en: 'We should then have confirmation that the package is installed, as seen in
    the following screenshot:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们应该确认包已经安装，正如下面的截图所示：
- en: '![](img/48cf4d3f-6f9f-43d8-b2dc-d607f1cf2794.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/48cf4d3f-6f9f-43d8-b2dc-d607f1cf2794.png)'
- en: 'We will then need to import the pipeline class from augmentor:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们需要从augmentor导入管道类：
- en: '`from Augmentor import Pipeline`'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`from Augmentor import Pipeline`'
- en: How to do it...
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: This section walks through the steps to increase the frequency and augmentation
    of our nine sample images.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍如何增加我们的九张样本图像的频率和增强效果。
- en: 'Initialize the `augmentor` function using the following script:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本初始化`augmentor`函数：
- en: '[PRE8]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Execute the following script so that the `augmentor` function can `rotate`
    our images with the following specifications:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，使得`augmentor`函数可以按以下规格`旋转`我们的图像：
- en: '[PRE9]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Execute the following script so that each image is augmented through two iterations
    10 times each:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下脚本，使得每张图像通过两个迭代进行增强，每次迭代10次：
- en: '[PRE10]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: How it works...
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: This section explains how our nine images are used to create additional images
    that are distorted.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将解释如何利用我们的九张图像生成额外的扭曲图像。
- en: 'We need to create a `Pipeline` for our image transformation and specify the
    location of the images that will be used.  This ensures the following:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要为图像转换创建一个`Pipeline`，并指定将要使用的图像位置。这可以确保以下内容：
- en: The source location of the images
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像的源位置
- en: The number of images that will be transformed
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将要转换的图像数量
- en: The destination location of the images
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像的目标位置
- en: 'We can see that our destination location is created with a subfolder called
    `/output/` as seen in the following screenshot:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到，我们的目标位置是通过一个名为`/output/`的子文件夹创建的，如下图所示：
- en: '![](img/b894e720-39ad-4b5d-8811-934591624989.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b894e720-39ad-4b5d-8811-934591624989.png)'
- en: The `augmentor` function is configured to rotate each image up to 25 degrees
    to the right or 25 degrees to the left with a 90 percent probability. Basically,
    the probability configuration determines how often an augmentation takes place.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`augmentor`函数被配置为将每张图像旋转最多25度向右或25度向左，概率为90%。基本上，概率配置决定了增强操作发生的频率。'
- en: 'A loop is created to go through each image twice and apply two transformations
    to each image; however, since we did add a probability to each transformation
    some images may not get transformed and others may get transformed more than twice.
    Once the transformations are complete, we should get a message indicating so,
    as seen in the following screenshot:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建了一个循环，通过每张图像两次，并对每张图像应用两次变换；然而，由于我们确实给每个变换添加了概率，因此某些图像可能不会被转换，而其他图像可能会被转换超过两次。变换完成后，我们应该会收到一条消息，指示变换已完成，如下图所示：
- en: '![](img/a3d8549c-a738-41f1-949e-96d894837ede.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a3d8549c-a738-41f1-949e-96d894837ede.png)'
- en: 'Once we have the augmentations complete, we can visit the `/output/` subdirectory
    and see how each digit is slightly altered, as seen in the following screenshot:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦完成增强操作，我们可以访问`/output/`子目录，查看每个数字是如何略微变化的，如下图所示：
- en: '![](img/ba5e0a68-9854-4537-bfd1-7147786af584.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba5e0a68-9854-4537-bfd1-7147786af584.png)'
- en: We can see that we have several variations of the digits 3, 1, 8, 0, and 9 all
    with varying degrees of rotation. We now have tripled our sample data set and
    added more variety without having to go out and extract more images for training
    and testing purposes.
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到，数字3、1、8、0和9的几种变体，它们的旋转角度各不相同。我们现在已经三倍增加了我们的样本数据集，并增加了更多的多样性，而不需要去提取更多的图像用于训练和测试。
- en: There's more...
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'We only applied the `rotate` transformation; however, there are several transformation
    and augmentation features available to apply to images:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只应用了`rotate`变换；然而，实际上有多种变换和增强功能可以应用到图像上：
- en: Perspective skewing
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 透视歪斜
- en: Elastic distortions
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弹性失真
- en: Shearing
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 剪切
- en: Cropping
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 裁剪
- en: Mirroring
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 镜像
- en: While not all of these transformations will be necessary when looking to increase
    frequency and variety of a training dataset, it may be beneficial to use some
    combination of features and evaluate model performance.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有这些变换在增加训练数据集的频率和多样性时都必要，但使用某些功能的组合并评估模型性能可能是有益的。
- en: See also
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参见
- en: 'To learn more about `augmentor` visit the following website:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于`augmentor`的信息，请访问以下网站：
- en: '[https://augmentor.readthedocs.io/en/master/](https://augmentor.readthedocs.io/en/master/)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://augmentor.readthedocs.io/en/master/](https://augmentor.readthedocs.io/en/master/)'
- en: 'Pain Point #5: Utilizing alternate sources for trained images'
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 痛点#5：利用其他来源的训练图像
- en: Sometimes there are just not enough resources available to perform a convolutional
    neural network. The resources could be limited from a computational perspective
    or a data collection perspective. In situations like these, we rely on other sources
    to help us with classifying our images.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，进行卷积神经网络操作时可能没有足够的资源。资源可能在计算角度或数据收集角度上受到限制。在这种情况下，我们依赖其他来源来帮助我们对图像进行分类。
- en: Getting ready
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The technique for utilizing pre-trained models as the source for testing outcomes
    on other datasets is referred to as transfer learning. The advantage here is that
    much of the CPU resources allotted for training images is outsourced to a pre-trained
    model. Transfer learning has become a common extension of deep learning more recently.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 利用预训练模型作为测试其他数据集结果来源的技术被称为迁移学习。其优势在于，大部分用于训练图像的CPU资源被外包给预训练模型。最近，迁移学习已成为深度学习的一个常见扩展。
- en: How to do it...
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: This section explains how the process of transfer learning works.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了迁移学习的工作原理。
- en: Collect a series of datasets or images that you are interested in classifying, just
    as you would with traditional machine learning or deep learning.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集一系列你感兴趣分类的数据集或图像，就像你在传统机器学习或深度学习中做的那样。
- en: Split the dataset into a training and testing split such as 75/25 or 80/20.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集分成训练集和测试集，例如75/25或80/20。
- en: Identify a pre-trained model that will be used to identify the patterns and
    recognition of the images you are looking to classify.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个预训练模型来识别你希望分类的图像的模式和特征。
- en: Build a deep learning pipeline that connects the training data to the pre-trained
    model and develops the weights and parameters needed to identify the test data.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个深度学习管道，将训练数据与预训练模型连接，并生成识别测试数据所需的权重和参数。
- en: Finally, evaluate the model performance on the test data.
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，评估模型在测试数据上的表现。
- en: How it works...
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: This section explains the process of transfer learning when applied to the MNIST
    dataset.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了将迁移学习应用于 MNIST 数据集的过程。
- en: We are definitely taking a shortcut approach with transfer learning as we are
    either limited in resources, time, or both as we are taking prior work that has
    already been done and hoping that it will help us solve something new.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在使用迁移学习时无疑是在走捷径，因为我们可能在资源、时间或两者都有限的情况下，利用已经完成的前期工作，并希望它能帮助我们解决新的问题。
- en: 'Since we are dealing with an image classification problem, we should use a
    pre-trained model that has worked with classifying common images in the past.
    There are many common ones out there but two that stand out are:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们面临的是图像分类问题，应该使用一个曾经处理过常见图像分类的预训练模型。市面上有许多常见的模型，但有两个特别突出：
- en: The ResNet model developed at Microsoft.
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 微软开发的 ResNet 模型。
- en: The Inception model developed at Google.
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 谷歌开发的 Inception 模型。
- en: Both models are useful for image classification because both Microsoft and Google
    have a wide spectrum of images that are available to them to train a robust model
    that can extract features at a more detailed level.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 两种模型对于图像分类都很有用，因为微软和谷歌都有广泛的图像资源，可以用来训练一个强大的模型，从而在更详细的层面上提取特征。
- en: Directly within Spark, there is the ability to build a deep learning pipeline
    and to call about a class called `DeepImageFeaturizer` and apply the `InceptionV3`
    model to a set of features collected from training data. The trained dataset is
    then evaluated on the testing data using some type of binary or multiclassification
    evaluator.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Spark 中，你可以构建一个深度学习管道，并调用一个名为 `DeepImageFeaturizer` 的类，应用 `InceptionV3` 模型到从训练数据中收集的一组特征。然后，使用某种二分类或多分类评估器在测试数据上评估训练数据集。
- en: A pipeline within deep learning or machine learning is simply the workflow process
    used to get from an initial environment of data collection to a final evaluation
    or classification environment on the collected data by applying a model.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 深度学习或机器学习中的管道是指从数据收集的初始环境到应用模型对收集的数据进行最终评估或分类的环境之间的工作流过程。
- en: There's more...
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多…
- en: As with everything, there are pros and cons to using transfer learning. As we
    discussed earlier on in the section, transfer learning is ideal when you are limited
    in resources to perform your own modeling on a large dataset. There is always
    the chance that the source data at hand does not exhibit many of the features
    unique to it in the pre-trained models leading to poor model performance. There
    is always the option to switch from one pre-trained model to another and evaluate
    model performance. Again, transfer learning is a fail fast approach that can be
    taken when other options are not available.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 像所有事物一样，使用迁移学习也有利有弊。正如我们在本节前面讨论的，迁移学习非常适合在你资源有限，无法对大数据集进行建模时使用。也有可能源数据在预训练模型中没有展示出许多独特的特征，从而导致模型性能不佳。你总是可以选择将一个预训练模型换成另一个，并重新评估模型的性能。同样，迁移学习是一种“快速失败”的方法，当其他选择不可用时可以使用。
- en: See also
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'To learn more about ResNet at Microsoft, visit the following website:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解更多关于微软 ResNet 的信息，请访问以下网站：
- en: '[https://resnet.microsoft.com/](https://resnet.microsoft.com/)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://resnet.microsoft.com/](https://resnet.microsoft.com/)'
- en: 'To learn more about Inception at Google, visit the following website:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解更多关于谷歌 Inception 的信息，请访问以下网站：
- en: '[https://www.tensorflow.org/tutorials/image_recognition](https://www.tensorflow.org/tutorials/image_recognition)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.tensorflow.org/tutorials/image_recognition](https://www.tensorflow.org/tutorials/image_recognition)'
- en: 'To learn more specifically about InceptionV3, you can read the following paper
    titled <q>Rethinking the Inception Architecture for Computer Vision</q> at Cornell
    University:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于 InceptionV3 的信息，你可以阅读康奈尔大学的以下论文，标题为《重新思考计算机视觉中的 Inception 架构》：
- en: '[https://arxiv.org/abs/1512.00567](https://arxiv.org/abs/1512.00567)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://arxiv.org/abs/1512.00567](https://arxiv.org/abs/1512.00567)'
- en: 'Pain Point #6: Prioritizing high-level libraries for CNNs'
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '痛点 #6：优先考虑CNN的高级库'
- en: There are many libraries available to perform convolutional neural networks.
    Some of them are considered low-level such as TensorFlow, where much of the configuration
    and setup requires extensive coding. This can be considered a major pain point
    for an inexperienced developer. There are other libraries, such as Keras, that
    are high-level frameworks built on top of libraries such as TensorFlow. These
    libraries require much less code to get up and running with building a convolutional
    neural network. Often times developers getting started with building a neural
    network will try and implement a model with TensorFlow and run into several issues
    along the way. This section will propose initially building a convolutional neural
    network with Keras instead to predict the hand-written images from the MNIST dataset.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多库可以用于执行卷积神经网络。一些被认为是低级的，如TensorFlow，其中许多配置和设置需要大量的编码。这对于缺乏经验的开发人员来说是一个主要的痛点。还有一些库，比如Keras，它们是建立在像TensorFlow这样的库之上的高级框架。这些库需要的代码更少，可以更快地开始构建卷积神经网络。许多初学者在构建神经网络时，往往会尝试使用TensorFlow实现一个模型，但在过程中会遇到许多问题。本节将建议首先使用Keras构建一个卷积神经网络，以预测MNIST数据集中的手写图像。
- en: Getting ready
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'In this section, we will be working with Keras to train a model for recognizing
    handwritten images from MNIST. You can install Keras by executing the following
    command at the terminal:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用Keras来训练一个识别MNIST手写图像的模型。你可以通过在终端执行以下命令来安装Keras：
- en: '[PRE11]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: How to do it...
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: This section walks through the steps to build a model to recognize handwritten
    images from MNIST.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将演示如何构建一个模型，以识别来自MNIST的手写图像。
- en: 'Create testing and training images and labels based on the MNIST dataset from
    the following variables using the following script:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本根据以下变量从MNIST数据集创建测试和训练图像及标签：
- en: '[PRE12]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Reshape the testing and training arrays using the following script:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本重新调整测试和训练数组的形状：
- en: '[PRE13]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Import the following from `keras` to build the convolutional neural network
    model:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`keras`导入以下内容，以构建卷积神经网络模型：
- en: '[PRE14]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Set the image ordering using the following script:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本设置图像排序：
- en: '[PRE15]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Initialize the `Sequential` `model` using the following script:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本初始化`Sequential`模型：
- en: '[PRE16]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Add layers to the `model` using the following script:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本向`model`添加层：
- en: '[PRE17]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Compile the `model` using the following script:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本编译`model`：
- en: '[PRE18]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Train the `model` using the following script:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本训练`model`：
- en: '[PRE19]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Test the `model` performance using the following script:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本测试`model`的性能：
- en: '[PRE20]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: How it works...
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: This section explains how the convolutional neural network is built on Keras
    to identify handwritten images from MNIST.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了如何在Keras上构建卷积神经网络，以识别MNIST中的手写图像。
- en: For any model development, we need to identify our testing and training datasets
    as well as the features and the labels. In our case, it is pretty straightforward
    as the MNIST data from TensorFlow is already broken up into `data.train.images`
    for the features and `data.train.labels` for the labels. Additionally, we want
    to convert the labels into arrays, so we utilize `np.asarray()` for `ytest` and
    `ytrain`.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于任何模型开发，我们需要识别我们的测试和训练数据集，以及特征和标签。在我们的案例中，这非常简单，因为TensorFlow中的MNIST数据已经拆分为`data.train.images`作为特征，`data.train.labels`作为标签。此外，我们还需要将标签转换为数组，因此我们使用`np.asarray()`来处理`ytest`和`ytrain`。
- en: 'The arrays for `xtrain`, `xtest`, `ytrain`, and `ytest` are currently not in
    the proper shape to be used for a convolutional neural network within Keras. As
    we identified early on in the chapter, the features for the MNIST images represent
    28 x 28-pixel images and the labels indicate one of ten values from 0 through
    9\. The x-arrays will be reshaped to (,28,28,1) and the y-arrays will be reshaped
    to (,10). The `shape` of the new arrays can be seen in the following screenshot:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 目前，`xtrain`、`xtest`、`ytrain`和`ytest`数组的形状不适合在Keras中用于卷积神经网络。正如我们在本章早些时候所提到的，MNIST图像的特征表示28x28像素的图像，而标签表示从0到9的十个值之一。`x`数组将被重塑为（,28,28,1），`y`数组将被重塑为（,10）。新数组的`shape`可以通过以下截图看到：
- en: '![](img/9d8995f0-b3cd-4f67-ac86-77e4906fd698.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9d8995f0-b3cd-4f67-ac86-77e4906fd698.png)'
- en: As mentioned previously, Keras is a high-level library; therefore, it does not
    perform tensor or convolutional operations without the assistance of a lower level
    library such as TensorFlow. In order to configure these operations, we set the
    `backend` to be `K` for `Keras` with the image dimensional ordering, `image_dim_ordering`,
    set to `tf` for TensorFlow.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述，Keras 是一个高级库，因此它在没有 TensorFlow 等低级库的帮助下无法执行张量或卷积操作。为了配置这些操作，我们将 `backend`
    设置为 `K`，表示 `Keras`，并将图像维度排序 `image_dim_ordering` 设置为 `tf`，以便与 TensorFlow 配合使用。
- en: Please note that the backend could also be set to other low-level libraries,
    such as `Theano`. Instead of `tf`, we would set the dimensional ordering to `th`.
    Additionally, we would need to reconstruct the shaping of the features. However,
    in the past few years, `Theano` has not garnered the same adoption rate `TensorFlow`
    has.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，后端也可以设置为其他低级库，如 `Theano`。如果使用 `Theano`，而不是 `tf`，我们需要将维度排序设置为 `th`。此外，我们还需要重构特征的形状。然而，在过去几年中，`Theano`
    并未获得像 `TensorFlow` 那样的普及度。
- en: Once we import the necessary libraries to build the CNN model, we can begin
    constructing the sequences or layers, `Sequential()`, of the model. For demonstration
    purposes, we will keep this model as simple as possible with only 4 layers to
    prove that we can still gain a high accuracy with minimal complexity. Each layer
    is added using the `.add()` method.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们导入了构建 CNN 模型所需的库，就可以开始构建模型的序列或层，`Sequential()`。为了演示，我们将模型保持尽可能简单，仅使用 4 层，以证明即使在最小复杂度下，我们也能获得高准确率。每一层都是通过
    `.add()` 方法添加的。
- en: The first layer is set to build a 2-Dimensional (`Conv2D`) convolution layer,
    which is common for spatial images such as the MNIST data. Since it is the first
    layer, we must explicitly define the `input_shape` of the incoming data. Additionally,
    we specify a `kernel_size` that is used to set the height and width of the window
    filter used for convolution. Usually, this is either a 3x3 window or 5x5 window
    for the 32 filters. Additionally, we have to set an activation function for this
    layer and rectified linear units, `relu`, are a good option here for efficiency
    purposes, especially early on in the neural network.
  id: totrans-220
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一层设置为构建一个二维（`Conv2D`）卷积层，这是处理空间图像（如 MNIST 数据）时常见的做法。由于它是第一层，我们必须显式定义输入数据的 `input_shape`。此外，我们还指定了一个
    `kernel_size`，用于设置卷积窗口的高度和宽度。通常，这个窗口是一个 3x3 或 5x5 的窗口，用于 32 个滤波器。此外，我们还需要为该层设置一个激活函数，使用修正线性单元（`relu`）是一个有效的选择，尤其是在神经网络的早期阶段，它有助于提高效率。
- en: Next, the second layer flattens the first layer inputs to retrieve a classification
    that we can use to determine whether the image is one of a possible 10 digits.
  id: totrans-221
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，第二层将第一个层的输入展开，以获取一个分类结果，我们可以用来判断该图像是否属于可能的 10 个数字之一。
- en: Third, we pass the outputs from the second layer into a `dense` layer that has
    128 hidden layers with another `relu` activation function. The function within
    a densely connected layer incorporates the `input_shape` and `kernel_size` as
    well as the bias to create the output for each of the 128 hidden layers.
  id: totrans-222
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三步，我们将第二层的输出传递给一个具有 128 个隐藏层并使用 `relu` 激活函数的 `dense` 层。密集连接层中的函数包含了 `input_shape`
    和 `kernel_size` 以及偏置项，用于为每个 128 个隐藏层生成输出。
- en: The final layer is the output that will determine what the predicted value will
    be for the MNIST image. We add another `dense` layer with a `sigmoid` function
    to output probabilities for each of the 10 possible scenarios our MNIST image
    could be. Sigmoid functions are useful for binary or multiclass classification
    outcomes.
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一层是输出层，它将决定预测的 MNIST 图像值。我们添加了另一个 `dense` 层，并使用 `sigmoid` 函数输出每个可能的 10 种情况的概率。Sigmoid
    函数对于二分类或多分类问题的输出非常有用。
- en: The next step is to compile the model using `adam` for the `optimizer` and evaluating
    `accuracy` for the `metrics`. The `adam` optimizer is common for CNN models as
    is using `categorical_crossentropy` as a loss function when dealing with multiclassification
    scenarios for 10 possible outcomes as is our case.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是使用 `adam` 优化器编译模型，并使用 `accuracy` 评估 `metrics`。`adam` 优化器在 CNN 模型中很常见，同时当处理具有
    10 个可能输出的多分类情形时，使用 `categorical_crossentropy` 作为损失函数也是常规做法。
- en: 'We train the model using a `batch_size` of `512` images at a time over `5`
    runs or `epochs`. The loss and accuracy of each epoch are captured and can be
    seen in the following screenshot:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用每次处理 `512` 张图像的 `batch_size`，在 `5` 次训练（即 `epochs`）中训练模型。每个训练周期的损失和准确率都会被记录，并可以在下面的截图中查看：
- en: '![](img/523622b0-32c1-4a34-a0b7-37358cd01f84.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/523622b0-32c1-4a34-a0b7-37358cd01f84.png)'
- en: 'We calculate the accuracy and the loss rate by evaluating the trained model
    on the test dataset as seen in the following screenshot:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过在测试数据集上评估训练后的模型来计算准确率和损失率，如下图所示：
- en: '![](img/2bcbcfc2-85d3-453b-8acd-9cb6a5f7b1bf.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2bcbcfc2-85d3-453b-8acd-9cb6a5f7b1bf.png)'
- en: Our model seems to be performing well with a 98.6% accuracy rate and a 5% loss
    rate.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的模型似乎表现良好，准确率为98.6%，损失率为5%。
- en: We built a simple convolutional neural network in Keras using five lines of
    code for the actual model design. Keras is a great way to get a model up and running
    in little time and code. Once you are ready to move onto more sophisticated model
    development and control, it may make more sense to build a convolutional neural
    network in TensorFlow.
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在Keras中构建了一个简单的卷积神经网络，仅用五行代码设计了实际模型。Keras是一个非常好的工具，可以在短时间内用很少的代码启动模型。一旦你准备好进行更复杂的模型开发和控制，使用TensorFlow构建卷积神经网络可能更为合适。
- en: There's more...
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'In addition to retrieving the accuracy of the model we can also produce the
    shapes within each layer of the CNN modeling process by executing the following
    script:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 除了检索模型的准确性，我们还可以通过执行以下脚本来生成CNN建模过程每一层的形状：
- en: '[PRE21]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The output of the `model.summary()` can be seen in the following screenshot:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '`model.summary()`的输出可以在以下截图中看到：'
- en: '![](img/aac3bf89-2b4a-407a-a159-a8ae8df4bf62.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aac3bf89-2b4a-407a-a159-a8ae8df4bf62.png)'
- en: We see that the output shape of the first layer (None, 24, 24, 32) was flattened
    out into a shape of (None, 18432) by multiplying 24 x 24 x 32 within the second
    layer. Additionally, we see our third and fourth layers have the shape that we
    assigned them using the Dense layer function
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到第一层的输出形状（None, 24, 24, 32）在第二层通过乘法24 x 24 x 32被展平为形状（None, 18432）。另外，我们看到第三层和第四层的形状是我们使用Dense层函数分配给它们的。
- en: See also
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'To learn more about 2D convolutional layer development in Keras, visit the
    following website:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关在Keras中开发2D卷积层的更多信息，请访问以下网站：
- en: '[https://keras.io/layers/convolutional/#conv2d](https://keras.io/layers/convolutional/#conv2d)'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://keras.io/layers/convolutional/#conv2d](https://keras.io/layers/convolutional/#conv2d)'
- en: 'To learn how to build a convolutional neural network in TensorFlow with MNIST
    images, visit the following website:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 要学习如何在TensorFlow中使用MNIST图像构建卷积神经网络，请访问以下网站：
- en: '[https://www.tensorflow.org/versions/r1.4/get_started/mnist/pros](https://www.tensorflow.org/versions/r1.4/get_started/mnist/pros)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.tensorflow.org/versions/r1.4/get_started/mnist/pros](https://www.tensorflow.org/versions/r1.4/get_started/mnist/pros)'
