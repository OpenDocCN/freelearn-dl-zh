- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序言
- en: This book will start off by introducing the foundations of machine learning,
    what makes learning visible, demonstrating the traditional machine learning techniques
    with some examples and eventually deep learning. You will then move to creating
    machine learning models that will eventually lead you to neural networks. You
    will get familiar with the basics of deep learning and explore various tools that
    enable deep learning in a powerful yet user-friendly manner. With a very low starting
    point, this book will enable a regular developer to get hands-on experience with
    deep learning. You will learn all the essentials needed to explore and understand
    what deep learning is and will perform deep learning tasks first-hand. Also, we
    will be using one of the most widely used deep learning frameworks. TensorFlow
    has big community support that is growing day by day, which makes it a good option
    for building your complex deep learning applications.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将从介绍机器学习的基础开始，阐述什么使学习变得可见，通过一些示例演示传统的机器学习技术，最终介绍深度学习。接着，您将学习如何创建机器学习模型，并最终引导您进入神经网络的领域。您将熟悉深度学习的基础，并探索各种能够以强大而易用的方式支持深度学习的工具。通过一个非常低的起点，本书将帮助普通开发者亲身体验深度学习。您将学习所需的所有基础知识，以便探索和理解深度学习，并亲自执行深度学习任务。此外，我们将使用一个广泛使用的深度学习框架。TensorFlow拥有一个日益壮大的社区支持，是构建复杂深度学习应用程序的一个很好的选择。
- en: Who this book is for
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书适合人群
- en: This book is a starting point for those who are keen on knowing about deep learning
    and implementing it but do not have an extensive background in machine learning,
    complex statistics, and linear algebra.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书是为那些热衷于了解深度学习并实现它的人而准备的，但这些人并没有广泛的机器学习、复杂统计学和线性代数背景。
- en: What this book covers
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书涵盖的内容
- en: '[Chapter 1](c6be0d67-2ba9-45ac-b6dd-116518853f42.xhtml), *Data science - Bird''s-eye
    view*, explains that data science or machine learning is the process of giving
    the machines the ability to learn from a dataset without being told or programmed.
    For instance, it will be extremely hard to write a program that takes a hand-written
    digit as an input image and outputs a value from 0-9 according to the number that''s
    written in this image. The same applies to the task of classifying incoming emails
    as spam or non-spam. To solve such tasks, data scientists uses learning methods
    and tools from the field of data science or machine learning to teach the computer
    how to automatically recognize digits by giving it some explanatory features that
    can distinguish each digit from another. The same for the spam/non-spam problem,
    instead of using regular expressions and writing hundred of rules to classify
    the incoming emails, we can teach the computer through specific learning algorithms
    how to distinguish between spam and non-spam emails.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[第1章](c6be0d67-2ba9-45ac-b6dd-116518853f42.xhtml)，*数据科学——鸟瞰图*，解释了数据科学或机器学习是赋予机器从数据集中学习的能力，而不需要明确的指令或编程。例如，编写一个程序，从手写数字的输入图像中输出0到9之间的一个值，根据图像中写下的数字来判断，这是极其困难的。同样，判断进入的电子邮件是垃圾邮件还是非垃圾邮件的任务也是如此。为了解决这些任务，数据科学家使用数据科学或机器学习领域的学习方法和工具，教计算机如何通过一些能区分每个数字的特征来自动识别数字。对于垃圾邮件/非垃圾邮件问题也是一样，我们可以通过特定的学习算法来教计算机如何区分垃圾邮件和非垃圾邮件，而不是使用常规表达式并编写数百条规则来分类进入的电子邮件。'
- en: '[Chapter 2](6e292a27-8ff3-4d9c-9186-433455cb380c.xhtml), *Data Modeling in
    Action - The Titanic Example*, linear models are the basic learning algorithms
    in the field of data science. Understanding how a linear model works is crucial
    in your journey of learning data science because it''s the basic building block
    for most of the sophisticated learning algorithms out there, including neural
    networks.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[第2章](6e292a27-8ff3-4d9c-9186-433455cb380c.xhtml)，*数据建模实践——泰坦尼克号示例*，线性模型是数据科学领域中最基本的学习算法。理解线性模型的工作原理对于您学习数据科学的旅程至关重要，因为它是大多数复杂学习算法的基本构建块，包括神经网络。'
- en: '[Chapter 3](171e9b02-5ed8-4635-85b0-9d46eddbd198.xhtml), *Feature Engineering
    and Model Complexity – Titanic Example Revisited*, covers model complexity and
    assessment. This is an important towards building a successful data science system.
    There are lots of tools that you can use to assess and choose your model. In this
    chapter, we are going to address some of tools that can help you to increase the
    value of your data by adding more descriptive features and extracting meaningful
    information from existing ones. We are also going to address other tools related
    to optimal number features and learn why it''s a problem to have a large number
    of features and fewer training samples/observations.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[第3章](171e9b02-5ed8-4635-85b0-9d46eddbd198.xhtml)，*特征工程与模型复杂度 - 再访 Titanic
    示例*，涵盖了模型复杂度和评估。这是构建成功数据科学系统的重要一步。有许多工具可以帮助你评估和选择模型。在这一章中，我们将讨论一些可以通过添加更多描述性特征并从现有特征中提取有意义信息来提高数据价值的工具。我们还将探讨与特征数量优化相关的其他工具，并了解为何特征数量过多而训练样本/观察值过少会带来问题。'
- en: '[Chapter 4](c1132ef7-e238-4318-a227-a23d67005917.xhtml), *Get Up and Running
    with TensorFlow*, gives an overview of one of the most widely used deep learning
    frameworks. TensorFlow has big community support that is growing day by day, which
    makes it a good option for building your complex deep learning applications'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[第4章](c1132ef7-e238-4318-a227-a23d67005917.xhtml)，*快速上手 TensorFlow*，概述了一个广泛使用的深度学习框架。TensorFlow
    拥有日益壮大的社区支持，这使它成为构建复杂深度学习应用的一个不错选择。'
- en: '[Chapter 5](8faa1d8b-609c-437a-829e-42bf170e2efc.xhtml), *Tensorflow in Action
    - Some Basic Examples*, will explain the main computational concept behind TensorFlow,
    which is the computational graph model, and demonstrate how to get you on track
    by implementing linear regression and logistic regression.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[第5章](8faa1d8b-609c-437a-829e-42bf170e2efc.xhtml)，*TensorFlow 实战 - 一些基本示例*，将解释
    TensorFlow 背后的主要计算概念——计算图模型，并通过实现线性回归和逻辑回归来演示如何帮助你入门。'
- en: '[Chapter 6](4ea31f54-ffc5-46fc-9b0f-86427c80868f.xhtml), *Deep Feed-forward
    Neural Networks - Implementing Digit Classification*, explains that a **feed-forward
    neural network** (**FNN**) is a special type of neural network wherein links/connections
    between neurons do not form a cycle. As such, it is different from other architectures
    in a neural network that we will get to study later on in this book (recurrent-type
    neural networks). The FNN is a widely used architecture and it was the first and
    simplest type of neural network. In this chapter, we will go through the architecture
    of a typical ;FNN, and we will be using the TensorFlow library for this. After
    covering these concepts, we will give a practical example of digit classification.
    The question of this example is, *Given a set of images that contain handwritten
    digits, how can you classify these images into 10 different classes (0-9)*?'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[第6章](4ea31f54-ffc5-46fc-9b0f-86427c80868f.xhtml)，*深度前馈神经网络 - 实现数字分类*，解释了 **前馈神经网络**（**FNN**）是一种特殊类型的神经网络，其中神经元之间的连接/链接不形成循环。因此，它与我们在本书后面将要学习的其他神经网络架构（如递归神经网络）不同。FNN
    是一种广泛使用的架构，也是最早、最简单的神经网络类型。在本章中，我们将介绍典型 FNN 的架构，并将使用 TensorFlow 库进行实现。在讲解完这些概念后，我们将给出一个数字分类的实际示例。这个示例的问题是，*给定一组包含手写数字的图像，如何将这些图像分类为
    10 个不同的类别（0-9）*？'
- en: '[Chapter 7](fa1fdcb0-1678-480f-80e2-6169a65381ab.xhtml), *Introduction to Convolutional
    Neural Networks*, explains that in data science, a **convolutional neural network** (**CNN**)
    is specific kind of deep learning architecture that uses the convolution operation
    to extract relevant explanatory features for the input image. CNN layers are connected
    as an FNN while using this convolution operation to mimic how the human brain
    functions when trying to recognize objects. Individual cortical neurons respond
    to stimuli in a restricted region of space known as the receptive field. In particular,
    biomedical imaging problems could be challenge sometimes but in this chapter,
    we''ll see how to use a CNN in order to discover patterns in this image.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[第7章](fa1fdcb0-1678-480f-80e2-6169a65381ab.xhtml)，*卷积神经网络简介*，解释了在数据科学中，**卷积神经网络**（**CNN**）是一种特定的深度学习架构，它使用卷积操作来提取输入图像的相关特征。CNN
    层的连接方式类似于 FNN，同时使用卷积操作来模拟人脑在识别物体时的工作方式。个别皮层神经元对刺激作出反应，反应的区域被称为感受野。特别是在生物医学成像问题中，挑战有时会比较大，但在这一章中，我们将展示如何使用
    CNN 来发现图像中的模式。'
- en: '[Chapter 8](89600395-7795-4ab8-859a-28ff4a80bbe4.xhtml), *Object Detection
    – CIFAR-10 Example*, covers the basics and the intuition/motivation behind CNNs,
    before demonstrating this on one of the most popular datasets available for object
    detection. We''ll also see how the initial layers of the CNN get very basic features
    about our objects, but the final convolutional layers will get more semantic-level
    features that are built up from those basic features in the first layers.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[第8章](89600395-7795-4ab8-859a-28ff4a80bbe4.xhtml)，*目标检测 - CIFAR-10 示例*，介绍了卷积神经网络（CNN）的基础知识及其背后的直觉/动机，接着在一个最受欢迎的目标检测数据集上进行了演示。我们还将看到CNN的初始层获取关于对象的非常基础的特征，而最终的卷积层将从这些基础特征中构建出更具语义层次的特征。'
- en: '[Chapter 9](ac080e92-e53a-4d4c-af7b-7d2c56b90d51.xhtml), *Object Detection
    – Transfer Learning with CNNs*, explains that **Transfer learning** (**TL**) is
    a research problem in data science that is mainly concerned with persisting knowledge
    acquired during solving a specific task and using this acquired knowledge to solve
    another different but similar task. In this chapter, we will demonstrate one of
    the modern practices and common themes used in the field of data science with
    TL. The idea here is how to get the help from domains with very large datasets
    to domains that have smaller datasets. Finally, we will revisit our object detection
    example of CIFAR-10 and try to reduce both the training time and performance error
    via TL.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[第9章](ac080e92-e53a-4d4c-af7b-7d2c56b90d51.xhtml)，*目标检测 - 使用CNN进行迁移学习*，解释了**迁移学习**（**TL**）是数据科学中的一个研究问题，主要关注在解决特定任务过程中获取的知识，并将这些知识应用于解决另一个不同但相似的任务。在这一章中，我们将演示数据科学领域中迁移学习的一种现代实践和常见主题。这里的想法是如何从拥有非常大数据集的领域获得帮助，以支持那些数据集较小的领域。最后，我们将重新审视CIFAR-10的目标检测示例，并尝试通过迁移学习减少训练时间和性能误差。'
- en: '[Chapter 10](da721487-236c-4027-8f3e-4cf1ae393559.xhtml), *Recurrent-Type Neural
    Networks - Language Modeling*, explains that **Recurrent neural networks** (**RNNs**)
    are a class of deep learning architectures that are widely used for natural language
    processing. This set of architectures enables us to provide contextual information
    for current predictions and also have specific architecture that deals with long-term
    dependencies in any input sequence. In this chapter, we''ll demonstrate how to
    make a sequence-to-sequence model, which will be useful in many applications in
    NLP. We will demonstrate these concepts by building a character-level language
    model and see how our model generates sentences similar to original input sequences.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[第10章](da721487-236c-4027-8f3e-4cf1ae393559.xhtml)，*递归神经网络 - 语言建模*，解释了**递归神经网络**（**RNNs**）是一类深度学习架构，广泛应用于自然语言处理。这类架构使我们能够为当前的预测提供上下文信息，并且具有处理任何输入序列中的长期依赖关系的特定架构。在这一章中，我们将演示如何构建一个序列到序列的模型，这在自然语言处理的许多应用中非常有用。我们将通过构建一个字符级语言模型来演示这些概念，并观察我们的模型如何生成类似于原始输入序列的句子。'
- en: '[Chapter 11](0a5230db-2991-4156-835e-d32172124843.xhtml), *Representation Learning
    - Implementing Word Embeddings*, explains that machine learning is a science that
    is mainly based on statistics and linear algebra. Applying matrix operations is
    very common among most machine learning or deep learning architectures because
    of backpropagation. This is the main reason deep learning, or machine learning
    in general, accepts only real-valued quantities as input. This fact contradicts
    many applications, such as machine translation, sentiment analysis, and so on;
    they have text as an input. So, in order to use deep learning for this application,
    we need to have it in the form that deep learning accepts! In this chapter, we
    are going to introduce the field of representation learning, which is a way to
    learn a real-valued representation from text while preserving the semantics of
    the actual text. For example, the representation of love should be very close
    to the representation of adore because they are used in very similar contexts.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[第11章](0a5230db-2991-4156-835e-d32172124843.xhtml)，*表示学习 - 实现词嵌入*，解释了机器学习是一门主要基于统计学和线性代数的科学。由于反向传播，大多数机器学习或深度学习架构中都非常常见应用矩阵操作。这是深度学习或一般机器学习仅接受**实数值**输入的主要原因。这个事实与许多应用相矛盾，比如机器翻译、情感分析等等，它们的输入是文本。因此，为了在这些应用中使用深度学习，我们需要将文本转化为深度学习能够接受的形式！在这一章中，我们将介绍表示学习领域，这是从文本中学习实数表示的一种方法，同时保持实际文本的语义。例如，"love"的表示应该与"adore"的表示非常接近，因为它们在非常相似的上下文中使用。'
- en: '[Chapter 12](1ab74bb7-e546-4872-9fe1-9e0e99fdc15f.xhtml), *Neural Sentiment
    Analysis*, addresses one of the hot and trendy applications in natural language
    processing, which is called sentiment analysis. Most people nowadays express their
    opinions about something through social media platforms, and making use of this
    vast amount of text to keep track of customer satisfaction about something is
    very crucial for companies or even governments.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[第12章](1ab74bb7-e546-4872-9fe1-9e0e99fdc15f.xhtml)，*神经网络情感分析*，讨论了自然语言处理中的一个热门应用——情感分析。如今，大多数人通过社交媒体平台表达他们对某事的看法，利用大量文本来跟踪客户对某件事的满意度，对于公司甚至政府来说都是至关重要的。'
- en: In this chapter, we are going to use RNNs to build a sentiment analysis solution.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用RNN（递归神经网络）构建一个情感分析解决方案。
- en: '[Chapter 13](bb259608-06da-4d50-bd05-c71ef2780334.xhtml), *Autoencoders – Feature
    Extraction and Denoising*, explains that an autoencoder network is nowadays one
    of the widely used deep learning architectures. It''s mainly used for unsupervised
    learning of efficient decoding tasks. It can also be used for dimensionality reduction
    by learning an encoding or a representation for a specific dataset. Using autoencoders
    in this chapter, we''ll show how to denoise your dataset by constructing another
    dataset with the same dimensions but less noise. To use this concept in practice,
    we will extract the important features from the MNIST dataset and try to see how
    the performance will be significantly enhanced by this.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[第13章](bb259608-06da-4d50-bd05-c71ef2780334.xhtml)，*自编码器——特征提取与去噪*，解释了自编码器网络如今是广泛使用的深度学习架构之一。它主要用于无监督学习的高效解码任务，也可以通过学习特定数据集的编码或表示来进行降维。在本章中，我们将通过构建另一个维度相同但噪声较少的数据集来演示如何去噪数据集。为了将这一概念付诸实践，我们将从MNIST数据集中提取重要特征，并尝试看看这种方法如何显著提升性能。'
- en: '[Chapter 14](b17d26d4-2b6d-4f89-8e11-bf6988042de2.xhtml), *Generative Adversarial
    Networks*, covers **Generative Adversarial Networks** (**GANs**). They are deep
    neural net architectures that consist of two networks pitted against each other
    (hence the name adversarial). GANs were introduced in a paper ([https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661))
    by Ian Goodfellow and other researchers, including Yoshua Bengio, at the University
    of Montreal in 2014\. Referring to GANs, Facebook''s AI research director, Yann
    LeCun, called **adversarial training** the most interesting idea in the last 10
    years in machine learning. The potential of GANs is huge, because they can learn
    to mimic any distribution of data. That is, GANs can be taught to create worlds
    eerily similar to our own in any domain: images, music, speech, or prose. They
    are robot artists in a sense, and their output is impressive ([https://www.nytimes.com/2017/08/14/arts/design/google-how-ai-creates-new-music-and-new-artists-project-magenta.html](https://www.nytimes.com/2017/08/14/arts/design/google-how-ai-creates-new-music-and-new-artists-project-magenta.html))—and
    poignant too.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[第14章](b17d26d4-2b6d-4f89-8e11-bf6988042de2.xhtml)，*生成对抗网络*，涵盖了**生成对抗网络**（**GANs**）。它们是由两个网络对立工作（因此得名“对抗”）的深度神经网络架构。GANs最早由Ian
    Goodfellow和其他研究人员（包括Yoshua Bengio）于2014年在蒙特利尔大学的论文中提出（[https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)）。关于GANs，Facebook的AI研究总监Yann
    LeCun曾称**对抗训练**为过去10年机器学习领域最有趣的想法。GANs的潜力巨大，因为它们可以学习模拟任何数据分布。也就是说，GANs可以被训练成在任何领域中创造出与我们自己的世界惊人相似的东西：图像、音乐、语音或散文。从某种意义上说，它们是“机器人艺术家”，并且它们的输出令人印象深刻（[https://www.nytimes.com/2017/08/14/arts/design/google-how-ai-creates-new-music-and-new-artists-project-magenta.html](https://www.nytimes.com/2017/08/14/arts/design/google-how-ai-creates-new-music-and-new-artists-project-magenta.html))——并且充满深意。'
- en: '[Chapter 15](a1323155-0162-437b-bf0b-7395d4a04556.xhtml), *Face Generation
    and Handling Missing Labels*, shows that the list of interesting applications
    that we can use GANs for is endless. In this chapter, we are going to demonstrate
    another promising application of GANs, which is face generation based on the CelebA
    database. We''ll also demonstrate how to use GANs for semi-supervised learning
    setups where we''ve got a poorly labeled dataset with some missing labels.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[第15章](a1323155-0162-437b-bf0b-7395d4a04556.xhtml)，*面部生成与缺失标签处理*，展示了我们可以使用GANs的有趣应用列表是无穷无尽的。在本章中，我们将展示GANs的另一个有前景的应用——基于CelebA数据库的面部生成。我们还将演示如何在半监督学习设置中使用GANs，尤其是在面对一个标注不完善、缺少部分标签的数据集时。'
- en: '[Appendix](fa5274ee-dd22-434a-89ac-ffc913249ced.xhtml), *Implementing Fish
    Recognition*, includes entire piece of code of fish recognition example.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[附录](fa5274ee-dd22-434a-89ac-ffc913249ced.xhtml)，*实现鱼类识别*，包括完整的鱼类识别示例代码。'
- en: To get the most out of this book
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为了充分利用本书
- en: Inform the reader of the things that they need to know before they start, and
    spell out what knowledge you are assuming.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 告知读者在开始之前需要了解的事项，并明确假设你所掌握的知识。
- en: Any additional installation instructions and information they need for getting
    set up.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何额外的安装说明和设置所需的信息。
- en: Download the example code files
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from your account at [www.packtpub.com](http://www.packtpub.com).
    If you purchased this book elsewhere, you can visit [www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files emailed directly to you.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从你的账户下载本书的示例代码文件，网址是：[www.packtpub.com](http://www.packtpub.com)。如果你是在其他地方购买本书，你可以访问[www.packtpub.com/support](http://www.packtpub.com/support)，注册后我们会直接通过电子邮件将文件发送给你。
- en: 'You can download the code files by following these steps:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下步骤下载代码文件：
- en: Log in or register at [www.packtpub.com](http://www.packtpub.com/support).
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录或在[www.packtpub.com](http://www.packtpub.com/support)注册。
- en: Select the SUPPORT tab.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择“支持”标签。
- en: Click on Code Downloads & Errata.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“代码下载和勘误”。
- en: Enter the name of the book in the Search box and follow the onscreen instructions.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索框中输入书名并按照屏幕上的指示操作。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦文件下载完成，请确保使用最新版本的工具解压或提取文件夹：
- en: WinRAR/7-Zip for Windows
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WinRAR/7-Zip for Windows
- en: Zipeg/iZip/UnRarX for Mac
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipeg/iZip/UnRarX for Mac
- en: 7-Zip/PeaZip for Linux
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 7-Zip/PeaZip for Linux
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Deep-Learning-By-Example](https://github.com/PacktPublishing/Deep-Learning-By-Example).
    We also have other code bundles from our rich catalog of books and videos available
    at **[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)**.
    Check them out!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的代码包也托管在GitHub上：[https://github.com/PacktPublishing/Deep-Learning-By-Example](https://github.com/PacktPublishing/Deep-Learning-By-Example)。我们还提供了其他书籍和视频的代码包，您可以在**[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)**找到它们。赶快查看吧！
- en: Download the color images
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载彩色图像
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [http://www.packtpub.com/sites/default/files/downloads/DeepLearningByExample_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/DeepLearningByExample_ColorImages.pdf).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一个PDF文件，其中包含本书中使用的屏幕截图/图表的彩色图像。你可以在这里下载：[http://www.packtpub.com/sites/default/files/downloads/DeepLearningByExample_ColorImages.pdf](http://www.packtpub.com/sites/default/files/downloads/DeepLearningByExample_ColorImages.pdf)。
- en: Conventions used
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用了许多文本约定。
- en: '`CodeInText`: Indicates code words in text, database table names, folder names,
    filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles.
    Here is an example: "Mount the downloaded `WebStorm-10*.dmg` disk image file as
    another disk in your system."'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`CodeInText`：表示文本中的代码词汇、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟网址、用户输入和Twitter用户名。例如：“将下载的`WebStorm-10*.dmg`磁盘映像文件挂载为系统中的另一个磁盘。”'
- en: 'A block of code is set as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块如下所示：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望你注意代码块中特定部分时，相关的行或项会以粗体显示：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出如下所示：
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For example, words in menus or dialog boxes appear in the text like this. Here
    is an example: "Select System info from the Administration panel."'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示新术语、重要词汇或屏幕上显示的词汇。例如，菜单或对话框中的词汇在文本中以这种方式出现。举个例子：“从管理面板中选择系统信息。”'
- en: Warnings or important notes appear like this.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 警告或重要提示以这种方式显示。
- en: Tips and tricks appear like this.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 提示和技巧通常以这种方式呈现。
- en: Get in touch
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与我们联系
- en: Feedback from our readers is always welcome.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。
- en: '**General feedback**: Email `feedback@packtpub.com` and mention the book title
    in the subject of your message. If you have questions about any aspect of this
    book, please email us at `questions@packtpub.com`.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**：请通过电子邮件 `feedback@packtpub.com` 并在邮件主题中提到书名。如果您对本书的任何内容有疑问，请发送邮件至
    `questions@packtpub.com` 与我们联系。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**：虽然我们已经尽力确保内容的准确性，但错误还是有可能发生。如果您在本书中发现任何错误，我们将不胜感激，如果您能向我们报告。请访问 [www.packtpub.com/submit-errata](http://www.packtpub.com/submit-errata)，选择您的书籍，点击“勘误提交表格”链接，并输入相关详情。'
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the Internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at `copyright@packtpub.com` with a
    link to the material.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果您在互联网上遇到任何形式的我们作品的非法复制品，我们将非常感激您能提供相关位置地址或网站名称。请通过电子邮件联系我们，地址为 `copyright@packtpub.com`，并附上该材料的链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com/).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您在某个领域拥有专业知识，并且有意写书或为书籍做贡献，请访问 [authors.packtpub.com](http://authors.packtpub.com/)。'
- en: Reviews
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评价
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 请留下评价。在您阅读并使用本书后，为什么不在您购买书籍的网站上留下您的评价呢？潜在的读者可以通过您的无偏见意见做出购买决策，我们 Packt 也能了解您对我们产品的看法，我们的作者也能看到您对其书籍的反馈。谢谢！
- en: For more information about Packt, please visit [packtpub.com](https://www.packtpub.com/).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解更多关于 Packt 的信息，请访问 [packtpub.com](https://www.packtpub.com/)。
