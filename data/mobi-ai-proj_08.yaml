- en: Implementing GANs to Recognize Handwritten Digits
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GAN识别手写数字
- en: In this chapter, we will build an Android application that detects handwritten
    numbers and works out what the number is by using adversarial learning. We will
    use the **Modified National Institute of Standards and Technology** (**MNIST**)
    dataset for digit classification. We will also look into the basics of **Generative
    Adversarial Networks** (**GANs**).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将构建一个安卓应用程序，该程序通过使用对抗学习来检测手写数字并识别数字是什么。我们将使用**修改后的国家标准与技术研究院** (**MNIST**)
    数据集进行数字分类。我们还将了解**生成对抗网络** (**GANs**)的基本知识。
- en: 'In this chapter, we will take a closer look at the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将更详细地探讨以下主题：
- en: Introduction to GANs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GAN简介
- en: Understanding the MNIST database
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解MNIST数据库
- en: Building the TensorFlow model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建TensorFlow模型
- en: Building the Android application
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建安卓应用程序
- en: The code for this application can be found at [https://github.com/intrepidkarthi/AImobileapps](https://github.com/intrepidkarthi/AImobileapps).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本应用程序的代码可以在[https://github.com/intrepidkarthi/AImobileapps](https://github.com/intrepidkarthi/AImobileapps)找到。
- en: Introduction to GANs
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN简介
- en: GANs are a class of **machine learning** (**ML**) algorithm that's used in unsupervised
    ML. They are comprised of two deep neural networks that are competing against
    each other (so it is termed as adversarial). GANs were introduced at the University
    of Montreal in 2014 by Ian Goodfellow and other researchers, including Yoshua
    Bengio.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: GAN是一类**机器学习** (**ML**) 算法，用于无监督学习。它们由两个深度神经网络组成，这两个网络相互竞争（因此被称为对抗式）。GAN是由Ian
    Goodfellow和其他研究人员（包括Yoshua Bengio）于2014年在蒙特利尔大学提出的。
- en: Ian Goodfellow's paper on GANs can be found at [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Ian Goodfellow关于GAN的论文可以在[https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)找到。
- en: 'GANs have the potential to mimic any data. This means that GANs can be trained
    to create similar versions of any data, such as images, audio, or text. A simple
    workflow of a GAN is shown in the following diagram:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: GAN具有模拟任何数据的潜力。这意味着GAN可以被训练生成任何数据的相似版本，例如图像、音频或文本。下图展示了GAN的简单工作流程：
- en: '![](img/155fcb59-cb75-46e4-bc93-4aa7fd25d6e7.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](img/155fcb59-cb75-46e4-bc93-4aa7fd25d6e7.png)'
- en: The workflow of the GAN will be explained in the following sections.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的工作流程将在接下来的章节中解释。
- en: Generative versus discriminative algorithms
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成算法与判别算法
- en: To understand GANs, we must know how discriminative and generative algorithms
    work. Discriminative algorithms try to predict a label and classify the input
    data, or categorize them to where the data belongs. On the other hand, generative
    algorithms make an attempt to predict features to give a certain label.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解GAN，我们必须知道判别算法和生成算法是如何工作的。判别算法试图预测一个标签并对输入数据进行分类，或者将它们归类到数据所属的类别中。另一方面，生成算法则尝试预测特征，以给出某个特定标签。
- en: 'For example, a discriminative algorithm can predict whether an email is spam
    or not. Here, spam is one of the labels, and the text that''s captured from the
    message is considered the input data. If you consider the label as *y* and the
    input as *x*, we can formulate this as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个判别算法可以预测一封邮件是否是垃圾邮件。这里，垃圾邮件是标签之一，邮件中提取的文本被认为是输入数据。如果将标签看作*y*，将输入看作*x*，我们可以将其表示如下：
- en: '![](img/c4a4b7b1-c903-4e1a-b3ef-9845baa9935e.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c4a4b7b1-c903-4e1a-b3ef-9845baa9935e.png)'
- en: On the other hand, generative algorithms try to guess how likely these input
    features (*x*, in the previous equation) are. Generative models care about how
    you get *x*, while discriminative models care about the relation between *x* and
    *y*.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，生成算法则尝试预测这些输入特征（在前面的公式中是*x*）的可能性。生成模型关注的是如何获得*x*，而判别模型关注的是*x*与*y*之间的关系。
- en: Using the MNIST database as an example, the generator will generate images and
    pass them on to the discriminator. The discriminator will authenticate the image
    if it is truly from the MNIST dataset. The generator generates images with the
    hope that it will pass through the discriminator and be authenticated, even though
    it is fake (as shown in the preceding diagram).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以MNIST数据库为例，生成器将生成图像并传递给判别器。如果图像确实来自MNIST数据集，判别器将验证该图像。生成器生成图像的目的是希望它能够通过判别器的验证，即使它是假的（如上图所示）。
- en: How GANs work
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN如何工作
- en: 'Based on our example, we will assume that we are passing numbers as inputs:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的示例，我们将假设输入的是数字：
- en: The generator takes random numbers as inputs and returns an image as the output
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成器接受随机数作为输入，并返回图像作为输出
- en: The output image is passed into the discriminator, and, at the same time, the
    discriminator receives input from the dataset
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输出图像传递给判别器，同时，判别器也从数据集中接收输入
- en: The discriminator takes in both real and fake input images, and returns probabilities
    between zero and one (with one representing a prediction of authenticity and zero
    representing a fake)
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 判别器接受真实和假输入图像，并返回一个0到1之间的概率（其中1表示真实性的预测，0表示假图像的预测）
- en: Using the example application we discussed in this chapter, we can use the same
    steps to pass the user's hand-drawn image as one of the fake images and try to
    find the probability value of it being correct.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用本章中讨论的示例应用程序，我们可以使用相同的步骤，将用户手绘的图像作为假图像之一，并尝试找出其正确性的概率值。
- en: Understanding the MNIST database
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解MNIST数据库
- en: The MNIST dataset consists of 60,000 handwritten digits. It also consists of
    a test dataset made up of 10,000 digits. While it is a subset of the NIST dataset,
    all the digits in this dataset are size normalized and have been centered on a
    28 x 28 pixels sized image. Here, every pixel contains a value of 0-255 with its
    grayscale value.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST数据集包含60,000个手写数字。它还包含一个由10,000个数字组成的测试数据集。虽然它是NIST数据集的一个子集，但该数据集中的所有数字都进行了大小归一化，并且已被居中在一个28
    x 28像素的图像中。在这里，每个像素包含一个0-255的值，对应于其灰度值。
- en: The MNIST dataset can be found at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).
    The NIST dataset can be found at [https://www.nist.gov/srd/nist-special-database-19](https://www.nist.gov/srd/nist-special-database-19).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST数据集可以在[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)找到。NIST数据集可以在[https://www.nist.gov/srd/nist-special-database-19](https://www.nist.gov/srd/nist-special-database-19)找到。
- en: Building the TensorFlow model
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建TensorFlow模型
- en: In this application, we will build an MNIST dataset based TensorFlow model that
    we will use in our Android application. Once we have the TensorFlow model, we
    will convert it into a TensorFlow Lite model. The step-by-step procedure of downloading
    the model and building the TensorFlow model is as follows.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个应用程序中，我们将构建一个基于MNIST数据集的TensorFlow模型，并将在我们的Android应用程序中使用它。一旦我们有了TensorFlow模型，我们将把它转换成TensorFlow
    Lite模型。下载模型并构建TensorFlow模型的步骤如下：
- en: 'Here is the architecture diagram on how our model works. The way to achieve
    this is explained as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的模型如何工作的架构图。实现这一点的方式如下所示：
- en: '![](img/191be622-af24-4350-abaa-b854ef81eb00.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/191be622-af24-4350-abaa-b854ef81eb00.png)'
- en: 'Using TensorFlow, we can download the MNIST data with one line of Python code,
    as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorFlow，我们可以通过一行Python代码下载MNIST数据，如下所示：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, we have the MNIST dataset downloaded. After that, we will read the data,
    as shown in the previous code.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经下载了MNIST数据集。之后，我们将按照之前的代码读取数据。
- en: 'Now, we can run the script to download the dataset. We will run the script
    from the console, as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以运行脚本来下载数据集。我们将从控制台运行该脚本，如下所示：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once we have the dataset ready, we will add a few variables that we will use
    in our application, as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们准备好数据集，我们将添加一些将在应用程序中使用的变量，如下所示：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We need to define these variables to control the parameters on building the
    model as required by the TensorFlow framework. This classification process is
    simple. The number of pixels that exist in a 28 x 28 image is 784\. So, we have
    a corresponding number of input layers. Once we have the architecture set up,
    we will train the network and evaluate the results, obtained to understand the
    effectiveness and accuracy of the model.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要定义这些变量，以控制构建模型时所需的参数，这是TensorFlow框架要求的。这个分类过程很简单。28 x 28图像中存在的像素数量是784。因此，我们有相应数量的输入层。设置好架构后，我们将训练网络并评估结果，以了解模型的有效性和准确性。
- en: 'Now, let''s define the variables that we added in the preceding code block.
    Depending on whether the model is in the training phase or the testing phase,
    different data will be passed through the classifier. The training process needs
    labels to be able to match them to current predictions. This is defined in the
    following variable:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们定义在前面的代码块中添加的变量。根据模型处于训练阶段还是测试阶段，不同的数据将传递到分类器中。训练过程需要标签，以便能够将其与当前预测进行匹配。这个变量如下所定义：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As the computation-graph evaluation occurs, placeholders will be filled. In
    the training process, we adjust the values of biases and weights toward increasing
    the accuracy of our results. To achieve this, we will define the weight and bias
    parameters, as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 随着计算图的评估进行，占位符将被填充。在训练过程中，我们调整偏置和权重的值，以提高结果的准确性。为了实现这一目标，我们将定义权重和偏置参数，如下所示：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once we have variables that can be tuned, we can move on to building the output
    layer in just one step:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了可以调节的变量，我们就可以一步完成输出层的构建：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We have successfully built the output layer of the network with the training
    data.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功地使用训练数据构建了网络的输出层。
- en: Training the neural network
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练神经网络
- en: By optimizing loss, we can get the training process to work. We need to reduce
    the difference between the actual label value and the network prediction. The
    term to define this loss is **cross entropy**.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通过优化损失，我们可以使训练过程有效。我们需要减少实际标签值与网络预测值之间的差异。定义这种损失的术语是**交叉熵**。
- en: 'In TensorFlow, cross entropy is provided by the following method:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow中，交叉熵通过以下方法提供：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This method applies softmax to the model''s prediction. Softmax is similar
    to logistic regression, and produces a decimal between 0 and 1.0\. For example,
    a logistic regression output of 0.9 from an email classifier suggests a 90% chance
    of an email being spam and a 10% chance of it not being spam. The sum of all the
    probabilities is 1.0, as shown with an example in the following table:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法将softmax应用于模型的预测。Softmax类似于逻辑回归，输出一个介于0和1.0之间的小数。例如，电子邮件分类器的逻辑回归输出0.9表示邮件为垃圾邮件的概率为90%，不为垃圾邮件的概率为10%。所有概率的总和为1.0，如下表所示：
- en: '![](img/b80b1630-1bd3-4b50-ab7c-da1d0d4e7ce8.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b80b1630-1bd3-4b50-ab7c-da1d0d4e7ce8.png)'
- en: Softmax is implemented through a neural network layer, just before the output
    layer. The softmax layer must have the same number of nodes as the output layer.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Softmax通过神经网络层实现，就在输出层之前。Softmax层必须与输出层具有相同数量的节点。
- en: 'Loss is defined using the `tf.reduce_mean` method, and the `GradientDescentOptimizer()`
    method is used in training steps to minimize the loss. This is shown in the following
    code:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 损失使用`tf.reduce_mean`方法定义，并且在训练步骤中使用`GradientDescentOptimizer()`方法来最小化损失。如下所示的代码演示了这一过程：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The `GradientDescentOptimizer` method will take several steps by adjusting
    the values of *w* and *b* (the weight and bias parameters) in the output. The
    values will be adjusted until we reduce loss and are closer to a more accurate
    prediction, as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`GradientDescentOptimizer`方法会通过调整输出中的*w*和*b*（权重和偏置参数）的值，经过多步迭代，直到我们减小损失并更接近准确的预测，具体如下：'
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We start the training by initializing the session and the variables, as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过初始化会话和变量来开始训练，如下所示：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Based on the parameters of the number of steps (`steps_number`) defined previously,
    the algorithm will run in a loop. We will then run the optimizer, as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 基于之前定义的步数（`steps_number`）参数，算法将循环运行。然后我们将运行优化器，如下所示：
- en: '[PRE10]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'With TensorFlow, we can measure the accuracy of our algorithm and print the
    accuracy value. We can keep it improving as long as the accuracy level increases
    and finds the threshold value on where to stop, as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorFlow，我们可以衡量算法的准确性并打印准确率值。只要准确度提高并找到停止的阈值，我们可以继续优化，如下所示：
- en: '[PRE11]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Once the training is done, we can evaluate the network''s performance. We can
    use the training data to measure performance, as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练完成，我们可以评估网络的性能。我们可以使用训练数据来衡量性能，如下所示：
- en: '[PRE12]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'When we run the Python script, the output on the console is as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行Python脚本时，控制台上的输出如下：
- en: '[PRE13]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Now, we have arrived at an accuracy rate of 89.2%. When we try to optimize our
    results more, the accuracy level reduces; this is where we set have our threshold
    value to stop the training.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的准确率已经达到了89.2%。当我们尝试进一步优化结果时，准确度反而下降；这就是我们设置阈值停止训练的原因。
- en: Let's build the TensorFlow model for the MNIST dataset. Inside the TensorFlow
    framework, the scripts that are provided save the MNIST dataset into a TensorFlow
    (`.pb`) model. The same script is attached to this application's repository.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为MNIST数据集构建TensorFlow模型。在TensorFlow框架中，提供的脚本将MNIST数据集保存为TensorFlow（`.pb`）模型。相同的脚本附在本应用程序的代码库中。
- en: The code for this application can be found at [https://github.com/intrepidkarthi/AImobileapps](https://github.com/intrepidkarthi/AImobileapps).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此应用程序的代码可以在 [https://github.com/intrepidkarthi/AImobileapps](https://github.com/intrepidkarthi/AImobileapps)
    找到。
- en: 'We will begin by training the model using the following Python code line:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从以下 Python 代码行开始训练模型：
- en: '[PRE14]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We will now run the script to generate our model.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将运行脚本生成我们的模型。
- en: 'The following script helps us export the model by adding some additional parameters:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以下脚本帮助我们通过添加一些额外参数来导出模型：
- en: '[PRE15]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The saved model can be found in the time stamped directory under `/./mnist_mode1/`
    (for example, `/./mnist_model/1536628294/`).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在时间戳目录 `/./mnist_mode1/` 下找到保存的模型（例如，`/./mnist_model/1536628294/`）。
- en: 'The obtained TensorFlow model will be converted into a TensorFlow Lite model
    using `toco`, as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 获得的 TensorFlow 模型将使用 `toco` 转换为 TensorFlow Lite 模型，如下所示：
- en: '[PRE16]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Toco is a command-line tool that's used to run the **TensorFlow Lite Optimizing
    Converter** (**TOCO**), which converts a TensorFlow model into a TensorFlow Lite
    model. The preceding `toco` command produces `mnist.tflite` as its output, which
    we will use in our application in the next section.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Toco 是一个命令行工具，用于运行 **TensorFlow Lite 优化转换器**（**TOCO**），将 TensorFlow 模型转换为 TensorFlow
    Lite 模型。上述 `toco` 命令会生成 `mnist.tflite` 作为输出，我们将在下一节中在我们的应用程序中使用它。
- en: Building the Android application
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建 Android 应用程序
- en: 'Let''s create the Android application step-by-step with the model that we have
    built. We will start by creating a new project in Android Studio:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照我们建立的模型逐步创建 Android 应用程序。我们将从在 Android Studio 中创建一个新项目开始：
- en: 'Create a new application in Android Studio:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Android Studio 中创建一个新应用程序：
- en: '![](img/04420888-dc76-451a-b2c2-5d0dc5fed348.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/04420888-dc76-451a-b2c2-5d0dc5fed348.png)'
- en: 'Drag the created TensorFlow Lite model to the `assets` folder, along with the
    `labels.txt` file. We will read the model and label from the assets folder:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将创建的 TensorFlow Lite 模型拖到 `assets` 文件夹中，以及 `labels.txt` 文件。我们将从 assets 文件夹中读取模型和标签：
- en: '![](img/8a178f84-13a2-418e-a617-a881a3e56cae.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8a178f84-13a2-418e-a617-a881a3e56cae.png)'
- en: The preceding screenshot shows the file structure in the project. If necessary,
    we can store the model file inside the secondary memory storage as well.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的屏幕截图显示了项目中的文件结构。如果需要，我们也可以将模型文件存储在辅助存储器中。
- en: One of the advantages of FreeHandView is that we can create a simple view where
    users can draw any number of digits. In addition to this, the bar chart on the
    screen will show the classification of the detected number.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: FreeHandView 的一个优点是我们可以创建一个简单的视图，用户可以在其中绘制任意数量的数字。除此之外，屏幕上的条形图将显示检测到的数字的分类。
- en: We will use a step-by-step procedure to create the classifier.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用逐步过程来创建分类器。
- en: 'Here is the `FreeHandView` constructor method that we will use to draw the
    digits. We initialize the `Paint` object with the necessary parameters, as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将用来绘制数字的 `FreeHandView` 构造方法。我们使用必要的参数初始化 `Paint` 对象，如下所示：
- en: '[PRE17]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The functions of each parameter that was used in the preceding code block are
    explained as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码块中每个参数的功能如下所述：
- en: '`mPaint.setAntiAlias(true)`: A helper for `setFlags()`, setting or clearing
    the `ANTI_ALIAS_FLAG` bit. Antialiasing smooths out the edges of what is being
    drawn, but it has no impact on the interior of the shape.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mPaint.setAntiAlias(true)`: `setFlags()` 的辅助函数，用于设置或清除 `ANTI_ALIAS_FLAG` 位。抗锯齿会使所绘制内容的边缘更加平滑，但不影响形状的内部。'
- en: '`mPaint.setDither(true)`: A helper for `setFlags()`, setting or clearing the
    `DITHER_FLAG` bit. Dithering affects how colors that are higher precision than
    the device are down-sampled.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mPaint.setDither(true)`: `setFlags()` 的辅助函数，用于设置或清除 `DITHER_FLAG` 位。抖动会影响高于设备精度的颜色如何被降低采样。'
- en: '`mPaint.setColor(DEFAULT_COLOR)`: Sets the paint''s color.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mPaint.setColor(DEFAULT_COLOR)`: 设置画笔的颜色。'
- en: '`mPaint.setStyle(Paint.Style.STROKE)`: Sets the paint''s style, used for controlling
    how primitives'' geometries are interpreted (except for `drawBitmap`, which always
    assumes `Fill`).'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mPaint.setStyle(Paint.Style.STROKE)`: 设置画笔的样式，用于控制如何解释基元的几何图形（除了 `drawBitmap`，它总是假定
    `Fill`）。'
- en: '`mPaint.setStrokeJoin(Paint.Join.ROUND)`: Sets the paint''s `Join`.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mPaint.setStrokeJoin(Paint.Join.ROUND)`: 设置画笔的 `Join`。'
- en: '`mPaint.setStrokeCap(Paint.Cap.ROUND)`: Sets the paint''s `Cap`.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mPaint.setStrokeCap(Paint.Cap.ROUND)`: 设置画笔的 `Cap`。'
- en: '`mPaint.setXfermode(null)`: Sets or clears the transfer mode object.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mPaint.setXfermode(null)`: 设置或清除传输模式对象。'
- en: '`mPaint.setAlpha(Oxff)`: A helper to `setColor()`, that only assigns the color''s
    `alpha` value, leaving its `r`, `g`, and `b` values unchanged.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mPaint.setAlpha(Oxff)`：一个辅助方法，用于 `setColor()`，它仅分配颜色的 `alpha` 值，保持其 `r`、`g`
    和 `b` 值不变。'
- en: 'Inside the `init()` method of the view life cycle, we will initialize the `ImageClassifier`,
    and pass on the `BarChart` object:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在视图生命周期的 `init()` 方法内部，我们将初始化 `ImageClassifier`，并传入 `BarChart` 对象：
- en: '[PRE18]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We will use the chart from the following library: [https://github.com/PhilJay/MPAndroidChart](https://github.com/PhilJay/MPAndroidChart).'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下库中的图表：[https://github.com/PhilJay/MPAndroidChart](https://github.com/PhilJay/MPAndroidChart)。
- en: 'We will initialize the `BarChart` view, with the *x* axis containing numbers
    from zero to nine and the *y* axis containing the probability value from 0 to
    1.0:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将初始化 `BarChart` 视图，*x* 轴包含从零到九的数字，*y* 轴包含从 0 到 1.0 的概率值：
- en: '[PRE19]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Once we have initialized the `BarChart` view, we will call the `OnDraw()` method
    of the view life cycle, which applies strokes in accordance with the path of the
    user's finger movements. The `OnDraw()` method is called as part of the view life
    cycle method once the `BarChart` view is initialized.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们初始化了 `BarChart` 视图，我们将调用视图生命周期中的 `OnDraw()` 方法，按照用户手指的移动路径绘制笔画。`OnDraw()`
    方法是视图生命周期方法的一部分，一旦 `BarChart` 视图初始化完成，就会被调用。
- en: 'Inside the `OnDraw` method, we will track the finger movement of the user,
    and the same movements will be drawn on the canvas, as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `OnDraw` 方法中，我们将跟踪用户的手指移动，并将相同的动作绘制到画布上，如下所示：
- en: '[PRE20]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Inside the `onTouchEvent()` method, we can track the user''s finger position
    using the move, up, and down events and initiate actions based upon that. This
    is one of the methods in the view''s life cycle that''s used to track events.
    There are three events that will be triggered when you touch your mobile based
    on finger movements. In the case of `action_down` and `action_move`, we will handle
    events to draw the on-hand movement on the view with the initial paint object
    attributes. When the `action_up` event is triggered, we will save the view into
    a file, as well as pass the file image to the classifier to identify the digit.
    After that, we will represent the probability values using the `BarChart` view.
    These steps are as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `onTouchEvent()` 方法中，我们可以通过移动、抬起和按下事件跟踪用户的手指位置，并基于此触发相应的动作。这是视图生命周期中的一个方法，用于跟踪事件。当你触摸手机时，会根据手指的移动触发三个事件。在
    `action_down` 和 `action_move` 的情况下，我们将处理事件，在视图上绘制手指的移动轨迹，使用初始的画笔对象属性。当 `action_up`
    事件被触发时，我们会将视图保存为文件，并将文件图像传递给分类器识别数字。之后，我们将使用 `BarChart` 视图表示概率值。这些步骤如下：
- en: '[PRE21]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Inside the `ACTION_UP` action, there is a `updateBarEntry()` method call. This
    is where we call the classifier to get the probability of the result. This method
    also updates the `BarChart` view based on the results from the classifier, as
    follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `ACTION_UP` 动作中，有一个 `updateBarEntry()` 方法调用。在这里，我们调用分类器来获取结果的概率值。这个方法还会根据分类器的结果更新
    `BarChart` 视图，如下所示：
- en: '[PRE22]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'FreeHandView looks like this, along with an empty bar chart:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: FreeHandView 看起来像这样，并附有一个空的柱状图：
- en: '![](img/ad30f114-27ff-4b55-87b6-1fb2e54beb58.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad30f114-27ff-4b55-87b6-1fb2e54beb58.png)'
- en: With this, we will add the module to recognize the handwritten digits and then
    classify them.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个，我们将添加一个模块来识别手写数字并进行分类。
- en: Digit classifier
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数字分类器
- en: Now, let's write the classifier.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们编写分类器。
- en: 'First, we will load the model file. This method reads the model from the assets
    folder and loads it into the memory:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将加载模型文件。这个方法从 assets 文件夹读取模型并将其加载到内存中：
- en: '[PRE23]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, let''s write the TensorFlow Lite classifier, frame-by-frame. This is the
    place where we get the results from the digit classifier. Once we have received
    the saved file image as the user input, the bitmap will be converted into a byte
    buffer to run the inference on top of the model. Once we have received the output,
    the time taken to get the results are noted using the `SystemClock` time:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们逐步编写 TensorFlow Lite 分类器。这是我们从数字分类器获得结果的地方。一旦我们接收到保存的文件图像作为用户输入，位图将被转换为字节缓冲区，以便在模型上运行推理。一旦接收到输出，所花费的时间将通过
    `SystemClock` 时间来记录：
- en: '[PRE24]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The `runlnference()` method calls the `run` method from`tflite`, as follows:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`runlnference()` 方法调用了`tflite`中的 `run` 方法，如下所示：'
- en: '[PRE25]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, let''s start the application from `MainActivity`, where the `barChart` view
    is initialized. Initialize the `barChart` view on the *x* and *y* axis, along
    with the following values:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们从 `MainActivity` 启动应用程序，在此处初始化 `barChart` 视图。初始化 `barChart` 视图时需要设置 *x*
    和 *y* 轴，并使用以下值：
- en: '[PRE26]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Initialize FreeHandView to start classifying inside the `OnCreate()` method
    of `MainActivity`:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `MainActivity` 的 `OnCreate()` 方法中初始化 FreeHandView 以开始分类：
- en: '[PRE27]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'When you reach the probability value of 1.00, the algorithm identifies the
    digit with 100% accuracy. An example of this is shown here:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你达到 1.00 的概率值时，算法能够以 100% 的准确度识别该数字。以下是一个示例：
- en: '![](img/21170abb-5da1-4041-ad38-d5ea86814376.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/21170abb-5da1-4041-ad38-d5ea86814376.png)'
- en: 'There are instances in which the classification decreases the probability with
    partial matches, as shown in the following screenshot:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在某些情况下，分类会因为部分匹配而降低概率，以下截图展示了这种情况：
- en: '![](img/c7b2ae6e-4285-4a5d-94da-05abb224eee7.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c7b2ae6e-4285-4a5d-94da-05abb224eee7.png)'
- en: 'There are also other instances where the probability ends up with multiple
    partial matches. An example of this is shown in the following screenshot:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还有其他情况，概率会出现多个部分匹配。以下截图展示了这种情况：
- en: '![](img/60708fa3-3c98-4444-b041-9d322a25909a.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/60708fa3-3c98-4444-b041-9d322a25909a.png)'
- en: Any such situation requires more rigorous training of the model.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 任何此类情况都需要对模型进行更严格的训练。
- en: 'Clicking on the RESET button will clear up the view so that you can draw again.
    We will implement it using the following lines of code:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 RESET 按钮将清除视图，以便你重新绘制。我们将使用以下代码行来实现此功能：
- en: '[PRE28]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Once you click on the RESET button, the preceding code clears up the FreeHandView
    area, as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦点击 RESET 按钮，前面的代码会清除 FreeHandView 区域，如下所示：
- en: '![](img/557caf09-525b-4553-8684-893d6776e15f.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/557caf09-525b-4553-8684-893d6776e15f.png)'
- en: You can also check that the application works properly by writing characters
    other than digits, and checking the performance of the output on the bar chart.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以通过写入数字以外的字符并检查条形图上的输出性能，来验证应用程序是否正常工作。
- en: In this section, we learned how the application classifies the different digits
    that are hand-drawn, and also provides the probability of those digits being correct.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们学习了应用程序如何对手绘的不同数字进行分类，并提供这些数字是否正确的概率。
- en: Summary
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Using this Android application, we can learn how to write a freehand writing
    classifier using TensorFlow Lite. With more data on handwritten alphabet datasets,
    we should be able to identify alphabets in any language using GANs.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个 Android 应用程序，我们可以学习如何使用 TensorFlow Lite 编写一个手写分类器。随着更多手写字母数据集的加入，我们应该能够使用
    GANs 识别任何语言的字母。
- en: In the next chapter, we will build a model for sentiment analysis and build
    an app on top of it.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将构建一个情感分析模型，并在其基础上构建一个应用程序。
