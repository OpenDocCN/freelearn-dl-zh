- en: 7\. Computer Vision with Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7. 使用卷积神经网络的计算机视觉
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概览
- en: This chapter covers computer vision and how this is accomplished with neural
    networks. You will learn to build image processing applications and classify models
    with convolutional neural networks. You will also study the architecture of convolutional
    neural networks and how to utilize techniques such as max pooling and flattening,
    feature mapping, and feature detection. By the end of this chapter, you will be
    able to not only build your own image classifiers but also evaluate them effectively
    for your own applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了计算机视觉以及如何通过神经网络实现这一目标。你将学习如何构建图像处理应用程序，并使用卷积神经网络进行模型分类。你还将研究卷积神经网络的架构，并学习如何利用最大池化、展平、特征映射和特征检测等技术。在本章结束时，你不仅能构建自己的图像分类器，还能有效地评估它们，以便应用到自己的实际项目中。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引言
- en: In the previous chapter, we explored model evaluation in detail. We covered
    `accuracy` and why it may be misleading for some datasets, especially for classification
    tasks with highly imbalanced classes. Datasets with imbalanced classes such as
    the prediction of hurricanes in the Pacific Ocean or the prediction of whether
    someone will default on their credit card loan have positive instances that are
    relatively rare compared to negative instances, so accuracy scores are misleading
    since the null accuracy is so high.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们详细探讨了模型评估。我们介绍了`准确率`，以及为什么在某些数据集上，尤其是类别高度不平衡的分类任务中，准确率可能会产生误导。像预测太平洋地区飓风或预测某人是否会违约信用卡贷款这样的数据集，正类实例相较于负类实例较为稀有，因此准确率分数会产生误导，因为空准确率如此之高。
- en: To combat class imbalance, we learned about techniques that we can use to appropriately
    evaluate our model, including calculating model evaluation metrics such as the
    sensitivity, specificity, false positive rate, and `AUC score`, and plotting the
    `ROC curve`. In this chapter, we will learn how to classify another type of dataset—namely,
    images. Image classification is extremely useful and there are many real-world
    applications of it, as we will discover.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对类别不平衡问题，我们学习了可以用来适当评估模型的技术，包括计算模型评估指标，如灵敏度、特异性、假阳性率和`AUC分数`，以及绘制`ROC曲线`。在本章中，我们将学习如何分类另一种类型的数据集——即图像。图像分类非常有用，并且有很多现实世界的应用，我们将会发现。
- en: '**Computer vision** is one of the most important concepts in machine learning
    and artificial intelligence. With the wide use of smartphones for capturing, sharing,
    and uploading images every day, the amount of data that''s generated through images
    is increasing exponentially. So, the need for experts who are specialized in the
    field of computer vision is at an all-time high. Industries such as the health
    care industry are on the verge of a revolution due to the progress that''s been
    made in the field of medical imaging.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算机视觉**是机器学习和人工智能中最重要的概念之一。随着智能手机在拍摄、分享和上传图片方面的广泛使用，通过图像生成的数据量正在呈指数级增长。因此，专注于计算机视觉领域的专家需求达到了历史最高水平。像医疗保健行业这样的行业，由于医学影像领域的进展，正处于一场革命的边缘。'
- en: This chapter will introduce you to computer vision and the various industries
    in which computer vision is used. You will also learn about `ANNs`, which use
    vectors as inputs, CNN uses images as its input. In this chapter, we will be studying
    `CNNs` in greater detail, along with the associated concepts of **max pooling**,
    **flattening**, **feature maps**, and **feature selection**. We will use Keras
    as a tool to run image processing algorithms on real-life images.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍计算机视觉及其应用的各个行业。你还将学习`ANNs`（人工神经网络），它使用向量作为输入，而CNN则使用图像作为输入。在本章中，我们将更详细地研究`CNNs`（卷积神经网络），以及与之相关的概念，如**最大池化**、**展平**、**特征图**和**特征选择**。我们将使用Keras作为工具，运行实际图像上的图像处理算法。
- en: Computer Vision
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: To understand computer vision, let's discuss human vision. Human vision is the
    ability of the human eye and brain to see and recognize objects. Computer vision
    is the process of giving a machine a similar, if not better, understanding of
    seeing and identifying objects in the real world.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解计算机视觉，我们先来讨论一下人类视觉。人类视觉是指人眼和大脑看见并识别物体的能力。计算机视觉是给机器提供一种类似的，甚至是更好的理解，能够看到和识别现实世界中的物体。
- en: It is fairly simple for the human eye to precisely identify whether an animal
    is a tiger or a lion, but it takes a lot of training for a computer system to
    understand such objects distinctly. Computer vision can also be defined as building
    mathematical models that can mimic the function of a human eye and brain. Basically,
    it is about training computers to understand and process images and videos.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对人眼来说，准确识别一个动物是老虎还是狮子相对简单，但对于计算机系统来说，要区分这些物体需要大量的训练。计算机视觉也可以定义为构建能够模仿人眼和大脑功能的数学模型。基本上，就是训练计算机理解和处理图像与视频。
- en: 'Computer vision is an integral part of many cutting-edge areas of robotics:
    health care and medical (X-rays, MRI scans, CT scans, and so on), drones, self-driving
    cars, sports and recreation, and so on. Almost all businesses need computer vision
    to run successfully.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉是许多前沿机器人技术领域的重要组成部分：医疗健康（X光片、MRI扫描、CT扫描等）、无人机、自动驾驶汽车、体育和娱乐等。几乎所有的企业都需要计算机视觉才能成功运营。
- en: Imagine a large amount of data that's generated by CCTV footage across the world,
    the number of pictures our smartphones capture each day, the number of videos
    that are shared on internet sites such as YouTube on a daily basis, and the pictures
    we share on popular social networking sites such as Facebook and Instagram. All
    of this generates huge volumes of image data. To process and analyze this data
    and make computers more intelligent in terms of processing, this data requires
    high-level experts who specialize in computer vision. Computer vision is a highly
    lucrative field in machine learning. The following sections will describe how
    computer vision is achieved with neural networks—and particularly convolutional
    neural networks—that perform well for computer vision tasks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，由全球的CCTV视频、我们智能手机每天捕捉的照片、每天在YouTube等互联网网站上传播的视频，以及我们在Facebook和Instagram等社交网站上分享的图片，所生成的大量数据。所有这些都会产生巨量的图像数据。为了处理和分析这些数据，使计算机在处理上变得更智能，这些数据需要高水平的计算机视觉专家来处理。计算机视觉是机器学习中一个高回报的领域。以下章节将描述如何通过神经网络——特别是卷积神经网络——来实现计算机视觉任务，而这些神经网络在计算机视觉任务中表现出色。
- en: Convolutional Neural Networks
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: 'When we talk about computer vision, we talk about CNNs in the same breath.
    CNN is a class of deep neural network that is mostly used in the field of computer
    vision and imaging. CNNs are used to identify images, cluster them by their similarity,
    and implement object recognition within scenes. CNN has different layers— namely,
    the input layer, the output layer, and multiple hidden layers. These hidden layers
    of a CNN consist of fully connected layers, convolutional layers, a `ReLU layer`
    as an `activation function`, `normalization layers`, and `pooling layers`. On
    a very simple level, CNNs help us identify images and label them appropriately;
    for example, a tiger image will be identified as a tiger:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论计算机视觉时，我们几乎总是提到CNN。CNN是一类深度神经网络，主要用于计算机视觉和图像领域。CNN用于识别图像，将它们按相似性进行聚类，并在场景中实现物体识别。CNN有不同的层次——即输入层、输出层和多个隐藏层。这些隐藏层包括全连接层、卷积层、作为**激活函数**的`ReLU层`、`归一化层`和池化层。在一个非常简单的层面上，CNN帮助我们识别图像并进行适当的标注；例如，一张老虎图像会被识别为老虎：
- en: '![Figure 7.1: A generalized CNN'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.1：一个通用的CNN'
- en: '](img/B15777_07_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_01.jpg)'
- en: 'Figure 7.1: A generalized CNN'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1：一个通用的CNN
- en: 'The following is an example of a CNN classifying a tiger:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个CNN分类老虎的例子：
- en: '![Figure 7.2: A CNN classifying an image of a tiger into the class “Tiger”'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.2：一个CNN将一张老虎图像分类为“老虎”类别'
- en: '](img/B15777_07_02.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_02.jpg)'
- en: 'Figure 7.2: A CNN classifying an image of a tiger into the class "Tiger"'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2：一个CNN将一张老虎图像分类为“老虎”类别
- en: The Architecture of a CNN
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CNN的架构
- en: 'The main components of CNN architecture are as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: CNN架构的主要组成部分如下：
- en: '`Input image`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`输入图像`'
- en: '`Convolutional layer`'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`卷积层`'
- en: '`Pooling layer`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`池化层`'
- en: '`Flattening`'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`扁平化`'
- en: Input Image
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输入图像
- en: 'An `input image` forms the first component of a CNN architecture. An image
    can be of any type: a human, an animal, scenery, a medical X-ray image, and so
    on. Each image is converted into a mathematical matrix of zeros and ones. The
    following figure explains how a computer views an image of the letter **T**.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`输入图像`是CNN架构的第一个组成部分。图像可以是任何类型的：人类、动物、风景、医学X光图像等等。每张图像都会被转换成一个由零和一组成的数学矩阵。以下图解释了计算机如何看待字母**T**的图像。'
- en: 'All the blocks that have a value of one represent the data, while the zeros
    represent blank space:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 所有值为1的块表示数据，而值为0的块表示空白区域：
- en: '![Figure 7.3: Matrix for the letter ‘T’'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.3：字母‘T’的矩阵'
- en: '](img/B15777_07_03.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_03.jpg)'
- en: 'Figure 7.3: Matrix for the letter ''T'''
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：字母‘T’的矩阵
- en: Convolution Layer
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积层
- en: 'The `convolution layer` is the place where image processing starts. A convolution
    layer consists of two parts:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`卷积层`是图像处理开始的地方。卷积层由两个部分组成：'
- en: '`Feature detector` or `filter`'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`特征检测器` 或 `滤波器`'
- en: '`Feature map`'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`特征图`'
- en: '`Feature detector` or a `filter`: This is a matrix or pattern that you put
    on an image to transform it into a feature map:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`特征检测器` 或 `滤波器`：这是一个矩阵或模式，将其应用到图像上，可以将其转化为特征图：'
- en: '![Figure 7.4: Feature detector'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.4：特征检测器'
- en: '](img/B15777_07_04.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_04.jpg)'
- en: 'Figure 7.4: Feature detector'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4：特征检测器
- en: 'As we can see, this feature detector is put (superimposed) on the original
    image and the computation is done on the corresponding elements. The computation
    is done by multiplying the corresponding elements, as shown in the following figure.
    This process is repeated for all the cells. This results in a new processed image—
    `(0x0+0x0+0x1) + (0x1+1x0+0x0) + (0x0+0x1+0x1) = 0`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，这个特征检测器被（叠加）放置在原始图像上，并对相应的元素进行计算。计算是通过乘以相应的元素完成的，如下图所示。这个过程会对所有单元进行重复。最终得到一个新的处理过的图像——
    `(0x0+0x0+0x1) + (0x1+1x0+0x0) + (0x0+0x1+0x1) = 0`：
- en: '![Figure 7.5: Feature detector masked in an image'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.5：特征检测器在图像中的掩膜'
- en: '](img/B15777_07_05.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_05.jpg)'
- en: 'Figure 7.5: Feature detector masked in an image'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5：特征检测器在图像中的掩膜
- en: '`Feature Map`: This is the reduced image that is produced by the convolution
    of an `image` and `feature detector`. We have to put the feature detector on all
    the possible locations of the original image and derive a smaller image from it;
    that derived image is the feature map of the input image:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`特征图`：这是通过将`图像`与`特征检测器`卷积得到的缩小图像。我们必须将特征检测器放在原始图像的所有可能位置，并从中得出一个更小的图像；这个生成的图像就是输入图像的特征图：'
- en: '![Figure 7.6: Feature map'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.6：特征图'
- en: '](img/B15777_07_06.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_06.jpg)'
- en: 'Figure 7.6: Feature map'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.6：特征图
- en: Note
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Here, the `feature detector` is the filter and the `feature map` is the reduced
    image. Some information is lost while reducing the image.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`特征检测器`是滤波器，`特征图`是缩小后的图像。在图像缩小时，一些信息会丢失。
- en: 'In an actual CNN, a number of feature detectors are used to produce a number
    of feature maps, as shown in the following figure:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际的卷积神经网络（CNN）中，会使用多个特征检测器生成多个特征图，如下图所示：
- en: '![Figure 7.7: Multiple feature detectors and maps'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.7：多个特征检测器和特征图'
- en: '](img/B15777_07_07.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_07.jpg)'
- en: 'Figure 7.7: Multiple feature detectors and maps'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7：多个特征检测器和特征图
- en: The Pooling Layer
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 池化层
- en: 'The `pooling layer` helps us ignore the less important data in the image and
    reduces the image further, all while preserving its important features. Consider
    the following three images, which contain four cats in total:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`池化层`帮助我们忽略图像中不太重要的数据，并进一步缩小图像的大小，同时保留其重要特征。考虑以下三张包含四只猫的图像：'
- en: '![Figure 7.8: Example of cat images'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.8：猫图像示例'
- en: '](img/B15777_07_08.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_08.jpg)'
- en: 'Figure 7.8: Example of cat images'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.8：猫图像示例
- en: To identify whether an image has a cat in it or not, the neural network analyzes
    the picture. It may look at ear shape, eye shape, and so on. At the same time,
    the image consists of lots of features that are not related to cats. The tree
    and leaves in the first two images are useless in the identification of the cat.
    The pooling mechanism helps the algorithm understand which parts of the image
    are relevant and which parts are irrelevant.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了识别图像中是否包含猫，神经网络分析图片。它可能会查看耳朵形状、眼睛形状等。同时，图像中包含许多与猫无关的特征。前两张图中的树和叶子在猫的识别中是无用的。池化机制帮助算法理解图像中哪些部分是相关的，哪些部分是无关的。
- en: 'The feature map derived from the convolution layer is passed through a pooling
    layer to further reduce the image, all while preserving the most relevant part
    of the image. The pooling layer consists of functions such as max pooling, min
    pooling, and average pooling. What this means is that we select a matrix size,
    say `2x2`, and we scan the feature map and select the maximum number from the
    `2x2` matrix that fits in that block. The following image gives us a clear idea
    of how max pooling works. Refer to the colors; the max number in each of the colored
    boxes from the feature map is selected in the pooled feature map:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从卷积层得到的特征图会通过池化层进一步减少图像的尺寸，同时保留图像中最相关的部分。池化层由最大池化、最小池化和平均池化等功能组成。这意味着我们选择一个矩阵大小，比如`2x2`，然后扫描特征图，选择适合该块的`2x2`矩阵中的最大数值。下图清晰地展示了最大池化是如何工作的。请参考颜色；从特征图中，每个彩色框中的最大值会被选中并放入池化后的特征图：
- en: '![Figure 7.9: Pooling'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.9：池化'
- en: '](img/B15777_07_09.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_09.jpg)'
- en: 'Figure 7.9: Pooling'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9：池化
- en: 'Consider the case of the box that has number `4` in it. Let''s assume that
    number `4` represents the ears of a cat, while the blank space around the ears
    is `0` and `1`. So, we ignore the `0` and `1` of that block and only select `4`.
    The following is some example code that we would use to add a pooling layer; here,
    `Maxpool2D` is used for max pooling, which helps identify the most important features:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个包含数字`4`的框。假设数字`4`表示一只猫的耳朵，而耳朵周围的空白部分是`0`和`1`。因此，我们忽略该块中的`0`和`1`，只选择`4`。以下是我们用来添加池化层的示例代码；这里使用`Maxpool2D`进行最大池化，它有助于识别最重要的特征：
- en: '[PRE0]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Flattening
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 展平
- en: '`Flattening` is part of a CNN where the image is made ready to use as an input
    to an ANN. As the name suggests, the pooled image is flattened and converted into
    a single column. Each row is made into a column and stacked one over another.
    Here, we have converted a `3x3` matrix into a `1xn` matrix, where `n`, in our
    case, is `9`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`Flattening`是CNN的一部分，其中图像被处理为ANN的输入。顾名思义，经过池化的图像被展平，并转换成一个单一的列。每一行被转化为一列，并一个接一个地堆叠在一起。在这里，我们将一个`3x3`矩阵转换成了一个`1xn`矩阵，其中`n`在我们的例子中为`9`：'
- en: '![Figure 7.10: Flattening'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.10：展平'
- en: '](img/B15777_07_10.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_10.jpg)'
- en: 'Figure 7.10: Flattening'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10：展平
- en: 'In real-time, we have a number of pooled feature maps, and we flatten them
    into a single column. This single column is used as input for an ANN. The following
    figure shows a number of pooled layers flattened into a single column:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在实时处理中，我们会得到多个池化后的特征图，并将它们展平成一个单一的列。这个单一的列会作为ANN的输入。下图展示了多个池化层被展平为单一列：
- en: '![Figure 7.11: Pooling and flattening'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.11：池化与展平'
- en: '](img/B15777_07_11.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_11.jpg)'
- en: 'Figure 7.11: Pooling and flattening'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11：池化与展平
- en: 'The following is some example code that we would use to add a flattening layer;
    here `Flatten` is used for flattening the CNN:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们用来添加展平层的示例代码；这里使用`Flatten`来展平CNN：
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, let''s look at the overall structure of a CNN:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下卷积神经网络（CNN）的整体结构：
- en: '![Figure 7.12: CNN architecture'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.12：CNN架构'
- en: '](img/B15777_07_12.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_12.jpg)'
- en: 'Figure 7.12: CNN architecture'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12：CNN架构
- en: 'The following is some example code that we would use to add the first layer
    to a CNN:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们用来为CNN添加第一层的示例代码：
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`32,3,3` refers to the fact that there are `32` feature detectors of size `3x3`.
    As a good practice, always start with `32`; you can add `64` or `128` later.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`32,3,3`表示有`32`个`3x3`大小的特征检测器。作为一个好的实践，建议从`32`开始，之后可以添加`64`或`128`。'
- en: '`Input_shape`: Since all the images are of different shapes and sizes, this
    `input_image` converts all the images into a uniform shape and size. `(64,64)`
    is the dimension of the converted image. It can be set to `128` or `256`, but
    if you are working on a CPU on a laptop, it is advisable to use `64x64`. The last
    argument, `3`, is used because the image is a colored image (coded in red, blue,
    and green, or RGB). If the image is black and white, the argument can be set to
    one. The activation function that''s being used is ReLU.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`Input_shape`：由于所有图像的形状和大小都不同，这个`input_image`将所有图像转换成统一的形状和大小。`(64,64)`是转换后的图像的尺寸。它可以设置为`128`或`256`，但如果你在笔记本电脑的CPU上工作，建议使用`64x64`。最后一个参数`3`是因为图像是彩色图像（使用红、绿、蓝编码，或RGB）。如果图像是黑白的，那么可以将该参数设置为1。使用的激活函数是ReLU。'
- en: Note
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We are using Keras with TensorFlow as the backend in this book. If the backend
    is Theano, then `input_image` will be coded as (`3,64,64`).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中，我们使用Keras并以TensorFlow作为后端。如果后端是Theano，那么`input_image`将被编码为（`3,64,64`）。
- en: 'The last step is to fit the data that''s been created. Here is the code that
    we use to do so:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是拟合已经创建的数据。这里是我们用来执行此操作的代码：
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`steps_per_epoch` is the number of training images. `validation_steps` is the
    number of test images.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`steps_per_epoch` 是训练图像的数量。`validation_steps` 是测试图像的数量。'
- en: Image Augmentation
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像增强
- en: The word **augmentation** means the action or process of making or becoming
    greater in size or amount. **Image** or **data augmentation** works in a similar
    manner. Image/data augmentation creates many batches of our images. Then, it applies
    random transformations to random images inside the batches. Data transformation
    can be rotating images, shifting them, flipping them, and so on. By applying this
    transformation, we get more diverse images inside the batches, and we also have
    much more data than we had originally.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**增强**这个词意味着使某物变大或增多的动作或过程。**图像**或**数据增强**以类似的方式工作。图像/数据增强创建了许多我们图像的批次。然后，它对批次中的随机图像应用随机转换。数据转换可以是旋转图像、平移图像、翻转图像等。通过应用这种转换，我们在批次中获得了更多样化的图像，并且我们也拥有了比原来更多的数据。'
- en: 'A cylinder can be rotated from different angles and seen differently. In the
    following figure, a single cylinder can be seen from five different angles. So,
    we have effectively created five different images from a single image:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一个圆柱体可以从不同角度旋转并呈现出不同的视角。在以下图像中，单个圆柱体可以从五个不同的角度看到。因此，我们实际上从一张图像中创建了五张不同的图像：
- en: '![Figure 7.13: Image augmentation of a cylinder'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.13：圆柱体的图像增强'
- en: '](img/B15777_07_13.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_13.jpg)'
- en: 'Figure 7.13: Image augmentation of a cylinder'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.13：圆柱体的图像增强
- en: 'The following is some example code that we would use for image augmentation;
    here, the `ImageDataGenerator` class is used for processing. `shear_range`, `zoom_range`,
    and `horizontal_flip` are all used for transforming the images:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们将用于图像增强的一些示例代码；在这里，`ImageDataGenerator` 类用于处理。`shear_range`、`zoom_range`
    和 `horizontal_flip` 都用于转换图像：
- en: '[PRE4]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Advantages of Image Augmentation
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像增强的优势
- en: 'Image augmentation is an important part of processing images:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图像增强是图像处理中的一个重要部分：
- en: '**Reduces overfitting**: It helps reduce overfitting by creating multiple versions
    of the same image, rotated by a given amount.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**减少过拟合**：通过创建相同图像的多个版本，并将其旋转一个给定角度，从而有助于减少过拟合。'
- en: '**Increases the number of images**: A single image acts as multiple images.
    So, essentially, the dataset has fewer images, but each image can be converted
    into multiple images with image augmentation. Image augmentation will increase
    the number of images and each image will be treated differently by the algorithm.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增加图像数量**：一张图像作为多张图像处理。因此，本质上，数据集中的图像较少，但每张图像都可以通过图像增强转换为多张图像。图像增强将增加图像的数量，并且每张图像将被算法以不同的方式处理。'
- en: '**Easy to predict new images**: Imagine that a single image of a football is
    looked at from different angles and each angle is considered a distinct image.
    This will mean that the algorithm will be more accurate at predicting new images:'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容易预测新图像**：想象一张足球的图像从不同角度拍摄，每个角度都被认为是一张不同的图像。这意味着算法在预测新图像时将更加准确：'
- en: '![Figure 7.14: Image augmentation of an image of a football'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.14：足球图像的图像增强'
- en: '](img/B15777_07_14.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_07_14.jpg)'
- en: 'Figure 7.14: Image augmentation of an image of a football'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14：足球图像的图像增强
- en: Now that we have learned about the concepts and theory behind computer vision
    with CNNs, let's work on some practical examples.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学习了计算机视觉与卷积神经网络（CNN）的概念和理论，让我们做一些实际的例子。
- en: 'First, we will start with an exercise in which we''ll build a simple CNN. In
    the following exercises and activities, we will tweak our CNN using permutation
    and combining the following:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将从一个练习开始，构建一个简单的CNN。在接下来的练习和活动中，我们将通过排列组合以下内容来调整我们的CNN：
- en: Adding more CNN layers
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加更多CNN层
- en: Adding more ANN layers
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加更多ANN层
- en: Changing the optimizer function
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改变优化器函数
- en: Changing the activation function
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改变激活函数
- en: Let's begin by creating our first CNN so that we can classify images of cars
    and flowers into their respective classes.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始创建我们的第一个CNN，以便将汽车和花卉图像分类到各自的类别中。
- en: 'Exercise 7.01: Building a CNN and Identifying Images of Cars and Flowers'
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 7.01：构建CNN并识别汽车和花卉的图像
- en: For this exercise, we have images of cars and flowers, which have been divided
    into training and testing sets, and we have to build a CNN that identifies whether
    an image is a car or a flower.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 本次练习中，我们有汽车和花朵的图像，这些图像已经分为训练集和测试集，我们需要构建一个CNN模型，用于识别图像是汽车还是花朵。
- en: Note
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: All the exercises and activities in this chapter will be developed in Jupyter
    notebooks. Please download this book's GitHub repository, along with all the prepared
    templates, from [https://packt.live/39tID2C](https://packt.live/39tID2C).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有练习和活动将在Jupyter notebooks中进行。请从[https://packt.live/39tID2C](https://packt.live/39tID2C)下载本书的GitHub仓库，以及所有准备好的模板。
- en: Before you begin, ensure that you have downloaded the image datasets from this
    book's GitHub repository to your own working directory. You will need a `training_set`
    folder to train your model and a `test_set` folder to test your model. Each of
    these folders will contain a `cars` folder, containing car images, and a `flowers`
    folder, containing flower images.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，确保已从本书的GitHub仓库下载了图像数据集到自己的工作目录。您将需要一个`training_set`文件夹来训练模型，一个`test_set`文件夹来测试模型。这些文件夹中都将包含一个`cars`文件夹，里面是汽车图像，以及一个`flowers`文件夹，里面是花朵图像。
- en: 'The steps for completing this exercise are as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此练习的步骤如下：
- en: 'Import the `numpy` library and the necessary Keras libraries and classes:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`库和所需的Keras库及类：
- en: '[PRE5]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, set a seed and initiate the model with the `Sequential` class:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，设置种子并使用`Sequential`类初始化模型：
- en: '[PRE6]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Add the first layer of the `CNN`, set the input shape to `(64, 64, 3)`, the
    dimension of each image, and set the activation function as a `ReLU`:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加`CNN`的第一层，将输入形状设置为`(64, 64, 3)`，即每个图像的维度，并设置激活函数为`ReLU`：
- en: '[PRE7]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`32,3,3` shows that there are `32` feature detectors of `3x3` size.'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`32,3,3`表示有`32`个`3x3`大小的特征探测器。'
- en: 'Now, add the pooling layer with the image size as `2x2`:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，添加池化层，图像大小为`2x2`：
- en: '[PRE8]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Flatten the output of the pooling layer by adding a flattening layer to the
    `CNN` model:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过添加展平层到`CNN`模型中，展平池化层的输出：
- en: '[PRE9]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Add the first `Dense` layer of the `ANN`. Here, `128` is the output of the
    number of nodes. As a good practice, `128` is good to get started. `activation`
    is `relu`. As a good practice, the power of two is preferred:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加ANN的第一层`Dense`。这里，`128`是节点的输出数量。作为一个好的实践，`128`是一个不错的起点。`activation`为`relu`，作为一个好的实践，最好选择2的幂次方：
- en: '[PRE10]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Add the output layer of the ANN. This is a binary classification problem, so
    the size is `1` and the activation is `sigmoid`:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加ANN的输出层。由于这是一个二分类问题，输出大小为`1`，激活函数为`sigmoid`：
- en: '[PRE11]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Compile the network with an `adam` optimizer and compute the accuracy during
    the training process:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`adam`优化器编译网络，并在训练过程中计算准确率：
- en: '[PRE12]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Create training and test data generators. Rescale the training and test images
    by `1/255` so that all the values are between `0` and `1`. Set these parameters
    for the training data generators only – `shear_range=0.2`, `zoom_range=0.2`, and
    `horizontal_flip=True`:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练和测试数据生成器。将训练和测试图像按`1/255`进行重缩放，使所有值都在`0`和`1`之间。仅为训练数据生成器设置以下参数——`shear_range=0.2`、`zoom_range=0.2`和`horizontal_flip=True`：
- en: '[PRE13]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create a training set from the `training set` folder. `''../dataset/training_set''`
    is the folder where our data has been placed. Our CNN model has an image size
    of `64x64`, so the same size should be passed here too. `batch_size` is the number
    of images in a single batch, which is `32`. `Class_mode` is set to `binary` since
    we are working on binary classifiers:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`training set`文件夹创建训练集。`'../dataset/training_set'`是我们存放数据的文件夹。我们的CNN模型的图像大小为`64x64`，因此这里也应传入相同的大小。`batch_size`是每个批次中的图像数量，设为`32`。`Class_mode`设置为`binary`，因为我们正在处理二分类问题：
- en: '[PRE14]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Repeat *step 10* for the test set while setting the folder to the location
    of the test images, that is, `''../dataset/test_set''`:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对测试集重复*第10步*，同时将文件夹设置为测试图像所在的位置，即`'../dataset/test_set'`：
- en: '[PRE15]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, fit the data. Set the `steps_per_epoch` to `10000` and the `validation_steps`
    to `2500`. The following step might take some time to execute:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，拟合数据。将`steps_per_epoch`设置为`10000`，`validation_steps`设置为`2500`。以下步骤可能需要一些时间来执行：
- en: '[PRE16]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The preceding code produces the following output:'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码将产生以下输出：
- en: '[PRE17]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The accuracy on the validation set is `84.22%`.
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 验证集上的准确率为`84.22%`。
- en: Note
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To get more accurate results, try increasing the number of epochs to about `25`.
    This will increase the time that it takes to process the data, and the total time
    is dependent on the configuration of your machine.
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了获得更准确的结果，尝试将epochs的数量增加到大约`25`。这将增加处理数据所需的时间，总时间取决于机器的配置。
- en: To access the source code for this specific section, please refer to [https://packt.live/38njqHU](https://packt.live/38njqHU).
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/38njqHU](https://packt.live/38njqHU)。
- en: You can also run this example online at [https://packt.live/3iqFpSN](https://packt.live/3iqFpSN).
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你还可以在[https://packt.live/3iqFpSN](https://packt.live/3iqFpSN)上在线运行这个示例。
- en: That completes this exercise on processing images and identifying the contents
    of the images. An important thing to remember here is that this is a robust code
    for any binary classification problem in computer vision. This means that the
    code remains the same, even if the image data changes. We will test our knowledge
    of this by modifying some of the parameters of our model in the next activity
    and evaluating the model's performance.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了关于处理图像和识别图像内容的练习。这里需要记住的一件重要事是，这段代码对于任何二分类问题都是健壮的。这意味着即使图像数据发生变化，代码也保持不变。我们将在下一个活动中通过修改模型的一些参数并评估模型的性能来测试我们对此的理解。
- en: 'Activity 7.01: Amending Our Model with Multiple Layers and the Use of softmax'
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 7.01：用多层和使用softmax修改我们的模型
- en: 'Since we have run a `CNN model` successfully, the next logical step is to try
    and improve the performance of our algorithm. There are many ways to improve its
    performance, and one of the most straightforward ways is by adding multiple ANN
    layers to the model, which we will learn about in this activity. We will also
    change the activation from sigmoid to softmax. By doing this, we can compare the
    result with that of the previous exercise. Follow these steps to complete this
    activity:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经成功运行了`CNN模型`，下一步是尝试提高我们算法的性能。有很多方法可以提高其性能，其中一种最直接的方法是向模型中添加多个ANN层，我们将在本活动中学习这个方法。我们还将激活函数从sigmoid改为softmax。通过这样做，我们可以将结果与上一个练习的结果进行比较。请按照以下步骤完成此活动：
- en: To build a CNN import library, set a seed and create a `Sequential` class and
    import `Conv2D`, `MaxPool2D`, `Flatten`, and `Dense`. `Conv2D` is used to build
    the convolution layer. Since our pictures are in 2D, we have used 2D here. Similarly,
    `Maxpool2D` is used for max pooling, `Flatten` is used for flattening the CNN,
    and `Dense` is used to add a fully connected CNN to an ANN.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要构建CNN导入库，设置种子并创建`Sequential`类，导入`Conv2D`、`MaxPool2D`、`Flatten`和`Dense`。`Conv2D`用于构建卷积层。由于我们的图片是二维的，所以这里使用了二维卷积。类似地，`MaxPool2D`用于最大池化，`Flatten`用于将CNN展开，`Dense`用于向ANN添加全连接层。
- en: Start building a CNN architecture using the preceding libraries. After adding
    the first layer, add two additional layers to your CNN.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前面的库开始构建CNN架构。在添加第一层之后，向CNN中添加两层额外的层。
- en: Add a pooling and flattening layer to it, which will serve as the input for
    the ANN.
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向其中添加一个池化和展平层，它将作为ANN的输入。
- en: Build a fully connected ANN whose inputs will be the output of the CNN. After
    adding the first layer of your ANN, add three additional layers. For the output
    layer of your ANN, use the softmax activation function. Compile the model.
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个全连接的ANN，其输入将是CNN的输出。在添加ANN的第一层后，再添加三层。对于ANN的输出层，使用softmax激活函数。编译模型。
- en: Perform image augmentation to process and transform the data. The `ImageDataGenerator`
    class is used for processing. `shear_range`, `zoom_range`, and `horizontal_flip`
    are all used for the transformation of images.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行图像增强以处理和转换数据。`ImageDataGenerator`类用于处理。`shear_range`、`zoom_range`和`horizontal_flip`都用于图像的转换。
- en: Create the training and test set data.
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练集和测试集数据。
- en: Lastly, fit the data that's been created.
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，拟合已创建的数据。
- en: 'After implementing these steps, you should get the following expected output:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现这些步骤之后，你应该得到以下预期输出：
- en: '[PRE18]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 439.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以在第439页找到。
- en: In this activity, we have modified our CNN model to try and improve the accuracy
    of our image classifier. We have added additional convolutional layers and additional
    ANN fully connected layers and changed the activation function in the output layer.
    By doing so our accuracy has decreased. In the next exercise, we will change the
    activation function back to a sigmoid. We will evaluate the performance by observing
    the accuracy evaluated on the validation dataset.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在此活动中，我们修改了CNN模型，尝试提高图像分类器的准确性。我们添加了额外的卷积层和额外的ANN全连接层，并更改了输出层的激活函数。这样做后，我们的准确性反而下降了。在下一个练习中，我们将激活函数更改回sigmoid。我们将通过观察在验证数据集上评估的准确性来评估性能。
- en: 'Exercise 7.02: Amending Our Model by Reverting to the Sigmoid Activation Function'
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习7.02：通过恢复为Sigmoid激活函数来修改我们的模型
- en: 'In this exercise, we will rebuild our model but revert the activation function
    from softmax back to sigmoid. By doing this, we can compare the accuracy with
    our previous model''s. Follow these steps to complete this exercise:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将重建模型，但将激活函数从softmax恢复为sigmoid。通过这样做，我们可以与之前的模型进行准确度比较。按照以下步骤完成此练习：
- en: 'Import the `numpy` library and the necessary Keras libraries and classes:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`库和必要的Keras库及类：
- en: '[PRE19]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, set the seed and initiate the model with the `Sequential` class:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，设置随机种子并使用`Sequential`类初始化模型：
- en: '[PRE20]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Add the first layer of the CNN, set the input shape to `(64, 64, 3)`, the dimension
    of each image, and set the activation function as a ReLU. Then, add `32` feature
    detectors of size `(3, 3)`. Add two additional convolutional layers with `32`
    feature detectors of size `(3, 3)`, also with ReLU activation functions:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加CNN的第一层，设置输入形状为`(64, 64, 3)`，即每张图像的维度，并将激活函数设置为ReLU。然后，添加`32`个大小为`(3, 3)`的特征检测器。再添加两层具有`32`个`(3,
    3)`大小特征检测器的卷积层，且同样使用ReLU激活函数：
- en: '[PRE21]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, add the pooling layer with the image size as `2x2`:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，添加池化层，图像大小为`2x2`：
- en: '[PRE22]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Add one more `Conv2D` with the same parameters as in *step 3* and a pooling
    layer to supplement it with the same parameters that we used in *step 4*:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再添加一个`Conv2D`层，参数与*步骤3*中的相同，再加一个池化层，用于补充*步骤4*中使用的相同参数：
- en: '[PRE23]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Flatten the output of the pooling layer by adding a flattening layer to the
    `CNN model`:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过向`CNN model`中添加一个flatten层，扁平化池化层的输出：
- en: '[PRE24]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Add the first `Dense` layer of the ANN. Here, `128` is the output of the number
    of nodes. As a good practice, `128` is good to get started. `activation` is `relu`.
    As a good practice, the power of two is preferred. Add three additional layers
    with the same parameters:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加ANN的第一个`Dense`层。这里，`128`是节点的输出数量。作为一个好的实践，`128`是一个很好的起点。`activation`是`relu`。作为一个好的实践，最好选择二的幂次。再添加三个具有相同参数的额外层：
- en: '[PRE25]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Add the output layer of the `ANN`. This is a binary classification problem,
    so the output is `1` and the activation is `sigmoid`:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加ANN的输出层。这是一个二分类问题，因此输出为`1`，激活函数为`sigmoid`：
- en: '[PRE26]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Compile the network with an Adam optimizer and compute the accuracy during
    the training process:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Adam优化器编译网络，并在训练过程中计算准确度：
- en: '[PRE27]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Create training and test data generators. Rescale the training and test images
    by `1/255` so that all the values are between `0` and `1`. Set these parameters
    for the training data generators only – `shear_range=0.2`, `zoom_range=0.2`, and
    `horizontal_flip=True`:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练和测试数据生成器。将训练和测试图像按`1/255`缩放，以使所有值位于`0`和`1`之间。只为训练数据生成器设置以下参数——`shear_range=0.2`，`zoom_range=0.2`，以及`horizontal_flip=True`：
- en: '[PRE28]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Create a training set from the `training set` folder. `../dataset/training_set`
    is the folder where our data is placed. Our CNN model has an image size of 64x64,
    so the same size should be passed here too. `batch_size` is the number of images
    in a single batch, which is `32`. `class_mode` is binary since we are working
    on binary classifiers:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`training set`文件夹创建训练集。`../dataset/training_set`是我们存放数据的文件夹。我们的CNN模型图像大小为64x64，因此这里也应该传入相同的大小。`batch_size`是单个批次中的图像数量，为`32`。`class_mode`为二进制，因为我们正在处理二分类问题：
- en: '[PRE29]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Repeat *step 11* for the test set by setting the folder to the location of
    the test images, that is, `''../dataset/test_set''`:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对测试集重复*步骤11*，通过设置文件夹为测试图像所在位置，即`'../dataset/test_set'`：
- en: '[PRE30]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Finally, fit the data. Set the `steps_per_epoch` to `10000` and the `validation_steps`
    to `2500`. The following step might take some time to execute:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，拟合数据。将`steps_per_epoch`设置为`10000`，`validation_steps`设置为`2500`。以下步骤可能需要一些时间来执行：
- en: '[PRE31]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The preceding code produces the following output:'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码产生以下输出：
- en: '[PRE32]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The accuracy of the model is `86.75%`, which is clearly greater than the accuracy
    of the model we built in the previous exercise. This shows the importance of activation
    functions. Just changing the output activation function from softmax to sigmoid
    increased the accuracy from `46.91%` to `86.75%`.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的准确率为`86.75%`，显然高于我们在上一个练习中构建的模型的准确率。这表明激活函数的重要性。仅仅将输出激活函数从softmax改为sigmoid，就将准确率从`46.91%`提高到了`86.75%`。
- en: Note
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2ZD9nKM](https://packt.live/2ZD9nKM).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/2ZD9nKM](https://packt.live/2ZD9nKM)。
- en: You can also run this example online at [https://packt.live/3dPZiiQ](https://packt.live/3dPZiiQ).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在网上运行此示例：[https://packt.live/3dPZiiQ](https://packt.live/3dPZiiQ)。
- en: In the next exercise, we will experiment with a different optimizer and observe
    how that affects the model's performance.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个练习中，我们将尝试不同的优化器，并观察它如何影响模型的性能。
- en: Note
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In a binary classification problem (in our case, cars versus flowers), it is
    always better to use sigmoid as the activation function for the output.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在二分类问题中（在我们的案例中是汽车与花朵），通常更好的做法是将sigmoid作为输出的激活函数。
- en: 'Exercise 7.03: Changing the Optimizer from Adam to SGD'
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 7.03：将优化器从Adam更改为SGD
- en: 'In this exercise, we will amend the model again by changing the optimizer to
    `SGD`. By doing this, we can compare the accuracy with our previous models. Follow
    these steps to complete this exercise:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将再次修改模型，将优化器更改为`SGD`。通过这样做，我们可以比较与之前模型的准确度。请按照以下步骤完成本练习：
- en: 'Import the `numpy` library and the necessary Keras libraries and classes:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`库以及所需的Keras库和类：
- en: '[PRE33]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now, initiate the model with the `Sequential` class:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`Sequential`类初始化模型：
- en: '[PRE34]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Add the first layer of the `CNN`, set the input shape to `(64, 64, 3)`, the
    dimension of each image, and set the activation function as `ReLU`. Then, add
    `32` feature detectors of size (`3, 3`). Add two additional convolutional layers
    with the same number of feature detectors with the same size:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加`CNN`的第一层，将输入形状设置为`(64, 64, 3)`，即每个图像的维度，并将激活函数设置为`ReLU`。然后，添加`32`个大小为`(3,
    3)`的特征检测器。再添加两个相同特征检测器和相同大小的卷积层：
- en: '[PRE35]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, add the pooling layer with the image size as `2x2`:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，添加池化层，图像大小为`2x2`：
- en: '[PRE36]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Add one more `Conv2D` with the same parameters as in *step 3* and a pooling
    layer to supplement it with the same parameters that we used in *step 4*:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加另一个`Conv2D`，参数与*步骤 3*中的相同，并添加一个池化层来补充它，使用与*步骤 4*中相同的参数：
- en: '[PRE37]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Add a `Flatten` layer to complete the CNN architecture:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个`Flatten`层以完成CNN架构：
- en: '[PRE38]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Add the first `Dense` layer of the ANN of size `128`. Add three more dense
    layers to the network with the same parameters:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加ANN的第一层`Dense`，大小为`128`。再向网络添加三个相同参数的`Dense`层：
- en: '[PRE39]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Add the output layer of the ANN. This is a binary classification problem, so
    the output is `1` and the activation is `sigmoid`:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加ANN的输出层。这是一个二分类问题，所以输出为`1`，激活函数为`sigmoid`：
- en: '[PRE40]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Compile the network with an `SGD optimizer` and compute the accuracy during
    the training process:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`SGD优化器`编译网络，并在训练过程中计算准确度：
- en: '[PRE41]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Create training and test data generators. Rescale the training and test images
    by `1/255` so that all the values are between `0` and `1`. Set these parameters
    for the training data generators only – `shear_range=0.2`, `zoom_range=0.2`, and
    `horizontal_flip=True`:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练和测试数据生成器。通过`1/255`对训练和测试图像进行重新缩放，使得所有值都在`0`和`1`之间。仅为训练数据生成器设置以下参数：`shear_range=0.2`，`zoom_range=0.2`，以及`horizontal_flip=True`：
- en: '[PRE42]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Create a training set from the `training set` folder. `../dataset/training_set`
    is the folder where our data is placed. Our CNN model has an image size of `64x64`,
    so the same size should be passed here too. `batch_size` is the number of images
    in a single batch, which is `32`. `class_mode` is binary since we are creating
    a binary classifier:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`training set`文件夹创建一个训练集。`../dataset/training_set`是我们存放数据的文件夹。我们的CNN模型图像大小为`64x64`，因此这里也应该传递相同的大小。`batch_size`是每批次的图像数量，即`32`。`class_mode`是二分类模式，因为我们正在创建一个二分类器：
- en: '[PRE43]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Repeat *step 11* for the test set by setting the folder to the location of
    the test images, that is, `''../dataset/test_set''`:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对测试集重复*步骤 11*，将文件夹设置为测试图像所在的位置，即`'../dataset/test_set'`：
- en: '[PRE44]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Finally, fit the data. Set the `steps_per_epoch` to `10000` and the `validation_steps`
    to `2500`. The following step might take some time to execute:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，拟合数据。将`steps_per_epoch`设置为`10000`，`validation_steps`设置为`2500`。以下步骤可能需要一些时间来执行：
- en: '[PRE45]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The preceding code produces the following output:'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码会产生以下输出：
- en: '[PRE46]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The accuracy is `84.54%` since we have used multiple `ANNs` and `SGD` as the optimizer.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 准确率为`84.54%`，因为我们使用了多个`ANNs`和`SGD`作为优化器。
- en: Note
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/31Hu9vm](https://packt.live/31Hu9vm).
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/31Hu9vm](https://packt.live/31Hu9vm)。
- en: You can also run this example online at [https://packt.live/3gqE9x8](https://packt.live/3gqE9x8).
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您还可以在[https://packt.live/3gqE9x8](https://packt.live/3gqE9x8)上在线运行这个示例。
- en: 'So far, we have worked with a number of different permutations and combinations
    of our model. It seems like the best accuracy for this dataset can be obtained
    by doing the following:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经尝试了模型的多种不同排列和组合。看起来，针对该数据集，获得最佳准确率的做法是：
- en: Adding multiple CNN layers.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加多个 CNN 层。
- en: Adding multiple ANN layers.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加多个 ANN 层。
- en: Having the activation as sigmoid.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 sigmoid 激活函数。
- en: Having the optimizer as adam.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Adam 作为优化器。
- en: Increasing the epoch size to about `25` (this takes a lot of computational time
    – make sure you have a GPU to do this). This will increase the accuracy of your predictions.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 epoch 大小增加到大约`25`（这需要大量的计算时间——确保您有 GPU 进行处理）。这将提高预测的准确性。
- en: Finally, we will go ahead and predict a new unknown image, pass it to the algorithm,
    and validate whether the image is classified correctly. In the next exercise,
    we will demonstrate how to use the model to classify new images.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将继续预测一个新的未知图像，将其传递给算法，并验证该图像是否被正确分类。在下一个练习中，我们将演示如何使用模型对新图像进行分类。
- en: 'Exercise 7.04: Classifying a New Image'
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 7.04：分类新图像
- en: In this exercise, we will try to classify a new image. The image hasn't been
    exposed to the algorithm, so we will use this exercise to test our algorithm.
    You can run any of the algorithms in this chapter (although the one that gets
    the highest accuracy is preferred) and then use the model to classify the image.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将尝试对新图像进行分类。该图像尚未接触过算法，因此我们将使用此练习来测试我们的算法。您可以运行本章中的任何算法（尽管推荐使用准确率最高的那个），然后使用模型对图像进行分类。
- en: Note
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The image that's being used in this exercise can be found in this book's GitHub
    repository at [https://packt.live/39tID2C](https://packt.live/39tID2C).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习中使用的图像可以在本书的 GitHub 仓库中找到，地址为[https://packt.live/39tID2C](https://packt.live/39tID2C)。
- en: Before we begin, ensure that you have downloaded `test_image_1` from this book's
    GitHub repository to your own working directory. This exercise follows on from
    the previous exercises, so ensure that you have one of the algorithms from this
    chapter ready to run in your workspace.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，请确保您已经从本书的 GitHub 仓库下载了`test_image_1`并将其保存到您的工作目录中。这个练习是基于之前的练习，所以请确保您已经在工作区中准备好本章中的算法并可以运行。
- en: 'The steps for completing this exercise are as follows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本练习的步骤如下：
- en: 'Load the image. `''test_image_1.jpg''` is the path of the test image. Please
    change the path to where you have saved the dataset in your system. Look at the
    image to verify what it is:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载图像。`'test_image_1.jpg'`是测试图像的路径。请将路径更改为您在系统中保存数据集的位置。查看图像以验证它是什么：
- en: '[PRE47]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Print the class labels located in the `class_indices` attribute of the training set:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印训练集的`class_indices`属性中的类别标签：
- en: '[PRE48]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Process the image:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理图像：
- en: '[PRE49]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Predict the new image:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测新图像：
- en: '[PRE50]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The `prediction` method will output the image as `1` or `0`. To map `1` and
    `0` to `flower` or `car`, use the `class_indices` method with an `if…else` statement,
    as follows:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`prediction` 方法将输出图像的`1`或`0`。为了将`1`和`0`映射到`flower`（花）或`car`（车），可以使用`class_indices`方法和`if…else`语句，示例如下：'
- en: '[PRE51]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The preceding code produces the following output:'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码会产生以下输出：
- en: '[PRE52]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '`test_image_1` is the image of a car (you can see this by viewing the image
    for yourself) and was correctly predicted to be a car by the model.'
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`test_image_1` 是一张汽车的图像（您可以通过查看图像确认），并且模型正确预测它是汽车。'
- en: In this exercise, we trained our model and then gave the model an image of a
    car. By doing this, we found out that the algorithm is classifying the image correctly.
    You can train the model on any type of an image by using the same process. For
    example, if you train the model with scans of lung infections and healthy lungs,
    then the model will be able to classify whether a new scan represents an infected
    lung or a healthy lung.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们训练了我们的模型，然后给模型提供了一张汽车的图像。通过这样做，我们发现算法正确地对图像进行了分类。你可以使用相同的过程训练模型来处理任何类型的图像。例如，如果你使用肺部感染和健康肺部的扫描训练模型，那么模型将能够分类新扫描是否代表感染的肺部或健康的肺部。
- en: Note
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/31I6B9F](https://packt.live/31I6B9F).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/31I6B9F](https://packt.live/31I6B9F)。
- en: You can also run this example online at [https://packt.live/2BzmEMx](https://packt.live/2BzmEMx).
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在 [https://packt.live/2BzmEMx](https://packt.live/2BzmEMx) 上在线运行此示例。
- en: In the next activity, we will put our knowledge into practice by using a model
    that we trained in *Exercise 7.04*, *Classifying a New Image*.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个活动中，我们将把我们的知识付诸实践，使用我们在 *Exercise 7.04*，*Classifying a New Image* 中训练的模型。
- en: 'Activity 7.02: Classifying a New Image'
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动7.02：分类新图像
- en: 'In this activity, you will try to classify another new image, just like we
    did in the preceding exercise. The image is not exposed to the algorithm, so we
    will use this activity to test our algorithm. You can run any of the algorithms
    in this chapter (although the one that gets the highest accuracy is preferred)
    and then use the model to classify your images. The steps to implement this activity
    are as follows:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，你将尝试像我们在前一个练习中所做的那样分类另一张新图像。由于图像没有暴露给算法，因此我们将利用此活动来测试我们的算法。你可以运行本章中的任何一个算法（尽管最高准确率的算法更可取），然后使用模型来对你的图像进行分类。实施此活动的步骤如下：
- en: Run any one of the algorithms from this chapter.
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行本章中的任何一个算法。
- en: Load the image (`test_image_2`) from your directory.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从你的目录加载图像（`test_image_2`）。
- en: Process the image using the algorithm.
  id: totrans-275
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用算法处理图像。
- en: Predict the subject of the new image. You can view the image yourself to check
    whether the prediction is correct.
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预测新图像的主题。你可以查看图像本身以检查预测是否正确。
- en: Note
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The image that's being used in this activity can be found in this book's GitHub
    repository at [https://packt.live/39tID2C](https://packt.live/39tID2C).
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个活动中使用的图像可以在这本书的 GitHub 仓库中找到，链接地址为 [https://packt.live/39tID2C](https://packt.live/39tID2C)。
- en: Before starting, ensure you have downloaded `test_image_2` from this book's
    GitHub repository to your own working directory. This activity follows on directly
    from the previous exercises, so please ensure that you have one of the algorithms
    from this chapter ready to run in your workspace.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保已经将 `test_image_2` 从这本书的 GitHub 仓库下载到你自己的工作目录中。此活动直接跟进前面的练习，因此请确保已经准备好本章中的一个算法以在你的工作空间中运行。
- en: 'After implementing these steps, you should get the following expected output:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 实施这些步骤后，你应该得到以下预期输出：
- en: '[PRE53]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Note
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 442.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可以在第442页找到。
- en: In this activity, we trained the most performant model in this chapter when
    given the various parameters that were modified, including the optimizer and the
    activation function in the output layer according to the accuracy on the validation
    dataset. We tested the classifier on a test image and found it to be correct.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在此活动中，我们根据在验证数据集上的准确性修改了各种参数，包括优化器和输出层中的激活函数，从而训练了本章中最高性能的模型。我们对一个测试图像进行了分类，发现其分类是正确的。
- en: Summary
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we studied why we need computer vision and how it works. We
    learned why computer vision is one of the hottest fields in machine learning.
    Then, we worked with convolutional neural networks, learned about their architecture,
    and looked at how we can build CNNs in real-life applications. We also tried to
    improve our algorithms by adding more ANN and CNN layers and by changing the activation
    and optimizer functions. Finally, we tried out different activation functions
    and loss functions.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们研究了为什么需要计算机视觉以及其工作原理。我们了解到为什么计算机视觉是机器学习中最热门的领域之一。然后，我们使用卷积神经网络进行了工作，了解了它们的架构，并探讨了如何在现实应用中构建CNN。我们还通过增加更多的ANN和CNN层以及更改激活和优化器函数来尝试改进我们的算法。最后，我们尝试了不同的激活函数和损失函数。
- en: In the end, we were able to successfully classify new images of cars and flowers
    through the algorithm. Remember, the images of cars and flowers can be substituted
    with any other images, such as tigers and deer, or MRI scans of brains with and
    without a tumor. Any binary classification computer imaging problem can be solved
    with the same approach.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们成功地通过该算法对新图像（如汽车和花卉）进行了分类。请记住，汽车和花卉的图像可以替换为任何其他图像，例如老虎和鹿，或带有和不带有肿瘤的大脑MRI扫描图像。任何二分类的计算机图像问题都可以采用相同的方法来解决。
- en: In the next chapter, we will study an even more efficient technique for working
    on computer vision, which is less time-consuming and easier to implement. The
    following chapter will teach us how to fine-tune pre-trained models for our own
    applications that will help create more accurate models that can be trained in
    faster times. The models that will be used are called VGG-16 and ResNet50 and
    are popular pre-trained models that are used to classify images.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习一种更高效的计算机视觉技术，它不仅节省时间，而且更容易实现。接下来的章节将教我们如何微调预训练模型，以便应用于我们的实际需求，从而帮助创建更加准确、训练速度更快的模型。将要使用的模型是VGG-16和ResNet50，它们是常用的预训练模型，广泛用于图像分类。
