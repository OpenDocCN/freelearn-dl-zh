- en: Modern Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现代神经网络
- en: In [Chapter 1](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml), *Computer Vision
    and Neural Networks*, we presented how recent neural networks, which are more
    suitable for image processing, surpassed previous computer vision methods of the
    past decade. However, limited by how much we can reimplement from scratch, we
    only covered basic architectures. Now, with TensorFlow's powerful APIs at our
    fingertips, it is time to discover what **convolutional neural networks** (**CNNs**)
    are, and how these modern methods are trained to further improve their robustness.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml)《计算机视觉与神经网络》中，我们介绍了近年来更适合图像处理的神经网络是如何超越过去十年计算机视觉方法的。然而，由于受限于我们从头开始重新实现的能力，我们只涵盖了基本架构。现在，随着TensorFlow强大的API触手可得，是时候探索什么是**卷积神经网络**（**CNNs**），以及这些现代方法是如何被训练以进一步提高它们的鲁棒性。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: CNNs and their relevance to computer vision
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN及其与计算机视觉的相关性
- en: Implementing these modern networks with TensorFlow and Keras
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorFlow和Keras实现这些现代网络
- en: Advanced optimizers and how to train CNNs efficiently
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级优化器和如何高效训练CNN
- en: Regularization methods and how to avoid overfitting
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则化方法和如何避免过拟合
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The main resources of this chapter are implemented with TensorFlow. The Matplotlib
    package ([https://matplotlib.org](https://matplotlib.org)) and the scikit-image
    package ([https://scikit-image.org](https://scikit-image.org)) are also used,
    though only to display some results or to load example images.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要资源是用TensorFlow实现的。同时，Matplotlib包（[https://matplotlib.org](https://matplotlib.org)）和scikit-image包（[https://scikit-image.org](https://scikit-image.org)）也有使用，尽管它们仅用于显示一些结果或加载示例图像。
- en: As in previous chapters, Jupyter notebooks illustrating the concepts covered
    in this chapter can be found in the following GitHub folder: [github.com/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2/tree/master/Chapter03](https://github.com/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2/tree/master/Chapter03).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如同前几章一样，展示本章概念的Jupyter笔记本可以在以下GitHub文件夹中找到：[github.com/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2/tree/master/Chapter03](https://github.com/PacktPublishing/Hands-On-Computer-Vision-with-TensorFlow-2/tree/master/Chapter03)。
- en: Discovering convolutional neural networks
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索卷积神经网络
- en: In the first part of this chapter, we will present CNNs, also known as **ConvNets**,and
    explain why they have become omnipresent in vision tasks.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的第一部分，我们将介绍CNN，也称为**卷积网络**（**ConvNets**），并解释为什么它们在视觉任务中变得无处不在。
- en: Neural networks for multidimensional data
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多维数据的神经网络
- en: CNNs were introduced to solve some of the shortcomings of the original neural
    networks. In this section, we will address these issues and present how CNNs deal
    with them.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: CNNs的引入是为了解决原始神经网络的一些缺陷。在本节中，我们将讨论这些问题，并展示CNN是如何处理它们的。
- en: Problems with fully connected networks
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 完全连接网络的问题
- en: 'Through our introductory experiment in [Chapter 1](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml),
    *Computer Vision and Neural Networks*, and [Chapter 2](c7c49010-458f-47ef-a538-96118f9cd892.xhtml),
    *TensorFlow Basics and Training a Model*, we have already highlighted the following
    two main drawbacks of basic networks when dealing with images:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过我们在[第1章](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml)《计算机视觉与神经网络》和[第2章](c7c49010-458f-47ef-a538-96118f9cd892.xhtml)《TensorFlow基础与训练模型》的入门实验，我们已经突出了基本网络在处理图像时的以下两个主要缺点：
- en: An explosive number of parameters
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爆炸性的参数数量
- en: A lack of spatial reasoning
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空间推理的缺乏
- en: Let's discuss each of these here.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这里讨论一下这些内容。
- en: An explosive number of parameters
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 爆炸性的参数数量
- en: Images are complex structures with a large number of values (that is, *H* × *W*
    × *D* values with *H* indiacting the image's height, *W* its width, and *D* its
    depth/number of channels, such as *D* = 3 for RGB images). Even the small, single-channel
    images we used as examples in the first two chapters represent input vectors of
    size *28 *× *28 *× *1 = 784* values each. For the first layer of the basic neural
    network we implemented, this meant a weight matrix of shape (784, 64). This equates
    to 50,176 (784 × 64) parameter values to optimize, just for this variable!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图像是具有大量值的复杂结构（即，*H* × *W* × *D* 个值，其中*H*表示图像的高度，*W*表示宽度，*D*表示深度/通道数，例如RGB图像的*D*
    = 3）。即使是我们在前两章中使用的单通道小图像，也代表了大小为*28 × 28 × 1 = 784*的输入向量。对于我们实现的基础神经网络的第一层，这意味着一个形状为(784,
    64)的权重矩阵。这意味着仅仅这个变量就需要优化50,176（784 × 64）个参数值！
- en: This number of parameters simply explodes when we consider larger RGB images
    or deeper networks.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑更大的RGB图像或更深的网络时，参数的数量会呈指数级增长。
- en: A lack of spatial reasoning
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缺乏空间推理
- en: Because their neurons receive all the values from the previous layer without
    any distinction (they are *fully connected*), these neural networks do not have
    a notion of *distance*/*spatiality*. Spatial relations in the data are lost. Multidimensional
    data, such as images, could also be anything from column vectors to dense layers
    because their operations do not take into account the data dimensionality nor
    the positions of input values. More precisely, this means that the notion of proximity
    between pixels is lost to **fully connected** (**FC**) layers, as all pixel values
    are combined by the layers with no regard for their original positions.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 因为它们的神经元接收来自上一层的所有值且没有任何区分（它们是*全连接的*），这些神经网络没有*距离*/*空间性*的概念。数据中的空间关系丧失了。多维数据，如图像，也可以是从列向量到密集层的任何形式，因为它们的操作没有考虑数据的维度性和输入值的位置。更准确地说，这意味着**全连接**（**FC**）层丧失了像素间的接近概念，因为所有像素值在层内被组合时并不考虑它们的原始位置。
- en: As it does not change the behavior of dense layers, to simplify their computations
    and parameter representations, it is common practice to *flatten* multidimensional
    inputs before passing them to these layers (that is, to reshape them into column
    vectors).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它不会改变全连接层的行为，为了简化计算和参数表示，通常会在将多维输入传递到这些层之前，先对其进行*展平*（即将其重塑为列向量）。
- en: Intuitively, neural layers would be much smarter if they could take into account
    **spatial information**; that is, that some input values belong to the same pixel
    (channel values) or to the same image region (neighbor pixels).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地看，如果神经网络能够考虑**空间信息**，即某些输入值属于同一个像素（通道值）或属于同一区域（相邻像素），那么神经层将更加智能。
- en: Introducing CNNs
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入卷积神经网络（CNN）
- en: CNNs offer simple solutions to these shortcomings. While they work the same
    way as the networks we introduced previously (such as feed-forward and backpropagation),
    some clever changes were brought to their architecture.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: CNN为这些不足提供了简单的解决方案。尽管它们与我们之前介绍的网络（如前馈网络和反向传播网络）工作原理相同，但它们的架构做了一些巧妙的改进。
- en: 'First of all, CNNs can handle multidimensional data. For images, a CNN takes
    as input three-dimensional data (height × width × depth) and has its own neurons
    arranged in a similar volume (refer to *Figure 3.1*). This leads to the second
    novelty of CNNs—unlike fully connected networks, where neurons are connected to
    all elements from the previous layer, each neuron in CNNs only has access to some
    elements in the neighboring region of the previous layer. This region (usually
    square and spanning all channels) is called the **receptive field** of the neurons
    (or the filter size):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，CNN能够处理多维数据。对于图像，CNN输入的是三维数据（高度 × 宽度 × 深度），并且它的神经元排列方式也类似于一个体积（参见*图 3.1*）。这导致了CNN的第二个创新——与全连接网络不同，在CNN中，每个神经元只访问上一层中相邻区域的一些元素，而不是连接到上一层的所有元素。这个区域（通常是正方形并跨越所有通道）被称为神经元的**感受野**（或过滤器大小）：
- en: '![](img/adc1e504-6290-43f6-b749-aa6409ffa9be.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/adc1e504-6290-43f6-b749-aa6409ffa9be.png)'
- en: 'Figure 3.1: CNN representation, showing the *receptive fields* of the top-left
    neurons from the first layer to the last (further explanations can be found in
    the following subsections)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：CNN表示，展示了从第一层到最后一层的左上角神经元的*感受野*（更多解释可在以下小节中找到）
- en: By linking neurons only to their neighboring ones in the previous layer, CNNs
    not only drastically reduce the number of parameters to train, but also preserve
    the localization of image features.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通过只将神经元与上一层中相邻的神经元相连，CNN不仅大幅减少了需要训练的参数数量，还保留了图像特征的定位。
- en: CNN operations
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络操作
- en: With this architecture paradigm, several new types of layers were also introduced,
    efficiently taking advantage of *multidimensionality* and *local connectivity*.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种架构范式下，还引入了几种新的层类型，充分利用了*多维性*和*局部连接性*。
- en: Convolutional layers
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积层
- en: CNNs get their name from *convolutional layers*, which are at the core of their
    architecture. In these layers, the number of parameters is further reduced by
    sharing the same weights and bias among all neurons connected to the same output
    channel.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: CNN之所以得名，是因为它们的核心架构包含了*卷积层*。在这些层中，通过在所有连接到同一输出通道的神经元之间共享相同的权重和偏置，进一步减少了参数的数量。
- en: Concept
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概念
- en: 'These specific neurons with shared weights and bias can also be thought of as
    a single neuron sliding over the whole input matrix with *spatially limited connectivity*.
    At each step, this neuron is only spatially connected to the local region in the
    input volume (*H* × *W* × *D*) it is currently sliding over. Given this limited
    input of dimensions, *k[H]* × *k[W]* × *D* for a neuron with a filter size (*k[H]*,
    *k[W]*), the neuron still works like the ones modeled in our first chapter—it
    linearly combines the input values (*k[H]* × *k[W]* × *D* values) before applying
    an activation function to the sum (a linear or non-linear function). Mathematically,
    the response, *z[i,j]*, of the neuron when presented with the input patch starting
    at position *(i,* *j*) can be expressed as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这些具有共享权重和偏置的特定神经元也可以被认为是一个在整个输入矩阵上滑动的单一神经元，具有*空间有限的连接性*。在每一步，这个神经元只与当前滑动的输入体积（*H*
    × *W* × *D*）中的局部区域进行空间连接。考虑到这种有限维度的输入，*k[H]* × *k[W]* × *D*，对于具有过滤器大小（*k[H]*，*k[W]*）的神经元，该神经元的工作方式与我们第一章中建模的神经元类似——它在线性组合输入值（*k[H]*
    × *k[W]* × *D* 个值）之后，再应用激活函数对和进行处理（线性或非线性函数）。从数学角度来看，当神经元接受从位置 *(i, j)* 开始的输入块时，它的响应
    *z[i,j]* 可以表示为：
- en: '![](img/2928d949-f803-4a05-af2b-f58df1cee1b8.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2928d949-f803-4a05-af2b-f58df1cee1b8.png)'
- en: '![](img/55a0a8c2-4a60-41e8-a9da-0c3bc0154704.png) is the neuron''s weights
    (that is, a two-dimensional matrix of shape *k[H]* × *k[W]* × *D*), ![](img/895581ac-c2d3-4936-8811-a3f896e59e00.png) is the
    neuron''s bias, and ![](img/4f85cb73-d794-47a7-a737-750799a3cc72.png) is the activation
    function (for instance, *sigmoid*). Repeating this operation for each position
    that the neuron can take over the input data, we obtain its complete response
    matrix, 𝑧, of dimensions *H*[o] × *W*[o], with *H*[o] and *W*[o] being the number
    of times the neuron can slide vertically and horizontally (respectively) over
    the input tensor.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/55a0a8c2-4a60-41e8-a9da-0c3bc0154704.png) 是神经元的权重（即形状为 *k[H]* × *k[W]*
    × *D* 的二维矩阵），![](img/895581ac-c2d3-4936-8811-a3f896e59e00.png) 是神经元的偏置，![](img/4f85cb73-d794-47a7-a737-750799a3cc72.png)
    是激活函数（例如，*sigmoid*）。对于神经元可以在输入数据上滑动的每个位置，重复此操作后，我们得到其完整的响应矩阵 𝑧，尺寸为 *H*[o] × *W*[o]，其中
    *H*[o] 和 *W*[o] 分别是神经元可以在输入张量上垂直和水平滑动的次数。'
- en: In practice, most of the time, square filters are used, meaning that they have
    a size (*k,* *k*) with *k =* *k[H]* = *k[W]*. For the rest of this chapter, we
    will only consider square filters to simplify the explanations, though it is good
    to remember that their height and width may vary.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，大多数情况下使用的是方形过滤器，这意味着它们的大小是 (*k*, *k*)，其中 *k =* *k[H]* = *k[W]*。在本章的其余部分，为了简化解释，我们将只考虑方形过滤器，尽管值得记住的是，它们的高度和宽度可能会有所变化。
- en: As a convolutional layer can still have *N* sets of different neurons (that
    is, *N* sets of neurons with shared parameters), their response maps are stacked
    together into an output tensor of shape *H*[o] × *W*[o] × *N*.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 由于卷积层仍然可以有 *N* 组不同的神经元（即，具有共享参数的 *N* 组神经元），它们的响应图被堆叠在一起，形成形状为 *H*[o] × *W*[o]
    × *N* 的输出张量。
- en: 'In the same way that we applied matrix multiplication to fully connected layers,
    the **convolution operation** can be used here to compute all the response maps
    at once (hence the name of these layers). Those familiar with this operation may
    have recognized it as soon as we mentioned *sliding filters over the input matrix*.
    For those who are unfamiliar with the operation, the results of a convolution
    are indeed obtained by sliding a filter, *w*, over the input matrix, *x*, and
    computing, at each position, the dot product of the filter and the patch of *x*
    starting at the current position. This operation is illustrated in *Figure 3.2*
    (an input tensor with a single channel is used to keep the diagram easy to understand):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在全连接层中应用矩阵乘法一样，**卷积操作**也可以在这里用来一次性计算所有响应图（因此这些层的名称）。熟悉这种操作的人，可能在我们提到*在输入矩阵上滑动过滤器*时就认出了它。对于那些不熟悉这种操作的人，卷积的结果确实是通过将一个过滤器
    *w* 滑动到输入矩阵 *x* 上，并在每个位置计算过滤器与从当前起始位置开始的 *x* 块的点积来获得的。此操作在*图 3.2*中得到了说明（使用单通道输入张量，以便使图示易于理解）：
- en: '![](img/6a7df36e-fb8c-46ea-91bc-ccbb59354477.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6a7df36e-fb8c-46ea-91bc-ccbb59354477.png)'
- en: 'Figure 3.2: A convolution illustrated'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2：卷积示意图
- en: In *Figure 3.2*, please note that the input, *x,* has been *padded* with zeros,
    which is commonly done in convolutional layers; for instance, when we want the
    output to be the same size as the original input (a size of 3 × 3 in this example).
    The notion of padding is further developed later in this chapter.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图3.2*中，请注意输入*x*已经被填充为零，这在卷积层中是常见的操作，例如当我们希望输出与原始输入（例如本例中的3 × 3大小）相同尺寸时。填充的概念在本章后面进一步发展。
- en: 'The proper mathematical term for this operation is actually *cross-correlation*,
    though *convolution *is commonly used in the machine learning community. The cross-correlation
    of a matrix, *x*, with a filter, *w*, is ![](img/bc0a22cf-8707-490f-9dcf-d6799fadb04f.png):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这种操作的正确数学术语实际上是*交叉相关*，尽管在机器学习社区中通常使用*卷积*。矩阵*x*与滤波器*w*的交叉相关定义为![](img/bc0a22cf-8707-490f-9dcf-d6799fadb04f.png)：
- en: '![](img/7679d42b-e3ac-4046-b758-00bd8baab798.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7679d42b-e3ac-4046-b758-00bd8baab798.png)'
- en: 'Notice the correspondence with our equation for *z*. On the other hand, the
    actual mathematical convolution of a matrix, *x*, with a filter, *w*, is for all
    valid positions (*i*, *j*):'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意我们用于*z*的方程式的对应关系。另一方面，矩阵*x*与滤波器*w*的实际数学卷积对所有有效位置(*i*, *j*)定义为：
- en: '![](img/cd2644fe-7b8b-45ee-b290-56ce8f40cbba.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cd2644fe-7b8b-45ee-b290-56ce8f40cbba.png)'
- en: As we can see, both operations are quite similar in this setup, and convolution
    results can be obtained from the cross-correlation operation by simply *flipping *the
    filters before it.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，在这种设置中，这两种操作非常相似，通过简单地在执行之前*翻转*滤波器，可以从交叉相关操作中获得卷积结果。
- en: Properties
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 属性
- en: A convolutional layer with *N* sets of different neurons is thus defined by *N*
    weight matrices (also called **filters** or **kernels**) of shape *D* × *k* ×
    *k* (when the filters are square), and *N* bias values. Therefore, this layer
    only has *N* × (*D**k*² + 1) values to train. A fully connected layer with similar
    input and output dimensions would need (*H* × *W* × *D*) × (*H*[o] × *W*[o] ×
    *N*) parameters instead. As we demonstrated previously, the number of parameters
    for fully connected layers is influenced by the dimensionality of the data, whereas
    this does not affect the parameter numbers for convolutional layers.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一个具有*N*组不同神经元的卷积层由形状为*D* × *k* × *k*（当滤波器为正方形时）的*N*个权重矩阵（也称为**滤波器**或**核心**）和*N*个偏置值定义。因此，这一层只需训练*N*
    × (*D**k*² + 1)个值。与具有相似输入和输出维度的全连接层不同，后者需要(*H* × *W* × *D*) × (*H*[o] × *W*[o]
    × *N*)个参数。正如我们之前所示，全连接层的参数数量受数据维度的影响，而这并不影响卷积层的参数数量。
- en: This property makes convolutional layers really powerful tools in computer vision
    for two reasons. First, as implied in the previous paragraph, it means we can
    train networks for larger input images without impacting the number of parameters
    we would need to tune. Second, this also means that convolutional layers can be
    applied to any images, irrespective of their dimensions! Unlike networks with
    fully connected layers, purely convolutional ones do not need to be adapted and
    retrained for inputs of different sizes.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 正是这一特性使得卷积层在计算机视觉中成为强大的工具，原因有两点。首先，正如前文所示，这意味着我们可以训练适用于更大输入图像的网络，而不影响需要调整的参数数量。其次，这也意味着卷积层可以应用于任何尺寸的图像！与具有全连接层的网络不同，纯卷积层不需要为不同尺寸的输入进行适应和重新训练。
- en: When applying a CNN to images of various sizes, you still need to be careful
    when sampling the input batches. Indeed, a subset of images can be stacked together
    into a normal batch tensor only if they all have the same dimensions. Therefore,
    in practice, you should either sort the images before batching them (mostly done
    during the training phase) or simply process each image separately (usually during
    the testing phase). However, both to simplify data processing and the network's
    task, people usually preprocess their images so they are all the same size (through
    scaling and/or cropping).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当将CNN应用于各种大小的图像时，对输入批次进行采样仍然需要注意。事实上，只有所有图像具有相同尺寸时，才能将图像的子集堆叠到普通的批次张量中。因此，在实践中，在批处理之前应对图像进行排序（主要在训练阶段）或简单地分别处理每个图像（通常在测试阶段）。然而，为了简化数据处理和网络任务，人们通常会预处理图像，使它们的大小都相同（通过缩放和/或裁剪）。
- en: Besides those computational optimizations, convolutional layers also have interesting
    properties related to image processing. With training, the layer's filters become
    really good at reacting to specific *local features* (a layer with *N* filters
    means the possibility to react to *N* different features). Each kernel of the
    first convolutional layer in a CNN would, for instance, learn to activate for
    a specific low-level feature, such as a specific line orientation or color gradient.
    Then, deeper layers would use these results to localize more abstract/advanced
    features, such as the shape of a face, and the contours of a particular object.
    Moreover, each filter (that is, each set of shared neurons) would respond to a
    specific image feature, whatever its location(s) in the image. More formally,
    convolutional layers are invariant to translation in the image coordinate space.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 除了那些计算优化外，卷积层还有一些与图像处理相关的有趣特性。经过训练，卷积层的滤波器能够非常擅长对特定的*局部特征*做出反应（一个拥有*N*个滤波器的层意味着能够对*N*种不同的特征做出反应）。例如，CNN中第一层卷积层的每个卷积核将学习对特定的低级特征做出响应，比如特定的线条方向或颜色渐变。接下来，较深的层将使用这些结果来定位更加抽象或高级的特征，比如人脸的形状或特定物体的轮廓。此外，每个滤波器（即每组共享的神经元）都会对图像中的特定特征作出反应，无论该特征在图像中的位置如何。更正式地说，卷积层对图像坐标空间中的平移是不变的。
- en: The response map of a filter over the input image can be described as a map
    representing the locations where the filter responded to its target feature. For
    this reason, those intermediary results in CNNs are commonly called **feature
    maps**. A layer with *N* filters will, therefore, return *N* feature maps, each
    corresponding to the detection of a particular feature in the input tensors. The
    stack of *N* feature maps returned by a layer is commonly called a **feature volume**
    (with a shape of *H*[o] × *W*[o] × *N*).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波器对输入图像的响应图可以描述为一个表示滤波器对目标特征响应位置的地图。因此，这些中间结果在CNN中通常被称为**特征图**。因此，一个拥有*N*个滤波器的层将返回*N*个特征图，每个特征图对应于输入张量中特定特征的检测。由层返回的*N*个特征图的堆叠通常被称为**特征体积**（形状为*H*[o]
    × *W*[o] × *N*）。
- en: Hyperparameters
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数
- en: A convolutional layer is first defined by its number of filters, *N*, by its
    input depth, *D* (that is, the number of input channels), and by its filter/kernel
    size, (*k[H]*, *k[W]*). As square filters are commonly used, the size is usually
    simply defined by *k* (though, as mentioned earlier, non-square filters are sometimes
    considered).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层首先由其滤波器的数量*N*、输入深度*D*（即输入通道的数量）和滤波器/卷积核的大小（*k[H]*，*k[W]*）来定义。由于常用的是方形滤波器，大小通常仅由*k*来定义（尽管如前所述，有时也会考虑非方形滤波器）。
- en: However, as mentioned previously, convolutional layers actually differ from
    the homonym mathematical operation. The operation between the input and their
    filters can take several additional hyperparameters, affecting the way the filters
    are *sliding* over the images.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如前面提到的，卷积层实际上与同名的数学运算有所不同。输入与滤波器之间的操作可以有几个额外的超参数，影响滤波器在图像上*滑动*的方式。
- en: First, we can apply different *strides* with which the filters are sliding.
    The stride hyperparameter thus defines whether the dot product between the image
    patches and the filters should be computed at every position when sliding (*stride
    = 1*), or every *s* position (*stride = s*). The larger the stride, the sparser
    the resulting feature maps.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以应用不同的*步幅*，即滤波器滑动的步伐。步幅超参数定义了当滑动时，图像块与滤波器之间的点积是否应在每个位置计算（*stride = 1*），还是在每*s*个位置计算（*stride
    = s*）。步幅越大，得到的特征图就越稀疏。
- en: Images can also be *zero-padded* before convolution; that is, their sizes can
    be synthetically increased by adding rows and columns of zeros around their original
    content. As shown in *Figure 3.2*, this padding increases the number of positions
    the filters can take over the images. We can thus specify the padding value to
    be applied (that is, the number of empty rows and columns to be added on each
    side of the inputs).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图像在进行卷积之前也可以进行*零填充*；即通过在原始内容周围添加零的行和列，合成地增加图像的尺寸。如*图3.2*所示，这种填充增加了滤波器可以覆盖的图像位置数量。我们因此可以指定要应用的填充值（即要在输入的每一侧添加的空行和空列的数量）。
- en: The letter *k* is commonly used for the filter/kernel size (*k* for *kernel*).
    Similarly, *s* is commonly used for the stride, and *p* for the padding. Note
    that, as with the filter size, the same values are usually used for the horizontal
    and vertical strides *(s = s[H] = s[W]),* as well as for the horizontal and vertical
    padding; though, for some specific use cases, they may have different values.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 字母*k*通常用于表示滤波器/核大小（*k*代表*kernel*）。类似地，*s*通常用于表示步幅，*p*用于表示填充。请注意，与滤波器大小一样，通常会对水平和垂直步幅使用相同的值（*s
    = s[H] = s[W]*），并且水平和垂直填充也通常使用相同的值；不过，在某些特定的使用案例中，它们可能会有不同的值。
- en: 'All these parameters (the number of kernels, *N;* kernel size, *k;* stride, *s;* and
    padding, *p*) not only affect the layer''s operations, but also its output shape.
    Until now, we defined this shape as (*H*[o], *W*[o], *N*), with *H*[o] and *W*[o]
    the number of times the neuron can slide vertically and horizontally over the
    inputs. So, what actually are *H*[o] and *W*[o]? Formally, they can be computed
    as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些参数（核的数量*N*；核的大小*k*；步幅*s*；以及填充*p*）不仅影响层的操作，还会影响其输出形状。到目前为止，我们定义的输出形状为(*H*[o]，*W*[o]，*N*)，其中*H*[o]和*W*[o]*是神经元在输入上垂直和水平滑动的次数。那么，*H*[o]和*W*[o]*到底是什么呢？从形式上来看，它们可以按以下方式计算：
- en: '![](img/ea6641bb-f197-4660-bd66-92dec120b447.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ea6641bb-f197-4660-bd66-92dec120b447.png)'
- en: While we invite you to pick some concrete examples to better grasp these formulas,
    we can intuitively understand the logic behind them. Filters of size 𝑘 can take
    a maximum of *H - k + 1* different vertical positions and *W - k + 1* horizontal
    ones in images of size *H* × *W*. Additionally, this number of positions increases
    to *H - k + 2p + 1 *(with respect to *W - k + 2p + 1*) if these images are padded
    by *p* on every side. Finally, increasing the stride, *s,* basically means considering
    only one position out of *s*, explaining the division (note that it is an integer
    division).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们邀请你选择一些具体的例子来更好地理解这些公式，但我们可以直观地理解它们背后的逻辑。大小为𝑘的滤波器在大小为*H* × *W*的图像中，可以占据最多*H
    - k + 1*个不同的垂直位置和*W - k + 1*个水平位置。此外，如果这些图像在每一边都进行了*p*的填充，那么这些位置的数量将增加到*H - k
    + 2p + 1*（关于*W - k + 2p + 1*）。最后，增加步幅*s*，基本上意味着只考虑*s*个位置中的一个，这就解释了除法（注意这是整数除法）。
- en: With these hyperparameters, we can easily control the layer's output sizes.
    This is particularly convenient for applications such as object segmentation;
    that is, when we want the output segmentation mask to be the same size as the
    input image.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些超参数，我们可以轻松控制层的输出尺寸。这在物体分割等应用中尤其方便；也就是说，当我们希望输出的分割掩码与输入图像的大小相同。
- en: TensorFlow/Keras methods
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow/Keras方法
- en: 'Available in the low-level API, `tf.nn.conv2d()` (refer to the documentation
    at [https://www.tensorflow.org/api_docs/python/tf/nn/conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d))
    is the default choice for image convolution. Its main parameters are as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在低级API中可用，`tf.nn.conv2d()`（请参考文档：[https://www.tensorflow.org/api_docs/python/tf/nn/conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)）是进行图像卷积的默认选择。其主要参数如下：
- en: '`input`: The batch of input images, of shape *(B, H, W, D*), with *B *being
    the batch size.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`input`：输入图像的批次，形状为*(B, H, W, D*)，其中*B*是批次大小。'
- en: '`filter`: The *N* filters stacked into a tensor of shape (*k[H], k[W], D, N*).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filter`：堆叠成形状为(*k[H], k[W], D, N*)的*N*个滤波器。'
- en: '`strides`: A list of four integers representing the stride for each dimension
    of the batched input. Typically, you would use *[1, s[H], s[W], 1*] (that is,
    applying a custom stride only for the two spatial dimensions of the image).'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strides`：表示批量输入每个维度步幅的四个整数的列表。通常，你会使用*[1, s[H], s[W], 1]*（即，仅对图像的两个空间维度应用自定义步幅）。'
- en: '`padding`: Either a list of *4 × 2* integers representing the padding before
    and after each dimension of the batched input, or a string defining which predefined
    padding case to use; that is, either `VALID` or `SAME` (explanations follow).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`：一个*4 × 2*整数列表，表示每个批量输入维度的前后填充，或者一个字符串，定义要使用的预定义填充案例；即，`VALID`或`SAME`（接下来的解释）。'
- en: '`name`: The name to identify this operation (useful for creating clear, readable
    graphs).'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：用于标识该操作的名称（有助于创建清晰、易读的图形）。'
- en: 'Note that `tf.nn.conv2d()` accepts some other more advanced parameters, which
    we will not cover yet (refer to the documentation). *Figures 3.3* and* 3.4* illustrate
    the effects of two convolutional operations with different arguments:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`tf.nn.conv2d()`接受一些更高级的参数，我们暂时不会介绍（请参考文档）。*图3.3*和*3.4*展示了两种不同参数的卷积操作效果：
- en: '![](img/8a9c4782-cf35-48eb-b204-c14d5a29ecb9.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8a9c4782-cf35-48eb-b204-c14d5a29ecb9.png)'
- en: 'Figure 3.3: Example of a convolution performed on an image with TensorFlow.
    The kernel here is a well-known one, commonly used to apply *Gaussian blur* to
    images'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3：使用 TensorFlow 对图像进行卷积的示例。这里的卷积核是一个著名的卷积核，常用于对图像应用*高斯模糊*。
- en: 'In the following screenshot, a kernel that''s well known in computer vision
    is applied:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下截图中，应用了计算机视觉领域中一个知名的卷积核：
- en: '![](img/0451566f-c965-4ee1-8b51-c38f95f12463.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0451566f-c965-4ee1-8b51-c38f95f12463.png)'
- en: 'Figure 3.4: Example of another TensorFlow convolution, with a larger stride.
    This specific kernel is commonly used to extract edges/contours in images'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4：另一个 TensorFlow 卷积的示例，具有更大的步幅。这个特定的卷积核通常用于提取图像中的边缘/轮廓。
- en: Regarding padding, TensorFlow developers made the choice to provide two different
    pre-implemented modes so that users do not have to figure out which value, *p,*
    they need for usual cases. `VALID` means the images won't be padded (*p* = 0),
    and the filters will slide only over the default *valid* positions. When opting
    for `SAME`, TensorFlow will calculate the value, *p,* so that the convolution
    outputs have the *same* height and width as the inputs for a stride of `1` (that
    is, solving *H*[o] = *H*[o] and *W*[o] = *W* given the equations presented in
    the previous section, temporarily setting *s* to 1).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 关于填充，TensorFlow 开发者选择提供两种不同的预实现模式，以便用户无需自己去搞清楚在常规情况下需要使用哪个值，*p*。`VALID` 表示图像不会被填充（*p*
    = 0），滤波器只会在默认的*有效*位置上滑动。而选择 `SAME` 时，TensorFlow 会计算 *p* 的值，以确保卷积输出的高度和宽度与输入在步幅为
    `1` 时相同（也就是说，根据前面章节中给出的方程，暂时将 *s* 设置为 1，从而解得 *H*[o] = *H*[o] 和 *W*[o] = *W*）。
- en: Sometimes, you may want to pad with something more complex than zeros. In those
    cases, it is recommended to use the `tf.pad()` method (refer to the documentation
    at [https://www.tensorflow.org/api_docs/python/tf/pad](https://www.tensorflow.org/api_docs/python/tf/pad))
    instead, and then simply instantiate a convolution operation with `VALID` padding.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，你可能需要使用比零更复杂的填充。在这种情况下，建议使用 `tf.pad()` 方法（请参考文档：[https://www.tensorflow.org/api_docs/python/tf/pad](https://www.tensorflow.org/api_docs/python/tf/pad)），然后简单地实例化一个使用
    `VALID` 填充的卷积操作。
- en: TensorFlow also offers several other low-level convolution methods, such as
    `tf.nn.conv1d()` (refer to the documentation at [https://www.tensorflow.org/api_docs/python/tf/nn/conv1d](https://www.tensorflow.org/api_docs/python/tf/nn/conv1d))
    and `tf.nn.conv3d()` (refer to the documentation at [https://www.tensorflow.org/api_docs/python/tf/nn/conv3d](https://www.tensorflow.org/api_docs/python/tf/nn/conv3d)), 
    for one-dimensional and three-dimensional data, respectively, or `tf.nn.depthwise_conv2d()`
    (refer to the documentation at [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d))
    to convolve each channel of the images with different filters, and more.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 还提供了其他几个低级别的卷积方法，例如 `tf.nn.conv1d()`（请参考文档：[https://www.tensorflow.org/api_docs/python/tf/nn/conv1d](https://www.tensorflow.org/api_docs/python/tf/nn/conv1d)）和
    `tf.nn.conv3d()`（请参考文档：[https://www.tensorflow.org/api_docs/python/tf/nn/conv3d](https://www.tensorflow.org/api_docs/python/tf/nn/conv3d)），分别用于一维和三维数据，或者使用
    `tf.nn.depthwise_conv2d()`（请参考文档：[https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)）对图像的每个通道进行不同滤波器的卷积等。
- en: 'So far, we have only presented convolutions with fixed filters. For CNNs, we
    have to make the filters trainable. Convolutional layers also apply a learned
    bias before passing the result to an activation function. This series of operations
    can, therefore, be implemented as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只展示了使用固定滤波器的卷积。对于卷积神经网络（CNN），我们必须使滤波器可训练。卷积层还会在将结果传递给激活函数之前应用一个学习到的偏置。因此，这一系列操作可以如下实现：
- en: '[PRE0]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This feed-forward function can further be wrapped into a `Layer` object, similar
    to how the fully connected layer we implemented in [Chapter 1](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml),
    *Computer Vision and Neural Networks*, was built around the matrix operations.
    Through the Keras API, TensorFlow 2 provides its own `tf.keras.layers.Layer` class,
    which we can extend (refer to the documentation at [https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)).
    The following code block demonstrates how a simple convolution layer can be built
    on this:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这个前馈函数可以进一步封装成一个`Layer`对象，类似于我们在[第1章](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml)中实现的全连接层，*计算机视觉与神经网络*，是围绕矩阵操作构建的。通过Keras
    API，TensorFlow 2提供了自己的`tf.keras.layers.Layer`类，我们可以对其进行扩展（参见[https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)的文档）。以下代码块演示了如何基于此构建一个简单的卷积层：
- en: '[PRE1]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Most of TensorFlow's mathematical operations (for example, in `tf.math` and
    `tf.nn`) already have their derivatives defined by the framework. Therefore, as
    long as a layer is composed of such operations, we do not have to manually define
    its backpropagation, saving quite some effort!
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow的大多数数学操作（例如`tf.math`和`tf.nn`中的操作）已经由框架定义了它们的导数。因此，只要一个层由这些操作组成，我们就不需要手动定义它的反向传播，节省了大量的精力！
- en: 'While this implementation has the advantage of being explicit, the Keras API
    also encapsulates the initialization of common layers (as presented in [Chapter
    2](c7c49010-458f-47ef-a538-96118f9cd892.xhtml), *TensorFlow Basics and Training
    a Model*), thereby speeding up development. With the `tf.keras.layers` module,
    we can instantiate a similar convolutional layer in a single call, as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个实现的优点是显式的，但Keras API也封装了常见层的初始化（如[第2章](c7c49010-458f-47ef-a538-96118f9cd892.xhtml)中介绍的，*TensorFlow基础与模型训练*），从而加速了开发过程。通过`tf.keras.layers`模块，我们可以通过一次调用实例化一个类似的卷积层，如下所示：
- en: '[PRE2]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`tf.keras.layers.Conv2D()` (refer to the documentation at [https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D))
    has a long list of additional parameters, encapsulating several concepts, such
    as weight regularization (presented later in this chapter). Therefore, it is recommended
    to use this method when building advanced CNNs, instead of spending time reimplementing
    such concepts.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.keras.layers.Conv2D()`（参见[https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)的文档）有一个长长的附加参数列表，封装了多个概念，比如权重正则化（将在本章稍后介绍）。因此，建议在构建高级CNN时使用此方法，而不是花时间重新实现这些概念。'
- en: Pooling layers
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 池化层
- en: Another commonly used category of layer introduced with CNNs is the *pooling*
    type.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个与CNN一起使用的常见层类别是*池化*类型。
- en: Concept and hyperparameters
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概念和超参数
- en: These pooling layers are a bit peculiar because they do not have any trainable
    parameters. Each neuron simply takes the values in its *window* (the receptive
    field) and returns a single output, computed from a predefined function. The two
    most common pooling methods are max-pooling and average-pooling. **Max-pooling**
    layers return only the maximum value at each depth of the pooled area (refer to
    *Figure 3.5*), and **average-pooling **layers compute the average at each depth
    of the pooled area (refer to *Figure 3.6*).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这些池化层有点特别，因为它们没有任何可训练的参数。每个神经元仅仅取其*窗口*（感受野）中的值，并返回一个单一的输出，该输出是通过预定义函数计算得出的。最常见的两种池化方法是最大池化和平均池化。**最大池化**层仅返回池化区域每个深度的最大值（参考*图
    3.5*），而**平均池化**层计算池化区域每个深度的平均值（参考*图 3.6*）。
- en: 'Pooling layers are commonly used with a *stride* value equal to the size of
    their *window/kernel size*, in order to apply the pooling function over non-overlapping
    patches. Their purpose is to *reduce the spatial dimensionality of the data*,
    cutting down the total number of parameters needed in the network, as well as
    its computation time. For instance, a pooling layer with a *2 × 2* window size
    and stride of *2* (that is, *k* = 2 and *s* = 2) would take patches of four values
    at each depth and return a single number. It would thus divide the height and
    the width of the features by *2;* that is, dividing the number of computations
    for the following layers by *2 × 2 = 4*. Finally, note that, as with convolutional
    layers, you can pad the tensors before applying the operation (as shown in *Figure
    3.5*):'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层通常与 *步幅* 值等于其 *窗口/核大小* 一起使用，以便对不重叠的区域应用池化函数。它们的目的是 *减少数据的空间维度*，从而减少网络中所需的参数总数以及计算时间。例如，具有
    *2 × 2* 窗口大小和步幅为 *2* 的池化层（即 *k* = 2 和 *s* = 2）将取每个深度的四个值，并返回一个单一的数字。这样，它将把特征的高度和宽度除以
    *2*；也就是说，减少接下来层的计算次数 *2 × 2 = 4*。最后，注意，和卷积层一样，你可以在应用操作之前对张量进行填充（如 *图 3.5* 所示）：
- en: '![](img/0594d28a-0092-4675-ba9b-4d181ffa9ab2.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0594d28a-0092-4675-ba9b-4d181ffa9ab2.png)'
- en: 'Figure 3.5: Illustration of a max-pooling operation with a window size of 3
    × 3, a padding of 1, and a stride of 2 on a single-channel input'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5：展示了一个窗口大小为 3 × 3、填充为 1、步幅为 2 的单通道输入的最大池化操作
- en: 'Through the padding and stride parameters, it is thus possible to control the
    dimensions of the resulting tensors. *Figure 3.6* provides another example:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 通过填充（padding）和步幅（stride）参数，可以控制生成张量的维度。*图 3.6* 提供了另一个示例：
- en: '![](img/aad0f6e0-c963-4531-be17-a1276f82aabc.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aad0f6e0-c963-4531-be17-a1276f82aabc.png)'
- en: 'Figure 3.6: Illustration of an average-pooling operation with a window size
    of 2 × 2, a padding of 0, and a stride of 2 on a single-channel input'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6：展示了一个窗口大小为 2 × 2、填充为 0、步幅为 2 的单通道输入的平均池化操作
- en: With hyperparameters being similar to convolutional layers except for the absence
    of trainable kernels, pooling layers are, therefore, easy to use and lightweight
    solutions for controlling data dimensionality.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 由于池化层的超参数与卷积层类似，除了没有可训练的卷积核，因此池化层是易于使用且轻量级的解决方案，适用于控制数据的维度。
- en: TensorFlow/Keras methods
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow/Keras 方法
- en: 'Also available from the `tf.nn` package, `tf.nn.max_pool()` (refer to the documentation
    at [https://www.tensorflow.org/api_docs/python/tf/nn/max_pool](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool))
    and `tf.nn.avg_pool()` (refer to the documentation at [https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool](https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool))
    conveniently have a signature quite similar to `tf.nn.conv2d()`, as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以从 `tf.nn` 包中获得，`tf.nn.max_pool()`（参考文档 [https://www.tensorflow.org/api_docs/python/tf/nn/max_pool](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool)）和
    `tf.nn.avg_pool()`（参考文档 [https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool](https://www.tensorflow.org/api_docs/python/tf/nn/avg_pool)）的签名与
    `tf.nn.conv2d()` 非常相似，如下所示：
- en: '`value`: The batch of input images of shape (*B*, *H*, *W*, *D*), with *B *being
    the batch size'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value`：形状为 (*B*, *H*, *W*, *D*) 的输入图像批次，其中 *B* 是批次大小'
- en: '`ksize`: A list of four integers representing the window size in each dimension;
    commonly, *[1, k, k, 1*] is used'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ksize`：一个包含四个整数的列表，表示每个维度的窗口大小；通常使用 *[1, k, k, 1]* '
- en: '`strides`: A list of four integers representing the stride for each dimension
    of the batched input, similar to `tf.nn.conv2d()`'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strides`：一个包含四个整数的列表，表示批处理输入每个维度的步幅，类似于 `tf.nn.conv2d()` '
- en: '`padding`: A string defining which padding algorithm to use (`VALID` or `SAME`)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`：一个字符串，定义要使用的填充算法（`VALID` 或 `SAME`）'
- en: '`name`: The name to identify this operation (useful for creating clear, readable
    graphs)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：用于标识此操作的名称（对于创建清晰、可读的图形非常有用）'
- en: '*Figure 3.7* illustrates an average-pooling operation applied to an image:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 3.7* 展示了应用于图像的平均池化操作：'
- en: '![](img/898a506c-2d09-4aa2-bc4d-6f5b4939fd16.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/898a506c-2d09-4aa2-bc4d-6f5b4939fd16.png)'
- en: 'Figure 3.7: Example of average-pooling performed on an image with TensorFlow'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.7：使用 TensorFlow 对图像进行平均池化的示例
- en: 'In *Figure 3.8*, the max-pooling function is applied to the same image:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 3.8* 中，对相同的图像应用了最大池化函数：
- en: '![](img/39987d76-b942-4691-92fb-031dd4c60dc0.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/39987d76-b942-4691-92fb-031dd4c60dc0.png)'
- en: 'Figure 3.8: Example of another max-pooling operation, with an excessively large
    window size compared to the stride (purely for demonstration purposes)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8：另一个最大池化操作的示例，窗口大小与步幅相比过大（仅用于演示目的）
- en: 'Here, again, we can still use the higher-level API to make the instantiation
    slightly more succinct:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们仍然可以使用更高级的API，使得实例化过程更加简洁：
- en: '[PRE3]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Since pooling layers do not have trainable weights, there is no real distinction
    between the pooling operation and the corresponding layer in TensorFlow. This
    makes these operations not only lightweight, but easy to instantiate.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 由于池化层没有可训练的权重，因此池化操作与TensorFlow中对应的层之间没有实际区别。这使得这些操作不仅轻量级，而且易于实例化。
- en: Fully connected layers
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全连接层
- en: It is worth mentioning that FC layers are also used in CNNs, the same way they
    are in regular networks. We will present, in the following paragraphs, when they
    should be considered, and how to include them in CNNs.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，全连接层也用于CNN，就像在常规网络中一样。接下来的段落中，我们将介绍何时考虑使用它们，以及如何将它们包含在CNN中。
- en: Usage in CNNs
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在CNN中的应用
- en: While FC layers can be added to CNNs processing multidimensional data, this
    implies, however, that the input tensors passed to these layers must first be
    reshaped into a batched column vector—the way we did with the MNIST images for
    our simple network in [Chapter 1](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml),
    *Computer Vision and Neural Networks*, and [Chapter 2](c7c49010-458f-47ef-a538-96118f9cd892.xhtml),
    *TensorFlow Basics and Training a Model* (that is, *flattening* the height, width,
    and depth dimensions into a single vector).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然全连接层可以添加到处理多维数据的CNN中，但这意味着传递给这些层的输入张量必须首先被重塑为批处理的列向量——就像我们在[第1章](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml)《计算机视觉与神经网络》和[第2章](c7c49010-458f-47ef-a538-96118f9cd892.xhtml)《TensorFlow基础与模型训练》中所做的那样（即将高度、宽度和深度维度*展平*为一个单一的向量）。
- en: FC layers are also often called **densely connected**, or simply **dense** (as
    opposed to other CNN layers that have more limited connectivity).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 全连接层也常被称为**密集连接**层，或简洁地称为**密集**层（与其他连接性较为有限的CNN层相对）。
- en: While it can be advantageous in some cases for neurons to have access to the
    complete input map (for instance, to combine spatially distant features), fully
    connected layers have several shortcomings, as mentioned at the beginning of this
    chapter (for example, the loss of spatial information and the large number of
    parameters). Moreover, unlike other CNN layers, dense ones are defined by their
    input and output sizes. A specific dense layer will not work for inputs that have
    a shape different from the one it was configured for. Therefore, using FC layers
    in a neural network usually means losing the possibility to apply them to images
    of heterogeneous sizes.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在某些情况下，神经元访问完整的输入图（例如，结合空间上远离的特征）可能是有利的，但全连接层有几个缺点，如本章开头所述（例如，空间信息丢失和参数数量庞大）。此外，与其他CNN层不同，全连接层是由其输入和输出的大小来定义的。特定的全连接层不能处理形状与其配置时不同的输入。因此，在神经网络中使用全连接层通常意味着失去将其应用于不同尺寸图像的可能性。
- en: Despite these shortcomings, these layers are still commonly used in CNNs. They
    are usually found among the final layers of a network, for instance, to convert
    the multidimensional features into a 1D classification vector.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些缺点，这些层仍然在CNN中广泛使用。它们通常位于网络的最后几层，用于将多维特征转换为1D分类向量。
- en: TensorFlow/Keras methods
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow/Keras 方法
- en: 'Although we already used TensorFlow''s dense layers in the previous chapter,
    we did not stop to focus on their parameters and properties. Once again, the signature
    of `tf.keras.layers.Dense()` (refer to the documentation at [https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense))
    is comparable to that of previously introduced layers, with the difference that
    they do not accept any `strides` or `padding` for parameters, but instead use `units`
    representing the number of neurons/output size, as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在上一章中已经使用了TensorFlow的全连接层，但我们没有停下来关注它们的参数和属性。再次提醒，`tf.keras.layers.Dense()`的签名（请参考[https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)的文档）与之前介绍的层类似，不同之处在于它们不接受任何`strides`或`padding`参数，而是使用`units`来表示神经元/输出大小，具体如下：
- en: '[PRE4]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Remember that you should, however, take care of *flattening* the multidimensional
    tensors before passing them to dense layers. `tf.keras.layers.Flatten()` (refer
    to the documentation at [https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten))
    can be used as an intermediate layer for that purpose.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，请记住，在将数据传递给密集层之前，你应当小心*展平*多维张量。`tf.keras.layers.Flatten()`（参考文档 [https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)）可以作为一个中间层来实现这一目的。
- en: Effective receptive field
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 有效感受野
- en: As we will detail in this section, the **effective receptive field** (**ERF**)
    of a neural network is an important notion in deep learning, as it may affect
    the ability of the network to cross-reference and combine distant elements in
    the input images.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本节中将详细说明的那样，神经网络的**有效感受野** (**ERF**) 是深度学习中的一个重要概念，因为它可能影响网络跨引用并结合输入图像中远距离元素的能力。
- en: Definitions
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义
- en: 'While the receptive field represents the local region of the previous layer
    that a neuron is connected to, the ERF defines *the region of the input image*
    (and not just of the previous layer), which affects the activation of a neuron
    for a given layer, as shown in *Figure 3.9*:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然感受野表示神经元与前一层连接的局部区域，但 ERF 定义了*输入图像的区域*（而不仅仅是前一层的区域），该区域影响给定层神经元的激活，如*图 3.9*所示：
- en: '![](img/0b54dcd5-94a2-42de-9d5a-6631a4214ad3.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0b54dcd5-94a2-42de-9d5a-6631a4214ad3.png)'
- en: 'Figure 3.9: Illustration of the receptive field of a layer with a simple network
    of two convolutional layers'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.9：具有两个卷积层简单网络的层的感受野示意图
- en: Note that it is common to find the term **receptive field **(**RF**) used in
    place of ERF, because RF can simply be referred to as the filter size or the window
    size of a layer. Some people also use RF or ERF to specifically define the input
    regions affecting each unit of the output layer (and not just any intermediary
    layer of a network).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，通常会将**感受野** (**RF**) 用作 ERF 的替代术语，因为 RF 可以简单地指代层的过滤器大小或窗口大小。一些人还使用 RF 或
    ERF 来特指影响输出层每个单元的输入区域（而不仅仅是网络的任何中间层）。
- en: Adding to the confusion, some researchers started calling ERFthe subset of the
    input region that is actually affecting a neuron. This was introduced by Wenjie
    Luo et al. in their paper, *Understanding the Effective Receptive Field in Deep
    Convolutional Neural Networks, *published in *Advances in Neural Information Processing
    Systems (2016)*. Their idea was that not all pixels *seen *by a neuron contribute
    *equally* to its response. We can intuitively accept that, for instance, pixels
    at the center of the RF will have more weight than peripheral ones. The information
    held by these central pixels can be propagated along multiple paths in the intermediary
    layers of the network to reach a given neuron, while pixels in the periphery of
    the receptive field are connected to this neuron through a single path. Therefore,
    the ERF, as defined by Luo et al., follows a pseudo-Gaussian distribution, unlike
    the uniform distribution of a traditional ERF.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 更加令人困惑的是，一些研究人员开始将 ERF 称为实际影响神经元的输入区域子集。这一观点由 Wenjie Luo 等人在他们的论文《Understanding
    the Effective Receptive Field in Deep Convolutional Neural Networks》中提出，该论文发表在《Advances
    in Neural Information Processing Systems (2016)》上。他们的观点是，并非所有被神经元“看到”的像素都对其响应有*相等*的贡献。我们可以直观地接受，例如，感受野中心的像素对神经元的响应权重会大于外围像素。这些中心像素携带的信息可以通过网络的中间层沿多条路径传播到达某个神经元，而感受野外围的像素则通过单一路径连接到该神经元。因此，Luo
    等人定义的 ERF 遵循伪高斯分布，而传统 ERF 是均匀分布的。
- en: The authors make an interesting parallel between this representation of the
    receptive field and the human **central fovea**, the region of the eye responsible
    for our sharp central vision. This detailed part of the vision is at the basis
    of many human activities. Half the optical nerves are linked to the fovea (despite
    its relatively small size), in the same way that central pixels in effective receptive
    fields are connected to a higher number of artificial neurons.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 作者将这种感受野的表示与人类的**中央黄斑**做了有趣的类比，中央黄斑是眼睛中负责清晰中央视觉的区域。视力的这一细节部分是许多人类活动的基础。尽管其相对较小，但一半的视神经与黄斑相连，就像有效感受野中的中央像素连接到更多的人工神经元一样。
- en: Formula
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 公式
- en: 'No matter what actual role its pixels are playing, the effective receptive
    field (named *R[i]* here) of the *i*^(th) layer of a CNN can be recursively computed
    as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 无论其像素实际扮演什么角色，卷积神经网络第*i*层的有效感受野（此处称为*R[i]*）可以通过递归方式计算如下：
- en: '![](img/f651c9be-9751-49c1-875c-8f4e891fab2f.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f651c9be-9751-49c1-875c-8f4e891fab2f.png)'
- en: 'In this equation, *k[i]* is the filter size of the layer, and *s[i]* is its
    stride (the last part of the equation thus represents the product of the strides
    for all the previous layers). As an example, we can apply this formula to the
    minimalist two-layer CNN presented in *Figure 3.9* to quantitatively evaluate
    the ERF of the second layer as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个方程中，*k[i]* 是该层的滤波器大小，*s[i]* 是它的步长（因此，方程的最后一部分表示所有前面层的步长的乘积）。例如，我们可以将此公式应用于*图
    3.9* 中展示的极简二层卷积神经网络（CNN），以定量评估第二层的有效感受野（ERF），计算方法如下：
- en: '![](img/5395488d-6ad1-4058-9589-62aac19a931c.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5395488d-6ad1-4058-9589-62aac19a931c.png)'
- en: This formula confirms that the ERF of a network is directly affected by the
    number of intermediary layers, their filter sizes, and the strides. Subsampling
    layers, such as pooling layers or layers with larger strides, greatly increase
    the ERF at the cost of lower feature resolution.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 该公式确认了网络的有效感受野（ERF）直接受到中间层数量、滤波器大小和步长的影响。子采样层（例如池化层或具有较大步长的层）会大大增加有效感受野，但会以牺牲特征分辨率为代价。
- en: Because of the local connectivity of CNNs, you should keep in mind how layers
    and their hyperparameters will affect the flow of visual information across the
    networks when defining their architecture.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 由于卷积神经网络（CNN）的局部连接性，在定义网络架构时，你应当牢记层与其超参数如何影响视觉信息在网络中的流动。
- en: CNNs with TensorFlow
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow实现卷积神经网络
- en: Most state-of-the-art computer vision algorithms are based on CNNs built with
    the three different types of layers we just introduced (that is, convolutional,
    pooling, and FC), with some tweaks and tricks that we will present in this book.
    In this section, we will build our first CNN and apply it to our digit recognition
    task.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数最先进的计算机视觉算法都基于卷积神经网络（CNN），这些网络使用我们刚刚介绍的三种不同类型的层（即卷积层、池化层和全连接层），并进行一些调整和技巧，这些内容我们将在本书中介绍。在这一部分，我们将实现第一个卷积神经网络，并将其应用于数字识别任务。
- en: Implementing our first CNN
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现我们的第一个卷积神经网络（CNN）
- en: 'For our first convolutional neural network, we will implement *LeNet-5*. First
    introduced by Yann Le Cun in 1995 (in *Learning algorithms for classification:
    A comparison on handwritten digit recognition*, *World Scientific Singapore*)
    and applied to the MNIST dataset, LeNet-5 may not be a recent network, but it
    is still commonly used to introduce people to CNNs. Indeed, with its seven layers,
    this network is straightforward to implement, while yielding interesting results.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '对于我们的第一个卷积神经网络，我们将实现*LeNet-5*。该网络最早由Yann Le Cun于1995年提出（在*Learning algorithms
    for classification: A comparison on handwritten digit recognition*, *World Scientific
    Singapore*一书中），并应用于MNIST数据集。LeNet-5可能不是一个新的网络，但它仍然是介绍卷积神经网络的常用模型。实际上，凭借其七个层次，这个网络非常容易实现，同时也能得到有趣的结果。'
- en: LeNet-5 architecture
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LeNet-5架构
- en: 'As shown in *Figure 3.10*, LeNet-5 is first composed of two blocks, each containing
    a convolutional layer (with the kernel size *k* = 5 and stride *s* = 1) followed
    by a max-pooling layer (with *k* = 2 and *s* = 2). In the first block, the input
    images are zero-padded by 2 on each side before convolution (that is, *p* = 2,
    hence an actual input size of *32 × 32*), and the convolution layer has six different
    filters (*N* = 6). There is no padding before the second convolution (*p* = 0),
    and its number of filters is set to 16 (*N* = 16). After the two blocks, three
    fully connected layers merge the features together and lead to the final class
    estimation (the 10 digit classes). Before the first dense layer, the *5 × 5 ×
    16* feature volume is flattened into a vector of 400 values. The complete architecture
    is represented in the following diagram:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 3.10*所示，LeNet-5首先由两个模块组成，每个模块包含一个卷积层（卷积核大小*k* = 5，步长*s* = 1），后接一个最大池化层（池化核*k*
    = 2，步长*s* = 2）。在第一个模块中，输入图像在进行卷积前在每一边填充2个像素（即，*p* = 2，因此实际输入大小为*32 × 32*），卷积层有六个不同的滤波器（*N*
    = 6）。第二个卷积层前没有填充（*p* = 0），它的滤波器数量设置为16（*N* = 16）。经过这两个模块后，三个全连接层将特征合并并最终输出分类结果（10个数字类别）。在第一个全连接层之前，*5
    × 5 × 16* 的特征体积被展平成一个400个值的向量。完整的网络架构如下图所示：
- en: '![](img/92f819f4-53b5-4b32-90e9-512d872806a1.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/92f819f4-53b5-4b32-90e9-512d872806a1.png)'
- en: 'Figure 3.10: LeNet-5 architecture (rendered with the NN-SVG tool by Alexander
    Lenail—http://alexlenail.me/NN-SVG)'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.10：LeNet-5 架构（使用 NN-SVG 工具渲染，由 Alexander Lenail 提供—http://alexlenail.me/NN-SVG）
- en: In the original implementation, each convolution layer and dense layer except
    the last one uses *tanh* as an activation function. However, *ReLU* is nowadays
    preferred to *tanh*, replacing it in most LeNet-5 implementations. For the last
    layer, the *softmax* function is applied. This function takes a vector of *N*
    values and returns a same-size vector, *y,* with its values normalized into a
    probability distribution. In other words, *softmax* normalizes a vector so that
    its values are all between 0 and 1, and their sum is exactly equal to 1\. Therefore,
    this function is commonly used at the end of neural networks applied to classification
    tasks in order to convert the network's predictions into per-class probability,
    as mentioned in [Chapter 1](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml), *Computer
    Vision and Neural Networks* (that is, given an output tensor, *y* = [*y[0], ...,
    y[i], ..., y[N]*], *y[i]* represents how likely it is that the sample belongs
    to class *i* according to the network).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始实现中，除了最后一层外，每个卷积层和全连接层都使用 *tanh* 作为激活函数。然而，*ReLU* 现在比 *tanh* 更为常用，已在大多数 LeNet-5
    实现中取代了 *tanh*。对于最后一层，应用 *softmax* 函数。该函数接受一个 *N* 值的向量，并返回一个相同大小的向量，*y*，其值被归一化为概率分布。换句话说，*softmax*
    会归一化一个向量，使其所有值都在 0 和 1 之间，并且它们的和恰好等于 1。因此，这个函数通常应用于分类任务的神经网络末尾，将网络的预测值转换为每个类别的概率值，如
    [第 1 章](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml)，*计算机视觉与神经网络* 中所述（即，给定输出张量，*y*
    = [*y[0], ..., y[i], ..., y[N]*]，*y[i]* 表示样本属于类别 *i* 的可能性）。
- en: The network's raw predictions (that is, before normalization) are commonly named
    **logits**. These unbounded values are usually converted into probabilities with
    the *softmax* function. This normalization process makes the prediction more *readable*
    (each value represents the confidence of the network for the corresponding class;
    refer to the belief scores mentioned in [Chapter 1](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml),
    *Computer Vision and Neural Networks*) and simplifies the computation of the training
    loss (that is, the categorical cross-entropy for classification tasks).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 网络的原始预测（即，未经过归一化的预测值）通常被称为 **logits**。这些无界的值通常通过 *softmax* 函数转换为概率值。这个归一化过程使得预测更加
    *易读*（每个值代表网络对对应类别的置信度；参见 [第 1 章](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml)，*计算机视觉与神经网络*），并简化了训练损失的计算（即，分类任务中的类别交叉熵）。
- en: TensorFlow and Keras implementations
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 和 Keras 实现
- en: 'We have all the tools in hand to implement this network. We suggest that you
    try them yourself, before checking the TensorFlow and Keras implementations provided.
    Reusing the notations and variables from [Chapter 2](c7c49010-458f-47ef-a538-96118f9cd892.xhtml),
    *TensorFlow Basics and Training a Model*, a LeNet-5 network using the Keras Sequential
    API would be as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们手头有了实现此网络的所有工具。在查看 TensorFlow 和 Keras 提供的实现之前，建议你自己尝试实现。使用 [第 2 章](c7c49010-458f-47ef-a538-96118f9cd892.xhtml)，*TensorFlow
    基础与模型训练* 中的符号和变量，使用 Keras Sequential API 实现的 LeNet-5 网络如下：
- en: '[PRE5]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The model is created by instantiating and adding the layers one by one, *sequentially*.
    As mentioned in [Chapter 2](c7c49010-458f-47ef-a538-96118f9cd892.xhtml), *TensorFlow
    Basics and Training a Model*, Keras also provides the **functional API**. This
    API makes it possible to define models in a more object-oriented approach (as
    shown in the following code), though it is also possible to directly instantiate `tf.keras.Model`
    with the layer operations (as illustrated in some of our Jupyter notebooks):'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型通过逐一实例化并添加层，*按顺序*创建。如同在 [第 2 章](c7c49010-458f-47ef-a538-96118f9cd892.xhtml)，*TensorFlow
    基础与模型训练* 中提到的，Keras 还提供了 **功能性 API**。该 API 使得用更面向对象的方式定义模型成为可能（如以下代码所示），尽管也可以直接通过层操作实例化
    `tf.keras.Model`（如在我们的某些 Jupyter 笔记本中所示）：
- en: '[PRE6]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Keras layers can indeed behave like functions that can be applied to input data
    and chained until the desired output is obtained. The functional API allows you
    to build more complex neural networks; for example, when one specific layer is
    reused several times inside the networks, or when layers have multiple inputs
    or outputs.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 层确实可以像函数一样，对输入数据进行处理并进行链式操作，直到获得所需的输出。功能性 API 允许你构建更复杂的神经网络；例如，当某一特定层在网络中被多次复用，或者当层具有多个输入或输出时。
- en: For those who have already experimented with PyTorch ([https://pytorch.org](https://pytorch.org)),
    another machine learning framework, this object-oriented approach to building
    neural networks may seem familiar, as it is favored there.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 对于已经尝试过PyTorch（[https://pytorch.org](https://pytorch.org)）的用户来说，这种面向对象的神经网络构建方法可能很熟悉，因为它在PyTorch中被广泛使用。
- en: Application to MNIST
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用到MNIST
- en: 'We can now compile and train our model for digit classification. Pursuing this
    with the Keras API (and reusing the MNIST data variables prepared in the last
    chapter), we instantiate the optimizer (a simple **stochastic gradient descent**
    (**SGD**) optimizer) and define the loss (the categorical cross-entropy) before
    launching the training, as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以编译并训练我们的数字分类模型。通过Keras API（并重用上一章中准备的MNIST数据变量），我们实例化优化器（一个简单的**随机梯度下降**（**SGD**）优化器），并在启动训练之前定义损失函数（类别交叉熵），如下所示：
- en: '[PRE7]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note the use of `sparse_categorical_crossentropy`, instead of `categorical_crossentropy`,
    to avoid one-hot encoding the labels. This loss was described in [Chapter 2](c7c49010-458f-47ef-a538-96118f9cd892.xhtml),
    *TensorFlow Basics and Training a Model*.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意使用 `sparse_categorical_crossentropy`，而非 `categorical_crossentropy`，以避免对标签进行独热编码。这个损失函数在[第二章](c7c49010-458f-47ef-a538-96118f9cd892.xhtml)中有描述，*TensorFlow基础与模型训练*。
- en: After ~60 epochs, we observe that our network's accuracy on the validation data
    reaches above ~98.5%! Compared to our previous attempts with non-convolutional
    networks, the relative error has been divided by *2* (from a ~3.0% to ~1.5% relative
    error), which is a significant improvement (given the high accuracy already).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 经过大约60个epoch后，我们观察到网络在验证数据上的准确率达到了超过98.5%！与我们之前使用非卷积网络的尝试相比，相对误差降低了*2*倍（从约3.0%的误差降至约1.5%），这是一个显著的改进（考虑到已经非常高的准确率）。
- en: In the following chapters, we will fully appreciate the analytical power of
    CNNs, applying them to increasingly complex visual tasks.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将充分理解卷积神经网络（CNN）的分析能力，并将其应用于越来越复杂的视觉任务。
- en: Refining the training process
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 精炼训练过程
- en: Network architectures are not the only things to have improved over the years.
    The way that networks are trained has also evolved, improving how reliably and
    quickly they can converge. In this section, we will tackle some of the shortcomings
    of the gradient descent algorithm we covered in [Chapter 1](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml),
    *Computer Vision and Neural Networks*, as well as some ways to avoid overfitting.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 网络架构不仅在这些年中得到了改进，网络的训练方式也在不断发展，提升了网络收敛的可靠性与速度。在本节中，我们将讨论在[第一章](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml)中介绍的梯度下降算法的一些不足，并探讨避免过拟合的一些方法。
- en: Modern network optimizers
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现代网络优化器
- en: Optimizing multidimensional functions, such as neural networks, is a complex
    task. The gradient descent solution we presented in the first chapter is an elegant
    solution, though it has some limitations that we will highlight in the following
    section. Thankfully, researchers have been developing new generations of optimization
    algorithms, which we will also discuss.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 优化多维函数（如神经网络）是一项复杂的任务。我们在第一章中介绍的梯度下降解法是一个优雅的解决方案，但它有一些局限性，接下来的部分将重点说明这些局限性。幸运的是，研究人员已经开发出新一代的优化算法，我们也将讨论这些算法。
- en: Gradient descent challenges
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度下降的挑战
- en: 'We previously presented how the parameters, *P*, of a neural network (that
    is, all the weight and bias parameters of its layers) can be iteratively updated
    during training to minimize the loss, *L*, backpropagating its gradient. If this
    gradient descent process could be summarized in a single equation, it would be
    the following:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前展示了神经网络的参数 *P*（即所有层的权重和偏置参数）如何在训练过程中通过反向传播梯度，逐步更新以最小化损失 *L*。如果把这个梯度下降过程用一个公式来总结，应该是下面这个样子：
- en: '![](img/d9fc0237-4e1b-4307-ac64-206590a62b1c.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d9fc0237-4e1b-4307-ac64-206590a62b1c.png)'
- en: '![](img/182e2239-4dff-46d3-a9db-a5e364c47e81.png) is the learning rate hyperparameter,
    which accentuates or attenuates how the network''s parameters are updated with
    regard to the gradient of the loss at every training iteration. While we mentioned
    that the learning rate value should be set with care, we did not explain how and
    why. The reasons for caution in this setup are threefold.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/182e2239-4dff-46d3-a9db-a5e364c47e81.png) 是学习率超参数，它强调或减弱网络参数在每次训练迭代时，根据损失函数的梯度更新的方式。虽然我们提到学习率值应谨慎设置，但并未解释为何及如何设置。对此需要谨慎的原因有三。'
- en: Training velocity and trade-off
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练速度与权衡
- en: 'We partially covered this point earlier. While setting a high learning rate
    may allow the trained network to converge faster (that is, in fewer iterations,
    as the parameters undergo larger updates each iteration), it also may prevent
    the network from finding a proper loss minimum. *Figure 3.11* is a famous illustration
    representing this trade-off between optimization over-cautiousness and haste:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前部分地讨论过这一点。虽然设置较高的学习率可能会让训练后的网络更快地收敛（即，在较少的迭代中，由于每次迭代时参数更新幅度较大），但它也可能会阻止网络找到合适的损失最小值。*图
    3.11* 是一个著名的插图，展示了优化时过于谨慎与急于求成之间的权衡：
- en: '![](img/6ddc34df-90e3-460b-a9af-8b410dc910d2.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6ddc34df-90e3-460b-a9af-8b410dc910d2.png)'
- en: 'Figure 3.11: Illustration of the learning rate trade-off'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.11：学习率权衡的插图
- en: From *Figure 3.11*, we can observe that an excessively low learning rate will
    slow down convergence (diagram A on the left), while an excessively high learning
    rate may cause it to overshoot the local minima (diagram B on the right).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图 3.11*中，我们可以观察到，过低的学习率会减慢收敛速度（左侧的图表A），而过高的学习率可能会导致其超过局部最小值（右侧的图表B）。
- en: Intuitively, there should be a better solution than trial and error to find
    the proper learning rate. For instance, a popular solution is to dynamically adjust
    the learning rate during training, starting with a larger value (for faster exploration
    of the loss domain at first) and decreasing it after every epoch (for more careful
    updating when getting closer to the minimum). This process is named **learning
    rate decay**. Manual decaying can still be found in many implementations, though,
    nowadays, TensorFlow offers more advanced learning rate schedulers and optimizers
    with adaptive learning rates.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，应该有比反复试验更好的方法来找到合适的学习率。例如，一种常见的解决方案是在训练过程中动态调整学习率，从较大的值开始（以便初期更快速地探索损失域），然后在每个周期后将其减小（以便在接近最小值时进行更谨慎的更新）。这一过程称为**学习率衰减**。手动衰减仍然可以在许多实现中找到，不过，现在
    TensorFlow 提供了更先进的学习率调度器和具有自适应学习率的优化器。
- en: Suboptimal local minima
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 次优局部最小值
- en: 'A common problem when optimizing complex (that is, *non-convex*) methods is
    getting stuck in **suboptimal local minima**. Indeed, gradient descent may lead
    us to a local minimum it cannot escape, even though a *better *minimum lies close
    by, as shown in *Figure 3.12*:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化复杂（即，*非凸*）方法时，一个常见的问题是陷入**次优局部最小值**。事实上，梯度下降法可能会将我们带到一个无法逃脱的局部最小值，即使*更好的*最小值就在旁边，如*图
    3.12*所示：
- en: '![](img/919aee27-8fb7-4891-bdf7-7494adf55da1.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/919aee27-8fb7-4891-bdf7-7494adf55da1.png)'
- en: 'Figure 3.12: Example of gradient descent ending up in a sub-optimal local minimum'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.12：梯度下降最终陷入次优局部最小值的示例
- en: Because of the random sampling of training samples (causing the gradients to
    often differ from one mini-batch to another), the SGD presented in [Chapter 1](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml),
    *Computer Vision and Neural Networks*, is already able to *jump out *of shallow
    local minima.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 由于训练样本的随机采样（导致每个小批次的梯度常常有所不同），[第 1 章](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml)中介绍的SGD（随机梯度下降），*计算机视觉与神经网络*，已经能够*跳出*浅层局部最小值。
- en: Note that the gradient descent process cannot ensure the convergence to a **global
    minimum** (that is, the convergence to the best set of parameters among all possible
    combinations). This would imply scanning the complete loss domain, to make sure
    that a given minimum is indeed the *best* (this would mean, for instance, computing
    the loss for all possible combinations of the parameters). Given the complexity
    of visual tasks and the large number of parameters needed to tackle them, data
    scientists are usually glad to just find a satisfying local minimum.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，梯度下降过程不能确保收敛到**全局最小值**（即，收敛到所有可能组合中的最佳参数集）。这将意味着扫描完整的损失域，以确保给定的最小值确实是*最好的*（这将意味着，例如，计算所有可能参数组合的损失）。考虑到视觉任务的复杂性和解决这些任务所需的庞大参数量，数据科学家通常更愿意找到一个令人满意的局部最小值。
- en: A single hyperparameter for heterogeneous parameters
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个适用于异质参数的超参数
- en: Finally, in traditional gradient descent, the same learning rate is used to
    update all the parameters of the network. However, not all these variables have
    the same sensitivity to changes, nor do they all impact the loss at every iteration.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在传统的梯度下降法中，相同的学习率用于更新网络中的所有参数。然而，并不是所有这些变量对变化的敏感度相同，也不是它们在每次迭代中都会对损失产生相同的影响。
- en: It may seem beneficial to have different learning rates (for instance, per subset
    of parameters) to update crucial parameters more carefully, and to more boldly update
    parameters that are not contributing often enough to the network's predictions.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会觉得使用不同的学习率（例如，针对参数的子集）更新关键参数，以便更加精细地更新这些参数，同时大胆更新那些对网络预测贡献不足的参数，这样做是有利的。
- en: Advanced optimizers
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级优化器
- en: Some of the intuitions we presented in the previous paragraphs have been properly
    studied and formalized by researchers, leading to new optimization algorithms
    based on SGD. We will now list the most common of these optimizers, detailing
    their contributions and how to use them with TensorFlow.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前述段落中提出的一些直觉已经被研究人员进行了适当的研究和形式化，从而导致了基于SGD的新优化算法。现在我们将列出这些优化器中最常见的几种，详细介绍它们的贡献以及如何在TensorFlow中使用它们。
- en: Momentum algorithms
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动量算法
- en: 'First suggested by Boris Polyak (in *Some methods of speeding up the convergence
    of iteration methods*, Elsevier, 1964), the momentum algorithm is based on SGD
    and inspired by the physics notion of **momentum**—as long as an object is moving
    downhill, its speed will increase with each step. Applied to gradient descent,
    the idea is to take previous parameter updates, *v[i-1]*, into account, adding
    them to the new update terms, *v[i]*,as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 动量算法最早由Boris Polyak提出（见*某些加速迭代方法收敛的方法*，Elsevier，1964年），该算法基于SGD并受到物理学中**动量**概念的启发——只要一个物体在下坡，它的速度将在每一步中加速。应用于梯度下降时，理念是考虑到之前的参数更新，*v[i-1]*，并将其加入到新的更新项中，*v[i]*，如下所示：
- en: '![](img/c055ee55-d604-4526-93ce-5678c5603373.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c055ee55-d604-4526-93ce-5678c5603373.png)'
- en: Here, ![](img/fceb4a4e-5c66-4e5b-93ec-931110036eb0.png) (*mu*) is the momentum
    weighing (the value between 0 and 1), defining the fraction of the previous updates
    to apply. If the current and previous steps have the same direction, their magnitudes
    will add up, accelerating the SGD in this relevant direction. If they have different
    directions, the momentum will dampen these oscillations.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，![](img/fceb4a4e-5c66-4e5b-93ec-931110036eb0.png)（*mu*）是动量权重（介于0和1之间的值），定义了应用前次更新的比例。如果当前步骤和前一步的方向相同，它们的幅度将会叠加，导致SGD在该方向上加速。如果方向不同，动量将抑制这些振荡。
- en: 'In `tf.optimizers` (also accessible as `tf.keras.optimizers`), momentum is
    defined as an optional parameter of SGD (refer to the documentation at [https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD))
    as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在`tf.optimizers`（也可以通过`tf.keras.optimizers`访问）中，动量被定义为SGD的一个可选参数（参见[https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD)）如下所示：
- en: '[PRE8]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This optimizer accepts a `decay` parameter, fixing the learning rate decay over
    each update (refer to the previous paragraphs).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 该优化器接受一个`decay`参数，用于修正每次更新时的学习率衰减（参见前述段落）。
- en: 'This optimizer instance can then be directly passed as a parameter to `model.fit()`
    when launching the training through the Keras API. For more complex training scenarios
    (for instance, when training interdependent networks), the optimizer can also
    be called, providing it with the loss gradients and the model''s trainable parameters.
    The following is an example of a simple training step implemented manually:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以直接将此优化器实例作为参数传递给`model.fit()`，通过Keras API启动训练。对于更复杂的训练场景（例如，当训练互依网络时），优化器也可以被调用，并提供损失梯度和模型的可训练参数。以下是一个简单的训练步骤示例，手动实现：
- en: '[PRE9]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`tf.optimizers.SGD` has one interesting Boolean parameter—to switch from the
    common momentum method to Nesterov''s algorithm. Indeed, a major problem of the
    former method is that by the time the network gets really close to its loss minimum,
    the accumulated momentum will usually be quite high, which may cause the method
    to miss or oscillate around the target minimum.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`tf.optimizers.SGD`有一个有趣的布尔参数——用于将常见的动量方法切换到Nesterov算法。实际上，前一种方法的一个主要问题是，当网络非常接近损失最小值时，积累的动量通常会非常高，这可能导致方法错过或在目标最小值周围振荡。'
- en: 'The **Nesterov accelerated gradient** (**NAG** or **Nesterov momentum**) offers
    a solution to this problem (a related course is *Introductory Lectures on Convex
    Programming Volume I: Basic course, *by Yurii Nesterov, *Springer Science and
    Business Media*). Back in the 1980s, Yurii Nesterov''s idea was to give the optimizer
    the possibility to have a look at the slope ahead so that it *knows *it should
    slow down if the slope starts going up. More formally, Nesterov suggested directly
    reusing the past term *v[i-1]* to estimate which values, *P[i+1]*, the parameters
    would take if we keep following this direction. The gradient is then evaluated
    with respect to those approximate future parameters, and it is used to finally
    compute the actual update as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**Nesterov 加速梯度**（**NAG** 或 **Nesterov 动量**）为这个问题提供了解决方案（相关课程为 *凸编程基础讲座第一卷：基础课程*，由
    Yurii Nesterov 编写，*Springer Science and Business Media* 出版）。早在 1980 年代，Yurii Nesterov
    的想法是让优化器有机会提前查看坡度，以便 *知道* 如果坡度开始上升，它应该放慢速度。更正式地说，Nesterov 建议直接重用过去的项 *v[i-1]*
    来估算如果我们继续沿此方向前进，参数 *P[i+1]* 会取什么值。然后，梯度将基于这些近似的未来参数进行评估，并最终用于计算实际的更新，公式如下：'
- en: '![](img/ae9b495d-7747-4cdb-bbc6-8fcb195b9509.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ae9b495d-7747-4cdb-bbc6-8fcb195b9509.png)'
- en: This version of the momentum optimizer (where the loss is derived with respect to
    the parameters' values updated according to the previous steps) is more adaptable
    to gradient changes, and can significantly speed up the gradient descent process.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这种动量优化器版本（其中损失是基于参数的值计算的，更新值根据之前的步骤进行调整）对梯度变化更具适应性，可以显著加快梯度下降的过程。
- en: The Ada family
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Ada 家族
- en: '**Adagrad**, **Adadelta**, and **Adam** are several iterations and variations
    around the idea of adapting the learning rate depending on the sensitivity and/or
    activation frequency of each neuron.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**Adagrad**、**Adadelta** 和 **Adam** 是围绕根据每个神经元的敏感性和/或激活频率调整学习率的思路的几个迭代和变体。'
- en: Developed first by John Duchi et al. (in *Adaptive Subgradient Methods for Online
    Learning and Stochastic Optimization*, Journal of Machine Learning Research, 2011),
    the *Adagrad* optimizer (for *adaptive gradients*) uses a neat formula (which
    we won't expand on here, though we invite you to search for it) to automatically
    decrease the learning rate more quickly for parameters linked to commonly found
    features, and more slowly for infrequent ones. In other words, as presented in
    the Keras documentation, *the more updates a parameter receives, the smaller the
    updates *(refer to the documentation at [https://keras.io/optimizers/](https://keras.io/optimizers/)).
    This optimization algorithm not only removes the need to manually adapt/decay
    the learning rate, but it also makes the SGD process more stable, especially for
    datasets with sparse representations.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '*Adagrad* 优化器（用于 *自适应梯度*）最初由 John Duchi 等人在《*在线学习和随机优化的自适应子梯度方法*》（《机器学习研究杂志》，2011）中提出，使用一个精巧的公式（我们在这里不展开，欢迎你自行查阅）来自动更快地减少与常见特征相关的参数的学习率，对于不常见的特征则减小得较慢。换句话说，正如
    Keras 文档中所描述，*一个参数接受的更新次数越多，更新的幅度越小*（可以参考 [https://keras.io/optimizers/](https://keras.io/optimizers/)
    的文档）。这种优化算法不仅消除了手动调整/衰减学习率的需求，还使得 SGD 过程更加稳定，特别是在具有稀疏表示的数据集上。'
- en: 'Introducing *Adadelta* in 2013, Matthew D. Zeiler et al. (in *ADADELTA: An
    Adaptive Learning Rate Method*, *arXiv preprint*) offered a solution to one problem
    inherent to *Adagrad.* As it keeps decaying the learning rate every iteration,
    at some point, the learning rate becomes too small and the network just cannot
    learn anymore (except maybe for infrequent parameters). *Adadelta* avoids this
    problem by keeping in check the factors used to divide the learning rate for each
    parameter.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '2013 年，Matthew D. Zeiler 等人在《*ADADELTA: 一种自适应学习率方法*》（*arXiv 预印本*）中介绍了 *Adadelta*，为
    *Adagrad* 固有的问题提供了解决方案。由于 *Adagrad* 在每次迭代中都会衰减学习率，因此到某个时刻，学习率变得过小，网络将无法继续学习（除了可能一些不常见的参数）。*Adadelta*
    通过控制每个参数用于除以学习率的因子，避免了这个问题。'
- en: '**RMSprop** by Geoffrey Hinton is another well-known optimizer (introduced
    in his Coursera course, <q>Lecture 6.5-rmsprop: Divide the gradient by a running
    average of its recent magnitude</q>). Associated with, and quite similar to *Adadelta*,
    *RMSprop* was also developed to correct *Adagrad*''s flaw.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '**RMSprop** 由 Geoffrey Hinton 提出，是另一个著名的优化器（在他的 Coursera 课程中介绍，<q>Lecture 6.5-rmsprop:
    将梯度除以其近期幅度的滑动平均值</q>）。与 *Adadelta* 密切相关且相似，**RMSprop** 也被开发用来修正 *Adagrad* 的缺陷。'
- en: '**Adam** (for **adaptive moment estimation**) is another iteration by Diederik
    P. Kingma et al. (in *Adam: A method for stochastic optimization*, ICLR, 2015).
    In addition to storing previous update terms, *v[i]*, to adapt the learning rate
    for each parameter, *Adam* also keeps track of the past momentum values. It is,
    therefore, often identified as a mix between *Adadelta* and *momentum*. Similarly,
    **Nadam** is an optimizer inheriting from *Adadelta* and *NAG*.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '**Adam**（自适应矩估计法）是Diederik P. Kingma等人提出的另一种优化方法（见*Adam: A method for stochastic
    optimization*，ICLR，2015）。除了存储先前的更新项 *v[i]* 来调整每个参数的学习率外，*Adam* 还会跟踪过去的动量值。因此，它通常被认为是*Adadelta*和*momentum*的混合体。同样，**Nadam**是继承自*Adadelta*和*NAG*的优化器。'
- en: All these various optimizers are available in the `tf.optimizers` package (refer
    to the documentation at [https://www.tensorflow.org/api_docs/python/tf/train/](https://www.tensorflow.org/api_docs/python/tf/train/)).
    Note that there is no consensus regarding which of these optimizers may be the
    best. *Adam* is, however, preferred by many computer vision professionals for
    its effectiveness on scarce data. *RMSprop* is also often considered a good choice
    for recurrent neural networks (introduced in [Chapter 8](97884989-bb57-4611-8c66-ebe8ab387965.xhtml),
    *Video and Recurrent Neural Networks*).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些不同的优化器都可以在`tf.optimizers`包中找到（请参考[https://www.tensorflow.org/api_docs/python/tf/train/](https://www.tensorflow.org/api_docs/python/tf/train/)中的文档）。需要注意的是，目前没有共识认为哪个优化器是最好的。然而，*Adam*
    被许多计算机视觉专业人士所青睐，因为它在数据稀缺的情况下表现有效。*RMSprop* 也常被认为是递归神经网络的一个不错选择（如在[第8章](97884989-bb57-4611-8c66-ebe8ab387965.xhtml)，*视频和递归神经网络*中介绍的）。
- en: A Jupyter notebook demonstrating how to use these various optimizers is provided
    in the Git repository. Each optimizer is also applied to the training of our *LeNet-5*
    for MNIST classification, in order to compare their convergence.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 一个展示如何使用这些不同优化器的Jupyter notebook已提供在Git仓库中。每个优化器还应用于我们用于MNIST分类的*LeNet-5*的训练，以便比较它们的收敛情况。
- en: Regularization methods
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 正则化方法
- en: Efficiently teaching neural networks so that they minimize the loss over training
    data is, however, not enough. We also want these networks to perform well once
    applied to new images. We do not want them to *overfit* the training set (as mentioned
    in [Chapter 1](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml), *Computer Vision and
    Neural Networks*). For our networks to generalize well, we mentioned that rich
    training sets (with enough variability to cover possible testing scenarios) and
    well-defined architectures (neither too shallow to avoid underfitting, nor too
    complex to prevent overfitting) are key. However, other methods have been developed
    over the years for **regularization**; for example, the process of refining the
    optimization phase to avoid overfitting.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅仅高效地训练神经网络，使其在训练数据上最小化损失，还不够。我们还希望这些网络在应用于新图像时表现良好。我们不希望它们*过拟合*训练集（如在[第1章](3d1c879b-b6fa-4eee-b578-60b57a77ff33.xhtml)，*计算机视觉与神经网络*中提到的那样）。为了让我们的网络具备良好的泛化能力，我们提到过，丰富的训练集（足够的变异性来覆盖可能的测试场景）和明确定义的架构（既不浅以避免欠拟合，也不复杂以防止过拟合）是关键。然而，随着时间的推移，已经开发了其他正则化方法；例如，优化阶段的精细调整过程，用以避免过拟合。
- en: Early stopping
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 早期停止
- en: Neural networks start overfitting when they iterate too many times over the
    same small set of training samples. Therefore, a straightforward solution to prevent
    this problem is to figure out the number of training epochs a model needs. The
    number should be low enough to stop before the network starts overfitting, but
    still high enough for the network to learn all it can from this training set.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 当神经网络在同一小批训练样本上迭代过多时，它们就会开始过拟合。因此，防止这种问题的一个简单解决方案是确定模型需要的训练周期数。这个数字应该足够低，以便在网络开始过拟合之前停止，但又足够高，让网络从这个训练集学到它能学到的一切。
- en: '**Cross-validation** is the key here to evaluate when training should be stopped.
    Providing a validation dataset to our optimizer, the latter can measure the performance
    of the model on images the network has not been directly optimized for. By *validating*
    the network, for instance, after each epoch, we can measure whether the training
    should continue (that is, when the validation accuracy appears to be still increasing)
    or be stopped (that is, when the validation accuracy stagnates or drops). The
    latter is called **early stopping**.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '**交叉验证** 在这里是评估何时停止训练的关键。通过为优化器提供验证数据集，优化器可以测量模型在网络未直接优化过的图像上的表现。通过对网络进行*验证*，例如在每个训练周期后，我们可以判断训练是否应继续（即，当验证准确率仍在上升时）或应停止（即，当验证准确率停滞或下降时）。后一种情况称为**早停**。'
- en: In practice, we usually monitor and plot the validation loss and metrics as
    a function of the training iterations, and we restore the saved weights at the
    optima (hence the importance of regularly saving the network during training).
    This monitoring, early stopping, and restoration of optimum weights can be automatically
    covered by one of the optional Keras callbacks (`tf.keras.callbacks.EarlyStopping`),
    as already showcased in our previous training.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们通常会监控并绘制验证损失和指标与训练迭代次数的关系，并在最优点恢复保存的权重（因此，在训练过程中定期保存网络非常重要）。这种监控、早停和最优权重恢复可以通过一个可选的
    Keras 回调函数（`tf.keras.callbacks.EarlyStopping`）自动完成，正如我们之前的训练中展示的那样。
- en: L1 and L2 regularization
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: L1 和 L2 正则化
- en: Another way to prevent overfitting is to modify the loss in order to include
    regularization as one of the training objectives. The L1 and L2 regularizers are
    prime examples of this.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种防止过拟合的方法是修改损失函数，将正则化作为训练目标之一。L1 和 L2 正则化就是这种方法的典型例子。
- en: Principles
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原则
- en: 'In machine learning, a **regularization term**, *R(P)*, computed over the parameters,
    *P*, of the method, *f*, to optimize (for instance, a neural network) can be added
    to the loss function, *L*, before training, as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，可以在训练前将一个计算出来的**正则化项** *R(P)*（它是方法 *f* 的参数 *P*）添加到损失函数 *L* 中进行优化（例如，一个神经网络），如下所示：
- en: '![](img/70fe393a-72e8-46d1-8fba-1b25c99d17ca.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![](img/70fe393a-72e8-46d1-8fba-1b25c99d17ca.png)'
- en: Here, ![](img/75a1c0fb-e5e8-42ef-8f01-90efa6fb04ad.png) is a factor controlling
    the strength of the regularization (typically, to scale down the amplitude of
    the regularization term compared to the main loss), and *y = f(x, P) *is the output
    of the method, *f*, parametrized by *P* for the input data, *x*. By adding this
    term, *R(P)*, to the loss, we force the network not only to optimize its task,
    but to optimize it while *constraining* the values its parameters can take.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/75a1c0fb-e5e8-42ef-8f01-90efa6fb04ad.png) 是控制正则化强度的因子（通常，用来缩小正则化项相对于主损失的幅度），而
    *y = f(x, P)* 是该方法的输出，*f*，通过输入数据 *x* 的参数 *P* 来参数化。通过将这个项 *R(P)* 添加到损失中，我们迫使网络不仅优化其任务，而且在*约束*其参数可能取值的同时进行优化。
- en: 'For L1 and L2 regularization, the respective terms are as follows:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: L1 和 L2 正则化的相应项如下：
- en: '![](img/d0e89b2e-ff40-46c1-904f-ae6fa01595d6.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d0e89b2e-ff40-46c1-904f-ae6fa01595d6.png)'
- en: '**L2 regularization** (also called **ridge regularization**) thus compels the
    network to minimize the sum of its squared parameter values. While this regularization
    leads to the decay of all parameter values over the optimization process, it more
    strongly punishes large parameters due to the squared term. Therefore, L2 regularization
    encourages the network *to keep its parameter values low and thus more homogeneously
    distributed*. It prevents the network from developing a small set of parameters
    with large values influencing its predictions (as it may prevent the network from
    generalizing).'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '**L2 正则化**（也称为**岭正则化**）因此迫使网络最小化其参数值的平方和。虽然这种正则化导致所有参数值在优化过程中逐渐衰减，但由于平方项的存在，它对大参数的惩罚更为强烈。因此，L2
    正则化鼓励网络*保持其参数值较低，从而更加均匀地分布*。它防止网络发展出一组具有大值的参数，这些大值会影响其预测（因为这可能会阻碍网络的泛化能力）。'
- en: On the other hand, the **L1 regularizer** (also called the **LASSO** (**least
    absolute shrinkage and selection operator**)**regularizer**, first introduced
    in *Linear Inversion of Band-Limited Reflection Seismograms, *by *Fadil Santosa
    and William Symes, SIAM, 1986*) compels the network to minimize the sum of its
    absolute parameter values. The difference between this and L2 regularization may
    seem symbolic at first glance, but their properties are actually quite different.
    As larger weights are not penalized by squaring, L1 regularization instead makes
    the network shrink the parameters linked to less important features toward zero.
    Therefore, it prevents overfitting by forcing the network to ignore less meaningful
    features (for instance, tied to dataset noise). In other words, L1 regularization
    forces the network to adopt sparse parameters; that is, to rely on a smaller set
    of non-null parameters. This can be advantageous if the footprint of the network
    should be minimized (for mobile applications, for example).
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**L1 正则化器**（也叫**LASSO**（**最小绝对收缩和选择算子**）正则化器，最早由*Fadil Santosa* 和 *William
    Symes*在 *《带限反射地震图的线性反演》* 中提出，SIAM，1986）迫使网络最小化其参数值的绝对值之和。乍一看，L1正则化和L2正则化的区别可能显得微不足道，但它们的特性实际上是非常不同的。由于较大的权重不会因平方而受到惩罚，L1正则化会迫使网络将与不重要特征相关联的参数缩小到零。因此，它通过强制网络忽略较不重要的特征（例如与数据集噪声相关的特征）来防止过拟合。换句话说，L1正则化强迫网络采用稀疏参数，即依赖于一小部分非零参数。如果网络的内存占用需要最小化（例如移动应用程序），这一点尤其有优势。
- en: TensorFlow and Keras implementations
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow和Keras实现
- en: To implement those techniques, we should define the regularization loss and
    attach this function to every target layer. At each training iteration, these
    additional losses should be computed over the layers' parameters, and summed with
    the main task-specific loss (for instance, the cross-entropy over the network's
    predictions) so that they can all be backpropagated together by the optimizer.
    Thankfully, TensorFlow 2 provides several tools to simplify this process.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这些技术，我们应该定义正则化损失并将此函数附加到每个目标层。在每次训练迭代中，这些附加损失应该基于层的参数计算，并与主要任务特定的损失（例如网络预测的交叉熵）求和，以便它们可以通过优化器一起反向传播。幸运的是，TensorFlow
    2提供了多个工具来简化这一过程。
- en: 'Additional losses can be attached to `tf.keras.layers.Layer` and `tf.keras.Model`
    instances through their `.add_loss(losses, ...)` method, with the `losses` tensors
    or zero-argument callables returning the loss values. Once properly added to a
    layer (see the following code), these losses will be computed every time the layer/model
    is called. All the losses attached to a `Layer` or `Model` instance, as well as
    the losses attached to its sublayers, will be computed, and the list of loss values
    will be returned when calling the `.losses` property. To better understand this
    concept, we''ll extend the simple convolution layer implemented previously to
    add optional regularization to its parameters:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过`tf.keras.layers.Layer`和`tf.keras.Model`实例的`.add_loss(losses, ...)`方法将附加的损失添加到网络中，其中`losses`是返回损失值的张量或无参可调用对象。一旦正确地添加到层（参见以下代码），这些损失将在每次调用层/模型时计算。附加到`Layer`或`Model`实例的所有损失，以及附加到其子层的损失，将会计算，并且在调用`.losses`属性时返回损失值列表。为了更好地理解这一概念，我们将扩展之前实现的简单卷积层，向其参数添加可选的正则化：
- en: '[PRE10]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Regularization losses should guide the models toward learning more robust features.
    They should not take precedence over the main training loss, which is preparing
    the model for its task. Therefore, we should be careful not to put too much weight
    on the regularization losses. Their values are usually dampened by a coefficient
    between 0 and 1 (refer to `coef` in our `l2_reg()` loss function). This weighing
    is especially important, for instance, when the main loss is averaged (for example,
    MSE and MAE). So that the regularization losses do not outweigh it, we should
    either make sure that they are also averaged over the parameters' dimensions,
    or we should decrease their coefficient further.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化损失应引导模型学习更强健的特征。它们不应优先于主要的训练损失，后者是为了让模型适应其任务。因此，我们应该小心不要过度强调正则化损失。正则化损失的值通常会通过一个介于0和1之间的系数进行衰减（参见我们`l2_reg()`损失函数中的`coef`）。这种加权尤其重要，例如，当主要损失是平均值时（例如，MSE和MAE）。为了使正则化损失不至于过大，我们应该确保它们也在参数维度上平均，或者进一步减小它们的系数。
- en: 'At each training iteration of a network composed of such layers, the regularization
    losses can be computed, listed, and added to the main loss as follows:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次训练迭代中，对于由这些层组成的网络，正则化损失可以被计算、列出并加入到主损失中，具体如下：
- en: '[PRE11]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We introduced `.add_loss()`, as this method can greatly simplify the process
    of adding layer-specific losses to custom networks. However, when it comes to
    adding regularization losses, TensorFlow provides a more straightforward solution.
    We can simply pass the regularization loss function as a parameter of the `.add_weight()` method
    (also named `.add_variable()`) used to create and attach variables to a `Layer`
    instance. For example, the kernels'' variable could be directly created with the
    regularization loss as follows: `self.kernels = self.add_weight(..., regularizer=self.kernel_regularizer)`.
    At each training iteration, the resulting regularization loss values can still
    be obtained through the layer or model''s `.losses` property.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们引入了`.add_loss()`方法，因为该方法可以极大地简化将特定层损失添加到自定义网络中的过程。然而，当涉及到添加正则化损失时，TensorFlow提供了一个更直接的解决方案。我们只需将正则化损失函数作为`.add_weight()`方法（也称为`.add_variable()`）的参数，该方法用于创建并附加变量到`Layer`实例。例如，卷积核的变量可以通过以下方式直接创建，并附加正则化损失：`self.kernels
    = self.add_weight(..., regularizer=self.kernel_regularizer)`。在每次训练迭代中，得到的正则化损失值仍然可以通过该层或模型的`.losses`属性获得。
- en: 'When using predefined Keras layers, we do not need to bother extending the
    classes to add regularization terms. These layers can receive regularizers for
    their variables as parameters. Keras even explicitly defines some regularizer
    callables in its `tf.keras.regularizers` module. Finally, when using Keras training
    operations (such as `model.fit(...)`), Keras automatically takes into account
    additional `model.losses` (that is, the regularization terms and other possible
    layer-specific losses), as follows:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用预定义的Keras层时，我们无需扩展类来添加正则化项。这些层可以通过参数接收正则化器。Keras甚至在其`tf.keras.regularizers`模块中显式定义了一些正则化器可调用函数。最后，在使用Keras训练操作（如`model.fit(...)`）时，Keras会自动考虑额外的`model.losses`（即正则化项和其他可能的特定层损失），如下所示：
- en: '[PRE12]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Dropout
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Dropout
- en: So far, the regularization methods we have covered are affecting the way networks
    are trained. Other solutions are affecting their architecture. **Dropout** is
    one such method and one of the most popular regularization tricks.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们介绍的正则化方法主要影响网络的训练方式。其他一些解决方案则影响网络的架构。**Dropout**（丢弃法）就是其中一种方法，也是最流行的正则化技巧之一。
- en: Definition
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义
- en: 'Introduced in *Dropout: A Simple Way to Prevent Neural Networks from Overfitting *(*JMLR,
    2014*) by Hinton and his team (who made numerous contributions to deep learning),
    *dropout* consists of randomly disconnecting (*dropping out*) some neurons of
    target layers at every training iteration. This method thus takes a hyperparameter
    ratio, ![](img/9860fd1e-4b64-4956-b2f4-e190e386e1d9.png), which represents the
    probability that neurons are being turned off at each training step (usually set
    between 0.1 and 0.5). The concept is illustrated in *Figure 3.13*:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '在*Dropout: A Simple Way to Prevent Neural Networks from Overfitting*（*JMLR,
    2014*）中，Hinton及其团队（他们为深度学习做出了许多贡献）首次引入了*dropout*方法，*dropout*通过在每次训练迭代中随机断开目标层的一些神经元（即“丢弃”）来实现。这种方法因此需要一个超参数比率，
    ![](img/9860fd1e-4b64-4956-b2f4-e190e386e1d9.png)，该比率表示每次训练步骤中神经元被关闭的概率（通常设定在0.1到0.5之间）。该概念在*图3.13*中有所展示：'
- en: '![](img/3c40f227-304e-4293-a27c-15d56a959f64.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c40f227-304e-4293-a27c-15d56a959f64.png)'
- en: 'Figure 3.13: Dropout represented on a simple neural network (note that dropped-out
    neurons of layers are randomly chosen in each iteration)'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13：在简单神经网络中表示的Dropout（注意，每次迭代时，丢弃的层神经元是随机选择的）
- en: By artificially and randomly impairing the network, this method forces the learning
    of robust and concurrent features. For instance, as dropout may deactivate the
    neurons responsible for a key feature, the network has to figure out other significant
    features in order to reach the same prediction. This has the effect of developing
    redundant representations of data for prediction.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 通过人为且随机地削弱网络，这种方法迫使网络学习到更加鲁棒且并行的特征。例如，由于dropout可能会停用负责某个关键特征的神经元，网络必须找到其他重要特征来达到相同的预测结果。这样就能促使网络发展出冗余的特征表示，用于预测。
- en: Dropout is also often explained as a cheap solution to simultaneously train
    a *multitude* of models (the randomly impaired versions of the original network).
    During the testing phase, dropout is not applied to the network, so the network's
    predictions can be seen as the combination of the results that the partial models
    would have provided. Therefore, this information averaging prevents the network
    from overfitting.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 丢弃法也常被解释为一种廉价的解决方案，可以同时训练*多个*模型（原始网络的随机失效版本）。在测试阶段，丢弃法不会应用于网络，因此网络的预测可以看作是各个部分模型结果的结合。因此，这种信息平均可以防止网络过拟合。
- en: TensorFlow and Keras methods
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow和Keras方法
- en: Dropout can be called as a function through `tf.nn.dropout(x, rate, ...)` (refer
    to the documentation at [https://www.tensorflow.org/api_docs/python/tf/nn/dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout))
    to directly obtain a tensor with values randomly dropped, or as a layer through
    `tf.keras.layers.Dropout()` (refer to the documentation at [https://www.tensorflow.org/api_docs/python/tf/layers/dropout](https://www.tensorflow.org/api_docs/python/tf/layers/dropout)),
    which can be added to neural models. By default, `tf.keras.layers.Dropout()` is
    only applied during training (when the layer/model is called with the `training=True`
    parameter) and is deactivated otherwise (forwarding the values without any alteration).
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 丢弃法可以通过函数`tf.nn.dropout(x, rate, ...)`调用（请参阅[https://www.tensorflow.org/api_docs/python/tf/nn/dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)）直接获得一个值随机丢弃的张量，或者通过`tf.keras.layers.Dropout()`作为层调用（请参阅[https://www.tensorflow.org/api_docs/python/tf/layers/dropout](https://www.tensorflow.org/api_docs/python/tf/layers/dropout)），可以将其添加到神经网络模型中。默认情况下，`tf.keras.layers.Dropout()`仅在训练时应用（当层/模型被调用时，带有`training=True`参数），否则会被禁用（转发未经修改的值）。
- en: 'Dropout layers should be added directly after layers we want to prevent from
    overfitting (as dropout layers will randomly drop values returned by their preceding
    layers, forcing them to adapt). For instance, you can apply dropout (for example,
    with a ratio, ![](img/0d8d3c23-bc8e-4837-b207-6ab366cf4c6d.png)) to a fully connected
    layer in Keras, as shown in the following code block:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 丢弃层应该直接添加到我们希望防止过拟合的层后面（因为丢弃层会随机丢弃前一层返回的值，迫使其进行适应）。例如，你可以在Keras中对全连接层应用丢弃法（例如，使用一个比率，![](img/0d8d3c23-bc8e-4837-b207-6ab366cf4c6d.png)），如下面的代码块所示：
- en: '[PRE13]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Batch normalization
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 批量归一化
- en: Though our list is not exhaustive, we will introduce a final common regularization
    method, which is also directly integrated into the networks' architectures.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们的列表并不详尽，但我们将介绍一种常见的正则化方法，这种方法也被直接集成到网络的架构中。
- en: Definition
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义
- en: 'Like dropout, **batch normalization** (proposed by Sergey Ioffe and Christian
    Szegedy in *Batch Normalization: Accelerating Deep Network Training by Reducing
    Internal Covariate Shift*, *JMLR, 2015*) is an operation that can be inserted
    into neural networks and affects their training. This operation takes the batched
    results of the preceding layers and *normalizes* them; that is, it subtracts the
    batch mean and divides it by the batch standard deviation.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于丢弃法，**批量归一化**（由Sergey Ioffe和Christian Szegedy在《批量归一化：通过减少内部协方差偏移加速深度网络训练》一文中提出，*JMLR,
    2015*）是一种可以插入神经网络并影响其训练的操作。该操作获取前一层的批量结果并进行*归一化*处理；即，减去批量均值并除以批量标准差。
- en: Since batches are randomly sampled in SGD (and thus are rarely the same twice),
    this means that the data will almost never be normalized the same way. Therefore,
    the network has to learn how to deal with these data fluctuations, making it more
    robust and generic. Furthermore, this normalization step concomitantly improves
    the way the gradients flow through the network, facilitating the SGD process.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在SGD中批次是随机采样的（因此很少有两个批次完全相同），这意味着数据几乎永远不会以相同的方式进行归一化。因此，网络必须学习如何处理这些数据波动，使其变得更加健壮和通用。此外，这一步归一化同时改善了梯度在网络中的流动方式，促进了SGD过程。
- en: The behavior of batch normalization layers is actually a bit more complex than
    what we have succinctly presented. These layers have a couple of trainable parameters
    that are used in denormalization operations, so that the next layer does not just
    try to learn how to undo the batch normalization.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 批量归一化层的行为实际上比我们简洁地呈现的要复杂。这些层有一些可训练的参数，用于去归一化操作，以便下一层不会仅仅试图学习如何撤销批量归一化。
- en: TensorFlow and Keras methods
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow和Keras方法
- en: Similar to dropout, batch normalization is available in TensorFlow both as a
    function, `tf.nn.batch_normalization()` (refer to the documentation at [https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization](https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization))
    and as a layer, `tf.keras.layers.BatchNormalization()` (refer to the documentation
    at [https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization)),
    making it straightforward to include this regularization tool inside networks.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 dropout，批量归一化在 TensorFlow 中既可以作为函数 `tf.nn.batch_normalization()` 使用（请参阅[https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization](https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization)中的文档），也可以作为层
    `tf.keras.layers.BatchNormalization()` 使用（请参阅[https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization)中的文档），这使得将这一正则化工具轻松地集成到网络中变得更加简单。
- en: All these various optimization techniques are precious tools for deep learning,
    especially when training CNNs on imbalanced or scarce datasets, which is often
    the case for custom applications (as elaborated on in [Chapter 7](337ec077-c215-4782-b56c-beae4d94d718.xhtml),
    *Training on Complex and Scarce Datasets*).
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些不同的优化技术都是深度学习中的宝贵工具，特别是在处理不平衡或稀缺数据集时训练 CNN 时，这种情况在定制应用中经常发生（如[第 7 章](337ec077-c215-4782-b56c-beae4d94d718.xhtml)《在复杂和稀缺数据集上的训练》中详细阐述）。
- en: Similar to the Jupyter notebook for the optimizers study, we provide another
    notebook demonstrating how these regularization methods can be applied, and how
    they affect the performance of our simple CNN.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 与优化器学习的 Jupyter 笔记本类似，我们提供了另一个笔记本，展示了如何应用这些正则化方法，以及它们如何影响我们简单 CNN 的性能。
- en: Summary
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: With the help of TensorFlow and Keras, we caught up with years of research in
    deep learning. As CNNs have become central to modern computer vision (and machine
    learning in general), it is essential to understand how they perform, and what
    kinds of layers they are composed of. As presented in this chapter, TensorFlow
    and Keras provide clear interfaces to efficiently build such networks. They are
    also implementing several advanced optimization and regularization techniques
    (such as various optimizers, L1/L2 regularization, dropout, and batch normalization)
    to improve the performance and robustness of trained models, which is important
    to keep in mind for any application.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 和 Keras 的帮助下，我们赶上了深度学习领域多年的研究进展。由于 CNN 已成为现代计算机视觉（以及机器学习一般）的核心，了解它们的性能以及它们由哪些层组成是至关重要的。正如本章所展示的，TensorFlow
    和 Keras 提供了清晰的接口，可以高效地构建这样的网络。它们还实现了多种先进的优化和正则化技术（例如各种优化器、L1/L2 正则化、dropout 和批量归一化），以提高训练模型的性能和鲁棒性，这对于任何应用都是非常重要的。
- en: We now have the tools to finally tackle more challenging computer vision tasks.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在拥有了最终应对更具挑战性的计算机视觉任务的工具。
- en: In the next chapter, we will therefore present several CNN architectures applied
    to the task of classifying large picture datasets.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍几种应用于大规模图像数据集分类任务的 CNN 架构。
- en: Questions
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Why does the output of a convolutional layer have a smaller width and height
    than the input, unless it is padded?
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么卷积层的输出宽度和高度比输入小，除非进行了填充？
- en: What would be the output of a max-pooling layer with a receptive field of (2,
    2) and stride of 2 on the input matrix in *Figure 3.6*?
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个大小为 (2, 2)，步幅为 2 的最大池化层，作用于*图 3.6*中的输入矩阵，输出会是什么？
- en: How could LeNet-5 be implemented using the Keras functional API in a non-object-oriented
    manner?
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何使用 Keras 函数式 API 以非面向对象的方式实现 LeNet-5？
- en: How does L1/L2 regularization affect networks?
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: L1/L2 正则化如何影响网络？
- en: Further reading
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*On the importance of initialization and momentum in deep learning* ([http://proceedings.mlr.press/v28/sutskever13.pdf](http://proceedings.mlr.press/v28/sutskever13.pdf)),
    by Ilya Sutskever et al. This often-referenced conference paper, published in
    2013, presents and compares the momentum and NAG algorithms.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*关于深度学习中初始化和动量的重要性*（[http://proceedings.mlr.press/v28/sutskever13.pdf](http://proceedings.mlr.press/v28/sutskever13.pdf)），Ilya
    Sutskever 等人撰写。该篇经常被引用的会议论文于 2013 年发布，提出并比较了动量和 NAG 算法。'
- en: '*Dropout: A Simple Way to Prevent Neural Networks from Overfitting* ([http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer)),
    by Nitish Srivastava et al. This other conference paper, published in 2014, introduced
    dropout. It is a great read for those who want to know more about this method
    and see it applied to several famous computer vision datasets.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Dropout: 防止神经网络过拟合的简单方法* ([http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf](http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf?utm_content=buffer79b43&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer))，作者：Nitish
    Srivastava 等人。该篇2014年发布的会议论文介绍了 dropout 方法。对于那些想深入了解这一方法并看到其在多个著名计算机视觉数据集中的应用的读者来说，这是一篇值得一读的好文章。'
