- en: Data Representation Using Autoencoders
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自编码器的数据表示
- en: 'This chapter will introduce unsupervised applications of deep learning using
    autoencoders. In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍自编码器的无监督深度学习应用。我们将覆盖以下主题：
- en: Setting up autoencoders
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置自编码器
- en: Data normalization
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据归一化
- en: Setting up a regularized autoencoder
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置正则化自编码器
- en: Fine-tuning the parameters of the autoencoder
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调自编码器的参数
- en: Setting up stacked autoencoders
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置堆叠自编码器
- en: Setting up denoising autoencoders
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置去噪自编码器
- en: Building and comparing stochastic encoders and decoders
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建和比较随机编码器和解码器
- en: Learning manifolds from autoencoders
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从自编码器学习流形
- en: Evaluating the sparse decomposition
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估稀疏分解
- en: Introduction
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Neural networks aim to find a non-linear relationship between input *X* with
    output *y,* as *y=f(x)***.** An autoencoder is a form of unsupervised neural network
    which tries to find a relationship between features in space such that *h*=*f(x)*,
    which helps us learn the relationship between input space and can be used for
    data compression, dimensionality reduction, and feature learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络旨在找到输入*X*与输出*y*之间的非线性关系，即*y=f(x)*。自编码器是一种无监督神经网络，试图找到空间中特征之间的关系，使得*h*=*f(x)*，帮助我们学习输入空间之间的关系，可用于数据压缩、降维和特征学习。
- en: An autoencoder consists of an encoder and decoder. The encoder helps encode
    the input *x* in a latent representation *y,* whereas a decoder converts back
    the *y* to *x*. Both the encoder and decoder possess a similar representation
    of form.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器由编码器和解码器组成。编码器帮助将输入*x*编码为潜在表示*y*，而解码器则将*y*转换回*x*。编码器和解码器具有相似的形式表示。
- en: 'Here is a representation of a one layer autoencoder:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是单层自编码器的表示：
- en: '**![](img/00051.jpeg)**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**![](img/00051.jpeg)**'
- en: The coder encodes input *X* to *h* under a hidden layer contain, whereas the
    decoder helps to attain the original data from encoded output *h*. The matrices
    *W[e]* and *W[d]* represent the weights of the encoder and decoder layers, respectively.
    The function *f* is the activation function.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器将输入*X*编码为*H*，并通过隐藏层处理，而解码器则帮助从编码输出*H*恢复原始数据。矩阵*W[e]*和*W[d]*分别表示编码器和解码器层的权重。函数*f*是激活函数。
- en: 'An illustration of an autoencoder is shown in the following diagram:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是自编码器的示意图：
- en: '![](img/00053.jpeg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00053.jpeg)'
- en: The constraints in the form of nodes allows the autoencoder to discover interesting
    structures within the data. For example, in the encoder in the preceding diagram,
    the five-input dataset must pass through three-node compression to get an encoded
    value *h****.*** The **Encoded Output layer** of an encoder can have a dimensionality
    that is the same, lower, or higher than the **input/output Decoded Output layer**.
    The **Encoded Output layer** with a fewer number of nodes than the input layer
    is referred to as an under-complete representation, and can be thought of as data
    compression transforming data into low-dimensional representation.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以节点形式的约束使自编码器能够发现数据中的有趣结构。例如，在前面的图中，编码器的五个输入数据集必须经过三个节点的压缩才能得到编码值*h*。**编码输出层**的维度可以与**输入/输出解码输出层**相同、较低或较高。输入层节点数少于编码层的**编码输出层**称为欠完备表示，可以视为将数据压缩成低维表示。
- en: An **Encoded Output layer** with a larger number of input layers is referred
    to as an over-complete representation and is used in a **sparse autoencoder**
    as a regularization strategy. The objective of an autoencoder is to find *y,*
    capturing the main factors along the variation of data, which is similar to **Principal
    Component Analysis (PCA)**, and thus can be used for compression as well.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**编码输出层**具有较多输入层的情况称为过完备表示，并在**稀疏自编码器**中作为正则化策略使用。自编码器的目标是找到*y*，捕捉数据变化的主要因素，这与**主成分分析（PCA）**类似，因此也可以用于压缩。'
- en: Setting up autoencoders
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置自编码器
- en: There exist a lot of different architectures of autoencoders distinguished by
    cost functions used to capture data representation. The most basic autoencoder
    is known as a vanilla autoencoder. It's a two-layer neural network with one hidden
    layer the same number of nodes at the input and output layers, with an objective
    to minimize the cost function*.* The typical choices, but not limited to, for
    a loss function are **mean square error** (**MSE**) for regression and cross entropy
    for classification. The current approach can be easily extended to multiple layers,
    also known as multilayer autoencoder.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 存在多种不同架构的自编码器，这些架构通过使用不同的代价函数来捕捉数据表示。最基本的自编码器被称为香草自编码器（vanilla autoencoder）。它是一个包含两个层的神经网络，其中隐藏层的节点数与输入层和输出层相同，目标是最小化代价函数。常用的（但不限于）损失函数包括回归问题中的**均方误差**(**MSE**)和分类问题中的交叉熵。当前方法可以轻松扩展到多个层次，这种扩展被称为多层自编码器。
- en: The number of nodes plays a very critical role in autoencoders. If the number
    of nodes in the hidden layer is less than the input layer then an autoencoder
    is known as an **under-complete** autoencoder. A higher number of nodes in the
    hidden layer represents an **over-complete** autoencoder or sparse autoencoder.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 节点数量在自编码器中起着至关重要的作用。如果隐藏层中的节点数少于输入层的节点数，那么该自编码器被称为**欠完备**自编码器。隐藏层中节点数较多则表示**过完备**自编码器或稀疏自编码器。
- en: The sparse autoencoder aims to impose sparsity in the hidden layer. This sparsity
    can be achieved by introducing a higher number of nodes than the input in the
    hidden layer or by introducing a penalty in the loss function that will move the
    weights for the hidden layer toward zero. Some autoencoders attain the sparsity
    by manually zeroing out the weight for nodes; these are referred to as **K-sparse
    autoencoders***.* We will set up an autoencoder on the occupancy dataset discussed
    in [Chapter 1](part0021.html#K0RQ1-a0a93989f17f4d6cb68b8cfd331bc5ab), *Getting
    Started*. The hidden layer for the current example can be tweaked around.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏自编码器旨在对隐藏层施加稀疏性。这种稀疏性可以通过在隐藏层引入比输入层更多的节点，或者通过在损失函数中引入惩罚来实现，从而使隐藏层的权重趋向于零。有些自编码器通过手动将节点的权重置为零来实现稀疏性，这些被称为**K-稀疏自编码器**。我们将在[第1章](part0021.html#K0RQ1-a0a93989f17f4d6cb68b8cfd331bc5ab)《入门指南》中讨论的`Occupancy`数据集上设置自编码器。当前示例的隐藏层可以进行调整。
- en: Getting ready
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'Let''s use the `Occupancy` dataset to set up an autoencoder:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`Occupancy`数据集来设置自编码器：
- en: Download the `Occupancy` dataset as described in [Chapter 1](part0021.html#K0RQ1-a0a93989f17f4d6cb68b8cfd331bc5ab),
    *Getting Started*
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载`Occupancy`数据集，如[第1章](part0021.html#K0RQ1-a0a93989f17f4d6cb68b8cfd331bc5ab)《入门指南》中所述。
- en: TensorFlow installation in R and Python
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在R和Python中安装TensorFlow
- en: How to do it...
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The current occupancy dataset as described in [Chapter 1](part0021.html#K0RQ1-a0a93989f17f4d6cb68b8cfd331bc5ab),
    *Getting Started*, is used to demonstrate the autoencoder setup in R using TensorFlow:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的`Occupancy`数据集，如[第1章](part0021.html#K0RQ1-a0a93989f17f4d6cb68b8cfd331bc5ab)《入门指南》中所述，用于演示如何在R中使用TensorFlow设置自编码器：
- en: Set up the R TensorFlow environment.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置R TensorFlow环境。
- en: 'The `load_occupancy_data` function can be used to load the data by setting
    the correct working directory path using `setwd`:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`load_occupancy_data`函数可以通过使用`setwd`设置正确的工作目录路径来加载数据：'
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The train and test occupancy dataset can be loaded to the R environment with
    the following script:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用以下脚本将训练和测试的`Occupancy`数据集加载到R环境中：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Data normalization
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据归一化
- en: '**Data normalization** is a critical step in machine learning to bring data
    to a similar scale. It is also known as feature scaling and is performed as data
    preprocessing.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据归一化**是机器学习中的一个关键步骤，用于将数据转换为相似的尺度。它也称为特征缩放，通常作为数据预处理的一部分进行。'
- en: The correct normalization is very critical in neural networks, else it will
    lead to saturation within the hidden layers, which in turn leads to zero gradient
    and no learning will be possible.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的归一化对于神经网络至关重要，否则它会导致隐藏层的饱和，从而导致梯度为零，无法进行学习。
- en: Getting ready
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'There are multiple ways to perform normalization:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方式可以执行归一化：
- en: '**Min-max standardization**: The min-max retains the original distribution
    and scales the feature values between *[0, 1],* with *0* as the minimum value
    of the feature and *1* as the maximum value. The standardization is performed
    as follows:'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最小-最大标准化**：最小-最大标准化保持原始分布，并将特征值缩放到*【0, 1】*之间，其中*0*为特征的最小值，*1*为最大值。标准化的过程如下：'
- en: '![](img/00055.jpeg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00055.jpeg)'
- en: Here, *x*' is the normalized value of the feature. The method is sensitive to
    outliers in the dataset.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*x*' 是特征的归一化值。该方法对数据集中的异常值较为敏感。
- en: '**Decimal scaling**: This form of scaling is used where values of different
    decimal ranges are present. For example, two features with different bounds can
    be brought to a similar scale using decimal scaling as follows:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**十进制缩放**：这种缩放形式用于存在不同十进制范围值的情况。例如，两个具有不同边界的特征可以通过如下方式使用十进制缩放将其带到相似的尺度：'
- en: '*x''=x/10^n*'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*x''=x/10^n*'
- en: '**Z-score:** This transformation scales the value toward a normal distribution
    with a zero mean and unit variance. The Z-score is computed as:'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Z-得分**：这种转换将值缩放到具有零均值和单位方差的正态分布。Z-得分计算公式为：'
- en: '*Z*=(**x-µ)/σ**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*Z*=(**x-µ)/σ**'
- en: Here, *µ* is the mean and σ is the standard deviation of the feature. These
    distributions are very efficient for a dataset with a Gaussian distribution.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*µ* 是均值，σ 是特征的标准差。这些分布对具有高斯分布的数据集非常有效。
- en: All the preceding methods are sensitive to outliers; there are other more robust
    approaches for normalization that you can explore, such as **Median Absolute Deviation**
    (**MAD**), tanh-estimator, and double sigmoid.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 所有前述方法对异常值敏感；你可以探索其他更稳健的归一化方法，例如**中位数绝对偏差** (**MAD**)、tanh估计器和双重sigmoid。
- en: Visualizing dataset distribution
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集分布的可视化
- en: 'Let''s look at the distribution of features for the occupation data:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看看职业数据的特征分布：
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](img/00059.gif)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00059.gif)'
- en: The figure shows that the features have linear correlations and the distributions
    are non-normal. The non-normality can be further validated using the Shapiro-Wilk
    test, using the `shapiro.test` function from R. Let's use min-max standardization
    for the occupation data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图表显示特征具有线性相关性，并且分布是非正态的。可以通过使用 Shapiro-Wilk 测试进一步验证非正态性，使用 R 中的 `shapiro.test`
    函数。我们将对职业数据使用最小-最大标准化。
- en: How to do it...
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Perform the following operation for data normalization:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下操作以进行数据归一化：
- en: '[PRE3]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The `minmax.normalize` function normalizes the data using min-max normalization.
    When the `scaler` variable is `NULL`, it performs normalization using the dataset
    provided, or normalizes using `scaler` values. The normalized data pair plot is
    shown in the following figure:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`minmax.normalize` 函数使用最小-最大标准化对数据进行归一化。当 `scaler` 变量为 `NULL` 时，它使用提供的数据集进行归一化，或者使用
    `scaler` 的值进行归一化。归一化后的数据对图如下面的图所示：'
- en: '![](img/00060.gif)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00060.gif)'
- en: This figure shows min-max normalization bringing the values within bounds *[0,
    1]* and it does not change the distribution and correlations between features.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 此图显示了最小-最大归一化将值限制在 *[0, 1]* 范围内，并且没有改变特征之间的分布和相关性。
- en: How to set up an autoencoder model
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何设置自编码器模型
- en: 'The next step is to set up the autoencoder model. Let''s set up a vanilla autoencoder
    using TensorFlow:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是设置自编码器模型。让我们使用 TensorFlow 设置一个基础的自编码器：
- en: 'Reset the `graph` and start `InteractiveSession`:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重置 `graph` 并启动 `InteractiveSession`：
- en: '[PRE4]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Define the input parameter where `n` and `m` are the number of samples and
    features, respectively. To build, network `m` is used to set up the input parameter:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义输入参数，其中 `n` 和 `m` 分别是样本数和特征数。为了构建网络，`m` 用来设置输入参数：
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: When `n_hidden_1` is low, the autoencoder is compressing the data and is referred
    to as an under-complete autoencoder; whereas, when `n_hidden_1` is large, then
    the autoencoder is sparse and is referred to as an over-complete autoencoder.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 当 `n_hidden_1` 很低时，自编码器会压缩数据，称为欠完备自编码器；而当 `n_hidden_1` 很大时，自编码器则是稀疏的，称为过完备自编码器。
- en: 'Define graph input parameters that include the input tensor and layer definitions
    for the encoder and decoder:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义包括输入张量和编码器、解码器层定义的图输入参数：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The preceding script designs a single-layer encoder and decoder.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 前述脚本设计了一个单层编码器和解码器。
- en: 'Define a function to evaluate the response:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数来评估响应：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `auto_encoder` function takes the node bias weights and computes the output.
    The same function can be used for `encoder` and `decoder` by passing respective
    weights.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`auto_encoder` 函数接收节点偏置权重并计算输出。通过传递相应的权重，可以使用相同的函数来处理 `encoder` 和 `decoder`。'
- en: 'Create `encoder` and `decoder` objects by passing symbolic TensorFlow variables:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过传递符号化的 TensorFlow 变量创建 `encoder` 和 `decoder` 对象：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `y_pred` is the outcome from `decoder`, which takes the `encoder` object
    as input with nodes and bias weights:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`y_pred` 是来自 `decoder` 的输出，它将 `encoder` 对象作为输入，包含节点和偏置权重：'
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding script defines mean square error as the cost function, and uses
    `RMSPropOptimizer` from TensorFlow with 0.1 learning rate for the optimization
    of weights. The TensorFlow graph for the preceding model is shown in the following
    diagram:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 上述脚本将均方误差定义为成本函数，并使用TensorFlow中的`RMSPropOptimizer`，学习率为0.1，来优化权重。上述模型的TensorFlow图如下所示：
- en: '![](img/00063.jpeg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00063.jpeg)'
- en: Running optimization
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行优化
- en: 'The next step is to run optimizer optimization. Executing this process in TensorFlow
    consists of two steps:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是执行优化器优化。执行此过程的TensorFlow步骤包括两部分：
- en: 'The first step is parameter initialization of the variables defined in the
    graph. The initialization is performed by calling the `global_variables_initializer`
    function from TensorFlow:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是对图中定义的变量进行参数初始化。初始化通过调用TensorFlow中的`global_variables_initializer`函数来完成：
- en: '[PRE10]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Optimization is performed based on optimizing and monitoring the train and
    test performance:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 优化是基于优化和监控训练和测试性能进行的：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The cost function from train and test can be observed to understand convergence
    of the model, as shown in the following figure:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以观察训练和测试中的成本函数，以了解模型的收敛情况，如下图所示：
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](img/00133.gif)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00133.gif)'
- en: This graph shows that the model major `convergence` is at around **400** iterations;
    however, it is still converging at a very slow rate even after **1,000** iterations.
    The model is stable in both the train and holdout test datasets.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 该图显示，模型的主要`收敛`发生在大约**400**次迭代时；然而，即使经过**1,000**次迭代后，收敛速度依然很慢。该模型在训练数据集和保留测试数据集中都很稳定。
- en: Setting up a regularized autoencoder
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置正则化自编码器
- en: A regularized autoencoder extends the standard autoencoder by adding a regularization
    parameter to the `cost` function.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化自编码器通过在`cost`函数中添加正则化参数来扩展标准自编码器。
- en: Getting ready
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The regularized autoencoder is an extension of the standard autoencoder. The
    set-up will require:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化自编码器是标准自编码器的扩展。设置将需要：
- en: TensorFlow installation in R and Python.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在R和Python中的TensorFlow安装。
- en: Implementation of a standard autoencoder.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标准自编码器的实现。
- en: How to do it...
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The code setup for the autoencoder can directly be converted to a regularized
    autoencoder by replacing the cost definition with the following lines:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器的代码设置可以通过将成本定义替换为以下几行，直接转换为正则化自编码器：
- en: '[PRE13]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: How it works...
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'As mentioned earlier, a regularized autoencoder extends the standard autoencoder
    by adding a regularization parameter to the cost function, shown as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，正则化自编码器通过在成本函数中添加正则化参数来扩展标准自编码器，如下所示：
- en: '![](img/00148.jpeg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00148.jpeg)'
- en: 'Here, *λ* is the regularization parameter and *i* and *j* are the node indexes
    with *W* representing the hidden layer weights for the autoencoder. The regularization
    autoencoder aims to ensure more robust encoding and prefers a low weight *h* function.
    The concept is further utilized to develop a contractive autoencoder, which utilizes
    the Frobenius norm of the Jacobian matrix on input, represented as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*λ*是正则化参数，*i*和*j*是节点索引，*W*表示自编码器的隐藏层权重。正则化自编码器的目的是确保更强大的编码，并偏好低权重*h*函数。这个概念进一步被用于开发收缩自编码器，它利用输入上雅可比矩阵的Frobenius范数，表示如下：
- en: '![](img/00029.jpeg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00029.jpeg)'
- en: 'where **J(x)** is the Jacobian matrix and is evaluated as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 其中**J(x)**是雅可比矩阵，计算方法如下：
- en: '![](img/00146.jpeg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00146.jpeg)'
- en: For a linear encoder, a contractive encoder and regularized encoder converge
    to L2 weight decay. The regularization helps in making the autoencoder less sensitive
    to the input; however, the minimization of the cost function helps the model to
    capture the variation and remain sensitive to manifolds of high density. These
    autoencoders are also referred to as **contractive autoencoders**.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线性编码器，收缩编码器和正则化编码器收敛到L2权重衰减。正则化有助于使自编码器对输入的敏感度降低；然而，成本函数的最小化帮助模型捕捉变化，并保持对高密度流形的敏感性。这些自编码器也被称为**收缩自编码器**。
- en: Fine-tuning the parameters of the autoencoder
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微调自编码器的参数
- en: 'The autoencoder involves a couple of parameters to tune, depending on the type
    of autoencoder we are working on. The major parameters in an autoencoder include
    the following:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器涉及一些需要调整的参数，这取决于我们所使用的自编码器类型。自编码器中的主要参数包括：
- en: Number of nodes in any hidden layer
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任何隐藏层中的节点数量
- en: Number of hidden layers applicable for deep autoencoders
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适用于深度自编码器的隐藏层数量
- en: Activation unit such as sigmoid, tanh, softmax, and ReLU activation functions
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激活单元，例如sigmoid、tanh、softmax和ReLU激活函数
- en: Regularization parameters or weight decay terms on hidden unit weights
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐藏单元权重上的正则化参数或权重衰减项
- en: Fraction of the signal to be corrupted in a denoising autoencoder
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在去噪自编码器中，信号损坏的比例
- en: Sparsity parameters in sparse autoencoders that control the expected activation
    of neurons in hidden layers
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稀疏自编码器中的稀疏性参数，用于控制隐藏层中神经元的期望激活值
- en: Batch size, if using batch gradient descent learning; learning rate and momentum
    parameter for stochastic gradient descent
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用批量梯度下降学习，批次大小；如果使用随机梯度下降，学习率和动量参数
- en: Maximum iterations to be used for the training
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练时使用的最大迭代次数
- en: Weight initialization
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 权重初始化
- en: Dropout regularization if dropout is used
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用了dropout，进行dropout正则化
- en: These hyperparameters can be trained by setting the problem as a grid search
    problem. However, each hyperparameter combination requires training the neuron
    weights for the hidden layer(s), which results in increasing computational complexity
    with an increase in the number of layers and number of nodes within each layer.
    To deal with these critical parameters and training issues, stacked autoencoder
    concepts have been proposed that train each layer separately to get pretrained
    weights, and then the model is fine-tuned using the obtained weights. This approach
    tremendously improves the training performance over the conventional mode of training.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这些超参数可以通过将问题设定为网格搜索问题来训练。然而，每个超参数组合都需要训练隐藏层的神经元权重，这导致随着层数和每层节点数的增加，计算复杂性也会增加。为了解决这些关键参数和训练问题，提出了堆叠自编码器概念，它逐层训练每一层，以获取预训练权重，然后使用获得的权重对模型进行微调。这种方法大大提高了训练性能，相比传统的训练方式。
- en: Setting up stacked autoencoders
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置堆叠自编码器
- en: 'The stacked autoencoder is an approach to train deep networks consisting of
    multiple layers trained using the greedy approach. An example of a stacked autoencoder
    is shown in the following diagram:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠自编码器是一种训练深度网络的方法，包含多个层，使用贪婪算法逐层训练。下面的图示展示了堆叠自编码器的一个示例：
- en: '![](img/00037.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00037.jpeg)'
- en: An example of a stacked autoencoder
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠自编码器的示例
- en: Getting ready
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'The preceding diagram demonstrates a stacked autoencoder with two layers. A
    stacked autoencoder can have *n* layers, where each layer is trained using one
    layer at a time. For example, the previous layer will be trained as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图示展示了一个具有两层的堆叠自编码器。堆叠自编码器可以有*n*层，其中每一层是逐层训练的。例如，前一层的训练过程如下：
- en: '![](img/00039.jpeg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00039.jpeg)'
- en: Training of a stacked autoencoder
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠自编码器的训练
- en: The initial pre-training of layer 1 is obtained by training it over the actual
    input *x[i]* . The first step is to optimize the *We(1)* layer of the encoder
    with respect to output X. The second step in the preceding example is to optimize
    the weights *We(2)* in the second layer, using *We(1)* as input and output. Once
    all the layers of *We(i)* where *i*=1, 2, ...,*n* is number of layers are pretrained,
    model fine-tuning is performed by connecting all the layers together, as shown
    in step 3 of the preceding diagram. The concept can also be applied to denoising
    to train multilayer networks, which is known as a stacked denoising autoencoder.
    The code developed in a denoising autoencoder can be easily tweaked to develop
    a **stacked denoising autoencoder**, which is an extension of the stacked autoencoder.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 第1层的初步训练是通过在实际输入*x[i]*上进行训练得到的。第一步是优化编码器的*We(1)*层，以适应输出X。上面的第二步是通过使用*We(1)*作为输入和输出，优化第二层的权重*We(2)*。一旦所有*We(i)*层（其中*i*=1,
    2, ..., *n*为层数）都经过预训练，就可以通过将所有层连接在一起进行模型微调，正如前图中的第3步所示。该概念还可以应用于去噪训练多层网络，这被称为堆叠去噪自编码器。去噪自编码器中开发的代码可以轻松调整为开发**堆叠去噪自编码器**，它是堆叠自编码器的扩展。
- en: 'The requirements for this recipe are:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 本配方的要求如下：
- en: R should be installed.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 需要安装R。
- en: '`SAENET` package, The package can be download from Cran using the command `install.packages("SAENET")`*.*'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`SAENET`包，可以通过命令`install.packages("SAENET")`从Cran下载安装该包。'
- en: How to do it...
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'There are other popular libraries in R to develop stacked autoencoders. Let''s
    utilize the `SAENET` package from R to set up a stacked autoencoder. The `SAENET`
    is a stacked autoencoder implementation, using a feedforward neural network using
    the `neuralnet` package from CRAN:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在R中还有其他流行的库用于开发堆叠自编码器。让我们使用R中的`SAENET`包来搭建一个堆叠自编码器。`SAENET`是一个堆叠自编码器的实现，使用的是`neuralnet`包中的前馈神经网络（来自CRAN）：
- en: 'Get the `SAENET` package from the CRAN repository, if not installed already:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果尚未安装，可以从CRAN仓库获取`SAENET`包：
- en: '[PRE14]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Load all library dependencies:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载所有库依赖项：
- en: '[PRE15]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Load the train and test occupancy dataset using `load_occupancy_data`:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`load_occupancy_data`加载训练和测试占用数据集：
- en: '[PRE16]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Normalize the dataset using the `minmax.normalize` function:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`minmax.normalize`函数对数据集进行归一化：
- en: '[PRE17]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The stacked autoencoder model can be built using the `SAENET.train` train function
    from the `SAENET` package:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 堆叠自编码器模型可以使用`SAENET.train`训练函数从`SAENET`包中构建：
- en: '[PRE18]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The output of the last node can be extracted using the `SAE_obj[[n]]$X.output`
    command.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`SAE_obj[[n]]$X.output`命令提取最后一个节点的输出。
- en: Setting up denoising autoencoders
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置去噪自编码器
- en: Denoising autoencoders are a special kind of autoencoder with a focus on extracting
    robust features from the input dataset. Denoising autoencoders are similar to
    the previous model except with a major difference that the data is corrupted before
    training the network. Different approaches for corruption can be used such as
    masking, which induces random error into the data.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 去噪自编码器是一种特殊类型的自编码器，专注于从输入数据集中提取稳健的特征。去噪自编码器与之前的模型类似，唯一的主要区别是数据在训练网络之前会被破坏。可以使用不同的破坏方法，例如遮罩，它会在数据中引入随机错误。
- en: Getting ready
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Let''s use the CIFAR-10 image data to set up a denoising dataset:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用CIFAR-10图像数据来设置去噪数据集：
- en: Download the CIFAR-10 dataset using the `download_cifar_data` function (covered
    in [Chapter 3](part0093.html#2OM4A1-a0a93989f17f4d6cb68b8cfd331bc5ab), *Convolution
    Neural Network*)
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`download_cifar_data`函数下载CIFAR-10数据集（见[第3章](part0093.html#2OM4A1-a0a93989f17f4d6cb68b8cfd331bc5ab)，*卷积神经网络*）
- en: TensorFlow installation in R and Python
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在R和Python中安装TensorFlow
- en: How to do it...
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: We first need to read the dataset.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先需要读取数据集。
- en: Reading the dataset
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读取数据集
- en: 'Load the `CIFAR` dataset using the steps explained in [Chapter 3](part0093.html#2OM4A1-a0a93989f17f4d6cb68b8cfd331bc5ab),
    *Convolution Neural Network*. The data files `data_batch_1` and `data_batch_2`
    are used to train. The `data_batch_5` and `test_batch` files are used for validation
    and testing, respectively. The data can be flattened using the `flat_data` function:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用[第3章](part0093.html#2OM4A1-a0a93989f17f4d6cb68b8cfd331bc5ab)中解释的步骤加载`CIFAR`数据集，*卷积神经网络*。使用`data_batch_1`和`data_batch_2`文件进行训练，`data_batch_5`和`test_batch`文件分别用于验证和测试。数据可以通过`flat_data`函数进行展平：
- en: '[PRE19]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `flat_data` function flattens the dataset as *NCOL = (Height * Width *
    number of channels)*, thus the dimension of the dataset is (# of images X NCOL).
    The images in `CIFAR` are 32 x 32 with three RGB channels; thus, we obtain 3,072
    columns after data flattening:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`flat_data`函数将数据集展平为*NCOL = (高度 * 宽度 * 通道数)*，因此数据集的维度是（图像数 × NCOL）。`CIFAR`中的图像大小为32
    x 32，包含三个RGB通道；因此，在数据展平后，我们得到3,072列：'
- en: '[PRE20]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Corrupting data to train
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 破坏数据以进行训练
- en: 'The next critical function needed to set up a denoising autoencoder is data
    corruption:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置去噪自编码器所需的下一个关键功能是数据破坏：
- en: '[PRE21]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The CIFAR-10 data can be corrupted using the following script:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用以下脚本来破坏CIFAR-10数据：
- en: '[PRE22]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'An example image after corruption is as follows:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 破坏后的示例图像如下：
- en: '![](img/00002.jpeg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00002.jpeg)'
- en: 'The preceding figure uses the masking approach to add noise. This method adds
    zero values at random image locations with a defined fraction. Another approach
    to add noise is by using salt & pepper noise. This method selects random locations
    in the image and replaces them, adding min or max values to the image using the
    flip of coin principle. An example of the salt and pepper approach for data corruption
    is shown in the following figure:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上图使用了遮罩方法来添加噪声。此方法在随机图像位置添加零值，且定义了一个比例。另一种添加噪声的方法是使用椒盐噪声。此方法在图像中选择随机位置并进行替换，使用抛硬币原理为图像添加最小值或最大值。以下是使用椒盐方法进行数据破坏的示例：
- en: '![](img/00045.jpeg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00045.jpeg)'
- en: The data corruption helps the autoencoder to learn more robust representation.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 数据破坏有助于自编码器学习更稳健的表示。
- en: Setting up a denoising autoencoder
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置去噪自编码器
- en: 'The next step is to set up the autoencoder model:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是设置自编码器模型：
- en: 'First, reset the graph and start an interactive session as follows:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，重置图并开始一个交互式会话，如下所示：
- en: '[PRE23]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The next step is to define two placeholders for the input signal and corrupt
    signal:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是为输入信号和破坏信号定义两个占位符：
- en: '[PRE24]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The `x_corrupt` will be used as input in the autoencoder, and *x* is the actual
    image that will be used as output.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`x_corrupt` 将作为自编码器的输入，而 *x* 是实际的图像，将用作输出。'
- en: 'Set up a denoising autoencoder function as shown in the following code:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置去噪自编码器函数，如下代码所示：
- en: '[PRE25]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Create the denoising object:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建去噪对象：
- en: '[PRE26]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Set the cost function:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置代价函数：
- en: '[PRE27]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Run optimization:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行优化：
- en: '[PRE28]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: How it works...
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The autoencoder keeps learning about the function form for the feature to capture
    the relationship between input and output. An example of how the computer is visualizing
    the image after 1,000 iterations is shown in the following figure:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器继续学习关于特征的函数形式，以捕捉输入和输出之间的关系。计算机在 1,000 次迭代后如何可视化图像的示例如下所示：
- en: '![](img/00061.jpeg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00061.jpeg)'
- en: 'After 1,000 iterations, the computer can distinguish between a major part of
    the object and environment. As we run the algorithm further to fine-tune the weights,
    the computer keeps learning more features about the object itself, as shown in
    the following figure:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行 1,000 次迭代后，计算机能够区分物体和环境的主要部分。随着我们继续运行算法来微调权重，计算机会继续学习更多关于物体本身的特征，如下图所示：
- en: '![](img/00140.gif)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00140.gif)'
- en: 'The preceding graph shows that the model is still learning, but the learning
    rate has become smaller over the iterations as it starts learning fine features
    about objects, as shown in the following image. There are instances when the model
    starts ascending instead of descending, due to batch gradient descent:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 上图显示了模型仍在学习，但随着它开始学习关于物体的精细特征，学习率在迭代过程中逐渐变小，如下图所示。有时，模型开始上升而不是下降，这是由于批量梯度下降引起的：
- en: '![](img/00007.jpeg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00007.jpeg)'
- en: Illustration of learning using denoising autoencoder
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 使用去噪自编码器进行学习的示意图
- en: Building and comparing stochastic encoders and decoders
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建和比较随机编码器和解码器
- en: 'Stochastic encoders fall into the domain of generative modeling, where the
    objective is to learn join probability *P(X)* over given data *X* transformed
    into another high-dimensional space. For example, we want to learn about images
    and produce similar, but not exactly the same, images by learning about pixel
    dependencies and distribution. One of the popular approaches in generative modeling
    is **Variational autoencoder** (**VAE**), which combines deep learning with statistical
    inference by making a strong distribution assumption on *h ~ P(h),* such as Gaussian
    or Bernoulli. For a given weight *W***,** the *X* can be sampled from the distribution
    as *Pw(X|h)***.** An example of VAE architecture is shown in the following diagram:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 随机编码器属于生成建模领域，目标是学习给定数据 *X* 在转换到另一个高维空间后的联合概率 *P(X)*。例如，我们想学习图像并通过学习像素依赖关系和分布生成类似但不完全相同的图像。生成建模中一种流行的方法是**变分自编码器**（**VAE**），它通过对
    *h ~ P(h)* 做出强假设，如高斯分布或伯努利分布，将深度学习与统计推理相结合。对于给定的权重 *W*，*X* 可以从分布中采样为 *Pw(X|h)*。下面的图示展示了
    VAE 的架构：
- en: '![](img/00052.gif)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00052.gif)'
- en: 'The cost function of VAE is based on log likelihood maximization. The cost
    function consists of reconstruction and regularization error terms:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: VAE 的代价函数基于对数似然最大化。代价函数由重建误差和正则化误差项组成：
- en: '*Cost = Reconstruction Error + Regularization Error*'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '*代价 = 重建误差 + 正则化误差*'
- en: The **reconstruction error** is how well we could map the outcome with the training
    data and the **regularization error** puts a penalty on the distribution formed
    at the encoder and decoder.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**重建误差** 是我们如何将结果与训练数据进行映射的准确度，而 **正则化误差** 对编码器和解码器形成的分布施加了惩罚。'
- en: Getting ready
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'TensorFlow needs to be installed and loaded in the environment:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 需要在环境中安装并加载：
- en: '[PRE29]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Dependencies need to be loaded:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 需要加载依赖项：
- en: '[PRE30]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The `MNIST` dataset needs to be loaded. The dataset is normalized using the
    following script:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`MNIST` 数据集需要被加载。数据集使用以下脚本进行归一化：'
- en: '[PRE31]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![](img/00054.jpeg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00054.jpeg)'
- en: How to do it...
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'The `MNIST` dataset is used to demonstrate the concept of sparse decomposition.
    The `MNIST` dataset uses handwritten digits. It is downloaded from the `tensorflow`
    dataset library. The dataset consists of handwritten images of `28 x 28` pixels.
    It consists of 55,000 training examples, 10,000 test examples, and 5,000 test
    examples. The dataset can be downloaded from the `tensorflow` library using the
    following script:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`MNIST` 数据集被用来演示稀疏分解的概念。`MNIST` 数据集包含手写数字。它是从 `tensorflow` 数据集库下载的。数据集包含 `28
    x 28` 像素的手写图像，包含 55,000 个训练样本，10,000 个测试样本和 5,000 个测试样本。可以通过以下脚本从 `tensorflow`
    库下载数据集：'
- en: '[PRE32]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'For computational simplicity, the `MNIST` image size is reduced from `28 x
    28` pixels to `16 x 16` pixels using the following function:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了简化计算，`MNIST` 图像的大小从 `28 x 28` 像素减小为 `16 x 16` 像素，使用以下函数：
- en: '[PRE33]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The following script can be used to prepare the `MNIST` training data with
    a 16 x 16 pixel image:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下脚本可以用来准备具有 `16 x 16` 像素图像的 `MNIST` 训练数据：
- en: '[PRE34]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The `plot_mnist` function can be used to visualize the selected `MNIST` image:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`plot_mnist` 函数可以用来可视化选择的 `MNIST` 图像：'
- en: '[PRE35]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Setting up a VAE model
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 VAE 模型：
- en: 'Start a new TensorFlow environment:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动一个新的 TensorFlow 环境：
- en: '[PRE36]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Define network parameters:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义网络参数：
- en: '[PRE37]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Start a new TensorFlow environment:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动一个新的 TensorFlow 环境：
- en: '[PRE38]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Define network parameters:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义网络参数：
- en: '[PRE39]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The preceding parameter will form a VAE network as follows:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 前述参数将形成如下的 VAE 网络：
- en: '![](img/00056.gif)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00056.gif)'
- en: 'Define the model initialization function, defining weights and biases at each
    layer of `encoder` and `decoder`:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义模型初始化函数，定义每一层 `encoder` 和 `decoder` 的权重和偏差：
- en: '[PRE40]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The `model_init` function returns `weights`, which is a two-dimensional list.
    The first dimension captures the weight''s association and type. For example,
    it describes if the `weights` variable is assigned to the encoder or decoder and
    if it stores the weight of the node or bias. The `xavier_init` function in `model_init`
    is used to assign initial weights for model training:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '`model_init` 函数返回 `weights`，它是一个二维列表。第一个维度表示权重的关联和类型。例如，它描述了 `weights` 变量是分配给编码器还是解码器，并且它是否存储节点的权重或偏差。`model_init`
    中的 `xavier_init` 函数用于为模型训练分配初始权重：'
- en: '[PRE41]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Set up the encoder evaluation function:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置编码器评估函数：
- en: '[PRE42]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The `vae_encoder` computes the mean and variance to sample the layer, using
    the weights and bias from the hidden layer.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '`vae_encoder` 计算均值和方差，用于从隐藏层的权重和偏差中采样：'
- en: 'Set up the decoder evaluation function:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置解码器评估函数：
- en: '[PRE43]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The `vae_decoder` function computes the mean and standard deviation associated
    with the sampling layer at output and average output.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '`vae_decoder` 函数计算与采样层相关的均值和标准差，以及输出和平均输出：'
- en: 'Set up the function for reconstruction estimation:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置重构估计的函数：
- en: '[PRE44]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Define the cost function for optimization:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义优化的成本函数：
- en: '[PRE45]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Set up the model to train:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置模型进行训练：
- en: '[PRE46]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Run optimization:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行优化：
- en: '[PRE47]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Output from the VAE autoencoder
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VAE 自编码器的输出：
- en: 'The outcome can be generated using the following script:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用以下脚本生成结果：
- en: '[PRE48]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The outcome obtained after `20,000` iterations from the preceding VAE autoencoder
    is shown in the following figure:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图所示是从前述 VAE 自编码器经过 `20,000` 次迭代后的结果：
- en: '![](img/00147.gif)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00147.gif)'
- en: Additionally, as VAE is a generative model, the outcome is not an exact replica
    of the input and would vary with runs, as a representative sample is extracted
    from the estimated distribution.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于 VAE 是生成模型，输出结果不是输入的精确复制，而是会随着运行的不同而有所变化，因为从估计的分布中提取了一个代表性样本。
- en: Learning manifolds from autoencoders
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从自编码器学习流形：
- en: 'Manifold learning is an approach in machine learning that assumes that data
    lies on a manifold of a much lower dimension. These manifolds can be linear or
    non-linear. Thus, the area tries to project the data from high-dimension space
    to a low dimension. For example, **principle component analysis** (**PCA**) is
    an example of linear manifold learning whereas an autoencoder is a **non-linear
    dimensionality reduction** (**NDR**) with the ability to learn non-linear manifolds
    in low dimensions. A comparison of linear and non-linear manifold learning is
    shown in the following figure:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 流形学习是机器学习中的一种方法，它假设数据位于一个维度远低于原始数据的流形上。这些流形可以是线性或非线性的。因此，该方法尝试将数据从高维空间投影到低维空间。例如，**主成分分析**（**PCA**）是线性流形学习的一个例子，而自编码器则是一个**非线性降维**（**NDR**）方法，具有学习低维空间中非线性流形的能力。线性与非线性流形学习的比较见下图：
- en: '![](img/00062.gif)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00062.gif)'
- en: As you can see from graph **a)**, the data is residing at a linear manifold,
    whereas in graph graph **b)**, the data is residing on a second-order non-linear
    manifold.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 如图**a)**所示，数据位于一个线性流形上，而在图**b)**中，数据则位于二阶非线性流形上。
- en: How to do it...
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Let's take an output from the stacked autoencoder section and analyze how manifolds
    look when transferred into a different dimension.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们取堆叠自编码器部分的输出，分析数据在转移到不同维度时，流形的表现。
- en: Setting up principal component analysis
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置主成分分析
- en: 'Before getting into non-linear manifolds, let''s analyze principal component
    analysis on the occupancy data:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在进入非线性流形之前，让我们分析占用数据上的主成分分析：
- en: '[PRE49]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The preceding function will transform the data into six orthogonal directions
    specified as linear combinations of features. The variance explained by each dimension
    can be viewed using the following script:'
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述函数将数据转化为六个正交方向，这些方向是特征的线性组合。每个维度所解释的方差可以通过以下脚本查看：
- en: '[PRE50]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The preceding command will plot the variance across principal components, as
    shown in the following figure:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述命令将绘制主成分的方差，如下图所示：
- en: '![](img/00064.gif)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00064.gif)'
- en: 'For the occupancy dataset, the first two principal components capture the majority
    of the variation, and when the principal component is plotted, it shows separation
    between the positive and negative classes for occupancy, as shown in the following
    figure:'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于占用数据集，前两个主成分捕捉了大部分变异，当绘制主成分时，显示出占用的正负类之间的分离，如下图所示：
- en: '![](img/00066.gif)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00066.gif)'
- en: Output from the first two principal components
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 前两个主成分的输出
- en: 'Let''s visualize the manifold in a low dimension learned by the autoencoder.
    Let''s use only one dimension to visualize the outcome, as follows:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们可视化自编码器学习到的低维流形。我们只使用一个维度来可视化结果，如下所示：
- en: '[PRE51]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The encoder architecture for the preceding script is shown as follows:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述脚本的编码器架构如下所示：
- en: '![](img/00115.jpeg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00115.jpeg)'
- en: 'The hidden layer outcome with one latent node from the stacked autoencoder
    is shown as follows:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 堆叠自编码器中一个潜在节点的隐藏层输出如下所示：
- en: '![](img/00092.gif)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00092.gif)'
- en: 'The preceding graph shows that occupancy is true at the peaks of the latent
    variables. However, the peaks are found at different values. Let''s increase the
    latent variables 2, as captured by PCA. The model can be developed and data can
    be plotted using the following script:'
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述图表显示，占用在潜在变量的峰值处为真。然而，峰值出现在不同的值上。让我们增加潜在变量2，这是通过PCA捕获的。可以使用以下脚本开发模型并绘制数据：
- en: '[PRE52]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The encoded values with two layers are shown in the following diagram:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 带有两层编码的值在下图中显示：
- en: '![](img/00123.gif)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00123.gif)'
- en: Evaluating the sparse decomposition
  id: totrans-275
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估稀疏分解
- en: 'The sparse autoencoder is also known as over-complete representation and has
    a higher number of nodes in the hidden layer. The sparse autoencoders are usually
    executed with the sparsity parameter (regularization), which acts as a constraint
    and restricts the node to being active. The sparsity can also be assumed as nodes
    dropout caused due to sparsity constraints. The loss function for a sparse autoencoder
    consists of a reconstruction error, a regularization term to contain the weight
    decay, and KL divergence for sparsity constraint. The following representation
    gives a very good illustration of what we are talking about:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏自编码器也被称为过完备表示，并且在隐藏层中具有更多的节点。稀疏自编码器通常使用稀疏性参数（正则化）执行，该参数充当约束，限制节点的激活。稀疏性也可以被看作是由于稀疏性约束而导致的节点丢弃。稀疏自编码器的损失函数由重建误差、用于控制权重衰减的正则化项以及用于稀疏性约束的KL散度组成。以下表示很好地说明了我们所讲的内容：
- en: '![](img/00095.jpeg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00095.jpeg)'
- en: Getting ready
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The dataset is loaded and set up.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集已加载并设置好。
- en: 'Install and load the `autoencoder` package using the following script:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下脚本安装并加载`autoencoder`包：
- en: '[PRE53]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: How to do it...
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The standard autoencoder code of TensorFlow can easily be extended to the sparse
    autoencoder module by updating the cost function. This section will introduce
    the autoencoder package of R, which comes with built-in functionality to run the
    sparse autoencoder:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TensorFlow的标准自编码器代码可以通过更新成本函数轻松扩展到稀疏自编码器模块。本节将介绍R的自编码器包，该包内置了运行稀疏自编码器的功能：
- en: '[PRE54]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The major parameters in the `autoencode` functions are as follows:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '`autoencode`函数中的主要参数如下：'
- en: '`nl`: This is the number of layers including the input and output layer (the
    default is three).'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nl`：这是包括输入层和输出层在内的层数（默认值为三层）。'
- en: '`N.hidden`: This is the vector with the number of neurons in each hidden layer.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`N.hidden`：这是每个隐藏层中神经元数量的向量。'
- en: '`unit.type`: This is the type of activation function to be used.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unit.type`：这是要使用的激活函数类型。'
- en: '`lambda`: This is the regularization parameter.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lambda`：这是正则化参数。'
- en: '`rho`: This is the sparsity parameter.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rho`：这是稀疏性参数。'
- en: '`beta`: This is the penalty for the sparsity term.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta`：这是稀疏项的惩罚。'
- en: '`max.iterations`: This is the maximum number of iterations.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max.iterations`：这是最大迭代次数。'
- en: '`epsilon`: This is the parameter for weight initialization. The weights are
    initialized using Gaussian distribution ~N(0, epsilon2).'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epsilon`：这是权重初始化的参数。权重是使用高斯分布 ~N(0, epsilon2) 初始化的。'
- en: How it works...
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'The following figure shows the shapes and orientation of digits from `MNIST`
    captured by the sparse autoencoder:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了稀疏自编码器捕获的来自`MNIST`的数字形状和方向：
- en: '![](img/00138.gif)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00138.gif)'
- en: Filter generated by the sparse autoencoder to get the digit outcome
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 通过稀疏自编码器生成的滤波器得到数字结果
- en: The filter learned by the sparse autoencoder can be visualized using the `visualize.hidden.units`
    function from the autoencoder package. The package plots the weight of the final
    layer with respect to the output. In the current scenario, 100 is the number of
    neurons in the hidden layer and 256 is the number of nodes in the output layer.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 稀疏自编码器学习到的滤波器可以使用来自自编码器包的`visualize.hidden.units`函数进行可视化。该包绘制了最终层的权重与输出之间的关系。在当前场景中，100是隐藏层中的神经元数量，256是输出层中的节点数量。
