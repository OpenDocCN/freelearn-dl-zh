- en: '21'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '21'
- en: Diffusion Model Transfer Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩散模型迁移学习
- en: 'This book is mainly focused on using Stable Diffusion with Python, and when
    doing so, we will need to fine-tune a model for our specific needs. As we discussed
    in previous chapters, there are many ways to customize the model, such as the
    following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书主要关注使用Python进行Stable Diffusion，这样做时，我们需要针对我们的特定需求微调模型。正如我们在前面的章节中讨论的那样，有许多方法可以定制模型，例如以下方法：
- en: Unlocking UNet to fine-tune all parameters
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解锁UNet以微调所有参数
- en: Training a textual inversion to add new keyword embeddings
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练一个文本反转以添加新的关键词嵌入
- en: Locking UNet and training a LoRA model for customized styles
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 锁定UNet并训练一个LoRA模型以定制样式
- en: Training a ControlNet model to guide image generation with control guidance
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练一个ControlNet模型以使用控制引导来指导图像生成
- en: Training an adaptor to use the image as one of the guidance embeddings
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练一个适配器，将图像作为指导嵌入之一
- en: It is impossible to cover all the model training topics in simply one chapter.
    Another book would be needed to discuss the details of model training.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个简单的章节中涵盖所有模型训练主题是不可能的。需要另一本书来讨论模型训练的细节。
- en: 'Nevertheless, we still want to use this chapter to drill down to the core concepts
    of model training. Instead of listing sample code on how to fine-tune a diffusion
    model, or using the scripts from the `Diffusers` package, we want to introduce
    you to the core concepts of training so that you fully understand the common training
    process. In this chapter, we will cover the following topics:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们仍然希望利用本章深入探讨模型训练的核心概念。我们不想列出如何微调扩散模型的示例代码，或者使用`Diffusers`软件包中的脚本，而是想介绍训练的核心概念，以便你完全理解常见的训练过程。在本章中，我们将涵盖以下主题：
- en: Introducing the foundations of training a model by training a linear model from
    scratch using PyTorch
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用PyTorch从头开始训练线性模型来介绍模型训练的基础知识
- en: Introducing the Hugging Face Accelerate package to train a model in multiple
    GPUs
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍Hugging Face Accelerate软件包以在多个GPU上训练模型
- en: Building code to train a Stable Diffusion V1.5 LoRA model using PyTorch and
    Accelerator step by step
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐步构建使用PyTorch和Accelerator训练Stable Diffusion V1.5 LoRA模型的代码
- en: By the end of this chapter, you’ll be familiar with the overall training process
    and key concepts, and you’ll be able to read sample code from other repositories
    and build your own training code to customize a model from a pre-trained model.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将熟悉整体训练过程和关键概念，并且能够阅读来自其他存储库的示例代码，构建自己的训练代码以从预训练模型定制模型。
- en: Writing code to train one model is the best way to learn how to train a model.
    Let’s start work on it.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 编写训练一个模型的代码是学习如何训练模型的最佳方式。让我们开始工作吧。
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Training a model requires more GPU power and VRAM than model inference. Prepare
    a GPU with at least 8 GB of VRAM – the more, the better. You can also train a
    model using multiple GPUs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 训练模型比模型推理需要更多的GPU功率和VRAM。准备一个至少有8GB VRAM的GPU – 越多越好。你也可以使用多个GPU来训练模型。
- en: 'It is recommended to install the latest version of the following packages:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 建议安装以下软件包的最新版本：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here are the specified packages with the versions I used to write the code
    samples:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出了我编写代码示例时使用的指定软件包及其版本：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The training code was tested in the Ubuntu 22.04 x64 version.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 训练代码在Ubuntu 22.04 x64版本上进行了测试。
- en: Training a neural network model with PyTorch
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyTorch训练神经网络模型
- en: The target of this section is to build and train one simple neural network model
    using PyTorch. The model will be a simple one-layer model, with no additional
    fancy layers. It is simple but with all the elements required to train a Stable
    Diffusion LoRA, as we will see later in this chapter.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是使用PyTorch构建和训练一个简单的神经网络模型。这个模型将是一个单层模型，没有额外的复杂层。它很简单，但包含了训练Stable Diffusion
    LoRA所需的所有元素，正如我们将在本章后面看到的那样。
- en: Feel free to skip this section if you are familiar with PyTorch model training.
    If it is your first time to start training a model, this simple model training
    will help you thoroughly understand the process of model training.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你熟悉PyTorch模型训练，可以跳过这一节。如果你是第一次开始训练模型，这个简单的模型训练将帮助你彻底理解模型训练的过程。
- en: Before starting, make sure you have installed all the required packages mentioned
    in the *Technical* *requirements* section.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，请确保你已经安装了*技术要求*部分中提到的所有必需的软件包。
- en: Preparing the training data
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备训练数据
- en: 'Let’s assume we want to train a model with four weights and output one digital
    result show, as shown in the following:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要训练一个具有四个权重并输出一个数字结果的模型，如下所示：
- en: y = w 1 × x 1 + w 2 × x 2 + w 3 × x 3 + w 4 × x 4
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: y = w1 × x1 + w2 × x2 + w3 × x3 + w4 × x4
- en: 'The four weights, w 1, w 2, w 3, w 4, are the model weights we want to have
    from the training data (Think of these weights as the Stable Diffusion model weight).
    Because we need to have some real data to train the model, I will use the weights
    `[2,3,4,7]` to generate some sample data:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 四个权重w1、w2、w3、w4是我们希望从训练数据中获得的模型权重（将这些权重视为Stable Diffusion模型的权重）。由于我们需要一些真实数据来训练模型，我将使用权重`[2,3,4,7]`来生成一些样本数据：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let’s create 10 groups of input sample data, `x_sample`; each `x_sample` is
    an array with four elements, the same length as the weight:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建10组输入样本数据`x_sample`；每个`x_sample`是一个包含四个元素的数组，与权重的长度相同：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In the following section, we will use a neural network model to predict a list
    of weights; for the sake of training, let’s assume that the true weights are unknown
    after generating the training data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下部分，我们将使用神经网络模型来预测一系列权重；为了训练的目的，让我们假设在生成训练数据后，真实的权重是未知的。
- en: 'In the preceding code snippet, we utilize `numpy` to leverage its dot product
    operator, `@`, to compute the output, `y`. Now, let’s generate `y_list` containing
    `10` elements:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们利用`numpy`利用其点积运算符`@`来计算输出`y`。现在，让我们生成包含`10`个元素的`y_list`：
- en: '[PRE4]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can print `x_list` and `y_list` to take a look at the training data.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以打印`x_list`和`y_list`来查看训练数据。
- en: Our training data is ready; there’s no need to download anything else. Next,
    let’s define the model itself and prepare for training.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的训练数据已经准备好了；不需要下载其他任何东西。接下来，让我们定义模型本身并准备训练。
- en: Preparing for training
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备训练
- en: 'Our model could be the world’s simplest model ever, a simple linear dot product,
    as defined in the following code:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模式可能是世界上最简单的模型，一个简单的线性点积，如下面的代码所示：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `torch.randn(4)` code is to generate a tensor with a four-weight number.
    No other code is needed; our NN model is ready now, named `MyLinear`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.randn(4)`代码是用来生成一个包含四个权重数字的张量。不需要其他代码；我们的NN模型现在准备好了，命名为`MyLinear`。'
- en: 'To train a model, we will need to initialize it, similar to initializing random
    weights in an LLM or diffusion model:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 要训练一个模型，我们需要初始化它，类似于在LLM或扩散模型中初始化随机权重：
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Almost all neural network model training follows these steps:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有神经网络模型训练都遵循以下步骤：
- en: Forward a pass to predict the result.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前向传递以预测结果。
- en: Compute the difference between the predicted result and the ground truth, known
    as the loss value.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算预测结果和真实结果之间的差异，即损失值。
- en: Perform backpropagation to calculate the gradient loss value.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行反向传播以计算梯度损失值。
- en: Update the model parameters.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新模型参数。
- en: Before kicking off the training, define a loss function and an optimizer. The
    loss function, `loss_fn`, will help calculate a loss value based on the predicted
    result and ground truth result. `optimizer` will be used to update the weights.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练之前，定义一个损失函数和一个优化器。损失函数`loss_fn`将帮助根据预测结果和真实结果计算损失值。`optimizer`将用于更新权重。
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`lr` represents the learning rate, a crucial hyperparameter to set. Determining
    the best **learning rate** (**lr**) often involves trial and error, depending
    on the characteristics of your model, dataset, and problem. To find a reasonable
    learning rate, you need to do the following:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`lr`代表学习率，这是一个关键的超参数需要设置。确定最佳**学习率**（**lr**）通常涉及试错，这取决于您模型的特性、数据集和问题。为了找到一个合理的学习率，您需要执行以下操作：'
- en: '**Start with a small learning rate**: A common practice is to start with a
    small learning rate, such as 0.001, and gradually increase or decrease it based
    on the observed convergence behavior.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**从较小的学习率开始**：一种常见的做法是从较小的学习率开始，例如0.001，并根据观察到的收敛行为逐渐增加或减少它。'
- en: '**Use learning rate schedules**: You can use learning rate schedules to adjust
    the learning rate dynamically during training. One common approach is step decay,
    where the learning rate decreases after a fixed number of epochs. Another popular
    method is exponential decay, in which the learning rate decreases exponentially
    over time. (We won’t use it in the world’s simplest model.)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用学习率调度器**：您可以在训练过程中动态调整学习率。一种常见的方法是步长衰减，即在固定数量的epoch后学习率降低。另一种流行的方法是指数衰减，其中学习率随时间指数下降。（我们不会在世界上最简单的模型中使用它。）'
- en: 'Also, don’t forget to convert the input and output to the torch Tensor object:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，别忘了将输入和输出转换为torch Tensor对象：
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: All the preparations are done, so let’s start training a model.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 所有准备工作都已完成，让我们开始训练一个模型。
- en: Training a model
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'We will set the epoch number to 100, which means looping through our training
    data 100 times:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将设置迭代次数为100，这意味着将训练数据循环100次：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let’s break down the preceding code:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解前面的代码：
- en: '`y_pred = model(x)`: This line applies the model to the current input data
    sample, `x`, generating a prediction, `y_pred`.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_pred = model(x)`: 这一行将模型应用于当前输入数据样本`x`，生成预测`y_pred`。'
- en: '`loss = loss_fn(y_pred,y_output[i])`: This line calculates the loss (also known
    as the error or cost) by comparing the predicted output, `y_pred`, with the actual
    output, `y_output[i]` , using a specified loss function, `loss_fn`.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss = loss_fn(y_pred,y_output[i])`: 这一行通过比较预测输出`y_pred`与实际输出`y_output[i]`，使用指定的损失函数`loss_fn`来计算损失（也称为误差或成本）。'
- en: '`optimizer.zero_grad()`: This line resets the gradients calculated during the
    backward pass to zero. This is important because it prevents gradient values from
    carrying over between different samples.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimizer.zero_grad()`: 这一行将反向传播期间计算的梯度重置为零。这很重要，因为它防止梯度值在不同样本之间传递。'
- en: '`loss.backward()`: This line performs the backpropagation algorithm, computing
    gradients for all parameters with respect to the loss.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss.backward()`: 这一行执行反向传播算法，计算所有参数相对于损失的梯度。'
- en: '`optimizer.step()`: This line updates the model’s parameters based on the computed
    gradients and the chosen optimization method.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimizer.step()`: 这一行根据计算出的梯度和选择的优化方法更新模型的参数。'
- en: 'Putting all the code together and running it, we will see the following output:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有代码合并并运行，我们将看到以下输出：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The loss value converges quickly and approaches `0` after `100` epochs. Execute
    the following code to see the current weight:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 损失值快速收敛并接近`0`，经过`100`个迭代周期后。执行以下代码以查看当前权重：
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You can see that the weights update as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到权重更新如下：
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This is quite close to `[2,3,4,7]`! The model was successfully trained to find
    the right weight numbers.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常接近 `[2,3,4,7]`！模型成功训练以找到正确的权重数字。
- en: In the case of Stable Diffusion and multiple GPU training, we can get help from
    the Hugging Face Accelerate package [4]. Let’s start using `Accelerate` next.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在Stable Diffusion和多GPU训练的情况下，我们可以从Hugging Face Accelerate包[4]中获得帮助。让我们开始使用`Accelerate`。
- en: Training a model with Hugging Face’s Accelerate
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Hugging Face的Accelerate训练模型
- en: Hugging Face’s `Accelerate` is a library that provides a high-level API over
    different PyTorch distributed frameworks, aiming to simplify the process of distributed
    and mixed-precision training. It is designed to keep changes to your training
    loop to a minimum and allow the same functions to work for any distributed setup.
    Let’s see what `Accelerate` can bring to the table.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face的`Accelerate`是一个库，它提供了对不同的PyTorch分布式框架的高级API，旨在简化分布式和混合精度训练的过程。它旨在将训练循环中的更改保持在最低限度，并允许相同的函数适用于任何分布式设置。让我们看看`Accelerate`能带来什么。
- en: Applying Hugging Face’s Accelerate
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用Hugging Face的Accelerate
- en: 'Let’s apply `Accelerate` to our simple but working model. Accelerate is designed
    to be used together with PyTorch, so we don’t need to change too much code. Here
    are the steps to use `Accelerate` to train a model:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将`Accelerate`应用于我们简单但有效的模型。Accelerate旨在与PyTorch一起使用，因此我们不需要更改太多代码。以下是使用`Accelerate`训练模型的步骤：
- en: 'Generate the default configuration file:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成默认配置文件：
- en: '[PRE13]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Initialize an `Accelerate` instance, and send the model instance and data to
    the device managed by Accelerate:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化一个`Accelerate`实例，并将模型实例和数据发送到Accelerate管理的设备：
- en: '[PRE15]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Replace `loss.backward` with `accelerator.backward(loss)` :'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`loss.backward`替换为`accelerator.backward(loss)`：
- en: '[PRE21]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Next, we will update the training code using Accelerate.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用Accelerate更新训练代码。
- en: Putting code together
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合并代码
- en: 'We will keep all the other code the same; here is the complete training code
    except for the data preparations and model initializing:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将保持所有其他代码不变；以下是完整的训练代码，除了数据准备和模型初始化：
- en: '[PRE23]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Running the preceding code, we should get the same output as when we run the
    training model without the Hugging Face `Accelerate` library. And the loss value
    converges as well.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 运行前面的代码，我们应该得到与运行不带Hugging Face `Accelerate`库的训练模型相同的输出。并且损失值也会收敛。
- en: Training a model with multiple GPUs using Accelerate
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Accelerate在多个GPU上训练模型
- en: There are many types of multiple GPU training; in our case, we will use the
    data parallel style [1]. Simply put, we will load the whole model data into each
    GPU and split the training data across multiple GPUs.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多种多 GPU 训练的方式；在我们的案例中，我们将使用数据并行风格 [1]。简单来说，我们将整个模型数据加载到每个 GPU 中，并将训练数据分配到多个
    GPU 上。
- en: 'In PyTorch, we can achieve this with the following code:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在 PyTorch 中，我们可以使用以下代码实现：
- en: '[PRE24]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'For the world’s simplest model, we will load the whole model to each GPU and
    split the 10 groups’ training data into 5 groups each. Each GPU will take five
    groups of data at the same time. After each step, all loss gradient numbers will
    be merged using the `allreduce` operation. The `allreduce` operation simply added
    all the loss data from all GPUs, added it up, and then sent it back to each GPU
    to update the weights, as shown in the following Python code:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 对于世界上最简单的模型，我们将整个模型加载到每个 GPU 中，并将 10 组训练数据分成每组 5 组。每个 GPU 将同时处理五组数据。在每一步之后，所有损失梯度数值将通过
    `allreduce` 操作合并。`allreduce` 操作简单地将所有 GPU 的损失数据相加，然后将其发送回每个 GPU 以更新权重，如下面的 Python
    代码所示：
- en: '[PRE25]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Accelerate will launch two independent processes to train. To avoid creating
    two training datasets, let’s generate one dataset and save it to local storage
    using the `pickle` package:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Accelerate 将启动两个独立的过程来训练。为了避免创建两个训练数据集，让我们生成一个数据集，并使用 `pickle` 包将其保存到本地存储：
- en: '[PRE26]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Then, wrap the whole model and training code in a `main` function and save
    it in a new Python file named `train_model_in_2gpus.py`:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将整个模型和训练代码包裹在一个 `main` 函数中，并将其保存到一个名为 `train_model_in_2gpus.py` 的新 Python
    文件中：
- en: '[PRE27]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Then, start the training using this command:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用以下命令开始训练：
- en: '[PRE28]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You should see something like this:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到类似这样的内容：
- en: '[PRE29]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: If so, congratulations! You just successfully trained an AI model in two GPUs.
    With the knowledge you’ve learned, let’s now start to train a Stable Diffusion
    V1.5 LoRA.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是这样，恭喜你！你刚刚在两个 GPU 上成功训练了一个 AI 模型。现在，让我们利用你所学到的知识开始训练一个稳定的扩散 V1.5 LoRA。
- en: Training a Stable Diffusion V1.5 LoRA
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练一个稳定的扩散 V1.5 LoRA
- en: The Hugging Face document provides complete guidance on training a LoRA by calling
    a pre-defined script [2] provided by Diffusers. However, we don’t want to stop
    at “using” the script. The training code from Diffusers includes a lot of edge-case
    handling and additional code that is hard to read and learn. In this section,
    we will write up each line of the training code to fully understand what happens
    in each step.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face 文档提供了通过调用 Diffusers 提供的预定义脚本 [2] 来训练 LoRA 的完整指导。然而，我们不想仅仅停留在“使用”脚本上。Diffusers
    的训练代码中包含了许多边缘情况处理和难以阅读和学习的额外代码。在本节中，我们将逐行编写训练代码，以全面了解每个步骤中发生的情况。
- en: In the following sample, we will use eight images with associated captions to
    train a LoRA. The image and image captions are provided in the `train_data` folder
    of the code for this chapter.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们将使用八张带有相关标题的图片来训练一个 LoRA。图片和图片标题包含在本章代码的 `train_data` 文件夹中。
- en: 'Our training code structure will be like this:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的训练代码结构将如下所示：
- en: '[PRE30]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Right below the `main()` function, we initialize the `accelerate` instance.
    The `Accelerator` instance is initialized with two hyperparameters:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `main()` 函数下方，我们初始化 `accelerate` 实例。`Accelerator` 实例使用两个超参数进行初始化：
- en: '`gradient_accumulation_steps`: This is the number of training steps to accumulate
    gradients before we update the model parameters. Gradient accumulation allows
    you to effectively train with a larger batch size than would be possible with
    a single GPU, while still fitting the model parameters in memory.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gradient_accumulation_steps`：这是在更新模型参数之前要累积梯度的训练步数。梯度累积允许你使用比单个 GPU 可能实现的更大的批大小进行有效训练，同时仍然将模型参数拟合到内存中。'
- en: '`mixed_precision`: This specifies the precision to use during training. The
    `"fp16"` value means that half-precision floating point values will be used for
    the intermediate computations, which can lead to faster training times and lower
    memory usage.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mixed_precision`：这指定了训练期间要使用的精度。`"fp16"` 值表示将使用半精度浮点值进行中间计算，这可以导致更快的训练时间和更低的内存使用。'
- en: The `Accelerator` instance also has an attribute device, which is the device
    (GPU or CPU) on which the model will be trained. The device attribute can be used
    to move the model and tensors to the appropriate device before training.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`Accelerator` 实例还有一个属性 device，它是在模型将要训练的设备（GPU 或 CPU）。device 属性可以在训练之前将模型和张量移动到适当的设备。'
- en: Now, let’s start defining hyperparameters.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始定义超参数。
- en: Defining training hyperparameters
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义训练超参数
- en: 'Hyperparameters are parameters that are not learned from the data but, instead,
    are set before the commencement of the learning process. They are user-defined
    settings that govern the training process of a machine learning algorithm. In
    our LoRA training case, we will have the following settings:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数是那些不是从数据中学习，而是在学习过程开始之前设置的参数。它们是用户定义的设置，用于控制机器学习算法的训练过程。在我们的 LoRA 训练案例中，我们将有以下设置：
- en: '[PRE31]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Let’s break down the preceding settings:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解前面的设置：
- en: '`output_dir`: This is the directory where the model outputs will be saved.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_dir`：这是模型输出将被保存的目录。'
- en: '`pretrained_model_name_or_path`: This is the name or path of the pretrained
    model to be used as the starting point for training.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pretrained_model_name_or_path`：这是用作训练起始点的预训练模型的名称或路径。'
- en: '`lora_rank`: This is the number of layers in the `32` might not be effective
    enough, while ranks above `256` might be overkill for most tasks. In our case,
    since we use only eight images to train the LoRA, setting the rank to `4` is enough.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_rank`：这是 `32` 层可能不足以有效，而高于 `256` 的 Rank 对于大多数任务可能过于冗余。在我们的案例中，因为我们只使用八个图像来训练
    LoRA，将 Rank 设置为 `4` 就足够了。'
- en: '`lora_alpha`: This, conversely, controls the strength of the updates made to
    the pretrained model’s weights during fine-tuning. Specifically, the weight changes
    generated during fine-tuning are multiplied by a scaling factor equal to Alpha
    divided by Rank, before being added back to the original model weights. Therefore,
    increasing Alpha relative to Rank. Setting Alpha equal to Rank is a common starting
    practice.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lora_alpha`：相反，这控制了在微调过程中对预训练模型权重进行的更新强度。具体来说，微调期间生成的权重变化乘以一个缩放因子，该因子等于 Alpha
    除以 Rank，然后将其添加回原始模型权重。因此，相对于 Rank 增加Alpha。将 Alpha 设置为 Rank 是一个常见的起始实践。'
- en: '`learning_rate`: This parameter controls how quickly the model learns from
    its mistakes during training. Specifically, it sets the step size for each iteration,
    determining how aggressively the model adjusts its parameters to minimize the
    `loss` function.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learning_rate`：此参数控制模型在训练过程中从错误中学习的速度。具体来说，它设置了每次迭代的步长，决定了模型调整其参数以最小化 `loss`
    函数的积极性。'
- en: '`adam_beta1` and `adam_beta2`: These are the parameters used in the Adam optimizer
    to control the decay rates of the moving averages of the gradient and squared
    gradient, respectively.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adam_beta1` 和 `adam_beta2`：这些是在 Adam 优化器中使用的参数，分别用于控制梯度移动平均和平方梯度的衰减率。'
- en: '`adam_weight_decay`: This is the weight decay used in the Adam optimizer to
    prevent overfitting.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adam_weight_decay`：这是 Adam 优化器中使用的权重衰减，用于防止过拟合。'
- en: '`adam_epsilon`: This is a small value added to the denominator for numerical
    stability in the Adam optimizer.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`adam_epsilon`：这是在 Adam 优化器中添加到分母的小值，以增加数值稳定性。'
- en: '`dataset_name`: This is the name of the dataset to be used for training. Particularly,
    this is the Hugging Face dataset ID, such as `lambdalabs/pokemon-blip-captions`.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset_name`：这是用于训练的数据集的名称。特别是，这是 Hugging Face 数据集 ID，例如 `lambdalabs/pokemon-blip-captions`。'
- en: '`train_data_dir`: This is the directory where the training data is stored.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_data_dir`：这是存储训练数据的目录。'
- en: '`top_rows`: This is the number of rows used for training. It is used to select
    the top rows for training; if you have a dataset with 1,000 rows, set it to 8
    to train the training code with the top 8 rows.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top_rows`：这是用于训练的行数。它用于选择训练的顶部行；如果你有一个包含 1,000 行的数据集，将其设置为 8 以训练顶部 8 行的训练代码。'
- en: '`output_dir`: This is the directory where the outputs will be saved during
    training.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`output_dir`：这是在训练过程中保存输出的目录。'
- en: '`resolution`: This is the resolution of the input images.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resolution`：这是输入图像的分辨率。'
- en: '`center_crop`: This is a Boolean flag indicating whether to perform center
    cropping on the input images.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`center_crop`：这是一个布尔标志，表示是否对输入图像执行中心裁剪。'
- en: '`random_flip`: This is a Boolean flag indicating whether to perform random
    horizontal flipping on the input images.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`random_flip`：这是一个布尔标志，表示是否对输入图像执行随机水平翻转。'
- en: '`train_batch_size`: This is the batch size used during training.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_batch_size`：这是训练过程中使用的批量大小。'
- en: '`gradient_accumulation_steps`: This is the number of training steps to accumulate
    gradients before updating the model parameters.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gradient_accumulation_steps`：这是在更新模型参数之前需要累积梯度的训练步数。'
- en: '`num_train_epochs`: This is the number of training epochs to perform.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_train_epochs`：这是要执行的训练轮数。'
- en: '`lr_scheduler_name`: This is the name of the learning rate scheduler to use.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lr_scheduler_name`：这是要使用的学习率调度器的名称。'
- en: '`max_grad_norm`: This is the maximum norm of the gradients to clip to prevent
    exploding gradients.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_grad_norm`：这是要剪裁以防止梯度爆炸的最大梯度范数。'
- en: '`diffusion_scheduler`: This is the name of the diffusion scheduler to use.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`diffusion_scheduler`：这是要使用的扩散调度器的名称。'
- en: Preparing the Stable Diffusion components
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备 Stable Diffusion 组件
- en: 'When training a LoRA, the process involves inference, adding the loss value,
    and backpropagation - a procedure reminiscent of the inference process. To facilitate
    this, let’s use the `StableDiffusionPipeline` from `Diffusers` package to get
    `tokenizer`, `text_encoder`, `vae`, and `unet`:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练 LoRA 时，涉及推理、添加损失值和反向传播的过程——这是一个类似于推理过程的过程。为了便于此，让我们使用来自 `Diffusers` 包的 `StableDiffusionPipeline`
    来获取 `tokenizer`、`text_encoder`、`vae` 和 `unet`：
- en: '[PRE32]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'During LoRA training, those components will facilitate the forward pass, but
    their weights won’t be updated during backpropagation, so we need to set `requires_grad_`
    to `False`, as shown here:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LoRA 训练期间，这些组件将促进前向传递，但它们的权重在反向传播期间不会更新，因此我们需要将 `requires_grad_` 设置为 `False`，如下所示：
- en: '[PRE33]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The LoRA weights are the part we want to train; let’s use PEFT’s [3] `LoraConfig`
    to initialize the LoRA configurations.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: LoRA 权重是我们想要训练的部分；让我们使用 PEFT 的 [3] `LoraConfig` 来初始化 LoRA 配置。
- en: '`PEFT` is a library developed by Hugging Face that provides parameter-efficient
    ways to adapt large pre-trained models to specific downstream applications. The
    key idea behind PEFT is to fine-tune only a small fraction of a model’s parameters
    instead of fine-tuning all of them, resulting in significant savings in terms
    of computation and memory usage. This makes it possible to fine-tune very large
    models even on consumer hardware with limited resources.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '`PEFT` 是由 Hugging Face 开发的库，它提供了参数高效的途径来适应大型预训练模型到特定的下游应用。PEFT 背后的关键思想是只微调模型参数的一小部分，而不是全部微调，从而在计算和内存使用方面节省了大量资源。这使得即使在资源有限的消费级硬件上也能微调非常大的模型。'
- en: LoRA is one of the PEFT methods supported by the PEFT library. With LoRA, instead
    of updating all the weights of a given layer during fine-tuning, only a low-rank
    approximation of the weight updates is learned, reducing the number of additional
    parameters required per layer. This approach allows you to fine-tune just 0.16%
    of the total parameters of a model while achieving similar performance to full
    fine-tuning.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: LoRA 是 PEFT 库支持的 PEFT 方法之一。使用 LoRA，在微调过程中，不是更新给定层的所有权重，而是学习权重更新的低秩近似，从而减少了每层所需的额外参数数量。这种方法允许你仅微调模型总参数的
    0.16%，同时实现与完全微调相似的性能。
- en: 'To use LoRA with a pre-trained transformer model, you need to instantiate a
    `LoraConfig` object and pass it to the appropriate component of your model. The
    `LoraConfig` class has several attributes that control its behavior, including
    the dimension/rank of the decomposition, dropout rates, and other hyperparameters.
    Once configured, you can then train your model using standard techniques, such
    as gradient descent. Here is the code to create a LoRA configuration object:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 LoRA 与预训练的 Transformer 模型，你需要实例化一个 `LoraConfig` 对象并将其传递到模型适当的组件中。`LoraConfig`
    类有几个属性来控制其行为，包括分解的维度/秩、dropout 率和其他超参数。一旦配置完成，你就可以使用标准技术，如梯度下降来训练你的模型。以下是创建 LoRA
    配置对象的代码：
- en: '[PRE34]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Next, let’s add the LoRA adapter to the UNet model using the `unet_lora_config`
    configuration:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们使用 `unet_lora_config` 配置将 LoRA 适配器添加到 UNet 模型中：
- en: '[PRE35]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Inside the `for` loop, if the parameters require gradients (i.e., they are trainable),
    their data type is explicitly cast to `torch.float32`. This ensures that only
    the trainable parameters are in the `float32` format for efficient training.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `for` 循环内部，如果参数需要梯度（即它们是可训练的），它们的数据类型将被显式转换为 `torch.float32`。这确保了只有可训练的参数以
    `float32` 格式存在，以便于高效训练。
- en: Loading the training data
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载训练数据
- en: 'Let’s load up some data using the following code:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下代码加载数据：
- en: '[PRE36]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Let’s break down the preceding code:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解前面的代码：
- en: '`if dataset_name:`: If `dataset_name` is provided, the code tries to load a
    dataset from Hugging Face’s dataset hub using the `load_dataset` function. If
    no `dataset_name` is provided, it assumes that the dataset is stored locally and
    loads it using the `imagefolder` dataset type.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`if dataset_name:`：如果提供了 `dataset_name`，代码将尝试使用 `load_dataset` 函数从 Hugging
    Face 的数据集库中加载数据集。如果没有提供 `dataset_name`，它假定数据集是本地存储的，并使用 `imagefolder` 数据集类型来加载它。'
- en: '`train_data = dataset["train"]`: The train split of the dataset is assigned
    to the `train_data` variable.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_data = dataset["train"]`: 将数据集的训练部分分配给`train_data`变量。'
- en: '`dataset["train"] = train_data.select(range(top_rows))`: The first top rows
    of the train dataset are selected and assigned back to the train split of the
    dataset. This is useful when working with a small subset of the dataset for faster
    experimentation.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset["train"] = train_data.select(range(top_rows))`: 选择训练数据集的前top行并将其分配回数据集的训练部分。当需要快速实验时，与数据集的小子集一起使用时很有用。'
- en: '`dataset_columns = list(dataset["train"].features.keys())`: The keys of the
    `dataset["train"]` feature dictionary are extracted and assigned to the `dataset_columns`
    variable. These keys represent the image and caption columns in the dataset.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dataset_columns = list(dataset["train"].features.keys())`: 从`dataset["train"]`特征字典中提取键并将其分配给`dataset_columns`变量。这些键代表数据集中的图像和标题列。'
- en: '`image_column, caption_column = dataset_columns[0], dataset_columns[1]`: The
    first and second columns are assigned to the `image_column` and `caption_column`
    variables, respectively. This assumes that the dataset has exactly two columns
    – the first for images and the second for captions.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_column, caption_column = dataset_columns[0], dataset_columns[1]`: 将第一列和第二列分别分配给`image_column`和`caption_column`变量。这假设数据集恰好有两列——第一列用于图像，第二列用于标题。'
- en: 'We will need a function to convert the input text to token IDs; we define the
    function like this:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个函数将输入文本转换为token ID；我们定义这个函数如下：
- en: '[PRE37]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'And then, we train the data transform pipeline:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们训练数据转换管道：
- en: '[PRE38]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The preceding code defines a set of image transformations that will be applied
    to the training dataset during the training of a machine learning or deep learning
    model. These transformations are defined using the `transforms` module from the
    `PyTorch` library.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码定义了一组图像转换，这些转换将在训练机器学习或深度学习模型时应用于训练数据集。这些转换是通过`PyTorch`库中的`transforms`模块定义的。
- en: 'Here’s a breakdown of what each line does:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是每行代码的作用说明：
- en: '`transforms.Compose()`: This is a function that “chains” multiple transformations
    together. It takes a list of transformation functions as input and applies them
    in order.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transforms.Compose()`: 这是一个将多个转换“链式连接”起来的函数。它接受一个转换函数列表作为输入，并按顺序应用它们。'
- en: '`transforms.Resize(resolution, interpolation=transforms.InterpolationMode.BILINEAR)`:
    This line resizes the image to the given resolution pixels while keeping the aspect
    ratio. The interpolation method used is bilinear interpolation.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transforms.Resize(resolution, interpolation=transforms.InterpolationMode.BILINEAR)`:
    这行代码将图像调整到指定的分辨率像素，同时保持宽高比。使用的插值方法是双线性插值。'
- en: '`transforms.CenterCrop(resolution) if center_crop else transforms.RandomCrop(resolution)`:
    This line crops the image to a square of resolution x resolution. If `center_crop`
    is `True`, the crop is taken from the center of the image. If `center_crop` is
    `False`, the crop is taken randomly.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transforms.CenterCrop(resolution) if center_crop else transforms.RandomCrop(resolution)`:
    这行代码将图像裁剪为分辨率x分辨率的正方形。如果`center_crop`为`True`，则从图像中心进行裁剪。如果`center_crop`为`False`，则随机裁剪。'
- en: '`transforms.RandomHorizontalFlip() if random_flip else transforms.Lambda(lambda
    x: x)`: This line horizontally flips the image randomly with a probability of
    0.5\. If `random_flip` is `False`, it leaves the image unchanged.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transforms.RandomHorizontalFlip() if random_flip else transforms.Lambda(lambda
    x: x)`: 这行代码以0.5的概率随机水平翻转图像。如果`random_flip`为`False`，则保持图像不变。'
- en: '`transforms.ToTensor()`: This line converts the image from a PIL image or NumPy
    array to a PyTorch tensor.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transforms.ToTensor()`: 这行代码将图像从PIL图像或NumPy数组转换为PyTorch张量。'
- en: '`transforms.Normalize([0.5], [0.5])`: This line scales the pixel values of
    the image between -1 and 1\. It is commonly used to normalize image data before
    passing it to a neural network.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transforms.Normalize([0.5], [0.5])`: 这行代码将图像的像素值缩放到-1和1之间。在将图像数据传递给神经网络之前，通常用于归一化图像数据。'
- en: By chaining these transformations together using `transforms.Compose`, you can
    easily preprocess your image data and apply multiple transformations to your dataset.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用`transforms.Compose`将这些转换链式连接起来，你可以轻松地预处理图像数据并对数据集应用多个转换。
- en: 'We need the following code to use the chained transformation object:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要以下代码来使用链式转换对象：
- en: '[PRE39]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The preceding code first defines a function called `preprocess_train`, which
    preprocesses the train data. It first converts the images to the RGB format, and
    then it applies a series of image transformations (resize, center/random crop,
    random horizontal flip, and normalization) to them using the `train_transforms`
    object. It then tokenizes the input captions using the `tokenize_captions` function.
    The resulting preprocessed data is added to the `examples` dictionary as the `pixel_values`
    and `input_ids` keys.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的代码首先定义了一个名为 `preprocess_train` 的函数，该函数用于预处理训练数据。它首先将图像转换为 RGB 格式，然后使用 `train_transforms`
    对象对这些图像应用一系列图像变换（调整大小、居中/随机裁剪、随机水平翻转和归一化）。接着，使用 `tokenize_captions` 函数对输入的标题进行标记化。处理后的预训练数据被添加到
    `examples` 字典中，作为 `pixel_values` 和 `input_ids` 键。
- en: The with `accelerator.main_process_first()` line is used to ensure that the
    code inside the block is executed only in the main process. In this case, it sets
    the training transforms for `train_dataset`.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `accelerator.main_process_first()` 行是为了确保代码块内的代码仅在主进程中执行。在这种情况下，它设置了 `train_dataset`
    的训练变换。
- en: The `collate_fn` function is used to collate the dataset examples into a batch
    to be fed to the model. It takes a list of examples and stacks `pixel_values`
    and `input_ids` together. The resulting tensors are then converted to the `float32`
    format and returned as a dictionary.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`collate_fn` 函数用于将数据集示例收集到一个批次中，以便输入模型。它接受一个示例列表，并将 `pixel_values` 和 `input_ids`
    堆叠在一起。然后，得到的张量被转换为 `float32` 格式，并作为字典返回。'
- en: Finally, `train_dataloader` is created using the `torch.utils.data.DataLoader`
    class, which loads `train_dataset` with the specified batch size, shuffle, and
    collate functions.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用 `torch.utils.data.DataLoader` 类创建了 `train_dataloader`，它以指定的批量大小、打乱和收集函数加载
    `train_dataset`。
- en: In PyTorch, DataLoader is a utility class that abstracts the process of loading
    data in batches for training or evaluation. It is used to load data in batches,
    which are sequences of data points used to train a machine learning model.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在 PyTorch 中，DataLoader 是一个实用类，它抽象了在训练或评估时批量加载数据的过程。它用于批量加载数据，这些数据点是用于训练机器学习模型的序列数据点。
- en: In the provided code, `train_dataloader` is an instance of PyTorch’s `DataLoader`
    class. It is used to load the training data in batches. More specifically, it
    loads the data from `train_dataset` in batches of a predefined batch size, shuffles
    the data for each epoch, and applies a user-defined `collate_fn` function to preprocess
    the data before feeding it to the model.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在提供的代码中，`train_dataloader` 是 PyTorch 的 `DataLoader` 类的一个实例。它用于批量加载数据。更具体地说，它以预定义的批量大小从
    `train_dataset` 中批量加载数据，在每个训练周期中打乱数据，并在将数据输入模型之前应用用户定义的 `collate_fn` 函数来预处理数据。
- en: '`train_dataloader` is necessary for the efficient training of the model. By
    loading data in batches, it allows the model to process multiple data points in
    parallel, which can significantly reduce training time. Additionally, shuffling
    the data for each epoch helps prevent overfitting by ensuring that the model sees
    different data points in each epoch.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`train_dataloader` 对于模型的效率训练是必要的。通过批量加载数据，它允许模型并行处理多个数据点，这可以显著减少训练时间。此外，在每个训练周期中打乱数据有助于通过确保模型在每个周期中看到不同的数据点来防止过拟合。'
- en: In the provided code, the `collate_fn` function is used to preprocess the data
    before it is fed to the model. It takes a list of examples and returns a dictionary
    containing the pixel values and input IDs for each example. The `collate_fn` function
    is applied to each batch of data by `DataLoader` before it is fed to the model.
    This allows for more efficient processing of the data by applying the same preprocessing
    steps to each batch of data.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在提供的代码中，`collate_fn` 函数用于在将数据输入模型之前对其进行预处理。它接受一个示例列表，并返回一个包含每个示例的像素值和输入 ID 的字典。`collate_fn`
    函数在 `DataLoader` 将数据输入模型之前应用于每个数据批次。这允许通过将相同的预处理步骤应用于每个数据批次来更有效地处理数据。
- en: Defining the training components
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义训练组件
- en: To prepare and define the training components, let’s first initialize an `AdamW`
    optimizer. `AdamW` is an optimization algorithm to train machine learning models.
    It is a variant of the popular `Adam` optimizer, which uses adaptive learning
    rates for each model parameter. The `AdamW` optimizer is similar to the `Adam`
    optimizer, but it includes an additional weight decay term in the gradient update
    step. This weight decay term is added to the gradient of the loss function during
    optimization, which helps to prevent overfitting by adding a regularization term
    to the loss function.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备和定义训练组件，我们首先初始化一个 `AdamW` 优化器。`AdamW` 是一种用于训练机器学习模型的优化算法。它是流行的 `Adam` 优化器的一个变体，为每个模型参数使用自适应学习率。`AdamW`
    优化器与 `Adam` 优化器类似，但在梯度更新步骤中包含一个额外的权重衰减项。这个权重衰减项在优化过程中添加到损失函数的梯度中，通过向损失函数添加正则化项来帮助防止过拟合。
- en: 'We can initialize an `AdamW` optimizer using the following code:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码初始化一个 `AdamW` 优化器：
- en: '[PRE40]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The `filter` function is used to iterate through all the parameters of the `unet`
    model and selects only those parameters that require gradient computation. The
    `filter` function returns a generator object that contains the parameters that
    require gradient computation. This generator object is assigned to the `lora_layers`
    variable, which will be used to optimize the model parameters during training.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`filter` 函数用于遍历 `unet` 模型的所有参数，并仅选择那些需要梯度计算的参数。`filter` 函数返回一个包含需要梯度计算参数的生成器对象。这个生成器对象被分配给
    `lora_layers` 变量，该变量将在训练过程中用于优化模型参数。'
- en: 'The `AdamW` optimizer is initialized with the following hyperparameters:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`AdamW` 优化器使用以下超参数初始化：'
- en: '`lr`: The learning rate, which controls the step size at each iteration while
    moving toward a minimum of a loss function'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lr`：学习率，它控制每次迭代中向损失函数最小值移动的步长'
- en: '`betas`: A tuple containing the exponential decay rates for the moving average
    of the gradient (β1) and the squared gradient (β2)'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`betas`：一个包含梯度移动平均的指数衰减率（β1）和平方梯度的指数衰减率（β2）的元组'
- en: '`weight_decay`: The weight decay term added to the gradient of the loss function
    during optimization'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weight_decay`：在优化过程中添加到损失函数梯度的权重衰减项'
- en: '`eps`: A small value added to the denominator to improve numerical stability'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eps`：添加到分母中的一个小值，以提高数值稳定性'
- en: 'Second, we define a learning rate scheduler – `lr_scheduler`. Instead of defining
    one manually, we can use the `get_scheduler` function provided by the `Diffusers`
    package (`from diffusers.optimization` `import get_scheduler`):'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们定义一个学习率调度器 - `lr_scheduler`。我们不必手动定义，可以使用 `Diffusers` 包提供的 `get_scheduler`
    函数（`from diffusers.optimization import get_scheduler`）：
- en: '[PRE41]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: This code creates a learning rate scheduler object using the `get_scheduler`
    function from the `Diffusers` library. The learning rate scheduler determines
    how the learning rate (i.e., the step size in gradient descent) changes during
    training.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码使用 `Diffusers` 库中的 `get_scheduler` 函数创建一个学习率调度器对象。学习率调度器确定学习率（即梯度下降中的步长）在训练期间如何变化。
- en: 'The `get_scheduler` function takes two arguments:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_scheduler` 函数接受两个参数：'
- en: '`lr_scheduler_name`: The name of the learning rate scheduler algorithm to use.
    In our sample, the name is `constant`, defined at the beginning of the code.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lr_scheduler_name`：要使用的学习率调度器算法的名称。在我们的示例中，名称是 `constant`，在代码开头定义。'
- en: '`optimizer`: The PyTorch optimizer object that the learning rate scheduler
    will be applied to. This is the `AdamW` optimizer we just initialized.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimizer`：学习率调度器将应用到的 PyTorch 优化器对象。这是我们刚刚初始化的 `AdamW` 优化器。'
- en: We have just prepared all the elements to kick off training and we have written
    lots of code to prepare the dataset, although the actual training code isn’t that
    long. Let’s write the training code next.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好了启动训练的所有元素，并且已经编写了大量代码来准备数据集，尽管实际的训练代码并不长。接下来，让我们编写训练代码。
- en: Training a Stable Diffusion V1.5 LoRA
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练 Stable Diffusion V1.5 LoRA
- en: 'Training a LoRA will usually take a while, and we’d better create a progress
    bar to track the training progress:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 LoRA 通常需要一段时间，我们最好创建一个进度条来跟踪训练进度：
- en: '[PRE42]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Here is the core training code:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是核心训练代码：
- en: '[PRE43]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The preceding code is a typical training loop for Stable Diffusion model training.
    Here’s a breakdown of what each part of the code does:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码是 Stable Diffusion 模型训练的典型训练循环。以下是代码各部分功能的分解：
- en: The outer loop (`for epoch in range(num_train_epochs)`) iterates over the number
    of training epochs. An epoch is one complete pass through the entire training
    dataset.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外层循环（`for epoch in range(num_train_epochs)`）遍历训练的轮数。一个轮次是对整个训练数据集的一次完整遍历。
- en: '`unet.train()` sets the model to training mode. This is important because some
    layers, such as dropout and batch normalization, behave differently during training
    and testing. In the training phase, these layers behave differently than in the
    evaluation phase. For example, dropout layers will drop out nodes with a certain
    probability during training to prevent overfitting, but they will not drop out
    any nodes during evaluation. Similarly, `BatchNorm` layers will use batch statistics
    during training, but will use accumulated statistics during evaluation. So, if
    you don’t call `unet.train()`, these layers will not behave correctly for the
    training phase, which could lead to incorrect results.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet.train()`将模型设置为训练模式。这很重要，因为一些层，如dropout和批归一化，在训练和测试期间表现不同。在训练阶段，这些层的表现与评估阶段不同。例如，dropout层在训练期间将以一定概率丢弃节点以防止过拟合，但在评估期间不会丢弃任何节点。同样，`BatchNorm`层在训练期间将使用批统计信息，但在评估期间将使用累积统计信息。因此，如果您不调用`unet.train()`，这些层在训练阶段将不会正确表现，这可能导致结果不正确。'
- en: The inner loop (`for step, batch in enumerate(train_dataloader)`) iterates over
    the training data. `train_dataloader` is a `DataLoader` object that provides batches
    of training data.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内层循环（`for step, batch in enumerate(train_dataloader)`）遍历训练数据。`train_dataloader`是一个`DataLoader`对象，它提供训练数据的批次。
- en: In *step 1*, the model encodes the input images into a latent space using a
    `latents`), which are scaled by a factor.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*步骤 1*中，模型使用`latents`将输入图像编码到潜在空间中，这些潜在变量通过一个因子进行缩放。
- en: In *step 2*, random noise is added to the latent vectors. This noise is sampled
    from a standard normal distribution and has the same shape as the latent vectors.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*步骤 2*中，向潜在向量添加随机噪声。这种噪声是从标准正态分布中采样的，并且与潜在向量的形状相同。
- en: In *step 3*, random timesteps are sampled for each image in the batch. This
    is part of a time-dependent noise addition process.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*步骤 3*中，为批处理中的每个图像随机采样时间步长。这是时间相关噪声添加过程的一部分。
- en: In *step 4*, the text encoder is used to get the text embedding for conditioning.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*步骤 4*中，使用文本编码器获取用于条件的文本嵌入。
- en: In *step 5*, noise is added to the latent vectors according to the noise magnitude
    at each timestep.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*步骤 5*中，根据每个时间步长的噪声幅度向潜在向量添加噪声。
- en: In *step 6*, the target for the loss calculation is determined based on the
    prediction type. It can be either the noise or the velocity of the noise.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*步骤 6*中，根据预测类型确定损失计算的目标。它可以是噪声或噪声的速度。
- en: In *steps 7* and *8*, The model makes a prediction using the noisy latent vectors,
    the timesteps, and the text embeddings. The loss is then calculated as the mean
    squared error between the model’s prediction and the target.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*步骤 7*和*步骤 8*中，模型使用带噪声的潜在向量、时间步长和文本嵌入进行预测。然后计算损失作为模型预测与目标之间的均方误差。
- en: In *step 9*, the loss is gathered across all processes for logging. This is
    necessary in the case of distributed training, where the model is trained on multiple
    GPUs. So that we can see the loss value changes in the middle of a training process.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*步骤 9*中，收集所有进程中的损失以进行日志记录。在分布式训练的情况下，这是必要的，其中模型在多个GPU上训练。这样我们可以在训练过程中看到损失值的变化。
- en: In *step 10*, the gradients of the loss with respect to the model parameters
    are computed (`accelerator.backward(loss)`), and the gradients are clipped if
    necessary. This is to prevent the gradients from becoming too large, which can
    cause numerical instability. The optimizer updates the model parameters based
    on the gradients (`optimizer.step()`), and the learning rate scheduler updates
    the learning rate (`lr_scheduler.step()`). The gradients are then reset to zero
    (`optimizer.zero_grad()`).
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*步骤 10*中，计算损失相对于模型参数的梯度（`accelerator.backward(loss)`），如果需要，则对梯度进行裁剪。这是为了防止梯度变得过大，这可能导致数值不稳定性。优化器根据梯度更新模型参数（`optimizer.step()`），学习率调度器更新学习率（`lr_scheduler.step()`）。然后梯度被重置为零（`optimizer.zero_grad()`）。
- en: In *step 11*, if the gradients are synchronized, the training loss is reset
    to zero and the progress bar is updated.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*步骤 11*中，如果梯度已同步，则将训练损失重置为零，并更新进度条。
- en: Finally, the training loss, learning rate, and current epoch are logged to monitor
    the training process. The progress bar is updated with these logs.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，训练损失、学习率和当前epoch 被记录下来以监控训练过程。进度条会根据这些日志更新。
- en: Once you understand the preceding steps, you can not only train a Stable Diffusion
    LoRA but also train any other models.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你理解了前面的步骤，你不仅可以训练 Stable Diffusion LoRA，还可以训练任何其他模型。
- en: 'Lastly, we will need to save the LoRA we just trained:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要保存我们刚刚训练的 LoRA：
- en: '[PRE44]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Let’s break down the preceding code:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解前面的代码：
- en: '`accelerator.wait_for_everyone()`: This line is used in distributed training
    to make sure all processes have reached this point in the code. It’s a synchronization
    point.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`accelerator.wait_for_everyone()`：这一行用于分布式训练，以确保所有进程都已达到代码中的这一点。这是一个同步点。'
- en: '`if accelerator.is_main_process:`: This checks whether the current process
    is the main one. In distributed training, you typically only want to save the
    model once, not once for each process.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`if accelerator.is_main_process:`：这一行检查当前进程是否为主进程。在分布式训练中，你通常只想保存一次模型，而不是为每个进程保存一次。'
- en: '`unet = unet.to(torch.float32)`: This line converts the data type of the model’s
    weights to `float32`. This is typically done to save memory, as `float32` uses
    less memory than `float64` but still provides sufficient precision for most deep
    learning tasks.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet = unet.to(torch.float32)`：这一行将模型权重的数据类型转换为 `float32`。这通常是为了节省内存，因为 `float32`
    比使用 `float64` 使用更少的内存，但仍然为大多数深度学习任务提供足够的精度。'
- en: '`unwrapped_unet = accelerator.unwrap_model(unet)`: This unwraps the model from
    the accelerator, which is a wrapper used for distributed training.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unwrapped_unet = accelerator.unwrap_model(unet)`：这一行将模型从加速器中解包，加速器是一个用于分布式训练的包装器。'
- en: '`unet_lora_state_dict = convert_state_dict_to_diffusers(get_peft_model_state_dict(unwrapped_unet))`:
    This line gets the state dictionary of the model, which contains the weights of
    the model, and then converts it to a format suitable for Diffusers.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unet_lora_state_dict = convert_state_dict_to_diffusers(get_peft_model_state_dict(unwrapped_unet))`：这一行获取模型的权重状态字典，其中包含模型的权重，并将其转换为适合
    Diffusers 的格式。'
- en: '`weight_name = f"lora_{pretrained_model_name_or_path.split(''/'')[-1]}_rank{lora_rank}_s{max_train_steps}_r{resolution}_{diffusion_scheduler.__name__}_{formatted_date}.safetensors"`:
    This line creates a name for the file where the weights will be saved. The name
    includes various details about the training process.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`weight_name = f"lora_{pretrained_model_name_or_path.split(''/'')[-1]}_rank{lora_rank}_s{max_train_steps}_r{resolution}_{diffusion_scheduler.__name__}_{formatted_date}.safetensors"`：这一行创建了一个用于保存权重的文件名。该名称包含了关于训练过程的各种详细信息。'
- en: '`StableDiffusionPipeline.save_lora_weights(...)`: This line saves the weights
    of the model to a file. The `save_directory` argument specifies the directory
    where the file will be saved, `unet_lora_layers` is the state dictionary of the
    model, `safe_serialization` indicates that the weights should be saved in a way
    that is safe to load later, and `weight_name` is the name of the file.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`StableDiffusionPipeline.save_lora_weights(...)`：这一行将模型的权重保存到文件中。`save_directory`
    参数指定了文件将保存的目录，`unet_lora_layers` 是模型的权重状态字典，`safe_serialization` 表示权重应以安全的方式保存，以便以后加载，`weight_name`
    是文件的名称。'
- en: '`accelerator.end_training()`: This line signals the end of the training process.
    This is typically used to clean up resources used during training.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`accelerator.end_training()`：这一行表示训练过程的结束。这通常用于清理训练过程中使用的资源。'
- en: We have the complete training code in the associated code folder for this chapter,
    named `train_sd16_lora.py`. We are not done yet; we still need to kick off the
    training using the `accelerator` command instead of entering `python` `py_file.py`
    directly.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章的关联代码文件夹中提供了完整的训练代码，文件名为 `train_sd16_lora.py`。我们还没有完成；我们仍然需要使用 `accelerator`
    命令来启动训练，而不是直接输入 `python py_file.py`。
- en: Kicking off the training
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动训练
- en: 'If you have one GPU, simply run the following command:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你只有一个 GPU，只需运行以下命令：
- en: '[PRE45]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'For two GPUs, increase `--num_processes` to `2`, like this:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 对于两个 GPU，将 `--num_processes` 增加到 `2`，如下所示：
- en: '[PRE46]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'If you have more than two GPUs and want to train on assigned GPUs (e.g., you
    have three GPUs and want the training code run on the second and third GPUs),
    use this command:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有多于两个 GPU，并且想在指定的 GPU 上进行训练（例如，你有三个 GPU，并且想让训练代码在第二个和第三个 GPU 上运行），请使用以下命令：
- en: '[PRE47]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'To use the first and third GPUs, simply update the `CUDA_VISIBLE_DEVICES` settings
    to `0,2`, like this:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用第一个和第三个 GPU，只需更新 `CUDA_VISIBLE_DEVICES` 设置为 `0,2`，如下所示：
- en: '[PRE48]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Verifying the result
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证结果
- en: 'This is the most exciting moment to witness the power of model training. First,
    let’s load up the LoRA but set its weight to `0.0` with `adapter_weights = [``0.0]`:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 这是见证模型训练力量的最激动人心的时刻。首先，让我们加载LoRA，但将其权重设置为`0.0`，使用`adapter_weights = [0.0]`：
- en: '[PRE49]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Running the preceding code, we will get the images shown in *Figure 21**.1*:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 运行前面的代码，我们将得到*图21.1*中显示的图像：
- en: '![Figure 21.1: A toy bike, a macro photo, a 3D game asset, and an image generated
    without using LoRA](img/B21263_21_01.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![图21.1：玩具自行车、宏观照片、3D游戏资产以及未使用LoRA生成的图像](img/B21263_21_01.jpg)'
- en: 'Figure 21.1: A toy bike, a macro photo, a 3D game asset, and an image generated
    without using LoRA'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图21.1：玩具自行车、宏观照片、3D游戏资产以及未使用LoRA生成的图像
- en: 'The result is not that good. Now, let’s enable the trained LoRA with `adapter_weights
    = [1.0]`. Run the code again, and you should see the images shown in *Figure 21**.2*:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 结果并不那么好。现在，让我们启用训练好的LoRA，使用`adapter_weights = [1.0]`。再次运行代码，你应该会看到*图21.2*中显示的图像：
- en: "![Figure 21.2: A toy bike, a macro photo, a 3D game asset, and an image generated\
    \ with LoRA training using eight images\uFEFF](img/B21263_21_02.jpg)"
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![图21.2：玩具自行车、宏观照片、3D游戏资产以及使用八张图像进行LoRA训练生成的图像](img/B21263_21_02.jpg)'
- en: 'Figure 21.2: A toy bike, a macro photo, a 3D game asset, and an image generated
    with LoRA training using eight images'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图21.2：玩具自行车、宏观照片、3D游戏资产以及使用八张图像进行LoRA训练生成的图像
- en: The result is way better than the images without using the LoRA! If you see
    similar results, congratulations!
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 结果比未使用LoRA的图像好得多！如果你看到类似的结果，恭喜你！
- en: Summary
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This has been a long chapter, but learning about the power of model training
    is worth the length. Once we have mastered the training skill, we can train any
    models based on our needs. The whole training process isn’t easy, as there are
    so many details and trivial things to deal with. However, writing the training
    code is the only way to fully understand how model training works; considering
    the fruitful outcome, it is worth spending time to figure it out from the bottom
    up.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一章内容丰富的章节，但了解模型训练的强大功能是值得这一长度的。一旦我们掌握了训练技能，我们就可以根据我们的需求训练任何模型。整个训练过程并不容易，因为有太多细节和琐碎的事情要处理。然而，编写训练代码是全面理解模型训练工作原理的唯一方法；考虑到丰硕的成果，花时间从底层弄清楚它是值得的。
- en: Due to the length limitation of one chapter, I can only cover the entire LoRA
    training process, but once you succeed with LoRA training, you can find more training
    samples from Diffusers, change the code based on your specific needs, or simply
    write your training code, especially if you are working on a new model’s architecture.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 由于章节长度的限制，我只能说整个LoRA训练过程，但一旦你在LoRA训练中取得成功，你可以在Diffusers中找到更多的训练样本，根据你的具体需求更改代码，或者简单地编写你的训练代码，尤其是如果你正在开发一个新模型的架构。
- en: In this chapter, we began by training one simple model; the model itself isn’t
    that interesting, but it helped you to understand the core steps of model training
    using PyTorch. Then, we moved on to leverage the Accelerator package to train
    a model in multiple GPUs. Finally, we touched on the real Stable Diffusion model
    and trained a full-functioning LoRA, using simply eight images.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们首先训练了一个简单的模型；模型本身并不那么有趣，但它帮助你理解了使用PyTorch进行模型训练的核心步骤。然后，我们转向利用Accelerator包在多个GPU上训练模型。最后，我们触及了真实的Stable
    Diffusion模型，并使用仅八张图像训练了一个全功能的LoRA。
- en: In the next and final chapter, we’ll discuss something less technical, AI, and
    its relationship with us, privacy, and how to keep pace with its fast-changing
    advancements.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章和最后一章中，我们将讨论一些不那么技术性的内容，即人工智能及其与我们、隐私的关系，以及如何跟上其快速变化的进步。
- en: References
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'What is **Distributed Data Parallel** (**DDP**): [https://pytorch.org/tutorials/beginner/ddp_series_theory.html](https://pytorch.org/tutorials/beginner/ddp_series_theory.html)'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是**分布式数据并行**（**DDP**）：[https://pytorch.org/tutorials/beginner/ddp_series_theory.html](https://pytorch.org/tutorials/beginner/ddp_series_theory.html)
- en: 'Launch the LoRA training script: [https://huggingface.co/docs/diffusers/en/training/lora#launch-the-script](https://huggingface.co/docs/diffusers/en/training/lora#launch-the-script'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动LoRA训练脚本：[https://huggingface.co/docs/diffusers/en/training/lora#launch-the-script](https://huggingface.co/docs/diffusers/en/training/lora#launch-the-script)
- en: )
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'Hugging Face PEFT: [https://huggingface.co/docs/peft/en/index](https://huggingface.co/docs/peft/en/index)'
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hugging Face PEFT：[https://huggingface.co/docs/peft/en/index](https://huggingface.co/docs/peft/en/index)
- en: 'Hugging Face Accelerate: [https://huggingface.co/docs/accelerate/en/index](https://huggingface.co/docs/accelerate/en/index'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Hugging Face Accelerate：[https://huggingface.co/docs/accelerate/en/index](https://huggingface.co/docs/accelerate/en/index)
- en: )
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: )
