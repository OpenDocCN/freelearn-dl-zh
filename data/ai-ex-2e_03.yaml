- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Machine Intelligence – Evaluation Functions and Numerical Convergence
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器智能 – 评估函数和数值收敛
- en: Two issues appear when a reward matrix (*R*)-driven MDP produces results. These issues
    can be summed up in two principles.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当奖励矩阵 (*R*) 驱动的 MDP 产生结果时，会出现两个问题。这些问题可以总结为两个原则。
- en: '**Principle 1**: AI algorithms often surpass humans in classification, prediction,
    and decision-making areas.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**原则 1**：AI 算法通常在分类、预测和决策领域超越人类。'
- en: The key executive function of human intelligence, decision-making, relies on
    the ability to evaluate a situation. No decision can be made without measuring
    the pros and cons and factoring the parameters.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 人类智能的关键执行功能——决策依赖于评估情况的能力。没有衡量利弊和考虑参数的决策是无法做出的。
- en: Humanity takes great pride in its ability to evaluate. However, in many cases,
    a machine can do better. Chess represents our pride in our thinking ability. A chessboard
    is often present in movies to symbolize human intelligence.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 人类以其评估能力为荣。然而，在许多情况下，机器能够做得更好。国际象棋代表了我们对思维能力的自豪。电影中常常出现棋盘，象征着人类智慧。
- en: Today, not a single chess player can beat the best chess engines. One of the
    extraordinary core capabilities of a chess engine is the evaluation function;
    it takes many parameters into account more precisely than humans.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，没有一位棋手能够击败最强的国际象棋引擎。国际象棋引擎的一个非凡核心能力是评估函数；它比人类更精确地考虑了多个参数。
- en: '**Principle 2**: Principle 1 leads to a very tough consequence. It is sometimes
    possible and other times impossible for a human to verify the results that an
    AI algorithm produces, let alone ensemble meta-algorithms.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**原则 2**：原则 1 导致了一个非常棘手的后果。人类有时能够验证 AI 算法产生的结果，有时则无法验证，更不用说集成元算法了。'
- en: Principle 1 has been difficult to detect because of the media hype surrounding
    face and object recognition. It is easy for a human to check whether the face
    or object the ML algorithm was supposed to classify was correctly classified.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 原则 1 一直很难被检测到，因为面部和物体识别的媒体炒作。人类很容易检查 ML 算法是否正确分类了应该分类的面部或物体。
- en: However, in a decision-making process involving many features, principle 2 rapidly
    appears. In this chapter, we will identify what results and convergence to measure
    and decide how to measure it. We will also explore measurement and evaluation
    methods.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在涉及许多特征的决策过程中，原则 2 很快显现出来。在本章中，我们将识别要衡量的结果和收敛性，并决定如何衡量它。我们还将探索衡量和评估方法。
- en: 'This chapter covers the following topics:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涉及以下主题：
- en: Evaluation of the episodes of a learning session
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习会话的阶段评估
- en: Numerical convergence measurements
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值收敛测量
- en: An introduction to numerical gradient descent
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数值梯度下降简介
- en: Decision tree supervised learning as an evaluation method
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决策树监督学习作为一种评估方法
- en: The first thing is to set evaluation goals. To do this, we will decide what
    to measure and how.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 首先需要设定评估目标。为此，我们将决定衡量什么以及如何衡量。
- en: Tracking down what to measure and deciding how to measure it
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪需要衡量的内容并决定如何衡量
- en: We will now tackle the tough task of finding the factors that can make a system
    go wrong.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将着手解决一个棘手的任务，即找出可能导致系统出错的因素。
- en: 'The model built in the previous chapters can be summed up as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中构建的模型可以总结如下：
- en: '![](img/B15438_03_001.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_03_001.png)'
- en: From *l*[v], the availability vector (capacity in a warehouse, for example),
    to *R*, the process creates the reward matrix from the raw data (*Chapter 2*,
    *Building a Reward Matrix – Designing Your Datasets*) required for the MDP reinforcement
    learning program (*Chapter 1*, *Getting Started with Next-Generation Artificial
    Intelligence through Reinforcement Learning*). As described in the previous chapter,
    a softmax(*l*[v]) function is applied to *l*[v]. In turn, a one-hot(softmax(*l*[v]))
    is applied, which is then converted into the reward value *R*, which will be used
    for the *Q* (Q-learning) algorithm.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 从 *l*[v]（例如仓库中的容量）到 *R*，该过程从原始数据中创建奖励矩阵（*第2章*，*构建奖励矩阵 – 设计您的数据集*），这是 MD P 强化学习程序所需要的（*第1章*，*通过强化学习开始探索下一代人工智能*）。正如前一章所描述的，softmax(*l*[v])
    函数应用于 *l*[v]。接着，应用 one-hot(softmax(*l*[v]))，然后将其转换为奖励值 *R*，该值将用于 *Q*（Q-learning）算法。
- en: The MDP-driven Bellman equation then runs from reading *R* (the reward matrix)
    to the results. Gamma is the learning parameter, *Q* is the Q-learning function,
    and the results represent the final value of the states of the process.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: MDP驱动的贝尔曼方程然后从读取*R*（奖励矩阵）到结果运行。Gamma是学习参数，*Q*是Q学习函数，结果代表过程状态的最终值。
- en: 'The parameters to be measured are as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 测量的参数如下：
- en: The company's input data. Ready-to-use datasets such as MNIST are designed to
    be efficient for an exploration phase. These ready-made datasets often contain
    some noise (unreliable data) to make them realistic. The same process must be
    achieved with raw company data. The only problem is that you cannot download a
    corporate dataset from somewhere. You have to build time-consuming datasets.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公司的输入数据。像MNIST这样的现成数据集被设计为在探索阶段高效使用。这些现成的数据集通常包含一些噪音（不可靠的数据），以使它们更真实。同样的过程必须通过原始公司数据完成。唯一的问题是你无法从某个地方下载公司数据集。你必须构建耗时的数据集。
- en: The weights and biases that will be applied.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将应用的权重和偏差。
- en: The activation function (a logistic function or other).
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激活函数（逻辑函数或其他）。
- en: The choices to make after the one-hot process.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在单热过程后要做出的选择。
- en: The learning parameter.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习参数。
- en: Episode management through convergence.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过收敛进行剧集管理。
- en: A verification process through interactive random checks and independent algorithms
    such as supervised learning to control unsupervised algorithms.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过交互式随机检查和独立算法（如监督学习）的验证过程来控制无监督算法。
- en: In real-life company projects, a system will not be approved until tens of thousands
    of results have been produced. In some cases, a corporation will approve the system
    only after hundreds of datasets with millions of data samples have been tested
    to be sure that all scenarios are accurate. Each dataset represents a scenario
    that consultants can work on with parameter scripts. The consultant introduces
    parameter scenarios that are tested by the system and measured. In decision-making
    systems with up to 200 parameters, a consultant will remain necessary for months
    in an industrial environment. A reinforcement learning program will be on its
    own to calculate events. However, even then, consultants are needed to manage
    the hyperparameters. In real-life systems, with high financial stakes, quality
    control will always remain essential.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在真实的公司项目中，一个系统在生产出数以万计的结果之前将不会被批准。在某些情况下，只有在测试了数百个数据集并有数百万数据样本的情况下，公司才会批准系统以确保所有场景都准确。每个数据集代表顾问可以使用参数脚本进行工作的一个场景。顾问引入由系统测试和测量的参数场景。在具有多达200个参数的决策系统中，在工业环境中，顾问将需要几个月的时间。强化学习程序将独自计算事件。然而，即便如此，顾问在管理超参数时仍然是必要的。在真实的具有高财务风险的系统中，质量控制将始终是必不可少的。
- en: Measurement should thus apply to generalization more than simply applying to
    a single or few datasets. Otherwise, you will have a natural tendency to control
    the parameters and overfit your model in a too-good-to-be-true scenario.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 测量因此应更多地适用于泛化，而不仅仅适用于单个或少数数据集。否则，你会有一种自然倾向来控制参数，并在太好以至于不真实的场景中过拟合你的模型。
- en: For example, say you wake up one morning and look at the sky. The weather is
    clear, the sun is shining, and there are no clouds. The next day, you wake up
    and you see the same weather. You write this down in a dataset and send it off
    to a customer for weather prediction. Every time the customer runs the program,
    it predicts clear sunny skies! That what overfitting leads to! This explains why
    we need large datasets to fully understand how to use an algorithm or illustrate
    how a machine learning program works.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你早上醒来，看到天空晴朗，阳光明媚，没有云。第二天你醒来，看到同样的天气。你将这些记录在数据集中，并发送给客户进行天气预测。每次客户运行程序时，它都预测天气晴朗！这就是过拟合导致的结果！这解释了为什么我们需要大量数据集来充分理解如何使用算法或说明机器学习程序的工作原理。
- en: 'Beyond the reward matrix, the reinforcement program in the first chapter had
    a learning parameter ![](img/B15438_03_003.png), shown in `mdp03.py`, which is
    used for this section:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 除了奖励矩阵之外，第一章的强化程序有一个学习参数！[](img/B15438_03_003.png)，在`mdp03.py`中显示，用于本节：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The ![](img/B15438_03_004.png) learning parameter in itself needs to be closely
    monitored because it introduces uncertainty into the system. This means that the
    learning process will always remain a probability, never a certainty. One might
    wonder why this parameter is not just taken out. Paradoxically, that will lead
    to even more global uncertainty. The more the ![](img/B15438_03_004.png) learning
    parameter tends to 1, the more you risk overfitting your results. Overfitting
    means that you are pushing the system to think it's learning well when it isn't.
    It's exactly like a teacher who gives high grades to everyone in the class all
    the time. The teacher would be overfitting the grade-student evaluation process,
    and nobody would know whether the students have learned anything.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B15438_03_004.png)学习参数本身需要被密切监控，因为它为系统引入了不确定性。这意味着学习过程始终保持一种概率性，永远无法确定。有人可能会想，为什么不干脆去除这个参数。矛盾的是，这样做反而会导致更大的全局不确定性。![](img/B15438_03_004.png)学习参数越接近1，你就越有可能使结果过拟合。过拟合意味着你让系统认为它在学习得很好，实际上并非如此。就像一位老师总是给班上每个学生都打高分一样。老师实际上是在过度拟合成绩与学生表现的评估过程，结果大家都不知道学生是否真的学到了东西。'
- en: The results of the reinforcement program need to be measured as they go through
    episodes. The range of the learning process itself must be measured.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 强化程序的结果需要在每次训练中进行衡量。学习过程本身的范围也必须被测量。
- en: All of these measurements will have a significant effect on the results obtained.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些测量都将对获得的结果产生重要影响。
- en: The best way to start is by measuring the quality of convergence of the system.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的开始方法是通过测量系统的收敛质量。
- en: If the system provides good convergence, you might avoid the headache of having
    to go back and check everything.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果系统提供了良好的收敛性，你可能会避免重新检查一切的麻烦。
- en: Convergence
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 收敛
- en: Convergence measures the distance between the present state of a training session
    and the goal of the training session. In a reinforcement learning program, an
    MDP, for example, there is no training data, so there is no target data to compare
    to.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 收敛度衡量的是训练会话当前状态与目标之间的距离。在强化学习程序中，例如在马尔可夫决策过程（MDP）中，并没有训练数据，因此也没有目标数据可以进行比较。
- en: 'However, two methods are available:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有两种方法可以选择：
- en: '**Implicit convergence**: In this case, we run the training for a large number
    of episodes, 50,000, for example. We know through trial and error that the program
    will reach a solution by then.'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**隐式收敛**：在这种情况下，我们运行大量的训练轮次，例如50,000次。通过反复试验，我们知道程序到那时会找到一个解决方案。'
- en: '**Numerically controlled gradient descent**: We measure the training progress
    at each episode and stop when it is safe to do so.'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数值控制梯度下降**：我们在每次训练中测量进展，并在安全的情况下停止训练。'
- en: Implicit convergence
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 隐式收敛
- en: In the last part of `mdp01.py` in the first chapter, a range of 50,000 was implemented.
    In this chapter, we will run `mdp03.py`.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章的`mdp01.py`最后部分，实现了50,000的范围。在这一章中，我们将运行`mdp03.py`。
- en: 'In the last part of `mdp01.py`, the idea was to set the number of episodes
    at such a level that meant that convergence was certain. In the following code,
    the range (`50000`) is a constant:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在`mdp01.py`的最后部分，设置了一个使得收敛得以保证的训练轮次。在下面的代码中，范围（`50000`）是一个常量：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Convergence, in this case, will be defined as the point at which no matter how
    long you run the system, the `Q` result matrix will not change anymore.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，收敛将定义为无论你运行系统多长时间，`Q`结果矩阵将不再发生变化。
- en: By setting the range to `50000`, you can test and verify this. As long as the
    reward matrices remain homogeneous, this will work. If the reward matrices strongly
    vary from one scenario to another, this model will produce unstable results.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过设置范围为`50000`，你可以进行测试和验证。只要奖励矩阵保持一致性，这样的方法就有效。如果奖励矩阵在不同情境中有较大变化，这个模型将会产生不稳定的结果。
- en: Try to run the program with different ranges. Lower the ranges until you see
    that the results are not optimal.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用不同的范围运行程序。逐渐降低范围，直到你发现结果不再最优。
- en: Numerically controlled gradient descent convergence
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数值控制梯度下降收敛
- en: 'In this section, we will use `mdp03.py`, a modified version of `mdp01.py` explored
    in *Chapter 1*, with an additional function: numerically controlled gradient descent.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我们将使用`mdp03.py`，它是`mdp01.py`在*第一章*中的修改版，并增加了一个新功能：数值控制梯度下降。
- en: Letting the MDP train for 50,000 will produce a good result but consume unnecessary
    CPU. Using a numerically controlled gradient descent evaluation function will
    save a lot of episodes. Let's see how many.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让 MDP 训练 50,000 次会得到不错的结果，但会消耗不必要的 CPU。使用数值控制的梯度下降评估函数可以节省大量轮次。让我们看看节省了多少。
- en: First, we need to define the gradient descent function based on a derivative.
    Let's have a quick review of what a derivative is.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要基于导数定义梯度下降函数。让我们快速回顾一下什么是导数。
- en: '![](img/B15438_03_006.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_03_006.png)'
- en: '*h* is the value of the step of the function. Imagine that *h* represents each
    line of a bank account statement. If we read the statement line by line, *h* =
    1\. If we read two lines at a time, *h* = 2.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*h* 是函数步长的值。想象 *h* 代表银行账户对账单的每一行。如果我们逐行阅读对账单，*h* = 1。如果我们每次读两行，*h* = 2。'
- en: Reading the present line of the bank account statement = *f*(*x*) = *a certain
    amount*.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读银行账户对账单的当前行 = *f*(*x*) = *某个数额*。
- en: When you read the next line of the bank account, the function is (*f* + *h*)
    = *the amount after f*(*x*). If you had 100 units of currency in your bank account
    at *f*(*x*) and spent 10 units of currency, on the next line, *x* + *h*, you would
    have *f*(*x* + *h*) = *90 units of currency* left.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当你阅读银行账户的下一行时，函数是 (*f* + *h*) = *f*(*x*) 后的数额。如果你的银行账户在 *f*(*x*) 时有 100 个货币单位，并且花费了
    10 个货币单位，那么在下一行，*x* + *h*，你将剩下 *f*(*x* + *h*) = *90 个货币单位*。
- en: 'The gradient provides the direction of your slope: up, down, or constant. In
    this case, we can say that the slope, the **gradient**, is doing downward, as
    shown in the following graph, which illustrates the decreasing values of *y*(cost,
    loss) as *x* increases (training episodes):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度提供了你的斜率方向：向上、向下或保持不变。在这种情况下，我们可以说斜率，即**梯度**，正在向下，如下图所示，图中展示了随着 *x* 增加（训练轮次），*y*（成本、损失）的值逐渐减少：
- en: '![](img/B15438_03_01.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_03_01.png)'
- en: 'Figure 3.1: Plotting the decreasing cost/loss values as training episodes increase'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1：随着训练轮次增加，成本/损失值逐渐减少的图示
- en: We also need to know by how much your bank account is changing – how much the
    **derivative** is worth. In this case, derivative means by how much the balance
    of your bank account is changing on each line of your bank statement. In this
    case, you spent 10 units of currency in one bank statement line, so the derivative
    at this value of *x* (line in your bank account) = –10.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要知道你的银行账户正在发生多大的变化——**导数**的值是多少。在这种情况下，导数意味着在你的银行账户对账单的每一行中，余额变化了多少。在这个例子中，你在一行对账单上花费了
    10 个货币单位，所以在该 *x*（银行账户中的行）处的导数 = –10。
- en: 'In the following code of the Bellman equation as seen in *Chapter 1*, *Getting
    Started with Next-Generation Artifcial Intelligence through Reinforcement Learning*,
    the step of the loop is 1 as well:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在《第一章，使用强化学习开始下一代人工智能》中的贝尔曼方程代码中，循环步长也是 1：
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Since *i* = 1, *h* = 1 in our gradient descent calculation can be simplified:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 *i* = 1，*h* = 1，在我们的梯度下降计算中可以简化为：
- en: '![](img/B15438_03_007.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_03_007.png)'
- en: 'We now define *f*(*x*) in the following code:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在在以下代码中定义 *f*(*x*)：
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`conv` is the sum of the 6×6 `Q` matrix that is slowly filling up as the MDP
    training progresses. Thus *f*(*x*) = `conv=Q.sum()` = sum of `Q`. The function
    adds up all the values in `Q` to have a precise value of the state of the system
    at each *i*.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`conv` 是 6×6 的 `Q` 矩阵的总和，随着 MDP 训练的进展，它逐渐填充。因此 *f*(*x*) = `conv=Q.sum()` =
    `Q` 的总和。该函数将 `Q` 中的所有值加起来，以精确地表示系统在每个 *i* 时的状态。'
- en: '*f*(*x*) = the state of the system at *i* – 1'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*f*(*x*) = 系统在 *i* – 1 时的状态'
- en: '*f*(*x* + 1) is the value of the system at *i*:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*f*(*x* + 1) 是系统在 *i* 时的值：'
- en: '[PRE4]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We must remember that the `Q` matrix is increasing progressively as the MDP
    process continues to train. We measure the distance between two steps, *h*. This
    distance will decrease. Now we have:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须记住，随着 MDP 训练过程的进行，`Q` 矩阵正在逐渐增加。我们测量两步之间的距离，*h*。这个距离会减小。现在我们有：
- en: '*f*(*x* + 1) – *f*(*x*) = `-Q.sum()+conv`'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*f*(*x* + 1) – *f*(*x*) = `-Q.sum()+conv`'
- en: 'First we implement additional variables for our evaluation function, which
    uses gradient descent at line 83 of `mdp01.py`:'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们为评估函数实现额外的变量，该函数在 `mdp01.py` 的第 83 行使用梯度下降：
- en: '[PRE5]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`nc=1` activates the evaluation function, and `ci` begins to count the episodes
    it will take with this function:'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nc=1` 激活评估函数，`ci` 开始计数此函数所需的轮次：'
- en: '[PRE6]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'At the first episode, `i==1`, *f*(*x*)= `Q.sum()` as planned:'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第一次训练轮次，`i==1`，*f*(*x*)= `Q.sum()`，如预期所示：
- en: '[PRE7]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '*f*(*x* + 1) = `-Q.sum()+conv` is applied:'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*f*(*x* + 1) = `-Q.sum()+conv` 被应用：'
- en: '[PRE8]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The distance, the absolute value of the derivative, is displayed and stored
    because we will be using it to plot a figure with Matplotlib:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 距离，导数的绝对值，会被显示并存储，因为我们将使用它来用Matplotlib绘制图形：
- en: '[PRE9]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`xi=100` plays a critical role in this numerically controlled gradient descent
    function. Every `xi`, the process stops to check the status of the training process:'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`xi=100`在这个数值控制的梯度下降函数中起着关键作用。每次`xi`，过程都会暂停检查训练过程的状态：'
- en: '[PRE10]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'There are two possible cases: **a)** and **b)**.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种可能的情况：**a)** 和 **b)**。
- en: '**Case a)** As long as the local derivative is >0 at each episode, the MDP
    continues its training process:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**情况a)** 只要每个回合的局部导数>0，MDP就会继续训练过程：'
- en: '[PRE11]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The output will display varying local derivatives:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将显示不同的局部导数：
- en: '[PRE12]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Case b)** When the derivative value reaches a constant value for `xi` episodes,
    the MDP has been trained and the training can now stop:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**情况b)** 当导数值在`xi`回合后达到一个常数值时，MDP已经训练完成，训练可以停止：'
- en: '[PRE13]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output will display a constant derivate, `xi`, before the training stops:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将显示一个常数导数，`xi`，在训练停止之前：
- en: '[PRE14]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'When the training is over, the number of training episodes is displayed:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练结束时，将显示训练回合的数量：
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 2,099 is a lot less than the 50,000 implicit convergence episodes, which proves
    the efficiency of this numerically controlled gradient descent method.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 2,099远小于50,000个隐式收敛回合，这证明了该数值控制的梯度下降方法的效率。
- en: 'At the end of the learning process, you can display a Matplotlib figure containing
    the convergence level of each episode that we had stored in `cq=ql.zeros((2500,
    1))`:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习过程结束时，你可以显示一个包含我们在`cq=ql.zeros((2500, 1))`中存储的每个回合收敛水平的Matplotlib图：
- en: '[PRE16]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The figure is displayed with a few lines of code:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 该图形由几行代码显示：
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![Une image contenant capture d’écran  Description générée automatiquement](img/B15438_03_02.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![Une image contenant capture d’écran  Description générée automatiquement](img/B15438_03_02.png)'
- en: 'Figure 3.2: A plot demonstrating numerical convergence'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2：演示数值收敛性的图
- en: This graph shows the numerical convergence. As you can see in the graph, the
    cost or loss decreases as the number of training episodes increases, as explained
    earlier in this chapter.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 该图显示了数值收敛性。如图中所示，随着训练回合数的增加，成本或损失下降，正如本章前面所解释的那样。
- en: 'Please note the following properties of this gradient descent method:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意该梯度下降方法的以下属性：
- en: The number of episodes will vary from one training session to another because
    the MDP is a random process.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回合数会因为MDP是一个随机过程而在不同的训练会话中有所变化。
- en: The training curve at local episodes is sometimes erratic because of the random
    nature of the training process. Sometimes, the curve will go up instead of down
    locally. In the end, it will reach 0 and stay there.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于训练过程的随机性，局部回合的训练曲线有时会波动。有时，曲线局部上升而非下降。最终，它会达到0并保持在那里。
- en: If the training curve increases locally, there is nothing you can do. An MDP
    does no backpropagation to modify weights, parameters, or strategies, as we will
    see when we look at artificial neural networks (ANNs), for example, in *Chapter
    8*, *Solving the XOR Problem with a Feedforward Neural Network*. No action is
    required in an MDP process. You can try to change the learning rate or go back
    and check your reward matrix and the preprocessing phase implemented on the raw
    datasets.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果训练曲线局部上升，没什么可以做的。MDP不会进行反向传播来修改权重、参数或策略，正如我们在*第8章*“用前馈神经网络解决XOR问题”中看到的那样。MDP过程不需要任何操作。你可以尝试更改学习率，或者回去检查你的奖励矩阵和在原始数据集上实施的预处理阶段。
- en: If the training curve does not reach 0 and stay there, check the learning parameters,
    the reward matrix, and the preprocessing phase implemented on the raw datasets.
    You might even have to go back and check the noise (defective data or missing
    data) in the initial datasets.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果训练曲线没有达到0并保持在那里，请检查学习参数、奖励矩阵和在原始数据集上实施的预处理阶段。你甚至可能需要回去检查初始数据集中的噪声（缺陷数据或缺失数据）。
- en: 'Once the MDP training is over, do some random tests using the functionality
    provided at line 145 and explained in *Chapter 1*:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦MDP训练完成，使用第145行提供的功能进行一些随机测试，该功能在*第1章*中有所解释：
- en: '[PRE18]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'For example, when prompted for an input, enter `1` and see if the result is
    correct, as shown in the following output:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当提示输入时，输入`1`并查看结果是否正确，如以下输出所示：
- en: '[PRE19]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This random test verification method will work efficiently with a relatively
    small reward matrix.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这种随机测试验证方法在相对较小的奖励矩阵下能有效工作。
- en: However, this approach will prove difficult with a size 25×25 reward matrix,
    for example. The machine easily provides a result. But how can we evaluate it?
    In that case, we have reached the limit of human analytic capacity. In the preceding
    code, we entered a starting point and obtained an answer. With a small reward
    matrix, it is easy to visually check and see if the answer is correct. When analyzing
    25 × 25 = 625 cells, it would take days to verify the results. For the record,
    bear in mind that when Andrey Markov invented his approach over 100 years ago,
    he used a pen and paper! However, we have computers, so we must use an evaluation
    algorithm to evaluate the results of our MDP process.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于一个 25×25 的奖励矩阵，这种方法就会变得困难。例如，机器可以轻松给出一个结果。但我们如何评估这个结果呢？在这种情况下，我们已经达到了人类分析能力的极限。在之前的代码中，我们输入了一个起始点并得到了答案。对于一个小的奖励矩阵，我们可以轻松地进行视觉检查，看看答案是否正确。然而，当分析
    25×25 = 625 个格子时，需要几天时间来验证结果。值得一提的是，当安德烈·马尔可夫在100多年前发明他的算法时，他使用的是纸和笔！然而，今天我们有计算机，所以我们必须使用评估算法来评估我们的马尔可夫决策过程（MDP）的结果。
- en: The increasing volumes of data and parameters in a global world have made it
    impossible for humans to outperform the ever-growing intelligence of machines.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在全球化的世界中，数据和参数的不断增加使得人类无法超越机器日益增长的智能。
- en: Evaluating beyond human analytic capacity
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越人类分析能力的评估
- en: An efficient manager has a high evaluation quotient. A machine often has a better
    one in an increasing number of fields. The problem for a human is to understand
    the evaluation machine intelligence has produced.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 一位高效的管理者拥有较高的评估商数。在越来越多的领域中，机器往往有更高的评估商数。人类面临的问题是理解机器产生的评估结果。
- en: Sometimes a human will say "that's a good machine thinking result" or "that's
    a bad result," without being able to explain why or determine whether there is
    a better solution.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 有时人类会说“这是一种很好的机器思维结果”或“这是一个糟糕的结果”，但却无法解释为什么，或判断是否有更好的解决方案。
- en: 'Evaluation is one of the major keys to efficient decision-making in all fields:
    from chess, production management, rocket launching, and self-driving cars to
    data center calibration, software development, and airport schedules.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 评估是所有领域中高效决策的关键之一：从国际象棋、生产管理、火箭发射、自驾车，到数据中心校准、软件开发、机场调度等。
- en: We'll explore a chess scenario to illustrate the limits of human evaluation.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过一个国际象棋的场景来展示人类评估的极限。
- en: Chess engines are not high-level deep learning-based software. They rely heavily
    on evaluations and calculations. They evaluate much better than humans, and there
    is a lot to learn from them. The question now is to know whether any human can
    beat a chess engine or not. The answer is no.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 国际象棋引擎并非基于高水平深度学习的软件。它们高度依赖于评估和计算。它们的评估能力远超人类，而且从它们身上有很多值得学习的地方。现在的问题是，是否有人类能够战胜国际象棋引擎？答案是否定的。
- en: To evaluate a position in chess, you need to examine all the pieces, their quantitative
    value, their qualitative value, the cooperation between pieces, who owns each
    of the 64 squares, the king's safety, the bishop pairs, the knight positioning,
    and many other factors.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 要评估国际象棋中的局面，你需要检查所有棋子，它们的定量价值、定性价值、棋子之间的协作、谁占据了64个格子中的每一个、国王的安全、主教对、骑士的位置，以及许多其他因素。
- en: Evaluating a position in a chess game shows why machines are surpassing humans
    in quite a few decision-making fields.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在国际象棋比赛中评估一个局面，显示了为什么机器在许多决策领域超过了人类。
- en: The following scenario is after move 23 in the Kramnik-Bluebaum 2017 game. It cannot
    be correctly evaluated by humans. It contains too many parameters to analyze and
    too many possibilities.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 以下场景是在2017年克拉姆尼克与布鲁鲍姆对局后的第23步。人类无法正确评估这个局面。它包含了太多的参数和可能性，无法进行分析。
- en: '![https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_03_4-1-298x300.png](img/B15438_03_03.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_03_4-1-298x300.png](img/B15438_03_03.png)'
- en: 'Figure 3.3: Chess example scenario'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3：国际象棋示例场景
- en: It is white's turn to play, and a close analysis shows that both players are
    lost at this point. In a tournament like this, they must each continue to keep
    a poker face. They often look at their position with a confident face to hide
    their dismay. Some even shorten their thinking time to make their opponent think
    they know where they are going.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在轮到白方走棋，经过仔细分析，发现此时两位选手都处于困境。在这样的比赛中，他们必须继续保持扑克脸。他们常常以自信的表情看着自己的棋盘，以掩饰内心的沮丧。有些人甚至缩短思考时间，让对手以为他们知道接下来的棋路。
- en: These unsolvable positions for humans are painless to solve with chess engines,
    even for cheap, high-quality chess engines on a smartphone. This can be generalized
    to all human activity that has become increasingly complex, unpredictable, and
    chaotic. Decision-makers will increasingly rely on AI to help them make the right
    choices.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这些对人类来说无法解决的局面，对于国际象棋引擎来说是轻松解决的，即使是智能手机上的廉价高质量国际象棋引擎也能轻松应对。这可以推广到所有日益复杂、不可预测和混乱的人类活动。决策者将越来越依赖人工智能来帮助他们做出正确的选择。
- en: No human can play chess and evaluate the way a chess engine does by simply calculating
    the positions of the pieces, their squares of liberty, and many other parameters.
    A chess engine generates an evaluation matrix with millions of calculations.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任何人能够像国际象棋引擎那样通过简单地计算棋子的摆放位置、自由格以及其他许多参数来评估棋局。国际象棋引擎通过数百万次计算生成评估矩阵。
- en: The following table is the result of an evaluation of only one position among
    many others (real and potential).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格是对多个位置中的一个位置（实际和潜在）进行评估的结果。
- en: '| **Position evaluated** | **0,3** |  |  |  |  |  |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| **局面评估** | **0,3** |  |  |  |  |  |'
- en: '| **White** | **34** |  |  |  |  |  |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| **白方** | **34** |  |  |  |  |  |'
- en: '|  | **Initial position** | **Position** | **Value** |  | **Quality Value**
    | **Total Value** |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '|  | **初始位置** | **位置** | **价值** |  | **质量值** | **总价值** |'
- en: '| **Pawn** | a2 | a2 | 1 | a2-b2 small pawn island | 0,05 | 1,05 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | a2 | a2 | 1 | a2-b2 小兵岛 | 0,05 | 1,05 |'
- en: '| **Pawn** | b2 | b2 | 1 | a2-b2 small pawn island | 0,05 | 1,05 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | b2 | b2 | 1 | a2-b2 小兵岛 | 0,05 | 1,05 |'
- en: '| **Pawn** | c2 | x | 0 | Captured | 0 | 0 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | c2 | x | 0 | 被吃掉 | 0 | 0 |'
- en: '| **Pawn** | d2 | d4 | 1 | Occupies center, defends Be5 | 0,25 | 1,25 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | d2 | d4 | 1 | 占据中心，防守 Be5 | 0,25 | 1,25 |'
- en: '| **Pawn** | e2 | e2 | 1 | Defends Qf3 | 0,25 | 1,25 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | e2 | e2 | 1 | 防守 Qf3 | 0,25 | 1,25 |'
- en: '| **Pawn** | f2 | x | 0 | Captured | 0 | 0 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | f2 | x | 0 | 被吃掉 | 0 | 0 |'
- en: '| **Pawn** | g2 | g5 | 1 | Unattacked, attacking 2 squares | 0,3 | 1,3 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | g2 | g5 | 1 | 未受攻击，攻击 2 格 | 0,3 | 1,3 |'
- en: '| **Pawn** | h2 | h3 | 1 | Unattacked, defending g4 | 0,1 | 1,1 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | h2 | h3 | 1 | 未受攻击，防守 g4 | 0,1 | 1,1 |'
- en: '| **Rook** | a1 | c1 | 5 | Occupying c-file, attacking b7 with Nd5-Be5 | 1
    | 6 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| **车** | a1 | c1 | 5 | 占据 c 文件，攻击 b7 配合 Nd5-Be5 | 1 | 6 |'
- en: '| **Knight** | b1 | d5 | 3 | Attacking Nb6, 8 squares | 0,5 | 3,5 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| **骑士** | b1 | d5 | 3 | 攻击 Nb6，8 格 | 0,5 | 3,5 |'
- en: '| **BishopDS** | c1 | e5 | 3 | Central position, 10 squares, attacking c7 |
    0,5 | 3,5 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| **主教DS** | c1 | e5 | 3 | 中央位置，10格，攻击 c7 | 0,5 | 3,5 |'
- en: '| **Queen** | d1 | f3 | 9 | Battery with Bg2, defending Ne5, X-Ray b7 | 1 |
    11 |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| **皇后** | d1 | f3 | 9 | 配合 Bg2 的电池，防守 Ne5，X 射线攻击 b7 | 1 | 11 |'
- en: '| **King** | e1 | h1 | 0 | X-rayed by Bb6 on a7-g1 diagonal | -0,5 | -0,5 |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| **国王** | e1 | h1 | 0 | 被 Bb6 在 a7-g1 对角线上 X 射线攻击 | -0,5 | -0,5 |'
- en: '| **BishopWS** | f1 | g2 | 3 | Supporting Qf3 in defense and attack | 0,5 |
    3,5 |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| **主教WS** | f1 | g2 | 3 | 支援 Qf3 防守与攻击 | 0,5 | 3,5 |'
- en: '| **Knight** | g1 | x | 0 | Captured | 0 | 0 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| **骑士** | g1 | x | 0 | 被吃掉 | 0 | 0 |'
- en: '| **Rook** | h1 | x | 0 | Captured | 0 | 0 |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| **车** | h1 | x | 0 | 被吃掉 | 0 | 0 |'
- en: '|  |  |  | 29 |  | 5 | 34 |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 29 |  | 5 | 34 |'
- en: '|  |  |  |  |  |  | White: 34 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  |  |  | 白方：34 |'
- en: The value of the position of white is 34.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 白方的位置价值为 34。
- en: '| **White** | **34** |  |  |  |  |  |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| **白方** | **34** |  |  |  |  |  |'
- en: '| **Black** | **33,7** |  |  |  |  |  |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| **黑方** | **33,7** |  |  |  |  |  |'
- en: '|  | **Initial position** | **Position** | **Value** |  | **Quality Value**
    | **Total Value** |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '|  | **初始位置** | **位置** | **价值** |  | **质量值** | **总价值** |'
- en: '| **Pawn** | a7 | a7 | 1 | a7-b7 small pawn island | 0,05 | 1,05 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | a7 | a7 | 1 | a7-b7 小兵岛 | 0,05 | 1,05 |'
- en: '| **Pawn** | b7 | b7 | 1 | a7-b7 small pawn island | 0,05 | 1,05 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | b7 | b7 | 1 | a7-b7 小兵岛 | 0,05 | 1,05 |'
- en: '| **Pawn** | c7 | x | 0 | Captured | 0 | 0 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | c7 | x | 0 | 被吃掉 | 0 | 0 |'
- en: '| **Pawn** | d7 | x | 0 | Captured | 0 | 0 |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | d7 | x | 0 | 被吃掉 | 0 | 0 |'
- en: '| **Pawn** | e7 | f5 | 1 | Doubled, 2 squares | 0 | 1 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | e7 | f5 | 1 | 叠加，2 格 | 0 | 1 |'
- en: '| **Pawn** | f7 | f7 | 1 |  | 0 | 1 |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | f7 | f7 | 1 |  | 0 | 1 |'
- en: '| **Pawn** | g7 | g6 | 1 | Defending f5 but abandoning Kg8 | 0 | 1 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | g7 | g6 | 1 | 防守 f5 但放弃 Kg8 | 0 | 1 |'
- en: '| **Pawn** | h7 | h5 | 1 | Well advanced with f5,g6 | 0,1 | 1,1 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| **兵** | h7 | h5 | 1 | 前进良好，配合 f5,g6 | 0,1 | 1,1 |'
- en: '| **Rook** | a8 | d8 | 5 | Semi-open d-file attacking Nd5 | 2 | 7 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| **车** | a8 | d8 | 5 | 半开放的 d 文件，攻击 Nd5 | 2 | 7 |'
- en: '| **Knight** | b8 | x | 0 | Captured | 0 | 0 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| **骑士** | b8 | x | 0 | 被吃掉 | 0 | 0 |'
- en: '| **BishopDS** | c8 | b6 | 3 | Attacking d4, 3 squares | 0,5 | 3,5 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| **主教DS** | c8 | b6 | 3 | 攻击 d4，3 格 | 0,5 | 3,5 |'
- en: '| **Queen** | d8 | e6 | 9 | Attacking d4,e5, a bit cramped | 1,5 | 10,5 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| **皇后** | d8 | e6 | 9 | 攻击 d4, e5，略显拥挤 | 1,5 | 10,5 |'
- en: '| **King** | e8 | g8 | 0 | f6,h6, g7,h8 attacked | -1 | -1 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| **国王** | e8 | g8 | 0 | f6,h6, g7,h8 受到攻击 | -1 | -1 |'
- en: '| **BishopWS** | f8 | x | 0 | Captured, white lost bishop pair | 0,5 | 0,5
    |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| **主教WS** | f8 | x | 0 | 被吃掉，白方失去主教对 | 0.5 | 0.5 |'
- en: '| **Knight** | g8 | e8 | 3 | Defending c7,f6,g7 | 1 | 4 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| **骑士** | g8 | e8 | 3 | 防守c7,f6,g7 | 1 | 4 |'
- en: '| **Rook** | h8 | f8 | 5 | Out of play | -2 | 3 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| **车** | h8 | f8 | 5 | 退出游戏 | -2 | 3 |'
- en: '|  |  |  | 31 |  | 2,7 | Black: 33,7 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 31 |  | 2,7 | 黑方：33,7 |'
- en: The value of black is 33.7.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 黑方的价值是33.7。
- en: So white is winning by 34 – 33.7 = 0.3.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 所以白方以34 – 33.7 = 0.3获胜。
- en: The evaluation system can easily be represented with two McCulloch-Pitts neurons,
    one for black and one for white. Each neuron would have 30 weights = {*w*[1],*w*[2]
    … *w*[30]}, as shown in the previous table. The sum of both neurons requires an
    activation function that converts the evaluation into 1/100th of a pawn, which
    is the standard measurement unit in chess. Each weight will be the output of squares
    and piece calculations. Then the MDP can be applied to Bellman's equation with
    a random generator of possible positions.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 评估系统可以通过两个麦卡洛克-皮茨神经元轻松表示，一个用于黑方，一个用于白方。每个神经元有30个权重 = {*w*[1],*w*[2] … *w*[30]}，如前表所示。两个神经元的总和需要一个激活函数，将评估值转换为1/100的棋子，这就是国际象棋的标准计量单位。每个权重将是方格和棋子计算的输出。然后，MDP可以应用到贝尔曼方程中，使用一个随机生成的可能位置。
- en: Present-day chess engines contain this type of brute calculation approach. They
    don't need more to beat humans.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现今的国际象棋引擎采用这种暴力计算的方法。它们不需要更多的东西就能击败人类。
- en: No human, not even world champions, can calculate these positions with this
    accuracy. The number of parameters to take into account overwhelms them each time
    they reach positions like these. They then play more or less randomly with a possibly
    good idea in mind. The chances of success against a chess engine resemble a lottery
    sometimes. Chess experts discover this when they run human-played games with powerful
    chess engines to see how the game plays out. The players themselves now tend to
    reveal their incapacity to provide a deep analysis when asked why they made a
    questionable move. It often takes hours to go through a game, its combinations
    and find the reasons of a bad move. In the end, the players will often use a machine
    to help them understand what happened.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 没有任何人类，即使是世界冠军，也无法以这种精度计算这些位置。需要考虑的参数数量每次都会让他们感到不堪重负，尤其当他们面对这样的局面时。然后，他们会带着或多或少的随机想法去走棋。与国际象棋引擎对弈的成功几率有时像是买彩票一样。国际象棋专家会在与强大棋引擎对弈时发现这一点，看看游戏如何展开。玩家们现在倾向于在被问及为何做出一个有争议的走法时，暴露出自己在提供深度分析上的无能。通常需要几个小时来回顾一局棋，分析其中的组合并找出错误走法的原因。最终，玩家们通常会借助机器来帮助他们理解发生了什么。
- en: The positions analyzed here represent only one possibility. A chess engine will
    test millions of possibilities. Humans can test only a few.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这里分析的位置仅代表一种可能性。国际象棋引擎会测试数百万种可能性。而人类只能测试其中的一小部分。
- en: Measuring a result like this has nothing to do with natural human thinking.
    Only machines can think like that. Not only do chess engines solve the problem,
    but they are also impossible to beat.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的结果测量与人类的自然思维无关。只有机器才能像这样思考。国际象棋引擎不仅能解决这个问题，而且是无法被打败的。
- en: '*Principle 1: At one point, there are problems humans face that only machines
    can solve.*'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '*原则1：在某些情况下，人类面临的问题只有机器才能解决。*'
- en: '*Principle 2: Sometimes, it will be possible to verify the result of an ML
    system, sometimes not. However, we must try to find ways to check the result.*'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '*原则2：有时，可以验证机器学习系统的结果，有时则不能。然而，我们必须努力找到验证结果的方法。*'
- en: One solution to solve the problem of principle 2 is to verify an unsupervised
    algorithm with a supervised algorithm through random samples.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 解决原则2问题的一种方法是通过随机样本使用监督算法验证无监督算法。
- en: Using supervised learning to evaluate a result that surpasses human analytic
    capacity
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用监督学习来评估超越人类分析能力的结果
- en: More often than not, an AI solution exceeds a human's capacity to analyze a
    situation in detail. It is often too difficult for a human to understand the millions
    of calculations a machine made to reach a conclusion and explain it. To solve
    that problem, another AI, ML, or DL algorithm will provide assisted AI capability.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 更常见的是，AI解决方案超出了人类在细节分析上的能力。人类往往很难理解机器为了得出结论所做的数百万次计算，并解释其中的过程。为了解决这个问题，另一种AI、机器学习或深度学习算法将提供辅助AI能力。
- en: 'Let''s suppose the following:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 假设如下情况：
- en: The raw data preprocessed by the neural approach of *Chapter 2*, *Building a
    Reward Matrix – Designing Your Datasets*, works fine. The reward matrix looks fine.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过*第 2 章*，*构建奖励矩阵 – 设计数据集*中的神经网络方法预处理的原始数据运行良好。奖励矩阵看起来没问题。
- en: The MDP-driven Bellman equation provides good reinforcement training results.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于 MDP 的贝尔曼方程提供了良好的强化学习训练结果。
- en: The convergence function and values work.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收敛函数和数值有效。
- en: The results on this dataset look satisfactory but the results are questioned.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在该数据集上的结果看起来令人满意，但结果仍然受到质疑。
- en: 'A manager or user will always come up with a killer question: how can you prove
    that this will work with other datasets in the future and confirm 100% that the
    results are reliable?'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 管理员或用户总会提出一个难题：如何证明这个方法在未来处理其他数据集时也有效，并且能够100%确认结果的可靠性？
- en: The only way to be sure that this whole system works is to run thousands of
    datasets with hundreds of thousands of product flows.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一能确保整个系统有效的方法是运行成千上万的数据集，涵盖数十万的产品流。
- en: The idea now is to use supervised learning to create an independent way of checking
    the results. One method is to use a decision tree to visualize some key aspects
    of the solution and be able to reassure the users and yourself that the system
    is reliable.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的想法是使用监督学习创建一种独立的方式来检查结果。一种方法是使用决策树来可视化解决方案的一些关键方面，从而能够安抚用户和自己，确保系统的可靠性。
- en: Decision trees provide a white box approach with powerful functionality. In
    this section, we will limit the exploration to an intuitive approach. In *Chapter
    5*, *How to Use Decision Trees to Enhance K-Means Clustering*, we will go into
    the theory of decision trees and random trees and explore more complex examples.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 决策树提供了一种白盒方法，具有强大的功能。在本节中，我们将限制探索为一种直观的方法。在*第 5 章*，*如何使用决策树增强 K-Means 聚类*中，我们将深入探讨决策树和随机树的理论，并探索更复杂的示例。
- en: In this model, the features of the input are analyzed so that we can classify
    them. The analysis can be transformed into decision trees depending on real-time
    data, to create a distribution representation to predict future outcomes.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在此模型中，输入的特征将被分析，以便我们进行分类。该分析可以根据实时数据转换为决策树，创建分布表示来预测未来结果。
- en: 'For this section, you can run the following program:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本节内容，你可以运行以下程序：
- en: '`Decision_Tree_Priority_classifier.py`'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`Decision_Tree_Priority_classifier.py`'
- en: 'Or the following Jupyter notebook on Google Colaboratory:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 或者在 Google Colaboratory 上运行以下 Jupyter notebook：
- en: '`DTCH03.ipynb`'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '`DTCH03.ipynb`'
- en: 'Google Colaboratory might have the two following packages installed:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Google Colaboratory 可能已经安装了以下两个软件包：
- en: '[PRE20]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: This could help you avoid installing them locally, which might take some time
    if you get a Graphviz requirement message.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以帮助你避免在本地安装它们，如果你收到 Graphviz 依赖的提示信息，这样做可能会节省一些时间。
- en: 'Both programs produce the same decision tree image:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 两个程序生成相同的决策树图像：
- en: '`warehouse_example_decision_tree.png`'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '`warehouse_example_decision_tree.png`'
- en: 'The intuitive description of this decision tree approach runs in 5 steps:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 该决策树方法的直观描述分为 5 个步骤：
- en: '**Step 1**: Represent the features of the incoming orders to store in a warehouse
    – for example:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 1**：表示进入仓库存储的订单特征，例如：'
- en: '[PRE21]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In this case, we will limit the model to three properties:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将模型限制为三个属性：
- en: Priority/location, which is the most important property in a warehouse flow
    in this model
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优先级/位置，这是该模型中仓库流程中最重要的属性
- en: Volumes to transport
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运输的体积
- en: Optimizing priority – the financial and customer satisfaction property
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化优先级 – 财务和客户满意度属性
- en: '**Step 2**: Provide priority labels for the learning dataset:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 2**：为学习数据集提供优先级标签：'
- en: '[PRE22]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '**Step 3**: Providing the dataset input matrix, which is the output matrix
    of the reinforcement learning program. The values have been approximated but are
    enough to run the model. They simulate some of the intermediate decisions and
    transformations that occur during the decision process (ratios applied, uncertainty
    factors added, and other parameters). The input matrix is `X`:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 3**：提供数据集输入矩阵，即强化学习程序的输出矩阵。虽然数值已被近似，但足以运行模型。它们模拟了决策过程中的一些中间决策和转换（应用的比例、不确定性因子以及其他参数）。输入矩阵为
    `X`：'
- en: '[PRE23]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The features in step 1 apply to each column.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 1 中的特征适用于每一列。
- en: The values in step 2 apply to every line.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤 2 中的数值适用于每一行。
- en: The values of the third column [0,1] are discrete indicators for the training
    session.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 第三列 [0,1] 的数值是训练会话中的离散指示符。
- en: '**Step 4**: Run a standard decision tree classifier. This classifier will distribute
    the representations (distributed representations) into two categories:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 4**：运行标准决策树分类器。此分类器将把表示（分布式表示）分为两类：'
- en: The properties of high-priority orders
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高优先级订单的属性
- en: The properties of low-priority orders
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低优先级订单的属性
- en: 'There are many types of algorithms. In this case, a standard `sklearn` function
    is called to do the job, as shown in the following source code:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多类型的算法。在这种情况下，调用一个标准的`sklearn`函数来完成任务，如下所示的源代码：
- en: '[PRE24]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '**Step 5**: Visualization separates the orders into priority groups. Visualizing
    the tree is optional but provides a trendy white box approach. You will have to
    use:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**步骤 5**：可视化将订单分为优先级组。可视化树是可选的，但提供了一种流行的白盒方法。你将需要使用：'
- en: '`import collections`, a Python container library.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import collections`，一个Python容器库。'
- en: '`import pydotplus`, a Python interface to Graphviz''s dot language. You can
    choose to use Graphviz directly with other variations of this source code.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`import pydotplus`，一个Python接口，用于Graphviz的dot语言。你可以选择直接使用Graphviz并与其他版本的源代码结合使用。'
- en: 'The source code will take the nodes and edges of the decision tree, draw them,
    and save the image in a file as follows:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 源代码将获取决策树的节点和边，绘制它们，并将图像保存为文件，如下所示：
- en: '[PRE25]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The file will contain this intuitive decision tree:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件将包含这个直观的决策树：
- en: '![Une image contenant signe, texte  Description générée automatiquement](img/B15438_03_04.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![包含标志、文本的图片  描述由系统自动生成](img/B15438_03_04.png)'
- en: 'Figure 3.3: A decision tree'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3：决策树
- en: 'The image produces the following information:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 该图片生成以下信息：
- en: A decision tree represented as a graph that has nodes (the boxes) and edges
    (the lines).
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个表示为图形的决策树，包含节点（框）和边（线）。
- en: When *gini*=0, this box is a **leaf**; the tree will grow no further.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当*gini*=0时，该框为**叶子节点**；树将不再继续生长。
- en: '*gini* means **Gini impurity**. At an intuitive level, Gini impurity will focus
    on the highest values of Gini impurity to classify the samples. We will go into
    the theory of Gini impurity in *Chapter 5*, *How to Use Decision Trees to Enhance
    K-Means Clustering*.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*gini*表示**基尼不纯度**。从直观层面来看，基尼不纯度将集中在最高的基尼不纯度值上，以分类样本。我们将在*第五章*《如何使用决策树增强K均值聚类》中深入探讨基尼不纯度的理论。'
- en: '*samples* = 6\. There are six samples in the training dataset:'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*samples* = 6。训练数据集中有六个样本：'
- en: 'Priority/location <=360.0 is the largest division point that can be visualized:'
  id: totrans-239
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优先级/位置 <=360.0 是可以可视化的最大分割点：
- en: '[PRE26]'
  id: totrans-240
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The false arrow points out the two values that are not <=360\. The ones that
    are classified as `True` are considered as low-priority values.
  id: totrans-241
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误的箭头指出了两个不符合<=360的值。那些被分类为`True`的值被认为是低优先级值。
- en: After a few runs, the user will get used to visualizing the decision process
    as a white box and trust the system.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 几次运行后，用户将习惯于将决策过程视为一个白盒，并且信任该系统。
- en: 'Each ML tool suits a special need in a specific situation. In the next chapter,
    *Optimizing Your Solutions with K-Means Clustering*, we will explore another machine
    learning algorithm: *k-means clustering*.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 每个机器学习工具都适用于特定情境中的特殊需求。在下一章《*通过K均值聚类优化解决方案*》中，我们将探讨另一种机器学习算法：*k均值聚类*。
- en: Summary
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter drew a distinction between machine intelligence and human intelligence.
    Solving a problem like a machine means using a chain of mathematical functions
    and properties. Machine intelligence surpasses humans in many fields.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 本章区分了机器智能和人类智能。像机器一样解决问题意味着使用一系列数学函数和属性。机器智能在许多领域超越了人类。
- en: The further you get in machine learning and deep learning, the more you will
    find mathematical functions that solve the core problems. Contrary to the astounding
    amount of hype, mathematics relying on CPUs is replacing humans, not some form
    of mysterious conscious intelligence.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习和深度学习的深入探索中，你会发现许多数学函数解决了核心问题。与令人震惊的宣传相反，依赖于CPU的数学正在取代人类，而不是某种神秘的意识智能。
- en: The power of machine learning reaches beyond human *mathematical reasoning*.
    It makes ML generalization to other fields easier. A mathematical model, without
    the complexity of humans entangled in emotions, makes it easier to deploy the
    same model in many fields. The models of the first three chapters of this book
    can be used for self-driving vehicles, drones, robots in a warehouse, scheduling
    priorities, and much more. Try to imagine as many fields you can apply these to
    as possible.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的力量超越了人类的*数学推理*。它使得机器学习在其他领域的推广变得更加容易。一个数学模型，不受人类情感困扰的复杂性影响，使得在多个领域部署相同的模型变得更简单。本书前三章的模型可以应用于自动驾驶汽车、无人机、仓库机器人、调度优先级等诸多领域。尽可能设想这些模型可以应用到的多个领域。
- en: Evaluation and measurement are at the core of machine learning and deep learning.
    The key factor is constantly monitoring convergence between the results the system
    produces and the goal it must attain. The door is open to the constant adaptation
    of the parameters of algorithms to reach their objectives.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 评估与测量是机器学习和深度学习的核心。关键因素是不断监测系统产生的结果与其必须达到的目标之间的收敛性。算法参数的持续适应，为达成目标打开了大门。
- en: When a human is surpassed by an unsupervised reinforcement learning algorithm,
    a decision tree, for example, can provide invaluable assistance to human intelligence.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个人类被一个无监督的强化学习算法超越时，决策树可以为人类智慧提供宝贵的帮助。
- en: The next chapter, *Optimizing Your Solutions with K-Means Clustering*, goes
    a step further into machine intelligence.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章，*通过 K-Means 聚类优化解决方案*，将进一步探讨机器智能。
- en: Questions
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Can a human beat a chess engine? (Yes | No)
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人类能够击败国际象棋引擎吗？（是 | 否）
- en: Humans can estimate decisions better than machines with intuition when it comes
    to large volumes of data. (Yes | No)
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在处理大量数据时，人类凭直觉比机器更能准确估计决策。（是 | 否）
- en: Building a reinforcement learning program with a Q function is a feat in itself.
    Using the results afterward is useless. (Yes | No)
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个具有 Q 函数的强化学习程序本身就是一项成就。之后使用其结果则毫无意义。（是 | 否）
- en: Supervised learning decision tree functions can be used to verify that the result
    of the unsupervised learning process will produce reliable, predictable results.
    (Yes | No)
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有监督学习的决策树功能可以用来验证无监督学习过程的结果，确保其能产生可靠、可预测的结果。（是 | 否）
- en: The results of a reinforcement learning program can be used as input to a scheduling
    system by providing priorities. (Yes | No)
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 强化学习程序的结果可以通过提供优先级作为输入，应用于调度系统。（是 | 否）
- en: Can artificial intelligence software think like humans? (Yes | No)
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人工智能软件能像人类一样思考吗？（是 | 否）
- en: Further reading
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more on decision trees: [https://youtu.be/NsUqRe-9tb4](https://youtu.be/NsUqRe-9tb4)'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欲了解更多关于决策树的内容：[https://youtu.be/NsUqRe-9tb4](https://youtu.be/NsUqRe-9tb4)
- en: 'For more on chess analysis by experts such as Zoran Petronijevic, with whom
    I discussed this chapter: [https://chessbookreviews.wordpress.com/tag/zoran-petronijevic/](https://chessbookreviews.wordpress.com/tag/zoran-petronijevic/),
    [https://www.chess.com/fr/member/zoranp](https://www.chess.com/fr/member/zoranp)'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欲了解更多关于国际象棋分析的内容，专家如 Zoran Petronijevic（我曾与他讨论过本章内容）：[https://chessbookreviews.wordpress.com/tag/zoran-petronijevic/](https://chessbookreviews.wordpress.com/tag/zoran-petronijevic/)，[https://www.chess.com/fr/member/zoranp](https://www.chess.com/fr/member/zoranp)
- en: 'For more on AI chess programs: [https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go](https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欲了解更多关于 AI 国际象棋程序的内容：[https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go](https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go)
