- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Temporal Graph Neural Networks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时序图神经网络
- en: 'In the previous chapters, we have only considered graphs where edges and features
    do not change. However, in the real world, there are many applications where this
    is not the case. For instance, in social networks, people follow and unfollow
    other users, posts go viral, and profiles evolve over time. This dynamicity cannot
    be represented using the GNN architectures we previously described. Instead, we
    must embed a new temporal dimension to transform static graphs into dynamic ones.
    These dynamic networks will then be used as inputs for a new family of GNNs: **Temporal
    Graph Neural Networks** (**T-GNNs**), also called **Spatio-Temporal GNNs**.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们仅考虑了边和特征不发生变化的图。然而，在现实世界中，有许多应用场景并非如此。例如，在社交网络中，人们会关注和取消关注其他用户，帖子会变得病毒式传播，个人资料随着时间变化。这种动态性无法通过我们之前描述的GNN架构来表示。相反，我们必须嵌入一个新的时间维度，将静态图转换为动态图。这些动态网络将作为新一类GNN的输入：**时序图神经网络**（**T-GNNs**），也称为**时空GNNs**。
- en: 'In this chapter, we will describe two kinds of **dynamic graphs** that include
    spatiotemporal information. We will list different applications and focus on time
    series forecasting, where temporal GNNs are mainly applied. The second section
    is dedicated to an application we previously looked at: web traffic forecasting.
    This time, we will exploit temporal information to improve our results and obtain
    reliable predictions. Finally, we will describe another temporal GNN architecture
    designed for dynamic graphs. We will apply it to epidemic forecasting to predict
    the number of cases of COVID-19 in different regions of England.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将描述两种包含时空信息的**动态图**。我们将列出不同的应用，并重点介绍时间序列预测，在该领域中，时序GNNs得到了广泛应用。第二节将专注于我们之前研究的一个应用：网页流量预测。这次，我们将利用时间信息来提高结果并获得可靠的预测。最后，我们将描述另一种为动态图设计的时序GNN架构，并将其应用于疫情预测，预测英国不同地区的COVID-19病例数。
- en: By the end of this chapter, you will know the difference between the two main
    types of dynamic graphs. This is particularly useful for modeling your data into
    the right kind of graph. Moreover, you will learn about the design and architecture
    of two temporal GNNs and how to implement them using PyTorch Geometric Temporal.
    This is an essential step to creating your own applications with temporal information.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将了解两种主要类型的动态图之间的区别。这对于将数据建模为正确类型的图非常有用。此外，您将学习两种时序GNN的设计和架构，并了解如何使用PyTorch
    Geometric Temporal来实现它们。这是创建自己的时序信息应用程序的关键步骤。
- en: 'In this chapter, we will cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主要内容：
- en: Introducing dynamic graphs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引入动态图
- en: Forecasting web traffic
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网页流量预测
- en: Predicting cases of COVID-19
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: COVID-19病例预测
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the code examples from this chapter can be found on GitHub at [https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter13](https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter13).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码示例都可以在GitHub上找到，网址是[https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter13](https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter13)。
- en: Installation steps required to run the code on your local machine can be found
    in the *Preface* of this book.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的*前言*部分，您可以找到在本地计算机上运行代码所需的安装步骤。
- en: Introducing dynamic graphs
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入动态图
- en: Dynamic graphs and temporal GNNs unlock a variety of new applications, such
    as transport and web traffic forecasting, motion classification, epidemiological
    forecasting, link prediction, power system forecasting, and so on. Time series
    forecasting is particularly popular with this kind of graph, as we can use historical
    data to predict the system’s future behavior.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 动态图和时序GNNs开启了多种新的应用场景，如交通和网页流量预测、动作分类、流行病预测、链接预测、电力系统预测等。时间序列预测在这种图结构中尤为流行，因为我们可以利用历史数据来预测系统的未来行为。
- en: 'In this chapter, we focus on graphs with a temporal component. They can be
    divided into two categories:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点讨论具有时间维度的图。它们可以分为两类：
- en: '**Static graphs with temporal signals**: The underlying graph does not change,
    but features and labels evolve over time.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**带有时间信号的静态图**：底层图结构不变，但特征和标签随着时间推移而变化。'
- en: '**Dynamic graphs with temporal signals**: The topology of the graph (the presence
    of nodes and edges), features, and labels evolve over time.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**具有时间信号的动态图**：图的拓扑结构（节点和边的存在性）、特征和标签随时间演变。'
- en: 'In the first case, the graph’s topology is *static*. For example, it can represent
    a network of cities within a country for traffic forecasting: features change
    over time, but the connections stay the same.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一种情况下，图的拓扑结构是*静态*的。例如，它可以表示一个国家内城市的网络用于交通预测：特征随时间变化，但连接保持不变。
- en: In the second option, nodes and/or connections are *dynamic*. It is useful to
    represent a social network where links between users can appear or disappear over
    time. This variant is more general, but also harder to learn how to implement.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个选项中，节点和/或连接是*动态*的。它有助于表示一个社交网络，其中用户之间的链接可以随时间出现或消失。这种变体更为通用，但实现起来更加困难。
- en: In the following sections, we will see how to handle these two types of graphs
    with temporal signals using PyTorch Geometric Temporal.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将看到如何使用PyTorch Geometric Temporal处理这两种具有时间信号的图形。
- en: Forecasting web traffic
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测网络流量
- en: 'In this section, we will predict the traffic of Wikipedia articles (as an example
    of a static graph with a temporal signal) using a temporal GNN. This regression
    task has already been covered in [*Chapter 6*](B19153_06.xhtml#_idTextAnchor074),
    *Introducing Graph Convolutional Networks*. However, in that version of the task,
    we performed traffic forecasting using a static dataset without a temporal signal:
    our model did not have any information about previous instances. This is an issue
    because it could not understand whether the traffic was currently increasing or
    decreasing, for example. We can now improve this model to include information
    about past instances.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用时间GNN来预测维基百科文章的流量（作为具有时间信号的静态图的示例）。这种回归任务已经在[*第6章*](B19153_06.xhtml#_idTextAnchor074)，*引入图卷积网络*中进行了讨论。然而，在那个版本的任务中，我们使用静态数据集进行了流量预测，没有时间信号：我们的模型没有任何关于先前实例的信息。这是一个问题，因为它无法理解流量当前是增加还是减少，例如。现在我们可以改进这个模型，以包含关于过去实例的信息。
- en: We will first introduce the temporal GNN architecture with its two variants
    and then implement it using PyTorch Geometric Temporal.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先介绍具有其两个变体的时间GNN架构，然后使用PyTorch Geometric Temporal实现它。
- en: Introducing EvolveGCN
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入EvolveGCN
- en: For this task, we will use the **EvolveGCN** architecture. Introduced by Pareja
    et al. [1] in 2019, it proposes a natural combination of GNNs and **Recurrent
    Neural Networks** (**RNNs**). Previous approaches, such as graph convolutional
    recurrent networks, applied RNNs with graph convolution operators to calculate
    node embeddings. By contrast, EvolveGCN applies RNNs to the GCN parameters themselves.
    As the name implies, the GCN evolves over time to produce relevant temporal node
    embeddings. The following figure illustrates a high-level view of this process.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个任务，我们将使用**EvolveGCN**架构。由Pareja等人[1]在2019年提出，它提议了GNN和**递归神经网络**（**RNNs**）的自然组合。以前的方法，如图卷积递归网络，应用RNN与图卷积操作符来计算节点嵌入。相比之下，EvolveGCN将RNN应用于GCN参数本身。顾名思义，GCN随时间演变以生成相关的时间节点嵌入。以下图展示了这个过程的高层视图。
- en: '![Figure 13.1 – The EvolveGCN’s architecture to produce node embeddings for
    a static or dynamic graph with temporal signal](img/B19153_13_001.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图13.1 – EvolveGCN的架构，用于生成具有时间信号的静态或动态图的节点嵌入](img/B19153_13_001.jpg)'
- en: Figure 13.1 – The EvolveGCN’s architecture to produce node embeddings for a
    static or dynamic graph with temporal signal
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1 – EvolveGCN的架构，用于生成具有时间信号的静态或动态图的节点嵌入
- en: 'This architecture has two variants:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构有两个变体：
- en: '**EvolveGCN-H**, where the recurrent neural network considers both the previous
    GCN parameters and the current node embeddings'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**EvolveGCN-H**，其中递归神经网络考虑先前的GCN参数和当前的节点嵌入'
- en: '**EvolveGCN-O**, where the recurrent neural network only considers the previous
    GCN parameters'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**EvolveGCN-O**，其中递归神经网络仅考虑先前的GCN参数'
- en: 'EvolveGCN-H typically uses a **Gated Recurrent Unit** (**GRU**) instead of
    a vanilla RNN. The GRU is a streamlined version of the **Long Short-Term Memory**
    (**LSTM**) unit that achieves comparable performance with fewer parameters. It
    is comprised of a reset gate, an update gate, and a cell state. In this architecture,
    GRU updates the GCN’s weight matrix for layer ![](img/Formula_B19153_13_001.png)
    at time ![](img/Formula_B19153_13_002.png) as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: EvolveGCN-H 通常使用 **门控递归单元** (**GRU**) 代替普通的RNN。GRU是**长短期记忆** (**LSTM**) 单元的简化版，能够在使用更少参数的情况下实现类似的性能。它由重置门、更新门和细胞状态组成。在这种架构中，GRU在时间
    ![](img/Formula_B19153_13_002.png) 时刻更新GCN的权重矩阵，具体过程如下：
- en: '![](img/Formula_B19153_13_003.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_13_003.jpg)'
- en: '![](img/Formula_B19153_13_004.png) denotes the node embeddings produced at
    layer ![](img/Formula_B19153_13_008.png) and time ![](img/Formula_B19153_13_006.png),
    and ![](img/Formula_B19153_13_007.png) is the weight matrix for layer ![](img/Formula_B19153_13_0081.png)
    from the previous time step.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/Formula_B19153_13_004.png) 表示在层 ![](img/Formula_B19153_13_008.png)
    和时间 ![](img/Formula_B19153_13_006.png) 生成的节点嵌入，而 ![](img/Formula_B19153_13_007.png)
    是来自上一个时间步的层 ![](img/Formula_B19153_13_0081.png) 的权重矩阵。'
- en: 'This resulting GCN weight matrix is then used to calculate the next layer’s
    node embeddings:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的GCN权重矩阵随后被用来计算下一层的节点嵌入：
- en: '![](img/Formula_B19153_13_009.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_13_009.png)'
- en: '![](img/Formula_B19153_13_010.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_13_010.png)'
- en: Here, ![](img/Formula_B19153_13_011.png) is the adjacency matrix, including
    self-loops, and ![](img/Formula_B19153_13_012.png) is the degree matrix with self-loops.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，![](img/Formula_B19153_13_011.png) 是包含自环的邻接矩阵，![](img/Formula_B19153_13_012.png)
    是包含自环的度矩阵。
- en: These steps are summarized in the following figure.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤在下图中进行了总结。
- en: '![Figure 13.2 – The EvolveGCN-H’s architecture with GRU and GNN](img/B19153_13_002.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.2 – 带有GRU和GNN的EvolveGCN-H架构](img/B19153_13_002.jpg)'
- en: Figure 13.2 – The EvolveGCN-H’s architecture with GRU and GNN
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2 – 带有GRU和GNN的EvolveGCN-H架构
- en: 'EvolveGCN-H can be implemented with a GRU that receives two extensions:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: EvolveGCN-H可以通过GRU来实现，GRU接收两个扩展：
- en: The inputs and hidden states are matrices instead of vectors to store the GCN
    weight matrices properly
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入和隐藏状态是矩阵，而非向量，用来正确存储GCN权重矩阵。
- en: The column dimension of the input must match that of the hidden state, which
    requires summarizing the node embedding matrix ![](img/Formula_B19153_13_013.png)
    to only keep the appropriate number of columns
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入的列维度必须与隐藏状态的列维度匹配，这要求对节点嵌入矩阵 ![](img/Formula_B19153_13_013.png) 进行汇总，仅保留合适的列数。
- en: 'These extensions are not required for the EvolveGCN-O variant. Indeed, EvolveGCN-O
    is based on an LSTM network to model the input-output relationship. We do not
    need to feed a hidden state to the LSTM, as it already includes a cell that remembers
    previous values. This mechanism simplifies the update step, which can be written
    as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这些扩展对于EvolveGCN-O变体来说并非必需。实际上，EvolveGCN-O基于LSTM网络来建模输入输出关系。我们不需要给LSTM提供隐藏状态，因为它已经包含了一个记忆先前值的细胞。这个机制简化了更新步骤，可以写成如下形式：
- en: '![](img/Formula_B19153_13_014.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_13_014.jpg)'
- en: 'The resulting GCN weight matrix is used in the same way to produce the next
    layer’s node embeddings:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的GCN权重矩阵以相同方式使用，以产生下一层的节点嵌入：
- en: '![](img/Formula_B19153_13_015.jpg)![](img/Formula_B19153_13_016.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_13_015.jpg)![](img/Formula_B19153_13_016.jpg)'
- en: 'This implementation is simpler since the temporal dimension entirely relies
    on a vanilla LSTM network. The following figure shows how EvolveGCN-O updates
    the weight matrix ![](img/Formula_B19153_13_017.png) and calculates node embeddings
    ![](img/Formula_B19153_13_018.png):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这个实现更为简单，因为时间维度完全依赖于一个普通的LSTM网络。下图展示了EvolveGCN-O如何更新权重矩阵 ![](img/Formula_B19153_13_017.png)
    并计算节点嵌入 ![](img/Formula_B19153_13_018.png)：
- en: '![Figure 13.3 – EvolveGCN-O’s architecture with LSTM and GCN](img/B19153_13_003.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.3 – 带有LSTM和GCN的EvolveGCN-O架构](img/B19153_13_003.jpg)'
- en: Figure 13.3 – EvolveGCN-O’s architecture with LSTM and GCN
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.3 – 带有LSTM和GCN的EvolveGCN-O架构
- en: 'So which version should we use? As is often the case in machine learning, the
    best solution is data-dependent:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们应该使用哪个版本呢？正如在机器学习中常见的那样，最佳解决方案依赖于数据：
- en: EvolveGCN-H works better when the node features are essential because its RNN
    explicitly incorporates node embeddings
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当节点特征至关重要时，EvolveGCN-H的表现更好，因为它的RNN明确地融合了节点嵌入。
- en: EvolveGCN-O works better when the graph structure plays an important role, as
    it focuses more on topological changes
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当图的结构起重要作用时，EvolveGCN-O表现得更好，因为它更侧重于拓扑变化。
- en: Note that these remarks are primarily theoretical, which is why it can be helpful
    to test both variants in your applications. This is what we will do by implementing
    these models for web traffic forecasting.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这些备注主要是理论性的，因此在您的应用程序中测试这两种变体可能会有所帮助。这正是我们通过实现这些模型来进行网络流量预测时所做的。
- en: Implementing EvolveGCN
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现EvolveGCN
- en: In this section, we want to forecast web traffic on a static graph with a temporal
    signal. The **WikiMaths** dataset is comprised of 1,068 articles represented as
    nodes. Node features correspond to the past daily number of visits (eight features
    by default). Edges are weighted, and weights represent the number of links from
    the source page to the destination page. We want to predict the daily user visits
    to these Wikipedia pages between March 16, 2019, and March 15, 2021, which results
    in 731 snapshots. Each snapshot is a graph describing the state of the system
    at a certain time.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们希望在带有时间信号的静态图上预测网络流量。**WikiMaths**数据集由1,068篇文章表示为节点。节点特征对应于过去每天的访问数量（默认情况下有八个特征）。边是加权的，权重表示从源页面到目标页面的链接数量。我们希望预测2019年3月16日至2021年3月15日之间这些Wikipedia页面的每日用户访问量，共有731个快照。每个快照是一个描述系统在特定时间状态的图。
- en: '*Figure 13**.4* shows a representation of WikiMaths made with Gephi, where
    the size and color of the nodes are proportional to their number of connections.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*图13**.4*展示了使用Gephi制作的WikiMaths表示，其中节点的大小和颜色与其连接数成比例。'
- en: '![Figure 13.4 – WikiMaths dataset as an unweighted graph (t=0)](img/B19153_13_004.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图13.4 – WikiMaths数据集作为无权图（t=0）](img/B19153_13_004.jpg)'
- en: Figure 13.4 – WikiMaths dataset as an unweighted graph (t=0)
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4 – WikiMaths数据集作为无权图（t=0）
- en: 'PyTorch Geometric does not natively support static or dynamic graphs with a
    temporal signal. Fortunately, an extension called PyTorch Geometric Temporal [2]
    fixes this issue and even implements various temporal GNN layers. The WikiMaths
    dataset was also made public during the development of PyTorch Geometric Temporal.
    In this chapter, we will use this library to simplify the code and focus on applications:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Geometric本身不支持带有时间信号的静态或动态图。幸运的是，一个名为PyTorch Geometric Temporal的扩展[2]解决了这个问题，并且实现了多种时间序列GNN层。在PyTorch
    Geometric Temporal开发过程中，WikiMaths数据集也被公开。在本章中，我们将使用这个库来简化代码并专注于应用：
- en: 'We need to install this library in an environment containing PyTorch Geometric:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要在包含PyTorch Geometric的环境中安装此库：
- en: '[PRE0]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We import the WikiMaths dataset, called `WikiMathDatasetLoader`, a temporal-aware
    train-test split with `temporal_signal_split`, and our GNN layer, `EvolveGCNH`:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入WikiMaths数据集，名为`WikiMathDatasetLoader`，带有`temporal_signal_split`的时间感知训练-测试划分，以及我们的GNN层`EvolveGCNH`：
- en: '[PRE1]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We load the WikiMaths dataset, which is a `StaticGraphTemporalSignal` object.
    In this object, `dataset[0]` describes the graph (also called a snapshot in this
    context) at ![](img/Formula_B19153_13_019.png) and `dataset[500]` at ![](img/Formula_B19153_13_020.png).
    We also create a train-test split with a ratio of `0.5`. The training set is composed
    of snapshots from the earlier time periods, while the test set regroups snapshots
    from the later periods:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们加载了WikiMaths数据集，这是一个`StaticGraphTemporalSignal`对象。在这个对象中，`dataset[0]`描述了时间点![](img/Formula_B19153_13_019.png)的图（在此上下文中也称为快照），而`dataset[500]`描述了时间点![](img/Formula_B19153_13_020.png)的图。我们还创建了一个训练集和测试集的划分，比例为`0.5`。训练集由较早时间段的快照组成，而测试集则重新组织了较晚时间段的快照：
- en: '[PRE2]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The graph is static, so the node and edge dimensions do not change. However,
    the values contained in these tensors are different. It is difficult to visualize
    the values of each of the 1,068 nodes. To better understand this dataset, we can
    calculate the mean and standard deviation values for each snapshot instead. The
    moving average is also helpful in smoothing out short-term fluctuations.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该图是静态的，因此节点和边的维度不会改变。然而，这些张量中包含的值是不同的。由于有1,068个节点，很难可视化每个节点的值。为了更好地理解这个数据集，我们可以计算每个快照的均值和标准差值。移动平均值也有助于平滑短期波动。
- en: '[PRE3]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We plot these time series with `matplotlib` to visualize our task:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`matplotlib`绘制这些时间序列，以可视化我们的任务：
- en: '[PRE4]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This produces *Figure 13**.5*.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了*图13**.5*。
- en: '![Figure 13.5 – WikiMaths’ mean normalized number of visits with moving average](img/B19153_13_005.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图13.5 – WikiMaths的平均归一化访问量与移动平均值](img/B19153_13_005.jpg)'
- en: Figure 13.5 – WikiMaths’ mean normalized number of visits with moving average
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.5 – WikiMaths的平均归一化访问次数与移动平均
- en: Our data presents periodic patterns that the temporal GNN can hopefully learn.
    We can now implement it and see how it performs.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据呈现周期性模式，希望时间GNN能够学习到这些模式。现在我们可以实现它并看看它的表现。
- en: 'The temporal GNN takes two parameters as inputs: the number of nodes (`node_count`)
    and the input dimension (`dim_in`). The GNN only has two layers: an EvolveGCN-H
    layer and a linear layer that outputs a predicted value for each node:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 时间GNN接收两个参数作为输入：节点数（`node_count`）和输入维度（`dim_in`）。GNN只有两个层次：一个EvolveGCN-H层和一个线性层，后者输出每个节点的预测值：
- en: '[PRE5]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `forward()` function applies both layers to the input with a ReLU activation
    function:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`forward()`函数将两个层应用于输入，并使用ReLU激活函数：'
- en: '[PRE6]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We create an instance of `TemporalGNN` and give it the number of nodes and
    input dimension from the WikiMaths dataset. We will train it using the `Adam`
    optimizer:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个`TemporalGNN`实例，并为其提供WikiMaths数据集的节点数和输入维度。我们将使用`Adam`优化器进行训练：
- en: '[PRE7]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can print the model to observe the layers contained in `EvolveGCNH`:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以打印模型，以观察`EvolveGCNH`中包含的层：
- en: '[PRE8]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We see three layers: `TopKPooling`, which summarizes the input matrix in eight
    columns; `GRU`, which updates the GCN weight matrix; and `GCNConv`, which produces
    the new node embedding. Finally, a linear layer outputs a predicted value for
    every node in the graph.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到三个层次：`TopKPooling`，它将输入矩阵总结为八列；`GRU`，它更新GCN权重矩阵；以及`GCNConv`，它生成新的节点嵌入。最后，一个线性层输出每个节点的预测值。
- en: 'We create a training loop that trains the model on every snapshot from the
    training set. The loss is backpropagated for every snapshot:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个训练循环，在训练集的每个快照上训练模型。对于每个快照，损失都会进行反向传播：
- en: '[PRE9]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Likewise, we evaluate the model on the test set. The MSE is averaged on the
    entire test set to produce the final score:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，我们在测试集上评估模型。MSE在整个测试集上取平均，以生成最终得分：
- en: '[PRE10]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We obtain a loss value of 0.7559\. Next, we will plot the mean values predicted
    by our model on the previous graph to interpret it. The process is straightforward:
    we must average the predictions and store them in a list. Then, we can add them
    to the previous plot:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们得到的损失值是0.7559。接下来，我们将绘制我们模型在之前图表上的平均预测值进行解读。过程很简单：我们需要对预测值取平均并将它们存储在一个列表中。然后，我们可以将它们添加到之前的图表中：
- en: '[PRE11]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: That gives us *Figure 13**.6*.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这给我们带来了*图 13**.6*。
- en: '![Figure 13.6 – Predicted mean normalized number of visits](img/B19153_13_006.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.6 – 预测的平均归一化访问次数](img/B19153_13_006.jpg)'
- en: Figure 13.6 – Predicted mean normalized number of visits
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6 – 预测的平均归一化访问次数
- en: We can see that the predicted values follow the general trend in the data. This
    is an excellent result, considering the limited size of the dataset.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到预测值遵循数据中的一般趋势。考虑到数据集的规模有限，这是一个很好的结果。
- en: 'Finally, let’s create a scatter plot to show how predicted and ground truth
    values differ for a single snapshot:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们创建一个散点图，展示预测值和真实值在单一快照中的差异：
- en: '[PRE12]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![Figure 13.7 – Predicted versus ground truth values for the WikiMaths dataset](img/B19153_13_007.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.7 – WikiMaths数据集的预测值与真实值对比](img/B19153_13_007.jpg)'
- en: Figure 13.7 – Predicted versus ground truth values for the WikiMaths dataset
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7 – WikiMaths数据集的预测值与真实值对比
- en: We observe a moderate positive correlation between predicted and real values.
    Our model is not remarkably accurate, but the previous figure showed that it understands
    the periodic nature of the data very well.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到预测值与真实值之间存在适度的正相关关系。我们的模型虽然没有特别准确，但前面的图表显示它很好地理解了数据的周期性特征。
- en: 'Implementing the EvolveGCN-O variant is very similar. Instead of using the
    `EvolveGCNH` layer from PyTorch Geometric Temporal, we replace it with `EvolveGCNO`.
    This layer does not require the number of nodes, so we only give it the input
    dimension. It is implemented as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 实现EvolveGCN-O变体非常相似。我们不使用PyTorch Geometric Temporal中的`EvolveGCNH`层，而是将其替换为`EvolveGCNO`。这个层不需要节点数，因此我们只提供输入维度。实现如下：
- en: '[PRE13]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: On average, the EvolveGCN-O model obtains similar results with an average MSE
    of 0.7524\. In this case, the use of a GRU or LSTM network does not impact the
    predictions. This is understandable since both the past numbers of visits contained
    in node features (EvolveGCN-H) and the connections between pages (EvolveGCN-O)
    are essential. As a result, this GNN architecture is particularly well-suited
    to this traffic forecasting task.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 平均来说，EvolveGCN-O模型的结果相似，平均MSE为0.7524。在这种情况下，使用GRU或LSTM网络不会影响预测。这是可以理解的，因为节点特征（EvolveGCN-H）中包含的过去访问次数和页面之间的连接（EvolveGCN-O）都至关重要。因此，这种GNN架构特别适用于此交通预测任务。
- en: Now that we have seen an example of a static graph, let’s explore how to process
    dynamic graphs.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了一个静态图的例子，让我们来探讨如何处理动态图。
- en: Predicting cases of COVID-19
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测COVID-19病例
- en: This section will focus on a new application with epidemic forecasting. We will
    use the **England Covid dataset**, a dynamic graph with temporal information introduced
    by Panagopoulos et al. in 2021 [3]. While nodes are static, connections between
    and edge weights vary over time. This dataset represents the number of reported
    cases of COVID-19 in 129 England NUTS 3 regions between March 3 and May 12, 2020\.
    Data was collected from mobile phones that installed the Facebook application
    and shared their location history. Our goal is to predict the number of cases
    in each node (region) in 1 day.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将重点介绍一个新的应用——流行病预测。我们将使用**英格兰Covid数据集**，这是一个带有时间信息的动态图，由Panagopoulos等人于2021年提出[3]。尽管节点是静态的，但节点之间的连接和边的权重随时间变化。该数据集表示2020年3月3日至5月12日间，英格兰129个NUTS
    3地区报告的COVID-19病例数。数据来源于安装了Facebook应用并共享其位置历史的手机。我们的目标是预测每个节点（地区）一天内的病例数。
- en: '![Figure 13.8 – NUTS 3 areas in England are colored in red](img/B19153_13_008.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图13.8 – 英格兰的NUTS 3区域以红色标出](img/B19153_13_008.jpg)'
- en: Figure 13.8 – NUTS 3 areas in England are colored in red
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.8 – 英格兰的NUTS 3区域以红色标出
- en: 'This dataset represents England as a graph ![](img/Formula_B19153_13_021.png).
    Due to the temporal nature of this dataset, it is composed of multiple graphs
    corresponding to each day of the studied period ![](img/Formula_B19153_13_022.png).
    In these graphs, node features correspond to the number of cases in each of the
    past ![](img/Formula_B19153_13_023.png) days in this region. Edges are unidirectional
    and weighted: the weight ![](img/Formula_B19153_13_024.png) of edge ![](img/Formula_B19153_13_025.png)
    represents the number of people that moved from region ![](img/Formula_B19153_13_026.png)
    to region ![](img/Formula_B19153_13_027.png) at time ![](img/Formula_B19153_13_028.png).
    These graphs also contain self-loops corresponding to people moving within the
    same region.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集将英格兰表示为一个图！[](img/Formula_B19153_13_021.png)。由于该数据集具有时间性，因此它由多个图组成，每个图对应研究期间的每一天！[](img/Formula_B19153_13_022.png)。在这些图中，节点特征表示该地区过去！[](img/Formula_B19153_13_023.png)天的病例数。边是单向的并且加权：边！[](img/Formula_B19153_13_025.png)的权重！[](img/Formula_B19153_13_024.png)表示在时间！[](img/Formula_B19153_13_028.png)从区域！[](img/Formula_B19153_13_026.png)到区域！[](img/Formula_B19153_13_027.png)的人数。这些图还包含自环，表示在同一地区内移动的人。
- en: This section will introduce a new GNN architecture designed for this task and
    show how to implement it step by step.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍一种专门为此任务设计的新型GNN架构，并展示如何一步步实现它。
- en: Introducing MPNN-LSTM
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍MPNN-LSTM
- en: As its name suggests, **MPNN-LSTM** architecture relies on combining an MPNN
    and an LSTM network. Like the England Covid dataset, it was also introduced by
    Panagopoulos et al. in 2021 [3].
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名所示，**MPNN-LSTM**架构依赖于将MPNN和LSTM网络相结合。像英格兰Covid数据集一样，它也是由Panagopoulos等人于2021年提出的[3]。
- en: The input node features with the corresponding edge indexes and weights are
    fed to a GCN layer. We apply a batch normalization layer and a dropout to this
    output. This process is repeated a second time with the outcome of the first MPNN.
    It produces a node embedding matrix ![](img/Formula_B19153_13_029.png). We create
    a sequence ![](img/Formula_B19153_13_030.png) of node embedding representations
    by applying these MPNNs for each time step. This sequence is fed to a 2-layer
    LSTM network to capture the temporal information from the graphs. Finally, we
    apply a linear transformation and a ReLU function to this output to produce a
    prediction at ![](img/Formula_B19153_13_031.png).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 输入的节点特征与相应的边索引和权重被送入 GCN 层。我们对这个输出应用批量归一化层和 dropout。这个过程会在第一次 MPNN 的输出结果基础上重复第二次。它生成一个节点嵌入矩阵
    ![](img/Formula_B19153_13_029.png)。我们通过对每个时间步应用这些 MPNN，创建一个节点嵌入表示序列 ![](img/Formula_B19153_13_030.png)。这个序列被送入一个
    2 层 LSTM 网络，以捕捉图中的时间信息。最后，我们对该输出应用线性变换和 ReLU 函数，生成一个在 ![](img/Formula_B19153_13_031.png)
    的预测结果。
- en: The following figure shows a high-level view of the MPNN-LSTM’s architecture.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了 MPNN-LSTM 架构的高级视图。
- en: '![Figure 13.9 – MPNN-LSTM’s architecture](img/B19153_13_009.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.9 – MPNN-LSTM 的架构](img/B19153_13_009.jpg)'
- en: Figure 13.9 – MPNN-LSTM’s architecture
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.9 – MPNN-LSTM 的架构
- en: The authors of MPNN-LSTM note that it is not the best-performing model on the
    England Covid dataset (the MPNN with a two-level GNN is). However, it is an interesting
    approach that could perform better in other scenarios. They also state that it
    is more suited for long-term forecasting, such as 14 days in the future instead
    of a single day, as in our version of this dataset. Despite this issue, we use
    the latter for convenience, as it does not impact the design of the solution.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: MPNN-LSTM 的作者指出，它并不是在英国 Covid 数据集上表现最好的模型（带有二级 GNN 的 MPNN 才是）。然而，它是一个有趣的方法，在其他场景中可能表现更好。他们还表示，它更适用于长期预测，比如预测未来
    14 天，而不是像我们在此数据集版本中所做的单日预测。尽管存在这个问题，我们还是为了方便使用后者，因为它不影响解决方案的设计。
- en: Implementing MPNN-LSTM
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现 MPNN-LSTM
- en: 'First, it is important to visualize the number of cases we want to predict.
    As in the previous section, we will summarize the 129 different time series that
    composed the dataset by calculating their mean and standard deviation:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，重要的是要可视化我们想要预测的病例数。与上一节相同，我们将通过计算均值和标准差来总结组成数据集的 129 个不同时间序列：
- en: 'We import `pandas`, `matplotlib`, the England Covid dataset, and the temporal
    train-test split function from PyTorch Geometric Temporal:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从 PyTorch Geometric Temporal 导入 `pandas`、`matplotlib`、英国 Covid 数据集以及时间序列训练-测试分割函数：
- en: '[PRE14]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We load the dataset with 14 lags, corresponding to the number of node features:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们加载包含 14 个滞后期的数据集，滞后期对应于节点特征的数量：
- en: '[PRE15]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We perform a temporal signal split with a training ratio of `0.8`:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们执行时间信号分割，训练比例为 `0.8`：
- en: '[PRE16]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We plot the following graph to show the mean normalized number of reported cases
    (they are reported approximately every day). The code is available on GitHub and
    adapts the snippet we used in the last section.
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们绘制了以下图表，以展示报告病例的均值标准化数量（这些病例大约每天报告一次）。代码可以在 GitHub 上找到，并且适配了我们在上一节中使用的代码片段。
- en: '![Figure 13.10 – England Covid dataset’s mean normalized number of cases](img/B19153_13_010.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.10 – 英国 Covid 数据集的均值标准化病例数](img/B19153_13_010.jpg)'
- en: Figure 13.10 – England Covid dataset’s mean normalized number of cases
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.10 – 英国 Covid 数据集的均值标准化病例数
- en: This plot shows a lot of volatility and a low number of snapshots. This is why
    we use an 80/20 train-test split in this example. Obtaining good performance on
    such a small dataset might be challenging, nonetheless.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表显示了大量的波动性和较少的快照数量。这就是为什么我们在本例中使用 80/20 的训练-测试划分。尽管如此，在这样一个小数据集上获得良好的性能可能会具有挑战性。
- en: Let’s now implement the MPNN-LSTM architecture.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来实现 MPNN-LSTM 架构。
- en: 'We import the `MPNNLSTM` layer from PyTorch Geometric Temporal:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从 PyTorch Geometric Temporal 导入 `MPNNLSTM` 层：
- en: '[PRE17]'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The temporal GNN takes three parameters as inputs: the input dimension, the
    hidden dimension, and the number of nodes. We declare three layers: the MPNN-LSTM
    layer, a dropout layer, and a linear layer with the right input dimension:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 时间序列 GNN 接受三个参数作为输入：输入维度、隐藏维度和节点数。我们声明了三个层：MPNN-LSTM 层、一个 dropout 层和一个具有正确输入维度的线性层：
- en: '[PRE18]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The `forward()` function considers the edge weights, an essential piece of
    information in this dataset. Note that we are processing a dynamic graph, so a
    new set of values for `edge_index` and `edge_weight` are provided at each time
    step. Unlike the original MPNN-LSTM described previously, we replace the final
    ReLU function with a `tanh` function. The main motivation is that tanh outputs
    values between -1 and 1, instead of 0 and 1, which is closer to what we observed
    in the dataset:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`forward()` 函数考虑了边的权重，这是该数据集中的关键信息。请注意，我们正在处理动态图，因此每个时间步骤都会提供一组新的 `edge_index`
    和 `edge_weight` 值。与之前描述的原始 MPNN-LSTM 不同，我们用 `tanh` 函数替代了最后的 ReLU 函数。主要的动机是，tanh
    输出的值在 -1 和 1 之间，而不是 0 和 1，这更接近我们在数据集中观察到的情况：'
- en: '[PRE19]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We create our MPNN-LSTM model with a hidden dimension of 64 and print it to
    observe the different layers:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建了一个隐藏维度为 64 的 MPNN-LSTM 模型，并打印它以观察不同的层：
- en: '[PRE20]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We see that the MPNN-LSTM layer contains two GCN, two batch normalization, and
    two LSTM layers (but no dropout), which corresponds to our previous description.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到 MPNN-LSTM 层包含两个 GCN、两个批归一化层和两个 LSTM 层（但没有 dropout），这与我们之前的描述一致。
- en: 'We train this model for `100` epochs with the `Adam` optimizer and a learning
    rate of `0.001`. This time, we backpropagate the loss after every snapshot instead
    of every instance:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 `Adam` 优化器和学习率为 `0.001`，将该模型训练了 `100` 轮。本次，我们在每次快照后反向传播损失，而不是在每个实例后反向传播：
- en: '[PRE21]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We evaluate the trained model on the test set and obtain the following MSE
    loss:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在测试集上评估了训练好的模型，并得到了以下的 MSE 损失：
- en: '[PRE22]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The MPNN-LSTM model obtained an MSE loss of 1.3722, which seems relatively high.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: MPNN-LSTM 模型的 MSE 损失为 1.3722，似乎相对较高。
- en: We cannot invert the normalization process that was applied to this dataset,
    so we will use the normalized numbers of cases instead. First, let’s plot the
    mean normalized number of cases that our model predicted (code available on GitHub).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法还原对该数据集应用的归一化过程，因此将使用归一化后的病例数。首先，让我们绘制模型预测的平均归一化病例数（代码可在 GitHub 上获取）。
- en: '![Figure 13.11 – Mean normalized number of cases with true values in black
    and predicted values in red](img/B19153_13_011.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.11 – 平均归一化病例数，真实值为黑色，预测值为红色](img/B19153_13_011.jpg)'
- en: Figure 13.11 – Mean normalized number of cases with true values in black and
    predicted values in red
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.11 – 平均归一化病例数，真实值为黑色，预测值为红色
- en: 'As expected, the predicted values do not match the ground truth very well.
    This is probably due to the lack of data: our model learned an average value that
    minimizes the MSE loss but cannot fit the curve and understand its periodicity.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，预测值与真实值不太匹配。这可能是由于数据不足：我们的模型学习到了一个最小化 MSE 损失的平均值，但无法拟合曲线并理解其周期性。
- en: Let’s inspect the scatter plot corresponding to the test set’s first snapshot
    (code available on GitHub).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看对应于测试集第一张快照的散点图（代码可在 GitHub 上获取）。
- en: '![Figure 13.12 – Predicted versus ground truth values for the England Covid
    dataset](img/B19153_13_012.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.12 – 英国 Covid 数据集的预测值与真实值对比](img/B19153_13_012.jpg)'
- en: Figure 13.12 – Predicted versus ground truth values for the England Covid dataset
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.12 – 英国 Covid 数据集的预测值与真实值对比
- en: The scatter plot shows a weak correlation. We see that the predictions (y-axis)
    are mostly centered around 0.35 with little variance. This does not correspond
    to the ground truth values, spanning from -1.5 to 0.6\. As per our experiments,
    adding a second linear layer did not improve the MPNN-LSTM’s predictions.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图显示了弱相关性。我们看到预测值（y 轴）大多集中在 0.35 左右，变化很小。这与真实值不一致，真实值的范围从 -1.5 到 0.6。根据我们的实验，添加第二个线性层并没有改善
    MPNN-LSTM 的预测结果。
- en: 'Several strategies could be implemented to help the model. First, more data
    points could greatly help because this is a small dataset. Additionally, the time
    series contains two interesting characteristics: trends (continued increase and
    decrease over time) and seasonality (predictable pattern). We could add a preprocessing
    step to remove these characteristics, which add noise to the signal we want to
    predict.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 可以实施几种策略来帮助模型。首先，更多的数据点会有很大帮助，因为这是一个小数据集。此外，时间序列包含两个有趣的特征：趋势（随时间持续增加或减少）和季节性（可预测的模式）。我们可以添加一个预处理步骤，去除这些特征，它们会为我们想要预测的信号增加噪声。
- en: Beyond recurrent neural networks, self-attention is another popular technique
    to create temporal GNNs [4]. Attention can be restricted to temporal information
    or also consider spatial data, typically handled by graph convolution. Finally,
    temporal GNNs can also be extended to heterogeneous settings described in the
    previous chapter. Unfortunately, this combination requires even more data and
    is currently an active area of research.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 除了递归神经网络外，自注意力机制是另一种常用的技术，用于创建时序GNN[4]。注意力机制可以仅限于时序信息，也可以考虑空间数据，通常通过图卷积来处理。最后，时序GNN也可以扩展到前一章中描述的异构设置。不幸的是，这种组合需要更多的数据，目前仍是一个活跃的研究领域。
- en: Summary
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This chapter introduced a new type of graph with spatiotemporal information.
    This temporal component is helpful in many applications, mostly related to time
    series forecasting. We described two types of graphs that fit this description:
    static graphs, where features evolve over time, and dynamic graphs, where features
    and topology can change. Both of them are handled by PyTorch Geometric Temporal,
    PyG’s extension dedicated to temporal graph neural networks.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了一种新型的具有时空信息的图。这种时间成分在许多应用中非常有用，主要与时间序列预测相关。我们描述了两种符合此描述的图：静态图，其中特征随时间演变；动态图，其中特征和拓扑可以发生变化。它们都由PyTorch
    Geometric Temporal处理，PyG的扩展专门用于时序图神经网络。
- en: Additionally, we covered two applications of temporal GNNs. First, we implemented
    the EvolveGCN architecture, which uses a GRU or an LSTM network to update the
    GCN parameters. We applied it by revisiting web traffic forecasting, a task we
    encountered in [*Chapter 6*](B19153_06.xhtml#_idTextAnchor074), *Introducing Graph
    Convolutional Networks*, and achieved excellent results with a limited dataset.
    Secondly, we used the MPNN-LSTM architecture for epidemic forecasting. We applied
    to the England Covid dataset a dynamic graph with a temporal signal, but its small
    size did not allow us to obtain comparable results.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还介绍了时序GNN的两个应用。首先，我们实现了EvolveGCN架构，该架构使用GRU或LSTM网络来更新GCN参数。我们通过回顾在[*第6章*](B19153_06.xhtml#_idTextAnchor074)，*引入图卷积网络*中遇到的网页流量预测任务，应用了这个架构，并在有限的数据集上取得了出色的结果。其次，我们使用MPNN-LSTM架构进行疫情预测。我们将其应用于英格兰Covid数据集，使用带有时间信号的动态图，但由于其数据量较小，未能获得可比的结果。
- en: In [*Chapter 14*](B19153_14.xhtml#_idTextAnchor165), *Explaining Graph Neural
    Networks*, we will focus on how to interpret our results. Beyond the different
    visualizations we have introduced so far, we will see how to apply techniques
    from **eXplainable Artificial Intelligence** (**XAI**) to graph neural networks.
    This field is a key component to build robust AI systems and improve machine learning
    adoption. In that chapter, we will introduce post hoc explanation methods and
    new layers to build models that are explainable by design.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第14章*](B19153_14.xhtml#_idTextAnchor165)，*解释图神经网络*中，我们将重点讨论如何解释我们的结果。除了我们迄今为止介绍的各种可视化方法外，我们还将看到如何将**可解释人工智能**（**XAI**）的技术应用于图神经网络。这个领域是构建稳健AI系统和推动机器学习应用的重要组成部分。在该章节中，我们将介绍事后解释方法和新的层，以构建从设计上就可以解释的模型。
- en: Further reading
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '[1] A. Pareja et al., *EvolveGCN: Evolving Graph Convolutional Networks for
    Dynamic Graphs*. arXiv, 2019\. DOI: 10.48550/ARXIV.1902.10191\. Available: [https://arxiv.org/abs/1902.10191](https://arxiv.org/abs/1902.10191)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] A. Pareja 等人，*EvolveGCN：用于动态图的演化图卷积网络*。arXiv，2019\. DOI: 10.48550/ARXIV.1902.10191\.
    可用：[https://arxiv.org/abs/1902.10191](https://arxiv.org/abs/1902.10191)'
- en: '[2] B. Rozemberczki et al., *PyTorch Geometric Temporal: Spatiotemporal Signal
    Processing with Neural Machine Learning Models*, in Proceedings of the 30th ACM
    International Conference on Information and Knowledge Management, 2021, pp. 4564–4573\.
    Available: [https://arxiv.org/abs/2104.07788](https://arxiv.org/abs/2104.07788)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] B. Rozemberczki 等人，*PyTorch Geometric Temporal：使用神经机器学习模型进行时空信号处理*，发表于第30届ACM国际信息与知识管理大会论文集，2021年，页4564–4573\.
    可用：[https://arxiv.org/abs/2104.07788](https://arxiv.org/abs/2104.07788)'
- en: '[3] G. Panagopoulos, G. Nikolentzos, and M. Vazirgiannis. *Transfer Graph Neural
    Networks for Pandemic Forecasting*. arXiv, 2020\. DOI: 10.48550/ARXIV.2009.08388\.
    Available: [https://arxiv.org/abs/2009.08388](https://arxiv.org/abs/2009.08388)'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] G. Panagopoulos，G. Nikolentzos 和 M. Vazirgiannis。*传递图神经网络在疫情预测中的应用*。arXiv，2020\.
    DOI: 10.48550/ARXIV.2009.08388\. 可用：[https://arxiv.org/abs/2009.08388](https://arxiv.org/abs/2009.08388)'
- en: '[4] Guo, S., Lin, Y., Feng, N., Song, C., & Wan, H. (2019). Attention Based
    Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting. Proceedings
    of the AAAI Conference on Artificial Intelligence, 33(01), 922-929\. [https://doi.org/10.1609/aaai.v33i01.3301922](https://doi.org/10.1609/aaai.v33i01.3301922)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Guo, S., Lin, Y., Feng, N., Song, C., & Wan, H. (2019). 基于注意力的时空图卷积网络用于交通流量预测.
    《人工智能协会会议论文集》，33(01)，922-929\. [https://doi.org/10.1609/aaai.v33i01.3301922](https://doi.org/10.1609/aaai.v33i01.3301922)'
