- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Generating and Summarizing Text with Amazon Bedrock
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon Bedrock 生成和总结文本
- en: In this chapter, we will explore architecture patterns for generating and summarizing
    text with Amazon Bedrock. You will learn about applications of text generation
    and how text generation works with Amazon Bedrock. Then, we will use some prompt
    engineering techniques, including contextual prompting, and orchestration using
    LangChain. After, we will explore text summarization using small texts/files,
    summarizing large articles and books, and discover use cases and patterns for
    text summarization.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨使用 Amazon Bedrock 生成和总结文本的架构模式。您将了解文本生成的应用以及文本生成如何与 Amazon Bedrock
    合作。然后，我们将使用一些提示工程技术，包括上下文提示和 LangChain 的编排。之后，我们将探索使用短文本/文件进行文本摘要、总结长篇文章和书籍，并发现文本摘要的使用案例和模式。
- en: By the end of this chapter, you will be able to understand and implement text
    generation and summarization with Amazon Bedrock in real-world use cases.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，您将能够理解和实现使用 Amazon Bedrock 在实际用例中的文本生成和总结。
- en: 'Here are the key topics that will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下关键主题：
- en: Generating text
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成文本
- en: Summarizing text
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总结文本
- en: Creating a secure serverless solution
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建安全的无服务器解决方案
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter requires you to have access to an AWS account. If you don’t have
    one already, you can go to [https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)
    and create one.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章要求您拥有 AWS 账户访问权限。如果您还没有，可以访问 [https://aws.amazon.com/getting-started/](https://aws.amazon.com/getting-started/)
    并创建一个。
- en: 'Secondly, you will need to install and configure the AWS CLI ([https://aws.amazon.com/cli/](https://aws.amazon.com/cli/)).
    You will use this to access Amazon Bedrock FMs from your local machine. Since
    the majority of the code cells we will be executing are based in Python, setting
    up an AWS Python SDK (Boto3) ([https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html))
    would be beneficial at this point. You can carry out the Python setup in any way:
    install it on your local machine, or use AWS Cloud9, or utilize AWS Lambda, or
    leverage Amazon SageMaker. If you’re using Jupyter Notebook with the AWS Python
    SDK to interact with Amazon Bedrock, make sure you run the following code cell
    in the notebook to import the essential libraries and create a Bedrock runtime
    client:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，您需要安装和配置 AWS CLI ([https://aws.amazon.com/cli/](https://aws.amazon.com/cli/))。您将使用它从您的本地机器访问
    Amazon Bedrock FMs。由于我们将要执行的多数代码单元都是基于 Python 的，此时设置 AWS Python SDK (Boto3) ([https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html](https://docs.aws.amazon.com/bedrock/latest/APIReference/welcome.html))
    将非常有帮助。您可以通过任何方式执行 Python 设置：在您的本地机器上安装它，使用 AWS Cloud9，利用 AWS Lambda，或者利用 Amazon
    SageMaker。如果您使用带有 AWS Python SDK 的 Jupyter Notebook 与 Amazon Bedrock 交互，请确保在笔记本中运行以下代码单元以导入必要的库并创建
    Bedrock 运行时客户端：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: There will be a charge associated with invoking and customizing the FMs of Amazon
    Bedrock. Please refer to [https://aws.amazon.com/bedrock/pricing/](https://aws.amazon.com/bedrock/pricing/)
    to learn more.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 调用和定制 Amazon Bedrock 的 FMs 将产生相关费用。请参阅 [https://aws.amazon.com/bedrock/pricing/](https://aws.amazon.com/bedrock/pricing/)
    了解更多信息。
- en: Generating text
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成文本
- en: Text generation plays a crucial role in various sectors, from marketing and
    advertising to journalism and creative writing. The significance of this technique
    lies in its capacity to streamline content creation processes, boost productivity,
    and unlock new realms of creativity.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成在各个领域都发挥着至关重要的作用，从市场营销和广告到新闻业和创意写作。这种技术的意义在于其能够简化内容创作流程，提高生产力，并开启新的创意领域。
- en: One of the key advantages of text generation is its potential to save valuable
    time and resources. Traditional content creation methods can be time-consuming
    and labor-intensive, often requiring extensive research, writing, and editing
    efforts. But by using generative AI models, businesses and individuals can quickly
    produce initial drafts, outlines, or complete pieces of content, freeing up valuable
    time for other tasks.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成的一个关键优势是其能够节省宝贵的时间和资源。传统的内容创作方法可能耗时且劳动密集，通常需要大量的研究、写作和编辑工作。但通过使用生成式 AI 模型，企业和个人可以快速生成初稿、大纲或完整的内容，从而为其他任务腾出宝贵的时间。
- en: Furthermore, text generation empowers content creators to explore new narrative
    avenues and push the boundaries of their creativity. By providing a starting point
    or a framework, these tools can spark fresh ideas and facilitate the exploration
    of unconventional storytelling techniques or unique writing styles. This capability
    is particularly valuable in industries where originality and distinctiveness are
    highly prized, such as fiction writing, advertising campaigns, or brand storytelling
    initiatives.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，文本生成赋予内容创作者探索新的叙事途径和拓展其创造力的边界。通过提供起点或框架，这些工具可以激发新想法，并促进非传统叙事技巧或独特写作风格的探索。这种能力在原创性和独特性被高度重视的行业中尤其有价值，例如小说写作、广告活动或品牌故事讲述计划。
- en: In addition to creative applications, text generation also holds immense potential
    in fields that demand high volumes of informative and factual content. For instance,
    news reporting, scientific publications, technical documentation, and text generation
    can aid in the rapid dissemination of accurate and up-to-date information. By
    leveraging vast data repositories and subject matter expertise, these tools can
    generate comprehensive reports, summaries, or articles, ensuring that relevant
    information is readily available to the intended audience.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 除了创意应用外，文本生成在需要大量信息和事实性内容的领域也具有巨大的潜力。例如，新闻报道、科学出版物、技术文档和文本生成可以帮助快速传播准确和最新的信息。通过利用庞大的数据存储库和专业知识，这些工具可以生成全面的报告、摘要或文章，确保相关信息能够迅速提供给目标受众。
- en: Moreover, text generation offers exciting opportunities for personalization
    and customization. By analyzing user preferences, demographics, and contextual
    data, these tools can tailor content so that it resonates with specific target
    audiences, enhancing engagement and fostering stronger connections with readers
    or customers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，文本生成提供了令人兴奋的个性化和定制机会。通过分析用户偏好、人口统计信息和上下文数据，这些工具可以定制内容，使其与特定目标受众产生共鸣，增强参与度并加强与读者或客户的联系。
- en: Let’s look at some real-world applications of text generation in detail.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细看看文本生成在现实世界中的应用。
- en: Text generation applications
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本生成应用
- en: 'While the applications of text generation are endless, here are a few examples
    to get you started:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然文本生成的应用无限，以下是一些示例以供参考：
- en: '**Generating product descriptions**: Amazon Bedrock’s text generation capabilities
    can be leveraged to automate the creation of product descriptions for marketing
    teams. By inputting the product’s features, specifications, and key benefits,
    the FM can generate compelling and SEO-optimized descriptions that highlight the
    unique selling points of the product. This can significantly streamline the process
    of creating product descriptions, saving time and resources for marketing teams.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成产品描述**：Amazon Bedrock的文本生成能力可以被用于为营销团队自动化创建产品描述。通过输入产品的特性、规格和关键优势，FM可以生成引人入胜且SEO优化的描述，突出产品的独特卖点。这可以显著简化创建产品描述的过程，为营销团队节省时间和资源。'
- en: The generated descriptions can be tailored to different target audiences, tone,
    and style preferences, ensuring a consistent and engaging brand voice across various
    channels. Additionally, the FM can be customized on existing product descriptions,
    allowing it to learn and mimic the desired writing style and formatting.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 生成的描述可以根据不同的目标受众、语气和风格偏好进行定制，确保在各种渠道上保持一致且引人入胜的品牌声音。此外，FM可以定制现有的产品描述，使其能够学习和模仿期望的写作风格和格式。
- en: '**Media articles and marketing campaigns generation**: Amazon Bedrock’s text
    generation capabilities can be utilized for creating high-quality content for
    media articles, blog posts, and marketing campaigns. By providing relevant information,
    data, and guidelines, the FM can generate well-structured and coherent articles
    that can be used for content marketing, thought leadership, or news dissemination.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**媒体文章和营销活动生成**：Amazon Bedrock的文本生成能力可用于创建媒体文章、博客文章和营销活动的高质量内容。通过提供相关信息、数据和指南，FM可以生成结构良好且连贯的文章，可用于内容营销、思想领导或新闻传播。'
- en: The FM can be trained on existing content, enabling it to understand and mimic
    the tone, style, and formatting preferences of specific publications or brands.
    It can also generate attention-grabbing headlines, engaging introductions, and
    compelling **calls to action** (**CTAs**) for marketing campaigns.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: FM可以在现有内容上进行训练，使其能够理解和模仿特定出版物或品牌的语气、风格和格式偏好。它还可以为营销活动生成吸引注意力的标题、引人入胜的引言和引人注目的**行动号召**（CTAs）。
- en: '**Personalized email and message composition**: Amazon Bedrock can be utilized
    to compose personalized emails, messages, and other written communications for
    customer outreach, marketing campaigns, or even internal communications. By leveraging
    customer data and preferences, the FM can generate highly tailored and engaging
    content, enhancing customer experience and increasing brand loyalty.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个性化电子邮件和消息撰写**：Amazon Bedrock可用于撰写个性化的电子邮件、消息和其他书面沟通，用于客户联系、营销活动，甚至内部沟通。通过利用客户数据和偏好，FM可以生成高度定制和引人入胜的内容，提升客户体验并增加品牌忠诚度。'
- en: '**Healthcare**: Clinical documentation is a critical aspect of healthcare,
    but it can be time-consuming and prone to errors. Bedrock can assist healthcare
    professionals in streamlining the note-taking and documentation process by generating
    accurate and comprehensive clinical notes based on conversations or dictations
    during patient encounters. Amazon offers another service called *AWS HealthScribe*
    that’s powered by Amazon Bedrock and is specifically designed to do that. To learn
    more about AWS HealthScribe, go to [https://aws.amazon.com/healthscribe/](https://aws.amazon.com/healthscribe/).'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**医疗保健**：临床文档是医疗保健的一个关键方面，但它可能耗时且容易出错。Bedrock可以通过根据患者接触期间的对话或口述生成准确和全面的临床笔记来协助医疗保健专业人员简化笔记和文档过程。Amazon还提供另一种名为*AWS
    HealthScribe*的服务，该服务由Amazon Bedrock提供支持，专门为此目的而设计。要了解更多关于AWS HealthScribe的信息，请访问[https://aws.amazon.com/healthscribe/](https://aws.amazon.com/healthscribe/)。'
- en: Bedrock can be employed to generate personalized health and wellness recommendations
    tailored to an individual’s unique health profile, lifestyle, and preferences.
    By analyzing data from various sources, such as **electronic health records**
    (**EHRs**), wearable devices, and self-reported information, Bedrock can provide
    tailored recommendations for diet, exercise, stress management, and preventive
    care.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Bedrock可用于生成针对个人独特健康状况、生活方式和偏好的个性化健康和福祉建议。通过分析来自各种来源的数据，例如**电子健康记录**（EHRs）、可穿戴设备和自我报告信息，Bedrock可以提供针对饮食、锻炼、压力管理和预防保健的定制建议。
- en: Text generation systems with Amazon Bedrock
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Amazon Bedrock文本生成系统
- en: 'If you have been following the previous chapters, you may have already tried
    generating text on Amazon Bedrock. But just as a reminder, a simple text generation
    system looks like this:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经阅读了前面的章节，您可能已经尝试在Amazon Bedrock上生成文本。但为了提醒，一个简单的文本生成系统看起来是这样的：
- en: '![Figure 6.1 – Simple text generation system](img/B22045_06_01.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图6.1 – 简单文本生成系统](img/B22045_06_01.jpg)'
- en: Figure 6.1 – Simple text generation system
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 – 简单文本生成系统
- en: 'You provide a prompt to the model and say something like `Compose an email
    to a customer support team`. Even if you don’t provide any context, the model
    will generate a sample email for you (as shown in *Figure 6**.2*):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 您向模型提供提示并说类似于“为客服团队撰写一封电子邮件”的话。即使您没有提供任何上下文，模型也会为您生成一个示例电子邮件（如图*6.2*所示）：
- en: '![Figure 6.2 – Generating an email](img/B22045_06_02.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图6.2 – 生成电子邮件](img/B22045_06_02.jpg)'
- en: Figure 6.2 – Generating an email
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 – 生成电子邮件
- en: 'In your Jupyter Notebook environment with the AWS Python SDK, run the following
    sample script to invoke the AI21 Jurassic model. Make sure you import the essential
    libraries and create the Bedrock runtime client first, as mentioned in the *Technical*
    *requirements* section:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的Jupyter Notebook环境中使用AWS Python SDK，运行以下示例脚本以调用AI21 Jurassic模型。请确保您首先导入必要的库并创建Bedrock运行时客户端，如*技术要求*部分所述：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, based on the model that you select, the response’s structure and output
    may vary. *Figure 6**.3* shows the response from the AI21 Jurassic model:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，根据您选择的模型，响应的结构和输出可能会有所不同。*图6.3*显示了AI21 Jurassic模型的响应：
- en: '![Figure 6.3 – AI21 Jurassic output](img/B22045_06_03.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图6.3 – AI21 Jurassic输出](img/B22045_06_03.jpg)'
- en: Figure 6.3 – AI21 Jurassic output
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 – AI21 Jurassic输出
- en: Here, we provided a simple prompt without providing any context or information.
    Now, let’s move on to the advanced architecture patterns of text generation and
    understand contextual prompting.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们提供了一个简单的提示，没有提供任何上下文或信息。现在，让我们继续探讨文本生成的先进架构模式，并了解上下文提示。
- en: Generating text using prompt engineering
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用提示工程生成文本
- en: 'In the previous section, we looked at a pattern of text generation where we
    did not provide any context or information to the model. Let’s use some of the
    prompt engineering techniques we learned about in [*Chapter 3*](B22045_03.xhtml#_idTextAnchor053):'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们查看了一种文本生成模式，我们没有向模型提供任何上下文或信息。让我们使用我们在 [*第 3 章*](B22045_03.xhtml#_idTextAnchor053)
    中了解到的某些提示工程技巧：
- en: '**Zero-shot contextual prompting**: Here, we will provide detailed context
    in the prompt in a zero-shot fashion:'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**零样本上下文提示**：在这里，我们将以零样本的方式在提示中提供详细上下文：'
- en: '[PRE2]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Running the preceding code will generate a response similar to the one shown
    in *Figure 6**.4*:'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 运行前面的代码将生成类似于 *图 6.4* 中所示的一个响应：
- en: '![Figure 6.4 – Zero-shot contextual prompt response](img/B22045_06_04.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.4 – 零样本上下文提示响应](img/B22045_06_04.jpg)'
- en: Figure 6.4 – Zero-shot contextual prompt response
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.4 – 零样本上下文提示响应
- en: In the preceding scenario, we used the Amazon Bedrock API – `invoke_model` –
    and passed the prompt, configuration parameters, and model ID. If you want to
    learn more about the various Bedrock APIs that are available, you are encouraged
    to revisit [*Chapter 2*](B22045_02.xhtml#_idTextAnchor034).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的场景中，我们使用了 Amazon Bedrock API – `invoke_model` – 并传递了提示、配置参数和模型 ID。如果您想了解更多关于可用的各种
    Bedrock API，请鼓励您重新阅读 [*第 2 章*](B22045_02.xhtml#_idTextAnchor034)。
- en: '**Few-shot contextual prompting**: Here, we will provide some examples in our
    prompt so that the model can start to generate reasonable continuations:'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**少样本上下文提示**：在这里，我们将在提示中提供一些示例，以便模型可以开始生成合理的延续：'
- en: '[PRE12]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Here, we provided three examples in our prompt to tell the model how our response
    should look. Then, we invoked the model to generate a product description for
    `Sony A7 III Mirrorless Camera`. We received the response shown in *Figure 6**.5*:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们在提示中提供了三个示例，以告诉模型我们的响应应该是什么样子。然后，我们调用了模型来为 `Sony A7 III 无反相机` 生成产品描述。我们收到了
    *图 6.5* 中所示的响应：
- en: '![Figure 6.5 – Few-shot contextual prompting response](img/B22045_06_05.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.5 – 少样本上下文提示响应](img/B22045_06_05.jpg)'
- en: Figure 6.5 – Few-shot contextual prompting response
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.5 – 少样本上下文提示响应
- en: '`invoke_model` API in this case):'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在此情况下，使用 `invoke_model` API):'
- en: Note
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: At the time of writing, we used `langchain_community.llms` library to import
    *Bedrock*. However, based on the updates from the LangChain community, it may
    be susceptible to change. For updated information on importing the LangChain package,
    please visit [https://python.langchain.com/v0.2/docs/integrations/platforms/](https://python.langchain.com/v0.2/docs/integrations/platforms/).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，我们使用了 `langchain_community.llms` 库来导入 *Bedrock*。然而，根据 LangChain 社区的更新，它可能容易发生变化。有关导入
    LangChain 包的最新信息，请访问 [https://python.langchain.com/v0.2/docs/integrations/platforms/](https://python.langchain.com/v0.2/docs/integrations/platforms/)。
- en: '[PRE33]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![Figure 6.6 – Zero-shot prompting with LangChain](img/B22045_06_06.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.6 – 使用 LangChain 的零样本提示](img/B22045_06_06.jpg)'
- en: Figure 6.6 – Zero-shot prompting with LangChain
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.6 – 使用 LangChain 的零样本提示
- en: '**Contextual generation with LangChain**: Here, we will provide instructions
    and context in our prompts before sending them to the model:'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用 LangChain 的上下文生成**：在这里，我们在将提示发送到模型之前，将在我们的提示中提供指令和上下文：'
- en: '[PRE34]'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[PRE54]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: In this scenario, we used the LangChain implementation of Bedrock. We defined
    a prompt template for creating a product description and invoked the Anthropic
    Claude model to generate a product description of a smart home security camera.
    The prompt template is essentially a reusable template for constructing prompts.
    Within the prompt template, you can provide the context, input variables, task,
    and some few-shot examples for the model to reference. To learn more about prompt
    templates, go to [https://python.langchain.com/v0.2/docs/concepts/#prompt-templates](https://python.langchain.com/v0.2/docs/concepts/#prompt-templates).
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个场景中，我们使用了 Bedrock 的 LangChain 实现。我们定义了一个用于创建产品描述的提示模板，并调用了 Anthropic Claude
    模型来生成智能家用安全摄像头的描述。提示模板本质上是一个可重复使用的模板，用于构建提示。在提示模板中，您可以提供上下文、输入变量、任务以及一些少样本示例供模型参考。要了解更多关于提示模板的信息，请访问
    [https://python.langchain.com/v0.2/docs/concepts/#prompt-templates](https://python.langchain.com/v0.2/docs/concepts/#prompt-templates)。
- en: 'The following figure shows the response from providing the preceding code snippet:'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图显示了提供前面代码片段的响应：
- en: '![Figure 6.7 – Contextual generation with LangChain](img/B22045_06_07.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图6.7 – 使用LangChain的上下文生成](img/B22045_06_07.jpg)'
- en: Figure 6.7 – Contextual generation with LangChain
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 – 使用LangChain的上下文生成
- en: Now that we’ve looked at various text generation patterns, let’s look at how
    we can perform summarization using Amazon Bedrock.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了各种文本生成模式，让我们看看如何使用Amazon Bedrock进行摘要。
- en: Summarizing text
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要文本
- en: Text summarization is a highly sought-after capability that holds immense value
    across diverse domains. It involves the intricate task of condensing lengthy text
    documents into concise and coherent summaries that capture the essence of the
    original content. These summaries aim to preserve the most salient information
    while omitting redundant or irrelevant details, thereby enabling efficient consumption
    and comprehension of extensive textual data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 文本摘要是一项高度需求的能力，在各个领域都具有巨大的价值。它涉及将长文本文档浓缩成简洁且连贯的摘要的复杂任务，这些摘要旨在保留最显著的信息，同时省略冗余或不相关的细节，从而实现高效的数据消费和理解。
- en: Text summarization finds applications in a wide range of sectors, from research
    and academia to journalism, business intelligence, and legal documentation. With
    the exponential growth of textual data generated daily, the need for effective
    summarization techniques has become increasingly paramount. Imagine sifting through
    voluminous reports, news articles, or legal documents – text summarization emerges
    as a powerful tool to distill the core information, saving time and cognitive
    effort for professionals and researchers alike.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 文本摘要广泛应用于各个领域，从研究、学术界到新闻、商业智能和法律文件。随着每天产生的文本数据的指数级增长，对有效摘要技术的需求变得越来越迫切。想象一下，在大量的报告、新闻文章或法律文件中筛选——文本摘要成为提炼核心信息的有力工具，为专业人士和研究人员节省时间和认知努力。
- en: 'Let’s look at some of the real-world applications of text summarization:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看文本摘要的一些实际应用：
- en: '**Content curation**: In today’s information-rich world, text summarization
    plays a pivotal role in curating and condensing vast amounts of data. This allows
    users to quickly grasp the essence of lengthy articles, reports, or online content
    without having to read every word.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容整理**：在当今信息丰富的世界中，文本摘要技术在整理和浓缩大量数据方面发挥着关键作用。这使得用户能够快速抓住长篇文章、报告或在线内容的精髓，而无需阅读每个单词。'
- en: '**News aggregation**: News aggregators and media platforms can leverage text
    summarization to provide concise summaries of breaking news stories, enabling
    users to stay informed about the latest developments without getting bogged down
    by extensive details.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新闻聚合**：新闻聚合器和媒体平台可以利用文本摘要技术提供突发新闻故事的简洁摘要，使用户能够了解最新的发展，而不会因详尽细节而感到困扰。'
- en: '**Research assistance**: Researchers and academics can benefit from text summarization
    techniques to quickly identify the most pertinent information from a vast corpus
    of literature, saving them valuable time and effort.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**研究辅助**：研究人员和学者可以从文本摘要技术中受益，以快速从大量文献中识别最相关的信息，从而节省他们宝贵的时间和精力。'
- en: '**Customer service**: Text summarization can enhance customer service by automatically
    generating concise summaries of lengthy customer inquiries or feedback, allowing
    support agents to quickly comprehend the crux of the issue and provide timely
    responses.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户服务**：文本摘要可以通过自动生成长客户咨询或反馈的简洁摘要来增强客户服务，使支持代理能够快速理解问题的核心并提供及时响应。'
- en: '**Legal and financial domains**: In industries where accurate representation
    of original text is critical, such as legal or financial sectors, text summarization
    techniques can be employed to generate summaries of contracts, agreements, or
    reports, ensuring that key information is not overlooked.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**法律和金融领域**：在准确呈现原始文本至关重要的行业，如法律或金融部门，文本摘要技术可以用于生成合同、协议或报告的摘要，确保关键信息不会被忽视。'
- en: '**Email management**: Email clients or productivity tools can leverage text
    summarization to provide concise overviews of long email threads or conversations,
    helping users quickly grasp the key points without having to read through every
    message.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电子邮件管理**：电子邮件客户端或生产力工具可以利用文本摘要技术提供长电子邮件线程或对话的简洁概述，帮助用户快速抓住要点，而无需阅读每条消息。'
- en: '**Meeting recap**: Text summarization can be applied to meeting transcripts
    or notes, generating succinct summaries that capture the most important discussions,
    decisions, and action items, enabling participants to quickly review and follow
    up on critical points.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**会议回顾**：文本摘要可以应用于会议记录或笔记，生成简洁的摘要，捕捉最重要的讨论、决策和行动项目，使参与者能够快速回顾并跟进关键点。'
- en: '**Social media monitoring**: Businesses and organizations can utilize text
    summarization to analyze and summarize vast amounts of social media data, such
    as customer feedback, product reviews, or brand mentions, enabling them to stay
    informed about public sentiment and respond promptly.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**社交媒体监控**：企业和组织可以利用文本摘要来分析和总结大量的社交媒体数据，如客户反馈、产品评论或品牌提及，使他们能够了解公众情绪并迅速做出回应。'
- en: '**Knowledge extraction**: Text summarization techniques can be used to extract
    and summarize relevant knowledge from large datasets or knowledge bases, making
    it easier to access and leverage valuable information for various applications,
    such as decision-making or knowledge management systems.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**知识提取**：文本摘要技术可以用于从大型数据集或知识库中提取和总结相关知识，使其更容易访问和利用有价值的信息，用于各种应用，如决策或知识管理系统。'
- en: '**Educational resources**: Text summarization can be applied to educational
    materials, such as textbooks or online courses, to generate concise summaries
    or study aids, helping students grasp key concepts and prepare for exams more
    efficiently.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**教育资源**：文本摘要技术可以应用于教育材料，如教科书或在线课程，以生成简洁的摘要或学习辅助工具，帮助学生更有效地掌握关键概念并准备考试。'
- en: 'While the list of applications is endless and spans across every industry,
    let’s look at how summarization systems work with Amazon Bedrock. We will learn
    about two approaches:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然应用范围无限，涵盖了各行各业，但让我们看看摘要系统如何与Amazon Bedrock协同工作。我们将了解两种方法：
- en: Summarization of small files
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小文件的摘要
- en: Summarization of large files
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大文件的摘要
- en: By small files, we mean pieces of text that fit into the context length of the
    model. This could range from a couple of sentences to a few paragraphs. On the
    other hand, by large files, we mean large documents or book(s) worth of information
    that does not fit into the context length of the model. It is important to note
    that there is no one-size-fits-all that works across all models. Every model,
    including their different versions, might have a different context length. For
    example, Cohere Command R+ has a context length of 128K tokens, while Cohere Command
    Light has a context length of 4,000 tokens.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所说的“小文件”，是指可以适应模型上下文长度的文本片段。这可以是从几句话到几段文字不等。另一方面，“大文件”则是指那些信息量巨大，无法适应模型上下文长度的文档或书籍。需要注意的是，没有一种适用于所有模型的万能解决方案。每个模型及其不同版本可能具有不同的上下文长度。例如，Cohere
    Command R+的上下文长度为128K个标记，而Cohere Command Light的上下文长度为4,000个标记。
- en: Summarization of small files
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小文件的摘要
- en: 'Small files can include meeting notes, blog posts, news articles, email messages,
    and call transcripts. These files are then used as a context for the prompt and
    sent to the model. The prompt here could be as simple as `Summarize the content`.
    The model then processes the file and provides you with the summarized response.
    *Figure 6**.8* shows the process of small file summarization:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 小文件可以包括会议记录、博客文章、新闻文章、电子邮件和通话记录。这些文件随后被用作提示的上下文并发送给模型。这里的提示可能非常简单，例如“摘要内容”。然后，模型将处理文件并提供摘要响应。*图6.8*展示了小文件摘要的过程：
- en: '![Figure 6.8 – Small file summarization](img/B22045_06_08.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图6.8 – 小文件摘要](img/B22045_06_08.jpg)'
- en: Figure 6.8 – Small file summarization
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8 – 小文件摘要
- en: 'Let’s consider an example of a news article from Yahoo! Finance. Since the
    news article fits into the context length of the model, we will use that as a
    context in the prompt, `Summarize the following news article`, and send it to
    the model. The model will then process the request and provide the summarized
    response, as shown in *Figure 6**.9*:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以Yahoo! Finance的新闻文章为例。由于新闻文章可以适应模型的上下文长度，我们将将其作为提示中的上下文，即“摘要以下新闻文章”，并将其发送给模型。然后，模型将处理请求并提供摘要响应，如图*6.9*所示。
- en: '![Figure 6.9 – Summarization of a news article](img/B22045_06_09.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图6.9 – 新闻文章的摘要](img/B22045_06_09.jpg)'
- en: Figure 6.9 – Summarization of a news article
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9 – 新闻文章的摘要
- en: 'There are a couple of ways to summarize small files in Bedrock. If you’re using
    the AWS Python SDK, you can pass the small file text into the prompt directly,
    as shown in the following code. However, if you would like to summarize a couple
    of paragraphs, you can utilize *prompt templates* to place the text dynamically
    within the prompts and use LangChain to invoke the model:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Bedrock 中总结小文件有几种方法。如果你使用 AWS Python SDK，可以直接将小文件文本传递到提示中，如下面的代码所示。然而，如果你想总结几段文字，你可以利用
    *提示模板* 将文本动态地放置在提示中，并使用 LangChain 调用模型：
- en: '[PRE55]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The response is shown in *Figure 6**.10*:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 响应在 *图 6.10* 中显示：
- en: '![Figure 6.10 – Small file summarization response](img/B22045_06_10.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.10 – 小文件总结响应](img/B22045_06_10.jpg)'
- en: Figure 6.10 – Small file summarization response
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.10 – 小文件总结响应
- en: We have parsed a news article ([https://finance.yahoo.com/news/us-174-time-put-amazon-110026932.html](https://finance.yahoo.com/news/us-174-time-put-amazon-110026932.html))
    from Yahoo! Finance as a sample context to the prompt and invoked the Titan text
    model to generate the summarized response, as shown in the preceding figure.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将一篇新闻文章（[https://finance.yahoo.com/news/us-174-time-put-amazon-110026932.html](https://finance.yahoo.com/news/us-174-time-put-amazon-110026932.html)）从
    Yahoo! Finance 解析出来，作为提示的样本上下文，并调用了 Titan 文本模型来生成总结的响应，如图中所示。
- en: Now, let’s look at the techniques for summarizing large files.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看总结大文件的技术。
- en: Summarization of large files
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大文件的总结
- en: 'Large files can include large documents or book(s) worth of information that
    do not fit into the context length of the model. When we say large documents,
    this includes 10-K reports, **Federal Open Market Committee** (**FOMC**) reports,
    public health reports, clinical study reports, e-magazines, service documentation,
    and more. The 10-K report for Amazon is an example of a large file: [https://www.sec.gov/Archives/edgar/data/1018724/000101872424000008/amzn-20231231.htm](https://www.sec.gov/Archives/edgar/data/1018724/000101872424000008/amzn-20231231.htm).'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 大文件可以包括大量文档或书籍的信息，这些信息不适合模型的上下文长度。当我们说大文档时，这包括 10-K 报告、**联邦公开市场委员会**（**FOMC**）报告、公共卫生报告、临床试验报告、电子杂志、服务文档等等。亚马逊的
    10-K 报告就是一个大文件的例子：[https://www.sec.gov/Archives/edgar/data/1018724/000101872424000008/amzn-20231231.htm](https://www.sec.gov/Archives/edgar/data/1018724/000101872424000008/amzn-20231231.htm)。
- en: 'When working with large files for summarizing text, several challenges are
    involved:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理用于总结文本的大文件时，会涉及几个挑战：
- en: '**Context length limitations**: All FMs, such as the ones used in Amazon Bedrock,
    have a maximum context length or input size that they can process at once. This
    limit varies from model to model, but it is typically in the range of a few thousand
    tokens (words or word pieces). For example, you can find FMs such as the Anthropic
    Claude 3 family with 200k tokens. When working with large documents that exceed
    this context length, it becomes impossible to summarize the entire document accurately
    and coherently. The model may miss important information or fail to capture the
    overall context and nuances present in the original text.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文长度限制**：所有 FM，例如在 Amazon Bedrock 中使用的 FM，都有一个它们可以一次性处理的最大上下文长度或输入大小。这个限制因模型而异，但通常在几千个标记（单词或词片段）的范围内。例如，你可以找到具有
    200k 标记的 Anthropic Claude 3 系列的 FM。当处理超过这个上下文长度的文档时，就变得不可能准确和连贯地总结整个文档。模型可能会错过重要信息，或者无法捕捉到原始文本中存在的整体上下文和细微差别。'
- en: '**Hallucinations**: Hallucination is a phenomenon where models generate output
    that is not grounded in the input data or contains factual inconsistencies. This
    issue can become more prevalent when dealing with large documents as the model
    might struggle to maintain coherence and faithfulness to the original text. As
    the input size increases, the model may start generating plausible-sounding but
    factually incorrect information, potentially leading to inaccurate summaries.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**幻觉**：幻觉是一种现象，其中模型生成的输出不是基于输入数据，或者包含事实上的不一致。当处理大文档时，这个问题可能会更加普遍，因为模型可能难以保持连贯性和对原始文本的忠实度。随着输入大小的增加，模型可能会开始生成听起来合理但实际上错误的信息，这可能导致总结不准确。'
- en: '**Memory and computational constraints**: Summarizing large documents can be
    computationally intensive and may require significant memory resources. Generative
    AI models need to process and store the entire input text, as well as intermediate
    representations and generated outputs. When working with very large documents,
    you might experience performance degradation due to the high computational demands
    if they’re not handled with dedicated compute capacity (see the *Provisioned throughput
    architecture* section in [*Chapter 12*](B22045_12.xhtml#_idTextAnchor226)).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存和计算限制**：总结大文档可能非常耗费计算资源，并且可能需要大量的内存资源。生成式AI模型需要处理和存储整个输入文本，以及中间表示和生成的输出。当处理非常大的文档时，如果没有使用专门的计算能力来处理，可能会因为高计算需求而出现性能下降（参见[*第12章*](B22045_12.xhtml#_idTextAnchor226)中的*配置吞吐量架构*部分）。'
- en: '**Context understanding**: Large documents often contain complex structures,
    such as sections, subsections, and cross-references. Generative AI models may
    struggle to accurately capture and understand the relationships and dependencies
    between different parts of the document. This can lead to summaries that lack
    coherence or fail to accurately represent the overall structure and flow of the
    original content.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文理解**：大文档通常包含复杂的结构，如章节、子章节和交叉引用。生成式AI模型可能难以准确捕捉和理解文档不同部分之间的关系和依赖。这可能导致摘要缺乏连贯性或无法准确代表原始内容的整体结构和流程。'
- en: '**Topic drift and coherence**: As the length of the input text increases, it
    becomes more challenging for the models to maintain focus and coherence throughout
    the summarization process. The model may drift away from the main topic or fail
    to properly connect and transition between different aspects of the document,
    resulting in summaries that lack cohesion or clarity.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主题漂移和连贯性**：随着输入文本长度的增加，模型在摘要过程中保持关注和连贯性变得更加困难。模型可能会偏离主要主题，或者无法正确连接和过渡到文档的不同方面，导致摘要缺乏连贯性或清晰度。'
- en: To address these challenges, let’s look at summarizing large files using LangChain.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些挑战，让我们看看如何使用LangChain来总结大文件。
- en: Text summarization using LangChain’s summarization chain
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 LangChain 的摘要链进行文本摘要
- en: 'Using LangChain, we are going to break down large files into smaller, more
    manageable chunks and process them sequentially. *Figure 6**.11* shows the architecture
    of large text summarization using LangChain:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LangChain，我们将大文件分解成更小、更易于管理的块，并按顺序处理它们。*图6.11*展示了使用LangChain进行大文本摘要的架构：
- en: '![Figure 6.11 – Large file summarization in LangChain](img/B22045_06_11.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图6.11 – LangChain中的大文件摘要](img/B22045_06_11.jpg)'
- en: Figure 6.11 – Large file summarization in LangChain
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.11 – LangChain中的大文件摘要
- en: 'Here’s how the process works:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是这个过程的工作原理：
- en: '**Data ingestion**: The first step in the process is to load a large document
    or file into the system. This involves loading the file from an Amazon S3 bucket
    or downloading it directly from the internet. The files you can provide can be
    in the form of text, PDF, Word documents, and more.'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据摄取**：这个过程的第一步是将一个大文档或文件加载到系统中。这涉及到从Amazon S3存储桶中加载文件或直接从互联网下载。您可以提供的文件可以是文本、PDF、Word文档等多种形式。'
- en: '`RecursiveCharacterTextSplitter` is recommended for general text, as per the
    LangChain documentation: [https://python.langchain.com/v0.2/docs/how_to/recursive_text_splitter/](https://python.langchain.com/v0.2/docs/how_to/recursive_text_splitter/).'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据 LangChain 文档的建议，`RecursiveCharacterTextSplitter` 适用于通用文本：[https://python.langchain.com/v0.2/docs/how_to/recursive_text_splitter/](https://python.langchain.com/v0.2/docs/how_to/recursive_text_splitter/).
- en: It recursively splits the text into smaller chunks until each chunk’s size falls
    below a specified threshold. The splitting process leverages separators (`"\n\n"`,
    `"\n"`), which ensures that individual paragraphs remain intact within a single
    chunk, rather than being fragmented across multiple chunks.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 它递归地将文本分割成更小的块，直到每个块的大小低于指定的阈值。分割过程利用分隔符（`"\n\n"`，`"\n"`），确保单个段落保持完整，而不是被分割到多个块中。
- en: '`stuff`: As the name suggests, this chain stuffs all the chunks into a single
    prompt.'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`stuff`：正如其名所示，这个链将所有块填充到一个单独的提示中。'
- en: '`map_reduce`: The map-reduce chain is a powerful pattern that allows you to
    split a large task into smaller subtasks, process them independently, and then
    combine the results. In the context of text summarization, this chain type is
    used to break down a long text document into smaller chunks, summarize each chunk
    independently using an LLM, and then combine the summaries into a final summarized
    output.'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`map_reduce`：map-reduce链是一个强大的模式，允许您将一个大任务分解成更小的子任务，独立处理它们，然后将结果合并。在文本摘要的上下文中，这种链类型用于将长文本文档分解成更小的块，独立使用LLM对每个块进行摘要，然后将摘要合并成最终的摘要输出。'
- en: '`refine`: This chain starts by summarizing the first chunk. Then, `refine`
    takes this summary and combines it with the second chunk to generate a new summary
    that encompasses both pieces of information. This process continues, where the
    latest summary is combined with the next chunk, and a new summary is generated.
    This iterative approach repeats until all the chunks have been incorporated into
    the final summary.'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`refine`：这个链首先对第一个块进行摘要。然后，`refine`将这个摘要与第二个块结合，生成一个新的摘要，包含这两部分信息。这个过程继续进行，最新的摘要与下一个块结合，生成一个新的摘要。这种迭代方法一直重复，直到所有块都被纳入最终的摘要中。'
- en: 'To load any of these summarization chains, you can call `load_summarize_chain`
    and provide the chain type:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载这些摘要链中的任何一个，您可以调用`load_summarize_chain`并提供链类型：
- en: '[PRE56]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '**Final summary**: Based on the summarization chain you select and once all
    the chunks have been processed, the final summary represents a condensed version
    of the entire original document.'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**最终摘要**：基于您选择的摘要链，一旦所有块都已处理，最终的摘要代表了整个原始文档的浓缩版本。'
- en: The notebook at [https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/06_OpenSource_examples/00_Langchain_TextGeneration_examples/05_long-text-summarization-titan%20Langchain.ipynb](https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/06_OpenSource_examples/00_Langchain_TextGeneration_examples/05_long-text-summarization-titan%20Langchain.ipynb)
    showcases the use of long text summarization using LangChain. In this example,
    it uses `map_reduce` as the chain type. We recommend that you try out different
    chain types and provide any blog posts, files, or news articles as a prompt.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在[https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/06_OpenSource_examples/00_Langchain_TextGeneration_examples/05_long-text-summarization-titan%20Langchain.ipynb](https://github.com/aws-samples/amazon-bedrock-workshop/blob/main/06_OpenSource_examples/00_Langchain_TextGeneration_examples/05_long-text-summarization-titan%20Langchain.ipynb)的笔记本中展示了使用LangChain进行长文本摘要的使用示例。在这个例子中，它使用`map_reduce`作为链类型。我们建议您尝试不同的链类型，并提供任何博客文章、文件或新闻文章作为提示。
- en: 'Now that we’ve summarized large files using the LangChain chain type, let’s
    say we want to summarize a whole book or multiple books’ worth of information.
    In such scenarios, where large manuscripts or books need to be summarized, the
    RAG approach can be potentially beneficial. However, please note that the summarized
    response might not contain some essential elements from the book – in other words,
    there could be information loss. Various advanced RAG techniques, such as query
    refinement, can be utilized to retrieve the summarized response and essential
    elements from the text. To learn more about query refinement for RAG, please take
    a look at the paper *RQ-RAG: Learning to Refine Queries for Retrieval Augmented*
    *Generation* ([https://arxiv.org/html/2404.00610v1](https://arxiv.org/html/2404.00610v1)).'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '现在我们已经使用LangChain链类型对大文件进行了摘要，假设我们想要摘要一本书或多本书的信息。在这种情况下，当需要总结大量手稿或书籍时，RAG方法可能具有潜在的好处。但是请注意，摘要的响应可能不包含书籍的一些基本元素——换句话说，可能会有信息丢失。可以使用各种高级RAG技术，如查询细化，来检索摘要响应和文本中的基本元素。要了解更多关于RAG查询细化的信息，请参阅论文*RQ-RAG:
    Learning to Refine Queries for Retrieval Augmented* *Generation* ([https://arxiv.org/html/2404.00610v1](https://arxiv.org/html/2404.00610v1))。'
- en: To learn more about how RAG works and some advanced RAG techniques, please refer
    to [*Chapter 5*](B22045_05.xhtml#_idTextAnchor090).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于RAG如何工作以及一些高级RAG技术，请参阅[*第五章*](B22045_05.xhtml#_idTextAnchor090)。
- en: Next, we’ll look at text summarization via Amazon Bedrock Knowledge Base.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过Amazon Bedrock知识库查看文本摘要。
- en: Amazon Bedrock Knowledge Base
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon Bedrock知识库
- en: In [*Chapter 5*](B22045_05.xhtml#_idTextAnchor090), we looked at how Amazon
    Bedrock Knowledge Base works and how to set it up. Let’s see an example of summarization
    using Knowledge Base.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第五章*](B22045_05.xhtml#_idTextAnchor090)中，我们探讨了Amazon Bedrock知识库的工作原理以及如何设置它。让我们看看使用知识库进行摘要的示例。
- en: 'We have put the *Attention is All You Need* research paper in our data store
    Amazon S3 bucket and synced it with our Bedrock Knowledge base, as shown in *Figure
    6**.12*:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将 *Attention is All You Need* 研究论文放入我们的数据存储 Amazon S3 存储桶，并将其与我们的 Bedrock
    知识库同步，如图 *图 6*.12* 所示：
- en: '![Figure 6.12 – Knowledge Base data source](img/B22045_06_12.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.12 – 知识库数据源](img/B22045_06_12.jpg)'
- en: Figure 6.12 – Knowledge Base data source
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.12 – 知识库数据源
- en: 'Select the model and provide a prompt to summarize the content. You will see
    the response from the LLM, as shown in *Figure 6**.13*:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 选择模型并提供一个提示来总结内容。您将看到 LLM 的响应，如图 *图 6*.13* 所示：
- en: '![Figure 6.13 – Test Knowledge base](img/B22045_06_13.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.13 – 测试知识库](img/B22045_06_13.jpg)'
- en: Figure 6.13 – Test Knowledge base
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.13 – 测试知识库
- en: If you would like to try this via APIs, you can call the **Retrieve** API or
    the **RetrieveAndGenerate** API. The Retrieve API accesses and retrieves the relevant
    data from Knowledge Base, whereas the RetrieveAndGenerate API, in addition to
    retrieving the data, generates the response based on the retrieved results. For
    more details on Amazon Bedrock Knowledge Base, please refer to [*Chapter 5*](B22045_05.xhtml#_idTextAnchor090).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想通过 API 尝试，您可以调用 **Retrieve** API 或 **RetrieveAndGenerate** API。Retrieve
    API 访问并从知识库检索相关数据，而 RetrieveAndGenerate API 除了检索数据外，还根据检索到的结果生成响应。有关 Amazon Bedrock
    知识库的更多详细信息，请参阅 [*第 5 章*](B22045_05.xhtml#_idTextAnchor090)。
- en: In this section, we discussed how to utilize text summarization systems with
    Amazon Bedrock. Summarizing small files is straightforward and involves utilizing
    the model’s context length. However, summarizing large files requires chunking
    and specialized techniques such as LangChain’s summarization chains, RAG, or Amazon
    Bedrock Knowledge Base to handle context length limitations, hallucination, computational
    constraints, and coherence issues.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了如何利用 Amazon Bedrock 中的文本摘要系统。总结小文件很简单，涉及利用模型的上下文长度。然而，总结大文件需要分块和专门的技巧，如
    LangChain 的摘要链、RAG 或 Amazon Bedrock 知识库来处理上下文长度限制、幻觉、计算约束和连贯性问题。
- en: Now that we have looked at generating and summarizing text using Amazon Bedrock,
    let’s look at how organizations can use these techniques and create a secure serverless
    solution involving other AWS services.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经了解了如何使用 Amazon Bedrock 生成和总结文本，那么让我们看看组织如何使用这些技术并创建一个涉及其他 AWS 服务的安全无服务器解决方案。
- en: Creating a secure serverless solution
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个安全无服务器解决方案
- en: When working with Generative AI models from Amazon Bedrock, organizations can
    develop an application that is secure and serverless. Instead of interacting directly
    with Amazon Bedrock using SDKs, they can have an interactive chatbot that abstracts
    away any complexity, provides a rich customer experience, and boosts overall productivity.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 当与 Amazon Bedrock 的生成式 AI 模型一起工作时，组织可以开发一个既安全又无服务器的应用程序。他们不必直接使用 SDK 与 Amazon
    Bedrock 交互，而是可以拥有一个交互式聊天机器人，该机器人抽象出任何复杂性，提供丰富的客户体验，并提高整体生产力。
- en: '*Figure 6**.14* shows an architecture diagram of how the user can interact
    with the web-based chatbot developed via AWS Amplify and have conversations, generate
    text in various forms, and perform language translation, text summarization, and
    more:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6*.14* 展示了用户如何通过 AWS Amplify 开发的基于 Web 的聊天机器人进行交互，进行对话，生成各种形式的文本，并执行语言翻译、文本摘要等操作：'
- en: '![Figure 6.14 – Serverless enterprise application with Amazon Bedrock](img/B22045_06_14.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.14 – 基于 Amazon Bedrock 的无服务器企业应用程序](img/B22045_06_14.jpg)'
- en: Figure 6.14 – Serverless enterprise application with Amazon Bedrock
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.14 – 基于 Amazon Bedrock 的无服务器企业应用程序
- en: 'Let’s take a closer look at this process:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看这个过程：
- en: '**User interaction with the chatbot on AWS Amplify**: AWS Amplify is a comprehensive
    set of tools and services that simplify the development and deployment of full-stack
    cloud-powered web and mobile applications. The user initiates the workflow by
    interacting with a chatbot integrated into a web application developed using AWS
    Amplify.'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**用户与 AWS Amplify 中的聊天机器人交互**：AWS Amplify 是一套全面的工具和服务，用于简化全栈云驱动型 Web 和移动应用程序的开发和部署。用户通过与使用
    AWS Amplify 开发的 Web 应用程序中集成的聊天机器人交互来启动工作流程。'
- en: '**User authentication and authorization with Amazon Cognito**: Amazon Cognito
    is a robust user identity management service provided by AWS. When the user interacts
    with the chatbot, AWS communicates with Amazon Cognito to perform user authentication
    and authorization. Amazon Cognito supports various authentication methods, including
    traditional username/password combinations, social identity providers (for example,
    Google or Facebook), and multi-factor authentication. It also provides features
    for user registration, account recovery, and secure storage of user data.'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用Amazon Cognito进行用户身份验证和授权**：Amazon Cognito是AWS提供的一项强大的用户身份管理服务。当用户与聊天机器人交互时，AWS会与Amazon
    Cognito通信以执行用户身份验证和授权。Amazon Cognito支持各种身份验证方法，包括传统的用户名/密码组合、社交身份提供者（例如，Google或Facebook）和多因素身份验证。它还提供用户注册、账户恢复和用户数据安全存储的功能。'
- en: '**API Gateway as a centralized entry point**: Once the user has been authenticated
    and authorized, their request is routed through an API gateway, which acts as
    a centralized entry point for APIs. API Gateway is a fully managed service that
    simplifies the process of creating, publishing, maintaining, monitoring, and securing
    APIs.'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**API网关作为集中入口点**：一旦用户经过身份验证和授权，他们的请求将通过API网关路由，该网关充当API的集中入口点。API网关是一项完全托管的服务，简化了创建、发布、维护、监控和保障API的过程。'
- en: '`/text`) to an AWS Lambda function that performs invocation calls to Amazon
    Bedrock LLMs:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将请求发送到执行对Amazon Bedrock LLMs调用操作的AWS Lambda函数（例如，`/text`）：
- en: This Lambda function will take the user’s input or prompt and pass it to Amazon
    Bedrock LLMs to generate relevant and coherent text. For example, the user can
    ask to generate an email or prepare a travel itinerary for a particular destination.
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此Lambda函数将用户的输入或提示传递给Amazon Bedrock LLMs以生成相关且连贯的文本。例如，用户可以要求生成一封电子邮件或为特定目的地准备旅行行程。
- en: Once the Amazon Bedrock LLMs have generated the requested text, the Lambda function
    receives the response and sends it back to the user through API Gateway. Here,
    API Gateway acts as an intermediary, facilitating the communication between the
    client (that is, the chatbot) and the backend services (Lambda functions and Amazon
    Bedrock LLMs).
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦Amazon Bedrock LLMs生成了所需文本，Lambda函数接收响应并通过API网关将其发送回用户。在这里，API网关充当中介，促进客户端（即聊天机器人）与后端服务（Lambda函数和Amazon
    Bedrock LLMs）之间的通信。
- en: '`/summarize`) to another AWS Lambda function specifically designed to perform
    invocation calls to Amazon Bedrock LLMs for summarization tasks:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将请求发送到专门设计用于执行对Amazon Bedrock LLMs总结任务调用操作的另一个AWS Lambda函数（例如，`/summarize`）：
- en: This Lambda function performs invocation calls to Amazon Bedrock LLMs to summarize
    text based on the user’s input or prompt and the provided context (small or large
    files).
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此Lambda函数执行对Amazon Bedrock LLMs的调用，根据用户的输入或提示和提供的上下文（小或大文件）总结文本。
- en: After the Amazon Bedrock LLM has generated the summarized text, the Lambda function
    receives the response and sends it back to the user via API Gateway.
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Amazon Bedrock LLM生成总结文本后，Lambda函数接收响应并通过API网关将其发送回用户。
- en: By separating the text generation and summarization tasks into different Lambda
    functions and API Gateway routes, the application can efficiently handle different
    types of requests and leverage the specialized capabilities of Amazon Bedrock
    LLMs for each task.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将文本生成和总结任务分别分配给不同的Lambda函数和API网关路由，应用程序可以高效地处理不同类型的请求，并利用Amazon Bedrock LLMs在每个任务中的专业能力。
- en: This workflow highlights the flexibility and modular nature of AWS services,
    allowing multiple components to be integrated to build complex applications. AWS
    Lambda functions act as computational engines that make invocation calls to Amazon
    Bedrock LLMs to perform text generation and summarization.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 此工作流程突出了AWS服务的灵活性和模块化特性，允许集成多个组件以构建复杂的应用程序。AWS Lambda函数作为计算引擎，向Amazon Bedrock
    LLMs发起调用以执行文本生成和总结。
- en: By breaking down the application into smaller, independent components, developers
    can easily maintain, update, and scale individual parts of the system without
    affecting the entire application.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将应用程序分解为更小、更独立的组件，开发者可以轻松维护、更新和扩展系统的各个部分，而不会影响整个应用程序。
- en: If you’re curious about trying out the serverless chatbot with Amazon Bedrock,
    check out [https://github.com/aws-samples/amazon-serverless-chatbot-using-bedrock](https://github.com/aws-samples/amazon-serverless-chatbot-using-bedrock).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你好奇想要尝试使用 Amazon Bedrock 的无服务器聊天机器人，请查看[https://github.com/aws-samples/amazon-serverless-chatbot-using-bedrock](https://github.com/aws-samples/amazon-serverless-chatbot-using-bedrock)。
- en: At this point, you should understand and be able to implement text generation
    and summarization with Amazon Bedrock in real-world use cases.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该能够理解和实现使用 Amazon Bedrock 在实际用例中进行文本生成和总结。
- en: Summary
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we dived into the architecture patterns for generating and
    summarizing text using Amazon Bedrock. The first part of this chapter covered
    text generation. We looked at the fundamentals of text generation through prompt
    engineering techniques, in-line context training, and orchestration with LangChain.
    Then, we explored various use cases and patterns for text generation that you
    can apply to real-world scenarios.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了使用 Amazon Bedrock 生成和总结文本的架构模式。本章的第一部分涵盖了文本生成。我们通过提示工程技术、内联上下文训练和与
    LangChain 的编排来探讨文本生成的根本原理。然后，我们探讨了可以应用于实际场景的各种文本生成用例和模式。
- en: The second part of this chapter covered text summarization. We discussed both
    extractive and abstractive summarization approaches and their respective applications.
    Furthermore, we examined the systems and techniques that can be employed for text
    summarization using Amazon Bedrock.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的第二部分涵盖了文本摘要。我们讨论了提取式和抽象式摘要方法及其相应的应用。此外，我们还考察了可以使用 Amazon Bedrock 进行文本摘要的系统和技术。
- en: In the next chapter, we will explore building question-answering and conversational
    interfaces.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨构建问答和对话界面的方法。
