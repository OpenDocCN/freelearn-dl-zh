- en: '*Chapter 4*: Enhancing and Styling Images with DeepDream, Neural Style Transfer,
    and Image Super-Resolution'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第4章*：通过DeepDream、神经风格迁移和图像超分辨率增强和美化图像'
- en: Although deep neural networks excel in traditional computer vision tasks for
    purely practical applications, they have a fun side too! As we'll discover in
    this chapter, we can unlock the artistic side of deep learning with the help of
    a little bit of cleverness and math, of course!
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然深度神经网络在传统计算机视觉任务中表现出色，尤其是在纯粹的实际应用中，但它们也有有趣的一面！正如我们将在本章中发现的那样，我们可以借助一点聪明才智和数学的帮助，解锁深度学习的艺术面。
- en: We'll start this chapter by covering **DeepDream**, an algorithm used to make
    neural networks produce dream-like images. Next, we'll seize the power of transfer
    learning to apply the style of famous paintings to our own images (this is known
    as **Neural Style Transfer**). Finally, we'll close with **Image Super-Resolution**,
    a deep learning approach that's used to improve the quality of an image.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将从介绍**DeepDream**开始，这是一种使神经网络生成梦幻般图像的算法。接下来，我们将利用迁移学习的力量，将著名画作的风格应用到我们自己的图像上（这就是**神经风格迁移**）。最后，我们将结束于**图像超分辨率**，这是一种用于提升图像质量的深度学习方法。
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下食谱：
- en: Implementing DeepDream
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现DeepDream
- en: Generating your own dreamy images
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成你自己的梦幻图像
- en: Implementing Neural Style Transfer
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现神经风格迁移
- en: Applying style transfer to custom images
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将风格迁移应用到自定义图像
- en: Applying style transfer with TFHub
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TFHub应用风格迁移
- en: Improving image resolution with deep learning
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用深度学习提高图像分辨率
- en: Let's get started!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The usual advice whenever we are working with deep learning applies here: if
    possible, access a GPU since it greatly improves efficiency and lowers the computing
    time. In each recipe, you''ll find specific preparation instructions in the *Getting
    ready* section, if needed. You can find all the code for this chapter here: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行深度学习时，一般建议适用：如果可能，使用GPU，因为它可以大大提高效率并减少计算时间。在每个食谱中，你会在*准备工作*部分找到具体的准备说明（如有必要）。你可以在这里找到本章的所有代码：[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4)。
- en: 'Check out the following link to see the Code in Action video:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下链接，观看代码实战视频：
- en: '[https://bit.ly/3bDns2A](https://bit.ly/3bDns2A).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://bit.ly/3bDns2A](https://bit.ly/3bDns2A)。'
- en: Implementing DeepDream
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现DeepDream
- en: '**DeepDream** is the result of an experiment that aimed to visualize the internal
    patterns that are learned by a neural network. In order to achieve this goal,
    we can pass an image through the network, compute its gradient with respect to
    the activations of a specific layer, and then modify the image to increase the
    magnitude of such activations to, in turn, magnify the patterns. The result? Psychedelic,
    surreal photos!'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**DeepDream**是一个实验的产物，旨在可视化神经网络学习到的内部模式。为了实现这一目标，我们可以将一张图像传入网络，计算它关于特定层激活的梯度，然后修改图像，以增强这些激活的幅度，从而放大模式。结果？迷幻、超现实的照片！'
- en: Although this recipe is a bit complex due to the nature of **DeepDream**, we
    will take it one step at a time, so don't worry.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管由于**DeepDream**的性质，本食谱稍显复杂，但我们将一步一步来，别担心。
- en: Let's get started.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: Getting ready
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We don''t need to install anything extra for this recipe. However, we won''t
    dive deep into the details of **DeepDream**, but if you''re interested in the
    topic, you can read the original blog post by Google here: [https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本食谱无需额外安装任何内容。不过，我们不会深入讨论**DeepDream**的细节，但如果你对这个话题感兴趣，可以在这里阅读Google的原始博客文章：[https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html)。
- en: How to do it…
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'Follow these steps and you''ll have your own deep dreamer in no time:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤操作，你很快就能拥有自己的深度梦幻生成器：
- en: 'Import all the necessary packages:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必要的包：
- en: '[PRE0]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Define the `DeepDreamer` class and its constructor:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`DeepDreamer`类及其构造函数：
- en: '[PRE1]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The constructor parameters specify the scale by which we''ll increase the size
    of an image (`octave_scale`), as well as the factor that will applied to the scale
    (`octave_power_factors`). `layers` contains the target layers that will be used
    to generate the dreams. Next, let''s store the parameters as object members:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构造函数参数指定了我们将如何按比例增大图像的尺寸（`octave_scale`），以及将应用于尺度的因子（`octave_power_factors`）。`layers`包含将用于生成梦境的目标层。接下来，我们将这些参数存储为对象成员：
- en: '[PRE2]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'If some of the inputs are `None`, we use defaults. If not, we use the inputs.
    Finally, create the dreamer model by extracting our `layers` from a pre-trained
    `InceptionV3` network:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果某些输入是`None`，我们使用默认值。如果不是，我们使用输入值。最后，通过从预训练的`InceptionV3`网络中提取`layers`来创建梦境生成模型：
- en: '[PRE3]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Define a private method that will compute the loss:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个私有方法来计算损失：
- en: '[PRE4]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Define a private method that will perform gradient ascent (remember, we want
    to magnify the patterns of the image). To increase performance, we can wrap this
    function in `tf.function`:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个私有方法来执行梯度上升（记住，我们希望放大图像中的图案）。为了提高性能，我们可以将此函数封装在`tf.function`中：
- en: '[PRE5]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Define a private method that will convert the image tensor generated by the
    dreamer back into a `NumPy` array:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个私有方法，将梦境生成器产生的图像张量转换回`NumPy`数组：
- en: '[PRE6]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Define a private method that will generate a dreamy image by performing `_gradient_ascent()`
    for a specific number of steps:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个私有方法，通过执行`_gradient_ascent()`一定步数来生成梦幻图像：
- en: '[PRE7]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Define a public method that will generate dreamy images. The main difference
    between this and `_dream()` (defined in *Step 6* and used internally here) is
    that we''ll use different image sizes (called `self.octave_scale` to each power
    in `self.octave_power_factors`:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个公共方法来生成梦幻图像。这与`_dream()`（在*第6步*中定义，并在此内部使用）之间的主要区别是，我们将使用不同的图像尺寸（称为`self.octave_scale`，每个`self.octave_power_factors`中的幂次）：
- en: '[PRE8]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `DeepDreamer()` class can be reused to produce dream-like versions of any
    image we supply to it. We'll see how this works in the next section.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`DeepDreamer()`类可以重用，用于生成我们提供的任何图像的梦幻版本。我们将在下一节中看到这个如何工作。'
- en: How it works…
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: We just implemented a utility class to easily apply **DeepDream**. The algorithm
    works by calculating the gradient with respect to the activations of a set of
    layers, then using such gradients to enhance the patterns seen by the network.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚实现了一个实用类，方便地应用**DeepDream**。该算法通过计算一组层的激活值的梯度，然后使用这些梯度来增强网络所见的图案。
- en: In our `DeepDreamer()` class, the previously described process is implemented
    in the `_gradient_ascent()` method (defined in *Step 4*), where we calculated
    the gradients and added them to the original image over a series of steps. The
    result was an activation map where, in each subsequent step, the **excitement**
    of certain neurons in the target layers was magnified.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`DeepDreamer()`类中，之前描述的过程已在`_gradient_ascent()`方法中实现（在*第4步*中定义），我们计算了梯度并将其添加到原始图像中，通过多个步骤得到结果。最终结果是一个激活图，其中在每个后续步骤中，目标层中某些神经元的**兴奋度**被放大。
- en: Generating a dream consists of applying gradient ascent many times, which we
    basically did in the `_dream()` method (*Step 6*).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 生成梦境的过程包括多次应用梯度上升，我们在`_dream()`方法中基本上已经做了这个（*第6步*）。
- en: One of the problems of applying gradient ascent at the same scale is that the
    result looks noisy, with low resolution. Also, the patterns seem to happen at
    the same granularity level, which produces a uniformity in the result that decreases
    the dream-like effect we want. To resolve all these issues, the main method, `dream()`,
    applies gradient ascent at different scales (called **octaves**), where the dreamy
    output of one octave is the input of the next iteration, at a higher scale.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 应用梯度上升于相同尺度的一个问题是，结果看起来噪声较大，分辨率低。而且，图案似乎发生在相同的粒度层级，这会导致结果的均匀性，从而减少我们想要的梦幻效果。为了解决这些问题，主要方法`dream()`在不同的尺度上应用梯度上升（称为**八度音阶**），其中一个八度的梦幻输出作为下一次迭代的输入，并且在更高的尺度上进行处理。
- en: See also
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: To see the dream-like results of passing different combinations of parameters
    to `DeepDreamer()`, please see the next recipe, *Generating your own dreamy images*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看将不同参数组合传递给`DeepDreamer()`后的梦幻效果，请参阅下一篇食谱，*生成你自己的梦幻图像*。
- en: Generating your own dreamy images
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成你自己的梦幻图像
- en: Deep learning has an entertaining side. **DeepDream** is one application that
    aims to understand the inner workings of deep neural networks by exciting certain
    activations on selected layers. However, beyond the investigative intent of the
    experiment, it also produces psychedelic, dream-like fun images.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习有一个有趣的方面。**DeepDream** 是一个应用程序，旨在通过激活特定层的某些激活点来理解深度神经网络的内部工作原理。然而，除了实验的调查意图外，它还产生了迷幻、梦幻般有趣的图像。
- en: In this recipe, we'll experiment with several configurations of **DeepDream**
    on a test image and see how they affect the results.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将尝试几种**DeepDream**的配置，看看它们如何影响结果。
- en: Getting ready
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备开始
- en: 'We''ll use the `DeepDreamer()` implementation from the first recipe of this
    chapter (*Implementing DeepDream*). Although I encourage you to try this out with
    your own images, if you want to follow this recipe as closely as possible, you
    can download the sample image here: https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe2/road.jpg.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用本章第一个配方中的`DeepDreamer()`实现（*实现 DeepDream*）。虽然我鼓励你尝试用自己的图像进行测试，但如果你想尽量跟随这个配方，你可以在这里下载示例图像：https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe2/road.jpg。
- en: 'Let''s take a look at the sample image:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下示例图像：
- en: '![Figure 4.1 – Sample image'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.1 – 示例图像'
- en: '](img/Image86668.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Image86668.jpg)'
- en: Figure 4.1 – Sample image
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – 示例图像
- en: Let's begin.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: How to do it…
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现……
- en: 'Follow these steps to cook up your own dreamy photos:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤制作你自己的梦幻照片：
- en: 'Let''s start by importing the required packages. Notice that we are importing
    `DeepDreamer()` from the previous recipe, *Implementing DeepDream*:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们从导入所需的包开始。请注意，我们正在从之前的配方中导入`DeepDreamer()`，*实现 DeepDream*：
- en: '[PRE9]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Define the `load_image()` function that will load images from disk into memory
    as `NumPy` arrays:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`load_image()`函数，从磁盘加载图像到内存中，作为`NumPy`数组：
- en: '[PRE10]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Define a function that will display an image (represented as a `NumPy` array)
    using `matplotlib`:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，使用`matplotlib`显示图像（以`NumPy`数组表示）：
- en: '[PRE11]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Load the original image and display it:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载原始图像并显示：
- en: '[PRE12]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here, we can see the displayed original image:'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里，我们可以看到显示的原始图像：
- en: '![Figure 4.2 – Original image that we’ll modify shortly'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.2 – 我们将很快修改的原始图像'
- en: '](img/B14768_04_002.jpg)'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_04_002.jpg)'
- en: Figure 4.2 – Original image that we'll modify shortly
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.2 – 我们将很快修改的原始图像
- en: As we can see, it is just a road that cuts through a forest.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如我们所见，这只是穿过森林的一条道路。
- en: 'Generate a dreamy version of the image using the default parameters and display
    the result:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用默认参数生成图像的梦幻版，并显示结果：
- en: '[PRE13]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Here''s the result:'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 4.3 – Result of using DeepDream with the default parameters'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.3 – 使用默认参数的 DeepDream 结果'
- en: '](img/B14768_04_003.jpg)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_04_003.jpg)'
- en: Figure 4.3 – Result of using DeepDream with the default parameters
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.3 – 使用默认参数的 DeepDream 结果
- en: The result preserves the overall theme of the original photo but adds lots of
    distortion on top of it in the form of circles, curves, and other basic patterns.
    Cool – and a bit creepy!
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果保留了原始照片的整体主题，但在其上添加了大量失真，形成了圆形、曲线和其他基本图案。酷——又有点怪异！
- en: 'Use three layers. Layers near the top (for instance, `''mixed7''`) encode higher-level
    patterns:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用三层。靠近顶部的层（例如，`'mixed7'`）编码更高层次的模式：
- en: '[PRE14]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here''s the result of using three layers:'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是使用三层后的结果：
- en: '![Figure 4.4 – Result of using DeepDream with more, higher-level layers'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.4 – 使用更多更高层次层的 DeepDream 结果'
- en: '](img/B14768_04_004.jpg)'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_04_004.jpg)'
- en: Figure 4.4 – Result of using DeepDream with more, higher-level layers
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.4 – 使用更多更高层次层的 DeepDream 结果
- en: The addition of more layers softened the produced dream. We can see that the
    patterns are smoother than before, which is likely due to the fact that the `'mixed7'`
    layer encodes more abstract information because it is farther down the architecture.
    Let's remember that the first layers in a network learn basic patterns, such as
    lines and shapes, while the layers closer to the output combine these basic patterns
    to learn more complex, abstract information.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 更多层的加入让生成的梦幻效果变得更柔和。我们可以看到，图案比以前更平滑，这很可能是因为`'mixed7'`层编码了更多的抽象信息，因为它离网络架构的末端更远。我们记得，网络中的前几层学习基本的模式，如线条和形状，而靠近输出的层则将这些基本模式组合起来，学习更复杂、更抽象的信息。
- en: 'Finally, let''s use more **octaves**. The result we expect is an image with
    less noise and more heterogeneous patterns:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们使用更多的**八度音阶**。我们期望的结果是图像中噪声较少，且具有更多异质模式：
- en: '[PRE15]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here''s the resulting image after using more octaves:'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是使用更多八度后得到的结果图像：
- en: '![Figure 4.5 – Result of using DeepDream with more octaves'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.5 – 使用更多八度的DeepDream效果'
- en: '](img/B14768_04_005.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_04_005.jpg)'
- en: Figure 4.5 – Result of using DeepDream with more octaves
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 – 使用更多八度的DeepDream效果
- en: This generated dream contains a satisfying mixture of both high- and low-level
    patterns, as well as a better color distribution than the one produced in *Step
    4*.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的梦境包含了一种令人满意的高低层次模式的混合，并且比*步骤4*中生成的梦境具有更好的色彩分布。
- en: Let's go to the next section to understand what we've just done.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入下一部分，了解我们刚刚做了什么。
- en: How it works…
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: In this recipe, we leveraged the hard work we did in the *Implementing DeepDream*
    recipe in order to produce several dreamy versions of our input image of a road
    in a forest. By combining different parameters, we discovered that the results
    could vary widely. Using higher layers, which encode more abstract information,
    we obtained pictures with less noise and more nuanced patterns.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们利用了在*实现DeepDream*食谱中所做的工作，生成了几种我们输入图像（森林中的一条道路）的梦幻版本。通过结合不同的参数，我们发现结果可以有很大的变化。使用更高层次的抽象信息，我们获得了噪音更少、模式更精细的图片。
- en: If we choose to use more octaves, this translates into more images, at different
    scales, being processed by the network. This approach generates less saturated
    images, while keeping the more raw, basic patterns typical of the first few layers
    in a convolutional neural network.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们选择使用更多八度，这意味着网络将处理更多的图像，且在不同的尺度上进行处理。这种方法生成的图像饱和度较低，同时保留了卷积神经网络前几层中典型的更原始、更基本的模式。
- en: In the end, with just an image and a little creativity, we can obtain pretty
    interesting results!
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过仅使用一张图片和一点创造力，我们可以获得非常有趣的结果！
- en: An even more entertaining application of deep learning is Neural Style Transfer,
    which we will cover in the next recipe.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的另一个更具娱乐性的应用是神经风格迁移，我们将在下一个食谱中讲解。
- en: Implementing Neural Style Transfer
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现神经风格迁移
- en: Creativity and artistic expression are not traits that we tend to associate
    with deep neural networks and AI in general. However, did you know that with the
    right tweaks, we can turn pre-trained networks into impressive artists, capable
    of applying the distinctive style of famous painters such as Monet, Picasso, and
    Van Gogh to our mundane pictures?
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 创造力和艺术表现并不是我们通常将其与深度神经网络和人工智能相联系的特征。然而，你知道吗，通过正确的调整，我们可以将预训练网络转变为令人印象深刻的艺术家，能够将像莫奈、毕加索和梵高这样的著名画家的独特风格应用到我们的平凡照片中？
- en: This is exactly what Neural Style Transfer does. By the end of this recipe,
    we'll have the artistic prowess of any painter at our disposal!
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是神经风格迁移的工作原理。通过这个食谱的学习，最终我们将掌握任何画家的艺术造诣！
- en: Getting ready
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正在准备中
- en: 'We don''t need to install any libraries or bring in extra resources to implement
    Neural Style Transfer. However, because this is a hands-on recipe, we won''t detail
    the inner workings of our solution extensively. If you''re interested in the ins
    and outs of Neural Style Transfer, I recommend that you read the original paper
    here: [https://arxiv.org/abs/1508.06576](https://arxiv.org/abs/1508.06576).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要安装任何库或引入额外的资源来实现神经风格迁移。然而，由于这是一个实践性的食谱，我们不会详细描述解决方案的内部工作原理。如果你对神经风格迁移的细节感兴趣，建议阅读原始论文：[https://arxiv.org/abs/1508.06576](https://arxiv.org/abs/1508.06576)。
- en: I hope you're ready because we are about to begin!
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你已经准备好，因为我们马上就要开始了！
- en: How to do it…
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'Follow these steps to implement your own, reusable, neural style transferrer:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 按照这些步骤实现你自己的可重用神经风格迁移器：
- en: 'Import the necessary packages (notice that we''re using a pre-trained **VGG19**
    network in our implementation):'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包（注意，在我们的实现中，我们使用了一个预训练的**VGG19**网络）：
- en: '[PRE16]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Define the `StyleTransferrer()` class and its constructor:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`StyleTransferrer()`类及其构造函数：
- en: '[PRE17]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The only relevant parameters are two optional lists of layers for the content
    and style generation, respectively. If they are `None`, we''ll use defaults internally
    (as we''ll see shortly). Next, load the pre-trained `VGG19` and freeze it:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 唯一相关的参数是内容和风格生成的两个可选层列表。如果它们是`None`，我们将在内部使用默认值（稍后我们会看到）。接下来，加载预训练的`VGG19`并将其冻结：
- en: '[PRE18]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Set the weight (importance) of the style and content losses (we''ll use these
    parameters later). Also, store the content and style layers (or use the defaults
    if necessary):'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置风格和内容损失的权重（重要性）（稍后我们会使用这些参数）。另外，存储内容和风格层（如果需要的话，可以使用默认设置）：
- en: '[PRE19]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Define and store the style transferrer model, which takes the **VGG19** input
    layer as input and outputs all the content and style layers (please take into
    account that we can use any model, but the best results are usually achieved using
    either VGG19 or InceptionV3):'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义并存储样式迁移模型，该模型以**VGG19**输入层为输入，输出所有内容层和样式层（请注意，我们可以使用任何模型，但通常使用VGG19或InceptionV3能获得最佳效果）：
- en: '[PRE20]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Define a private method that will calculate the **Gram Matrix**, which is used
    to calculate the style of an image. This is represented by a matrix that contains
    the means and correlations across different feature maps in the input tensor (for
    instance, the weights in a particular layer), known as a **Gram Matrix**. For
    more information on the **Gram Matrix**, please refer to the *See also* section
    of this recipe:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个私有方法，用于计算**Gram矩阵**，它用于计算图像的样式。它由一个矩阵表示，其中包含输入张量中不同特征图之间的均值和相关性（例如，特定层中的权重），被称为**Gram矩阵**。有关**Gram矩阵**的更多信息，请参阅本配方中的*另请参阅*部分：
- en: '[PRE21]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next, define a private method that will calculate the outputs (content and
    style). What this private method does is pass the inputs to the model and then
    compute the **Gram Matrix** of all the style layers, as well as the identity of
    the content layers, returning dicts that map each layer name to the processed
    values:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，定义一个私有方法，用于计算输出（内容和样式）。该私有方法的作用是将输入传递给模型，然后计算所有样式层的**Gram矩阵**以及内容层的身份，返回映射每个层名称到处理后值的字典：
- en: '[PRE22]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Define a static helper private method that will clip values between `0` and
    `1`:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个静态辅助私有方法，用于将值限制在`0`和`1`之间：
- en: '[PRE23]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Define a static helper private method that will compute the loss between a
    pair of outputs and targets:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个静态辅助私有方法，用于计算一对输出和目标之间的损失：
- en: '[PRE24]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Define a private method that will compute the total loss, which is the result
    of computing the style and content loss individually, by multiplying them by their
    respective weight distributed across the corresponding layer and then adding them
    up:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个私有方法，用于计算总损失，该损失是通过分别计算样式损失和内容损失，乘以各自权重并分配到相应层，再加总得到的：
- en: '[PRE25]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, define a private method that will train the model. During a set number
    of epochs, and for a given number of steps per epoch, we''ll calculate the outputs
    (style and content), compute the total loss, and obtain and apply the gradient
    to the generated image while using `Adam` as an optimizer:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，定义一个私有方法，用于训练模型。在一定数量的epochs和每个epoch的指定步数下，我们将计算输出（样式和内容），计算总损失，并获取并应用梯度到生成的图像，同时使用`Adam`作为优化器：
- en: '[PRE26]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Define a static helper private method that will convert a tensor into a `NumPy`
    image:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个静态辅助私有方法，用于将张量转换为`NumPy`图像：
- en: '[PRE27]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Finally, define a public `transfer()` method that will take a style image and
    a content image and generate a new image. This should preserve the content as
    much as possible while still applying the style of the style image:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，定义一个公共的`transfer()`方法，该方法接受一张样式图像和一张内容图像，生成一张新图像。它应该尽可能保留内容，同时应用样式图像的样式：
- en: '[PRE28]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: That was a lot of work! We'll go a bit deeper in the next section.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这可真是费了一番功夫！我们将在下一部分深入探讨。
- en: How it works…
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In this recipe, we learned that Neural Style Transfer works by optimizing two
    losses instead of one. On one hand, we want to preserve the content as much as
    possible, but on the other hand, we want to make this content look like it was
    produced using the style of the style image.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在本配方中，我们学到，神经风格迁移是通过优化两个损失而不是一个来工作的。一方面，我们希望尽可能保留内容，另一方面，我们希望让这个内容看起来像是使用样式图像的风格生成的。
- en: Quantifying content is achieved by using the content layers, as we would normally
    do in image classification. How do we quantify style, though? Here's where the
    **Gram Matrix** plays a crucial role, since it computes the correlations across
    the feature maps (more precisely, the outputs) of the style layers.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 内容量化是通过使用内容层实现的，正如我们在图像分类中通常会做的那样。那么，如何量化样式呢？这时，**Gram矩阵**发挥了至关重要的作用，因为它计算了样式层的特征图（更准确地说，是输出）之间的相关性。
- en: How do we inform the network that the content is more important than the style?
    By using weights when computing the combined loss. By default, the content weight
    is *10,000*, while the style weight is just *0.01*. This tells the network that
    most of its effort should be on reproducing the content, but also optimizing it
    a bit for style.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何告诉网络内容比风格更重要呢？通过在计算组合损失时使用权重。默认情况下，内容权重是*10,000*，而风格权重仅为*0.01*。这告诉网络它的大部分努力应该集中在重现内容上，但也要稍微优化一下风格。
- en: In the end, we obtained an image that preserves the coherence of the original
    one, but with the visual appeal of the style reference image, which is the result
    of optimizing the output so that it matches the statistics of both input images.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们获得了一张图像，它保留了原始图像的连贯性，但却拥有了风格参考图像的视觉吸引力，这是通过优化输出，使其匹配两个输入图像的统计特征所得到的结果。
- en: See also
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: If you want to learn more the math behind the `StyleTransferrer()` in action,
    see the next recipe, *Applying style transfer to custom images*.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于`StyleTransferrer()`运作背后的数学原理，请参见下一个配方，*将风格迁移应用于自定义图像*。
- en: Applying style transfer to custom images
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将风格迁移应用于自定义图像
- en: Have you ever wondered how a picture of your puppy Fluffy would look if your
    favorite artist painted it? What if a photo of your car was the product of merging
    it with the magic of your most beloved painting? Well, you don't have to wonder
    anymore! With Neural Style Transfer, we can make our favorite images look like
    wonderful pieces of art effortlessly!
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否曾经想过，如果你最喜欢的艺术家画了你的小狗Fluffy的照片会是什么样子？如果你车子的照片与最喜爱的画作的魔力结合，会变成什么样？好吧，你再也不需要想象了！通过神经风格迁移，我们可以轻松地将我们最喜欢的图像变成美丽的艺术作品！
- en: In this recipe, we'll use the `StyleTransferrer()` class we implemented in the
    *Implementing Neural Style Transfer* recipe to stylize our own images.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将使用我们在*实现神经风格迁移*配方中实现的`StyleTransferrer()`类来为我们自己的图像添加风格。
- en: Getting ready
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备中
- en: 'In this recipe, we''ll be using the `StyleTransferrer()` implementation from
    the previous recipe. In order to maximize the fun you''ll get out of this recipe,
    you can find the sample image, along with many different paintings (which you
    can use as the style reference), here:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，我们将使用上一个配方中的`StyleTransferrer()`实现。为了最大化您从这个配方中获得的乐趣，您可以在这里找到示例图像以及许多不同的画作（您可以用作风格参考）：
- en: '[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe4](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe4).'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe4](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe4)。'
- en: 'The following is the sample image we''ll be using:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们将使用的示例图像：
- en: '![Figure 4.6 – Sample content image'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.6 – 示例内容图像'
- en: '](img/B14768_04_006.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_04_006.jpg)'
- en: Figure 4.6 – Sample content image
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6 – 示例内容图像
- en: Let's get started!
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: How to do it…
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'The following steps will teach you how to transfer the style of famous paintings
    to your own images:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将教您如何将著名画作的风格转移到您自己的图像上：
- en: 'Import the necessary packages:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的包：
- en: '[PRE29]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Notice we're importing `StyleTransferrer()`, which we implemented in the *Implementing
    Neural Style Transfer* recipe.
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，我们正在导入在*实现神经风格迁移*配方中实现的`StyleTransferrer()`。
- en: 'Tell TensorFlow that we want to run in eager mode because otherwise, it will
    try to run the `tf.function` decorator functions in `StyleTransferrer()` in graph
    mode, which will prevent it from working properly:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 告诉TensorFlow我们希望以急切模式运行，因为否则，它会尝试在图模式下运行`StyleTransferrer()`中的`tf.function`装饰器函数，这将导致其无法正常工作：
- en: '[PRE30]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Define a function that will load an image as a TensorFlow tensor. Notice that
    we''re rescaling it to a sensible size. We are doing this because Neural Style
    Transfer is a resource-intensive process, so working on large images can take
    a long time:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，将图像加载为TensorFlow张量。请注意，我们正在将其重新缩放到一个合理的大小。我们这样做是因为神经风格迁移是一个资源密集型的过程，因此处理大图像可能需要很长时间：
- en: '[PRE31]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Define a function that will display an image using `matplotlib`:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，用于通过`matplotlib`显示图像：
- en: '[PRE32]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Load the content image and display it:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载内容图像并显示它：
- en: '[PRE33]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Here''s the content image:'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是内容图像：
- en: '![Figure 4.7 – Content image of a car'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图4.7 – 一辆车的内容图像'
- en: '](img/B14768_04_007.jpg)'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_04_007.jpg)'
- en: Figure 4.7 – Content image of a car
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图4.7 – 一辆车的内容图像
- en: We'll apply the style of a painting to this image.
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将把一幅画作的风格应用到这张图像上。
- en: 'Load and display the style image:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载并显示风格图像：
- en: '[PRE34]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Here''s the style image:'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是风格图像：
- en: '![Figure 4.8 – Style image'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.8 – 风格图像](img/B14768_04_010.jpg)'
- en: '](img/B14768_04_008.jpg)'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_04_009.jpg)'
- en: Figure 4.8 – Style image
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.8 – 风格图像
- en: Can you imagine how our car would look if the artist of this painting painted
    it?
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你能想象如果这幅画的艺术家为我们的车绘制图像，它会是什么样子吗？
- en: 'Use `StyleTransferrer()` to apply the style of the painting to our image of
    a BMW. Then, display the result:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `StyleTransferrer()` 将画作的风格应用到我们的 BMW 图像上。然后，展示结果：
- en: '[PRE35]'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Here''s the result:'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 4.9 – Result of applying the style of the painting to the content
    image'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.9 – 将画作的风格应用到内容图像的结果](img/B14768_04_010.jpg)'
- en: '](img/B14768_04_009.jpg)'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_04_009.jpg)'
- en: Figure 4.9 – Result of applying the style of the painting to the content image
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.9 – 将画作的风格应用到内容图像的结果
- en: Impressive, isn't it?
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 惊艳吧，是不是？
- en: 'Repeat this process, this time for 100 epochs:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复这个过程，这次进行 100 个训练周期：
- en: '[PRE36]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Here''s the result:'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是结果：
- en: '![Figure 4.10 – Result of applying the style of the painting to the content
    image for 100 epochs'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.10 – 对内容图像应用画作风格的结果（100 个训练周期）](img/B14768_04_011.jpg)'
- en: '](img/B14768_04_010.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_04_008.jpg)'
- en: Figure 4.10 – Result of applying the style of the painting to the content image
    for 100 epochs
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – 对内容图像应用画作风格的结果（100 个训练周期）
- en: This time, the result is sharper. However, we had to wait a while for the process
    to complete. There's a clear trade-off between time and quality.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，结果更为锐利。然而，我们不得不等一段时间才能完成这个过程。时间和质量之间的权衡非常明显。
- en: Let's move on to the next section.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续进入下一部分。
- en: How it works…
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: In this recipe, we leveraged the hard work we did in the *Implementing Neural
    Style Transfer* recipe. We took an image of a car and applied the style of a cool
    and captivating piece of art to it. The result, as we saw, is fascinating.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们利用了在*实现神经风格迁移*食谱中所做的辛勤工作。我们取了一张汽车的图像，并将一幅酷炫迷人的艺术作品风格应用到其中。正如我们所看到的，结果非常吸引人。
- en: However, we must be aware of how taxing this process is since it takes a long
    time to complete on a CPU – even on a GPU. Therefore, there's a trade-off to be
    accounted for between the number of epochs or iterations used to refine the result
    and the overall quality of the output.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们必须意识到这个过程的负担，因为在 CPU 上完成它需要很长时间——即使是在 GPU 上也是如此。因此，我们需要在用于精细化结果的训练周期或迭代次数与最终输出质量之间进行权衡。
- en: See also
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参见也
- en: 'I encourage you to try this recipe with your own pictures and styles. As a
    starting point, you can use the images in the following repository to hit the
    ground running: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe4](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe4).
    There, you''ll find famous artworks from Warhol, Matisse, and Monet, among others.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你尝试使用自己的图片和风格来应用这个食谱。作为起点，你可以使用以下仓库中的图像来快速入门：[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe4](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe4)。在那里，你将找到来自沃霍尔、马蒂斯、莫奈等人的著名艺术作品。
- en: Applying style transfer with TFHub
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TFHub 应用风格迁移
- en: Implementing Neural Style Transfer from scratch is a demanding task. Fortunately,
    we can use out-of-the-box solutions that live in **TensorFlow Hub** (**TFHub**).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 从零开始实现神经风格迁移是一项艰巨的任务。幸运的是，我们可以使用**TensorFlow Hub**（**TFHub**）中的现成解决方案。
- en: In this recipe, we'll style our own images in just a few lines of code by harnessing
    the utility and convenience that TFHub provides.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们只需几行代码，就能通过 TFHub 提供的工具和便捷性，快速为自己的图像添加风格。
- en: Getting ready
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We must install `tensorflow-hub`. We can do this with just a simple `pip` command:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须安装 `tensorflow-hub`。我们只需一个简单的 `pip` 命令即可完成：
- en: '[PRE37]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'If you want to access different sample content and style images, please visit
    this link: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe5](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe5).'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想访问不同的示例内容和风格图像，请访问这个链接：[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe5](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe5)。
- en: 'Let''s take a look at the sample image:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下示例图像：
- en: '![Figure 4.11 – Content image'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.11 – 内容图像](img/B14768_04_011.jpg)'
- en: '](img/B14768_04_011.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_04_011.jpg)'
- en: Figure 4.11 – Content image
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.11 – 内容图像
- en: Let's get started!
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: How to do it…
  id: totrans-211
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Neural Style Transfer with TFHub is a breeze! Follow these steps to complete
    this recipe:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TFHub 进行神经风格迁移非常简单！按照以下步骤完成此食谱：
- en: 'Import the necessary dependencies:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的依赖项：
- en: '[PRE38]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Define a function that will load an image as a TensorFlow tensor. We need to
    rescale the image in order to save time and resources, given that Neural Style
    Transfer is a taxing process, so working on large images can take a long time:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个将图像加载为 TensorFlow 张量的函数。由于神经风格迁移是一个计算密集型的过程，因此我们需要对图像进行重缩放，以节省时间和资源，因为处理大图像可能会花费很长时间：
- en: '[PRE39]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Define a function that will convert a tensor into an image:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个将张量转换为图像的函数：
- en: '[PRE40]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Define a function that will display an image using `matplotlib`:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个使用`matplotlib`显示图像的函数：
- en: '[PRE41]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Define the path to the style transfer implementation in TFHub and load the
    model:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义风格迁移实现的路径，并加载模型：
- en: '[PRE42]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Load the content image. Then, display it:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载内容图像，然后显示它：
- en: '[PRE43]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Here it is:'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 就是这个：
- en: '![Figure 4.12 – Content image of a car'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.12 – 一辆车的内容图像'
- en: '](img/B14768_04_012.jpg)'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_04_012.jpg)'
- en: Figure 4.12 – Content image of a car
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.12 – 一辆车的内容图像
- en: We'll apply style transfer to this photo in the next step.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将在下一步应用风格迁移到这张照片上。
- en: 'Load and display the style image:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载并显示风格图像：
- en: '[PRE44]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Here, you can see the style image:'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，你可以看到风格图像：
- en: '![Figure 4.13 – This is our style image of choice'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.13 – 这是我们选择的风格图像'
- en: '](img/B14768_04_013.jpg)'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_04_013.jpg)'
- en: Figure 4.13 – This is our style image of choice
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.13 – 这是我们选择的风格图像
- en: We'll pass this and the content image to the TFHub module we recently created
    and wait for the result.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将这个和内容图像传递给我们最近创建的 TFHub 模块，并等待结果。
- en: 'Apply Neural Style Transfer using the model we downloaded from TFHub and display
    the result:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们从 TFHub 下载的模型应用神经风格迁移，并显示结果：
- en: '[PRE45]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Here''s the result of applying Neural Style Transfer with TFHub:'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是使用 TFHub 应用神经风格迁移的结果：
- en: '![Figure 4.14 – Result of applying style transfer using TFHub'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.14 – 使用 TFHub 应用风格迁移的结果'
- en: '](img/B14768_04_014.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_04_014.jpg)'
- en: Figure 4.14 – Result of applying style transfer using TFHub
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.14 – 使用 TFHub 应用风格迁移的结果
- en: '*Voilà!* The result looks pretty good, don''t you think? We''ll dive a bit
    deeper in the next section.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '*瞧！* 结果看起来相当不错，你不觉得吗？我们将在下一节深入探讨。'
- en: How it works…
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: In this recipe, we learned that using TFHub to stylize images is substantially
    easier than implementing the algorithm from scratch. However, it gives us less
    control since it acts as a black box.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们学到，使用 TFHub 进行图像风格化比从头实现算法要容易得多。然而，它给了我们较少的控制，因为它像一个黑盒子。
- en: Either way, the result is quite satisfactory because it preserves the coherence
    and meaning of the original scene, while adding the artistic traits of the style
    image on top.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 无论哪种方式，结果都相当令人满意，因为它保持了原始场景的连贯性和意义，同时将风格图像的艺术特征叠加在上面。
- en: The most important part is downloading the correct module from TFHub, and then
    loading it using the `load()` function.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的部分是从 TFHub 下载正确的模块，然后使用 `load()` 函数加载它。
- en: For the pre-packaged module to work, we must pass both the content and style
    images as `tf.constant` constants.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让预打包模块正常工作，我们必须将内容和风格图像都作为 `tf.constant` 常量传递。
- en: Finally, because we received a tensor, in order to properly display the result
    on-screen, we used our custom function, `tensor_to_image()`, to turn it into a
    `NumPy` array that can easily be plotted using `matplotlib`.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于我们接收到的是一个张量，为了正确地在屏幕上显示结果，我们使用了自定义函数 `tensor_to_image()`，将其转化为可以通过 `matplotlib`
    容易绘制的 `NumPy` 数组。
- en: See also
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: You can read more about the TFHub module we used here at https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在此链接阅读更多关于我们使用的 TFHub 模块：https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2。
- en: 'Also, why don''t you play around with your own images and other styles? You
    can use the assets here as a starting point: [https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe5](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe5).'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，为什么不尝试一下你自己的图像和其他风格呢？你可以使用这里的资源作为起点：[https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe5](https://github.com/PacktPublishing/Tensorflow-2.0-Computer-Vision-Cookbook/tree/master/ch4/recipe5)。
- en: Improving image resolution with deep learning
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度学习提高图像分辨率
- en: '**Convolutional Neural Networks (CNNs)** can also be used to improve the resolution
    of low-quality images. Historically, we can achieve this by using interpolation
    techniques, example-based approaches, or low- to high-resolution mappings that
    must be learned.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络（CNN）** 也可以用来提高低质量图像的分辨率。历史上，我们可以通过使用插值技术、基于示例的方法，或需要学习的低到高分辨率映射来实现这一点。'
- en: As we'll see in this recipe, we can obtain better results faster by using an
    end-to-end deep learning-based approach.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在这个步骤中将看到的，通过使用基于端到端深度学习的方法，我们可以更快地获得更好的结果。
- en: Sound interesting? Let's get to it!
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来有趣吗？那我们就开始吧！
- en: Getting ready
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We will need `Pillow` in this recipe, which you can install with the following
    command:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个步骤中，我们需要使用`Pillow`，你可以通过以下命令安装：
- en: '[PRE46]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'In this recipe, we are using the `Dog and Cat Detection` dataset, which is
    hosted on Kaggle: [https://www.kaggle.com/andrewmvd/dog-and-cat-detection](https://www.kaggle.com/andrewmvd/dog-and-cat-detection).
    In order to download it, you''ll need to sign in on the website or sign up. Once
    you''re logged in, save it in a place of your preference as `dogscats.zip`. Finally,
    decompress it in a folder named `dogscats`. From now on, we''ll assume the data
    is in `~/.keras/datasets/dogscats`.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个步骤中，我们使用的是`Dog and Cat Detection`数据集，该数据集托管在Kaggle上：[https://www.kaggle.com/andrewmvd/dog-and-cat-detection](https://www.kaggle.com/andrewmvd/dog-and-cat-detection)。要下载它，你需要在网站上登录或注册。一旦登录，将其保存到你喜欢的地方，命名为`dogscats.zip`。然后，将其解压到一个名为`dogscats`的文件夹中。从现在开始，我们假设数据存储在`~/.keras/datasets/dogscats`目录下。
- en: 'The following is a sample from the two classes in the dataset:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是数据集中两个类别的示例：
- en: '![Figure 4.15 – Example images'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.15 – 示例图像'
- en: '](img/B14768_04_015.jpg)'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_04_015.jpg)'
- en: Figure 4.15 – Example images
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.15 – 示例图像
- en: Let's get started!
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: How to do it…
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做……
- en: 'Follow these steps to implement a fully convolutional network in order to perform
    image super-resolution:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤实现一个全卷积网络，以执行图像超分辨率：
- en: 'Import all the necessary modules:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必要的模块：
- en: '[PRE47]'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Define a function that will build the network architecture. Notice that this
    is a fully convolutional network, which means only convolutional layers (besides
    the activations) comprise it, including the output:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，构建网络架构。请注意，这是一个全卷积网络，这意味着它仅由卷积层（除了激活层）组成，包括输出层：
- en: '[PRE48]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Define a function that will resize an image based on a scale factor. Take into
    consideration that it receives an image represented as a `NumPy` array:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，根据缩放因子调整图像的大小。需要考虑的是，它接收的是一个表示图像的`NumPy`数组：
- en: '[PRE49]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Define a function that will tightly crop an image. We are doing this because
    we want the image to fit nicely when we apply a sliding window to extract patches
    later. `SCALE` is the factor we want the network to learn how to enlarge images
    by:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，紧密裁剪图像。我们这样做是因为当我们稍后应用滑动窗口提取补丁时，希望图像能恰当地适应。`SCALE`是我们希望网络学习如何放大图像的因子：
- en: '[PRE50]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Define a function that will purposely reduce the resolution of an image by
    downsizing it and then upsizing it:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，故意通过缩小图像然后再放大它来降低图像分辨率：
- en: '[PRE51]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Define a function that will crop patches from input images. `INPUT_DIM` is
    the height and width of the images we will feed into the network:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，用于从输入图像中裁剪补丁。`INPUT_DIM`是我们输入到网络中的图像的高度和宽度：
- en: '[PRE52]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Define a function that will crop patches of output images. `LABEL_SIZE` is
    the height and width of the images outputted by the network. On the other hand,
    `PAD` is the number of pixels that will be used as padding to ensure we are cropping
    the region of interest properly:'
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，用于裁剪输出图像的区域。`LABEL_SIZE`是网络输出图像的高度和宽度。另一方面，`PAD`是用于填充的像素数，确保我们正确裁剪感兴趣的区域：
- en: '[PRE53]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Set the random seed:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置随机种子：
- en: '[PRE54]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Load the paths to all the images in the dataset:'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集中所有图像的路径：
- en: '[PRE55]'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Because the dataset is huge and we don''t need all the images in it to achieve
    our goal, let''s randomly pick 1,500 of them:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为数据集非常庞大，而我们并不需要其中所有的图像来实现我们的目标，所以让我们随机挑选其中1,500张：
- en: '[PRE56]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Define the parameters that will be used to create our dataset of low-resolution
    patches as input and high-resolution patches (the labels) as output. All of these
    parameters were defined in previous steps, except for `STRIDE`, which is the number
    of pixels we''ll slide both in the horizontal and vertical axes to extract patches:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义将用于创建低分辨率补丁数据集（作为输入）和高分辨率补丁（作为标签）数据集的参数。除了`STRIDE`参数外，所有这些参数都在前面的步骤中定义过。`STRIDE`是我们在水平和垂直轴上滑动提取补丁时使用的像素数：
- en: '[PRE57]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Build the dataset. The inputs will be low-resolution patches that have been
    extracted from the images after being downsized and upsized. The labels will be
    patches from the unaltered image:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建数据集。输入将是从图像中提取的低分辨率补丁，这些补丁是通过缩小和放大处理过的。标签将是来自未改变图像的补丁：
- en: '[PRE58]'
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Instantiate the network, which we''ll train for 12 epochs while using `Adam()`
    as our optimizer with learning rate decay. The loss function is `''mse''`. Why?
    Because our goal is not to achieve great accuracy, but to learn a set of filters
    that correctly map patches from low to high resolution:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化网络，我们将在12个周期内进行训练，并使用`Adam()`作为优化器，同时进行学习率衰减。损失函数是`'mse'`。为什么？因为我们的目标不是实现高准确率，而是学习一组过滤器，正确地将低分辨率图像块映射到高分辨率：
- en: '[PRE59]'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Train the network:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练网络：
- en: '[PRE60]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Now, to evaluate our solution, we''ll load a test image, convert it into a
    `NumPy` array, and reduce its resolution:'
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，为了评估我们的解决方案，我们将加载一张测试图像，将其转换为`NumPy`数组，并降低其分辨率：
- en: '[PRE61]'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Display the low-resolution image:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显示低分辨率图像：
- en: '[PRE62]'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Let''s see the result:'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们看看结果：
- en: '![Figure 4.16 – Low-resolution test image'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 4.16 – 低分辨率测试图像'
- en: '](img/B14768_04_016.jpg)'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B14768_04_016.jpg)'
- en: Figure 4.16 – Low-resolution test image
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 4.16 – 低分辨率测试图像
- en: Now, we want to create a sharper version of this photo.
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们想要创建这张照片的更清晰版本。
- en: 'Create a canvas with the same dimensions of the input image. This is where
    we''ll store the high-resolution patches generated by the network:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个与输入图像相同尺寸的画布。这是我们存储网络生成的高分辨率图像块的地方：
- en: '[PRE63]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Extract low-resolution patches, pass them through the network to obtain their
    high-resolution counterparts, and place them in their proper location in the output
    canvas:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取低分辨率图像块，将它们传入网络以获得高分辨率的对应图像块，并将它们放置在输出画布的正确位置：
- en: '[PRE64]'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Finally, display the high-resolution result:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，显示高分辨率结果：
- en: '[PRE65]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Here''s the super-resolution output:'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是超分辨率输出：
- en: '![Figure 4.17 – High-resolution test image'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.17 – 高分辨率测试图像'
- en: '](img/B14768_04_017.jpg)'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14768_04_017.jpg)'
- en: Figure 4.17 – High-resolution test image
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.17 – 高分辨率测试图像
- en: Compared to the low-resolution image, this photo does a better job of detailing
    the dogs and the overall scene, don't you think?
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 与低分辨率图像相比，这张照片更好地展示了狗和整个场景的细节，你不觉得吗？
- en: Tip
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: I recommend that you open both the low- and high-resolution images in a PDF
    or photo viewer. This will help you closely examine the differences between them
    and convince yourself that the network did its job well. It can be hard to judge
    the distinction in the print version of this book.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议你在PDF或照片查看器中同时打开低分辨率和高分辨率的图像。这将帮助你仔细检查它们之间的差异，并让你确信网络完成了它的工作。在本书的打印版本中，可能很难判断这种区别。
- en: How it works…
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: In this recipe, we created a model capable of improving the resolution of a
    blurry or low resolution image. The biggest takeaway of this implementation is
    that it is powered by a **fully convolutional neural network**, meaning that it
    comprises only convolutional layers and their activations.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们创建了一个能够提高模糊或低分辨率图像分辨率的模型。这个实现的最大收获是它由**完全卷积神经网络**驱动，意味着它只包含卷积层及其激活。
- en: This is a regression problem, where each pixel in the output is a feature we
    want to learn.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个回归问题，输出中的每个像素都是我们想要学习的特征。
- en: However, our goal is not to optimize for accuracy, but to train the model so
    the feature maps encode the necessary information to produce high-resolution patches
    from low-resolution ones.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的目标不是优化准确性，而是训练模型，使特征图能够编码必要的信息，从低分辨率图像生成高分辨率图像块。
- en: 'Now, we must ask ourselves: why patches? We don''t want to *learn* what''s
    in the image. Instead, again, we want our network to figure out how to go from
    low to high resolution. Patches are good enough for this purpose as they enclose
    localized patterns that are easier to grasp.'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们必须问自己：为什么是图像块？我们不想*学习*图像中的内容。相反，我们希望网络弄清楚如何从低分辨率到高分辨率。图像块足够适合这个目的，因为它们包含了局部的模式，更容易理解。
- en: You might have noticed that we didn't train for many epochs (only 12). This
    is by design because it's been shown that training for too long can actually hurt
    the network's performance.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到我们并没有训练很多周期（只有12个）。这是经过设计的，因为研究表明，训练过长实际上会损害网络的性能。
- en: Finally, it must be noted that because this network was trained on images of
    dogs and cats, its expertise lies in upscaling photos of these animals. Nonetheless,
    by switching the dataset, we can easily create a super-resolution network that
    specializes in other kind of data.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 最后需要注意的是，由于该网络是在狗和猫的图像上进行训练的，因此它的专长在于放大这些动物的照片。尽管如此，通过更换数据集，我们可以轻松地创建一个专门处理其他类型数据的超分辨率网络。
- en: See also
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'Our implementation is based on the great work of Dong et al., whose paper on
    the subject can be read here: [https://arxiv.org/abs/1501.00092](https://arxiv.org/abs/1501.00092).'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的实现基于董等人的重要工作，有关该主题的论文可以在这里阅读：[https://arxiv.org/abs/1501.00092](https://arxiv.org/abs/1501.00092)
