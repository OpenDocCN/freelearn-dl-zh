- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Machine Learning Refresher
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习复习
- en: '**Machine learning** (**ML**) is much more than just models. It is about following
    a certain process and best practices. This chapter will provide a refresher on
    these: from loading data and model evaluation to model training and optimization,
    the main steps and methods will be explained here.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）远不止是模型。它是关于遵循某种过程和最佳实践。本章将为这些内容提供复习：从加载数据、模型评估到模型训练和优化，主要的步骤和方法将在这里解释。'
- en: 'In this chapter, we are going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Loading data
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据加载
- en: Splitting data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据拆分
- en: Preparing quantitative data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备定量数据
- en: Preparing qualitative data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备定性数据
- en: Training a model
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型
- en: Evaluating a model
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估模型
- en: Performing hyperparameter optimization
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行超参数优化
- en: Even though the recipes in this chapter are independent from a methodological
    standpoint, they build upon each other and are meant to be executed sequentially.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本章中的各个教程在方法论上是独立的，但它们是相互衔接的，旨在按顺序执行。
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, you will need to be able to run code to load datasets, prepare
    data, and train, optimize, and evaluate ML models. To do so, you will need the
    following libraries:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你需要能够运行代码来加载数据集、准备数据、训练、优化和评估机器学习模型。为此，你将需要以下库：
- en: '**numpy**'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**numpy**'
- en: '**pandas**'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**pandas**'
- en: '**scikit-learn**'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**scikit-learn**'
- en: 'They can be installed using `pip` with the following command line:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 它们可以使用`pip`和以下命令行安装：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In this book, some best practices such as using virtual environments won’t be
    explicitly mentioned. However, it is highly recommended that you use a virtual
    environment before installing any library using `pip` or any other package manager.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，一些最佳实践，如使用虚拟环境，将不会明确提及。然而，强烈建议在使用`pip`或其他包管理器安装任何库之前，先使用虚拟环境。
- en: Loading data
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据加载
- en: The primary focus of this recipe is to load data from a CSV file. However, this
    is not the only thing that this recipe covers. Since the data is usually the first
    step in any ML project, this recipe is also a good opportunity to give a quick
    recap of the ML workflow, as well as the different types of data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程的主要内容是从CSV文件加载数据。然而，这并不是本教程的唯一内容。由于数据通常是任何机器学习项目的第一步，因此这个教程也是快速回顾机器学习工作流和不同类型数据的好机会。
- en: Getting ready
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Before loading the data, we should keep in mind that an ML model follows a
    two-step process:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载数据之前，我们应记住，机器学习模型遵循一个两步过程：
- en: Train a model on a given dataset to create a new model.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在给定的数据集上训练模型，以创建一个新模型。
- en: Reuse the previously trained model to infer predictions on new data.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重用先前训练的模型，对新数据进行推理预测。
- en: 'These two steps are summarized in the following figure:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这两步在以下图示中总结：
- en: '![Figure 2.1 – A simple view of the two-step ML process](img/B19629_02_01.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1 – 两步机器学习过程的简化视图](img/B19629_02_01.jpg)'
- en: Figure 2.1 – A simple view of the two-step ML process
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – 两步机器学习过程的简化视图
- en: 'Of course, in most cases, this is a rather simplistic view. A more detailed
    view can be seen in Figure 2.2:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在大多数情况下，这是一个相当简化的视图。更详细的视图可以参见图 2.2：
- en: '![Figure 2.2 – A more complete view of the ML process](img/B19629_02_02.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.2 – 更完整的机器学习过程视图](img/B19629_02_02.jpg)'
- en: Figure 2.2 – A more complete view of the ML process
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2 – 更完整的机器学习过程视图
- en: 'Let’s take a closer look at the training part of the ML process shown in *Figure
    2**.2*:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看机器学习过程中的训练部分，见*图 2.2*：
- en: First, training data is queried from a data source (this can be a database,
    a data lake, an open dataset, and so on).
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，从数据源（如数据库、数据湖、开放数据集等）查询训练数据。
- en: The data is preprocessed, such as via feature engineering, rescaling, and so
    on.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据被预处理，例如通过特征工程、重缩放等。
- en: A model is trained and stored (on a data lake, locally, on the edge, and so
    on).
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练并存储模型（存储在数据湖、本地、边缘等位置）。
- en: Optionally, the output of this model is post-processed – for example, via formatting,
    heuristics, business rules, and more.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，模型的输出会进行后处理，例如通过格式化、启发式方法、业务规则等。
- en: Optionally again, this model (with or without postprocessing) is stored in a
    database for later reference or evaluation if needed.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，这个模型（无论是否进行后处理）会被存储在数据库中，以便在需要时进行后续参考或评估。
- en: 'Now, let’s take a look at the inference part of the ML process:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看机器学习过程中的推理部分：
- en: The data is queried from a data source (a database, an API query, and so on).
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据从数据源（数据库、API 查询等）中查询。
- en: The data goes through the same preprocessing step as the training data.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据经过与训练数据相同的预处理步骤。
- en: The trained model is fetched if it doesn’t already exist locally.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果训练好的模型不存在本地，会从远程获取模型。
- en: The model is used to infer output.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用该模型推断输出。
- en: Optionally, the output of the model is post-processed via the same post-processing
    step as the training data.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，模型的输出通过与训练数据相同的后处理步骤进行后处理。
- en: Optionally, the output is stored in a database for monitoring and later reference.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，输出存储在数据库中，以供监控和后续参考。
- en: 'Even in this schema, many steps were not mentioned: splitting data for training
    purposes, using evaluation metrics, cross-validation, hyperparameter optimization,
    and others. This chapter will dive into the more training-specific steps and apply
    them to the very common but practical Titanic dataset, a binary classification
    problem. But first, we need to load the data.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在这个架构中，许多步骤也未被提及：数据划分用于训练、使用评估指标、交叉验证、超参数优化等。本章将深入探讨更具体的训练步骤，并将其应用于非常常见但实用的泰坦尼克号数据集，这是一个二分类问题。但首先，我们需要加载数据。
- en: 'To do so, you must download the **Titanic dataset training set** locally. This
    can be performed with the following command line:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，你必须将 **泰坦尼克号数据集训练集** 下载到本地。可以通过以下命令行执行此操作：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: How to do it…
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到……
- en: 'This recipe is about loading a CSV file and displaying a few lines of code
    so that we can have a first glance at what it is about:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配方是关于加载一个 CSV 文件并显示几行代码，以便我们可以初步了解它的内容：
- en: 'The first step is to import the required libraries. Here, the only library
    we need is pandas:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是导入所需的库。在这里，我们唯一需要的库是 pandas：
- en: '[PRE2]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, we can load the data using the `read_csv` function provided by pandas.
    The first argument is the path to the file. Assuming the file is named `train.csv`
    and located in the current folder, we only have to provide `train.csv` as an argument:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 pandas 提供的 `read_csv` 函数加载数据。第一个参数是文件的路径。假设文件名为 `train.csv`，并位于当前文件夹中，我们只需要提供
    `train.csv` 作为参数：
- en: '[PRE3]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The returned object is a `dataframe` object, which provides many useful methods
    for data processing.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的对象是一个 `dataframe` 对象，它提供了许多用于数据处理的有用方法。
- en: 'Now, we can display the first five lines of the loaded file using the `.``head()`
    method:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 `.head()` 方法显示加载文件的前五行：
- en: '[PRE5]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This code will output the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码将输出以下内容：
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here is a description of the data types in each column:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是每一列数据类型的描述：
- en: '`PassengerId` (qualitative): A unique, arbitrary ID for each passenger.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PassengerId`（定性）：每个乘客的唯一任意 ID。'
- en: '`Survived` (qualitative): 1 for yes, 0 for no. This is our label, so this is
    a binary classification problem.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Survived`（定性）：1 表示是，0 表示否。这是我们的标签，因此这是一个二分类问题。'
- en: '`Pclass` (quantitative, discrete): The class, which is arguably quantitative.
    Is class 1 better than class 2? Most likely yes.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pclass`（定量，离散）：乘客的舱位，通常是定量的。舱位 1 是否比舱位 2 更好？很可能是的。'
- en: '`Name` (unstructured): The name and title of the passenger.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Name`（非结构化）：乘客的姓名和头衔。'
- en: '`Sex` (qualitative): The registered sex of the passenger, either male or female.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Sex`（定性）：乘客的注册性别，可以是男性或女性。'
- en: '`Age` (quantitative, discrete): The age of the passenger.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Age`（定量，离散）：乘客的年龄。'
- en: '`SibSp` (quantitative, discrete): The number of siblings and spouses on board.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SibSp`（定量，离散）：船上兄弟姐妹和配偶的数量。'
- en: '`Parch` (quantitative, discrete): The number of parents and children on board.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Parch`（定量，离散）：船上父母和子女的数量。'
- en: '`Ticket` (unstructured): The ticket reference.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Ticket`（非结构化）：票务参考。'
- en: '`Fare` (quantitative, continuous): The ticket price.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Fare`（定量，连续）：票价。'
- en: '`Cabin` (unstructured): The cabin number, which is arguably unstructured. It
    can be seen as a qualitative feature with high cardinality.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Cabin`（非结构化）：舱位号，可以说是非结构化的。它可以看作是一个具有高基数的定性特征。'
- en: '`Embarked` (qualitative): The embarked city, either Southampton (`S`), Cherbourg
    (`C`), or Queenstown (`Q`).'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Embarked`（定性）：登船城市，可以是南安普顿（`S`）、瑟堡（`C`）或皇后镇（`Q`）。'
- en: There’s more…
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: Let’s talk about the different types of data that are available. Data is a very
    generic word and can describe many things. We are surrounded by data all the time.
    One way to specify data is using opposites.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来谈谈可用的不同数据类型。数据是一个非常通用的词，可以描述很多东西。我们总是被数据包围。指定数据的一种方式是使用对立面。
- en: 'Data can be *structured* or *unstructured*:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以是 *结构化* 或 *非结构化*：
- en: Structured data comes in the form of tables, databases, Excel files, CSV files,
    and JSON files.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结构化数据以表格、数据库、Excel 文件、CSV 文件和 JSON 文件的形式存在。
- en: 'Unstructured data does not fit in a table: it can be text, sound, image, videos,
    and so on. Even if we tend to have tabular representation, this kind of data does
    not naturally fit in an Excel table.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非结构化数据不适合表格形式：它可以是文本、声音、图像、视频等。即使我们倾向于使用表格形式表示，这类数据也不自然适合放入 Excel 表格中。
- en: Data can be *quantitative* or *qualitative*.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以是*定量的*或*定性的*。
- en: 'Quantitative data is ordered. Here are some examples:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 定量数据是有序的。以下是一些例子：
- en: €100 is greater than €10
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: €100 比 €10 大
- en: 1.8 meters is taller than 1.6 meters
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1.8 米比 1.6 米更高
- en: 18 years old is younger than 80 years old
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 18 岁比 80 岁年轻
- en: 'Qualitative data has no intrinsic order, as shown here:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 定性数据没有固有的顺序，如下所示：
- en: Blue is not intrinsically better than red
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝色并不天生优于红色
- en: A dog is not intrinsically greater than a cat
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一只狗并不天生比一只猫更优秀
- en: A kitchen is not intrinsically more useful than a bathroom
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个厨房并不天生比一个浴室更有用
- en: 'These are not mutually exclusive. An object can have both quantitative and
    qualitative features, as can be seen in the case of the car in the following figure:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特征并非互相排斥。一个对象可以同时具有定量和定性特征，如下图所示的汽车案例：
- en: '![Figure 2.3 – A single object depicted by both quantitative (left) and qualitative
    (right) features](img/B19629_02_03.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.3 – 一个对象的定量（左）和定性（右）特征表示](img/B19629_02_03.jpg)'
- en: Figure 2.3 – A single object depicted by both quantitative (left) and qualitative
    (right) features
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 – 一个对象的定量（左）和定性（右）特征表示
- en: Finally, data can be *continuous* or *discrete*.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，数据可以是*连续的*或*离散的*。
- en: 'Some data is continuous, as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 一些数据是连续的，如下所示：
- en: A weight
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个体重
- en: A volume
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个体积
- en: A price
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个价格
- en: 'On the other hand, some data is discrete:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，一些数据是离散的：
- en: A color
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种颜色
- en: A football score
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个足球得分
- en: A nationality
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个国籍
- en: Note
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Discrete != qualitative.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 离散数据 ≠ 定性数据。
- en: 'For example, a football score is discrete, but there is an intrinsic order:
    3 points is more than 2.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，足球得分是离散的，但存在固有的顺序：3 分大于 2 分。
- en: See also
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'The pandas `read_csv` function has a lot of flexibility as it can use other
    separators, handle headers, and much more. This is described in the official documentation:
    [https://pandas.pydata.org/docs/reference/api/pandas.read_csv.xhtml](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.xhtml).'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 的 `read_csv` 函数非常灵活，能够使用其他分隔符、处理标题等更多功能。这些都在官方文档中有所描述：[https://pandas.pydata.org/docs/reference/api/pandas.read_csv.xhtml](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.xhtml)。
- en: 'The pandas library allows I/O operations that have different types of inputs.
    For more information, have a look at the official documentation: [https://pandas.pydata.org/docs/reference/io.xhtml](https://pandas.pydata.org/docs/reference/io.xhtml).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 库允许执行具有不同输入类型的 I/O 操作。欲了解更多信息，请查看官方文档：[https://pandas.pydata.org/docs/reference/io.xhtml](https://pandas.pydata.org/docs/reference/io.xhtml)。
- en: Splitting data
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分割数据
- en: After loading data, splitting it is a crucial step. This recipe will explain
    why we need to split data, as well as how to do it.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据后，分割数据是一个关键步骤。本食谱将解释为什么我们需要分割数据，以及如何进行分割。
- en: Getting ready
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备中
- en: Why do we need to split data? An ML model is quite like a student.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们需要分割数据？一个机器学习模型就像一个学生。
- en: You provide a student with many lectures and exercises, with or without the
    answers. But more often than not, students are evaluated on a completely new problem.
    To make sure they fully understand the concepts and methods, they not only learn
    the exercises and solutions – they also understand the underlying concepts.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 你给学生提供许多讲座和练习，带或不带答案。但通常，学生们会在一个全新的问题上进行评估。为了确保他们完全理解概念和方法，他们不仅学习练习和解决方案——还要理解其背后的概念。
- en: 'An ML model is no different: you train the model on training data and then
    evaluate it on test data. This way, you make sure the model fully understands
    the task and generalizes well to new, unseen data.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一个机器学习模型也是一样：你在训练数据上训练模型，然后在测试数据上评估它。通过这种方式，你可以确保模型充分理解任务，并且能够很好地推广到新的、未见过的数据。
- en: 'So, the dataset is usually split into *train* and *test* sets:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，数据集通常会被分割成*训练集*和*测试集*：
- en: The train set must be as large as possible to give as many samples as possible
    to the model
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练集必须尽可能大，以便为模型提供尽可能多的样本
- en: The test set must be large enough to be statistically significant in evaluating
    the model
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试集必须足够大，以便在评估模型时具有统计意义
- en: Typical splits can be anywhere between 80% to 20% for rather small datasets
    (for example, hundreds of samples), and 99% to 1% for very large datasets (for
    example, millions of samples and more).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对于较小的数据集（例如，几百个样本），常见的划分比例为 80% 对 20%；对于非常大的数据集（例如，数百万个样本），比例通常为 99% 对 1%。
- en: For this recipe and the others in this chapter, it is assumed that the code
    has been executed in the same notebook as the previous recipe since each recipe
    reuses the code from the previous ones.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章节的这个示例和其他示例中，假设代码是在与前一个示例相同的笔记本中执行的，因为每个示例都会重复使用前一个示例中的代码。
- en: How to do it…
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Here are the steps to try out this recipe:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是尝试此示例的步骤：
- en: 'You can split the data rather easily with scikit-learn and the `train_test_split()`
    function:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用 scikit-learn 和 `train_test_split()` 函数相对容易地划分数据：
- en: '[PRE8]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This function uses the following parameters as input:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数使用以下参数作为输入：
- en: '`X`: All columns but the `''``Survived''` label'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X`：除了 `''Survived''` 标签列之外的所有列'
- en: '`y`: The `''Survived''` label column'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y`：`''Survived''` 标签列'
- en: '`test_size`: This is `0.2`, which means the training size will be 80%'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test_size`：这是 `0.2`，意味着训练集的比例为 80%。'
- en: '`stratify`: This specifies the `''Survived''` column to ensure the same label
    balance is used in both splits'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stratify`：此参数指定 `''Survived''` 列，以确保在两个数据集划分中标签的平衡性相同。'
- en: '`random_state`: `0` is any integer to ensure reproducibility'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`random_state`：`0` 是任何整数值，用于确保结果的可复现性。'
- en: 'It returns the following outputs:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 它返回以下输出：
- en: '`X_train`: The train split of `X`'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X_train`：`X` 的训练集。'
- en: '`X_test`: The test split of `X`'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`X_test`：`X` 的测试集。'
- en: '`y_train`: The training split of `y`, associated with `X_train`'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_train`：与 `X_train` 相关的 `y` 的训练集。'
- en: '`y_test`: The test split of `y`, associated with `X_test`'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y_test`：与 `X_test` 相关的 `y` 的测试集。'
- en: Note
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The `stratify` option is not mandatory but can be critical to ensure a balanced
    split of any qualitative feature, not just the labels, as is the case with imbalanced
    data.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`stratify` 选项不是强制性的，但对于确保任何定性特征（不仅仅是标签）的平衡划分非常关键，特别是对于不平衡数据的情况。'
- en: This split should be done as early as possible when performing data processing
    so that you avoid any potential data leakage. From now on, all the preprocessing
    will be computed on the train set, and only then applied to the test set, in agreement
    with *Figure 2**.2*.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 数据划分应尽早进行，以避免潜在的数据泄漏。从现在起，所有预处理步骤都会在训练集上计算，然后应用到测试集，这与 *图 2.2* 的做法一致。
- en: See also
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'See the official documentation for the `train_test_split` function: [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.xhtml](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.xhtml).'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 查看 `train_test_split` 函数的官方文档：[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.xhtml](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.xhtml)。
- en: Preparing quantitative data
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备定量数据
- en: Depending on the type of data, how the features must be prepared may differ.
    In this recipe, we’ll cover how to prepare quantitative data, including missing
    data imputation and rescaling.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据类型，特征的准备方式可能会有所不同。在本例中，我们将讨论如何准备定量数据，包括缺失数据填补和重新缩放。
- en: Getting ready
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In the Titanic dataset, as well as any other dataset, there may be missing data.
    There are several ways to deal with missing data. For example, you can drop a
    column or a row, or impute a value. There are many imputation techniques, some
    of which are more or less sophisticated. scikit-learn supplies several implementations
    of imputers, such as `SimpleImputer` and `KNNImputer`.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Titanic 数据集中，和其他任何数据集一样，可能存在缺失数据。处理缺失数据的方法有很多种。例如，可以删除某一列或某一行，或者进行数据填补。填补方法有很多种，其中一些更复杂或者更简单。scikit-learn
    提供了几种填补器的实现，例如 `SimpleImputer` 和 `KNNImputer`。
- en: As we will see in this recipe, using `SimpleImputer`, we can impute the missing
    quantitative data with the mean value.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在这个示例中所见，使用 `SimpleImputer`，我们可以用均值来填补缺失的定量数据。
- en: Once the missing data has been handled, we can prepare the quantitative data
    by rescaling it so that all the data is at the same scale.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦缺失数据得到处理，我们就可以通过重新缩放数据来准备定量数据，使得所有数据都在相同的尺度上。
- en: Several rescaling strategies exist, such as min-max scaling, robust scaling,
    standard scaling, and others.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种重新缩放策略，例如最小-最大缩放、鲁棒缩放、标准缩放等。
- en: 'In this recipe, we will use **standard scaling**. So, for each feature, we
    will subtract the mean value of this feature, and then divide it by the standard
    deviation of that feature:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用**标准缩放**。因此，对于每个特征，我们将减去该特征的均值，然后除以该特征的标准差：
- en: '![](img/Formula_02_001.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_02_001.jpg)'
- en: Fortunately, scikit-learn provides a fully working implementation via `StandardScaler`.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，scikit-learn通过`StandardScaler`提供了一个完整的实现。
- en: How to do it…
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'We will sequentially handle missing values and rescale the data in this recipe:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将依次处理缺失值并重新缩放数据：
- en: 'Import the required classes – `SimpleImputer` for missing data imputation and
    `StandardScaler` for rescaling:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的类——`SimpleImputer`用于缺失数据插补，`StandardScaler`用于重新缩放：
- en: '[PRE15]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Select the quantitative features we want to keep. Here, we will keep `''Pclass''`,
    `''Age''`, `''Fare''`, `''SibSp''`, and `''Parch''` and store these features in
    new variables for both the train and test sets:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择我们要保留的定量特征。在这里，我们将保留`'Pclass'`、`'Age'`、`'Fare'`、`'SibSp'`和`'Parch'`，并将这些特征存储在训练集和测试集的新变量中：
- en: '[PRE17]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Instantiate the simple imputer with a mean strategy. Here, the missing value
    of a feature will be replaced with the mean value of that feature:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用均值策略实例化简单填充器。在这里，特征的缺失值将被该特征的均值替代：
- en: '[PRE21]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Fit the imputer on the train set and apply it to the test set so that it avoids
    leakage in the imputation:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上拟合填充器，并将其应用于测试集，这样可以避免在插补中出现数据泄漏：
- en: '[PRE23]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now that imputation has been performed, instantiate the `scaler` object:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在插补已经完成，实例化`scaler`对象：
- en: '[PRE27]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Finally, fit and apply the standard scaler to the train set, and then apply
    it to the test set:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，拟合并应用标准缩放器到训练集，然后将其应用于测试集：
- en: '[PRE29]'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: We now have quantitative data with no missing values, fully rescaled, with no
    data leakage.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了没有缺失值、完全缩放的定量数据，且没有数据泄漏。
- en: There’s more…
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'In this recipe, we used the simple imputer, assuming there was missing data.
    In practice, it is highly recommended that you look at the data first to check
    whether there are missing values, as well as how many. It is possible to look
    at the number of missing values per column with the following code snippet:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们使用了简单填充器，假设存在缺失数据。在实际应用中，强烈建议你首先查看数据，检查是否存在缺失值以及缺失的数量。你可以使用以下代码片段查看每列的缺失值数量：
- en: '[PRE33]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This will output the following:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出如下结果：
- en: '[PRE34]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Thanks to this, we know that the `Age` feature has `146` missing values, while
    the other features have no missing data.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样做，我们知道`Age`特征有`146`个缺失值，而其他特征没有缺失数据。
- en: See also
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'A few imputers are available in scikit-learn. The list is available here: [https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.impute](https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.impute).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn中有几种可用的填充器。完整列表请见这里：[https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.impute](https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.impute)。
- en: 'There are many ways to scale data, and you can find the methods that are available
    in scikit-learn here: [https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.preprocessing).'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 数据缩放有很多方法，你可以在scikit-learn中找到可用的方法，详见：[https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.preprocessing)。
- en: 'You might be interested in looking at this comparison of several scalers on
    some given data: [https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.xhtml#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.xhtml#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会对以下内容感兴趣，这是一个关于不同缩放器在给定数据上效果对比的展示：[https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.xhtml#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.xhtml#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py)。
- en: Preparing qualitative data
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备定性数据
- en: In this recipe, we will prepare qualitative data, including missing value imputation
    and encoding.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将准备定性数据，包括缺失值插补和编码。
- en: Getting ready
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Qualitative data requires different treatment from quantitative data. Imputing
    missing values with the mean value of a feature would make no sense (and would
    not work with non-numeric data): it makes more sense, for example, to use the
    most frequent value or the mode of a feature. The `SimpleImputer` class allows
    us to do such things.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 定性数据需要与定量数据不同的处理方式。使用特征的均值填补缺失值是没有意义的（并且对非数值数据不起作用）：例如，使用最频繁的值或特征的众数来填补缺失值更为合理。`SimpleImputer`类允许我们进行这种操作。
- en: 'The same goes for rescaling: it would make no sense to rescale qualitative
    data. Instead, it is more common to encode it. One of the most typical techniques
    is called **one-hot encoding**.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 重缩放同样适用：对定性数据进行重缩放没有意义。相反，更常见的是对其进行编码。最典型的技术之一叫做**独热编码**。
- en: 'The idea is to transform each of the categories, over a total possible *N*
    categories, in a vector holding a 1 and N-1 zeros. In our example, the `Embarked`
    feature’s one-hot encoding would be as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 其思想是将每个类别在总共可能的*N*个类别中转换为一个向量，其中包含一个1和N-1个零。在我们的例子中，`Embarked`特征的独热编码如下：
- en: '*‘C’ = [1,* *0, 0]*'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*‘C’ = [1, 0, 0]*'
- en: '*‘Q’ = [0,* *1, 0]*'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*‘Q’ = [0, 1, 0]*'
- en: '*‘S’ = [0,* *0, 1]*'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*‘S’ = [0, 0, 1]*'
- en: Note
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: Having *N* columns for *N* categories is not necessarily optimal. What happens
    if, in the preceding example, we remove the first column? If the value is not
    *‘Q’ = [1, 0]* nor *‘S’ = [0, 1]*, then it must *be ‘C’ = [0, 0]*. There is no
    need to add one more column to have all the necessary information. This can be
    generalized to *N* categories only requiring *N*-1 columns to have all the information,
    which is why one-hot encoding functions usually allow you to drop a column.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 对于*N*个类别使用*N*列并不一定是最优的。如果在前面的例子中我们去掉第一列会发生什么？如果值既不是*‘Q’ = [1, 0]*也不是*‘S’ = [0,
    1]*，那么它必须是*‘C’ = [0, 0]*。没有必要再增加一列来获取所有必要的信息。这可以推广到*N*个类别，只需要*N*-1列就能包含所有信息，这也是为什么独热编码函数通常允许你丢弃一列。
- en: The `sklearn` class’ `OneHotEncoder` allows us to do this. It also allows us
    to deal with unknown categories that may appear in the test set (or the production
    environment) with several strategies, such as an error, ignore, or infrequent
    class. Finally, it allows us to drop the first column after encoding.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn`类的`OneHotEncoder`允许我们实现这一点。它还允许我们使用几种策略处理可能出现在测试集（或生产环境）中的未知类别，如错误、忽略或低频类别。最后，它允许我们在编码后丢弃第一列。'
- en: How to do it…
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'Just like in the preceding recipe, we will handle any missing data and the
    features will be one-hot encoded:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在前面的食谱中一样，我们将处理任何缺失的数据，并且特征将进行独热编码：
- en: 'Import the necessary classes – `SimpleImputer` for missing data imputation
    (already imported in the previous recipe) and `OneHotEncoder` for encoding. We
    also need to import `numpy` so that we can concatenate the qualitative and quantitative
    data that’s been prepared at the end of this recipe:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的类——用于缺失数据填补的`SimpleImputer`（在前面的食谱中已导入）和用于编码的`OneHotEncoder`。我们还需要导入`numpy`，以便我们可以在本食谱结束时将已准备好的定性和定量数据拼接在一起：
- en: '[PRE35]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '[PRE37]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Select the qualitative features we want to keep: `''Sex''` and `''Embarked''`.
    Then, store these features in new variables for both the train and test sets:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择我们要保留的定性特征：`'Sex'`和`'Embarked'`。然后，将这些特征分别存储到训练集和测试集中的新变量中：
- en: '[PRE38]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Instantiate `SimpleImputer` with `most_frequent strategy`. Any missing values
    will be replaced by the most frequent ones:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`SimpleImputer`并选择`most_frequent strategy`。任何缺失的值将被最频繁的值替代：
- en: '[PRE42]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Fit and transform the imputer on the train set, and then transform the test
    set:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上拟合并转换填补器，然后在测试集上进行转换：
- en: '[PRE44]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Instantiate the encoder. Here, we will specify the following parameters:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化编码器。在这里，我们将指定以下参数：
- en: '`drop=''first''`: This will drop the first columns of the encoding'
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`drop=''first''`：这将删除编码后的第一列'
- en: '`handle_unknown=''ignore''`: If a new value appears in the test set (or in
    production), it will be encoded as zeros:'
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`handle_unknown=''ignore''`：如果在测试集（或生产环境）中出现新值，它将被编码为零：'
- en: '[PRE48]'
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Fit and transform the encoder on the training set, and then transform the test
    set using this encoder:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上拟合并转换编码器，然后使用此编码器在测试集上进行转换：
- en: '[PRE50]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Note
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 注
- en: We need to use `.toarray()` out of the encoder because the array is a sparse
    matrix object by default and cannot be concatenated in that form with the other
    features.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要使用`.toarray()`从编码器中提取数据，因为默认情况下数组是稀疏矩阵对象，不能以这种形式与其他特征进行拼接。
- en: 'With that, all the data has been prepared – both quantitative and qualitative
    (considering this recipe and the previous one). It is now possible to concatenate
    this data before training a model:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这样，所有数据都已经准备好——包括定量数据和定性数据（考虑到本教程和之前的教程）。现在可以在训练模型之前将这些数据连接起来：
- en: '[PRE54]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: There’s more…
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'It is possible to save the data as a pickle file, either to share it or save
    it and avoid having to prepare it again. The following code will allow us to do
    this:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将数据保存为pickle文件，既可以分享它，也可以保存它以避免重新准备数据。以下代码将允许我们这样做：
- en: '[PRE58]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: We now have fully prepared data that can be used to train ML models.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在拥有完全准备好的数据，可以用于训练机器学习模型。
- en: Note
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Several steps have been omitted or simplified here for more clarity. Data may
    need more preparation, such as more thorough missing value imputation, outlier
    and duplicate detection (and perhaps removal), feature engineering, and so on.
    It is assumed that you already have some sense of those aspects and are encouraged
    to read other materials about this topic if required.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 这里省略或简化了一些步骤以便更加清晰。数据可能需要更多的准备工作，例如更彻底的缺失值填补、异常值和重复值检测（以及可能的删除）、特征工程等。假设你已经对这些方面有一定了解，并鼓励你在需要时阅读其他相关资料。
- en: See also
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参见
- en: 'This more general documentation about missing data imputation is worth looking
    at: [https://scikit-learn.org/stable/modules/impute.xhtml](https://scikit-learn.org/stable/modules/impute.xhtml).'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这份关于缺失数据填补的更通用文档值得一看：[https://scikit-learn.org/stable/modules/impute.xhtml](https://scikit-learn.org/stable/modules/impute.xhtml)。
- en: 'Finally, this more general documentation about data preprocessing can be very
    useful: [https://scikit-learn.org/stable/modules/preprocessing.xhtml](https://scikit-learn.org/stable/modules/preprocessing.xhtml).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这份关于数据预处理的更通用文档非常有用：[https://scikit-learn.org/stable/modules/preprocessing.xhtml](https://scikit-learn.org/stable/modules/preprocessing.xhtml)。
- en: Training a model
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练模型
- en: Once data has been fully cleaned and prepared, it is fairly easy to train a
    model thanks to scikit-learn. In this recipe, before training a logistic regression
    model on the Titanic dataset, we will quickly recap the ML paradigm and the different
    types of ML we can use.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据完全清洗和准备好，通过scikit-learn训练模型就相对容易了。在这份教程中，在对Titanic数据集训练逻辑回归模型之前，我们将快速回顾机器学习的范式和我们可以使用的不同类型的机器学习。
- en: Getting ready
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: If you were asked how to differentiate a car from a truck, you may be tempted
    to provide a list of rules, such as the number of wheels, size, weight, and so
    on. By doing so, you would be able to provide a set of explicit rules that would
    allow anyone to identify a car and a truck as different types of vehicles.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有人问你如何区分汽车和卡车，你可能会倾向于提供一系列规则，比如轮子数量、大小、重量等等。通过这样做，你就能提供一套显式的规则，让任何人都能将汽车和卡车区分开来。
- en: Traditional programming is not so different. While developing algorithms, programmers
    often build explicit rules, which allow them to map from data input (for example,
    a vehicle) to answers (for example, a car). We can summarize this paradigm as
    *data + rules =* *answers*.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 传统编程并没有那么不同。在开发算法时，程序员通常会构建显式规则，从而使他们能够将数据输入（例如，一辆车）映射到答案（例如，一辆汽车）。我们可以将这种范式总结为*数据
    + 规则 =* *答案*。
- en: 'If we were to train an ML model to discriminate cars from trucks, we would
    use another strategy: we would feed an ML algorithm with many pieces of data and
    their associated answers, expecting the model to learn to correct rules by itself.
    This is a different approach that can be summarized as *data + answers = rules*.
    This paradigm difference is summarized in *Figure 2**.4*. As little as it might
    look to ML practitioners, it changes everything in terms of regularization:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们要训练一个机器学习模型来区分汽车和卡车，我们会使用另一种策略：我们会将大量数据及其相关答案输入机器学习算法，期望模型能够自我学习并纠正规则。这是一种不同的方法，可以总结为*数据
    + 答案 = 规则*。这种范式的差异总结在*图2.4*中。尽管它对机器学习从业者看起来可能微不足道，但在正则化方面，它改变了一切：
- en: '![Figure 2.4 – Comparing traditional programming with ML algorithms](img/B19629_02_04.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![图2.4 – 比较传统编程与机器学习算法](img/B19629_02_04.jpg)'
- en: Figure 2.4 – Comparing traditional programming with ML algorithms
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 – 比较传统编程与机器学习算法
- en: Regularizing traditional algorithms is conceptually straightforward. For example,
    what if the rules for defining a truck overlap with the bus definition? If so,
    we can add the fact that buses have lots of windows.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 对传统算法进行正则化在概念上是直接的。例如，如果定义卡车的规则与公共汽车的定义重叠该怎么办？如果是这样，我们可以增加“公共汽车有很多窗户”这一事实。
- en: Regularization in ML is intrinsically implicit. What if the model in this case
    does not discriminate between buses and trucks?
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中的正则化本质上是隐式的。如果在这种情况下模型无法区分公交车和卡车怎么办？
- en: Should we add more data?
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该增加更多数据吗？
- en: Is the model complex enough to capture such a difference?
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是否足够复杂，以捕捉这种差异？
- en: Is it underfitting or overfitting?
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是欠拟合还是过拟合？
- en: This fundamental property of ML makes regularization complex.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的这一基本特性使得正则化变得复杂。
- en: ML can be applied to many tasks. Anyone who uses ML knows there is not just
    one type of ML model.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习可以应用于许多任务。任何使用机器学习的人都知道，机器学习模型不仅仅有一种类型。
- en: 'Arguably, most ML models fall into three main categories:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，大多数机器学习模型可以分为三大类：
- en: '**Supervised learning**'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**'
- en: '**Unsupervised learning**'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**'
- en: '**Reinforcement learning**'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习**'
- en: As is usually the case for categories, the landscape is more complex, with sub-categories
    and methods overlapping several categories. But this is beyond the scope of this
    book.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 正如通常对于类别问题的情况一样，情况更为复杂，有子类别和多种方法重叠多个类别。但这超出了本书的范围。
- en: 'This book will focus on regularization for supervised learning. In supervised
    learning, the problem is usually quite easy to specify: we have input features,
    *X* (for example, apartment surface), and labels, *y* (for example, apartment
    price). The goal is to train a model so that it’s robust enough to predict *y*,
    given *X*.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将重点讨论监督学习中的正则化。在监督学习中，问题通常很容易界定：我们有输入特征，*X*（例如，公寓面积），以及标签，*y*（例如，公寓价格）。目标是训练一个足够健壮的模型，以便在给定*X*的情况下预测*y*。
- en: 'The two major types of ML are classification and regression:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的两大主要类型是分类和回归：
- en: '**Classification**: The labels are made of qualitative data. For example, the
    task is predicting between two or more classes such as car, bus, and truck.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：标签由定性数据构成。例如，任务是预测两个或多个类别之间的区别，如汽车、公交车和卡车。'
- en: '**Regression**: The labels are made of quantitative data. For example, the
    task is predicting an actual value, such as an apartment price.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**：标签由定量数据构成。例如，任务是预测一个实际的值，如公寓价格。'
- en: 'Again, the line can be blurry; some tasks can be solved with classification
    while the labels are quantitative data, while others tasks can be both classification
    and regression ones. See *Figure 2**.5*:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这条界限可能模糊；一些任务虽然标签是定量数据，但仍然可以通过分类来解决，而其他任务可能既属于分类也属于回归。参见*图2.5*：
- en: '![Figure 2.5 – Regularization versus classification](img/B19629_02_05.jpg)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![图2.5 – 正则化与分类](img/B19629_02_05.jpg)'
- en: Figure 2.5 – Regularization versus classification
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 – 正则化与分类
- en: How to do it…
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: 'Assuming we want to train a logistic regression model (which will be explained
    properly in the next chapter), the scikit-learn library provides the `LogisticRegression`
    class, along with the `fit()` and `predict()` methods. Let’s learn how to use
    it:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们要训练一个逻辑回归模型（将在下章中详细解释），scikit-learn库提供了`LogisticRegression`类，以及`fit()`和`predict()`方法。让我们来学习如何使用它：
- en: 'Import the `LogisticRegression` class:'
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`LogisticRegression`类：
- en: '[PRE59]'
  id: totrans-278
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Instantiate a `LogisticRegression` object:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化`LogisticRegression`对象：
- en: '[PRE60]'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Fit the model on the train set:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练集上拟合模型：
- en: '[PRE62]'
  id: totrans-283
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Optionally, compute predictions by using that model on the test set:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，使用该模型在测试集上计算预测：
- en: '[PRE64]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '[PRE65]'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: See also
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'Even though more details will be provided in the next chapter, you might be
    interested in looking at the documentation of the `LogisticRegression` class:
    [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.xhtml](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.xhtml).'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管下章会提供更多细节，但你可能有兴趣查看`LogisticRegression`类的文档：[https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.xhtml](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.xhtml)。
- en: Evaluating a model
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型
- en: Once the model has been trained, it is important to evaluate it. In this recipe,
    we will provide a few insights about a few typical metrics for both classification
    and regression, before evaluating our model on the test set.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型训练完成，评估它非常重要。在本例中，我们将在评估模型在测试集上的表现之前，提供一些关于分类和回归的典型指标的见解。
- en: Getting ready
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Many evaluation metrics exist. If we think about predicting a binary classification
    and take a step back, there are only four cases:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多评估指标。如果我们考虑预测一个二分类问题并回顾一下，只有四种情况：
- en: '**False positive** (**FP**): Positive prediction, negative ground truth'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假阳性**（**FP**）：正预测，负实际值'
- en: '**True positive** (**TP**): Positive prediction, positive ground truth'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真正例** (**TP**): 正确的正类预测，正类真实值'
- en: '**True negative** (**TN**): Negative prediction, negative ground truth'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**真负例** (**TN**): 正确的负类预测，负类真实值'
- en: '**False negative** (**FN**): Negative prediction, positive ground truth:'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**假负例** (**FN**): 错误的负类预测，正类真实值：'
- en: '![Figure 2.6 – Representation of false positive, true positive, true negative,
    and false negative](img/B19629_02_06.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.6 – 假正例、真正例、真负例和假负例的表示](img/B19629_02_06.jpg)'
- en: Figure 2.6 – Representation of false positive, true positive, true negative,
    and false negative
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 – 假正例、真正例、真负例和假负例的表示
- en: Based on this, we can define a wide range of evaluation metrics.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，我们可以定义一系列评估指标。
- en: 'One of the most common metrics is accuracy, which is the ratio of good predictions.
    The definition of accuracy is as follows:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的指标之一是准确率，它是正确预测的比例。准确率的定义如下：
- en: '![](img/Formula_02_002.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_02_002.jpg)'
- en: Note
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Although very common, the accuracy may be misleading, especially for imbalanced
    labels. For example, let’s assume an extreme case where 99% of Titanic passengers
    survived, and we have a model that predicts that every passenger survived. Our
    model would have a 99% accuracy but would be wrong for 100% of passengers who
    did not survive.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管准确率非常常见，但它可能会产生误导，尤其是在标签不平衡的情况下。例如，假设一个极端情况是 99% 的泰坦尼克号乘客幸存，而我们有一个模型预测每个乘客都幸存。我们的模型准确率为
    99%，但对于所有未幸存的乘客来说，它都是错误的。
- en: There are several other very common metrics, such as precision, recall, and
    the F1 score.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些其他非常常见的指标，如精确度、召回率和 F1 分数。
- en: 'Precision is most suited when you’re trying to maximize the true positives
    and minimize the false positives – for example, making sure you detect only surviving
    passengers:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度最适用于最大化真正例并最小化假正例的情况——例如，确保只检测到幸存的乘客：
- en: '![](img/Formula_02_003.jpg)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_02_003.jpg)'
- en: 'Recall is most suited when you’re trying to maximize the true positives and
    minimize the false negatives – for example, making sure you don’t miss any surviving
    passengers:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 召回率最适用于最大化真正例并最小化假负例的情况——例如，确保不会漏掉任何幸存的乘客：
- en: '![](img/Formula_02_004.jpg)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_02_004.jpg)'
- en: 'The F1 score is just a combination of the precision and recall metrics as a
    harmonic mean:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: F1 分数是精确度和召回率的调和均值组合：
- en: '![](img/Formula_02_005.jpg)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_02_005.jpg)'
- en: Another useful classification evaluation metric is the **Receiver Operating
    Characteristic Area Under Curve** (**ROC** **AUC**) score.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有用的分类评估指标是 **接收者操作特征曲线下的面积** (**ROC** **AUC**) 分数。
- en: 'All these metrics behave similarly: when there are values between 0 and 1,
    the higher the value, the better the model. Some are also more robust to imbalanced
    labels, especially the F1 score and ROC AUC.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些指标的行为类似：当值介于 0 和 1 之间时，值越高，模型越好。有些指标对于标签不平衡更为稳健，尤其是 F1 分数和 ROC AUC。
- en: For regression tasks, the most used metrics are the **mean squared error** (**MSE**)
    and the R2 score.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 对于回归任务，最常用的指标是 **均方误差** (**MSE**) 和 R2 分数。
- en: 'The MSE is the averaged square difference between the predictions and the ground
    truth:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: MSE 是预测值和真实值之间的平均平方差：
- en: '![](img/Formula_02_006.jpg)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_02_006.jpg)'
- en: 'Here, *m* is the number of samples, *ŷ* is the predictions, and *y* is the
    ground truth:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*m*是样本数量，*ŷ*是预测值，*y*是真实值：
- en: '![Figure 2.7 – Visualization of the errors for a regression task](img/B19629_02_07.jpg)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.7 – 回归任务的误差可视化](img/B19629_02_07.jpg)'
- en: Figure 2.7 – Visualization of the errors for a regression task
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 – 回归任务的误差可视化
- en: 'In terms of the R2 score, it is a metric that can be negative and is defined
    as follows:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 就 R2 分数而言，它是一个可能为负的指标，定义如下：
- en: '![](img/Formula_02_007.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_02_007.jpg)'
- en: Note
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: While the R2 score is a typical evaluation metric (the closer to 1, the better),
    the MSE is more typical of a loss function (the closer to 0, the better).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 R2 分数是一个典型的评估指标（越接近 1 越好），但是 MSE 更典型地作为损失函数（越接近 0 越好）。
- en: How to do it…
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'Assuming our chosen evaluation metric here is accuracy, a very simple way to
    evaluate our model is to use the `accuracy_score()` function:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们选择的评估指标是准确率，那么评估我们模型的一个非常简单的方法是使用 `accuracy_score()` 函数：
- en: '[PRE66]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'This outputs the following:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 这会输出以下结果：
- en: '[PRE67]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Here, the `accuracy_score()` function provides an accuracy of 78.77%, meaning
    about 79% of our model’s predictions are right.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`accuracy_score()` 函数提供了 78.77% 的准确率，意味着大约 79% 的模型预测是正确的。
- en: See also
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另见
- en: 'Here is a list of the available metrics in scikit-learn: [https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.metrics](https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.metrics).'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 scikit-learn 中可用度量的列表：[https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.metrics](https://scikit-learn.org/stable/modules/classes.xhtml#module-sklearn.metrics)。
- en: Performing hyperparameter optimization
  id: totrans-332
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行超参数优化
- en: 'In this recipe, we will explain what hyperparameter optimization is and some
    related concepts: the definition of a **hyperparameter**, **cross-validation**,
    and various **hyperparameter optimization methods**. We will then perform a grid
    search to optimize the hyperparameters of the logistic regression task on the
    Titanic dataset.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将解释什么是超参数优化以及一些相关概念：**超参数**的定义、**交叉验证**和各种**超参数优化方法**。然后，我们将执行网格搜索，优化
    Titanic 数据集上逻辑回归任务的超参数。
- en: Getting ready
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 做好准备
- en: Most of the time, in ML, we do not simply train a model on the training set
    and evaluate it against the test set.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，大多数情况下，我们不仅仅是在训练集上训练一个模型，然后在测试集上评估它。
- en: This is because, like most other algorithms, ML algorithms can be fine-tuned.
    This fine-tuning process allows us to optimize hyperparameters to achieve the
    best possible results. This sometimes acts as leverage so that we can regularize
    a model.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为像大多数其他算法一样，机器学习算法可以进行微调。这个微调过程让我们可以优化超参数，从而获得最佳的结果。这有时也作为杠杆，帮助我们对模型进行正则化。
- en: Note
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In ML, hyperparameters can be tuned by humans, unlike parameters, which are
    learned through the model training process, and thus can’t be tuned.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，超参数是由人类调整的，而参数是通过模型训练过程学习的，因此不能调整。
- en: 'To properly optimize hyperparameters, a third split has to be introduced: the
    validation set.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确优化超参数，需要引入第三个拆分：验证集。
- en: 'This means there are now three splits:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着现在有了三个拆分：
- en: '**The training set**: Where the model is trained'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练集**：模型训练的地方'
- en: '**The validation set**: Where the hyperparameters are optimized'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**验证集**：超参数优化的地方'
- en: '**The test set**: Where the model is evaluated'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试集**：模型进行评估的地方'
- en: You could create such a set by splitting `X_train` into `X_train` and `X_valid`
    with the `train_test_split()` function from scikit-learn.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用 scikit-learn 的 `train_test_split()` 函数将 `X_train` 拆分成 `X_train` 和 `X_valid`
    来创建这样的集。
- en: 'But in practice, most people just use cross-validation and do not bother creating
    this validation set. The k-fold cross-validation method allows us to make *k*
    splits out of the training set and divide it, as presented in *Figure 2**.8*:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 但在实际操作中，大多数人仅使用交叉验证，并且不费心创建这个验证集。k折交叉验证方法允许我们从训练集中进行*k*次拆分，并将其分开，如*图 2.8*所示：
- en: '![Figure 2.8 – Typical split between training, validation, and test sets, without
    cross-validation (top) and with cross-validation (bottom)](img/B19629_02_08.jpg)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.8 – 典型的训练集、验证集和测试集的拆分，无交叉验证（上图）和有交叉验证（下图）](img/B19629_02_08.jpg)'
- en: Figure 2.8 – Typical split between training, validation, and test sets, without
    cross-validation (top) and with cross-validation (bottom)
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.8 – 典型的训练集、验证集和测试集的拆分，无交叉验证（上图）和有交叉验证（下图）
- en: In doing so, not just one model is trained, but *k*, for a given set of hyperparameters.
    The performances are averaged over those *k* models, based on a chosen metric
    (for example, accuracy, MSE, and so on).
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做时，不是训练一个模型，而是针对给定的超参数集训练*k*个模型。然后基于选择的度量（例如准确度、均方误差等），对这*k*个模型的表现进行平均。
- en: Several sets of hyperparameters can then be tested, and the one that shows the
    best performance is selected. After selecting the best hyperparameter set, the
    model is trained one more time on the entire train set to maximize the data for
    training purposes.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可以测试多个超参数集合，选择性能最佳的那个。在选择了最佳超参数集合后，模型会在整个训练集上再次训练，以最大化用于训练的数据。
- en: 'Finally, you can implement several strategies to optimize the hyperparameters,
    as follows:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以实施几种策略来优化超参数，如下所示：
- en: '**Grid search**: Test all combinations of the provided values of hyperparameters'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网格搜索**：测试提供的超参数值的所有组合'
- en: '**Random search**: Randomly search combinations of hyperparameters'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机搜索**：随机搜索超参数的组合'
- en: '**Bayesian search**: Perform Bayesian optimization on the hyperparameters'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贝叶斯搜索**：对超参数进行贝叶斯优化'
- en: How to do it…
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'While being rather complicated to explain conceptually, hyperparameter optimization
    with cross-validation is super easy to implement. In this recipe, we’ll assume
    that we want to optimize a logistic regression model to predict whether a passenger
    would have survived:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然从概念上解释起来相当复杂，但使用交叉验证进行超参数优化非常容易实现。在这个例子中，我们假设我们希望优化一个逻辑回归模型，预测乘客是否会幸存：
- en: First, we need to import the `GridSearchCV` class from `sklearn.model_selection`.
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要从`sklearn.model_selection`导入`GridSearchCV`类。
- en: 'We would like to test the following hyperparameter values for `C`: `[0.01,
    0.03, 0.1]`. We must define a parameter grid with the hyperparameter as the key
    and the list of values to test as the value.'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们希望测试以下`C`的超参数值：`[0.01, 0.03, 0.1]`。我们必须定义一个参数网格，其中超参数作为键，待测试的值列表作为值。
- en: 'The `C` hyperparameter is the inverse of the penalization strength: the higher
    `C` is, the lower the regularization. See the next chapter for more details:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: '`C`超参数是惩罚强度的倒数：`C`越大，正则化越小。详细信息请参见下一章：'
- en: '[PRE68]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Finally, let’s assume we want to optimize our model on accuracy, with five
    cross-validation folds. To do this, we will instantiate the `GridSearchCV` object
    and provide the following arguments:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，假设我们希望通过五次交叉验证折叠来优化模型的准确性。为此，我们将实例化`GridSearchCV`对象，并提供以下参数：
- en: The model to optimize, which is a `LogisticRegression` instance
  id: totrans-361
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要优化的模型，它是一个`LogisticRegression`实例
- en: The parameter grid, `param_grid`, which we defined previously
  id: totrans-362
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们之前定义的超参数网格`param_grid`
- en: The scoring on which to optimize – that is, `accuracy`
  id: totrans-363
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要优化的评分标准——即`accuracy`
- en: The number of cross-validation folds, which has been set to `5` here
  id: totrans-364
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置为`5`的交叉验证折叠次数
- en: 'We must also set `return_train_score` to `True` to get some useful information
    we can use later:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还必须将`return_train_score`设置为`True`，以便获取一些我们以后可以使用的有用信息：
- en: '[PRE69]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '[PRE71]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[PRE72]'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '[PRE74]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: '[PRE75]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Finally, all we have to do is train this object on the train set. This will
    automatically make all the computations and store the results:'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们要做的就是在训练集上训练这个对象。这将自动进行所有计算并存储结果：
- en: '[PRE77]'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: '[PRE78]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: '[PRE79]'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: '[PRE80]'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '[PRE81]'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Note
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Depending on the input dataset and the number of tested hyperparameters, the
    fit may take some time.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 根据输入数据集和测试的超参数数量，拟合可能需要一些时间。
- en: 'Once the fit has been completed, you can get a lot of useful information, such
    as the following:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合完成后，您可以获取许多有用的信息，例如以下内容：
- en: The hyperparameter set via the `.``best_params` attribute
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`.best_params`属性获得超参数集
- en: The best accuracy score via the `.``best_score` attribute
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`.best_score`属性获得最佳准确度分数
- en: The cross-validation results via the `.``cv_results` attribute
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`.cv_results`属性获得交叉验证结果
- en: 'Finally, you can infer the model that was trained with optimized hyperparameters
    using the `.``predict()` method:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，您可以使用`.predict()`方法推断经过优化超参数训练的模型：
- en: '[PRE82]'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Optionally, you can evaluate the chosen model with the accuracy score:'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，您可以使用准确度评分来评估所选择的模型：
- en: '[PRE83]'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: '[PRE84]'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'This provides the following output:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 这将提供以下输出：
- en: '[PRE85]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Thanks to the tools provided by scikit-learn, it is fairly easy to have a well-optimized
    model and evaluate it against several metrics. In the next recipe, we’ll learn
    how to diagnose bias and variance based on such an evaluation.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 借助scikit-learn提供的工具，优化模型并使用多个指标进行评估非常容易。在下一节中，我们将学习如何基于这样的评估来诊断偏差和方差。
- en: See also
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 另见
- en: The documentation for `GridSearchCV` can be found at [https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.xhtml](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.xhtml).
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '`GridSearchCV`的文档可以在[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.xhtml](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.xhtml)找到。'
