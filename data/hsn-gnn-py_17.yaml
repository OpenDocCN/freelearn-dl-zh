- en: '17'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '17'
- en: Building a Recommender System Using LightGCN
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LightGCN构建推荐系统
- en: Recommender systems have become an integral part of modern online platforms,
    with the goal of providing personalized recommendations to users based on their
    interests and past interactions. These systems can be found in a variety of applications,
    including suggesting products to purchase on e-commerce websites, recommending
    content to watch on streaming services, and suggesting connections to make on
    social media platforms.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统已成为现代在线平台的不可或缺的一部分，旨在根据用户的兴趣和过去的互动提供个性化推荐。这些系统可以在多种应用中找到，包括在电子商务网站上推荐购买的产品，在流媒体服务中推荐观看的内容，以及在社交媒体平台上推荐建立联系的对象。
- en: Recommendation systems are one of the main applications of GNNs. Indeed, they
    can effectively incorporate the complex relationships between users, items, and
    their interactions into a unified model. In addition, the graph structure allows
    for the incorporation of side information, such as user and item metadata, into
    the recommendation process.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统是GNN的主要应用之一。事实上，它们可以有效地将用户、项目及其互动之间的复杂关系整合到一个统一的模型中。此外，图结构还允许在推荐过程中融入附加信息，例如用户和项目的元数据。
- en: In this chapter, we will introduce a new GNN architecture called `Book-Crossing`
    dataset, which contains users, books, and over a million ratings. Using this dataset,
    we will build a book recommender system with collaborative filtering and apply
    it to get recommendations for a specific user. Through this process, we will demonstrate
    how to use the LightGCN architecture to build a practical recommendation system.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍一种新的GNN架构，名为`Book-Crossing`数据集，该数据集包含用户、书籍以及超过百万条评分。利用该数据集，我们将构建一个基于协同过滤的书籍推荐系统，并应用它为特定用户提供推荐。通过这一过程，我们将展示如何使用LightGCN架构构建一个实用的推荐系统。
- en: By the end of this chapter, you will be able to create your own recommender
    system using LightGCN. You will learn how to process any dataset with users, items,
    and scores for a collaborative filtering approach. Finally, you will learn how
    to implement and evaluate this architecture and get recommendations for individual
    users.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束时，你将能够使用LightGCN创建自己的推荐系统。你将学习如何处理包含用户、项目和评分的数据集，以实现协同过滤方法。最后，你将学习如何实现和评估该架构，并为个别用户提供推荐。
- en: 'In this chapter, we will cover the following main topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将覆盖以下主要内容：
- en: Exploring the Book-Crossing dataset
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索Book-Crossing数据集
- en: Preprocessing the Book-Crossing dataset
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理Book-Crossing数据集
- en: Implementing the LightGCN architecture
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现LightGCN架构
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the code examples from this chapter can be found on GitHub at [https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter17](https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter17).
    The installation steps required to run the code on your local machine can be found
    in the *Preface* of this book.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码示例都可以在GitHub上找到，地址是[https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter17](https://github.com/PacktPublishing/Hands-On-Graph-Neural-Networks-Using-Python/tree/main/Chapter17)。运行代码所需的安装步骤可以在本书的*前言*中找到。
- en: This chapter requires a large amount of GPU. You can lower it by decreasing
    the size of the training set in the code.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要大量的GPU资源。你可以通过减少代码中训练集的大小来降低需求。
- en: Exploring the Book-Crossing dataset
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索Book-Crossing数据集
- en: In this section, we will perform exploratory data analysis on a new dataset
    and visualize its main characteristics.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中，我们将对一个新的数据集进行探索性数据分析，并可视化其主要特征。
- en: The `Book-Crossing` dataset [1] is a collection of book ratings provided by
    278,858 users in the *BookCrossing community* ([www.bookcrossing.com](http://www.bookcrossing.com)).
    The ratings, which are both explicit (rating between 1 and 10) and implicit (users
    interacted with the book), total 1,149,780 and pertain to 271,379 books. The dataset
    was collected by Cai-Nicolas Ziegler during a four-week crawl in August and September
    2004\. We will use the `Book-Crossing` dataset to build a book recommender system
    in this chapter.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '`Book-Crossing`数据集[1]是由278,858名用户提供的书籍评分集合，来自*BookCrossing社区*（[www.bookcrossing.com](http://www.bookcrossing.com)）。这些评分既有显式的（1到10之间的评分），也有隐式的（用户与书籍的互动），总计1,149,780条，涉及271,379本书。该数据集由Cai-Nicolas
    Ziegler于2004年8月和9月的四周爬取收集。我们将在本章中使用`Book-Crossing`数据集来构建一个书籍推荐系统。'
- en: 'Let’s download the dataset and unzip it with the following commands:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下命令下载数据集并解压：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This will unzip three files:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这将解压出三个文件：
- en: The `BX-Users.csv` file contains data on individual BookCrossing users. User
    IDs have been anonymized and are represented as integers. Demographic information,
    such as location and age, is also included for some users. If this information
    is not available, the corresponding fields contain `NULL` values.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BX-Users.csv` 文件包含单个 BookCrossing 用户的数据。用户 ID 已被匿名处理，表示为整数。一些用户的 demographic
    信息，如所在地和年龄，也被包括在内。如果这些信息不可用，相应的字段将包含 `NULL` 值。'
- en: The `BX-Books.csv` file contains data on the books included in the dataset,
    identified by their ISBN. Invalid ISBNs have been removed from the dataset. In
    addition to content-based information, such as the book title, author, year of
    publication, and publisher. This file also includes URLs linking to cover images
    of the books of three different sizes.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BX-Books.csv` 文件包含数据集中的书籍信息，通过 ISBN 进行标识。无效的 ISBN 已从数据集中删除。除了书籍标题、作者、出版年份和出版社等内容相关信息外，此文件还包括指向三种不同大小封面图像的书籍链接
    URL。'
- en: The `BX-Book-Ratings.csv` file includes information on the ratings given to
    books in the dataset. Ratings are either explicit, given on a scale from 1-10
    with higher values indicating a greater appreciation, or implicit, indicated by
    a rating of 0.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`BX-Book-Ratings.csv` 文件包含有关数据集中书籍评分的信息。评分可以是显式的，采用 1 到 10 的等级，较高的值表示更高的评价；或者是隐式的，用
    0 表示评分。'
- en: The following figure is a graph representation made with Gephi using a subsample
    of this dataset.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 下图是使用 Gephi 制作的图形表示，采用了数据集的一个子样本。
- en: '![Figure 17.1 – Graph representation of the Book-Crossing dataset, with books
    represented as blue nodes and users represented as red nodes](img/B19153_17_001.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.1 – Book-Crossing 数据集的图形表示，书籍表示为蓝色节点，用户表示为红色节点](img/B19153_17_001.jpg)'
- en: Figure 17.1 – Graph representation of the Book-Crossing dataset, with books
    represented as blue nodes and users represented as red nodes
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.1 – Book-Crossing 数据集的图形表示，书籍表示为蓝色节点，用户表示为红色节点
- en: The size of the nodes is proportional to the number of connections (degree)
    in the graph. We can see popular books such as **The Da Vinci Code** that act
    like hubs thanks to their high number of connections.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 节点的大小与图中的连接数量（度数）成比例。我们可以看到像 **达·芬奇密码** 这样的热门书籍，它们由于连接数高而充当了枢纽。
- en: 'Now, let’s explore the dataset to get more insight:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探索数据集，获取更多的洞察：
- en: 'We import `pandas` and load every file with the `;` separator and the `latin-1`
    encoding for compatibility issues. `BX-Books.csv` also requires the `error_bad_lines`
    parameter:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入 `pandas` 并加载每个文件，使用 `;` 分隔符和 `latin-1` 编码，以解决兼容性问题。`BX-Books.csv` 文件还需要
    `error_bad_lines` 参数：
- en: '[PRE1]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s print these DataFrames to see the columns and the number of rows:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们打印这些数据框，以查看列和行数：
- en: '[PRE2]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let’s repeat the process with the `users` DataFrame:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们重复这个过程，使用 `users` 数据框：
- en: '[PRE3]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Finally, the `books` DataFrame has too many columns to be printed like the
    two others. Let’s print the column names instead:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，`books` 数据框包含的列太多，无法像另外两个数据框那样打印出来。我们可以改为打印列名：
- en: '[PRE4]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `ratings` DataFrame links the `users` and `books` DataFrames using `User-ID`
    and `ISBN` information and includes a rating, which could be considered a weight.
    The `users` DataFrame includes demographic information, such as location and age,
    for each user when available. The `books` DataFrame includes content-related information
    about the books, such as the title, author, year of publication, publisher, and
    URLs linking to cover images of three different sizes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`ratings` 数据框通过 `User-ID` 和 `ISBN` 信息连接了 `users` 和 `books` 数据框，并包含评分，这可以视为一种权重。`users`
    数据框包含每个用户的 demographic 信息，如所在地和年龄（如果有的话）。`books` 数据框包含关于书籍的内容相关信息，如书名、作者、出版年份、出版社以及链接到三种不同大小封面图像的
    URL。'
- en: 'Let’s visualize the rating distribution to see whether we can use this information.
    We can plot it using `matplotlib` and `seaborn` as follows:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们可视化评分分布，以查看是否能利用这些信息。我们可以使用 `matplotlib` 和 `seaborn` 按如下方式绘制：
- en: '[PRE5]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This gives us the following plot:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这为我们提供了以下图表：
- en: '![Figure 17.2 – Rating distribution (interaction with a book is represented
    as a rating of zero, while ratings between 1 and 10 are real ratings)](img/B19153_17_002.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.2 – 评分分布（与书籍的互动被表示为零评分，而 1 到 10 之间的评分为真实评分）](img/B19153_17_002.jpg)'
- en: Figure 17.2 – Rating distribution (interaction with a book is represented as
    a rating of zero, while ratings between 1 and 10 are real ratings)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.2 – 评分分布（与一本书的互动表现为评分为零，而 1 到 10 之间的评分为真实评分）
- en: 'Do these ratings correspond to the data we have in the `books` and `users`
    DataFrames? We can compare the number of unique `User-ID` and `ISBN` entries in
    `ratings` to the number of rows in these DataFrames as a quick check:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这些评分是否与我们在 `books` 和 `users` DataFrame 中的数据相对应？我们可以通过比较 `ratings` 中的唯一 `User-ID`
    和 `ISBN` 条目的数量与这些 DataFrame 中行数的差异，快速检查：
- en: '[PRE6]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Interestingly, there are fewer unique users in `ratings` compared to `users`
    (105,283 versus 278,858) but more unique ISBNs compared to `books` (340,556 versus
    271,379). This means that our database is missing a lot of values, so we will
    need to be careful when joining tables.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，与 `users`（105,283 与 278,858）相比，`ratings` 中的独立用户较少，但与 `books`（340,556 与
    271,379）相比，独立 ISBN 数量更多。这意味着我们的数据库缺失了很多数据，因此在连接表时需要特别小心。
- en: 'Let’s finish by plotting the number of books that have been rated only once,
    twice, and so on. First, we calculate the number of times each ISBN appears in
    the `ratings` DataFrame using the `groupby()` and `size()` functions:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们绘制仅被评分一次、两次等次数的书籍数量。首先，我们使用 `groupby()` 和 `size()` 函数计算每本 ISBN 在 `ratings`
    DataFrame 中出现的次数：
- en: '[PRE7]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This creates a new DataFrame, `isbn_counts`, which contains the count of each
    unique ISBN in the `ratings` DataFrame.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这创建了一个新的 DataFrame，`isbn_counts`，它包含了每个独立 ISBN 在 `ratings` DataFrame 中的计数。
- en: 'We calculate the number of occurrences of each count value using the `value_counts()`
    function. This new DataFrame will contain the count of occurrences of each count
    value in `isbn_counts`:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 `value_counts()` 函数计算每个计数值的出现次数。这个新的 DataFrame 将包含 `isbn_counts` 中每个计数值的出现次数。
- en: '[PRE8]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, we can plot the distribution using `pandas`’ `.plot()` method. In
    this case, we will only plot the first 15 values:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以使用 `pandas` 的 `.plot()` 方法绘制分布图。在这种情况下，我们只绘制前 15 个值：
- en: '[PRE9]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We obtain the following plot:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们得到以下图表：
- en: '![Figure 17.3 – Distribution of the number of times each book (ISBN) appears
    in ratings (15 first values)](img/B19153_17_003.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.3 – 每本书（ISBN）在评分中出现次数的分布（前 15 个值）](img/B19153_17_003.jpg)'
- en: Figure 17.3 – Distribution of the number of times each book (ISBN) appears in
    ratings (15 first values)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.3 – 每本书（ISBN）在评分中出现次数的分布（前 15 个值）
- en: We see that a lot of books have only been rated once or twice. It is very rare
    to see books with a lot of ratings, which makes things more difficult for us since
    we rely on these connections.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到许多书籍只被评分一次或两次。看到评分很多次的书籍非常罕见，这使得我们的任务更加困难，因为我们依赖于这些连接。
- en: 'We repeat the same process to obtain the distribution of the number of times
    each user (`User-ID`) appears in `ratings`:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们重复相同的过程，以获取每个用户（`User-ID`）在 `ratings` 中出现次数的分布：
- en: '[PRE10]'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We obtain a similar distribution:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们得到了一个类似的分布：
- en: '![Figure 17.4 – Distribution of the number of times each user (User-ID) appears
    in ratings (15 first values)](img/B19153_17_004.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.4 – 每个用户（用户 ID）在评分中出现次数的分布（前 15 个值）](img/B19153_17_004.jpg)'
- en: Figure 17.4 – Distribution of the number of times each user (User-ID) appears
    in ratings (15 first values)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.4 – 每个用户（用户 ID）在评分中出现次数的分布（前 15 个值）
- en: This also means that most users only rate one or two books, but a few of them
    rate a lot of books.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这也意味着大多数用户只评分一两本书，但有少数用户评分了很多书。
- en: There are different issues with this dataset, such as mistakes in the year of
    publication or the name of the publishers, and other missing or incorrect values.
    However, we will not directly use metadata from the `books` and `users` DataFrames
    in this chapter. We will rely on the connections between `User-ID` and `ISBN`
    values, which is why we don’t need to clean the dataset here.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集存在一些问题，如出版年份或出版商名称的错误，以及其他缺失或不正确的值。然而，在本章中，我们不会直接使用 `books` 和 `users` DataFrame
    中的元数据。我们将依赖 `User-ID` 和 `ISBN` 值之间的连接，因此不需要在这里清理数据集。
- en: In the next section, we will see how to process the dataset to prepare it before
    feeding it to the LightGCN.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看到如何处理数据集，为将其输入到 LightGCN 做准备。
- en: Preprocessing the Book-Crossing dataset
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预处理 Book-Crossing 数据集
- en: 'We want to process the dataset for a particular task: recommending items, and
    more specifically using a **collaborative filtering** approach. Collaborative
    filtering is a technique used to make personalized recommendations to users. It
    is based on the idea that users who have similar preferences or behaviors are
    more likely to have similar interests. Collaborative filtering algorithms use
    this information to identify patterns and make recommendations to users based
    on the preferences of similar users.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望处理数据集以完成特定任务：推荐物品，具体来说是使用**协同过滤**方法。协同过滤是一种用于向用户提供个性化推荐的技术。它基于这样一个观点：具有相似偏好或行为的用户更有可能有相似的兴趣。协同过滤算法利用这些信息识别模式，并基于相似用户的偏好向用户做出推荐。
- en: This is different from content-based filtering, which is a recommendation approach
    that relies on the features of the items being recommended. It generates recommendations
    by identifying the characteristics of an item and matching them to the characteristics
    of other items that have been liked by the user in the past. **Content-based filtering**
    approaches are typically based on the idea that if a user likes an item with certain
    characteristics, they will also like items with similar characteristics.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这与基于内容的过滤不同，基于内容的过滤是一种依赖于推荐物品特征的推荐方法。它通过识别物品的特征并将其与用户过去喜欢的其他物品的特征进行匹配，从而生成推荐。**基于内容的过滤**方法通常基于这样一个观点：如果用户喜欢具有某些特征的物品，那么他们也会喜欢具有相似特征的物品。
- en: In this chapter, we will focus on collaborative filtering. Our objective is
    to determine which book to recommend to a user based on the preferences of other
    users. This problem can be represented as a bipartite graph as in the following
    figure.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点讨论协同过滤。我们的目标是根据其他用户的偏好来确定推荐给用户的书籍。这个问题可以通过二分图来表示，如下图所示。
- en: '![Figure 17.5 – Example of a user-item bipartite graph](img/B19153_17_005.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.5 – 用户-物品二分图示例](img/B19153_17_005.jpg)'
- en: Figure 17.5 – Example of a user-item bipartite graph
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.5 – 用户-物品二分图示例
- en: Knowing that user **1** liked items **A** and **B**, and user **3** liked items
    **B** and **D**, we should probably recommend item **B** to user **2**, who also
    enjoyed items **A** and **D**.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 知道用户**1**喜欢物品**A**和**B**，用户**3**喜欢物品**B**和**D**，我们应该推荐物品**B**给用户**2**，他也喜欢物品**A**和**D**。
- en: This is the type of graph we want to build from the `Book-Crossing` dataset.
    More precisely, we also want to include negative samples. In this context, negative
    samples refer to items that have not been rated by a given user. Items that have
    been rated by a particular user are also referred to as positive items. We will
    explain why we use this negative sampling technique when we implement the `loss`
    function.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们希望从`Book-Crossing`数据集中构建的图类型。更准确地说，我们还希望包括负样本。在这种情况下，负样本指的是给定用户未评分的物品。已经评分的物品被称为正样本。我们将在实现`loss`函数时解释为什么使用这种负采样技术。
- en: 'In the rest of the chapter, the `LightGCN` code is mostly based on the official
    implementation and the excellent work of Hotta and Zhou [2] and Li et al. [3]
    on a different dataset:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，`LightGCN`代码主要基于官方实现以及Hotta和Zhou [2]以及Li等人[3]在不同数据集上出色的工作：
- en: 'We import the following libraries:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们导入以下库：
- en: '[PRE11]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We re-load the datasets:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们重新加载数据集：
- en: '[PRE12]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We only keep rows where `ISBN` information can be found in the `books` DataFrame
    and `User-ID` information can be found in the `users` DataFrame:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只保留在`books`数据框中可以找到`ISBN`信息和在`users`数据框中可以找到`User-ID`信息的行：
- en: '[PRE13]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We only keep high ratings (>= 8/10) so the connections we create correspond
    to books that were liked by users. Then, we filter out even more samples and keep
    a limited number of rows (100,000) to speed up training:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们只保留高评分（>= 8/10），因此我们创建的连接对应于用户喜欢的书籍。然后，我们进一步筛选样本，只保留有限数量的行（100,000）以加快训练速度：
- en: '[PRE14]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We create mappings from `user` and `item` identifiers to integer indices:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建`user`和`item`标识符到整数索引的映射：
- en: '[PRE15]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We count the number of users, items, and total entities in the dataset:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们统计数据集中的用户数、物品数和总实体数：
- en: '[PRE16]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We create a tensor of `user` and `item` indices based on the user ratings in
    the dataset. The `edge_index` tensor is created by stacking these two tensors:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们基于数据集中的用户评分创建`user`和`item`索引的张量。通过堆叠这两个张量来创建`edge_index`张量：
- en: '[PRE17]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We split `edge_index` into training, validation, and test sets using the `train_test_split()`
    function from `scikit-learn`:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 `scikit-learn` 中的 `train_test_split()` 函数将 `edge_index` 分割为训练集、验证集和测试集：
- en: '[PRE18]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We generate a batch of random indices using the `np.random.choice()` function.
    This generates `BATCH_SIZE` random indices from a range of `0` to `edge_index.shape[1]-1`.
    These indices will be used to select rows from the `edge_index` tensor:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 `np.random.choice()` 函数生成一个随机索引批次。该函数从 `0` 到 `edge_index.shape[1]-1` 的范围内生成
    `BATCH_SIZE` 个随机索引。这些索引将用于从 `edge_index` 张量中选择行：
- en: '[PRE19]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We generate negative samples using the `structured_negative_sampling()` function
    from PyTorch Geometric. Negative samples are items with which the corresponding
    user has not interacted. We use the `torch.stack()` function to add a dimension
    at the beginning:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 PyTorch Geometric 中的 `structured_negative_sampling()` 函数生成负样本。负样本是用户未与之交互的项。我们使用
    `torch.stack()` 函数在开头添加一个维度：
- en: '[PRE20]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We select the user, positive item, and negative item indices for the batch
    using the `index` array and the `edge_index` tensor:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用 `index` 数组和 `edge_index` 张量选择该批次的用户、正样本项和负样本项索引：
- en: '[PRE21]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `user_index` tensor contains the user indices for the batch, the `pos_item_index`
    tensor contains the positive item indices for the batch, and the `neg_item_index`
    tensor contains the negative item indices for the batch.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`user_index` 张量包含该批次的用户索引，`pos_item_index` 张量包含该批次的正样本项索引，`neg_item_index`
    张量包含该批次的负样本项索引。'
- en: We now have three sets and a function to return mini-batches. The next step
    is to understand and implement the LightGCN architecture.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有三组数据和一个返回小批量数据的函数。接下来的步骤是理解并实现 LightGCN 架构。
- en: Implementing the LightGCN architecture
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现 LightGCN 架构
- en: The LightGCN [4] architecture aims to learn representations for nodes by smoothing
    features over the graph. It iteratively performs graph convolution, where neighboring
    nodes’ features are aggregated as the new representation of a target node. The
    entire architecture is summarized in *Figure 17**.6*.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: LightGCN [4] 架构旨在通过图上的特征平滑来学习节点的表示。它通过图卷积反复执行，其中相邻节点的特征被聚合为目标节点的新表示。整个架构概述见
    *图 17.6*。
- en: '![Figure 17.6 – LightGCN model architecture with convolution and layer combination](img/B19153_17_006.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![图 17.6 – 带有卷积和层组合的 LightGCN 模型架构](img/B19153_17_006.jpg)'
- en: Figure 17.6 – LightGCN model architecture with convolution and layer combination
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.6 – 带有卷积和层组合的 LightGCN 模型架构
- en: 'However, `LightGCN` adopts a simple weighted sum aggregator rather than using
    feature transformation or nonlinear activation as seen in other models such as
    the GCN or GAT. The light graph convolution operation calculates the ![](img/Formula_B19153_17_001.png)-th
    user and item embedding ![](img/Formula_B19153_17_002.png) and ![](img/Formula_B19153_17_003.png)
    as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，`LightGCN` 采用了简单的加权和聚合器，而不是像 GCN 或 GAT 等其他模型中使用的特征变换或非线性激活。轻量级图卷积操作计算 ![](img/Formula_B19153_17_001.png)
    处的用户和项嵌入 ![](img/Formula_B19153_17_002.png) 和 ![](img/Formula_B19153_17_003.png)，计算方式如下：
- en: '![](img/Formula_B19153_17_004.jpg)![](img/Formula_B19153_17_005.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_17_004.jpg)![](img/Formula_B19153_17_005.jpg)'
- en: The symmetric normalization term ensures that the scale of embeddings does not
    increase with graph convolution operations. In contrast to other models, `LightGCN`
    only aggregates the connected neighbors and does not include self-connections.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对称归一化项确保嵌入的尺度不会随着图卷积操作而增加。与其他模型不同，`LightGCN` 仅聚合连接的邻居节点，并不包含自连接。
- en: 'Indeed, it achieves the same effect by using a layer combination operation.
    This mechanism consists of a weighted sum using user and item embeddings at each
    layer. It produces the final embeddings ![](img/Formula_B19153_17_006.png) and
    ![](img/Formula_B19153_17_007.png) with the following equations:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，它通过使用层组合操作来实现相同的效果。这个机制由每层使用用户和项嵌入的加权和组成。它通过以下方程式产生最终的嵌入 ![](img/Formula_B19153_17_006.png)
    和 ![](img/Formula_B19153_17_007.png)：
- en: '![](img/Formula_B19153_17_008.jpg)![](img/Formula_B19153_17_009.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_17_008.jpg)![](img/Formula_B19153_17_009.jpg)'
- en: Here, the contribution of ![](img/Formula_B19153_17_010.png)-th layer is weighted
    by the variable ![](img/Formula_B19153_17_011.png). The authors of `LightGCN`
    recommend setting it to ![](img/Formula_B19153_17_012.png).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，第 ![](img/Formula_B19153_17_010.png) 层的贡献由变量 ![](img/Formula_B19153_17_011.png)
    加权。`LightGCN` 的作者建议将其设置为 ![](img/Formula_B19153_17_012.png)。
- en: 'The prediction shown in *Figure 17**.6* corresponds to ratings or ranking scores.
    It is obtained using the inner product of user and item final representations:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '*图17.6*中显示的预测对应于评分或排名分数。它是通过用户和项目最终表示的内积得到的：'
- en: '![](img/Formula_B19153_17_013.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_17_013.jpg)'
- en: 'Let’s now implement this architecture in PyTorch Geometric:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们在PyTorch Geometric中实现这个架构：
- en: 'We create a `LightGCN` class with four arguments: `num_users`, `num_items`,
    `num_layers`, and `dim_h`. The `num_users` and `num_items` arguments specify the
    number of users and items in the dataset, respectively. `num_layers` indicates
    the number of `LightGCN` layers that will be used, and the `dim_h` argument specifies
    the size of the embedding vectors (for the users and items):'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个带有四个参数的`LightGCN`类：`num_users`、`num_items`、`num_layers`和`dim_h`。`num_users`和`num_items`参数分别指定数据集中用户和项目的数量。`num_layers`表示将使用的`LightGCN`层的数量，而`dim_h`参数指定嵌入向量的大小（适用于用户和项目）：
- en: '[PRE22]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'We store the number of users and items and create user and item embedding layers.
    The shape of the `emb_users` or ![](img/Formula_B19153_17_014.png) is ![](img/Formula_B19153_17_015.png)
    and the shape of the `emb_items` or ![](img/Formula_B19153_17_016.png) is ![](img/Formula_B19153_17_017.png):'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们存储用户和项目的数量，并创建用户和项目的嵌入层。`emb_users`或![](img/Formula_B19153_17_014.png)的形状是![](img/Formula_B19153_17_015.png)，而`emb_items`或![](img/Formula_B19153_17_016.png)的形状是![](img/Formula_B19153_17_017.png)：
- en: '[PRE23]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We create a list of `num_layers` (previously called ![](img/Formula_B19153_17_018.png))
    `LightGCN` layers using PyTorch Geometric’s `LGConv()`. This will be used to perform
    the light graph convolution operations:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用PyTorch Geometric的`LGConv()`创建一个包含`num_layers`（之前称为![](img/Formula_B19153_17_018.png)）个`LightGCN`层的列表。这将用于执行轻量图卷积操作：
- en: '[PRE24]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We initialize the user and item embedding layers with normal distributions
    with a standard deviation of `0.01`. This helps to prevent the model from getting
    stuck in poor local optima when it is trained:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过标准差为`0.01`的正态分布初始化用户和项目嵌入层。这有助于防止模型在训练时陷入较差的局部最优解：
- en: '[PRE25]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The `forward()` method takes in an edge index tensor and returns the final
    user and item embedding vectors, ![](img/Formula_B19153_17_019.png) and ![](img/Formula_B19153_17_020.png).
    It starts by concatenating the user and item embedding layers and storing the
    result in the `emb` tensor. It then creates a list, `embs`, with `emb` as its
    first element:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`forward()`方法接收一个边索引张量，并返回最终的用户和项目嵌入向量，![](img/Formula_B19153_17_019.png) 和
    ![](img/Formula_B19153_17_020.png)。它首先将用户和项目的嵌入层拼接在一起，并将结果存储在`emb`张量中。然后，它创建一个列表`embs`，将`emb`作为其第一个元素：'
- en: '[PRE26]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We then apply the `LightGCN` layers in a loop and store the output of each
    layer in the `embs` list:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在一个循环中应用`LightGCN`层，并将每一层的输出存储在`embs`列表中：
- en: '[PRE27]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We perform layer combination by calculating the final embedding vectors by
    taking the mean of the tensors in the `embs` list along the second dimension:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过计算`embs`列表中张量在第二维度上的均值来执行层组合，从而得到最终的嵌入向量：
- en: '[PRE28]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We split `emb_final` into user and item embedding vectors (![](img/Formula_B19153_17_021.png)
    and ![](img/Formula_B19153_17_022.png)) and return them along with ![](img/Formula_B19153_17_023.png)
    and ![](img/Formula_B19153_17_024.png):'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将`emb_final`拆分为用户和项目嵌入向量（![](img/Formula_B19153_17_021.png) 和 ![](img/Formula_B19153_17_022.png)），并与![](img/Formula_B19153_17_023.png)
    和 ![](img/Formula_B19153_17_024.png)一起返回：
- en: '[PRE29]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Finally, the model is created by calling the `LightGCN()` class with the appropriate
    arguments:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终，通过调用具有适当参数的`LightGCN()`类来创建模型：
- en: '[PRE30]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Before we can train the model, we need a loss function. The `LightGCN` architecture
    employs **Bayesian Personalized Ranking** (**BPR**) loss, which optimizes the
    model’s ability to rank positive items higher than negative items for a given
    user. It is implemented as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以训练模型之前，我们需要一个损失函数。`LightGCN`架构采用**贝叶斯个性化排序**（**BPR**）损失，该损失优化模型在给定用户的情况下，将正项排在负项之前的能力。实现如下：
- en: '![](img/Formula_B19153_17_025.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_17_025.jpg)'
- en: Here, ![](img/Formula_B19153_17_026.png) is the ![](img/Formula_B19153_17_027.png)th-layer
    embedding matrix (concatenation of the initial user and item embeddings), ![](img/Formula_B19153_17_030.png)
    weighs the regularization strength, ![](img/Formula_B19153_17_028.png) corresponds
    to the predicted rating of a positive item, and ![](img/Formula_B19153_17_029.png)
    represents the predicted rating of a negative item.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/Formula_B19153_17_026.png)是第![](img/Formula_B19153_17_027.png)层的嵌入矩阵（即初始用户和项目嵌入的连接），![](img/Formula_B19153_17_030.png)表示正则化强度，![](img/Formula_B19153_17_028.png)对应于正项的预测评分，![](img/Formula_B19153_17_029.png)代表负项的预测评分。
- en: 'We implement it in PyTorch with the following function:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用以下函数在PyTorch中实现它：
- en: 'We calculate the regularization loss based on the embeddings that are stored
    in the `LightGCN` model:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们根据存储在`LightGCN`模型中的嵌入计算正则化损失：
- en: '[PRE31]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We calculate the ratings for the positive and negative items as the dot product
    between the user and item embeddings:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们计算正项和负项的评分，即用户嵌入和项目嵌入之间的点积：
- en: '[PRE32]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Unlike the log sigmoid in the previous equation, we calculate the BPR loss
    as the mean of the `softplus` function applied to the difference between the positive
    and negative scores. This variant was chosen because it gave better experimental
    results:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与之前公式中的对数sigmoid不同，我们将BPR损失计算为应用于正负评分差异的`softplus`函数的均值。选择这个变体是因为它给出了更好的实验结果：
- en: '[PRE33]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We return the BPR loss and the regularization loss as follows:'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们返回BPR损失和正则化损失，如下所示：
- en: '[PRE34]'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'On top of the BPR loss, we use two metrics to evaluate the performance of our
    model:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 除了BPR损失外，我们使用两个指标来评估模型的表现：
- en: '**Recall@k** is the proportion of relevant recommended items in top *k* among
    all possible relevant items. However, this metric does not consider the order
    of relevant items in top *k*:'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Recall@k**是所有可能相关项中，前*k*项中相关推荐项的比例。然而，这个指标不考虑相关项在前*k*中的顺序：'
- en: '![](img/Formula_B19153_17_031.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_B19153_17_031.jpg)'
- en: '**Normalized Discounted Cumulative Gain** (**NDGC**) measures the effectiveness
    of the system’s ranking of the recommendations, taking into account the relevance
    of the items, where relevance is usually represented by a score or a binary relevance
    (relevant or not).'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**归一化折扣累积增益**（**NDGC**）衡量系统在排序推荐中的有效性，考虑到项目的相关性，其中相关性通常由分数或二进制相关性（相关或不相关）表示。'
- en: The implementation is not included in this chapter for improved readability.
    However, it can be found in the GitHub repository along with the rest of the code.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 该实现未包含在本章中，以提高可读性。然而，它可以在GitHub仓库中找到，连同其余的代码一起。
- en: 'We can now create a training loop and start training the `LightGCN` model:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以创建一个训练循环，并开始训练`LightGCN`模型：
- en: 'We define the following constants. They can be tuned as hyperparameters to
    improve the performance of the model:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们定义了以下常数。它们可以作为超参数进行调整，以提高模型性能：
- en: '[PRE35]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We try to select a GPU if one is available. Otherwise, we use a CPU instead.
    The model and data are moved to this device:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们尝试选择一个GPU，如果有的话。否则，我们使用CPU。模型和数据会被移动到这个设备上：
- en: '[PRE36]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We create an `Adam` optimizer with a learning rate of `0.001`:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个学习率为`0.001`的`Adam`优化器：
- en: '[PRE37]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let’s start the training loop. First, we calculate `num_batch`, the number
    of `BATCH_SIZE` batches in an epoch. Then, we create two loops: one of 31 epochs,
    and a second one the length of `num_batch`:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们开始训练循环。首先，我们计算`num_batch`，即每个周期中的`BATCH_SIZE`批次数。然后，我们创建两个循环：一个是31个周期，另一个是`num_batch`的长度：
- en: '[PRE38]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The model is run on the training data and returns the initial and final user
    and item embeddings:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型在训练数据上运行，并返回初始和最终的用户和项目嵌入：
- en: '[PRE39]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The training data is then sampled in mini-batches using the `sample_mini_batch()`
    function, which returns the indices of the sampled user, positive item, and negative
    item embeddings:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练数据然后通过`sample_mini_batch()`函数按小批量进行采样，该函数返回采样的用户、正项和负项嵌入的索引：
- en: '[PRE40]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The embeddings for the sampled users, positive items, and negative items are
    then retrieved:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后检索采样的用户、正项和负项的嵌入：
- en: '[PRE41]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The loss is then computed using the `bpr_loss()` function:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后使用`bpr_loss()`函数计算损失：
- en: '[PRE42]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The optimizer is then used to perform the backward pass and update the model
    parameters:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后使用优化器执行反向传播，并更新模型参数：
- en: '[PRE43]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The model’s performance is evaluated every 250 epochs on the validation set
    using the `test()` function. The evaluation metrics are printed:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型的性能每250个周期在验证集上使用`test()`函数进行评估。评估指标会被打印出来：
- en: '[PRE44]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This gives us the following output:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这给出了以下输出：
- en: '[PRE45]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We evaluate the model’s performance on the test set as follows:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如下评估模型在测试集上的表现：
- en: '[PRE46]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: We obtain a `recall@20` value of `0.01936` and an `ndcg@20` value of `0.01119`,
    which is close to the results obtained by the authors of `LightGCN` on other datasets.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得了`recall@20`值为`0.01936`和`ndcg@20`值为`0.01119`，这一结果接近`LightGCN`的作者在其他数据集上得到的结果。
- en: 'Now that the model is trained, we want to get recommendations for a given user.
    The recommendation function we want to create has two components:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已经训练完成，我们想为给定用户获取推荐。我们想要创建的推荐函数包含两个部分：
- en: First, we want to retrieve a list of books the user liked. This will help us
    to contextualize the recommendations for our own understanding.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们要获取一个用户喜欢的书籍列表。这将帮助我们为自己的理解提供推荐的背景信息。
- en: Secondly, we want to generate a list of recommendations. These recommendations
    cannot be books the user has already rated (it cannot be a positive item).
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 其次，我们要生成一个推荐书单。这些推荐不能是用户已经评分的书籍（即不能是正向项）。
- en: 'Let’s write this function step by step:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步编写这个函数：
- en: 'We create a function called `recommend` that takes in two arguments: `user_id`
    (the identifier for a user), and `num_recs` (the number of recommendations we
    want to generate):'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们创建一个名为`recommend`的函数，该函数接受两个参数：`user_id`（用户标识符）和`num_recs`（我们想要生成的推荐数量）：
- en: '[PRE47]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We create the `user` variable by looking up the user’s identifier in the `user_mapping`
    dictionary, which maps user IDs to integer indices:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过查找用户标识符在`user_mapping`字典中的位置来创建`user`变量，该字典将用户ID映射到整数索引：
- en: '[PRE48]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We retrieve the `dim_h` dim vector learned by the `LightGCN` model for this
    particular user:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们检索`LightGCN`模型为该特定用户学到的`dim_h`维向量：
- en: '[PRE49]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We can use it to calculate the corresponding ratings. As seen previously, we
    use the dot product of the embeddings for all items stored in the `LightGCN`’s
    `emb_items` attribute and the `emb_user` variable:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以用它来计算相应的评分。如前所述，我们使用`LightGCN`的`emb_items`属性中的所有项目的嵌入与`emb_user`变量的点积来计算评分：
- en: '[PRE50]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We apply the `topk()` function to the `ratings` tensor, which returns the top
    100 values (scores calculated by the model) and their corresponding indices:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将`topk()`函数应用于`ratings`张量，该函数返回前100个值（模型计算的评分）及其相应的索引：
- en: '[PRE51]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Let’s get a list of this user’s favorite books. We create a new list of indices
    by filtering the `indices` list to only include those that are present in the
    `user_items` dictionary for the given user. In other words, we only keep books
    that this user rated. This list is then sliced to keep the first `num_recs` items:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们获取该用户喜欢的书籍列表。我们通过过滤`indices`列表，只保留在给定用户的`user_items`字典中出现的书籍，创建一个新的索引列表。换句话说，我们只保留该用户评分的书籍。然后，我们对该列表进行切片，只保留前`num_recs`个条目：
- en: '[PRE52]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We convert these book IDs into ISBNs:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将这些书籍ID转换为ISBN：
- en: '[PRE53]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We can now use these ISBNs to retrieve more information about the books. Here,
    we want to obtain the titles and the authors so that we can print them:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用这些ISBN来获取书籍的更多信息。在这里，我们想获取书籍的标题和作者，以便打印出来：
- en: '[PRE54]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We print this information as follows:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如下打印这些信息：
- en: '[PRE55]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'We repeat this process, but with IDs of books that were not rated by the user
    (`not` `in user_pos_items[user]`):'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们重复这个过程，但使用用户未评分的书籍ID（`not` `in user_pos_items[user]`）：
- en: '[PRE56]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Let’s get `5` recommendations for a user in our database. Let’s use `277427`:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们为我们数据库中的一个用户获取`5`个推荐。我们使用`277427`：
- en: '[PRE57]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'This is the output we obtain:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这是我们得到的输出：
- en: '[PRE58]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: We can now generate recommendations for any user from the original `df` DataFrame.
    You can test other IDs and explore how that changes the recommendations.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以从原始`df`数据框中为任何用户生成推荐。你可以测试其他ID并查看它如何改变推荐结果。
- en: Summary
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter presented a detailed exploration of using `LightGCN` for book recommendation
    tasks. We used the `Book-Crossing` dataset, preprocessed it to form a bipartite
    graph, and implemented a `LightGCN` model with BPR loss. We trained the model
    and evaluated it using the `recall@20` and `ndcg@20` metrics. We demonstrated
    the effectiveness of the model by generating recommendations for a given user.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 本章详细探讨了如何使用`LightGCN`进行书籍推荐任务。我们使用了`Book-Crossing`数据集，对其进行了预处理，形成了一个二分图，并实现了一个带有BPR损失的`LightGCN`模型。我们训练了该模型，并使用`recall@20`和`ndcg@20`指标进行了评估。通过为给定用户生成推荐，我们展示了该模型的有效性。
- en: Overall, this chapter has provided valuable insight into the usage of `LightGCN`
    models in recommendation tasks. It is a state-of-the-art architecture that performs
    better than more complex models. You can expand this project by trying other techniques
    we discussed in previous chapters, such as matrix factorization and `node2vec`.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，本章提供了关于在推荐任务中使用 `LightGCN` 模型的宝贵见解。它是一种最先进的架构，性能优于更复杂的模型。你可以通过尝试我们在前几章讨论的其他技术来扩展这个项目，例如矩阵分解和
    `node2vec`。
- en: Further reading
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '[1] C.-N. Ziegler, S. M. McNee, J. A. Konstan, and G. Lausen, *Improving Recommendation
    Lists through Topic Diversification*, in *Proceedings of the 14th International
    Conference on World Wide Web*, 2005, pp. 22–32\. doi: 10.1145/1060745.1060754\.
    Available: [https://dl.acm.org/doi/10.1145/1060745.1060754](https://dl.acm.org/doi/10.1145/1060745.1060754)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] C.-N. Ziegler, S. M. McNee, J. A. Konstan, 和 G. Lausen, *通过主题多样化改进推荐列表*,
    载于 *第十四届国际万维网会议论文集*, 2005, 页码 22–32\. doi: 10.1145/1060745.1060754\. 可获取: [https://dl.acm.org/doi/10.1145/1060745.1060754](https://dl.acm.org/doi/10.1145/1060745.1060754)'
- en: '[2] D. Li, P. Maldonado, A. Sbaih, *Recommender Systems with GNNs in PyG*,
    *Stanford CS224W GraphML Tutorials*, 2022\. Available: [https://medium.com/stanford-cs224w/recommender-systems-with-gnns-in-pyg-d8301178e377](https://medium.com/stanford-cs224w/recommender-systems-with-gnns-in-pyg-d8301178e377)'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] D. Li, P. Maldonado, A. Sbaih, *使用 GNN 的推荐系统在 PyG 中的实现*, *斯坦福 CS224W 图形机器学习教程*,
    2022\. 可获取: [https://medium.com/stanford-cs224w/recommender-systems-with-gnns-in-pyg-d8301178e377](https://medium.com/stanford-cs224w/recommender-systems-with-gnns-in-pyg-d8301178e377)'
- en: '[3] X. He, K. Deng, X. Wang, Y. Li, Y. Zhang, and M. Wang, *LightGCN: Simplifying
    and Powering Graph Convolution Network for Recommendation*. arXiv, 2020\. doi:
    10.48550/ARXIV.2002.02126\. Available: [https://arxiv.org/abs/2002.02126](https://arxiv.org/abs/2002.02126)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] X. He, K. Deng, X. Wang, Y. Li, Y. Zhang, 和 M. Wang, *LightGCN: 简化并增强图卷积网络用于推荐系统的能力*.
    arXiv, 2020\. doi: 10.48550/ARXIV.2002.02126\. 可获取: [https://arxiv.org/abs/2002.02126](https://arxiv.org/abs/2002.02126)'
- en: '[4] H. Hotta and A. Zhou, *LightGCN with PyTorch Geometric*. *Stanford CS224W
    GraphML Tutorials*, 2022\. Available: [https://medium.com/stanford-cs224w/lightgcn-with-pytorch-geometric-91bab836471e](https://medium.com/stanford-cs224w/lightgcn-with-pytorch-geometric-91bab836471e)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] H. Hotta 和 A. Zhou, *使用 PyTorch Geometric 实现 LightGCN*. *斯坦福 CS224W 图形机器学习教程*,
    2022\. 可获取: [https://medium.com/stanford-cs224w/lightgcn-with-pytorch-geometric-91bab836471e](https://medium.com/stanford-cs224w/lightgcn-with-pytorch-geometric-91bab836471e)'
