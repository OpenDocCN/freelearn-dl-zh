- en: '*Chapter 9*: Working with Multimodal and Multitasking Data'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第9章*：处理多模态和多任务数据'
- en: In this chapter, we will learn how to use the AutoModel API to handle multimodal
    and multitasking data.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何使用AutoModel API来处理多模态和多任务数据。
- en: By the end of this chapter, you will have learned how to use the concepts and
    tools necessary to create models with multiple inputs and multiple outputs. You
    will be able to apply these concepts to your own projects by creating a model
    from scratch or by adapting the practical example shown in this chapter to other,
    similar datasets.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将学会如何使用创建具有多个输入和多个输出的模型所需的概念和工具。你将能够通过从头开始创建模型或将本章展示的实际示例适应其他相似数据集，将这些概念应用到自己的项目中。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Exploring models with multiple input or outputs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索具有多个输入或输出的模型
- en: Creating a multitasking/multimodal model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个多任务/多模态模型
- en: Customizing the search space
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义搜索空间
- en: But first, let's explain the technical requirements for this chapter.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，让我们解释一下本章的技术要求。
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: All the code examples in this book are available as Jupyter notebooks that can
    be downloaded from [https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的所有代码示例都可以作为Jupyter笔记本下载，下载地址是[https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras)。
- en: Since code cells can be executed, each notebook can be self-installed; simply
    add the code snippet that contains the requirements you need. For this reason,
    at the beginning of each notebook, there is a code cell for environment setup
    that installs AutoKeras and its dependencies.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 由于代码单元可以执行，因此每个笔记本都可以自我安装；只需添加包含所需依赖项的代码片段。因此，在每个笔记本的开头，都有一个用于环境设置的代码单元，用来安装AutoKeras及其依赖项。
- en: 'So, to run the code examples in this chapter, you only need a computer with
    Ubuntu Linux as its OS and must install the Jupyter Notebook with the following
    line of code:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了运行本章中的代码示例，你只需要一台运行Ubuntu Linux操作系统的计算机，并且必须通过以下代码行安装Jupyter Notebook：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Alternatively, you can also run these notebooks using Google Colaboratory, in
    which case you will only need a web browser. See [*Chapter 2*](B16953_02_Final_PG_ePub.xhtml#_idTextAnchor029),
    *AutoKeras with Google Colaboratory*, for more details. Furthermore, in the *Installing
    AutoKeras* section of that chapter, you will find other installation options.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，你也可以使用Google Colaboratory运行这些笔记本，在这种情况下，你只需要一个网页浏览器。有关详细信息，请参见[*第2章*](B16953_02_Final_PG_ePub.xhtml#_idTextAnchor029)，*AutoKeras与Google
    Colaboratory*。此外，在该章节的*安装AutoKeras*部分，你将找到其他安装选项。
- en: Now, let's put these concepts we mentioned in the introduction into practice
    by looking at a practical example.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过一个实际示例来实践在介绍中提到的这些概念。
- en: Exploring models with multiple inputs or outputs
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索具有多个输入或输出的模型
- en: As we will see later, sometimes, it may interest us that our model feeds on
    information from different sources (multimodal) and/or predicts multiple targets
    at the same time (multitask). AutoKeras has a class called **AutoModel** that
    allows us to define several sources and targets as a list of parameters. Let's
    dive a little deeper into this before looking at a practical example.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们稍后将看到的，有时我们可能希望我们的模型同时获取来自不同来源的信息（多模态）和/或同时预测多个目标（多任务）。AutoKeras有一个叫做**AutoModel**的类，允许我们将多个来源和目标定义为一组参数列表。在看实际示例之前，让我们稍微深入了解一下这个内容。
- en: What is AutoModel?
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是AutoModel？
- en: AutoModel is a class that allows us to define a model in a granular way by defining
    not only its inputs and outputs but also its intermediate layers.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: AutoModel是一个类，允许我们通过定义不仅是输入和输出，还包括其内部层来精细地定义模型。
- en: 'It can be used in two different ways:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以通过两种不同的方式使用：
- en: '**Basic**: Here, the input/output nodes are specified and AutoModel infers
    the remaining part of the model.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基本**：在这里，输入/输出节点被指定，AutoModel推断模型的其余部分。'
- en: '**Advanced**: Here, the high-level architecture is defined by connecting the
    layers (blocks) with the Functional API, which is the same as the Keras functional
    API.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高级**：在这里，高级架构通过使用功能API连接各层（模块）来定义，这与Keras的功能API相同。'
- en: Let's look at an example of each one.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下每个示例。
- en: Basic example
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本示例
- en: 'The user only specifies the input nodes and output heads:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 用户只需指定输入节点和输出头：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Next, let's look at an advanced example.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看一个高级示例。
- en: Advanced example
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高级示例
- en: 'The user specifies the high-level architecture:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 用户指定高级架构：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the preceding code, we configured AutoModel to create a model with multiple
    inputs (multimodal) and several outputs (multitask). Next, we will explain these
    concepts and see them in action by creating our own multimodel.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们配置了 AutoModel 以创建一个具有多个输入（多模态）和多个输出（多任务）的模型。接下来，我们将解释这些概念，并通过创建自己的多模态模型来实际应用它们。
- en: What is multimodal?
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是多模态？
- en: We say that data is multimodal when each data instance contains multiple forms
    of information. For example, we can save a photo as an image, but in addition
    to that image, it also contains *meta* information about where it was taken. This
    meta information can be treated as structured data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们称数据为多模态数据，当每个数据实例包含多种信息形式时。例如，我们可以将一张照片保存为图像，但除了这张图像，它还包含关于拍摄地点的*元*信息。这些元信息可以视为结构化数据。
- en: What is multitask?
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是多任务？
- en: We say that a model is multitask when it predicts multiple targets with the
    same input features. For example, let's say we want to classify photos of people
    by ethnic groups, but at the same time, we want to specify their age as a number
    between 0 and 100.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们称一个模型为多任务模型，当它使用相同的输入特征预测多个目标时。例如，假设我们想按族群分类人物照片，同时还希望指定其年龄，年龄范围为 0 到 100。
- en: 'The following diagram shows an example of a multimodal and multitask neural
    network model:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了一个多模态和多任务神经网络模型的示例：
- en: '![Figure 9.1 – Example of a multimodal and multitask neural network model'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.1 – 多模态和多任务神经网络模型示例'
- en: '](img/B16953_09_01.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16953_09_01.jpg)'
- en: Figure 9.1 – Example of a multimodal and multitask neural network model
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 – 多模态和多任务神经网络模型示例
- en: 'Here, we can see that there are two entries: **images** (**ImageInput**) and
    **structured data** (**StructuredDataInput**). Each image is associated with a
    set of attributes in the structured data. From this data, we can try to predict
    the **classification label** (**ClassificationHead**) and the **regression value**
    (**RegressionHead**) at the same time.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到有两个条目：**图像**（**ImageInput**）和**结构化数据**（**StructuredDataInput**）。每个图像都与结构化数据中的一组属性相关联。通过这些数据，我们可以尝试同时预测**分类标签**（**ClassificationHead**）和**回归值**（**RegressionHead**）。
- en: Let's look at these concepts in more detail by looking at a practical example.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过实际示例更详细地了解这些概念。
- en: Creating a multitask/multimodal model
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个多任务/多模态模型
- en: Based on the example provided at the beginning of this chapter, the model that
    we are going to create will take an image and its structured data attributes as
    input and will predict a category value and a scalar value. In this case, instead
    of using a dataset, we will generate our own data. The notebook we will be using
    that contains the complete source code can be found at [https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter09/Chapter9_MultiModel.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter09/Chapter9_MultiModel.ipynb).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 基于本章开头提供的示例，我们将创建一个模型，该模型将图像及其结构化数据属性作为输入，并预测一个类别值和一个标量值。在这种情况下，我们将不使用现有数据集，而是生成我们自己的数据。我们将使用的笔记本，包含完整的源代码，可以在
    [https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter09/Chapter9_MultiModel.ipynb](https://github.com/PacktPublishing/Automated-Machine-Learning-with-AutoKeras/blob/main/Chapter09/Chapter9_MultiModel.ipynb)
    上找到。
- en: 'Now, let''s have a look at the relevant cells of the notebook in detail:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们详细查看笔记本中的相关单元格：
- en: '**Installing AutoKeras**: As we''ve mentioned in the previous chapters, this
    snippet at the top of the notebook is responsible for installing AutoKeras and
    its dependencies using the pip package manager:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安装 AutoKeras**：正如我们在前几章中提到的，笔记本顶部的这段代码负责使用 pip 包管理器安装 AutoKeras 及其依赖项：'
- en: '[PRE3]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`numpy`, and `AutoKeras` as the necessary dependencies for this project:'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy` 和 `AutoKeras` 是该项目所需的依赖项：'
- en: '[PRE4]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Creating the datasets**: First, we are going to create the datasets by generating
    a random image and structured data as multimodal data:'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**创建数据集**：首先，我们将通过生成随机图像和结构化数据作为多模态数据来创建数据集：'
- en: '[PRE5]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, generate some multitask targets for classification and regression:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，生成一些用于分类和回归的多任务目标：
- en: '[PRE6]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now, it's time to create the model.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候创建模型了。
- en: Creating the model
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建模型
- en: Now, we will create the model using `AutoModel`, first in its basic configuration
    and then in its advanced one. As in the previous examples, we will set a small
    amount of `max_trials` and `epochs` so that the training process doesn't take
    too long.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用`AutoModel`创建模型，首先是基本配置，然后是高级配置。与之前的示例一样，我们将设置较小的`max_trials`和`epochs`，以避免训练过程花费太长时间。
- en: 'First, we will initialize the model with multiple inputs and outputs:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用多个输入和输出初始化模型：
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In the previous code, we have defined two inputs (image and structured data)
    and two outputs (regression and classification). Here, we are telling the model
    that we want to train our input data with a regressor and a classifier at the
    same time.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码中，我们定义了两个输入（图像和结构化数据）和两个输出（回归和分类）。在这里，我们告诉模型，我们希望同时使用回归器和分类器来训练输入数据。
- en: 'Now, let''s run the training process to search for the optimal model for the
    training dataset:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们运行训练过程，以搜索适合训练数据集的最佳模型：
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here''s the output:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '![Figure 9.2 – Notebook output of model training'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.2 – 模型训练的笔记本输出'
- en: '](img/B16953_09_02.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16953_09_02.jpg)'
- en: Figure 9.2 – Notebook output of model training
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 – 模型训练的笔记本输出
- en: Unlike the previous examples, here, we can see that the output shows two losses
    – one for the regressor and one for the classifier. In this case, the data is
    generated randomly, so there is no point in looking at performance for evaluation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的示例不同，在这里，我们可以看到输出显示了两个损失值——一个用于回归器，另一个用于分类器。在这种情况下，数据是随机生成的，因此没有必要关注性能评估。
- en: Visualizing the model
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可视化模型
- en: 'Now, let''s look at a little summary of the architecture for the best generated
    model:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看最佳生成模型的架构摘要：
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Here is the output:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '![Figure 9.3 – Best model architecture summary'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.3 – 最佳模型架构总结'
- en: '](img/B16953_09_03.jpg)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16953_09_03.jpg)'
- en: Figure 9.3 – Best model architecture summary
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 – 最佳模型架构总结
- en: Let's briefly describe the blocks that were used for this model.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要描述一下用于该模型的各个模块。
- en: In this case, AutoKeras creates two submodels – one for each piece of input
    data. It has chosen a deep residual network architecture (**resnet50**), which
    we already presented in [*Chapter 4*](B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063),
    *Image Classification and Regression using AutoKeras*, to process the image data
    and a couple of fully connected layers to ingest the structured data. After digesting
    the two data sources, the results of both submodels are concatenated and separated
    again to generate the two different outputs (a scalar value and a category value).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，AutoKeras创建了两个子模型——每个输入数据对应一个子模型。它选择了一个深度残差网络架构（**resnet50**），该架构我们已经在[*第4章*](B16953_04_Final_PG_ePub.xhtml#_idTextAnchor063)中介绍过，*使用AutoKeras进行图像分类和回归*，用于处理图像数据，以及几个全连接层用于处理结构化数据。在消化了这两种数据源之后，两个子模型的结果被连接起来，再分开生成两个不同的输出（一个标量值和一个分类值）。
- en: 'Here is a visual representation of this:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是该过程的可视化表示：
- en: '![Figure 9.4 – Best model architecture visualization](img/B16953_09_04.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.4 – 最佳模型架构可视化](img/B16953_09_04.jpg)'
- en: Figure 9.4 – Best model architecture visualization
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.4 – 最佳模型架构可视化
- en: Now, let's use AutoModel in a more advanced mode to customize the intermediate
    blocks.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在更高级的模式下使用AutoModel，定制中间模块。
- en: Customizing the search space
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定制搜索空间
- en: As we mentioned at the beginning of this chapter, there is an advanced way to
    use AutoModel. We can do this by defining the whole model architecture by connecting
    the layers (blocks) with the functional API, which is the same as the Keras functional
    API.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在本章开头提到的，使用AutoModel有一种高级方式。我们可以通过使用功能性API来定义整个模型架构，将层（模块）连接起来，这与Keras的功能性API相同。
- en: 'Let''s do this in the following example:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在以下示例中进行操作：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here, we have defined each block sequentially by connecting the output of one
    to the input of the next. In this case, we've customized the model by adding some
    image preprocessing blocks for normalization and augmentation. We've also placed
    a convolutional layer in parallel to the ResNet layer to train the image data,
    which has also been customized. You can even specify the version of the ResNet
    architecture you want to use.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们通过将一个模块的输出连接到下一个模块的输入，按顺序定义了每个模块。在这种情况下，我们通过添加一些图像预处理模块来进行定制，目的是进行归一化和数据增强。我们还将一个卷积层与ResNet层并行放置，以训练图像数据，该层也已进行定制。你甚至可以指定要使用的ResNet架构版本。
- en: Although this mode is more complex, it is much more powerful and flexible. Note
    that you can even specify the version of the ResNet architecture that you want
    to use (v2). It is important to note that for parameters (such as version) that
    haven't been customized, AutoKeras will try different combinations of values to
    find the most optimal one.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这种模式更复杂，但它更强大且更灵活。请注意，你甚至可以指定想要使用的ResNet架构版本（v2）。需要注意的是，对于那些未自定义的参数（如版本），AutoKeras会尝试不同的值组合，以找到最优解。
- en: Summary
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned what a multitasking model is, what a multimodal
    model is, and how to use the powerful AutoModel class to create efficient models
    with multiple inputs and outputs. You are now ready to apply these concepts to
    your own multimodel projects by creating them from scratch or by adapting this
    practical example for your own datasets.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了什么是多任务模型，什么是多模态模型，以及如何使用强大的AutoModel类创建具有多个输入和输出的高效模型。现在，你已经准备好将这些概念应用到自己的多模态项目中，可以从头开始创建，或者通过调整这个实用示例来适应你自己的数据集。
- en: In the next chapter, we will learn how to export our models and how to use a
    powerful visualization tool to track and visualize metrics such as loss and accuracy
    in real-time graphs.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何导出我们的模型，以及如何使用一个强大的可视化工具来实时跟踪和可视化诸如损失和准确率等指标的图形。
