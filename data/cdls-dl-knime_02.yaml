- en: '*Chapter 1:* Introduction to Deep Learning with KNIME Analytics Platform'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 1 章:* 使用 KNIME Analytics Platform 入门深度学习'
- en: We'll start our journey of exploring **Deep Learning** (**DL**) paradigms by
    looking at KNIME Analytics Platform. If you have always been drawn to neural networks
    and deep learning architectures and have always thought that the coding part would
    be an obstacle to you developing a quick learning curve, then this is the book
    for you.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过探索 KNIME Analytics Platform 来开始我们的**深度学习**（**DL**）范式之旅。如果你一直对神经网络和深度学习架构感兴趣，并且总觉得编码部分会成为你快速学习曲线的障碍，那么这本书就是为你而写的。
- en: Deep learning can be quite complex, and we must make sure that the journey is
    worth the result. Thus, we'll start this chapter by stating, once again, the relevance
    of deep learning techniques when it comes to successfully implementing applications
    for data science.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习可能相当复杂，我们必须确保这一旅程值得获得的结果。因此，我们将再次从阐述深度学习技术在成功实施数据科学应用中的重要性开始本章内容。
- en: We will continue by providing a quick overview of the tool of choice for this
    book – KNIME Software – and focus on how it complements both KNIME Analytics Platform
    and KNIME Server.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将简要介绍本书所选工具——KNIME 软件，并重点讲解它如何与 KNIME Analytics Platform 和 KNIME Server
    相辅相成。
- en: The work we'll be doing throughout this book will be implemented in KNIME Analytics
    Platform, which is open source and available for free. We will dedicate a full
    section to how to download, install, and use KNIME Analytics Platform, even though
    more details will be provided in the chapters to follow.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中所做的工作将通过 KNIME Analytics Platform 实现，该平台是开源的，且可以免费使用。我们将专门有一部分介绍如何下载、安装和使用
    KNIME Analytics Platform，尽管在接下来的章节中会提供更多细节。
- en: Among the benefits of KNIME Analytics Platform is, of course, its codeless Deep
    Learning - Keras Integration extension, which we will be making extensive use
    of throughout this book. In this chapter, we will just focus on the basic concepts
    and requirements for this KNIME extension.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME Analytics Platform 的一个优势，当然是它无代码的深度学习 - Keras 集成扩展，我们将在本书中广泛使用该扩展。在本章中，我们将专注于该
    KNIME 扩展的基本概念和要求。
- en: Finally, we will conclude this chapter by stating the goal and structure of
    this book. We wanted to give it a practical flavor, so most of the chapters will
    revolve around a practical case study that includes real-world data. In each chapter,
    we will take the chance to dig deeper into the required neural architecture, data
    preparation, deployment, and other aspects necessary to make the case study at
    hand a success.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将通过阐明本书的目标和结构来结束本章。我们希望让本书更具实践性，因此大多数章节将围绕一个包括真实数据的实际案例研究展开。在每一章中，我们将有机会深入探讨所需的神经网络架构、数据准备、部署及其他使案例研究成功的要素。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涉及以下主题：
- en: The Importance of Deep Learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习的重要性
- en: Exploring KNIME Software
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索 KNIME 软件
- en: Exploring KNIME Analytics Platform
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索 KNIME Analytics Platform
- en: Installing KNIME Deep Learning – Keras Integration
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 KNIME 深度学习 - Keras 集成
- en: Goals and Structure of this Book
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本书的目标与结构
- en: We'll start by stating the importance of deep learning when it comes to successful
    data science applications.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从阐述深度学习在成功的数据科学应用中的重要性开始。
- en: The Importance of Deep Learning
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习的重要性
- en: If you have been working in the field of **data science** – or **Artificial
    Intelligence** (**AI**), as it is called nowadays – for a few years, you might
    have noticed the recent sudden explosion of scholarly and practitioner articles
    about successful solutions based on deep learning techniques.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在**数据科学**——或者如今所说的**人工智能**（**AI**）——领域工作了几年，你可能注意到最近关于基于深度学习技术的成功解决方案的学术与实践文章激增。
- en: The big breakthrough happened in 2012 when the deep learning-based AlexNet network
    won the ImageNet challenge by an unprecedented margin. This victory kicked off
    a surge in the usage of deep learning networks. Since then, these have expanded
    to many different domains and tasks.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 重大突破发生在 2012 年，当时基于深度学习的 AlexNet 网络以空前的优势赢得了 ImageNet 挑战赛。这一胜利引发了深度学习网络应用的激增。自那时以来，深度学习已扩展到许多不同的领域和任务。
- en: So, what are we referring to exactly when we talk about deep learning? Deep
    learning covers a subset of **Machine Learning** (**ML**) algorithms, most of
    which stem from neural networks. Deep learning is indeed the modern evolution
    of traditional neural networks. Apart from the classic feedforward, fully connected,
    backpropagation-trained, and multilayer perceptron architectures, *deeper* architectures
    have been added. Deeper indicates more hidden layers and a few new additional
    neural paradigms, including **Recurrent Neural Networks** (**RNNs**), **Long-Short
    Term Memory** (**LSTM**), **Convolutional Neural Networks** (**CNNs**), **Generative
    Adversarial Networks** (**GANs**), and more.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，当我们谈论深度学习时，究竟指的是什么呢？深度学习涵盖了一部分**机器学习**（**ML**）算法，其中大多数来源于神经网络。深度学习确实是传统神经网络的现代演进。除了经典的前馈、全连接、反向传播训练和多层感知机架构之外，还增加了*更深*的架构。更深意味着更多的隐藏层以及一些新的神经网络范式，包括**递归神经网络**（**RNNs**）、**长短期记忆网络**（**LSTM**）、**卷积神经网络**（**CNNs**）、**生成对抗网络**（**GANs**）等。
- en: The recent success of these new types of neural networks is due to several reasons.
    First, the increased computational power in modern machines has favored the introduction
    and development of new paradigms and more complex neural architectures. Training
    a complex neural network in minutes leaves space for more experimentation compared
    to training the same network for hours or days. Another reason is due to their
    flexibility. Neural networks are universal function approximators, which means
    that they can approximate almost anything, provided that their architecture is
    sufficiently complex.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些新型神经网络最近的成功有多个原因。首先，现代机器计算能力的提升有利于新范式和更复杂神经架构的引入与发展。在几分钟内训练一个复杂的神经网络，相较于将相同网络训练数小时或数天，留下了更多的实验空间。另一个原因是它们的灵活性。神经网络是通用的函数逼近器，这意味着只要它们的架构足够复杂，它们几乎可以逼近任何事物。
- en: Having mathematical knowledge of these algorithms, experience with the most
    effective paradigms and architectures, and domain wisdom are all basic, important,
    and necessary ingredients for the success of any data science project. However,
    there are other, more contingent factors – such as ease of learning, speed of
    prototyping, options for debugging and testing to ensure the correctness of the
    solution, flexibility to experiment, availability of help from external experts,
    and automation and security capabilities – that also influence the final result
    of the project.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对这些算法的数学知识、对最有效的范式和架构的经验以及领域智慧，都是任何数据科学项目成功的基本、重要且必要的要素。然而，还有其他更多的偶然因素——例如学习的易用性、原型设计的速度、调试和测试选项以确保解决方案的正确性、实验的灵活性、外部专家帮助的可用性，以及自动化和安全功能——这些也会影响项目的最终结果。
- en: In this book, we'll present deep learning solutions that can be implemented
    with the open source, visual programming-based, free-to-use tool known as KNIME
    Analytics Platform. The deployment phases for some of these solutions also use
    a few features provided by KNIME Server.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将展示可以通过开源、基于可视化编程、免费使用的工具 KNIME Analytics Platform 实现的深度学习解决方案。这些解决方案的某些部署阶段也使用了
    KNIME Server 提供的一些功能。
- en: Next, we will learn about how KNIME Analytics Platform and KNIME Server complement
    each other, as well as which tasks both should be used for.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将了解 KNIME Analytics Platform 和 KNIME Server 如何相互补充，以及它们各自适用于哪些任务。
- en: Exploring KNIME Software
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索 KNIME 软件
- en: 'We will mainly be working with two KNIME products: KNIME Analytics Platform
    and KNIME Server. KNIME Analytics Platform includes ML and deep learning algorithms
    and data operations needed for data science projects. KNIME Server, on the other
    hand, provides the IT infrastructure for easy and secure deployment, as well as
    model monitoring over time.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将主要使用两款 KNIME 产品：KNIME Analytics Platform 和 KNIME Server。KNIME Analytics Platform
    包含数据科学项目所需的 ML 和深度学习算法及数据操作。另一方面，KNIME Server 提供了 IT 基础设施，便于安全部署以及随时间对模型进行监控。
- en: We'll concentrate on KNIME Analytics Platform first and provide an overview
    of what it can accomplish.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先集中介绍 KNIME Analytics Platform，并概述它能完成的工作。
- en: KNIME Analytics Platform
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KNIME Analytics Platform
- en: '**KNIME Analytics Platform** is an open source piece of software for all your
    data needs. It is free to download from the KNIME website ([https://www.knime.com/downloads](https://www.knime.com/downloads))
    and free to use. It covers all the main data wrangling and machine learning techniques
    available at the time of writing, and it is based on visual programming.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**KNIME分析平台**是一款满足所有数据需求的开源软件。它可以从KNIME官网（[https://www.knime.com/downloads](https://www.knime.com/downloads)）免费下载并使用。它涵盖了撰写时所有主要的数据清洗和机器学习技术，并且基于可视化编程。'
- en: '**Visual programming** is a key feature of KNIME Analytics Platform for quick
    prototyping. It makes the tool very easy to use. In visual programming, a **Graphical
    User Interface** (**GUI**) guides you through all the necessary steps for building
    a pipeline (workflow) of dedicated blocks (nodes). Each node implements a given
    task; each workflow of nodes takes your data from the beginning to the end of
    the designed journey. A workflow substitutes a script; a node substitutes one
    or more script lines.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**可视化编程**是KNIME分析平台的一个关键特性，用于快速原型开发。它使得该工具非常易于使用。在可视化编程中，**图形用户界面**（**GUI**）引导您完成构建专用模块（节点）流水线（工作流）的所有必要步骤。每个节点执行一个特定任务；每个节点的工作流将数据从起点处理到设计的终点。一个工作流替代了脚本，一个节点替代了一行或多行脚本。'
- en: Without extensive coverage when it comes to commonly used data wrangling techniques,
    machine learning algorithms, and data types and formats, and without integration
    with most common database software, data sources, reporting tools, external scripts,
    and programming languages, the software's ease of use would be limited. For this
    reason, KNIME Analytics Platform has been designed to be open to different data
    formats, data types, data sources, and data platforms, as well as external tools
    such as Python and R.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有广泛涵盖常用的数据清洗技术、机器学习算法、数据类型和格式，也没有与大多数常见的数据库软件、数据源、报告工具、外部脚本和编程语言的集成，软件的易用性将受到限制。因此，KNIME分析平台被设计成支持不同数据格式、数据类型、数据源和数据平台的开放性，并且可以与Python和R等外部工具集成。
- en: 'We''ll start by looking at a few ML algorithms. KNIME Analytics Platform covers
    most machine learning algorithms: from decision trees to random forest and gradient
    boosted trees, from recommendation engines to a number of clustering techniques,
    from Naïve Bayes to linear and logistic regression, from neural networks to deep
    learning. Most of these algorithms are native to KNIME Analytics Platform, though
    some can be integrated from other open source tools such as Python and R.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一些机器学习算法开始。KNIME分析平台涵盖了大多数机器学习算法：从决策树到随机森林和梯度提升树，从推荐引擎到多种聚类技术，从朴素贝叶斯到线性回归和逻辑回归，从神经网络到深度学习。大多数算法原生支持KNIME分析平台，虽然一些算法可以通过集成其他开源工具（如Python和R）来使用。
- en: To train different deep learning architectures, such as RNNs, autoencoders,
    and CNNs, KNIME Analytics Platform has integrated the **Keras** deep learning
    library through the **KNIME Deep Learning - Keras Integration** extension ([https://www.knime.com/deeplearning/keras](https://www.knime.com/deeplearning/keras)).
    Through this extension, it is possible to drag and drop nodes to define complex
    neural architectures and train the final network without necessarily writing any
    code.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练不同的深度学习架构，例如RNN、自动编码器和CNN，KNIME分析平台通过**KNIME深度学习 - Keras集成**扩展集成了**Keras**深度学习库（[https://www.knime.com/deeplearning/keras](https://www.knime.com/deeplearning/keras)）。通过这个扩展，您可以拖放节点来定义复杂的神经网络架构，并训练最终的网络，而无需编写任何代码。
- en: However, defining the network is just one of the many steps that must be taken.
    Ensuring the data is in the right form to train the network is another crucial
    step. For this, a very large number of nodes are available so that we can implement
    a myriad of **Data Wrangling** techniques. By combining nodes dedicated to small
    tasks, you can implement very complex data transformation operations.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，定义网络只是必须采取的众多步骤之一。确保数据以正确的形式用于训练网络是另一个至关重要的步骤。为此，提供了大量的节点，以便我们可以实现各种**数据清洗**技术。通过结合专注于小任务的节点，您可以实现非常复杂的数据转换操作。
- en: 'KNIME Analytics Platform also connects to most of the required data sources:
    from databases to cloud repositories, from big data platforms to files.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME分析平台还连接到大多数所需的数据源：从数据库到云存储库，从大数据平台到文件。
- en: But what if all of this is not enough? What if you need a specific procedure
    for a specific domain? What if you need a specific network manipulation function
    from Python? Where KNIME Analytics Platform and its extensions cannot reach, you
    can integrate with other scripting and programming languages, such as **Python**,
    **R**, **Java**, and **Javascript**, just to mention a few. In addition, KNIME
    Analytics Platform has seamless integration with BIRT, a business intelligence
    and reporting tool. Integrations with other reporting platforms such as Tableau,
    QlickView, PowerBI, and Spotfire are also available.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 但是如果这些还不够呢？如果你需要一个针对特定领域的具体过程呢？如果你需要从 Python 中获取一个特定的网络操作功能呢？当 KNIME Analytics
    Platform 及其扩展无法满足需求时，你可以与其他脚本语言和编程语言进行集成，例如 **Python**、**R**、**Java** 和 **Javascript**，仅举几个例子。此外，KNIME
    Analytics Platform 与 BIRT（一款商业智能和报表工具）具有无缝集成。还可以与其他报表平台如 Tableau、QlickView、PowerBI
    和 Spotfire 进行集成。
- en: 'Several JavaScript-based nodes are dedicated to implementing data visualization
    plots and charts: from a simple scatter plot to a more complex sunburst chart,
    from a simple histogram to a parallel coordinate plot, and more. These nodes seem
    simple but are potentially quite powerful. If you combine them within a **component**,
    you can interactively select data points across multiple charts. By doing this,
    the component inherits and combines all the views from the contained nodes and
    connects them in a way that, if the points are selected and visualized in one
    chart, they can also be selected and visualized in the other charts of the component''s
    composite view.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 几个基于 JavaScript 的节点专门用于实现数据可视化的图表和图形：从简单的散点图到更复杂的旭日图，从简单的直方图到并行坐标图，等等。这些节点看似简单，但可能非常强大。如果你将它们组合在一个
    **组件** 中，你可以跨多个图表交互选择数据点。通过这种方式，组件继承并结合了包含节点中的所有视图，并以一种方式将它们连接起来，使得如果在一个图表中选择并可视化数据点，它们也可以在组件的复合视图中的其他图表中选择并可视化。
- en: '*Figure 1.1* shows an example of a composite view:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.1* 显示了一个复合视图的示例：'
- en: '![Figure 1.1 – Composite view of a component containing a scatter plot, a bar
    chart, and a parallel coordinate plot](img/B16391_01_001.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.1 – 包含散点图、条形图和并行坐标图的组件复合视图](img/B16391_01_001.jpg)'
- en: Figure 1.1 – Composite view of a component containing a scatter plot, a bar
    chart, and a parallel coordinate plot
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1 – 包含散点图、条形图和并行坐标图的组件复合视图
- en: '*Figure 1.1* shows the composite view of a component containing a scatter plot,
    a bar chart, and a parallel coordinate plot. The three plots visualize the same
    data and are connected in a way that, by selecting data in the bar chart, it selects
    and optionally visualizes the data that''s been selected in the other two charts.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.1* 显示了一个复合视图，包含散点图、条形图和并行坐标图。三个图表可视化相同的数据，并以一种方式连接，使得通过在条形图中选择数据，可以选择并在其他两个图表中可视化所选数据。'
- en: When it comes to creating a data science solution, KNIME Analytics Platform
    provides everything you need. However, KNIME Server offers a few additional features
    to ease your job when it comes to moving the solution to production.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建数据科学解决方案时，KNIME Analytics Platform 提供了你所需的一切。然而，KNIME Server 提供了一些额外功能，以帮助你将解决方案投入生产环境。
- en: KNIME Server for the Enterprise
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KNIME 企业版服务器
- en: The last step in any data science cycle is to deploy the solution to production
    – and in the case of an enterprise, providing an easy, comfortable, and secure
    deployment.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学周期中的最后一步是将解决方案部署到生产环境中——对于企业来说，这意味着提供一个轻松、舒适且安全的部署方式。
- en: This process of moving the application into the real world is called *moving
    into production*. The process of including the trained model in this final application
    is called **deployment**. Both phases are deeply connected and can be quite problematic
    since all the errors that occurred in the application design show up at this stage.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 将应用程序推向现实世界的过程称为 *投入生产*。将训练好的模型包含在最终应用程序中的过程称为 **部署**。这两个阶段紧密相关，并且可能会出现问题，因为在应用程序设计过程中出现的所有错误都将在这一阶段显现出来。
- en: It is possible, though limited, to move an application into production using
    KNIME Analytics Platform. If you, as a lone data scientist or a data science student,
    do not regularly deploy applications and models, KNIME Analytics Platform is probably
    enough for your needs. However, if you are just a bit more involved in an enterprise
    environment, where scheduling, versioning, access rights, disaster recovery, web
    applications and REST services, and all the other typical functions of a production
    server are needed, then just using KNIME Analytics Platform for production can
    be cumbersome.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有限，但使用KNIME Analytics Platform将应用程序投入生产是可能的。如果你是一个独立的数据科学家或数据科学学生，通常不需要定期部署应用程序和模型，那么KNIME
    Analytics Platform可能足够满足你的需求。然而，如果你在企业环境中工作，涉及调度、版本控制、访问权限、灾难恢复、Web应用和REST服务等典型的生产服务器功能，那么仅使用KNIME
    Analytics Platform进行生产可能会显得繁琐。
- en: In this case, **KNIME Server**, which comes with an annual license fee, can
    make your life easier. First of all, it is going to fit the governance of the
    enterprise's IT environment better. It also offers a protected collaboration environment
    for your group and the entire data science lab. And of course, its main advantage
    consists of making model deployment and moving it into production easier and safer
    since it uses the *integrated deployment* feature and allows you to use *one-click
    deployment* into production. End users can then run the application from a KNIME
    Analytics Platform client or – even better – from a web browser.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，**KNIME Server**（需要年度许可费用）可以让你的工作更轻松。首先，它能够更好地适应企业IT环境的治理需求。它还为你的团队和整个数据科学实验室提供了一个受保护的协作环境。当然，它的主要优势在于简化和更安全的模型部署过程，因为它使用了*集成部署*功能，并允许你通过*一键部署*将模型投入生产。最终用户可以通过KNIME
    Analytics Platform客户端运行应用程序，或者——更好的是——通过Web浏览器运行。
- en: Remember those composite views that offer interactive interconnected views of
    selected points? These become fully formed web pages when the application is executed
    on a web browser via **KNIME Server's WebPortal**.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得那些提供选定点的交互式互联视图的复合视图吗？当应用程序通过**KNIME Server的WebPortal**在Web浏览器中执行时，这些视图将变成完整的网页。
- en: Using the components as touchpoints within the workflow, we get [a **Guided
    Analytics** (](https://www.knime.com/blog/principles-of-guided-analytics)) application
    within the web browser. Guided analytics inserts touchpoints to be consumed by
    the end user from a web browser within the flow of the application. The end user
    can take advantage of these touchpoints to insert knowledge or preferences and
    to steer the analysis in the desired direction.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 利用组件作为工作流中的接触点，我们可以在Web浏览器中获得[一个**引导分析**（](https://www.knime.com/blog/principles-of-guided-analytics))应用程序。引导分析将接触点插入到应用程序流中，供最终用户从Web浏览器中使用。最终用户可以利用这些接触点插入知识或偏好，并引导分析朝着期望的方向发展。
- en: Now, let's download KNIME Analytics Platform and give it a try!
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们下载KNIME Analytics Platform并试试看！
- en: Exploring KNIME Analytics Platform
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索KNIME Analytics Platform
- en: To install KNIME Analytics Platform, foll[ow these steps:](http://www.knime.com/downloads)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装KNIME Analytics Platform，请[按照这些步骤：](http://www.knime.com/downloads)
- en: '[Go to](http://www.knime.com/downloads) .'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[前往](http://www.knime.com/downloads)。'
- en: Provide some details about yourself (step **1** in *Figure 1.2*).
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供一些关于你的详细信息（*图1.2*中的**第1步**）。
- en: Download the version that's suitable for your operating system (step **2** in
    *Figure 1.2*).
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载适合你操作系统的版本（*图1.2*中的**第2步**）。
- en: 'While you''re waiting for the appropriate version to download, browse through
    the different steps to get started (step **3** in *Figure 1.2*):'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你等待适当版本的下载时，浏览一下不同的入门步骤（*图1.2*中的**第3步**）：
- en: '![Figure 1.2 – Steps for downloading the KNIME Analytics Platform package](img/B16391_01_002.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图1.2 – 下载KNIME Analytics Platform包的步骤](img/B16391_01_002.jpg)'
- en: Figure 1.2 – Steps for downloading the KNIME Analytics Platform package
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – 下载KNIME Analytics Platform包的步骤
- en: Once you've downloaded the package, locate it, start it, and follow the instructions
    that appear onscreen to install it in any directory that you have write permissions
    for.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 下载完成后，找到安装包，启动它，并按照屏幕上显示的说明将其安装到任何你有写权限的目录中。
- en: Once it's been installed, locate your instance of KNIME Analytics Platform –
    from the appropriate folder, desktop link, application, or link in the start menu
    – and start it.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，找到你安装的KNIME Analytics Platform实例——无论是从相应的文件夹、桌面链接、应用程序，还是开始菜单中的链接——并启动它。
- en: 'When the splash screen appears, a window will ask for the location of your
    workspace (*Figure 1.3*). This workspace is a folder on your machine that will
    host all your work. The default workspace folder is called `knime-workspace`:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当启动画面出现时，会弹出一个窗口要求你选择工作区的位置（*图 1.3*）。这个工作区是你计算机上的一个文件夹，用来存储你的所有工作。默认的工作区文件夹名为`knime-workspace`：
- en: '![Figure 1.3 – The KNIME Analytics Platform Launcher window asking for the
    workspace folder](img/B16391_01_003.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.3 – KNIME Analytics Platform 启动窗口要求选择工作区文件夹](img/B16391_01_003.jpg)'
- en: Figure 1.3 – The KNIME Analytics Platform Launcher window asking for the workspace
    folder
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3 – KNIME Analytics Platform 启动窗口要求选择工作区文件夹
- en: After clicking **Launch**, the workbench for **KNIME Analytics Platform** will
    open.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**启动**后，**KNIME Analytics Platform**的工作台将会打开。
- en: 'The workbench of KNIME Analytics Platform is organized as depicted in *Figure
    1.4*:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME Analytics Platform 的工作台如*图 1.4*所示组织：
- en: '![Figure 1.4 – The KNIME Analytics Platform workbench](img/B16391_01_004.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.4 – KNIME Analytics Platform 工作台](img/B16391_01_004.jpg)'
- en: Figure 1.4 – The KNIME Analytics Platform workbench
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4 – KNIME Analytics Platform 工作台
- en: 'The KNIME workbench consists of different panels that can be resized, removed
    by clicking the `View` menu. Let''s take a look at these panels:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME工作台由不同的面板组成，可以通过点击`视图`菜单进行调整大小或移除。让我们来看看这些面板：
- en: '**KNIME Explorer**: The **KNIME Explorer** panel in the upper-left corner displays
    all the workflows in the selected (**LOCAL**) workspace, possible connections
    to mounted KNIME servers, a connection to the **EXAMPLES** server, and a connection
    to the **My-KNIME-Hub** space.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**KNIME Explorer**：位于左上角的**KNIME Explorer**面板显示了所选（**LOCAL**）工作区中的所有工作流、可能连接的KNIME服务器、与**EXAMPLES**服务器的连接以及与**My-KNIME-Hub**空间的连接。'
- en: The **LOCAL** workspace displays all workflows, saved in the workspace folder
    that were selected when KNIME Analytics Platform was started. The very first time
    the platform is opened, the LOCAL workspace only contains workflows and data in
    the *Example Workflows* folder. These are example applications to be used as starting
    points for your projects.
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**LOCAL**工作区显示了在启动KNIME Analytics Platform时所选工作区文件夹中保存的所有工作流。第一次打开平台时，LOCAL工作区仅包含*示例工作流*文件夹中的工作流和数据。这些是可以作为你项目起点的示例应用程序。'
- en: The **EXAMPLES** server is a read-only KNIME hosted server that contains many
    more example workflows, organized into categories. Just double-click it to be
    automatically logged in with read-only mode. Once you've done this, you can browse,
    open, explore, and download all available example workflows. Once you have located
    a workflow, double-click it to explore it or drag and drop it into **LOCAL** to
    create a local editable copy.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**EXAMPLES**服务器是一个只读的KNIME托管服务器，包含了更多按类别组织的示例工作流。只需双击它即可自动以只读模式登录。完成此操作后，你可以浏览、打开、探索并下载所有可用的示例工作流。一旦找到一个工作流，双击它进行探索，或将其拖放到**LOCAL**中创建一个本地可编辑副本。'
- en: '**My-KNIME-Hub** provides access to the KNIME community shared repository (**KNIME
    Hub**), either in public or private mode. You can use **My-KNIME-Hub/Public**
    to share your work with the KNIME community or **My-KNIME-Hub/Private** as a space
    for your current work.'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**My-KNIME-Hub**提供了访问KNIME社区共享库（**KNIME Hub**）的途径，可以选择公共或私有模式。你可以使用**My-KNIME-Hub/Public**与KNIME社区共享你的工作，或者使用**My-KNIME-Hub/Private**作为你当前工作的空间。'
- en: '**Workflow Coach**: **Workflow Coach** is a node recommendation engine that
    aids you when you''re building workflows. Based on worldwide user statistics or
    your own private statistics, it will give you suggestions on which nodes you should
    use to complete your workflow.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作流教练**：**工作流教练**是一个节点推荐引擎，可以在你构建工作流时提供帮助。基于全球用户统计数据或你自己的私人统计数据，它会为你提供使用哪些节点的建议，以完成你的工作流。'
- en: '**Node Repository**: The **Node Repository** contains all the KNIME nodes you
    have currently installed, organized into categories. To help you with orientation,
    a search box is located at the top of the **Node Repository** panel. The magnifier
    lens on its left switches between the exact match and the fuzzy search option.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点库**：**节点库**包含了你当前安装的所有KNIME节点，并按类别进行组织。为了帮助你进行定位，**节点库**面板的顶部有一个搜索框。搜索框左侧的放大镜图标可以切换精确匹配和模糊搜索选项。'
- en: '**Workflow Editor**: The **Workflow Editor** is the canvas at the center of
    the page and is where you assemble workflows, configure and execute nodes, inspect
    results, and explore data. Nodes are added from the **Node Repository** panel
    to the workflow editor by drag and drop or double-click. Upon starting KNIME Analytics
    Platform, the Workflow Editor will open on the **Welcome Page** panel, which includes
    a number of useful tips on where to find help, courses, events, and the latest
    news about the software.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工作流编辑器**：**工作流编辑器**是页面中央的画布，你可以在这里组装工作流、配置和执行节点、检查结果并探索数据。节点可以从**节点库**面板通过拖放或双击的方式添加到工作流编辑器中。启动
    KNIME Analytics Platform 后，工作流编辑器将在**欢迎页面**面板中打开，那里有许多有用的提示，告诉你如何找到帮助、课程、活动以及关于软件的最新资讯。'
- en: '**Outline**: The **Outline** view displays the entire workflow, even if only
    a small part is visible in the workflow editor. This part is marked in gray in
    the **Outline** view. Moving the gray rectangle in the **Outline** view changes
    the portion of the workflow that''s visible in the Workflow Editor.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大纲**：**大纲**视图显示整个工作流，即使在工作流编辑器中只有一小部分可见。这部分在**大纲**视图中以灰色标出。移动**大纲**视图中的灰色矩形会改变工作流编辑器中可见的工作流部分。'
- en: '**Console** and **Node Monitor**: The **Console** and the **Node Monitor**
    share one panel with two tabs. The **Console** tab prints out possible error and
    warning messages. The same information is written to a log file, located in the
    workspace directory. The **Node Monitor** tab shows you the data that''s available
    at the output ports of the selected executed node in the Workflow Editor. If a
    node has multiple output ports, you can select the data of interest from a dropdown
    menu. By default, the data at the top output port is sh[own.](http://www.hub.knime.com)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**控制台**和**节点监视器**：**控制台**和**节点监视器**共享一个面板，分为两个标签页。**控制台**标签页输出可能的错误和警告信息。相同的信息会写入日志文件，位置在工作空间目录中。**节点监视器**标签页显示你在工作流编辑器中选择执行节点的输出端口可用的数据。如果一个节点有多个输出端口，你可以从下拉菜单中选择感兴趣的数据。默认情况下，顶部输出端口的数据会显示出来。[链接](http://www.hub.knime.com)'
- en: '[**KNIME Hub**: The **KNI**](http://www.hub.knime.com)**ME Hub** ([https://hub.knime.com/](https://hub.knime.com/))
    is an external space where KNIME users can share their work. This panel allows
    you to search for workflows, nodes, and components shared by members of the KNIME
    community.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**KNIME Hub**: The **KNI**](http://www.hub.knime.com)**ME Hub** ([https://hub.knime.com/](https://hub.knime.com/))
    是一个外部空间，KNIME 用户可以在其中分享他们的工作。此面板允许你搜索由 KNIME 社区成员分享的工作流、节点和组件。'
- en: '**Description**: The **Description** panel displays information about the selected
    node or category. In particular, for nodes, it explains the node''s task, the
    algorithm behind it (if any), the dialog options, the available views, the expected
    input data, and the resulting output data. For categories, it displays all contained
    nodes.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**描述**：**描述**面板显示有关所选节点或类别的信息。特别是，对于节点，它解释了节点的任务、背后的算法（如果有的话）、对话框选项、可用的视图、预期的输入数据以及产生的输出数据。对于类别，它显示所有包含的节点。'
- en: Finally, at the very top, you can find the **Top Menu**, which includes menus
    for file management and preference settings, workflow editing options, additional
    views, node commands, and help documentation.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在页面顶部，你可以找到**顶部菜单**，它包括文件管理和首选项设置、工作流编辑选项、附加视图、节点命令和帮助文档的菜单。
- en: Besides the core software, KNIME Analytics Platform benefits from external **extensions**
    provided by the KNIME community. The **install KNIME extensions** and **update
    KNIME** commands, available in the **File** menu, allow you to expand your current
    instance with external extensions or update it to a newer version.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 除了核心软件外，KNIME Analytics Platform 还受益于 KNIME 社区提供的外部**扩展**。在**文件**菜单中提供的**安装
    KNIME 扩展**和**更新 KNIME**命令，允许你通过外部扩展扩展当前实例或将其更新到更新版本。
- en: Under the top menu, a **toolbar** is available. When a workflow is open, the
    toolbar offers commands for workflow editing, node execution, and customization.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部菜单下，提供了一个**工具栏**。当工作流打开时，工具栏提供工作流编辑、节点执行和自定义的命令。
- en: A **workflow** can be built by dragging and dropping nodes from the **Node Repository**
    panel onto the **Workflow Editor** window or by just double-clicking them. Nodes
    are the basic processing units of any workflow. Each **node** has several input
    and/or output ports. **Data** flows over a connection from an **output port**
    to the **input port**(s) of other nodes. Two nodes are connected – and the data
    flow is established – by clicking the mouse at the output port of the first node
    and releasing the mouse at the input port of the next node. A pipeline of such
    nodes makes a workflow.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从**节点库**面板将节点拖放到**工作流编辑器**窗口中，或者直接双击它们，可以构建一个**工作流**。节点是任何工作流的基本处理单元。每个**节点**都有多个输入和/或输出端口。**数据**通过连接从**输出端口**流向其他节点的**输入端口**。通过点击第一个节点的输出端口，并将鼠标释放到下一个节点的输入端口，两个节点就被连接起来——数据流也随之建立。由这样的一系列节点构成的数据处理流程便是一个工作流。
- en: 'In *Figure 1.5*, under each node, you will see a **status light**: red, yellow,
    or green:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 1.5*中，每个节点下方会看到一个**状态灯**：红色、黄色或绿色：
- en: '![Figure 1.5 – Node structure and status lights](img/B16391_01_005.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.5 – 节点结构和状态灯](img/B16391_01_005.jpg)'
- en: Figure 1.5 – Node structure and status lights
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5 – 节点结构和状态灯
- en: When a new node is created, the status light is usually red, which means that
    the node's settings still need to be configured for the node to be able to execute
    its task.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当创建一个新节点时，状态灯通常是红色的，这意味着节点的设置仍需要配置，才能执行任务。
- en: To configure a node, right-click it and select **Configure** or just double-click
    it. Then, adjust the necessary settings in the node's dialog. When the dialog
    is closed by pressing the **OK** button, the node is configured, and the status
    light changes to yellow; this means that the node is ready to be executed. Right-clicking
    on the node again shows an enabled **Execute** option; pressing it will execute
    the node.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要配置一个节点，右键点击它并选择**配置**，或者直接双击它。然后，在节点的对话框中调整必要的设置。当按下**确定**按钮关闭对话框时，节点就被配置好了，状态灯变为黄色；这意味着节点已准备好执行。再次右键点击节点时，会显示一个启用的**执行**选项；点击它将执行该节点。
- en: The ports on the left are input ports, where the data from the outport of the
    predecessor node is fed into the node. Ports on the right are outgoing ports.
    The result of the node's operation on the data is provided by the output port
    of the successor nodes. When you hover over the port, a tooltip will provide information
    about the output dimension of the node.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 左侧的端口是输入端口，来自前置节点输出端口的数据将通过它输入到节点中。右侧的端口是输出端口。节点对数据的操作结果通过后续节点的输出端口提供。当你将鼠标悬停在端口上时，会显示一个工具提示，提供节点输出维度的信息。
- en: Important note
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Only ports of the same type can be connected!
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 只有相同类型的端口才能连接！
- en: '**Data ports** (black triangles) are the most common type of node ports and
    transfer flat data tables from node to node. **Database ports** (brown squares)
    transfer SQL queries from node to node. Many more node ports exist and transfer
    different objects from one node to the next.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据端口**（黑色三角形）是最常见的节点端口类型，用于在节点之间传输平面数据表。**数据库端口**（棕色方块）用于在节点之间传输 SQL 查询。还有许多其他类型的节点端口，传输不同的对象。'
- en: 'After successful execution, the status light of the node turns green, indicating
    that the processed data is now available on the outports. The result(s) can be
    inspected by exploring the outport view(s): the last entries in the context menu
    open them.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 执行成功后，节点的状态灯变为绿色，表示处理后的数据现在可以在输出端口中使用。结果可以通过查看输出端口视图来检查：右键菜单中的最后一项会打开它们。
- en: With that, we have completed our quick tour of the workbench in KNIME Analytics
    Platform.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止，我们已经完成了 KNIME Analytics Platform 工作台的快速游览。
- en: Now, let's take a look at where we can find starting examples and help.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看在哪里可以找到起始示例和帮助。
- en: Useful Links and Materials
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有用的链接和材料
- en: 'At this point, we have already looked at the `read file` and you will get a
    list of example workflows illustrating how to read `CSV` files, `.table` files,
    `Excel` files, and so on. (*Figure 1.6*):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们已经查看了 `read file`，你将获得一个示例工作流列表，展示如何读取 `CSV` 文件、`.table` 文件、`Excel` 文件等。（*图
    1.6*）：
- en: '![Figure 1.6 – Resulting list of workflows from searching for "read file" on
    the KNIME Hub](img/B16391_01_006.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.6 – 在 KNIME Hub 上搜索 "read file" 后得到的工作流列表](img/B16391_01_006.jpg)'
- en: Figure 1.6 – Resulting list of workflows from searching for "read file" on the
    KNIME Hub
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 – 在 KNIME Hub 上搜索 "read file" 后得到的工作流列表
- en: 'All workflows described in this book are also available on the KNIME Hub for
    you: [https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/](https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中描述的所有工作流也可以在 KNIME Hub 上找到，供你使用：[https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/](https://hub.knime.com/kathrin/spaces/Codeless%20Deep%20Learning%20with%20KNIME/latest/)。
- en: Once you've isolated the workflow you are interested in, click on it to open
    its page, and then download it or open it in KNIME Analytics Platform to customize
    it to your own needs.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你找到了感兴趣的工作流，点击它以打开其页面，然后下载或在 KNIME Analytics Platform 中打开它，以根据你的需要进行自定义。
- en: On the other hand, to share your work on the KNIME Hub, just copy your workflows
    from your local workspace into the *My-KNIME-Hub/Public* folder in the **KNIME
    Explorer** panel within the KNIME workbench. It will be automatically available
    to all members of the KNIME community.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，要在 KNIME Hub 上分享你的工作，只需将你的工作流从本地工作区复制到 **KNIME Explorer** 面板中的 *My-KNIME-Hub/Public*
    文件夹中。这样，它将自动对所有 KNIME 社区成员可用。
- en: The KNIME community is also very active, with tips and tricks available on the
    **KNIME Forum** ([https://forum.knime.com/](https://forum.knime.com/)). Here,
    you can ask questions or search for answers.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME 社区也非常活跃，**KNIME 论坛**（[https://forum.knime.com/](https://forum.knime.com/)）上有许多技巧和窍门。在这里，你可以提问或查找答案。
- en: Finally, contributions from the community are available as posts on the **KNIME
    Blog** ([https://www.knime.com/blog](https://www.knime.com/blog)), as books via
    **KNIME Press** ([https://www.knime.com/knimepress](https://www.knime.com/knimepress)**E
    TV** () channel on YouTube.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，社区的贡献可以通过**KNIME 博客**（[https://www.knime.com/blog](https://www.knime.com/blog)）上的帖子、**KNIME
    Press**（[https://www.knime.com/knimepress](https://www.knime.com/knimepress)）出版的书籍，或者通过**KNIME
    TV** () 频道在 YouTube 上观看。
- en: The two books *KNIME Beginner's Luck* and *KNIME Advanced Luck* provide tutorials
    for those users who are starting out in data science with KNIME Analytics Platform.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 两本书《*KNIME 初学者的幸运*》和《*KNIME 高级幸运*》为那些刚开始使用 KNIME Analytics Platform 从事数据科学的用户提供了教程。
- en: Now, let's build our first workflow, shall we?
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们构建我们的第一个工作流，好吗？
- en: Build and Execute Your First Workflow
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建并执行你的第一个工作流
- en: 'In this section, we''ll build our first, simple, small workflow. We''ll start
    with something basic: reading data from an ASCII file, performing some filtering,
    and displaying the results in a bar chart.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将构建我们的第一个简单的小型工作流。我们将从一些基础的内容开始：从 ASCII 文件读取数据，进行一些过滤，并在条形图中显示结果。
- en: 'In KNIME Explorer, do the following:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在 KNIME Explorer 中，按以下步骤操作：
- en: 'Create a new empty folder by doing the following:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过以下步骤创建一个新的空文件夹：
- en: a) Right-click `Chapter 1`.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 右键点击 `第1章`。
- en: Click **Finish**. You should then see a new folder with that name in the **KNIME
    Explorer** panel.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**完成**。然后你应该能在**KNIME Explorer**面板中看到一个新文件夹，名称就是你刚刚设置的名称。
- en: Important note
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: Folders in KNIME Explorer are called **Workflow Groups**.
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 KNIME Explorer 中，文件夹被称为**工作流组**。
- en: 'Similarly, you can create a new workflow, as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你可以按照以下步骤创建一个新的工作流：
- en: 'Create a new workflow by doing the following:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过以下步骤创建一个新的工作流：
- en: a) Right-click the `Chapter 1` folder (or anywhere you want your workflow to
    be).
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: a) 右键点击 `第1章` 文件夹（或者在你希望放置工作流的地方）。
- en: b) Select `My_first_workflow`.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: b) 选择 `My_first_workflow`。
- en: Click **Finish**. You should then see a new workflow with that name in the **KNIME
    Explorer** panel.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**完成**。然后你应该能在**KNIME Explorer**面板中看到一个新工作流，名称就是你刚刚设置的名称。
- en: After clicking **Finish**, the Workflow Editor will open the canvas for the
    empty workflow.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 点击**完成**后，工作流编辑器将打开空工作流的画布。
- en: Tip
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: By default, the canvas for a new workflow opens with the grid on; to turn it
    off, click the **Open the settings dialog for the workflow editor** button (the
    button before the last one) in the toolbar. This button opens a window where you
    can customize the workflow's appearance (for example, allowing curved connections)
    and perform editing (turn the grid on/off).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，新工作流的画布会显示网格；若要关闭它，请点击工具栏中**打开工作流编辑器设置对话框**按钮（倒数第二个按钮）。此按钮会打开一个窗口，你可以在其中自定义工作流的外观（例如，允许弯曲的连接线）并进行编辑（打开/关闭网格）。
- en: '*Figure 1.7* shows the **New Workflow Group**... option in the KNIME Explorer''s
    context menu. It allows you to create a new, empty folder:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.7* 显示了 **新工作流组**... 选项，在 KNIME Explorer 的上下文菜单中。它允许你创建一个新的空文件夹：'
- en: '![Figure 1.7 – Context menu for creating a new folder and a new workflow in
    KNIME Explorer](img/B16391_01_007.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.7 – 在 KNIME Explorer 中创建新文件夹和新工作流的上下文菜单](img/B16391_01_007.jpg)'
- en: Figure 1.7 – Context menu for creating a new folder and a new workflow in KNIME
    Explorer
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7 – 在KNIME Explorer中创建新文件夹和新工作流的上下文菜单
- en: The first thing we need to do in our workflow is read an ASCII file with the
    data. Let's read the *adult.csv* file that comes with the installation of KNIME
    Analytics Platform. This can be found under **Example Workflows/The Data/Basics**.
    adult.csv is a US Census public file that describes 30K people by age, gender,
    origin, and professional and private life.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的工作流中，首先需要读取包含数据的ASCII文件。让我们读取安装KNIME Analytics Platform时提供的*adult.csv*文件。它位于**Example
    Workflows/The Data/Basics**下。adult.csv是一个美国人口普查公共文件，描述了30K人群体的年龄、性别、来源、职业和私人生活。
- en: 'Let''s **create** the node so that we can read the *adult.csv* ASCII file:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们**创建**该节点，以便能够读取*adult.csv* ASCII文件：
- en: a) In the `Node Repository`, search for the **File Reader** node (it is actually
    located in the **IO/Read** category).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: a) 在`Node Repository`中，搜索**File Reader**节点（它实际上位于**IO/Read**类别中）。
- en: b) Drag and drop the `File Reader` node onto the **Workflow Editor** panel.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: b) 将`File Reader`节点拖放到**Workflow Editor**面板中。
- en: c) Alternatively, just double-click the `File Reader` node in the `Node Repository`;
    this will automatically create it in the **Workflow Editor** panel.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: c) 或者，直接双击`File Reader`节点，这将在**Workflow Editor**面板中自动创建它。
- en: 'In *Figure 1.8*, see the `File Reader` node located in the `Node Repository`:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 1.8*中，查看`Node Repository`中位于**IO/Read**下的`File Reader`节点：
- en: '![Figure 1.8 – The File Reader node under IO/Read in the Node Repository](img/B16391_01_008.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.8 – 在Node Repository中的IO/Read下的File Reader节点](img/B16391_01_008.jpg)'
- en: Figure 1.8 – The File Reader node under IO/Read in the Node Repository
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8 – `Node Repository`中**IO/Read**下的File Reader节点
- en: 'Now, let''s `File Reader` node in the Workflow Editor and manually configure
    it with the file path to the *adult.csv* file. Alternatively, just drag and drop
    the *adult.csv* file from the **KNIME Explorer** panel (or from anywhere on your
    machine) onto the **Workflow Editor** window. You can see this action in *Figure
    1.9*:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在Workflow Editor中使用`File Reader`节点，并手动配置文件路径以读取*adult.csv*文件。或者，直接将*adult.csv*文件从**KNIME
    Explorer**面板（或你计算机上的任何位置）拖放到**Workflow Editor**窗口中。你可以在*图 1.9*中看到这一操作：
- en: '![Figure 1.9 – Dragging and dropping the adult.csv file onto the Workflow Editor
    panel.](img/B16391_01_009.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.9 – 将adult.csv文件拖放到Workflow Editor面板中。](img/B16391_01_009.jpg)'
- en: Figure 1.9 – Dragging and dropping the adult.csv file onto the Workflow Editor
    panel.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.9 – 将adult.csv文件拖放到Workflow Editor面板中。
- en: This automatically generates a File Reader node that contains most of the correct
    configuration settings for reading the file.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这将自动生成一个File Reader节点，其中包含读取文件的大部分正确配置设置。
- en: Tip
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'The **Advanced** button in the File Reader configuration window leads you to
    additional advanced settings: reading files with special characters, such as quotes;
    allowing lines with different lengths; using different encodings; and so on.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在File Reader配置窗口中的**Advanced**按钮将引导你到更多高级设置：读取包含特殊字符（如引号）的文件；允许长度不同的行；使用不同的编码方式；等等。
- en: To execute this node, just right-click it and from the context menu, select
    **Execute**; alternatively, click on the **Execute** buttons (single and double
    white arrows on a green background) that are available in the toolbar.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行该节点，只需右键单击它，并从上下文菜单中选择**Execute**；或者，点击工具栏中可用的**Execute**按钮（绿色背景上的单白箭头和双白箭头）。
- en: To inspect the output data table that's produced by this node's execution, right-click
    on the node and select the last option available in the context menu. This opens
    the data table that appears as a result of reading the *adult.csv* file. You will
    notice columns such as **Age**, **Workclass**, and so on.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查由该节点执行生成的输出数据表，右键单击该节点并选择上下文菜单中的最后一个选项。这将打开作为读取*adult.csv*文件结果的数据表。你将看到**Age**、**Workclass**等列。
- en: Important note
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: Data in KNIME Analytics Platform is organized into tables. Each cell is uniquely
    identified via the **column header** and the **row ID**. Therefore, column headers
    and row IDs need to have unique values.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME Analytics Platform中的数据是以表格形式组织的。每个单元格通过**列标题**和**行ID**唯一标识。因此，列标题和行ID需要具有唯一的值。
- en: '`fnlwgt` is one column for which we were never sure of what it meant. So, let''s
    remove it from further analysis by using the **Column Filter** node.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`fnlwgt`是一个我们一直不确定其含义的列。因此，使用**Column Filter**节点将其从进一步分析中移除。'
- en: To do this, search for `File Reader` node to the input of the `Column Filter`
    node. Alternatively, we can select the `File Reader` node in the `Column Filter`
    node in the Node Repository. This automatically creates a node and its connections
    in the Workflow Editor.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，搜索 `File Reader` 节点并将其连接到 `Column Filter` 节点的输入端口。或者，我们可以在节点库中选择 `Column
    Filter` 节点中的 `File Reader` 节点。这会自动在工作流编辑器中创建节点及其连接。
- en: 'The `Column Filter` node and its configuration window are shown in *Figure
    1.10*:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`Column Filter` 节点及其配置窗口如 *图 1.10* 所示：'
- en: '![Figure 1.10 – Configuring the Column Filter node to remove the column named
    fnlwgt from the input data table](img/B16391_01_010.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.10 – 配置 `Column Filter` 节点以从输入数据表中删除名为 fnlwgt 的列](img/B16391_01_010.jpg)'
- en: Figure 1.10 – Configuring the Column Filter node to remove the column named
    fnlwgt from the input data table
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.10 – 配置 `Column Filter` 节点以从输入数据表中删除名为 fnlwgt 的列
- en: 'Again, double-click or right-click the node and then select **Configure** to
    configure it. This configuration window contains three options that can be selected
    via three radio buttons: **Manual Selection**, **Wildcard/Regex Selection**, and
    **Type Selection**. Let''s take a look at these in more detail:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，双击或右击节点，然后选择 **配置** 进行配置。该配置窗口包含三个选项，可以通过三个单选按钮选择：**手动选择**、**通配符/正则表达式选择**
    和 **类型选择**。让我们更详细地了解这些选项：
- en: '**Manual Selection** offers an Include/Exclude framework so that you can manually
    transfer columns from the **Include** set into the **Exclude** set and vice versa.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**手动选择** 提供了一个包含/排除框架，您可以通过框架之间的按钮手动将列从 **包含** 集合转移到 **排除** 集合，反之亦然。'
- en: '**Wildcard/Regex Selection** extracts the columns you wish to keep, based on
    a wildcard (using ***** as the wildcard) or regex expression.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通配符/正则表达式选择** 根据通配符（使用 ***** 作为通配符）或正则表达式提取您希望保留的列。'
- en: '**Type Selection** keeps the columns based on the data types they carry.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**类型选择** 根据列所包含的数据类型来保留列。'
- en: Since this is our first workflow, we'll go for the easiest approach; that is,
    Manual Selection. Go to the `fnlwgt` column to the **Exclude** set via the buttons
    in-between the two frames (these can be seen in *Figure 1.10*).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是我们的第一个工作流，我们将选择最简单的方法；也就是手动选择。通过框架之间的按钮，将 `fnlwgt` 列移到 **排除** 集合中（这些按钮可以在
    *图 1.10* 中看到）。
- en: After executing the Column Filter node, if we inspect the output data table
    (right-click and select the last option in the context menu), we'll see a table
    that doesn't contain the `fnlwgt` column.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 执行 `Column Filter` 节点后，如果我们检查输出数据表（右击并选择上下文菜单中的最后一个选项），我们会看到一个不包含 `fnlwgt` 列的表格。
- en: Now, let's extract all the records of people who work more than 20 hours/week.
    `hours-per-week` is the column that contains the data of interest.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们提取所有每周工作超过 20 小时的人的记录。`hours-per-week` 是包含相关数据的列。
- en: 'For this, we need to create a Row Filter node and implement the required condition:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要创建一个 Row Filter 节点，并实现所需的条件：
- en: '[PRE0]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Again, let's locate the `Column Filter` node to its input port, and open its
    configuration window.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，定位 `Column Filter` 节点到其输入端口，并打开其配置窗口。
- en: 'In the configuration window of the `Row Filter` node (*Figure 1.11*), we''ll
    find three default filtering criteria: **use pattern matching**, **use range checking**,
    and **only missing values match**. Let''s take a look at what they do:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `Row Filter` 节点的配置窗口中（*图 1.11*），我们将看到三个默认的过滤条件：**使用模式匹配**、**使用范围检查** 和 **仅缺失值匹配**。让我们来看一下它们的作用：
- en: '**use pattern matching** matches the given pattern to the content of the selected
    column in the **Column to test** field and keeps the matching rows.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用模式匹配** 将给定的模式与 **测试列** 字段中选定列的内容进行匹配，并保留匹配的行。'
- en: '**use range checking** keeps only those data rows whose value in the **Column
    to test** columns falls between the **lower bound** and **upper bound** values.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用范围检查** 仅保留在 **测试列** 中值位于 **下限** 和 **上限** 之间的数据行。'
- en: '**only missing values match** only keeps the data rows where a missing value
    is present in the selected column.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仅缺失值匹配** 只保留选定列中存在缺失值的数据行。'
- en: The default behavior is to include the matching data rows in the output data
    table. However, this can be changed by enabling **Exclude rows by attribute value**
    via the radio buttons on the left-hand side of the configuration window.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 默认行为是将匹配的数据行包含在输出数据表中。然而，您可以通过配置窗口左侧的单选按钮启用 **按属性值排除行** 来更改此行为。
- en: 'Alternative filtering criteria can be done by row number or by row ID. This
    can also be enabled via the radio buttons on the left-hand side of the configuration
    window:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 替代的过滤条件可以通过行号或行 ID 完成。也可以通过配置窗口左侧的单选按钮启用：
- en: '![Figure 1.11 – Configuring the Row Filter node to keep only rows with hours-per-week
    > 20 in the input data table](img/B16391_01_011.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.11 – 配置行过滤器节点，以仅保留输入数据表中每周工作小时数大于 20 的行](img/B16391_01_011.jpg)'
- en: Figure 1.11 – Configuring the Row Filter node to keep only rows with hours-per-week
    > 20 in the input data table
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.11 – 配置行过滤器节点，以仅保留输入数据表中每周工作小时数大于 20 的行
- en: 'After execution, upon opening the output data table (*Figure 1.12*), no data
    rows with *hours-per-week < 20* should be present:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 执行后，打开输出数据表（*图 1.12*）时，不应出现 *每周工作小时数 < 20* 的数据行：
- en: '![Figure 1.12 – Right-clicking a successfully executed node and selecting the
    last option shows the data table that was produced by the node](img/B16391_01_012.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.12 – 右键点击成功执行的节点并选择最后一个选项，显示由该节点生成的数据表](img/B16391_01_012.jpg)'
- en: Figure 1.12 – Right-clicking a successfully executed node and selecting the
    last option shows the data table that was produced by the node
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.12 – 右键点击成功执行的节点并选择最后一个选项，显示由该节点生成的数据表
- en: 'Now, let''s look at some very basic visualization. Let''s visualize the number
    of men versus women in this dataset, which contains people who work more than
    20 hours/week:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一些非常基础的可视化。我们将可视化这个数据集中男性与女性的数量，该数据集包含每周工作超过 20 小时的人：
- en: '![Figure 1.13 – The Bar Chart node and its configuration window](img/B16391_01_013.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.13 – 条形图节点及其配置窗口](img/B16391_01_013.jpg)'
- en: Figure 1.13 – The Bar Chart node and its configuration window
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.13 – 条形图节点及其配置窗口
- en: 'To do this, locate the `Row Filter` node, and open its configuration window
    (*Figure 1.13*). Here, there are four tabs we can use for configuration purposes.
    **Options** covers all data settings, **General Plot Options** covers all plot
    settings, **Control Options** covers all control options, and **Interactivity**
    covers all subscription events when it comes to interacting with other plots,
    views, and charts when they''ve been assembled to create a component. Again, since
    this is just a beginner''s workflow, we''ll adopt all the default settings and
    just set the following:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，找到 `Row Filter` 节点，并打开其配置窗口（*图 1.13*）。这里有四个标签可以用于配置：**选项** 涵盖所有数据设置，**常规绘图选项**
    涵盖所有绘图设置，**控制选项** 涵盖所有控制设置，**交互性** 涵盖所有与其他图表、视图和图形交互时的订阅事件。由于这是一个初学者的工作流，我们将采用所有默认设置，只设置以下内容：
- en: From the `sex`, ensuring it appears on the *x* axis. Then, select **Occurrence
    Count** in order to count the number of rows by sex.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 `sex` 中，确保它出现在 *x* 轴上。然后，选择 **出现次数** 以按性别统计行数。
- en: From the **General Plot Options** tab, set a title, a subtitle, and the axis
    labels.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 **常规绘图选项** 标签中，设置标题、副标题和轴标签。
- en: 'This node does not produce data, but rather a view of the bar chart. So, to
    inspect the results produced by this node after its execution, right-click it
    and select the central option; that is, **Interactive View: Group Bar Chart**
    (*Figure 1.14*):'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点不会生成数据，而是生成条形图的视图。因此，要检查该节点执行后的结果，右键点击它并选择中央选项，即 **交互视图：分组条形图**（*图 1.14*）：
- en: '![Figure 1.14 – Right-clicking a successfully executed visualization node and
    selecting the Interactive View: Grouped Bar Chart option to see the chart/plot
    that has been produced](img/B16391_01_014.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.14 – 右键点击成功执行的可视化节点并选择交互视图：分组条形图选项，以查看生成的图表/图形](img/B16391_01_014.jpg)'
- en: 'Figure 1.14 – Right-clicking a successfully executed visualization node and
    selecting the Interactive View: Grouped Bar Chart option to see the chart/plot
    that has been produced'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.14 – 右键点击成功执行的可视化节点并选择交互视图：分组条形图选项，以查看生成的图表/图形
- en: Notice the three buttons in the top-right corner of the view on the right of
    *Figure 1.14*. These three buttons enable **zooming**, **toggling to full screen**,
    and **node settings**, respectively. From the view itself, you can explore how
    the chart would look if different settings were to be selected, such as a different
    category column or a different title.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 *图 1.14* 右侧视图的右上角有三个按钮。这三个按钮分别启用 **缩放**、**切换到全屏** 和 **节点设置**。在视图本身中，您可以探索选择不同设置后的图表效果，例如选择不同的类别列或标题。
- en: Important note
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'Most data visualization nodes produce a view and not a data table. To see the
    respective view, right-click the successfully executed node and select the **Interactive
    View: …** option.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数数据可视化节点生成的是视图，而不是数据表。要查看相应的视图，右键点击成功执行的节点并选择**交互视图：...**选项。
- en: The second lower input port of the **Bar Chart** node is optional (a white triangle)
    and is used to read a color map so that you can color the bars in the bar chart.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**条形图**节点的第二个下输入端口是可选的（一个白色三角形），用于读取颜色映射，这样你就可以给条形图中的条形上色。'
- en: Important note
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'Note that a number of different data visualization nodes are available in the
    Node Repository: JavaScript, Local(Swing), Plotly, and so on. `Bar Chart` node
    from the JavaScript category in the **Node Repository** panel here.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，节点库中提供了多种不同的数据可视化节点：JavaScript、本地（Swing）、Plotly 等。在**节点库**面板中，可以找到来自 JavaScript
    类别的 `条形图` 节点。
- en: Now, we'll add a few comments to document the workflow. You can add comments
    at the node level or at the general workflow level.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将添加一些注释以记录工作流。你可以在节点级别或整个工作流级别添加注释。
- en: 'Each node in the workflow is created with a default label of *Node xx* under
    it. Upon double-clicking it, the node label editor appears. This allows you to
    customize the text, the font, the color, the background, and other similar properties
    of the node (*Figure 1.15*). We need to write a little comment under each node
    to make it clear what tasks they are implementing:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流中的每个节点默认都会创建一个名为*节点 xx*的标签。双击它后，节点标签编辑器将出现。你可以自定义文本、字体、颜色、背景以及节点的其他类似属性（*图
    1.15*）。我们需要在每个节点下写上一些简短的注释，明确它们正在执行的任务：
- en: '![Figure 1.15 – Editor for customizing the labels under each node](img/B16391_01_015.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.15 – 自定义每个节点下标签的编辑器](img/B16391_01_015.jpg)'
- en: Figure 1.15 – Editor for customizing the labels under each node
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.15 – 自定义每个节点下标签的编辑器
- en: 'You can also write annotations at the workflow level. Just right-click anywhere
    in the Workflow Editor and select **New Workflow Annotation**. A yellow frame
    will appear in editing mode. Here, you can add text and customize it, as well
    as its frame. To close the annotation editor, just click anywhere else in the
    Workflow Editor. To reopen the annotation editor, double-click in the top-left
    corner of the annotation (*Figure 1.16*):'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在工作流级别写注释。只需右键点击工作流编辑器中的任意位置，然后选择**新建工作流注释**。在编辑模式下，黄色框架将出现。在这里，你可以添加文本并自定义它以及其框架。要关闭注释编辑器，只需在工作流编辑器中的其他地方单击。要重新打开注释编辑器，双击注释的左上角（*图
    1.16*）：
- en: '![Figure 1.16 – Creating and editing workflow annotations](img/B16391_01_016.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.16 – 创建和编辑工作流注释](img/B16391_01_016.jpg)'
- en: Figure 1.16 – Creating and editing workflow annotations
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.16 – 创建和编辑工作流注释
- en: 'Congratulations! You have just built your first workflow with KNIME Analytics
    Platform. It should look something like the one in *Figure 1.17*:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你刚刚使用 KNIME 分析平台构建了你的第一个工作流。它应该看起来像*图 1.17*中的样子：
- en: '![Figure 1.17 – My_first_Workflow](img/B16391_01_017.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.17 – 我的第一个工作流](img/B16391_01_017.jpg)'
- en: Figure 1.17 – My_first_Workflow
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.17 – 我的第一个工作流
- en: That was a quick introduction to how to use KNIME Analytics Platform.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是 KNIME 分析平台使用的简要介绍。
- en: Now, let's make sure we have KNIME Deep Learning – Keras Integration installed
    and functioning.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们确保已安装并正常运行 KNIME 深度学习 – Keras 集成。
- en: Installing KNIME Deep Learning – Keras Integration
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 KNIME 深度学习 – Keras 集成
- en: In this section, you will learn how to install and set up **KNIME Deep Learning
    - Keras Integration** in order to train neural networks in KNIME Analytics Platform.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将学习如何安装和设置**KNIME 深度学习 - Keras 集成**，以便在 KNIME 分析平台中训练神经网络。
- en: KNIME Analytics Platform consists of a software core and several provided extensions
    and integrations. Such extensions and integrations are provided by the KNIME community
    and extend the original software core through a variety of data science functionalities,
    including advanced algorithms for AI.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME 分析平台由软件核心和若干提供的扩展及集成组成。这些扩展和集成由 KNIME 社区提供，并通过多种数据科学功能扩展原始软件核心，包括用于人工智能的高级算法。
- en: The KNIME extension of interest here is called **KNIME Deep Learning – Keras
    Integration**. It offers a codeless GUI-based integration of the Keras library,
    while using TensorFlow as its backend. This means that a number of functions from
    Keras libraries have been wrapped into KNIME nodes, within KNIME's classic, easy-to-use
    visual dialog window. Due to this integration, you can read, write, create, train,
    and execute deep learning networks without writing code.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这里感兴趣的 KNIME 扩展叫做 **KNIME 深度学习 - Keras 集成**。它提供了一个基于图形用户界面的无代码集成 Keras 库，同时使用
    TensorFlow 作为其后端。这意味着 Keras 库中的许多功能已被封装到 KNIME 节点中，并通过 KNIME 经典的、易于使用的视觉对话框窗口进行操作。由于这种集成，您可以在不编写代码的情况下读取、写入、创建、训练和执行深度学习网络。
- en: Another deep learning integration that's available is called **KNIME Deep Learning
    - TensorFlow Integration**. This extension allows you to convert **Keras** models
    into **TensorFlow** models, as well as read, execute, and write TensorFlow models.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可用的深度学习集成是 **KNIME 深度学习 - TensorFlow 集成**。该扩展允许您将 **Keras** 模型转换为 **TensorFlow**
    模型，还可以读取、执行和写入 TensorFlow 模型。
- en: TensorFlow is an open source library provided by Google that includes a number
    of deep learning paradigms. TensorFlow functions can run on single devices, as
    well as on multiple CPUs and multiple GPUs. This parallel calculation feature
    is the key to speeding up the computationally intensive training that's required
    for deep learning networks.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 是由谷歌提供的开源库，包含了多种深度学习范式。TensorFlow 函数可以在单个设备上运行，也可以在多个 CPU 和多个 GPU
    上运行。这种并行计算功能是加速深度学习网络所需的计算密集型训练的关键。
- en: However, using the TensorFlow library within Python can prove quite complicated,
    even for an expert Python programmer or a deep learning pro. Thus, a number of
    simplified interfaces have been developed on top of TensorFlow that expose a subset
    of its functions and parameters. The most successful of such TensorFlow-based
    libraries is Keras. However, even Keras still requires some programming skills.
    The KNIME Deep Learning – Keras Integration puts the KNIME GUI on top of the Keras
    libraries that are available, mostly eliminating the need to code.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在 Python 中使用 TensorFlow 库可能会相当复杂，即使是经验丰富的 Python 程序员或深度学习专家也不例外。因此，开发了一些简化的接口，基于
    TensorFlow，暴露了其部分功能和参数。最成功的 TensorFlow 基于库之一是 Keras。然而，甚至 Keras 仍然需要一定的编程技能。**KNIME
    深度学习 - Keras 集成** 将 KNIME GUI 放置在 Keras 库之上，基本消除了编写代码的需求。
- en: 'To make the KNIME Deep Learning – Keras Integration work, a few pieces of the
    puzzle need to be installed:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让 **KNIME 深度学习 - Keras 集成** 正常工作，需要安装几个必要的组件：
- en: The Keras and TensorFlow nodes
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras 和 TensorFlow 节点
- en: The Python environment
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 环境
- en: 'Let''s start with the first piece: installing the Keras and TensorFlow nodes.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第一步开始：安装 Keras 和 TensorFlow 节点。
- en: Installing the Keras and TensorFlow Nodes
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Keras 和 TensorFlow 节点
- en: To add nodes to the Node Repository, you must install a few extensions and integrations.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 要向节点库添加节点，您必须安装一些扩展和集成。
- en: 'You can install them from within KNIME Analytics Platform by clicking on **File**
    from the top menu and selecting **Install KNIME Extension…**. This opens the dialog
    shown in *Figure 1.18*:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过点击 KNIME Analytics Platform 顶部菜单中的 **文件**，选择 **安装 KNIME 扩展…** 来安装它们。这将打开如
    *图 1.18* 所示的对话框：
- en: '![Figure 1.18 – Dialog for installing extensions](img/B16391_01_018.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.18 – 安装扩展的对话框](img/B16391_01_018.jpg)'
- en: Figure 1.18 – Dialog for installing extensions
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.18 – 安装扩展的对话框
- en: From this new dialog, you can select the extensions and integrations you want
    to install. Using the search bar at the top is helpful for filtering the available
    extensions and integrations.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个新对话框中，您可以选择要安装的扩展和集成。使用顶部的搜索栏有助于过滤可用的扩展和集成。
- en: Tip
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Another way you can install extensions is by dragging and dropping them from
    the KNIME Hub.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过从 KNIME Hub 拖放扩展来安装它们。
- en: 'To install the Keras and TensorFlow nodes that will be used in the case studies
    described in this book, you need to select the following:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 为了安装将在本书案例研究中使用的 Keras 和 TensorFlow 节点，您需要选择以下内容：
- en: '**KNIME Deep Learning – Keras Integration**'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**KNIME 深度学习 - Keras 集成**'
- en: '**KNIME Deep Learning – TensorFlow Integration**'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**KNIME 深度学习 - TensorFlow 集成**'
- en: Then, press the **Next** button, accept the terms and conditions, and click
    **Finish**. Once the installation is done, you need to restart KNIME Analytics
    Platform.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，按下 **下一步** 按钮，接受条款和条件，并点击 **完成**。安装完成后，您需要重新启动 KNIME Analytics Platform。
- en: 'At this point, you should have the Keras and TensorFlow nodes in your Node
    Repository (*Figure 1.19*):'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你应该在节点库中看到 Keras 和 TensorFlow 节点（*图 1.19*）：
- en: '![Figure 1.19 – Installed deep learning nodes in the Node Repository](img/B16391_01_019.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.19 – 节点库中已安装的深度学习节点](img/B16391_01_019.jpg)'
- en: Figure 1.19 – Installed deep learning nodes in the Node Repository
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.19 – 节点库中已安装的深度学习节点
- en: 'A large number of nodes implement neural layers: the nodes for input and dropout
    layers can be found in the **Core** sub-category, the nodes for LSTM layers can
    be found in **Recurrent**, and the nodes for embedding layers can be found in
    **Embedding**. Then, there are the Learner, Reader, and Writer nodes, which can
    be used to train, load, and store a network, respectively. All these nodes have
    a configuration window and don''t require any coding. The Python deep learning
    nodes allow you to define, train, execute, and edit networks using Python code.
    The last subcategory contains TensorFlow-based nodes.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 很多节点实现了神经网络层：输入层和丢弃层的节点可以在 **Core** 子类别中找到，LSTM 层的节点可以在 **Recurrent** 中找到，嵌入层的节点可以在
    **Embedding** 中找到。然后，还有用于训练、加载和存储网络的学习器（Learner）、读取器（Reader）和写入器（Writer）节点。这些节点都有配置窗口，并且不需要编写代码。Python
    深度学习节点允许你使用 Python 代码定义、训练、执行和编辑网络。最后一个子类别包含基于 TensorFlow 的节点。
- en: Next, we need to set up the Python environment.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要设置 Python 环境。
- en: Setting up the Python Environment
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 Python 环境
- en: The KNIME Keras Integration and the KNIME TensorFlow Integration depend on an
    existing **Python** installation, which requires certain Python dependencies to
    be installed.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME Keras 集成和 KNIME TensorFlow 集成依赖于现有的 **Python** 安装，这需要安装一些 Python 依赖项。
- en: Similar to the KNIME Python Integration, the KNIME Deep Learning Integration
    uses **Anaconda** to manage Python environments. If you have already installed
    Anaconda for, for example, the KNIME Python Integration, you can skip the first
    step.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 与 KNIME Python 集成类似，KNIME 深度学习集成使用 **Anaconda** 来管理 Python 环境。如果你已经为 KNIME Python
    集成安装了 Anaconda（例如），你可以跳过第一步。
- en: 'Let''s get started:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧：
- en: First, get and install the latest Anaconda version (Anaconda ≥ 2019.03, conda
    ≥ 4.6.2) from [https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual).
    On the Anaconda download page, you can choose between Anaconda with Python 3.x
    or Python 2.x. Either one should work (if you're not sure, we suggest selecting
    Python 3).
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，从 [https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual)
    获取并安装最新版本的 Anaconda（Anaconda ≥ 2019.03，conda ≥ 4.6.2）。在 Anaconda 下载页面，你可以选择 Python
    3.x 或 Python 2.x 的版本。两者都可以使用（如果不确定，建议选择 Python 3）。
- en: 'Next, we need to create an environment with the correct libraries installed.
    To do so, from within KNIME Analytics Platform, open the Python Deep Learning
    preferences. From here, do the following:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建一个包含正确库的环境。为此，在 KNIME Analytics Platform 中打开 Python 深度学习偏好设置。然后，执行以下操作：
- en: First, select **File -> Preferences** from the top menu. This will open a new
    dialog with a list on the left.
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，从顶部菜单中选择 **文件 -> 偏好设置**。这将打开一个新对话框，左侧会列出相关选项。
- en: From the dialog, select **KNIME** **-> Python Deep Learning**.
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在对话框中，选择 **KNIME** **-> Python Deep Learning**。
- en: 'You should now see a dialog like that in *Figure 1.20*:'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你现在应该会看到一个像 *图 1.20* 中那样的对话框：
- en: '![Figure 1.20 – Python Deep Learning preference page](img/B16391_01_020.jpg)'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.20 – Python 深度学习偏好页面](img/B16391_01_020.jpg)'
- en: Figure 1.20 – Python Deep Learning preference page
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.20 – Python 深度学习偏好页面
- en: From this page, create some Conda environments with the correct packages installed
    for Keras or TensorFlow 2\. For the case studies in this book, it will be sufficient
    to set up an environment for Keras.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从此页面，可以创建一些 Conda 环境，并安装适用于 Keras 或 TensorFlow 2 的正确包。对于本书中的案例研究，设置一个适用于 Keras
    的环境就足够了。
- en: To create and set up a new environment, enable **Use special Deep Learning configuration**
    and set **Keras** to **Library used for DL Python**. Next, enable **Conda** and
    provide the path to your Conda installation directory.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要创建并设置新环境，启用 **使用特殊的深度学习配置**，并将 **Keras** 设置为 **用于 DL Python 的库**。接下来，启用 **Conda**
    并提供 Conda 安装目录的路径。
- en: In addition, to create a new environment for Keras, click on the **New environment…**
    button in the Keras framework.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，要为 Keras 创建新环境，点击 Keras 框架中的 **新建环境…** 按钮。
- en: 'This opens a new dialog, as in *Figure 1.21*, where you can set the new environment''s
    name:'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将打开一个新的对话框，如 *图 1.21* 所示，你可以在此设置新环境的名称：
- en: '![Figure 1.21 – Dialog for setting the new environment''s name](img/B16391_01_021.jpg)'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 1.21 – 设置新环境名称的对话框](img/B16391_01_021.jpg)'
- en: Figure 1.21 – Dialog for setting the new environment's name
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.21 – 设置新环境名称的对话框
- en: Click on the **Create new CPU environment** or **Create new GPU environment**
    button to create a new environment for using either a CPU or GPU, if available.
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击**创建新的 CPU 环境**或**创建新的 GPU 环境**按钮，可以为使用 CPU 或 GPU（如果有的话）创建一个新环境。
- en: 'Now, you can get started. In this section, you were introduced to the most
    convenient way of setting up a Python environment. Other options can be found
    in the KNIME documentation: [https://docs.knime.com/2019-06/deep_learning_installation_guide/index.html#keras-integration](https://docs.knime.com/2019-06/deep_learning_installation_guide/index.html#keras-integration).'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以开始了。在本节中，您已经介绍了设置 Python 环境的最便捷方式。其他选项可以在 KNIME 文档中找到：[https://docs.knime.com/2019-06/deep_learning_installation_guide/index.html#keras-integration](https://docs.knime.com/2019-06/deep_learning_installation_guide/index.html#keras-integration)。
- en: Goal and Structure of this Book
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书的目标与结构
- en: In this book, our aim is to provide you with a strong theoretical basis about
    deep learning architectures and training paradigms, as well as some detailed codeless
    experience of their implementations for solving practical case studies based on
    real-world data.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们的目标是为您提供关于深度学习架构和训练范式的坚实理论基础，以及一些基于真实世界数据解决实际案例研究的详细无代码体验。
- en: For this journey, we have adopted the codeless tool, KNIME Analytics Platform.
    KNIME Analytics Platform is based on visual programming and exploits a user-friendly
    GUI to make data analytics a more affordable task without the barrier of coding.
    As with many other external extensions, KNIME Analytics Platform has integrated
    the Keras libraries under this same GUI, thus including deep learning as part
    of its list of codeless extensions. From within KNIME Analytics Platform, you
    can build, train, and test a deep learning architecture with just a few drag and
    drops and a few clicks of the mouse. We provided a little introduction to the
    tool in this chapter, but we will provide more detailed information about it in
    [*Chapter 2*](B16391_02_Final_SK_ePUB.xhtml#_idTextAnchor051), *Data Access and
    Preprocessing with KNIME Analytics Platform*.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这一旅程，我们采用了无代码工具 KNIME Analytics 平台。KNIME Analytics 平台基于可视化编程，并利用用户友好的 GUI，使数据分析成为一项更经济的任务，无需编程障碍。与许多其他外部扩展一样，KNIME
    Analytics 平台在相同的 GUI 下集成了 Keras 库，从而将深度学习纳入其无代码扩展列表。在 KNIME Analytics 平台内，您只需拖放几下和鼠标几次点击，即可构建、训练和测试深度学习架构。我们在本章中对该工具进行了简要介绍，但在[*第
    2 章*](B16391_02_Final_SK_ePUB.xhtml#_idTextAnchor051)中，我们将提供更详细的信息，*使用 KNIME Analytics
    平台进行数据访问和预处理*。
- en: After that, in [*Chapter 3*](B16391_03_Final_PG_ePUB.xhtml#_idTextAnchor073),
    *Getting Started with Neural Networks*, we will provide a quick overview of the
    basic concepts behind neural networks and deep learning. This chapter will by
    no means provide complete coverage of all the architectures and paradigms involved
    in neural networks and deep learning. Instead, it will provide a quick overview
    of them to help you familiarize yourself with the concept, either for the first
    time or again, before you continue implementing them. Please refer to more specialized
    literature if you want to know more about the mathematical background of deep
    learning.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，在[*第 3 章*](B16391_03_Final_PG_ePUB.xhtml#_idTextAnchor073)，*开始使用神经网络*，我们将快速概述神经网络和深度学习背后的基本概念。本章将绝不会完全涵盖所有涉及神经网络和深度学习的架构和范式。相反，它将为您提供一个快速概述，帮助您在继续实施之前，第一次或再次熟悉这些概念。如果您想了解更多关于深度学习的数学背景，请参考更专业的文献。
- en: As we stated previously, we decided to talk about deep learning techniques in
    a very practical way; that is, always with reference to real case studies where
    a particular deep learning technique had been successfully implemented. We'll
    start this trend in [*Chapter 4*](B16391_04_Final_NM_ePUB.xhtml#_idTextAnchor101),
    *Building and Training a Feedforward Network*, where we'll describe a few basic
    example applications we can use to train and apply the basic concepts surrounding
    deep learning networks that we explored in [*Chapter 3*](B16391_03_Final_PG_ePUB.xhtml#_idTextAnchor073),
    *Getting Started with Neural Networks*. Although these are simple toy examples,
    they are still useful for illustrating how to apply the theoretical concepts we
    described in the previous chapter.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所述，我们决定以非常实际的方式讨论深度学习技术；也就是说，总是通过参考真实的案例研究，展示某种深度学习技术如何成功实施。我们将在[*第4章*](B16391_04_Final_NM_ePUB.xhtml#_idTextAnchor101)《构建与训练前馈网络》中开始这一趋势，在这一章中，我们将描述一些基本的示例应用，用以训练并应用我们在[*第3章*](B16391_03_Final_PG_ePUB.xhtml#_idTextAnchor073)《神经网络入门》中探讨的深度学习网络的基本概念。尽管这些只是简单的玩具示例，但它们仍然对于阐明如何应用我们在前一章中描述的理论概念非常有用。
- en: With [*Chapter 5*](B16391_05_Final_NM_ePUB.xhtml#_idTextAnchor152), *Autoencoder
    for Fraud Detection*, we'll start looking at real case studies. The first case
    study we'll describe in this chapter aims to prevent fraud detection in credit
    card transactions by firing an alarm every time a suspicious transaction is detected.
    To implement this subspecies of anomaly detection, we'll use an approach based
    on the autoencoder architecture, as well as the calculated distance between the
    output and the input values of the network.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第5章*](B16391_05_Final_NM_ePUB.xhtml#_idTextAnchor152)《用于欺诈检测的自编码器》中，我们将开始研究真实的案例研究。我们将在本章中描述的第一个案例研究旨在通过每次检测到可疑交易时触发警报，从而防止信用卡交易中的欺诈行为。为了实现这一种异常检测子类，我们将采用基于自编码器架构的方法，以及网络输出与输入值之间计算出的距离。
- en: 'With [*Chapter 5*](B16391_05_Final_NM_ePUB.xhtml#_idTextAnchor152), *Autoencoder
    for Fraud Detection*, we are still in the realm of classic neural networks, including
    feedforward networks and those trained with backpropagation, albeit with an original
    architecture. In [*Chapter 6*](B16391_06_Final_VK_ePUB.xhtml#_idTextAnchor181),
    *Recurrent Neural Networks for Demand Prediction*, we''ll enter the realm of deep
    learning network with RNNs – specifically, with LSTMs. Here, the dynamic character
    of such networks and their capability to capture the time evolution of a signal
    will be exploited to solve a classic time series analysis problem: demand prediction.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第5章*](B16391_05_Final_NM_ePUB.xhtml#_idTextAnchor152)《用于欺诈检测的自编码器》中，我们仍处于经典神经网络的范畴，包括前馈网络和通过反向传播训练的网络，尽管采用了原始架构。在[*第6章*](B16391_06_Final_VK_ePUB.xhtml#_idTextAnchor181)《用于需求预测的循环神经网络》中，我们将进入深度学习网络的领域，具体来说是使用RNN，尤其是LSTM。在这里，我们将利用此类网络的动态特性及其捕捉信号时间演变的能力来解决一个经典的时间序列分析问题：需求预测。
- en: 'Upon introducing RNNs, we will learn how to use them for **Natural Language
    Processing** (**NLP**) case studies. [*Chapter 7*](B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230),
    *Implementing NLP Applications*, covers a few such NLP use cases: sentiment analysis,
    free text generation, and product name generation, to name a few. All such use
    cases are similar in the sense that they analyze streams of text. All of them
    are also slightly different in that they find a solution to a different problem:
    classification for sentiment analysis for the former case, and unconstrained generation
    of sequences of words or characters for the other two use cases. Nevertheless,
    data preparation techniques and RNN architectures are similar for all case studies,
    which is why they have been placed into one single chapter.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍RNN后，我们将学习如何将其应用于**自然语言处理**（**NLP**）案例研究。[*第7章*](B16391_07_Final_NM_ePUB.xhtml#_idTextAnchor230)《实现NLP应用》中涵盖了几个这样的NLP用例：情感分析、自由文本生成和产品名称生成等等。所有这些用例在某种意义上是相似的，因为它们都分析文本流。它们也有所不同，因为它们解决的是不同的问题：前者的情感分析是分类任务，而后两者则是对词语或字符序列的无约束生成。然而，数据准备技术和RNN架构对于所有的案例研究来说都是相似的，这就是为什么它们被放在同一章中的原因。
- en: '[*Chapter 8*](B16391_08_Final_SK_ePUB.xhtml#_idTextAnchor290), *Neural Machine
    Translation*, describes a spin-off case of free text generation with RNNs. Here,
    a sequence of words will be generated at the output of the network as a response
    to a corresponding sequence of words in the input layer. The output sequence will
    be generated in the target language, while the input sequence will be provided
    in the source language.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第8章*](B16391_08_Final_SK_ePUB.xhtml#_idTextAnchor290)，*神经机器翻译*，描述了一个基于RNN的自由文本生成案例。在这里，网络的输出端会根据输入层中相应的词序列生成一段词序列。输出序列将以目标语言生成，而输入序列则以源语言提供。'
- en: Deep learning does not just come in the form of RNNs and text mining. Actually,
    the first examples of deep learning networks came from the field of image processing.
    [*Chapter 9*](B16391_09_Final_NM_ePUB.xhtml#_idTextAnchor316), *Convolutional
    Neural Networks for Image Classification*, is dedicated to describing a case study
    where histopathology slide images must be classified as one of three different
    types of cancer. To do that, we will introduce CNNs. Training networks for image
    analysis is not a simple task in terms of time, the amount of data, and computational
    resources. Often, to train a neural network so that it recognizes images, we must
    rely on the benefits of transfer learning, as described in [*Chapter 9*](B16391_09_Final_NM_ePUB.xhtml#_idTextAnchor316),
    *Convolutional Neural Networks for Image Classification*, as well.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习不仅仅是RNN和文本挖掘的形式。实际上，深度学习网络的最初实例来源于图像处理领域。[*第9章*](B16391_09_Final_NM_ePUB.xhtml#_idTextAnchor316)，*用于图像分类的卷积神经网络*，专门描述了一个案例研究，其中需要将组织病理切片图像分类为三种不同类型的癌症之一。为此，我们将介绍CNN。训练用于图像分析的网络在时间、数据量和计算资源方面并非易事。通常，为了训练一个神经网络使其能够识别图像，我们必须依赖于迁移学习的优势，正如[*第9章*](B16391_09_Final_NM_ePUB.xhtml#_idTextAnchor316)，*用于图像分类的卷积神经网络*中所描述的那样。
- en: '[*Chapter 9*](B16391_09_Final_NM_ePUB.xhtml#_idTextAnchor316), *Convolutional
    Neural Networks for Image Classification*, concludes our in-depth look into how
    deep learning techniques can be implemented for real case studies. We are aware
    of the fact that other deep learning paradigms have been used to produce solutions
    for other data science problems. However, here, we decided to only report the
    common paradigms in which we had real-life experiences.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第9章*](B16391_09_Final_NM_ePUB.xhtml#_idTextAnchor316)，*用于图像分类的卷积神经网络*，总结了我们深入探讨的深度学习技术在实际案例中的应用。我们意识到，其他深度学习范式也被用于解决其他数据科学问题。然而，在此我们决定仅报告我们有实际经验的常见范式。'
- en: 'After training a network, the deployment phase must take place. Deployment
    is often conveniently forgotten since this is the phase where all problems are
    put to the test. This includes errors in the application''s design, in training
    the network, in accessing and preparing the data: all of them will show up here,
    during deployment. Due to this, the last two chapters of this book are dedicated
    to the deployment phase of trained deep learning networks.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完网络后，必须进入部署阶段。由于这是所有问题都会暴露的阶段，因此部署阶段经常被忽略。这包括应用程序设计中的错误、网络训练中的错误、数据访问和准备中的错误：所有这些问题都会在此阶段显现出来。因此，本书的最后两章专门讨论了训练深度学习网络的部署阶段。
- en: '[*Chapter 10*](B16391_10_Final_VK_ePUB.xhtml#_idTextAnchor367), *Deploying
    a Deep Learning Network*, will show you how to build a deployment application,
    while [*Chapter 11*](B16391_11_Final_NM_ePUB.xhtml#_idTextAnchor386), *Best Practices
    and Other Deployment Options*, will show you all the deployment options that are
    available (a web application or a REST service). It will also provide you with
    a few tips and tricks from our own experience.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第10章*](B16391_10_Final_VK_ePUB.xhtml#_idTextAnchor367)，*部署深度学习网络*，将向你展示如何构建部署应用程序，而[*第11章*](B16391_11_Final_NM_ePUB.xhtml#_idTextAnchor386)，*最佳实践及其他部署选项*，则将展示所有可用的部署选项（如网页应用或REST服务）。它还将为你提供一些我们自身经验中的小贴士和技巧。'
- en: Each chapter comes with its own set of questions so that you can test your understanding
    of the material that's been provided.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 每一章后都有相应的问题，帮助你测试自己对所学内容的理解。
- en: With that, please read on to discover the various deep learning architectures
    that can be applied to real use cases using KNIME Analytics Platform.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在此，请继续阅读，了解如何使用KNIME Analytics Platform将各种深度学习架构应用于实际案例。
- en: Summary
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This first chapter aimed to prepare you for the content provided in this book.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目的是为你提供本书内容的预备知识。
- en: Thus, we started this chapter by reminding you of the importance of deep learning,
    as well as the surge in popularity it garnered following the first deep learning
    success stories. Such a surge in popularity is probably what brought you here,
    with the desire to learn more about practical implementations of deep learning
    networks for real use cases.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们通过提醒你深度学习的重要性以及它在第一次深度学习成功案例之后获得的广泛关注来开始本章。这种关注的激增可能正是将你吸引到这里的原因，带着对深度学习网络在实际应用中实现的更多了解的渴望。
- en: Nowadays, the main barrier that we come across when learning about deep learning
    is the coding skills that are required. Here, we adopted KNIME software, and in
    particular the open source KNIME Analytics Platform, so that we can look at the
    case studies that will be proposed throughout this book. To do this, we described
    KNIME software and KNIME Analytics Platform in detail.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们在学习深度学习时遇到的主要障碍是所需的编程技能。在这里，我们采用了 KNIME 软件，特别是开源的 KNIME Analytics Platform，以便我们可以查看本书中提出的案例研究。为此，我们详细描述了
    KNIME 软件和 KNIME Analytics Platform。
- en: KNIME Analytics Platform also benefits from an extension known as KNIME Deep
    Learning – Keras Integration, which helps with integrating Keras deep learning
    libraries. It does this by wrapping Python-based libraries into the codeless KNIME
    GUI. We dedicated a full section to installing it.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: KNIME Analytics Platform 还受益于一个名为 KNIME Deep Learning – Keras Integration 的扩展，它帮助整合
    Keras 深度学习库。它通过将基于 Python 的库封装到无代码的 KNIME 图形用户界面中来实现这一点。我们专门为此安装过程提供了一个完整的章节。
- en: Finally, we concluded this chapter by providing an overview of what the remaining
    chapters in this book will cover.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过概述本书剩余章节的内容来结束本章。
- en: Before we dive into the math and applications of deep learning networks, we
    will use the next chapter to familiarize ourselves with the basic features of
    KNIME Analytics Platform.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨深度学习网络的数学和应用之前，我们将在下一章中先熟悉 KNIME Analytics Platform 的基本功能。
