- en: GANs - Attacks and Defenses
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GANs - 攻击与防御
- en: '**Generative adversarial networks** (**GANs**) represent the most advanced
    example of neural networks that deep learning makes available to us in the context
    of cybersecurity. GANs can be used for legitimate purposes, such as authentication
    procedures, but they can also be exploited to violate these procedures.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成对抗网络**（**GANs**）代表了深度学习在网络安全领域为我们提供的最先进的神经网络示例。GANs可以用于合法目的，如身份验证程序，但它们也可以被利用来破坏这些程序。'
- en: 'In this chapter, we will look at the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: The fundamental concepts of GANs and their use in attack and defense scenarios
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GANs的基本概念及其在攻击和防御场景中的应用
- en: The main libraries and tools for developing adversarial examples
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发对抗样本的主要库和工具
- en: Attacks against **deep neural networks** (**DNNs**) via model substitution
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过模型替代对**深度神经网络**（**DNNs**）的攻击
- en: Attacks against **intrusion detection systems** (**IDS**) via GANs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 GANs 对**入侵检测系统**（**IDS**）的攻击
- en: Attacks against facial recognition procedures using adversarial examples
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用对抗样本对面部识别程序的攻击
- en: We will now begin the chapter by introducing the basic concepts of GANs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将通过介绍GANs的基本概念开始本章内容。
- en: GANs in a nutshell
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GANs 简述
- en: GANs were theorized in a famous paper that dates back to 2014 ([https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)),
    written by a team of researchers including Ian Goodfellow and Yoshua Bengio, which
    described the potential and characteristics of a special category of adversarial
    processes, called GANs.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: GANs在2014年发表的一篇著名论文中被提出（[https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)），该论文由包括Ian
    Goodfellow和Yoshua Bengio在内的研究团队撰写，描述了一种特殊类型对抗过程的潜力和特点，这种过程被称为GANs。
- en: The basic idea behind GANs is simple, as they consist of putting two neural
    networks in competition with one another, until a balanced condition of results
    is achieved; however at the same time, the possibilities of using these intuitions
    are almost unlimited, since GANs are able to learn how to imitate and artificially
    reproduce any data distribution, whether it represents faces, voices, texts, or
    even works of art.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: GANs背后的基本思想很简单，它们通过让两个神经网络相互竞争，直到达到一个平衡的结果条件；然而，与此同时，利用这些直觉的可能性几乎是无限的，因为GANs能够学习如何模仿并人工重现任何数据分布，无论是面孔、声音、文本，还是甚至是艺术作品。
- en: In this chapter, we will extend the use of GANs in the field of cybersecurity,
    learning how it is possible to use them to both carry out attacks (such as attacks
    against security procedures based on the recognition of biometric evidences) and
    to defend neural networks from attacks conducted through GANs. In order to fully
    understand the characteristics and potential of GANs, we need to introduce a number
    of fundamental concepts concerning **neural networks** (**NNs**) and **deep learning**
    (**DL**).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将扩展生成对抗网络（GANs）在网络安全领域的应用，了解如何利用它们同时进行攻击（例如针对基于生物特征识别的安全程序的攻击）以及保护神经网络免受通过GANs进行的攻击。为了全面理解GANs的特点和潜力，我们需要介绍一些关于**神经网络**（**NNs**）和**深度学习**（**DL**）的基本概念。
- en: A glimpse into deep learning
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习概述
- en: We have already encountered NNs in [Chapter 4](3311e837-18a2-4a50-8322-f7b9c12bcbc8.xhtml),
    *Malware Threat Detection*, and [Chapter 6](f467340a-244d-4714-8a39-68b230db2404.xhtml),
    *Securing User Authentication*, and now, we will extend the topic further by treating
    DL in a more systematic way. DL is a branch of **machine learning** (**ML**) that
    aims to emulate the cognitive abilities of the human brain in an attempt to perform
    those typically higher-level human tasks characterized by high complexity, such
    as facial recognition and speech recognition. DL therefore seeks to emulate the
    behavior of the human brain by introducing networks based on artificial neurons
    that are stratified on multiple levels and connected to one another, and that
    are characterized by a more or less high degree of depth which is where the **deep**
    adjective in the phrase deep learning has its origins.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第4章](3311e837-18a2-4a50-8322-f7b9c12bcbc8.xhtml)《恶意软件威胁检测》和[第6章](f467340a-244d-4714-8a39-68b230db2404.xhtml)《保护用户身份验证》中已经遇到过神经网络（NN）。现在，我们将通过更加系统化的方式进一步探讨深度学习（DL）。深度学习是**机器学习**（**ML**）的一个分支，旨在模仿人脑的认知能力，试图执行那些典型的高复杂度人类任务，如面部识别和语音识别。因此，深度学习旨在通过引入基于人工神经元的网络来模拟人脑的行为，这些神经元分布在多个层级并相互连接，并且这些层次的深度可以高或低，这也是“深度学习”这一术语中**深度**一词的由来。
- en: The concepts of DL and NNs are not new, but only in recent years have they found
    concrete practical, as well as theoretical, application, thanks to the progress
    achieved in the field of digital architectures, which have benefited from increased
    computational capacity, as well as the possibility of fully exploiting distributed
    computing through cloud computing, together with the almost unlimited availability
    of training data made possible by big data analytics.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习和神经网络的概念并不新鲜，但仅在近年来，得益于数字架构领域的进展，它们才找到了实际的理论与实践应用，这一进展得到了计算能力的提升、分布式计算通过云计算的充分利用以及大数据分析所带来的几乎无限的训练数据的支持。
- en: The potential of DL has been recognized not only in the research and business
    sector, but also in the field of cybersecurity, where it is increasingly essential
    to use solutions capable of dynamically adapting to changes in context, adopting
    not only static detection tools, but algorithms that are able to dynamically learn
    how to recognize new types of attacks autonomously, finding possible threats by
    analyzing the most representative features within the often noisy datasets.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的潜力不仅在研究和商业领域得到了认可，还在网络安全领域得到了广泛应用。在网络安全中，越来越需要使用能够动态适应环境变化的解决方案，这些解决方案不仅采用静态检测工具，还能够动态学习如何自动识别新型攻击的算法，进而通过分析数据集中的代表性特征来发现可能的威胁，尤其是在这些数据集往往是噪声较多的情况下。
- en: Compared to traditional ML, DL is also characterized by a greater complexity
    from a mathematical point of view, especially regarding its widespread use of
    calculus and linear algebra. However, compared to ML, DL is able to achieve much
    better results in terms of accuracy and the potential reuse of algorithms in different
    application sectors.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的机器学习（ML）相比，从数学角度来看，深度学习也具有更高的复杂性，尤其是在广泛使用微积分和线性代数方面。然而，与机器学习相比，深度学习能够在准确性和算法在不同应用领域的潜在重用方面取得更好的结果。
- en: Through the use of layers of NNs that are connected to one another, DL does
    not limit itself to analyzing the features of the original datasets, but is also
    able to recombine them by creating new ones, thereby adapting to the complexity
    of the analysis that is to be conducted.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用互相连接的神经网络（NN）层，深度学习不仅限于分析原始数据集的特征，还能够通过创建新的特征重新组合这些数据，从而适应所需进行的分析的复杂性。
- en: The layers of artificial neurons that constitute DL analyze the data and features
    received as input and share them with the various inner layers, and these, in
    turn, process the output data of the outer layers. In this way, the original features
    extracted from the datasets are recombined, giving rise to new features that are
    optimized for analysis.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 构成深度学习（DL）的人工神经网络层分析接收到的输入数据和特征，并将它们与各个内部层共享，这些内部层反过来处理外部层的输出数据。通过这种方式，从数据集中提取的原始特征被重新组合，产生新的特征，这些特征经过优化以供分析使用。
- en: The greater the number of internal layers that are interconnected, the greater
    the depth and ability to recombine the features and adapt to the complexity of
    the problem, thereby reducing it to more specific and more manageable subtasks.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 内部层之间的连接越多，深度和重新组合特征的能力越强，从而更好地适应问题的复杂性，将其分解为更具体、可管理的子任务。
- en: We have already mentioned that the constitutive elements of DL are the layers
    of NNs composed of artificial neurons. Now, we will examine the characteristics
    of these constituent elements in greater detail, starting with artificial neurons.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提到，深度学习（DL）的构成元素是由人工神经元组成的神经网络（NN）层。现在，我们将更详细地研究这些构成元素的特点，从人工神经元开始。
- en: Artificial neurons and activation functions
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工神经元和激活函数
- en: We have already encountered (in [Chapter 3](aaf59353-00b3-4625-8732-63aad02cc8e5.xhtml),
    *Ham or Spam? Detecting Email Cybersecurity Threats with AI*) a particular type
    of artificial neuron, Rosenblatt's Perceptron, and we have seen that this artificial
    neuron emulates the behavior of neurons in the human brain by activating itself
    in the presence of a positive signal beyond a threshold.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[第3章](aaf59353-00b3-4625-8732-63aad02cc8e5.xhtml)中遇到过一种特定类型的人工神经元——罗森布拉特的感知器，并且我们已经看到，这种人工神经元通过在超过阈值的正信号出现时自我激活，模拟了人类大脑中神经元的行为。
- en: 'To verify the presence of a positive signal beyond a threshold, a special function
    is used, known as the **activation** function, which, in the case of a Perceptron,
    has the following characteristics:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证阈值以上是否存在正信号，使用了一个特殊的函数，称为**激活**函数，在感知器的情况下，具有以下特点：
- en: '![](img/893080af-61b0-4cd9-9b91-d306614030ee.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/893080af-61b0-4cd9-9b91-d306614030ee.png)'
- en: In practice, if the product of the *wx* values—consisting of the input data
    multiplied by the corresponding weights—exceeds a certain threshold ![](img/ab446c36-e490-4d55-b41c-08b080a54fef.png),
    then the Perceptron is activated; otherwise, it remains inert. Therefore, the
    task of the activation function is precisely to activate or not activate the artificial
    neuron following the verification of certain conditions.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际应用中，如果*wx*值的乘积——即输入数据与相应权重的乘积——超过某个阈值 ![](img/ab446c36-e490-4d55-b41c-08b080a54fef.png)，则感知器被激活；否则，它保持静止。因此，激活函数的任务就是在验证某些条件后，决定是否激活人工神经元。
- en: Different types of activation functions are possible, but perhaps the most common
    is the **rectified linear unit** (**ReLU**), which, in its simplest version, entails
    assuming, as the activation value, the result obtained by applying the function
    *max(0, wx)* to the input values (multiplied by the respective weights).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数有不同的类型，但最常见的可能是**修正线性单元**（**ReLU**），在其最简单的版本中，假设将函数*max(0, wx)*应用于输入值（与相应的权重相乘），结果即为激活值。
- en: 'In formal terms, this can be expressed as the following equation:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从形式上看，这可以表示为以下方程：
- en: '![](img/6d82dfa4-04d7-4444-b1e5-8140e51eb28a.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6d82dfa4-04d7-4444-b1e5-8140e51eb28a.png)'
- en: 'There is also a variant known as *LeakyReLU,* as shown in the following equation:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种变体被称为*LeakyReLU*，如以下方程所示：
- en: '![](img/a7f0552e-90c4-4272-ac4e-d4f70f2b0947.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a7f0552e-90c4-4272-ac4e-d4f70f2b0947.png)'
- en: Unlike the plain ReLU, the leaky version of the activation function returns
    a softened value of the product *wx* (instead of *0*, for negative values ​​of
    *wx*), determined by the application of a multiplicative constant, ![](img/666e3062-4473-4fc6-99e6-256c9b4cd643.png),
    which usually assumes reduced values ​​close to *0* (but not equal to *0*).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 与普通ReLU不同，激活函数的泄漏版本返回的是*wx*的软化值（对于*wx*的负值，而不是*0*），这个值是通过应用乘法常数 ![](img/666e3062-4473-4fc6-99e6-256c9b4cd643.png)得到的，通常该常数的值较小，接近*0*（但不等于*0*）。
- en: From a mathematical point of view, the ReLU activation function represents a
    nonlinear transformation of a linear relationship consisting of the product of
    the input values ​​for their respective weights.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学角度看，ReLU激活函数代表了一种非线性变换，将输入值与各自权重的乘积关系转化为非线性关系。
- en: In this way, we are able to approximate any kind of behavior without having
    to limit ourselves to simple linear relationships. We mentioned this in [Chapter
    6](f467340a-244d-4714-8a39-68b230db2404.xhtml), *Securing User Authentication*,when
    we introduced the section titled *User detection with multilayer perceptrons*,
    showing how a **multilayer perceptron** (**MLP**), being made up of multiple layers
    of artificial neurons implemented by Perceptrons, is able to overcome the limitations
    of the single Perceptron, approximating any continuous mathematical function by
    introducing an adequate number of neurons in the neural network. This ability
    to approximate any continuous mathematical function is what characterizes neural
    networks, and this determines their power in terms of learning.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们能够逼近任何类型的行为，而不必将自己局限于简单的线性关系。我们在[第6章](f467340a-244d-4714-8a39-68b230db2404.xhtml)《确保用户身份验证》中提到过这一点，当时我们介绍了名为*用户检测与多层感知器*的章节，展示了如何通过**多层感知器**（**MLP**）——由多个人工神经元组成的感知器层——克服单一感知器的局限性，通过在神经网络中引入足够数量的神经元来逼近任何连续的数学函数。这种逼近任何连续数学函数的能力正是神经网络的特征，这也决定了它们在学习方面的强大能力。
- en: Now, let's see how we get to neural networks from individual artificial neurons.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何从单个人工神经元过渡到神经网络。
- en: From artificial neurons to neural networks
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从人工神经元到神经网络
- en: We have seen the characteristics of artificial neurons and the tasks performed
    by the activation functions. Now let's look more closely at the characteristics
    of NNs. NNs are made up of layers of neurons, which together form a network. NNs
    can also be interpreted as artificial neuron graphs in which a weight is associated
    with each connection.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了人工神经元的特性以及激活函数执行的任务。接下来，让我们更深入地了解神经网络的特性。神经网络由多层神经元组成，这些神经元共同构成一个网络。神经网络还可以解释为人工神经元图，每个连接都有一个权重。
- en: We have said that by adding an adequate number of neurons to the NNs, it is
    possible to emulate the behavior of any continuous mathematical function. In practice,
    NNs are nothing but an alternative way of representing mathematical functions
    of arbitrary complexity. The power of NNs manifests itself in their ability to
    assemble the original features extracted from the datasets by creating new ones.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经说过，通过向神经网络中添加足够数量的神经元，可以模拟任何连续数学函数的行为。实际上，神经网络不过是表示任意复杂度数学函数的一种替代方式。神经网络的强大之处在于它们能够通过创造新的特征来组装从数据集中提取的原始特征。
- en: Layers (hidden layers) are added to a neural network in order to perform such
    a combination of features. More layers are added, thereby enhancing the power
    of the network to generate new features. Particular attention must be given to
    the training procedure for NNs.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络中会增加（隐藏层）层，以便执行这种特征组合。随着层数的增加，网络生成新特征的能力也得到了增强。必须特别关注神经网络的训练过程。
- en: One of the most common approaches to training NNs is **forward propagation.**
    Training data is fed as input to the outer layers of the network, which, in turn,
    pass on their own partial processing output to the inner layers, and so on. The
    inner layers will carry out their elaborations on the input data received from
    the external layers, propagating the partial output returned from their processing
    forward to successive layers
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 训练神经网络的最常见方法之一是**前向传播**。训练数据作为输入被送入网络的外层，外层将它们的部分处理输出传递给内层，依此类推。内层将对来自外层的输入数据进行处理，并将它们处理后的部分输出继续传递给后续层。
- en: The processing carried out by the various layers usually entails evaluating
    the goodness of the weights associated with the individual predictions, based
    on the anticipated values. In the case of supervised learning, for example, we
    already know the expected values ​​of the labeled samples in advance, and adjust
    the weights accordingly, based on the chosen learning algorithm. This results
    in a series of calculations, usually represented by the partial derivatives of
    the parameters associated with the individual neurons of which the different layers
    are composed, to be performed iteratively within the individual layers, thus resulting
    in a considerable load in computational terms.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 各层所执行的处理通常包括根据预期值评估与单个预测相关的权重的好坏。例如，在监督学习的情况下，我们已经提前知道标记样本的预期值，并根据所选的学习算法调整权重。这将导致一系列计算，通常通过表示与各层神经元相关的参数的偏导数来表示，这些计算需要在各个层中迭代执行，从而在计算上带来了相当大的负担。
- en: As the number of layers in the NNs increases, the number of steps that the data
    must make within the network increases exponentially. To get an idea of this,
    just think of the number of paths taken by the output of a neuron that gets forwarded
    to an inner layer consisting of 100 neurons, whose output is then, in turn, propagated
    to another layer composed of as many as 100 neurons, and so on, until it reaches
    the outer layers of neurons that return the final network output.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 随着神经网络中层数的增加，数据在网络中需要经历的步骤数呈指数级增长。为了理解这一点，可以想象一个神经元的输出经过100个神经元组成的内部层后，继续传递到另一个由100个神经元组成的层，依此类推，直到到达返回最终网络输出的外层神经元。
- en: An alternative training strategy, which significantly reduces the computational
    load, involves **backpropagation**. Instead of propagating the partial outputs
    obtained from the single layers toward the subsequent layers, the final outputs
    are computed at the level of the individual layers by consolidating the values
    ​​obtained, by memorizing the outputs obtained at the individual layers. In this
    way, training is affected by propagating back the output of the entire network.
    Instead of the single outputs returned by the individual layers, the weights are
    updated accordingly to minimize the error rate.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一种替代的训练策略，显著降低了计算负担，涉及**反向传播**。与其将从单层获得的部分输出传递到后续层，不如在各个层级上通过整合所获得的值来计算最终输出，通过记忆各个层级获得的输出值。这样，训练就受到将整个网络的输出反向传播的影响。不同于各个层返回的单一输出，权重会根据需要更新，以最小化错误率。
- en: In mathematical terms, **backpropagation** is as a product of the **matrices**
    and **vectors** (which is less demanding in computational terms), rather than
    of a **matrix**–**matrix multiplication**, as in the case of forward propagation
    (for further details, refer to *Python Machine Learning – Second Edition*, by
    Sebastian Raschka, Packt Publishing).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从数学角度看，**反向传播**是作为**矩阵**和**向量**的乘积（在计算上要求较低），而不是像前向传播那样进行**矩阵**–**矩阵乘法**（更多细节请参阅*Python机器学习——第二版*，作者：Sebastian
    Raschka，Packt出版）。
- en: 'Now, let''s look at some of the most common types of NNs:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下最常见的几种神经网络类型：
- en: '**Feedforward neural networks (FFNNs)**: FFNNs represent the basic typology
    of NNs. The individual layers of neurons are connected to some (or all) of the
    neurons present in the next layer. The peculiarity of FFNNs is that the connections
    between the neurons of the individual layers go only in one direction, and there
    are no cyclical or backward connections.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前馈神经网络（FFNNs）**：FFNNs代表了神经网络（NNs）的基本类型。每一层的神经元与下一层的一些（或所有）神经元相连接。FFNNs的特点是各层之间的连接仅朝一个方向进行，并且没有循环或反向连接。'
- en: '**Recurrent neural network (RNNs)**: These networks are characterized by the
    fact that the connections between neurons take the form of directed cycles in
    which the inputs and outputs consist of time series. RNNs facilitate the identification
    of patterns within the data as the data is accumulated and analyzed, and are therefore
    particularly useful for performing dynamic tasks such as speech recognition and
    language translation. In cybersecurity, RNNs are widely used in network traffic
    analysis, in static analysis, and so on. One example of an RNN is **long short-term
    memory** (**LSTM**) networks.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**循环神经网络（RNNs）**：这些网络的特点是神经元之间的连接形成有向循环，输入和输出都是时间序列。随着数据的积累和分析，RNNs有助于识别数据中的模式，因此特别适用于执行动态任务，如语音识别和语言翻译。在网络流量分析和静态分析中，RNNs在网络安全领域被广泛使用。一个RNN的例子是**长短期记忆（LSTM）**网络。'
- en: '**Convolutional neural networks** (**CNNs**): These networks are particularly used
    to perform image-recognition tasks. CNNs are characterized by their ability to
    identify the presence of specific features within the data. The layers that make
    up the CNNs are associated with specific filters that represent the features of
    interest (such as, for example, a set of pixels representing digits within an
    image). These filters have the characteristic of being **invariant** with respect
    to the translations in space, thereby enabling the presence of features of interest
    in different areas of the search space to be detected (for example, the presence
    of the same digit in different areas of the image). The typical architecture of
    a CNN includes a series of **convolution layers**, **activation layers**, **pooling
    layers**, and **fully connected layers**. The pooling layer has the function of
    reducing the size of the features of interest to facilitate the search for the
    presence of the features within the search space. The following diagram shows
    CNN filters in action, within the different layers:'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积神经网络（CNNs）**：这些网络特别用于执行图像识别任务。CNNs的特点是能够识别数据中特定特征的存在。构成CNNs的层与特定的过滤器相关联，这些过滤器表示感兴趣的特征（例如，表示图像中数字的一组像素）。这些过滤器具有相对于空间平移不变的特性，从而能够检测到搜索空间中不同区域中的感兴趣特征的存在（例如，在图像的不同区域中相同数字的存在）。CNN的典型架构包括一系列**卷积层**、**激活层**、**池化层**和**全连接层**。池化层的功能是减小感兴趣特征的大小，以便在搜索空间内查找这些特征。'
- en: '![](img/d71eec3a-9d49-4bce-b136-d5c5f45cfc91.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d71eec3a-9d49-4bce-b136-d5c5f45cfc91.png)'
- en: '(*Image credits: https://commons.wikimedia.org/wiki/File:3_filters_in_a_Convolutional_Neural_Network.gif*)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: （*图片来源：https://commons.wikimedia.org/wiki/File:3_filters_in_a_Convolutional_Neural_Network.gif*）
- en: Following this quick review of NNs, we are now ready to get acquainted with
    GANs.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这对神经网络的快速回顾之后，我们现在准备认识GANs。
- en: Getting to know GANs
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 认识GANs
- en: We have said that the intuition on which GANs are based entails putting two
    NNs in competition with one another in order to improve the overall results. The
    term **adversarial** refers specifically to the fact that the two NNs compete
    between themselves in completing their respective tasks. The outcome of this competition
    is an overall result that cannot be further improved, thereby attaining an equilibrium
    condition.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提到，GANs的基本直觉是让两个神经网络相互竞争，以改进总体结果。术语**对抗**特指这两个神经网络在完成各自任务时相互竞争。这种竞争的结果是一个无法进一步改进的整体结果，从而达到平衡条件。
- en: A typical example of using GANs is the implementation of a particular NN, called
    a **generative network**, with the task of creating an artificial image that simulates
    the characteristics of a real image. A second NN, called the **discriminator network**,
    is placed in competition with the first one (the generator) in order to distinguish
    the artificially simulated image from the real one.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GANs的典型例子是实现一个名为**生成网络**的特定神经网络，其任务是创建模拟真实图像特征的人工图像。第二个神经网络称为**判别网络**，与生成网络竞争，以区分人工模拟图像与真实图像。
- en: An interesting aspect is the fact that the two networks collaborate in achieving
    a situation of equilibrium (condition of indifference), putting in competition
    with one another the optimization of their respective objective functions. The
    generator network bases its optimization process on its ability to deceive the
    discriminator network.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有趣的方面是，这两个网络通过实现一种平衡状态（无差异状态）进行协作，它们各自的目标函数优化彼此竞争。生成网络将其优化过程建立在欺骗判别网络的能力上。
- en: The discriminator network, in turn, carries out its optimization process, based
    on the accuracy achieved in distinguishing the real image from the artificially
    generated image from the generator network. Now, let's look at the differences
    between the two NNs in more detail.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 判别网络则基于在区分真实图像和由生成网络人工生成的图像时所达到的准确度，执行其优化过程。现在，让我们更详细地看一下这两个神经网络之间的差异。
- en: Generative versus discriminative networks
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成网络与判别网络
- en: One way to intuitively understand the different tasks associated with individual
    NNs involved in a GAN is to consider the scenario in which the discriminator network
    tries to correctly classify spam messages artificially generated by the generator
    network. To demonstrate the different objective functions that the individual
    NNs must optimize, we will resort to conditional probabilities (which are the
    basis of the Bayes' rule), which we have already encountered in [Chapter 3](aaf59353-00b3-4625-8732-63aad02cc8e5.xhtml), *Ham
    or Spam? Detecting Email Cybersecurity Threats with AI*, in the section *Spam
    detection with Naive Bayes*.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 理解生成对抗网络（GAN）中各个神经网络（NN）任务的一种直观方式是考虑这样一个场景：判别网络试图正确分类由生成网络人工生成的垃圾邮件。为了展示每个神经网络必须优化的不同目标函数，我们将借助条件概率（这是贝叶斯定理的基础），这一概念我们已经在[第3章](aaf59353-00b3-4625-8732-63aad02cc8e5.xhtml)，*垃圾邮件还是正常邮件？利用人工智能检测电子邮件网络安全威胁*一节中的*朴素贝叶斯垃圾邮件检测*部分遇到过。
- en: We define ***P***(***S***|***W***) as the probability that a given email message
    represents spam (***S***), based on the presence within the text of occurrences
    of suspect words (***W***). The task of the discriminator network therefore entails
    correctly estimating the probability ***P***(***S***|***W***) associated with
    each single email analyzed.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义***P***(***S***|***W***)为给定电子邮件消息表示垃圾邮件（***S***）的概率，该概率基于文本中出现可疑词汇（***W***）。因此，判别网络的任务是正确估计与每封分析过的电子邮件相关的概率***P***(***S***|***W***).
- en: 'Symmetrically, the task of the generative network is the opposite: namely,
    to estimate the probability ***P***(***W***|***S***)—that is, given a spam message,
    how conceivable it is that the text contains the occurrences of the suspect words
    (***W***). You will recall from the theory of conditional probabilities that the
    value ***P***(***S***|***W***) is different from the value ***P***(***W***|***S***),
    so the two neural networks have different objective functions to optimize, even
    if they are correlated.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对称地，生成网络的任务正好相反：即估计概率***P***(***W***|***S***)——也就是说，给定一条垃圾邮件，文本中包含可疑词汇（***W***）的可能性有多大。你会从条件概率理论中回忆到，***P***(***S***|***W***)的值与***P***(***W***|***S***)的值不同，因此这两个神经网络有不同的目标函数需要优化，即使它们是相关的。
- en: The discriminator network will therefore seek to optimize its objective function,
    which involves estimating appropriately the probability ***P***(***S***|***W***) by
    correctly classifying the spam messages artificially generated by the generative
    network, which in turn optimizes its objective function by generating spam email messages based
    on the probability ***P***(***W***|***S***) associated with each message. The
    generator network will then try to simulate spam messages, trying to deceive the
    discriminator network. At the same time, the discriminator network tries to correctly
    identify authentic spam messages, distinguishing them from those artificially
    created by the generator network by comparing them against the samples of genuine
    spam messages previously classified.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，判别网络将寻求优化其目标函数，该函数涉及通过正确分类由生成网络人工生成的垃圾邮件，来适当地估计概率***P***(***S***|***W***)，而生成网络通过根据每条邮件的概率***P***(***W***|***S***)生成垃圾邮件，从而优化其目标函数。生成网络接着将尝试模拟垃圾邮件，试图欺骗判别网络。同时，判别网络则试图正确识别真实的垃圾邮件，将其与生成网络人工创建的邮件区分开来，通过与先前已分类的真实垃圾邮件样本进行比较。
- en: Both networks learn from mutual interaction. The fake spam messages generated
    by the generative network are passed as input to the discriminative network, which
    analyzes them together with real spam messages, progressively refining the estimate
    of the probability constituted by the ***P***(***S***|***W***)  estimated value.
    This establishes a symbiotic relationship  between the two neural networks, in
    which both networks try to optimize their opposite objective functions.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 两个网络通过相互作用进行学习。生成网络生成的虚假垃圾邮件被作为输入传递给判别网络，判别网络将它们与真实垃圾邮件一起分析，逐步细化由***P***(***S***|***W***)
    估计值组成的概率估计。这建立了两个神经网络之间的共生关系，在这种关系中，两个网络都试图优化各自的对立目标函数。
- en: This situation is defined by game theory as a **zero-sum game**, and the dynamic
    equilibrium that is progressively reached, which puts an end to the optimization
    process of both networks, is known as the **Nash equilibrium**.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况被博弈论定义为**零和博弈**，而逐步达成的动态平衡，结束了两个网络的优化过程，这就是**纳什均衡**。
- en: The Nash equilibrium
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 纳什均衡
- en: In the mathematical theory of games, the Nash equilibrium is defined as the
    condition in which two competing players consider their respective game strategies
    as the best possible options available to them. This condition of equilibrium
    is the result of the learning performed by the players by iteratively repeating
    playing sessions.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在博弈论的数学理论中，纳什均衡被定义为两个竞争玩家将各自的游戏策略视为他们可以选择的最佳选项的条件。这种平衡状态是玩家通过反复进行博弈学习的结果。
- en: In a Nash equilibrium condition, each player will then choose to perform the
    same action without modifying it.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在纳什均衡条件下，每个玩家将选择执行相同的动作，并且不会做出修改。
- en: 'The conditions under which this balance is determined are particularly restrictive.
    In fact, they imply the following:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 确定这种平衡的条件是特别严格的。事实上，它们意味着以下几点：
- en: All players are rational (that is, they must maximize their own objective function)
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有玩家都是理性的（也就是说，他们必须最大化自己的目标函数）
- en: All the players know that the other players are, in turn, rational, and know
    the respective objective functions to be maximized
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有玩家都知道其他玩家也是理性的，并且知道各自需要最大化的目标函数
- en: All players play their game simultaneously, without being aware of the choices
    made by the others
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有玩家同时进行博弈，而不了解其他玩家做出的选择
- en: Now, let's look at how to represent GANs in mathematical terms.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下如何用数学术语表示GAN。
- en: The math behind GANs
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN背后的数学
- en: 'We have said that the purpose of a GAN is to achieve a condition of equilibrium
    between the two NNs. The search for this equilibrium involves solving the following
    equation, a minimax condition:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经说过，GAN的目的是实现两个神经网络之间的平衡状态。寻找这个平衡涉及到解决以下方程式，这是一个极小极大条件：
- en: '![](img/086f1ba1-e063-4bd4-850e-0ee0d62e0194.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/086f1ba1-e063-4bd4-850e-0ee0d62e0194.png)'
- en: From the preceding formula, you can see the antagonistic goal that characterizes
    the two neural networks. We try to maximize *D* while minimizing *G*. In other
    words, the neural network *D*, which represents the discriminator, aims to maximize
    the equation, which translates into maximizing the output associated with real
    samples while minimizing the output associated with fake samples. On the other
    side, the neural network *G*, which represents the generator, has the inverse
    goal, which is to minimize the number of failures of *G*, which results in maximizing
    the output returned by *D* when it is put in front of the fake samples.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的公式中，你可以看到定义两个神经网络的对抗目标。我们试图最大化*D*，同时最小化*G*。换句话说，代表判别器的神经网络*D*旨在最大化方程式，这转化为最大化与真实样本相关的输出，同时最小化与虚假样本相关的输出。另一方面，代表生成器的神经网络*G*有相反的目标，即最小化*G*的失败次数，从而最大化*D*在面对虚假样本时返回的输出。
- en: The overall objective of the GAN is to achieve a balance in a zero-sum game
    (Nash equilibrium), characterized by a condition of indifference in which the
    output of *D* will consist of a probability estimate of 50% assigned to each categorized
    sample. In other words, the discriminator cannot reliably distinguish between
    genuine samples and fake samples.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的总体目标是在零和博弈（纳什均衡）中实现平衡，这种平衡特征是一个无差别的条件，其中*D*的输出将是每个分类样本分配的50%的概率估计。换句话说，判别器不能可靠地区分真实样本和虚假样本。
- en: How to train a GAN
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何训练GAN
- en: Training a GAN may require high computational capacity; otherwise, the time
    required to carry out the training may vary from a few hours to a few days. Given
    the mutual dependency that is established between the two NNs, it is advisable
    to keep the values returned by the generator network constant while training the
    discriminator network. At the same time, it can be useful to perform the pretraining
    of the discriminator network using the training data available, before training
    the generator network.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 训练GAN可能需要较高的计算能力；否则，进行训练所需的时间可能从几小时到几天不等。由于两个神经网络之间的相互依赖，建议在训练判别器网络时保持生成器网络返回的值不变。与此同时，使用可用的训练数据对判别器网络进行预训练，再训练生成器网络也是一种有益的做法。
- en: It is also important to adequately set the learning rates of the two NNs, so
    as to avoid a situation where the learning rate of the discriminator network exceeds
    that of the generator network and vice versa, thereby preventing the respective
    NNs from achieving their optimization goals.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，合理设置两个神经网络的学习率也非常重要，以避免判别器网络的学习率超过生成器网络的学习率，反之亦然，从而防止各自的神经网络未能实现其优化目标。
- en: An example of a GAN–emulating MNIST handwritten digits
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个GAN的示例–模拟MNIST手写数字
- en: In the following example, adapted from the original code available at [https://github.com/eriklindernoren/ML-From-Scratch/blob/master/mlfromscratch/unsupervised_learning/generative_adversarial_network.py](https://github.com/eriklindernoren/ML-From-Scratch/blob/master/mlfromscratch/unsupervised_learning/generative_adversarial_network.py)
    (released under the MIT license at [https://github.com/eriklindernoren/ML-From-Scratch/blob/master/LICENSE](https://github.com/eriklindernoren/ML-From-Scratch/blob/master/LICENSE)),
    we see an example of a GAN that is able to artificially generate, from some input
    noise, the reproduction of handwritten digit images by comparing them against
    the MNIST dataset (available for download at[ http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，改编自原始代码，原始代码可在[https://github.com/eriklindernoren/ML-From-Scratch/blob/master/mlfromscratch/unsupervised_learning/generative_adversarial_network.py](https://github.com/eriklindernoren/ML-From-Scratch/blob/master/mlfromscratch/unsupervised_learning/generative_adversarial_network.py)找到（根据MIT许可证发布，详情见[https://github.com/eriklindernoren/ML-From-Scratch/blob/master/LICENSE](https://github.com/eriklindernoren/ML-From-Scratch/blob/master/LICENSE)），我们看到一个GAN的示例，它能够通过一些输入噪声，生成与MNIST数据集中的手写数字图像相似的图像（MNIST数据集可在[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)下载）。
- en: The activation functions of the GAN's NNs, implemented by the `build_generator()`
    and `build_discriminator()` functions, are both based on Leaky ReLU (in order
    to improve the stability of the GAN, which can be affected by the presence of
    sparse gradients).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的神经网络的激活函数，由`build_generator()`和`build_discriminator()`函数实现，都基于Leaky ReLU（为了提高GAN的稳定性，避免稀疏梯度的影响）。
- en: 'We will make use of sample noise as generator input by leveraging the `normal()`
    function from the `random` library as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过利用`random`库中的`normal()`函数来使用样本噪声作为生成器输入，如下所示：
- en: '[PRE0]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The training phase of both NNs is implemented by the `train()` method:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 两个神经网络的训练阶段通过`train()`方法实现：
- en: '[PRE1]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Finally, in the `train()` method, the link between the two NNs is evident:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在`train()`方法中，两个神经网络之间的联系非常明显：
- en: '[PRE2]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the following image, we see the progressive learning of GANs in relation
    to the different epochs. The progress achieved by the GAN in generating the representative
    images of the numbers is clearly visible:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的图像中，我们可以看到生成对抗网络（GAN）在不同训练周期中的逐步学习进程。GAN在生成数字图像代表的过程中所取得的进展是显而易见的：
- en: '![](img/ee6d925d-0113-4f8d-987d-380e93f968d2.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee6d925d-0113-4f8d-987d-380e93f968d2.png)'
- en: 'The following is the code example, adapted from the original, that is available
    at [https://github.com/eriklindernoren/ML-From-Scratch/blob/master/mlfromscratch/unsupervised_learning/generative_adversarial_network.py](https://github.com/eriklindernoren/ML-From-Scratch/blob/master/mlfromscratch/unsupervised_learning/generative_adversarial_network.py)
    (released under the MIT license at [https://github.com/eriklindernoren/ML-From-Scratch/blob/master/LICENSE](https://github.com/eriklindernoren/ML-From-Scratch/blob/master/LICENSE)):'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是代码示例，改编自原始代码，原始代码可在[https://github.com/eriklindernoren/ML-From-Scratch/blob/master/mlfromscratch/unsupervised_learning/generative_adversarial_network.py](https://github.com/eriklindernoren/ML-From-Scratch/blob/master/mlfromscratch/unsupervised_learning/generative_adversarial_network.py)找到（根据MIT许可证发布，详情见[https://github.com/eriklindernoren/ML-From-Scratch/blob/master/LICENSE](https://github.com/eriklindernoren/ML-From-Scratch/blob/master/LICENSE)）：
- en: '[PRE3]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'After importing the necessary libraries, we are now ready to address the `GAN`
    class definition, which implements our GAN, deploying deep, fully-connected neural
    networks in the form of generator and discriminator components, instantiated in
    the class constructor (the `__init__()` method):'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入必要的库之后，我们现在可以着手定义`GAN`类，该类实现了我们的生成对抗网络（GAN），并以生成器和判别器组件的形式部署了深度全连接神经网络，这些组件在类构造函数（`__init__()`方法）中实例化：
- en: '[PRE4]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The generator and discriminator components are defined in the `build_generator()` and
    the `build_discriminator()` class methods, respectively:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器和判别器组件分别在`build_generator()`和`build_discriminator()`类方法中定义：
- en: '[PRE5]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To train the GAN, we define the `train()` class method, which takes care of
    training both the generator and discriminator components:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练GAN，我们定义了`train()`类方法，负责训练生成器和判别器组件：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'After training the GAN, we can save the newly created adversarial sample images
    with the `save_imgs()` class method, which is defined as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练完GAN后，我们可以通过`save_imgs()`类方法保存新创建的对抗样本图像，该方法定义如下：
- en: '[PRE7]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To launch the script, we just need to define the `__main__` entry point as
    follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动脚本，我们只需如下定义`__main__`入口点：
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now, let's move on and have a look at the GAN tools and libraries developed
    in Python.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续看看用Python开发的GAN工具和库。
- en: GAN Python tools and libraries
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN Python工具和库
- en: The number of tools and libraries (both to carry out attacks and to defend from
    attacks) for developing adversarial examples is constantly growing. We will look
    at some of the most common examples of these. In this section, we will consolidate
    the general-use libraries and tools, and in the following sections, we will deal
    with libraries and specific tools based on the individual strategies and scenarios
    of attack and defense.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 用于开发对抗样本的工具和库（无论是进行攻击还是防御）不断增多。我们将查看其中一些最常见的示例。在本节中，我们将整合常用的库和工具，接下来的章节将分别讨论基于不同攻击和防御策略与场景的特定库和工具。
- en: To fully understand the usefulness of these tools and libraries, we need to
    analyze the vulnerabilities of the cybersecurity solutions based on neural networks,
    the possibilities involved in the implementation of the attacks, and the difficulties
    in preparing an appropriate defense.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分理解这些工具和库的实用性，我们需要分析基于神经网络的网络安全解决方案的脆弱性、实施攻击的可能性，以及准备适当防御措施的难度。
- en: Neural network vulnerabilities
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络的脆弱性
- en: Despite the fact, as we have seen previously, that NNs have acquired particular
    relevance in recent times (as we have seen previously), due to their significant
    potential when it comes to resolving more complex problems that are usually the
    prerogative of human cognitive abilities, such as facial recognition and speech
    recognition, NNs, especially DNNs, suffer from a number of rather important vulnerabilities,
    which can be exploited through the use of GANs. This implies the possibility,
    for example, of deceiving biometric authentication procedures based on facial
    recognition or other biometric evidence made possible by the artificial creation
    of adversarial examples.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管正如我们之前所看到的，神经网络（NN）近年来因其在解决通常是人类认知能力专属的复杂问题（如面部识别和语音识别）时展现出的巨大潜力，已获得了特别关注，神经网络，尤其是深度神经网络（DNN），仍然存在一些相当重要的脆弱性，这些脆弱性可以通过生成对抗网络（GAN）加以利用。这意味着，举例来说，可能会通过人工创建对抗样本来欺骗基于面部识别或其他生物特征的生物认证程序。
- en: 'Apparently harmless devices such as 3D medical imagery scanners have been exploited
    as attack vectors, as shown in a recent paper, *CT-GAN: Malicious Tampering of
    3D Medical Imagery using Deep Learning*, by Yisroel Mirsky, Tom Mahler, Ilan Shelef,
    and Yuval Elovici of the Department of Information Systems Engineering, Ben-Gurion
    University, Israel Soroka University Medical Center, arXiv: 1901.03597v2).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '显然无害的设备，如3D医学影像扫描仪，已被用作攻击载体，正如最近一篇论文所示，*CT-GAN: 使用深度学习恶意篡改3D医学影像*，作者为以色列本·古里安大学信息系统工程系、Soroka大学医学中心的Yisroel
    Mirsky、Tom Mahler、Ilan Shelef和Yuval Elovici（arXiv: 1901.03597v2）。'
- en: In the study, the authors focused on the possibility of injecting and removing
    cancer images from CT scans, demonstrating how DNNs are highly susceptible to
    attack.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中，作者集中研究了如何将癌症图像注入和移除CT扫描，展示了深度神经网络（DNN）对攻击的高度脆弱性。
- en: By adding fake evidence or removing some genuine evidence of a medical condition,
    an attacker with access to medical imagery can change the outcome of a patient's
    diagnosis.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 通过添加虚假证据或删除一些真实的医学图像证据，攻击者如果能访问到医学影像，可以改变患者的诊断结果。
- en: For example, an attacker can add or remove evidence of aneurysms, tumors in
    the brain, and other forms of pathological evidences, such as heart disease. This
    type of threat shows how the use of DNNs to manage sensitive information, such
    as those pertaining to health conditions, can determine the expansion of the potential
    attack surface by several orders of magnitude, up to the possibility of committing
    crimes such as murder, which could involve politicians, heads of state, and so
    on as potential victims, without the need for the attacker to get their hands
    dirty, simply by exploiting the vulnerabilities of digital devices and procedures
    as **aseptic** attack vectors.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，攻击者可以添加或删除脑动脉瘤、脑肿瘤以及其他病理证据，如心脏病的证据。这种类型的威胁展示了DNN在处理敏感信息（如健康状况信息）时如何通过几个数量级的扩展攻击面，甚至可能涉及犯罪，如谋杀，且不需要攻击者亲自参与，只需利用数字设备和程序的漏洞作为**无菌**攻击向量。
- en: From what we have said, we can easily understand the severity level caused by
    the lack of robustness to adversarial attacks by DNNs, which can determine the
    compromising of the procedures and the applications they rely on.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们所说的内容中，我们可以轻松理解深度神经网络（DNN）在面对对抗性攻击时缺乏鲁棒性所带来的严重性，这可能决定了程序及其依赖应用的妥协性。
- en: Nevertheless, among the applications that exploit DNNs, there are also mission-critical
    applications (such as those that manage the functions of self-driving cars).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在利用DNN的应用中，也有一些关键任务应用（例如那些管理自动驾驶汽车功能的应用）。
- en: Deep neural network attacks
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度神经网络攻击
- en: 'There are basically two main ways to carry out an attack against DNNs:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对DNN进行攻击的基本方法有两种：
- en: '**White-box attacks**: This type of attack presupposes the model transparency
    of the DNN''s target, which grants the ability to directly verify the sensitivity
    of the response to the adversarial examples.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**白盒攻击**：这种攻击假设DNN目标模型具有透明性，允许直接验证对抗性示例对响应的敏感性。'
- en: '**Black-box attacks**: Unlike the previous case, the sensitivity check of the
    adversarial example is implemented indirectly, not having available the configuration
    details of the targeted neural network; the only information available is the
    output values ​​returned by the neural networks to the respective inputs sent
    to them.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黑盒攻击**：与前一种情况不同，对抗性示例的敏感性检查是间接实现的，因为无法获得目标神经网络的配置细节；唯一可用的信息是神经网络对发送给它们的相应输入返回的输出值。'
- en: Irrespective of the type of attack, the attacker is, in any case, able to exploit
    some general characteristics concerning neural networks. As we have seen, among
    the most widespread adversarial attacks are those that aim to deceive the image
    classification algorithms, exploiting artificially created image samples. Therefore,
    knowing that image classification applications prefer to use **convolutional neural
    networks** (**CNNs**), an attacker will focus more on the vulnerabilities of such
    neural networks to conduct their own attacks.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 无论攻击类型如何，攻击者总是能够利用一些关于神经网络的一般特性。如我们所见，最广泛的对抗性攻击之一是那些旨在欺骗图像分类算法的攻击，利用人工创建的图像样本。因此，考虑到图像分类应用更倾向于使用**卷积神经网络**（**CNN**），攻击者将更加专注于这种神经网络的漏洞进行攻击。
- en: Even the learning strategies used by DNNs can indirectly constitute vectors
    of attack. We have previously seen how the use of the backpropagation technique
    is preferred in carrying out the training of the algorithms by virtue of its greater
    efficiency in computational terms. Being aware of this preferential learning choice,
    an attacker can, in turn, exploit algorithms such as gradient descent to attack
    DNNs, trusting that the backpropagation strategy allows the gradient computation
    of the output returned by the entire DNN.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是DNN使用的学习策略也可以间接构成攻击向量。我们之前已经看到，反向传播技术因其在计算上的更高效率而被优先用于训练算法。了解这一优先学习选择后，攻击者可以反过来利用梯度下降等算法攻击DNN，假设反向传播策略允许计算整个DNN返回输出的梯度。
- en: Adversarial attack methodologies
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对抗性攻击方法
- en: 'The following are some of the most commonly used methods to develop adversarial
    attacks:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些最常用的对抗攻击开发方法：
- en: '**Fast gradient sign method** (**FGSM**): To generate adversarial examples,
    this method exploits the sign of the gradient associated with the backpropagation
    method used by the DNN''s victim.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速梯度符号方法**（**FGSM**）：为了生成对抗样本，这种方法利用与DNN受害者反向传播方法相关的梯度符号。'
- en: '**Jacobian-based saliency map attack** (**JSMA**): This attack methodology
    iteratively modifies information (such as the most significant pixel of an image)
    to create adversarial examples, based on a JSMA that characterizes the existing
    relationship between the input and output returned by the target neural network.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于雅可比矩阵的显著性图攻击**（**JSMA**）：这种攻击方法通过迭代修改信息（例如图像中最显著的像素）来创建对抗样本，基于一个JSMA来描述输入和目标神经网络返回输出之间的现有关系。'
- en: '**Carlini and Wagner** (**C and W**): This adversarial attack methodology is
    perhaps the most reliable, and the most difficult to detect. The adversarial attack
    is treated as an optimization problem that uses a predefined measure (such as
    the Euclidean distance) to determine the gap between the original and the adversarial
    examples.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Carlini 和 Wagner**（**C 和 W**）：这种对抗攻击方法可能是最可靠且最难检测的。对抗攻击被视为一个优化问题，使用预定义的度量（例如欧几里得距离）来确定原始样本与对抗样本之间的差距。'
- en: 'However, adversarial examples also show an interesting feature: **attack transferability**.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对抗样本也表现出一个有趣的特点：**攻击可转移性**。
- en: Adversarial attack transferability
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对抗攻击的可转移性
- en: A typical feature of adversarial attacks has to do with their **transferability**.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗攻击的一个典型特点与其**可转移性**有关。
- en: This feature refers to the possibility that the adversarial examples generated
    for a given DNN can also be transferred to another DNN, due to the high generalization
    capacity that characterizes the neural networks, and that constitutes their power
    (but also their fragility).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这一特点指的是，针对某个特定DNN生成的对抗样本，可能也能转移到另一个DNN，因为神经网络具有很高的泛化能力，这正是它们的优势（但同时也是它们的脆弱性）。
- en: Taking advantage of the transferability of adversarial attacks, an attacker
    is able to create reusable adversarial examples without needing to know the exact
    parameters of the individual configurations of the neural networks.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 利用对抗攻击的可转移性，攻击者能够创建可重用的对抗样本，而无需知道神经网络的个别配置的确切参数。
- en: It is therefore very likely that a set of adversarial examples developed to
    successfully deceive a specific DNN for image classification, for example, can
    be exploited to deceive other neural networks with similar classification tasks.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，很可能一组成功欺骗特定DNN进行图像分类的对抗样本，能够被用来欺骗其他具有相似分类任务的神经网络。
- en: Defending against adversarial attacks
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 防御对抗攻击
- en: 'Following the growing diffusion of adversarial attacks, many attempts have
    been made to provide adequate defense measures, based mainly on the following
    methods:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 随着对抗攻击的传播，已经有许多尝试提供适当的防御措施，主要基于以下几种方法：
- en: '**Statistical-based detection defense**: This method tries to detect the presence
    of adversarial examples by exploiting statistical tests and outlier detection.
    It assumes that the statistical distributions characterizing the real examples
    and the adversarial examples are fundamentally distinct from one another. However,
    the effectiveness of the C and W attack methodology shows that this assumption
    is not at all obvious or reliable.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于统计的检测防御**：这种方法通过利用统计测试和异常值检测来尝试检测对抗样本的存在。它假设描述真实样本和对抗样本的统计分布在根本上是不同的。然而，C和W攻击方法的有效性表明，这一假设并不是显而易见或可靠的。'
- en: '**Gradient masking defense**: We have seen how adversarial attacks exploit
    the backpropagation optimization strategy adopted by most DNNs to their advantage,
    relying on information pertaining to gradient calculations performed by the target
    neural network. One form of defense, gradient masking, therefore involves hiding
    information specifically pertaining to gradients during neural network training.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度遮蔽防御**：我们已经看到对抗攻击如何利用大多数深度神经网络（DNN）采用的反向传播优化策略，并依赖于目标神经网络执行的梯度计算信息。梯度遮蔽防御因此涉及在神经网络训练过程中隐藏与梯度相关的信息。'
- en: '**Adversarial training defense**: This method of defense aims to make the learning
    algorithm more robust with regard to possible perturbations present in the training
    data by inserting the adversarial samples, as well as the genuine samples, in
    the training dataset. This defense methodology also appears to be the most promising
    against C and W adversarial attacks. However, it does have a cost associated with
    it, involving the increased complexity of the network and of the increase in model
    parameters.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对抗训练防御**：这种防御方法旨在通过将对抗样本和真实样本插入训练数据集中，使学习算法对可能出现在训练数据中的扰动更加鲁棒。这种防御方法似乎对 C
    和 W 对抗攻击最为有效。然而，它也有一定的代价，涉及网络复杂性的增加和模型参数的增加。'
- en: Now that the vulnerabilities of the DNNs—along with the adversarial attacks
    and defense methodologies—have been introduced, we can now analyze the main libraries
    used to develop the adversarial examples.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，DNN 的脆弱性以及对抗攻击和防御方法已被介绍，我们可以分析开发对抗样本时使用的主要库。
- en: CleverHans library of adversarial examples
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CleverHans 对抗样本库
- en: One of the Python libraries that is garnering the most attention is definitely
    the CleverHans library, which is often the basis of other libraries and tools
    for developing adversarial examples.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当前备受关注的 Python 库之一无疑是 CleverHans 库，它通常是开发对抗样本的其他库和工具的基础。
- en: The CleverHans library is available at [https://github.com/tensorflow/cleverhans](https://github.com/tensorflow/cleverhans),
    and is released under the MIT license ([https://github.com/tensorflow/cleverhans/blob/master/LICENSE](https://github.com/tensorflow/cleverhans/blob/master/LICENSE)).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: CleverHans 库可以在[https://github.com/tensorflow/cleverhans](https://github.com/tensorflow/cleverhans)找到，并根据
    MIT 许可证发布（[https://github.com/tensorflow/cleverhans/blob/master/LICENSE](https://github.com/tensorflow/cleverhans/blob/master/LICENSE)）。
- en: This library is particularly suitable for constructing attacks, building defenses,
    and benchmarking machine learning systems' vulnerability to adversarial attacks.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 该库特别适合构建攻击、搭建防御措施，以及基准测试机器学习系统对对抗攻击的脆弱性。
- en: To install the CleverHans library, we must first proceed with the installation
    of the TensorFlow library ([https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)),
    which is used to perform the graph computations necessary in the implementation
    of learning models.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 CleverHans 库，我们必须首先安装 TensorFlow 库（[https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)），该库用于执行学习模型实现所需的图计算。
- en: 'After installing TensorFlow, we can proceed with the installation of CleverHans
    using the usual command:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 TensorFlow 后，我们可以使用常规命令安装 CleverHans：
- en: '[PRE9]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: One of the many advantages of the CleverHans library is that it offers several
    examples and tutorials in which the many different methods of using the models
    for the development of adversarial examples are shown.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: CleverHans 库的众多优点之一是它提供了多个示例和教程，展示了使用不同方法通过模型开发对抗样本的过程。
- en: 'In particular, the CleverHans library provides us with the following tutorials
    (based on the MNIST training handwritten digits dataset, available for download
    at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/) ):'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，CleverHans 库为我们提供了以下教程（基于 MNIST 手写数字训练数据集，数据集可以在[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)下载）：
- en: '**MNIST with FGSM**: This tutorial covers how to train a MNIST model to craft
    adversarial examples using the FGSM and make the model more robust to adversarial
    examples using adversarial training.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用 FGSM 的 MNIST**：本教程介绍了如何训练 MNIST 模型，利用 FGSM 制作对抗样本，并通过对抗训练使模型对对抗样本更加鲁棒。'
- en: '**MNIST with JSMA**: This tutorial covers how to define a MNIST model to craft
    adversarial examples using the JSMA approach.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用 JSMA 的 MNIST**：本教程介绍了如何定义一个 MNIST 模型，通过 JSMA 方法制作对抗样本。'
- en: '**MNIST using a black-box attack**: This tutorial implements a black-box attack
    based on the adversarial training of a substitute model (that is, a copy that
    imitates the black-box model by observing the labels that the black-box model
    assigns to inputs chosen carefully by the adversary). The adversary then uses
    the substitute model''s gradients to find adversarial examples that are incorrectly
    classified by the black-box model as well.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用黑盒攻击的 MNIST**：本教程实现了一种基于对抗训练的替代模型的黑盒攻击（即通过观察黑盒模型为精心挑选的输入分配的标签，来模仿黑盒模型的副本）。对抗者然后使用替代模型的梯度来查找那些被黑盒模型错误分类的对抗样本。'
- en: During this chapter, we will encounter some examples that use the CleverHans
    library to develop adversarial attack and defense scenarios.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将遇到一些使用 CleverHans 库开发对抗性攻击和防御场景的示例。
- en: EvadeML-Zoo library of adversarial examples
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EvadeML-Zoo 对抗性示例库
- en: Another library of particular interest is EvadeML-Zoo. EvadeML-Zoo is a benchmarking
    and visualization tool for adversarial machine learning, developed by the machine
    learning group and the security research group at the University of Virginia.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个特别值得关注的库是 EvadeML-Zoo。EvadeML-Zoo 是一个用于对抗性机器学习的基准测试和可视化工具，由弗吉尼亚大学的机器学习小组和安全研究小组开发。
- en: EvadeML-Zoo is released under the MIT license ([https://github.com/mzweilin/EvadeML-Zoo/blob/master/LICENSE](https://github.com/mzweilin/EvadeML-Zoo/blob/master/LICENSE))
    and is freely available for download at [https://github.com/mzweilin/EvadeML-Zoo](https://github.com/mzweilin/EvadeML-Zoo).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: EvadeML-Zoo 采用 MIT 许可证发布（[https://github.com/mzweilin/EvadeML-Zoo/blob/master/LICENSE](https://github.com/mzweilin/EvadeML-Zoo/blob/master/LICENSE)），并可在
    [https://github.com/mzweilin/EvadeML-Zoo](https://github.com/mzweilin/EvadeML-Zoo)
    免费下载。
- en: 'The EvadeML-Zoo library provides a series of tools and models, including the
    following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: EvadeML-Zoo 库提供了一系列工具和模型，包括以下内容：
- en: Attacking methods such as FGSM, BIM, JSMA, Deepfool, Universal Perturbations,
    and Carlini/Wagner-L2/Li/L0
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击方法如 FGSM、BIM、JSMA、Deepfool、Universal Perturbations 和 Carlini/Wagner-L2/Li/L0
- en: Pretrained state-of-the-art models to attack
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于攻击的最先进的预训练模型
- en: Visualization of adversarial examples
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对抗性示例的可视化
- en: Defense methods
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 防御方法
- en: Several ready-to-use datasets, such as, MNIST, CIFAR-10, and ImageNet-ILSVRC
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 几个现成的可用数据集，如 MNIST、CIFAR-10 和 ImageNet-ILSVRC
- en: 'Once the package has been downloaded, you can install the EvadeML-Zoo library
    on a machine that only uses a CPU with the following command:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 下载完包后，你可以使用以下命令在只使用 CPU 的机器上安装 EvadeML-Zoo 库：
- en: '[PRE10]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Also, if you have a compatible GPU available, you can execute the following
    command:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果你有兼容的 GPU 可用，可以执行以下命令：
- en: '[PRE11]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We have seen that the features offered by the EvadeML-Zoo library also include
    the pretrained models, particularly useful for accelerating the development process
    of adversarial examples, which are notoriously rather heavy in computational terms.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到，EvadeML-Zoo 库提供的功能还包括预训练模型，这对于加速对抗性示例的开发过程尤其有用，而这些示例通常在计算上非常消耗资源。
- en: 'To download the pretrained models, run the following command:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 要下载预训练模型，请运行以下命令：
- en: '[PRE12]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Another interesting feature of the EvadeML-Zoo library is that it can be executed
    by running the `main.py` utility.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: EvadeML-Zoo 库的另一个有趣特点是，它可以通过运行 `main.py` 工具来执行。
- en: 'In the following code block, you can see the usage menu of `main.py`, along
    with an example of execution of the tool:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码块中，你可以看到 `main.py` 的使用菜单，并附带了工具执行的示例：
- en: '[PRE13]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The EvadeML-Zoo library is executed using the Carlini model and an FGSM adversarial
    attack on the MNIST dataset, as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: EvadeML-Zoo 库使用 Carlini 模型和对 MNIST 数据集的 FGSM 对抗性攻击进行执行，具体如下：
- en: '[PRE14]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Finally, we will learn how to develop defense models against adversarial attacks
    using the `Defense-GAN` library.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将学习如何使用 `Defense-GAN` 库开发对抗性攻击的防御模型。
- en: Before analyzing the details of the Defense-GAN library, let's try to understand
    the assumptions that it is based on, along with the features it offers to implement
    an adequate defense against adversarial attacks.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析 Defense-GAN 库的详细信息之前，让我们先尝试理解它所基于的假设，以及它提供的功能，以实现有效的对抗性攻击防御。
- en: As we have seen, adversarial attacks are categorized as either white-box attacks
    or black-box attacks; in the case of white-box attacks, the attacker has complete
    access to the model architecture and parameters, while in the case of black-box
    attacks, the attacker does not have access to the model parameters.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，对抗性攻击可以分为白盒攻击和黑盒攻击；在白盒攻击的情况下，攻击者可以完全访问模型的架构和参数，而在黑盒攻击的情况下，攻击者无法访问模型参数。
- en: We also know that many methods of defense against adversarial attacks have been
    proposed that are essentially based on the ability to distinguish the statistical
    distributions of adversarial examples from genuine samples (statistical detection),
    on the ability to hide sensitive information relating to the neural learning phase
    network (gradient masking), or on the possibility of training the learning algorithm
    using the adversarial examples together with the other training samples (adversarial
    training).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还知道，许多防御对抗攻击的方法已经被提出，这些方法本质上基于区分对抗样本与真实样本的统计分布（统计检测），基于隐藏与神经网络学习阶段相关的敏感信息（梯度掩蔽），或者基于使用对抗样本与其他训练样本一起训练学习算法（对抗训练）。
- en: All these defense methods present limitations, as they are effective against
    either white-box attacks or black-box attacks, but not both.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些防御方法都有一定的局限性，因为它们只能有效防御白盒攻击或黑盒攻击，但不能同时防御两者。
- en: Defense-GAN can instead be used as a defense against any attack, since it does
    not assume an attack model, but simply leverages the generative power of GANs
    to reconstruct adversarial examples.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: Defense-GAN 可以作为对抗任何攻击的防御工具，因为它不假设攻击模型，而是简单地利用 GAN 的生成能力来重构对抗样本。
- en: Defense-GAN proposes a new defense strategy based on a GAN trained in an unsupervised
    manner on legitimate (unperturbed) training samples in order to denoise adversarial
    examples.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Defense-GAN 提出了一种新的防御策略，该策略基于一个无监督训练的 GAN，在合法（未扰动）训练样本上进行训练，以去噪对抗样本。
- en: The Defense-GAN library is released under the Apache 2.0 license ([https://github.com/kabkabm/defensegan/blob/master/LICENSE](https://github.com/kabkabm/defensegan/blob/master/LICENSE)),
    and is freely available for download at [https://github.com/kabkabm/defensegan](https://github.com/kabkabm/defensegan).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: Defense-GAN 库是根据 Apache 2.0 许可证发布的 ([https://github.com/kabkabm/defensegan/blob/master/LICENSE](https://github.com/kabkabm/defensegan/blob/master/LICENSE))，并可以在
    [https://github.com/kabkabm/defensegan](https://github.com/kabkabm/defensegan)
    上免费下载。
- en: 'Once the library is downloaded, you can install it by launching the following
    command:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 下载库后，您可以通过启动以下命令来安装它：
- en: '[PRE15]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To download the dataset and prepare the data directory, launch the `download_dataset.py` Python
    script with the following command:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 要下载数据集并准备数据目录，请使用以下命令启动 `download_dataset.py` Python 脚本：
- en: '[PRE16]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Train a GAN model by launching `train.py script`:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 通过启动 `train.py` 脚本来训练 GAN 模型：
- en: '[PRE17]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The script execution will create:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本执行将创建：
- en: A directory in the output directory for each experiment with the same name as
    the directory where the model checkpoints are saved
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个实验的目录都位于输出目录中，并与保存模型检查点的目录同名。
- en: A configuration file is saved in each experiment directory so that it can be
    loaded as the address to that directory
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个实验目录中都会保存一个配置文件，以便可以加载该目录的地址。
- en: A training directory in the output directory for each experiment with the same
    name as the directory where the model checkpoints are saved
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个实验的训练目录都位于输出目录中，并与保存模型检查点的目录同名。
- en: A training configuration file is saved in each experiment directory so that
    it can be loaded as the address to that directory
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个实验目录中都会保存一个训练配置文件，以便可以加载该目录的地址。
- en: The Defense-GAN library also offers tools that you can use to experiment with
    the different attack modes, thereby allowing the effectiveness of defense models
    to be verified.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Defense-GAN 库还提供了一些工具，您可以用来实验不同的攻击模式，从而验证防御模型的有效性。
- en: 'To perform black-box attacks, we can launch the `blackbox.py` tool:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行黑盒攻击，我们可以启动 `blackbox.py` 工具：
- en: '[PRE18]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s take a look at each parameter here:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下这里的每个参数：
- en: The `--cfg` parameter is the path to the configuration file for training the
    iWGAN. This can also be the path to the output directory of the model.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--cfg` 参数是用于训练 iWGAN 的配置文件路径。这也可以是模型输出目录的路径。'
- en: The `--results_dir` parameter is the path where the final results are saved
    in text files.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--results_dir` 参数是保存最终结果文本文件的路径。'
- en: The `--bb_model` parameter represents the black-box model architectures that
    are used in tables 1 and 2.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--bb_model` 参数表示在表格 1 和 2 中使用的黑盒模型架构。'
- en: The `--sub_model` parameter represents the substitute model architectures that
    are used in tables 1 and 2.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--sub_model` 参数表示在表格 1 和 2 中使用的替代模型架构。'
- en: The `--defense_type` parameter specifies the type of defense to protect the
    classifier.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--defense_type` 参数指定保护分类器的防御类型。'
- en: The `--train_on_recs` and `--online_training` parameters are optional. If they
    are set, the classifier will be trained on the reconstructions of Defense-GAN
    (for example, in the `Defense-GAN-Rec` column of tables 1 and 2); otherwise, the
    results are for `Defense-GAN-Orig`. Note that `--online_training` will take a
    while if `--rec_iters`, or `L` in the paper, is set to a large value.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--train_on_recs`和`--online_training`参数是可选的。如果设置了这些参数，分类器将基于Defense-GAN的重构结果进行训练（例如，表1和表2中的`Defense-GAN-Rec`列）；否则，结果将是`Defense-GAN-Orig`的结果。请注意，如果设置了`--rec_iters`或论文中的`L`为较大的值，`--online_training`将需要一些时间。'
- en: 'There is also a list of `--` that are the same as the hyperparameters that
    are defined in configuration files (all lowercase), along with a list of flags
    in `blackbox.py`. The most important ones are as follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一份`--`参数列表，与配置文件中定义的超参数（均为小写）相同，并列出了`blackbox.py`中的标志。最重要的几个如下：
- en: '`--rec_iters`: The number of **gradient descent** (**GD**) reconstruction iterations
    for Defense-GAN, or `L` in the paper.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--rec_iters`: Defense-GAN的**梯度下降**（**GD**）重构迭代次数，或论文中的`L`。'
- en: '`--rec_lr`: The learning rate of the reconstruction step.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--rec_lr`: 重构步骤的学习率。'
- en: '`--rec_rr`: The number of random restarts for the reconstruction step, or `R`
    in the paper.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--rec_rr`: 重构步骤的随机重启次数，或论文中的`R`。'
- en: '`--num_train`: The number of images on which to train the black-box model.
    For debugging purposes, set this to a small value.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--num_train`: 用于训练黑盒模型的图像数量。为了调试，设置一个较小的值。'
- en: '`--num_test`: The number of images to test on. For debugging purposes, set
    this to a small value.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--num_test`: 测试图像的数量。为了调试，设置一个较小的值。'
- en: '`--debug`: This will save qualitative attack and reconstruction results in
    the debug directory and will not run the adversarial attack part of the code.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--debug`: 该选项将把定性攻击和重构结果保存到调试目录，并且不会运行代码中的对抗攻击部分。'
- en: 'An example of `blackbox.py` execution with parameters is as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 带参数的`blackbox.py`执行示例如下：
- en: '[PRE19]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can, of course, test Defense-GAN for white-box attacks by launching the
    `whitebox.py` tool:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当然可以通过启动`whitebox.py`工具，测试Defense-GAN对抗白盒攻击：
- en: '[PRE20]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'An example of `whitebox.py` execution with parameters is as follows:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 带参数的`whitebox.py`执行示例如下：
- en: '[PRE21]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'As for `blackbox.py` , there is also a list of `--` that are the same as the
    hyperparameters that are defined in the configuration files (all lowercase), along
    with a list of flags in `whitebox.py`. The most important ones are as follows:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 至于`blackbox.py`，还有一份`--`参数列表，与配置文件中定义的超参数（均为小写）相同，并列出了`whitebox.py`中的标志。最重要的几个如下：
- en: '`--rec_iters`: The number of GD reconstruction iterations for Defense-GAN,
    or `L` in the paper'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--rec_iters`: Defense-GAN的GD重构迭代次数，或论文中的`L`。'
- en: '`--rec_lr`: The learning rate of the reconstruction step'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--rec_lr`: 重构步骤的学习率。'
- en: '`--rec_rr`: The number of random restarts for the reconstruction step, or `R`
    in the paper'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--rec_rr`: 重构步骤的随机重启次数，或论文中的`R`。'
- en: '`--num_test`: The number of images to test on. For debugging purposes, set
    this to a small value'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--num_test`: 测试图像的数量。为了调试，设置一个较小的值。'
- en: Let's now move on and see how attacks against neural networks can be performed
    via model substitution.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续看看如何通过模型替代来对神经网络进行攻击。
- en: Network attack via model substitution
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过模型替代进行网络攻击
- en: 'An interesting demonstration of the potential offered by adversarial attacks
    conducted in black-box mode is the one described in the paper *Practical Black-Box
    Attacks against Machine Learning* (arXiv: 1602.02697v4), in which the possibility
    of carrying out an attack against remotely hosted DNNs is demonstrated, without
    the attacker being aware of the configuration characteristics of the target NN.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '在黑盒模式下进行对抗攻击所展现的潜力的一个有趣示例是论文*Practical Black-Box Attacks against Machine Learning*（arXiv:
    1602.02697v4）中描述的内容，其中展示了对远程托管的深度神经网络进行攻击的可能性，而攻击者并不知道目标神经网络的配置特征。'
- en: In these cases, the only information available to the attacker is that of the
    output returned by the neural network based on the type of input provided by the
    attacker. In practice, the attacker observes the classification labels returned
    by the DNN in relation to the attacking inputs. And it is here that an attack
    strategy becomes interesting. A local substitute model is, in fact, trained in
    place of the remotely hosted NN, using inputs synthetically generated by an adversary
    model and labeled by the target NN.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，攻击者唯一可用的信息是神经网络根据攻击者提供的输入类型返回的输出。实际上，攻击者观察到DNN在针对攻击输入时返回的分类标签。正是在这里，攻击策略变得有趣。实际上，本地替代模型是用一个对抗模型合成生成的输入，并由目标神经网络标记训练的，以代替远程托管的神经网络。
- en: A neural network hosted by MetaMind is used as a remote hosted network target,
    which exposes a DL API on the internet. By submitting to the hosted network, the
    adversarial examples trained on the local substitute, the authors verify that
    the RNN wrongly classifies over 80% of the adversarial examples. Furthermore,
    this attack strategy is also verified against similar services made available
    online by Amazon and Google, with even worse results in terms of the misclassification
    rate, which goes up to 96%.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 由MetaMind托管的神经网络作为远程托管网络目标，公开了一个互联网DL API。通过将攻击示例提交到托管网络，作者验证了在本地替代模型上训练的对抗示例，RNN错误地分类了超过80%的对抗示例。此外，这一攻击策略也在亚马逊和谷歌提供的类似在线服务上进行验证，结果更为糟糕，误分类率高达96%。
- en: In this way, the authors demonstrate that their black-box adversarial attacks
    strategy is of general validity, and not limited to the specific target neural
    network chosen. The result obtained also demonstrates the validity of the principle
    of the **transferability of adversarial attacks,** using the synthetic dataset
    tested on the local model. The attacker is actually replacing the local model
    with the target model by approximating the characteristics sufficiently to be
    able to exploit the vulnerabilities identified on the local model to the target
    model.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，作者证明了他们的黑盒对抗攻击策略具有普遍有效性，而不仅仅局限于特定选择的目标神经网络。获得的结果还证明了**对抗攻击可转移性**原理的有效性，使用在本地模型上测试的合成数据集。攻击者实际上是通过充分逼近特征来替代本地模型，用目标模型来替代本地模型，从而能够利用本地模型识别到的漏洞攻击目标模型。
- en: Therefore, the critical elements of the model-substitution-based adversarial
    attack methodology are substitute model training and synthetic dataset generation.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，基于模型替代的对抗攻击方法的关键要素是替代模型训练和合成数据集生成。
- en: Let's take a closer look at both features.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看一下这两个特性。
- en: Substitute model training
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 替代模型训练
- en: As we said previously, the model-substitution-based adversarial attack methodology
    is aimed at training a **substitute model** that resembles the original target
    NN in order to find viable vulnerabilities on the target NN.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所说，基于模型替代的对抗攻击方法旨在训练一个**替代模型**，该模型与原始目标神经网络相似，以便找到目标神经网络上的可行漏洞。
- en: 'The training phase of the substitute model is therefore characterized by a
    number of important peculiarities, which involves the following:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，替代模型的训练阶段具有一些重要的特殊性，涉及以下内容：
- en: Selecting an architecture for the substitute model without knowledge of the
    targeted model
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在没有目标模型知识的情况下选择替代模型的架构
- en: Limiting the number of queries made to the targeted model in order to ensure
    that the approach is tractable
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制对目标模型进行查询的次数，以确保该方法可操作
- en: In order to address these difficult tasks, the proposed attack strategy is based
    on the generation of synthetic data (using the technique known as **Jacobian-based
    dataset augmentation**).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些困难的任务，提出的攻击策略基于合成数据的生成（使用一种称为**雅可比矩阵数据增强**的技术）。
- en: Generating the synthetic dataset
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成合成数据集
- en: The approach followed in the generation of the synthetic dataset is of central
    importance in the attack strategy based on model substitution.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据集生成中的方法在基于模型替代的攻击策略中至关重要。
- en: To understand it, you only need to consider the fact that, although, in principle,
    it is possible to carry out an indefinite (even infinite) number of different
    queries toward the targeted model (to verify the output that the target model
    generates in relation to the input contained in the individual queries), this
    approach is not viable from a practical point of view.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解这一点，你只需要考虑这样一个事实：尽管原则上可以对目标模型进行无限次（甚至是无限数量的）不同查询（以验证目标模型针对每个查询输入生成的输出），但从实际角度来看，这种方法是不可行的。
- en: It is unsustainable in the first place because the high number of queries would
    make the adversarial attack easily detectable, but it is also unsustainable because
    we would increase the number of requests to be sent to the target model in proportion
    to the number of potential input components of the target neural network.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，它是不可持续的，因为大量的查询会使对抗性攻击容易被检测到，而且它也不可持续，因为我们需要根据目标神经网络的潜在输入组件数量，增加发送到目标模型的请求数量。
- en: The alternative solution involves using an appropriate heuristic to generate
    the synthetic dataset, based on identifying how the directions in the target model's
    output vary around an initial set of training points. These directions are identified
    with the substitute model's Jacobian matrix to accurately approximate the target
    model's decision boundaries by prioritizing the samples when querying the target
    model for labels.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 替代方案涉及使用合适的启发式方法生成合成数据集，基于识别目标模型输出中方向在初始训练点集周围的变化。这些方向通过替代模型的雅可比矩阵来识别，以便通过优先选择样本并在查询目标模型标签时准确地逼近目标模型的决策边界。
- en: Fooling malware detectors with MalGAN
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用MalGAN欺骗恶意软件检测器
- en: The black-box adversarial attack strategy can also be validly used to deceive
    the next-generation antimalware systems, based on NNs.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 黑盒对抗性攻击策略同样可以有效地用来欺骗基于神经网络的下一代反恶意软件系统。
- en: A useful library for developing black-box adversarial attacks with malware examples
    is MalGAN, available for download at [https://github.com/yanminglai/Malware-GAN/](https://github.com/yanminglai/Malware-GAN/),
    and released under the GPL 3.0 license ([https://github.com/yanminglai/Malware-GAN/blob/master/LICENSE](https://github.com/yanminglai/Malware-GAN/blob/master/LICENSE)).
    The fundamental idea behind MalGAN is to use a GAN to generate adversarial malware
    examples, which are able to bypass black-box machine-learning-based detection
    models. To install the MalGAN library, you need to install the TensorFlow 1.80,
    Keras 2.0, and Cuckoo Sandbox 2.03 ([https://cuckoo.readthedocs.io/en/2.0.3/](https://cuckoo.readthedocs.io/en/2.0.3/))
    libraries. Cuckoo Sandbox is used to extract API features from malware samples
    acquired from [https://virusshare.com/](https://virusshare.com/) (128 API features
    are selected as dimensional vectors to be input to the NN).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有用的库，用于开发带有恶意软件示例的黑盒对抗性攻击是MalGAN，可以从[https://github.com/yanminglai/Malware-GAN/](https://github.com/yanminglai/Malware-GAN/)下载，并且遵循GPL
    3.0许可证（[https://github.com/yanminglai/Malware-GAN/blob/master/LICENSE](https://github.com/yanminglai/Malware-GAN/blob/master/LICENSE)）。MalGAN背后的基本思想是使用GAN生成对抗性的恶意软件示例，这些示例能够绕过基于机器学习的黑盒检测模型。要安装MalGAN库，你需要安装TensorFlow
    1.80、Keras 2.0和Cuckoo Sandbox 2.03（[https://cuckoo.readthedocs.io/en/2.0.3/](https://cuckoo.readthedocs.io/en/2.0.3/)）库。Cuckoo
    Sandbox用于从[https://virusshare.com/](https://virusshare.com/)获取的恶意软件样本中提取API特征（选择128个API特征作为维度向量输入神经网络）。
- en: 'The following is the code of the main MalGAN class (version 2):'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是主MalGAN类（版本2）的代码：
- en: '[PRE22]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'After importing the necessary libraries, let''s look at the `MalGAN()` class
    definition, beginning with its constructor (the `__init__()` method):'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入必要的库之后，让我们先看看`MalGAN()`类的定义，从其构造函数（`__init__()`方法）开始：
- en: '[PRE23]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `MalGAN` class then provides the methods for building the generator component
    and the substitute detector, along with the `blackbox_detector`:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '`MalGAN`类提供了构建生成器组件和替代检测器的方法，以及`blackbox_detector`：'
- en: '[PRE24]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The training of the generator component, along with the training of the `blackbox`
    and substitute detectors, is implemented in the `train()` method:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器组件的训练以及`blackbox`和替代检测器的训练在`train()`方法中实现：
- en: '[PRE25]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We''ll train the generator as follows:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按如下方式训练生成器：
- en: '[PRE26]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To launch the script, we just need to define the `__main__` entry point:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动脚本，我们只需定义`__main__`入口点：
- en: '[PRE27]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Let's now continue illustrating the IDS evasion techniques that leverage the
    GANs.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续说明利用GAN进行IDS规避的技术。
- en: IDS evasion via GAN
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过GAN进行IDS规避
- en: We have dealt extensively with IDS in [Chapter 5](a6eab48a-f031-44c9-ae4a-0cfd5db2e05e.xhtml), *Network
    Anomaly Detection with AI*, where we learned about the delicate role played by
    these devices in a context like the current one, characterized by a growing explosion
    of malware threats spread through network attacks.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第5章](a6eab48a-f031-44c9-ae4a-0cfd5db2e05e.xhtml)《*基于AI的网络异常检测*》中详细讨论了IDS，了解了这些设备在当前这种网络攻击不断增加、恶意软件威胁日益扩散的背景下所发挥的微妙作用。
- en: It is therefore necessary to introduce tools capable of promptly detecting possible
    malware threats, preventing them from spreading across the entire corporate network,
    and thereby compromising both the software and the integrity of the data (just
    think, for example, of the growing diffusion of ransomware attacks).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，有必要引入能够及时检测可能的恶意软件威胁的工具，防止它们在整个企业网络中扩散，从而危及软件和数据的完整性（例如，想想日益蔓延的勒索软件攻击）。
- en: In order to be able to promptly and effectively carry out—that is, reduce—the
    number of false positives, it is therefore necessary to equip IDS systems with
    automated procedures capable of adequately classifying the traffic analyzed. It
    is no coincidence, therefore, that modern IDSes employ machine learning algorithms,
    also increasingly resorting to DNNs (such as CNNs, and RNNs) to improve intrusion
    detection accuracy.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 为了能够及时有效地执行——即减少——误报的数量，因此有必要为IDS系统配备能够充分分类分析流量的自动化程序。因此，现代IDS系统采用机器学习算法，也越来越多地借助深度神经网络（如CNN和RNN）来提高入侵检测的准确性。
- en: Consequently, not even **intrusion detection systems** (**IDSes**) can be considered
    immune to adversarial attacks, generated specifically to deceive the underlying
    models of the IDS, thereby reducing (or even eliminating) the ability to correctly
    classify the anomalous traffic.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，连**入侵检测系统**（**IDS**）也不能视为对对抗性攻击免疫，这些攻击是专门为欺骗IDS的基础模型而生成的，从而降低（甚至消除）正确分类异常流量的能力。
- en: Despite this, to date, there are still few theoretical studies and software
    implementations that use adversarial examples to carry out attacks against IDSes.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，迄今为止，仍然有少数理论研究和软件实现利用对抗性样本对IDS进行攻击。
- en: 'One of the demonstrations of the possibility of evading IDS detection using
    GANs is described in the paper *IDSGAN: Generative Adversarial Networks for Attack
    Generation against Intrusion Detection* ([https://arxiv.org/pdf/1809.02077](https://arxiv.org/pdf/1809.02077)).'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '使用GAN绕过IDS检测的可能性的一个示范描述在论文《*IDSGAN: 生成对抗网络用于入侵检测攻击生成*》中（[https://arxiv.org/pdf/1809.02077](https://arxiv.org/pdf/1809.02077)）。'
- en: Introducing IDSGAN
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍IDSGAN
- en: Also, in the case of IDSGAN, the type of attack is based on a black-box strategy,
    in which the implementation details and configuration of the target IDS are unknown.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，在IDSGAN的情况下，攻击类型基于黑盒策略，其中目标IDS的实现细节和配置是未知的。
- en: The underlying GAN of IDSGAN usually includes two antagonistic neural networks
    in which the generator component takes care of transforming the original network
    traffic into malicious traffic through the crafting of adversarial examples.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: IDSGAN的基础GAN通常包括两个对抗性的神经网络，其中生成器组件负责通过构造对抗性样本将原始网络流量转换为恶意流量。
- en: The discriminator component of IDSGAN, on the other hand, deals with correctly
    classifying the traffic, simulating the black-box detection system, thereby providing
    the necessary feedback to the generator component for the creation of adversarial
    examples.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: IDSGAN的判别器组件则负责正确分类流量，模拟黑盒检测系统，从而为生成对抗样本的生成器组件提供必要的反馈。
- en: Even in the case of IDSGAN, the adversarial examples generated using the NSL-KDD
    dataset ([http://www.unb.ca/cic/datasets/nsl.html](http://www.unb.ca/cic/datasets/nsl.html))
    show the characteristics of **attack transportability**; that is, they can be
    reused to attack many detection systems, thereby demonstrating the robustness
    of the underlying model.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在IDSGAN的情况下，使用NSL-KDD数据集生成的对抗性样本（[http://www.unb.ca/cic/datasets/nsl.html](http://www.unb.ca/cic/datasets/nsl.html)）也显示了**攻击可转移性**的特征；也就是说，它们可以被重新利用来攻击许多检测系统，从而展示了基础模型的鲁棒性。
- en: Features of IDSGAN
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: IDSGAN的特点
- en: 'The main features offered by IDSGAN are as follows:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: IDSGAN提供的主要功能如下：
- en: The ability to develop attacks against IDS by emulating their behavior
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过模拟IDS的行为开发攻击的能力
- en: The ability to take advantage of adversarial examples to make attacks against
    IDS in black-box mode
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用对抗样本在黑盒模式下对IDS进行攻击的能力
- en: The ability to reduce the detection rate of artificially produced traffic to
    zero
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将人工生成流量的检测率降到零的能力
- en: The ability to reuse the adversarial examples generated to attack different
    types of IDS
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重用生成的对抗样本以攻击不同类型的IDS的能力
- en: Now, let's look at the structure of IDSGAN.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下IDSGAN的结构。
- en: The IDSGAN training dataset
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: IDSGAN训练数据集
- en: First of all, IDSGAN uses the NSL-KDD dataset ([http://www.unb.ca/cic/datasets/nsl.html](http://www.unb.ca/cic/datasets/nsl.html)),
    which contains both malicious and genuine traffic samples. These samples are particularly
    useful for checking the performance of IDSGAN, as they are also used by common
    IDS.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，IDSGAN使用NSL-KDD数据集（[http://www.unb.ca/cic/datasets/nsl.html](http://www.unb.ca/cic/datasets/nsl.html)），该数据集包含恶意和真实的流量样本。这些样本对于检查IDSGAN的性能特别有用，因为它们也被常见的IDS所使用。
- en: The NSL-KDD dataset is then used as a benchmark both to verify the effectiveness
    of the generator component and to allow the discriminator component to return
    the feedback required to create the adversarial examples. Therefore, the choice
    of the NSL-KDD dataset is not by chance, as the traffic data samples contain both
    normal and malicious traffic, subdivided into four main categories, such as probing
    (probe), **denial of service** (**DoS**), **user to root** (**U2R**), and **root
    to local** (**R2L**).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，NSL-KDD数据集作为基准，既验证生成器组件的有效性，又允许判别器组件返回创建对抗样本所需的反馈。因此，选择NSL-KDD数据集并非偶然，因为流量数据样本包含正常和恶意流量，细分为四个主要类别，如探测（probe）、**拒绝服务**（**DoS**）、**用户到根**（**U2R**）和**根到本地**（**R2L**）。
- en: Moreover, the dataset exposes the traffic according to 41 complex features,
    of which 9 are characterized by discrete values, while the remaining 32 features
    take continuous values.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，数据集根据41个复杂特征展示流量，其中9个特征为离散值，剩余的32个特征为连续值。
- en: 'These features, in turn, can be divided into the following four types:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这些特性可以进一步分为以下四种类型：
- en: '**Intrinsic**: The features reflect the inherent characteristics of a single
    connection'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内在**：这些特性反映了单个连接的固有特征'
- en: '**Content**: The features mark the content of connections that relate to possible
    attacks'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容**：这些特性标记与可能的攻击相关的连接内容'
- en: '**Time based**: The features examine the connections established in the past
    2 seconds that have the same destination host or the same service as the current
    connection'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于时间**：这些特性检查过去2秒内已建立的连接，这些连接与当前连接具有相同的目标主机或相同的服务'
- en: '**Hosted based**: The features monitor the connections in the past 100 connections
    that have the same destination host or the same service as the current connection'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于主机**：这些特性监视过去100个连接中与当前连接具有相同目标主机或相同服务的连接'
- en: In the data preprocessing phase, particular attention is given to the dimensional
    impact reduction between feature values. A normalization method based on the min–max
    criterion is used to convert the input data and make it fall within the interval
    [0, 1], thereby being able to manage both the discrete features and the continuous
    features.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据预处理阶段，特别关注特征值之间的维度影响减少。采用基于最小-最大标准的方法进行归一化，将输入数据转换并使其落入区间[0, 1]，从而能够管理离散特征和连续特征。
- en: 'The mathematical formula used to carry out this normalization is as follows:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 用于执行此归一化的数学公式如下：
- en: '![](img/518c36f9-c301-4cb8-a21a-3c0d01e002be.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![](img/518c36f9-c301-4cb8-a21a-3c0d01e002be.png)'
- en: Here, *x* represents the feature value before normalization, and *x′* is the
    feature value after normalization.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*x*表示归一化前的特征值，*x′*是归一化后的特征值。
- en: Once we have analyzed the training dataset and data normalization we can move
    on to examine the characteristics of the IDSGAN components.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们分析了训练数据集和数据归一化，我们就可以继续研究IDSGAN组件的特性。
- en: Generator network
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成器网络
- en: As in all GANs, the generator network is the component responsible for generating
    the adversarial examples.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 与所有GAN一样，生成器网络是负责生成对抗样本的组件。
- en: In IDSGAN, the generator transforms an original sample of the input traffic,
    associated with the vector of size *m*, which represents the characteristics of
    the original sample, a vector of dimension *n*, containing noise—that is, random
    numbers extracted from a uniform distribution whose values fall within the range
    [***0***, ***1***].
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在IDSGAN中，生成器将原始输入流量样本转换为与大小为*m*的向量相关联的样本，该向量表示原始样本的特征，另一个维度为*n*的向量，其中包含噪声——即从均匀分布中提取的随机数，其值落在[***0***,
    ***1***]范围内。
- en: The generator network consists of five layers (with which the ReLU activation
    function is associated) to manage the output of the internal layers, while the
    output layer has sufficient units to meet the original *m*-dimensional sample
    vector.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器网络由五个层组成（其中与ReLU激活函数相关联），用于管理内部层的输出，而输出层具有足够的单元，以满足原始的*m*维样本向量。
- en: As we anticipated, the generator network adjusts its parameters based on the
    feedback received from the discriminator network (that emulates the behavior of
    IDS in black-box mode).
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所预期的那样，生成器网络根据从判别器网络（模拟IDS在黑箱模式下的行为）收到的反馈调整其参数。
- en: Now, let's look at the features of IDSGAN's discriminator component in more
    detail.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们更详细地看看IDSGAN判别器组件的特性。
- en: Discriminator network
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 判别器网络
- en: We have said that the attack strategy implemented by IDSGAN follows the black-box
    mode, which means that it is assumed that the attacker has no knowledge of the
    implementations of the target IDS. In this sense, the discriminator component
    of IDSGAN tries to mimic the attacked IDS, classifying the output generated by
    the generator component by comparing it with the normal traffic examples.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提到，IDSGAN实现的攻击策略遵循黑箱模式，这意味着假设攻击者对目标IDS的实现没有任何了解。从这个角度来看，IDSGAN的判别器组件试图模拟被攻击的IDS，通过将生成器组件输出与正常流量示例进行比较，来分类其输出。
- en: In this way, the discriminator is able to provide the necessary feedback to
    the generator in order to craft the adversarial examples. Therefore, the discriminator
    component consists of a multilayer neural network whose training dataset contains
    both the normal traffic and the adversarial examples.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，判别器能够为生成器提供必要的反馈，以便生成对抗样本。因此，判别器组件由一个多层神经网络组成，其训练数据集包含正常流量和对抗样本。
- en: 'The training phases of the discriminator network are therefore as follows:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器网络的训练阶段如下：
- en: The normal samples and the adversarial examples are classified by the IDS
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正常样本和对抗样本由IDS进行分类
- en: The results of the IDS are used as the target labels of the discriminator
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IDS的结果用作判别器的目标标签
- en: The discriminator mimics the IDS classification using the resulting training
    dataset
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器使用结果训练数据集来模拟IDS分类
- en: The algorithms used to train the generator and discriminator components are
    outlined in the following sections.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 用于训练生成器和判别器组件的算法将在接下来的章节中概述。
- en: Understanding IDSGAN's algorithm training
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解IDSGAN的算法训练
- en: 'To train the generator network, the gradients of the results obtained from
    the classification of adversarial examples by the discriminator network are used.
    The objective function, also known as the **loss function**—represented by, *L*
    in the following equation that the generator network must minimize—consists of
    the following equation:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练生成器网络，使用来自判别器网络对对抗样本分类结果的梯度。目标函数，也称为**损失函数**—以下方程中的*L*表示，生成器网络必须最小化的函数—由以下方程组成：
- en: '![](img/199fefbe-6687-418c-a9c1-c32c1a30b175.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](img/199fefbe-6687-418c-a9c1-c32c1a30b175.png)'
- en: Here, *G* and *D* represent the generator and the discriminator networks, respectively,
    while *S**[attack]* represents the original malicious samples, with *M* and *N*
    representing the *m*-dimensional vector that matches the original traffic sample
    and the *n*-dimensional vector matching the noisy part, respectively.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*G*和*D*分别表示生成器和判别器网络，而*S**[attack]*表示原始恶意样本，*M*和*N*分别表示与原始流量样本匹配的*m*维向量和与噪声部分匹配的*n*维向量。
- en: 'In the case of the discriminator network, training takes place by optimizing
    the objective function represented by the following equation:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 对于判别器网络，训练是通过优化由以下方程表示的目标函数进行的：
- en: '![](img/0be233a6-d951-40e8-b61e-12024feb99b9.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0be233a6-d951-40e8-b61e-12024feb99b9.png)'
- en: As we have seen, the training dataset of the discriminator network consists
    of both normal samples and adversarial examples, while the target labels are represented
    by the outputs returned by the IDS.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，判别器网络的训练数据集包含了正常样本和对抗性样本，而目标标签则由IDS返回的输出表示。
- en: In the objective function, therefore, *s* represents the traffic examples used
    for the discriminator's training, while *B[normal]* and *B*[*attack* ]represent
    the normal examples and the adversarial examples correctly predicted by the IDS,
    respectively.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在目标函数中，*s* 代表用于判别器训练的流量样本，而 *B[normal]* 和 *B*[*attack*] 分别代表IDS正确预测的正常样本和对抗性样本。
- en: Facial recognition attacks with GAN
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GAN进行人脸识别攻击
- en: As a last example of the use of GANs, we will look at what is perhaps the most
    symptomatic and well-known case, which involves generating adversarial examples
    representative of human faces.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 作为GAN使用的最后一个例子，我们将看到可能是最具象征性和最著名的案例，它涉及生成代表人类面孔的对抗性样本。
- en: Apart from the surprising effect that this technique can have on those who examine
    the results, which are often very realistic, this technique, when used as an attack
    tool, constitutes a serious threat to all those cybersecurity procedures based
    on the verification of biometric evidence (often used to access, for example,
    online banking services, or, more recently, to log in to social networks, and
    even access your own smartphone).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这一技术对结果检查者可能产生的惊人效果（这些结果通常非常真实），当它作为攻击工具使用时，它构成了对所有基于生物识别证据验证的网络安全程序的严重威胁（这些程序常用于访问例如在线银行服务，或更近期的社交网络登录，甚至是访问你的智能手机）。
- en: Moreover, it can be used to deceive even the AI-empowered facial-recognition
    tools used by the police to identify suspects, consequently reducing their overall
    reliability.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，它甚至可以用来欺骗警方用于识别嫌疑人的AI驱动的人脸识别工具，从而降低其整体可靠性。
- en: 'As demonstrated in the paper *Explaining and Harnessing Adversarial Examples* (arxiv:
    1412.6572, whose authors include Ian Goodfellow, who first introduced GANs to
    the world), you only need to introduces small perturbation (imperceptible to the
    human eye) to build artificial images that can fool neural network classifiers.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '正如论文《*解释与利用对抗性样本*》中所证明的（arxiv: 1412.6572，其作者包括首次将GAN引入世界的Ian Goodfellow），你只需要引入微小的扰动（人眼无法察觉），就可以构建出能够欺骗神经网络分类器的人工图像。'
- en: 'The following is reproduced from a famous image in which a panda is erroneously
    classified as a gibbon, due to the effect of the small perturbation injected into
    the original sample:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从一张著名图片中复制的内容，其中一只熊猫由于注入原始样本的微小扰动而被错误分类为长臂猿：
- en: '![](img/b2f8fe03-3026-448f-a10b-23b7297278b8.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b2f8fe03-3026-448f-a10b-23b7297278b8.png)'
- en: (Image taken from the paper entitled *Explaining and Harnessing Adversarial
    Examples* – 1412.6572)
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: （图片摘自论文《*解释与利用对抗性样本*》– 1412.6572）
- en: Facial recognition vulnerability to adversarial attacks
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸识别对抗攻击的脆弱性
- en: The reason why common facial-recognition models are vulnerable to adversarial
    attacks is that two identical CNNs are used, which together constitute a **Siamese
    network**. In an attempt to calculate the distance between two representative
    images of the faces to be compared, a CNN is combined with the first image and
    another CNN is combined with the second image.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 普通人脸识别模型易受对抗攻击的原因在于使用了两个相同的CNN，它们共同构成了一个**连体网络**。为了计算要比较的两张人脸的代表性图像之间的距离，一个CNN与第一张图像结合，另一个CNN与第二张图像结合。
- en: The distance calculated between the representations—also known as **output embeddings**,
    formulated by the CNNs in relation to the respective images—is evaluated based
    on the exceedance of a given threshold value.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 计算表示之间的距离——也称为**输出嵌入**，由CNN相对于各自图像的表示形式进行——是根据超过给定阈值来评估的。
- en: The weak link of this facial recognition method is constituted precisely by
    a correct evaluation of the distance existing between the embedding outputs associated
    with the individual images, in order to verify the exceedance of the threshold
    that determines, consequently, the failed matching of the images.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这种人脸识别方法的薄弱环节恰恰在于正确评估与单独图像相关联的嵌入输出之间的距离，以验证是否超过决定图像匹配失败的阈值。
- en: Therefore, an attacker who wants to be recognized in place of the legitimate
    user, for example, in order to log in to an online banking website or a social
    network should try to obtain CNN output embeddings by performing an unauthorized
    access of the database where they are stored. Alternatively, the attacker can
    identify themselves as any user, fooling the Siamese network by leveraging an
    adversarial example attack.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，攻击者如果想替代合法用户被识别，例如，为了登录在线银行网站或社交网络，应该尝试通过未经授权访问存储 CNN 输出嵌入的数据库来获取这些嵌入。另一种方式是，攻击者可以通过利用对抗示例攻击，欺骗
    Siamese 网络，冒充任何用户。
- en: Adversarial examples against FaceNet
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对 FaceNet 的对抗示例
- en: An example of an attack that uses adversarial examples to deceive a CNN implementing
    a facial-recognition model is contained in the CleverHans library (under the examples
    directory; it is freely available for download at [https://github.com/tensorflow/cleverhans/blob/master/examples/facenet_adversarial_faces/facenet_fgsm.py](https://github.com/tensorflow/cleverhans/blob/master/examples/facenet_adversarial_faces/facenet_fgsm.py).
    The example code is released under the MIT license at [https://github.com/tensorflow/cleverhans/blob/master/LICENSE](https://github.com/tensorflow/cleverhans/blob/master/LICENSE)).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 使用对抗示例欺骗实现面部识别模型的 CNN 的攻击示例包含在 CleverHans 库中（位于 examples 目录下；可以在 [https://github.com/tensorflow/cleverhans/blob/master/examples/facenet_adversarial_faces/facenet_fgsm.py](https://github.com/tensorflow/cleverhans/blob/master/examples/facenet_adversarial_faces/facenet_fgsm.py)
    免费下载。示例代码根据 MIT 许可证发布，详情请见 [https://github.com/tensorflow/cleverhans/blob/master/LICENSE](https://github.com/tensorflow/cleverhans/blob/master/LICENSE)）。
- en: The example code shows how to perform an adversarial attack against the FaceNet
    library, using the `FGSM` method, obtaining an accuracy in excess of 99%.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 示例代码展示了如何使用 `FGSM` 方法对 FaceNet 库进行对抗攻击，准确率超过 99%。
- en: 'Here is the code for the adversarial attack example against the facial-recognition
    model implemented by the FaceNet library:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对 FaceNet 库实现的面部识别模型进行对抗攻击的示例代码：
- en: '[PRE28]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'After loading the necessary libraries, we can delve deeper with the `InceptionResnetV1Model`
    class definition, which provides us with all the requested methods we need to
    perform the adversarial attack against the FaceNet library:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 在加载必要的库之后，我们可以深入了解 `InceptionResnetV1Model` 类的定义，它为我们提供了执行针对 FaceNet 库的对抗攻击所需的所有方法：
- en: '[PRE29]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We are now ready to perform our attack, leveraging the FGSM method:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好利用 FGSM 方法执行我们的攻击：
- en: '[PRE30]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'As a result, the FGSM will follow two different attack strategies:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，FGSM 将遵循两种不同的攻击策略：
- en: Impersonation attack (the attack is aimed at impersonating a specific user),
    using pairs of faces belonging to different individuals
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冒充攻击（该攻击旨在冒充特定用户），使用属于不同个体的面部图像对
- en: Dodging attack (the attack is aimed at being identified as any possible user),
    using pairs of faces belonging to the same person
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 躲避攻击（该攻击旨在将自己识别为任何可能的用户），使用属于同一人的面部图像对
- en: Let's now look at how to launch the adversarial attack against FaceNet's CNN.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下如何对 FaceNet 的 CNN 发起对抗攻击。
- en: Launching the adversarial attack against FaceNet's CNN
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对 FaceNet 的 CNN 发起对抗攻击
- en: 'In order to run the adversarial attack example against FaceNet''s CNN, go through
    the following steps:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行针对 FaceNet CNN 的对抗攻击示例，请按照以下步骤操作：
- en: Install the FaceNet library, download and align the LFW faces, and download
    a pretrained FaceNet model as described in the FaceNet tutorial available at [https://github.com/davidsandberg/facenet/wiki/Validate-on-LFW](https://github.com/davidsandberg/facenet/wiki/Validate-on-LFW).
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 FaceNet 库，下载并对齐 LFW 人脸，并根据 FaceNet 教程中的说明下载一个预训练的 FaceNet 模型，教程请见 [https://github.com/davidsandberg/facenet/wiki/Validate-on-LFW](https://github.com/davidsandberg/facenet/wiki/Validate-on-LFW)。
- en: Verify that the downloaded datasets and the models' folders are in the same
    folder of the example.
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保下载的数据集和模型文件夹位于示例代码的同一文件夹中。
- en: 'Edit the following line in the example code, verifying that the name and path
    of the `.pb` file match the path and the filename of the FaceNet model downloaded
    previously:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑示例代码中的以下行，确保 `.pb` 文件的名称和路径与之前下载的 FaceNet 模型的路径和文件名匹配：
- en: '[PRE31]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Launch the Python script with the following command:'
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令启动 Python 脚本：
- en: '[PRE32]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Summary
  id: totrans-343
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we looked at the attack and defense techniques that exploit
    the adversarial examples created with GANs.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了利用 GAN 创建的对抗示例进行的攻击与防御技术。
- en: We looked at the concrete threats that can arise from the use of GANs against
    DNNs that are increasingly at the heart of cybersecurity procedures, such as malware-detection
    tools, and biometric authentication. In addition to the risks associated with
    the widespread use of NNs in the management of sensitive data, such as health
    data, these threats lead to new forms of GAN-based attacks that can compromise
    even the health and physical safety of citizens.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 我们研究了使用 GANs 对越来越多成为网络安全程序核心的 DNNs 可能带来的具体威胁，例如恶意软件检测工具和生物识别。除了与 NNs 广泛应用于敏感数据管理相关的风险，如健康数据，这些威胁导致了基于
    GAN 的新型攻击形式，甚至可能 compromise 公民的健康和生理安全。
- en: In the next chapter, we will learn how to evaluate algorithms with the help
    of several examples.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何通过多个示例评估算法。
