- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: The Future of Graph Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图学习的未来
- en: Throughout this book, we’ve covered a wide range of topics regarding graph learning,
    from fundamental concepts to cutting-edge applications. You now have a solid foundation
    to tackle complex graph-based problems and contribute to this rapidly evolving
    field.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书涵盖了图学习的广泛主题，从基础概念到前沿应用。现在你已经具备了坚实的基础，可以应对复杂的基于图的问题，并为这一快速发展的领域做出贡献。
- en: The field of graph learning stands at the cusp of a revolutionary era, poised
    to transform how we understand and interact with complex, interconnected data.
    As we look ahead, several key trends and advancements are shaping the trajectory
    of this dynamic field.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图学习领域正处于革命性时代的风口浪尖，准备转变我们理解和与复杂、相互关联数据互动的方式。展望未来，几个关键的趋势和进展正在塑造这一动态领域的发展轨迹。
- en: 'In this last chapter, we’ll discuss the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章最后，我们将讨论以下主题：
- en: Emerging trends and directions
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新兴的趋势和方向
- en: Advanced architectures and techniques
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级架构和技术
- en: Integration with other **artificial intelligence** ( **AI** ) domains
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他**人工智能**（**AI**）领域的集成
- en: Potential breakthroughs and long-term vision
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 潜在的突破与长期愿景
- en: Emerging trends and directions
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 新兴的趋势和方向
- en: The new trends in graph learning reflect both the growing capabilities of graph-based
    models and the expanding range of applications where they’re being deployed. From
    advances in model architectures to novel training techniques, the following developments
    are at the forefront of graph learning research and practice.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图学习的新趋势反映了基于图的模型日益增强的能力以及它们在应用领域的广泛扩展。从模型架构的进展到新颖的训练技术，以下发展处于图学习研究和实践的前沿。
- en: Scalability and efficiency
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展性和效率
- en: As we saw in [*Chapter 5*](B22118_05.xhtml#_idTextAnchor093) , the ability to
    handle increasingly large and complex graphs is becoming a crucial challenge as
    data volumes grow exponentially. Researchers are developing innovative approaches
    to tackle this challenge.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[*第5章*](B22118_05.xhtml#_idTextAnchor093)中看到的那样，随着数据量的指数级增长，处理日益庞大和复杂的图已经成为一个关键挑战。研究人员正在开发创新的方法来应对这一挑战。
- en: Handling larger and more complex graphs
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理更大、更复杂的图
- en: New algorithms are being designed to process graphs with billions of nodes and
    edges efficiently (for more details on node- and edge-level learning, please refer
    to [*Chapter 2*](B22118_02.xhtml#_idTextAnchor042) ). These methods often leverage
    the sparsity and locality properties of real-world graphs. For example, sampling-based
    approaches such as **GraphSAGE** (see [*Chapter 4*](B22118_04.xhtml#_idTextAnchor078)
    ) and **FastGCN** have shown promise in scaling **graph neural networks** ( **GNNs**
    ) to large graphs by operating on subsets of nodes rather than the entire graph.
    Another direction is the development of more efficient aggregation schemes, such
    as the **Cluster-GCN** method (also discussed in [*Chapter 4*](B22118_04.xhtml#_idTextAnchor078)
    ), which pre-processes the graph into smaller clusters to reduce computational
    complexity.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 新的算法正在被设计，用于高效地处理包含数十亿节点和边的图（有关节点级和边级学习的更多详细信息，请参见[*第2章*](B22118_02.xhtml#_idTextAnchor042)）。这些方法通常利用现实世界图的稀疏性和局部性特征。例如，基于采样的方法，如**GraphSAGE**（参见[*第4章*](B22118_04.xhtml#_idTextAnchor078)）和**FastGCN**，已经在通过操作节点子集而非整个图来扩展**图神经网络**（**GNNs**）到大规模图中表现出前景。另一个方向是开发更高效的聚合方案，如**Cluster-GCN**方法（也在[*第4章*](B22118_04.xhtml#_idTextAnchor078)中讨论），该方法将图预处理为较小的聚类以降低计算复杂度。
- en: Distributed and parallel graph learning algorithms
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分布式和并行图学习算法
- en: Techniques such as graph partitioning and distributed training allow massive
    graphs to be processed across multiple machines or **graph processing units**
    ( **GPUs** ). This allows us to scale to previously intractable problem sizes.
    Distributed GNN frameworks such as **DistDGL** ( [https://arxiv.org/abs/2010.05337](https://arxiv.org/abs/2010.05337)
    ) and **AliGraph** ( [https://arxiv.org/abs/1902.08730](https://arxiv.org/abs/1902.08730)
    ) are making it possible to train models on graphs with billions of nodes and
    edges. These systems often employ sophisticated partitioning strategies to minimize
    communication overhead while maintaining model accuracy.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 技术如图分割和分布式训练使得可以在多个机器或**图处理单元**（**GPU**）上处理大规模图。这使得我们能够扩展到以前无法处理的问题规模。分布式GNN框架，如**DistDGL**（[https://arxiv.org/abs/2010.05337](https://arxiv.org/abs/2010.05337)）和**AliGraph**（[https://arxiv.org/abs/1902.08730](https://arxiv.org/abs/1902.08730)），使得在包含数十亿节点和边的图上训练模型成为可能。这些系统通常采用复杂的分割策略，以最小化通信开销，同时保持模型的准确性。
- en: Graph compression techniques
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图压缩技术
- en: Novel methods for compressing graph structures while preserving important topological
    information are emerging. These techniques reduce memory requirements and computational
    complexity, making it feasible to work with enormous graphs on limited hardware.
    Approaches such as **graph sparsification** and **node pruning** can significantly
    reduce graph size while maintaining essential structural properties. Additionally,
    techniques such as quantization and low-rank approximation are being applied to
    GNN models to reduce their memory footprint.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 出现了新方法，用于在保留重要拓扑信息的同时压缩图结构。这些技术减少了内存需求和计算复杂性，使得在有限硬件上处理巨大的图变得可行。诸如**图稀疏化**和**节点剪枝**的方法，可以显著减少图的大小，同时保持基本的结构属性。此外，量化和低秩近似等技术也正在应用于GNN模型，以减少其内存占用。
- en: Interpretability and explainability
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可解释性与可解释性
- en: As graph learning models become more complex, the need for interpretability
    grows.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 随着图学习模型变得更加复杂，解释性需求也在增加。
- en: Developing methods to understand GNN decisions
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开发理解GNN决策的方法
- en: Researchers are creating techniques to visualize and explain the decision-making
    process of GNNs. This includes methods such as attention visualization and feature
    importance analysis. For instance, **GNNExplainer** provides a way to identify
    important subgraphs and features for individual predictions. Other approaches,
    such as **PGExplainer** , focus on generating human-readable explanations for
    GNN predictions.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在开发技术，以可视化并解释GNN的决策过程。这包括诸如注意力可视化和特征重要性分析等方法。例如，**GNNExplainer** 提供了一种识别个别预测中重要子图和特征的方法。其他方法，如**PGExplainer**，则专注于生成易于理解的GNN预测解释。
- en: Visualization techniques for graph learning models
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图学习模型的可视化技术
- en: Advanced visualization tools are being developed to help researchers and practitioners
    understand the inner workings of graph models. These tools can reveal patterns
    in node embeddings (which we also explored in [*Chapter 3*](B22118_03.xhtml#_idTextAnchor063)
    ), highlight important subgraphs, and show how information flows through the graph.
    Projects such as **GraphViz** and **NetworkX** are being extended to support the
    visualization of GNN architectures and their learned representations.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 正在开发先进的可视化工具，帮助研究人员和从业者理解图模型的内部工作原理。这些工具可以揭示节点嵌入中的模式（我们也在[*第3章*](B22118_03.xhtml#_idTextAnchor063)中探讨了这一点），突出显示重要的子图，并展示信息如何在图中流动。诸如**GraphViz**和**NetworkX**等项目正在扩展，以支持可视化GNN架构及其学习到的表示。
- en: Causal inference in graph structures
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图结构中的因果推断
- en: There’s growing interest in understanding causal relationships within graphs.
    This involves developing methods to distinguish between correlation and causation
    in graph data, which is crucial for many real-world applications. Causal discovery
    algorithms for graphs such as **directed acyclic graph-graph neural networks**
    ( **DAG-GNNs** ) are being developed to infer causal structures from observational
    data. These methods have potential applications in fields such as healthcare and
    social sciences.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对图中的因果关系的理解兴趣日益增长。这涉及到开发方法，以区分图数据中的相关性和因果性，这对于许多实际应用至关重要。针对图的因果发现算法，如**有向无环图-图神经网络**（**DAG-GNNs**），正被开发用于从观测数据中推断因果结构。这些方法在医疗保健和社会科学等领域具有潜在的应用。
- en: Dynamic and temporal graphs
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动态与时序图
- en: Many real-world graphs evolve, necessitating new approaches.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 许多现实世界中的图是动态演化的，这需要新的方法来应对。
- en: Learning about evolving graph structures
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习关于演变的图结构
- en: Techniques are being developed to handle graphs where nodes and edges appear
    or disappear over time. This is particularly important for applications such as
    social network analysis and financial fraud detection. Models such as **EvolveGCN**
    and **DynGEM** can update node representations efficiently as the graph structure
    changes. These approaches often use recurrent architectures to capture temporal
    dependencies.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正在开发处理节点和边随时间出现或消失的图的方法。这对于社交网络分析和金融欺诈检测等应用尤其重要。像**EvolveGCN**和**DynGEM**这样的模型能够随着图结构的变化有效更新节点表示。这些方法通常使用递归架构来捕捉时间依赖关系。
- en: Incorporating temporal information in graph models
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在图模型中融合时间信息
- en: Researchers are exploring ways to embed time-related information directly into
    graph models. This allows complex temporal dependencies and patterns to be captured
    in dynamic graphs. **Temporal graph neural networks** ( **TGNNs** ) (see [*Chapter
    11*](B22118_11.xhtml#_idTextAnchor211) ) and **time-aware graph neural networks**
    ( **TA-GNNs** ) are examples of architectures that are designed to handle continuous-time
    dynamic graphs.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在探索将时间相关的信息直接嵌入图模型的方法。这使得复杂的时间依赖关系和模式可以在动态图中被捕捉。**时间图神经网络**（**TGNNs**）（见[*第11章*](B22118_11.xhtml#_idTextAnchor211)）和**时间感知图神经网络**（**TA-GNNs**）是为处理连续时间动态图而设计的架构示例。
- en: Predicting future graph states
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预测未来的图状态
- en: Advanced models are being created to forecast how graphs will evolve. This has
    applications in areas such as traffic prediction, epidemic modeling, and recommendation
    systems (which we looked at in detail in [*Chapter 9*](B22118_09.xhtml#_idTextAnchor156)
    ). Methods such as **Graph WaveNet** , **spatial-temporal graph neural networks**
    ( **STGNNs** ) (see [*Chapter 11*](B22118_11.xhtml#_idTextAnchor211) ), and **spatial-temporal
    graph convolutional networks** ( **STGCNs** ) combine graph convolutions with
    temporal convolutions to capture both spatial and temporal dependencies for forecasting
    tasks.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 正在创建高级模型来预测图的演变。这在交通预测、流行病建模和推荐系统等领域有广泛应用（我们在[*第9章*](B22118_09.xhtml#_idTextAnchor156)中进行了详细探讨）。像**Graph
    WaveNet**、**时空图神经网络**（**STGNNs**）（见[*第11章*](B22118_11.xhtml#_idTextAnchor211)）和**时空图卷积网络**（**STGCNs**）等方法将图卷积与时间卷积结合，以捕捉空间和时间的依赖关系，从而进行预测任务。
- en: Heterogeneous and multi-modal graphs
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 异质和多模态图
- en: Real-world graphs often contain diverse types of nodes and edges, as well as
    multiple data modalities.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现实世界中的图通常包含多种类型的节点和边，以及多种数据模态。
- en: Handling diverse node and edge types
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理多样化的节点和边类型
- en: New architectures are being designed to process graphs with heterogeneous node
    and edge types effectively. This is crucial for applications such as knowledge
    graphs and biological networks. **Heterogeneous graph neural networks** ( **HGNNs**
    ) (see [*Chapter 4*](B22118_04.xhtml#_idTextAnchor078) ) and **relational graph
    convolutional networks** ( **R-GCNs** ) are examples of models that can handle
    multiple node and edge types.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 新的架构正在被设计，用于有效处理具有异质节点和边类型的图谱。这对于知识图谱和生物网络等应用至关重要。**异质图神经网络**（**HGNNs**）（见[*第4章*](B22118_04.xhtml#_idTextAnchor078)）和**关系图卷积网络**（**R-GCNs**）是能够处理多种节点和边类型的模型示例。
- en: Integrating multiple data modalities with graphs
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将多种数据模态与图结合
- en: Researchers are developing methods to combine graph data with other modalities
    such as text, images, and audio. This allows for richer representations and more
    powerful models. For instance, **Graph-BERT** combines graph structure with textual
    information using transformer architectures. In the field of computer vision,
    which we covered in [*Chapter 10*](B22118_10.xhtml#_idTextAnchor182) , methods
    such as STGNNs integrate visual and graph data for tasks such as action recognition.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在开发将图数据与其他模态（如文本、图像和音频）结合的方法。这使得图谱能够表示更丰富的信息，并构建更强大的模型。例如，**Graph-BERT**结合了图结构和文本信息，采用了变换器架构。在我们在[*第10章*](B22118_10.xhtml#_idTextAnchor182)中讨论的计算机视觉领域，方法如STGNNs将视觉和图数据结合，用于动作识别等任务。
- en: Cross-modal learning on graphs
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图谱上的跨模态学习
- en: Techniques for transferring knowledge between different modalities within a
    graph are emerging. This enables more robust and versatile graph learning models.
    Approaches such as **graph cross-modal attention networks** allow information
    to be exchanged between different modalities, enhancing performance on tasks that
    require multi-modal reasoning.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在正在出现跨模态知识转移技术，这使得图学习模型更加健壮和多功能。例如，**图跨模态注意力网络**（**graph cross-modal attention
    networks**）可以在不同模态之间交换信息，增强在需要多模态推理的任务上的表现。
- en: Advanced architectures and techniques
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级架构和技术
- en: From advanced transformer architectures to cutting-edge generative models and
    innovative reinforcement learning strategies, graph learning demonstrates immense
    potential across a diverse set of tasks.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 从先进的变压器架构到前沿的生成模型，再到创新的强化学习策略，图学习在各种任务中展现出巨大的潜力。
- en: Graph transformers and attention mechanisms
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图变换器和注意力机制
- en: The success of transformer architectures in **natural language processing**
    ( **NLP** ), which we looked at in [*Chapter 8*](B22118_08.xhtml#_idTextAnchor138)
    , is inspiring new approaches in graph learning.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在**自然语言处理**（**NLP**）中，变压器架构的成功（我们在[*第8章*](B22118_08.xhtml#_idTextAnchor138)中讨论过）正在激发图学习的新方法。
- en: Adapting transformer architectures for graph data
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为图数据适配变压器架构
- en: Researchers are modifying transformer models so that they work effectively with
    graph-structured data. This allows long-range dependencies and global context
    to be captured in graphs. **Graph transformer networks** ( **GTNs** ) adapt the
    self-attention mechanism to operate on graph-structured data, enabling the model
    to learn complex relationships between nodes. These models can dynamically adjust
    the graph structure during the learning process, potentially discovering hidden
    relationships that are not explicitly present in the original graph.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在修改变压器模型，使其能够有效地处理图结构数据。这使得图中能够捕捉到长程依赖关系和全局上下文。**图变换器网络**（**GTNs**）调整自注意力机制，以便在图结构数据上操作，使模型能够学习节点之间的复杂关系。这些模型可以在学习过程中动态调整图结构，可能会发现原始图中未显式呈现的隐藏关系。
- en: Self-attention mechanisms for graph learning
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图学习的自注意力机制
- en: Novel attention mechanisms designed specifically for graphs are being developed.
    These allow models to focus on the most relevant parts of a graph for a given
    task. **Graph attention networks** ( **GATs** ) (see [*Chapter 4*](B22118_04.xhtml#_idTextAnchor078)
    ) introduce attention coefficients to weigh the importance of different neighboring
    nodes during the aggregation step. This enables the model to assign different
    importance to different nodes, improving performance on various graph-based tasks.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 专门为图设计的新型注意力机制正在开发。这些机制使得模型能够专注于图中与给定任务最相关的部分。**图注意力网络**（**GATs**）（见[*第4章*](B22118_04.xhtml#_idTextAnchor078)）引入了注意力系数，在聚合步骤中对不同邻近节点的重要性进行加权。这使得模型能够为不同的节点分配不同的重要性，从而提升在各种图任务中的表现。
- en: Long-range dependencies in graphs
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图中的长程依赖关系
- en: New techniques are emerging to capture relationships between distant nodes in
    a graph efficiently. This is particularly important for tasks that require global
    graph structure to be understood. Methods such as **adaptive graph convolutional
    networks** ( **AGCNs** ) and graph wavelets are being developed to capture multi-scale
    information in graphs, allowing models to consider both local and global graph
    structures simultaneously.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 新技术正在出现，以高效地捕捉图中远距离节点之间的关系。这对于需要理解全局图结构的任务尤为重要。方法如**自适应图卷积网络**（**AGCNs**）和图小波正在开发，以捕捉图中的多尺度信息，允许模型同时考虑局部和全局图结构。
- en: AGCNs are designed to dynamically adjust the graph structure during the learning
    process. This adaptive nature allows them to capture and model relationships between
    nodes that may not be directly connected in the original graph structure. By doing
    so, AGCNs can establish connections between distant nodes effectively, thus addressing
    the long-range dependency problem that traditional GCNs often struggle with.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**AGCNs** 旨在在学习过程中动态调整图结构。这种自适应特性使其能够捕捉并建模在原始图结构中可能没有直接连接的节点之间的关系。通过这种方式，**AGCNs**
    可以有效地建立远距离节点之间的连接，从而解决传统 **GCNs** 经常难以应对的长程依赖问题。'
- en: Graph generative models
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图生成模型
- en: The ability to generate realistic graph structures is opening up new possibilities.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 生成逼真图结构的能力正在开启新的可能性。
- en: Generating realistic graph structures
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成逼真的图结构
- en: Advanced generative models, such as **graph variational autoencoders** ( **GVAEs**
    ) and **graph generative adversarial networks** ( **GraphGANs** ), are being developed
    to create synthetic graphs that mimic real-world network properties. These models
    can learn to generate graphs with specific characteristics, such as degree distribution,
    clustering coefficient, and community structure. This capability is particularly
    useful for simulating complex systems and generating benchmark datasets.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 高级生成模型，如**图变分自编码器**（**GVAE**）和**图生成对抗网络**（**GraphGAN**），正在被开发用于创建模拟真实网络属性的合成图。这些模型能够学习生成具有特定特征的图，如度分布、聚类系数和社区结构。这一能力特别适用于模拟复杂系统和生成基准数据集。
- en: Applications in drug discovery and material science
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 药物发现和材料科学的应用
- en: Graph generative models are being used to design new molecules and materials
    with desired properties, potentially accelerating scientific discovery. Models
    such as **MolGAN** and **GraphAF** can generate novel molecular structures with
    specific chemical properties, aiding in the discovery of new drugs and materials.
    These approaches have the potential to significantly reduce the time and cost
    associated with traditional experimental methods in these fields.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图生成模型正在被用于设计具有所需属性的新分子和材料，可能会加速科学发现。像**MolGAN**和**GraphAF**这样的模型可以生成具有特定化学属性的新型分子结构，有助于新药物和材料的发现。这些方法有潜力显著减少传统实验方法所需的时间和成本。
- en: GVAEs and GANs
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GVAEs和GANs
- en: These models are being refined to generate increasingly realistic and diverse
    graph structures, with applications ranging from social network simulation to
    protein design. Recent advancements include conditional graph generation, where
    models can generate graphs with specific properties or constraints. This has applications
    in areas such as network design, where graphs with certain structural properties
    are desired.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型正在不断改进，以生成越来越逼真和多样的图结构，应用范围从社交网络模拟到蛋白质设计。最近的进展包括条件图生成，在这种方式下，模型可以生成具有特定属性或约束的图。这在网络设计等领域具有应用价值，其中需要具有特定结构属性的图。
- en: Few-shot and zero-shot learning on graphs
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图上的少样本和零样本学习
- en: '**Few-shot learning** on graphs refers to the ability of a model to learn and
    make predictions on graph-structured data with only a small number of labeled
    examples. This approach is particularly useful when dealing with large-scale graph
    datasets where obtaining labeled data is expensive or time-consuming.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**少样本学习**在图上的应用是指模型能够在只有少量标注示例的情况下学习并对图结构数据进行预测。这种方法在处理大规模图数据集时尤其有用，因为获取标注数据既昂贵又耗时。'
- en: '**Zero-shot learning** on graphs, on the other hand, takes this concept even
    further by enabling models to make predictions on entirely new classes or tasks
    that weren’t seen during training. This is achieved by leveraging semantic information
    or attributes associated with nodes or edges in the graph.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，**零样本学习**在图上的应用更进一步，使模型能够对训练过程中未见过的全新类别或任务进行预测。这是通过利用与图中节点或边相关的语义信息或属性来实现的。
- en: Transferring knowledge to new graph tasks
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 知识迁移到新的图任务
- en: Techniques are being developed to apply knowledge from one graph domain to another,
    enabling rapid adaptation to new problems. Graph meta-learning frameworks, such
    as **Meta-GNN** , allow models to quickly adapt to new tasks by learning a meta-model
    that can be fine-tuned with minimal data. This is particularly useful in domains
    where labeled data is scarce or expensive to obtain.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 正在开发的技术可以将一个图领域的知识应用到另一个领域，从而实现快速适应新问题。图的元学习框架，如**Meta-GNN**，允许模型通过学习一个可以通过最少数据进行微调的元模型，快速适应新任务。这在标注数据稀缺或获取成本高的领域尤为有用。
- en: Meta-learning approaches for graphs
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图的元学习方法
- en: Researchers are exploring meta-learning frameworks that can quickly adapt to
    new graph tasks with minimal fine-tuning. Approaches such as **graph few-shot
    learning** ( **GFL** ) aim to learn transferable knowledge across different graph
    datasets and tasks. These methods often involve learning a base model that can
    be quickly adapted to new tasks with just a few examples.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在探索可以快速适应新图任务并进行最小调整的元学习框架。像**图少样本学习**（**GFL**）这样的方式旨在跨不同的图数据集和任务学习可转移的知识。这些方法通常涉及学习一个基础模型，可以通过少量示例快速适应新任务。
- en: Handling limited labeled data in graph domains
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理图领域中的有限标注数据
- en: New semi-supervised and self-supervised learning techniques are being created
    to leverage large amounts of unlabeled graph data effectively. Self-supervised
    methods such as **graph contrastive learning** ( **GraphCL** ) and **Deep Graph
    Infomax** ( **DGI** ) learn useful representations from unlabeled graph data,
    which can then be fine-tuned for specific tasks with limited labeled data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 正在创造新的半监督和自监督学习技术，以有效利用大量未标注的图数据。像**图对比学习**（**GraphCL**）和**深度图信息最大化**（**DGI**）这样的自监督方法，通过从未标注的图数据中学习有用的表示，然后可以使用有限的标注数据进行微调，以适应特定任务。
- en: Reinforcement learning on graphs
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图上的强化学习
- en: Combining graph learning with **reinforcement learning** ( **RL** ) is opening
    up new application areas.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 将图学习与**强化学习**（**RL**）结合正在开辟新的应用领域。
- en: Graph-based RL for decision-making
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于图的强化学习在决策制定中的应用
- en: Researchers are developing RL algorithms that can operate directly on graph-structured
    state spaces, enabling more efficient decision-making in complex environments.
    **Graph convolutional reinforcement learning** ( **GCRL** ) ( [https://arxiv.org/abs/1810.09202](https://arxiv.org/abs/1810.09202)
    ) combines GNNs with RL to handle environments with graph-structured state representations.
    This approach has shown promise in tasks such as traffic signal control and resource
    allocation in complex networks.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在开发能够直接在图结构状态空间上运行的强化学习算法，从而在复杂环境中实现更高效的决策制定。**图卷积强化学习**（**GCRL**）([https://arxiv.org/abs/1810.09202](https://arxiv.org/abs/1810.09202)
    )将GNN与强化学习结合，处理具有图结构状态表示的环境。这一方法在交通信号控制和复杂网络中的资源分配等任务中显示出了前景。
- en: Applications in robotics and autonomous systems
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在机器人技术和自主系统中的应用
- en: Graph-based RL is being applied to tasks such as robot navigation and multi-agent
    coordination, where understanding spatial relationships is crucial. For example,
    GNNs for decentralized multi-robot path planning have been developed to coordinate
    multiple robots in complex environments. These approaches allow robots to reason
    about their environment and other agents more effectively.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的强化学习（RL）正在应用于机器人导航和多智能体协调等任务，在这些任务中，理解空间关系至关重要。例如，针对去中心化多机器人路径规划的图神经网络（GNN）已经被开发出来，用于协调复杂环境中的多个机器人。这些方法使得机器人能够更有效地推理其环境和其他智能体。
- en: Combining GNNs with RL algorithms
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将图神经网络（GNN）与强化学习（RL）算法结合
- en: Novel architectures that integrate GNNs into RL frameworks are being explored,
    allowing for more effective learning in graph-structured environments. Approaches
    such as **relational reinforcement learning** ( **RRL** ) use GNNs to model relationships
    between entities in an environment, enabling more sample-efficient learning in
    complex, structured domains. This has potential applications in areas such as
    strategic game-playing and complex system optimization.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 正在探索将图神经网络（GNN）融入强化学习框架的新型架构，这使得在图结构环境中能够更有效地进行学习。像**关系强化学习**（**RRL**）这样的 approaches
    利用GNN来建模环境中实体之间的关系，从而实现更高效的样本学习，尤其是在复杂的结构化领域中。这一方法在战略游戏和复杂系统优化等领域具有潜在应用。
- en: Integration with other AI domains
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与其他人工智能领域的整合
- en: The integration of different AI domains has emerged as a key strategy for tackling
    complex problems and enhancing system performance. This synergistic approach is
    particularly evident in the integration of graph learning with **large language
    models** ( **LLMs** ), federated learning, and quantum computing techniques.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 不同人工智能领域的整合已成为解决复杂问题和提升系统性能的关键策略。这一协同方法在将图学习与**大语言模型**（**LLMs**）、联邦学习和量子计算技术相结合时尤为明显。
- en: Graph learning and LLMs
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图学习与大语言模型（LLMs）
- en: The synergy between graph learning and LLMs is, as we learned in [*Chapter 6*](B22118_06.xhtml#_idTextAnchor118)
    , a rapidly growing area. Let’s explore the future of this relationship.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[*第六章*](B22118_06.xhtml#_idTextAnchor118) 中学到的，图学习与大语言模型（LLMs）之间的协同作用是一个快速发展的领域。让我们一起探讨这种关系的未来。
- en: Enhancing LLMs with graph-structured knowledge
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用图结构知识增强大语言模型（LLMs）
- en: Researchers are exploring ways to incorporate graph-structured knowledge into
    LLMs, improving their reasoning capabilities and factual accuracy. One approach
    is to use knowledge graphs as external memory for LLMs, allowing them to access
    structured information during inference. For example, the **knowledge graph language
    model** ( **KGLM** ) integrates a knowledge graph with an LLM, enabling more accurate
    and contextually relevant text generation.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在探索将图结构化知识纳入LLM的方法，以提高其推理能力和事实准确性。一种方法是将知识图谱作为LLM的外部记忆，使其在推理时可以访问结构化信息。例如，**知识图谱语言模型**（**KGLM**）将知识图谱与LLM集成，从而实现更准确且具有上下文相关性的文本生成。
- en: Another direction is to pre-train LLMs on graph-structured data alongside text.
    Models such as **Enhanced Language Representation with Informative Entities**
    ( **ERNIE** ) incorporate entity embeddings from knowledge graphs during pre-training,
    resulting in improved performance on entity-related tasks.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方向是对图结构化数据与文本一起进行LLM的预训练。像**带有信息实体的增强语言表示**（**ERNIE**）这样的模型在预训练过程中结合了来自知识图谱的实体嵌入，从而在与实体相关的任务上提升了表现。
- en: Graph-based reasoning in language models
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于图的语言模型推理
- en: New techniques are being developed to enable LLMs to perform explicit reasoning
    over graph-structured knowledge, enhancing their ability to answer complex queries.
    Graph-to-text models such as **Graph2Seq** can generate natural language descriptions
    of graph structures, bridging the gap between structured knowledge and human-readable
    text.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 新技术正在被开发，以使LLM能够对图结构化知识进行显式推理，从而增强其回答复杂问题的能力。像**Graph2Seq**这样的图到文本模型可以生成图结构的自然语言描述，架起了结构化知识与人类可读文本之间的桥梁。
- en: Researchers are also developing methods for multi-hop reasoning over knowledge
    graphs using LLMs. For instance, the **Graph REASoning Enhanced Language Model**
    ( **GREASELM** ) framework ( [https://arxiv.org/abs/2201.08860](https://arxiv.org/abs/2201.08860)
    ) allows language models to perform step-by-step reasoning over knowledge graphs,
    improving performance on complex question-answering tasks.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员还在开发使用LLM进行多跳推理的方法。例如，**图推理增强语言模型**（**GREASELM**）框架（[https://arxiv.org/abs/2201.08860](https://arxiv.org/abs/2201.08860)）允许语言模型在知识图谱上执行逐步推理，从而提高在复杂问答任务中的表现。
- en: Knowledge graph completion and updating using LLMs
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用LLM进行知识图谱的补充和更新
- en: LLMs are being used to automatically expand and update knowledge graphs, creating
    a symbiotic relationship between textual and graph-based knowledge. Models such
    as **GPT-3** have shown the ability to generate plausible facts that can be used
    to populate knowledge graphs. However, ensuring the accuracy of these generated
    facts remains a challenge.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: LLM正在被用来自动扩展和更新知识图谱，创造文本与图结构化知识之间的共生关系。像**GPT-3**这样的模型已显示出生成可以用来填充知识图谱的合理事实的能力。然而，确保这些生成事实的准确性仍然是一个挑战。
- en: Techniques such as **zero-shot relation extraction** are being developed to
    automatically identify new relationships in text and add them to existing knowledge
    graphs. This allows us to continuously update knowledge graphs based on the latest
    information that’s been extracted from text-by-language models.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 像**零-shot关系抽取**这样的技术正在被开发，用于自动识别文本中的新关系并将其添加到现有的知识图谱中。这使得我们能够基于从文本中提取的最新信息，持续更新知识图谱。
- en: Federated graph learning
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 联邦图学习
- en: '**Federated graph learning** ( **FGL** ) is an innovative approach that combines
    federated learning principles with graph-based data structures and algorithms.
    It enables multiple participants to train machine learning models on distributed
    graph data collaboratively without directly sharing sensitive information. FGL
    addresses privacy concerns in scenarios involving interconnected data, such as
    social networks or financial systems. This method allows graph-structured data
    to be analyzed while maintaining data locality and privacy, making it particularly
    valuable in domains where data sensitivity and regulatory compliance are crucial.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**联邦图学习**（**FGL**）是一种创新方法，它将联邦学习原则与基于图的数据结构和算法结合在一起。它使多个参与者能够在分布式图数据上协同训练机器学习模型，而无需直接共享敏感信息。FGL解决了涉及互联数据（如社交网络或金融系统）场景中的隐私问题。该方法允许在保持数据本地性和隐私的同时分析图结构数据，使其在数据敏感性和合规性至关重要的领域具有特别重要的价值。'
- en: Distributed learning on decentralized graph data
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分布式学习在去中心化图数据上的应用
- en: Federated learning approaches are being adapted for graph data, allowing multiple
    parties to train models collaboratively without sharing raw data. **Federated
    graph neural networks** ( **FedGNNs** ) allow GNNs to be trained across multiple
    decentralized graph datasets, with only model updates being shared between parties.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦学习方法正在被适应于图数据，允许多个方在无需共享原始数据的情况下共同训练模型。**联邦图神经网络**（**FedGNNs**）允许在多个去中心化的图数据集上训练
    GNN，仅在各方之间共享模型更新。
- en: Techniques such as vertical federated learning are being explored for scenarios
    where different features of the same entities are distributed across multiple
    parties. This allows for collaborative learning on graph data, even when different
    aspects of the graph are held by different organizations.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 垂直联邦学习等技术正在被探索，用于处理同一实体的不同特征分布在多个方的场景。这使得即使图的不同部分由不同组织持有，也能进行图数据的协作学习。
- en: Privacy-preserving graph analytics
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 隐私保护图分析
- en: New techniques are being developed to perform graph analysis while protecting
    sensitive information, which is crucial for applications in healthcare and finance.
    Differential privacy methods for graphs, such as edge differential privacy, allow
    graph statistics to be released while formal privacy guarantees are provided.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 正在开发新技术，以在保护敏感信息的同时执行图分析，这对医疗和金融领域的应用至关重要。图的差分隐私方法，如边缘差分隐私，可以在提供正式隐私保证的同时发布图统计数据。
- en: Secure **multi-party computation** ( **MPC** ) techniques are being adapted
    for graph data, enabling multiple parties to jointly analyze their graph data
    without revealing sensitive information to each other. This is particularly useful
    in scenarios where different organizations want to collaborate on graph analysis
    without sharing raw data.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 安全的**多方计算**（**MPC**）技术正在适应图数据，允许多个方共同分析图数据而不相互泄露敏感信息。这在不同组织希望共同进行图分析而不共享原始数据的场景中尤为有用。
- en: Applications in healthcare and finance
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 医疗和金融领域的应用
- en: FGL is enabling collaborative research and model development in sensitive domains
    such as healthcare and finance, where data privacy is paramount. In healthcare,
    FGL can be used to analyze patient interaction networks across multiple hospitals
    without sharing sensitive patient data. This can lead to improved disease prediction
    and treatment recommendation models.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: FGL 正在推动在数据隐私至关重要的敏感领域（如医疗和金融）中进行协作研究和模型开发。在医疗领域，FGL 可以用于分析跨多家医院的患者互动网络，而无需共享敏感的患者数据。这有助于改进疾病预测和治疗推荐模型。
- en: Expanding on what we discussed in [*Chapter 11*](B22118_11.xhtml#_idTextAnchor211)
    , in finance, FGL can be applied to tasks such as fraud detection in transaction
    networks, allowing multiple financial institutions to collaborate on model development
    without having to share confidential customer data.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展我们在[*第11章*](B22118_11.xhtml#_idTextAnchor211)中讨论的内容，在金融领域，FGL 可应用于交易网络中的欺诈检测等任务，允许多家金融机构在无需共享机密客户数据的情况下进行模型开发。
- en: Quantum GNNs
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 量子图神经网络（Quantum GNNs）
- en: The intersection of quantum computing and graph learning is an exciting frontier.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 量子计算与图学习的交集是一个令人兴奋的前沿领域。
- en: Leveraging quantum computing for graph problems
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 利用量子计算解决图问题
- en: Researchers are exploring how quantum algorithms can solve certain graph problems
    exponentially faster than classical algorithms. **Quantum approximate optimization
    algorithms** ( **QAOA** ) have shown promise for solving combinatorial optimization
    problems on graphs, such as the **maximum** **cut problem** .
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在探索量子算法如何比经典算法更快地解决某些图问题。**量子近似优化算法**（**QAOA**）在解决图上的组合优化问题（如**最大割问题**）方面表现出了潜力。
- en: The maximum cut problem is a fundamental graph optimization task where the goal
    is to partition the vertices of a graph into two sets such that the number of
    edges between the sets is maximized. By leveraging quantum superposition and interference,
    QAOA can explore multiple graph partitions simultaneously, potentially leading
    to faster convergence to near-optimal solutions.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最大割问题是一个基本的图优化任务，其目标是将图的顶点划分为两组，使得两组之间的边数最大化。通过利用量子叠加和干涉，QAOA 可以同时探索多个图的划分，从而可能更快地收敛到接近最优的解。
- en: In addition, quantum walk-based algorithms are being developed for tasks such
    as graph isomorphism testing and centrality computation, potentially offering
    significant speedups over classical methods for certain graph structures.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，基于量子行走的算法正在开发中，适用于图同构测试和中心性计算等任务，可能在某些图结构上提供比经典方法显著的加速。
- en: Quantum-inspired classical algorithms for graphs
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 量子启发的经典算法用于图
- en: Insights from quantum computing are inspiring new classical algorithms for graph
    problems, potentially offering significant speedups. Tensor network methods, inspired
    by quantum many-body physics, are being applied to graph problems such as community
    detection and link prediction (see [*Chapter 7*](B22118_07.xhtml#_idTextAnchor131)
    ).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 来自量子计算的洞察正在启发新的经典算法，以解决图问题，可能带来显著的加速。受量子多体物理学启发的张量网络方法正被应用于图问题，如社区检测和链接预测（参见
    [*第7章*](B22118_07.xhtml#_idTextAnchor131)）。
- en: Additionally, quantum-inspired sampling techniques, such as those based on **quantum
    annealing** , are being adapted for classical computers to solve graph optimization
    problems more efficiently.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，基于**量子退火**的量子启发式采样技术正被调整为适用于经典计算机，以更高效地解决图优化问题。
- en: Potential speedups in graph learning tasks
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图学习任务中的潜在加速
- en: Quantum GNNs are being developed, which could offer dramatic speedups for certain
    graph learning tasks once quantum hardware matures. Variational quantum circuits
    are being designed to implement graph convolution operations, potentially allowing
    for more efficient processing of graph-structured data on quantum hardware.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 量子GNN正被开发中，一旦量子硬件成熟，它们可能为某些图学习任务提供巨大的加速。变分量子电路正在设计中，以实现图卷积操作，这可能使得在量子硬件上更高效地处理图结构数据成为可能。
- en: Hybrid quantum-classical approaches are also being explored, where certain parts
    of a graph learning pipeline are executed on quantum hardware while others remain
    classical. This could allow the strengths of both quantum and classical computing
    paradigms to be leveraged.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 混合量子-经典方法也在探索中，在这种方法中，图学习流程的某些部分在量子硬件上执行，而其他部分保持经典计算。这可能使得量子和经典计算范式的优点能够相互补充。
- en: Potential breakthroughs and long-term vision
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 潜在的突破和长期愿景
- en: As we explore the frontier of artificial intelligence, it’s crucial to consider
    the potential breakthroughs and long-term vision that could shape the future of
    this field.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探索人工智能的前沿时，考虑可能的突破和长期愿景至关重要，这些突破和愿景可能会塑造该领域的未来。
- en: Artificial general intelligence and graphs
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工通用智能与图
- en: Graph representations could play a crucial role in the development of **artificial
    general** **intelligence** ( **AGI** ).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图表示可能在**人工通用智能**（**AGI**）的发展中发挥关键作用。
- en: The role of graph representations in AGI
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图表示在AGI中的作用
- en: Researchers are exploring how graph-structured knowledge and reasoning could
    contribute to more general and flexible AI systems. Graph representations offer
    a natural way to model complex relationships and hierarchies, which is essential
    for human-like reasoning. For example, the **Neuro-Symbolic Concept Learner**
    combines GNNs with symbolic reasoning to learn concepts and relationships from
    visual scenes, demonstrating a potential path toward more general AI systems.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在探索图结构的知识和推理如何有助于更通用和灵活的AI系统。图表示提供了一种自然的方式来建模复杂的关系和层次结构，这对于类人推理至关重要。例如，**神经符号概念学习器**将GNN与符号推理相结合，从视觉场景中学习概念和关系，展示了朝着更通用AI系统发展的潜力。
- en: Graph-based world models are being developed to enable AI systems to build and
    maintain internal representations of their environment. These models can capture
    causal relationships and allow for planning and reasoning in complex, dynamic
    environments, which is crucial for AGI.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的世界模型正在开发中，以使AI系统能够建立和维持其环境的内部表示。这些模型能够捕捉因果关系，并允许在复杂动态环境中进行规划和推理，这对于AGI至关重要。
- en: Graph-based reasoning and common-sense knowledge
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于图的推理和常识知识
- en: Graph representations are being used to capture and reason about common-sense
    knowledge, a key challenge in AI. Projects such as **ConceptNet** and **ATOMIC**
    are building large-scale knowledge graphs that encode common-sense facts and relationships.
    These graphs can be integrated with neural models to enhance their reasoning capabilities
    and ground their understanding in real-world knowledge.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图形表示正在被用于捕捉和推理常识知识，这是人工智能中的一个关键挑战。像**ConceptNet**和**ATOMIC**这样的项目正在构建大规模的知识图谱，编码常识事实和关系。这些图谱可以与神经模型整合，以增强其推理能力，并将其理解基于现实世界的知识。
- en: Researchers are also developing graph-based inference engines that can perform
    multi-hop reasoning over common-sense knowledge graphs. This allows AI systems
    to make logical deductions and answer complex queries that require multiple pieces
    of information to be combined.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员还在开发基于图形的推理引擎，能够在常识知识图上进行多跳推理。这使得人工智能系统能够做出逻辑推理，并回答需要将多个信息片段结合起来的复杂查询。
- en: Integrating symbolic and neural approaches through graphs
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通过图形集成符号和神经方法
- en: Graphs are serving as a bridge between symbolic AI and neural networks, potentially
    leading to more powerful hybrid systems. Neural-symbolic integration approaches,
    such as **logic tensor networks** , use graph structures to combine the strengths
    of neural networks (learning from data) with symbolic logic ( explicit reasoning).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图形正在作为符号人工智能和神经网络之间的桥梁，可能促成更强大的混合系统。神经-符号集成方法，如**逻辑张量网络**，利用图形结构将神经网络（从数据中学习）的优势与符号逻辑（显式推理）的优势相结合。
- en: Graph-based neuro-symbolic architectures are being explored for tasks such as
    visual question-answering and natural language understanding. These systems can
    leverage both the pattern recognition capabilities of neural networks and the
    explicit reasoning capabilities of symbolic systems, potentially leading to more
    robust and interpretable AI.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图形的神经-符号架构正在被探索用于视觉问答和自然语言理解等任务。这些系统可以同时利用神经网络的模式识别能力和符号系统的显式推理能力，有可能导致更强大且更具可解释性的人工智能。
- en: Neuromorphic computing with graphs
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经形态计算与图形
- en: Brain-inspired computing architectures are being explored for graph processing.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 启发自大脑的计算架构正在被探索用于图形处理。
- en: Brain-inspired graph architectures
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启发自大脑的图形架构
- en: Researchers are developing neural network architectures that more closely mimic
    the brain’s graph-like structure. **Spiking neural networks** ( **SNNs** ) are
    being adapted for graph processing tasks, offering potential advantages in terms
    of energy efficiency and biological plausibility. These models can process information
    in a more event-driven manner, similar to how neurons in the brain communicate.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在开发更贴近大脑图形结构的神经网络架构。**脉冲神经网络**（**SNNs**）正在被适应于图形处理任务，提供在能效和生物学合理性方面的潜在优势。这些模型能够以更事件驱动的方式处理信息，类似于大脑中神经元的沟通方式。
- en: Reservoir computing approaches, inspired by the dynamics of biological neural
    networks, are being applied to graph learning tasks. These models can process
    temporal graph data efficiently and have shown promise in tasks such as predicting
    the evolution of dynamic graphs.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 受生物神经网络动态启发的水库计算方法正在被应用于图形学习任务。这些模型能够高效处理时序图数据，并在预测动态图演变等任务中展现出潜力。
- en: Hardware acceleration for graph learning
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图形学习的硬件加速
- en: Specialized hardware is being designed to accelerate graph learning algorithms,
    potentially leading to dramatic speedups. Neuromorphic chips, such as Intel’s
    Loihi, are being developed to process graph-structured data efficiently and run
    SNNs. These chips can potentially offer orders of magnitude of improvements in
    energy efficiency for certain graph learning tasks.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 专用硬件正在被设计以加速图形学习算法，有可能带来显著的速度提升。神经形态芯片，如英特尔的Loihi，正在被开发用于高效处理图形结构化数据并运行SNNs。这些芯片可能在某些图形学习任务中提供数量级的能效提升。
- en: GPUs are being designed specifically for graph computations. These specialized
    processors aim to overcome the memory bandwidth limitations of traditional architectures
    when dealing with large, sparse graphs.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 专门为图形计算设计的GPU正在被研发。这些专用处理器旨在克服传统架构在处理大型稀疏图形时的内存带宽限制。
- en: Energy-efficient graph processing
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高能效的图形处理
- en: New approaches are being explored to make graph learning more energy-efficient
    and are inspired by the brain’s low power consumption. Approximate computing techniques
    are being applied to graph algorithms, trading off some accuracy for significant
    gains in energy efficiency. This is particularly important for edge computing
    applications where power consumption is a critical constraint.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 正在探索新的方法，以提高图学习的能源效率，这些方法受到大脑低功耗消耗的启发。近似计算技术正在应用于图算法，通过牺牲一些准确性来换取显著的能效提升。这对于边缘计算应用尤为重要，因为功耗是一个关键约束。
- en: Researchers are also exploring analog computing approaches for graph processing,
    which can potentially offer extreme energy efficiency for certain graph operations.
    These include using **memristive devices** to implement GNN operations directly
    in hardware. Memristive devices are electronic components that can remember their
    previous resistance state even when power is removed, mimicking the behavior of
    biological synapses. These nanoscale devices hold great promise for advancing
    neuromorphic computing, enabling more efficient and brain-like artificial intelligence
    systems.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员还在探索用于图处理的模拟计算方法，这些方法可能为某些图操作提供极高的能效。这些方法包括使用**忆阻器**设备直接在硬件中实现图神经网络操作。忆阻器是一种电子组件，即使在断电后也能记住其先前的电阻状态，模拟生物突触的行为。这些纳米尺度设备在推动类脑计算方面具有巨大的潜力，能够实现更高效、更类似大脑的人工智能系统。
- en: Graph learning in the Metaverse
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 元宇宙中的图学习
- en: As virtual worlds become more prevalent, graph learning will play a crucial
    role.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 随着虚拟世界的普及，图学习将发挥至关重要的作用。
- en: Representing and learning from virtual world graphs
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从虚拟世界图谱中表示和学习
- en: Techniques are being developed to model and analyze the complex networks of
    interactions in virtual environments. Graph-based representations of virtual worlds
    can capture spatial relationships, object interactions, and user behaviors. These
    graph models can be used for tasks such as efficient rendering, physics simulations,
    and intelligent non-player character behaviors.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 正在开发用于建模和分析虚拟环境中复杂交互网络的技术。基于图的虚拟世界表示能够捕捉空间关系、物体互动和用户行为。这些图模型可用于高效渲染、物理仿真和智能非玩家角色行为等任务。
- en: Researchers are exploring ways to learn about and update the graph representations
    of virtual environments in real time, allowing for dynamic and responsive virtual
    worlds. This includes techniques for online graph learning and incremental graph
    updates.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在探索实时学习和更新虚拟环境图谱表示的方法，从而实现动态响应的虚拟世界。这包括在线图学习和增量图更新的技术。
- en: Graph-based social interactions in digital spaces
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数字空间中的基于图的社交互动
- en: Graph learning is being applied to understand and facilitate social dynamics
    in virtual worlds. Social network analysis techniques are being adapted for virtual
    environments to study user interactions, community formation, and information
    spread. This can help in designing more engaging and socially rich virtual experiences.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图学习正在被应用于理解和促进虚拟世界中的社交动态。社交网络分析技术正在被调整以适应虚拟环境，用于研究用户互动、社区形成和信息传播。这有助于设计更加引人入胜、社交丰富的虚拟体验。
- en: Graph-based recommendation systems are being developed for virtual worlds, suggesting
    connections, activities, or content based on users’ interaction patterns and preferences
    within the virtual environment.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 正在开发基于图的推荐系统，用于虚拟世界，根据用户在虚拟环境中的互动模式和偏好，推荐连接、活动或内容。
- en: Augmented reality applications of graph learning
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图学习的增强现实应用
- en: Graph-based models are being used to understand and enhance the physical world
    in **augmented reality** ( **AR** ) applications. Scene graphs are being employed
    to represent the spatial and semantic relationships between objects in the real
    world, enabling more sophisticated AR experiences. GNNs can be used to reason
    about these scene graphs and predict how virtual objects should interact with
    the real environment.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的模型正在被用于理解和增强**增强现实**（**AR**）应用中的物理世界。场景图被用来表示现实世界中物体之间的空间和语义关系，从而实现更复杂的增强现实体验。图神经网络（GNN）可用于推理这些场景图，并预测虚拟物体如何与现实环境互动。
- en: Researchers are also exploring graph-based approaches for **simultaneous localization
    and mapping** ( **SLAM** ) in AR, using graph optimization techniques to improve
    the accuracy of spatial mapping and tracking.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员还在探索基于图的方法用于**同时定位与建图**（**SLAM**）在增强现实中的应用，通过图优化技术提高空间映射和跟踪的准确性。
- en: Interdisciplinary applications
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跨学科应用
- en: As we’ll see in the following sections, graph learning is finding applications
    in diverse fields.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在接下来的章节中将看到的那样，图学习正被广泛应用于不同领域。
- en: Graph learning in climate science and sustainability
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 气候科学与可持续性中的图学习
- en: Graph-based models are being used to understand complex climate systems and
    optimize resource allocation for sustainability. Climate networks, where *nodes*
    represent geographical locations and *edges* represent climate interactions, are
    being analyzed using graph learning techniques to study phenomena such as El Niño
    and predict extreme weather events.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的模型正在被用来理解复杂的气候系统，并优化资源配置以实现可持续性。气候网络中，*节点*代表地理位置，*边*代表气候相互作用，正在通过图学习技术进行分析，用以研究如厄尔尼诺现象等现象，并预测极端天气事件。
- en: In sustainability, graph learning is being applied to optimize smart grids,
    manage water resources, and design more efficient transportation networks. For
    example, GNNs are being used to predict energy demand and optimize the distribution
    of renewable energy sources.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在可持续性领域，图学习正被应用于优化智能电网、管理水资源以及设计更高效的交通网络。例如，图神经网络（GNNs）被用来预测能源需求并优化可再生能源的分配。
- en: Applications in social sciences and humanities
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 社会科学与人文学科的应用
- en: Researchers are applying graph learning to analyze social networks, study historical
    texts, and understand cultural phenomena. In sociology, graph learning techniques
    are being used to study the spread of information and behaviors through social
    networks. This has applications in understanding phenomena such as the spread
    of fake news or the adoption of new technologies.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在应用图学习来分析社交网络，研究历史文本，并理解文化现象。在社会学中，图学习技术被用来研究信息和行为如何通过社交网络传播。这对于理解如假新闻传播或新技术采用等现象具有应用价值。
- en: In digital humanities, graph learning is being applied to analyze large corpora
    of historical texts, uncovering relationships between concepts, authors, and historical
    events. This can lead to new insights in fields such as literary analysis and
    historical research.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在数字人文学科中，图学习正被应用于分析大量历史文本语料库，揭示概念、作者和历史事件之间的关系。这可能为文学分析和历史研究等领域带来新的见解。
- en: Graph-based approaches in economics and finance
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 经济学和金融领域的基于图的方法
- en: Graph learning is being used to model economic networks, predict market trends,
    and detect financial fraud. In economics, researchers are using GNNs to model
    supply chain networks and predict the impact of disruptions. This has become particularly
    relevant in light of recent global supply chain challenges.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图学习正在被用来建模经济网络、预测市场趋势并检测金融欺诈。在经济学中，研究人员正在使用GNNs来建模供应链网络，并预测扰动的影响。这在最近全球供应链挑战的背景下尤为重要。
- en: In finance, graph-based anomaly detection techniques are being developed to
    identify complex fraud patterns in transaction networks. Graph learning is also
    being applied to analyze financial markets, model relationships between different
    financial instruments, and predict market movements.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融领域，正在开发基于图的异常检测技术，以识别交易网络中的复杂欺诈模式。图学习还被应用于分析金融市场，建模不同金融工具之间的关系，并预测市场动向。
- en: These interdisciplinary applications demonstrate the broad potential of graph
    learning to tackle complex problems across various domains, potentially leading
    to significant breakthroughs in how we understand and manage complex systems.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这些跨学科应用展示了图学习在应对各个领域复杂问题中的广泛潜力，可能会带来我们理解和管理复杂系统的重大突破。
- en: Summary
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored the exciting future of graph learning, highlighting
    key trends and advancements shaping this dynamic field. We discussed upcoming
    directions in scalability and efficiency, focusing on techniques that you can
    use to handle larger and more complex graphs, distributed learning algorithms,
    and graph compression methods. We delved into the growing importance of interpretability
    and explainability in graph models, as well as advancements in handling dynamic
    and temporal graphs. We also covered the challenges and opportunities presented
    by heterogeneous and multi-modal graphs and explored advanced architectures such
    as graph transformers and generative models.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了图学习的激动人心的未来，重点介绍了塑造这一动态领域的关键趋势和进展。我们讨论了可扩展性和效率方面的未来发展，着重介绍了可以用来处理更大、更复杂图的技术，分布式学习算法和图压缩方法。我们深入探讨了图模型中可解释性和可解释性的重要性日益增加的现象，以及处理动态和时序图的进展。我们还讨论了异构和多模态图带来的挑战与机遇，并探讨了图变换器和生成模型等先进架构。
- en: Then, we examined the integration of graph learning with other AI domains, such
    as LLMs and RL, along with privacy-preserving techniques in FGL. In addition,
    we touched on the potential of quantum GNNs and the role of graph learning in
    AGI. Finally, we discussed interdisciplinary applications of graph learning in
    fields such as climate science, social sciences, and economics, showcasing the
    broad impact and potential of this technology across various domains.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们考察了图学习与其他人工智能领域的结合，如LLMs和RL，以及FGL中的隐私保护技术。此外，我们还简要讨论了量子GNN的潜力以及图学习在AGI中的作用。最后，我们讨论了图学习在气候科学、社会科学和经济学等领域的跨学科应用，展示了这一技术在各个领域的广泛影响和潜力。
- en: As this is our final chapter, we want to remind you of all the skills you’ve
    acquired throughout this book and how you can apply them, from understanding why
    we need graphs to using graph deep learning for real-world applications. To continue
    your journey, we recommend exploring further research in specialized areas that
    interest you most, whether that involves GNNs, knowledge graphs, or graph-based
    recommender systems. You may also consider participating in graph learning competitions
    or contributing to open-source graph learning projects to gain practical experience.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是我们的最后一章，我们想提醒你本书中所学到的所有技能，以及如何将它们应用于从理解为何需要图到使用图深度学习进行现实应用的各个方面。为了继续你的学习旅程，我们建议深入探索你最感兴趣的专业领域的进一步研究，无论是GNN、知识图谱还是基于图的推荐系统。你还可以考虑参加图学习竞赛或为开源图学习项目做贡献，从中积累实践经验。
- en: Remember, the field of graph learning is constantly evolving, so staying updated
    with the latest research papers and attending relevant conferences or workshops
    will help you remain at the forefront of this exciting domain.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，图学习领域正在不断发展，因此保持关注最新的研究论文并参加相关的会议或研讨会，将有助于你保持在这个激动人心的领域的前沿。
