- en: Answers to the Questions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题的答案
- en: Chapter 1 – Getting Started with Next-Generation Artificial Intelligence through
    Reinforcement Learning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 – 通过强化学习开始了解下一代人工智能
- en: '**Is reinforcement learning memoryless? (Yes | No)**'
  id: totrans-2
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**强化学习是否无记忆？（是 | 否）**'
- en: The answer is **yes**. Reinforcement learning is memoryless. The agent calculates
    the next state without looking into the past. This is significantly different
    from humans. Humans rely heavily on memory. A CPU-based reinforcement learning
    system finds solutions without experience. Human intelligence merely proves that
    intelligence can solve a problem. No more, no less. An adaptive thinker can then
    imagine new forms of machine intelligence.
  id: totrans-3
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。强化学习是无记忆的。代理通过计算下一个状态而不查看过去。这与人类有显著不同。人类极度依赖记忆。基于CPU的强化学习系统在没有经验的情况下找到解决方案。人类智能仅仅证明了智能能够解决问题。仅此而已。适应性思考者可以想象出新的机器智能形式。
- en: It must be noted that exceptions exist in some cases, but the general rule is a memoryless
    system.
  id: totrans-4
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 必须注意，在某些情况下存在例外，但一般规则是无记忆系统。
- en: '**Does reinforcement learning use stochastic (random) functions? (Yes | No)**'
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**强化学习是否使用随机（随机）函数？（是 | 否）**'
- en: The answer is **yes**. In the particular Markov decision process model, the
    choices are random. In just two questions, you can see that the Bellman equation
    is memoryless and makes random decisions. No human reasons like that. Being an
    adaptive thinker is a leap of faith. You have to leave who you were behind and
    begin to think in terms of equations.
  id: totrans-6
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。在特定的马尔可夫决策过程模型中，选择是随机的。通过仅仅两个问题，你就可以看到贝尔曼方程是无记忆的，并且做出随机决策。没有人类是这样推理的。成为一个适应性思考者是一种信仰的飞跃。你必须抛弃过去的自我，开始用方程式的思维方式进行思考。
- en: '**Is the MDP based on a rule base? (Yes | No)**'
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**MDP是否基于规则库？（是 | 否）**'
- en: The answer is **no**. Human rule-based experience is useless in this process.
    Human thinking is often based on rules of cause and effect, for example. Furthermore,
    the MDP provides efficient alternatives to long consulting times with future users
    who cannot clearly express their problem.
  id: totrans-8
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。人类基于规则的经验在这个过程中是无用的。人类的思维通常基于因果关系的规则，例如。此外，MDP提供了有效的替代方案，可以避免长时间与无法清晰表达问题的未来用户进行咨询。
- en: '**Is the Q function based on the MDP? (Yes | No)**'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Q函数是否基于MDP？（是 | 否）**'
- en: The answer is **yes**. The use of the expression *Q* appeared around the time
    the Bellman equation, based on the MDP, came into fashion. It is more trendy to
    say you are using a Q function than to speak about Bellman, who put all of this
    together in 1957\. The truth is that Andrey Markov was Russian and applied this
    method in 1913 using a dataset of 20,000 letters to predict the future use of
    letters in a novel. He then extended that to a dataset of 100,000 letters. This
    means that the theory was there 100 years ago. *Q* fits our new world of impersonal
    and powerful CPUs.
  id: totrans-10
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。*Q*这一表达方式出现在贝尔曼方程基于MDP流行的时期。说你在使用Q函数比谈论贝尔曼更时髦，因为是他在1957年将这一切组合在一起。事实上，安德烈·马尔可夫是俄罗斯人，他在1913年使用一个包含2万封信件的数据集，预测了信件在小说中的未来使用情况。之后他又将其扩展到包含10万封信件的数据集。这意味着，这一理论早在100年前就已存在。*Q*适应我们这个充满个性且强大的CPU的新世界。
- en: '**Is mathematics essential to AI? (Yes | No)**'
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数学对人工智能至关重要吗？（是 | 否）**'
- en: The answer is **yes**. If you master the basics of linear algebra and probability,
    you will be on top of all the technology that is coming. It is worth spending
    a few months' worth of evenings on the subject or taking a MOOC. Otherwise, you
    will depend on others to explain things to you.
  id: totrans-12
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。如果你掌握了线性代数和概率的基础，你将处于即将到来的所有技术的最前沿。值得花上几个月的晚上时间学习这个话题，或者参加一门在线课程（MOOC）。否则，你将依赖别人来向你解释事情。
- en: '**Can the Bellman-MDP process in this chapter apply to many problems? (Yes
    | No)**'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**本章中的贝尔曼-MDP过程是否能应用于许多问题？（是 | 否）**'
- en: The answer is **yes**. You can use this for robotics, market analysis, IoT,
    linguistics, and scores of other problems.
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。你可以将其应用于机器人技术、市场分析、物联网、语言学以及众多其他问题。
- en: '**Is it impossible for a machine learning program to create another program
    by itself? (Yes| No)**'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**机器学习程序是否不可能自行创建另一个程序？（是 | 否）**'
- en: 'The answer is **no**. It is not impossible. It has already been done by DeepCode:
    [https://www.deepcode.ai/](https://www.deepcode.ai/).'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。这并非不可能。DeepCode已经做到了：[https://www.deepcode.ai/](https://www.deepcode.ai/)。
- en: Do not be surprised. Now that you have become an adaptive thinker and know that
    these systems rely on equations, not humans, you can easily understand the fact
    that mathematical systems are not that difficult to reproduce.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不要感到惊讶。既然你已经成为一个适应性思维者，并且知道这些系统依赖于方程式，而不是人类，你就能轻松理解数学系统并不像你想象的那样难以复制。
- en: '**Is a consultant required to enter business rules in a reinforcement learning
    program? (Yes| No)**'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在强化学习程序中是否需要顾问输入商业规则？（是 | 否）**'
- en: The answer is **no**. It is only an option. Reinforcement learning in the MDP
    process is memoryless and random. Consultants are there to manage, explain, and
    train in these projects.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。这只是一个选项。MDP过程中的强化学习是没有记忆且随机的。顾问们的职责是管理、解释和在这些项目中进行培训。
- en: '**Is reinforcement learning supervised or unsupervised? (Supervised | Unsupervised)**'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**强化学习是监督学习还是无监督学习？（监督 | 无监督）**'
- en: The answer is **unsupervised**. The whole point is to learn from unlabeled data.
    If the data is labeled, then we enter the world of supervised learning; that will
    be searching for patterns and learning them. At this point, you can easily see
    you are at sea in an adventure—a memoryless, random, and unlabeled world for you
    to discover.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**无监督**。关键在于从未标记的数据中学习。如果数据是有标签的，那么我们就进入了监督学习的世界；那时我们会寻找模式并学习它们。在这一点上，你可以很容易地看到自己正在进行一场冒险——一个没有记忆、随机且没有标签的世界等待你去发现。
- en: '**Can Q-learning run without a reward matrix? (Yes | No)**'
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Q学习能在没有奖励矩阵的情况下运行吗？（是 | 否）**'
- en: The answer is **no**. A smart developer could always find a way around this,
    of course. The system requires a starting point. You will see in the second chapter
    that it is quite a task to find the right reward matrix in real-life projects.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。当然，一个聪明的开发者总能找到解决方法。该系统需要一个起始点。你会在第二章看到，在现实项目中找到正确的奖励矩阵是一个相当大的挑战。
- en: Chapter 2 – Building a Reward Matrix – Designing Your Datasets
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章 - 构建奖励矩阵 - 设计你的数据集
- en: '**Raw data can be the input to a neuron and transformed with weights. (Yes
    | No)**'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**原始数据可以作为神经元的输入并通过权重进行转换吗？（是 | 否）**'
- en: The answer is **yes** if the data is in numerical format. If it is in a proper
    numerical format, the input can be multiplied by the weights and biases.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果数据是数值格式，答案是**是**。如果它是一个合适的数值格式，输入可以与权重和偏差相乘。
- en: If the data is not in a numerical format, then it requires a numerical encoding phase.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果数据不是数值格式，那么就需要一个数值编码阶段。
- en: '**Does a McCulloch-Pitts neuron require a threshold? (Yes | No)**'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**麦卡洛赫-皮特神经元是否需要阈值？（是 | 否）**'
- en: The answer is **yes**. Adding up weights does not mean much if you do not have
    something to measure the value. It took months of work for McCulloch and Pitt
    to put this together. At first, time was in the equation, just like it is in our
    brain. But then, like Joseph Fourier (1768-1830), they found cycles that repeated
    themselves—periods that did not require much more than that neuron.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。加权和并不意味着什么，如果你没有什么东西来衡量其值。麦卡洛赫和皮特花费了数月的时间来完成这项工作。最初，时间是方程式的一部分，就像它在我们大脑中一样。但随后，像约瑟夫·傅里叶（Joseph
    Fourier，1768-1830）一样，他们发现了自我重复的周期——这些周期并不需要超出该神经元的更多内容。
- en: Warren McCulloch and Walter Pitts invented the first neuron and published a
    paper in 1943\. Legend has it that at age 12 years in 1935, Walter Pitts, a poor
    child living in a bad neighborhood, was chased by bullies and sought refuge in
    a library. There, he discovered *Principia Mathematica*, by *Bertrand Russell*
    and *Alfred Whitehead*. Anyway, not only did he find mistakes in the reasoning,
    but he also sent a letter to Bertrand Russell! From then on, Walter was noted
    for his genius in mathematics. With Warren McCulloch, another genius, they invented
    the first neuron. It seems simple. But it's the result of a number of sleepless
    nights. Just as the invention of the wheel appears simple, nothing better has
    been found to this day. This concept of a neuron is the wheel of AI.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 沃伦·麦卡洛赫和沃尔特·皮特斯在1943年发明了第一个神经元并发表了论文。传说沃尔特·皮特斯在1935年时，12岁的小孩生活在一个贫困的社区，被恶霸追赶，寻求藏身之所时进入了图书馆。在那里，他发现了*《数学原理》*，作者是*伯特兰·罗素*和*阿尔弗雷德·怀特海德*。总之，他不仅发现了推理中的错误，还写信给了伯特兰·罗素！从此，沃尔特被认为是数学方面的天才。与沃伦·麦卡洛赫，这位另一位天才一起，他们发明了第一个神经元。看起来很简单，但这是经历了无数个不眠之夜的结果。正如轮子的发明看似简单一样，到今天为止没有找到比它更好的东西。这个神经元的概念就是AI的轮子。
- en: '**A logistic sigmoid activation function makes the sum of the weights larger. (Yes
    | No)**'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**逻辑 sigmoid 激活函数会让权重的总和变大。（是 | 否）**'
- en: The answer is **no**. The whole point of a sigmoid function is to reduce the
    sums when necessary to have comparable numbers to work with.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。Sigmoid 函数的核心目的是在必要时减少总和，以便得到可以比较的数值。
- en: '**A McCulloch-Pitts neuron sums the weights of its inputs. (Yes | No)**'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**McCulloch-Pitts 神经元会对输入的权重求和。（是 | 否）**'
- en: The answer is **yes**. It's only when you sum the weights that they make sense.
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。只有在你对权重求和时，它们才有意义。
- en: '**A logistic sigmoid function is a log10 operation. (Yes | No)**'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**logistic sigmoid 函数是一个 log10 操作。（是 | 否）**'
- en: The answer is **no**. The sigmoid function is based on Euler's number, *e*,
    a constant that is equal to 2.71828\. This number produces a natural logarithm.
    Leonhard Euler (1707-1783) discovered this in the 18th century with a quill—no
    scientific calculator or computer! Did you notice that the main mathematical functions
    used in AI run far back in history? This aspect of the hype around what we think
    we have found now but has existed for decades, and sometimes centuries, will be
    dealt with in the following chapters.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。Sigmoid 函数基于欧拉数 *e*，这是一个等于 2.71828 的常数。这个数字会产生自然对数。18世纪，莱昂哈德·欧拉（1707-1783）用羽毛笔发现了这一点——那时候没有科学计算器或计算机！你是否注意到，AI
    中使用的主要数学函数早在历史上就存在了？我们现在所认为的发现，实际上已经存在了几十年，有时甚至是几个世纪，这个现象将在后续章节中讨论。
- en: '**A logistic softmax is not necessary if a logistic sigmoid function is applied
    to a vector. (Yes | No)**'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**如果对一个向量应用了 logistic sigmoid 函数，则不需要 logistic softmax。（是 | 否）**'
- en: The answer is **no**. Calculating the sum of several numbers of a vector and
    then dividing each number by that sum gives a view of the proportions involved.
    It is a precious tool to keep in mind.
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。计算向量中若干数值的和，然后将每个数值除以该和，能够显示涉及的比例。这是一个值得牢记的宝贵工具。
- en: '**A probability is a value between –1 and 1\. (Yes | No)**'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**概率是一个介于 -1 和 1 之间的值。（是 | 否）**'
- en: The answer is **no**. Probabilities lie between 0 and 1.
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。概率的范围是 0 到 1 之间。
- en: Chapter 3 – Machine Intelligence – Evaluation Functions and Numerical Convergence
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章 – 机器智能 – 评估函数与数值收敛
- en: '**Can a human beat a chess engine? (Yes | No)**'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**人类能打败国际象棋引擎吗？（是 | 否）**'
- en: The answer is **no**. Today, the highest-level chess tournaments are not between
    humans but between chess engines. Each chess engine software editor prepares for
    these competitions by making their algorithms faster and requiring less CPU. Today,
    a top chess engine running on a smartphone can beat humans. In human-to-human
    chess competitions, the level of chess has reached very high limits of complexity.
    Humans now mostly train against machines.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。如今，最高级别的国际象棋比赛不是在人类之间进行，而是在国际象棋引擎之间进行的。每个国际象棋引擎的开发者通过加速算法并减少 CPU 占用，为这些比赛做准备。如今，在智能手机上运行的顶级国际象棋引擎能够击败人类。在人类与人类的国际象棋比赛中，国际象棋的复杂性已经达到了极高的水平。现在，人类主要是与机器进行训练。
- en: '**Humans can estimate decisions better than machines with intuition when it
    comes to large volumes of data. (Yes | No)**'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在人类直觉方面，处理大量数据时，人类比机器更能做出更好的决策。（是 | 否）**'
- en: The answer is **no**. The sheer CPU power of an average machine or even a smartphone
    can generate better results than humans with the proper algorithms.
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。即便是普通机器或智能手机的强大 CPU，结合合适的算法，能够比人类产生更好的结果。
- en: '**Building a reinforcement learning program with a Q function is a feat in
    itself. Using the results afterward is useless. (Yes | No)**'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建一个具有 Q 函数的强化学习程序本身就是一项壮举。事后使用结果是没有意义的。（是 | 否）**'
- en: The answer is **no**. While learning AI, just verifying that the results are
    correct is enough. In real-life applications, the results are used in databases
    or as input to other systems.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。在学习 AI 时，仅仅验证结果是否正确就足够了。在实际应用中，这些结果被用于数据库或作为其他系统的输入。
- en: '**Supervised learning decision tree functions can be used to verify that the
    result of the unsupervised learning process will produce reliable, predictable
    results. (Yes | No)**'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**监督学习中的决策树函数可以用来验证无监督学习过程的结果是否会产生可靠、可预测的结果。（是 | 否）**'
- en: The answer is **yes**. Decision tree functions are very efficient in many cases.
    When large volumes are involved, decision tree functions can be used to analyze
    the results of the machine learning process and contribute to a prediction process.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。在许多情况下，决策树函数非常高效。当涉及到大规模数据时，决策树函数可以用于分析机器学习过程的结果，并有助于预测过程。
- en: '**The results of a reinforcement learning program can be used as input to a scheduling
    system by providing priorities. (Yes | No)**'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**强化学习程序的结果可以通过提供优先级作为输入，应用到调度系统中。（是 | 否）**'
- en: The answer is **yes**. The output of reinforcement learning Q functions can
    be injected as input into another Q function. Several results can be consolidated
    in phase 1 and become the reward matrix of a phase 2 reinforcement learning session.
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。强化学习的Q函数输出可以作为输入注入到另一个Q函数中。几个结果可以在第一阶段合并，并成为第二阶段强化学习会话的奖励矩阵。
- en: '**Can artificial intelligence software think like humans? (Yes | No)**'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**人工智能软件能像人类一样思考吗？（是 | 否）**'
- en: The answer is **yes**, and **no**. In the early days, this was attempted with
    neuroscience-based models. However, applying mathematical models is presently
    far more efficient.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**，也是**否**。在早期，这种方法曾尝试使用基于神经科学的模型。然而，目前应用数学模型要高效得多。
- en: Who knows what will happen in future research with neuromorphic computing, for
    example? But for the time being, deep learning, the main trend, is based on mathematical
    functions.
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 谁知道未来的神经形态计算研究会有什么发展呢？但就目前而言，深度学习作为主流，依赖于数学函数。
- en: Chapter 4 – Optimizing Your Solutions with K-Means Clustering
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四章 – 使用K-means聚类优化您的解决方案
- en: '**Can a prototype be built with random data in corporate environments? (Yes
    | No)**'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**可以在企业环境中使用随机数据构建原型吗？（是 | 否）**'
- en: The answer is **yes**, and **no**. To start developing a prototype, using random
    data can help make sure that the basic algorithm works as planned.
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**，也是**否**。为了开始开发一个原型，使用随机数据可以帮助确保基本算法按计划工作。
- en: However, once the prototype is advanced, it will be more reliable to use a well-designed
    dataset. Then, once the training has been accomplished, random data can again
    help to see how your system behaves in all situations.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然而，一旦原型得到了提升，使用设计良好的数据集将更加可靠。然后，一旦训练完成，随机数据可以再次帮助你观察系统在各种情况下的表现。
- en: '**Do design matrices contain one example per matrix? (Yes | No)**'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设计矩阵每个矩阵包含一个示例吗？（是 | 否）**'
- en: The answer is **no**. A good design matrix contains one example in each row
    or each column depending on the shape you want it to have. But be careful; a design
    matrix that contains data that is too efficient might *overfit*. That means the
    learning algorithm will be efficient with that data but not adapt to new data.
    On the other hand, if the dataset contains too many errors, then the algorithm
    might *underfit*, meaning it won't learn correctly. A good design matrix should
    contain reliable data, some imprecise data, and some *noise* (some data that can
    influence the algorithm in unreliable ways).
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。一个好的设计矩阵在每一行或每一列包含一个示例，具体取决于你希望它具有的形状。但要小心；一个包含过于高效数据的设计矩阵可能会*过拟合*。这意味着学习算法对这些数据非常有效，但无法适应新数据。另一方面，如果数据集包含过多错误，那么算法可能会*欠拟合*，也就是说它无法正确学习。一个好的设计矩阵应该包含可靠数据，一些不精确数据，以及一些*噪音*（一些能以不可靠方式影响算法的数据）。
- en: '**Automated guided vehicles (AGVs) can never be widespread. (Yes | No)**'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自动引导车（AGVs）永远无法广泛应用。（是 | 否）**'
- en: 'The answer is **no**. The sentence is not a correct assertion. AGVs will expand
    endlessly from now on: drones, cars, planes, warehouse vehicles, industrial vehicles,
    and more. AGVs, added to AI and IoT, constitute the fourth industrial revolution.'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。这句话是不正确的。自动引导车（AGVs）将从现在开始不断扩展：无人机、汽车、飞机、仓储车辆、工业车辆等等。AGVs，加上AI和物联网，构成了第四次工业革命。
- en: '**Can k-means clustering be applied to drone traffic? (Yes | No)**'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**K-means聚类能否应用于无人机交通？（是 | 否）**'
- en: The answer is **yes**. Seeing where traffic builds up will prevent drone jams
    (drones circling and waiting).
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。看到交通积压的位置可以防止无人机堵塞（无人机盘旋等待）。
- en: '**Can k-means clustering be applied to forecasting? (Yes | No)**'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**K-means聚类能否应用于预测？（是 | 否）**'
- en: The answer is **yes**. K-means clustering can be used for predictions.
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。K-means聚类可以用于预测。
- en: '**Lloyd''s algorithm is a two-step approach. (Yes | No)**'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Lloyd算法是一个两步法吗？（是 | 否）**'
- en: '**Yes**, Lloyd''s algorithm first classifies each data point in the best cluster.
    Then, once that is done, it calculates the geometric center or centroid of that
    center. When no data point changes the cluster anymore, the algorithm has been
    trained.'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**，Lloyd算法首先将每个数据点分类到最佳簇中。然后，一旦完成，它计算该簇的几何中心或质心。当没有数据点再更改簇时，算法就已经训练完成。'
- en: '**Do hyperparameters control the behavior of the algorithm? (Yes | No)**'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**超参数控制算法的行为吗？（是 | 否）**'
- en: 'The answer is **yes**. Hyperparameters determine the course of the computation:
    the number of clusters, features, batch sizes, and more.'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是的**。超参数决定了计算的过程：聚类的数量、特征、批量大小等。
- en: '**Once a program works, the way it is presented does not matter. (Yes | No)**'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**一旦程序运行成功，展示方式就不重要了。（是 | 否）**'
- en: The answer is **no**. Without a clear presentation of the results, the whole
    training process is confusing at best and useless at worst.
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**不是**。如果没有清晰的结果展示，整个训练过程最多是混乱，最差则是毫无用处的。
- en: '**K-means clustering is only a classification algorithm. It''s not a prediction
    algorithm. (Yes | No)**'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**K均值聚类仅仅是一个分类算法。它不是一个预测算法。（是 | 否）**'
- en: The answer is **no**. K-means clustering can be used as a prediction algorithm
    as well.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**不是**。K均值聚类也可以作为一种预测算法使用。
- en: Chapter 5 – How to Use Decision Trees to Enhance K-Means Clustering
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章 – 如何使用决策树增强K均值聚类
- en: The questions will focus on the hyperparameters.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 问题将集中在超参数上。
- en: '**The number of k clusters is not that important. (Yes | No)**'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**k聚类的数量并不那么重要。（是 | 否）**'
- en: The answer is **no**. The number of clusters requires careful selection, possibly
    a trial-and-error approach. Each project will lead to different clusters.
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**不是**。聚类的数量需要仔细选择，可能需要试错的方法。每个项目都会导致不同的聚类结果。
- en: '**Mini-batches and batches contain the same amount of data. (Yes | No)**'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**小批量和批量包含相同数量的数据。（是 | 否）**'
- en: The answer is **no**. "Batch" generally refers to the dataset, and "mini-batch"
    represents a "subset" of data.
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**不是**。"批量"通常指的是数据集，而"小批量"代表数据的"子集"。
- en: '**K-means can run without mini-batches. (Yes | No)**'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**K均值可以在没有小批量的情况下运行。（是 | 否）**'
- en: The answer is **yes**, and **no**. If the volume of data remains small, then
    the training epochs can run on the whole dataset. If the data volume exceeds a reasonable
    amount of computer power (CPU or GPU), mini-batches must be created to optimize
    training computation.
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是的**，也**不是**。如果数据量保持较小，训练周期可以在整个数据集上运行。如果数据量超出了合理的计算能力（CPU或GPU），则必须创建小批量来优化训练计算。
- en: '**Must centroids be optimized for result acceptance? (Yes | No)**'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**质心是否必须经过优化才能接受结果？（是 | 否）**'
- en: The answer is **yes**, and **no**. Suppose you want to put a key in a keyhole.
    The keyhole represents the centroid of your visual cluster. You must be precise.
    If you are simply throwing a piece of paper in your garbage can, you do not need
    to aim at the perfect center (centroid) of the cluster (marked by the rim of the
    garbage can) to attain that goal. Centroid precision depends on what is asked
    of the algorithm.
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是的**，也**不是**。假设你想把一把钥匙放进钥匙孔。钥匙孔代表你的视觉聚类的质心。你必须非常精确。如果你只是把一张纸扔进垃圾桶，你不需要瞄准聚类的完美中心（由垃圾桶的边缘标记）来实现目标。质心的精确度取决于算法的要求。
- en: '**It does not take long to optimize hyperparameters. (Yes | No)**'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**优化超参数不会花费太长时间。（是 | 否）**'
- en: The answer is **yes**, and **no**. If it's a simple project, it will not take
    long. If you are facing a large dataset, it will take some time to find the optimal
    hyperparameters.
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是的**，也**不是**。如果是一个简单的项目，时间不会很长。如果你面对的是一个大数据集，找到最优超参数会需要一些时间。
- en: '**It sometimes takes weeks to train a large dataset. (Yes | No)**'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练一个大数据集有时需要数周时间。（是 | 否）**'
- en: The answer is **yes**. Media hype and hard work are two different worlds. Machine
    learning and deep learning are still tough projects to implement.
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是的**。媒体炒作和艰苦的工作是两个完全不同的领域。机器学习和深度学习仍然是艰难的实现项目。
- en: '**Decision trees and random forests are unsupervised algorithms. (Yes | No)**'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**决策树和随机森林是无监督算法。（是 | 否）**'
- en: The answer is **yes**, and **no**. Decision trees can both be used for supervised
    or unsupervised learning. Decision trees can start with a target value, which
    makes them supervised. Random forests can be used in the same way.
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是的**，也**不是**。决策树既可以用于监督学习，也可以用于无监督学习。决策树可以从目标值开始，这使得它们成为监督学习算法。随机森林也可以以相同的方式使用。
- en: Chapter 6 – Innovating AI with Google Translate
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第六章 – 利用谷歌翻译创新AI
- en: '**Is it better to wait until you have a top-quality product before putting
    it on the market? (Yes | No)**'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在将产品投放市场之前，是否更好等到你拥有顶级的产品？（是 | 否）**'
- en: The answer is **yes**, and **no**. Context is everything. In the early 21st
    century, Airbus was struggling to complete the A380, the largest ever passenger
    airplane. Their engineers worked on hundreds of improvements before transporting
    commercial passengers. We would expect no less!
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是的**，也是**不**。上下文才是关键。在21世纪初，空客公司正为完成A380——有史以来最大的客机——而努力。工程师们在运送商业乘客之前，进行了数百项改进。我们对他们的期望一点也不低！
- en: In the case of Google Translate, it is a massive no. By putting Google Translate
    online and providing an API, Google encouraged thousands of AI developers, linguists,
    consultants, and users to provide feedback and improvements. Furthermore, Google,
    once again, occupies a large share of the web market.
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 就谷歌翻译而言，答案是一个巨大的“不”。通过将谷歌翻译上线并提供API，谷歌鼓励了成千上万的AI开发者、语言学家、顾问和用户提供反馈和改进。此外，谷歌再次占据了网络市场的较大份额。
- en: '**Considering the investment made, a new product should always be priced high
    to reach the top segment of the market. (Yes | No)**'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**考虑到所做的投资，新产品应始终定价较高，以达到市场的顶端。 (是的 | 不)**'
- en: The answer is **yes** and **no**. Again, context determines the answer. When
    Ferrari puts a new car on the market, the price has to be high for two reasons; the
    quality of the car and the cost of production make it necessary to do so to make
    the innovation profitable. Also, Ferrari avoids mass production to keep its quality
    at high levels.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是的**，也是**不**。同样，上下文决定了答案。当法拉利将新车推向市场时，价格必须高，原因有二；一是车的质量，二是生产成本，这使得高价才能确保创新的盈利性。同时，法拉利避免大规模生产，以保持其质量的高水平。
- en: When Amazon Web Services put machine learning on the market with SageMaker,
    it put a "pay-as-you-go" policy in place, starting at a very low end of the market.
    The product had, and has, its limits, but Amazon now receives tremendous volumes
    of feedback and is continuously improving the product.
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当亚马逊网络服务（AWS）通过SageMaker将机器学习推向市场时，它实施了一项“按需付费”政策，从市场的低端开始。这个产品有其局限性，但亚马逊现在收到了大量反馈，并持续改进该产品。
- en: '**Inventing a new solution will make it known in itself. (Yes | No)**'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**发明一种新解决方案会使其自身被知晓。 (是的 | 不)**'
- en: '**Yes**. An invention society is ready to accept will make its way on its own
    no matter what. You might be surprised to know that saving a camera''s projected
    image by drawing it dates so far back in history that nobody knows for sure when
    it was first used. Nobody knows if it was invented or discovered. In any case,
    the first *camera obscura* (the first "cameras") was revolutionary. It is now
    proven that famous painters used the technique. The picture was projected on a
    paper or canvas. The "printer" was manual. The painter was the "printer." However,
    cameras, as we know, only became disruptive in the 20th century.'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。一个发明社会准备接受的发明将会自行成功，无论如何。你可能会惊讶地发现，通过绘制投影图像来保存相机的图像，这一做法追溯的历史悠久，甚至没有人确切知道它是什么时候首次被使用的。没人知道它是被发明出来的，还是被发现的。无论如何，第一个*暗箱*（第一个“相机”）是具有革命性的。现在已经证明，著名的画家们曾经使用过这一技巧。图像被投影到纸张或画布上。“打印机”是手动的。画家就是“打印机”。然而，如我们所知，相机直到20世纪才真正变得具有颠覆性。'
- en: '**AI can solve most problems without using standard non-learning algorithms.
    (Yes | No)**'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**AI能在不使用标准非学习算法的情况下解决大多数问题。 (是的 | 不)**'
- en: The answer is **no**. Non-learning classical algorithms are necessary to create
    datasets, for example. Furthermore, AI relies on cloud servers, architectures,
    standard algorithms in all languages (C++, Java, Python, and others), and Apache
    servers. Even on a self-driving car, the sensors installed require standard hard
    work to get them working and interpreting information before AI comes in to solve
    some of the problems.
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**不**。例如，创建数据集时需要使用非学习型的经典算法。此外，AI依赖于云服务器、架构、所有编程语言中的标准算法（如C++、Java、Python等）和Apache服务器。即便是在自动驾驶汽车中，安装的传感器也需要进行标准的硬件工作，才能使其正常工作并解读信息，之后AI才介入解决一些问题。
- en: AI is like our brain. Without a body, it cannot function.
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: AI就像我们的“大脑”。没有身体，它无法运作。
- en: '**Google Translate can satisfactorily translate all languages. (Yes | No)**'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**谷歌翻译能令人满意地翻译所有语言。 (是的 | 不)**'
- en: After reading this chapter, you might be surprised to have a **yes** and **no**
    answer. If you are using Google Translate to say "hello," "how are you?", "thanks
    for the message," and similar friendly phrases on your favorite social network
    or in an email, it is good enough.
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阅读完这一章后，你可能会惊讶地发现，答案既是**是的**，又是**不**。如果你在你最喜欢的社交网络上，或者在电子邮件中使用谷歌翻译来说“你好”，“你好吗？”“谢谢你的消息”，以及类似的友好短语，那就足够了。
- en: But when dealing with more detailed phrases and sentences, Google Translate
    provides random satisfactory results. From a user's perspective, this is bad news.
    For a developer, it is a goldmine!
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 但是当处理更详细的短语和句子时，Google Translate会提供随机的令人满意的结果。从用户的角度来看，这是坏消息。对于开发者来说，这是一个宝藏！
- en: '**If you are not creative, it is no use trying to innovate. (Yes | No)**'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**如果你没有创造力，试图创新是没有用的。（是 | 否）**'
- en: The answer is a massive **no**. You certainly do not need to be either imaginative
    or creative to innovate. Do not let anybody convince you of such nonsense. If
    you are designing a solution and find a missing component, look for some alternative
    components on the web, talk about it, and find people that can help. Then get
    it done through teamwork. This works every time!
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是一个巨大的**不**。你完全不需要富有想象力或创造力才能创新。不要让任何人让你相信这种胡说八道。如果你正在设计一个解决方案并发现缺少某个组件，去网上寻找一些替代组件，讨论一下，找到可以帮忙的人。然后通过团队合作完成它。每次都有效！
- en: Even the great Bill Gates was smart enough to ask Tim Patterson for help to develop
    MS-DOS, and he went on to become a billionaire.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 即使是伟大的比尔·盖茨也足够聪明，向Tim Patterson求助来开发MS-DOS，之后他成了亿万富翁。
- en: '**If you are not a linguist, it is no use bothering with trying to improve
    Google Translate. (Yes | No)**'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**如果你不是语言学家，试图改进Google Translate是没有用的。（是 | 否）**'
- en: The answer is **no**! Once again, never let somebody convince you of such nonsense.
    Innovating is teamwork. If you like Google Translate and you understand this chapter
    and have ideas, team up with a linguist around you or through a social network.
    The world is yours to improve!
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**不**！再说一遍，绝对不要让任何人让你相信这种胡说八道。创新是团队合作。如果你喜欢Google Translate并且理解这一章的内容，并且有一些想法，和身边的语言学家合作，或者通过社交网络找到他们。这个世界是你用来改进的！
- en: '**Translating is too complicated to understand. (Yes | No)**'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**翻译太复杂，难以理解。（是 | 否）**'
- en: '**No**. The way some explain it is too complicated. If you speak a language,
    you are an expert in translating your thoughts into words. With work, you can
    get into the translation business.'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。一些人解释的方式过于复杂。如果你会说某种语言，你就是把自己的思想转化为语言的专家。通过努力，你可以进入翻译行业。'
- en: '**AI has already reached its limits. (Yes | No)**'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**人工智能已经达到了它的极限。（是 | 否）**'
- en: Certainly **not**! We have just scratched the surface of both theory and applications.
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当然**不是**！我们只是刚刚触及了理论和应用的表面。
- en: Chapter 7 – Optimizing Blockchains with Naive Bayes
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第七章 – 使用朴素贝叶斯优化区块链
- en: '**Cryptocurrency is the only use of blockchains today. (Yes | No)**'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**加密货币是区块链今天唯一的用途。（是 | 否）**'
- en: '**No**. IBM HyperLedger, for example, uses blockchains to organize secure transactions
    in a supply chain environment.'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。例如，IBM HyperLedger使用区块链来组织供应链环境中的安全交易。'
- en: '**Mining blockchains can be lucrative. (Yes | No)**'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**开采区块链可能是有利可图的。（是 | 否）**'
- en: '**Yes**. But it is a risk, like any other mining operation or any speculative
    endeavor. Some companies have huge resources to mine cryptocurrency, meaning that
    they can beat smaller competitors in creating a block.'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。但这是一种风险，就像任何其他的矿业操作或任何投机性努力一样。一些公司拥有巨大的资源来开采加密货币，这意味着他们能够击败小型竞争者来创建一个区块。'
- en: '**Blockchains for companies cannot be applied to sales. (Yes | No)**'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**公司用区块链不能应用于销售。（是 | 否）**'
- en: '**No**. Blockchain cloud platforms provide smart contracts and a secure way
    of managing transactions during a sales process.'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。区块链云平台提供智能合约和在销售过程中管理交易的安全方式。'
- en: '**Smart contracts for blockchains are more accessible to write than standard
    offline contracts. (Yes | No)**'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**区块链的智能合约比标准的离线合同更容易编写。（是 | 否）**'
- en: '**Yes**, if they are standard contracts, this speeds the transaction up.'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**，如果它们是标准合同，这将加快交易速度。'
- en: On the other hand, **no**. If the transaction is complex and requires customization,
    a lawyer will have to write the contract, which can then only be used on a blockchain
    cloud platform.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另一方面，**不**。如果交易复杂且需要定制，律师将不得不编写合同，然后只能在区块链云平台上使用。
- en: '**Once a block is in a blockchain network, everyone in the network can read the
    content. (Yes | No)**'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**一旦一个区块进入区块链网络，网络中的每个人都可以读取其内容。（是 | 否）**'
- en: '**Yes**, if no privacy rule has been enforced.'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**，如果没有强制执行隐私规则。'
- en: '**No**, if a privacy rule has been enforced. IBM Hyperledger, for example,
    provides privacy functions.'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**，如果强制执行了隐私规则。例如，IBM Hyperledger提供隐私功能。'
- en: '**A block in a blockchain guarantees that absolutely no fraud is possible.
    (Yes | No)**'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**一个区块在区块链中可以保证绝对不可能发生欺诈。（是 | 否）**'
- en: '**Yes** and **no**. A block in a blockchain can never be changed again, thereby
    avoiding fraud. Nobody can tamper with the data. However, if the transaction is
    illegal in the first place, then the block will be fraudulent as well.'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**和**不是**。区块链中的一个区块一旦生成就无法再修改，从而避免了欺诈行为。没有人能篡改数据。然而，如果交易本身是非法的，那么该区块也会是欺诈性的。'
- en: '**There is only one way of applying Bayes'' theorem. (Yes | No)**'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**应用贝叶斯定理只有一种方式。(是 | 否)**'
- en: '**No**. There are many variations of Bayes'' theorem. Using naive Bayes, for
    example, avoids the conditional probability constraint. But another approach could
    use conditional probability.'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。贝叶斯定理有很多变种。例如，使用朴素贝叶斯算法可以避免条件概率的约束。但另一种方法可能会使用条件概率。'
- en: '**Training a naive Bayes dataset requires a standard function. (Yes | No)**'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练朴素贝叶斯数据集需要一个标准函数。(是 | 否)**'
- en: '**No**. Gaussian functions, for example, can be used to calculate naive Bayes
    algorithms, among others.'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。例如，高斯函数可以用于计算朴素贝叶斯算法等。'
- en: '**Machine learning algorithms will not change the intrinsic nature of the corporate
    business. (Yes | No)**'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**机器学习算法不会改变企业业务的本质。(是 | 否)**'
- en: '**No**. Well-designed machine learning will disrupt every area of business
    as algorithms spread through the company, optimizing processes.'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。精心设计的机器学习将通过算法在公司内部传播，优化流程，进而颠覆各个业务领域。'
- en: Chapter 8 – Solving the XOR Problem with a Feedforward Neural Network
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 – 使用前馈神经网络解决XOR问题
- en: '**Can the perceptron alone solve the XOR problem? (Yes | No)**'
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**感知机单独能解决XOR问题吗？(是 | 否)**'
- en: '**Yes**. The answer would have been no in 1969\. A neural network, or some
    other mathematical process, is necessary to solve this problem. For the record,
    this is a common problem for electric circuits that function with "feedforward"
    electricity, and was solved long ago.'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。1969年时答案是“否”。解决这个问题需要一个神经网络或其他数学过程。值得一提的是，这是电路中常见的问题，尤其是在“前馈”电流的电路中，这个问题早已得到解决。'
- en: '**Is the XOR function linearly non-separable? (Yes | No)**'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**XOR函数是线性不可分的吗？(是 | 否)**'
- en: The answer is **no** if you use a single neuron, and **yes** if you use a hidden
    layer with at least two neurons. That is a major problem to address in deep learning.
    If you cannot separate the features of a face, for example, in a picture, recognizing
    that face will prove difficult. Imagine a picture with one half of the face in
    shadow and the other half in bright sunlight. Since the eye and features of one
    half are in shadow, a poor deep learning program might only capture half of the
    face, separating the face in the wrong place with a poor edge detection function.
    Linear separability is thus a key aspect of machine learning.
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你使用一个神经元，那么答案是**否**；如果你使用至少两个神经元的隐藏层，那么答案是**是**。这是深度学习中需要解决的一个主要问题。例如，如果你无法在图片中区分一个面部的特征，那么识别这个面部将变得非常困难。想象一下，图片中一半的面部处于阴影中，另一半处于强烈的阳光下。由于一半眼睛和特征在阴影中，一个糟糕的深度学习程序可能只能捕捉到面部的一半，并且错误地分隔面部，造成边缘检测不佳。因此，线性可分性是机器学习的一个关键方面。
- en: '**One of the main goals of layers in a neural network is classification. (Yes
    | No)**'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**神经网络中层的主要目标之一是分类。(是 | 否)**'
- en: The answer is **yes**. Once the data is identifiable with a given neural network
    architecture, predictions and many other functions become possible. The key to
    deep learning is to be able to transform data into pieces of information that
    will make sense through the abstraction obtained over the layers.
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是的**。一旦数据能够与给定的神经网络架构相匹配，预测和许多其他功能便成为可能。深度学习的关键在于能够将数据转化为通过各层获得的抽象理解后可以理解的信息片段。
- en: '**Is deep learning the only way to classify data? (Yes | No)**'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**深度学习是分类数据的唯一方法吗？(是 | 否)**'
- en: 'The answer is **no**. You can classify data with a SQL query, spreadsheets,
    AI, machine learning, and standard source code. Deep learning becomes vital when
    many dimensions of classification are involved: first finding the edges of objects
    in a picture, then forms, and then determining what the object represents. To
    do this with millions of pictures is beyond the scope of standard programming
    or early AI and machine learning programs.'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。你可以通过SQL查询、电子表格、AI、机器学习以及标准源代码来分类数据。当分类涉及多个维度时，深度学习变得至关重要：首先要找到图片中的物体边缘，然后是形状，最后确定物体代表什么。要处理数百万张图片，这已经超出了标准编程或早期AI和机器学习程序的范畴。
- en: '**A cost function shows the increase in the cost of a neural network. (Yes
    | No)**'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**成本函数显示神经网络的成本增加。(是 | 否)**'
- en: The answer is **no**. A cost function determines how much the training costs
    you. Running 100,000 epochs is more expensive than running 50,000 epochs. So,
    at each epoch, the cost of training (how far the system is from its goal) must
    be estimated. Thus, a good cost function will decrease the cost of running a neural
    network.
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。成本函数决定了训练的花费。运行 100,000 个 epoch 比运行 50,000 个 epoch 更昂贵。因此，在每个 epoch
    中，必须估算训练成本（系统距离目标的远近）。因此，一个好的成本函数会减少运行神经网络的成本。
- en: '**Can simple arithmetic be enough to optimize a cost function? (Yes | No)**'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**简单的算术运算足以优化成本函数吗？ (是 | 否)**'
- en: The answer is **yes**. As long as you know to what extent your cost function
    is increasing or decreasing, anything that works is fine.
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。只要你知道你的成本函数是如何增加或减少的，任何有效的方法都是可以的。
- en: '**A feedforward network requires inputs, layers, and an output. (Yes | No)**'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**前馈网络需要输入、层和输出。 (是 | 否)**'
- en: The answer is **yes**. Without layers, there is no network.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**。没有层，就没有网络。
- en: '**A feedforward network always requires training with backpropagation. (Yes
    | No)**'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**前馈网络总是需要反向传播训练。 (是 | 否)**'
- en: The answer is often **yes** in changing environments. Since the field is new,
    we tend to think that once the training is done, the work is done. If the datasets
    are very stable in a repetitive environment, such as recognizing the difference
    between various constant products in a shop, warehouse, or factory, then the neural
    network will do the classification it is designed for. If new products are introduced,
    then training can be initiated again.
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在变化的环境中，答案通常是**是**。由于该领域是新的，我们往往认为一旦训练完成，工作就结束了。如果数据集在重复的环境中非常稳定，比如在商店、仓库或工厂中区分各种恒定产品，那么神经网络将完成它设计的分类任务。如果引入了新产品，则可以重新启动训练。
- en: '**In real-life applications, solutions are only found by following existing
    theories. (Yes | No)**'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在实际应用中，解决方案只能通过遵循现有理论来找到。 (是 | 否)**'
- en: The answer is **no**. Without academic research, deep learning would not even
    exist. Without universities, the ideas used would be so simple that they would
    never work well.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。没有学术研究，深度学习甚至不会存在。没有大学，这些使用的理念将是如此简单，以至于永远不会有好的效果。
- en: On the other hand, researchers need real-life feedback. If we find new ways
    of doing things they recommend, we should publish them to help global research.
    It's a two-way street.
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 另一方面，研究人员需要现实世界的反馈。如果我们发现新的做法符合他们的建议，我们应该将其发布出来，帮助全球研究。这是一个双向过程。
- en: Chapter 9 – Abstract Image Classification with Convolutional Neural Networks
    (CNNs)
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第九章 – 使用卷积神经网络 (CNN) 进行抽象图像分类
- en: '**A convolutional neural network (CNN) can only process images. (Yes | No)**'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**卷积神经网络 (CNN) 只能处理图像。 (是 | 否)**'
- en: The answer is **no**. CNNs can process words, sounds, or video sequences, to classify
    and predict.
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。CNN 可以处理单词、声音或视频序列，用于分类和预测。
- en: '**A kernel is a preset matrix used for convolutions. (Yes | No)**'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**卷积核是用于卷积的预设矩阵。 (是 | 否)**'
- en: The answer is **yes**, and **no**. There are many preset matrices used to process
    images, such as the one used in `Edge_detection_Kernel.py` in this chapter. However,
    in this chapter, kernels were created randomly, and then the network trained their
    weights to fit the target images.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**，并且是**否**。有许多预设矩阵用于处理图像，比如本章中 `Edge_detection_Kernel.py` 中使用的矩阵。然而，在本章中，卷积核是随机创建的，然后网络训练它们的权重以适应目标图像。
- en: '**Does pooling have a pooling matrix, or is it random?**'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**池化有池化矩阵吗，还是随机的？**'
- en: In some cases, a pooling matrix has a size that is an option when the pooling layer
    is added to the model, such as a 2×2 pooling window. However, in AutoML neural
    networks, for example, we can try to run optimizing algorithms that will test
    various sizes to see which one produces the best performance.
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在某些情况下，当将池化层添加到模型中时，池化矩阵的大小是一个可选项，例如 2×2 的池化窗口。然而，在 AutoML 神经网络中，我们可以尝试运行优化算法，测试不同的大小，看看哪种大小能提供最佳性能。
- en: '**The size of the dataset always has to be large. (Yes | No)**'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据集的大小必须总是很大。 (是 | 否)**'
- en: '**No**. A dataset does not have a standard size. It depends on the training
    model. If the target images, for example, do not contain complex features, the
    dataset will be smaller than a complex feature dataset. Furthermore, the `ImageDataGenerator`
    function will expand the data by distorting it with the options provided.'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。数据集没有标准大小。它取决于训练模型。如果目标图像没有复杂的特征，例如，数据集将比具有复杂特征的数据集要小。此外，`ImageDataGenerator`函数将通过扭曲数据并使用提供的选项来扩展数据集。'
- en: '**Finding a dataset is not a problem with all the available image banks on
    the web. (Yes | No)**'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在网络上有众多的图像库可供选择，找到一个数据集并不是问题。 (是 | 否)**'
- en: The answer is **yes**, and **no**. Yes, because if the model remains a standard
    academic one, then the available images (CIFAR, MNIST, or others) will suffice.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**，也是**否**。是的，因为如果模型仍然是标准的学术模型，那么现有的图像（CIFAR，MNIST或其他）就足够了。
- en: No, because in real-life corporate situations, you will have to build your dataset
    and add images containing *noise*. Noise requires more fine-tuning of the model
    to become reliable and generalized.
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不，因为在实际的企业环境中，你必须构建自己的数据集，并添加包含*噪声*的图像。噪声需要更多的精细调优，才能使模型变得可靠且具有广泛的适应性。
- en: '**Once a CNN is built, training it does not take much time. (Yes | No)**'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**一旦CNN建立，训练它并不需要太多时间。 (是 | 否)**'
- en: The answer is **no**. Whatever the model is, training will remain time-consuming
    if you want it to be reliable. As seen in this chapter, a model requires a lot
    of options and mathematical thinking.
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。无论模型是什么样的，如果你希望它可靠，训练仍然是一个耗时的过程。正如本章所示，一个模型需要许多选项和数学思维。
- en: '**A trained CNN model applies to only one type of image. (Yes | No)**'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练好的CNN模型只适用于一种类型的图像。 (是 | 否)**'
- en: '**Yes** and **no**. There are three main types of overfitting:'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**与**否**。过拟合主要有三种类型：'
- en: Overfitting a model for a certain type of image with absolutely no consequence
    of implementation. In this case, the model classifies and predicts enough to satisfy
    the goals set. Suppose you are using a type of image with a very high definition.
    The CNN will detect the small details we may be trying to detect. However, when
    the application is in production, lower-quality images might make the model fail
    to identify what it had accurately detected with high-quality images.
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对某一类图像的过拟合，几乎没有实施后果。在这种情况下，模型足够分类和预测，能够满足设定的目标。假设你使用的是一种非常高定义的图像。CNN将检测到我们可能试图检测的细小细节。然而，当应用程序进入生产阶段时，低质量的图像可能会导致模型无法准确识别它以前在高质量图像中检测到的内容。
- en: Overfitting a model that creates implementation problems because it cannot adapt
    to different images at the same time. The model will then go through more training.
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型过拟合会产生实现问题，因为它无法同时适应不同类型的图像。然后，该模型将经历更多的训练。
- en: Overfitting a model that trains a certain type of image quite well but does
    not fit similar types of images when needed.
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型过拟合对某一类图像训练得很好，但在需要时无法适应类似类型的图像。
- en: Each situation has its constraints. As long as the model works, no general rules
    apply. It is up to you to decide.
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每种情况都有其限制。只要模型有效，就没有通用规则适用。最终决定权在于你。
- en: '**A quadratic loss function is not very efficient compared to a cross-entropy
    function. (Yes | No)**'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**与交叉熵函数相比，二次损失函数效率不高。 (是 | 否)**'
- en: The answer is **no**. Each model has its constraints. Quadratic loss functions
    work fine on some models and do not provide good results on others. This represents
    the main problems of training a model. No general rules will help you. You have
    to use your neurons or write a program that modifies the model automatically.
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**否**。每个模型都有其限制。二次损失函数在某些模型上效果很好，但在其他模型上可能无法提供良好的结果。这代表了训练模型的主要问题。没有通用的规则可以帮助你，你必须动用你的神经元，或者编写一个程序来自动修改模型。
- en: '**The performance of a deep learning CNN does not present a real issue with
    modern CPUs and GPUs. (Yes | No)**'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**现代CPU和GPU并不会使深度学习CNN的性能成为一个真正的问题。 (是 | 否)**'
- en: The answer is **yes**, and **no**. If the model runs quickly enough for your
    needs, then performance will not limit the outcome of your project. However, in
    many cases, it remains a problem. Reducing features to focus on the best ones
    is one of the reasons that the layers bring the size to analyze down, layer by
    layer.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是**是**，也是**否**。如果模型足够快满足你的需求，那么性能就不会限制你项目的结果。然而，在许多情况下，性能仍然是一个问题。减少特征，专注于最好的特征，是层次结构逐层缩小分析规模的原因之一。
- en: Chapter 10 – Conceptual Representation Learning
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章 – 概念表示学习
- en: '**The curse of dimensionality leads to reducing dimensions and features in
    machine learning algorithms. (Yes | No)**'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**维度的诅咒导致了机器学习算法中对维度和特征的缩减。（是 | 否）**'
- en: '**Yes**. The volume of data and features makes it necessary to extract the
    main features of an observed event (an image, sound, and words) to make sense
    of it.'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。数据和特征的体量使得必须提取观测事件的主要特征（如图像、声音和文字）才能理解它。'
- en: Overfitting and underfitting apply to dimensionality reduction as well. Reducing
    the features until the system works in a lab (overfitting) might lead to nowhere
    once the application faces real-life data. Trying to use all the features might
    lead to underfitting because the application solves no problem at all.
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 过拟合和欠拟合同样适用于降维。将特征减少到系统在实验室中能够工作的程度（过拟合），一旦面对实际数据，可能会毫无用处。尝试使用所有特征可能会导致欠拟合，因为应用根本解决不了任何问题。
- en: Regularization applies not just to data but to every aspect of a project.
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正则化不仅适用于数据，还适用于项目的各个方面。
- en: '**Transfer learning determines the profitability of a project. (Yes | No)**'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迁移学习决定了项目的盈利性。（是 | 否）**'
- en: '**Yes**, if an application of an AI model in itself was unprofitable the first
    time, but could generate profit if used for a similar type of learning. Reusing
    some functions would generate profit, no doubt.'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**，如果一个AI模型的应用第一次没有盈利，但如果用于类似类型的学习，可能会带来利润。重用某些功能无疑会产生利润。'
- en: '**No**, if the first application was extremely profitable but "overfitted"
    to meet the specifications of a given project.'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**，如果第一次应用非常有利可图，但却“过拟合”以符合特定项目的要求。'
- en: '**Reading model.h5 does not provide much information. (Yes | No)**'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**读取model.h5并不能提供太多信息。（是 | 否）**'
- en: '**No**. No in this case means that the assertion of the sentence is wrong.
    The saved model does provide useful information. Saving the weights of a TensorFlow
    model, for example, is vital during the training process to control the values.
    Furthermore, trained models often use HDF files (`.h5`) to load the trained weights.
    A Hierarchical Data Format (HDF) contains multidimensional arrays of scientific
    data.'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。在这种情况下，“不是”意味着句子的断言是错误的。保存的模型确实提供了有用的信息。例如，保存TensorFlow模型的权重在训练过程中至关重要，有助于控制数值。此外，训练过的模型通常使用HDF文件（`.h5`）来加载训练的权重。层次数据格式（HDF）包含多维科学数据数组。'
- en: '**Numbers without meaning are enough to replace humans. (Yes | No)**'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**没有意义的数字足以替代人类。（是 | 否）**'
- en: '**Yes**, in the sense that in many cases, mathematics provides enough tools
    to replace humans for many tasks (games, optimization algorithms, and image recognition).'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**，在许多情况下，数学提供了足够的工具来替代人类执行许多任务（如游戏、优化算法和图像识别）。'
- en: '**No**, in cases where mathematics cannot solve problems that require concepts,
    such as many aspects of NLP.'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**，在数学无法解决需要概念性问题的情况下，例如自然语言处理中的许多方面。'
- en: '**Chatbots prove that body language doesn''t mean that much. (Yes | No)**'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聊天机器人证明了肢体语言并没有那么重要。（是 | 否）**'
- en: '**Yes**, in the sense that in many applications, body language does not provide
    additional information. If only a yes or no answer is required, body language
    will not add much to the conversation.'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**，在许多应用中，肢体语言并没有提供额外的信息。如果只需要一个“是”或“否”的答案，肢体语言不会为对话增加太多内容。'
- en: '**No**, in the sense that if emotional intelligence is required to understand
    the tone of the user, a webcam detecting body language could provide useful information.'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**，在需要情感智能来理解用户语气的情况下，检测肢体语言的网络摄像头可以提供有用的信息。'
- en: '**Present-day artificial neural networks (ANNs) provide enough theory to solve
    all AI requests. (Yes | No)**'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**现代人工神经网络（ANNs）提供了足够的理论来解决所有的AI需求。（是 | 否）**'
- en: '**No**. Artificial neural networks (ANNs) cannot solve thousands of problems,
    for example, translating poetry novels or recognizing images with forms that constantly
    vary.'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。人工神经网络（ANNs）无法解决成千上万的问题，例如翻译诗歌小说或识别形态不断变化的图像。'
- en: '**Chatbots can now replace humans in all situations. (Yes | No)**'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聊天机器人现在可以在所有情况下替代人类。（是 | 否）**'
- en: '**No**. Concepts need to be added. The market provides all the necessary tools.
    It will take some years to be able to speak effectively with chatbots.'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。需要添加概念。市场提供了所有必要的工具。要有效地与聊天机器人对话可能需要几年时间。'
- en: '**Self-driving cars have been approved and do not need conceptual training.
    (Yes | No)**'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自动驾驶汽车已经获得批准，并且不需要概念性训练。（是 | 否）**'
- en: '**Yes** and **no**; there is some debate in this area. On the one hand, sensors
    and mathematics (linear algebra, probabilities) might succeed in effectively navigating
    roads in most driving conditions within a few years.'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**和**否**；这个领域存在一些争论。一方面，传感器和数学（线性代数、概率论）可能在几年内成功地在大多数驾驶条件下有效地导航道路。'
- en: However, certain problems will require concepts (and more robotics) in critical
    situations. If a self-driving car encounters a wounded person lying on the road,
    what is the best approach? The choices are to call for help, find another person
    if the help arrives too late, pick up the victim, drive them to a hospital (robotics),
    and much more.
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然而，某些问题在关键情况下会需要更多的概念（以及更多的机器人技术）。比如，当一辆自动驾驶汽车遇到躺在路上的伤员时，最佳的应对方式是什么？可以选择呼叫援助、如果援助到达太晚则寻找其他人、救起伤者、将其送往医院（机器人技术）等等。
- en: '**Industries can implement AI algorithms for all of their needs. (Yes | No)**'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**各行各业可以为所有需求实现人工智能算法。（是 | 否）**'
- en: '**Yes** and **no**. In many cases, all of the necessary tools are there to
    be used. If the right team decides to solve a problem with AI and robotics, it
    can be done.'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**和**否**。在许多情况下，所有必要的工具都可以使用。如果合适的团队决定用人工智能和机器人技术解决一个问题，那是可以做到的。'
- en: However, some tools are missing when it comes to addressing particular circumstances;
    for example, real-time management decision tools when faced with unplanned events.
    If a system breaks down, humans can still adapt faster to find alternative solutions
    to continue production.
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然而，当面临特定情况时，有些工具仍然缺失；例如，在面对突发事件时，缺少实时管理决策工具。如果系统发生故障，人类仍然能够更快地适应并找到替代解决方案来继续生产。
- en: Chapter 11 – Combining Reinforcement Learning and Deep Learning
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章 – 结合强化学习与深度学习
- en: '**A CNN can be trained to understand an abstract concept? (Yes | No)**'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**卷积神经网络（CNN）可以被训练来理解抽象概念吗？（是 | 否）**'
- en: '**Yes**. A CNN can classify images and make predictions. But CNNs can analyze
    any type of object or representation. An image, for example, can be linked to
    a word or phrase. The image thus becomes a message in itself.'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。卷积神经网络（CNN）可以分类图像并进行预测。但CNN可以分析任何类型的物体或表现形式。例如，一张图像可以与一个词或短语相连接。这样，图像本身就成了一个信息。'
- en: '**Is it better to avoid concepts and only use real-life images? (Yes | No)**'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**避免使用概念，只使用现实生活中的图像更好吗？（是 | 否）**'
- en: '**No**. Images provide many practical applications, but at some point, more
    is required to solve planning problems, for example.'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。图像提供了许多实际应用，但在某些情况下，例如解决规划问题时，仍然需要更多的东西。'
- en: Planning requires much more than this type of dataset.
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 规划所需的数据集远远不止这些。
- en: '**Do planning and scheduling mean the same thing? (Yes | No)**'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**规划和调度是同一个意思吗？（是 | 否）**'
- en: '**No**. Planning describes the tasks that must be carried out. Scheduling adds
    a time factor. Planning tells us what to do, and scheduling tells us when.'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。规划描述了必须执行的任务。调度则加入了时间因素。规划告诉我们做什么，调度告诉我们什么时候做。'
- en: '**Is Amazon''s manufacturing patent a revolution? (Yes | No)**'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**亚马逊的制造专利是一次革命吗？（是 | 否）**'
- en: '**No**. Manufacturing clothing has been mastered by factories around the world.
    It would be a revolution if something in the process was entirely new. However,
    automation in the apparel industry has been around for 20+ years. The patent is
    a specialized case of elements that exist, like a new brand of car.'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。全球的工厂已经掌握了服装制造技术。如果过程中某个部分是全新的，那才算得上是革命。然 而，服装行业的自动化已经存在超过20年。这个专利是现有元素的一个特殊案例，就像一款新品牌的汽车。'
- en: '**Yes**. With such a worldwide distribution, Amazon has come very close to
    the end user. The end user can choose a new garment, and it will be manufactured
    directly on demand. This connectivity will change the apparel manufacturing processes
    and force its competitors to find new ways of making and selling garments.'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。凭借如此广泛的分布，亚马逊已经非常接近最终用户。最终用户可以选择一件新衣服，它会根据需求直接制造。这种互联性将改变服装制造过程，并迫使其竞争对手寻找新的生产和销售方式。'
- en: '**Learning how warehouses function is not useful. (Yes | No)**'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**学习仓库如何运作没有用。（是 | 否）**'
- en: '**No**. Online shopping requires more and more warehouse space and processes.
    The number of warehouses will now increase faster than shops. There are many opportunities
    for AI applications in warehouses.'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。在线购物需要越来越多的仓库空间和流程。仓库的数量将比商店增长得更快。仓库中的AI应用有许多机会。'
- en: '**Online marketing does not require AI. (Yes | No)**'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在线营销不需要人工智能。（是 | 否）**'
- en: '**No**. On the contrary, AI is used by applications for online marketing every
    day, and this will continue for decades.'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。相反，人工智能每天都被用于在线营销应用，而且这种情况将在未来几十年继续。'
- en: Chapter 12 – AI and the Internet of Things
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章 – 人工智能与物联网
- en: '**Driving quickly to a location is better than safety in any situation. (Yes
    | No)**'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在任何情况下，快速到达目的地比安全更重要。（是 | 否）**'
- en: '**Yes** and **no**.'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**和**不**。'
- en: 'Self-driving cars face the same difficulties as human-driven cars: getting
    to a location on time, respecting speed limits, or driving as safely as possible.
    Self-driving cars, like humans, are constantly improving their driving abilities
    through experience.'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自动驾驶汽车面临与人类驾驶汽车相同的困难：按时到达目的地、遵守限速规定、或者尽可能安全地驾驶。自动驾驶汽车就像人类一样，通过经验不断提升其驾驶能力。
- en: Yes. Sometimes, a self-driving car will perform better on a highway with little
    traffic.
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 是的。有时候，自动驾驶汽车在交通较少的高速公路上表现会更好。
- en: No. Sometimes, if the highways are dangerous (owing to weather conditions and
    heavy traffic), a self-driving car should take a safer road defined by slow speed
    and little to no traffic. This way, if difficulties occur, the self-driving car
    can slow down and even stop more easily than on a highway.
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不行。有时，如果高速公路由于天气条件和交通拥堵变得危险，自动驾驶汽车应该选择一条更安全的道路，速度较慢且几乎没有交通。这样，如果发生困难，自动驾驶汽车能够比在高速公路上更容易减速甚至停车。
- en: '**Self-driving cars will never really replace human drivers. (Yes | No)**'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自动驾驶汽车永远无法真正取代人类司机。（是 | 否）**'
- en: Nobody can answer that question. As self-driving cars build their abilities
    and experience, they might well end up driving better than humans.
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 没有人能回答这个问题。随着自动驾驶汽车不断积累能力和经验，它们很可能会比人类驾驶得更好。
- en: In very unpredictable situations, humans can go off the road to avoid another car
    and back off a bit, for example. It will take more work to get a self-driving
    car to do that.
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在非常不可预测的情况下，人类可以通过驶离道路来避开其他汽车，或者稍微倒退一点。例如，要让自动驾驶汽车做到这一点会更加困难。
- en: One thing is certain, though. If a human is driving all night and falls asleep,
    the self-driving car will detect the head slumping movement, take over, and save
    lives. The self-driving car can also save lives if the human has a medical problem
    while driving.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然而，有一件事是可以肯定的。如果一个人整晚驾驶并且打瞌睡，自动驾驶汽车会检测到头部下垂的动作，接管驾驶并拯救生命。如果人在驾驶过程中发生健康问题，自动驾驶汽车也可以拯救生命。
- en: '**Will a self-driving fire truck with robots be able to put out a fire one
    day? (Yes | No)**'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自动驾驶消防车搭载机器人有一天能扑灭火灾吗？（是 | 否）**'
- en: '**Yes**. Combining self-driving fire trucks with robots will certainly save
    many lives when a fire department faces difficult fires to extinguish. Those saved
    lives include firefighters who risk their own lives. It might help firefighters
    focus on helping people while robots do tougher jobs. This robot-human team will
    no doubt save thousands of lives in the future.'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。将自动驾驶消防车与机器人结合，当消防部门面临难以扑灭的火灾时，肯定会拯救许多生命。这些被拯救的生命包括那些冒着生命危险的消防员。它可能有助于消防员专注于帮助人们，而机器人则处理更艰难的工作。这种机器人-人类团队无疑将在未来拯救成千上万的生命。'
- en: '**Do major cities need to invest in self-driving cars or avoid them? (Invest
    | Avoid)**'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**大城市需要投资自动驾驶汽车还是避免投资它们？（投资 | 避免）**'
- en: '**Invest**. With slow but safe self-driving cars, commuters could share public,
    free, or very cheap electric self-driving cars instead of having to drive. It
    would be like having a personal chauffeur.'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**投资**。通过缓慢但安全的自动驾驶汽车，通勤者可以共享公共的、免费的或非常便宜的电动自动驾驶汽车，而无需自己开车。这就像有了个人司机一样。'
- en: '**Would you trust a self-driving bus to take children to school and back? (Yes
    | No)**'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**你会相信一辆自动驾驶公交车能安全地送孩子们上下学吗？（是 | 否）**'
- en: This answer will change with time, as technology continues to evolve.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个答案会随着时间推移而变化，因为技术在不断发展。
- en: '**No**. Not in the present state of self-driving vehicles. You should not fully
    trust an autonomous vehicle 100%!'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**。在现有的自动驾驶车辆技术状态下，你不应该完全信任自动驾驶汽车！'
- en: '**Yes**, when self-driving cars, buses, and trucks prove that they can outperform humans.
    Self-driving vehicles will not make the same mistakes as humans: using smartphones
    while driving, talking to passengers without looking at the road, and many others.'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**，当自动驾驶汽车、公交车和卡车证明它们能够超越人类时，自动驾驶车辆将不会犯和人类一样的错误：在驾驶时使用智能手机、与乘客交谈而不看路等。'
- en: '**Would you be able to sleep in a self-driving car on a highway? (Yes | No)**'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**你能在高速公路上睡在自动驾驶汽车里吗？（是 | 否）**'
- en: '**No**, not in the present state of self-driving vehicle technology.'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不**，在现有的自动驾驶技术状态下不行。'
- en: '**Yes**, when reliability replaces doubts.'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**，当可靠性替代了怀疑。'
- en: '**Would you like to develop a self-driving program for a project for a city?
    (Yes | No)**'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**你想为一个城市的项目开发一个自动驾驶程序吗？（是 | 否）**'
- en: That one is for you to think about! You can also apply the technology to warehouses
    for AGVs by contacting the companies or AGV manufacturers directly.
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 那个问题留给你自己思考！你还可以通过直接联系公司或AGV制造商，将这项技术应用到仓库中的AGV。
- en: Chapter 13 – Visualizing Networks with TensorFlow 2.x and TensorBoard
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第13章 – 使用TensorFlow 2.x和TensorBoard可视化网络
- en: '**A CNN always has the same number of layers. (Yes | No)**'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**CNN总是有相同数量的层次。（是 | 否）**'
- en: '**No**. A CNN does not have the same number of layers or even the same type of
    layers. The number of layers is part of the work to optimize an artificial neural
    network.'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。CNN没有相同数量的层，甚至没有相同类型的层。层数是优化人工神经网络的一部分工作。'
- en: '**ReLU is the best activation function. (Yes | No)**'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ReLU是最好的激活函数。（是 | 否）**'
- en: '**No**. ReLU is an efficient activation function, but there are others such
    as leaky ReLU, softmax, sigmoid, and tanh.'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。ReLU是一个有效的激活函数，但还有其他的，如leaky ReLU、softmax、sigmoid和tanh。'
- en: '**It is not necessary to compile a sequential classifier. (Yes | No)**'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**不必编译顺序分类器。（是 | 否）**'
- en: '**No**. The assertion should be yes – it is necessary.'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。这个断言应该是肯定的——这是必须的。'
- en: '**The output of a layer is best viewed without running a prediction. (Yes |
    No)**'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**一个层的输出最好在不运行预测的情况下查看。（是 | 否）**'
- en: '**No**. The output of a layer and a prediction are unrelated. The output of
    the layer can be the transformation of a layer (convolutional, pooling, dropout,
    flattening, other) or a prediction.'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。层的输出和预测是无关的。层的输出可以是层的变换（卷积、池化、丢弃、展平等），也可以是预测。'
- en: '**The names of the layers mean nothing when viewing their outputs. (Yes | No)**'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**查看层的输出时，层的名称没有意义。（是 | 否）**'
- en: '**No**. The layers mean everything! A pooling layer and a dropout layer are
    quite different.'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。层次结构意味着一切！池化层和丢弃层是完全不同的。'
- en: '**TensorFlow 2.x does not include Keras. (Yes | No)**'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**TensorFlow 2.x不包含Keras。（是 | 否）**'
- en: '**No**. TensorFlow has now integrated Keras, which helps to build seamless
    neural networks.'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。TensorFlow现在已集成Keras，帮助构建无缝的神经网络。'
- en: '**Google Colaboratory is just a repository, like GitHub. (Yes | No)**'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Google Colaboratory只是一个代码库，像GitHub一样。（是 | 否）**'
- en: '**No**. Google Colaboratory provides a small but free server to create and
    run programs online.'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。Google Colaboratory提供一个小型但免费的服务器，用于在线创建和运行程序。'
- en: '**Google Colaboratory cannot run notebooks. (Yes | No)**'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Google Colaboratory不能运行笔记本。（是 | 否）**'
- en: '**No**. It can run notebooks.'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。它可以运行笔记本。'
- en: '**It is possible to run TensorBoard in Google Colaboratory notebooks (Yes |
    No)**'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**可以在Google Colaboratory笔记本中运行TensorBoard。（是 | 否）**'
- en: '**Yes**. This is a useful feature.'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。这是一个有用的功能。'
- en: '**Accuracy is displayed in TensorBoard (Yes | No)**'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**TensorBoard中显示了准确性。（是 | 否）**'
- en: '**Yes**. It is an efficient way to evaluate the efficiency of ANNs, for example.'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。这是一种有效的评估ANN效率的方法，例如。'
- en: Chapter 14 – Preparing the Input of Chatbots with Restricted Boltzmann Machines
    (RBMs) and Principal Component Analysis (PCA)
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第14章 – 使用限制玻尔兹曼机（RBMs）和主成分分析（PCA）准备聊天机器人的输入
- en: '**RBMs are based on directed graphs. (Yes | No)**'
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**RBMs基于有向图。（是 | 否）**'
- en: '**No**. RBM graphs are undirected, unsupervised, and memoryless, and the decision-making
    is based on random calculations.'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。RBM图是无向的、无监督的、无记忆的，决策是基于随机计算的。'
- en: '**The hidden units of an RBM are generally connected to one another. (Yes |
    No)**'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**RBM的隐藏单元通常相互连接。（是 | 否）**'
- en: '**No**. The hidden units of an RBM are not generally connected to each other.'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。RBM的隐藏单元通常不会互相连接。'
- en: '**Random sampling is not used in an RBM. (Yes | No)**'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**随机采样在RBM中没有使用。（是 | 否）**'
- en: '**No**. False. Gibbs random sampling is frequently applied to RBMs.'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。错误。吉布斯随机采样通常应用于RBMs。'
- en: '**PCA transforms data into higher dimensions. (Yes | No)**'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**PCA将数据转换为更高的维度。（是 | 否）**'
- en: '**Yes**. The whole point of PCA is to transform data into a lower number of
    dimensions in higher abstraction dimensions (key dimensions isolated) to find
    the principal component (highest eigenvalue of a covariance matrix), then the
    second highest, down to the lowest values.'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。PCA的核心目的是将数据转换为较低维度，在更高抽象维度（关键维度隔离）中找到主成分（协方差矩阵的最大特征值），然后是第二大特征值，依此类推，直到最小值。'
- en: '**In a covariance matrix, the eigenvector shows the direction of the vector
    representing that matrix, and the eigenvalue shows the size of that vector. (Yes
    | No)**'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**在协方差矩阵中，特征向量表示该矩阵的方向，而特征值表示该向量的大小。（是 | 否）**'
- en: '**Yes**. Eigenvalues indicate how important a feature is, and eigenvectors
    provide a direction.'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。特征值表示一个特征的重要性，而特征向量提供一个方向。'
- en: '**It** **is impossible to represent a human mind in a machine. (Yes | No)**'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**不可能** **在机器中表示一个人类的思维。（是 | 否）**'
- en: '**No**. It is possible to a certain extent with sensors and in a limited perimeter.'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。在一定程度上，通过传感器并在有限的范围内是可能的。'
- en: '**A machine cannot learn concepts, which is why classical applied mathematics
    is enough to make efficient AI programs for every field. (Yes | No)**'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**机器无法学习概念，这就是为什么经典应用数学足以为各个领域制作高效的人工智能程序。（是 | 否）**'
- en: '**No**. Never believe that. Progress is being made and will never stop until
    mind machines become mainstream.'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。绝不要相信这一点。进展正在取得，并且将永不停歇，直到思维机器成为主流。'
- en: Chapter 15 – Setting Up a Cognitive NLP UI/CUI Chatbot
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第15章 – 设置认知NLP UI/CUI聊天机器人
- en: '**Can a chatbot communicate like a human? (Yes | No)**'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聊天机器人能像人类一样交流吗？（是 | 否）**'
- en: '**No**. Communicating like a human means being human: having a body with body
    language, sensations, odors, fear hormones, and much more. Chatbots only emulate
    these behaviors.'
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。像人类一样交流意味着成为人类：拥有身体、肢体语言、感觉、气味、恐惧激素等等。聊天机器人只是模仿这些行为。'
- en: '**Are chatbots necessarily AI programs? (Yes | No)**'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聊天机器人一定是人工智能程序吗？（是 | 否）**'
- en: '**No**. Many call centers use the "press 1, press 2 … press *n*" method, which
    requires careful organization but no AI.'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。许多呼叫中心使用“按1、按2...按*n*”的方法，这需要精心组织，但不需要人工智能。'
- en: '**Chatbots only need words to communicate. (Yes | No)**'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聊天机器人只需要用语言进行交流。（是 | 否）**'
- en: The answer is not a clear-cut one.
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案并非绝对明确。
- en: '**Yes**. Simple chatbots can communicate with words in a controlled situation.'
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。简单的聊天机器人在受控的情况下可以通过语言进行交流。'
- en: '**No**. When polysemy (several meanings for the same word or situation) is
    involved, pictograms and more add more efficient dimensions.'
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。当涉及到多义词（同一个词或情境有多个意义）时，象形符号等可以提供更加高效的维度。'
- en: '**Do humans only chat with words? (Yes | No)**'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**人类仅通过语言聊天吗？（是 | 否）**'
- en: '**No**. Humans express themselves through the tone of their voice, body language,
    or music, for example.'
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。人类通过声音的语调、肢体语言或音乐等方式表达自己。'
- en: '**Humans only think in words and numbers. (Yes | No)**'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**人类仅通过语言和数字思考。（是 | 否）**'
- en: '**No**. Certainly not. Humans think in images, sounds, odors, and feelings.'
  id: totrans-292
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。当然不是。人类通过图像、声音、气味和感觉进行思考。'
- en: '**Careful machine learning preparation is necessary to build a cognitive chatbot.
    (Yes | No)**'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建认知聊天机器人需要仔细的机器学习准备。（是 | 否）**'
- en: The answer depends on the context.
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案取决于具体情境。
- en: '**No**. In limited "press 1 or press 2 " situations, chatbots can perform well
    with limited cognitive capacities.'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。在有限的“按1或按2”情境下，聊天机器人凭借有限的认知能力可以表现良好。'
- en: '**Yes**. To engage in a real conversation with a human, mental images are the key
    to providing an empathetic exchange.'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。与人类进行真实对话的关键是通过心理图像来提供富有同理心的交流。'
- en: '**For a chatbot to function, a dialog flow needs to be planned. (Yes | No)**'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**为了使聊天机器人正常工作，需要规划对话流程。（是 | 否）**'
- en: This depends upon what you want your chatbot to do.
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这取决于你希望聊天机器人做什么。
- en: '**Yes**. It will provide better results in a business environment.'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。它在商业环境中将提供更好的结果。'
- en: '**No**. If you want the chatbot to talk freely, you need to free it a bit.
    This still requires planning of the dialog, but it is more flexible.'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。如果你希望聊天机器人自由地交流，你需要稍微解放它。这仍然需要对对话的规划，但会更加灵活。'
- en: '**A chatbot possesses general AI, so no prior development is required. (Yes
    | No)**'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聊天机器人拥有通用人工智能，因此无需提前开发。（是 | 否）**'
- en: '**No**. This is presently impossible. Only narrow (specific to one or a few
    fields) AI exists in real life, contrary to science fiction movies and media hype.'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。目前这是不可能的。现实生活中只存在狭窄的（特定于一两个领域的）人工智能，与科幻电影和媒体炒作相反。'
- en: '**A chatbot translates fine without any function other than a translation API.
    (Yes | No)**'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聊天机器人在没有任何其他功能（除了翻译API）的情况下，能够完成翻译吗？（是 | 否）**'
- en: '**No**. At this point in the history of translation bots, the translations
    are not quite reliable without additional customization.'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。在目前的翻译机器人历史阶段，没有额外的定制，翻译结果并不可靠。'
- en: '**Chatbots can already chat like humans in most cases. (Yes | No)**'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聊天机器人在大多数情况下已经能够像人类一样聊天。（是 | 否）**'
- en: '**No**. Interpreting a language will take quite some more challenging work
    and contributions.'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。解释语言需要更多的挑战性工作和贡献。'
- en: Chapter 16 – Improving the Emotional Intelligence Deficiencies of Chatbots
  id: totrans-307
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第16章 – 改进聊天机器人情商的不足
- en: '**When a chatbot fails to provide a correct response, a hotline with actual
    humans needs to take over the conversation. (Yes | No)**'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**当聊天机器人未能提供正确的回应时，需要由人工热线接管对话。 (是 | 否)**'
- en: This comes down to context and practicality.
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这取决于上下文和实用性。
- en: '**Yes**. That is what the best solution would be. To have an interactive chat
    service kick in.'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。这是最佳解决方案。需要有一个互动聊天服务介入。'
- en: '**No**. In many cases, it would be too expensive. A nice support screen could
    do the job and send an email to the support team.'
  id: totrans-311
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。在许多情况下，这将是太昂贵了。一块好的支持屏幕就可以完成工作，并向支持团队发送电子邮件。'
- en: '**Small talk serves no purpose in everyday life or with chatbots. It is best
    to just get to the point. (Yes | No)**'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**闲聊在日常生活或与聊天机器人交互时没有任何意义。最好直接进入正题。 (是 | 否)**'
- en: Again, this is a matter of context.
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 再次，这取决于具体的上下文。
- en: '**Yes**. If it''s an emergency bot, of course!'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。如果是紧急情况的机器人，当然！'
- en: '**No**. If the chatbot is there to perform a tedious administrative function,
    some degree of small talk will make the system more bearable.'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。如果聊天机器人的任务是执行繁琐的行政功能，适度的闲聊会让系统更加耐受。'
- en: '**Data logging can be used to improve speech recognition. (Yes | No)**'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据日志记录可以用于改善语音识别。 (是 | 否)**'
- en: '**Yes**. Absolutely. More data means better machine learning training.'
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。完全正确。更多的数据意味着更好的机器学习训练。'
- en: '**The history of a chatbot agent''s conversations will contain valuable information.
    (Yes | No)**'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**聊天机器人代理的对话历史将包含有价值的信息。 (是 | 否)**'
- en: '**Yes**. Absolutely. More feedback means more machine learning progress.'
  id: totrans-319
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。完全正确。更多的反馈意味着更多的机器学习进展。'
- en: '**Present-day technology cannot make use of the data logging of a user''s dialogs.
    (Yes | No)**'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**现今技术无法利用用户对话的数据记录。 (是 | 否)**'
- en: '**No**. We can, of course, parse data logging and extract valuable information.'
  id: totrans-321
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。我们当然可以解析数据记录并提取有价值的信息。'
- en: '**An RNN uses sequences of data to make predictions. (Yes | No)**'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**RNN 使用数据序列来做出预测。 (是 | 否)**'
- en: '**Yes**, it does.'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**，它是这样。'
- en: '**An RNN can generate the dialog flow of a chatbot automatically for all applications.
    (Yes | No)**'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**RNN 可以自动生成聊天机器人的对话流程，适用于所有应用。 (是 | 否)**'
- en: '**Yes** and **no**. It can, but the quality is sometimes still terrible at
    this point in the history of automatic dialog flows!'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**和**否**。它能做到，但在自动对话流程的历史阶段，这个质量仍然有时很差！'
- en: Chapter 17 – Genetic Algorithms in Hybrid Neural Networks
  id: totrans-326
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第17章 – 混合神经网络中的遗传算法
- en: '**A cell contains 42 chromosomes. (Yes | No)**'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**细胞含有42条染色体。 (是 | 否)**'
- en: '**No**. There are 46 chromosomes in a cell.'
  id: totrans-328
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。每个细胞有46条染色体。'
- en: '**A genetic algorithm is deterministic, not random. (Yes | No)**'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**遗传算法是确定性的，而非随机的。 (是 | 否)**'
- en: '**No**. A genetic algorithm is random, which makes it more efficient than many deterministic
    algorithms.'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。遗传算法是随机的，这使它比许多确定性算法更高效。'
- en: '**An evolutionary algorithm means that program code evolves. (Yes | No)**'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**进化算法意味着程序代码会进化。 (是 | 否)**'
- en: There is not a single clear-cut answer.
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这没有一个明确的答案。
- en: '**No**. The program runs like any other program.'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。程序就像其他程序一样运行。'
- en: '**Yes**. In some ways, when it is used to optimize a neural network in a hybrid neural
    network, it changes the parameters of the system. Also, it is possible to use
    a genetic algorithm to add or take layers out of a CNN, for example.'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。在某些情况下，当它被用于优化混合神经网络中的神经网络时，它会改变系统的参数。此外，也可以使用遗传算法向CNN中添加或移除层。'
- en: '**It is best for a child to have the same genes as one of the parents even
    after many generations. (Yes | No)**'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**即使经过多代，孩子最好继承父母之一的基因。 (是 | 否)**'
- en: '**No**. Certainly not! We need diverse genes to remain a fit genetic group.'
  id: totrans-336
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。当然不是！我们需要多样化的基因才能保持适应性的基因群体。'
- en: '**Diversity makes the gene sets weaker. (Yes | No)**'
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**多样性使得基因集变弱。 (是 | 否)**'
- en: '**No**. The greater the diversity, the richer the genetic pool is to adapt
    and remain fit.'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。多样性越大，基因池越丰富，更能适应并保持适应性。'
- en: '**Building a neural network only takes a few lines, and the architecture always
    works. (Yes | No)**'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**建立神经网络只需几行代码，而且架构总是有效的。 (是 | 否)**'
- en: This depends on what you mean by "work."
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这取决于你所说的“工作”是什么意思。
- en: '**Yes**. Building a neural network only takes a few lines with TensorFlow 2.x,
    for example, and it will work.'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。例如，使用 TensorFlow 2.x 构建神经网络只需要几行代码，它就能工作。'
- en: '**No**. The neural network will work, but it will most probably not be efficient
    until its architecture and hyperparameters are fine-tuned.'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。神经网络可以运行，但在其架构和超参数经过微调之前，它很可能不会高效。'
- en: '**Building a neural network with a genetic algorithm can help optimize the architecture
    of the layers. (Yes | No)**'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**用遗传算法构建神经网络有助于优化层的架构。 (是 | 否)**'
- en: '**Yes**. It is possible to extend a genetic algorithm to layer optimizing.
    Each layer can be a gene, and then the various alternatives can be run to check
    their accuracy.'
  id: totrans-344
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。有可能将遗传算法扩展到层优化中。每一层可以是一个基因，然后可以运行各种替代方案以检查它们的准确性。'
- en: '**Hybrid neural networks are useless since deep learning will constantly progress.
    (Yes | No)**'
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**混合神经网络是没用的，因为深度学习将不断进步。 (是 | 否)**'
- en: '**No**. Deep learning will reach an asymptote, as do all systems. At that point,
    new dimensions can be added to deep learning architecture, such as genetic algorithms.'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。深度学习会达到一个渐近线，正如所有系统一样。到那时，可以向深度学习架构中添加新的维度，比如遗传算法。'
- en: '**Would you trust a genetic algorithm to make decisions for you? (Yes | No)**'
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**你会信任遗传算法为你做决策吗？ (是 | 否)**'
- en: '**Yes**, if the system is properly designed. No if you don''t trust genetic
    algorithms!'
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**，如果系统设计得当。如果你不信任遗传算法，那就否！'
- en: '**Would you trust a hybrid neural network to optimize the architecture of your
    network? (Yes | No)**'
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**你会信任一个混合神经网络来优化你网络的架构吗？ (是 | 否)**'
- en: '**Yes**, if the system is properly designed. No, if it is unreliable or biased.'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**，如果系统设计得当。否，如果它不可靠或有偏差。'
- en: Chapter 18 – Neuromorphic Computing
  id: totrans-351
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第18章 – 类脑计算
- en: '**Neuromorphic computing reproduces our mental activity. (Yes | No)**'
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**类脑计算再现了我们的心理活动。 (是 | 否)**'
- en: '**No**. That is the point. Neuromorphic begins with sub-symbolic low-level
    neuronal brain activity stimulations that do not form high-level mental activity
    yet. Our mental activity already uses symbols and contains representations in
    the form of words, images, numbers, and all kinds of constructions in general.'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。这正是关键。类脑计算始于低层次的、非符号的神经元大脑活动刺激，这些刺激尚未形成高级的心理活动。我们的心理活动已经使用符号，并且包含以词语、图像、数字以及各种构建形式的表示。'
- en: However, we can say YES if we are referring to the output results translated
    into mental activity. My point is that yes and no answers limit our views of AI.
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然而，如果我们指的是转换为心理活动的输出结果，我们可以说**是**。我的意思是，"是"和"否"的回答限制了我们对人工智能的看法。
- en: '**Neuromorphic computing reproduces our brain activity. (Yes | No)**'
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**类脑计算再现了我们的大脑活动。 (是 | 否)**'
- en: '**Yes**. That is the point! The core concept is to go from brain activity to
    structures formed by neuron spikes.'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**。这正是关键！核心概念是从大脑活动到由神经元尖峰形成的结构。'
- en: '**Semantic Pointer Architecture (SPA) is a hardware architecture. (Yes | No)**'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**语义指针架构（SPA）是一种硬件架构。 (是 | 否)**'
- en: '**No**. Semantic pointers are like computer program pointers such as C++ pointers.
    The difference is that they carry a partial meaning of representation to come,
    hence the word "semantic."'
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。语义指针就像计算机程序指针，例如 C++ 指针。不同之处在于，它们携带的是部分表示意义，因此叫做“语义”。'
- en: '**NEF stands for Neural Engineering Framework. (Yes | No)**'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**NEF代表神经工程框架。 (是 | 否)**'
- en: '**Yes**, this is true.'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是**，这是正确的。'
- en: '**Loihi is a classical chip. (Yes | No)**'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Loihi 是一个经典芯片。 (是 | 否)**'
- en: '**No**. Not at all! Loihi is an Intel neurocomputing chip containing a massive
    number of neurons. A human brain contains around 100 billion neurons. Imagine
    that, soon, you''ll have a network of neurocomputing chips (Intel or other) that
    attain that number. Then imagine what can be done with semantic pointers through
    neurocomputing.'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。绝对不是！Loihi 是英特尔的类脑计算芯片，包含大量的神经元。人类大脑大约有 1000 亿个神经元。想象一下，快的话，你将拥有一个由类脑计算芯片（英特尔或其他厂商）构成的网络，达到了这个数量。再想象一下，通过类脑计算可以做什么，尤其是语义指针。'
- en: '**Reproducing our brain''s neural activity cannot solve an equation. (Yes |
    No)**'
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**再现我们大脑的神经活动不能解决方程。 (是 | 否)**'
- en: '**No**. Of course, we can use neurocomputing to solve equations through the
    SPA approach.'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**否**。当然，我们可以使用类脑计算通过 SPA 方法来求解方程。'
- en: '**An ensemble in Nengo contains algorithms. (Yes | No)**'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Nengo 中的一个集成包含算法。 (是 | 否)**'
- en: '**No**. But the question was tricky! Basically, Nengo uses a non-symbolic approach
    as discussed at length previously. However, it contains Python tutorials with
    many algorithms solved through neurocomputing, forming a complete problem-solving
    package.'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。但是这个问题很棘手！基本上，Nengo使用如前所述的非符号化方法。然而，它包含许多通过神经计算解决的算法的Python教程，形成了一个完整的问题解决方案。'
- en: '**Spiking blocks neuronal activity. (Yes | No)**'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**尖峰阻止神经元活动。（是的 | 不是）**'
- en: '**No**. But again, this is a tricky question. Spiking is reflected in the level
    of activity in a neuron. So, in that respect, the answer is no. But a spiking
    neuron can inhibit another neuron, thereby blocking it indirectly.'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。但这又是一个棘手的问题。尖峰反映了神经元活动的水平。所以，在这个方面，答案是“不是”。但一个尖峰神经元可以抑制另一个神经元，从而间接地阻止它。'
- en: '**Firing patterns can be used to analyze brain activity. (Yes | No)**'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**放电模式可以用来分析大脑活动。（是的 | 不是）**'
- en: '**Yes**. Firing patterns change in time in neurocomputing, providing useful
    information on how the neurons reach a given state.'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。在神经计算中，放电模式会随时间变化，提供有关神经元如何到达给定状态的有用信息。'
- en: '**Machine learning and deep learning are only metaphors of our brain''s activity.
    (Yes | No)**'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**机器学习和深度学习只是我们大脑活动的隐喻。（是的 | 不是）**'
- en: '**Yes**. That is the core problem associated with deep learning. They are high-level
    representations of our brain''s neuronal activity.'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。这就是深度学习所面临的核心问题。它们是我们大脑神经活动的高级表现。'
- en: Chapter 19 – Quantum Computing
  id: totrans-373
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第19章 – 量子计算
- en: '**Beyond the hype, no quantum computer exists. (Yes | No)**'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**超越炒作，目前还没有量子计算机存在。（是的 | 不是）**'
- en: '**No**. False. You can already run a quantum computer on IBM Q''s cloud platform:
    [https://www.research.ibm.com/ibm-q/](https://www.research.ibm.com/ibm-q/).'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。错误。你现在已经可以在IBM Q的云平台上运行量子计算机：[https://www.research.ibm.com/ibm-q/](https://www.research.ibm.com/ibm-q/)。'
- en: 'The following screenshot is the result of one of the real quantum computer
    (IBM) calculations I ran on a quantum score explained in the chapter:'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图是我在量子得分上运行的一个真实量子计算机（IBM）计算结果，详细解释在章节中：
- en: '![](img/B15438_20_01.png)'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B15438_20_01.png)'
- en: 'Figure A.1: IBM quantum computer calculation'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.1：IBM量子计算机计算
- en: '**A quantum computer can store data. (Yes | No)**'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**量子计算机能存储数据。（是的 | 不是）**'
- en: '**No**. Instability prevents any form of storage at this point.'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。不稳定性目前阻止了任何形式的存储。'
- en: '**The effect of quantum gates on qubits can be viewed with the Bloch sphere.
    (Yes | No)**'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**量子门对量子比特的影响可以通过布洛赫球体来观察。（是的 | 不是）**'
- en: '**Yes**. A Bloch sphere will display the state of a qubit.'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。布洛赫球体将显示量子比特的状态。'
- en: '**A mind that thinks with past experiences, images, words, and other bits of everyday
    information, like stored memories, will find deeper solutions to problems that
    mathematics alone cannot solve. (Yes | No)**'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**一个通过过去经验、图像、词语和其他日常信息（如存储的记忆）思考的大脑，将会找到数学单独无法解决的问题的更深层次解决方案。（是的 | 不是）**'
- en: There is no single generally accepted answer for this. Just as qubits, the answer
    is somewhere between yes (1) and no (0)!
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个问题没有单一普遍接受的答案。就像量子比特一样，答案介于“是”（1）和“不是”（0）之间！
- en: '**No**. False. Many researchers believe that mathematics alone can solve all
    human problems.'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是**。错误。许多研究人员认为仅凭数学无法解决所有人类问题。'
- en: '**Yes**. True. Mathematics alone cannot replace deep thinking. Even if computers
    have incredible power and can beat human players at chess, for example, they still
    cannot adapt to new situations without going through a design and training process.
    Concepts need to be added and experienced (memory as well).'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。正确。仅凭数学无法替代深入思考。即使计算机拥有惊人的计算能力，并且能够在国际象棋中击败人类选手，例如，它们仍然不能在没有经过设计和训练的过程中适应新情况。概念需要被添加并且经历（包括记忆）。'
- en: I bet that machine mind concepts will become progressively more mainstream to
    solve deep thinking problems.
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我敢打赌，机器思维的概念将会逐渐成为主流，用于解决深度思维问题。
- en: '**A quantum computer will solve medical research problems that cannot be solved
    today. (Yes | No)**'
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**量子计算机将解决今天无法解决的医学研究问题。（是的 | 不是）**'
- en: '**Yes**. There is no doubt about that. The sheer computing power of a quantum
    computer can provide exponential DNA sequencing programs for epigenetic research.'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。这一点毫无疑问。量子计算机的强大计算能力能够为表观遗传学研究提供指数级的DNA测序程序。'
- en: '**A quantum computer can solve mathematical problems exponentially faster than
    classical computers. (Yes | No)**'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**量子计算机能比经典计算机更快地指数级解决数学问题。（是的 | 不是）**'
- en: '**Yes**. Classical computers function at 2 × *n* (number of bits), and quantum
    computers run at 2^n (*n* being the number of qubits)!'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**是的**。经典计算机以 2 × *n*（位数）运行，而量子计算机则以 2^n（*n* 为量子比特的数量）运行！'
- en: '**Classical computers will soon disappear and smartphone processors too. (Yes |
    No)**'
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**经典计算机和智能手机处理器很快会消失。（是 | 否）**'
- en: '**No**. Quantum computers require such a large amount of space and physical
    stability that this will not happen soon. Furthermore, classical computers and smartphones
    can store data; quantum computers cannot.'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是的**。量子计算机需要非常大的空间和物理稳定性，因此这一点短期内不会发生。而且，经典计算机和智能手机可以存储数据，但量子计算机不能。'
- en: '**A quantum score cannot be written in source code format but only with a visual
    interface. (Yes | No)**'
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**量子得分无法以源代码格式编写，只能通过可视化界面实现。（是 | 否）**'
- en: '**No**. False. IBM, for example, can swap the quantum from score to a QASM
    interface or display both, as shown here:'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是的**。错误。例如，IBM 可以将量子得分从量子代码转换为 QASM 界面或同时显示两者，如下所示：'
- en: '![](img/B15438_20_02.png)'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B15438_20_02.png)'
- en: 'Figure A.2: QASM interface'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 A.2：QASM 界面
- en: '**Quantum simulators can run as fast as quantum computers. (Yes | No)**'
  id: totrans-398
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**量子模拟器可以运行得和量子计算机一样快。（是 | 否）**'
- en: '**No**. Certainly not! A simulator shows how a quantum score would behave on
    a real quantum computer. Although the simulator can help build the score, a quantum
    computer will run exponentially faster than the simulator.'
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是的**。绝对不行！模拟器展示了量子得分在真实量子计算机上会如何表现。虽然模拟器可以帮助构建得分，但量子计算机的运行速度会比模拟器快得多。'
- en: '**Quantum computers produce intermediate results when they are running calculations.
    (Yes | No)**'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**量子计算机在运行计算时会产生中间结果。（是 | 否）**'
- en: '**No**. This is not possible. The qubits are too unstable. Observing them makes the
    system collapse. However, simulators such as Quirk come in handy. Since they are
    not real, intermediate results can be displayed to design a quantum score.'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**不是的**。这是不可能的。量子比特太不稳定了。对其进行观察会导致系统崩溃。然而，像 Quirk 这样的模拟器非常有用。由于它们不是实际的量子计算机，因此可以显示中间结果来设计量子得分。'
