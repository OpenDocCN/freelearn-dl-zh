- en: Classifying Images Using Amazon SageMaker
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon SageMaker 进行图像分类
- en: Image classification has been one of the leading research fields in the last
    five years. This is not surprising because being able to successfully classify
    images solves many business problems across a variety of industries. For example,
    the entire autonomous vehicle industry is dependent on the accuracy of these image
    classification and object detection models.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类是过去五年中最重要的研究领域之一。这并不令人惊讶，因为成功地分类图像解决了许多不同行业的业务问题。例如，整个自动驾驶汽车行业依赖于图像分类和物体检测模型的准确性。
- en: In this chapter, we will look at how Amazon SageMaker drastically simplifies
    the image classification problem. Aside from gathering a rich set of images for
    training, we will look at how to specify hyperparameters (parameters internal
    to the algorithm), train Docker images, and use infrastructure specifications
    for training.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨 Amazon SageMaker 如何大大简化图像分类问题。除了收集丰富的图像集进行训练外，我们还将学习如何指定超参数（算法内部的参数）、训练
    Docker 镜像，并使用基础设施规范进行训练。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下内容：
- en: Walking through convolutional neural and residual networks
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解卷积神经网络和残差网络
- en: Classifying images through transfer learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过迁移学习进行图像分类
- en: Performing inferences on images through Batch Transform
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过批量变换对图像进行推断
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Please use the following link to refer to the source code for this chapter :[https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services](https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 请使用以下链接查看本章的源代码：[https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services](https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services)。
- en: Walking through convolutional neural and residual networks
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解卷积神经网络和残差网络
- en: The SageMaker image classification algorithm is an implementation of **residual
    networks** (**ResNets**). Before we delve into the details of the algorithm, let's
    briefly understand **convolutional neural networks** (**CNN**) and ResNet and
    how they learn patterns from images.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 图像分类算法是 **残差网络**（**ResNets**）的实现。在深入了解算法的细节之前，让我们简要了解一下 **卷积神经网络**（**CNN**）和
    ResNet，以及它们是如何从图像中学习模式的。
- en: Like any other neural network, CNNs are made up of input, hidden, and output
    layers. These networks have learnable parameters called weights and biases. These
    weights and biases can be adjusted through an appropriate optimizer, such as **Stochastic
    Gradient Descent** (**SGD**), with backpropagation. However, the difference between
    any feedforward artificial neural network and CNNs is that the hidden layers in
    CNNs are convolutional layers. Each convolutional layer consists of one or more
    filters. The job of these filters is to recognize patterns in input images.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 像其他神经网络一样，CNN 由输入层、隐藏层和输出层组成。这些网络有可学习的参数，称为权重和偏差。通过适当的优化器（例如 **随机梯度下降**（**SGD**））与反向传播，权重和偏差可以进行调整。然而，任何前馈人工神经网络与
    CNN 之间的区别在于，CNN 中的隐藏层是卷积层。每个卷积层由一个或多个过滤器组成。这些过滤器的任务是识别输入图像中的模式。
- en: These filters can have varying shapes, ranging from 1 x 1 to 3 x 3 and so on,
    and are initialized with random weights. As the input image passes through the
    convolutional layer, each filter will slide over every 3 x 3 block of pixels (in
    the case of a 3 x 3 filter) until the entire image is covered. This sliding is
    referred to as convolving. During the process of convolving, a dot product is
    applied to the filter weights and pixel values in the 3 x 3 block, thus learning
    about the image's features. The initial layers of the CNN learn basic geometric
    shapes, such as edges and circles, while later layers learn about more sophisticated
    objects, such as eyes, ears, feathers, beaks, cats, and dogs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这些过滤器可以具有不同的形状，范围从 1 x 1 到 3 x 3 等等，并且它们是以随机权重进行初始化的。当输入图像通过卷积层时，每个过滤器将滑过每个
    3 x 3 像素块（以 3 x 3 过滤器为例），直到整个图像被覆盖。这种滑动被称为卷积。在卷积过程中，过滤器权重与 3 x 3 块中的像素值进行点积，从而学习图像的特征。CNN
    的初始层学习基本的几何形状，如边缘和圆形，而后续层学习更复杂的物体，如眼睛、耳朵、羽毛、喙、猫和狗。
- en: With deeper convolutional neural networks, as we stack more layers to learn
    complex features, vanishing gradient problems arise. In other words, during the
    training process, some neurons die (do not activate), causing a vanishing gradient.
    This happens when an activation function receives input with varying distributions
    (for example, if you're passing black and white images of cats as opposed to colored
    ones through the network, the input raw pixels belong to a different distribution,
    causing a vanishing gradient problem). If we restrict neuron output to the area
    to around zero, we can ensure that each layer will pass a substantive gradient
    back to the previous layers.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着卷积神经网络的加深，随着我们堆叠更多层来学习复杂特征，消失梯度问题也随之而来。换句话说，在训练过程中，一些神经元会失效（不会激活），导致消失梯度问题。这种情况发生在激活函数接收到具有不同分布的输入时（例如，如果你将黑白猫的图像与彩色猫的图像传递给网络，输入的原始像素属于不同的分布，从而导致消失梯度问题）。如果我们将神经元输出限制在接近零的范围内，就能确保每一层都会将有效的梯度传递回前一层。
- en: 'To solve the challenges that CNNs bring with them, deep residual learning combines
    what has been learned from previous layers with what has been learned from shallower
    models:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决卷积神经网络带来的挑战，深度残差学习将前一层学到的内容与浅层模型学到的内容相结合：
- en: '*![](img/81c15e7f-52f1-4cef-9ae2-3ce15e463a64.png)*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*![](img/81c15e7f-52f1-4cef-9ae2-3ce15e463a64.png)*'
- en: Here, *![](img/59f4c0f0-897d-4e35-b86e-0d8299b3f806.png)* is a convolutional
    layer or shallower model and ![](img/2bcc9ac6-3a27-4ef9-8ae4-02b8105d0834.png)
    is the previous layer.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*![](img/59f4c0f0-897d-4e35-b86e-0d8299b3f806.png)* 是一个卷积层或浅层模型，而 ![](img/2bcc9ac6-3a27-4ef9-8ae4-02b8105d0834.png)
    是前一层。
- en: Residual networks, while addressing the challenges of CNNs, are an optimal approach
    to use when classifying images. In the next section, we will look at transfer
    learning as an approach to incrementally training an already-trained image classification
    model.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 残差网络在解决卷积神经网络的挑战时，是一种进行图像分类时的最佳方法。在下一部分，我们将探讨迁移学习作为逐步训练已训练图像分类模型的一种方法。
- en: Classifying images through transfer learning in Amazon SageMaker
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过迁移学习在 Amazon SageMaker 中对图像进行分类
- en: One of the key challenges in classifying images is the availability of large
    training datasets. For example, to create Amazon Go-type experiences, the e-commerce
    retailer may have trained their machine learning algorithms on large volumes of
    images. When we don't have images covering all types of real-world scenarios –
    scenarios ranging from time of the day (brightness), ambience around the target
    item, and item angle – we're unable to train image classification algorithms that
    are able to perform well in real-life environments. Furthermore, it takes a lot
    of effort to build a convolutional neural network architecture that is optimal
    for the dataset at hand. These considerations range from the number of convolutional
    layers to the batch size, to the optimizer, and to dropout rates. It takes multiple
    trial-and-error experiments to arrive at an optimal model iteration.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类的关键挑战之一是大型训练数据集的可用性。例如，为了创建类似 Amazon Go 的体验，电子商务零售商可能已经在大量图像上训练了他们的机器学习算法。当我们没有涵盖所有现实世界场景的图像时——这些场景包括一天中的时间（亮度）、目标物品周围的环境以及物品角度——我们就无法训练出在现实环境中表现良好的图像分类算法。此外，构建一个对当前数据集最优的卷积神经网络架构需要付出大量的努力。这些考虑因素从卷积层的数量到批处理大小，再到优化器和丢弃率，都需要进行反复试验和调整，才能得到一个最优的模型迭代。
- en: Because image classification requires a large number of images for training
    convolutional networks, an alternative approach can be used to classify images
    when the size of the training dataset is small. Transfer learning allows you to
    apply the knowledge of an already trained model to a different but related problem.
    We can reuse the weights of a pre-trained deep learning model that's been trained
    on millions of images and fine-tune the network with a new/custom dataset that's
    unique to our business case. Through transfer learning, low-level geometric features,
    such as edges, can already be recognized by a pre-trained ResNet-18 (18 layer
    network). However, for mid- to high-level feature learning, the top **fully connected**
    (**FC**) layer is reinitialized with random weights. Then, the whole network is
    fine-tuned with the new data—the random weights are adjusted by passing training
    data through the network and using an optimization technique, for example, stochastic
    gradient descent with backpropagation.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 因为图像分类需要大量的图像来训练卷积网络，当训练数据集较小时，可以采用另一种方法来对图像进行分类。迁移学习允许你将已经训练好的模型的知识应用于不同但相关的问题。我们可以重用一个经过百万张图像训练的预训练深度学习模型的权重，并通过新的/自定义的数据集对网络进行微调，这些数据集是针对我们业务案例特有的。通过迁移学习，低级几何特征，如边缘，已经能够被一个预训练的ResNet-18（18层网络）识别。然而，对于中级到高级特征学习，顶部的**全连接**（**FC**）层会被重新初始化为随机权重。然后，通过新数据对整个网络进行微调——随机权重通过将训练数据传入网络并使用优化技术（例如，带有反向传播的随机梯度下降）进行调整。
- en: In this chapter, we'll employ SageMaker's image classification algorithm in
    transfer learning mode to classify some bakery and fast food items. We will use
    the pre-trained ResNet-18 that's provided by Amazon SageMaker. The image classification
    algorithm implements ResNets to categorize images. We can either train ResNets
    from scratch or use pre-trained networks. Since we have a small image dataset
    to train, we'll use an 18-layer pre-trained ResNet provided by Amazon SageMaker.
    We can also experiment with ResNet50, a 50-layer residual network, to determine
    which network yields a higher performance. Usually, deeper networks perform better
    than shallow networks since they are able to represent images better. However,
    given the type and complexity of the input images, the results can vary.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将采用SageMaker的图像分类算法，以迁移学习模式对一些面包店和快餐项目进行分类。我们将使用Amazon SageMaker提供的预训练ResNet-18。图像分类算法实现了ResNet来对图像进行分类。我们可以从头开始训练ResNet，或者使用预训练的网络。由于我们有一个小的图像数据集来进行训练，我们将使用Amazon
    SageMaker提供的18层预训练ResNet。我们还可以尝试使用ResNet50，一个50层的残差网络，以确定哪个网络的性能更好。通常，深层网络比浅层网络表现更好，因为它们能够更好地表示图像。然而，考虑到输入图像的类型和复杂性，结果可能会有所不同。
- en: Our new dataset contains around 302 images with five categories (Hot Dog, Berry
    Donut, Glazed Twist, Muffin, and Peanut Butter Cookie). Each of these items contains
    40 to 90 images, covering the item from varying angles, as well as brightness,
    contrast, and size.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的新数据集包含约302张图像，涵盖五个类别（热狗、莓果甜甜圈、糖霜扭结、松饼和花生酱饼干）。每个类别包含40到90张图像，涵盖不同的角度，以及亮度、对比度和尺寸。
- en: 'The image classifier learns about the image''s low-level features from a pre-trained
    ResNet and the high-level features by training the same ResNet-18 with a new dataset.
    The following is an illustration of how the features—low, mid, and high-level—of
    a Berry Donut are learned by SageMaker''s image classification algorithm:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类器从一个预训练的ResNet中学习图像的低级特征，并通过使用新的数据集训练相同的ResNet-18来学习高级特征。以下是SageMaker的图像分类算法如何学习一只莓果甜甜圈的特征——低级、中级和高级——的示意图：
- en: '![](img/7a6fc71d-830a-4765-b9b6-d132bb3e8394.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7a6fc71d-830a-4765-b9b6-d132bb3e8394.png)'
- en: So far, we've reviewed what transfer learning is and when it is appropriate.
    We've also briefly described the image dataset that we're going to feed to the
    image classification algorithm in SageMaker. Let's get the images dataset prepared
    for training.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经回顾了迁移学习是什么以及何时适用。我们还简要描述了将要提供给SageMaker图像分类算法的图像数据集。现在，来准备好图像数据集进行训练。
- en: Creating input for image classification
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为图像分类创建输入
- en: 'Amazon SageMaker''s image classification algorithm accepts images in file mode
    via two content types, namely:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon SageMaker的图像分类算法通过两种内容类型接受文件模式下的图像，分别是：
- en: RecordIO (application/`x-recordio`)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RecordIO（application/`x-recordio`）
- en: Image (image/`.png`, image/`.jpeg`, and application/`x-image`)
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像（image/`.png`、image/`.jpeg` 和 application/`x-image`）
- en: In this chapter, we will use the RecordIO format. **RecordIO** is a binary format
    for representing images efficiently and storing them in a compact format. Training
    and validation images are available in a zipped format as part of the source code
    associated with this chapter.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用 RecordIO 格式。**RecordIO** 是一种用于高效表示图像并以紧凑格式存储它们的二进制格式。训练和验证图像以压缩格式提供，作为本章相关源代码的一部分。
- en: 'In order to create RecordIO files for our training and validation datasets,
    we will do the following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了为我们的训练和验证数据集创建 RecordIO 文件，我们将执行以下操作：
- en: Extract `.zip` files, both training and validation (via the `extract_zipfile`
    function)
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取 `.zip` 文件，包括训练和验证文件（通过 `extract_zipfile` 函数）
- en: Create list files for training and validation (via the `create_listfile` function)
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为训练和验证创建列表文件（通过 `create_listfile` 函数）
- en: Create Record IO files for training and validation (via the `create_recordio`
    function)
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建用于训练和验证的 Record IO 文件（通过 `create_recordio` 函数）
- en: 'For definitions of these functions, please refer to the accompanying source
    code folder:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 有关这些函数的定义，请参阅随附的源代码文件夹：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: To create a RecordIO format for training and validation datasets, we need to
    create a list file that outlines the image index, followed by image classification
    (note that we have five categories of images) and the location of the image itself.
    We need to define these attributes for each of the images in the training and
    validation datasets. To create a list file for images, we will use the **im2rec**
    (**image to Recordio**) module of MXNet, an open-source deep-learning library
    for training and deploying deep learning models.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 为了为训练和验证数据集创建 RecordIO 格式，我们需要创建一个列表文件，列出图像索引，后面跟着图像分类（注意我们有五类图像）和图像本身的位置。我们需要为训练和验证数据集中的每张图像定义这些属性。为了创建图像的列表文件，我们将使用
    MXNet 的 **im2rec**（**图像转 RecordIO**）模块，MXNet 是一个用于训练和部署深度学习模型的开源深度学习库。
- en: 'The following code snippet illustrates how to create a list file using the
    `im2rec` module. In order to create a list file, `im2rec` requires the location
    of the images:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段展示了如何使用 `im2rec` 模块创建列表文件。为了创建列表文件，`im2rec` 需要图像的位置：
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `create_listfile()` function produces the following output. The following
    is an excerpt of a sample list file:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`create_listfile()` 函数产生如下输出。以下是示例列表文件的摘录：'
- en: '![](img/6442d6ce-5baf-450d-82ac-68680a82a7a1.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6442d6ce-5baf-450d-82ac-68680a82a7a1.png)'
- en: From the list file we created, we produce a compressed representation of images
    via the RecordIO format—again, using the im2rec module from MXNet.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们创建的列表文件中，我们通过 RecordIO 格式生成图像的压缩表示——同样使用 MXNet 的 im2rec 模块。
- en: 'We will now upload the aforementioned training and validation datasets (`.rec`
    files) to an S3 bucket. Additionally, we will upload test images, separately from
    the training and validation images, to a test folder. Please refer to the accompanying
    source code folder. The following screenshot shows the S3 bucket, along with the
    relevant datasets:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将上传前述的训练和验证数据集（`.rec` 文件）到 S3 存储桶。此外，我们还将把测试图像单独上传到测试文件夹，而不是上传到训练和验证图像文件夹。请参阅随附的源代码文件夹。以下截图显示了
    S3 存储桶及相关数据集：
- en: '![](img/c3ec101d-0706-494b-8877-bbb71867f51f.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c3ec101d-0706-494b-8877-bbb71867f51f.png)'
- en: Now that we have all the datasets for training and inference, we are ready to
    define the parameters of the image classification algorithm.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了所有用于训练和推理的数据集，接下来我们准备定义图像分类算法的参数。
- en: Defining hyperparameters for image classification
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义用于图像分类的超参数
- en: 'There are two kinds of parameter that we need to specify before fitting the
    model to the training and validation datasets:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在将模型拟合到训练和验证数据集之前，我们需要指定两类参数：
- en: Parameters for the training job
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练任务的参数
- en: Hyperparameters that are specific to the algorithm
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特定于算法的超参数
- en: The parameters for the training job deal with the input and output configuration,
    including the type of infrastructure to provision.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 训练任务的参数处理输入和输出配置，包括要提供的基础设施类型。
- en: 'To train the job configuration, we need to do the following:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练任务配置，我们需要执行以下步骤：
- en: First, we need to define the image classification Docker image and training
    input mode (file versus pipe mode. Pipe mode is a recent addition to the SageMaker
    toolkit, where input data is fed on the fly to the algorithm's container with
    no need to download it before training).
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要定义图像分类的Docker镜像和训练输入模式（文件模式与管道模式。管道模式是SageMaker工具包中的新功能，数据输入会实时传送到算法容器中，无需在训练前下载）。
- en: Next, we define the location of the training output (`S3OutputPath`), along
    with the number and type of EC2 instances, to provision and the hyperparameters.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义训练输出的位置（`S3OutputPath`），以及要配置的EC2实例的数量和类型，以及超参数。
- en: After that, we specify the *train* and *validation* channels, which are going
    to be the locations of the training and validation data. As for distribution training,
    the algorithm currently only supports `fullyreplicated` mode, where data is copied
    onto each machine.
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们指定*训练*和*验证*通道，这些通道将作为训练和验证数据的位置。至于分布式训练，目前该算法只支持`fullyreplicated`模式，其中数据会被复制到每台机器上。
- en: 'The following hyperparameters are specific to the algorithm:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下超参数是算法特定的：
- en: '`num_layers`: The number of layers for the network. In this example, we will
    use the default 18 layers.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_layers`：网络的层数。在此示例中，我们将使用默认的18层。'
- en: '`image_shape`: Image dimensions (*width x height*).'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_shape`：图像维度（*宽度 x 高度*）。'
- en: '`num_training_samples`: This is the total number of training data points. In
    our case, this is set to `302`.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_training_samples`：训练数据点的总数。在我们的案例中，这个值为`302`。'
- en: '`num_classes`: This is the number of categories. For our dataset, this is 5\.
    We will classify five pieces of merchandise.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_classes`：类别数。对于我们的数据集，这是5。我们将对五个商品进行分类。'
- en: '`mini_batch_size`: The number of training samples that are used for each mini-batch.
    In a single machine multi-GPU setting, each GPU handles `mini_batch_size`/num
    of GPU samples. In the case of distributed training, where multiple machines are
    involved, the actual batch size is the number of `machines` * `mini_batch_size`.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mini_batch_size`：每个小批量使用的训练样本数。在单机多GPU设置中，每个GPU处理`mini_batch_size`/GPU数量的样本。在分布式训练中，当涉及多个机器时，实际批量大小是`machines`
    * `mini_batch_size`。'
- en: '`epochs`: The number of iterations to go through to train the classification
    algorithm.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epochs`：训练分类算法所需的迭代次数。'
- en: '`learning_rate`: This defines how big the steps should be when back-propagating
    to reduce loss. In the case of transfer learning, we will take smaller steps so
    that we can incrementally train the pre-trained network.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learning_rate`：这定义了反向传播时应该采取多大的步长以减少损失。在迁移学习的情况下，我们将采取较小的步长，以便可以逐步训练预训练的网络。'
- en: 'In the following code, we''ve defined the values of each of the hyperparameters:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，我们定义了每个超参数的值：
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'It is now time for training: we will provide the *training parameters* that
    we defined as input to the `create_training_job` method of SageMaker. The SageMaker
    service is invoked using `boto3`, an Amazon Web Services SDK for Python. Once
    the training job has been created, we can check its status.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是训练时间：我们将提供作为输入定义的*训练参数*，并将其传递给SageMaker的`create_training_job`方法。SageMaker服务通过`boto3`调用，`boto3`是一个Amazon
    Web Services的Python SDK。创建训练任务后，我们可以检查其状态。
- en: 'Use the following code to create a training job in SageMaker:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码在SageMaker中创建训练任务：
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We will now plot the results to evaluate the training and validation accuracy
    of ResNet-18\. We want to ensure that we''ve not overfitted the network—a scenario
    where validation accuracy decreases as training accuracy increases. Let''s have
    a look at the following graph:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将绘制结果图来评估ResNet-18的训练和验证准确度。我们希望确保没有过拟合网络——即当训练准确度增加时，验证准确度下降的情况。让我们看一下以下的图表：
- en: '![](img/a248ee06-cc86-4884-8388-0b8fee7d2d96.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a248ee06-cc86-4884-8388-0b8fee7d2d96.png)'
- en: 'The results from training are available in the CloudWatch logs. The preceding
    representation is a visual of how the accuracy of the training and validation
    sets varies during the training period. The following code explains the blue and
    orange lines in the preceding graph:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 训练结果可以在CloudWatch日志中查看。上面的表示是训练期间，训练集和验证集准确度变化的可视化图。以下代码解释了上面图中蓝色和橙色线条的含义：
- en: '[PRE4]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As we can see, the trained ResNet model has picked up enough patterns from the
    fast-food and bakery images. We deployed the trained model for inference.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，训练后的ResNet模型已从快餐和面包店图像中学习到了足够的模式。我们已将训练好的模型部署用于推理。
- en: Performing inference through Batch Transform
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过 Batch Transform 执行推理
- en: In this section, we will classify (in batch mode) a few images that form part
    of the test dataset. Since we want to classify more than one image at a time,
    we will create a Batch Transform job. Please refer to [Chapter 8](16e50aca-401b-47b0-87c3-34cc0346e66e.xhtml),
    *Creating Machine Learning Inference Pipelines*, to learn about when and where
    Batch Transform jobs are used and how they work.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将以批量模式分类一些测试数据集中的图像。由于我们希望一次分类多张图片，因此我们将创建一个 Batch Transform 作业。请参阅[第
    8 章](16e50aca-401b-47b0-87c3-34cc0346e66e.xhtml)，*创建机器学习推理管道*，以了解何时以及如何使用 Batch
    Transform 作业。
- en: Before we create a Batch Transform job, we need to provision the trained model.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建 Batch Transform 作业之前，我们需要配置训练好的模型。
- en: 'In the following code snippet, we are going to do the following:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码片段中，我们将执行以下操作：
- en: We will create a trained model by calling the `create_model()` function of the
    SageMaker service (`boto3`, the AWS SDK for Python, is used to provision a low-level
    interface to the SageMaker service).
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将通过调用 SageMaker 服务的 `create_model()` 函数来创建一个训练好的模型（`boto3`，即 AWS Python SDK，用于配置与
    SageMaker 服务的低级接口）。
- en: 'We will pass a Docker image of the image classification algorithm and the path
    to the trained model to this function:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将把图像分类算法的 Docker 镜像和训练好的模型路径传递给这个函数：
- en: '[PRE5]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now that the trained model has been provisioned, we will need to create a Batch
    Transform job.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在训练好的模型已配置完成，我们需要创建一个 Batch Transform 作业。
- en: 'We will specify the transform input, output, and resources to configure a Batch
    Transform job. The following are the definitions:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将指定转换输入、输出和资源来配置 Batch Transform 作业。以下是定义：
- en: Transform input defines the location and format of images.
  id: totrans-82
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换输入定义了图像的位置和格式。
- en: Transform output defines the location of the results of the inference.
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换输出定义了推理结果的位置。
- en: Transform resources define the number and type of instances to provision.
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换资源定义了要配置的实例数量和类型。
- en: 'In the following code snippet, we call the `create_transform_job`functionof
    the SageMaker service by passing job specifications as part of the `request`JSON
    file:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码片段中，我们通过将作业规格作为 `request` JSON 文件的一部分传递，调用 SageMaker 服务的 `create_transform_job`
    函数：
- en: '[PRE6]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the previous code, we used the `describe_transform_job()` function of the
    SageMaker service to obtain the status of the Batch Transform job. The preceding
    code will return the following message:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在之前的代码中，我们使用了 SageMaker 服务的 `describe_transform_job()` 函数来获取 Batch Transform
    作业的状态。前面的代码将返回以下消息：
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'It is now time to review the results. Let''s navigate to the Batch Transform
    output and test dataset folders on the S3 bucket to review the results. For each
    of the images in the test dataset, we will print their highest classification
    probability, that is, what the trained model classifies an input image as:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是回顾结果的时候了。让我们导航到 S3 存储桶中的 Batch Transform 输出和测试数据集文件夹，以查看结果。对于测试数据集中的每张图片，我们将打印其最高分类概率，也就是训练好的模型将输入图像分类为：
- en: The first image in the test dataset is a Hot Dog, as shown in the following
    screenshot. The trained model identifies the Hot Dog with 92% probability.
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试数据集中的第一张图片是一只热狗，如下图所示。训练好的模型以 92% 的概率识别这只热狗。
- en: 'The following is the result of the prediction, that is, label: `Hot_Dog_1`,
    probability: `0.92`:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是预测结果，即标签：`Hot_Dog_1`，概率：`0.92`：
- en: '![](img/ab14c2e6-4f2d-4fd6-ba9d-8dfcb376585f.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ab14c2e6-4f2d-4fd6-ba9d-8dfcb376585f.png)'
- en: 'The second image is of a Berry Donut, as shown in the following screenshot.
    The trained model identifies the following screenshot as a Berry Donut with 99%
    probability:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二张图片是一只浆果甜甜圈，如下图所示。训练好的模型以 99% 的概率识别这张截图为浆果甜甜圈：
- en: '![](img/990ed830-f963-4d25-9ff5-74c3a3f97108.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/990ed830-f963-4d25-9ff5-74c3a3f97108.png)'
- en: 'The third image is a Muffin, as shown in the following screenshot. The trained
    model identifies the following screenshot as a Muffin with 66% probability:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三张图片是一个松饼，如下图所示。训练好的模型以 66% 的概率将以下截图识别为松饼：
- en: '![](img/e139f0b1-4d1a-4cfd-89b1-05a79efce4a0.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e139f0b1-4d1a-4cfd-89b1-05a79efce4a0.png)'
- en: 'In the case of the fourth image, however, the trained model does not correctly
    identify the image. While the real image is a Peanut Butter Cookie, the model
    misidentifies it as a Muffin. One interesting thing to note here is that the Cookie
    looks like a Muffin:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然而，在第四张图片的情况下，训练好的模型并未正确识别图像。虽然实际图像是花生酱饼干，但模型将其误识别为松饼。这里有一个有趣的地方是，这个饼干看起来像松饼：
- en: '![](img/6cc98739-63fd-4fa4-b439-cb7b9fff3326.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6cc98739-63fd-4fa4-b439-cb7b9fff3326.png)'
- en: As we can see, out of the four images three were classified correctly. To improve
    the accuracy of the model, we can consider hyperparameter tuning and collecting
    large volumes of fast-food and bakery images. Transfer learning, therefore, is
    employed to incrementally train pre-trained image classification models with use-case-specific
    images.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，在四张图像中，有三张被正确分类。为了提高模型的准确性，我们可以考虑调整超参数并收集大量的快餐和烘焙食品图像。因此，迁移学习被用来通过使用特定应用场景的图像来逐步训练预训练的图像分类模型。
- en: Summary
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we've gone through an overview of convolutional neural and
    residual networks. In addition, we've illustrated how SageMaker's image classification
    algorithm can be used to identify fast-food and bakery images. Specifically, we've
    reviewed training an image classification algorithm, including provisioning its
    infrastructure; creating a compressed image format (RecordIO) for training and
    validation datasets; and supplying formatted datasets for model fitting. For inference,
    we've employed the Batch Transform feature of SageMaker to classify multiple images
    in one go.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回顾了卷积神经网络和残差网络的概述。此外，我们还展示了如何使用 SageMaker 的图像分类算法来识别快餐和烘焙食品图像。具体来说，我们回顾了训练图像分类算法的过程，包括为其提供基础设施；创建用于训练和验证数据集的压缩图像格式（RecordIO）；以及提供格式化数据集以进行模型拟合。在推理方面，我们使用了
    SageMaker 的批量转换功能，一次性对多个图像进行分类。
- en: Most importantly, we've learned how to apply transfer learning to image classification.
    This technique becomes very powerful in instances where you do not have large
    amounts of training data.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，我们学会了如何将迁移学习应用于图像分类。这种技术在你没有大量训练数据的情况下尤为强大。
- en: In the next chapter, you'll learn how to forecast retail sales using the DeepAR
    algorithm from SageMaker—another use case where deep learning can be used to solve
    real business challenges.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，你将学习如何使用 SageMaker 的 DeepAR 算法预测零售销售——这是深度学习应用于解决真实商业挑战的另一个案例。
- en: Further reading
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '**MXNet estimator in SageMaker**: [https://medium.com/devseed/use-label-maker-and-amazon-sagemaker-to-automatically-map-buildings-in-vietnam-a63090fb399f](https://medium.com/devseed/use-label-maker-and-amazon-sagemaker-to-automatically-map-buildings-in-vietnam-a63090fb399f)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SageMaker 中的 MXNet 估算器**：[https://medium.com/devseed/use-label-maker-and-amazon-sagemaker-to-automatically-map-buildings-in-vietnam-a63090fb399f](https://medium.com/devseed/use-label-maker-and-amazon-sagemaker-to-automatically-map-buildings-in-vietnam-a63090fb399f)'
- en: '**Vanishing Gradient**: [https://towardsdatascience.com/intuit-and-implement-batch-normalization-c05480333c5b](https://towardsdatascience.com/intuit-and-implement-batch-normalization-c05480333c5b)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**梯度消失**：[https://towardsdatascience.com/intuit-and-implement-batch-normalization-c05480333c5b](https://towardsdatascience.com/intuit-and-implement-batch-normalization-c05480333c5b)'
- en: '**AWS SageMaker Labs**: [https://github.com/awslabs/amazon-sagemaker-examples](https://github.com/awslabs/amazon-sagemaker-examples)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS SageMaker 实验室**：[https://github.com/awslabs/amazon-sagemaker-examples](https://github.com/awslabs/amazon-sagemaker-examples)'
