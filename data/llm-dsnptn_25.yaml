- en: '25'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '25'
- en: Automatic Multi-Step Reasoning and Tool Use
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动多步推理和工具使用
- en: 'Multi-step reasoning and tool use in LLMs involve the model’s ability to break
    down complex tasks into manageable steps and leverage external resources or APIs
    to accomplish these tasks. This capability significantly extends the problem-solving
    potential of LLMs, allowing them to tackle more complex, real-world scenarios.
    Its key characteristics include the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM中的多步推理和工具使用涉及到模型将复杂任务分解为可管理的步骤，并利用外部资源或API来完成这些任务的能力。这种能力显著扩展了LLM的解决问题的潜力，使它们能够处理更复杂、更真实世界的场景。其关键特征包括以下内容：
- en: '**Task decomposition**: This refers to the model’s ability to take a complex
    input or goal and divide it into smaller, more manageable sub-tasks that can be
    solved sequentially or hierarchically. Instead of trying to solve an entire problem
    in one step, the model creates a structured plan or sequence of reasoning steps
    that progressively leads to a solution. This process mimics the way humans often
    approach complex problems by identifying dependencies, sequencing actions, and
    breaking large goals into intermediate objectives. Techniques such as chain-of-thought
    prompting explicitly encourage this behavior by prompting the model to articulate
    each reasoning step before arriving at an answer.'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务分解**：这指的是模型将复杂输入或目标分解成更小、更易于管理的子任务的能力，这些子任务可以按顺序或分层解决。模型不是试图一次性解决整个问题，而是创建一个结构化的计划或推理步骤序列，逐步引导到解决方案。这个过程模仿了人类通常通过识别依赖关系、排序行动和将大目标分解为中间目标来处理复杂问题的方法。诸如思维链提示等技术通过提示模型在得出答案之前明确阐述每个推理步骤，明确鼓励这种行为。'
- en: '**External tools**: The capabilities of LLMs can be enhanced by integrating
    additional resources, such as databases, APIs, or specialized services, that LLMs
    cannot access directly due to limitations in their training environment. These
    tools enable the LLMs to interact with real-time data, perform specific tasks
    beyond their built-in knowledge, or offer enhanced functionalities such as web
    browsing, file handling, or executing external scripts. For example, an LLM can
    use an external tool to query up-to-date weather data, retrieve specific information
    from a live API, or run computations that require specialized algorithms. This
    integration allows LLMs to offer more dynamic, relevant, and specialized responses,
    particularly for applications requiring real-time information or complex multi-step
    processes.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部工具**：通过集成额外的资源，如数据库、API或专用服务，可以增强LLM的能力，这些资源由于训练环境中的限制，LLM无法直接访问。这些工具使LLM能够与实时数据交互，执行超出其内置知识的特定任务，或提供增强功能，如网页浏览、文件处理或执行外部脚本。例如，LLM可以使用外部工具查询最新的天气数据，从实时API检索特定信息，或运行需要专用算法的计算。这种集成使LLM能够提供更动态、相关和专业的响应，特别是对于需要实时信息或复杂多步过程的适用。'
- en: '**Reasoning about tool applicability**: This involves the model’s judgment
    in recognizing when an external capability is required to solve a particular sub-task.
    The model must assess the nature of the sub-task and determine whether internal
    reasoning suffices or whether delegating part of the task to a tool would yield
    better or even necessary results.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关于工具适用性的推理**：这涉及到模型在识别何时需要外部能力来解决特定子任务时的判断。模型必须评估子任务的性质，并确定内部推理是否足够，或者将部分任务委托给工具是否会产生更好甚至必要的成果。'
- en: '**Tool selection and invocation**: This refers to the model’s ability to identify
    which tool is appropriate for a given sub-task and to formulate the correct input
    to trigger its use. This requires the model to understand the functionality and
    input requirements of each available tool and to match these against the demands
    of the current step in the reasoning process. For example, if the task requires
    accessing up-to-date weather information, the model must choose a weather API
    and generate a syntactically correct and semantically relevant query to that API.
    This phase includes formatting inputs, calling the tool, and ensuring that the
    request aligns with both the current problem context and the tool’s capabilities.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工具选择和调用**：这指的是模型识别适用于给定子任务的工具并制定正确输入以触发其使用的能力。这要求模型理解每个可用工具的功能和输入要求，并将这些与推理过程中当前步骤的需求相匹配。例如，如果任务需要访问最新的天气信息，模型必须选择天气API并生成一个对该API语法正确且语义相关的查询。此阶段包括格式化输入、调用工具并确保请求与当前问题上下文和工具的功能相一致。'
- en: '**Integration of tool outputs**: This describes the model’s capability to interpret
    the results returned by the external tool and incorporate them into the ongoing
    reasoning process. After a tool is invoked and responds with data—such as a numerical
    value, a structured object, or a text snippet—the model must parse the result,
    extract relevant elements, and update its understanding or intermediate outputs
    accordingly. This step often involves interpreting heterogeneous output formats,
    managing type mismatches, and maintaining continuity in the reasoning chain. Effective
    integration ensures that tool use is not isolated but meaningfully contributes
    to solving the broader task.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工具输出集成**：这描述了模型解释外部工具返回的结果并将其纳入持续推理过程的能力。在工具被调用并响应数据（如数值、结构化对象或文本片段）后，模型必须解析结果、提取相关元素并相应地更新其理解或中间输出。此步骤通常涉及解释异构输出格式、管理类型不匹配并在推理链中保持连续性。有效的集成确保工具使用不是孤立的，而是有意义地贡献于解决更广泛的任务。'
- en: '**Iterative problem solving**: This refers to the model’s recursive application
    of the previous stages—decomposition, tool reasoning, selection, invocation, and
    integration—in a loop until the task is resolved or further steps become unproductive.
    The model continuously reassesses its progress, determines whether additional
    sub-tasks remain, and decides whether further tool use is necessary. This iterative
    behavior enables the model to handle tasks with dynamic structure, uncertainty,
    or errors from prior steps by adjusting the plan or refining previous actions.
    In agent-based architectures, this process may be explicitly managed by a planner
    or controller, while in prompt-based settings, it often emerges through recursive
    self-queries and prompt augmentation.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代问题解决**：这指的是模型递归地应用先前阶段——分解、工具推理、选择、调用和集成——在一个循环中，直到任务解决或进一步步骤变得无效。模型持续评估其进度，确定是否还有剩余的子任务，并决定是否需要进一步使用工具。这种迭代行为使模型能够通过调整计划或细化先前行动来处理具有动态结构、不确定性或先前步骤中的错误的任务。在基于代理的架构中，此过程可能由规划器或控制器显式管理，而在基于提示的设置中，它通常通过递归自我查询和提示增强而出现。'
- en: In this chapter, we’ll delve into advanced techniques for enabling LLMs to perform
    complex multi-step reasoning and utilize external tools.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨使LLM能够执行复杂多步推理并利用外部工具的高级技术。
- en: 'In this chapter, we’ll be covering the following topics:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Designing prompts for complex task decomposition
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计用于复杂任务分解的提示
- en: Integrating external tools
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成外部工具
- en: Implementing automatic tool selection and use
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现自动工具选择和使用
- en: Complex problem solving
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂问题解决
- en: Evaluating multi-step reasoning and tool use
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估多步推理和工具使用
- en: Challenges and future directions
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 挑战和未来方向
- en: Designing prompts for complex task decomposition
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计用于复杂任务分解的提示
- en: 'To enable effective multi-step reasoning, prompts should guide the LLM to break
    down complex tasks into smaller, manageable steps. Here’s an example of a task
    decomposition prompt:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现有效的多步推理，提示应引导LLM将复杂任务分解成更小、更易管理的步骤。以下是一个任务分解提示的示例：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This function generates a prompt that guides the LLM to decompose a complex
    task into steps, considering the available tools.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 此功能生成一个提示，引导LLM将复杂任务分解成步骤，考虑可用的工具。
- en: Integrating external tools
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集成外部工具
- en: 'To enable LLMs to use external tools such as search, calculations, API calls,
    and so on, we need to create an interface between the model and the tools. Here’s
    a simple implementation:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使LLMs能够使用外部工具，如搜索、计算、API调用等，我们需要在模型和工具之间创建一个接口。以下是一个简单的实现：
- en: 'Perform the necessary imports and define the `ToolKit` class:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行必要的导入并定义`ToolKit`类：
- en: '[PRE1]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The preceding code defines a `ToolKit` class that organizes and offers access
    to different functionalities through its methods. In the `__init__` method, a
    dictionary named `tools` is initialized with keys representing tool names such
    as `"Twitter API"`, `"Sentiment Analysis"`, and `"Data Visualization"`, and values
    that reference the corresponding methods for fetching tweets, performing sentiment
    analysis using the TextBlob library, and creating data visualizations using Matplotlib.
    The `requests` library is imported for making HTTP requests, while `TextBlob`
    is used for natural language processing tasks such as sentiment analysis, and
    `matplotlib.pyplot` is imported for generating visualizations. The code sets up
    the structure for these tools but is incomplete as the `fetch_tweets`, `analyze_sentiment`,
    and `create_visualization` methods are not defined, leaving room for further implementation
    of these functionalities.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码定义了一个`ToolKit`类，通过其方法组织和提供对不同功能的访问。在`__init__`方法中，名为`tools`的字典被初始化，其键代表工具名称，如`"Twitter
    API"`、`"Sentiment Analysis"`和`"Data Visualization"`，值引用获取推文、使用TextBlob库执行情感分析和使用Matplotlib创建数据可视化的相应方法。导入`requests`库用于发送HTTP请求，`TextBlob`用于自然语言处理任务，如情感分析，`matplotlib.pyplot`用于生成可视化。代码为这些工具设置了结构，但代码不完整，因为`fetch_tweets`、`analyze_sentiment`和`create_visualization`方法尚未定义，为这些功能的进一步实现留出了空间。
- en: 'Define three methods: `fetch_tweets` for generating mock tweets based on a
    query, `analyze_sentiment` for computing sentiment polarity scores for a list
    of texts using TextBlob, and `create_visualization` for creating and saving a
    histogram of the sentiment data with a specified title:'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义三个方法：`fetch_tweets`用于根据查询生成模拟推文，`analyze_sentiment`用于使用TextBlob计算文本列表的情感极性分数，以及`create_visualization`用于创建并保存具有指定标题的情感数据直方图：
- en: '[PRE2]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Define the `use_tool` method to execute a specified tool with given arguments
    if it exists in the tools dictionary; otherwise, return an error message:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义`use_tool`方法，如果工具字典中存在指定的工具，则使用给定的参数执行该工具；否则，返回错误信息：
- en: '[PRE3]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following example demonstrates using a `ToolKit` class to fetch tweets
    about a product launch, analyze their sentiments, create a sentiment visualization,
    and print the path to the generated visualization file:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下示例演示了使用`ToolKit`类获取有关产品发布的推文，分析其情感，创建情感可视化，并打印生成的可视化文件路径：
- en: '[PRE4]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This `ToolKit` class provides an interface for the LLM to interact with external
    tools, simulating API calls and data processing tasks.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`ToolKit`类为LLM提供了一个与外部工具交互的接口，模拟API调用和数据处理任务。
- en: Implementing automatic tool selection and use
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现自动工具选择和使用
- en: 'To enable LLMs to automatically select and use tools, we can create a system
    that interprets the model’s output and executes the appropriate tools. Here’s
    an example:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使大型语言模型（LLMs）能够自动选择和使用工具，我们可以创建一个系统来解释模型的输出并执行相应的工具。以下是一个示例：
- en: 'First, we define a function, `auto_tool_use`, that uses a pre-trained language
    model and tokenizer from Hugging Face’s Transformers library to decompose a task
    into executable steps using a prompt, parses the decomposition into steps, executes
    tools as needed using a toolkit, and collects the results:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们定义一个函数`auto_tool_use`，该函数使用来自Hugging Face的Transformers库的预训练语言模型和分词器，通过提示将任务分解为可执行步骤，将分解步骤解析为步骤，使用工具包按需执行工具，并收集结果：
- en: '[PRE5]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then we generate a final report. The generated report contains the task description,
    a breakdown of each step along with its result, and a concluding summary. The
    model uses the provided steps and results to generate a more cohesive and comprehensive
    narrative of the task:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们生成最终报告。生成的报告包含任务描述，每个步骤的分解及其结果，以及总结。模型使用提供的步骤和结果来生成更连贯和全面的任务叙述：
- en: '[PRE6]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, we implement logic to parse the decomposition into structured steps.
    This is a simplified placeholder implementation:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们实现逻辑来将分解步骤结构化。这是一个简化的占位符实现：
- en: '[PRE7]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following example usage demonstrates loading a language model and tokenizer
    using `AutoModelForCausalLM` and `AutoTokenizer`, defining a task to analyze tweet
    sentiments and generate a summary report with visualizations, and using an `auto_tool_use`
    function to automate the task via `ToolKit`, with the final report being printed:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下示例用法演示了使用 `AutoModelForCausalLM` 和 `AutoTokenizer` 加载语言模型和分词器，定义一个分析推文情感并生成带有可视化总结报告的任务，以及使用
    `auto_tool_use` 函数通过 `ToolKit` 自动化任务，最终报告将被打印出来：
- en: '[PRE8]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This code snippet shows at a high level how to enable the LLM to automatically
    decompose tasks, select appropriate tools, and generate a final report based on
    the results.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段从高层次展示了如何使大型语言模型（LLM）自动分解任务、选择合适的工具，并根据结果生成最终报告。
- en: The first three sections of this chapter laid the groundwork by covering prompt
    design, integrating external tools, and implementing automatic tool selection
    to enhance AI functionality. In the following section, we will explore how to
    design prompts for complex problem solving.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的前三部分通过涵盖提示设计、集成外部工具和实现自动工具选择来增强人工智能功能，奠定了基础。在接下来的部分，我们将探讨如何设计用于复杂问题解决的提示。
- en: Complex problem solving
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 复杂问题解决
- en: 'Multi-step reasoning and tool use can be applied to various complex problem-solving
    scenarios. Here’s an example of how to use this approach for market analysis:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 多步推理和工具使用可以应用于各种复杂问题解决场景。以下是如何使用这种方法进行市场分析的示例：
- en: '[PRE9]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `market_analysis` function automates the generation of a market research
    report for a given product by constructing a structured task prompt and passing
    it to an external utility, `auto_tool_use`, which is assumed to orchestrate tool-augmented
    responses from a language model. The prompt requests a multi-part analysis—covering
    competitors, sentiment analysis of customer feedback, and visualization of market
    trends—targeted to the specific `product_name` supplied. This design leverages
    the model and toolkit to produce a consolidated report without manual intervention,
    enabling a consistent and repeatable approach to product market research through
    prompt-driven execution.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '`market_analysis` 函数通过构建结构化任务提示并将其传递给外部实用工具 `auto_tool_use`（假设它协调语言模型从工具增强的响应），自动化给定产品的市场研究报告的生成。提示要求进行多部分分析——涵盖竞争对手、客户反馈的情感分析以及市场趋势的可视化——针对提供的特定
    `product_name`。这种设计利用模型和工具包生成综合报告，无需人工干预，通过提示驱动的执行实现产品市场研究的一致性和可重复性方法。'
- en: Evaluating multi-step reasoning and tool use
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估多步推理和工具使用
- en: 'To assess the effectiveness of multi-step reasoning and tool use, we need to
    evaluate both the process and the outcome. Here’s a simple evaluation framework:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估多步推理和工具使用的有效性，我们需要评估过程和结果。以下是一个简单的评估框架：
- en: '[PRE10]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This evaluation framework assesses both the quality of the generated report
    and the effectiveness of tool use in the process.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此评估框架评估了生成的报告的质量以及工具使用过程中的有效性。
- en: Challenges and future directions
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 挑战和未来方向
- en: 'While powerful, multi-step reasoning and tool use in LLMs face several challenges:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管功能强大，LLM中的多步推理和工具使用面临几个挑战：
- en: '**Tool selection accuracy**: Ensure LLMs choose the most appropriate tools
    for each task'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**工具选择准确性**：确保LLM为每个任务选择最合适的工具'
- en: '**Error propagation**: Mitigate the impact of errors in the early steps of
    the reasoning process; keep in mind that error propagation across multiple steps
    can be a major risk in complex tool chains if not mitigated early'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**错误传播**：减轻推理过程早期步骤中错误的影响；记住，如果不在早期减轻，错误在多个步骤中的传播可能会在复杂的工具链中成为主要风险'
- en: '**Scalability**: Manage the complexity of integrating a large number of diverse
    tools'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性**：管理集成大量不同工具的复杂性'
- en: '**Adaptability**: Enable LLMs to work with new, unseen tools without retraining'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**适应性**：使LLM能够在不重新训练的情况下与新的、未见过的工具一起工作'
- en: 'To address some of these challenges, consider implementing a self-correction
    mechanism:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些挑战，可以考虑实现一个自我纠正机制：
- en: '[PRE11]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Self-correcting in this context refers to a method where a language model iteratively
    refines its output by evaluating and improving its own previous responses without
    external feedback. In the `self_correcting_tooluse` function, this is implemented
    by first generating a report using `auto_tool_use` and then prompting the model
    to assess the quality of that report. If the model’s self-evaluation does not
    include indicators of adequacy—such as “satisfactory” and “no major issues”—the
    evaluation is appended to the task description, effectively guiding the next iteration
    to address identified shortcomings. This loop continues for a set number of attempts
    (`max_attempts`) until the output meets the model’s own acceptance criteria, allowing
    self-guided refinement across multiple passes.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个语境中，自我纠正指的是一种语言模型通过评估和改进其先前响应（而不需要外部反馈）来迭代地细化其输出的方法。在`self_correcting_tooluse`函数中，这是通过首先使用`auto_tool_use`生成报告，然后提示模型评估该报告的质量来实现的。如果模型的自评估不包括充分性的指标——例如“满意”和“没有重大问题”——则评估将附加到任务描述中，有效地指导下一次迭代解决已识别的不足。这个循环会持续一定次数的尝试（`max_attempts`），直到输出满足模型自己的接受标准，允许在多次迭代中进行自我引导的细化。
- en: 'We can identify the following three promising research areas for overcoming
    the challenges from some research conducted by AI/ML communities:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以确定以下三个有希望的研究领域，以克服来自AI/ML社区一些研究带来的挑战：
- en: '**Enhanced tool learning and discovery**: Future LLMs will be able to dynamically
    learn about and integrate new tools without explicit programming. This involves
    mechanisms for understanding tool documentation and API specifications and even
    experimenting with tools to infer their functionality. This will allow LLMs to
    adapt to a constantly evolving landscape of software and services, expanding their
    capabilities beyond a fixed set of pre-defined tools. This will involve techniques
    such as meta-learning, reinforcement learning from tool interactions, and semantic
    understanding of tool descriptions ([https://arxiv.org/abs/2305.17126](https://arxiv.org/abs/2305.17126)).'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强的工具学习和发现**：未来的LLMs将能够动态地了解和整合新工具，而无需显式编程。这涉及到理解工具文档和API规范以及通过实验工具来推断其功能性的机制。这将使LLMs能够适应不断演变的软件和服务景观，扩展其功能，而不仅仅是预定义的工具集。这将涉及元学习、从工具交互中进行强化学习以及工具描述的语义理解技术（[https://arxiv.org/abs/2305.17126](https://arxiv.org/abs/2305.17126)）。'
- en: '**Robust and adaptive reasoning with uncertainty**: Future LLMs will incorporate
    probabilistic models to handle uncertainty in multi-step tasks. This means assigning
    probabilities to different reasoning paths, outcomes, and tool effectiveness.
    Bayesian methods, Monte Carlo simulations, and other probabilistic techniques
    will be integrated into the reasoning process. This will enable LLMs to make more
    robust decisions in complex scenarios with incomplete or noisy information and
    to better manage the inherent uncertainty of real-world problems. LLMs will be
    better equipped to handle unexpected situations, recover from errors, and provide
    more reliable solutions when faced with ambiguity ([https://arxiv.org/abs/2310.04406](https://arxiv.org/abs/2310.04406)).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**具有不确定性的鲁棒和自适应推理**：未来的大型语言模型（LLMs）将整合概率模型来处理多步任务中的不确定性。这意味着为不同的推理路径、结果和工具有效性分配概率。贝叶斯方法、蒙特卡洛模拟和其他概率技术将被整合到推理过程中。这将使LLMs能够在信息不完整或噪声复杂场景中做出更鲁棒的决定，并更好地管理现实世界问题的固有不确定性。LLMs将更好地应对意外情况，从错误中恢复，并在面对模糊性时提供更可靠的解决方案（[https://arxiv.org/abs/2310.04406](https://arxiv.org/abs/2310.04406)）。'
- en: '**Human-in-the-loop multi-step reasoning with explainability**: Future systems
    will involve closer collaboration between humans and LLMs in multi-step problem
    solving. This means creating interfaces that allow humans to understand the LLM’s
    reasoning process, provide guidance, correct errors, and work together on complex
    tasks. Explainability will be key, with LLMs able to articulate their reasoning
    steps, justify tool choices, and present alternative solution paths. This will
    foster trust and allow for more effective human-AI collaboration, especially in
    critical domains such as healthcare, finance, and scientific research. This could
    involve visualizations of reasoning graphs, natural language explanations, and
    interactive debugging tools: [https://www.microsoft.com/en-us/research/blog/guidance-for-developing-with-large-language-models-llms/](https://www.microsoft.com/en-us/research/blog/guidance-for-developing-with-large-language-models-llms/).'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**具有可解释性的闭环多步推理**：未来的系统将在多步问题解决中涉及人类与大型语言模型（LLM）之间更紧密的合作。这意味着创建允许人类理解LLM推理过程、提供指导、纠正错误并在复杂任务上共同工作的界面。可解释性将是关键，LLM能够阐述其推理步骤、证明工具选择并展示替代解决方案路径。这将促进信任并允许更有效的人类-人工智能合作，特别是在医疗保健、金融和科学研究等关键领域。这可能包括推理图的可视化、自然语言解释和交互式调试工具：[https://www.microsoft.com/en-us/research/blog/guidance-for-developing-with-large-language-models-llms/](https://www.microsoft.com/en-us/research/blog/guidance-for-developing-with-large-language-models-llms/).'
- en: Summary
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Automatic multi-step reasoning and tool use significantly expand the problem-solving
    capabilities of LLMs, enabling them to tackle complex, real-world tasks.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 自动多步推理和工具使用显著扩展了LLM的解决问题能力，使它们能够处理复杂、现实世界的任务。
- en: In this chapter, you learned how to design prompts for complex task decomposition
    and implement systems that allow LLMs to interact with external tools and APIs.
    We looked at strategies for automatic tool selection and use and explored applications
    in complex problem-solving scenarios. You also learned how to evaluate the effectiveness
    of multi-step reasoning and tool use in LLMs. By implementing the techniques and
    considerations discussed in this chapter, you can create sophisticated AI systems
    that can decompose problems, leverage external tools, and generate comprehensive
    solutions to multi-faceted challenges.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何设计用于复杂任务分解的提示，并实现允许LLM与外部工具和API交互的系统。我们探讨了自动工具选择和使用的策略，并探讨了在复杂问题解决场景中的应用。你还学习了如何评估LLM中多步推理和工具使用的有效性。通过实施本章讨论的技术和考虑因素，你可以创建复杂的AI系统，这些系统能够分解问题、利用外部工具并针对多方面挑战生成全面的解决方案。
- en: As we move forward, the next part of the book will focus on retrieval and knowledge
    integration. This will build upon the tool use capabilities we’ve discussed here,
    exploring how LLMs can be enhanced with external knowledge, improving their ability
    to access and utilize information effectively.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续前进，本书的下一部分将专注于检索和知识集成。这将建立在我们在本部分讨论的工具使用能力之上，探讨LLM如何通过外部知识得到增强，提高其有效获取和利用信息的能力。
- en: 'Part 5: Retrieval and Knowledge Integration in Large Language Models'
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5部分：大型语言模型中的检索和知识集成
- en: We conclude this book by examining techniques that enhance LLMs with external
    knowledge through retrieval-augmented generation (RAG) methods. You will learn
    how to design retrieval systems that efficiently access relevant information,
    integrate structured knowledge into model outputs, and leverage graph-based retrieval
    to enrich responses with contextual relationships. Advanced RAG patterns, such
    as iterative and adaptive retrieval, will be explored, helping you create models
    capable of dynamic knowledge integration. We also discuss evaluation methodologies
    to measure retrieval quality and effectiveness. The final chapter introduces agentic
    patterns, enabling you to build autonomous systems that combine reasoning, planning,
    and decision-making. By mastering these techniques, you will be able to create
    LLMs that are not only informed but also capable of goal-directed behavior.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过考察通过检索增强生成（RAG）方法增强LLMs的外部知识的技术来结束本书。你将学习如何设计检索系统，以高效地访问相关信息，将结构化知识集成到模型输出中，并利用基于图的检索来丰富响应中的上下文关系。我们将探讨高级RAG模式，如迭代和自适应检索，帮助你创建能够动态集成知识的模型。我们还讨论了评估方法，以衡量检索质量和有效性。最后一章介绍了代理模式，使你能够构建结合推理、规划和决策的自主系统。通过掌握这些技术，你将能够创建不仅信息丰富，而且能够实现目标导向行为的LLMs。
- en: 'This part has the following chapters:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 26*](B31249_26.xhtml#_idTextAnchor366), *Retrieval-Augmented Generation*'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第26章*](B31249_26.xhtml#_idTextAnchor366)，*检索增强生成*'
- en: '[*Chapter 27*](B31249_27.xhtml#_idTextAnchor378), *Graph-Based RAG*'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第27章*](B31249_27.xhtml#_idTextAnchor378)，*基于图的RAG*'
- en: '[*Chapter 28*](B31249_28.xhtml#_idTextAnchor389), *Advanced RAG*'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第28章*](B31249_28.xhtml#_idTextAnchor389)，*高级RAG*'
- en: '[*Chapter 29*](B31249_29.xhtml#_idTextAnchor400), *Evaluating RAG Systems*'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第29章*](B31249_29.xhtml#_idTextAnchor400)，*评估RAG系统*'
- en: '[*Chapter 30*](B31249_30.xhtml#_idTextAnchor469), *Agentic Patterns*'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第30章*](B31249_30.xhtml#_idTextAnchor469)，*代理模式*'
