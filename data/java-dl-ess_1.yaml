- en: Chapter 1. Deep Learning Overview
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 深度学习概述
- en: '**Artificial Intelligence** (**AI**) is a word that you might start to see
    more often these days. AI has become a hot topic not only in academic society,
    but also in the field of business. Large tech companies such as Google and Facebook
    have actively bought AI-related start-ups. Mergers and acquisitions in these AI
    areas have been especially active, with big money flowing into AI. The Japanese
    IT/mobile carrier company Softbank released a robot called Pepper in June 2014,
    which understands human feelings, and a year later they have started to sell Pepper
    to general consumers. This is a good movement for the field of AI, without a doubt.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**人工智能**（**AI**）是您可能最近越来越频繁看到的一个词汇。AI不仅在学术界成为热门话题，也在商业领域引起了广泛关注。像谷歌和脸书这样的科技巨头已经积极收购与AI相关的初创公司。在这些AI领域的并购活动尤其活跃，大量资金涌入AI行业。2014年6月，日本的IT/移动运营商软银公司发布了一款名为Pepper的机器人，它能够理解人类的情感，且在一年后开始将Pepper出售给普通消费者。毫无疑问，这是人工智能领域的一个积极发展。'
- en: The idea of AI has been with us for decades. So, why has AI suddenly became
    a hot field? One of the factors that has driven recent AI-related movements, and
    is almost always used with the word AI, is **deep learning**. After deep learning
    made a vivid debut and its technological capabilities began to grow exponentially,
    people started to think that finally AI would become a reality. It sounds like
    deep learning is definitely something we need to know. So, what exactly is it?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的概念已存在数十年。那么，为什么人工智能突然成为热门领域呢？推动近期AI相关变革的因素之一，几乎总是与**深度学习**一词一起使用。随着深度学习的精彩登场及其技术能力的指数级增长，人们开始认为人工智能最终将成为现实。看起来深度学习无疑是我们需要掌握的内容。那么，究竟什么是深度学习呢？
- en: 'To answer the previous questions, in this chapter we''ll look at why and how
    AI has become popular by following its history and fields of studies. The topics
    covered will be:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答前面的问题，本章将通过回顾人工智能的历史和研究领域，探讨为什么以及如何人工智能（AI）变得如此流行。我们将涉及的主题包括：
- en: The former approaches and techniques of AI
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人工智能的早期方法与技术
- en: An introduction to machine learning and a look at how it has evolved into deep
    learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习简介及其如何演变为深度学习
- en: An introduction to deep learning and some recent use cases
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习简介及其一些最新应用案例
- en: If you already know what deep learning is or if you would like to find out about
    the specific algorithm of the deep learning/implementation technique, you can
    skip this chapter and jump directly to [Chapter 2](ch02.html "Chapter 2. Algorithms
    for Machine Learning – Preparing for Deep Learning"), *Algorithms for Machine
    Learning – Preparing for Deep Learning*.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经了解深度学习的基本概念，或者希望了解深度学习的具体算法和实现技术，您可以跳过本章，直接阅读[第2章](ch02.html "第2章 机器学习算法——为深度学习做准备")，*机器学习算法——为深度学习做准备*。
- en: Although deep learning is an innovative technique, it is not actually that complicated.
    It is rather surprisingly simple. Reading through this book, you will see how
    brilliant it is. I sincerely hope that this book will contribute to your understanding
    of deep learning and thus to your research and business.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度学习是一项创新技术，但它实际上并不复杂，反而出奇地简单。通过阅读本书，您将看到它的非凡之处。我真诚地希望本书能帮助您更好地理解深度学习，从而促进您的研究和商业发展。
- en: Transition of AI
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能的变迁
- en: So, why is it now that deep learning is in the spotlight? You might raise this
    question, especially if you are familiar with machine learning, because deep learning
    is not that different to any other machine learning algorithm (don't worry if
    you don't know this, as we'll go through it later in the book). In fact, we can
    say that deep learning is the adaptation of neural networks, one of the algorithms
    of machine learning, which mimics the structure of a human brain. However, what
    deep learning can achieve is much more significant and different to any other
    machine learning algorithm, including neural networks. If you see what processes
    and research deep learning has gone through, you will have a better understanding
    of deep learning itself. So, let's go through the transition of AI. You can just
    skim through this while sipping your coffee.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么现在深度学习会成为焦点呢？你可能会问这个问题，尤其是如果你熟悉机器学习，因为深度学习与其他机器学习算法并没有太大不同（如果你不熟悉这一点也没关系，因为我们会在本书后面讲解）。事实上，我们可以说深度学习是神经网络（机器学习的一种算法）的改进，模仿人类大脑的结构。然而，深度学习能够实现的东西，比任何其他机器学习算法，包括神经网络，都要更为显著和不同。如果你了解深度学习所经历的过程和研究，你会更好地理解深度学习本身。因此，让我们来看看AI的发展历程。你可以一边喝着咖啡一边浏览这些内容。
- en: Definition of AI
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI的定义
- en: All of a sudden, AI has become a hot topic in the world; however, as it turns
    out, actual AI doesn't exist yet. Of course, research is making progress in creating
    actual AI, but it will take more time to achieve it. Pleased or not, the human
    brain—which could be called "intelligence"—is structured in an extremely complicated
    way and you can't easily replicate it.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 突然间，AI成为了全球的热门话题；然而，事实证明，真正的AI还并不存在。当然，研究正在推进以实现真正的AI，但这还需要更多的时间才能实现。不管你是否高兴，人类的大脑——可以称之为“智慧”——是极为复杂的结构，你无法轻易复制它。
- en: But wait a moment - we see many advertisements for products with the phrase
    *by AI* or *using AI* all over them. Are they fraudulent? Actually, they are!
    Surprised? You might see words like *recommendation system by AI* or *products
    driven by AI*, but the word *AI* used here doesn't indicate the actual meaning
    of AI. Strictly speaking, the word AI is used with a much broader meaning. The
    research into AI and the AI techniques accumulated in the past have achieved only
    some parts of AI, but now people are using the word AI for those parts too.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 等等——我们看到很多广告中都带有*由AI驱动*或*使用AI*的字眼。这些是骗人的广告吗？实际上，它们确实是！惊讶吗？你可能会看到像*由AI推荐系统*或*由AI驱动的产品*这样的词语，但这里使用的*AI*并没有表达出AI的实际含义。严格来说，AI这个词被用在一个更广泛的意义上。过去对AI的研究以及积累的AI技术只实现了AI的一部分，但如今人们也开始用这个词来描述这些部分。
- en: 'Let''s look at a few examples. Roughly divided, there are three different categories
    recognized as AI in general:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看看几个例子。大致上，有三个被广泛认定为AI的不同类别：
- en: Simple repetitive machine movements that a human programmed beforehand. For
    example, high speed processing industrial robots that only process the same set
    of work.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的重复性机械动作，是人类事先编程的。例如，那些只处理相同一组工作的高速工业机器人。
- en: Searching or guessing answers to a given assignment following rules set by a
    human. For example, the iRobot Roomba can clean up along the shape of a room as
    it can assume the shape of a room by bumping into obstacles.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据人类设定的规则搜索或猜测给定任务的答案。例如，iRobot Roomba能够根据碰撞障碍物来推测房间的形状，并沿着房间的形状进行清扫。
- en: Providing an answer to unknown data by finding measurable regularity from the
    existing data. For example, a product recommendation system based on a user's
    purchase history or distributing banner ads among ad networks falls under this
    category.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过从现有数据中找出可量化的规律，提供未知数据的答案。例如，基于用户购买历史的产品推荐系统，或是在广告网络中分发横幅广告，都属于这一类别。
- en: People use the word AI for these categories and, needless to say, new technology
    that utilizes deep learning is also called AI. Yet, these technologies are different
    both in structure and in what they can do. So, which should we specifically call
    AI? Unfortunately, people have different opinions about that question and the
    answer cannot be objectively explained. Academically, a term has been set as either
    **strong AI** or **weak AI** depending on the level that a machine can achieve.
    However, in this book, to avoid confusion, AI is used to mean (*Not yet achieved)
    human-like intelligence that is hard to distinguish from the actual human brain*.
    The field of AI is being drastically developed, and the possibility of AI becoming
    reality is exponentially higher when driven by deep learning. This field is booming
    now more than ever in history. How long this boom will continue depends on future
    research.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 人们使用AI这个词来指代这些范畴，毫无疑问，利用深度学习的新技术也被称为AI。然而，这些技术在结构和功能上存在差异。那么，究竟哪种技术才应该被具体称为AI呢？不幸的是，大家对这个问题的看法不同，答案无法客观地解释。从学术角度来看，已经有一个术语被设定为**强AI**或**弱AI**，具体取决于机器能够达到的水平。然而，在本书中，为了避免混淆，AI被用来指代（*尚未实现的*）与实际人脑难以区分的人类智能。AI领域正在飞速发展，深度学习驱动下，AI成为现实的可能性呈指数增长。这个领域现在比历史上任何时候都更加蓬勃发展。这个繁荣会持续多久，取决于未来的研究。
- en: AI booms in the past
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI在过去曾经历过繁荣。
- en: 'AI suddenly became a hot topic recently: however, this is not the first AI
    boom. When you look back to the past, research into AI has been conducted for
    decades and there has been a cycle of being active and inactive. The recent boom
    is the third boom. Therefore, some people actually think that, at this time, it''s
    just an evanescent boom again.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，AI突然成为了热门话题，但这并不是第一次AI的繁荣。回顾过去，AI研究已经进行了几十年，并且有过活跃和不活跃的周期。最近的繁荣是第三次繁荣。因此，一些人认为，这次不过是又一次短暂的繁荣而已。
- en: However, the latest boom has a significant difference from the past booms. Yes,
    that is deep learning. Deep learning has achieved what the past techniques could
    not achieve. What is that? Simply put, a machine itself is able to find out the
    feature quantity from the given data, and learn. With this achievement, we can
    see the great possibility of AI becoming a reality, because until now a machine
    couldn't understand a new concept by itself and a human needed to input a certain
    feature quantity in advance using past techniques created in the AI field.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，最新的繁荣与过去的繁荣有着显著的不同。没错，那就是深度学习。深度学习实现了过去技术无法达成的成就。那是什么呢？简而言之，机器能够从给定的数据中自动提取特征量并进行学习。有了这一成就，我们可以看到AI成为现实的巨大可能性，因为直到现在，机器无法自行理解新的概念，而人类需要提前输入某些特征量，这些特征量是基于AI领域中创建的过去技术。
- en: It doesn't look like a huge difference if you just read this fact, but there's
    a world of difference. There has been a long path taken before reaching the stage
    where a machine can measure feature quantity by itself. People were finally able
    to take a big step forward when a machine could obtain intelligence driven by
    deep learning. So, what's the big difference between the past techniques and deep
    learning? Let's briefly look back into the past AI field to get a better sense
    of the difference.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果仅仅阅读这个事实，看起来似乎没有太大差别，但其中差距巨大。要到达机器能够自我测量特征量的阶段，经历了漫长的过程。当机器能够通过深度学习获得智能时，人们终于迈出了巨大的步伐。那么，过去的技术和深度学习之间的巨大差异是什么呢？让我们简要回顾一下过去的AI领域，以更好地理解这个差异。
- en: The first AI boom came in the late 1950s. Back then, the mainstream research
    and development of a search program was based on fixed rules—needless to say,
    they were human-defined. The search was, simply put, dividing cases. In this search,
    if we wanted a machine to perform any process, we had to write out every possible
    pattern we might need for the process. A machine can calculate much faster than
    a human can. It doesn't matter how enormous the patterns are, a machine can easily
    handle them. A machine will keep searching a million times and eventually will
    find the best answer. However, even if a machine can calculate at high speed,
    if it is just searching for an answer randomly and blindly it will take a massive
    amount of time. Yes, don't forget that constraint condition, "time." Therefore,
    further studies were conducted on how to make the search more efficient. The most
    popular search methods among the studies were **depth-first search** (**DFS**)
    and **breadth-first search** (**BFS**).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次人工智能的热潮出现在1950年代末。当时，主流的搜索程序研发是基于固定规则——不用说，这些规则是由人类定义的。简单来说，搜索就是分割案例。在这种搜索中，如果我们希望机器执行某个过程，我们必须列出可能需要的每一种模式。机器的计算速度远远快于人类。无论模式有多庞大，机器都能够轻松处理。机器会不断地搜索一百万次，最终会找到最佳答案。然而，即便机器计算速度极快，如果只是盲目地随机搜索答案，仍然需要消耗大量的时间。是的，不要忘记那个限制条件，“时间”。因此，后续的研究聚焦于如何提高搜索效率。在这些研究中，最流行的搜索方法是**深度优先搜索**（**DFS**）和**广度优先搜索**（**BFS**）。
- en: 'Out of every possible pattern you can think of, search for the most efficient
    path and make the best possible choice among them within a realistic time frame.
    By doing this, you should get the best answer each time. Based on this hypothesis,
    two searching or traversing algorithms for a tree of graph data structures were
    developed: DFS and BFS. Both start at the root of a graph or tree, and DFS explores
    as far as possible along each branch before backtracking, whereas BFS explores
    the neighbor nodes first before moving to the next level neighbors. Here are some
    example diagrams that show the difference between DFS and BFS:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在你能想到的每一种可能模式中，寻找最有效的路径，并在现实的时间限制内做出最佳选择。通过这种方式，你应该能够每次都得到最佳答案。基于这个假设，开发了两种用于树形图数据结构的搜索或遍历算法：DFS和BFS。两者都从图或树的根节点开始，DFS会沿每个分支尽可能深入，直到回溯，而BFS则首先探索邻居节点，然后再移动到下一层的邻居节点。以下是展示DFS和BFS差异的示例图：
- en: '![AI booms in the past](img/B04779_01_01.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![过去的人工智能热潮](img/B04779_01_01.jpg)'
- en: These search algorithms could achieve certain results in a specific field, especially
    fields like Chess and Shogi. This board game field is one of the areas that a
    machine excels in. If it is given an input of massive amounts of win/lose patterns,
    past game data, and all the permitted moves of a piece in advance, a machine can
    evaluate the board position and decide the best possible next move from a very
    large range of patterns.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这些搜索算法在特定领域中能够实现某些结果，尤其是在象棋和将棋等领域。这个棋盘游戏领域是机器擅长的一个领域。如果提前提供大量的胜负模式、过去的游戏数据以及棋子的所有允许移动，机器就能够评估棋盘位置，并从大量的模式中选择最佳的下一步棋。
- en: For those of you who are interested in this field, let's look into how a machine
    plays chess in more detail. Let's say a machine makes the first move as "white,"
    and there are 20 possible moves for both "white" and "black" for the next move.
    Remember the tree-like model in the preceding diagram. From the top of the tree
    at the start of the game, there are 20 branches underneath as white's next possible
    move. Under one of these 20 branches, there's another 20 branches underneath as
    black's next possible movement, and so on. In this case, the tree has 20 x 20
    = 400 branches for black, depending on how white moves, 400 x 20 = 8,000 branches
    for white, 8,000 x 20 = 160,000 branches again for black, and... feel free to
    calculate this if you like.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些对这个领域感兴趣的人，我们来更详细地看看机器是如何下棋的。假设机器先走"白棋"，并且下一步无论是"白棋"还是"黑棋"，都有20种可能的走法。记得之前图示中的树状模型吧。从游戏开始时树的顶部，白棋的下一步有20个分支。在其中一个分支下，又有20个分支作为黑棋的下一步走法，以此类推。在这种情况下，根据白棋的走法，树下有20
    x 20 = 400个黑棋分支，再根据黑棋的走法，400 x 20 = 8,000个白棋分支，8,000 x 20 = 160,000个黑棋分支，依此类推……如果你愿意的话，可以继续计算下去。
- en: A machine generates this tree and evaluates every possible board position from
    these branches, deciding the best arrangement in a second. How deep it goes (how
    many levels of the tree it generates and evaluates) is controlled by the speed
    of the machine. Of course, each different piece's movement should also be considered
    and embedded in a program, so the chess program is not as simple as previously
    thought, but we won't go into detail about this in this book. As you can see,
    it's not surprising that a machine can beat a human at Chess. A machine can evaluate
    and calculate massive amounts of patterns at the same time, in a much shorter
    time than a human could. It's not a new story that a machine has beaten a Chess
    champion; a machine has won a game over a human. Because of stories like this,
    people expected that AI would become a true story.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一台机器生成这棵树并从这些分支中评估每一个可能的棋盘位置，在一秒钟内决定最佳安排。它的深度（生成和评估的树的层数）由机器的速度控制。当然，每个不同棋子的运动也应当考虑并嵌入到程序中，因此棋类程序并不像之前认为的那样简单，但在本书中我们不会详细探讨这一点。正如你所看到的，机器能够击败人类下棋并不令人惊讶。机器可以在比人类更短的时间内同时评估和计算大量的模式。机器战胜国际象棋冠军并不是什么新鲜事；机器曾经在与人类的对局中获胜。正因为这些故事，人们预期人工智能将成为现实。
- en: 'Unfortunately, reality is not that easy. We then found out that there was a
    big wall in front of us preventing us from applying the search algorithm to reality.
    Reality is, as you know, complicated. A machine is good at processing things at
    high speed based on a given set of rules, but it cannot find out how to act and
    what rules to apply by itself when only a task is given. Humans unconsciously
    evaluate, discard many things/options that are not related to them, and make a
    choice from millions of things (patterns) in the real world whenever they act.
    A machine cannot make these unconscious decisions like humans can. If we create
    a machine that can appropriately consider a phenomenon that happens in the real
    world, we can assume two possibilities:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，现实并没有那么简单。我们随后发现，面前有一堵大墙阻止我们将搜索算法应用于现实。正如你所知，现实是复杂的。机器擅长根据给定的一组规则快速处理事情，但当只给定一个任务时，它无法自己找到如何行动以及应该应用哪些规则。人类在无意识中评估并丢弃许多与自己无关的事物/选项，并在每次行动时从现实世界的数百万种事物（模式）中做出选择。机器无法像人类一样做出这些无意识的决策。如果我们创造出一台能够恰当地考虑现实世界中发生现象的机器，我们可以假设两种可能性：
- en: A machine tries to accomplish its task or purpose without taking into account
    secondarily occurring incidents and possibilities
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台机器试图完成其任务或目的，而不考虑次要发生的事件和可能性
- en: A machine tries to accomplish its task or purpose without taking into account
    irrelevant incidents and possibilities
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台机器试图完成其任务或目的，而不考虑无关的事件和可能性
- en: Both of these machines would still freeze and be lost in processing before they
    accomplished their purpose when humans give them a task; in particular, the latter
    machine would immediately freeze before even taking its first action. This is
    because these elements are almost infinite and a machine can't sort them out within
    a realistic time if it tries to think/search these infinite patterns. This issue
    is recognized as one of the important challenges in the AI field, and it's called
    the **frame problem**.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这两台机器在面对人类赋予的任务时仍然会冻结并迷失在处理过程中；尤其是后一台机器甚至在进行第一步操作前就会立即冻结。这是因为这些元素几乎是无限的，如果机器试图思考/搜索这些无限的模式，它无法在现实的时间内整理出来。这个问题被认为是人工智能领域的一个重要挑战，它被称为**框架问题**。
- en: A machine can achieve great success in the field of Chess or Shogi because the
    searching space, the space a machine should be processing within, is limited (set
    in a certain frame) in advance. You can't write out an enormous amount of patterns,
    so you can't define what the best solution is. Even if you are forced to limit
    the number of patterns or to define an optimal solution, you can't get the result
    within an economical time frame for use due to the enormous amounts of calculation
    needed. After all, the research at that time would only make a machine follow
    detailed rules set by a human. As such, although this search method could succeed
    in a specific area, it is far from achieving actual AI. Therefore, the first AI
    boom cooled down rapidly with disappointment.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 机器可以在象棋或将棋领域取得巨大成功，因为搜索空间——机器应该在内部处理的空间——事先是有限的（在特定框架内设置）。你无法写出大量的模式，因此也无法定义最佳解是什么。即使你被迫限制模式的数量或定义最佳解，也无法在经济时间范围内得出结果，因为需要大量的计算。毕竟，那时的研究只会使机器遵循人类设定的详细规则。因此，尽管这种搜索方法在特定领域可能会成功，但远未能实现真正的人工智能。因此，第一次AI热潮由于失望而迅速冷却。
- en: 'The first AI boom was swept away; however, on the side, the research into AI
    continued. The second AI boom came in the 1980s. This time, the movement of so-called
    **Knowledge Representation** (**KR**) was booming. KR intended to describe knowledge
    that a machine could easily understand. If all the knowledge in the world was
    integrated into a machine and a machine could understand this knowledge, it should
    be able to provide the right answer even if it is given a complex task. Based
    on this assumption, various methods were developed for designing knowledge for
    a machine to understand better. For example, the structured forms on a web page—the
    semantic web—is one example of an approach that tried to design in order for a
    machine to understand information easier. An example of how the semantic web is
    described with KR is shown here:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次AI热潮被席卷而去；然而，AI的研究在一旁继续。第二次AI热潮始于1980年代。这次，所谓的**知识表示**（**KR**）运动蓬勃发展。知识表示旨在描述机器可以轻松理解的知识。如果世界上所有的知识都整合到一个机器中，机器能够理解这些知识，即使面对复杂任务也应该能够提供正确答案。基于这一假设，开发了各种方法来更好地为机器设计理解知识。例如，网页上的结构化形式——语义网，是试图设计以便机器更容易理解信息的方法的一个例子。语义网如何用知识表示来描述的一个例子如下所示：
- en: '![AI booms in the past](img/B04779_01_02.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![过去的AI热潮](img/B04779_01_02.jpg)'
- en: Making a machine gain knowledge is not like a human ordering a machine what
    to do one-sidedly, but more like a machine being able to respond to what humans
    ask and then answer. One of the simple examples of how this is applied to the
    actual world is positive-negative analysis, one of the topics of sentiment analysis.
    If you input data that defines a tone of positive or negative for every word in
    a sentence (called "a dictionary") into a machine beforehand, a machine can compare
    the sentence and the dictionary to find out whether the sentence is positive or
    negative.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让机器获取知识并不像人单方面地命令机器要做什么，而更像是机器能够响应人类的询问然后回答。这在实际世界中应用的一个简单例子是情感分析的一个话题，即正负面分析。如果你事先将定义每个句子中每个单词的正面或负面语调的数据（称为“字典”）输入到机器中，机器就可以比较句子和字典，从而判断句子是正面还是负面。
- en: This technique is used for the positive-negative analysis of posts or comments
    on a social network or blog. If you ask a machine "Is the reaction to this blog
    post positive or negative?" it analyzes the comments based on its knowledge (dictionary)
    and replies to you. From the first AI boom, where a machine only followed rules
    that humans set, the second AI boom showed some progress.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术用于社交网络或博客上的正负面分析。如果你问机器“对这篇博客文章的反应是正面的还是负面的？”，它会基于其知识（字典）分析评论并回答你。从最初人类设定规则让机器遵循的第一次AI热潮，第二次AI热潮显示了一些进展。
- en: 'By integrating knowledge into a machine, a machine becomes the almighty. This
    idea itself is not bad for achieving AI; however, there were two high walls ahead
    of us in achieving it. First, as you may have noticed, inputting all real-world
    knowledge requires an almost infinite amount of work now that the Internet is
    more commonly used and we can obtain enormous amounts of open data from the Web.
    Back then, it wasn''t realistic to collect millions of pieces of data and then
    analyze and input that knowledge into a machine. Actually, this work of databasing
    all the world''s data has continued and is known as **Cyc** ([http://www.cyc.com/](http://www.cyc.com/)).
    Cyc''s ultimate purpose is to build an inference engine based on the database
    of this knowledge, called **knowledge base**. Here is an example of KR using the
    Cyc project:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将知识整合到机器中，机器变得无所不能。这个想法本身并不错，用于实现AI；然而，在实现这一目标时，我们面临着两道高墙。首先，正如你可能已经注意到的那样，要输入所有的现实世界知识现在需要几乎无限的工作量，尤其是在互联网更普遍使用、我们能从网络上获得大量开放数据的今天。在那时，收集数百万条数据并分析、输入到机器中是不现实的。事实上，这项工作在不断进行中，并以**Cyc**（[http://www.cyc.com/](http://www.cyc.com/)）而闻名。Cyc的最终目标是基于这些知识数据库构建推理引擎，称为**知识库**。以下是使用Cyc项目的KR的一个示例：
- en: '![AI booms in the past](img/B04779_01_03.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![过去的AI热潮](img/B04779_01_03.jpg)'
- en: Second, it's not that a machine understands the actual meaning of the knowledge.
    Even if the knowledge is structured and systemized, a machine understands it as
    a mark and never understands the concept. After all, the knowledge is input by
    a human and what a machine does is just compare the data and assume meaning based
    on the dictionary. For example, if you know the concept of "apple" and "green"
    and are taught "green apple = apple + green", then you can understand that "a
    green apple is a green colored apple" at first sight, whereas a machine can't.
    This is called the **symbol grounding problem** and is considered one of the biggest
    problems in the AI field, as well as the frame problem.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，机器并不理解知识的实际含义。即使知识是结构化和系统化的，机器也只会将其理解为标记，而从不理解概念。毕竟，知识是由人类输入的，机器所做的只是根据字典比较数据并假设意义。例如，如果你知道“苹果”和“绿色”的概念，并且被教授“绿苹果
    = 苹果 + 绿色”，那么你能够一眼看出“绿苹果是一种绿色的苹果”，而机器却做不到。这被称为**符号接地问题**，被认为是AI领域中最大的问题之一，也是框架问题。
- en: The idea was not bad—it did improve AI—however, this approach won't achieve
    AI in reality as it's not able to create AI. Thus, the second AI boom cooled down
    imperceptibly, and with a loss of expectation from AI, the number of people who
    talked about AI decreased. When it came to the question of "Are we really able
    to achieve AI?" the number of people who answered "no" increased gradually.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法并不错——它确实提高了AI的水平——然而，这种方法实际上无法实现真正的AI，因为它无法创造AI。因此，第二次AI热潮悄然冷却，而AI的期望也因此而减少，讨论AI的人数也有所减少。当涉及到“我们真的能实现AI吗？”这个问题时，回答“不行”的人数逐渐增加。
- en: Machine learning evolves
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习的发展
- en: While people had a hard time trying to establish a method to achieve AI, a completely
    different approach had steadily built a generic technology . That approach is
    called machine learning. You should have heard the name if you have touched on
    data mining even a little. Machine learning is a strong tool compared to past
    AI approaches, which simply searched or assumed based on the knowledge given by
    a human, as mentioned earlier in the chapter, so machine learning is very advanced.
    Until machine learning, a machine could only search for an answer from the data
    that had already been inputted. The focus was on how fast a machine could pull
    out knowledge related to a question from its saved knowledge. Hence, a machine
    can quickly reply to a question it already knows, but gets stuck when it faces
    questions it doesn't know.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 当人们试图建立实现AI的方法时，一个完全不同的方法逐渐发展成了一种通用技术。这种方法被称为机器学习。即使你对数据挖掘稍有涉猎，也应该听过这个名字。与之前章节提到的简单搜索或基于人类给定知识的假设不同，机器学习是一种强大的工具。直到机器学习出现之前，机器只能从已经输入的数据中搜索答案。关注点在于机器能多快地从存储的知识中提取与问题相关的答案。因此，机器能够迅速回答它已经知道答案的问题，但在面对不知道的问题时会陷入困境。
- en: On the other hand, in machine learning, a machine is literally learning. A machine
    can cope with unknown questions based on the knowledge it has learned. So, how
    was a machine able to learn, you ask? What exactly is *learning* here? Simply
    put, learning is when a machine can divide a problem into "yes" or "no." We'll
    go through more detail on this in the next chapter, but for now we can say that
    machine learning is a method of pattern recognition.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，在机器学习中，机器确实是在学习。机器可以根据它所学到的知识来应对未知的问题。那么，你会问，机器是如何学习的呢？这里的*学习*到底是什么意思？简而言之，学习是当机器能够将一个问题分为“是”或“否”时。我们将在下一章详细讨论这一点，但现在可以说，机器学习是一种模式识别的方法。
- en: We could say that, ultimately, every question in the world can be replaced with
    a question that can be answered with yes or no. For example, the question "What
    color do you like?" can be considered almost the same as asking "Do you like red?
    Do you like green? Do you like blue? Do you like yellow?..." In machine learning,
    using the ability to calculate and the capacity to process at high speed as a
    weapon, a machine utilizes a substantial amount of training data, replaces complex
    questions with yes/no questions, and finds out the regularity with which data
    is yes, and which data is no (in other words, it learns). Then, with that learning,
    a machine assumes whether the newly-given data is yes or no and provides an answer.
    To sum up, machine learning can give an answer by recognizing and sorting out
    patterns from the data provided and then classifying that data into the possible
    appropriate pattern (predicting) when it faces unknown data as a question.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以说，最终，世界上每一个问题都可以被替换成一个可以通过“是”或“否”来回答的问题。例如，问题“你喜欢什么颜色？”几乎可以看作是问“你喜欢红色吗？你喜欢绿色吗？你喜欢蓝色吗？你喜欢黄色吗？”在机器学习中，利用计算能力和高速处理能力，机器使用大量的训练数据，将复杂的问题替换为“是/否”问题，并找出数据中哪些是“是”，哪些是“否”的规律（换句话说，它学习了）。然后，凭借这些学习，机器假设新给定的数据是“是”还是“否”，并提供答案。总结来说，机器学习可以通过识别和整理数据中的模式，然后在面对未知数据作为问题时，将数据分类为可能的适当模式（预测），从而给出答案。
- en: In fact, this approach is not doing something especially difficult. Humans also
    unconsciously classify data into patterns. For example, if you meet a man/woman
    who's perfectly your type at a party, you might be desperate to know whether the
    man/woman in front of you has similar feelings towards you. In your head, you
    would compare his/her way of talking, looks, expressions, or gestures to past
    experience (that is, data) and assume whether you will go on a date! This is the
    same as a presumption based on pattern recognition.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这种方法并不是做一些特别困难的事情。人类也会不自觉地将数据分类为模式。例如，如果你在一个聚会上遇到了一个完全符合你类型的男/女，你可能会迫切想知道眼前的男/女是否也对你有相似的感觉。在你的脑海里，你会将他/她的说话方式、外貌、表情或手势与过去的经验（即数据）进行对比，并假设是否会约会！这与基于模式识别的假设是一样的。
- en: Machine learning is a method that can process this pattern recognition not by
    humans but by a machine in a mechanical manner. So, how can a machine recognize
    patterns and classify them? The standard of classification by machine learning
    is a presumption based on a numerical formula called the **probabilistic statistical
    model**. This approach has been studied based on various mathematical models.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一种能够通过机器而非人类以机械方式处理这种模式识别的方法。那么，机器是如何识别模式并进行分类的呢？机器学习的分类标准是基于一个叫做**概率统计模型**的数值公式进行的假设。这种方法已经在各种数学模型的基础上进行了研究。
- en: Learning, in other words, is tuning the parameters of a model and, once the
    learning is done, building a model with one adjusted parameter. The machine then
    categorizes unknown data into the most possible pattern (that is, the pattern
    that fits best). Categorizing data mathematically has great merit. While it is
    almost impossible for a human to process multi-dimensional data or multiple-patterned
    data, machine learning can process the categorization with almost the same numerical
    formulas. A machine just needs to add a vector or the number of dimensions of
    a matrix. (Internally, when it classifies multi-dimensions, it's not done by a
    classified line or a classified curve but by a hyperplane.)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，学习就是调整模型的参数，一旦学习完成，就会建立一个经过调整参数的模型。机器随后会将未知数据分类到最可能的模式中（也就是说，适合度最好的模式）。数学上的数据分类具有巨大的优势。虽然人类几乎无法处理多维数据或多模式数据，但机器学习可以用几乎相同的数学公式来进行分类。机器只需要增加一个向量或者矩阵的维度数量。（在内部，当它对多维数据进行分类时，并不是通过分类线或分类曲线来完成的，而是通过超平面。）
- en: Until this approach was developed, machines were helpless in terms of responding
    to unknown data without a human's help, but with machine learning machines became
    capable of responding to data that humans can't process. Researchers were excited
    about the possibilities of machine learning and jumped on the opportunity to start
    working on improving the method. The concept of machine learning itself has a
    long history, but researchers couldn't do much research and prove the usefulness
    of machine learning due to a lack of available data. Recently, however, many open-source
    data have become available online and researchers can easily experiment with their
    algorithms using the data. Then, the third AI boom came about like this. The environment
    surrounding machine learning also gave its progress a boost. Machine learning
    needs a massive amount of data before it can correctly recognize patterns. In
    addition, it needs to have the capability to process data. The more data and types
    of patterns it handles, the more the amount of data and the number of calculations
    increases. Hence, obviously, past technology wouldn't have been able to deal with
    machine learning.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法被开发出来之前，机器在没有人类帮助的情况下，无法应对未知数据，但随着机器学习的发展，机器能够应对人类无法处理的数据。研究人员对于机器学习的可能性感到兴奋，纷纷抓住机会开始致力于改进这一方法。机器学习的概念本身有着悠久的历史，但由于缺乏可用数据，研究人员未能进行大量的研究，也未能证明机器学习的实用性。然而，近年来，许多开源数据已在线上提供，研究人员可以轻松使用这些数据来实验他们的算法。随后，第三次人工智能浪潮就这样到来了。围绕机器学习的环境也为其进展提供了推动力。机器学习需要大量数据才能正确识别模式。此外，它还需要具备处理数据的能力。它处理的数据量和模式类型越多，数据量和计算量就越大。因此，很显然，过去的技术无法应对机器学习。
- en: However, time is progressing, not to mention that the processing capability
    of machines has improved. In addition, the web has developed and the Internet
    is spreading all over the world, so open data has increased. With this development,
    everyone can handle data mining only if they pull data from the web. The environment
    is set for everyone to casually study machine learning. The web is a treasure
    box of text-data. By making good use of this text-data in the field of machine
    learning, we are seeing great development, especially with statistical natural
    language processing. Machine learning has also made outstanding achievements in
    the field of image recognition and voice recognition, and researchers have been
    working on finding the method with the best precision.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，时间在不断前进，更不用说机器的处理能力已经得到了提升。此外，网络也在发展，互联网正在全球范围内传播，因此开放数据的数量也在增加。随着这一发展，任何人只要从网络上提取数据，就可以进行数据挖掘。如今，大家都可以轻松学习机器学习。网络是一个充满文本数据的宝库。通过充分利用这些文本数据在机器学习领域，我们见证了巨大的进步，尤其是在统计自然语言处理方面。机器学习在图像识别和语音识别领域也取得了显著成就，研究人员一直致力于寻找精度最优的方法。
- en: Machine learning is utilized in various parts of the business world as well.
    In the field of natural language processing, the prediction conversion in the
    **input method editor** (**IME**) could soon be on your mind. The fields of image
    recognition, voice recognition, image search, and voice search in the search engine
    are good examples. Of course, it's not limited to these fields. It is also applied
    to a wide range of fields from marketing targeting, such as the sales prediction
    of specific products or the optimization of advertisements, or designing store
    shelf or space planning based on predicting human behavior, to predicting the
    movements of the financial market. It can be said that the most used method of
    data mining in the business world is now machine learning. Yes, machine learning
    is that powerful. At present, if you hear the word "AI," it's usually the case
    that the word simply indicates a process done by machine learning.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习也被广泛应用于商业世界的各个领域。在自然语言处理领域，**输入法编辑器**（**IME**）中的预测转换很可能已经出现在你的脑海里。图像识别、语音识别、图像搜索以及搜索引擎中的语音搜索都是很好的例子。当然，它并不限于这些领域。它还被应用于各种领域，从营销目标定位，如特定产品的销售预测或广告优化，或者基于预测人类行为来设计商店货架或空间规划，到预测金融市场的走势。可以说，目前商业世界中使用最多的数据挖掘方法就是机器学习。是的，机器学习就是如此强大。目前，如果你听到“AI”这个词，通常是指机器学习所完成的过程。
- en: What even machine learning cannot do
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习无法做到的事情
- en: A machine learns by gathering data and predicting an answer. Indeed, machine
    learning is very useful. Thanks to machine learning, questions that are difficult
    for a human to solve within a realistic time frame (such as using a 100-dimensional
    hyperplane for categorization!) are easy for a machine. Recently, "big data" has
    been used as a buzzword and, by the way, analyzing this big data is mainly done
    using machine learning too.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 机器通过收集数据并预测答案来学习。的确，机器学习非常有用。得益于机器学习，那些在人类可接受时间范围内难以解决的问题（例如使用100维超平面进行分类！）对机器来说却轻松简单。最近，“大数据”已成为一个流行词，顺便提一下，分析这些大数据也主要是通过机器学习来完成的。
- en: Unfortunately, however, even machine learning cannot make AI. From the perspective
    of "can it actually achieve AI?" machine learning has a big weak point. There
    is one big difference in the process of learning between machine learning and
    human learning. You might have noticed the difference, but let's see. Machine
    learning is the technique of pattern classification and prediction based on input
    data. If so, what exactly is that input data? Can it use any data? Of course…
    it can't. It's obvious that it can't correctly predict based on irrelevant data.
    For a machine to learn correctly, it needs to have appropriate data, but then
    a problem occurs. A machine is not able to sort out what is appropriate data and
    what is not. Only if it has the right data can machine learning find a pattern.
    No matter how easy or difficult a question is, it's humans that need to find the
    right data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，不幸的是，即使是机器学习也无法实现人工智能。从“它是否能真正实现人工智能？”的角度来看，机器学习有一个巨大的弱点。在机器学习和人类学习的过程中，有一个很大的区别。你可能已经注意到这个区别，但让我们来看看。机器学习是基于输入数据的模式分类和预测技术。那么，这些输入数据到底是什么？它能使用任何数据吗？当然……不能。显然，如果数据无关紧要，机器是无法做出正确预测的。为了让机器正确学习，它需要拥有合适的数据，但问题就在于，机器无法分辨哪些数据是合适的，哪些数据是不合适的。只有当机器拥有正确的数据时，机器学习才能找到模式。无论问题有多简单或复杂，找到正确数据的任务还是交给人类。
- en: 'Let''s think about this question: "Is the object in front of you a human or
    a cat?" For a human, the answer is all too obvious. It''s not difficult at all
    to distinguish them. Now, let''s do the same thing with machine learning. First,
    we need to prepare the format that a machine can read, in other words, we need
    to prepare the image data of a human and a cat respectively. This isn''t anything
    special. The problem is the next step. You probably just want to use the image
    data for inputting, but this doesn''t work. As mentioned earlier, a machine can''t
    find out what to learn from data by itself. Things a machine should learn need
    to be processed from the original image data and created by a human. Let''s say,
    in this example, we might need to use data that can define the differences such
    as face colors, facial part position, the facial outlines of a human and a cat,
    and so on, as input data. These values, given as inputs that humans need to find
    out, are called the features.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们思考这个问题：“你面前的物体是人还是猫？”对于人类来说，答案显而易见，区分它们一点也不难。现在，让我们用机器学习做同样的事情。首先，我们需要准备机器可以读取的格式，换句话说，我们需要分别准备人类和猫的图像数据。这并不是什么特别的事情。问题出现在下一步。你可能只是想直接使用图像数据作为输入，但这样行不通。正如前面提到的，机器无法自行从数据中找出应该学习的内容。机器应该学习的内容需要从原始图像数据中处理并由人类创建。举个例子，在这个例子中，我们可能需要使用可以定义人类和猫之间差异的数据，例如面部颜色、面部部位的位置、面部轮廓等，作为输入数据。这些由人类需要找出的输入值，称为特征。
- en: 'Machine learning can''t do feature engineering. This is the weakest point of
    machine learning. Features are, namely, variables in the model of machine learning.
    As this value shows the feature of the object quantitatively, a machine can appropriately
    handle pattern recognition. In other words, how you set the value of identities
    will make a huge difference in terms of the precision of prediction. Potentially,
    there are two types of limitations with machine learning:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习无法进行特征工程。这是机器学习的薄弱环节。特征，通常指的是机器学习模型中的变量。由于这个值定量地显示了物体的特征，机器可以适当地处理模式识别。换句话说，你如何设置身份信息的值，会在预测精度上产生巨大差异。机器学习可能存在两种类型的局限性：
- en: An algorithm can only work well on data with the assumption of the training
    data - with data that has different distribution. In many cases, the learned model
    does not generalize well.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法只能在假设训练数据的情况下对数据有效——也就是说，数据具有不同的分布。在许多情况下，学习到的模型并不能很好地进行泛化。
- en: Even the well-trained model lacks the ability to make a smart meta-decision.
    Therefore, in most cases, machine learning can be very successful in a very narrow
    direction.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使是经过良好训练的模型，也缺乏做出智能元决策的能力。因此，在大多数情况下，机器学习只在非常狭窄的方向上取得成功。
- en: Let's look at a simple example so that you can easily imagine how identities
    have a big influence on the prediction precision of a model. Imagine there is
    a corporation that wants to promote a package of asset management based on the
    amount of assets. The corporation would like to recommend an appropriate product,
    but as it can't ask a personal question, it needs to predict how many assets a
    customer might have and prepare in advance. In this case, what type of potential
    customers shall we consider as an identity? We can assume many factors such as
    their height, weight, age, address, and so on as an identity, but clearly age
    or residence seem more relevant than height or weight. You probably won't get
    a good result if you try machine learning based on height or weight, as it predicts
    based on irrelevant data, meaning it's just a random prediction.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个简单的例子，这样你可以更容易地想象身份信息对模型预测精度的巨大影响。假设有一个公司想要根据资产数量推销一款资产管理套餐。公司希望推荐一个合适的产品，但由于无法询问个人问题，它需要预测客户可能拥有的资产数量并提前做准备。在这种情况下，我们应该考虑什么样的潜在客户作为身份信息？我们可以假设许多因素，例如他们的身高、体重、年龄、地址等，作为身份信息，但显然年龄或居住地比身高或体重更相关。如果你根据身高或体重尝试机器学习，结果可能不太好，因为它是基于不相关的数据进行预测，也就是说，这只是一个随机预测。
- en: As such, machine learning can provide an appropriate answer against the question
    only after the machine reads an appropriate identity. But, unfortunately, the
    machine can't judge what the appropriate identity is, and the precision of machine
    learning depends on this feature engineering!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，机器学习只能在机器读取到合适的身份信息后，才能提供对问题的合适回答。但是，不幸的是，机器无法判断什么是合适的身份信息，而机器学习的精度就依赖于这个特征工程！
- en: Machine learning has various methods, but the problem of being unable to do
    feature engineering is seen across all of these. Various methods have been developed
    and people compete against their precision rates, but after we have achieved precision
    to a certain extent, people decide whether a method of machine learning is good
    or bad based on how great a feature they can find. This is no longer a difference
    in algorithms, but more like a human's intuition or taste, or the fine-tuning
    of parameters, and this can't be said to be innovative at all. Various methods
    have been developed, but after all, the hardest thing is to think of the best
    identity and a human has to do that part anyway.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习有多种方法，但无法进行特征工程的问题在所有方法中都有出现。尽管已经开发出多种方法，人们也在争夺精度率，但当我们在一定程度上实现了精度后，人们评判一个机器学习方法的好坏，往往取决于它能找到多么优秀的特征。这不再是算法的差异，更像是人的直觉或品味，或者是参数的微调，这根本不能算是创新。各种方法虽然已经被提出，但归根结底，最难的部分还是要想出最好的特征，而这一部分最终必须由人来完成。
- en: Things dividing a machine and human
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 区分机器与人类的东西
- en: 'We have gone through three problems: the frame problem, the symbol grounding
    problem, and feature engineering. None of these problems concern humans at all.
    So, why can''t a machine handle these problems? Let''s review the three problems
    again. If you think about it carefully, you will find that all three problems
    confront the same issue in the end:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经经历了三个问题：框架问题、符号基础问题和特征工程问题。这些问题与人类完全无关。那么，为什么机器无法解决这些问题呢？我们再来回顾一下这三个问题。如果仔细思考，你会发现最终这三个问题面对的都是同一个问题：
- en: The frame problem is that a machine can't recognize what knowledge it should
    use when it is assigned a task
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 框架问题是指机器在接受任务时无法识别应该使用哪些知识
- en: The symbol grounding problem is that a machine can't understand a concept that
    puts knowledge together because it only recognizes knowledge as a mark
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 符号基础问题在于，机器无法理解将知识结合起来的概念，因为它只是将知识当作标记来识别
- en: The problem of feature engineering in machine learning is that a machine can't
    find out what the feature is for objects
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习中的特征工程问题在于，机器无法发现物体的特征是什么
- en: These problems can be solved only if a machine can sort out *which feature of
    things/phenomena it should focus on and what information it should use*. After
    all, this is the biggest difference between a machine and a human. Every object
    in this world has its own inherent features. A human is good at catching these
    features. Is this by experience or by instinct? Anyhow, humans know features,
    and, based on these features, humans can understand a thing as a "concept."
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题只有在机器能够搞清楚*它应该关注事物/现象的哪些特征，以及应该使用什么信息*时，才能解决。毕竟，这就是机器与人类的最大区别。这个世界上的每一个物体都有它固有的特征，而人类擅长捕捉这些特征。这是靠经验还是本能呢？无论如何，人类知道特征，并且基于这些特征，人类能够将一件事物理解为一个“概念”。
- en: Now, let's briefly explain what a concept is. First of all, as a premise, take
    into account that every single thing in this world is constituted of a set of
    symbol representations and the symbols' content. For example, if you don't know
    the word "cat" and see a cat when you walk down a street, does it mean you can't
    recognize a cat? No, this is not true. You know it exists, and if you see another
    cat just after, you will understand it as "a similar thing to what I saw earlier."
    Later, you are told "That is called a cat", or you look it up for yourself, and
    for the first time you can connect the existence and the word.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们简要解释一下什么是概念。首先，作为前提，要考虑到这个世界上的每个事物都是由一组符号表示和这些符号的内容构成的。例如，如果你不知道“猫”这个词，走在街上看到一只猫，这是否意味着你无法辨认出那是一只猫呢？不，这并不是真的。你知道它的存在，如果你很快看到另一只猫，你会理解它是“和我之前看到的东西相似的”。后来，如果有人告诉你“那叫做猫”，或者你自己查找，你就能第一次将存在和这个词联系起来。
- en: This word, cat, is the **symbol representation** and the concept that you recognize
    as a cat is the **symbol content**. You can see these are two sides of the same
    coin. (Interestingly, there is no necessity between these two sides. There is
    no necessity to write cat as C-A-T or to pronounce it as such. Even so, in our
    system of understanding, these are considered to be inevitable. If people hear
    "cat", we all imagine the same thing.) The concept is, namely, symbol content.
    These two concepts have terms. The former is called **signifiant** and the latter
    is called **signifié**, and a set of these two as a pair is called **signe**.
    (These words are French. You can say signifier, signified, and sign in English,
    respectively.) We could say what divides a machine and human is whether it can
    get signifié by itself or not.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这个词，“cat”，是**符号表示**，而你所认知的猫的概念是**符号内容**。你可以看到这两者是同一枚硬币的两面。（有趣的是，这两者之间并没有必要性。没有必要将“cat”写作
    C-A-T，也没有必要按这种方式发音。即便如此，在我们的理解系统中，这些被认为是不可避免的。如果人们听到“cat”，我们都会想象出同样的东西。）概念，即符号内容。这两个概念有各自的术语。前者叫做**signifiant**，后者叫做**signifié**，这两者作为一对被称为**signe**。（这些词来自法语。你可以分别用英语说
    signifier、signified 和 sign。）我们可以说，区分机器和人类的关键在于它是否能够独立获得 signifié。
- en: What would happen if a machine could find the notable feature from given data?
    As for the frame problem, if a machine could extract the notable feature from
    the given data and perform the knowledge representation, it wouldn't have the
    problem of freezing when thinking of how to pick up the necessary knowledge anymore.
    In terms of the symbol grounding problem, if a machine could find the feature
    by itself and understand the concept from the feature, it could understand the
    inputted symbol.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果机器能够从给定数据中找到显著特征，会发生什么？对于框架问题，如果机器能够从给定数据中提取显著特征并进行知识表示，那么在思考如何获取必要知识时，它就不会再遇到停滞问题。至于符号基础问题，如果机器能够自己找到特征并理解该特征的概念，它就能够理解输入的符号。
- en: Needless to say, the feature engineering problem in machine learning would also
    be solved. If a machine can obtain appropriate knowledge by itself following a
    situation or a purpose, and not use knowledge from a fixed situation, we can solve
    the various problems we have been facing in achieving AI. Now, the method that
    a machine can use to find the important feature value from the given data is close
    to being accomplished. Yes, finally, this is deep learning. In the next section,
    I'll explain this deep learning, which is considered to be the biggest breakthrough
    in the more-than-50 years of AI history.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 不言而喻，机器学习中的特征工程问题也会得到解决。如果机器能够根据情境或目的自行获取适当的知识，而不是依赖固定情境中的知识，我们就能解决在实现 AI 过程中一直面临的各种问题。现在，机器如何从给定数据中找到重要特征值的方法已经接近完成。是的，最终，这就是深度学习。在下一部分，我将解释这种被认为是
    AI 50 多年历史中最大突破的深度学习。
- en: AI and deep learning
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI 和深度学习
- en: Machine learning, the spark for the third AI boom, is very useful and powerful
    as a data mining method; however, even with this approach of machine learning,
    it appeared that the way towards achieving AI was closed. Finding features is
    a human's role, and here there is a big wall preventing machine learning from
    reaching AI. It looked like the third AI boom would come to an end as well. However,
    surprisingly enough, the boom never ended, and on the contrary a new wave has
    risen. What triggered this wave is deep learning.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习，作为第三次 AI 热潮的引擎，作为一种数据挖掘方法非常有用且强大；然而，即便采用这种机器学习的方法，似乎通往实现 AI 的道路已经关闭。特征提取是人类的角色，这里有一道大墙，阻碍了机器学习实现
    AI。看起来第三次 AI 热潮也将结束。然而，令人惊讶的是，这一热潮并没有结束，反而迎来了新的浪潮。触发这一浪潮的正是深度学习。
- en: With the advent of deep learning, at least in the fields of image recognition
    and voice recognition, a machine became able to obtain "what should it decide
    to be a feature value" from the inputted data by itself rather than from a human.
    A machine that could only handle a symbol as a symbol notation has become able
    to obtain concepts.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习的出现，至少在图像识别和语音识别领域，机器变得能够从输入的数据中自主地获取“应当被决定为特征值的内容”，而不是依赖于人类。一个仅能将符号视为符号表示的机器，已经能够获取概念。
- en: '![AI and deep learning](img/B04779_01_04.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![AI 和深度学习](img/B04779_01_04.jpg)'
- en: Correspondence diagram between AI booms up to now and the research fields of
    AI
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: AI 热潮至今与 AI 研究领域的对应图
- en: The first time deep learning appeared was actually quite a while ago, back in
    2006\. Professor Hinton at Toronto University in Canada, and others, published
    a paper ([https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf](https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf)).
    In this paper, a method called **deep belief nets** (**DBN**) was presented, which
    is an expansion of neural networks, a method of machine learning. DBN was tested
    using the **MNIST** database, the standard database for comparing the precision
    and accuracy of each image recognition method. This database includes 70,000 28
    x 28 pixel hand-written character image data of numbers from 0 to 9 (60,000 are
    for training and 10,000 are for testing).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习首次出现其实是在很久以前，回到2006年。加拿大多伦多大学的Hinton教授和其他人发布了一篇论文（[https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf](https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf)）。在这篇论文中，提出了一种叫做**深度信念网络**（**DBN**）的方法，这是神经网络的一种扩展，是一种机器学习方法。DBN使用**MNIST**数据库进行了测试，MNIST是用于比较各类图像识别方法的精度和准确性的标准数据库。该数据库包括70,000个28
    x 28像素的手写数字图像数据，涵盖从0到9的数字（其中60,000用于训练，10,000用于测试）。
- en: Then, they constructed a prediction model based on the training data and measured
    its accuracy based on whether a machine could correctly answer which number from
    0 to 9 was written in the test case. Although this paper presented a result with
    considerably higher precision than a conventional method, it didn't attract much
    attention at the time, maybe because it was compared with another general method
    of machine learning.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，他们基于训练数据构建了一个预测模型，并根据机器能否正确回答测试用例中写的数字是0到9中的哪个数字来衡量其准确性。尽管这篇论文提出的结果比传统方法有显著更高的精度，但当时并未引起太多关注，可能是因为它与另一种通用的机器学习方法进行了比较。
- en: Then, a while later in 2012, the whole AI research world was shocked by one
    method. At the world competition for image recognition, **Imagenet Large Scale
    Visual Recognition Challenge** (**ILSVRC**), a method using deep learning called
    SuperVision (strictly, that's the name of the team), which was developed by Professor
    Hinton and others from Toronto University, won the competition. It far surpassed
    the other competitors, with formidable precision. At this competition, the task
    was assigned for a machine to automatically distinguish whether an image was a
    cat, a dog, a bird, a car, a boat, and so on. 10 million images were provided
    as learning data and 150,000 images were used for the test. In this test, each
    method competes to return the lowest error rate (that is, the highest accuracy
    rate).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在2012年稍后，整个人工智能研究界被一种方法震惊了。在全球的图像识别比赛——**Imagenet大规模视觉识别挑战赛**（**ILSVRC**）中，一种名为SuperVision的深度学习方法（严格来说，这是一个团队的名称），由Hinton教授和多伦多大学的其他人开发，赢得了比赛。它远远超过了其他竞争者，具有强大的精确度。在这场比赛中，任务是让机器自动区分图像是猫、狗、鸟、车、船等。提供了1000万张图像作为学习数据，150,000张图像用于测试。在这项测试中，每种方法都争夺最低的错误率（即最高的准确率）。
- en: 'Let''s look at the following table that shows the result of the competition:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下展示比赛结果的表格：
- en: '| Rank | Team name | Error |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 排名 | 队名 | 错误率 |'
- en: '| --- | --- | --- |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 1 | SuperVision | 0.15315 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 1 | SuperVision | 0.15315 |'
- en: '| 2 | SuperVision | 0.16422 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 2 | SuperVision | 0.16422 |'
- en: '| 3 | ISI | 0.26172 |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 3 | ISI | 0.26172 |'
- en: '| 4 | ISI | 0.26602 |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 4 | ISI | 0.26602 |'
- en: '| 5 | ISI | 0.26646 |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 5 | ISI | 0.26646 |'
- en: '| 6 | ISI | 0.26952 |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 6 | ISI | 0.26952 |'
- en: '| 7 | OXFORD_VGG | 0.26979 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 7 | OXFORD_VGG | 0.26979 |'
- en: '| 8 | XRCE/INRIA | 0.27058 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 8 | XRCE/INRIA | 0.27058 |'
- en: You can see that the difference in the error rate between SuperVision and the
    second position, ISI, is more than 10%. After the second position, it's just a
    competition within 0.1%. Now you know how greatly SuperVision outshone the others
    with precision rates. Moreover, surprisingly, it was the first time SuperVision
    joined this ILSVRC, in other words, image recognition is not their usual field.
    Until SuperVision (deep learning) appeared, the normal approach for the field
    of image recognition was machine learning. And, as mentioned earlier, a feature
    value necessary to use machine learning had to be set or designed by humans. They
    reiterated design features based on human intuition and experiences and fine-tuning
    parameters over and over, which, in the end, contributed to improving precision
    by just 0.1%. The main issue of the research and the competition before deep learning
    evolved was who was able to invent good feature engineering. Therefore, researchers
    must have been surprised when deep learning suddenly showed up out of the blue.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，SuperVision和第二名ISI之间的错误率差距超过了10%。第二名之后，差距几乎不到0.1%。现在你可以明白SuperVision在精确度上是如何远远超越其他竞争者的。而且，令人惊讶的是，SuperVision是第一次参加ILSVRC，换句话说，图像识别并非他们的常规领域。直到SuperVision（深度学习）出现之前，图像识别领域的常规方法是机器学习。如前所述，使用机器学习时，特征值必须由人类设置或设计。研究人员基于人类直觉和经验不断地重新设计特征，反复调优参数，最终只能提升精度0.1%。在深度学习出现之前，研究和竞赛的主要问题是，谁能发明出好的特征工程。因此，当深度学习突然出现时，研究人员一定感到非常惊讶。
- en: 'There is one other major event that spread deep learning across the world.
    That event happened in 2012, the same year the world was shocked by SuperVision
    at ILSVRC, when Google announced that a machine could automatically detect a cat
    using YouTube videos as learning data from the deep learning algorithm that Google
    proposed. The details of this algorithm are explained at [http://googleblog.blogspot.com/2012/06/using-large-scale-brain-simulations-for.html](http://googleblog.blogspot.com/2012/06/using-large-scale-brain-simulations-for.html).
    This algorithm extracted 10 million images from YouTube videos and used them as
    input data. Now, remember, in machine learning, a human has to detect feature
    values from images and process data. On the other hand, in deep learning, original
    images can be used for inputs as they are. This shows that a machine itself comes
    to find features automatically from training data. In this research, a machine
    learned the concept of a cat. (Only this cat story is famous, but the research
    was also done with human images and it went well. A machine learned what a human
    is!) The following image introduced in the research illustrates the characteristics
    of what deep learning thinks a cat is, after being trained using still frames
    from unlabeled YouTube videos:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个重大事件将深度学习传播到了全球。这个事件发生在2012年，同年，世界因ILSVRC中的SuperVision而震惊，当时谷歌宣布，利用YouTube视频作为学习数据，通过谷歌提出的深度学习算法，机器能够自动识别猫。该算法的细节可以在[http://googleblog.blogspot.com/2012/06/using-large-scale-brain-simulations-for.html](http://googleblog.blogspot.com/2012/06/using-large-scale-brain-simulations-for.html)中找到。该算法从YouTube视频中提取了1000万张图片，并将它们作为输入数据。现在请记住，在机器学习中，人类需要从图像中提取特征值并处理数据。另一方面，在深度学习中，原始图像可以直接作为输入使用。这表明机器本身能够自动从训练数据中寻找特征。在这项研究中，机器学习了“猫”的概念。（尽管这只猫的故事非常有名，但研究同样也涉及了人类图像，并且效果很好。机器学会了什么是人类！）下图展示了该研究中使用YouTube视频中的静帧训练后，深度学习所认为的猫的特征：
- en: '![AI and deep learning](img/B04779_01_05.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![AI和深度学习](img/B04779_01_05.jpg)'
- en: These two big events impressed us with deep learning and triggered the boom
    that is still accelerating now.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个重大事件给我们留下了深刻的深度学习印象，并引发了至今仍在加速发展的热潮。
- en: 'Following the development of the method that can recognize a cat, Google conducted
    another experiment for a machine to draw a picture by utilizing deep learning.
    This method is called **Inceptionism** ([http://googleresearch.blogspot.ch/2015/06/inceptionism-going-deeper-into-neural.html](http://googleresearch.blogspot.ch/2015/06/inceptionism-going-deeper-into-neural.html)).
    As written in the article, in this method, the network is asked:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在能够识别猫的算法发展之后，谷歌进行了一项新的实验，利用深度学习让机器绘画。这种方法被称为**Inceptionism** ([http://googleresearch.blogspot.ch/2015/06/inceptionism-going-deeper-into-neural.html](http://googleresearch.blogspot.ch/2015/06/inceptionism-going-deeper-into-neural.html))。正如文章中所写，在这种方法中，网络被要求：
- en: '*"Whatever you see there, I want more of it!". This creates a feedback loop:
    if a cloud looks a little bit like a bird, the network will make it look more
    like a bird. This in turn will make the network recognize the bird even more strongly
    on the next pass and so forth, until a highly detailed bird appears, seemingly
    out of nowhere.*'
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“无论你看到什么，我都想要更多！”这创造了一个反馈循环：如果一朵云看起来有点像鸟，网络就会让它看起来更像鸟。反过来，这会让网络在下一轮中更强烈地识别出鸟，依此类推，直到一个非常详细的鸟出现，似乎凭空出现。*'
- en: 'While the use of neural networks in machine learning is a method usually used
    to detect patterns to be able to specify an image, what Inceptionism does is the
    opposite. As you can see from the following examples of Inceptionism, these paintings
    look odd and like the world of a nightmare:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然神经网络在机器学习中的使用通常是用来检测模式以便能够指定图像，但Inceptionism做的正好相反。如以下Inceptionism的例子所示，这些画作看起来很奇怪，像是噩梦中的世界：
- en: '![AI and deep learning](img/B04779_01_06.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![人工智能与深度学习](img/B04779_01_06.jpg)'
- en: Or rather, they could look artistic. The tool that enables anyone to try Inceptionism
    is open to the public on GitHub and is named Deep Dream ([https://github.com/google/deepdream](https://github.com/google/deepdream)).
    Example implementations are available on that page. You can try them if you can
    write Python codes.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 或者说，它们看起来可能像是艺术作品。让任何人都能尝试Inceptionism的工具是公开在GitHub上的，名为Deep Dream（[https://github.com/google/deepdream](https://github.com/google/deepdream)）。该页面上提供了示例实现。如果你会写Python代码，可以尝试它们。
- en: Well, nothing stops deep learning gaining momentum, but there are still questions,
    such as what exactly is innovative about deep learning? What special function
    dramatically increased this precision? Surprisingly, actually, there isn't a lot
    of difference for deep learning in algorithms. As mentioned briefly, deep learning
    is an application of neural networks, which is an algorithm of machine learning
    that imitates the structure of a human brain; nevertheless, a device adopted it
    and changed everything. The representatives are **pretraining** and **dropout**
    (with an activation function). These are also keywords for implementation, so
    please remember them.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，虽然没有什么能阻止深度学习的快速发展，但仍然有一些问题，比如深度学习究竟有什么创新之处？是什么特殊功能大幅提高了其精度？令人惊讶的是，实际上，深度学习在算法上并没有太大差异。如前所述，深度学习是神经网络的一种应用，神经网络是模仿人脑结构的机器学习算法；然而，正是某种设备采用了它并改变了一切。代表性的技术是**预训练**和**丢弃法**（配合激活函数）。这些也是实现过程中的关键词，请记住它们。
- en: To begin with, what does the *deep* in deep learning indicate? As you probably
    know, the human brain is a circuit structure, and that structure is really complicated.
    It is made up of an intricate circuit piled up in many layers. On the other hand,
    when the neural network algorithm first appeared its structure was quite simple.
    It was a simplified structure of the human brain and the network only had a few
    layers. Hence, the patterns it could recognize were extremely limited. So, everyone
    wondered "Can we just accumulate networks like the human brain and make its implementation
    complex?" Of course, though this approach had already been tried. Unfortunately,
    as a result, the precision was actually lower than if we had just piled up the
    networks. Indeed, we faced various issues that didn't occur with a simple network.
    Why was this? Well, in a human brain, a signal runs into a different part of the
    circuit depending on what you see. Based on the patterns that differ based on
    which part of the circuit is stimulated, you can distinguish various things.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，深度学习中的*深度*是什么意思呢？如你所知，人脑是一个电路结构，而这个结构非常复杂。它由许多层堆叠起来的复杂电路组成。另一方面，当神经网络算法首次出现时，其结构非常简单。它是人脑结构的简化版本，网络只有几层。因此，它能够识别的模式非常有限。于是，大家开始问“我们能不能像人脑一样积累网络，让它的实现变得复杂？”当然，虽然这种方法已经尝试过了。不幸的是，结果表明，精度其实比仅仅堆积网络时还要低。事实上，我们遇到了简单网络不会出现的各种问题。这是为什么呢？因为在人脑中，一个信号会根据你看到的东西，流向电路的不同部分。基于这些电路部分的不同刺激模式，你能够区分出不同的事物。
- en: To reproduce this mechanism, the neural network algorithm substitutes the linkage
    of the network by weighting with numbers. This is a great way to do it, but soon
    a problem occurs. If a network is simple, weights are properly allocated from
    the learning data and the network can recognize and classify patterns well. However,
    once a network gets complicated, the linkage becomes too dense and it is difficult
    to make a difference in the weights. In short, it cannot divide into patterns
    properly. Also, in a neural network, the network can make a proper model by adopting
    a mechanism that feeds back errors that occurred during training to the whole
    network. Again, if the network is simple the feedback can be reflected properly,
    but if the network has many layers a problem occurs in which the error disappears
    before it's reflected to the whole network—just imagine if that error was stretched
    out and diluted.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了再现这一机制，神经网络算法通过使用数字对网络的连接进行加权替代。这是一个很好的方法，但很快就会出现问题。如果网络比较简单，权重可以从学习数据中适当地分配，网络能够很好地识别和分类模式。然而，一旦网络变得复杂，连接变得过于密集，权重之间很难做出区分。简而言之，它无法正确地划分出模式。此外，在神经网络中，网络通过采用将训练过程中出现的错误反馈到整个网络的机制来构建一个合适的模型。同样地，如果网络较为简单，反馈可以得到适当的体现，但如果网络有很多层，就会出现一个问题，即错误在反馈到整个网络之前就已经消失——试想一下，如果那个错误被延伸并稀释了。
- en: The intention that things would go well if the network was built with a complicated
    structure ended in disappointing failure. The concept of the algorithm itself
    was splendid but it couldn't be called a good algorithm by any standards; that
    was the world's understanding. While deep learning succeeded in making a network
    multi-layered, that is, making a network "deep," the key to success was to make
    each layer learn in stages. The previous algorithm treated the whole multi-layered
    network as one gigantic neural network and made it learn as one, which caused
    the problems mentioned earlier.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 网络如果构建成复杂结构，事情就会顺利进行的这一设想，最终以令人失望的失败告终。算法本身的概念是非常出色的，但无论从哪个标准来看，都不能称其为一个好的算法；这是世界的普遍理解。虽然深度学习成功地使得网络变得多层化，即使网络变得“深”，但成功的关键在于让每一层逐步学习。之前的算法将整个多层网络视为一个巨大的神经网络，并使其作为一个整体进行学习，这也导致了前面提到的问题。
- en: Hence, deep learning took the approach of making each layer learn in advance.
    This is literally known as pretraining. In pretraining, learning starts from the
    lower-dimension layer in order. Then, the data that is learned in the lower layer
    is treated as input data for the next layer. This way, machines become able to
    take a step by learning a feature of a low layer at the low-grade layer and gradually
    learning a feature of a higher grade. For example, when learning what a cat is,
    the first layer is an outline, the next layer is the shape of its eyes and nose,
    the next layer is a picture of a face, the next layers is the detail of a face,
    and so on. Similarly, it can be said that humans take the same learning steps
    as they catch the whole picture first and see the detailed features later. As
    each layer learns in stages, the feedback for an error of learning can also be
    done properly in each layer. This leads to an improvement in precision. There
    is also a device for each respective approach to each layer's learning, but this
    will be introduced later on.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，深度学习采取了让每一层先行学习的方法。这通常被称为预训练。在预训练中，学习从较低维度的层开始，按顺序进行。然后，较低层学习到的数据被作为输入数据传递给下一层。通过这种方式，机器能够通过在低级层学习一个特征，逐渐学习更高层的特征。例如，在学习什么是猫的时候，第一层是轮廓，下一层是眼睛和鼻子的形状，接下来是面部的图像，再往后是面部的细节，依此类推。类似地，可以说人类也采取了相同的学习步骤：先抓住整体的图像，再逐渐观察细节特征。随着每一层逐步学习，学习中的错误反馈也可以在每一层得到适当的反映，从而提高精度。每一层学习的方法也有各自的设备，但这将在后续介绍。
- en: We have also addressed the fact that the network became too dense. The method
    that prevents this density problem is called the **dropout**. Networks with the
    dropout learn by cutting some linkages randomly within the units of networks.
    The dropout physically makes the network sparse. Which linkage is cut is random,
    so a different network is formed at each learning step. Just by looking, you might
    doubt that this will work, but it greatly contributes to improving the precision
    and as a result it increases the robustness of the network. The circuit of the
    human brain also has different places in which to react or not depending on the
    subject it sees. The dropout seems to be able to successfully imitate this mechanism.
    By embedding the dropout in the algorithm, the adjustment of the network weight
    was done well.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提到过网络变得过于密集的问题。防止这一密集问题的方法被称为**丢弃法**。使用丢弃法的网络通过在网络单元中随机切断一些连接来进行学习。丢弃法在物理上使网络变得稀疏。被切断的连接是随机的，因此每一步学习时都会形成一个不同的网络。仅凭直观看，你可能会怀疑这是否有效，但它大大提高了精度，进而增强了网络的鲁棒性。人类大脑的电路也有不同的地方，根据看到的主题是否反应。丢弃法似乎能够成功地模仿这种机制。通过将丢弃法嵌入算法中，网络权重的调整得到了很好的完成。
- en: Deep learning has seen great success in various fields; however, of course deep
    learning has a demerit too. As is shown in the name "deep learning," the learning
    in this method is very deep. This means the steps to complete the learning take
    a long time. The amount of calculation in this process tends to be enormous. In
    fact, the previously mentioned learning of the recognition of a cat by Google
    took three days to be processed with 1,000 computers. Conversely, although the
    idea of deep learning itself could be conceived using past techniques, it couldn't
    be implemented. The method wouldn't appear if you couldn't easily use a machine
    that has a large-scale processing capacity with massive data.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在各个领域都取得了巨大的成功；然而，深度学习当然也有其缺点。正如“深度学习”这个名称所示，这种学习方法的深度非常大。这意味着完成学习的步骤需要很长时间。这个过程中的计算量往往非常庞大。事实上，之前提到的谷歌识别猫的学习过程，使用了1,000台计算机，处理了整整三天。相反，尽管深度学习的概念可以使用过去的技术来构思，但它是无法实现的。如果无法轻松使用具有大规模处理能力并能处理海量数据的机器，那么这一方法是不会出现的。
- en: As we keep saying, deep learning is just the first step for a machine to obtain
    human-like knowledge. Nobody knows what kind of innovation will happen in the
    future. Yet we can predict to what extent a computer's performance will be improved
    in the future. To predict this, Moore's law is used. The performance of an integrated
    circuit that supports the progress of a computer is indicated by the loaded number
    of transistors. Moore's law shows the number, and the number of transistors is
    said to double every one and a half years. In fact, the number of transistors
    in the CPU of a computer has been increasing following Moore's law. Compared to
    the world's first micro-processor, the Intel® 4004 processor, which had 1x103
    (one thousand) transistors, the recent 2015 version, the 5th Generation Intel®
    Core™ Processor, has 1x109 (one billion)! If this technique keeps improving at
    this pace, the number of transistors will exceed ten billion, which is more than
    the number of cells in the human cerebrum.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们一直在说的，深度学习只是机器获得类人知识的第一步。没人知道未来会发生什么样的创新。但我们可以预测计算机性能在未来将如何提升。为了预测这一点，我们使用摩尔定律。支持计算机进步的集成电路的性能由其中所载的晶体管数量来表示。摩尔定律展示了这一数字，并且晶体管的数量据说每隔一年半就会翻一番。事实上，计算机CPU中的晶体管数量一直在遵循摩尔定律增长。与世界上第一款微处理器——英特尔®
    4004处理器（拥有1x10³个晶体管）相比，最近的2015款第五代英特尔® 酷睿™处理器，竟有1x10⁹（十亿）个晶体管！如果这种技术继续以这个速度进步，晶体管的数量将超过100亿个，超过人类大脑皮层中的细胞数量。
- en: Based on Moore's law, further in the future in 2045, it is said that we will
    reach a critical point called **Technical Singularity** where humans will be able
    to do technology forecasting. By that time, a machine is expected to be able to
    produce self-recursive intelligence. In other words, in about 30 years, AI will
    be ready. What will the world be like then…
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 基于摩尔定律，未来2045年，预计我们将到达一个被称为**技术奇点**的临界点，那时人类将能够进行技术预测。到那时，预计机器将能够产生自我递归的智能。换句话说，大约30年后，AI将准备就绪。到时的世界会是什么样子……
- en: '![AI and deep learning](img/B04779_01_07.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![人工智能与深度学习](img/B04779_01_07.jpg)'
- en: History of Moore's law
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 摩尔定律的历史
- en: The number of transistors loaded in the processor invented by Intel has been
    increasing smoothly following Moore's law.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 英特尔发明的处理器中加载的晶体管数量一直平稳增长，符合摩尔定律。
- en: 'The world famous professor Stephen Hawking answered in an interview by the
    BBC ([http://www.bbc.com/news/technology-30290540](http://www.bbc.com/news/technology-30290540)):'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 世界著名的教授斯蒂芬·霍金在接受BBC采访时回答道（[http://www.bbc.com/news/technology-30290540](http://www.bbc.com/news/technology-30290540)）：
- en: '*"The development of full artificial intelligence could spell the end of the
    human race."*'
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“全人工智能的发展可能意味着人类种族的终结。”*'
- en: Will deep learning become a black magic? Indeed, the progress of technology
    has sometimes caused tragedy. Achieving AI is still far in the future, yet we
    should be careful when working on deep learning.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习会变成一种“黑魔法”吗？的确，技术的进步有时会带来悲剧。实现人工智能仍然遥不可及，但我们在从事深度学习时应保持谨慎。
- en: Summary
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned how techniques in the field of AI have evolved
    into deep learning. We now know that there were two booms in AI and that we are
    now in the third boom. Searching and traversing algorithms were developed in the
    first boom, such as DFS and BFS. Then, the study focused on how knowledge could
    be represented with symbols that a machine could easily understand in the second
    boom.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了人工智能领域的技术如何演变为深度学习。我们现在知道，人工智能经历了两次繁荣，目前正处于第三次繁荣。第一次繁荣中，开发了诸如深度优先搜索（DFS）和广度优先搜索（BFS）等搜索和遍历算法。随后，第二次繁荣的研究重点是如何用机器容易理解的符号表示知识。
- en: Although these booms had faded away, techniques developed during those times
    built up much useful knowledge of AI fields. The third boom spread out with machine
    learning algorithms in the beginning with those of pattern recognition and classification
    based on probabilistic statistical models. With machine learning, we've made great
    progress in various fields, but this is not enough to realize true AI because
    we need to tell a machine what the features of objects to be classified are. The
    technique required for machine learning is called feature engineering. Then, deep
    learning came out, based on one machine learning algorithm - namely, neural networks.
    A machine can automatically learn what the features of objects are with deep learning,
    and thus deep learning is recognized as a very innovative technique. Studies of
    deep learning are becoming more and more active, and every day new technologies
    are invented. Some of the latest technologies are introduced in the last chapter
    of this book, [Chapter 8](ch08.html "Chapter 8. What's Next?"), *What's Next?*,
    for reference.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这些繁荣已经消退，但在这些时期发展起来的技术积累了大量人工智能领域的有用知识。第三次繁荣从机器学习算法开始，最初是基于概率统计模型的模式识别和分类。通过机器学习，我们在多个领域取得了巨大进展，但这还不足以实现真正的人工智能，因为我们需要告诉机器要分类的对象的特征是什么。实现机器学习所需的技术被称为特征工程。随后，深度学习出现了，它基于一种机器学习算法——即神经网络。通过深度学习，机器可以自动学习对象的特征，因此深度学习被认为是一项非常创新的技术。深度学习的研究越来越活跃，每天都有新技术被发明出来。本书最后一章[第8章](ch08.html
    "Chapter 8. What's Next?")，*未来展望*，介绍了一些最新的技术，供参考。
- en: Deep learning is often thought to be very complicated, but the truth is it's
    not. As mentioned, deep learning is the evolving technique of machine learning,
    and deep learning itself is very simple yet elegant. We'll look at more details
    of machine learning algorithms in the next chapter. With a great understanding
    of machine learning, you will easily acquire the essence of deep learning.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习通常被认为非常复杂，但事实并非如此。如前所述，深度学习是机器学习的演变技术，深度学习本身非常简单却又优雅。我们将在下一章详细介绍更多机器学习算法。通过对机器学习的深入理解，你将轻松掌握深度学习的精髓。
