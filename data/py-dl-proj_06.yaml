- en: Generative Language Model for Content Creation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内容创作的生成性语言模型
- en: This work is certainly getting exciting, and the word is out that we're demonstrating
    a professional set of deep learning capabilities by producing solutions for a
    wide range of business use cases! As data scientists, we understand the transferability
    of our skills. We know that we can provide value by employing core skills when
    working on problems that we know are similar in structure but that may seem different
    at first glance. This couldn't be more true than in the next deep learning project.
    Next, we're (hypothetically) going to be working on a project in which a creative
    group has asked us to help produce some original content for movie scripts, song
    lyrics, and even music!
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作无疑令人兴奋，而且已经有消息传出，我们正在展示一套专业的深度学习能力，通过为各种商业用例提供解决方案！作为数据科学家，我们理解自己技能的可迁移性。我们知道，在处理我们知道结构上相似但乍看之下不同的问题时，通过运用核心技能，我们能够提供价值。这一点在下一个深度学习项目中尤为真实。接下来，我们（假设性地）将参与一个项目，创意团队请求我们帮助为电影剧本、歌曲歌词，甚至音乐创作一些原创内容！
- en: How can we leverage our experience in solving problems for restaurant chains
    to such a different industry? Let's explore what we know and what we're going
    to be asked to do. In past projects, we demonstrated that we could take an image
    as input and output a class label ([Chapter 2](027b6171-1cf7-4589-b9a2-e417dbe53d8b.xhtml),
    *Training NN for Prediction Using Regression*); we trained a model to take text
    input and output sentiment classifications ([Chapter 3](4dcd4b65-934b-4a8a-a252-9af7513a4787.xhtml),
    *Word Representation Using word2vec*); we built a NLP pipeline for an open domain
    question and answering chatbot where we took text as input and identified text
    in a corpus to present as the appropriate output ([Chapter 4](c6f638a5-96bf-4488-9e14-4fbc9b969a42.xhtml),
    *Building an NLP Pipeline for Building Chatbots*); and we expanded that chatbot's
    functionality so that it was able to serve a restaurant with an automated ordering
    system ([Chapter 5](856ccfef-cfe1-462f-9998-73f2b5168ae7.xhtml), *Sequence-to-Sequence
    Models for Building Chatbots*).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何将解决餐饮连锁店问题的经验，运用到如此不同的行业中呢？让我们探索一下我们所知道的和将要做的事情。在过去的项目中，我们展示了如何以图像为输入并输出类别标签（[第
    2 章](027b6171-1cf7-4589-b9a2-e417dbe53d8b.xhtml)，*使用回归进行预测的神经网络训练*）；我们训练了一个模型，接受文本输入并输出情感分类（[第
    3 章](4dcd4b65-934b-4a8a-a252-9af7513a4787.xhtml)，*使用 word2vec 进行词汇表示*）；我们构建了一个开放领域问题解答聊天机器人的
    NLP 管道，接受文本输入并从语料库中提取相关文本作为适当输出（[第 4 章](c6f638a5-96bf-4488-9e14-4fbc9b969a42.xhtml)，*为构建聊天机器人构建
    NLP 管道*）；我们还扩展了该聊天机器人的功能，使其能够为餐厅提供自动化点餐系统服务（[第 5 章](856ccfef-cfe1-462f-9998-73f2b5168ae7.xhtml)，*用于构建聊天机器人的序列到序列模型*）。
- en: '**Define the goal**: In this next project, we''re going to take the next step
    in our computational linguistics journey in *Python Deep Learning Projects* and
    generate new content for our client. We need to help them by providing a deep
    learning solution that generates new content that can be used in movie scrips,
    song lyrics, and music.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义目标**：在这个项目中，我们将迈出计算语言学旅程的下一步，在 *Python 深度学习项目* 中为客户生成新的内容。我们需要通过提供一个深度学习解决方案来帮助他们，生成可用于电影剧本、歌曲歌词和音乐的新内容。'
- en: In this chapter, we will implement a generative model that can generate content
    using **long short-term memory** (**LSTM**), variational autoencoders, and **Generative
    Adversarial Networks** (**GANs**). We will be implementing models for both text
    and images, which can then generate images and text for artists and various businesses.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将实现一个生成模型，使用 **长短期记忆**（**LSTM**）、变分自编码器和 **生成对抗网络**（**GANs**）来生成内容。我们将实现用于文本和图像的模型，生成图像和文本供艺术家和各种商业使用。
- en: 'In this chapter, we''ll cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Text generation with LSTM
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 LSTM 进行文本生成
- en: Additional power of a bi-directional LSTM for text generation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 双向 LSTM 在文本生成中的额外优势
- en: Deep (multi-layer) LSTM to generate lyrics for a song
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度（多层）LSTM 生成歌曲歌词
- en: Deep (multi-layer) LSTM music generation for a song
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度（多层）LSTM 音乐生成用于歌曲创作
- en: LSTM for text generation
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LSTM 在文本生成中的应用
- en: 'In this section, we''ll explore a popular deep learning model: the **recurrent
    neural network** (**RNN**), and how it can be used in the generation of sequence
    data. The universal way to create sequence data in deep learning is to train a
    model (usually a RNN or a ConvNet) to predict the next token or next few tokens
    in a series, based on the previous tokens as input. For instance, let''s imagine
    that we''re given the sentence with these words as input: `I love to work in deep
    learning`. We will train the network to predict the next character as our target.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探索一种流行的深度学习模型：**循环神经网络**（**RNN**），以及它如何用于生成序列数据。在深度学习中，创建序列数据的通用方法是训练一个模型（通常是RNN或ConvNet）来预测序列中的下一个标记或下几个标记，基于前面的标记作为输入。例如，假设我们给定输入句子：`I
    love to work in deep learning`。我们将训练该网络以预测下一个字符作为目标。
- en: When working with textual data, tokens are typically words or characters, and
    any network that can model the probability of the next token given the previous
    ones is called a language model that can capture the latent space of language.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理文本数据时，标记通常是单词或字符，任何能够基于前一个标记预测下一个标记的网络都称为语言模型，它可以捕捉语言的潜在空间。
- en: Upon training the language model, we can then proceed to feed some initial text
    and ask it to generate the next token, then add the generated token back into
    the language model to predict more tokens. For our hypothetical use case, our
    creative client will use this model and later provide examples of text that we
    would then be asked to create novel content for in that style.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 训练语言模型后，我们可以开始输入一些初始文本，要求它生成下一个标记，然后将生成的标记重新输入语言模型，以预测更多的标记。对于我们的假设用例，我们的创意客户将使用此模型，并随后提供一些文本示例，我们将被要求在该风格下创建新的内容。
- en: The first step in building the generative model for text is to import all the
    modules required. Keras APIs will be used in this project to create the models
    and Keras utils will be used to download the dataset. In order to build text generation
    modules, we need a significant amount of simple text data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 构建文本生成模型的第一步是导入所需的所有模块。该项目将使用Keras API来创建模型，Keras工具将用于下载数据集。为了构建文本生成模块，我们需要大量简单的文本数据。
- en: 'You can find the code file for this at [https://github.com/PacktPublishing/Python-Deep-Learning-Projects/blob/master/Chapter06/Basics/generative_text.py](https://github.com/PacktPublishing/Python-Deep-Learning-Projects/blob/master/Chapter06/Basics/generative_text.py):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://github.com/PacktPublishing/Python-Deep-Learning-Projects/blob/master/Chapter06/Basics/generative_text.py](https://github.com/PacktPublishing/Python-Deep-Learning-Projects/blob/master/Chapter06/Basics/generative_text.py)找到该代码文件：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Data pre-processing
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: Let's perform the data pre-processing to convert the raw data into its encoded
    form. We will extract fixed length sentences, encode them using a one-hot encoding
    process, and finally build a tensor of the (`sequence`, `maxlen`, `unique_characters`)
    shape, as shown in the following diagram. At the same time, we will prepare the
    target vector, `y`, to contain the associated next character that follows each
    extracted sequence.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行数据预处理，将原始数据转换为编码形式。我们将提取固定长度的句子，使用独热编码过程对它们进行编码，最后构建一个形状为（`sequence`，`maxlen`，`unique_characters`）的张量，如下图所示。同时，我们将准备目标向量`y`，用于包含每个提取序列后续的字符。
- en: 'The following is the code we''ll use to pre-process the data:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们将用于预处理数据的代码：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Following is how data preprocessing looks like. We have transformed the raw
    data into the tensors which we will further use for the training purpose:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是数据预处理的过程。我们已经将原始数据转换为张量，接下来将用于训练目的：
- en: '![](img/b412734c-ce09-4512-8bf6-29e1340dbd95.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b412734c-ce09-4512-8bf6-29e1340dbd95.png)'
- en: Defining the LSTM model for text generation
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义用于文本生成的LSTM模型
- en: This deep model is a network that's made up of one hidden LSTM layer with `128`
    memory units, followed by a `Dense` classifier layer with a `softmax` activation
    function over all possible characters. Targets are one-hot encoded, and this means
    that we'll train the model using `categorical_crossentropy` as the `loss` function.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个深度模型是一个由一个隐藏的LSTM层（具有`128`个内存单元）组成的网络，后面跟着一个`Dense`分类器层，并对所有可能的字符使用`softmax`激活函数。目标是独热编码，这意味着我们将使用`categorical_crossentropy`作为`loss`函数来训练模型。
- en: 'The following code block defines the model''s architecture:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块定义了模型的架构：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following diagram helps us visualize the model''s architecture:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 下图帮助我们可视化模型的架构：
- en: '![](img/1172e519-40f4-46f6-a18b-662dfa35653e.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1172e519-40f4-46f6-a18b-662dfa35653e.png)'
- en: Training the model
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练模型
- en: In text generation, the way we choose the succeeding character is crucial. The
    most common way (greedy sampling) leads to repetitive characters that does not produce a
    coherent language. This is why we use a different approach called **stochastic
    sampling**. This adds a degree of randomness to the prediction probability distribution.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本生成中，选择后续字符的方式至关重要。最常见的方法（贪婪采样）会导致重复的字符，无法生成连贯的语言。这就是为什么我们使用一种不同的方法，称为**随机采样**。这种方法在预测概率分布中添加了一定程度的随机性。
- en: 'Use the following code to re-weight the prediction probability distribution
    and sample a character index:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下代码重新加权预测概率分布并采样一个字符索引：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now, we iterate the training and text generation, beginning with 30 training
    epochs and then fitting the model for 1 iteration. Then, perform a random selection
    of the seed text, convert it into one-hot encoding format, and perform predictions
    of 100 characters. Finally, append the newly generated character to the seed text
    in each iteration.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们开始迭代训练和文本生成，首先进行30轮训练，然后对模型进行1次迭代拟合。接着，随机选择一个种子文本，将其转换为独热编码格式，并预测100个字符。最后，在每次迭代中将新生成的字符附加到种子文本后。
- en: After each epoch, generation is performed by utilizing a different temperature
    from a range of values. This makes it possible to see and understand the evolution
    of the generated text at model convergence, and the consequences of temperature
    in the sampling strategy.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 每次迭代后，通过使用不同的温度值进行生成。这样可以查看并理解在模型收敛时生成文本的演变，以及温度在采样策略中的影响。
- en: '**Temperature** is an LSTM hyperparameter that is used to influence prediction
    randomness by logit scaling before applying softmax.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**Temperature**是LSTM的超参数，它通过在应用softmax之前进行logit缩放来影响预测的随机性。'
- en: 'We need to execute the following code so that we can train the model:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要执行以下代码，以便训练模型：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Inference and results
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推理与结果
- en: This gets us to the exciting part of our generative language model—creating
    custom content! The inference step in deep learning is where we take a trained
    model and expose it to new data to make predictions or classifications. In the
    current context of this project, we're looking for model outputs, that is, new
    sentences, which will be our novel custom content. Let's see what our deep learning
    model can do!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这将引导我们进入生成语言模型的激动人心的部分——创建自定义内容！深度学习中的推理步骤是我们将训练好的模型暴露于新数据，并进行预测或分类。在本项目的当前背景下，我们寻找的是模型输出，也就是新的句子，这将是我们的新颖自定义内容。让我们看看我们的深度学习模型能做什么！
- en: 'We will use the following code to store and load the checkpoints into a binary
    file that stores all of the weights:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下代码将检查点存储到一个二进制文件中，该文件保存所有权重：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, we will use the trained model and generate new text:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用训练好的模型生成新的文本：
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'After successfully training the model, we will see the following results at
    the 30^(th) epoch:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功训练模型后，我们将在第30^(th)轮看到以下结果：
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We find that, with low values for the `temperature` hyperparameter, the model
    is able to generate more practical and realistic words. When we use higher temperatures,
    the generated text becomes more interesting and unusual—some might even say creative.
    Sometimes, the model will even invent new words that often sound vaguely credible.
    So, the idea of using low temperature is more reasonable for business use cases
    where you need to be realistic, while higher temperature values can be used in
    more creative and artistic use cases.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，当`temperature`超参数取较低值时，模型能够生成更实用和更真实的词语。当我们使用较高的温度时，生成的文本变得更加有趣和不寻常——有些人甚至会说它是具有创意的。有时，模型甚至会发明出一些听起来模糊可信的新词。因此，低温度的使用理念对于需要保持现实的商业用例更为合理，而较高温度值则适用于更加创意和艺术化的用例。
- en: The art of deep learning and generative linguistic models is a balance between
    the learned structure and randomness, which makes the output interesting.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习和生成语言模型的艺术在于平衡学习到的结构和随机性，这使得输出变得有趣。
- en: Generating lyrics using deep (multi-layer) LSTM
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度（多层）LSTM生成歌词
- en: 'Now that we have built a basic LSTM model for text generation and learned its
    value, let''s move one step further and create a deep LSTM model suited for the
    task of generating music lyrics. We now have a new goal: to build and train a
    model that outputs entirely new and original lyrics that is in the style of an
    arbitrary number of artists.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为文本生成构建了基本的 LSTM 模型并学习了它的价值，让我们再进一步，创建一个适用于生成音乐歌词任务的深层 LSTM 模型。我们现在有了一个新目标：构建并训练一个模型，输出完全新颖、原创性的歌词，符合任意数量艺术家的风格。
- en: Let's begin. You can refer to the code file found at `Lyrics-ai` ([https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter06/Lyrics-ai](https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter06/Lyrics-ai))
    for this exercise.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。您可以参考位于 `Lyrics-ai` 文件夹中的代码文件 ([https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter06/Lyrics-ai](https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter06/Lyrics-ai))
    进行此练习。
- en: Data pre-processing
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: To build a model that can generate lyrics, we will need a huge amount of lyric
    data, which can easily be extracted from various sources. We collected lyrics
    from around 10,000 songs and stored them in a text file called `lyrics_data.txt`.
    You can find the data file in our GitHub repository ([https://github.com/PacktPublishing/Python-Deep-Learning-Projects/blob/master/Chapter06/Lyrics-ai/lyrics_data.txt](https://github.com/PacktPublishing/Python-Deep-Learning-Projects/blob/master/Chapter06/Lyrics-ai/lyrics_data.txt)).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建一个能够生成歌词的模型，我们需要大量的歌词数据，可以从各种来源轻松提取。我们从大约 10,000 首歌曲中收集了歌词，并将它们存储在一个名为 `lyrics_data.txt`
    的文本文件中。您可以在我们的 GitHub 仓库 ([https://github.com/PacktPublishing/Python-Deep-Learning-Projects/blob/master/Chapter06/Lyrics-ai/lyrics_data.txt](https://github.com/PacktPublishing/Python-Deep-Learning-Projects/blob/master/Chapter06/Lyrics-ai/lyrics_data.txt))
    中找到数据文件。
- en: 'Now that we have our data, we need to convert this raw text into the one-hot
    encoding version:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了数据，我们需要将这些原始文本转换为独热编码版本：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The overall objective of the pre-processing module is to convert the raw text
    data into one-hot encoding, as shown in the following diagram:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 预处理模块的总体目标是将原始文本数据转换为独热编码，如下图所示：
- en: '![](img/e4d420da-9566-43e9-9e58-6bb5d412098f.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e4d420da-9566-43e9-9e58-6bb5d412098f.png)'
- en: This figure represents the data preprocessing part. The law lyrics data is used
    to build the vocabulary mapping which is further been transformed into the on-hot
    encoding.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 该图表示数据预处理部分。原始歌词数据用于构建词汇映射，进而转换为独热编码。
- en: After the successful execution of the pre-processing module, a binary file will
    be dumped as `{dataset_filename}.vocab`. This `vocab` file is one of the mandatory
    files that needs to be fed into the model during the training process, along with
    the dataset.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 成功执行预处理模块后，将会以 `{dataset_filename}.vocab` 的形式导出一个二进制文件。此 `vocab` 文件是在训练过程中必须提供给模型的文件之一，连同数据集一起。
- en: Defining the model
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义模型
- en: We will be using a approach from the Keras model that we used earlier in this
    project to build this model. To build a more complex model, we will use TensorFlow
    to write each layer from scratch. TensorFlow gives us, as data scientists and
    deep learning engineers, more fine-tuned control over our model's architecture.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用此项目中早期使用的 Keras 模型方法来构建这个模型。为了构建一个更复杂的模型，我们将使用 TensorFlow 从头开始编写每一层。作为数据科学家和深度学习工程师，TensorFlow
    为我们提供了对模型架构更精细的控制。
- en: 'For this model, we will use the code in the following block to create two placeholders
    that will store the input and output values:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个模型，我们将使用以下代码块中的代码创建两个占位符，用于存储输入和输出值：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we need to store the weights and bias in the variables that we''ve created:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要将权重和偏置存储到我们创建的变量中：
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can build this model by using multiple LSTM layers, with the basic LSTM
    cells assigning each layer with the specified number of cells, as shown in the
    following diagram:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用多个 LSTM 层来构建此模型，基本的 LSTM 单元为每个层分配指定数量的单元，如下图所示：
- en: '![](img/98851e09-270a-41e3-92b0-8a269e5f7bd6.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/98851e09-270a-41e3-92b0-8a269e5f7bd6.png)'
- en: Tensorboard visualization of the LSTM architecture
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Tensorboard 可视化 LSTM 架构
- en: 'The following is the code for this:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是此过程的代码：
- en: '[PRE11]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Training the deep TensorFlow-based LSTM model
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练基于 TensorFlow 的深度 LSTM 模型
- en: 'Now that we have the mandatory inputs, that is, the dataset file path, the `vocab`
    file path, and the model name, we will initiate the training process. Let''s define
    all of the hyperparameters for the model:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了必要的输入，即数据集文件路径、`vocab` 文件路径和模型名称，我们将启动训练过程。让我们定义模型的所有超参数：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Since we are batch training the model, we will divide the dataset into batches
    of a defined `batch_size` using the `Batch` module:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们是在进行批量训练，我们将使用`Batch`模块将数据集划分为定义好的`batch_size`批次：
- en: '[PRE13]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Each batch will return two arrays. One will be the input vector of the input
    sequence, which will have a shape of [`batch_size`, `sequence_length`, `vocab_size`],
    and the other array will hold the label vector, which will have a shape of [`batch_size`,
    `vocab_size`].
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 每个批次将返回两个数组。一个是输入序列的输入向量，形状为[`batch_size`, `sequence_length`, `vocab_size`]，另一个数组将保存标签向量，形状为[`batch_size`,
    `vocab_size`]。
- en: Now, we initialize our model and create the optimizer function. In this model,
    we used the `Adam` Optimizer.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们初始化模型并创建优化器函数。在这个模型中，我们使用了`Adam`优化器。
- en: The Adam Optimizer is a powerful tool. You can read up on it from the official
    TensorFlow documentation at
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Adam 优化器是一个强大的工具。你可以通过官方的 TensorFlow 文档了解更多内容
- en: '[https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer).'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer)'
- en: 'Then, we will train our model and perform the optimization over each batch:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将训练我们的模型，并对每一批次进行优化：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Once the model completes its training, the checkpoints are stored. We can use
    later on for inferencing. The following is a graph of the accuracy and the loss
    that occurred during the training process:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型完成训练，检查点将被存储。我们可以稍后用于推理。以下是训练过程中准确率和损失的图示：
- en: '![](img/8ec64ecd-bb63-4680-aa9e-9bc1965e6a4f.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8ec64ecd-bb63-4680-aa9e-9bc1965e6a4f.png)'
- en: The accuracy (top) and the loss (bottom) plot with respect to the time. We can
    see that accuracy getting increased and loss getting reduced over the period of
    time.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 随时间变化的准确率（上）和损失（下）图。我们可以看到，准确率随着时间增加而提高，损失随着时间减少。
- en: Inference
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推理
- en: 'Now that the model is ready, we can use it to make predictions. We will start
    by defining all of the parameters. While building inference, we need to provide
    some seed text, just like we did in the previous model. Along with that, we will
    also provide the path of the `vocab` file and the output file in which we will
    store the generated lyrics. We will also provide the length of the text that we
    need to generate:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已准备就绪，我们可以使用它来进行预测。我们将首先定义所有的参数。在构建推理时，我们需要提供一些种子文本，就像我们在前一个模型中做的那样。同时，我们还需要提供`vocab`文件的路径和我们将存储生成歌词的输出文件。我们还将提供生成文本的长度：
- en: '[PRE15]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next, we will load the model by providing the name of model that we used in
    the training step in the preceding code, and we will restore the vocabulary from
    the file:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过提供我们在前面的代码训练步骤中使用的模型名称来加载模型，并从文件中恢复词汇：
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We will be using the stack methods to store the generated characters, append
    the stack, and then use the same stack to feed it into the model in an interactive
    fashion:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用堆栈方法来存储生成的字符，附加到堆栈上，然后用相同的堆栈以交互的方式将其输入到模型中：
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Output
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 输出
- en: 'After successful execution, we will get our own freshly brewed, AI generated
    lyrics reviewed and published. The following is one sample of such lyrics. We
    have modified some of the spelling so that the sentence makes sense:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 执行成功后，我们将获得自己新鲜出炉的、由 AI 生成的歌词，经过审核并发布。以下是其中一首歌词的示例。我们已修改部分拼写，以使句子更通顺：
- en: '[PRE18]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Here, we can see that the model has learned in the way it has generated the
    paragraphs and sentences with appropriate spacing. It still lacks perfection and
    also doesn't make sense.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到模型已经学会了如何生成段落和句子，并且使用了适当的空格。它仍然不完美，并且有些地方不合逻辑。
- en: '**Seeing signs of success**: The first task is to create a model that can learn,
    and then the second one is used to improve on that model. This can be obtained
    by training the model with a larger training dataset and longer training durations.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**看到成功的迹象**：第一个任务是创建一个能够学习的模型，第二个任务是改进该模型。通过使用更大的训练数据集和更长的训练时间来训练模型，可以实现这一点。'
- en: Generating music using a multi-layer LSTM
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用多层 LSTM 生成音乐
- en: 'Our (hypothetical) creative agency client loves what we''ve done in how we
    can generate music lyrics. Now, they want us to create some music. We will be
    using multiple layers of LSTMs, as shown in the following diagram:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的（假设的）创意代理客户非常喜欢我们在生成音乐歌词方面的成果。现在，他们希望我们能创作一些音乐。我们将使用多个 LSTM 层，如下图所示：
- en: '![](img/bd77caaf-1d4a-47a4-8cdf-8808426666d5.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd77caaf-1d4a-47a4-8cdf-8808426666d5.png)'
- en: By now, we know that RNNs are good for sequential data, and we can also represent
    a music track as notes and chord sequences. In this paradigm, notes become data
    objects containing octave, offset, and pitch information. Chords become data container
    objects holding information for the combination of notes played at one time.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们知道RNNs适合处理序列数据，我们也可以将一首音乐曲目表示为音符和和弦的序列。在这种范式中，音符变成包含八度、偏移量和音高信息的数据对象。和弦则变成包含同时演奏的音符组合信息的数据容器对象。
- en: '**Pitch** is the sound frequency of a note. Musicians represent notes with
    letter designations [A, B, C, D, E, F, G], with G being the lowest and A being
    the highest.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**音高**是音符的声音频率。音乐家使用字母表示音符[A, B, C, D, E, F, G]，其中G是最低音，A是最高音。'
- en: '**Octave**identifies the set of pitches used at any one time while playing
    an instrument.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**八度**标识在演奏乐器时使用的音高集合。'
- en: '**Offset**identifies the location of a note in the piece of music.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**偏移量**标识音符在乐曲中的位置。'
- en: Let's explore the following section to build our intuition on how to generate
    music by first processing the sound files, converting them into the sequential
    mapping data, and then using the RNN to train the model.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨以下部分，建立如何通过首先处理音频文件、将其转换为序列映射数据，然后使用RNN训练模型来生成音乐的直觉。
- en: Let's do it. You can refer to the Music-ai code for this exercise, which can
    be found at [https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter06/Music-ai](https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter06/Music-ai).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始吧。你可以参考此练习的Music-ai代码，代码可以在[https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter06/Music-ai](https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter06/Music-ai)找到。
- en: Pre-processing data
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: 'To generate music, we will need a good size set of training data of music files.
    These will be used to extract sequences while building our training dataset. To
    simplify this process, in this chapter, we are using the soundtrack of a single
    instrument. We collected some melodies and stored them in MIDI files. The following
    sample of a MIDI file shows you what this looks like:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成音乐，我们需要一组足够大的音乐文件训练数据。这些数据将用于提取序列，并建立我们的训练数据集。为了简化此过程，在本章中，我们使用单一乐器的原声带。我们收集了一些旋律并将其存储在MIDI文件中。以下MIDI文件的示例展示了其内容：
- en: '![](img/4259903c-6f13-47a5-b084-50843c671689.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4259903c-6f13-47a5-b084-50843c671689.png)'
- en: The image represents the pitch and note distribution for a sample MIDI file
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 该图片表示了一个示例MIDI文件的音高和音符分布
- en: We can see the intervals between notes, the offset for each note, and the pitch.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到音符之间的间隔、每个音符的偏移量以及音高。
- en: To extract the contents of our dataset, we will be using music21\. This also
    takes the output of the model and translates it into musical notation. Music21
    ([http://web.mit.edu/music21/](http://web.mit.edu/music21/)) is a very helpful Python
    toolkit that's used for computer-aided musicology.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提取我们的数据集内容，我们将使用music21。它还可以将模型的输出转化为音乐符号。Music21 ([http://web.mit.edu/music21/](http://web.mit.edu/music21/))
    是一个非常有用的Python工具包，用于计算机辅助音乐学。
- en: To get started, we will load each file and use the `converter.parse(file)` function
    to create a music21 `stream` object*. *We will get a list of all of the notes
    and chords in the file by using this `stream` object later. Because the most salient
    features of a note's pitch can be recreated from string notation, we'll append
    the pitch of every note. To handle chords, we will encode the ID of every note
    in the chord as a single string, where each note is separated by a dot, and append
    this to the chord. This encoding process makes it possible for us to decode the
    model generated output with ease into the correct notes and chords.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始，我们将加载每个文件，并使用`converter.parse(file)`函数来创建一个music21 `stream`对象*。*稍后，我们将通过这个`stream`对象获取文件中的所有音符和和弦列表。由于音符的音高最显著的特征可以通过谱号重现，我们将附加每个音符的音高。为了处理和弦，我们将把和弦中每个音符的ID编码为一个单一字符串，音符之间用点分隔，并将其附加到和弦上。这个编码过程使我们能够轻松地解码模型生成的输出，得到正确的音符和和弦。
- en: 'We will load the data from the MIDI files into an array, as you can see in
    the following code snippet:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把MIDI文件中的数据加载到一个数组中，如下代码片段所示：
- en: '[PRE19]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The next step is to create input sequences for the model and the corresponding
    outputs, as shown in the following diagram:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是为模型创建输入序列和相应的输出，如下图所示：
- en: '![](img/a2924167-d48a-495a-8162-7c797127dd54.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a2924167-d48a-495a-8162-7c797127dd54.png)'
- en: The overview of data processing part in which we take the MIDI files, extract
    the notes and chords from each file and strore them as an array.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理部分的概述，其中我们从MIDI文件中提取音符和和弦，并将它们存储为数组。
- en: The model outputs a note or chord for each input sequence. We use the first
    note or chord, following the input sequence in our list of notes. To complete
    the final step in data preparation for our network, we need to one-hot encode
    the output. This normalizes the input for the next iteration.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 模型对每个输入序列输出一个音符或和弦。我们使用输入序列中第一个音符或和弦，在我们的音符列表中继续。为了完成数据准备的最后一步，我们需要对输出进行独热编码。这将标准化下一次迭代的输入。
- en: 'We can do this with the following code:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下代码来实现：
- en: '[PRE20]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now that we have all the notes and chords extracted. We will create our training
    data X and Y as shown in the following figure:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经提取了所有音符和和弦。我们将创建我们的训练数据X和Y，如下图所示：
- en: '![](img/f70cadbb-c649-4c33-aba7-dc12505592a5.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f70cadbb-c649-4c33-aba7-dc12505592a5.png)'
- en: The captured notes any chords in the array is further transformed into a one
    -hot encoding vector by mapping the values from the vocabulary. So we will fed
    the sequences in X matrix and expect the model to learn to predict Y for the given
    sequence.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 捕获的音符和和弦在数组中进一步转换为独热编码向量，通过映射词汇表中的值。所以我们将把X矩阵中的序列输入到模型中，并期望模型能够学习预测给定序列的Y。
- en: Defining the model and training
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义模型和训练
- en: 'Now, we are getting to the part that all deep learning engineers love: designing
    the model''s architecture!  We will be using four distinctive types of layers
    in our model architecture:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们进入了所有深度学习工程师喜爱的部分：设计模型架构！我们将在模型架构中使用四种不同类型的层：
- en: '**LSTM**: This is a type of RNN layer.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LSTM**：这是一种RNN层。'
- en: '**Dropout**:A technique for regularization. This helps prevent the model from
    overfitting by randomly dropping some nodes.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Dropout**：一种正则化技术。它通过随机丢弃一些节点来帮助防止模型过拟合。'
- en: '**Dense:** This is a fully connected layer where every input node is connected
    to every output node.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Dense**：这是一个全连接层，其中每个输入节点都与每个输出节点相连。'
- en: '**Activation**: This determines the `activation` function that''s going to
    be used to produce the node''s output.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Activation**：这个决定了将用于生成节点输出的`activation`函数。'
- en: 'We will again employ the Keras APIs to make the implementation quick:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将再次使用Keras API来快速实现：
- en: '[PRE21]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The generative model architecture we designed has three LSTM layers, three
    `Dropout` layers, two `Dense` layers, and one `Activation` layer, as shown in
    the following diagram:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计的生成模型架构包含三层LSTM、三层`Dropout`、两层`Dense`和一层`Activation`，如下面的图所示：
- en: '![](img/7d431f84-1eb2-4ed9-95d8-dc10562177d7.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7d431f84-1eb2-4ed9-95d8-dc10562177d7.png)'
- en: The model architecture for music generation
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 音乐生成的模型架构
- en: Categorical cross entropy will be used to calculate the loss for each iteration
    of the training. We will once again use the Adam optimizer in this network. Now
    that we have our deep learning model architecture configured, it's time to train
    the model. We have decided to train the model for 200 epochs, each with 25 batches,
    by using `model.fit()`. We also want to track the reduction in loss over each
    epoch and will use checkpoints for this purpose.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 将使用类别交叉熵来计算每次训练迭代的损失。我们将在此网络中再次使用Adam优化器。现在我们已经配置了深度学习模型架构，接下来是时候训练模型了。我们决定训练模型200个周期，每个周期有25个批次，使用`model.fit()`。我们还希望跟踪每个周期损失的减少，并将使用检查点来实现这个目的。
- en: 'Now we will perform the training operation and dump the model in the file mentioned
    in the following code:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将执行训练操作，并将模型保存到以下代码中提到的文件：
- en: '[PRE22]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The performance of the model can be seen as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的性能如下所示：
- en: '![](img/bb82d271-5ac9-40c9-9342-ce2f84d03c58.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bb82d271-5ac9-40c9-9342-ce2f84d03c58.png)'
- en: The accuracy and the loss plot over the epochs
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 精度和损失在各个周期中的变化图
- en: Now that the training process is completed, we will load the trained models and
    generate our own music.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在训练过程已完成，我们将加载训练好的模型并生成我们自己的音乐。
- en: Generating music
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成音乐
- en: It's time for the real fun! Let's generate some instrumental music. We will
    use the code from the model setup and training, but instead of executing the training
    (as our model is already trained), we will insert the learned weights that we
    obtained in earlier training.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 真正有趣的部分来了！让我们生成一些器乐音乐。我们将使用模型设置和训练中的代码，但不执行训练（因为我们的模型已经训练完成），而是插入我们在之前训练中获得的学习到的权重。
- en: 'The following code block executes these two steps:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码块执行这两个步骤：
- en: '[PRE23]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: By doing this, we created the same model, but this time for prediction purposes,
    and added one extra line of code to load the weights into memory.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样做，我们创建了相同的模型，但这次是为了预测目的，并添加了一行额外的代码来将权重加载到内存中。
- en: 'Because we need a seed input so that the model can start generating music,
    we chose to use a random sequence of notes that we obtained from our processed
    files. You can also send your own nodes as long as you can ensure that the sequence
    length is precisely 100:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们需要一个种子输入，以便模型可以开始生成音乐，我们选择使用从处理文件中获得的随机音符序列。只要你确保序列长度恰好为100，你也可以发送你自己的节点：
- en: '[PRE24]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: We iterated the model generation 1,000 times, which created 1,000 notes using
    the network, producing approximately five minutes of music. The process we used
    to select the next sequence for each iteration was that we'd start with the first
    sequence to submit, since it was of the sequence of notes that was at the starting
    index. For subsequent input sequences, we removed the first note and appended
    the output from the previous iteration at the end of the sequence. This is a very
    crude way to do this and is known as the sliding window approach. You can play
    around and add some randomness to each sequence we select, which could give more
    creativity to the music that is generated.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迭代了1,000次模型生成，这创建了1,000个音符，并通过网络生成了大约五分钟的音乐。我们用来选择每次迭代下一个序列的过程是：我们从第一个序列开始提交，因为它是起始索引位置的音符序列。对于后续的输入序列，我们去掉第一个音符，并将前一次迭代的输出附加到序列的末尾。这是一种非常粗糙的方法，称为滑动窗口方法。你可以尝试并为每个选择的序列添加一些随机性，这可能会为生成的音乐带来更多的创造力。
- en: It is at this point that we have an array of all of the encoded representations
    of the notes and chords. To turn this array back into `Note` and `Chord` objects,
    we need to decode it.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们有一个包含所有音符和和弦编码表示的数组。为了将这个数组转换回`Note`和`Chord`对象，我们需要对其进行解码。
- en: When we detect that the pattern is that of a `Chord` object, we will separate
    the string into an array of notes. We will then loop through the string's representation
    of each note to create a `Note` object for each item. The `Chord` object is then
    created, which contains each of these notes.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们检测到模式是`Chord`对象时，我们将把字符串分解成音符数组。然后，我们将遍历字符串中每个音符的表示形式，为每个项目创建一个`Note`对象。接着，我们创建`Chord`对象，其中包含这些音符。
- en: When the pattern is that of a `Note` object, we will use the string representation
    of the pitch pattern to create a `Note` object. At the end of each iteration,
    we increase the offset by `0.5`, which can again be changed and randomness can
    be introduced to it.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 当模式是`Note`对象时，我们将使用音高模式的字符串表示形式来创建`Note`对象。在每次迭代结束时，我们将偏移量增加`0.5`，这可以再次更改，并且可以引入随机性。
- en: The following function is responsible for determining whether the output is
    a `Note` or `Chord` object. Finally, can we use the music21 output `stream` object
    to create the MIDI file. Here are a few samples of generated music: [https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter06/Music-ai/generated_music](https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter06/Music-ai/generated_music).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数负责确定输出是`Note`还是`Chord`对象。最后，我们可以使用music21输出的`stream`对象来创建MIDI文件。以下是一些生成的音乐样本：[https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter06/Music-ai/generated_music](https://github.com/PacktPublishing/Python-Deep-Learning-Projects/tree/master/Chapter06/Music-ai/generated_music)。
- en: 'To execute these steps, you can make use of this `helper` function, as shown
    in the following code block:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行这些步骤，你可以使用这个`helper`函数，如以下代码块所示：
- en: '[PRE25]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Summary
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Wow, that's an impressive set of practical examples of using deep learning projects
    in Python to build solutions in a creative space! Let's revisit the goals we set
    up for ourselves.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，这些都是使用深度学习项目在Python中构建解决方案的实用示例，真是太令人印象深刻了！让我们回顾一下我们为自己设定的目标。
- en: '**Defining the goal**:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义目标**：'
- en: In this project, we're going to take the next step in our computational linguistics
    journey in deep learning projects in Python and generate new content for our client.
    We need to help them by providing a deep learning solution that generates new
    content that can be used in movie scripts, song lyrics, and music.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们将继续在深度学习项目中进行计算语言学的下一步，并为我们的客户生成新的内容。我们需要为他们提供一个深度学习解决方案，生成可以用于电影剧本、歌曲歌词和音乐的新内容。
- en: Deep learning generated content for creative purposes is obviously very tricky.
    Our realistic goal in this chapter was to demonstrate and train you on the skills
    and architecture needed to get started on these types of projects. Producing acceptable
    results takes interacting with the data, the model, and the outputs and testing
    it with the appropriate audiences. The key takeaway to remember is that the outputs
    of your models can be quite personalized to the task at hand and that you can
    expand your thinking of what types of business use cases you should feel comfortable
    working on in your career.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 使用深度学习生成创意内容显然是非常棘手的。本章的现实目标是展示并训练你掌握启动此类项目所需的技能和架构。要产生可接受的结果，必须与数据、模型及其输出进行互动，并通过适当的受众进行测试。需要记住的关键点是，你的模型输出可以根据具体任务进行高度个性化，而且你可以拓展思维，思考哪些商业用例是你在职业生涯中应当自信从事的。
- en: 'In this chapter, we implemented a generative model, which generated content
    with the use of LSTMs. We implemented models for both text and audio that generated
    content for artists and various businesses in the creative space (hypothetically):
    the music and movie industries.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们实现了一个生成模型，通过使用 LSTM 来生成内容。我们实现了适用于文本和音频的模型，假设它们为艺术家和创意领域的各类企业（如：音乐和电影产业）生成内容。
- en: 'What we learned in this chapter was the following:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中我们学到的内容如下：
- en: Text generation with LSTM
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 LSTM 进行文本生成
- en: The additional power of a Bi-directional LSTM for text generation
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 双向 LSTM 在文本生成中的附加功能
- en: Deep (multi-layer) LSTM to generate lyrics for a song
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度（多层）LSTM 用于生成歌曲歌词
- en: Deep (multi-layer) LSTM to generate the music for a song
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度（多层）LSTM 用于生成歌曲音乐
- en: This is some exciting work regarding deep learning, and it keeps on coming in
    the next chapter. Let's see what's in store!
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一些令人兴奋的关于深度学习的工作，并且它将在下一章继续展开。让我们看看接下来有什么内容！
