- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Correcting and Optimizing Your Generative AI Application
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修正和优化您的生成式AI应用
- en: Until this point, you’ve read about how to build a **generative AI** (**GenAI**)
    application, its various components, and how they fit together. You've gained
    a solid understanding of what makes them work (and not work) well. You’re also
    aware of some of the challenges of GenAI applications and how to identify them.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经阅读了如何构建**生成式AI**（**GenAI**）应用、其各种组件以及它们如何相互配合的内容。您已经对它们如何工作（以及如何不工作）有了坚实的理解。您也意识到了一些GenAI应用的挑战以及如何识别它们。
- en: In this chapter, you’ll begin unraveling the mystery of how to *improve* your
    GenAI application once you’ve identified its shortcomings. You will also learn
    about optimizing and fine-tuning your GenAI application, so it’s a reliable, effective,
    and stable machine working in your favor, instead of a rogue actor bringing chaos.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将开始揭开如何*改进*您的GenAI应用之谜，一旦您确定了其不足之处。您还将了解优化和微调您的GenAI应用，使其成为一个可靠、有效且稳定的机器，为您服务，而不是一个带来混乱的恶意行为者。
- en: This chapter will discuss several well-known techniques to improve your GenAI
    application, so you can be confident in your finished product. Ideally, you will
    perform all of these techniques. The chapter will define each of these and explain
    how they can improve your application. Then, you will complete a robust example
    of each of these as an activity. By the end of this chapter, you will have many
    ideas on how to improve your application.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将讨论几种提高您的GenAI应用效果的经典技术，以便您对自己的成品充满信心。理想情况下，您将执行所有这些技术。本章将定义这些技术并解释它们如何改进您的应用。然后，您将通过活动完成这些技术的稳健示例。到本章结束时，您将有许多关于如何改进您应用的想法。
- en: 'This chapter will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Baselining
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试
- en: Training and evaluation datasets
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和评估数据集
- en: Few-shot prompting
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 少样本提示
- en: Retrieval and reranking
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索和重排
- en: Late interaction strategies, including in-application feedback and user feedback
    loops
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 晚期交互策略，包括应用内反馈和用户反馈循环
- en: Query rewriting
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询重写
- en: Testing and red teaming
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试和红队行动
- en: Information post-processing
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息后处理
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter does not contain any coding. However, it builds upon all the previous
    chapters to describe various methodologies for improving and optimizing your GenAI
    application output. To recreate some of the examples, you’ll simply need to use
    your favorite **large language model** (**LLM**) provider and recreate the attempts
    yourself. This chapter uses ChatGPT.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章不包含任何编码。然而，它建立在所有前面的章节之上，描述了各种改进和优化您的GenAI应用输出的方法。要重现一些示例，您只需使用您最喜欢的**大型语言模型**（**LLM**）提供商并自行尝试即可。本章使用ChatGPT。
- en: Baselining
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准测试
- en: '**Baselining**, in the context of GenAI, refers to the process of defining
    a standard or a reference output for the AI model to compare future outputs. This
    standard serves as a crucial benchmark for evaluating the model’s performance,
    consistency, and improvements over time. By establishing a baseline, developers
    and stakeholders can objectively measure how the AI performs relative to a predefined
    set of expectations, ensuring that the model meets and maintains desired standards.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在GenAI的背景下，**基准测试**指的是为AI模型定义一个标准或参考输出，以便比较未来的输出。这个标准作为评估模型性能、一致性和随时间改进的关键基准。通过建立基准，开发人员和利益相关者可以客观地衡量AI相对于预定义的预期表现，确保模型达到并维持期望的标准。
- en: In GenAI, baselining is essential for several reasons. Firstly, it provides
    a clear metric for assessing the quality and performance of the AI model. Secondly,
    it helps in tracking the model’s progress and improvements over time. Finally,
    baselining is a tool to help ensure consistency in the model’s outputs, via detection
    of output variability. All of these are vital for maintaining reliability and
    trust in the AI system.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在GenAI中，基准测试对于以下几个原因至关重要。首先，它为评估AI模型的质量和性能提供了一个明确的指标。其次，它有助于跟踪模型随时间的进展和改进。最后，基准测试是帮助确保模型输出一致性的工具，通过检测输出变异性来实现。所有这些对于维护AI系统的可靠性和信任至关重要。
- en: 'The aspects of the AI model that can be baselined are numerous and highly dependent
    on the specific application and its goals. Some common elements that might be
    baselined include the following:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 可以进行基准测试的AI模型方面众多，且高度依赖于具体的应用及其目标。以下是一些可能进行基准测试的常见元素：
- en: '**Accuracy**: This involves measuring the correctness of the model’s outputs.
    For instance, in a language model, accuracy can be gauged by how well the generated
    text matches the expected text or how often it provides the correct information.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确性**：这涉及到衡量模型输出的正确性。例如，在语言模型中，准确性可以通过生成的文本与预期文本的匹配程度或提供正确信息的频率来衡量。'
- en: '**Speed of response**: This refers to the time it takes for the model to generate
    an output after receiving an input. Faster response times are generally preferred,
    especially in real-time applications.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**响应速度**：这指的是模型在接收到输入后生成输出所需的时间。通常，更快的响应时间更受欢迎，尤其是在实时应用中。'
- en: '**Effectiveness**: This can be a measure of how well the AI meets its intended
    purpose. For example, in a recommendation system, effectiveness might be assessed
    by the relevance and personalization of the recommendations provided.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有效性**：这可以衡量AI实现其预期目的的程度。例如，在推荐系统中，有效性可能通过提供的推荐的相关性和个性化来评估。'
- en: '**User satisfaction**: This subjective metric can be gauged through user feedback
    and surveys, reflecting how satisfied users are with the AI’s performance and
    outputs.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户满意度**：这个主观指标可以通过用户反馈和调查来衡量，反映用户对AI性能和输出的满意度。'
- en: Establishing a baseline standard alongside your current performance also helps
    you—the engineer—determine whether you are improving results over time. This knowledge
    is crucial for ensuring that your application is not degrading in performance.
    In some industries, baseline performance indicators may be required to meet industry
    or regulatory standards and may be a reporting requirement for your application
    or organization.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的当前性能旁边建立基线标准也有助于您——工程师——确定您是否随着时间的推移在提高结果。这种知识对于确保您的应用程序性能没有下降至关重要。在某些行业中，基线性能指标可能需要满足行业或监管标准，并且可能是您应用程序或组织的报告要求。
- en: Once you evaluate the initial performance of your application, you’ll want to
    document these results. Subsequently, ensure that you consistently compare the
    model’s outputs to the baseline during each training and update cycle. Comprehensive
    documentation provides a reference that can be used to compare future outputs
    and identify trends or issues in the model’s performance.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 评估您应用程序的初始性能后，您将希望记录这些结果。随后，确保您在每个训练和更新周期中持续将模型的输出与基线进行比较。全面的文档提供了可以用于比较未来输出并识别模型性能中的趋势或问题的参考。
- en: Regular evaluation of the model’s outputs against the baseline is also critical.
    During subsequent iterations of training and updates, these evaluations can help
    in detecting deviations from the expected (baseline) performance. If the model’s
    performance drops below the baseline, it can indicate a problem that needs to
    be addressed, such as data drift, changes in user behavior, or issues with the
    training dataset.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 定期评估模型输出与基线之间的差异也是至关重要的。在随后的训练和更新迭代中，这些评估有助于检测与预期（基线）性能的偏差。如果模型的性能低于基线，这可能表明需要解决的问题，例如数据漂移、用户行为变化或训练数据集问题。
- en: Training and evaluation datasets
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练和评估数据集
- en: To create your baseline, you will need to create an **evaluation dataset**.
    An evaluation dataset is a series of questions asked of your application to determine
    whether it meets the standards you have identified. Note that the evaluation dataset
    is not to be confused with the **training dataset**, which is the data that you
    used to *train* your model. The evaluation dataset should be a wholly different
    set of questions and answers. Effectively, the training dataset is akin to the
    notes and sources that you’d give to a student to learn, while the evaluation
    dataset is like the final exam. You don’t want to make that exam too easy!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建您的基线，您需要创建一个**评估数据集**。评估数据集是一系列针对您的应用程序提出的问题，以确定它是否满足您已确定的标准。请注意，评估数据集不应与**训练数据集**混淆，训练数据集是您用于**训练**模型的数据。评估数据集应是一组完全不同的问题和答案。实际上，训练数据集类似于您提供给学生的笔记和资料，而评估数据集则类似于期末考试。您不希望考试太容易！
- en: Training datasets
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练数据集
- en: As its name suggests, a training dataset is a collection of data used to teach
    or *train* a machine learning model. It contains input-output pairs where the
    input data is fed to the model, and the model learns to produce the correct output.
    This process involves adjusting the model’s parameters so that it can generalize
    well to new, unseen data. The quality and diversity of the training dataset directly
    impact the performance and accuracy of the trained model.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名所示，训练数据集是用于教授或**训练**机器学习模型的 数据集合。它包含输入-输出对，其中输入数据被输入到模型中，模型学习产生正确的输出。这个过程涉及调整模型的参数，以便它能够很好地泛化到新的、未见过的数据。训练数据集的质量和多样性直接影响训练模型的性能和准确性。
- en: High-quality training data ensures that the model can recognize patterns and
    make accurate predictions or generate appropriate responses. Therefore, your training
    dataset should be representative of the problem domain, covering a wide range
    of scenarios that the model would be expected to encounter in real-world applications.
    This helps in reducing biases and improving the model’s generalizability.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 高质量训练数据确保模型能够识别模式并做出准确的预测或生成适当的响应。因此，您的训练数据集应代表问题域，涵盖模型在现实世界应用中预期会遇到的各种场景。这有助于减少偏差并提高模型的泛化能力。
- en: 'The types of data in the training dataset might include the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集中的数据类型可能包括以下内容：
- en: '**Labeled data**: This is the primary type of data used in supervised learning.
    Each data point consists of an input and a corresponding correct output, or label.
    For instance, in a text classification task, labeled data might include sentences
    paired with their respective categories.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标记数据**：这是监督学习中使用的主要数据类型。每个数据点都包含一个输入和一个相应的正确输出，或标签。例如，在文本分类任务中，标记数据可能包括句子及其相应的类别。'
- en: '**Unlabeled data**: Used in unsupervised learning, this data does not come
    with predefined labels. The model tries to find patterns and structures in the
    data. For example, clustering algorithms use unlabeled data to group similar data
    points together.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未标记数据**：在无监督学习中使用，这种数据没有预定义的标签。模型试图在数据中找到模式和结构。例如，聚类算法使用未标记数据将相似的数据点分组在一起。'
- en: '**Mixed data**: Semi-supervised learning uses a combination of labeled and
    unlabeled data. This approach leverages the large amounts of unlabeled data available
    while benefiting from the smaller labeled dataset to guide the learning process.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合数据**：半监督学习结合了标记和未标记数据。这种方法利用了大量的未标记数据，同时从较小的标记数据集中受益，以指导学习过程。'
- en: '**Diverse data**: Including diverse data ensures that the model can handle
    various inputs. This might include different languages, dialects, formats, and
    contexts. For certain types of applications, this might include training data
    that is both human-readable documentation as well as code bases.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多样化数据**：包括多样化数据确保模型可以处理各种输入。这可能包括不同的语言、方言、格式和上下文。对于某些类型的应用，这可能包括既有人可读的文档又包括代码库的训练数据。'
- en: 'Despite all that, you might wish to also include **supplemental training data**.
    Supplemental training data refers to additional data used to fine-tune or enhance
    the performance of an already trained model. There are many reasons to do this,
    but let’s talk about three that are particularly compelling:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，您可能还希望包括**补充训练数据**。补充训练数据是指用于微调或增强已训练模型性能的附加数据。有许多原因要做这件事，但让我们谈谈其中三个特别有说服力的原因：
- en: Supplemental data can help adapt a general model to a specific domain. For example,
    a language model trained on general text might be fine-tuned with medical literature
    to perform better in healthcare applications.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 补充数据可以帮助将通用模型适应特定领域。例如，在通用文本上训练的语言模型可以通过医学文献进行微调，以在医疗应用中表现更好。
- en: Supplemental training data can be used to enhance the model’s ability in particular
    areas where it might be weak. For example, adding more data related to financial
    transactions can help a fraud detection model become more accurate.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 补充训练数据可以用来增强模型在可能较弱的特定领域的功能。例如，添加更多与金融交易相关的数据可以帮助欺诈检测模型变得更加准确。
- en: As new information becomes available, supplemental training data can be used
    to update the model’s knowledge. This is especially relevant for applications
    requiring up-to-date information, such as news generation or where the industry
    is rapidly evolving (such as technology).
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着新信息的出现，补充训练数据可以用来更新模型的知识。这对于需要最新信息的应用尤其相关，例如新闻生成或行业快速发展的领域（如技术）。
- en: Evaluation datasets
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估数据集
- en: In addition to your training data and supplemental data, you’ll also need an
    evaluation dataset. Evaluation datasets are crucial because they provide a controlled
    and consistent way to measure the performance of your AI model. They serve as
    a benchmark for comparison, ensuring that the model’s outputs can be objectively
    assessed against predefined criteria. By using a standard dataset, you can reliably
    track improvements, identify weaknesses, and maintain the quality of the model
    over time. It helps in validating that the model is not only performing well during
    the development phase but also generalizing effectively to new, unseen data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 除了您的训练数据和补充数据之外，您还需要一个评估数据集。评估数据集至关重要，因为它们提供了一种受控和一致的方式来衡量AI模型的表现。它们作为比较的基准，确保模型输出可以客观地与预定义的标准进行比较。通过使用标准数据集，您可以可靠地跟踪改进、识别弱点，并随着时间的推移保持模型的质量。这有助于验证模型不仅在开发阶段表现良好，而且能够有效地推广到新的、未见过的数据。
- en: 'The content of an evaluation dataset depends on the specific application and
    its goals. Generally, it should include the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 评估数据集的内容取决于具体的应用及其目标。通常，它应包括以下内容：
- en: '**Representative queries**: A variety of questions or inputs that the AI is
    likely to encounter in real-world usage. These should cover different scenarios
    and edge cases to ensure a comprehensive evaluation.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代表性查询**：AI在现实世界使用中可能遇到的各种问题或输入。这些应该涵盖不同的场景和边缘情况，以确保全面的评估。'
- en: '**Expected outputs**: Corresponding correct or ideal responses for each query,
    against which the AI’s responses will be compared.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预期输出**：对应于每个查询的正确或理想响应，这些响应将用于与AI的响应进行比较。'
- en: '**Diverse data**: Data that reflects the diversity of inputs the model will
    face, including variations in language, format, and context. This helps in assessing
    the model’s robustness and ability to handle different types of input.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多样化数据**：反映模型将面临的各种输入的数据，包括语言、格式和上下文的变化。这有助于评估模型的鲁棒性和处理不同类型输入的能力。'
- en: 'For example, the evaluation dataset for the MongoDB documentation chatbot includes
    questions and answers to the top 250 search terms, top 250 support questions by
    volume, and some of the most common questions asked about MongoDB. This can take
    the form of simple keywords or actual phrases in full-sentence format, like so:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，MongoDB文档聊天机器人的评估数据集包括针对前250个搜索术语、前250个按数量排序的支持问题和关于MongoDB的一些最常见问题的问答。这可以采取简单的关键词或完整的句子格式，如下所示：
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: These terms and questions were retrieved from a combination of sources, which
    will vary depending on your infrastructure. For MongoDB, this infrastructure comes
    from the Google search console for [mongodb.com](http://mongodb.com) as well as
    the support chat, community forums, and Stack Overflow.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这些术语和问题是从多个来源检索的，具体取决于您的基础设施。对于MongoDB，这些基础设施来自[mongodb.com](http://mongodb.com)的Google搜索控制台，以及支持聊天、社区论坛和Stack
    Overflow。
- en: Determining the right amount of evaluation involves balancing thoroughness with
    practicality. You should have enough data to cover a wide range of scenarios and
    ensure the outputs of your GenAI application are consistently accurate and reliable.
    Typically, this involves hundreds or even thousands of data points, depending
    on the complexity of the application.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 确定合适的评估数据量需要平衡彻底性和实用性。您应该有足够的数据来覆盖广泛的场景，并确保您的GenAI应用的输出始终准确可靠。通常，这涉及数百甚至数千个数据点，具体取决于应用的复杂性。
- en: That said, while more data can provide a more comprehensive assessment, there
    is a point of diminishing returns where additional data does not significantly
    improve the evaluation but adds to the complexity and resource requirements. **Over-evaluation**
    can also lead to overfitting of the evaluation dataset rather than improving overall
    performance. Returning to the earlier student/exam analogy, you don’t want your
    evaluation exam to be an exact replica of the training materials because all you
    would be testing then is whether the student was able to memorize a question and
    response. You would not be testing how well the student has learned the material.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，虽然更多的数据可以提供更全面的评估，但存在一个收益递减的点，即额外的数据不会显著提高评估，但会增加复杂性和资源需求。**过度评估**也可能导致评估数据集过度拟合，而不是提高整体性能。回到之前的学生/考试类比，你不想你的评估考试是训练材料的精确复制品，因为那时你只是在测试学生是否能够记住一个问题及其回答。你不会测试学生掌握材料的情况。
- en: In summary, ensuring high-quality, accurate, and comprehensive training and
    evaluation datasets can reduce the likelihood of the model learning incorrect
    patterns. This requires significant effort upfront before deployment of the GenAI
    application but can dramatically improve your GenAI accuracy and depth of response
    as well as ensure its quality of responses to your users.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，确保高质量的、准确的和全面的训练和评估数据集可以降低模型学习错误模式的可能性。这需要在部署GenAI应用之前投入大量努力，但可以显著提高你的GenAI准确性和响应的深度，以及确保其响应质量。
- en: Few-shot prompting
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Few-shot提示
- en: In many cases, you will be asking your GenAI application to produce new content
    or summarize existing content, in which case what you need to do is provide the
    existing application with a properly engineered prompt. Most of the time, having
    the user simply request what they need is sufficient. But in cases where the outputs
    are complex, you will find that the quality and accuracy of the GenAI application’s
    response are improved by using a technique called **few-shot prompting**. Few-shot
    prompting is when you provide an example as part of the input to the LLM so that
    it can see exactly what type of syntax and response you need. You can also include
    a definition as part of the example in case you believe the input might be a term
    with which the LLM would not be familiar, or in case you’re using a business-specific
    term.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，你会要求你的GenAI应用生成新内容或总结现有内容，在这种情况下，你需要做的是向现有应用提供正确设计的提示。大多数时候，用户简单地请求他们需要的内容就足够了。但在输出复杂的情况下，你会发现使用一种称为**few-shot提示**的技术可以改善GenAI应用的响应质量和准确性。Few-shot提示是指你将示例作为LLM输入的一部分提供，以便它可以看到你确切需要什么类型的语法和响应。如果你认为输入可能是一个LLM不熟悉的术语，或者你正在使用特定于业务的术语，你还可以在示例中包含一个定义。
- en: Let’s try out an example using GPT-4.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一个GPT-4的例子来试一试。
- en: '**Example 1**: Let’s see how the LLM responds to a request that does not use
    few-shot prompting.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 1**：让我们看看LLM对未使用few-shot提示的请求如何响应。'
- en: 'This is the user input:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用户输入：
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here is the output:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '[PRE2]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Example 2**: Now, let’s try this example with few-shot prompting.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2**：现在，让我们尝试使用few-shot提示的例子。'
- en: 'This is the user input:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这是用户输入：
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here is the output:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是输出：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can see how, by providing the example text, you can enhance the output to
    make it match whatever syntax you prefer. The additional prompt information need
    not be terribly difficult to produce either. If you can provide an example output
    to your GenAI application, its results will be much nearer to what you desire.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，通过提供示例文本，你可以增强输出以匹配你偏好的任何语法。额外的提示信息也不需要特别困难来生成。如果你能向你的GenAI应用提供示例输出，其结果将更接近你期望的。
- en: Retrieval and reranking
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检索和重排序
- en: Retrieval and reranking are key techniques used to enhance the performance and
    accuracy of LLMs. First, understand that by retrieving relevant context or documents,
    an LLM provides more accurate and contextually relevant responses. This is particularly
    useful when the model’s training data does not cover the specifics of the query
    or when up-to-date information is required.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 检索和重排序是用于增强LLM性能和准确性的关键技术。首先，要明白通过检索相关上下文或文档，LLM可以提供更准确和上下文相关的响应。这在模型训练数据未涵盖查询的具体内容或需要最新信息时尤其有用。
- en: 'In the context of LLMs, **retrieval** can involve searching through a vast
    collection of documents, knowledge bases, or other data sources to find pieces
    of information that are pertinent to a given query or task. Let’s have a look
    at the two different types of retrieval:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LLM 的背景下，**检索**可能涉及在大量文档、知识库或其他数据源中进行搜索，以找到与特定查询或任务相关的信息片段。让我们看看两种不同的检索类型：
- en: '`cars` in your query, it returns documents that contain the word *cars*.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在你的查询中包含 `cars`，它会返回包含单词 *cars* 的文档。
- en: '**Embedding-based retrieval**: This uses vector embeddings to find matching
    documents. Both the query and documents are transformed into vectors in a high-dimensional
    space. Retrieval then involves finding vectors (that is, documents) that are close
    to the query vector.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于嵌入的检索**：这使用向量嵌入来找到匹配的文档。查询和文档都被转换成高维空间中的向量。检索涉及找到接近查询向量的向量（即文档）。'
- en: '**Reranking** is the process of reordering the retrieved documents or pieces
    of information to prioritize the most relevant ones. After the initial retrieval,
    the documents are ranked based on their relevance to the query. Retrieved documents
    are initially ranked based on their similarity to the query using methods such
    as cosine similarity in embedding space. However, a more sophisticated model can
    rerank these initially retrieved documents by considering additional features
    and context.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**重新排序**是重新排列检索到的文档或信息片段的过程，以优先考虑最相关的内容。在初始检索之后，文档根据其与查询的相关性进行排名。检索到的文档最初根据其在嵌入空间中的相似性（例如，使用余弦相似度）与查询进行排名。然而，一个更复杂的模型可以通过考虑额外的特征和上下文来重新排序这些最初检索到的文档。'
- en: Let’s look at the following examples.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看以下示例。
- en: '**Example 1**: Recommending restaurants with a GenAI application.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 1**：使用 GenAI 应用推荐餐厅。'
- en: You have built a GenAI application that provides restaurant recommendations.
    A user requests restaurants currently open near them. When examining the potential
    restaurants to provide to the user, the application looks at the distance from
    the user’s current location or provided address and the current local time and
    opening hours.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经构建了一个 GenAI 应用程序，该程序提供餐厅推荐。用户请求附近的当前营业的餐厅。在检查提供给用户的潜在餐厅时，应用程序会查看用户当前位置或提供的地址与当前本地时间和营业时间之间的距离。
- en: It will then rank the results so that the closest restaurant is the first one
    shown to the user. This is a perfectly fine solution. But you may want to have
    smarter results that are dynamically reranked based on other criteria, such as
    user ratings for the restaurants. You may want to show a higher-rated restaurant
    that is three miles away first, rather than a one-star restaurant that is one
    mile away. As the user gives feedback on the results, you may want to rerank dynamically,
    expanding your pool of restaurants as you get more information about what the
    user would prefer (including, say, the type of cuisine or ambiance).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它会根据结果进行排名，使得最近的餐厅首先显示给用户。这是一个完全可行的解决方案。但你可能希望得到更智能的结果，这些结果可以根据其他标准动态重新排序，例如餐厅的用户评分。你可能希望首先显示一个距离三英里远的评分较高的餐厅，而不是一个距离一英里远的评分为一星的餐厅。随着用户对结果的反馈，你可能希望动态重新排序，随着你获得更多关于用户偏好的信息（包括，比如说，菜系或氛围），扩大你的餐厅选择范围。
- en: By reranking the results, the most relevant and useful information is prioritized,
    improving the overall quality of the LLM’s output. It helps in filtering out less
    relevant or redundant information, ensuring the response is precise and useful.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通过重新排序结果，最相关和有用的信息被优先考虑，从而提高了 LLM 输出的整体质量。它有助于过滤掉不那么相关或冗余的信息，确保响应精确且有用。
- en: 'When combined, retrieval and reranking significantly enhance LLM outputs with
    the following:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当结合检索和重新排序时，可以显著增强 LLM 的输出，具体如下：
- en: The model can access and utilize relevant information that might not be present
    in its training data, providing more accurate and contextually appropriate answers.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型可以访问并利用其训练数据中可能不存在的相关信息，提供更准确和上下文相关的答案。
- en: By focusing on the most relevant information through reranking, the model’s
    responses become more precise, reducing errors and irrelevant content.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过通过重新排序来关注最相关的信息，模型的响应变得更加精确，减少了错误和不相关的内容。
- en: Retrieval can pull in the latest information from updated sources, making the
    model’s responses more current.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索可以从更新的来源中提取最新信息，使模型的响应更加及时。
- en: These techniques allow the model to handle specific, detailed queries efficiently
    without needing to retrain the entire model frequently.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些技术使模型能够高效地处理特定、详细的查询，而无需频繁重新训练整个模型。
- en: '**Example 2**: Summarizing the latest research on quantum computing.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例 2**：总结量子计算的最新研究。'
- en: 'Here’s another practical example. Suppose you ask an LLM about the latest research
    on quantum computing. The steps of the output would be as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有一个实际例子。假设您询问LLM关于量子计算的最新研究。输出步骤如下：
- en: '**Retrieval**: The model searches through a large database of scientific papers
    and articles to find relevant documents on quantum computing.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检索**：该模型通过搜索大量科学论文和文章的数据库来找到关于量子计算的相关文档。'
- en: '**Reranking**: The initially retrieved documents are then reranked, with the
    most recent and pertinent studies placed at the top.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**重排序**：最初检索到的文档随后被重新排序，最新的和最相关的研究被置于顶部。'
- en: '**Response generation**: The LLM uses the top-ranked documents to generate
    a detailed and accurate response about the latest research trends in quantum computing.'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**响应生成**：LLM使用排名最高的文档来生成关于量子计算最新研究趋势的详细和准确响应。'
- en: By incorporating retrieval and reranking, the LLM can provide a well-informed,
    up-to-date, and contextually accurate answer, vastly improving the user experience.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合检索和重排序，LLM可以提供信息丰富、最新和上下文准确的答案，极大地改善了用户体验。
- en: Late interaction strategies
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 后期交互策略
- en: Now that you’re ready to take your application into production, there are still
    a few more things you can do to help improve the user experience and create a
    feedback loop in order to get a better signal as to the behavior of your GenAI
    application. This next set of recommendations focuses on **late interaction strategies**,
    sometimes referred to as **contextualized late interaction over** **BERT** (**ColBERT**).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您准备将应用程序投入生产，还有一些事情可以做来帮助改善用户体验并创建反馈循环，以便更好地了解您的GenAI应用程序的行为。这些建议的下一组重点在于**后期交互策略**，有时也称为**BERT上的上下文化后期交互**（**ColBERT**）。
- en: First, let’s define **interaction**. Interaction refers to the process of evaluating
    the relevance between a query and a document by comparing their representations.
    A late processing strategy is one where the interaction between the query and
    document representations occurs later in the process, typically after both have
    been independently encoded. Early interaction models are where query and document
    embeddings interact at earlier stages, typically before or during their encoding
    by the model.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们定义**交互**。交互是指通过比较查询和文档的表示来评估查询与文档之间相关性的过程。后期处理策略是指在处理过程中较晚发生查询和文档表示之间的交互，通常是在它们被独立编码之后。早期交互模型是在查询和文档嵌入在早期阶段交互，通常是在模型编码之前或编码期间。
- en: Second, let’s dig a little bit into the internal workings. When a user interacts
    with a GenAI application, they input a query that is encoded into a dense vector
    representation. Potential responses, usually documents or passages, are also encoded
    into dense vector representations. The system performs similarity matching between
    the query and document embeddings, returning the documents with the highest similarity
    scores as the best matches.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，让我们深入了解一下其内部工作原理。当用户与GenAI应用程序交互时，他们输入一个查询，该查询被编码成一个密集向量表示。潜在响应，通常是文档或段落，也被编码成密集向量表示。系统在查询和文档嵌入之间执行相似度匹配，返回相似度得分最高的文档作为最佳匹配。
- en: To enhance relevance, you don’t return all matching results to the user. Instead,
    you aim to provide the most relevant results or a summarized version of the result
    set. Late interaction models such as ColBERT improve efficiency by focusing on
    the most promising query-document pairs rather than considering all possible pairs,
    yielding more precise results and a better user experience. This selective approach
    allows for more precise and relevant results, enhancing the user experience.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高相关性，您不会向用户返回所有匹配结果。相反，您旨在提供最相关的结果或结果集的总结版本。ColBERT等后期交互模型通过专注于最有希望的查询-文档对，而不是考虑所有可能的组合，从而提高效率，产生更精确的结果和更好的用户体验。这种选择性的方法可以提供更精确和相关的结果，从而提升用户体验。
- en: If you need to focus on improving search results, consider implementing ColBERT
    or similar techniques to enhance retrieval performance and provide more relevant
    results for user queries.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要专注于提高搜索结果，考虑实现ColBERT或类似技术来增强检索性能，并为用户查询提供更相关的结果。
- en: Query rewriting
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询重写
- en: '**Query rewriting**, or **query reformulation**, is a technique used to improve
    the quality of the answers provided by LLMs. This process involves modifying the
    original query to make it clearer, more specific, or more detailed, which can
    help the model generate better responses. LLMs do not explicitly rewrite queries
    in the background, so this effort is manual unless you have implemented a workflow
    that will evaluate and rewrite the user’s query before it’s processed.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**查询重写**，或**查询重构**，是一种用于提高LLM（大型语言模型）提供答案质量的技巧。这个过程涉及修改原始查询，使其更清晰、更具体或更详细，这有助于模型生成更好的响应。LLMs不会在后台明确重写查询，因此除非你实现了在处理之前评估和重写用户查询的工作流程，否则这项工作将是手动的。'
- en: Rewriting a query can make it clearer and more precise, reducing ambiguity and
    ensuring the model understands exactly what is being asked. Adding relevant context
    or details to the query can help the model provide more accurate and contextually
    appropriate answers and can help disambiguate terms that have multiple meanings,
    ensuring the response aligns with the intended meaning. In addition, reformulating
    the query to include additional relevant details can lead to more comprehensive
    answers.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 重写查询可以使它更清晰、更精确，减少歧义，并确保模型确切地理解了被询问的内容。向查询中添加相关上下文或细节可以帮助模型提供更准确和上下文相关的答案，并有助于消除具有多个含义的术语的歧义，确保响应与预期意义一致。此外，重构查询以包含更多相关细节可以导致更全面的答案。
- en: How does query rewriting work? It’s important to understand user intent for
    your GenAI application. What is the *purpose* of your application, and what kinds
    of questions will your application attempt to answer? Understanding what sort
    of response users expect versus what your application might deliver is key. After
    that, you can do the following activities, which are not mutually exclusive, meaning
    that you can perform some, just one, or none of these.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 查询重写是如何工作的？了解你的GenAI（生成式人工智能）应用程序的用户意图非常重要。你的应用程序的**目的**是什么，它将尝试回答哪些类型的问题？了解用户期望得到的响应与你的应用程序可能提供的响应之间的差异是关键。之后，你可以进行以下活动，这些活动不是相互排斥的，这意味着你可以执行一些、一个或全部这些活动。
- en: For instance, based on the **intent**, the user query can be augmented with
    additional **context** and details. This activity substantially expands the user
    query (and increases the token count per query) but will typically yield much
    better results.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，基于**意图**，用户查询可以通过添加额外的**上下文**和细节来增强。这项活动极大地扩展了用户查询（并增加了每个查询的令牌计数），但通常会得到更好的结果。
- en: To take an easy example, imagine that your application generates images. The
    user requests `a picture of a kitten`, a quite simple query that could have endless
    results.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 以一个简单的例子来说明，假设你的应用程序生成图像。用户请求“一张小猫的图片”，这是一个相当简单的查询，可能有无穷无尽的结果。
- en: 'To help the user get better results, you can add three buttons in the UI so
    that the user can select a `a picture of a kitten`, the query is modified to the
    following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助用户获得更好的结果，你可以在用户界面中添加三个按钮，以便用户可以选择“一只小猫的图片”，查询被修改为以下内容：
- en: '[PRE5]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, for each button style, you can add the terms that augment the user query
    and then apply them before submission.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，对于每种按钮样式，你可以在提交前添加增强用户查询的术语。
- en: 'As another example, consider this user query:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个例子，考虑以下用户查询：
- en: '[PRE6]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'A meaningful rewrite could be as follows:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 有意义的重写可能如下所示：
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This rewritten query with additional context helps the system understand that
    the user is asking for a specific product and time period, leading to a more accurate
    and useful response.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这个添加了额外上下文的重写查询有助于系统理解用户正在请求特定产品和时间段，从而得到更准确和有用的响应。
- en: Ultimately, when conducting query rewrites, you’ll want to **simplify the language**.
    Complex queries can be simplified or broken down into simpler parts, making it
    easier for the model to process and respond accurately. This method involves taking
    a large query and breaking it into constituent parts (which typically is achieved
    via a series of input fields/forms) and then unifying each data entry into a single
    submitted query. This guides your user into constructing a well-formed query without
    specialized knowledge.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，在进行查询重写时，你希望**简化语言**。复杂的查询可以被简化或分解成更简单的部分，使模型更容易处理并准确响应。这种方法涉及将大型查询分解为其组成部分（通常通过一系列输入字段/表单实现），然后将每个数据条目统一为一个提交的查询。这指导用户构建一个没有专业知识的良好格式查询。
- en: As an example, imagine your user has only a single-entry field to input their
    query. In such a case, they may leave out relevant information or provide irrelevant
    information that could impact accuracy or increase the possibility of hallucination.
    Instead, if you were to provide the user with a series of fields, each with clear
    instructions, and then assemble the inputted information into a query that was
    fed into the GenAI application, you would get a better outcome than a free-form
    text entry.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你的用户只有一个输入字段来输入他们的查询。在这种情况下，他们可能会遗漏相关信息或提供可能影响准确性或增加幻觉可能性的无关信息。相反，如果你为用户提供一系列字段，每个字段都有明确的说明，然后将输入的信息组装成一个查询，该查询被输入到GenAI应用中，你会得到比自由文本输入更好的结果。
- en: For practical implementation, you could consider a workflow in which the system
    itself analyzes the query for intent and context, reviews the query’s complexity,
    and then rewrites the query to be clearer, more specific, or more detailed. The
    reformulated query can then be used to generate the response.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实际实施，你可以考虑一个工作流程，其中系统本身分析查询的意图和上下文，审查查询的复杂性，然后将查询重写得更清晰、更具体或更详细。重写的查询可以用来生成响应。
- en: Testing and red teaming
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试和红队行动
- en: Testing AI systems is critical to ensure their accuracy, reliability, and overall
    performance. Typically, in software engineering, automated testing is used as
    part of the software development process. GenAI applications are no different.
    You’ll want to routinely and regularly test the outputs to ensure there are no
    radical shifts in output quality.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 测试AI系统对于确保它们的准确性、可靠性和整体性能至关重要。通常，在软件工程中，自动化测试被用作软件开发过程的一部分。GenAI应用也不例外。你希望定期和定期测试输出，以确保输出质量没有发生重大变化。
- en: Testing
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试
- en: Just like your typical software engineering features, you’ll want to include
    the phases of unit testing, integration testing, performance testing, and user
    acceptance into your test plan. However, the specifics of how this is done vary
    from one use case to another.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 就像你典型的软件工程特性一样，你希望在测试计划中包括单元测试、集成测试、性能测试和用户验收测试的阶段。然而，具体做法因用例而异。
- en: 'In the context of GenAI applications, **unit testing** still has the same basic
    tenets and involves testing individual components or modules of the application
    to ensure they function correctly. However, in the case of GenAI applications,
    your unit tests will need to also include steps such as the following:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在GenAI应用的背景下，**单元测试**仍然遵循相同的基本原则，涉及测试应用程序的各个组件或模块以确保它们能正确运行。然而，在GenAI应用的情况下，你的单元测试还需要包括以下步骤：
- en: '**Input validation**: Ensure that the application correctly handles and validates
    various input types, formats, and ranges. Test for edge cases, such as empty inputs,
    excessively large inputs, or malformed data.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入验证**：确保应用程序正确处理和验证各种输入类型、格式和范围。测试边缘情况，如空输入、过大输入或不规范数据。'
- en: '**Pre-processing**: Verify that any pre-processing steps, such as tokenization,
    normalization, or feature extraction, are performed correctly.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预处理**：验证任何预处理步骤，如分词、归一化或特征提取，是否正确执行。'
- en: '**Model loading**: Test that the model is correctly loaded from its storage
    location, and verify that the correct version is being used.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型加载**：测试模型是否正确从其存储位置加载，并验证是否使用了正确的版本。'
- en: '**Model inference**: Ensure that the model generates outputs without errors
    given valid inputs. Test the inference function with controlled inputs to verify
    expected behavior, such as deterministic responses for certain prompts or scenarios.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型推理**: 确保模型在给定有效输入的情况下能够生成无错误的输出。通过受控输入测试推理函数以验证预期的行为，例如对于某些提示或场景的确定性响应。'
- en: '**Output format**: Validate that the generated outputs meet the expected format
    and structure. This includes checking that outputs are complete, correctly formatted,
    and adhere to any length or content constraints.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出格式**: 验证生成的输出是否符合预期的格式和结构。这包括检查输出是否完整、格式正确，并遵守任何长度或内容限制。'
- en: '**Post-processing**: Test any post-processing steps that modify or enhance
    the model’s output, such as cleaning up text, converting formats, or applying
    additional business logic.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**后处理**: 测试任何修改或增强模型输出的后处理步骤，例如清理文本、转换格式或应用额外的业务逻辑。'
- en: '**Proper functioning**: The outputs should work. If your GenAI application
    outputs code, you will need to test that the code itself compiles and behaves
    as intended.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正常功能**: 输出应该正常工作。如果你的 GenAI 应用程序输出代码，你需要测试代码本身是否能够编译并且按照预期行为执行。'
- en: These are just a few of the items that you should include for unit testing your
    GenAI application.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是你应该包括在单元测试你的 GenAI 应用程序中的几个项目。
- en: '**Integration testing** focuses on verifying that the components of your GenAI
    system work together as needed. This means you’ll be testing the interactions
    between components to check the following:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**集成测试**侧重于验证你的 GenAI 系统的组件是否按需协同工作。这意味着你将测试组件之间的交互，以检查以下内容：'
- en: Whether your data ingestion pipeline pulls the correct data
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否你的数据摄取管道拉取了正确的数据
- en: How recommendations are presented to the user (formatting, for instance, if
    this is done by another library or tool)
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何向用户展示推荐（例如，格式化，如果这是由另一个库或工具完成的）
- en: API load testing, if you’re using another LLM such as OpenAI or Anthropic
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你使用的是 OpenAI 或 Anthropic 等其他 LLM，进行 API 负载测试。
- en: 'You’ll want to evaluate processing time, efficiency, and scalability via **performance
    testing**. This might include activities such as the following:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 你将通过**性能测试**评估处理时间、效率和可扩展性。这可能包括以下活动：
- en: Load testing your application for how it handles a large volume of simultaneous
    queries.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试你的应用程序如何处理大量并发查询的负载。
- en: Assessing the inference time of self-hosted models on various hardware configurations.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估自托管模型在不同硬件配置下的推理时间。
- en: Measuring how many token limits should be set for input and output to control
    costs and processing time.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量输入和输出应该设置多少令牌限制以控制成本和处理时间。
- en: Measuring the time taken for the model to generate outputs and ensuring it meets
    performance requirements. This can be especially important for applications with
    real-time constraints.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测量模型生成输出所需的时间，并确保它符合性能要求。这对于具有实时约束的应用程序尤为重要。
- en: 'In addition to this routine testing, you have more to add to your test suite.
    In general, it is also recommended that GenAI applications go through **additional
    testing** for the following:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这个常规测试之外，你还需要为你的测试套件添加更多内容。一般来说，也建议 GenAI 应用程序进行以下**额外测试**：
- en: '**Bias and fairness**: If your model is making recommendations that affect
    lives and livelihoods, you’ll want to carefully consider training data biases
    for different demographic groups.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**偏差和公平性**: 如果你的模型做出的推荐会影响生活和生计，你将需要仔细考虑不同人口群体的训练数据偏差。'
- en: '**Robustness**: To ensure your GenAI application is resilient to variations
    and noise, you’ll want to test with adversarial examples and edge cases to evaluate
    its ability to handle unexpected inputs.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**鲁棒性**: 为了确保你的 GenAI 应用程序能够抵抗变化和噪声，你需要使用对抗性示例和边缘情况来测试，以评估其处理意外输入的能力。'
- en: Once you’ve gotten through all of that, you’ll want to think about **user acceptance
    testing**, which is one of the most exciting parts of the process, as you will
    see in the next section.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你完成了所有这些，你将想要考虑**用户验收测试**，这是流程中最激动人心的部分，你将在下一节中看到。
- en: Red teaming
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 红队攻击
- en: If your GenAI application will accept natural language prompts and inputs from
    human beings, then the practice of **red teaming** cannot be recommended enough.
    Red teaming involves simulating real-world, challenging, or adversarial situations
    to identify vulnerabilities and weaknesses in your GenAI application. This approach
    is borrowed from cybersecurity practices and is particularly important for ensuring
    your GenAI application meets user expectations.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的GenAI应用将接受来自人类的自然语言提示和输入，那么强烈推荐进行**红队测试**。红队测试涉及模拟现实世界、具有挑战性或对抗性的情况，以识别你的GenAI应用中的漏洞和弱点。这种方法借鉴了网络安全实践，对于确保你的GenAI应用满足用户期望尤为重要。
- en: This involves having a large pool of *users* who will ask real-world questions,
    but they are not limited by *scripts* as to what they may ask. The reason for
    red teaming is that GenAI applications can, and often do, produce different outputs
    that vary widely, even with similar or the same input. Not only that but the quality
    of the generated output is often subjective and depends on human judgment. So,
    while traditional software applications produce predictable and consistent results,
    the same is not true of GenAI. Let’s take an example to see how this works.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及到拥有一个大量用户池，他们会提出现实世界的问题，但他们不受**脚本**的限制，不知道可以问什么。进行红队测试的原因是GenAI应用可以，并且经常会产生不同的输出，即使输入相似或相同，输出也会有很大的差异。不仅如此，生成的输出质量往往是主观的，取决于人类判断。因此，虽然传统软件应用会产生可预测和一致的结果，但GenAI并非如此。让我们通过一个例子来看看这是如何工作的。
- en: 'For a chatbot application, you might have routine automated testing that would
    ask your GenAI application the top 200 most common user questions and then evaluate
    them for correctness. With a red team, you would have 50 users ask whatever questions
    they wanted, and then record both the questions asked and the responses. This
    might yield insights such as the following:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对于聊天机器人应用，你可能会有常规的自动化测试，它会向你的GenAI应用提出最常问的200个问题，然后评估它们的正确性。使用红队，你会让50个用户提出他们想问的任何问题，并记录下提出的问题和回答。这可能会产生以下见解：
- en: If a user asks a question in a similar way but not with the exact same wording,
    they receive incorrect or less correct answers.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果用户以类似的方式提出问题，但不是用完全相同的措辞，他们就会收到不正确或不那么正确的答案。
- en: Some users will ask malicious questions and the GenAI application will respond
    poorly.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些用户会提出恶意问题，而GenAI应用会做出较差的回应。
- en: Other users ask questions that are not part of the training data, and the GenAI
    application hallucinates answers (or gives no answer at all), thus identifying
    the need to expand your training data.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他用户提出的问题不在训练数据中，GenAI应用会胡编乱造答案（或者根本不回答），从而识别出需要扩展训练数据的必要性。
- en: When users ask many questions in a row, the application stalls.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当用户连续提出许多问题时，应用会卡住。
- en: When a user asks specific question types, they are dissatisfied with the output
    because the application lacks high-quality training data or the formatting of
    the reply is undesirable.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当用户提出特定类型的问题时，他们会对输出感到不满意，因为应用缺乏高质量的训练数据，或者回复的格式不理想。
- en: When properly prompted, the GenAI application will share details of other users’
    sessions, thus identifying a security issue.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当得到适当的提示时，GenAI应用会分享其他用户会话的细节，从而识别出安全问题。
- en: To enable the red-teaming phase, it is recommended that you record every question
    asked by every user, as well as every response given, and then ask testers to
    rate the response with notes. While this level of detailed user testing is strenuous
    and uncommon in software development, it is incredibly valuable to see how your
    application performs in real-world scenarios, with real human beings, before production.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启用红队测试阶段，建议你记录下每个用户提出的每个问题以及每个给出的回答，然后要求测试者对回答进行评分并附上备注。虽然这种详细程度的用户测试在软件开发中既费力又罕见，但在产品发布前看到你的应用在现实场景中、与真实人类互动的表现，却具有极高的价值。
- en: Due to the scale and scope of some AI systems, fully testing each component
    is impossible. Effective testing and red teaming rely on using judgment in terms
    of which parts of the system are most risky. It may be true that giving occasionally
    not-quite-accurate advice is a non-impactful event. However, the potential harm
    of a single hallucination could be quite high. You will want to consider the severity
    of harm, the likelihood of inaccuracy, and the ability to retract or rectify the
    inaccuracy as your standard measures of risk. Using those simple, albeit subjective,
    measures can assist you in determining to what extent you test each aspect of
    the system, and the size of your red team.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 由于某些人工智能系统的规模和范围，全面测试每个组件是不可能的。有效的测试和红队行动依赖于对系统哪些部分风险最高的判断。偶尔给出不太准确的建议可能是一个无足轻重的事件。然而，单个幻觉的潜在危害可能相当高。您将需要考虑危害的严重性、不准确性的可能性以及撤回或纠正不准确性的能力，作为您衡量风险的标准措施。使用这些简单但主观的措施可以帮助您确定测试系统每个方面的程度以及您红队的大小。
- en: To give yourself a sense of what sorts of harms and incidents you will be testing
    for—which are too many to enumerate—you will find it helpful to review the AI
    Incident Database at [https://incidentdatabase.ai/](https://incidentdatabase.ai/).
    Upon review of this tool, you may find your specific use case (or ones like it)
    and what incidents have already been reported, so that you can test and think
    through the repercussions of inaccuracies.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让您对将要测试哪些类型的危害和事件有一个概念——这些事件太多，无法一一列举——您会发现查看[https://incidentdatabase.ai/](https://incidentdatabase.ai/)上的AI事件数据库很有帮助。在审查此工具后，您可能会发现您特定的用例（或类似用例）以及已经报告的事件，这样您就可以测试并思考不准确性可能带来的后果。
- en: As an example, one incident that is detailed here involved an application that
    made staffing-level recommendations. However, the algorithm-based recommendations
    left facilities understaffed, leading to critical incidents of neglect, injury,
    and death. Those incidents then prompted lawsuits and even legislation against
    healthcare providers using AI.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这里详细描述的一个事件涉及一个提供人员配备级别建议的应用程序。然而，基于算法的建议导致设施人员不足，导致忽视、伤害和死亡的关键事件。这些事件随后引发了针对使用人工智能的医疗保健提供者的诉讼甚至立法。
- en: Information post-processing
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 信息后处理
- en: You might know that the main way in which GenAI differs from previous forms
    of AI or analytics is that it generates new content efficiently. But did you know
    that that content is often in *unstructured* forms, for example, written text
    or images? When you see outputs that are nicely formatted, in bulleted lists,
    multiple fonts, and so on, it is a form of **information post-processing**.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能知道，生成式人工智能与之前的人工智能或分析形式的主要区别在于它能够高效地生成新内容。但您知道这些内容通常是*非结构化*形式，例如书面文本或图像吗？当您看到格式良好、以项目符号列表、多种字体等形式呈现的输出时，这是一种**信息后处理**的形式。
- en: 'Information post-processing refers to the series of steps taken after an AI
    model generates an initial response, but before that response is sent to the user.
    This crucial step enhances the output of GenAI models, refining raw responses
    to make them more useful, accurate, and contextually appropriate. It can take
    many forms, so this chapter will only discuss some of the most useful ones along
    with information on how to implement them:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 信息后处理指的是在人工智能模型生成初步响应之后，但在将响应发送给用户之前所采取的一系列步骤。这一关键步骤增强了生成式人工智能模型的输出，将原始响应精炼得更加有用、准确和符合上下文。它可能采取多种形式，因此本章将仅讨论其中一些最有用的形式，并附带如何实施它们的信息：
- en: '**Fact-checking**: Verifying the accuracy of the information provided. This
    can involve checking facts against reliable sources or databases.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事实核查**：验证提供信息的准确性。这可能涉及将事实与可靠来源或数据库进行核对。'
- en: '**Formatting**: Structuring the information in a clear and readable format,
    such as bullet points, paragraphs, or tables. This may also include style changes
    such as bold, text color, or font to enhance readability and emphasis.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**格式化**：以清晰易读的格式组织信息，例如项目符号、段落或表格。这还可能包括风格变化，如粗体、文字颜色或字体，以增强可读性和强调。'
- en: '**Grammar, style, and tone checking**: At times, the resulting text provided
    by GenAI applications is not up to par or consistent with the exact messaging,
    tone, and style that one would expect a human being to write. Post-processing
    tools and vendors can take generated text outputs and markedly improve them for
    readability, making them match reader expectations.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语法、风格和语气检查**：有时，GenAI应用提供的文本结果不符合标准或与预期的精确信息、语气和风格不一致。后处理工具和供应商可以显著改善生成的文本输出，使其更具可读性，使其符合读者的期望。'
- en: Information post-processing is a vital component in the lifecycle of GenAI outputs.
    It bridges the gap between raw model outputs and polished, user-ready responses,
    enhancing accuracy, readability, relevance, and overall user satisfaction. By
    implementing effective post-processing strategies, AI systems can deliver higher-quality
    and more reliable results.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 信息后处理是GenAI输出生命周期中的一个重要组成部分。它弥合了原始模型输出和经过打磨、用户准备好的响应之间的差距，提高了准确性、可读性、相关性和整体用户满意度。通过实施有效的后处理策略，AI系统可以提供更高质量和更可靠的输出。
- en: There are entire services springing up around this valuable step in the GenAI
    process, so engineers do not have to build it themselves.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 围绕GenAI流程中这一宝贵步骤，出现了整个服务，因此工程师不必自己构建它。
- en: Other remedies
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他补救措施
- en: Some other technical remedies can be employed even more easily than the ones
    detailed in this chapter. Some of these may improve the accuracy and performance
    of your GenAI application, though the level of effort involved varies. As an example,
    during MongoDB’s testing of GPT, it was discovered that the accuracy rate for
    the same set of questions was improved by 7% between GPT-3.5 and GPT-4\. Getting
    such a level of improvement in accuracy via prompting, retrieval augmentation,
    or late interaction strategies is certainly possible but would have been difficult.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一些其他的技术补救措施甚至比本章详细描述的更容易实施。其中一些可能会提高你的GenAI应用的准确性和性能，尽管所需的努力程度不同。例如，在MongoDB对GPT的测试中，发现相同问题集的准确率在GPT-3.5和GPT-4之间提高了7%。通过提示、检索增强或后期交互策略获得这样的准确率提升是可能的，但会非常困难。
- en: 'So, it is worth investigating every avenue of potential improvement, including
    areas such as hardware upgrades, code optimization, concurrency management, database
    query optimization, and even just upgrading your software. All of these can improve
    the results of your GenAI application and should be independently investigated:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，调查所有潜在的改进途径都是值得的，包括硬件升级、代码优化、并发管理、数据库查询优化，甚至仅仅是升级你的软件。所有这些都可以提高你的GenAI应用的结果，并且应该独立进行调查：
- en: '**Hardware and software upgrades**: Upgrade computational resources, such as
    using more powerful GPUs, scaling horizontally with more servers, or updating
    to the latest version of the software, to outsize impacts on both accuracy and
    performance.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件和软件升级**：升级计算资源，例如使用更强大的GPU、通过更多服务器进行横向扩展，或更新到软件的最新版本，以对准确性和性能产生巨大影响。'
- en: '**Code optimization**: Refactor and optimize code to improve efficiency, reduce
    computational load, and handle data more effectively.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码优化**：重构和优化代码以提高效率，减少计算负载，并更有效地处理数据。'
- en: '**Network optimization**: Reduce network latency by optimizing data transfer,
    caching responses, and minimizing API call overheads.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络优化**：通过优化数据传输、缓存响应和最小化API调用开销来降低网络延迟。'
- en: '**Concurrency management**: Implement concurrency and parallel processing techniques
    to handle multiple requests efficiently.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**并发管理**：实现并发和并行处理技术以高效处理多个请求。'
- en: '**Database optimization**: Optimize database queries and interactions to reduce
    I/O overhead.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据库优化**：优化数据库查询和交互以减少I/O开销。'
- en: Summary
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Implementing mechanisms to correct and optimize your GenAI application can have
    many forms and can be implemented before, during, and after answers are generated.
    For optimal performance, you’ll want to train your GenAI model with high-quality
    data, supplement existing models with your specific use case data, and have thorough
    evaluation datasets and record the model’s performance to establish a baseline
    of accuracy.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 实施纠正和优化你的GenAI应用的机制可以有多种形式，可以在生成答案之前、期间和之后实施。为了获得最佳性能，你希望用高质量的数据训练你的GenAI模型，用你的特定用例数据补充现有模型，并拥有详尽的评估数据集，记录模型的表现以建立准确性的基线。
- en: Once you have that baseline, however, you can immediately begin improving upon
    it with the techniques discussed in this chapter. Among these techniques is one-
    or few-shot prompting. It involves providing the GenAI model with a single example
    or prompt to guide its response, enabling the model to generate relevant and contextually
    appropriate outputs with minimal training data. You can also try retrieving and
    reranking relevant documents or data points based on the user’s query, and then
    reordering these results to prioritize the most relevant and useful information
    before generating a final response. Query rewriting is another technique that
    can improve clarity, specificity, or context, helping the AI model understand
    and respond more accurately to the user’s requests.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一旦有了这个基准，你就可以立即开始使用本章讨论的技术来改进它。其中一种技术是一或少量提示。这涉及到向GenAI模型提供一个示例或提示来引导其响应，使模型能够在最少训练数据的情况下生成相关且上下文适当的输出。你也可以尝试根据用户的查询检索和重新排序相关文档或数据点，然后在生成最终响应之前重新排序这些结果，以优先显示最相关和有用的信息。查询重写是另一种可以提高清晰度、具体性或上下文的技术，有助于AI模型更准确地理解和响应用户的请求。
- en: Formatting GenAI responses via structuring and presenting the AI-generated content
    in a clear, organized, and readable manner can enhance the overall user experience
    and ensure the information is easily digestible. Similarly, implementing late
    interaction strategies such as ColBERT can improve the relevance and accuracy
    of the retrieved information. By testing, red teaming, and recording your results,
    you can track your progress in improving the performance, security, and quality
    of responses over time.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结构化和以清晰、有序和可读的方式呈现AI生成的内容来格式化GenAI响应可以增强整体用户体验并确保信息易于消化。同样，实施如ColBERT之类的后期交互策略可以提高检索信息的关联性和准确性。通过测试、红队攻击和记录你的结果，你可以跟踪你在提高性能、安全性和响应质量方面的进展。
- en: GenAI technologies are changing (and will continue to change) the face of the
    software industry. With these optimization strategies in place, your GenAI application
    will be well equipped to adapt and excel in an ever-evolving landscape.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI技术正在改变（并将继续改变）软件行业的面貌。有了这些优化策略，你的GenAI应用将能够适应并在这个不断变化的环境中脱颖而出。
- en: 'Appendix: Further Reading'
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录：进一步阅读
- en: In addition to the links provided within the chapters, here are some resources
    to take your learning journey forward.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 除了章节内提供的链接外，这里还有一些资源可以帮助你继续学习之旅。
- en: '[**Chapter 1**](B22495_01.xhtml#_idTextAnchor009)**, Getting Started with**
    **Generative AI**'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '[**第1章**](B22495_01.xhtml#_idTextAnchor009)**, 开始使用生成式AI**'
- en: Gryka, Maciej. “Invest in RAG” in “Building reliable systems out of unreliable
    agents.” *The Rainforest Blog*, April 3, 2024\. [https://www.rainforestqa.com/blog/building-reliable-systems-out-of-unreliable-agents#Invest_in_RAG](https://www.rainforestqa.com/blog/building-reliable-systems-out-of-unreliable-agents#Invest_in_RAG).
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gryka, Maciej. “Invest in RAG” in “Building reliable systems out of unreliable
    agents.” *The Rainforest Blog*, April 3, 2024\. [https://www.rainforestqa.com/blog/building-reliable-systems-out-of-unreliable-agents#Invest_in_RAG](https://www.rainforestqa.com/blog/building-reliable-systems-out-of-unreliable-agents#Invest_in_RAG).
- en: '“The Black Box: Even AI’s creators don’t understand it.” July 2023\. *Unexplainable*.
    Produced by Vox Creative. Podcast, Spotify, 36:15\. [https://open.spotify.com/episode/3npjXNCtUSGRUjVR4EYb4Y?si=-XpudYVzSEKfhD0-2NBjEQ](https://open.spotify.com/episode/3npjXNCtUSGRUjVR4EYb4Y?si=-XpudYVzSEKfhD0-2NBjEQ).'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '“The Black Box: Even AI’s creators don’t understand it.” July 2023\. *Unexplainable*.
    Produced by Vox Creative. Podcast, Spotify, 36:15\. [https://open.spotify.com/episode/3npjXNCtUSGRUjVR4EYb4Y?si=-XpudYVzSEKfhD0-2NBjEQ](https://open.spotify.com/episode/3npjXNCtUSGRUjVR4EYb4Y?si=-XpudYVzSEKfhD0-2NBjEQ).'
- en: '[**Chapter 2**](B22495_02.xhtml#_idTextAnchor021)**, Building Blocks of** **Intelligent
    Applications**'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[**第2章**](B22495_02.xhtml#_idTextAnchor021)**, 智能应用构建模块**'
- en: Naveed et al. “A Comprehensive Overview of Large Language Models.” arXiv, July
    12, 2023\. [https://arxiv.org/abs/2307.06435](https://arxiv.org/abs/2307.06435).
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Naveed et al. “大型语言模型的全面概述。” arXiv，2023年7月12日\[https://arxiv.org/abs/2307.06435](https://arxiv.org/abs/2307.06435).
- en: '[**Chapter 3**](B22495_03.xhtml#_idTextAnchor041)**, Large** **Language Models**'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[**第3章**](B22495_03.xhtml#_idTextAnchor041)**, 大型语言模型**'
- en: “Speech and Language Processing,” n.d., [https://web.stanford.edu/~jurafsky/slp3/](https://web.stanford.edu/~jurafsky/slp3/).
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “语音和语言处理，” n.d., [https://web.stanford.edu/~jurafsky/slp3/](https://web.stanford.edu/~jurafsky/slp3/).
- en: 'Hochreiter, Sepp, and Jürgen Schmidhuber. “Long Short-Term Memory.” *Neural
    Computation* 9, no. 8 (November 1, 1997): 1735–80\. [https://doi.org/10.1162/neco.1997.9.8.1735](https://doi.org/10.1162/neco.1997.9.8.1735).'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hochreiter, Sepp，和 Jürgen Schmidhuber。“长短期记忆。” *Neural Computation* 9，第 8 期（1997年11月1日）：1735–80\[https://doi.org/10.1162/neco.1997.9.8.1735](https://doi.org/10.1162/neco.1997.9.8.1735).
- en: Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan
    N. Gomez, Lukasz Kaiser, and Illia Polosukhin. “Attention Is All You Need.” *arXiv
    (Cornell University)*, January 1, 2017\. [https://doi.org/10.48550/arxiv.1706.03762](https://doi.org/10.48550/arxiv.1706.03762).
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani, Ashish，Noam Shazeer，Niki Parmar，Jakob Uszkoreit，Llion Jones，Aidan N.
    Gomez，Lukasz Kaiser，和 Illia Polosukhin。“Attention Is All You Need。” *arXiv (Cornell
    University)*，2017年1月1日\[https://doi.org/10.48550/arxiv.1706.03762](https://doi.org/10.48550/arxiv.1706.03762).
- en: “Prompt Engineering Guide – Nextra,” n.d., [https://www.promptingguide.ai/](https://www.promptingguide.ai/).
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “提示工程指南 – Nextra”，未注明日期\[https://www.promptingguide.ai/](https://www.promptingguide.ai/).
- en: '[**Chapter 4**](B22495_04.xhtml#_idTextAnchor061)**,** **Embedding Models**'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '[**第四章**](B22495_04.xhtml#_idTextAnchor061)**,** **嵌入模型**'
- en: 'A. Aruna Gladys and V. Vetriselvi, “Survey on multimodal approaches to emotion
    recognition,” *Neurocomputing* 556 (November 1, 2023): 126693, [https://doi.org/10.1016/j.neucom.2023.126693](https://doi.org/10.1016/j.neucom.2023.126693).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: A. Aruna Gladys 和 V. Vetriselvi，“关于情感识别的多模态方法综述”，*Neurocomputing* 556（2023年11月1日）：126693\[https://doi.org/10.1016/j.neucom.2023.126693](https://doi.org/10.1016/j.neucom.2023.126693).
- en: Sumit Kumar, “Positive and Negative Sampling Strategies for Representation Learning
    in Semantic Search,” Sumit’s Diary, March 22, 2023, [https://blog.reachsumit.com/posts/2023/03/pairing-for-representation](https://blog.reachsumit.com/posts/2023/03/pairing-for-representation).
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sumit Kumar，“语义搜索中表示学习的正负采样策略”，Sumit 的日记，2023年3月22日\[https://blog.reachsumit.com/posts/2023/03/pairing-for-representation](https://blog.reachsumit.com/posts/2023/03/pairing-for-representation).
- en: Tomas Mikolov et al., “Efficient Estimation of Word Representations in Vector
    Space,” arXiv.org, January 16, 2013, [https://arxiv.org/abs/1301.3781](https://arxiv.org/abs/1301.3781).
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tomas Mikolov 等人，“在向量空间中高效估计词表示”，arXiv.org，2013年1月16日，[https://arxiv.org/abs/1301.3781](https://arxiv.org/abs/1301.3781).
- en: OpenAI, “GPT-4”. GPT-4 Research, March 14, 2023\. [https://openai.com/index/gpt-4-research](https://openai.com/index/gpt-4-research).
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI，“GPT-4”。GPT-4 研究，2023年3月14日\[https://openai.com/index/gpt-4-research](https://openai.com/index/gpt-4-research).
- en: 'Jeffrey Pennington, “GloVe: Global Vectors for Word Representation,” n.d.,
    [https://nlp.stanford.edu/projects/glove](https://nlp.stanford.edu/projects/glove).'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jeffrey Pennington，“GloVe：全局词向量表示”，未注明日期\[https://nlp.stanford.edu/projects/glove](https://nlp.stanford.edu/projects/glove).
- en: 'Jacob Devlin et al., “BERT: Pre-training of Deep Bidirectional Transformers
    for Language Understanding,” arXiv.org, October 11, 2018, [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805).'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jacob Devlin 等人，“BERT：用于语言理解的深度双向变换器预训练”，arXiv.org，2018年10月11日\[https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805).
- en: “fastText,” n.d., [https://fasttext.cc/](https://fasttext.cc/).
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “fastText”，未注明日期\[https://fasttext.cc/](https://fasttext.cc/).
- en: Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., and
    Zettlemoyer, L. “Deep contextualized word representations,” arXiv:1802.05365,
    March 22, 2018\. [https://arxiv.org/pdf/1802.05365](https://arxiv.org/pdf/1802.05365).
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Peters, M. E.，Neumann, M.，Iyyer, M.，Gardner, M.，Clark, C.，Lee, K.，和 Zettlemoyer,
    L.，“深度上下文化词表示”，arXiv:1802.05365，2018年3月22日\[https://arxiv.org/pdf/1802.05365](https://arxiv.org/pdf/1802.05365).
- en: Karen Simonyan and Andrew Zisserman, “Very Deep Convolutional Networks for Large-Scale
    Image Recognition,” arXiv.org, September 4, 2014, [https://arxiv.org/abs/1409.1556v6](https://arxiv.org/abs/1409.1556v6).
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karen Simonyan 和 Andrew Zisserman，“用于大规模图像识别的非常深卷积网络”，arXiv.org，2014年9月4日\[https://arxiv.org/abs/1409.1556v6](https://arxiv.org/abs/1409.1556v6).
- en: Kaiming He et al., “Deep Residual Learning for Image Recognition,” arXiv.org,
    December 10, 2015, [https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385).
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaiming He 等人，“用于图像识别的深度残差学习”，arXiv.org，2015年12月10日\[https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385).
- en: Aurora Cramer, Ho-Hsiang Wu, Justin Salamon, and Juan Pablo Bello, “OpenL3 —
    OpenL3 0.4.2 documentation,” n.d., [https://openl3.readthedocs.io/en/latest/#](https://openl3.readthedocs.io/en/latest/#).
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aurora Cramer，Ho-Hsiang Wu，Justin Salamon，和 Juan Pablo Bello，“OpenL3 — OpenL3
    0.4.2 文档”，未注明日期\[https://openl3.readthedocs.io/en/latest/#](https://openl3.readthedocs.io/en/latest/#).
- en: “Google | vggish | Kaggle,” n.d., [https://www.kaggle.com/models/google/vggish](https://www.kaggle.com/models/google/vggish).
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “Google | vggish | Kaggle”，未注明日期\[https://www.kaggle.com/models/google/vggish](https://www.kaggle.com/models/google/vggish).
- en: Tran, D., Bourdev, L., Fergus, R., Torresani, L., and Paluri, M., “Learning
    Spatiotemporal Features with 3D Convolutional Networks.” arXiv:1412.0767, October
    7, 2015\. [https://arxiv.org/pdf/1412.0767](https://arxiv.org/pdf/1412.0767).
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tran, D.，Bourdev, L.，Fergus, R.，Torresani, L.，和 Paluri, M.，“使用 3D 卷积网络学习时空特征。”arXiv:1412.0767，2015年10月7日。[https://arxiv.org/pdf/1412.0767](https://arxiv.org/pdf/1412.0767).
- en: 'Grover, A., and Leskovec, J. “Node2Vec: Scalable Feature Learning for Networks.”
    *Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery
    and Data Mining*, 2016\. [https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf](https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf).'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grover, A.，和 Leskovec, J.，“Node2Vec：网络的缩放特征学习方法。”*第 22 届 ACM SIGKDD 国际知识发现和数据挖掘会议论文集*，2016年。[https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf](https://cs.stanford.edu/~jure/pubs/node2vec-kdd16.pdf).
- en: Bryan Perozzi, Rami Al-Rfou, and Steven Skiena, “DeepWalk,” August 24, 2014,
    [https://doi.org/10.1145/2623330.2623732](https://doi.org/10.1145/2623330.2623732).
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bryan Perozzi，Rami Al-Rfou，和 Steven Skiena，“DeepWalk，”2014年8月24日，[https://doi.org/10.1145/2623330.2623732](https://doi.org/10.1145/2623330.2623732).
- en: 'Zhang, S., and Xu, Y. “Json2Vec: A Representation Learning Method for JSON
    Data.” arXiv:2002.05707, February 13, 2020\. [https://arxiv.org/pdf/2002.05707](https://arxiv.org/pdf/2002.05707).'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang, S.，和 Xu, Y.，“Json2Vec：JSON 数据的表示学习方法。”arXiv:2002.05707，2020年2月13日。[https://arxiv.org/pdf/2002.05707](https://arxiv.org/pdf/2002.05707).
- en: Alec Radford et al., “Learning Transferable Visual Models From Natural Language
    Supervision,” arXiv.org, February 26, 2021, [https://arxiv.org/abs/2103.00020](https://arxiv.org/abs/2103.00020).
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alec Radford 等人，“从自然语言监督中学习可迁移的视觉模型，”arXiv.org，2021年2月26日，[https://arxiv.org/abs/2103.00020](https://arxiv.org/abs/2103.00020).
- en: '[**Chapter 5**](B22495_05.xhtml#_idTextAnchor115)**,** **Vector Databases**'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '[**第五章**](B22495_05.xhtml#_idTextAnchor115)**，向量数据库**'
- en: Yu. A. Malkov and D. A. Yashunin, “Efficient and robust approximate nearest
    neighbor search using Hierarchical Navigable Small World graphs,” arXiv.org, March
    30, 2016, [http://arxiv.org/abs/1603.09320](http://arxiv.org/abs/1603.09320).
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu. A. Malkov 和 D. A. Yashunin，“使用分层可导航小世界图进行高效且鲁棒的近似最近邻搜索，”arXiv.org，2016年3月30日，[http://arxiv.org/abs/1603.09320](http://arxiv.org/abs/1603.09320).
- en: 'Yikun Han, Chunjiang Liu, and Pengfei Wang, “A Comprehensive Survey on Vector
    Database: Storage and Retrieval Technique, Challenge,” arXiv.org, October 18,
    2023, [http://arxiv.org/abs/2310.11703](http://arxiv.org/abs/2310.11703).'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yikun Han，Chunjiang Liu，和 Pengfei Wang，“向量数据库全面综述：存储和检索技术，挑战，”arXiv.org，2023年10月18日，[http://arxiv.org/abs/2310.11703](http://arxiv.org/abs/2310.11703).
- en: 'Zhi Jing et al., “When Large Language Models Meet Vector Databases: A Survey,”
    arXiv.org, January 30, 2024, [http://arxiv.org/abs/2402.01763](http://arxiv.org/abs/2402.01763).'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhi Jing 等人，“大型语言模型与向量数据库的相遇：综述，”arXiv.org，2024年1月30日，[http://arxiv.org/abs/2402.01763](http://arxiv.org/abs/2402.01763).
- en: Doug Turnbull, “What Is a Judgment List?,” Doug Turnbull’s Blog, February 21,
    2021, [https://softwaredoug.com/blog/2021/02/21/what-is-a-judgment-list](https://softwaredoug.com/blog/2021/02/21/what-is-a-judgment-list).
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Doug Turnbull，“什么是判断列表？”，Doug Turnbull 的博客，2021年2月21日，[https://softwaredoug.com/blog/2021/02/21/what-is-a-judgment-list](https://softwaredoug.com/blog/2021/02/21/what-is-a-judgment-list).
- en: “Building RAG-based LLM Applications for Production,” Anyscale, n.d., [https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1](https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1).
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “构建基于 RAG 的 LLM 应用程序以用于生产，”Anyscale，未注明日期，[https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1](https://www.anyscale.com/blog/a-comprehensive-guide-for-building-rag-based-llm-applications-part-1).
- en: “How to Perform Hybrid Search - MongoDB Atlas,” n.d., [https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/reciprocal-rank-fusion/](https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/reciprocal-rank-fusion/).
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “如何执行混合搜索 - MongoDB Atlas，”未注明日期，[https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/reciprocal-rank-fusion/](https://www.mongodb.com/docs/atlas/atlas-vector-search/tutorials/reciprocal-rank-fusion/).
- en: “Review Deployment Options - MongoDB Atlas,” n.d., [https://www.mongodb.com/docs/atlas/atlas-vector-search/deployment-options/](https://www.mongodb.com/docs/atlas/atlas-vector-search/deployment-options/).
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “审查部署选项 - MongoDB Atlas，”未注明日期，[https://www.mongodb.com/docs/atlas/atlas-vector-search/deployment-options/](https://www.mongodb.com/docs/atlas/atlas-vector-search/deployment-options/).
- en: '[**Chapter 6**](B22495_06.xhtml#_idTextAnchor137)**, AI/ML** **Application
    Design**'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '[**第六章**](B22495_06.xhtml#_idTextAnchor137)**，AI/ML 应用设计**'
- en: “How to Index Fields for Vector Search - MongoDB Atlas,” n.d., [https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-type/#considerations](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-type/#considerations).
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “如何在向量搜索中索引字段 - MongoDB Atlas，”未注明日期，[https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-type/#considerations](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-type/#considerations).
- en: Lauren Schaefer Daniel Coupal, “Bloated Documents | MongoDB,” May 31, 2022,
    [https://www.mongodb.com/developer/products/mongodb/schema-design-anti-pattern-bloated-documents/](https://www.mongodb.com/developer/products/mongodb/schema-design-anti-pattern-bloated-documents/).
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lauren Schaefer Daniel Coupal，“膨胀的文档 | MongoDB，”2022年5月31日，[https://www.mongodb.com/developer/products/mongodb/schema-design-anti-pattern-bloated-documents/](https://www.mongodb.com/developer/products/mongodb/schema-design-anti-pattern-bloated-documents/).
- en: 'Daniel Coupal, “Building with Patterns: The Extended Reference Pattern,” MongoDB,
    March 19, 2019, [https://www.mongodb.com/blog/post/building-with-patterns-the-extended-reference-pattern](https://www.mongodb.com/blog/post/building-with-patterns-the-extended-reference-pattern).'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Daniel Coupal，“使用模式构建：扩展引用模式，”MongoDB，2019年3月19日，[https://www.mongodb.com/blog/post/building-with-patterns-the-extended-reference-pattern](https://www.mongodb.com/blog/post/building-with-patterns-the-extended-reference-pattern).
- en: “Atlas Cluster Sizing and Tier Selection - MongoDB Atlas,” n.d., [https://www.mongodb.com/docs/atlas/sizing-tier-selection/](https://www.mongodb.com/docs/atlas/sizing-tier-selection/).
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “Atlas 集群大小和层级选择 - MongoDB Atlas，”未注明日期，[https://www.mongodb.com/docs/atlas/sizing-tier-selection/](https://www.mongodb.com/docs/atlas/sizing-tier-selection/).
- en: “Customize Cluster Storage - MongoDB Atlas,” n.d., [https://www.mongodb.com/docs/atlas/customize-storage/](https://www.mongodb.com/docs/atlas/customize-storage/).
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “自定义集群存储 - MongoDB Atlas，”未注明日期，[https://www.mongodb.com/docs/atlas/customize-storage/](https://www.mongodb.com/docs/atlas/customize-storage/).
- en: “Amazon EBS volume types - Amazon EBS,” n.d., [https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html#gp3-ebs-volume-type](https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html#gp3-ebs-volume-type).
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “Amazon EBS 卷类型 - Amazon EBS，”未注明日期，[https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html#gp3-ebs-volume-type](https://docs.aws.amazon.com/ebs/latest/userguide/ebs-volume-types.html#gp3-ebs-volume-type).
- en: “Customize Cluster Storage - MongoDB Atlas,” n.d., [https://www.mongodb.com/docs/atlas/customize-storage/](https://www.mongodb.com/docs/atlas/customize-storage/).
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “自定义集群存储 - MongoDB Atlas，”未注明日期，[https://www.mongodb.com/docs/atlas/customize-storage/](https://www.mongodb.com/docs/atlas/customize-storage/).
- en: '[**Chapter 7**](B22495_07.xhtml#_idTextAnchor162)**, Useful Frameworks, Libraries,**
    **and APIs**'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '[**第7章**](B22495_07.xhtml#_idTextAnchor162)**，有用的框架、库和 API**'
- en: “MongoDB Atlas,” LangChain, n.d., [https://python.langchain.com/v0.2/docs/integrations/vectorstores/mongodb_atlas/](https://python.langchain.com/v0.2/docs/integrations/vectorstores/mongodb_atlas/).
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “MongoDB Atlas，”LangChain，未注明日期，[https://python.langchain.com/v0.2/docs/integrations/vectorstores/mongodb_atlas/](https://python.langchain.com/v0.2/docs/integrations/vectorstores/mongodb_atlas/).
- en: “How to Index Fields for Vector Search - MongoDB Atlas,” n.d., [https://www.mongodb.com/docs/atlas/atlas-vector-search/manage-indexes/](https://www.mongodb.com/docs/atlas/atlas-vector-search/manage-indexes/).
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “如何在向量搜索中索引字段 - MongoDB Atlas，”未注明日期，[https://www.mongodb.com/docs/atlas/atlas-vector-search/manage-indexes/](https://www.mongodb.com/docs/atlas/atlas-vector-search/manage-indexes/).
- en: “Get Started with the LangChain Integration - MongoDB Atlas,” n.d., [https://www.mongodb.com/docs/atlas/atlas-vector-search/ai-integrations/langchain/](https://www.mongodb.com/docs/atlas/atlas-vector-search/ai-integrations/langchain/).
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “使用 LangChain 集成开始 - MongoDB Atlas，”未注明日期，[https://www.mongodb.com/docs/atlas/atlas-vector-search/ai-integrations/langchain/](https://www.mongodb.com/docs/atlas/atlas-vector-search/ai-integrations/langchain/).
- en: “MongoDB with Python - MongoDB Documentation,” n.d., [https://www.mongodb.com/docs/languages/python/#integrations](https://www.mongodb.com/docs/languages/python/#integrations).
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “使用 Python 的 MongoDB - MongoDB 文档，”未注明日期，[https://www.mongodb.com/docs/languages/python/#integrations](https://www.mongodb.com/docs/languages/python/#integrations).
- en: “Transformers,” n.d., [https://huggingface.co/docs/transformers/en/index](https://huggingface.co/docs/transformers/en/index).
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “Transformers，”未注明日期，[https://huggingface.co/docs/transformers/en/index](https://huggingface.co/docs/transformers/en/index).
- en: “OpenAI developer platform,” OpenAI Platform, n.d., [https://platform.openai.com/docs/overview](https://platform.openai.com/docs/overview).
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “OpenAI 开发者平台，”OpenAI 平台，未注明日期，[https://platform.openai.com/docs/overview](https://platform.openai.com/docs/overview).
- en: '[**Chapter 8**](B22495_08.xhtml#_idTextAnchor180)**, Implementing Vector Search
    in** **AI Applications**'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '[**第8章**](B22495_08.xhtml#_idTextAnchor180)**，在 AI 应用中实现向量搜索**'
- en: 'Yunfan Gao et al., “Retrieval-Augmented Generation for Large Language Models:
    A Survey,” arXiv.org, December 18, 2023, [https://arxiv.org/abs/2312.10997](https://arxiv.org/abs/2312.10997).'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yunfan Gao等人，“大型语言模型的检索增强生成：综述，” arXiv.org，2023年12月18日，[https://arxiv.org/abs/2312.10997](https://arxiv.org/abs/2312.10997).
- en: Rupak Roy, “Harness LLM Output-parsers like CommaSeparatedListOutputParser,
    PydanticOutputParser and more for a Structured Ai | by Rupak (Bob) Roy - II |
    Medium | Medium,” *Medium*, August 14, 2024, [https://bobrupakroy.medium.com/harness-llm-output-parsers-for-a-structured-ai-7b456d231834](https://bobrupakroy.medium.com/harness-llm-output-parsers-for-a-structured-ai-7b456d231834).
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rupak Roy, “利用CommaSeparatedListOutputParser、PydanticOutputParser等LLM输出解析器构建结构化AI
    | by Rupak (Bob) Roy - II | Medium | Medium，” *Medium*，2024年8月14日，[https://bobrupakroy.medium.com/harness-llm-output-parsers-for-a-structured-ai-7b456d231834](https://bobrupakroy.medium.com/harness-llm-output-parsers-for-a-structured-ai-7b456d231834).
- en: Mirjam Minor and Eduard Kaucher, “Retrieval Augmented Generation with LLMs for
    Explaining Business Process Models,” in *Lecture Notes in Computer Science*, 2024,
    175–90, [https://doi.org/10.1007/978-3-031-63646-2_12](https://doi.org/10.1007/978-3-031-63646-2_12).
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mirjam Minor和Eduard Kaucher，“使用LLM进行检索增强生成以解释业务流程模型，” 在 *Lecture Notes in Computer
    Science*，2024年，第175-190页，[https://doi.org/10.1007/978-3-031-63646-2_12](https://doi.org/10.1007/978-3-031-63646-2_12).
- en: '[**Chapter 9**](B22495_09.xhtml#_idTextAnchor193)**, LLM** **Output Evaluation**'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '[**第9章**](B22495_09.xhtml#_idTextAnchor193)**, LLM输出评估**'
- en: “Papers with Code - Measuring Massive Multitask Language Understanding,” September
    7, 2020, [https://paperswithcode.com/paper/measuring-massive-multitask-language](https://paperswithcode.com/paper/measuring-massive-multitask-language).
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “Papers with Code - 测量大规模多任务语言理解，” 2020年9月7日，[https://paperswithcode.com/paper/measuring-massive-multitask-language](https://paperswithcode.com/paper/measuring-massive-multitask-language).
- en: '“Papers with Code - HellaSwag: Can a Machine Really Finish Your Sentence?,”
    May 19, 2019, [https://paperswithcode.com/paper/hellaswag-can-a-machine-really-finish-your](https://paperswithcode.com/paper/hellaswag-can-a-machine-really-finish-your).'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '“Papers with Code - HellaSwag: 一台机器真的能完成你的句子吗？，” 2019年5月19日，[https://paperswithcode.com/paper/hellaswag-can-a-machine-really-finish-your](https://paperswithcode.com/paper/hellaswag-can-a-machine-really-finish-your).'
- en: “Papers with Code - Evaluating Large Language Models Trained on Code,” July
    7, 2021, [https://paperswithcode.com/paper/evaluating-large-language-models-trained-on](https://paperswithcode.com/paper/evaluating-large-language-models-trained-on).
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “Papers with Code - 评估在代码上训练的大型语言模型，” 2021年7月7日，[https://paperswithcode.com/paper/evaluating-large-language-models-trained-on](https://paperswithcode.com/paper/evaluating-large-language-models-trained-on).
- en: “Introduction | Ragas,” n.d., [https://docs.ragas.io/en/stable/index.html](https://docs.ragas.io/en/stable/index.html).
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “介绍 | Ragas，” 未注明日期，[https://docs.ragas.io/en/stable/index.html](https://docs.ragas.io/en/stable/index.html).
- en: '[**Chapter 10**](B22495_10.xhtml#_idTextAnchor214)**, Refining the Semantic
    Data Model to** **Improve Accuracy**'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '[**第10章**](B22495_10.xhtml#_idTextAnchor214)**, 精炼语义数据模型以提高准确性**'
- en: “SentenceTransformers Documentation — Sentence Transformers documentation,”
    n.d., [https://sbert.net/](https://sbert.net/).
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “SentenceTransformers 文档 — Sentence Transformers 文档，” 未注明日期，[https://sbert.net/](https://sbert.net/).
- en: “Train and Fine-Tune Sentence Transformers Models,” n.d., [https://huggingface.co/blog/how-to-train-sentence-transformers](https://huggingface.co/blog/how-to-train-sentence-transformers).
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “训练和微调Sentence Transformers模型，” 未注明日期，[https://huggingface.co/blog/how-to-train-sentence-transformers](https://huggingface.co/blog/how-to-train-sentence-transformers).
- en: “Run Vector Search Queries - MongoDB Atlas,” n.d., [https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter).
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “运行向量搜索查询 - MongoDB Atlas，” 未注明日期，[https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter](https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#atlas-vector-search-pre-filter).
- en: “Knowledge Graph RAG Query Engine - LlamaIndex,” n.d., [https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/](https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/).
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “知识图谱RAG查询引擎 - LlamaIndex，” 未注明日期，[https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/](https://docs.llamaindex.ai/en/stable/examples/query_engine/knowledge_graph_rag_query_engine/).
- en: '[**Chapter 11**](B22495_11.xhtml#_idTextAnchor232)**, Common Failures of**
    **Generative AI**'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[**第11章**](B22495_11.xhtml#_idTextAnchor232)**, 生成式AI的常见失败**'
- en: Lance Eliot, “Doctors Relying On Generative AI To Summarize Medical Notes Might
    Unknowingly Be Taking Big Risks,” *Forbes*, July 2, 2024, [https://www.forbes.com/sites/lanceeliot/2024/02/05/doctors-relying-on-generative-ai-to-summarize-medical-notes-might-unknowingly-be-taking-big-risks/](https://www.forbes.com/sites/lanceeliot/2024/02/05/doctors-relying-on-generative-ai-to-summarize-medical-notes-might-unknowingly-be-taking-big-risks/).
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lance Eliot， “医生依赖生成式AI来总结医疗记录可能会不知不觉地承担重大风险，” *Forbes*，2024年7月2日，[https://www.forbes.com/sites/lanceeliot/2024/02/05/doctors-relying-on-generative-ai-to-summarize-medical-notes-might-unknowingly-be-taking-big-risks/](https://www.forbes.com/sites/lanceeliot/2024/02/05/doctors-relying-on-generative-ai-to-summarize-medical-notes-might-unknowingly-be-taking-big-risks/).
- en: 'Markman, Ofer. “Time to Strategize: 85% of Data is Garbage or Siloed.” *Filo
    Focus*, February 11, 2024\. [https://www.filo.systems/blog/85-percent-of-data-is-not-actionable-time-to-restrategize](https://www.filo.systems/blog/85-percent-of-data-is-not-actionable-time-to-restrategize).'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Markman, Ofer. “是时候制定战略了：85%的数据是垃圾或孤岛化的。” *Filo Focus*，2024年2月11日。 [https://www.filo.systems/blog/85-percent-of-data-is-not-actionable-time-to-restrategize](https://www.filo.systems/blog/85-percent-of-data-is-not-actionable-time-to-restrategize).
- en: 'Neeman, Ella, Roee Aharoni, Or Honovich, et al. “DisentQA: Disentangling Parametric
    and Contextual Knowledge with Counterfactual Question Answering.” arXiv.org, November
    10, 2022\. [https://arxiv.org/pdf/2211.05655](https://arxiv.org/pdf/2211.05655).'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neeman, Ella, Roee Aharoni, Or Honovich, 等人. “DisentQA：通过反事实问答分解参数知识和上下文知识。”
    arXiv.org，2022年11月10日。 [https://arxiv.org/pdf/2211.05655](https://arxiv.org/pdf/2211.05655).
- en: Sharma, Mrinank, Meg Tong, Tomasz Korbak, et al. “Towards Understanding Sycophancy
    in Language Models.” arXiv.org, October 20, 2023\. [https://arxiv.org/abs/2310.13548](https://arxiv.org/abs/2310.13548).
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sharma, Mrinank, Meg Tong, Tomasz Korbak, 等人. “理解语言模型中的谄媚。” arXiv.org，2023年10月20日。
    [https://arxiv.org/abs/2310.13548](https://arxiv.org/abs/2310.13548).
- en: Sparkes, Matthew. “AI chatbots become more sycophantic as they get more advanced.”
    *New Scientist*, August 17, 2023\. [https://www.newscientist.com/article/2386915-ai-chatbots-become-more-sycophantic-as-they-get-more-advanced/](https://www.newscientist.com/article/2386915-ai-chatbots-become-more-sycophantic-as-they-get-more-advanced/).
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sparkes, Matthew. “随着AI聊天机器人变得更加高级，它们变得越来越谄媚。” *New Scientist*，2023年8月17日。 [https://www.newscientist.com/article/2386915-ai-chatbots-become-more-sycophantic-as-they-get-more-advanced/](https://www.newscientist.com/article/2386915-ai-chatbots-become-more-sycophantic-as-they-get-more-advanced/).
- en: Wei, Jerry, Da Huang, Yifeng Lu, et al. “Simple synthetic data reduces sycophancy
    in large language models.” arXiv.org, August 7, 2023\. [https://arxiv.org/abs/2308.03958](https://arxiv.org/abs/2308.03958).
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wei, Jerry, Da Huang, Yifeng Lu, 等人. “简单的合成数据可以减少大型语言模型中的谄媚。” arXiv.org，2023年8月7日。
    [https://arxiv.org/abs/2308.03958](https://arxiv.org/abs/2308.03958).
- en: '[**Chapter 12**](B22495_12.xhtml#_idTextAnchor253)**, Correcting and Optimizing
    Your Generative** **AI Application**'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '[**第12章**](B22495_12.xhtml#_idTextAnchor253)**，纠正和优化您的生成式AI应用**'
- en: Chui, Michael, Roger Roberts, Tanya Rodchenko, et al. “What every CEO should
    know about generative AI.” McKinsey Digital, May 12, 2023\. [https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/what-every-ceo-should-know-about-generative-ai](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/what-every-ceo-should-know-about-generative-ai).
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chui, Michael, Roger Roberts, Tanya Rodchenko, 等人. “每位CEO都应该了解的生成式AI。” McKinsey
    Digital, 2023年5月12日。 [https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/what-every-ceo-should-know-about-generative-ai](https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/what-every-ceo-should-know-about-generative-ai).
- en: Xiao, Han. “What is ColBERT and Late Interaction and Why They Matter in Search?,”
    Jina AI, February 20, 2024\. [https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/](https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/).
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xiao, Han. “什么是ColBERT和晚期交互，以及为什么它们在搜索中很重要？”，Jina AI，2024年2月20日。 [https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/](https://jina.ai/news/what-is-colbert-and-late-interaction-and-why-they-matter-in-search/).
