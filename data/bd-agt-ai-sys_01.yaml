- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Fundamentals of Generative AI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIåŸºç¡€
- en: Generative AI has quickly become a transformative technology in the field of
    **artificial intelligence** ( **AI** ) and machine learning, revolutionizing creative
    processes and problem-solving across diverse industries and use cases. It is pushing
    the boundaries of autonomy in agent-based intelligent systems. In this chapter,
    we will cover the basics of generative AI. We will explore what generative AI
    is along with a brief history of generative AI models. We will then discuss the
    different types of generative models, which include **variational autoencoders**
    ( **VAEs** ), **generative adversarial networks** ( **GANs** ), autoregressive,
    and Transformer models. Next, we will delve into the applications of generative
    AI and wrap up the chapter with a brief discussion of some of the limitations
    and challenges related to generative AI.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIè¿…é€Ÿæˆä¸ºäººå·¥æ™ºèƒ½ï¼ˆ**AI**ï¼‰å’Œæœºå™¨å­¦ä¹ é¢†åŸŸçš„ä¸€é¡¹å˜é©æ€§æŠ€æœ¯ï¼Œå®ƒæ­£åœ¨æ”¹å˜ç€å„ä¸ªè¡Œä¸šå’Œç”¨ä¾‹ä¸­çš„åˆ›æ„è¿‡ç¨‹å’Œé—®é¢˜è§£å†³æ–¹å¼ã€‚å®ƒæ­£åœ¨æ¨åŠ¨åŸºäºä»£ç†çš„æ™ºèƒ½ç³»ç»Ÿè‡ªä¸»æ€§çš„è¾¹ç•Œã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»ç”Ÿæˆå¼AIçš„åŸºç¡€ã€‚æˆ‘ä»¬å°†æ¢è®¨ç”Ÿæˆå¼AIæ˜¯ä»€ä¹ˆï¼Œä»¥åŠç”Ÿæˆå¼AIæ¨¡å‹çš„ç®€è¦å†å²ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è®¨è®ºä¸åŒç±»å‹çš„ç”Ÿæˆæ¨¡å‹ï¼ŒåŒ…æ‹¬**å˜åˆ†è‡ªç¼–ç å™¨**ï¼ˆ**VAEs**ï¼‰ã€**ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ**ï¼ˆ**GANs**ï¼‰ã€è‡ªå›å½’å’ŒTransformeræ¨¡å‹ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†æ·±å…¥ç ”ç©¶ç”Ÿæˆå¼AIçš„åº”ç”¨ï¼Œå¹¶åœ¨æœ¬ç« ç»“æŸæ—¶ç®€è¦è®¨è®ºä¸€äº›ä¸ç”Ÿæˆå¼AIç›¸å…³çš„å±€é™æ€§å’ŒæŒ‘æˆ˜ã€‚
- en: 'We will cover the following topics in this introductory chapter that will help
    set the foundations of generative AI as we explore further the capabilities of
    autonomous intelligent agents powered by generative AI:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç®€ä»‹ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¶µç›–ä»¥ä¸‹ä¸»é¢˜ï¼Œè¿™å°†å¸®åŠ©æˆ‘ä»¬ä¸ºè¿›ä¸€æ­¥æ¢ç´¢ç”±ç”Ÿæˆå¼AIé©±åŠ¨çš„è‡ªä¸»æ™ºèƒ½ä»£ç†çš„èƒ½åŠ›å¥ å®šåŸºç¡€ï¼š
- en: Introduction to generative AI
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIç®€ä»‹
- en: Types of generative AI models
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIæ¨¡å‹çš„ç±»å‹
- en: Applications of generative AI
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIçš„åº”ç”¨
- en: Challenges and limitations of generative AI
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIçš„æŒ‘æˆ˜å’Œå±€é™æ€§
- en: By the end of this chapter, you will have gained a comprehensive understanding
    of generative AI, including its fundamental concepts, diverse applications, and
    current challenges. You will also learn about the technologyâ€™s potential and limitations,
    with a particular focus on its critical role in advancing intelligent agents and
    agentic systems.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ°æœ¬ç« ç»“æŸæ—¶ï¼Œä½ å°†å…¨é¢äº†è§£ç”Ÿæˆå¼AIï¼ŒåŒ…æ‹¬å…¶åŸºæœ¬æ¦‚å¿µã€å¤šæ ·åŒ–çš„åº”ç”¨å’Œå½“å‰æŒ‘æˆ˜ã€‚ä½ è¿˜å°†äº†è§£è¿™é¡¹æŠ€æœ¯çš„æ½œåŠ›å’Œå±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯å®ƒå¯¹æ¨è¿›æ™ºèƒ½ä»£ç†å’Œä»£ç†ç³»ç»Ÿæ‰€å‘æŒ¥çš„å…³é”®ä½œç”¨ã€‚
- en: Introduction to generative AI
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIç®€ä»‹
- en: Generative AI refers to a class of AI technologies that is capable of generating
    various forms of content, including but not limited to text, images, audio, and
    video. These AI systems can generate new content, based on their training data
    and input parameters, which usually include text prompts but can also involve
    other forms of input such as images. The recent buzz around generative AI comes
    from the simplicity with which new user interfaces powered by this AI technology
    can create high-quality text, graphics, and videos in seconds.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIæŒ‡çš„æ˜¯ä¸€ç±»èƒ½å¤Ÿç”Ÿæˆå„ç§å½¢å¼å†…å®¹çš„äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘ã€‚è¿™äº›AIç³»ç»Ÿå¯ä»¥æ ¹æ®å…¶è®­ç»ƒæ•°æ®å’Œè¾“å…¥å‚æ•°ç”Ÿæˆæ–°çš„å†…å®¹ï¼Œé€šå¸¸åŒ…æ‹¬æ–‡æœ¬æç¤ºï¼Œä½†ä¹Ÿå¯èƒ½æ¶‰åŠå…¶ä»–å½¢å¼çš„è¾“å…¥ï¼Œå¦‚å›¾åƒã€‚æœ€è¿‘å›´ç»•ç”Ÿæˆå¼AIçš„ç‚’ä½œæºäºè¿™ç§AIæŠ€æœ¯æ”¯æŒçš„æ–°ç”¨æˆ·ç•Œé¢èƒ½å¤Ÿä»¥æç®€çš„æ–¹å¼åœ¨å‡ ç§’é’Ÿå†…åˆ›å»ºé«˜è´¨é‡çš„æ–‡æœ¬ã€å›¾å½¢å’Œè§†é¢‘ã€‚
- en: In very simple terms, generative AI is about making new data that looks like
    the data from which it has been trained. In other words, learning the underlying
    patterns, structures, and distributions of input data enables a procedure within
    the model allowing it to generate new data in a similar way. For instance, if
    trained on a dataset of human faces, a generative AI model will be able to create
    completely new faces of people that donâ€™t actually exist in real life but are
    very realistic. In essence, generative AI models work by learning the probability
    distribution of a dataset and then sampling from that distribution to create new
    instances. This approach is different from discriminative models, whose goal is
    to learn how to tell classes of data apart. For example, a discriminative model
    could be trained to separate pictures of cats and dogs, but a generative model
    would be trained to make up completely new pictures of cats or dogs.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ç”¨éå¸¸ç®€å•çš„æœ¯è¯­æ¥è¯´ï¼Œç”Ÿæˆå¼AIæ˜¯å…³äºåˆ›å»ºçœ‹èµ·æ¥åƒå…¶è®­ç»ƒæ•°æ®çš„æ–°æ•°æ®ã€‚æ¢å¥è¯è¯´ï¼Œå­¦ä¹ è¾“å…¥æ•°æ®çš„åº•å±‚æ¨¡å¼ã€ç»“æ„å’Œåˆ†å¸ƒï¼Œä½¿å¾—æ¨¡å‹å†…éƒ¨çš„ä¸€ä¸ªè¿‡ç¨‹èƒ½å¤Ÿä»¥ç±»ä¼¼çš„æ–¹å¼ç”Ÿæˆæ–°æ•°æ®ã€‚ä¾‹å¦‚ï¼Œå¦‚æœåœ¨ä¸€ä¸ªåŒ…å«äººç±»é¢éƒ¨æ•°æ®é›†ä¸Šè®­ç»ƒï¼Œä¸€ä¸ªç”Ÿæˆå¼AIæ¨¡å‹å°†èƒ½å¤Ÿåˆ›å»ºå‡ºå®Œå…¨ä¸å­˜åœ¨äºç°å®ç”Ÿæ´»ä¸­çš„æ–°é¢å­”ï¼Œä½†è¿™äº›é¢å­”éå¸¸é€¼çœŸã€‚æœ¬è´¨ä¸Šï¼Œç”Ÿæˆå¼AIæ¨¡å‹é€šè¿‡å­¦ä¹ æ•°æ®é›†çš„æ¦‚ç‡åˆ†å¸ƒï¼Œç„¶åä»è¯¥åˆ†å¸ƒä¸­é‡‡æ ·ä»¥åˆ›å»ºæ–°å®ä¾‹æ¥å·¥ä½œã€‚è¿™ç§æ–¹æ³•ä¸åˆ¤åˆ«æ¨¡å‹ä¸åŒï¼Œåˆ¤åˆ«æ¨¡å‹çš„ç›®æ ‡æ˜¯å­¦ä¹ å¦‚ä½•åŒºåˆ†æ•°æ®ç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªåˆ¤åˆ«æ¨¡å‹å¯ä»¥è¢«è®­ç»ƒæ¥åŒºåˆ†çŒ«å’Œç‹—çš„å›¾ç‰‡ï¼Œä½†ä¸€ä¸ªç”Ÿæˆæ¨¡å‹åˆ™è¢«è®­ç»ƒæ¥åˆ¶ä½œçŒ«æˆ–ç‹—çš„å…¨æ–°å›¾ç‰‡ã€‚
- en: The concept of generative AI goes a long way back; in fact, it dates back to
    the time when machine learning was in its cradle. However, it is only recently
    that this field has come under the limelight due to neural networks and drastic
    improvements in computing power over the last 10 years. In the early attempts
    at generative modelingâ€”Gaussian mixture models and hidden Markov modelsâ€”many simpler
    statistical techniques were involved. Methods of modeling arbitrary complex data
    distributions have much higher potential compatibility with the kinds of methods
    that were previously dominant but have recently been overcome by deep learning.
    Deep learning was therefore a watershed development for the field of generative
    AI. Models, such as VAEs, which started appearing around the beginning of the
    2010s, were able to leverage deep neural networks to model more complex data distributions.
    Around that same period, GANs were proposed; for the first time, they offered
    a new way for two neural networks to work together to create data, using principles
    from game theory. In a general sense, these breakthroughs took leaps toward the
    possibilities of making real, high-quality, realistic creation of data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIçš„æ¦‚å¿µå¯ä»¥è¿½æº¯åˆ°å¾ˆä¹…ä»¥å‰ï¼›å®é™…ä¸Šï¼Œå®ƒå¯ä»¥è¿½æº¯åˆ°æœºå™¨å­¦ä¹ å°šå¤„äºæ‘‡ç¯®æ—¶æœŸçš„æ—¶å€™ã€‚ç„¶è€Œï¼Œç”±äºç¥ç»ç½‘ç»œå’Œè¿‡å»10å¹´è®¡ç®—èƒ½åŠ›çš„å·¨å¤§æå‡ï¼Œè¿™ä¸ªé¢†åŸŸæœ€è¿‘æ‰å—åˆ°å…³æ³¨ã€‚åœ¨æ—©æœŸç”Ÿæˆå»ºæ¨¡å°è¯•ä¸­â€”â€”é«˜æ–¯æ··åˆæ¨¡å‹å’Œéšé©¬å°”å¯å¤«æ¨¡å‹â€”â€”æ¶‰åŠäº†è®¸å¤šç®€å•çš„ç»Ÿè®¡æŠ€æœ¯ã€‚å»ºæ¨¡ä»»æ„å¤æ‚æ•°æ®åˆ†å¸ƒçš„æ–¹æ³•ä¸ä¹‹å‰å ä¸»å¯¼åœ°ä½ä½†æœ€è¿‘è¢«æ·±åº¦å­¦ä¹ æ‰€è¶…è¶Šçš„æ–¹æ³•å…·æœ‰æ›´é«˜çš„å…¼å®¹æ€§ã€‚å› æ­¤ï¼Œæ·±åº¦å­¦ä¹ å¯¹ç”Ÿæˆå¼AIé¢†åŸŸæ¥è¯´æ˜¯ä¸€ä¸ªåˆ†æ°´å²­çš„å‘å±•ã€‚ä¾‹å¦‚ï¼ŒVAEsç­‰æ¨¡å‹åœ¨2010å¹´ä»£åˆå¼€å§‹å‡ºç°ï¼Œèƒ½å¤Ÿåˆ©ç”¨æ·±åº¦ç¥ç»ç½‘ç»œæ¥å»ºæ¨¡æ›´å¤æ‚çš„æ•°æ®åˆ†å¸ƒã€‚åœ¨åŒä¸€ä¸ªæ—¶æœŸï¼ŒGANsè¢«æå‡ºï¼›å®ƒä»¬ç¬¬ä¸€æ¬¡æå‡ºäº†ä¸€ç§è®©ä¸¤ä¸ªç¥ç»ç½‘ç»œé€šè¿‡åšå¼ˆè®ºåŸç†å…±åŒå·¥ä½œä»¥åˆ›å»ºæ•°æ®çš„æ–°æ–¹æ³•ã€‚ä»ä¸€èˆ¬æ„ä¹‰ä¸Šè®²ï¼Œè¿™äº›çªç ´åœ¨å®ç°çœŸå®ã€é«˜è´¨é‡ã€é€¼çœŸæ•°æ®åˆ›å»ºçš„å¯èƒ½æ€§æ–¹é¢è¿ˆå‡ºäº†å·¨å¤§çš„æ­¥ä¼ã€‚
- en: 'This can lead to innovation in most fields across industries, such as healthcare,
    finance, education, travel and hospitality, manufacturing, and more. Generative
    AI in creative industries helps artists and designers think outside the box, helping
    with the conception of new and innovative content. It opens ways for new routes
    of drug discovery and personalized medicine in health. In the business world,
    generative AI works by providing efficient and effective customer engagement through
    personalized content and experiences. The other point involves questioning oneâ€™s
    own stance regarding creativity and originality: when machines are able to pump
    out very similar material, one is automatically forced to think about what creativity
    is, who the artist really is, and what the ethical parameters should be for AI-created
    content.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯ä»¥åœ¨å¤§å¤šæ•°è¡Œä¸šä¸­çš„å¤§å¤šæ•°é¢†åŸŸå¸¦æ¥åˆ›æ–°ï¼Œä¾‹å¦‚åŒ»ç–—ä¿å¥ã€é‡‘èã€æ•™è‚²ã€æ—…æ¸¸å’Œé…’åº—ä¸šã€åˆ¶é€ ä¸šç­‰ç­‰ã€‚åˆ›æ„äº§ä¸šä¸­çš„ç”Ÿæˆå¼AIå¸®åŠ©è‰ºæœ¯å®¶å’Œè®¾è®¡å¸ˆè·³å‡ºæ€ç»´å®šåŠ¿ï¼Œå¸®åŠ©æ„æ€æ–°çš„åˆ›æ–°å†…å®¹ã€‚å®ƒä¸ºè¯ç‰©å‘ç°å’Œä¸ªæ€§åŒ–åŒ»ç–—å¼€è¾Ÿäº†æ–°çš„é€”å¾„ã€‚åœ¨å•†ä¸šä¸–ç•Œä¸­ï¼Œç”Ÿæˆå¼AIé€šè¿‡æä¾›ä¸ªæ€§åŒ–çš„å†…å®¹å’Œä½“éªŒï¼Œä»¥é«˜æ•ˆå’Œæœ‰æ•ˆçš„æ–¹å¼ä¸å®¢æˆ·äº’åŠ¨ã€‚å¦ä¸€ä¸ªè¦ç‚¹æ¶‰åŠè´¨ç–‘è‡ªå·±å¯¹åˆ›é€ åŠ›å’ŒåŸåˆ›æ€§çš„ç«‹åœºï¼šå½“æœºå™¨èƒ½å¤Ÿå¤§é‡äº§å‡ºéå¸¸ç›¸ä¼¼çš„ææ–™æ—¶ï¼Œäººä»¬ä¼šè‡ªåŠ¨è¢«è¿«æ€è€ƒä»€ä¹ˆæ˜¯åˆ›é€ åŠ›ï¼ŒçœŸæ­£çš„è‰ºæœ¯å®¶æ˜¯è°ï¼Œä»¥åŠAIåˆ›å»ºå†…å®¹çš„ä¼¦ç†å‚æ•°åº”è¯¥æ˜¯ä»€ä¹ˆã€‚
- en: Having understood what generative AI is and its brief history, letâ€™s explore
    the different types of generative AI models.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ç†è§£äº†ä»€ä¹ˆæ˜¯ç”Ÿæˆå¼AIåŠå…¶ç®€è¦å†å²ä¹‹åï¼Œè®©æˆ‘ä»¬æ¥æ¢è®¨ä¸åŒç±»å‹çš„ç”Ÿæˆå¼AIæ¨¡å‹ã€‚
- en: Types of generative AI models
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIæ¨¡å‹ç±»å‹
- en: 'Generative AI is an exciting domain of AI that deals with the generation of
    new, synthetic data by learning patterns from existing datasets, aiming to generate
    outputs that share similar statistical properties and characteristics with the
    training data. Here is a broad overview of some of the most prominent types of
    generative models: VAEs, GANs, and autoregressive models.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIæ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªä»¤äººå…´å¥‹çš„é¢†åŸŸï¼Œå®ƒé€šè¿‡ä»ç°æœ‰æ•°æ®é›†ä¸­å­¦ä¹ æ¨¡å¼æ¥ç”Ÿæˆæ–°çš„ã€åˆæˆçš„æ•°æ®ï¼Œæ—¨åœ¨ç”Ÿæˆä¸è®­ç»ƒæ•°æ®å…·æœ‰ç›¸ä¼¼ç»Ÿè®¡ç‰¹æ€§å’Œç‰¹å¾çš„è¾“å‡ºã€‚ä»¥ä¸‹æ˜¯å¯¹ä¸€äº›æœ€çªå‡ºçš„ç”Ÿæˆæ¨¡å‹ç±»å‹çš„æ¦‚è¿°ï¼šVAEã€GANå’Œè‡ªå›å½’æ¨¡å‹ã€‚
- en: VAEs
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VAEs
- en: 'One of the most popular generative models is the VAE. The core idea behind
    VAE consists of learning a probabilistic mapping between data and a latent space,
    and vice versa. This means learning how to convert real data into a simplified
    representation (such as a compressed form) and then back again into data that
    looks real. VAEs are designed to ensure a high likelihood of the data while preserving
    a well-structured latent space to enable the generation of new data samples similar
    to the training data. Some of the most common flavors of VAE are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€å—æ¬¢è¿çš„ç”Ÿæˆå¼æ¨¡å‹ä¹‹ä¸€æ˜¯VAEã€‚VAEèƒŒåçš„æ ¸å¿ƒæ€æƒ³æ˜¯å­¦ä¹ æ•°æ®ä¸æ½œåœ¨ç©ºé—´ä¹‹é—´çš„æ¦‚ç‡æ˜ å°„ï¼Œåä¹‹äº¦ç„¶ã€‚è¿™æ„å‘³ç€å­¦ä¹ å¦‚ä½•å°†çœŸå®æ•°æ®è½¬æ¢ä¸ºç®€åŒ–çš„è¡¨ç¤ºï¼ˆä¾‹å¦‚å‹ç¼©å½¢å¼ï¼‰ï¼Œç„¶åå†å°†å…¶è½¬æ¢å›çœ‹èµ·æ¥çœŸå®çš„æ•°æ®ã€‚VAEsè¢«è®¾è®¡ç”¨æ¥ç¡®ä¿æ•°æ®çš„é«˜å¯èƒ½æ€§ï¼ŒåŒæ—¶ä¿ç•™ä¸€ä¸ªç»“æ„è‰¯å¥½çš„æ½œåœ¨ç©ºé—´ï¼Œä»¥ä¾¿ç”Ÿæˆä¸è®­ç»ƒæ•°æ®ç›¸ä¼¼çš„æ–°æ•°æ®æ ·æœ¬ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›æœ€å¸¸è§çš„VAEå˜ä½“ï¼š
- en: '**VAE** : The basic model that compresses and reconstructs data. It gives a
    framework for generating new samples out of the learned latent space. The VAE
    is a generative model that learns to compress and reconstruct data while also
    learning a probability distribution of the latent space. In simpler terms, a VAE
    is like a clever algorithm that learns to understand and recreate data. Imagine
    it as a skilled artist who can compress a detailed painting into a simple sketch
    (encoding) and then recreate the full painting from that sketch (decoding). What
    makes VAEs special is that they donâ€™t just copy data but also learn the essence
    of it, allowing them to create new, similar data. This is like an artist learning
    not just to copy specific paintings but also to understand the style so well that
    they can paint new, original works in that style. In real life, VAEs have been
    used in many creative ways. For instance, in drug discovery, VAEs have been used
    to generate novel molecular structures. Researchers at AstraZeneca used VAEs to
    explore chemical space and propose new drug-like molecules with desired properties,
    potentially accelerating the drug development process [1].'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VAE**ï¼šè¿™æ˜¯ä¸€ç§åŸºæœ¬çš„æ¨¡å‹ï¼Œç”¨äºå‹ç¼©å’Œé‡å»ºæ•°æ®ã€‚å®ƒæä¾›äº†ä¸€ä¸ªæ¡†æ¶ï¼Œç”¨äºä»å­¦ä¹ åˆ°çš„æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆæ–°çš„æ ·æœ¬ã€‚VAEæ˜¯ä¸€ç§ç”Ÿæˆæ¨¡å‹ï¼Œå®ƒå­¦ä¹ å‹ç¼©å’Œé‡å»ºæ•°æ®çš„åŒæ—¶ï¼Œä¹Ÿå­¦ä¹ æ½œåœ¨ç©ºé—´çš„æ¦‚ç‡åˆ†å¸ƒã€‚ç®€å•æ¥è¯´ï¼ŒVAEå°±åƒæ˜¯ä¸€ä¸ªèªæ˜çš„ç®—æ³•ï¼Œå®ƒå­¦ä¼šäº†ç†è§£å’Œé‡å»ºæ•°æ®ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œå®ƒå°±åƒä¸€ä¸ªæŠ€è‰ºé«˜è¶…çš„è‰ºæœ¯å®¶ï¼Œå¯ä»¥å°†ä¸€å¹…è¯¦ç»†çš„ç”»ä½œå‹ç¼©æˆç®€å•çš„ç´ æï¼ˆç¼–ç ï¼‰ï¼Œç„¶åä»é‚£ä¸ªç´ æä¸­é‡æ–°åˆ›ä½œå‡ºå®Œæ•´çš„ç”»ä½œï¼ˆè§£ç ï¼‰ã€‚VAEçš„ç‹¬ç‰¹ä¹‹å¤„åœ¨äºï¼Œå®ƒä»¬ä¸ä»…å¤åˆ¶æ•°æ®ï¼Œè¿˜å­¦ä¹ æ•°æ®çš„æœ¬è´¨ï¼Œä»è€Œèƒ½å¤Ÿåˆ›å»ºæ–°çš„ã€ç±»ä¼¼çš„æ•°æ®ã€‚è¿™å°±åƒä¸€ä¸ªè‰ºæœ¯å®¶ä¸ä»…å­¦ä¼šäº†å¤åˆ¶ç‰¹å®šçš„ç”»ä½œï¼Œè€Œä¸”å¯¹é£æ ¼çš„ç†è§£å¦‚æ­¤ä¹‹æ·±ï¼Œä»¥è‡³äºä»–ä»¬å¯ä»¥ä»¥é‚£ç§é£æ ¼åˆ›ä½œå‡ºæ–°çš„ã€åŸåˆ›çš„ä½œå“ã€‚åœ¨ç°å®ç”Ÿæ´»ä¸­ï¼ŒVAEså·²ç»è¢«ç”¨äºè®¸å¤šåˆ›é€ æ€§çš„æ–¹å¼ã€‚ä¾‹å¦‚ï¼Œåœ¨è¯ç‰©å‘ç°ä¸­ï¼ŒVAEsè¢«ç”¨äºç”Ÿæˆæ–°çš„åˆ†å­ç»“æ„ã€‚é˜¿æ–¯åˆ©åº·çš„ç ”ç©¶äººå‘˜ä½¿ç”¨VAEsæ¥æ¢ç´¢åŒ–å­¦ç©ºé—´ï¼Œå¹¶æå‡ºå…·æœ‰æ‰€éœ€ç‰¹æ€§çš„æ–°å‹è¯ç‰©åˆ†å­ï¼Œè¿™å¯èƒ½ä¼šåŠ é€Ÿè¯ç‰©å¼€å‘è¿‡ç¨‹[1]ã€‚'
- en: '**Beta-VAE** : An extension of VAE that introduces a hyperparameter to control
    explicitly the trade-off between the reconstruction quality and the disentanglement
    of the latent space. The model undertakes the creation of more interpretable disentangled
    representations. In simpler terms, Beta-VAE is like a more flexible version of
    the original VAE. It allows researchers to adjust how much the model focuses on
    recreating exact details versus understanding the underlying features of the data.
    This is similar to teaching an art student to not just copy a painting but also
    to understand and separate the key elements such as color, shape, and style. This
    ability to *disentangle* features makes Beta-VAE particularly useful in fields
    such as computer vision and robotics. For example, researchers have used Beta-VAE
    to teach robots to understand objects better. By learning to separate features
    such as size, color, and position, robots can more easily recognize and manipulate
    objects in different situations, making them more adaptable and efficient in various
    tasks [2].'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Beta-VAE**ï¼šVAEçš„ä¸€ç§æ‰©å±•ï¼Œå¼•å…¥äº†ä¸€ä¸ªè¶…å‚æ•°æ¥æ˜¾å¼åœ°æ§åˆ¶é‡å»ºè´¨é‡å’Œæ½œåœ¨ç©ºé—´è§£è€¦ä¹‹é—´çš„æƒè¡¡ã€‚è¯¥æ¨¡å‹æ‰¿æ‹…äº†åˆ›å»ºæ›´å¤šå¯è§£é‡Šçš„è§£è€¦è¡¨ç¤ºçš„ä»»åŠ¡ã€‚ç®€å•æ¥è¯´ï¼ŒBeta-VAEå°±åƒæ˜¯ä¸€ä¸ªæ›´çµæ´»çš„åŸç‰ˆVAEã€‚å®ƒå…è®¸ç ”ç©¶äººå‘˜è°ƒæ•´æ¨¡å‹åœ¨é‡å»ºç²¾ç¡®ç»†èŠ‚å’Œç†è§£æ•°æ®åŸºæœ¬ç‰¹å¾ä¹‹é—´çš„å…³æ³¨ç¨‹åº¦ã€‚è¿™ç±»ä¼¼äºæ•™ä¸€ä¸ªè‰ºæœ¯å­¦ç”Ÿä¸ä»…å¤åˆ¶ä¸€å¹…ç”»ï¼Œè¿˜è¦ç†è§£å’ŒåŒºåˆ†å…³é”®å…ƒç´ ï¼Œå¦‚é¢œè‰²ã€å½¢çŠ¶å’Œé£æ ¼ã€‚è¿™ç§*è§£è€¦*ç‰¹å¾çš„èƒ½åŠ›ä½¿Beta-VAEåœ¨è®¡ç®—æœºè§†è§‰å’Œæœºå™¨äººå­¦ç­‰é¢†åŸŸç‰¹åˆ«æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œç ”ç©¶äººå‘˜å·²ç»ä½¿ç”¨Beta-VAEæ¥æ•™æœºå™¨äººæ›´å¥½åœ°ç†è§£ç‰©ä½“ã€‚é€šè¿‡å­¦ä¹ åˆ†ç¦»å¤§å°ã€é¢œè‰²å’Œä½ç½®ç­‰ç‰¹å¾ï¼Œæœºå™¨äººå¯ä»¥æ›´å®¹æ˜“åœ°åœ¨ä¸åŒæƒ…å†µä¸‹è¯†åˆ«å’Œæ“ä½œç‰©ä½“ï¼Œä½¿å®ƒä»¬åœ¨å„ç§ä»»åŠ¡ä¸­æ›´åŠ é€‚åº”å’Œé«˜æ•ˆ
    [2]ã€‚'
- en: '**Conditional variational autoencoder** ( **CVAE** ): A variant that conditions
    the generation process on some extra information, typically class labels, producing
    not just data similar to the training set but also samples that can then be drawn
    from specific classes . Think of CVAE as a more controlled version of VAE, like
    an artist who can paint in different styles on demand. Instead of just creating
    random new paintings, this artist can be told to â€œ *Paint a landscape* â€ or â€œ
    *Paint a portrait* â€ and theyâ€™ll create new art in that specific category. This
    added control makes CVAE very useful in practical applications. For instance,
    in the field of computer games, CVAE has been used for game development and procedural
    content generation with the generation of game elements such as character design,
    level layouts, music and sound effects, and so on. By providing different conditions
    such as â€œ *Create a forest level* â€ or â€œ *Create a desert level* ,â€ the CVAE can
    produce a wide variety of game environments, saving time for designers and enhancing
    the playerâ€™s experience with more diverse and interesting game worlds [3].'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨**ï¼ˆ**CVAE**ï¼‰ï¼šä¸€ç§å˜ä½“ï¼Œå®ƒå°†ç”Ÿæˆè¿‡ç¨‹æ¡ä»¶åŒ–åœ¨é¢å¤–ä¿¡æ¯ä¸Šï¼Œé€šå¸¸æ˜¯ç±»åˆ«æ ‡ç­¾ï¼Œä¸ä»…äº§ç”Ÿä¸è®­ç»ƒé›†ç›¸ä¼¼çš„æ•°æ®ï¼Œè¿˜å¯ä»¥ä»ä¸­æŠ½å–ç‰¹å®šç±»åˆ«çš„æ ·æœ¬ã€‚å°†CVAEè§†ä¸ºä¸€ä¸ªæ›´å—æ§åˆ¶çš„VAEç‰ˆæœ¬ï¼Œå°±åƒä¸€ä¸ªå¯ä»¥æ ¹æ®éœ€æ±‚ç»˜åˆ¶ä¸åŒé£æ ¼çš„è‰ºæœ¯å®¶ã€‚è¿™ä½è‰ºæœ¯å®¶ä¸ä»…ä¼šéšæœºåˆ›ä½œæ–°çš„ç”»ä½œï¼Œè¿˜å¯ä»¥è¢«è¦æ±‚â€œ*ç”»ä¸€å¹…é£æ™¯ç”»*â€æˆ–â€œ*ç”»ä¸€å¹…è‚–åƒç”»*â€ï¼Œä»–ä»¬å°†åœ¨ç‰¹å®šç±»åˆ«ä¸­åˆ›ä½œæ–°çš„è‰ºæœ¯ä½œå“ã€‚è¿™ç§é¢å¤–çš„æ§åˆ¶ä½¿CVAEåœ¨å®ç”¨åº”ç”¨ä¸­éå¸¸æœ‰ç”¨ã€‚ä¾‹å¦‚ï¼Œåœ¨è®¡ç®—æœºæ¸¸æˆé¢†åŸŸï¼ŒCVAEå·²è¢«ç”¨äºæ¸¸æˆå¼€å‘å’Œç¨‹åºå†…å®¹ç”Ÿæˆï¼ŒåŒ…æ‹¬è§’è‰²è®¾è®¡ã€å…³å¡å¸ƒå±€ã€éŸ³ä¹å’ŒéŸ³æ•ˆç­‰æ¸¸æˆå…ƒç´ ã€‚é€šè¿‡æä¾›ä¸åŒçš„æ¡ä»¶ï¼Œå¦‚â€œ*åˆ›å»ºä¸€ä¸ªæ£®æ—å…³å¡*â€æˆ–â€œ*åˆ›å»ºä¸€ä¸ªæ²™æ¼ å…³å¡*â€ï¼ŒCVAEå¯ä»¥äº§ç”Ÿå„ç§å„æ ·çš„æ¸¸æˆç¯å¢ƒï¼Œä¸ºè®¾è®¡å¸ˆèŠ‚çœæ—¶é—´ï¼Œå¹¶é€šè¿‡æ›´å¤šæ ·åŒ–å’Œæœ‰è¶£çš„æ¸¸æˆä¸–ç•Œæ¥å¢å¼ºç©å®¶çš„ä½“éªŒ
    [3]ã€‚'
- en: GANs
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GANs
- en: 'A GAN is basically formed by two neural networks: a **generator** and a **discriminator**
    . The generator generates synthetic data samples; the other trained neural network
    should then be able to tell the difference between real and created samples. While
    training these networks, they are trained together antagonistically: the generator
    tries to fool the discriminator, while the discriminator tries rightly to classify
    real versus fake data. In this competition, the generator gets better and better
    at faking data. The following are some of the different types of GANs:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: GANåŸºæœ¬ä¸Šç”±ä¸¤ä¸ªç¥ç»ç½‘ç»œç»„æˆï¼šä¸€ä¸ª**ç”Ÿæˆå™¨**å’Œä¸€ä¸ª**åˆ¤åˆ«å™¨**ã€‚ç”Ÿæˆå™¨ç”Ÿæˆåˆæˆæ•°æ®æ ·æœ¬ï¼›å¦ä¸€ä¸ªè®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œåº”è¯¥èƒ½å¤ŸåŒºåˆ†çœŸå®å’Œåˆ›å»ºçš„æ ·æœ¬ã€‚åœ¨è®­ç»ƒè¿™äº›ç½‘ç»œæ—¶ï¼Œå®ƒä»¬æ˜¯ç›¸äº’å¯¹æŠ—åœ°è®­ç»ƒçš„ï¼šç”Ÿæˆå™¨è¯•å›¾æ¬ºéª—åˆ¤åˆ«å™¨ï¼Œè€Œåˆ¤åˆ«å™¨åˆ™è¯•å›¾æ­£ç¡®åœ°åˆ†ç±»çœŸå®å’Œä¼ªé€ æ•°æ®ã€‚åœ¨è¿™åœºç«äº‰ä¸­ï¼Œç”Ÿæˆå™¨åœ¨ä¼ªé€ æ•°æ®æ–¹é¢å˜å¾—è¶Šæ¥è¶Šæ“…é•¿ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ä¸åŒç±»å‹çš„GANï¼š
- en: '**GAN** : The basic model in which the generator and discriminator are trained
    adversarially; it is the root model for most innovations in generative modeling.
    As explained earlier, you can imagine GAN as a game between two playersâ€”a counterfeiter
    (generator) trying to create fake money, and a detective (discriminator) trying
    to identify the fakes. As they compete, they both get better at their jobs, which
    means that the counterfeiter gets increasingly better at creating fake money.
    This clever setup allows GANs to create incredibly realistic fake data, such as
    images or sounds [4].'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GAN**ï¼šè¿™æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨é€šè¿‡å¯¹æŠ—æ€§è®­ç»ƒçš„åŸºæœ¬æ¨¡å‹ï¼›å®ƒæ˜¯å¤§å¤šæ•°ç”Ÿæˆæ¨¡å‹åˆ›æ–°çš„åŸºç¡€æ¨¡å‹ã€‚å¦‚å‰æ‰€è¿°ï¼Œä½ å¯ä»¥å°† GAN æƒ³è±¡æˆä¸¤ä¸ªç©å®¶ä¹‹é—´çš„æ¸¸æˆâ€”â€”ä¸€ä¸ªä¼ªé€ è€…ï¼ˆç”Ÿæˆå™¨ï¼‰è¯•å›¾åˆ¶é€ å‡å¸ï¼Œè€Œä¸€ä¸ªä¾¦æ¢ï¼ˆåˆ¤åˆ«å™¨ï¼‰è¯•å›¾è¯†åˆ«å‡å¸ã€‚éšç€ä»–ä»¬ä¹‹é—´çš„ç«äº‰ï¼Œä»–ä»¬å„è‡ªçš„å·¥ä½œéƒ½å˜å¾—æ›´å¥½ï¼Œè¿™æ„å‘³ç€ä¼ªé€ è€…åˆ¶é€ å‡å¸çš„èƒ½åŠ›è¶Šæ¥è¶Šå¼ºã€‚è¿™ç§å·§å¦™çš„è®¾ç½®ä½¿å¾—
    GANs èƒ½å¤Ÿåˆ›å»ºæå…¶é€¼çœŸçš„å‡æ•°æ®ï¼Œå¦‚å›¾åƒæˆ–å£°éŸ³ [4]ã€‚'
- en: '**Deep convolutional GAN** ( **DCGAN** ): This is a refinement of the base
    GAN model with deep convolutional neural networks; at the moment, it is one of
    the best architectures for generating images of high quality. Think of DCGAN as
    a more sophisticated artist compared to the basic GAN. Itâ€™s like upgrading from
    simple sketching tools to a full digital art studio, allowing for the creation
    of much more detailed and realistic images. DCGANs are particularly good at understanding
    and recreating complex patterns in images [5].'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ·±åº¦å·ç§¯ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ** ( **DCGAN** )ï¼šè¿™æ˜¯åŸºäºæ·±åº¦å·ç§¯ç¥ç»ç½‘ç»œå¯¹åŸºç¡€ GAN æ¨¡å‹çš„ä¸€ç§æ”¹è¿›ï¼›ç›®å‰ï¼Œå®ƒæ˜¯ç”Ÿæˆé«˜è´¨é‡å›¾åƒçš„æœ€ä½³æ¶æ„ä¹‹ä¸€ã€‚å°†
    DCGAN æƒ³è±¡æˆä¸€ä¸ªæ¯”åŸºæœ¬ GAN æ›´ä¸ºå¤æ‚çš„è‰ºæœ¯å®¶ã€‚å®ƒå°±åƒæ˜¯ä»ç®€å•çš„ç´ æå·¥å…·å‡çº§åˆ°å®Œæ•´çš„æ•°å­—è‰ºæœ¯å·¥ä½œå®¤ï¼Œå…è®¸åˆ›å»ºæ›´åŠ è¯¦ç»†å’Œé€¼çœŸçš„å›¾åƒã€‚DCGANs ç‰¹åˆ«æ“…é•¿ç†è§£å’Œé‡ç°å›¾åƒä¸­çš„å¤æ‚æ¨¡å¼
    [5]ã€‚'
- en: '**Wasserstein GAN** ( **WGAN** ): This proposes a different loss function with
    the Wasserstein distance. This removes problems while training with a GAN, hence
    making training more stable and improving sample quality. This helps measure the
    distance between two probability distributions better. WGAN is like giving the
    artist (generator) and critic (discriminator) in a GAN a better way to communicate
    and evaluate each otherâ€™s work. Instead of just saying â€œ *good* â€ or â€œ *bad* ,â€
    they can now give more nuanced feedback, such as â€œ *Youâ€™re getting warmer* â€ or
    â€œ *Youâ€™re way off* .â€ This leads to more consistent improvement and high-quality
    results. In practical applications, WGANs have been used in medical imaging to
    generate synthetic medical images for training purposes. This helps in creating
    larger, more diverse datasets for training diagnostic AI systems, potentially
    improving their accuracy in detecting diseases from scans and X-rays [6].'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Wasserstein GAN** ( **WGAN** )ï¼šè¿™æå‡ºäº†ä¸€ä¸ªä½¿ç”¨ Wasserstein è·ç¦»çš„ä¸åŒæŸå¤±å‡½æ•°ã€‚è¿™æ¶ˆé™¤äº†ä½¿ç”¨ GAN
    è®­ç»ƒæ—¶çš„é—®é¢˜ï¼Œå› æ­¤ä½¿è®­ç»ƒæ›´åŠ ç¨³å®šå¹¶æé«˜æ ·æœ¬è´¨é‡ã€‚è¿™æœ‰åŠ©äºæ›´å¥½åœ°è¡¡é‡ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒä¹‹é—´çš„è·ç¦»ã€‚WGAN å°±åƒæ˜¯ç»™ GAN ä¸­çš„è‰ºæœ¯å®¶ï¼ˆç”Ÿæˆå™¨ï¼‰å’Œè¯„è®ºå®¶ï¼ˆåˆ¤åˆ«å™¨ï¼‰æä¾›äº†ä¸€ä¸ªæ›´å¥½çš„æ²Ÿé€šå’Œè¯„ä¼°å½¼æ­¤ä½œå“çš„æ–¹å¼ã€‚ä»–ä»¬ç°åœ¨ä¸ä»…å¯ä»¥è¯´å‡ºâ€œ*å¥½*â€æˆ–â€œ*å*â€ï¼Œè¿˜å¯ä»¥ç»™å‡ºæ›´ç»†å¾®çš„åé¦ˆï¼Œä¾‹å¦‚â€œ*ä½ è¶Šæ¥è¶Šæ¥è¿‘äº†*â€æˆ–â€œ*ä½ å®Œå…¨é”™äº†*â€ã€‚è¿™å¯¼è‡´æ›´ä¸€è‡´çš„æ”¹è¿›å’Œé«˜å“è´¨çš„ç»“æœã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒWGANs
    å·²è¢«ç”¨äºåŒ»å­¦æˆåƒï¼Œç”¨äºç”Ÿæˆç”¨äºè®­ç»ƒç›®çš„çš„åˆæˆåŒ»å­¦å›¾åƒã€‚è¿™æœ‰åŠ©äºåˆ›å»ºæ›´å¤§çš„ã€æ›´å¤šæ ·åŒ–çš„æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒè¯Šæ–­äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œå¯èƒ½æé«˜å…¶ä»æ‰«æå’Œ X å°„çº¿ä¸­æ£€æµ‹ç–¾ç—…å‡†ç¡®æ€§çš„èƒ½åŠ›
    [6]ã€‚'
- en: '**StyleGAN** : This generates high-quality realistic images. The model is especially
    good at handling style and content separately. Progressions offered by the introductions
    of StyleGAN2 and StyleGAN3 are still aimed at improving image fidelity and realism.
    Think of StyleGAN as an advanced digital artist that can not only create realistic
    images but also mix and match different styles and contents. Itâ€™s like having
    a painter who can take the style of Van Gogh and apply it to a modern cityscape.
    This flexibility makes StyleGAN incredibly versatile [7].'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**StyleGAN**ï¼šå®ƒç”Ÿæˆé«˜è´¨é‡çš„é€¼çœŸå›¾åƒã€‚è¯¥æ¨¡å‹ç‰¹åˆ«æ“…é•¿åˆ†åˆ«å¤„ç†é£æ ¼å’Œå†…å®¹ã€‚StyleGAN2 å’Œ StyleGAN3 çš„å¼•å…¥å¸¦æ¥çš„è¿›å±•ä»ç„¶æ—¨åœ¨æé«˜å›¾åƒçš„ä¿çœŸåº¦å’Œé€¼çœŸåº¦ã€‚å°†
    StyleGAN æƒ³è±¡æˆä¸€ä¸ªé«˜çº§æ•°å­—è‰ºæœ¯å®¶ï¼Œä»–ä¸ä»…èƒ½åˆ›å»ºé€¼çœŸçš„å›¾åƒï¼Œè¿˜èƒ½æ··åˆå’ŒåŒ¹é…ä¸åŒçš„é£æ ¼å’Œå†…å®¹ã€‚è¿™å°±åƒæœ‰ä¸€ä¸ªç”»å®¶ï¼Œä»–å¯ä»¥å°†æ¢µé«˜çš„é£æ ¼åº”ç”¨åˆ°ç°ä»£åŸå¸‚æ™¯è§‚ä¸­ã€‚è¿™ç§çµæ´»æ€§ä½¿
    StyleGAN æå…¶å¤šæ‰å¤šè‰º [7]ã€‚'
- en: Autoregressive models and Transformer architecture
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è‡ªå›å½’æ¨¡å‹å’Œ Transformer æ¶æ„
- en: 'Autoregressive models generate their data points one at a time, conditioning
    each of its data points on the previous one. Surprisingly, this ultimately proves
    very useful in tasks in which the sequence or structure of data is relevant, such
    as text generation and image generation. The Transformer architecture, introduced
    in the *Attention Is All You Need* paper [8], is a model architecture that has
    revolutionized many sequential data tasks, especially in **natural language processing**
    ( **NLP** ). Its key components are demonstrated in *Figure 1* *.1* :'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: è‡ªå›å½’æ¨¡å‹ä¸€æ¬¡ç”Ÿæˆä¸€ä¸ªæ•°æ®ç‚¹ï¼Œæ¯ä¸ªæ•°æ®ç‚¹éƒ½åŸºäºå‰ä¸€ä¸ªæ•°æ®ç‚¹ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œè¿™æœ€ç»ˆåœ¨åºåˆ—æˆ–æ•°æ®ç»“æ„ç›¸å…³çš„ä»»åŠ¡ä¸­éå¸¸æœ‰ç”¨ï¼Œä¾‹å¦‚æ–‡æœ¬ç”Ÿæˆå’Œå›¾åƒç”Ÿæˆã€‚åœ¨ã€Š*æ³¨æ„åŠ›å³æ˜¯æ‰€æœ‰ä½ éœ€è¦*ã€‹è®ºæ–‡
    [8] ä¸­å¼•å…¥çš„Transformeræ¶æ„æ˜¯ä¸€ç§å·²ç»å½»åº•æ”¹å˜äº†è®¸å¤šåºåˆ—æ•°æ®ä»»åŠ¡çš„æ¨¡å‹æ¶æ„ï¼Œç‰¹åˆ«æ˜¯åœ¨**è‡ªç„¶è¯­è¨€å¤„ç†**ï¼ˆ**NLP**ï¼‰æ–¹é¢ã€‚å…¶å…³é”®ç»„ä»¶åœ¨*å›¾1*
    *.1* ä¸­å±•ç¤ºï¼š
- en: '![img](img/B31483_01_1.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B31483_01_1.jpg)'
- en: Figure 1.1 â€“ The Transformer architecture
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾1.1 â€“ Transformeræ¶æ„
- en: 'These key components include the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›å…³é”®ç»„ä»¶åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š
- en: '**Self-attention m** **echanism** : A computational technique that allows the
    model to dynamically focus on different parts of the input when processing each
    element'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è‡ªæ³¨æ„åŠ›æœºåˆ¶**ï¼šä¸€ç§è®¡ç®—æŠ€æœ¯ï¼Œå…è®¸æ¨¡å‹åœ¨å¤„ç†æ¯ä¸ªå…ƒç´ æ—¶åŠ¨æ€åœ°å…³æ³¨è¾“å…¥çš„ä¸åŒéƒ¨åˆ†'
- en: '**Multi-head attention** : Multiple attention mechanisms running in parallel,
    allowing the model to focus on different aspects of the input simultaneously'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¤šå¤´æ³¨æ„åŠ›**ï¼šå¹¶è¡Œè¿è¡Œå¤šä¸ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå…è®¸æ¨¡å‹åŒæ—¶å…³æ³¨è¾“å…¥çš„ä¸åŒæ–¹é¢'
- en: '**Positional encoding** : Adds information about the position of each element
    in the sequence'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä½ç½®ç¼–ç **ï¼šä¸ºåºåˆ—ä¸­æ¯ä¸ªå…ƒç´ çš„ä½ç½®æ·»åŠ ä¿¡æ¯'
- en: '**Feed-forward neural networks** : Process the output of the attention layers'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å‰é¦ˆç¥ç»ç½‘ç»œ**ï¼šå¤„ç†æ³¨æ„åŠ›å±‚çš„è¾“å‡º'
- en: '**Layer normalization and residual connections** : Enhance training stability
    and information flow'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å±‚å½’ä¸€åŒ–å’Œæ®‹å·®è¿æ¥**ï¼šå¢å¼ºè®­ç»ƒç¨³å®šæ€§å’Œä¿¡æ¯æµ'
- en: 'Transformers can be used in both autoregressive and non-autoregressive configurations,
    making them versatile for various tasks. The following are some examples:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Transformerå¯ä»¥ç”¨äºè‡ªå›å½’å’Œéè‡ªå›å½’é…ç½®ï¼Œä½¿å…¶é€‚ç”¨äºå„ç§ä»»åŠ¡ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›ç¤ºä¾‹ï¼š
- en: '**PixelCNN** : Autoregressively generates images pixel by pixel, conditioning
    each pixel on the previously generated ones. This model works very well in generating
    high-quality images with fine details [9].'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PixelCNN**ï¼šè‡ªå›å½’åœ°é€åƒç´ ç”Ÿæˆå›¾åƒï¼Œæ¯ä¸ªåƒç´ éƒ½åŸºäºä¹‹å‰ç”Ÿæˆçš„åƒç´ ã€‚è¯¥æ¨¡å‹åœ¨ç”Ÿæˆå…·æœ‰ç²¾ç»†ç»†èŠ‚çš„é«˜è´¨é‡å›¾åƒæ–¹é¢è¡¨ç°éå¸¸å¥½ [9]ã€‚'
- en: '**PixelSNAIL** : A refinement over PixelCNN that adds attention mechanisms
    into the model to capture strong dependencies between pixels, and hence, a better
    quality of an image [10].'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PixelSNAIL**ï¼šåœ¨PixelCNNçš„åŸºç¡€ä¸Šè¿›è¡Œæ”¹è¿›ï¼Œå°†æ³¨æ„åŠ›æœºåˆ¶æ·»åŠ åˆ°æ¨¡å‹ä¸­ï¼Œä»¥æ•æ‰åƒç´ ä¹‹é—´çš„å¼ºä¾èµ–å…³ç³»ï¼Œä»è€Œæé«˜å›¾åƒè´¨é‡ [10]ã€‚'
- en: '**GPT** : Standing for **Generative Pre-trained Transformer** , it is a line
    of models specializing in text generationâ€”namely, predicting which words should
    come next. Among them are GPT-2, GPT-3, and GPT-4, making a huge leap in generating
    coherent and contextually relevant text [ 11] [12].'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT**ï¼šä»£è¡¨**ç”Ÿæˆé¢„è®­ç»ƒå˜æ¢å™¨**ï¼Œè¿™æ˜¯ä¸€ç³»åˆ—ä¸“æ³¨äºæ–‡æœ¬ç”Ÿæˆçš„æ¨¡å‹â€”â€”å³é¢„æµ‹æ¥ä¸‹æ¥åº”è¯¥å‡ºç°å“ªäº›å•è¯ã€‚å…¶ä¸­åŒ…å«GPT-2ã€GPT-3å’ŒGPT-4ï¼Œåœ¨ç”Ÿæˆè¿è´¯ä¸”ä¸Šä¸‹æ–‡ç›¸å…³çš„æ–‡æœ¬æ–¹é¢å–å¾—äº†å·¨å¤§é£è·ƒ
    [11] [12]ã€‚'
- en: '**BERT** : Unlike GPT, BERT, which stands for **Bidirectional Encoder Representations
    from Transformers** , is designed to understand the context from both directions
    in text. It uses the encoder part of the Transformer and is typically used for
    tasks that require an understanding of the entire input at once, rather than generating
    text autoregressively [13].'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BERT**ï¼šä¸GPTä¸åŒï¼ŒBERTä»£è¡¨**ä»å˜æ¢å™¨ä¸­æå–çš„åŒå‘ç¼–ç å™¨è¡¨ç¤º**ï¼Œå®ƒæ—¨åœ¨ä»æ–‡æœ¬çš„ä¸¤ä¸ªæ–¹å‘ç†è§£ä¸Šä¸‹æ–‡ã€‚å®ƒä½¿ç”¨Transformerçš„ç¼–ç å™¨éƒ¨åˆ†ï¼Œé€šå¸¸ç”¨äºéœ€è¦ä¸€æ¬¡æ€§ç†è§£æ•´ä¸ªè¾“å…¥çš„ä»»åŠ¡ï¼Œè€Œä¸æ˜¯è‡ªå›å½’åœ°ç”Ÿæˆæ–‡æœ¬
    [13]ã€‚'
- en: '**Text-To-Text Transfer Transformer** ( **T5** ): This model frames all NLP
    tasks in a text-to-text format. It uses the full Transformer architecture (both
    encoder and decoder) and can handle various text generation tasks [14].'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ–‡æœ¬åˆ°æ–‡æœ¬è¿ç§»å˜æ¢å™¨**ï¼ˆ**T5**ï¼‰ï¼šè¯¥æ¨¡å‹å°†æ‰€æœ‰NLPä»»åŠ¡æ¡†æ¶åŒ–ä¸ºæ–‡æœ¬åˆ°æ–‡æœ¬æ ¼å¼ã€‚å®ƒä½¿ç”¨å®Œæ•´çš„Transformeræ¶æ„ï¼ˆç¼–ç å™¨å’Œè§£ç å™¨ï¼‰ï¼Œå¯ä»¥å¤„ç†å„ç§æ–‡æœ¬ç”Ÿæˆä»»åŠ¡
    [14]ã€‚'
- en: Although it depends on the task, these models demonstrate how the Transformer
    architecture can be adapted for both autoregressive (such as GPT) and non-autoregressive
    (such as BERT) tasks, showcasing its versatility in handling sequential data.
    Strengths differ across generative models. This class of models goes from generating
    photorealistic images to coherent text to totally new data samples.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡è¿™äº›æ¨¡å‹å–å†³äºä»»åŠ¡ï¼Œä½†å®ƒä»¬å±•ç¤ºäº†Transformeræ¶æ„å¦‚ä½•é€‚åº”è‡ªå›å½’ï¼ˆä¾‹å¦‚GPTï¼‰å’Œéè‡ªå›å½’ï¼ˆä¾‹å¦‚BERTï¼‰ä»»åŠ¡ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤„ç†åºåˆ—æ•°æ®æ–¹é¢çš„å¤šåŠŸèƒ½æ€§ã€‚ç”Ÿæˆæ¨¡å‹çš„ä¼˜åŠ¿å„ä¸ç›¸åŒã€‚è¿™ç±»æ¨¡å‹ä»ç”Ÿæˆé€¼çœŸçš„å›¾åƒåˆ°ç”Ÿæˆè¿è´¯çš„æ–‡æœ¬ï¼Œå†åˆ°å…¨æ–°çš„æ•°æ®æ ·æœ¬ã€‚
- en: 'Building upon the success of models such as GPT, researchers have scaled up
    these architectures to create **large language models** ( **LLMs** ). These models,
    often trained on vast amounts of open web text and other freely available text
    data, have demonstrated exceptional proficiency in understanding and generating
    human-like text across diverse applications, showcasing their versatility and
    advanced linguistic abilities. Examples of LLMs include GPT-3, GPT-4, PaLM, and
    BERT-large. These models have pushed the boundaries of whatâ€™s possible in NLP,
    showing proficiency in tasks ranging from question-answering and summarization
    to creative writing and code generation. The following is an overview of the common
    types of LLMs:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: å»ºç«‹åœ¨GPTç­‰æ¨¡å‹æˆåŠŸçš„åŸºç¡€ä¸Šï¼Œç ”ç©¶äººå‘˜å°†è¿™äº›æ¶æ„æ‰©å±•åˆ°åˆ›å»º**å¤§å‹è¯­è¨€æ¨¡å‹**ï¼ˆ**LLMs**ï¼‰ã€‚è¿™äº›æ¨¡å‹é€šå¸¸åœ¨å¤§é‡å…¬å¼€ç½‘ç»œæ–‡æœ¬å’Œå…¶ä»–å…è´¹å¯ç”¨çš„æ–‡æœ¬æ•°æ®ä¸Šè®­ç»ƒï¼Œå±•ç¤ºäº†å®ƒä»¬åœ¨ç†è§£å’Œç”Ÿæˆç±»ä¼¼äººç±»æ–‡æœ¬æ–¹é¢çš„å“è¶Šèƒ½åŠ›ï¼Œå±•ç¤ºäº†å®ƒä»¬çš„å¤šæ ·æ€§å’Œé«˜çº§è¯­è¨€èƒ½åŠ›ã€‚LLMsçš„ä¾‹å­åŒ…æ‹¬GPT-3ã€GPT-4ã€PaLMå’ŒBERT-largeã€‚è¿™äº›æ¨¡å‹æ¨åŠ¨äº†è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å¯èƒ½æ€§çš„è¾¹ç•Œï¼Œå±•ç¤ºäº†åœ¨ä»é—®ç­”å’Œæ‘˜è¦åˆ°åˆ›æ„å†™ä½œå’Œä»£ç ç”Ÿæˆç­‰ä»»åŠ¡ä¸­çš„ç†Ÿç»ƒç¨‹åº¦ã€‚ä»¥ä¸‹æ˜¯å¯¹LLMså¸¸è§ç±»å‹çš„æ¦‚è¿°ï¼š
- en: '**Autoregressive LLMs** : These language models are typically capable of generating
    text sequentially, that is, one token at a time. Some of the common tasks that
    these types of models are used for include text generation, text completion tasks,
    and creative writing. Some popular examples of autoregressive LLMs are the GPT
    series (GPT-3, GPT-4), and PaLM.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è‡ªå›å½’LLMs**ï¼šè¿™äº›è¯­è¨€æ¨¡å‹é€šå¸¸èƒ½å¤ŸæŒ‰é¡ºåºç”Ÿæˆæ–‡æœ¬ï¼Œå³ä¸€æ¬¡ç”Ÿæˆä¸€ä¸ªæ ‡è®°ã€‚è¿™äº›ç±»å‹æ¨¡å‹å¸¸ç”¨çš„ä»»åŠ¡åŒ…æ‹¬æ–‡æœ¬ç”Ÿæˆã€æ–‡æœ¬è¡¥å…¨ä»»åŠ¡å’Œåˆ›æ„å†™ä½œã€‚è‡ªå›å½’LLMsçš„æµè¡Œä¾‹å­åŒ…æ‹¬GPTç³»åˆ—ï¼ˆGPT-3ã€GPT-4ï¼‰å’ŒPaLMã€‚'
- en: '**Encoder-only LLMs** : These models specialize in **natural language understanding**
    ( **NLU** ) tasks, which involve analyzing and comprehending input text without
    generating new text. Encoder-only LLMs, such as BERT and its variants including
    RoBERTa, focus on understanding the context and meaning of input text. These models
    process the entire input sequence simultaneously, allowing them to capture the
    context helping with tasks such as text classification, **named entity recognition**
    ( **NER** ), and sentiment analysis.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä»…ç¼–ç å™¨LLMs**ï¼šè¿™äº›æ¨¡å‹ä¸“æ³¨äº**è‡ªç„¶è¯­è¨€ç†è§£**ï¼ˆ**NLU**ï¼‰ä»»åŠ¡ï¼Œæ¶‰åŠåˆ†æå’Œç†è§£è¾“å…¥æ–‡æœ¬è€Œä¸ç”Ÿæˆæ–°æ–‡æœ¬ã€‚ä»…ç¼–ç å™¨LLMsï¼Œå¦‚BERTåŠå…¶å˜ä½“åŒ…æ‹¬RoBERTaï¼Œä¸“æ³¨äºç†è§£è¾“å…¥æ–‡æœ¬çš„ä¸Šä¸‹æ–‡å’Œå«ä¹‰ã€‚è¿™äº›æ¨¡å‹åŒæ—¶å¤„ç†æ•´ä¸ªè¾“å…¥åºåˆ—ï¼Œä½¿å®ƒä»¬èƒ½å¤Ÿæ•æ‰ä¸Šä¸‹æ–‡ï¼Œå¸®åŠ©å®Œæˆæ–‡æœ¬åˆ†ç±»ã€**å‘½åå®ä½“è¯†åˆ«**ï¼ˆ**NER**ï¼‰å’Œæƒ…æ„Ÿåˆ†æç­‰ä»»åŠ¡ã€‚'
- en: '**Encoder-decoder LLMs** : This is a combination of encoder and decoder architecture
    where the models can not only understand the context of the input text (NLU) but
    are also capable of generating textual output. The T5 model discussed earlier
    is a very popular example of an encoder-decoder LLM, along with models such as
    BERT. These models are capable of language translation, summarization, and question-answering.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç¼–ç å™¨-è§£ç å™¨LLMs**ï¼šè¿™æ˜¯ç¼–ç å™¨å’Œè§£ç å™¨æ¶æ„çš„ç»„åˆï¼Œæ¨¡å‹ä¸ä»…èƒ½ç†è§£è¾“å…¥æ–‡æœ¬çš„ä¸Šä¸‹æ–‡ï¼ˆNLUï¼‰ï¼Œè¿˜èƒ½ç”Ÿæˆæ–‡æœ¬è¾“å‡ºã€‚å‰é¢è®¨è®ºçš„T5æ¨¡å‹æ˜¯ç¼–ç å™¨-è§£ç å™¨LLMsçš„ä¸€ä¸ªéå¸¸æµè¡Œçš„ä¾‹å­ï¼Œè¿˜æœ‰BERTç­‰æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œè¯­è¨€ç¿»è¯‘ã€æ‘˜è¦å’Œé—®ç­”ã€‚'
- en: '**Multimodal LLMs** : Multimodality is a concept where an AI model can not
    only handle text but also other modalities such as image, video, and audio. Multimodal
    LLMs can process and generate content in various modalities such as text, image,
    audio, video, and any combination thereof. These models are rather novel in nature
    and recent advancements in compute have made it possible to train multimodal LLMs.
    Some of the well-known multimodal LLMs are DALL-E, Stable Diffusion, Flamingo,
    GPT-4, and LlaVa.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¤šæ¨¡æ€LLMs**ï¼šå¤šæ¨¡æ€æ˜¯ä¸€ä¸ªæ¦‚å¿µï¼Œå³AIæ¨¡å‹ä¸ä»…èƒ½å¤„ç†æ–‡æœ¬ï¼Œè¿˜èƒ½å¤„ç†å…¶ä»–æ¨¡æ€ï¼Œå¦‚å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘ã€‚å¤šæ¨¡æ€LLMså¯ä»¥å¤„ç†å’Œç”Ÿæˆå„ç§æ¨¡æ€çš„å†…å®¹ï¼Œå¦‚æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘åŠå…¶ä»»ä½•ç»„åˆã€‚è¿™äº›æ¨¡å‹åœ¨æœ¬è´¨ä¸Šç›¸å½“æ–°é¢–ï¼Œè®¡ç®—èƒ½åŠ›çš„æœ€æ–°è¿›å±•ä½¿å¾—è®­ç»ƒå¤šæ¨¡æ€LLMsæˆä¸ºå¯èƒ½ã€‚ä¸€äº›çŸ¥åçš„å¤šæ¨¡æ€LLMsåŒ…æ‹¬DALL-Eã€Stable
    Diffusionã€Flamingoã€GPT-4å’ŒLlaVaã€‚'
- en: '**Instruction-tuned LLMs** : LLMs are often trained on a large corpus of openly
    available web or other text. As such, in certain scenarios, these models may not
    perform effectively for tasks that use data that the model has never seen before
    and thus may fail to follow the user intent. For example, a manufacturing manual
    for a proprietary instrument may contain domain-specific proprietary language,
    which the model may not have been exposed to during training. In such cases, LLMs
    can be fine-tuned using the domain-specific data to follow specific instructions
    and prompts (that is, text input to the model). This special fine-tuning enables
    the model to perform domain-specific tasks on which the model was fine-tuned,
    in addition to its other capabilities. Think of this as localizing a personal
    copy of a model to be good at performing a task that is meaningful for your use
    case. One of the common examples of such a model is InstructGPT, where researchers
    fine-tuned the GPT-3 model on specific instructions. These types of models are
    used in a multitude of different tasks such as chatbots, virtual assistants, and
    task-specific applications.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æŒ‡ä»¤è°ƒæ•´çš„LLM**ï¼šLLMé€šå¸¸æ˜¯åœ¨å¤§é‡å…¬å¼€å¯ç”¨çš„ç½‘ç»œæˆ–å…¶ä»–æ–‡æœ¬è¯­æ–™åº“ä¸Šè®­ç»ƒçš„ã€‚å› æ­¤ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œè¿™äº›æ¨¡å‹å¯èƒ½æ— æ³•æœ‰æ•ˆåœ°æ‰§è¡Œä½¿ç”¨æ¨¡å‹ä¹‹å‰ä»æœªè§è¿‡çš„æ•°æ®çš„ä»»åŠ¡ï¼Œä»è€Œå¯èƒ½æ— æ³•éµå¾ªç”¨æˆ·æ„å›¾ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªä¸“æœ‰ä»ªå™¨çš„åˆ¶é€ æ‰‹å†Œå¯èƒ½åŒ…å«ç‰¹å®šé¢†åŸŸçš„ä¸“æœ‰è¯­è¨€ï¼Œè¿™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨¡å‹å¯èƒ½æ²¡æœ‰æ¥è§¦è¿‡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯ä»¥ä½¿ç”¨ç‰¹å®šé¢†åŸŸçš„æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œä»¥ä½¿LLMéµå¾ªç‰¹å®šçš„æŒ‡ä»¤å’Œæç¤ºï¼ˆå³è¾“å…¥åˆ°æ¨¡å‹ä¸­çš„æ–‡æœ¬ï¼‰ã€‚è¿™ç§ç‰¹æ®Šçš„å¾®è°ƒä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å¾®è°ƒçš„ç‰¹å®šé¢†åŸŸä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼ŒåŒæ—¶è¿˜èƒ½å‘æŒ¥å…¶å…¶ä»–èƒ½åŠ›ã€‚å°†å…¶è§†ä¸ºå°†æ¨¡å‹çš„ä¸ªäººå‰¯æœ¬æœ¬åœ°åŒ–ä»¥æ“…é•¿æ‰§è¡Œå¯¹æ‚¨çš„ç”¨ä¾‹æœ‰æ„ä¹‰çš„ä»»åŠ¡ã€‚è¿™ç±»æ¨¡å‹çš„å¸¸è§ä¾‹å­æ˜¯InstructGPTï¼Œå…¶ä¸­ç ”ç©¶äººå‘˜åœ¨ç‰¹å®šæŒ‡ä»¤ä¸Šå¾®è°ƒäº†GPT-3æ¨¡å‹ã€‚è¿™ç±»æ¨¡å‹è¢«ç”¨äºå¤šç§ä¸åŒçš„ä»»åŠ¡ï¼Œå¦‚èŠå¤©æœºå™¨äººã€è™šæ‹ŸåŠ©æ‰‹å’Œç‰¹å®šåº”ç”¨ã€‚'
- en: '**Domain-specific LLMs** : As mentioned earlier, while LLMs are often trained
    on a large set of open, generally available, web data, they may not perform very
    well in domain-specific environments. While instruction-tuned LLMs are an avenue
    to make these general-purpose models work for domain-specific tasks, researchers
    have innovated on training domain-specific LLMs from the ground up. This means
    that these models were pre-trained on highly specialized, domain knowledge. For
    example, the BioBERT model is trained on hyper-specialized medical data, whereas
    LegalBERT is trained on legal documents. These models are useful for specialized
    tasks in specific fields such as medicine, law, and finance.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç‰¹å®šé¢†åŸŸçš„LLM**ï¼šå¦‚å‰æ‰€è¿°ï¼Œè™½ç„¶LLMé€šå¸¸æ˜¯åœ¨å¤§é‡å…¬å¼€ã€æ™®éå¯ç”¨çš„ç½‘ç»œæ•°æ®ä¸Šè®­ç»ƒçš„ï¼Œä½†å®ƒä»¬åœ¨ç‰¹å®šé¢†åŸŸç¯å¢ƒä¸­å¯èƒ½è¡¨ç°ä¸ä½³ã€‚è™½ç„¶æŒ‡ä»¤è°ƒæ•´çš„LLMæ˜¯ä½¿è¿™äº›é€šç”¨æ¨¡å‹é€‚ç”¨äºç‰¹å®šä»»åŠ¡çš„ä¸€æ¡é€”å¾„ï¼Œä½†ç ”ç©¶äººå‘˜å·²ç»ä»åº•å±‚åˆ›æ–°äº†ç‰¹å®šé¢†åŸŸLLMçš„è®­ç»ƒã€‚è¿™æ„å‘³ç€è¿™äº›æ¨¡å‹æ˜¯åœ¨é«˜åº¦ä¸“ä¸šåŒ–çš„ã€é¢†åŸŸçŸ¥è¯†ä¸Šé¢„å…ˆè®­ç»ƒçš„ã€‚ä¾‹å¦‚ï¼ŒBioBERTæ¨¡å‹æ˜¯åœ¨é«˜åº¦ä¸“ä¸šåŒ–çš„åŒ»ç–—æ•°æ®ä¸Šè®­ç»ƒçš„ï¼Œè€ŒLegalBERTæ˜¯åœ¨æ³•å¾‹æ–‡ä»¶ä¸Šè®­ç»ƒçš„ã€‚è¿™äº›æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„ä¸“ä¸šä»»åŠ¡ä¸­éå¸¸æœ‰ç”¨ï¼Œä¾‹å¦‚åŒ»å­¦ã€æ³•å¾‹å’Œé‡‘èã€‚'
- en: LLM-powered AI agents
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMé©±åŠ¨çš„AIä»£ç†
- en: Each of the previously discussed LLM types has its own strengths and weaknesses
    and is well-suited for different applications. However, our focus in this book
    would be to dive deeper into LLM agent capabilities and explore how advanced systems
    can be built utilizing them. It is important to note that LLM agents do not fit
    neatly into a single category, as they represent an advanced application of LLM
    technology rather than a specific type of model architecture. Agents are typically
    built using instruction-tuned LLMs as their foundation, often combined with additional
    components and capabilities as you will learn further in this book.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹‹å‰è®¨è®ºçš„æ¯ç§LLMç±»å‹éƒ½æœ‰å…¶è‡ªèº«çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿ï¼Œå¹¶ä¸”é€‚ç”¨äºä¸åŒçš„åº”ç”¨ã€‚ç„¶è€Œï¼Œæœ¬ä¹¦çš„é‡ç‚¹å°†æ·±å…¥æ¢è®¨LLMä»£ç†çš„èƒ½åŠ›ï¼Œå¹¶æ¢è®¨å¦‚ä½•åˆ©ç”¨å®ƒä»¬æ„å»ºé«˜çº§ç³»ç»Ÿã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒLLMä»£ç†å¹¶ä¸é€‚åˆå•ä¸€ç±»åˆ«ï¼Œå› ä¸ºå®ƒä»¬ä»£è¡¨çš„æ˜¯LLMæŠ€æœ¯çš„å…ˆè¿›åº”ç”¨ï¼Œè€Œä¸æ˜¯ç‰¹å®šç±»å‹çš„æ¨¡å‹æ¶æ„ã€‚ä»£ç†é€šå¸¸ä½¿ç”¨æŒ‡ä»¤è°ƒæ•´çš„LLMä½œä¸ºå…¶åŸºç¡€ï¼Œé€šå¸¸ç»“åˆæœ¬ä¹¦å°†è¿›ä¸€æ­¥å­¦ä¹ çš„é¢å¤–ç»„ä»¶å’Œèƒ½åŠ›ã€‚
- en: 'Let us take a look at a simple example to demonstrate the capabilities of an
    agentic system powered by an LLM. Our example is a travel website that has a **Flight
    Booking Assistant** chatbot that is a conversational interface built with an LLM.
    It can help customers book travel tickets via human-like conversations. In the
    backend, the chatbot can perform various tasks as the conversation progresses.
    Hereâ€™s what a sample conversation may look like for a customer who is looking
    to book a flight ticket:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥å±•ç¤ºç”±LLMé©±åŠ¨çš„æ™ºèƒ½ä½“ç³»ç»Ÿçš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ä¾‹å­æ˜¯ä¸€ä¸ªæ‹¥æœ‰**èˆªç­é¢„è®¢åŠ©æ‰‹**èŠå¤©æœºå™¨äººçš„æ—…è¡Œç½‘ç«™ï¼Œè¯¥èŠå¤©æœºå™¨äººæ˜¯ä¸€ä¸ªä½¿ç”¨LLMæ„å»ºçš„å¯¹è¯ç•Œé¢ã€‚å®ƒå¯ä»¥é€šè¿‡ç±»ä¼¼äººç±»çš„å¯¹è¯å¸®åŠ©å®¢æˆ·é¢„è®¢æ—…è¡Œç¥¨åŠ¡ã€‚åœ¨åå°ï¼Œéšç€å¯¹è¯çš„è¿›è¡Œï¼ŒèŠå¤©æœºå™¨äººå¯ä»¥æ‰§è¡Œå„ç§ä»»åŠ¡ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªå®¢æˆ·æƒ³è¦é¢„è®¢æœºç¥¨çš„æ ·æœ¬å¯¹è¯ï¼š
- en: '| Flight Booking Assistant |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| èˆªç­é¢„è®¢åŠ©æ‰‹'
- en: '| ![img](img/B31483_01_Icon_1.png) | Hi, I want to book a flight. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| ![img](img/B31483_01_Icon_1.png) | å—¨ï¼Œæˆ‘æƒ³é¢„è®¢èˆªç­ã€‚'
- en: '| ğŸ¤– | Hello! Iâ€™d be happy to help you book a flight. To get started, could
    you please tell me your departure city and destination? |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| ğŸ¤– | ä½ å¥½ï¼æˆ‘å¾ˆä¹æ„å¸®åŠ©ä½ é¢„è®¢èˆªç­ã€‚ä¸ºäº†å¼€å§‹ï¼Œä½ èƒ½å‘Šè¯‰æˆ‘ä½ çš„å‡ºå‘åŸå¸‚å’Œç›®çš„åœ°å—ï¼Ÿ'
- en: '| ![img](img/B31483_01_Icon_1.png) | I want to go from San Diego to SFO. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| ![img](img/B31483_01_Icon_1.png) | æˆ‘è¦ä»åœ£åœ°äºšå“¥å»SFOã€‚'
- en: '| ğŸ¤– | Great, thank you for providing that information. Youâ€™re looking to fly
    from San Diego (SAN) to San Francisco International Airport (SFO). To help you
    find the best flight options, Iâ€™ll need a few more details.1. What is your preferred
    travel date?2. Is this a one-way trip or a round trip?3. How many passengers will
    be traveling? |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| ğŸ¤– | å¤ªå¥½äº†ï¼Œæ„Ÿè°¢ä½ æä¾›è¿™äº›ä¿¡æ¯ã€‚ä½ æ‰“ç®—ä»åœ£åœ°äºšå“¥ï¼ˆSANï¼‰é£å¾€æ—§é‡‘å±±å›½é™…æœºåœºï¼ˆSFOï¼‰ã€‚ä¸ºäº†å¸®åŠ©ä½ æ‰¾åˆ°æœ€ä½³èˆªç­é€‰é¡¹ï¼Œæˆ‘éœ€è¦æ›´å¤šä¸€äº›è¯¦ç»†ä¿¡æ¯ã€‚1.
    ä½ å¸Œæœ›å“ªå¤©å‡ºè¡Œï¼Ÿ2. è¿™æ˜¯å•ç¨‹è¿˜æ˜¯å¾€è¿”ï¼Ÿ3. å°†æœ‰å¤šå°‘ä¹˜å®¢å‡ºè¡Œï¼Ÿ'
- en: '| ![img](img/B31483_01_Icon_1.png) | I want to go next Friday and come back
    on Sunday. Just me traveling. |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| ![img](img/B31483_01_Icon_1.png) | æˆ‘æƒ³åœ¨ä¸‹å‘¨äº”å‡ºå‘ï¼Œå‘¨æ—¥è¿”å›ã€‚åªæœ‰æˆ‘ä¸€ä¸ªäººå‡ºè¡Œã€‚'
- en: '| ğŸ¤– | Thank you for the additional information. Let me summarize what I have
    so far:- Departure: San Diego (SAN) to San Francisco (SFO)- Outbound Date: Next
    Friday â€“ 08/23/2024- Return Date: Sunday â€“ 08/25/2024- Passengers: 1 adultBefore
    I search for flights, I have a few more questions:1. Do you have a preferred time
    of day for your flights (morning, afternoon, or evening)?2. Do you have a preferred
    airline or are you open to all airlines?3. What class of service would you prefer
    (Economy, Premium Economy, Business, or First Class)? |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| ğŸ¤– | æ„Ÿè°¢æ‚¨æä¾›é¢å¤–ä¿¡æ¯ã€‚è®©æˆ‘æ€»ç»“ä¸€ä¸‹åˆ°ç›®å‰ä¸ºæ­¢çš„æƒ…å†µï¼š- å‡ºå‘åœ°ï¼šåœ£åœ°äºšå“¥ï¼ˆSANï¼‰è‡³æ—§é‡‘å±±ï¼ˆSFOï¼‰- å‡ºå‘æ—¥æœŸï¼šä¸‹å‘¨äº” â€“ 08/23/2024-
    è¿”å›æ—¥æœŸï¼šå‘¨æ—¥ â€“ 08/25/2024- ä¹˜å®¢ï¼š1ä½æˆäºº'
- en: '| ![img](img/B31483_01_Icon_1.png) | I prefer morning flights. No airline preference.
    Economy is fine. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| ![img](img/B31483_01_Icon_1.png) | æˆ‘æ›´å–œæ¬¢æ—©æ™¨çš„èˆªç­ã€‚æ²¡æœ‰èˆªç©ºå…¬å¸åå¥½ã€‚ç»æµèˆ±å³å¯ã€‚'
- en: '| ğŸ¤– | Thank you for those details. Iâ€™ll search for morning flights in Economy
    class across all airlines for your trip. Give me a moment to find the best options
    for you.[searching flights...please stand byâ€¦.] |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| ğŸ¤– | æ„Ÿè°¢ä½ æä¾›è¿™äº›è¯¦ç»†ä¿¡æ¯ã€‚æˆ‘å°†æœç´¢æ‰€æœ‰èˆªç©ºå…¬å¸ç»æµèˆ±çš„æ—©æ™¨èˆªç­ã€‚è¯·ç¨ç­‰ï¼Œæˆ‘ä¸ºä½ æ‰¾åˆ°æœ€ä½³é€‰é¡¹ã€‚[æœç´¢èˆªç­ä¸­...è¯·ç¨å€™....]'
- en: '| ğŸ¤– | Iâ€™ve found a few options for your trip. Here are the best morning flights:Outbound
    (SAN to SFO) - Next Friday:1. United Airlines UA1234: Depart 7:15 AM, Arrive 8:45
    AM2. Alaska Airlines AS5678: Depart 8:30 AM, Arrive 10:00 AMReturn (SFO to SAN)
    - Sunday:1. Delta Air Lines DL9876: Depart 9:00 AM, Arrive 10:30 AM2. Southwest
    Airlines WN5432: Depart 10:15 AM, Arrive 11:45 AMThe total price for the round
    trip, including taxes and fees, is:- Option 1 ( United/Alaska): $325- Option 2
    ( Delta/Southwest): $310Which option would you prefer? Or would you like me to
    look for different flights? |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| ğŸ¤– | æˆ‘ä¸ºä½ æ‰¾åˆ°äº†å‡ ä¸ªæ—…è¡Œé€‰é¡¹ã€‚ä»¥ä¸‹æ˜¯æœ€ä½³çš„æ—©æ™¨èˆªç­ï¼š- å‡ºå‘ï¼ˆSANè‡³SFOï¼‰- ä¸‹å‘¨äº”ï¼š1. è”åˆèˆªç©º UA1234ï¼šå‡ºå‘æ—¶é—´ 7:15 AMï¼Œåˆ°è¾¾æ—¶é—´
    8:45 AM2. é˜¿æ‹‰æ–¯åŠ èˆªç©º AS5678ï¼šå‡ºå‘æ—¶é—´ 8:30 AMï¼Œåˆ°è¾¾æ—¶é—´ 10:00 AM- è¿”å›ï¼ˆSFOè‡³SANï¼‰- å‘¨æ—¥ï¼š1. è¾¾ç¾èˆªç©º DL9876ï¼šå‡ºå‘æ—¶é—´
    9:00 AMï¼Œåˆ°è¾¾æ—¶é—´ 10:30 AM2. è¥¿å—èˆªç©º WN5432ï¼šå‡ºå‘æ—¶é—´ 10:15 AMï¼Œåˆ°è¾¾æ—¶é—´ 11:45 AMå¾€è¿”æ€»è´¹ç”¨ï¼ˆåŒ…æ‹¬ç¨è´¹å’Œè´¹ç”¨ï¼‰ä¸ºï¼š-
    é€‰é¡¹1ï¼ˆè”åˆ/é˜¿æ‹‰æ–¯åŠ ï¼‰ï¼š$325- é€‰é¡¹2ï¼ˆè¾¾ç¾/è¥¿å—ï¼‰ï¼š$310ä½ å¸Œæœ›é€‰æ‹©å“ªä¸ªé€‰é¡¹ï¼Ÿæˆ–è€…ä½ æƒ³è®©æˆ‘å¯»æ‰¾ä¸åŒçš„èˆªç­å—ï¼Ÿ'
- en: '| ![img](img/B31483_01_Icon_1.png) | The second option looks good. Can you
    book that for me? |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| ![img](img/B31483_01_Icon_1.png) | ç¬¬äºŒä¸ªé€‰é¡¹çœ‹èµ·æ¥ä¸é”™ã€‚ä½ èƒ½ä¸ºæˆ‘é¢„è®¢å—ï¼Ÿ'
- en: '| ğŸ¤– | Certainly! Iâ€™d be happy to book the second option for you. Just to confirm,
    Iâ€™ll be booking the following itinerary:Outbound: Alaska Airlines AS5678- Date:
    08/23/2024- Depart San Diego at 8:30 AM, Arrive in SFO at 10:00 AMReturn: Southwest
    Airlines WN5432- Date: 08/25/2024- Depart SFO at 10:15 AM, Arrive in San Diego
    at 11:45 AMTotal price: $310To proceed with the booking, Iâ€™ll need some additional
    information:1. Your full name as it appears on your government-issued ID2. Your
    date of birth3. Your email address (for sending the confirmation)4. Your phone
    number5. Any special requests (for example, meal preferences, seat preferences)Also,
    please note that youâ€™ll need to provide a form of payment to complete the booking.
    Are you ready to proceed with this information? |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| ğŸ¤– | å½“ç„¶å¯ä»¥ï¼æˆ‘å¾ˆä¹æ„ä¸ºæ‚¨é¢„è®¢ç¬¬äºŒä¸ªé€‰é¡¹ã€‚ä¸ºäº†ç¡®è®¤ï¼Œæˆ‘å°†é¢„è®¢ä»¥ä¸‹è¡Œç¨‹ï¼š- å‡ºå‘ï¼šé˜¿æ‹‰æ–¯åŠ èˆªç©ºå…¬å¸AS5678- æ—¥æœŸï¼š2024å¹´8æœˆ23æ—¥-
    ä»åœ£åœ°äºšå“¥å‡ºå‘æ—¶é—´ä¸ºä¸Šåˆ8:30ï¼Œåˆ°è¾¾æ—§é‡‘å±±å›½é™…æœºåœºæ—¶é—´ä¸ºä¸Šåˆ10:00- è¿”å›ï¼šè¥¿å—èˆªç©ºå…¬å¸WN5432- æ—¥æœŸï¼š2024å¹´8æœˆ25æ—¥- ä»æ—§é‡‘å±±å›½é™…æœºåœºå‡ºå‘æ—¶é—´ä¸ºä¸Šåˆ10:15ï¼Œåˆ°è¾¾åœ£åœ°äºšå“¥æ—¶é—´ä¸ºä¸Šåˆ11:45-
    æ€»ä»·ï¼š310ç¾å…ƒã€‚ä¸ºäº†è¿›è¡Œé¢„è®¢ï¼Œæˆ‘éœ€è¦ä¸€äº›é¢å¤–çš„ä¿¡æ¯ï¼š1. æ‚¨åœ¨æ”¿åºœé¢å‘çš„èº«ä»½è¯ä¸Šæ˜¾ç¤ºçš„å®Œæ•´å§“å2. æ‚¨çš„å‡ºç”Ÿæ—¥æœŸ3. æ‚¨çš„ç”µå­é‚®ä»¶åœ°å€ï¼ˆç”¨äºå‘é€ç¡®è®¤ä¿¡æ¯ï¼‰4.
    æ‚¨çš„ç”µè¯å·ç 5. ä»»ä½•ç‰¹æ®Šè¦æ±‚ï¼ˆä¾‹å¦‚ï¼Œé¤é£Ÿåå¥½ï¼Œåº§ä½åå¥½ï¼‰ã€‚æ­¤å¤–ï¼Œè¯·æ³¨æ„ï¼Œæ‚¨éœ€è¦æä¾›ä¸€ç§ä»˜æ¬¾æ–¹å¼ä»¥å®Œæˆé¢„è®¢ã€‚æ‚¨å‡†å¤‡å¥½ä½¿ç”¨è¿™äº›ä¿¡æ¯è¿›è¡Œé¢„è®¢äº†å—ï¼Ÿ |'
- en: '| ![img](img/B31483_01_Icon_1.png) | Yes, Iâ€™m ready. My name is John Smith,
    born on 05/15/1985. My email is john.smith@email.com and my phone number is 555-123-4567.
    No special requests. |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| ![img](img/B31483_01_Icon_1.png) | æ˜¯çš„ï¼Œæˆ‘å·²ç»å‡†å¤‡å¥½äº†ã€‚æˆ‘å«çº¦ç¿°Â·å²å¯†æ–¯ï¼Œå‡ºç”Ÿäº1985å¹´5æœˆ15æ—¥ã€‚æˆ‘çš„ç”µå­é‚®ä»¶æ˜¯john.smith@email.comï¼Œæˆ‘çš„ç”µè¯å·ç æ˜¯555-123-4567ã€‚æ²¡æœ‰ç‰¹æ®Šè¦æ±‚ã€‚
    |'
- en: '| ğŸ¤– | Thank you for providing that information, Mr. Smith. Iâ€™ve entered your
    details into the booking system. Hereâ€™s a summary of the information I have:-
    Name: John Smith- Date of Birth: 05/15/1985- Email: john.smith@email.com- Phone:
    555-123-4567- Special Requests: NoneThe final step is to process the payment of
    $310 for your flights. For security reasons, I canâ€™t accept credit card information
    directly in this chat. Instead, Iâ€™ll send a secure payment link to your email
    address (john.smith@email.com).Once you receive the email, please follow the link
    to complete the payment process. After the payment is successfully processed,
    youâ€™ll receive another email with your flight confirmation and e-tickets.Is it
    okay to proceed with sending the payment link to your email? |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| ğŸ¤– | å²å¯†æ–¯å…ˆç”Ÿï¼Œæ„Ÿè°¢æ‚¨æä¾›è¿™äº›ä¿¡æ¯ã€‚æˆ‘å·²ç»å°†æ‚¨çš„è¯¦ç»†ä¿¡æ¯è¾“å…¥åˆ°é¢„è®¢ç³»ç»Ÿä¸­ã€‚ä»¥ä¸‹æ˜¯æ‚¨æä¾›ä¿¡æ¯çš„æ‘˜è¦ï¼š- å§“åï¼šçº¦ç¿°Â·å²å¯†æ–¯- å‡ºç”Ÿæ—¥æœŸï¼š05/15/1985-
    ç”µå­é‚®ä»¶ï¼šjohn.smith@email.com- ç”µè¯ï¼š555-123-4567- ç‰¹æ®Šè¦æ±‚ï¼šæ— ã€‚æœ€åä¸€æ­¥æ˜¯å¤„ç†æ‚¨æœºç¥¨çš„310ç¾å…ƒä»˜æ¬¾ã€‚å‡ºäºå®‰å…¨åŸå› ï¼Œæˆ‘æ— æ³•åœ¨æ­¤èŠå¤©ä¸­ç›´æ¥æ¥å—ä¿¡ç”¨å¡ä¿¡æ¯ã€‚ç›¸åï¼Œæˆ‘å°†é€šè¿‡æ‚¨çš„ç”µå­é‚®ä»¶åœ°å€ï¼ˆjohn.smith@email.comï¼‰å‘é€ä¸€ä¸ªå®‰å…¨çš„ä»˜æ¬¾é“¾æ¥ã€‚ä¸€æ—¦æ‚¨æ”¶åˆ°ç”µå­é‚®ä»¶ï¼Œè¯·ç‚¹å‡»é“¾æ¥å®Œæˆä»˜æ¬¾è¿‡ç¨‹ã€‚ä»˜æ¬¾æˆåŠŸå¤„ç†åï¼Œæ‚¨å°†æ”¶åˆ°å¦ä¸€å°ç”µå­é‚®ä»¶ï¼Œå…¶ä¸­åŒ…å«æ‚¨çš„èˆªç­ç¡®è®¤å’Œç”µå­æœºç¥¨ã€‚å¯ä»¥å¼€å§‹å°†ä»˜æ¬¾é“¾æ¥å‘é€åˆ°æ‚¨çš„ç”µå­é‚®ä»¶åœ°å€å—ï¼Ÿ
    |'
- en: '| ![img](img/B31483_01_Icon_1.png) | Yes, thatâ€™s fine. Please send the payment
    link. |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| ![img](img/B31483_01_Icon_1.png) | æ˜¯çš„ï¼Œè¿™æ ·å¾ˆå¥½ã€‚è¯·å‘é€ä»˜æ¬¾é“¾æ¥ã€‚ |'
- en: '| ğŸ¤– | Excellent, Mr. Smith. Iâ€™ve initiated the process to send the secure payment
    link to your email address (john.smith@email.com). You should receive it within
    the next few minutes. Please check your inbox and spam folder if you donâ€™t see
    it right away.Once you complete the payment, the system will automatically process
    your booking and send your confirmation email with the e-tickets. This email will
    include important information such as:1. Booking confirmation number2. Detailed
    flight itinerary3. Check-in instructions4. Baggage allowance information5. Airline
    contact informationAfter you receive your confirmation email, please review all
    the details to ensure everything is correct. If you notice any issues or have
    any questions, please donâ€™t hesitate to contact us.Is there anything else you
    need assistance with regarding your trip or the booking process? |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| ğŸ¤– | æå¥½ï¼Œå²å¯†æ–¯å…ˆç”Ÿã€‚æˆ‘å·²ç»å¯åŠ¨äº†å°†å®‰å…¨ä»˜æ¬¾é“¾æ¥å‘é€åˆ°æ‚¨çš„ç”µå­é‚®ä»¶åœ°å€ï¼ˆjohn.smith@email.comï¼‰çš„è¿‡ç¨‹ã€‚æ‚¨åº”è¯¥åœ¨æ¥ä¸‹æ¥çš„å‡ åˆ†é’Ÿå†…æ”¶åˆ°å®ƒã€‚å¦‚æœæ‚¨ç«‹åˆ»æ²¡æœ‰çœ‹åˆ°ï¼Œè¯·æ£€æŸ¥æ‚¨çš„æ”¶ä»¶ç®±å’Œåƒåœ¾é‚®ä»¶æ–‡ä»¶å¤¹ã€‚å®Œæˆä»˜æ¬¾åï¼Œç³»ç»Ÿå°†è‡ªåŠ¨å¤„ç†æ‚¨çš„é¢„è®¢å¹¶å‘é€åŒ…å«ç”µå­æœºç¥¨çš„ç¡®è®¤ç”µå­é‚®ä»¶ã€‚æ­¤ç”µå­é‚®ä»¶å°†åŒ…å«ä»¥ä¸‹é‡è¦ä¿¡æ¯ï¼š1.
    é¢„è®¢ç¡®è®¤å·ç 2. è¯¦ç»†èˆªç­è¡Œç¨‹3. ç™»æœºæŒ‡ç¤º4. è¡Œæé¢åº¦ä¿¡æ¯5. èˆªç©ºå…¬å¸è”ç³»æ–¹å¼ã€‚æ”¶åˆ°ç¡®è®¤ç”µå­é‚®ä»¶åï¼Œè¯·ä»”ç»†æ£€æŸ¥æ‰€æœ‰è¯¦ç»†ä¿¡æ¯ï¼Œä»¥ç¡®ä¿ä¸€åˆ‡æ­£ç¡®ã€‚å¦‚æœæ‚¨å‘ç°é—®é¢˜æˆ–æœ‰ä»»ä½•ç–‘é—®ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ä»¬ã€‚æ‚¨åœ¨æ—…è¡Œæˆ–é¢„è®¢è¿‡ç¨‹ä¸­è¿˜éœ€è¦å…¶ä»–å¸®åŠ©å—ï¼Ÿ
    |'
- en: '| ![img](img/B31483_01_Icon_1.png) | No, thatâ€™s all. Thank you for your help!
    |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| ![img](img/B31483_01_Icon_1.png) | ä¸ï¼Œå°±è¿™äº›ã€‚æ„Ÿè°¢æ‚¨çš„å¸®åŠ©ï¼ |'
- en: '| ğŸ¤– | Youâ€™re welcome, Mr. Smith! Iâ€™m glad I could assist you with booking your
    flights from San Diego to San Francisco. If you need any further assistance with
    this booking or have any questions about your trip, please donâ€™t hesitate to reach
    out. Weâ€™re here to help 24/7. Have a great trip to San Francisco next week! |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| ğŸ¤– | å²å¯†æ–¯å…ˆç”Ÿï¼Œä¸å®¢æ°”ï¼å¾ˆé«˜å…´æˆ‘èƒ½å¸®åŠ©æ‚¨é¢„è®¢ä»åœ£åœ°äºšå“¥åˆ°æ—§é‡‘å±±çš„èˆªç­ã€‚å¦‚æœæ‚¨éœ€è¦ä»»ä½•è¿›ä¸€æ­¥çš„å¸®åŠ©æˆ–æœ‰å…³äºæ‚¨æ—…è¡Œçš„ä»»ä½•é—®é¢˜ï¼Œè¯·éšæ—¶è”ç³»æˆ‘ä»¬ã€‚æˆ‘ä»¬24/7éƒ½åœ¨è¿™é‡Œä¸ºæ‚¨æœåŠ¡ã€‚ç¥æ‚¨ä¸‹å‘¨å»æ—§é‡‘å±±çš„æ—…ç¨‹æ„‰å¿«ï¼
    |'
- en: On the surface, this example looks pretty straightforward. However, there are
    a number of things that are happening in the background. Firstly, the customer
    starts with a vague request to book a flight. The AI assistant understands that
    in order to proceed with this request, it needs a few more pieces of information
    to look up available flights, such as departure/arrival city, dates of travel,
    and so on.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¡¨é¢ä¸Šï¼Œè¿™ä¸ªä¾‹å­çœ‹èµ·æ¥ç›¸å½“ç›´æ¥ã€‚ç„¶è€Œï¼Œåœ¨å¹•åå‘ç”Ÿäº†å¾ˆå¤šäº‹æƒ…ã€‚é¦–å…ˆï¼Œå®¢æˆ·å¼€å§‹æ—¶æå‡ºä¸€ä¸ªæ¨¡ç³Šçš„è¯·æ±‚ï¼Œæƒ³è¦é¢„è®¢èˆªç­ã€‚äººå·¥æ™ºèƒ½åŠ©æ‰‹æ˜ç™½ï¼Œä¸ºäº†å¤„ç†è¿™ä¸ªè¯·æ±‚ï¼Œå®ƒéœ€è¦æŸ¥æ‰¾æ›´å¤šçš„ä¸€äº›ä¿¡æ¯ï¼Œæ¯”å¦‚å‡ºå‘/åˆ°è¾¾åŸå¸‚ã€æ—…è¡Œæ—¥æœŸç­‰ç­‰ã€‚
- en: 'As the conversation progresses, the AI assistant requests further pieces of
    information to be able to successfully complete the booking. The information it
    gathers at each step is used as a parameter value to call flight booking-related
    APIs in the backend; for example, city/travel dates/number of passengers are required
    to look up available flight information using a (fictitious) API named **flightLookup**
    , customer name/phone/email are required to actually make the booking using an
    API named b **ookFlight** , and so on. *Figure 1* *.2* gives an overview of the
    decisions that the model makes, the flow of the interaction, and the tools (API
    functions) it calls to complete each step:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€å¯¹è¯çš„è¿›è¡Œï¼Œäººå·¥æ™ºèƒ½åŠ©æ‰‹è¯·æ±‚è¿›ä¸€æ­¥çš„ä¿¡æ¯ï¼Œä»¥ä¾¿èƒ½å¤ŸæˆåŠŸå®Œæˆé¢„è®¢ã€‚å®ƒåœ¨æ¯ä¸ªæ­¥éª¤æ”¶é›†çš„ä¿¡æ¯è¢«ç”¨ä½œå‚æ•°å€¼ï¼Œåœ¨åå°è°ƒç”¨ä¸èˆªç­é¢„è®¢ç›¸å…³çš„APIï¼›ä¾‹å¦‚ï¼Œéœ€è¦åŸå¸‚/æ—…è¡Œæ—¥æœŸ/ä¹˜å®¢æ•°é‡ç­‰ä¿¡æ¯æ¥ä½¿ç”¨ä¸€ä¸ªï¼ˆè™šæ„çš„ï¼‰APIåä¸º**flightLookup**æŸ¥æ‰¾å¯ç”¨çš„èˆªç­ä¿¡æ¯ï¼Œéœ€è¦å®¢æˆ·å§“å/ç”µè¯/ç”µå­é‚®ä»¶ç­‰ä¿¡æ¯æ¥ä½¿ç”¨åä¸º**bookFlight**çš„APIå®é™…å®Œæˆé¢„è®¢ï¼Œç­‰ç­‰ã€‚*å›¾
    1.2* ç»™å‡ºäº†æ¨¡å‹åšå‡ºçš„å†³ç­–ã€äº¤äº’æµç¨‹ä»¥åŠå®ƒä¸ºå®Œæˆæ¯ä¸ªæ­¥éª¤è°ƒç”¨çš„å·¥å…·ï¼ˆAPIå‡½æ•°ï¼‰çš„æ¦‚è¿°ï¼š
- en: '![img](img/B31483_01_2.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B31483_01_2.jpg)'
- en: Figure 1.2 â€“ Flight Booking Assistant chatbot with LLM-powered multi-agents
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 1.2 â€“ åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“èˆªç­é¢„è®¢åŠ©æ‰‹èŠå¤©æœºå™¨äºº
- en: In addition to just tool calling, you will also notice that the model does a
    bit of introspection, also known as **chain of thought** ( **CoT** ), at the beginning
    of the conversation. This means the model in the backend crafts a step-by-step
    approach to complete the task but identifies some missing information. It then
    responds back to the customer with a request to provide the required information.
    Subsequently, based on the input from the customer, it makes certain decisions
    autonomously to call specific tools using the agent and completes the task.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†è°ƒç”¨å·¥å…·ä¹‹å¤–ï¼Œä½ è¿˜ä¼šæ³¨æ„åˆ°ï¼Œåœ¨å¯¹è¯å¼€å§‹æ—¶ï¼Œæ¨¡å‹è¿›è¡Œäº†ä¸€äº›è‡ªæˆ‘åæ€ï¼Œè¿™è¢«ç§°ä¸º**æ€ç»´é“¾**ï¼ˆ**CoT**ï¼‰ã€‚è¿™æ„å‘³ç€åç«¯çš„æ¨¡å‹åˆ¶å®šäº†ä¸€ä¸ªé€æ­¥çš„æ–¹æ³•æ¥å®Œæˆä»»åŠ¡ï¼Œä½†å‘ç°äº†ä¸€äº›ç¼ºå¤±çš„ä¿¡æ¯ã€‚ç„¶åï¼Œå®ƒå‘å®¢æˆ·è¯·æ±‚æä¾›æ‰€éœ€çš„ä¿¡æ¯ã€‚éšåï¼Œæ ¹æ®å®¢æˆ·æä¾›çš„è¾“å…¥ï¼Œå®ƒè‡ªä¸»åœ°åšå‡ºæŸäº›å†³å®šï¼Œä½¿ç”¨æ™ºèƒ½ä½“è°ƒç”¨ç‰¹å®šçš„å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚
- en: In addition to the external tools and APIs, there are a number of other things
    to consider when designing such a system. We will cover the fundamentals of each
    of these components in detail in the subsequent chapters. For now, it is sufficient
    to know that agents are an advanced application of LLMs (such as this travel booking
    AI assistant) and represent an emerging field that combines aspects of various
    LLM types with additional AI techniques such as reinforcement learning, planning,
    and tool use. As you learn more in subsequent chapters, you will notice that agents
    are designed to be more interactive, adaptable, and capable of completing complex,
    multi-step tasks compared to standard LLMs, which makes them suitable for a variety
    of different complex tasks and workflows.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è®¾è®¡è¿™æ ·çš„ç³»ç»Ÿæ—¶ï¼Œé™¤äº†å¤–éƒ¨å·¥å…·å’ŒAPIä¹‹å¤–ï¼Œè¿˜æœ‰è®¸å¤šå…¶ä»–å› ç´ éœ€è¦è€ƒè™‘ã€‚æˆ‘ä»¬å°†åœ¨åç»­ç« èŠ‚ä¸­è¯¦ç»†è®¨è®ºè¿™äº›ç»„ä»¶çš„åŸºæœ¬åŸç†ã€‚ç°åœ¨ï¼Œåªéœ€çŸ¥é“æ™ºèƒ½ä½“æ˜¯LLMï¼ˆå¦‚è¿™ä¸ªæ—…è¡Œé¢„è®¢äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼‰çš„é«˜çº§åº”ç”¨ï¼Œä»£è¡¨äº†ä¸€ä¸ªæ–°å…´é¢†åŸŸï¼Œå®ƒå°†å„ç§LLMç±»å‹çš„ç‰¹ç‚¹ä¸é¢å¤–çš„AIæŠ€æœ¯ç›¸ç»“åˆï¼Œå¦‚å¼ºåŒ–å­¦ä¹ ã€è§„åˆ’å’Œå·¥å…·ä½¿ç”¨ã€‚éšç€æ‚¨åœ¨åç»­ç« èŠ‚ä¸­å­¦ä¹ æ›´å¤šï¼Œæ‚¨ä¼šå‘ç°æ™ºèƒ½ä½“è¢«è®¾è®¡å¾—æ›´åŠ äº’åŠ¨ã€é€‚åº”æ€§å¼ºï¼Œå¹¶ä¸”èƒ½å¤Ÿå®Œæˆæ¯”æ ‡å‡†LLMæ›´å¤æ‚ã€å¤šæ­¥éª¤çš„ä»»åŠ¡ï¼Œè¿™ä½¿å¾—å®ƒä»¬é€‚åˆå„ç§ä¸åŒçš„å¤æ‚ä»»åŠ¡å’Œå·¥ä½œæµç¨‹ã€‚
- en: But before we dive deeper into the details of agentic systems, let us review
    some of the applications of generative AI.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ·±å…¥æ¢è®¨æ™ºèƒ½ä½“ç³»ç»Ÿçš„ç»†èŠ‚ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹ç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„ä¸€äº›åº”ç”¨ã€‚
- en: Applications of generative AI
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIçš„åº”ç”¨
- en: 'Generative AI has innovation capabilities that cover a diverse set of fields.
    As discussed earlier, industries such as healthcare, finance, education, media
    and entertainment, marketing, manufacturing, retail, and so on all have the potential
    to benefit from generative AI capabilities. The following is a survey of only
    a few of the primary applications of generative AI:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIå…·æœ‰æ¶µç›–ä¼—å¤šé¢†åŸŸçš„åˆ›æ–°èƒ½åŠ›ã€‚å¦‚å‰æ‰€è¿°ï¼ŒåŒ»ç–—ä¿å¥ã€é‡‘èã€æ•™è‚²ã€åª’ä½“å’Œå¨±ä¹ã€å¸‚åœºè¥é”€ã€åˆ¶é€ ä¸šã€é›¶å”®ç­‰è¡Œä¸šéƒ½æœ‰å¯èƒ½ä»ç”Ÿæˆå¼AIçš„èƒ½åŠ›ä¸­å—ç›Šã€‚ä»¥ä¸‹æ˜¯å¯¹ç”Ÿæˆå¼AIä¸»è¦åº”ç”¨ä¸­çš„ä¸€äº›åº”ç”¨çš„æ¦‚è¿°ï¼š
- en: '**Generation of images and videos** : Multimodal generative models (that is,
    LLMs that can handle images, text, audio, and videos) are making it possible to
    generate realistic audio/visuals through various platforms and tools. For example,
    in media and entertainment, generative AI can help in generating visual effects,
    designing avatars, and developing virtual reality content. In the fashion and
    design industry, it is being used to conceptualize new clothing designs, prepare
    virtual fashion shows, and make fashion trend predictions. In marketing ads and
    promotion space, generative AI is being used to generate tailor-made advertisements,
    campaigns, marketing communications, and other marketing materials creatives such
    as images and logos.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å›¾åƒå’Œè§†é¢‘ç”Ÿæˆ**ï¼šå¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹ï¼ˆå³èƒ½å¤Ÿå¤„ç†å›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘å’Œè§†é¢‘çš„LLMsï¼‰æ­£åœ¨é€šè¿‡å„ç§å¹³å°å’Œå·¥å…·ä½¿ç”Ÿæˆé€¼çœŸçš„éŸ³é¢‘/è§†è§‰å†…å®¹æˆä¸ºå¯èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨åª’ä½“å’Œå¨±ä¹é¢†åŸŸï¼Œç”Ÿæˆå¼AIå¯ä»¥å¸®åŠ©ç”Ÿæˆè§†è§‰æ•ˆæœã€è®¾è®¡å¤´åƒå’Œå¼€å‘è™šæ‹Ÿç°å®å†…å®¹ã€‚åœ¨æ—¶å°šå’Œè®¾è®¡è¡Œä¸šï¼Œå®ƒè¢«ç”¨äºæ„æ€æ–°çš„æœè£…è®¾è®¡ã€å‡†å¤‡è™šæ‹Ÿæ—¶è£…ç§€å’Œé¢„æµ‹æ—¶å°šè¶‹åŠ¿ã€‚åœ¨è¥é”€å¹¿å‘Šå’Œæ¨å¹¿é¢†åŸŸï¼Œç”Ÿæˆå¼AIè¢«ç”¨äºç”Ÿæˆå®šåˆ¶å¹¿å‘Šã€æ´»åŠ¨ã€è¥é”€æ²Ÿé€šä»¥åŠå…¶ä»–è¥é”€ææ–™åˆ›æ„ï¼Œå¦‚å›¾åƒå’Œæ ‡å¿—ã€‚'
- en: '**Text and content generation** : Generative AI has made significant strides
    when it comes to text-based tasks. For instance, content writing such as rapid
    and hassle-free generation of articles, blog posts, marketing, and product copies
    are already some of the most common use cases. Chatbots and virtual assistants
    are providing customer support in a very humanlike manner to information-related
    inquiries. Generative AI is also assisting in text translation, document summarization,
    and content localization for increased accessibility of content for platforms
    such as online learning and specialized search engines.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ–‡æœ¬å’Œå†…å®¹ç”Ÿæˆ**ï¼šç”Ÿæˆå¼AIåœ¨åŸºäºæ–‡æœ¬çš„ä»»åŠ¡æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ä¾‹å¦‚ï¼Œå†…å®¹å†™ä½œï¼Œå¦‚å¿«é€Ÿä¸”æ— çƒ¦æ¼åœ°ç”Ÿæˆæ–‡ç« ã€åšå®¢æ–‡ç« ã€è¥é”€å’Œäº§å“å‰¯æœ¬ï¼Œå·²ç»æˆä¸ºæœ€å¸¸è§çš„ç”¨ä¾‹ä¹‹ä¸€ã€‚èŠå¤©æœºå™¨äººå’Œè™šæ‹ŸåŠ©æ‰‹æ­£åœ¨ä»¥éå¸¸äººæ€§åŒ–çš„æ–¹å¼æä¾›å®¢æˆ·æ”¯æŒï¼Œä»¥å›ç­”ä¿¡æ¯ç›¸å…³çš„é—®é¢˜ã€‚ç”Ÿæˆå¼AIè¿˜åœ¨æ–‡æœ¬ç¿»è¯‘ã€æ–‡æ¡£æ‘˜è¦å’Œå†…å®¹æœ¬åœ°åŒ–æ–¹é¢æä¾›å¸®åŠ©ï¼Œä»¥å¢åŠ å†…å®¹å¯¹åœ¨çº¿å­¦ä¹ å’Œä¸“ä¸šæœç´¢å¼•æ“ç­‰å¹³å°çš„å¯è®¿é—®æ€§ã€‚'
- en: '**Music and audio generation** : Creating original music, sound effects, and
    voice synthesis is yet another paradigm of multi-media content generation that
    is being powered by generative AI. Practically, contents such as these are being
    used in the gaming and entertainment industry to create audio-assisted training
    materials, automated call center assistants, and IoT devices such as Amazon Alexa,
    or Google Next that can take audio commands and use voice responses to complete
    automated tasks.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**éŸ³ä¹å’ŒéŸ³é¢‘ç”Ÿæˆ**ï¼šåˆ›å»ºåŸåˆ›éŸ³ä¹ã€éŸ³æ•ˆå’Œè¯­éŸ³åˆæˆæ˜¯å¤šåª’ä½“å†…å®¹ç”Ÿæˆé¢†åŸŸç”±ç”Ÿæˆå¼AIæ¨åŠ¨çš„å¦ä¸€ç§èŒƒå¼ã€‚å®é™…ä¸Šï¼Œè¿™ç±»å†…å®¹æ­£åœ¨è¢«ç”¨äºæ¸¸æˆå’Œå¨±ä¹è¡Œä¸šï¼Œä»¥åˆ›å»ºè¾…åŠ©è®­ç»ƒææ–™ã€è‡ªåŠ¨å‘¼å«ä¸­å¿ƒåŠ©æ‰‹ä»¥åŠå¦‚äºšé©¬é€ŠAlexaæˆ–è°·æ­ŒNextç­‰ç‰©è”ç½‘è®¾å¤‡ï¼Œè¿™äº›è®¾å¤‡å¯ä»¥æ¥æ”¶éŸ³é¢‘å‘½ä»¤å¹¶ä½¿ç”¨è¯­éŸ³å“åº”æ¥å®Œæˆè‡ªåŠ¨åŒ–ä»»åŠ¡ã€‚'
- en: '**Healthcare and drug discovery** : Generative AI finds space in health care.
    For example, the design of new drugs and the prediction of their capability to
    treat diseases or other conditions; personalized medicine, whereby treatment plans
    are tailored individually on a patient-by-patient basis; and medical imaging,
    whereby image quality is refined and synthetic images generated for research purposes.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åŒ»ç–—ä¿å¥å’Œè¯ç‰©å‘ç°**ï¼šç”Ÿæˆå¼AIåœ¨åŒ»ç–—ä¿å¥é¢†åŸŸæ‰¾åˆ°äº†ä¸€å¸­ä¹‹åœ°ã€‚ä¾‹å¦‚ï¼Œæ–°è¯çš„è®¾è®¡å’Œé¢„æµ‹å…¶æ²»ç–—ç–¾ç—…æˆ–å…¶ä»–æ¡ä»¶çš„èƒ½åŠ›ï¼›ä¸ªæ€§åŒ–åŒ»ç–—ï¼Œå³æ ¹æ®æ¯ä¸ªæ‚£è€…çš„æƒ…å†µé‡èº«å®šåˆ¶æ²»ç–—æ–¹æ¡ˆï¼›ä»¥åŠåŒ»å­¦æˆåƒï¼Œå³é€šè¿‡ç ”ç©¶ç›®çš„ç”Ÿæˆåˆæˆå›¾åƒå¹¶æé«˜å›¾åƒè´¨é‡ã€‚'
- en: '**Code generation** : Code generation is an emerging LLM feature that is helping
    developers in software development. These models can often generate accurate code
    snippets, or sometimes an entire function based on text prompts. Advanced implementation
    of generative AI in code generation includes plugins created for various **integrated
    development environments** ( **IDEs** ), such as **Visual Studio Code** ( **VS
    Code** ), that can understand the entire context of the code base, identify errors,
    create code documentation, and generate unit test scripts. Another implementation
    of code generation is text-to-query use cases where a natural language prompt
    is converted into a SQL query, which can then be executed against a database to
    get the desired results. However, this is one of the areas where special caution
    must be taken, especially before executing the code generated by an LLM, to prevent
    risks of malicious code execution. Often, in these situations, the code generated
    by the LLM is executed in a sandbox and sanitized to check whether the code is
    safe and appropriate for execution in an autonomous environment.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä»£ç ç”Ÿæˆ**ï¼šä»£ç ç”Ÿæˆæ˜¯LLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰çš„ä¸€ä¸ªæ–°å…´åŠŸèƒ½ï¼Œå®ƒæ­£åœ¨å¸®åŠ©è½¯ä»¶å¼€å‘è€…ã€‚è¿™äº›æ¨¡å‹é€šå¸¸å¯ä»¥æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆå‡†ç¡®çš„ä»£ç ç‰‡æ®µï¼Œæœ‰æ—¶ç”šè‡³å¯ä»¥æ ¹æ®æ–‡æœ¬æç¤ºç”Ÿæˆæ•´ä¸ªå‡½æ•°ã€‚ä»£ç ç”Ÿæˆä¸­ç”Ÿæˆå¼AIçš„é«˜çº§å®ç°åŒ…æ‹¬ä¸ºå„ç§**é›†æˆå¼€å‘ç¯å¢ƒ**ï¼ˆ**IDE**ï¼‰åˆ›å»ºçš„æ’ä»¶ï¼Œä¾‹å¦‚**Visual
    Studio Code**ï¼ˆ**VS Code**ï¼‰ï¼Œå®ƒå¯ä»¥ç†è§£æ•´ä¸ªä»£ç åº“çš„ä¸Šä¸‹æ–‡ï¼Œè¯†åˆ«é”™è¯¯ï¼Œåˆ›å»ºä»£ç æ–‡æ¡£ï¼Œå¹¶ç”Ÿæˆå•å…ƒæµ‹è¯•è„šæœ¬ã€‚ä»£ç ç”Ÿæˆçš„å¦ä¸€ç§å®ç°æ˜¯æ–‡æœ¬åˆ°æŸ¥è¯¢ç”¨ä¾‹ï¼Œå…¶ä¸­è‡ªç„¶è¯­è¨€æç¤ºè¢«è½¬æ¢ä¸ºSQLæŸ¥è¯¢ï¼Œç„¶åå¯ä»¥å¯¹è¯¥æ•°æ®åº“æ‰§è¡Œä»¥è·å–æ‰€éœ€çš„ç»“æœã€‚ç„¶è€Œï¼Œè¿™æ˜¯å¿…é¡»ç‰¹åˆ«å°å¿ƒå¤„ç†çš„ä¸€ä¸ªé¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨æ‰§è¡Œç”±LLMç”Ÿæˆçš„ä»£ç ä¹‹å‰ï¼Œä»¥é˜²æ­¢æ¶æ„ä»£ç æ‰§è¡Œçš„é£é™©ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼ŒLLMç”Ÿæˆçš„ä»£ç é€šå¸¸åœ¨æ²™ç›’ä¸­æ‰§è¡Œå¹¶ç»è¿‡æ¸…ç†ï¼Œä»¥æ£€æŸ¥ä»£ç æ˜¯å¦å®‰å…¨ä¸”é€‚åˆåœ¨è‡ªä¸»ç¯å¢ƒä¸­æ‰§è¡Œã€‚'
- en: '**Autonomous workflows and robotics** : As we briefly discussed earlier, LLM-powered
    AI agents are an advanced implementation of generative AI with LLMs serving as
    their foundations. These agents can perform several tasks in various use cases.
    For example, a travel booking website with a virtual assistant chatbot can implement
    agents to automate the travel and hotel booking process for the customer. In these
    cases, the agent-based system can act on specific tasks using tools (such as calling
    a flight booking API) simply by understanding the context of the conversation
    that the customer is having with the chatbot. More advanced agent-based systems
    often come into play when discussing robotics, where a robotâ€™s actions are primarily
    controlled by agents. The robotic agent essentially determines what decisions
    to make based on its environment or the specific task it is assigned to perform.
    It uses agents to execute actions that an LLM would otherwise be unable to perform;
    for example, an agent can turn on or off the limb actuators of a robot. AI in
    robotics is a novel and open field of research, with numerous innovations emerging
    in the industry, particularly targeted toward manufacturing applications.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**è‡ªä¸»å·¥ä½œæµå’Œæœºå™¨äººæŠ€æœ¯**ï¼šæ­£å¦‚æˆ‘ä»¬ä¹‹å‰ç®€è¦è®¨è®ºçš„é‚£æ ·ï¼Œç”±LLMï¼ˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼‰é©±åŠ¨çš„AIä»£ç†æ˜¯ç”Ÿæˆå¼AIçš„é«˜çº§å®ç°ï¼Œå…¶ä¸­LLMä½œä¸ºå…¶åŸºç¡€ã€‚è¿™äº›ä»£ç†å¯ä»¥åœ¨å„ç§ç”¨ä¾‹ä¸­æ‰§è¡Œå¤šä¸ªä»»åŠ¡ã€‚ä¾‹å¦‚ï¼Œä¸€ä¸ªæ‹¥æœ‰è™šæ‹ŸåŠ©æ‰‹èŠå¤©æœºå™¨äººçš„æ—…è¡Œé¢„è®¢ç½‘ç«™å¯ä»¥å®ç°ä»£ç†æ¥è‡ªåŠ¨åŒ–å®¢æˆ·çš„æ—…è¡Œå’Œé…’åº—é¢„è®¢æµç¨‹ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼ŒåŸºäºä»£ç†çš„ç³»ç»Ÿå¯ä»¥é€šè¿‡ç†è§£å®¢æˆ·ä¸èŠå¤©æœºå™¨äººè¿›è¡Œçš„å¯¹è¯ä¸Šä¸‹æ–‡æ¥æ‰§è¡Œç‰¹å®šä»»åŠ¡ï¼Œä¾‹å¦‚è°ƒç”¨èˆªç­é¢„è®¢APIã€‚å½“è®¨è®ºæœºå™¨äººæŠ€æœ¯æ—¶ï¼Œæ›´é«˜çº§çš„åŸºäºä»£ç†çš„ç³»ç»Ÿé€šå¸¸è¢«åº”ç”¨ï¼Œå…¶ä¸­æœºå™¨äººçš„åŠ¨ä½œä¸»è¦å—ä»£ç†æ§åˆ¶ã€‚æœºå™¨äººä»£ç†åŸºæœ¬ä¸Šæ ¹æ®å…¶ç¯å¢ƒæˆ–åˆ†é…ç»™å…¶æ‰§è¡Œçš„å…·ä½“ä»»åŠ¡æ¥å†³å®šè¦åšå‡ºä»€ä¹ˆå†³å®šã€‚å®ƒä½¿ç”¨ä»£ç†æ¥æ‰§è¡ŒLLMæ— æ³•æ‰§è¡Œçš„åŠ¨ä½œï¼›ä¾‹å¦‚ï¼Œä»£ç†å¯ä»¥æ‰“å¼€æˆ–å…³é—­æœºå™¨äººçš„è‚¢ä½“æ‰§è¡Œå™¨ã€‚æœºå™¨äººå·¥æ™ºèƒ½æ˜¯ä¸€ä¸ªæ–°é¢–ä¸”å¼€æ”¾çš„ç ”ç©¶é¢†åŸŸï¼Œè¯¥é¢†åŸŸåœ¨è¡Œä¸šä¸­æ¶Œç°å‡ºè®¸å¤šåˆ›æ–°ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹åˆ¶é€ åº”ç”¨ã€‚'
- en: 'These are just some of the common examples of the uses of generative AI with
    LLMs. Other specific examples include uses in fashion and design, synthetic data
    generation, personalized educational content, financial modeling and forecasting,
    and predictive maintenance. The following is a brief list of examples of commercial
    and open source tools that use generative AI for the number of use cases we discussed:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›åªæ˜¯ä½¿ç”¨LLMçš„ç”Ÿæˆå¼AIçš„ä¸€äº›å¸¸è§ç¤ºä¾‹ã€‚å…¶ä»–å…·ä½“ç¤ºä¾‹åŒ…æ‹¬åœ¨æ—¶å°šå’Œè®¾è®¡ã€åˆæˆæ•°æ®ç”Ÿæˆã€ä¸ªæ€§åŒ–æ•™è‚²å†…å®¹ã€é‡‘èå»ºæ¨¡å’Œé¢„æµ‹ä»¥åŠé¢„æµ‹æ€§ç»´æŠ¤ä¸­çš„åº”ç”¨ã€‚ä»¥ä¸‹æ˜¯æˆ‘ä»¬è®¨è®ºçš„ç”¨ä¾‹ä¸­ä½¿ç”¨çš„å•†ä¸šå’Œå¼€æºå·¥å…·çš„ç®€è¦åˆ—è¡¨ï¼š
- en: '| **Use case** | **Commercial tools** | **Open** **source tools** |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| **ç”¨ä¾‹** | **å•†ä¸šå·¥å…·** | **å¼€æºå·¥å…·** |'
- en: '| --- | --- | --- |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Visual effects and** **avatar design** |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| **è§†è§‰æ•ˆæœå’Œ** **è™šæ‹Ÿå½¢è±¡è®¾è®¡** |'
- en: '**Unreal Engineâ€™s MetaHuman Creator** : Allows for the creation of highly realistic
    digital humans for games and films'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Unreal Engineçš„MetaHuman Creator**ï¼šå…è®¸åˆ›å»ºç”¨äºæ¸¸æˆå’Œç”µå½±çš„éå¸¸é€¼çœŸçš„æ•°å­—äººç±»'
- en: '**NVIDIA Omniverse** : A platform for 3D design collaboration and simulation,
    useful for creating visual effects'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NVIDIA Omniverse**ï¼šä¸€ä¸ªç”¨äº3Dè®¾è®¡åä½œå’Œæ¨¡æ‹Ÿçš„å¹³å°ï¼Œé€‚ç”¨äºåˆ›å»ºè§†è§‰æ•ˆæœ'
- en: '|'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**DeepFaceLab** : Used for face swapping and creating digital avatars'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DeepFaceLab**ï¼šç”¨äºé¢éƒ¨äº¤æ¢å’Œåˆ›å»ºæ•°å­—å¤´åƒ'
- en: '**StyleGAN** : Capable of generating highly realistic faces and can be adapted
    for avatar creation'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**StyleGAN**ï¼šèƒ½å¤Ÿç”Ÿæˆé«˜åº¦é€¼çœŸçš„é¢å­”ï¼Œå¹¶å¯é€‚åº”ç”¨äºå¤´åƒåˆ›å»º'
- en: '|'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Virtual reality** **content development** |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| **è™šæ‹Ÿç°å®** **å†…å®¹å¼€å‘** |'
- en: '**Unity** : While not exclusively for VR, it has robust VR development capabilities'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Unity**ï¼šè™½ç„¶ä¸æ˜¯ä¸“é—¨ç”¨äºVRï¼Œä½†å®ƒå…·æœ‰å¼ºå¤§çš„VRå¼€å‘èƒ½åŠ›'
- en: '**Adobe Aero** : Allows for the creation of AR experiences'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Adobe Aero**ï¼šå…è®¸åˆ›å»ºARä½“éªŒ'
- en: '|'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**A-Frame** : A web framework for building virtual reality experiences'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**A-Frame**ï¼šä¸€ä¸ªç”¨äºæ„å»ºè™šæ‹Ÿç°å®ä½“éªŒçš„Webæ¡†æ¶'
- en: '**Godot** : An open source game engine with VR support'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Godot**ï¼šä¸€ä¸ªæ”¯æŒVRçš„å¼€æºæ¸¸æˆå¼•æ“'
- en: '|'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Clothing design and virtual** **fashion shows** |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| **æœè£…è®¾è®¡** **å’Œè™šæ‹Ÿæ—¶å°šç§€** |'
- en: '**CLO3D** : A 3D garment design software that can create virtual fashion shows'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CLO3D**ï¼šä¸€ä¸ª3Dæœè£…è®¾è®¡è½¯ä»¶ï¼Œå¯ä»¥åˆ›å»ºè™šæ‹Ÿæ—¶å°šç§€'
- en: '**Browzwear** : Offers 3D design solutions for the fashion industry'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Browzwear**ï¼šä¸ºæ—¶å°šè¡Œä¸šæä¾›3Dè®¾è®¡è§£å†³æ–¹æ¡ˆ'
- en: '|'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**Blender** : While primarily a 3D modeling tool, it can be used for fashion
    design and virtual shows'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Blender**ï¼šè™½ç„¶ä¸»è¦æ˜¯ä¸€ä¸ª3Då»ºæ¨¡å·¥å…·ï¼Œä½†ä¹Ÿå¯ä»¥ç”¨äºæ—¶å°šè®¾è®¡å’Œè™šæ‹Ÿç§€'
- en: '|'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Fashion** **trend predictions** |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| **æ—¶å°š** **è¶‹åŠ¿é¢„æµ‹** |'
- en: '**WGSN** : Uses AI for trend forecasting in fashion'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**WGSN**ï¼šä½¿ç”¨AIè¿›è¡Œæ—¶å°šè¶‹åŠ¿é¢„æµ‹'
- en: '**Heuritech** : Provides AI-powered trend forecasting'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Heuritech**ï¼šæä¾›AIé©±åŠ¨çš„è¶‹åŠ¿é¢„æµ‹'
- en: '|'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: None
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: None
- en: '|'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Marketing â€“ ad generation and** **campaign creation** |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| **è¥é”€** **å¹¿å‘Šç”Ÿæˆå’Œ** **æ´»åŠ¨åˆ›å»º** |'
- en: '**Jasper** : An AI writing assistant that can help create marketing copy'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jasper**ï¼šä¸€ä¸ªAIå†™ä½œåŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©åˆ›å»ºè¥é”€æ–‡æ¡ˆ'
- en: '**Midjourney** : An AI image generation tool useful for creating marketing
    visuals'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Midjourney**ï¼šä¸€ä¸ªAIå›¾åƒç”Ÿæˆå·¥å…·ï¼Œå¯ç”¨äºåˆ›å»ºè¥é”€è§†è§‰å†…å®¹'
- en: '|'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**GPT-J** : An open source language model that can be fine-tuned for marketing
    content generation'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GPT-J**ï¼šä¸€ä¸ªå¼€æºè¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥é’ˆå¯¹è¥é”€å†…å®¹ç”Ÿæˆè¿›è¡Œå¾®è°ƒ'
- en: '**Stable Diffusion** :An open source image generation model that can create
    marketing visuals.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Stable Diffusion**ï¼šä¸€ä¸ªå¼€æºçš„å›¾åƒç”Ÿæˆæ¨¡å‹ï¼Œå¯ä»¥åˆ›å»ºè¥é”€è§†è§‰å†…å®¹ã€‚'
- en: '|'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Logo and** **image creation** |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| **æ ‡å¿—å’Œ** **å›¾åƒåˆ›å»º** |'
- en: '**DALL-E 2** : Can generate unique images and logos based on text descriptions'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DALL-E 2**ï¼šå¯ä»¥æ ¹æ®æ–‡æœ¬æè¿°ç”Ÿæˆç‹¬ç‰¹çš„å›¾åƒå’Œæ ‡å¿—'
- en: '**Canva** : While not fully AI-powered, it incorporates AI features for design
    assistance'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Canva**ï¼šè™½ç„¶ä¸æ˜¯å®Œå…¨ç”±AIé©±åŠ¨ï¼Œä½†å®ƒé›†æˆäº†AIåŠŸèƒ½ä»¥è¾…åŠ©è®¾è®¡'
- en: '|'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**Stable Diffusion** : Can be used for logo and image generation'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Stable Diffusion**ï¼šå¯ç”¨äºæ ‡å¿—å’Œå›¾åƒç”Ÿæˆ'
- en: '**Craiyon (formerly DALL-E mini)** : An open source alternative to DALL-E'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Craiyonï¼ˆåŸåDALL-E miniï¼‰**ï¼šDALL-Eçš„å¼€æºæ›¿ä»£å“'
- en: '|'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Text and** **content generation** |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| **æ–‡æœ¬å’Œ** **å†…å®¹ç”Ÿæˆ** |'
- en: ChatGPT by OpenAI
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAIçš„ChatGPT
- en: Claude AI by Anthropic
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anthropicçš„Claude AI
- en: Jasper
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jasper
- en: Copy.ai
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Copy.ai
- en: Anyword
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Anyword
- en: Writer
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Writer
- en: WriteSonic
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WriteSonic
- en: And many moreâ€¦ |
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰æ›´å¤šâ€¦â€¦ |
- en: '**Mistral 7B** : An open source LLM known for its efficiency and precision
    in text generation tasks'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Mistral 7B**ï¼šä¸€ä¸ªä»¥åœ¨æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­çš„æ•ˆç‡å’Œç²¾ç¡®æ€§è€Œé—»åçš„å¼€æºLLM'
- en: '**LLaMA** : A collection of open source pre-trained and fine-tuned generative
    text models, offering versions with different parameter sizes'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLaMA**ï¼šä¸€ç»„å¼€æºçš„é¢„è®­ç»ƒå’Œå¾®è°ƒçš„ç”Ÿæˆæ–‡æœ¬æ¨¡å‹ï¼Œæä¾›ä¸åŒå‚æ•°å¤§å°çš„ç‰ˆæœ¬'
- en: '**BLOOM Language Model** : A large open-access AI model developed by over 1,000
    AI researchers, known for its robustness and versatility in text generation'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BLOOMè¯­è¨€æ¨¡å‹**ï¼šç”±1000å¤šåAIç ”ç©¶äººå‘˜å¼€å‘çš„å¤§å‹å¼€æ”¾è®¿é—®AIæ¨¡å‹ï¼Œä»¥å…¶åœ¨æ–‡æœ¬ç”Ÿæˆä¸­çš„é²æ£’æ€§å’Œå¤šåŠŸèƒ½æ€§è€Œé—»å'
- en: And many moreâ€¦ |
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰æ›´å¤šâ€¦ |
- en: '| **Code generation** |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| **ä»£ç ç”Ÿæˆ** |'
- en: GitHub Copilot
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GitHub Copilot
- en: Amazon Q for Developers
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon Q for Developers
- en: Tabnine
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tabnine
- en: OpenAI Codex
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI Codex
- en: And many moreâ€¦ |
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰æ›´å¤šâ€¦â€¦ |
- en: '**Code T5** : An open source AI model trained for code-related tasks. It can
    generate code snippets, complete code, and even translate between programming
    languages.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Code T5**ï¼šä¸€ä¸ªç”¨äºä»£ç ç›¸å…³ä»»åŠ¡çš„å¼€æºAIæ¨¡å‹ã€‚å®ƒå¯ä»¥ç”Ÿæˆä»£ç ç‰‡æ®µã€å®Œæ•´ä»£ç ï¼Œç”šè‡³å¯ä»¥åœ¨ç¼–ç¨‹è¯­è¨€ä¹‹é—´è¿›è¡Œç¿»è¯‘ã€‚'
- en: '**Polycoder** : An open source alternative to commercial code generators. Itâ€™s
    trained on a large code base spanning multiple programming languages and can generate
    code for various tasks.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Polycoder**ï¼šä¸€ä¸ªå¼€æºçš„å•†ä¸šä»£ç ç”Ÿæˆå™¨çš„æ›¿ä»£å“ã€‚å®ƒåœ¨æ¶µç›–å¤šç§ç¼–ç¨‹è¯­è¨€çš„åºå¤§ä»£ç åº“ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå¯ä»¥ç”Ÿæˆç”¨äºå„ç§ä»»åŠ¡çš„ä»£ç ã€‚'
- en: '|'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Autonomous workflows** **and robotics** |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| **è‡ªä¸»å·¥ä½œæµ** **å’Œæœºå™¨äºº** |'
- en: '**UiPath** incorporates generative AI into its **robotic process automation**
    ( **RPA** ) platform. It uses AI to discover automation opportunities and enhance
    tasks such as document understanding and communications mining.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**UiPath** å°†ç”Ÿæˆå¼ AI é›†æˆåˆ°å…¶ **æœºå™¨äººæµç¨‹è‡ªåŠ¨åŒ–**ï¼ˆ**RPA**ï¼‰å¹³å°ä¸­ã€‚å®ƒä½¿ç”¨ AI æ¥å‘ç°è‡ªåŠ¨åŒ–æœºä¼šï¼Œå¹¶å¢å¼ºè¯¸å¦‚æ–‡æ¡£ç†è§£å’Œé€šä¿¡æŒ–æ˜ç­‰ä»»åŠ¡ã€‚'
- en: '**Automation Anywhere** integrates generative AI into its automation platform.
    It offers features such as Automation Co-Pilot for Automators, which uses generative
    AI to accelerate developer productivity.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Automation Anywhere** å°†ç”Ÿæˆå¼ AI é›†æˆåˆ°å…¶è‡ªåŠ¨åŒ–å¹³å°ä¸­ã€‚å®ƒæä¾›äº†è‡ªåŠ¨åŒ–ååŒé©¾é©¶è€…ç­‰ç‰¹æ€§ï¼Œè¯¥ç‰¹æ€§ä½¿ç”¨ç”Ÿæˆå¼ AI æ¥åŠ é€Ÿå¼€å‘è€…çš„ç”Ÿäº§åŠ›ã€‚'
- en: '**NVIDIA** provides AI workflows that leverage their AI frameworks, including
    generative AI capabilities, for developing innovative solutions in robotics and
    autonomous systems.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NVIDIA** æä¾›äº†åˆ©ç”¨å…¶ AI æ¡†æ¶çš„ AI å·¥ä½œæµï¼ŒåŒ…æ‹¬ç”Ÿæˆå¼ AI åŠŸèƒ½ï¼Œç”¨äºå¼€å‘æœºå™¨äººå­¦å’Œè‡ªä¸»ç³»ç»Ÿä¸­çš„åˆ›æ–°è§£å†³æ–¹æ¡ˆã€‚'
- en: '|'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '**OpenAI Gym** provides a toolkit for developing and comparing reinforcement
    learning algorithms, which can be combined with LLMs for more advanced robotics
    applications.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OpenAI Gym** æä¾›äº†ä¸€ä¸ªç”¨äºå¼€å‘å’Œæ¯”è¾ƒå¼ºåŒ–å­¦ä¹ ç®—æ³•çš„å·¥å…·åŒ…ï¼Œè¿™äº›ç®—æ³•å¯ä»¥ä¸ LLMs ç»“åˆï¼Œç”¨äºæ›´é«˜çº§çš„æœºå™¨äººåº”ç”¨ã€‚'
- en: '**Hugging Face** offers open source libraries that can be used to implement
    LLMs in robotics and autonomous workflow applications.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hugging Face** æä¾›äº†å¼€æºåº“ï¼Œå¯ç”¨äºåœ¨æœºå™¨äººå­¦å’Œè‡ªä¸»å·¥ä½œæµåº”ç”¨ä¸­å®ç° LLMsã€‚'
- en: '**LangChain** is an open source Python library used for developing applications
    using LLMs, which can be applied to create more intelligent autonomous workflows
    and robotic systems.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LangChain** æ˜¯ä¸€ä¸ªå¼€æºçš„ Python åº“ï¼Œç”¨äºå¼€å‘ä½¿ç”¨ LLMs çš„åº”ç”¨ç¨‹åºï¼Œå¯ä»¥åº”ç”¨äºåˆ›å»ºæ›´æ™ºèƒ½çš„è‡ªä¸»å·¥ä½œæµå’Œæœºå™¨äººç³»ç»Ÿã€‚'
- en: '|'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Table 1.1 â€“ Examples of commercial and open source tools that use generative
    AI
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: è¡¨ 1.1 â€“ ä½¿ç”¨ç”Ÿæˆå¼ AI çš„å•†ä¸šå’Œå¼€æºå·¥å…·ç¤ºä¾‹
- en: This is in no way an exhaustive list of commercial and open source tools available
    in the market at the moment and the landscape is changing every day. We are witnessing
    a host of new start-ups providing new and innovative ways of solving real-life
    use cases with generative AI, and we are also witnessing new model providers developing
    state-of-the-art LLMs that are more capable than the previous ones and are much
    cheaper to operate. This just goes to show you how dynamic and exciting the field
    of generative AI is.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç»ä¸æ˜¯ç›®å‰å¸‚åœºä¸Šå¯ç”¨çš„å•†ä¸šå’Œå¼€æºå·¥å…·çš„å®Œæ•´åˆ—è¡¨ï¼Œè€Œä¸”è¿™ä¸ªé¢†åŸŸæ¯å¤©éƒ½åœ¨å˜åŒ–ã€‚æˆ‘ä»¬æ­£åœ¨è§è¯è®¸å¤šæ–°çš„åˆåˆ›å…¬å¸æä¾›ä½¿ç”¨ç”Ÿæˆå¼ AI è§£å†³ç°å®ç”Ÿæ´»ç”¨ä¾‹çš„æ–°é¢–å’Œåˆ›æ–°æ–¹æ³•ï¼ŒåŒæ—¶æˆ‘ä»¬ä¹Ÿåœ¨è§è¯æ–°çš„æ¨¡å‹æä¾›å•†å¼€å‘å‡ºæ¯”ä¹‹å‰æ›´å¼ºå¤§ä¸”è¿è¥æˆæœ¬æ›´ä½çš„
    LLMsã€‚è¿™ä»…ä»…å±•ç¤ºäº†ç”Ÿæˆå¼ AI é¢†åŸŸçš„åŠ¨æ€å’Œæ¿€åŠ¨äººå¿ƒçš„ç‰¹ç‚¹ã€‚
- en: Challenges and limitations of generative AI
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼ AI çš„æŒ‘æˆ˜å’Œå±€é™æ€§
- en: Though generative AI has immense benefits, it is not without its own set of
    challenges and limitations. Some of these challenges and limitations need to be
    taken into account with a lot of caution while considering a generative AI technology
    for any particular use case. Hereâ€™s a brief discussion of some of the most common
    caveats related to LLMs and some of the ways to mitigate them.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡ç”Ÿæˆå¼ AI å…·æœ‰å·¨å¤§çš„å¥½å¤„ï¼Œä½†å®ƒå¹¶éæ²¡æœ‰è‡ªå·±çš„æŒ‘æˆ˜å’Œå±€é™æ€§ã€‚åœ¨è€ƒè™‘å°†ç”Ÿæˆå¼ AI æŠ€æœ¯åº”ç”¨äºä»»ä½•ç‰¹å®šç”¨ä¾‹æ—¶ï¼Œéœ€è¦éå¸¸è°¨æ…åœ°è€ƒè™‘è¿™äº›æŒ‘æˆ˜å’Œå±€é™æ€§ã€‚ä»¥ä¸‹æ˜¯å¯¹ä¸€äº›ä¸
    LLMs ç›¸å…³çš„å¸¸è§æ³¨æ„äº‹é¡¹çš„ç®€è¦è®¨è®ºï¼Œä»¥åŠä¸€äº›å‡è½»è¿™äº›é—®é¢˜çš„æ–¹æ³•ã€‚
- en: Quality of data and bias
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®è´¨é‡å’Œåè§
- en: The generative models are largely aided by the quality and diversity of data
    in the training dataset. Any model trained with biased or unrepresentative data
    will reproduce outputs with the same kind of bias, hence solidifying existing
    biases or allowing marginalization of one or several groups in case of bias in
    the training data.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆæ¨¡å‹åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºè®­ç»ƒæ•°æ®é›†ä¸­æ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚ä»»ä½•ä½¿ç”¨æœ‰åè§æˆ–ä¸å…·ä»£è¡¨æ€§çš„æ•°æ®è¿›è¡Œè®­ç»ƒçš„æ¨¡å‹éƒ½å°†äº§ç”Ÿå…·æœ‰ç›¸åŒç±»å‹åè§çš„è¾“å‡ºï¼Œä»è€Œå·©å›ºç°æœ‰çš„åè§ï¼Œæˆ–è€…åœ¨è®­ç»ƒæ•°æ®å­˜åœ¨åè§çš„æƒ…å†µä¸‹ï¼Œä½¿ä¸€ä¸ªæˆ–å¤šä¸ªç¾¤ä½“è¾¹ç¼˜åŒ–ã€‚
- en: 'One way this challenge can be dealt with is by ensuring richness in diversity,
    good quality data, and so on for a wide array of perspectives within the dataset
    itself used for training. As with any machine learning problem, analysis of the
    data and knowing the data distribution across features is often helpful. Data
    analysis can reveal imbalances that can introduce bias in the model. There are
    several algorithmic ways of mitigating bias in training data (for instance, using
    oversampling or undersampling), but each of these methods has its own advantages
    and disadvantages. For example, consider two classes of data in a training dataset
    that contains more instances of *Class 0* data than *Class 1* data, causing a
    natural imbalance in the dataset. When a model is trained with such a dataset,
    the model would â€œoverfitâ€ on the *Class 0* type of data and would become more
    proficient in or even memorize data that belongs to *Class 0* and may not perform
    well for data belonging to *Class 1* This inherently causes the model to perform
    poorly and demonstrate heavy bias. The following figure demonstrates the effect
    of oversampling and undersampling on such a dataset to mitigate bias:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: å¤„ç†è¿™ç§æŒ‘æˆ˜çš„ä¸€ç§æ–¹æ³•æ˜¯é€šè¿‡ç¡®ä¿æ•°æ®é›†æœ¬èº«ç”¨äºè®­ç»ƒçš„å¹¿æ³›è§†è§’ä¸­çš„å¤šæ ·æ€§ä¸°å¯Œæ€§ã€é«˜è´¨é‡æ•°æ®ç­‰ã€‚ä¸ä»»ä½•æœºå™¨å­¦ä¹ é—®é¢˜ä¸€æ ·ï¼Œåˆ†ææ•°æ®å’Œäº†è§£æ•°æ®åœ¨ç‰¹å¾ä¸Šçš„åˆ†å¸ƒé€šå¸¸æ˜¯æœ‰å¸®åŠ©çš„ã€‚æ•°æ®åˆ†æå¯ä»¥æ­ç¤ºå¯èƒ½å¯¼è‡´æ¨¡å‹åå·®çš„ä¸å¹³è¡¡ã€‚æœ‰å‡ ç§ç®—æ³•æ–¹æ³•å¯ä»¥å‡è½»è®­ç»ƒæ•°æ®ä¸­çš„åå·®ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨è¿‡é‡‡æ ·æˆ–æ¬ é‡‡æ ·ï¼‰ï¼Œä½†æ¯ç§æ–¹æ³•éƒ½æœ‰å…¶è‡ªèº«çš„ä¼˜ç¼ºç‚¹ã€‚ä¾‹å¦‚ï¼Œè€ƒè™‘ä¸€ä¸ªè®­ç»ƒæ•°æ®é›†çš„ä¸¤ä¸ªç±»åˆ«ï¼Œå…¶ä¸­*Class
    0*æ•°æ®å®ä¾‹æ¯”*Class 1*æ•°æ®å®ä¾‹å¤šï¼Œå¯¼è‡´æ•°æ®é›†è‡ªç„¶ä¸å¹³è¡¡ã€‚å½“ä½¿ç”¨è¿™æ ·çš„æ•°æ®é›†è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæ¨¡å‹ä¼šå¯¹*Class 0*ç±»å‹çš„æ•°æ®â€œè¿‡åº¦æ‹Ÿåˆâ€ï¼Œå¹¶å¯èƒ½æ›´åŠ æ“…é•¿æˆ–ç”šè‡³è®°ä½å±äº*Class
    0*çš„æ•°æ®ï¼Œè€Œå¯¹äºå±äº*Class 1*çš„æ•°æ®å¯èƒ½è¡¨ç°ä¸ä½³ã€‚è¿™æœ¬è´¨ä¸Šå¯¼è‡´æ¨¡å‹è¡¨ç°ä¸ä½³å¹¶æ˜¾ç¤ºå‡ºä¸¥é‡çš„åå·®ã€‚ä»¥ä¸‹å›¾å±•ç¤ºäº†è¿‡é‡‡æ ·å’Œæ¬ é‡‡æ ·å¯¹è¿™ç§æ•°æ®é›†çš„å½±å“ï¼Œä»¥å‡è½»åå·®ï¼š
- en: '![img](img/B31483_01_3.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B31483_01_3.jpg)'
- en: Figure 1.3 â€“ Imbalanced data distribution and effects of oversampling and undersampling
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾1.3 â€“ ä¸å¹³è¡¡æ•°æ®åˆ†å¸ƒå’Œè¿‡é‡‡æ ·ã€æ¬ é‡‡æ ·çš„å½±å“
- en: Data privacy
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ•°æ®éšç§
- en: Multiple experiments and researchers have proven that LLMs have a propensity
    to leak data they are trained on. This is especially problematic if the models
    are trained on large amounts of private or proprietary information. Special techniques
    and styles of prompting LLMs have shown that it is sufficient to coerce the model
    to generate data that includes verbatim text from its training dataset. These
    prompting techniques are not sophisticated and often make it a very easy, cost-effective
    attack vector to get a model to leak information. For example, as discussed in
    the paper named *Scalable Extraction of Training Data from (Production) Language
    Models* [15], researchers were able to spend only $200 worth of API calls to OpenAIâ€™s
    GPT-3.5 model and use prompt injection techniques to coerce the model to leak
    private information. The leaked information includes peopleâ€™s names, email and
    physical addresses, and phone numbers that were inadvertently present in the modelâ€™s
    training dataset. While some of these issues are actively being addressed by model
    providers such as OpenAI, it can still be problematic for organizations that choose
    to train their own models in-house.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: å¤šé¡¹å®éªŒå’Œç ”ç©¶äººå‘˜å·²ç»è¯æ˜ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æœ‰æ³„éœ²å®ƒä»¬è®­ç»ƒæ•°æ®çš„å€¾å‘ã€‚å¦‚æœæ¨¡å‹æ˜¯åœ¨å¤§é‡ç§äººæˆ–ä¸“æœ‰ä¿¡æ¯ä¸Šè®­ç»ƒçš„ï¼Œè¿™å°¤å…¶æˆé—®é¢˜ã€‚å¯¹LLMsè¿›è¡Œç‰¹æ®ŠæŠ€å·§å’Œé£æ ¼çš„æç¤ºå·²ç»è¡¨æ˜ï¼Œè¿«ä½¿æ¨¡å‹ç”ŸæˆåŒ…å«å…¶è®­ç»ƒæ•°æ®é›†ä¸­å­—é¢æ–‡æœ¬çš„æ•°æ®æ˜¯è¶³å¤Ÿçš„ã€‚è¿™äº›æç¤ºæŠ€æœ¯å¹¶ä¸å¤æ‚ï¼Œé€šå¸¸ä½¿æ”»å‡»å‘é‡å˜å¾—éå¸¸ç®€å•ã€æˆæœ¬æ•ˆç›Šé«˜ï¼Œå¯ä»¥è¿«ä½¿æ¨¡å‹æ³„éœ²ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œæ­£å¦‚åœ¨åä¸º*Scalable
    Extraction of Training Data from (Production) Language Models* [15]çš„è®ºæ–‡ä¸­è®¨è®ºçš„é‚£æ ·ï¼Œç ”ç©¶äººå‘˜èƒ½å¤Ÿä»…èŠ±è´¹ä»·å€¼200ç¾å…ƒçš„APIè°ƒç”¨è´¹ç”¨ï¼Œä½¿ç”¨æç¤ºæ³¨å…¥æŠ€æœ¯è¿«ä½¿OpenAIçš„GPT-3.5æ¨¡å‹æ³„éœ²ç§äººä¿¡æ¯ã€‚æ³„éœ²çš„ä¿¡æ¯åŒ…æ‹¬äººä»¬çš„å§“åã€ç”µå­é‚®ä»¶å’Œç‰©ç†åœ°å€ï¼Œä»¥åŠæ¨¡å‹è®­ç»ƒæ•°æ®é›†ä¸­æ„å¤–å‡ºç°çš„ç”µè¯å·ç ã€‚è™½ç„¶ä¸€äº›è¿™äº›é—®é¢˜æ­£åœ¨ç”±æ¨¡å‹æä¾›å•†å¦‚OpenAIç§¯æè§£å†³ï¼Œä½†å¯¹äºé€‰æ‹©åœ¨å†…éƒ¨è‡ªè¡Œè®­ç»ƒæ¨¡å‹çš„ç»„ç»‡æ¥è¯´ï¼Œè¿™ä»ç„¶å¯èƒ½æ˜¯ä¸ªé—®é¢˜ã€‚
- en: Some of the common mechanisms to mitigate this is to perform data anonymization
    or pseudonymization on the training data to remove or obscure personal, private,
    and or proprietary information, even before training the model. Both of these
    techniques involved using smaller, cheaper, and faster AI models to perform classification
    and entity detection to identify the presence of personal or private data in the
    training dataset. Once identified, the private information can be obscured, masked,
    or entirely removed from the training dataset. Note that there could be several
    implications to doing this depending on your use case, so special analysis must
    be performed to ensure that it doesnâ€™t impact the modelâ€™s performance.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€äº›å¸¸è§çš„ç¼“è§£æœºåˆ¶æ˜¯åœ¨è®­ç»ƒæ•°æ®ä¸Šæ‰§è¡Œæ•°æ®åŒ¿ååŒ–æˆ–å‡ååŒ–ï¼Œä»¥åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰åˆ é™¤æˆ–æ¨¡ç³Šä¸ªäººã€ç§äººæˆ–ä¸“æœ‰ä¿¡æ¯ã€‚è¿™ä¸¤ç§æŠ€æœ¯éƒ½æ¶‰åŠä½¿ç”¨æ›´å°ã€æ›´ä¾¿å®œã€æ›´å¿«çš„AIæ¨¡å‹æ¥æ‰§è¡Œåˆ†ç±»å’Œå®ä½“æ£€æµ‹ï¼Œä»¥è¯†åˆ«è®­ç»ƒæ•°æ®é›†ä¸­æ˜¯å¦å­˜åœ¨ä¸ªäººæˆ–ç§äººæ•°æ®ã€‚ä¸€æ—¦è¯†åˆ«å‡ºæ¥ï¼Œè¿™äº›ç§äººä¿¡æ¯å¯ä»¥è¢«æ¨¡ç³Šã€æ©ç›–æˆ–å®Œå…¨ä»è®­ç»ƒæ•°æ®é›†ä¸­åˆ é™¤ã€‚è¯·æ³¨æ„ï¼Œæ ¹æ®æ‚¨çš„ç”¨ä¾‹ï¼Œè¿™æ ·åšå¯èƒ½ä¼šæœ‰å‡ ä¸ªå½±å“ï¼Œå› æ­¤å¿…é¡»è¿›è¡Œç‰¹æ®Šåˆ†æä»¥ç¡®ä¿ä¸ä¼šå½±å“æ¨¡å‹çš„è¡¨ç°ã€‚
- en: Computational resources
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è®¡ç®—èµ„æº
- en: Training sophisticated generative models is very resource-intensive and requires
    high computational power; this often makes it economically cost-prohibitive and
    energy-consuming to train large language models. Although there have been several
    hardware breakthroughs that make it possible to train such models, access to these
    hardware assets still remains expensive, privileged, and limited. For example,
    **graphics processing units** ( **GPUs** ), initially designed for rendering high-fidelity
    graphics, have become crucial for AI model training, fine-tuning, and computations.
    NVIDIAâ€™s CUDA architecture, introduced in 2006, allowed GPUs to be used for general-purpose
    computing, and modern GPUs such as NVIDIAâ€™s A100 and H100 have since been specifically
    optimized for AI workloads. However, these high-end GPUs can often cost tens of
    thousands of dollars per unit.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå¤æ‚çš„ç”Ÿæˆæ¨¡å‹éå¸¸èµ„æºå¯†é›†ï¼Œéœ€è¦é«˜è®¡ç®—èƒ½åŠ›ï¼›è¿™é€šå¸¸ä½¿å¾—è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç»æµä¸Šæˆæœ¬é«˜æ˜‚ä¸”èƒ½è€—å·¨å¤§ã€‚å°½ç®¡å·²ç»æœ‰ä¸€äº›ç¡¬ä»¶çªç ´ä½¿å¾—è®­ç»ƒæ­¤ç±»æ¨¡å‹æˆä¸ºå¯èƒ½ï¼Œä½†è¿™äº›ç¡¬ä»¶èµ„äº§ä»ç„¶ä»·æ ¼æ˜‚è´µã€ç‰¹æƒä¸”æœ‰é™ã€‚ä¾‹å¦‚ï¼Œ**å›¾å½¢å¤„ç†å•å…ƒ**ï¼ˆ**GPU**ï¼‰ï¼Œæœ€åˆæ˜¯ä¸ºæ¸²æŸ“é«˜ä¿çœŸå›¾å½¢è€Œè®¾è®¡çš„ï¼Œå·²ç»æˆä¸ºAIæ¨¡å‹è®­ç»ƒã€å¾®è°ƒå’Œè®¡ç®—çš„å…³é”®ã€‚NVIDIAçš„CUDAæ¶æ„äº2006å¹´æ¨å‡ºï¼Œä½¿å¾—GPUèƒ½å¤Ÿç”¨äºé€šç”¨è®¡ç®—ï¼Œè€Œç°ä»£GPUå¦‚NVIDIAçš„A100å’ŒH100è‡ªé‚£æ—¶èµ·å°±ä¸“é—¨é’ˆå¯¹AIå·¥ä½œè´Ÿè½½è¿›è¡Œäº†ä¼˜åŒ–ã€‚ç„¶è€Œï¼Œè¿™äº›é«˜ç«¯GPUçš„å•ä½ä»·æ ¼é€šå¸¸é«˜è¾¾æ•°ä¸‡ç¾å…ƒã€‚
- en: Training large models such as GPT-3 is estimated to cost millions of dollars
    in compute resources alone. The exact cost depends on factors such as model size,
    training duration, and hardware efficiency. For example, training GPT-3 was estimated
    to cost around $4â€“5 million in compute resources, and more recent models such
    as GPT-4 and PaLM are likely even more expensive to train. Beyond the hardware
    itself, there are significant infrastructure costs related to power consumption,
    cooling, and data center space. Due to the high costs, training large language
    models is primarily done by large tech companies or well-funded research institutions.
    Cloud services now offer access to pre-trained models and fine-tuning capabilities,
    making some level of LLM work more accessible to smaller organizations and the
    general public. A way to overcome this challenge can be found in recent innovations
    with **small language models** ( **SLMs** ), which are much smaller generative
    AI models that can be trained to achieve specific tasks. Even though these models
    are limited to a very narrow set of domain-specific tasks, it is much more economical
    to train these models since they require far fewer computational resources.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: è®­ç»ƒå¤§å‹æ¨¡å‹å¦‚GPT-3ä»…è®¡ç®—èµ„æºå°±ä¼°è®¡éœ€è¦æ•°ç™¾ä¸‡ç¾å…ƒã€‚ç¡®åˆ‡æˆæœ¬å–å†³äºæ¨¡å‹å¤§å°ã€è®­ç»ƒæ—¶é—´å’Œç¡¬ä»¶æ•ˆç‡ç­‰å› ç´ ã€‚ä¾‹å¦‚ï¼Œè®­ç»ƒGPT-3ä¼°è®¡éœ€è¦çº¦4000ä¸‡è‡³5000ä¸‡ç¾å…ƒçš„è®¡ç®—èµ„æºï¼Œè€Œæ›´è¿‘æœŸçš„æ¨¡å‹å¦‚GPT-4å’ŒPaLMçš„è®­ç»ƒæˆæœ¬å¯èƒ½æ›´é«˜ã€‚é™¤äº†ç¡¬ä»¶æœ¬èº«ä¹‹å¤–ï¼Œè¿˜å­˜åœ¨ç€ä¸ç”µåŠ›æ¶ˆè€—ã€å†·å´å’Œæ•°æ®ä¸­å¿ƒç©ºé—´ç›¸å…³çš„é‡å¤§åŸºç¡€è®¾æ–½æˆæœ¬ã€‚ç”±äºæˆæœ¬é«˜æ˜‚ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒä¸»è¦ç”±å¤§å‹ç§‘æŠ€å…¬å¸æˆ–èµ„é‡‘å……è¶³çš„ç§‘ç ”æœºæ„å®Œæˆã€‚äº‘æœåŠ¡ç°åœ¨æä¾›å¯¹é¢„è®­ç»ƒæ¨¡å‹å’Œå¾®è°ƒèƒ½åŠ›çš„è®¿é—®ï¼Œä½¿å¾—æŸäº›çº§åˆ«çš„LLMå·¥ä½œå¯¹å°å‹ç»„ç»‡å’Œå…¬ä¼—æ›´åŠ å¯åŠã€‚æœ€è¿‘åœ¨**å°å‹è¯­è¨€æ¨¡å‹**ï¼ˆ**SLMs**ï¼‰æ–¹é¢çš„åˆ›æ–°æä¾›äº†ä¸€ç§å…‹æœè¿™ä¸€æŒ‘æˆ˜çš„æ–¹æ³•ï¼Œè¿™äº›æ¨¡å‹æ˜¯æ›´å°çš„ç”ŸæˆAIæ¨¡å‹ï¼Œå¯ä»¥è®­ç»ƒä»¥å®Œæˆç‰¹å®šä»»åŠ¡ã€‚å°½ç®¡è¿™äº›æ¨¡å‹ä»…é™äºéå¸¸ç‹­çª„çš„ç‰¹å®šé¢†åŸŸä»»åŠ¡ï¼Œä½†ç”±äºå®ƒä»¬éœ€è¦çš„è®¡ç®—èµ„æºè¿œå°‘å¾—å¤šï¼Œå› æ­¤è®­ç»ƒè¿™äº›æ¨¡å‹çš„ç»æµæ€§è¦é«˜å¾—å¤šã€‚
- en: Ethical and social implications
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é“å¾·å’Œç¤¾ä¼šå½±å“
- en: 'The range of issues in ethics and society exposed by strides in technological
    generative AI opened up the following many-headed issues, which is far from an
    exhaustive list:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: æŠ€æœ¯ç”Ÿæˆå¼AIçš„è¿›æ­¥åœ¨ä¼¦ç†å’Œç¤¾ä¼šæ–¹é¢æš´éœ²å‡ºçš„ä¸€ç³»åˆ—é—®é¢˜ï¼Œå¼•å‘äº†ä»¥ä¸‹è®¸å¤šå¤æ‚é—®é¢˜ï¼Œè¿™è¿œéä¸€ä¸ªè¯¦å°½çš„åˆ—è¡¨ï¼š
- en: '**Deepfakes and misinformation** : It is able to produce very realistic synthetically
    generated content. If that were to happen, it would yield deepfakes or even misinformation,
    which could be a threat to privacy, security, or even public trust.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ·±åº¦ä¼ªé€ å’Œè™šå‡ä¿¡æ¯**ï¼šå®ƒèƒ½å¤Ÿç”Ÿæˆéå¸¸é€¼çœŸçš„åˆæˆå†…å®¹ã€‚å¦‚æœå‘ç”Ÿè¿™ç§æƒ…å†µï¼Œå®ƒå°†äº§ç”Ÿæ·±åº¦ä¼ªé€ ç”šè‡³è™šå‡ä¿¡æ¯ï¼Œè¿™å¯èƒ½å¯¹éšç§ã€å®‰å…¨ç”šè‡³å…¬ä¼—ä¿¡ä»»æ„æˆå¨èƒã€‚'
- en: '**Intellectual property** : The process of developing comparable content to
    existing ones brings forth issues with copyright and intellectual property rights.
    The legal complexity attached to the very originality of the creation and correct
    ownership can be most perplexing.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**çŸ¥è¯†äº§æƒ**ï¼šå¼€å‘ä¸ç°æœ‰å†…å®¹ç›¸ä¼¼çš„è¿‡ç¨‹ä¼šå¼•å‘ç‰ˆæƒå’ŒçŸ¥è¯†äº§æƒé—®é¢˜ã€‚ä¸åˆ›ä½œçš„åŸåˆ›æ€§å’Œæ­£ç¡®æ‰€æœ‰æƒç›¸å…³çš„æ³•å¾‹å¤æ‚æ€§å¯èƒ½éå¸¸ä»¤äººå›°æƒ‘ã€‚'
- en: '**Job displacement** : Economists often downplay concerns about significant
    job losses in content generation and other automated task sectors. Of concern
    is the fact that resultant effects are expected to be paralleled with studies
    on ways of reskilling and adjustment strategies that can help the affected workers,
    as well as entrepreneurial opportunities.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å·¥ä½œæ›¿ä»£**ï¼šç»æµå­¦å®¶å¸¸å¸¸æ·¡åŒ–å¯¹å†…å®¹ç”Ÿæˆå’Œå…¶ä»–è‡ªåŠ¨åŒ–ä»»åŠ¡é¢†åŸŸé‡å¤§å¤±ä¸šçš„æ‹…å¿§ã€‚ä»¤äººæ‹…å¿§çš„æ˜¯ï¼Œé¢„æœŸç»“æœå°†ä¸å…³äºå†åŸ¹è®­å’Œè°ƒæ•´ç­–ç•¥çš„ç ”ç©¶ç›¸å¹³è¡Œï¼Œè¿™äº›ç­–ç•¥å¯ä»¥å¸®åŠ©å—å½±å“çš„å·¥äººï¼Œä»¥åŠåˆ›ä¸šæœºä¼šã€‚'
- en: When it comes to mitigating social and ethical implications, the question is
    more philosophical than technical. While some measures such as deepfake AI image
    detection and private and personal data detection methods are common strategies,
    the societal implications are a larger question in the context of AIâ€™s benefit
    to society and any existing or impending government regulations.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: å½“è°ˆåˆ°å‡è½»ç¤¾ä¼šå’Œä¼¦ç†å½±å“æ—¶ï¼Œé—®é¢˜æ›´å¤šçš„æ˜¯å“²å­¦æ€§çš„ï¼Œè€Œä¸æ˜¯æŠ€æœ¯æ€§çš„ã€‚è™½ç„¶æ·±åº¦ä¼ªé€ AIå›¾åƒæ£€æµ‹å’Œç§äººåŠä¸ªäººæ•°æ®æ£€æµ‹æ–¹æ³•ç­‰æ˜¯ä¸€äº›å¸¸è§çš„ç­–ç•¥ï¼Œä½†åœ¨AIå¯¹ç¤¾ä¼šçš„å¥½å¤„ä»¥åŠä»»ä½•ç°æœ‰æˆ–å³å°†å‡ºå°çš„æ”¿åºœæ³•è§„çš„èƒŒæ™¯ä¸‹ï¼Œç¤¾ä¼šå½±å“æ˜¯ä¸€ä¸ªæ›´å¤§çš„é—®é¢˜ã€‚
- en: Generalization and creativity
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ³›åŒ–ä¸åˆ›é€ åŠ›
- en: One of the big problems with these generative AI models is that their generalization
    ability turns out to be very poor. More concretely, they seldom generate content
    that is strikingly different from the training data. That is, they are brilliant
    at copying the repeating patterns but fail really to create something original
    or novel. As a consequence, their potential for capital *C* creativity stays very
    limited.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ç”Ÿæˆå¼AIæ¨¡å‹çš„ä¸€ä¸ªå¤§é—®é¢˜æ˜¯å®ƒä»¬çš„æ³›åŒ–èƒ½åŠ›éå¸¸å·®ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œå®ƒä»¬å¾ˆå°‘ç”Ÿæˆä¸è®­ç»ƒæ•°æ®æ˜¾è‘—ä¸åŒçš„å†…å®¹ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒä»¬æ“…é•¿å¤åˆ¶é‡å¤çš„æ¨¡å¼ï¼Œä½†çœŸæ­£åˆ›é€ åŸåˆ›æˆ–æ–°é¢–çš„ä¸œè¥¿çš„èƒ½åŠ›éå¸¸æœ‰é™ã€‚å› æ­¤ï¼Œå®ƒä»¬åœ¨èµ„æœ¬Cåˆ›é€ åŠ›æ–¹é¢çš„æ½œåŠ›éå¸¸æœ‰é™ã€‚
- en: As generative AI continues to evolve in novel ways, it is bound to introduce
    novel challenges, as we are witnessing the barrage of new research and efforts
    to ensure sensible and responsible use of this technology.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: éšç€ç”Ÿæˆå¼AIä»¥æ–°é¢–çš„æ–¹å¼ä¸æ–­è¿›åŒ–ï¼Œå®ƒå¿…ç„¶ä¼šå¸¦æ¥æ–°çš„æŒ‘æˆ˜ï¼Œæ­£å¦‚æˆ‘ä»¬æ­£åœ¨è§è¯çš„æ–°ç ”ç©¶å’ŒåŠªåŠ›ï¼Œä»¥ç¡®ä¿è¯¥æŠ€æœ¯çš„åˆç†å’Œè´Ÿè´£ä»»çš„ä½¿ç”¨ã€‚
- en: Summary
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ‘˜è¦
- en: Generative AI is a rather rapidly growing area, having huge disruptive potential
    for industries and changing areas of our lives. In contrast, applications of generative
    AI include very realistic image generation and generation of text, accelerated
    drug discovery, and enriched creative expression.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIæ˜¯ä¸€ä¸ªå‘å±•ç›¸å½“è¿…é€Ÿçš„é¢†åŸŸï¼Œå¯¹è¡Œä¸šå’Œæˆ‘ä»¬çš„ç”Ÿæ´»çš„è®¸å¤šæ–¹é¢å…·æœ‰å·¨å¤§çš„é¢ è¦†æ€§æ½œåŠ›ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç”Ÿæˆå¼AIçš„åº”ç”¨åŒ…æ‹¬éå¸¸é€¼çœŸçš„å›¾åƒç”Ÿæˆå’Œæ–‡æœ¬ç”Ÿæˆã€åŠ é€Ÿè¯ç‰©å‘ç°ä»¥åŠä¸°å¯Œçš„åˆ›æ„è¡¨è¾¾ã€‚
- en: One of the key points regarding this is an understanding of the different generative
    models, such as VAEs, GANs, and autoregressive models, that provide insight into
    how technologies work and where they can be applied. It would also, however, be
    important to state the many problems and limitations generative AI faces, including
    data quality, computational resources, ethical considerations, and even creativity.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: å…³äºè¿™ä¸€ç‚¹çš„ä¸€ä¸ªå…³é”®ç‚¹æ˜¯ç†è§£ä¸åŒçš„ç”Ÿæˆæ¨¡å‹ï¼Œå¦‚VAEsã€GANså’Œè‡ªå›å½’æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥æä¾›å¯¹æŠ€æœ¯å¦‚ä½•å·¥ä½œä»¥åŠå®ƒä»¬å¯ä»¥åº”ç”¨åœ¨å“ªäº›æ–¹é¢çš„è§è§£ã€‚ç„¶è€Œï¼ŒæŒ‡å‡ºç”Ÿæˆå¼AIé¢ä¸´çš„è®¸å¤šé—®é¢˜å’Œå±€é™æ€§ä¹Ÿå¾ˆé‡è¦ï¼ŒåŒ…æ‹¬æ•°æ®è´¨é‡ã€è®¡ç®—èµ„æºã€ä¼¦ç†è€ƒè™‘ï¼Œç”šè‡³åˆ›é€ åŠ›ã€‚
- en: In the next chapter, we will learn about the principles of agentic systems,
    which include the concepts of agency and autonomy, the characteristics of intelligent
    agents, various architectures of intelligent systems, and multi-agent systems.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ å…³äºä»£ç†ç³»ç»ŸåŸç†çš„å†…å®¹ï¼Œè¿™åŒ…æ‹¬ä»£ç†å’Œè‡ªä¸»çš„æ¦‚å¿µã€æ™ºèƒ½ä»£ç†çš„ç‰¹å¾ã€æ™ºèƒ½ç³»ç»Ÿå„ç§æ¶æ„ä»¥åŠå¤šä»£ç†ç³»ç»Ÿã€‚
- en: Questions
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: é—®é¢˜
- en: Generative AI models can only take text data as input. True or false?
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIæ¨¡å‹åªèƒ½æ¥å—æ–‡æœ¬æ•°æ®ä½œä¸ºè¾“å…¥ã€‚å¯¹è¿˜æ˜¯é”™ï¼Ÿ
- en: What are the different types of generative AI models?
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIæ¨¡å‹æœ‰å“ªäº›ä¸åŒç±»å‹ï¼Ÿ
- en: What are some of the ethical and social implications of generative AI?
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç”Ÿæˆå¼AIæœ‰å“ªäº›ä¼¦ç†å’Œç¤¾ä¼šå½±å“ï¼Ÿ
- en: What are some of the methods to mitigate bias in training data?
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ‰å“ªäº›æ–¹æ³•å¯ä»¥å‡è½»è®­ç»ƒæ•°æ®ä¸­çš„åå·®ï¼Ÿ
- en: What are some of the text and content generation open source LLMs?
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æœ‰å“ªäº›æ–‡æœ¬å’Œå†…å®¹ç”Ÿæˆçš„å¼€æºLLMsï¼Ÿ
- en: Answers
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç­”æ¡ˆ
- en: False. Generative AI models can take text as well as image, video, and audio
    data as inputs.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: é”™è¯¯ã€‚ç”Ÿæˆå¼AIæ¨¡å‹å¯ä»¥å°†æ–‡æœ¬ä»¥åŠå›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘æ•°æ®ä½œä¸ºè¾“å…¥ã€‚
- en: VAEs, GANs, and autoregressive models.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: VAEsã€GANså’Œè‡ªå›å½’æ¨¡å‹ã€‚
- en: Deepfakes, misinformation, issues with copyright or intellectual property, and
    job displacements are some of the social and ethical implications of generative
    AI.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Deepfakesã€è™šå‡ä¿¡æ¯ã€ç‰ˆæƒæˆ–çŸ¥è¯†äº§æƒé—®é¢˜ä»¥åŠå°±ä¸šå²—ä½çš„æµå¤±æ˜¯ç”Ÿæˆå¼AIçš„ä¸€äº›ç¤¾ä¼šå’Œä¼¦ç†å½±å“ã€‚
- en: Some of the common methods to address bias in training data are oversampling
    or undersampling.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: è§£å†³è®­ç»ƒæ•°æ®åå·®çš„ä¸€äº›å¸¸è§æ–¹æ³•åŒ…æ‹¬è¿‡é‡‡æ ·æˆ–æ¬ é‡‡æ ·ã€‚
- en: Mistral, LLaMA, and Bloom are some of the open source text and content generation
    LLMs.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Mistralã€LLaMAå’ŒBloomæ˜¯ä¸€äº›å¼€æºçš„æ–‡æœ¬å’Œå†…å®¹ç”ŸæˆLLMsã€‚
- en: Further reading
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: è¿›ä¸€æ­¥é˜…è¯»
- en: '*Mastering Machine Learning Algorithms â€“ Second Edition* by Giuseppe Bonaccorso'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ã€Šç²¾é€šæœºå™¨å­¦ä¹ ç®—æ³•â€”â€”ç¬¬äºŒç‰ˆã€‹* ç”±Giuseppe Bonaccorsoè‘—'
- en: '*Machine Learning for Imbalanced Data* by Kumar Abhishek and Dr. Mounir Abdelaziz'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ã€Šä¸å¹³è¡¡æ•°æ®æœºå™¨å­¦ä¹ ã€‹* ç”±Kumar Abhishekå’ŒDr. Mounir Abdelazizè‘—'
- en: '*Generative AI with Python and TensorFlow 2* by Joseph Babcock and Raghav Bali'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ã€Šä½¿ç”¨Pythonå’ŒTensorFlow 2çš„ç”Ÿæˆå¼AIã€‹* ç”±Joseph Babcockå’ŒRaghav Baliè‘—'
- en: References
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: å‚è€ƒæ–‡çŒ®
- en: '*Auto-Encoding Variational* *Bayes* : [https://arxiv.org/abs/1312.6114](https://arxiv.org/abs/1312.6114)'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*è‡ªç¼–ç å˜åˆ†è´å¶æ–¯* : [https://arxiv.org/abs/1312.6114](https://arxiv.org/abs/1312.6114)'
- en: '*beta-VAE: Learning Basic Visual Concepts with a Constrained Variational* *Framework*
    : [https://openreview.net/forum?id=Sy2fzU9gl](https://openreview.net/forum?id=Sy2fzU9gl)'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*beta-VAEï¼šä½¿ç”¨çº¦æŸå˜åˆ†æ¡†æ¶å­¦ä¹ åŸºæœ¬è§†è§‰æ¦‚å¿µ* : [https://openreview.net/forum?id=Sy2fzU9gl](https://openreview.net/forum?id=Sy2fzU9gl)'
- en: '*Learning Structured Output Representation using Deep Conditional Generative*
    *Models* : [https://papers.nips.cc/paper_files/paper/2015/hash/8d55a249e6baa5c06772297520da2051-Abstract.html](https://papers.nips.cc/paper_files/paper/2015/hash/8d55a249e6baa5c06772297520da2051-Abstract.html)'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä½¿ç”¨æ·±åº¦æ¡ä»¶ç”Ÿæˆæ¨¡å‹å­¦ä¹ ç»“æ„åŒ–è¾“å‡ºè¡¨ç¤º* : [https://papers.nips.cc/paper_files/paper/2015/hash/8d55a249e6baa5c06772297520da2051-Abstract.html](https://papers.nips.cc/paper_files/paper/2015/hash/8d55a249e6baa5c06772297520da2051-Abstract.html)'
- en: '*Generative Adversarial* *Networks* : [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ* : [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)'
- en: '*Unsupervised Representation Learning with Deep Convolutional Generative Adversarial*
    *Networks* : [https://arxiv.org/abs/1511.06434](https://arxiv.org/abs/1511.06434)'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ã€Šä½¿ç”¨æ·±åº¦å·ç§¯ç”Ÿæˆå¯¹æŠ—ç½‘ç»œè¿›è¡Œæ— ç›‘ç£è¡¨ç¤ºå­¦ä¹ ã€‹* : [https://arxiv.org/abs/1511.06434](https://arxiv.org/abs/1511.06434)'
- en: '*Wasserstein* *GAN* : [https://arxiv.org/abs/1701.07875](https://arxiv.org/abs/1701.07875)'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*Wasserstein GAN* : [https://arxiv.org/abs/1701.07875](https://arxiv.org/abs/1701.07875)'
- en: '*A Style-Based Generator Architecture for Generative Adversarial* *Networks*
    : [https://ieeexplore.ieee.org/document/8953766](https://ieeexplore.ieee.org/document/8953766)'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ç”¨äºç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„åŸºäºé£æ ¼çš„ç”Ÿæˆå™¨æ¶æ„* : [https://ieeexplore.ieee.org/document/8953766](https://ieeexplore.ieee.org/document/8953766)'
- en: '*Attention Is All You* *Need* : [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ã€Šä¸“æ³¨å³ä¸€åˆ‡ã€‹* : [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)'
- en: '*Conditional Image Generation with PixelCNN* *Decoders* : [https://arxiv.org/abs/1606.05328](https://arxiv.org/abs/1606.05328)'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä½¿ç”¨PixelCNNè§£ç å™¨è¿›è¡Œæ¡ä»¶å›¾åƒç”Ÿæˆ* : [https://arxiv.org/abs/1606.05328](https://arxiv.org/abs/1606.05328)'
- en: '*PixelSNAIL: An Improved Autoregressive Generative* *Model* : [https://www.researchgate.net/publication/322114155_PixelSNAIL_An_Improved_Autoregressive_Generative_Model](https://www.researchgate.net/publication/322114155_PixelSNAIL_An_Improved_Autoregressive_Generative_Model)'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*PixelSNAILï¼šæ”¹è¿›çš„è‡ªå›å½’ç”Ÿæˆæ¨¡å‹* : [https://www.researchgate.net/publication/322114155_PixelSNAIL_An_Improved_Autoregressive_Generative_Model](https://www.researchgate.net/publication/322114155_PixelSNAIL_An_Improved_Autoregressive_Generative_Model)'
- en: '*Language Models are Few-Shot* *Learners* : [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*è¯­è¨€æ¨¡å‹æ˜¯å°‘æ ·æœ¬* *å­¦ä¹ è€…* : [https://arxiv.org/abs/2005.14165](https://arxiv.org/abs/2005.14165)'
- en: '*GPT-4 Technical* *Report* : [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*GPT-4æŠ€æœ¯* *æŠ¥å‘Š* : [https://arxiv.org/abs/2303.08774](https://arxiv.org/abs/2303.08774)'
- en: '*BERT: Pre-training of Deep Bidirectional Transformers for Language* *Understanding*
    : [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*BERTï¼šç”¨äºè¯­è¨€* *ç†è§£* çš„æ·±åº¦åŒå‘Transformeré¢„è®­ç»ƒ* : [https://arxiv.org/abs/1810.04805](https://arxiv.org/abs/1810.04805)'
- en: '*Exploring the Limits of Transfer Learning with a Unified Text-to-Text* *Transformer*
    : [https://arxiv.org/abs/1910.10683](https://arxiv.org/abs/1910.10683)'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*æ¢ç´¢ç»Ÿä¸€æ–‡æœ¬åˆ°æ–‡æœ¬* *Transformer* çš„è¿ç§»å­¦ä¹ æé™* : [https://arxiv.org/abs/1910.10683](https://arxiv.org/abs/1910.10683)'
- en: '*Scalable Extraction of Training Data from (Production) Language* *Models*
    : [https://arxiv.org/abs/2311.17035](https://arxiv.org/abs/2311.17035)'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*ä»ï¼ˆç”Ÿäº§ï¼‰è¯­è¨€* *æ¨¡å‹* ä¸­å¯æ‰©å±•åœ°æå–è®­ç»ƒæ•°æ®* : [https://arxiv.org/abs/2311.17035](https://arxiv.org/abs/2311.17035)'
- en: Join our communities on Discord and Reddit
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: åŠ å…¥æˆ‘ä»¬çš„Discordå’ŒRedditç¤¾åŒº
- en: Have questions about the book or want to contribute to discussions on Generative
    AI and LLMs? Join our Discord server at [https://packt.link/I1tSU](https://packt.link/I1tSU)
    and our Reddit channel at [https://packt.link/ugMW0](https://packt.link/ugMW0)
    to connect, share, and collaborate with like-minded enthusiasts.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹è¿™æœ¬ä¹¦æœ‰ç–‘é—®æˆ–æƒ³å‚ä¸å…³äºç”Ÿæˆå¼AIå’ŒLLMsçš„è®¨è®ºï¼ŸåŠ å…¥æˆ‘ä»¬çš„DiscordæœåŠ¡å™¨[https://packt.link/I1tSU](https://packt.link/I1tSU)å’ŒReddité¢‘é“[https://packt.link/ugMW0](https://packt.link/ugMW0)ï¼Œä¸å¿—åŒé“åˆçš„çˆ±å¥½è€…äº¤æµã€åˆ†äº«å’Œåä½œã€‚
- en: '![img](img/B31483_Discord_QR_new.jpg)![img](img/qrcode_Reddit_Channel.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B31483_Discord_QR_new.jpg)![img](img/qrcode_Reddit_Channel.jpg)'
