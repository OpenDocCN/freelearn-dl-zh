- en: Object Detection – CIFAR-10 Example
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标检测 – CIFAR-10 示例
- en: After covering the basics and the intuition/motivation behind **Convolution
    Neural Networks** (**CNNs**), we are going to demonstrate this on one of the most
    popular datasets available for object detection. We'll also see how the initial
    layers of the CNN get very basic features about our objects, but the final convolutional
    layers will get more semantic-level features that are built up from those basic
    features in the first layers.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍了**卷积神经网络**（**CNNs**）的基础和直觉/动机后，我们将在目标检测中展示其在其中一个最流行的数据集上的应用。我们还将看到CNN的初始层获取对象的基本特征，而最终的卷积层将从第一层的这些基本特征构建更语义级别的特征。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Object detection
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标检测
- en: CIFAR-10 object detection in mages—model building and training
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CIFAR-10 图像中对象检测—模型构建和训练
- en: Object detection
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标检测
- en: 'Wikipedia states that:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 维基百科指出：
- en: '"Object detection – technology in the field of computer vision for finding
    and identifying objects in an image or video sequence. Humans recognize a multitude
    of objects in images with little effort, despite the fact that the image of the
    objects may vary somewhat in different view points, in many different sizes and
    scales or even when they are translated or rotated. Objects can even be recognized
    when they are partially obstructed from view. This task is still a challenge for
    computer vision systems. Many approaches to the task have been implemented over
    multiple decades."'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '"目标检测是计算机视觉领域中用于在图像或视频序列中查找和识别对象的技术。人类在图像中识别多种对象并不费力，尽管对象的图像在不同视角、大小和比例以及平移或旋转时可能有所变化。即使对象部分遮挡视图时，也能识别出对象。对计算机视觉系统而言，这仍然是一个挑战。多年来已实施了多种方法来解决此任务。"'
- en: 'Image analysis is one of the most prominent fields in deep learning. Images
    are easy to generate and handle, and they are exactly the right type of data for
    machine learning: easy to understand for human beings, but difficult for computers.
    Not surprisingly, image analysis played a key role in the history of deep neural
    networks.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分析是深度学习中最显著的领域之一。图像易于生成和处理，它们恰好是机器学习的正确数据类型：对人类易于理解，但对计算机而言却很难。不奇怪，图像分析在深度神经网络的历史中发挥了关键作用。
- en: '![](img/0d82c9b0-e87a-4f16-a94c-805efcf6f9f5.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0d82c9b0-e87a-4f16-a94c-805efcf6f9f5.jpg)'
- en: 'Figure 11.1: Examples of detecting objects. Source: B. C. Russell, A. Torralba,
    C. Liu, R. Fergus, W. T. Freeman, Object Detection by Scene Alignment, Advances
    in Neural Information Processing Systems, 2007, at: http://bryanrussell.org/papers/nipsDetectionBySceneAlignment07.pdf'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1：检测对象的示例。来源：B. C. Russell, A. Torralba, C. Liu, R. Fergus, W. T. Freeman，《通过场景对齐进行对象检测》，2007
    年进展神经信息处理系统，网址：http://bryanrussell.org/papers/nipsDetectionBySceneAlignment07.pdf
- en: With the rise of autonomous cars, facial detection, smart video surveillance,
    and people-counting solutions, fast and accurate object detection systems are
    in a big demand. These systems include not only object recognition and classification
    in an image, but can also locate each one of them by drawing appropriate boxes
    around them. This makes object detection a harder task than its traditional computer
    vision predecessor, image classification.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着自动驾驶汽车、面部检测、智能视频监控和人数统计解决方案的兴起，快速准确的目标检测系统需求量大。这些系统不仅包括图像中对象的识别和分类，还可以通过绘制适当的框来定位每个对象。这使得目标检测比传统的计算机视觉前身——图像分类更为复杂。
- en: In this chapter, we'll look at object detection — finding out which objects
    are in an image. For example, imagine a self-driving car that needs to detect
    other cars on the road as in *Figure 11.1*. There are lots of complicated algorithms
    for object detection. They often require huge datasets, very deep convolutional
    networks, and long training times.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论目标检测——找出图像中有哪些对象。例如，想象一下自动驾驶汽车需要在道路上检测其他车辆，就像*图 11.1*中一样。目标检测有许多复杂的算法。它们通常需要庞大的数据集、非常深的卷积网络和长时间的训练。
- en: CIFAR-10 – modeling, building, and training
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CIFAR-10 – 建模、构建和训练
- en: This example shows how to make a CNN for classifying images in the CIFAR-10
    dataset. We'll be using a simple convolution neural network implementation of
    a couple of convolutions and fully connected layers.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例展示了如何在CIFAR-10数据集中制作用于分类图像的CNN。我们将使用一个简单的卷积神经网络实现一些卷积和全连接层。
- en: Even though the network architecture is very simple, you will see how well it
    performs when trying to detect objects in the CIFAR-10 images.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 即使网络架构非常简单，当尝试检测 CIFAR-10 图像中的对象时，您会看到它表现得有多好。
- en: So, let's start off this implementation.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们开始这个实现。
- en: Used packages
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的包
- en: 'We import all the required packages for this implementation:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们导入了此实现所需的所有包：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Loading the CIFAR-10 dataset
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 载入 CIFAR-10 数据集
- en: 'In this implementation, we''ll use CIFAR-10, which is one of the most widely
    used datasets for object detection. So, let''s start off by defining a helper
    class to download and extract the CIFAR-10 dataset, if it''s not already downloaded:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实现中，我们将使用 CIFAR-10 数据集，这是用于对象检测的最常用的数据集之一。因此，让我们先定义一个辅助类来下载和提取 CIFAR-10 数据集（如果尚未下载）：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After downloading and extracting the CIFAR-10 dataset, you will find out that
    it''s already split into five batches. CIFAR-10 contains images for 10 categories/classes:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 下载并提取 CIFAR-10 数据集后，您会发现它已经分成了五个批次。CIFAR-10 包含了 10 个类别的图像：
- en: '`airplane`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`airplane`'
- en: '`automobile`'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`automobile`'
- en: '`bird`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bird`'
- en: '`cat`'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cat`'
- en: '`deer`'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deer`'
- en: '`dog`'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dog`'
- en: '`frog`'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`frog`'
- en: '`horse`'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`horse`'
- en: '`ship`'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ship`'
- en: '`truck`'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`truck`'
- en: Before we dive into building the core of the network, let's do some data analysis
    and preprocessing.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入构建网络核心之前，让我们进行一些数据分析和预处理。
- en: Data analysis and preprocessing
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据分析和预处理
- en: 'We need to analyze the dataset and do some basic preprocessing. So, let''s
    start off by defining some helper functions that will enable us to load a specific
    batch from the five batches that we have and print some analysis about this batch
    and its samples:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要分析数据集并进行一些基本的预处理。因此，让我们首先定义一些辅助函数，这些函数将使我们能够从我们有的五批次中加载特定批次，并打印关于此批次及其样本的一些分析：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, we define a function that can help us display the stats of a specific
    sample from a specific batch:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们定义一个函数，可以帮助我们显示特定批次中特定样本的统计信息：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, we can use this function to play around with our dataset and visualize
    specific images:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用这个函数来操作我们的数据集，并可视化特定的图像：
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output is as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](img/ae827baa-2394-4eaf-93cd-018a7ae7b8a1.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ae827baa-2394-4eaf-93cd-018a7ae7b8a1.png)'
- en: 'Figure 11.2: Sample image 6 from batch 3'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '图 11.2: 来自第 3 批次的样本图像 6'
- en: Before going ahead and feeding our dataset to the model, we need to normalize
    it to the range of zero to one.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续将数据集馈送到模型之前，我们需要将其归一化到零到一的范围内。
- en: 'Batch normalization optimizes network training. It has been shown to have several
    benefits:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 批归一化优化了网络训练。已经显示它有几个好处：
- en: '**Faster training**: Each training step will be slower because of the extra
    calculations during the forward pass of the network and the additional hyperparameters
    to train during backward propagation passes of the network. However, it should
    converge much more quickly, so training should be faster overall.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练更快**：每个训练步骤会变慢，因为在网络的前向传播过程中需要额外的计算，在网络的反向传播过程中需要训练额外的超参数。然而，它应该会更快地收敛，因此总体训练速度应该更快。'
- en: '**Higher learning rates**: The gradient descent algorithm mostly requires small
    learning rates for the network to converge to the loss function''s minima. And
    as the neural networks get deeper, their gradient values get smaller and smaller
    during backpropagation, so they usually require even more iterations. Using the
    idea of batch normalization allows us to use much higher learning rates, which
    further increases the speed at which networks train.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更高的学习率**：梯度下降算法通常需要较小的学习率才能使网络收敛到损失函数的最小值。随着神经网络变得更深，它们在反向传播过程中的梯度值会变得越来越小，因此通常需要更多的迭代次数。使用批归一化的想法允许我们使用更高的学习率，这进一步增加了网络训练的速度。'
- en: '**Easy to initialize weights**: Weight initialization can be difficult, and
    it will be even more difficult if we are using deep neural networks. Batch normalization
    seems to allow us to be much less careful about choosing our initial starting
    weights.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**权重初始化简单**: 权重初始化可能会很困难，特别是在使用深度神经网络时。批归一化似乎使我们在选择初始权重时可以更不谨慎。'
- en: 'So, let''s proceed by defining a function that will be responsible for normalizing
    a list of input images so that all the pixel values of these images are between
    zero and one:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们继续定义一个函数，该函数将负责将输入图像列表归一化，以便这些图像的所有像素值都在零到一之间。
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Next up, we need to implement another helper function to encode the labels of
    the input image. In this function, we will use one-hot encoding of sklearn, where
    each image label is represented by a vector of zeros except for the class index
    of the image that this vector represents.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要实现另一个辅助函数，对输入图像的标签进行编码。在这个函数中，我们将使用 sklearn 的独热编码（one-hot encoding），其中每个图像标签通过一个零向量表示，除了该向量所代表的图像的类别索引。
- en: 'The size of the output vector will be dependent on the number of classes that
    we have in the dataset, which is 10 classes in the case of CIFAR-10 data:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 输出向量的大小将取决于数据集中的类别数量，对于 CIFAR-10 数据集来说是10个类别：
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, it''s time to call the preceding helper functions to do the preprocessing
    and persist the dataset so that we can use it later:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候调用之前的辅助函数进行预处理并保存数据集，以便我们以后可以使用它了：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: So, we have the preprocessed data saved to disk.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经将预处理数据保存到磁盘。
- en: 'We also need to load the validation set for running the trained model on it
    at different epochs of the training process:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要加载验证集，以便在训练过程的不同 epoch 上运行训练好的模型：
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Building the network
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建网络
- en: It's now time to build the core of our classification application, which is
    the computational graph of this CNN architecture, but to maximize the benefits
    of this implementation, we aren't going to use the TensorFlow layers API. Instead,
    we are going to use the TensorFlow neural network version of it.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候构建我们分类应用程序的核心，即 CNN 架构的计算图了，但为了最大化该实现的优势，我们不会使用 TensorFlow 层 API，而是将使用它的神经网络版本。
- en: 'So, let''s start off by defining the model input placeholders which will input
    the images, target classes, and the keep probability parameter of the dropout
    layer (this helps us to reduce the complexity of the architecture by dropping
    some connections and hence reducing the chances of overfitting):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们从定义模型输入占位符开始，这些占位符将输入图像、目标类别以及 dropout 层的保留概率参数（这有助于我们通过丢弃一些连接来减少架构的复杂性，从而减少过拟合的几率）：
- en: '[PRE10]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next up, we need to use the TensorFlow neural network implementation version
    to build up our convolution layers with max pooling:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要使用 TensorFlow 神经网络实现版本来构建我们的卷积层，并进行最大池化：
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As you have probably seen in the previous chapter, the output of the max pooling
    operation is a 4D tensor, which is not compatible with the required input format
    for the fully connected layers. So, we need to implement a flattened layer to
    convert the output of the max pooling layer from 4D to 2D tensor:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能在前一章中看到的，最大池化操作的输出是一个4D张量，这与全连接层所需的输入格式不兼容。因此，我们需要实现一个展平层，将最大池化层的输出从4D转换为2D张量：
- en: '[PRE12]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Next up, we need to define a helper function that will enable us to add a fully
    connected layer to our architecture:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要定义一个辅助函数，允许我们向架构中添加一个全连接层：
- en: '[PRE13]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Finally, before using these helper functions to create the entire architecture,
    we need to create another one that will take the output of the fully connected
    layer and produce 10 real-valued corresponding to the number of classes that we
    have in the dataset:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在使用这些辅助函数创建整个架构之前，我们需要创建另一个函数，它将接收全连接层的输出并产生10个实值，对应于我们数据集中类别的数量：
- en: '[PRE14]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'So, let''s go ahead and define the function that will put all these bits and
    pieces together and create a CNN with three convolution layers. Each one of them
    is followed by max pooling operations. We''ll also have two fully connected layers,
    where each one of them is followed by a dropout layer to reduce the model complexity
    and prevent overfitting. Finally, we''ll have the output layer to produce 10 real-valued
    vectors, where each value represents a score for each class being the correct
    one:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们定义一个函数，把所有这些部分组合起来，创建一个具有三个卷积层的 CNN。每个卷积层后面都会跟随一个最大池化操作。我们还会有两个全连接层，每个全连接层后面都会跟一个
    dropout 层，以减少模型复杂性并防止过拟合。最后，我们将有一个输出层，产生10个实值向量，每个值代表每个类别的得分，表示哪个类别是正确的：
- en: '[PRE15]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s call the preceding helper functions to build the network and define
    its loss and optimization criteria:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们调用之前的辅助函数来构建网络并定义它的损失和优化标准：
- en: '[PRE16]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now that we have built the computational architecture of this network, it's
    time to kick off the training process and see some results.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经构建了该网络的计算架构，是时候启动训练过程并查看一些结果了。
- en: Model training
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练
- en: 'So, let''s define a helper function that will make us able to kick off the
    training process. This function will take the input images, one-hot encoding of
    the target classes, and the keep probability value as input. Then, it will feed
    these values to the computational graph and call the model optimizer:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们定义一个辅助函数，使我们能够启动训练过程。这个函数将接受输入图像、目标类别的独热编码以及保持概率值作为输入。然后，它将把这些值传递给计算图，并调用模型优化器：
- en: '[PRE17]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We''ll need to validate our model during different time steps in the training
    process, so we are going to define a helper function that will print out the accuracy
    of the model on the validation set:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在训练过程中的不同时间点验证模型，因此我们将定义一个辅助函数，打印出模型在验证集上的准确率：
- en: '[PRE18]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s also define the model hyperparameters, which we can use to tune the
    model for better performance:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们还定义一些模型的超参数，这些参数可以帮助我们调整模型以获得更好的性能：
- en: '[PRE19]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now, let's kick off the training process, but only for a single batch of the
    CIFAR-10 dataset, and see what the model accuracy based on this batch is.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们启动训练过程，但只针对CIFAR-10数据集的单一批次，看看基于该批次的模型准确率。
- en: 'Before that, however, we are going to define a helper function that will load
    a batch training and also separate the input images from the target classes:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在此之前，我们将定义一个辅助函数，加载一个批次的训练数据，并将输入图像与目标类别分开：
- en: '[PRE20]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, let''s start the training process for one batch:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始一个批次的训练过程：
- en: '[PRE21]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'As you can see, the validation accuracy is not that good while training only
    on a single batch. Let''s see how the validation accuracy is going to change based
    on only a full training process of the model:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，仅在单一批次上训练时，验证准确率并不高。让我们看看仅通过完整训练过程，验证准确率会如何变化：
- en: '[PRE22]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Testing the model
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试模型
- en: 'Let''s test the trained model against the test set part of the CIFAR-10 dataset.
    First, we are going to define a helper function that will help us to visualize
    the predictions of some sample images and their corresponding true labels:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在CIFAR-10数据集的测试集部分上测试训练好的模型。首先，我们将定义一个辅助函数，帮助我们可视化一些示例图像的预测结果及其对应的真实标签：
- en: '[PRE23]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, let''s restore the trained model and test it against the test set:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们恢复训练好的模型并对测试集进行测试：
- en: '[PRE24]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](img/fc105794-646e-4a0a-8fe0-c7c432a1ccca.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fc105794-646e-4a0a-8fe0-c7c432a1ccca.png)'
- en: 'Let''s visualize another example to see some errors:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们可视化另一个例子，看看一些错误：
- en: '![](img/ee5f68c7-4a4e-40f9-9009-a78465f6559e.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee5f68c7-4a4e-40f9-9009-a78465f6559e.png)'
- en: Now, we have a test accuracy of around 75%, which is not bad for a simple CNN
    like the one we have used.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的测试准确率大约为75%，对于像我们使用的简单CNN来说，这并不算差。
- en: Summary
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter showed us how to make a CNN for classifying images in the CIFAR-10
    dataset. The classification accuracy was about 79% - 80% on the test set. The
    output of the convolutional layers was also plotted, but it was difficult to see
    how the neural network recognizes and classifies the input images. Better visualization
    techniques are needed.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 本章向我们展示了如何制作一个CNN来分类CIFAR-10数据集中的图像。测试集上的分类准确率约为79% - 80%。卷积层的输出也被绘制出来，但很难看出神经网络是如何识别和分类输入图像的。需要更好的可视化技术。
- en: Next up, we'll use one of the modern and exciting practice of deep learning,
    which is transfer learning. Transfer learning allows you to use data-greedy architectures
    of deep learning with small datasets.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用深度学习中的一种现代且激动人心的实践方法——迁移学习。迁移学习使你能够使用深度学习中的数据需求大的架构，适用于小型数据集。
