- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Interpreting Neural Networks
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解读神经网络
- en: When trying to comprehend the reasons behind a model’s prediction, local per-sample
    feature importance can be a valuable tool. This method enables you to focus your
    analysis on a smaller part of the input data, resulting in a more targeted understanding
    of key features that contributed to the model’s output. However, it is often still
    unclear which patterns the models are using to identify highly important features.
    This issue can be somewhat circumvented by reviewing more prediction explanations
    from targeted samples meant to strategically discern the actual reason for the
    prediction, which will also be introduced practically later in this chapter. However,
    this method is limited to the available number of samples you must validate your
    model against, and it can sometimes still be difficult to pinpoint the pattern
    used concretely.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试理解模型预测背后的原因时，局部单样本特征重要性可以是一个有价值的工具。此方法使你能够将分析重点集中在输入数据的较小部分，从而更有针对性地理解对模型输出起到重要作用的关键特征。然而，通常仍然不清楚模型使用了哪些模式来识别高度重要的特征。通过回顾来自目标样本的更多预测解释，战略性地辨别预测的实际原因，某种程度上可以规避这一问题，实际操作部分将在本章稍后介绍。然而，这种方法受到必须验证的样本数量的限制，有时仍然很难明确指出具体使用的模式。
- en: '**Deep neural networks** (**DNNs**) learn low- to high-level features that
    help the prediction layer discern the right label under the hood. When we use
    local feature importance-based explanations on the input, we can’t know for sure
    which low-, medium-, or high-level patterns contributed to the importance of the
    input data. For images, this would range from low-level features, such as simple
    shapes, to medium-level features, such as the silhouette shape of a human body,
    all the way to a combination of patterns that build up to become a human face
    or everyday objects. For text, this would range from low-level features such as
    word embeddings, which represent the meaning of a word, to medium-level features
    such as the semantic roles of words in a sentence that enable the meaning of the
    text to be represented properly such as sentence embeddings, all the way to high-level
    features we are more familiar with, such as topics and sentiment. Of course, these
    are merely theoretical assumptions on what we think NNs are learning.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**深度神经网络**（**DNNs**）学习低层到高层特征，帮助预测层在幕后辨识正确的标签。当我们在输入数据上使用基于局部特征重要性的解释时，我们无法确定到底是哪些低、中或高层的模式对输入数据的特征重要性做出了贡献。对于图像，这些特征从低层的简单形状到中层的人的轮廓形状，再到逐步组合成一个人的面孔或日常物品的模式。对于文本，这些特征从低层的词嵌入（表示单词的意义）到中层的语义角色（如句子中的单词角色，帮助正确表示文本意义的句子嵌入），一直到我们更熟悉的高层特征，如主题和情感。当然，这些只是我们对神经网络学习内容的理论假设。'
- en: 'In this chapter, we will explore a method that can help to clear all the ambiguity
    in the features learned by a deep neural network, which is to visualize the patterns
    an NN detects directly through input optimization. By visualizing the patterns
    learned directly in combination with the filtering of activations, we can shed
    light on the actual reasons a deep neural network makes its predictions. Specifically,
    the following topics will be discussed:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨一种方法，帮助清除深度神经网络学习特征中的所有模糊性，即通过输入优化直接可视化神经网络所检测到的模式。通过将直接学习的模式与激活过滤相结合进行可视化，我们可以揭示深度神经网络做出预测的实际原因。具体来说，本章将讨论以下主题：
- en: Interpreting neurons
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解读神经元
- en: Finding neurons to interpret
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找可解读的神经元
- en: Interpreting learned image patterns
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解读学习到的图像模式
- en: Discovering the counterfactual explanation strategy
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现反事实解释策略
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter includes practical implementation in the Python programming language.
    To complete it, you will need to have a computer with the following libraries
    installed:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包括在Python编程语言中的实际实现。为完成本章，你需要一台已安装以下库的计算机：
- en: '`torchvision`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torchvision`'
- en: '`torch`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch`'
- en: '`torch-lucent==0.1.8`'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch-lucent==0.1.8`'
- en: '`matplotlib==3.3.0`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`matplotlib==3.3.0`'
- en: '`captum`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`captum`'
- en: '`pillow`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pillow`'
- en: '`numpy`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy`'
- en: 'The code files are present on GitHub: [https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_12](https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_12).'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 代码文件可以在GitHub上找到：[https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_12](https://github.com/PacktPublishing/The-Deep-Learning-Architect-Handbook/tree/main/CHAPTER_12)。
- en: Interpreting neurons
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释神经元
- en: Neurons in NN layers produce features that will be consumed by subsequent layers.
    The features or activations produced are simply an indicator of how prominent
    a learned pattern is in the input data. But have you ever wondered what the patterns
    are? Decoding the actual patterns learned by the NN can further improve the transparency
    needed to achieve the goals mentioned in the *Exploring the value of prediction
    explanations* section of [*Chapter 11*](B18187_11.xhtml#_idTextAnchor172), *Explaining
    Neural* *Network Predictions*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络层中的神经元产生的特征将被后续层使用。这些产生的特征或激活值仅仅是学习到的模式在输入数据中显著性的一个指示。但你是否曾经想过这些模式是什么？解码神经网络实际学习到的模式可以进一步提高透明度，从而帮助实现[*第11章*](B18187_11.xhtml#_idTextAnchor172)中*探索预测解释的价值*部分提到的目标，*解释神经网络预测*。
- en: Data is composed of many complicated patterns combined into a single sample.
    Traditionally, to discern what a neuron is detecting, much input data has to be
    evaluated and compared against other data so that a qualitative conclusion can
    be made by humans, which is both time-consuming and hard to get right. This method
    allows us to pinpoint the actual pattern that causes a high activation value visually,
    without the disturbance of other highly correlated patterns.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 数据由许多复杂的模式组合成单一样本。传统上，为了辨识神经元在检测什么，必须评估大量输入数据并与其他数据进行比较，以便由人类得出定性的结论，这既耗时又很难做到准确。该方法使我们能够直观地
    pinpoint 产生高激活值的实际模式，而不受其他高度相关模式的干扰。
- en: 'More formally, feature visualization by optimization can be useful in the following
    use cases:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地说，通过优化进行的特征可视化在以下用例中是有用的：
- en: 'Understanding the patterns associated with confusing labels without help from
    a domain expert:'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解与混淆标签相关的模式，而无需领域专家的帮助：
- en: This is more prevalent in real-world audio data where the sound of the label
    in the real data can often be mixed together with lots of noises
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这种情况在真实世界的音频数据中更为常见，在这些数据中，标签的声音常常与大量噪声混合在一起
- en: This can also happen in image data
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这也可能发生在图像数据中
- en: It is not straightforward or possible to obtain real data to test any hypothesis
    on what the NN learned that can’t be proven with gradient-based feature attribution
    techniques on available data
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 直接获取真实数据来测试关于神经网络学习内容的任何假设并非易事，且无法通过基于梯度的特征归因技术在可用数据上得到证明。
- en: The core of the neuron interpretation technique is **neural input optimization**,
    which is a process that modifies the input data of the NN to activate highly on
    the chosen neuron. Remember that during the training process, we optimize the
    weights of the NNs toward reducing the loss value. In this technique, we randomly
    initialize an input and optimize the input data to activate highly on chosen neurons,
    effectively treating the input data as NN weights. Gradients can be naturally
    computed to the input data stage, making it possible to update the input data
    according to the computed gradients after applying a learning rate. This technique
    also allows you to jointly optimize multiple neurons to activate highly and obtain
    an image that shows the patterns of how two different neurons can coexist.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 神经元解释技术的核心是**神经输入优化**，这是一种修改神经网络输入数据的过程，目的是使其在选择的神经元上产生高度激活。记住，在训练过程中，我们优化神经网络的权重以减少损失值。在这种技术中，我们随机初始化一个输入并优化该输入数据，使其在选定的神经元上产生高度激活，实际上将输入数据视为神经网络的权重。梯度可以自然地计算到输入数据阶段，使得在应用学习率后，可以根据计算的梯度更新输入数据。该技术还允许你联合优化多个神经元，使它们同时高度激活，并获得一张展示两种不同神经元如何共存的图像。
- en: '*Figure 12**.1* showcases the idea of low-level to medium-level and high-level
    patterns in `efficientnet-b0` model:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*图12.1*展示了`efficientnet-b0`模型中从低级到中级和高级模式的概念：'
- en: '![Figure 12.1 – Example of optimized images from random filters in the efficientnet-b0
    model](img/B18187_12_1.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图12.1 – 来自efficientnet-b0模型的随机滤波器优化图像示例](img/B18187_12_1.jpg)'
- en: Figure 12.1 – Example of optimized images from random filters in the efficientnet-b0
    model
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.1 – 来自efficientnet-b0模型的随机滤波器优化图像示例
- en: If you look at the high-level filter patterns, the first optimized image on
    a random filter looks somewhat like flowers, and the second image looks like leaf
    patterns.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你观察高层次的滤波器模式，第一个在随机滤波器上的优化图像看起来有点像花朵，第二个图像则像叶子图案。
- en: However, a main caveat with this technique is that the resulting optimized input
    data may not represent all the real-life variations of a pattern associated with
    a neuron. Even for a dynamic input data variable such as an image, which can be
    optimized to present the pattern in diverse ways, the resulting optimized input
    can still miss out on some representations of the pattern. A good approach to
    tackle this caveat is to first obtain the initial optimized input data variant
    and then execute subsequent optimizations and ensure the optimized input data
    will be different from the initial variant. This can be done by jointly optimizing
    an additional component – the negative cosine similarity between the initial optimized
    input data and the current input data being optimized. This technique helps to
    generate diverse input data examples. But before you can optimize the input data
    and attempt to interpret a neuron, you need a strategy to choose the best neurons
    to optimize input data against, which will be discussed in the next section.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种技术的一个主要警告是，得到的优化输入数据可能并不能代表与神经元相关的模式的所有真实变化。即使是像图像这样的动态输入数据变量，也可以被优化以多种方式展示模式，但最终的优化输入仍然可能会遗漏一些模式的表现。解决这个警告的一个好方法是，首先获得初始的优化输入数据变体，然后执行后续优化，并确保优化后的输入数据与初始变体不同。这可以通过联合优化一个额外的组件——即初始优化输入数据与当前优化输入数据之间的负余弦相似度来实现。这一技术有助于生成多样化的输入数据示例。但在你能够优化输入数据并尝试解释神经元之前，你需要一个策略来选择最佳的神经元进行输入数据优化，这将在下一节中讨论。
- en: Finding neurons to interpret
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查找需要解释的神经元
- en: 'With millions and billions of neurons in today’s SoTA architectures, it’s impossible
    to interpret every single neuron, and, frankly, a waste of time. The choice of
    the neuron to explain should depend on your goal. The following list shows some
    of the different goals and associated methods for choosing suitable neurons:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在当今的最先进架构中，拥有数百万甚至数十亿个神经元，解释每一个神经元是不可行的，坦率来说，这也是浪费时间。选择要解释的神经元应根据你的目标来决定。以下列表展示了一些不同的目标和选择合适神经元的相关方法：
- en: '**Finding out what a certain prediction label or class pattern looks like**:
    In this case, you should simply choose a neuron specific to the prediction of
    the target label or class. This is usually done to understand whether the model
    captured the desired patterns of the class well, or whether it learned irrelevant
    features. This can also be useful in multilabel scenarios where multiple labels
    always only exist together, and you want to decouple the labels to understand
    the input patterns associated with a single label better.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**找出某个预测标签或类别模式的样子**：在这种情况下，你应该简单地选择一个特定的神经元，用于预测目标标签或类别。这通常是为了理解模型是否很好地捕捉了该类别的模式，或者它是否学习到了无关的特征。在多标签场景中，多个标签总是一起存在，你希望解耦这些标签，从而更好地理解与单一标签相关的输入模式，这时这也会很有用。'
- en: '**Wanting to understand the latent reasons why a specific label can be predicted
    in your dataset, or for all labels in general**: In this case, you should choose
    the top most impactful neurons from the latent intermediate layers from a global
    neuron importance score. Global neuron importance can be obtained by aggregating
    the results of the integrated gradients method (introduced in [*Chapter 11*](B18187_11.xhtml#_idTextAnchor172),
    *Explaining Neural Network Predictions*) applied to your validation dataset for
    all neurons. The importance values for all neurons can then be ranked, and the
    top neurons can be picked.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**想要理解在数据集中为什么某个特定标签可以被预测，或者一般而言所有标签的潜在原因**：在这种情况下，你应该从全局神经元重要性评分中选择潜在中间层中最具影响力的神经元。全局神经元重要性可以通过聚合集成梯度方法的结果来获得，该方法应用于你验证数据集中的所有神经元（此方法在[*第11章*](B18187_11.xhtml#_idTextAnchor172)，*解释神经网络预测*中有介绍）。然后可以对所有神经元的影响值进行排名，并挑选出最重要的神经元。'
- en: '**Finding out the breakdown reasons why a prediction was made on top of saliency-based
    explanation techniques**: In this case, you should choose the neuron that has
    the highest activation value and highest importance score. A neuron that is activated
    highly does not necessarily mean that it is important for a certain prediction.
    Additionally, a neuron that is important does not mean that the neuron is activated.
    Using both the integrated gradients’ importance value and the activation values
    to obtain the most important neuron will help to make sure the neurons you care
    about are chosen. Additionally, you can further filter out more neurons if you
    have a focus area based on the initial input data saliency map by only choosing
    neurons that affect the chosen focus area.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**找出基于显著性解释技术的预测原因的细分理由**：在这种情况下，您应选择具有最高激活值和最高重要性得分的神经元。高度激活的神经元并不一定意味着它对某种预测很重要。此外，重要的神经元并不意味着该神经元被激活。利用整合梯度的重要性值和激活值来获取最重要的神经元将有助于确保选择您关心的神经元。此外，如果基于初始输入数据显著性地图有一个关注区域，您可以进一步通过仅选择影响所选关注区域的神经元来过滤出更多神经元。'
- en: '**Understanding the interactions between multiple labels or classes**: In scenarios
    where the relationships between multiple labels or classes are important, you
    can choose neurons that capture these interactions. Identify neurons that are
    highly activated and have high importance scores when multiple labels or classes
    are predicted together. Analyzing these neurons can help you understand how the
    model captures the relationships between different labels or classes and may reveal
    potential areas for improvement.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**理解多个标签或类别之间的相互作用**：在关注多个标签或类别之间的关系重要的情况下，您可以选择捕捉这些相互作用的神经元。识别在预测多个标签或类别时激活度高且重要性得分高的神经元。分析这些神经元可以帮助您理解模型如何捕捉不同标签或类别之间的关系，并可能揭示改进的潜在领域。'
- en: '**Investigating the robustness of the model to adversarial attacks**: In this
    case, you should choose neurons that are sensitive to adversarial perturbations
    in the input data. You can generate adversarial examples, with more info on how
    to do so in [*Chapter 14*](B18187_14.xhtml#_idTextAnchor206), *Analyzing Adversarial
    Performance*, and then compute the neuron importance scores using techniques such
    as integrated gradients. By visualizing neurons that are most affected by adversarial
    perturbations, you can gain insights into the model’s vulnerabilities and explore
    potential defenses.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**研究模型对抗性攻击的稳健性**：在这种情况下，您应选择对输入数据的对抗性扰动敏感的神经元。您可以生成对抗性示例，有关如何操作请参见[*第14章*](B18187_14.xhtml#_idTextAnchor206)，*分析对抗性能*，然后使用整合梯度等技术计算神经元的重要性得分。通过可视化受对抗性扰动影响最大的神经元，您可以深入了解模型的脆弱性并探索潜在的防御措施。'
- en: '**Exploring the hierarchical structure of learned features**: In this case,
    you should choose neurons from different layers of the NN to understand how the
    model learns hierarchical features. Select neurons from early layers to investigate
    low-level features, and from deeper layers to investigate high-level features.
    You can also select multiple neurons to co-optimize the input data for high activation
    to understand how multiple-neuron learned patterns can exist in the same input
    data. Visualizing these neurons can help you understand the model’s internal representation
    of the data and how it builds increasingly complex features. This can provide
    insights into the model’s learning process and potential areas for improvement.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**探索学习特征的分层结构**：在这种情况下，您应选择来自NN不同层的神经元，以理解模型如何学习分层特征。选择早期层的神经元以研究低级特征，选择更深层次的神经元以研究高级特征。您还可以选择多个神经元以协同优化输入数据以获得高激活，以了解同一输入数据中多神经元学习模式的存在方式。可视化这些神经元可以帮助您理解模型对数据的内部表示及其如何构建越来越复杂的特征。这可以提供关于模型学习过程及其改进潜力领域的见解。'
- en: '**Analyzing the model’s generalization capabilities across different datasets**:
    To understand how well the model generalizes to new data, you should choose neurons
    that are consistently important across different datasets. Calculate the neuron
    importance scores using techniques such as integrated gradients for different
    datasets, and identify neurons that maintain high importance scores across all
    datasets. By visualizing these neurons, you can gain insights into the model’s
    generalization capabilities and identify potential areas for improvement.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分析模型在不同数据集上的泛化能力**：为了了解模型在新数据上的泛化能力，应该选择在不同数据集上始终重要的神经元。使用集成梯度等技术计算不同数据集上的神经元重要性得分，并识别在所有数据集上保持高重要性得分的神经元。通过可视化这些神经元，你可以深入了解模型的泛化能力，并发现潜在的改进领域。'
- en: Now that we’ve established the method to choose a neuron for interpretation,
    let’s start with a practical exploration of interpreting neurons with image input
    data!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了选择神经元进行解释的方法，让我们从实际的角度开始探索如何用图像输入数据解释神经元！
- en: Interpreting learned image patterns
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释学习到的图像模式
- en: Interpreting NNs that take in image data enables a new paradigm in interpretation,
    which is the capability to visualize exactly what a neuron is detecting. In the
    case of audio input data, interpreting NNs would allow us to audibly represent
    what a neuron is detecting, similar to how we visualize patterns in image data!
    Choose neurons you want to understand based on your goal and visualize the patterns
    it is detecting through iterative optimizing on image data to activate highly
    for that neuron.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 解释接收图像数据的神经网络（NN）开启了解释的新范式，即可视化神经元正在检测的内容。以音频输入数据为例，解释神经网络可以使我们听到神经元检测到的内容，类似于我们在图像数据中可视化模式的方式！根据你的目标选择你想理解的神经元，并通过对图像数据的迭代优化，激活该神经元以可视化它检测到的模式。
- en: Practically, however, optimizing image data based on a neuron has an issue where
    the resulting image often produces high-frequency patterns that are perceived
    to be noisy, uninterpretable, and unaesthetic. High-frequency patterns are defined
    to be pixels that are high in intensity and change quickly from one to the next.
    This is largely due to the mostly unconstrained range of values that a pixel can
    be represented by, and pixels in isolation are not the semantic units we care
    about. Zooming in on the resulting image might make it more interpretable, but
    the interpretation effectiveness is diminished with the need to perform human
    evaluation and extra work.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，实际上，基于神经元优化图像数据时，存在一个问题，即生成的图像通常会产生被认为是噪声、不可解释且不美观的高频模式。高频模式被定义为那些强度较高且变化迅速的像素。这主要是由于像素可以表示的值范围通常没有约束，而且单独的像素并不是我们关心的语义单元。放大生成的图像可能会使其更具可解释性，但解释效果会因为需要进行人工评估和额外工作而降低。
- en: 'This issue can be effectively mitigated practically through the following techniques:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题可以通过以下技术有效缓解：
- en: 'Frequency penalization – example techniques are as follows:'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 频率惩罚 – 示例技术如下：
- en: Randomly blurring the image during optimization using a bilateral filter, which
    has the benefit of also preserving edge patterns
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在优化过程中随机使用双边滤波器对图像进行模糊处理，这样做的好处是还能保留边缘模式
- en: Penalizing variation between neighboring pixels conservatively in the optimization
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在优化过程中保守地惩罚相邻像素之间的变化
- en: Image augmentations
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像增强
- en: 'Image preprocessing – example techniques are as follows:'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像预处理 – 示例技术如下：
- en: Data decorrelation
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据去相关
- en: Fast Fourier transform
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速傅里叶变换
- en: Let’s continue our journey here by going through a practical tutorial using
    a pre-trained 121-layer densenet model on the ImageNet dataset.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用在 ImageNet 数据集上预训练的 121 层 densenet 模型，继续我们的学习之旅。
- en: Explaining predictions with image input data and integrated gradients
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用图像输入数据和集成梯度来解释预测结果
- en: 'In this section, we will explorepredictions, explaining withpredictions, explaining
    with a practical tutorial on explaining predictions from a CNN model that takes
    in image input data with integrated gradients, providing some insight into the
    reasons the model made its prediction. In this tutorial, we will discover what
    answers we need that are missing from prediction explanations, which will set
    us up for interpreting the CNN model. We’ll proceed as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨预测，并通过一个实际教程来解释如何解释CNN模型的预测，该模型接受带有集成梯度的图像输入数据，并提供一些对模型做出预测的原因的见解。在本教程中，我们将发现预测解释中缺失的必要答案，这将为我们理解CNN模型提供帮助。我们将按以下步骤进行：
- en: 'We will be using the `lucent` library for this tutorial, which provides methods
    to interpret NNs through feature visualization by optimization. Additionally,
    we will be using the `torch` library for the densenet model. We will also be using
    the `captum` library to use the integrated gradients method. Let’s start by importing
    all the necessary libraries:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本教程中，我们将使用`lucent`库，它提供了通过优化特征可视化来解释神经网络的方法。此外，我们还将使用`torch`库来处理densenet模型。我们还将使用`captum`库来使用集成梯度方法。让我们从导入所有必要的库开始：
- en: '[PRE0]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we will define the model class for the pre-trained densenet model that
    we will use:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将定义一个预训练的densenet模型的类：
- en: '[PRE1]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will be using the defined model class to load weights pre-trained on an
    image dataset called `HAM10000` with seven different skin lesion classes:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用定义好的模型类加载一个名为`HAM10000`的图像数据集上预训练的权重，该数据集包含七种不同的皮肤病变类别：
- en: '[PRE2]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The seventh index of the prediction layer of the pre-trained model is trained
    to predict melanoma, which is a type of skin cancer. Let’s take a look at a few
    examples of melanoma from the `ISIC-2017` dataset and see what exactly the pre-trained
    model is focusing on when predicting these images. We will be using the integrated
    gradients method from the `captum` library. First, let’s define the preprocessing
    needed to allow model inferencing, which converts a `numpy` image array into `torch`
    tensors, resizes the image into the pre-trained image size, and normalizes it:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预训练模型的预测层的第七个索引被训练用于预测黑色素瘤，这是一种皮肤癌。让我们看看`ISIC-2017`数据集中的一些黑色素瘤示例，并看看当预测这些图像时，预训练模型到底关注了什么。我们将使用`captum`库中的集成梯度方法。首先，让我们定义需要的预处理步骤，以便进行模型推理，这将把`numpy`图像数组转换为`torch`张量，调整图像大小为预训练的图像尺寸，并进行归一化：
- en: '[PRE3]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The mean and standard deviation values are derived directly from the ImageNet
    dataset and were used to pre-train the model, as prior to pre-training on the
    `HAM10000` dataset, it was pre-trained on ImageNet. Additionally, the `224` dimension
    is also adopted from the ImageNet pre-trained settings. As we need the intermediate
    result after resizing separately, we defined the logic for resizing and normalization
    separately.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 均值和标准差值直接来自ImageNet数据集，并用于预训练模型，因为在`HAM10000`数据集上预训练之前，它已在ImageNet上进行过预训练。此外，`224`的维度也来自于ImageNet预训练设置。由于我们需要在调整大小后的中间结果，因此我们单独定义了调整大小和归一化的逻辑。
- en: 'Next, we will use the `glob` library to load all the melanoma images in the
    provided dataset folder:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将使用`glob`库加载提供的数据集文件夹中的所有黑色素瘤图像：
- en: '[PRE4]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We will be using the `captum` library implementation of integrated gradients
    and noise tunneling to smooth out the resulting attribution noise. Let’s define
    the instances needed to execute these components, along with defining the prediction
    class index for the `Melanoma` target class that we are interested in:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`captum`库实现的集成梯度和噪声隧道方法，以平滑结果中的归因噪声。让我们定义执行这些组件所需的实例，并定义我们感兴趣的`黑色素瘤`目标类的预测类索引：
- en: '[PRE5]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We can now loop through the first six images, apply the preprocessing, apply
    the integrated gradients method from `captum`, and finally, visualize the original
    image and the obtained input importance heat map:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以遍历前六张图像，应用预处理，使用`captum`中的集成梯度方法，并最终可视化原始图像和获得的输入重要性热力图：
- en: '[PRE6]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This will show visualizations presented in *Figure 12**.2*:'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将展示在*图12.2*中呈现的可视化结果：
- en: '![Figure 12.2 – Six real images of melanoma from the ISIC-2017 dataset along
    with the gradient-based attribution of the model](img/B18187_12_2.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图12.2 - 来自ISIC-2017数据集的六张真实黑色素瘤图像及模型的基于梯度的归因](img/B18187_12_2.jpg)'
- en: Figure 12.2 – Six real images of melanoma from the ISIC-2017 dataset along with
    the gradient-based attribution of the model
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2 – 来自ISIC-2017数据集的六张真实黑色素瘤图像，以及模型的基于梯度的归因
- en: 'The model seems to be mainly focusing on the darker spots in the first five
    examples, but the model still considers the surrounding skin, although with much
    less focus. This might be a signal that the model can depend on the surrounding
    skin slightly to predict melanoma. But this begs the question: Is the model identifying
    the darkness of the skin for melanoma, or is it identifying some sort of pattern
    under the hood, or is it both? For the last example, the model seems to be all
    over the place and not really focusing on the dark spots. This could mean that
    the skin has patterns that are related to melanoma that are not necessarily darker
    in color. There are a few more questions that can’t really be answered through
    these examples, which are as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在前五个例子中，模型似乎主要集中在较暗的斑点上，但它仍然会考虑周围的皮肤，尽管关注度较低。这可能表明模型在一定程度上依赖周围皮肤来预测黑色素瘤。但这也引发了一个问题：模型是在根据皮肤的暗度来预测黑色素瘤，还是在识别某种模式，还是两者兼有？在最后一个例子中，模型似乎没有特别集中，且并没有真正关注那些暗斑。这可能意味着皮肤有一些与黑色素瘤相关的模式，这些模式未必是颜色较深的。还有一些问题通过这些例子无法真正解答，具体如下：
- en: Is the model dependent on the color of the skin to predict melanoma? Or is it
    really about the pattern?
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个模型是否依赖皮肤颜色来预测黑色素瘤？还是说它实际上是通过模式来预测的？
- en: What exactly are the patterns the model is detecting?
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型究竟检测到的模式是什么？
- en: To answer these questions, we will use the `lucent` library to visualize the
    patterns learned to predict melanoma confidently.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这些问题，我们将使用`lucent`库来可视化模型学到的模式，从而自信地预测黑色素瘤。
- en: Practically visualizing neurons with image input data
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实际可视化带有图像输入数据的神经元
- en: In this section, we will continue with the previous tutorial to further explore
    how to practically visualize neurons with image input data using optimization
    techniques to gain insights into the patterns and behaviors learned by the CNN
    model. This process involves choosing neurons to interpret, optimizing image data
    for those neurons, and applying regularization techniques to generate visually
    interpretable patterns. By visualizing the patterns learned by the model, we can
    gain a better understanding of the model’s predictions and answer questions that
    may not be apparent from traditional feature importance methods.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将继续前面的教程，进一步探讨如何使用优化技术实际可视化带有图像输入数据的神经元，以获得对CNN模型所学模式和行为的深入理解。这个过程涉及选择要解释的神经元，为这些神经元优化图像数据，并应用正则化技术来生成可视化的可解释模式。通过可视化模型所学到的模式，我们可以更好地理解模型的预测，并回答传统特征重要性方法无法揭示的问题。
- en: 'By following the steps outlined in this tutorial, you can visualize the patterns
    learned by your deep neural network, gaining a deeper understanding of the model’s
    predictions and the features that contribute to those predictions. This can help
    to answer questions about the model’s dependence on certain features, such as
    the color of the skin or the shape of the melanoma, and provide valuable insights
    into the patterns and behaviors of the model. Let’s get started:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循本教程中概述的步骤，你可以可视化你的深度神经网络所学到的模式，从而更深入地理解模型的预测及其对这些预测有贡献的特征。这有助于回答关于模型是否依赖于某些特征的问题，比如皮肤颜色或黑色素瘤的形状，并提供关于模型模式和行为的宝贵见解。让我们开始吧：
- en: 'First, let’s define the necessary variables. We want to visualize image patterns
    for the `Melanoma` class, which is at the sixth prediction layer index, so we
    must define the parameter we want to optimize as follows:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们定义必要的变量。我们希望可视化`Melanoma`类别的图像模式，它位于第六个预测层索引处，因此我们必须按如下方式定义我们要优化的参数：
- en: '[PRE7]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, for the first iteration, we will be utilizing the `lucent` specifically,
    CPPN consists of several convolutional layers with a compositional activation
    function consisting of element-wise tangents, squaring, division, and concatenation.
    This means that instead of optimizing the image directly, we optimize the parameters
    of the CPPN convolutional network that generates the input image for the main
    network. Backpropagation can be executed all the way through the generated input
    image till the first layer of the CPPN network. The initial input image is a fixed
    image comprising a circular region in the center of the image, with the values
    at the center being close to zero and gradually increasing toward the edges of
    the circle. However, with CPPN, the learning rate usually needs to be lower to
    converge properly. Let’s define the CPPN configuration with a `224` image size
    and the `Adam` optimizer with a lower-than-typical learning rate:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在第一次迭代中，我们将使用 `lucent`，具体来说，CPPN 由多个卷积层组成，激活函数是由元素级的正切、平方、除法和连接操作构成的组合函数。这意味着我们不是直接优化图像，而是优化生成主网络输入图像的
    CPPN 卷积网络的参数。反向传播可以一直执行到生成的输入图像的第一层 CPPN 网络。初始输入图像是一个固定图像，包含图像中心的圆形区域，圆心的值接近零，并且逐渐增加到圆边缘。然而，使用
    CPPN 时，学习率通常需要较低才能正常收敛。让我们定义一个大小为 `224` 的 CPPN 配置，并使用学习率较低的 `Adam` 优化器：
- en: '[PRE8]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, let’s utilize the defined variables and visualize the patterns captured
    by the melanoma part of the prediction layer using a GPU-configured model:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们利用定义的变量，使用 GPU 配置的模型可视化预测层中捕获的黑色素瘤部分的模式：
- en: '[PRE9]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `thresholds` list component controls the number of optimization steps taken,
    along with the intermediate step number to visualize the optimized image. Additionally,
    a hidden component built into the `render_vis` method is the `transforms` component.
    The `transforms` component adds minimal augmentations such as padding, jitter,
    random scaling, and random rotating to reduce any random noise in the image being
    optimized. The result from the previous code is shown in *Figure 12**.3*:'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`thresholds` 列表组件控制优化步骤的数量，并可视化优化图像的中间步骤号。此外，`render_vis` 方法中内置的一个隐藏组件是 `transforms`
    组件。`transforms` 组件添加了最小化的增强，例如填充、抖动、随机缩放和随机旋转，以减少优化图像中的随机噪声。之前代码的结果如 *图 12.3*
    所示：'
- en: '![Figure 12.3 – Progress of optimizing the CPPN to generate an image that activates
    highly for the melanoma class prediction](img/B18187_12_3.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.3 – 优化 CPPN 的进展，以生成在黑色素瘤类别预测中具有高激活度的图像](img/B18187_12_3.jpg)'
- en: Figure 12.3 – Progress of optimizing the CPPN to generate an image that activates
    highly for the melanoma class prediction
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.3 – 优化 CPPN 的进展，以生成在黑色素瘤类别预测中具有高激活度的图像
- en: A pretty good image of what seems to be the actual melanoma was able to be generated
    from the process.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个过程中生成了一个相当好的图像，看起来像是实际的黑色素瘤。
- en: 'Let’s find out the melanoma probability of this image. We can do this by defining
    the preprocessing methods needed to perform inference with this model:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们来找出这张图像的黑色素瘤概率。我们可以通过定义进行推断所需的预处理方法来实现这一点：
- en: '[PRE10]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here, we predict the skin lesion classes of the final optimized image from
    the process while disabling gradient computation:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们预测从过程生成的最终优化图像的皮肤病变类别，同时禁用梯度计算：
- en: '[PRE11]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This results in a 100% probability of the image being predicted as melanoma!
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果显示图像被预测为黑色素瘤的概率为 100%！
- en: 'However, the image alone does not make it apparent that all the diverse sets
    of images can be recognized as melanoma. Some classes can be sufficiently represented
    in a single image, but some labels can’t really be represented in a single picture.
    Take a background class, for example: it is impossible to put every single background
    visual in a single image. Here are some specific questions that could be useful
    to answer based on the result:'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然而，仅凭图像并不能明显表明所有不同类型的图像集可以被识别为黑色素瘤。有些类别可以在单张图像中充分表示，但有些标签确实无法在单张图像中表现出来。以背景类为例：不可能将每一个背景图像都放在一张图像中。以下是一些基于结果可能有用的问题：
- en: Does the color of the skin matter?
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 皮肤的颜色是否重要？
- en: Does the shape of the melanoma matter, as the final generated image seems to
    have similar melanoma patterns?
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黑色素瘤的形状是否重要，因为最终生成的图像似乎具有相似的黑色素瘤模式？
- en: Does the color of the melanoma patch matter? There are green patches with a
    similar pattern to the red patch.
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 黑色素瘤斑块的颜色重要吗？这里有一些绿色斑块，它们的图案与红色斑块相似。
- en: 'This is where the loss used to ensure diversity mentioned earlier can help
    to provide more insight. Now, let’s utilize the diversity objective with the original
    melanoma prediction layer index objective and optimize a batch of four input images
    concurrently. The batch mode functionality is not supported for CPPN in `lucent`
    and is only supported for the basic input image initialization `param` module:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里提到的用来确保多样性的损失函数可以提供更多的洞察。现在，让我们利用多样性目标与原始黑色素瘤预测层的目标一起，同时优化四张输入图像。批量模式功能不支持
    `lucent` 中的 CPPN，只支持基本输入图像初始化的 `param` 模块：
- en: '[PRE12]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Two additional points on the image initialization method are as follows:'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于图像初始化方法的两个额外要点如下：
- en: '`fft` stands for Fast Fourier transform'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fft` 代表快速傅里叶变换'
- en: '`decorrelate` applies SVD to the image input'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`decorrelate` 对图像输入应用了SVD'
- en: Both techniques here are acknowledged in research to allow faster convergence,
    reduce high-frequency images, and generate better-looking images.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这两种技术在研究中得到认可，能够加速收敛，减少高频图像，并生成更美观的图像。
- en: 'The results are shown in *Figure 12**.4*:'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 结果如*图12.4*所示：
- en: '![Figure 12.4 – Four jointly optimized images to activate highly on the melanoma
    neuron](img/B18187_12_4.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图12.4 – 四张共同优化的图像，能够在黑色素瘤神经元上强烈激活](img/B18187_12_4.jpg)'
- en: Figure 12.4 – Four jointly optimized images to activate highly on the melanoma
    neuron
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.4 – 四张共同优化的图像，能够在黑色素瘤神经元上强烈激活
- en: 'These are very funky-looking images. The non-black color portions are probably
    simulating the skin. Let’s see the probability of the melanoma class for each
    of these images to verify:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图像看起来非常独特。非黑色部分可能模拟了皮肤。我们来看一下每张图像对应黑色素瘤类别的概率，来验证一下：
- en: '[PRE13]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This will result in the following array:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下的数组：
- en: '[PRE14]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'They all have high probabilities for melanoma! From this, the following conclusion
    can be argued:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 它们的黑色素瘤概率都很高！由此可以得出以下结论：
- en: The model does not depend a lot on the color of the skin to detect melanoma.
    The most that skin color can provide will likely be in the range of around a 3%
    probability boost.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型在检测黑色素瘤时不太依赖皮肤的颜色。皮肤颜色所能提供的最大增益可能只是大约 3% 的概率提升。
- en: The model depends on the underlying lower-level pattern mostly to detect melanoma.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型主要依赖于底层低级模式来检测黑色素瘤。
- en: The model doesn’t depend a lot on the color of the melanoma patch. The color
    of the melanoma in the first generated image and real images was reddish. The
    color of the melanoma patch in the batch-generated images was black.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型对黑色素瘤斑块的颜色不太依赖。第一张生成图像和真实图像中的黑色素瘤颜色偏红，而批量生成图像中的黑色素瘤斑块颜色是黑色的。
- en: The model can detect smaller melanoma signals from the real images used.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型能够从使用的真实图像中检测到较小的黑色素瘤信号。
- en: 'The results here are exemplary of how complementary each insight technique
    is to the other. We will end this topic with some useful notes about the pattern
    visualization of neurons through optimization techniques in general:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的结果展示了每种洞察技术之间的互补性。我们将通过一些有用的笔记来结束这个话题，讲解关于神经元通过优化技术进行模式可视化的一般情况：
- en: Some problems are harder to converge than others, and some just don’t converge
    at all. Be ready to experiment with multiple settings to see whether you can get
    a resulting input that can activate highly on your chosen neuron, channel, or
    entire layer. You can even choose multiple neurons to see how they interact!
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些问题比其他问题更难收敛，有些问题根本无法收敛。准备好尝试多种设置，看看能否得到一个能够在你选择的神经元、通道或整个层上强烈激活的输入。你甚至可以选择多个神经元，看看它们如何相互作用！
- en: The loss can turn out to be extremely negative, and the more the input converges,
    the more negative it gets. This is good, as the loss is defined as the negative
    of the resulting activation value.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失函数可能会变得非常负，且输入收敛的越多，损失越负。这是好的，因为损失被定义为结果激活值的负数。
- en: Regularization techniques are the key to allowing reasonable inputs to be generated
    through optimization.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则化技术是通过优化生成合理输入的关键。
- en: Use both real data and diverse optimized data to understand the patterns your
    model learned to detect. One optimized piece of data usually can’t represent the
    entire range of patterns a neuron can detect.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用真实数据和多样化的优化数据来理解模型学习到的检测模式。单一的优化数据通常无法代表神经元能够检测到的所有模式。
- en: In this tutorial, we used the final classification layer, which made it easier
    to find samples that activate highly toward the chosen neuron. If an intermediate
    neuron is chosen, be sure to find the set of data with the highest activations
    for the chosen neuron.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本教程中，我们使用了最终分类层，这使得找到对选定神经元激活度高的样本变得更容易。如果选择的是一个中间神经元，请确保找到对该神经元激活度最高的数据集。
- en: The `lucent` library for `pytorch`-based models and the `lucid` library for
    TensorFlow-based models are focused on image visualizations but can both be adapted
    to other input variable types such as text. However, not much research has been
    done there to figure out good regularization techniques for other variable types
    to allow faster convergence.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lucent`库是基于`pytorch`的模型，而`lucid`库则是基于TensorFlow的模型，它们专注于图像可视化，但也可以适应其他输入变量类型，如文本。然而，目前在这方面的研究较少，尚未找到针对其他变量类型的良好正则化技术来实现更快的收敛。'
- en: Overall, the visualization of neurons through optimization techniques can provide
    valuable insights into the patterns and behaviors of **machine learning** (**ML**)
    models, but it requires experimentation and careful consideration of the inputs
    and regularization techniques used. As a bonus here, with knowledge of how to
    execute prediction explanations and NN interpretation, we will discover a useful
    way to make explanations more effective in general with a method called counterfactual
    explanations.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，通过优化技术可视化神经元可以为**机器学习**（**ML**）模型的模式和行为提供有价值的洞察，但这需要实验和对输入及正则化技术的谨慎考虑。作为一个额外的收获，通过了解如何执行预测解释和神经网络（NN）解释，我们将发现一种叫做反事实解释的方法，可以使解释在一般情况下更为有效。
- en: Discovering the counterfactual explanation strategy
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发现反事实解释策略
- en: Counterfactual explanation or reasoning is a method of understanding and explaining
    anything in general by considering alternative and counterfactual scenarios or
    “what-if” situations. In the context of prediction explanations, it involves identifying
    changes in the input data that would lead to a different outcome. Ideally, the
    minimal changes should be identified. In the context of NN interpretation, it
    involves visualizing the opposite of the target label or intermediate latent features.
    This approach makes sense to use because it closely aligns with how humans naturally
    explain events and assess causality, which ultimately allows us to comprehend
    the underlying decision-making process of the model better.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 反事实解释或推理是一种通过考虑替代的和反事实的情境或“如果……会怎样”的情况来理解和解释任何事物的方法。在预测解释的背景下，它涉及识别输入数据的变化，这些变化会导致不同的结果。理想情况下，应该识别出最小的变化。在神经网络解释的背景下，它涉及到可视化目标标签或中间潜在特征的反面。这种方法是有意义的，因为它与人类自然解释事件和评估因果关系的方式密切相关，最终能够帮助我们更好地理解模型的决策过程。
- en: Humans tend to think in terms of cause and effect, and we often explore alternative
    possibilities to make sense of events or decisions. For example, when trying to
    understand why a certain decision was made, we may ask questions such as, “What
    would have happened if we had chosen a different option?” or “What factors led
    to this outcome?”. This kind of reasoning helps us identify the key elements that
    influenced the decision and allows us to learn from the experience. Counterfactual
    explanations for ML models follow a similar thought process. By presenting alternative
    input instances that would have resulted in a different prediction, counterfactual
    explanations help us understand which features of the input data are most critical
    in the model’s decision-making process. This kind of explanation allows users
    to grasp the model’s rationale more intuitively and can also help improve their
    trust in the model’s predictions.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 人类倾向于从因果关系的角度思考，我们常常探索替代性可能性，以便理解事件或决策的原因。例如，当试图理解某个决策为何做出时，我们可能会问：“如果我们选择了不同的选项，会发生什么？”或“是什么因素导致了这个结果？”这种推理帮助我们识别出影响决策的关键因素，并且让我们从经验中学习。机器学习模型的反事实解释遵循类似的思维过程。通过展示如果输入实例不同将会导致不同预测的替代输入实例，反事实解释帮助我们理解在模型决策过程中，哪些输入特征最为关键。这种解释方式使得用户能够更直观地理解模型的推理过程，并有助于提高他们对模型预测的信任度。
- en: Counterfactual reasoning complements feature importance and neuron visualization
    techniques. Together, these methods can provide a more comprehensive understanding
    of how the model arrives at its decisions. This, in turn, can help users better
    assess the reliability of the model and make more informed decisions based on
    its predictions.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 反事实推理补充了特征重要性和神经元可视化技术。结合这些方法，可以更全面地理解模型是如何做出决策的。反过来，这也有助于用户更好地评估模型的可靠性，并根据模型的预测做出更有根据的决策。
- en: Summary
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: NN interpretation is a form of a model understanding process that is different
    from explaining the predictions made by a model. Both manual discovery of real
    images and optimizing synthetic images to activate highly for the chosen neuron
    to interpret are techniques that can be applied together to understand the NN.
    Practically, the interpretation of NNs will be useful when you have goals to reveal
    the appearance of a particular prediction label or class pattern, gain insight
    into the factors contributing to the prediction of a specific label in your dataset
    or all labels in general, and gain a detailed breakdown of the reasons behind
    a prediction.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络解释是一种与解释模型做出的预测不同的模型理解过程。通过手动发现真实图像和优化合成图像，使其在选定神经元上高度激活进行解释，是可以一起应用的技术，以理解神经网络。实际上，当你有目标去揭示特定预测标签或类别模式的外观，洞察影响你数据集中某个特定标签预测的因素，或者所有标签的预测时，神经网络的解释会非常有用，并能详细分析预测背后的原因。
- en: There might be hiccups when trying to apply the technique in your use case,
    so don’t be afraid to experiment with the parameters and components introduced
    in this chapter in your goal to interpret your NN.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试将此技术应用于你的使用案例时，可能会遇到一些小问题，因此不要害怕在你的目标是解释神经网络时，尝试调整本章中介绍的参数和组件。
- en: We will explore a different facet of insights that you can obtain from your
    data and your model in the next chapter, which is about bias and fairness.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将探索你可以从数据和模型中获得的另一个层面的洞察，即偏见与公平性。
