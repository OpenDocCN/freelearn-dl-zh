- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Introduction to Generative AI Patterns
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成型AI模式简介
- en: This chapter provides an overview of key concepts, techniques, and integration
    patterns related to generative AI that will empower you to harness these capabilities
    in real-world applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章概述了与生成型AI相关的关键概念、技术和集成模式，这将使你能够在实际应用中利用这些能力。
- en: We will provide an overview of generative AI architectures, such as transformers
    and diffusion models, which are the basis for these generative models to produce
    text, images, audio, and more. You’ll get a brief introduction to specialized
    training techniques, like pre-training and prompt engineering, that upgrade basic
    language models into creative powerhouses.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将概述生成型AI架构，如transformers和diffusion模型，这些是这些生成模型产生文本、图像、音频等的基础。你将简要了解专门的训练技术，如预训练和提示工程，这些技术将基本语言模型升级为创意
    powerhouse。
- en: Understanding the relentless pace of innovation in this space is critical due
    to new models and ethical considerations emerging constantly. We’ll introduce
    strategies for experimenting rapidly while ensuring responsible, transparent development.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 由于新模型和伦理考虑的持续出现，理解这个领域的创新步伐至关重要。我们将介绍快速实验的策略，同时确保负责任、透明的开发。
- en: The chapter also introduces common integration patterns for connecting generative
    AI into practical workflows. Whether crafting chatbots that leverage models in
    real time or performing batch enrichment of data, we will introduce prototyping
    blueprints to jumpstart building AI-powered systems.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还介绍了将生成型AI连接到实际工作流程的常见集成模式。无论是制作利用实时模型的聊天机器人，还是执行批量数据丰富，我们将介绍原型蓝图以启动构建AI驱动系统的过程。
- en: By the end, you will have a one-thousand-foot view of which generative AI models
    are available, why experimentation is important, and how these integration patterns
    can help create value for your organization leveraging generative AI.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到最后，你将全面了解哪些生成型AI模型可用，为什么实验很重要，以及这些集成模式如何帮助你的组织利用生成型AI创造价值。
- en: 'In a nutshell, the following main topics will be covered:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，以下主要主题将被涵盖：
- en: Interacting with AI
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与AI交互
- en: Predictive AI vs generative AI use case ideation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测型AI与生成型AI用例构思
- en: A change in the paradigm
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 范式的转变
- en: General generative AI concepts
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通用生成型AI概念
- en: Introduction to generative AI integration patterns
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成型AI集成模式简介
- en: From AI predictions to generative AI
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从AI预测到生成型AI
- en: The intent of this section is to provide a brief overview of artificial intelligence,
    highlighting our initial experiences with it. In the early 2000s, AI started to
    become more tangible for consumers. For example, in 2001, Google introduced the
    “Did you mean?” feature ([https://blog.google/intl/en-mena/product-updates/explore-get-answers/25-biggest-moments-in-search-from-helpful-images-to-ai/](https://blog.google/intl/en-mena/product-updates/explore-get-answers/25-biggest-moments-in-search-from-helpful-images-to-ai/)),
    which suggests spelling corrections. This was one of Google’s first applications
    of machine learning and one of the early AI features that the general public got
    to experience on a large scale.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目的在于提供一个关于人工智能的简要概述，强调我们与它的初步体验。在2000年代初，AI开始对消费者变得更加具体。例如，在2001年，谷歌推出了“你是指？”功能([https://blog.google/intl/en-mena/product-updates/explore-get-answers/25-biggest-moments-in-search-from-helpful-images-to-ai/](https://blog.google/intl/en-mena/product-updates/explore-get-answers/25-biggest-moments-in-search-from-helpful-images-to-ai/))，建议拼写纠正。这是谷歌机器学习的第一次应用之一，也是公众大规模体验的早期AI功能之一。
- en: Over the following years, AI systems became more sophisticated, especially in
    areas like computer vision, speech-to-text conversion, and text-to-speech synthesis.
    Working in the telecom industry helped me witness the innovation driven by speech-to-text
    in particular. Integrating speech-to-text capabilities into **interactive voice
    response** (**IVR**) systems led to better user experiences by allowing people
    to speak their requests rather than punch numbers into a keypad. For example,
    you could be calling a bank where you would be welcomed by a message asking you
    to say “balance” to check your balance, “open account” in order to open an account,
    etc. Nowadays we are seeing more and more implementations of AI, simplifying more
    complex and time-consuming tasks.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几年里，AI系统变得更加复杂，特别是在计算机视觉、语音转文本转换和文本转语音合成等领域。在电信行业的工作使我得以见证由语音转文本驱动的创新。将语音转文本功能集成到**交互式语音响应**（**IVR**）系统中，通过让人们说出他们的请求而不是在键盘上按键，从而提高了用户体验。例如，你可以拨打一家银行，你会听到一条消息，要求你说“余额”来查询余额，“开户”以开户等。如今，我们越来越多地看到AI的应用，简化了更复杂和耗时的工作。
- en: The exponential increase in available computing power, paired with the massive
    datasets needed to train machine learning models, unleashed new AI capabilities.
    In the 2010s, AI started matching and even surpassing human performance on certain
    tightly defined tasks like image classification.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 可用计算能力的指数级增长，加上训练机器学习模型所需的庞大数据集，释放了新的AI能力。在2010年代，AI开始在图像分类等某些严格定义的任务上与人类性能相匹配，甚至超越。
- en: The advent of generative AI has reignited interest and innovation in the AI
    field, introducing new approaches for exploring use cases and system integration.
    Models like Gemini, PaLM, Claude, DALL-E, OpenAI GPT, and Stable Diffusion showcase
    the ability of AI systems to generate synthetic text, images, and other media.
    The outputs exhibit creativity and imagination that capture the public’s attention.
    However, the powerful capabilities of generative models also highlight new challenges
    around system design and responsible deployment. There is a need to rethink integration
    patterns and architecture to support safe, robust, and cost-effective implementations.
    Specifically, issues around security, bias, toxicity, and misinformation must
    be addressed through techniques like dataset filtering, human-in-the-loop systems,
    enhanced monitoring, and immediate remediation.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能的出现重新点燃了人们对AI领域的兴趣和创新，引入了探索用例和系统集成的新方法。Gemini、PaLM、Claude、DALL-E、OpenAI
    GPT和Stable Diffusion等模型展示了AI系统生成合成文本、图像和其他媒体的能力。这些输出展现了创造力和想象力，吸引了公众的注意。然而，生成模型强大的能力也突显了系统设计和负责任部署方面的新挑战。需要重新思考集成模式和架构，以支持安全、稳健和成本效益的实施。具体来说，需要通过数据集过滤、人机协作系统、增强监控和即时补救等技术来解决关于安全、偏见、毒性和错误信息的问题。
- en: As generative AI continues maturing, best practices and governance frameworks
    must evolve in tandem. Industry leaders have formed partnerships like the Content
    Authenticity Initiative to develop technical standards and policy guidance around
    the responsible development of the next iteration of AI. This technology’s incredible
    potential, from accelerating drug discovery to envisioning new products, can only
    be realized through a commitment to transparency, ethics, and human rights. Constructive
    collaboration that balances innovation with caution is imperative.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成式人工智能的不断发展成熟，最佳实践和治理框架必须同步演进。行业领导者已经建立了如内容真实性倡议（Content Authenticity Initiative）等伙伴关系，以开发围绕人工智能下一迭代负责任发展的技术标准和政策指导。这种技术令人难以置信的潜力，从加速药物发现到构想新产品，只有通过承诺透明度、伦理和人权才能实现。在创新与谨慎之间保持建设性合作是至关重要的。
- en: Generative AI marks an inflection point for the field. The ripples from this
    groundswell of creative possibility are just beginning to reach organizations
    and communities. Maintaining an open, evidence-driven dialogue around not just
    capabilities but also challenges lays a foundation for AI deployment that empowers
    people, unlocks new utility, and earns widespread trust.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能标志着该领域的转折点。这一创造性可能性的浪潮所引起的涟漪才刚刚开始触及组织和社区。围绕能力以及挑战展开的开放、基于证据的对话，为赋予人们权力、解锁新效用和赢得广泛信任的人工智能部署奠定了基础。
- en: We are witnessing an unprecedented democratization of generative AI capabilities
    through publicly accessible APIs from established companies like Google, Meta,
    and Amazon, and startups such as Anthropic, Mistral AI, Stability AI, and OpenAI.
    The table below summarizes several leading models that provide versatile foundations
    for natural language and image generation.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在见证生成式人工智能能力前所未有的民主化，这是通过像谷歌、Meta和亚马逊这样的知名公司以及Anthropic、Mistral AI、Stability
    AI和OpenAI等初创公司提供的公开可访问的API实现的。下表总结了几个领先的模型，它们为自然语言和图像生成提供了多才多艺的基础。
- en: Just a few years ago, developing with generative AI required specialized expertise
    in deep learning and access to vast computational resources. Now, models like
    Gemini, Claude, GPT-4, DALL-E, and Stable Diffusion can be accessed via simple
    API calls at near-zero cost. The bar for experimentation has never been lower.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 只需几年前，使用生成式人工智能进行开发需要深度学习方面的专业知识以及访问大量计算资源。现在，Gemini、Claude、GPT-4、DALL-E和Stable
    Diffusion等模型可以通过简单的API调用以近乎零的成本访问。实验的门槛从未如此之低。
- en: This commoditization has sparked an explosion of new applications leveraging
    these pre-trained models – from creative tools for content generation to process
    automation solutions infused with AI. Expect integrations with generative foundations
    across all industries in the coming months and years.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这种商品化引发了利用这些预训练模型的新应用爆炸式增长——从内容生成的创意工具到融入人工智能的流程自动化解决方案。预计在未来几个月和几年内，所有行业都将实现与生成式基础的集成。
- en: Models are becoming more knowledgeable, with broader capabilities and reasoning
    that will reduce hallucinations and increase accuracy across model responses.
    Multimodality is also gaining traction, with models able to ingest and generate
    content across text, images, audio, video, and 3D scenes. In terms of scalability,
    model size and context windows continue expanding exponentially; for example,
    Google’s Gemini 1.5 now supports a context window of 1 million tokens.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 模型正变得更加知识渊博，具备更广泛的技能和推理能力，这将减少幻觉并提高模型响应的准确性。多模态也在获得关注，模型能够处理和生成文本、图像、音频、视频和3D场景的内容。在可扩展性方面，模型大小和上下文窗口正在呈指数级增长；例如，谷歌的Gemini
    1.5现在支持1百万个标记的上下文窗口。
- en: Overall, the outlook points to a future where generative AI will become deeply
    integrated into most technologies. These models introduce new efficiencies and
    automation potential and inspire creativity across nearly every industry imaginable.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，展望未来，生成式人工智能将深度融入大多数技术中。这些模型引入了新的效率和自动化潜力，并激发几乎所有可想象行业的创造力。
- en: The table below highlights some of the most popular LLMs and their providers.
    The purpose of the table is to highlight the vast number of options available
    on the market at the time of writing this book. We expect this table to quickly
    become outdated by the time of publication and highly encourage readers to dive
    deep into the model providers’ websites to stay up to date with any new launches.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 下表突出了一些最受欢迎的大型语言模型及其提供商。本表的目的在于强调在撰写本书时市场上可用的众多选项。我们预计，到本书出版时，此表将很快过时，并强烈建议读者深入访问模型提供商的网站，以保持对任何新发布的最新信息。
- en: '| **Model** | **Provider** | **Landing Page** |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| **模型** | **提供商** | **着陆页** |'
- en: '| Gemini | Google | [https://deepmind.google/technologies/gemini](https://deepmind.google/technologies/gemini)
    |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| Gemini | Google | [https://deepmind.google/technologies/gemini](https://deepmind.google/technologies/gemini)
    |'
- en: '| Claude | Anthropic | [https://claude.ai/](https://claude.ai/) |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| Claude | Anthropic | [https://claude.ai/](https://claude.ai/) |'
- en: '| ChatGPT | OpenAI | [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)
    |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT | OpenAI | [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)
    |'
- en: '| Stable Diffusion | Stability AI | [https://stability.ai/](https://stability.ai/)
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| Stable Diffusion | Stability AI | [https://stability.ai/](https://stability.ai/)
    |'
- en: '| Mistral | Mistral AI | [https://mistral.ai/](https://mistral.ai/) |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| Mistral | Mistral AI | [https://mistral.ai/](https://mistral.ai/) |'
- en: '| LLaMA | Meta | [https://llama.meta.com/](https://llama.meta.com/) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| LLaMA | Meta | [https://llama.meta.com/](https://llama.meta.com/) |'
- en: 'Table 1.1: Overview of popular LLMs and their providers'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.1：流行的大型语言模型及其提供商概述
- en: Predictive AI vs generative AI use case ideation
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测式人工智能与生成式人工智能用例构思
- en: Predictive AI refers to systems that analyze data to identify patterns and make
    forecasts or classifications about future events. In contrast, generative AI models
    create new synthetic content like images, text, or code based on the patterns
    gleaned from their training data. For example, with predictive AI, you can confidently
    identify if an image contains a cat or not, whereas with generative AI you can
    create an image of a cat from a text prompt, modify an existing image to include
    a cat where there was none, or generate a creative text blurb about a cat.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 预测AI指的是分析数据以识别模式并对未来事件进行预测或分类的系统。相比之下，生成式AI模型根据从训练数据中提取的模式创建新的合成内容，如图像、文本或代码。例如，使用预测AI，你可以自信地识别图像中是否包含猫，而使用生成AI，你可以根据文本提示创建猫的图像，修改现有的图像以包含原本没有的猫，或者生成关于猫的创意文本摘要。
- en: Product innovation focused on AI involves various phases of the product development
    lifecycle. With the emergence of generative AI, the paradigm has shifted away
    from initially needing to compile training data to train traditional ML models
    and toward leveraging flexible pre-trained models.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 专注于AI的产品创新涉及产品开发生命周期的各个阶段。随着生成式AI的出现，范式已经从最初需要编译训练数据来训练传统ML模型转变为利用灵活的预训练模型。
- en: Foundational models like Google’s PaLM 2 and Gemini, OpenAI’s GPT and DALL-E,
    and Stable Diffusion provide broad foundations enabling rapid prototype development.
    Their versatile capabilities lower the barrier for experimenting with novel AI
    applications.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 像谷歌的PaLM 2和Gemini、OpenAI的GPT和DALL-E、以及Stable Diffusion这样的基础模型提供了广泛的基础，使得快速原型开发成为可能。它们的通用能力降低了尝试新型AI应用的门槛。
- en: Where previously data curation and model training from scratch could take months
    before assessing viability, now proof-of-concept generation is possible within
    days without the need to fine-tune a foundation model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在以前，从数据整理和从头开始训练模型到评估可行性可能需要数月时间，而现在，在无需微调基础模型的情况下，几天内就可以生成概念验证。
- en: This generative approach facilitates more iterative concept validation. After
    quickly building an initial prototype powered by the baseline model, developers
    can then collect niche training data and perform knowledge transfer via techniques
    like distillation to customize later versions; we will deep dive into the concept
    of distillation later in the book. The model’s primary foundation contains already
    encoded patterns useful for kickstarting and for iterations of new models.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这种生成式方法促进了更迭的迭代概念验证。在快速构建由基线模型驱动的初始原型后，开发者可以收集特定训练数据，并通过蒸馏等技巧进行知识迁移，以定制后续版本；本书稍后将对蒸馏的概念进行深入探讨。模型的主要基础中已经包含了用于启动和迭代新模型的编码模式。
- en: In contrast, the predictive modeling approach requires upfront data gathering
    and training before any application testing. This more linear progression limits
    early-stage flexibility. However, predictive systems can efficiently learn specialized
    correlations and achieve a high level of confidence inference metrics once substantial
    data exists.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，预测建模方法需要在任何应用测试之前进行数据收集和训练。这种更线性的进展限制了早期阶段的灵活性。然而，一旦存在大量数据，预测系统可以有效地学习专业相关性，并实现高置信度的推理指标。
- en: Leveraging versatile generative foundations supports rapid prototyping and use
    case exploration. But, later, custom predictive modeling boosts performance on
    narrow tasks with sufficient data. Blending these AI approaches capitalizes on
    their complementary strengths throughout the model deployment lifecycle.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 利用通用的生成式基础支持快速原型设计和用例探索。但是，后来，定制预测建模在具有足够数据的狭窄任务上提高了性能。结合这些AI方法可以在模型部署的生命周期中充分利用它们的互补优势。
- en: Beyond the basic use – prompt engineering – of a foundational model, several
    auxiliary, more complex techniques can enhance its capabilities. Examples include
    **Chain-of-Thought** (**CoT**) and **ReAct**, which empower the model to not only
    reason about a situation but also define and evaluate a course of action.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 除去基础使用——提示工程——之外，还有几个辅助的、更复杂的技巧可以增强基础模型的能力。例如，**思维链**（**CoT**）和**ReAct**，这些技巧使模型不仅能对情况进行推理，还能定义和评估行动方案。
- en: 'ReAct, presented in the paper *ReAct: Synergizing Reasoning and Acting in Language
    Models* ([https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)),
    addresses the current disconnect between LLMs’ language understanding and their
    ability to make decisions. While LLMs excel at tasks like comprehension and question
    answering, their reasoning and action-taking skills (for example, generating action
    plans or adapting to unforeseen situations) are often treated separately.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文*《ReAct：在语言模型中协同推理和行动》*中提出的ReAct，解决了LLMs在语言理解能力与决策能力之间当前存在的脱节。虽然LLMs在理解任务和问答任务上表现出色，但它们的推理和行动技能（例如，生成行动计划或适应不可预见的情况）通常被分开处理。
- en: ReAct bridges this gap by prompting LLMs to generate both “reasoning traces,”
    detailing the model’s thought process, and task-specific actions in an interleaved
    manner. This tight coupling allows the model to leverage reasoning for planning,
    execution monitoring, and error handling, while simultaneously using actions to
    gather additional information from external sources like knowledge bases or environments.
    This integrated approach demonstrably improves LLM performance in both language
    and decision-making tasks.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: ReAct通过提示LLMs以交错的方式生成“推理轨迹”，详细说明模型的思维过程，以及特定任务的动作来弥合这一差距。这种紧密耦合允许模型利用推理进行规划、执行监控和错误处理，同时使用行动从外部来源（如知识库或环境）收集更多信息。这种集成方法显著提高了LLMs在语言和决策任务上的性能。
- en: For example, in question-answering and fact-verification tasks, ReAct combats
    common issues like hallucination and error propagation by utilizing a simple Wikipedia
    API. This interaction allows the model to generate more transparent and trustworthy
    solutions compared to methods lacking reasoning or action components. LLM hallucinations
    are defined as content generated that seems plausible yet factually unsupported.
    There are various papers that aim to address this phenomenon. For example, *A
    survey of Hallucination in Large Language Models – Principles, Taxonomy, Challenges,
    and Open Questions* deep dives into an approach to not only identify but also
    mitigate hallucinations. Another good example of a mitigation technique is covered
    in the paper *Chain-of-Verification Reduces Hallucination in Large Language Models*
    ([https://arxiv.org/pdf/2309.11495.pdf](https://arxiv.org/pdf/2309.11495.pdf)).
    At the time of writing this book, hallucinations are a very rapidly changing field.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在问答和事实核查任务中，ReAct通过利用简单的维基百科API来对抗诸如幻觉和错误传播等常见问题。这种交互使得模型能够生成比缺乏推理或行动组件的方法更透明、更值得信赖的解决方案。LLM的幻觉被定义为看似合理但实际上没有事实依据的内容。有许多论文旨在解决这个问题。例如，*《大型语言模型中幻觉的综述——原理、分类、挑战和开放性问题》*深入探讨了不仅识别而且减轻幻觉的方法。另一个缓解技术的良好例子可以在论文*《通过验证链减少大型语言模型中的幻觉》*中找到（[https://arxiv.org/pdf/2309.11495.pdf](https://arxiv.org/pdf/2309.11495.pdf)）。在撰写本书时，幻觉是一个变化非常快的领域。
- en: 'Both CoT and ReAct rely on prompting: feeding the LLM with carefully crafted
    instructions that guide its thought process. CoT, as presented in the paper *Chain-of-Thought
    Prompting Elicits Reasoning in Large Language Models* ([https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)),
    focuses on building a chain of reasoning steps, mimicking human thinking. Imagine
    prompting the model with: “I want to bake a cake. First, I need flour. Where can
    I find some?” The model responds with a potential source, like your pantry. This
    back-and-forth continues, building a logical chain of actions and decisions.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: CoT和ReAct都依赖于提示：向LLM提供精心设计的指令，以引导其思维过程。CoT，如论文*《思维链提示在大型语言模型中激发推理》*中所述（[https://arxiv.org/abs/2201.11903](https://arxiv.org/abs/2201.11903)），专注于构建推理步骤链，模仿人类思维。想象一下提示模型：“我想烤蛋糕。首先，我需要面粉。我在哪里能找到一些？”模型会回应一个潜在来源，比如你的储藏室。这种一来一往的对话继续进行，构建了一个逻辑上的行动和决策链。
- en: ReAct takes things a step further, integrating action into the reasoning loop.
    Think of it as a dynamic dance between thought and action. The LLM not only reasons
    about the situation but also interacts with the world, fetching information or
    taking concrete steps, and then updates its reasoning based on the results. It’s
    like the model simultaneously planning a trip and checking maps to adjust the
    route if it hits a roadblock.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: ReAct 将事情推进了一步，将行动整合到推理循环中。把它想象成思维与行动之间的动态舞蹈。LLM 不仅对情况进行推理，而且与世界互动，获取信息或采取具体步骤，然后根据结果更新其推理。这就像模型同时在规划旅行并检查地图以调整路线，如果遇到障碍。
- en: This powerful synergy between reasoning and action unlocks a new realm of possibilities
    for LLMs. CoT and ReAct tackle challenges like error propagation (jumping to the
    wrong conclusions based on faulty assumptions) by allowing the model to trace
    its logic and correct course. They also improve transparency, making the LLM’s
    thought process clear and understandable.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这种推理与行动之间强大的协同作用为LLM开辟了新的可能性领域。CoT和ReAct通过允许模型追踪其逻辑并纠正方向来解决挑战，如错误传播（基于错误假设得出错误结论）。它们还提高了透明度，使LLM的思维过程变得清晰易懂。
- en: In other words, **large language models** (**LLMs**) are like brilliant linguists,
    adept at understanding and generating text. But when it comes to real-world tasks
    demanding reasoning and action, they often stumble. Here’s where techniques like
    CoT and ReAct enter the scene, transforming LLMs into reasoning powerhouses.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，**大型语言模型（LLMs**）就像杰出的语言学家，擅长理解和生成文本。但说到需要推理和行动的实际情况，它们往往举步维艰。这正是CoT和ReAct等技术出现的地方，将LLM转变为推理的强大力量。
- en: Imagine an LLM helping diagnose a complex disease. CoT could guide it through
    a logical chain of symptoms and examinations, while ReAct could prompt it to consult
    medical databases or run simulations. This not only leads to more accurate diagnoses
    but also enables doctors to understand the LLM’s reasoning, fostering trust and
    collaboration.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下LLM帮助诊断一种复杂的疾病。CoT可以引导它通过症状和检查的逻辑链，而ReAct可以提示它咨询医学数据库或运行模拟。这不仅导致更准确的诊断，而且使医生能够理解LLM的推理，培养信任和协作。
- en: These futuristic applications are what drive us to keep building and investing
    in this technology, which is very exciting. Before we dive deep into the patterns
    that are needed to leverage generative AI technology to generate business value,
    let’s take a step back and look at some initial concepts.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这些未来派应用正是推动我们不断构建和投资这项技术的原因，这非常令人兴奋。在我们深入探讨利用生成式AI技术产生商业价值所需的模式之前，让我们退一步，看看一些初步概念。
- en: A change in the paradigm
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 范式的改变
- en: It feels like eons ago in tech years, but let’s rewind just a couple of years,
    back when if you were embarking on solving an AI problem, you couldn’t default
    to utilizing a pre-trained model through the web or a managed endpoint. The process
    was meticulous – you’d have to first clearly define the specific use case, identify
    what data you had available and could collect to train a custom model, select
    the appropriate algorithm and model architecture, train the model using specialized
    hardware and software, and validate if the outputs would actually help solve the
    task at hand. If all went well, you would have a model that would take a predefined
    input and also provide a predefined output.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在科技年数中，这感觉像是远古时代，但让我们回顾一下仅仅几年前的时光，那时如果你开始着手解决一个AI问题，你不能默认通过网络或托管端点利用预训练模型。这个过程非常细致——你首先必须明确定义具体的用例，确定你有什么可用和可收集的数据来训练定制模型，选择合适的算法和模型架构，使用专用硬件和软件训练模型，并验证输出是否真的有助于解决手头的任务。如果一切顺利，你将拥有一个模型，它将接受预定义的输入并提供预定义的输出。
- en: The paradigm profoundly shifted with the advent of LLMs and large multimodal
    models. Suddenly, you could access a pre-trained model with billions of parameters
    and start experimenting right off the bat with these versatile foundational models
    where the inputs and outputs are dynamic in nature. After tinkering around, you’d
    then evaluate if any fine-tuning is necessary to adapt the model to your needs,
    rather than pre-training an entire model from scratch. And spoiler alert – in
    most cases, chances are you won’t even need to fine-tune a foundational model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 随着大型语言模型和大型多模态模型的问世，范式发生了根本性的转变。突然之间，你可以访问具有数十亿参数的预训练模型，并立即开始使用这些多才多艺的基础模型进行实验，其中输入和输出都是动态的。在尝试一番之后，你会评估是否需要微调以适应你的需求，而不是从头开始预训练整个模型。而且剧透一下——在大多数情况下，你可能甚至不需要微调基础模型。
- en: Another key shift relates to the early belief that one model would outperform
    all others and solve all tasks. However, the model itself is just the engine;
    you still need an entire ecosystem packaged together to provide a complete solution.
    Foundational models have certainly demonstrated some incredible capabilities beyond
    initial expectations. But we also observe that certain models are better suited
    for certain tasks. And running the same prompt through other models can produce
    very different outputs depending on the underlying model’s training datasets and
    architecture.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个关键转变与早期认为一个模型将优于所有其他模型并解决所有任务的信念有关。然而，模型本身只是引擎；你仍然需要一个完整的生态系统打包在一起，以提供完整的解决方案。基础模型确实展示了超出初始预期的某些令人难以置信的能力。但我们还观察到，某些模型更适合某些任务。将相同的提示通过其他模型运行可能会产生非常不同的输出，这取决于底层模型的训练数据集和架构。
- en: So, the new experimental path often focuses first on prompt engineering, response
    evaluation, and then fine-tuning the foundational model if gaps exist. This contrasts
    sharply with the previous flow of data prep, training, and experimentation before
    you could get your hands dirty. The bar to start creating with AI has never been
    lower.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，新的实验路径通常首先关注提示工程、响应评估，如果存在差距，然后是微调基础模型。这与之前的数据准备、训练和实验流程形成鲜明对比。开始使用人工智能的门槛从未如此之低。
- en: In the following sections, we will explore the difference between the development
    lifecycle of predictive AI and generative AI use cases. In each section, we have
    provided a high-level visual representation of a simplified development lifecycle
    and an explanation of the thought process behind each approach.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将探讨预测人工智能用例和生成人工智能用例开发生命周期的差异。在每个章节中，我们都提供了一个简化开发生命周期的概述性视觉表示以及每种方法的思维过程解释。
- en: Predictive AI use case development – simplified lifecycle
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 预测人工智能用例开发——简化生命周期
- en: '![](img/B22175_01_01.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22175_01_01.png)'
- en: 'Figure 1.1: Predictive AI use case development simplified lifecycle'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1：预测人工智能用例开发简化生命周期
- en: Let’s dive into the process of developing a predictive AI model first. Everything
    starts with a good use case, and ROI (return on investment) is top of mind when
    evaluating AI use cases. Think about pain points in your business or industry
    that could be solved by predicting an outcome. It is very important to always
    keep an eye on feasibility – whether you can procure the data you need, etc.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先深入了解开发预测人工智能模型的过程。一切从良好的用例开始，在评估人工智能用例时，投资回报率（ROI）是首要考虑的。想想看，你的业务或行业中哪些痛点可以通过预测结果来解决。始终关注可行性非常重要——例如，你是否能获取所需的数据等。
- en: Once you’ve landed on a compelling value-driven use case, next up is picking
    algorithms. You’ve got endless options here – decision trees, neural nets, regressions,
    random forests, and on and on. It is very important not to be swayed by the bias
    for the latest and greatest and to focus on the core requirements of your data
    and use case to narrow the options down. You can always switch it up or add additional
    experiments as you iterate through your testing.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你确定了一个有吸引力的价值驱动的用例，接下来就是选择算法。在这里你有无数的选择——决策树、神经网络、回归、随机森林，等等。非常重要的一点是不要被对最新和最好的偏好所左右，而要专注于你数据和用例的核心需求，以缩小选项范围。你可以在测试过程中随时调整或添加额外的实验。
- en: With a plan in place, now it is time to get your hands dirty with the data.
    Identifying sources, cleaning things up, and carrying out feature engineering
    is an art and, more often than not, the key to improving your model’s results.
    There is no shortcut for rigor here, unfortunately! Garbage in, garbage out, as
    they say. But once you’ve wrangled datasets you can rely on, then comes the fun
    part.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 计划已经就绪，现在是你动手处理数据的时候了。识别数据源，整理数据，并进行特征工程是一种艺术，而且往往是提高模型结果的关键。不幸的是，这里没有捷径！正如他们所说：“垃圾进，垃圾出”。但一旦你整理好了可以信赖的数据集，接下来就是有趣的部分。
- en: It’s time to work with your model. Define your evaluation process upfront, split
    data wisely, and start training various configurations. Don’t forget to monitor
    and tune based on validation performance. Then, once you’ve got your golden model,
    implement robust serving infrastructure so it scales without a hitch.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候开始与你的模型工作了。事先定义你的评估流程，明智地分割数据，并开始训练各种配置。别忘了根据验证性能进行监控和调整。然后，一旦你得到了你的黄金模型，实施稳健的服务基础设施，以确保它能够顺利扩展。
- en: But wait, not so fast! Testing doesn’t end when models are in production. Collect
    performance data continuously, monitor for concept drifts, and retrain when needed.
    A solid predictive model requires ongoing feedback mechanisms, as shown via the
    arrow connecting **Model Enhancement** to **Testing** in *Figure 1.1*. There is
    no such thing as set and forget in this space.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 但等等，别这么快！测试并不在模型投入生产时结束。持续收集性能数据，监控概念漂移，并在需要时重新训练。一个稳固的预测模型需要持续的反馈机制，正如连接**模型增强**到**测试**的箭头在*图1.1*中所示。在这个领域，没有一劳永逸的事情。
- en: Generative AI use case development – simplified lifecycle
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成式AI用例开发 - 简化生命周期
- en: '![](img/B22175_01_02.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22175_01_02.png)'
- en: 'Figure 1.2: Generative AI use case development simplified lifecycle'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2：生成式AI用例开发简化生命周期
- en: The process of generative AI use case development is similar but not the same
    as in predictive AI; there are some common steps, but the order of tasks is different.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI用例开发的流程与预测式AI类似，但又不完全相同；有一些共同步骤，但任务顺序不同。
- en: The first step is the ideation of potential use cases. This selection needs
    to be balanced with business needs as satisfying them is our main objective.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是构思潜在用例。这一选择需要与业务需求相平衡，因为满足这些需求是我们的主要目标。
- en: With a clear problem definition in place, extensive analysis of published model
    benchmarks often informs the selection of a robust foundational model best suited
    for the task. In this step, it is worth asking ourselves the question is this
    use case better suited for a predictive model?
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在明确问题定义之后，对已发布模型基准的广泛分析通常有助于选择最适合该任务的稳健基础模型。在这一步，值得我们自问的问题是：这个用例更适合预测模型吗？
- en: As foundational models provide capabilities out of the box, initial testing
    comes as a step early in the process. A structured testing methodology helps reveal
    innate strengths, weaknesses, and quirks of a specific model. Both quantitative
    metrics and qualitative human evaluations fuel iterative improvement throughout
    the full development lifecycle.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 由于基础模型提供即插即用的功能，初始测试在流程中是一个早期步骤。结构化的测试方法有助于揭示特定模型的内在优势、劣势和怪癖。定量指标和定性的人类评估在整个开发生命周期中推动迭代改进。
- en: The next step is to move to the art of prompt engineering. Prompting is the
    mechanism used to interact with LLMs. Techniques like chain-of-thought prompting,
    skeleton prompts, and retrieval augmentation build guardrails enabling more consistent,
    logical outputs.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是转向提示工程的艺术。提示是与LLMs交互的机制。像思维链提示、骨架提示和检索增强等技术构建了护栏，使输出更加一致和逻辑。
- en: If gaps remain after prompt optimization, model enhancement via fine-tuning
    and distillation offers a precision tool to adapt models closer to the target
    task.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在优化后仍有差距，通过微调和蒸馏进行模型增强提供了一种精确的工具，以使模型更接近目标任务。
- en: In rare cases, pretraining a fully custom model from scratch is warranted when
    no existing model can viably serve the use case. However, it is important to keep
    in mind that due to the massive data requirements posed by model retraining, this
    task won’t be suitable for most use cases and teams; retraining a foundational
    model requires an extensive amount of data and processing power that makes the
    process unpractical from a financial and technical perspective.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在极少数情况下，当没有现有模型能够有效满足用例时，从头开始预训练一个完全定制的模型是必要的。然而，重要的是要记住，由于模型重新训练对数据的大量需求，这项任务对于大多数用例和团队来说可能并不适合；重新训练基础模型需要大量的数据和计算能力，从财务和技术角度来看，这个过程是不切实际的。
- en: Above all, the interplay between evaluation and model improvement underscores
    the deeply empirical nature of advancing generative AI responsibly. Testing often
    reveals that better solutions come from creativity in problem framing rather than
    pure technological advances alone.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，评估和模型改进之间的相互作用突出了负责任地推进生成性AI的深刻经验性质。测试通常表明，更好的解决方案来自问题框架的创造性，而不仅仅是纯技术进步。
- en: '![](img/B22175_01_03.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22175_01_03.png)'
- en: 'Figure 1.3: Predictive and generative AI development lifecycle side-by-side
    comparison'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3：预测性和生成性AI开发生命周期并排比较
- en: As we can see from the preceding figure, the development lifecycle is an iterative
    process that enables us to realize value from a given use case and technology
    type. Across the rest of this chapter and this book, we are going to focus on
    generative AI general concepts, some that are going to be familiar if you are
    experienced in predictive AI and others that are specific to this new field in
    AI.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，开发生命周期是一个迭代过程，使我们能够从给定的用例和技术类型中实现价值。在本章的其余部分和本书中，我们将关注生成性AI的一般概念，其中一些如果您在预测AI方面有经验将会熟悉，而其他则是AI这个新领域的特定概念。
- en: General generative AI concepts
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通用生成性AI概念
- en: When integrating generative AI into practical applications, it is important
    to have an understanding of concepts such as model architecture and training.
    In this section, we cover an overview of prominent concepts, including transformers,
    diffusion models, pre-training, and prompt engineering, that enable systems to
    generate impressively accurate text, images, audio, and more.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当将生成性AI集成到实际应用中时，了解诸如模型架构和训练等概念非常重要。在本节中，我们将概述一些突出概念，包括Transformer、扩散模型、预训练和提示工程，这些概念使系统能够生成令人印象深刻的高精度文本、图像、音频等。
- en: Understanding these core concepts will equip you to make informed decisions
    when selecting foundations for your use cases. However, putting models into production
    requires further architectural considerations. We will be highlighting these decision
    points in the rest of the chapters in the book and in practical examples.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这些核心概念将使您在选择用例的基础时做出明智的决定。然而，将模型投入生产需要进一步的架构考虑。本书的其余章节和实际示例中，我们将突出这些决策点。
- en: Generative AI model architectures
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成性AI模型架构
- en: Generative AI models are based on specialized neural network architectures optimized
    for generative tasks. The two more widely known models are transformers and diffusion
    models.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性AI模型基于针对生成任务优化的专用神经网络架构。两个更广为人知的模型是Transformer和扩散模型。
- en: '**Transformer models** are not a new concept. They were first introduced by
    Google in a 2017 paper called *Attention Is All You Need* ([https://arxiv.org/pdf/1706.03762.pdf](https://arxiv.org/pdf/1706.03762.pdf)).
    The paper explains the **Transformer neural network architecture**, which is entirely
    based on attention mechanisms using the encoder and decoder concepts. This architecture
    enables models to identify relationships across an input text. By having these
    relationships, the model predicts the next token, leveraging its previous prediction
    as an input, creating this recursive loop to generate new content.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**Transformer模型**不是一个新概念。它们首次由谷歌在2017年的一篇名为《Attention Is All You Need》的论文中提出([https://arxiv.org/pdf/1706.03762.pdf](https://arxiv.org/pdf/1706.03762.pdf))。这篇论文解释了**Transformer神经网络架构**，该架构完全基于使用编码器和解码器概念的注意力机制。这种架构使模型能够识别输入文本中的关系。通过这些关系，模型预测下一个标记，利用其之前的预测作为输入，创建这个递归循环以生成新内容。'
- en: '**Diffusion models** have drawn considerable interest as generative models
    due to their foundation in the physical processes of non-equilibrium thermodynamics.
    In physics, diffusion refers to the motion of particles from areas of high concentration
    to low concentration over time. Diffusion models try to mimic this concept in
    their training process. These models are trained through two phases: the **forward
    diffusion** process adds “noise” to the original training data, followed by a
    **reverse conditioning** process, which then learns how to remove noise in the
    reverse diffusion process. By learning this process, these models can produce
    samples by starting from pure noise and letting the reverse diffusion model clear
    away unnecessary “noise” and preserving the desired “generated” content.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**扩散模型**因其基于非平衡热力学物理过程的坚实基础而作为生成模型引起了相当大的兴趣。在物理学中，扩散是指粒子随时间从高浓度区域向低浓度区域的运动。扩散模型试图在其训练过程中模仿这一概念。这些模型通过两个阶段进行训练：**正向扩散**过程向原始训练数据添加“噪声”，随后是**反向条件化**过程，该过程学习如何在反向扩散过程中去除噪声。通过学习这个过程，这些模型可以从纯噪声开始，让反向扩散模型清除不必要的“噪声”，并保留所需的“生成”内容。'
- en: 'Other types of deep learning architectures, such as **Generative Adversarial
    Networks** (**GANs**), allow you to generate synthetic data based on existing
    data. GANs are useful because they leverage two models: one to generate a synthetic
    output and another one that tries to predict if this output is real or fake.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 其他类型的深度学习架构，如**生成对抗网络**（**GANs**），允许您根据现有数据生成合成数据。GANs很有用，因为它们利用两个模型：一个用于生成合成输出，另一个试图预测这个输出是真实还是虚假。
- en: Through this iterative process, we can generate data that is indistinguishable
    from the real data but different enough to be used to enhance our training datasets.
    Another example of data generation architectures is **Variational Autoencoders**
    (**VAEs**), which use an encoder-decoder approach to generate new data samples
    resembling their training datasets.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个迭代过程，我们可以生成与真实数据难以区分但足够不同的数据，以便用于增强我们的训练数据集。数据生成架构的另一个例子是**变分自编码器**（**VAEs**），它使用编码器-解码器方法来生成与训练数据集相似的新数据样本。
- en: Techniques available to optimize foundational models
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可用于优化基础模型的技术
- en: 'There are several techniques used to develop and optimize foundational models
    that have driven significant gains in AI capabilities, some of which are more
    complex than others from a technical and monetary perspective:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种技术被用来开发和优化基础模型，这些技术推动了人工智能能力的显著提升，其中一些在技术和经济方面比其他技术更复杂：
- en: '**Pre-training** refers to fully training a model on a large dataset. It allows
    models to learn very broad representations from billions of data points, which
    help the model adapt to other closely related tasks. Popular methods include contrastive
    self-supervised pre-training on unlabeled data and pre-training on vast supervised
    data like the internet.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预训练**是指在大型数据集上完全训练一个模型。这允许模型从数十亿个数据点中学习非常广泛的表现形式，这有助于模型适应其他密切相关任务。流行的方法包括在未标记数据上的对比自监督预训练和在大量监督数据（如互联网）上的预训练。'
- en: '**Fine-tuning** adapts a pre-trained model’s already learned feature representations
    to perform a specific task. This only tunes some higher-level model layers rather
    than training from scratch. On the other hand, adapter tuning equips models with
    small, lightweight adapters that can rapidly tune to new tasks without interfering
    with existing capabilities. These pluggable adapters give a parameter-efficient
    way of accumulating knowledge across multiple tasks by learning task-specific
    behaviors while reusing the bulk of model weights. They help mitigate forgetting
    previous tasks and simplify personalization. For example, models may first be
    pre-trained on billions of text webpages to acquire general linguistic knowledge,
    before being fine-tuned on more domain-specific datasets for question answering,
    classification, etc.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微调**将预训练模型已经学习到的特征表示调整为执行特定任务。这仅调整一些高级模型层，而不是从头开始训练。另一方面，适配器微调为模型配备了小型、轻量级的适配器，这些适配器可以快速调整到新任务，而不会干扰现有功能。这些可插拔的适配器通过学习特定任务的行为同时重用大部分模型权重，以参数高效的方式在多个任务中积累知识。它们有助于减轻对先前任务的遗忘并简化个性化。例如，模型可能首先在数十亿个文本网页上进行预训练，以获取一般语言知识，然后针对更特定领域的数据集进行微调，用于问答、分类等。'
- en: '**Distillation** uses a “teacher” model to train a smaller “student” model
    to reproduce the performance of the larger pre-trained model at a lower cost and
    latency. Quantizing and compressing large models into efficient forms for deployments
    also helps optimize performance and cost.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**蒸馏**使用“教师”模型训练一个较小的“学生”模型，以在较低的成本和延迟下重现较大预训练模型的性能。将大型模型量化并压缩成高效的部署形式也有助于优化性能和成本。'
- en: The combination of comprehensive pre-training followed by specialized fine-tuning,
    adapter tuning, and portable distillation has enabled unprecedented versatility
    of deep learning across domains. Each approach smartly reuses and transfers available
    knowledge, enabling the customization and scaling of generative AI.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 综合预训练后跟随着专门的微调、适配器调整和可移植蒸馏的结合，使得深度学习在各个领域的应用具有前所未有的灵活性。每种方法都智能地重用和转移现有知识，从而实现生成式AI的定制和扩展。
- en: Techniques to augment your foundational model responses
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 增强基础模型响应的技术
- en: In addition to architecture and training advances, progress in generative AI
    has been fueled by innovations in how these models are augmented by external data
    at inference time.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 除了架构和训练的进步之外，生成式AI的进展还受到了在推理时如何通过外部数据增强这些模型的方法创新所推动。
- en: '**Prompt engineering** tunes the text prompts provided to models to steer their
    generation quality, capabilities, and properties. Well-designed prompts guide
    the model to produce the desired output format, reduce ambiguity, and provide
    helpful contextual constraints. This allows simpler model architectures to solve
    complex problems by encoding human knowledge into the prompts.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**提示工程**调整提供给模型的文本提示，以引导其生成质量、能力和属性。精心设计的提示指导模型产生期望的输出格式，减少歧义，并提供有用的上下文约束。这允许更简单的模型架构通过将人类知识编码到提示中来解决复杂问题。'
- en: '**Retrieval augmented generation**, also known as **RAG**, enhances text generation
    through efficient retrieval of relevant knowledge from external stores. Models
    receive contextual pieces of information as “context” to be considered as additional
    input before generating its output. **Grounding** LLMs (large language models)
    refers to providing model-specific factual knowledge rather than just model parameters,
    enabling more accurate, knowledgeable, and specific language generation.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**检索增强生成**，也称为**RAG**，通过从外部存储中高效检索相关知识来增强文本生成。模型在生成输出之前接收作为“上下文”的上下文信息片段，作为额外的输入。**基于事实学习**LLM（大型语言模型）指的是提供模型特定的实际知识，而不仅仅是模型参数，从而实现更准确、知识渊博和具体的语言生成。'
- en: 'Together, these approaches augment basic predictive language models to become
    far more versatile, robust, and scalable. They reduce brittleness via tight integration
    of human knowledge and grounded learning rather than just statistical patterns.
    RAG handles the breadth and real-time retrieval of information, prompts provide
    depth and rules to the desired outputs, and grounding binds them to reality. We
    would highly encourage readers to get familiar with this topic, as it is an industry
    best practice to perform RAG and to ground your model to prevent it from hallucinating.
    A good start is the following paper: *Retrieval-Augmented Generation for Large
    Language Models: A Survey* ([https://arxiv.org/pdf/2312.10997](https://arxiv.org/pdf/2312.10997)).'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法共同增强了基本的预测语言模型，使其变得更加灵活、健壮和可扩展。它们通过紧密集成人类知识和基于事实的学习来减少脆弱性，而不仅仅是统计模式。RAG处理信息的广度和实时检索，提示提供深度和规则以指导期望的输出，而基于事实的学习将它们与现实世界联系起来。我们强烈建议读者熟悉这个主题，因为进行RAG并将模型基于事实来防止其产生幻觉是行业最佳实践。一个好的起点是以下这篇论文：*检索增强生成对于大型语言模型的调查*
    ([https://arxiv.org/pdf/2312.10997](https://arxiv.org/pdf/2312.10997))。
- en: Constant evolution across the generative AI space
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式AI领域的持续进化
- en: The generative AI space is characterized by relentless innovation and rapid
    advancement across model architectures, applications, and ethical considerations.
    As soon as one method or architecture shows promising results, hundreds of competing
    and complementary approaches emerge to push capabilities even further. Transformers
    gave way to BERT, which was outpaced by GPT-3, soon rivaled by image synthesizers
    like DALL-E, and now GPT-4 and Gemini are competing for the top spot. All of which
    happened in the past few years.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI领域以不懈的创新和快速进步为特征，涉及模型架构、应用和伦理考量。一旦一种方法或架构显示出有希望的结果，就会有数百种竞争性和互补的方法出现，以进一步推动能力。Transformer让位于BERT，而BERT又很快被GPT-3超越，随后又被像DALL-E这样的图像合成器所超越，现在GPT-4和Gemini正在争夺头把交椅。所有这些都在过去几年内发生。
- en: Meanwhile, we are seeing new modalities like audio, video, and 3D scene generation
    gaining vast popularity and usability. On the business front, new services are
    launched monthly, targeting media and entertainment, finance, healthcare, art,
    code, music, and more. However, considerations around ethics, access control,
    and legalities are key in order to maintain public trust.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，我们看到了新的模式，如音频、视频和3D场景生成，获得了巨大的流行度和可用性。在商业领域，每月都有新的服务推出，针对媒体和娱乐、金融、医疗保健、艺术、代码、音乐等领域。然而，考虑到道德、访问控制和法律问题，以维持公众信任是关键。
- en: One breakthrough enables several more, and each unlocks added potential. This
    self-fueling cycle arises from the very nature of AI – its ability to recursively
    assist innovation. The only certainty is that the field will look very different
    within months, not years. Maintaining awareness, responsiveness, and responsibility
    is critical amid this constant evolution.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一个突破使得更多的突破成为可能，每个突破都释放了额外的潜力。这种自我加速的循环源于AI的本质——其递归协助创新的能力。唯一确定的是，几个月内该领域将非常不同，而不是几年。在这种持续的演变中，保持意识、反应性和责任感至关重要。
- en: Introducing generative AI integration patterns
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍生成式AI集成模式
- en: Let’s now assume you already have a promising use case in mind. As I’m sure
    you would agree, clearly defining the use case is critical before proceeding further.
    You’ve already identified which foundational model provides acceptable performance
    for your needs. So now you’re starting to consider how GenAI fits into the application
    development process.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在假设您已经有一个有希望的应用场景在心中。正如我确信您会同意的那样，在进一步进行之前，明确定义用例至关重要。您已经确定了哪种基础模型能够满足您的需求。因此，现在您开始考虑GenAI如何融入应用程序开发过程。
- en: At a high level, there are two main workflows for integrating applications with
    GenAI. One is **real time**, where you’ll typically interact with an end user
    or AI agent, providing responses as prompts come in. The second is **batch processing**,
    where requirements are bundled up and processed in groups (batches).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，有两种主要的流程用于将应用程序与GenAI集成。一种是**实时**，在这种情况下，您通常与最终用户或AI代理互动，在提示到来时提供响应。第二种是**批量处理**，其中需求被捆绑成组（批量）进行处理。
- en: A prime example of a real-time workflow would be a chatbot. Here, prompts from
    the user are processed and then sent to the model and the responses are returned
    immediately, as you need to consume the outputs without delay. On the other hand,
    consider a data enrichment use case for batch processing. You could collect multiple
    data points over time for later consumption after being enriched by the model
    in batches.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一个实时工作流程的典型例子是聊天机器人。在这里，用户的提示被处理，然后发送到模型，并立即返回响应，因为您需要不延迟地消费输出。另一方面，考虑批量处理的数据丰富用例。您可以在一段时间内收集多个数据点，然后在模型批量丰富后进行后续消费。
- en: In this book, we will explore these integration patterns through practical examples.
    This will help you to obtain hands-on experience with GenAI-driven applications
    and allow you to integrate these patterns in your own use cases.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们将通过实际例子来探讨这些集成模式。这将帮助您获得与GenAI驱动应用程序的动手经验，并允许您在自己的用例中集成这些模式。
- en: By “integration pattern,” we refer to a standardized architectural approach
    for incorporating a technology into your application or system. In this context,
    integration patterns provide proven methods for connecting generative AI models
    to real-world software.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 通过“集成模式”，我们指的是将技术集成到您的应用程序或系统中的标准化架构方法。在这种情况下，集成模式提供了将生成式AI模型连接到现实世界软件的成熟方法。
- en: 'There are a few key reasons why we need integration patterns when working with
    generative AI:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个关键原因说明为什么在处理生成式AI时我们需要集成模式：
- en: '**Time savings**: Following established patterns allows developers to avoid
    reinventing the wheel for common integration challenges. This accelerates time
    to value.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节省时间**：遵循既定模式允许开发者避免为常见的集成挑战重新发明轮子。这加快了价值实现的进程。'
- en: '**Improving quality**: Leveraging best practices encoded in integration patterns
    leads to more robust, production-grade integrations. Things like scalability,
    security, and reliability are top of mind.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提高质量**：利用集成模式中编码的最佳实践，可以导致更稳健、适用于生产的集成。可扩展性、安全性和可靠性是首要考虑的因素。'
- en: '**Reducing risk**: Well-defined integration patterns enable developers to mitigate
    risks around performance, costs, and other pitfalls that can emerge when integrating
    new technologies.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**降低风险**：定义良好的集成模式使开发者能够减轻性能、成本和其他潜在风险，这些风险可能在集成新技术时出现。'
- en: Overall, integration patterns deliver templates and guardrails, so developers
    don’t have to start integration efforts from scratch. By relying on proven blueprints,
    readers can integrate generative AI more efficiently while avoiding common mistakes.
    This speeds up development cycles significantly and sets integrations up for long-term
    success.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，集成模式提供了模板和指导方针，因此开发者不必从头开始集成工作。通过依赖经过验证的蓝图，读者可以更有效地集成生成式AI，同时避免常见的错误。这显著加快了开发周期，并为长期成功奠定了基础。
- en: Summary
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered an overview of key concepts, techniques, and integration
    patterns related to generative AI. You now have a high-level background on prominent
    generative AI model architectures like transformers and diffusion models, as well
    as various methods for developing and enhancing these models, covering pre-training,
    fine-tuning, adapter tuning, distillation, prompt engineering, retrieval augmented
    generation, and grounding.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们概述了与生成式AI相关的关键概念、技术和集成模式。现在，您对像transformers和扩散模型这样的突出生成式AI模型架构有了高级背景知识，以及开发和完善这些模型的各种方法，包括预训练、微调、适配器调整、蒸馏、提示工程、检索增强生成和归一化。
- en: We discussed how rapid innovation in generative AI leads to constant evolution,
    with new models and capabilities emerging at a fast pace. It emphasizes the need
    to keep pace with progress while ensuring ethical, responsible development.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了生成式AI的快速创新如何导致持续进化，新模型和能力以快速的速度出现。这强调了在确保道德、负责任发展的同时，保持与进步同步的必要性。
- en: Finally, we introduced common integration patterns for connecting generative
    AI to real-world applications, considering real-time use cases like chatbots as
    well as batch processing for data enrichment. Real examples were provided to demonstrate
    workflows for integrating generative models into production systems.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们介绍了将生成式AI连接到现实世界应用的常见集成模式，考虑到实时用例，如聊天机器人，以及用于数据丰富化的批量处理。提供了真实示例来展示将生成模型集成到生产系统中的工作流程。
- en: Innovation in AI has a very fast pace, demanding constant awareness, swift experimentation,
    and a responsible approach to harnessing the latest advances. This is particularly
    evident in the field of generative AI, where we’re witnessing a paradigm shift
    in AI-powered applications that allows for faster experimentation and development.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能的创新步伐非常快，需要持续的警觉、迅速的实验和负责任地利用最新进展的方法。这在生成式AI领域尤为明显，我们正在见证人工智能应用中的范式转变，这允许更快地进行实验和开发。
- en: A wide array of techniques has emerged to enhance models’ capabilities and efficiency.
    These include pre-training, adapter tuning, distillation, and prompt engineering,
    each offering unique advantages in different scenarios. When it comes to integrating
    these AI models into practical applications, key patterns have emerged for both
    real-time workflows, such as chatbots, and batch processing tasks like data enrichment.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 出现了各种技术来增强模型的能力和效率。这包括预训练、适配器调整、蒸馏和提示工程，每种技术在不同场景中都有独特的优势。当涉及到将这些AI模型集成到实际应用中时，对于实时工作流程，如聊天机器人，以及批量处理任务，如数据丰富化，都出现了关键模式。
- en: The art of crafting well-designed prompts has become crucial in constraining
    and steering model outputs effectively. Additionally, techniques like retrieval
    augmentation and grounding have proven invaluable in improving the accuracy of
    AI-generated content. The potential in blending predictive and generative approaches
    is a very interesting space. This combination leverages the strengths of both
    methodologies, allowing for custom modeling where sufficient data exists while
    utilizing generative foundations to enable rapid prototyping and innovation.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 设计良好提示的艺术已成为有效约束和引导模型输出的关键。此外，检索增强和扎根等技术在提高AI生成内容准确性方面已被证明非常有价值。将预测和生成方法相结合的潜力是一个非常有趣的空间。这种组合利用了两种方法的优势，允许在存在足够数据的情况下进行定制建模，同时利用生成基础来实现快速原型设计和创新。
- en: These core concepts empower informed decision-making when architecting generative
    AI systems. The integration patterns offer blueprints for connecting models to
    practical applications across diverse domains.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这些核心概念在构建生成式AI系统时，能够支持明智的决策制定。集成模式为将模型连接到不同领域的实际应用提供了蓝图。
- en: Harnessing the power of LLMs begins with identifying the right use cases where
    they can drive value for your business. In the next chapter, we will present a
    framework and examples for categorizing LLM use cases based on projected business
    value.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 利用大型语言模型（LLM）的力量，首先在于识别适合它们发挥价值的正确用例。在下一章中，我们将介绍一个框架和示例，用于根据预期的商业价值对LLM用例进行分类。
- en: In the next chapter, we will explore identifying use cases that can be solved
    with Generative AI.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨如何识别可以用生成式AI解决的问题。
- en: Join our community on Discord
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord社区
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的Discord空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/genpat](https://packt.link/genpat)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/genpat](https://packt.link/genpat)'
- en: '![](img/QR_Code134841911667913109.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code134841911667913109.png)'
