- en: Recognizing traffic signs using Convnets
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用卷积神经网络（ConvNets）识别交通标志
- en: 'As the first project of the book, we''ll try to work on a simple model where
    deep learning performs very well: traffic sign recognition. Briefly, given a color
    image of a traffic sign, the model should recognize which signal it is. We will
    explore the following areas:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 作为本书的第一个项目，我们将尝试构建一个简单的模型，在深度学习表现非常好的领域：交通标志识别。简而言之，给定一张交通标志的彩色图像，模型应能识别出它是哪种标志。我们将探讨以下几个方面：
- en: How the dataset is composed
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集的组成方式
- en: Which deep network to use
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用哪个深度网络
- en: How to pre-process the images in the dataset
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何预处理数据集中的图像
- en: How to train and make predictions with an eye on performance
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何训练并关注性能进行预测
- en: The dataset
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集
- en: Since we'll try to predict some traffic signs using their images, we will use
    a dataset built for the same purpose. Fortunately, researchers of Institute für
    Neuroinformatik, Germany, created a dataset containing almost 40,000 images, all
    different and related to 43 traffic signs. The dataset we will use is part of
    a competition named **German Traffic Sign Recognition Benchmark** (**GTSRB**),
    which attempted to score the performance of multiple models for the same goal.
    The dataset is pretty old—2011! But it looks like a nice and well-organized dataset
    to start our project from.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将尝试通过图像预测一些交通标志，因此我们将使用一个为此目的而创建的数据集。幸运的是，德国神经信息学研究所的研究人员创建了一个包含近 40,000
    张图像的数据集，所有图像都不同，且与 43 个交通标志相关。我们将使用的数据集是名为 **德国交通标志识别基准**（**GTSRB**）的一部分，该基准旨在对多个模型的表现进行评分，目标都是相同的。这个数据集已经相当旧了——2011
    年！但看起来它是一个很不错且组织良好的数据集，适合我们从中启动项目。
- en: The dataset used in this project is freely available at [http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Training_Images.zip](http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Training_Images.zip).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目使用的数据集可以在 [http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Training_Images.zip](http://benchmark.ini.rub.de/Dataset/GTSRB_Final_Training_Images.zip)
    免费获取。
- en: Before you start running the code, please download the file and unpack it in
    the same directory as the code. After decompressing the archive, you'll have a
    new folder, named GTSRB, containing the dataset.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在你开始运行代码之前，请先下载文件并将其解压到与代码相同的目录下。解压完压缩包后，你将得到一个名为 GTSRB 的新文件夹，里面包含了数据集。
- en: The authors of the book would like to thank those who worked on the dataset
    and made it open source.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的作者感谢那些参与数据集制作并使其开源的人们。
- en: Also, refer [http://cs231n.github.io/convolutional-networks/](http://cs231n.github.io/convolutional-networks/)
    to learn more about CNN.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，可以参考 [http://cs231n.github.io/convolutional-networks/](http://cs231n.github.io/convolutional-networks/)
    了解更多关于 CNN 的信息。
- en: 'Let''s now see some examples:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一些示例：
- en: '"Speed limit 20 km/h":'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: “限速 20 公里/小时”：
- en: '![](img/fccc98ce-8fa7-42b6-b84a-0c099ce0f4a6.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fccc98ce-8fa7-42b6-b84a-0c099ce0f4a6.png)'
- en: '"go straight or turn right":'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: “直行或右转”：
- en: '![](img/0af10cb0-4f00-4137-bf30-68fefc3df1df.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0af10cb0-4f00-4137-bf30-68fefc3df1df.png)'
- en: '"roundabout":'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: “环形交叉口”：
- en: '![](img/45a70e63-353a-485d-8006-2662616623cc.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/45a70e63-353a-485d-8006-2662616623cc.png)'
- en: As you can see, the signals don't have a uniform brightness (some are very dark
    and some others are very bright), they're different in size, the perspective is
    different, they have different backgrounds, and they may contain pieces of other
    traffic signs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这些信号的亮度不统一（有些非常暗，有些则非常亮），它们的大小不同，透视不同，背景不同，而且可能包含其他交通标志的部分图像。
- en: 'The dataset is organized in this way: all the images of the same label are
    inside the same folder. For example, inside the path `GTSRB/Final_Training/Images/00040/`,
    all the images have the same label, `40`. For the images with another label, `5`,
    open the folder `GTSRB/Final_Training/Images/00005/`. Note also that all the images
    are in PPM format, a lossless compression format for images with many open source
    decoders/encoders.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的组织方式是这样的：同一标签的所有图像都在同一个文件夹内。例如，在路径 `GTSRB/Final_Training/Images/00040/`
    中，所有的图像都有相同的标签 `40`。如果图像的标签是另一个标签 `5`，请打开文件夹 `GTSRB/Final_Training/Images/00005/`。还要注意，所有图像都是
    PPM 格式，这是一种无损压缩格式，适用于图像，并且有许多开源解码器/编码器可以使用。
- en: The CNN network
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）
- en: 'For our project, we will use a pretty simple network with the following architecture:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的项目，我们将使用一个非常简单的网络，具有以下架构：
- en: '![](img/ed38d09a-6f57-4af7-bf66-8224e098e188.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed38d09a-6f57-4af7-bf66-8224e098e188.png)'
- en: 'In this architecture, we still have the choice of:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个架构中，我们仍然有以下选择：
- en: The number of filters and kernel size in the 2D convolution
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2D 卷积中的滤波器数量和核大小
- en: The kernel size in the Max pool
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大池化中的核大小
- en: The number of units in the Fully Connected layer
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全连接层中的单元数
- en: The batch size, optimization algorithm, learning step (eventually, its decay
    rate), activation function of each layer, and number of epochs
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批处理大小、优化算法、学习步长（最终其衰减率）、每层的激活函数以及训练的轮数
- en: Image preprocessing
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像预处理
- en: The first operation of the model is reading the images and standardizing them.
    In fact, we cannot work with images of variable sizes; therefore, in this first
    step, we'll load the images and reshape them to a predefined size (32x32). Moreover,
    we will one-hot encode the labels in order to have a 43-dimensional array where
    only one element is enabled (it contains a 1), and we will convert the color space
    of the images from RGB to grayscale. By looking at the images, it seems obvious
    that the information we need is not contained in the color of the signal but in
    its shape and design.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的第一个操作是读取图像并进行标准化。事实上，我们无法处理大小不一的图像；因此，在这第一步中，我们将加载图像并将其调整为预定义的大小（32x32）。此外，我们将对标签进行独热编码，以便生成一个
    43 维的数组，其中只有一个元素被激活（即值为 1），同时我们会将图像的颜色空间从 RGB 转换为灰度图像。从图像中可以明显看出，我们需要的信息不在信号的颜色中，而是在其形状和设计中。
- en: 'Let''s now open a Jupyter Notebook and place some code to do that. First of
    all, let''s create some final variables containing the number of classes (43)
    and the size of the images after being resized:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们打开一个 Jupyter Notebook，并编写一些代码来完成这项工作。首先，我们创建一些包含类别数量（43）和调整大小后图像大小的最终变量：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we will write a function that reads all the images given in a path, resize
    them to a predefined shape, convert them to grayscale, and also one-hot encode
    the label. In order to do that, we''ll use a named tuple named `dataset`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将编写一个函数，读取指定路径中的所有图像，将其调整为预定义的形状，转换为灰度图像，并进行独热编码标签。为此，我们将使用一个名为 `dataset`
    的命名元组：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Thanks to the skimage module, the operation of reading, transforming, and resizing
    is pretty easy. In our implementation, we decided to convert the original color
    space (RGB) to lab, then retaining only the luminance component. Note that another
    good conversion here is YUV, where only the "Y" component should be retained as
    a grayscale image.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 得益于 skimage 模块，读取、转换和调整大小的操作变得非常简单。在我们的实现中，我们决定将原始的颜色空间（RGB）转换为 lab，然后仅保留亮度成分。请注意，另一个好的转换是
    YUV，其中应该保留“Y”分量作为灰度图像。
- en: 'Running the preceding cell gives this:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上面的单元格会得到以下结果：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'One note about the output format: the shape of the observation matrix *X* has
    four dimensions. The first indexes the observations (in this case, we have almost
    40,000 of them); the other three dimensions contain the image (which is 32 pixel,
    by 32 pixels grayscale, that is, one-dimensional). This is the default shape when
    dealing with images in TensorFlow (see the code `_tf_format` function).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 关于输出格式的一个说明：观察矩阵*X*的形状有四个维度。第一个维度是观察值的索引（在这种情况下，我们有大约 40,000 个样本）；其他三个维度包含图像（其大小为
    32 像素 × 32 像素的灰度图像，也就是一维的）。这是在 TensorFlow 中处理图像时的默认形状（参见代码中的 `_tf_format` 函数）。
- en: As for the label matrix, the rows index the observation, while the columns are
    the one-hot encoding of the label.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 至于标签矩阵，行是观察的索引，列是标签的独热编码。
- en: 'In order to have a better understanding of the observation matrix, let''s print
    the feature vector of the first sample, together with its label:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解观察矩阵，让我们打印第一个样本的特征向量以及它的标签：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![](img/244954aa-b5cb-45a5-a0be-8b4576ff5a95.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/244954aa-b5cb-45a5-a0be-8b4576ff5a95.png)'
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You can see that the image, that is, the feature vector, is 32x32\. The label
    contains only one `1` in the first position.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到图像，也就是特征向量，是 32x32 的。标签仅在第一个位置包含一个 `1`。
- en: 'Let''s now print the last sample:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们打印最后一个样本：
- en: '[PRE5]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![](img/255c7721-64e7-411f-8020-b03bab04a1db.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/255c7721-64e7-411f-8020-b03bab04a1db.png)'
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The feature vector size is the same (32x32), and the label vector contains one
    `1` in the last position.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 特征向量的大小相同（32x32），而标签向量在最后一个位置包含一个 `1`。
- en: These are the two pieces of information we need to create the model. Please,
    pay particular attention to the shapes, because they're crucial in deep learning
    while working with images; in contrast to classical machine learning observation
    matrices, here the *X* has four dimensions!
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们需要创建模型的两项信息。请特别注意形状，因为它们在深度学习中处理图像时至关重要；与经典机器学习中的观察矩阵不同，这里的*X*有四个维度！
- en: 'The last step of our preprocessing is the train/test split. We want to train
    our model on a subset of the dataset, and then measure the performance on the
    leftover samples, that is, the test set. To do so, let''s use the function provided
    by `sklearn`:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们预处理的最后一步是训练/测试集拆分。我们希望在数据集的一个子集上训练我们的模型，然后在剩余的样本上衡量模型的表现，即测试集。为此，让我们使用`sklearn`提供的函数：
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In this example, we''ll use 75% of the samples in the dataset for training
    and the remaining 25% for testing. In fact, here''s the output of the previous
    code:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用数据集中75%的样本用于训练，剩下的25%用于测试。事实上，下面是前一个代码的输出：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Train the model and make predictions
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练模型并进行预测
- en: 'The first thing to have is a function to create minibatches of training data.
    In fact, at each training iteration, we''d need to insert a minibatch of samples
    extracted from the training set. Here, we''ll build a function that takes the
    observations, labels, and batch size as arguments and returns a minibatch generator.
    Furthermore, to introduce some variability in the training data, let''s add another
    argument to the function, the possibility to shuffle the data to have different
    minibatches of data for each generator. Having different minibatches of data in
    each generator will force the model to learn the in-out connection and not memorize
    the sequence:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 首先需要一个函数来创建训练数据的小批量。事实上，在每次训练迭代时，我们都需要插入从训练集中提取的小批量样本。在这里，我们将构建一个函数，该函数以观察值、标签和批量大小作为参数，并返回一个小批量生成器。此外，为了在训练数据中引入一些变异性，让我们向函数中添加另一个参数，即可以选择是否打乱数据，从而为每个生成器提供不同的小批量数据。每个生成器中不同的小批量数据将迫使模型学习输入输出连接，而不是记住序列：
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'To test this function, let''s print the shapes of minibatches while imposing
    `batch_size=10000`:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试这个函数，让我们打印出小批量的形状，同时设置`batch_size=10000`：
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'That prints the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印出以下内容：
- en: '[PRE11]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Unsurprisingly, the 29,406 samples in the training set are split into two minibatches
    of 10,000 elements, with the last one of `9406` elements. Of course, there are
    the same number of elements in the label matrix too.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，训练集中的29,406个样本被分成两个小批量，每个小批量包含10,000个元素，最后一个小批量包含`9406`个元素。当然，标签矩阵中也有相同数量的元素。
- en: 'It''s now time to build the model, finally! Let''s first build the blocks that
    will compose the network. We can start creating the fully connected layer with
    a variable number of units (it''s an argument), without activation. We''ve decided
    to use Xavier initialization for the coefficients (weights) and 0-initialization
    for the biases to have the layer centered and scaled properly. The output is simply
    the multiplication of the input tensor by the weights, plus the bias. Please take
    a look at the dimensionality of the weights, which is defined dynamically, and
    therefore can be used anywhere in the network:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在终于到了构建模型的时候！让我们首先构建组成网络的各个模块。我们可以从创建一个带有可变数量单元的全连接层开始（这是一个参数），并且没有激活函数。我们决定使用Xavier初始化来初始化系数（权重），并使用0初始化来初始化偏置，以便使得该层居中并正确缩放。输出只是输入张量与权重的乘积，加上偏置。请注意，权重的维度是动态定义的，因此可以在网络中的任何位置使用：
- en: '[PRE12]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s now create the fully connected layer with activation; specifically,
    here we will use the leaky ReLU. As you can see, we can build this function using
    the previous one:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个带有激活函数的全连接层；具体来说，我们将使用泄漏ReLU。正如你所看到的，我们可以使用之前的函数来构建这个功能：
- en: '[PRE13]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Finally, let''s create a convolutional layer that takes as arguments the input
    data, kernel size, and number of filters (or units). We will use the same activations
    used in the fully connected layer. In this case, the output passes through a leaky
    ReLU activation:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们创建一个卷积层，接受输入数据、卷积核大小和滤波器数量（或单元）作为参数。我们将使用与全连接层相同的激活函数。在这种情况下，输出将通过一个泄漏ReLU激活：
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, it''s time to create a `maxpool_layer`. Here, the size of the window and
    the strides are both squares (quadrates):'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候创建一个`maxpool_layer`了。在这里，窗口大小和步幅都是正方形的（矩阵）：
- en: '[PRE15]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The last thing to define is the dropout, used for regularizing the network.
    Pretty simple thing to create, but remember that dropout should only be used when
    training the network, and not when predicting the outputs; therefore, we need
    to have a conditional operator to define whether to apply dropouts or not:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最后需要定义的是dropout，用于正则化网络。创建起来相当简单，但请记住，dropout只应在训练网络时使用，而不应在预测输出时使用；因此，我们需要使用条件操作符来定义是否应用dropout：
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Finally, it''s time to put it all together and create the model as previously
    defined. We''ll create a model composed of the following layers:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，是时候将所有内容整合起来，按照之前定义的创建模型。我们将创建一个由以下层组成的模型：
- en: 2D convolution, 5x5, 32 filters
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2D 卷积，5x5，32 个过滤器
- en: 2D convolution, 5x5, 64 filters
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2D 卷积，5x5，64 个过滤器
- en: Flattenizer
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 展平器
- en: Fully connected later, 1,024 units
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 全连接层，1,024 个单元
- en: Dropout 40%
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Dropout 40%
- en: Fully connected layer, no activation
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 全连接层，无激活函数
- en: Softmax output
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Softmax 输出
- en: 'Here''s the code:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这是代码：
- en: '[PRE17]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: And now, let's write the function to train the model on the training set and
    test the performance on the test set. Please note that all of the following code
    belongs to the function `train_model` function; it's broken down in to pieces
    just for simplicity of explanation.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们编写一个函数，在训练集上训练模型并测试测试集上的表现。请注意，以下所有代码都属于 `train_model` 函数；它被拆解为几个部分，以便于解释。
- en: 'The function takes as arguments (other than the training and test sets and
    their labels) the learning rate, the number of epochs, and the batch size, that
    is, number of images per training batch. First things first, some TensorFlow placeholders
    are defined: one for the minibatch of images, one for the minibatch of labels,
    and the last one to select whether to run for training or not (that''s mainly
    used by the dropout layer):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数的参数包括（除了训练集、测试集及其标签）学习率、周期数和批次大小，也就是每个训练批次的图像数量。首先，定义了一些 TensorFlow 占位符：一个用于图像的迷你批次，一个用于标签的迷你批次，最后一个用于选择是否进行训练（这主要由
    dropout 层使用）：
- en: '[PRE18]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, let''s define the output, metric score, and optimizer. Here, we decided
    to use the `AdamOptimizer` and the cross entropy with `softmax(logits)` as loss:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们定义输出、度量分数和优化器。在这里，我们决定使用 `AdamOptimizer` 和交叉熵损失函数与 `softmax(logits)`：
- en: '[PRE19]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'And finally, here''s the code for training the model with minibatches:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这里是使用迷你批次训练模型的代码：
- en: '[PRE20]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After the training, it''s time to test the model on the test set. Here, instead
    of sending a minibatch, we will use the whole test set. Mind it! `is_training` should
    be set as `False` since we don''t want to use the dropouts:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 训练完成后，接下来就是在测试集上测试模型。这里，我们将使用整个测试集，而不是发送迷你批次。注意！`is_training` 应该设置为 `False`，因为我们不想使用
    dropout：
- en: '[PRE21]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'And, as a final operation, let''s print the classification report and plot
    the confusion matrix (and its `log2` version) to see the misclassifications:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步，打印分类报告并绘制混淆矩阵（及其 `log2` 版本），查看误分类情况：
- en: '[PRE22]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, let''s run the function with some parameters. Here, we will run the
    model with a learning step of 0.001, 256 samples per minibatch, and 10 epochs:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们用一些参数运行这个函数。在这里，我们将使用学习步长为 0.001，单次批次 256 个样本，以及 10 个周期来运行模型：
- en: '[PRE23]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here''s the output:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '[PRE24]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This is followed by the classification report per class:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是每个类别的分类报告：
- en: '[PRE25]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As you can see, we managed to reach a precision of `0.99` on the test set; also,
    recall and f1 score have the same score. The model looks stable since the loss
    in the test set is similar to the one reported in the last iteration; therefore,
    we're not over-fitting nor under-fitting.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们成功在测试集上达到了 `0.99` 的准确率；同时，召回率和 F1 分数也达到了相同的分数。模型看起来很稳定，因为测试集中的损失值与最后一次迭代报告的损失值相似；因此，我们既没有过拟合也没有欠拟合。
- en: 'And the confusion matrices:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以及混淆矩阵：
- en: '![](img/1133d1f1-0f4e-49f0-9102-dae691a5c4f2.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1133d1f1-0f4e-49f0-9102-dae691a5c4f2.png)'
- en: 'The following is the `log2` version of preceding screenshot:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前述截图的 `log2` 版本：
- en: '![](img/8b1e724e-aa03-4b01-a9d2-22f38c6089d1.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b1e724e-aa03-4b01-a9d2-22f38c6089d1.png)'
- en: Follow-up questions
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 后续问题
- en: Try adding/removing some CNN layers and/or fully connected layers. How does
    the performance change?
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试添加/移除一些 CNN 层和/或全连接层。性能如何变化？
- en: This simple project is proof that dropouts are necessary for regularization.
    Change the dropout percentage and check the overfitting-underfitting in the output.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个简单的项目证明了 dropout 对于正则化是必要的。改变 dropout 百分比，并检查输出中的过拟合与欠拟合情况。
- en: Now, take a picture of multiple traffic signs in your city, and test the trained
    model in real life!
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，拍一张你所在城市的多个交通标志的照片，并在现实生活中测试训练好的模型！
- en: Summary
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we saw how to recognize traffic signs using a convolutional
    neural network, or CNN. In the next chapter, we'll see something more complex
    that can be done with CNNs.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用卷积神经网络（CNN）识别交通标志。在下一章中，我们将看到 CNN 可以做的一些更复杂的事情。
