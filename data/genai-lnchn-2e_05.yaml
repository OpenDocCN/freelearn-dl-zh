- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Building Intelligent RAG Systems
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建智能 RAG 系统
- en: So far in this book, we’ve talked about LLMs and tokens and working with them
    in LangChain. **Retrieval-Augmented Generation** (**RAG**) extends LLMs by dynamically
    incorporating external knowledge during generation, addressing limitations of
    fixed training data, hallucinations, and context windows. A RAG system, in simple
    terms, takes a query, converts it directly into a semantic vector embedding, runs
    a search extracting relevant documents, and passes these to a model that generates
    a context-appropriate user-facing response.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在这本书中，我们讨论了 LLMs、标记以及如何在 LangChain 中与他们一起工作。**检索增强生成**（**RAG**）通过在生成过程中动态地结合外部知识来扩展
    LLMs，解决了固定训练数据、幻觉和上下文窗口的限制。简单来说，RAG 系统接收一个查询，直接将其转换为语义向量嵌入，运行搜索提取相关文档，并将这些文档传递给生成上下文适当的用户响应的模型。
- en: This chapter explores RAG systems and the core components of RAG, including
    vector stores, document processing, retrieval strategies, implementation, and
    evaluation techniques. After that, we’ll put into practice a lot of what we’ve
    learned so far in this book by building a chatbot. We’ll build a production-ready
    RAG pipeline that streamlines the creation and validation of corporate project
    documentation. This corporate use case demonstrates how to generate initial documentation,
    assess it for compliance and consistency, and incorporate human feedback—all in
    a modular and scalable workflow.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了 RAG 系统和 RAG 的核心组件，包括向量存储、文档处理、检索策略、实现和评估技术。之后，我们将通过构建聊天机器人来实践本书中迄今为止学到的许多内容。我们将构建一个生产就绪的
    RAG 管道，以简化企业项目文档的创建和验证。这个企业用例展示了如何生成初始文档，评估其合规性和一致性，并整合人类反馈——所有这些都在一个模块化和可扩展的工作流程中完成。
- en: 'The chapter has the following sections:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含以下部分：
- en: From indexes to intelligent retrieval
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从索引到智能检索
- en: Components of a RAG system
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG 系统的组成部分
- en: From embeddings to search
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从嵌入到搜索
- en: Breaking down the RAG pipeline
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拆解 RAG 管道
- en: Developing a corporate documentation chatbot
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发企业文档聊天机器人
- en: Troubleshooting RAG systems
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故障排除 RAG 系统
- en: Let’s begin by introducing RAG, its importance, and the main considerations
    when using the RAG framework.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先介绍 RAG、其重要性以及使用 RAG 框架时的主要考虑因素。
- en: From indexes to intelligent retrieval
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从索引到智能检索
- en: 'Information retrieval has been a fundamental human need since the dawn of recorded
    knowledge. For the past 70 years, retrieval systems have operated under the same
    core paradigm:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 信息检索自从有记录知识以来一直是人类的基本需求。在过去 70 年中，检索系统一直在同一个核心范式下运行：
- en: First, a user frames an information need as a query.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，用户将信息需求表述为一个查询。
- en: They then submit this query to the retrieval system.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他们然后将这个查询提交给检索系统。
- en: 'Finally, the system returns references to documents that may satisfy the information
    need:'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，系统返回可能满足信息需求的文档引用：
- en: References may be rank-ordered by decreasing relevance
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参考文献可能按相关性递减排序
- en: Results may contain relevant excerpts from each document (known as snippets)
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果可能包含来自每个文档的相关摘录（称为片段）
- en: While this paradigm has remained constant, the implementation and user experience
    have undergone remarkable transformations. Early information retrieval systems
    relied on manual indexing and basic keyword matching. The advent of computerized
    indexing in the 1960s introduced the inverted index—a data structure that maps
    each word to a list of documents containing it. This lexical approach powered
    the first generation of search engines like AltaVista (1996), where results were
    primarily based on exact keyword matches.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个范式保持不变，但实现和用户体验已经经历了显著的转变。早期的信息检索系统依赖于人工索引和基本的关键词匹配。20 世纪 60 年代计算机化索引的出现引入了倒排索引——一种将每个单词映射到包含它的文档列表的数据结构。这种词汇方法推动了第一代搜索引擎，如
    AltaVista（1996 年），其结果主要基于精确的关键词匹配。
- en: The limitations of this approach quickly became apparent, however. Words can
    have multiple meanings (polysemy), different words can express the same concept
    (synonymy), and users often struggle to articulate their information needs precisely.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法很快显现出局限性。单词可以有多个含义（多义性），不同的单词可以表达相同的概念（同义性），而且用户往往难以精确地表达他们的信息需求。
- en: 'Information-seeking activities come with non-monetary costs: time investment,
    cognitive load, and interactivity costs—what researchers call “Delphic costs.”
    User satisfaction with search engines correlates not just with the relevance of
    results, but with how easily users can extract the information they need.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 信息检索活动伴随着非货币成本：时间投入、认知负荷和交互成本——研究人员称之为“德尔菲成本”。用户对搜索引擎的满意度不仅与结果的相关性相关，还与用户提取所需信息的多容易程度相关。
- en: 'Traditional retrieval systems aimed to reduce these costs through various optimizations:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 传统检索系统旨在通过各种优化来降低这些成本：
- en: Synonym expansion to lower cognitive load when framing queries
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在构建查询时通过同义词扩展来降低认知负荷
- en: Result ranking to reduce the time cost of scanning through results
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果排序以减少浏览结果的时间成本
- en: Result snippeting (showing brief, relevant excerpts from search results) to
    lower the cost of evaluating document relevance
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果摘录（显示搜索结果的简短、相关摘录）以降低评估文档相关性的成本
- en: These improvements reflected an understanding that the ultimate goal of search
    is not just finding documents but satisfying information needs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这些改进反映了这样一个理解：搜索的最终目标不仅仅是找到文档，而是满足信息需求。
- en: 'Google’s PageRank algorithm (late 1990s) improved results by considering link
    structures, but even modern search engines faced fundamental limitations in understanding
    meaning. The search experience evolved from simple lists of matching documents
    to richer presentations with contextual snippets (beginning with Yahoo’s highlighted
    terms in the late 1990s and evolving to Google’s dynamic document previews that
    extract the most relevant sentences containing search terms), but the underlying
    challenge remained: bridging the semantic gap between query terms and relevant
    information.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Google的PageRank算法（20世纪90年代末）通过考虑链接结构来改进结果，但即使是现代搜索引擎也面临着理解意义的基本局限性。搜索体验从简单的匹配文档列表发展到更丰富的呈现方式，包括上下文摘录（从20世纪90年代末Yahoo的高亮术语开始，发展到Google的动态文档预览，提取包含搜索词的最相关句子），但根本的挑战仍然存在：弥合查询术语与相关信息之间的语义差距。
- en: A fundamental limitation of traditional retrieval systems lies in their lexical
    approach to document retrieval. In the Uniterm model, query terms were mapped
    to documents through inverted indices, where each word in the vocabulary points
    to a “postings list” of document positions. This approach efficiently supported
    complex boolean queries but fundamentally missed semantic relationships between
    terms. For example, “turtle” and “tortoise” are treated as completely separate
    words in an inverted index, despite being semantically related. Early retrieval
    systems attempted to bridge this gap through pre-retrieval stages that augmented
    queries with synonyms, but the underlying limitation remained.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 传统检索系统的一个基本局限性在于它们对文档检索的词汇方法。在Uniterm模型中，查询术语通过倒排索引映射到文档，其中词汇表中的每个词都指向一个“位置列表”。这种方法有效地支持了复杂的布尔查询，但本质上忽略了术语之间的语义关系。例如，“乌龟”和“陆龟”在倒排索引中被视为完全不同的词语，尽管它们在语义上是相关的。早期的检索系统试图通过在查询中添加同义词来弥合这一差距，但根本的局限性仍然存在。
- en: The breakthrough came with advances in neural network models that could capture
    the meaning of words and documents as dense vector representations—known as embeddings.
    Unlike traditional keyword systems, embeddings create a *semantic map* where related
    concepts cluster together—”turtle,” “tortoise,” and “reptile” would appear as
    neighbors in this space, while “bank” (financial) would cluster with “money” but
    far from “river.” This geometric organization of meaning enabled retrieval based
    on conceptual similarity rather than exact word matching.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 突破随着神经网络模型的发展而来，这些模型能够捕捉词语和文档的意义，作为密集向量表示——称为嵌入。与传统的关键词系统不同，嵌入创建了一个*语义地图*，其中相关概念聚集在一起——“乌龟”、“陆龟”和“爬行动物”在这个空间中会作为邻居出现，而“银行”（金融）会与“金钱”聚集在一起，但与“河流”相距甚远。这种意义的几何组织使得检索基于概念相似性而不是精确的词语匹配。
- en: This transformation gained momentum with models like Word2Vec (2013) and later
    transformer-based models such as BERT (2018), which introduced contextual understanding.
    BERT’s innovation was to recognize that the same word could have different meanings
    depending on its context—”bank” as a financial institution versus “bank” of a
    river. These distributed representations fundamentally changed what was possible
    in information retrieval, enabling the development of systems that could understand
    the intent behind queries rather than just matching keywords.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这种转换随着Word2Vec（2013）和后来的基于transformer的模型如BERT（2018）等模型的出现而加速，这些模型引入了上下文理解。BERT的创新在于认识到同一个词在不同的上下文中可能有不同的含义——“银行”作为一个金融机构与“河流”的“河岸”。这些分布式表示从根本上改变了信息检索的可行性，使得能够开发出能够理解查询背后的意图而不是仅仅匹配关键词的系统。
- en: 'As transformer-based language models grew in scale, researchers discovered
    they not only learned linguistic patterns but also memorized factual knowledge
    from their training data. Studies by Google researchers showed that models like
    T5 could answer factual questions without external retrieval, functioning as implicit
    knowledge bases. This suggested a paradigm shift—from retrieving documents containing
    answers to directly generating answers from internalized knowledge. However, these
    “closed-book” generative systems faced limitations: hallucination risks, knowledge
    cutoffs limited to training data, inability to cite sources, and challenges with
    complex reasoning. The solution emerged in **RAG**, which bridges traditional
    retrieval systems with generative language models, combining their respective
    strengths while addressing their individual weaknesses.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 随着基于transformer的语言模型规模的扩大，研究人员发现它们不仅学习了语言模式，还记住了训练数据中的事实知识。谷歌研究人员的研究表明，像T5这样的模型可以在没有外部检索的情况下回答事实问题，充当隐式知识库。这表明了一种范式转变——从检索包含答案的文档到直接从内部知识生成答案。然而，这些“闭卷”生成系统面临局限性：幻觉风险、知识截止到训练数据、无法引用来源以及复杂推理的挑战。解决方案在**RAG**中浮现，它将传统的检索系统与生成语言模型相结合，结合它们各自的优势同时解决各自的弱点。
- en: Components of a RAG system
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RAG系统的组件
- en: 'RAG enables language models to ground their outputs in external knowledge,
    providing an elegant solution to the limitations that plague pure LLMs: hallucinations,
    outdated information, and restricted context windows. By retrieving only relevant
    information on demand, RAG systems effectively bypass the context window constraints
    of language models, allowing them to leverage vast knowledge bases without squeezing
    everything into the model’s fixed attention span.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: RAG使语言模型能够将它们的输出建立在外部知识的基础上，为纯LLM所面临的局限性提供了一个优雅的解决方案：幻觉、过时信息和受限的上下文窗口。通过按需检索相关信息，RAG系统有效地绕过了语言模型的上下文窗口限制，允许它们利用庞大的知识库，而无需将所有内容压缩到模型的固定注意力范围内。
- en: Rather than simply retrieving documents for human review (as traditional search
    engines do) or generating answers solely from internalized knowledge (as pure
    LLMs do), RAG systems retrieve information to inform and ground AI-generated responses.
    This approach combines the verifiability of retrieval with the fluency and comprehension
    of generative AI.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统搜索引擎简单地检索文档供人类审查（或像纯LLM那样仅从内部知识生成答案）不同，RAG系统检索信息以告知并支持AI生成的响应。这种方法结合了检索的可验证性与生成AI的流畅性和理解力。
- en: 'At its core, RAG consists of these main components working in concert:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，RAG由以下主要组件协同工作：
- en: '**Knowledge base**: The storage layer for external information'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**知识库**：外部信息的存储层'
- en: '**Retriever**: The knowledge access layer that finds relevant information'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索器**：知识访问层，用于查找相关信息'
- en: '**Augmenter**: The integration layer that prepares retrieved content'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增强器**：整合层，用于准备检索到的内容'
- en: '**Generator**: The response layer that produces the final output'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成器**：生成最终输出的响应层'
- en: 'From a process perspective, RAG operates through two interconnected pipelines:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从流程角度来看，RAG通过两个相互连接的管道运行：
- en: An indexing pipeline that processes, chunks, and stores documents in the knowledge
    base
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个索引管道，用于处理、分块和存储知识库中的文档
- en: A query pipeline that retrieves relevant information and generates responses
    using that information
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个查询管道，用于检索相关信息并使用这些信息生成响应
- en: 'The workflow in a RAG system follows a clear sequence: when a query arrives,
    it’s processed for retrieval; the retriever then searches the knowledge base for
    relevant information; this retrieved context is combined with the original query
    through augmentation; finally, the language model generates a response grounded
    in both the query and the retrieved information. We can see this in the following
    diagram:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: RAG系统中的工作流程遵循一个清晰的顺序：当查询到达时，它被处理以进行检索；检索器随后在知识库中搜索相关信息；检索到的上下文通过增强与原始查询相结合；最后，语言模型生成一个基于查询和检索信息的响应。我们可以在以下图中看到这一点：
- en: '![Figure 4.1: RAG architecture and workflow](img/B32363_04_01.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图4.1：RAG架构和工作流程](img/B32363_04_01.png)'
- en: 'Figure 4.1: RAG architecture and workflow'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1：RAG架构和工作流程
- en: 'This architecture offers several advantages for production systems: modularity
    allows components to be developed independently; scalability enables resources
    to be allocated based on specific needs; maintainability is improved through the
    clear separation of concerns; and flexibility permits different implementation
    strategies to be swapped in as requirements evolve.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构为生产系统提供了几个优点：模块化允许组件独立开发；可扩展性使资源可以根据特定需求分配；通过明确分离关注点来提高可维护性；灵活性允许根据需求的变化交换不同的实现策略。
- en: 'In the following sections, we’ll explore each component in *Figure 4.1* in
    detail, beginning with the fundamental building blocks of modern RAG systems:
    **embeddings** and **vector stores** that power the knowledge base and retriever
    components. But before we dive in, it’s important to first consider the decision
    between implementing RAG or using pure LLMs. This choice will fundamentally impact
    your application’s overall architecture and operational characteristics. Let’s
    discuss the trade-offs!'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将详细探讨图4.1中的每个组件，从现代RAG系统的基本构建块开始：为知识库和检索器组件提供动力的**嵌入**和**向量存储**。但在我们深入之前，首先考虑实施RAG或使用纯LLM之间的决策非常重要。这个选择将从根本上影响你应用程序的整体架构和操作特性。让我们讨论一下权衡利弊！
- en: When to implement RAG
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时实施RAG
- en: Introducing RAG brings architectural complexity that must be carefully weighed
    against your application requirements. RAG proves particularly valuable in specialized
    domains where current or verifiable information is crucial. Healthcare applications
    must process both medical images and time-series data, while financial systems
    need to handle high-dimensional market data alongside historical analysis. Legal
    applications benefit from RAG’s ability to process complex document structures
    and maintain source attribution. These domain-specific requirements often justify
    the additional complexity of implementing RAG.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 引入RAG带来了必须仔细权衡的架构复杂性，以符合你的应用程序需求。RAG在当前或可验证信息至关重要的专业领域特别有价值。医疗应用程序必须处理医学图像和时间序列数据，而金融系统需要处理高维度的市场数据以及历史分析。法律应用程序得益于RAG处理复杂文档结构和维护来源归属的能力。这些特定领域的需求通常证明实施RAG的额外复杂性是合理的。
- en: The benefits of RAG, however, come with significant implementation considerations.
    The system requires efficient indexing and retrieval mechanisms to maintain reasonable
    response times. Knowledge bases need regular updates and maintenance to remain
    valuable. Infrastructure must be designed to handle errors and edge cases gracefully,
    especially where different components interact. Development teams must be prepared
    to manage these ongoing operational requirements.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，RAG的好处伴随着重大的实施考虑。系统需要高效的索引和检索机制来维持合理的响应时间。知识库需要定期更新和维护以保持其价值。基础设施必须设计得能够优雅地处理错误和边缘情况，特别是在不同组件交互的地方。开发团队必须准备好管理这些持续的操作需求。
- en: Pure LLM implementations, on the other hand, might be more appropriate when
    these complexities outweigh the benefits. Applications focusing on creative tasks,
    general conversation, or scenarios requiring rapid response times often perform
    well without the overhead of retrieval systems. When working with static, limited
    knowledge bases, techniques like fine-tuning or prompt engineering might provide
    simpler solutions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，当这些复杂性超过其好处时，纯LLM实现可能更为合适。专注于创意任务、一般对话或需要快速响应时间的场景的应用通常在没有检索系统开销的情况下表现良好。当与静态、有限的知识库一起工作时，微调或提示工程等技术可能提供更简单的解决方案。
- en: This analysis, drawn from both research and practical implementations, suggests
    that specific requirements for knowledge currency, accuracy, and domain expertise
    should guide the choice between RAG and pure LLMs, balanced against the organizational
    capacity to manage the additional architectural complexity.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这项分析既来自研究，也来自实际实施，表明对于知识货币、准确性和领域专业知识的具体要求应指导RAG与纯LLM之间的选择，同时平衡组织管理额外架构复杂性的能力。
- en: At Chelsea AI Ventures, our team has observed that clients in regulated industries
    particularly benefit from RAG’s verifiability, while creative applications often
    perform adequately with pure LLMs.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在Chelsea AI Ventures，我们的团队观察到，在监管行业中的客户特别受益于RAG的可验证性，而创意应用通常在纯LLM上表现良好。
- en: 'Development teams should consider RAG when their applications require:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当开发团队的应用程序需要以下功能时，应考虑使用RAG：
- en: Access to current information not available in LLM training data
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问LLM训练数据中不可用的当前信息
- en: Domain-specific knowledge integration
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领域特定知识整合
- en: Verifiable responses with source attribution
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有来源归属的可验证响应
- en: Processing of specialized data formats
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理专用数据格式
- en: High precision in regulated industries
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在监管行业中的高精度
- en: With that, let’s explore the implementation details, optimization strategies,
    and production deployment considerations for each RAG component.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们探讨每个RAG组件的实现细节、优化策略和生产部署考虑因素。
- en: From embeddings to search
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从嵌入到搜索
- en: 'As mentioned, a RAG system comprises a retriever that finds relevant information,
    an augmentation mechanism that integrates this information, and a generator that
    produces the final output. When building AI applications with LLMs, we often focus
    on the exciting parts – prompts, chains, and model outputs. However, the foundation
    of any robust RAG system lies in how we store and retrieve our vector embeddings.
    Think of it like building a library – before we can efficiently find books (vector
    search), we need both a building to store them (vector storage) and an organization
    system to find them (vector indexing). In this section, we introduce the core
    components of a RAG system: vector embeddings, vector stores, and indexing strategies
    to optimize retrieval.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，RAG系统包括一个检索器，用于找到相关信息，一个增强机制，用于整合这些信息，以及一个生成器，用于生成最终输出。在构建使用LLM的AI应用程序时，我们通常关注令人兴奋的部分——提示、链和模型输出。然而，任何稳健的RAG系统的基石在于我们如何存储和检索我们的向量嵌入。想象一下，就像建造一个图书馆——在我们能够高效地找到书籍（向量搜索）之前，我们需要一个建筑来存储它们（向量存储）和一个组织系统来找到它们（向量索引）。在本节中，我们介绍了RAG系统的核心组件：向量嵌入、向量存储和索引策略以优化检索。
- en: 'To make RAG work, we first need to solve a fundamental challenge: how do we
    help computers understand the meaning of text so they can find relevant information?
    This is where embeddings come in.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要使RAG（Retrieval-Augmented Generation，检索增强生成）工作，我们首先需要解决一个基本挑战：我们如何帮助计算机理解文本的意义，以便它们能够找到相关信息？这正是嵌入技术发挥作用的地方。
- en: Embeddings
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌入
- en: Embeddings are numerical representations of text that capture semantic meaning.
    When we create an embedding, we’re converting words or chunks of text into vectors
    (lists of numbers) that computers can process. These vectors can be either sparse
    (mostly zeros with few non-zero values) or dense (most values are non-zero), with
    modern LLM systems typically using dense embeddings.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入是捕获语义意义的文本的数值表示。当我们创建嵌入时，我们正在将单词或文本块转换为计算机可以处理的向量（数字列表）。这些向量可以是稀疏的（大部分为零，只有少数非零值）或密集的（大多数值非零），现代LLM（Large
    Language Model，大型语言模型）系统通常使用密集嵌入。
- en: What makes embeddings powerful is that texts with similar meanings have similar
    numerical representations, enabling semantic search through nearest neighbor algorithms.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入的强大之处在于，具有相似意义的文本具有相似的数值表示，这使得通过最近邻算法进行语义搜索成为可能。
- en: 'In other words, the embedding model transforms text into numerical vectors.
    The same model is used for both documents as well as queries to ensure consistency
    in the vector space. Here’s how you’d use embeddings in LangChain:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，嵌入模型将文本转换为数值向量。相同的模型用于文档以及查询，以确保向量空间的一致性。以下是您如何在LangChain中使用嵌入的方法：
- en: '[PRE0]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once we have these OpenAI embeddings (the 1536-dimensional vectors we generated
    for our example sentences above), we need a purpose-built system to store them.
    Unlike regular database values, these high-dimensional vectors require specialized
    storage solutions.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了这些OpenAI嵌入（我们为上述示例句子生成的1536维向量），我们需要一个专门设计的系统来存储它们。与常规数据库值不同，这些高维向量需要专门的存储解决方案。
- en: 'The `Embeddings` class in LangChain provides a standard interface for all embedding
    models from various providers (OpenAI, Cohere, Hugging Face, and others). It exposes
    two primary methods:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain中的`Embeddings`类为来自各种提供商（OpenAI、Cohere、Hugging Face等）的所有嵌入模型提供了一个标准接口。它公开了两个主要方法：
- en: '`embed_documents`: Takes multiple texts and returns embeddings for each'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embed_documents`：接受多个文本并为每个文本返回嵌入'
- en: '`embed_query`: Takes a single text (your search query) and returns its embedding'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embed_query`：接受单个文本（您的搜索查询）并返回其嵌入'
- en: Some providers use different embedding methods for documents versus queries,
    which is why these are separate methods in the API.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一些提供商对文档和查询使用不同的嵌入方法，这就是为什么这些方法在API中是分开的。
- en: This brings us to vector stores – specialized databases optimized for similarity
    searches in high-dimensional spaces.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这就引出了向量存储——专门针对高维空间中的相似度搜索进行优化的数据库。
- en: Vector stores
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量存储
- en: Vector stores are specialized databases designed to store, manage, and efficiently
    search vector embeddings. As we’ve seen, embeddings convert text (or other data)
    into numerical vectors that capture semantic meaning.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储是专门设计的数据库，用于存储、管理和高效搜索向量嵌入。正如我们所看到的，嵌入将文本（或其他数据）转换为捕获语义意义的数值向量。
- en: 'Vector stores solve the fundamental challenge of how to persistently and efficiently
    search through these high-dimensional vectors. Please note that the vector database
    operates as an independent system that can be:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储解决了如何持久化和高效地搜索这些高维向量的基本挑战。请注意，向量数据库作为一个独立的系统，可以：
- en: Scaled independently of the RAG components
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立于RAG组件进行扩展
- en: Maintained and optimized separately
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立维护和优化
- en: Potentially shared across multiple RAG applications
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能在多个RAG应用程序之间共享
- en: Hosted as a dedicated service
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为一项专用服务托管
- en: 'When working with embeddings, several challenges arise:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理嵌入时，会出现几个挑战：
- en: '**Scale**: Applications often need to store millions of embeddings'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规模**：应用程序通常需要存储数百万个嵌入'
- en: '**Dimensionality**: Each embedding might have hundreds or thousands of dimensions'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维度**：每个嵌入可能包含数百或数千个维度'
- en: '**Search performance**: Finding similar vectors quickly becomes computationally
    intensive'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**搜索性能**：快速找到相似向量变得计算密集'
- en: '**Associated data**: We need to maintain connections between vectors and their
    source documents'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关联数据**：我们需要维护向量与其源文档之间的联系'
- en: 'Consider a real-world example of what we need to store:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个现实世界的例子，看看我们需要存储什么：
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'At their core, vector stores combine two essential components:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在其核心，向量存储结合了两个基本组件：
- en: '**Vector storage**: The actual database that persists vectors and metadata'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量存储**：实际持久化向量和元数据的数据库'
- en: '**Vector index**: A specialized data structure that enables efficient similarity
    search'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量索引**：一种专门的数据结构，能够实现高效的相似度搜索'
- en: The efficiency challenge comes from the *curse of dimensionality* – as vector
    dimensions increase, computing similarities becomes increasingly expensive, requiring
    O(dN) operations for d dimensions and N vectors. This makes naive similarity search
    impractical for large-scale applications.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 效率挑战来自**维度诅咒**——随着向量维度的增加，计算相似性变得越来越昂贵，需要O(dN)操作，其中d是维度，N是向量。这使得原始的相似度搜索对于大规模应用来说不切实际。
- en: Vector stores enable similarity-based search through distance calculations in
    high-dimensional space. While traditional databases excel at exact matching, vector
    embeddings allow for semantic search and **approximate nearest neighbor** (**ANN**)
    retrieval.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储通过在多维空间中进行距离计算，实现了基于相似度的搜索。虽然传统数据库擅长精确匹配，但向量嵌入允许进行语义搜索和**近似最近邻**（**ANN**）检索。
- en: The key difference from traditional databases is how vector stores handle searches.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统数据库的关键区别在于向量存储如何处理搜索。
- en: '**Traditional database search**:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**传统数据库搜索**：'
- en: Uses exact matching (equality, ranges)
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用精确匹配（相等，范围）
- en: Optimized for structured data (for example, “find all customers with age > 30”)
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化用于结构化数据（例如，“找到所有年龄大于30岁的客户”）
- en: Usually utilizes B-trees or hash-based indexes
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常使用B树或基于哈希的索引
- en: '**Vector store search:**'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**向量存储搜索**：'
- en: Uses similarity metrics (cosine similarity, Euclidean distance)
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用相似度度量（余弦相似度，欧几里得距离）
- en: Optimized for high-dimensional vector spaces
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化用于高维向量空间
- en: Employs Approximate Nearest Neighbor (ANN) algorithms
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 采用近似最近邻（ANN）算法
- en: Vector stores comparison
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向量存储比较
- en: 'Vector stores manage high-dimensional embeddings for retrieval. The following
    table compares popular vector stores across key attributes to help you select
    the most appropriate solution for your specific needs:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储管理高维嵌入以进行检索。以下表格比较了根据关键属性流行的向量存储，以帮助您选择最适合您特定需求的解决方案：
- en: '| **Database** | **Deployment options** | **License** | **Notable features**
    |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| **数据库** | **部署选项** | **许可** | **显著特性** |'
- en: '| Pinecone | Cloud-only | Commercial | Auto-scaling, enterprise security, monitoring
    |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| Pinecone | 仅云 | 商业 | 自动扩展，企业安全，监控 |'
- en: '| Milvus | Cloud, Self-hosted | Apache 2.0 | HNSW/IVF indexing, multi-modal
    support, CRUD operations |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Milvus | 云，自托管 | Apache 2.0 | HNSW/IVF 索引，多模态支持，CRUD 操作 |'
- en: '| Weaviate | Cloud, Self-hosted | BSD 3-Clause | Graph-like structure, multi-modal
    support |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| Weaviate | 云，自托管 | BSD 3-Clause | 图形结构，多模态支持 |'
- en: '| Qdrant | Cloud, Self-hosted | Apache 2.0 | HNSW indexing, filtering optimization,
    JSON metadata |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| Qdrant | 云，自托管 | Apache 2.0 | HNSW 索引，过滤优化，JSON 元数据 |'
- en: '| ChromaDB | Cloud, Self-hosted | Apache 2.0 | Lightweight, easy setup |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| ChromaDB | 云，自托管 | Apache 2.0 | 轻量级，易于设置 |'
- en: '| AnalyticDB-V | Cloud-only | Commercial | OLAP integration, SQL support, enterprise
    features |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| AnalyticDB-V | 仅云 | 商业 | OLAP 集成，SQL 支持，企业功能 |'
- en: '| pg_vector | Cloud, Self-hosted | OSS | SQL support, PostgreSQL integration
    |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| pg_vector | 云，自托管 | 开源 | SQL 支持，PostgreSQL 集成 |'
- en: '| Vertex Vector Search | Cloud-only | Commercial | Easy setup, low latency,
    high scalability |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| Vertex Vector Search | 仅云 | 商业 | 易于设置，低延迟，高可扩展性 |'
- en: 'Table 4.1: Vector store comparison by deployment options, licensing, and key
    features'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.1：根据部署选项、许可和关键特性比较向量存储
- en: 'Each vector store offers different tradeoffs in terms of deployment flexibility,
    licensing, and specialized capabilities. For production RAG systems, consider
    factors such as:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 每个向量存储在部署灵活性、许可和专用功能方面都有不同的权衡。对于生产级 RAG 系统，考虑以下因素：
- en: Whether you need cloud-managed or self-hosted deployment
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您是否需要云托管或自托管部署
- en: The need for specific features like SQL integration or multi-modal support
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对特定功能的需求，如 SQL 集成或多模态支持
- en: The complexity of setup and maintenance
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置和维护的复杂性
- en: Scaling requirements for your expected embedding volume
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预期嵌入体积的扩展需求
- en: 'For many applications starting with RAG, lightweight options like ChromaDB
    provide an excellent balance of simplicity and functionality, while enterprise
    deployments might benefit from the advanced features of Pinecone or AnalyticDB-V.
    Modern vector stores support several search patterns:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多以 RAG 为起点的应用，ChromaDB 等轻量级选项提供了简单性和功能性的良好平衡，而企业部署可能从 Pinecone 或 AnalyticDB-V
    的高级功能中受益。现代向量存储支持多种搜索模式：
- en: '**Exact search**: Returns precise nearest neighbors but becomes computationally
    prohibitive with large vector collections'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确搜索**: 返回精确的最近邻，但随着大型向量集合的增大，计算成本变得过高'
- en: '**Approximate search**: Trades accuracy for speed using techniques like LSH,
    HNSW, or quantization; measured by recall (the percentage of true nearest neighbors
    retrieved)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**近似搜索**: 使用 LSH、HNSW 或量化等技术以速度换取精度；通过召回率（检索到的真实最近邻的百分比）来衡量'
- en: '**Hybrid search**: Combines vector similarity with text-based search (like
    keyword matching or BM25) in a single query'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合搜索**: 在单个查询中结合向量相似性和基于文本的搜索（如关键词匹配或 BM25）'
- en: '**Filtered vector search**: Applies traditional database filters (for example,
    metadata constraints) alongside vector similarity search'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过滤向量搜索**: 在向量相似性搜索的同时应用传统的数据库过滤器（例如，元数据约束）'
- en: 'Vector stores also handle different types of embeddings:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储还处理不同类型的嵌入：
- en: '**Dense vector search**: Uses continuous embeddings where most dimensions have
    non-zero values, typically from neural models (like BERT, OpenAI embeddings)'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**密集向量搜索**: 使用连续嵌入，其中大多数维度具有非零值，通常来自神经网络模型（如 BERT、OpenAI 嵌入）'
- en: '**Sparse vector search**: Uses high-dimensional vectors where most values are
    zero, resembling traditional TF-IDF or BM25 representations'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稀疏向量搜索**: 使用高维向量，其中大多数值为零，类似于传统的 TF-IDF 或 BM25 表示'
- en: '**Sparse-dense hybrid**: Combines both approaches to leverage semantic similarity
    (dense) and keyword precision (sparse)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稀疏-密集混合**: 结合两种方法以利用语义相似性（密集）和关键词精确度（稀疏）'
- en: 'They also often give a choice of multiple similarity measures, for example:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 它们还经常提供多种相似度度量选择，例如：
- en: '**Inner product**: Useful for comparing semantic directions'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内积**: 用于比较语义方向'
- en: '**Cosine similarity**: Normalizes for vector magnitude'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**余弦相似度**：对向量大小进行归一化'
- en: '**Euclidean distance**: Measures the L2 distance in vector space (note: with
    normalized embeddings, this becomes functionally equivalent to the dot product)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**欧几里得距离**：在向量空间中测量L2距离（注意：对于归一化嵌入，这功能上等同于点积）'
- en: '**Hamming distance**: For binary vector representations'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**汉明距离**：对于二进制向量表示'
- en: When implementing vector storage for RAG applications, one of the first architectural
    decisions is whether to use local storage or a cloud-based solution. Let’s explore
    the tradeoffs and considerations for each approach.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 当为RAG应用实现向量存储时，第一个架构决策之一是使用本地存储还是基于云的解决方案。让我们探讨每种方法的权衡和考虑因素。
- en: Choose local storage when you need maximum control, have strict privacy requirements,
    or operate at a smaller scale with predictable workloads.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你需要最大控制权、有严格的隐私要求，或在较小规模且工作负载可预测的情况下运营时，请选择本地存储。
- en: Choose cloud storage when you need elastic scaling, prefer managed services,
    or operate distributed applications with variable workloads.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你需要弹性扩展、偏好管理服务或以可变工作负载运营分布式应用时，请选择云存储。
- en: Consider hybrid storage architecture when you want to balance performance and
    scalability, combining local caching with cloud-based persistence.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你想平衡性能和可扩展性时，考虑混合存储架构，结合本地缓存和基于云的持久化。
- en: Hardware considerations for vector stores
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向量存储的硬件考虑因素
- en: 'Regardless of your deployment approach, understanding the hardware requirements
    is crucial for optimal performance:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你的部署方法如何，了解硬件要求对于最佳性能至关重要：
- en: '**Memory requirements**: Vector databases are memory-intensive, with production
    systems often requiring 16-64GB RAM for millions of embeddings. Local deployments
    should plan for sufficient memory headroom to accommodate index growth.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存需求**：向量数据库内存密集，生产系统通常需要16-64GB RAM来存储数百万个嵌入。本地部署应计划足够的内存余量以容纳索引增长。'
- en: '**CPU vs. GPU**: While basic vector operations work on CPUs, GPU acceleration
    significantly improves performance for large-scale similarity searches. For high-throughput
    applications, GPU support can provide 10-50x speed improvements.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CPU与GPU**：虽然基本的向量操作可以在CPU上运行，但GPU加速显著提高了大规模相似度搜索的性能。对于高吞吐量应用，GPU支持可以提供10-50倍的速度提升。'
- en: '**Storage speed**: SSD storage is strongly recommended over HDD for production
    vector stores, as index loading and search performance depend heavily on I/O speed.
    This is especially critical for local deployments.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储速度**：在生产向量存储中，强烈建议使用SSD存储而不是HDD，因为索引加载和搜索性能高度依赖于I/O速度。这对于本地部署尤为重要。'
- en: '**Network bandwidth**: For cloud-based or distributed setups, network latency
    and bandwidth become critical factors that can impact query response times.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络带宽**：对于基于云或分布式设置，网络延迟和带宽成为影响查询响应时间的关键因素。'
- en: For development and testing, most vector stores can run on standard laptops
    with 8GB+ RAM, but production deployments should consider dedicated infrastructure
    or cloud-based vector store services that handle these resource considerations
    automatically.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 对于开发和测试，大多数向量存储可以在8GB+ RAM的标准笔记本电脑上运行，但生产部署应考虑专用基础设施或基于云的向量存储服务，这些服务可以自动处理这些资源考虑因素。
- en: Vector store interface in LangChain
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LangChain中的向量存储接口
- en: 'Now that we’ve explored the role of vector stores and compared some common
    options, let’s look at how LangChain simplifies working with them. LangChain provides
    a standardized interface for working with vector stores, allowing you to easily
    switch between different implementations:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了向量存储的作用并比较了一些常见选项，让我们看看LangChain是如何简化与它们一起工作的。LangChain提供了一个标准化的接口来处理向量存储，允许你轻松地在不同的实现之间切换：
- en: '[PRE2]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The `vectorstore` base class in LangChain provides these essential operations:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain中的`vectorstore`基类提供了这些基本操作：
- en: 'Adding documents:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加文档：
- en: '[PRE3]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Similarity search:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相似度搜索：
- en: '[PRE4]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Deletion:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除：
- en: '[PRE5]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Maximum marginal relevance search:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最大边际相关度搜索：
- en: '[PRE6]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'It’s important to also briefly highlight applications of vector stores apart
    from RAG:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 还重要的是简要概述向量存储除RAG以外的应用。
- en: Anomaly detection in large datasets
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大数据集中的异常检测
- en: Personalization and recommendation systems
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个性化推荐系统
- en: NLP tasks
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NLP任务
- en: Fraud detection
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 欺诈检测
- en: Network security monitoring
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络安全监控
- en: Storing vectors isn’t enough, however. We need to find similar vectors quickly
    when processing queries. Without proper indexing, searching through vectors would
    be like trying to find a book in a library with no organization system – you’d
    have to check every single book.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，存储向量还不够。在处理查询时，我们需要快速找到相似向量。如果没有适当的索引，搜索向量就像试图在没有组织系统的图书馆中找到一本书 – 你不得不检查每一本书。
- en: Vector indexing strategies
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量索引策略
- en: 'Vector indexing is a critical component that makes vector databases practical
    for real-world applications. At its core, indexing solves a fundamental performance
    challenge: how to efficiently find similar vectors without comparing against every
    single vector in the database (brute force approach), which is computationally
    prohibitive for even medium-sized data volumes.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 向量索引是使向量数据库适用于现实世界应用的关键组件。在其核心，索引解决了基本性能挑战：如何高效地找到相似向量，而无需与数据库中的每个向量进行比较（暴力方法），这对于即使是中等规模的数据量也是计算上不可行的。
- en: Vector indexes are specialized data structures that organize vectors in ways
    that allow the system to quickly identify which sections of the vector space are
    most likely to contain similar vectors. Instead of checking every vector, the
    system can focus on promising regions first.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 向量索引是专门的数据结构，以组织向量，使系统能够快速识别向量空间中最可能包含相似向量的部分。系统不必检查每个向量，而是首先关注有希望的区域。
- en: 'Some common indexing approaches include:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的索引方法包括：
- en: '**Tree-based structures** that hierarchically divide the vector space'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于树的结构**，按层次划分向量空间'
- en: '**Graph-based methods** like **Hierarchical Navigable Small World** (**HNSW**)
    that create navigable networks of connected vectors'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于图的方法**，如**分层可导航小世界**（HNSW），创建连接向量的可导航网络'
- en: '**Hashing techniques** that map similar vectors to the same “buckets”'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**哈希技术**将相似向量映射到相同的“桶”'
- en: 'Each of the preceding approaches offers different trade-offs between:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 前述每种方法都提供了在以下方面之间的不同权衡：
- en: Search speed
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索速度
- en: Accuracy of results
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果的准确性
- en: Memory usage
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存使用
- en: Update efficiency (how quickly new vectors can be added)
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新效率（添加新向量有多快）
- en: When using a vector store in LangChain, the indexing strategy is typically handled
    by the underlying implementation. For example, when you create a FAISS index or
    use Pinecone, those systems automatically apply appropriate indexing strategies
    based on your configuration.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 当在 LangChain 中使用向量存储时，索引策略通常由底层实现处理。例如，当你创建 FAISS 索引或使用 Pinecone 时，这些系统会根据你的配置自动应用适当的索引策略。
- en: The key takeaway is that proper indexing transforms vector search from an O(n)
    operation (where n is the number of vectors) to something much more efficient
    (often closer to O(log n)), making it possible to search through millions of vectors
    in milliseconds rather than seconds or minutes.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 关键要点是，适当的索引将向量搜索从 O(n) 操作（其中 n 是向量的数量）转变为更高效的操作（通常接近 O(log n)），这使得能够在毫秒内而不是秒或分钟内搜索数百万个向量。
- en: 'Here’s a table to provide an overview of different strategies:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个表格，概述不同的策略：
- en: '| **Strategy** | **Core algorithm** | **Complexity** | **Memory usage** | **Best
    for** | **Notes** |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| **策略** | **核心算法** | **复杂度** | **内存使用** | **最佳用途** | **备注** |'
- en: '| Exact Search (Brute Force) | Compares query vector with every vector in database
    | Search: O(DN)Build: O(1) | Low – only stores raw vectors |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 精确搜索（暴力搜索） | 将查询向量与数据库中的每个向量进行比较 | 搜索：O(DN)构建：O(1) | 低 – 只存储原始向量 |'
- en: Small datasets
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小数据集
- en: When 100% recall needed
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当需要100%召回率时
- en: Testing/baseline
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试/基线
- en: '|'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Easiest to implement
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现最简单
- en: Good baseline for testing
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 好的测试基线
- en: '|'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| HNSW (Hierarchical Navigable Small World) | Creates layered graph with decreasing
    connectivity from bottom to top | Search: O(log N)Build: O(N log N) | High – stores
    graph connections plus vectors |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| HNSW（分层可导航小世界） | 创建从底部到顶部连接度递减的分层图 | 搜索：O(log N)构建：O(N log N) | 高 – 存储图连接和向量
    |'
- en: Production systems
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产系统
- en: When high accuracy needed
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当需要高精度时
- en: Large-scale search
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大规模搜索
- en: '|'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Industry standard
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 行业标准
- en: Requires careful tuning of M (connections) and ef (search depth)
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要仔细调整 M（连接数）和 ef（搜索深度）
- en: '|'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| LSH (Locality Sensitive Hashing) | Uses hash functions that map similar vectors
    to the same buckets | Search: O(N![](img/Icon_2.png))Build: O(N) | Medium – stores
    multiple hash tables |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| LSH（局部敏感哈希） | 使用将相似向量映射到相同桶的哈希函数 | 搜索：O(N![](img/Icon_2.png))构建：O(N) | 中等
    – 存储多个哈希表 |'
- en: Streaming data
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流式数据
- en: When updates frequent
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当更新频繁时
- en: Approximate search OK
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 近似搜索可行
- en: '|'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Good for dynamic data
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适用于动态数据
- en: Tunable accuracy vs speed
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可调精度与速度
- en: '|'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| IVF (Inverted File Index) | Clusters vectors and searches within relevant
    clusters | Search: O(DN/k)Build: O(kN) | Low – stores cluster assignments |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| IVF（倒排文件索引） | 在相关簇内聚类向量和搜索 | 搜索：O(DN/k)构建：O(kN) | 低 – 存储簇分配 |'
- en: Limited memory
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存有限
- en: Balance of speed/accuracy
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 速度/精度平衡
- en: Simple implementation
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单实现
- en: '|'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: k = number of clusters
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k = 簇的数量
- en: Often combined with other methods
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常与其他方法结合使用
- en: '|'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Product Quantization (PQ) | Compresses vectors by splitting into subspaces
    and quantizing | Search: variesBuild: O(N) | Very Low – compressed vectors |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 产品量化（PQ） | 通过将向量分割到子空间并进行量化来压缩向量 | 搜索：变化构建：O(N) | 非常低 – 压缩向量 |'
- en: Memory-constrained systems
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存受限系统
- en: Massive datasets
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 巨大数据集
- en: '|'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Often combined with IVF
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常与IVF结合使用
- en: Requires training codebooks
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要训练代码簿
- en: Complex implementation
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂实现
- en: '|'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Tree-Based (KD-Tree, Ball Tree)
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 基于树的（KD-Tree，球树）
- en: '| Recursively partitions space into regions | Search: O(D log N) best caseBuild:
    O(N log N) | Medium – tree structure |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 递归地将空间划分为区域 | 搜索：O(D log N)最佳情况构建：O(N log N) | 中等 – 树结构 |'
- en: Low dimensional data
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低维数据
- en: Static datasets
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静态数据集
- en: '|'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Works well for D < 100
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于D < 100效果良好
- en: Expensive updates
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 费时更新
- en: '|'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'Table 4.2: Vector store comparison by deployment options, licensing, and key
    features'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.2：根据部署选项、许可和关键特性比较向量存储
- en: 'When selecting an indexing strategy for your RAG system, consider these practical
    tradeoffs:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 当为你的RAG系统选择索引策略时，考虑这些实际的权衡：
- en: '**For maximum accuracy with small datasets** (<100K vectors): Exact Search
    provides perfect recall but becomes prohibitively expensive as your dataset grows.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对于小数据集的最大精度**（<100K个向量）：精确搜索提供了完美的召回率，但随着数据集的增长变得过于昂贵。'
- en: '**For production systems with millions of vectors**: HNSW offers the best balance
    of search speed and accuracy, making it the industry standard for large-scale
    applications. While it requires more memory than other approaches, its logarithmic
    search complexity delivers consistent performance even as your dataset scales.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对于拥有数百万向量的生产系统**：HNSW提供了速度和精度之间的最佳平衡，使其成为大规模应用的行业标准。虽然它比其他方法需要更多的内存，但其对数搜索复杂度即使在数据集规模扩大时也能提供一致的性能。'
- en: '**For memory-constrained environments**: IVF+PQ (Inverted File Index with Product
    Quantization) dramatically reduces memory requirements—often by 10-20x compared
    to raw vectors—with a modest accuracy tradeoff. This combination is particularly
    valuable for edge deployments or when embedding billions of documents.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对于内存受限的环境**：IVF+PQ（倒排文件索引与产品量化）显著降低了内存需求——通常比原始向量低10-20倍，但精度有所妥协。这种组合对于边缘部署或嵌入数十亿文档时特别有价值。'
- en: '**For frequently updated collections**: LSH provides efficient updates without
    rebuilding the entire index, making it suitable for streaming data applications
    where documents are continuously added or removed.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对于频繁更新的集合**：LSH提供了高效的更新，无需重建整个索引，这使得它适合于流数据应用，其中文档持续添加或删除。'
- en: 'Most modern vector databases default to HNSW for good reason, but understanding
    these tradeoffs allows you to optimize for your specific constraints when necessary.
    To illustrate the practical difference between indexing strategies, let’s compare
    the performance and accuracy of exact search versus HNSW indexing using FAISS:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现代向量数据库默认使用HNSW，这是有充分理由的，但了解这些权衡允许你在必要时针对你的特定约束进行优化。为了说明索引策略之间的实际差异，让我们使用FAISS比较精确搜索与HNSW索引的性能和精度：
- en: '[PRE7]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This example demonstrates the fundamental tradeoff in vector indexing: exact
    search guarantees finding the true nearest neighbors but takes longer, while HNSW
    provides approximate results significantly faster. The overlap percentage shows
    how many of the same nearest neighbors were found by both methods.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子展示了向量索引中的基本权衡：精确搜索保证了找到真正的最近邻，但需要更长的时间，而HNSW提供了显著更快的近似结果。重叠百分比显示了两种方法找到的相同最近邻的数量。
- en: For small datasets like this example (10,000 vectors), the absolute time difference
    is minimal. However, as your dataset grows to millions or billions of vectors,
    exact search becomes prohibitively expensive, while HNSW maintains logarithmic
    scaling—making approximate indexing methods essential for production RAG systems.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像这个例子这样的小型数据集（10,000个向量），绝对时间差异最小。然而，当你的数据集增长到数百万或数十亿个向量时，精确搜索变得过于昂贵，而HNSW保持对数缩放——这使得近似索引方法对于生产级RAG系统至关重要。
- en: 'Here’s a diagram that can help developers choose the right indexing strategy
    based on their requirements:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个图表，可以帮助开发者根据他们的需求选择合适的索引策略：
- en: '![Figure 4.2: Choosing an indexing strategy](img/B32363_04_02.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![图4.2：选择索引策略](img/B32363_04_02.png)'
- en: 'Figure 4.2: Choosing an indexing strategy'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2：选择索引策略
- en: 'The preceding figure illustrates a decision tree for selecting the appropriate
    indexing strategy based on your deployment constraints. The flowchart helps you
    navigate key decision points:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图展示了基于部署限制选择适当索引策略的决策树。流程图帮助你导航关键决策点：
- en: '**Start by assessing your dataset size**: For small collections (under 100K
    vectors), exact search remains viable and provides perfect accuracy.'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**首先评估你的数据集大小**：对于小型集合（小于100K个向量），精确搜索仍然可行，并提供完美精度。'
- en: '**Consider your memory constraints**: If memory is limited, follow the left
    branch toward compression techniques like **Product Quantization** (**PQ**).'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**考虑你的内存限制**：如果内存有限，遵循左侧分支，转向压缩技术，如**产品量化**（**PQ**）。'
- en: '**Evaluate update frequency**: If your application requires frequent index
    updates, prioritize methods like LSH that support efficient updates.'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估更新频率**：如果你的应用需要频繁更新索引，优先考虑支持高效更新的方法，如LSH。'
- en: '**Assess search speed requirements**: For applications demanding ultra-low
    latency, HNSW typically provides the fastest search times once built.'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**评估搜索速度需求**：对于需要超低延迟的应用，一旦构建完成，HNSW通常提供最快的搜索时间。'
- en: '**Balance with accuracy needs**: As you move downward in the flowchart, consider
    the accuracy-efficiency tradeoff based on your application’s tolerance for approximate
    results.'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**平衡精度需求**：随着你在流程图中的向下移动，根据你的应用对近似结果的可容忍度，考虑精度-效率权衡。'
- en: For most production RAG applications, you’ll likely end up with HNSW or a combined
    approach like IVF+HNSW, which clusters vectors first (IVF) and then builds efficient
    graph structures (HNSW) within each cluster. This combination delivers excellent
    performance across a wide range of scenarios.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数生产RAG应用，你可能会选择HNSW或类似IVF+HNSW的混合方法，该方法首先对向量进行聚类（IVF），然后在每个聚类内构建高效的图结构（HNSW）。这种组合在多种场景下都提供了出色的性能。
- en: To improve retrieval, documents must be processed and structured effectively.
    The next section explores loading various document types and handling multi-modal
    content.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高检索效果，文档必须被有效处理和结构化。下一节将探讨加载各种文档类型和处理多模态内容。
- en: 'Vector libraries, like Facebook (Meta) Faiss or Spotify Annoy, provide functionality
    for working with vector data. They typically offer different implementations of
    the **ANN** algorithm, such as clustering or tree-based methods, and allow users
    to perform vector similarity searches for various applications. Let’s quickly
    go through a few of the most popular ones:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 向量库，如Facebook（Meta）Faiss或Spotify Annoy，提供处理向量数据的功能。它们通常提供**ANN**算法的不同实现，如聚类或基于树的方法，并允许用户为各种应用执行向量相似度搜索。让我们快速浏览一些最受欢迎的几个：
- en: '**Faiss** is a library developed by Meta (previously Facebook) that provides
    efficient similarity search and clustering of dense vectors. It offers various
    indexing algorithms, including PQ, LSH, and HNSW. Faiss is widely used for large-scale
    vector search tasks and supports both CPU and GPU acceleration.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Faiss**是由Meta（以前称为Facebook）开发的库，它提供了高效的大规模向量搜索和聚类。它提供了包括PQ、LSH和HNSW在内的各种索引算法。Faiss广泛用于大规模向量搜索任务，并支持CPU和GPU加速。'
- en: '**Annoy** is a C++ library for approximate nearest neighbor search in high-dimensional
    spaces maintained and developed by Spotify, implementing the Annoy algorithm based
    on a forest of random projection trees.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Annoy**是一个由Spotify维护和开发的C++库，用于在多维空间中进行近似最近邻搜索，它基于随机投影树森林实现了Annoy算法。'
- en: '**hnswlib** is a C++ library for approximate nearest-neighbor search using
    the HNSW algorithm.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**hnswlib**是一个使用HNSW算法进行近似最近邻搜索的C++库。'
- en: '**Non-Metric Space Library** (**nmslib**) supports various indexing algorithms
    like HNSW, SW-graph, and SPTAG.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非度量空间库**（**nmslib**）支持各种索引算法，如HNSW、SW-graph和SPTAG。'
- en: '**SPTAG** by Microsoft implements a distributed ANN. It comes with a k-d tree
    and relative neighborhood graph (SPTAG-KDT), and a balanced k-means tree and relative
    neighborhood graph (SPTAG-BKT).'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微软的**SPTAG**实现了分布式ANN。它包含k-d树和相对邻域图（SPTAG-KDT），以及平衡k-means树和相对邻域图（SPTAG-BKT）。
- en: There are a lot more vector search libraries you can choose from. You can get
    a complete overview at [https://github.com/erikbern/ann-benchmarks](https://github.com/erikbern/ann-benchmarks).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以选择的向量搜索库有很多。你可以在[https://github.com/erikbern/ann-benchmarks](https://github.com/erikbern/ann-benchmarks)获得完整的概述。
- en: 'When implementing vector storage solutions, consider:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施向量存储解决方案时，请考虑：
- en: The tradeoff between exact and approximate search
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 精确搜索和近似搜索之间的权衡
- en: Memory constraints and scaling requirements
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存限制和扩展要求
- en: The need for hybrid search capabilities combining vector and traditional search
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要结合向量和传统搜索能力的混合搜索功能
- en: Multi-modal data support requirements
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多模态数据支持要求
- en: Integration costs and maintenance complexity
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成成本和维护复杂性
- en: For many applications, a hybrid approach combining vector search with traditional
    database capabilities provides the most flexible solution.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多应用来说，结合向量搜索和传统数据库功能的混合方法提供了最灵活的解决方案。
- en: Breaking down the RAG pipeline
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分解RAG管道
- en: Think of the RAG pipeline as an assembly line in a library, where raw materials
    (documents) get transformed into a searchable knowledge base that can answer questions.
    Let us walk through how each component plays its part.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 将RAG管道想象成图书馆中的装配线，其中原材料（文档）被转换成可搜索的知识库，可以回答问题。让我们来看看每个组件是如何发挥作用的。
- en: '**Document processing – the foundation**'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**文档处理 – 基础**'
- en: 'Document processing is like preparing books for a library. When documents first
    enter the system, they need to be:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 文档处理就像为图书馆准备书籍。当文档首次进入系统时，它们需要被：
- en: Loaded using document loaders appropriate for their format (PDF, HTML, text,
    etc.)
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用适合其格式的文档加载器加载（PDF、HTML、文本等）
- en: Transformed into a standard format that the system can work with
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换为系统可以处理的标准格式
- en: Split into smaller, meaningful chunks that are easier to process and retrieve
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将其拆分为更小、更有意义的块，以便于处理和检索
- en: For example, when processing a textbook, we might break it into chapter-sized
    or paragraph-sized chunks while preserving important context in metadata.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在处理教科书时，我们可能会将其拆分为章节大小或段落大小的块，同时在元数据中保留重要上下文。
- en: '**Vector indexing – creating the card catalog**'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**向量索引 – 创建卡片目录**'
- en: 'Once documents are processed, we need a way to make them searchable. This is
    where vector indexing comes in. Here’s how it works:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦文档被处理，我们需要一种方法使它们可搜索。这就是向量索引的作用。以下是它是如何工作的：
- en: An embedding model converts each document chunk into a vector (think of it as
    capturing the document’s meaning in a list of numbers)
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌入模型将每个文档块转换为向量（可以将其视为在数字列表中捕捉文档的意义）
- en: These vectors are organized in a special data structure (the vector store) that
    makes them easy to search
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些向量被组织在一个特殊的数据结构（向量存储）中，使得它们易于搜索
- en: The vector store also maintains connections between these vectors and their
    original documents
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量存储还维护这些向量与它们原始文档之间的联系
- en: This is similar to how a library’s card catalog organizes books by subject,
    making it easy to find related materials.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这类似于图书馆的卡片目录按主题组织书籍，使得查找相关材料变得容易。
- en: '**Vector stores – the organized shelves**'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**向量存储 – 有序的书架**'
- en: 'Vector stores are like the organized shelves in our library. They:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储就像我们图书馆中的有序书架。它们：
- en: Store both the document vectors and the original document content
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储文档向量和原始文档内容
- en: Provide efficient ways to search through the vectors
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供高效的方法来搜索向量
- en: Offer different organization methods (like HNSW or IVF) that balance speed and
    accuracy
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供不同的组织方法（如HNSW或IVF），以平衡速度和准确性
- en: For example, using FAISS (a popular vector store), we might organize our vectors
    in a hierarchical structure that lets us quickly narrow down which documents to
    examine in detail.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，使用FAISS（一个流行的向量存储），我们可能会以分层结构组织我们的向量，这样我们可以快速缩小需要详细检查的文档范围。
- en: '**Retrieval – finding the right books**'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检索 – 找到正确的书籍**'
- en: 'Retrieval is where everything comes together. When a question comes in:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 检索是所有事情汇聚的地方。当一个问题时：
- en: The question gets converted into a vector using the same embedding model
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用相同的嵌入模型将问题转换为向量
- en: The vector store finds documents whose vectors are most similar to the question
    vector
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量存储找到与问题向量最相似的文档
- en: 'The retriever might apply additional logic, like:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 检索器可能会应用额外的逻辑，例如：
- en: Removing duplicate information
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除重复信息
- en: Balancing relevance and diversity
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平衡相关性和多样性
- en: Combining results from different search methods
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合不同搜索方法的结果
- en: 'A basic RAG implementation looks like this:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的RAG实现看起来像这样：
- en: '[PRE9]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'results = vector_db.similarity_search(query)This implementation covers the
    core RAG workflow: document loading, embedding, storage, and retrieval.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: results = vector_db.similarity_search(query)此实现涵盖了核心RAG工作流程：文档加载、嵌入、存储和检索。
- en: 'Building a RAG system with LangChain requires understanding two fundamental
    building blocks, which we should discuss a bit more in detail: **document loaders**
    and **retrievers**. Let’s explore how these components work together to create
    effective retrieval systems.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LangChain构建RAG系统需要理解两个基本构建块，我们应更详细地讨论一下：**文档加载器**和**检索器**。让我们探索这些组件如何协同工作以创建有效的检索系统。
- en: Document processing
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文档处理
- en: LangChain provides a comprehensive system for loading documents from various
    sources through document loaders. A document loader is a component in LangChain
    that transforms various data sources into a standardized document format that
    can be used throughout the LangChain ecosystem. Each document contains the actual
    content and associated metadata.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain提供了一套全面的系统，通过文档加载器从各种来源加载文档。文档加载器是LangChain中的一个组件，它将各种数据源转换为LangChain生态系统内可用的标准化文档格式。每个文档包含实际内容和相关元数据。
- en: 'Document loaders serve as the foundation for RAG systems by:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 文档加载器作为RAG系统的基础，通过以下方式服务：
- en: Converting diverse data sources into a uniform format
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将多样化的数据源转换为统一格式
- en: Extracting text and metadata from files
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从文件中提取文本和元数据
- en: Preparing documents for further processing (like chunking or embedding)
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备文档以进行进一步处理（如分块或嵌入）
- en: 'LangChain supports loading documents from a wide range of document types and
    sources through specialized loaders, for example:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain通过专门的加载器支持从广泛的文档类型和来源加载文档，例如：
- en: '**PDFs**: Using PyPDFLoader'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PDFs**：使用PyPDFLoader'
- en: '**HTML**: WebBaseLoader for extracting web page text'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HTML**：WebBaseLoader用于提取网页文本'
- en: '**Plain text**: TextLoader for raw text inputs'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**纯文本**：TextLoader用于原始文本输入'
- en: '**WebBaseLoader** for web page content extraction'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**WebBaseLoader** 用于网页内容提取'
- en: '**ArxivLoader** for scientific papers'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ArxivLoader** 用于科学论文'
- en: '**WikipediaLoader** for encyclopedia entries'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**WikipediaLoader** 用于百科全书条目'
- en: '**YoutubeLoader** for video transcripts'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**YoutubeLoader** 用于视频字幕'
- en: '**ImageCaptionLoader** for image content'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ImageCaptionLoader** 用于图像内容'
- en: You may have noticed some non-text content types in the preceding list. Advanced
    RAG systems can handle non-text data; for example, image embeddings or audio transcripts.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到了前面列表中的一些非文本内容类型。高级RAG系统可以处理非文本数据；例如，图像嵌入或音频转录。
- en: 'The following table organizes LangChain document loaders into a comprehensive
    table:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 下表将LangChain文档加载器组织成一个全面的表格：
- en: '| **Category** | **Description** | **Notable Examples** | **Common Use Cases**
    |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| **类别** | **描述** | **显著示例** | **常见用例** |'
- en: '| File Systems | Load from local files | TextLoader, CSVLoader, PDFLoader |
    Processing local documents, data files |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 文件系统 | 从本地文件加载 | TextLoader, CSVLoader, PDFLoader | 处理本地文档，数据文件 |'
- en: '| Web Content | Extract from online sources | WebBaseLoader, RecursiveURLLoader,
    SitemapLoader | Web scraping, content aggregation |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 网络内容 | 从在线来源提取 | WebBaseLoader, RecursiveURLLoader, SitemapLoader | 网络爬虫，内容聚合
    |'
- en: '|'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Cloud Storage
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 云存储
- en: '| Access cloud-hosted files | S3DirectoryLoader, GCSFileLoader, DropboxLoader
    | Enterprise data integration |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| 访问云托管文件 | S3DirectoryLoader, GCSFileLoader, DropboxLoader | 企业数据集成 |'
- en: '| Databases | Load from structured data stores | MongoDBLoader, SnowflakeLoader,
    BigQueryLoader | Business intelligence, data analysis |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| 数据库 | 从结构化数据存储中加载 | MongoDBLoader, SnowflakeLoader, BigQueryLoader | 商业智能，数据分析
    |'
- en: '| Social Media | Import social platform content | TwitterTweetLoader, RedditPostsLoader,
    DiscordChatLoader | Social media analysis |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 社交媒体 | 导入社交平台内容 | TwitterTweetLoader, RedditPostsLoader, DiscordChatLoader
    | 社交媒体分析 |'
- en: '| Productivity Tools | Access workspace documents | NotionDirectoryLoader,
    SlackDirectoryLoader, TrelloLoader | Knowledge base creation |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 生产力工具 | 访问工作空间文档 | NotionDirectoryLoader, SlackDirectoryLoader, TrelloLoader
    | 知识库创建 |'
- en: '| Scientific Sources | Load academic content | ArxivLoader, PubMedLoader |
    Research applications |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 科学资源 | 加载学术内容 | ArxivLoader, PubMedLoader | 研究应用 |'
- en: 'Table 4.3: Document loaders in LangChain'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.3：LangChain中的文档加载器
- en: 'Finally, modern document loaders offer several sophisticated capabilities:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，现代文档加载器提供了几个高级功能：
- en: Concurrent loading for better performance
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并发加载以提升性能
- en: Metadata extraction and preservation
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元数据提取和保存
- en: Format-specific parsing (like table extraction from PDFs)
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 格式特定解析（如从PDF中提取表格）
- en: Error handling and validation
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错误处理和验证
- en: Integration with transformation pipelines
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与转换管道的集成
- en: 'Let’s go through an example of loading a JSON file. Here’s a typical pattern
    for using a document loader:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个加载 JSON 文件的例子来了解一下。以下是使用文档加载器的一个典型模式：
- en: '[PRE10]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Document loaders come with a standard `.load()` method interface that returns
    documents in LangChain’s document format. The initialization is source-specific.
    After loading, documents often need processing before storage and retrieval, and
    selecting the right chunking strategy determines the relevance and diversity of
    AI-generated responses.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 文档加载器提供了一个标准的 `.load()` 方法接口，它以 LangChain 的文档格式返回文档。初始化是针对源特定的。加载后，文档通常需要处理才能存储和检索，选择正确的分块策略决定了
    AI 生成的响应的相关性和多样性。
- en: Chunking strategies
  id: totrans-334
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分块策略
- en: 'Chunking—how you divide documents into smaller pieces—can dramatically impact
    your RAG system’s performance. Poor chunking can break apart related concepts,
    lose critical context, and ultimately lead to irrelevant retrieval results. The
    way you chunk documents affects:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 分块——您将文档分割成更小的部分的方式——可以显著影响您的 RAG 系统的性能。不良的分块可能会拆分相关概念，丢失关键上下文，并最终导致无关的检索结果。您分块文档的方式会影响：
- en: '**Retrieval accuracy**: Well-formed chunks maintain semantic coherence, making
    them easier to match with relevant queries'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索准确性**：结构良好的块保持语义一致性，这使得它们更容易与相关查询匹配'
- en: '**Context preservation**: Poor chunking can split related information, causing
    knowledge gaps'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文保留**：不良的分块可能会分割相关信息，造成知识空白'
- en: '**Response quality**: When the LLM receives fragmented or irrelevant chunks,
    it generates less accurate responses'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**响应质量**：当 LLM 收到碎片化或不相关的块时，它生成的响应准确性较低'
- en: Let’s explore a hierarchy of chunking approaches, from simple to sophisticated,
    to help you implement the most effective strategy for your specific use case.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索分块方法的层次结构，从简单到复杂，以帮助您为特定的用例实施最有效的策略。
- en: Fixed-size chunking
  id: totrans-340
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 固定大小分块
- en: 'The most basic approach divides text into chunks of a specified length without
    considering content structure:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 最基本的方法是将文本分割成指定长度的块，不考虑内容结构：
- en: '[PRE11]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Fixed-size chunking is good for quick prototyping or when document structure
    is relatively uniform, however, it often splits text at awkward positions, breaking
    sentences, paragraphs, or logical units.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 固定大小的分块对于快速原型设计或当文档结构相对统一时很好，然而，它通常会在尴尬的位置分割文本，破坏句子、段落或逻辑单元。
- en: Recursive character chunking
  id: totrans-344
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 递归字符分块
- en: 'This method respects natural text boundaries by recursively applying different
    separators:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 此方法通过递归应用不同的分隔符来尊重自然文本边界：
- en: '[PRE12]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here are the chunks:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是分块：
- en: '[PRE13]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: How it works is that the splitter first attempts to divide text at paragraph
    breaks (`\n\n`). If the resulting chunks are still too large, it tries the next
    separator (`\n`), and so on. This approach preserves natural text boundaries while
    maintaining reasonable chunk sizes.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 它的工作原理是拆分器首先尝试在段落分隔符（`\n\n`）处分割文本。如果生成的块仍然太大，它将尝试下一个分隔符（`\n`），依此类推。这种方法在保持合理的块大小时，同时保留了自然文本边界。
- en: Recursive character chunking is the recommended default strategy for most applications.
    It works well for a wide range of document types and provides a good balance between
    preserving context and maintaining manageable chunk sizes.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 递归字符分块是大多数应用的推荐默认策略。它适用于广泛的文档类型，并在保留上下文和保持可管理的块大小之间提供了良好的平衡。
- en: Document-specific chunking
  id: totrans-351
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 特定文档分块
- en: Different document types have different structures. Document-specific chunking
    adapts to these structures. An implementation could involve using different specialized
    splitters based on document type using `if` statements. For example, we could
    be using a `MarkdownTextSplitter`, `PythonCodeTextSplitter`, or `HTMLHeaderTextSplitter`
    depending on the content type being markdown, Python, or HTML.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的文档类型有不同的结构。特定文档的分块适应这些结构。实现可能涉及根据文档类型使用不同的专用拆分器，通过 `if` 语句。例如，我们可能使用 `MarkdownTextSplitter`、`PythonCodeTextSplitter`
    或 `HTMLHeaderTextSplitter`，具体取决于内容类型是 markdown、Python 还是 HTML。
- en: This can be useful when working with specialized document formats where structure
    matters – code repositories, technical documentation, markdown articles, or similar.
    Its advantage is that it preserves logical document structure, maintains functional
    units together (like code functions, markdown sections), and improves retrieval
    relevance for domain-specific queries.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 这在处理结构重要的专用文档格式时很有用，例如代码库、技术文档、Markdown文章或类似内容。其优势在于它保留了逻辑文档结构，将功能单元（如代码函数、Markdown部分）保持在一起，并提高了针对特定查询的检索相关性。
- en: Semantic chunking
  id: totrans-354
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 语义分块
- en: Unlike previous approaches that rely on textual separators, semantic chunking
    analyzes the meaning of content to determine chunk boundaries.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 与依赖于文本分隔符的先前方法不同，语义分块通过分析内容的意义来确定块边界。
- en: '[PRE14]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'These are the chunks:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是块：
- en: '[PRE15]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here’s how the `SemanticChunker` works:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是`SemanticChunker`的工作方式：
- en: Splits text into sentences
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文本分割成句子
- en: Creates embeddings for groups of sentences (determined by `buffer_size`)
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为句子组创建嵌入（由`buffer_size`确定）
- en: Measures semantic similarity between adjacent groups
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测量相邻组之间的语义相似度
- en: Identifies natural breakpoints where topics or concepts change
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 识别自然断点，其中主题或概念发生变化
- en: Creates chunks that preserve semantic coherence
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建保持语义连贯性的块
- en: You may use semantic chunking for complex technical documents where semantic
    cohesion is crucial for accurate retrieval and when you’re willing to spend additional
    compute/costs on embedding generation.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用语义分块来处理复杂的技术文档，其中语义连贯性对于准确检索至关重要，并且您愿意在嵌入生成上投入额外的计算/成本。
- en: Benefits include chunk creation based on actual meaning rather than superficial
    text features and keeping related concepts together even when they span traditional
    separator boundaries.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 优点包括基于实际意义而不是表面文本特征创建块，以及即使在跨越传统分隔边界的情况下也能将相关概念保持在一起。
- en: Agent-based chunking
  id: totrans-367
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于代理的分块
- en: 'This experimental approach uses LLMs to intelligently divide text based on
    semantic analysis and content understanding in the following manner:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 这种实验性方法使用LLM根据以下方式进行语义分析和内容理解，智能地划分文本：
- en: Analyze the document’s structure and content
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分析文档的结构和内容
- en: Identify natural breakpoints based on topic shifts
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据主题变化识别自然断点
- en: Determine optimal chunk boundaries that preserve meaning
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定保持意义的最佳块边界
- en: Return a list of starting positions for creating chunks
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 返回创建块的起始位置列表
- en: 'This type of chunking can be useful for exceptionally complex documents where
    standard splitting methods fail to preserve critical relationships between concepts.
    This approach is particularly useful when:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型的分块对于标准分割方法无法保留概念之间关键关系的极其复杂的文档很有用。这种方法特别有用当：
- en: Documents contain intricate logical flows that need to be preserved
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文档包含复杂的逻辑流程，需要保留
- en: Content requires domain-specific understanding to chunk appropriately
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内容需要特定领域的理解才能适当地分块
- en: Maximum retrieval accuracy justifies the additional expense of LLM-based processing
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大的检索准确性证明了基于LLM处理的额外成本是合理的
- en: The limitations are that it comes with a higher computational cost and latency,
    and that chunk sizes are less predictable.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 其局限性在于它具有更高的计算成本和延迟，并且块大小不太可预测。
- en: Multi-modal chunking
  id: totrans-378
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多模态分块
- en: Modern documents often contain a mix of text, tables, images, and code. Multi-modal
    chunking handles these different content types appropriately.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 现代文档通常包含文本、表格、图像和代码的混合。多模态分块适当地处理这些不同的内容类型。
- en: 'We can imagine the following process for multi-modal content:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以想象以下多模态内容的过程：
- en: Extract text, images, and tables separately
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分别提取文本、图像和表格
- en: Process text with appropriate text chunker
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用合适的文本分块器处理文本
- en: Process tables to preserve structure
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理表格以保留结构
- en: 'For images: generate captions or extract text via OCR or a vision LLM'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于图像：生成标题或通过OCR或视觉LLM提取文本
- en: Create metadata linking related elements
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建链接相关元素的元数据
- en: Embed each element appropriately
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 适当地嵌入每个元素
- en: In practice, you would use specialized libraries such as unstructured for document
    parsing, vision models for image understanding, and table extraction tools for
    structured data.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，您会使用专门的库，如用于文档解析的unstructured，用于图像理解的视觉模型，以及用于结构化数据提取的工具。
- en: Choosing the right chunking strategy
  id: totrans-388
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 选择正确的分块策略
- en: 'Your chunking strategy should be guided by document characteristics, retrieval
    needs, and computational resources as the following table illustrates:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 你的块分割策略应受文档特征、检索需求和计算资源的指导，如下表所示：
- en: '| **Factor** | **Condition** | **Recommended Strategy** |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
  zh: '| **因素** | **条件** | **推荐策略** |'
- en: '| **Document Characteristics** | Highly structured documents (markdown, code)
    | Document-specific chunking |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '| **文档特征** | 高度结构化的文档（markdown，代码） | 文档特定块分割 |'
- en: '|  | Complex technical content | Semantic chunking |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '|  | 复杂技术内容 | 语义块分割 |'
- en: '|  | Mixed media | Multi-modal approaches |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '|  | 混合媒体 | 多模态方法 |'
- en: '| **Retrieval Needs** | Fact-based QA | Smaller chunks (100-300 tokens) |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| **检索需求** | 基于事实的问答 | 较小的块（100-300个标记） |'
- en: '|  | Complex reasoning | Larger chunks (500-1000 tokens) |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '|  | 复杂推理 | 较大的块（500-1000个标记） |'
- en: '|  |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '|  |'
- en: Context-heavy answers
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文丰富的答案
- en: '| Sliding window with significant overlap |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 具有显著重叠的滑动窗口 |'
- en: '| **Computational Resources** | Limited API budget | Basic recursive chunking
    |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| **计算资源** | 有限的API预算 | 基本递归块分割 |'
- en: '|  | Performance-critical | Pre-computed semantic chunks |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '|  | 性能关键 | 预计算的语义块 |'
- en: 'Table 4.4: Comparison of chunking strategies'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.4：块分割策略比较
- en: We recommend starting with Level 2 (Recursive Character Chunking) as your baseline,
    then experiment with more advanced strategies if retrieval quality needs improvement.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议从Level 2（递归字符块分割）作为你的基准开始，然后如果需要提高检索质量，可以尝试更高级的策略。
- en: For most RAG applications, the `RecursiveCharacterTextSplitter` with appropriate
    chunk size and overlap settings provides an excellent balance of simplicity, performance,
    and retrieval quality. As your system matures, you can evaluate whether more sophisticated
    chunking strategies deliver meaningful improvements.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数RAG应用，使用适当的块大小和重叠设置的`RecursiveCharacterTextSplitter`提供了简单性、性能和检索质量的良好平衡。随着你的系统成熟，你可以评估更复杂的块分割策略是否带来有意义的改进。
- en: However, it is often critical to performance to experiment with different chunk
    sizes specific to your use case and document types. Please refer to [*Chapter
    8*](E_Chapter_8.xhtml#_idTextAnchor390) for testing and benchmarking strategies.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，针对你的具体用例和文档类型，尝试不同的块大小对于性能来说通常至关重要。请参阅[*第8章*](E_Chapter_8.xhtml#_idTextAnchor390)以获取测试和基准测试策略。
- en: The next section covers semantic search, hybrid methods, and advanced ranking
    techniques.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将介绍语义搜索、混合方法和高级排名技术。
- en: Retrieval
  id: totrans-406
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检索
- en: Retrieval integrates a vector store with other LangChain components for simplified
    querying and compatibility. Retrieval systems form a crucial bridge between unstructured
    queries and relevant documents.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 检索将向量存储与其他LangChain组件集成，以简化查询和兼容性。检索系统在非结构化查询和相关文档之间形成了一个关键桥梁。
- en: In LangChain, a retriever is fundamentally an interface that accepts natural
    language queries and returns relevant documents. Let’s explore how this works
    in detail.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 在LangChain中，检索器本质上是一个接受自然语言查询并返回相关文档的接口。让我们详细探讨它是如何工作的。
- en: 'At its heart, a retriever in LangChain follows a simple yet powerful pattern:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在LangChain中，检索器本质上遵循一个简单而强大的模式：
- en: '**Input**: Takes a query as a string'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入**：接受一个字符串形式的查询'
- en: '**Processing**: Applies retrieval logic specific to the implementation'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理**：应用特定于实现的检索逻辑'
- en: '**Output**: Returns a list of document objects, each containing:'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输出**：返回一个包含以下内容的文档对象列表：'
- en: '`page_content`: The actual document content'
  id: totrans-413
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`page_content`：实际文档内容'
- en: '`metadata`: Associated information like document ID or source'
  id: totrans-414
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata`：关联信息，如文档ID或来源'
- en: This diagram (from the LangChain documentation) illustrates this relationship.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 此图（来自LangChain文档）说明了这种关系。
- en: '![Figure 4.3: The relationship between query, retriever, and documents](img/B32363_04_03.png)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
  zh: '![图4.3：查询、检索器和文档之间的关系](img/B32363_04_03.png)'
- en: 'Figure 4.3: The relationship between query, retriever, and documents'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3：查询、检索器和文档之间的关系
- en: LangChain offers a rich ecosystem of retrievers, each designed to solve specific
    information retrieval challenges.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain提供了一系列丰富的检索器，每个检索器都旨在解决特定的信息检索挑战。
- en: LangChain retrievers
  id: totrans-419
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: LangChain检索器
- en: 'The retrievers can be broadly categorized into a few key groups that serve
    different use cases and implementation needs:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 检索器可以广泛地分为几个关键组，这些组服务于不同的用例和实现需求：
- en: '**Core infrastructure retrievers** include both self-hosted options like ElasticsearchRetriever
    and cloud-based solutions from major providers like Amazon, Google, and Microsoft.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**核心基础设施检索器**包括自托管选项，如ElasticsearchRetriever，以及来自主要提供商如亚马逊、谷歌和微软的云解决方案。'
- en: '**External knowledge retrievers** tap into external and established knowledge
    bases. ArxivRetriever, WikipediaRetriever, and TavilySearchAPI stand out here,
    offering direct access to academic papers, encyclopedia entries, and web content
    respectively.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部知识检索器**利用外部和已建立的知识库。ArxivRetriever、WikipediaRetriever和TavilySearchAPI在这里脱颖而出，分别提供直接访问学术论文、百科全书条目和网页内容。'
- en: '**Algorithmic retrievers** include several classic information retrieval methods.
    The BM25 and TF-IDF retrievers excel at lexical search, while kNN retrievers handle
    semantic similarity searches. Each of these algorithms brings its own strengths
    – BM25 for keyword precision, TF-IDF for document classification, and kNN for
    similarity matching.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**算法检索器**包括几个经典的信息检索方法。BM25和TF-IDF检索器在词汇搜索方面表现出色，而kNN检索器处理语义相似度搜索。每种算法都带来自己的优势——BM25用于关键词精确度，TF-IDF用于文档分类，kNN用于相似度匹配。'
- en: '**Advanced/Specialized retrievers** often address specific performance requirements
    or resource constraints that may arise in production environments. LangChain offers
    specialized retrievers with unique capabilities. NeuralDB provides CPU-optimized
    retrieval, while LLMLingua focuses on document compression.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高级/专用检索器**通常解决生产环境中可能出现的特定性能要求或资源限制。LangChain提供了具有独特功能的专用检索器。NeuralDB提供CPU优化的检索，而LLMLingua专注于文档压缩。'
- en: '**Integration retrievers** connect with popular platforms and services. These
    retrievers, like those for Google Drive or Outline, make it easier to incorporate
    existing document repositories into your RAG application.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集成检索器**连接到流行的平台和服务。这些检索器，如Google Drive或Outline的检索器，使得将现有的文档存储库集成到您的RAG应用程序中变得更加容易。'
- en: 'Here’s a basic example of retriever usage:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个检索器使用的基本示例：
- en: '[PRE16]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'LangChain supports several sophisticated approaches to retrieval:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain支持几种复杂的检索方法：
- en: Vector store retrievers
  id: totrans-429
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 向量存储检索器
- en: 'Vector stores serve as the foundation for semantic search, converting documents
    and queries into embeddings for similarity matching. Any vector store can become
    a retriever through the `as_retriever()` method:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 向量存储作为语义搜索的基础，将文档和查询转换为嵌入以进行相似度匹配。任何向量存储都可以通过`as_retriever()`方法成为检索器：
- en: '[PRE17]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: These are the retrievers most relevant for RAG systems.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是对于RAG系统最相关的检索器。
- en: '**Search API retrievers**: These retrievers interface with external search
    services without storing documents locally. For example:'
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**搜索API检索器**：这些检索器与外部搜索服务接口，而不在本地存储文档。例如：'
- en: '[PRE18]'
  id: totrans-434
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**Database retrievers**: These connect to structured data sources, translating
    natural language queries into database queries:'
  id: totrans-435
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据库检索器**：这些连接到结构化数据源，将自然语言查询转换为数据库查询：'
- en: SQL databases using text-to-SQL conversion
  id: totrans-436
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用文本到SQL转换的SQL数据库
- en: Graph databases using text-to-Cypher translation
  id: totrans-437
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用文本到Cypher翻译的图数据库
- en: Document databases with specialized query interfaces
  id: totrans-438
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有专用查询界面的文档数据库
- en: '**Lexical search retrievers**: These implement traditional text-matching algorithms:'
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**词汇搜索检索器**：这些实现传统的文本匹配算法：'
- en: BM25 for probabilistic ranking
  id: totrans-440
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: BM25用于概率排名
- en: TF-IDF for term frequency analysis
  id: totrans-441
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: TF-IDF用于词频分析
- en: Elasticsearch integration for scalable text search
  id: totrans-442
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展文本搜索的Elasticsearch集成
- en: 'Modern retrieval systems often combine multiple approaches for better results:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 现代检索系统通常结合多种方法以获得更好的结果：
- en: '**Hybrid search**: Combines semantic and lexical search to leverage:'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**混合搜索**：结合语义和词汇搜索以利用：'
- en: Vector similarity for semantic understanding
  id: totrans-445
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量相似性用于语义理解
- en: Keyword matching for precise terminology
  id: totrans-446
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键词匹配以获得精确术语
- en: Weighted combinations for optimal results
  id: totrans-447
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加权组合以获得最佳结果
- en: '**Maximal Marginal Relevance (MMR)**: Optimizes for both relevance and diversity
    by:'
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**最大边际相关性（MMR）**：通过以下方式优化相关性和多样性：'
- en: Selecting documents similar to the query
  id: totrans-449
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择与查询相似的文档
- en: Ensuring retrieved documents are distinct from each other
  id: totrans-450
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保检索到的文档彼此不同
- en: Balancing exploration and exploitation
  id: totrans-451
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平衡探索和利用
- en: '**Custom retrieval logic**: LangChain allows the creation of specialized retrievers
    by implementing the `BaseRetriever` class.'
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自定义检索逻辑**：LangChain允许通过实现`BaseRetriever`类来创建专门的检索器。'
- en: Advanced RAG techniques
  id: totrans-453
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级RAG技术
- en: When building production RAG systems, a simple vector similarity search often
    isn’t enough. Modern applications need more sophisticated approaches to find and
    validate relevant information. Let’s explore how to enhance a basic RAG system
    with advanced techniques that dramatically improve result quality.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建生产级RAG系统时，简单的向量相似性搜索通常是不够的。现代应用需要更复杂的方法来查找和验证相关信息。让我们探讨如何通过使用显著提高结果质量的高级技术来增强基本RAG系统。
- en: 'A standard vector search has several limitations:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 标准向量搜索有几个局限性：
- en: It might miss contextually relevant documents that use different terminology
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能会错过使用不同术语的相关上下文文档
- en: It can’t distinguish between authoritative and less reliable sources
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它无法区分权威和不太可靠的信息来源
- en: It might return redundant or contradictory information
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能会返回冗余或矛盾的信息
- en: It has no way to verify if generated responses accurately reflect the source
    material
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它没有方法来验证生成的响应是否准确反映了源材料
- en: Modern retrieval systems often employ multiple complementary techniques to improve
    result quality. Two particularly powerful approaches are hybrid retrieval and
    re-ranking.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 现代检索系统通常采用多种互补技术来提高结果质量。两种特别有效的方法是混合检索和重排。
- en: 'Hybrid retrieval: Combining semantic and keyword search'
  id: totrans-461
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 混合检索：结合语义和关键词搜索
- en: 'Hybrid retrieval combines two retrieval methods in parallel and the results
    are fused to leverage the strengths of both approaches:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 混合检索并行结合两种检索方法，并将结果融合以利用两种方法的优势：
- en: '**Dense retrieval**: Uses vector embeddings for semantic understanding'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**密集检索**：使用向量嵌入进行语义理解'
- en: '**Sparse retrieval**: Employs lexical methods like BM25 for keyword precision'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**稀疏检索**：采用BM25等词汇方法进行关键词精确度'
- en: For example, a hybrid retriever might use vector similarity to find semantically
    related documents while simultaneously running a keyword search to catch exact
    terminology matches, then combine the results using rank fusion algorithms.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，混合检索器可能使用向量相似性来查找语义相关的文档，同时运行关键词搜索以捕捉精确术语匹配，然后使用排名融合算法结合结果。
- en: '[PRE19]'
  id: totrans-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Re-ranking
  id: totrans-467
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重排
- en: 'Re-ranking is a post-processing step that can follow any retrieval method,
    including hybrid retrieval:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 重排是后处理步骤，可以跟随任何检索方法，包括混合检索：
- en: First, retrieve a larger set of candidate documents
  id: totrans-469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，检索一组更大的候选文档
- en: Apply a more sophisticated model to re-score documents
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用更复杂的模型重新评分文档
- en: Reorder based on these more precise relevance scores
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据这些更精确的相关性分数进行重新排序
- en: 'Re-ranking follows three main paradigms:'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 重排遵循三个主要范式：
- en: '**Pointwise rerankers**: Score each document independently (for example, on
    a scale of 1-10) and sort the resulting array of documents accordingly'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**点重排器**：独立评分每个文档（例如，在1-10的范围内）并相应地排序生成的文档数组'
- en: '**Pairwise rerankers**: Compare document pairs to determine preferences, then
    construct a final ordering by ranking documents based on their win/loss record
    across all comparisons'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成对重排器**：比较文档对以确定偏好，然后通过根据所有比较中的胜负记录对文档进行排序来构建最终排序'
- en: '**Listwise rerankers**: The re-ranking model processes the entire list of documents
    (and the original query) holistically to determine optimal order by optimizing
    NDCG or MAP'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**列表重排器**：重排模型整体处理文档列表（以及原始查询）以通过优化NDCG或MAP来确定最佳顺序'
- en: 'LangChain offers several re-ranking implementations:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain提供了几个重排实现：
- en: '**Cohere rerank**: Commercial API-based solution with excellent quality:'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cohere重排**：基于商业API的高质量解决方案：'
- en: '[PRE20]'
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '**RankLLM**: Library supporting open-source LLMs fine-tuned specifically for
    re-ranking:'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RankLLM**：支持开源LLM的库，专门针对重排进行微调：'
- en: '[PRE21]'
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**LLM-based custom rerankers**: Using any LLM to score document relevance:'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于LLM的定制重排器**：使用任何LLM来评分文档的相关性：'
- en: '[PRE22]'
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Please note that while Hybrid retrieval focuses on how documents are retrieved,
    re-ranking focuses on how they’re ordered after retrieval. These approaches can,
    and often should, be used together in a pipeline. When evaluating re-rankers,
    use position-aware metrics like Recall@k, which measures how effectively the re-ranker
    surfaces all relevant documents in the top positions.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，虽然混合检索侧重于文档的检索方式，但重排侧重于检索后的文档排序。这些方法可以，并且通常应该一起在管道中使用。在评估重排器时，使用位置感知指标如Recall@k，该指标衡量重排器在顶部位置中有效地展示所有相关文档的有效性。
- en: Cross-encoder re-ranking typically improves these metrics by 10-20% over initial
    retrieval, especially for the top positions.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 跨编码重排通常在初始检索的基础上将指标提高10-20%，特别是对于顶部位置。
- en: 'Query transformation: Improving retrieval through better queries'
  id: totrans-485
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查询转换：通过更好的查询提高检索
- en: Even the best retrieval system can struggle with poorly formulated queries.
    Query transformation techniques address this challenge by enhancing or reformulating
    the original query to improve retrieval results.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是最佳的检索系统也可能难以处理表述不佳的查询。查询转换技术通过增强或重新表述原始查询来改善检索结果。
- en: 'Query expansion generates multiple variations of the original query to capture
    different aspects or phrasings. This helps bridge the vocabulary gap between users
    and documents:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 查询扩展生成原始查询的多个变体，以捕捉不同的方面或措辞。这有助于弥合用户和文档之间的词汇差距：
- en: '[PRE23]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Generate three alternative versions that express the same information need
    but with different wording:'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: 生成三个表达相同信息需求但措辞不同的替代版本：
- en: '[PRE24]'
  id: totrans-490
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let’s see this in practice:'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看实际应用中的情况：
- en: '[PRE25]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We should be getting something like this:'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该得到类似这样的结果：
- en: '[PRE26]'
  id: totrans-494
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: A more advanced approach is **Hypothetical Document Embeddings** (**HyDE**).
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 一种更高级的方法是**假设文档嵌入**（**HyDE**）。
- en: Hypothetical Document Embeddings (HyDE)
  id: totrans-496
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 假设文档嵌入（HyDE）
- en: 'HyDE uses an LLM to generate a hypothetical answer document based on the query,
    and then uses that document’s embedding for retrieval. This technique is especially
    powerful for complex queries where the semantic gap between query and document
    language is significant:'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: HyDE使用一个LLM根据查询生成一个假设的答案文档，然后使用该文档的嵌入进行检索。这种技术在处理语义差距较大的复杂查询时特别强大：
- en: '[PRE27]'
  id: totrans-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Query transformation techniques are particularly useful when dealing with ambiguous
    queries, questions formulated by non-experts, or situations where terminology
    mismatches between queries and documents are common. They do add computational
    overhead but can dramatically improve retrieval quality, especially for complex
    or poorly formulated questions.
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 查询转换技术在处理模糊查询、非专家提出的疑问或查询与文档之间术语不匹配常见的情况下特别有用。它们确实增加了计算开销，但可以显著提高检索质量，尤其是对于复杂或表述不佳的问题。
- en: 'Context processing: maximizing retrieved information value'
  id: totrans-500
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 上下文处理：最大化检索信息价值
- en: Once documents are retrieved, context processing techniques help distill and
    organize the information to maximize its value in the generation phase.
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦检索到文档，上下文处理技术有助于提炼和组织信息，以最大化其在生成阶段的价值。
- en: Contextual compression
  id: totrans-502
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 上下文压缩
- en: 'Contextual compression extracts only the most relevant parts of retrieved documents,
    removing irrelevant content that might distract the generator:'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文压缩仅提取检索文档中最相关的部分，移除可能分散生成器注意力的不相关内容：
- en: '[PRE28]'
  id: totrans-504
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Here are our compressed documents:'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我们的压缩文档：
- en: '[PRE29]'
  id: totrans-506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Maximum marginal relevance
  id: totrans-507
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 最大边际相关性
- en: 'Another powerful approach is **Maximum Marginal Relevance** (**MMR**), which
    balances document relevance with diversity, ensuring that the retrieved set contains
    varied perspectives rather than redundant information:'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种强大的方法是**最大边际相关性**（**MMR**），它平衡了文档的相关性和多样性，确保检索到的集合包含不同的观点，而不是冗余信息：
- en: '[PRE30]'
  id: totrans-509
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Context processing techniques are especially valuable when dealing with lengthy
    documents where only portions are relevant, or when providing comprehensive coverage
    of a topic requires diverse viewpoints. They help reduce noise in the generator’s
    input and ensure that the most valuable information is prioritized.
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文处理技术在处理篇幅较长的文档，其中只有部分相关，或当需要全面覆盖一个主题需要不同观点时特别有价值。它们有助于减少生成器输入中的噪声，并确保最有价值的信息得到优先处理。
- en: The final area for RAG enhancement focuses on improving the generated response
    itself, ensuring it’s accurate, trustworthy, and useful.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: RAG增强的最后一个领域是改进生成的响应本身，确保其准确、可靠且有用。
- en: 'Response enhancement: Improving generator output'
  id: totrans-512
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 响应增强：改进生成器输出
- en: These response enhancement techniques are particularly important in applications
    where accuracy and transparency are paramount, such as educational resources,
    healthcare information, or legal advice. They help build user trust by making
    AI-generated content more verifiable and reliable.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 这些响应增强技术在准确性透明度至关重要的应用中尤为重要，例如教育资源、医疗信息或法律建议。它们通过使AI生成的内容更具可验证性和可靠性来帮助建立用户信任。
- en: 'Let’s first assume we have some documents as our knowledge base:'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们假设我们有一些文档作为我们的知识库：
- en: '[PRE31]'
  id: totrans-515
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-516
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Source attribution
  id: totrans-517
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 来源归属
- en: 'Source attribution explicitly connects generated information to the retrieved
    sources, helping users verify facts and understand where information comes from.
    Let’s set up our foundation for source attribution. We’ll initialize a vector
    store with our documents and create a retriever configured to fetch the top 3
    most relevant documents for each query. The attribution prompt template instructs
    the model to use citations for each claim and include a reference list:'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 来源归属明确地将生成信息与检索到的来源联系起来，帮助用户核实事实并了解信息来源。让我们为来源归属设置基础。我们将初始化一个包含我们的文档的向量存储，并创建一个配置为为每个查询检索最相关的前3个文档的检索器。归属提示模板指示模型为每个主张使用引用并包含参考文献列表：
- en: '[PRE33]'
  id: totrans-519
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-520
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Next, we’ll need helper functions to format the sources with citation numbers
    and generate attributed responses:'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要辅助函数来格式化带有引用编号的来源并生成归属响应：
- en: '[PRE35]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-523
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'This example implements source attribution by:'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例通过以下方式实现来源归属：
- en: Retrieving relevant documents for a query
  id: totrans-525
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为查询检索相关文档
- en: Formatting each document with a citation number
  id: totrans-526
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以引用编号格式化每份文档
- en: Using a prompt that explicitly requests citations for each fact
  id: totrans-527
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用提示明确要求为每个事实提供引用
- en: Generating a response that includes inline citations ([1], [2], etc.)
  id: totrans-528
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成包含内联引用（[1]，[2]，等等）的响应
- en: Adding a references section that links each citation to its source
  id: totrans-529
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加参考文献部分，将每个引用链接到其来源
- en: The key advantages of this approach are transparency and verifiability – users
    can trace each claim back to its source, which is especially important for academic,
    medical, or legal applications.
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的关键优势是透明度和可验证性——用户可以追踪每个主张回到其来源，这对于学术、医学或法律应用尤为重要。
- en: 'Let’s see what we get when we execute this with a query:'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看执行查询时我们会得到什么：
- en: '[PRE37]'
  id: totrans-532
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-533
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Self-consistency checking compares the generated response against the retrieved
    context to verify accuracy and identify potential hallucinations.
  id: totrans-534
  prefs: []
  type: TYPE_NORMAL
  zh: 自洽性检查将生成的响应与检索到的上下文进行比较，以验证准确性并识别潜在的幻觉。
- en: 'Self-consistency checking: ensuring factual accuracy'
  id: totrans-535
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自洽性检查：确保事实准确性
- en: 'Self-consistency checking verifies that generated responses accurately reflect
    the information in retrieved documents, providing a crucial layer of protection
    against hallucinations. We can use LCEL to create streamlined verification pipelines:'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
  zh: 自洽性检查验证生成的响应是否准确反映了检索到的文档中的信息，提供了一层至关重要的保护，以防止幻觉。我们可以使用LCEL创建简化的验证管道：
- en: '[PRE39]'
  id: totrans-537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-538
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The function above begins our verification process by accepting the retrieved
    documents and generated answers as inputs. It initializes a language model for
    verification if one isn’t provided and combines all document content into a single
    context string. Next, we’ll define the verification prompt that instructs the
    LLM to perform a detailed fact-checking analysis:'
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的函数通过接受检索到的文档和生成的答案作为输入来开始我们的验证过程。如果没有提供，它将初始化一个用于验证的语言模型，并将所有文档内容组合成一个单一上下文字符串。接下来，我们将定义验证提示，指导LLM执行详细的核实分析：
- en: '[PRE41]'
  id: totrans-540
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-541
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: The verification prompt is structured to perform a comprehensive fact check.
    It instructs the model to break down each claim in the answer and categorize it
    based on how well it’s supported by the provided context. The prompt also requests
    the output in a structured JSON format that can be easily processed programmatically.
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 验证提示的结构是为了执行全面的核实。它指示模型将答案中的每个主张分解，并根据提供的上下文支持程度对其进行分类。提示还要求以结构化的JSON格式输出，以便易于程序化处理。
- en: 'Finally, we’ll complete the function with the verification chain and example
    usage:'
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将通过验证链和示例用法完成函数：
- en: '[PRE43]'
  id: totrans-544
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-545
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We should get a response like this:'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该得到如下响应：
- en: '[PRE45]'
  id: totrans-547
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-548
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Based on the verification result, you can:'
  id: totrans-549
  prefs: []
  type: TYPE_NORMAL
  zh: 根据验证结果，您可以：
- en: Regenerate the answer if issues are found
  id: totrans-550
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果发现问题，重新生成答案
- en: Add qualifying statements to indicate uncertainty
  id: totrans-551
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加限定性语句以表示不确定性
- en: Filter out unsupported claims
  id: totrans-552
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过滤掉未经支持的断言
- en: Include confidence indicators for different parts of the response
  id: totrans-553
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为响应的不同部分包含置信度指标
- en: This approach systematically analyzes generated responses against source documents,
    identifying specific unsupported claims rather than just providing a binary assessment.
    For each factual assertion, it determines whether it’s fully supported, partially
    supported, contradicted, or not mentioned in the context.
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法系统地分析生成的响应与源文档，识别具体的未经支持的断言，而不仅仅是提供二元评估。对于每个事实主张，它确定它是否得到充分支持、部分支持、相互矛盾或未在上下文中提及。
- en: Self-consistency checking is essential for applications where trustworthiness
    is paramount, such as medical information, financial advice, or educational content.
    Detecting and addressing hallucinations before they reach users significantly
    improves the reliability of RAG systems.
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: 自洽性检查对于信任至关重要的应用至关重要，例如医疗信息、财务建议或教育内容。在用户之前检测和处理幻觉可以显著提高 RAG 系统的可靠性。
- en: 'The verification can be further enhanced by:'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 验证可以通过以下方式进一步增强：
- en: '**Granular claim extraction**: Breaking down complex responses into atomic
    factual claims'
  id: totrans-557
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**细粒度断言提取**：将复杂响应分解为原子事实断言'
- en: '**Evidence linking**: Explicitly connecting each claim to specific supporting
    text'
  id: totrans-558
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**证据链接**：明确地将每个断言与特定的支持文本连接起来'
- en: '**Confidence scoring**: Assigning numerical confidence scores to different
    parts of the response'
  id: totrans-559
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**置信度评分**：将数值置信度评分分配给响应的不同部分'
- en: '**Selective regeneration**: Regenerating only the unsupported portions of responses'
  id: totrans-560
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**选择性再生**：仅再生响应中不受支持的部分'
- en: These techniques create a verification layer that substantially reduces the
    risk of presenting incorrect information to users while maintaining the fluency
    and coherence of generated responses.
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术创建了一个验证层，在保持生成响应的流畅性和连贯性的同时，大大降低了向用户呈现错误信息的风险。
- en: While the techniques we’ve discussed enhance individual components of the RAG
    pipeline, corrective RAG represents a more holistic approach that addresses fundamental
    retrieval quality issues at a systemic level.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们讨论的技术增强了 RAG 管道的各个组件，但纠正 RAG 代表了一种更全面的方法，它从系统层面解决基本的检索质量问题。
- en: Corrective RAG
  id: totrans-563
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 纠正 RAG
- en: The techniques we’ve explored so far mostly assume that our retrieval mechanism
    returns relevant, accurate documents. But what happens when it doesn’t? In real-world
    applications, retrieval systems often return irrelevant, insufficient, or even
    misleading content. This “garbage in, garbage out” problem represents a critical
    vulnerability in standard RAG systems. **Corrective Retrieval-Augmented Generation**
    (**CRAG**) directly addresses this challenge by introducing explicit evaluation
    and correction mechanisms into the RAG pipeline.
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 我们迄今为止探索的技术大多假设我们的检索机制返回相关、准确的文档。但是，当它不这样做时会发生什么？在现实世界的应用中，检索系统经常返回无关、不足，甚至误导性的内容。这个问题“垃圾输入，垃圾输出”代表了标准
    RAG 系统的一个关键漏洞。**纠正检索增强生成**（**CRAG**）通过在 RAG 管道中引入显式的评估和纠正机制直接解决这一挑战。
- en: 'CRAG extends the standard RAG pipeline with evaluation and conditional branching:'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: CRAG 通过评估和条件分支扩展了标准的 RAG 管道：
- en: '**Initial retrieval:** Standard document retrieval from the vector store based
    on the query.'
  id: totrans-566
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**初始检索**：根据查询从向量存储中检索标准文档。'
- en: '**Retrieval evaluation:** A retrieval evaluator component assesses each document’s
    relevance and quality.'
  id: totrans-567
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检索评估**：检索评估组件评估每份文档的相关性和质量。'
- en: '**Conditional correction:**'
  id: totrans-568
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**条件纠正**：'
- en: '**Relevant documents:** Pass high-quality documents directly to the generator.'
  id: totrans-569
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**相关文档**：将高质量文档直接传递给生成器。'
- en: '**Irrelevant documents:** Filter out low-quality documents to prevent noise.'
  id: totrans-570
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**无关文档**：过滤掉低质量文档以防止噪声。'
- en: '**Insufficient/Ambiguous results:** Trigger alternative information-seeking
    strategies (like web search) when internal knowledge is inadequate.'
  id: totrans-571
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**不足/模糊的结果**：当内部知识不足时，触发替代的信息寻求策略（如网络搜索）。'
- en: '**Generation:** Produce the final response using the filtered or augmented
    context.'
  id: totrans-572
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**生成**：使用过滤或增强的上下文生成最终响应。'
- en: This workflow transforms RAG from a static pipeline into a more dynamic, self-correcting
    system capable of seeking additional information when needed.
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 此工作流程将 RAG 从静态管道转变为更动态、自我纠正的系统，能够在需要时寻求更多信息。
- en: '![Figure 4.4: Corrective RAG workflow showing evaluation and conditional branching](img/B32363_04_04.png)'
  id: totrans-574
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4：显示评估和条件分支的纠正 RAG 工作流程](img/B32363_04_04.png)'
- en: 'Figure 4.4: Corrective RAG workflow showing evaluation and conditional branching'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4：显示评估和条件分支的纠正 RAG 工作流程
- en: 'The retrieval evaluator is the cornerstone of CRAG. Its job is to analyze the
    relationship between retrieved documents and the query, determining which documents
    are truly relevant. Implementations typically use an LLM with a carefully crafted
    prompt:'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 检索评估者是 CRAG 的基石。其任务是分析检索文档与查询之间的关系，确定哪些文档真正相关。实现通常使用一个精心设计的提示的 LLM：
- en: '[PRE47]'
  id: totrans-577
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: By evaluating each document independently, CRAG can make fine-grained decisions
    about which content to include, exclude, or supplement, substantially improving
    the quality of the final context provided to the generator.
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 通过独立评估每份文档，CRAG可以就包含、排除或补充哪些内容做出细致的决策，从而显著提高提供给生成器的最终上下文的质量。
- en: Since the CRAG implementation builds on concepts we’ll introduce in [*Chapter
    5*](E_Chapter_5.xhtml#_idTextAnchor231), we’ll not be showing the complete code
    here, but you can find the implementation in the book’s companion repository.
    Please note that LangGraph is particularly well-suited for implementing CRAG because
    it allows for conditional branching based on document evaluation.
  id: totrans-579
  prefs: []
  type: TYPE_NORMAL
  zh: 由于CRAG实现基于我们在[*第五章*](E_Chapter_5.xhtml#_idTextAnchor231)中将要介绍的概念，我们在此不展示完整的代码，但您可以在书籍的配套仓库中找到实现。请注意，LangGraph特别适合实现CRAG，因为它允许根据文档评估进行条件分支。
- en: While CRAG enhances RAG by adding evaluation and correction mechanisms to the
    retrieval pipeline, Agentic RAG represents a more fundamental paradigm shift by
    introducing autonomous AI agents to orchestrate the entire RAG process.
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 当CRAG通过在检索管道中添加评估和纠正机制来增强RAG时，代理式RAG通过引入自主AI代理来编排整个RAG过程，代表了一种更根本的范式转变。
- en: Agentic RAG
  id: totrans-581
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代理式RAG
- en: 'Agentic RAG employs AI agents—autonomous systems capable of planning, reasoning,
    and decision-making—to dynamically manage information retrieval and generation.
    Unlike traditional RAG or even CRAG, which follow relatively structured workflows,
    agentic RAG uses agents to:'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 代理式RAG采用AI代理——能够进行规划、推理和决策的自主系统——来动态管理信息检索和生成。与传统的RAG或甚至CRAG不同，它们遵循相对结构化的工作流程，代理式RAG使用代理来：
- en: Analyze queries and decompose complex questions into manageable sub-questions
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析查询并将复杂问题分解为可管理的子问题
- en: Plan information-gathering strategies based on the specific task requirements
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据具体任务需求制定信息收集策略
- en: Select appropriate tools (retrievers, web search, calculators, APIs, etc.)
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择合适的工具（检索器、网络搜索、计算器、API等）
- en: Execute multi-step processes, potentially involving multiple rounds of retrieval
    and reasoning
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行多步过程，可能涉及多轮检索和推理
- en: Reflect on intermediate results and adapt strategies accordingly
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反思中间结果并根据情况调整策略
- en: 'The key distinction between CRAG and agentic RAG lies in their focus: CRAG
    primarily enhances data quality through evaluation and correction, while agentic
    RAG focuses on process intelligence through autonomous planning and orchestration.'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: CRAG与代理式RAG之间的关键区别在于它们的重点：CRAG主要通过评估和纠正来增强数据质量，而代理式RAG则侧重于通过自主规划和编排来提高过程智能。
- en: 'Agentic RAG is particularly valuable for complex use cases that require:'
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 代理式RAG对于需要以下复杂用例尤其有价值：
- en: Multi-step reasoning across multiple information sources
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在多个信息源之间进行多步推理
- en: Dynamic tool selection based on query analysis
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据查询分析进行动态工具选择
- en: Persistent task execution with intermediate reflection
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有中间反思的持续任务执行
- en: Integration with various external systems and APIs
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成各种外部系统和API
- en: However, agentic RAG introduces significant complexity in implementation, potentially
    higher latency due to multiple reasoning steps, and increased computational costs
    from multiple LLM calls for planning and reflection.
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，代理式RAG在实施过程中引入了显著的复杂性，由于多个推理步骤，可能导致更高的延迟，以及由于多次调用LLM进行规划和反思而增加的计算成本。
- en: In [*Chapter 5*](E_Chapter_5.xhtml#_idTextAnchor231), we’ll explore the implementation
    of agent-based systems in depth, including patterns that can be applied to create
    agentic RAG systems. The core techniques—tool integration, planning, reflection,
    and orchestration—are fundamental to both general agent systems and agentic RAG
    specifically.
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第五章*](E_Chapter_5.xhtml#_idTextAnchor231)中，我们将深入探讨基于代理的系统实现，包括可以应用于创建代理式RAG系统的模式。核心技术——工具集成、规划、反思和编排——对于通用代理系统和特定的代理式RAG都是基本的。
- en: By understanding both CRAG and agentic RAG approaches, you’ll be equipped to
    select the most appropriate RAG architecture based on your specific requirements,
    balancing accuracy, flexibility, complexity, and performance.
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 通过理解CRAG和代理式RAG方法，您将能够根据您的具体要求选择最合适的RAG架构，平衡准确性、灵活性、复杂性和性能。
- en: Choosing the right techniques
  id: totrans-597
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择正确的技术
- en: 'When implementing advanced RAG techniques, consider the specific requirements
    and constraints of your application. To guide your decision-making process, the
    following table provides a comprehensive comparison of RAG approaches discussed
    throughout this chapter:'
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现高级RAG技术时，请考虑您应用程序的具体需求和限制。为了指导您的决策过程，以下表格提供了本章讨论的RAG方法的全面比较：
- en: '| **RAG Approach** | **Chapter Section** | **Core Mechanism** | **Key Strengths**
    | **Key Weaknesses** | **Primary Use Cases** | **Relative Complexity** |'
  id: totrans-599
  prefs: []
  type: TYPE_TB
  zh: '| **RAG方法** | **章节部分** | **核心机制** | **主要优势** | **主要劣势** | **主要用例** | **相对复杂性**
    |'
- en: '| Naive RAG | Breaking down the RAG pipeline | Basic index ![](img/Icon.png)
    retrieve ![](img/Icon.png) generate workflow with single retrieval step |'
  id: totrans-600
  prefs: []
  type: TYPE_TB
  zh: '| 基础RAG | 拆分RAG管道 | 具有单个检索步骤的基本索引 ![](img/Icon.png) 检索 ![](img/Icon.png) 生成工作流程
    |'
- en: Simple implementation
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的实现
- en: Low initial resource usage
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始资源使用量低
- en: Straightforward debugging
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的调试
- en: '|'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Limited retrieval quality
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索质量有限
- en: Vulnerability to hallucinations
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容易产生幻觉
- en: No handling of retrieval failures
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不处理检索失败的情况
- en: '|'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Simple Q&A systems
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的问答系统
- en: Basic document lookup
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本文档查找
- en: Prototyping
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原型设计
- en: '| Low |'
  id: totrans-612
  prefs: []
  type: TYPE_TB
  zh: '| 低 |'
- en: '| Hybrid Retrieval | Advanced RAG techniques – hybrid retrieval | Combines
    sparse (BM25) and dense (vector) retrieval methods |'
  id: totrans-613
  prefs: []
  type: TYPE_TB
  zh: '| 混合检索 | 高级RAG技术 – 混合检索 | 结合稀疏（BM25）和密集（向量）检索方法 |'
- en: Balances keyword precision with semantic understanding
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平衡关键词精确度与语义理解
- en: Handles vocabulary mismatch
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理词汇不匹配
- en: Improves recall without sacrificing precision
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不牺牲精确度的同时提高召回率
- en: '|'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Increased system complexity
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统复杂性增加
- en: Challenge in optimizing fusion weights
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化融合权重的挑战
- en: Higher computational overhead
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 较高的计算开销
- en: '|'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Technical documentation
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 技术文档
- en: Content with specialized terminology
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 含有专业术语的内容
- en: Multi-domain knowledge bases
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多领域知识库
- en: '| Medium |'
  id: totrans-625
  prefs: []
  type: TYPE_TB
  zh: '| 中等 |'
- en: '| Re-ranking | Advanced RAG techniques – re-ranking | Post-processes initial
    retrieval results with more sophisticated relevance models |'
  id: totrans-626
  prefs: []
  type: TYPE_TB
  zh: '| 重新排序 | 高级RAG技术 – 重新排序 | 使用更复杂的相关性模型后处理初始检索结果 |'
- en: Improves result ordering
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改善结果排序
- en: Captures nuanced relevance signals
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 捕获细微的相关性信号
- en: Can be applied to any retrieval method
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可应用于任何检索方法
- en: '|'
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Additional computation layer
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 额外的计算层
- en: May create bottlenecks for large result sets
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能会为大型结果集创建瓶颈
- en: Requires training or configuring re-rankers
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要训练或配置重新排序器
- en: '|'
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: When retrieval quality is critical
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当检索质量至关重要时
- en: For handling ambiguous queries
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理模糊查询的方法
- en: High-value information needs
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高价值信息需求
- en: '| Medium |'
  id: totrans-638
  prefs: []
  type: TYPE_TB
  zh: '| 中等 |'
- en: '| Query Transformation (HyDE) | Advanced RAG techniques – query transformation
    | Generates hypothetical document from query for improved retrieval |'
  id: totrans-639
  prefs: []
  type: TYPE_TB
  zh: '| 查询转换（HyDE） | 高级RAG技术 – 查询转换 | 从查询生成假设文档以改进检索 |'
- en: Bridges query-document semantic gap
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 桥接查询-文档语义差距
- en: Improves retrieval for complex queries
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改善复杂查询的检索效果
- en: Handles implicit information needs
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理隐含的信息需求
- en: '|'
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Additional LLM generation step
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 额外的LLM生成步骤
- en: Depends on hypothetical document quality
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 依赖于假设文档的质量
- en: Potential for query drift
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询漂移的潜在可能性
- en: '|'
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Complex or ambiguous queries
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂或模糊的查询
- en: Users with unclear information needs
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信息需求不明确的用户
- en: Domain-specific search
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领域特定搜索
- en: '| Medium |'
  id: totrans-651
  prefs: []
  type: TYPE_TB
  zh: '| 中等 |'
- en: '|'
  id: totrans-652
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Context Processing
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文处理
- en: '| Advanced RAG techniques - context processing | Optimizes retrieved documents
    before sending to the generator (compression, MMR) |'
  id: totrans-654
  prefs: []
  type: TYPE_TB
  zh: '| 高级RAG技术 – 上下文处理 | 在发送到生成器之前优化检索到的文档（压缩，MMR） |'
- en: Maximizes context window utilization
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大化上下文窗口利用率
- en: Reduces redundancy Focuses on most relevant information
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少冗余，关注最相关信息
- en: '|'
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Risk of removing important context
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除重要上下文的风险
- en: Processing adds latency
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理增加延迟
- en: May lose document coherence
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能会失去文档的连贯性
- en: '|'
  id: totrans-661
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Large documents
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大型文档
- en: When context window is limited
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当上下文窗口有限时
- en: Redundant information sources
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 红余信息源
- en: '| Medium |'
  id: totrans-665
  prefs: []
  type: TYPE_TB
  zh: '| 中等 |'
- en: '| Response Enhancement | Advanced RAG techniques – response enhancement | Improves
    generated output with source attribution and consistency checking |'
  id: totrans-666
  prefs: []
  type: TYPE_TB
  zh: '| 响应增强 | 高级RAG技术 – 响应增强 | 通过来源归属和一致性检查改进生成的输出 |'
- en: Increases output trustworthiness
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高输出可信度
- en: Provides verification mechanisms
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供验证机制
- en: Enhances user confidence
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高用户信心
- en: '|'
  id: totrans-670
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: May reduce fluency or conciseness
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能会降低流畅性或简洁性
- en: Additional post-processing overhead
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 额外的后处理开销
- en: Complex implementation logic
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂的实现逻辑
- en: '|'
  id: totrans-674
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Educational or research content
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 教育或研究内容
- en: Legal or medical information
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 法律或医学信息
- en: When attribution is required
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当需要归属时
- en: '| Medium-High |'
  id: totrans-678
  prefs: []
  type: TYPE_TB
  zh: '| 中高 |'
- en: '| Corrective RAG (CRAG) | Advanced RAG techniques – corrective RAG | Evaluates
    retrieved documents and takes corrective actions (filtering, web search) |'
  id: totrans-679
  prefs: []
  type: TYPE_TB
  zh: '| 纠正RAG（CRAG） | 高级RAG技术 – 纠正RAG | 评估检索到的文档并采取纠正措施（过滤、网络搜索）|'
- en: Explicitly handles poor retrieval results
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 明确处理检索结果不佳的情况
- en: Improves robustness
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高鲁棒性
- en: Can dynamically supplement knowledge
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以动态补充知识
- en: '|'
  id: totrans-683
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Increased latency from evaluation
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估带来的增加延迟
- en: Depends on evaluator accuracy
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 取决于评估者的准确性
- en: More complex conditional logic
  id: totrans-686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更复杂的条件逻辑
- en: '|'
  id: totrans-687
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: High-reliability requirements
  id: totrans-688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高可靠性要求
- en: Systems needing factual accuracy
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要事实准确性的系统
- en: Applications with potential knowledge gaps
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有潜在知识差距的应用
- en: '| High |'
  id: totrans-691
  prefs: []
  type: TYPE_TB
  zh: '| 高 |'
- en: '| Agentic RAG | Advanced RAG techniques – agentic RAG | Uses autonomous AI
    agents to orchestrate information gathering and synthesis |'
  id: totrans-692
  prefs: []
  type: TYPE_TB
  zh: '| 代理RAG | 高级RAG技术 – 代理RAG | 使用自主AI代理来协调信息收集和综合 |'
- en: Highly adaptable to complex tasks
  id: totrans-693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高度适应复杂任务
- en: Can use diverse tools beyond retrieval
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用除检索以外的多种工具
- en: Multi-step reasoning capabilities
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多步骤推理能力
- en: '|'
  id: totrans-696
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Significant implementation complexity
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重要的实现复杂性
- en: Higher cost and latency
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更高的成本和延迟
- en: Challenging to debug and control
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试和控制具有挑战性
- en: '|'
  id: totrans-700
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Complex multi-step information tasks
  id: totrans-701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂的多步骤信息任务
- en: Research applications
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 研究应用
- en: Systems integrating multiple data sources
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成多个数据源的系统
- en: '| Very High |'
  id: totrans-704
  prefs: []
  type: TYPE_TB
  zh: '| 非常高 |'
- en: 'Table 4.5: Comparing RAG techniques'
  id: totrans-705
  prefs: []
  type: TYPE_NORMAL
  zh: 表4.5：比较RAG技术
- en: For technical or specialized domains with complex terminology, hybrid retrieval
    provides a strong foundation by capturing both semantic relationships and exact
    terminology. When dealing with lengthy documents where only portions are relevant,
    add contextual compression to extract the most pertinent sections.
  id: totrans-706
  prefs: []
  type: TYPE_NORMAL
  zh: 对于具有复杂术语的技术或专业领域，混合检索通过捕捉语义关系和精确术语提供了一个强大的基础。当处理只有部分内容相关的长文档时，添加上下文压缩以提取最相关的部分。
- en: For applications where accuracy and transparency are critical, implement source
    attribution and self-consistency checking to ensure that generated responses are
    faithful to the retrieved information. If users frequently submit ambiguous or
    poorly formulated queries, query transformation techniques can help bridge the
    gap between user language and document terminology.
  id: totrans-707
  prefs: []
  type: TYPE_NORMAL
  zh: 对于准确性和透明度至关重要的应用，实施来源归属和自洽性检查，以确保生成的响应忠实于检索到的信息。如果用户经常提交含糊不清或表述不佳的查询，查询转换技术可以帮助弥合用户语言和文档术语之间的差距。
- en: So when should you choose each approach?
  id: totrans-708
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你何时应该选择每种方法？
- en: Start with naive RAG for quick prototyping and simple question-answering
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从简单的RAG原型设计和问答开始
- en: Add hybrid retrieval when facing vocabulary mismatch issues or mixed content
    types
  id: totrans-710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在面对词汇不匹配问题或混合内容类型时添加混合检索
- en: Implement re-ranking when the initial retrieval quality needs refinement
  id: totrans-711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当初始检索质量需要细化时实施重新排序
- en: Use query transformation for complex queries or when users struggle to articulate
    information needs
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在处理复杂查询或用户难以表达信息需求时使用查询转换
- en: Apply context processing when dealing with limited context windows or redundant
    information
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在处理有限上下文窗口或冗余信息时应用上下文处理
- en: Add response enhancement for applications requiring high trustworthiness and
    attribution
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为需要高可信度和归属的应用添加响应增强
- en: Consider CRAG when reliability and factual accuracy are mission-critical
  id: totrans-715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑CRAG（纠正RAG）当可靠性和事实准确性是关键任务时
- en: Explore agentic RAG (covered more in [*Chapter 5*](E_Chapter_5.xhtml#_idTextAnchor231))
    for complex, multi-step information tasks requiring reasoning
  id: totrans-716
  prefs: []
  type: TYPE_NORMAL
  zh: 探索代理RAG（在[*第五章*](E_Chapter_5.xhtml#_idTextAnchor231)中介绍更多）用于复杂的多步骤信息任务，这些任务需要推理
- en: In practice, production RAG systems often combine multiple approaches. For example,
    a robust enterprise system might use hybrid retrieval with query transformation,
    apply context processing to optimize the retrieved information, enhance responses
    with source attribution, and implement CRAG’s evaluation layer for critical applications.
  id: totrans-717
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，生产RAG系统通常结合多种方法。例如，一个健壮的企业系统可能会使用混合检索和查询转换，应用上下文处理以优化检索到的信息，通过来源归属增强响应，并在关键应用中实施CRAG的评估层。
- en: Start with implementing one or two key techniques that address your most pressing
    challenges, then measure their impact on performance metrics like relevance, accuracy,
    and user satisfaction. Add additional techniques incrementally as needed, always
    considering the tradeoff between improved results and increased computational
    costs.
  id: totrans-718
  prefs: []
  type: TYPE_NORMAL
  zh: 从实施一个或两个解决你最紧迫挑战的关键技术开始，然后衡量它们对性能指标（如相关性、准确性和用户满意度）的影响。根据需要逐步添加更多技术，始终考虑改进结果和增加计算成本之间的权衡。
- en: To demonstrate a RAG system in practice, in the next section, we’ll walk through
    the implementation of a chatbot that retrieves and integrates external knowledge
    into responses.
  id: totrans-719
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示RAG系统在实际中的应用，在下一节中，我们将介绍一个聊天机器人的实现，该聊天机器人检索并整合外部知识到响应中。
- en: Developing a corporate documentation chatbot
  id: totrans-720
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发企业级文档聊天机器人
- en: 'In this section, we will build a corporate documentation chatbot that leverages
    LangChain for LLM interactions and LangGraph for state management and workflow
    orchestration. LangGraph complements the implementation in several critical ways:'
  id: totrans-721
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将构建一个利用LangChain进行LLM交互和LangGraph进行状态管理和工作流程编排的企业级文档聊天机器人。LangGraph在几个关键方面补充了实现：
- en: '**Explicit state management**: Unlike basic RAG pipelines that operate as linear
    sequences, LangGraph maintains a formal state object containing all relevant information
    (queries, retrieved documents, intermediate results, etc.).'
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**显式状态管理**：与作为线性序列运行的基本RAG管道不同，LangGraph维护一个包含所有相关信息（查询、检索到的文档、中间结果等）的正式状态对象。'
- en: '**Conditional processing**: LangGraph enables conditional branching based on
    the quality of retrieved documents or other evaluation criteria—essential for
    ensuring reliable output.'
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**条件处理**：LangGraph允许基于检索到的文档质量或其他评估标准进行条件分支——这对于确保可靠输出至关重要。'
- en: '**Multi-step reasoning**: For complex documentation tasks, LangGraph allows
    breaking the process into discrete steps (retrieval, generation, validation, refinement)
    while maintaining context throughout.'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多步推理**：对于复杂的文档任务，LangGraph允许将过程分解为离散步骤（检索、生成、验证、细化），同时在整个过程中保持上下文。'
- en: '**Human-in-the-loop integration**: When document quality or compliance cannot
    be automatically verified, LangGraph facilitates seamless integration of human
    feedback.'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人类在环集成**：当文档质量或合规性无法自动验证时，LangGraph促进人类反馈的无缝集成。'
- en: 'With the **Corporate Documentation Manager** tool we built, you can generate,
    validate, and refine project documentation while incorporating human feedback
    to ensure compliance with corporate standards. In many organizations, maintaining
    up-to-date project documentation is critical. Our pipeline leverages LLMs to:'
  id: totrans-726
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们构建的**企业文档管理器**工具，您可以生成、验证和细化项目文档，同时结合人类反馈以确保符合企业标准。在许多组织中，保持项目文档的最新性至关重要。我们的管道利用LLM来实现：
- en: '**Generate documentation**: Produce detailed project documentation from a user’s
    prompt'
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成文档**：根据用户的提示生成详细的项目文档'
- en: '**Conduct compliance checks**: Analyze the generated document for adherence
    to corporate standards and best practices'
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**执行合规性检查**：分析生成的文档是否符合企业标准和最佳实践'
- en: '**Handle human feedback**: Solicit expert feedback if compliance issues are
    detected'
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理人类反馈**：如果检测到合规性问题，征求专家反馈'
- en: '**Finalize documentation**: Revise the document based on feedback to ensure
    it is both accurate and compliant'
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最终化文档**：根据反馈修订文档，以确保其准确性和合规性'
- en: The idea is that this process not only streamlines documentation creation but
    also introduces a safety net by involving human-in-the-loop validation. The code
    is split into several modules, each handling a specific part of the pipeline,
    and a Streamlit app ties everything together for a web-based interface.
  id: totrans-731
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是，这个过程不仅简化了文档创建，而且通过涉及人类在环验证引入了一个安全网。代码被分成几个模块，每个模块处理管道的特定部分，而Streamlit应用程序将一切整合在一起，以实现基于网络的界面。
- en: 'The code will demonstrate the following key features:'
  id: totrans-732
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将展示以下关键特性：
- en: '**Modular pipeline design**: Defines a clear state and uses nodes for documentation
    generation, compliance analysis, human feedback, and finalization'
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模块化管道设计**：定义清晰的州并使用节点进行文档生成、合规性分析、人类反馈和最终化'
- en: '**Interactive interface**: Integrates the pipeline with Gradio for real-time
    user interactions'
  id: totrans-734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**交互式界面**：将管道与Gradio集成，以实现实时用户交互'
- en: While this chapter provides a brief overview of performance measurements and
    evaluation metrics, an in-depth discussion of performance and observability will
    be covered in [*Chapter 8*](E_Chapter_8.xhtml#_idTextAnchor390). Please make sure
    you have installed all the dependencies needed for this book, as explained in
    [*Chapter 2*](E_Chapter_2.xhtml#_idTextAnchor044). Otherwise, you might run into
    issues.
  id: totrans-735
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本章提供了性能测量和评估指标的简要概述，但性能和可观察性的深入讨论将在[*第8章*](E_Chapter_8.xhtml#_idTextAnchor390)中进行。请确保您已安装本书所需的全部依赖项，如[*第2章*](E_Chapter_2.xhtml#_idTextAnchor044)中所述。否则，您可能会遇到问题。
- en: Additionally, given the pace of the field and the development of the LangChain
    library, we are making an effort to keep the GitHub repository up to date. Please
    see [https://github.com/benman1/generative_ai_with_langchain](https://github.com/benman1/generative_ai_with_langchain).
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，鉴于该领域的发展速度和LangChain库的开发，我们正努力保持GitHub存储库的更新。请参阅[https://github.com/benman1/generative_ai_with_langchain](https://github.com/benman1/generative_ai_with_langchain)。
- en: 'For any questions, or if you have any trouble running the code, please create
    an issue on GitHub or join the discussion on Discord: [https://packt.link/lang](https://packt.link/lang).'
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任何问题，或者如果您在运行代码时遇到任何麻烦，请在GitHub上创建一个问题或加入Discord上的讨论：[https://packt.link/lang](https://packt.link/lang)。
- en: Let’s get started! Each file in the project serves a specific role in the overall
    documentation chatbot. Let’s first look at document loading.
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！项目中的每个文件在整体文档聊天机器人中都有其特定的作用。让我们首先看看文档加载。
- en: Document loading
  id: totrans-739
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文档加载
- en: The main purpose of this module is to give an interface to read different document
    formats.
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: 此模块的主要目的是提供一个接口来读取不同的文档格式。
- en: The `Document` class in LangChain is a fundamental data structure for storing
    and manipulating text content along with associated metadata. It stores text content
    through its required `page_content` parameter along with optional metadata stored
    as a dictionary.
  id: totrans-741
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain中的`Document`类是存储和操作文本内容及其相关元数据的基本数据结构。它通过其必需的`page_content`参数存储文本内容，以及作为字典存储的可选元数据。
- en: 'The class also supports an optional `id` parameter that ideally should be formatted
    as a UUID to uniquely identify documents across collections, though this isn’t
    strictly enforced. Documents can be created by simply passing content and metadata,
    as in this example:'
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: 该类还支持一个可选的`id`参数，理想情况下应格式化为UUID，以在集合间唯一标识文档，尽管这不是强制性的。可以通过简单地传递内容和元数据来创建文档，如下例所示：
- en: '[PRE48]'
  id: totrans-743
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: This interface serves as the standard representation of text data throughout
    LangChain’s document processing pipelines, enabling consistent handling during
    loading, splitting, transformation, and retrieval operations.
  id: totrans-744
  prefs: []
  type: TYPE_NORMAL
  zh: 此接口作为LangChain文档处理管道中文本数据的标准表示，使加载、拆分、转换和检索操作期间的处理保持一致。
- en: 'This module is responsible for loading documents in various formats. It defines:'
  id: totrans-745
  prefs: []
  type: TYPE_NORMAL
  zh: 此模块负责加载各种格式的文档。它定义了：
- en: '**Custom Loader classes**: The `EpubReader` class inherits from `UnstructuredEPubLoader`
    and configures it to work in “fast” mode using element extraction, optimizing
    it for EPUB document processing.'
  id: totrans-746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自定义加载器类**：`EpubReader`类继承自`UnstructuredEPubLoader`，并配置它使用元素提取在“快速”模式下工作，从而优化EPUB文档处理。'
- en: '**DocumentLoader class**: A central class that manages document loading across
    different file formats by maintaining a mapping between file extensions and their
    appropriate loader classes.'
  id: totrans-747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DocumentLoader类**：一个中央类，通过维护文件扩展名与其适当的加载器类之间的映射来管理不同文件格式的文档加载。'
- en: '**load_document function**: A utility function that accepts a file path, determines
    its extension, instantiates the appropriate loader class from the `DocumentLoader`''s
    mapping, and returns the loaded content as a list of `Document` objects.'
  id: totrans-748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加载文档函数**：一个实用函数，它接受一个文件路径，确定其扩展名，从`DocumentLoader`的映射中实例化适当的加载器类，并返回作为`Document`对象列表的加载内容。'
- en: 'Let’s get the imports out of the way:'
  id: totrans-749
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先把导入的部分处理掉：
- en: '[PRE49]'
  id: totrans-750
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: This module first defines a custom class, `EpubReader`, that inherits from `UnstructuredEPubLoader`.
    This class is responsible for loading documents with supported extensions. The
    `supported_extentions` dictionary maps file extensions to their corresponding
    document loader classes. This gives us interfaces to read PDF, text, EPUB, and
    Word documents with different extensions.
  id: totrans-751
  prefs: []
  type: TYPE_NORMAL
  zh: 此模块首先定义了一个自定义类`EpubReader`，该类继承自`UnstructuredEPubLoader`。此类负责加载具有支持扩展名的文档。`supported_extentions`字典将文件扩展名映射到相应的文档加载器类。这为我们提供了读取具有不同扩展名的PDF、文本、EPUB和Word文档的接口。
- en: 'The `EpubReader` class inherits from an EPUB loader and configures it to work
    in `"fast"` mode using element extraction:'
  id: totrans-752
  prefs: []
  type: TYPE_NORMAL
  zh: '`EpubReader`类继承自EPUB加载器，并配置它以使用元素提取在`"fast"`模式下工作：'
- en: '[PRE50]'
  id: totrans-753
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Our `DocumentLoader` maintains a mapping (`supported_extensions`) of file extensions
    (for example, .pdf, .txt, .epub, .docx, .doc) to their respective loader classes.
    But we’ll also need one more function:'
  id: totrans-754
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`DocumentLoader`维护一个文件扩展名（例如，.pdf、.txt、.epub、.docx、.doc）到其相应加载器类的映射（`supported_extensions`）。但我们也需要一个额外的函数：
- en: '[PRE51]'
  id: totrans-755
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-756
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: The `load_document` function defined above takes a file path, determines its
    extension, selects the appropriate loader from the `supported_extensions` dictionary,
    and returns a list of `Document` objects. If the file extension isn’t supported,
    it raises a `DocumentLoaderException` to alert the user that the file type cannot
    be processed.
  id: totrans-757
  prefs: []
  type: TYPE_NORMAL
  zh: 上文定义的`load_document`函数接受一个文件路径，确定其扩展名，从`supported_extensions`字典中选择适当的加载器，并返回一个`Document`对象列表。如果文件扩展名不受支持，它将引发`DocumentLoaderException`以提醒用户该文件类型无法处理。
- en: Language model setup
  id: totrans-758
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语言模型设置
- en: The `llms.py` module sets up the LLM and embeddings for the application. First,
    the imports and loading the API keys as environment variables – please see [*Chapter
    2*](E_Chapter_2.xhtml#_idTextAnchor044) for details if you skipped that part.
  id: totrans-759
  prefs: []
  type: TYPE_NORMAL
  zh: '`llms.py`模块设置应用程序的LLM和嵌入。首先，导入并加载API密钥作为环境变量 - 如果您跳过了那一部分，请参阅[*第2章*](E_Chapter_2.xhtml#_idTextAnchor044)以获取详细信息。'
- en: '[PRE53]'
  id: totrans-760
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Let’s initialize the LangChain `ChatGroq` interface using the API key from
    environment variables:'
  id: totrans-761
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用环境变量中的API密钥初始化LangChain `ChatGroq`接口：
- en: '[PRE54]'
  id: totrans-762
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: This uses `ChatGroq` (configured with a specific model, temperature, and retries)
    for generating documentation drafts and revisions. The configured model is the
    DeepSeek 70B R1 model.
  id: totrans-763
  prefs: []
  type: TYPE_NORMAL
  zh: 这使用`ChatGroq`（配置了特定模型、温度和重试次数）来生成文档草案和修订。配置的模型是DeepSeek 70B R1模型。
- en: 'We’ll then use `OpenAIEmbeddings` to convert text into vector representations:'
  id: totrans-764
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将使用`OpenAIEmbeddings`将文本转换为向量表示：
- en: '[PRE55]'
  id: totrans-765
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[PRE56]'
  id: totrans-766
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: To reduce API costs and speed up repeated queries, it wraps the embeddings with
    a caching mechanism (`CacheBackedEmbeddings`) that stores vectors locally in a
    file-based store (`LocalFileStore`).
  id: totrans-767
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少API成本并加快重复查询，它使用缓存机制（`CacheBackedEmbeddings`）将嵌入包装起来，该机制在基于文件的存储（`LocalFileStore`）中本地存储向量。
- en: Document retrieval
  id: totrans-768
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文档检索
- en: 'The `rag.py` module implements document retrieval based on semantic similarity.
    We have these main components:'
  id: totrans-769
  prefs: []
  type: TYPE_NORMAL
  zh: '`rag.py`模块实现了基于语义相似性的文档检索。我们主要有以下组件：'
- en: Text splitting
  id: totrans-770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本拆分
- en: In-memory vector store
  id: totrans-771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存向量存储
- en: '`DocumentRetriever` class'
  id: totrans-772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DocumentRetriever`类'
- en: 'Let’s start with the imports again:'
  id: totrans-773
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次开始导入：
- en: '[PRE57]'
  id: totrans-774
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We need to set up a vector store for the retriever to use:'
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为检索器设置一个向量存储：
- en: '[PRE58]'
  id: totrans-776
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The document chunks are stored in an `InMemoryVectorStore` using the cached
    embeddings, allowing for fast similarity searches. The module uses `RecursiveCharacterTextSplitter`
    to break documents into smaller chunks, which makes them more manageable for retrieval:'
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: 文档块使用缓存的嵌入存储在`InMemoryVectorStore`中，允许快速相似性搜索。该模块使用`RecursiveCharacterTextSplitter`将文档拆分为更小的块，这使得它们在检索时更容易管理：
- en: '[PRE59]'
  id: totrans-778
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'This custom retriever inherits from a base retriever and manages an internal
    list of documents:'
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: 此自定义检索器继承自基本检索器并管理一个内部文档列表：
- en: '[PRE60]'
  id: totrans-780
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-781
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'There are a few methods that we should explain:'
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个方法我们应该解释：
- en: '`store_documents()` splits the documents and adds them to the vector store.'
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`store_documents()`将文档拆分并添加到向量存储中。'
- en: '`add_uploaded_docs()` processes files uploaded by the user, stores them temporarily,
    loads them as documents, and adds them to the vector store.'
  id: totrans-784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`add_uploaded_docs()`处理用户上传的文件，临时存储它们，将它们作为文档加载，并将它们添加到向量存储中。'
- en: '`_get_relevant_documents()` returns the top k documents related to a given
    query from the vector store. This is the similarity search that we’ll use.'
  id: totrans-785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_get_relevant_documents()`从向量存储中返回与给定查询相关的top k个文档。这是我们将要使用的相似性搜索。'
- en: Designing the state graph
  id: totrans-786
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计状态图
- en: 'The `rag.py` module implements the RAG pipeline that ties together document
    retrieval with LLM-based generation:'
  id: totrans-787
  prefs: []
  type: TYPE_NORMAL
  zh: '`rag.py`模块实现了将文档检索与基于LLM的生成结合在一起的RAG管道：'
- en: '**System prompt**: A template prompt instructs the AI on how to use the provided
    document snippets when generating a response. This prompt sets the context and
    provides guidance on how to utilize the retrieved information.'
  id: totrans-788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统提示**：模板提示指导AI如何使用提供的文档片段来生成响应。此提示设置上下文并提供如何利用检索到的信息的指导。'
- en: '**State definition**: A `TypedDict` class defines the structure of our graph’s
    state, tracking key information like the user’s question, retrieved context documents,
    generated answers, issues reports, and the conversation’s message history. This
    state object flows through each node in our pipeline and gets updated at each
    step.'
  id: totrans-789
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**状态定义**：一个`TypedDict`类定义了我们图的状态结构，跟踪关键信息，如用户的问题、检索到的上下文文档、生成的答案、问题报告以及对话的消息历史。此状态对象流经我们流程中的每个节点，并在每个步骤中更新。'
- en: '**Pipeline steps**: The module defines several key functions that serve as
    processing nodes in our graph:'
  id: totrans-790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流程步骤**：该模块定义了几个关键函数，这些函数作为我们图中的处理节点：'
- en: '**Retrieve function**: Fetches relevant documents based on the user’s query'
  id: totrans-791
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索函数**：根据用户的查询获取相关文档'
- en: '**generate function**: Creates a draft answer using the retrieved documents
    and query'
  id: totrans-792
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**generate函数**：使用检索到的文档和查询创建草稿答案'
- en: '**double_check function**: Evaluates the generated content for compliance with
    corporate standards'
  id: totrans-793
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**double_check函数**：评估生成内容是否符合公司标准'
- en: '**doc_finalizer function**: Either returns the original answer if no issues
    were found or revises it based on the feedback from the checker'
  id: totrans-794
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**doc_finalizer函数**：如果没有发现问题，则返回原始答案；否则，根据检查员的反馈进行修改'
- en: '**Graph compilation**: Uses a state graph (via LangGraph’s `StateGraph`) to
    define the sequence of steps. The pipeline is then compiled into a runnable graph
    that can process queries through the complete workflow.'
  id: totrans-795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图编译**：使用状态图（通过LangGraph的`StateGraph`）来定义步骤的顺序。然后，将流程编译成一个可运行的图，可以通过完整的工作流程处理查询。'
- en: 'Let’s get the imports out of the way:'
  id: totrans-796
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把导入的部分处理掉：
- en: '[PRE62]'
  id: totrans-797
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'As we mentioned earlier, the system prompt template instructs the AI on how
    to use the provided document snippets when generating a response:'
  id: totrans-798
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，系统提示模板指导AI如何在使用提供的文档片段生成响应时使用：
- en: '[PRE63]'
  id: totrans-799
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'We’ll then instantiate a `DocumentRetriever` and a `prompt`:'
  id: totrans-800
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将实例化一个`DocumentRetriever`和一个`prompt`：
- en: '[PRE64]'
  id: totrans-801
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'We then have to define the state of the graph. A `TypedDict` state is used
    to hold the current state of the application (for example, question, context documents,
    answer, issues report):'
  id: totrans-802
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来需要定义图的状态。使用`TypedDict`状态来保持应用程序的当前状态（例如，问题、上下文文档、答案、问题报告）：
- en: '[PRE65]'
  id: totrans-803
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Each of these fields corresponds to a node in the graph that we’ll define with
    LangGraph. We have the following processing in the nodes:'
  id: totrans-804
  prefs: []
  type: TYPE_NORMAL
  zh: 这些字段对应于我们将使用LangGraph定义的图中的节点。我们在节点中有以下处理：
- en: '`retrieve` function: Uses the retriever to get relevant documents based on
    the most recent message'
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`retrieve`函数：使用检索器根据最新消息获取相关文档'
- en: '`generate` function: Creates a draft answer by combining the retrieved document
    content with the user question using the chat prompt'
  id: totrans-806
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generate`函数：通过使用聊天提示将检索到的文档内容与用户问题结合，创建草稿答案'
- en: '`double_check` function: Reviews the generated draft for compliance with corporate
    standards. It checks the draft and sets flags if issues are detected'
  id: totrans-807
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`double_check`函数：检查生成的草稿是否符合公司标准。如果发现问题，它会设置标志'
- en: '`doc_finalizer` function: If issues are found, it revises the document based
    on the provided feedback; otherwise, it returns the original answer'
  id: totrans-808
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`doc_finalizer`函数：如果发现问题，则根据提供的反馈修改文档；否则，返回原始答案'
- en: 'Let’s start with the retrieval:'
  id: totrans-809
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从检索开始：
- en: '[PRE66]'
  id: totrans-810
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'We’ll also implement a content validation check as a critical quality assurance
    step in our RAG pipeline. Please note that this is the simplest implementation
    possible. In a production environment, we could have implemented a human-in-the-loop
    review process or more sophisticated guardrails. Here, we’re using an LLM to analyze
    the generated content for any issues:'
  id: totrans-811
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将实现一个内容验证检查，作为我们RAG流程中的关键质量保证步骤。请注意，这是可能的最简单实现。在生产环境中，我们可以实现人工审查流程或更复杂的防护措施。在这里，我们使用LLM分析生成内容以查找任何问题：
- en: '[PRE67]'
  id: totrans-812
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The final node integrates any feedback to produce the finalized, compliant
    document:'
  id: totrans-813
  prefs: []
  type: TYPE_NORMAL
  zh: 最终节点整合任何反馈以生成最终、符合标准的文档：
- en: '[PRE68]'
  id: totrans-814
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '[PRE69]'
  id: totrans-815
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'With our nodes defined, we construct the state graph:'
  id: totrans-816
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了节点后，我们构建状态图：
- en: '[PRE70]'
  id: totrans-817
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'This is what the sequential flow from document retrieval to generation, validation,
    and finalization looks like:'
  id: totrans-818
  prefs: []
  type: TYPE_NORMAL
  zh: 这是从文档检索到生成、验证和最终化的顺序流程：
- en: '![Figure 4.5:  State graph of the corporate documentation pipeline](img/B32363_04_05.png)'
  id: totrans-819
  prefs: []
  type: TYPE_IMG
  zh: '![图4.5：公司文档流程的状态图](img/B32363_04_05.png)'
- en: 'Figure 4.5: State graph of the corporate documentation pipeline'
  id: totrans-820
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5：公司文档流程的状态图
- en: 'Before building a user interface, it’s important to test our RAG pipeline to
    ensure it functions correctly. Let’s examine how we can do this programmatically:'
  id: totrans-821
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建用户界面之前，测试我们的 RAG 流程以确保其正确运行非常重要。让我们探讨如何以编程方式执行此操作：
- en: '[PRE71]'
  id: totrans-822
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The execution time varies depending on the complexity of the query and how
    extensively the model needs to reason about its response. Each step in our graph
    may involve API calls to the LLM, which contributes to the overall processing
    time. Once the pipeline completes, we can extract the final response from the
    returned object:'
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: 执行时间取决于查询的复杂性和模型需要对其响应进行推理的程度。我们的图中的每一步都可能涉及对 LLM 的 API 调用，这有助于总体处理时间。一旦流程完成，我们可以从返回的对象中提取最终响应：
- en: '[PRE72]'
  id: totrans-824
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: The response object contains the complete state of our workflow, including all
    intermediate results. By accessing `response["messages"][-1].content`, we’re retrieving
    the content of the last message, which contains the finalized answer generated
    by our RAG pipeline.
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
  zh: 响应对象包含了我们工作流程的完整状态，包括所有中间结果。通过访问 `response["messages"][-1].content`，我们正在检索最后一条消息的内容，其中包含了由我们的
    RAG 流程生成的最终答案。
- en: Now that we’ve confirmed our pipeline works as expected, we can create a user-friendly
    interface. While there are several Python frameworks available for building interactive
    interfaces (such as Gradio, Dash, and Taipy), we’ll use Streamlit due to its popularity,
    simplicity, and strong integration with data science workflows. Let’s explore
    how to create a comprehensive user interface for our RAG application!
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确认我们的流程按预期工作，我们可以创建一个用户友好的界面。虽然有几个 Python 框架可用于构建交互式界面（如 Gradio、Dash 和
    Taipy），但我们将使用 Streamlit，因为它受欢迎、简单，并且与数据科学工作流程集成良好。让我们探索如何为我们的 RAG 应用程序创建一个全面的用户界面！
- en: Integrating with Streamlit for a user interface
  id: totrans-827
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成 Streamlit 以实现用户界面
- en: 'We integrate our pipeline with Streamlit to enable interactive documentation
    generation. This interface lets users submit documentation requests and view the
    process in real time:'
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将我们的流程与 Streamlit 集成以实现交互式文档生成。此界面允许用户提交文档请求并实时查看过程：
- en: '[PRE73]'
  id: totrans-829
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'We’ll configure the Streamlit page with a title and wide layout for better
    readability:'
  id: totrans-830
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用标题和宽布局配置 Streamlit 页面，以获得更好的可读性：
- en: '[PRE74]'
  id: totrans-831
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'We’ll initialize the session state for chat history and file management:'
  id: totrans-832
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将初始化会话状态以保存聊天历史和文件管理：
- en: '[PRE75]'
  id: totrans-833
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Every time we reload the app, we display chat messages from the history on
    the app rerun:'
  id: totrans-834
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我们重新加载应用程序时，我们都会在应用程序重新运行时显示历史聊天消息：
- en: '[PRE76]'
  id: totrans-835
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'The retriever processes all uploaded files and embeds them for semantic search:'
  id: totrans-836
  prefs: []
  type: TYPE_NORMAL
  zh: 检索器处理所有上传的文件并将它们嵌入以进行语义搜索：
- en: '[PRE77]'
  id: totrans-837
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: Please remember to avoid repeated calls for the same documents, we’re using
    a cache.
  id: totrans-838
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住避免对同一文档进行重复调用，我们正在使用缓存。
- en: 'We need a function next to invoke the graph and return a string:'
  id: totrans-839
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个函数来调用图并返回一个字符串：
- en: '[PRE78]'
  id: totrans-840
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'This ignores the previous messages. We could change the prompt to provide previous
    messages to the LLM. We can then show a project description using markdown. Just
    briefly:'
  id: totrans-841
  prefs: []
  type: TYPE_NORMAL
  zh: 这将忽略之前的消息。我们可以更改提示以向 LLM 提供之前的消息。然后我们可以使用 markdown 显示项目描述。简要来说：
- en: '[PRE79]'
  id: totrans-842
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Next, we present our UI in two columns, one for chat and one for file management:'
  id: totrans-843
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将我们的 UI 以两列的形式展示，一列用于聊天，另一列用于文件管理：
- en: '[PRE80]'
  id: totrans-844
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Column 1 looks like this:'
  id: totrans-845
  prefs: []
  type: TYPE_NORMAL
  zh: 第一列看起来像这样：
- en: '[PRE81]'
  id: totrans-846
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '[PRE82]'
  id: totrans-847
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Column 2 takes the files and gives them to the retriever:'
  id: totrans-848
  prefs: []
  type: TYPE_NORMAL
  zh: 第二列接收文件并将它们交给检索器：
- en: '[PRE83]'
  id: totrans-849
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'To run our Corporate Documentation Manager application on Linux or macOS, follow
    these steps:'
  id: totrans-850
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Linux 或 macOS 上运行我们的企业文档管理器应用程序，请按照以下步骤操作：
- en: Open your terminal and change directory to where your project files are. This
    ensures that the `chapter4/` directory is accessible.
  id: totrans-851
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开您的终端并将目录更改为您的项目文件所在的位置。这确保了 `chapter4/` 目录可访问。
- en: 'Set `PYTHONPATH` and run Streamlit. The imports within the project rely on
    the current directory being in the Python module search path. Therefore, we’ll
    set `PYTHONPATH` when we run Streamlit:'
  id: totrans-852
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 `PYTHONPATH` 并运行 Streamlit。项目中的导入依赖于当前目录位于 Python 模块搜索路径中。因此，我们将设置 `PYTHONPATH`
    当我们运行 Streamlit：
- en: '[PRE84]'
  id: totrans-853
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: The preceding command tells Python to look in the current directory for modules,
    allowing it to find the `chapter4` package.
  id: totrans-854
  prefs: []
  type: TYPE_NORMAL
  zh: 此前命令告诉 Python 在当前目录中查找模块，使其能够找到 `chapter4` 包。
- en: Once the command runs successfully, Streamlit will start a web server. Open
    your web browser and navigate to `http://localhost:8501` to use the application.
  id: totrans-855
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦命令成功运行，Streamlit 将启动一个网络服务器。打开您的网络浏览器并导航到 `http://localhost:8501` 以使用应用程序。
- en: '**Troubleshooting tips**'
  id: totrans-856
  prefs: []
  type: TYPE_NORMAL
  zh: '**故障排除技巧**'
- en: Please make sure you’ve installed all required packages. You can ensure you
    have Python installed on your system by using pip or other package managers as
    explained in [*Chapter 2*](E_Chapter_2.xhtml#_idTextAnchor044).
  id: totrans-857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请确保您已安装所有必需的包。您可以通过使用pip或其他包管理器，如[*第二章*](E_Chapter_2.xhtml#_idTextAnchor044)中所述，来确保您的系统上已安装Python。
- en: If you encounter import errors, verify that you’re in the correct directory
    and that `PYTHONPATH` is set correctly.
  id: totrans-858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您遇到导入错误，请验证您是否位于正确的目录中，并且`PYTHONPATH`设置正确。
- en: By following these steps, you should be able to run the application and use
    it to generate, check, and finalize corporate documentation with ease.
  id: totrans-859
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循这些步骤，您应该能够轻松运行应用程序，并使用它来生成、检查和最终确定企业文档。
- en: Evaluation and performance considerations
  id: totrans-860
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估和性能考虑
- en: In [*Chapter 3*](E_Chapter_3.xhtml#_idTextAnchor107), we explored implementing
    RAG with citations in the Corporate Documentation Manager example. To further
    enhance reliability, additional mechanisms can be incorporated into the pipeline.
    One improvement is to integrate a robust retrieval system such as FAISS, Pinecone,
    or Elasticsearch to fetch real-time sources. This is complemented by scoring mechanisms
    like precision, recall, and mean reciprocal rank to evaluate retrieval quality.
    Another enhancement involves assessing answer accuracy by comparing generated
    responses against ground-truth data or curated references and incorporating human-in-the-loop
    validation to ensure the outputs are both correct and useful.
  id: totrans-861
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第三章*](E_Chapter_3.xhtml#_idTextAnchor107)中，我们探讨了在《企业文档管理器》示例中实现RAG（检索即生成）与引用的结合。为了进一步提高可靠性，可以将额外的机制整合到流程中。一项改进是将FAISS、Pinecone或Elasticsearch等强大的检索系统集成到流程中，以获取实时来源。这通过评分机制如精确度、召回率和平均倒数排名来补充，以评估检索质量。另一项增强是通过将生成的响应与真实数据或精选参考数据进行比较来评估答案的准确性，并引入人工验证以确保输出既正确又有用。
- en: It is also important to implement robust error-handling routines within each
    node. For example, if a citation retrieval fails, the system might fall back to
    default sources or note that citations could not be retrieved. Building observability
    into the pipeline by logging API calls, node execution times, and retrieval performance
    is essential for scaling up and maintaining reliability in production. Optimizing
    API use by leveraging local models when possible, caching common queries, and
    managing memory efficiently when handling large-scale embeddings further supports
    cost optimization and scalability.
  id: totrans-862
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个节点中实现健壮的错误处理程序也同样重要。例如，如果引用检索失败，系统可能会回退到默认来源或指出无法检索引用。通过记录API调用、节点执行时间和检索性能将可观察性构建到流程中对于扩大规模和在生产中保持可靠性至关重要。通过在可能的情况下利用本地模型、缓存常见查询和在处理大规模嵌入时高效管理内存来优化API的使用，进一步支持成本优化和可扩展性。
- en: Evaluating and optimizing our documentation chatbot is vital for ensuring both
    accuracy and efficiency. Modern benchmarks focus on whether the documentation
    meets corporate standards and how accurately it addresses the original request.
    Retrieval quality metrics such as precision, recall, and mean reciprocal rank
    measure the effectiveness of retrieving relevant content during compliance checks.
    Comparing the AI-generated documentation against ground-truth or manually curated
    examples provides a basis for assessing answer accuracy. Performance can be improved
    by fine-tuning search parameters for faster retrieval, optimizing memory management
    for large-scale embeddings, and reducing API costs by using local models for inference
    when applicable.
  id: totrans-863
  prefs: []
  type: TYPE_NORMAL
  zh: 评估和优化我们的文档聊天机器人对于确保准确性和效率至关重要。现代基准主要关注文档是否符合企业标准以及它如何准确地回应原始请求。检索质量指标，如精确度、召回率和平均倒数排名，衡量在合规性检查期间检索相关内容的有效性。将AI生成的文档与真实数据或手动精选的示例进行比较，为评估答案准确性提供了基础。通过微调搜索参数以实现更快的检索、优化大规模嵌入的内存管理以及在使用本地模型进行推理时减少API成本，可以提高性能。
- en: These strategies build a more reliable, transparent, and production-ready RAG
    application that not only generates content but also explains its sources. Further
    performance and observability strategies will be covered in [*Chapter 8*](E_Chapter_8.xhtml#_idTextAnchor390).
  id: totrans-864
  prefs: []
  type: TYPE_NORMAL
  zh: 这些策略构建了一个更可靠、更透明且适用于生产的RAG应用程序，它不仅生成内容，还解释其来源。进一步的性能和可观察性策略将在[*第八章*](E_Chapter_8.xhtml#_idTextAnchor390)中介绍。
- en: Building an effective RAG system means understanding its common failure points
    and addressing them with quantitative and testing-based strategies. In the next
    section, we’ll explore the typical failure points and best practices in relation
    to RAG systems.
  id: totrans-865
  prefs: []
  type: TYPE_NORMAL
  zh: 建立一个有效的RAG系统意味着理解其常见的故障点，并使用基于数量和测试的策略来解决它们。在下一节中，我们将探讨RAG系统相关的典型故障点和最佳实践。
- en: Troubleshooting RAG systems
  id: totrans-866
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 故障排除RAG系统
- en: 'Barnett and colleagues in their paper *Seven Failure Points When Engineering
    a Retrieval Augmented Generation System* (2024), and Li and colleagues in their
    paper *Enhancing Retrieval-Augmented Generation: A Study of Best Practices* (2025)
    emphasize the importance of both robust design and continuous system calibration:'
  id: totrans-867
  prefs: []
  type: TYPE_NORMAL
  zh: 在他们的论文《设计检索增强生成系统时的七个故障点》（2024）中，Barnett及其同事，以及在他们论文《增强检索增强生成：最佳实践研究》（2025）中的Li及其同事，强调了稳健设计和持续系统校准的重要性：
- en: '**Foundational setup**: Ensure comprehensive and high-quality document collections,
    clear prompt formulations, and effective retrieval techniques that enhance precision
    and relevance.'
  id: totrans-868
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设置**：确保全面且高质量的文档集合、清晰的提示表述和有效的检索技术，这些技术可以增强精确性和相关性。'
- en: '**Continuous calibration**: Regular monitoring, user feedback, and updates
    to the knowledge base help identify emerging issues during operation.'
  id: totrans-869
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续校准**：定期监控、用户反馈和知识库的更新有助于在运行过程中识别出现的新问题。'
- en: By implementing these practices early in development, many common RAG failures
    can be prevented. However, even well-designed systems encounter issues. The following
    sections explore the seven most common failure points identified by Barnett and
    colleagues (2024) and provide targeted solutions informed by empirical research.
  id: totrans-870
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发早期实施这些实践，可以预防许多常见的RAG故障。然而，即使是设计良好的系统也可能遇到问题。以下几节将探讨Barnett及其同事（2024）确定的七个最常见故障点，并提供基于实证研究的针对性解决方案。
- en: 'A few common failure points and their remedies are as follows:'
  id: totrans-871
  prefs: []
  type: TYPE_NORMAL
  zh: 一些常见的故障点和它们的补救措施如下：
- en: '**Missing content**: Failure occurs when the system lacks relevant documents.
    Prevent this by validating content during ingestion and adding domain-specific
    resources. Use explicit signals to indicate when information is unavailable.'
  id: totrans-872
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容缺失**：当系统缺少相关文档时，会发生故障。通过在内容摄入时验证内容并添加特定领域的资源来预防这种情况。使用明确的信号来指示信息不可用。'
- en: '**Missed top-ranked documents**: Even with relevant documents available, poor
    ranking can lead to their exclusion. Improve this with advanced embedding models,
    hybrid semantic-lexical searches, and sentence-level retrieval.'
  id: totrans-873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**遗漏高排名文档**：即使有相关文档可用，较差的排名可能导致它们被排除。通过使用高级嵌入模型、混合语义-词汇搜索和句子级检索来改进这一点。'
- en: '**Context window limitations**: When key information is spread across documents
    that exceed the model’s context limit, it may be truncated. Mitigate this by optimizing
    document chunking and extracting the most relevant sentences.'
  id: totrans-874
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文窗口限制**：当关键信息分布在超出模型上下文限制的文档中时，它可能会被截断。通过优化文档分块和提取最相关的句子来减轻这一问题。'
- en: '**Information extraction failure**: Sometimes, the LLM fails to synthesize
    the available context properly. This can be resolved by refining prompt design—using
    explicit instructions and contrastive examples enhances extraction accuracy.'
  id: totrans-875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息提取故障**：有时，LLM无法正确综合可用上下文。这可以通过改进提示设计来解决——使用明确的指令和对比示例可以提高提取准确性。'
- en: '**Format compliance issues**: Answers may be correct but delivered in the wrong
    format (e.g., incorrect table or JSON structure). Enforce structured output with
    parsers, precise format examples, and post-processing validation.'
  id: totrans-876
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**格式合规性问题**：答案可能是正确的，但以错误的格式提供（例如，不正确的表格或JSON结构）。通过解析器强制执行结构化输出，精确的格式示例和后处理验证来确保结构化输出。'
- en: '**Specificity mismatch**: The output may be too general or too detailed. Address
    this by using query expansion techniques and tailoring prompts based on the user’s
    expertise level.'
  id: totrans-877
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特定性不匹配**：输出可能过于笼统或过于详细。通过使用查询扩展技术和根据用户的专家水平定制提示来解决这一问题。'
- en: '**Incomplete information**: Answers might capture only a portion of the necessary
    details. Increase retrieval diversity (e.g., using maximum marginal relevance)
    and refine query transformation methods to cover all aspects of the query.'
  id: totrans-878
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息不完整**：答案可能只捕获必要细节的一部分。通过增加检索多样性（例如，使用最大边际相关性）和细化查询转换方法来覆盖查询的所有方面。'
- en: Integrating focused retrieval methods, such as retrieving documents first and
    then extracting key sentences, has been shown to improve performance—even bridging
    some gaps caused by smaller model sizes. Continuous testing and prompt engineering
    remain essential to maintaining system quality as operational conditions evolve.
  id: totrans-879
  prefs: []
  type: TYPE_NORMAL
  zh: 集成聚焦检索方法，例如先检索文档然后提取关键句子，已被证明可以提高性能——甚至可以弥补由较小模型尺寸引起的某些差距。随着操作条件的演变，持续测试和提示工程对于维持系统质量仍然至关重要。
- en: Summary
  id: totrans-880
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we explored the key aspects of RAG, including vector storage,
    document processing, retrieval strategies, and implementation. Following this,
    we built a comprehensive RAG chatbot that leverages LangChain for LLM interactions
    and LangGraph for state management and workflow orchestration. This is a prime
    example of how you can design modular, maintainable, and user-friendly LLM applications
    that not only generate creative outputs but also incorporate dynamic feedback
    loops.
  id: totrans-881
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了RAG的关键方面，包括向量存储、文档处理、检索策略和实现。在此基础上，我们构建了一个综合的RAG聊天机器人，该机器人利用LangChain进行LLM交互，并利用LangGraph进行状态管理和工作流程编排。这是一个如何设计模块化、可维护且用户友好的LLM应用的典范，不仅能够生成创意输出，还融入了动态反馈循环。
- en: This foundation opens the door to more advanced RAG systems, whether you’re
    retrieving documents, enhancing context, or tailoring outputs to meet specific
    user needs. As you continue to develop production-ready LLM applications, consider
    how these patterns can be adapted and extended to suit your requirements. In [*Chapter
    8*](E_Chapter_8.xhtml#_idTextAnchor390), we’ll be discussing how to benchmark
    and quantify the performance of RAG systems to ensure performance is up to requirements.
  id: totrans-882
  prefs: []
  type: TYPE_NORMAL
  zh: 这个基础为更高级的RAG系统打开了大门，无论你是检索文档、增强上下文还是定制输出以满足特定用户需求。随着你继续开发生产就绪的LLM应用，考虑如何将这些模式适应和扩展以满足你的需求。在[*第8章*](E_Chapter_8.xhtml#_idTextAnchor390)中，我们将讨论如何基准测试和量化RAG系统的性能，以确保性能符合要求。
- en: In the next chapter, we will build on this foundation by introducing intelligent
    agents that can utilize tools for enhanced interactions. We will cover various
    tool integration strategies, structured tool output generation, and agent architectures
    such as ReACT. This will allow us to develop more capable AI systems that can
    dynamically interact with external resources.
  id: totrans-883
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将通过介绍能够利用工具进行增强交互的智能代理来在此基础上构建。我们将涵盖各种工具集成策略、结构化工具输出生成和代理架构，如ReACT。这将使我们能够开发出能够动态与外部资源交互的更强大的AI系统。
- en: Questions
  id: totrans-884
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What are the key benefits of using vector embeddings in RAG?
  id: totrans-885
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用向量嵌入在RAG中的关键好处是什么？
- en: How does MMR improve document retrieval?
  id: totrans-886
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: MMR是如何改进文档检索的？
- en: Why is chunking necessary for effective document retrieval?
  id: totrans-887
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么分块对于有效的文档检索是必要的？
- en: What strategies can be used to mitigate hallucinations in RAG implementations?
  id: totrans-888
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用哪些策略来减轻RAG实现中的幻觉问题？
- en: How do hybrid search techniques enhance the retrieval process?
  id: totrans-889
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 混合搜索技术是如何增强检索过程的？
- en: What are the key components of a chatbot utilizing RAG principles?
  id: totrans-890
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于RAG原则的聊天机器人的关键组件有哪些？
- en: Why is performance evaluation critical in RAG-based systems?
  id: totrans-891
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么在基于RAG的系统中性能评估至关重要？
- en: What are the different retrieval methods in RAG systems?
  id: totrans-892
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RAG系统中有哪些不同的检索方法？
- en: How does contextual compression refine retrieved information before LLM processing?
  id: totrans-893
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在LLM处理之前，上下文压缩是如何细化检索信息的？
- en: Subscribe to our weekly newsletter
  id: totrans-894
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 订阅我们的每周通讯
- en: Subscribe to AI_Distilled, the go-to newsletter for AI professionals, researchers,
    and innovators, at [https://packt.link/Q5UyU](E_Chapter_4.xhtml).
  id: totrans-895
  prefs: []
  type: TYPE_NORMAL
  zh: 订阅AI_Distilled，这是AI专业人士、研究人员和创新者的首选通讯简报，请访问[https://packt.link/Q5UyU](E_Chapter_4.xhtml)。
- en: '![](img/Newsletter_QRcode1.jpg)'
  id: totrans-896
  prefs: []
  type: TYPE_IMG
  zh: '![Newsletter_QRcode1.jpg](img/Newsletter_QRcode1.jpg)'
