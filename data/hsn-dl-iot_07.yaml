- en: Indoor Localization in IoT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 物联网中的室内定位
- en: Many IoT applications, such as indoor navigation and location-aware marketing
    by retailers, smart homes, smart campuses, and hospitals, rely on indoor localization.
    The input data generated from such applications generally comes from numerous
    sources such as infrared, ultrasound, Wi-Fi, RFID, ultrawideband, Bluetooth, and
    so on.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 许多物联网应用，如室内导航、零售商的定位营销、智能家居、智能校园和医院，都依赖于室内定位。这些应用生成的输入数据通常来自多个来源，如红外线、超声波、Wi-Fi、RFID、超宽带、蓝牙等。
- en: 'The communication fingerprint of those devices and technologies, such as Wi-Fi
    fingerprinting data, can be analyzed using DL models to predict the location of
    the device or user in indoor environments. In this chapter, we will discuss how
    DL techniques can be used for indoor localization in IoT applications in general
    with a hands-on example. Furthermore, we will discuss some deployment settings
    for indoor localization services in IoT environments. The following topics will
    be briefly covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这些设备和技术的通信指纹，如Wi-Fi指纹数据，可以使用深度学习模型进行分析，以预测设备或用户在室内环境中的位置。在本章中，我们将讨论如何将深度学习技术应用于物联网应用中的室内定位，并提供一个实践示例。此外，我们还将讨论一些物联网环境中室内定位服务的部署设置。本章将简要涵盖以下主题：
- en: Introducing indoor localization in IoT applications
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在物联网应用中引入室内定位
- en: '**Deep learning** (**DL**) for indoor localization in IoT applications'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度学习**（**DL**）在物联网应用中的室内定位'
- en: Example – indoor localization in Wi-Fi fingerprinting
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 示例 – Wi-Fi指纹定位中的室内定位
- en: Different deployment options for DL-based indoor localization
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于深度学习的室内定位的不同部署选项
- en: An overview of indoor localization
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 室内定位概述
- en: With the rapid development of mobile internet, **Location-Based** **S****ervices**
    (**LBS**) in large public indoor places is becoming increasingly popular. In such
    an indoor location, the **Received Signal Strength Indicator** (**RSSI**) is often
    used as an estimated measure of the power level that an IoT device is receiving
    from **Wireless Access Points** (**WAPs**). However, when the distance from the
    source is increased, the signal gets weaker and the wireless data rates get slower,
    leading to a lower overall data throughput.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 随着移动互联网的快速发展，**基于位置的** **服务**（**LBS**）在大型公共室内场所变得越来越流行。在这种室内位置中，**接收信号强度指示器**（**RSSI**）通常作为估算物联网设备从**无线接入点**（**WAPs**）接收到的功率水平的指标。然而，当与信号源的距离增加时，信号变弱，无线数据速率变慢，导致总体数据吞吐量降低。
- en: Techniques for indoor localization
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 室内定位技术
- en: Several indoor localization technologies have been proposed to date based on
    measuring techniques such as ultrasound, infrared, image, light, magnetic field,
    and wireless signals. For example, **Bluetooth low energy** (**BLE**)-based indoor
    localization has been attracting increasing interest because it is low-cost, low-power
    consumption, and has ubiquitous availability on almost every mobile device. On
    the other hand, the Wi-Fi localization system is based on the **Channel State
    Information** (**CSI**) of Wi-Fi signals.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 目前已经提出了几种基于不同测量技术的室内定位技术，如超声波、红外线、图像、光、磁场和无线信号。例如，基于**蓝牙低能耗**（**BLE**）的室内定位因其低成本、低功耗以及几乎所有移动设备上普遍可用，受到了越来越多的关注。另一方面，Wi-Fi定位系统则基于Wi-Fi信号的**信道状态信息**（**CSI**）。
- en: Lately, DL approaches have been proposed in which DL models are used to learn
    the fingerprint patterns of high-dimensional CSI signals. Although, each Wi-Fi
    scan contains the signal strength measurements for APs available in its vicinity,
    only a subset of a total number of networks in the environment are observed.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，已经提出了深度学习（DL）方法，其中使用深度学习模型来学习高维CSI信号的指纹模式。虽然每次Wi-Fi扫描包含了其周围接入点（AP）的信号强度测量，但只观察到环境中总数网络的一个子集。
- en: Also, since those devices are low-end with very small processing power, the
    unpredictable weakening or strengthening combination used in those approaches
    affect the multi-path signals, which will break the relationship between the RSSI
    and the transmission distance, and consequently prove to be less effective. On
    the other hand, the fingerprinting approach doesn't rely on the recovery of distances
    but instead uses the measured RSSIs as spatial patterns only. It is thus less
    vulnerable to the multi-path effect.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，由于这些设备是低端的，处理能力非常小，因此在这些方法中使用的不可预测的信号增强或减弱组合会影响多路径信号，从而打破RSSI与传输距离之间的关系，导致效果较差。另一方面，指纹识别方法并不依赖于距离的恢复，而是仅使用测量到的RSSI作为空间模式。因此，它对多路径效应的敏感度较低。
- en: Fingerprinting
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指纹识别
- en: 'The fingerprinting approaches used commonly have two phases: an offline phase
    and an online phase.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的指纹识别方法通常分为两个阶段：离线阶段和在线阶段。
- en: 'One phase uses a fingerprint database to construct position-dependent parameters,
    which are extracted from measured RSSIs'' reference locations, known as **offline
    phases**. In a localization phase, which is also known as an **online phase**,
    the mapping of RSSI measurements is done to a reference location using the most
    relevant RSSI fingerprint from the database, which can be explained as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一个阶段使用指纹数据库构建位置依赖的参数，这些参数从测量到的RSSI参考位置中提取，称为**离线阶段**。在定位阶段，也称为**在线阶段**，RSSI测量值被映射到参考位置，使用数据库中最相关的RSSI指纹来完成，这可以通过以下方式解释：
- en: '![](img/b86e0d50-48d9-41ad-bcad-3f123875d7ae.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b86e0d50-48d9-41ad-bcad-3f123875d7ae.png)'
- en: 'In the preceding equation, ![](img/bab27896-3a38-49f3-8ec0-1677e6fc1bb6.png)
    is the total number of reference locations in the database, ![](img/242d15f7-deb3-407d-b33c-ca60da767fea.png)
    denotes the fingerprint pattern of the ![](img/b68d16c9-827a-41a5-a8cf-380580a3429b.png)
    reference location, and ![](img/449d1379-8d2b-43d3-aab5-ecca314065e9.png) is the
    spatial coordinates of that reference location. The fingerprint pattern, ![](img/ab5fac86-a4b7-43f4-92b9-8b545d15ff87.png),
    can be raw RSSI values from multiple beacon stations, or any other feature vectors
    extracted from the RSSIs, which can be expressed as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述方程中，![](img/bab27896-3a38-49f3-8ec0-1677e6fc1bb6.png)表示数据库中参考位置的总数，![](img/242d15f7-deb3-407d-b33c-ca60da767fea.png)表示第![](img/b68d16c9-827a-41a5-a8cf-380580a3429b.png)参考位置的指纹模式，![](img/449d1379-8d2b-43d3-aab5-ecca314065e9.png)是该参考位置的空间坐标。指纹模式，![](img/ab5fac86-a4b7-43f4-92b9-8b545d15ff87.png)，可以是来自多个信标站的原始RSSI值，或者是从RSSI中提取的其他特征向量，可以通过以下方式表示：
- en: '![](img/d6372765-89d2-45b0-8de8-c747c53e1a14.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d6372765-89d2-45b0-8de8-c747c53e1a14.png)'
- en: However, the raw RSSI values are used as spatial patterns in existing fingerprinting
    systems. In the preceding equation, *m* is the total number of BLE beacon stations
    or Wi-Fi APs, and ![](img/44ce7c44-7826-44b9-85f5-cf7b91f88441.png) represents
    the measured RSSI value of the ![](img/01e38a2a-24f4-455d-9388-1dc08b082661.png)
    station.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，原始RSSI值在现有的指纹识别系统中被用作空间模式。在前述方程中，*m*是BLE信标站或Wi-Fi接入点（AP）的总数，![](img/44ce7c44-7826-44b9-85f5-cf7b91f88441.png)表示第![](img/01e38a2a-24f4-455d-9388-1dc08b082661.png)站的测量RSSI值。
- en: Now, we roughly know what indoor localization is. In the next section, we'll
    see how machine learning and DL algorithms can be used to develop such an indoor
    localization system.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们大致了解了什么是室内定位。在下一节中，我们将看到如何使用机器学习和深度学习（DL）算法来开发这样的室内定位系统。
- en: DL-based indoor localization for IoT
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于深度学习（DL）的物联网室内定位
- en: Now, if we want to develop a DL application and deploy low-end devices, such
    IoT devices won't be able to process them. In particular, handling very high-dimensional
    data would be a bottleneck. So, an outdoor localization problem can be solved
    with reasonable accuracy using a machine learning algorithm such as **k-nearest
    neighbors** (**k-NNs**) because the inclusion of GPS sensors in mobile devices
    means we now have more data at hand.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们想要开发一个深度学习应用并部署低端设备，这些物联网设备将无法处理它们。特别是，处理非常高维度的数据会成为瓶颈。因此，使用像**k近邻（k-NNs）**这样的机器学习算法，户外定位问题可以在合理的精度下得到解决，因为移动设备中包含GPS传感器，这意味着我们现在手头有更多的数据。
- en: 'However, indoor localization is still an open research problem, mainly due
    to the loss of GPS signals in indoor environments, despite advanced indoor positioning
    technologies. Fortunately, by using DL techniques, we can solve this problem with
    reasonable accuracy, especially since using **Autoencoders** (**AEs**) and their
    representation capabilities can be a pretty good workaround and a viable option.
    In such a setting, we have two options:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，室内定位仍然是一个未解决的研究问题，主要是由于室内环境中GPS信号的丧失，尽管有先进的室内定位技术。幸运的是，通过使用深度学习（DL）技术，我们可以以合理的精度解决这个问题，尤其是由于使用**自编码器**（**AEs**）及其表示能力，可以成为一个很好的替代方案和可行的选择。在这种情况下，我们有两种选择：
- en: Add a fully connected layer and a softmax layer in front of the AE network,
    which will act as an end-to-end classifier.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AE网络前添加一个全连接层和一个softmax层，这将作为一个端到端的分类器。
- en: 'Use any other classification algorithms, such as logistic regression, k-NN,
    Random Forest, or a support vector machine for the location estimation (that is,
    classification), as shown in the following diagram:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用其他分类算法，如逻辑回归、k-NN、随机森林或支持向量机进行位置估计（即分类），如下图所示：
- en: '![](img/0c323e9d-9947-4845-b736-6e662bc90b1f.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0c323e9d-9947-4845-b736-6e662bc90b1f.png)'
- en: The idea is to use AEs for the representation learning so that the network can
    learn the features well. Then, the output of the encoder part can be used to initialize
    the weight of the classifier part. In the following section, we will discuss k-NN
    and AEs and see how they can be used to solve the indoor localization problem.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这个思路是使用AEs进行表示学习，以便网络能够很好地学习特征。然后，编码器部分的输出可以用来初始化分类器部分的权重。在接下来的部分，我们将讨论k-NN和AEs，并看看它们如何用于解决室内定位问题。
- en: K-nearest neighbor (k-NN) classifier
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K近邻（k-NN）分类器
- en: The k-NN algorithm is a non-parametric method that can be trained using the
    fingerprinting data coming from IoT devices. This tries to classify the collected
    RSSI values from the gateways to one of the reference points and not to the coordinates.
    The input consists of the k-closest RSSI values and the output would be a class
    membership. An input sample is then classified by a plurality vote of its neighbors,
    with the object being assigned to the class most common among its k-nearest neighbors.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: k-NN算法是一种非参数方法，可以使用来自物联网设备的指纹数据进行训练。该方法试图将从网关收集到的RSSI值分类到一个参考点而非坐标。输入包括k个最接近的RSSI值，输出将是一个类的成员资格。然后，输入样本通过其邻居的多数投票进行分类，物体被分配到其k个最近邻中最常见的类。
- en: 'Technically, if the fingerprinting database consists of (*X, y*)—with *X* being
    the RSSI values and *y* being the set of already known locations—then k-NN first
    computes the distance ![](img/b6016adb-5765-47b1-8f24-9983adfe5dfb.png), where
    *x* is the unknown sample. Then, it computes a set, ![](img/90cfbfa6-1377-48ef-af6e-d3b0bad19a33.png),
    containing indices for the *k* smallest distances from ![](img/d6f38274-2e83-4fe5-8ee9-d2f0c4d3b6e7.png).
    Then, the majority label for ![](img/18562ef7-7264-488e-b212-421a0c37a3e7.png)
    is returned, where ![](img/d3ee66fb-7bd8-4e35-b3f9-2e7feaf938a4.png). In other
    words, using k-NN, the classification is performed by computing the similarity
    between the observed data and records in the training RSSI samples in the database.
    Ultimately, the grid cell with the highest occurrence in the first *k* most similar
    records is the estimated location, as shown in the following diagram:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术上讲，如果指纹数据库由(*X, y*)组成——其中*X*是RSSI值，*y*是已知位置的集合——那么k-NN首先计算距离 ![](img/b6016adb-5765-47b1-8f24-9983adfe5dfb.png)，其中*x*是未知样本。然后，它计算一个集合，![](img/90cfbfa6-1377-48ef-af6e-d3b0bad19a33.png)，包含来自
    ![](img/d6f38274-2e83-4fe5-8ee9-d2f0c4d3b6e7.png) 的k个最小距离的索引。接着，返回 ![](img/18562ef7-7264-488e-b212-421a0c37a3e7.png)
    的多数标签，其中 ![](img/d3ee66fb-7bd8-4e35-b3f9-2e7feaf938a4.png)。换句话说，通过使用k-NN，分类是通过计算观察数据与数据库中训练RSSI样本记录的相似度来进行的。最终，在前k个最相似记录中出现次数最多的网格单元就是估计的位置，如下图所示：
- en: '![](img/e7c21824-f316-41f0-99ef-9b1ceca414e5.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e7c21824-f316-41f0-99ef-9b1ceca414e5.png)'
- en: Localization of IoT enabled devices using k-NN algorithm
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用k-NN算法进行物联网设备的定位
- en: In the preceding diagram, for k=4, the Wi-Fi packet trace is classified as being
    in the grid c (green triangles) record, while it is classified as being in grid
    a (red rectangle) when *k=6*. So, k-NN can be thought of as a lazy learning approach,
    where the function is only approximated locally and all computation is deferred
    until classification occurs. The good thing about the k-NN algorithm is that it
    is robust against noisy data. In particular, the inverse square of the weighted
    distance is used as the distance measure. Nevertheless, it performs well if it's
    already trained on a large amount of training data.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图示中，当 k=4 时，Wi-Fi 数据包跟踪被归类为网格 c（绿色三角形）记录，而当 *k=6* 时，则被归类为网格 a（红色矩形）。因此，k-NN
    可以被视为一种懒惰学习方法，在这种方法中，函数仅在局部进行近似，所有计算都推迟到分类发生时。k-NN 算法的优点是它对噪声数据具有鲁棒性。特别地，使用加权距离的反平方作为距离度量。尽管如此，如果它已经在大量训练数据上进行了训练，它仍然表现良好。
- en: There are possible drawbacks as well. For example, we need to determine the
    *K* parameter value, which is the number of nearest neighbors. It performs quite
    differently based on the distance measure used. The computation cost using the
    k-NN algorithm is quite high since it is required to compute the distance of each
    sample in the training data. This becomes even worse in the case of very high-dimensional
    data. In the next section, we will use k-NN as an end-to-end classifier rather
    than using a neural network setting to provide a comparative analysis between
    an AE-based classifier and k-NN classifiers.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 也存在一些潜在的缺点。例如，我们需要确定 *K* 参数值，即最近邻居的数量。它在使用不同的距离度量时表现差异较大。使用 k-NN 算法的计算成本较高，因为需要计算训练数据中每个样本的距离。在数据维度非常高的情况下，这一问题尤为严重。在下一节中，我们将使用
    k-NN 作为端到端分类器，而不是使用神经网络设置，提供基于 AE 的分类器与 k-NN 分类器之间的比较分析。
- en: AE classifier
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AE 分类器
- en: 'As described in [Chapter 2](7626c72a-c3b8-4707-96a5-88d524d9f3f7.xhtml), *Deep
    Learning Architectures for IoT*, AEs are special types of neural networks that
    learn automatically from the input data. AEs consists of two components: an encoder
    and a decoder. An encoder compresses the input into a latent-space representation.
    Then, the decoder part, tries to reconstruct the original input data from that
    representation:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [第 2 章](7626c72a-c3b8-4707-96a5-88d524d9f3f7.xhtml)《物联网深度学习架构》所述，AEs 是一种特殊类型的神经网络，它们能够从输入数据中自动学习。AEs
    由两个部分组成：编码器和解码器。编码器将输入压缩为潜在空间表示。然后，解码器部分尝试从该表示中重建原始输入数据：
- en: '**Encoder**: Encodes or compresses the input into a latent-space representation
    using a function known as ![](img/b5bf675d-1f97-4cdd-a9c5-c5de096126fd.png)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编码器**：使用一种称为 ![](img/b5bf675d-1f97-4cdd-a9c5-c5de096126fd.png) 的函数，将输入编码或压缩为潜在空间表示。'
- en: '**Decoder**: Decodes or reconstructs the input from the latent space representation
    using a function known as ![](img/643771fa-fed6-457b-b4c6-beb20bfbcf5d.png)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解码器**：使用一种称为 ![](img/643771fa-fed6-457b-b4c6-beb20bfbcf5d.png) 的函数，从潜在空间表示中解码或重建输入。'
- en: 'So, an AE can be described by a function of ![](img/5455f554-5bcc-42bd-8b3b-ec1070db6e05.png),
    where we want *0* to be as close as the original input of *x*. AEs are very useful
    for data denoising and dimensionality reduction for data visualization. AEs can
    learn data projections, called **representations**, more effectively than PCA.
    The following diagram shows the architecture of a denoising AE:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，AE 可以通过 ![](img/5455f554-5bcc-42bd-8b3b-ec1070db6e05.png) 的函数来描述，其中我们希望 *0*
    尽可能接近原始输入 *x*。AEs 在数据去噪和降维数据可视化方面非常有用。AEs 比 PCA 更有效地学习数据投影，称为 **表示**。下图展示了一个去噪
    AE 的架构：
- en: '![](img/f40044e9-4968-443e-8ca5-1771240ccac6.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f40044e9-4968-443e-8ca5-1771240ccac6.png)'
- en: 'So, once we have a fingerprinting database to hand, AEs can be trained with
    the raw RSSI measurements and the trained network itself is used as the fingerprint
    pattern for a specific reference location. Since a deep network can be represented
    by the weight of each layer, the fingerprint pattern can be expressed as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一旦我们手头有了指纹数据库，AEs 就可以通过原始的 RSSI 测量值进行训练，训练好的网络本身则用作特定参考位置的指纹模式。由于深度网络可以通过每层的权重表示，因此指纹模式可以表达为以下形式：
- en: '![](img/468c9efa-9469-4607-a4a8-2b8f4f4defe4.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/468c9efa-9469-4607-a4a8-2b8f4f4defe4.png)'
- en: 'In the preceding equation, *l* is the number of encoding hidden layers of an
    AE, and ![](img/5a91f9bf-9c2b-44bb-857a-a1e0f676c199.png) and ![](img/35489ecc-25a5-4e0a-b4ae-4378f7665645.png)
    represent the weights of the ![](img/ef1ef057-8bed-40e9-87b9-8de470f3daae.png)
    encoding hidden layer and its decoding mirror layer, as shown in the following
    diagram:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述公式中，*l* 是AE（自编码器）的隐藏层编码层的数量，![](img/5a91f9bf-9c2b-44bb-857a-a1e0f676c199.png)
    和 ![](img/35489ecc-25a5-4e0a-b4ae-4378f7665645.png) 表示编码隐藏层及其解码镜像层的权重，如下图所示：
- en: '![](img/8b2950f2-58fb-4dff-ad2f-7fa884d78a3a.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b2950f2-58fb-4dff-ad2f-7fa884d78a3a.png)'
- en: Then, we can use the output of the central hidden layers of the AE as the input
    to the fully connected softmax layer to predict the location, as shown in the
    preceding diagram. Now that we know how indoor localization works in a neural
    network or machine learning setting, we can now start a hands-on example using
    Wi-Fi fingerprinting.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将AE中央隐藏层的输出作为全连接Softmax层的输入，以预测位置，如上图所示。现在我们已经知道神经网络或机器学习环境下的室内定位工作原理，接下来可以开始使用Wi-Fi指纹的实际示例。
- en: Example – Indoor localization with Wi-Fi fingerprinting
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例 – 使用Wi-Fi指纹进行室内定位
- en: In this example, we will use a **multi-building, multi-floor indoor localization**
    database and stacked AEs to localize Wi-Fi fingerprinting. With some minimal effort,
    this application can be deployed to mobile robots to use Wi-Fi localization subsystems.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用**多建筑、多楼层的室内定位**数据库和堆叠的AE来进行Wi-Fi指纹定位。只需进行一些最小的努力，这个应用可以部署到移动机器人上，使用Wi-Fi定位子系统。
- en: Describing the dataset
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 描述数据集
- en: 'The `UJIIndoorLoc` dataset is a multi-building, multi-floor indoor localization
    database designed to test an indoor positioning system relying on Wi-Fi fingerprinting.
    Automatic user localization consists of estimating the position of the user, such
    as the latitude, longitude, and altitude, collected from a mobile phone. The `UJIIndoorLoc`
    database covers three buildings of Universitat Jaume I with 4 or more floors and
    almost 110,000 square meters, measured in 2013 by means of more than 20 different
    users and 25 Android devices. The database consists of two CSV files:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`UJIIndoorLoc` 数据集是一个多建筑、多楼层的室内定位数据库，旨在测试基于Wi-Fi指纹的室内定位系统。自动用户定位包括估算用户的位置信息，如经度、纬度和海拔，这些信息通过手机收集。`UJIIndoorLoc`数据库覆盖了Jaume
    I大学的三栋建筑，楼层数为4层或以上，总面积接近110,000平方米，数据收集于2013年，涉及20多位用户和25台Android设备。该数据库包含两个CSV文件：'
- en: '`trainingData.csv`: 19,937 training/reference records'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trainingData.csv`：19,937条训练/参考记录'
- en: '`validationData.csv`: 1,111 validation/test records'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`validationData.csv`：1,111条验证/测试记录'
- en: 'The 529 attributes contain Wi-Fi fingerprints and the coordinates where they
    were taken. Each Wi-Fi fingerprint can be characterized by the detected WAPs and
    the corresponding RSSI. The intensity values are represented as negative integer
    values ranging from 1,04 dBm (extremely poor signal) to 0 dBm. The positive 100
    value is used to denote when a WAP was not detected. During the database creation,
    520 different WAPs were detected. Thus, the Wi-Fi fingerprint is composed of 520
    intensity values. The coordinates'' latitude, longitude, floor, and **BuildingID** information
    are the attributes to be predicted. The following list gives a quick summary of
    the dataset:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 529个属性包含Wi-Fi指纹及其采集的坐标。每个Wi-Fi指纹可以通过检测到的WAP和相应的RSSI来描述。强度值以负整数形式表示，范围从-104 dBm（非常差的信号）到0
    dBm。正值100表示WAP未被检测到。在数据库创建过程中，检测到了520个不同的WAP。因此，Wi-Fi指纹由520个强度值组成。坐标的纬度、经度、楼层和**BuildingID**信息是需要预测的属性。以下是数据集的快速总结：
- en: '**Attribute 001 to 520 (that is, WAP001 to WAP520)**: These are the intensity
    measurement values for the access points in which values are in—104 to 0 and +100\.
    The 100 value signifies that WAP001 was not detected.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性001到520（即WAP001到WAP520）**：这些是接入点的强度测量值，取值范围为-104到0和+100。100表示未检测到WAP001。'
- en: '**Attribute 521 (Longitude)**: Negative real values from 7,695.9,387,549,299,299,000
    to -7299.786516730871000'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性521（经度）**：负实数值，从7,695,938,754,929,900到-7299.786516730871000'
- en: '**Attribute 522 (Latitude)**: Positive real values from 4,864,745.7,450,159,714
    to 4,865,017.3,646,842,018.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性522（纬度）**：正实数值，从4,864,745.7,450,159,714到4,865,017.3,646,842,018。'
- en: '**Attribute 523 (Floor)**: Altitude in floors inside the building. Integer
    values from 0 to 4.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性523（楼层）**：建筑物内的楼层高度。整数值范围从0到4。'
- en: '**Attribute 524 (BuildingID)**: ID to identify the building provided as categorical
    integer values from 0 to 2.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性524（建筑ID）**：用于识别建筑的ID，作为从0到2的分类整数值提供。'
- en: '**Attribute 525 (SpaceID)**: Internal ID number to identify the space, such
    as the office, the corridor, or the classroom.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性525（空间ID）**：用于识别空间的内部ID号码，例如办公室、走廊或教室。'
- en: '**Attribute 526 (RelativePosition)**: Relative position with respect to the
    space (1—inside, 2—outside, in front of the door).'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性526（相对位置）**：相对于空间的相对位置（1—室内，2—室外，门前）。'
- en: '**Attribute 527 (UserID)**: User identifier.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性527（用户ID）**：用户标识符。'
- en: '**Attribute 528 (PhoneID)**: Android device identifier (see the following).'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性528（手机ID）**：安卓设备标识符（见下文）。'
- en: '**Attribute 529 (Timestamp)**: UNIX time when the capture was taken.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性529（时间戳）**：捕获时间的UNIX时间。'
- en: Network construction
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络构建
- en: 'The AE classifier we will be using will have an AE part consisting of an encoder
    and a decoder. The following AE architecture is used to determine the floor and
    building location where the Wi-Fi is located. The input to the AE are signal strengths
    detected in a scan. Then, one value for each visible network is considered an
    RSSI record. The output of a decoder is the reconstructed input from the reduced
    representation, as shown in the following diagram (source: *Low-effort place recognition
    with Wi-Fi fingerprints using deep learning*, Michał N. et al., arXiv:1611.02049v1):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用的AE分类器将包含一个由编码器和解码器组成的AE部分。以下的AE架构用于确定Wi-Fi所在的楼层和建筑位置。AE的输入是扫描中检测到的信号强度。然后，每个可见网络的一个值被视为RSSI记录。解码器的输出是来自压缩表示的重建输入，如下图所示（来源：*使用深度学习的低努力场所识别与Wi-Fi指纹*，Michał
    N.等人，arXiv:1611.02049v1）：
- en: '![](img/104e89b7-6a30-4173-bc33-ed0cbacab1e5.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/104e89b7-6a30-4173-bc33-ed0cbacab1e5.png)'
- en: The AE architecture for the feature space representation
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 用于特征空间表示的AE架构
- en: 'The classifier part consists of two hidden layers; depending on the complexity
    of the problem, the number of neurons needs to be selected. When the unsupervised
    learning of the weights of AE is finished, the decoder part of the network is
    disconnected. Then fully-connected layers are typically placed after the output
    of the encoder by turning the whole network into a classifier. In the following
    diagram, the pre-trained encoder part is connected to the fully connected softmax
    layer (source: *Low-effort Place Recognition with Wi-Fi Fingerprints Using Deep
    Learning*, Michał N. et al., arXiv:1611.02049v1):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器部分由两个隐藏层组成；根据问题的复杂性，需要选择神经元的数量。当AE的权重进行无监督学习完成后，网络的解码器部分将断开。然后，通常会在编码器输出后放置全连接层，通过将整个网络转化为分类器。在以下图中，预训练的编码器部分连接到全连接的softmax层（来源：*使用深度学习的低努力场所识别与Wi-Fi指纹*，Michał
    N.等人，arXiv:1611.02049v1）：
- en: '![](img/7efbdf3f-e1a6-4412-9f42-0003d051578a.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7efbdf3f-e1a6-4412-9f42-0003d051578a.png)'
- en: The architecture of an AE classifier for classifying a building and its floor
    based on Wi-Fi scan input
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 用于基于Wi-Fi扫描输入分类建筑及其楼层的AE分类器架构
- en: The final output layer is a softmax layer that outputs the probabilities of
    the current sample belonging to the analyzed classes. Now, without any further
    delay, let's start implementing the preceding networks.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的输出层是一个softmax层，它输出当前样本属于分析类别的概率。现在，让我们不再拖延，开始实现前述网络。
- en: Implementation
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现
- en: 'We will use Keras to wrap up this conceptualization. First, let''s import the
    necessary packages and libraries, as follows:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Keras来实现这一概念。首先，让我们导入必要的包和库，如下所示：
- en: '[PRE0]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Once we have imported all the necessary packages, we can proceed to prepare
    the training set and test set, which can be used to train and evaluate the model,
    respectively.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们导入了所有必要的包，就可以继续准备训练集和测试集，分别用于训练和评估模型。
- en: Exploratory analysis
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索性分析
- en: 'The exploratory analysis of data using the **Python pandas** library provides
    many powerful features–no doubt. However, using `df.describe()`, `df.dtypes`,
    or using `df.isnull().sum()` and plotting them separately is always time-consuming.
    Sometimes, you won''t even get the required information in a sophisticated way.
    In fact, you''ll have to write extra lines of code to convert them into a presentable
    format. However, to make your life easier, you can now start using the `pandas_profiling`
    library (see [https://github.com/pandas-profiling/pandas-profiling](https://github.com/pandas-profiling/pandas-profiling)).
    Just one line of code will give the information you need:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**Python pandas**库进行数据探索性分析提供了许多强大的功能——毫无疑问。然而，使用`df.describe()`、`df.dtypes`，或者使用`df.isnull().sum()`并分别绘制这些图表总是非常耗时。有时，你甚至无法以一种高级的方式获取所需的信息。实际上，你必须编写额外的代码行将它们转换成可展示的格式。然而，为了让你的工作更轻松，现在你可以开始使用`pandas_profiling`库（请参阅[https://github.com/pandas-profiling/pandas-profiling](https://github.com/pandas-profiling/pandas-profiling)）。只需一行代码，就能提供你所需要的信息：
- en: '[PRE1]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Surely, it would be worth using `pandas_profiling` to get a quick understanding
    of your data. Let''s try it out! First, we read the training data by explicitly
    passing `header=0` to be able to replace the existing names:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，使用`pandas_profiling`来快速了解你的数据是非常值得的。让我们试试看！首先，我们通过显式传递`header=0`来读取训练数据，以便能够替换现有的列名：
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'To retrieve the list of variables that are rejected due to high correlation,
    you can use the following command:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取由于高度相关性而被拒绝的变量列表，可以使用以下命令：
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This will produce a report showing information on the dataset:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一份报告，显示关于数据集的信息：
- en: '![](img/f81ce1d6-dc12-4b22-a14c-4b38ff6d3eff.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f81ce1d6-dc12-4b22-a14c-4b38ff6d3eff.png)'
- en: 'Let''s look at the first few lines of the report. As we can see, we don''t
    have any null values and all the variables are numeric, which is great. However,
    some features are less significant, being highly correlated with other variables
    (for example, 74 variables were rejected) and some of the variables are very skewed,
    giving a very wide distribution. Even our training dataset has 637 duplicate rows.
    Rejected variables would not help the model learn well. Consequently, those can
    be dropped from the training data (this is optional, though). The list of such
    rejected variables can be collected using the `get_rejected_variables` method,
    as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下报告的前几行。正如我们所看到的，数据中没有任何空值，所有变量都是数值型的，这非常好。然而，有些特征意义较小，因为它们与其他变量高度相关（例如，74个变量被拒绝），还有一些变量分布非常偏斜，给出了非常宽广的分布。甚至我们的训练数据集也有637行重复数据。被拒绝的变量不会对模型的学习产生帮助。因此，这些可以从训练数据中删除（不过这一步是可选的）。这些被拒绝的变量列表可以通过以下`get_rejected_variables`方法来获取：
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If you want to generate a HTML report file, save the profile to an object and
    use the `to_file` function as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想生成HTML报告文件，可以将分析结果保存到一个对象中，并使用`to_file`函数，如下所示：
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This will generate an `HTML` report containing the necessary information. Now
    that we know the data and variables, let's focus on the feature engineering steps
    by which we'll prepare the data required for training and testing.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个包含必要信息的`HTML`报告。现在我们了解了数据和变量，接下来让我们专注于特征工程步骤，在此过程中我们将准备训练和测试所需的数据。
- en: Preparing training and test sets
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备训练集和测试集
- en: 'First, we scale the data to center to the mean. Then, we perform component-wise
    scaling to unit variance. This will help our model to converge the training more
    quickly:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将数据进行标准化，中心化到均值。然后，我们对每个分量进行单位方差缩放。这将有助于我们的模型更快地收敛：
- en: '[PRE6]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, we construct the true labels. We convert all the building IDs and building
    floors to strings:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们构建真实标签。我们将所有的建筑物ID和楼层ID转换为字符串：
- en: '[PRE7]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, let''s try to create two variables: `train_x` and `train_y`. This will
    help to avoid confusion during the training evaluation:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们尝试创建两个变量：`train_x`和`train_y`。这将有助于在训练评估过程中避免混淆：
- en: '[PRE8]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, similar to the training set, we prepare the test set as well:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，与训练集类似，我们也准备好测试集：
- en: '[PRE9]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Once we have the training and the test sets ready, we can now proceed with creating
    an AE.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们准备好了训练集和测试集，就可以继续创建一个自编码器（AE）。
- en: Creating an AE
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建自编码器（AE）
- en: 'Let''s create separate encoder and decoder functions since you will be using
    encoder weights later on for classification purposes. First, we define some parameters,
    such as the number of epochs and the batch size. Also, we compute the shape of
    the input data and the number of classes that will be required to construct and
    train the AE:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建独立的编码器和解码器函数，因为你稍后会使用编码器权重进行分类。首先，我们定义一些参数，比如 epoch 数量和批量大小。此外，我们计算输入数据的形状和构建与训练
    AE 所需的类别数：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, we create the encoder part of the AE, which has three hidden layers:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建 AE 的编码器部分，它有三个隐藏层：
- en: '[PRE11]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, we create the decoder part of the AE, which has three hidden layers,
    followed by the `compile()` method:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建 AE 的解码器部分，它有三个隐藏层，接着是 `compile()` 方法：
- en: '[PRE12]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then, we stack them together to construct an AE:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将它们堆叠在一起以构建 AE：
- en: '[PRE13]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s see the structure and a summary of the AE:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 AE 的结构和总结：
- en: '![](img/d99b49b5-34e4-402d-8d44-9f1def2179d7.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d99b49b5-34e4-402d-8d44-9f1def2179d7.png)'
- en: 'We can then train the AE with the training data for 100 iterations, where 10%
    of the training data is to be used for validation:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用训练数据训练 AE 100 次，其中 10% 的训练数据将用于验证：
- en: '[PRE14]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Since we set the `verbose =1` in the preceding code block, during training,
    you''ll see the following logs:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在前面的代码块中设置了 `verbose =1`，因此在训练过程中，你将看到以下日志：
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then, we take the output of the encoder network for both the training set and
    the test set as the latent features:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将编码器网络的输出作为训练集和测试集的潜在特征：
- en: '[PRE16]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Creating an AE classifier
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建 AE 分类器
- en: 'Next, we will re-train the `auto_encoder` model by making the first three layers
    trainable as `True` instead of keeping them as `False`:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过将前三层的训练状态设置为 `True` 来重新训练 `auto_encoder` 模型，而不是将它们保持为 `False`：
- en: '[PRE17]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Alternatively, we can pop off the first three layers as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们也可以通过以下方式删除前三层：
- en: '[PRE18]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Then, we add fully connected layers in front, with the `BatchNormalization`
    layer is followed by the first dense layer. Then, we add another dense layer,
    followed by the `BatchNormalization` and `Dropout` layers. Then, we place another
    dense layer, followed by a `GaussionNoise` layer and a `Dropout` layer, before
    we finally have the softmax layer:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们在前面添加全连接层，`BatchNormalization` 层紧随其后，接着是第一个密集层。接着，我们添加另一个密集层，再后面是 `BatchNormalization`
    和 `Dropout` 层。然后，我们放置另一个密集层，接着是 `GaussionNoise` 层和一个 `Dropout` 层，最后是 softmax 层：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Finally, we get the full AE classifier:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们得到了完整的 AE 分类器：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The full code is given as follows:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码如下：
- en: '[PRE21]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then, we compile the model before starting the training:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们在开始训练之前编译模型：
- en: '[PRE22]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, we start fine-tuning the network in a supervised way:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们开始以监督方式微调网络：
- en: '[PRE23]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Since we set `verbose =1` in the preceding code block, during training, you''ll
    experience the following logs:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在前面的代码块中设置了`verbose =1`，因此在训练过程中，你会看到以下日志：
- en: '[PRE24]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now let''s take a look at the training loss versus validation loss, which will
    help us to understand how the training went. This will also help us to establish
    whether our neural network has issues such as overfitting and underfitting:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看训练损失与验证损失的对比，这将帮助我们理解训练过程。这也将帮助我们判断我们的神经网络是否存在过拟合和欠拟合等问题：
- en: '[PRE25]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The preceding code block will plot the training loss and validation losses:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码块将绘制训练损失和验证损失：
- en: '![](img/c2372d36-7447-4aca-9c0e-86565eeefeaf.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c2372d36-7447-4aca-9c0e-86565eeefeaf.png)'
- en: As seen in the preceding graph, the training losses across epochs are higher
    than the validation loss, which is a sign of overfitting. We don't have enough
    training samples to train the neural network well. Some samples were even repeated
    in the dataset, which literally turned out to be trivial and redundant in the
    network. This was probably the reason adding the **Dropout** and **Gaussian**
    noise layers didn't help much. Anyway, we can also save the trained model for
    future reuse, which we'll discuss in the next section.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的图所示，跨越多个 epoch 的训练损失大于验证损失，这是过拟合的表现。我们没有足够的训练样本来很好地训练神经网络。一些样本在数据集中甚至重复，这些样本在网络中实际上变得非常琐碎和冗余。这可能是添加
    **Dropout** 和 **Gaussian** 噪声层没有太大帮助的原因。无论如何，我们也可以保存训练好的模型，以便将来重用，我们将在下一部分讨论这个问题。
- en: Saving the trained model
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保存训练好的模型
- en: 'Now that we have the AE classifier fully trained, we can save it so that we
    can restore it from disk later on:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完全训练好了 AE 分类器，可以保存它，以便稍后从磁盘恢复：
- en: '[PRE26]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In the next section, we will evaluate the trained model on the test set, which
    we will discuss in the next subsection.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分中，我们将对测试集进行评估，我们将在下一个小节中讨论这个问题。
- en: Evaluating the model
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估模型
- en: 'Now that our model is fully trained, we can evaluate its performance on unseen
    data:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的模型已经完全训练好了，可以在未见过的数据上评估其性能：
- en: '[PRE27]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The preceding lines of code will show the accuracy score, something like this:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码行将显示准确度得分，类似如下：
- en: '[PRE28]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Then, let''s compute the performance metrics:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，让我们计算性能指标：
- en: '[PRE29]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The preceding code block will show the following output, giving an F1-score
    of 88%, approximately:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码块将显示以下输出，F1-score 大约为 88%：
- en: '[PRE30]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Additionally, we can print the classification report to know the class-specific
    localization as well:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以打印分类报告以了解类特定的定位情况：
- en: '[PRE31]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The preceding line of code will produce the following output:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码行将产生以下输出：
- en: '![](img/e2f80ecc-424d-4628-9cd6-b442280fcb78.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e2f80ecc-424d-4628-9cd6-b442280fcb78.png)'
- en: 'Additionally, we will plot the confusion matrix:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将绘制混淆矩阵：
- en: '[PRE32]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The preceding line of code will produce the following confusion matrix:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码行将生成以下混淆矩阵：
- en: '![](img/91024568-524d-40ff-9690-1f36e7a1242b.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![](img/91024568-524d-40ff-9690-1f36e7a1242b.png)'
- en: 'As seen in the preceding confusion matrix, our AE classifier was mostly confused
    for class 11 and predicted as many as 39 samples to be classified in grid 12\.
    However, we have still managed to get very good accuracy. Possible suggestions
    for improvements could be as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述混淆矩阵所示，我们的 AE 分类器大多数情况下被误判为类别 11，并且将多达 39 个样本预测为属于网格 12。但是，我们仍然取得了非常好的准确率。改进的可能建议如下：
- en: Training the network after removing the rejected variables
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在移除被拒绝的变量后训练网络
- en: Training the network on more epochs
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在更多的训练轮次上训练网络
- en: Performing hyperparameter tuning using grid search and cross-validation
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用网格搜索和交叉验证进行超参数调优
- en: Adding more layers to the network
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向网络中添加更多的层
- en: Once you find the optimized model trained on more data, giving stable, improved
    performance, it can be deployed in on IoT enabled device. We will discuss some
    possible deployment options in the next section.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦找到经过更多数据训练的优化模型，并且能够提供稳定、改进的性能，它就可以部署到 IoT 设备上。我们将在下一部分讨论一些可能的部署选项。
- en: Deployment techniques
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署技术
- en: As we argued earlier, each Wi-Fi scan contains the signal strength measurements
    for APs available in its vicinity, but only a subset of the total number of networks
    in the environment are observed. Many IoT devices, such as a mobile phone or a
    Raspberry Pi, are low-end with very little processing power. So, deploying such
    a DL model would be a challenging task.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所讨论的，每次 Wi-Fi 扫描都包含其周围可用 AP 的信号强度测量，但仅会观察到环境中所有网络的一个子集。许多 IoT 设备，如手机或树莓派，处理能力较低。因此，部署这样的深度学习模型将是一项具有挑战性的任务。
- en: 'Many solution providers and technology companies provide smart positioning
    services commercially. Using Wi-Fi fingerprinting from indoor and outdoor location
    data, the accurate tracking of devices is now possible. In most of these companies,
    the RSSI fingerprint positioning is used as the core technology. In such a setting,
    signals or messages that bear different sensitivity levels across RSSI values
    (which is of course subject to the proximity) can be picked up by gateways. Then,
    if there are ![](img/c189cb14-792d-4335-8822-38f5e338c167.png) gateways in a network,
    the RSSI values acquired from a particular indoor or outdoor location will form
    the RSSI fingerprint having *n* entries at that location, which is as follows:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 许多解决方案提供商和科技公司提供商业化的智能定位服务。利用室内外定位数据中的 Wi-Fi 指纹技术，现如今可以实现设备的精确追踪。在这些公司中，大多数使用
    RSSI 指纹定位作为核心技术。在这种情况下，具有不同敏感度的信号或消息（这当然取决于距离）可以被网关接收。如果网络中有 ![](img/c189cb14-792d-4335-8822-38f5e338c167.png)
    网关，那么从特定的室内或室外位置获取的 RSSI 值将形成该位置的 RSSI 指纹，其中包含 *n* 个条目，如下所示：
- en: '![](img/f080db6c-cb77-425d-bedb-97be4ebdc152.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f080db6c-cb77-425d-bedb-97be4ebdc152.png)'
- en: 'The preceding diagram corresponds to the following equation:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表对应于以下方程：
- en: '![](img/95c8924c-4289-48ba-887d-109ac1944279.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/95c8924c-4289-48ba-887d-109ac1944279.png)'
- en: However, in cases with a large number of gateways (> 4), the fingerprint could
    be distinctly unique within a certain range. One deployment technique could be
    using the trained model serving at the backend and serving it as an Android or
    iOS mobile application. The application then monitors the signals from the IoT
    devices already deployed in the indoor location, inserts them as RSSI values in
    the SQLite database and, based on the RSSI values, prepares the test set and sends
    a query to the pre-trained model to get the location.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在有大量网关（>4）的情况下，指纹可能在某个范围内明显独特。一种部署技术是通过训练好的模型在后台提供服务，并作为 Android 或 iOS 移动应用程序提供服务。然后，应用程序监控已部署在室内位置的物联网设备信号，将其作为
    RSSI 值插入到 SQLite 数据库中，并根据 RSSI 值准备测试集，向预先训练好的模型发送查询，以获取位置。
- en: 'The following diagram shows a schematic architecture outlining all the steps
    required for such a deployment:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了一个示意架构，概述了该部署所需的所有步骤：
- en: '![](img/187ba3bf-40ca-4c00-8ed9-aef4555073f5.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![](img/187ba3bf-40ca-4c00-8ed9-aef4555073f5.png)'
- en: In such a case, the trained model will serve as the transfer learning. Nevertheless,
    the trained model can be served as a web application using Flask or the DJango
    Python framework. Then, the RSSI values and signals from the IoT devices can be
    stored in a database to enrich the historical data. The location can subsequently
    be tracked using an Android or iOS application.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，训练过的模型将作为迁移学习的方式。然而，训练过的模型可以作为一个 web 应用程序，通过 Flask 或 DJango Python 框架来提供服务。然后，来自物联网设备的
    RSSI 值和信号可以存储在数据库中，以丰富历史数据。随后，可以通过 Android 或 iOS 应用程序来追踪位置。
- en: Summary
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have discussed how indoor localization works for IoT enabled
    devices. In particular, we have seen how DL techniques can be used for indoor
    localization in IoT applications employing that data in general with a hands-on
    example. Furthermore, we have looked at some deployment settings of indoor localization
    services in IoT environments.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了物联网设备的室内定位工作原理。特别是，我们看到了深度学习技术如何应用于物联网应用中的室内定位，并通过一个实际示例展示了如何使用这些数据。此外，我们还探讨了物联网环境中室内定位服务的一些部署设置。
- en: In [Chapter 6](958a0ed2-1d5f-4df1-8bfa-55d3c870d733.xhtml), *Physiological and
    Psychological State Detection in IoT*, we will discuss DL-based human physiological
    and psychological state detection techniques for IoT applications in general.
    Considering a real-world scenario, we will look at two IoT applications based
    on physiological and psychological state detection.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第六章](958a0ed2-1d5f-4df1-8bfa-55d3c870d733.xhtml)《物联网中的生理和心理状态检测》中，我们将讨论基于深度学习的物联网应用中人体生理和心理状态检测技术。结合现实场景，我们将讨论两个基于生理和心理状态检测的物联网应用。
