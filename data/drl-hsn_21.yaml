- en: '21'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '21'
- en: RL in Discrete Optimization
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 离散优化中的强化学习（RL）
- en: The perception of deep reinforcement learning (RL) is that it is a tool to be
    used mostly for playing games. This is not surprising given the fact that, historically,
    the first success in the field was achieved on the Atari game suite by DeepMind
    in 2015 ([https://deepmind.com/research/dqn/](https://deepmind.com/research/dqn/)).
    The Atari benchmark suite turned out to be very successful for RL problems and,
    even now, lots of research papers use it to demonstrate the efficiency of their
    methods. As the RL field progresses, the classic 53 Atari games continue to become
    less and less challenging (at the time of writing, almost all the games have been
    solved with superhuman accuracy) and researchers are turning to more complex games,
    like StarCraft and Dota 2.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 深度强化学习（RL）的普遍看法是它主要用于玩游戏。考虑到历史上该领域的首次成功是在2015年由DeepMind在雅达利游戏套件上取得的（[https://deepmind.com/research/dqn/](https://deepmind.com/research/dqn/))，这并不令人惊讶。雅达利基准测试套件对于RL问题非常成功，直到现在，许多研究论文仍然用它来展示他们方法的效率。随着RL领域的发展，经典的53款雅达利游戏逐渐变得越来越不具挑战性（在撰写本文时，几乎所有游戏都已被超人级精度解决），研究人员正在转向更复杂的游戏，如《星际争霸》和《Dota
    2》。
- en: This perception, which is especially prevalent in the media, is something that
    I’ve tried to counterbalance in this book by accompanying Atari games with examples
    from other domains, including stock trading and natural language processing (NLP)
    problems, web navigation automation, continuous control, board games, and robotics.
    In fact, RL’s very flexible Markov decision process (MDP) model potentially could
    be applied to a wide variety of domains; computer games are just one convenient
    and attention-grabbing example of complicated decision-making.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这种观点，尤其是在媒体中较为常见，是我在本书中试图加以平衡的。我通过将雅达利游戏与其他领域的实例结合起来，包括股票交易、自然语言处理（NLP）问题、网页导航自动化、连续控制、棋盘游戏和机器人技术，来对其进行补充。事实上，RL非常灵活的马尔可夫决策过程（MDP）模型潜在地可以应用于各种领域；计算机游戏只是复杂决策的一种便捷且引人注目的示例。
- en: 'In this chapter, we will explore a new field in RL application: discrete optimization
    (which is a branch of mathematics that studies optimization problems on discrete
    structures), which will be showcased using the famous Rubik’s cube puzzle. I’ve
    tried to provide a detailed description of the process followed in the paper titled
    Solving the Rubik’s cube without human knowledge, by UCI researchers McAleer et
    al. [[McA+18](#)]. In addition, we will cover my implementation of the method
    described in the paper (which is in the Chapter21 directory of the book’s GitHub
    repository) and discuss directions to improve the method. I’ve combined the description
    of the paper’s method with code pieces from my version to illustrate the concepts
    with concrete implementation.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探索RL应用中的一个新领域：离散优化（这是一门研究离散结构上的优化问题的数学分支），通过著名的魔方谜题来展示。我尝试提供对UCI研究员McAleer等人撰写的论文《无人工知识解决魔方》的详细描述[[McA+18](#)]。此外，我们还将介绍我对论文中所述方法的实现（该实现位于本书GitHub仓库的Chapter21目录中），并讨论改进该方法的方向。我将论文方法的描述与我版本中的代码片段结合起来，以通过具体实现来说明这些概念。
- en: 'More specifically, in this chapter, we will:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，在本章中，我们将：
- en: Briefly discuss the basics of discrete optimization
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简要讨论离散优化的基础知识
- en: Cover step by step the process followed by McAleer et al. [[McA+18](#)], who
    apply RL methods to the Rubik’s cube optimization problem
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逐步讲解McAleer等人[[McA+18](#)]应用RL方法解决魔方优化问题的过程
- en: Explore experiments that I’ve done in an attempt to reproduce the paper’s results
    and directions for future method improvement
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探讨我在尝试重现论文结果过程中所做的实验以及未来方法改进的方向
- en: Let’s start with an overview of the Rubik’s cube and discrete optimization in
    general.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从魔方和离散优化的一般概述开始。
- en: The Rubik’s cube and discrete optimization
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 魔方与离散优化
- en: I’m sure you are aware of what a Rubik’s cube is, so I’m not going to go over
    the general description ([https://en.wikipedia.org/wiki/Rubik\%27s_Cube](https://en.wikipedia.org/wiki/Rubik/))
    of this puzzle, but rather focus on the connections it has to mathematics and
    computer science.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信你知道魔方是什么，因此我不会过多介绍这个谜题的通用描述（[https://en.wikipedia.org/wiki/Rubik\%27s_Cube](https://en.wikipedia.org/wiki/Rubik/))，而是专注于它与数学和计算机科学的联系。
- en: If it’s not explicitly stated, by “cube” I mean the 3 × 3 × 3 classic Rubik’s
    cube. There are lots of variations based on the original 3 × 3 × 3 puzzle, but
    they are still far less popular than the classic invention.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有明确说明，"魔方"指的是3 × 3 × 3经典的鲁比克魔方。基于原始的3 × 3 × 3谜题有很多变种，但它们仍然远不如经典版本流行。
- en: 'Despite being quite simple in terms of mechanics and the task at hand, the
    cube is quite a tricky object in terms of all the transformations we can make
    by possible rotations of its sides. It was calculated that in total, the cube
    has ≈ 4.33 ⋅ 10^(19) distinct states reachable by rotating it. That’s only the
    states that are reachable without disassembling the cube; by taking it apart and
    then assembling it, you can get 12 times more states in total: ≈ 5.19 ⋅ 10^(20),
    but those “extra” states make the cube unsolvable without disassembling it.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管从机械原理和任务本身来看，魔方相对简单，但在所有通过旋转面实现的变换中，魔方却是一个相当棘手的物体。经过计算，总共通过旋转魔方可以到达约4.33 ⋅
    10^(19)个不同的状态。这些只是通过旋转魔方能到达的状态，而不需要拆解魔方；如果将魔方拆解后重新组装，最终可以获得多出12倍的状态，总数约为5.19 ⋅
    10^(20)，但这些“额外”状态使得魔方在不拆解的情况下无法解决。
- en: All those states are quite intimately intertwined with each other through rotations
    of the cube’s sides. For example, if we rotate the left side clockwise in some
    state, we get to the state from which rotation of the same side counterclockwise
    will destroy the effect of the transformation, and we will get into the original
    state.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些状态通过魔方面的旋转密切交织在一起。例如，如果我们在某个状态下将左侧顺时针旋转，则会到达一个状态，在该状态下，逆时针旋转同一面会取消变换的效果，并恢复到原始状态。
- en: But if we apply the left-side clockwise rotation three times in a row, the shortest
    path to the original state will be just a single rotation of the left side clockwise,
    but not three times counterclockwise (which is also possible, but just not optimal).
    As the cube has 6 edges and each edge can be rotated in 2 directions, we have
    12 possible rotations in total. Sometimes, half turns (which are two consecutive
    rotations in the same direction) are also included as distinct rotations, but
    for simplicity, we will treat them as two distinct transformations of the cube.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果我们连续三次进行左侧顺时针旋转，那么返回到原始状态的最短路径只需进行一次左侧顺时针旋转，而不是三次逆时针旋转（虽然逆时针旋转也是可能的，但并不是最优的）。由于魔方有6条边，每条边可以旋转2个方向，因此总共有12种可能的旋转。有时，半圈旋转（即两次连续的同向旋转）也被视为不同的旋转，但为了简便起见，我们将其视为魔方的两种不同变换。
- en: In mathematics, there are several areas that study objects of this kind. One
    of these is abstract algebra, a very broad division of math that studies abstract
    sets of objects with operations on top of them. In these terms, the Rubik’s cube
    is an example of quite a complicated group ( [https://en.wikipedia.org/wiki/Group_theory](https://en.wikipedia.org/wiki/Group_theory))
    with lots of interesting properties.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学中，有几个领域研究这类对象。其中之一是抽象代数，这是数学中一个非常广泛的分支，研究带有运算的抽象对象集合。从这些角度来看，鲁比克魔方是一个相当复杂的群体（[https://en.wikipedia.org/wiki/Group_theory](https://en.wikipedia.org/wiki/Group_theory)），具有许多有趣的性质。
- en: 'The cube is not just states and transformations; it’s a puzzle, with the primary
    goal to find a sequence of rotations with the solved cube as the end point. Problems
    of this kind are studied using combinatorial optimization, which is a subfield
    of applied math and theoretical computer science. This discipline has lots of
    famous problems of high practical value, for example:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 魔方不仅仅是状态和变换，它是一个谜题，主要目标是找到一个旋转序列，以解决魔方作为最终目标。这类问题通过组合优化进行研究，组合优化是应用数学和理论计算机科学的一个子领域。这个学科有很多具有高实际价值的著名问题，例如：
- en: 'The traveling salesman problem ([https://en.wikipedia.org/wiki/Travelling_salesman_problem](https://en.wikipedia.org/wiki/Travelling_salesman_problem)):
    Finds the shortest closed path in a graph'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旅行商问题 ([https://en.wikipedia.org/wiki/Travelling_salesman_problem](https://en.wikipedia.org/wiki/Travelling_salesman_problem))：在图中找到最短的闭合路径
- en: 'The protein folding simulation ([https://en.wikipedia.org/wiki/Protein_folding](https://en.wikipedia.org/wiki/Protein_folding)):
    Finds possible 3D structures of protein'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蛋白质折叠模拟 ([https://en.wikipedia.org/wiki/Protein_folding](https://en.wikipedia.org/wiki/Protein_folding))：寻找蛋白质的可能三维结构
- en: 'Resource allocation: How to spread a fixed set of resources among consumers
    to get the best objective'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源分配：如何在消费者之间分配固定的资源集，以达到最佳目标
- en: What those problems have in common is a huge state space, which makes it infeasible
    to just check all possible combinations to find the best solution. Our “toy cube
    problem” also falls into the same category, because a state space of 4.33 ⋅ 10^(19)
    makes a brute-force approach very impractical.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题的共同点是状态空间巨大，单纯通过检查所有可能的组合来找到最佳解是不切实际的。我们的“玩具魔方问题”也属于同类问题，因为 4.33 ⋅ 10^(19)
    的状态空间使得暴力破解方法非常不实用。
- en: Optimality and God’s number
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最优性与上帝之数
- en: 'What makes the combinatorial optimization problem tricky is that we’re not
    looking for any solution; we’re in fact interested in the optimal solution of
    the problem. So, what is the difference? Right after the Rubik’s cube was invented,
    it was known how to reach the goal state (but it took Ernő Rubik about a month
    to figure out the first method of solving his own invention, which I expect was
    a frustrating experience). Nowadays, there are lots of different ways or schemes
    of cube solving: the beginner’s method (layer by layer), the method by Jessica
    Fridrich (very popular among speedcubers), and so on.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 使得组合优化问题棘手的原因在于，我们并不是在寻找任何解法；我们实际上关注的是问题的最优解。那么，二者有什么区别呢？魔方发明之后，人们就知道如何达到目标状态（但
    Ernő Rubik 花了大约一个月的时间才弄明白他自己发明的魔方的第一个解法，这应该是一次令人沮丧的经历）。如今，有很多不同的魔方解法或方案：初学者方法（逐层法）、Jessica
    Fridrich 方法（在速解者中非常流行）等。
- en: 'All of them vary by the number of moves to be taken. For example, a very simple
    beginner’s method requires about 100 rotations to solve the cube using just 5…7
    sequences of rotations to be memorized. In contrast, the current world record
    in the speedcubing competition is solving the cube in 3.13 seconds, which requires
    much fewer steps, but more sequences need to be memorized. The method by Fridrich
    requires about 55 moves on average, but you need to familiarize yourself with
     120 different sequences of moves. Of course, the big question is: what is the
    shortest sequence of actions to solve any given state of the cube? Surprisingly,
    after 50 years since the invention of the cube, humanity still doesn’t know the
    full answer to this question. Only in 2010 did a group of researchers from Google
    prove that the minimum number of moves needed to solve any cube state is 20\.
    This number is also known as God’s number (not to be confused with the ”golden
    ratio” or ”divine proportion,” which is found everywhere in nature). Of course,
    on average, the optimal solution is shorter, as only a bunch of states require
    20 moves and one single state doesn’t require any moves at all (the solved state).
    This result only proves the minimal amount of moves; it does not find the solution
    itself. How to find the optimal solution for any given state is still an open
    question.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些方法的差异在于所需的步骤数。例如，一个非常简单的初学者方法需要大约 100 次旋转才能解出魔方，只需记住 5…7 种旋转序列。相比之下，目前的世界纪录是在
    3.13 秒内解出魔方，这需要更少的步骤，但需要记住更多的旋转序列。Fridrich 方法的平均步数大约是 55 步，但你需要熟悉 120 种不同的旋转序列。当然，关键问题是：解决任何给定魔方状态的最短动作序列是什么？令人惊讶的是，魔方发明
    50 年后，人类仍然不知道这个问题的完整答案。直到 2010 年，谷歌的研究人员才证明，解决任何魔方状态所需的最小步数是 20 步。这个数字也被称为上帝之数（不要与自然界中到处可见的“黄金比例”或“神圣比例”混淆）。当然，平均而言，最优解的步数更短，因为只有少数几个状态需要
    20 步，而某个单一状态根本不需要任何步骤（即已解状态）。这个结果仅证明了最小步数；它并没有找到具体的解法。如何为任何给定的状态找到最优解仍然是一个悬而未决的问题。
- en: Approaches to cube solving
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 魔方求解方法
- en: 'Before the paper by McAleer et al. was published, there were two major directions
    for solving the Rubik’s cube:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在 McAleer 等人发表论文之前，解决魔方问题的研究方向主要有两个：
- en: By using group theory, it is possible to significantly reduce the state space
    to be checked. One of the most popular solutions using this approach is Kociemba’s
    algorithm ([https://en.wikipedia.org/wiki/Optimal_solutions_for_Rubik\%27s_Cube#Kociemba’s_algorithm](https://en.wikipedia.org/wiki/Optimal_solutions_for_Rubik/)).
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用群论，可以显著减少需要检查的状态空间。使用这种方法的最流行的解决方案之一是 Kociemba 算法（[https://en.wikipedia.org/wiki/Optimal_solutions_for_Rubik\%27s_Cube#Kociemba’s_algorithm](https://en.wikipedia.org/wiki/Optimal_solutions_for_Rubik/))。
- en: By using brute-force search accompanied by manually crafted heuristics, we can
    direct the search in the most promising direction. A vivid example of this is
    Korf’s algorithm ([https://en.wikipedia.org/wiki/Optimal_solutions_for_Rubik\%27s_Cube#Korf’s_algorithm](https://en.wikipedia.org/wiki/Optimal_solutions_for_Rubik/)),
    which uses A* search with a large database of patterns to cut out bad directions.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用暴力搜索并辅以人工编写的启发式方法，我们可以将搜索引导至最有前景的方向。一个生动的例子是 Korf 的算法（[https://en.wikipedia.org/wiki/Optimal_solutions_for_Rubik\%27s_Cube#Korf’s_algorithm](https://en.wikipedia.org/wiki/Optimal_solutions_for_Rubik/))，它使用
    A* 搜索和一个庞大的模式数据库来排除不良的方向。
- en: 'McAleer et al. [[McA+18](#)] introduced a third approach (called autodidactic
    iteration, or ADI): by training the neural network (NN) on lots of randomly shuffled
    cubes, it is possible to get the policy that will show us the direction to take
    toward the solved state. The training is done without any prior knowledge about
    the domain; the only thing needed is the cube itself (not the physical one, but
    the computer model of it). This is in contrast with the two preceding methods,
    which require lots of human knowledge about the domain and labor to implement
    them in the form of computer code.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: McAleer 等人 [[McA+18](#)] 提出了第三种方法（称为自学迭代，或 ADI）：通过对大量随机打乱的魔方进行神经网络（NN）训练，可以得到一个策略，该策略会指引我们朝着解决状态前进。该训练不依赖于领域的先验知识；所需的唯一条件是魔方本身（不是物理魔方，而是其计算机模型）。这与前两种方法形成对比，后者需要大量的领域知识并付出人力将其实现为计算机代码。
- en: 'This method has lots of similarities to the AlphaGo Zero method we discussed
    in the previous chapter: we need a model of the environment and use Monte Carlo
    tree search (MCTS) to avoid full-state space exploration.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法与我们在前一章讨论的 AlphaGo Zero 方法有很多相似之处：我们需要一个环境模型，并使用蒙特卡洛树搜索（MCTS）来避免对完整状态空间的探索。
- en: 'In the subsequent sections, we will take a detailed look at this approach;
    we’ll start with data representation. In our cube problem, we have two entities
    that need to be encoded: actions and states.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在随后的章节中，我们将详细介绍这一方法；我们将从数据表示开始。在我们的魔方问题中，有两个实体需要被编码：动作和状态。
- en: Actions
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 动作
- en: Actions are possible rotations that we can do from any given cube state and,
    as has already been mentioned, we have only 12 actions in total. For every side,
    we have two different actions, corresponding to the clockwise and counterclockwise
    rotation of the side (90^∘ or −90^∘). One small, but very important, detail is
    that a rotation is performed from the position when the desired side is facing
    toward you. This is obvious for the front side, for example, but for the back
    side, it might be confusing due to the mirroring of the rotation.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 动作是我们可以从任何给定魔方状态执行的旋转，如前所述，我们总共有 12 个动作。对于每一面，我们有两个不同的动作，分别对应于该面的顺时针和逆时针旋转（90^∘
    或 −90^∘）。一个小但非常重要的细节是，旋转是从希望的面朝向你的位置执行的。对于前面来说，这一点显而易见，但对于后面来说，由于旋转的镜像特性，可能会产生混淆。
- en: 'The names of the actions are taken from the cube sides that we’re rotating:
    left, right, top, bottom, front, and back. The first letter of a side’s name is
    used. For instance, the rotation of the right side clockwise is named as R. There
    are different notations for counterclockwise actions; sometimes they are denoted
    with an apostrophe (R′), with a lowercase letter (r), or even with a tilde (R̃).
    The first and last notations are not very practical in computer code, so in my
    implementation, I’ve used lowercase actions to denote counterclockwise rotations.
    For the right side, we have two actions: R and r, and we have another two for
    the left side: L and l, and so on.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 动作的名称取自我们旋转的魔方面：左、右、上、下、前和后。面名称的第一个字母被用来表示。例如，右侧顺时针旋转的动作命名为 R。逆时针旋转有不同的表示方法；有时用撇号（R′）、小写字母（r）或波浪号（R̃）来表示。前两种表示方法在计算机代码中不太实用，因此在我的实现中，我使用小写字母表示逆时针旋转。对于右侧，我们有两个动作：R
    和 r；左侧也有两个动作：L 和 l，依此类推。
- en: 'In my code, the action space is implemented using a Python enum in libcube/cubes/cube3x3.py,
    in the Action class, where each action is mapped into the unique integer value:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的代码中，动作空间是通过 Python 枚举在 libcube/cubes/cube3x3.py 文件中的 Action 类实现的，其中每个动作都映射为唯一的整数值：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In addition, we describe the dictionary with reverse actions:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们描述了一个包含反向动作的字典：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: States
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 状态
- en: 'A state is a particular configuration of the cube’s colored stickers and, as
    discussed earlier, the size of our state space is very large (4.33 ⋅ 10^(19) different
    states). But the number of states is not the only complication we have; in addition,
    we have different objectives that we would like to meet when we choose a particular
    representation of a state:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 状态是立方体上彩色贴纸的特定配置，正如之前讨论的那样，我们的状态空间非常大（4.33 ⋅ 10^(19) 种不同状态）。但是，状态的数量并不是我们面临的唯一复杂性；此外，在选择特定状态表示方式时，我们有不同的目标希望达成：
- en: 'Avoid redundancy: In the extreme case, we can represent a state of the cube
    by just recording the colors of every sticker on every side. But if we just count
    the number of such combinations, we get 6^(6⋅8) = 6^(48) ≈ 2.25 ⋅ 10^(37), which
    is significantly larger than our cube’s state space size, which just means that
    this representation is highly redundant; for example, it allows all sides of the
    cube to have one single color (except the center cubelets). If you’re curious
    to know how I got 6^(6⋅8), this is simple: we have six sides of a cube, each having
    eight small cubes (we’re not counting centers), so we have 48 stickers in total
    and each of them could be colored in one of six colors.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免冗余：在极端情况下，我们可以仅通过记录每一面上每个贴纸的颜色来表示立方体的状态。但如果仅计算这种组合的数量，我们得到的是 6^(6⋅8) = 6^(48)
    ≈ 2.25 ⋅ 10^(37)，这比我们立方体的状态空间大小要大得多，这意味着这种表示方式具有高度冗余；例如，它允许立方体的所有面都有相同的颜色（除了中心的小立方体）。如果你想知道我是如何得到
    6^(6⋅8) 的，这很简单：我们有六个面，每个面有八个小立方体（我们不算中心立方体），所以我们总共有 48 个贴纸，每个贴纸可以涂成六种颜色之一。
- en: 'Memory efficiency: As you will see shortly, during the training and, even more
    so, during the model application, we will need to keep in our computer’s memory
    a large amount of different states of the cube, which might influence the performance
    of the process. So, we would like the representation to be as compact as possible.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存效率：如你即将看到的，在训练过程中，尤其是在模型应用期间，我们将需要在计算机内存中保持大量不同的立方体状态，这可能会影响过程的性能。因此，我们希望表示方式尽可能紧凑。
- en: 'Performance of the transformations: On the other hand, we need to implement
    all the actions applied to the state, and those actions need to be taken quickly.
    If our representation is very compact in terms of memory (uses bit-encoding, for
    example), but requires us to do a lengthy unpacking process for every rotation
    of the cube’s side, our training might become too slow.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变换的性能：另一方面，我们需要实现所有应用于状态的操作，这些操作需要快速执行。如果我们的表示方式在内存上非常紧凑（例如使用位编码），但每次旋转立方体的面时都需要进行冗长的解包过程，那么我们的训练可能会变得过于缓慢。
- en: 'NN friendliness: Not every data representation is equally as good as input
    for the NN. This is true not only for our case but for machine learning in general.
    For example, in NLP, it is common to use bag of words or word embeddings; in computer
    vision, images are decoded from JPEG into raw pixels; random forests require data
    to be heavily feature-engineered; and so on.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络友好性：并不是每种数据表示方式都同样适合作为神经网络的输入。这不仅在我们的案例中成立，在机器学习中普遍如此。例如，在自然语言处理（NLP）中，常用词袋模型或词嵌入；在计算机视觉中，图像从
    JPEG 解码为原始像素；随机森林则要求数据经过大量特征工程；等等。
- en: 'In the paper, every state of the cube is represented as a 20 × 24 tensor with
    one-hot encoding. To understand how this is done and why it has this shape, let’s
    start with the picture taken from the paper shown in Figure [21.1](#x1-396002r1):'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文中，立方体的每个状态都表示为一个 20 × 24 的张量，采用 one-hot 编码。为了理解这是如何实现的，以及为什么它具有这种形状，让我们从论文中所示的图
    [21.1](#x1-396002r1) 开始：
- en: '![PIC](img/file315.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/file315.png)'
- en: 'Figure 21.1: Stickers we need to track in the cube are marked in a lighter
    color'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 21.1：我们需要在立方体上跟踪的贴纸被标记为较浅的颜色
- en: 'Here, the light color marks the stickers of the cubelets that we need to track;
    the rest of the stickers (shown in a darker color) are redundant and there is
    no need to track them. As you know, a cube consists of three types of cubelets:
    8 corner cubelets with 3 stickers, 12 side cubelets with 2 stickers, and 6 central
    ones with a single sticker. It might not be obvious from first sight, but the
    central cubelets do not need to be tracked at all, as they can’t change their
    relative position and can only rotate. So, in terms of the central cubelets, we
    need only to agree on the cube alignment (how the cube is oriented in space) and
    stick to it.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，浅色标记了我们需要追踪的块的贴纸；其他贴纸（以较深的颜色显示）是冗余的，无需追踪。如你所知，立方体由三种类型的块组成：8个角块，每个有3个贴纸；12个侧块，每个有2个贴纸；以及6个中心块，每个有1个贴纸。乍一看，可能不太明显，但中心块完全不需要追踪，因为它们不能改变相对位置，只能旋转。因此，关于中心块，我们只需要就立方体的对齐方式（立方体在空间中的方向）达成一致并保持一致。
- en: In my implementation, the white side is always on the top, the front is red,
    the left is green, and so on. This makes our state rotation-invariant, which basically
    means that all possible rotations of the cube as a whole are considered as the
    same state.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的实现中，白色面始终在顶部，前面是红色，左面是绿色，依此类推。这样使得我们的状态具有旋转不变性，基本上意味着整个立方体的所有可能旋转被视为相同的状态。
- en: 'As the central cubelets are not tracked at all, on the figure, they are marked
    with the darker color. What about the rest? Obviously, every cubelet of a particular
    kind (corner or side) has a unique color combination of its stickers. For example,
    the assembled cube in my orientation (white on top, red on the front, and so on)
    has a top-left cubelet facing us with the following colors: green, white, and
    red. There are no other corner cubelets with those colors (please check in case
    of any doubt). The same is true for the side cubelets.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 由于中心块完全不被追踪，在图中，它们被标记为较深的颜色。那么剩下的块呢？显然，每种类型的块（角块或侧块）都有其独特的颜色组合。例如，我的方向（白色在顶部，红色在前面，依此类推）下，组装后的立方体中，左上角的角块正对我们，颜色是绿色、白色和红色。没有其他角块有这些颜色组合（如有疑问请检查）。侧块也是如此。
- en: 'Due to this, to find the position of some particular cubelet, we need to know
    the position of only one of its stickers. The selection of such stickers is completely
    arbitrary, but once they are selected, you need to stick to this. As shown in
    the preceding figure, we track eight stickers from the top side, eight stickers
    from the bottom, and four additional side stickers: two on the front face and
    two on the back. This gives us 20 stickers to be tracked.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个原因，要找到某个特定角块的位置，我们只需要知道其中一个贴纸的位置。选择哪个贴纸完全是任意的，但一旦选择了，就必须坚持下去。如前图所示，我们追踪来自顶部的八个贴纸，来自底部的八个贴纸，以及四个额外的侧面贴纸：两个在前面，两个在后面。这样我们就有了20个需要追踪的贴纸。
- en: Now, let’s discuss where 24 in the tensor dimension comes from. In total, we
    have 20 different stickers to track, but in which positions could they appear
    due to cube transformations? It depends on the kind of cubelet we’re tracking.
    Let’s start with corner cubelets. In total, there are eight corner cubelets and
    cube transformations can reshuffle them in any order. So, any particular cubelet
    could end up in any of eight possible corners.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论一下张量维度中的24是怎么来的。总的来说，我们有20个不同的贴纸需要追踪，那么它们在哪些位置可能会出现，取决于立方体的变换？这取决于我们正在追踪的块的类型。我们从角块开始讲起。总共有八个角块，立方体的变换可以把它们重新排列成任何顺序。所以，任何特定的角块都可以出现在八个可能的角位置中。
- en: 'In addition, every corner cubelet could be rotated, so our “green, white, and
    red” cubelet could end up in three possible orientations:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，每个角块都可以旋转，所以我们的“绿色、白色和红色”角块可能有三种不同的方向：
- en: White on top, green left, and red front
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 白色在顶部，绿色在左侧，红色在前面
- en: Green on top, red left, and white front
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绿色在顶部，红色在左侧，白色在前面
- en: Red on top, white left, and green front
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 红色在顶部，白色在左侧，绿色在前面
- en: 'So, to precisely indicate the position and orientation of the corner cubelet,
    we have 8 × 3 = 24 different combinations. In the case of the 12-side cubelets,
    they have only two stickers, so there are only two orientations possible, which,
    again, gives us 24 combinations, but they are obtained from a different calculation:
    12 × 2 = 24\. Finally, we have 20 cubelets to be tracked, 8 corners and 12 sides,
    each having 24 positions that it could end up in.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了准确指示角块的定位和方向，我们有8 × 3 = 24种不同的组合。对于12个边块，它们只有两个贴纸，因此只有两种可能的方向，这同样给我们提供了24种组合，但它们来自不同的计算：12
    × 2 = 24。最后，我们有20个立方体小块需要跟踪，8个角块和12个边块，每个小块都有24个可能的状态。
- en: A very popular option to feed such data into an NN is one-hot encoding, when
    the concrete position of the object has 1, with other positions filled with 0\.
    This gives us the final representation of the state as a tensor with the shape
    20 × 24.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一种非常流行的将此类数据输入神经网络的方法是独热编码（one-hot encoding），即对象的具体位置为1，其他位置填充为0。这样我们最终得到的状态表示是一个形状为20
    × 24的张量。
- en: From a redundancy point of view, this representation is much closer to the total
    state space; the amount of possible combinations equals 24^(20) ≈ 4.02 ⋅ 10^(27).
    It is still larger than the cube state space (it could be said that it is significantly
    larger, as the factor of 10⁸ is a lot), but it is better than encoding all the
    colors of every sticker. This redundancy comes from tricky properties of cube
    transformations; for example, it is not possible to rotate one single corner cubelet
    (or flip one side cubelet) leaving all others in their places. Mathematical properties
    are well beyond the scope of this book, but if you’re interested, I recommend
    the wonderful book by Alexander Frey and David Singmaster called Handbook of Cubik
    Math [[FS20](#)].
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 从冗余度的角度来看，这种表示法与总状态空间更加接近；可能的组合数量为24^(20) ≈ 4.02 ⋅ 10^(27)。它仍然大于立方体状态空间（可以说它大得多，因为10⁸的因子非常大），但比编码每个贴纸的所有颜色要好。这种冗余来自于立方体变换的复杂特性；例如，不能仅旋转一个角块（或翻转一个边块），而使其他所有块保持不变。数学特性超出了本书的范围，但如果你有兴趣，我推荐亚历山大·弗雷（Alexander
    Frey）和大卫·辛格马斯特（David Singmaster）所著的《魔方数学手册》[[FS20](#)]。
- en: 'You might have noticed that the tensor representation of the cube state has
    one significant drawback: memory inefficiency. Indeed, by keeping the state as
    a floating-point tensor of 20 × 24, we’re using 4 × 20 × 24 = 1,920 bytes of memory,
    which is a lot given the requirement to keep thousands of states during the training
    process and millions of them during the cube solving (as you will get to know
    shortly). To overcome this, in my implementation, I used two representations:
    one tensor is intended for NN input and another, more compact, representation
    is needed to store different states for longer. This compact state is saved as
    a bunch of lists, encoding the permutations of corner and side cubelets, and their
    orientation. This representation is not only much more memory efficient (160 bytes)
    but also much more convenient for transformation implementation.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，立方体状态的张量表示有一个显著的缺点：内存低效。实际上，通过将状态保持为20 × 24的浮点张量，我们使用了4 × 20 × 24 =
    1,920字节的内存，这在训练过程中需要保持成千上万的状态以及在解立方体时需要保持百万个状态的情况下非常庞大（正如你稍后会了解的那样）。为了克服这个问题，在我的实现中，我使用了两种表示法：一种张量用于神经网络输入，另一种更紧凑的表示法则用于长期存储不同的状态。这种紧凑的状态被保存为一组列表，编码角块和边块的置换及其方向。这个表示法不仅更加节省内存（160字节），而且在实现变换时也更为方便。
- en: To illustrate this, what follows is the piece of the cube 3 × 3 library, libcube/cubes/cube3x3.py,
    which is responsible for compact representation.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明这一点，接下来是立方体3 × 3库libcube/cubes/cube3x3.py的部分内容，负责紧凑表示。
- en: 'The variable intial_state is the encoding of the solved state of the cube.
    In it, corner and side stickers that we’re tracking are in their original positions,
    and both orientation lists are set to 0, indicating the initial orientation of
    the cubelets:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 变量`initial_state`是立方体已解状态的编码。在其中，我们跟踪的角块和边块贴纸处于其原始位置，两个方向列表都设置为0，表示立方体小块的初始方向：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The transformation of the cube is a bit complex and includes lots of tables
    holding the rearrangements of cubelets after different rotations are applied.
    I’m not going to put this code here; if you’re curious, you can start with the
    function transform(state, action) in libcube/cubes/cube3x3.py. It might also be
    helpful to check unit tests of this code.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 立方体的变换有点复杂，包含了许多表格，记录了应用不同旋转后的立方体块重新排列。我不会把这段代码放在这里；如果你感兴趣，可以从 libcube/cubes/cube3x3.py
    中的 transform(state, action) 函数开始。检查该代码的单元测试也可能会有所帮助。
- en: Besides the actions and compact state representation and transformation, the
    module cube3x3.py includes a function that converts the compact representation
    of the cube state (as the State named tuple) into the tensor form. This functionality
    is provided by the encode_inplace() method.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 除了动作、紧凑状态表示和变换外，模块 cube3x3.py 还包括一个将立方体状态的紧凑表示（作为名为 State 的元组）转换为张量形式的函数。这个功能由
    encode_inplace() 方法提供。
- en: Another functionality implemented is the ability to render the compact state
    into human-friendly form by applying the render() function. It is very useful
    for debugging the transformation of the cube, but it’s not used in the training
    code.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个已实现的功能是通过应用 render() 函数将紧凑的状态渲染为人类友好的形式。这个功能对于调试立方体变换非常有用，但在训练代码中并未使用。
- en: The training process
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练过程
- en: Now that you know how the state of the cube is encoded in a 20 × 24 tensor,
    let’s explore the NN architecture and understand how it is trained.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道了如何将立方体的状态编码成 20 × 24 的张量，让我们来探索神经网络架构，理解它是如何训练的。
- en: The NN architecture
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络架构
- en: 'Figure [21.2](#x1-398003r2), from the paper by McAleer et al., shows the network
    architecture:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [21.2](#x1-398003r2)，来自 McAleer 等人的论文，展示了网络架构：
- en: '![PIC](img/file316.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file316.png)'
- en: 'Figure 21.2: The NN architecture transforming the observation (top) to the
    action and value (bottom)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 21.2：神经网络架构将观察（顶部）转化为动作和值（底部）
- en: 'As the input, it accepts the already familiar cube state representation as
    a 20 × 24 tensor and produces two outputs:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 作为输入，它接受已经熟悉的立方体状态表示形式，作为一个 20 × 24 的张量，并输出两个结果：
- en: The policy, which is a vector of 12 numbers, representing the probability distribution
    over our actions.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 策略是一个包含 12 个数字的向量，表示我们行动的概率分布。
- en: The value, a single scalar estimating the “goodness” of the state passed. The
    concrete meaning of a value will be discussed in the next section.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值是一个标量，估计传递的状态的“好坏”。值的具体含义将在下一节中讨论。
- en: 'In my implementation, the architecture is exactly the same as in the paper,
    and the model is in the module libcube/model.py. Between the input and output,
    the network has several fully connected layers with exponential linear unit (ELU)
    activations, as discussed in the paper:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的实现中，架构与论文中的完全一致，模型位于模块 libcube/model.py 中。在输入和输出之间，网络有多个全连接层，使用指数线性单元（ELU）激活函数，如论文中所讨论的：
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The forward() call can be used in two modes: to get both the policy and the
    value, or whenever value_only=True, only the value. This saves us some computations
    in the case when only the value head’s result is of interest.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: forward() 调用可以有两种模式：既可以获取策略和值，也可以在 value_only=True 时，仅获取值。这在只有值头部结果需要关注时可以节省一些计算。
- en: The training
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练
- en: 'In this network, the policy tells us what transformation we should apply to
    the state, and the value estimates how good the state is. But the big question
    still remains: how do we train the network?'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个网络中，策略告诉我们应该对状态应用什么变换，而值则估计状态的好坏。但是，大问题仍然存在：我们如何训练这个网络？
- en: As discussed earlier, the training method proposed in the paper is called autodidactic
    iterations (ADI). Let’s look at its structure. We start with the goal state (the
    assembled cube) and apply the sequence of random transformations of some predefined
    length, N. This gives us a sequence of N states.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，论文中提出的训练方法称为自学迭代（ADI）。让我们来看看它的结构。我们从目标状态（已组装的立方体）开始，应用一系列预定义长度 N 的随机变换。这样我们就得到了一个包含
    N 个状态的序列。
- en: 'For each state, s, in this sequence, we carry out the following procedure:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 对于序列中的每个状态 s，我们执行以下过程：
- en: Apply every possible transformation (12 in total) to s.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对 s 应用所有可能的变换（共 12 种）。
- en: Pass those 12 states to our current NN, asking for the value output. This gives
    us 12 values for every substate of s.
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这 12 个状态传递给我们当前的神经网络，要求输出值。这为 s 的每个子状态提供了 12 个值。
- en: The target value for s is calculated as y[v[i]] = max[a](v[s](a)+R(A(s,a))),
    where A(s,a) is the state after the action, a, is applied to s and R(s) equals
    1 if s is the goal state and -1 otherwise.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: s 的目标值计算公式为 y[v[i]] = max[a](v[s](a)+R(A(s,a)))，其中 A(s,a) 是对状态 s 执行动作 a 后的状态，R(s)
    等于 1 如果 s 是目标状态，其他情况为 -1。
- en: 'The target policy for s is calculated using the same formula, but instead of
    max, we take argmax: y[p[i]] = arg max[a](v[s](a) + R(A(s,a))). This just means
    that our target policy will have 1 at the position of the maximum value for the
    substate and 0 on all other positions.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: s 的目标策略使用相同的公式进行计算，但我们取的是 argmax 而非 max：y[p[i]] = arg max[a](v[s](a) + R(A(s,a)))。这意味着我们的目标策略将在子状态的最大值位置上为
    1，在其他所有位置上为 0。
- en: This process is shown in Figure [21.3](#x1-399011r3), taken from the paper.
    The sequence of scrambles, x[0],x[1],…x[N], is generated, where the cube, x[i],
    is shown expanded. For this state, x[i], we make targets for the policy and value
    heads from the expanded states by applying the preceding formulas.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程如图 [21.3](#x1-399011r3) 所示，取自论文。生成了一个混乱序列，x[0],x[1],…x[N]，其中魔方 x[i] 被展开显示。对于这个状态
    x[i]，我们通过应用前述公式，从展开状态中为策略头和值头生成目标。
- en: '![PIC](img/file317.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file317.png)'
- en: 'Figure 21.3: Data generation for training'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图 21.3：训练数据生成
- en: Using this process, we can generate any amounts of training data that we want.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个过程，我们可以生成任何我们需要的训练数据。
- en: The model application
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型应用
- en: 'Okay, imagine that we have trained the model using the process just described.
    How should we use it to solve the scrambled cube? From the network’s structure,
    you might imagine the obvious, but not very successful, way:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，假设我们已经使用刚才描述的过程训练好了模型。我们应该如何使用它来解决打乱的魔方呢？从网络的结构上看，你可能会想出一个明显的，但并不成功的方法：
- en: Feed the model the current state of the cube that we want to solve.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将我们想要解决的魔方的当前状态输入模型。
- en: From the policy head, get the largest action to perform (or sample it from the
    resulting distribution).
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从策略头获取最大动作（或从结果分布中采样）。
- en: Apply the action to the cube.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对魔方执行该动作。
- en: Repeat the process until the solved state has been reached.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复该过程，直到达到已解决的状态。
- en: 'On paper, this method should work, but in practice, it has one serious issue:
    it doesn’t! The main reason for that is our model’s quality. Due to the size of
    the state space and the nature of the NNs, it just isn’t possible to train an
    NN to return the exact optimal action for any input state all of the time. Rather
    than telling us what to do to get the solved state, our model shows us promising
    directions to explore. Those directions could bring us closer to the solution,
    but sometimes they could be misleading, just from the fact that this particular
    state has never been seen during the training. Don’t forget, there are 4.33 ⋅
    10^(19) of them, so even with a graphics processing unit (GPU) training speed
    of hundreds of thousands of states per second, and after a month of training,
    we will only see a tiny portion of the state space, about 0.0000005%. So, a more
    sophisticated approach has to be used.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，这种方法应该可行，但在实践中，它存在一个严重的问题：它不可行！主要原因在于我们的模型质量。由于状态空间的庞大和神经网络的性质，我们无法训练出一个神经网络，在任何输入状态下都能准确地返回最优动作。我们的模型并不是直接告诉我们如何做才能得到已解决的状态，而是展示了我们应该探索的有前景的方向。这些方向可能会把我们带得更接近解决方案，但有时也可能会误导我们，因为这个特定状态在训练过程中从未见过。别忘了，状态空间有
    4.33 ⋅ 10^(19) 个，即使使用每秒数十万个状态的图形处理单元（GPU）训练速度，经过一个月的训练，我们也只能看到状态空间中的一小部分，大约为 0.0000005%。因此，必须使用更复杂的方法。
- en: 'There is a family of very popular methods, called MCTS, and one of these methods
    was covered in the last chapter. There are lots of variants of those methods,
    but the overall idea can be described in comparison with the well-known brute-force
    search methods, like breadth-first search (BFS) or depth-first search (DFS). In
    BFS and DFS, we perform an exhaustive search of our state space by trying all
    the possible actions and exploring all the states that we get from those actions.
    That behavior is the other extreme of the procedure described previously (when
    we have something that tells us where to go at every state). But MCTS offers something
    in between those extremes: we want to perform the search and we have some information
    about where we should go, but this information could be unreliable, noisy, or
    just wrong in some situations. However, sometimes, this information could show
    us the promising directions that could speed up the search process.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 有一类非常流行的方法，称为MCTS，其中一种方法在上一章中已有介绍。这些方法有很多变种，但总体思路可以通过与众所周知的暴力搜索方法进行比较来描述，比如广度优先搜索（BFS）或深度优先搜索（DFS）。在BFS和DFS中，我们通过尝试所有可能的动作并探索从这些动作得到的所有状态，来对我们的状态空间进行穷举搜索。这种行为与之前描述的过程正好相反（当我们有某种东西可以告诉我们在每个状态下应该去哪里时）。但MCTS在这些极端之间提供了一种选择：我们想进行搜索，并且有一些关于我们应该去哪里的信息，但在某些情况下，这些信息可能不可靠、嘈杂，甚至完全错误。然而，有时这些信息能够帮助我们发现可能加速搜索过程的有前景的方向。
- en: As I’ve mentioned, MCTS is a family of methods and they vary in their particular
    details and characteristics. In the paper, a method called Upper Confidence Bound
    1 is used. This method operates on the tree, where the nodes are the states and
    the edges are actions connecting those states. The whole tree is enormous in most
    cases, so we can’t try to build the whole tree, just some tiny portion of it.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我提到的，MCTS是一系列方法，它们在具体细节和特点上有所不同。在论文中，使用了一种叫做上置信界1（Upper Confidence Bound 1）的方法。这种方法作用于树形结构，其中节点代表状态，边表示连接这些状态的动作。在大多数情况下，整个树是巨大的，因此我们不能尝试构建整个树，而只能构建其中的一小部分。
- en: 'In the beginning, we start with a tree consisting of a single node, which is
    our current state. At every step of the MCTS, we walk down the tree, exploring
    some path in the tree, and there are two options we can face:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一开始，我们从一个只包含一个节点的树开始，这个节点就是我们当前的状态。在每一步的MCTS中，我们沿着树向下走，探索树中的某条路径，可能会遇到两种选择：
- en: Our current node is a leaf node (we haven’t explored this direction yet)
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们当前的节点是叶节点（我们还没有探索这个方向）
- en: Our current node is in the middle of the tree and has children
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们当前的节点位于树的中间，并且有子节点。
- en: In the case of a leaf node, we “expand” it by applying all the possible actions
    to the state. All the resulting states are checked for being the goal state (if
    the goal state of the solved cube has been found, our search is done). The leaf
    state is passed to the model and the outputs from both the value and policy heads
    are stored for later use.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 对于叶节点，我们通过对状态应用所有可能的动作来“扩展”它。所有结果状态都会被检查是否是目标状态（如果已找到已解的魔方的目标状态，我们的搜索就结束了）。叶节点状态会被传递到模型，并且来自值头和策略头的输出会被存储以供后续使用。
- en: If the node is not the leaf, we know about its children (reachable states),
    and we have value and policy outputs from the network. So, we need to make the
    decision about which path to follow (in other words, which action is more promising
    to explore). This decision is not a trivial one and this is the exploration versus
    exploitation problem that we have covered previously in this book. On the one
    hand, our policy from the network says what to do. But what if it is wrong? This
    could be solved by exploring surrounding states, but we don’t want to explore
    all the time (as the state space is enormous). So, we should keep the balance,
    and this has a direct influence on the performance and the outcome of the search
    process.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果节点不是叶节点，我们就知道它的子节点（可达的状态），并且我们从网络中获得了值和策略的输出。因此，我们需要做出决定，选择应该跟随哪条路径（换句话说，选择哪一个动作更有可能被探索）。这个决策并非易事，这就是我们在本书中先前讲过的探索与利用问题。一方面，来自网络的策略告诉我们该怎么做。但如果它是错误的呢？这个问题可以通过探索周围的状态来解决，但我们不希望总是进行探索（因为状态空间是巨大的）。因此，我们应该保持平衡，这直接影响到搜索过程的性能和结果。
- en: To solve this, for every state, we keep the counter for every possible action
    (there are 12 of them), which is incremented every time the action has been chosen
    during the search. To make the decision to follow a particular action, we use
    this counter; the more an action has been taken, the less likely it is to be chosen
    in the future.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，对于每个状态，我们保持一个计数器，记录每个可能的动作（共有12个），每当该动作在搜索过程中被选择时，计数器会增加。为了决定跟随哪个动作，我们使用这个计数器；一个动作被采取得越多，它在未来被选择的可能性就越小。
- en: In addition, the value returned by the model is also used in this decision-making.
    The value is tracked as the maximum from the current state’s value and the value
    from its children. This allows the most promising paths (from the model perspective)
    to be seen from the parent’s states.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，模型返回的值也被用于这个决策过程中。这个值作为当前状态的值与其子状态的最大值进行跟踪。这使得最有前景的路径（从模型的角度来看）能够从父状态中被看到。
- en: 'To summarize, the action to follow from a non-leaf tree is chosen by using
    the following formula:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，从非叶节点的树中选择的动作是通过以下公式来选择的：
- en: '![π (a |s) = P[At = a|St = s] ](img/eq75.png) ![π (a |s) = P[At = a|St = s]
    ](img/eq76.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![π (a |s) = P[At = a|St = s] ](img/eq75.png) ![π (a |s) = P[At = a|St = s]
    ](img/eq76.png)'
- en: Here, N[s[t]](a) is a count of times that action a has been chosen in state
    s[t]. P[s[t]](a) is the policy returned by the model for state s[t] and W[s[t]](a)
    is the maximum value returned by the model for all children states of s[t] under
    the branch a.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，N[s[t]](a)表示在状态s[t]中选择动作a的次数。P[s[t]](a)是模型为状态s[t]返回的策略，W[s[t]](a)是模型对于状态s[t]在分支a下所有子状态的最大值。
- en: This procedure is repeated until the solution has been found or our time budget
    has been exhausted. To speed up the process, MCTS is very frequently implemented
    in a parallel way, where several searches are performed by multiple threads. In
    that case, some extra loss could be subtracted from A[t] to prevent multiple threads
    from exploring the same paths of the tree.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程会一直重复，直到找到解决方案或耗尽时间预算。为了加速这一过程，MCTS通常以并行方式实现，由多个线程执行多个搜索。在这种情况下，可能会从A[t]中减去一些额外的损失，以防止多个线程探索树的相同路径。
- en: 'The final piece in solving the process puzzle is how to get the solution from
    the MCTS tree once we have reached the goal state. The authors of the paper experimented
    with two approaches:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个过程难题的最后一部分是，一旦我们到达目标状态，如何从MCTS树中获取解决方案。论文的作者尝试了两种方法：
- en: 'Naïve: Once we have faced the goal state, we use our path from the root state
    as the solution'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初步方法：一旦我们遇到目标状态，我们就使用从根状态到目标状态的路径作为解决方案。
- en: 'The BFS way: After reaching the goal state, BFS is performed on the MCTS tree
    to find the shortest path from the root to this state'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BFS方法：在达到目标状态后，在MCTS树上执行BFS，以找到从根节点到该状态的最短路径。
- en: According to the authors, the second method finds shorter solutions than the
    naïve version, which is not surprising, as the stochastic nature of the MCTS process
    can introduce cycles to the solution path.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 根据作者的说法，第二种方法比初步方法找到的解决方案更短，这并不令人惊讶，因为MCTS过程的随机性可能会在解决路径中引入循环。
- en: Results
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: 'The final result published in the paper is quite impressive. After 44 hours
    of training on a machine with three GPUs, the network learned how to solve cubes
    at the same level as (and sometimes better than) human-crafted solvers. The final
    model has been compared against the two solvers described earlier: the Kociemba
    two-stage solver and Korf. The method proposed in the paper is named DeepCube.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 论文中发布的最终结果相当令人印象深刻。在一个配有三块GPU的机器上训练了44小时后，网络学会了解决魔方，达到了与人类设计的求解器相同的水平（有时甚至更好）。最终模型与前面提到的两种求解器进行了比较：Kociemba两阶段求解器和Korf。论文中提出的方法名为DeepCube。
- en: To compare efficiency, 640 randomly scrambled cubes were used in all the methods.
    The depth of the scramble was 1,000 moves. The time limit for the solution was
    an hour and both the DeepCube and Kociemba solvers were able to solve all of the
    cubes within the limit. The Kociemba solver is very fast, and its median solution
    time is just one second, but due to the hardcoded rules implemented in the method,
    its solutions are not always the shortest ones.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较效率，所有方法使用了640个随机打乱的魔方。打乱的深度为1,000步。解决方案的时间限制为一小时，DeepCube和Kociemba求解器都能在该时间限制内解决所有魔方。Kociemba求解器非常快速，其中位解决时间仅为一秒，但由于该方法中硬编码规则的实现，它的解决方案并不总是最短的。
- en: The DeepCube method took much more time, with the median time being about 10
    minutes, but it was able to match the length of the Kociemba solutions or do better
    in 55% of cases. From my personal perspective, 55% is not enough to say that NNs
    are significantly better, but at least they are not worse.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: DeepCube 方法花费了更多的时间，中位数时间大约为 10 分钟，但它能够与 Kociemba 解法的解答长度相匹配，或者在 55% 的情况下表现得更好。从个人角度来看，55%
    的表现并不足以证明神经网络在性能上有显著优势，但至少它们并不逊色。
- en: 'In Figure [21.4](#x1-401002r4), taken from the paper, the length distributions
    for all the solvers are shown. As you can see, the Korf solver wasn’t compared
    in 1,000 scramble test cases, due to the very long time needed to solve the cube.
    To compare the performance of DeepCube against the Korf solver, a much easier
    15-step scramble test set was created:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 [21.4](#x1-401002r4) 中，展示了所有求解器的解答长度分布。正如你所看到的，由于 Korf 求解器解决魔方所需的时间过长，它没有在
    1,000 次混乱测试中进行比较。为了将 DeepCube 的表现与 Korf 求解器进行比较，创建了一个更简单的 15 步混乱测试集：
- en: '![PIC](img/file318.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file318.png)'
- en: 'Figure 21.4: The length of solutions found by various solvers'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 21.4：不同求解器找到的解答长度
- en: The code outline
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代码大纲
- en: 'Now that you have some context, let’s switch to the code, which is in the Chapter21
    directory in the book’s GitHub repository. In this section, I’m going to give
    a quick outline of my implementation and the key design decisions, but before
    that, I have to emphasize the important points about the code to set up the correct
    expectations:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了一些背景，让我们切换到代码部分，代码位于书籍 GitHub 仓库的 Chapter21 目录中。在本节中，我将简要概述我的实现和关键设计决策，但在此之前，我必须强调关于代码的重要细节，以便设定正确的期望：
- en: I’m not a researcher, so the original goal of this code was just to reimplement
    the paper’s method. Unfortunately, the paper has very few details about the exact
    hyperparameters used, so I had to experiment a lot, and still, my results are
    very different from those published in the paper.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我不是一个研究人员，所以这段代码的最初目标只是重新实现论文中的方法。不幸的是，论文中关于超参数的细节非常少，所以我不得不做很多实验，尽管如此，我的结果与论文中发布的结果差异很大。
- en: 'At the same time, I’ve tried to implement everything in a general way to simplify
    further experiments. For example, the exact details about the cube state and transformations
    are abstracted away, which allows us to implement more puzzles similar to the
    3×3 cube just by adding a new module. In my code, two cubes are implemented: 2×2
    and 3×3, but any fully observable environment with a fixed set of predictable
    actions can be implemented and experimented with. The details are given later
    in this section (in the Cube environments subsection).'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与此同时，我尽量将所有内容实现得更通用，以简化后续的实验。例如，魔方状态和变换的具体细节被抽象化，这使得我们可以通过添加新模块来实现更多类似于 3×3
    魔方的谜题。在我的代码中，已实现了 2×2 和 3×3 魔方，但任何具有固定可预测动作集合的完全可观察环境都可以被实现并进行实验。具体细节将在本节稍后（在“魔方环境”小节中）给出。
- en: Code clarity and simplicity were put ahead of performance. Of course, when it
    was possible to improve performance without introducing much overhead, I did so.
    For example, the training process was sped up by a factor of five by just splitting
    the generation of the scrambled cubes and the forward network pass. But if the
    performance required refactoring everything into multi-GPU and multithreaded mode,
    I preferred to keep things simple. A very clear example is the MCTS process, which
    is normally implemented as multithreaded code sharing the tree. It usually gets
    sped up several times, but requires tricky synchronization between processes.
    So, my version of MCTS is serial, with only trivial optimization of the batched
    search.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码的清晰性和简洁性被置于性能之前。当然，当有机会在不引入过多开销的情况下提高性能时，我会这么做。例如，仅仅通过将混乱魔方的生成和前向网络传递分开，训练过程的速度提高了五倍。但如果性能要求将一切重构为多
    GPU 和多线程模式，我宁愿保持简单。一个很明确的例子是 MCTS 过程，通常会实现为多线程代码共享树结构。它通常可以加速数倍，但需要在进程之间进行复杂的同步。因此，我的
    MCTS 版本是串行的，仅对批量搜索做了微小的优化。
- en: 'Overall, the code consists of the following parts:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，代码包含以下部分：
- en: The cube environment, which defines the observation space, the possible actions,
    and the exact representation of the state to the network. This part is implemented
    in the libcube/cubes module.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 魔方环境，定义了观察空间、可能的动作以及状态到网络的准确表示。这个部分在 libcube/cubes 模块中实现。
- en: The NN part, which describes the model that we will train, the generation of
    training samples, and the training loop. It includes the training tool train.py
    and the module libcube/model.py.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经网络部分，描述了我们将要训练的模型、训练样本的生成和训练循环。它包括训练工具 train.py 和模块 libcube/model.py。
- en: The solver of cubes or the search process, including the solver.py utility and
    the libcube/mcts.py module, which implements MCTS.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 立方体的求解器或搜索过程，包括求解器（solver.py）工具和实现 MCTS 的 libcube/mcts.py 模块。
- en: Various tools used to glue up other parts, like configuration files with hyperparameters
    and tools used to generate cube problem sets.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 各种工具被用来将其他部分粘合在一起，如包含超参数的配置文件和用于生成立方体问题集的工具。
- en: Cube environments
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 立方体环境
- en: 'As you have already seen, combinatorial optimization problems are quite large
    and diverse. Even the narrow area of cube-like puzzles includes a couple of dozen
    variations. The most popular ones are 2 × 2 × 2, 3 × 3 × 3, and 4 × 4 × 4 Rubik’s
    cubes, Square-1, and Pyraminx ([https://ruwix.com/twisty-puzzles/](https://ruwix.com/twisty-puzzles/)).
    At the same time, the method presented in the paper is quite general and doesn’t
    depend on prior domain knowledge, the amount of actions, and the state space size.
    The critical assumptions imposed on the problem include:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你已经看到的，组合优化问题是相当庞大和多样的。即使是狭义的立方体类谜题，也包括了几十种变体。最流行的包括 2 × 2 × 2、3 × 3 × 3 和
    4 × 4 × 4 的魔方，Square-1 和 Pyraminx（[https://ruwix.com/twisty-puzzles/](https://ruwix.com/twisty-puzzles/)）。与此同时，本文中提出的方法是相当通用的，不依赖于先验领域知识、动作数量和状态空间大小。对问题的关键假设包括：
- en: States of the environment need to be fully observable and observations need
    to distinguish states from each other. That’s the case for the cube when we can
    see all the sides’ states, but it doesn’t hold true for most variants of poker,
    for example, when we can’t see the cards of our opponent.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境的状态需要是完全可观察的，观察结果需要能够区分不同的状态。这对魔方来说是成立的，因为我们可以看到所有面的状态，但对于大多数扑克牌变体来说，这不成立，例如我们看不到对手的牌。
- en: The number of actions needs to be discrete and finite. There is a limited number
    of actions we can take with the cube, but if our action space is “rotate the steering
    wheel on angle α ∈ [−120^∘…120^∘],” we have a different problem domain here, as
    you have already seen in chapters devoted to the continuous control problems.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动作的数量需要是离散且有限的。我们可以对魔方采取的动作数量是有限的，但如果我们的动作空间是“将方向盘旋转角度 α ∈ [−120^∘…120^∘]”，那么我们面对的将是一个不同的问题领域，正如你在涉及连续控制问题的章节中已经看到的那样。
- en: 'We need to have a reliable model of the environment; in other words, we have
    to be able to answer questions like “What will be the result of applying action
    a[i] to the state s[j]?” Without this, both ADI and MCTS become non-applicable.
    This is a strong requirement and, for most problems, we don’t have such a model
    or its outputs are quite noisy. On the other hand, in games like chess or Go,
    we have such a model: the rules of the game.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要有一个可靠的环境模型；换句话说，我们必须能够回答类似“将动作 a[i] 应用于状态 s[j] 后会得到什么结果？”这样的问题。如果没有这个，ADI
    和 MCTS 都无法应用。这是一个强要求，对于大多数问题，我们没有这样的模型，或者其输出是相当嘈杂的。另一方面，在像国际象棋或围棋这样的游戏中，我们有这样的模型：游戏规则。
- en: At the same time, as we’ve seen in the previous chapter (about the MuZero method),
    you can approximate the model with neural networks, but paying the price of lower
    performance.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与此同时，正如我们在上一章（关于 MuZero 方法）中看到的，你可以使用神经网络来逼近模型，但代价是性能会降低。
- en: In addition, our domain is deterministic, as the same action applied to the
    same state always ends up in the same final state. The counter example might be
    backgammon, when, on each turn, players roll the dice to get the amount of moves
    they can possibly make. Most likely, this method could be generalized to this
    case as well.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，我们的领域是确定性的，因为对相同的状态应用相同的动作总是会得到相同的最终状态。反例可能是西洋双陆棋，每回合玩家投掷骰子来决定他们可能进行的步数。很可能，这种方法也可以推广到这种情况。
- en: To simplify the application of the methods to domains different from the 3 ×
    3 cube, all concrete environment details are moved to separate modules, communicating
    with the rest of the code via the abstract interface CubeEnv, which is described
    in the libcube/cubes/_env.py module. Let’s go through its interface.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化方法在与 3 × 3 立方体不同领域中的应用，所有具体的环境细节被移到单独的模块中，并通过抽象接口 CubeEnv 与其余代码进行通信，该接口在
    libcube/cubes/_env.py 模块中进行了描述。让我们来看看它的接口。
- en: 'As shown in the following code snippet, the constructor of the class takes
    a bunch of arguments:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如下代码片段所示，类的构造函数接受一组参数：
- en: The name of the environment.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境的名称。
- en: The type of the environment state.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境状态的类型。
- en: The instance of the initial (assembled) state of the cube.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 魔方的初始（已组装）状态实例。
- en: The predicate function to check that a particular state represents the assembled
    cube. For 3 × 3 cubes, this might look like an overhead, as we possibly could
    just compare this with the initial state passed in the initial_state argument,
    but cubes of size 2 × 2 and 4 × 4, for instance, might have multiple final states,
    so a separate predicate is needed to cover such cases.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查特定状态是否表示已组装魔方的谓词函数。对于3×3魔方来说，这可能是多余的，因为我们可以直接将其与传递给`initial_state`参数的初始状态进行比较；但对于2×2和4×4等魔方，可能有多个最终状态，因此需要单独的谓词函数来处理这种情况。
- en: The enumeration of actions that we can apply to the state.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以应用于状态的动作枚举。
- en: The transformation function, which takes the state and the action and returns
    the resulting state.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转换函数，接受状态和动作，并返回结果状态。
- en: The inverse function, which maps every action into its inverse.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逆函数，将每个动作映射到其逆操作。
- en: The render function to represent the state in human-readable form.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 渲染函数，用于以人类可读的形式表示状态。
- en: The shape of the encoded state tensor.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码状态张量的形状。
- en: The function to encode the compact state representation into an NN-friendly
    form.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将紧凑状态表示编码为适合神经网络的形式的函数。
- en: '[PRE4]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As you can see, cube environments are not compatible with the Gym API; I used
    this example intentionally to illustrate how you can step beyond Gym.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，魔方环境与Gym API不兼容；我故意使用这个例子来说明如何超越Gym的限制。
- en: 'Some of the methods in the CubeEnv API are just wrappers around functions passed
    to the constructor. This allows the new environment to be implemented in a separate
    module, register itself in the environment registry, and provide a consistent
    interface to the rest of the code:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: CubeEnv API中的一些方法仅仅是构造函数传递的函数的包装器。这允许新的环境在一个单独的模块中实现，注册到环境注册表中，并为其余代码提供一致的接口：
- en: '[PRE5]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: All the other methods in the class provide extended uniform functionality based
    on those primitive operations.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 类中的所有其他方法提供基于这些原始操作的扩展统一功能。
- en: 'The sample_action() method provides the functionality of randomly sampling
    the random action. If the prev_action argument is passed, we exclude the reverse
    action from possible results, which is handy to avoid a generation of short loops,
    like R →r or L →l, for example:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 方法`sample_action()`提供了随机选择一个动作的功能。如果传递了`prev_action`参数，我们会排除逆向动作，从而避免生成短循环，例如R
    →r或L →l：
- en: '[PRE6]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The method scramble() applies the list of actions (passed as an argument) to
    the initial state of the cube, returning the final state:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 方法`scramble()`将一系列动作（作为参数传递）应用于魔方的初始状态，并返回最终状态：
- en: '[PRE7]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The method scramble_cube() provides the functionality of randomly scrambling
    the cube, returning all the intermediate states. In the case of the return_inverse
    argument being False, the function returns the list of tuples with (depth, state)
    for every step of the scrambling process. If the argument is True, it returns
    a tuple with three values: (depth, state, inv_action), which are needed in some
    situations:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 方法`scramble_cube()`提供了随机打乱魔方的功能，并返回所有中间状态。如果`return_inverse`参数为False，函数返回包含每一步打乱过程的(depth,
    state)元组列表。如果参数为True，它返回一个包含三个值的元组：(depth, state, inv_action)，这些值在某些情况下是必需的：
- en: '[PRE8]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The method explore_states() implements functionality for ADI and applies all
    the possible actions to the given cube state. The result is a tuple of lists in
    which the first list contains the expanded states, and the second has flags of
    those states as the goal state:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 方法`explore_states()`实现了ADI的功能，并对给定的魔方状态应用所有可能的动作。返回值是一个元组，其中第一个列表包含扩展状态，第二个列表包含标记这些状态是否为目标状态的标志：
- en: '[PRE9]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'With this generic functionality, a similar environment might be implemented
    and plugged into the existing training and testing methods with very little boilerplate
    code. As an example, I have provided both the 2 × 2 × 2 cube and the 3 × 3 × 3
    cube that I used in my experiments. Their internals reside in libcube/cubes/cube2x2.py
    and libcube/cubes/cube3x3.py, which you can use as a base to implement your own
    environments of this kind. Every environment needs to register itself by creating
    the instance of the CubeEnv class and passing the instance into the function register(),
    defined in libcube/cubes/_env.py. The following is the relevant piece of code
    from the cube2x2.py module:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种通用功能，类似的环境可以被实现并轻松地插入到现有的训练和测试方法中，只需要非常少的样板代码。作为示例，我提供了我在实验中使用的 2 × 2 ×
    2 立方体和 3 × 3 × 3 立方体。它们的内部实现位于 libcube/cubes/cube2x2.py 和 libcube/cubes/cube3x3.py，你可以将它们作为基础来实现你自己的此类环境。每个环境需要通过创建
    CubeEnv 类的实例并将该实例传递给 libcube/cubes/_env.py 中定义的 register() 函数来注册自己。以下是来自 cube2x2.py
    模块的相关代码：
- en: '[PRE10]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Once this is done, the cube environment can be obtained by using the libcube.cubes.get()
    method, which takes the environment name as an argument. The rest of the code
    uses only the public interface of the CubeEnv class, which makes the code cube-type
    agnostic and simplifies the extensibility.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此步骤后，可以通过使用 `libcube.cubes.get()` 方法来获取立方体环境，该方法以环境名称作为参数。其余的代码仅使用 CubeEnv
    类的公共接口，这使得代码与立方体类型无关，并简化了可扩展性。
- en: Training
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练
- en: 'The training process is implemented in the tool train.py and the module libcube/model.py,
    and it is a straightforward implementation of the training process described in
    the paper, with one difference: the code supports two methods of calculating the
    target values for the value head of the network. One of the methods is exactly
    how it was described in the paper and the other is my modification, which I’ll
    explain in detail in the subsequent section.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程在工具 train.py 和模块 libcube/model.py 中实现，它是对论文中描述的训练过程的直接实现，有一个区别：该代码支持两种计算网络值头目标值的方法。方法之一与论文中描述的完全相同，另一种是我的修改，我将在后续部分详细解释。
- en: 'To simplify the experimentation and make the results reproducible, all the
    parameters of the training are specified in a separate .ini file, which gives
    the following options for training:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化实验并使结果可复现，所有训练的参数都在单独的 .ini 文件中指定，该文件提供了以下训练选项：
- en: The name of the environment to be used; currently, cube2x2 and cube3x3 are available.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将要使用的环境名称；目前，cube2x2 和 cube3x3 可用。
- en: The name of the run, which is used in TensorBoard names and directories to save
    models.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行的名称，在 TensorBoard 名称和目录中用于保存模型。
- en: 'What target value calculation method in ADI will be used. I implemented two
    of them: one is described in the paper and then there is my modification, which,
    from my experiments, has more stable convergence.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 ADI 中将使用哪种目标值计算方法。我实现了两种方法：一种是论文中描述的，另一种是我的修改方法，从我的实验来看，这种方法具有更稳定的收敛性。
- en: 'The training parameters: the batch size, the usage of CUDA, the learning rate,
    the learning rate decay, and others.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练参数：批量大小、CUDA 使用、学习率、学习率衰减等。
- en: You can find the examples of my experiments in the ini folder in the repo. During
    the training, TensorBoard metrics of the parameters are written in the runs folder.
    Models with the best loss value are saved in the saves directory.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在仓库的 ini 文件夹中找到我的实验示例。在训练过程中，参数的 TensorBoard 指标会被写入 runs 文件夹。具有最佳损失值的模型会保存在
    saves 目录中。
- en: 'To give you an idea of what the configuration file looks like, the following
    is ini/cube2x2-paper-d200.ini, which defines the experiment for a 2 × 2 cube,
    using the value calculation method from the paper and a scramble depth of 200:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让你了解配置文件的样子，以下是 ini/cube2x2-paper-d200.ini，它定义了一个使用论文中的值计算方法和 200 步混合的 2 ×
    2 立方体实验：
- en: '[PRE11]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To start the training, you need to pass the .ini file to the train.py utility;
    for example, this is how the preceding .ini file could be used to train the model:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始训练，你需要将 .ini 文件传递给 train.py 工具；例如，以下是如何使用前述 .ini 文件来训练模型：
- en: '[PRE12]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The extra argument -n gives the name of the run, which will be combined with
    the name in the .ini file to be used as the name of a TensorBoard series.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 额外的参数 -n 用于指定运行的名称，该名称将与 .ini 文件中的名称结合，作为 TensorBoard 系列的名称。
- en: The search process
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 搜索过程
- en: The result of the training is a model file with the network’s weights. The file
    could be used to solve cubes using MCTS, which is implemented in the tool solver.py
    and the module libcube/mcts.py.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的结果是一个包含网络权重的模型文件。该文件可以用于使用 MCTS 求解魔方，MCTS 实现位于工具 solver.py 和模块 libcube/mcts.py
    中。
- en: 'The solver tool is quite flexible and could be used in various modes:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 求解工具非常灵活，可以在多种模式下使用：
- en: To solve a single scrambled cube given as a comma-separated list of action indices,
    passed in the -p option. For example, -p 1,6,1 is a cube scrambled by applying
    the second action, then the seventh action, and finally, the second action again.
    The concrete meaning of the actions is environment-specific, which is passed with
    the -e option. You can find actions with their indices in the cube environment
    module. For example, the actions 1,6,1 for a 2×2 cube mean an L →R′→L transformation.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过传递 -p 选项来解决给定的一个打乱的魔方，作为逗号分隔的动作索引列表。例如，-p 1,6,1 表示通过应用第二个动作、然后第七个动作，最后再次应用第二个动作来打乱魔方。动作的具体含义依赖于环境，通过
    -e 选项传递。你可以在魔方环境模块中找到动作及其索引。例如，2×2 魔方上，动作 1,6,1 表示 L → R′ → L 的变换。
- en: To read permutations from a text file (one cube per line) and solve them. The
    file name is passed with the -i option. There are several sample problems available
    in the folder cubes_tests. You can generate your own random problem sets using
    the gen_cubes.py tool, which allows you to set the random seed, the depth of the
    scramble, and other options.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从文本文件中读取排列（每行一个魔方），并解决它们。文件名通过 -i 选项传递。文件夹 cubes_tests 中有几个示例问题。你可以使用 gen_cubes.py
    工具生成自己的随机问题集，该工具允许你设置随机种子、打乱深度以及其他选项。
- en: To generate a random scramble of the given depth and solve it.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成一个随机的打乱，给定的深度并解决它。
- en: To run a series of tests with increasing complexity (scramble depth), solve
    them, and write a CSV file with the result. This mode is enabled by passing the
    -o option and is very useful for evaluating the quality of the trained model,
    but it can take lots of time to complete. Optionally, plots with those test results
    are produced.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过增加复杂度（打乱深度）运行一系列测试，解决问题，并写入包含结果的CSV文件。通过传递 -o 选项启用此模式，它对于评估训练模型的质量非常有用，但完成这些操作可能需要大量时间。可选地，可以生成带有这些测试结果的图表。
- en: In all cases, you need to pass the environment name with the -e option and the
    file with the model’s weights (the -m option). In addition, there are other parameters,
    allowing you to tweak MCTS options and time or search step limits. You can find
    the names of those options in the code of solver.py.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有情况下，你需要通过 -e 选项传递环境名称，并通过 -m 选项传递模型的权重文件。此外，还有其他参数，允许你调整 MCTS 选项以及时间或搜索步数的限制。你可以在
    solver.py 的代码中找到这些选项的名称。
- en: The experiment results
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实验结果
- en: 'Unfortunately, the paper provided no details about very important aspects of
    the method, like training hyperparameters, how deeply cubes were scrambled during
    the training, and the obtained convergence. To fill in the missing blanks, I experimented
    with various values of hyperparameters (.ini files are available in the GitHub
    repo), but still my results are very different from those published in the paper.
    I observed that the training convergence of the original method is very unstable.
    Even with a small learning rate and a large batch size, the training eventually
    diverges, with the value loss component growing exponentially. Examples of this
    behavior are shown in Figure [21.5](#x1-406002r5) and Figure [21.6](#x1-406003r6)
    (obtained from the 2 × 2 environment):'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，论文没有提供关于该方法的许多重要细节，如训练超参数、训练过程中魔方被打乱的深度以及获得的收敛性。为了填补这些空白，我尝试了不同的超参数值（.ini
    文件可在 GitHub 仓库中找到），但我的结果与论文中发布的结果差异很大。我观察到，原始方法的训练收敛性非常不稳定。即使使用较小的学习率和较大的批量大小，训练最终仍会发散，值损失成分会呈指数增长。图[21.5](#x1-406002r5)和图[21.6](#x1-406003r6)展示了这种行为的例子（来自2×2环境）：
- en: '![PIC](img/B22150_21_05.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22150_21_05.png)'
- en: 'Figure 21.5: Values predicted by the value head during training on the paper’s
    method'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 图21.5：在论文方法训练期间，值头预测的值
- en: '![PIC](img/B22150_21_06.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22150_21_06.png)'
- en: 'Figure 21.6: The policy loss (left) and value loss (right) during the typical
    run of the paper’s method'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图21.6：论文方法典型运行中的策略损失（左）和值损失（右）
- en: 'After several experiments with this problem, I came to the conclusion that
    this behavior is a result of the wrong value objective being proposed in the method.
    Indeed, in the formula y[v[i]] = max[a](v[s](a) + R(A(s,a))), the value v[s](a)
    returned by the network is always added to the actual reward, R(s), even for the
    goal state. With this, the actual values returned by the network could be anything:
    −100, 10⁶, or 3.1415\. This is not a great situation for NN training, especially
    with the mean squared error (MSE) objective.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行多次实验后，我得出结论，这种行为是由于方法中提出了错误的值目标。实际上，在公式 `y[v[i]] = max[a](v[s](a) + R(A(s,a)))`
    中，网络返回的值 `v[s](a)` 总是加到实际奖励 `R(s)` 上，即使是目标状态。这样，网络返回的实际值可能是任何值：−100、10⁶，或者 3.1415。这对于神经网络训练来说并不是一个理想的情况，尤其是当使用均方误差（MSE）目标时。
- en: 'To check this, I modified the method of the target value calculation by assigning
    a 0 target for the goal state:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查这一点，我通过为目标状态分配一个0目标，修改了目标值计算的方法：
- en: '![π (a |s) = P[At = a|St = s] ](img/eq77.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![π (a |s) = P[At = a|St = s] ](img/eq77.png)'
- en: This target could be enabled in the .ini file by specifying the parameter value_targets_method
    to be zero_goal_value, instead of the default value_targets_method=paper.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过在 .ini 文件中指定参数 `value_targets_method` 为 `zero_goal_value` 来启用这个目标，而不是默认的
    `value_targets_method=paper`。
- en: 'With this simple modification, the training process converged much quicker
    to stable values returned by the value head of the network. An example of this
    convergence is shown in Figure [21.7](#x1-406006r7) and Figure [21.8](#x1-406007r8):'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个简单的修改，训练过程更快地收敛到了网络值头返回的稳定值。这种收敛的一个例子展示在图[21.7](#x1-406006r7)和图[21.8](#x1-406007r8)中：
- en: '![PIC](img/B22150_21_07.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/B22150_21_07.png)'
- en: 'Figure 21.7: Values predicted by the value head during training'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图 21.7：训练期间值头预测的值
- en: '![PIC](img/B22150_21_08.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/B22150_21_08.png)'
- en: 'Figure 21.8: The policy loss (left) and value loss (right) after modifications
    in value calculation'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 21.8：修改值计算后，策略损失（左）和值损失（右）
- en: The 2 × 2 cube
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 × 2 立方体
- en: In the paper, the authors reported training for 44 hours on a machine with three
    Titan Xp GPUs. During the training, their model saw 8 billion cube states. Those
    numbers correspond to the training speed  50,000 cubes/second. My implementation
    shows 15,000 cubes/second on a single GTX 1080 Ti, which is comparable. So, to
    repeat the training process on a single GPU, we need to wait for almost six days,
    which is not very practical for experimentation and hyperparameter tuning.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文中，作者报告了在一台配有三块Titan Xp GPU的机器上训练了44小时。在训练过程中，他们的模型查看了80亿个立方体状态。这些数字对应于训练速度
    50,000 立方体/秒。我的实现使用单个GTX 1080 Ti显示为15,000 立方体/秒，速度相当。因此，要在单个GPU上重复训练过程，我们需要等待近六天，这对于实验和超参数调优来说并不实用。
- en: 'To overcome this, I implemented a much simpler 2 × 2 cube environment, which
    takes just an hour or two to train. To reproduce my training, there are two .ini
    files in the repo:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这一点，我实现了一个简单得多的2 × 2立方体环境，训练只需要一两个小时。为了重现我的训练，仓库中有两个 .ini 文件：
- en: 'ini/cube2x2-paper-d200.ini: This uses the value target method described in
    the paper'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ini/cube2x2-paper-d200.ini：使用了论文中描述的值目标方法
- en: 'ini/cube2x2-zero-goal-d200.ini: The value target is set to 0 for goal states'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ini/cube2x2-zero-goal-d200.ini: 目标值被设置为0，用于目标状态'
- en: 'Both configurations use batches of 10k states and a scramble depth of 200,
    and the training parameters are the same. After the training, using both configurations,
    two models were produced:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 两种配置都使用了10k状态的批次和200的打乱深度，训练参数相同。训练结束后，使用这两种配置分别生成了两个模型：
- en: 'The paper’s method: loss 0.032572'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 论文方法：损失 0.032572
- en: 'The zero-goal method: loss 0.012226'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零目标方法：损失 0.012226
- en: To perform a fair comparison, I generated 20 test scrambles for depths 1…50
    (1,000 test cubes in total), which are available in cubes_test/3ed, and ran the
    solver.py utility on the best model produced by each method. For every test scramble,
    the limit for searches was set to 30,000\. This utility produced CSV files (available
    in csvs/3ed) with details about every test outcome.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行公平的比较，我为深度 1…50（共1000个测试立方体）生成了20个测试打乱，保存在 `cubes_test/3ed` 中，并在每种方法生成的最佳模型上运行了
    `solver.py` 工具。对于每个测试打乱，搜索的限制被设置为30,000。该工具生成了CSV文件（保存在 `csvs/3ed` 中），其中包含每个测试结果的详细信息。
- en: My experiments have shown that the model described in the paper was able to
    solve 55% of test cubes, while the model with zero-goal modification solved 100%.
    The results for both models depending on scramble depth are shown in Figure [21.9](#x1-407004r9).
    On the left plot, the ratio of solved cubes is shown. On the right plot, the average
    MCTS search steps per scramble depth are displayed. As you can see, the modified
    version requires significantly (3x-5x) fewer MCTS searches to find a solution,
    so the learned policy is better.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我的实验表明，论文中描述的模型能够解决55%的测试魔方，而带零目标修改的模型解决了100%。两种模型在不同混乱深度下的结果如图[21.9](#x1-407004r9)所示。在左图中，显示了解决魔方的比例。在右图中，显示了每个混乱深度所需的平均MCTS搜索步数。正如你所见，修改版本在找到解时需要显著（3倍至5倍）更少的MCTS搜索次数，因此学到的策略更好。
- en: '![PIC](img/B22150_21_09.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/B22150_21_09.png)'
- en: 'Figure 21.9: The ratio of solved 2 × 2 cubes (left) and average count of MCTS
    searches needed for various scramble depths'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图21.9：已解2 × 2魔方的比例（左）和不同混乱深度下需要的平均MCTS搜索次数
- en: Finally, let’s check the length of the found solutions. In Figure [21.10](#x1-407005r10),
    both the naïve and BFS solution lengths are plotted. From those plots, it can
    be seen that the naïve solutions are much longer (by a factor of 10) than solutions
    found by BFS. Such a difference might be an indication of untuned MCTS parameters,
    which could be improved. In naïve solutions, the zero goal finds shorter solutions
    (which might again be an indication of a better policy).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们检查一下找到的解的长度。在图[21.10](#x1-407005r10)中，绘制了天真的方法和BFS解的长度。从这些图中可以看出，天真的解比BFS找到的解长得多（长了10倍）。这样的差异可能是未调优MCTS参数的迹象，这些参数是可以改进的。在天真的解中，零目标找到的解更短（这可能再次表明一个更好的策略）。
- en: '![PIC](img/B22150_21_10.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/B22150_21_10.png)'
- en: 'Figure 21.10: A comparison of naïve (left) and BFS (right) ways of solution
    generation'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 图21.10：天真方法（左）和BFS方法（右）生成解法的比较
- en: The 3 × 3 cube
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 × 3魔方
- en: The training of the 3 × 3 cube model is much more heavy; we’ve just scratched
    the surface here. But my limited experiments show that zero-goal modifications
    to the training method greatly improve the training stability and resulting model
    quality. Training requires about 20 hours, so running lots of experiments requires
    time and patience.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 3 × 3魔方模型的训练要重得多；我们这里仅仅是刚刚触及表面。但我有限的实验表明，零目标修改训练方法大大提高了训练稳定性和最终模型质量。训练大约需要20小时，因此进行大量实验需要时间和耐心。
- en: 'My results are not as shiny as those reported in the paper: the best model
    I was able to obtain can solve cubes up to a scrambling depth of 12…15, but consistently
    fails at more complicated problems. Probably, those numbers could be improved
    with more central processing unit (CPU) cores plus parallel MCTS. To get the data,
    the search process was limited to 100k steps and, for every scramble depth, five
    random scrambles were generated (available in cubes_tests/3ed in the repo). But
    again, the modified version shows better results – the model trained using the
    paper’s method was able to solve only problems with a scramble depth of 9, but
    the modified version was able to reach a depth of 13.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我的结果没有论文中报告的那样亮眼：我能够获得的最佳模型可以解决最多**12…15**深度的魔方混乱问题，但在更复杂的问题上总是失败。可能，利用更多的中央处理单元（CPU）核心和并行MCTS，这些数字可以得到改进。为了获取数据，搜索过程限制为100k步，并且每个混乱深度生成了五个随机混乱（可在repo中的cubes_tests/3ed找到）。但再次强调，修改版本显示出了更好的结果——使用论文方法训练的模型只能解决混乱深度为9的问题，而修改版本能够达到13的深度。
- en: Figure [21.11](#x1-408004r11) shows a comparison of solution rates (left plot)
    for the method presented in the paper and the modified version with the zero-value
    target. On the right part of the figure, the average number of MCTS searches is
    shown.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图[21.11](#x1-408004r11)显示了论文中提出的方法和带零值目标的修改版本的解法率比较（左图）。图的右侧显示了平均MCTS搜索次数。
- en: '![PIC](img/B22150_21_11.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/B22150_21_11.png)'
- en: 'Figure 21.11: The ratio of solved 3 × 3 cubes by both methods (left) and the
    average number of MCTS searches'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图21.11：两种方法解决的3 × 3魔方比例（左）和平均MCTS搜索次数
- en: 'Figure [21.12](#x1-408006r12) shows the length of the optimal solution found.
    As before, naïve search produces longer results than the BFS-optimized one. The
    BFS length almost perfectly aligned with the scramble depth:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图[21.12](#x1-408006r12)显示了找到的最优解的长度。如前所述，天真搜索产生的解比BFS优化后的解长。BFS的解长几乎完美地与混乱深度对齐：
- en: '![PIC](img/B22150_21_12.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/B22150_21_12.png)'
- en: 'Figure 21.12: A comparison of naïve (left) and BFS (right) solution lengths
    for 3 × 3 cube'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图 21.12：3 × 3 魔方的朴素（左）与广度优先搜索（右）解法长度对比
- en: In theory, after a depth of 20, it should saturate (because “the God number”
    is 20), but my version wasn’t able to solve any cubes with a scramble longer than
    13, so it is hard to tell.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，在深度达到 20 后，它应该会饱和（因为“神数”是 20），但我的版本无法解决任何打乱深度超过 13 的魔方，因此很难判断。
- en: Further improvements and experiments
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步的改进和实验
- en: 'There are lots of directions and things that could be tried:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方向和方法可以尝试：
- en: 'More input and network engineering: The cube is a complicated thing, so simple
    feed-forward NNs may not be the best model. Probably, the network could greatly
    benefit from convolutions.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多输入和网络工程：魔方是一个复杂的物体，因此简单的前馈神经网络可能不是最佳模型。可能，网络可以从卷积中大大受益。
- en: Oscillations and instability during training might be a sign of a common RL
    issue with inter-step correlations. The usual approach is the target network,
    when we use the old version of the network to get bootstrapped values.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练中的振荡和不稳定性可能是强化学习中常见的步骤间相关性问题的信号。通常的方法是目标网络，我们使用旧版本的网络来获取自举值。
- en: The priority replay buffer might help the training speed.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优先重放缓冲区可能有助于提高训练速度。
- en: My experiments show that the samples’ weighting (inversely proportional to the
    scramble depth) helps to get a better policy that knows how to solve slightly
    scrambled cubes, but might slow down the learning of deeper states. Probably,
    this weighting could be made adaptive to make it less aggressive in later training
    stages.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我的实验显示，样本的加权（与打乱深度成反比）有助于获得一个更好的策略，能够解决稍微打乱的魔方，但可能会减慢对更深状态的学习。可能，随着训练的进行，这种加权可以做成自适应的，使得它在后期训练阶段不那么激进。
- en: Entropy loss could be added to the training to regularize our policy.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以将熵损失加入训练中，以规范化我们的策略。
- en: The 2×2 cube model doesn’t take into account the fact that the cube doesn’t
    have central cubelets, so the whole cube could be rotated. This might not be very
    important for a 2 × 2 cube, as the state space is small, but the same observation
    will be critical for 4 × 4 cubes.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2×2 立方体模型没有考虑到立方体没有中央小方块这一事实，因此整个立方体可以旋转。对于 2 × 2 立方体来说，这可能并不十分重要，因为状态空间较小，但对于
    4 × 4 立方体来说，相同的观察将变得至关重要。
- en: More experiments are needed to get better training and MCTS parameters.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要更多实验以获得更好的训练和蒙特卡罗树搜索（MCTS）参数。
- en: Summary
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed discrete optimization problems – a subfield of
    the optimization domain that deals with discrete structures like graphs or sets.
    We checked RL’s applicability using the Rubik’s cube as a well-known, but still
    challenging, problem. But in general, this topic is much wider than just puzzles
    – the same methods could be used in optimizing schedules, optimal route planning,
    and other practical topics.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们讨论了离散优化问题——优化领域的一个子领域，处理像图或集合这样的离散结构。我们通过使用魔方这一众所周知但仍具挑战性的问题来检验强化学习的适用性。但总体来说，这一话题远比拼图问题广泛——同样的方法可以用于优化日程安排、最优路径规划和其他实际问题。
- en: In the final chapter of the book, we will talk about multi-agent problems in
    RL.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的最后一章，我们将讨论强化学习中的多智能体问题。
