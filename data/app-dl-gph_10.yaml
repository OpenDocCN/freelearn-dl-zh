- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Graph Deep Learning for Computer Vision
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉中的图深度学习
- en: '**Computer vision** ( **CV** ) has traditionally relied on grid-based representations
    of images and videos, which have been highly successful with **convolutional neural
    networks** ( **CNNs** ). However, many visual scenes and objects have inherent
    relational and structural properties that aren’t easily captured by grid-based
    approaches. This is where graph representations come into play, offering a more
    flexible and expressive way to model visual data.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**计算机视觉**（**CV**）传统上依赖于基于网格的图像和视频表示，这些表示与**卷积神经网络**（**CNNs**）结合取得了很大的成功。然而，许多视觉场景和物体具有固有的关系和结构属性，这些属性不能轻易通过基于网格的方法来捕捉。这正是图表示发挥作用的地方，它提供了一种更灵活、更具表现力的方式来建模视觉数据。'
- en: Graphs can naturally represent relationships between objects in a scene, hierarchical
    structures in images, non-grid data such as 3D point clouds, and long-range dependencies
    in videos. For example, in a street scene, a graph can represent cars, pedestrians,
    and traffic lights as nodes, with edges representing their spatial relationships
    or interactions. This representation captures the scene’s structure more intuitively
    than a pixel grid.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图可以自然地表示场景中物体之间的关系、图像中的层次结构、非网格数据（如3D点云）以及视频中的长程依赖关系。例如，在街道场景中，图可以将汽车、行人和交通灯表示为节点，边表示它们的空间关系或相互作用。这种表示方式比像素网格更直观地捕捉了场景的结构。
- en: 'In this chapter, we’ll elaborate on the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将详细讨论以下主题：
- en: Traditional CV approaches versus graph-based approaches
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传统的计算机视觉方法与基于图的方法
- en: Graph construction for visual data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视觉数据的图构建
- en: '**Graph neural networks** ( **GNNs** ) for image classification'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图神经网络**（**GNNs**）用于图像分类'
- en: Object detection and segmentation using GNNs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用图神经网络（GNN）进行物体检测与分割
- en: Multi-modal learning with GNNs
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GNN进行多模态学习
- en: Limitations and next steps
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制与下一步发展
- en: Traditional CV approaches versus graph-based approaches
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传统的计算机视觉方法与基于图的方法
- en: Traditional CV approaches primarily rely on CNNs that operate on regular grid
    structures, extracting features through convolution and pooling operations. While
    effective for many tasks, these methods often struggle with long-range dependencies
    and relational reasoning. In contrast, graph-based approaches represent visual
    data as nodes and edges, utilizing GNNs to process information. This structure
    allows for easier incorporation of non-local information and relational inductive
    biases.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的计算机视觉方法主要依赖于CNN，它们在规则网格结构上进行操作，通过卷积和池化操作提取特征。尽管在许多任务中效果显著，但这些方法通常在处理长程依赖关系和关系推理时遇到困难。相比之下，基于图的方法将视觉数据表示为节点和边，利用GNNs处理信息。这种结构使得更容易融入非局部信息和关系性归纳偏置。
- en: For instance, in image classification, a CNN might have difficulty relating
    distant parts of an image, whereas a graph-based approach could represent different
    image regions as *nodes* and their relationships as *edges* , facilitating long-range
    reasoning. This fundamental difference in data representation and processing enables
    graph-based methods to overcome some of the limitations inherent in traditional
    CNN-based approaches, potentially leading to improved performance in tasks that
    require understanding complex spatial relationships or global context within visual
    data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在图像分类中，CNN可能很难关联图像中遥远部分的关系，而基于图的方法可以将不同的图像区域表示为*节点*，它们之间的关系表示为*边*，从而促进长程推理。这种数据表示和处理的根本差异使得基于图的方法能够克服传统基于CNN的方法中固有的一些限制，可能在需要理解复杂空间关系或全局上下文的视觉数据任务中提高性能。
- en: 'The advantages of graph representations for visual data are as follows:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图表示在视觉数据中的优势如下：
- en: '**Flexibility** : Graphs can represent various types of visual data, from pixels
    to objects to entire scenes.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活性** ：图可以表示各种类型的视觉数据，从像素到物体，再到整个场景。'
- en: '**Relational reasoning** : Graphs explicitly model relationships, making it
    easier to reason about object interactions.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关系推理** ：图显式地建模关系，使得推理物体之间的相互作用变得更加容易。'
- en: '**Incorporating prior knowledge** : Domain knowledge can be easily encoded
    in the graph structure.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**融入先验知识** ：领域知识可以轻松地编码进图结构中。'
- en: '**Handling irregular data** : Graphs are well suited for non-grid data such
    as 3D point clouds or social network images.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理不规则数据** ：图特别适合处理如3D点云或社交网络图像等非网格数据。'
- en: '**Interpretability** : Graph structures often align more closely with human
    understanding of visual scenes.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性**：图结构通常与人类对视觉场景的理解更为一致。'
- en: For instance, in a face recognition task, a graph-based approach might represent
    facial landmarks (specific points on a face that correspond to key facial features
    such as the corners of the eyes, the tip of the nose, the edges of the mouth,
    and so on) as *nodes* and their geometric relationships as *edges* . This representation
    can be more robust to variations in pose and expression compared to grid-based
    approaches.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在面部识别任务中，基于图的方法可能将面部标志（面部上的特定点，通常对应眼角、鼻尖、嘴角等关键面部特征）表示为*节点*，它们的几何关系则表示为*边*。与基于网格的方法相比，这种表示对姿势和表情的变化更具鲁棒性。
- en: 'Here’s a simple example of constructing a face graph:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是构建面部图的一个简单示例：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This graph representation captures the spatial relationships between facial
    features, which can be leveraged by GNNs for tasks such as face recognition or
    emotion detection. Now, let’s jump into the concepts of constructing graphs specifically
    for image data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图形表示法捕捉了面部特征之间的空间关系，图神经网络（GNNs）可以利用这些关系执行面部识别或情感检测等任务。现在，让我们深入探讨如何专门为图像数据构建图。
- en: Graph construction for visual data
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视觉数据的图构建
- en: Constructing graphs from visual data is a crucial step in applying graph-based
    methods to CV tasks. The choice of graph construction method can significantly
    impact the performance and interpretability of downstream tasks. This section
    explores various approaches to graph construction, each suited to different types
    of visual data and problem domains.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 从视觉数据构建图是将基于图的方法应用于计算机视觉（CV）任务的关键步骤。图的构建方法选择会显著影响下游任务的性能和可解释性。本节将探讨多种图构建方法，每种方法都适用于不同类型的视觉数据和问题领域。
- en: Pixel-level graphs
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 像素级图
- en: '**Pixel-level graphs** represent images at their most granular level, with
    each pixel serving as a *node* in the graph. *Edges* are typically formed between
    neighboring pixels, creating a grid-like structure that mirrors the original image.
    This approach preserves fine-grained spatial information but can lead to large,
    computationally expensive graphs for high-resolution images.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**像素级图**以最细粒度的方式表示图像，每个像素作为图中的一个*节点*。*边*通常形成在相邻的像素之间，创建出一种类似于网格的结构，反映了原始图像。这种方法保留了细粒度的空间信息，但对于高分辨率图像，可能会导致大型且计算量大的图。'
- en: For example, in a 100x100 pixel image, we would create a graph with 10,000 nodes.
    Each node might be connected to its four or eight nearest neighbors, depending
    on whether we consider diagonal connections. The node features could include color
    information (RGB values) and pixel coordinates. This type of graph is particularly
    useful for tasks that require precise spatial information, such as image segmentation
    or edge detection.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在一张100x100像素的图像中，我们将创建一个拥有10,000个节点的图。每个节点可能与其四个或八个最近的邻居相连，具体取决于是否考虑对角线连接。节点特征可能包括颜色信息（RGB值）和像素坐标。这种类型的图特别适用于需要精确空间信息的任务，如图像分割或边缘检测。
- en: 'Here’s a simple example of how you might construct a pixel-level graph using
    **NetworkX** :'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个如何使用**NetworkX**构建像素级图的简单示例：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This function creates a graph representation of an image, where each pixel is
    a node and edges connect neighboring pixels based on the specified connectivity
    ( **4** or **8** ).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数创建了一个图像的图表示，其中每个像素都是一个节点，边根据指定的连通性（**4**或**8**）连接相邻像素。
- en: 'Let’s call the function:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们调用这个函数：
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Superpixel-based graphs
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于超像素的图
- en: '**Superpixel-based graphs** offer a middle ground between pixel-level and object-level
    representations. Superpixels are groups of pixels that share similar characteristics,
    often created through image segmentation algorithms such as **simple linear iterative
    clustering** ( **SLIC** ). In a superpixel graph, each *node* represents a superpixel,
    and *edges* connect adjacent superpixels.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于超像素的图**提供了一种介于像素级表示和对象级表示之间的中间方式。超像素是具有相似特征的像素群，通常通过图像分割算法（如**简单线性迭代聚类**（**SLIC**））创建。在超像素图中，每个*节点*代表一个超像素，*边*则连接相邻的超像素。'
- en: This approach reduces the graph size compared to pixel-level graphs while still
    maintaining local image structure. For instance, a 1,000x1,000-pixel image might
    be reduced to a graph of 1,000 superpixels, each representing an average of 1,000
    pixels. Node features could include average color, texture information, and the
    spatial location of the superpixel.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法减少了与像素级图相比的图大小，同时仍保持局部图像结构。例如，一张1,000x1,000像素的图像可能会缩减为一个包含1,000个超像素的图，每个超像素代表平均1,000个像素。节点特征可能包括平均颜色、纹理信息和超像素的空间位置。
- en: Superpixel graphs are particularly effective for tasks such as semantic segmentation
    or object proposal generation. They capture local consistency in the image while
    reducing computational complexity. For example, in a scene understanding task,
    superpixels might naturally group pixels belonging to the same object or surface,
    simplifying the subsequent analysis.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 超像素图对于语义分割或对象提议生成等任务特别有效。它们在图像中捕捉局部一致性，同时减少计算复杂性。例如，在场景理解任务中，超像素可能自然地将属于同一对象或表面的像素分组，从而简化后续的分析。
- en: Object-level graphs
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对象级图
- en: '**Object-level graphs** represent images at a higher level of abstraction,
    with *nodes* corresponding to detected objects or regions of interest. *Edges*
    in these graphs often represent relationships or interactions between objects.
    This representation is particularly useful for tasks involving scene understanding,
    visual relationship detection, or high-level reasoning about image content.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**对象级图**在更高层次的抽象上表示图像，*节点*对应于检测到的对象或感兴趣区域。图中的*边*通常表示对象之间的关系或交互。这种表示对于涉及场景理解、视觉关系检测或关于图像内容的高层推理任务特别有用。'
- en: Consider an image of a living room. An object-level graph might have *nodes*
    for “sofa,” “coffee table,” “lamp,” and “bookshelf.” *Edges* could represent spatial
    relationships (for example, “lamp on table”) or functional relationships (for
    example, “person sitting on sofa”). Node features might include object class probabilities,
    bounding box coordinates, and appearance descriptors.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 假设是一张客厅的图像。一个对象级图可能会有“沙发”、“咖啡桌”、“台灯”和“书架”等*节点*。*边*可能表示空间关系（例如，“台灯在桌子上”）或功能关系（例如，“人坐在沙发上”）。节点特征可能包括对象类别概率、边界框坐标和外观描述符。
- en: Object-level graphs are powerful for tasks that require reasoning about object
    interactions, such as visual question answering or image captioning. They allow
    the model to focus on relevant high-level information without getting bogged down
    in pixel-level details.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对象级图在需要推理对象交互的任务中非常强大，例如视觉问答或图像标注。它们允许模型集中处理相关的高层信息，而不被像素级的细节所困扰。
- en: Scene graphs
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 场景图
- en: '**Scene graphs** take object-level representations a step further by explicitly
    modeling relationships between objects as separate entities in the graph. In a
    scene graph, *nodes* typically represent objects and attributes, while *edges*
    represent relationships. This structured representation captures the semantics
    of an image in a form that’s closer to human understanding.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**场景图**通过明确地建模对象之间的关系，将对象级别的表示进一步推进，将这些关系作为图中的独立实体。在场景图中，*节点*通常表示对象和属性，而*边*表示关系。这种结构化表示捕捉了图像的语义，以一种更接近人类理解的形式。'
- en: 'For example, in an image of a park, a scene graph might have nodes for “person,”
    “dog,” “tree,” and “frisbee,” with relationship edges such as “person throwing
    frisbee” or “dog under tree.” Attributes such as “tree: green” or “frisbee: red”
    can be included as additional nodes or as node features.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在一张公园的图像中，场景图可能会有“人”、“狗”、“树”和“飞盘”等节点，关系边可能包括“人投飞盘”或“狗在树下”。属性如“树：绿色”或“飞盘：红色”可以作为额外的节点或节点特征。
- en: Scene graphs are particularly valuable for tasks that require a deep understanding
    of image content, such as image retrieval based on complex queries, or generating
    detailed image descriptions. They provide a structured representation that bridges
    the gap between visual features and semantic understanding.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 场景图对于需要深入理解图像内容的任务尤其有价值，例如基于复杂查询的图像检索或生成详细的图像描述。它们提供了一种结构化的表示，弥合了视觉特征和语义理解之间的鸿沟。
- en: Comparing different graph construction methods
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较不同的图构建方法
- en: Each graph construction method has its strengths and is suited to different
    types of CV tasks. Pixel-level graphs preserve fine-grained information but can
    be computationally expensive. Superpixel graphs offer a good balance between detail
    and efficiency. Object-level and scene graphs capture high-level semantics but
    may miss fine-grained details.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 每种图构建方法都有其优点，适用于不同类型的计算机视觉任务。像素级图保留了细粒度的信息，但计算开销较大。超像素图在细节和效率之间提供了良好的平衡。对象级图和场景图捕捉了高级语义，但可能会错失细粒度的细节。
- en: The choice of graph construction method depends on the specific task, computational
    resources, and the level of abstraction required. For instance, image denoising
    might benefit from pixel-level graphs, while visual relationship detection would
    be better served by object-level or scene graphs.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图构建方法的选择取决于具体任务、计算资源和所需的抽象层次。例如，图像去噪可能受益于像素级图，而视觉关系检测则更适合使用对象级图或场景图。
- en: It’s also worth noting that these approaches aren’t mutually exclusive. Some
    advanced models use hierarchical graph representations that combine multiple levels
    of abstraction, allowing them to reason about both fine-grained details and high-level
    semantics simultaneously.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，这些方法并不是相互排斥的。一些高级模型使用分层图表示，结合了多个抽象层次，使其能够同时推理细粒度的细节和高级语义。
- en: The creation of graphs at different hierarchical levels (pixel, superpixel,
    and object) faces distinct challenges related to noise and data resolution. At
    the pixel level, high-frequency noise and sensor artifacts can create spurious
    connections, leading to unreliable graph structures. To address this, median filtering
    or bilateral filtering can be applied as preprocessing steps to preserve edges
    while reducing noise. Superpixel-level graphs encounter challenges with boundary
    precision and varying segment sizes, which can be mitigated through adaptive segmentation
    algorithms such as SLIC or using boundary refinement techniques.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同层次的图构建（像素、超像素和对象）中，会面临与噪声和数据分辨率相关的不同挑战。在像素层次上，高频噪声和传感器伪影可能会创建虚假的连接，导致图结构不可靠。为了解决这个问题，可以在预处理阶段应用中值滤波或双边滤波，以保留边缘同时减少噪声。超像素层次的图则面临边界精度和分割大小变化的挑战，可以通过自适应分割算法（如SLIC）或边界精细化技术来缓解这些问题。
- en: Object-level graphs face resolution-dependent issues where object boundaries
    may be ambiguous or objects may appear at different scales. This can be addressed
    through multi-scale graph construction approaches or hierarchical graph representations
    that maintain connections across different resolution levels. To handle varying
    data resolutions, adaptive graph construction methods can be employed, where edge
    weights and neighborhood sizes are dynamically adjusted based on local data characteristics.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对象级图面临分辨率相关的问题，其中对象边界可能不明确，或者对象可能出现在不同的尺度上。可以通过多尺度图构建方法或保持跨分辨率层次连接的分层图表示来解决这些问题。为了处理不同的数据分辨率，可以采用自适应图构建方法，其中边缘权重和邻域大小会根据局部数据特征动态调整。
- en: Another effective solution is to implement graph pooling strategies that aggregate
    information intelligently across different levels while preserving important structural
    relationships. Preprocessing techniques such as feature normalization and outlier
    removal can also improve graph quality. For cases with severe noise, weighted
    graph construction methods that incorporate uncertainty measures in edge weights
    have proven effective, allowing the model to learn more robust representations
    despite data imperfections.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种有效的解决方案是实现图池化策略，智能地在不同层次之间聚合信息，同时保持重要的结构关系。特征归一化和异常值去除等预处理技术也能提高图的质量。对于噪声严重的情况，采用加权图构建方法，通过在边缘权重中引入不确定性度量，已被证明是有效的，这使得模型能够在数据不完美的情况下学习到更强的表示。
- en: Now, let’s look at how exactly GNNs can be leveraged for image classification.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下如何具体利用GNN进行图像分类。
- en: GNNs for image classification
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于图像分类的GNN
- en: Image classification, a fundamental task in CV, has traditionally been dominated
    by CNNs. However, GNNs are emerging as a powerful alternative, offering unique
    advantages in capturing global structure and long-range dependencies. This section
    will explore how GNNs can be applied to image classification tasks while discussing
    various architectures and techniques.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类，作为计算机视觉中的一项基础任务，传统上一直由CNN主导。然而，GNN（图神经网络）正作为一种强有力的替代方案崭露头角，在捕捉全局结构和长程依赖方面具有独特优势。本节将探讨如何将GNN应用于图像分类任务，并讨论各种架构和技术。
- en: Graph convolutional networks for image data
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图卷积网络在图像数据中的应用
- en: '**Graph convolutional networks** ( **GCNs** ) form the backbone of many graph-based
    approaches to image classification. Unlike traditional CNNs that operate on regular
    grid-like structures, GCNs can work with irregular graph structures, making them
    more flexible in representing image data.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**图卷积网络**（**GCNs**）是许多基于图的方法在图像分类中的核心。与传统的CNN（卷积神经网络）在规则网格结构上操作不同，GCNs能够处理不规则的图结构，使得它们在表示图像数据时更加灵活。'
- en: To apply GCNs to images, we need to convert the image into a graph structure.
    This can be done using any of the methods discussed in the previous section, such
    as pixel-level graphs or superpixel graphs. Once we have the graph representation,
    we can apply graph convolutions to aggregate information from neighboring nodes.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将GCN应用于图像，我们需要将图像转换为图结构。这可以通过上一节讨论的任何方法来完成，例如像素级图或超像素图。一旦我们得到图的表示，就可以应用图卷积来聚合来自邻居节点的信息。
- en: For example, consider a superpixel-based graph of an image. Each node (superpixel)
    might have features such as average color, texture descriptors, and spatial information.
    A graph convolution operation would update each node’s features based on its features
    and those of its neighbors. This allows the network to capture local patterns
    and gradually build up to more global representations.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个基于超像素的图像图。每个节点（超像素）可能具有如平均颜色、纹理描述符和空间信息等特征。图卷积操作会根据节点本身的特征以及邻居节点的特征来更新每个节点的特征。这使得网络能够捕捉局部模式，并逐渐构建出更全局的表示。
- en: 'Here’s a simple example of how a graph convolution layer might be implemented
    using **PyTorch Geometric** :'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个简单的例子，展示了如何使用**PyTorch Geometric**实现一个图卷积层：
- en: '[PRE3]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In this example, the model takes node features and an edge index as input, applies
    two graph convolution layers, and outputs class probabilities for each node. The
    final classification for the entire image could be obtained by pooling over all
    node predictions.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，模型将节点特征和边缘索引作为输入，应用两个图卷积层，并输出每个节点的类别概率。整个图像的最终分类可以通过对所有节点预测结果进行池化来获得。
- en: Attention mechanisms in graph-based image classification
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于图的图像分类中的注意力机制
- en: '**Attention mechanisms** have proven highly effective in various deep learning
    tasks, and they can be particularly powerful when applied to graph-based image
    classification. **Graph attention networks** ( **GATs** ) allow the model to assign
    different levels of importance to different neighbors when aggregating information,
    potentially leading to more effective feature learning.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意力机制**在各类深度学习任务中已被证明是非常有效的，在基于图的图像分类中应用时，尤其能发挥强大作用。**图注意力网络**（**GATs**）允许模型在聚合信息时为不同的邻居分配不同的重要性，这可能导致更有效的特征学习。'
- en: In the context of image classification, attention can help the model focus on
    the most relevant parts of the image for the classification task. For instance,
    when classifying animal images, an attention mechanism might learn to focus on
    distinctive features such as the shape of the ears or the pattern of the fur,
    even if these features are spatially distant in the original image.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像分类的背景下，注意力机制可以帮助模型集中于图像中与分类任务最相关的部分。例如，在分类动物图像时，注意力机制可能会学会聚焦于耳朵的形状或毛发的图案等具有区分性的特征，即使这些特征在原始图像中空间上相距较远。
- en: Consider an object-level graph representation of an image. An attention-based
    GNN could learn to assign higher importance to edges connecting objects that frequently
    co-occur in certain image classes. For example, in classifying “kitchen” scenes,
    the model might learn to pay more attention to edges connecting “stove” and “refrigerator”
    nodes as these objects are strongly indicative of kitchen environments.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个基于对象的图表示。一个基于注意力机制的 GNN 可以学会赋予连接那些在特定图像类别中经常共同出现的物体的边更高的权重。例如，在分类“厨房”场景时，模型可能会学会更关注连接“炉灶”和“冰箱”节点的边，因为这些物体强烈表明是厨房环境。
- en: Hierarchical graph representations for multi-scale feature learning
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于多尺度特征学习的分层图表示
- en: One of the strengths of CNNs in image classification is their ability to learn
    features at multiple scales through a hierarchy of convolutions and pooling operations.
    GNNs can achieve similar multi-scale feature learning through hierarchical graph
    representations.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 在图像分类中的一个优势是它们能够通过卷积和池化操作的层次结构在多个尺度上学习特征。GNN 也可以通过分层图表示来实现类似的多尺度特征学习。
- en: A hierarchical graph approach might start with a fine-grained graph representation
    (for example, superpixel-level) and coarsen the graph progressively through pooling
    operations. Each level of the hierarchy captures features at a different scale,
    from local textures to more global shapes and arrangements.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 一个分层的图方法可能从一个细粒度的图表示（例如，超像素级别）开始，并通过池化操作逐渐粗化图。每个层级捕捉不同尺度的特征，从局部纹理到更全球的形状和排列。
- en: For example, in classifying architectural styles, the lowest level of the hierarchy
    might capture local textures (brick patterns and window shapes), the middle levels
    might represent larger structures (roof types and facade layouts), and the highest
    levels could capture overall building shapes and arrangements.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在分类建筑风格时，层次结构的最低层可能捕捉局部纹理（如砖块图案和窗户形状），中间层可能代表更大的结构（如屋顶类型和立面布局），而最高层则可能捕捉整体建筑形状和布局。
- en: 'This hierarchical approach can be implemented using graph pooling operations.
    Here’s a conceptual example of how this might look in PyTorch Geometric:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分层方法可以通过图池化操作来实现。以下是一个在 PyTorch Geometric 中如何实现这一方法的概念性示例：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this example, the model applies alternating convolution and pooling operations,
    gradually reducing the graph size and capturing features at different scales.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，模型应用了交替的卷积和池化操作，逐渐减少图的大小，并在不同尺度上捕捉特征。
- en: GNNs versus CNNs
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GNN 与 CNN
- en: While GNNs offer several advantages for image classification, it’s important
    to compare their performance with traditional CNN-based approaches. GNNs excel
    in capturing long-range dependencies and global structure, which can be beneficial
    for certain types of images and classification tasks. For instance, GNNs might
    outperform CNNs on tasks that require understanding the overall layout or relationships
    between distant parts of an image.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 GNN 在图像分类中提供了若干优势，但重要的是要与传统的基于 CNN 的方法进行比较。GNN 擅长捕捉长程依赖和全局结构，这对于某些类型的图像和分类任务是有益的。例如，GNN
    可能在需要理解图像整体布局或远距离部分之间关系的任务中优于 CNN。
- en: However, CNNs still hold advantages in their ability to capture local patterns
    efficiently and optimize for grid-like data. Many state-of-the-art approaches
    now combine elements of both GNNs and CNNs, leveraging the strengths of each.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，CNN 在高效捕捉局部模式和优化网格数据方面仍然具有优势。许多最先进的方法现在结合了 GNN 和 CNN 的元素，利用它们各自的优势。
- en: For example, you might use a CNN to extract initial features from the image,
    then construct a graph based on these features and apply GNN layers for final
    classification. This approach combines the local feature extraction capabilities
    of CNNs with the global reasoning capabilities of GNNs.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以使用 CNN 从图像中提取初始特征，然后基于这些特征构建图，并应用 GNN 层进行最终分类。这种方法将 CNN 的局部特征提取能力与 GNN
    的全局推理能力结合起来。
- en: In practice, the choice between GNN-based and CNN-based approaches (or a hybrid
    of the two) depends on the specific characteristics of the dataset and the nature
    of the classification task. Evaluating the target dataset empirically is often
    necessary to determine the most effective approach.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，基于 GNN 的方法与基于 CNN 的方法（或两者的混合）之间的选择，取决于数据集的具体特征和分类任务的性质。通常需要通过实证评估目标数据集，以确定最有效的方法。
- en: Object detection is one of the most important tasks in image understanding.
    Let’s see how graphs can help us there.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 物体检测是图像理解中最重要的任务之一。让我们看看图形如何在其中发挥作用。
- en: Object detection and segmentation using GNNs
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GNN进行物体检测和分割
- en: '**Object detection** and **segmentation** are crucial tasks in CV, with applications
    ranging from autonomous driving to medical image analysis. While CNNs have been
    the go-to approach for these tasks, GNNs are emerging as a powerful alternative
    or complementary technique. This section will explore how GNNs can be applied
    to object detection and segmentation tasks while discussing various approaches
    and their advantages.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**物体检测**和**分割**是计算机视觉中的重要任务，应用领域从自动驾驶到医学图像分析。虽然卷积神经网络（CNN）一直是这些任务的主要方法，但图神经网络（GNN）作为一种强有力的替代或补充技术，正在崭露头角。本节将探讨如何将GNN应用于物体检测和分割任务，并讨论不同方法及其优势。'
- en: Graph-based object proposal generation
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于图的物体提议生成
- en: '**Object proposal generation** is often the first step in many object detection
    pipelines. Traditional methods rely on sliding windows or region proposal networks,
    but graph-based approaches offer an interesting alternative. By representing an
    image as a graph, we can leverage the relational inductive bias of GNNs to generate
    more informed object proposals.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**物体提议生成**通常是许多物体检测流水线中的第一步。传统方法依赖于滑动窗口或区域提议网络，但基于图的方法提供了一个有趣的替代方案。通过将图像表示为图形，我们可以利用GNN的关系归纳偏差来生成更有信息的物体提议。'
- en: For example, consider an image represented as a graph of superpixels. Each superpixel
    ( *node* ) might have features such as color histograms, texture descriptors,
    and spatial information. *Edges* could represent adjacency or similarity between
    superpixels. A GNN can then process this graph to identify regions likely to contain
    objects.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑将图像表示为超像素图。每个超像素（*节点*）可能具有如颜色直方图、纹理描述符和空间信息等特征。*边缘*可以表示超像素之间的邻接或相似性。然后，GNN可以处理这个图，识别可能包含物体的区域。
- en: 'Here’s a simplified example of how a GNN might be used for object proposal
    generation:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个简化的示例，展示了GNN如何用于物体提议生成：
- en: '[PRE5]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this example, the model processes the graph and outputs an “objectness” score
    for each node (superpixel). These scores can then be used to generate bounding
    box proposals by grouping high-scoring adjacent superpixels.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，模型处理图并为每个节点（超像素）输出一个“物体性”分数。然后可以使用这些分数通过将高分相邻超像素组合起来生成边界框提议。
- en: Relational reasoning for object detection
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 面向物体检测的关系推理
- en: One of the key advantages of using GNNs for object detection is their ability
    to perform relational reasoning. Objects in an image often have meaningful relationships
    with each other, and capturing these relationships can significantly improve detection
    accuracy.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GNN进行物体检测的一个主要优势是其进行关系推理的能力。图像中的物体通常具有彼此之间的有意义关系，捕捉这些关系可以显著提高检测的准确性。
- en: For instance, in a street scene, knowing that a “wheel” object is next to a
    “car” object can increase the confidence of both detections. Similarly, detecting
    a “person” on a “horse” can help in classifying the scene as an equestrian event.
    GNNs can naturally model these relationships through message passing between object
    proposals.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在街景中，知道“轮子”物体靠近“汽车”物体可以提高这两个物体的检测信心。同样，检测到一个“人”骑在“马”上可以帮助将该场景分类为马术赛事。GNN可以通过物体提议之间的信息传递自然地建模这些关系。
- en: 'Consider an approach where initial object proposals are generated (either through
    a traditional method or a graph-based approach, as discussed earlier), and then
    a GNN is used to refine these proposals:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一种方法，在该方法中初步的物体提议通过传统方法或基于图的方式（如前所述）生成，然后使用GNN来优化这些提议：
- en: '[PRE6]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this model, each *node* represents an object proposal, and *edges* represent
    the relationships between proposals (for example, spatial proximity or feature
    similarity). The GNN refines the features of each proposal based on its relationships
    with other proposals, potentially leading to more accurate classifications and
    bounding box refinements.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，每个*节点*代表一个物体提议，*边缘*代表提议之间的关系（例如，空间邻近性或特征相似性）。GNN根据每个提议与其他提议的关系来优化提议的特征，从而可能导致更精确的分类和边界框优化。
- en: Instance segmentation with GNNs
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用GNN进行实例分割
- en: '**Instance segmentation** , which combines object detection with pixel-level
    segmentation, can also benefit from graph-based approaches. GNNs can be used to
    refine segmentation masks by considering the relationships between different parts
    of an object or between different objects in the scene.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**实例分割**，结合了目标检测与像素级分割，也能从基于图的方法中受益。GNNs 可以通过考虑物体的不同部分或场景中不同物体之间的关系来优化分割掩膜。'
- en: One approach is to represent an image as a graph of superpixels or pixels, where
    each node has features derived from a CNN backbone. A GNN can then process this
    graph to produce refined segmentation masks. This approach can be particularly
    effective for objects with complex shapes or in cases where global context is
    important for accurate segmentation.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 一种方法是将图像表示为超像素或像素的图，其中每个节点的特征来自 CNN 主干网络。然后，GNN 可以处理此图并生成细化的分割掩膜。此方法对于形状复杂的物体或在全局上下文对准确分割至关重要的情况下，特别有效。
- en: For example, in medical image analysis, segmenting organs with complex shapes
    (such as the brain or lungs) can benefit from considering long-range dependencies
    and overall organ structure, which GNNs can capture effectively.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在医学图像分析中，对复杂形状的器官（如大脑或肺部）进行分割，可以受益于考虑长程依赖关系和器官的整体结构，而 GNN 能有效捕捉这些信息。
- en: 'Here’s a conceptual example of how a GNN might be used for instance segmentation:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个概念示例，展示了 GNN 如何用于实例分割：
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This model takes a graph representation of an image (for example, superpixels)
    and outputs a mask probability for each node. These probabilities can then be
    used to construct the final instance segmentation masks.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型采用图像的图表示（例如，超像素），并为每个节点输出一个掩膜概率。然后，可以使用这些概率构建最终的实例分割掩膜。
- en: Panoptic segmentation using graph-structured outputs
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用图结构输出进行全景分割
- en: '**Panoptic segmentation** , which aims to provide a unified segmentation of
    both **stuff** (amorphous regions such as sky or grass) and **things** (countable
    objects), presents a unique challenge that graph-based methods are well suited
    to address. GNNs can model the complex relationships between different segments
    in the image, whether they represent distinct objects or parts of the background.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**全景分割**，旨在对**物体**（如天空或草地等无定形区域）和**事物**（可计数的物体）进行统一的分割，提出了一个独特的挑战，基于图的方法非常适合解决这一问题。GNNs
    可以建模图像中不同区域之间的复杂关系，无论它们代表的是独立的物体还是背景的一部分。'
- en: A graph-structured output for panoptic segmentation might represent each segment
    (both stuff and things) as *nodes* in a graph. *Edges* in this graph could represent
    adjacency or semantic relationships between segments. This representation allows
    the model to reason about the overall scene structure and ensure consistency in
    the segmentation.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 用于全景分割的图结构输出可能将每个区域（包括物体和事物）表示为图中的*节点*。该图中的*边*可以表示区域之间的邻接关系或语义关系。这种表示方法使得模型能够推理整体场景结构并确保分割的一致性。
- en: For instance, in a street scene, a graph-based panoptic segmentation model might
    learn that “car” segments are likely to be adjacent to “road” segments but not
    “sky” segments. This relational reasoning can help refine the boundaries between
    different segments and resolve ambiguities.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在街景中，基于图的全景分割模型可能学会“汽车”区域很可能与“道路”区域相邻，但与“天空”区域不相邻。这种关系推理有助于细化不同区域之间的边界，并解决歧义。
- en: 'Here’s a simplified example of how a GNN might be used for panoptic segmentation:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个简化的示例，展示了如何使用 GNN 进行全景分割：
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In this model, each node represents a segment in the image. The model outputs
    both semantic class predictions and instance predictions for each segment. The
    instance predictions can be used to distinguish between different instances of
    the same semantic class.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，每个节点代表图像中的一个区域。该模型为每个区域输出语义类别预测和实例预测。实例预测可以用来区分同一语义类别的不同实例。
- en: Next, we’ll look at how to leverage GNNs to build intelligence over multiple
    modalities.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探讨如何利用 GNNs 在多个模态上构建智能。
- en: Multi-modal learning with GNNs
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 GNNs 进行多模态学习
- en: Multi-modal learning involves processing and relating information from multiple
    types of data sources or sensory inputs. In the context of CV, this often means
    combining visual data with other modalities such as text, audio, or sensor data.
    GNNs provide a powerful framework for multi-modal learning by naturally representing
    different types of data and their inter-relationships in a unified graph structure.
    This section will explore how GNNs can be applied to multi-modal learning tasks
    in CV.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态学习涉及处理和关联来自多个数据源或感官输入的信息。在计算机视觉的背景下，这通常意味着将视觉数据与其他模态（如文本、音频或传感器数据）结合起来。GNN
    为多模态学习提供了一个强大的框架，通过自然地表示不同类型的数据及其相互关系，在统一的图结构中处理这些数据。该部分将探讨 GNN 如何应用于计算机视觉中的多模态学习任务。
- en: Integrating visual and textual information using graphs
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用图来整合视觉和文本信息
- en: One of the most common multi-modal pairings in CV is the combination of visual
    and textual data. This integration is crucial for tasks such as image captioning,
    visual question answering, and text-based image retrieval. GNNs offer a natural
    way to represent and process these two modalities in a single framework.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉领域，最常见的多模态配对之一是视觉和文本数据的结合。这种整合对于图像描述、视觉问答和基于文本的图像检索等任务至关重要。GNN 提供了一种自然的方式来在单一框架中表示和处理这两种模态。
- en: For example, consider a visual question-answering task. We can construct a graph
    where nodes represent both image regions and words from the question. Edges can
    then represent relationships between these elements, such as spatial relationships
    between image regions or syntactic relationships between words. By applying graph
    convolutions to this heterogeneous graph, the model can reason about the relationships
    between the visual and textual elements to answer the question.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个视觉问答任务。我们可以构建一个图，其中节点表示图像区域和问题中的单词。边可以表示这些元素之间的关系，例如图像区域之间的空间关系或单词之间的句法关系。通过对这个异质图应用图卷积，模型可以推理视觉和文本元素之间的关系，从而回答问题。
- en: 'Here’s a simplified example of how such a model might be structured. We begin
    with the necessary imports:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个简化的示例，展示了这样的模型如何构建。我们从必要的导入开始：
- en: '[PRE9]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The **VisualTextualGNN** class defines a visual-textual GNN model that can
    process both image and text data:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**VisualTextualGNN** 类定义了一个视觉-文本 GNN 模型，它可以处理图像和文本数据：'
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The **forward** method shows how the model processes the input data through
    various layers to produce the final output:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**forward** 方法展示了模型如何通过各种层处理输入数据，最终产生输出结果：'
- en: '[PRE11]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In this example, the model processes both image regions and words using separate
    GCN layers and then fuses this information in a subsequent layer. This allows
    the model to capture cross-modal interactions and reason about the relationship
    between visual and textual elements.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，模型使用独立的 GCN 层分别处理图像区域和单词，然后在后续层中融合这些信息。这使得模型能够捕捉跨模态交互，并推理视觉元素和文本元素之间的关系。
- en: Cross-modal retrieval using graph-based representations
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于图表示的跨模态检索
- en: Cross-modal retrieval tasks, such as finding images that match a text description
    or vice versa, can benefit greatly from graph-based representations. GNNs can
    learn the joint embeddings of different modalities, allowing for efficient and
    accurate retrieval across modalities.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 跨模态检索任务，例如查找与文本描述匹配的图像或反之，也可以通过图表示获得极大的帮助。GNN 可以学习不同模态的联合嵌入，从而实现高效且准确的跨模态检索。
- en: For instance, we could create a graph where nodes represent both images and
    text descriptions. Edges in this graph might connect similar images, similar text
    descriptions, and images with their corresponding descriptions. By applying GNN
    layers to this graph, we can learn embeddings that capture both intra-modal and
    cross-modal relationships.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以构建一个图，其中节点表示图像和文本描述。该图中的边可能连接相似的图像、相似的文本描述，以及图像与其对应的描述。通过对这个图应用 GNN 层，我们可以学习捕捉模态内和跨模态的关系的嵌入。
- en: 'Here’s an example of how a GNN-based cross-modal retrieval model might be structured:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个基于 GNN 的跨模态检索模型如何构建的示例：
- en: '[PRE12]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In this model, both images and text are encoded into a shared embedding space.
    The fusion layer allows for information to flow between the modalities, helping
    to align the embeddings. During retrieval, we can use these embeddings to find
    the nearest neighbors across modalities.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，图像和文本都被编码到一个共享的嵌入空间中。融合层使得信息能够在不同模态之间流动，帮助对齐嵌入。在检索过程中，我们可以使用这些嵌入来找到跨模态的最近邻。
- en: GNNs for visual-language navigation
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于视觉语言导航的GNN
- en: Visual-language navigation is a complex task that requires understanding and
    integrating visual scene information with natural language instructions. GNNs
    can be particularly effective for this task by representing the navigation environment
    as a graph and incorporating language information into this graph structure.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉语言导航是一项复杂的任务，要求理解并将视觉场景信息与自然语言指令进行整合。图神经网络（GNN）对于这项任务特别有效，通过将导航环境表示为图形，并将语言信息融入该图结构中。
- en: For example, we could represent a navigation environment as a graph where nodes
    correspond to locations and edges represent possible movements between locations.
    Each node could have associated visual features extracted from images of that
    location. The natural language instructions can be incorporated by adding additional
    nodes or node features representing key elements of the instructions.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以将导航环境表示为一个图，其中节点对应位置，边表示位置之间的可能移动。每个节点可以关联从该位置的图像中提取的视觉特征。自然语言指令可以通过添加额外的节点或节点特征来融入，表示指令中的关键元素。
- en: 'Here’s a conceptual example of how a GNN might be used for visual-language
    navigation:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个概念示例，展示了GNN如何用于视觉语言导航：
- en: '[PRE13]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this model, both visual scene information and language instructions are encoded
    and fused using GNN layers. The fused representations are then used to predict
    the next action in the navigation sequence.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，视觉场景信息和语言指令都通过GNN层进行编码和融合。融合后的表示随后用于预测导航序列中的下一个动作。
- en: Multi-modal learning with GNNs opens up exciting possibilities for more sophisticated
    and context-aware CV systems. By representing different modalities and their relationships
    in a unified graph structure, GNNs can capture complex interactions between modalities
    that are difficult to model with traditional approaches. This can lead to more
    robust and interpretable models for tasks that require information to be integrated
    from multiple sources.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GNN的多模态学习为更加复杂且具有上下文感知的计算机视觉（CV）系统开辟了令人兴奋的可能性。通过在统一的图结构中表示不同的模态及其关系，GNN能够捕捉到传统方法难以建模的模态间复杂互动。这可以为需要从多个来源整合信息的任务提供更强大、更易解释的模型。
- en: As research in this area continues to advance, we can expect to see further
    innovations in graph-based architectures for multi-modal learning, potentially
    leading to breakthroughs in areas such as embodied AI, human-robot interaction,
    and advanced content retrieval systems.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 随着该领域研究的不断推进，我们可以期待看到图架构在多模态学习中的进一步创新，可能会在像具身AI、人机交互和高级内容检索系统等领域带来突破。
- en: It’s important to understand the current challenges of performing graph-based
    learning on CV tasks. Let’s go through some of them.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 了解在计算机视觉任务中进行基于图的学习的当前挑战非常重要。让我们一起看看其中的一些挑战。
- en: Limitations and next steps
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制与下一步
- en: As graph deep learning continues to make strides in CV, several challenges and
    promising research directions have begun to emerge. One of the primary challenges
    in applying graph-based methods to CV is scalability.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 随着图深度学习在计算机视觉领域的不断进展，几个挑战和有前景的研究方向已经开始显现。将图方法应用于计算机视觉的主要挑战之一是可扩展性。
- en: Scalability issues in large-scale visual datasets
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大规模视觉数据集中的可扩展性问题
- en: As we saw in [*Chapter 5*](B22118_05.xhtml#_idTextAnchor093) , as the size of
    visual datasets continues to grow, constructing and processing large graphs becomes
    computationally expensive. For instance, a high-resolution image represented as
    a pixel-level graph could contain millions of nodes, making it challenging to
    perform graph convolutions efficiently.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[*第5章*](B22118_05.xhtml#_idTextAnchor093)中看到的，随着视觉数据集规模的不断增长，构建和处理大规模图变得计算上昂贵。例如，将高分辨率图像表示为像素级图形可能包含数百万个节点，这使得高效执行图卷积变得具有挑战性。
- en: Researchers are exploring various approaches to address this issue. One promising
    direction is the development of more efficient graph convolution operations. For
    example, the **GraphSAGE** algorithm can be used with a sampling-based approach
    to reduce the computational complexity of graph convolutions. Another approach
    is to use **hierarchical graph representations** , where the graph is progressively
    coarsened, allowing for efficient processing of large-scale data.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在探索各种方法来解决这个问题。一种有前景的方向是开发更高效的图卷积操作。例如，**GraphSAGE** 算法可以与基于采样的方法结合使用，以减少图卷积的计算复杂度。另一种方法是使用**层次化图表示**，通过逐步简化图形，允许对大规模数据进行高效处理。
- en: 'Consider the following example of a hierarchical GNN that could be used to
    process large images:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下示例，一个可以用来处理大规模图像的层次化图神经网络（GNN）：
- en: '[PRE14]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This model progressively reduces the graph’s size, allowing it to process larger
    initial graphs more efficiently.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型逐步减少图形的大小，使其能够更高效地处理更大的初始图形。
- en: Efficient graph construction and updating for real-time applications
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实时应用中的高效图形构建和更新
- en: Many CV applications, such as autonomous driving or augmented reality, require
    real-time processing. Constructing and updating graphs on the fly for these applications
    presents a significant challenge. Future research needs to focus on developing
    methods for rapid graph construction and updating graph structures efficiently
    as new visual information becomes available.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 许多计算机视觉（CV）应用，如自动驾驶或增强现实，需要实时处理。为这些应用程序即时构建和更新图形是一个巨大的挑战。未来的研究需要集中在开发快速图形构建和图形结构更新的方法，尤其是随着新视觉信息的到来。
- en: One potential approach is to develop incremental graph construction methods
    that can update an existing graph structure with new information efficiently,
    rather than rebuilding the entire graph from scratch. For example, in a video
    processing task, we might want to update our scene graph as new frames arrive.
    Consider an autonomous vehicle navigating urban traffic. The system needs to maintain
    a dynamic scene graph that represents relationships between various objects, such
    as vehicles, pedestrians, traffic signs, and road infrastructure. As new frames
    arrive at 30 **frames per second** ( **FPS** ), the system must update this graph
    structure efficiently without compromising real-time performance.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 一种潜在的方法是开发增量图构建方法，该方法能够高效地用新信息更新现有的图形结构，而不是从头开始重建整个图形。例如，在视频处理任务中，我们可能希望随着新帧的到来更新场景图。考虑一个自动驾驶车辆在城市交通中的导航系统。该系统需要维护一个动态的场景图，表示各种物体之间的关系，如车辆、行人、交通标志和道路基础设施。随着每秒30帧（**FPS**）的新帧到来，系统必须高效地更新图形结构，而不影响实时性能。
- en: For instance, when a new vehicle enters the scene, instead of reconstructing
    the entire graph, an incremental approach would only add new nodes and edges representing
    the vehicle and its relationships with existing objects. If a pedestrian moves
    from one location to another, only the edges representing spatial relationships
    need to be updated, while the core node attributes remain unchanged. This selective
    updating significantly reduces computational overhead compared to full graph reconstruction.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当一辆新车进入场景时，采用增量方法只需添加代表该车辆及其与现有物体关系的新节点和边，而不是重建整个图形。如果行人从一个位置移动到另一个位置，仅需更新表示空间关系的边，而核心节点属性保持不变。与完全重建图形相比，这种选择性更新显著降低了计算开销。
- en: The system could employ a hierarchical graph structure where high-level relationships
    (such as vehicle-to-vehicle interactions) are updated less frequently than low-level
    details (such as precise object positions). This multi-scale approach allows for
    efficient resource allocation while maintaining accuracy where it matters most.
    For example, the relative positions of parked cars might be updated every few
    frames, while the trajectory of a crossing pedestrian requires frame-by-frame
    precision.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 该系统可以采用层次化图结构，其中高层次关系（例如车辆之间的互动）更新的频率低于低层次细节（如精确的物体位置）。这种多尺度方法在保持关键准确性的同时，能够高效地分配资源。例如，停车车辆的相对位置可能每隔几帧更新一次，而过马路行人的轨迹则需要逐帧精确更新。
- en: To further optimize performance, the system could implement a priority-based
    updating mechanism. Objects closer to the vehicle or those moving at higher speeds
    would receive more frequent updates than distant or stationary objects. This approach
    could be complemented with predictive models that anticipate object movements
    and pre-compute likely graph updates, reducing the processing load when new frames
    arrive.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步优化性能，系统可以实现基于优先级的更新机制。与车辆距离较近或以较高速度移动的物体将比远离或静止的物体更频繁地进行更新。这个方法可以通过预测模型来补充，这些模型能够预测物体的运动，并预先计算可能的图更新，从而减少新帧到来时的处理负载。
- en: Advanced data structures, such as spatial indices and efficient memory management
    schemes, can be employed to speed up node and edge updates. For instance, using
    R-trees or octrees to organize spatial information can significantly reduce the
    time needed to locate and update relevant graph components. Additionally, maintaining
    a cache of recently modified graph regions can help optimize frequent updates
    to dynamic parts of the scene.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 可以采用先进的数据结构，如空间索引和高效的内存管理方案，加速节点和边的更新。例如，使用R树或八叉树来组织空间信息，可以显著减少定位和更新相关图形组件所需的时间。此外，维护一个最近修改过的图形区域的缓存，可以帮助优化动态场景部分的频繁更新。
- en: These optimization strategies must be carefully balanced with memory constraints
    and the need to maintain graph consistency. The system should also be robust enough
    to handle edge cases, such as sudden changes in lighting conditions or occlusions,
    which may temporarily affect the quality of the visual information that’s available
    for graph updates.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这些优化策略必须与内存限制以及保持图形一致性的需求之间进行仔细平衡。系统还应足够健壮，能够处理一些极端情况，例如光照条件的突然变化或遮挡，这可能会暂时影响用于图形更新的视觉信息的质量。
- en: Integrating graph-based methods with other deep learning approaches
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将基于图的方法与其他深度学习方法相结合
- en: While graph-based methods offer unique advantages for CV tasks, they aren’t
    a replacement for other deep learning techniques. Rather, the future likely lies
    in integrating graph-based methods with other approaches such as CNNs, transformers,
    and traditional CV algorithms effectively. For instance, we might use CNNs to
    extract initial features from images, construct a graph based on these features,
    and then apply GNN layers for further processing.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然基于图的方法在计算机视觉任务中具有独特的优势，但它们并不能取代其他深度学习技术。未来可能在于将基于图的方法与其他方法（如卷积神经网络（CNNs）、变压器（transformers）和传统计算机视觉算法）有效结合。例如，我们可能会使用CNN从图像中提取初步特征，根据这些特征构建图形，然后应用GNN层进行进一步处理。
- en: New applications and research opportunities
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 新的应用和研究机会
- en: 'As graph deep learning for CV matures, new applications and research opportunities
    continue to emerge. Here are some exciting areas for future research:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 随着基于图的深度学习在计算机视觉（CV）领域的成熟，新的应用和研究机会不断涌现。以下是一些未来研究的激动人心的方向：
- en: '**Graph-based, few-shot, and zero-shot learning** : Leveraging graph structures
    to improve generalization to new classes with limited or no examples'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于图的少样本学习和零样本学习**：利用图结构提升在有限或没有样本的情况下对新类别的泛化能力'
- en: '**Explainable AI through graph visualizations** : Using graph structures to
    provide more interpretable explanations of model decisions'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过图可视化进行可解释的AI**：利用图结构为模型决策提供更具可解释性的解释'
- en: '**Graph-based 3D vision** : Applying GNNs to 3D point cloud data for tasks
    such as 3D object detection and segmentation'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于图的3D视觉**：将图神经网络（GNN）应用于3D点云数据，进行3D物体检测和分割等任务'
- en: '**Dynamic graph learning for video understanding** : Developing methods to
    learn and update graph structures over time for video analysis tasks'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用于视频理解的动态图学习**：开发方法，随着时间推移学习和更新图结构，用于视频分析任务'
- en: '**Graph-based visual reasoning** : Using GNNs to perform complex reasoning
    tasks on visual data, such as solving visual puzzles or answering multi-step visual
    questions'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于图的视觉推理**：使用GNN在视觉数据上执行复杂的推理任务，如解决视觉难题或回答多步骤的视觉问题'
- en: As these areas develop, we can expect to see new architectures, training methods,
    and theoretical insights that will further advance the field of graph deep learning
    for CV.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 随着这些领域的发展，我们可以预期会看到新的架构、训练方法和理论见解，进一步推动基于图的深度学习在计算机视觉领域的进展。
- en: Summary
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Graph deep learning has emerged as a powerful paradigm in CV, offering unique
    advantages in capturing relational information and global context across various
    tasks, from image classification to multi-modal learning. In this chapter, we’ve
    shown that by providing a more structured and flexible approach to visual data
    processing, graph-based methods address the limitations of traditional CNN-based
    approaches, excel at modeling non-grid structured data, and enhance the integration
    of multi-modal information.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图深度学习作为计算机视觉中的一种强大范式，提供了在各种任务中捕捉关系信息和全局上下文的独特优势，从图像分类到多模态学习。在本章中，我们展示了通过提供更结构化和灵活的视觉数据处理方法，基于图的方法解决了传统卷积神经网络（CNN）方法的局限性，擅长建模非网格结构数据，并增强了多模态信息的融合。
- en: You learned that as the field evolves, graph deep learning is poised to significantly
    impact real-world applications such as autonomous driving, medical imaging, augmented
    reality, robotics, and content retrieval systems. While challenges remain, particularly
    in scalability and real-time processing, the synergy between graph theory and
    deep learning promises to shape the future of CV, pushing toward more sophisticated
    visual reasoning and human-level understanding.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经了解到，随着该领域的发展，图深度学习有望在自动驾驶、医学影像、增强现实、机器人技术和内容检索系统等现实世界应用中产生深远影响。尽管仍面临诸多挑战，尤其是在可扩展性和实时处理方面，但图论与深度学习的协同作用有望塑造计算机视觉的未来，推动更复杂的视觉推理和人类级别的理解。
- en: In the following chapter, we’ll explore applications of graph learning beyond
    natural language processing, CV, and recommendation systems.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将探讨图学习在自然语言处理、计算机视觉和推荐系统之外的应用。
- en: 'Part 4: Future Directions'
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四部分：未来方向
- en: In the final part of the book, you will discover additional applications of
    graph learning beyond the core domains and explore future directions. You will
    learn about the latest contemporary applications and gain insights into the challenges
    and opportunities that lie ahead in the field of graph learning.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在书的最后部分，你将发现图学习在核心领域之外的更多应用，并探索未来的发展方向。你将了解最新的当代应用，并深入了解图学习领域未来面临的挑战与机遇。
- en: 'This part has the following chapters:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 11*](B22118_11.xhtml#_idTextAnchor211) , *Emerging Applications*'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第11章*](B22118_11.xhtml#_idTextAnchor211)，*新兴应用*'
- en: '[*Chapter 12*](B22118_12.xhtml#_idTextAnchor254) , *The Future of Graph Learning*'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第12章*](B22118_12.xhtml#_idTextAnchor254)，*图学习的未来*'
