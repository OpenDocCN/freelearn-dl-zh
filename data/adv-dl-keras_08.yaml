- en: Chapter 8. Variational Autoencoders (VAEs)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 变分自编码器（VAE）
- en: Similar to **Generative Adversarial Networks** (**GANs**) that we've discussed
    in the previous chapters, **Variational Autoencoders** (**VAEs**) [1] belong to
    the family of generative models. The generator of VAE is able to produce meaningful
    outputs while navigating its continuous latent space. The possible attributes
    of the decoder outputs are explored through the latent vector.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们在前几章讨论的**生成对抗网络**（**GANs**）类似，**变分自编码器**（**VAE**）[1]属于生成模型家族。VAE的生成器能够在其连续的潜在空间中生成有意义的输出。解码器输出的可能属性通过潜在向量进行探索。
- en: In GANs, the focus is on how to arrive at a model that approximates the input
    distribution. VAEs attempt to model the input distribution from a decodable continuous
    latent space. This is one of the possible underlying reasons why GANs are able
    to generate more realistic signals when compared to VAEs. For example, in image
    generation, GANs are able to produce more realistic looking images while VAEs
    in comparison generate images that are less sharp.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在GAN中，重点是如何得到一个能够逼近输入分布的模型。VAE则试图通过可解码的连续潜在空间来建模输入分布。这是GAN与VAE生成更逼真信号的一个可能的根本原因。例如，在图像生成中，GAN能够生成更逼真的图像，而VAE则生成较为模糊的图像。
- en: Within VAEs, the focus is on the variational inference of latent codes. Therefore,
    VAEs provide a suitable framework for both learning and efficient Bayesian inference
    with latent variables. For example, VAEs with disentangled representations enable
    latent code reuse for transfer learning.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在VAE中，重点是潜在代码的变分推断。因此，VAE为学习和高效的贝叶斯推断提供了一个合适的框架。例如，具有解耦表示的VAE可以使潜在代码在迁移学习中得到重用。
- en: In terms of structure, VAEs bear a resemblance to an autoencoder. They are also made
    up of an encoder (also known as recognition or inference model) and a decoder
    (also known as a generative model). Both VAEs and autoencoders attempt to reconstruct
    the input data while learning the latent vector. However, unlike autoencoders,
    the latent space of VAEs is continuous, and the decoder itself is used as a generative
    model.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 从结构上看，VAE与自编码器相似。它们也由编码器（也称为识别或推断模型）和解码器（也称为生成模型）组成。VAE和自编码器都试图在学习潜在向量的同时重建输入数据。然而，与自编码器不同，VAE的潜在空间是连续的，解码器本身被用作生成模型。
- en: In the same line of discussions on GANs that we discussed in the previous chapters,
    the VAEs decoder can also be conditioned. For example, in the MNIST dataset, we're
    able to specify the digit to produce given a one-hot vector. This class of conditional
    VAE is called CVAE [2]. VAE latent vectors can also be disentangled by including
    a regularizing hyperparameter on the loss function. This is called
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 与前几章讨论的生成对抗网络（GANs）类似，VAE的解码器也可以进行条件化。例如，在MNIST数据集中，我们可以指定给定一个one-hot向量时要生成的数字。这类条件VAE被称为CVAE
    [2]。VAE的潜在向量也可以通过在损失函数中加入正则化超参数来进行解耦。这被称为
- en: '![Variational Autoencoders (VAEs)](img/B08956_08_001.jpg)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![变分自编码器（VAE）](img/B08956_08_001.jpg)'
- en: -VAE [5]. For example, within MNIST, we're able to isolate the latent vector
    that determines the thickness or tilt angle of each digit.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE [5]。例如，在MNIST中，我们可以分离出决定每个数字的厚度或倾斜角度的潜在向量。
- en: 'The goal of this chapter is to present:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是介绍：
- en: The principles of VAEs
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VAE的原理
- en: An understanding of the reparameterization trick that facilitates the use of stochastic
    gradient descent on VAE optimization
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解重新参数化技巧，帮助在VAE优化中使用随机梯度下降
- en: The principles of conditional VAE (CVAE) and![Variational Autoencoders (VAEs)](img/B08956_08_002.jpg)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 条件VAE（CVAE）的原理和![变分自编码器（VAE）](img/B08956_08_002.jpg)
- en: -VAE
  id: totrans-12
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: -VAE
- en: An understanding of how to implement VAEs within the Keras library
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解如何在Keras库中实现VAE
- en: Principles of VAEs
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VAE原理
- en: 'In a generative model, we''re often interested in approximating the true distribution
    of our inputs using neural networks:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成模型中，我们通常感兴趣的是使用神经网络来逼近输入的真实分布：
- en: '![Principles of VAEs](img/B08956_08_003.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![VAE原理](img/B08956_08_003.jpg)'
- en: (Equation 8.1.1)
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: （公式 8.1.1）
- en: In the preceding equation,
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的公式中，
- en: '![Principles of VAEs](img/B08956_08_004.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![VAE原理](img/B08956_08_004.jpg)'
- en: are the parameters determined during training. For example, in the context of
    the celebrity faces dataset, this is equivalent to finding a distribution that
    can draw faces. Similarly, in the MNIST dataset, this distribution can generate
    recognizable handwritten digits.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 是在训练过程中确定的参数。例如，在名人面孔数据集的背景下，这相当于找到一个可以生成面孔的分布。类似地，在MNIST数据集中，这个分布可以生成可识别的手写数字。
- en: In machine learning, to perform a certain level of inference, we're interested
    in finding
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，为了进行某种层次的推理，我们感兴趣的是找到
- en: '![Principles of VAEs](img/B08956_08_005.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_005.jpg)'
- en: ', a joint distribution between inputs, *x*, and the latent variables, *z*.
    The latent variables are not part of the dataset but instead encode certain properties
    observable from inputs. In the context of celebrity faces, these might be facial
    expressions, hairstyles, hair color, gender, and so on. In the MNIST dataset,
    the latent variables may represent the digit and writing styles.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: ，是输入*x*与潜在变量*z*之间的联合分布。潜在变量不是数据集的一部分，而是编码从输入中可观察到的某些属性。在名人面孔的背景下，这些可能是面部表情、发型、发色、性别等。在MNIST数据集中，潜在变量可能表示数字和书写风格。
- en: '![Principles of VAEs](img/B08956_08_006.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_006.jpg)'
- en: 'is practically a distribution of input data points and their attributes. *P*
    *θ*(*x*) can be computed from the marginal distribution:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上是输入数据点及其属性的分布。*P* *θ*(*x*)可以从边际分布中计算出来：
- en: '![Principles of VAEs](img/B08956_08_007.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_007.jpg)'
- en: (Equation 8.1.2)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: （方程8.1.2）
- en: In other words, considering all of the possible attributes, we end up with the
    distribution that describes the inputs. In celebrity faces, if we consider all
    the facial expressions, hairstyles, hair colors, gender, the distribution describing
    the celebrity faces is recovered. In the MNIST dataset, if we consider all of
    the possible digits, writing styles, and so on, we end up with the distribution
    of handwritten digits.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，考虑所有可能的属性，我们最终得到了描述输入的分布。在名人面孔的例子中，如果我们考虑所有的面部表情、发型、发色、性别，那么描述名人面孔的分布就能被恢复出来。在MNIST数据集中，如果我们考虑所有可能的数字、书写风格等，最终我们得到了手写数字的分布。
- en: The problem is *Equation 8.1.2* is *intractable*. the equation does not have
    an analytic form or an efficient estimator. It cannot be differentiated with respect
    to its parameters. Therefore, optimization by a neural network is not feasible.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是*方程8.1.2*是*不可解的*。这个方程没有解析形式或有效的估计器，无法对其参数进行微分。因此，使用神经网络进行优化是不可行的。
- en: 'Using Bayes theorem, we can find an alternative expression for *Equation 8.1.2*:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用贝叶斯定理，我们可以为*方程8.1.2*找到另一种表达方式：
- en: '![Principles of VAEs](img/B08956_08_008.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_008.jpg)'
- en: (Equation 8.1.3)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: （方程8.1.3）
- en: '*P*(*z*) is a prior distribution over *z*. It is not conditioned on any observations.
    If *z* is discrete and'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '*P*(*z*)是*z*的先验分布。它不依赖于任何观察。如果*z*是离散的，并且'
- en: '![Principles of VAEs](img/B08956_08_009.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_009.jpg)'
- en: is a Gaussian distribution, then
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 是高斯分布，那么
- en: '![Principles of VAEs](img/B08956_08_010.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_010.jpg)'
- en: is a mixture of Gaussians. If *z* is continuous,
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 是高斯混合分布。如果*z*是连续的，
- en: '![Principles of VAEs](img/B08956_08_011.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_011.jpg)'
- en: is an infinite mixture of Gaussians.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 它是高斯分布的无限混合。
- en: In practice, if we try to build a neural network to approximate
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，如果我们尝试构建一个神经网络来逼近
- en: '![Principles of VAEs](img/B08956_08_012.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_012.jpg)'
- en: without a suitable loss function, it will just ignore *z* and arrive at a trivial
    solution
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有合适的损失函数，它将忽略*z*并得出一个琐碎的解
- en: '![Principles of VAEs](img/B08956_08_013.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_013.jpg)'
- en: '='
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '='
- en: '![Principles of VAEs](img/B08956_08_014.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_014.jpg)'
- en: . Therefore, *Equation 8.1.3* does not provide us with a good estimate of
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，*方程8.1.3*不能为我们提供一个好的估计
- en: '![Principles of VAEs](img/B08956_08_015.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_015.jpg)'
- en: .
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: 'Alternatively, *Equation 8.1.2* can also be expressed as:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，*方程8.1.2*也可以表达为：
- en: '![Principles of VAEs](img/B08956_08_016.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_016.jpg)'
- en: (Equation 8.1.4)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: （方程8.1.4）
- en: However,
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，
- en: '![Principles of VAEs](img/B08956_08_017.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_017.jpg)'
- en: is also intractable. The goal of a VAEs is to find a tractable distribution
    that closely estimates
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 也是不可解的。VAEs的目标是找到一个可解的分布，能紧密地估计
- en: '![Principles of VAEs](img/B08956_08_018.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![VAEs原理](img/B08956_08_018.jpg)'
- en: .
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: Variational inference
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变分推断
- en: In order to make
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使
- en: '![Variational inference](img/B08956_08_019.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![变分推断](img/B08956_08_019.jpg)'
- en: 'tractable, VAE introduces the variational inference model (an encoder):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可处理性，VAE 引入了变分推断模型（编码器）：
- en: '![Variational inference](img/B08956_08_020.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![变分推断](img/B08956_08_020.jpg)'
- en: (Equation 8.1.5)
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: (方程式 8.1.5)
- en: '![Variational inference](img/B08956_08_021.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![变分推断](img/B08956_08_021.jpg)'
- en: provides a good estimate of
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了一个对的良好估计
- en: '![Variational inference](img/B08956_08_022.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![变分推断](img/B08956_08_022.jpg)'
- en: . It is both parametric and tractable.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: . 它既是参数化的，又是可处理的。
- en: '![Variational inference](img/B08956_08_023.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![变分推断](img/B08956_08_023.jpg)'
- en: can be approximated by deep neural networks by optimizing the parameters
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过深度神经网络优化参数来近似
- en: '![Variational inference](img/B08956_08_024.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![变分推断](img/B08956_08_024.jpg)'
- en: .
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: Typically,
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，
- en: '![Variational inference](img/B08956_08_025.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![变分推断](img/B08956_08_025.jpg)'
- en: 'is chosen to be a multivariate Gaussian:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 被选为多元高斯分布：
- en: '![Variational inference](img/B08956_08_026.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![变分推断](img/B08956_08_026.jpg)'
- en: (Equation 8.1.6)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: (方程式 8.1.6)
- en: Both mean,
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 两者的含义是，
- en: '![Variational inference](img/B08956_08_027.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![变分推断](img/B08956_08_027.jpg)'
- en: ', and standard deviation,'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ，以及标准差，
- en: '![Variational inference](img/B08956_08_028.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![变分推断](img/B08956_08_028.jpg)'
- en: ', are computed by the encoder neural network using the input data points. The
    diagonal matrix implies that the elements of *z* are independent.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: ，由编码器神经网络使用输入数据点计算得出。对角矩阵意味着 *z* 的元素是独立的。
- en: Core equation
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 核心方程
- en: The inference model
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 推断模型
- en: '![Core equation](img/B08956_08_029.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_029.jpg)'
- en: generates latent vector *z* from input *x*.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 从输入 *x* 生成潜在向量 *z*。
- en: '![Core equation](img/B08956_08_030.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_030.jpg)'
- en: is like the encoder in an autoencoder model. On the other hand,
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 它类似于自编码器模型中的编码器。另一方面，
- en: '![Core equation](img/B08956_08_031.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_031.jpg)'
- en: reconstructs the input from the latent code *z*.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 从潜在代码 *z* 重构输入数据。
- en: '![Core equation](img/B08956_08_032.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_032.jpg)'
- en: acts like the decoder in an autoencoder model. To estimate
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 其作用类似于自编码器模型中的解码器。为了估计
- en: '![Core equation](img/B08956_08_033.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_033.jpg)'
- en: ', we must identify its relationship with'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: ，我们必须确定它与的关系
- en: '![Core equation](img/B08956_08_034.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_034.jpg)'
- en: and
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![Core equation](img/B08956_08_035.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_035.jpg)'
- en: .
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: If
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果
- en: '![Core equation](img/B08956_08_036.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_036.jpg)'
- en: is an estimate of
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 是对的估计
- en: '![Core equation](img/B08956_08_037.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_037.jpg)'
- en: ', the **Kullback-Leibler** (**KL**) divergence determines the distance between
    these two conditional densities:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ，**Kullback-Leibler**（**KL**）散度决定了这两个条件概率分布之间的距离：
- en: '![Core equation](img/B08956_08_038.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_038.jpg)'
- en: (Equation 8.1.7)
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: (方程式 8.1.7)
- en: Using Bayes theorem,
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用贝叶斯定理，
- en: '![Core equation](img/B08956_08_039_.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_039_.jpg)'
- en: (Equation 8.1.8)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: (方程式 8.1.8)
- en: in *Equation 8.1.7*,
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *方程式 8.1.7* 中，
- en: '![Core equation](img/B08956_08_040.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_040.jpg)'
- en: (Equation 8.1.9)
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: (方程式 8.1.9)
- en: '![Core equation](img/B08956_08_041.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_041.jpg)'
- en: can be taken out the expectation since it is not dependent on
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 可以将期望值提出，因为它不依赖于
- en: '![Core equation](img/B08956_08_042.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_042.jpg)'
- en: . Rearranging the preceding equation and recognizing that
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: . 重新排列前面的方程并认识到
- en: '![Core equation](img/B08956_08_043.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_043.jpg)'
- en: ':'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ':'
- en: '![Core equation](img/B08956_08_044.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_044.jpg)'
- en: (Equation 8.1.10)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: (方程式 8.1.10)
- en: '*Equation 8.1.10* is the core of VAEs. The left-hand side is the term'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*方程式 8.1.10* 是变分自编码器（VAE）的核心。左边是'
- en: '![Core equation](img/B08956_08_045.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_045.jpg)'
- en: that we are maximizing less the error due to the distance of
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在最大化的是由于距离造成的误差较小
- en: '![Core equation](img/B08956_08_046.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_046.jpg)'
- en: from the true
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 来自真实
- en: '![Core equation](img/B08956_08_047.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_047.jpg)'
- en: . We can recall that the logarithm does not change the location of maxima (or
    minima). Given an inference model that provides a good estimate of
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: . 我们可以回忆起对数运算不会改变极大值（或极小值）的位置。给定一个能够提供良好估计的推断模型
- en: '![Core equation](img/B08956_08_048.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_048.jpg)'
- en: ','
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: ，
- en: '![Core equation](img/B08956_08_049.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_049.jpg)'
- en: is approximately zero. The first term,
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 近似为零。第一项，
- en: '![Core equation](img/B08956_08_050.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_050.jpg)'
- en: ', on the right-hand side resembles a decoder that takes samples from the inference
    model to reconstruct the input. The second term is another distance. This time
    it''s between'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: ，右侧看起来像一个解码器，它从推理模型中提取样本来重建输入。第二项是另一个距离。这一次，它是在
- en: '![Core equation](img/B08956_08_051.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_051.jpg)'
- en: and the prior
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 先验
- en: '![Core equation](img/B08956_08_052.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_052.jpg)'
- en: .
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 。
- en: The left side of *Equation 8.1.10* is also known as the **variational lower
    bound** or **evidence lower bound** (**ELBO**). Since the KL is always positive,
    ELBO is the lower bound of
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*方程8.1.10*的左侧也被称为**变分下界**或**证据下界** (**ELBO**)。由于KL总是正值，ELBO是'
- en: '![Core equation](img/B08956_08_053.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_053.jpg)'
- en: . Maximizing ELBO by optimizing the parameters
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 。通过优化参数来最大化ELBO
- en: '![Core equation](img/B08956_08_054.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_054.jpg)'
- en: and
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![Core equation](img/B08956_08_055.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![核心方程](img/B08956_08_055.jpg)'
- en: 'of the neural network means that:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的意义是：
- en: '![Core equation](img/B08956_08_056.jpg) or the inference model is getting better
    in encoding the attributes of *x* in *z*'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![核心方程](img/B08956_08_056.jpg) 或推理模型在编码*x*的属性到*z*时变得更好'
- en: '![Core equation](img/B08956_08_057.jpg) on the right-hand side of *Equation
    8.1.10* is maximized or the decoder model is getting better in reconstructing
    *x* from the latent vector *z*'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![核心方程](img/B08956_08_057.jpg) 在*方程8.1.10*的右侧被最大化，或者解码器模型在从潜在向量*z*重建*x*方面变得更好'
- en: Optimization
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化
- en: The right-hand side of *Equation 8.1.10* has two important bits of information
    about the loss function of VAEs. The decoder term
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*方程8.1.10*的右侧包含关于VAE损失函数的两个重要信息。解码器项'
- en: '![Optimization](img/B08956_08_058.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_058.jpg)'
- en: means that the generator takes *z* samples from the output of the inference
    model to reconstruct the inputs. Maximizing this term implies that we minimize
    the **Reconstruction Loss**,
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 意味着生成器从推理模型的输出中获取*z*样本来重建输入。最大化这一项意味着我们最小化**重建损失**，
- en: '![Optimization](img/B08956_08_059.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_059.jpg)'
- en: . If the image (data) distribution is assumed to be Gaussian, then MSE can be
    used. If every pixel (data) is considered a Bernoulli distribution, then the loss
    function is a binary cross entropy.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 。如果假设图像（数据）分布是高斯分布，则可以使用MSE。如果每个像素（数据）被视为伯努利分布，则损失函数是二元交叉熵。
- en: The second term,
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 第二项，
- en: '![Optimization](img/B08956_08_060.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_060.jpg)'
- en: ', turns out to be straightforward to evaluate. From *Equation 8.1.6*,'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: ，结果证明可以直接评估。从*方程8.1.6*，
- en: '![Optimization](img/B08956_08_061.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_061.jpg)'
- en: is a Gaussian distribution. Typically,
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 是一个高斯分布。通常，
- en: '![Optimization](img/B08956_08_062.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_062.jpg)'
- en: 'is also a Gaussian with zero mean and standard deviation equal to 1.0\. The
    KL term simplifies to:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 也是一个均值为零、标准差为1.0的高斯分布。KL项简化为：
- en: '![Optimization](img/B08956_08_063.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_063.jpg)'
- en: (Equation 8.1.11)
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: （方程8.1.11）
- en: Where
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '![Optimization](img/B08956_08_064.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_064.jpg)'
- en: is the dimensionality of *z*. Both
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 是*z*的维度。两者
- en: '![Optimization](img/B08956_08_065.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_065.jpg)'
- en: and
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![Optimization](img/B08956_08_066.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_066.jpg)'
- en: are functions of *x* computed through the inference model. To maximize
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 是通过推理模型计算的*x*的函数。为了最大化
- en: '![Optimization](img/B08956_08_067.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_067.jpg)'
- en: ','
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: ，
- en: '![Optimization](img/B08956_08_068.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_068.jpg)'
- en: and
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![Optimization](img/B08956_08_069.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_069.jpg)'
- en: . The choice of
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 。选择
- en: '![Optimization](img/B08956_08_070.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_070.jpg)'
- en: stems from the property of isotropic unit Gaussian which can be morphed to an
    arbitrary distribution given a suitable function. From *Equation 8.1.11*, the
    **KL Loss**
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 来源于各向同性单位高斯的属性，通过适当的函数可以将其变形成任意分布。从*方程8.1.11*，**KL损失**
- en: '![Optimization](img/B08956_08_071.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_071.jpg)'
- en: is simply
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 只是
- en: '![Optimization](img/B08956_08_072.jpg)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_072.jpg)'
- en: .
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 。
- en: Note
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注
- en: For example, it was previously [6] demonstrated that an isotropic Gaussian could
    be morphed into a ring-shaped distribution using the function
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，之前[6]已证明，可以使用该函数将各向同性高斯分布变形成环形分布
- en: '![Optimization](img/B08956_08_073.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_073.jpg)'
- en: .
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 。
- en: Readers can further explore the theory as presented in Luc Devroye's, *Sample-Based
    Non-Uniform Random Variate Generation* [7].
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 读者可以进一步探讨Luc Devroye的理论，*基于样本的非均匀随机变异生成* [7]。
- en: 'In summary, the VAE loss function is defined as:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，VAE损失函数被定义为：
- en: '![Optimization](img/B08956_08_074.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_08_074.jpg)'
- en: (Equation 8.1.12)
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: (方程式 8.1.12)
- en: Reparameterization trick
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重参数化技巧
- en: '![Reparameterization trick](img/B08956_08_01.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![重参数化技巧](img/B08956_08_01.jpg)'
- en: 'Figure 8.1.1: A VAE network with and without the reparameterization trick'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1.1：带有和不带有重参数化技巧的VAE网络
- en: On the left side of the preceding figure shows the VAE network. The encoder
    takes the input *x*, and estimates the mean,
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在前图的左侧展示了VAE网络。编码器接受输入*x*，并估计均值，
- en: '![Reparameterization trick](img/B08956_08_075.jpg)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![重参数化技巧](img/B08956_08_075.jpg)'
- en: ', and the standard deviation,'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: ，以及标准差，
- en: '![Reparameterization trick](img/B08956_08_076.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![重参数化技巧](img/B08956_08_076.jpg)'
- en: ', of the multivariate Gaussian distribution of the latent vector *z*. The decoder
    takes samples from the latent vector *z* to reconstruct the input as'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: ，多元高斯分布的潜在向量*z*。解码器从潜在向量*z*中采样，重建输入为
- en: '![Reparameterization trick](img/B08956_08_077.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![重参数化技巧](img/B08956_08_077.jpg)'
- en: . This seems straightforward until the gradient updates happen during backpropagation.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 。这看起来很简单，直到反向传播时梯度更新发生。
- en: Backpropagation gradients will not pass through the stochastic **Sampling**
    block. While it's fine to have stochastic inputs for neural networks, it's not
    possible for the gradients to go through a stochastic layer.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播的梯度不会通过随机**采样**块。虽然神经网络可以有随机输入，但梯度无法通过随机层。
- en: 'The solution to this problem is to push out the **Sampling** process as the
    input as shown on the right side of *Figure 8.1.1*. Then, compute the sample as:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 解决此问题的方法是将**采样**过程作为输入推送出去，如*图8.1.1*右侧所示。然后，计算样本为：
- en: '![Reparameterization trick](img/B08956_08_078.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![重参数化技巧](img/B08956_08_078.jpg)'
- en: (Equation 8.1.13)
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: (方程式 8.1.13)
- en: If
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果
- en: '![Reparameterization trick](img/B08956_08_079.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![重参数化技巧](img/B08956_08_079.jpg)'
- en: and
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![Reparameterization trick](img/B08956_08_080.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![重参数化技巧](img/B08956_08_080.jpg)'
- en: are expressed in vector format, then
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 以向量格式表达，然后
- en: '![Reparameterization trick](img/B08956_08_081.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![重参数化技巧](img/B08956_08_081.jpg)'
- en: is element-wise multiplication. Using *Equation 8.1.13*, it appears as if sampling
    is directly coming from the latent space as originally intended. This technique
    is better known as the **Reparameterization Trick**.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 是逐元素相乘。使用*方程式8.1.13*，看起来就像采样直接来自原本设想的潜在空间。这个技巧被称为**重参数化技巧**。
- en: With *Sampling* now happening at the input, the VAE network can be trained using the
    familiar optimization algorithms such as SGD, Adam, or RMSProp.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在*采样*发生在输入端，VAE网络可以使用熟悉的优化算法进行训练，如SGD、Adam或RMSProp。
- en: Decoder testing
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解码器测试
- en: After training the VAE network, the inference model including the addition and
    multiplication operator can be discarded. To generate new meaningful outputs,
    samples are taken from the Gaussian distribution used in generating
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练完VAE网络后，推理模型，包括加法和乘法操作符，可以丢弃。为了生成新的有意义的输出，从生成所使用的高斯分布中采样。
- en: '![Decoder testing](img/B08956_08_082.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![解码器测试](img/B08956_08_082.jpg)'
- en: '. Following figure shows us how to test the decoder:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 。接下来的图展示了我们如何测试解码器：
- en: '![Decoder testing](img/B08956_08_02.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![解码器测试](img/B08956_08_02.jpg)'
- en: 'Figure 8.1.2: Decoder testing setup'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1.2：解码器测试设置
- en: VAEs in Keras
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Keras中的VAE
- en: The structure of VAE bears a resemblance to a typical autoencoder. The difference
    is mainly on the sampling of the Gaussian random variables in the reparameterization
    trick. *Listing* *8.1.1* shows the encoder, decoder, and VAE which are implemented
    using MLP. This code has also been contributed to the official Keras GitHub repository.
    For simplicity of the discussion, the latent vector *z* is 2-dim.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: VAE的结构与典型的自编码器相似。区别主要在于重参数化技巧中的高斯随机变量采样。*列表* *8.1.1*展示了使用MLP实现的编码器、解码器和VAE。这个代码也已经贡献到官方的Keras
    GitHub库中。为了简化讨论，潜在向量*z*是二维的。
- en: The encoder is just a two-layer MLP with the second layer generating the mean
    and log variance. The use of log variance is for simplicity in the computation
    of *KL Loss* and reparameterization trick. The third output of the encoder is
    the sampling of *z* using the reparameterization trick. We should note that in
    the sampling function,
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器只是一个两层的MLP，第二层生成均值和对数方差。使用对数方差是为了简化*KL损失*和重参数化技巧的计算。编码器的第三个输出是使用重参数化技巧对*z*的采样。我们需要注意，在采样函数中，
- en: '![VAEs in Keras](img/B08956_08_083.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![Keras中的VAE](img/B08956_08_083.jpg)'
- en: since
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 由于
- en: '![VAEs in Keras](img/B08956_08_084.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![Keras 中的 VAEs](img/B08956_08_084.jpg)'
- en: given that it's the standard deviation of the Gaussian distribution.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 给定它是高斯分布的标准差。
- en: The decoder is also a two-layer MLP that takes samples of *z* to approximate
    the inputs. Both the encoder and the decoder use an intermediate dimension with a size
    of 512.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器也是一个两层的 MLP，它接受 *z* 的样本来近似输入。编码器和解码器都使用一个大小为 512 的中间维度。
- en: The VAE network is simply both the encoder and the decoder joined together.
    *Figures 8.1.3* to *8.1.5* show the encoder, decoder, and VAE models. The loss
    function is the sum of both the *Reconstruction Loss* and *KL Loss*. The VAE network
    has good results on the default Adam optimizer. The total number of parameters
    of the VAE network is 807,700.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: VAE 网络实际上是编码器和解码器的组合。*图 8.1.3* 到 *图 8.1.5* 显示了编码器、解码器和 VAE 模型。损失函数是 *重建损失* 和
    *KL 损失* 的总和。VAE 网络在默认的 Adam 优化器下表现良好。VAE 网络的总参数数目为 807,700。
- en: 'The Keras code for VAE MLP has pretrained weights. To test, we need to run:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 中的 VAE MLP 代码已经预训练权重。要进行测试，我们需要运行：
- en: '[PRE0]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The complete code can be found on the following link: [https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras](https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras).'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 完整代码可以在以下链接中找到：[https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras](https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras)。
- en: 'Listing 8.1.1, `vae-mlp-mnist-8.1.1.py` shows us the Keras code of VAE using
    MLP layers:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 8.1.1，`vae-mlp-mnist-8.1.1.py` 显示了使用 MLP 层的 VAE Keras 代码：
- en: '[PRE1]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![VAEs in Keras](img/B08956_08_03.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![Keras 中的 VAEs](img/B08956_08_03.jpg)'
- en: 'Figure 8.1.3: The encoder models of VAE MLP'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1.3：VAE MLP 的编码器模型
- en: '![VAEs in Keras](img/B08956_08_04.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![Keras 中的 VAEs](img/B08956_08_04.jpg)'
- en: 'Figure 8.1.4: The decoder model of VAE MLP'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1.4：VAE MLP 的解码器模型
- en: '![VAEs in Keras](img/B08956_08_05.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![Keras 中的 VAEs](img/B08956_08_05.jpg)'
- en: 'Figure 8.1.5: The VAE model using MLP'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1.5：使用 MLP 的 VAE 模型
- en: '*Figure 8.1.6* shows the continuous space of latent vector after 50 epochs
    using `plot_results()`. For simplicity, the function is not shown here but can
    be found in the rest of the code of `vae-mlp-mnist-8.1.1.py`. The function plots
    two images, the test dataset labels (*Figure 8.1.6*) and the sample generated
    digits (*Figure 8.1.7*) both as a function of *z*. Both plots demonstrate how
    the latent vector determines the attributes of the generated digits.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 8.1.6* 显示了使用 `plot_results()` 在 50 个 epoch 后的潜在向量连续空间。为简化起见，函数在此未显示，但可以在
    `vae-mlp-mnist-8.1.1.py` 的其余代码中找到。该函数绘制了两个图像，分别是测试数据集标签（*图 8.1.6*）和生成的数字样本（*图
    8.1.7*），两者均为 *z* 的函数。这两个图展示了潜在向量如何决定生成数字的特征。'
- en: Navigating through the continuous space will always result in an output that
    bears a resemblance to the MNIST digits. For example, the region of digit 9 is
    close to the region of digit 7\. Moving from 9 near the center to the left morphs
    the digit to 7\. Moving from the center downward changes the generated digits
    from 3 to 8 and finally to 1\. The morphing of the digits is more evident in *Figure
    8.1.7* which is another way of interpreting *Figure 8.1.6*.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在连续空间中导航总是会得到一个与 MNIST 数字相似的输出。例如，数字 9 的区域靠近数字 7 的区域。从接近中心的 9 向左移动将数字变为 7。从中心向下移动将生成的数字从
    3 变为 8，最终变为 1。数字的形态变化在 *图 8.1.7* 中更为明显，这也是对 *图 8.1.6* 的另一种解释。
- en: In *Figure 8.1.7*, instead of colorbar, the generator output is displayed. The
    distribution of digits in the latent space is shown. It can be observed that all
    the digits are represented. Since the distribution is dense near the center, the
    change is rapid in the middle and slow as the mean values get bigger. We need
    to remember that *Figure 8.1.7* is a reflection of *Figure 8.1.6*. For example,
    digit 0 is on the top right quadrant on both figures while digit 1 is on the lower
    right quadrant.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 8.1.7* 中，生成器输出显示了潜在空间中数字的分布，而不是色条。可以观察到所有数字都被表示出来。由于分布在中心附近较为密集，因此在中间区域的变化较快，而在均值较大的地方变化较慢。我们需要记住，*图
    8.1.7* 是 *图 8.1.6* 的反映。例如，数字 0 在两个图中的右上象限，而数字 1 在右下象限。
- en: 'There are some unrecognizable digits in *Figure 8.1.7*, especially on the top
    left quadrant. From the following figure, it can be observed that this region
    is mostly empty and far away from the center:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 8.1.7* 中有一些无法识别的数字，尤其是在左上方的象限。从下面的图中可以观察到，该区域大多为空，并且远离中心：
- en: '![VAEs in Keras](img/B08956_08_06.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![Keras 中的 VAEs](img/B08956_08_06.jpg)'
- en: 'Figure 8.1.6: The latent vector mean values for the test dataset (VAE MLP).
    The colorbar shows the corresponding MNIST digit as a function of z. Color images
    can be found on the book GitHub repository: https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter8-vae.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1.6：测试数据集的潜在向量均值（VAE MLP）。颜色条显示了与 z 对应的 MNIST 数字。彩色图像可在书籍的 GitHub 仓库中找到：https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter8-vae。
- en: '![VAEs in Keras](img/B08956_08_07.jpg)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![Keras 中的 VAE](img/B08956_08_07.jpg)'
- en: 'Figure 8.1.7: The digits generated as a function of latent vector mean values
    (VAE MLP). For ease of interpretation, the range of values for the mean is similar
    to Figure 8.1.6.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1.7：作为潜在向量均值函数生成的数字（VAE MLP）。为了便于解释，均值的值范围与图 8.1.6 类似。
- en: Using CNNs for VAEs
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 CNNs 进行 VAE
- en: In the original paper *Auto-encoding Variational Bayes* [1], the VAE network
    was implemented using MLP, which is similar to what we covered in the previous
    section. In this section, we'll demonstrate that using a CNN will result in a
    significant improvement in the quality of the digits produced and a remarkable
    reduction in the number of parameters down to 134,165.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始论文 *Auto-encoding Variational Bayes* [1] 中，VAE 网络是使用 MLP 实现的，这与我们在前一节中介绍的类似。在本节中，我们将展示使用
    CNN 会显著提高生成的数字质量，并且将参数数量大幅减少至 134,165。
- en: '*Listing* *8.1.3* shows the encoder, decoder, and VAE network. This code was
    also contributed to the official Keras GitHub repository. For conciseness, some
    lines of code that are similar to the MLP are no longer shown. The encoder is
    made of two layers of CNNs and two layers of MLPs in order to generate the latent
    code. The encoder output structure is similar to the MLP implementation seen in
    the previous section. The decoder is made up of one layer of MLP and three layers
    of transposed CNNs. *Figures 8.1.8* to *8.1.10* show the encoder, decoder, and
    VAE models. For VAE CNN, RMSprop will result in a lower loss than Adam.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing* *8.1.3* 展示了编码器、解码器和 VAE 网络。该代码也已贡献到官方的 Keras GitHub 仓库。为了简洁起见，类似
    MLP 的一些代码行不再显示。编码器由两层 CNN 和两层 MLP 组成，用于生成潜在代码。编码器输出结构类似于前一节中看到的 MLP 实现。解码器由一层
    MLP 和三层反向卷积 CNN 组成。*图 8.1.8* 到 *8.1.10* 展示了编码器、解码器和 VAE 模型。对于 VAE CNN，RMSprop
    会比 Adam 得到更低的损失。'
- en: 'The Keras code for VAE CNN has pre-trained weights. To test, we need to run:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: VAE CNN 的 Keras 代码已包含预训练权重。要进行测试，我们需要运行：
- en: '[PRE2]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Listing 8.1.3, `vae-cnn-mnist-8.1.2.py` shows us the Keras code of VAE using
    CNN layers:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: Listing 8.1.3, `vae-cnn-mnist-8.1.2.py` 显示了使用 CNN 层的 VAE Keras 代码：
- en: '[PRE3]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Using CNNs for VAEs](img/B08956_08_08.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![使用 CNNs 进行 VAE](img/B08956_08_08.jpg)'
- en: 'Figure 8.1.8: The encoder of VAE CNN'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1.8：VAE CNN 的编码器
- en: '![Using CNNs for VAEs](img/B08956_08_09.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![使用 CNNs 进行 VAE](img/B08956_08_09.jpg)'
- en: 'Figure 8.1.9: The decoder of VAE CNN'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1.9：VAE CNN 的解码器
- en: '![Using CNNs for VAEs](img/B08956_08_10.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![使用 CNNs 进行 VAE](img/B08956_08_10.jpg)'
- en: 'Figure 8.1.10: The VAE model using CNNs'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1.10：使用 CNNs 的 VAE 模型
- en: '![Using CNNs for VAEs](img/B08956_08_11.jpg)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![使用 CNNs 进行 VAE](img/B08956_08_11.jpg)'
- en: 'Figure 8.1.11: The latent vector mean values for the test dataset (VAE CNN).
    The colorbar shows the corresponding MNIST digit as a function of z. Color images
    can be found on the book GitHub repository: https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter8-vae.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1.11：测试数据集的潜在向量均值（VAE CNN）。颜色条显示了与 z 对应的 MNIST 数字。彩色图像可在书籍的 GitHub 仓库中找到：https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter8-vae。
- en: 'Preceding figure shows the continuous latent space of a VAE using the CNN implementation
    after 30 epochs. The region where each digit is assigned may be different, but
    the distribution is roughly the same. Following figure shows us the output of
    the generative model. Qualitatively, there are fewer digits that are ambiguous
    as compared to *Figure 8.1.7* with the MLP implementation:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 前述图像展示了使用 CNN 实现的 VAE 在训练 30 个 epoch 后的连续潜在空间。每个数字分配的区域可能不同，但分布大致相同。下图展示了生成模型的输出。定性上，与
    *图 8.1.7* 中的 MLP 实现相比，模糊的数字较少：
- en: '![Using CNNs for VAEs](img/B08956_08_12.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![使用 CNNs 进行 VAE](img/B08956_08_12.jpg)'
- en: 'Figure 8.1.12: The digits generated as a function of latent vector mean values
    (VAE CNN). For ease of interpretation, the range of values for the mean is similar
    to Figure 8.1.11.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1.12：作为潜在向量均值函数生成的数字（VAE CNN）。为了便于解释，均值的值范围与图 8.1.11 类似。
- en: Conditional VAE (CVAE)
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条件 VAE (CVAE)
- en: Conditional VAE [2] is similar to the idea of CGAN. In the context of the MNIST
    dataset, if the latent space is randomly sampled, VAE has no control over which
    digit will be generated. CVAE is able to address this problem by including a condition
    (a one-hot label) of the digit to produce. The condition is imposed on both the
    encoder and decoder inputs.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 条件变分自编码器 [2] 类似于 CGAN 的思想。在 MNIST 数据集的背景下，如果潜在空间是随机采样的，VAE 无法控制生成哪个数字。CVAE 通过包含一个条件（数字的独热标签）来解决这个问题，从而生成特定的数字。这个条件被强加到编码器和解码器的输入上。
- en: 'Formally, the core equation of VAE in *Equation* *8.1.10* is modified to include
    the condition *c*:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 从形式上讲，VAE 的核心方程 *方程* *8.1.10* 被修改，以包括条件 *c*：
- en: '![Conditional VAE (CVAE)](img/B08956_08_085.jpg)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![条件变分自编码器（CVAE）](img/B08956_08_085.jpg)'
- en: (Equation 8.2.1)
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: (方程 8.2.1)
- en: Similar to VAEs, *Equation* *8.2.1* means that if we want to maximize the output
    conditioned on *c*,
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 与 VAE 类似，*方程* *8.2.1* 表示，如果我们想要最大化基于 *c* 的输出，
- en: '![Conditional VAE (CVAE)](img/B08956_08_086.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![条件变分自编码器（CVAE）](img/B08956_08_086.jpg)'
- en: ', then the two loss terms must be minimized:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ，那么两个损失项必须最小化：
- en: Reconstruction loss of the decoder given both the latent vector and the condition.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在给定潜在向量和条件的情况下，解码器的重建损失。
- en: KL loss between the encoder given both the latent vector and the condition and
    the prior distribution given the condition. Similar to a VAE, we typically choose![Conditional
    VAE (CVAE)](img/B08956_08_087.jpg)
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编码器在给定潜在向量和条件的情况下与先验分布之间的 KL 损失。与 VAE 类似，我们通常选择 ![条件变分自编码器（CVAE）](img/B08956_08_087.jpg)
- en: .
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: .
- en: 'Listing 8.2.1, `cvae-cnn-mnist-8.2.1.py` shows us the Keras code of CVAE using
    CNN layers. In the code that is highlighted showcases the changes made to support
    CVAE:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 8.2.1，`cvae-cnn-mnist-8.2.1.py` 展示了使用 CNN 层的 CVAE 的 Keras 代码。在突出显示的代码中展示了为支持
    CVAE 所做的修改：
- en: '[PRE4]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Conditional VAE (CVAE)](img/B08956_08_13.jpg)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![条件变分自编码器（CVAE）](img/B08956_08_13.jpg)'
- en: 'Figure 8.2.1: The encoder in CVAE CNN. The input is now made of the concatenation
    of the VAE input and a conditioning label.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2.1：CVAE CNN 中的编码器。输入现在是 VAE 输入和条件标签的拼接。
- en: '![Conditional VAE (CVAE)](img/B08956_08_14.jpg)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![条件变分自编码器（CVAE）](img/B08956_08_14.jpg)'
- en: 'Figure 8.2.2: The decoder in CVAE CNN. The input is now made of the concatenation
    of the z sampling and a conditioning label.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2.2：CVAE CNN 中的解码器。输入现在是 z 采样和条件标签的拼接。
- en: '![Conditional VAE (CVAE)](img/B08956_08_15.jpg)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![条件变分自编码器（CVAE）](img/B08956_08_15.jpg)'
- en: 'Figure 8.2.3: The CVAE model using a CNN. The input is now made of a VAE input
    and a conditioning label.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2.3：使用 CNN 的 CVAE 模型。输入现在是 VAE 输入和条件标签的拼接。
- en: Implementing CVAE requires a few modifications in the code of the VAE. For the
    CVAE, the VAE CNN implementation is used. *Listing* *8.2.1* highlights the changes
    made to the original code of VAE for MNIST digits. The encoder input is now a
    concatenation of original input image and its one-hot label. The decoder input
    is now a combination of the latent space sampling and the one-hot label of the
    image it should generate. The total number of parameters is 174, 437\. The codes
    related to
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 实现 CVAE 需要对 VAE 的代码进行一些修改。对于 CVAE，使用了 VAE CNN 的实现。*列表* *8.2.1* 突出显示了对 MNIST
    数字的 VAE 原始代码所做的修改。编码器输入现在是原始输入图像和其独热标签的拼接。解码器输入现在是潜在空间采样和它应该生成的图像的独热标签的组合。总参数数量为
    174,437。与代码相关的部分
- en: '![Conditional VAE (CVAE)](img/B08956_08_088.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![条件变分自编码器（CVAE）](img/B08956_08_088.jpg)'
- en: -VAE will be discussed in the next section of this chapter.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE 将在本章的下一节中讨论。
- en: There are no changes in the loss function. However, the one-hot labels are supplied
    during training, testing, and plotting of results. *Figures 8.2.1* to *8.2.3*
    show us the encoder, decoder, and CVAE models. The role of the conditioning label
    in the form of a one-hot vector is indicated.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数没有变化。然而，在训练、测试和绘制结果时提供了独热标签。*图 8.2.1* 到 *8.2.3* 向我们展示了编码器、解码器和 CVAE 模型。指明了条件标签作为独热向量的作用。
- en: '![Conditional VAE (CVAE)](img/B08956_08_16.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![条件变分自编码器（CVAE）](img/B08956_08_16.jpg)'
- en: 'Figure 8.2.4: The latent vector mean values for the test dataset (CVAE CNN).
    The colorbar shows the corresponding MNIST digit as a function of z. Color images
    can be found on the book GitHub repository: https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter8-vae.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2.4：测试数据集的潜在向量均值（CVAE CNN）。颜色条显示了与 z 相关的对应 MNIST 数字。彩色图像可以在书籍的 GitHub 仓库找到：
    https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter8-vae。
- en: '![Conditional VAE (CVAE)](img/B08956_08_17.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![条件变分自编码器（CVAE）](img/B08956_08_17.jpg)'
- en: 'Figure 8.2.5: Digits 0 to 5 generated as a function of latent vector mean values
    and one-hot label (CVAE CNN). For ease of interpretation, the range of values
    for the mean is similar to Figure 8.2.4.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2.5：根据潜在向量均值和独热标签（CVAE CNN）生成的数字0到5。为了便于理解，均值的取值范围与图8.2.4相似。
- en: '![Conditional VAE (CVAE)](img/B08956_08_18.jpg)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![条件VAE (CVAE)](img/B08956_08_18.jpg)'
- en: 'Figure 8.2.6: Digits 6 to 9 generated as a function of latent vector mean values
    and one-hot label (CVAE CNN). For ease of interpretation, the range of values
    for the mean is similar to Figure 8.2.4.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2.6：根据潜在向量均值和独热标签（CVAE CNN）生成的数字6到9。为了便于理解，均值的取值范围与图8.2.4相似。
- en: In *Figure 8.2.4*, the distribution of mean per label is shown after 30 epochs.
    Unlike in both *Figures 8.1.6* and *8.1.11* in the previous sections, each label
    is not concentrated on a region but distributed across the plot. This is expected
    since every sampling in the latent space should generate a specific digit. Navigating
    the latent space changes the attribute of that specific digit. For example, if
    the digit specified is 0, then navigating the latent space will still produce
    a 0 but the attributes, such as tilt angle, thickness, and other writing style
    aspects will be different.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图8.2.4*中，展示了经过30个epoch后每个标签的均值分布。与前面章节中的*图8.1.6*和*8.1.11*不同，每个标签并没有集中在某个区域，而是分布在整个图中。这是预期中的结果，因为在潜在空间中的每次采样应当生成一个特定的数字。导航潜在空间会改变该特定数字的属性。例如，如果指定的数字是0，那么导航潜在空间仍会产生0，但其属性（如倾斜角度、粗细以及其他书写风格特征）会有所不同。
- en: 'These changes are more clearly shown in *Figures 8.2.5* and *8.2.6*. For ease
    of comparison, the range of values for the latent vector is the same as in *Figure
    8.2.4*. Using the pretrained weights, a digit (for example, 0) can be generated
    by executing the command:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变化在*图8.2.5*和*8.2.6*中表现得更加清晰。为了便于比较，潜在向量的取值范围与*图8.2.4*中的一致。使用预训练的权重，可以通过执行以下命令生成一个数字（例如，0）：
- en: '[PRE5]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In *Figures 8.2.5* and *8.2.6*, it can be noticed that the width and roundness
    (if applicable) of each digit change as *z*[0] is traced from left to right. Meanwhile,
    the tilt angle and roundness (if applicable) of each digit change as *z*[1] is
    navigated from top to bottom. As we move away from the center of the distribution,
    the image of the digit starts to degrade. This is expected since the latent space
    is a circle.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图8.2.5*和*8.2.6*中，可以注意到每个数字的宽度和圆度（如果适用）随着*z*[0]从左到右的变化而变化。同时，随着*z*[1]从上到下的变化，每个数字的倾斜角度和圆度（如果适用）也会发生变化。当我们离分布的中心越来越远时，数字的图像开始退化。这是预期中的结果，因为潜在空间是一个圆形。
- en: Other noticeable variations in attributes may be digit specific. For example,
    the horizontal stroke (arm) for digit 1 becomes visible in the upper left quadrant.
    The horizontal stroke (crossbar) for digit 7 can be seen in the right quadrants
    only.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 其他显著的属性变化可能是针对特定数字的。例如，数字1的水平笔画（臂）会出现在左上方区域。数字7的水平笔画（横杆）则只出现在右侧区域。
- en: '![Conditional VAE (CVAE)](img/B08956_08_089.jpg)-VAE: VAE with disentangled
    latent representations'
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '![条件VAE (CVAE)](img/B08956_08_089.jpg)-VAE：具有解耦潜在表示的VAE'
- en: In [Chapter 6](ch06.html "Chapter 6. Disentangled Representation GANs"), *Disentangled
    Representation GANs*, the concept, and importance of the disentangled representation
    of latent codes were discussed. We can recall that a disentangled representation
    is where single latent units are sensitive to changes in single generative factors
    while being relatively invariant to changes in other factors [3]. Varying a latent
    code results to changes in one attribute of the generated output while the rest
    of the properties remain the same.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第6章](ch06.html "第6章 解耦表示GAN")中，讨论了*解耦表示GAN*的概念以及潜在编码的解耦表示的重要性。我们可以回顾一下，解耦表示指的是单一潜在单元对单个生成因子的变化敏感，同时对其他因子的变化保持相对不变[3]。改变潜在编码会导致生成输出中某一属性的变化，而其他属性保持不变。
- en: In the same chapter, InfoGANs [4] demonstrated to us that in the MNIST dataset,
    it is possible to control which digit to generate and the tilt and thickness of
    writing style. Observing the results in the previous section, it can be noticed
    that the VAE is intrinsically disentangling the latent vector dimensions to a
    certain extent. For example, looking at digit 8 in *Figure 8.2.6*, navigating
    *z*[1] from top to bottom decreases the width and roundness while rotating the
    digit clockwise. Increasing *z*[0] from left to right also decreases the width
    and roundness while rotating the digit counterclockwise. In other words, *z*[1]
    controls the clockwise rotation, *z*[0] affects the counterclockwise rotation,
    and both of them alter the width and roundness.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一章节中，InfoGANs [4]向我们展示了在MNIST数据集中，可以控制生成的数字和倾斜和书写风格的厚度。观察前一节中的结果，可以注意到VAE在某种程度上本质上正在分离潜在向量维度。例如，查看*图8.2.6*中的数字8，导航*z*[1]从顶部到底部减少宽度和圆度，同时将数字顺时针旋转。增加*z*[0]从左到右也减少了宽度和圆度，同时将数字逆时针旋转。换句话说，*z*[1]控制顺时针旋转，*z*[0]影响逆时针旋转，两者都改变宽度和圆度。
- en: In this section, we'll demonstrate that a simple modification in the loss function
    of VAE forces the latent codes to disentangle further. The modification is the
    positive constant weight,
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将展示VAE损失函数中的简单修改如何进一步迫使潜在代码分离。该修改是正常数加权，
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_090.jpg)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_090.jpg)'
- en: ', acting as a regularizer on the KL loss:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: ，作为KL损失的正则化器：
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_091.jpg)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_091.jpg)'
- en: (Equation 8.3.1)
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: （方程8.3.1）
- en: This variation of VAE is called
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 这种VAE的变体被称为
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_092.jpg)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_092.jpg)'
- en: -VAE [5]. The implicit effect of
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE [5]。隐式效果
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_093.jpg)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_093.jpg)'
- en: is a tighter standard deviation. In other words,
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 是更紧密的标准偏差。换句话说，
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_094.jpg)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_094.jpg)'
- en: forces the latent codes in the posterior distribution,
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 强制后验分布中的潜在代码，
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_095.jpg)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_095.jpg)'
- en: to be independent.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 独立。
- en: It is straightforward to implement
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 实施是很直接的
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_096.jpg)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_096.jpg)'
- en: -VAE. For example, for the CVAE from the previous, the required modification
    is the extra **beta** factor in `kl_loss`.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE。例如，对于前述的CVAE，所需的修改是`kl_loss`中额外的**beta**因子。
- en: '[PRE6]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: CVAE is a special case of
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: CVAE是的一种特例
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_097.jpg)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_097.jpg)'
- en: -VAE with
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE with
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_098.jpg)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_098.jpg)'
- en: . Everything else is the same. However, determining the value of
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 。其他都相同。然而，确定 
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_099.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_099.jpg)'
- en: requires some trial and error. There must be a careful balance between the reconstruction
    error and regularization for latent codes independence. The disentanglement is
    maximized at around
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 需要一些试验和错误。必须在重建误差和潜在代码独立性的正则化之间进行仔细平衡。在约
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_100.jpg)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_100.jpg)'
- en: . When the value of
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: . 当值为 
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_101.jpg)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_101.jpg)'
- en: ', the'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: ，
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_102.jpg)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_102.jpg)'
- en: '-VAE is forced to learn one disentangled representation only while muting the
    other latent dimension:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE被迫仅学习一个分离的表示，同时静音另一个潜在维度：
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_19.jpg)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_19.jpg)'
- en: 'Figure 8.3.1: The latent vector mean values for the test dataset ('
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3.1：测试数据集的潜在向量均值（
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_103.jpg)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 具有分离的潜在表示的VAE](img/B08956_08_103.jpg)'
- en: -VAE with
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE with
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_104.jpg)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_104.jpg)'
- en: ') Color images can be found on the book GitHub repository: https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter8-vae.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: ）彩色图像可以在本书的 GitHub 仓库中找到： https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter8-vae。
- en: '*Figures 8.3.1* and *8.3.2* show the latent vector means for'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 8.3.1* 和 *图 8.3.2* 展示了'
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_105.jpg)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_105.jpg)'
- en: -VAE with
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE 与
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_106.jpg)'
  id: totrans-338
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_106.jpg)'
- en: and
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_107.jpg)'
  id: totrans-340
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_107.jpg)'
- en: . With
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 。随着
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_108.jpg)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_108.jpg)'
- en: ', the distribution has a smaller standard deviation when compared to CVAE.
    With'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: ，与 CVAE 相比，该分布的标准差较小。随着
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_109.jpg)'
  id: totrans-344
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_109.jpg)'
- en: ', there is only the latent code that is learned. The distribution is practically
    shrunk to 1D with the first latent code *z*[0] ignored by the encoder and decoder:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: ，只有学习到的潜在编码。分布实际上被缩小到 1D，第一潜在编码 *z*[0] 被编码器和解码器忽略：
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_20.jpg)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_20.jpg)'
- en: 'Figure 8.3.2: The latent vector mean values for the test dataset ('
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3.2：测试数据集的潜在向量均值（
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_110.jpg)'
  id: totrans-348
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_110.jpg)'
- en: -VAE with
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE 与
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_111.jpg)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_111.jpg)'
- en: ')Color images can be found on the book GitHub repository: https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter8-vae.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: ）彩色图像可以在本书的 GitHub 仓库中找到： https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras/tree/master/chapter8-vae。
- en: These observations are reflected in *Figure 8.3.3*.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 这些观察结果在 *图 8.3.3* 中有所体现。
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_112.jpg)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_112.jpg)'
- en: -VAE with
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE 与
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_113.jpg)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_113.jpg)'
- en: has two latent codes that are practically independent. *z*[0] determines the
    tilt of the writing style. Meanwhile, *z*[1] specifies the width and roundness
    (if applicable) of the digits. For
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个潜在编码是相对独立的。*z*[0] 决定书写风格的倾斜角度。同时，*z*[1] 指定数字的宽度和圆润度（如果适用）。
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_114.jpg)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_114.jpg)'
- en: -VAE with
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE 与
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_115.jpg)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_115.jpg)'
- en: ', *z*[0] is muted. Increasing *z*[0] does not alter the digit in a significant
    way. *z*[1] determines the tilt angle and width of the writing style.'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: ，*z*[0] 被静音。增加 *z*[0] 不会显著改变数字。*z*[1] 决定了书写风格的倾斜角度和宽度。
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_21.jpg)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_21.jpg)'
- en: 'Figure 8.3.3: Digits 0 to 3 generated as a function of latent vector mean values
    and one-hot label ('
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3.3：数字 0 到 3 作为潜在向量均值和 one-hot 标签的函数生成（
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_116.jpg)'
  id: totrans-363
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_116.jpg)'
- en: -VAE
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_117.jpg)'
  id: totrans-365
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_117.jpg)'
- en: ). For ease of interpretation, the range of values for the mean is similar to
    Figure 8.3.1.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: ）为了便于理解，均值的值范围与图 8.3.1 类似。
- en: The Keras code for
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 代码
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_118.jpg)'
  id: totrans-368
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_118.jpg)'
- en: -VAE has pre-trained weights. To test
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE 具有预训练权重。要测试
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_119.jpg)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_119.jpg)'
- en: -VAE with
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE 与
- en: '![-VAE: VAE with disentangled latent representations](img/B08956_08_120.jpg)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![-VAE: 带有解耦潜在表示的 VAE](img/B08956_08_120.jpg)'
- en: 'generating digit 0, we need to run:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 生成数字 0，我们需要运行：
- en: '[PRE7]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Conclusion
  id: totrans-375
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter, we've covered the principles of variational autoencoders (VAEs).
    As we learned in the principles of VAEs, they bear a resemblance to GANs in the
    aspect of both attempt to create synthetic outputs from latent space. However,
    it can be noticed that the VAE networks are much simpler and easier to train compared
    to GANs. It's becoming clear how conditional VAE and
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了变分自编码器（VAE）的基本原理。正如我们在VAE原理中所学到的，它们与GAN在某些方面相似，因为它们都试图从潜在空间生成合成输出。然而，可以注意到，相较于GAN，VAE网络更加简单且易于训练。条件VAE和
- en: '![Conclusion](img/B08956_08_121.jpg)'
  id: totrans-377
  prefs: []
  type: TYPE_IMG
  zh: '![结论](img/B08956_08_121.jpg)'
- en: -VAE are similar in concept to conditional GAN and disentangled representation
    GAN respectively.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE在概念上与条件GAN和解缠表示GAN相似。
- en: VAEs have an intrinsic mechanism to disentangle the latent vectors. Therefore,
    building a
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: VAE具有解缠潜在向量的内在机制。因此，构建一个
- en: '![Conclusion](img/B08956_08_122.jpg)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![结论](img/B08956_08_122.jpg)'
- en: -VAE is straightforward. We should note however that interpretable and disentangled
    codes are important in building intelligent agents.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: -VAE非常直观。然而，我们应该注意到，可解释的和解缠的编码在构建智能代理时是重要的。
- en: In the next chapter, we're going to focus on Reinforcement learning. Without
    any prior data, an agent learns by interacting with its world. We'll discuss how
    the agent can be rewarded for correct actions and punished for the wrong ones.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将重点介绍强化学习。在没有任何先验数据的情况下，代理通过与环境的互动来学习。我们将讨论如何根据正确的行动奖励代理，并对错误的行动进行惩罚。
- en: References
  id: totrans-383
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Diederik P. Kingma and Max Welling. *Auto-encoding Variational Bayes*. arXiv
    preprint arXiv:1312.6114, 2013([https://arxiv.org/pdf/1312.6114.pdf](https://arxiv.org/pdf/1312.6114.pdf)).
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Diederik P. Kingma和Max Welling。*自编码变分贝叶斯*。arXiv预印本arXiv:1312.6114，2013([https://arxiv.org/pdf/1312.6114.pdf](https://arxiv.org/pdf/1312.6114.pdf))。
- en: Kihyuk Sohn, Honglak Lee, and Xinchen Yan. *Learning Structured Output Representation
    Using Deep Conditional Generative Models*. Advances in Neural Information Processing
    Systems, 2015([http://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models.pdf](http://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models.pdf)).
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kihyuk Sohn、Honglak Lee和Xinchen Yan。*使用深度条件生成模型学习结构化输出表示*。神经信息处理系统进展，2015([http://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models.pdf](http://papers.nips.cc/paper/5775-learning-structured-output-representation-using-deep-conditional-generative-models.pdf))。
- en: 'Yoshua Bengio, Aaron Courville, and Pascal Vincent. *Representation Learning:
    A Review and New Perspectives*. IEEE transactions on Pattern Analysis and Machine
    Intelligence 35.8, 2013: 1798-1828([https://arxiv.org/pdf/1206.5538.pdf](https://arxiv.org/pdf/1206.5538.pdf)).'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Yoshua Bengio、Aaron Courville和Pascal Vincent。*表示学习：综述与新视角*。IEEE模式分析与机器智能事务35.8，2013：1798-1828([https://arxiv.org/pdf/1206.5538.pdf](https://arxiv.org/pdf/1206.5538.pdf))。
- en: 'Xi Chen and others. *Infogan: Interpretable Representation Learning by Information
    Maximizing Generative Adversarial Nets*. Advances in Neural Information Processing
    Systems, 2016([http://papers.nips.cc/paper/6399-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets.pdf](http://papers.nips.cc/paper/6399-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets.pdf)).'
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Xi Chen等人。*Infogan: 通过信息最大化生成对抗网络进行可解释的表示学习*。神经信息处理系统进展，2016([http://papers.nips.cc/paper/6399-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets.pdf](http://papers.nips.cc/paper/6399-infogan-interpretable-representation-learning-by-information-maximizing-generative-adversarial-nets.pdf))。'
- en: I. Higgins, L. Matthey, A. Pal, C. Burgess, X. Glorot, M. Botvinick, S. Mohamed,
    and A. Lerchner.![References](img/B08956_08_123.jpg)
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: I. Higgins、L. Matthey、A. Pal、C. Burgess、X. Glorot、M. Botvinick、S. Mohamed和A.
    Lerchner。![参考文献](img/B08956_08_123.jpg)
- en: '*-VAE: Learning basic visual concepts with a constrained variational framework*.
    ICLR, 2017([https://openreview.net/pdf?id=Sy2fzU9gl](https://openreview.net/pdf?id=Sy2fzU9gl)).'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*-VAE: 使用受限变分框架学习基础视觉概念*。ICLR，2017([https://openreview.net/pdf?id=Sy2fzU9gl](https://openreview.net/pdf?id=Sy2fzU9gl))。'
- en: Carl Doersch. *Tutorial on variational autoencoders*. arXiv preprint arXiv:1606.05908,
    2016 ([https://arxiv.org/pdf/1606.05908.pdf](https://arxiv.org/pdf/1606.05908.pdf)).
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Carl Doersch。*变分自编码器教程*。arXiv预印本arXiv:1606.05908，2016([https://arxiv.org/pdf/1606.05908.pdf](https://arxiv.org/pdf/1606.05908.pdf))。
- en: Luc Devroye. *Sample-Based Non-Uniform Random Variate Generation*. Proceedings
    of the 18th conference on Winter simulation. ACM, 1986([http://www.eirene.de/Devroye.pdf](http://www.eirene.de/Devroye.pdf)).
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Luc Devroye. *基于样本的非均匀随机变量生成*. 第18届冬季仿真会议论文集. ACM, 1986([http://www.eirene.de/Devroye.pdf](http://www.eirene.de/Devroye.pdf)).
