- en: 'Chapter 2:'
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第2章：
- en: Running TensorFlow Enterprise in Google AI Platform
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Google AI 平台上运行 TensorFlow Enterprise
- en: Currently, the TensorFlow Enterprise distribution is only available through
    Google Cloud AI Platform. This chapter will demonstrate how to launch AI Platform
    for use with TensorFlow Enterprise. In AI Platform, TensorFlow Enterprise can
    interact with Cloud Storage and BigQuery via their respective command-line tools
    as well as simple APIs to load data from the source. In this chapter, we are going
    to take a look at how to launch AI Platform and how easy it is to start using
    the TensorFlow Enterprise distribution.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当前，TensorFlow Enterprise 发行版仅通过 Google Cloud AI 平台提供。本章将演示如何启动 AI 平台并将其用于 TensorFlow
    Enterprise。在 AI 平台中，TensorFlow Enterprise 可以通过各自的命令行工具以及简单的 API 与 Cloud Storage
    和 BigQuery 进行交互，从而加载源数据。本章将展示如何启动 AI 平台，并且演示开始使用 TensorFlow Enterprise 发行版的简便方法。
- en: 'We''ll cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖以下主要内容：
- en: Setting up a notebook environment
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置笔记本环境
- en: Easy parameterized data extraction from BigQuery
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 BigQuery 轻松提取参数化数据
- en: Setting up a notebook environment
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置笔记本环境
- en: 'TensorFlow Enterprise is exclusively available in the JupyterLab environment
    hosted by Google Cloud. There are three ways to consume the JupyterLab with this
    TensorFlow distribution: **Google Cloud** **AI Platform Notebook**, **Google Cloud**
    **Deep Learning Virtual Machine Images (DLVM)**, and **Google Cloud** **Deep Learning
    Containers** (**Docker image**) running on your local machine. No matter which
    one you choose, you will see the same interface of a standard JupyterLab environment
    like this:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Enterprise 仅在由 Google Cloud 托管的 JupyterLab 环境中提供。使用此 TensorFlow 发行版，有三种方式可以使用
    JupyterLab：**Google Cloud** **AI 平台笔记本**，**Google Cloud** **深度学习虚拟机镜像（DLVM）**，以及在本地计算机上运行的**Google
    Cloud** **深度学习容器**（**Docker 镜像**）。无论您选择哪种方式，您将看到标准 JupyterLab 环境的相同界面，如下所示：
- en: '![Figure 2.1 – JupyterLab portal](img/Figure_2.1.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1 – JupyterLab 门户](img/Figure_2.1.jpg)'
- en: Figure 2.1 – JupyterLab portal
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – JupyterLab 门户
- en: So let's take a look at how to get started.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们来看看如何开始。
- en: AI Platform Notebook
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI 平台笔记本
- en: 'This is the easiest and least complicated way to start using TensorFlow Enterprise
    and get it running in Google Cloud:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这是开始使用 TensorFlow Enterprise 并使其在 Google Cloud 上运行的最简单、最不复杂的方式：
- en: Simply go to the Google Cloud portal, select **AI Platform** in the left panel,
    then select the **Notebooks** option:![Figure 2.2 – AI Platform starting portal
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只需进入 Google Cloud 门户，选择左侧面板中的**AI 平台**，然后选择**笔记本**选项：![图 2.2 – AI 平台启动门户
- en: '](img/Figure_2.2.jpg)'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.2.jpg)'
- en: Figure 2.2 – AI Platform starting portal
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.2 – AI 平台启动门户
- en: Then click on **NEW INSTANCE**, and you'll be offered choices for TensorFlow
    Enterprise, which is available for **1.15** as well as **2.1** and **2.3**. You
    also have the option to use one **Tesla K4** GPU:![Figure 2.3 – Creating a new
    notebook instance in AI Platform
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后点击**新实例**，您将获得 TensorFlow Enterprise 的选择，可以选择**1.15**、**2.1**或**2.3**版本。您还可以选择使用一个**Tesla
    K4** GPU：![图 2.3 – 在 AI 平台上创建新的笔记本实例
- en: '](img/Figure_2.3.jpg)'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.3.jpg)'
- en: Figure 2.3 – Creating a new notebook instance in AI Platform
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.3 – 在 AI 平台上创建新的笔记本实例
- en: For our examples in this chapter, we don't need to use a GPU. Selecting **Without
    GPUs** will suffice.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于本章中的示例，我们不需要使用 GPU。选择**无 GPU**即可。
- en: Then click on **CREATE** to accept the default node choice, or **CUSTOMIZE**
    to see all the setup options available:![Figure 2.4 – Customizing a compute instance
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后点击**创建**以接受默认节点选择，或点击**自定义**查看所有可用的设置选项：![图 2.4 – 自定义计算实例
- en: '](img/Figure_2.4.jpg)'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.4.jpg)'
- en: Figure 2.4 – Customizing a compute instance
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.4 – 自定义计算实例
- en: 'These are the available machine configuration choices when using the notebook
    option in AI Platform:'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 AI 平台使用笔记本选项时，以下是可用的机器配置选择：
- en: '![Figure 2.5 – Available options for the machine instance'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 2.5 – 可用的机器实例选项'
- en: '](img/Figure_2.5.jpg)'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.5.jpg)'
- en: Figure 2.5 – Available options for the machine instance
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.5 – 可用的机器实例选项
- en: 'The Notebook instance will be available within a few minutes after clicking
    **CREATE**:'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 点击**创建**后，几分钟内笔记本实例将可用：
- en: '![Figure 2.6 – Instance going live and ready'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 2.6 – 实例上线并准备就绪'
- en: '](img/Figure_2.6.jpg)'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.6.jpg)'
- en: Figure 2.6 – Instance going live and ready
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.6 – 实例上线并准备就绪
- en: 'When the instance is ready, **OPEN JUPYTERLAB** will be activated and you may
    click on it. Clicking on it will lead you to a JupyterLab notebook:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当实例准备就绪时，**打开 JUPYTERLAB** 将被激活，您可以点击它。点击后会进入 JupyterLab 笔记本：
- en: '![Figure 2.7 – JupyterLab environment'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.7 – JupyterLab 环境'
- en: '](img/Figure_2.7.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.7.jpg)'
- en: Figure 2.7 – JupyterLab environment
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 – JupyterLab 环境
- en: We will use Python 3 for all our examples.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Python 3 来展示所有示例。
- en: Deep Learning Virtual Machine Image
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习虚拟机镜像
- en: 'If you wish to have more options, such as different GPU choices, then DLVM
    is a better choice. You may find these references helpful:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望有更多选项，例如不同的 GPU 选择，那么 DLVM 是更好的选择。你可能会发现以下参考资料有帮助：
- en: '[https://cloud.google.com/ai-platform/deep-learning-vm/docs/quickstart-cli](https://cloud.google.com/ai-platform/deep-learning-vm/docs/quickstart-cli)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/ai-platform/deep-learning-vm/docs/quickstart-cli](https://cloud.google.com/ai-platform/deep-learning-vm/docs/quickstart-cli)'
- en: '[https://cloud.google.com/ai-platform/deep-learning-vm/docs/quickstart-marketplace](https://cloud.google.com/ai-platform/deep-learning-vm/docs/quickstart-marketplace)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://cloud.google.com/ai-platform/deep-learning-vm/docs/quickstart-marketplace](https://cloud.google.com/ai-platform/deep-learning-vm/docs/quickstart-marketplace)'
- en: 'Follow these steps to choose DLVM:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤选择 DLVM：
- en: Click **Marketplace** in the left panel:![Figure 2.8 – Google Cloud Platform
    Marketplace
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击左侧面板中的 **市场**：![图 2.8 – Google Cloud Platform 市场
- en: '](img/Figure_2.8.jpg)'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.8.jpg)'
- en: Figure 2.8 – Google Cloud Platform Marketplace
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.8 – Google Cloud Platform 市场
- en: Search for `Deep Learning VM` in the query box and you will see the following:![Figure
    2.9 – Enabling DLVM
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在查询框中搜索 `Deep Learning VM`，你将看到如下内容：![图 2.9 – 启用 DLVM
- en: '](img/Figure_2.9.jpg)'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.9.jpg)'
- en: Figure 2.9 – Enabling DLVM
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.9 – 启用 DLVM
- en: This is where you can launch a DLVM deployment.
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里是你可以启动 DLVM 部署的地方。
- en: Click on **LAUNCH**, and you will see many options available, including **Machine
    Type**, **GPU type**, and **Number of GPUs**:![Figure 2.10 – DLVM configuration
    portal
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **启动**，你将看到许多可用选项，包括 **机器类型**、**GPU 类型** 和 **GPU 数量**：![图 2.10 – DLVM 配置门户
- en: '](img/Figure_2.10.jpg)'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.10.jpg)'
- en: Figure 2.10 – DLVM configuration portal
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.10 – DLVM 配置门户
- en: 'Also, DLVM has many more frameworks besides TensorFlow Enterprise:'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，DLVM 除了 TensorFlow Enterprise 之外，还支持更多框架：
- en: '![Figure 2.11 – DLVM and options for frameworks'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 2.11 – DLVM 和框架选项'
- en: '](img/Figure_2.11.jpg)'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.11.jpg)'
- en: Figure 2.11 – DLVM and options for frameworks
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.11 – DLVM 和框架选项
- en: If you choose one of the two TensorFlow Enterprise frameworks, then click
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你选择其中一个 TensorFlow Enterprise 框架，然后点击
- en: '**CREATE**, you will be able to reach JupyterLab as you did previously:'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**创建**，你将能够像之前一样访问 JupyterLab：'
- en: '![Figure 2.12 – JupyterLab entry point'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.12 – JupyterLab 入口点'
- en: '](img/Figure_2.12.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.12.jpg)'
- en: Figure 2.12 – JupyterLab entry point
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12 – JupyterLab 入口点
- en: 'Here''s a suggestion. In order to minimize your cost, it is important to stop
    your instances after you are done. The quickest way to see what you have running
    is to choose **Compute Engine** in the left panel, and then select **VM instances**:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个建议。为了最小化成本，完成工作后，停止实例非常重要。查看正在运行的实例的最快方式是选择左侧面板中的 **计算引擎**，然后选择 **VM 实例**：
- en: '![Figure 2.13 – Compute instances in a subscription'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.13 – 订阅中的计算实例'
- en: '](img/Figure_2.13.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.13.jpg)'
- en: Figure 2.13 – Compute instances in a subscription
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.13 – 订阅中的计算实例
- en: 'From there you will see all the instances you have created. Stop them when
    you are done:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里你将看到所有已创建的实例。完成后停止它们：
- en: '![Figure 2.14 – Listing VM instances and managing their use'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.14 – 列出 VM 实例并管理其使用情况'
- en: '](img/Figure_2.14.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.14.jpg)'
- en: Figure 2.14 – Listing VM instances and managing their use
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.14 – 列出 VM 实例并管理其使用情况
- en: It is the user's responsibility to be aware of the instances that are running.
    As a good practice, when you are finished with your work, download or check in
    your notebook to save your work, and delete the instance when not in use.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 用户有责任关注正在运行的实例。作为良好的实践，完成工作后，下载或提交你的笔记本以保存工作，并在不使用时删除实例。
- en: Deep Learning Container (DLC)
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习容器 (DLC)
- en: This is a relatively more complicated way of using TensorFlow Enterprise. An
    important reason for using this approach is for cases where data is not stored
    in Google Cloud, and you wish to run TensorFlow Enterprise on-premises or in your
    local machine. Another reason is that for enterprise use, you may want to use
    DLC as a base Docker image to build your own Docker image for a specific use or
    distribution amongst your team. This is the way to run TensorFlow Enterprise outside
    of Google Cloud. Since it is a Docker image, it requires the Docker Engine installed,
    and the daemon running. It would be extremely helpful to have some basic understanding
    of Docker. You will find a full list of currently available DLCs at [https://console.cloud.google.com/gcr/images/deeplearning-platform-release](https://console.cloud.google.com/gcr/images/deeplearning-platform-release).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用TensorFlow Enterprise的一种相对复杂的方式。使用此方法的一个重要原因是，在数据不存储在Google Cloud的情况下，你希望在本地或本地机器上运行TensorFlow
    Enterprise。另一个原因是，对于企业使用，你可能希望将DLC作为基础Docker镜像来构建你自己的Docker镜像，以便为特定用途或在团队之间分发使用。这是运行TensorFlow
    Enterprise的方式，超出了Google Cloud的范围。由于它是一个Docker镜像，因此需要安装Docker引擎并运行守护进程。对Docker有一些基本了解将非常有帮助。你可以在[https://console.cloud.google.com/gcr/images/deeplearning-platform-release](https://console.cloud.google.com/gcr/images/deeplearning-platform-release)找到当前可用的DLC的完整列表。
- en: 'The goal is running a TensorFlow Enterprise JupyterLab. But since it is in
    a local machine, the URL to the JupyterLab is in the following format:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是运行TensorFlow Enterprise JupyterLab。但由于它是在本地计算机上运行，JupyterLab的URL格式如下：
- en: '`localhost:<LOCAL_PORT>`'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`localhost:<LOCAL_PORT>`'
- en: 'Here''s how we can accomplish this (for reference, see [https://cloud.google.com/ai-platform/deep-learning-containers/docs/getting-started-local](https://cloud.google.com/ai-platform/deep-learning-containers/docs/getting-started-local)):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们可以如何实现这一目标（参考：[https://cloud.google.com/ai-platform/deep-learning-containers/docs/getting-started-local](https://cloud.google.com/ai-platform/deep-learning-containers/docs/getting-started-local)）：
- en: 'Assuming a Docker daemon is running, we will execute the following command
    to run the TensorFlow Enterprise container:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设Docker守护进程正在运行，我们将执行以下命令来运行TensorFlow Enterprise容器：
- en: '[PRE0]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s understand the parts of the preceding command with the following table:'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们通过以下表格了解前面命令的各个部分：
- en: '![Figure 2.15 – Explaining the objects of the command to run the TensorFlow
    Enterprise container'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 2.15 – 解释运行TensorFlow Enterprise容器命令中的各个对象](img/Figure_2.15.jpg)'
- en: '](img/Figure_2.15.jpg)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.15.jpg)'
- en: Figure 2.15 – Explaining the objects of the command to run the TensorFlow Enterprise
    container
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.15 – 解释运行TensorFlow Enterprise容器命令中的各个对象
- en: 'In the preceding table, note the following:'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的表格中，注意以下几点：
- en: '`<LOCAL_PORT>` refers to the port number in the local machine to host this
    Docker image instance. It may be `8080`, or any other available port number that
    you wish to use, should `8080` be in use by another program or process already.'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<LOCAL_PORT>` 指的是本地计算机上用于托管该Docker镜像实例的端口号。如果`8080`已被其他程序或进程占用，可以使用任何其他可用的端口号。'
- en: '`<LOCAL_DIR>` is the path to the top-level directory where the training data
    and assets can be found. For a Windows machine, it may be `C:\Users\XXXX\Documents`.
    For Linux or Mac machine, it may be `/home/XXXX/Documents`.'
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<LOCAL_DIR>` 是指存放训练数据和资产的顶级目录的路径。对于Windows机器，它可能是 `C:\Users\XXXX\Documents`。对于Linux或Mac机器，它可能是
    `/home/XXXX/Documents`。'
- en: '`<CONTAINER_REGISTRY>` is where the Docker image can be found on the internet,
    and for the Docker container of our interest, it is in `gcr.io/deeplearning-platform-release/tf2-cpu.2-1`.'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<CONTAINER_REGISTRY>` 是指Docker镜像在互联网上的位置，对于我们关心的Docker容器，它位于`gcr.io/deeplearning-platform-release/tf2-cpu.2-1`。'
- en: 'Put these together in a command and run it from a terminal of a local machine
    (such as Windows Command Prompt):'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将这些组合在一起形成一个命令，并从本地计算机的终端（如Windows命令提示符）运行：
- en: '[PRE1]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now you may access the local port through your browser:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你可以通过浏览器访问本地端口：
- en: '`localhost:8080`'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`localhost:8080`'
- en: 'And you will see the JupyterLab running as a Docker container, as follows:'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后你将看到JupyterLab作为Docker容器运行，如下所示：
- en: '![Figure 2.16 – Docker image of JupyterLab running in a local or on-premises
    environment](img/Figure_2.16.jpg)'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 2.16 – JupyterLab在本地或本地环境中作为Docker镜像运行](img/Figure_2.16.jpg)'
- en: Figure 2.16 – Docker image of JupyterLab running in a local or on-premises environment
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.16 – JupyterLab在本地或本地环境中作为Docker镜像运行
- en: Let's take a look at the left panel first. The left panel shows all the local
    files and folders that you designated as `<LOCAL_DIR>`. In this case, it is `/temp/chapter2`
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先让我们看一下左侧面板。左侧面板显示了你指定为`<LOCAL_DIR>`的所有本地文件和文件夹。在这种情况下，它是`/temp/chapter2`
- en: The `-v` (or `--volume`) option maps the local directory to the `/home` directory
    of your Docker container instance. This is how local contents become accessible
    to your Docker container.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`-v`（或`--volume`）选项将本地目录映射到 Docker 容器实例的`/home`目录。这就是本地内容如何访问 Docker 容器的方式。'
- en: You can click on the `/home`:![Figure 2.17 – Docker image of JupyterLab reading
    local data
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以点击`/home`：![图 2.17 – JupyterLab 读取本地数据的 Docker 镜像
- en: '](img/Figure_2.17.jpg)'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.17.jpg)'
- en: Figure 2.17 – Docker image of JupyterLab reading local data
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.17 – JupyterLab 读取本地数据的 Docker 镜像
- en: You can also write data to the local directory:![Figure 2.18 – Docker image
    of JupyterLab writing data locally
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你还可以将数据写入本地目录：![图 2.18 – Docker 镜像中的 JupyterLab 写入本地数据
- en: '](img/Figure_2.18.jpg)'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.18.jpg)'
- en: '[PRE2]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Since you mapped `/home` with a local directory, you will also find the file
    in the local file explorer:'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于你将`/home`与本地目录映射，因此你也可以在本地文件资源管理器中找到该文件：
- en: '![Figure 2.19 – Local data written by JupyterLab running in a Docker image'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 2.19 – JupyterLab 在 Docker 镜像中运行时写入的本地数据'
- en: '](img/Figure_2.19.jpg)'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/Figure_2.19.jpg)'
- en: Figure 2.19 – Local data written by JupyterLab running in a Docker image
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2.19 – JupyterLab 在 Docker 镜像中运行时写入的本地数据
- en: 'Once you are done, in order to shut down the Docker image, you need to know
    the container ID assigned to this instance by your local Docker daemon. The command
    is as follows:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，为了关闭 Docker 镜像，你需要知道本地 Docker 守护进程为此实例分配的容器 ID。命令如下：
- en: '[PRE3]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'And it will return an output similar to this:'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 它将返回类似于以下的输出：
- en: '[PRE4]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Make a note of the `CONTAINER ID` value. Then use the following command to
    shut it down:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 记下`CONTAINER ID`的值。然后使用以下命令来关闭它：
- en: '[PRE5]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Suggestions for selecting workspaces
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择工作区的建议
- en: 'All three methods discussed in the previous section lead you to a JupyterLab
    that runs TensorFlow Enterprise. There are some differences and consequences to
    consider for each method:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节讨论的三种方法将你引导到运行 TensorFlow Enterprise 的 JupyterLab。每种方法都有一些差异和需要考虑的后果：
- en: The Docker image running locally is preferred for local data access.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地运行的 Docker 镜像更适合进行本地数据访问。
- en: The DLC can serve as a base image for creating a new enterprise-specific image.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DLC 可以作为创建新的企业特定镜像的基础镜像。
- en: With the Docker image running locally, its advantage lies in its direct access
    to the local environment or data sources. We have seen how it can easily read
    and write data on a local node. This obviously cannot be easily achieved with
    the AI Platform environment. Therefore, if the training data and output are to
    stay on-premises or in the local environment, then this is the most sensible choice.
    The downside of this method is the overhead of setting up and managing your own
    Docker environment. Another reason for using the DLC is that big enterprises often
    need to have customizable environments. They may want to create their own Docker
    container on top of the DLC and later ask everyone in the company to use that
    container with Cloud AI Platform Notebook. Notebook supports the custom container
    mode, as long as that container is based on the DLC.
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在本地运行的 Docker 镜像的优势在于它能直接访问本地环境或数据源。我们已经看到它如何轻松地在本地节点上读取和写入数据。显然，这在 AI 平台环境中无法轻松实现。因此，如果训练数据和输出需要保留在本地或本地环境中，那么这是最明智的选择。此方法的缺点是设置和管理自己的
    Docker 环境的开销。使用 DLC 的另一个原因是，大型企业通常需要可定制的环境。它们可能希望在 DLC 基础上创建自己的 Docker 容器，并随后要求公司中的每个人都使用该容器与
    Cloud AI Platform Notebook。Notebook 支持自定义容器模式，只要该容器是基于 DLC 的。
- en: Use DLVM if you want to customize compute instance cores, memory, and disk resources.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你想自定义计算实例核心、内存和磁盘资源，请使用 DLVM。
- en: If you want to configure the CPU, GPU, memory, or disk resources for the workload,
    then DLVM is the method of choice.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你想为工作负载配置 CPU、GPU、内存或磁盘资源，那么 DLVM 是首选方法。
- en: Use the default notebook environment for most general needs.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于大多数一般需求，使用默认的笔记本环境。
- en: With AI Platform, the notebook environment obviously has direct access to cloud
    storage such as bucket containers or BigQuery tables. If it is not essential to
    pick and choose your CPU or GPU configurations, then the AI Platform Notebook
    would definitely suffice.
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用AI平台时，笔记本环境显然可以直接访问云存储，如存储桶容器或BigQuery表。如果不需要特别选择CPU或GPU配置，AI平台的笔记本环境完全足够。
- en: What we have learned so far are the three different environments for users to
    start using Google's AI Platform and consume the TensorFlow Enterprise distribution.
    By and large, these methods all provide a consistent user experience and runtime
    distribution of the TensorFlow Enterprise library. The rationale for choosing
    a method is grounded in your need for data access and compute resource configurations.
    If the training data is on-premises or on your local disks, then the Docker image
    is the preferred method. If compute resources and speed are the primary concerns,
    then DLVM is the preferred choice.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了三种不同的环境，供用户开始使用Google的AI平台并消费TensorFlow Enterprise发行版。总的来说，这些方法都提供了一致的用户体验和TensorFlow
    Enterprise库的运行时分发。选择方法的理由主要基于数据访问和计算资源配置的需求。如果训练数据存储在本地或本地磁盘上，那么Docker镜像是首选方法。如果计算资源和速度是主要关注点，那么DLVM是首选。
- en: Now, having arrived at AI Platform and its notebook environment, as a starter,
    we are going to take a closer look at a common example of using AI Platform to
    access data in BigQuery and build your own training data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，已经进入AI平台及其笔记本环境，作为入门，我们将仔细查看一个常见的示例，演示如何使用AI平台访问BigQuery中的数据，并构建自己的训练数据。
- en: Easy parameterized data extraction from BigQuery
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从BigQuery中轻松提取参数化数据
- en: Very often, your enterprise data warehouse contains the sources for you to build
    your own training data, and simple SQL query commands would meet your requirements
    for row and column selection and feature transformation. So let's take a look
    at a convenient, flexible, and fast way of selecting and manipulating original
    data through SQL queries, where the result of the query is a pandas DataFrame.
    We have already seen how to use the `%%bigquery` interpreter to execute a query
    and return the result as a pandas DataFrame. We now will look at how to pass in
    query parameters so users may explore and select data suitable for model training.
    The following example uses one of the public datasets, `covid19_juh_csse`, and
    its `summary` table.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 很多时候，您的企业数据仓库包含了用于构建自己训练数据的来源，而简单的SQL查询命令就能满足行列选择和特征转换的需求。所以让我们看看一种方便、灵活、快速的方式，通过SQL查询选择和操作原始数据，其中查询结果是一个pandas
    DataFrame。我们已经看到如何使用`%%bigquery`解释器执行查询并将结果返回为pandas DataFrame。接下来，我们将学习如何传入查询参数，以便用户可以探索和选择适合模型训练的数据。以下示例使用的是一个公共数据集`covid19_juh_csse`及其`summary`表。
- en: 'This table has the following structure:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 该表具有以下结构：
- en: '![Figure 2.20 – A table’s schema as shown using BigQuery'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.20 – 使用BigQuery显示的表结构'
- en: '](img/Figure_2.20.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.20.jpg)'
- en: Figure 2.20 – A table's schema using BigQuery
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.20 – 使用BigQuery显示的表结构
- en: 'In the JupyterLab provided by any of the three methods discussed earlier, you
    may execute the following steps to perform parameterized queries:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面提到的任何三种方法提供的JupyterLab环境中，您可以执行以下步骤来进行参数化查询：
- en: 'Define a set of parameters in a JSON-compatible format, that is, a key-value
    pair as in a Python dictionary:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一组JSON兼容格式的参数，即键值对，如同Python字典：
- en: '[PRE6]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Construct the query and assign it to a DataFrame by name. Notice how each key
    in the parameter is referenced in the query with a preceding `@`:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建查询并通过名称将其分配给DataFrame。注意查询中每个参数键如何通过前缀`@`来引用：
- en: '[PRE7]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Examine the data:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查数据：
- en: '[PRE8]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'And the following is the output of the aggregation command, which demonstrates
    the total results by country:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是聚合命令的输出，显示了按国家汇总的结果：
- en: '![Figure 2.21 – Output of the aggregation command from the notebook'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.21 – 从笔记本中聚合命令的输出'
- en: '](img/Figure_2.21.jpg)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.21.jpg)'
- en: Figure 2.21 – Output of the aggregation command from the notebook
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.21 – 从笔记本中聚合命令的输出
- en: 'We may confirm the data structure of our data object using Python''s `type`
    command:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用Python的`type`命令来确认数据对象的结构：
- en: '[PRE9]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'And it confirms the object being a pandas DataFrame:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 并确认该对象为pandas DataFrame：
- en: '![Figure 2.22 – Output from type(myderiveddata)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.22 – type(myderiveddata)的输出'
- en: '](img/B16070_02_021.png)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16070_02_021.png)'
- en: Figure 2.22 – Output from type(myderiveddata)
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.22 – type(myderiveddata)的输出
- en: The DataFrame may be serialized as a pickle file for future use. Once converted
    to the pickle format, you may persist it in the cloud storage as demonstrated
    in the previous chapter.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 可以被序列化为 pickle 文件以供未来使用。一旦转换为 pickle 格式，你可以将其持久化存储在云存储中，如上一章所示。
- en: 'Here are the key takeaways:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是关键要点：
- en: Parameterized querying enables quick and easy data selection and manipulation
    for building training data as a pandas DataFrame.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数化查询使得数据选择和操作变得快速简便，适用于构建训练数据作为 pandas DataFrame。
- en: Parameters are wrapped in a Python dictionary and can be passed into the query
    string during execution.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数被封装在 Python 字典中，并可以在执行过程中传递到查询字符串中。
- en: The query string can refer to the parameter with the `@` operator.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询字符串可以通过 `@` 运算符引用参数。
- en: Putting it together
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 汇总
- en: 'The following is the complete code snippet for the quick example we just worked
    with:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们刚刚处理的快速示例的完整代码片段：
- en: '[PRE10]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The output is shown in *Figure 2.23*:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如 *图 2.23* 所示：
- en: '![Figure 2.23 – Output from BigQuery and compatibility with pandas DataFrame
    format'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.23 – 来自 BigQuery 的输出及与 pandas DataFrame 格式的兼容性'
- en: '](img/Figure_2.22.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/Figure_2.22.jpg)'
- en: Figure 2.23 – Output from BigQuery and compatibility with pandas DataFrame format
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.23 – 来自 BigQuery 的输出及与 pandas DataFrame 格式的兼容性
- en: As the preceding steps demonstrate, the notebook environment is integrated closely
    with BigQuery. As a result, an inline query with SQL produces a DataFrame that
    is ready for use in Python. This further demonstrates the flexibility of the Google
    Cloud AI Platform Notebook environment.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面步骤所示，笔记本环境与 BigQuery 紧密集成。因此，使用 SQL 执行的内联查询将生成一个准备好在 Python 中使用的 DataFrame。这进一步展示了
    Google Cloud AI Platform Notebook 环境的灵活性。
- en: Summary
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, you have learned how to launch the JupyterLab environment
    to run TensorFlow Enterprise. TensorFlow Enterprise is available in three different
    forms: AI Platform Notebook, DLVM, and a Docker container. The computing resources
    used by these methods can be found in the Google Cloud Compute Engine panel. These
    compute nodes do not shut down on their own, therefore it is important to stop
    or delete them once you are done using them.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你已经学习了如何启动 JupyterLab 环境来运行 TensorFlow Enterprise。TensorFlow Enterprise
    以三种不同的形式提供：AI Platform Notebook、DLVM 和 Docker 容器。这些方法使用的计算资源可以在 Google Cloud Compute
    Engine 面板中找到。这些计算节点不会自动关闭，因此在使用完毕后，务必停止或删除它们。
- en: The BigQuery command tool is seamlessly integrated with the TensorFlow Enterprise
    environment. Parameterized data extraction via the use of a SQL query string enables
    the quick and easy creation of a derived dataset and feature selection.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: BigQuery 命令工具与 TensorFlow Enterprise 环境无缝集成。通过使用 SQL 查询字符串进行参数化数据提取，可以快速便捷地创建派生数据集并进行特征选择。
- en: TensorFlow Enterprise works even when your data is not yet in Google Cloud storage.
    By pulling and running the TensorFlow Enterprise Docker container, you can use
    it with on-premises or local data sources.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 即使数据尚未存储在 Google Cloud 中，TensorFlow Enterprise 仍然可以工作。通过拉取并运行 TensorFlow Enterprise
    Docker 容器，你可以将其与本地或本地数据源一起使用。
- en: Now that you have seen how to leverage data availability and accessibility for
    TensorFlow Enterprise consumption, in the next chapter, we are going to examine
    some common data transformation, serialization, and storage techniques optimized
    for TensorFlow Enterprise consumption and model training pipelines.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了如何利用数据的可用性和可访问性进行 TensorFlow Enterprise 的使用，接下来我们将探讨一些常见的数据转换、序列化和存储技术，这些技术经过优化，适用于
    TensorFlow Enterprise 的使用和模型训练流程。
