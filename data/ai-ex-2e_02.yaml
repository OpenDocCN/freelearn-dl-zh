- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Building a Reward Matrix – Designing Your Datasets
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建奖励矩阵 – 设计你的数据集
- en: Experimenting and implementation comprise the two main approaches of artificial
    intelligence. Experimenting largely entails trying ready-to-use datasets and black
    box, ready-to-use Python examples. Implementation involves preparing a dataset,
    developing preprocessing algorithms, and then choosing a model, the proper parameters,
    and hyperparameters.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 实验和实现是人工智能的两种主要方法。实验主要包括尝试现成的数据集和黑盒、现成的Python示例。实现则包括准备数据集、开发预处理算法，然后选择模型、适当的参数和超参数。
- en: Implementation usually involves white box work that entails knowing exactly
    how an algorithm works and even being able to modify it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 实现通常涉及白盒工作，这需要精确了解算法的工作原理，甚至能够修改它。
- en: In *Chapter 1*, *Getting Started with Next-Generation Artifcial Intelligence
    through Reinforcement Learning*, the MDP-driven Bellman equation relied on a reward
    matrix. In this chapter, we will get our hands dirty in a white box process to
    create that reward matrix.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第一章*，*通过强化学习开始使用下一代人工智能*中，基于MDP（马尔可夫决策过程）的贝尔曼方程依赖于奖励矩阵。在本章中，我们将深入探讨创建奖励矩阵的白盒过程。
- en: An MDP process cannot run without a reward matrix. The reward matrix determines
    whether it is possible to go from one cell to another, from A to B. It is like
    a map of a city that tells you if you are allowed to take a street or if it is
    a one-way street, for example. It can also set a goal, such as a place that you
    would like to visit in a city, for example.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: MDP过程无法在没有奖励矩阵的情况下运行。奖励矩阵决定了是否可以从一个单元移动到另一个单元，从A到B。例如，它就像城市地图一样，告诉你是否可以走某条街，或者那条街是否是单行道。它还可以设定一个目标，比如在城市中你想去的某个地方。
- en: To achieve the goal of designing a reward matrix, the raw data provided by other
    systems, software, and sensors needs to go through **preprocessing**. A machine
    learning program will not provide efficient results if the data has not gone through a **standardization**
    process.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现设计奖励矩阵的目标，其他系统、软件和传感器提供的原始数据需要经过**预处理**。如果数据没有经过**标准化**处理，机器学习程序将无法提供有效的结果。
- en: The reward matrix, *R*, will be built using a McCulloch-Pitts neuron in TensorFlow.
    Warehouse management has grown exponentially as e-commerce has taken over many
    marketing segments. This chapter introduces automated guided vehicles (AGVs),
    the equivalent of an SDC in a warehouse to store and retrieve products.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 奖励矩阵，*R*，将使用TensorFlow中的McCulloch-Pitts神经元来构建。随着电子商务在许多市场领域的崛起，仓库管理也呈现出爆炸式增长。本章介绍了自动导引车（AGV），它是仓库中用于存取产品的相当于SDC（自动存取设备）的系统。
- en: The challenge in this chapter will be to understand the preprocessing phase
    in detail. The quality of the processed dataset will influence directly the accuracy
    of any machine learning algorithm.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的挑战是详细理解预处理阶段。处理后的数据集质量将直接影响任何机器学习算法的准确性。
- en: 'This chapter covers the following topics:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: The McCulloch-Pitts neuron will take the raw data and transform it
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McCulloch-Pitts神经元将处理原始数据并对其进行转换
- en: Logistic classifiers will begin the neural network process
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归分类器将启动神经网络过程
- en: The logistic sigmoid will squash the values
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑 sigmoid 将压缩这些值
- en: The softmax function will normalize the values
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: softmax函数将对值进行归一化处理
- en: The one-hot function will choose the target for the reward matrix
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: one-hot函数将选择奖励矩阵的目标
- en: An example of AGVs in a warehouse
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仓库中AGV（自动导引车）的示例
- en: The topics form a list of tools that, in turn, form a pipeline that will take
    raw data and transform it into a reward matrix—an MDP.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这些主题构成了一系列工具，这些工具又形成了一个管道，将原始数据转换为奖励矩阵——一个MDP。
- en: Designing datasets – where the dream stops and the hard work begins
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计数据集 – 梦想停止的地方，艰苦工作的开始
- en: As in the previous chapter, bear in mind that a real-life project goes through
    a three-dimensional method in some form or other. First, it's important to think
    and talk about the problem in need of solving without jumping onto a laptop. Once
    that is done, bear in mind that the foundation of machine learning and deep learning
    relies on mathematics. Finally, once the problem has been discussed and mathematically
    represented, it is time to develop the solution.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如同上一章所述，请记住，现实生活中的项目在某种形式下都会经历三维方法。首先，重要的是在不急于打开笔记本电脑的情况下，先思考和讨论需要解决的问题。完成这一步后，请记住，机器学习和深度学习的基础依赖于数学。最后，一旦问题被讨论并进行了数学表示，就可以开始开发解决方案。
- en: First, think of a problem in **natural language**. Then, make a **mathematical
    description** of a problem. Only then should you begin the **software implementation**.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，考虑一个**自然语言**的问题。然后，做出该问题的**数学描述**。只有在此之后，才应开始**软件实现**。
- en: Designing datasets
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计数据集
- en: The reinforcement learning program described in the first chapter can solve
    a variety of problems involving unlabeled classification in an unsupervised decision-making
    process. The Q function can be applied to drone, truck, or car deliveries. It
    can also be applied to decision making in games or real life.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 第一章中描述的强化学习程序可以解决多种涉及无标签分类的无监督决策问题。Q 函数可以应用于无人机、卡车或汽车配送，也可以应用于游戏或现实生活中的决策。
- en: However, in a real-life case study problem (such as defining the reward matrix
    in a warehouse for the AGV, for example), the difficulty will be to produce an
    efficient matrix using the proper **features**.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在一个实际案例研究问题中（例如，在仓库中为 AGV 定义奖励矩阵），难点在于使用合适的 **特征**生成一个高效的矩阵。
- en: 'For example, an AGV requires information coming from different sources: daily
    forecasts and real-time warehouse flows.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，AGV 需要来自不同来源的信息：每日预测和实时仓库流量。
- en: The warehouse manages thousands of locations and hundreds of thousands of inputs
    and outputs. Trying to fit too many features into the model would be counterproductive.
    Removing both features and worthless data requires careful consideration.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 仓库管理着成千上万个位置和数十万个输入输出。将过多的特征塞入模型会适得其反。移除特征和无价值的数据需要谨慎考虑。
- en: A simple neuron can provide an efficient way to attain the **standardization**
    of the input data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的神经元可以提供一种高效的方法来实现输入数据的**标准化**。
- en: Machine learning and deep learning are frequently used to preprocess input data
    for standardization purposes, normalization, and feature reduction.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习和深度学习常常用于预处理输入数据，以实现标准化、归一化和特征减少。
- en: Using the McCulloch-Pitts neuron
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 McCulloch-Pitts 神经元
- en: To create the reward matrix, *R*, a robust model for processing the inputs of
    the huge volumes in a warehouse must be reduced to a limited number of features.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建奖励矩阵 *R*，需要将仓库中处理巨大数据量的强大模型简化为有限数量的特征。
- en: 'In one model, for example, the thousands to hundreds of thousands of inputs
    can be described as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个模型中，例如，成千上万的输入可以描述如下：
- en: 'Forecast product arrivals with a low priority weight: *w*[1] = 10'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低优先级权重的预测产品到达：*w*[1] = 10
- en: 'Confirmed arrivals with a high priority weight: *w*[2] = 70'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高优先级权重的确认到达：*w*[2] = 70
- en: 'Unplanned arrivals decided by the sales department: *w*[3] = 75'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 销售部门决定的非计划到达：*w*[3] = 75
- en: 'Forecasts with a high priority weight: *w*[4] = 60'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高优先级权重的预测：*w*[4] = 60
- en: 'Confirmed arrivals that have a low turnover and so have a low weight: *w*[5]
    = 20'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低周转率的确认到达，因此权重较低：*w*[5] = 20
- en: The weights have been provided as constants. A McCulloch-Pitts neuron does not
    modify weights. A perceptron neuron does as we will see beginning with *Chapter
    8*, *Solving the XOR Problem with a Feedforward Neural Network*. Experience shows
    that modifying weights is not always necessary.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 权重已作为常量提供。McCulloch-Pitts 神经元不会修改权重。Perceptron 神经元会修改权重，正如我们将在*第八章*中看到的，*通过前馈神经网络解决
    XOR 问题*。经验表明，修改权重并非总是必要的。
- en: 'These weights form a vector, as shown here:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些权重形成一个向量，如下所示：
- en: '![](img/B15438_02_001.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_02_001.png)'
- en: Each element of the vector represents the weight of a feature of a product stored
    in optimal locations. The ultimate phase of this process will produce a reward
    matrix, *R*, for an MDP to optimize itineraries between warehouse locations.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 向量的每个元素代表存储在最佳位置的产品特征的权重。该过程的最终阶段将生成一个奖励矩阵 *R*，用于优化 MDP 中仓库位置之间的路径。
- en: Let's focus on our neuron. These weights, used through a system such as this
    one, can attain up to more than 50 weights and parameters per neuron. In this
    example, 5 weights are implemented. However, in real-life case, many other parameters
    come into consideration, such as unconfirmed arrivals, unconfirmed arrivals with
    a high priority, confirmed arrivals with a very low priority, arrivals from locations
    that probably do not meet security standards, arrivals with products that are
    potentially dangerous and require special care, and more. At that point, humans
    and even classical software cannot face such a variety of parameters.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们关注我们的神经元。这些权重，像这样的系统使用时，每个神经元可以达到超过 50 个权重和参数。在这个例子中，实现了 5 个权重。然而，在现实生活中，许多其他参数需要考虑，比如未确认的到达、具有高优先级的未确认到达、低优先级的已确认到达、来自可能不符合安全标准位置的到达、包含潜在危险且需要特别处理的到达等等。到那时，人类甚至经典软件也无法应对如此多样化的参数。
- en: The reward matrix will be size 6×6\. It contains six locations, A to F. In this
    example, the six locations, `l1` to `l6`, are warehouse storage and retrieval
    locations.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 奖励矩阵的大小将是 6×6。它包含六个位置，A 到 F。在此示例中，六个位置，`l1` 到 `l6`，是仓库存储和取货位置。
- en: A 6×6 reward matrix represents the target of the McCulloch-Pitts layer implemented
    for the six locations.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 6×6 的奖励矩阵表示为六个位置实现的 McCulloch-Pitts 层的目标。
- en: When experimenting, the reward matrix, *R*, can be invented for testing purposes.
    In real-life implementations, you will have to find a way to build datasets from
    scratch. The reward matrix becomes the output of the preprocessing phase. The
    following source code shows the input of the reinforcement learning program used
    in the first chapter. The goal of this chapter describes how to produce the following
    reward matrix that we will be building in the next sections.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验过程中，奖励矩阵 *R* 可以用于测试目的进行构造。在现实生活中的实现中，你需要找到从头开始构建数据集的方法。奖励矩阵将成为预处理阶段的输出。以下源代码展示了第一章中使用的强化学习程序的输入。本章的目标是描述如何生成接下来几节中将构建的奖励矩阵。
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For the warehouse example that we are using as for any other domain, the McCulloch-Pitts
    neuron sums up the weights of the input vector described previously to fill in
    the reward matrix.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们正在使用的仓库示例，和任何其他领域一样，McCulloch-Pitts 神经元会对之前描述的输入向量的权重进行求和，从而填充奖励矩阵。
- en: Each location will require its neuron, with its weights.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 每个位置都需要其独立的神经元及其权重。
- en: '*INPUTS* -> *WEIGHTS* -> *BIAS* -> *VALUES*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*输入* -> *权重* -> *偏置* -> *值*'
- en: Inputs are the flows in a warehouse or any form of data.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入是仓库中的流量或任何形式的数据。
- en: Weights will be defined in this model.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 权重将在此模型中定义。
- en: Bias is for stabilizing the weights. Bias does exactly what it means. It will
    tilt weights. It is very useful as a referee that will keep the weights on the
    right track.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 偏置用于稳定权重。偏置的作用正如其字面意思，它会倾斜权重。它非常有用，充当一个裁判，确保权重保持在正确的轨道上。
- en: Values will be the output.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值将是输出。
- en: There are as many ways as you can imagine to create reward matrices. This chapter
    describes one way of doing it that works.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 创建奖励矩阵的方法有很多种，只要你能想象出来。本章描述了一种有效的方法。
- en: The McCulloch-Pitts neuron
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: McCulloch-Pitts 神经元
- en: The McCulloch-Pitts neuron dates back to 1943\. It contains inputs, weights,
    and an activation function. Part of the preprocessing phase consists of selecting
    the right model. The McCulloch-Pitts neuron can represent a given location efficiently.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: McCulloch-Pitts 神经元可以追溯到 1943 年。它包含输入、权重和激活函数。预处理阶段的一部分是选择合适的模型。McCulloch-Pitts
    神经元能够高效地表示给定的位置。
- en: 'The following diagram shows the McCulloch-Pitts neuron model:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了 McCulloch-Pitts 神经元模型：
- en: '![https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_02_01-2.png](img/B15438_02_01.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_02_01-2.png](img/B15438_02_01.png)'
- en: 'Figure 2.1: The McCulloch-Pitts neuron model'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1：McCulloch-Pitts 神经元模型
- en: This model contains several input *x* weights that are summed to either reach
    a threshold that will lead, once transformed, to the output, *y* = 0, or 1\. In
    this model, *y* will be calculated in a more complex way.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型包含多个输入 *x* 权重，这些权重被求和，直到达到一个阈值，经过变换后将输出 *y* = 0 或 1。在此模型中，*y* 将以更复杂的方式计算。
- en: '`MCP.py` written with TensorFlow 2 will be used to illustrate the neuron.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 2 编写的 `MCP.py` 将用于说明神经元。
- en: 'In the following source code, the TensorFlow variables will contain the input
    values (`x`), the weights (`W`), and the bias (`b`). Variables represent the structure
    of your graph:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下源代码中，TensorFlow 变量将包含输入值（`x`）、权重（`W`）和偏置（`b`）。变量代表图形的结构：
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the original McCulloch-Pitts artificial neuron, the inputs (*x*) were multiplied
    by the following weights:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在原始的 McCulloch-Pitts 人工神经元中，输入（*x*）与以下权重相乘：
- en: '![](img/B15438_02_002.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_02_002.png)'
- en: 'The mathematical function becomes a function with the neuron code triggering
    a logistic activation function (sigmoid), which will be explained in the second
    part of the chapter. Bias (`b`) has been added, which makes this neuron format
    useful even today, shown as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 数学函数变为一个通过神经元代码触发的逻辑激活函数（sigmoid），将在本章第二部分中解释。已添加偏置（`b`），使得这一神经元格式至今仍然有效，如下所示：
- en: '[PRE2]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Before starting a session, the McCulloch-Pitts neuron (1943) needs an operator
    to set its weights. That is the main difference between the McCulloch-Pitts neuron
    and the perceptron (1957), which is the model for modern deep learning neurons.
    The perceptron optimizes its weights through optimizing processes. *Chapter 8*,
    *Solving the XOR Problem with a Feedforward Neural Network*, describes why a modern
    perceptron was required.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动会话之前，McCulloch-Pitts 神经元（1943）需要操作员设置其权重。这是 McCulloch-Pitts 神经元与感知器（1957）之间的主要区别，后者是现代深度学习神经元的模型。感知器通过优化过程来优化其权重。*第八章*，*使用前馈神经网络解决
    XOR 问题*，解释了为什么需要现代感知器。
- en: 'The weights are now provided, and so are the quantities for each input value,
    which are stored in the *x* vector at *l*[1], one of the six locations of this
    warehouse example:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 权重现已提供，输入值的数量也已提供，这些值存储在 *l*[1] 的 *x* 向量中，*l*[1] 是此仓库示例中的六个位置之一：
- en: '![](img/B15438_02_001.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_02_001.png)'
- en: 'The weight values will be divided by 100, to represent percentages in terms
    of 0 to 1 values of warehouse flows in a given location. The following code deals
    with the choice of *one* location, *l*[1] **only**, its values, and parameters:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 权重值将除以 100，以表示仓库流量在给定位置的 0 到 1 之间的百分比。以下代码处理的是选择一个位置，*l*[1] **仅**，其值和参数：
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The neuron function is called, and the weights (`w_t`) and the quantities (`x_1`)
    of the warehouse flow are entered. Bias is set to `1` in this model. No session
    needs to be initialized; the neuron function is called:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 调用神经元函数，并输入仓库流量的权重（`w_t`）和数量（`x_1`）。在此模型中，偏置设置为 `1`。无需初始化会话；只需调用神经元函数：
- en: '[PRE4]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The neuron function `neuron` will calculate the value of the neuron. The program
    returns the following value:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 神经元函数 `neuron` 将计算神经元的值。程序返回以下值：
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This value represents the activity of location *l*[1] at a given date and a
    given time. This example represents only one of the six locations to compute.
    For this location, the higher the value, the closer to 1, the higher the probable
    saturation rate of this area. This means there is little space left to store products
    at that location. That is why the reinforcement learning program for a warehouse
    is looking for the **least loaded** area for a given product in this model.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 该值表示位置 *l*[1] 在特定日期和特定时间的活动情况。此示例仅表示需要计算的六个位置中的一个。对于该位置，值越高，接近 1，表明该区域的饱和率越高。这意味着该位置几乎没有空间用于存储产品。这就是为什么仓库的强化学习程序在此模型中会寻找某一产品在给定时间内的**最少负载**区域。
- en: 'Each location has a probable **availability**:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 每个位置都有一个可能的**可用性**：
- en: '*A* = Availability = 1 – load'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '*A* = 可用性 = 1 – 负载'
- en: The probability of a load of a given storage point lies between 0 and 1.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 给定存储点的负载概率介于 0 和 1 之间。
- en: 'High values of availability will be close to 1, and low probabilities will
    be close to 0, as shown in the following example:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 高可用性值接近 1，而低概率值接近 0，如下例所示：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: For example, the load of *l*[1] has a probable rounded load of 0.99, and its
    probable *availability* is 0.002 maximum. The goal of the AGV is to search and
    find the closest and most available location to optimize its trajectories. *l*[1]
    is not a good candidate at that day and time. **Load** is a keyword in production
    or service activities. The less available resources have the highest load rate.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，*l*[1] 的负载可能为 0.99，且其最大**可用性**为 0.002。AGV 的目标是搜索并找到最近且最具可用性的地点，以优化其轨迹。在该日期和时间，*l*[1]
    不是一个好的选择。**负载**是生产或服务活动中的一个关键字。资源越不可用，负载率越高。
- en: 'When all six locations'' availabilities have been calculated by the McCulloch-Pitts
    neuron—each with its respective quantity inputs, weights, and bias—a location
    vector of the results of this system will be produced. Then, the program needs
    to be implemented to run all six locations and not just one location through a
    recursive use of the one neuron model:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有六个位置的可用性通过 McCulloch-Pitts 神经元计算完成——每个位置都有其各自的输入量、权重和偏差——该系统的结果将生成一个位置向量。然后，程序需要实现通过递归使用单一神经元模型来运行所有六个位置，而不仅仅是一个位置：
- en: '*A*(*L*) = {*a*(*l*[1]),*a*(*l*[2]),*a*(*l*[3]),*a*(*l*[4]),*a*(*l*[5]),*a*(*l*[6])}'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*A*(*L*) = {*a*(*l*[1]), *a*(*l*[2]), *a*(*l*[3]), *a*(*l*[4]), *a*(*l*[5]),
    *a*(*l*[6])}'
- en: The availability, 1 – *output value of the neuron*, constitutes a six-line vector.
    The following vector, *l*[v], will be obtained by running the previous sample
    code on **all** six locations.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 可用性，1 – *神经元的输出值*，构成一个六维向量。以下的向量，*l*[v]，将在**所有**六个位置上运行之前的示例代码后获得。
- en: '![](img/B15438_02_004.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_02_004.png)'
- en: As shown in the preceding formula, *l*[v] is the vector containing the value
    of each location for a given AGV to choose from. The values in the vector represent
    availability. 0.0002 means little availability; 0.9 means high availability. With
    this choice, the MDP reinforcement learning program will optimize the AGV's trajectory
    to get to this specific warehouse location.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的公式所示，*l*[v] 是一个包含每个位置的值的向量，供给定 AGV 选择。向量中的值表示可用性。0.0002 表示可用性很低；0.9 表示可用性很高。通过这种选择，MDP
    强化学习程序将优化 AGV 的轨迹，以到达这个特定的仓库位置。
- en: The *l*[v] is the result of the weighing function of six potential locations
    for the AGV. It is also a vector of transformed inputs.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '*l*[v] 是 AGV 六个潜在位置的加权函数结果。它也是一个经过转换的输入向量。'
- en: The Python-TensorFlow architecture
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Python-TensorFlow 架构
- en: 'Implementation of the McCulloch-Pitts neuron can best be viewed as shown in
    the following graph:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: McCulloch-Pitts 神经元的实现可以最好地通过以下图表来展示：
- en: '![https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_02_02-3.png](img/B15438_02_02.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_02_02-3.png](img/B15438_02_02.png)'
- en: 'Figure 2.2: Implementation of the McCulloch-Pitts neuron'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2：McCulloch-Pitts 神经元的实现
- en: A data flow graph will also help optimize a program when things go wrong as
    in classical computing.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 数据流图还可以在出现问题时帮助优化程序，正如经典计算中那样。
- en: Logistic activation functions and classifiers
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Logistic 激活函数和分类器
- en: Now that the value of each location of *L* = {*l*[1], *l*[2], *l*[3], *l*[4],
    *l*[5], *l*[6]} contains its availability in a vector, the locations can be sorted
    from the most available to the least available location. From there, the reward
    matrix, *R*, for the MDP process described in *Chapter 1*, *Getting Started with
    Next-Generation Artifcial Intelligence through Reinforcement Learning*, can be
    built.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，*L* = {*l*[1], *l*[2], *l*[3], *l*[4], *l*[5], *l*[6]} 中包含每个位置的可用性值，所有位置可以从最可用到最不可用的顺序进行排序。接着，可以构建用于
    MDP 过程的奖励矩阵 *R*，该过程在 *第1章*《通过强化学习入门下一代人工智能》中描述。
- en: Overall architecture
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总体架构
- en: 'At this point, the overall architecture contains two main components:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，总体架构包含两个主要组件：
- en: '**Chapter 1**: A reinforcement learning program based on the value-action Q
    function using a reward matrix that will be finalized in this chapter. The reward
    matrix was provided in the first chapter as an experiment, but in the implementation
    phase, you''ll often have to build it from scratch. It sometimes takes weeks to
    produce a good reward matrix.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**第1章**：基于值-动作 Q 函数的强化学习程序，使用奖励矩阵，该矩阵将在本章最终确定。奖励矩阵在第一章中作为实验提供，但在实现阶段，您通常需要从头开始构建它。有时，制作一个好的奖励矩阵可能需要几周的时间。'
- en: '**Chapter 2**: Designing a set of 6×1 neurons that represents the flow of products
    at a given time at six locations. The output is the availability probability from
    0 to 1\. The highest value indicates the highest availability. The lowest value
    indicates the lowest availability.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**第2章**：设计一组 6×1 神经元，表示在六个位置上某一时刻的产品流。输出是从 0 到 1 的可用性概率。最高值表示最高可用性，最低值表示最低可用性。'
- en: 'At this point, there is some real-life information we can draw from these two
    main functions through an example:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以通过一个示例从这两个主要功能中提取一些现实生活中的信息：
- en: An AGV is automatically moving in a warehouse and is waiting to receive its
    next location to use an MDP, to calculate the optimal trajectory of its mission.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台 AGV 正在自动移动在仓库中，并等待接收下一个位置，以使用 MDP 来计算任务的最优轨迹。
- en: An AGV is using a reward matrix, *R*, that was given during the experimental
    phase but needed to be designed during the implementation process.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台 AGV 使用在实验阶段提供的奖励矩阵 *R*，但需要在实施过程中进行设计。
- en: A system of six neurons, one per location, weighing the real quantities and probable
    quantities to give an availability vector, *l*[v], has been calculated. It is
    almost ready to provide the necessary reward matrix for the AGV.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已计算出一个六个神经元的系统，每个神经元对应一个位置，权衡实际数量和可能数量，给出一个可用性向量 *l*[v]。它几乎准备好为 AGV 提供所需的奖励矩阵。
- en: To calculate the input values of the reward matrix in this reinforcement learning
    warehouse model, a bridge function between *l*[v] and the reward matrix, *R*,
    is missing.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个强化学习仓库模型中，为了计算奖励矩阵的输入值，缺少一个连接 *l*[v] 和奖励矩阵 *R* 的桥接函数。
- en: That bridge function is a logistic classifier based on the outputs of the *n*
    neurons that all perform the same tasks independently or recursively with one
    neuron.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 该桥接函数是一个基于 *n* 个神经元输出的逻辑分类器，这些神经元独立或递归地执行相同的任务，且每个神经元仅执行一次。
- en: 'At this point, the system:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，系统：
- en: Took corporate data
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取企业数据
- en: Used *n* neurons calculated with weights
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用了计算过权重的 *n* 个神经元
- en: Applied an activation function
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用了激活函数
- en: The activation function in this model requires a logistic classifier, a commonly
    used one.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 此模型中的激活函数要求使用一个常用的逻辑分类器。
- en: Logistic classifier
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑分类器
- en: 'The logistic classifier will be applied to *l*[v] (the six location values)
    to find the best location for the AGV. This method can be applied to any other
    domain. It is based on the output of the six neurons as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑分类器将应用于 *l*[v]（六个位置值），以找到 AGV 的最佳位置。此方法可以应用于任何其他领域。它基于六个神经元的输出，如下所示：
- en: '*input* × *weight* + *bias*'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*输入* × *权重* + *偏置*'
- en: What are logistic functions? The goal of a logistic classifier is to produce
    a probability distribution from 0 to 1 for each value of the output vector. As
    you have seen so far, artificial intelligence applications use applied mathematics
    with probable values, not raw outputs.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑函数是什么？逻辑分类器的目标是为输出向量的每个值生成一个从 0 到 1 的概率分布。正如你所看到的，人工智能应用使用的是应用数学与可能值，而不是原始输出。
- en: The main reason is that machine learning/deep learning works best with standardization
    and normalization for workable homogeneous data distributions. Otherwise, the
    algorithms will often produce underfitted or overfitted results.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 主要原因是，机器学习/深度学习在标准化和归一化可操作的均匀数据分布时效果最佳。否则，算法通常会产生欠拟合或过拟合的结果。
- en: In the warehouse model, for example, the AGV needs to choose the best, most
    probable location, *l*[i]. Even in a well-organized corporate warehouse, many
    uncertainties (late arrivals, product defects, or some unplanned problems) reduce
    the probability of a choice. A probability represents a value between 0 (low probability)
    and 1 (high probability). Logistic functions provide the tools to convert all
    numbers into probabilities between 0 and 1 to *normalize* data.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在仓库模型中，例如，AGV 需要选择最佳的、最可能的位置 *l*[i]。即使在组织良好的企业仓库中，许多不确定因素（如迟到的货物、产品缺陷或一些未计划的突发问题）也会降低选择的概率。概率表示一个值，介于
    0（低概率）和 1（高概率）之间。逻辑函数提供了将所有数值转换为 0 到 1 之间的概率以*标准化*数据的工具。
- en: Logistic function
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑函数
- en: The logistic sigmoid provides one of the best ways to normalize the weight of
    a given output. The activation function of the neuron will be the logistic sigmoid.
    The threshold is usually a value above which the neuron has a *y* = 1 value; or
    else it has a *y* = 0 value. In this model, the minimum value will be 0.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑 sigmoid 函数提供了标准化给定输出权重的最佳方式之一。神经元的激活函数将是逻辑 sigmoid。阈值通常是一个值，超过该值时，神经元的 *y*
    = 1；否则，*y* = 0。在此模型中，最小值将为 0。
- en: 'The logistic function is represented as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑函数表示如下：
- en: '![](img/B15438_02_005.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_02_005.png)'
- en: '*e* represents Euler''s number, or 2.71828, the natural logarithm.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*e* 代表欧拉数，或 2.71828，自然对数。'
- en: '*x* is the value to be calculated. In this case, *s* is the result of the logistic
    sigmoid function.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x* 是要计算的值。在这种情况下，*s* 是逻辑 sigmoid 函数的结果。'
- en: 'The code has been rearranged in the following example to show the reasoning
    process that produces the output, `y`, of the neuron:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 代码已经在下面的示例中重新排列，以展示产生神经元输出`y`的推理过程：
- en: '[PRE7]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Thanks to the logistic sigmoid function, the value for the first location in
    the model comes out squashed between 0 and 1 as 0.99, indicating a high probability
    that this location will be full.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 得益于逻辑 sigmoid 函数，模型中第一个位置的值被压缩到0和1之间，结果为0.99，表示该位置将被占满的概率很高。
- en: 'To calculate the availability of the location once the 0.99 value has been
    taken into account, we subtract the load from the total availability, which is
    1, as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑了0.99值后，要计算该位置的可用性，我们从总可用性（即1）中减去负载，计算方法如下：
- en: Availability = 1 – probability of being full (value)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 可用性 = 1 - 满载的概率（值）
- en: Or
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 或
- en: availability = 1 – value
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 可用性 = 1 - 值
- en: As seen previously, once all locations are calculated in this manner, a final
    availability vector, *l*[v], is obtained.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所见，一旦以这种方式计算所有位置，就会得到一个最终的可用性向量，*l*[v]。
- en: '![](img/B15438_02_004.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_02_004.png)'
- en: When analyzing *l*[v], a problem has stopped the process. Individually, each
    line appears to be fine. By applying the logistic sigmoid to each output weight
    and subtracting it from 1, each location displays a probable availability between
    0 and 1\. However, the sum of the lines in *l*[v] exceeds 1\. That is not possible.
    A probability cannot exceed 1\. The program needs to fix that.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析*l*[v]时，处理过程中出现了问题。单独看，每一行似乎没有问题。通过对每个输出权重应用逻辑 sigmoid 并从1中减去，每个位置显示的可用性在0和1之间。但是，*l*[v]的行总和超过了1。那是不可能的。概率不能超过1。程序需要修正这个问题。
- en: Each line produces a [0, 1] solution, which fits the prerequisite of being a
    valid probability.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 每一行都会产生一个[0, 1]的解，这符合有效概率的前提条件。
- en: In this case, the vector *l*[v] contains more than one value and becomes a probability
    distribution. The sum of *l*[v] cannot exceed 1 and needs to be normalized.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，向量*l*[v]包含多个值，成为一个概率分布。*l*[v]的总和不能超过1，需要进行归一化。
- en: The *softmax* function provides an excellent method to normalize *l*[v]. Softmax
    is widely used in machine learning and deep learning.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '*softmax*函数提供了一种很好的方法来归一化*l*[v]。softmax在机器学习和深度学习中得到了广泛应用。'
- en: Bear in mind that *mathematical tools are not rules*. You can adapt them to
    your problem as much as you wish as long as your solution works.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，*数学工具不是规则*。只要解决方案有效，你可以根据需要将它们调整到适合你问题的形式。
- en: Softmax
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Softmax
- en: The softmax function appears in many artificial intelligence models to normalize
    data. Softmax can be used for classification purposes and regression. In our example,
    we will use it to find an optimized goal for an MDP.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: softmax函数出现在许多人工智能模型中，用于归一化数据。softmax可以用于分类目的和回归。在我们的示例中，我们将使用它来为MDP找到一个优化目标。
- en: In the case of the warehouse example, an AGV needs to make a probable choice
    between six locations in the *l*[v] vector. However, the total of the *l*[v] values
    exceeds 1. *l*[v] requires normalization of the softmax function, *S*. In the
    source code, the *l*[v] vector will be named `y`.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在仓库示例中，AGV需要在*l*[v]向量中的六个位置之间做出可能的选择。然而，*l*[v]的总值超过了1。*l*[v]需要对softmax函数*S*进行归一化。在源代码中，*l*[v]向量将命名为`y`。
- en: '![](img/B15438_02_007.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_02_007.png)'
- en: The following code used is `SOFTMAX.py`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下使用的代码是`SOFTMAX.py`。
- en: '`y` represents the *l*[v] vector:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`y`表示*l*[v]向量：'
- en: '[PRE8]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](img/B15438_02_008.png) is the *exp*(*i*) result of each value in `y` (*l*[v]
    in the warehouse example), as follows:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/B15438_02_008.png)是`y`中的每个值（在仓库示例中是*l*[v]）的*exp*(*i*)结果，计算如下：'
- en: '[PRE9]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](img/B15438_02_009.png) is the sum of ![](img/B15438_02_010.png) as shown
    in the following code:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/B15438_02_009.png)是![](img/B15438_02_010.png)的总和，如下面的代码所示：'
- en: '[PRE10]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, each value of the vector is normalized by applying the following function:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，通过应用以下函数来对向量的每个值进行归一化：
- en: '[PRE11]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](img/B15438_02_011.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_02_011.png)'
- en: softmax(*l*[v]) provides a normalized vector with a sum equal to 1, as shown
    in this compressed version of the code. The vector obtained is often described
    as containing logits.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: softmax(*l*[v])提供了一个归一化的向量，其总和等于1，如下面的压缩版本代码所示。得到的向量通常被描述为包含logits。
- en: 'The following code shows one version of a softmax function:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了softmax函数的一个版本：
- en: '[PRE12]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '*l*[v] is now normalized by softmax(*l*[v]) as follows.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*l*[v]现在通过softmax(*l*[v])进行归一化，方法如下。'
- en: '![](img/B15438_02_011.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_02_011.png)'
- en: 'The last part of the softmax function requires softmax(*l*[v]) to be rounded
    to 0 or 1\. The higher the value in softmax(*l*[v]), the more probable it will
    be. In clear-cut transformations, the highest value will be close to 1, and the
    others will be closer to 0\. In a decision-making process, the highest value needs
    to be established as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: softmax 函数的最后一部分要求 softmax(*l*[v]) 被四舍五入为 0 或 1。softmax(*l*[v]) 中的值越大，其可能性越大。在明确的转换中，最高值将接近
    1，其他值将接近 0。在决策过程中，需要按以下方式确定最高值：
- en: '[PRE13]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The output value is `0.273` and has been chosen as the most probable location.
    It is then set to 1, and the other, lower values are set to 0\. This is called
    a one-hot function. This one-hot function is extremely helpful for encoding the
    data provided. The vector obtained can now be applied to the reward matrix. The
    value 1 probability will become 100 in the *R* reward matrix, as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 输出值为 `0.273`，已被选为最可能的位置。然后它被设置为 1，其他较低的值被设置为 0。这叫做 one-hot 函数。这个 one-hot 函数对于编码提供的数据非常有帮助。现在得到的向量可以应用到奖励矩阵中。1
    概率值将变为 *R* 奖励矩阵中的 100，如下所示：
- en: '![](img/B15438_02_013.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_02_013.png)'
- en: The softmax function is now complete. Location *l*[3] or **C** is the best solution
    for the AGV. The probability value is multiplied by 100, and the reward matrix,
    *R*, can now receive the input.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: softmax 函数现在已完成。位置 *l*[3] 或 **C** 是 AGV 的最佳解决方案。概率值被乘以 100，奖励矩阵 *R* 现在可以接收输入。
- en: Before continuing, take some time to play around with the values in the source
    code and run it to become familiar with the softmax function.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，花些时间调整源代码中的值并运行它，以熟悉 softmax 函数。
- en: We now have the data for the reward matrix. The best way to understand the mathematical
    aspect of the project is to draw the result on a piece of paper using the actual
    warehouse layout from locations **A** to **F**.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有了奖励矩阵的数据。理解项目的数学部分的最佳方法是使用实际的仓库布局从 **A** 到 **F** 画出结果。
- en: '[PRE14]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Line **C** of the reward matrix ={0, 0, 100, 0, 0, 0}, where **C** (the third
    value) is now the target for the self-driving vehicle, in this case, an AGV in
    a warehouse.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 奖励矩阵的 **C** 行 ={0, 0, 100, 0, 0, 0}，其中 **C**（第三个值）现在是自动驾驶车辆的目标，在此情况下是仓库中的 AGV。
- en: '![https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_02_03-2.png](img/B15438_02_03.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![https://packt-type-cloud.s3.amazonaws.com/uploads/sites/2134/2018/05/B09946_02_03-2.png](img/B15438_02_03.png)'
- en: 'Figure 2.3: Illustration of a warehouse transport problem'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3：仓库运输问题的示意图
- en: 'We obtain the following reward matrix, *R*, described in *Chapter 1*, *Getting
    Started with Next-Generation Artificial Intelligence through Reinforcement Learning*:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了以下奖励矩阵 *R*，它在*第一章*，*开始使用强化学习的下一代人工智能* 中有所描述：
- en: '| **State/values** | **A** | **B** | **C** | **D** | **E** | **F** |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| **State/values** | **A** | **B** | **C** | **D** | **E** | **F** |'
- en: '| **A** | - | - | - | - | 1 | - |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| **A** | - | - | - | - | 1 | - |'
- en: '| **B** | - | - | - | 1 | - | 1 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| **B** | - | - | - | 1 | - | 1 |'
- en: '| **C** | - | - | 100 | 1 | - | - |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| **C** | - | - | 100 | 1 | - | - |'
- en: '| **D** | - | 1 | 1 | - | 1 | - |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| **D** | - | 1 | 1 | - | 1 | - |'
- en: '| **E** | 1 | - | - | 1 | - | - |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| **E** | 1 | - | - | 1 | - | - |'
- en: '| **F** | - | 1 | - | - | - | - |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| **F** | - | 1 | - | - | - | - |'
- en: 'This reward matrix is exactly the one used in the Python reinforcement learning
    program using the Q function from *Chapter 1*. The output of this chapter is thus
    the input of the *R* matrix. The 0 values are there for the agent to avoid those
    values. The 1 values indicate the reachable cells. The 100 in the C×C cell is
    the result of the softmax output. This program is designed to stay close to probability
    standards with positive values, as shown in the following *R* matrix taken from
    the `mdp01.py` of *Chapter 1*:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这个奖励矩阵正是使用 Python 强化学习程序中的 Q 函数的那个矩阵，来源于*第一章*。因此，本章的输出正是 *R* 矩阵的输入。0 值是为了让代理避开这些值。1
    值表示可达的单元格。C×C 单元格中的 100 是 softmax 输出的结果。该程序设计成保持接近概率标准并有正值，如以下从 *第一章* 的 `mdp01.py`
    中提取的 *R* 矩阵所示：
- en: '[PRE15]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'At this point:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 此时：
- en: The output of the functions in this chapter generated a reward matrix, *R*,
    which is the input of the MDP described in *Chapter 1, Getting Started with Next-Generation
    Artificial Intelligence through Reinforcement Learning*.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章中函数的输出生成了奖励矩阵 *R*，它是*第一章，开始使用强化学习的下一代人工智能*中描述的 MDP 的输入。
- en: The MDP process was set to run for 50,000 episodes in *Chapter 1*.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MDP 过程被设置为在*第一章*中运行 50,000 次。
- en: The output of the MDP has multiple uses, as we saw in this chapter and *Chapter
    1*.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MDP的输出有多种用途，正如我们在本章和*第1章*中看到的。
- en: The building blocks are in place to begin evaluating the execution and performances
    of the reinforcement learning program, as we will see in *Chapter 3*, *Machine
    Intelligence – Evaluation Functions and Numerical Convergence*.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 基础构建模块已就绪，可以开始评估强化学习程序的执行和性能，正如我们在*第3章*中看到的，*机器智能——评估函数与数值收敛*。
- en: Summary
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Using a McCulloch-Pitts neuron with a logistic activation function in a one-layer
    network to build a reward matrix for reinforcement learning shows one way to preprocess
    a dataset.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 使用带有logistic激活函数的McCulloch-Pitts神经元，在单层网络中构建强化学习的奖励矩阵，展示了一种预处理数据集的方法。
- en: Processing real-life data often requires a generalization of a logistic sigmoid
    function through a softmax function, and a one-hot function applied to logits
    to encode the data.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 处理现实生活中的数据通常需要通过softmax函数对logistic sigmoid函数进行泛化，并且对logits应用one-hot函数来编码数据。
- en: Machine learning functions are tools that must be understood to be able to use
    all or parts of them to solve a problem. With this practical approach to artificial
    intelligence, a whole world of projects awaits you.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习函数是必须理解的工具，只有理解它们，才能利用它们的全部或部分来解决问题。通过这种人工智能的实用方法，一个充满项目的世界正等着你。
- en: This neuronal approach is the parent of the multilayer perceptron that will
    be introduced starting in *Chapter 8*, *Solving the XOR Problem with a Feedforward
    Neural Network*.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 这种神经元方法是多层感知器的前身，后者将在*第8章*中介绍，*通过前馈神经网络解决XOR问题*。
- en: This chapter went from an experimental black box machine learning and deep learning
    to white box implementation. Implementation requires a full understanding of machine
    learning algorithms that often require fine-tuning.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 本章从实验性的黑箱机器学习和深度学习转向了白箱实现。实现需要对机器学习算法有全面的理解，这些算法通常需要微调。
- en: However, artificial intelligence goes beyond understanding machine learning
    algorithms. Machine learning or deep learning require evaluation functions. Performance
    or results cannot be validated without evaluation functions, as explained in *Chapter
    3*, *Machine Intelligence – Evaluation Functions and Numerical Convergence*.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，人工智能不仅仅是理解机器学习算法。机器学习或深度学习需要评估函数。如果没有评估函数，就无法验证性能或结果，正如在*第3章*中所解释的，*机器智能——评估函数与数值收敛*。
- en: In the next chapter, the evaluation process of machine intelligence will be
    illustrated by examples that show the limits of human intelligence and the rise
    of machine power.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，将通过一些例子展示机器智能的评估过程，这些例子展示了人类智能的局限性和机器能力的崛起。
- en: Questions
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Raw data can be the input to a neuron and transformed with weights. (Yes | No)
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 原始数据可以作为神经元的输入，并通过权重进行变换。（是 | 否）
- en: Does a neuron require a threshold? (Yes | No)
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 神经元是否需要一个阈值？（是 | 否）
- en: A logistic sigmoid activation function makes the sum of the weights larger.
    (Yes | No)
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: logistic sigmoid激活函数使得权重的总和增大。（是 | 否）
- en: A McCulloch-Pitts neuron sums the weights of its inputs. (Yes | No)
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: McCulloch-Pitts神经元对其输入的权重进行加权求和。（是 | 否）
- en: A logistic sigmoid function is a log10 operation. (Yes | No)
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: logistic sigmoid函数是一个log10运算。（是 | 否）
- en: A logistic softmax is not necessary if a logistic sigmoid function is applied
    to a vector. (Yes | No)
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果对向量应用logistic sigmoid函数，则不需要logistic softmax。（是 | 否）
- en: A probability is a value between –1 and 1\. (Yes | No)
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 概率是介于–1和1之间的一个值。（是 | 否）
- en: Further reading
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'The original McCulloch-Pitts neuron 1943 paper: [http://www.cse.chalmers.se/~coquand/AUTOMATA/mcp.pdf](http://www.cse.chalmers.se/~coquand/AUTOMATA/mcp.pdf)'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始的McCulloch-Pitts神经元1943年论文：[http://www.cse.chalmers.se/~coquand/AUTOMATA/mcp.pdf](http://www.cse.chalmers.se/~coquand/AUTOMATA/mcp.pdf)
- en: 'TensorFlow variables: [https://www.tensorflow.org/beta/guide/variables](https://www.tensorflow.org/beta/guide/variables)'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow变量：[https://www.tensorflow.org/beta/guide/variables](https://www.tensorflow.org/beta/guide/variables)
