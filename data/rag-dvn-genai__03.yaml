- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Building Index-Based RAG with LlamaIndex, Deep Lake, and OpenAI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LlamaIndex、Deep Lake和OpenAI构建基于索引的RAG
- en: Indexes increase precision and speed performances, but they offer more than
    that. Indexes transform retrieval-augmented generative AI by adding a layer of
    transparency. With an index, the source of a response generated by a RAG model
    is fully traceable, offering visibility into the precise location and detailed
    content of the data used. This improvement not only mitigates issues like bias
    and hallucinations but also addresses concerns around copyright and data integrity.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 索引提高了精确度和速度性能，但它们提供的不仅仅是这些。索引通过增加一层透明度，将检索增强型生成式AI进行了转变。有了索引，RAG模型生成的响应的来源可以完全追踪，可以查看数据使用的精确位置和详细内容。这种改进不仅减轻了诸如偏差和幻觉等问题，还解决了关于版权和数据完整性的担忧。
- en: In this chapter, we’ll explore how indexed data allows for greater control over
    generative AI applications. If the output is unsatisfactory, it’s no longer a
    mystery why, since the index allows us to identify and examine the exact data
    source of the issue. This capability makes it possible to refine data inputs,
    tweak system configurations, or switch components, such as vector store software
    and generative models, to achieve better outcomes.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨索引数据如何使我们对生成式AI应用有更大的控制权。如果输出结果不满意，不再是一个谜团，因为索引使我们能够识别和检查问题的确切数据来源。这种能力使得我们可以细化数据输入，调整系统配置，或更换组件，例如向量存储软件和生成模型，以实现更好的结果。
- en: We will begin the chapter by laying out the architecture of an index-based RAG
    pipeline that will enhance speed, precision, and traceability. We will show how
    LlamaIndex, Deep Lake, and OpenAI can be seamlessly integrated without having
    to create all the necessary functions ourselves. This provides a solid base to
    start building from. Then, we’ll introduce the main indexing types we’ll use in
    our programs, such as vector, tree, list, and keyword indexes. Then, we will build
    a domain-specific drone technology LLM RAG agent that a user can interact with.
    Drone technology is expanding to all domains, such as fire detection, traffic
    information, and sports events; hence, I’ve decided to use it in our example.
    The goal of this chapter is to prepare an LLM drone technology dataset that we
    will enhance with multimodal data in the next chapter. We will also illustrate
    the key indexing types in code.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先介绍一个基于索引的RAG管道架构，这将提高速度、精确度和可追踪性。我们将展示如何无缝集成LlamaIndex、Deep Lake和OpenAI，而无需自己创建所有必要的函数。这为我们提供了一个坚实的基础来开始构建。然后，我们将介绍我们程序中将使用的主要索引类型，例如向量、树、列表和关键词索引。然后，我们将构建一个用户可以与之交互的特定领域无人机技术LLM
    RAG代理。无人机技术正在扩展到所有领域，如火灾检测、交通信息和体育赛事；因此，我决定在我们的示例中使用它。本章的目标是准备一个LLM无人机技术数据集，我们将在下一章中用多模态数据增强它。我们还将用代码展示关键索引类型。
- en: By the end of this chapter, you’ll be adept at manipulating index-based RAG
    through vector stores, datasets, and LLMs, and know how to optimize retrieval
    systems and ensure full traceability. You will discover how our integrated toolkit—combining
    LlamaIndex, Deep Lake, and OpenAI—not only simplifies technical complexities but
    also frees your time to develop and hone your analytical skills, enabling you
    to dive deeper into understanding RAG-driven generative AI.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将熟练地通过向量存储、数据集和LLM操作基于索引的RAG，并了解如何优化检索系统并确保完全可追踪。你将发现我们的集成工具包——结合LlamaIndex、Deep
    Lake和OpenAI——不仅简化了技术复杂性，而且释放了你的时间来开发和磨练你的分析技能，使你能够更深入地理解由RAG驱动的生成式AI。
- en: 'We’ll cover the following topics in this chapter:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中将要涵盖以下主题：
- en: Building a semantic search engine with a LlamaIndex framework and indexing methods
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LlamaIndex框架和索引方法构建语义搜索引擎
- en: Populating Deep Lake vector stores
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填充Deep Lake向量存储
- en: Integration of LlamaIndex, Deep Lake, and OpenAI
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LlamaIndex、Deep Lake和OpenAI的集成
- en: Score ranking and cosine similarity metrics
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分数排名和余弦相似度指标
- en: Metadata enhancement for traceability
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元数据增强以提高可追踪性
- en: Query setup and generation configuration
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询设置和生成配置
- en: Introducing automated document ranking
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化文档排名介绍
- en: Vector, tree, list, and keyword indexing types
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量、树、列表和关键词索引类型
- en: Why use index-based RAG?
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么使用基于索引的RAG？
- en: Index-based search takes advanced RAG-driven generative AI to another level.
    It increases the speed of retrieval when faced with large volumes of data, taking
    us from raw chunks of data to organized, indexed nodes that we can trace from
    the output back to the source of a document and its location.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 基于索引的搜索将先进的RAG驱动的生成式AI提升到了另一个层次。在面对大量数据时，它提高了检索速度，将我们从原始数据块转变为有组织、可索引的节点，我们可以从输出追溯到文档的来源及其位置。
- en: Let’s understand the differences between a vector-based similarity search and
    an index-based search by analyzing the architecture of an index-based RAG.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过分析基于索引的RAG的架构来了解基于向量的相似性搜索和基于索引的搜索之间的区别。
- en: Architecture
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构
- en: 'Index-based search is faster than vector-based search in RAG because it directly
    accesses relevant data using indices, while vector-based search sequentially compares
    embeddings across all records. We implemented a vector-based similarity search
    program in *Chapter 2*, *RAG Embedding Vector Stores with Deep Lake and OpenAI*,
    as shown in *Figure 3.1*:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在RAG中，基于索引的搜索比基于向量的搜索更快，因为它直接使用索引访问相关数据，而基于向量的搜索则是按顺序比较所有记录中的嵌入。我们在*第二章*中实现了基于向量的相似性搜索程序，即*使用Deep
    Lake和OpenAI的RAG嵌入向量存储*，如图*3.1*所示：
- en: 'We collected and prepared data in *Pipeline #1: Data Collection and Preparation*'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*管道#1：数据收集和准备*中，我们收集并准备了数据。
- en: 'We embedded the data and stored the prepared data in a vector store in *Pipeline
    #2: Embeddings and vector store*'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*管道#2：嵌入和向量存储*中，我们将数据嵌入并存储了准备好的数据。
- en: 'We then ran retrieval queries and generative AI with *Pipeline #3* to process
    user input, run retrievals based on vector similarity searches, augment the input,
    generate a response, and apply performance metrics.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们使用*管道#3*运行检索查询和生成式AI，以处理用户输入，基于向量相似性搜索进行检索，增强输入，生成响应，并应用性能指标。
- en: This approach is flexible because it gives you many ways to implement each component,
    depending on the needs of your project.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法很灵活，因为它提供了多种方式来实现每个组件，具体取决于你项目的需求。
- en: '![A diagram of a process  Description automatically generated](img/B31169_03_01.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![一个流程图  描述由系统自动生成](img/B31169_03_01.png)'
- en: 'Figure 3.1: RAG-driven generative AI pipelines, as described in Chapter 2,
    with additional functionality'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1：RAG驱动的生成式AI管道，如第二章所述，增加了额外的功能
- en: 'However, implementing index-based searches will take us into the future of
    AI, which will be faster, more precise, and traceable. We will follow the same
    process as in *Chapter 2*, with three pipelines, to make sure that you are ready
    to work in a team in which the tasks are specialized. Since we are using the same
    pipelines as in *Chapter 2*, let’s add the functions from that chapter to them,
    as shown in *Figure 3.1*:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，实施基于索引的搜索将引领我们进入AI的未来，这将更加快速、精确且可追溯。我们将遵循与*第二章*相同的流程，使用三个管道，以确保你准备好在一个任务专业化的团队中工作。由于我们使用与*第二章*相同的管道，因此让我们将那一章的功能添加到它们中，如图*3.1*所示：
- en: '**Pipeline Component #1 and D2-Index**: We will collect data and preprocess
    it. However, this time, we will prepare the data source one document at a time
    and store them in separate files. We will then add their name and location to
    the metadata we load into the vector store. The metadata will help us trace a
    response all the way back to the exact file that the retrieval function processed.
    We will have a direct link from a response to the data that it was based on.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道组件#1和D2-索引**：我们将收集数据并对其进行预处理。然而，这次，我们将一次准备一个数据源并将其存储在单独的文件中。然后，我们将它们的名称和位置添加到我们加载到向量存储中的元数据中。元数据将帮助我们追踪一个响应，直到它所处理的精确文件。我们将从响应直接链接到基于的数据。'
- en: '**Pipeline Component #2 and D3-Index**: We will load the data into a vector
    store by installing and using the innovative integrated `llama-index-vector-stores-deeplake`
    package, which includes everything we need in an optimized starter scenario: chunking,
    embedding, storage, and even LLM integration. We have everything we need to get
    to work on index-based RAG in a few lines of code! This way, once we have a solid
    program, we can customize and expand the pipelines as we wish, as we did, for
    example, in *Chapter 2*, when we explicitly chose the LLM models and chunking
    sizes.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道组件 #2 和 D3-索引**：我们将通过安装和使用创新的集成 `llama-index-vector-stores-deeplake` 包来将数据加载到向量存储中，该包包含我们在优化启动场景中所需的一切：分块、嵌入、存储，甚至
    LLM 集成。我们拥有所有需要的工具，只需几行代码就可以开始基于索引的 RAG 工作！这样，一旦我们有一个稳固的程序，我们就可以像在*第二章*中那样，根据需要自定义和扩展管道。'
- en: '**Pipeline Component #3 and D4-Index**: We will load the data in a dataset
    by installing and using the innovative integrated `llama-index-vector-stores-deeplake`
    package, which includes everything we need to get indexed-based retrieval and
    generation started, including automated ranking and scoring. The process is seamless
    and extremely productive. We’ll leverage LlamaIndex with Deep Lake to streamline
    information retrieval and processing. An integrated retriever will efficiently
    fetch relevant data from the Deep Lake repository, while an LLM agent will then
    intelligently synthesize and interact with the retrieved information to generate
    meaningful insights or actions. Indexes are designed for fast retrieval, and we
    will implement several indexing methods.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道组件 #3 和 D4-索引**：我们将通过安装和使用创新的集成 `llama-index-vector-stores-deeplake` 包来将数据加载到数据集中，该包包含我们启动基于索引的检索和生成所需的一切，包括自动排名和评分。整个过程无缝且极具生产力。我们将利用
    LlamaIndex 和 Deep Lake 来简化信息检索和处理。一个集成的检索器将有效地从 Deep Lake 存储库中检索相关数据，而一个 LLM 代理将随后智能地综合和交互检索到的信息以生成有意义的见解或行动。索引是为快速检索而设计的，我们将实现几种索引方法。'
- en: '**Pipeline Component #3 and E1-Index**: We will add a time and score metric
    to evaluate the output.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道组件 #3 和 E1-索引**：我们将添加时间和分数指标来评估输出。'
- en: 'In the previous chapter, we implemented vector-based similarity search and
    retrieval. We embedded documents to transform data into high-dimensional vectors.
    Then, we performed retrieval by calculating distances between vectors. In this
    chapter, we will go further and create a vector store. However, we will load the
    data into a dataset that will be reorganized using retrieval indexing types. *Table
    3.1* shows the differences between vector-based and index-based search and retrieval
    methods:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们实现了基于向量的相似性搜索和检索。我们将文档嵌入以将数据转换为高维向量。然后，我们通过计算向量之间的距离来进行检索。在本章中，我们将更进一步，创建一个向量存储。然而，我们将数据加载到将使用检索索引类型重新组织的数据集中。*表
    3.1* 展示了基于向量和基于索引的搜索和检索方法之间的差异：
- en: '| **Feature** | **Vector-based similarity search and retrieval** | **Index-based
    vector, tree, list, and keyword search and retrieval** |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| **特性** | **基于向量的相似性搜索和检索** | **基于索引的向量、树、列表和关键词搜索和检索** |'
- en: '| Flexibility | High | Medium (precomputed structure) |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 灵活性 | 高 | 中等（预计算结构） |'
- en: '| Speed | Slower with large datasets | Fast and optimized for quick retrieval
    |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 速度 | 在大型数据集中较慢 | 快速且针对快速检索进行了优化 |'
- en: '| Scalability | Limited by real-time processing | Highly scalable with large
    datasets |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 可扩展性 | 受实时处理限制 | 与大型数据集高度可扩展 |'
- en: '| Complexity | Simpler setup | More complex and requires an indexing step |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 复杂度 | 简单设置 | 更复杂且需要索引步骤 |'
- en: '| Update Frequency | Easy to update | Requires re-indexing for updates |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 更新频率 | 更容易更新 | 更新需要重新索引 |'
- en: 'Table 3.1: Vector-based and index-based characteristics'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.1：基于向量和基于索引的特性
- en: We will now build a semantic index-based RAG program with Deep Lake, LlamaIndex,
    and OpenAI.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用 Deep Lake、LlamaIndex 和 OpenAI 构建一个基于语义索引的 RAG 程序。
- en: Building a semantic search engine and generative agent for drone technology
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为无人机技术构建语义搜索引擎和生成代理
- en: In this section, we will build a semantic index-based search engine and generative
    AI agent engine using Deep Lake vector stores, LlamaIndex, and OpenAI. As mentioned
    earlier, drone technology is expanding in domains such as fire detection and traffic
    control. As such, the program’s goal is to provide an index-based RAG agent for
    drone technology questions and answers. The program will demonstrate how drones
    use computer vision techniques to identify vehicles and other objects. We will
    implement the architecture illustrated in *Figure 3.1*, described in the *Architecture*
    section of this chapter.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 Deep Lake 向量存储、LlamaIndex 和 OpenAI 构建一个基于语义索引的搜索引擎和生成式 AI 代理引擎。如前所述，无人机技术在火灾检测和交通控制等领域正在扩展。因此，程序的目标是提供一个基于索引的
    RAG 代理，用于无人机技术的问答。程序将演示无人机如何使用计算机视觉技术识别车辆和其他物体。我们将实现本章“架构”部分中描述的 *图 3.1* 所示的架构。
- en: Open `2-Deep_Lake_LlamaIndex_OpenAI_indexing.ipynb` from the GitHub repository
    of this chapter. The titles of this section are the same as the section titles
    in the notebook, so you can match the explanations with the code.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 从本章的 GitHub 仓库中打开 `2-Deep_Lake_LlamaIndex_OpenAI_indexing.ipynb`。本节标题与笔记本中的章节标题相同，因此你可以将解释与代码匹配。
- en: 'We will first begin by installing the environment. Then, we will build the
    three main pipelines of the program:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先开始安装环境。然后，我们将构建程序的主要三个管道：
- en: '**Pipeline 1**: Collecting and preparing the documents. Using sources like
    GitHub and Wikipedia, collect and clean documents for indexing.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道 1**：收集和准备文档。使用 GitHub 和维基百科等来源收集和清理用于索引的文档。'
- en: '**Pipeline 2**: Creating and populating a Deep Lake vector store. Create and
    populate a Deep Lake vector store with the prepared documents.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道 2**：创建和填充 Deep Lake 向量存储。使用准备好的文档创建和填充一个 Deep Lake 向量存储。'
- en: '**Pipeline 3**: Index-based RAG for query processing and generation. Applying
    time and score performances with LLMs and cosine similarity metrics.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道 3**：基于索引的 RAG 用于查询处理和生成。使用 LLMs 和余弦相似度指标进行时间和分数性能评估。'
- en: When possible, break your project down into separate pipelines so that teams
    can progress independently and in parallel. The pipelines in this chapter are
    an example of how this can be done, but there are many other ways to do this,
    depending on your project. For now, we will begin by installing the environment.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 当可能时，将你的项目分解成独立的管道，以便团队可以独立并行地进展。本章中的管道是这种做法的一个例子，但还有许多其他方法可以做到这一点，具体取决于你的项目。现在，我们将从安装环境开始。
- en: Installing the environment
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装环境
- en: 'The environment is mostly the same as in the previous chapter. Let’s focus
    on the packages that integrate LlamaIndex, vector store capabilities for Deep
    Lake, and also OpenAI modules. This integration is a major step forward to seamless
    cross-platform implementations:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 环境与上一章基本相同。让我们关注集成 LlamaIndex、Deep Lake 的向量存储能力和 OpenAI 模块的包。这种集成是向无缝跨平台实现迈出的一个重要步骤：
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The program requires additional Deep Lake functionalities:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 程序需要额外的 Deep Lake 功能：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The program also requires LlamaIndex functionalities:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 程序还需要 LlamaIndex 的功能：
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let’s now check if the packages can be properly imported from `llama-index`,
    including vector stores for Deep Lake:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们检查是否可以从 `llama-index` 正确导入包，包括 Deep Lake 的向量存储：
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: With that, we have installed the environment. We will now collect and prepare
    the documents.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就安装了环境。接下来，我们将收集和准备文档。
- en: 'Pipeline 1: Collecting and preparing the documents'
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**管道 1**：收集和准备文档'
- en: 'In this section, we will collect and prepare the drone-related documents with
    the metadata necessary to trace the documents back to their source. The goal is
    to trace a response’s content back to the exact chunk of data retrieved to find
    its source. First, we will create a data directory in which we will load the documents:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将收集和准备与无人机相关的文档，并包含必要的元数据以追踪文档的来源。目标是追踪响应内容的来源，将其追溯到检索到的确切数据块。首先，我们将创建一个数据目录，用于加载文档：
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we will use a heterogeneous corpus for the drone technology data that
    we will process using `BeautifulSoup`:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用一个异构语料库来处理无人机技术数据，我们将使用 `BeautifulSoup` 进行处理：
- en: '[PRE5]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The corpus contains a list of sites related to drones, computer vision, and
    related technologies. However, the list also contains noisy links such as [https://keras.io/](https://keras.io/)
    and [https://pytorch.org/](https://pytorch.org/), which do *not* contain the specific
    information we are looking for.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 语料库包含与无人机、计算机视觉和相关技术相关的网站列表。然而，列表中也包含了一些噪声链接，如 [https://keras.io/](https://keras.io/)
    和 [https://pytorch.org/](https://pytorch.org/)，它们并不包含我们正在寻找的特定信息。
- en: In real-life projects, we will not always have the luxury of working on perfect,
    pertinent, structured, and well-formatted data. Our RAG pipelines must be sufficiently
    robust to retrieve relevant data in a noisy environment.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实生活中的项目中，我们并不总是有在完美、相关、结构化和良好格式的数据上工作的奢侈。我们的 RAG 管道必须足够健壮，能够在嘈杂的环境中检索相关数据。
- en: In this case, we are working with unstructured data in various formats and variable
    quality as related to drone technology. Of course, in a closed environment, we
    can work with the persons or organizations that produce the documents, but we
    must be ready for any type of document in a fast-moving, digital world.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们正在处理与无人机技术相关的各种格式和不同质量的无结构数据。当然，在封闭环境中，我们可以与生产文档的个人或组织合作，但我们必须准备好在快速发展的数字世界中应对任何类型的文档。
- en: 'The code will fetch and clean the data, as it did in *Chapter 2*:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将像在第 2 章中那样检索和清理数据：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Each project will require specific names and paths for the original data. In
    this case, we will introduce an additional function to save each piece of text
    with the name of its data source, by creating a keyword based on its URL:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 每个项目都需要特定的原始数据名称和路径。在这种情况下，我们将引入一个额外的函数来保存每段文本，并使用其数据源的名称，通过创建基于其 URL 的关键词：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output shows that the goal is achieved, although some documents could not
    be decoded:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示目标已达成，尽管一些文档无法解码：
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Depending on the project’s goals, you can choose to investigate and ensure that
    all documents are retrieved, or estimate that you have enough data for user queries.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 根据项目的目标，你可以选择调查并确保所有文档都已检索，或者估计你已有足够的数据用于用户查询。
- en: 'If we check `./data/`, we will find that each article is now in a separate
    file, as shown in the content of the directory:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们检查 `./data/`，我们会发现每篇文章现在都在一个单独的文件中，如目录内容所示：
- en: '![A screenshot of a computer  Description automatically generated](img/B31169_03_02.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图 自动生成的描述](img/B31169_03_02.png)'
- en: 'Figure 3.2: List of prepared documents'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2：准备文档列表
- en: 'The program now loads the documents from `./data/`:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 程序现在从 `./data/` 加载文档：
- en: '[PRE9]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The LlamaIndex `SimpleDirectoryReader` class is designed for working with unstructured
    data. It recursively scans the directory and identifies and loads all supported
    file types, such as `.txt`, `.pdf`, and `.docx`. It then extracts the content
    from each file and returns a list of document objects with its text and metadata,
    such as the filename and file path. Let’s display the first entry of this list
    of dictionaries of the documents:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: LlamaIndex 的 `SimpleDirectoryReader` 类旨在用于处理无结构数据。它递归地扫描目录，并识别和加载所有支持的文件类型，如
    `.txt`、`.pdf` 和 `.docx`。然后它从每个文件中提取内容，并返回一个包含其文本和元数据的文档对象列表，例如文件名和文件路径。让我们显示这个文档字典列表的第一个条目：
- en: '[PRE10]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The output shows that the directory reader has provided fully transparent information
    on the source of its data, including the name of the document, such as `1804.06985.txt`
    in this case:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示目录读取器已提供关于其数据来源的完全透明信息，包括文档名称，例如本例中的 `1804.06985.txt`：
- en: '[PRE11]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The content of this document contains noise that seems unrelated to the drone
    technology information we are looking for. But that is exactly the point of this
    program, which aims to do the following:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 本文档的内容包含了一些看似与我们要找的无人机技术信息无关的噪声。但这正是本程序的目的，旨在完成以下任务：
- en: Start with all the raw, unstructured, loosely drone-related data we can get
    our hands on
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从我们能得到的所有原始、无结构、松散相关的无人机数据开始
- en: Simulate how real-life projects often begin
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模拟现实生活中的项目通常是如何开始的
- en: Evaluate how well an index-based RAG generative AI program can perform in a
    challenging environment
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估基于索引的 RAG 生成式 AI 程序在具有挑战性的环境中的表现如何
- en: Let’s now create and populate a Deep Lake vector store in complete transparency.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在以完全透明的方式创建并填充一个 Deep Lake 向量存储库。
- en: 'Pipeline 2: Creating and populating a Deep Lake vector store'
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道 2：创建和填充 Deep Lake 向量存储库
- en: 'In this section, we will create a Deep Lake vector store and populate it with
    the data in our documents. We will implement a standard tensor configuration with:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将创建一个Deep Lake向量存储库，并用我们文档中的数据填充它。我们将实现一个标准的张量配置，使用：
- en: '`text (str)`: The text is the content of one of the text files listed in the
    dictionary of documents. It will be seamless, and chunking will be optimized,
    breaking the text into meaningful chunks.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text (str)`: 文本是文档字典中列出的文本文件的其中一个的内容。它将是无缝的，并且分块将被优化，将文本分割成有意义的块。'
- en: '`metadata(json)`: In this case, the metadata will contain the filename source
    of each chunk of text for full transparency and control. We will see how to access
    this information in code.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata(json)`: 在这种情况下，元数据将包含每个文本数据块的文件名来源，以实现完全透明和控制。我们将看到如何在代码中访问这些信息。'
- en: '`embedding (float32)`: The embedding is seamless, using an OpenAI embedding
    model called directly by the `LlamaIndex-Deep Lake-OpenAI` package.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding (float32)`: 嵌入是无缝的，使用OpenAI的嵌入模型，该模型直接由`LlamaIndex-Deep Lake-OpenAI`包调用。'
- en: '`id (str, auto-populated)`: A unique ID is attributed automatically to each
    chunk. The vector store will also contain an index, which is a number from `0`
    to `n`, but it cannot be used semantically, since it will change each time we
    modify the dataset. However, the unique ID field will remain unchanged until we
    decide to optimize it with index-based search strategies, as we will see in the
    *Pipeline 3: Index-based RAG* section that follows.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id (str, auto-populated)`: 每个数据块都会自动分配一个唯一的ID。向量存储库也将包含一个索引，它是一个从 `0` 到 `n`
    的数字，但它不能用于语义上，因为每次我们修改数据集时它都会改变。然而，唯一的ID字段将保持不变，直到我们决定使用基于索引的搜索策略来优化它，正如我们将在接下来的
    *Pipeline 3: 基于索引的RAG* 部分中看到的。'
- en: 'The program first defines our vector store and dataset paths:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 程序首先定义我们的向量存储库和数据集路径：
- en: '[PRE12]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Replace the vector store and dataset paths with your account name and the name
    of the dataset you wish to use:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 将向量存储库和数据集路径替换为您的账户名称和您希望使用的数据集名称：
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We then create a vector store, populate it, and create an index over the documents:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建一个向量存储库，填充它，并在文档上创建一个索引：
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Notice that `overwrite` is set to `True` to create the vector store and overwrite
    any existing one. If `overwrite=False`, the dataset will be appended.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，`overwrite` 设置为 `True` 以创建向量存储库并覆盖任何现有的一个。如果 `overwrite=False`，数据集将被追加。
- en: 'The index created will be reorganized by the indexing methods, which will rearrange
    and create new indexes when necessary. However, the responses will always provide
    the original source of the data. The output confirms that the dataset has been
    created and the data is uploaded:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 创建的索引将由索引方法重新组织，当需要时将重新排列和创建新的索引。然而，响应将始终提供数据的原始来源。输出确认数据集已创建并且数据已上传：
- en: '[PRE15]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output also shows the structure of the dataset once it is populated:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 输出还显示了数据集一旦填充后的结构：
- en: '[PRE16]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The data is stored in tensors with their type and shape:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 数据以张量的形式存储，包括其类型和形状：
- en: '![A screenshot of a computer  Description automatically generated](img/B31169_03_03.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  自动生成的描述](img/B31169_03_03.png)'
- en: 'Figure 3.3: Dataset structure'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3：数据集结构
- en: 'We will now load our dataset in memory:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将在内存中加载我们的数据集：
- en: '[PRE17]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We can visualize the dataset online by clicking on the link provided in the
    output:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过点击输出中提供的链接在线可视化数据集：
- en: '[PRE18]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We can also decide to add code to display the dataset. We begin by loading
    the data in a pandas DataFrame:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以决定添加代码来显示数据集。我们首先通过将数据加载到pandas DataFrame中开始：
- en: '[PRE19]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Then, we create a function to display a record:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建一个函数来显示一条记录：
- en: '[PRE20]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Finally, we can select a record and display each field:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以选择一个记录并显示每个字段：
- en: '[PRE21]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The `id` is a unique string code:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`id` 是一个唯一的字符串代码：'
- en: '[PRE22]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The `metadata` field contains the information we need to trace the content
    back to the original file and file path, as well as everything we need to understand
    this record, from the source to the embedded vector. It also contains the information
    of the node created from the record’s data, which can then be used for the indexing
    engine we will run in *Pipeline 3*:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`metadata` 字段包含我们需要追踪内容回原始文件和文件路径的信息，以及我们需要了解此记录的所有信息，从来源到嵌入向量。它还包含从记录数据创建的节点的信息，然后可以用于我们在
    *Pipeline 3* 中运行的索引引擎：'
- en: '`file_path`: Path to the file in the dataset `(/content/data/1804.06985.txt`).'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`file_path`: 数据集中文件的路径（`` `/content/data/1804.06985.txt` ``）。'
- en: '`file_name`: Name of the file (`` `1804.06985.txt` ``).'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`file_name`: 文件名（`` `1804.06985.txt` ``）。'
- en: '`file_type`: Type of file (`` `text/plain` ``).'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`file_type`: 文件类型（`` `text/plain` ``）。'
- en: '`file_size`: Size of the file in bytes (`` `3700` ``).'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`file_size`: 文件的大小（以字节为单位，`` `3700` ``）。'
- en: '`creation_date`: Date the file was created (`` `2024-08-09` ``).'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`creation_date`: 文件创建的日期（`` `2024-08-09` ``）。'
- en: '`last_modified_date`: Date the file was last modified (`` `2024-08-09` ``).'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`last_modified_date`: 文件最后修改的日期（`` `2024-08-09` ``）。'
- en: '`_node_content`: Detailed content of the node, including the following main
    items:'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_node_content`: 节点的详细内容，包括以下主要项目：'
- en: '`id_`: Unique identifier for the node (`` `a89cdb8c-3a85-42ff-9d5f-98f93f414df6
    ` ``).'
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id_`: 节点的唯一标识符（`` `a89cdb8c-3a85-42ff-9d5f-98f93f414df6 ` ``）。'
- en: '`embedding`: Embedding related to the text (`null`).'
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`embedding`: 与文本相关的嵌入（`null`）。'
- en: '`metadata`: Repeated metadata about the file.'
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata`: 关于文件的重复元数据。'
- en: '`excluded_embed_metadata_keys`: Keys excluded from embedding metadata (not
    necessary for embedding).'
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`excluded_embed_metadata_keys`: 从嵌入元数据中排除的键（对于嵌入不是必需的）。'
- en: '`excluded_llm_metadata_keys`: Keys excluded from LLM metadata (not necessary
    for an LLM).'
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`excluded_llm_metadata_keys`: 从 LLM 元数据中排除的键（对于 LLM 不是必需的）。'
- en: '`relationships`: Information about relationships to other nodes.'
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`relationships`: 关于与其他节点关系的详细信息。'
- en: '`text`: Actual text content of the document. It can be the text itself, an
    abstract, a summary, or any other approach to optimize search functions.'
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text`: 文档的实际文本内容。它可以是指定的文本、摘要、总结或其他优化搜索功能的方法。'
- en: '`start_char_idx`: Starting character index of the text.'
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`start_char_idx`: 文本的起始字符索引。'
- en: '`end_char_idx`: Ending character index of the text.'
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`end_char_idx`: 文本的结束字符索引。'
- en: '`text_template`: Template for displaying text with metadata.'
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_template`: 带有元数据的文本显示模板。'
- en: '`metadata_template`: Template for displaying metadata.'
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata_template`: 显示元数据的模板。'
- en: '`metadata_seperator`: Separator used in metadata display.'
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata_seperator`: 元数据显示中使用的分隔符。'
- en: '`class_name`: Type of node (e.g., `` `TextNode` ``).'
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_name`: 节点的类型（例如，`` `TextNode` ``）。'
- en: '`_node_type`: Type of node (`` `TextNode` ``).'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_node_type`: 节点的类型（`` `TextNode` ``）。'
- en: '`document_id`: Identifier for the document (`` `61e7201d-0359-42b4-9a5f-32c4d67f345e`
    ``).'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`document_id`: 文档的标识符（`` `61e7201d-0359-42b4-9a5f-32c4d67f345e` ``）。'
- en: '`doc_id`: Document ID, same as `document_id`.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`doc_id`: 文档 ID，与 `document_id` 相同。'
- en: '`ref_doc_id`: Reference document ID, same as `document_id`.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ref_doc_id`: 参考文档 ID，与 `document_id` 相同。'
- en: 'The `text` field contains the field of this chunk of data, not the whole original
    text:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '`text` 字段包含此数据块的字段，而不是整个原始文本：'
- en: '[PRE23]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `Embedding` field contains the embedded vector of the text content:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`Embedding` 字段包含文本内容的嵌入向量：'
- en: '[PRE24]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The structure and format of RAG datasets vary from one domain or project to
    another. However, the following four columns of this dataset provide valuable
    information on the evolution of AI:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 数据集的结构和格式因领域或项目而异。然而，以下四个数据集的列提供了关于 AI 进化的宝贵信息：
- en: '`id`: The `id` is the index we will be using to organize the chunks of text
    of the `text` column in the dataset. The chunks will be transformed into *nodes*
    that can contain the original text, summaries of the original text, and additional
    information, such as the source of the data used for the output that is stored
    in the metadata column. We created this index in **Pipeline 2** of this notebook
    when we created the vector store. However, we can generate indexes in memory on
    an existing database that contains no indexes, as we will see in *Chapter 4*,
    *Multimodal Modular RAG for Drone Technology*.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`id`: `id` 是我们将用于组织数据集中 `text` 列的文本块索引。这些块将被转换为可以包含原始文本、原始文本的摘要以及附加信息（例如，存储在元数据列中的用于输出的数据源）的
    *节点*。我们在笔记本的 **Pipeline 2** 中创建了这个索引，当我们创建向量存储时。然而，我们可以在不包含索引的现有数据库中在内存中生成索引，正如我们将在
    *第 4 章*，*多模态模块化 RAG 用于无人机技术* 中看到的。'
- en: '`metadata`: The metadata was generated automatically in **Pipeline 1** when
    Deep Lake’s `SimpleDirectoryReader` loaded the source documents in a documents
    object, and also when the vector store was created. In *Chapter 2*, *RAG Embedding
    Vector Stores with Deep Lake and OpenAI*, we only had one file source of data.
    In this chapter, we stored the data in one file for each data source (URL).'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata`: 在 **Pipeline 1** 中自动生成的元数据，当 Deep Lake 的 `SimpleDirectoryReader`
    将源文档加载到文档对象中，以及创建向量存储时。在 *第 2 章*，*使用 Deep Lake 和 OpenAI 的 RAG 嵌入向量存储* 中，我们只有一个数据源文件。在这一章中，我们将每个数据源（URL）存储在一个文件中。'
- en: '`text`: The text processed by Deep Lake’s vector store creation functionality
    that we ran in **Pipeline 2** automatically chunked the data, without us having
    to configure the size of the chunks, as we did in the *Retrieving a batch of prepared
    documents* section in *Chapter 2*. Once again, the process is seamless. We will
    see how smart chunking is done in the *Optimized chunking* section of *Pipeline
    3: Index-based RAG* in this chapter.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`文本`：Deep Lake的向量存储创建功能在**管道2**中处理的文本，自动分块了数据，我们无需像在第2章的*检索一批准备好的文档*部分中那样配置块的大小。再次强调，这个过程是无缝的。我们将在本章的*管道3：基于索引的RAG*的*优化分块*部分中看到如何智能地进行分块。'
- en: '`embedding`: The embedding for each chunk of data was generated through an
    embedding model that we do not have to configure. We could choose an embedding
    model, as we did in the *Data embedding and storage* section in *Chapter 2*, *RAG
    Embedding Vector Stores with Deep Lake and OpenAI*. We selected an embedding model
    and wrote a function. In this program, Deep Lake selects the embedding model and
    embeds the data, without us having to write a single line of code.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`嵌入`：每个数据块嵌入的生成是通过我们无需配置的嵌入模型完成的。我们可以选择一个嵌入模型，就像我们在第2章的*数据嵌入和存储*部分中做的那样，*使用Deep
    Lake和OpenAI的RAG嵌入向量存储*。我们选择了一个嵌入模型并编写了一个函数。在这个程序中，Deep Lake选择嵌入模型并嵌入数据，我们无需编写任何代码。'
- en: We can see that embedding, chunking, indexing, and other data processing functions
    are now encapsulated in platforms and frameworks, such as Activeloop Deep Lake,
    LlamaIndex, OpenAI, LangChain, Hugging Face, Chroma, and many others. Progressively,
    the initial excitement of generative AI models and RAG will fade, and they will
    become industrialized, encapsulated, and commonplace components of AI pipelines.
    AI is evolving, and it might be helpful to facilitate a platform that offers a
    default configuration based on effective practices. Then, once we have implemented
    a basic configuration, we can customize and expand the pipelines as necessary
    for our projects.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，嵌入、分块、索引和其他数据处理函数现在都被封装在平台和框架中，例如Activeloop Deep Lake、LlamaIndex、OpenAI、LangChain、Hugging
    Face、Chroma等。随着时间推移，生成式AI模型和RAG的初始兴奋感将逐渐消退，它们将变成AI管道中工业化的、封装的、常见的组件。AI在不断发展，可能有助于提供一个基于有效实践的默认配置的平台。然后，一旦我们实现了基本配置，我们就可以根据我们的项目需求进行定制和扩展管道。
- en: We are now ready to run index-based RAG.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已准备好运行基于索引的RAG。
- en: 'Pipeline 3: Index-based RAG'
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管道3：基于索引的RAG
- en: 'In this section, we will implement an index-based RAG pipeline using `LlamaIndex`,
    which uses the data we have prepared and processed with Deep Lake. We will retrieve
    relevant information from the heterogeneous (noise-containing) drone-related document
    collection and synthesize the response through OpenAI’s LLM models. We will implement
    four index engines:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用`LlamaIndex`实现一个基于索引的RAG管道，它使用我们用Deep Lake准备和处理的已有数据。我们将从包含噪声的异构（无人机相关）文档集中检索相关信息，并通过OpenAI的LLM模型合成响应。我们将实现四个索引引擎：
- en: '**Vector Store Index Engine**: Creates a vector store index from the documents,
    enabling efficient similarity-based searches.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量存储索引引擎**：从文档中创建向量存储索引，实现基于相似性的高效搜索。'
- en: '**Tree Index**: Builds a hierarchical tree index from the documents, offering
    an alternative retrieval structure.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**树索引**：从文档中构建一个分层树索引，提供一种替代的检索结构。'
- en: '**List Index**: Constructs a straightforward list index from the documents.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**列表索引**：从文档中构建一个简单的列表索引。'
- en: '**Keyword Table Index**: Creates an index based on keywords extracted from
    the documents.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关键词表索引**：根据从文档中提取的关键词创建索引。'
- en: 'We will implement querying with an LLM:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用LLM实现查询：
- en: '**Query Response and Source**: Queries the index with user input, retrieves
    the relevant documents, and returns a synthesized response along with source information.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询响应和来源**：使用用户输入查询索引，检索相关文档，并返回合成的响应以及来源信息。'
- en: We will measure the responses with a *time-weighted average metric with LLM
    score and cosine similarity* that calculates a time-weighted average, based on
    retrieval and similarity scores. The content and execution times might vary from
    one run to another due to the stochastic algorithms implemented.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用带有LLM分数和余弦相似度的*时间加权平均指标*来衡量响应，该指标基于检索和相似度分数计算时间加权平均。由于实现了随机算法，内容和执行时间可能因运行而异。
- en: User input and query parameters
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用户输入和查询参数
- en: The user input will be the reference question for the four index engines we
    will run. We will evaluate each response based on the index engine’s retrievals
    and measure the outputs, using time and score ratios. The input will be submitted
    to the four index and query engines we will build later.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 用户输入将是我们将运行的四个索引引擎的参考问题。我们将根据索引引擎的检索结果评估每个响应，并使用时间和分数比率来衡量输出。输入将被提交给我们将构建的四个索引和查询引擎。
- en: 'The user input is:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 用户输入是：
- en: '[PRE25]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The four query engines that implement an LLM (in this case, an OpenAI model)
    will seamlessly be called with the same parameters. The three parameters that
    we will set are:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 实现一个 LLM（在这种情况下，是一个 OpenAI 模型）的四个查询引擎将无缝地使用相同的参数调用。我们将设置以下三个参数：
- en: '[PRE26]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'These key parameters are:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这些关键参数是：
- en: '`k=3`: The query engine will be required to find the top 3 most probable responses
    by setting the top-k (most probable choices) to 3\. In this case, k will serve
    as a ranking function that will force the LLM to select the top documents.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`k=3`：查询引擎将需要通过设置 top-k（最可能的选择）为 3 来找到最可能的三个响应。在这种情况下，k 将作为排名函数，迫使 LLM 选择最相关的文档。'
- en: '`temp=0.1`: A low temperature such as `0.1` will encourage the LLM to produce
    precise results. If the temperature is increased to `0.9`, for example, the response
    will be more creative. However, in this case, we are exploring drone technology,
    which requires precision.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`temp=0.1`：低温度如 `0.1` 将鼓励 LLM 产生精确的结果。例如，如果温度增加到 `0.9`，则响应将更加富有创意。然而，在这种情况下，我们正在探索无人机技术，这需要精确度。'
- en: '`mt=1024`: This parameter will limit the number of tokens of the output to
    `1,024`.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mt=1024`：此参数将限制输出中令牌的数量为 `1,024`。'
- en: The user input and parameters will be applied to the four query engines. Let’s
    now build the cosine similarity metric.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 用户输入和参数将被应用于四个查询引擎。现在让我们构建余弦相似度指标。
- en: Cosine similarity metric
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 余弦相似度指标
- en: 'The cosine similarity metric was described in the *Evaluating the Output with
    the Cosine Similarity* section in *Chapter 2*. If necessary, take the time to
    go through that section again. Here, we will create a function for the responses:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 余弦相似度指标在 *第 2 章* 的 *使用余弦相似度评估输出* 部分进行了描述。如果需要，请花时间再次阅读该部分。在这里，我们将创建一个用于响应的函数：
- en: '[PRE27]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The function uses `sklearn` and also Hugging Face’s `SentenceTransformer`. The
    program first creates the vector store engine.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数使用 `sklearn` 和 Hugging Face 的 `SentenceTransformer`。程序首先创建向量存储引擎。
- en: Vector store index query engine
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 向量存储索引查询引擎
- en: '`VectorStoreIndex` is a type of index within LlamaIndex that implements vector
    embeddings to represent and retrieve information from documents. These documents
    with similar meanings will have embeddings that are closer together in the vector
    space, as we explored in the previous chapter. However, this time, the `VectorStoreIndex`
    does not automatically use the existing Deep Lake vector store. It can create
    a new in-memory vector index, re-embed the documents, and create a new index structure.
    We will take this approach further in *Chapter 4*, *Multimodal Modular RAG for
    Drone Technology*, when we implement a dataset that contains no indexes or embeddings.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`VectorStoreIndex` 是 LlamaIndex 中的一种索引类型，它通过向量嵌入来表示和检索文档中的信息。与上一章中探讨的类似意义的文档将具有在向量空间中更接近的嵌入，然而这次，`VectorStoreIndex`
    并不会自动使用现有的 Deep Lake 向量存储。它可以创建一个新的内存向量索引，重新嵌入文档，并创建一个新的索引结构。我们将在 *第 4 章*，*多模态模块化
    RAG 用于无人机技术* 中进一步探讨这种方法，当我们实现一个不包含索引或嵌入的数据集时。'
- en: There is no silver bullet to deciding which indexing method is suitable for
    your project! The best way to make a choice is to test the vector, tree, list,
    and keyword indexes introduced in this chapter.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在决定哪种索引方法适合您的项目时没有一劳永逸的方法！最佳选择方法是测试本章中介绍的向量、树、列表和关键词索引。
- en: 'We will first create the vector store index:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建向量存储索引：
- en: '[PRE28]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We then display the vector store index we created:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们显示我们创建的向量存储索引：
- en: '[PRE29]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We will receive the following output, which confirms that the engine was created:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将收到以下输出，这确认了引擎已被创建：
- en: '[PRE30]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We now need a query engine to retrieve and synthesize the document(s) retrieved
    with an LLM—in our case, an OpenAI model (installed with `!pip install llama-index-vector-stores-deeplake==0.1.2`):'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要一个查询引擎来检索和综合使用 LLM（在我们的例子中是 OpenAI 模型，通过 `!pip install llama-index-vector-stores-deeplake==0.1.2`
    安装）检索到的文档：
- en: '[PRE31]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We defined the parameters of the query engine in the *User input and query parameters*
    subsection. We can now query the dataset and generate a response.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*用户输入和查询参数*子节中定义了查询引擎的参数。我们现在可以查询数据集并生成响应。
- en: Query response and source
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询响应和来源
- en: 'Let’s define a function that will manage the query and return information on
    the content of the response:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个函数来管理查询并返回响应内容的信息：
- en: '[PRE32]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '`index_query(input_query)` executes a query using a vector query engine and
    processes the results into a structured format. The function takes an input query
    and retrieves relevant information, using the query engine in a pandas DataFrame:
    `Node ID`, `Score`, `File Path`, `Filename`, and `Text`.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`index_query(input_query)` 使用向量查询引擎执行查询，并将结果处理成结构化格式。该函数接受一个输入查询，并使用pandas
    DataFrame中的查询引擎检索相关信息：`节点ID`、`得分`、`文件路径`、`文件名`和`文本`。'
- en: 'The code will now call the query:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 代码现在将调用查询：
- en: '[PRE33]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We will evaluate the time it takes for the query to retrieve the relevant data
    and generate a response synthesis with the LLM (in this case, an OpenAI model).
    The output of the semantic search first returns a response synthesized by the
    LLM:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将评估查询检索相关数据并使用LLM（在这种情况下，是一个OpenAI模型）生成响应合成所需的时间。语义搜索的输出首先返回由LLM合成的响应：
- en: '[PRE34]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The output then displays the elapsed time of the query:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 输出随后显示查询的经过时间：
- en: '[PRE35]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The output now displays node information. The score of each node of three `k=3`
    documents was retrieved with their text excerpts:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 输出现在显示节点信息。三个`k=3`文档的每个节点的得分及其文本摘录被检索出来：
- en: '![A close-up of a number  Description automatically generated](img/B31169_03_04.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![数字的特写  自动生成的描述](img/B31169_03_04.png)'
- en: 'Figure 3.4: Node information output'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4：节点信息输出
- en: 'The ID of the node guarantees full transparency and can be traced back to the
    original document, even when the index engines re-index the dataset. We can obtain
    the node source of the first node, for example, with the following code:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 节点的ID保证了完全的透明度，并且可以在索引引擎重新索引数据集时追溯回原始文档。例如，我们可以使用以下代码获取第一个节点的节点源：
- en: '[PRE36]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output provides the node ID:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 输出提供了节点ID：
- en: '[PRE37]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We can drill down and retrieve the full text of the node containing the document
    that was synthesized by the LLM:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以深入挖掘并检索由LLM合成的文档所包含的节点的全文：
- en: '[PRE38]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The output will display the following text:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将显示以下文本：
- en: '[PRE39]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: We can also peek into the nodes and retrieve their chunk size.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以查看节点并检索它们的分块大小。
- en: Optimized chunking
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化分块
- en: 'We can predefine the chunk size, or we can let LlamaIndex select it for us.
    In this case, the code determines the chunk size automatically:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以预先定义分块大小，或者我们可以让LlamaIndex为我们选择。在这种情况下，代码自动确定分块大小：
- en: '[PRE40]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The advantage of an automated chunk size is that it can be variable. For example,
    in this case, the chunk size shown in the size of the output nodes is probably
    in the 4000-to-5500-character range:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化分块大小的优势在于它可以变化。例如，在这种情况下，输出节点大小中显示的分块大小可能在4000到5500个字符的范围内：
- en: '[PRE41]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The chunking function does not linearly cut content but optimizes the chunks
    for semantic search.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 分块函数不是线性切割内容，而是优化分块以进行语义搜索。
- en: Performance metric
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能指标
- en: We will also implement a performance metric based on the accuracy of the queries
    and the time elapsed. This function calculates and prints a performance metric
    for a query, along with its execution time. The metric is based on the weighted
    average relevance scores of the retrieved information, divided by the time it
    took to get the results. Higher scores indicate better performance.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将实现一个基于查询准确性和经过时间的性能指标。此函数计算并打印查询的性能指标及其执行时间。该指标基于检索信息的加权平均相关度得分，除以获取结果所需的时间。更高的分数表示更好的性能。
- en: 'We first calculate the sum of the scores and the average score, and then we
    divide the weighted average by the time elapsed to perform the query:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先计算得分的总和和平均得分，然后我们将加权平均除以查询经过的时间：
- en: '[PRE42]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The result is a ratio based on the average weight divided by the elapsed time:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是基于平均权重除以经过的时间的比率：
- en: '[PRE43]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'We can then call the function:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以调用该函数：
- en: '[PRE44]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The output provides an estimation of the quality of the response:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 输出提供了对响应质量的估计：
- en: '[PRE45]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: This performance metric is not an absolute value. It’s an indicator that we
    can use to compare this output with the other index engines. It may also vary
    from one run to another, due to the stochastic nature of machine learning algorithms.
    Additionally, the quality of the output depends on the user’s subjective perception.
    In any case, this metric will help compare the query engines’ performances in
    this chapter.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这个性能指标不是一个绝对值。它是一个我们可以用来比较这个输出与其他索引引擎的指标。它也可能因机器学习算法的随机性质而有所不同。此外，输出的质量取决于用户的主观感知。无论如何，这个指标将有助于比较本章中查询引擎的性能。
- en: We can already see that the average score is satisfactory, even though we loaded
    heterogeneous and sometimes unrelated documents in the dataset. The integrated
    retriever and synthesizer functionality of LlamaIndex, Deep Lake, and OpenAI have
    proven to be highly effective.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经可以看到，尽管我们在数据集中加载了异构的有时甚至无关的文档，平均分数仍然令人满意。LlamaIndex、Deep Lake和OpenAI的集成检索和合成功能已被证明非常有效。
- en: Tree index query engine
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 树索引查询引擎
- en: 'The tree index in LlamaIndex creates a hierarchical structure for managing
    and querying text documents efficiently. However, think of something other than
    a classical hierarchical structure! The tree index engine optimizes the hierarchy,
    content, and order of the nodes, as shown in *Figure 3.5*:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: LlamaIndex中的树索引创建了一个用于高效管理和查询文本文档的分层结构。然而，除了经典分层结构之外，请考虑其他可能性！树索引引擎优化了节点、内容和顺序，如图*3.5*所示：
- en: '![A diagram of a tree index  Description automatically generated](img/B31169_03_05.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![树索引的示意图  自动生成描述](img/B31169_03_05.png)'
- en: 'Figure 3.5: Optimized tree index'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.5：优化的树索引
- en: The tree index organizes documents in a tree structure, with broader summaries
    at higher levels and detailed information at lower levels. Each node in the tree
    summarizes the text it covers. The tree index is efficient for large datasets
    and queries large collections of documents rapidly by breaking them down into
    manageable optimized chunks. Thus, the optimization of the tree structure allows
    for rapid retrieval by traversing the relevant nodes without wasting time.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 树索引以树结构组织文档，在较高层有更广泛的摘要，在较低层有详细信息。树中的每个节点都总结了它覆盖的文本。树索引对大型数据集高效，通过将它们分解成可管理的优化块，快速查询大量文档集合。因此，树结构的优化允许通过遍历相关节点来快速检索，而不浪费时间。
- en: Organizing this part of the pipeline and adjusting parameters such as tree depth
    and summary methods can be a specialized task for a team member. Depending on
    the project and workload, working on the tree structure could be part of **Pipeline
    2** when creating and populating a vector store. Alternatively, the tree structure
    can be created in memory at the beginning of each session. The flexibility of
    the structure and implementation of tree structures and index engines, in general,
    can be a fascinating and valuable specialization in a RAG-driven generative AI
    team.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 组织这部分流程和调整如树深度和摘要方法等参数可能是一个团队成员的专业任务。根据项目和工作量，在创建和填充向量存储时，对树结构的处理可能是**流程2**的一部分。或者，可以在每个会话开始时在内存中创建树结构。树结构和索引引擎的灵活性和实现，在以RAG驱动的生成人工智能团队中，可能是一个令人着迷且有价值的专业化方向。
- en: In this index model, the LLM (an OpenAI model in this case) acts like it is
    answering a multiple-choice question when selecting the best nodes during a query.
    It analyzes the query, compares it with the summaries of the current node’s children,
    and decides which path to follow to find the most relevant information.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个索引模型中，LLM（在本例中为OpenAI模型）在查询过程中选择最佳节点时，表现得像是在回答一个多项选择题。它分析查询，将其与当前节点子节点的摘要进行比较，并决定遵循哪个路径以找到最相关的信息。
- en: The integrated LlamaIndex-Deep Lake-OpenAI process in this chapter is industrializing
    components seamlessly, taking AI to another level. LLM models can now be used
    for embedding, document ranking, and conversational agents. The market offers
    various language models from providers like OpenAI, Cohere, AI21 Labs, and Hugging
    Face. LLMs have evolved from the early days of being perceived as magic to becoming
    industrialized, seamless, multifunctional, and integrated components of broader
    AI pipelines.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中集成的LlamaIndex-Deep Lake-OpenAI流程正在无缝地工业化组件，将人工智能提升到了另一个层次。现在，LLM模型可用于嵌入、文档排名和对话代理。市场上提供了来自OpenAI、Cohere、AI21
    Labs和Hugging Face等提供商的各种语言模型。LLM已经从早期被视为魔法般的存在，发展成为工业化的、无缝的、多功能和更广泛人工智能管道的集成组件。
- en: 'Let’s create a tree index in two lines of code:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在两行代码中创建一个树索引：
- en: '[PRE46]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The code then checks the class we just created:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 代码随后检查我们刚刚创建的类：
- en: '[PRE47]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output confirms that we are in the `TreeIndex` class:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认我们处于`TreeIndex`类：
- en: '[PRE48]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We can now make our tree index the query engine:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将我们的树索引作为查询引擎：
- en: '[PRE49]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The parameters of the LLM are those defined in the *User input and query parameters*
    section. The code now calls the query, measures the time elapsed, and processes
    the response:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的参数是在*用户输入和查询参数*部分定义的。现在代码调用查询，测量经过的时间，并处理响应：
- en: '[PRE50]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The query time and the response are both satisfactory:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 查询时间和响应都是令人满意的：
- en: '[PRE51]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Let’s apply a performance metric to the output.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将性能指标应用于输出。
- en: Performance metric
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能指标
- en: 'This performance metric will calculate the cosine similarity defined in the
    *Cosine similarity metric* section between the user input and the response of
    our RAG pipeline:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 这个性能指标将计算在*余弦相似度指标*部分定义的余弦相似度，它是用户输入和我们的RAG管道响应之间的相似度：
- en: '[PRE52]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The output shows that although the quality of the response was satisfactory,
    the execution time was slow, which brings the performance metric down:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，尽管响应质量令人满意，但执行时间较慢，这降低了性能指标：
- en: '[PRE53]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Of course, the execution time depends on the server (power) and the data (noise).
    As established earlier, the execution times might vary from one run to another,
    due to the stochastic algorithms used. Also, when the dataset increases in volume,
    the execution times of all the indexing types may change.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，执行时间取决于服务器（功率）和数据（噪声）。如前所述，由于使用了随机算法，执行时间可能从一个运行到另一个运行会有所变化。此外，当数据集的体积增加时，所有索引类型的执行时间可能会改变。
- en: The list index query engine may or may not be better in this case. Let’s run
    it to find out.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，列表索引查询引擎可能更好，也可能不那么好。让我们运行它来找出答案。
- en: List index query engine
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 列表索引查询引擎
- en: Don’t think of `ListIndex` as simply a list of nodes. The query engine will
    process the user input and each document as a prompt for an LLM. The LLM will
    evaluate the semantic similarity relationship between the documents and the query,
    thus implicitly ranking and selecting the most relevant nodes. LlamaIndex will
    filter the documents based on the rankings obtained, and it can also take the
    task further by synthesizing information from multiple nodes and documents.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 不要将`ListIndex`仅仅视为节点列表。查询引擎将处理用户输入和每个文档作为LLM的提示。LLM将评估文档和查询之间的语义相似度关系，从而隐式地排名和选择最相关的节点。LlamaIndex将根据获得的排名过滤文档，并且它还可以通过从多个节点和文档中综合信息来进一步完成任务。
- en: We can see that the selection process with an LLM is not rule-based. Nothing
    is predefined, which means that the selection is prompt-based by combining the
    user input with a collection of documents. The LLM evaluates each document in
    the list *independently*, assigning a score based on its perceived relevance to
    the query. This score isn’t relative to other documents; it’s a measure of how
    well the LLM thinks the current document answers the question. Then, the top-k
    documents are retained by the query engine if we wish, as in the function used
    in this section.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，使用LLM的选择过程不是基于规则的。没有预先定义的内容，这意味着选择是基于提示的，通过将用户输入与文档集合相结合。LLM会独立评估列表中的每个文档，根据其感知的相关性对查询进行评分。这个评分与其他文档无关；它是LLM认为当前文档回答问题的好坏的度量。然后，如果需要，查询引擎会保留前k个文档，如本节中使用的函数所示。
- en: 'Like the tree index, the list index can also be created in two lines of code:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 与树索引一样，列表索引也可以在两行代码中创建：
- en: '[PRE54]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The code verifies the class that we are using:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 代码验证了我们使用的类：
- en: '[PRE55]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output confirms that we are in the `list` class:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认我们处于`list`类：
- en: '[PRE56]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The list index is a `SummaryIndex`, which shows the large amount of document
    summary optimization that is running under the hood! We can now utilize our list
    index as a query engine in the seamless framework provided by LlamaIndex:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 列表索引是一个`SummaryIndex`，它显示了在底层运行的大量文档摘要优化！现在我们可以利用我们的列表索引作为LlamaIndex提供的无缝框架中的查询引擎：
- en: '[PRE57]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The LLM parameters remain unchanged so that we can compare the indexing types.
    We can now run our query, wrap the response up, and display the output:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: LLM参数保持不变，这样我们就可以比较索引类型。现在我们可以运行我们的查询，封装响应，并显示输出：
- en: '[PRE58]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The output shows a longer execution time but an acceptable response:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示较长的执行时间，但响应是可以接受的：
- en: '[PRE59]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The execution time is longer because the query goes through a list, not an optimized
    tree. However, we cannot draw conclusions from this because each project or even
    each sub-task of a project has different requirements. Next, let’s apply the performance
    metric.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 执行时间较长是因为查询是通过列表而不是优化后的树进行的。然而，我们不能从这个结果中得出结论，因为每个项目或甚至每个项目的子任务都有不同的要求。接下来，让我们应用性能指标。
- en: Performance metric
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能指标
- en: 'We will use the cosine similarity, as we did for the tree index, to evaluate
    the similarity score:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用余弦相似度，就像我们为树索引所做的那样，来评估相似度得分：
- en: '[PRE60]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The performance metric is lower than the tree index due to the longer execution
    time:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 由于执行时间较长，性能指标低于树索引：
- en: '[PRE61]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Again, remember that this execution time may vary from one run to another, due
    to the stochastic algorithms implemented.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，由于实现了随机算法，执行时间可能从一次运行到另一次运行会有所不同。
- en: If we look back at the performance metric of each indexing type, we can see
    that, for the moment, the vector store index was the fastest. Once again, let’s
    not jump to conclusions. Each project might produce surprising results, depending
    on the type and complexity of the data processed. Next, let’s examine the keyword
    index.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们回顾每种索引类型的性能指标，我们可以看到，目前，向量存储索引是最快的。但请再次记住，不要急于下结论。每个项目可能会根据处理数据的类型和复杂性产生令人惊讶的结果。接下来，让我们来检查一下关键词索引。
- en: Keyword index query engine
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键词索引查询引擎
- en: '`KeywordTableIndex` is a type of index in LlamaIndex, designed to extract keywords
    from your documents and organize them in a table-like structure. This structure
    makes it easier to query and retrieve relevant information based on specific keywords
    or topics. Once again, don’t think about this function as a simple list of extracted
    keywords. The extracted keywords are organized into a table-like format where
    each keyword is associated with an ID that points to the related nodes.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '`KeywordTableIndex`是LlamaIndex中的一种索引类型，旨在从您的文档中提取关键词并将它们组织成类似表格的结构。这种结构使得根据特定的关键词或主题查询和检索相关信息变得更加容易。再次强调，不要将此功能视为简单的提取关键词列表。提取的关键词被组织成类似表格的格式，其中每个关键词都与一个ID相关联，该ID指向相关的节点。'
- en: 'The program creates the keyword index in two lines of code:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 程序用两行代码创建了关键词索引：
- en: '[PRE62]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Let’s extract the data and create a pandas DataFrame to see how the index is
    structured:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们提取数据并创建一个pandas DataFrame来查看索引的结构：
- en: '[PRE63]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The output shows that each keyword is associated with an ID that contains a
    document or a summary, depending on the way LlamaIndex optimizes the index:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示每个关键词都与一个ID相关联，该ID包含一个文档或摘要，具体取决于LlamaIndex如何优化索引：
- en: '![A screenshot of a computer  Description automatically generated](img/B31169_03_06.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，描述由系统自动生成](img/B31169_03_06.png)'
- en: 'Figure 3.6: Keywords linked to document IDs in a DataFrame'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.6：DataFrame中的关键词与文档ID的链接
- en: 'We now define the keyword index as the query engine:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将关键词索引定义为查询引擎：
- en: '[PRE64]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Let’s run the keyword query and see how well and fast it can produce a response:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行关键词查询，看看它如何快速地产生响应：
- en: '[PRE65]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The output is satisfactory, as well as the execution time:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 输出和执行时间都是令人满意的：
- en: '[PRE66]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: We can now measure the output with a performance metric.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用性能指标来衡量输出。
- en: Performance metric
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能指标
- en: 'The code runs the same metric as for the tree and list index:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 代码运行了与树索引和列表索引相同的指标：
- en: '[PRE67]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The performance metric is acceptable:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 性能指标是可以接受的：
- en: '[PRE68]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Once again, we can draw no conclusions. The results of all the indexing types
    are relatively satisfactory. However, each project comes with its dataset complexity
    and machine power availability. Also, the execution times may vary from one run
    to another, due to the stochastic algorithms employed.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，我们无法得出结论。所有索引类型的成果相对令人满意。然而，每个项目都伴随着其数据集的复杂性和机器能力的可用性。此外，由于使用了随机算法，执行时间可能从一次运行到另一次运行会有所不同。
- en: With that, we have reviewed some of the main indexing types and retrieval strategies.
    Let’s summarize the chapter and move on to multimodal modular retrieval and generation
    strategies.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们已经回顾了一些主要的索引类型和检索策略。让我们总结本章内容，并继续探讨多模态模块化检索和生成策略。
- en: Summary
  id: totrans-305
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This chapter explored the transformative impact of index-based search on RAG
    and introduced a pivotal advancement: *full traceability*. The documents become
    nodes that contain chunks of data, with the source of a query leading us all the
    way back to the original data. Indexes also increase the speed of retrievals,
    which is critical as the volume of datasets increases. Another pivotal advance
    is the integration of technologies such as LlamaIndex, Deep Lake, and OpenAI,
    which are emerging in another era of AI. The most advanced AI models, such as
    OpenAI GPT-4o, Hugging Face, and Cohere, are becoming seamless *components* in
    a RAG-driven generative AI pipeline, like GPUs in a computer.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了基于索引的搜索对 RAG 的变革性影响，并介绍了一项关键进步：*完全可追溯性*。文档成为包含数据块节点的集合，查询的来源将我们带回到原始数据。索引还提高了检索速度，这对于数据集量的增加至关重要。另一项关键进步是集成
    LlamaIndex、Deep Lake 和 OpenAI 等技术，这些技术正在 AI 的另一个时代兴起。最先进的 AI 模型，如 OpenAI GPT-4o、Hugging
    Face 和 Cohere，正在成为由 RAG 驱动的生成式 AI 管道中的无缝 *组件*，就像计算机中的 GPU 一样。
- en: We started by detailing the architecture of an index-based RAG generative AI
    pipeline, illustrating how these sophisticated technologies can be seamlessly
    integrated to boost the creation of advanced indexing and retrieval systems. The
    complexity of AI implementation is changing the way we organize separate pipelines
    and functionality for a team working in parallel on projects that scale and involve
    large amounts of data. We saw how every response generated can be traced back
    to its source, providing clear visibility into the origins and accuracy of the
    information used. We illustrated the advanced RAG technology implemented through
    drone technology.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先详细介绍了基于索引的 RAG 生成式 AI 管道的架构，说明了这些复杂技术如何无缝集成以提升高级索引和检索系统的创建。AI 实现的复杂性正在改变我们组织并行工作在扩展项目和大量数据上的团队单独管道和功能的方式。我们看到了每个生成的响应都可以追溯到其来源，从而提供了对信息来源和准确性的清晰可见性。我们展示了通过无人机技术实现的先进
    RAG 技术。
- en: Throughout the chapter, we introduced the essential tools to build these systems,
    including vector stores, datasets, chunking, embedding, node creation, ranking,
    and indexing methods. We implemented the LlamaIndex framework, Deep Lake vector
    stores, and OpenAI’s models. We also built a Python program that collects data
    and adds critical metadata to pinpoint the origin of every chunk of data in a
    dataset. We highlighted the pivotal role of indexes (vector, tree, list, and keyword
    types) in giving us greater control over generative AI applications, enabling
    precise adjustments and improvements.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了构建这些系统的基本工具，包括向量存储、数据集、分块、嵌入、节点创建、排名和索引方法。我们实现了 LlamaIndex 框架、Deep
    Lake 向量存储和 OpenAI 的模型。我们还构建了一个 Python 程序，该程序收集数据并为数据集中的每个数据块添加关键元数据，以确定数据块的来源。我们强调了索引（向量、树、列表和关键词类型）在赋予我们对生成式
    AI 应用更大控制权方面的重要作用，使精确调整和改进成为可能。
- en: We then thoroughly examined indexed-based RAG through detailed walkthroughs
    in Python notebooks, guiding you through setting up vector stores, conducting
    advanced queries, and ensuring the traceability of AI-generated responses. We
    introduced metrics based on the quality of a response and the time elapsed to
    obtain it. Exploring drone technology with LLMs showed us the new skillsets required
    to build solid AI pipelines, and we learned how drone technology involves computer
    vision and, thus, multimodal nodes.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后通过在 Python 笔记本中的详细操作流程，彻底检查了基于索引的 RAG，引导您设置向量存储、执行高级查询，并确保 AI 生成的响应的可追溯性。我们引入了基于响应质量和获取响应所需时间的指标。使用大型语言模型（LLMs）探索无人机技术，让我们看到了构建稳固
    AI 管道所需的新技能集，并了解了无人机技术如何涉及计算机视觉，从而涉及多模态节点。
- en: In the upcoming chapter, we include multimodal data in our datasets and expand
    multimodular RAG.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将多模态数据纳入我们的数据集，并扩展多模态 RAG。
- en: Questions
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Answer the following questions with *Yes* or *No*:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 用 *Yes* 或 *No* 回答以下问题：
- en: Do indexes increase precision and speed in retrieval-augmented generative AI?
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引在检索增强的生成式 AI 中是否可以提高精确性和速度？
- en: Can indexes offer traceability for RAG outputs?
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索引可以为 RAG 输出提供可追溯性吗？
- en: Is index-based search slower than vector-based search for large datasets?
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于大型数据集，基于索引的搜索是否比基于向量的搜索慢？
- en: Does LlamaIndex integrate seamlessly with Deep Lake and OpenAI?
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LlamaIndex 是否与 Deep Lake 和 OpenAI 无缝集成？
- en: Are tree, list, vector, and keyword indexes the only types of indexes?
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 树、列表、向量和关键词索引是唯一的索引类型吗？
- en: Does the keyword index rely on semantic understanding to retrieve data?
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键字索引是否依赖于语义理解来检索数据？
- en: Is LlamaIndex capable of automatically handling chunking and embedding?
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LlamaIndex 是否能够自动处理分块和嵌入？
- en: Are metadata enhancements crucial for ensuring the traceability of RAG-generated
    outputs?
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元数据增强对于确保 RAG 生成的输出的可追溯性是否至关重要？
- en: Can real-time updates easily be applied to an index-based search system?
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否可以轻松地将实时更新应用于基于索引的搜索系统？
- en: Is cosine similarity a metric used in this chapter to evaluate query accuracy?
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 余弦相似度是否是本章用于评估查询准确性的度量标准？
- en: References
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'LlamaIndex: [https://docs.llamaindex.ai/en/stable/](https://docs.llamaindex.ai/en/stable/)'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'LlamaIndex: [https://docs.llamaindex.ai/en/stable/](https://docs.llamaindex.ai/en/stable/)'
- en: 'Activeloop Deep Lake: [https://docs.activeloop.ai/](https://docs.activeloop.ai/)'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Activeloop Deep Lake: [https://docs.activeloop.ai/](https://docs.activeloop.ai/)'
- en: 'OpenAI: [https://platform.openai.com/docs/overview](https://platform.openai.com/docs/overview)'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenAI: [https://platform.openai.com/docs/overview](https://platform.openai.com/docs/overview)'
- en: Further reading
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'High-Level Concepts (RAG), LlamaIndex: [https://docs.llamaindex.ai/en/stable/getting_started/concepts/](https://docs.llamaindex.ai/en/stable/getting_started/concepts/)'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '高级概念（RAG），LlamaIndex: [https://docs.llamaindex.ai/en/stable/getting_started/concepts/](https://docs.llamaindex.ai/en/stable/getting_started/concepts/)'
- en: Join our community on Discord
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://www.packt.link/rag](https://www.packt.link/rag)'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.packt.link/rag](https://www.packt.link/rag)'
- en: '![](img/QR_Code50409000288080484.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code50409000288080484.png)'
