- en: Sales Forecasting with Deep Learning and Auto Regression
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度学习和自回归进行销售预测
- en: Demand forecasting is key to many industries such as airlines, retail, telecommunications,
    and healthcare. Inaccurate and imprecise demand forecasting leads to missed sales
    and customers, significantly impacting an organization's bottom line. One of the
    key challenges facing retailers is effectively managing inventory based on multiple
    internal and external factors. Inventory management is a complex business problem
    to solve—the demand for a product changes by location, weather, promotions, holidays,
    day of the week, special events, and other external factors, such as store demographics,
    consumer confidence, and unemployment.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 需求预测是许多行业的关键，如航空公司、零售、电信和医疗保健。不准确和不精确的需求预测会导致错失销售和客户，显著影响组织的底线。零售商面临的一个主要挑战是如何有效地管理基于多种内部和外部因素的库存。库存管理是一个复杂的商业问题——产品需求会根据地点、天气、促销活动、节假日、星期几、特殊事件以及其他外部因素（如门店人口统计数据、消费者信心和失业率）发生变化。
- en: In this chapter, we will look at how traditional techniques of time series forecasting
    such as ARIMA and exponential smoothing are different from neural network-based
    techniques. We will also look at how DeepAR works, discussing its model architecture.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究传统的时间序列预测技术（如ARIMA和指数平滑）与基于神经网络的技术有何不同。我们还将讨论DeepAR如何工作，并探讨其模型架构。
- en: 'Following are the topics that will be covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是本章将要涵盖的主题：
- en: Understanding traditional time series forecasting
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解传统时间序列预测
- en: Understanding how the DeepAR model works
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解DeepAR模型的工作原理
- en: Understanding model sales through DeepAR
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过DeepAR理解模型销售
- en: Predicting and evaluating sales
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 销售预测与评估
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For the following sections, we will employ the [retail](https://www.kaggle.com/manjeetsingh/retaildataset)
    dataset containing sales of around 45 stores to illustrate how DeepAR predicts
    future sales given multiple factors such as holidays, promotions, and macro-economic
    indicators (unemployment).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将使用[零售](https://www.kaggle.com/manjeetsingh/retaildataset)数据集，其中包含约45家门店的销售数据，来说明DeepAR如何根据假期、促销和宏观经济指标（如失业率）等多个因素预测未来销售。
- en: 'In the [folder](https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services)
    associated with this chapter, you will find three CSV files:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在与本章相关的[文件夹](https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services)中，您将找到三个CSV文件：
- en: '**Features dataset**: This contains the data of regional activity related to
    the store.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征数据集**：此数据集包含与门店相关的区域活动数据。'
- en: '**Sales dataset**: This contains historical sales data covering three years,
    from 2010 to 2012\. It covers sales for 143 weeks.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**销售数据集**：此数据集包含2010年至2012年间的历史销售数据，覆盖了143周。'
- en: '**Store dataset:**This contains anonymized information about the 45 stores,
    including the type and size of the store.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**门店数据集**：此数据集包含关于45家门店的匿名化信息，包括门店类型和大小。'
- en: 'Please refer to the following link of GitHub for the source code of this chapter:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考以下GitHub链接获取本章的源代码：
- en: '[https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services](https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services](https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services)'
- en: It is now time to understand traditional time series forecasting techniques.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候理解传统的时间序列预测技术了。
- en: Understanding traditional time series forecasting
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解传统时间序列预测
- en: Let's begin by looking at traditional time series forecasting techniques, specifically
    ARIMA and exponential smoothing to model demand in simple use cases. We will look
    at how ARIMA estimates sales using historical sales and forecast errors. Also,
    we'll review how exponential smoothing accounts for irregularities in historical
    sales and captures trends and seasonality to forecast sales.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从研究传统的时间序列预测技术开始，具体来说是ARIMA和指数平滑方法，以便在简单的使用案例中建模需求。我们将研究ARIMA如何利用历史销售数据和预测误差来估算销售。此外，我们还将回顾指数平滑如何处理历史销售数据中的不规则性，并捕捉趋势和季节性变化来预测销售。
- en: Auto-Regressive Integrated Moving Average (ARIMA )
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自回归积分滑动平均（ARIMA）
- en: ARIMA is a time series analytical technique used to capture different temporal
    structures in univariate data. To model the time series data, differencing is
    applied across the series to make the data stationary. Differencing is the technique
    of subtracting the previous data point from the current one for every data point
    excluding the first one. The technique makes the mean and variance of the probability
    distribution of the time series constant over time, making future values of the
    series much more predictable. A specific number of lagged forecasts and forecast
    errors are used to model time series. This number is iteratively adjusted until
    the residuals are uncorrelated with the target (sales forecast) or all of the
    signals in the data have been picked up.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ARIMA是一种时间序列分析技术，用于捕捉单变量数据中的不同时间结构。为了对时间序列数据建模，对数据进行差分处理，使其平稳。差分技术是指对每个数据点（不包括第一个数据点），用当前数据点减去前一个数据点。此技术使得时间序列的概率分布的均值和方差在时间上保持不变，从而使得未来值的预测更加可靠。使用特定数量的滞后预测和预测误差来建模时间序列。该数量会通过迭代调整，直到残差与目标（销售预测）不相关，或者数据中的所有信号都已被捕捉。
- en: 'Let''s unpack ARIMA to look at the underlying components—autoregressive, integrated,
    and moving average:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解析ARIMA，看看其基本组成部分——自回归、差分和移动平均：
- en: '**The number of autoregressive terms**: These establish a relationship between
    a specific number of historical data points and the current one that is, it uses
    historical demand to estimate the current demand.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自回归项的数量**：这些项建立了特定数量历史数据点与当前数据点之间的关系，也就是说，它利用历史需求来估算当前需求。'
- en: '**The number of non-seasonal differences**: These make temporal or time series
    data stationary by differencing. We''re assuming that future demand will look
    like historical demand if the difference in demand during the last few time steps
    is very small.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非季节性差分的数量**：这些通过差分使时间序列数据变得平稳。我们假设，如果过去几次时间步长中的需求差异非常小，未来的需求将与历史需求相似。'
- en: '**The number of moving-average terms (lagged forecast errors**): These account
    for forecast error—actual versus forecasted demand—or a specific number of historical
    data points.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**移动平均项的数量（滞后预测误差）**：这些项考虑了预测误差——实际需求与预测需求之间的差异——或者特定数量的历史数据点。'
- en: 'Let''s look at the ARIMA equation, both in words and mathematical form:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下ARIMA方程，既有文字描述也有数学表达形式：
- en: '*Demand forecast = constant term + autoregressive terms + moving average terms*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*需求预测 = 常数项 + 自回归项 + 滚动平均项*'
- en: '![](img/f5713d77-c78b-494d-b4f8-d86d38c16ad1.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f5713d77-c78b-494d-b4f8-d86d38c16ad1.png)'
- en: 'Here is a visual representation of how ARIMA works:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是ARIMA工作原理的可视化表示：
- en: '![](img/33aca5fa-63ba-47e5-92e2-2233610d3166.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/33aca5fa-63ba-47e5-92e2-2233610d3166.png)'
- en: In the ARIMA model, the AR terms are positive, while the MA terms are negative;
    in other words, the autoregressive terms have a positive impact on demand while
    the moving-average of lagged errors has a negative impact.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在ARIMA模型中，AR项为正，而MA项为负；换句话说，自回归项对需求产生正面影响，而滞后误差的移动平均则对需求产生负面影响。
- en: Exponential smoothing
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指数平滑
- en: The other alternative to ARIMA is the exponential smoothing technique, which
    is also a time series forecasting method for univariate data, where random noise
    is neglected, revealing the underlying time structure. Although it is like ARIMA
    in that demand forecast is a weighted sum of past observations, the method of
    applying weights to lagged observations is different—instead of providing equal
    weights to past observations, the model employs exponentially decreasing weights
    for lags. In other words, the most recent observations are more relevant than
    historical ones. Exponential smoothing is used to make short-term forecasts, where
    we assume that future patterns and trends will look like current patterns and
    trends.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ARIMA的另一种替代方法是指数平滑技术，这也是一种用于单变量数据的时间序列预测方法，其中忽略了随机噪声，揭示了潜在的时间结构。尽管它与ARIMA类似，都是将过去的观测值加权求和来进行需求预测，但加权应用的方法不同——它并不是对过去的观测值赋予相等的权重，而是对滞后的观测值应用指数衰减的权重。换句话说，最近的观测值比历史数据更为相关。指数平滑用于进行短期预测，我们假设未来的模式和趋势将与当前的模式和趋势相似。
- en: 'Following are the three types of exponential smoothing methods:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是三种类型的指数平滑方法：
- en: '**Single exponential smoothing**: As the name indicates, the technique does
    not account for seasonality or trend. It requires a single parameter, alpha (![](img/9b3dc95b-fb71-42e8-a1be-ecafa0677063.png)),
    to control the level of smoothing. Low alpha means there are no irregularities
    in the data, implying that the latest observations are given lower weight.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单一指数平滑**：顾名思义，这种技术不考虑季节性或趋势。它需要一个单一参数，alpha (![](img/9b3dc95b-fb71-42e8-a1be-ecafa0677063.png))，来控制平滑程度。低
    alpha 表示数据中没有不规则性，意味着最新的观察值被赋予较低的权重。'
- en: '**Double exponential smoothing**: This technique, on the other hand, supports
    trends in univariate series. In addition to controlling how important recent observations
    are relative to historical ones, an additional factor is used to control the influence
    of trend on demand forecasts. The trend can be either multiplicative or additive
    and is controlled using a smoothing factor, ![](img/4d2ce8ab-d8fd-4828-9883-1e50e0960d31.png).'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**双重指数平滑**：这种技术支持单变量序列中的趋势。除了控制最近观察值与历史观察值之间的重要性外，还使用一个额外的因子来控制趋势对需求预测的影响。趋势可以是乘法型的也可以是加法型的，并通过平滑因子
    ![](img/4d2ce8ab-d8fd-4828-9883-1e50e0960d31.png) 来控制。'
- en: '**Triple exponential smoothing**: This one adds support for seasonality. Another
    new parameter, gamma (![](img/1d5a8cac-5805-4fd7-b1ef-bad2f80d0901.png)), is used
    to control the influence of the seasonal component on demand forecasts.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**三重指数平滑**：此方法支持季节性。另一个新参数，gamma (![](img/1d5a8cac-5805-4fd7-b1ef-bad2f80d0901.png))，用于控制季节性因素对需求预测的影响。'
- en: 'The following diagram illustrates the difference between the different types
    of exponential smoothing:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了不同类型的指数平滑方法之间的区别：
- en: '![](img/92261167-415b-47bb-a882-29ff7b30e1a6.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/92261167-415b-47bb-a882-29ff7b30e1a6.png)'
- en: 'In the preceding diagram, we can see the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图示中，我们可以看到以下内容：
- en: Single exponential smoothing that forecasts demand at time, *t*, is based on
    estimated demand and forecast error (actual—estimated demand) at time, *t-1*.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过单一指数平滑预测在时刻 *t* 的需求，基于时刻 *t-1* 处的估计需求和预测误差（实际需求—估计需求）。
- en: 'In the case of double exponential smoothing, demand is forecasted by capturing
    both trend and historical data. We use two smoothing factors here, data and trend
    (here''s a visual on how double exponential smoothing captures trends):'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在双重指数平滑的情况下，需求通过捕捉趋势和历史数据来进行预测。我们在这里使用两个平滑因子，数据和平滑趋势（以下是双重指数平滑如何捕捉趋势的可视化图示）：
- en: '![](img/e96e3a23-7a46-4c74-bf70-9ecd3f451aed.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e96e3a23-7a46-4c74-bf70-9ecd3f451aed.png)'
- en: 'For triple exponential smoothing, we also account for seasonality through a
    third smoothing factor called a seasonal smoothing factor. See the following diagram,
    which captures seasonal peaks and troughs, along with trend:'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于三重指数平滑，我们还通过一个名为季节性平滑因子的第三个平滑因子来考虑季节性。请参见下图，它展示了季节性高峰和低谷，以及趋势：
- en: '![](img/30cb92f2-f89e-4b0f-ac64-25e3b97dd9a1.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/30cb92f2-f89e-4b0f-ac64-25e3b97dd9a1.png)'
- en: The problem with this approach is that it views past sales as indicative of
    future sales. Besides, they are all forecasting techniques for univariate time
    series. As detailed earlier, there could be other factors that impact current
    and future sales, such as weather, promotions, day of the week, holidays, and
    special events.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的问题在于它将过去的销售数据视为未来销售的指标。此外，这些方法都是针对单一时间序列的预测技术。正如前面所详细说明的那样，可能会有其他因素影响当前和未来的销售情况，如天气、促销、星期几、节假日和特殊事件。
- en: Let's look at how the DeepAR model from SageMaker can be leveraged to model
    multi-variate time series, defining a non-linear relationship between an output
    variable (demand) and input variables (includes historical sales, promotions,
    weather, and time of the day.)
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下如何利用 SageMaker 的 DeepAR 模型来建模多变量时间序列，定义输出变量（需求）与输入变量（包括历史销售数据、促销、天气和一天中的时间）之间的非线性关系。
- en: How the DeepAR model works
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DeepAR 模型是如何工作的
- en: The DeepAR algorithm offered by Sagemaker is a generalized deep learning model
    that learns about demand across several related time series. Unlike traditional
    forecasting methods, in which an individual time series is modeled, DeepAR models
    thousands or millions of related time series.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Sagemaker 提供的 DeepAR 算法是一个通用的深度学习模型，能够学习多个相关时间序列中的需求。与传统的预测方法不同，传统方法是针对单个时间序列进行建模，而
    DeepAR 则可以建模成千上万甚至百万个相关时间序列。
- en: Examples include forecasting load for servers in a data center, or forecasting
    demand for all products that a retailer offers, and energy consumption of individual
    households. The unique thing about this approach is that a substantial amount
    of data on past behavior of similar or related time series can be leveraged for
    forecasting an individual time series. This approach addresses over-fitting issues
    and time—and labor-intensive manual feature engineering and model selection steps
    required by traditional techniques.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在数据中心预测服务器负载，或预测零售商提供的所有产品的需求，或预测各个家庭的能源消耗。该方法的独特之处在于，能够利用大量关于类似或相关时间序列的过去行为数据来预测单个时间序列。这种方法解决了传统技术所面临的过拟合问题，以及所需的时间和劳动密集型的手动特征工程和模型选择步骤。
- en: 'DeepAR is a forecasting method based on autoregressive neural networks and
    it learns about a global model from historical data of all-time series in the
    data set. DeepAR employs **Long Short-Term Memory** (**LSTM**), a type of **Recurrent
    Neural Network** (**RNN**), to model time series. The main idea of RNNs is to
    capture sequential information. Unlike normal neural networks, the inputs (and
    outputs) are dependent on each other. RNNs hence have a memory that captures information
    about what has been estimated so far. The following is a diagram of an unfolded
    RNN—to remember what has been learned so far, at each step, the hidden state is
    computed, not only based on the current input, but also the previous hidden state:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: DeepAR是一种基于自回归神经网络的预测方法，它通过数据集中所有时间序列的历史数据学习全局模型。DeepAR使用**长短期记忆**（**LSTM**），一种**递归神经网络**（**RNN**），来建模时间序列。RNN的主要思想是捕捉顺序信息。与普通神经网络不同，输入（和输出）是相互依赖的。因此，RNN具有记忆功能，能够捕捉到迄今为止所估算的信息。以下是展开的RNN示意图——为了记住已学习的信息，在每一步中，隐藏状态的计算不仅基于当前输入，还基于先前的隐藏状态：
- en: '![](img/42eb4d1b-9929-46e3-8d68-79f721545547.png)*A recurrent neural network
    and illustration of sequential learning as the time steps are unfolded. Source:
    Nature; Image Credits* *[WildML](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)*[.](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/42eb4d1b-9929-46e3-8d68-79f721545547.png)*递归神经网络和随着时间步展开的顺序学习示意图。来源：Nature；图片来源*
    *[WildML](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)*[.](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)'
- en: 'Let''s explain in more detail:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地解释一下：
- en: '![](img/a87f6d79-2416-4f6f-97f2-29c700f669cb.png) is input at a time, *t.*'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/a87f6d79-2416-4f6f-97f2-29c700f669cb.png)在时间*t*时输入。'
- en: '**[![](img/993cee63-e3bb-4921-b07c-84c9ca961f8b.png)]** is the hidden state
    at time, *t*. This state is computed based on previous hidden state and current
    input, and in [![](img/de230eb3-e03d-4922-a6c0-93e7b113f3fc.png)], function, *f*,
    is an activation function.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[![](img/993cee63-e3bb-4921-b07c-84c9ca961f8b.png)]**是在时间*t*时的隐藏状态。这个状态是基于之前的隐藏状态和当前输入计算得出的，在[![](img/de230eb3-e03d-4922-a6c0-93e7b113f3fc.png)]中，*f*是激活函数。'
- en: '*[![](img/b5a3338a-e13a-4540-90a4-dbab88ba7dcb.png)]* is output at time, *t*,
    and [![](img/e8a8ae94-70b9-4b1c-9bf2-d62459b40b1e.png)]. The activation function,
    *f*, can vary depending on the use case. For example, the softmax activation function
    is used when we need to predict which of the classes the input belongs to—in other
    words, whether the image being detected is a cat or a dog or a giraffe.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*[![](img/b5a3338a-e13a-4540-90a4-dbab88ba7dcb.png)]*是在时间*t*时的输出，[![](img/e8a8ae94-70b9-4b1c-9bf2-d62459b40b1e.png)]。激活函数，*f*，根据具体应用可能有所不同。例如，当我们需要预测输入属于哪个类别时，会使用softmax激活函数——换句话说，是否检测到的图像是一只猫、一只狗还是一只长颈鹿。'
- en: The network weights, *U*, *V,* and *W*, remain the same across all of the time
    steps.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络权重，*U*，*V*，和*W*，在所有时间步中保持不变。
- en: 'RNNs have interesting applications in different fields, such as the following:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: RNN在不同领域有着有趣的应用，举例如下：
- en: '**Natural language processing**: From generating image captions to generating
    text to machine translations, RNNs can act as generative models.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自然语言处理**：从生成图像描述到生成文本，再到机器翻译，RNN可以作为生成模型。'
- en: '**Autonomous cars**: They are used to conduct dynamic facial analysis.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动驾驶汽车**：它们用于进行动态面部分析。'
- en: '**Time series**: RNNs are used in econometrics (finance and trend monitoring)
    and for demand forecasting.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间序列**：RNN广泛应用于计量经济学（金融和趋势监测）和需求预测。'
- en: 'However, general RNNs fail to learn long-term dependencies due to the gap between
    recent and older data. LSTMs, on the other hand, can solve this challenge: the
    inner cells of LSTMs can carry information unchanged through special structures
    called **gates**—input, forget, and output. Through these cells, LSTMs can control
    the information to be retained or erased.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，普通的RNN由于最近数据和较老数据之间的间隙，无法学习长期依赖关系。而LSTM则可以解决这个问题：LSTM的内层单元通过特殊的结构——**门控**（输入、遗忘和输出）——能够不变地携带信息。通过这些单元，LSTM可以控制保留或删除的信息。
- en: Let's now look at the model architecture of DeepAR, an LSTM network.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看DeepAR的模型架构，即LSTM网络。
- en: Model architecture
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型架构
- en: The DeepAR algorithm employs the LSTM network and probability models to identify
    non-linear structures in time series data and provide probabilistic estimates
    of forecasts.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: DeepAR算法采用LSTM网络和概率模型来识别时间序列数据中的非线性结构，并提供预测的概率估计。
- en: The model is autoregressive in that it consumes observations from the last time
    step as input. It is also recurrent since it uses the previous output of the network
    as input at the next time step. During the training phase, the hidden or the encoded
    state of the network, at each time step, is computed based on current covariates,
    previous observation, and previous network output. The hidden state is then used
    to compute parameters for a probability model that characterizes the behavior
    of time series (product demand, for example).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型是自回归的，它将上一个时间步的观察值作为输入。它也是递归的，因为它在下一个时间步使用网络的先前输出作为输入。在训练阶段，网络在每个时间步的隐藏状态或编码状态是基于当前协变量、先前的观察值和先前的网络输出计算的。然后，隐藏状态用于计算概率模型的参数，以描述时间序列的行为（例如，产品需求）。
- en: In other words, we assume the demand to be a random variable following a specific
    probability distribution. Once we have the probability model that can be defined
    through a set of parameters (say, mean and variance), it can be used to estimate
    forecasts. DeepAR uses the Adam optimizer, a stochastic gradient descent algorithm,
    to optimize the maximum log likelihood of training data, given Gaussian model
    parameters. Using this approach, we can derive (optimize) both probability model
    parameters and LSTM parameters to accurately estimate forecasts.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，我们假设需求是一个随机变量，服从特定的概率分布。一旦我们有了可以通过一组参数（如均值和方差）定义的概率模型，就可以用来估计预测值。DeepAR使用Adam优化器——一种随机梯度下降算法——来优化给定高斯模型参数的训练数据的最大对数似然性。通过这种方法，我们可以推导（优化）概率模型参数和LSTM参数，以准确估计预测。
- en: 'The following diagram demonstrates how the DeepAR algorithm works:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了DeepAR算法的工作原理：
- en: '![](img/99f778cb-1c7a-435d-bdb3-51667927ba9c.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99f778cb-1c7a-435d-bdb3-51667927ba9c.png)'
- en: 'As shown in the preceding diagram, **Maximum Likelihood Estimation** (**MLE**)
    is used to estimate two sets of parameters, given all of the time series in the
    input dataset:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，**最大似然估计**（**MLE**）用于估计两组参数，前提是输入数据集中的所有时间序列都已给出：
- en: '**Parameters of RNN**: These parameters or the hidden state of the RNN network
    are used to compute Gaussian parameters.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RNN的参数**：这些参数或RNN网络的隐藏状态用于计算高斯参数。'
- en: '**Parameters of the Gaussian model**: The Gaussian parameters are used to provide
    probabilistic estimates of forecasts.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高斯模型的参数**：高斯参数用于提供预测的概率估计。'
- en: MLE is computed by leveraging data across all time series, *i*, where *i* goes
    from 1 to *N*—that is, there could be *N* different products the demand of which
    you're trying to estimate. *T* represents the length of the time series.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: MLE是通过利用所有时间序列的数据计算的，*i*，其中*i*从1到*N*，也就是说，可能有*N*个不同的产品，其需求是你试图估计的。*T*表示时间序列的长度。
- en: For more information on MLE, refer to this [article](https://www.analyticsvidhya.com/blog/2018/07/introductory-guide-maximum-likelihood-estimation-case-study-r/).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有关最大似然估计（MLE）的更多信息，请参阅这篇[文章](https://www.analyticsvidhya.com/blog/2018/07/introductory-guide-maximum-likelihood-estimation-case-study-r/)。
- en: Arriving at optimal network weights
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 到达最佳网络权重
- en: The time series or observations are fed to DeepAR as part of the training. At
    each time step, current covariates, previous observations, and previous network
    output are used. The model uses **Back Propagation Through Time** (**BPTT**) to
    compute gradient descent after each iteration. In particular, the Adam optimizer
    is used to conduct BPTT. Through the stochastic gradient descent algorithm, Adam,
    we arrive at optimal network weights via back propagation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列或观测数据作为训练的一部分输入DeepAR。在每个时间步，当前的协变量、先前的观测值以及先前的网络输出都会被使用。该模型使用**时间反向传播**（**BPTT**）在每次迭代后计算梯度下降。特别地，Adam优化器被用来进行BPTT。通过随机梯度下降算法Adam，我们通过反向传播得到了最优的网络权重。
- en: At each time step, *t*, the inputs to the network are covariates, ![](img/f1640cc4-07d1-4a1c-b5e6-2ef157a2a133.png);
    the target at the previous time step, ![](img/f0d0aca4-9ef6-4a61-89f3-941b9a9a899a.png);
    as well as the previous network output, ![](img/598bd999-812c-48d8-b09d-5132c687bf0d.png).
    The network output, ![](img/b09d5fc7-6d40-4b8b-b705-97d4249f181e.png), is then
    used to compute Gaussian parameters that maximize the probability of observing
    the input dataset.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时间步*t*，网络的输入包括协变量，![](img/f1640cc4-07d1-4a1c-b5e6-2ef157a2a133.png)；上一个时间步的目标，![](img/f0d0aca4-9ef6-4a61-89f3-941b9a9a899a.png)；以及上一个网络输出，![](img/598bd999-812c-48d8-b09d-5132c687bf0d.png)。然后，网络输出，![](img/b09d5fc7-6d40-4b8b-b705-97d4249f181e.png)，用于计算高斯参数，以最大化观察输入数据集的概率。
- en: 'The following visual illustrates sequence-to-sequence learning, where the encoder
    encapsulates demand patterns in the historical time series and sends the same
    (![](img/4b65cef4-67fb-4548-a977-78c387d12d11.png)) as input to the decoder. The
    function of the decoder is to predict demand, taking into consideration the input
    from encoder:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下视觉图示说明了序列到序列的学习过程，其中编码器将历史时间序列中的需求模式进行封装，并将相同的数据（![](img/4b65cef4-67fb-4548-a977-78c387d12d11.png)）作为输入传递给解码器。解码器的功能是根据来自编码器的输入来预测需求：
- en: '![](img/0321fea6-ad86-42b5-af68-a1a7bd55d6b9.png)*Source: Probabilistic Forecasting
    with Autoregressive Recurrent Networks (**[link](https://arxiv.org/abs/1704.04110)**)*'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/0321fea6-ad86-42b5-af68-a1a7bd55d6b9.png)*来源：使用自回归递归网络的概率预测（**[link](https://arxiv.org/abs/1704.04110)**）*'
- en: For prediction, the history of the time series, ![](img/5bab8f64-cf7a-49a7-be0f-4b67c2502ad5.png),
    is fed in for ![](img/a1e275cf-a586-4b6b-8e2f-2645f4bc3acb.png), and, then, in
    the prediction range for ![](img/29f766f6-f2a3-4eab-8f83-85d79dd9ca75.png), a
    sample ![](img/f081231c-3bf5-41f7-b212-0265496b27ef.png) is drawn and fed back
    for the next point until the end of the prediction range, ![](img/cda36150-c0e7-4c79-a21d-d309947330f5.png).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 对于预测，将时间序列的历史数据，![](img/5bab8f64-cf7a-49a7-be0f-4b67c2502ad5.png)，输入到预测范围![](img/a1e275cf-a586-4b6b-8e2f-2645f4bc3acb.png)中，之后在预测范围内![](img/29f766f6-f2a3-4eab-8f83-85d79dd9ca75.png)，采样![](img/f081231c-3bf5-41f7-b212-0265496b27ef.png)并反馈至下一点，直到预测范围结束，![](img/cda36150-c0e7-4c79-a21d-d309947330f5.png)。
- en: DeepAR produces accurate forecast distributions learned from historical behavior
    of all of the time series jointly. Also, probabilistic forecasts provide optimal
    decisions under uncertainty versus point estimates.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: DeepAR通过联合学习所有时间序列的历史行为，产生精确的预测分布。此外，概率预测在不确定性下提供最优决策，而非点估计。
- en: Understanding model sales through DeepAR
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过DeepAR理解模型销售
- en: As noted in the introduction to this chapter, managing inventory for retailers
    is a complex activity to handle. Holidays, special events, and markdowns can have
    a significant impact on how a store performs and, in turn, how a department within
    a store performs.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章介绍所述，零售商的库存管理是一项复杂的活动。节假日、特殊事件和降价促销会对商店的表现产生重大影响，进而影响商店内部各个部门的表现。
- en: The Kaggle [dataset](https://www.kaggle.com/manjeetsingh/retaildataset) contains
    historical sales for 45 stores, with each store belonging to a specific type (location
    and performance) and size. The retailer runs several promotional markdowns throughout
    the year. These markdowns precede holidays, such as SuperBowl, Labor Day, Thanksgiving,
    and Christmas.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle [数据集](https://www.kaggle.com/manjeetsingh/retaildataset)包含45家商店的历史销售数据，每个商店属于特定类型（位置和表现）和规模。零售商全年进行几次促销降价。这些降价活动通常发生在节假日之前，如超级碗、劳动节、感恩节和圣诞节。
- en: Brief description of the dataset
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据集简要描述
- en: 'Let''s briefly consider the dataset that we are about to model:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们简要考虑一下我们即将建模的数据集：
- en: '**Features data:**This is data of regional activity related to the store:'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征数据：**这是与商店相关的区域活动数据：'
- en: '**Store**: Numeric store ID for each store.'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**商店**：每个商店的数字化商店ID。'
- en: '**Date**: Important dates for store.'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Date**: 商店的重要日期。'
- en: '**Fuel price**: Current fuel prices.'
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Fuel price**: 当前燃油价格。'
- en: '**Markdowns**: The discount you take on merchandise in your retail store from
    the original marked sale price.'
  id: totrans-90
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Markdowns**: 在零售商店中，你从原始标价中获得的商品折扣。'
- en: '**CPI** (**Consumer Price Index**): A measure that examines the weighted average
    of prices of a basket of consumer goods and services, such as transportation,
    food, and medical care.'
  id: totrans-91
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CPI**（**消费者物价指数**）：衡量一篮子消费品和服务（如交通、食品和医疗）的加权平均价格的指数。'
- en: '**Unemployment**: Current unemployment rate.'
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Unemployment**: 当前失业率。'
- en: '**IsHoliday**: Whether it''s a holiday or not, on a particular date.'
  id: totrans-93
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IsHoliday**: 特定日期是否为假期。'
- en: '**Sales data**: This is historical sales data covering three years, from 2010
    to 2012\. It covers sales for 143 weeks:'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Sales data**: 这是覆盖2010年到2012年三年的历史销售数据，共143周的销售数据：'
- en: '**Store**: Numeric store ID for each store.'
  id: totrans-95
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Store**: 每个商店的数字化商店ID。'
- en: '**Dept**: Numeric department ID for each department of the store.'
  id: totrans-96
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Dept**: 每个部门的数字化部门ID。'
- en: '**Date**: Important dates for the store.'
  id: totrans-97
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Date**: 商店的重要日期。'
- en: '**Weekly sales**: Weekly sales to measure the sales performance of each store.'
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Weekly sales**: 每周销售额，用于衡量每个商店的销售表现。'
- en: '**IsHoliday**: Is it a holiday or not on a particular date.'
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IsHoliday**: 特定日期是否为假期。'
- en: '**Store data:**This is anonymized information about the 45 stores, including
    the type and size of the store:'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Store data**: 这是45个商店的匿名信息，包括商店的类型和规模：'
- en: '**Store**: Numeric store ID for each store.'
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Store**: 每个商店的数字化商店ID。'
- en: '**Type**: The type of store.'
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Type**: 商店的类型。'
- en: '**Size**: The size of the store.'
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Size**: 商店的规模。'
- en: '**Model Input and Output:** Now let''s look at the input and output formats
    including the hyperparameters of the SageMaker DeepAR algorithm.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Model Input and Output**: 现在让我们来看一下输入和输出格式，包括SageMaker DeepAR算法的超参数。'
- en: The algorithm has two input channels and it takes training and test JSONs as
    input through two channels. The training JSON contains only 134 weeks of sales,
    while the test JSON contains sales from all 143 weeks.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 算法有两个输入通道，并通过这两个通道输入训练和测试JSON。训练JSON仅包含134周的销售数据，而测试JSON包含全部143周的销售数据。
- en: 'The following is the structure of the training JSON:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是训练JSON的结构：
- en: '[PRE0]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the preceding structure, we can see the following:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的结构中，我们可以看到以下内容：
- en: '`start`: Is the start date of weekly sales.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`start`: 每周销售的开始日期。'
- en: '`target`: Is for sorted weekly sales.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target`: 用于排序后的每周销售数据。'
- en: '`cat`: Is the category to group time series.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cat`: 用于分组时间序列的类别。'
- en: '`Dynamic_feat`: Includes the dynamic features to account for factors impacting
    sales such as holidays.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Dynamic_feat`: 包括动态特征，用于考虑影响销售的因素，如假期。'
- en: 'The test JSON also has the same format as that of the training JSON. Let''s
    have a look at the following code:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 测试JSON的格式与训练JSON相同。我们来看看以下代码：
- en: '[PRE1]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'DeepAR supports a range of hyperparameters. Following, is a list of some of
    the key hyperparameters. For a detailed list, check out Amazon documentation [here](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_hyperparameters.html):'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: DeepAR支持一系列超参数。以下是一些关键超参数的列表。详细列表请参阅亚马逊文档[这里](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_hyperparameters.html)：
- en: '**Time frequency**: Indicates whether the time series is hourly, weekly, monthly,
    or yearly.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Time frequency**: 表示时间序列是按小时、按周、按月还是按年进行的。'
- en: '**Context length**: How many time steps in the past the algorithm should look
    at for training.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Context length**: 算法在训练时需要查看的过去时间步长数量。'
- en: '**Prediction length**: The number of data points to predict.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prediction length**: 需要预测的数据点数量。'
- en: '**Number of cells**: The number of neurons to use in each of the hidden layers.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Number of cells**: 每个隐藏层中使用的神经元数量。'
- en: '**Number of layers**: The number of hidden layers.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Number of layers**: 隐藏层的数量。'
- en: '**Likelihood function**: We will choose the Gaussian model since weekly sales
    are real values.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Likelihood function**: 由于每周销售额是实际值，我们将选择高斯模型。'
- en: '**epochs**: The maximum number of passes over the training data.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**epochs**: 训练数据的最大遍历次数。'
- en: '**Mini batch size**: The size of the mini-batches used during training.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Mini batch size**: 训练过程中使用的小批量的大小。'
- en: '**Learning rate**: The pace at which the loss is optimized.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Learning rate**: 损失优化的速度。'
- en: '**Dropout rate**: For each epoch, the percentage of hidden neurons that are
    not updated.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Dropout rate**: 每次迭代中未更新的隐藏神经元的百分比。'
- en: '**Early stopping patience**: The training stops after a designated number of
    unsuccessful epochs, those in which the loss doesn''t improve.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提前停止耐心值**：当指定数量的训练周期（那些损失未改进的周期）没有取得改进时，训练将停止。'
- en: '**Inference**:For a given department, we sent 134 weeks of historical sales,
    along with the department category and holiday flag across all of the weeks.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推理**：对于给定的部门，我们发送了134周的历史销售数据，以及该部门类别和假期标志，涵盖了所有的周。'
- en: 'Following, is a sample JSON output from the model endpoint. Because DeepAR
    produces probabilistic forecasts, the output contains several sales samples from
    the Gaussian distribution. Mean and quantiles (50% and 90%) of these samples are
    also reported, as shown in the following:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是来自模型端点的示例JSON输出。由于DeepAR生成概率预测，输出包含来自高斯分布的多个销售样本。这些样本的均值和分位数（50%和90%）也会被报告，如下所示：
- en: '[PRE2]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We have just reviewed sample input and output of the DeepAR algorithm for items
    with historical weekly sales.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚回顾了DeepAR算法对于具有历史每周销售数据的商品的输入和输出示例。
- en: DeepAR also offers unique capabilities that account for complexities in real-world
    time series problems. For new items or products, the length of time series is
    going to be shorter than that of regular items that have full sales history. DeepAR
    captures the distance to the first observation for new items or products. Because
    the algorithm learns item demand across multiple time series, it can estimate
    demand even for newly introduced items—the length of weekly sales across all time
    series need not remain the same. Additionally, the algorithm can also handle missing
    values, with missing values replaced with "Nan".
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: DeepAR还提供了独特的功能，能够处理现实世界时间序列问题中的复杂性。对于新商品或产品，时间序列的长度将短于具有完整销售历史的常规商品。DeepAR能够捕捉新商品或产品首次观察的距离。由于该算法在多个时间序列中学习商品需求，它甚至可以估计新推出商品的需求——所有时间序列中的每周销售长度不需要保持一致。此外，算法还能够处理缺失值，缺失值将被替换为“Nan”。
- en: 'The following screenshot is a visual representation of the variety of inputs
    and output of DeepAR:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是DeepAR输入和输出多样性的可视化表示：
- en: '![](img/5279d84f-a5f5-47a3-b9b3-ce0fa1a0b37c.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5279d84f-a5f5-47a3-b9b3-ce0fa1a0b37c.png)'
- en: As shown in the preceding, the probabilistic forecasts of weekly sales can be
    produced by modeling historical weekly sales (Sales Time Series) across all new
    (Age) and regular items, along with taking into input item category (Item Embedding)
    and other features (Price and Promotion).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所示，通过对所有新商品（年龄）和常规商品进行建模，可以生成每周销售的概率预测（销售时间序列），同时输入商品类别（商品嵌入）和其他特征（价格和促销）。
- en: Exploratory data analysis
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索性数据分析
- en: Although there are 45 stores, we will select one store, store number 20, to
    analyze performance across different departments across three years. The main
    idea here is that, using DeepAR, we can learn the sales of items across different
    departments.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有45家商店，但我们将选择其中一家商店，即商店编号20，来分析三年来不同部门的业绩。这里的主要思想是，使用DeepAR，我们可以学习不同部门商品的销售情况。
- en: In SageMaker, through Lifecycle Configurations, we can custom install Python
    packages before notebook instances are started. This eliminates the need to manually
    track packages required before the notebooks are executed.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在SageMaker中，通过生命周期配置，我们可以在笔记本实例启动之前自定义安装Python包。这避免了在执行笔记本之前手动追踪所需的包。
- en: For exploring the retail sales data, we will need the latest version, 0.9.0,
    of `seaborn` installed.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探索零售销售数据，我们需要安装最新版本0.9.0的`seaborn`。
- en: 'In SageMaker, under Notebook, click on Lifecycle Configurations:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在SageMaker中，点击笔记本下的生命周期配置：
- en: 'Under Start notebook, enter the command to upgrade the `seaborn` Python package,
    as shown:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开始笔记本下，输入命令以升级`seaborn` Python包，如下所示：
- en: '![](img/18891f22-8ceb-4aba-bc86-973064a16de3.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/18891f22-8ceb-4aba-bc86-973064a16de3.png)'
- en: Edit the notebook settings by clicking on the notebook instance, selecting Actions,
    and picking Update Settings.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击笔记本实例，选择操作，然后选择更新设置，编辑笔记本设置。
- en: Under the Update Settings a Lifecycle configuration section, select the name
    of the newly created Lifecycle configuration.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“更新设置”生命周期配置部分下，选择新创建的生命周期配置的名称。
- en: 'This option enables SageMaker to manage all Python pre-requisites before the
    notebook instances are made available, as shown:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 该选项使SageMaker能够在笔记本实例可用之前管理所有Python的前置条件，如下所示：
- en: '![](img/0fe80c03-6ce2-40b4-b56e-073781fb8a1a.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0fe80c03-6ce2-40b4-b56e-073781fb8a1a.png)'
- en: 'Let''s merge the data across the sales, store, and features CSV files:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们合并销售、商店和特征的CSV文件数据：
- en: 'We will import the key Python libraries, as shown in the following:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将导入关键的Python库，如下所示：
- en: '[PRE3]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let''s read the `.csv` files into Python DataFrames, as shown:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们将`.csv`文件读取到Python数据框中，如下所示：
- en: '[PRE4]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let''s look at the shape of each of the DataFrames created, as in the following:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们看一下每个创建的数据框的形状，如下所示：
- en: '[PRE5]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, merge the `features` DataFrame with `sales` and `stores` to create one
    DataFrame containing all of the required information, as shown:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，合并`features`数据框与`sales`和`stores`，创建一个包含所有所需信息的数据框，如下所示：
- en: '[PRE6]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Convert `IsHoliday` into numerical form and convert the `Date` field into the
    `pandas` date format, as in the following:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`IsHoliday`转换为数值型，并将`Date`字段转换为`pandas`日期格式，如下所示：
- en: '[PRE7]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Write merged dataset to `.csv` with the help of the following code:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码将合并后的数据集写入`.csv`文件：
- en: '[PRE8]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, let''s look at the distribution of each of the key factors (`Temperature`,
    `Fuel_Price`, `Unemployment`, and `CPI`) that may impact sales, as shown:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们看看可能影响销售额的每个关键因素（`Temperature`、`Fuel_Price`、`Unemployment`和`CPI`）的分布情况，如下所示：
- en: '[PRE9]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We use the `seaborn` Python library to plot the distribution of `Temperature`,
    `Fuel_Price`, `Unemployment`, and `CPI` in the dataset. Let''s have a look at
    the following output:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`seaborn` Python库绘制数据集中`Temperature`、`Fuel_Price`、`Unemployment`和`CPI`的分布情况。让我们看看以下输出：
- en: '![](img/2e79d837-9b0b-4a1a-a47e-450670f67576.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2e79d837-9b0b-4a1a-a47e-450670f67576.png)'
- en: 'As can be seen from the preceding distributions, the temperature is mostly
    between 60 to 80 degrees when the sales happened. Also, fuel prices were around
    $2.75 and $3.75 during the majority of the sales activity:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的分布可以看出，销售发生时的温度大多在60到80度之间。同时，在大多数销售活动期间，燃油价格大约在$2.75到$3.75之间：
- en: '![](img/50c88a7c-8426-42e7-b808-58eeb3ca6090.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](img/50c88a7c-8426-42e7-b808-58eeb3ca6090.png)'
- en: From the preceding visual, unemployment rate was between 6% and 9% during the
    majority of the sales activity. As for CPI, sales activity occurred during both
    low and high CPI levels.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的可视化中可以看出，在大多数销售活动期间，失业率在6%到9%之间。至于CPI，销售活动发生在低CPI和高CPI水平下。
- en: 'Now that we have looked at the distribution of each of the key features, let''s
    see how they are correlated to weekly sales:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经查看了每个关键特征的分布，接下来让我们看看它们与每周销售额的相关性：
- en: 'First, let''s look at the scatter plot between sales (target) and each of the
    explanatory variables— `Holidays`, `Temperature`, `CPI`, `Unemployment`, and `Store
    Type`:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们看一下销售额（目标）与每个解释变量之间的散点图——`Holidays`、`Temperature`、`CPI`、`Unemployment`和`Store
    Type`：
- en: '[PRE10]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the preceding code, we''ve plotted a scatterplot between sales and fuel
    price and sales and temperature. Let''s analyze how fuel price and temperature
    are related to sales:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们绘制了销售额与燃油价格和销售额与温度之间的散点图。让我们分析一下燃油价格和温度如何与销售额相关：
- en: '![](img/a3a863f8-ee4a-4592-a7e3-70b6a3fe6a58.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a3a863f8-ee4a-4592-a7e3-70b6a3fe6a58.png)'
- en: It is evident from the preceding visual that the fuel price between $3.25 and
    $3.75 is generating higher weekly sales. Also, a temperature between 50 and 65
    degrees is generating higher weekly sales.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从前面的可视化中可以明显看出，燃油价格在$3.25到$3.75之间时，每周销售额较高。而温度在50到65度之间时，每周销售额较高。
- en: 'Let''s now plot holiday or not and CPI against sales, as shown in the following
    code:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将假期与否和CPI与销售额进行绘图，如以下代码所示：
- en: '[PRE11]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s look at how sales vary with a holiday or not and CPI in the following
    screenshot:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下假期与否以及CPI如何影响销售额，如下截图所示：
- en: '![](img/cba77cff-6337-4dbd-a0ac-5e2fff453593.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cba77cff-6337-4dbd-a0ac-5e2fff453593.png)'
- en: It seems that holiday sales are higher than non-holiday sales. Also, there appears
    to be no material impact of CPI on weekly sales.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 看起来假期销售额高于非假期销售额。同时，CPI对每周销售额似乎没有明显的影响。
- en: 'Let''s now plot `Unemployment` and `Store Type` against sales, as shown in
    the following code:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们将`Unemployment`和`Store Type`与销售额进行绘图，如以下代码所示：
- en: '[PRE12]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let''s see how sales vary with unemployment and store type in the following
    screenshot:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看销售额如何随着失业率和商店类型的变化而变化，如下截图所示：
- en: '![](img/3f4b38ce-74b3-403d-b16a-108a48bf2fb4.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f4b38ce-74b3-403d-b16a-108a48bf2fb4.png)'
- en: From the preceding visual, weekly sales appear to be higher when unemployment
    rate is lower (7 to 8.5) and B type stores seem to have higher weekly sales.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的可视化中可以看出，当失业率较低（7到8.5之间）时，每周销售额较高，而B类型商店的每周销售额似乎较高。
- en: Second, let's look at a heatmap across all of the features to identify what
    features impact sales. Let's draw a heatmap to see correlations between sales
    and several sales predictors all in one go.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 其次，让我们查看所有特征的热图，找出哪些特征会影响销售额。我们将绘制一个热图，查看销售额与多个销售预测因子之间的相关性。
- en: 'The following screenshot is a heatmap of numerical attributes in the dataset—we
    drop store and department from the dataset since they are categorical variables:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是数据集中数值属性的热图——我们从数据集中删除了商店和部门字段，因为它们是分类变量：
- en: '![](img/f3d3ab63-2650-4b62-a1fb-12341db2f89b.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3d3ab63-2650-4b62-a1fb-12341db2f89b.png)'
- en: 'From the scatter plot and heat map, the following is apparent:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 从散点图和热图中，可以明显看出以下几点：
- en: Markdowns are happening during holidays.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Markdown格式的文本会出现在节假日期间。
- en: Sales are higher during holidays.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节假日期间销售额较高。
- en: Type B stores generate higher sales.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B类商店产生更高的销售额。
- en: Lower fuel prices (between $3 and $3.75) generate higher sales.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更低的燃油价格（在$3到$3.75之间）会带来更高的销售额。
- en: The ideal temperature (between 50 and 65 degrees) generates higher sales.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理想的温度（在50到65度之间）会带来更高的销售额。
- en: For our further modeling, we will pick the best performing store, store 20,
    to model sales across different departments and years. For each of the time steps
    in the time series, we will also pass whether a particular day was observed as
    a holiday or not.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进一步建模的过程中，我们将选择表现最好的商店——商店20，来建模不同部门和不同年份的销售情况。对于时间序列中的每个时间步，我们还将传递该日期是否为假期的标识。
- en: Data pre-processing
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: 'Let''s begin with preparing the dataset for modeling:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从准备建模所需的数据集开始：
- en: Create a module named `retailsales.py` to create JSON files that DeepAR can
    consume for training and validation.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个名为 `retailsales.py` 的模块，用于创建DeepAR可以用于训练和验证的JSON文件。
- en: Create a module named `salesinference.py` to build inference data and retrieve
    and plot predictions.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个名为 `salesinference.py` 的模块，用于构建推理数据并获取和绘制预测结果。
- en: For details on the modules, please refer to the source code associated with
    this chapter.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 有关模块的详细信息，请参阅本章相关的源代码。
- en: To modularize the code to test DeepAR, we will package the two modules, `retailsales`
    and `salesinference`. To package the modules, we will create the `__init__.py`
    file to import the modules. We will then create `setup.py`, detailing the pre-requisite
    packages to be installed.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将代码模块化以测试DeepAR，我们将把 `retailsales` 和 `salesinference` 两个模块打包。为了打包这些模块，我们将创建
    `__init__.py` 文件来导入这些模块，然后创建 `setup.py` 文件，详细说明需要安装的先决条件包。
- en: 'Following, is the folder structure of the DeepAR project:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是DeepAR项目的文件夹结构：
- en: '[PRE13]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s take a look at the following steps:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看接下来的步骤：
- en: 'In `setup.py`, we will define pre-requisite packages to be installed:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `setup.py` 文件中，我们将定义需要安装的先决条件包：
- en: '[PRE14]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'In `_init_.py`, we will import the modules, `retailsales` and `salesinference`,
    defined earlier:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `_init_.py` 文件中，我们将导入之前定义的 `retailsales` 和 `salesinference` 模块：
- en: '[PRE15]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We will now install the package for the modules to be available while training
    DeepAR:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在将安装这个包，以便在训练DeepAR时使用这些模块：
- en: '[PRE16]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We are now ready with all of the packages required to pre-process weekly sales
    data. Pre-processing included not only converting categorical data into numerical,
    but also creating training and testing data in JSON formats required by the DeepAR
    algorithm.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好了所有需要的包来预处理每周的销售数据。预处理不仅包括将分类数据转换为数值数据，还包括按照DeepAR算法要求的JSON格式创建训练和测试数据。
- en: Training DeepAR
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练DeepAR模型
- en: In this section, we will fit DeepAR to the weekly sales. Let's start by preparingtraining
    and test datasets in JSON format*.*
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将为每周销售数据拟合DeepAR模型。让我们从准备训练和测试数据集（JSON格式）开始。
- en: 'Let''s have a look at the following code, which demonstrates the creation of
    `json` lines:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下以下代码，展示了如何创建 `json` 行：
- en: '[PRE17]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'In the preceding code block, we have created JSON lines for training and testing
    the datasets:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码块中，我们已经创建了用于训练和测试的数据集的JSON行：
- en: The `prepareSalesData()` function is used to select departments with sales across
    all of the 143 weeks. This step is to ensure that there were no missing values
    in the data. Although DeepAR can handle missing values, we've tried to make the
    problem less complex by only considering departments that have sales in almost
    all weeks.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prepareSalesData()` 函数用于选择在所有143周内都有销售的部门。此步骤确保数据中没有缺失值。虽然DeepAR能够处理缺失值，但我们尽量简化问题，只考虑几乎每周都有销售的部门。'
- en: We use department numbers to group or categorize the time series for the DeepAR
    algorithm. This grouping will be used by DeepAR to make demand predictions by
    department.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用部门编号来分组或分类时间序列，以供 DeepAR 算法使用。此分组将由 DeepAR 用来按部门进行需求预测。
- en: The `getTestSales()` function is used to create JSON lines for the testing dataset.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getTestSales()` 函数用于为测试数据集创建 JSON 行。'
- en: The `getTrainSales()` function, on the other hand, is used to create JSON lines
    for the training dataset, which is a subset of the testing dataset. For each of
    the departments, we will chop the last nine weekly sales determined by prediction
    length.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getTrainSales()` 函数则用于为训练数据集创建 JSON 行，该数据集是测试数据集的一个子集。对于每个部门，我们将截取由预测长度决定的最后九周的销售数据。'
- en: 'Now, we will look at uploading the `json` files to the S3 bucket, as shown
    in the following code:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将查看将 `json` 文件上传到 S3 存储桶的代码，如下所示：
- en: '[PRE18]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In the preceding code, the newly created `json` files are uploaded to the designated
    S3 bucket via the `upload_data()` function from the Sagemaker session object (Sagemaker
    Python SDK).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，通过 Sagemaker 会话对象（Sagemaker Python SDK）中的 `upload_data()` 函数将新创建的 `json`
    文件上传到指定的 S3 存储桶。
- en: 'We will be obtaining the URI of the DeepAR Docker image with the help of the
    following code:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过以下代码获得 DeepAR Docker 镜像的 URI：
- en: '[PRE19]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the preceding code block, we can see the following:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码块中，我们可以看到以下内容：
- en: The `get_image_uri()` function from the SageMaker estimator object is used to
    obtain `uri` of the DeepAR Docker image.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`get_image_uri()` 函数来自 SageMaker 估算器对象，用于获取 DeepAR Docker 镜像的 `uri`。'
- en: Once `uri` is obtained, the DeepAR estimator is created.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦获得 `uri`，便会创建 DeepAR 估算器。
- en: The constructor parameters include the Docker image `uri`, execution role, training
    instance type and count, and `outpath` path to save the trained algorithm and
    SageMaker session.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构造函数参数包括 Docker 镜像 `uri`、执行角色、训练实例类型和数量，以及 `outpath` 保存训练后的算法和 SageMaker 会话的路径。
- en: 'Hyperparameters are used to configure the learning or training process. Let''s
    have a look at `hyperparameters` used in the following code:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数用于配置学习或训练过程。让我们来看一下以下代码中使用的 `hyperparameters`：
- en: '[PRE20]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In the preceding code, we came across the following hyperparameters:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们遇到了以下超参数：
- en: '`learning_rate`: Defines how fast the weights are updated during training.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learning_rate`：定义训练过程中权重更新的速度。'
- en: '`dropout_rate`: To avoid overfitting, for each iteration, a random subset of
    hidden neurons are not updated.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropout_rate`：为了避免过拟合，在每次迭代中，会随机选择一部分隐藏神经元不进行更新。'
- en: '`num_cells`: Defines the number of cells to use in each of the hidden layers.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_cells`：定义每个隐藏层中使用的单元格数量。'
- en: '`num_layers`: Defines the number of hidden layers in the RNN.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_layers`：定义 RNN 中的隐藏层数。'
- en: '`time_freq`: Defines the frequency of time series.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time_freq`：定义时间序列的频率。'
- en: '`epochs`: Defines the maximum number of passes over the training data.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epochs`：定义训练数据的最大遍历次数。'
- en: '`context_length`: Defines look back period—how many data points are we going
    to look at before predicting.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`context_length`：定义回溯期——我们在预测之前会查看多少个数据点。'
- en: '`prediction_length`: Defines the number of data points to predict.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction_length`：定义要预测的数据点数量。'
- en: '`mini_batch_size`: Defines how often weights are updated—that is, weights are
    updated after processing the designated number of data points.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mini_batch_size`：定义权重更新的频率——即在处理指定数量的数据点后更新权重。'
- en: 'In the following code, we fit `deepAR` to the training dataset:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们将 `deepAR` 拟合到训练数据集：
- en: '[PRE21]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In the preceding code, we can see the following:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们可以看到以下内容：
- en: We passed the location of the training and testing JSONs on the S3 bucket.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将训练和测试 JSON 文件的路径传递到 S3 存储桶中。
- en: The testing dataset is used to evaluate the performance of the model.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试数据集用于评估模型的性能。
- en: For training, we called the `fit()` function on the DeepAR estimator.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于训练，我们在 DeepAR 估算器上调用了 `fit()` 函数。
- en: 'Following is the output from training DeepAR:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是训练 DeepAR 的输出：
- en: '[PRE22]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As it is seen in the preceding output, the **Root Mean Squared Error** (**RMSE**
    ) is used as a metric to pick the best performing model.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的输出所示，**均方根误差** (**RMSE**) 被用作评估最佳表现模型的指标。
- en: We have successfully trained the DeepAR model on our training dataset, which
    had 134 weekly sales. To fit training data to the model, we have defined the location
    of training and testing JSONs on the S3 bucket. Also, we've defined hyperparameters
    to control the learning or fitting process. The best performing model (based on
    the lowest RMSE—in that predicted sales are close as possible to actual sales)
    is then persisted.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功地在我们的训练数据集上训练了 DeepAR 模型，该数据集包含134周的每周销售数据。为了将训练数据拟合到模型，我们已经定义了 S3 存储桶中训练和测试
    JSON 文件的位置。此外，我们还定义了超参数来控制学习或拟合过程。然后，将表现最好的模型（基于最低 RMSE——即预测销售额尽可能接近实际销售额）进行保存。
- en: Predicting and evaluating sales
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 销售预测与评估
- en: In this section, the trained model will be deployed, so that we can predict
    weekly sales for the next nine weeks for a given department.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，训练好的模型将被部署，以便我们可以预测给定部门未来九周的每周销售额。
- en: 'Let''s have a look at the following code :'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下下面的代码：
- en: '[PRE23]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'In the preceding code, the `deploy` function of the `deepAR` estimator is used
    to host the model as an endpoint. The number and type of hosting instances should
    be specified through the following parameters :'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，`deepAR` 估算器的 `deploy` 函数用于将模型托管为一个端点。托管实例的数量和类型应通过以下参数指定：
- en: '`initial_instance_count`'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initial_instance_count`'
- en: '`instance_type`'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instance_type`'
- en: 'To assess the model performance, we use department number 90, as shown in the
    following code:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估模型性能，我们使用了部门编号90，如下面的代码所示：
- en: '[PRE24]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In the preceding code, we can see the following:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们可以看到以下内容：
- en: The `buildInferencedata()` function is used to prepare the time series data
    in JSON format. We build inference data, by a given department, listing holidays
    across the entire 143 weeks, weekly sales for 134 weeks, and corresponding item
    category. The goal here is to estimate sales in the last nine weeks, where `9`
    is the prediction length.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`buildInferencedata()` 函数用于准备 JSON 格式的时间序列数据。我们通过给定部门，列出整个143周的假期、134周的每周销售数据以及对应的商品类别，来构建推断数据。这里的目标是估计最后九周的销售额，其中
    `9` 是预测的长度。'
- en: 'Following is a JSON sample produced by the `buildInferenceData` function:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 `buildInferenceData` 函数生成的 JSON 示例：
- en: '![](img/dd96649e-fd17-4eb9-8edb-d8b3385901f1.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dd96649e-fd17-4eb9-8edb-d8b3385901f1.png)'
- en: The SageMaker predictor object is used for inference.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SageMaker 预测器对象用于推断。
- en: The `getInferenceSeries()` function is used to parse the JSON results from the
    DeepAR algorithm to identify mean sales, sales in the 10 percentile, and sales
    in the 90 percentile. Note that, using Gaussian distribution, DeepAR generates
    100 samples of weekly sales for the next nine weeks. Therefore, sales in 10 percentile
    and 90 percentile indicate the lower and upper bounds of weekly sales during the
    prediction period.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`getInferenceSeries()` 函数用于解析来自 DeepAR 算法的 JSON 结果，识别平均销售额、10百分位销售额和90百分位销售额。请注意，使用高斯分布，DeepAR
    生成了未来九周的每周销售的100个样本。因此，10百分位和90百分位的销售额表示预测期内每周销售的下限和上限。'
- en: The results returned from the endpoint are then plotted against actual sales
    via the `plotResults()` function. For each of the nine weeks, we will look at
    mean sales, ground truth sales, sample sales, 10 percentile sales, and 90 percentile
    sales.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从端点返回的结果将通过 `plotResults()` 函数与实际销售进行对比并绘制。对于九周中的每一周，我们将查看平均销售额、实际销售额、样本销售额、10百分位销售额和90百分位销售额。
- en: 'As shown in the following, the mean estimated sales are close to the actual
    sales, indicating that the DeepAR algorithm has adequately picked up sales demand
    across different departments. Change the department number to evaluate model performance
    across all departments. The probabilistic sales estimates hence enable us to estimate
    demand more accurately than point estimates. Here is the output of the preceding
    code:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示，平均估计销售额接近实际销售额，这表明 DeepAR 算法已经充分捕捉到了不同部门的销售需求。更改部门编号，以评估所有部门的模型性能。因此，概率性销售估计使我们能够比点估计更准确地估算需求。以下是前面代码的输出：
- en: '[PRE25]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In the following graph, we can see the following:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们可以看到以下内容：
- en: The blue line indicates mean sales from the prediction of nine weeks in the
    future.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝线表示未来九周预测的平均销售额。
- en: The purple line, on the other hand, reflects ground truth.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 紫线则反映了实际销售情况。
- en: 'The two lines are close enough, indicating that the model has done a decent
    job capturing patterns in sales, given holidays and historical weekly sales:'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这两条线足够接近，表明模型在捕捉销售模式（考虑了假期和历史每周销售）方面做得相当不错：
- en: '![](img/22eef7f3-f8c1-45b0-b12e-e1bbbe498629.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![](img/22eef7f3-f8c1-45b0-b12e-e1bbbe498629.png)'
- en: 'We have only looked at store 20 sales. However, you can train on all store
    sales by including the store number in the category list—for each time series
    in the train and test sets, include the following code:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只看了20个门店的销售数据。然而，你可以通过在类别列表中加入门店编号来训练所有门店的销售数据——对于训练集和测试集中的每个时间序列，包含以下代码：
- en: '[PRE26]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: With a large number of time series across different products and stores, we
    would have been able to achieve better performance.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 通过覆盖不同产品和门店的大量时间序列，我们本可以实现更好的性能。
- en: Summary
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we briefly looked at univariate time series forecasting techniques,
    such as ARIMA and exponential smoothing. However, as demand varies by multiple
    variables, it becomes important to model multi-variate series. DeepAR enables
    modeling of multi-variate series, along with providing probabilistic forecasting.
    While point estimates may work in some situations, probabilistic estimates provide
    better data for improved decision making. The algorithm works by generating a
    global model that is trained across a large number of time series. Each item or
    product across several stores and departments will have its own weekly sales.
    The trained model accounts for newly introduced items, missing sales per item,
    and multiple predictors that explain sales. With the LSTM network and Gaussian
    likelihood, DeepAR in SageMaker provides a flexible approach to demand forecasting.
    Additionally, we walked through model training, selection, hosting, and inference
    in SageMaker through the SageMaker Python SDK.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们简要介绍了单变量时间序列预测技术，如ARIMA和指数平滑。然而，由于需求受多个变量影响，建模多变量序列变得至关重要。DeepAR使得建模多变量序列成为可能，并提供了概率预测。虽然在某些情况下点估计可以起作用，但概率估计能够提供更好的数据，帮助做出更优决策。该算法通过生成一个全局模型，跨多个时间序列进行训练。每个项目或产品在多个门店和部门中都会有自己的每周销售数据。训练后的模型会考虑新推出的项目、每个项目的缺失销售数据以及多个能够解释销售的预测变量。借助LSTM网络和高斯似然函数，SageMaker中的DeepAR提供了灵活的需求预测方法。此外，我们还通过SageMaker
    Python SDK，介绍了模型的训练、选择、托管和推断过程。
- en: Now, that we've experienced SageMaker's capabilities to solve demand forecasting
    at scale, in the next chapter, we will walk through model monitoring and governance
    and will learn about why models degrade in production.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，既然我们已经体验了SageMaker在大规模需求预测中的能力，在下一章中，我们将介绍模型监控与治理，并了解为何模型在生产中会退化。
- en: Further reading
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Overview of a variety of univariate time series forecasting methods:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 各种单变量时间序列预测方法概览：
- en: '[https://machinelearningmastery.com/exponential-smoothing-for-time-series-forecasting-in-Python/](https://machinelearningmastery.com/exponential-smoothing-for-time-series-forecasting-in-python/)'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://machinelearningmastery.com/exponential-smoothing-for-time-series-forecasting-in-Python/](https://machinelearningmastery.com/exponential-smoothing-for-time-series-forecasting-in-python/)'
- en: '[https://towardsdatascience.com/unboxing-arima-models-1dc09d2746f8](https://towardsdatascience.com/unboxing-arima-models-1dc09d2746f8)'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://towardsdatascience.com/unboxing-arima-models-1dc09d2746f8](https://towardsdatascience.com/unboxing-arima-models-1dc09d2746f8)'
- en: 'Details on how the DeepAR algorithm works:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: DeepAR算法如何工作的详细信息：
- en: '[https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_how-it-works.html](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_how-it-works.html)'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_how-it-works.html](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar_how-it-works.html)'
- en: 'Details on DeepAR inference formats:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: DeepAR推断格式的详细信息：
- en: '[https://docs.aws.amazon.com/sagemaker/latest/dg/deepar-in-formats.html](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar-in-formats.html)'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://docs.aws.amazon.com/sagemaker/latest/dg/deepar-in-formats.html](https://docs.aws.amazon.com/sagemaker/latest/dg/deepar-in-formats.html)'
