- en: Introduction to the Markov Process
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 马尔可夫过程简介
- en: 'In this chapter, we will develop the basic concepts that we need to understand
    **Hidden Markov Models** (**HMM**). We will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将展开理解**隐马尔可夫模型**（**HMM**）所需的基本概念。我们将涵盖以下主题：
- en: Random processes
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机过程
- en: Markov processes
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马尔可夫过程
- en: Markov chains or discrete-time Markov processes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马尔可夫链或离散时间马尔可夫过程
- en: Continuous-time Markov chains
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续时间马尔可夫链
- en: Random variables
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机变量
- en: As we always do in statistics, let's start with a simple example of rolling
    a dice. If we consider rolling a fair dice, the outcome of the dice can be anything
    from 1 to 6, and is random. To represent such situations (the outcome of rolling
    the dice in this case), in mathematics we use the concept of random variables.
    We come across a lot of such variables in our everyday lives. Another example
    could be ordering food at a restaurant. In this case, the outcome could be any
    food item on the menu. In general terms, a random variable is a variable whose
    possible values are outcomes of a random phenomenon. The possible states of the
    outcomes are also known as the **domain of the random variable**, and the outcome
    is based on the probability distribution defined over the domain of the random
    variable.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在统计学中常做的那样，让我们从一个简单的掷骰子例子开始。如果我们考虑掷一个公平的骰子，骰子的结果可以是从1到6的任何一个数，且是随机的。为了表示这种情况（本例中是掷骰子的结果），在数学中我们使用随机变量的概念。在我们的日常生活中，我们会遇到很多这样的变量。另一个例子是点餐。在这种情况下，结果可以是菜单上的任何一道菜。一般来说，随机变量是一个其可能的值是随机现象结果的变量。结果的可能状态也被称为**随机变量的定义域**，而结果则是基于在随机变量定义域上定义的概率分布。
- en: Coming back to rolling the dice, the domain of the random variable outcome*,
    O, *is given by *domain(O) = (1, 2, 3, 4, 5, 6),* and the probability distribution
    is given by a uniform distribution *P(o) = 1/6 ∀ ∈ domain(O)*. Similarly, in the
    case of the restaurant example, for the random variable *choosing a dish*, the
    domain would be every item on the menu, and the probability distribution would
    depend on your food preference. In both of the previous examples, the domain of
    the random variable has discrete variables; such random variables are known as
    **discrete random variables**. But it's also possible for the domain to be a continuous
    space. For example, consider the random variable representing the stock price
    of Googletomorrow. The domain of this random variable will be all positive real
    numbers with most of the probability mass distributed around ±5% of today's price.
    Such random variables are known as **continuous random variables**.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 回到掷骰子的例子，随机变量的结果*O*的定义域是*domain(O) = (1, 2, 3, 4, 5, 6)*，其概率分布为均匀分布，*P(o) =
    1/6 ∀ o ∈ domain(O)*。类似地，在餐厅的例子中，随机变量*选择菜肴*的定义域将是菜单上的每一项菜品，而概率分布则取决于你的食物偏好。在之前的两个例子中，随机变量的定义域是离散的；这种随机变量称为**离散随机变量**。但也有可能定义域是一个连续的空间。例如，考虑表示明天Google股票价格的随机变量。该随机变量的定义域将是所有正实数，并且大部分概率质量分布在今天价格的±5%范围内。这种随机变量称为**连续随机变量**。
- en: Random processes
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 随机过程
- en: In the previous section, we discussed random variables that are able to mathematically
    represent the outcomes of a single random phenomenon. But what if we want to represent
    these random events over some period of time or the length of an experiment? For
    example, let's say we want to represent the stock prices for a whole day at intervals
    of every one hour, or we want to represent the height of a ball at intervals of every
    one second after being dropped from some height in a vacuum. For such situations,
    we would need a set of random variables, each of which will represent the outcome
    at the given instance of time. These sets of random variables that represent random
    variables over a period of time are also known as **random processes**.It is worth
    noting that the domains of all these random variables are the same. Therefore,
    we can also think of the process as just changing the states.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们讨论了能够在数学上表示单一随机现象结果的随机变量。但如果我们想要表示这些随机事件在一段时间内或者实验持续过程中发生的情况，该怎么办呢？例如，假设我们想要表示一天内每小时的股价，或者想要表示一个从某高度在真空中自由下落的球在每秒钟的高度。对于这种情况，我们需要一组随机变量，每个随机变量表示在给定时间点的结果。这些表示随机现象在一段时间内的随机变量集合也被称为**随机过程**。值得注意的是，所有这些随机变量的定义域是相同的。因此，我们也可以把这个过程看作是状态的变化。
- en: Here, we have been talking about random variables at different instances of
    time, but it doesn't need to be time-based in every case. It could be just some
    other event. But since, in most cases, it is usually time, and it is much easier
    to talk about random processes in terms of time, we will use time to represent
    any such event. The same concepts will apply to creating a model if it varies
    over some other event instead of time.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们讨论的是不同时间点的随机变量，但并不一定每次都以时间为基础。它也可以是其他某种事件。但由于在大多数情况下，通常是时间，因此讨论随机过程时更容易使用时间来表示任何此类事件。如果它随着其他事件变化而非时间变化，创建模型时相同的概念也会适用。
- en: Now let's discuss the previous two examples in more detail. Starting with the
    example of dropping the ball from a height in a vacuum, if we know the exact value
    of gravity and the height from which the ball is being dropped, we will be able
    to determine the exact location of the ball at every interval of one second using
    Newton's laws of motion.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们更详细地讨论之前的两个例子。首先是从真空中将球从一定高度掉落的例子，如果我们知道重力的准确数值和球体掉落的高度，那么我们可以通过牛顿运动定律，在每秒的时间间隔内精确地确定球的位置。
- en: Such random processes, in which we can deterministically find the state of each
    random variable given the initial conditions (in this case, dropping the ball,
    zero initial velocity) and the parameters of the system (in this case, the value
    of gravity), are known as **deterministic random processes** (commonly called **deterministic
    processes**).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这类随机过程中，我们可以通过初始条件（在此案例中是掉落球，初速度为零）和系统参数（在此案例中是重力的数值），确定每个随机变量的状态，这类过程被称为**确定性随机过程**（通常称为**确定性过程**）。
- en: Now let's go to the second example; representing the stock price over time.
    In this case, even if we know the current price and the exact probability distribution
    of the price at the next one hour mark, we won't be able to deterministically
    compute the value. These random processes, in which we can't determine the state
    of a process, even if we are given the initial conditions and all the parameters
    of the system, are known as **stochastic random processes** (commonly called **processes**).
    A very good way of understanding or getting a feel for a stochastic process is
    to think of it as being the opposite of a deterministic process.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看第二个例子：表示股票价格随时间的变化。在这种情况下，即使我们知道当前价格以及下一小时的价格的精确概率分布，我们也无法确定性地计算出价格。这些随机过程，即使在给定初始条件和所有系统参数的情况下，我们仍然无法确定过程的状态，被称为**随机随机过程**（通常称为**过程**）。理解或感受随机过程的一种非常好的方式是将其视为与确定性过程的对立面。
- en: Markov processes
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 马尔可夫过程
- en: 'A stochastic process is called a **Markov process **if the state of the random
    variable at the next instance of time depends only on the outcome of the random
    variable at the current time. In simplistic mathematical terms, for a stochastic
    process, *S = {R1, R[2], . . ., R[n]} = {R}[t=1, . . ., n]*, to be a Markov process,
    it must satisfy the following condition:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果随机变量在下一时刻的状态仅依赖于当前时刻随机变量的结果，则该随机过程被称为**马尔可夫过程**。用简单的数学术语表示，对于一个随机过程，*S = {R1,
    R[2], . . ., R[n]} = {R}[t=1, . . ., n]*，要成为一个马尔可夫过程，它必须满足以下条件：
- en: '![](img/57bcdc2f-a875-446c-82c5-fa07de0db4d9.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/57bcdc2f-a875-446c-82c5-fa07de0db4d9.png)'
- en: According to the previous condition, the probability distribution for any variable
    at any given instance in a Markov process is a conditional distribution, which
    is conditioned only on the random variable at the last time instance. This property
    of a system, such that the future states of the system depend only on the current
    state of the system, is also known as the **Markov property**. Systems satisfying
    the Markov property are also known as **memoryless systems** since they don't
    need to remember the previous states to compute the distribution of the next state,
    or, in other words, the next state depends only on the current state of the system.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的条件，马尔可夫过程中的任何变量在给定时刻的概率分布是一个条件分布，只依赖于上一时刻的随机变量。系统的这一特性，即系统的未来状态仅依赖于当前状态，也被称为**马尔可夫性质**。满足马尔可夫性质的系统也被称为**无记忆系统**，因为它们不需要记住之前的状态来计算下一个状态的分布，换句话说，下一个状态仅依赖于系统的当前状态。
- en: A very common example used to explain the Markov process is a drunk man walking
    along a street. We consider that, since the man is drunk, he can either take a
    step backward, a step forward, or stay in his current position, which is given
    by some distribution of these, let's say *[0.4, 0.4, 0.2]*. Now, given the position
    of the man at any given instance in time, his position at the next instance depends
    only on his current position and the parameters of the system (his step size and
    the probability distribution of possible actions). Therefore, this is an example
    of a Markov process.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常用的例子来解释马尔可夫过程是一个醉汉在街上走路。我们假设，由于这个人醉了，他可以选择向后走一步、向前走一步，或者停留在当前位置，这些动作的概率分布是
    *[0.4, 0.4, 0.2]*。现在，假设我们知道这个人在某一时刻的位置，那么他在下一个时刻的位置仅仅取决于他当前的位置以及系统的参数（他的步长和可能动作的概率分布）。因此，这是一个马尔可夫过程的例子。
- en: 'In the previous example, let''s assume that the drunk man takes an action (steps
    forward/backward or stays in his position) at fixed intervals of time and his
    step size is always the same. With these considerations, the Markov process in
    our example has a discrete state space. Also, since the man takes steps after
    fixed intervals of time, we can think of it as a discrete time. But Markov processes
    don''t need to have discrete state space or discrete time intervals. Considering
    discrete and continuous time as well as discrete and continuous state space, we
    can categorize Markov processes into four main categories:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们假设醉汉在固定的时间间隔内采取行动（向前/向后走或者停留在原地），并且他的步长始终相同。考虑到这些因素，我们的例子中的马尔可夫过程具有离散的状态空间。此外，由于这个人是在固定的时间间隔后迈出步伐，我们可以把它看作是一个离散时间的过程。但马尔可夫过程不一定需要离散状态空间或离散时间间隔。考虑到离散与连续时间以及离散与连续状态空间，我们可以将马尔可夫过程分为四大类：
- en: Discrete time and discrete state space
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 离散时间与离散状态空间
- en: Discrete time and continuous state space
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 离散时间与连续状态空间
- en: Continuous time and discrete state space
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续时间与离散状态空间
- en: Continuous time and continuous state space
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续时间与连续状态空间
- en: We will discuss each of these categories of Markov process in more detail in
    the following sections.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中更详细地讨论这些马尔可夫过程的类别。
- en: Installing Python and packages
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 Python 和包
- en: Before moving ahead, we need to set up Python and all the packages required
    to run the code examples. For all the code examples in this book, we will be using
    Python 3.4\. All the example code in the book is also available on GitHub at [https://github.com/PacktPublishing/HandsOnMarkovModelswithPython](https://github.com/PacktPublishing/HandsOnMarkovModelswithPython).
    We highly recommend using Miniconda to set up your environment for running the
    examples. Miniconda can be downloaded from [https://conda.io/miniconda.html](https://conda.io/miniconda.html).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，我们需要设置 Python 和所有运行代码示例所需的包。在本书中的所有代码示例都将使用 Python 3.4。书中的所有示例代码也可以在 GitHub
    上找到：[https://github.com/PacktPublishing/HandsOnMarkovModelswithPython](https://github.com/PacktPublishing/HandsOnMarkovModelswithPython)。我们强烈建议使用
    Miniconda 来设置运行示例所需的环境。Miniconda 可以从 [https://conda.io/miniconda.html](https://conda.io/miniconda.html)
    下载。
- en: Installation on Windows
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Windows 上的安装
- en: 'Miniconda can be installed on a Windows system by just double-clicking on the
    downloaded `.exe` file and following the installation instructions. After installation,
    we will need to create a `conda` environment and install all the required packages
    in the environment. To create a new Python 3.4 environment with the name `hmm`,
    run the following command:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Miniconda 可以通过双击下载的 `.exe` 文件并按照安装说明进行安装来在 Windows 系统上安装。安装完成后，我们需要创建一个 `conda`
    环境，并在环境中安装所有所需的包。要创建一个名为 `hmm` 的 Python 3.4 环境，请运行以下命令：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After creating the environment, we will need to activate it and install the
    required packages in it. This can be done using the following commands:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建环境之后，我们需要激活它并安装所需的包。这可以通过以下命令完成：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Installation on Linux
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Linux 上的安装
- en: 'On Linux, after downloading the `Miniconda` file, we will need to give it execution
    permissions and then install it. This can be done using the following commands:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Linux 上，下载 `Miniconda` 文件后，我们需要赋予它执行权限，然后进行安装。这可以通过以下命令完成：
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'After executing the file, we can simply follow the installation instructions.
    Once installed, we will need to create a new environment and install the required
    packages. We can create a new Python 3.4 environment with the name `hmm` using
    the following commands:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 执行文件后，我们可以简单地按照安装说明进行操作。一旦安装完成，我们需要创建一个新的环境并安装所需的软件包。我们可以使用以下命令创建一个名为 `hmm`
    的 Python 3.4 环境：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Once the environment has been created, we will need to activate it and install
    the packages inside it using the following:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 环境创建完成后，我们需要激活该环境，并使用以下命令在其中安装软件包：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Markov chains or discrete-time Markov processes
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 马尔可夫链或离散时间马尔可夫过程
- en: 'A Markov chain is a type of Markov process in which the time is discrete. However,
    there is a lot of disagreement among researchers on what categories of Markov
    process should be called **Markov chain**. But, most commonly, it is used to refer
    to discrete-state-space Markov processes. Therefore, a Markov chain is a stochastic
    process over a discrete state space satisfying the Markov property. More formally,
    we can say that a discrete-time Markov chain is a sequence of random variables
    *X[1]*, *X[2]*, *X[3]*, ... that satisfy the Markov property, namely that the
    probability of moving from the current state to the next state depends only on
    the present state and not on any of the previous states. In terms of the probability
    distribution, we can say that, given that the system is at time instance *n*,
    the conditional distribution of the states at the next time instance, *n + 1*,
    is conditionally independent of the state of the system at time instances *{1,
    2, . . ., n-1}*, given the state of the random variable at time instance *n*.
    This can be written as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫链是一种马尔可夫过程，其中时间是离散的。然而，研究人员对于哪些类别的马尔可夫过程应该被称为**马尔可夫链**存在较大分歧。但通常来说，它是用来指代离散状态空间的马尔可夫过程。因此，马尔可夫链是一个定义在离散状态空间上的随机过程，满足马尔可夫性质。更正式地说，我们可以说，离散时间马尔可夫链是一个随机变量序列
    *X[1]*、*X[2]*、*X[3]*、...，这些随机变量满足马尔可夫性质，即从当前状态转移到下一个状态的概率仅依赖于当前状态，而不依赖于之前的任何状态。就概率分布而言，我们可以说，假设系统在时间点
    *n* 时处于某状态，那么在下一个时间点 *n + 1* 的条件分布是条件独立于时间点 *{1, 2, ..., n-1}* 的系统状态，前提是知道时间点
    *n* 的随机变量状态。这可以写成如下形式：
- en: '![](img/834a5c22-1466-4e66-bf09-24972d32a079.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/834a5c22-1466-4e66-bf09-24972d32a079.png)'
- en: 'Markov chains are often represented using directed graphs. The nodes in the
    directed graphs represent the different possible states of the random variables,
    and the edges represent the probability of the system going from one state to
    the other in the next time instance. Let''s take a simple example of predicting
    the weather to understand this representation better. We will consider that there
    are three possible states of the random variable *Weather={Sunny, Rainy, Snowy}*,
    and possible Markov chains for this can be represented as shown in *Figure 1.1*:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫链通常使用有向图表示。有向图中的节点表示随机变量的不同可能状态，边表示系统在下一个时间点从一个状态转移到另一个状态的概率。为了更好地理解这种表示方法，假设我们要预测天气。我们考虑随机变量
    *Weather={晴天，雨天，雪天}* 的三种可能状态，可能的马尔可夫链可以表示如下，如*图 1.1*所示：
- en: '![](img/346d701d-7454-4060-9e93-059c68a637f2.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/346d701d-7454-4060-9e93-059c68a637f2.png)'
- en: 'Figure 1.1: A simple Markov chain on the random variable, representing the random
    variable Weather={Sunny, Rainy, Snowy}and showing the probability of the random
    variable switching to other states in the next time instance'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1：一个简单的马尔可夫链，表示随机变量，表示随机变量 Weather={晴天，雨天，雪天}，并展示了该随机变量在下一个时间点切换到其他状态的概率。
- en: One of the main points to understand in Markov chains is that we are modeling
    the outcomes of a sequence of random variables over time. This is sometimes confusing
    for people since the model is represented using a single graph, which doesn't
    mention anything about time. So, the name state transitions is not a particularly
    good name for this, since the state is not changing for any random variable; rather,
    we are trying to determine the state of the next random variable given the observed
    state of our current random variable. Coming back to our example, we can see that
    the nodes of the graph represent the different possible states of the random variable *Weather, *and
    the edges between them show the probability of the next random variable taking
    the different possible states, given the state of the current random variable.
    The self-loops show the probability of the model staying in its current state.
    In the previous Markov chain, let's say we know that the observed state of the
    current random variable is *Sunny, *then the probability that the random variable
    at the next time instance will also take the value *Sunny *is *0.8*. It could
    also take the value *Rainy *with a probability of *0.19*, or *Snowy* with a probability
    of *0.01*. One thing to note here is that the sum of all the probability values
    on all the outward edges from any state should equal 1, since it's an exhaustive
    event.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 理解马尔可夫链的一个关键点是，我们正在模拟一系列随机变量随时间变化的结果。这一点有时会让人感到困惑，因为模型是通过一个单一的图来表示的，而图中并没有提到任何关于时间的内容。因此，“状态转移”这个名称并不特别合适，因为任何随机变量的状态并没有发生变化；相反，我们是试图根据当前随机变量的观测状态来确定下一个随机变量的状态。回到我们的例子中，可以看到图中的节点表示随机变量*天气*的不同可能状态，而节点之间的边则显示在当前随机变量状态下，下一个随机变量转移到不同可能状态的概率。自循环则显示模型保持在当前状态的概率。在前面的马尔可夫链中，假设我们知道当前随机变量的观测状态是*晴天*，那么下一个时间点随机变量仍然是*晴天*的概率是*0.8*。它也可能是*雨天*，其概率为*0.19*，或者是*雪天*，其概率为*0.01*。这里需要注意的是，从任何状态出发的所有外向边的概率值之和应该等于1，因为这是一个穷尽事件。
- en: 'Now, let''s try to code this simple Markov chain. We will start by defining
    a simple `MarkovChain` class, and we will keep on adding methods to this class
    as we go through this chapter:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试编写这个简单的马尔可夫链。我们将首先定义一个简单的`MarkovChain`类，并在本章中逐步为这个类添加方法：
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, we can try out our example with this `MarkovChain` class:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以尝试用这个`MarkovChain`类来运行我们的例子：
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the previous code example, you might find your outputs to be different from
    what's shown here. This is because the Markov chain is probabilistic in nature
    and it picks on the next state based on a probability distribution, which can
    give different outputs on different runs.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码示例中，你可能会发现你的输出与这里显示的不同。这是因为马尔可夫链本质上是概率性的，它基于概率分布选择下一个状态，这可能导致不同运行结果的不同输出。
- en: So far in the discussion, we have considered that the probability space of the
    variables doesn't change over different instances of time. This is known as a **time-homogeneous
    Markov chain**, but it is also possible to have a **time-inhomogeneous Markov
    chain**, which also has a lot of applications but is outside the scope of this
    book.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论的假设是变量的概率空间在不同时间点之间是不变的。这种情况称为**时间齐次马尔可夫链**，但也可以存在**时间不齐次马尔可夫链**，这种情况在许多应用中也有用，但超出了本书的范围。
- en: Parameterization of Markov chains
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 马尔可夫链的参数化
- en: In the code for the Markov chain in the previous section, we used a dictionary
    to parameterize the Markov chain that had the probability values of all the possible
    state transitions. Another way of representing state transitions is using a **transition
    matrix**. The transition matrix, as the name suggests, uses a tabular representation
    for the transition probabilities. The transition matrix for the example in *Figure
    1.1* is shown in the following table.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节的马尔可夫链代码中，我们使用字典对马尔可夫链进行参数化，字典中包含了所有可能的状态转移的概率值。另一种表示状态转移的方式是使用**转移矩阵**。顾名思义，转移矩阵使用表格形式表示转移概率。*图1.1*中的例子对应的转移矩阵如下表所示。
- en: 'The following table shows the transition matrix for the Markov chain shown
    in *Figure 1.1*. The probability values represent the probability of the system
    going from the state in the row to the states mentioned in the columns:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 下表展示了*图1.1*中马尔可夫链的转移矩阵。概率值表示系统从行中的状态转移到列中状态的概率：
- en: '| **States** | **Sunny** | **Rainy** | **Snowy** |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| **状态** | **晴天** | **雨天** | **雪天** |'
- en: '| **Sunny** | 0.8 | 0.19 | 0.01 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| **晴天** | 0.8 | 0.19 | 0.01 |'
- en: '| **Rainy** | 0.2 | 0.7 | 0.1 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| **雨天** | 0.2 | 0.7 | 0.1 |'
- en: '| **Snowy** | 0.1+ | 0.2 | 0.7 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| **雪天** | 0.1+ | 0.2 | 0.7 |'
- en: 'The transition matrix represents the same information as in the dictionary,
    but in a more compact way. For this reason, the transition matrix is the standard
    way of representing Markov chains. Let''s modify our `MarkovChain` class so that
    it can accept a transition matrix:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 转移矩阵以更紧凑的方式表示与字典相同的信息。因此，转移矩阵是表示马尔可夫链的标准方法。让我们修改我们的`MarkovChain`类，使其能够接受转移矩阵：
- en: '[PRE7]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Running this code should also give similar results to what we got in the previous
    section. Using a transition matrix might not seem like a good idea because it
    requires us to create extra variables to store the indices. But, in cases when
    we have hundreds of states, using a transition matrix is much more efficient than
    using the simple dictionary implementation. In the case of a transition matrix,
    we can simply use NumPy indexing to get the probability values in the `next_state`
    method, whereas we were looping over all the state names in the previous implementation:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这段代码应该会得到与我们在前一节中得到的类似结果。使用转移矩阵可能看起来不是一个好主意，因为它要求我们创建额外的变量来存储索引。但在状态数目达到数百个时，使用转移矩阵比使用简单的字典实现要高效得多。在转移矩阵的情况下，我们可以简单地使用NumPy索引在`next_state`方法中获取概率值，而在前一个实现中，我们是循环遍历所有状态名称的：
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Properties of Markov chains
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 马尔可夫链的性质
- en: In this section, we will talk about the different properties of Markov chains,
    namely reducibility, periodicity, transience and recurrence, ergodicity, and steady-state
    analysis and limiting distributions. We will also try some simple examples of
    our `MarkovChain` class to show these properties.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论马尔可夫链的不同性质，即可约性、周期性、瞬时性和重现性、遍历性、稳态分析和极限分布。我们还将尝试一些简单的`MarkovChain`类的示例，以展示这些性质。
- en: Reducibility
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可约性
- en: 'A Markov chain is said to be **irreducible** if we can reach any state of the
    given Markov chain from any other state. In terms of states, state *j* is said
    to be **accessible** from another state *i *if a system that started at state
    *i* has a non-zero probability of getting to the state *j*. In more formal terms,
    state *j* is said to be accessible from state *i* if an integer *n[ij] ≥ 0* exists
    such that the following condition is met:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们可以从马尔可夫链中的任何状态到达其他任何状态，则该马尔可夫链被称为**不可约的**。就状态而言，状态 *j* 被称为从另一个状态 *i* **可访问**，如果从状态
    *i* 启动的系统有非零的概率到达状态 *j*。更正式地说，状态 *j* 被称为从状态 *i* 可访问，如果存在一个整数 *n[ij] ≥ 0*，使得满足以下条件：
- en: '![](img/08868cdf-6f36-4bf9-9a0a-238a7b3ae4ac.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/08868cdf-6f36-4bf9-9a0a-238a7b3ae4ac.png)'
- en: 'The *n[ij]* here is basically the number of steps it takes to go from state
    *i* to *j*, and it can be different for different pairs of values for *i* and
    *j*. Also, for a given state *i*, if all the values for *n[ij] = 0*, it means
    that all the states of the Markov chain are directly accessible from it. The accessibility
    relation is reflexive and transitive, but not necessary symmetric. We can take
    a simple example to understand this property:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的*n[ij]* 基本上是从状态 *i* 到状态 *j* 所需的步数，它对于不同的 *i* 和 *j* 值对可能不同。此外，对于给定的状态 *i*，如果所有的
    *n[ij] = 0*，这意味着马尔可夫链的所有状态都可以从它直接访问。可访问性关系是自反的和传递的，但不一定是对称的。我们可以通过一个简单的例子来理解这一性质：
- en: '![](img/2157c03e-4397-4110-a66a-e37822909cf6.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2157c03e-4397-4110-a66a-e37822909cf6.png)'
- en: 'Figure 1.2: An example of an irreducible Markov chain'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1.2: 一个不可约马尔可夫链的示例'
- en: In the previous example, it can be clearly seen that all of the states are accessible
    from all other states and hence are irreducible.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的例子中，可以清楚地看到所有状态都可以从其他状态访问，因此是不可约的。
- en: Note in the examples in *Figure 1.2* and *Figure 1.3* that we haven't represented
    edges if probability values are 0\. This helps to keep the model less complicated
    and easier to read.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在*图 1.2* 和 *图 1.3* 中的例子，我们没有表示概率值为0的边。这有助于保持模型不那么复杂，更容易阅读。
- en: 'In the following example, we can see that state **D** is not accessible from
    **A**, **B**, or **C**. Also, state **C** is not accessible from either **A**
    or **B**. But all the states are accessible from state **D**, and states **A**
    and **B** are accessible from **C**:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们可以看到状态**D**无法从**A**、**B**或**C**访问。此外，状态**C**无法从**A**或**B**访问。但所有状态都可以从状态**D**访问，并且状态**A**和**B**可以从状态**C**访问：
- en: '![](img/90f569c3-3c03-4fcc-8f3d-cd039301b53d.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](img/90f569c3-3c03-4fcc-8f3d-cd039301b53d.png)'
- en: 'Figure 1.3: An example of a reducible Markov chain'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3：一个可约马尔可夫链的示例
- en: 'We can also add a couple of methods to our `MarkovChain` class to check which
    states in our chain are reachable and whether our chain is irreducible:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以为`MarkovChain`类添加几个方法，用于检查我们链中的哪些状态是可达的，并且检查我们的链是否是不可约的：
- en: '[PRE9]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let''s give our examples a try using the examples in *Figure 1.2* and *Figure
    1.3*:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用*图1.2*和*图1.3*中的示例来进行实验：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Periodicity
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 周期性
- en: 'State *i* is said to have period *k* if any possible path to return to state
    *i* would be a multiple of *k* steps. Formally, it is defined like this:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果从状态*i*返回到状态*i*的任何可能路径的步数都是*k*的倍数，则状态*i*的周期为*k*。形式化地定义如下：
- en: '![](img/6dbaa677-d15d-4024-a027-174e6458d04f.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6dbaa677-d15d-4024-a027-174e6458d04f.png)'
- en: Here, *gcd *means the **greatest common divisor** (**GCD**). Basically, *k* is
    the GCD of the length/number of steps of all possible paths from state *i* back
    to itself. If there are no possible paths from state *i *back to itself, then
    the period for it is not defined. We also need to note that *k* has nothing to
    do with the number of steps required to return to the starting state. For example,
    let's say that for any given state the number of steps required to return to it
    are *(4, 6, 8, 12, 16)*. In this case *k=2*, but the minimum number of steps required
    to return is *4,* and *2* doesn't even appear in the list of possible numbers
    of steps.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*gcd*表示**最大公约数**（**GCD**）。基本上，*k*是从状态*i*返回到自身的所有可能路径的长度/步数的最大公约数。如果没有从状态*i*返回到自身的路径，则其周期未定义。我们还需要注意，*k*与返回起始状态所需的步数无关。例如，假设对于任意给定的状态，返回该状态所需的步数是*(4,
    6, 8, 12, 16)*。在这种情况下，*k=2*，但返回所需的最小步数是*4*，而*2*甚至没有出现在可能的步数列表中。
- en: 'For any given state in the Markov chain, if *k=1*, the state is said to be
    **aperiodic**. A Markov chain is called aperiodic if all of its states are aperiodic.
    One major thing to note is that, in the case of an irreducible Markov chain, a
    single aperiodic state is enough to imply that all the states are aperiodic. Let''s
    take a simple example and check the periodicity of different states:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于马尔可夫链中的任何给定状态，如果*k=1*，则该状态称为**非周期性**。如果马尔可夫链的所有状态都是非周期性的，则该马尔可夫链称为非周期性的。需要注意的是，在不可约马尔可夫链的情况下，单个非周期性状态就足以说明所有状态都是非周期性的。让我们举一个简单的例子，检查不同状态的周期性：
- en: '![](img/e557d34b-4c7d-488b-aac4-79b0078332b2.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e557d34b-4c7d-488b-aac4-79b0078332b2.png)'
- en: Figure 1.4: Markov chain is also periodic
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4：马尔可夫链也是周期性的
- en: 'In the previous example, we can easily see that for state **A** the possible
    paths to return are **A** -> **B** -> **C** -> **A** or **A** -> **B** -> **C**
    -> **D** -> **E** -> **C** -> **A**. For these two paths, the path lengths are
    3 and 6, respectively, and hence state **A** has a period of 3\. Similarly, **B**,
    **C**, **D**, and **E** also each has a period of 3 in the Markov chain, and hence
    the Markov chain is also periodic:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们可以很容易地看到，对于状态**A**，返回的可能路径是**A** -> **B** -> **C** -> **A**或**A**
    -> **B** -> **C** -> **D** -> **E** -> **C** -> **A**。这两条路径的长度分别是3和6，因此状态**A**的周期是3。同样，**B**、**C**、**D**和**E**在马尔可夫链中也都有3的周期，因此该马尔可夫链也是周期性的：
- en: '![](img/53bdcce6-38f9-4282-8046-827e2ae07a11.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/53bdcce6-38f9-4282-8046-827e2ae07a11.png)'
- en: 'Figure 1.5: Example of Markov Chain with aperiodic states.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5：具有非周期性状态的马尔可夫链示例。
- en: In this example, we added a couple of extra edges, due to which the possible
    path lengths for **A** are now *3, 5, 7, ...;* and for **B** are *2, 3, 4, 5,
    ...* And, since the GCD of these path lengths is 1, states **A** and **B** are
    both now aperiodic. Similarly, we can compute the period of other nodes, each
    of which is also 1, and hence the Markov chain is also aperiodic.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们增加了一些额外的边，因此**A**的可能路径长度现在是*3, 5, 7, ...*；**B**的可能路径长度是*2, 3, 4, 5,
    ...*。由于这些路径长度的最大公约数（GCD）为1，因此**A**和**B**现在都是非周期性的。类似地，我们可以计算其他节点的周期，每个节点的周期也是1，因此该马尔可夫链也是非周期性的。
- en: 'Let''s now add a couple of new methods to our `MarkovChain` class to compute
    the period of different states and check whether our model is aperiodic:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们为`MarkovChain`类添加几个新方法，用于计算不同状态的周期并检查我们的模型是否是非周期性的：
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s now try out our methods on our examples. In this example, we will randomly
    assign probability values to different transitions:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们在我们的例子中尝试这些方法。在这个例子中，我们将随机分配不同过渡的概率值：
- en: '[PRE12]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Transience and recurrence
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 瞬态与重现性
- en: 'Given that we start at state *i*, it is called **transient **if there is a
    non-zero probability that we will never return to state *i*. To define this in
    more formal terms, let''s consider a random variable *T[i]* as the first return
    time to state *i*:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们从状态*i*开始，如果存在一个非零概率我们永远不会返回到状态*i*，则称该状态为**瞬态**。为了更正式地定义这一点，我们可以将随机变量*T[i]*看作是首次返回到状态*i*的时间：
- en: '![](img/04d20803-cef5-45c5-9b34-dc573ecd193a.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/04d20803-cef5-45c5-9b34-dc573ecd193a.png)'
- en: 'Let''s now define another term, ![](img/4f34bad6-91a7-4962-84fc-d352a981f4fc.png),
    as the probability of the system returns to state *i* after *n* steps:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们定义另一个术语，![](img/4f34bad6-91a7-4962-84fc-d352a981f4fc.png)，作为系统在*n*步之后返回到状态*i*的概率：
- en: '![](img/270650b0-6e5f-44da-ae58-7dd809c8bc7c.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/270650b0-6e5f-44da-ae58-7dd809c8bc7c.png)'
- en: 'Now we can define that any given state *i* is transient if the following condition
    is met:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以定义，当以下条件满足时，任何给定状态*i*是瞬态的：
- en: '![](img/2f7cf787-a6e8-4932-80c9-222ebe3bf2e5.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2f7cf787-a6e8-4932-80c9-222ebe3bf2e5.png)'
- en: 'In the preceding equation, we are basically checking whether the total sum
    of probabilities of returning to state *i* in step sizes less than ![](img/5e7bf897-9732-416f-9b50-5f97c4443743.png)
    is less than *1*. If the total sum is less than *1*, it would mean that the probability
    of *T[i]* to be ![](img/698f246f-4292-4db7-9ec1-0662ddf1b719.png) is greater than
    *0* which would mean that the state *i* is transient. The given state *i* is called **recurrent**
    if it is not transient:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的公式中，我们基本上是在检查返回到状态*i*的概率总和，步长小于![](img/5e7bf897-9732-416f-9b50-5f97c4443743.png)时是否小于*1*。如果总和小于*1*，则意味着*T[i]*返回到![](img/698f246f-4292-4db7-9ec1-0662ddf1b719.png)的概率大于*0*，这就意味着状态*i*是瞬态的。如果状态*i*不是瞬态的，那么它被称为**常返**：
- en: '![](img/e52def1e-c33f-4ac5-890c-54ae185acdab.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e52def1e-c33f-4ac5-890c-54ae185acdab.png)'
- en: 'Figure 1.6:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6：
- en: In the preceding example, we can see that states **A** and **B** are transient
    because **A** doesn't have any incoming edge. **B** does have an incoming edge,
    but it's incoming from another transient state and therefore it is also transient.
    Hence, once the system leaves state **A** or **B**, it won't be able to come back.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的例子中，我们可以看到状态**A**和**B**是瞬态的，因为**A**没有任何输入边。**B**确实有输入边，但它来自另一个瞬态状态，因此它也是瞬态的。因此，一旦系统离开状态**A**或**B**，就无法再返回。
- en: 'It is really simple to check whether a given state is transient or not. We
    can simply check whether there are any incoming edges from other states or not.
    If not, the state is transient. Let''s write a simple method to check this for
    our `MarkovChain` class:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 检查一个给定状态是否是瞬态状态其实非常简单。我们只需检查是否有来自其他状态的输入边。如果没有，那么该状态就是瞬态的。让我们为`MarkovChain`类编写一个简单的方法来检查这一点：
- en: '[PRE13]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now we can use this method in our example in *Figure 1.6* to check which nodes
    are transient:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以在*图 1.6*中的示例中使用此方法来检查哪些节点是瞬态的：
- en: '[PRE14]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In the following subsections, we will talk about the statistical properties
    of the random variable *T[i]*.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的小节中，我们将讨论随机变量*T[i]*的统计性质。
- en: Mean recurrence time
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平均返回时间
- en: 'The first-return time for the initial state *i* is also known as the **hitting
    time**. It was represented using the random variable *T[i]* in the previous section.
    The **mean recurrence time **of state *i* is defined as its expected return time:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 初始状态*i*的首次返回时间也被称为**击中时间**。在上一节中，它通过随机变量*T[i]*表示。状态*i*的**平均返回时间**定义为其预期返回时间：
- en: '![](img/ed32432b-7b90-47b3-b018-58e9ccf05b4b.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed32432b-7b90-47b3-b018-58e9ccf05b4b.png)'
- en: If the mean recurrence time, *M[i]*, is finite, the state is called **positive
    recurrent**, otherwise it is called **null recurrent**.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 如果平均返回时间*M[i]*是有限的，则该状态被称为**正常常返**，否则称为**无常返**。
- en: Expected number of visits
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预期访问次数
- en: 'As is evident from the name, the **expected number of visits **for any state
    *i* is the number of times the system is expected to be in that state. Also, a
    given state *i* is recurrent if and only if the expected number of visits to *i* is
    infinite:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，从名称上看，任何状态*i*的**预期访问次数**是系统预计将处于该状态的次数。此外，只有当状态*i*的预期访问次数为无限时，该状态才是常返的：
- en: '![](img/fb6b31d3-c6c7-495d-a26b-ad26a66abaff.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fb6b31d3-c6c7-495d-a26b-ad26a66abaff.png)'
- en: Absorbing states
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 吸收状态
- en: 'State *i* is said to be an **absorbing state **if it is impossible for a system
    to leave that state once it reaches it. For a state to be an absorbing state,
    the probability of staying in the same state should be *1*, and all the other
    probabilities should be *0*:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一旦系统达到某个状态后无法离开该状态，则称状态*i*为**吸收状态**。要成为吸收状态，停留在同一状态的概率应该是*1*，而所有其他状态的概率应该是*0*：
- en: '![](img/09d3d7e8-7bed-43c4-aaed-c50658b6e009.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/09d3d7e8-7bed-43c4-aaed-c50658b6e009.png)'
- en: 'In a Markov chain, if all the states are absorbing, then we call it an absorbing
    Markov chain:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在马尔可夫链中，如果所有状态都是吸收状态，则我们称其为吸收马尔可夫链：
- en: '![](img/ed11565f-4c97-40c8-b946-587c3d705b3a.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed11565f-4c97-40c8-b946-587c3d705b3a.png)'
- en: 'Figure 1.7: An example showing an absorbing state C, since the probability
    of transitioning from state C to C is **1**'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7：一个示例，展示了吸收状态C，因为从状态C转移到C的概率是**1**
- en: 'Again, we can add a very simple method to check for absorbing states in our
    `MarkovChain` class:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们可以为我们的`MarkovChain`类添加一个非常简单的方法来检查吸收状态：
- en: '[PRE15]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can again check whether our state in the example is absorbing by creating
    a Markov chain and using the `is_absorbing` method:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过创建一个马尔可夫链并使用`is_absorbing`方法再次检查示例中的状态是否是吸收状态：
- en: '[PRE16]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Ergodicity
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 遗传性
- en: State *i* is said to be ergodicif it is recurrent, has a period of *1*, and
    has a finite mean recurrence time. If all the states of a Markov chain are ergodic,
    then it's an ergodic Markov chain. In general terms, a Markov chain is ergodic
    if there is a number *N*, such that any state in the system can be reached from
    any other state in any number of steps greater than or equal to the number *N*.
    Therefore, in the case of a fully connected transition matrix, where all transitions
    have a non-zero probability, this condition is fulfilled with *N=1*.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 状态*i*被称为具有遗传性的，如果它是重现的，周期为*1*，并且具有有限的平均重现时间。如果一个马尔可夫链的所有状态都是遗传的，那么它就是一个遗传马尔可夫链。一般而言，如果存在一个数字*N*，使得系统中的任何状态都可以通过大于或等于*N*步数的方式从任何其他状态到达，那么这个马尔可夫链就是遗传的。因此，在完全连接的转移矩阵中，所有转移具有非零概率时，这个条件通过*N=1*得以满足。
- en: Steady-state analysis and limiting distributions
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稳态分析与极限分布
- en: 'In a Markov chain, vector *π* is called the **stationary distribution** if *∀
    j ∈ s* satisfies the following conditions:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在马尔可夫链中，如果向量*π*满足*∀ j ∈ s*，并且满足以下条件，则称其为**定常分布**：
- en: '![](img/a953572f-46e4-4143-8949-bb5c54f86fd0.png)![](img/a08e7d8a-dc8a-4a1f-88f6-c1785c4aee42.png)![](img/abef43c3-94bd-45eb-86ef-e533349dc6b2.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a953572f-46e4-4143-8949-bb5c54f86fd0.png)![](img/a08e7d8a-dc8a-4a1f-88f6-c1785c4aee42.png)![](img/abef43c3-94bd-45eb-86ef-e533349dc6b2.png)'
- en: The stationary distribution is one of the most important properties of Markov
    chains, and we will talk about it in much more detail in later sections of this
    chapter.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 定常分布是马尔可夫链最重要的性质之一，我们将在本章后续部分详细讨论它。
- en: Continuous-time Markov chains
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连续时间马尔可夫链
- en: Continuous-time Markov chains are quite similar to discrete-time Markov chains
    except for the fact that in the continuous case we explicitly model the transition
    time between the states using a positive-value random variable. Also, we consider
    the system at all possible values of time instead of just the transition times.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 连续时间马尔可夫链与离散时间马尔可夫链非常相似，不同之处在于，在连续时间的情况下，我们显式地使用一个正值随机变量来建模状态之间的转换时间。此外，我们还会考虑系统在所有可能的时间值下的状态，而不仅仅是转换时间。
- en: Exponential distributions
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指数分布
- en: 'The random variable *x* is said to have an exponential distribution with a
    rate of distribution of *λ* if its probability density function is defined as
    follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量*x*被称为具有分布率*λ*的指数分布，如果其概率密度函数定义如下：
- en: '![](img/b3978ef3-e2da-4d7a-a261-2b515257ad70.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b3978ef3-e2da-4d7a-a261-2b515257ad70.png)'
- en: 'Here, the rate of distribution *λ* needs to be greater than *0*. We can also
    compute the expectation of *X* as this:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，分布率*λ*需要大于*0*。我们还可以按如下方式计算*X*的期望：
- en: '![](img/75e9d1c4-2111-4f43-a9e3-10abfa201cd6.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/75e9d1c4-2111-4f43-a9e3-10abfa201cd6.png)'
- en: We see that the expectation of *X* is inversely proportional to the rate of
    learning. This means that an exponential distribution with a higher rate of learning
    would have a lower expectation. The exponential distribution is often used to
    model problems that involve modelling time until some event happens. A simple
    example could be modelling the time before an alarm clock goes off, or the time
    before a server comes to your table in a restaurant. And, as we know ![](img/dd100edc-df74-492f-8eb3-5ec358f9ebc2.png),
    the higher the learning rate, the sooner we would expect the event to happen,
    and hence the name *learning rate*.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到 *X* 的期望与学习率成反比。这意味着，具有较高学习率的指数分布会有较低的期望值。指数分布通常用于建模涉及某个事件发生时间的问题。一个简单的例子是建模闹钟响铃之前的时间，或者餐厅服务员上桌前的时间。而且，正如我们所知
    ![](img/dd100edc-df74-492f-8eb3-5ec358f9ebc2.png)，学习率越高，我们期望事件发生的时间越短，因此得名 *学习率*。
- en: 'We can also compute the second moment and the variance of the exponential distribution:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以计算指数分布的第二矩和方差：
- en: '![](img/b1ae65c6-6e54-47db-87eb-707b6fa61733.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b1ae65c6-6e54-47db-87eb-707b6fa61733.png)'
- en: 'And, using the first moment and the second moment, we can compute the variance
    of the distribution:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 使用第一矩和第二矩，我们可以计算该分布的方差：
- en: '![](img/ef34e702-b79c-40a3-8895-4ae604c4887d.png)![](img/825fd73b-5528-4cc5-8038-7f6591e99edd.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ef34e702-b79c-40a3-8895-4ae604c4887d.png)![](img/825fd73b-5528-4cc5-8038-7f6591e99edd.png)'
- en: 'Figure 1.x: Probability distribution of exponential distribution'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.x：指数分布的概率分布
- en: '![](img/01d538af-5079-4bf5-9a31-acceb2ec78a0.png) ![](img/5e2aefcc-b7b3-41d8-ba93-19e3fd346718.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/01d538af-5079-4bf5-9a31-acceb2ec78a0.png) ![](img/5e2aefcc-b7b3-41d8-ba93-19e3fd346718.png)'
- en: 'Now we will move on to some of the properties of the exponential distribution
    that are relevant to our example:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将继续讨论一些与我们示例相关的指数分布的属性：
- en: '**Memoryless**:*Figure 1.x* shows a plot of an exponential distribution. In
    the diagram, we can clearly see that the graph after any given point (*a* in this
    case) is an exact copy of the original distribution. We can also say that an exponential
    distribution that is conditioned on (*X > a*) still stays exponential. If we think
    about this property in terms of our examples, it means that if we had an alarm
    clock, and at any time, *t*, we check that it still hasn''t gone off, we can still
    determine the distribution over the time ahead of *t*, which will be the same
    exponential distribution. This property of the exponential distribution is known
    as being **memoryless**,since at any given point in time, if you know the current
    state of the system (in this example, that the alarm hasn''t gone off), you can
    determine the probability distribution over time in the future. This property
    of exponential distributions is quite similar to Markov chains, as you may recall
    from previous sections.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无记忆性**：*图 1.x* 显示了指数分布的图像。在图中，我们可以清晰地看到，在任意给定点（此例为 *a*）之后的图形与原始分布完全相同。我们也可以说，条件为
    (*X > a*) 的指数分布仍然是指数分布。如果从我们的示例来理解这一属性，这意味着如果我们有一个闹钟，在任意时间 *t*，我们检查它是否还没有响铃，我们仍然可以确定
    *t* 之后的时间的分布，这将是相同的指数分布。指数分布的这一属性被称为 **无记忆性**，因为在任何给定的时间点，如果你知道系统的当前状态（例如闹钟没有响），你就可以确定未来时间的概率分布。指数分布的这一属性与马尔科夫链非常相似，正如你可能在前面章节中回忆到的。'
- en: '**Probability of minimum value**:Let''s say we have *n* independent exponential
    distributions over the random variables *X[0]*, . . ., *X[n]* with learning rates *λ[0],
    ..., λ[n]*, respectively. For these distributions, we can prove that the distribution
    of *min(X[0], . . ., X[n])* is also an exponential distribution with learning
    rate ![](img/61a44bbe-5d1f-438a-a39b-77f63415ceb4.png):'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最小值的概率**：假设我们有 *n* 个独立的指数分布，随机变量分别为 *X[0]*，...，*X[n]*，学习率分别为 *λ[0]*，...，*λ[n]*。对于这些分布，我们可以证明，*min(X[0],
    . . ., X[n])* 的分布也是一个指数分布，学习率为 ![](img/61a44bbe-5d1f-438a-a39b-77f63415ceb4.png)：'
- en: '![](img/d2d9ee00-7dc9-4139-bfc6-1033a6dc3bb4.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d2d9ee00-7dc9-4139-bfc6-1033a6dc3bb4.png)'
- en: We will use both of these properties of the exponential distribution in our
    example for the continuous time Markov chain in a later section.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在后面的连续时间马尔科夫链示例中使用指数分布的这两个属性。
- en: Poisson process
  id: totrans-154
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 泊松过程
- en: 'The Poisson process is a continuous process, and there can be multiple interpretations
    of it, which lead to different possible definitions. In this section, we will
    start with the formal definition and build up to a more simple, intuitive definition. A
    continuous-time stochastic process *N(t):t > 0* is a **Poisson process** with
    a rate *λ > 0* if the following conditions are met:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '泊松过程是一个连续过程，可以有多种解释，从而导致不同的定义。在本节中，我们将从正式定义开始，逐步过渡到更简单、更直观的定义。一个连续时间随机过程*N(t):
    t > 0*，如果满足以下条件，则称其为**泊松过程**，速率为*λ > 0*：'
- en: '*N(0) = 0*'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*N(0) = 0*'
- en: It has **stationary** and **independent increments**
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它具有**平稳**和**独立增量**
- en: 'The distribution of *N(t)* is Poisson with mean *λt*:'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*N(t)*的分布为泊松分布，均值为*λt*：'
- en: '![](img/ee5e44d4-e407-47e7-b423-c6b65a4838c4.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee5e44d4-e407-47e7-b423-c6b65a4838c4.png)'
- en: First of all, we need to define what the stationary and independent increments
    are. For a continuous-time stochastic process, *X(t): ≥ 0*, an increment is defined
    as the difference in state of the system between two time instances; that is,
    given two time instances *s* and *t* with *s < t*, the increment from time *s* to
    time *t* is *X(t) - X(s)*. As the name suggests, a process is said to have a stationary
    increment if its distribution for the increment depends only on the time difference.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，我们需要定义什么是平稳增量和独立增量。对于一个连续时间随机过程*X(t): t ≥ 0*，增量被定义为系统在两个时间点之间状态的差异；也就是说，给定两个时间点*s*和*t*，且*s
    < t*，从时间*s*到时间*t*的增量是*X(t) - X(s)*。顾名思义，一个过程如果其增量的分布仅依赖于时间差，则称为具有平稳增量的过程。'
- en: In other words, a process is said to have a stationary increment if the distribution
    of *X(t[1]) - X(s[1])* is equal to *X(t[2]) - X(s[2])* if *t[1] > s[1],t[2] >
    s[2]* and *t[1] - s[1] = t[2] -s[2]*. A process is said to have an independent
    increment if any two increments in disjointed time intervals are independent;
    that is, if *t[1] > s[1] > t[2] > s[2]*, then the increments *X(t[2]) - X(s[2])* and *X(t1) -
    X(s1)* are independent.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，如果一个过程的增量分布依赖于时间差，而与具体时间点无关，则该过程称为具有平稳增量；即，如果*X(t[1]) - X(s[1])*的分布等于*X(t[2])
    - X(s[2])*，且满足*t[1] > s[1], t[2] > s[2]*并且*t[1] - s[1] = t[2] - s[2]*，则该过程具有平稳增量。如果任意两个不重叠时间区间的增量是独立的，则该过程称为具有独立增量；也就是说，如果*t[1]
    > s[1] > t[2] > s[2]*，那么增量*X(t[2]) - X(s[2])*和*X(t1) - X(s1)*是独立的。
- en: Now let's come back to defining the Poisson process. The Poisson process is
    essentially a counting process that counts the number of events that have occurred
    before time *t*. This count of the number of events before time *t* is given by
    *N(t),* and, similarly, the number of events occurring between time intervals
    *t* and *t + s* is given by *N(t + s) - N(t)*. The value *N(t + s) - N(t)* is
    Poisson-distributed with a mean *λ[s]*. We can see that the Poisson process has
    stationary increments in fixed time intervals, but as ![](img/8fc844b3-9885-4aea-8137-0b980d454a11.png),
    the value of *N(t)* will also approach infinity; that is, ![](img/a4c5c95a-61b3-4f89-a6f3-4b6eaaa929c3.png).
    Another thing worth noting is that, as the value of *λ* increases, the number
    of events happening will also increase, and that is why *λ* is also known as the
    **rate of the process**.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们回到定义泊松过程。泊松过程本质上是一个计数过程，用来统计在时间*t*之前发生的事件数量。这个时间*t*之前发生的事件数量由*N(t)*给出，同样，在时间区间*t*到*t
    + s*之间发生的事件数量由*N(t + s) - N(t)*给出。*N(t + s) - N(t)*的值服从泊松分布，均值为*λ[s]*。我们可以看到，泊松过程在固定时间间隔内具有平稳增量，但如同
    ![](img/8fc844b3-9885-4aea-8137-0b980d454a11.png)，*N(t)*的值也将趋近于无穷大；也就是说，![](img/a4c5c95a-61b3-4f89-a6f3-4b6eaaa929c3.png)。另一个值得注意的点是，随着*λ*值的增加，发生的事件数量也会增加，这就是为什么*λ*也被称为**过程的速率**。
- en: 'This brings us to our second simplified definition of the Poisson process.
    A continuous-time stochastic process *N(t): t ≥ 0* is called a Poisson process
    with the rate of learning *λ > 0* if the following conditions are met:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '这引出了我们对泊松过程的第二个简化定义。一个连续时间随机过程*N(t): t ≥ 0*，如果满足以下条件，则称其为泊松过程，学习速率为*λ > 0*：'
- en: '**N(0) = 0**'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**N(0) = 0**'
- en: It is a counting process; that is, *N(T)* gives the count of the number of events
    that have occurred before time *t*
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是一个计数过程；也就是说，*N(T)*给出了在时间*t*之前发生的事件数量。
- en: The times between the events are distributed independently and identically,
    with an exponential distribution having a learning rate of *λ*
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件之间的时间间隔是独立且同分布的，服从指数分布，学习速率为*λ*。
- en: Continuous-time Markov chain example
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连续时间马尔科夫链示例
- en: Now, since we have a basic understanding of exponential distributions and the
    Poisson process, we can move on to the example to build up a continuous-time Markov
    chain. In this example, we will try to show how the properties of exponential
    distributions can be used to build up generic continuous-time Markov chains. Let's
    consider a hotel reception where *n* receptionists are working in parallel. Also
    consider that the guests arrive according to a Poisson process, with rate *λ*,
    and the service time for each guest is represented using an exponential random
    variable with learning rate *µ*. Also, if all the receptionists are busy when
    a new guest arrives, he/she will depart without getting any service. Now let's
    consider that a new guest arrives and finds all the receptionists are busy, and
    let's try to compute the expected number of busy receptionists in the next time
    interval.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，既然我们对指数分布和泊松过程有了基本的理解，我们可以进入示例，构建一个连续时间马尔可夫链。在这个例子中，我们将展示如何利用指数分布的特性来构建通用的连续时间马尔可夫链。假设有一个酒店接待处，*n*个接待员并行工作。同时，假设客人按照泊松过程到达，速率为*λ*，每位客人的服务时间使用具有学习速率*µ*的指数随机变量表示。此外，如果所有接待员都忙碌，当新客人到达时，他/她将无法获得服务并离开。现在假设一个新客人到达并发现所有接待员都忙碌，接下来我们尝试计算在下一个时间区间内的忙碌接待员的期望数量。
- en: Let's start by assuming that *T[k]* represents the number of *k* busy receptionists
    in the next time instance. We can also use *T[k]* to represent the expected number
    of busy receptionists found by the next arriving guest if *k* receptionists are
    busy at the current time instance. These two representations of *T[k]* are equivalent
    because of the memoryless property of exponential distributions.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 假设*T[k]*表示下一个时间点上有*k*个忙碌的接待员。我们也可以使用*T[k]*表示如果当前时刻有*k*个接待员忙碌，下一个到达的客人找到的忙碌接待员的期望数量。这两种*T[k]*的表示是等效的，因为指数分布具有无记忆性。
- en: 'Firstly, *T[0]* is clearly *0*, because if there are currently *0* busy receptionists,
    the next arrival will also find *0* busy receptionists for sure. Now, considering
    *T[1]*, if there are currently *i* busy receptionists, the next arriving guest
    will find *1* busy receptionist if the time to the next arrival is less than the
    remaining service time for the busy receptionist. From the memoryless property,
    we know that the next arrival time is exponentially distributed with a learning
    rate of *λ*, and the remaining service time is also exponentially distributed
    with a learning rate of *µ*. Therefore, the probability that the next guest will
    find one receptionist busy is ![](img/068b24db-2f99-4a87-b9cd-014c064a8012.png)
    and hence the following is true:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，*T[0]*显然是*0*，因为如果当前没有忙碌的接待员，下一个到达的客人也一定会发现没有忙碌的接待员。现在考虑*T[1]*，如果当前有*i*个忙碌的接待员，下一个到达的客人会发现有1个忙碌的接待员，前提是下一次到达的时间小于忙碌接待员剩余的服务时间。从无记忆性属性出发，我们知道下一次到达时间服从指数分布，学习速率为*λ*，而剩余的服务时间也服从指数分布，学习速率为*µ*。因此，下一个客人发现一个接待员忙碌的概率是![](img/068b24db-2f99-4a87-b9cd-014c064a8012.png)，因此以下结论成立：
- en: '![](img/442d615d-93a8-4b50-83df-cad87da8a688.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/442d615d-93a8-4b50-83df-cad87da8a688.png)'
- en: 'In general, we consider the situation that *k* receptionists are busy. We can
    obtain an expression for *T[k]* by conditioning on what happens first. When we
    have *k* receptionists busy, we can think of basically *k+1* independent exponential
    distributions: *k* exponentials with a learning rate of *µ* for the remaining
    service time for each receptionist, and *1* exponential distribution with a learning
    rate of *λ* for the next arriving guest. In our case, we want to condition on
    whether a service completion happens first or a new guest arrives first. The time
    for a service completion will be the minimum of the *k* exponentials. This first
    completion time is also exponentially distributed with a learning rate of *kµ*.
    Now, the probability of having a service completion before the next guest arrives
    is ![](img/7ce58380-fab8-4c4b-9d1f-f3f3fe154a99.png). Similarly, the probability
    of the next thing happening being a guest arrival is ![](img/175c5826-e3d2-475c-b4a7-3429afbc162f.png).'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，我们考虑 *k* 个接待员忙碌的情况。我们可以通过条件概率获得 *T[k]* 的表达式，具体条件取决于哪个事件先发生。当我们有 *k* 个接待员忙碌时，我们可以认为有
    *k+1* 个独立的指数分布：*k* 个指数分布，代表每个接待员的剩余服务时间，学习速率为 *µ*，以及 *1* 个指数分布，代表下一位到达的客人，学习速率为
    *λ*。在我们的案例中，我们希望根据服务完成还是新客人到达哪个事件先发生来进行条件化。服务完成的时间将是 *k* 个指数分布中的最小值。这个完成时间同样遵循指数分布，学习速率为
    *kµ*。现在，服务完成发生在下一位客人到达之前的概率为 ![](img/7ce58380-fab8-4c4b-9d1f-f3f3fe154a99.png)。类似地，下一件发生的事件是客人到达的概率为
    ![](img/175c5826-e3d2-475c-b4a7-3429afbc162f.png)。
- en: 'Now, based on this, we can say that if the next event is service completion,
    then the expected number of busy receptionists will be *T[k-1]*. Otherwise, if
    a guest arrives first, there will be *k* busy receptionists. Therefore we have
    the following:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，基于这一点，我们可以说，如果下一个事件是服务完成，那么预期的忙碌接待员数量将是 *T[k-1]*。否则，如果客人先到，将会有 *k* 个忙碌的接待员。因此我们得出以下结论：
- en: '![](img/82b218d4-3aba-4497-a550-b40a0f84beb6.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/82b218d4-3aba-4497-a550-b40a0f84beb6.png)'
- en: 'We need to just solve this recursion now. *T[2]* will be given by this equation:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在只需要解这个递归方程。 *T[2]* 将由以下方程给出：
- en: '![](img/10c9c1e2-44bf-4b47-95db-9f7d20a07ea5.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/10c9c1e2-44bf-4b47-95db-9f7d20a07ea5.png)'
- en: 'If we continue this same pattern, we will get *T[3]* as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们继续这个模式，我们将得到 *T[3]*，其形式如下：
- en: '![](img/bd73ad20-4547-46a9-81f7-b7c796b8e79c.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd73ad20-4547-46a9-81f7-b7c796b8e79c.png)'
- en: 'We can see a pattern in the values of *T[1]* and *T[2]*, and therefore we can
    write a general term for it as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到 *T[1]* 和 *T[2]* 的值中有规律可循，因此我们可以写出一个通项公式，如下所示：
- en: '![](img/bb49a251-7a25-4539-a1a2-cd330a334033.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bb49a251-7a25-4539-a1a2-cd330a334033.png)'
- en: 'Let''s point out our observations on the previous example:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下之前例子的观察结果：
- en: At any given time instance, if there are *i* busy receptionists, for *i < n* there
    are *i + 1* independent exponential distributions, with *i* of them having rate *µ*,
    and *1* of them having rate *λ*. The time until the process makes a jump is exponential,
    and its rate is given by *iµ + λ*. If all the receptionists are busy, then only
    the *n* exponential distributions corresponding to the service time can trigger
    a jump, and the time until the process makes a jump is exponential with rate *nµ*.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任何给定的时间点，如果有 *i* 个忙碌的接待员，且 *i < n*，则有 *i + 1* 个独立的指数分布，其中 *i* 个的速率为 *µ*，而 *1*
    个的速率为 *λ*。直到过程发生跳跃的时间是指数分布，其速率为 *iµ + λ*。如果所有接待员都忙碌，那么只有与服务时间相关的 *n* 个指数分布能够触发跳跃，且过程发生跳跃的时间是指数分布，速率为
    *nµ*。
- en: When the process jumps from state *i*, for *i < n*, it jumps to state *i + 1* with
    probability ![](img/ed6d8ec5-8072-4d0c-a69a-ee917ca54e2a.png), and jumps to state
    *i - 1* with probability of ![](img/1db82956-143a-4aea-9a00-55b931fdcf1f.png).
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当过程从状态 *i* 跳转时，若 *i < n*，则以概率 ![](img/ed6d8ec5-8072-4d0c-a69a-ee917ca54e2a.png)
    跳转到状态 *i + 1*，以概率 ![](img/1db82956-143a-4aea-9a00-55b931fdcf1f.png) 跳转到状态 *i -
    1*。
- en: When the process makes a jump from state *i*, we can start up a whole new set
    of distributions corresponding to the state we jumped to. This is because, even
    though some of the old exponential distributions haven't triggered, it's equivalent
    to resetting or replacing those distributions.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当过程从状态 *i* 发生跳跃时，我们可以启动一整套新的分布，分别对应我们跳转到的状态。这是因为，即使某些旧的指数分布尚未触发，也等同于重置或替换这些分布。
- en: Every time we jump to state *i*, regardless of when the time is, the distribution
    of how long we stay in state *i* and the probabilities of where we jump to next
    when we leave state *i* are the same. In other words, the process is time-homogeneous.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我们跳转到状态 *i* 时，无论时间何时，停留在状态 *i* 中的时间分布以及离开状态 *i* 后跳转到下一个状态的概率都是相同的。换句话说，该过程是时间齐次的。
- en: The preceding description of a continuous-time stochastic process corresponds
    to a continuous-time Markov chain. In the next section, we will try to define
    it in a more formal way.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 前面对连续时间随机过程的描述对应于一个连续时间马尔可夫链。在接下来的部分，我们将尝试以更正式的方式来定义它。
- en: Continuous-time Markov chain
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连续时间马尔可夫链
- en: In the previous section, we showed an example of a continuous-time Markov chain
    to give an indication of how it works. Let's now move on to formally define it.
    In a continuous-time Markov chain with a discrete state space *S,* for each state
    *i ∈ S* we have an associated set of *n[i]* independent exponential distributions
    with rates *q[i], j[1], ..., q[i],j[n[i]]*, where *j[1], ..., j[n[i]]* is the
    set of possible states the process may jump to when it leaves state *i*. And,
    when the process enters state *i*, the amount of time it spends in state *i* is
    exponentially distributed with rate *v[i] = q[i]j[1]+...+q[i]j[n[i]]*, and when
    it leaves state *i* it will go to state *j[l]* with probability ![](img/4f414e44-4ad4-415c-b90a-e4faab286f59.png)
    for *l = 1, ...,n[i]*.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一部分中，我们展示了一个连续时间马尔可夫链的例子，以说明它是如何工作的。现在我们将继续正式定义它。在一个具有离散状态空间 *S* 的连续时间马尔可夫链中，对于每个状态
    *i ∈ S*，我们有一组 *n[i]* 个独立的指数分布，其速率为 *q[i], j[1], ..., q[i], j[n[i]]*，其中 *j[1],
    ..., j[n[i]]* 是该过程离开状态 *i* 时可能跳转到的状态集合。当该过程进入状态 *i* 时，它在状态 *i* 中停留的时间服从速率为 *v[i]
    = q[i]j[1] + ... + q[i]j[n[i]]* 的指数分布，而当它离开状态 *i* 时，它将以概率 ![](img/4f414e44-4ad4-415c-b90a-e4faab286f59.png)
    跳转到状态 *j[l]*，其中 *l = 1, ..., n[i]*。
- en: We can also extend the Markov property from the discrete-time case to continuous
    time.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将马尔可夫性从离散时间情况扩展到连续时间情况。
- en: 'For a continuous-time stochastic process *(X(t) : t ≥ 0)* with state space
    *S*, we say it has the Markov property if the following condition is met:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '对于一个状态空间为 *S* 的连续时间随机过程 *(X(t) : t ≥ 0)*，我们说它具有马尔可夫性质，如果满足以下条件：'
- en: '![](img/32561f53-1637-4826-ad1c-8ce3f50d5a35.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/32561f53-1637-4826-ad1c-8ce3f50d5a35.png)'
- en: Here, *0 ≤ t[1] ≤ t2 ≤. . . .t[n-1 ]≤ s ≤ t* is any non-decreasing sequence
    of *n + 1* times, and *i[1, i]2, . . ., i[n-1], i, j∈ S* are any *n + 1* states
    in the state space, for any integer *n ≥ 1*.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*0 ≤ t[1] ≤ t2 ≤ ... ≤ t[n-1] ≤ s ≤ t* 是任何非递减的 *n + 1* 个时间点的序列，*i[1, i]2,
    ..., i[n-1], i, j ∈ S* 是状态空间中任意的 *n + 1* 个状态，对于任意整数 *n ≥ 1*。
- en: 'Similarly, we can extend time-homogeneity to the case of continuous-time Markov
    chains. We say that a continuous-time Markov chain is time homogenous if, for
    any *s ≤ t*, and any states *i*, *j ∈ S*, the following condition is met:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以将时间齐次性扩展到连续时间马尔可夫链的情况。我们说一个连续时间马尔可夫链是时间齐次的，如果对于任意 *s ≤ t* 和任意状态 *i*,
    *j ∈ S*，满足以下条件：
- en: '![](img/11009b6b-202e-4776-af19-20bc7b346c53.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](img/11009b6b-202e-4776-af19-20bc7b346c53.png)'
- en: As in the case of discrete-time Markov chains, a continuous-time Markov chain
    does not need to be time-homogeneous, but non-homogeneous Markov chains are out
    of scope for this book. For more details on non-homogeneous Markov chains, you
    can refer to Cheng-Chi Huang's thesis on the topic: [https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=8613&context=rtd](https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=8613&context=rtd).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 与离散时间马尔可夫链的情况一样，连续时间马尔可夫链不需要是时间齐次的，但非齐次的马尔可夫链超出了本书的讨论范围。关于非齐次马尔可夫链的更多细节，您可以参考黄成吉关于这一主题的论文：[https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=8613&context=rtd](https://lib.dr.iastate.edu/cgi/viewcontent.cgi?article=8613&context=rtd)。
- en: 'Now let''s define the transition probability for a continuous-time Markov chain.
    Just as the rates *q[ij]* in a continuous-time Markov chain are the counterpart
    of the transition probabilities *p[ij]* in a discrete-time Markov chain, there
    is a counterpart to the n-step transition probabilities *p[ij](t)* for a time-homogeneous,
    continuous-time Markov chain, which is defined as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们定义连续时间马尔可夫链的转移概率。就像连续时间马尔可夫链中的速率 *q[ij]* 是离散时间马尔可夫链中转移概率 *p[ij]* 的对应物一样，时间齐次的连续时间马尔可夫链也有与
    n 步转移概率 *p[ij](t)* 对应的概念，其定义如下：
- en: '![](img/4e6b5a80-1819-4567-a31b-770a6c9f1798.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4e6b5a80-1819-4567-a31b-770a6c9f1798.png)'
- en: Summary
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we gave a detailed introduction to Markov chains. We talked
    about different types of Markov chains, mainly chains with a discrete state space,
    with either discrete time or continuous time. We also introduced the concepts
    of time-homogeneous and non-time-homogeneous Markov chains. We discussed the different
    properties of Markov chains in detail, and provided relevant examples and code.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们对马尔可夫链进行了详细介绍。我们讨论了不同类型的马尔可夫链，主要是具有离散状态空间的链，涵盖离散时间或连续时间的情况。我们还介绍了时间齐次和非时间齐次马尔可夫链的概念。我们详细讨论了马尔可夫链的不同属性，并提供了相关的示例和代码。
- en: Markov chains and their properties are the basic concepts on which HMMs are
    built. In the next chapter, we will discuss HMMs in much more detail.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫链及其属性是隐马尔可夫模型（HMM）构建的基础概念。在下一章，我们将更加详细地讨论HMM。
