- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: Deep reinforcement learning enables the building of intelligent agents, products,
    and services that can go beyond computer vision or perception to perform actions.
    TensorFlow 2.x is the latest major release of the most popular deep learning framework
    that is used to develop and train **deep neural networks** (**DNNs**).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 深度强化学习使得构建智能代理、产品和服务成为可能，这些代理不仅仅局限于计算机视觉或感知，而是能够执行各种操作。TensorFlow 2.x是最新的主要版本，是最流行的深度学习框架，广泛用于开发和训练**深度神经网络**（**DNNs**）。
- en: The book begins with an introduction to the fundamentals of deep reinforcement
    learning and the latest major version of TensorFlow 2.x. You'll then cover OpenAI
    Gym, model-based RL, and model-free RL, and learn how to develop basic agents.
    Moving on, you will discover how to implement advanced deep reinforcement learning
    algorithms such as actor-critic, deep deterministic policy gradients, deep-Q networks,
    proximal policy optimization, deep recurrent Q-networks, and the soft actor-critic
    algorithm to train your RL agents. You'll also explore reinforcement learning
    in the real world by building cryptocurrency trading agents, stock/share trading
    agents, and intelligent agents for automating task completion. Lastly, you will
    find out how to deploy deep reinforcement learning agents to the cloud and build
    cross-platform apps for the web, mobile, and other platforms using TensorFlow
    2.x.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本书首先介绍了深度强化学习的基础知识以及TensorFlow 2.x的最新主要版本。接着，你将学习OpenAI Gym、基于模型的强化学习和无模型强化学习，并学习如何开发基本的代理。然后，你将发现如何实现高级深度强化学习算法，例如演员-评论家、深度确定性策略梯度、深度Q网络、近端策略优化、深度递归Q网络和软演员-评论家算法，以训练你的强化学习代理。你还将通过构建加密货币交易代理、股票/股市交易代理和用于自动化任务完成的智能代理来探索强化学习在实际中的应用。最后，你将了解如何将深度强化学习代理部署到云端，并使用TensorFlow
    2.x构建适用于Web、移动和其他平台的跨平台应用。
- en: By the end of this cookbook, you will have gained a solid understanding of deep
    reinforcement learning algorithms with the help of easy-to-follow and concise
    implementations from scratch using TensorFlow 2.x.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本书结束时，你将通过易于遵循的简洁实现，掌握深度强化学习算法的核心概念，并能够使用TensorFlow 2.x从头开始进行实现。
- en: Who this book is for
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书的读者对象
- en: The book is for machine learning application developers, AI and applied AI researchers,
    data scientists, deep learning practitioners, and students with a basic understanding
    of the reinforcement learning concepts who want to build, train, and deploy their
    own reinforcement learning systems from scratch using TensorFlow 2.x.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本书适用于机器学习应用开发人员、人工智能和应用人工智能研究人员、数据科学家、深度学习从业者，以及具有强化学习基础知识的学生，他们希望从零开始使用TensorFlow
    2.x构建、训练和部署自己的强化学习系统。
- en: What this book covers
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书涵盖的内容
- en: '[*Chapter 1*](B15074_01_Final_AM.xhtml#_idTextAnchor015), *Developing Building
    Blocks for Deep Reinforcement Learning Using TensorFlow 2.x*, provides recipes
    for getting started with RL environments, deep neural network-based RL agents,
    evolutionary neural agents, and other building blocks for both discrete and continuous
    action-space RL applications.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第1章*](B15074_01_Final_AM.xhtml#_idTextAnchor015)，*使用TensorFlow 2.x开发深度强化学习的构建模块*，提供了关于如何开始使用强化学习环境、基于深度神经网络的强化学习代理、进化神经代理以及其他用于离散和连续动作空间强化学习应用的构建模块的实现方法。'
- en: '[*Chapter 2*](B15074_02_Final_AM.xhtml#_idTextAnchor044), *Implementing Value-Based
    Policy Gradients and Actor-Critic Deep RL Algorithms*, includes recipes for implementing
    value iteration-based learning agents and breaks down the implementation of several
    foundational algorithms in RL, such as Monte-Carlo control, SARSA and Q-learning,
    actor-critic, and policy gradient algorithms into simple steps.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第2章*](B15074_02_Final_AM.xhtml#_idTextAnchor044)，*实现基于价值的策略梯度和演员-评论家深度强化学习算法*，包括实现基于价值迭代的学习代理的实现方法，并将强化学习中几个基础算法的实现分解为简单步骤，例如蒙特卡洛控制、SARSA和Q学习、演员-评论家以及策略梯度算法。'
- en: '[*Chapter 3*](B15074_03_ePub_AM.xhtml#_idTextAnchor090), *Implementing Advanced
    RL Algorithms*, provides concise recipes to implement complete agent training
    systems using Deep Q-Network (DQN), Double and Dueling Deep Q-Network (DDQN, DDDQN),
    Deep Recurrent Q-Network (DRQN), Asynchronous Advantage Actor-Critic (A3C), Proximal
    Policy Optimization (PPO), and Deep Deterministic Policy Gradient (DDPG) RL algorithms.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第3章*](B15074_03_ePub_AM.xhtml#_idTextAnchor090)，*实现高级强化学习算法*，提供了实现完整的代理训练系统的简明方法，使用的算法包括深度Q网络（DQN）、双重深度Q网络（DDQN、DDDQN）、深度递归Q网络（DRQN）、异步优势演员-评论家（A3C）、近端策略优化（PPO）和深度确定性策略梯度（DDPG）强化学习算法。'
- en: '[*Chapter 4*](B15074_04_ePub_AM.xhtml#_idTextAnchor135), *RL in the Real World*
    *–* *Building Cryptocurrency Trading Agents*, shows how to implement and train
    a soft actor-critic agent in custom RL environments for bitcoin and ether trading
    using real market data from trading exchanges such as Gemini, containing both
    tabular and visual (image) state/observation and discrete and continuous action
    spaces.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第4章*](B15074_04_ePub_AM.xhtml#_idTextAnchor135)，*现实世界中的强化学习* *–* *构建加密货币交易代理*，展示了如何在自定义RL环境中实现并训练一个软演员-评论家代理，使用来自交易所（如Gemini）的真实市场数据进行比特币和以太坊交易，涵盖了表格和视觉（图像）状态/观测以及离散和连续动作空间。'
- en: '[*Chapter 5*](B15074_05_ePub_AM.xhtml#_idTextAnchor153), *RL in the Real World*
    *–* *Building Stock/Share Trading Agents*, covers how to train advanced RL agents
    to trade for profit in the stock market using visual price charts and/or tabular
    ticket data and more in custom RL environments powered by real stock market exchange
    data.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第5章*](B15074_05_ePub_AM.xhtml#_idTextAnchor153)，*现实世界中的强化学习* *–* *构建股票/证券交易代理*，介绍了如何训练先进的RL代理，通过使用视觉价格图表和/或表格票据数据等，在由真实股票市场交易所数据驱动的自定义RL环境中进行股票市场交易以获取利润。'
- en: '[*Chapter 6*](B15074_06_ePub_AM.xhtml#_idTextAnchor167), *RL in the Real World*
    *–* *Building Intelligent Agents to Complete Your To-Dos*, provides recipes to
    build, train, and test vision-based RL agents for completing tasks on the web
    to help you automate tasks such as clicking on pop-up/confirmation dialogs on
    web pages, logging into various websites, finding and booking the cheapest flight
    tickets for your travel, decluttering your email inbox, and like/share/retweeting
    posts on social media sites to engage with your followers.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第6章*](B15074_06_ePub_AM.xhtml#_idTextAnchor167)，*现实世界中的强化学习* *–* *构建智能代理来完成您的待办事项*，提供了构建、训练和测试基于视觉的RL代理的食谱，用于在网络上完成任务，帮助您自动化诸如点击网页上的弹出/确认对话框、登录各大网站、查找并预订最便宜的机票、清理电子邮件收件箱、在社交媒体上进行点赞/分享/转发以与粉丝互动等任务。'
- en: '[*Chapter 7*](B15074_07_ePub_AM.xhtml#_idTextAnchor193), *Deploying Deep RL
    Agents to the Cloud*, contains recipes to equip you with tools and details to
    get ahead of the curve and build cloud-based Simulation-as-a-Service and Agent/Bot-as-a-Service
    programs using deep RL. Learn how to train RL agents using remote simulators running
    on the cloud, package runtime components of RL agents, and deploy deep RL agents
    to the cloud by deploying your own trading bot-as-a-service.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第7章*](B15074_07_ePub_AM.xhtml#_idTextAnchor193)，*将深度强化学习代理部署到云端*，包含了帮助您超越潮流的工具和细节，使用深度RL构建基于云的模拟即服务（Simulation-as-a-Service）和代理/机器人即服务（Agent/Bot-as-a-Service）程序。学习如何使用运行在云端的远程模拟器训练RL代理，如何打包RL代理的运行时组件，并通过部署您自己的交易机器人即服务将深度RL代理部署到云端。'
- en: '[*Chapter 8*](B15074_08_ePub_AM.xhtml#_idTextAnchor221), *Distributed Training
    for the Accelerated Development of Deep RL Agents*, contains recipes to speed
    up deep RL agent development using the distributed training of deep neural network
    models by leveraging TensorFlow 2.x''s capabilities. Learn how to utilize multiple
    CPUs and GPUs both on a single machine as well as on a cluster of machines to
    scale up/out your deep RL agent training and also learn how to leverage Ray, Tune,
    and RLLib for large-scale accelerated training.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第8章*](B15074_08_ePub_AM.xhtml#_idTextAnchor221)，*加速深度RL代理开发的分布式训练*，包含了通过利用TensorFlow
    2.x的功能，使用深度神经网络模型的分布式训练加速深度RL代理开发的食谱。学习如何利用单台机器或集群机器上的多个CPU和GPU来扩展深度RL代理训练，并学习如何利用Ray、Tune和RLLib进行大规模加速训练。'
- en: '[*Chapter 9*](B15074_09_ePub_AM.xhtml#_idTextAnchor244), *Deploying Deep RL
    Agents on Multiple Platforms*, provides customizable templates that you can utilize
    for building and deploying your own deep RL applications for your use cases. Learn
    how to export RL agent models for serving/deployment in various production-ready
    formats, such as TensorFlow Lite, TensorFlow.js, and ONNX, and learn how to leverage
    NVIDIA Triton or build your own solution to launch production-ready, RL-based
    AI services. You will also deploy an RL agent in a mobile and web app and learn
    how to deploy RL bots in your Node.js applications.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第9章*](B15074_09_ePub_AM.xhtml#_idTextAnchor244)，*在多个平台上部署深度RL代理*，提供了可定制的模板，您可以用来构建和部署您自己深度RL应用程序，以满足您的使用案例。学习如何将RL代理模型导出为各种生产就绪格式进行服务/部署，例如TensorFlow
    Lite、TensorFlow.js和ONNX，并学习如何利用NVIDIA Triton或构建您自己的解决方案来启动生产就绪的基于RL的AI服务。您还将学习如何将RL代理部署到移动和网页应用，并如何在您的Node.js应用中部署RL机器人。'
- en: To get the most out of this book
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为了最大程度地利用本书
- en: The code in this book is extensively tested on Ubuntu 18.04 and Ubuntu 20.04
    and should work with later versions of Ubuntu if Python 3.6+ is available. With
    Python 3.6+ installed along with the necessary Python packages, as listed at the
    start of each of the recipes, the code should run fine on Windows and macOS X
    too.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的代码在Ubuntu 18.04和Ubuntu 20.04上进行了广泛测试，如果安装了Python 3.6+，则应该能在更高版本的Ubuntu上正常运行。安装了Python
    3.6+以及每个示例开头列出的必要Python包后，代码也应该能够在Windows和macOS X上顺利运行。
- en: '![](img/B15074_Table_1.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15074_Table_1.jpg)'
- en: It is advised to create and use a Python virtual environment named tfrl-cookbook
    to install the packages and run the code in this book. A Miniconda or Anaconda
    installation for Python virtual environment management is recommended.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 建议创建并使用名为tfrl-cookbook的Python虚拟环境来安装包并运行本书中的代码。推荐使用Miniconda或Anaconda进行Python虚拟环境管理。
- en: '**If you are using the digital version of this book, we advise you to type
    the code yourself or access the code via the GitHub repository (link available
    in the next section). Doing so will help you avoid any potential errors related
    to the copying and pasting of code.**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你正在使用本书的数字版本，建议你自己输入代码，或者通过GitHub仓库访问代码（下节提供链接）。这样可以帮助你避免与代码复制粘贴相关的潜在错误。**'
- en: It is highly recommended to star and fork the GitHub repository to receive updates
    and improvements to the code recipes.We urge you to share what you build and also
    engage with other readers and the community at[https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/discussions](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/discussions).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 强烈建议你为GitHub仓库加星并进行分叉，以便接收代码示例的更新和改进。我们鼓励你分享你所构建的内容，并与其他读者和社区互动，访问[https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/discussions](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/discussions)。
- en: Download the example code files
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载示例代码文件
- en: You can download the example code files for this book from your account at [www.packt.com](http://www.packt.com).
    If you purchased this book elsewhere, you can visit [www.packtpub.com/support](http://www.packtpub.com/support)
    and register to have the files emailed directly to you.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过你的账户在[www.packt.com](http://www.packt.com)下载本书的示例代码文件。如果你在其他地方购买了本书，你可以访问[www.packtpub.com/support](http://www.packtpub.com/support)并注册，以便将文件直接通过电子邮件发送给你。
- en: 'You can download the code files by following these steps:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下步骤下载代码文件：
- en: Log in or register at [www.packt.com](http://www.packt.com).
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在[www.packt.com](http://www.packt.com)登录或注册。
- en: Select the **Support** tab.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**支持**选项卡。
- en: Click on **Code Downloads**.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**代码下载**。
- en: Enter the name of the book in the **Search** box and follow the onscreen instructions.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**搜索**框中输入书名，并按照屏幕上的说明操作。
- en: 'Once the file is downloaded, please make sure that you unzip or extract the
    folder using the latest version of:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 下载完成后，请确保使用以下最新版本的工具解压或提取文件夹：
- en: WinRAR/7-Zip for Windows
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Windows版的WinRAR/7-Zip
- en: Zipeg/iZip/UnRarX for Mac
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zipeg/iZip/UnRarX（适用于Mac）
- en: 7-Zip/PeaZip for Linux
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linux版的7-Zip/PeaZip
- en: The code bundle for the book is also hosted on GitHub at [https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/).
    In case there's an update to the code, it will be updated on the existing GitHub
    repository.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的代码包也托管在GitHub上，地址为[https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/](https://github.com/PacktPublishing/Tensorflow-2-Reinforcement-Learning-Cookbook/)。如果代码有更新，将会在现有的GitHub仓库中进行更新。
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了其他代码包，来自我们丰富的图书和视频目录，访问[https://github.com/PacktPublishing/](https://github.com/PacktPublishing/)。快去看看吧！
- en: Download the color images
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载彩色图片
- en: 'We also provide a PDF file that has color images of the screenshots/diagrams
    used in this book. You can download it here: [https://static.packt-cdn.com/downloads/9781838982546_ColorImages.pdf](https://static.packt-cdn.com/downloads/9781838982546_ColorImages.pdf).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还提供了一份PDF文件，包含了本书中使用的截图/图表的彩色图片。你可以在这里下载：[https://static.packt-cdn.com/downloads/9781838982546_ColorImages.pdf](https://static.packt-cdn.com/downloads/9781838982546_ColorImages.pdf)。
- en: Conventions used
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: There are a number of text conventions used throughout this book.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中使用了多种文本约定。
- en: '`Code in text`: Indicates code words used in the recipes. Here is an example:
    "We will start with the implementation of the `save` method in the `Actor` class
    to export the Actor model to TensorFlow''s `SavedModel` format."'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`文本中的代码`：表示在配方中使用的代码词。例如：“我们将从在`Actor`类中实现`save`方法开始，以将Actor模型导出为TensorFlow的`SavedModel`格式。”'
- en: 'A block of code is set as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一段代码设置如下：
- en: '[PRE0]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When we wish to draw your attention to a particular part of a code block, the
    relevant lines or items are set in bold:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望引起您对代码块中特定部分的注意时，相关行或项将设置为粗体：
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Any command-line input or output is written as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 任何命令行输入或输出如下所示：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Bold**: Indicates a new term, an important word, or words that you see onscreen.
    For example, words in menus or dialog boxes appear in the text like this. Here
    is an example: "Click on the **Open an Existing Project** option and you will
    see a popup asking you to choose the directory on your filesystem. Navigate to
    the [*Chapter 9*](B15074_09_ePub_AM.xhtml#_idTextAnchor244) recipes and choose
    **9.2_rl_android_app**."'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示新术语、重要单词或您在屏幕上看到的单词。例如，菜单或对话框中的文字通常会以这种方式显示。以下是一个示例：“点击**打开现有项目**选项，您将看到一个弹出窗口，要求您选择文件系统中的目录。导航到[*第9章*](B15074_09_ePub_AM.xhtml#_idTextAnchor244)的配方，并选择**9.2_rl_android_app**。”'
- en: Tips or important notes
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 提示或重要注意事项
- en: Appear like this.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 显示如下。
- en: Get in touch
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。
- en: '`customercare@packtpub.com`.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`customercare@packtpub.com`。'
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata),
    selecting your book, clicking on the Errata Submission Form link, and entering
    the details.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**：尽管我们已尽最大努力确保内容的准确性，但错误有时仍会发生。如果您发现本书中的错误，请向我们报告。请访问[www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)，选择您的书籍，点击“勘误提交表单”链接并填写详细信息。'
- en: '`copyright@packt.com` with a link to the material.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`copyright@packt.com`，并附上相关链接。'
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您在某个领域有专长，并且有意写作或为书籍做贡献，请访问[authors.packtpub.com](http://authors.packtpub.com)。'
- en: Reviews
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 书评
- en: Please leave a review. Once you have read and used this book, why not leave
    a review on the site that you purchased it from? Potential readers can then see
    and use your unbiased opinion to make purchase decisions, we at Packt can understand
    what you think about our products, and our authors can see your feedback on their
    book. Thank you!
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 请留下评论。当您阅读并使用完本书后，为什么不在您购买该书的网站上留下评论呢？潜在的读者可以看到并根据您的客观意见做出购买决定，我们Packt也能了解您对我们产品的看法，而我们的作者也能看到您对他们书籍的反馈。谢谢！
- en: For more information about Packt, please visit [packt.com](http://packt.com).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 欲了解有关Packt的更多信息，请访问[packt.com](http://packt.com)。
