- en: '*Chapter 5*: Creating NLP Search'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第五章*：创建 NLP 搜索'
- en: In the previous chapters, you were introduced to Amazon Textract for extracting
    text from documents, and Amazon Comprehend to extract insights with no prior **Machine
    Learning** (**ML**) experience as a prerequisite. In the last chapter, we showed
    you how you can combine these features together to solve a real-world use case
    for document automation by giving an example of loan processing.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，您已经了解了如何使用 Amazon Textract 提取文档中的文本，并使用 Amazon Comprehend 提取洞察，而无需提前具备
    **机器学习**（**ML**）经验。在上一章中，我们向您展示了如何结合这些功能，通过贷款处理的实例，解决实际的文档自动化案例。
- en: In this chapter, we will use the Amazon Textract and Amazon Comprehend services
    to show you how you can quickly set up an intelligent search solution with the
    integration of powerful elements, such as **Amazon Elasticsearch**, which is a
    managed service to set up search and log analytics, and **Amazon Kendra**, which
    is an intelligent managed search solution powered by ML for natural language search.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用 Amazon Textract 和 Amazon Comprehend 服务，展示如何快速搭建一个智能搜索解决方案，并结合强大的元素，如
    **Amazon Elasticsearch**，这是一项用于设置搜索和日志分析的托管服务，和 **Amazon Kendra**，这是一项由机器学习驱动的智能托管搜索解决方案，支持自然语言搜索。
- en: 'We will cover the following topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Going over search use cases and choices for search solutions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回顾搜索用例和搜索解决方案的选择
- en: Building a search solution for scanned images using Amazon Elasticsearch
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon Elasticsearch 为扫描图像构建搜索解决方案
- en: Setting up an enterprise search solution using Amazon Kendra
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon Kendra 设置企业搜索解决方案
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you will need access to an AWS account. Before getting started
    we recommend that you create an AWS account by going through these steps here:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您需要访问 AWS 账户。在开始之前，我们建议您按照以下步骤创建一个 AWS 账户：
- en: Open [https://portal.aws.amazon.com/billing/signup](https://portal.aws.amazon.com/billing/signup).
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 [https://portal.aws.amazon.com/billing/signup](https://portal.aws.amazon.com/billing/signup)。
- en: Please go through and execute the steps provided on the web page to sign up.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请访问并执行网页上提供的步骤进行注册。
- en: Log in to your AWS account when prompted in the sections.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在提示时登录到您的 AWS 账户。
- en: The Python code and sample datasets for the Amazon Textract examples are provided
    on the book's GitHub repo at [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2005](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2005).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的 GitHub 仓库中提供了 Amazon Textract 示例的 Python 代码和样本数据集，地址为：[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2005](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2005)。
- en: Check out the following video to see the Code in Action at [https://bit.ly/3nygP5S](https://bit.ly/3nygP5S).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频，查看代码演示：[https://bit.ly/3nygP5S](https://bit.ly/3nygP5S)。
- en: Creating NLP-powered smart search indexes
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建基于 NLP 的智能搜索索引
- en: Every organization has lots of documents in the form of paper and in their archives
    too. The challenge is that these documents lie mostly in separate silos and not
    all in one place. So, for these organizations to make a business decision based
    on the hidden information in their siloed documents is extremely challenging.
    Some approaches these organizations take to make their documents searchable is
    putting the documents in a data lake. However, extracting meaningful information
    from these documents is another challenge as it would require a lot of NLP expertise,
    ML skills, and infrastructure to set that up. Even if you were able to extract
    insights from these documents, another challenge will then be setting up a scalable
    search solution.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 每个组织都有大量的文档，既有纸质文档，也有存档文件。问题在于，这些文档大多分散在不同的孤岛中，而不是集中在一个地方。因此，对于这些组织来说，基于这些孤立文档中的隐藏信息做出业务决策是极具挑战性的。这些组织采取的一些方法是将文档放入数据湖中以便搜索。然而，从这些文档中提取有意义的信息则是另一项挑战，因为这需要大量的自然语言处理（NLP）专业知识、机器学习（ML）技能以及搭建基础设施的能力。即使您能够从这些文档中提取出有价值的见解，另一个挑战将是建立一个可扩展的搜索解决方案。
- en: In this section, we will address these challenges by using the AWS AI services
    we introduced in previous chapters and then talk about how they can be used to
    set up a centralized document store.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将通过使用我们在前几章中介绍的 AWS AI 服务来解决这些挑战，并讨论如何利用这些服务建立一个集中式的文档存储。
- en: Once all the documents are in a centralized storage service such as Amazon S3,
    which is a scalable and durable object store similar to Dropbox, we can use *Amazon
    Textract* as covered in [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)*,*
    *Introducing Amazon Textract,* to extract text from these documents, and use *Amazon
    Comprehend* as covered in [*Chapter 3*](B17528_03_Final_SB_ePub.xhtml#_idTextAnchor049)*,*
    *Introducing Amazon Comprehend,* to extract NLP-based insights such as entities,
    keywords, sentiments, and more. Moreover, we can then quickly index the insights
    and the text and send it to Amazon Elasticsearch or Amazon Kendra to set up a
    smart search solution.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有文档都存储在像 Amazon S3 这样的集中存储服务中，Amazon S3 是一种可扩展、耐用的对象存储，类似于 Dropbox，我们可以使用
    *Amazon Textract*（如在 [*第 2 章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)
    中介绍的）提取这些文档中的文本，并使用 *Amazon Comprehend*（如在 [*第 3 章*](B17528_03_Final_SB_ePub.xhtml#_idTextAnchor049)
    中介绍的）提取基于 NLP 的洞察，如实体、关键词、情感等。此外，我们可以快速对这些洞察和文本进行索引，并将其发送到 Amazon Elasticsearch
    或 Amazon Kendra，以建立智能搜索解决方案。
- en: 'The following diagram shows the architecture we will cover in this section:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了我们将在本节中讨论的架构：
- en: '![Figure 5.1 – Creating an NLP-powered search index'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.1 – 创建基于 NLP 的搜索索引'
- en: '](img/B17528_05_01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_05_01.jpg)'
- en: Figure 5.1 – Creating an NLP-powered search index
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1 – 创建基于 NLP 的搜索索引
- en: 'In *Figure 5.1*, you can see the two options we have to build a search index.
    The options are as follows:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 5.1* 中，你可以看到我们构建搜索索引的两种选项，具体如下：
- en: Using Amazon Elasticsearch to build a search on top of your document processing
    pipeline with Amazon Textract and Amazon Comprehend
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Amazon Elasticsearch 在基于 Amazon Textract 和 Amazon Comprehend 的文档处理管道上构建搜索
- en: Using Amazon Kendra to build a serverless intelligent search on top of your
    existing document processing pipeline with Amazon Textract and Amazon Comprehend
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Amazon Kendra 在现有的基于 Amazon Textract 和 Amazon Comprehend 的文档处理管道上构建无服务器的智能搜索
- en: If you are looking for a natural language-based search solution powered by ML
    where you can ask human-like questions rather than searching for keywords, you
    can choose Amazon Kendra for the search, as Amazon Kendra is an AWS AI service
    powered by ML. Amazon Kendra offers natural language search functionality and
    will provide you with NLP-based answers, meaning human-like contextual answers.
    For example, imagine you are setting up the search function on your IT support
    documents in Salesforce. Using Amazon Kendra you can ask direct questions such
    as *"where is the IT desk located?"* and Amazon Kendra will give you an exact
    response, such as "*the sixth floor*," whereas in Amazon Elasticsearch you can
    only perform keyword-based search.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在寻找基于自然语言的搜索解决方案，且该解决方案由机器学习驱动，让你能够提问类似人类的问题，而不是只进行关键词搜索，你可以选择 Amazon Kendra
    进行搜索，因为 Amazon Kendra 是一个由机器学习驱动的 AWS AI 服务。Amazon Kendra 提供自然语言搜索功能，并将为你提供基于自然语言处理（NLP）的答案，也就是说，提供类似人类的上下文答案。例如，假设你正在为
    Salesforce 中的 IT 支持文档设置搜索功能。使用 Amazon Kendra，你可以直接提问诸如 *“IT 服务台在哪里？”* 这样的问题，Amazon
    Kendra 会给出精确的回答，比如 "*在六楼*"，而在 Amazon Elasticsearch 中，你只能进行基于关键词的搜索。
- en: Moreover, you can also integrate Amazon Kendra into Amazon Lex, which is a service
    to create chatbots. You can deploy a smart search chatbot on your website powered
    by Amazon Lex and Amazon Kendra. Also, Amazon Kendra comes with a lot of connectors
    to discover and index your data for search, including Amazon S3, OneDrive, Google
    Drive, Salesforce, relational databases such as RDS, and many more supported by
    third-party vendors.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还可以将 Amazon Kendra 集成到 Amazon Lex 中，后者是一个用于创建聊天机器人的服务。你可以在网站上部署由 Amazon
    Lex 和 Amazon Kendra 提供支持的智能搜索聊天机器人。Amazon Kendra 还提供了大量连接器，能够发现并索引你的数据进行搜索，包括
    Amazon S3、OneDrive、Google Drive、Salesforce、RDS 等关系型数据库，以及许多第三方供应商支持的其他平台。
- en: You can set up a search on many different interesting use cases, for example,
    for financial analysts searching for financial events, as they have to scroll
    through tons of SEC filing reports and look for meaningful financial entities
    such as mergers and acquisitions. Using the proposed pipeline along with Amazon
    Comprehend Events can easily reduce the time and noise while scrolling through
    these documents and update their financial models in case of any financial events
    such as mergers or acquisitions.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在许多不同的有趣用例中设置搜索功能，例如，财务分析师在寻找财务事件时，通常需要浏览大量的 SEC 文件报告，查找有意义的财务实体，如并购事件。使用提议的流程管道以及
    Amazon Comprehend Events，可以轻松减少浏览这些文档时的时间和噪音，并在出现财务事件（如并购）时及时更新他们的财务模型。
- en: For healthcare companies, they can use the set of services and options offered
    by Amazon Comprehend Medical to create a smart search for healthcare data, where
    a doctor can log in and search for relevant keywords or information from the centralized
    patient data in Amazon HealthLake. We will cover more on this use case in this
    chapter.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对于医疗保健公司，他们可以利用 Amazon Comprehend Medical 提供的一整套服务和选项来创建智能搜索，医生可以登录并从 Amazon
    HealthLake 中集中管理的患者数据中搜索相关的关键词或信息。本章将进一步介绍这一用例。
- en: We all know finding jobs is extremely difficult. It's harder even for talent
    acquisition companies hunting for good candidates to search for relevant skills
    across thousands of resumes. You can use the proposed solution to set up a resume
    processing pipeline where you can upload the resumes of various candidates in
    Amazon S3 and search for relevant skills based on the jobs you are looking for.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都知道找工作非常困难。对于猎头公司来说，要在成千上万的简历中寻找合适的候选人和相关技能更是难上加难。你可以使用提出的解决方案，建立一个简历处理流水线，将不同候选人的简历上传到Amazon
    S3，并根据你所寻找的职位要求，搜索相关技能。
- en: In this section, we covered two options with which to set up smart search indexes.
    In the next section, we will show you how you can set up this architecture to
    create an NLP-powered search application where **Human Resources** (**HR**) admin
    users can quickly upload candidates' scanned resumes and other folks can log in
    and search for relevant skill sets based on open job positions.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了两种设置智能搜索索引的选项。在下一节中，我们将展示如何设置此架构，创建一个 NLP 驱动的搜索应用程序，在这个应用程序中，**人力资源**（**HR**）管理员用户可以快速上传候选人的扫描简历，其他用户可以登录并根据职位空缺搜索相关的技能集。
- en: Building a search solution for scanned images using Amazon Elasticsearch
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon Elasticsearch 构建扫描图像搜索解决方案
- en: In the previous chapters, we spoke about how you can use Amazon Lambda functions
    to create a serverless application. In this section, we will walk you through
    the following architecture to set up a scanned image-based search solution by
    calling the Amazon Textract and Amazon Comprehend APIs using an Amazon Lambda
    function. We are going to use Amazon Elasticsearch for this use case. However,
    you can also replace Amazon Elasticsearch with Amazon Kendra to create an ML-based
    search solution where you can use natural language to ask questions while searching.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们讨论了如何使用 Amazon Lambda 函数创建一个无服务器应用程序。在本节中，我们将通过以下架构，带你一步步建立一个基于扫描图像的搜索解决方案，通过
    Amazon Lambda 函数调用 Amazon Textract 和 Amazon Comprehend APIs。我们将为此用例使用 Amazon Elasticsearch。不过，你也可以将
    Amazon Elasticsearch 替换为 Amazon Kendra，以创建一个基于 ML 的搜索解决方案，在其中你可以使用自然语言提问进行搜索。
- en: '![Figure 5.2 – Building NLP search using Amazon Elasticsearch'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.2 – 使用 Amazon Elasticsearch 构建 NLP 搜索'
- en: '](img/B17528_05_02.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_05_02.jpg)'
- en: Figure 5.2 – Building NLP search using Amazon Elasticsearch
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 – 使用 Amazon Elasticsearch 构建 NLP 搜索
- en: The AWS service used in the previous architecture is **Amazon Cognito** to set
    up the login for your backend users.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的架构中使用的 AWS 服务是**Amazon Cognito**，用于设置后台用户的登录。
- en: Amazon S3 is used for centralized storage. Amazon Lambda functions are used
    as serverless event triggers when the scanned resumes are uploaded to Amazon S3,
    and then we use both Amazon Textract and Amazon Comprehend to extract text and
    insights such as key phrases and entities. Then we index everything into Amazon
    Elasticsearch. Your end users can log in through Cognito, and will access Amazon
    Elasticsearch through a Kibana dashboard that comes integrated with Amazon Elasticsearch
    for visualization.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon S3 用于集中存储。Amazon Lambda 函数作为无服务器事件触发器，在扫描的简历上传到 Amazon S3 后触发，然后我们使用
    Amazon Textract 和 Amazon Comprehend 提取文本和洞察信息，如关键短语和实体。接着我们将所有数据索引到 Amazon Elasticsearch。最终用户可以通过
    Cognito 登录，并通过与 Amazon Elasticsearch 集成的 Kibana 仪表盘进行可视化访问 Amazon Elasticsearch。
- en: Prerequisites
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 先决条件
- en: 'We will use an AWS CloudFormation template to spin up the resources needed
    for this chapter. CloudFormation templates are scripts written in YAML or JSON
    format to spin up resources or **Infrastructure as Code** (**IaC**). AWS CloudFormation
    templates write IaC and set all the necessary permissions for you:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 AWS CloudFormation 模板来启动本章所需的资源。CloudFormation 模板是以 YAML 或 JSON 格式编写的脚本，用于启动资源或**基础设施即代码**（**IaC**）。AWS
    CloudFormation 模板编写 IaC，并为你设置所有必要的权限：
- en: Click [https://forindexing.s3.eu-west-1.amazonaws.com/template-export-textract.yml](https://forindexing.s3.eu-west-1.amazonaws.com/template-export-textract.yml)
    to download and deploy an AWS CloudFormation template.![Figure 5.3 – CloudFormation
    template stack
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击[https://forindexing.s3.eu-west-1.amazonaws.com/template-export-textract.yml](https://forindexing.s3.eu-west-1.amazonaws.com/template-export-textract.yml)下载并部署AWS
    CloudFormation模板。![图5.3 – CloudFormation模板堆栈
- en: '](img/B17528_05_03.jpg)'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_03.jpg)'
- en: Figure 5.3 – CloudFormation template stack
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.3 – CloudFormation模板堆栈
- en: Scroll down to `documentsearchapp` for **DOMAINNAME** as shown in the following
    screenshot:![Figure 5.4 – Enter parameters
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动到`documentsearchapp`，并找到如以下截图所示的**DOMAINNAME**:![图5.4 – 输入参数
- en: '](img/B17528_05_04.jpg)'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_04.jpg)'
- en: Figure 5.4 – Enter parameters
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.4 – 输入参数
- en: Scroll down and check all three acknowledgments under **Capabilities and transforms**,
    then click **Create stack**.![Figure 5.5 – The Capabilities and transforms section
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动并勾选**Capabilities and transforms**下的所有三个确认框，然后点击**Create stack**。![图5.5
    – Capabilities and transforms部分
- en: '](img/B17528_05_05.jpg)'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_05.jpg)'
- en: Figure 5.5 – The Capabilities and transforms section
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.5 – Capabilities and transforms部分
- en: You will see your stack creation in progress. Wait till it's completed as shown
    in the following screenshot – you can refresh to see the changing status. It might
    take 20 minutes to deploy this stack so go grab a quick coffee:![Figure 5.6 –
    CloudFormation resources creation complete](img/B17528_05_06.jpg)
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将看到堆栈创建过程正在进行中。请等待直到完成，像下面的截图所示——您可以刷新页面以查看状态的变化。部署此堆栈可能需要20分钟，趁此机会去喝杯咖啡吧:![图5.6
    – CloudFormation资源创建完成](img/B17528_05_06.jpg)
- en: Figure 5.6 – CloudFormation resources creation complete
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.6 – CloudFormation资源创建完成
- en: 'Note:'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意：
- en: You will get an email with the login details to Cognito while your stack is
    being created. Make sure you check the same email you provided while creating
    this stack. An admin can add multiple users' email addresses through the Amazon
    Cognito console once it's deployed. Those emails can be sent to end users for
    logging in to the system once the resumes' data has been uploaded to Amazon S3.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在您的堆栈创建过程中，您将收到一封包含Cognito登录详细信息的电子邮件。请确保检查在创建此堆栈时提供的相同电子邮件。管理员可以在部署后通过Amazon
    Cognito控制台添加多个用户的电子邮件地址。这些电子邮件可以发送给最终用户，在将简历数据上传到Amazon S3后，用户可以登录系统。
- en: Go to the **Outputs** tab, and scroll down to the **Outputs** section.![Figure
    5.7 – CloudFormation outputs
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到**Outputs**标签页，向下滚动到**Outputs**部分。![图5.7 – CloudFormation输出
- en: '](img/B17528_05_07.jpg)'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_07.jpg)'
- en: Figure 5.7 – CloudFormation outputs
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.7 – CloudFormation输出
- en: Copy the values for **S3KeyPhraseBucket** and **KibanaLoginURL** from the **Value**
    section. We are going to use these links for this section while walking through
    this app.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从**Value**部分复制**S3KeyPhraseBucket**和**KibanaLoginURL**的值。我们将在本节中使用这些链接，逐步指导您操作此应用程序。
- en: Now you have set up up the infrastructure, including an Amazon S3 bucket, Lambda
    functions, the Cognito login, Kibana, and the Amazon Elasticsearch cluster using
    CloudFormation. You have the output from CloudFormation for your S3 bucket and
    Kibana dashboard login URLs. In the next section, we will walk you through how
    you can upload scanned images to interact with this application as an admin user.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经通过CloudFormation设置了基础设施，包括Amazon S3桶、Lambda函数、Cognito登录、Kibana以及Amazon
    Elasticsearch集群。您已经获得了CloudFormation的输出，其中包含S3桶和Kibana仪表板登录的URL。在接下来的部分中，我们将向您展示如何将扫描的图像上传到此应用程序，并以管理员身份进行交互。
- en: Uploading documents to Amazon S3
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 上传文档到Amazon S3
- en: 'We''ll start with the following steps for uploading documents to Amazon S3:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将开始以下步骤来上传文档到Amazon S3:'
- en: Click on the S3 link copied from the CloudFormation template output in the previous
    section. Then download the sample resume at [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/resume_sample.PNG](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/resume_sample.PNG),
    and upload it in S3 by clicking on the **Upload** button followed by **Add files**.![Figure
    5.8 – Scanned image in Amazon S3
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击从上一节CloudFormation模板输出中复制的S3链接。然后，下载[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/resume_sample.PNG](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/resume_sample.PNG)中的示例简历，并通过点击**Upload**按钮，再点击**Add
    files**上传到S3。![图5.8 – Amazon S3中的扫描图像
- en: '](img/B17528_05_08.jpg)'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_08.jpg)'
- en: Figure 5.8 – Scanned image in Amazon S3
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.8 – Amazon S3中的扫描图像
- en: This upload triggers an Amazon S3 event notification to the AWS Lambda function.
    To check that, go to the **Properties** tab and then scroll down to **Event notifications**
    as shown in the following screenshot:![Figure 5.9 – S3 event notifications to
    notify the AWS Lambda function
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个上传触发了一个 Amazon S3 事件通知到 AWS Lambda 函数。要检查此项，请转到**属性**标签页，然后滚动到**事件通知**，如下截图所示：![图
    5.9 – S3 事件通知以通知 AWS Lambda 函数
- en: '](img/B17528_05_09.jpg)'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_09.jpg)'
- en: Figure 5.9 – S3 event notifications to notify the AWS Lambda function
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.9 – S3 事件通知以通知 AWS Lambda 函数
- en: Click on the Lambda function link shown under **Destination**. We will inspect
    this Lambda function in the next section.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**目标**下显示的 Lambda 函数链接。我们将在下一节中检查这个 Lambda 函数。
- en: We have uploaded the sample scanned resume to Amazon S3, and also showed you
    where you can find the S3 event notifications that trigger a Lambda function.
    In the next section, let's explore what is happening in the Lambda function.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已将示例扫描简历上传到 Amazon S3，并且还向你展示了在哪里可以找到触发 Lambda 函数的 S3 事件通知。在下一节中，让我们一起探索 Lambda
    函数中发生了什么。
- en: Inspecting the AWS Lambda function
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查 AWS Lambda 函数
- en: In this section, we will inspect the code blocks of AWS Lambda and the API calls
    made to Amazon Textract and Amazon Comprehend along with Amazon Elasticsearch.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将检查 AWS Lambda 的代码块以及对 Amazon Textract 和 Amazon Comprehend 的 API 调用，并结合使用
    Amazon Elasticsearch。
- en: '![Figure 5.10 – AWS Lambda function'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.10 – AWS Lambda 函数'
- en: '](img/B17528_05_10.jpg)'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_05_10.jpg)'
- en: Figure 5.10 – AWS Lambda function
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 – AWS Lambda 函数
- en: 'The deployment code is too large for this function to show up in this AWS Lambda
    console. You can access the code through through the following GitHub repo instead,
    at [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/lambda/index.py](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/lambda/index.py):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 部署代码过于庞大，无法在此 AWS Lambda 控制台中显示。你可以通过以下 GitHub 仓库访问代码：[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/lambda/index.py](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/lambda/index.py)：
- en: 'First, we are getting the files through Amazon S3 events as shown in the following
    code block from the main Lambda handler. In Lambda, all code blocks are executed
    from this main handler. The `handler` method is invoked by Lambda for each function
    invocation and acts as an entry point. The code outside the handler contains functions
    that can be called from the main handler and some global variables:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们通过 Amazon S3 事件获取文件，如下所示是来自主 Lambda 处理程序的代码块。在 Lambda 中，所有代码块都从这个主处理程序执行。`handler`
    方法会在每次函数调用时由 Lambda 调用，作为入口点。处理程序外的代码包含可以从主处理程序调用的函数以及一些全局变量：
- en: '[PRE0]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following code downloads the file from Amazon S3 to process it with Textract
    and Comprehend:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码从 Amazon S3 下载文件，以便使用 Textract 和 Comprehend 进行处理：
- en: '[PRE1]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After getting the objects or scanned resumes from S3 events and reading through
    a Lambda function, we will call the Amazon Textract AnalyzeDocument API, a real-time
    API to extract the text, using the following code:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在通过 S3 事件获取对象或扫描简历并通过 Lambda 函数读取后，我们将调用 Amazon Textract AnalyzeDocument API，这是一个实时
    API，用于提取文本，代码如下：
- en: '[PRE2]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will parse the response to extract the lines of text to be sent to Amazon
    Comprehend:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将解析响应，提取要发送到 Amazon Comprehend 的文本行：
- en: '[PRE3]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Once we have extracted text, we will call the Comprehend Keyphrase API by putting
    it in a list variable to be indexed later:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦提取了文本，我们将通过将其放入列表变量中调用 Comprehend Keyphrase API，以便稍后进行索引：
- en: '[PRE4]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now we will extract entities using the Comprehend DetectEntities API and save
    it in a map data structure variable to be indexed later:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将使用 Comprehend DetectEntities API 提取实体，并将其保存在映射数据结构变量中，以便稍后进行索引：
- en: '[PRE5]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now we will create an Amazon S3 URL to be indexed:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将创建一个要进行索引的 Amazon S3 URL：
- en: '[PRE6]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We have the text, keyphrases, and entities, as well as the S3 link of the uploaded
    document. Now we will index it all and upload it in Elasticsearch:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们已经获取了文本、关键词和实体，以及上传文档的 S3 链接。接下来，我们将对其进行索引并上传到 Elasticsearch：
- en: '[PRE7]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Note:'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意：
- en: In case the resumes have tables or forms, we have prepared to index them as
    well. Moreover, this solution can also be used for **invoice search.**
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果简历中包含表格或表单，我们已经准备好对它们进行索引。此外，这个解决方案还可以用于**发票搜索**。
- en: In this section, we walked you through how you can extract text and insights
    from the documents uploaded to Amazon S3\. We also indexed the data into Amazon
    Elasticsearch. In the next section, we will walk you through how you can log in
    to Kibana using your admin login email setup while creating CloudFormation templates
    and visualize the data in the Kibana dashboard.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们向您展示了如何从上传到 Amazon S3 的文档中提取文本和洞察。我们还将数据索引到 Amazon Elasticsearch 中。在接下来的部分，我们将向您展示如何使用您在创建
    CloudFormation 模板时设置的管理员登录邮件登录 Kibana，并在 Kibana 仪表板中可视化数据。
- en: Searching for and discovering data in the Kibana console
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Kibana 控制台中搜索并发现数据
- en: In this section, we will cover how you can sign up to Kibana through Amazon
    Cognito by using the email you entered as the admin while deploying the resources
    through AWS CloudFormation. Then we will walk you through how you can set up your
    index in Kibana. We will cover how you can discover and search the data in the
    Kibana dashboard based on entity, keyword, and table filters from Amazon Comprehend.
    Lastly, you can download the searched resume link from Amazon S3.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讲解如何通过 Amazon Cognito 使用您在通过 AWS CloudFormation 部署资源时输入的管理员电子邮件来注册 Kibana。然后，我们将向您展示如何在
    Kibana 中设置索引。我们还将展示如何根据来自 Amazon Comprehend 的实体、关键词和表格过滤器在 Kibana 仪表板中发现和搜索数据。最后，您可以从
    Amazon S3 下载搜索到的简历链接。
- en: We will cover walkthroughs including signing up to the Kibana console, making
    the index discoverable for the search functionality, and searching for insights
    in Kibana.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将包括 Kibana 控制台的注册过程、使索引可被搜索功能发现，以及如何在 Kibana 中搜索洞察。
- en: Signing up to the Kibana console
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注册 Kibana 控制台
- en: 'In these steps, we will walk you through how you can log in to Kibana using
    the CloudFormation-generated output link:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些步骤中，我们将向您演示如何使用 CloudFormation 生成的输出链接登录 Kibana：
- en: Click on the Kibana login link you got from the CloudFormation output as shown
    in the following screenshot:![Figure 5.11 – CloudFormation output – Kibana URL
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击您从 CloudFormation 输出中获得的 Kibana 登录链接，如以下截图所示：![图 5.11 – CloudFormation 输出
    – Kibana URL](img/B17528_05_11.jpg)
- en: '](img/B17528_05_11.jpg)'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_11.jpg)'
- en: Figure 5.11 – CloudFormation output – Kibana URL
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.11 – CloudFormation 输出 – Kibana URL
- en: This link will redirect you to this console:![Figure 5.12 – Kibana sign-in dialog
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 该链接将把您重定向到此控制台：![图 5.12 – Kibana 登录对话框](img/B17528_05_12.jpg)
- en: '](img/B17528_05_12.jpg)'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_12.jpg)'
- en: Figure 5.12 – Kibana sign-in dialog
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.12 – Kibana 登录对话框
- en: 'Note:'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意：
- en: You can sign up additional end users using the **Sign up** button shown in the
    previous screenshot.
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以通过点击前一截图中显示的**注册**按钮来注册更多的终端用户。
- en: You should have got an email with a username and temporary password – enter
    those details in the preceding dialog, and click on **Sign in**.![Figure 5.13
    – Verification and password login email
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您应该已收到一封包含用户名和临时密码的电子邮件 – 在前面的对话框中输入这些信息，然后点击**Sign in**。![图 5.13 – 验证和密码登录邮件](img/B17528_05_13.jpg)
- en: '](img/B17528_05_13.jpg)'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_13.jpg)'
- en: Figure 5.13 – Verification and password login email
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.13 – 验证和密码登录邮件
- en: It will ask you to change your password the first time you sign in. After changing
    your password, you will be redirected to the Kibana console.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一次登录时，系统会要求您更改密码。更改密码后，您将被重定向到 Kibana 控制台。
- en: We have covered how to sign up for Kibana. In the next section, we will walk
    you through setting up the index in Kibana.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讲解了如何注册 Kibana。在接下来的部分，我们将向您展示如何在 Kibana 中设置索引。
- en: Making the index discoverable for the search functionality
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使索引可被搜索功能发现
- en: 'In this section, we will walk you through setting up an index in Kibana for
    searching:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向您展示如何在 Kibana 中设置索引以进行搜索：
- en: Click on **Discover** when you reach the Kibana console and we will walk you
    through setting up your index in Kibana.![Figure 5.14 – Kibana Create index pattern
    page](img/B17528_05_14.jpg)
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 到达 Kibana 控制台后，点击**Discover**，我们将引导您在 Kibana 中设置索引。![图 5.14 – Kibana 创建索引模式页面](img/B17528_05_14.jpg)
- en: Figure 5.14 – Kibana Create index pattern page
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.14 – Kibana 创建索引模式页面
- en: Enter `document` in the **Index pattern** field, as shown in the following screenshot,
    then click **Next step**:![Figure 5.15 – Define index pattern
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**Index pattern**字段中输入`document`，如以下截图所示，然后点击**Next step**：![图 5.15 – 定义索引模式](img/B17528_05_15.jpg)
- en: '](img/B17528_05_15.jpg)'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_15.jpg)'
- en: Figure 5.15 – Define index pattern
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.15 – 定义索引模式
- en: Click on **Create index pattern**. This will make your Elasticsearch index discoverable.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**Create index pattern**。这将使您的 Elasticsearch 索引可搜索。
- en: '![Figure 5.16 – Create index pattern'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.16 – 创建索引模式](img/B17528_05_16.jpg)'
- en: '](img/B17528_05_16.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_05_16.jpg)'
- en: Figure 5.16 – Create index pattern
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.16 – 创建索引模式
- en: We have created an index. Now we will start searching for insights.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经创建了索引。现在我们将开始搜索见解。
- en: Searching for insights in Kibana
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Kibana 中搜索见解
- en: 'In this section, we will walk you through searching for insights in Kibana:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将带您了解如何在 Kibana 中搜索见解：
- en: Click on **Discover** and on the left-hand side you will find entities and key
    phrases that can be added to your search filters under **Available Fields**.![Figure
    5.17 – Kibana's Discover dashboard (a)
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **Discover**，在左侧您将找到可以添加到搜索筛选器中的实体和关键词短语，位于 **可用字段** 下。![图 5.17 – Kibana
    的 Discover 仪表盘 (a)
- en: '](img/B17528_05_17.jpg)'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_17.jpg)'
- en: Figure 5.17 – Kibana's Discover dashboard (a)
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.17 – Kibana 的 Discover 仪表盘 (a)
- en: 'Let''s look at another output shown in the following screenshot:'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们看一下以下截图中的另一个输出：
- en: '![Figure 5.18 – Kibana''s Discover dashboard (b)](img/B17528_05_18.jpg)'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![图 5.18 – Kibana 的 Discover 仪表盘 (b)](img/B17528_05_18.jpg)'
- en: Figure 5.18 – Kibana's Discover dashboard (b)
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.18 – Kibana 的 Discover 仪表盘 (b)
- en: '**Entity search**: Let''s search for a candidate by date and title by adding
    the available fields of **Entity.TITLE** and **Entity.dATE** for a quick search.
    You can click on **Add a filter** and these filters will get added as seen in
    the following screenshot. You can see that it found someone with the big data
    analytics title in July 2017:![Figure 5.19 – Adding an entity filter to selected
    fields'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**实体搜索**：通过添加 **Entity.TITLE** 和 **Entity.dATE** 等可用字段，按日期和职位搜索候选人以快速查找。您可以点击
    **添加筛选器**，这些筛选器将如下面的截图所示被添加。您可以看到它找到了2017年7月具有大数据分析职称的人：![图 5.19 – 向选定字段添加实体筛选器'
- en: '](img/B17528_05_19.jpg)'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_19.jpg)'
- en: Figure 5.19 – Adding an entity filter to selected fields
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.19 – 向选定字段添加实体筛选器
- en: '**Keyword search using the keyphrases and table**: Add the **KeyPhrases** and
    **table filters** from **available fields** and you will get a table summary of
    all the skills you are looking for, along with keyphrases about the candidate.![Figure
    5.20 – Keyword and table fields search](img/B17528_05_20.jpg)'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**使用关键词和表格进行搜索**：从 **可用字段** 中添加 **关键词短语** 和 **表格筛选器**，您将获得一张汇总表，列出所有您需要的技能，以及关于候选人的关键词短语。![图
    5.20 – 关键词和表字段搜索](img/B17528_05_20.jpg)'
- en: Figure 5.20 – Keyword and table fields search
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.20 – 关键词和表字段搜索
- en: '`Amazon Sagemaker and MySQL` in the search field and see whether we have a
    candidate resume matching our needs. We are able to find a candidate resume with
    both these skills as highlighted in the following screenshot:![Figure 5.21 – Keyword
    search with AND condition'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索框中输入 `Amazon Sagemaker 和 MySQL`，查看是否有符合我们需求的候选人简历。我们能够找到一份同时具备这两项技能的候选人简历，如下图所示：![图
    5.21 – 使用 AND 条件的关键词搜索
- en: '](img/B17528_05_21.jpg)'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_21.jpg)'
- en: Figure 5.21 – Keyword search with AND condition
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.21 – 使用 AND 条件的关键词搜索
- en: '**Downloading the resume of the candidate matched**: We can download the resume
    of the matched candidate by adding an S3 link on **selected fields** as follows:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**下载匹配候选人简历**：我们可以通过在 **选定字段** 上添加 S3 链接来下载匹配候选人的简历，如下所示：'
- en: '![Figure 5.22 – S3 link to download the resume'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.22 – 下载简历的 S3 链接'
- en: '](img/B17528_05_22.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_05_22.jpg)'
- en: Figure 5.22 – S3 link to download the resume
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.22 – 下载简历的 S3 链接
- en: In this section, we gave you an architecture overview of the search solution
    for scanned images where an admin user uploads the scanned documents in Amazon
    S3, and then showed how to sign up for the Kibana dashboard and search for keywords
    to gain meaningful insights from the scanned documents.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们为您提供了扫描图像搜索解决方案的架构概述，其中管理员用户将扫描的文档上传到 Amazon S3，然后展示了如何注册 Kibana 仪表盘并搜索关键词，从扫描文档中获取有意义的见解。
- en: We walked you through the steps to set up the architecture using AWS CloudFormation
    template one-click deploy, and you can check the *Further reading* section to
    learn more about how to create these templates. We also showed how you can interact
    with this application by uploading some sample documents. We guided you on how
    to set up the Kibana dashboard and provide some sample queries to gain insights
    from the keywords and entities as filters.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经带您完成了使用 AWS CloudFormation 模板一键部署架构的步骤，您可以查看 *进一步阅读* 部分，了解如何创建这些模板。我们还展示了如何通过上传一些示例文档与此应用程序进行交互。我们指导您如何设置
    Kibana 仪表盘，并提供了一些示例查询，以便通过关键词和实体作为筛选条件获得见解。
- en: In the next section, we will explore a Kendra-powered search solution. Let's
    get started exploring Amazon Kendra and what you can uncover by using it to power
    Textract and Comprehend in your document processing workflows.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将探索一个基于Kendra的搜索解决方案。让我们开始探索Amazon Kendra，以及如何通过使用它为Textract和Comprehend提供支持，来加速文档处理工作流。
- en: Setting up an enterprise search solution using Amazon Kendra
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Amazon Kendra设置企业级搜索解决方案
- en: In this section, we will cover how you can quickly create an end-to-end serverless
    document search application using Amazon Kendra.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将介绍如何使用Amazon Kendra快速创建一个端到端的无服务器文档搜索应用。
- en: In this section, we will cover the steps to get started.
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 本节将介绍开始使用的步骤。
- en: Git cloning the notebook
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Git克隆笔记本
- en: We will walk through the steps to git clone the notebook and show code samples
    to set up the kendra based search architecture using simple boto3 APIs.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演示如何Git克隆笔记本，并展示如何使用简单的boto3 API设置基于Kendra的搜索架构的代码示例。
- en: In the SageMaker Jupyter notebook you set up in the previous chapters, Git clone
    [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/).
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在前面章节中设置的SageMaker Jupyter笔记本中，使用Git克隆[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/)。
- en: Go to `Chapter 05/Ch05-Kendra Search.ipynb` and start running the notebook.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往`Chapter 05/Ch05-Kendra Search.ipynb`并开始运行笔记本。
- en: 'Note:'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意：
- en: Please add Kendra IAM access to the SageMaker notebook IAM role so that you
    can call Kendra APIs through this notebook. In previous chapters, you already
    added IAM access to Amazon Comprehend and Textract APIs from the SageMaker notebook.
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请为SageMaker笔记本的IAM角色添加Kendra IAM访问权限，以便你能够通过该笔记本调用Kendra API。在前面的章节中，你已经为SageMaker笔记本添加了对Amazon
    Comprehend和Textract API的IAM访问权限。
- en: Creating an Amazon S3 bucket
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建Amazon S3存储桶
- en: We will show you how you can create a Amazon S3 bucket. We will use this bucket
    as a Kendra datasource and also to store extracted data from Amazon Textract.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将展示如何创建Amazon S3存储桶。我们将使用此存储桶作为Kendra数据源，并用于存储从Amazon Textract提取的数据。
- en: Create an Amazon S3 bucket by going to the Amazon S3 console at [https://s3.console.aws.amazon.com/s3/home?region=us-east-1](https://s3.console.aws.amazon.com/s3/home?region=us-east-1).
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过访问Amazon S3控制台[https://s3.console.aws.amazon.com/s3/home?region=us-east-1](https://s3.console.aws.amazon.com/s3/home?region=us-east-1)来创建一个Amazon
    S3存储桶。
- en: Click on the **Create bucket** button and enter any bucket name as shown in
    the following screenshot:![Figure 5.23 – Create an Amazon S3 bucket
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建存储桶**按钮，并输入任意存储桶名称，如下图所示：![图 5.23 – 创建一个Amazon S3存储桶
- en: '](img/B17528_05_23.jpg)'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_23.jpg)'
- en: Figure 5.23 – Create an Amazon S3 bucket
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.23 – 创建一个Amazon S3存储桶
- en: Scroll down and click on **Create bucket**.
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动并点击**创建存储桶**。
- en: 'Copy the created bucket name, open `Chapter 05/Ch05-Kendra Search.ipynb,` and
    paste it in the following cell in place of `''<your s3 bucket name>''` to get
    started:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制已创建的存储桶名称，打开`Chapter 05/Ch05-Kendra Search.ipynb`，并在以下单元格中将其粘贴到`'<your s3
    bucket name>'`的位置开始：
- en: '[PRE8]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We have the notebook ready and the Amazon S3 bucket created for this section's
    solution. Let's see a quick architecture walkthrough in the next section to understand
    the key components and then we will walk you through the code in the notebook
    you have set up.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好了笔记本，并且为本节的解决方案创建了Amazon S3存储桶。接下来，我们将通过快速的架构演示，帮助你了解关键组件，随后会引导你通过你已经设置的笔记本中的代码。
- en: Walking through the solution
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 演示解决方案
- en: Setting up an enterprise-level search can be hard. That's why we have Amazon
    Kendra, which can crawl data from various data connectors to create a quick and
    easy search solution. In the following architecture, we will walk you through
    how you can set up a document search when you have your PDF documents in Amazon
    S3\. We will extract the data using Amazon Textract from these PDF documents and
    send it to Amazon Comprehend to extract some key entities such as **ORGANIZATION**,
    **TITLE**, **DATE**, and so on. These entities will be used as filters while we
    sync the documents directly into Amazon Kendra for search.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 设置企业级搜索可能比较困难。这就是为什么我们有Amazon Kendra，它可以通过各种数据连接器爬取数据，快速创建简单的搜索解决方案。在接下来的架构中，我们将引导你了解如何在将PDF文档存储在Amazon
    S3中时设置文档搜索。我们将使用Amazon Textract从这些PDF文档中提取数据，并将其发送到Amazon Comprehend，以提取一些关键实体，如**组织**、**标题**、**日期**等。这些实体将作为过滤器，在我们将文档直接同步到Amazon
    Kendra进行搜索时使用。
- en: '![Figure 5.24 – Architecture for the Amazon Kendra-powered search with Textract
    and Comprehend](img/B17528_05_24.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.24 – 基于 Textract 和 Comprehend 的 Amazon Kendra 搜索架构](img/B17528_05_24.jpg)'
- en: Figure 5.24 – Architecture for the Amazon Kendra-powered search with Textract
    and Comprehend
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.24 – 基于 Textract 和 Comprehend 的 Amazon Kendra 搜索架构
- en: So, we gave you a high-level implementation architecture in the previous diagram.
    In the next section, we will walk you through how you can build this out with
    few lines of code and using the Python Boto3 APIs.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们在前面的图示中给出了一个高层次的实现架构。在下一节中，我们将向你展示如何用几行代码以及 Python Boto3 API 构建这个架构。
- en: Code walkthrough
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码讲解
- en: 'In this section, we will walk you through how you can quickly set up the proposed
    architecture:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将带你快速设置建议的架构：
- en: 'We will refer to this notebook: [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/Ch05-Kendra%20Search.ipynb](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/Ch05-Kendra%20Search.ipynb).
    The following code presents the Boto3 client setup for Comprehend, Kendra, and
    Textract APIs'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将参考这个笔记本：[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/Ch05-Kendra%20Search.ipynb](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/Ch05-Kendra%20Search.ipynb)。以下代码展示了用于
    Comprehend、Kendra 和 Textract API 的 Boto3 客户端设置。
- en: '[PRE9]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now we will upload the PDF document at [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/resume_Sample.pdf](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/resume_Sample.pdf)
    from this repo to Amazon S3.
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将从这个仓库上传 PDF 文档 [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/resume_Sample.pdf](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2005/resume_Sample.pdf)
    到 Amazon S3。
- en: 'Note:'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意：
- en: You can upload as many documents for search as you wish. For this demonstration,
    we are providing just one sample. Please feel free to play around by uploading
    your documents to Amazon S3 and generating metadata files before you start syncing
    your documents to Amazon Kendra.
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以上传任意数量的文档进行搜索。为了演示，我们只提供了一个样本。请随意上传你的文档到 Amazon S3，并在开始同步文档到 Amazon Kendra
    之前生成元数据文件。
- en: For extracting text from the PDF uploaded to Amazon S3, we will use the same
    code as we used for the asynchronous processing covered in [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)*,
    Introducing Amazon Textract*.
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了从上传到 Amazon S3 的 PDF 中提取文本，我们将使用与在[*第 2 章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)中处理异步过程相同的代码，*介绍
    Amazon Textract*。
- en: 'The following code shows text extraction from Amazon Textract:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码展示了如何从 Amazon Textract 提取文本：
- en: '[PRE10]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The sample results shown in the following screenshot contain the text from
    the PDF:'
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下屏幕截图展示了从 PDF 中提取的文本：
- en: '![Figure 5.25 – Extracted text response from Amazon Textract for the resume
    data'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.25 – 从 Amazon Textract 提取的简历数据文本响应](img/B17528_05_25.jpg)'
- en: '](img/B17528_05_25.jpg)'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_05_25.jpg)'
- en: Figure 5.25 – Extracted text response from Amazon Textract for the resume data
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.25 – 从 Amazon Textract 提取的简历数据文本响应
- en: 'Now we will send this text to Amazon Comprehend for entity extraction by running
    the following code:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将通过运行以下代码将文本发送到 Amazon Comprehend 进行实体提取：
- en: '[PRE11]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now we will create an Amazon Kendra index. Go to the Kendra console at https://console.aws.amazon.com/kendra/home?region=us-east-1#indexes
    and click the `Search` for **Index name**, then scroll down and click on **Create
    a new role (Recommended)**, shown highlighted in the following screenshot:![Figure
    5.26 – Create a new role for the Kendra index](img/B17528_05_26.jpg)
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将创建一个 Amazon Kendra 索引。请访问 Kendra 控制台 [https://console.aws.amazon.com/kendra/home?region=us-east-1#indexes](https://console.aws.amazon.com/kendra/home?region=us-east-1#indexes)，点击**索引名称**，然后向下滚动并点击**创建新角色（推荐）**，如下图所示：![图
    5.26 – 为 Kendra 索引创建新角色](img/B17528_05_26.jpg)
- en: Figure 5.26 – Create a new role for the Kendra index
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.26 – 为 Kendra 索引创建新角色
- en: Enter `AmazonKendra-us-east-1-kendra` as the role name and click on `AmazonKendra-us-east-1-`.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入`AmazonKendra-us-east-1-kendra`作为角色名称并点击`AmazonKendra-us-east-1-`。
- en: For **Configure user access control**, Use **tokens for access control**? select
    **No** and click **Next**.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于**配置用户访问控制**，选择**否**以表示不使用**令牌进行访问控制**，然后点击**下一步**。
- en: 'For **Specify provisioning**, choose **Developer Edition** and click on **Create**.
    Alternatively, you can run the following notebook cell after creating an IAM role
    to create the index programmatically:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于**指定配置**，选择**开发者版**，然后点击**创建**。或者，在创建IAM角色后，您可以运行以下笔记本单元格，使用编程方式创建索引：
- en: '[PRE12]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Note:'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意：
- en: Index creation can take up to 30 minutes.
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 索引创建可能需要最多30分钟。
- en: After creating the index, we need to get the index ID to run through this notebook.Once
    the index is created, click on **Index** and go to **Index Settings** to copy
    the index ID.![Figure 5.27 – Copying the Kendra index ID from the Kendra console](img/B17528_05_27.jpg)
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建索引后，我们需要获取索引ID，以便在此笔记本中运行。一旦索引创建完成，点击**索引**并进入**索引设置**以复制索引ID。![图 5.27 – 从Kendra控制台复制Kendra索引ID](img/B17528_05_27.jpg)
- en: Figure 5.27 – Copying the Kendra index ID from the Kendra console
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.27 – 从Kendra控制台复制Kendra索引ID
- en: Alternatively, if you created the index programmatically using the *CreateIndex
    API*, its response will contain an index ID of 36 digits that you need to copy
    and paste to run the next piece of code to update the search filters based on
    the Comprehend entities.
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 或者，如果您使用*CreateIndex API*编程创建了索引，其响应将包含一个36位数字的索引ID，您需要复制并粘贴该ID，然后运行下一段代码，以根据Comprehend实体更新搜索过滤器。
- en: 'Copy and paste the Kendra index ID over the placeholder in the following cell,
    then run the cell to update the index we created with filters for search. Refer
    to the notebook for the complete code to add all the filters:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将Kendra索引ID复制并粘贴到以下单元格中的占位符处，然后运行该单元格以更新我们使用过滤器进行搜索的索引。有关完整代码以添加所有过滤器，请参阅笔记本：
- en: '[PRE13]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Now we will define the list of categories recognized by Comprehend:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将定义Comprehend识别的类别列表：
- en: '[PRE14]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now we will iterate over the entities and generate a metadata file to populate
    the filters based on the entities from Amazon Comprehend:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将遍历这些实体并生成一个元数据文件，以便根据Amazon Comprehend中的实体填充过滤器：
- en: '[PRE15]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: You will get a response back detailing the Comprehend entity types and values
    detected in the text from the PDF document.![Figure 5.28 – Comprehend's extracted
    entities](img/B17528_05_28.jpg)
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将收到一个响应，详细说明从PDF文档中的文本检测到的Comprehend实体类型和值。![图 5.28 – Comprehend提取的实体](img/B17528_05_28.jpg)
- en: Figure 5.28 – Comprehend's extracted entities
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.28 – Comprehend提取的实体
- en: 'Populate the Kendra metadata list from the previous entities for Amazon Kendra
    attributes filter:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从先前的实体填充Kendra元数据列表，以便为Amazon Kendra属性过滤器使用：
- en: '[PRE16]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Take the `elimit` number of recognized text strings that have the highest frequency
    of occurrence:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择`elimit`数量的识别文本字符串，这些字符串的出现频率最高：
- en: '[PRE17]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The last step is to save this file with the `metadata.json`. Make sure the
    filename is the original PDF document filename followed by `metadata.json` in
    the Amazon S3 bucket where your PDF document is uploaded:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一步是将此文件保存为`metadata.json`。确保文件名是原始PDF文档的文件名，后面跟上`metadata.json`，并将其上传到您的PDF文档所在的Amazon
    S3存储桶中：
- en: '[PRE18]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We gave you a code walkthrough on how to upload a PDF document and extract data
    from it using Amazon Textract and then use Amazon Comprehend to extract entities.
    We then created a metadata file using the filters or entities extracted by Comprehend
    and uploaded it into Amazon S3\. In the next section, we will walk you through
    how you can set up Amazon Kendra sync with the S3 document you uploaded, and how
    you can create a `meta` folder and place your metadata files there so that Amazon
    Kendra picks them up as metadata filters during the Kendra sync.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经向您展示了如何上传PDF文档，使用Amazon Textract提取数据，然后使用Amazon Comprehend提取实体。然后，我们使用Comprehend提取的过滤器或实体创建了一个元数据文件，并将其上传到Amazon
    S3。在下一部分，我们将向您展示如何将Amazon Kendra与您上传的S3文档同步，并且如何创建一个`meta`文件夹并将您的元数据文件放置在其中，以便Amazon
    Kendra在同步时将其作为元数据过滤器。
- en: Searching in Amazon Kendra with enriched filters from Comprehend
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用来自Comprehend的增强过滤器在Amazon Kendra中进行搜索
- en: 'In this section, we will walk you through how you can sync the documents to
    the index you have created, along with the filters in the metadata file:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将向您展示如何将文档同步到您创建的索引，并同步元数据文件中的过滤器：
- en: Set the Kendra data source as the Amazon S3 bucket to which you uploaded your
    documents. Navigate to **Amazon Kendra** | **Indexes** | **<Name of the Index>**|
    **Data sources |** **Add data source |** **Amazon S3**, as shown in the following
    screenshot:![Figure 5.29 – Configuring Amazon Kendra sync](img/B17528_05_29.jpg)
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 Kendra 数据源设置为你上传文档的 Amazon S3 存储桶。导航到**Amazon Kendra** | **索引** | **<索引名称>**|
    **数据源** | **添加数据源** | **Amazon S3**，如下面的截图所示：![图 5.29 – 配置 Amazon Kendra 同步](img/B17528_05_29.jpg)
- en: Figure 5.29 – Configuring Amazon Kendra sync
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.29 – 配置 Amazon Kendra 同步
- en: Enter `s3://<your bucket name>` in the `meta/` as shown in the previous screenshot.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `meta/` 中输入 `s3://<你的存储桶名称>`，如前面的截图所示。
- en: In the `AmazonKendra-s3` in the **Role name** field.![Figure 5.30 – The run-on-demand
    schedule for Kendra](img/B17528_05_30.jpg)
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **角色名称** 字段中填写 `AmazonKendra-s3`。![图 5.30 – Kendra 按需运行的计划](img/B17528_05_30.jpg)
- en: Figure 5.30 – The run-on-demand schedule for Kendra
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.30 – Kendra 按需运行的计划
- en: Then set the frequency for the sync run schedule to be **Run on demand** and
    click **Next**.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后将同步运行计划的频率设置为**按需运行**，并点击**下一步**。
- en: Click on **Review** + Cr**eate**.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **审核** + **创建**。
- en: After your data source has been created, click on **Sync now**.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据源创建后，点击 **立即同步**。
- en: Once the sync is successful, all your documents in Amazon S3 will be synced
    and the Kendra filters will be populated with the metadata attributes extracted
    by Amazon Comprehend.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦同步成功，所有你在 Amazon S3 中的文档将被同步，Kendra 过滤器将填充由 Amazon Comprehend 提取的元数据属性。
- en: In the next section, we will walk you through how you can navigate to the Amazon
    Kendra console to search.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将带你了解如何导航到 Amazon Kendra 控制台进行搜索。
- en: Searching in Amazon Kendra
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Amazon Kendra 中进行搜索
- en: Amazon Kendra comes with a built-in search UI that can be used for testing the
    search functionality.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Kendra 附带一个内置的搜索 UI，可用于测试搜索功能。
- en: You can also deploy this UI in a React app after testing. The page at [https://docs.aws.amazon.com/kendra/latest/dg/deploying.html](https://docs.aws.amazon.com/kendra/latest/dg/deploying.html)
    has the deployment UI code available, which can be integrated with any serverless
    application using API Gateway and Lambda.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 测试后，你还可以在 React 应用中部署此 UI。页面 [https://docs.aws.amazon.com/kendra/latest/dg/deploying.html](https://docs.aws.amazon.com/kendra/latest/dg/deploying.html)
    提供了部署 UI 的代码，可以与任何使用 API Gateway 和 Lambda 的无服务器应用程序集成。
- en: You can also use the `Kendra.query()` API to retrieve results from the index
    you created in Kendra.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用 `Kendra.query()` API 从你在 Kendra 中创建的索引中检索结果。
- en: 'In this section, we will walk you through using the built-in Kendra search
    console:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将带你了解如何使用内置的 Kendra 搜索控制台：
- en: Navigate to `person with cloud skills` in the search field:![Figure 5.31 – Kendra
    query results](img/B17528_05_31.jpg)
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索框中导航到 `具有云技能的人员`：![图 5.31 – Kendra 查询结果](img/B17528_05_31.jpg)
- en: Figure 5.31 – Kendra query results
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.31 – Kendra 查询结果
- en: Amazon Kendra is able to give you a contextual answer containing Jane Doe, whose
    resume we indexed.
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Amazon Kendra 能够提供包含简历中 Jane Doe 的上下文答案，我们已将其简历索引。
- en: It also provides you with filters based on Comprehend entities on the left-hand
    side to quickly sort individuals based on entities such as **ORGANIZATION**, **TITLE**,
    **DATE**, and their word count frequencies.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 它还为你提供基于 Comprehend 实体的过滤器，位于左侧，可以根据 **组织**、**职位**、**日期** 等实体以及它们的词频快速对个人进行排序。
- en: You can also create *Comprehend custom entities*, as we covered in [*Chapter
    4*](B17528_04_Final_SB_ePub.xhtml#_idTextAnchor063)*, Automated Document Processing
    Workflows*, to enrich your metadata filters based on your business needs.
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你还可以创建 *Comprehend 自定义实体*，正如我们在 [*第 4 章*](B17528_04_Final_SB_ePub.xhtml#_idTextAnchor063)*
    自动化文档处理工作流* 中介绍的那样，依据你的业务需求丰富你的元数据过滤器。
- en: Next, type the `person with 10 years of experience` query into the Kendra Search
    console.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在 Kendra 搜索控制台中输入 `具有 10 年经验的人员` 查询。
- en: '![Figure 5.32 – Kendra query results with filters on the left from Comprehend''s
    metadata enrichment'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 5.32 – Kendra 查询结果，左侧显示 Comprehend 元数据增强的过滤器'
- en: '](img/B17528_05_32.jpg)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_05_32.jpg)'
- en: Figure 5.32 – Kendra query results with filters on the left from Comprehend's
    metadata enrichment
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.32 – Kendra 查询结果，左侧显示 Comprehend 元数据增强的过滤器
- en: Amazon Kendra is able to provide you with the exact contextual answer. You can
    also boost the response in Kendra based on relevance and provide feedback using
    the thumbs-up and thumbs-down buttons to improve your Kendra model.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Kendra 能够为你提供准确的上下文答案。你还可以根据相关性提高 Kendra 的响应，并通过点赞和点踩按钮提供反馈，改进你的 Kendra
    模型。
- en: 'Note:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：
- en: Amazon Kendra supports the use of PDF, Word, JSON, TXT, PPT, and HTML documents
    for the search functionality. Feel free to add more documents through this pipeline
    for better search results and accuracy.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Kendra 支持使用 PDF、Word、JSON、TXT、PPT 和 HTML 文档进行搜索功能。可以通过此管道添加更多文档，以提高搜索结果和准确性。
- en: Summary
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we covered two options to set up an intelligent search solution
    for your document-processing workflow. The first option involved setting up an
    NLP-based search quickly using Amazon Textract, Amazon Comprehend, and Amazon
    Elasticsearch using a Lambda function in a CloudFormation template for your scanned
    resume analysis, and can be used with anything scanned, such as images, invoices,
    or receipts. For the second option, we covered how you can set up an enterprise-level
    serverless scalable search solution with Amazon Kendra for your PDF documents.
    We also walked you through how you can enrich the Amazon Kendra search with additional
    attributes or metadata generated from Amazon Comprehend named entities.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了设置文档处理工作流的智能搜索解决方案的两种选项。第一个选项涉及快速设置基于 NLP 的搜索，使用 Amazon Textract、Amazon
    Comprehend 和 Amazon Elasticsearch，通过 Lambda 函数和 CloudFormation 模板进行扫描简历分析，并且可以用于任何扫描的内容，如图像、发票或收据。第二个选项，我们介绍了如何为您的
    PDF 文档设置一个企业级的无服务器可扩展搜索解决方案，使用 Amazon Kendra。我们还向您展示了如何利用从 Amazon Comprehend 生成的命名实体，丰富
    Amazon Kendra 搜索的额外属性或元数据。
- en: In the next chapter, we will talk about how you can use AI to improve customer
    service in your contact center.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何使用 AI 来提升联系中心的客户服务。
- en: Further reading
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: '*Building an NLP-powered search index with Amazon Textract and Amazon Comprehend*
    by Mona Mona and Saurabh Shrivastava ([https://aws.amazon.com/blogs/machine-learning/building-an-nlp-powered-search-index-with-amazon-textract-and-amazon-comprehend/](https://aws.amazon.com/blogs/machine-learning/building-an-nlp-powered-search-index-with-amazon-textract-and-amazon-comprehend/))'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用 Amazon Textract 和 Amazon Comprehend 构建 NLP 驱动的搜索索引*，作者：Mona Mona 和 Saurabh
    Shrivastava（[https://aws.amazon.com/blogs/machine-learning/building-an-nlp-powered-search-index-with-amazon-textract-and-amazon-comprehend/](https://aws.amazon.com/blogs/machine-learning/building-an-nlp-powered-search-index-with-amazon-textract-and-amazon-comprehend/)）'
- en: '*Build an intelligent search solution with automated content enrichment* by Abhinav
    Jawadekar and Udi Hershkovich ([https://aws.amazon.com/blogs/machine-learning/build-an-intelligent-search-solution-with-automated-content-enrichment/](https://aws.amazon.com/blogs/machine-learning/build-an-intelligent-search-solution-with-automated-content-enrichment/))'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*构建智能搜索解决方案与自动化内容丰富*，作者：Abhinav Jawadekar 和 Udi Hershkovich（[https://aws.amazon.com/blogs/machine-learning/build-an-intelligent-search-solution-with-automated-content-enrichment/](https://aws.amazon.com/blogs/machine-learning/build-an-intelligent-search-solution-with-automated-content-enrichment/)）'
