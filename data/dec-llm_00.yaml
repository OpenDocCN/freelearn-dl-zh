- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前言
- en: In *Decoding Large Language Models* , you will embark on a comprehensive journey,
    starting with the historical evolution of **Natural Language Processing** ( **NLP**
    ) and the development of **Large Language Models** ( **LLMs** ). The book explores
    the complex architecture of these models, making intricate concepts such as transformers
    and attention mechanisms accessible. As the journey progresses, it transitions
    into the practicalities of training and fine-tuning LLMs, providing hands-on guidance
    for real-world applications. The narrative then explores advanced optimization
    techniques and addresses the crucial aspect of ethical considerations in AI. In
    its final stages, the book offers a forward-looking perspective, preparing you
    for future developments such as GPT-5. This journey not only educates but also
    empowers you to skillfully implement and deploy LLMs in various domains.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在《解码大型语言模型》中，您将开始一段全面的旅程，从自然语言处理 (NLP) 的历史演变和大型语言模型 (LLM) 的发展开始。本书探讨了这些模型的复杂架构，使如
    Transformer 和注意力机制等复杂概念变得易于理解。随着旅程的推进，它转向了训练和微调 LLM 的实用性，为现实世界应用提供实际指导。叙述随后探讨了高级优化技术，并解决了人工智能伦理考量的关键问题。在最后阶段，本书提供了前瞻性的视角，为您应对未来如
    GPT-5 的发展做好准备。这段旅程不仅教育您，还赋予您在各个领域熟练实施和部署 LLM 的能力。
- en: By the end of this book, you will have gained a thorough understanding of the
    historical evolution and current state of LLMs in NLP. You will be proficient
    in the complex architecture of these models, including transformers and attention
    mechanisms. Your skills will extend to effectively training and fine-tuning LLMs
    for a variety of real-world applications. You will also have a strong grasp of
    advanced optimization techniques to enhance model performance. You will be well-versed
    in the ethical considerations surrounding AI, enabling you to deploy LLMs responsibly.
    Lastly, you will be prepared for emerging trends and future advancements in the
    field, such as GPT-5, equipping you to stay at the forefront of AI technology
    and its applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书结束时，您将全面了解自然语言处理 (NLP) 中 LLM 的历史演变和当前状态。您将熟练掌握这些模型的复杂架构，包括 Transformer 和注意力机制。您的技能将扩展到有效地训练和微调
    LLM 以应用于各种现实世界场景。您还将深刻理解用于提升模型性能的高级优化技术。您将熟悉围绕人工智能的伦理考量，使您能够负责任地部署 LLM。最后，您将准备好应对该领域的未来趋势和进步，例如
    GPT-5，让您能够保持在人工智能技术和其应用的前沿。
- en: Who this book is for
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 这本书面向谁
- en: If you are a technical leader working in NLP, an AI researcher, or a software
    developer interested in building AI-powered applications, this book is the essential
    guide to mastering LLMs.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您是从事 NLP 的技术领导者、人工智能研究人员或对构建人工智能应用感兴趣的软件开发人员，这本书是掌握 LLM 的必备指南。
- en: What this book covers
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书涵盖内容
- en: '[*Chapter 1*](B21242_01.xhtml#_idTextAnchor013) , *LLM Architecture* , introduces
    you to the complex anatomy of LLMs. The chapter breaks down the architecture into
    understandable segments, focusing on the cutting-edge transformer models and the
    pivotal attention mechanisms they use. A side-by-side analysis with previous RNN
    models allows you to appreciate the evolution and advantages of current architectures,
    laying the groundwork for deeper technical understanding.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第一章*](B21242_01.xhtml#_idTextAnchor013) ，*LLM 架构*，向您介绍了 LLM 的复杂结构。本章将架构分解为可理解的段落，重点关注前沿的
    Transformer 模型及其使用的关键注意力机制。与之前的 RNN 模型进行对比分析，让您欣赏当前架构的演变和优势，为更深入的技术理解打下基础。'
- en: '[*Chapter 2*](B21242_02.xhtml#_idTextAnchor036) , *How LLMs Make Decisions*
    , provides an in-depth exploration of the decision-making mechanisms in LLMs.
    It starts by examining how LLMs utilize probability and statistical analysis to
    process information and predict outcomes. Then, the chapter focuses on the intricate
    process through which LLMs interpret input and generate responses. Following this,
    the chapter discusses the various challenges and limitations currently faced by
    LLMs, including issues of bias and reliability. The chapter concludes by looking
    at the evolving landscape of LLM decision-making, highlighting advanced techniques
    and future directions in this rapidly advancing field.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第2章*](B21242_02.xhtml#_idTextAnchor036) ，*LLMs如何做决策*，深入探讨了LLMs中的决策机制。它首先考察了LLMs如何利用概率和统计分析来处理信息和预测结果。然后，本章重点介绍了LLMs解释输入并生成响应的复杂过程。随后，本章讨论了LLMs目前面临的多种挑战和限制，包括偏见和可靠性问题。本章最后展望了LLM决策的演变趋势，突出了该快速发展的领域的先进技术和未来方向。'
- en: '[*Chapter 3*](B21242_03.xhtml#_idTextAnchor058) , *The Mechanics of Training
    LLMs* , guides you through the intricate process of training LLMs, starting with
    the crucial task of data preparation and management. The chapter further explores
    the establishment of a robust training environment, delving into the science of
    hyperparameter tuning and elaborating on how to address overfitting, underfitting,
    and other common training challenges, giving you a thorough grounding in creating
    effective LLMs.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第3章*](B21242_03.xhtml#_idTextAnchor058) ，*训练LLMs的机制*，引导你了解训练LLMs的复杂过程，从数据准备和管理这一关键任务开始。本章进一步探讨了建立稳健的训练环境，深入探讨超参数调优的科学，并详细阐述如何解决过拟合、欠拟合和其他常见的训练挑战，为你创建有效的LLMs提供了全面的基础。'
- en: '[*Chapter 4*](B21242_04.xhtml#_idTextAnchor078) , *Advanced Training Strategies*
    , provides more sophisticated training strategies that can significantly enhance
    the performance of LLMs. It covers the nuances of transfer learning, the strategic
    advantages of curriculum learning, and the future-focused approaches to multitasking
    and continual learning. Each concept is solidified with a case study, providing
    real-world context and applications.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第4章*](B21242_04.xhtml#_idTextAnchor078) ，*高级训练策略*，提供了更复杂的训练策略，这些策略可以显著提高LLMs的性能。它涵盖了迁移学习的细微差别，课程学习的战略优势，以及面向未来的多任务和持续学习的方法。每个概念都通过案例研究得到巩固，提供了现实世界的背景和应用。'
- en: '[*Chapter 5*](B21242_05.xhtml#_idTextAnchor101) , *Fine-Tuning LLMs for Specific
    Applications* , teaches you the fine-tuning techniques tailored to a variety of
    NLP tasks. From the intricacies of conversational AI to the precision required
    for language translation and the subtleties of sentiment analysis, you will learn
    how to customize LLMs for nuanced language comprehension and interaction, equipping
    you with the skills to meet specific application needs.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第5章*](B21242_05.xhtml#_idTextAnchor101) ，*针对特定应用微调LLMs*，教授你针对各种NLP任务定制的微调技术。从对话AI的复杂性到语言翻译所需的精确度，以及情感分析的微妙之处，你将学习如何定制LLMs以实现细微的语言理解和交互，为你提供满足特定应用需求所需的技能。'
- en: '[*Chapter 6*](B21242_06.xhtml#_idTextAnchor140) , *Testing and Evaluating LLMs*
    , explores the crucial phase of testing and evaluating LLMs. This chapter not
    only covers the quantitative metrics that gauge performance but also stresses
    the qualitative aspects, including human-in-the-loop evaluation methods. It emphasizes
    the necessity of ethical considerations and the methodologies for bias detection
    and mitigation, ensuring that LLMs are both effective and equitable.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第6章*](B21242_06.xhtml#_idTextAnchor140) ，*测试和评估LLMs*，探讨了测试和评估LLMs的关键阶段。本章不仅涵盖了衡量性能的定量指标，还强调了定性方面，包括闭环评估方法。它强调了道德考虑的必要性，以及偏见检测和缓解的方法，确保LLMs既有效又公平。'
- en: '[*Chapter 7*](B21242_07.xhtml#_idTextAnchor162) , *Deploying LLMs in Production*
    , addresses the real-world application of LLMs. You will learn about the strategic
    deployment of these models, including tackling scalability and infrastructure
    concerns, ensuring robust security practices, and the crucial role of ongoing
    monitoring and maintenance to ensure that deployed models remain reliable and
    efficient.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第7章*](B21242_07.xhtml#_idTextAnchor162) ，*在生产中部署LLMs*，讨论了LLMs的实际应用。你将了解这些模型的战略部署，包括解决可扩展性和基础设施问题，确保稳健的安全实践，以及持续监控和维护的关键作用，以确保部署的模型保持可靠和高效。'
- en: '[*Chapter 8*](B21242_08.xhtml#_idTextAnchor183) , *Strategies for Integrating
    LLMs* , offers an insightful overview of integrating LLMs into existing systems.
    It covers the evaluation of LLM compatibility with current technologies, followed
    by strategies for their seamless integration. The chapter also delves into the
    customization of LLMs to meet specific system needs, and it concludes with a critical
    discussion on ensuring security and privacy during the integration process. This
    concise guide provides essential knowledge to effectively incorporate LLM technology
    into established systems while maintaining data integrity and system security.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第8章*](B21242_08.xhtml#_idTextAnchor183) ，*整合LLM的策略*，提供了将LLM整合到现有系统中的见解性概述。它涵盖了评估LLM与现有技术的兼容性，随后是它们无缝整合的策略。本章还深入探讨了根据特定系统需求定制LLM，并以在整合过程中确保安全和隐私为关键讨论内容。本简要指南提供了将LLM技术有效整合到现有系统中的必要知识，同时保持数据完整性和系统安全。'
- en: '[*Chapter 9*](B21242_09.xhtml#_idTextAnchor204) , *Optimization Techniques
    for Performance* , introduces advanced techniques that improve the performance
    of LLMs without sacrificing efficiency. Techniques such as quantization and pruning
    are discussed in depth, along with knowledge distillation strategies. A focused
    case study on mobile deployment gives you practical insights into applying these
    optimizations.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第9章*](B21242_09.xhtml#_idTextAnchor204) ，*性能优化技术*，介绍了不牺牲效率的先进技术，以提高LLM的性能。深入讨论了量化、剪枝等技术，以及知识蒸馏策略。一个专注于移动部署的案例研究为您提供了应用这些优化的实用见解。'
- en: '[*Chapter 10*](B21242_10.xhtml#_idTextAnchor234) , *Advanced Optimization and
    Efficiency* , dives deeper into the technical aspects of enhancing LLM performance.
    You will explore state-of-the-art hardware acceleration and learn how to manage
    data storage and representation for optimal efficiency. The chapter provides a
    balanced view of the trade-offs between cost and performance, a key consideration
    to deploy LLMs at scale.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第10章*](B21242_10.xhtml#_idTextAnchor234) ，*高级优化和效率*，更深入地探讨了提高LLM性能的技术方面。您将探索最先进的硬件加速，并学习如何管理数据存储和表示以实现最佳效率。本章提供了成本与性能之间的权衡的平衡视角，这是大规模部署LLM的关键考虑因素。'
- en: '[*Chapter 11*](B21242_11.xhtml#_idTextAnchor252) , *LLM Vulnerabilities, Biases,
    and Legal Implications* , explores the complexities surrounding LLMs, focusing
    on their vulnerabilities and biases. It discusses the impact of these issues on
    LLM functionality and the efforts needed to mitigate them. Additionally, the chapter
    provides an overview of the legal and regulatory frameworks governing LLMs, highlighting
    intellectual property concerns and the evolving global regulations. It aims to
    balance the perspectives on technological advancement and ethical responsibilities
    in the field of LLMs, emphasizing the importance of innovation aligned with regulatory
    caution.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第11章*](B21242_11.xhtml#_idTextAnchor252) ，*LLM的漏洞、偏见和法律影响*，探讨了围绕LLM的复杂性，重点关注它们的漏洞和偏见。它讨论了这些问题对LLM功能的影响以及缓解这些问题的努力。此外，本章概述了管理LLM的法律和监管框架，突出了知识产权问题和全球法规的演变。它旨在平衡LLM领域的技术进步和伦理责任的观点，强调与监管谨慎相一致的创新的重要性。'
- en: '[*Chapter 12*](B21242_12.xhtml#_idTextAnchor276) , *Case Studies – Business
    Applications and ROI* , examines the application and **return on investment**
    ( **ROI** ) of LLMs in business. It starts with their role in enhancing customer
    service, showcasing examples of improved efficiency and interaction. The focus
    then shifts to marketing, exploring how LLMs optimize strategies and content.
    The chapter then covers LLMs in operational efficiency, particularly in automation
    and data analysis. It concludes by assessing the ROI from LLM implementations,
    considering both the financial and operational benefits. Throughout these sections,
    the chapter presents a comprehensive overview of LLMs’ practical business uses
    and their measurable impacts.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第12章*](B21242_12.xhtml#_idTextAnchor276) ，*案例研究 – 商业应用和投资回报率*，探讨了LLM在商业中的应用和**投资回报率**（**ROI**）。它从它们在提升客户服务中的作用开始，展示了提高效率和互动的例子。随后，重点转向市场营销，探讨LLM如何优化策略和内容。本章接着讨论了LLM在运营效率方面的应用，特别是在自动化和数据分析方面。最后，它通过评估LLM实施的投资回报率，考虑了财务和运营效益。在这些部分中，本章全面概述了LLM的实际商业用途及其可衡量的影响。'
- en: '[*Chapter 13*](B21242_13.xhtml#_idTextAnchor308) , *The Ecosystem of LLM Tools
    and Frameworks* , explores the rich ecosystem of tools and frameworks available
    for LLMs. It offers a roadmap to navigate the various open source and proprietary
    tools and comprehensively discusses how to integrate LLMs within existing tech
    stacks. The strategic role of cloud services in supporting NLP initiatives is
    also unpacked.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第13章*](B21242_13.xhtml#_idTextAnchor308) ，*LLM工具和框架的生态系统*，探讨了为LLMs提供的丰富工具和框架生态系统。它提供了一个路线图，以导航各种开源和专有工具，并全面讨论了如何在现有技术堆栈中集成LLMs。云服务在支持NLP倡议中的战略作用也得到了详细阐述。'
- en: '[*Chapter 14*](B21242_14.xhtml#_idTextAnchor317) , *Preparing for GPT-5 and
    Beyond* , prepares you for the arrival of GPT-5 and subsequent models. It covers
    the expected features, infrastructure needs, and skillset preparations. The chapter
    also challenges you to think strategically about potential breakthroughs and how
    to stay ahead of the curve in a rapidly advancing field.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第14章*](B21242_14.xhtml#_idTextAnchor317) ，*为GPT-5及以后做准备*，为你迎接GPT-5及其后续模型做好准备。它涵盖了预期的功能、基础设施需求以及技能准备。本章还挑战你战略性地思考潜在的突破，以及如何在快速发展的领域中保持领先。'
- en: '[*Chapter 15*](B21242_15.xhtml#_idTextAnchor337) , *Conclusion and Looking
    Forward* , synthesizes the key insights gained throughout the reading journey.
    It offers a forward-looking perspective on the trajectory of LLMs, pointing you
    toward resources for continued education and adaptation in the evolving landscape
    of AI and NLP. The final note encourages you to embrace the LLM revolution with
    an informed and strategic mindset.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[*第15章*](B21242_15.xhtml#_idTextAnchor337) ，*结论与展望*，综合了阅读过程中的关键洞见。它为LLMs的发展轨迹提供了一个前瞻性的视角，指引你寻找继续教育和适应AI和NLP不断变化领域资源的途径。最后的笔记鼓励你以知情和战略性的心态拥抱LLM革命。'
- en: To get the most out of this book
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为了充分利用本书
- en: To effectively engage with *Decoding Large Language Models* , you should come
    equipped with a foundational understanding of machine learning principles, proficiency
    in a programming language such as Python, a grasp of essential mathematics such
    as algebra and statistics, and familiarity with NLP basics.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地参与《解码大型语言模型》的学习，你应该具备机器学习原理的基础知识、对Python等编程语言的熟练掌握、对代数和统计学等基本数学的掌握，以及NLP基础的了解。
- en: Conventions used
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用的约定
- en: Here are the text conventions used throughout this book.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本书通篇使用的文本约定如下。
- en: '**Code in text** : Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “This contains two basic functions: **add()** and
    **subtract()** .”'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**文本中的代码**：表示文本中的代码单词、数据库表名、文件夹名、文件名、文件扩展名、路径名、虚拟URL、用户输入和Twitter昵称。以下是一个示例：“这包含两个基本函数：**add()**
    和 **subtract()**。”'
- en: 'A block of code is set as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 代码块设置如下：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Bold** : Indicates a new term, an important word, or words that you see on
    screen. For instance, words in menus or dialog boxes appear in **bold** . Here
    is an example: “This process, known as **unsupervised learning** , does not require
    labeled data but instead relies on the patterns inherent in the text itself.”'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**粗体**：表示新术语、重要单词或屏幕上看到的单词。例如，菜单或对话框中的单词以**粗体**显示。以下是一个示例：“这个过程被称为**无监督学习**，不需要标记数据，而是依赖于文本本身固有的模式。”'
- en: Tips or important notes
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 小贴士或重要注意事项
- en: Appear like this.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来像这样。
- en: Get in touch
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 联系我们
- en: Feedback from our readers is always welcome.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们始终欢迎读者的反馈。
- en: '**General feedback** : If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](mailto:customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**一般反馈**：如果你对本书的任何方面有疑问，请通过电子邮件发送至[customercare@packtpub.com](mailto:customercare@packtpub.com)，并在邮件主题中提及书名。'
- en: '**Errata** : Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**勘误**：尽管我们已经尽一切努力确保内容的准确性，但错误仍然可能发生。如果你在这本书中发现了错误，我们非常感谢你向我们报告。请访问[www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)并填写表格。'
- en: '**Piracy** : If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](mailto:copyright@packt.com)
    with a link to the material.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**盗版**：如果您在互联网上以任何形式遇到我们作品的非法副本，如果您能提供位置地址或网站名称，我们将不胜感激。请通过[版权@packt.com](mailto:copyright@packt.com)与我们联系，并提供材料的链接。'
- en: '**If you are interested in becoming an author** : If there is a topic that
    you have expertise in and you are interested in either writing or contributing
    to a book, please visit [authors.packtpub.com](http://authors.packtpub.com) .'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果您有兴趣成为作者**：如果您在某个领域有专业知识，并且您有兴趣撰写或为书籍做出贡献，请访问[authors.packtpub.com](http://authors.packtpub.com)。'
- en: Share Your Thoughts
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分享您的想法
- en: Once you’ve read *Decoding Large Language Models* , we’d love to hear your thoughts!
    Please [click here to go straight to the Amazon review page](https://www.packtpub.com/)
    for this book and share your feedback.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您阅读了《解码大型语言模型》，我们非常乐意听到您的想法！请[点击此处直接进入此书的亚马逊评论页面](https://www.packtpub.com/)并分享您的反馈。
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 您的评论对我们和科技社区非常重要，并将帮助我们确保我们提供高质量的内容。
- en: Download a free PDF copy of this book
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载此书的免费PDF副本
- en: Thanks for purchasing this book!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您购买此书！
- en: Do you like to read on the go but are unable to carry your print books everywhere?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你喜欢在路上阅读，但无法携带你的印刷书籍到处走吗？
- en: Is your eBook purchase not compatible with the device of your choice?
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您的电子书购买是否与您选择的设备不兼容？
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 别担心，现在每购买一本Packt书籍，您都可以免费获得该书的DRM免费PDF版本。
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何地方、任何设备上阅读。直接从您最喜欢的技术书籍中搜索、复制和粘贴代码到您的应用程序中。
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 优惠远不止这些，您还可以获得独家折扣、时事通讯和每日收件箱中的精彩免费内容。
- en: 'Follow these simple steps to get the benefits:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下简单步骤获取优惠：
- en: Scan the QR code or visit the link below
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扫描下面的二维码或访问以下链接
- en: '![img](img/B21242_QR_Free_PDF.jpg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![img](img/B21242_QR_Free_PDF.jpg)'
- en: '[https://packt.link/free-ebook/978-1-83508-465-6](https://packt.link/free-ebook/978-1-83508-465-6)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/free-ebook/978-1-83508-465-6](https://packt.link/free-ebook/978-1-83508-465-6)'
- en: Submit your proof of purchase
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交您的购买证明
- en: That’s it! We’ll send your free PDF and other benefits to your email directly
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就这些！我们将直接将您的免费PDF和其他优惠发送到您的电子邮件中
- en: 'Part 1: The Foundations of Large Language Models (LLMs)'
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一部分：大型语言模型（LLMs）的基础
- en: This part provides you with an introduction to LLM architecture, including the
    anatomy of a language model, transformers and attention mechanisms, **Recurrent
    Neural Networks** ( **RNNs** ) and their limitations, and a comparative analysis
    between transformer and RNN models. It also explains decision making in LLMs,
    LLM response generation, challenges and limitations in LLM decision making, and
    advanced techniques and future directions.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分为您提供了LLM架构的介绍，包括语言模型的解剖结构、transformers和注意力机制、**循环神经网络**（**RNNs**）及其局限性，以及transformer和RNN模型之间的比较分析。它还解释了LLM中的决策制定、LLM响应生成、LLM决策中的挑战和局限性，以及高级技术和未来方向。
- en: 'This part contains the following chapters:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 1*](B21242_01.xhtml#_idTextAnchor013) , *LLM Architecture*'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第一章*](B21242_01.xhtml#_idTextAnchor013) ，*LLM架构*'
- en: '[*Chapter 2*](B21242_02.xhtml#_idTextAnchor036) , *How LLMs Make Decisions*'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第二章*](B21242_02.xhtml#_idTextAnchor036) ，*LLMs如何做决策*'
