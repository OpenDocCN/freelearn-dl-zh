- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Building the Generative AI Controller
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建生成式AI控制器
- en: 'A **generative AI system** (**GenAISys**)’s controller requires two key components:
    a **conversational agent** and an **orchestrator**. The conversational agent—powered
    by a generative AI model—interacts with human users and system processes. The
    orchestrator, on the other hand, is a set of generative AI and non-AI functions,
    such as managing user roles, content generation, activating machine learning algorithms,
    and running classical queries. We need both to build a functional GenAISys.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**生成式AI系统**（**GenAISys**）的控制器需要两个关键组件：一个**对话代理**和一个**编排器**。对话代理由生成式AI模型驱动，与人类用户和系统进程进行交互。另一方面，编排器是一组生成式AI和非AI功能，例如管理用户角色、内容生成、激活机器学习算法以及运行经典查询。我们需要这两个组件来构建一个功能性的GenAISys。
- en: If we examine this architecture closely, we’ll see that software orchestrators
    and user interfaces date back to the first computers. Any operating system, with
    even basic functionality, has orchestrators that trigger disk space alerts, memory
    usage, and hundreds of other functions. Today’s user interfaces are intuitive
    and have event-driven functionality, but at a high level, the underlying architecture
    of a GenAISys still echoes decades of software design principles. So, what sets
    a classical software controller apart from a GenAISys controller?
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们仔细检查这个架构，我们会看到软件编排器和用户界面可以追溯到第一台计算机。任何具有甚至基本功能的操作系统都有编排器，可以触发磁盘空间警报、内存使用和其他数百个功能。今天的用户界面直观且具有事件驱动功能，但在高层次上，GenAISys的底层架构仍然反映了数十年的软件设计原则。那么，什么是经典软件控制器与GenAISys控制器之间的区别呢？
- en: 'We can sum up the difference in one word: *adaptability*. In a classical software
    controller, a sequence of tasks is more or less hardcoded. But in a GenAISys,
    the user interface is a conversational AI agent that is flexible, and the generative
    AI model behind it is pre-trained to respond to a wide range of requests with
    no additional coding. Furthermore, the orchestrator isn’t locked into static flows
    either; it can modify the tasks it triggers based on the user (human or system)
    prompts.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以用一个词来总结这种差异：*适应性*。在经典软件控制器中，一系列任务或多或少是硬编码的。但在GenAISys中，用户界面是一个灵活的对话AI代理，其背后的生成式AI模型经过预训练，可以无需额外编码对广泛的请求做出响应。此外，编排器也没有锁定在静态流程中；它可以根据用户（人类或系统）的提示修改它触发的任务。
- en: In this chapter, we’ll take a hands-on approach to building a custom GenAISys
    based on the architecture of a GenAISys defined in the previous chapter. We’ll
    begin by defining the structure of our AI controller in Python, breaking it into
    two parts—the conversational agent and the orchestrator—and exploring how the
    two interact. Then, we’ll build the conversational agent using GPT-4o. We’ll automate
    the contextual awareness and memory retention features from [*Chapter 1*](Chapter_1.xhtml#_idTextAnchor021).
    Our system will support both short-term and long-term memory, as well as multi-user
    and cross-session capabilities—pushing it beyond what standard copilots typically
    offer.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将采取动手实践的方法来构建一个基于前一章中定义的GenAISys架构的定制GenAISys。我们首先将定义我们的AI控制器结构，在Python中将它分为两部分——对话代理和编排器——并探讨这两个部分如何交互。然后，我们将使用GPT-4o构建对话代理。我们将自动化从[*第1章*](Chapter_1.xhtml#_idTextAnchor021)中提到的上下文感知和记忆保持功能。我们的系统将支持短期和长期记忆，以及多用户和跨会话功能——将其推向标准共飞行员通常提供的服务之外。
- en: Finally, we will build the structure of an AI controller to interpret user input
    and trigger a response scenario. The response will be a sentiment analysis or
    a semantic (hard science) analysis, depending on the context of what the AI controller
    will analyze and manage. Our custom GenAISys will lay the groundwork for domain-specific
    RAG, something a standard ChatGPT-grade system can’t offer when you’re working
    with large volumes of data, especially in cases of daily dataset updates, such
    as the daily sales of a product or service. By the end of this chapter, you’ll
    know how to build the foundations of a GenAISys AI controller that we will enhance
    throughout the book.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将构建一个AI控制器的结构来解释用户输入并触发响应场景。响应将根据AI控制器将分析和管理的上下文进行情感分析或语义（硬科学）分析。我们的定制GenAISys将为特定领域的RAG奠定基础，这是标准ChatGPT级系统在处理大量数据时无法提供的，尤其是在每日数据集更新案例中，例如产品或服务的每日销售。到本章结束时，你将了解如何构建GenAISys
    AI控制器的基石，我们将在整本书中对其进行增强。
- en: 'To sum up, this chapter covers the following topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本章涵盖了以下主题：
- en: Architecture of the AI controller
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI 控制器的架构
- en: Architecture of an AI conversational agent and its workflow
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI 会话代理及其工作流程架构
- en: Implementing the storage of short- and long-term memory sessions in code
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在代码中实现短期和长期记忆会话的存储
- en: Architecture of an AI orchestrator and the intent functionality
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI 协调器和意图功能架构
- en: Creating a GenAI scenario library containing instruction scenarios
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个包含指令场景的 GenAI 场景库
- en: Processing an input with vector search to orchestrate instructions
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用向量搜索处理输入以协调指令
- en: Processing an input with a GPT-4o analysis to orchestrate instructions
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GPT-4o 分析处理输入以协调指令
- en: Selecting and executing tasks based on the input with the multipurpose orchestrator
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据输入使用多功能协调器选择和执行任务
- en: Let’s begin by defining the architecture of the AI controller.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义 AI 控制器的架构开始。
- en: Architecture of the AI controller
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI 控制器的架构
- en: We’ll continue to implement the architecture of GenAISys as we’ve defined in
    *Figure 1.1* from [*Chapter 1*](Chapter_1.xhtml#_idTextAnchor021). *Figure 2.1*,
    on the other hand, takes us further into the underlying functions of a GenAISys.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续按照在 *图 1.1* 中定义的架构实现 GenAISys 的架构，[第 1 章](Chapter_1.xhtml#_idTextAnchor021)。另一方面，*图
    2.1* 带我们进一步了解了 GenAISys 的底层功能。
- en: '![Figure 2.1: Defining the functions to build](img/B32304_02_1.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1：定义要构建的功能](img/B32304_02_1.png)'
- en: 'Figure 2.1: Defining the functions to build'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1：定义要构建的功能
- en: We established in the previous chapter that human roles are essential, and the
    preceding figure acknowledges that fact. We are the core of a GenAISys, no matter
    how advanced the building blocks (models or frameworks) are. Our first task is
    designing using our human creativity to find effective ways to implement a GenAISys
    controller. GenAISys needs human creativity, judgment, and technical decision-making.
    Under the hood of seamless copilots such as ChatGPT, Gemini, and Microsoft Copilot
    lie intricate layers of AI and non-AI logic. If we want to build our own ChatGPT-like
    system, we humans need to do the heavy lifting!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们确定了人类角色的必要性，前面的图也认可了这一点。无论构建块（模型或框架）多么先进，我们都是 GenAISys 的核心。我们的第一个任务是利用人类的创造力，找到有效的方法来实施
    GenAISys 控制器。GenAISys 需要人类的创造力、判断和技术决策。在 ChatGPT、Gemini 和 Microsoft Copilot 等无缝协同驾驶员的底层，隐藏着复杂的
    AI 和非 AI 逻辑层。如果我们想构建自己的 ChatGPT 类似系统，我们需要人类付出辛勤的努力！
- en: 'We will build two separate programs:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将构建两个独立的程序：
- en: A **conversational agent** implemented with GPT-4o, which supports both short-
    and long-term memory. This will help us enforce contextual awareness across multiple
    exchanges. It aligns with function **F3** in *Figure 2.1*.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GPT-4o 实现的 **会话代理**，它支持短期和长期记忆。这将帮助我们加强多个交流中的上下文意识。它与 *图 2.1* 中的功能 **F3**
    保持一致。
- en: An **AI controller orchestrator** that will also use GPT-4o to analyze the user
    input, search a library of instructions, augment the input with the appropriate
    instructions, and run the function(s) in the instructions.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 **AI 控制器协调器**，它也将使用 GPT-4o 分析用户输入，搜索指令库，用适当的指令增强输入，并运行指令中的函数（们）。
- en: 'In this chapter, we’ll focus on two scenarios: sentiment analysis and semantic
    (hard science) analysis, which correspond to functions **F1** and **F2** in our
    architecture. Functions **F4** and **F5** will be added in [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将关注两个场景：情感分析和语义（硬科学）分析，这对应于我们架构中的功能 **F1** 和 **F2**。功能 **F4** 和 **F5**
    将在第 3 章[第 3 章](Chapter_3.xhtml#_idTextAnchor085)中添加。
- en: Although these examples are built for OpenAI’s API, the logic is model-agnostic.
    Once you understand how it works, you can adapt the code to use any LLM—such as
    Meta’s Llama, xAI’s Grok, Google’s Gemini, or Cohere.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些示例是为 OpenAI 的 API 构建的，但其逻辑是模型无关的。一旦你了解了它的工作原理，你就可以将代码修改为使用任何大型语言模型（LLM），例如
    Meta 的 Llama、xAI 的 Grok、Google 的 Gemini 或 Cohere。
- en: Once we’ve built the conversational agent and controller orchestrator programs
    separately, we will merge them into a unified intelligence AI controller, as shown
    in *Figure 2.2*.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们分别构建了会话代理和控制器协调器程序，我们将它们合并成一个统一的智能 AI 控制器，如图 2.2 所示。
- en: '![Figure 2.2: Next steps—integrating the AI controller functions through a
    Pinecone vector store](img/B32304_02_2.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.2：下一步——通过 Pinecone 向量存储整合 AI 控制器功能](img/B32304_02_2.png)'
- en: 'Figure 2.2: Next steps—integrating the AI controller functions through a Pinecone
    vector store'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2：下一步——通过 Pinecone 向量存储整合 AI 控制器功能
- en: For now, we need to focus on building each component individually so we can
    fully understand their behavior. Once that foundation is in place, in [*Chapter
    3*](Chapter_3.xhtml#_idTextAnchor085), we will merge them through a Pinecone vector
    store. Let’s now dive straight down into code and begin developing the conversational
    agent.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要专注于单独构建每个组件，以便我们能够完全理解它们的行为。一旦这个基础建立起来，在 [*第 3 章*](Chapter_3.xhtml#_idTextAnchor085)
    中，我们将通过 Pinecone 向量存储将它们合并。现在让我们直接进入代码，开始开发对话代理。
- en: Conversational AI agent
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对话人工智能代理
- en: 'Our two primary goals for this section are to build a conversational AI agent
    with the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的主要目标是构建一个具有以下功能的对话人工智能代理：
- en: '**Short-term memory retention** for a full ChatGPT-like conversational loop.
    The user and agent can have as many exchanges as they wish; there is no limit
    to the number of interactions between them.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**短期记忆保留**完整的 ChatGPT 风格对话循环。用户和代理可以进行他们希望的任何数量的交换；他们之间的交互次数没有限制。'
- en: '**Long-term memory retention** across multiple users and sessions. We’ll store
    in-memory sessions and persist them to a memory storage (in this case, a text
    file). This will enable multi-user contextual awareness for users such as John,
    Myriam, and Bob. Our conversational agent will move beyond classic one-to-one
    ChatGPT-style dialogues toward a custom GenAISys capable of handling multi-session,
    multi-user interactions.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**长期记忆保留**跨越多个用户和会话。我们将存储内存中的会话并将它们持久化到内存存储（在这种情况下，是一个文本文件）。这将使用户如 John、Myriam
    和 Bob 等能够实现多用户上下文感知。我们的对话代理将超越经典的点对点 ChatGPT 风格对话，转向能够处理多会话、多用户交互的定制 GenAISys。'
- en: To get started, open `Conversational_AI_Agent.ipynb` in this chapter’s GitHub
    directory ([https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main)).
    This notebook will guide you through the environment setup.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始，请在此章节的 GitHub 目录中打开 `Conversational_AI_Agent.ipynb`（[https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main](https://github.com/Denis2054/Building-Business-Ready-Generative-AI-Systems/tree/main)）。这个笔记本将引导您完成环境设置。
- en: Setting up the environment
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置环境
- en: 'We’ll reuse the setup process from the previous chapter. If you need a refresher,
    feel free to revisit that section. Start by installing OpenAI and downloading
    the required files:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重用前一章中的设置过程。如果您需要复习，请随时查阅该部分。首先安装 OpenAI 并下载所需的文件：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We’ll also need to download two additional functions to build our conversational
    agent:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要下载两个额外的函数来构建我们的对话代理：
- en: '`download("commons","conversational_agent.py")`: This contains the functions
    to manage a full-turn conversation loop and memorize the dialogue.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`download("commons","conversational_agent.py")`：此文件包含管理完整回合对话循环和记忆对话的功能。'
- en: '`download("commons", "processing_conversations.py")`: This contains tools to
    load, display, and cleanse past conversations to increase the memory span of the
    conversational agent across several sessions and users. This custom multisession,
    multi-user feature goes beyond the scope of standard ChatGPT-like copilots.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`download("commons", "processing_conversations.py")`：此文件包含用于加载、显示和净化过去对话的工具，以增加对话代理在多个会话和用户之间的记忆跨度。这个定制的多会话、多用户功能超出了标准
    ChatGPT 风格合作者的范畴。'
- en: Let’s now move on to implementing the functions in `conversational_agent.py`,
    which we’ll call throughout our sessions with the conversational AI agent.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续在 `conversational_agent.py` 中实现函数，这是我们将在与对话人工智能代理的整个会话中使用的。
- en: Conversational AI agent workflow
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对话人工智能代理工作流程
- en: 'The conversation AI agent contains two main parts:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对话人工智能代理包含两个主要部分：
- en: Starting the initial conversation to initiate a dialogue with the AI agent
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始初始对话以与人工智能代理开始对话
- en: Running the full-turn conversation loop to continue as many in-memory exchanges
    as a user wishes with the AI agent. At the end of each session, the dialog is
    saved so it can be resumed later—by the same user or another.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行完整回合对话循环，以继续用户希望与人工智能代理进行的内存交换。在每个会话结束时，对话将被保存，以便稍后可以继续——无论是同一用户还是其他用户。
- en: Starting the initial conversation
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开始初始对话
- en: The initial conversation marks the entry point for a new session. It’s handled
    by the AI controller and illustrated in *Figure 2.3*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 初始对话是新会话的入口点。它由 AI 控制器处理，并在 *图 2.3* 中展示。
- en: '![Figure 2.3: The initial conversation controller](img/B32304_02_3.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.3：初始对话控制器](img/B32304_02_3.png)'
- en: 'Figure 2.3: The initial conversation controller'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3：初始对话控制器
- en: We will go through each step of the initial conversation with the generative
    AI model to understand in detail how a small-scale ChatGPT-like conversational
    agent works. The 10-step process begins with *Start*.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐步了解与生成式AI模型的初始对话的每个步骤，以详细了解一个小型ChatGPT-like对话代理是如何工作的。10步流程从*开始*开始。
- en: 1\. Starting the conversation
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1. 开始对话
- en: 'The program begins at this entry point through the `run_conversational_agent`
    function in `openai_api.py`, which will be called in the notebook by `conversational_agent`
    and its parameters:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 程序通过 `openai_api.py` 中的 `run_conversational_agent` 函数从这个入口点开始，该函数将在笔记本中通过 `conversational_agent`
    及其参数被调用：
- en: '[PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The parameters the conversational agent will process in this case are the following:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，对话代理将处理的参数如下：
- en: '`uinput`: Contains the input (user or system), for example, `Where is Hawaii?`.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`uinput`：包含输入（用户或系统），例如，`夏威夷在哪里？`。'
- en: '`mrole`: Defines the role of the message. It can be `user` or `system`. You
    can also assign other roles that the API will interpret, such as defining the
    AI’s persona, for example, `You are a geology expert`.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mrole`：定义消息的角色。它可以是 `用户` 或 `系统`。您还可以分配API将解释的其他角色，例如定义AI的个性，例如，`您是一位地质学专家`。'
- en: '`mcontent`: Is what we expect the system to be, for example, `You are a geology
    expert`.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mcontent`：这是我们期望系统呈现的内容，例如，`您是一位地质学专家`。'
- en: '`user_role`: Defines the role of the user, for example, `user`.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`user_role`：定义用户的角色，例如，`用户`。'
- en: '`user_name`: The name of the user, for example, `John`.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`user_name`：用户的姓名，例如，`约翰`。'
- en: 2–3\. Initializing API variables and the messages object
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2–3. 初始化API变量和消息对象
- en: '`messages_obj` is initialized with the parameters of the conversation described
    in the previous step, *Starting the conversation*:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`messages_obj` 使用上一步中描述的对话参数初始化，*开始对话*：'
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`messages_obj` is focusing on the memory of the system. This object will be
    appended as long as the session lasts with the exchanges with the GPT-4o model.
    It will be used to log conversations between sessions. The first message contains
    the role and content for setting up the agent’s context.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`messages_obj` 关注系统的记忆。此对象将在会话期间与GPT-4o模型的交流中附加。它将被用于记录会话之间的对话。第一条消息包含设置代理上下文的角色和内容。'
- en: 4\. Printing a welcome message
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4. 打印欢迎信息
- en: 'The system is now ready to interact with users. The agent first displays a
    welcome message and explains how to exit the system once the conversation is over:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 系统现在已准备好与用户互动。代理首先显示欢迎信息，并解释如何在对话结束后退出系统：
- en: '[PRE3]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 5\. Handling the initial user input
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5. 处理初始用户输入
- en: 'The user’s initial input is added to `messages_obj` to provide the agent with
    memory and provide the direction the agent is expected to follow. The initial
    user input will be sent from the conversational agent:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 用户的初始输入被添加到 `messages_obj` 中，以向代理提供记忆并提供代理预期遵循的方向。初始用户输入将由对话代理发送：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 6\. Cleansing the initial conversation log
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6. 清理初始对话日志
- en: '`messages_obj` holds the conversation’s history in a structured format. For
    certain operations within our application, such as generating a simplified display,
    creating a consolidated log entry, or preparing input for a text-based function,
    we need to convert this structured log into a single, continuous string. This
    makes sure that the data is in the correct format for these specific tasks and
    helps resolve any potential punctuation or formatting quirks that might arise
    when combining the different message parts:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`messages_obj` 以结构化格式保存对话的历史。在我们的应用程序中，对于某些操作，例如生成简化的显示、创建综合日志条目或为基于文本的函数准备输入，我们需要将这个结构化日志转换为单个、连续的字符串。这确保了数据以正确的格式适用于这些特定任务，并有助于解决在组合不同的消息部分时可能出现的任何潜在的标点或格式问题：'
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The cleansing function cleans the conversation and returns a string:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 清理函数清理对话并返回一个字符串：
- en: '[PRE6]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 7\. Making the initial API call
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7. 进行初始API调用
- en: 'The cleansed conversation string is sent to the API for processing. The API
    provides a response based on the last input and the conversation history. The
    system now has a memory:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 清理后的对话字符串被发送到API进行处理。API根据最后输入和对话历史提供响应。现在系统有了记忆：
- en: '[PRE7]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 8\. Appending the initial API response
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8. 添加初始API响应
- en: 'The assistant’s response from the API is processed and appended to `messages_obj`.
    We are continuing to increase the system’s memory and, thus, its contextual awareness:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: API的助手响应被处理并附加到 `messages_obj`。我们正在继续增加系统的记忆和，因此，其上下文意识：
- en: '[PRE8]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 9\. Displaying the initial assistant’s response
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 9. 显示初始助手响应
- en: 'The system’s response is displayed for the user to analyze and decide whether
    to continue or exit the session:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 系统的响应显示给用户分析，并决定是否继续或退出会话：
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 10\. Starting the conversation loop
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 10. 开始对话循环
- en: 'The system now enters the conversation loop, where multiple dialogue turns
    can take place until the user decides to exit the session:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 系统现在进入对话循环，其中可以发生多个对话回合，直到用户决定退出会话：
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We are now ready to begin a full-turn conversation loop.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在准备好开始一个完整对话循环。
- en: The full-turn conversation loop
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 完整对话循环
- en: The initial conversation is now initialized. We will enter the full-turn conversation
    loop starting from *step 11* onward, as illustrated in *Figure 2.4*.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 初始对话现在初始化。我们将从*步骤11*开始，进入完整对话循环，如图2.4所示。
- en: '![Figure 2.4: The conversation loop starting from step 11](img/B32304_02_4.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图2.4：从步骤11开始的对话循环](img/B32304_02_4.png)'
- en: 'Figure 2.4: The conversation loop starting from step 11'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4：从步骤11开始的对话循环
- en: 11\. Prompting for the user input
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11. 提示用户输入
- en: 'The conversation continues the initial dialogue and is memorized through the
    `messages` object. The user prompt triggers a full-turn conversation loop. The
    first step is to enter the user’s name. This custom takes us beyond the standard
    ChatGPT-like conversational agents that are limited to one user per session. We
    are initializing a multi-user conversation:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对话继续初始对话，并通过`messages`对象进行记忆。用户提示触发完整对话循环。第一步是输入用户的名字。这个自定义功能使我们超越了仅限于每个会话一个用户的标准ChatGPT-like对话代理。我们正在初始化一个多用户对话：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 12\. Checking the Exit condition
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 12. 检查退出条件
- en: 'If `q` or `quit` is entered, the session is ended:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果输入`q`或`quit`，会话结束：
- en: '[PRE12]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 13\. Appending the user input to the messages object
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 13. 将用户输入附加到消息对象
- en: 'The system is now equipped with a memory of a full-turn conversation loop.
    It uses the generic API format we defined. The user’s input is appended to `messages_obj`:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 系统现在具备了一个完整对话循环的记忆。它使用我们定义的通用API格式。用户的输入被附加到`messages_obj`：
- en: '[PRE13]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 14\. Cleansing the conversation log (loop)
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 14. 清理对话日志（循环）
- en: 'The updated `messages_obj` is cleansed to make sure it complies with the API
    calls, as in *step 6*, *Cleansing the initial conversation log*:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 更新的`messages_obj`被清理以确保它符合API调用，正如在*步骤6*，*清理初始对话日志*中所述：
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 15\. Making the API call in the conversation loop
  id: totrans-105
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 15. 在对话循环中调用API
- en: 'In this full-turn conversation loop, the whole conversation is sent to the
    API. The API will thus return a response based on the context of the whole conversation
    and the new input:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个完整对话循环中，整个对话被发送到API。因此，API将根据整个对话的上下文和新输入返回响应：
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 16\. Appending the API response in the conversation loop
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 16. 在对话循环中附加API响应
- en: 'The API’s response is appended to `messages_obj` at each conversation turn:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个对话回合，API的响应被附加到`messages_obj`：
- en: '[PRE16]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 17\. Displaying the assistant’s response
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 17. 显示助手响应
- en: 'The API response is displayed at each conversation turn in the loop:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在循环的每个对话回合中显示API响应：
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 18\. Exiting and saving the conversation log
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 18. 退出并保存对话日志
- en: 'When a user exits the loop, the conversation is saved. This feature will replicate
    a ChatGPT-like platform that can save dialogue between two sessions with the same
    user. However, as we will see in our implementation of a conversational agent
    in the *Running the conversational agent* section, our program will be able to
    save a multi-user session in a conversation between team members:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户退出循环时，对话将被保存。这个功能将复制一个ChatGPT-like平台，可以保存同一用户在两个会话之间的对话。然而，正如我们将在“运行对话代理”部分中看到，我们的程序将能够在团队成员之间的对话中保存多用户会话：
- en: '[PRE18]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 19\. End
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 19. 结束
- en: 'The conversational agent terminates the session after memorizing the conversation:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 对话代理在记忆对话后终止会话：
- en: '[PRE19]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We have explored the conversational agent’s functionality.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探讨了对话代理的功能。
- en: Now, let’s move on to the AI conversational agent program that represents an
    AI controller.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续讨论代表AI控制器的AI对话代理程序。
- en: Running the conversational AI agent
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行对话AI代理
- en: 'The main program, `Conversational_AI_Agent.ipynb`, calls the necessary functions
    from `conversational_agent.py` to handle AI interactions. We will be running a
    conversation through three user sessions with this scenario:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 主程序`Conversational_AI_Agent.ipynb`从`conversational_agent.py`调用必要的函数来处理AI交互。我们将使用这个场景运行三个用户会话的对话：
- en: John begins with a short-term memory session with the conversational AI agent.
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 约翰开始与对话式人工智能代理进行短期记忆会话。
- en: John’s conversation will be saved in a log file when the session is over.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当会话结束时，约翰的对话将保存在日志文件中。
- en: Myriam resumes the session using that same log file.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Myriam 使用相同的日志文件继续会话。
- en: Myriam’s conversation will be saved in the same log file as John’s when the
    session is over.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当会话结束时，Myriam 的对话将保存在与约翰相同的日志文件中。
- en: Bob will pick up where John and Myriam left off.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 鲍勃将从约翰和 Myriam 离开的地方继续。
- en: Bob’s conversation will be saved in the same log file as John’s and Myriam’s
    when the session is over.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当会话结束时，鲍勃的对话将保存在与约翰和 Myriam 相同的日志文件中。
- en: 'All three users interact in successive sessions. In [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085),
    we’ll go further by grouping users through a Pinecone vector store so that multiple
    users can participate together in a session in real time. For the moment, let’s
    walk through this multi-user setup step by step and see how the conversational
    AI agent handles these sessions. Let’s begin with the first step: John’s short-term
    memory session.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 所有三位用户在连续的会话中进行互动。在 [*第 3 章*](Chapter_3.xhtml#_idTextAnchor085) 中，我们将通过 Pinecone
    向量存储将用户分组，以便多个用户可以实时一起参与会话。目前，让我们一步一步地走过这个多用户设置，看看对话式人工智能代理如何处理这些会话。让我们从第一步开始：约翰的短期记忆会话。
- en: Short-term memory session
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 短期记忆会话
- en: 'The session begins with the parameters described in *step 1*, *Starting the
    conversation*, of the conversational agent:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 会话以对话代理的 *步骤 1*，*开始对话* 中描述的参数开始：
- en: '[PRE20]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We are also adding the name of the user like in a ChatGPT-like session:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在会话中添加了用户名，就像在 ChatGPT 类型的会话中一样：
- en: '[PRE21]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This simple addition—`user_name`—is what takes our GenAISys beyond standard
    ChatGPT-like platforms. It allows us to associate memory with specific users and
    expand into multi-user conversations within a single system.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的添加——`user_name`——使我们的 GenAISys 超越了标准 ChatGPT 类型的平台。它允许我们将记忆与特定用户关联，并在单个系统中扩展到多用户对话。
- en: 'We will now import the first function, the OpenAI API functionality, to make
    a request to OpenAI’s API, as described in [*Chapter 1*](Chapter_1.xhtml#_idTextAnchor021):'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将导入第一个函数，即 OpenAI API 功能，按照 [*第 1 章*](Chapter_1.xhtml#_idTextAnchor021)
    中所述向 OpenAI 的 API 发送请求：
- en: '[PRE22]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The program now imports the second function, the conversational agent, and
    runs it as described earlier in this section:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 程序现在导入第二个函数，即对话代理，并按本节前面所述运行：
- en: '[PRE23]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Let’s go through each step of the dialog implemented with our two functions.
    The agent first welcomes us:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一查看使用我们两个函数实现的对话的每个步骤。代理首先欢迎我们：
- en: '[PRE24]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'John, the first user, asks for a geological explanation about Hawaii:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 约翰，第一个用户，请求关于夏威夷的地质解释：
- en: '[PRE25]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The agent provides a satisfactory answer:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 代理提供了令人满意的回答：
- en: '[PRE26]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'John now asks about surfing “there”:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 约翰现在询问“那里”冲浪的情况：
- en: '[PRE27]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Thanks to the memory we built into the agent, it now has contextual awareness
    through memory retention. The agent correctly responds about surfing in Hawaii:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 多亏了代理中内置的记忆，它现在通过记忆保留具有上下文意识。代理正确地回答了关于夏威夷冲浪的问题：
- en: '[PRE28]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'John now asks about the best places to stay without mentioning Hawaii:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 约翰现在询问最佳住宿地点，但没有提到夏威夷：
- en: '[PRE29]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The agent answers correctly using contextual awareness:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 代理利用上下文意识正确回答：
- en: '[PRE30]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'John then quits the session:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 约翰然后退出会话：
- en: '[PRE31]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The agent exits the conversation and saves the dialogue in a conversation log:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 代理退出对话，并将对话保存在对话日志中：
- en: '[PRE32]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The short-term session ends, but thanks to memory retention via `conversation_log.txt`,
    we can easily pick up from where John left off. We can thus continue the dialogue
    immediately or at a later time, leveraging memory retention through the `conversation_log.txt`
    file that was automatically generated.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 短期会话结束，但多亏了通过 `conversation_log.txt` 实现的记忆保留，我们可以轻松地从约翰离开的地方继续。因此，我们可以立即或稍后继续对话，利用自动生成的
    `conversation_log.txt` 文件实现记忆保留。
- en: Long-term memory session
  id: totrans-160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 长期记忆会话
- en: 'The short-term session is saved. We have three options:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 短期会话已保存。我们有三个选项：
- en: Stop the program now. In this case, `conversation_log.txt` will only contain
    John’s session, which can be continued or not.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在停止程序。在这种情况下，`conversation_log.txt` 将只包含约翰的会话，可以选择继续或不继续。
- en: Decide to initialize a separate `conversation_log.txt` for the next user, Myriam.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决定为下一个用户 Myriam 初始化一个单独的 `conversation_log.txt`。
- en: Continue with a multi-user session by loading John’s conversation into Myriam’s
    initial dialog context.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将约翰的对话加载到 Myriam 的初始对话上下文中，继续进行多用户会话。
- en: The program in this chapter chooses to continue a multi-session, multi-user
    scenario.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的程序选择继续一个多会话、多用户场景。
- en: 'The first step to continue the conversation with John is to load and display
    the conversation log using the function in `processing_conversations.py` that
    we downloaded in the *Setting up the environment* section. We now import and run
    the function that we need to load and display the conversation log:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 继续与John对话的第一步是使用我们在*设置环境*部分下载的`processing_conversations.py`中的函数加载和显示对话日志。我们现在导入并运行我们需要的加载和显示对话日志的函数：
- en: '[PRE33]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The function is a standard `IPython` process using HTML functionality that
    reads and displays the conversation:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数是一个标准的`IPython`过程，使用HTML功能读取和显示对话：
- en: '[PRE34]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The output displays each participant in the conversation, beginning with the
    system’s information, followed by John’s request, and then the GPT-4o assistant’s
    response at each turn:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示对话中的每个参与者，首先是系统的信息，然后是John的请求，接着是GPT-4o助手在每个回合的回应：
- en: '[PRE35]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Before adding the conversation to the context of the next input, we will clean
    and prepare it. To achieve this, we successively import `cleanse_conversation_log`
    and import `initialize_uinput` from `processing_conversations.py`:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在将对话添加到下一个输入的上下文之前，我们将对其进行清理和准备。为此，我们依次导入`cleanse_conversation_log`和从`processing_conversations.py`导入`initialize_uinput`：
- en: '[PRE36]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Then, we will call the two Python functions that we defined to cleanse and
    then prepare the new input:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将调用我们定义的两个Python函数来清理并准备新的输入：
- en: '[PRE37]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The `cleanse` function removes punctuation and potentially problematic characters:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '`cleanse`函数移除标点符号和可能有问题的人物：'
- en: '[PRE38]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Finally, we initialize the new input:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们初始化新的输入：
- en: '[PRE39]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The output confirms that the conversation log has been cleansed:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 输出确认对话日志已被清理：
- en: '[PRE40]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Then, the output confirms that `nuinput` contains the conversation log for
    continuation:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，输出确认`nuinput`包含用于继续的对话日志：
- en: '[PRE41]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Continuing the previous session
  id: totrans-184
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 继续之前的会话
- en: 'We can now continue the conversation that John began with `nuinput` as the
    memory retention variable for contextual awareness. We will add the context, `nuinput`,
    to Myriam’s request using the message variables as before:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以使用`nuinput`作为记忆保留变量来继续John开始的对话。我们将使用消息变量将上下文`nuinput`添加到Myriam的请求中：
- en: '[PRE42]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The message call contains two key features:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 消息调用包含两个关键特性：
- en: '`ninput = nuinput+ [user input]`, which shows that the AI controller now has
    a long-term memory that goes beyond a single session'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ninput = nuinput+ [user input]`，这表明AI控制器现在拥有超越单个会话的长期记忆'
- en: '`user_name = "Myriam"`, which shows the multi-user feature, proving that our
    custom small-scale ChatGPT-like AI controller has more flexibility than a standard
    copilot'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`user_name = "Myriam"`，这展示了多用户功能，证明了我们定制的ChatGPT-like AI控制器比标准机助有更大的灵活性'
- en: 'The overall process is the same as with John. Myriam asks a question:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程与John的情况相同。Myriam提出一个问题：
- en: '[PRE43]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The agent responds:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 代理回应：
- en: '[PRE44]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Myriam quits:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Myriam退出：
- en: '[PRE45]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The agent confirms that the conversation has ended and is saved to the conversation
    log:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 代理确认对话已结束并保存在对话日志中：
- en: '[PRE46]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The AI controller now has a log of John’s session and Myriam’s continuation
    of the session. The controller can take this further and add yet another user
    to the conversation.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: AI控制器现在有了John的会话和Myriam继续会话的日志。控制器可以进一步操作并添加另一个用户到对话中。
- en: Continuing the long-term multi-user memory
  id: totrans-199
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 继续长期的多用户记忆
- en: 'Let’s add Bob to the mix to continue the conversation. First, display the conversation
    log again:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们加入Bob以继续对话。首先，再次显示对话日志：
- en: '[PRE47]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'You’ll see entries for both John and Myriam:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到John和Myriam的条目：
- en: '[PRE48]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The log is then cleansed and prepared for the next turn of the conversation
    as previously. `nuinput` now contains John and Myriam’s sessions:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 然后将日志清理并准备为对话的下一个回合。`nuinput`现在包含John和Myriam的会话：
- en: '[PRE49]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Bob is focused on the geological mission, not leisure:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: Bob专注于地质任务，而不是休闲：
- en: '[PRE50]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The AI agent provides an accurate response:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: AI代理提供了一个准确的回应：
- en: '[PRE51]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Bob then quits the session:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: Bob随后退出了会话：
- en: '[PRE52]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The agent exits the conversation and saves it in the conversation log:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 代理退出对话并将其保存在对话日志中：
- en: '[PRE53]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: With these three scenarios, we have implemented a conversational agent managed
    by the AI controller in a multi-user full-turn conversational loop. Let’s examine
    the next steps for this conversational agent.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这三个场景，我们已经在多用户全回合对话循环中实现了由AI控制器管理的对话代理。让我们检查这个对话代理的下一步：
- en: Next steps
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下一步
- en: At this point, we have the basic structure of a conversational agent. We need
    to integrate it into an AI controller orchestrator. Let’s sum up the work we did
    for the conversational agent before beginning to build the AI controller orchestrator.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，我们已经拥有了对话代理的基本结构。我们需要将其集成到一个AI控制器协调器中。在开始构建AI控制器协调器之前，让我们总结一下我们为对话代理所做的工作。
- en: '![Figure 2.5: The cycle of a conversational agent loop](img/B32304_02_5.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![图2.5：对话代理循环的周期](img/B32304_02_5.png)'
- en: 'Figure 2.5: The cycle of a conversational agent loop'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5：对话代理循环的周期
- en: 'As illustrated in the preceding figure, the AI conversation agent does the
    following:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，AI对话代理执行以下操作：
- en: The agent processes the input (system or human user).
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理处理输入（系统或人类用户）。
- en: The agent responds.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代理做出回应。
- en: The memory retention function is activated.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 激活记忆保留功能。
- en: The conversation is added to the following input as context.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对话被添加到以下输入作为上下文。
- en: The user can quit.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户可以退出。
- en: However, the entry/exit point is incomplete. We can enter and exit the conversation
    but cannot call functions to orchestrate tasks such as activating sentiment analysis
    and semantic analysis. To complete the architecture of the AI controller, we need
    to begin building the AI controller orchestrator.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，入口/出口点是不完整的。我们可以进入和退出对话，但不能调用函数来协调任务，如激活情感分析和语义分析。为了完成AI控制器的架构，我们需要开始构建AI控制器协调器。
- en: AI controller orchestrator
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI控制器协调器
- en: 'In this section, we will build the first component of our AI controller orchestrator:
    the ability to select the right task to perform. We develop this component as
    a standalone component that we will integrate starting from [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085),
    where we will bridge the conversational agent with the AI controller orchestrator
    through a Pinecone vector store.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将构建我们的AI控制器协调器的第一个组件：选择正确任务执行的能力。我们将开发这个作为独立组件，从[*第3章*](Chapter_3.xhtml#_idTextAnchor085)开始集成，在那里我们将通过Pinecone向量存储将对话代理与AI控制器协调器连接起来。
- en: '*Figure 2.6* illustrates the workflow of the AI controller orchestrator we’ll
    be developing:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '*图2.6*展示了我们将开发的AI控制器协调器的工作流程：'
- en: '**C1\. AI controller entry point input** triggers the process.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C1. AI控制器入口点输入**触发流程。'
- en: '**C2\. Analyzes input,** which could be a system or human user prompt.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C2. 分析输入**，这可能是一个系统或人类用户的提示。'
- en: '**C3\. Embeds user input** through GPT-4o’s native functionality.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C3. 通过GPT-4o的本地功能嵌入用户输入**。'
- en: '**C4\. Embeds task scenario** **repository** through GPT-4o’s native functionality.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C4. 通过GPT-4o的本地功能嵌入任务场景** **存储库**。'
- en: '**C5\. Selects a** **scenario** to execute a task that best matches the input.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C5. 选择一个** **场景** 来执行与输入最匹配的任务。'
- en: '**C6\. Executes the scenario** selected by the AI controller orchestrator.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**C6. 执行AI控制器协调器选择的场景**。'
- en: '![Figure 2.6: Workflow of the AI controller orchestrator](img/B32304_02_6.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![图2.6：AI控制器协调器的工作流程](img/B32304_02_6.png)'
- en: 'Figure 2.6: Workflow of the AI controller orchestrator'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6：AI控制器协调器的工作流程
- en: We’ll develop this first component of the AI controller orchestrator with OpenAI’s
    GPT-4o API and Python. Additionally, since the idea is to leverage the full power
    of the generative AI model to perform several tasks requested by the AI controller
    orchestrator, we will thus avoid overloading the orchestrator with additional
    libraries to focus on the architecture of the GenAISys.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用OpenAI的GPT-4o API和Python开发AI控制器协调器的这个第一个组件。此外，由于我们的想法是利用生成式AI模型的全功能来执行AI控制器协调器请求的多个任务，因此我们将避免在协调器上加载额外的库，以专注于GenAISys的架构。
- en: 'In this notebook, GPT-4o will perform three key functions in the program, as
    shown in *Figure 2.7*:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个笔记本中，GPT-4o将在程序中执行三个关键功能，如图*图2.7*所示：
- en: '**Embedding**: GPT-4o systematically embeds all the data it receives through
    a prompt. The input is embedded before going through the layers of the model.
    In [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085), we will take this further
    by embedding and upserting reusable data such as instruction scenarios into a
    Pinecone vector store.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入**：GPT-4o系统性地将所有通过提示接收到的数据嵌入。输入在通过模型层之前被嵌入。在[*第3章*](Chapter_3.xhtml#_idTextAnchor085)中，我们将通过将可重用数据如指令场景嵌入到Pinecone向量存储中进一步扩展这一做法。'
- en: '**Similarity search**: GPT-4o can perform a similarity search with reliable
    results. GPT-4o doesn’t have a deterministic fixed cosine similarity function.
    It learns to understand relationships through its complex neural network, mimicking
    similarity judgments in a much more nuanced, less deterministic way.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相似度搜索**：GPT-4o 可以执行相似度搜索并得到可靠的结果。GPT-4o 没有确定性的固定余弦相似度函数。它通过其复杂的神经网络学习理解关系，以一种更加细腻、不那么确定性的方式模仿相似度判断。'
- en: '**Task execution**: Once a scenario is chosen, GPT-4o can execute a number
    of standard tasks, such as sentiment and semantic analysis.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务执行**：一旦选择了一个场景，GPT-4o 可以执行一系列标准任务，例如情感分析和语义分析。'
- en: '![Figure 2.7: Triggering tasks with similarity searches in a list of instructions](img/B32304_02_7.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.7：在指令列表中使用相似度搜索触发任务](img/B32304_02_7.png)'
- en: 'Figure 2.7: Triggering tasks with similarity searches in a list of instructions'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7：在指令列表中使用相似度搜索触发任务
- en: We have defined the workflow of the orchestrator and the generative AI model’s
    usage. However, we must examine how a model identifies the task it is expected
    to perform.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了协调器的工作流程和生成式 AI 模型的使用。然而，我们必须检查模型如何识别它预期执行的任务。
- en: Understanding the intent functionality
  id: totrans-245
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解意图功能
- en: 'No matter how powerful a generative AI model such as GPT-4o is, it cannot guess
    what a user wants without a prompt that explicitly expresses *intent*. We cannot
    just say, “The Grand Canyon is a great place to visit in Arizona” and expect the
    model to guess that we want a sentiment analysis done on our statement. We have
    to explicitly formulate our intent by entering: “Provide a sentiment analysis
    of the following text: The Grand Canyon is a great place to visit in Arizona.”'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 无论像 GPT-4o 这样的生成式 AI 模型多么强大，如果没有一个明确表达意图的提示，它就无法猜测用户的需求。我们不能只是说，“大峡谷是亚利桑那州一个伟大的旅游胜地”，并期望模型猜测我们想要对这句话进行情感分析。我们必须通过输入以下内容来明确表达我们的意图：“提供以下文本的情感分析：大峡谷是亚利桑那州一个伟大的旅游胜地。”
- en: To resolve the issue of intent for an AI controller, we have to find a framework
    for it to orchestrate its tasks. A good place to start is to study the **Text-to-Text
    Transfer Transformer** (**T5**), which is a text-to-text model (Raffel et al.,
    2020). A T5 model uses *task tags* or *task-specific prefixes* to provide the
    intent of a prompt to the transformer model. A task tag contains instructions
    such as summarization, translation, and classification. The model will detect
    the tag and know what to do, as shown in *Figure 2.8*.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决 AI 控制器的意图问题，我们必须找到一个框架来协调其任务。一个好的起点是研究 **文本到文本迁移变换器**（**T5**），这是一个文本到文本模型（Raffel
    等人，2020 年）。T5 模型使用 *任务标签* 或 *特定任务的前缀* 来向变换器模型提供提示的意图。任务标签包含总结、翻译和分类等指令。模型将检测标签并知道要做什么，如图
    *图 2.8* 所示。
- en: '![Figure 2.8: T5 with task tags](img/B32304_02_8.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.8：带有任务标签的 T5](img/B32304_02_8.png)'
- en: 'Figure 2.8: T5 with task tags'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.8：带有任务标签的 T5
- en: 'Training a T5 model involves *explicitly* adding a task tag when creating an
    input and then providing the response. However, OpenAI GPT models learn which
    task to perform by analyzing billions of sequences of language, not explicit structures,
    that contain instructions and responses. A generative AI model using GPT-like
    architectures will thus learn which task to perform *implicitly* through the context
    of the prompt. For example, a well-parsed prompt such as “Provide a sentiment
    analysis of the following text: The Grand Canyon is a great place to visit in
    Arizona.” contains enough context for GPT-4o to infer the desired operation—without
    requiring an explicit tag.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 T5 模型涉及在创建输入时 *明确地* 添加任务标签，然后提供响应。然而，OpenAI 的 GPT 模型通过分析包含指令和响应的数十亿个语言序列来学习执行哪个任务，而不是显式结构。因此，使用类似
    GPT 架构的生成式 AI 模型将通过提示的上下文 *隐式地* 学习执行哪个任务。例如，一个良好解析的提示，如“提供以下文本的情感分析：大峡谷是亚利桑那州一个伟大的旅游胜地。”，为
    GPT-4o 提供了足够多的上下文来推断所需的操作——无需显式标签。
- en: Let’s illustrate how a GPT model works by running T5-style examples with GPT-4o’s
    implicit analysis of which task needs to be performed.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过运行带有 GPT-4o 隐式分析需要执行哪个任务的 T5 风格示例来展示 GPT 模型的工作原理。
- en: From T5 to GPT models
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从 T5 到 GPT 模型
- en: In this section, we’ll write a program to show how GPT-4o interprets instructions—a
    capability we’ll leverage in our orchestrator. The aim is to demonstrate that,
    although GPT-style models infer intent implicitly, they still need clear instructions.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将编写一个程序来展示GPT-4o如何解释指令——这是我们将在编排器中利用的能力。目标是证明，尽管GPT风格的模型隐式地推断意图，但它们仍然需要清晰的指令。
- en: 'We’ll begin by opening `T52GPT.ipynb` in the `Chapter02` directory on GitHub.
    Set up the environment exactly as in the *Setting up the environment* subsection
    of the *Conversational AI agent* section, installing only the OpenAI environment:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先在GitHub上的`Chapter02`目录中打开`T52GPT.ipynb`。设置环境与*设置环境*子节中的*对话式AI代理*部分完全一致，仅安装OpenAI环境：
- en: '[PRE54]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: No additional installations are required. Let’s now begin with a CoLA task.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 不需要额外的安装。现在让我们开始一个CoLA任务。
- en: Corpus of Linguistic Acceptability (CoLA)
  id: totrans-257
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语言学可接受性语料库（CoLA）
- en: The **Corpus of Linguistic Acceptability** (**CoLA**) is a public dataset of
    short English sentences, each tagged as acceptable (grammatical) or unacceptable
    (ungrammatical). By testing GPT-4o on these examples, we can show that advanced
    generative models can tackle new tasks purely by understanding language, without
    any task-specific fine-tuning. This means that we can apply advanced generative
    AI models to a wide range of tasks we didn’t train them for.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '**语言学可接受性语料库**（**CoLA**）是一个公共的短英语句子数据集，每个句子都被标记为可接受（语法正确）或不可接受（语法错误）。通过在这些例子上测试GPT-4o，我们可以展示高级生成模型可以通过理解语言来处理新任务，而无需任何特定任务的微调。这意味着我们可以将高级生成式AI模型应用于我们未对其进行训练的广泛任务。'
- en: 'Let’s first submit the following input to the GPT-4o model to see whether it
    is acceptable without an explicit task tag:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先向GPT-4o模型提交以下输入，看看它是否在没有明确任务标签的情况下是可接受的：
- en: '[PRE55]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'We will provide minimal information to the system:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将向系统提供最少的信息：
- en: '[PRE56]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'We’ll also make an OpenAI API call with the function we have been using throughout
    this chapter:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用本章中一直使用的函数调用OpenAI API：
- en: '[PRE57]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The output shows that even one of the most powerful generative AI models doesn’t
    have a clue about what to do without a task tag:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，即使是最强大的生成式AI模型在没有任务标签的情况下也没有头绪：
- en: '[PRE58]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Now, let’s write an instruction with a task tag and the same message:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们编写一个带有任务标签和相同信息的指令：
- en: '[PRE59]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The input now contains an indication of what is expected of the generative
    AI model. The output is now accurate:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 输入现在包含了对生成式AI模型期望的指示。输出现在也是准确的：
- en: '[PRE60]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Let’s now perform a translation task.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们执行一个翻译任务。
- en: Translation task
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 翻译任务
- en: 'The task begins with a task tag that is expressed in natural language:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 任务以自然语言表达的任务标签开始：
- en: '[PRE61]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The output we get is accurate:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的输出是准确的：
- en: '[PRE62]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Let’s now perform a **Semantic Textual Similarity Benchmark** (**STSB**) task.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们执行一个**语义文本相似度基准**（**STSB**）任务。
- en: Semantic Textual Similarity Benchmark (STSB)
  id: totrans-278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语义文本相似度基准（STSB）
- en: 'STSB-style scoring is an important feature for a GenAISys AI controller, which
    depends on similarity searches to pick the right instruction scenarios, documents,
    and other resources. The orchestrator will rely on this very capability. In the
    test that follows, we submit two sentences to the model and ask it to judge their
    semantic similarity:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: STSB风格的评分是GenAISys AI控制器的重要功能，它依赖于相似度搜索来选择正确的指令场景、文档和其他资源。编排器将依赖于这一能力。在接下来的测试中，我们向模型提交两个句子并要求它判断它们的语义相似度：
- en: '[PRE63]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'The output we get is accurate:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到的输出是准确的：
- en: '[PRE64]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: This function will prove to be very useful when we’re searching for data that
    matches the input in a dataset. Let’s now run a summarization task.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在数据集中搜索与输入匹配的数据时，这个函数将非常有用。现在让我们运行一个摘要任务。
- en: Summarization
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In the following input, GPT-4o can detect the summarization instruction tag
    and also interpret the maximum length of the response required:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下输入中，GPT-4o可以检测到摘要指令标签，并解释所需的响应最大长度：
- en: '[PRE65]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The output is once again accurate:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 输出再次是准确的：
- en: '[PRE66]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: The takeaway of this exploration is that no matter which generative AI model
    we implement, it requires task tags to react as we expect. Next, we’ll use this
    insight to implement semantic textual similarity in our orchestrator for processing
    task tags.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这次探索的要点是，无论我们实施哪种生成式AI模型，它都需要任务标签才能按照我们的预期进行反应。接下来，我们将利用这一洞察力在我们的编排器中实现语义文本相似度处理任务标签。
- en: Implementing the orchestrator for instruction selection
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现指令选择的编排器
- en: 'In this section, we will begin building the orchestrator for two instructions
    based on task tags, as shown in *Figure 2.9*: sentiment analysis to determine
    the sentiment of a sentence and semantic analysis to analyze the facts in a sentence.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将开始构建基于任务标签的两个指令的调度器，如图*2.9*所示：情感分析以确定句子的情感和语义分析以分析句子中的事实。
- en: We will make the system more complex by asking the generative AI model to find
    the best task tag scenario (sentiment or semantic analysis) based on the input.
    In other words, the task tag will not be part of the input. We will use GPT-4o’s
    semantic textual similarity features to choose the right task tag itself.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过要求生成式AI模型根据输入找到最佳任务标签场景（情感或语义分析）来使系统更加复杂。换句话说，任务标签将不会是输入的一部分。我们将使用GPT-4o的语义文本相似度功能来选择正确的任务标签本身。
- en: '![Figure 2.9: Running tasks with implicit task tags](img/B32304_02_9.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![图2.9：使用隐式任务标签运行任务](img/B32304_02_9.png)'
- en: 'Figure 2.9: Running tasks with implicit task tags'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9：使用隐式任务标签运行任务
- en: Eventually, our orchestrator will support any task (see **3\. Any Task required**
    in *Figure 2.9*), not just sentiment or semantic analysis.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们的调度器将支持任何任务（参见*图2.9*中的**3. 任何所需任务**），而不仅仅是情感或语义分析。
- en: 'Setting up the environment is the same as earlier:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 环境设置与之前相同：
- en: '[PRE67]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: No additional installations are required for the orchestrator. We will begin
    by implementing an instruction scenario selection.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 对于调度器不需要额外的安装。我们将首先实施一个指令场景选择。
- en: Selecting a scenario
  id: totrans-299
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择场景
- en: 'The core of an AI controller is to decide what to do when it receives an input
    (system or human user). The selection of a task opens a world of possible methods
    that we will explore throughout the book. However, we can classify them into two
    categories:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: AI控制器的核心是在接收到输入（系统或人类用户）时决定做什么。任务的选择打开了一个我们将全书探索的可能方法的世界。然而，我们可以将它们分为两类：
- en: Using an explicit task tag to trigger an instruction. This tag can be a context
    in a generative AI model and expressed freely in various ways in a prompt.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用显式任务标签来触发指令。这个标签可以是一个生成式AI模型中的上下文，并在提示中以各种方式自由表达。
- en: The prompt has no task instruction but instead a repository of scenarios from
    which the AI controller will make decisions based on semantic textual similarity.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示没有任务指令，而是一个场景存储库，AI控制器将根据语义文本相似度从中做出决策。
- en: Here, we’ll explore the second, more proactive approach. We’ll test two prompts
    with no instructions, no task tag, and no clue as to what is expected of the generative
    AI model. Although we will implement other, more explicit approaches later with
    task tags, a GenAISys AI controller orchestrator must be able to be proactive
    in certain situations.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将探讨第二种更主动的方法。我们将测试两个没有任何指示、没有任务标签和没有任何关于对生成式AI模型期望的提示的提示。虽然我们稍后会实施带有任务标签的更明确的方法，但GenAISys
    AI控制器调度器必须能够在某些情况下主动行事。
- en: 'The first prompt is an opinion on a movie, implying that a sentiment analysis
    might interest the user:'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个提示是对一部电影的看法，暗示用户可能对情感分析感兴趣：
- en: '[PRE68]'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The second prompt is a fact, implying that a semantic analysis might interest
    the user:'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个提示是一个事实，暗示用户可能对语义分析感兴趣：
- en: '[PRE69]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: To provide the AI controller with decision-making capabilities, we will need
    a repository of instruction scenarios.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供AI控制器决策能力，我们需要一个指令场景存储库。
- en: Defining task/instruction scenarios
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义任务/指令场景
- en: 'Scenarios are sets of instructions that live in a repository within a GenAISys.
    While ChatGPT-like models are trained to process many instructions natively, domain-specific
    use cases need custom scenarios (we’ll dive into these starting from [*Chapter
    5*](Chapter_5.xhtml#_idTextAnchor140)). For example, a GenAISys could receive
    a message such as `Customer order #9283444 is late`. The message could be about
    a production delay or a delivery delay. By examining the sender’s username and
    group (production or delivery department), the AI controller can determine the
    context and, selecting a scenario, take an appropriate decision.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 场景是一组存在于GenAISys内部存储库中的指令。虽然ChatGPT-like模型被训练来原生处理许多指令，但特定领域的用例需要定制场景（我们将在[*第五章*](Chapter_5.xhtml#_idTextAnchor140)中深入探讨这些）。例如，GenAISys可能收到一条消息，例如“客户订单#9283444延迟”。这条消息可能是关于生产延迟或交付延迟。通过检查发送者的用户名和组（生产或交付部门），AI控制器可以确定上下文，并选择一个场景，做出适当的决定。
- en: In this notebook, the scenarios are stored in memory. In [*Chapter 3*](Chapter_3.xhtml#_idTextAnchor085),
    we will organize the storage and retrieval of these instruction sets in Pinecone
    vector stores.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个笔记本中，场景存储在内存中。在[*第3章*](Chapter_3.xhtml#_idTextAnchor085)中，我们将组织这些指令集在Pinecone向量存储中的存储和检索。
- en: 'In both cases, we begin by creating a repository of structured scenarios (market,
    sentiment, and semantic analysis):'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，我们首先创建一个结构化场景的仓库（市场、情感和语义分析）：
- en: '[PRE70]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'We will also add a dictionary of the same scenarios, containing simple definitions
    of the scenarios:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将添加一个包含相同场景的字典，包含场景的简单定义：
- en: '[PRE71]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'We now extract the strings from the dictionary and store them in a list:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在从字典中提取字符串并将它们存储在一个列表中：
- en: '[PRE72]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: At this point, our AI controller has everything it needs to recognize intent—matching
    any incoming prompt to the best-fitting scenario.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的AI控制器已经拥有了识别意图所需的一切——将任何传入的提示与最佳匹配的场景相匹配。
- en: Performing intent recognition and scenario selection
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 执行意图识别和场景选择
- en: 'We first define the parameters of the conversational AI agent just as we did
    in the *Conversational AI agent* section:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义对话人工智能代理的参数，就像我们在*对话人工智能代理*部分所做的那样：
- en: '[PRE73]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: The orchestrator’s job is to find the best task for any given input, making
    the AI controller flexible and adaptive. In some cases, the orchestrator may decide
    not to apply a scenario and just follow the user’s input. In the following example,
    however, the orchestrator will select a scenario and apply it.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 调度器的任务是找到任何给定输入的最佳任务，使人工智能控制器灵活且适应性较强。在某些情况下，调度器可能决定不应用场景，而只是跟随用户的输入。然而，在以下示例中，调度器将选择一个场景并应用它。
- en: 'We now adjust the input to take the orchestrator’s request into account:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在调整输入以考虑调度器的请求：
- en: '[PRE74]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'GPT-4o will now perform a text semantic similarity search as we ran in the
    *Semantic Textual Similarity Benchmark (STSB)* section. In this case, it doesn’t
    just perform a plain text comparison, but matches one text (the user input) against
    a list of texts (our scenario descriptions):'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-4o现在将执行文本语义相似度搜索，就像我们在*语义文本相似度基准（STSB）*部分所做的那样。在这种情况下，它不仅执行纯文本比较，而且将一个文本（用户输入）与一系列文本（我们的场景描述）进行匹配：
- en: '[PRE75]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Our user input is as follows:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的用户输入如下：
- en: '[PRE76]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Then, the scenario is chosen:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，选择场景：
- en: '[PRE77]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'The scenario number is then chosen, stored with the instructions that go with
    it, and displayed:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，选择场景编号，将其与相应的指令一起存储并显示：
- en: '[PRE78]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'For our *Gladiator II* example, the orchestrator correctly picks the sentiment
    analysis scenario:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的*Gladiator II*示例，调度器正确地选择了情感分析场景：
- en: '[PRE79]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: This autonomous task-selection capability—letting GenAISys choose the right
    analysis without explicit tags—will prove invaluable in real-world deployments
    (see [*Chapter 5*](Chapter_5.xhtml#_idTextAnchor140)). The program now runs the
    scenarios with the generative AI agent.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 这种自主任务选择能力——让GenAISys在没有明确标签的情况下选择正确的分析——将在实际部署中非常有价值（参见[*第5章*](Chapter_5.xhtml#_idTextAnchor140)）。程序现在使用生成式人工智能代理运行场景。
- en: Running scenarios with the generative AI agent
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用生成式人工智能代理运行场景
- en: 'Now that the AI controller has identified the correct `scenario_number`, it’s
    time to execute the selected task. In this notebook, we’ll walk through that process
    step by step. We first print the input:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 现在人工智能控制器已经识别出正确的`scenario_number`，是时候执行所选任务了。在这个笔记本中，我们将逐步介绍这个过程。我们首先打印输入：
- en: '[PRE80]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Using the `scenario_number` value, we access the scenario description from
    our `instructions_as_strings` list:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`scenario_number`值，我们从`instructions_as_strings`列表中访问场景描述：
- en: '[PRE81]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: The orchestrator is now ready to run a sentiment analysis.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 现在调度器已经准备好运行情感分析了。
- en: Sentiment analysis
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 情感分析
- en: 'We append the description of the scenario to the original user prompt and send
    the combined request to GPT-4o:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将场景描述附加到原始用户提示中，并将组合请求发送给GPT-4o：
- en: '[PRE82]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: '[PRE83]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'For our *Gladiator II* example, the response might look like this:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的*Gladiator II*示例，响应可能看起来像这样：
- en: '[PRE84]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: The response shows that the orchestrator found a scenario that matches the input
    and produces an acceptable output. Now, let’s go back, change the prompt, and
    see whether the orchestrator finds the right scenario.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 响应显示调度器找到了与输入匹配的场景并产生了可接受的输出。现在，让我们回到之前，更改提示，看看调度器是否找到了正确的场景。
- en: Semantic analysis
  id: totrans-349
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语义分析
- en: The goal now is to verify, without changing a single line of code, whether the
    orchestrator can access another scenario. The orchestrator will rely on GPT-4o’s
    native ability to perform semantic text similarity searches.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 目前的目标是验证，在不更改任何一行代码的情况下，协调器能否访问另一个场景。协调器将依赖于GPT-4o的本地能力来执行语义文本相似度搜索。
- en: 'We will now activate prompt 2:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将激活提示2：
- en: '[PRE85]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'This input clearly calls for a semantic analysis rather than sentiment analysis.
    We then reuse the exact same code as our sentiment analysis search:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输入明显需要语义分析而不是情感分析。然后我们重复使用与我们的情感分析搜索相同的代码：
- en: '[PRE86]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'The output shows that the right scenario was found:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示找到了正确的场景：
- en: '[PRE87]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'The task response is displayed:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 任务响应显示：
- en: '[PRE88]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'The output shows that the orchestrator produces a coherent semantic analysis:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示协调器产生了连贯的语义分析：
- en: '[PRE89]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: This demonstrates that in some cases, the orchestrator will be able to find
    the right scenarios without task tags. This will prove useful when we tackle more
    complex workflows, such as advanced production and support.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明在某些情况下，协调器将能够在没有任务标签的情况下找到正确的场景。当我们处理更复杂的流程时，例如高级生产和支持，这将非常有用。
- en: Summary
  id: totrans-362
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'The first takeaway from this chapter is the central role of humans in a GenAISys.
    Human design drove the creation of both our conversational agent and orchestrator.
    We started developing these two complex components with simply an OpenAI API and
    Python, yet we *humans* designed the initial levels of the AI controller that
    powers our custom GenAISys. The basic GenAISys rule will always apply: no human
    roles, no GenAISys. We design AI systems, implement them, maintain them, and evolve
    them based on ongoing feedback.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的第一个要点是人在GenAISys中的核心作用。人类设计推动了我们的对话式代理和协调器的创建。我们只是用OpenAI API和Python开始开发这两个复杂组件，但我们这些“人类”设计了为我们的定制GenAISys提供动力的AI控制器的初始级别。基本的GenAISys规则始终适用：没有人类角色，就没有GenAISys。我们设计AI系统，实施它们，维护它们，并根据持续的反馈进行进化。
- en: The second takeaway is how our conversational AI agent goes beyond a small-scale
    ChatGPT-like structure. We not only built short-term context and memory retention
    for a full-turn dialogue, but we also added long-term memory across multiple users
    and multiple topics. Our dialogue included three users (John, Myriam, and Bob)
    and two topics (geology and surfing). As we progress through the book, we will
    expand the scope of these multi-user, multi-topic sessions to use cases where
    team cooperation is essential.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个要点是如何我们的对话式AI代理超越了小型ChatGPT-like结构。我们不仅为完整轮对话构建了短期上下文和记忆保留，还添加了跨多个用户和多个主题的长期记忆。我们的对话包括三个用户（John、Myriam和Bob）和两个主题（地质学和冲浪）。随着我们阅读这本书的进展，我们将扩大这些多用户、多主题会话的范围，以应用于团队合作至关重要的用例。
- en: The third takeaway concerns our AI controller orchestrator. We gave the orchestrator
    a small scenario dataset containing custom instructions that we can expand for
    a domain-specific use case, and then leveraged GPT-4o to both select the appropriate
    scenario and execute the task itself.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个要点涉及我们的AI控制器协调器。我们为协调器提供了一个包含自定义指令的小型场景数据集，我们可以根据特定用例进行扩展，然后利用GPT-4o来选择合适的场景并执行任务本身。
- en: At this point, we have a conversational agent and a nascent AI controller orchestrator.
    When we assemble our AI controller, they will together form a unique multi-user,
    multi-domain customized GenAISys. To build our multi-user, multi-domain GenAISys
    AI controller, we will now build a Pinecone vector store in the next chapter.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们有一个对话式代理和一个新兴的AI控制器协调器。当我们组装我们的AI控制器时，它们将共同形成一个独特的多用户、多领域定制GenAISys。为了构建我们的多用户、多领域GenAISys
    AI控制器，我们将在下一章构建Pinecone向量存储。
- en: Questions
  id: totrans-367
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: A ChatGPT-like GenAISys only needs a generative AI model such as GPT-4o. (True
    or False)
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似ChatGPT的GenAISys只需要一个生成式AI模型，如GPT-4o。（对或错）
- en: A ChatGPT-like GenAISys doesn’t require an AI controller. (True or False)
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似ChatGPT的GenAISys不需要AI控制器。（对或错）
- en: Human roles are critical when building and running GenAISys. (True or False)
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在构建和运行GenAISys时，人类角色至关重要。（对或错）
- en: Generally, not always, a generative AI model such as GPT-4o contains a task
    tag in one form or the other. (True or False)
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通常情况下，但不总是，一个生成式AI模型如GPT-4o以一种或另一种形式包含任务标签。（对或错）
- en: Sometimes, not always, a generative model can find the most probable task to
    perform without a task tag. (True or False)
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有时，但不总是，一个生成模型可以在没有任务标签的情况下找到最可能执行的任务。（对或错）
- en: Semantic text similarity cannot be natively performed by GPT-4o. (True or False)
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 语义文本相似性不能由GPT-4o原生执行。（对或错）
- en: A full-turn generative AI conversation loop with an OpenAI API AI requires coding.
    (True or False)
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用OpenAI API的AI进行全轮生成式人工智能对话需要编码。（对或错）
- en: Long-term memory AI conversation sessions are never necessary. (True or False)
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 长期记忆人工智能对话会话从不必要。（对或错）
- en: Summarizing a text can only be done in English by GPT-4o. (True or False)
  id: totrans-376
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 总结文本只能用英语由GPT-4o完成。（对或错）
- en: An AI controller orchestrator is sentient. (True or False)
  id: totrans-377
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人工智能控制器协调器是有感知的。（对或错）
- en: References
  id: totrans-378
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou,
    Y., Li, W., & Liu, P. J. (2020). *Exploring the Limits of Transfer Learning with
    a Unified Text-to-Text Transformer.* [https://arxiv.org/abs/1910.10683](https://arxiv.org/abs/1910.10683)
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou,
    Y., Li, W., & Liu, P. J. (2020). *Exploring the Limits of Transfer Learning with
    a Unified Text-to-Text Transformer.* [https://arxiv.org/abs/1910.10683](https://arxiv.org/abs/1910.10683)
- en: 'Ren, J., Sun, Y., Du, H., Yuan, W., Wang, C., Wang, X., Zhou, Y., Zhu, Z.,
    Wang, F., & Cui, S. (2024). *Generative Semantic Communication: Architectures,
    Technologies, and Applications.* [https://doi.org/10.48550/arXiv.2412.08642](https://doi.org/10.48550/arXiv.2412.08642
    )'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ren, J., Sun, Y., Du, H., Yuan, W., Wang, C., Wang, X., Zhou, Y., Zhu, Z.,
    Wang, F., & Cui, S. (2024). *Generative Semantic Communication: Architectures,
    Technologies, and Applications.* [https://doi.org/10.48550/arXiv.2412.08642](https://doi.org/10.48550/arXiv.2412.08642
    )'
- en: Further reading
  id: totrans-381
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Koziolek, H., Gruener, S., & Ashiwal, V. (2023). *ChatGPT for PLC/DCS Control
    Logic Generation.* [https://doi.org/10.48550/arXiv.2305.15809](https://doi.org/10.48550/arXiv.2305.15809)
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koziolek, H., Gruener, S., & Ashiwal, V. (2023). *ChatGPT for PLC/DCS Control
    Logic Generation.* [https://doi.org/10.48550/arXiv.2305.15809](https://doi.org/10.48550/arXiv.2305.15809)
- en: Subscribe for a Free eBook
  id: totrans-383
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 订阅免费电子书
- en: New frameworks, evolving architectures, research drops, production breakdowns—*AI_Distilled*
    filters the noise into a weekly briefing for engineers and researchers working
    hands-on with LLMs and GenAI systems. Subscribe now and receive a free eBook,
    along with weekly insights that help you stay focused and informed.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 新框架、演进的架构、研究发布、生产分解——*AI_Distilled*将噪音过滤成每周简报，供与LLMs和GenAI系统实际工作的工程师和研究人员阅读。现在订阅，即可获得免费电子书，以及每周的洞察力，帮助您保持专注并获取信息。
- en: Subscribe at [https://packt.link/TRO5B](https://packt.link/TRO5B) or scan the
    QR code below.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 在[https://packt.link/TRO5B](https://packt.link/TRO5B)订阅或扫描下面的二维码。
- en: '![](img/Newsletter_QR_Code.png)'
  id: totrans-386
  prefs: []
  type: TYPE_IMG
  zh: '![Newsletter_QR_Code](img/Newsletter_QR_Code.png)'
