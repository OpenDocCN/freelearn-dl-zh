- en: Digit Classification Using TensorFlow Lite
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorFlow Lite 进行数字分类
- en: There has been a lot of progress in the field of **machine learning** (**ML**)
    in the last five years. These days, a variety of ML applications are being used
    in our daily lives and we don't even realize it. Since ML has taken the spotlight,
    it would be helpful if we could use it to run deep models on mobile devices, which
    is one of the most used devices in our daily life.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 过去五年，**机器学习**（**ML**）领域取得了很大进展。如今，许多 ML 应用已经进入我们的日常生活，而我们往往没有意识到。由于 ML 已成为焦点，如果我们能在移动设备上运行深度模型，那将非常有帮助，而移动设备正是我们日常生活中最常使用的设备之一。
- en: Innovation in mobile hardware, coupled with new software frameworks for deploying
    ML models on mobile devices, is proving to be one of the major accelerators for
    developing ML based applications on mobile or other edge devices like tablet..
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 移动硬件的创新，加上用于在移动设备上部署 ML 模型的新软件框架，正在成为开发基于 ML 的移动应用或其他边缘设备（如平板电脑）应用的主要推动力之一。
- en: 'In this chapter, we will learn about Google''s new library, TensorFlow Lite, which
    can be used to deploy ML models on mobile devices. We will train a deep learning
    model on the MNIST digits dataset and look at how we can convert this model into
    a mobile-friendly format by understanding the following concepts:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习谷歌的新库 TensorFlow Lite，该库可以用于在移动设备上部署 ML 模型。我们将使用 MNIST 数字数据集训练一个深度学习模型，并通过理解以下概念来了解如何将该模型转换为适合移动设备的格式：
- en: A brief introduction to TensorFlow Lite and its architecture
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow Lite 及其架构简介
- en: Introduction to Classification model evaluation metrics
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分类模型评估指标简介
- en: Developing a deep learning model on the MNIST dataset
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 MNIST 数据集上开发深度学习模型
- en: Converting the trained model into a mobile-friendly format using TensorFlow
    Lite
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow Lite 将训练好的模型转换为适合移动设备的格式
- en: Note that this chapter will not discuss building an Android application to deploy
    these models since this has been extensively documented in Google's TensorFlow
    tutorials ([https://www.tensorflow.org/lite/](https://www.tensorflow.org/lite/)).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，本章不会讨论如何构建 Android 应用来部署这些模型，因为这一内容在谷歌的 TensorFlow 教程中已有广泛文档记录（[https://www.tensorflow.org/lite/](https://www.tensorflow.org/lite/)）。
- en: What is TensorFlow Lite?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 TensorFlow Lite？
- en: Before we take a deep dive into TensorFlow Lite, let's try to understand what
    are the advantages of doing ML on edge devices like mobile/tablet and others.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨 TensorFlow Lite 之前，让我们先了解在边缘设备（如手机、平板电脑等）上进行 ML 的优势。
- en: '**Privacy**: If inference on a ML model can be performed on a device, user
    data doesn''t need to leave the device, which helps in preserving the privacy
    of the user.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隐私**：如果 ML 模型的推理可以在设备上进行，用户数据就不需要离开设备，从而有助于保护用户隐私。'
- en: '**Offline predictions**: The device doesn''t need to be connected to a network
    to make predictions on a ML model. This unlocks a lot of use cases in developing
    nations such as India where network connectivity is not so great.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**离线预测**：设备无需连接网络即可对 ML 模型进行预测。这为像印度这样的开发中国家提供了大量应用场景，因为这些地区的网络连接状况并不理想。'
- en: '**Smart devices**: This can also enable the development of smart home devices
    such as microwaves and thermostats with on-device intelligence.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**智能设备**：这也可以促进智能家居设备的发展，如带有设备智能的微波炉和恒温器。'
- en: '**Power efficient**: An on-device ML can be more power-efficient as there is
    no need to transfer data back and forth to the server.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节能**：设备上的 ML 推理可以更节能，因为无需将数据来回传输到服务器。'
- en: '**Sensor data utilization**: ML models can make use of rich sensor data since
    it is easily available on mobile.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**传感器数据利用**：ML 模型可以利用丰富的传感器数据，因为它在移动设备上易于获取。'
- en: 'However, mobile devices are not same as our desktops and laptops. There are
    different considerations when deploying the model on mobile or embedded devices
    such as:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，移动设备与我们的桌面和笔记本电脑不同。在将模型部署到移动或嵌入式设备时，需要考虑不同的因素，比如：
- en: '**Model size**:As we know, mobiles have limited memory and we can''t store
    a memory-heavy model on a device. There are two ways of handling this:'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型大小**：如我们所知，移动设备的内存有限，我们不能在设备上存储占用大量内存的模型。处理这个问题有两种方式：'
- en: We can round or quantize the weights of the model so that they require fewer
    floating-point representations. This is in line with our understanding that integers
    always require less memory to store than the floating point numbers.
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以对模型的权重进行四舍五入或量化，使其所需的浮点表示更少。这与我们的理解一致，即整数存储所需的内存通常少于浮点数。
- en: Since we only use devices for inferences or predictions, we can strip out all
    the training operations in our Tensorflow graph which are not useful for making
    predictions.
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于我们仅在设备上进行推断或预测，因此可以去除Tensorflow图中所有对进行预测无用的训练操作。
- en: '**Speed**:One of the important things for deploying models on mobile devices
    is the speed with which we can run an inference so that we gain a better user
    experience. Models have to be optimized in such a manner that they don''t exceed
    the latency budget on the phone but are still fast.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速度**：在移动设备上部署模型的重要因素之一是我们能够运行推断的速度，以获得更好的用户体验。必须优化模型，以确保它们不会超出手机的延迟预算，同时又保持快速。'
- en: '**Ease of deployment**: We need efficient frameworks/libraries so that deployment
    on mobile devices is very straightforward.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署简便性**：我们需要高效的框架/库，以便在移动设备上部署非常简单。'
- en: With these considerations in mind, Google has developed TensorFlow Lite, which
    is a lightweight version of original Tensorflow for deploying deep learning models
    on mobile and embedded devices.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些因素，Google开发了TensorFlow Lite，这是原始TensorFlow的轻量级版本，用于在移动和嵌入式设备上部署深度学习模型。
- en: 'To understand TensorFlow Lite, take a look at the following diagram, which
    shows its high-level architecture:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解TensorFlow Lite，请查看以下显示其高级架构的图表：
- en: '![](img/7ee6c212-fbed-4caf-b6fc-bd44dc9b4ee3.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7ee6c212-fbed-4caf-b6fc-bd44dc9b4ee3.png)'
- en: This architecture makes it evident that we need to convert a trained TF model
    into `.tflite` format. This format is different from usual TF models as it is
    optimized for inference on devices. We will learn about the conversion process
    in detail later in the chapter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构清楚地表明，我们需要将训练好的TF模型转换为`.tflite`格式。这种格式与通常的TF模型不同，因为它经过优化，可用于设备上的推断。我们将在本章后面详细学习转换过程。
- en: 'For now, let''s try to understand the major features of using TF Lite format:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们试着了解使用TF Lite格式的主要特点：
- en: The model is serialized and converted to a Flatbuffer format([https://google.github.io/flatbuffers/](https://google.github.io/flatbuffers/)).
    Flatbuffers have the advantage that data can be directly accessed without parsing/unpacking
    of large files that contain weights.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型被序列化并转换为Flatbuffer格式([https://google.github.io/flatbuffers/](https://google.github.io/flatbuffers/))。Flatbuffers的优点在于数据可以直接访问，无需解析/解包包含权重的大文件。
- en: Weights and biases of the model are pre-fused into TF lite format.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的权重和偏差已预先融合到TF Lite格式中。
- en: TF lite is cross-platform and can be deployed on Android, iOS, Linux, and hardware
    devices such as Raspberry Pi.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: TF Lite跨平台，可部署在Android、iOS、Linux和硬件设备（如Raspberry Pi）上。
- en: It includes an on-device interpreter that has been optimized for faster execution
    on mobile. The core interpreter with all of the supported operations is around
    400 KB, and 75 KB without the supported operations. This means that the model
    takes up little space on the device. Overall, the idea is to keep the parts of
    the model that are essential for inference and strip out all the other parts.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 它包括一个在设备上优化为更快执行的解释器。所有支持的操作的核心解释器大小约为400 KB，不支持操作时为75 KB。这意味着模型在设备上占用的空间很小。总体而言，理念是保留仅对推断至关重要的模型部分，并剥离所有其他部分。
- en: With innovation in hardware, many companies are also developing GPUs and Digital
    Signal Processors (DSPs) that are optimized for neural network inference. TF Lite
    provides the Android Neural Networks API, which can perform hardware acceleration
    on these devices.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 利用硬件创新，许多公司还在开发专为神经网络推断优化的GPU和数字信号处理器（DSP）。TF Lite提供了Android神经网络API，可以在这些设备上进行硬件加速。
- en: Classification Model Evaluation Metrics
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类模型评估指标
- en: Just building a model does not suffice; we need to make sure that our model
    functions well and gives us a good and accurate output. To do this, we need to
    understand some classification metrics that will be used to evaluate the model
    throughout this book.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅构建模型是不够的；我们需要确保我们的模型功能良好，并为我们提供良好和准确的输出。为此，我们需要了解一些分类指标，这些指标将用于全书中评估模型。
- en: 'Let''s begin by defining some building blocks of the metrics that will be used
    to evaluate the classification models. To do this, take a simple example of spam
    detection that is done by any online mailbox for reference. A spam email shall
    be considered to be of a positive class and the normal email to be of a negative
    class. We can summarize this spam detection model into four categories, which
    are illustrated in the following matrix:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义一些用于评估分类模型的度量标准开始。为此，取一个简单的垃圾邮件检测示例作为参考，任何在线邮箱都可以进行这样的检测。垃圾邮件将被视为正类，正常邮件则视为负类。我们可以将这个垃圾邮件检测模型总结为四类，如下矩阵所示：
- en: '| **True positives** (**TP**) | **False positives** (**FP**) |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| **真正类** (**TP**) | **假正类** (**FP**) |'
- en: '| Reality: Email is spam | Reality: Email is NOT spam |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 现实：邮件是垃圾邮件 | 现实：邮件不是垃圾邮件 |'
- en: '| Model Prediction: Email is spam | Model Prediction: Email is spam |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 模型预测：邮件是垃圾邮件 | 模型预测：邮件是垃圾邮件 |'
- en: '| **False negatives** (**FN**) | **True negatives** (**TN**) |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| **假负类** (**FN**) | **真负类** (**TN**) |'
- en: '| Reality: Email is spam | Reality: Email is NOT spam |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 现实：邮件是垃圾邮件 | 现实：邮件不是垃圾邮件 |'
- en: '| Model Prediction: Email is NOT spam | Model Prediction: Email is NOT spam
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 模型预测：邮件不是垃圾邮件 | 模型预测：邮件不是垃圾邮件 |'
- en: This matrix is also commonly known as the **confusion matrix.**
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这个矩阵通常也被称为 **混淆矩阵**。
- en: 'The three major metrics that we will use to define classifier quality, primarily
    in an unbalanced dataset, are as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用来定义分类器质量的三大主要度量标准，主要针对不平衡数据集，分别如下：
- en: '**Accuracy: **Accuracy is the most basic metric used for classification problems.
    It is defined as follows:'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准确度：**准确度是用于分类问题的最基本度量标准。其定义如下：'
- en: '![](img/8f86fe08-4b08-4072-ade1-c38090aa1b26.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f86fe08-4b08-4072-ade1-c38090aa1b26.png)'
- en: '**Precision: **Precision tries to measure the true positives out of all predicted
    positives from the model. If your Gmail doesn''t misclassify a lot of emails from
    your friends (or normal emails) and put them into spam, then it has very high
    precision. It is mathematically represented as follows:'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确度：**精确度试图衡量模型预测出的所有正类中真正的正类数量。如果你的 Gmail 没有将很多来自朋友（或正常邮件）的邮件错误分类到垃圾邮件中，那么它的精确度就非常高。其数学表示如下：'
- en: '![](img/f1baadc5-fcc9-4bcc-b39e-5fa42314b6d0.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f1baadc5-fcc9-4bcc-b39e-5fa42314b6d0.png)'
- en: '**Recall: **Recall tries to measure the number of values classified as positive
    out of all real positives in the dataset. In simple terms, if your Gmail doesn''t
    misclassify a lot of your spam emails as normal emails and sends them to your
    inbox, then it has very high recall:'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**召回率：**召回率试图衡量数据集中所有真实正类中被分类为正类的数量。简单来说，如果你的 Gmail 没有将很多垃圾邮件误分类为正常邮件并将其发送到收件箱，那么它的召回率就非常高：'
- en: '![](img/aa450a95-27b8-4bc7-940c-50fd19ba4e4b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aa450a95-27b8-4bc7-940c-50fd19ba4e4b.png)'
- en: Ideally, we want a model with high precision and high recall. However, there
    is always a trade-off between high precision and high recall in machine learning.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们希望模型具有高精确度和高召回率。然而，在机器学习中，精确度和召回率之间总是存在权衡。
- en: Classifying digits using TensorFlow Lite
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorFlow Lite 分类数字
- en: 'To complete this project, we will use the MNIST digit dataset, which is available
    in the TensorFlow datasets library ([https://www.tensorflow.org/guide/datasets](https://www.tensorflow.org/guide/datasets)).
    It consists of images of handwritten digits from 0 to 9\. The training dataset
    has 60,000 images and the testing set has 10,000 images. Some of the images in
    the dataset are as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成这个项目，我们将使用 MNIST 手写数字数据集，该数据集可在 TensorFlow 数据集库中找到（[https://www.tensorflow.org/guide/datasets](https://www.tensorflow.org/guide/datasets)）。它包含了从
    0 到 9 的手写数字图像。训练数据集有 60,000 张图像，测试集有 10,000 张图像。数据集中的一些图像如下所示：
- en: '![](img/dc9f7e6e-15de-4103-9800-449c941e283c.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dc9f7e6e-15de-4103-9800-449c941e283c.png)'
- en: If we take a look at TensorFlow Lite tutorials, we will see that the focus is
    on using pre-trained models such as Mobilenet or retraining the existing ones.
    However, none of these tutorials talk about building new models, which is something
    we will be doing here.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看 TensorFlow Lite 教程，会发现重点是使用预训练模型，如 Mobilenet 或重新训练现有的模型。然而，这些教程中没有谈到构建新模型，而这正是我们在这里要做的事情。
- en: Note that we specifically choose a simple model because at the time of writing
    this book, TensorFlow Lite doesn't have adequate support for all types of complex
    models
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们特别选择了一个简单的模型，因为在撰写本书时，TensorFlow Lite 对所有复杂模型的支持不足。
- en: We will use categorical cross entropy as the loss function for this classification
    problem. Categorical cross entropy was explained in detail in [Chapter 3](60549866-497e-4dfa-890c-6651f34cf8e4.xhtml), *Sentiment
    Analysis in Your Browser Using TensorFlow.js*, of this book. In this chapter,
    we have 10 different digits in the dataset, so we will use the categorical cross
    entropy over 10 classes.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用类别交叉熵作为这个分类问题的损失函数。类别交叉熵在本书的[第3章](60549866-497e-4dfa-890c-6651f34cf8e4.xhtml)《使用
    TensorFlow.js 在浏览器中进行情感分析》中有详细说明。在本章中，我们的数据集包含 10 个不同的数字，因此我们将使用类别交叉熵，分类数为 10。
- en: Pre-processing data and defining the model
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理与模型定义
- en: 'We need to pre-process our data for making it ready to feed into our model,
    define our model, and create an evaluation metric:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要对数据进行预处理，以使其准备好输入到模型中，定义我们的模型，并创建一个评估指标：
- en: Pre-process the data by ensuring the images are of shape 28x28x1 and converting
    the pixels into a float type variable for training. Also, here we define NUM_CLASSES
    = 10 as there are 10 different digits in the images.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过确保图像的形状为 28x28x1，并将像素转换为浮动类型变量来进行数据预处理，以供训练使用。同时，这里我们定义 NUM_CLASSES = 10，因为图像中有
    10 个不同的数字。
- en: '[PRE0]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Define the model as having two convolutional layers with the same filter sizes, two
    fully connected layers, two dropout layers with dropout probabilities of 0.25
    and 0.5 respectively, a Rectified Linear (ReLU) after every fully connected or
    convolutional layer except the last one, and one max pool layer. Also we add a
    Softmax activation to convert the output of the model to probabilities for each
    of the 10 digits. Note that we use this model as it produces good results. You
    can try improving the model by adding more layers or trying different shapes of
    the existing layers.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义模型为具有两个卷积层（使用相同的过滤器大小）、两个全连接层、两个丢弃层（丢弃概率分别为 0.25 和 0.5）、每个全连接层或卷积层后都有一个修正线性单元（ReLU，除最后一层外），以及一个最大池化层。此外，我们还添加了
    Softmax 激活函数，将模型的输出转化为每个数字的概率。请注意，我们使用此模型是因为它能产生良好的结果。你可以通过添加更多层或尝试不同形状的现有层来改进该模型。
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note that we have named our output tensor `softmax_tensor`, which will come
    in pretty handy when we try to convert this model into a TensorFlow Lite format.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们将输出张量命名为 `softmax_tensor`，这将在我们尝试将此模型转换为 TensorFlow Lite 格式时非常有用。
- en: 'Further define the following parameters for the model:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进一步为模型定义以下参数：
- en: Loss = Categorical Cross Entropy
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 损失 = 类别交叉熵
- en: Optimizer = AdaDelta. Adam optimizer, defined in  [Chapter 3](60549866-497e-4dfa-890c-6651f34cf8e4.xhtml), *Sentiment
    Analysis in Your Browser Using TensorFlow.js*, is an extension of AdaDelta. We
    use AdaDelta as it gives good result for this model. You can find more details
    about AdaDelta in the original paper ([https://arxiv.org/abs/1212.5701](https://arxiv.org/abs/1212.5701)).
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化器 = AdaDelta。Adam 优化器在[第3章](60549866-497e-4dfa-890c-6651f34cf8e4.xhtml)《使用
    TensorFlow.js 在浏览器中进行情感分析》中有介绍，它是 AdaDelta 的扩展。我们使用 AdaDelta，因为它在这个模型上能够获得良好的结果。你可以在原始论文中找到更多关于
    AdaDelta 的细节 ([https://arxiv.org/abs/1212.5701](https://arxiv.org/abs/1212.5701))。
- en: Evaluation Metric = Classification Accuracy
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估指标 = 分类准确度
- en: 'Code for defining these is as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 定义这些内容的代码如下：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Enable Tensorboard logging to visualize the model graph and training progress.
    Code is defined as follows:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用 TensorBoard 日志记录，以可视化模型图和训练进度。代码定义如下：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Train the model using the following parameters:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下参数训练模型：
- en: Epochs = 12
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练周期 = 12
- en: 'Batch Size = 128:'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量大小 = 128：
- en: '[PRE4]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We achieved **99.24% **accuracy on the test dataset with just 12 epochs.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在测试数据集上仅用 12 个训练周期达到了 **99.24%** 的准确率。
- en: Note that we use the `callbacks` parameter to log the training progress on TensorBoard.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们使用 `callbacks` 参数来记录 TensorBoard 上的训练进度。
- en: Converting TensorFlow model to TensorFlow Lite
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 TensorFlow 模型转换为 TensorFlow Lite
- en: Now that we have trained the model in the usual way, let's look at how we can
    convert this model into a TensorFlow Lite format.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经按照常规方法训练了模型，接下来我们来看看如何将该模型转换为 TensorFlow Lite 格式。
- en: 'The general procedure for conversion is illustrated in the following diagram:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 转换的通用流程如下面的图示所示：
- en: '![](img/5c787e53-0ca7-404e-82ad-051bff8c99c5.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5c787e53-0ca7-404e-82ad-051bff8c99c5.png)'
- en: 'The procedure is simple: we take a trained model, freeze the graph, optimize
    it for inference/prediction, and convert it into `.tflite` format. Before going
    further, let''s understand what we mean by Freeze Graph and Optimize For Inference:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程很简单：我们获取一个已训练的模型，冻结图形，优化它以进行推理/预测，并将其转换为 `.tflite` 格式。在继续之前，让我们先了解一下“冻结图形”和“优化推理”的含义：
- en: '**Freeze Graph : **Freeze graph operation effectively freezes the weights of
    the model by converting all the of the TF Variables as Constants. As you can imagine,
    having all of the weights as constants can save space compared to keeping them
    as variables. As we only perform inference on mobile (and not training), we don''t
    want to change the model weights anyway'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**冻结图：**冻结图操作通过将所有TF变量转换为常量，从而有效地冻结了模型的权重。正如你所想的，将所有权重作为常量可以节省空间，相比保持它们作为变量。在移动设备上我们只进行推理（而不是训练），所以我们不需要修改模型权重。'
- en: '**Optimize For Inference**: Once the graph is frozen, we remove all the operations
    in the graph which are not useful for inference. For example, Dropout operation
    is used to train the model such that it doesn''t overfit. However, there is absolutely
    no use of this operation during prediction on mobile.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**优化推理：**一旦图被冻结，我们会移除图中所有对推理无用的操作。例如，Dropout操作用于训练模型，以防过拟合。然而，在移动设备上的预测过程中，这个操作完全没有用处。'
- en: 'For the rest of this section, we will heavily use TensorBoard visualization
    ([https://www.TensorFlow.org/guide/summaries_and_tensorboard](https://www.tensorflow.org/guide/summaries_and_tensorboard))
    for graph visualization. :'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的剩余部分，我们将大量使用TensorBoard可视化（[https://www.TensorFlow.org/guide/summaries_and_tensorboard](https://www.tensorflow.org/guide/summaries_and_tensorboard)）来进行图形可视化。
- en: 'Once you have trained the model, you must have a file with the prefix `events.out.tfevents.` in
    your model folder. Go to the `logs` folder and type the following into terminal:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你训练了模型，你的模型文件夹中必须有一个以`events.out.tfevents.`为前缀的文件。进入`logs`文件夹并在终端中输入以下命令：
- en: '[PRE5]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: TensorBoard will start in port `6006` by default. Launch it by going to your
    browser and typing `localhost:6006` into the address bar*. *Once the Tensorboard
    opens, if you navigate to the Graphs tab at the top, you will be able to see the
    Tensorflow Graph of your model. In the following diagram, we illustrate the main
    graph, with annotations for the input tensor, output tensor, and training part
    of the graph. As we can see, we shouldn't keep anything from the training graph
    for inference/making predictions on mobile.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，TensorBoard将启动在`6006`端口。通过进入浏览器并在地址栏中输入`localhost:6006`启动它。一旦打开TensorBoard，如果你导航到顶部的Graph标签，你将能够看到你模型的Tensorflow图。在以下示意图中，我们展示了主图，并标注了输入张量、输出张量以及图中的训练部分。正如我们所看到的，我们不应该保留任何用于训练图的内容，因为它们对在移动设备上进行推理/预测没有任何用处。
- en: '![](img/7d23c048-2039-40ad-87e5-922447fddf5b.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7d23c048-2039-40ad-87e5-922447fddf5b.png)'
- en: Next implement a function `freeze_sesssion` which takes TF session as input,
    converts all variables into constants, and returns the frozen graph. After executing
    this function, you will obtain a frozen graph file named `MNIST_model.pb` in the `<model_folder>/logs/freeze` folder.
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来实现一个名为`freeze_sesssion`的函数，该函数接受TF会话作为输入，将所有变量转换为常量，并返回冻结的图。执行此函数后，你将在`<model_folder>/logs/freeze`文件夹中获得一个名为`MNIST_model.pb`的冻结图文件。
- en: '[PRE6]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, here is where it gets really strange: you can''t visualize the `MNIST_model.pb`
    file directly through TensorBoard. You need to write the graph in a format that
    TensorBoard can pick up. Execute the function `pb_to_tensorboard` mentioned below
    and you will see another file in `<model_folder>/logs/freeze` folder with prefix
    `events.out.tfevents`.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，事情变得有些奇怪：你不能通过TensorBoard直接可视化`MNIST_model.pb`文件。你需要将图写成TensorBoard能够识别的格式。执行下面提到的`pb_to_tensorboard`函数，你将会在`<model_folder>/logs/freeze`文件夹中看到一个以`events.out.tfevents`为前缀的文件。
- en: '[PRE7]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, start TensorBoard again with `logdir` as `<model_folder>/logs/freeze` and
    visualize the frozen graph. You will observe the you have stripped out most of
    the variables from the graph. The following diagram illustrates the frozen graph
    you will obtain:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用`<model_folder>/logs/freeze`作为`logdir`重新启动TensorBoard，并可视化冻结的图。你会看到，图中大多数变量已经被去除。以下示意图展示了你将获得的冻结图：
- en: '![](img/8c2b389b-9f29-42ec-b89a-3baa069e4159.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8c2b389b-9f29-42ec-b89a-3baa069e4159.png)'
- en: 'Next step is further trim to optimize it for inference. As explained before,
    we will remove Dropout variables from the graph as they are not useful for inference
    on mobile. However, there is no perfect way to remove those from the graph based
    on the existing TensorFlow functions/programs. The new improvements to TensorFlow
    Lite don''t work for this example, which suggests that they are still under development.
    Instead, you will have to manually specify the operations you want to remove and
    connect the input of the Dropout operations to the operations after them in the
    graph. For example, in the frozen graph, let''s say we want to remove the `dropout_3`
    operation. The following diagram shows the zoomed-in version of the frozen graph:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是进一步优化图形以便推理。如前所述，我们将从图中移除 Dropout 变量，因为它们对移动设备上的推理没有用。然而，根据现有的 TensorFlow
    函数/程序，没有完美的方法来移除这些操作。TensorFlow Lite 的新改进并不适用于本示例，这表明它们仍在开发中。相反，您必须手动指定要移除的操作，并将
    Dropout 操作的输入连接到图中它们之后的操作。例如，在冻结的图中，假设我们要移除`dropout_3`操作。下图显示了冻结图的放大版：
- en: '![](img/001f621c-afb7-42cb-ba3c-42b2af5ae316.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/001f621c-afb7-42cb-ba3c-42b2af5ae316.png)'
- en: In such a case, you will have to connect the `max_pooling2` operation directly
    to the `flatten_2` operation, thereby skipping the `dropout_3` op in the graph.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，您需要将`max_pooling2`操作直接连接到`flatten_2`操作，从而跳过图中的`dropout_3`操作。
- en: Execute the function `optimize_graph` mentioned below to remove all of the dropout
    ops in the graph. It manually flushes out all the Dropout operations from the
    graph. This will result in a new file named `MNIST_optimized.pb` under the `<model_folder>/logs/optimized` folder.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 执行下文提到的`optimize_graph`函数，以去除图中的所有 Dropout 操作。它会手动将所有 Dropout 操作从图中清除。这将导致在`<model_folder>/logs/optimized`文件夹下生成一个名为`MNIST_optimized.pb`的新文件。
- en: '[PRE8]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Again, to visualize the graph in TensorBoard, you need to convert it using the
    function `pb_to_tensorboar` defined in step 3 so that it's TensorBoard-friendly
    and obtain a new file with the prefix `events.out.tfevents` in the same folder.
    The following figure illustrates the graph you will obtain after removing the
    Dropout operations.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，为了在 TensorBoard 中可视化图形，您需要使用步骤 3 中定义的函数`pb_to_tensorboar`进行转换，以使其适应 TensorBoard，并在同一文件夹中获得一个以`events.out.tfevents`为前缀的新文件。下图展示了去除
    Dropout 操作后您将获得的图形。
- en: '![](img/30c933b9-110b-4297-8945-76860bc3e017.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/30c933b9-110b-4297-8945-76860bc3e017.png)'
- en: Note that getting rid of Dropout from the graph will not affect testing set
    accuracy as Dropout is not used for inference.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，从图中去除 Dropout 不会影响测试集的准确性，因为 Dropout 并未用于推理。
- en: 'The last step in obtaining the model in a mobile-friendly format is to convert
    it into a `.tflite` file. For this step, you will use `toco` command, which stands
    for TensorFlow Lite Optimizing Converter ([https://www.tensorflow.org/lite/convert/](https://www.tensorflow.org/lite/convert/)).
    The code is provided as follows:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取移动友好格式的模型的最后一步是将其转换为 `.tflite` 文件。对于此步骤，您将使用`toco`命令，该命令代表 TensorFlow Lite
    优化转换器（[https://www.tensorflow.org/lite/convert/](https://www.tensorflow.org/lite/convert/)）。以下是提供的代码：
- en: '[PRE9]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This will produce a file named `mnist.tflite` in `<model_folder>`. Essentially,
    this step is trying to convert the optimized graph into a Flatbuffer for efficient
    on-device inference.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成一个名为`mnist.tflite`的文件，保存在`<model_folder>`中。实质上，此步骤是将优化后的图形转换为 Flatbuffer，以便于高效的设备端推理。
- en: We will not cover deploying our project to the mobile device as its development
    is outside the scope of this book. However, feel free to take a look at TensorFlow
    Lite tutorials on how to deploy the TF Lite models Android ([https://www.tensorflow.org/lite/demo_android](https://www.tensorflow.org/lite/demo_android))
    or iOS ([https://www.tensorflow.org/lite/demo_ios](https://www.tensorflow.org/lite/demo_ios)).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会涵盖将我们的项目部署到移动设备上的内容，因为该部分开发超出了本书的范围。然而，您可以查看 TensorFlow Lite 的教程，了解如何将 TF
    Lite 模型部署到 Android（[https://www.tensorflow.org/lite/demo_android](https://www.tensorflow.org/lite/demo_android)）或
    iOS（[https://www.tensorflow.org/lite/demo_ios](https://www.tensorflow.org/lite/demo_ios)）。
- en: Summary
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Machine learning is at the edge of the next wave, where we try to make ML ubiquitous
    in our everyday life. It has several advantages such as offline access, data privacy,
    and so on.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习正处于下一波发展的前沿，我们正在努力将机器学习普及到日常生活中。它具有诸多优势，例如离线访问、数据隐私等。
- en: In this chapter, we looked at a new library from Google known as TensorFlow
    Lite, which has been optimized for deploying ML models on mobile and embedded
    devices. We understood the architecture of TensorFlow Lite, which converts the
    trained TensorFlow model into `.tflite` format. This is designed for inference
    at fast speed and low memory on devices. TensorFlow Lite also supports multiple
    platforms, such as Android, iOS, Linux, and Raspberry Pi.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了来自谷歌的一个新库——TensorFlow Lite，它已针对在移动设备和嵌入式设备上部署机器学习模型进行了优化。我们了解了 TensorFlow
    Lite 的架构，它将训练好的 TensorFlow 模型转换为 `.tflite` 格式。这是为在设备上进行快速推理和低内存占用而设计的。TensorFlow
    Lite 还支持多个平台，如 Android、iOS、Linux 和 Raspberry Pi。
- en: 'Next, we used the MNIST handwritten digit dataset to train a deep learning
    model. Subsequently, we followed the necessary steps to convert the trained model
    into `.tflite` format. The steps are as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用了 MNIST 手写数字数据集来训练一个深度学习模型。随后，我们按照必要的步骤将训练好的模型转换为 `.tflite` 格式。步骤如下：
- en: Froze the graph with variables converted to constants
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图冻结，将变量转换为常量
- en: Optimized the graph for inference by removing the unused ops like Dropout
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过移除未使用的操作（如 Dropout），优化了推理图
- en: Used **TensorFlow Optimization Converter Tool** (**toco**) to convert the optimized
    model to `.tflitte` format
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 **TensorFlow 优化转换工具** (**toco**) 将优化后的模型转换为 `.tflite` 格式
- en: At every step, we used TensorBoard to visualize the state of the graph.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在每一步，我们都使用 TensorBoard 来可视化图的状态。
- en: This is a very exciting field that is continuing to evolve, both in terms of
    hardware and software. Once this technology reaches maturity, it will open up
    new use cases and business models across the world.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常激动人心的领域，正在不断发展，无论是在硬件还是软件方面。一旦这项技术成熟，它将在全球范围内开辟新的使用场景和商业模式。
- en: In the next chapter, we'll create a project that will help us convert text to
    speech.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将创建一个项目，帮助我们将文本转换为语音。
- en: Questions
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'The following are the questions:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些问题：
- en: How is TensorFlow Lite different from usual TensorFlow?
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TensorFlow Lite 与常规 TensorFlow 有什么不同？
- en: Can you try and if you can build the model on a movie review dataset in  [Chapter
    3](60549866-497e-4dfa-890c-6651f34cf8e4.xhtml), *Sentiment Analysis in Your Browser
    Using TensorFlow.js*? Do you face some issues with Tensorflow Lite in that case?
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能尝试在[第 3 章](60549866-497e-4dfa-890c-6651f34cf8e4.xhtml)中使用电影评论数据集构建模型吗？*在浏览器中使用
    TensorFlow.js 进行情感分析*？如果是这样，你在使用 TensorFlow Lite 时遇到什么问题了吗？
- en: Can you try Adam optimizer and see if it improves the performance of the model?
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能尝试使用 Adam 优化器，看看它是否能提升模型的性能吗？
- en: Can you think you operations other than Dropout which are also not important
    for inference on mobile?
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能想到除了 Dropout 之外，也不重要于移动端推理的操作吗？
