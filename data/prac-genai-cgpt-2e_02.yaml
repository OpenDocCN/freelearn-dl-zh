- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Introduction to Generative AI
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式AI简介
- en: Hello! Welcome to *Practical Generative AI with ChatGPT*! In this book, we will
    explore the fascinating world of generative **artificial intelligence** (**AI**)
    and its groundbreaking applications, with a particular focus on ChatGPT.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你好！欢迎来到 *《ChatGPT的实用生成式AI》*！在这本书中，我们将探索生成式**人工智能**（**AI**）的迷人世界及其突破性的应用，特别关注ChatGPT。
- en: Generative AI has transformed the way we interact with machines, enabling computers
    to create, predict, and learn without explicit human instruction. Since the launch
    of OpenAI’s ChatGPT in November 2022, we have witnessed unprecedented advances
    in natural language processing, image and video synthesis, and many other fields.
    Whether you are a curious beginner or an experienced practitioner, this guide
    will equip you with the knowledge and skills to effectively navigate the exciting
    landscape of generative AI. So, let’s dive in and start the book with some definitions
    of the context we are moving in.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI已经改变了我们与机器互动的方式，使计算机能够在没有明确的人类指令的情况下进行创作、预测和学习。自2022年11月OpenAI的ChatGPT发布以来，我们在自然语言处理、图像和视频合成等多个领域见证了前所未有的进步。无论你是好奇的新手还是经验丰富的从业者，这本指南都将为你提供所需的知识和技能，以有效地探索生成式AI的激动人心领域。那么，让我们深入其中，从我们所处环境的定义开始这本书。
- en: In this chapter, we focus on the applications of generative AI to various fields,
    such as image synthesis, text generation, and music composition, highlighting
    the potential of generative AI to revolutionize various industries with concrete
    examples and recent developments. Being aware of the research journey toward the
    current state of the art of generative AI will give you an understanding of the
    foundations of recent developments and state-of-the-art models.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们关注生成式AI在各个领域的应用，如图像合成、文本生成和音乐创作，通过具体的例子和最新发展，突出生成式AI有潜力通过革命性的方式改变各个行业。了解生成式AI当前研究进展，将帮助你理解最近发展的基础和最先进模型。
- en: 'All this, we will cover through the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些，我们将在以下主题中涵盖：
- en: Introducing generative AI
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍生成式AI
- en: Exploring the domains of generative AI
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索生成式AI的领域
- en: Main trends and innovation after 2 years of ChatGPT
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ChatGPT发布两年后的主要趋势和创新
- en: Legal and ethical landscape of generative AI
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI的法律和伦理环境
- en: By the end of this chapter, you will be familiar with the exciting world of
    generative AI, its applications, the research history behind it, and the current
    developments that could have – and are currently having – a disruptive impact
    on businesses.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将熟悉生成式AI的激动人心世界，其应用，其背后的研究历史，以及可能——并且目前正在产生——对商业产生颠覆性影响的当前发展。
- en: Introducing generative AI
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍生成式AI
- en: Generative AI is an exciting branch of AI that focuses on creating new content,
    such as text, images, music, or even videos, that is often indistinguishable from
    something made by humans.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI是人工智能的一个令人兴奋的分支，专注于创建新的内容，如文本、图像、音乐，甚至视频，这些内容通常与人类制作的内容难以区分。
- en: 'To understand where it fits, let’s break it down:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解其适用范围，让我们将其分解：
- en: '**AI**: AI is the broad field that enables machines to mimic human-like tasks,
    such as decision-making or problem-solving.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI**：AI是一个广泛的领域，它使机器能够模仿类似人类的行为，如决策或解决问题。'
- en: '**Machine learning** (**ML**): Within AI, ML refers to techniques where machines
    learn patterns from data to make predictions or decisions without being explicitly
    programmed. The process of learning is made possible by sophisticated mathematical
    models called algorithms.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）：在人工智能领域，机器学习指的是机器从数据中学习模式以进行预测或决策的技术，而不需要明确编程。学习过程是通过称为算法的复杂数学模型实现的。'
- en: '**Deep learning** (**DL**): A subset of ML, DL uses complex algorithms inspired
    by the human brain to process large amounts of data and recognize intricate patterns.
    Because of their architecture – inspired by our brains and neural connections
    – these algorithms are called artificial neural networks.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**深度学习**（**DL**）：机器学习的一个子集，深度学习使用受人类大脑启发的复杂算法来处理大量数据并识别复杂的模式。由于它们的架构——受我们的大脑和神经连接的启发——这些算法被称为人工神经网络。'
- en: '**Definition**'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**定义**'
- en: An artificial neural network is a type of computer program designed to learn
    patterns by processing information in a way that’s inspired by the human brain.
    Instead of following strict, step-by-step rules, it uses interconnected “nodes”
    (like virtual brain cells) that work together and adjust their connections over
    time. By repeatedly reviewing examples, it gradually improves at tasks like recognizing
    images, understanding speech, or predicting outcomes—all without needing explicit
    instructions for each step.
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 人工神经网络是一种计算机程序，它通过模仿人脑处理信息的方式来学习模式。它不是遵循严格的、一步一步的规则，而是使用相互连接的“节点”（类似于虚拟脑细胞），这些节点共同工作并在时间中调整它们的连接。通过反复审查示例，它逐渐提高在识别图像、理解语音或预测结果等任务上的能力——所有这些都不需要为每一步提供明确的指令。
- en: Generative AI emerges from DL and uses specialized algorithms to generate something
    entirely new based on what it has learned from existing data. For example, a generative
    AI model trained on thousands of paintings could create brand-new art that blends
    different styles or themes.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI源于深度学习（DL），并使用专门的算法根据从现有数据中学到的内容生成全新的东西。例如，一个在数千幅画作上训练的生成式AI模型可以创造出融合不同风格或主题的新艺术作品。
- en: 'The following figure shows how these areas of research are related to each
    other:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了这些研究领域之间是如何相互关联的：
- en: '![](img/B31559_01_01.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B31559_01_01.png)'
- en: 'Figure 1.1: Relationship between AI, ML, DL, and generative AI'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1：AI、ML、DL和生成式AI之间的关系
- en: Generative AI models are trained on vast amounts of data and then they can generate
    new examples based on user’s requests. And the game-changer element here is that
    these requests are made in the easiest way possible – using our natural language.
    These models are called **large language models** (**LLMs**).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI模型在大量数据上进行训练，然后可以根据用户请求生成新的示例。这里的变革性元素在于，这些请求是以最简单的方式提出的——使用我们的自然语言。这些模型被称为**大型语言模型**（**LLMs**）。
- en: '**Definition**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: LLMs are a type of artificial neural network featured by a particular architectural
    framework called “Transformer.” They are characterized by a huge number of parameters
    (in the order of billions) and have been trained on billions of words. Given the
    training set, LLMs are capable of inferring language patterns and intents in user
    queries and generating natural language responses.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）是一种具有特定架构框架“Transformer”的人工神经网络。它们以数十亿个参数（数量级）为特征，并在数十亿个单词上进行训练。给定训练集，LLMs能够从用户查询中推断语言模式和意图，并生成自然语言响应。
- en: The possibility of interacting in natural language with LLMs is disruptive,
    and a whole new science has been born around that activity. This science is called
    “prompt engineering,” named after the term “prompt,” which we are going to cover
    in *Chapter 3*.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 与大型语言模型（LLMs）进行自然语言交互的可能性具有颠覆性，围绕这一活动诞生了一门全新的科学。这门科学被称为“提示工程”，这个名字来源于“提示”这个词，我们将在*第3章*中进行介绍。
- en: '**Definition**'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: A prompt is the specific text, question, or description you provide to a generative
    AI model to guide it toward producing the kind of output you want—whether that’s
    a helpful explanation, a creative story, or a detailed solution. How you phrase
    the prompt can greatly affect the AI’s response. This practice of carefully designing
    and refining prompts, often called “prompt engineering,” involves experimenting
    with different word choices, instructions, and formats to improve both the quality
    and accuracy of the AI’s output. By learning how to craft effective prompts, you
    help ensure the AI more consistently gives you results that are useful, engaging,
    and aligned with your goals.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 提示是你提供给生成式AI模型的具体文本、问题或描述，以引导它产生你想要的结果——无论是有用的解释、一个创意故事，还是详细的解决方案。你如何措辞提示可以极大地影响AI的响应。这种精心设计和完善提示的做法，通常被称为“提示工程”，涉及对不同词汇选择、指令和格式的实验，以提高AI输出的质量和准确性。通过学习如何制作有效的提示，你帮助确保AI更一致地给出有用、吸引人且符合你目标的结果。
- en: Even though text understanding and generation is probably one of the most outstanding
    features of Generative AI, this field covers many domains, which we will cover
    next.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管文本理解和生成可能是生成式AI最突出的功能之一，但这个领域涵盖了众多领域，我们将在下一部分进行介绍。
- en: Domains of generative AI
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式AI的领域
- en: In recent years, generative AI has made significant advancements and has expanded
    its applications to a wide range of domains, such as art, music, fashion, and
    architecture. In some of them, it is indeed transforming the way we create, design,
    and understand the world around us. In others, it is improving and making existing
    processes and operations more efficient.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，生成式人工智能取得了显著进步，并将其应用扩展到艺术、音乐、时尚和建筑等多个领域。在这些领域中，它确实正在改变我们创造、设计和理解周围世界的方式。在其他领域，它正在改进现有流程和操作，使其更加高效。
- en: For example, in the context of the pharmaceutical industry, generative AI is
    revolutionizing drug discovery by enabling the rapid design of novel therapeutic
    molecules, thereby significantly reducing development timelines and costs. By
    analyzing extensive datasets of chemical and biological information, generative
    AI models can identify promising drug candidates and predict their interactions
    within the human body. For instance, Insilico Medicine utilized generative AI
    to develop ISM001-055, a drug candidate for idiopathic pulmonary fibrosis, which
    progressed to Phase II clinical trials in 2023 (https://insilico.com/blog/first_phase2).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在制药行业的背景下，生成式人工智能通过快速设计新型治疗分子，正在彻底改变药物发现，从而显著缩短开发周期和成本。通过分析大量的化学和生物信息数据集，生成式人工智能模型可以识别有希望的药物候选物并预测它们在人体内的相互作用。例如，Insilico
    Medicine利用生成式人工智能开发了ISM001-055，这是一种用于治疗特发性肺纤维化的药物候选物，于2023年进入II期临床试验（[Insilico
    Medicine的博客：首个II期临床试验](https://insilico.com/blog/first_phase2)）。
- en: Another example is the way generative AI is revolutionizing game development
    by enabling the creation of dynamic and adaptive environments that respond to
    player actions, thereby enhancing immersion and replayability. By leveraging generative
    AI, developers can procedurally generate vast, ever-changing game worlds, ensuring
    that each playthrough offers a unique experience. This technology facilitates
    the creation of realistic **non-playable characters** (**NPCs**) with behaviors
    that adapt to player interactions, making game narratives more engaging. Additionally,
    generative AI streamlines the development process by automating asset creation,
    which reduces production time and costs.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是生成式人工智能如何通过允许创建对玩家动作做出反应的动态和自适应环境，从而革命性地改变游戏开发。通过利用生成式人工智能，开发者可以程序性地生成庞大且不断变化的游戏世界，确保每次游玩都提供独特的体验。这项技术促进了具有适应玩家互动行为的真实**非玩家角色**（NPCs）的创建，使游戏叙事更加引人入胜。此外，生成式人工智能通过自动化资产创建简化了开发过程，从而减少了生产时间和成本。
- en: As a result, developers can focus more on crafting innovative gameplay mechanics
    and rich storytelling, ultimately delivering more personalized and captivating
    gaming experiences (https://www.xcubelabs.com/blog/generative-ai-in-game-development-creating-dynamic-and-adaptive-environments/).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，开发者可以更多地专注于创造创新的游戏玩法机制和丰富的叙事，最终提供更加个性化和吸引人的游戏体验（[生成式人工智能在游戏开发中的应用：创建动态和自适应环境](https://www.xcubelabs.com/blog/generative-ai-in-game-development-creating-dynamic-and-adaptive-environments/)）。
- en: Lastly, generative AI can have a great impact on advertising and visual asset
    generation. For example, in March 2023, Coca-Cola launched the “Create Real Magic”
    platform (https://www.coca-colacompany.com/media-center/coca-cola-invites-digital-artists-to-create-real-magic-using-new-ai-platform),
    inviting digital artists worldwide to craft original artwork using iconic brand
    assets from its archives. Developed in collaboration with OpenAI and Bain & Company,
    this innovative platform combines the capabilities of GPT-4 and DALL-E, enabling
    users to generate unique pieces that blend Coca-Cola’s heritage with modern AI
    technology. Participants had the opportunity to submit their creations for a chance
    to be featured on Coca-Cola’s digital billboards in New York’s Times Square and
    London’s Piccadilly Circus, exemplifying the brand’s commitment to fostering creativity
    through cutting-edge technology. These are just a few examples of how generative
    AI can reshape business processes.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，生成式人工智能对广告和视觉资产生成也有重大影响。例如，2023年3月，可口可乐推出了“创造真实魔法”平台（[可口可乐邀请全球数字艺术家使用新的AI平台创造真实魔法](https://www.coca-colacompany.com/media-center/coca-cola-invites-digital-artists-to-create-real-magic-using-new-ai-platform)），邀请全球数字艺术家使用其档案中的标志性品牌资产创作原创艺术品。该平台与OpenAI和Bain
    & Company合作开发，结合了GPT-4和DALL-E的能力，使用户能够生成融合可口可乐遗产与现代AI技术的独特作品。参与者有机会提交他们的作品，以获得在纽约时代广场和伦敦皮卡迪利广场的可口可乐数字广告牌上展示的机会，这体现了品牌通过尖端技术培养创造力的承诺。这些只是生成式人工智能如何重塑业务流程的几个例子。
- en: Now, the fact that generative AI is used in many domains also implies that its
    models can deal with different kinds of data, from natural language to audio or
    images. In the next section, we’ll explore how generative AI models address different
    types of data and domains.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，生成式AI在许多领域的应用也意味着其模型可以处理不同类型的数据，从自然语言到音频或图像。在下一节中，我们将探讨生成式AI模型如何处理不同类型的数据和领域。
- en: Text generation
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文本生成
- en: The evolution of text generation within AI has been a journey from early theoretical
    concepts to today’s sophisticated language models. The 1950s marked the formal
    inception of AI as a field, with pioneers like Alan Turing exploring machine intelligence.
    Early efforts in **natural language processing** (**NLP**) during the 1960s and
    1970s led to programs such as ELIZA, which simulated conversation through pattern
    matching. The 1980s and 1990s saw the development of statistical models that improved
    language modeling by probabilistically predicting word sequences. The advent of
    ML algorithms during this period further advanced text generation capabilities.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI中，文本生成的演变是一段从早期的理论概念到今天复杂语言模型的旅程。20世纪50年代标志着人工智能作为一个领域的正式诞生，先驱如艾伦·图灵探索了机器智能。20世纪60年代和70年代的早期**自然语言处理**（NLP）努力导致了ELIZA等程序的出现，这些程序通过模式匹配模拟对话。20世纪80年代和90年代，统计模型的发展通过概率预测词序列来改进语言建模。在这一时期，机器学习算法的出现进一步提升了文本生成能力。
- en: A significant breakthrough occurred in 2017 with the introduction of the Transformer
    architecture which, as aforementioned, is the framework that features today’s
    LLMs.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 2017年，随着Transformer架构的引入，发生了重大突破，正如之前所述，这是今天LLMs所采用的框架。
- en: The unique element of this new series of models featuring the landscape of generative
    AI is that – once they are trained – they can be consumed, queried, and instructed
    in the easiest way possible. The introduction of LLMs marked a paradigm shift
    in the context of AI since no advanced skills were needed to benefit from them.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这一系列新模型中，以生成式AI的景观为特色的独特之处在于——一旦它们被训练——它们可以通过最简单的方式被消费、查询和指令。LLMs的引入标志着AI领域的一个范式转变，因为不需要高级技能就能从中受益。
- en: Today, one of the greatest applications of generative AI—and the one we are
    going to cover the most throughout this book—is its ability to produce new content
    in natural language. Indeed, generative AI models can be used to generate new
    coherent and grammatically correct text in different languages, such as articles,
    poetry, and product descriptions. They can also extract relevant features from
    text such as keywords, topics, or full summaries.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，生成式AI最伟大的应用之一——也是我们将在整本书中最多讨论的应用——是其能够在自然语言中生成新内容的能力。确实，生成式AI模型可以用于生成不同语言中新的连贯且语法正确的文本，如文章、诗歌和产品描述。它们还可以从文本中提取相关特征，如关键词、主题或完整摘要。
- en: 'Here is an example of working with GPT-4o, one of the latest models released
    by OpenAI and available through ChatGPT:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个使用GPT-4o的例子，这是OpenAI最新发布的模型之一，并通过ChatGPT提供：
- en: '![A screenshot of a computer  Description automatically generated](img/B31559_01_02.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，描述自动生成](img/B31559_01_02.png)'
- en: 'Figure 1.2: Example of ChatGPT responding to a user’s query in natural language'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2：ChatGPT以自然语言回应用户查询的示例
- en: As you can see, the model was not only able to answer my question with an explanation
    of what a proton is; it also adapted its style and jargon to a specific target
    audience – in my case, a 5-year-old child. This is remarkable since it paves the
    way for many scenarios of hyper-personalization that were not possible before.
    In the next chapters, we will cover many examples of that.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，该模型不仅能够用解释质子是什么的方式来回答我的问题；它还能根据特定的目标受众调整其风格和术语——在我这个例子中，是一个5岁的孩子。这一点非常了不起，因为它为许多以前不可能的超个性化场景铺平了道路。在接下来的章节中，我们将探讨许多这样的例子。
- en: ChatGPT is the main focus of this book, and in the upcoming chapters, you will
    see examples that showcase this powerful application.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT是本书的重点，在接下来的章节中，你将看到展示这一强大应用功能的示例。
- en: Now, we will move on to image generation.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将转向图像生成。
- en: Image generation
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像生成
- en: One of the earliest and most well-known examples of generative AI in image synthesis
    is the **generative adversarial network (GAN)** architecture introduced in the
    2014 paper by I. Goodfellow et al., *Generative Adversarial Networks*. The purpose
    of GANs is to generate realistic images that are indistinguishable from real images.
    This ability has several interesting business applications, such as generating
    synthetic datasets for training computer vision models, generating realistic product
    images, and generating realistic images for virtual reality and augmented reality
    applications.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 在图像合成中最早的也是最著名的例子之一是 I. Goodfellow 等人在 2014 年发表的论文中引入的 **生成对抗网络（GAN**）架构，*Generative
    Adversarial Networks*。GANs 的目的是生成与真实图像难以区分的逼真图像。这种能力有几种有趣的应用，例如生成用于训练计算机视觉模型的合成数据集，生成逼真的产品图像，以及生成用于虚拟现实和增强现实应用的逼真图像。
- en: Then, in 2021, a new generative AI model was introduced in this field by OpenAI,
    **DALL-E**. Different from GANs, the DALL-E model is designed to generate images
    from descriptions in natural language and can generate a wide range of images.
    The main difference here is that while GANs are often used to create or improve
    realistic images, models like DALL-E are ideal for visual creativity, turning
    any description in natural language into an illustration.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在 2021 年，OpenAI 在这个领域引入了一个新的生成式 AI 模型 **DALL-E**。与 GANs 不同，DALL-E 模型旨在从自然语言描述中生成图像，并且可以生成各种图像。这里的主要区别在于，虽然
    GANs 通常用于创建或改进逼真的图像，但像 DALL-E 这样的模型非常适合视觉创造力，将任何自然语言描述转化为插图。
- en: DALL-E has great potential in creative industries such as advertising, product
    design, and fashion to create unique and creative images.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: DALL-E 在广告、产品设计、时尚等创意产业中具有巨大的潜力，可以创建独特且富有创意的图像。
- en: 'Since its first release to the time of writing (December 2024), DALL-E has
    improved dramatically, as you can see in the following examples. Below is an artistic
    creation by DALL-E at the dawn of its life:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '从其首次发布到撰写本书的时间（2024 年 12 月），DALL-E 的改进非常显著，以下是一些示例。以下是在 DALL-E 生命之初的艺术创作： '
- en: '![](img/B31559_01_03.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_01_03.png)'
- en: 'Figure 1.3: Images generated by DALL-E with a natural language prompt as input'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3：DALL-E 使用自然语言提示作为输入生成的图像
- en: 'Let’s now see what **DALL-E3**, the most recent version of the model at the
    time of writing this book, can produce (here, we will use Microsoft Image Creator,
    powered by DALL-E3\. You can try it at https://copilot.microsoft.com/images/create):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看在撰写本书时最新的模型版本 **DALL-E3** 可以产生什么（在这里，我们将使用由 DALL-E3 驱动的 Microsoft Image
    Creator，您可以在 https://copilot.microsoft.com/images/create 尝试）：
- en: '![A screenshot of a computer  Description automatically generated](img/B31559_01_04.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，描述自动生成](img/B31559_01_04.png)'
- en: 'Figure 1.4: Images generated by DALL-E3 with a natural language prompt as input'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4：DALL-E3 使用自然语言提示作为输入生成的图像
- en: It’s impressive to see the level of improvement of this model in less than 2
    years. We are just scraping the surface of the massive improvements occurring
    at a fast pace.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在不到 2 年的时间里看到这个模型的改进水平令人印象深刻。我们只是触及了正在快速发生的巨大改进的表面。
- en: Music generation
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 音乐生成
- en: The first approaches to generative AI for music generation trace back to the
    1950s, with research in the field of algorithmic composition, a technique that
    uses algorithms to generate musical compositions. In 1957, Lejaren Hiller and
    Leonard Isaacson created the *Illiac Suite* for *String Quartet* (https://www.youtube.com/watch?v=n0njBFLQSk8),
    the first piece of music entirely composed by AI. Since then, the field of generative
    AI for music has been the subject of ongoing research.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式 AI 用于音乐生成的最初方法可以追溯到 1950 年代，该领域的研究是算法作曲，这是一种使用算法生成音乐作品的技术。在 1957 年，Lejaren
    Hiller 和 Leonard Isaacson 为 *String Quartet* 创建了 *Illiac Suite*（https://www.youtube.com/watch?v=n0njBFLQSk8），这是第一首完全由
    AI 作曲的音乐作品。从那时起，生成式 AI 在音乐领域的应用一直是持续研究的主题。
- en: Among recent years’ developments, new architectures and frameworks have become
    widespread among the general public, such as the WaveNet architecture introduced
    by Google in 2016, which has been able to generate high-quality audio samples,
    and the Magenta project, also developed by Google, which uses **recurrent neural
    networks** (**RNNs**) and other ML techniques to generate music and other forms
    of art.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在近年来的发展中，新的架构和框架在公众中变得普遍，例如 Google 在 2016 年引入的 WaveNet 架构，它能够生成高质量的音频样本，以及由
    Google 开发的 Magenta 项目，该项目使用 **循环神经网络**（**RNNs**）和其他机器学习技术来生成音乐和其他艺术形式。
- en: '**Definition**'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: '**RNNs** are a type of neural network designed to process sequential data by
    retaining information from previous inputs through a loop-like structure. This
    allows them to recognize patterns and dependencies over time, making them ideal
    for tasks like language modeling, time-series prediction, and speech recognition.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**RNNs**是一种神经网络，通过循环结构保留先前输入的信息来处理序列数据。这使得它们能够识别随时间变化的模式和依赖关系，因此非常适合语言建模、时间序列预测和语音识别等任务。'
- en: In 2020, OpenAI also announced Jukebox, a neural network that generates music
    when provided with genre, artist, and lyrics as input.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 2020年，OpenAI还宣布了Jukebox，这是一个神经网络，当提供流派、艺术家和歌词作为输入时，可以生成音乐。
- en: These and other frameworks became the foundations of many AI composer assistants
    for music generation. An example is Flow Machines, developed by Sony CSL Research.
    This generative AI system was trained on a large database of musical pieces to
    create new music in a variety of styles. It was used by French composer Benoît
    Carré to compose an album called *Hello World* (https:// www.helloworldalbum.net/),
    which features collaborations with several human musicians.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这些以及其他框架成为了许多音乐生成人工智能助手的基石。例如，索尼CSL研究开发的Flow Machines。这个生成式人工智能系统在大量音乐作品数据库上进行了训练，以创作出多种风格的新音乐。法国作曲家本诺·卡雷（Benoît
    Carré）使用它创作了一张名为《Hello World*》（https://www.helloworldalbum.net/）的专辑，其中包含与多位人类音乐家的合作。
- en: 'Here, you can see an example of a track generated entirely by Music Transformer,
    one of the models within the Magenta project:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到一个完全由Music Transformer生成的曲目示例，它是Magenta项目中的一个模型：
- en: '![](img/B31559_01_05.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_01_05.png)'
- en: 'Figure 1.5: Music Transformer allows users to listen to musical performances
    generated by AI (https://magenta.tensorflow.org/music-transformer)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5：音乐Transformer允许用户聆听由AI生成的音乐表演（https://magenta.tensorflow.org/music-transformer）
- en: Another incredible application of generative AI within the music domain is speech
    synthesis. This refers to AI tools that can create audio based on text inputs
    in the voices of well-known singers.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能在音乐领域的另一个令人惊叹的应用是语音合成。这指的是能够根据文本输入创建音频的人工智能工具，并以知名歌手的声音输出。
- en: For example, if you have always wondered how your songs would sound if Lady
    Gaga performed them, well, you can now fulfill your dreams with tools such as
    FakeYou *Text to Speech* (https://fakeyou.com/tts) or UberDuck.ai (https://uberduck.ai/)!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你一直想知道如果你的歌曲由Lady Gaga演唱会是什么样子，那么现在，你可以通过像FakeYou *Text to Speech*（https://fakeyou.com/tts）或UberDuck.ai（https://uberduck.ai/）这样的工具来实现你的梦想！
- en: '![](img/B31559_01_06.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_01_06.png)'
- en: 'Figure 1.6: Text-to-speech synthesis with fakeyou.com'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.6：fakeyou.com的文本到语音合成
- en: The results are really impressive! If you want to have fun, you can also try
    voices from your favorite cartoons, such as *Winnie the Pooh*. The only thing
    you need to do is input the text of the song you want your favorite voice to sing
    aloud.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 结果非常令人印象深刻！如果你想找乐子，你还可以尝试你最喜欢的卡通中的声音，比如*维尼熊*。你需要做的只是输入你希望你最喜欢的声音大声唱出的歌曲文本。
- en: 'Let’s go even further. What if we could generate a song from scratch, just
    asking the generative AI to do that for us in natural language? Well, we can do
    that seamlessly today and without any knowledge about music. Among the generative
    AI products that are rising in the music market today is Suno, whose mission is
    *“[...]building a future where anyone can make great music. Whether you’re a shower
    singer or a charting artist, we break barriers between you and the song you dream
    of making. No instrument needed, just imagination. From your mind to music.”*
    (source: https://suno.com/about).'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更进一步。如果我们能够从头开始生成一首歌，只需让生成式人工智能以自然语言为我们完成这项任务，那会怎么样呢？嗯，我们今天可以无缝地做到这一点，而且不需要任何音乐知识。在当今音乐市场上崛起的生成式人工智能产品中，Suno就是其中之一，其使命是*“[...]构建一个任何人都可以创作出伟大音乐的未来。无论你是淋浴歌手还是排行榜上的艺术家，我们都打破了你们与梦想中的歌曲之间的障碍。无需乐器，只需想象力。从你的心中到音乐。”*（来源：https://suno.com/about）。
- en: '![A screenshot of a computer  Description automatically generated](img/B31559_01_07.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  自动生成的描述](img/B31559_01_07.png)'
- en: 'Figure 1.7: Example of an entire song generated by Suno.com from a description
    in natural language'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.7：Suno.com从自然语言描述中生成的整首歌曲的示例
- en: As you can see, on the left-hand side of the picture, I provided a very brief
    song description in natural language – this was my prompt. From that, the model
    was able to generate not only the title and lyrics of a song (on the right-hand
    side) but also the music!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，在图片的左侧，我提供了一个非常简短的用自然语言描述的歌曲——这就是我的提示。基于此，模型不仅能够生成歌曲的标题和歌词（在右侧），还能生成音乐！
- en: Can you believe that it became my summer 2024 hit? If you want to create your
    summer hit too, you can try it for free at https://suno.com/create.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 你能相信它成为了我2024年夏天的热门歌曲吗？如果你想创作自己的夏日热门歌曲，你可以在https://suno.com/create免费尝试。
- en: Video generation
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视频生成
- en: Generative AI for video generation shares a similar timeline of development
    with image generation. One of the key developments in the field of video generation
    has been the development of GANs. Thanks to their accuracy in producing realistic
    images, researchers have started to apply this technique to video generation as
    well. One of the most notable examples of GAN-based video generation is DeepMind’s
    Veo, which generates high-quality videos from a single image and a sequence of
    motions. Another great example is NVIDIA’s **video-to-video synthesis** (**Vid2Vid**)
    DL-based framework, which uses GANs to synthesize high-quality videos from input
    videos.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 视频生成领域的生成式AI与图像生成领域的发展时间线相似。视频生成领域的一个关键发展是GANs（生成对抗网络）的发展。得益于它们在生成逼真图像方面的准确性，研究人员开始将这项技术应用于视频生成。基于GANs的视频生成的一个最显著的例子是DeepMind的Veo，它可以从单个图像和一系列动作生成高质量的视频。另一个很好的例子是NVIDIA的**视频到视频合成**（**Vid2Vid**）基于DL（深度学习）的框架，它使用GANs从输入视频中合成高质量的视频。
- en: 'The Vid2Vid system can generate temporally consistent videos, meaning that
    they maintain smooth and realistic motion over time. The technology can be used
    to perform a variety of video synthesis tasks, such as the following:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Vid2Vid系统可以生成时间上一致的视频，这意味着它们在时间上保持平滑和逼真的运动。这项技术可以用于执行各种视频合成任务，例如以下任务：
- en: Converting videos from one domain into another (for example, converting a daytime
    video into a nighttime video or a sketch into a realistic image)
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将视频从一个领域转换为另一个领域（例如，将白天视频转换为夜间视频或草图转换为逼真图像）
- en: Modifying existing videos (for example, changing the style or appearance of
    objects in a video)
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修改现有的视频（例如，改变视频中对象的风格或外观）
- en: Creating new videos from static images (for example, animating a sequence of
    still images)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从静态图像创建新的视频（例如，将一系列静态图像动画化）
- en: In September 2022, Meta’s researchers announced the general availability of
    **Make-A-Video** (https://makeavideo.studio/), a new AI system that allows users
    to convert their natural language prompts into video clips. Behind this technology,
    you can recognize many of the models that we mentioned in other domains – language
    understanding for the prompt, image and motion generation with image generation,
    and background music made by AI composers.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 2022年9月，Meta的研究人员宣布**Make-A-Video**（https://makeavideo.studio/）的通用版正式发布，这是一个新的AI系统，允许用户将他们的自然语言提示转换为视频片段。在这项技术背后，你可以认出许多我们在其他领域提到过的模型——用于提示的语言理解、使用图像生成进行图像和运动生成，以及由AI作曲家创作的背景音乐。
- en: 'Now, everything we’ve mentioned above pales in comparison to the latest text-to-video
    models. To name one, OpenAI announced a text-to-video model called **SORA** in
    February 2024 and released some early experiments:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们上面提到的所有内容与最新的文本到视频模型相比都显得黯然失色。以其中一个为例，OpenAI在2024年2月宣布了一种名为**SORA**的文本到视频模型，并发布了一些早期实验：
- en: '![A person in a black jacket and red dress standing on a wet street  Description
    automatically generated](img/B31559_01_08.png)![A group of mammoths in the snow  Description
    automatically generated](img/B31559_01_09.png)![A person in a space suit  Description
    automatically generated](img/B31559_01_10.png) ![A cartoon animal looking at a
    candle  Description automatically generated](img/B31559_01_11.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![一位身穿黑色夹克和红色连衣裙的人站在湿漉漉的街道上  自动生成的描述](img/B31559_01_08.png)![一群长毛象在雪中  自动生成的描述](img/B31559_01_09.png)![一位身穿宇航服的人  自动生成的描述](img/B31559_01_10.png)
    ![一只卡通动物看着蜡烛  自动生成的描述](img/B31559_01_11.png)'
- en: 'Figure 1.8: Videos generated by SORA from prompts in natural language. Source:
    https://openai.com/index/sora/'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.8：SORA从自然语言提示中生成的视频。来源：https://openai.com/index/sora/
- en: I do encourage you to visit the SORA webpage to have a look at the amazing videos
    it created. At the time of writing, SORA is not publicly available, as it is going
    through several tests by the OpenAI Red Team.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我确实鼓励您访问SORA网页，看看它创造的精彩视频。在撰写本文时，SORA尚未公开发布，因为它正在通过OpenAI红队进行多项测试。
- en: Overall, generative AI has impacted many domains for years, and some AI tools
    already consistently support artists, organizations, and general users. Despite
    the fact we’ve been experimenting and building applications with generative AI
    for only two years, there are already some consolidated trends and future innovations
    to keep in mind. Let’s explore them in the next section.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，生成式人工智能已经影响了多个领域多年，一些AI工具已经持续支持艺术家、组织和普通用户。尽管我们只用了两年时间在生成式人工智能上进行实验和构建应用，但已经有一些巩固的趋势和未来创新需要我们关注。让我们在下一节中探讨它们。
- en: Main trends and innovations
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主要趋势和创新
- en: From November 2022 to today, we have witnessed a huge amount of innovation in
    the field of generative AI. Many of these innovations are linked to the brand-new
    models developed and released to the public, like OpenAI’s GPT-4o and DALL-E3,
    but also Google Gemini, Meta Llama 3, Microsoft Phi3, and many others.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 从2022年11月至今，我们见证了生成式人工智能领域的大量创新。其中许多创新与公开推出的一系列全新模型有关，例如OpenAI的GPT-4o和DALL-E3，还有Google
    Gemini、Meta Llama 3、Microsoft Phi3以及其他许多模型。
- en: However, the most remarkable achievements probably lie in the way we interact
    with and build applications around those models. In this section, we are going
    to explore three main advancements that have marked the most popular reference
    architectures for generative-AI-powered applications.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，最引人注目的成就可能在于我们与这些模型互动以及围绕这些模型构建应用的方式。在本节中，我们将探讨三个主要进展，这些进展标志着生成式人工智能应用中最受欢迎的参考架构。
- en: Retrieval augmented generation
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检索增强生成
- en: One of the first limitations of ChatGPT and, generally speaking, of LLMs was
    the knowledge base cutoff. The knowledge of LLMs is limited to the training set
    they have been trained on and, although this can be exhaustive, it’s not up to
    date (in fact, once the model is trained, any new data or information that emerges
    afterward won’t be part of its knowledge, since it wasn’t included in the original
    training set). Plus, the data is likely missing the proprietary knowledge base
    that might be relevant for us or our organization. For example, if you ask ChatGPT,
    “What is my company’s policy for employee health insurance?”, the model won’t
    be able to answer since it has no access to this information.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT以及一般而言的LLM的第一个局限性是知识库截止点。LLM的知识仅限于它们训练的数据集，尽管这可能很全面，但并不更新（事实上，一旦模型训练完成，任何在此之后出现的新数据或信息都不会成为其知识的一部分，因为它们没有包含在原始训练集中）。此外，数据可能缺少对我们或我们的组织可能相关的专有知识库。例如，如果你问ChatGPT，“我公司的员工医疗保险政策是什么？”模型将无法回答，因为它无法访问这些信息。
- en: To bypass this limitation, a new framework was designed to allow LLMs to navigate
    through customized documentation that we can provide. This framework is called
    **retrieval augmented generation** (**RAG**).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了绕过这一限制，设计了一个新的框架，允许大型语言模型（LLM）在我们提供的定制文档中导航。这个框架被称为**检索增强生成**（**RAG**）。
- en: The idea behind RAG is to augment the LLM’s knowledge by adding external sources
    of information, yet without modifying the structure of the model at all.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: RAG背后的想法是通过添加外部信息源来增强LLM的知识，而无需对模型结构进行任何修改。
- en: '**Definition**'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: An embedding is a way to turn complex information—like words, sentences, or
    images—into a list of numbers (a vector). This makes it easier for a computer
    to understand what those words or sentences mean. If two pieces of text have similar
    meanings, their vectors will be close together in the numerical space. In other
    words, embeddings let computers measure how alike different inputs are based on
    their content, not just their exact wording.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入是将复杂信息（如单词、句子或图像）转换为数字列表（向量）的一种方式。这使得计算机更容易理解这些单词或句子的含义。如果两段文本具有相似的含义，它们的向量在数值空间中将彼此靠近。换句话说，嵌入让计算机根据内容而不是精确措辞来衡量不同输入的相似程度。
- en: For example, if two concepts are similar, then their vector representations
    should also be similar.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果两个概念相似，那么它们的向量表示也应该相似。
- en: '![](img/B31559_01_12.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B31559_01_12.png)'
- en: 'Figure 1.9: Example of vector representation of four different words'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.9：四个不同单词的向量表示示例
- en: 'In this example, we can see that the mathematical distance between the two
    vectors corresponding to “Queen” and “King” is more or less the same as the difference
    between “Woman” and “Man.” Semantically speaking, this makes sense, as we are
    talking about a similar relationship. A similar example might be applied to the
    relationship between countries and capital cities: once embedded in a vector space,
    the distance between “Italy” and “Rome” should be similar to the distance between
    “France” and “Paris” as they are mapping the same relationships.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们可以看到“Queen”和“King”对应的两个向量之间的数学距离与“Woman”和“Man”之间的差异大致相同。从语义上讲，这是有道理的，因为我们正在谈论类似的关系。一个类似的例子可以应用于国家和首都之间的关系：一旦嵌入到向量空间中，“Italy”和“Rome”之间的距离应该与“France”和“Paris”之间的距离相似，因为它们映射的是相同的关系。
- en: 'RAG is made of three phases:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: RAG由三个阶段组成：
- en: '**Retrieval**: Given a user’s query and its corresponding numerical representation,
    the most similar pieces of documents (those corresponding to the vectors that
    are closest to the user query’s vector) are retrieved and used as the base context
    for the LLM.'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**检索**：给定用户的查询及其对应的数值表示，检索出与用户查询向量最相似的文档片段（对应于与用户查询向量最近的向量），并将其用作LLM的基础上下文。'
- en: '![A close-up of a text box  Description automatically generated](img/B31559_01_13.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![文本框的特写  自动生成的描述](img/B31559_01_13.png)'
- en: 'Figure 1.10: Example of retrieving three different chunks from different documents,
    since they are represented by the closest vectors to the user query'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.10：从不同文档中检索三个不同片段的示例，因为它们由最接近用户查询的向量表示
- en: '**Augmentation**: The retrieved context is enriched through additional instructions,
    rules, safety guardrails, and similar practices that are typical of prompt engineering
    techniques (we will cover the topic of prompt engineering in *Chapter 3*).'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**增强**：通过额外的指令、规则、安全护栏以及类似提示工程技术的典型做法，检索到的上下文得到丰富（我们将在*第3章*中介绍提示工程的主题）。'
- en: '![](img/B31559_01_14.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B31559_01_14.png)'
- en: 'Figure 1.11: Example of adding more context to the retrieved chunks of documents'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.11：向检索到的文档片段添加更多上下文的示例
- en: '**Generation**: Based on the augmented context, the LLM generates the response
    to the user’s query.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**生成**：基于增强的上下文，LLM生成对用户查询的响应。'
- en: '![A screenshot of a computer screen  Description automatically generated](img/B31559_01_15.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  自动生成的描述](img/B31559_01_15.png)'
- en: 'Figure 1.12: Example of using the augmented context as the system message for
    the model to generate the final answer'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.12：使用增强上下文作为系统消息的示例，以供模型生成最终答案
- en: RAG combines the strengths of generative models and information retrieval systems
    to enhance the quality and relevance of generated content. Traditional generative
    models rely solely on their training data to produce responses, which can sometimes
    result in outdated or irrelevant information. RAG addresses this limitation by
    integrating external knowledge bases during the generation process.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: RAG结合了生成模型和信息检索系统的优势，以增强生成内容的质和相关性。传统的生成模型完全依赖于其训练数据来生成响应，这有时会导致过时或不相关的信息。RAG通过在生成过程中整合外部知识库来解决这一局限性。
- en: Multimodality
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多模态
- en: Earlier in this chapter, we looked at the various domains of generative AI,
    ranging from text to images, from videos to music. Typically, large foundation
    models tend to be domain-specific, as we saw for LLMs in the case of language
    understanding and generation, or DALL-E3 in the case of image generation.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的早期，我们探讨了生成式AI的各个领域，从文本到图像，从视频到音乐。通常，大型基础模型倾向于特定于领域，正如我们在语言理解和生成案例中看到的LLMs，或者在图像生成案例中的DALL-E3。
- en: However, the recent advances in generative AI have enabled the development of
    **large multimodal models** (**LMMs**) that can process and generate different
    types of data, such as text, images, audio, and video.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，近年来生成式AI的进步使得**大型多模态模型**（LMMs）的开发成为可能，这些模型可以处理和生成不同类型的数据，如文本、图像、音频和视频。
- en: LMMs share with *standard* LLMs the ability to generalize and adapt typical
    large foundation models. However, LMMs are capable of processing diverse data
    with the idea of mirroring the way humans interact with the surrounding ecosystem
    – that is, with all our senses.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: LMMs与**标准**LLMs共享泛化和适应典型大型基础模型的能力。然而，LMMs能够处理多样化的数据，其理念是模仿人类与周围生态系统互动的方式——也就是说，通过我们所有的感官。
- en: 'A great example of a multimodal model is OpenAI’s GPT-4o, which is able to
    interact with users via text, images, and audio. Take the following example:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态模型的一个很好的例子是 OpenAI 的 GPT-4o，它能够通过文本、图像和音频与用户进行交互。以下是一个例子：
- en: '![A screenshot of a computer  Description automatically generated](img/B31559_01_16.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，描述由系统自动生成](img/B31559_01_16.png)'
- en: 'Figure 1.13: Example of providing ChatGPT-4o with a picture and asking it to
    name the building'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.13：向 ChatGPT-4o 提供图片并要求它命名建筑物的示例
- en: As you can see, the model was able to analyze the image and reason over it.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，该模型能够分析图像并对它进行推理。
- en: 'Let’s now go ahead and ask the model to generate an illustration:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来要求模型生成一幅插图：
- en: '![A black and white drawing of a tall building  Description automatically generated](img/B31559_01_17.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![一幅黑白的高层建筑素描，描述由系统自动生成](img/B31559_01_17.png)'
- en: 'Figure 1.14: Example of ChatGPT-4o generating an illustration based on a previously
    provided picture'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.14：ChatGPT-4o 根据之前提供的图片生成插图的示例
- en: What sets LLMs apart is their ability to retain advanced reasoning capabilities,
    making them uniquely suited for tackling complex reasoning tasks across diverse
    data contexts, unlike traditional AI models. Let’s consider, for example, traditional
    computer vision models, which are task-specific, and they do not *reason* over
    an image, but rather perform tasks like detecting objects or extracting text from
    images. On the other hand, LMMs can use the same reasoning capabilities as LLMs,
    yet they can apply these capabilities to data other than text.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: LLM 与其他模型的不同之处在于它们保留高级推理能力，这使得它们特别适合在多样化的数据环境中处理复杂的推理任务，而传统的 AI 模型则不然。以传统的计算机视觉模型为例，它们是针对特定任务的，它们不会对图像进行推理，而是执行诸如检测对象或从图像中提取文本等任务。另一方面，LMMs
    可以使用与 LLM 相同的推理能力，但它们可以将这些能力应用于除文本以外的数据。
- en: 'Let’s consider this last example (showing only the first lines of the response):'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑这个最后的例子（只显示响应的前几行）：
- en: '![A crossword puzzle with text  Description automatically generated](img/B31559_01_18.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![带有文本的填字游戏，描述由系统自动生成](img/B31559_01_18.png)'
- en: 'Figure 1.15: Example of ChatGPT 4o solving a crossword game'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.15：ChatGPT 4o 解决填字游戏的示例
- en: 'As you can see, the model was able to:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，该模型能够：
- en: Read and understand the scenario the image is posing
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读并理解图像所呈现的场景
- en: Reason about it and solve the complex task that it is offering, which is solving
    a puzzle
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对其进行推理并解决它所提供的复杂任务，即解决谜题
- en: As you may imagine, this opens a landscape of applications in various industries,
    and we are going to see some concrete examples in the upcoming chapters.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所想，这为各个行业的应用开辟了一片天地，我们将在接下来的章节中看到一些具体的例子。
- en: AI agents
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI 代理
- en: In previous sections, we uncovered how LLMs are great when it comes to generating
    content. However, they lack one ability, which is taking action and interacting
    with the surrounding ecosystem that goes beyond the single user. For example,
    what if we want our LLM to be able not only to generate an amazing LinkedIn post
    but also publish it on our page?
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们揭示了 LLM 在生成内容方面的强大能力。然而，它们缺少一种能力，那就是采取行动并与周围生态系统进行交互，这种交互超越了单个用户。例如，如果我们想让我们的
    LLM 不仅能够生成一篇精彩的 LinkedIn 帖子，还能在我们页面上发布它呢？
- en: AI agents emerge as key players in overcoming this limitation. But what exactly
    are they? Agents can be seen as AI systems powered by LLMs that, given a user’s
    query, are able to interact with the surrounding ecosystem to the extent to which
    we allow them. The perimeter of the ecosystem is delimited by the tools (or plugins)
    we provide the agents with (in our previous example, we might provide the agent
    with a LinkedIn plugin so that it is able to post the generated content).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: AI 代理作为克服这一限制的关键角色出现。但它们究竟是什么呢？代理可以被看作是受 LLM 驱动的 AI 系统，在给定用户查询的情况下，能够与周围生态系统进行交互，直到我们允许它们做到的程度。生态系统的边界由我们提供给代理的工具（或插件）界定（在我们之前的例子中，我们可能给代理提供一个
    LinkedIn 插件，以便它能够发布生成的内容）。
- en: 'Agents are made of the following ingredients:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 代理由以下成分构成：
- en: An LLM, which acts as the reasoning engine of the AI system.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 LLM，作为 AI 系统的推理引擎。
- en: 'A system message, which instructs the agent to behave and think in a given
    way. For example, you can design an agent as a teaching assistant for students
    with the following system message: “You are a teaching assistant. Given a student’s
    query, NEVER provide the final answer, but rather provide some hints to get there.”'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个系统消息，指示代理以某种方式行为和思考。例如，你可以设计一个代理作为学生的教学助手，以下是一个系统消息：“你是一名教学助手。面对学生的查询，永远不要提供最终答案，而是提供一些提示来引导他们。”
- en: A set of tools the agent can leverage to interact with the surrounding ecosystem.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组代理可以利用的工具来与周围生态系统互动。
- en: 'AI agents are a perfect representation of the meaning of “LLM as reasoning
    engine of an application.” In fact, the beauty of agents is that they can pick
    the best tool to use to accomplish a user’s request. For example, let’s say we
    have an AI agent to produce LinkedIn content, and we provide it with two tools:
    a LinkedIn plugin and a web search plugin (each one with a correct description
    of its functionality). Let’s explore the behavior of the agent in three different
    scenarios:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: AI代理是“LLM作为应用程序推理引擎”这一含义的完美体现。实际上，代理的美丽之处在于它们可以选择最佳工具来完成用户的请求。例如，假设我们有一个AI代理来生成LinkedIn内容，我们向它提供两个工具：一个LinkedIn插件和一个网络搜索插件（每个都对其功能有正确的描述）。让我们探索代理在三个不同场景下的行为：
- en: '**Generate a story about a little dog walking around the mountains**: The agent
    will generate the story without using a plugin.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成一个关于一只小狗在山间漫步的故事**：代理将生成故事而不使用插件。'
- en: '**Generate a story about the current weather in Milan**: The agent will invoke
    the web search plugin to get the current weather in Milan.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成一篇关于米兰当前天气的故事**：代理将调用网络搜索插件以获取米兰的当前天气。'
- en: '**Generate a LinkedIn post about the current weather in Milan and publish it
    on my profile**: The agent will invoke the web search plugin to get the current
    weather in Milan and the LinkedIn plugin to post it on my profile.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成一篇关于米兰当前天气的LinkedIn帖子并发布在我的个人资料上**：代理将调用网络搜索插件以获取米兰的当前天气，并使用LinkedIn插件在我的个人资料上发布。'
- en: The combination of instructions and a set of plugins makes AI agents extremely
    versatile, and you can create highly specialized entities to address specific
    scenarios.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 指令和一组插件的组合使AI代理极其灵活，你可以创建高度专业化的实体来应对特定场景。
- en: And that’s not all.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这还不是全部。
- en: Why have only one agent if you can create your own crew of agents talking to
    and cooperating with each other? Imagine multiple agents, each one with a specific
    expertise and goal, communicating and interacting to accomplish a task. This is
    what **multi-agent applications** look like, and in the last few months, this
    pattern started showing very interesting results.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你可以创建自己的代理团队，相互交谈并合作，为什么只有一个代理呢？想象一下多个代理，每个代理都有特定的专业知识和目标，通过沟通和互动来完成一项任务。这就是**多代理应用程序**的样子，在过去的几个月里，这种模式开始显示出非常有趣的结果。
- en: Let’s consider the following example. We want to generate an elevator pitch
    about climate change. We need up-to-date information to do so (latest trends and
    research, future perspectives, and so on), as well as solid research grounded
    by academic papers. Plus, we need to be concise yet sharp and effective, delivering
    all the key information in a very short pitch.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下例子。我们想要生成一个关于气候变化的电梯演讲。为此，我们需要最新的信息（最新趋势和研究、未来展望等），以及基于学术论文的扎实研究。此外，我们需要简洁而尖锐、有效，在非常短的演讲中传达所有关键信息。
- en: 'Now, we could ask a single agent to do all of that, providing it with all the
    required tools and long instructions to accomplish the task. However, if the task
    gets very complex, a single agent might not be the best approach as it might lead
    to inaccurate results. Instead, let’s use a multi-agent approach, creating a team
    with the following AI professionals:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以要求一个代理完成所有这些工作，向它提供所有必需的工具和长指令来完成这项任务。然而，如果任务变得非常复杂，单个代理可能不是最佳方法，因为它可能导致不准确的结果。相反，让我们采用多代理方法，创建一个由以下AI专业人士组成的团队：
- en: 'A market analyst who can search the web for the latest news about climate change:
    This will be an agent with a web search plugin and specific instructions to search
    for news.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个能够搜索有关气候变化最新新闻的市场分析师：这将是一个具有网络搜索插件和特定搜索新闻指令的代理。
- en: 'An expert researcher who can easily navigate through academic research papers
    about climate change: This will be an agent with an Arxiv (a curated research-sharing
    platform) plugin and specific instructions on how to retrieve relevant information.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个能够轻松浏览关于气候变化学术研究论文的专家研究者：这将是一个带有Arxiv（一个精选的研究共享平台）插件和如何检索相关信息的具体指令的代理。
- en: 'An expert in public speaking who can easily consolidate all the information
    in one elevator pitch: This will be an agent with instructions on how to deliver
    perfect pitches.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个能够轻松将所有信息整合到一个电梯演讲中的公共演讲专家：这将是一个带有如何进行完美演讲的指令的代理。
- en: 'A critic who will review the pitch and propose some changes to the expert in
    public speaking, if needed: This will be an agent with instructions on how to
    review and improve a pitch by identifying pitfalls and areas of improvement.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个将审查提案并对公共演讲专家提出一些修改意见的评论家（如果需要的话）：这将是一个带有如何通过识别陷阱和改进区域来审查和改进提案的指令的代理。
- en: So, when the user asks the agents to generate an elevator pitch about the current
    issue of climate change, all the agents can start working on the project.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当用户要求代理生成关于当前气候变化问题的电梯演讲时，所有代理都可以开始工作。
- en: There are many frameworks that can help developers with multi-agent applications
    (including AutoGen, LangGraph, and CrewAI), especially when it comes to the *flow*
    that we want our agents to follow. For example, we might want to enforce a specific
    number of iterations; or that all agents are invoked at least once; or even to
    involve us, as users, in every iteration to provide further feedback to be incorporated
    in the upcoming iteration.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多框架可以帮助开发者处理多代理应用（包括AutoGen、LangGraph和CrewAI），尤其是在我们希望代理遵循的*流程*方面。例如，我们可能希望强制执行特定的迭代次数；或者所有代理至少被调用一次；甚至可能涉及我们，作为用户，在每次迭代中提供进一步反馈以纳入即将到来的迭代。
- en: At the time of writing, the multi-agent framework is showing promising advancements,
    and it is a glimpse of the outstanding reasoning capabilities behind LLMs and
    how they can unlock new ways of problem-solving.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，多代理框架显示出有希望的发展，这是LLMs背后卓越推理能力的缩影，以及它们如何解锁新的问题解决方式。
- en: Small language models
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小型语言模型
- en: LLMs are, unsurprisingly, large. This means that the architecture of an **ANN**
    featuring LLMs is made of a huge number of parameters, in the order of billions.
    Typically, a large number of parameters is associated with a better-performing
    model, since it is able to deal with more information and examples and henceforth
    is able to recognize and infer more patterns the moment users ask their questions.
    However, with large numbers of parameters typically comes a high cost of training
    and hosting, since a powerful AI infrastructure is needed. Plus, the energy consumption
    of these models raises serious questions about the environmental impact of LLM
    training and their overall sustainability in the long run.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs（大型语言模型）不出所料地很大。这意味着包含LLMs的**ANN（人工神经网络**）架构由数亿个参数组成。通常，大量的参数与性能更好的模型相关联，因为它能够处理更多的信息和示例，因此当用户提问时能够识别和推断出更多的模式。然而，大量的参数通常伴随着高昂的训练和托管成本，因为需要强大的AI基础设施。此外，这些模型的能耗引发了关于LLM训练的环境影响及其长期可持续性的严重问题。
- en: These smaller models are called **small language models** (**SLMs**) and, besides
    being lighter and less demanding in terms of infrastructure, they are also showing
    surprisingly high performance.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这些较小的模型被称为**小型语言模型**（**SLMs**），除了在基础设施方面更轻、需求更低之外，它们还表现出令人惊讶的高性能。
- en: Now, we might think that GPT-3.5-turbo is deprecated; however, we have to remember
    that it used to be the most powerful model on the market just one year ago, and
    it is remarkable to see that a 7B model is capable of better results.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可能会认为GPT-3.5-turbo已经过时；然而，我们必须记住，它一年前曾是市场上最强大的模型，看到7B模型能够取得更好的结果是非常令人瞩目的。
- en: SLMs are definitely a research stream to keep an eye on, especially when it
    comes to scenarios where we might want to deploy a model locally or even customize
    it with fine-tuning (we will cover fine-tuning in the next chapter).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: SLMs（小型语言模型）绝对是一个值得关注的科研领域，尤其是在我们可能希望本地部署模型或通过微调对其进行定制（我们将在下一章介绍微调）的场景中。
- en: Legal and ethical landscape of generative AI
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式AI的法律和伦理格局
- en: When developing and deploying generative AI systems, a broad range of legal
    and ethical considerations must be carefully addressed to ensure responsible and
    sustainable use. These considerations extend beyond mere compliance and enter
    a domain where moral responsibility, public trust, and technological accountability
    intersect.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发和部署生成式AI系统时，必须仔细处理广泛的法律法规和伦理考量，以确保其负责任和可持续的使用。这些考量不仅限于合规性，还进入了一个道德责任、公众信任和技术问责相交的领域。
- en: Copyright and intellectual property issues
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 版权和知识产权问题
- en: LLMs are often trained on vast corpora scraped from the internet, including
    content that may be copyrighted. As a result, there is a real risk of embedding
    copyrighted text, music, images, or video segments directly into AI output, inadvertently
    producing infringements when these outputs are shared or commercialized.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs通常在从互联网上抓取的大量语料库上进行训练，包括可能受版权保护的内容。因此，存在将受版权保护的文本、音乐、图像或视频片段直接嵌入AI输出的实际风险，当这些输出被共享或商业化时，可能会无意中产生侵权行为。
- en: This concrete risk also escalated in November 2024, when major Canadian news
    organizations (https://www.reuters.com/sustainability/boards-policy-regulation/major-canadian-news-media-companies-launch-legal-action-against-openai-2024-11-29/),
    including The Globe and Mail and CBC/Radio-Canada, filed a lawsuit against OpenAI.
    They alleged that OpenAI used their copyrighted content without authorization
    to train its AI models, seeking damages and an injunction to prevent further unauthorized
    use.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这种具体风险在2024年11月也加剧了，当时包括《环球邮报》和CBC/Radio-Canada在内的主要加拿大新闻机构（https://www.reuters.com/sustainability/boards-policy-regulation/major-canadian-news-media-companies-launch-legal-action-against-openai-2024-11-29/）对OpenAI提起了诉讼。他们声称OpenAI未经授权使用他们的版权内容来训练其AI模型，寻求赔偿和禁止进一步未经授权使用的禁令。
- en: Misinformation, hallucinations, and the risk of fake news
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 错误信息、幻觉和虚假新闻的风险
- en: One of the known limitations of current generative AI models is their tendency
    to **hallucinate** – to produce entirely plausible-sounding but factually incorrect
    statements. This can result in the inadvertent spread of misinformation, especially
    when AI-generated content is taken at face value by consumers, journalists, or
    public officials.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 当前生成式AI模型的一个已知局限性是它们倾向于**产生幻觉**——产生听起来完全合理但实际上错误的信息。这可能导致无意中传播错误信息，尤其是在消费者、记者或公众官员将AI生成内容视为事实时。
- en: As an example, in December 2024, misinformation researcher Jeff Hancock (https://www.theverge.com/2024/12/4/24313132/jeff-hancock-minnesota-deepfake-law-ai-hallucinations-citation)
    admitted that ChatGPT fabricated details in a court filing he prepared, leading
    to the submission of non-existent citations. This incident emphasizes the risk
    of AI-generated content introducing inaccuracies in critical documents.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在2024年12月，虚假信息研究员杰夫·汉考克（https://www.theverge.com/2024/12/4/24313132/jeff-hancock-minnesota-deepfake-law-ai-hallucinations-citation）承认，他在准备法庭文件时，ChatGPT捏造了细节，导致提交了不存在的引用。这一事件强调了AI生成内容在关键文件中引入不准确性的风险。
- en: Continual exposure to unreliable AI output may lead to widespread skepticism
    regarding all digital content, undermining the credibility of legitimate sources
    and diminishing trust in expert commentary and reputable journalism. Organizations
    must therefore invest in factual verification processes, human-in-the-loop validation,
    and transparent model evaluation methods.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 持续接触不可靠的AI输出可能导致对所有数字内容的广泛怀疑，损害合法来源的信誉，并减少对专家评论和信誉良好的新闻的信任。因此，组织必须投资于事实核查流程、人工介入验证和透明的模型评估方法。
- en: Deepfakes and deceptive manipulation
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度伪造和欺骗性操纵
- en: Deepfake technology, an advanced subset of generative AI that synthesizes highly
    realistic images, videos, and voice recordings, can be weaponized to impersonate
    public figures, fabricate scandalous events, or produce manipulative political
    propaganda.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造技术，作为生成式AI的一个高级子集，能够合成高度逼真的图像、视频和语音录音，可以被用来模仿公众人物、编造丑闻事件或制作操纵性的政治宣传。
- en: '**Definition**'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**'
- en: A deepfake is a type of artificial media created using DL algorithms, where
    a person’s likeness, voice, or movements are digitally manipulated to create realistic
    but fake content. Typically, deepfakes involve altering videos or images to make
    it appear as if someone said or did something they never actually did.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造是一种使用深度学习算法创建的人工媒体，其中一个人的肖像、声音或动作被数字化操纵以创建逼真但虚假的内容。通常，深度伪造涉及修改视频或图像，使其看起来像某人说了或做了他们实际上从未做过的事情。
- en: A recent example occurred back in 2023, when a finance clerk at a Hong Kong
    branch of a multinational corporation was deceived into transferring over $25
    million after scammers used deepfake audio to impersonate senior executives, directing
    unauthorized fund transfers (https://www.secureworld.io/industry-news/hong-kong-deepfake-cybercrime).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的一个例子发生在2023年，当时一家跨国公司香港分行的财务职员在骗子使用深度伪造音频模仿高级管理人员后，被骗转款超过2500万美元，指示未经授权的资金转账（https://www.secureworld.io/industry-news/hong-kong-deepfake-cybercrime）。
- en: Companies, governments, and individuals targeted by deepfakes may suffer severe
    reputational harm, leading to public embarrassment, financial losses, or diminished
    trust. Building detection tools, implementing digital watermarking techniques,
    and establishing legal frameworks that penalize malicious deepfake creators are
    crucial steps in mitigating these risks.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 受深度伪造攻击的公司、政府和个人可能会遭受严重的声誉损害，导致公众尴尬、经济损失或信任度降低。建立检测工具、实施数字水印技术以及建立惩罚恶意深度伪造创作者的法律框架是减轻这些风险的关键步骤。
- en: Bias, discrimination, and social harm
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏见、歧视和社会伤害
- en: Generative AI models can unintentionally reproduce and magnify existing societal
    prejudices present in their training data. For example, models might consistently
    portray certain professions as male-dominated or depict particular cultural groups
    in stereotypical roles.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI模型可能会无意中复制和放大其训练数据中存在的现有社会偏见。例如，模型可能会持续描绘某些职业为男性主导，或以刻板印象描绘特定的文化群体。
- en: These biased outputs can influence hiring decisions, product recommendations,
    and policy-making processes, ultimately disadvantaging underrepresented groups.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这些有偏见的输出可能会影响招聘决策、产品推荐和政策制定过程，最终对代表性不足的群体造成不利。
- en: In this regard, a 2023 study, *Demographic Stereotypes in Text-to-Image Generation*
    (https://hai.stanford.edu/sites/default/files/2023-11/Demographic-Stereotypes.pdf),
    highlighted that text-to-image generative AI models tend to encode substantial
    bias and stereotypes. For example, prompts requesting images of professionals
    often resulted in depictions aligning with traditional gender roles, such as male
    doctors and female nurses, thereby reinforcing outdated and discriminatory views.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，2023年的一项研究，*文本到图像生成中的人口统计学刻板印象*（https://hai.stanford.edu/sites/default/files/2023-11/Demographic-Stereotypes.pdf），强调了文本到图像生成AI模型往往编码了大量的偏见和刻板印象。例如，请求专业人士图像的提示通常会导致与传统性别角色一致的描绘，如男性医生和女性护士，从而强化了过时和歧视性的观点。
- en: 'Another study, *Social Dangers of Generative Artificial Intelligence: Review
    and Guidelines* (https://dl.acm.org/doi/fullHtml/10.1145/3657054.3664243), investigates
    the extent to which these technologies can exacerbate existing inequality. For
    instance, AI-generated content may marginalize certain communities by underrepresenting
    them or portraying them negatively, leading to social harm and reinforcing systemic
    discrimination.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 另一项研究，*生成式人工智能的社会危险：综述和指南*（https://dl.acm.org/doi/fullHtml/10.1145/3657054.3664243），调查了这些技术可能加剧现有不平等的程度。例如，AI生成的内容可能会通过代表性不足或负面描绘某些社区来边缘化它们，导致社会伤害和强化系统性歧视。
- en: Organizations must commit to comprehensive bias audits, regularly updating training
    datasets, implementing fairness constraints, and involving diverse stakeholders
    in model development and evaluation.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 组织必须承诺进行全面偏见审计，定期更新训练数据集，实施公平约束，并让多元化的利益相关者参与模型开发和评估。
- en: These are just some examples of the potential risks and issues associated with
    generative AI. Furthermore, it is important to acknowledge that similar legal
    and ethical implications are not limited to generative AI, but rather they apply
    to the broader landscape of AI, whose applications have always been raising some
    concerns (for example, privacy considerations when it comes to face recognition).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是与生成式AI相关的潜在风险和问题的几个例子。此外，重要的是要认识到，类似的法律和伦理影响并不仅限于生成式AI，而是适用于更广泛的AI领域，其应用始终引发一些担忧（例如，在人脸识别方面的隐私考虑）。
- en: However, the extremely rapid evolvement and – most importantly – adoption of
    generative AI tools has highlighted the pressing need for organizations, policymakers,
    and developers to collaborate to craft robust governance frameworks that address
    the unique challenges posed by generative AI. This involves adopting standards
    for transparent data sourcing, obtaining explicit permissions for copyrighted
    content, implementing strict verification procedures to counter misinformation,
    and working closely with regulators to establish legal guardrails. It also demands
    that AI practitioners remain continuously vigilant in updating models, refining
    algorithms, and engaging with interdisciplinary experts to ensure that generative
    AI serves as a force for innovation and positive societal impact, rather than
    a source of harm or ethical compromise.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，生成式AI工具的极端快速发展和——更重要的是——采用，凸显了组织、政策制定者和开发者合作制定稳健治理框架的紧迫需求，以应对生成式AI带来的独特挑战。这包括采用透明数据来源的标准，获取版权内容的明确许可，实施严格的验证程序以对抗虚假信息，并与监管机构紧密合作建立法律界限。这也要求AI从业者持续保持警惕，更新模型，改进算法，并与跨学科专家合作，以确保生成式AI作为创新和积极社会影响的动力，而不是伤害或道德妥协的来源。
- en: Summary
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have explored the exciting world of generative AI and its
    various domains of application, including image generation, text generation, music
    generation, and video generation. We learned how generative AI models such as
    ChatGPT and DALL-E, trained by OpenAI, use DL techniques to learn patterns in
    large datasets and generate new content that is both novel and coherent. We also
    discussed the history of generative AI, its origins, and the current status of
    research on it.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探索了生成式AI的激动人心的世界及其各种应用领域，包括图像生成、文本生成、音乐生成和视频生成。我们学习了由OpenAI训练的生成式AI模型，如ChatGPT和DALL-E，如何使用深度学习技术在大数据集中学习模式，并生成既新颖又连贯的新内容。我们还讨论了生成式AI的历史、起源以及当前的研究状况。
- en: The goal of this chapter was to provide a solid foundation in the basics of
    generative AI and to inspire you to explore this fascinating field further.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是提供生成式AI基础知识的坚实基础，并激发您进一步探索这个迷人的领域。
- en: In the next chapter, we will focus on one of the most promising technologies
    available on the market today, ChatGPT. We will go through the research behind
    it and its development by OpenAI, the architecture of its model, and the main
    use cases it can address as of today.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将重点关注市场上最具有前景的技术之一，ChatGPT。我们将探讨其背后的研究和由OpenAI的开发，其模型的架构，以及截至今天它可以解决的主要用例。
- en: References
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Generative adversarial networks: https://arxiv.org/abs/1406.2661'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成对抗网络：https://arxiv.org/abs/1406.2661
- en: 'Analyzing and improving the image quality of StyleGAN: https://arxiv.org/abs/1912.04958'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析和改进StyleGAN的图像质量：https://arxiv.org/abs/1912.04958
- en: 'Video-to-video synthesis: https://arxiv.org/abs/1808.06601'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频到视频合成：https://arxiv.org/abs/1808.06601
- en: 'A deep generative model trifecta: Three advances that work towards harnessing
    large-scale power: https://www.microsoft.com/en-us/research/blog/a-deep-generative-
    model-trifecta-three-advances-that-work-towards-harnessing- large-scale-power/'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度生成模型三合一：三个旨在利用大规模力量的进展：https://www.microsoft.com/en-us/research/blog/a-deep-generative-
    model-trifecta-three-advances-that-work-towards-harnessing- large-scale-power/
- en: 'Vid2Vid: https://tcwang0509.github.io/vid2vid/'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Vid2Vid: https://tcwang0509.github.io/vid2vid/'
- en: 'LLaMA: Open and Efficient Foundation Language Models: https://arxiv.org/pdf/2302.13971'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLaMA：开放和高效的基座语言模型：https://arxiv.org/pdf/2302.13971
- en: 'Introducing Phi-3: https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍Phi-3：https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/
- en: Join our communities on Discord and Reddit
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord和Reddit社区
- en: Have questions about the book or want to contribute to discussions on Generative
    AI and LLMs? Join our Discord server at [https://packt.link/I1tSU](Chapter_1.xhtml)
    and our Reddit channel at [https://packt.link/jwAmA](Chapter_1.xhtml) to connect,
    share, and collaborate with like-minded enthusiasts.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 对本书有任何疑问或想参与关于生成式AI和LLMs的讨论？加入我们的Discord服务器[https://packt.link/I1tSU](Chapter_1.xhtml)和Reddit频道[https://packt.link/jwAmA](Chapter_1.xhtml)，以连接、分享和与志同道合的爱好者合作。
- en: '![](img/Discord.png) ![](img/QR_Code757615820155951000.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Discord.png) ![](img/QR_Code757615820155951000.png)'
