- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: The Ethics of Model Adaptability
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型适应性的伦理
- en: This chapter gives a detailed overview of detecting different types of model
    drift for model governance purposes in organizations. The primary objective of
    this chapter is to demonstrate variations of ML models, with multiple examples
    to give you an awareness of the importance of the different statistical measures
    available for detecting data changes and model metric variations. This will help
    data scientists and MLOps professionals to choose the right drift detection mechanisms
    and stick to the correct model metric performance thresholds to control risks
    arising due to incorrect predictions. You’ll learn how to quantify and explain
    model drift and answer questions related to the need for model calibration. This
    will also allow you to understand the scope of designing fairly calibrated models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章详细介绍了如何在组织中为模型治理目的检测不同类型的模型漂移。本章的主要目标是展示机器学习（ML）模型的变异，通过多个示例让你意识到检测数据变化和模型指标变动所需的不同统计量的重要性。这将帮助数据科学家和MLOps专业人员选择合适的漂移检测机制，并遵循正确的模型指标性能阈值，以控制由于错误预测带来的风险。你将学会如何量化和解释模型漂移，并解答与模型校准需求相关的问题。这还将使你能够理解设计合理校准模型的范围。
- en: 'In this chapter, these topics will be covered in the following sections:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将覆盖以下内容：
- en: Adaptability framework for data and model drift
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据和模型漂移的适应性框架
- en: How we can explain ML models when subjected to drift or calibration
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何解释在漂移或校准条件下的机器学习模型
- en: Understanding the need for model calibration
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解模型校准的必要性
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter requires you to have Python 3.8 and to run the following commands
    before starting:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章要求你使用Python 3.8并在开始之前运行以下命令：
- en: '`pip` `install` `alibi-detect`'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip` `install` `alibi-detect`'
- en: '`pip` `install` `river`'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip` `install` `river`'
- en: '`pip` `install` `detecta`'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip` `install` `detecta`'
- en: '`pip install nannyml (``dependency numpy==1.21.0)`'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pip install nannyml (``dependency numpy==1.21.0)`'
- en: '`git` `clone` [https://github.com/zelros/cinnamon.git](https://github.com/zelros/cinnamon.git)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`git` `clone` [https://github.com/zelros/cinnamon.git](https://github.com/zelros/cinnamon.git)'
- en: '`python3` `setup.py install`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`python3` `setup.py install`'
- en: '`git` `clone` [https://github.com/Western-OC2-Lab/PWPAE-Concept-Drift-Detection-and-Adaptation.git](https://github.com/Western-OC2-Lab/PWPAE-Concept-Drift-Detection-and-Adaptation.git)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`git` `clone` [https://github.com/Western-OC2-Lab/PWPAE-Concept-Drift-Detection-and-Adaptation.git](https://github.com/Western-OC2-Lab/PWPAE-Concept-Drift-Detection-and-Adaptation.git)'
- en: The `alibi-detect` package mentioned in the installation step can be found on
    GitHub. For reference, you can check out more details of the project at [https://github.com/SeldonIO/alibi-detect](https://github.com/SeldonIO/alibi-detect).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 安装步骤中提到的`alibi-detect`包可以在GitHub上找到。作为参考，你可以在[https://github.com/SeldonIO/alibi-detect](https://github.com/SeldonIO/alibi-detect)查看该项目的更多细节。
- en: Adaptability framework for data and model drift
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据和模型漂移的适应性框架
- en: Data processing depends on the way data is accessed based on its availability,
    whether it’s sequential or continuous. Along with the data processing and modeling
    techniques built on different modes of incoming data, various factors (internal
    and external) cause the data distribution to change dynamically. This change is
    called **concept drift**, and it creates several threats to ML models in production.
    In concept drift terminology, and as far as the shift in data distributions is
    concerned, the term **window** is used to refer to the most recently known concept
    that was used to train the current or most recent predictor.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据处理取决于数据访问的方式，基于其可用性，无论是顺序数据还是连续数据。随着不同模式的输入数据处理和建模技术的建立，各种因素（内部和外部）会导致数据分布发生动态变化。这种变化被称为**概念漂移**，它对生产中的机器学习模型构成了若干威胁。在概念漂移术语中，关于数据分布的变化，**窗口**一词用来指代用于训练当前或最近预测器的最新已知概念。
- en: Examples of concept drift can be seen in e-commerce systems where ML algorithms
    profile the shopping patterns of the user and provide personalized recommendations
    of relevant products. Factors that result in concept drift include events such
    as marriage and relocating to a different geographical region. The COVID-19 pandemic
    caused a drastic change in consumers' buying behavior, because people were forced
    to turn to e-commerce platforms for online shopping. This resulted in higher demand
    for products than expected, causing a high rate of prediction errors in forecasting
    demand in supply chain networks. The e-commerce, supply chain, and banking industries
    have experienced changes in incoming data patterns, leading to model drift.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 概念漂移的例子可以在电子商务系统中看到，其中机器学习算法分析用户的购物模式，并提供个性化的相关产品推荐。导致概念漂移的因素包括婚姻、搬迁到不同地理区域等事件。COVID-19疫情导致了消费者购买行为的剧烈变化，因为人们被迫转向电子商务平台进行在线购物。这导致了对产品的需求远高于预期，从而在供应链网络中的需求预测中产生了高错误率。电子商务、供应链和银行行业已经经历了数据模式的变化，导致模型漂移。
- en: '![Figure 11.1 – Four types of concept drift](img/Figure_11.01_B18681.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.1 – 四种概念漂移类型](img/Figure_11.01_B18681.jpg)'
- en: Figure 11.1 – Four types of concept drift
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – 四种概念漂移类型
- en: 'As illustrated in *Figure 11**.1*, there are four kinds of concept drift, caused
    by various internal or external factors, or even adversarial activities:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 11.1*所示，概念漂移有四种类型，可能由各种内部或外部因素，甚至是对抗性活动引起：
- en: '**Abrupt**: Caused by behavior shifts'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**突变**：由行为变化引起'
- en: '**Incremental**: A sudden change with slower decay'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**增量**：突发变化，具有较慢的衰减'
- en: '**Reoccurring**: Similar to seasonal trends'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**重现**：类似于季节性趋势'
- en: '**Gradual**: Slow, long-lasting changes'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**渐变**：缓慢、长期的变化'
- en: Other indirect factors, such as the speed of learning, errors in reporting the
    right features (or units of measurement), and large changes in the classification
    or prediction accuracy, can also result in concept drift. This is illustrated
    in *Figure 11**.2*. To address concept drift, we need to update the models causing
    the drift. This could be a blind update or training with weighted data, model
    ensembling, an incremental model update, or applying modes of online learning.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 其他间接因素，如学习速度、报告正确特征（或度量单位）时的错误，以及分类或预测准确性的巨大变化，也可能导致概念漂移。*图 11.2*中进行了说明。为了解决概念漂移，我们需要更新导致漂移的模型。这可能是盲目更新或使用加权数据训练、模型集成、增量模型更新，或者应用在线学习模式。
- en: "![Figure 11.2 – Different types of drift-causing factors\uFEFF and remedial\
    \ actions](img/Figure_11.02_B18681.jpg)"
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.2 – 漂移因素和补救措施的不同类型](img/Figure_11.02_B18681.jpg)'
- en: Figure 11.2 – Different types of drift-causing factors and remedial actions
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 – 漂移因素和补救措施的不同类型
- en: We categorize concept drift detectors (illustrated in *Figure 11**.3*) primarily
    based on the batch or online data arrival mode. Batch detection techniques can
    further be classified into whole-batch and partial-batch detection techniques.
    The size and sample of the batch are two of the factors used to classify them
    as whole-batch or partial-batch detection. Online detectors are further classified
    based on their ability to manipulate the reference window in order to detect drift.
    The detection window is often a sliding window that moves with an incoming instance,
    often referred to as the current concept. However, fixed reference windows are
    also used to detect concept drift.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根据数据到达模式（批处理或在线）对概念漂移检测器（如*图 11.3*所示）进行分类。批处理检测技术可以进一步分为全批次检测和部分批次检测技术。批次的大小和样本是将其分类为全批次或部分批次检测的两个因素。在线检测器则根据其调整参考窗口的能力来检测漂移。检测窗口通常是一个滑动窗口，随着新的实例到来而移动，通常被称为当前概念。然而，也有使用固定参考窗口来检测概念漂移的情况。
- en: Online detectors function by evaluating the test statistics computed for the
    first *W* data points and then updating the test statistics. The updates can be
    done sequentially at a lower cost, thereby helping us to detect fluctuations in
    the test statistics beyond a threshold value. A value exceeding the threshold
    indicates that drift has taken place.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在线检测器通过评估前*W*个数据点计算的测试统计量来工作，然后更新测试统计量。更新可以以较低的成本按顺序进行，从而帮助我们检测测试统计量是否超出阈值。超过阈值的值表示已经发生了漂移。
- en: '![Figure 11.3 – Commonly used drift detectors](img/Figure_11.03_B18681.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.3 – 常用的漂移检测器](img/Figure_11.03_B18681.jpg)'
- en: Figure 11.3 – Commonly used drift detectors
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 – 常用的漂移检测器
- en: '*Figure 11**.3* illustrates the idea of unsupervised batch-based (with a fixed
    window) and online-based (fixed and sliding windows) drift detection techniques
    that, after necessary data distribution comparison and a significance test, detect
    whether there has been drift or not. Batch-based methods may require instance
    selection and statistical computations on a batch to confirm the testing of drift
    conditions, enabling us to infer whether drift has occurred or not. The numbers
    here signify the sequence of steps required to detect both online and offline
    drift.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*图11.3*展示了无监督批量基础（固定窗口）和基于在线（固定和滑动窗口）漂移检测技术的概念，这些方法在必要的数据分布比较和显著性测试后，用来检测是否存在漂移。批量方法可能需要在批次上进行实例选择和统计计算，以确认漂移条件的测试，从而推断是否发生了漂移。这里的数字表示检测在线和离线漂移所需的步骤顺序。'
- en: '![Figure 11.4 – Online and batch drift detection methods](img/Figure_11.04_B18681.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图11.4 – 在线和批量漂移检测方法](img/Figure_11.04_B18681.jpg)'
- en: Figure 11.4 – Online and batch drift detection methods
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4 – 在线和批量漂移检测方法
- en: An example of an online drift adaptive framework is the **Performance Weighted
    Probability Averaging Ensemble** (**PWPAE**) framework, which can be used effectively
    in IoT anomaly detection use cases.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一个在线漂移自适应框架的例子是**性能加权概率平均集成**（**PWPAE**）框架，能够在IoT异常检测应用场景中有效使用。
- en: 'This framework can be deployed on IoT cloud servers to process big data streams
    using a wireless medium from IoT devices. This kind of ensemble adaptive drift
    detector is composed of four base learners that help with real-time drift detection:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架可以部署在IoT云服务器上，利用来自IoT设备的无线媒介处理大数据流。这个集成自适应漂移检测器由四个基础学习器组成，帮助进行实时漂移检测：
- en: An **Adaptive Random Forest** (**ARF**) model with an **ADWIN drift detector**
    (referred to as **ARF-ADWIN**)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个带有**ADWIN漂移检测器**的**自适应随机森林**（**ARF**）模型（简称**ARF-ADWIN**）
- en: An ARF model with a **DDM drift detector** (referred to as **ARF-DDM**)
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个带有**DDM漂移检测器**的ARF模型（简称**ARF-DDM**）
- en: A **Streaming Random Patches** (**SRP**) model with an **ADWIN drift detector**
    (referred to as **SRP-ADWIN**)
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个带有**ADWIN漂移检测器**的**流随机补丁**（**SRP**）模型（简称**SRP-ADWIN**）
- en: An SRP model with a **DDM drift detector** (referred to as **SRP-DDM**)
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个带有**DDM漂移检测器**的SRP模型（简称**SRP-DDM**）
- en: 'The four base online learners are combined by weighting them based on their
    accuracy and classification probabilities. Let’s try the PWPAE framework on the
    CICIDS2017 ([https://www.unb.ca/cic/datasets/ids-2017.html](https://www.unb.ca/cic/datasets/ids-2017.html))
    simulated intrusion detection dataset, which contains benign and recent common
    attacks, resembling true real-world examples:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 四个基础在线学习器通过根据它们的准确性和分类概率加权组合在一起。让我们在CICIDS2017（[https://www.unb.ca/cic/datasets/ids-2017.html](https://www.unb.ca/cic/datasets/ids-2017.html)）模拟入侵检测数据集上尝试PWPAE框架，该数据集包含良性和近期常见的攻击，类似于真实世界的例子：
- en: 'To run PWPAE, let''s first make the necessary imports from the `river` package:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了运行PWPAE，让我们首先从`river`包中导入必要的模块：
- en: '[PRE0]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then we set up the PWPAE model with `X_train` and `y_train` to train the model,
    and we test it on `X_test` and `y_test`. The following code snippet uses the PWPAE
    model:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们使用`X_train`和`y_train`设置PWPAE模型进行训练，并在`X_test`和`y_test`上进行测试。以下代码片段展示了如何使用PWPAE模型：
- en: '[PRE1]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The trained results and the comparative outputs are visualized in *Figure 11.5*.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 训练结果和比较输出在*图11.5*中进行了可视化。
- en: "![Figure 11.5 – The performance results of PWPAE with \uFEFFthe \uFEFFHoeffding\
    \ Tree (HT) and Leveraging Bagging (LB) models](img/Figure_11.05_B18681.jpg)"
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![图11.5 – PWPAE与Hoeffding树（HT）和提升袋装（LB）模型的性能结果](img/Figure_11.05_B18681.jpg)'
- en: Figure 11.5 – The performance results of PWPAE with the Hoeffding Tree (HT)
    and Leveraging Bagging (LB) models
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5 – PWPAE与Hoeffding树（HT）和提升袋装（LB）模型的性能结果
- en: The accuracy of PWPAE is 99.06% and it exceeds the accuracy of other models.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: PWPAE的准确率为99.06%，超越了其他模型的准确率。
- en: Let us investigate some supervised drift detection strategies where actual feedback
    for prediction is available and is used with the predicted outcomes to yield error
    metrics.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们研究一些有监督的漂移检测策略，其中可以获得实际的预测反馈，并与预测结果一起使用，以产生误差指标。
- en: Statistical methods
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 统计方法
- en: Statistical methods help us to compare and assess two different distributions.
    A divergence factor or a distance metric can be used to measure the difference
    between two distributions at different points in time to understand their behavior.
    This helps with the timely detection of the model’s performance metrics and finding
    the features that are causing the change.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 统计方法帮助我们比较和评估两种不同的分布。散度因子或距离度量可以用来衡量两种分布在不同时间点的差异，以了解它们的行为。这有助于及时检测模型的性能指标，并找出导致变化的特征。
- en: Kullback–Leibler divergence
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 库尔巴克–莱布勒散度
- en: '**Kullback–Leibler** (**KL**) divergence, also popularly known as **relative
    entropy**, quantifies how much one probability distribution differs from another.
    Mathematically, it can be stated as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**库尔巴克–莱布勒**（**KL**）散度，也通常称为**相对熵**，量化了一个概率分布与另一个概率分布之间的差异。数学上，它可以表示为以下公式：'
- en: '![](img/Formula_11_001.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_11_001.jpg)'
- en: '*Q* is the distribution of the old data and *P* is the distribution of the
    new data for which we compute the divergence, and || represents the divergence.
    When *P*(*x*) is high and *Q*(*x*) is low, the divergence will be high. On the
    other hand, if *P*(*x*) is low and *Q*(*x*) is high, the divergence will be high
    but not too high. When *P*(*x*) and *Q*(*x*) are similar, then the divergence
    will be low. The following code creates a KL divergence plot for a (*P*, *Q*,
    *M*) distribution with a mean of 5 and a standard deviation of 4:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '*Q* 是旧数据的分布，*P* 是新数据的分布，我们为此计算散度，|| 表示散度。当 *P*（*x*）很高而 *Q*（*x*）很低时，散度会很高。另一方面，如果
    *P*（*x*）较低而 *Q*（*x*）较高，散度会很高，但不会太高。当 *P*（*x*）和 *Q*（*x*）相似时，散度会很低。以下代码为一个均值为 5，标准差为
    4 的（*P*，*Q*，*M*）分布生成一个 KL 散度图：'
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The change in distribution patterns due to KL divergence is illustrated in
    *Figure 11**.6*:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 KL 散度导致的分布模式变化在*图 11.6*中有所展示：
- en: '![Figure 11.6 – KL divergence](img/Figure_11.06_B18681.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.6 – KL 散度](img/Figure_11.06_B18681.jpg)'
- en: Figure 11.6 – KL divergence
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.6 – KL 散度
- en: There are more forms of divergence, which we will look at next.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 还有更多形式的散度，接下来我们将讨论这些。
- en: Jensen–Shannon divergence
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 詹森–香农散度
- en: '**Jensen–Shannon** (**JS**) divergence uses KL divergence and can be formulated
    mathematically as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**詹森–香农**（**JS**）散度使用 KL 散度，并可以通过以下数学公式表示：'
- en: '![](img/Formula_11_002.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_11_002.jpg)'
- en: 'One difference between KL and JS divergence is that JS divergence is symmetrical
    with a mandatory finite value. The change in distribution patterns due to JS divergence
    is illustrated in *Figure 11**.7*:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: KL 散度与 JS 散度之间的一个区别是，JS 散度是对称的，并且具有强制性的有限值。由于 JS 散度导致的分布模式变化在*图 11.7*中有所展示：
- en: '![](img/Figure_11.07_B18681.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Figure_11.07_B18681.jpg)'
- en: Figure 11.7 – JS divergence
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7 – JS 散度
- en: 'To compute JS and KL divergence, we run the following code snippet:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算 JS 和 KL 散度，我们运行以下代码片段：
- en: 'First, we create a normal distribution for distribution 1:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们为分布 1 创建一个正态分布：
- en: '[PRE3]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we create another normal distribution, which is our second distribution:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们创建另一个正态分布，这就是我们的第二个分布：
- en: '[PRE4]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the next step, we first evaluate the KL divergence between probability distribution
    1 and the mean of the two `Y1` and `Y2` and the same for probability distribution
    2:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一步中，我们首先评估概率分布 1 与 `Y1` 和 `Y2` 的均值之间的 KL 散度，同样地，我们也评估概率分布 2：
- en: '[PRE5]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The previous step yields the following output:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上一步的输出如下所示：
- en: '[PRE6]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the next step, we first evaluate the JS divergence between the distributions
    and also within each distribution individually:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一步中，我们首先评估分布之间的 JS 散度，也评估每个分布内部的 JS 散度：
- en: '[PRE7]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We evaluate this against the SciPy calculation of JS divergence between the
    distributions:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将其与 SciPy 计算的分布之间的 JS 散度进行比较：
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The preceding step yields the following output:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 上述步骤的输出如下所示：
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The first distance gives the symmetric JS divergence, while the second evaluated
    metric gives the JS distance, which is the square root of the JS divergence. The
    third and fourth distance metrics evaluated give us the JS distance between `X1`,
    `X2` and `dx1`, `dx2`, respectively. `dx1` and `dx2` here signify the entropy
    of distributions created from `Y1`, `X1` and `Y2`, `X2`, respectively.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个距离给出了对称的 JS 散度，而第二个评估的度量给出了 JS 距离，这是 JS 散度的平方根。评估出的第三个和第四个距离度量分别给出了 `X1`、`X2`
    和 `dx1`、`dx2` 之间的 JS 距离。这里的 `dx1` 和 `dx2` 表示从 `Y1`、`X1` 和 `Y2`、`X2` 分布中生成的熵。
- en: The Kolmogorov-Smirnov test
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 科尔莫哥罗夫–斯米尔诺夫检验
- en: 'The two-sample **Kolmogorov-Smirnov** (**KS**) test is a general nonparametric
    method used to differentiate two samples. The data change pattern, best identified
    by the KS test, is illustrated in *Figure 11**.8*. The **Cumulative Distribution
    Function** (**CDF**) of (*sample, x*) quantifies the percentage of observations
    below *x* on the sample. This can be obtained by doing the following:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '两样本**Kolmogorov-Smirnov**（**KS**）检验是一种常用的非参数方法，用于区分两个样本。通过KS检验识别的数据变化模式如*图11.8*所示。**累积分布函数**（**CDF**）表示在样本中低于*x*的观察值的百分比。这可以通过以下步骤获得：  '
- en: Sorting the sample
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '对样本进行排序  '
- en: Counting whether the number of observations within the sample is less than or
    equal to *x*
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '计算样本内观察值的数量是否小于或等于*x*  '
- en: Dividing the numerator computed in step 2 by the total number of observations
    on the sample
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '将步骤2中计算的分子除以样本上的总观察值数量  '
- en: 'The purpose of the drift detector is to detect drift patterns when two distribution
    functions observe a change, causing a shape change in two samples:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '漂移检测器的目的是在两个分布函数观察到变化时，检测漂移模式，这会导致两个样本形态的变化：  '
- en: '![Figure 11.8 – KS test](img/Figure_11.08_B18681.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图11.8 – KS检验](img/Figure_11.08_B18681.jpg)  '
- en: Figure 11.8 – KS test
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '图11.8 – KS检验  '
- en: Population stability index
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**人口稳定性指数**  '
- en: '**Population stability index** (**PSI**) is a metric that monitors and measures
    shifts in population behavior between two samples or over two periods of time.
    It serves as a risk-scorecard metric to give a probable risk estimation between
    an out-of-time validation sample and a modeling sample including both dependent
    and independent variables. The application of PSI can also be extended to compare
    the education, income, and health status of two or more populations in social-demographic
    studies.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**人口稳定性指数**（**PSI**）是一种监测和衡量两个样本或两个时间段之间人口行为变化的指标。它作为一个风险评分卡指标，用于提供一个时间外验证样本与建模样本之间的风险估计，包括依赖变量和独立变量。PSI的应用还可以扩展到社会人口学研究中比较两个或更多人口的教育、收入和健康状况。  '
- en: '**Model distillation** is a technique that allows the transfer of knowledge
    from a large network to a small network, which trains a second model with a simplified
    architecture on soft targets (the output distributions or the logits) retrieved
    from the original model. It paves the way to detect adversarial and malicious
    data and data drift by comparing the output distributions of both the original
    model and the distilled model.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型蒸馏**是一种技术，它允许将知识从一个大网络转移到一个小网络，该小网络在简化架构上使用从原始模型提取的软目标（输出分布或logits）训练第二个模型。这为通过比较原始模型和蒸馏模型的输出分布来检测对抗性和恶意数据以及数据漂移铺平了道路。  '
- en: 'Let us now see, with an example, how adversarial scores are detected by the
    model distillation detector in the context of drift detection. The KS test has
    been used as the scoring function to run a simple univariate test between the
    adversarial scores of the reference batch and the test data. A high adversarial
    score indicates a harmful drift, and a flag is raised for malicious data drift.
    Here, we can fetch the pretrained model distillation detector from a Google Cloud
    bucket or train one from scratch:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '现在让我们通过一个例子，看看如何在漂移检测的背景下通过模型蒸馏检测器检测对抗得分。KS检验已被用作评分函数，以便在参考批次和测试数据的对抗得分之间进行简单的一维检验。较高的对抗得分表示有害的漂移，并为恶意数据漂移设置标志。在这里，我们可以从Google
    Cloud桶中提取预训练的模型蒸馏检测器，或者从头开始训练一个：  '
- en: 'First, we import the necessary packages from `alibi_detect`:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '首先，我们从`alibi_detect`导入必要的包：  '
- en: '[PRE10]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Then, we define and train the distilled model:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们定义并训练蒸馏模型：
- en: '[PRE11]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, based on our configuration, we can either load a pretrained model or
    train a new model:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '接下来，根据我们的配置，我们可以选择加载一个预训练模型或训练一个新模型：  '
- en: '[PRE12]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We now plot the mean scores and standard deviations per severity level. We
    define the model accuracy plot as the mean and standard deviation of the harmfulness
    and no-harmfulness scores:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '我们现在绘制每个严重程度级别的平均得分和标准差。我们将模型准确性图定义为有害和无害得分的均值和标准差：  '
- en: '[PRE13]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The plot (illustrated in *Figure 11**.9*) shows the mean harmfulness scores
    (the line plot starting from the left-hand side) and ResNet-32 accuracies (the
    bars displayed on the right-hand side) for increasing data corruption severity
    levels. Level 0 corresponds to the original test set. We have demonstrated the
    impact of varying levels of malicious (corrupted) data along with its severity
    levels.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图表（见*图 11.9*）展示了不同数据损坏严重度等级下的平均危害评分（从左侧开始的折线图）和ResNet-32准确率（右侧显示的柱状图）。级别0对应原始测试集。我们展示了不同恶意（损坏）数据及其严重度对模型的影响。
- en: Harmful scores signify instances that gave an incorrect prediction because of
    corrupted data. Even not-harmful predictions are known to exist, which remains
    unchanged (as shown by the harmful index, marked in yellow along the *Y* axis)
    after the data corruption due to the injection of malicious adversarial samples.
    To summarize further, we see in *Figure 11**.9* that the corruption severity increases
    as the harmfulness score increases (shown by the cyan bars) and the accuracy decreases
    (shown by the blue line).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 危害评分表示由于数据损坏而给出错误预测的实例。即使是无害的预测也存在，这些预测（如*Y*轴上标注为黄色的危害指数所示）在数据损坏后保持不变，这是由于恶意对抗样本的注入。进一步总结，我们可以在*图
    11.9*中看到，随着危害评分的增加（由青色柱状图表示），损坏严重度加剧，准确率下降（由蓝色折线表示）。
- en: '![Figure 11.9 – Distilled drift detector detecting the corruption severity](img/Figure_11.09_B18681.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.9 – 提取型漂移检测器检测数据损坏严重度](img/Figure_11.09_B18681.jpg)'
- en: Figure 11.9 – Distilled drift detector detecting the corruption severity
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.9 – 提取型漂移检测器检测数据损坏严重度
- en: There are some other methods that we can categorize as contextual methods.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些其他方法可以归类为上下文方法。
- en: Contextual methods
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 上下文方法
- en: The purpose of these methods is to compare and assess the difference between
    the train and test datasets and evaluate the drift when there’s a significant
    difference in the predicted outcomes.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法的目的是比较并评估训练集与测试集之间的差异，并在预测结果存在显著差异时评估漂移情况。
- en: Tree features
  id: totrans-113
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 树的特征
- en: This method enables you to train a simple tree based on data and prediction
    timestamps that are fed as independent input features, along with other features.
    Once the tree model is analyzed for feature importance, it is evident that the
    effect on data at different points in time helps to substantiate the differences
    arising due to concept drift. The tree splits, and the feature splits done on
    the timestamp, help to explain the changes due to drift.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法允许你基于数据和预测时间戳训练一个简单的树模型，时间戳作为独立输入特征之一，与其他特征一起使用。通过分析树模型的特征重要性，显而易见，不同时间点的数据对模型的影响有助于揭示由概念漂移引起的差异。树的分裂以及基于时间戳的特征分裂，有助于解释漂移带来的变化。
- en: Shuffling and resampling (SR)
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 洗牌与重采样（SR）
- en: The data is split into train and test sets at an assumed drift point, and then
    the model is trained using the train dataset and evaluated against the test dataset
    to compute the error rates. The same mechanism of training and testing is repeated
    by shuffling the same dataset and recomputing the error metrics. Drift is said
    to be detected when the difference between the ordered data error rate and the
    average shuffled data error rate is above a specified threshold. This is also
    a computationally intensive mechanism as it involves training multiple models
    during occurrences of drift.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 数据在假定的漂移点处被分为训练集和测试集，然后使用训练集训练模型，并通过测试集评估模型的错误率。通过洗牌相同的数据集并重新计算错误度量，重复相同的训练和测试机制。当天订单数据的错误率与洗牌数据的平均错误率之间的差异超过指定阈值时，认为检测到了漂移。这也是一个计算密集型机制，因为它涉及在漂移发生时训练多个模型。
- en: Statistical process control
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 统计过程控制
- en: This kind of drift detector control mechanism ensures that when the model in
    production generates varying accuracy metrics over time, the errors in the model
    can be managed. Though this method is effective in detecting sudden, gradual,
    and incremental drift in a short span of time, the latency could be high when
    extracting labels from the samples. The requirement of having labeled data makes
    it more difficult to be applied widely.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这种漂移检测器控制机制确保当生产中的模型随着时间产生变化的准确度指标时，模型的误差能够得到管理。尽管这种方法在短时间内有效检测到突发性、渐进性和增量性的漂移，但提取样本标签时可能存在较高的延迟。要求有标签数据的限制使得该方法更难以广泛应用。
- en: Drift detection method (DDM)
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 漂移检测方法（DDM）
- en: This method of drift detection is one of the earliest devised. Incoming data
    is assumed to be in a sequence following a binomial distribution and a Bernoulli
    trial variable (or single data point) inferring the occurrence of drift based
    on the prediction error rate.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这种漂移检测方法是最早设计的方法之一。假设输入数据呈现二项分布，且伯努利试验变量（或单一数据点）根据预测误差率推断漂移的发生。
- en: The algorithm records the **minimum probability of error** (*p*) rate and the
    **minimum standard deviation** (*s*) of the binomial distribution when *p + s*
    reaches its own minimum. Drift is said to be present when the *p + s* value exceeds
    the sum of the **minimum probability of error** (pmin) and a **multiple of the
    minimum standard deviation** (smin). We can state that as (p + s) > (pmin + 3
    ✶ *s*min).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法记录**最小误差概率**（*p*）率和二项分布的**最小标准差**（*s*），当*p + s*达到其最小值时。若*p + s*的值超过**最小误差概率**（pmin）与**最小标准差的倍数**（smin）的和，则认为存在漂移。我们可以表示为（p
    + s）>（pmin + 3 ✶ *s*min）。
- en: The recommended multiplying factor is 3\. This method has limitations when the
    change occurs slowly, where the cache/memory may overflow.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐的乘数因子是3。当变化发生缓慢时，该方法有局限性，此时缓存/内存可能会溢出。
- en: Early Drift Detection Method (EDDM)
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 早期漂移检测方法（EDDM）
- en: This method, although similar to DDM, focuses on gradual drift by computing
    the **mean** (*m*) and **standard deviation** (*s*) of the distance between two
    errors. It records (*m* + 2 ✶ *s*) and when it reaches its maximum value, it saves
    both values as mmax and smax , respectively. When the ratio, (*m* + 2 ✶ *s*)/(*m*
    + 2 ✶ *s*max), drops below a threshold (*β*; the recommended value is 0.9), drift
    is detected, and an alarm should be raised.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法虽然与DDM类似，但通过计算两个误差之间的**均值**（*m*）和**标准差**（*s*）来关注渐进式漂移。它记录（*m* + 2 ✶ *s*），当该值达到最大值时，会将这两个值分别保存为mmax和smax。当比率（*m*
    + 2 ✶ *s*）/（*m* + 2 ✶ *s*max）低于阈值（*β*；推荐值为0.9）时，漂移被检测到，并应触发警报。
- en: CUSUM and Page-Hinkley
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CUSUM和Page-Hinkley
- en: '**Cumulative Sum** (**CUSUM**) and its variant, **Page-Hinkley** (**PH**),
    both rely on a sequential analysis technique, typically from an average Gaussian
    signal. These methods detect the change and raise an alarm when they observe that
    the difference between the observed values and the mean is higher than a user-defined
    threshold. As the changes are sensitive to the parameter values, one disadvantage
    of this is the triggering of false alarms. These methods can be widely applied
    to data streams.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**累积和**（**CUSUM**）及其变种**Page-Hinkley**（**PH**）都依赖于顺序分析技术，通常基于平均高斯信号。这些方法通过检测当观察值与均值之间的差异超过用户定义的阈值时发出警报。由于这些变化对参数值敏感，这种方法的一个缺点是可能会触发误报。这些方法可以广泛应用于数据流。'
- en: CUSUM
  id: totrans-127
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: CUSUM
- en: This drift detection algorithm detects small changes in the mean using CUSUM.
    When the probability distributions before and after the change are known, then
    the CUSUM procedure optimizes an objective function by considering the delays
    and frequency of false alarms. It has the additional advantage of being simple
    and intuitive to interpret in terms of maximum likelihood. It is memoryless, one-sided,
    and asymmetrical, with the ability to detect only an increase in the difference
    between the observed value and the mean.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 该漂移检测算法使用CUSUM检测均值的微小变化。当变化前后的概率分布已知时，CUSUM过程通过考虑延迟和误报频率来优化目标函数。它具有额外的优点，即在最大似然的解释上简单直观。它是无记忆的、单侧的和不对称的，只能检测观察值与均值之间差异的增加。
- en: The CUSUM detector is a kernel-based technique that continuously compares samples
    from the database. The metric for drift determination is called the **Maximum
    Mean Discrepancy** (**MMD**). This procedure is well suited for large data volumes
    because it does not need to compare pre- and post-distributions, instead concentrating
    on the current data to identify drift. CUSUM has been enhanced to use a dual mean
    value on nested sliding windows, which is called the **Double CUSUM Based on Data
    Stream** (**DCUSUM-DS**). Another variant of CUSUM is DCUSUM-DS, which uses a
    dual mean value CUSUM. The DCUSUM-DS algorithm works on nested sliding windows
    and detects drift by calculating the average value of the data within the window
    twice. After detecting the average, it extracts new features and then generates
    accumulated and controlled graphs to avoid false inference. One major benefit
    of this method is that it can detect new features and rerun its analysis to ensure
    it detects the correct drift and does not rely only on the average values detected.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: CUSUM检测器是一种基于核的方法，持续比较数据库中的样本。漂移判断的指标叫做**最大均值差异**（**MMD**）。该程序非常适合大数据量，因为它无需比较变化前后的分布，而是集中于当前数据来识别漂移。CUSUM已经被增强，使用嵌套滑动窗口的双均值方法，这被称为**基于数据流的双CUSUM**（**DCUSUM-DS**）。CUSUM的另一个变体是DCUSUM-DS，它使用双均值的CUSUM。DCUSUM-DS算法在嵌套滑动窗口中工作，通过两次计算窗口内数据的平均值来检测漂移。检测到平均值后，它提取新特征，然后生成累积和受控图表，以避免虚假推断。这种方法的一个主要优点是，它可以检测到新特征并重新运行分析，以确保正确检测漂移，而不仅仅依赖于检测到的平均值。
- en: The kernel-based variant of CUSUM does not require the pre- and post-change
    distributions and instead depends on a database of samples from the pre-change
    distribution, with which it can continuously compare incoming observations with
    samples from the database. The kernel function chosen by the user and the statistical
    metric for comparison is MMD. The **Kernel Cumulative Sum** (**KCUSUM**) algorithm
    works well in settings where there is a huge amount of background data available,
    and when it is necessary to detect deviations from the background data.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: CUSUM的基于核的变体不需要变化前后的分布，而是依赖于变化前分布中的样本数据库，利用该数据库与进入的观察样本进行持续比较。用户选择的核函数和比较的统计指标是MMD。**核累积和**（**KCUSUM**）算法在拥有大量背景数据的情况下效果良好，尤其是在需要检测与背景数据偏差的情况下。
- en: 'The algorithm can be configured with a threshold that sets the limit beyond
    which an alarm is triggered. The magnitude of the drift threshold (say, 80%, 50%,
    or 30%) helps us to obtain the right metric for identifying a drift. Accordingly,
    an alarm needs to be raised when any deviations in the data or model pattern are
    observed. For example, an algorithm can be set to a very large amplitude with
    an 80% threshold boundary, which will enable it to detect drift more frequently
    than when it is set to 30%. The detector returns the following values:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法可以配置一个阈值，设置超过该阈值时触发警报。漂移阈值的大小（例如，80%、50%或30%）帮助我们获得识别漂移的正确指标。因此，当数据或模型模式出现任何偏差时，需要触发警报。例如，算法可以设置为非常大的幅度，并且80%的阈值边界将使其比设置为30%时更频繁地检测到漂移。检测器返回以下值：
- en: '`ta`: Change detection index – a return value that represents the alarm time
    (the index when the change was detected)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ta`：变化检测指标 —— 返回值表示报警时间（检测到变化时的索引）'
- en: '`tai`: Starting index of change – shows the index when the change started'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tai`：变化的起始索引 —— 显示变化开始时的索引'
- en: '`taf`: Ending index of change – denotes the index when the change ended (if
    `ending` is `True`)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`taf`：变化的结束索引 —— 表示变化结束时的索引（如果`ending`为`True`）'
- en: '`amp`: Denotes the amplitude of the changes (if `ending` is `True`)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`amp`：表示变化的幅度（如果`ending`为`True`）'
- en: One way to configure the parameters is to start with a very large `threshold`
    value and set `drift` to half of the expected change. We can also adjust `drift`
    so that `g` is `0` more than 50% of the time. We can then fine-tune `threshold`
    so the required number of false alarms or delays in detecting drift is obtained.
    For faster drift detection, we need to decrease `drift`, whereas to reduce false
    alarms and minimize the effect of small changes, we need to increase `drift`.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 配置参数的一种方法是从一个非常大的`threshold`值开始，并将`drift`设置为预期变化的一半。我们还可以调整`drift`，使得`g`有超过50%的时间为`0`。然后，我们可以微调`threshold`，以便获得所需的虚假警报或延迟检测漂移的数量。为了更快地检测漂移，我们需要减小`drift`，而为了减少虚假警报并最小化小变化的影响，我们需要增大`drift`。
- en: 'The following code snippet demonstrates how to use the CUSUM drift detector:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段演示了如何使用CUSUM漂移探测器：
- en: '[PRE14]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: The preceding code is able to detect drift between a range of data, illustrated
    in the following figure, by drift percentage, threshold, and the number of instances
    of change.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码能够检测出不同数据区间之间的漂移，通过漂移百分比、阈值和变化实例的数量来进行说明。
- en: '![Figure 11.10 – CUSUM drift detector change detections](img/Figure_11.10_B18681.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.10 – CUSUM漂移探测器变化检测](img/Figure_11.10_B18681.jpg)'
- en: Figure 11.10 – CUSUM drift detector change detections
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.10 – CUSUM漂移探测器变化检测
- en: The threshold-based drift detection technique used here demonstrates (*Figure
    11**.10*) the role of the CUSUM of positive and negative changes in detecting
    drift.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用的基于阈值的漂移检测技术展示了(*图 11.10*)在检测漂移时，CUSUM对正负变化的作用。
- en: Covariate and prior probability data drift
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 协变量和先验概率数据漂移
- en: Covariate drift occurs due to changes in the distributions of one or more of
    the independent features due to internal or external factors, but the relationship
    between the input *X* and target *Y* remains the same. While the distribution
    of input feature *X* changes with covariate data drift, with prior probability
    shift, the distribution of the input variables remains the same but the distribution
    of the target variable changes. Changes in the target distribution result in prior
    probability data drift. To implement covariate drift, we apply a shift to the
    mean of one of the normal distributions.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 协变量漂移是由于内部或外部因素引起的一个或多个独立特征的分布发生变化，但输入*X*和目标*Y*之间的关系保持不变。当协变量数据漂移时，输入特征*X*的分布发生变化，而在先验概率变化下，输入变量的分布保持不变，但目标变量的分布发生变化。目标分布的变化导致了先验概率数据漂移。为了实现协变量漂移，我们将一个正态分布的均值进行偏移。
- en: The model is now being tested on a new region of the feature space, causing
    the model to misclassify new test observations. In the absence of true test labels,
    it is impossible to measure the model’s accuracy. Here, the drift detector helps
    by detecting whether covariate or prior probability drift is occurring. If it’s
    the latter, a proxy for prior drift can be monitored by initializing the detector
    on labels from the reference set, which is then fed into a model’s predicted labels
    to identify drift.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型现在正在新区域的特征空间中进行测试，导致模型错误分类新的测试观测。在没有真实测试标签的情况下，无法衡量模型的准确性。在这种情况下，漂移探测器可以帮助检测是否发生了协变量漂移或先验概率漂移。如果是后者，可以通过在参考集的标签上初始化探测器来监控先验漂移的代理，然后将其输入到模型的预测标签中，以识别漂移。
- en: 'The following steps illustrate how to detect data drift by comparing it with
    the original model trained on the initial dataset:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤展示了如何通过与初始数据集上训练的原始模型进行比较来检测数据漂移：
- en: 'First, we take a multivariate normal distribution and then specify the reference
    data to initialize the detectors:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们采用多变量正态分布，然后指定参考数据以初始化探测器：
- en: '[PRE15]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We stack the reference distributions and try to estimate the drift by comparing
    it with `true_slope`, which has been set to `-1`:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们堆叠参考分布，并通过与`true_slope`进行比较来估计漂移，`true_slope`已被设置为`-1`：
- en: '[PRE16]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The code snippet generates the following plots to demonstrate a use case of
    no drift versus covariate drift, exhibiting lower mean accuracy where there is
    drift (right side) than where there is none (left side).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码片段生成以下图表，以演示无漂移与协变量漂移的用例，显示出漂移情况下（右侧）均值准确度较低，而没有漂移时（左侧）较高。
- en: '![Figure 11.11 – Covariate data drift](img/Figure_11.11_B18681.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.11 – 协变量数据漂移](img/Figure_11.11_B18681.jpg)'
- en: Figure 11.11 – Covariate data drift
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.11 – 协变量数据漂移
- en: 'While *Figure 11**.11* shows covariate data drift, the following code demonstrates
    the use of the MMD method, in which an estimate of the expected squared difference
    between the kernel **conditional** mean embeddings of *X*ref | *C* and *X*test
    | *C* are computed to evaluate the test statistic:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当*图 11.11*展示协变量数据漂移时，以下代码演示了MMD方法的使用，其中计算了*X*ref | *C*和*X*test | *C*的核**条件**均值嵌入之间的期望平方差，以评估测试统计量：
- en: '[PRE17]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We get the following output:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '[PRE18]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The MMD detector detects drift with a distance of `0.1076`, and the threshold
    of drift detection is `0.013342`.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: MMD探测器在`0.1076`的距离下检测到漂移，漂移检测的阈值为`0.013342`。
- en: Least-squared density difference
  id: totrans-159
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 最小二乘密度差异
- en: The `[0,1]` and predicts the same binary outcomes.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`[0,1]`并预测相同的二元结果。'
- en: 'The LSDD online drift detector from `alibi_detect` necessitates an **Expected
    Runtime** (**ERT**) (an inverted **False Positive Rate** (**FPR**)), allowing
    the detector to run an average number of steps in the absence of drift before
    making a false detection. With a high ERT, detectors lose their sensitivity and
    become slow to respond, so the configuration adjusts the trade-off between the
    ERT and the expected detection delay to target desirable ERTs. The best way to
    simulate the desired configuration is to select training data that is an order
    of magnitude larger than the desired ERT:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 来自`alibi_detect`的 LSDD 在线漂移检测器需要一个**期望运行时间**（**ERT**）（反向的**假阳性率**（**FPR**）），使得检测器在没有漂移的情况下运行平均步数，之后才可能产生错误检测。若
    ERT 较高，检测器的敏感度降低，响应变慢，因此该配置会在 ERT 和期望检测延迟之间调整权衡，以针对理想的 ERT 进行优化。模拟所需配置的最佳方式是选择比所需
    ERT 大一个数量级的训练数据：
- en: 'In the following code snippet, the model is trained on white wine samples,
    which form the reference distribution, and red wine samples are drawn from a drifted
    distribution. The steps following the upcoming code block illustrate how to run
    LSDD drift detection, and how it helps to compare no drift versus drift:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下代码片段中，模型在白葡萄酒样本上进行训练，这些样本形成了参考分布，而红葡萄酒样本则来自漂移的分布。接下来的步骤展示了如何运行 LSDD 漂移检测，并帮助比较无漂移与有漂移的情况：
- en: '[PRE19]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the first run, without the detector set, we do not detect any drift:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一次运行中，没有设置检测器，我们没有检测到任何漂移：
- en: '[PRE20]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The preceding code yields the following output:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码产生如下输出：
- en: '[PRE21]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following code snippet imports `LSDDDriftOnline` from `alibi_detect` and
    sets it up with reference data, `ert`, `window_size`, the number of runs, and
    a TensorFlow backend both for the original and current distributions to detect
    drift. Then, the online drift detector is run with an `ert` value of `50` and
    `window_size` of `10`:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码片段从`alibi_detect`导入`LSDDDriftOnline`并通过参考数据、`ert`、`window_size`、运行次数以及原始分布和当前分布的
    TensorFlow 后端来设置漂移检测器。然后，在线漂移检测器以`ert`值为`50`和`window_size`为`10`运行：
- en: '[PRE22]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This produces the following output:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![Figure 11.12 – LSDD drift detector](img/Figure_11.12_B18681.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.12 – LSDD 漂移检测器](img/Figure_11.12_B18681.jpg)'
- en: Figure 11.12 – LSDD drift detector
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.12 – LSDD 漂移检测器
- en: '*Figure 11.12* demonstrates online drift detection with LSDD. Here, we let
    the detector run a configurable number of times (50) or iterations and configure
    5,500 bootstraps to detect the drift. The bootstraps are used to run the simulations
    and configure the thresholds. A greater magnitude helps to achieve better accuracy
    in terms of obtaining the ERT, and it is typically configured to be an order of
    magnitude larger than the ERT.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 11.12* 演示了使用 LSDD 进行在线漂移检测。在这里，我们让检测器运行可配置的次数（50）或迭代，并配置 5,500 次自助法（bootstraps）来检测漂移。自助法用于运行模拟并配置阈值。更大的数量有助于提高获取
    ERT 的准确性，通常配置为比 ERT 大一个数量级。'
- en: 'We get the following output:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到如下输出：
- en: '[PRE23]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Furthermore, we observe that the detector on the held-out reference data in
    the first run follows a geometric distribution with mean ERT, without having any
    drift. However, as soon as drift is detected, the detector is very fast to respond,
    as shown in *Figure 11**.12*.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们观察到，在第一次运行时，保留的参考数据上的检测器遵循几何分布，均值为 ERT，且没有漂移。然而，一旦检测到漂移，检测器反应非常迅速，如*图 11.12*所示。
- en: Page-Hinkley
  id: totrans-177
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Page-Hinkley
- en: 'This method of drift detection functions by detecting changes by computing
    the observed values and their mean up to the current moment. Without issuing any
    warning signals, it runs the PH test to detect concept drift if the observed mean
    is found to exceed a threshold lambda value. Mathematically, it can be formulated
    as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这种漂移检测方法通过计算观察值及其均值来检测变化，直到当前时刻。如果发现观察均值超过阈值 lambda 值，则不会发出任何警告信号，而是运行 PH 测试来检测概念漂移。数学上，它可以表示为：
- en: '![](img/Formula_11_003.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_11_003.jpg)'
- en: When gt– Gt > h, an alarm is raised.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当 gt– Gt > h 时，会触发警报。
- en: 'Now, let us walk through the step-by-step process of detecting drift using
    the PH method:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们逐步了解使用 PH 方法检测漂移的过程：
- en: 'The following code sample demonstrates how we simulate two distributions:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码示例演示了我们如何模拟两个分布：
- en: '[PRE24]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, we compose and plot a data stream composed of three data distributions:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们组合并绘制一个由三种数据分布组成的数据流：
- en: '[PRE25]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, we update the drift detector and see whether a change has been detected:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们更新漂移检测器并查看是否检测到变化：
- en: '[PRE26]'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We get the following output. We see that drift is detected for three different
    distributions of the graph at different points in time. The change detection points
    are printed on two sides of the plot.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们得到以下输出。我们看到在不同时间点检测到图表的三个不同分布的漂移。变化检测点打印在图表的两侧。
- en: '![Figure 11.13 – Drift detected at three ranges of a distribution with a PH
    detector](img/Figure_11.13_B18681.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.13 – 使用PH探测器在分布的三个范围内检测到漂移](img/Figure_11.13_B18681.jpg)'
- en: Figure 11.13 – Drift detected at three ranges of a distribution with a PH detector
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.13 – 使用PH探测器在分布的三个范围内检测到漂移
- en: The Fast Hoeffding Drift Detection Method
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 快速Hoeffding漂移检测方法
- en: The **Fast Hoeffding Drift Detection Method** (**FHDDM**) allows the constant
    tracking of a sliding window of values of the probability of correct predictions
    along with the maximum observed probability values. A drift is said to have occurred
    when the correct prediction probability drops below the maximum configured value,
    along with the difference in probabilities exceeding a threshold.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '**快速Hoeffding漂移检测方法**（**FHDDM**）允许持续追踪正确预测概率的滑动窗口值以及观察到的最大概率值。当正确预测概率低于最大配置值，并且概率差异超过阈值时，就认为发生了漂移。'
- en: Paired learner
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配对学习器
- en: The **paired learner** (**PL**) mechanism includes two learners, one of which
    is a stable learner that gets trained on all data, and the other learner is trained
    on recent data. A counter is incremented each time the stable learner makes an
    error in prediction but the recent learner does not. To account for mistakes,
    a counter is decremented each time the recent learner makes an error in prediction.
    Once the increment counter exceeds a specified threshold, drift is considered
    to have occurred. This mechanism involves heavy computation to train new models
    and to have two learners in place.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '**配对学习器**（**PL**）机制包括两个学习器，一个是对所有数据进行训练的稳定学习器，另一个是对最近数据进行训练的学习器。每当稳定学习器在预测中出错而最近学习器没有出错时，计数器就会递增。为了弥补错误，每当最近学习器在预测中出错时，计数器就会递减。一旦计数器的增量超过指定的阈值，就认为发生了漂移。该机制涉及大量计算，用于训练新模型并保持两个学习器。'
- en: Exponentially Weighted Moving Average Concept Drift Detection
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指数加权滑动平均概念漂移检测
- en: In the **Exponentially Weighted Moving Average Concept Drift Detection** (**ECDD**)
    method, the **exponentially weighted moving average** (**EWMA**) forecast is used
    by calculating the forecast’s mean and standard deviation continuously. It is
    often used to monitor and detect the misclassification rate of a streaming classifier.
    Drift is detected when the forecast exceeds the sum of the mean plus a multiple
    factor/coefficient of the standard deviation.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在**指数加权滑动平均概念漂移检测**（**ECDD**）方法中，通过连续计算预测的均值和标准差，使用**指数加权滑动平均**（**EWMA**）预测。它通常用于监控和检测流分类器的误分类率。当预测值超过均值加上标准差的倍数时，就检测到漂移。
- en: Feature distribution
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征分布
- en: This drift detection technique functions without response feedback by identifying
    a change in *p(y|x)* due to a corresponding change in *p(x)*. This change can
    be detected using any multivariate unsupervised drift detection technique.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这种漂移检测技术通过识别*p(y|x)*由于*p(x)*的相应变化来实现，无需反馈响应。可以使用任何多元无监督漂移检测技术来检测这种变化。
- en: Drift in a regression model
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回归模型中的漂移
- en: To detect drift in a regression model, you take the regression error (a real
    number) and apply any unsupervised drift detection technique to the error data.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 要在回归模型中检测漂移，您需要取回归误差（一个实数）并对误差数据应用任何无监督漂移检测技术。
- en: Ensemble and hierarchy drift detectors
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集成和层次漂移检测器
- en: Ensemble detectors work primarily on an agreed consensus level, where consensus
    can be derived from only a few, all, or a majority of learners. Hierarchical detectors
    come into play only after drift is detected by a detector at the first level using
    any of the drift detection techniques discussed previously. Then, the consensus
    approach can be used to validate the result at other levels, starting from the
    next level. Some ensemble and hierarchy drift detector algorithms include **Linear
    Fore Rates** (**LFR**), **Selective Detector Ensemble** (**eDetector**), **Drift
    Detection Ensemble** (**DDE**), and **Hierarchical Hypothesis** **Testing** (**HLFR**).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 集成检测器主要基于一致性水平工作，其中一致性可以从少数、全部或大多数学习者中得出。层次化检测器仅在第一级检测器通过任何先前讨论的漂移检测技术检测到漂移后才会起作用。然后，可以使用一致性方法在其他级别验证结果，从下一级开始。一些集成和层次漂移检测算法包括**线性前馈率**（**LFR**）、**选择性检测器集成**（**eDetector**）、**漂移检测集成**（**DDE**）和**层次假设测试**（**HLFR**）。
- en: Now that we have looked at different types of concept drift detection techniques,
    let us discuss model explainability whenever there is drift/calibration.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了不同类型的概念漂移检测技术，接下来我们讨论在漂移/校准时的模型可解释性。
- en: Multivariate drift detection with PCA
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 PCA 进行多变量漂移检测
- en: To detect drift from multivariate data distributions, we use **Principal Component
    Analysis** (**PCA**) by compressing the data to a lower-dimensional space and
    then decompressing the data to retrieve the original feature representation. As
    we preserve only the relevant information in the transformation process, the reconstruction
    errors (evaluated using the Euclidean distance between the original and transformed
    data) help us to identify a change in data relationships among one or multiple
    features. In the first step, we compute the PCA on the original reference dataset
    and store the reconstruction errors with allowable limits of upper and lower thresholds.
    The process is repeated with the new data, where we compress and decompress the
    data using PCA. When the reconstruction errors exceed the upper or lower threshold,
    it signifies a change in data distribution.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从多变量数据分布中检测漂移，我们通过**主成分分析**（**PCA**）将数据压缩到一个低维空间，然后再解压数据以恢复原始特征表示。由于我们在转换过程中仅保留相关信息，重建误差（通过原始数据和转换数据之间的欧氏距离评估）帮助我们识别一个或多个特征之间数据关系的变化。在第一步中，我们在原始参考数据集上计算
    PCA，并存储带有允许上下限阈值的重建误差。然后对新数据重复此过程，在该过程中我们使用 PCA 对数据进行压缩和解压。当重建误差超过上限或下限阈值时，表示数据分布发生了变化。
- en: 'The following code demonstrates how we can detect multivariate feature drift:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码演示了如何检测多变量特征漂移：
- en: 'In the first step, we have the necessary imports:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一步中，我们进行必要的导入：
- en: '[PRE27]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Next, we have a random data setup based on its three features:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们基于其三个特征进行随机数据设置：
- en: '[PRE28]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Next, we can do a further interpretation of the independent feature, but the
    goal is to set up the drift detector as follows:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们可以进一步解释独立特征，但目标是按照以下方式设置漂移检测器：
- en: '[PRE29]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: This yields what is shown in *Figure 11**.14*, where we see that the data has
    drifted from 0.84 to 0.80.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这产生了*图 11.14*中所示的结果，在其中我们看到数据从 0.84 漂移到 0.80。
- en: '![Figure 11.14 – Multivariate drift detector using PCA](img/Figure_11.14_B18681.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.14 – 使用 PCA 的多变量漂移检测器](img/Figure_11.14_B18681.jpg)'
- en: Figure 11.14 – Multivariate drift detector using PCA
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.14 – 使用 PCA 的多变量漂移检测器
- en: Understanding model explainability during concept drift/calibration
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解概念漂移/校准过程中的模型可解释性
- en: 'In the preceding section, we learned about different types of concept drift.
    Now, let us study how we can explain them with interpretable ML:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们学习了不同类型的概念漂移。现在，让我们研究如何通过可解释的机器学习来解释它们：
- en: 'First, we import the necessary packages for creating a regression model and
    the drift explainer library. The California Housing dataset has been used to explain
    concept drift:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入创建回归模型和漂移解释库所需的包。加利福尼亚住房数据集已被用来解释概念漂移：
- en: '[PRE30]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, we train the XGBoost regressor model:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们训练 XGBoost 回归模型：
- en: '[PRE31]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'In the next step, we fit our trained model using `ModelDriftExplainer`, plot
    the prediction, and retrieve any drift, if it is observed by the explainer:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一步中，我们使用 `ModelDriftExplainer` 拟合我们的训练模型，绘制预测图，并提取任何漂移，如果解释器观察到的话：
- en: '[PRE32]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The following figure illustrates differences in drift detection in two different
    datasets.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 下图说明了在两个不同数据集中的漂移检测差异。
- en: '![Figure 11.15 – Drift from the input features or data distributions of two
    datasets](img/Figure_11.15_B18681.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.15 – 两个数据集的输入特征或数据分布的漂移](img/Figure_11.15_B18681.jpg)'
- en: Figure 11.15 – Drift from the input features or data distributions of two datasets
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.15 – 两个数据集的输入特征或数据分布的漂移
- en: In *Figure 11.15*, it is evident that there isn’t any apparent drift in the
    distributions of the predictions.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 11.15*中，可以明显看出预测分布中没有出现明显的漂移。
- en: 'Then, we plot the target labels to evaluate any drift in the predicted outcomes:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们绘制目标标签来评估预测结果中是否有漂移：
- en: '[PRE33]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'However, as shown in *Figure 11.16*, we do not observe any apparent drift in
    the target labels:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如*图 11.16*所示，我们并没有观察到目标标签的明显漂移：
- en: '![Figure 11.16 – Drift from the target data distributions of the California
    Housing dataset](img/Figure_11.16_B18681.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.16 – 加利福尼亚住房数据集目标数据分布的漂移](img/Figure_11.16_B18681.jpg)'
- en: Figure 11.16 – Drift from the target data distributions of the California Housing
    dataset
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.16 – 加利福尼亚住房数据集目标数据分布的漂移
- en: 'In the next step, when we evaluate the performance metrics of the California
    Housing train and test datasets, we can see a data drift from the mean and the
    explained variance of the performance metrics:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在接下来的步骤中，当我们评估加利福尼亚住房训练集和测试集的数据性能指标时，我们可以看到性能指标的均值和解释方差出现了数据漂移：
- en: '[PRE34]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'On running the drift explainer on the California Housing dataset, we get the
    following output:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行加利福尼亚住房数据集的漂移解释器时，我们得到以下输出：
- en: '[PRE35]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Our next task is to plot drift values computed with the tree-based approach,
    obtain the feature importances of the California Housing dataset, and use `AdversarialDriftExplainer`
    on the datasets. This is illustrated in *Figure 11**.17*, which clearly shows
    that the `Neighborhood_OldTown` and `BsmtQual_Gd` features are the features most
    impacted by the drift:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的下一个任务是绘制基于树的方法计算出的漂移值，获取加利福尼亚住房数据集的特征重要性，并在数据集上使用`AdversarialDriftExplainer`。如*图
    11.17*所示，`Neighborhood_OldTown`和`BsmtQual_Gd`特征是受到漂移影响最大的特征：
- en: '![Figure 11.17 – Feature importance in the resultant drift](img/Figure_11.17_B18681.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.17 – 结果漂移中的特征重要性](img/Figure_11.17_B18681.jpg)'
- en: Figure 11.17 – Feature importance in the resultant drift
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.17 – 结果漂移中的特征重要性
- en: 'In the end, we can plot each feature and evaluate the drift for each of them,
    as shown in *Figure 11**.18*. Here, `Neighborhood_OldTown`, the first feature,
    does not show any noticeable drift between the train and test datasets:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终，我们可以绘制每个特征并评估它们的漂移，如*图 11.18*所示。这里，`Neighborhood_OldTown`，第一个特征，在训练集和测试集之间没有显示出明显的漂移：
- en: '[PRE36]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The preceding code snippet yields the following output, showing the difference
    between the two datasets is not significant, as `p_value` is 0.996 > 0.05:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段输出以下结果，显示两个数据集之间的差异不显著，因为`p_value`是0.996 > 0.05：
- en: '[PRE37]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '![Figure 11.18 – Distribution differences/drift due to the Neighborhood_Old_Town
    feature](img/Figure_11.18_B18681.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.18 – 由于 Neighborhood_Old_Town 特征导致的分布差异/漂移](img/Figure_11.18_B18681.jpg)'
- en: Figure 11.18 – Distribution differences/drift due to the Neighborhood_Old_Town
    feature
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.18 – 由于 Neighborhood_Old_Town 特征导致的分布差异/漂移
- en: After gaining an understanding of drift, as data scientists, we also need to
    understand when we need to calibrate our models in the event of any change.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解漂移后，作为数据科学家，我们还需要理解在发生变化时，何时需要对模型进行校准。
- en: Understanding the need for model calibration
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 理解模型校准的必要性
- en: Recommendation systems (content-based filtering or hybrid systems) are used
    in almost all industry sectors, including retail, telecoms, and energy and utilities.
    Deep learning recommendation models using user-to-user or item-to-item embeddings
    with explainability features have been able to build trust and confidence and
    improve the user experience. Deep learning recommendation systems have often used
    attention distributions to explain the neural network’s performance, but such
    explanations in the case of **natural language processing** (**NLP**) are limited
    by poor calibrations of deep neural networks.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统（基于内容的过滤或混合系统）几乎在所有行业领域中都得到了应用，包括零售、电信、能源和公用事业。使用用户到用户或项目到项目嵌入的深度学习推荐模型，通过可解释性特征建立了信任和信心，并改善了用户体验。深度学习推荐系统通常使用注意力分布来解释神经网络的性能，但在**自然语言处理**（**NLP**）的情况下，这种解释受到深度神经网络校准不良的限制。
- en: It has been observed that models become less reliable due to over-confidence
    or under-confidence impacting models designed for healthcare (disease detection)
    and autonomous driving, among others. In such a scenario where model reliability
    comes into question, it is important to have a metric such as model calibration
    in place so that the degree of a model’s predicted probability is correlated with
    its true correctness likelihood, which determines the model's performance.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 已观察到，由于过度自信或缺乏自信，模型的可靠性会受到影响，特别是对于设计用于医疗保健（疾病检测）和自动驾驶等领域的模型。在模型的可靠性受到质疑的情况下，使用像模型校准这样的度量标准至关重要，因为它能够确保模型预测的概率与其真实正确性的可能性相关联，从而决定模型的性能。
- en: In other words, a calibrated model can be called authentic when it has a high
    confidence level (more than 80%, say) where more than 80% of the predictions are
    classified accurately. We can also use model calibration to plot reliability plots.
    This serves as the accuracy of the model by interpreting reliability as a function
    of its confidence in the predictions. An over-confident model’s reliability plot
    falls below the identity function, while an under-confident plot’s reliability
    goes above the identity function. We also see that an authentic calibrated model
    provides the perfect classification boundary where the reliability plot can be
    benchmarked as the identity function.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，当一个经过校准的模型具有较高的置信度（比如超过80%）时，可以称其为真实有效的模型，此时超过80%的预测结果被准确分类。我们还可以通过模型校准来绘制可靠性图。这可以作为模型的准确性，通过将可靠性解释为模型对预测的置信度的函数来实现。过于自信的模型的可靠性图低于身份函数，而缺乏信心的模型的可靠性图则高于身份函数。我们还可以看到，经过校准的真实模型提供了完美的分类边界，其中可靠性图可以作为身份函数进行基准测试。
- en: '*Figure 11**.19* contains a reliability plot for the **Deep Item-Based Collaborative
    Filtering** (**DeepICF**) model. DeepICF examines nonlinear and higher-order relationships
    among all interacting item pairs by training them using nonlinear neural networks.
    It can help us to understand how we model the predictions in different groups
    and study the trade-off between accuracy and confidence through a reliability
    plot.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '*图11.19*包含了**深度基于物品的协同过滤**（**DeepICF**）模型的可靠性图。DeepICF通过使用非线性神经网络训练所有交互物品对，检查物品之间的非线性和高阶关系。它有助于我们理解如何在不同组中建模预测，并通过可靠性图研究准确性与置信度之间的权衡。'
- en: '![ Figure 11.19 – A reliability plot for the DeepICF model](img/Figure_11.19_B18681.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![图11.19 – DeepICF模型的可靠性图](img/Figure_11.19_B18681.jpg)'
- en: Figure 11.19 – A reliability plot for the DeepICF model
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.19 – DeepICF模型的可靠性图
- en: 'We segmented the model predictions into different buckets based on their confidence
    and calculated the accuracy for each of them. *Figure 11**.19* demonstrates the
    DeepICF model (with attention networks: [https://www.researchgate.net/publication/333866071_Model_Explanations_under_Calibration](https://www.researchgate.net/publication/333866071_Model_Explanations_under_Calibration))
    becoming over-confident as the confidence increases for both positive and negative
    classes. The DeepICF model is a deep neural network that is produced after learning
    latent low-dimensional embeddings of users and items. The pair-wise user and item
    interactions are captured with a neural network layer by means of an element-wise
    dot product. Further, the model also uses attention based pooling to yield an
    output vector of fixed size. This leads to a drop in accuracy for imbalanced and
    negatively skewed datasets, demonstrating that model explanations generated from
    the attention distribution become less reliable with over-confident predictions.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将模型的预测结果按置信度分成不同的区间，并计算每个区间的准确性。*图11.19*展示了DeepICF模型（带有注意力网络：[https://www.researchgate.net/publication/333866071_Model_Explanations_under_Calibration](https://www.researchgate.net/publication/333866071_Model_Explanations_under_Calibration)）随着置信度的增加，正负类别的预测变得过于自信。DeepICF模型是一个深度神经网络，它通过学习用户和物品的潜在低维嵌入生成。通过逐元素点积，神经网络层捕捉用户和物品之间的配对交互。此外，该模型还使用基于注意力的池化方法生成固定大小的输出向量。这导致在不平衡和负偏态数据集上准确性下降，表明通过注意力分布生成的模型解释在过于自信的预测下变得不那么可靠。
- en: Now, let us discuss how explainability and model calibration can be brought
    together when we see drifts in a model’s predicted outcomes.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论一下当我们看到模型预测结果出现漂移时，如何将可解释性和模型校准结合起来。
- en: Explainability and calibration
  id: totrans-256
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可解释性与校准
- en: Model explainability and proper model calibration can be achieved by addressing
    imbalance in the dataset and by adding stability to attention distributions. However,
    one more problem that needs to be addressed is the calibration drift resulting
    from the same factors as concept drift. One example evident in the healthcare
    industry is poorly calibrated risk predictions with changing patient characteristics
    and disease incidence or prevalence rates in different health centers, regions,
    and countries. When an algorithm is trained in a setting with a high disease incidence,
    it is dominated by the model inputs and yields overestimated risk estimates. When
    such calibration drift occurs due to the deployment of models in nonstationary
    environments, these models require retraining and recalibration. Recalibration
    helps to fix the model’s accuracy and confidence levels and, consequently, the
    reliability plot.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 通过解决数据集中的不平衡问题并为注意力分布添加稳定性，可以实现模型可解释性和适当的模型校准。然而，另一个需要解决的问题是由概念漂移引起的校准漂移。在医疗行业中，一个明显的例子是由于患者特征和不同健康中心、地区及国家的疾病发生率或流行率变化，导致风险预测校准不佳。当一个算法在高疾病发生率的环境中训练时，它会受到模型输入的主导，导致风险估计过高。当这种校准漂移由于模型在非静态环境中的部署发生时，这些模型需要重新训练和重新校准。重新校准有助于修复模型的准确性和置信度，从而提高可靠性图。
- en: 'Now, let us see, with an example, why it is necessary to calibrate a recommendation
    model, which is most useful in the following situations:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过一个例子来看看为什么在以下情况下有必要对推荐模型进行校准：
- en: When a change in user preferences is observed due to the addition of new customer
    segments in the population
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当由于人口中新客户群体的加入而观察到用户偏好的变化时
- en: When a change in user preferences is observed among existing customers
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当观察到现有客户中用户偏好的变化时
- en: When there are promotions/campaigns or new products are released
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当有促销/活动或新产品发布时
- en: 'In the following example, let us study how post-preprocessing logic can be
    embedded in an underlying recommendation algorithm to ensure the recommendation
    becomes more calibrated. To explain this problem, we will use `movielens-20m-dataset`:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将研究如何将后处理逻辑嵌入到底层推荐算法中，以确保推荐结果变得更加校准。为了说明这个问题，我们将使用`movielens-20m-dataset`：
- en: 'To compute the utility metrics of recommender systems, we must compute the
    KL divergence between the user-item interaction distribution and the recommendation
    distribution. Here, we have chosen an associated lambda term that controls the
    score and calibration trade-off. The higher the lambda, the higher the probability
    that the resulting recommendation will be calibrated:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了计算推荐系统的效用指标，我们必须计算用户-项目交互分布与推荐分布之间的KL散度。在这里，我们选择了一个相关的lambda项，用来控制评分和校准之间的权衡。lambda值越高，最终推荐结果被校准的概率越大：
- en: '[PRE38]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The utility function defined here is invoked at each iteration to update the
    list with the item that maximizes the utility function:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里定义的效用函数在每次迭代时都会被调用，以更新列表并选择最大化效用函数的项目：
- en: '[PRE39]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The lambda term allows us to tweak the controller (lambda) to extremely elevated
    levels to generate the modified calibrated recommendation list. Now, let us differentiate
    and evaluate the computed recommendation generated after calibrating it (to optimize
    the score, 𝑠), the original recommendation, and the user’s past relationship with
    the items. Here, 𝑠(𝑖) represents the score of the items, 𝑖∈𝐼, predicted by the
    recommender system, and s(I) = ∑i ∈ Is(i) denotes the sum of all the items’ scores
    in the newly generated list:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: lambda项允许我们将控制器(lambda)调整到极高的水平，以生成修改后的校准推荐列表。现在，让我们对校准后的计算推荐进行区分和评估（以优化评分𝑠），并与原始推荐及用户与项目的历史关系进行比较。这里，𝑠(𝑖)表示推荐系统预测的项目评分，𝑖∈𝐼，s(I)
    = ∑i ∈ Is(i)表示新生成列表中所有项目评分的总和：
- en: '[PRE40]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Here, we observe that the calibrated recommendation has larger coverage of the
    genre, and its distribution looks like that of the distribution of the user’s
    past interactions and the calibration metric. KL divergence also ensures that
    the value generated from the calibrated recommendations is lower than the original
    recommendation’s score. Even though the precision of calibrated recommendation
    distribution (0.125) is lower than the original distribution’s precision (0.1875),
    we can further control the lambda to achieve an acceptable trade-off between precision
    and calibration.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们观察到校准后的推荐在类型覆盖面上更广，并且其分布看起来类似于用户过去互动的分布和校准度量。KL 散度还确保从校准推荐生成的值低于原始推荐的分数。即使校准推荐分布的精度（0.125）低于原始分布的精度（0.1875），我们仍然可以进一步控制
    λ，达到精度与校准之间的可接受平衡。
- en: '![Figure 11.20 – Comparing a user’s historical distribution and calibrated
    recommendation distribution](img/Figure_11.20_B18681.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.20 – 比较用户历史分布和校准推荐分布](img/Figure_11.20_B18681.jpg)'
- en: Figure 11.20 – Comparing a user’s historical distribution and calibrated recommendation
    distribution
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.20 – 比较用户历史分布和校准推荐分布
- en: In the preceding discussion, we saw the importance of developing a calibrated
    model due to changes in the input data and the model. Now, let us discuss, from
    the standpoint of ethical AI, how to incorporate fairness into models and build
    calibrated models.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的讨论中，我们看到了由于输入数据和模型的变化，开发校准模型的重要性。现在，让我们从伦理AI的角度，讨论如何将公平性纳入模型并构建校准模型。
- en: Challenges with calibration and fairness
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 校准和公平性的挑战
- en: So far, we have learned what it means to have a fair ML model across different
    population subgroups so that the prediction results are unbiased across all races,
    ethnicities, genders, and other population categories. From the standpoint of
    AI ethics, we should also try to design fair and calibrated models, and in the
    process, try to understand the risks associated with them. To design a fair and
    calibrated model, it is essential that a group of people assigned a predicted
    probability of *p* of generic ML models sees a fair representation. To achieve
    this, we should have a *p* fraction of members of this set belonging to positive
    instances of the classification problem.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了什么是跨不同人群子群体的公平机器学习模型，使得预测结果在所有种族、民族、性别和其他人口类别中都不会存在偏差。从AI伦理的角度来看，我们还应尝试设计公平且校准的模型，并在过程中理解与其相关的风险。为了设计一个公平且校准的模型，至关重要的是，赋予预测概率为
    *p* 的群体，在通用机器学习模型中能够看到公平的代表性。为了实现这一点，我们应该让这组成员的 *p* 部分属于分类问题中的正实例。
- en: Thus, to justify fairness between two groups, G1 and G2 (such as African-American
    and white defendants), the best way to satisfy both groups is for the calibration
    condition to hold simultaneously for each individual within each of these groups
    as well.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了证明两个组之间的公平性，G1 和 G2（例如非洲裔美国人和白人被告），满足两组公平性的最佳方式是校准条件在每个组内的每个个体上同时成立。
- en: However, calibration and error-rate constraints have mutually conflicting goals.
    Research studies demonstrate that calibration is tolerant only with a single error
    constraint (which is equal false negative rates across groups). It also becomes
    increasingly hard to minimize error disparity across different population groups
    with calibrated probability estimates. Even when the objective is satisfied, the
    resulting solution resembles a generic classifier, which only optimizes for a
    percentage of predictions. Thus, to summarize, a perfectly fair and calibrated
    model cannot be designed.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，校准和误差率约束有着相互冲突的目标。研究表明，校准仅在存在单一误差约束时是容忍的（即各组之间的假阴性率相等）。此外，在使用校准概率估计时，跨不同人群群体最小化误差差异变得越来越困难。即使目标得以满足，得到的解决方案也类似于一个通用分类器，它仅优化一部分预测结果。因此，总结来说，无法设计出一个完全公平且校准的模型。
- en: Summary
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have learned about different ideas related to concept drift.
    These can be applied to both streaming (batch streams) and live data as well as
    trained ML models. We also learned how both statistical and contextual methods
    play an important role in estimating model metrics by determining model drift.
    The chapter also answered some important questions related to model drift and
    explainability and helped you to understand model calibration. In the context
    of calibration, we also learned about fairness and calibration and the limitations
    of achieving both at the same time.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了与概念漂移相关的不同思想。这些思想可以应用于流式数据（批处理流）、实时数据以及训练好的机器学习模型。我们还学习了统计方法和上下文方法如何在通过判断模型漂移来估计模型度量指标时发挥重要作用。本章还回答了一些关于模型漂移和可解释性的重要问题，并帮助你理解模型校准。在校准的背景下，我们还讨论了公平性与校准，以及如何同时实现两者的局限性。
- en: In the next chapter, we will learn more about model evaluation techniques and
    handling uncertainties in model-building pipelines.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习更多关于模型评估技术以及如何处理模型构建流程中的不确定性。
- en: Further reading
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '*8 Concept Drift Detection* *Methods*: [https://www.aporia.com/blog/concept-drift-detection-methods/](https://www.aporia.com/blog/concept-drift-detection-methods/)'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*8种概念漂移检测* *方法*：[https://www.aporia.com/blog/concept-drift-detection-methods/](https://www.aporia.com/blog/concept-drift-detection-methods/)'
- en: '*On Fairness and* *Calibration*: [https://proceedings.neurips.cc/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf](https://proceedings.neurips.cc/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf)'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*关于公平性与* *校准*：[https://proceedings.neurips.cc/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf](https://proceedings.neurips.cc/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf)'
- en: '*Calibrated* *Recommendations*: [http://ethen8181.github.io/machine-learning/recsys/calibration/calibrated_reco.html](http://ethen8181.github.io/machine-learning/recsys/calibration/calibrated_reco.html)'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*校准的* *推荐系统*：[http://ethen8181.github.io/machine-learning/recsys/calibration/calibrated_reco.html](http://ethen8181.github.io/machine-learning/recsys/calibration/calibrated_reco.html)'
