- en: Chapter 4. Generative Adversarial Networks (GANs)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章 生成对抗网络（GANs）
- en: In this chapter, we'll be investigating **Generative Adversarial Networks**
    (**GAN**s) [1], the first of three artificial intelligence algorithms that we'll
    be looking at. GANs belong to the family of generative models. However, unlike
    autoencoders, generative models are able to create new and meaningful outputs
    given arbitrary encodings.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究**生成对抗网络**（**GAN**s）[1]，这是我们将要研究的三种人工智能算法中的第一个。GAN属于生成模型的范畴。然而，与自编码器不同，生成模型能够根据任意编码生成新的、有意义的输出。
- en: In this chapter, the working principles of GANs will be discussed. We'll also
    review the implementations of several early GANs within Keras. While later on
    the chapter, we'll be demonstrating the techniques needed to achieve stable training.
    The scope of this chapter covers two popular examples of GAN implementations,
    **Deep Convolutional GAN** (**DCGAN**) [2] and **Conditional GAN** (**CGAN**)
    [3].
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将讨论GAN的工作原理。我们还将回顾Keras中几个早期GAN的实现。稍后，我们将展示实现稳定训练所需的技术。本章的范围涵盖了两种流行的GAN实现示例，**深度卷积生成对抗网络**（**DCGAN**）[2]和**条件生成对抗网络**（**CGAN**）[3]。
- en: 'In summary, the goal of this chapter is to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，本章的目标是：
- en: Introduce the principles of GANs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍生成对抗网络（GAN）的原理
- en: How to implement GANs such as DCGAN and CGAN in Keras
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在Keras中实现GAN，如DCGAN和CGAN
- en: An overview of GANs
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN概述
- en: Before we move into the more advanced concepts of GANs, let's start by going
    over GANs, and introducing the underlying concepts of them. GANs are very powerful;
    this simple statement is proven by the fact that they can generate new celebrity
    faces that are not of real people by performing latent space interpolations.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入研究GAN的更高级概念之前，我们先来回顾一下GAN，并介绍它们的基本概念。GAN非常强大；这一简单的说法通过它们能够生成虚拟名人面孔来证明这一点，这些面孔并非真实人物，而是通过进行潜空间插值生成的。
- en: A great example of the advanced features of GANs [4] can be seen with this YouTube video
    ([https://youtu.be/G06dEcZ-QTg](https://youtu.be/G06dEcZ-QTg)). The video, which
    shows how GANs can be utilized to produce realistic faces just shows how powerful
    they can be. This topic is much more advanced than anything we've looked at before
    in this book. For example, the above video is something that can't be accomplished
    easily by autoencoders, which we covered in [Chapter 3](ch03.html "Chapter 3. Autoencoders"),
    *Autoencoders*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的高级特性[4]的一个绝佳示例可以通过这个YouTube视频（[https://youtu.be/G06dEcZ-QTg](https://youtu.be/G06dEcZ-QTg)）看到。视频展示了如何利用GAN生成逼真的面孔，这显示了它们的强大功能。这个话题比我们在本书中之前讨论的任何内容都要复杂。例如，上述视频是自编码器无法轻易实现的，正如我们在[第3章](ch03.html
    "第3章. 自编码器")中讨论的，*自编码器*。
- en: GANs are able to learn how to model the input distribution by training two competing
    (and cooperating) networks referred to as **generator** and **discriminator**
    (sometimes known as **critic**). The role of the generator is to keep on figuring
    out how to generate fake data or signals (this includes, audio and images) that
    can fool the discriminator. Meanwhile, the discriminator is trained to distinguish
    between fake and real signals. As the training progresses, the discriminator will
    no longer be able to see the difference between the synthetically generated data
    and the real ones. From there, the discriminator can be discarded, and the generator
    can now be used to create new realistic signals that have never been observed
    before.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: GAN能够通过训练两个竞争（又互相合作）的网络来学习如何建模输入分布，这两个网络被称为**生成器**和**判别器**（有时也称为**评论器**）。生成器的角色是不断探索如何生成能够欺骗判别器的虚假数据或信号（这包括音频和图像）。与此同时，判别器被训练用来区分真假信号。随着训练的进行，判别器将无法再分辨合成数据与真实数据之间的差异。从这里开始，判别器可以被丢弃，而生成器可以用来创造前所未见的全新、逼真的信号。
- en: The underlying concept of GANs is straightforward. However, one thing we'll find is that
    the most challenging aspect is how do we achieve stable training of the generator-discriminator
    network? There must be a healthy competition between the generator and discriminator
    in order for both networks to be able to learn simultaneously. Since the loss
    function is computed from the output of the discriminator, its parameters update
    is fast. When the discriminator converges faster, the generator no longer receives
    sufficient gradient updates for its parameters and fails to converge. Other than
    being hard to train, GANs can also suffer from either a partial or total modal
    collapse, a situation wherein the generator is producing almost similar outputs
    for different latent encodings.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的基本概念很简单。然而，我们会发现最具挑战性的问题是如何实现生成器-判别器网络的稳定训练？生成器和判别器必须进行健康的竞争，以便两个网络能够同时学习。由于损失函数是从判别器的输出计算的，其参数更新速度很快。当判别器收敛得更快时，生成器不再接收到足够的梯度更新以便其参数收敛。除了难以训练外，GAN还可能遭受部分或完全的模态崩溃，即生成器对不同的潜在编码几乎产生相似的输出。
- en: Principles of GANs
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GAN的原理
- en: As shown in *Figure 4.1.1* a GAN is analogous to a counterfeiter (generator)
    - police (discriminator) scenario. At the academy, the police are taught how to
    determine if a dollar bill is either genuine or fake. Samples of real dollar bills
    from the bank and fake money from the counterfeiter are used to train the police.
    However, from time to time, the counterfeiter will attempt to pretend that he
    printed real dollar bills. Initially, the police will not be fooled and will tell
    the counterfeiter why the money is fake. Taking into consideration this feedback,
    the counterfeiter hones his skills again and attempts to produce new fake dollar
    bills. As expected the police will be able to both spot the money as fake and
    justify why the dollar bills are fake.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 4.1.1*所示，GAN类似于一个赝品制造者（生成器）和警察（判别器）的场景。在学院里，警察被教导如何判断一张美元是真是假。从银行得到的真钞样本和赝品制造者的假钱用来训练警察。然而，赝品制造者偶尔会试图假装他印了真钞。起初，警察不会上当，会告诉赝品制造者这些钱为什么是假的。考虑到这些反馈，赝品制造者再次磨练技能，试图制造新的假美元。预计警察将能够识破这些假币，并且证明为何这些美元是假的。
- en: '![Principles of GANs](img/B08956_04_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![GAN的原理](img/B08956_04_01.jpg)'
- en: 'Figure 4.1.1: The generator and discriminator of GANs are analogous to the
    counterfeiter and the police. The goal of the counterfeiter is to fool the police
    into believing that the dollar bill is real.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1.1：GAN的生成器和判别器类似于赝品制造者和警察。赝品制造者的目标是欺骗警察认为这些美元是真的。
- en: This scenario continues indefinitely but eventually, a time will come when the
    counterfeiter has mastered his skills in making fake dollar bills that are indistinguishable
    from real ones. The counterfeiter can then infinitely print dollar bills without
    getting caught by the police as they are no longer indefinable as counterfeit.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况将无限期地继续下去，但最终会有一个时机，赝品制造者掌握了制作与真钞无法区分的假美元的技能。赝品制造者随后可以无限制地印刷美元，而不会被警察逮捕，因为这些假币已经无法被定义为伪造品。
- en: '![Principles of GANs](img/B08956_04_02.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![GAN的原理](img/B08956_04_02.jpg)'
- en: 'Figure 4.1.2: A GAN is made up of two networks, a generator, and a discriminator.
    The discriminator is trained to distinguish between real and fake signals or data.
    The generator''s job is to generate fake signals or data that can eventually fool
    the discriminator.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1.2：GAN由两个网络组成，生成器和判别器。判别器被训练来区分真实和假的信号或数据。生成器的任务是生成能最终愚弄判别器的假信号或数据。
- en: As shown in *Figure 4.1.2*, a GAN is made up of two networks, a generator, and
    a discriminator. The input to the generator is noise, and the output is a synthesized
    signal. Meanwhile, the discriminator's input will be either a real or a synthesized
    signal. Genuine signals come from the true sampled data, while the fake signals
    come from the generator. All of the valid signals are labeled 1.0 (that is, 100%
    probability of being real) while all the synthesized signals are labeled 0.0 (that
    is, 0% probability of being real). Since the labeling process is automated, GANs
    are still considered part of the unsupervised learning approach in deep learning.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 4.1.2*所示，GAN 由两个网络组成，一个生成器和一个鉴别器。生成器的输入是噪声，输出是合成信号。与此同时，鉴别器的输入将是一个真实信号或合成信号。真实信号来自真实的采样数据，而伪造信号来自生成器。所有有效信号被标记为
    1.0（即 100% 真实的概率），而所有合成信号被标记为 0.0（即 0% 真实的概率）。由于标记过程是自动化的，GAN 仍然被认为是深度学习中无监督学习方法的一部分。
- en: The objective of the discriminator is to learn from this supplied dataset on
    how to distinguish real signals from fake signals. During this part of GAN training,
    only the discriminator parameters will be updated. Like a typical binary classifier,
    the discriminator is trained to predict on a range of 0.0 to 1.0 in confidence
    values on how close a given input signal is to the true one. However, this is
    only half of the story.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴别器的目标是从提供的数据集中学习如何区分真实信号和伪造信号。在 GAN 训练的这一部分，只有鉴别器的参数会被更新。像典型的二元分类器一样，鉴别器被训练以预测输入信号与真实信号之间的相似度，输出值在
    0.0 到 1.0 的范围内表示其信心值。然而，这只是故事的一半。
- en: At regular intervals, the generator will pretend that its output is a genuine
    signal and will ask the GAN to label it as 1.0\. When the fake signal is then
    presented to the discriminator, naturally it will be classified as fake with a
    label close to 0.0\. The optimizer computes the generator parameter updates based
    on the presented label (that is, 1.0). It also takes its own prediction into account
    when training on this new data. In other words, the discriminator has some doubt
    about its prediction, and so, GANs takes that into consideration. This time, GANs
    will let the gradients backpropagate from the last layer of the discriminator
    down to the first layer of the generator. However, in most practices, during this
    phase of training, the discriminator parameters are temporarily frozen. The generator
    will use the gradients to update its parameters and improve its ability to synthesize
    fake signals.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在规律的间隔下，生成器将假装它的输出是一个真实信号，并要求 GAN 将其标记为 1.0。当伪造信号呈现给鉴别器时，它自然会被分类为伪造，并被标记为接近
    0.0。优化器根据所呈现的标签（即 1.0）计算生成器参数的更新。它还会在训练这个新数据时考虑自身的预测。换句话说，鉴别器对其预测有一定的怀疑，因此，GAN
    会考虑到这一点。这时，GAN 会让梯度从鉴别器的最后一层反向传播到生成器的第一层。然而，在大多数实践中，在这个训练阶段，鉴别器的参数通常是冻结的。生成器将使用这些梯度来更新其参数，并提高其合成伪造信号的能力。
- en: Overall, the whole process is akin to two networks competing with one another
    while still cooperating at the same time. When the GAN training converges, the
    end result is a generator that can synthesize signals. The discriminator thinks
    these synthesized signals are real or with a label near 1.0, which means the discriminator
    can then be discarded. The generator part will be useful in producing meaningful
    outputs from arbitrary noise inputs.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这个过程类似于两个网络彼此竞争，同时又在某种程度上相互合作。当 GAN 训练收敛时，最终结果是一个可以合成信号的生成器。鉴别器认为这些合成的信号是真的，或者它们的标签接近
    1.0，这意味着鉴别器可以被丢弃。生成器部分将在从任意噪声输入中产生有意义的输出时发挥作用。
- en: '![Principles of GANs](img/B08956_04_03.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![GAN 原理](img/B08956_04_03.jpg)'
- en: 'Figure 4.1.3: Training the discriminator is similar to training a binary classifier
    network using binary cross-entropy loss. The fake data is supplied by the generator
    while real data is from true samples.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1.3：训练鉴别器类似于使用二元交叉熵损失训练一个二分类网络。伪造数据由生成器提供，真实数据来自真实样本。
- en: 'As shown in the preceding figure, the discriminator can be trained by minimizing
    the loss function in the following equation:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，鉴别器可以通过最小化以下方程中的损失函数来进行训练：
- en: '![Principles of GANs](img/B08956_04_001.jpg) (Equation 4.1.1)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![GAN 原理](img/B08956_04_001.jpg) （方程 4.1.1）'
- en: 'The equation is just the standard binary cross-entropy cost function. The loss
    is the negative sum of the expectation of correctly identifying real data, ![Principles
    of GANs](img/B08956_04_002.jpg), and the expectation of 1.0 minus correctly identifying
    synthetic data, ![Principles of GANs](img/B08956_04_003.jpg). The log does not
    change the location of the local minima. Two mini-batches of data are supplied
    to the discriminator during training:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 该方程就是标准的二元交叉熵损失函数。损失是正确识别真实数据的期望值的负和，![GANs 原理](img/B08956_04_002.jpg)，以及正确识别合成数据的
    1.0 减去期望值，![GANs 原理](img/B08956_04_003.jpg)。对数不会改变局部最小值的位置。训练时，判别器会提供两小批次数据：
- en: '![Principles of GANs](img/B08956_04_004.jpg), real from sampled data (that
    is, ![Principles of GANs](img/B08956_04_005.jpg)) with label 1.0'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![GANs 原理](img/B08956_04_004.jpg)，来自采样数据的真实数据（即，![GANs 原理](img/B08956_04_005.jpg)），标签为
    1.0'
- en: '![Principles of GANs](img/B08956_04_006.jpg) , fake data from the generator
    with label 0.0'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![GANs 原理](img/B08956_04_006.jpg)，来自生成器的假数据，标签为 0.0'
- en: In order to minimize the loss function, the discriminator parameters, ![Principles
    of GANs](img/B08956_04_007.jpg), will be updated through backpropagation by correctly
    identifying the genuine data, ![Principles of GANs](img/B08956_04_008.jpg), and
    synthetic data, ![Principles of GANs](img/B08956_04_009.jpg). Correctly identifying
    real data is equivalent to ![Principles of GANs](img/B08956_04_010.jpg) while
    correctly classifying fake data is the same as ![Principles of GANs](img/B08956_04_011.jpg)
    or ![Principles of GANs](img/B08956_04_012.jpg). In this equation, ![Principles
    of GANs](img/B08956_04_013.jpg) is the arbitrary encoding or noise vector that
    is used by the generator to synthesize new signals. Both contribute to minimizing
    the loss function.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最小化损失函数，判别器的参数，![GANs 原理](img/B08956_04_007.jpg)，将通过反向传播来更新，通过正确识别真实数据，![GANs
    原理](img/B08956_04_008.jpg)，以及合成数据，![GANs 原理](img/B08956_04_009.jpg)。正确识别真实数据等同于![GANs
    原理](img/B08956_04_010.jpg)，而正确分类假数据则等同于![GANs 原理](img/B08956_04_011.jpg) 或者![GANs
    原理](img/B08956_04_012.jpg)。在这个方程中，![GANs 原理](img/B08956_04_013.jpg) 是生成器用来合成新信号的任意编码或噪声向量。两者共同作用于最小化损失函数。
- en: 'To train the generator, GAN considers the total of the discriminator and generator
    losses as a zero-sum game. The generator loss function is simply the negative
    of the discriminator loss function:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练生成器，GAN 将判别器和生成器的损失视为零和博弈。生成器的损失函数只是判别器损失函数的负值：
- en: '![Principles of GANs](img/B08956_04_014.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![GANs 原理](img/B08956_04_014.jpg)'
- en: (Equation 4.1.2)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: （公式 4.1.2）
- en: 'This can then be rewritten more aptly as a value function:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以更恰当地重新写成一个价值函数：
- en: '![Principles of GANs](img/B08956_04_015.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![GANs 原理](img/B08956_04_015.jpg)'
- en: (Equation 4.1.3)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: （公式 4.1.3）
- en: 'From the perspective of the generator, *Equation 4.1.3* should be minimized.
    From the point of view of the discriminator, the value function should be maximized.
    Therefore, the generator training criterion can be written as a minimax problem:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 从生成器的角度来看，*公式 4.1.3* 应该被最小化。从判别器的角度来看，价值函数应该被最大化。因此，生成器的训练准则可以写成一个最小最大问题：
- en: '![Principles of GANs](img/B08956_04_016.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![GANs 原理](img/B08956_04_016.jpg)'
- en: (Equation 4.1.4)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: （公式 4.1.4）
- en: 'Occasionally, we''ll try to fool the discriminator by pretending that the synthetic
    data is real with label 1.0\. By maximizing with respect to ![Principles of GANs](img/B08956_04_017.jpg),
    the optimizer sends gradient updates to the discriminator parameters to consider
    this synthetic data as real. At the same time, by minimizing with respect to ![Principles
    of GANs](img/B08956_04_018.jpg), the optimizer will train the generator''s parameters
    on how to trick the discriminator. However, in practice, the discriminator is
    confident in its prediction in classifying the synthetic data as fake and will
    not update its parameters. Furthermore, the gradient updates are small and have
    diminished significantly as they propagate to the generator layers. As a result,
    the generator fails to converge:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们会通过伪装合成数据为真实数据（标签为 1.0）来试图欺骗判别器。通过相对于![GANs 原理](img/B08956_04_017.jpg)的最大化，优化器向判别器参数发送梯度更新，使其将该合成数据视为真实数据。与此同时，通过相对于![GANs
    原理](img/B08956_04_018.jpg)的最小化，优化器将训练生成器的参数，教其如何欺骗判别器。然而，实际上，判别器在将合成数据分类为假数据时非常自信，因此不会更新其参数。此外，梯度更新很小，并且在传播到生成器层时已经大大减弱。因此，生成器未能收敛：
- en: '![Principles of GANs](img/B08956_04_04.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![GANs 原理](img/B08956_04_04.jpg)'
- en: 'Figure 4.1.4: Training the generator is like training a network using a binary
    cross-entropy loss function. The fake data from the generator is presented as
    genuine.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1.4：训练生成器就像使用二元交叉熵损失函数训练一个网络。生成器产生的假数据被当作真实数据展示。
- en: 'The solution is to reformulate the loss function of the generator in the form:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案是将生成器的损失函数重新构建为以下形式：
- en: '![Principles of GANs](img/B08956_04_019.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![GAN原理](img/B08956_04_019.jpg)'
- en: (Equation 4.1.5)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: （方程式4.1.5）
- en: The loss function simply maximizes the chance of the discriminator into believing
    that the synthetic data is real by training the generator. The new formulation
    is no longer zero-sum and is purely heuristics-driven. *Figure 4.1.4* shows the
    generator during training. In this figure, the generator parameters are only updated
    when the whole adversarial network is trained. This is because the gradients are
    passed down from the discriminator to the generator. However, in practice, the
    discriminator weights are only temporarily frozen during adversarial training.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数的作用是通过训练生成器来最大化判别器将合成数据认为是现实数据的可能性。新的公式不再是零和的，而是纯粹基于启发式的驱动。*图4.1.4* 展示了训练中的生成器。在这个图中，生成器的参数仅在整个对抗网络训练时更新。这是因为梯度从判别器传递给生成器。然而，实际上，在对抗训练过程中，判别器的权重只是暂时被冻结。
- en: In deep learning, both the generator and discriminator can be implemented using
    a suitable neural network architecture. If the data or signal is an image, both
    the generator and discriminator networks will use a CNN. For single-dimensional
    sequences like in NLP, both networks are usually recurrent (RNN, LSTM or GRU).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，生成器和判别器都可以使用合适的神经网络架构来实现。如果数据或信号是图像，生成器和判别器网络将使用CNN。对于像自然语言处理（NLP）中的一维序列，两个网络通常是递归网络（RNN、LSTM或GRU）。
- en: GAN implementation in Keras
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Keras中的GAN实现
- en: In the previous section, we learned that the principles behind GANs are straightforward.
    We also learned how GANs could be implemented by familiar network layers such
    as CNNs and RNNs. What differentiates GANs from other networks is they are notoriously
    difficult to train. Something as simple as a minor change in the layers can drive
    the network to training instability.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一部分中，我们了解到GAN的原理是直观的。我们还学会了如何通过熟悉的网络层，如CNN和RNN，来实现GAN。使GAN与其他网络不同的是，它们通常很难训练。即便是简单的层变化，也可能导致网络训练的不稳定。
- en: In this section, we'll examine one of the early successful implementations of GANs using
    deep CNNs. It is called DCGAN [3].
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我们将研究使用深度CNN实现的早期成功的GAN实现之一。它被称为DCGAN [3]。
- en: '*Figure 4.2.1* shows DCGAN that is used to generate fake MNIST images. DCGAN recommends
    the following design principles:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.2.1* 显示了用于生成假MNIST图像的DCGAN。DCGAN推荐以下设计原则：'
- en: Use of *strides* > 1 convolution instead of `MaxPooling2D` or `UpSampling2D`.
    With *strides* > 1, the CNN learns how to resize the feature maps.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用*步幅* > 1 的卷积，而不是`MaxPooling2D`或`UpSampling2D`。通过*步幅* > 1，卷积神经网络（CNN）学会了如何调整特征图的大小。
- en: Avoid using `Dense` layers. Use CNN in all layers. The `Dense` layer is utilized
    only as the first layer of the generator to accept the *z*-vector. The output
    of the `Dense` layer is resized and becomes the input of the succeeding CNN layers.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免使用`Dense`层。在所有层中使用CNN。`Dense`层仅用作生成器的第一层，用于接受*z*向量。`Dense`层的输出经过调整大小后，成为后续CNN层的输入。
- en: Use of **Batch Normalization** (**BN**) to stabilize learning by normalizing
    the input to each layer to have zero mean and unit variance. No BN in the generator
    output layer and discriminator input layer. In the implementation example to be
    presented here, no batch normalization is used in the discriminator.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**批量归一化**（**BN**）来通过标准化每一层的输入，使其均值为零，方差为单位，从而稳定学习。在生成器的输出层和判别器的输入层中不使用BN。在这里展示的实现示例中，判别器中不使用批量归一化。
- en: '**Rectified Linear Unit** (**ReLU**) is used in all layers of the generator
    except in the output layer where the *tanh* activation is utilized. In the implementation
    example to be presented here, *sigmoid* is used instead of *tanh* in the output
    of the generator since it generally results in a more stable training for MNIST digits.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修正线性单元**（**ReLU**）在生成器的所有层中使用，除了输出层，输出层使用*tanh*激活函数。在这里展示的实现示例中，输出层使用*sigmoid*而不是*tanh*，因为它通常能使MNIST数字的训练更加稳定。'
- en: Use of **Leaky ReLU** in all layers of the discriminator. Unlike ReLU, instead
    of zeroing out all outputs when the input is less than zero, Leaky ReLU generates
    a small gradient equal to *alpha* × *input*. In the following example, *alpha*
    = 0.2.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在鉴别器的所有层中使用 **Leaky ReLU**。与 ReLU 不同，当输入小于零时，Leaky ReLU 不会将所有输出置为零，而是生成一个小的梯度，等于
    *alpha* × *input*。在以下示例中，*alpha* = 0.2。
- en: '![GAN implementation in Keras](img/B08956_04_05.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![Keras 中的 GAN 实现](img/B08956_04_05.jpg)'
- en: 'Figure 4.2.1: A DCGAN model'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2.1：一个 DCGAN 模型
- en: The generator learns to generate fake images from 100-dim input vectors ([-1.0,
    1.0] range 100-dim random noise with uniform distribution). The discriminator
    classifies real from fake images but inadvertently coaches the generator how to
    generate real images when the adversarial network is trained. The kernel size
    used in our DCGAN implementation is 5, this is to allow it to increase the coverage
    and expressive power of the convolution.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器学习从 100 维输入向量生成假图像（[-1.0, 1.0] 范围的 100 维均匀分布随机噪声）。鉴别器将真实图像与假图像区分开，但在对抗网络训练过程中，无意中指导生成器如何生成真实图像。我们在
    DCGAN 实现中使用的卷积核大小为 5，目的是增加卷积的覆盖范围和表达能力。
- en: The generator accepts the 100-dim *z*-vector generated by a uniform distribution
    with a range of -1.0 to 1.0\. The first layer of the generator is a 7 × 7 ×128
    = 6,272 - *unit* `Dense` layer. The number of units is computed based on the intended
    ultimate dimensions of the output image (28 × 28 × 1, 28 is a multiple of 7) and
    the number of filters of the first `Conv2DTranspose`, which is equal to 128\.
    We can imagine transposed CNNs (`Conv2DTranspose`) as the reversed process of
    CNN. In a simple example, if a CNN converts an image to feature maps, a transposed
    CNN will produce an image given feature maps. Hence, transposed CNNs were used
    in the decoder in the previous chapter and here on generators.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器接受由均匀分布生成的 100 维 *z* 向量，范围为 -1.0 到 1.0。生成器的第一层是一个 7 × 7 × 128 = 6,272 个 *单元*
    的 `Dense` 层。单元的数量是根据输出图像的最终尺寸（28 × 28 × 1，28 是 7 的倍数）以及第一层 `Conv2DTranspose` 的滤波器数量（等于
    128）来计算的。我们可以将反卷积神经网络（`Conv2DTranspose`）看作是卷积神经网络（CNN）过程的反向过程。简单地说，如果 CNN 将图像转化为特征图，则反卷积
    CNN 会根据特征图生成图像。因此，反卷积 CNN 在上一章的解码器和本章的生成器中都得到了应用。
- en: After undergoing two `Conv2DTranspose` with `strides = 2`, the feature maps
    will have a size of 28 × 28 × *number of filters*. Each `Conv2DTranspose` is preceded
    by batch normalization and ReLU. The final layer has *sigmoid* activation that
    generates the 28 × 28 × 1 fake MNIST images. Each pixel is normalized to [0.0, 1.0]
    corresponding to [0, 255] grayscale levels. Following listing shows the implementation
    of the generator network in Keras. A function is defined to build the generator
    model. Due to the length of the entire code, we will limit the listing to the
    particular lines being discussed.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在经过两次 `Conv2DTranspose`（`strides = 2`）处理后，特征图的大小将为 28 × 28 × *滤波器数量*。每个 `Conv2DTranspose`
    前都进行批归一化和 ReLU 激活。最终层使用 *sigmoid* 激活函数，生成 28 × 28 × 1 的假 MNIST 图像。每个像素被归一化到 [0.0,
    1.0]，对应于 [0, 255] 的灰度级别。以下列表显示了在 Keras 中实现生成器网络的代码。我们定义了一个函数来构建生成器模型。由于整个代码较长，我们将仅列出与讨论相关的部分。
- en: Note
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The complete code is available on GitHub: [https://github.com/PacktPublishing/Advanced-Deep-](https://github.com/PacktPublishing/Advanced-Deep-)
    [Learning-with-Keras](http://Learning-with-Keras).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 完整代码可在 GitHub 上获取：[https://github.com/PacktPublishing/Advanced-Deep-](https://github.com/PacktPublishing/Advanced-Deep-)
    [Learning-with-Keras](http://Learning-with-Keras)。
- en: 'Listing 4.2.1, `dcgan-mnist-4.2.1.py` shows us the generator network builder
    function for DCGAN:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 4.2.1，`dcgan-mnist-4.2.1.py` 向我们展示了 DCGAN 的生成器网络构建函数：
- en: '[PRE0]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The discriminator is similar to many CNN-based classifiers. The input is a 28
    × 28 × 1 MNIST image that is classified as either real (1.0) or fake (0.0). There
    are four CNN layers. Except for the last convolution, each `Conv2D` uses `strides
    = 2` to down sample the feature maps by two. Each `Conv2D` is then preceded by
    a Leaky ReLU layer. The final filter size is 256, while the initial filter size
    is 32 and doubles every convolution layer. The final filter size of 128 also works.
    However, we'll find that the generated images look better with 256\. The final
    output layer is flattened, and a single unit `Dense` layer generates the prediction
    between 0.0 to 1.0 after scaling by the sigmoid activation layer. The output is
    modeled as a Bernoulli distribution. Hence, the binary cross-entropy loss function
    is used.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器与许多基于CNN的分类器类似。输入是一个28 × 28 × 1的MNIST图像，分类为真实（1.0）或虚假（0.0）。共有四个CNN层。除了最后一个卷积层外，每个`Conv2D`都使用`strides
    = 2`来对特征图进行下采样。每个`Conv2D`层后面都接一个Leaky ReLU层。最终的滤波器大小是256，而初始滤波器大小是32，并且每个卷积层的滤波器大小都会翻倍。最终的滤波器大小为128也能工作，但我们会发现，使用256时生成的图像效果更好。最终输出层会将特征图展平，并通过一个单元的`Dense`层在经过sigmoid激活层缩放后输出介于0.0到1.0之间的预测值。输出被建模为伯努利分布。因此，使用二元交叉熵损失函数。
- en: 'After building the generator and discriminator models, the adversarial model
    is made by concatenating the generator and discriminator networks. Both discriminator
    and adversarial networks use the RMSprop optimizer. The learning rate for the
    discriminator is 2e-4 while for the adversarial network, it is 1e-4\. RMSprop
    decay rates of 6e-8 for discriminator and 3e-8 for the adversarial network are
    applied. Setting the learning rate of the adversarial equal to half of the discriminator
    will result in a more stable training. We''ll recall from *Figure 4.1.3* and *4.1.4*,
    that the GAN training has two parts: discriminator training and generator training,
    which is adversarial training, with discriminator weights frozen.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建生成器和判别器模型后，通过连接生成器和判别器网络来构建对抗模型。判别器和对抗网络都使用RMSprop优化器。判别器的学习率为2e-4，而对抗网络的学习率为1e-4。应用RMSprop衰减率，判别器为6e-8，对抗网络为3e-8。将对抗网络的学习率设置为判别器的一半将使训练更加稳定。我们从*图4.1.3*和*4.1.4*中回忆到，GAN训练有两个部分：判别器训练和生成器训练，这是对抗训练，期间冻结判别器权重。
- en: '*Listing* *4.2.2* shows the implementation of the discriminator in Keras. A
    function is defined to build the discriminator model. In *Listing* *4.2.3*, we''ll
    illustrate how to build GAN models. Firstly, the discriminator model is built
    and following on from that the generator model is instantiated. The adversarial
    model is just the generator and the discriminator put together. Across many GANs,
    the batch size of 64 appears to be the most common. The network parameters are
    shown in *Listing* *4.2.3*.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单* *4.2.2*展示了在Keras中实现判别器的代码。定义了一个函数来构建判别器模型。在*清单* *4.2.3*中，我们将展示如何构建GAN模型。首先构建判别器模型，然后是生成器模型的实例化。对抗模型只是将生成器和判别器组合在一起。许多GAN模型中，批处理大小64似乎是最常见的。网络参数显示在*清单*
    *4.2.3*中。'
- en: As can be seen in *Listing* *4.2.1* and *4.2.2*, the DCGAN models are straightforward.
    What makes it difficult to build is small changes in the network design can easily
    break the training convergence. For example, if batch normalization is used in
    the discriminator or if `strides = 2` in the generator is transferred to the latter
    CNN layers, DCGAN will fail to converge.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如*清单* *4.2.1*和*4.2.2*所示，DCGAN模型是直观的。构建它的难点在于网络设计中的微小变化会轻易导致训练无法收敛。例如，如果在判别器中使用了批归一化，或者将生成器中的`strides
    = 2`转移到后面的CNN层，DCGAN将无法收敛。
- en: 'Listing 4.2.2, `dcgan-mnist-4.2.1.py` shows us the discriminator network builder
    function for DCGAN:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 清单4.2.2，`dcgan-mnist-4.2.1.py`展示了我们DCGAN判别器网络构建函数：
- en: '[PRE1]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Listing 4.2.3, `dcgan-mnist-4.2.1.py`: Function to build DCGAN models and call
    the training routine:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 清单4.2.3，`dcgan-mnist-4.2.1.py`：构建DCGAN模型并调用训练程序的函数：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Listing* *4.2.4* shows the function dedicated to training the discriminator
    and adversarial networks. Due to custom training, the usual `fit()` function is
    not going to be used. Instead, `train_on_batch()` is called up to run a single
    gradient update for the given batch of data. The generator is then trained via
    an adversarial network. The training first randomly picks a batch of real images
    from the dataset. This is labeled as real (1.0). Then a batch of fake images will
    be generated by the generator. This is labeled as fake (0.0). The two batches
    are concatenated and are used to train the discriminator.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单* *4.2.4* 显示了专门用于训练判别器和对抗网络的函数。由于自定义训练，通常的 `fit()` 函数不会被使用。相反，调用 `train_on_batch()`
    来对给定的数据批次进行单次梯度更新。接着，通过对抗网络来训练生成器。训练过程首先从数据集中随机选择一批真实图像，并将其标记为真实（1.0）。然后，生成器生成一批假图像，并将其标记为假（0.0）。这两批图像被连接在一起，用于训练判别器。'
- en: 'After this is completed, a new batch of fake images will be generated by the
    generator and labeled as real (1.0). This batch will be used to train the adversarial
    network. The two networks are trained alternately for about 40,000 steps. At regular
    intervals, the generated MNIST digits based on a certain noise vector are saved
    on the filesystem. At the last training step, the network has converged. The generator
    model is also saved on a file so we can easily reuse the trained model for future
    MNIST digits generation. However, only the generator model is saved since that
    is the useful part of GANs in the generation of new MNIST digits. For example,
    we can generate new and random MNIST digits by executing:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 完成此步骤后，生成器将生成新的假图像，并标记为真实（1.0）。这一批图像将用于训练对抗网络。两个网络会交替训练约 40,000 步。在规律的间隔中，基于某个噪声向量生成的
    MNIST 数字会保存在文件系统中。在最后的训练步骤中，网络已经收敛。生成器模型也会保存在文件中，以便我们可以轻松地重用已训练的模型来生成未来的 MNIST
    数字。然而，只有生成器模型会被保存，因为它才是 GAN 在生成新 MNIST 数字时的有用部分。例如，我们可以通过执行以下操作生成新的随机 MNIST 数字：
- en: '[PRE3]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Listing 4.2.4, `dcgan-mnist-4.2.1.py` shows us the function to train the discriminator
    and adversarial networks:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 4.2.4，`dcgan-mnist-4.2.1.py` 显示了用于训练判别器和对抗网络的函数：
- en: '[PRE4]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Figure 4.2.1* shows the evolution of fake images from the generator as a function
    of training steps. At 5,000 steps, the generator is already producing recognizable
    images. It''s very much like having an agent that knows how to draw digits. It''s
    worth noting that some digits change from one recognizable form (for example,
    8 on the 2nd column of the last row) to another (for example, 0). When the training
    converges, the discriminator loss reaches near 0.5 while the adversarial loss
    approaches near 1.0 as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4.2.1* 展示了生成器生成的假图像随着训练步骤的变化而演化的过程。在 5000 步时，生成器已经开始生成可识别的图像。这就像拥有一个能够画数字的代理一样。值得注意的是，一些数字会从一种可识别的形式（例如，最后一行第二列的
    8）变换成另一种形式（例如，0）。当训练收敛时，判别器损失接近 0.5，而对抗损失接近 1.0，如下所示：'
- en: '[PRE5]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![GAN implementation in Keras](img/B08956_04_06.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![Keras 中的 GAN 实现](img/B08956_04_06.jpg)'
- en: 'Figure 4.2.2: The fake images generated by the DCGAN generator at different
    training steps'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2.2：不同训练步骤下 DCGAN 生成器生成的假图像
- en: Conditional GAN
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条件生成对抗网络
- en: In the previous section, the fake images generated by the DCGAN are random.
    There is no control over which specific digits will be produced by the generator.
    There is no mechanism for how to request a particular digit from the generator.
    This problem can be addressed by a variation of GAN called **Conditional GAN**
    (**CGAN**) [4].
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，DCGAN 生成的假图像是随机的。生成器无法控制生成哪些特定的数字，也没有机制可以从生成器中请求某个特定的数字。这个问题可以通过一种叫做**条件生成对抗网络**（**CGAN**）的
    GAN 变种来解决[4]。
- en: Using the same GAN, a condition is imposed on both the generator and discriminator
    inputs. The condition is in the form of a one-hot vector version of the digit.
    This is associated with the image to produce (generator) or classified as real
    or fake (discriminator). The CGAN model is shown in *Figure 4.3.1*.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同的 GAN，对生成器和判别器的输入都施加一个条件。这个条件是数字的 one-hot 向量形式。这与要生成的图像（生成器）或是否被分类为真实或假（判别器）相关联。CGAN
    模型如*图 4.3.1*所示。
- en: 'CGAN is similar to DCGAN except for the additional one-hot vector input. For
    the generator, the one-hot label is concatenated with the latent vector before
    the `Dense` layer. For the discriminator, a new `Dense` layer is added. The new
    layer is used to process the one-hot vector and reshape it so that it is suitable
    for concatenation to the other input of the succeeding CNN layer:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: CGAN类似于DCGAN，唯一的区别是添加了独热向量输入。对于生成器，独热标签在进入 `Dense` 层之前与潜在向量连接。对于判别器，添加了一个新的
    `Dense` 层。这个新层用于处理独热向量并将其重塑，以便它能够与后续CNN层的其他输入进行拼接：
- en: '![Conditional GAN](img/B08956_04_08.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![条件生成对抗网络](img/B08956_04_08.jpg)'
- en: 'Figure 4.3.1: The CGAN model is similar to DCGAN except for the one-hot vector,
    which is used to condition the generator and discriminator outputs'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3.1：CGAN模型与DCGAN类似，唯一不同的是使用独热向量来对生成器和判别器的输出进行条件化。
- en: The generator learns to generate fake images from a 100-dim input vector and
    a specified digit. The discriminator classifies real from fake images based on
    real and fake images and their corresponding labels.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器学会从一个100维的输入向量和一个指定的数字生成假图像。判别器根据真实和假图像及其相应的标签来分类真假图像。
- en: The basis of CGAN is still the same as the original GAN principle except that
    the discriminator and generator inputs are conditioned on one-hot labels, *y*.
    By incorporating this condition in *Equations* *4.1.1* and *4.1.5*, the loss functions
    for the discriminator and generator are shown in *Equations* *4.3.1* and *4.3.2* respectively.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: CGAN的基础仍然与原始GAN原理相同，唯一的区别是判别器和生成器的输入是以独热标签 *y* 为条件的。通过将此条件结合到 *方程式* *4.1.1*
    和 *4.1.5* 中，判别器和生成器的损失函数分别如 *方程式* *4.3.1* 和 *4.3.2* 所示。
- en: 'Given *Figure 4.3.2*, it may be more appropriate to write the loss functions
    as:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 *图 4.3.2*，更合适的写法是将损失函数写作：
- en: '![Conditional GAN](img/B08956_04_021.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![条件生成对抗网络](img/B08956_04_021.jpg)'
- en: and
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![Conditional GAN](img/B08956_04_022.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![条件生成对抗网络](img/B08956_04_022.jpg)'
- en: .
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: '![Conditional GAN](img/B08956_04_023.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![条件生成对抗网络](img/B08956_04_023.jpg)'
- en: (Equation 4.3.1)
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: (方程式 4.3.1)
- en: '![Conditional GAN](img/B08956_04_025.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![条件生成对抗网络](img/B08956_04_025.jpg)'
- en: (Equation 4.3.2)
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: (方程式 4.3.2)
- en: The new loss function of the discriminator aims to minimize the error of predicting
    real images coming from the dataset and fake images coming from the generator
    given their one-hot labels. *Figure 4.3.2* shows how to train the discriminator.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器的新损失函数旨在最小化预测来自数据集的真实图像与来自生成器的假图像的错误，给定它们的独热标签。*图 4.3.2* 显示了如何训练判别器。
- en: '![Conditional GAN](img/B08956_04_09.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![条件生成对抗网络](img/B08956_04_09.jpg)'
- en: 'Figure 4.3.2: Training the CGAN discriminator is similar to training the GAN
    discriminator. The only difference is both the generated fake and the dataset''s
    real images are conditioned with their corresponding one-hot labels.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3.2：训练CGAN判别器与训练GAN判别器类似。唯一的区别是生成的假图像和数据集的真实图像都使用它们相应的独热标签进行条件化。
- en: 'The new loss function of the generator minimizes the correct prediction of
    the discriminator on fake images conditioned on the specified one-hot labels.
    The generator learns how to generate the specific MNIST digit given its one-hot
    vector that can fool the discriminator. The following figure shows how to train
    the generator:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器的新损失函数最小化判别器对根据指定的独热标签条件化的假图像的正确预测。生成器学会生成特定的MNIST数字，给定其独热向量，可以欺骗判别器。以下图像展示了如何训练生成器：
- en: '![Conditional GAN](img/B08956_04_07.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![条件生成对抗网络](img/B08956_04_07.jpg)'
- en: 'Figure 4.3.3: Training the CGAN generator through the adversarial network is
    similar to training GAN generator. The only difference is the generated fake images
    are conditioned with one-hot labels.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3.3：通过对抗网络训练CGAN生成器与训练GAN生成器类似。唯一的区别是生成的假图像是通过独热标签进行条件化的。
- en: Following listing highlights the minor changes needed in the discriminator model.
    The code processes the one-hot vector using a `Dense` layer and concatenates it
    with the image input. The `Model` instance is modified for the image and one-hot
    vector inputs.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 以下清单突出显示了判别器模型中所需的小修改。代码使用 `Dense` 层处理独热向量，并将其与图像输入连接。`Model` 实例被修改以适应图像和独热向量输入。
- en: Listing 4.3.1, `cgan-mnist-4.3.1.py` shows us the CGAN discriminator. In highlight
    are the changes made in DCGAN.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 4.3.1，`cgan-mnist-4.3.1.py` 向我们展示了CGAN判别器。高亮部分显示了DCGAN中做出的更改。
- en: '[PRE6]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Following listing highlights the code changes to incorporate the conditioning
    one-hot labels in the generator builder function. The `Model` instance is modified
    for the *z*-vector and one-hot vector inputs.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表突出显示了为了在生成器构建函数中加入条件化one-hot标签而做的代码更改。`Model`实例已针对*z*-向量和one-hot向量输入进行了修改。
- en: 'Listing 4.3.2, `cgan-mnist-4.3.1.py` shows us the CGAN generator. In highlight
    are the changes made in DCGAN:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.3.2，`cgan-mnist-4.3.1.py` 显示了CGAN生成器。突出显示了DCGAN中所做的更改：
- en: '[PRE7]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '*Listing* *4.3.3* highlights the changes made in the `train()` function to
    accommodate the conditioning one-hot vector for the discriminator and the generator.
    The CGAN discriminator is firstly trained with one batch of real and fake data
    conditioned on their respective one-hot labels. Then, the generator parameters
    are updated by training the adversarial network given one-hot label conditioned
    fake data pretending to be real. Similar to DCGAN, the discriminator weights are
    frozen during adversarial training.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表* *4.3.3* 突出显示了为适应判别器和生成器的条件化one-hot向量而对`train()`函数所做的更改。首先，CGAN判别器使用一批真实数据和假数据进行训练，数据根据它们各自的one-hot标签进行条件化。然后，通过训练对抗网络，更新生成器的参数，给定条件化的假数据，假数据伪装成真实数据。与DCGAN类似，在对抗训练过程中，判别器的权重被冻结。'
- en: 'Listing 4.3.3, `cgan-mnist-4.3.1.py` shows us the CGAN training. In highlight
    are the changes made in DCGAN:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 列表4.3.3，`cgan-mnist-4.3.1.py` 显示了CGAN训练过程。突出显示了DCGAN中所做的更改：
- en: '[PRE8]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '*Figure 4.3.4* shows the evolution of MNIST digits generated when the generator
    is conditioned to produce digits with the following labels:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.3.4* 显示了当生成器被设置为生成带有以下标签的数字时，生成的MNIST数字的演变：'
- en: '[0 1 2 3'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '[0 1 2 3'
- en: 4 5 6 7
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 4 5 6 7
- en: 8 9 0 1
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 8 9 0 1
- en: 2 3 4 5]
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 2 3 4 5]
- en: '![Conditional GAN](img/B08956_04_10.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![条件GAN](img/B08956_04_10.jpg)'
- en: 'Figure 4.3.4: The fake images generated by CGAN at different training steps
    when conditioned with labels [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3.4：在不同训练步骤中，当使用标签[0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]作为条件时，CGAN生成的假图像
- en: 'You''re encouraged to run the trained generator model to see new synthesized
    MNIST digits images:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 鼓励你运行训练好的生成器模型，以查看新的合成MNIST数字图像：
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Alternatively, a specific digit (for example, 8) to be generated can also be
    requested:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，也可以请求生成一个特定的数字（例如，8）：
- en: '[PRE10]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: With CGAN it's like having an agent that we can ask to draw digits similar to how humans
    write digits. The key advantage of CGAN over DCGAN is that we can specify which
    digit we want the agent to draw.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 使用CGAN就像拥有一个代理，我们可以要求它绘制类似人类书写的数字。CGAN相较于DCGAN的主要优势在于，我们可以指定代理绘制哪个数字。
- en: Conclusion
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This chapter discussed the general principles behind GANs, to give you a foundation
    to the more advanced topics we'll now move on to, including Improved GANs, Disentangled
    Representations GANs, and Cross-Doman GANs. We started this chapter by understanding
    how GANs are made up of two networks called generator and discriminator. The role
    of the discriminator is to discriminate between real and fake signals. The aim
    of the generator is to fool the discriminator. The generator is normally combined
    with the discriminator to form an adversarial network. It is through training
    the adversarial network that the generator learns how to produce fake signals
    that can trick the discriminator.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了生成对抗网络（GANs）背后的基本原理，为我们接下来的更高级话题奠定了基础，这些话题包括改进型GAN、解耦表示GAN和跨域GAN。我们从了解GAN是由两个网络组成——生成器和判别器开始。判别器的作用是区分真实信号和假信号。生成器的目标是欺骗判别器。生成器通常与判别器结合形成一个对抗网络。通过训练对抗网络，生成器学会如何生成能够欺骗判别器的假信号。
- en: We also learned how GANs are easy to build but notoriously difficult to train.
    Two example implementations in Keras were presented. DCGAN demonstrated that it
    is possible to train GANs to generate fake images using deep CNNs. The fake images
    are MNIST digits. However, the DCGAN generator has no control over which specific
    digit it should draw. CGAN addressed this problem by conditioning the generator
    to draw a specific digit. The condition is in the form of a one-hot label. CGAN
    is useful if we want to build an agent that can generate data of a specific class.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还了解到，虽然GANs很容易构建，但训练起来极为困难。文中展示了两个Keras中的示例实现。DCGAN展示了如何训练GAN生成假图像，这些假图像是MNIST数字。然而，DCGAN生成器无法控制应生成哪个具体数字。CGAN通过将生成器条件化为绘制特定数字来解决这个问题。条件是以one-hot标签的形式出现的。如果我们想构建一个能够生成特定类别数据的代理，CGAN是非常有用的。
- en: In the next chapter, improvements on the DCGAN and CGAN will be introduced.
    In particular, the focus is on how to stabilize the training of DCGAN and how
    to improve the perceptive quality of CGAN. This will be done by introducing new
    loss functions and slightly different model architectures.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，将介绍 DCGAN 和 CGAN 的改进。特别关注如何稳定 DCGAN 的训练以及如何提高 CGAN 的感知质量。这将通过引入新的损失函数和稍微不同的模型架构来实现。
- en: References
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Ian Goodfellow. *NIPS 2016 Tutorial: Generative Adversarial Networks*. arXiv
    preprint arXiv:1701.00160, 2016 ([https://arxiv.org/pdf/1701.00160.pdf](https://arxiv.org/pdf/1701.00160.pdf)).'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ian Goodfellow。*NIPS 2016 教程：生成对抗网络*。arXiv 预印本 arXiv:1701.00160，2016 ([https://arxiv.org/pdf/1701.00160.pdf](https://arxiv.org/pdf/1701.00160.pdf)).
- en: Alec Radford, Luke Metz, and Soumith Chintala. *Unsupervised Representation
    Learning with Deep Convolutional Generative Adversarial Networks*. arXiv preprint
    arXiv:1511.06434, 2015 ([https://arxiv.org/pdf/1511.06434.pdf](https://arxiv.org/pdf/1511.06434.pdf)).
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Alec Radford、Luke Metz 和 Soumith Chintala。*深度卷积生成对抗网络的无监督表示学习*。arXiv 预印本 arXiv:1511.06434，2015
    ([https://arxiv.org/pdf/1511.06434.pdf](https://arxiv.org/pdf/1511.06434.pdf)).
- en: Mehdi Mirza and Simon Osindero. *Conditional Generative Adversarial Nets*. arXiv
    preprint arXiv:1411.1784, 2014 ([https://arxiv.org/pdf/1411.1784.pdf](https://arxiv.org/pdf/1411.1784.pdf)).
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Mehdi Mirza 和 Simon Osindero。*条件生成对抗网络*。arXiv 预印本 arXiv:1411.1784，2014 ([https://arxiv.org/pdf/1411.1784.pdf](https://arxiv.org/pdf/1411.1784.pdf)).
- en: Tero Karras and others. *Progressive Growing of GANs for Improved Quality, Stability,
    and Variation*. ICLR, 2018 ([https://arxiv.org/pdf/1710.10196.pdf](https://arxiv.org/pdf/1710.10196.pdf)).
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Tero Karras 等人。*渐进增长的生成对抗网络：提高质量、稳定性和变化性*。ICLR，2018 ([https://arxiv.org/pdf/1710.10196.pdf](https://arxiv.org/pdf/1710.10196.pdf)).
