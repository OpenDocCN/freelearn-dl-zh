- en: '*Chapter 9*: Extracting Metadata from Financial Documents'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第9章*：从金融文档中提取元数据'
- en: In the previous chapter, we learned how to build an intelligent solution for
    media content monetization using AWS AI services. We did this by talking about
    how our fictitious company **LiveRight Holdings private limited** requires a cost-effective
    expansion for content monetization. We designed an architecture using AWS AI services,
    media services, and the content delivery network for an end-to-end walkthrough
    of how to monetize content in video files.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何利用 AWS AI 服务为媒体内容创收构建智能解决方案。我们讨论了如何通过我们虚构的公司 **LiveRight Holdings
    私人有限公司** 寻求低成本的内容创收扩展。我们设计了一个架构，结合了 AWS AI 服务、媒体服务和内容分发网络，提供了如何在视频文件中实现内容创收的端到端流程。
- en: In this chapter, we will look at how AWS AI services can help us extract metadata
    for financial filing reports for **LiveRight Holdings**. This will allow their
    financial analysts to look into important information and make better decisions
    concerning financial events such as mergers, acquisitions, and IPOs.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究 AWS AI 服务如何帮助我们提取 **LiveRight Holdings** 的财务报告元数据。这将使他们的金融分析师能够查看重要信息，并就合并、收购和
    IPO 等财务事件做出更好的决策。
- en: We will talk about what metadata is and why it is important to extract metadata.
    Then, we will cover how to use Amazon Comprehend entity extraction and how Amazon
    Comprehend events can be used to extract metadata from documents.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论什么是元数据，为什么提取元数据很重要。然后，我们将介绍如何使用 Amazon Comprehend 实体提取，以及如何使用 Amazon Comprehend
    事件从文档中提取元数据。
- en: 'In this chapter, we will be covering the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Extracting metadata from financial documents
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从金融文档中提取元数据
- en: Setting up the use case
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置使用案例
- en: Technical requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you will need access to an AWS account. Please make sure that
    you follow the instructions specified in the *Technical requirements* section
    of [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027), *Introducing
    Amazon Textract*, to create your AWS account, and log into the AWS Management
    Console before trying the steps in the *Extracting metadata from financial documents*
    section.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，您需要访问一个 AWS 账户。请确保按照[*第2章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)《介绍
    Amazon Textract》部分中指定的技术要求创建 AWS 账户，并登录 AWS 管理控制台，然后再尝试 *从金融文档中提取元数据* 部分中的步骤。
- en: The Python code and sample datasets for our solution can be found at [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2009](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2009).
    Please use the instructions in the following sections, along with the code in
    the aforementioned repository, to build the solution.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解决方案的 Python 代码和示例数据集可以在[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2009](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2009)找到。请按照以下部分中的说明以及上述仓库中的代码构建解决方案。
- en: Check out the following video to see the Code in Action at [https://bit.ly/3jBxp3E](https://bit.ly/3jBxp3E).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下视频，了解代码的实际应用：[https://bit.ly/3jBxp3E](https://bit.ly/3jBxp3E)。
- en: Extracting metadata from financial documents
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从金融文档中提取元数据
- en: 'In this section, we will talk about a use case where **LiveRight Holdings private
    limited** is attempting to acquire AwakenLife Pvt Ltd. They are going to do a
    press release soon and financial analysts are curious to identify the important
    metadata such as the acquisition date, amount, organization, and so forth so that
    they can act according to the market. LiveRight analyzed the Amazon Whole Foods
    merger to determine what it can learn and how metadata extraction will be useful
    for its due diligence. We will use the Amazon Whole Foods merger sample dataset
    to understand how you can perform metadata extraction using the preceding architecture:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论一个使用案例，其中 **LiveRight Holdings 私人有限公司** 正试图收购 AwakenLife Pvt Ltd。它们即将发布新闻稿，金融分析师希望识别重要的元数据，例如收购日期、金额、组织等，以便根据市场情况采取行动。LiveRight
    分析了 Amazon Whole Foods 合并案，以确定它能从中学到什么，以及元数据提取如何有助于其尽职调查。我们将使用 Amazon Whole Foods
    合并案的示例数据集，了解如何使用前述架构执行元数据提取：
- en: '![Figure 9.1 – Metadata extraction architecture](img/B17528_09_01.jpg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.1 – 元数据提取架构](img/B17528_09_01.jpg)'
- en: Figure 9.1 – Metadata extraction architecture
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 – 元数据提取架构
- en: In this architecture, we will start with large financial documents for extracting
    metadata. We will show you how you can use Amazon Textract batch processing jobs
    to extract data from this large document and save this extracted data as a text
    file. Then, we will show you how to extract entities from this text file using
    Comprehend Events and visualize the relationships between the entity using a knowledge
    graph. Alternatively, you can use Amazon Neptune, which is a graph database that's
    used to visualize these relations.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在此架构中，我们将从提取大规模财务文档的元数据开始。我们将展示如何使用 Amazon Textract 批处理作业从这些大型文档中提取数据，并将提取的数据保存为文本文件。然后，我们将展示如何使用
    Comprehend Events 从该文本文件中提取实体，并使用知识图谱可视化实体之间的关系。你还可以使用 Amazon Neptune，它是一个图形数据库，可用于可视化这些关系。
- en: In the next section, we'll look at this architecture by using Jupyter Notebook
    code.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将通过使用 Jupyter Notebook 代码来查看此架构。
- en: Setting up the use case
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置用例
- en: In this section, we will cover how to get started and walk you through the architecture
    shown in the preceding diagram.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍如何入门，并带你走一遍上图所示的架构。
- en: 'We have broken down the solution code walkthrough into the following sections:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将解决方案代码演示分为以下几个部分：
- en: Setting up the notebook code and S3 bucket creation
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置笔记本代码和 S3 桶的创建
- en: Uploading sample documents and extracting text using Textract
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上传示例文档并使用 Textract 提取文本
- en: Metadata extraction using Comprehend
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Comprehend 提取元数据
- en: Starting Comprehend Events job with the SDK
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 SDK 启动 Comprehend Events 作业
- en: Collecting the Comprehend Events job results from S3
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 S3 收集 Comprehend Events 作业结果
- en: Analyzing the output of Comprehend Events
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析 Comprehend Events 的输出
- en: Setting up the notebook code and S3 Bucket creation
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置笔记本代码和 S3 桶的创建
- en: 'Follow these steps to set up the notebook:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤设置笔记本：
- en: In the SageMaker Jupyter notebook you set up in the previous chapters, Git clone
    [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/).
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你之前章节中设置的 SageMaker Jupyter 笔记本中，使用 Git 克隆 [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/)。
- en: Then, go to `/Chapter 09/chapter 09 metadata extraction.ipynb` and start running
    the notebook.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，前往 `/Chapter 09/chapter 09 metadata extraction.ipynb` 并开始运行笔记本。
- en: Now that we have set up the notebook, we'll create an Amazon S3 bucket. Follow
    the steps provided in [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027),
    *Introducing Amazon Textract*, to create an Amazon S3 bucket.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经设置好了笔记本，接下来将创建一个 Amazon S3 桶。按照 [*第 2 章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)，*介绍
    Amazon Textract* 中提供的步骤创建一个 Amazon S3 桶。
- en: 'Copy the created bucket, open your sample code from [*Chapter 9*](B17528_09_Final_SB_ePub.xhtml#_idTextAnchor117)*,
    Extracting Metadata from Financial Documents* (`Chapter 09/chapter 09 metadata
    extraction.ipynb`), and paste it into the following notebook cell to get started:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制创建的桶，打开你从 [*第 9 章*](B17528_09_Final_SB_ePub.xhtml#_idTextAnchor117)*，从财务文档提取元数据*
    (`Chapter 09/chapter 09 metadata extraction.ipynb`) 中获取的示例代码，并将其粘贴到以下笔记本单元格中以开始：
- en: '[PRE0]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: We assume that your notebook has IAM access for Amazon Comprehend full access,
    Amazon S3 full access, and Amazon Textract full access. If you do not have access,
    you will get an access denied exception.
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们假设你的笔记本已获得 Amazon Comprehend 完全访问权限、Amazon S3 完全访问权限以及 Amazon Textract 完全访问权限。如果没有访问权限，将会遇到访问拒绝异常。
- en: If you get an access denied exception while running any of the steps in this
    notebook, please go to [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027),
    *Introducing Amazon Textract*, and set up the relevant IAM roles.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在运行笔记本中的任何步骤时遇到访问拒绝异常，请前往 [*第 2 章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)，*介绍
    Amazon Textract*，并设置相关的 IAM 角色。
- en: In the next section, we will walk you through the code so that you understand
    how the architecture works.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将引导你通过代码，让你了解架构是如何工作的。
- en: Uploading sample documents and extracting text using Textract
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 上传示例文档并使用 Textract 提取文本
- en: In this section, we will walk you through how you can quickly set up the proposed
    architecture shown in *Figure 9.1*. We have already created an Amazon S3 bucket
    where your output and sample documents will be stored. We also pasted that S3
    bucket's name in the notebook cell. If you haven't done this yet, please complete
    the preceding steps.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向您展示如何快速设置图 *9.1* 中显示的提议架构。我们已经创建了一个 Amazon S3 存储桶，用于存储您的输出和示例文件。我们还将该
    S3 存储桶的名称粘贴在了笔记本单元格中。如果您还没有完成此步骤，请完成之前的步骤。
- en: 'We will refer to the following notebook: [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2009/chapter%2009%20metadata%20extraction.ipynb](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2009/chapter%2009%20metadata%20extraction.ipynb).
    Let''s get started:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将参考以下笔记本：[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2009/chapter%2009%20metadata%20extraction.ipynb](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2009/chapter%2009%20metadata%20extraction.ipynb)。让我们开始吧：
- en: First, we must download the sample PDF financial press release document from
    Amazon S3.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们必须从 Amazon S3 下载示例 PDF 财务新闻稿文件。
- en: 'Now, we must upload it using the `upload_file` S3 command via the `sample_financial_news_doc.pdf`
    boto3 API to an S3 bucket for processing. The same bucket will be used to return
    service output:'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们必须使用 `upload_file` S3 命令通过 `sample_financial_news_doc.pdf` boto3 API 将其上传到
    S3 存储桶以进行处理。相同的存储桶将用于返回服务输出：
- en: '[PRE1]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: This PDF file consists of a press release statement of the Whole Foods and Amazon
    merger in 2017 and consists of 156 pages.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该 PDF 文件包含关于 Whole Foods 和 Amazon 在 2017 年合并的新闻稿声明，共 156 页。
- en: 'Now, we will run Amazon Textract to convert this PDF into a text file; Amazon
    Comprehend accepts a text input file with UTF 8 encoding for metadata extraction
    as input. You can run the notebook code to start an asynchronous processing job
    to extract text from documents. We explained how the asynchronous Textract batch
    processing code works in detail in [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027),
    *Introducing Amazon Textract*. If you want to deep dive, please refer to that
    chapter. Run the following cell to get the job results:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将运行 Amazon Textract 将此 PDF 转换为文本文件；Amazon Comprehend 接受 UTF-8 编码的文本输入文件用于元数据提取。您可以运行笔记本代码开始一个异步处理任务，从文档中提取文本。我们已经在
    [*第二章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027) 中详细解释了异步 Textract 批处理代码的工作原理，*介绍
    Amazon Textract*。如果您想深入了解，请参阅该章节。运行以下单元格获取任务结果：
- en: '[PRE2]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'At this point, you will get a `Job ID`. Wait until the job''s status changes
    from in progress to complete:'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此时，您将获得一个 `Job ID`。等待任务的状态从进行中更改为完成：
- en: '![Figure 9.2 – Textract job status'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.2 – Textract 任务状态'
- en: '](img/B17528_09_02.jpg)'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_09_02.jpg)'
- en: Figure 9.2 – Textract job status
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 9.2 – Textract 任务状态
- en: 'Now, we will convert the extracted data from Amazon Textract into a UTF 8 text
    file for Amazon Comprehend by running the following notebook cell:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将通过运行以下笔记本单元格，将从 Amazon Textract 提取的数据转换为 UTF-8 文本文件，以供 Amazon Comprehend
    使用：
- en: '[PRE3]'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The financial press release document text will be extracted from the press
    release documents:'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 财务新闻稿文件文本将从新闻稿文件中提取：
- en: '![Figure 9.3 – Text extracted from the press release document using Amazon
    Textract](img/B17528_09_03.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.3 – 使用 Amazon Textract 从新闻稿文件中提取的文本](img/B17528_09_03.jpg)'
- en: Figure 9.3 – Text extracted from the press release document using Amazon Textract
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 – 使用 Amazon Textract 从新闻稿文件中提取的文本
- en: In this section, we covered how to extract text data from a press release document
    (a 2017 press release about Amazon's acquisition of Whole Foods), which consists
    of 156 pages, into text format using Amazon Textract. In the next section, we
    will talk about how to extract metadata from this document using Comprehend entity
    detection sync APIs and Comprehend events async jobs.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了如何使用 Amazon Textract 将新闻稿文件（关于 Amazon 收购 Whole Foods 的 2017 年新闻稿，共
    156 页）中的文本数据提取为文本格式。在下一节中，我们将讨论如何使用 Comprehend 实体检测同步 API 和 Comprehend 事件异步任务从该文件中提取元数据。
- en: Metadata extraction using Comprehend
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Comprehend 提取元数据
- en: In this section, we will use the aforementioned text file to extract metadata
    using the Amazon Comprehend Events API.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用上述文本文件，利用 Amazon Comprehend 事件 API 提取元数据。
- en: Comprehend Events API
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Comprehend 事件 API
- en: Amazon Comprehend Events is a very specific API that can help you analyze financial
    events such as mergers, acquisitions, IPO dates, press releases, bankruptcy, and
    more. It extracts important financial entities such as IPO dates, the merger parties'
    names, and so on from these events and establishes relationships so that financial
    analysts can act in real time on their financial models and make accurate predictions
    and quick decisions.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Comprehend事件是一个非常特定的API，可以帮助您分析金融事件，如并购、收购、IPO日期、新闻稿、破产等。它从这些事件中提取重要的金融实体，如IPO日期、并购方名称等，并建立关系，以便金融分析师能够实时处理其金融模型，做出准确的预测和快速决策。
- en: 'Amazon Comprehend Events can help you analyze asynchronous jobs. To do this,
    you must ensure you do the following first:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Comprehend事件可以帮助您分析异步作业。为此，您必须首先确保执行以下操作：
- en: Set up an Amazon Comprehend Events job through the AWS Console.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过AWS控制台设置Amazon Comprehend事件作业。
- en: Set up an Amazon Comprehend Events job through the notebook ([https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2009/chapter%2009%20metadata%20extraction.ipynb](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2009/chapter%2009%20metadata%20extraction.ipynb))
    using boto3 Python APIs.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过笔记本设置Amazon Comprehend事件作业（[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2009/chapter%2009%20metadata%20extraction.ipynb](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/blob/main/Chapter%2009/chapter%2009%20metadata%20extraction.ipynb)），使用boto3
    Python API。
- en: Note
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: You can choose one of the aforementioned approaches to analyze your press release
    documents using Amazon Comprehend events.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您可以选择上述方法之一，使用Amazon Comprehend事件分析您的新闻稿文档。
- en: 'Let''s start by setting up an Amazon Comprehend Events job using the Amazon
    Comprehend consol:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从使用Amazon Comprehend控制台设置Amazon Comprehend事件作业开始：
- en: Open the Amazon Comprehend console by going to [https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#home](https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#home).
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过访问[https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#home](https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#home)打开Amazon
    Comprehend控制台。
- en: Go to **Analysis Jobs** -> **Create Analysis Job**.
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到**分析作业** -> **创建分析作业**。
- en: 'In **Job Settings**, enter **Name: Test-events**. You will see that we can
    choose from various types of analysis, such as **Sentiment**, **PII**, **Entity**,
    and **Topic modeling**. Choose **Events**. For **Language** choose **English**,
    while for **Target Event Types**, choose all the available options, as shown in
    the following screenshot:![Figure 9.4 – Creating a Comprehend events analysis
    job'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**作业设置**中，输入**名称：Test-events**。您将看到可以选择多种分析类型，如**情感分析**、**PII**、**实体**和**主题建模**。选择**事件**。对于**语言**，选择**英语**，对于**目标事件类型**，选择所有可用选项，如下图所示：![图9.4
    – 创建Comprehend事件分析作业](img/B17528_09_04.jpg)
- en: '](img/B17528_09_04.jpg)'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_09_04.jpg)'
- en: Figure 9.4 – Creating a Comprehend events analysis job
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.4 – 创建Comprehend事件分析作业
- en: For `s3://<your bucket>/ sample_finance_data.txt`. Choose one document per line
    for **Input format**.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`s3://<your bucket>/sample_finance_data.txt`，选择每行一个文档作为**输入格式**。
- en: Note
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: We are using one document per line as the input format instead of one document
    per file. This is because the total file size of this press release document is
    655 KB and the limit for one document per file is 10 KB. One document per line
    format can have 5,000 lines in a single document; the press release document we
    are using for this demo contains 156 lines.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们使用每行一个文档作为输入格式，而不是每个文件一个文档。这是因为这份新闻稿文档的总文件大小为655 KB，而每个文件的文档大小限制为10 KB。每行一个文档格式最多可以容纳5,000行；我们在本演示中使用的新闻稿文档包含156行。
- en: '![Figure 9.5 – Choosing Input data for the analysis job'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.5 – 为分析作业选择输入数据'
- en: '](img/B17528_09_05.jpg)'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_09_05.jpg)'
- en: Figure 9.5 – Choosing Input data for the analysis job
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.5 – 为分析作业选择输入数据
- en: For `s3://<your-bucket>`:![Figure 9.6 – Choosing an output S3 location for the
    analysis job](img/B17528_09_06.jpg)
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`s3://<your-bucket>`：![图9.6 – 为分析作业选择输出S3位置](img/B17528_09_06.jpg)
- en: Figure 9.6 – Choosing an output S3 location for the analysis job
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.6 – 为分析作业选择输出S3位置
- en: For `events-role`:![Figure 9.7 – Setting up access permissions by creating an
    IAM role
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`events-role`：![图9.7 – 通过创建IAM角色设置访问权限](img/B17528_09_07.jpg)
- en: '](img/B17528_09_07.jpg)'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_09_07.jpg)'
- en: Figure 9.7 – Setting up access permissions by creating an IAM role
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.7 – 通过创建IAM角色设置访问权限
- en: Click on the **Create Job** button to trigger an events job. Grab a coffee/tea
    as this job will take 15 minutes to complete.
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**创建作业**按钮以触发事件作业。趁此机会喝杯咖啡或茶，因为此作业需要 15 分钟才能完成。
- en: 'Once your job is complete, go to `Job ID`:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦作业完成，请前往`作业 ID`：
- en: '![Figure 9.8 – Copying the job ID from the Job details page after creating
    a job](img/B17528_09_08.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.8 – 在创建作业后，从作业详情页面复制作业 ID](img/B17528_09_08.jpg)'
- en: Figure 9.8 – Copying the job ID from the Job details page after creating a job
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.8 – 在创建作业后，从作业详情页面复制作业 ID
- en: Note
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If you are creating events using the Amazon Comprehend console, skip the *Start
    an asynchronous job with the SDK* section in the notebook and move on to the *Collect
    the results from S3* section.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是通过 Amazon Comprehend 控制台创建事件作业，跳过笔记本中的*使用 SDK 启动异步作业*部分，直接进入*从 S3 收集结果*部分。
- en: In this section, we covered how to create a Comprehend Events job using the
    **AWS Console** for a large financial press release document. Skip the next section
    if you have already set up using the console.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讲解了如何使用**AWS 控制台**为一份大型财务新闻稿文档创建 Comprehend Events 作业。如果你已经通过控制台进行设置，请跳过下一部分。
- en: Starting Comprehend Events jobs with the SDK
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 SDK 启动 Comprehend Events 作业
- en: 'In this section, we will switch back to our notebook to start an asynchronous
    job with the SDK. Let''s get started:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将切换回笔记本，使用 SDK 启动异步作业。让我们开始：
- en: 'Create an IAM role by going to the IAM console at [https://console.aws.amazon.com/iam/home?region=us-east-1#/home](https://console.aws.amazon.com/iam/home?region=us-east-1#/home).
    Ensure that you create an IAM role with access to Comprehend and have specified
    S3\. Paste the following into the cell:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过访问 IAM 控制台 [https://console.aws.amazon.com/iam/home?region=us-east-1#/home](https://console.aws.amazon.com/iam/home?region=us-east-1#/home)
    创建一个 IAM 角色。确保创建一个有访问 Comprehend 权限并已指定 S3 的 IAM 角色。将以下内容粘贴到单元格中：
- en: '[PRE4]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Run the following cell to set up other Events job parameters, such as event
    types and input data format:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以设置其他 Events 作业参数，如事件类型和输入数据格式：
- en: '[PRE5]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Run the following cell to trigger the Events analysis job. This job is calling
    the Python boto 3 starts event detection job API. Go to [https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/comprehend.html#Comprehend.Client.start_events_detection_job](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/comprehend.html#Comprehend.Client.start_events_detection_job)
    to learn more:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下单元格以触发 Events 分析作业。该作业正在调用 Python boto 3 启动事件检测作业的 API。请访问 [https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/comprehend.html#Comprehend.Client.start_events_detection_job](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/comprehend.html#Comprehend.Client.start_events_detection_job)
    了解更多信息：
- en: '[PRE6]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this section, we covered how to trigger Comprehend Events analysis jobs using
    the SDK. At this point, we have a job ID that we will use in the next section
    to collect the output and analyze the metadata.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讲解了如何使用 SDK 启动 Comprehend Events 分析作业。此时，我们已有一个作业 ID，接下来将使用它收集输出并分析元数据。
- en: Collecting the results from S3
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从 S3 收集结果
- en: 'In this section, we will analyze the output results of this job in Amazon S3\.
    Let''s get started:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将在 Amazon S3 中分析此作业的输出结果。让我们开始：
- en: 'If you used the Amazon Comprehend console previously, you must have copied
    the `Job ID` at the end of that section. Please paste it in the following cell
    by uncommenting it. Then, run the cell:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你之前使用过 Amazon Comprehend 控制台，你应该已经在该部分末尾复制了`作业 ID`。请通过取消注释将其粘贴到以下单元格中，然后运行该单元格：
- en: '[PRE7]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If you used the Amazon Comprehend SDK to trigger Events analysis jobs, continue
    with the following cell to track the job''s status:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你使用 Amazon Comprehend SDK 启动了 Events 分析作业，请继续执行以下单元格来跟踪作业状态：
- en: '[PRE8]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Once the job is completed, you can get the output from Amazon S3 by running
    the following cell:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦作业完成，你可以通过运行以下单元格从 Amazon S3 获取输出：
- en: '[PRE9]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this section, we covered how to track a Comprehend Events job's completion
    using SDKs and collect the output from Amazon S3\. Now that we have collected
    the results, we will analyze the results and metadata that have been extracted.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讲解了如何使用 SDK 跟踪 Comprehend Events 作业的完成情况，并从 Amazon S3 收集输出。现在我们已经收集了结果，接下来我们将分析提取的结果和元数据。
- en: Analyzing the output of Comprehend Events
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析 Comprehend Events 的输出
- en: 'In this section, we will show you different ways you can analyze the output
    of Comprehend Events. This output can be used by financial analysts to predict
    market trends or look up key information in large datasets. But first, let''s
    understand the **Comprehend Events** system''s output ([https://docs.aws.amazon.com/comprehend/latest/dg/how-events.html](https://docs.aws.amazon.com/comprehend/latest/dg/how-events.html)):'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向您展示不同的方式来分析 Comprehend Events 的输出。金融分析师可以利用这些输出预测市场趋势或查找大数据集中的关键信息。但首先，让我们了解一下**Comprehend
    Events**系统的输出（[https://docs.aws.amazon.com/comprehend/latest/dg/how-events.html](https://docs.aws.amazon.com/comprehend/latest/dg/how-events.html)）：
- en: 'The system returns JSON output for each submitted document. The structure of
    the response is shown here:'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统返回每个提交文档的 JSON 输出。响应的结构如下所示：
- en: '[PRE10]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the response, you get entities, as well as entities grouped as `mentions`,
    `arguments`, and `triggers`, along with the confidence score. We will see these
    terms being used throughout the notebook:'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在响应中，您会得到实体，以及作为 `mentions`、`arguments` 和 `triggers` 分组的实体，附带置信度分数。我们将在整个笔记本中看到这些术语的使用：
- en: '![Figure 9.9 – Comprehend events JSON output'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.9 – Comprehend events JSON 输出'
- en: '](img/B17528_09_09.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_09_09.jpg)'
- en: Figure 9.9 – Comprehend events JSON output
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.9 – Comprehend events JSON 输出
- en: '`Events` are groups of `triggers`. The API''s output includes the text, character
    offset, and type of each trigger, along with the confidence score. The confidence
    of event group membership is provided by `GroupScore`. Run the following notebook
    cell to take a look at these:'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Events` 是 `triggers` 的组。API 的输出包括每个触发器的文本、字符偏移量和类型，以及置信度分数。事件组的成员资格置信度由 `GroupScore`
    提供。运行以下笔记本单元格来查看这些内容：'
- en: '[PRE11]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following is the output of the preceding code:'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是前面代码的输出：
- en: '![Figure 9.10 – Comprehend events triggers'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.10 – Comprehend events 触发器'
- en: '](img/B17528_09_10.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_09_10.jpg)'
- en: Figure 9.10 – Comprehend events triggers
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.10 – Comprehend events 触发器
- en: '`acquire` and `transaction` are related to the `CORPORATE_ACQUISTION` type
    event.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`acquire` 和 `transaction` 与 `CORPORATE_ACQUISTION` 类型的事件相关联。'
- en: 'Arguments are linked to entities by `EntityIndex`, along with the classification
    confidence of the role assignment. It talks about how the entity is related to
    the event. Run the following code to understand this:'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数通过 `EntityIndex` 与实体相关联，同时包括角色分配的分类置信度。它描述了实体与事件之间的关系。运行以下代码以理解这一点：
- en: '[PRE12]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The output of `arguments` will look as follows:'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`arguments` 的输出将如下所示：'
- en: '![Figure 9.11 – Comprehend events arguments'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.11 – Comprehend events 参数'
- en: '](img/B17528_09_11.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_09_11.jpg)'
- en: Figure 9.11 – Comprehend events arguments
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.11 – Comprehend events 参数
- en: '`Investee`, `Amount`, and `Date` are roles with entity indexes and confidence
    scores.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`Investee`、`Amount` 和 `Date` 是具有实体索引和置信度分数的角色。'
- en: 'Entities are groups of `Mentions` that consist of `text`, character `offset`,
    and `type` of each mention, along with their confidence scores. The confidence
    of the entity group''s membership is provided by `Group Scores`. Let''s run the
    following cell to understand this:'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实体是由 `Mentions` 组成的组，这些 `Mentions` 包括每个提及的 `text`、字符 `offset` 和 `type`，以及它们的置信度分数。实体组的成员资格置信度由
    `Group Scores` 提供。让我们运行以下单元格来理解这一点：
- en: '[PRE13]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following output shows what the `Mention` entity looks like:'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下输出显示了 `Mention` 实体的样子：
- en: '![Figure 9.12 – Comprehend events mentions'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.12 – Comprehend events 提及'
- en: '](img/B17528_09_12.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_09_12.jpg)'
- en: Figure 9.12 – Comprehend events mentions
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.12 – Comprehend events 提及
- en: '`entityIndex` 5 refers to the `Type` `Monetary_Value` in the output.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`entityIndex` 5 指输出中的 `Type` `Monetary_Value`。'
- en: Now that we know what `entity`, `arguments`, and `mentions` are, let's visualize
    the relationships between them.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道了什么是 `entity`、`arguments` 和 `mentions`，让我们可视化它们之间的关系。
- en: Visualizing events and entities
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事件和实体的可视化
- en: 'In the remainder of the notebook, we''ll provided several tabulations and visualizations
    to help you understand what the API is returning. First, we''ll look at `spans`,
    both `triggers` and entity `mentions`. One of the most essential visualization
    tasks for sequence labeling tasks is highlighting tagged text in documents. For
    demonstration purposes, we''ll do this with **displaCy**, which is a built-in
    dependency visualizer that lets you check your model''s predictions in your browser
    ([https://explosion.ai/demos/displacy](https://explosion.ai/demos/displacy)):'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的笔记本部分，我们将提供几种表格和可视化，帮助你理解API返回的内容。首先，我们将查看`spans`，包括`triggers`和实体`mentions`。序列标注任务中最基本的可视化任务之一是高亮文档中的标注文本。为了演示目的，我们将使用**displaCy**，这是一款内置的依存关系可视化工具，可以让你在浏览器中查看模型的预测结果（[https://explosion.ai/demos/displacy](https://explosion.ai/demos/displacy)）：
- en: 'Run the following code to convert `entity` into displaCy format. Convert the
    output of `Events` into displaCy format:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码将`entity`转换为displaCy格式。将`Events`的输出转换为displaCy格式：
- en: '[PRE14]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Use the following code to map `triggers`:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码映射`triggers`：
- en: '[PRE15]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Run the following code so that `spans` is `sorted` so that displaCy can process
    it correctly:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码，使得`spans`被`sorted`，以便displaCy能够正确处理它：
- en: '[PRE16]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we will render all `entities` participating in the event by running the
    following notebook code:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将通过运行以下笔记本代码，呈现所有参与事件的`entities`：
- en: '[PRE17]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following is the output of running the preceding code:'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是运行前述代码的输出：
- en: '![Figure 9.13 – Comprehend events and entities](img/B17528_09_13.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.13 – Comprehend 事件和实体](img/B17528_09_13.jpg)'
- en: Figure 9.13 – Comprehend events and entities
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.13 – Comprehend 事件和实体
- en: We have color-coded the events based on the relationships that were found. Just
    by looking at the highlighted entities and relationships that are the same color,
    we can see that John Mackey is the co-founder and CEO and that he will remain
    employed.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已根据发现的关系对事件进行了颜色编码。通过查看相同颜色的高亮实体和关系，我们可以看到John Mackey是联合创始人兼CEO，并且他将继续在公司工作。
- en: Rendering tabular data
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 渲染表格数据
- en: Many financial users use `Events` to create structured data from unstructured
    text. In this section, we'll demonstrate how to do this with pandas.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 许多金融用户使用`Events`从非结构化文本中创建结构化数据。在本节中，我们将演示如何使用pandas做到这一点。
- en: 'First, we must flatten the hierarchical JSON data into a pandas DataFrame by
    doing the following:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须通过以下操作将层次结构的JSON数据展平为pandas DataFrame：
- en: 'Create the `entities` DataFrame. The entity indices must be explicitly created:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建`entities` DataFrame。实体索引必须显式创建：
- en: '[PRE18]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Create the `events` DataFrame. The `Event` indices must be explicitly created:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建`events` DataFrame。`Event`索引必须显式创建：
- en: '[PRE19]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following code will join the two tables into one flat data structure:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码将把两个表连接成一个平坦的数据结构：
- en: '[PRE20]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The following is the output of `EntityIndex` as a tabular structure:'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是`EntityIndex`作为表格结构的输出：
- en: '![Figure 9.14 – Comprehend events entity as a DataFrame'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.14 – Comprehend 事件作为DataFrame的实体](img/B17528_09_14.jpg)'
- en: '](img/B17528_09_14.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_09_14.jpg)'
- en: Figure 9.14 – Comprehend events entity as a DataFrame
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.14 – Comprehend 事件作为DataFrame的实体
- en: We can see that its easy to analyze and extract important events and metadata
    respective to those events such as Date and time as a python pandas dataframe.
    Once your data is in dataframe this can be easily saved into downstream applications
    such as a database or a graph database for furthur analysis.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，将事件和相关元数据（如日期和时间）作为python pandas DataFrame进行分析和提取非常容易。一旦数据在DataFrame中，可以轻松保存到下游应用程序，如数据库或图数据库，进行进一步分析。
- en: Tabular representation of analytics
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析的表格表示
- en: 'We''re primarily interested in the *event structure*, so let''s make that more
    transparent by creating a new table with `Roles` as a column header, grouped by
    event:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们主要关注的是*事件结构*，因此我们通过创建一个新的表格，将`Roles`作为列标题，按事件分组来使其更加透明：
- en: 'The following code will do this for us:'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下代码将为我们完成此操作：
- en: '[PRE21]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following code will group data by `EventIndex` and format:'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下代码将按`EventIndex`对数据进行分组并格式化：
- en: '[PRE22]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The following screenshot shows the output of the DataFrame representing the
    tabular format of Comprehend Events:'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图展示了表示Comprehend事件表格格式的DataFrame输出：
- en: '![Figure 9.15 – Comprehend events tabular representation'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.15 – Comprehend 事件的表格表示](img/B17528_09_15.jpg)'
- en: '](img/B17528_09_15.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_09_15.jpg)'
- en: Figure 9.15 – Comprehend events tabular representation
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.15 – Comprehend 事件的表格表示
- en: In the preceding output, we have a tabular representation of the event type,
    date, investee, investor, employer, employee, and title, all of which can easily
    be used by financial analysts to look into the necessary metadata.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们有事件类型、日期、被投资方、投资者、雇主、雇员和职务的表格表示，金融分析师可以轻松利用这些信息查看必要的元数据。
- en: Graphing event semantics
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事件语义图
- en: 'The most striking representation of the output of Comprehend Events can be
    found in a semantic graph, which is a network of the entities and events that
    have been referenced in a document(s). The code we will cover shortly (please
    open the `pyvis` link for this) uses two open source libraries: `Networkx` and
    `pyvis`. `Networkx` is a Python package that''s used to create, manipulate, and
    study the structure, dynamics, and functions of complex networks ([https://networkx.org/](https://networkx.org/)),
    while `pyvis` ([https://pyvis.readthedocs.io/en/latest/](https://pyvis.readthedocs.io/en/latest/))
    is a library that allows you to quickly generate visual networks to render events
    system output. The vertices represent entity `mentions` and `triggers`, while
    the edges are the argument roles held by the entities concerning the `triggers`
    in the graph.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Comprehend Events 输出的最引人注目的表示形式是在语义图中，这是一个包含在文档中引用的实体和事件的网络。我们稍后将介绍的代码（请打开`pyvis`链接查看）使用了两个开源库：`Networkx`和`pyvis`。`Networkx`是一个Python包，用于创建、操作和研究复杂网络的结构、动态和功能（[https://networkx.org/](https://networkx.org/)），而`pyvis`（[https://pyvis.readthedocs.io/en/latest/](https://pyvis.readthedocs.io/en/latest/)）是一个库，可以快速生成可视化网络来呈现事件系统输出。顶点代表实体`mentions`和`triggers`，边则是图中实体与`triggers`之间所持的参数角色。
- en: Formatting data
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 格式化数据
- en: 'The system output must be conformed to the node (that is, the vertex) and edge
    list format required by Networkx. This requires iterating over `triggers`, `entities`,
    and `argument` structural relations. Note that we can use the `GroupScore` and
    `Score` keys on various objects to prune nodes and edges where the model has less
    confidence. We can also use various strategies to pick a "canonical" mention from
    each `mention` group to appear in the graph; here, we have chosen the mention
    with the longest string-wise extent. Run the following code to format it:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 系统输出必须符合Networkx要求的节点（即顶点）和边列表格式。这需要遍历`triggers`、`entities`和`argument`结构关系。请注意，我们可以使用`GroupScore`和`Score`键对各种对象进行修剪，以剔除模型信心较低的节点和边。我们还可以使用不同的策略从每个`mention`组中选取一个“规范”提及以在图中显示；在这里，我们选择了字符串长度最长的提及。运行以下代码进行格式化：
- en: 'Entities are associated with events by group, not individual `mentions` for
    simplicity. The following method assumes that the canonical mention is the longest
    one:'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了简化，实体是按组与事件关联的，而非单个`mentions`。以下方法假设规范提及为最长的一个：
- en: '[PRE23]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Set a global confidence threshold:'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置全局置信度阈值：
- en: '[PRE24]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In the following code, we are representing nodes as (`id`, `type`, `tag`, `score`,
    `mention_type`) tuples:'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在以下代码中，我们将节点表示为（`id`，`type`，`tag`，`score`，`mention_type`）元组：
- en: '[PRE25]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In the following code, we are representing edges as (`trigger_id`, `node_id`,
    `role`, `score`) tuples:'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在以下代码中，我们将边表示为（`trigger_id`，`node_id`，`role`，`score`）元组：
- en: '[PRE26]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To create a compact graph, once the nodes and edges have been defined, we can
    create and visualize the graph by using the following code block:'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了创建一个紧凑的图形，一旦节点和边被定义，我们可以使用以下代码块来创建和可视化图形：
- en: '[PRE27]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Iterate over the `triggers` and entity `mentions`, as follows:'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遍历`triggers`和实体`mentions`，如下所示：
- en: '[PRE28]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The following code iterates over the argument role assignments:'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下代码遍历参数角色分配：
- en: '[PRE29]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The following code drops `mentions` that don''t participate in events:'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下代码会删除不参与事件的`mentions`：
- en: '[PRE30]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The following is the output in graph format:'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是图形格式的输出：
- en: '![Figure 9.16 – Comprehend events knowledge graph representation'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.16 – 理解事件知识图谱表示'
- en: '](img/B17528_09_16.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_09_16.jpg)'
- en: Figure 9.16 – Comprehend events knowledge graph representation
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.16 – 理解事件知识图谱表示
- en: In the preceding output, if we traverse this graph, we can see the relationships
    between the entity, known as Whole Foods, which is a participant in the corporate
    merger, and its employer. This is John Macey, whose title is CEO.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，如果我们遍历此图，可以看到实体之间的关系，已知的实体名为Whole Foods，参与了公司合并的过程，且与其雇主有关系。雇主是John
    Macey，他的职务是CEO。
- en: A more complete graph
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更完整的图
- en: The preceding graph is compact and only relays essential event type and argument
    role information. We can use a slightly more complicated set of functions to graph
    all of the information returned by the API.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图表非常简洁，只传达了基本的事件类型和参数角色信息。我们可以使用一组稍微复杂的函数来绘制API返回的所有信息。
- en: 'This convenient function in `events_graph.py`. It plots a complete graph of
    the document, showing all `events`, `triggers`, and `entities`, as well as their
    groups:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`events_graph.py`中的一个便捷函数。它绘制了文档的完整图，显示了所有的`events`、`triggers`和`entities`，以及它们的分组：
- en: '[PRE31]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The following is the output in graph format:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是图形格式的输出：
- en: '![Figure 9.17 – Comprehend Events knowledge graph visualization](img/B17528_09_17.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.17 – 理解事件知识图谱可视化](img/B17528_09_17.jpg)'
- en: Figure 9.17 – Comprehend Events knowledge graph visualization
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.17 – 理解事件知识图谱可视化
- en: Note
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You can use **Amazon Neptune** for large-scale knowledge graph analysis with
    Amazon Comprehend Events.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用**Amazon Neptune**与Amazon Comprehend Events进行大规模知识图谱分析。
- en: Here, we have extracted the metadata and analyzed it in a tabular manner and
    showed how we can present it in a graph. You can use Amazon Neptune for large-scale
    knowledge graph analysis with Amazon Comprehend Events, as we covered in *Figure
    9.1*.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们已经提取了元数据并以表格方式分析它，并展示了如何将其呈现为图形。你可以使用Amazon Neptune与Amazon Comprehend
    Events进行大规模知识图谱分析，正如我们在*图 9.1*中所介绍的。
- en: To deep dive into how you can do this using Amazon Neptune, please refer to
    the *Further reading* section for the relevant blog, which will walk you through
    how you can build a knowledge graph in Amazon Neptune using Amazon Comprehend
    Events.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 要深入了解如何使用Amazon Neptune实现这一点，请参考*进一步阅读*部分的相关博客，博客将引导你如何使用Amazon Comprehend Events在Amazon
    Neptune中构建知识图谱。
- en: Note
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`Entities` extracted with Comprehend Events are going to be different than
    Comprehend detect entity API as events are specific to the financial event''s
    entity and relationship extraction.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Comprehend Events提取的`Entities`将与Comprehend的实体检测API不同，因为事件特定于金融事件的实体和关系提取。
- en: You can also extract metadata from Amazon Comprehend for Word or PDF documents
    using either a detect entity, a custom entity, or even Comprehend Events in the
    case of financial documents and enrich the document labeling process using **SageMaker
    Ground Truth**. SageMaker Ground Truth is a service that is primarily used for
    labeling data.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用Amazon Comprehend提取Word或PDF文档的元数据，使用检测实体、自定义实体，或者在金融文档的情况下使用Comprehend
    Events，并通过**SageMaker Ground Truth**丰富文档标注过程。SageMaker Ground Truth是一项主要用于标注数据的服务。
- en: Summary
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned why metadata extraction is really important before
    looking at the use case for **LiveRight**, our fictitious bank, which had acquisitions
    that made a press release statement. Financial analysts wanted to quickly evaluate
    the events and entities concerning this press release and wanted to make market
    predictions. We looked at an architecture to help you accomplish this. In the
    architecture shown in *Figure 1.1*, we spoke about how you can use AWS AI services
    such as Amazon Textract to extract text from the sample press release documents.
    Then, we saved all the text with utf-8 encoding in the Amazon S3 bucket for Amazon
    Comprehend entity or metadata extractions jobs.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们学习了在查看**LiveRight**（我们虚构的银行）的用例之前，为什么元数据提取非常重要。该银行进行了收购并发布了新闻稿。财务分析师希望快速评估与该新闻稿相关的事件和实体，并进行市场预测。我们看了一种架构来帮助你实现这一目标。在*图
    1.1*中展示的架构中，我们讨论了如何使用AWS AI服务，如Amazon Textract，从样本新闻稿中提取文本。然后，我们将所有文本以utf-8编码保存在Amazon
    S3桶中，用于Amazon Comprehend的实体或元数据提取任务。
- en: We used an Amazon Comprehend Events job to extract entities and relationships
    between the entity. We have provided a *walkthrough video* link of the *Comprehend
    Events feature* in the *Further reading* section if you wish to learn more. We
    also provided two ways to configure Comprehend Events job; that is, use either
    the AWS console or AWS Python boto3 APIs. Finally, we talked about how you can
    visualize this relationship between extracted metadata using either a graph API
    such as `displayCy`, `Networkx`, or `pyvis,` or using Amazon Neptune's graph database.
    We also suggested that this metadata can be further used as an input to data labeling
    using **Amazon SageMaker Ground Truth**.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了一个 Amazon Comprehend Events 作业来提取实体及实体之间的关系。如果您希望进一步了解，可以在 *进一步阅读* 部分找到
    *Comprehend Events 功能* 的 *演示视频* 链接。我们还提供了两种配置 Comprehend Events 作业的方法；即，可以使用 AWS
    控制台或 AWS Python boto3 API。最后，我们讨论了如何使用图形 API（例如 `displayCy`、`Networkx` 或 `pyvis`）或使用
    Amazon Neptune 的图形数据库来可视化提取的元数据之间的关系。我们还建议，可以将这些元数据进一步用作数据标注的输入，使用 **Amazon SageMaker
    Ground Truth**。
- en: In the next chapter, we will talk about how you can perform content monetization
    for your cool websites.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何为您的酷炫网站进行内容变现。
- en: Further reading
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多本章中涵盖的主题，请查看以下资源：
- en: '*Building a knowledge graph in Amazon Neptune using Amazon Comprehend Events*,
    by Brian O''Keefe, Graham Horwood, and Navtanay Sinha ([https://aws.amazon.com/blogs/database/building-a-knowledge-graph-in-amazon-neptune-using-amazon-comprehend-events/](https://aws.amazon.com/blogs/database/building-a-knowledge-graph-in-amazon-neptune-using-amazon-comprehend-events/)).'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在 Amazon Neptune 中使用 Amazon Comprehend Events 构建知识图谱*，由 Brian O''Keefe、Graham
    Horwood 和 Navtanay Sinha 编写 ([https://aws.amazon.com/blogs/database/building-a-knowledge-graph-in-amazon-neptune-using-amazon-comprehend-events/](https://aws.amazon.com/blogs/database/building-a-knowledge-graph-in-amazon-neptune-using-amazon-comprehend-events/))。'
- en: '*Announcing the launch of Amazon Comprehend Events*, by Graham Horwood, Sameer
    Karnik, and Ben Snively ([https://aws.amazon.com/blogs/machine-learning/announcing-the-launch-of-amazon-comprehend-events/](https://aws.amazon.com/blogs/machine-learning/announcing-the-launch-of-amazon-comprehend-events/)).'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*宣布推出 Amazon Comprehend Events*，由 Graham Horwood、Sameer Karnik 和 Ben Snively
    编写 ([https://aws.amazon.com/blogs/machine-learning/announcing-the-launch-of-amazon-comprehend-events/](https://aws.amazon.com/blogs/machine-learning/announcing-the-launch-of-amazon-comprehend-events/))。'
- en: '*Fintech Snacks 2 – Extracting Market-Moving Events with Amazon Comprehend
    Events*, by Mona Mona and Evan Peck ([https://www.youtube.com/watch?v=QvmVT_8y7-Y](https://www.youtube.com/watch?v=QvmVT_8y7-Y)).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Fintech Snacks 2 – 使用 Amazon Comprehend Events 提取市场驱动事件*，由 Mona Mona 和 Evan
    Peck 编写 ([https://www.youtube.com/watch?v=QvmVT_8y7-Y](https://www.youtube.com/watch?v=QvmVT_8y7-Y))。'
