- en: '27'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '27'
- en: Graph-Based RAG
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于图的 RAG
- en: In this chapter, we’ll learn how to leverage graph-structured knowledge in RAG
    for LLMs. You’ll learn about graph-based knowledge representation and how to design
    RAG architectures that can utilize this structured information.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何利用 RAG 中的图结构化知识为 LLM。你将了解基于图的知識表示以及如何设计能够利用这种结构化信息的 RAG 架构。
- en: A graph-based knowledge representation structures information as nodes and edges
    in a graph, where nodes represent concepts or facts and edges capture their relationships.
    When used with RAG, this approach enables richer information retrieval by leveraging
    both the individual pieces of information and their interconnections, allowing
    for more contextual and relationship-aware responses.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的知识表示将信息结构化为图中的节点和边，其中节点代表概念或事实，边捕获它们之间的关系。当与 RAG 结合使用时，这种方法通过利用信息片段及其相互连接，实现更丰富的信息检索，从而允许更上下文化和关系感知的响应。
- en: We’ll cover graph embedding techniques for retrieval, query expansion using
    graph structures, and methods for integrating graph information into LLM generation.
    You’ll also explore various applications and use cases of graph RAG in LLMs.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将涵盖用于检索的图嵌入技术、使用图结构进行查询扩展以及将图信息集成到 LLM 生成中的方法。你还将探索 LLM 中图 RAG 的各种应用和用例。
- en: By the end of this chapter, you’ll be able to implement advanced RAG systems
    that can leverage the rich relationships in graph-structured data.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够实现利用图结构化数据的丰富关系的先进 RAG 系统。
- en: 'In this chapter, we’ll be covering the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introduction to graph-based knowledge representation for LLMs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于图的 LLM 知識表示简介
- en: Designing graph RAG architectures for LLMs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为 LLM 设计图 RAG 架构
- en: Graph embedding techniques for LLM retrieval
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM 检索的图嵌入技术
- en: Query expansion using graph structures in LLMs
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 LLM 中使用图结构进行查询扩展
- en: Integrating graph information into LLM generation
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将图信息集成到 LLM 生成中
- en: Applications and use cases of graph RAG in LLMs
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM 中图 RAG 的应用和用例
- en: Challenges and future directions in graph-based RAG
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于图的 RAG 的挑战和未来方向
- en: Introduction to graph-based knowledge representation for LLMs
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于图的 LLM 知識表示简介
- en: Graph-based knowledge representation allows complex relationships to be encoded
    between concepts and facts, which can significantly enhance the contextual understanding
    of LLMs. In a graph, nodes represent entities, and edges represent relationships
    between them.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的知識表示允许在概念和事实之间编码复杂关系，这可以显著增强 LLM 的上下文理解。在图中，节点代表实体，边代表它们之间的关系。
- en: '![Figure 27.1 – Graph-based knowledge representation for LLMs](img/B31249_27_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图 27.1 – 为 LLMs 的基于图的知識表示](img/B31249_27_01.jpg)'
- en: Figure 27.1 – Graph-based knowledge representation for LLMs
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 27.1 – 为 LLMs 的基于图的知識表示
- en: 'The following are the key benefits of graph-based knowledge for LLMs:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是基于图的 LLM 知識表示的关键优势：
- en: Captures complex relationships
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 捕获复杂关系
- en: Enables multi-hop reasoning
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现多跳推理
- en: Provides structured context for generation
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为生成提供结构化上下文
- en: Facilitates domain-specific knowledge integration
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 促进特定领域知识的集成
- en: 'Let’s start by implementing a simple graph structure:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先从实现一个简单的图结构开始：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This code implements a foundational `KnowledgeGraph` class in Python, allowing
    knowledge to be represented as a network of interconnected entities. The class
    uses dictionaries to store nodes and edges, where nodes are identified by unique
    IDs and hold associated properties, and edges define relationships between nodes
    through source, target, and relation labels. The `add_node` method populates the
    `nodes` dictionary, while `add_edge` establishes connections within the `edges`
    dictionary. The `get_neighbors` method allows nodes directly connected to a given
    node to be retrieved, along with the corresponding relationship types.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码在 Python 中实现了一个基础的 `KnowledgeGraph` 类，允许将知识表示为相互连接的实体网络。该类使用字典来存储节点和边，其中节点通过唯一的
    ID 识别并持有相关属性，边通过源、目标和关系标签定义节点之间的关系。`add_node` 方法填充 `nodes` 字典，而 `add_edge` 在 `edges`
    字典中建立连接。`get_neighbors` 方法允许检索与给定节点直接相连的节点，以及相应的关联关系类型。
- en: This example demonstrates how to create a graph, add nodes representing `Paris`
    and `France`, define the `capital_of` relationship between them, and then query
    the graph to find neighbors of `Paris`. This structure provides a basis for encoding
    complex relationships and facilitating knowledge-aware applications.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子演示了如何创建一个图，添加代表 `Paris` 和 `France` 的节点，定义它们之间的 `capital_of` 关系，然后查询图以找到
    `Paris` 的邻居。这种结构为编码复杂关系和促进知识感知应用提供了基础。
- en: Next, we’ll discuss how to design graph RAG architecture.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论如何设计图 RAG 架构。
- en: Designing graph RAG architectures for LLMs
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为 LLM 设计图 RAG 架构
- en: 'To design a graph RAG system, we need to integrate our knowledge graph with
    the retrieval and generation components:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设计一个图 RAG 系统，我们需要将我们的知识图谱与检索和生成组件集成：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the preceding code, we used the NetworkX Python package. The NetworkX package
    is designed for creating, manipulating, and studying the structure, dynamics,
    and functions of complex networks. It provides tools for working with graphs,
    which are collections of nodes (vertices) and edges (connections between nodes),
    and offers a wide range of algorithms for analyzing network properties, making
    it invaluable for fields such as social network analysis, biology, and infrastructure
    studies.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用了 NetworkX Python 包。NetworkX 包旨在创建、操作和研究复杂网络的结构、动态和功能。它提供了用于处理图（节点集合和节点之间的连接）的工具，并提供了一系列分析网络属性的算法，对于社会网络分析、生物学和基础设施研究等领域来说非常有价值。
- en: This code defines a `GraphRAG` class that combines a `KnowledgeGraph` object
    with a Sentence Transformer model to enable context-aware information retrieval.
    The class initializes with a `KnowledgeGraph` object and a Sentence Transformer
    model name, which it uses to build a `networkx` graph representation of the knowledge
    graph and compute embeddings for each node based on its ID and properties. The
    `build_networkx_graph` method converts the custom `KnowledgeGraph` object into
    a `networkx` directed graph, preserving node properties and edge relationships.
    The `compute_node_embeddings` method generates embeddings for each node by concatenating
    its ID and properties into a text string and encoding it using the Sentence Transformer
    model.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码定义了一个 `GraphRAG` 类，它将 `KnowledgeGraph` 对象与 Sentence Transformer 模型结合，以实现上下文感知的信息检索。该类使用
    `KnowledgeGraph` 对象和 Sentence Transformer 模型名称初始化，它使用这些名称来构建知识图谱的 `networkx` 图表示，并根据每个节点的
    ID 和属性计算嵌入。`build_networkx_graph` 方法将自定义的 `KnowledgeGraph` 对象转换为 `networkx` 有向图，保留节点属性和边关系。`compute_node_embeddings`
    方法通过将节点的 ID 和属性连接成一个文本字符串并使用 Sentence Transformer 模型对其进行编码来生成每个节点的嵌入。
- en: The `retrieve` method takes a query, encodes it using the same Sentence Transformer,
    calculates the cosine similarity between the query embedding and each node embedding,
    and returns the top *k* most similar node IDs. This architecture leverages graph
    structure and semantic embeddings to retrieve relevant knowledge based on query
    context, bridging the gap between symbolic knowledge representation and neural
    information retrieval.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '`retrieve` 方法接受一个查询，使用相同的 Sentence Transformer 对其进行编码，计算查询嵌入与每个节点嵌入之间的余弦相似度，并返回最相似的
    *k* 个节点 ID。这种架构利用图结构和语义嵌入，根据查询上下文检索相关知识，弥合了符号知识表示和神经信息检索之间的差距。'
- en: Now, let’s explore more advanced techniques for representing our graph data
    to further enhance the performance of our LLM retrieval system. Specifically,
    we’ll delve into graph embedding techniques for LLM retrieval.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探索更多高级技术来表示我们的图数据，以进一步增强我们的 LLM 检索系统的性能。具体来说，我们将深入研究 LLM 检索的图嵌入技术。
- en: Graph embedding techniques for LLM retrieval
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM 检索的图嵌入技术
- en: Graph embedding techniques aim to represent the nodes of a graph in a low-dimensional
    vector space, capturing the graph’s structural properties and relationships. Several
    methods exist, each with its own approach – for instance, **Node2Vec** explores
    neighborhoods through biased random walks, balancing breadth-first and depth-first
    exploration. **DeepWalk** is another random-walk-based approach but performs walks
    uniformly. **Graph convolutional networks** (**GCNs**) aggregate information from
    a node’s neighbors using convolutional operations, learning node embeddings based
    on the graph’s structure and node features. **Graph attention networks** (**GATs**)
    extend GCNs by incorporating an attention mechanism to weigh the importance of
    different neighbors when aggregating information. **Translating Embeddings for
    Knowledge Graphs** (**TransE**) is specifically designed for knowledge graphs,
    representing entities and relations as vectors such that if (*h*, *r*, *t*) holds
    (head, relation, tail), then *h + r ≈* *t*.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图嵌入技术旨在将图中的节点表示为低维向量空间，捕捉图的结构属性和关系。存在几种方法，每种方法都有自己的方法——例如，**Node2Vec**通过有偏随机游走来探索邻域，平衡广度优先和深度优先探索。**DeepWalk**是另一种基于随机游走的方法，但执行的是均匀的游走。**图卷积网络**（**GCNs**）通过卷积操作从节点的邻居中聚合信息，根据图的结构和节点特征学习节点嵌入。**图注意力网络**（**GATs**）通过引入注意力机制来扩展GCNs，在聚合信息时权衡不同邻居的重要性。**知识图谱嵌入翻译**（**TransE**）专门为知识图谱设计，将实体和关系表示为向量，使得如果(*h*,
    *r*, *t*)成立（头，关系，尾），则*h + r ≈* *t*。
- en: 'Let’s focus on **Node2Vec** as an example. Node2Vec aims to create embeddings
    that preserve network neighborhoods. It achieves this by employing biased random
    walks that balance **breadth-first search** (**BFS**) and **depth-first search**
    (**DFS**). BFS prioritizes exploring immediate neighbors and capturing local structural
    information, while DFS explores distant nodes, thereby capturing higher-order
    dependencies and community structures. The bias is controlled by two parameters,
    *p* (return parameter) and *q* (in-out parameter), which influence the likelihood
    of revisiting the previous node or exploring distant nodes, respectively. By learning
    embeddings that reflect these biased random walks, Node2Vec captures both local
    and global network structures, allowing for effective node classification, link
    prediction, and community detection:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以**Node2Vec**为例。Node2Vec旨在创建能够保留网络邻域的嵌入。它通过采用平衡**广度优先搜索**（**BFS**）和**深度优先搜索**（**DFS**）的有偏随机游走来实现这一点。BFS优先探索最近的邻居并捕获局部结构信息，而DFS探索远程节点，从而捕获更高阶的依赖关系和社区结构。偏差由两个参数控制，*p*（返回参数）和*q*（出入参数），它们分别影响重新访问前一个节点或探索远程节点的可能性。通过学习反映这些有偏随机游走的嵌入，Node2Vec能够捕捉局部和全局网络结构，从而实现有效的节点分类、链接预测和社区检测：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This code builds upon the `GraphRAG` class by incorporating `Node2Vec` embeddings
    for enhanced retrieval performance. It introduces an `AdvancedGraphRAG` class
    that inherits from `GraphRAG` and computes `Node2Vec` embeddings during initialization.
    The `compute_node2vec_embeddings` method utilizes the `node2vec` library to generate
    these embeddings, creating a `Node2Vec` object with specified dimensions, walk
    length, number of walks, and worker threads; it then trains the Node2Vec model
    by using random walks on the graph structure and extracts the learned node embeddings.
    The `retrieve` method is overridden to combine both the original text-based embeddings
    and the `Node2Vec` embeddings for similarity calculation. For each node, it computes
    the cosine similarity between the query embedding and both the text-based embedding
    and the `Node2Vec` embedding, then averages these two similarity scores with equal
    weights to produce a combined similarity score. Finally, it returns the top *k*
    nodes with the highest combined similarity scores, leveraging both semantic and
    structural information for more effective retrieval.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码通过结合 `Node2Vec` 嵌入来增强检索性能，在 `GraphRAG` 类的基础上进行了扩展。它引入了一个 `AdvancedGraphRAG`
    类，该类继承自 `GraphRAG` 并在初始化期间计算 `Node2Vec` 嵌入。`compute_node2vec_embeddings` 方法使用
    `node2vec` 库生成这些嵌入，创建一个具有指定维度、行走长度、行走次数和工作线程的 `Node2Vec` 对象；然后通过在图结构上使用随机游走来训练
    Node2Vec 模型，并提取学习到的节点嵌入。`retrieve` 方法被重写，以结合原始基于文本的嵌入和 `Node2Vec` 嵌入进行相似度计算。对于每个节点，它计算查询嵌入与基于文本的嵌入和
    `Node2Vec` 嵌入之间的余弦相似度，然后以相等的权重平均这两个相似度得分，以产生一个综合相似度得分。最后，它返回具有最高综合相似度得分的前 *k*
    个节点，利用语义和结构信息进行更有效的检索。
- en: Now, let’s explore how we can further improve retrieval by leveraging the graph
    structure to refine our queries. In the next section, we’ll implement a simple
    yet effective technique to broaden the scope of our search.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探讨如何通过利用图结构来细化我们的查询，进一步提高检索效果。在下一节中，我们将实现一个简单而有效的技术来扩大搜索范围。
- en: Query expansion using graph structures in LLMs
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 LLM 中使用图结构进行查询扩展
- en: 'We can leverage graph structures to expand queries and improve retrieval. Let’s
    implement a simple query expansion technique:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用图结构来扩展查询并提高检索效果。让我们实现一个简单的查询扩展技术：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This code implements query expansion within a graph-based RAG system to enhance
    retrieval performance. The `QueryExpansionGraphRAG` class inherits from `AdvancedGraphRAG`
    and introduces an `expand_query` method that takes a query and the desired number
    of expansions as input. First, this method retrieves the top three most relevant
    nodes based on the initial query using the base class’s `retrieve` method. It
    then iterates through these initial nodes, selecting a random neighbor for each
    and constructing an expanded query by appending the neighbor’s type (if available)
    and the neighbor’s ID to the original query. The `retrieve` method is overridden
    to first expand the input query using the `expand_query` method. It then retrieves
    results for each expanded query using the base class’s `retrieve` method, concatenates
    the results, removes duplicates while preserving order, and returns the top *k*
    unique nodes. This approach leverages the graph structure to explore related concepts
    and broaden the search scope, potentially capturing more relevant information
    than a direct query alone.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码在基于图的结构化检索系统（RAG）中实现了查询扩展，以增强检索性能。`QueryExpansionGraphRAG` 类继承自 `AdvancedGraphRAG`
    并引入了一个 `expand_query` 方法，该方法接受一个查询和期望的扩展次数作为输入。首先，此方法使用基类的 `retrieve` 方法根据初始查询检索出最相关的三个节点。然后，它遍历这些初始节点，为每个节点随机选择一个邻居，并通过将邻居的类型（如果可用）和邻居的
    ID 添加到原始查询中来构建一个扩展查询。`retrieve` 方法被重写，首先使用 `expand_query` 方法扩展输入查询。然后，它使用基类的 `retrieve`
    方法为每个扩展查询检索结果，合并结果，同时保留顺序并移除重复项，最后返回前 *k* 个独特的节点。这种方法利用图结构来探索相关概念并扩大搜索范围，可能比单独的直接查询捕获到更多相关信息。
- en: Query expansion is particularly useful when the initial query is too narrow
    or underspecified, resulting in low recall. In graph-based retrieval settings,
    this often occurs when the query does not explicitly mention related entities
    or concepts that are semantically or structurally linked in the graph. By incorporating
    neighboring nodes into the query formulation, the system can uncover relevant
    content that would otherwise be overlooked, making query expansion especially
    beneficial in exploratory search scenarios or domains with sparse or highly interconnected
    data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 查询扩展在初始查询过于狭窄或未充分指定时特别有用，导致召回率低。在基于图的检索设置中，这通常发生在查询没有明确提及与图中语义或结构上相关联的相关实体或概念时。通过将相邻节点纳入查询制定中，系统可以发现否则会被忽视的相关内容，这使得查询扩展在探索性搜索场景或数据稀疏或高度互联的领域中特别有益。
- en: Now that we’ve explored techniques to enhance retrieval, let’s shift our focus
    to improving the generation phase. We’ll now delve into the process of integrating
    graph information into LLM generation, examining how we can incorporate graph
    knowledge directly into the generation process to create more informed and coherent
    responses.Integrating graph information into LLM generation
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了增强检索的技术，让我们将注意力转向改进生成阶段。我们将深入了解将图信息集成到LLM生成过程中的方法，探讨如何将图知识直接集成到生成过程中，以创建更全面和连贯的响应。集成图信息到LLM生成
- en: 'To integrate graph information into LLM generation, we can create a prompt
    that incorporates the retrieved graph context:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 要将图信息集成到LLM生成中，我们可以创建一个提示，其中包含检索到的图上下文：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This code integrates an LLM for response generation within the graph-based
    RAG framework. The `GenerativeGraphRAG` class inherits from `QueryExpansionGraphRAG`
    and initializes with `KnowledgeGraph`, a retriever model name, and a generator
    model name. It loads a pre-trained causal language model and its corresponding
    tokenizer using `transformers`. The `generate_response` method orchestrates the
    entire process: first, it retrieves relevant nodes from the knowledge graph using
    the `retrieve` method inherited from the parent class. Then, it constructs a context
    string by calling `build_graph_context`, which formats the retrieved nodes, their
    properties, and their relationships to other nodes into a readable text. This
    context is then incorporated into a prompt alongside the original query, which
    is fed into the pre-trained language model. The language model generates a response
    based on the prompt, and the generated tokens are decoded back into a human-readable
    string, effectively leveraging the graph structure to inform the language model’s
    response generation. The `build_graph_context` method formats retrieved graph
    information into the prompt, including node IDs, properties, and relationships
    to neighbors, providing a structured representation of the relevant knowledge
    to the LLM.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码在基于图的RAG框架内集成了一个用于响应生成的LLM。`GenerativeGraphRAG`类从`QueryExpansionGraphRAG`继承，并使用`KnowledgeGraph`（知识图谱）、检索器模型名称和生成器模型名称进行初始化。它使用`transformers`加载了一个预训练的因果语言模型及其相应的分词器。`generate_response`方法协调整个过程：首先，它使用从父类继承的`retrieve`方法从知识图谱中检索相关节点。然后，它通过调用`build_graph_context`构建一个上下文字符串，该字符串格式化检索到的节点、它们的属性以及它们与其他节点的关系，形成一个可读的文本。然后，这个上下文与原始查询一起纳入提示中，并输入到预训练的语言模型中。语言模型根据提示生成一个响应，生成的标记被解码回人类可读的字符串，有效地利用图结构来指导语言模型生成响应。`build_graph_context`方法将检索到的图信息格式化为提示，包括节点ID、属性以及与邻居的关系，为LLM提供相关知识的结构化表示。
- en: Now that we’ve explored how to integrate graph information into the generation
    process, let’s consider the broader applications and potential uses of this approach.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了如何将图信息集成到生成过程中，让我们考虑这一方法的更广泛的应用和潜在用途。
- en: Applications and use cases of graph RAG in LLMs
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图RAG在LLM中的应用和用例
- en: 'Graph-based RAG can be particularly effective in various applications:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的RAG在多种应用中特别有效：
- en: Question-answering over knowledge graphs
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于知识图谱的问答
- en: Personalized recommendation systems
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个性化推荐系统
- en: Scientific literature analysis
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 科学文献分析
- en: Drug discovery and biomedical research
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 药物发现和生物医学研究
- en: Social network analysis
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社交网络分析
- en: 'Here’s an example of how graph RAG could be used for a recommendation system:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个如何使用图RAG构建推荐系统的例子：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This example demonstrates how graph RAG can be used to generate personalized
    recommendations and explain those recommendations using the graph structure.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子展示了如何使用图RAG生成个性化推荐，并利用图结构解释这些推荐。
- en: Challenges and future directions in graph-based RAG
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于图的RAG的挑战和未来方向
- en: 'Let’s consider some key challenges and future research directions in graph-based
    RAG:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一些基于图的关系增强生成（RAG）的关键挑战和未来研究方向：
- en: Scalability to very large graphs
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展到非常大的图
- en: Handling dynamic and evolving graph structures
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理动态和演变的图结构
- en: Incorporating uncertainty and probabilistic relationships
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合不确定性和概率关系
- en: Improving the interpretability of graph-based retrievals and generations
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高基于图的检索和生成的可解释性
- en: Developing more sophisticated graph-aware language models
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发更复杂的图感知语言模型
- en: 'These are fascinating and complex research topics. In this chapter, we’ll focus
    on the scalability aspect of graph-based RAG. You are encouraged to read the research
    paper titled *Graph Retrieval-Augmented Generation: A Survey* at [https://arxiv.org/abs/2408.08921](https://arxiv.org/abs/2408.08921)
    for more information on other challenges and research directions.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是令人着迷且复杂的研究主题。在本章中，我们将关注基于图的RAG的可扩展性方面。我们鼓励您阅读标题为《图检索增强生成：综述》的研究论文[https://arxiv.org/abs/2408.08921](https://arxiv.org/abs/2408.08921)，以了解更多关于其他挑战和研究方向的信息。
- en: Real-world knowledge graphs can contain millions or even billions of nodes and
    edges. Querying and traversing such massive graphs can be computationally expensive,
    especially when incorporated into a real-time RAG pipeline. Furthermore, providing
    a huge subgraph as context to the LLM can exceed its context window limit and
    dilute the relevant information with noise.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 实际世界的知识图谱可能包含数百万甚至数十亿个节点和边。查询和遍历这样的大规模图可能计算成本高昂，尤其是在实时RAG管道中。此外，向LLM提供巨大的子图作为上下文可能会超过其上下文窗口限制，并使相关信息与噪声稀释。
- en: 'Several factors contribute to this scalability bottleneck:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 几个因素导致了这个可扩展性瓶颈：
- en: '**Graph traversal complexity**: Finding relevant nodes and their connections
    within a large graph can be time consuming. Standard graph algorithms such as
    BFS or DFS can become inefficient as the graph grows.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图遍历复杂性**：在大型图中找到相关节点及其连接可能耗时。随着图的增长，标准图算法如BFS或DFS可能变得效率低下。'
- en: '**Embedding storage and retrieval**: Storing and retrieving node embeddings
    for a massive graph requires significant memory and computational resources. Computing
    similarity scores between the query embedding and all node embeddings becomes
    a bottleneck.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**嵌入存储和检索**：存储和检索大规模图的节点嵌入需要大量的内存和计算资源。计算查询嵌入与所有节点嵌入之间的相似度分数成为瓶颈。'
- en: '**Context window limitations**: LLMs have a limited context window, meaning
    they can only process a fixed amount of text at a time. A large graph context
    can easily exceed this limit, forcing truncation and potentially resulting in
    the loss of important information.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文窗口限制**：LLM有一个有限的范围，这意味着它们一次只能处理固定数量的文本。大型图上下文很容易超过这个限制，导致截断，并可能造成重要信息的丢失。'
- en: '**Noise in context**: Including too much irrelevant information from the graph
    as context can confuse the LLM and degrade the quality of the generated response.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文中的噪声**：将过多无关信息从图中作为上下文可能会混淆LLM并降低生成响应的质量。'
- en: 'To address these scalability challenges, several strategies can be employed.
    One such strategy, which we will implement, is **subgraph sampling**. This involves
    extracting a smaller, more manageable subgraph from the overall knowledge graph
    that is most relevant to the user’s query. This reduces the computational cost
    of graph traversal and embedding retrieval, while also ensuring that the LLM receives
    a focused and informative context. Other techniques for improving scalability
    include the following:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些可扩展性挑战，可以采用几种策略。我们将实施的一种策略是**子图采样**。这涉及到从整体知识图谱中提取一个更小、更易于管理的子图，该子图与用户的查询最相关。这降低了图遍历和嵌入检索的计算成本，同时确保LLM接收到的上下文是专注且信息丰富的。提高可扩展性的其他技术包括以下内容：
- en: '**Graph databases**: Using specialized graph databases such as Neo4j or Amazon
    Neptune can significantly improve query performance and scalability compared to
    general-purpose databases'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图数据库**：使用专门的图数据库，如Neo4j或Amazon Neptune，与通用数据库相比，可以显著提高查询性能和可扩展性。'
- en: '**Approximate nearest neighbor (ANN) search**: Using ANN algorithms for embedding
    retrieval can significantly speed up the search process by sacrificing some accuracy'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**近似最近邻（ANN）搜索**：使用ANN算法进行嵌入检索可以通过牺牲一些精度显著加快搜索过程。'
- en: '**Knowledge graph summarization**: Condensing the knowledge graph into a smaller,
    more manageable representation while preserving its essential information'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**知识图谱摘要**：将知识图谱压缩成更小、更易于管理的表示形式，同时保留其基本信息。'
- en: '**Hardware acceleration**: Utilizing GPUs or specialized hardware accelerators
    can speed up graph computations and embedding operations'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**硬件加速**：利用GPU或专用硬件加速器可以加快图计算和嵌入操作。'
- en: '**Context distillation**: Techniques such as selective context injection or
    hierarchical retrieval can filter and prioritize the most relevant information
    for the LLM'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文蒸馏**：如选择性上下文注入或分层检索等技术可以过滤并优先选择对LLM最相关的信息。'
- en: 'Now, let’s proceed with implementing subgraph sampling to see how it helps
    address scalability concerns:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续实现子图采样，看看它如何帮助解决可扩展性问题：
- en: '[PRE6]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This code introduces a `ScalableGraphRAG` class, which is designed to address
    the scalability challenges of graph-based RAG systems by implementing a subgraph
    sampling technique. Inheriting from `GenerativeGraphRAG`, it incorporates a `max_subgraph_size`
    parameter to limit the size of the extracted subgraph.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码引入了一个`ScalableGraphRAG`类，该类通过实现子图采样技术来解决基于图RAG系统的可扩展性挑战。它从`GenerativeGraphRAG`继承，并包含一个`max_subgraph_size`参数来限制提取的子图大小。
- en: The overridden retrieve method first identifies an initial set of relevant nodes
    using the base class’s retrieval mechanism. It then calls the `sample_subgraph`
    method to construct a subgraph centered around these initial nodes, limiting its
    growth to the specified `max_subgraph_size`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 重写的检索方法首先使用基类的检索机制确定一组初始相关节点。然后，它调用`sample_subgraph`方法构建一个以这些初始节点为中心的子图，限制其增长到指定的`max_subgraph_size`。
- en: The `sample_subgraph` method performs a breadth-first expansion from the seed
    nodes, adding nodes and edges to the subgraph until the size limit is reached,
    prioritizing nodes closer to the seed.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`sample_subgraph`方法从种子节点进行广度优先扩展，向子图添加节点和边，直到达到大小限制，优先考虑靠近种子节点的节点。'
- en: Subgraph sampling can be tuned by adjusting the `max_subgraph_size` parameter
    so that it balances context richness and computational efficiency. A smaller size
    results in faster processing but potentially misses crucial contextual information,
    while a larger size captures more context but increases computational cost. Additionally,
    the algorithm’s node selection criteria during subgraph expansion can be tuned
    – for example, prioritizing nodes with higher semantic similarity to the query
    or nodes with stronger connectivity to the seed nodes. Experimenting with these
    parameters is useful for optimizing the RAG system’s performance for specific
    applications and graph structures.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过调整`max_subgraph_size`参数来调整子图采样，以平衡上下文丰富性和计算效率。较小的尺寸会导致处理速度更快，但可能会错过关键上下文信息，而较大的尺寸可以捕获更多上下文，但会增加计算成本。此外，算法在子图扩展期间的节点选择标准也可以进行调整——例如，优先考虑与查询具有更高语义相似度的节点或与种子节点具有更强连接性的节点。对这些参数进行实验对于优化RAG系统针对特定应用和图结构的性能是有用的。
- en: Finally, the `rank_nodes_in_subgraph` method calculates the relevance of each
    node within the subgraph to the query by computing the cosine similarity between
    the query embedding and the node’s pre-computed embedding. Then, it returns a
    ranked list of nodes based on their similarity scores, ensuring that only the
    most relevant nodes within the sampled subgraph are considered for context augmentation.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`rank_nodes_in_subgraph`方法通过计算查询嵌入与节点预先计算的嵌入之间的余弦相似度来计算子图内每个节点相对于查询的相关性。然后，它根据相似度分数返回一个节点排名列表，确保只考虑采样子图中最相关的节点进行上下文增强。
- en: Summary
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Graph-based RAG extends the capabilities of traditional RAG systems by leveraging
    the rich structure of knowledge graphs. By implementing the techniques and approaches
    discussed in this chapter, you can create more sophisticated LLM systems capable
    of reasoning over complex relationships and generating more contextually appropriate
    responses. In the next chapter, we will explore advanced RAG patterns for LLMs.
    This will build upon the graph-based techniques we’ve discussed here so that you
    can create even more powerful and flexible RAG systems.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的RAG通过利用知识图谱的丰富结构扩展了传统RAG系统的功能。通过实施本章讨论的技术和方法，您可以创建更复杂的LLM系统，这些系统能够对复杂关系进行推理并生成更符合语境的响应。在下一章中，我们将探讨LLM的高级RAG模式。这将基于我们在这里讨论的图技术，以便您创建更强大和灵活的RAG系统。
