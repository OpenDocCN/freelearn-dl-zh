- en: Convolution Neural Network
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涉及以下主题：
- en: Downloading and configuring an image dataset
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下载并配置图像数据集
- en: Learning the architecture of a CNN classifier
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习CNN分类器的架构
- en: Using functions to initialize weights and biases
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用函数初始化权重和偏差
- en: Using functions to create a new convolution layer
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用函数创建新的卷积层
- en: Using functions to flatten the densely connected layer
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用函数将密集连接层展平
- en: Defining placeholder variables
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义占位符变量
- en: Creating the first convolution layer
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建第一个卷积层
- en: Creating the second convolution layer
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建第二个卷积层
- en: Flattening the second convolution layer
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 展平第二个卷积层
- en: Creating the first fully connected layer
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建第一个全连接层
- en: Applying dropout to the first fully connected layer
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对第一个全连接层应用dropout
- en: Creating the second fully connected layer with dropout
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建带有dropout的第二个全连接层
- en: Applying softmax activation to obtain a predicted class
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用softmax激活函数以获取预测类别
- en: Defining the cost function used for optimization
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义用于优化的成本函数
- en: Performing gradient descent cost optimization
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行梯度下降成本优化
- en: Executing the graph in a TensorFlow session
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在TensorFlow会话中执行图
- en: Evaluating the performance on test data
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在测试数据上评估性能
- en: Introduction
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: '**Convolution neural networks** (**CNN**) are a category of deep learning neural
    networks with a prominent role in building image recognition- and natural language
    processing-based classification models.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积神经网络** (**CNN**) 是深度学习神经网络的一类，在构建基于图像识别和自然语言处理的分类模型中发挥着重要作用。'
- en: The CNN follows a similar architecture to LeNet, which was primarily designed
    to recognize characters such as numbers, zip codes, and so on. As against artificial
    neural networks, CNN have layers of neurons arranged in three-dimensional space
    (width, depth, and height). Each layer transforms a two-dimensional image into
    a three-dimensional input volume, which is then transformed into a three-dimensional
    output volume using neuron activation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: CNN的架构类似于LeNet，它主要用于识别数字、邮政编码等字符。与人工神经网络不同，CNN有按三维空间（宽度、深度、高度）排列的神经元层。每一层将二维图像转换为三维输入体积，接着通过神经元激活将其转换为三维输出体积。
- en: 'Primarily, CNNs are built using three main types of activation layers: convolution
    layer ReLU, pooling layer, and fully connected layer. The convolution layer is
    used to extract features (spatial relationship between pixels) from the input
    vector (of images) and stores them for further processing after computing a dot
    product with weights (and biases).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: CNN主要使用三种类型的激活层：卷积层ReLU、池化层和全连接层。卷积层用于从输入向量（图像）中提取特征（像素之间的空间关系），并在计算与权重（和偏差）的点积后存储它们，以供进一步处理。
- en: '**Rectified Linear Unit** (**ReLU**) is then applied after convolution to introduce
    non-linearity in the operation.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**修正线性单元** (**ReLU**) 在卷积操作后应用，以引入非线性。'
- en: This is an element-wise operation (such as a threshold function, sigmoid, and
    tanh) applied to each convolved feature map. Then, the pooling layer (operations
    such as max, mean, and sum) is used to downsize the dimensionality of each feature
    map ensuring minimum information loss. This operation of spatial size reduction
    is used to control overfitting and increase the robustness of the network to small
    distortions or transformations. The output of the pooling layer is then connected
    to a traditional multilayer perceptron (also called the fully connected layer).
    This perceptron uses activation functions such as softmax or SVM to build classifier-based
    CNN models.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个逐元素操作（如阈值函数、sigmoid和tanh），应用于每一个卷积特征图。然后，池化层（如最大池化、平均池化和求和池化等操作）用于缩减每个特征图的维度，以确保最小的信息丢失。该空间尺寸缩减操作用于控制过拟合，并增强网络对小的扭曲或变换的鲁棒性。池化层的输出随后与传统的多层感知机（也称为全连接层）连接。该感知机使用激活函数，如softmax或SVM，来构建基于分类器的CNN模型。
- en: The recipes in this chapter will focus on building a convolution neural network
    for image classification using Tensorflow in R. While the recipes will provide
    you with an overview of a typical CNN, we encourage you to adapt and modify the
    parameters according to your needs.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的教程将重点讲解如何使用R中的TensorFlow构建图像分类的卷积神经网络。虽然这些教程会给你提供典型CNN的概览，但我们鼓励你根据自己的需求调整和修改参数。
- en: Downloading and configuring an image dataset
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下载并配置图像数据集
- en: In this chapter, we will use the CIFAR-10 dataset to build a convolution neural
    network for image classification. The CIFAR-10 dataset consists of 60,000 32 x
    32 color images of 10 classes, with 6,000 images per class. These are further
    divided into five training batches and one test batch, each with 10,000 images.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用CIFAR-10数据集来构建用于图像分类的卷积神经网络。CIFAR-10数据集包含60,000张32x32的彩色图像，涵盖10个类别，每个类别有6,000张图像。数据集进一步分为五个训练批次和一个测试批次，每个批次包含10,000张图像。
- en: 'The test batch contains exactly 1,000 randomly-selected images from each class.
    The training batches contain the remaining images in random order, but some training
    batches may contain more images from one class than another. Between them, the
    training batches contain exactly 5,000 images from each class. The ten outcome
    classes are airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and
    truck. The classes are completely mutually exclusive. In addition, the format
    of the dataset is as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 测试批次包含每个类别中精确选择的1,000张随机图片。训练批次包含剩余的图片，按随机顺序排列，但某些训练批次可能包含某一类别更多的图片。所有训练批次中，每个类别的图片总数为5,000张。十个输出类别分别为飞机、汽车、鸟类、猫、鹿、狗、青蛙、马、船和卡车。各类别完全互斥。此外，数据集的格式如下：
- en: 'The first column: The label with 10 classes: airplane, automobile, bird, cat,
    deer, dog, frog, horse, ship, and truck'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一列：包含10个类别的标签：飞机、汽车、鸟类、猫、鹿、狗、青蛙、马、船和卡车
- en: 'The next 1,024 columns: Red pixels in the range of 0 to 255'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来的1,024列：红色像素值范围从0到255
- en: 'The next 1,024 columns: Green pixels in the range of 0 to 255'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来的1,024列：绿色像素值范围从0到255
- en: 'The next 1,024 columns: Blue pixels in the range of 0 to 255'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来的1,024列：蓝色像素值范围从0到255
- en: Getting ready
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: For this recipe, you will require R with some packages installed such as `data.table`
    and `imager`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本食谱，您需要安装一些包的R版本，例如`data.table`和`imager`。
- en: How to do it...
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: Start R (using Rstudio or Docker) and load the required packages.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动R（使用Rstudio或Docker）并加载所需的包。
- en: 'Download the dataset (binary version) from [http://www.cs.toronto.edu/~kriz/cifar.html](http://www.cs.toronto.edu/~kriz/cifar.html)
    manually or use the following function to download the data in the R environment.
    The function takes the working directory or the downloaded dataset''s location
    path as an input parameter (`data_dir`):'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 手动从[http://www.cs.toronto.edu/~kriz/cifar.html](http://www.cs.toronto.edu/~kriz/cifar.html)下载数据集（二进制版本），或者使用以下函数在R环境中下载数据。该函数以工作目录或下载数据集的位置路径作为输入参数（`data_dir`）：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once the dataset is downloaded and untarred (or unzipped), read it in the R
    environment as train and test datasets. The function takes the filenames of the
    train and test batch datasets (`filenames`) and the number of images to retrieve
    per batch file (`num.images`) as input parameters:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦数据集下载并解压（或解压缩），将其作为训练和测试数据集读取到R环境中。该函数以训练和测试批次数据集的文件名（`filenames`）和每个批次文件中要检索的图像数量（`num.images`）作为输入参数：
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The outcome of the earlier function is a list of red, green, and blue pixel
    dataframes for each image along with their labels. Then, flatten the data into
    a list of two dataframes (one for input and the other for output) using the following
    function, which takes two parameters--a list of input variables (`x_listdata`)
    and a list of output variables (`y_listdata`):'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前面函数的输出是每张图片的红、绿、蓝像素数据框和它们的标签。然后，使用以下函数将数据展平为两个数据框（一个用于输入，另一个用于输出）的列表，该函数需要两个参数——输入变量列表（`x_listdata`）和输出变量列表（`y_listdata`）：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once the list of input and output train and test dataframes is ready, perform
    sanity checks by plotting the images along with their labels. The function requires
    two mandatory parameters (`index`: image row number and `images.rgb`: flattened
    input dataset) and one optional parameter (`images.lab`: flattened output dataset):'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦输入和输出的训练与测试数据框列表准备就绪，通过绘制图像及其标签来执行完整性检查。该函数需要两个必需的参数（`index`：图片行号和`images.rgb`：展平的输入数据集）和一个可选参数（`images.lab`：展平的输出数据集）：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now transform the input data using the min-max standardization technique. The
    `preProcess` function from the package can be used for normalization. The `"range"`
    option of the method performs min-max normalization as follows:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在使用最小-最大标准化技术对输入数据进行转换。可以使用包中的`preProcess`函数进行归一化。该方法的`"range"`选项执行最小-最大归一化，过程如下：
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: How it works...
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'Let''s take a look at what we did in the earlier recipe. In step 2, we downloaded
    the CIFAR-10 dataset from the link mentioned in case it is not present in the
    given link or working directory. In step 3, the unzipped files are loaded in the
    R environment as train and test datasets. The train dataset has a list of 50,000
    images and the test dataset has a list of 10,000 images along with their labels.
    Then, in step 4, the train and test datasets are flattened into a list of two
    dataframes: one with input variables (or images) of length 3,072 (1,024 of red,
    1,024 of green, and 1,024 of blue) and the other with output variables (or labels)
    of length 10 (binary for each class). In step 5, we perform sanity checks for
    the created train and test datasets by generating plots. The following figure
    shows a set of six train images along with their labels. Finally, in step 6, the
    input data is transformed using the min-max standardization technique. An example
    of categories from the CIFAR-10 dataset is shown in the following figure:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下前面步骤中做的事情。在第2步中，我们从给定链接下载了CIFAR-10数据集，以防该链接或工作目录中没有该数据集。在第3步中，解压缩后的文件作为训练集和测试集加载到R环境中。训练集包含50,000张图像，测试集包含10,000张图像及其标签。然后，在第4步中，训练集和测试集被展平成包含两个数据框的列表：一个是输入变量（或图像），其长度为3,072（1,024个红色，1,024个绿色，1,024个蓝色），另一个是输出变量（或标签），长度为10（每个类别的二进制标签）。在第5步中，我们通过生成图表对创建的训练集和测试集进行合理性检查。下图展示了一组六张训练图像及其标签。最后，在第6步中，使用最小-最大标准化技术对输入数据进行转换。CIFAR-10数据集的类别示例如下图所示：
- en: '![](img/00030.jpeg)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00030.jpeg)'
- en: See also
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另请参见
- en: '*Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009*
    ([http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf](http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf)).
    This is also the reference for this section.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*《从微小图像中学习多层特征》，Alex Krizhevsky，2009* ([http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf](http://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf))。这也是本节的参考文献。'
- en: Learning the architecture of a CNN classifier
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 学习CNN分类器的架构
- en: The CNN classifier covered in this chapter has two convolution layers followed
    by two fully connected layers in the end, in which the last layer acts as a classifier
    using the softmax `activation` function.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍的CNN分类器有两个卷积层，后面跟着两个全连接层，其中最后一层使用softmax `激活`函数作为分类器。
- en: Getting ready
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The recipe requires the CIFAR-10 dataset. Thus, the CIFAR-10 dataset should
    be downloaded and loaded into the R environment. Also, images are of size 32 x
    32 pixels.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 该教程需要CIFAR-10数据集。因此，应该下载CIFAR-10数据集并将其加载到R环境中。此外，图像的大小为32 x 32像素。
- en: How to do it...
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 怎么做……
- en: 'Let''s define the configuration of the CNN classifier as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按如下方式定义CNN分类器的配置：
- en: 'Each input image (CIFAR-10) is of size 32 x 32 pixels and can be labeled one
    among 10 classes:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个输入图像（CIFAR-10）的大小为32 x 32像素，并可以被标记为10个类别中的一个：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The images of the CIFAR-10 dataset have three channels (red, green, and blue):'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CIFAR-10数据集的图像有三个通道（红色、绿色和蓝色）：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The images are stored in one-dimensional arrays of the following length (`img_size_flat`):'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像存储在以下长度的一维数组中（`img_size_flat`）：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In the first convolution layer, the size (width x height) of the convolution
    filter is 5 x 5 pixels (`filter_size1`) and the depth (or number) of convolution
    filter is `64` (`num_filters1`):'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第一个卷积层中，卷积滤波器的大小（宽度 x 高度）为5 x 5像素（`filter_size1`），卷积滤波器的深度（或数量）为`64`（`num_filters1`）：
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'In the second convolution layer, the size and depth of the convolution filter
    is the same as the first convolution layer:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二个卷积层中，卷积滤波器的大小和深度与第一个卷积层相同：
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Similarly, the output of the first fully connected layer is the same as the
    input of the second fully connected layer:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似地，第一个全连接层的输出与第二个全连接层的输入相同：
- en: '[PRE10]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: How it works...
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The dimensions and characteristics of an input image are shown in steps 1 and
    2, respectively. Every input image is further processed in a convolution layer
    using a set of filters as defined in steps 4 and 5\. The first convolution layer
    results in a set of 64 images (one for each set filter). In addition, the resolution
    of these images are also reduced to half (because of 2 x 2 max pooling); namely,
    from 32 x 32 pixels to 16 x 16 pixels.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 输入图像的维度和特性分别在步骤1和步骤2中展示。每个输入图像在卷积层中经过一组滤波器的进一步处理，如步骤4和5所定义。第一个卷积层生成一组64张图像（每个滤波器对应一张图像）。此外，这些图像的分辨率也被减半（因为使用了2
    x 2最大池化）；即，从32 x 32像素变为16 x 16像素。
- en: The second convolution layer will input these 64 images and provide an output
    of new 64 images with further reduced resolutions. The updated resolution is now
    8 x 8 pixels (again due to 2 x 2 max pooling). In the second convolution layer,
    a total of 64 x 64 = 4,096 filters are created, which are then further convoluted
    into 64 output images (or channels). Remember that these 64 images of 8 x 8 resolution
    correspond to a single input image.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 第二卷积层将输入这64张图像，并输出新的64张图像，分辨率进一步降低。更新后的分辨率为8 x 8像素（由于2 x 2最大池化）。在第二卷积层中，共创建了64
    x 64 = 4,096个滤波器，然后它们被进一步卷积为64张输出图像（或通道）。请记住，这64张8 x 8分辨率的图像对应于一个输入图像。
- en: Further, these 64 output images of 8 x 8 pixels are flattened into a single
    vector of length 4,096 (8 x 8 x 64), as defined in step 3, and are used as an
    input to a fully connected layer of a given set of neurons, as defined in step
    6\. The vector of 4,096 elements is then fed into the first fully connected layer
    of 1,024 neurons. The output neurons are again fed into a second fully connected
    layer of 10 neurons (equal to `num_classes`). These 10 neurons represent each
    of the class labels, which are then used to determine the (final) class of the
    image.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这64张8 x 8像素的输出图像会被展平为一个长度为4,096（8 x 8 x 64）的单一向量，如第3步中所定义，并作为输入传递给一层全连接神经元，这些神经元在第6步中定义。该4,096个元素的向量接着被输入到第一个包含1,024个神经元的全连接层。输出神经元再次输入到第二个包含10个神经元的全连接层（与`num_classes`相等）。这10个神经元代表每个类别标签，然后用来确定图像的（最终）类别。
- en: First, the weights of the convolution and fully connected layers are randomly
    initialized till the classification stage (the end of CNN graph). Here, the classification
    error is computed based on the true class and the predicted class (also called
    cross entropy).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，卷积层和全连接层的权重被随机初始化，直到分类阶段（CNN图的结束）。在这里，分类误差是基于真实类别和预测类别计算的（也叫做交叉熵）。
- en: Then, the optimizer backpropagates the error through the convolution network
    using the chain rule of differentiation, post which the weights of the layers
    (or filters) are updated such that the error is minimized. This entire cycle of
    one forward and backward propagation is called one iteration. Thousands of such
    iterations are performed till the classification error is reduced to a sufficiently
    low value.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，优化器通过使用链式法则反向传播误差，通过卷积网络进行传播，之后更新各层（或滤波器）的权重，使得误差最小化。这个包含一次正向传播和反向传播的完整周期被称为一次迭代。进行成千上万次这样的迭代，直到分类误差降到足够低的值。
- en: Generally, these iterations are performed using a batch of images instead of
    a single image to increase the efficiency of computation.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这些迭代使用一批图像而不是单一图像来执行，以提高计算效率。
- en: 'The following image represents the convolution network designed in this chapter:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了本章设计的卷积网络：
- en: '![](img/00032.jpeg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00032.jpeg)'
- en: Using functions to initialize weights and biases
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用函数初始化权重和偏置
- en: Weights and biases form an integral part of any deep neural network optimization
    and here we define a couple of functions to automate these initializations. It
    is a good practice to initialize weights with small noise to break symmetry and
    prevent zero gradients. Additionally, a small positive initial bias would avoid
    inactivated neurons, suitable for ReLU activation neurons.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 权重和偏置是任何深度神经网络优化的重要组成部分，在这里我们定义了一些函数来自动化这些初始化。一个好的做法是用小噪声初始化权重，以打破对称性并防止零梯度。此外，适当的小正偏置将避免神经元不激活，适合ReLU激活神经元。
- en: Getting ready
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备开始
- en: Weights and biases are model coefficients which need to be initialized before
    model compilation. This steps require the `shape` parameter to be determined based
    on input dataset.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 权重和偏置是模型系数，需要在模型编译之前初始化。此步骤需要根据输入数据集确定`shape`参数。
- en: How to do it...
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'The following function is used to return randomly initialized weights:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下函数用于返回随机初始化的权重：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following function is used to return constant biases:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下函数用于返回常量偏置：
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: How it works...
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: These functions return TensorFlow variables that are later used as part of a
    Tensorflow graph. The `shape` is defined as a list of attributes defining a filter
    in the convolution layer, which is covered in the next recipe. The weights are
    randomly initialized with a standard deviation equal to `0.1` and biases are initialized
    with a constant value of `0.1`.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数返回TensorFlow变量，后续将在TensorFlow图中使用。`shape`定义为一个列表，描述了卷积层中滤波器的属性，接下来会在下一个配方中介绍。权重以标准差为`0.1`随机初始化，偏置则以常量`0.1`初始化。
- en: Using functions to create a new convolution layer
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用函数创建新的卷积层
- en: Creating a convolution layer is the primary step in a CNN TensorFlow computational
    graph. This function is primarily used to define the mathematical formulas in
    the TensorFlow graph, which is later used in actual computation during optimization.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 创建卷积层是CNN TensorFlow计算图中的主要步骤。此函数主要用于定义TensorFlow图中的数学公式，后续在优化过程中会用到这些公式进行实际计算。
- en: Getting ready
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The input dataset is defined and loaded. The `create_conv_layer` function presented
    in the recipe takes the following five input parameters and needs to be defined
    while setting-up a convolution layer:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据集已定义并加载。配方中呈现的`create_conv_layer`函数接受以下五个输入参数，并且在设置卷积层时需要定义：
- en: '`Input`: This is a four-dimensional tensor (or a list) that comprises a number
    of (input) images, the height of each image (here 32L), the width of each image
    (here 32L), and the number of channels of each image (here 3L : red, blue, and
    green).'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Input`：这是一个四维张量（或列表），包含多个（输入）图像，每个图像的高度（此处为32L）、宽度（此处为32L）以及每个图像的通道数（此处为3L：红色、蓝色和绿色）。'
- en: '`Num_input_channels`: This is defined as the number of color channels in the
    case of the first convolution layer or the number of filter channels in the case
    of subsequent convolution layers.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Num_input_channels`：这是指在第一个卷积层的情况下颜色通道的数量，或者在后续卷积层的情况下滤波器通道的数量。'
- en: '`Filter_size`: This is defined as the width and height of each filter in the
    convolution layer. Here, the filter is assumed to be a square.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Filter_size`：这是指卷积层中每个滤波器的宽度和高度。这里假设滤波器为正方形。'
- en: '`Num_filters`: This is defined as the number of filters in a given convolution
    layer.'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Num_filters`：这是指在给定卷积层中滤波器的数量。'
- en: '`Use_pooling`: This is a binary variable that is used perform 2 x 2 max pooling.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Use_pooling`：这是一个二进制变量，用于执行2 x 2的最大池化。'
- en: How to do it...
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Run the following function to create a new convolution layer:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下函数以创建一个新的卷积层：
- en: '[PRE13]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Run the following function to generate plots of convolution layers:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下函数以生成卷积层的图：
- en: '[PRE14]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Run the following function to generate plots of convolution layer weights:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下函数以生成卷积层权重的图：
- en: '[PRE15]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: How it works...
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The function begins with creating a shape tensor; namely, the list of four integers
    that are the width of a filter, the height of a filter, the number of input channels,
    and the number of given filters. Using this shape tensor, initialize a tensor
    of new weights with the defined shape and create a tensor a new (constant) biases,
    one for each filter.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数首先创建一个形状张量；即一个包含四个整数的列表，分别是滤波器的宽度、滤波器的高度、输入通道数和给定滤波器的数量。使用该形状张量，初始化一个具有定义形状的新权重张量，并为每个滤波器创建一个新的（常量）偏置张量。
- en: Once the necessary weights and biases are initialized, create a TensorFlow operation
    for convolution using the `tf$nn$conv2d` function. In our current setup, the strides
    are set to 1 in all four dimensions and padding is set to `SAME`. The first and
    last are set to 1 by default, but the middle two can factor in higher strides.
    A stride is the number of pixels by which we allow the filter matrix to slide
    over the input (image) matrix.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦初始化了必要的权重和偏置，使用`tf$nn$conv2d`函数创建卷积的TensorFlow操作。在我们当前的设置中，所有四个维度的步长都设置为1，填充设置为`SAME`。第一和最后一个默认设置为1，但中间两个可以有更大的步长。步长是指我们允许滤波器矩阵在输入（图像）矩阵上滑动的像素数。
- en: A stride of 3 would mean three pixel jumps across the *x* or *y* axis for each
    filter slide. Smaller strides would produce larger feature maps, thereby requiring
    higher computation for convergence. As the padding is set to `SAME`, the input
    (image) matrix is padded with zeros around the border so that we can apply the
    filter to border elements of the input matrix. Using this feature, we can control
    the size of the output matrix (or feature maps) to be the same as the input matrix.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 步幅为3意味着每次过滤器滑动时，沿*x*或*y*轴会跳过三个像素。较小的步幅会产生较大的特征图，从而需要更多的计算来收敛。由于填充设置为`SAME`，输入（图像）矩阵会在边界周围用零填充，以便我们可以将过滤器应用于输入矩阵的边界元素。利用这个特性，我们可以控制输出矩阵（或特征图）的大小与输入矩阵相同。
- en: On convolution, the bias values are added to each filter channel followed by
    pooling to prevent overfitting. In the current setup, 2 x 2 max-pooling (using
    `tf$nn$max_pool`) is performed to downsize the image resolution. Here, we consider
    2 x 2 (`ksize`*)-*sized windows and select the largest value in each window. These
    windows stride by two pixels (`strides`) either in the x or y direction.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积中，偏置值被添加到每个过滤器通道，并通过池化来防止过拟合。在当前设置中，执行2 x 2最大池化（使用`tf$nn$max_pool`）以减少图像分辨率。在这里，我们考虑2
    x 2（`ksize`*）大小的窗口，并选择每个窗口中的最大值。这些窗口每次按两个像素（`strides`）沿x或y方向滑动。
- en: On pooling, we add non-linearity to the layer using the ReLU activation function
    (`tf$nn$relu`). In ReLU, each pixel is triggered in the filter and all negative
    pixel values are replaced with zero using the `max(x,0)` function, where *x* is
    a pixel value. Generally, ReLU activation is performed before pooling. However,
    as we are using max-pooling, it doesn't necessarily impact the outcome as such
    because `relu(max_pool(x))` is equivalent to `max_pool(relu(x))`. Thus, by applying
    ReLU post pooling, we can save a lot of ReLU operations (~75%).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在池化时，我们通过ReLU激活函数（`tf$nn$relu`）向层中添加非线性。在ReLU中，每个像素都会在过滤器中被触发，所有负的像素值都会通过`max(x,0)`函数替换为零，其中*x*是像素值。通常，ReLU激活会在池化之前执行。然而，由于我们使用的是最大池化，它对结果的影响并不显著，因为`relu(max_pool(x))`等同于`max_pool(relu(x))`。因此，通过在池化后应用ReLU，我们可以节省大量ReLU操作（大约75%）。
- en: 'Finally, the function returns a list of convoluted layers and their corresponding
    weights. The convoluted layer is a four-dimensional tensor with the following
    attributes:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，函数返回一个包含卷积层及其对应权重的列表。卷积层是一个四维张量，具有以下属性：
- en: Number of (input) images, the same as `input`
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入图像的数量，与`input`相同
- en: Height of each image (reduced to half in the case of 2 x 2 max-pooling)
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个图像的高度（在2 x 2最大池化的情况下减少一半）
- en: Width of each image (reduced to half in the case of 2 x 2 max-pooling)
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个图像的宽度（在2 x 2最大池化的情况下减少一半）
- en: Number of channels produced, one for each convolution filter
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个卷积过滤器产生的通道数
- en: Using functions to create a new convolution layer
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用函数创建新的卷积层
- en: The four-dimensional outcome of a newly created convolution layer is flattened
    to a two-dimensional layer such that it can be used as an input to a fully connected
    multilayered perceptron.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 新创建的卷积层的四维结果被扁平化为二维层，以便将其作为输入用于全连接的多层感知机。
- en: Getting ready
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The recipe explains how to flatten a convolution layer before building the deep
    learning model. The input to the given function ( `flatten_conv_layer`) is a four-dimensional
    convolution layer that is defined based on previous layer.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 该配方解释了如何在构建深度学习模型之前扁平化卷积层。给定函数（`flatten_conv_layer`）的输入是一个四维的卷积层，该层是基于前一层定义的。
- en: How to do it...
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'Run the following function to flatten the convolution layer:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下函数以扁平化卷积层：
- en: '[PRE16]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: How it works...
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'The function begins with extracting the shape of the given input layer. As
    stated in previous recipes, the shape of the input layer comprises four integers:
    image number, image height, image width, and the number of color channels in the
    image. The number of features (`num_features`) is then evaluated using a dot-product
    of image height, image weight, and number of color channels.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数首先提取给定输入层的形状。如前述配方所述，输入层的形状由四个整数组成：图像数量、图像高度、图像宽度以及图像的颜色通道数。然后，通过图像高度、图像宽度和颜色通道数的点积计算特征数量（`num_features`）。
- en: Then, the layer is flattened or reshaped into a two-dimensional tensor (using
    `tf$reshape`). The first dimension is set to -1 (which is equal to the total number
    of images) and the second dimension is the number of features.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，该层被扁平化或调整为二维张量（使用`tf$reshape`）。第一维设置为-1（等于图像总数），第二维是特征数。
- en: Finally, the function returns a list of flattened layers along with the total
    number of (input) features.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，函数返回一个包含扁平化层及输入特征总数的列表。
- en: Using functions to flatten the densely connected layer
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用函数扁平化密集连接层
- en: The CNN generally ends with a fully connected multilayered perceptron using
    softmax activation in the output layer. Here, each neuron in the previous convoluted-flattened
    layer is connected to every neuron in the next (fully connected) layer.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: CNN通常以一个全连接的多层感知机结束，在输出层使用softmax激活函数。在这里，前一卷积扁平化层中的每个神经元都与下一层（全连接层）中的每个神经元相连。
- en: The key purpose of the fully convoluted layer is to use the features generated
    in the convolution and pooling stage to classify the given input image into various
    outcome classes (here, 10L). It also helps in learning the non-linear combinations
    of these features to define the outcome classes.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 全卷积层的主要目的是利用卷积和池化阶段生成的特征，将给定的输入图像分类为不同的输出类别（这里是10L）。它还有助于学习这些特征的非线性组合，从而定义输出类别。
- en: In this chapter, we use two fully connected layers for optimization. This function
    is primarily used to define the mathematical formulas in the TensorFlow graph,
    which is later used in actual computation during optimization.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用两个全连接层进行优化。这个函数主要用于定义张量流图中的数学公式，随后在优化过程中实际计算时使用。
- en: Getting ready
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'The (`create_fc_layer`) function takes four input parameters, which are as
    follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: (`create_fc_layer`)函数接收四个输入参数，具体如下：
- en: '`Input`: This is similar to the input of the new convolution layer function'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Input`：这类似于新卷积层函数的输入。'
- en: '`Num_inputs`: This is the number of input features generated post flattening
    the convoluted layer'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Num_inputs`：这是在扁平化卷积层后生成的输入特征数量。'
- en: '`Num_outputs`: This is the number of output neurons fully connected with the
    input neurons'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Num_outputs`：这是与输入神经元完全连接的输出神经元数量。'
- en: '`Use_relu`: This takes the binary flag that is set to `FALSE` only in the case
    of the final fully connected layer'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Use_relu`：这是一个二进制标志，只有在最终全连接层时设置为`FALSE`。'
- en: How to do it...
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Run the following function to create a new fully connected layer:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下函数以创建新的全连接层：
- en: '[PRE17]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: How it works...
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The function begins with initialing new weights and biases. Then, perform matrix
    multiplication of the input layer with initialized weights and add relevant biases.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 函数从初始化新的权重和偏置开始。然后，对输入层与初始化的权重进行矩阵乘法，并添加相关偏置。
- en: If, the fully connected layer is not the final layer of the CNN TensorFlow graph,
    ReLU non-linear activation can be performed. Finally, the fully connected layer
    is returned.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果全连接层不是CNN张量流图中的最终层，则可以执行ReLU非线性激活。最后，返回全连接层。
- en: Defining placeholder variables
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义占位符变量
- en: In this recipe, let's define the placeholder variables that serve as input to
    the modules in a TensorFlow computational graph. These are typically multidimensional
    arrays or matrices in the form of tensors.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个配方中，让我们定义作为张量流计算图模块输入的占位符变量。这些通常是多维数组或矩阵，呈现为张量的形式。
- en: Getting ready
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: The data type of placeholder variables is set to float32 (`tf$float32`) and
    the shape is set to a two-dimensional tensor.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 占位符变量的数据类型设置为float32（`tf$float32`），形状设置为二维张量。
- en: How to do it...
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现...
- en: 'Create an input placeholder variable:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个输入占位符变量：
- en: '[PRE18]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The NULL value in the placeholder allows us to pass non-deterministic arrays
    size.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 占位符中的NULL值允许我们传递非确定性数组的大小。
- en: 'Reshape the input placeholder `x` into a four-dimensional tensor:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入占位符`x`重新调整为四维张量：
- en: '[PRE19]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Create an output placeholder variable:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个输出占位符变量：
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Get the (`true`) classes of the output using argmax:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用argmax获取输出的（true）类别：
- en: '[PRE21]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: How it works...
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In step 1, we define an input placeholder variable. The dimensions of the shape
    tensor are `NULL` and `img_size_flat`. The former is set to hold any number of
    images (as rows) and the latter defines the length of input features for each
    image (as columns). In step 2, the input two-dimensional tensor is reshaped into
    a four-dimensional tensor, which can be served as input convolution layers. The
    four dimensions are as follows:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 1 中，我们定义了一个输入占位符变量。形状张量的维度是 `NULL` 和 `img_size_flat`。前者用于存储任意数量的图像（作为行），后者定义了每张图像的输入特征长度（作为列）。在步骤
    2 中，输入的二维张量被重塑成一个四维张量，作为卷积层的输入。四个维度如下：
- en: The first defines the number of input images (currently set to -1)
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一项定义了输入图像的数量（当前设置为 -1）
- en: The second defines the height of each image (equivalent to image size 32L)
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二项定义了每张图像的高度（相当于图像大小 32L）
- en: The third defines the width of each image (equivalent to image size, again 32L)
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三项定义了每张图像的宽度（相当于图像大小，这里是 32L）
- en: The fourth defines the number of color channels in each image (here 3L)
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四项定义了每张图像的颜色通道数（这里是 3L）
- en: In step 3, we define an output placeholder variable to hold true classes or
    labels of the images in `x`. The dimensions of the shape tensor are `NULL` and
    `num_classes`. The former is set to hold any number of images (as rows) and the
    latter defines the true class of each image as a binary vector of length `num_classes`
    (as columns). In our scenario, we have 10 classes. In step 4, we compress the
    two-dimensional output placeholder into a one-dimensional tensor of class numbers
    ranging from 1 to 10.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 3 中，我们定义了一个输出占位符变量，用于保存 `x` 中图像的真实类别或标签。形状张量的维度是 `NULL` 和 `num_classes`。前者用于存储任意数量的图像（作为行），后者定义了每张图像的真实类别作为一个长度为
    `num_classes` 的二进制向量（作为列）。在我们的场景中，有 10 个类别。步骤 4 中，我们将二维输出占位符压缩成一个一维的类别编号张量，类别编号范围从
    1 到 10。
- en: Creating the first convolution layer
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建第一个卷积层
- en: In this recipe, let's create the first convolution layer.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们来创建第一个卷积层。
- en: Getting ready
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: The following are the inputs to the function `create_conv_layer` defined in
    the recipe *Using functions to create a new convolution layer*.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是食谱 *使用函数创建新的卷积层* 中定义的函数 `create_conv_layer` 的输入：
- en: '`Input`: This is a four-dimensional reshaped input placeholder variable: `x_image`'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Input`：这是一个四维的重塑输入占位符变量：`x_image`'
- en: '`Num_input_channels`: This is the number of color channels, namely `num_channels`'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Num_input_channels`：这是颜色通道的数量，也就是 `num_channels`'
- en: '`Filter_size`: This is the height and width of the filter layer `filter_size1`'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Filter_size`：这是过滤层的高度和宽度 `filter_size1`'
- en: '`Num_filters`: This is the depth of the filter layer, namely `num_filters1`'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Num_filters`：这是过滤层的深度，也就是 `num_filters1`'
- en: '`Use_pooling`: This is the binary flag set to `TRUE`'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Use_pooling`：这是一个设置为 `TRUE` 的二进制标志'
- en: How to do it...
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Run the `create_conv_layer` function with the preceding input parameters:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 `create_conv_layer` 函数，使用前面的输入参数：
- en: '[PRE22]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Extract the `layers` of the first convolution layer:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取第一个卷积层的 `layers`：
- en: '[PRE23]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Extract the final `weights` of the first convolution layer:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取第一个卷积层的最终 `weights`：
- en: '[PRE24]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Generate the first convolution layer plots:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成第一个卷积层的图：
- en: '[PRE25]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Generate the first convolution layer weight plots:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成第一个卷积层的权重图：
- en: '[PRE26]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: How it works...
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In steps 1 and 2, we create a first convolution layer of four-dimensions. The
    first dimension (?) represents any number of input images, the second and third
    dimensions represent the height (16 pixels) and width (16 pixels) of each convoluted
    image, and the fourth dimension represents the number of channels (64) produced--one
    for each convoluted filter. In steps 3 and 5, we extract the final weights of
    the convolution layer, as shown in the following screenshot:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 1 和 2 中，我们创建了一个四维的第一个卷积层。第一维（?）表示输入图像的数量，第二和第三维分别表示每个卷积图像的高度（16 像素）和宽度（16
    像素），第四维表示产生的通道数（64）——每个卷积过滤器对应一个通道。在步骤 3 和 5 中，我们提取卷积层的最终权重，如下截图所示：
- en: '![](img/00035.gif)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00035.gif)'
- en: 'In step 4, we plot the output of the first convolution layer, as shown in the
    following screenshot:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 4 中，我们绘制第一个卷积层的输出，如下截图所示：
- en: '![](img/00038.jpeg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00038.jpeg)'
- en: Creating the second convolution layer
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建第二个卷积层
- en: In this recipe, let's create the second convolution layer.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们来创建第二个卷积层。
- en: Getting ready
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: The following are the inputs to the function `create_conv_layer` defined in
    the recipe *Using functions to create a new convolution layer*.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是食谱《使用函数创建新的卷积层》中定义的函数输入`create_conv_layer`：
- en: '`Input`: This is the four-dimensional output of the first convoluted layer;
    that is, `layer_conv1`'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Input`：这是第一个卷积层的四维输出；即`layer_conv1`'
- en: '`Num_input_channels`: This is the number of filters (or depth) in the first
    convoluted layer, `num_filters1`'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Num_input_channels`：这是第一个卷积层中的滤波器数量（或深度），`num_filters1`'
- en: '`Filter_size`: This is the height and width of the filter layer; namely, `filter_size2`'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Filter_size`：这是滤波器层的高度和宽度；即`filter_size2`'
- en: '`Num_filters`: This is the depth of the filter layer, `num_filters2`'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Num_filters`：这是滤波器层的深度，`num_filters2`'
- en: '`Use_pooling`: This is the binary flag set to `TRUE`'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Use_pooling`：这是设置为`TRUE`的二进制标志'
- en: How to do it...
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作方法...
- en: 'Run the `create_conv_layer` function with the preceding input parameters:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前述输入参数运行`create_conv_layer`函数：
- en: '[PRE27]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Extract the layers of the second convolution layer:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取第二个卷积层的层：
- en: '[PRE28]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Extract the final weights of the second convolution layer:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取第二卷积层的最终权重：
- en: '[PRE29]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Generate the second convolution layer plots:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成第二卷积层的图：
- en: '[PRE30]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Generate the second convolution layer weight plots:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成第二卷积层权重图：
- en: '[PRE31]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: How it works...
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In steps 1 and 2, we create a second convolution layer of four dimensions. The
    first dimension (?) represents any number of input images, the second and third
    dimensions represent the height (8 pixels) and width (8 pixels) of each convoluted
    image, and the fourth dimension represents the number of channels (64) produced,
    one for each convoluted filter.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在第1步和第2步中，我们创建一个四维的第二卷积层。第一维（?）表示任意数量的输入图像，第二和第三维表示每个卷积图像的高度（8像素）和宽度（8像素），第四维表示每个卷积滤波器产生的通道数（64）。
- en: 'In steps 3 and 5, we extract the final weights of the convolution layer, as
    shown in the following screenshot:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在第3步和第5步中，我们提取卷积层的最终权重，如下图所示：
- en: '![](img/00040.gif)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00040.gif)'
- en: 'In step 4, we plot the output of the second convolution layer, as shown in
    the following screenshot:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在第4步中，我们绘制第二个卷积层的输出，如下图所示：
- en: '![](img/00042.gif)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00042.gif)'
- en: Flattening the second convolution layer
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 展平第二个卷积层
- en: In this recipe, let's flatten the second convolution layer that we created.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将展平我们创建的第二个卷积层。
- en: Getting ready
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The following is the input to the function defined in the recipe Creating the
    second convolution layer, `flatten_conv_layer`:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是食谱《创建第二个卷积层》中定义的函数输入，`flatten_conv_layer`：
- en: '`Layer`: This is the output of the second convolution layer, `layer_conv2`'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Layer`：这是第二个卷积层的输出，`layer_conv2`'
- en: How to do it...
  id: totrans-221
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作方法...
- en: 'Run the `flatten_conv_layer` function with the preceding input parameter:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前述输入参数运行`flatten_conv_layer`函数：
- en: '[PRE32]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Extract the flattened layer:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取展平层：
- en: '[PRE33]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Extract the number of (input) features generated for each image:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取每个图像生成的（输入）特征数量：
- en: '[PRE34]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: How it works...
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Prior to connecting the output of the (second) convolution layer with a fully
    connected network, in step 1, we reshape the four-dimensional convolution layer
    into a two-dimensional tensor. The first dimension (?) represents any number of
    input images (as rows) and the second dimension represents the flattened vector
    of features generated for each image of length 4,096; that is, 8 x 8 x 64 (as
    columns). Steps 2 and 3 validate the dimensions of the reshaped layers and input
    features.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在将（第二）卷积层的输出与全连接网络连接之前，在第1步中，我们将四维卷积层重塑为二维张量。第一维（?）表示任意数量的输入图像（作为行），第二维表示为每个图像生成的展平特征向量，长度为4,096；即8
    x 8 x 64（作为列）。第2步和第3步验证重塑后层和输入特征的维度。
- en: Creating the first fully connected layer
  id: totrans-230
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建第一个全连接层
- en: In this recipe, let's create the first fully connected layer.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将创建第一个全连接层。
- en: Getting ready
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'The following are the inputs to the function defined in the recipe *Using functions
    to flatten the densely connected layer*, `create_fc_layer`:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是食谱《使用函数展平密集连接层》中定义的函数输入，`create_fc_layer`：
- en: '`Input`: This is the flattened convolution layer; that is, `layer_flat`'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Input`：这是展平后的卷积层；即`layer_flat`'
- en: '`Num_inputs`: This is the number of features created post flattening, `num_features`'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Num_inputs`：这是在展平之后生成的特征数量，`num_features`'
- en: '`Num_outputs`: This is the number of fully connected neurons output, `fc_size`'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Num_outputs`：这是全连接神经元的输出数量，`fc_size`'
- en: '`Use_relu`: This is the binary flag set to `TRUE` to incorporate non-linearity
    in the tensor'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Use_relu`：这是一个二进制标志，设置为 `TRUE` 以在张量中引入非线性'
- en: How to do it...
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Run the `create_fc_layer` function with the preceding input parameters:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前面的输入参数运行 `create_fc_layer` 函数：
- en: '[PRE35]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: How it works...
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Here, we create a fully connected layer that returns a two-dimensional tensor.
    The first dimension (?) represents any number of (input) images and the second
    dimension represents the number of output neurons (here, 1,024).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们创建一个全连接层，该层返回一个二维张量。第一维（？）表示任意数量的（输入）图像，第二维表示输出神经元的数量（这里是 1,024）。
- en: Applying dropout to the first fully connected layer
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 dropout 应用到第一个全连接层
- en: In this recipe, let's apply dropout to the output of the fully connected layer
    to reduce the chance of overfitting. The dropout step involves removing some neurons
    randomly during the learning process.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将应用 dropout 到全连接层的输出，以减少过拟合的可能性。dropout 步骤包括在学习过程中随机去除一些神经元。
- en: Getting ready
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: The dropout is connected to the output of the layer. Thus, model initial structure
    is set up and loaded. For example, in dropout current layer `layer_fc1` is defined,
    on which dropout is applied.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: dropout 连接到层的输出。因此，模型的初始结构已设置并加载。例如，在 dropout 当前层 `layer_fc1` 中定义了 dropout 并应用于此层。
- en: How to do it...
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Create a placeholder for dropout that can take probability as an input:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个占位符用于 dropout，可以接收概率作为输入：
- en: '[PRE36]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Use TensorFlow''s dropout function to handle the scaling and masking of neuron
    outputs:'
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 的 dropout 函数来处理神经元输出的缩放和屏蔽：
- en: '[PRE37]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: How it works...
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In steps 1 and 2, we can drop (or mask) out the output neurons based on the
    input probability (or percentage). The dropout is generally allowed during training
    and can be turned off (by assigning probability as `1` or `NULL`) during testing.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 1 和步骤 2 中，我们可以根据输入的概率（或百分比）丢弃（或屏蔽）输出神经元。dropout 通常在训练期间允许，并且在测试期间可以关闭（通过将概率设置为
    `1` 或 `NULL`）。
- en: Creating the second fully connected layer with dropout
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建第二个全连接层并加入 dropout
- en: In this recipe, let's create the second fully connected layer along with dropout.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将创建第二个全连接层并加入 dropout。
- en: Getting ready
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'The following are the inputs to the function defined in the recipe *Using functions
    to flatten the densely connected layer*, `create_fc_layer`:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是函数 *使用函数来展开全连接层* 中定义的输入参数，`create_fc_layer`：
- en: '`Input`: This is the output of the first fully connected layer; that is, `layer_fc1`'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Input`：这是第一个全连接层的输出，即 `layer_fc1`'
- en: '`Num_inputs`: This is the number of features in the output of the first fully
    connected layer, `fc_size`'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Num_inputs`：这是第一个全连接层输出的特征数量，`fc_size`'
- en: '`Num_outputs`: This is the number of the fully connected neurons output (equal
    to the number of labels, `num_classes` )'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Num_outputs`：这是全连接神经元输出的数量（等于标签的数量，`num_classes`）'
- en: '`Use_relu`: This is the binary flag set to `FALSE`'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Use_relu`：这是一个二进制标志，设置为 `FALSE`'
- en: How to do it...
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Run the `create_fc_layer` function with the preceding input parameters:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前面的输入参数运行 `create_fc_layer` 函数：
- en: '[PRE38]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Use TensorFlow''s dropout function to handle the scaling and masking of neuron
    outputs:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 的 dropout 函数来处理神经元输出的缩放和屏蔽：
- en: '[PRE39]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: How it works...
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In step 1, we create a fully connected layer that returns a two-dimensional
    tensor. The first dimension (?) represents any number of (input) images and the
    second dimension represents the number of output neurons (here, 10 class labels).
    In step 2, we provide the option for dropout primarily used during the training
    of the network.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 1 中，我们创建一个全连接层，返回一个二维张量。第一维（？）表示任意数量的（输入）图像，第二维表示输出神经元的数量（这里是 10 个类别标签）。在步骤
    2 中，我们提供了一个选项用于 dropout，主要在网络训练过程中使用。
- en: Applying softmax activation to obtain a predicted class
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用 softmax 激活函数来获得预测类别
- en: In this recipe, we will normalize the outputs of the second fully connected
    layer using softmax activation such that each class has a (probability) value
    restricted between 0 and 1, and all the values across 10 classes add up to 1.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在本食谱中，我们将使用 softmax 激活函数规范化第二个全连接层的输出，使得每个类别的（概率）值限制在 0 和 1 之间，且所有 10 个类别的值加起来为
    1。
- en: Getting ready
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备就绪
- en: The activation function is applied at the end of the pipeline on predictions
    generated by the deep learning model. Before executing this step, all steps in
    the pipeline need to be executed. The recipe requires the TensorFlow library.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数应用于深度学习模型生成的预测结果的管道末端。在执行此步骤之前，管道中的所有步骤需要执行完毕。该配方需要 TensorFlow 库。
- en: How to do it...
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Run the `softmax` activation function on the output of the second fully connected
    layer:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二个全连接层的输出上运行 `softmax` 激活函数：
- en: '[PRE40]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Use the `argmax` function to determine the class number of the label. It is
    the index of the class with the largest (probability) value:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `argmax` 函数确定标签的类别编号。它是具有最大（概率）值的类别的索引：
- en: '[PRE41]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Defining the cost function used for optimization
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义用于优化的损失函数
- en: The cost function is primarily used to evaluate the current performance of the
    model by comparing the true class labels (`y_true_cls`) with the predicted class
    labels (`y_pred_cls`). Based on the current performance, the optimizer then fine-tunes
    the network parameters, such as weights and biases, to further improve its performance.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数主要用于通过将真实类别标签（`y_true_cls`）与预测类别标签（`y_pred_cls`）进行比较，评估模型的当前性能。基于当前的性能，优化器会进一步调整网络参数，例如权重和偏置，从而提升模型的性能。
- en: Getting ready
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 做好准备
- en: The cost function definition is critical as it will decide optimization criteria.
    The cost function definition will require true classes and predicted classes to
    do comparison. The objective function used in this recipe is cross entropy, used
    in multi-classification problems.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数的定义至关重要，因为它决定了优化的标准。损失函数定义需要真实类别和预测类别进行比较。本例中使用的目标函数是交叉熵，适用于多分类问题。
- en: How to do it...
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Evaluate the current performance of each image using the cross entropy function
    in TensorFlow. As the cross entropy function in TensorFlow internally applies
    softmax normalization, we provide the output of the fully connected layer post
    dropout (`layer_fc2_drop`) as an input along with true labels (`y_true`):'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用交叉熵函数在 TensorFlow 中评估每张图像的当前性能。由于 TensorFlow 中的交叉熵函数内部应用了 softmax 正则化，我们将全连接层丢弃后的输出（`layer_fc2_drop`）与真实标签（`y_true`）一起作为输入：
- en: '[PRE42]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: In the current cost function, softmax activation function is embedded thus the
    activation function is not required to be defined separately.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前的损失函数中，softmax 激活函数已经嵌入，因此不需要单独定义激活函数。
- en: 'Calculate the average of the cross entropy, which needs to be minimized using
    an optimizer:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算交叉熵的平均值，并使用优化器将其最小化：
- en: '[PRE43]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: How it works...
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In step 1, we define a cross entropy to evaluate the performance of classification.
    Based on the exact match between the true and predicted labels, the cross entropy
    function returns a value that is positive and follows a continuous distribution.
    As zero cross entropy ensures a full match, optimizers tend to minimize the cross
    entropy toward the value zero by updating the network parameters such as weights
    and biases. The cross entropy function returns a value for each individual image
    that needs to be further compressed into a single scalar value, which can be used
    in an optimizer. Hence, in step 2, we calculate a simple average of the cross
    entropy output and store it as *cost*.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤 1 中，我们定义了一个交叉熵函数来评估分类的性能。根据真实标签和预测标签之间的准确匹配，交叉熵函数返回一个正值，并遵循连续分布。因为零交叉熵确保完全匹配，优化器通常通过更新网络参数（如权重和偏置）将交叉熵最小化至零。交叉熵函数为每个单独的图像返回一个值，该值需要进一步压缩成一个标量值，供优化器使用。因此，在步骤
    2 中，我们计算交叉熵输出的简单平均值，并将其存储为 *cost*。
- en: Performing gradient descent cost optimization
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行梯度下降成本优化
- en: In this recipe, let's define an optimizer that can minimize the cost. Post optimization,
    check for CNN performance.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在本例中，我们定义一个能够最小化成本的优化器。优化后，检查 CNN 的性能。
- en: Getting ready
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 做好准备
- en: The optimizer definition will require the `cost` recipe to be defined as it
    goes as input to the optimizer.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 优化器定义需要定义 `cost` 配方，因为它作为输入传递给优化器。
- en: How to do it...
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Run an Adam optimizer with the objective of minimizing the cost for a given
    `learning_rate`:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用目标是最小化给定 `learning_rate` 的成本的 Adam 优化器：
- en: '[PRE44]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Extract the number of `correct_predictions` and calculate the mean percentage
    accuracy:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取 `correct_predictions` 的数量，并计算平均准确率：
- en: '[PRE45]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Executing the graph in a TensorFlow session
  id: totrans-299
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 TensorFlow 会话中执行图
- en: Until now, we have only created tensor objects and added them to a TensorFlow
    graph for later execution. In this recipe, we will learn how to create a TensorFlow
    session that can be used to execute (or run) the TensorFlow graph.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只创建了张量对象并将它们添加到TensorFlow图中以供后续执行。在这个例子中，我们将学习如何创建一个可以用来执行（或运行）TensorFlow图的TensorFlow会话。
- en: Getting ready
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: Before we run the graph, we should have TensorFlow installed and loaded in R.
    The installation details can be found in [Chapter 1](part0021.html#K0RQ1-a0a93989f17f4d6cb68b8cfd331bc5ab),
    *Getting Started*.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行图之前，我们应该已经在R中安装并加载了TensorFlow。安装详细信息可以在[第1章](part0021.html#K0RQ1-a0a93989f17f4d6cb68b8cfd331bc5ab)中找到，*入门*。
- en: How to do it...
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Load the `tensorflow` library and import the `numpy` package:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载`tensorflow`库并导入`numpy`包：
- en: '[PRE46]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Reset or remove any existing `default_graph`:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重置或移除任何现有的`default_graph`：
- en: '[PRE47]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Start an `InteractiveSession`:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动`InteractiveSession`：
- en: '[PRE48]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Initialize the `global_variables`:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化`global_variables`：
- en: '[PRE49]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Run iterations to perform optimization (`training`):'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行迭代以执行优化（`training`）：
- en: '[PRE50]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Evaluate the performance of the trained model on test data:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估训练模型在测试数据上的表现：
- en: '[PRE51]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: How it works...
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Steps 1 through 4 are, in a way, the default way to launch a new TensorFlow
    session. In step 4, the variables of weights and biases are initialized, which
    is mandatory before their optimization. Step 5 is primarily to execute the TensorFlow
    session for optimization. As we have a large number of training images, it becomes
    highly difficult (computationally) to calculate the optimum gradient taking all
    the images at once into the optimizer.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 步骤1至4在某种程度上是启动一个新TensorFlow会话的默认方式。在第4步中，权重和偏置的变量会被初始化，这是它们优化之前的必要步骤。第5步主要是执行TensorFlow会话进行优化。由于我们有大量的训练图像，计算所有图像的最优梯度变得非常困难（计算上）。
- en: Hence, a small random sample of 128 images is selected to train the activation
    layer (weights and biases) in each iteration. In the current setup, we run 100
    iterations and report training accuracy for every tenth iteration.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，每次迭代时，选择128张小的随机样本来训练激活层（权重和偏置）。在当前设置中，我们运行100次迭代，并在每十次迭代后报告训练准确度。
- en: However, these can be increased based on the cluster configuration or computational
    power (CPU or GPU) to obtain higher model accuracy. In addition, a 50% dropout
    rate is used to train the CNN in each iteration. In step 6, we can evaluate the
    performance of the trained model on a test data of 10,000 images.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些值可以根据集群配置或计算能力（CPU或GPU）增加，以提高模型准确性。此外，每次迭代使用50%的dropout率来训练CNN。在第6步中，我们可以评估训练模型在10,000张测试图像上的表现。
- en: Evaluating the performance on test data
  id: totrans-320
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在测试数据上的性能评估
- en: In this recipe, we will look into the performance of the trained CNN on test
    images using a confusion matrix and plots.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用混淆矩阵和图表来查看训练后的CNN在测试图像上的表现。
- en: Getting ready
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备工作
- en: The prerequisite packages for plots are `imager` and `ggplot2`.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 绘图的先决条件包是`imager`和`ggplot2`。
- en: How to do it...
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'Get the `actual` or `true` class labels of test images:'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取测试图像的`实际`或`真实`类别标签：
- en: '[PRE52]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Get the predicted class labels of test images. Remember to add `1` to each
    class label, as the starting index of TensorFlow (the same as Python) is 0 and
    that of R is `1`:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取测试图像的预测类别标签。记得给每个类别标签加`1`，因为TensorFlow（与Python相同）的起始索引是0，而R是`1`：
- en: '[PRE53]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Generate the confusion matrix with rows as true labels and columns as predicted
    labels:'
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成混淆矩阵，行是实际标签，列是预测标签：
- en: '[PRE54]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Generate a plot of the `confusion` matrix:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成`confusion`矩阵的图：
- en: '[PRE55]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Run a helper function to plot images:'
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行一个辅助函数来绘制图像：
- en: '[PRE56]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Plot random misclassified test images:'
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制随机分类错误的测试图像：
- en: '[PRE57]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: How it works...
  id: totrans-337
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: 'In steps 1 through 3, we extract the true and predicted test class labels and
    create a confusion matrix. The following image shows the confusion matrix of the
    current test predictions:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 在步骤1至3中，我们提取了真实的和预测的测试类别标签，并创建了混淆矩阵。下图展示了当前测试预测的混淆矩阵：
- en: '![](img/00046.gif)'
  id: totrans-339
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00046.gif)'
- en: The test accuracy post 700 training iterations is only ~51% and can be further
    improved by increasing the number of iterations, increasing the batch size, configuring
    layer parameters such as the number of convolution layers (used 2), types of activation
    functions (used ReLU), number of fully connected layers (used two), optimization
    objective function (used accuracy), pooling (used max 2 x 2), dropout probability,
    and many others.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 700 次训练迭代后的测试准确率仅为约 51%，可以通过增加迭代次数、增加批量大小、配置层参数（使用了 2 个卷积层）、激活函数类型（使用了 ReLU）、全连接层数量（使用了两个）、优化目标函数（使用了准确率）、池化（使用了最大
    2 x 2）、丢弃概率等进一步提高。
- en: 'Step 4 is used to build a facet plot of the test confusion matrix, as shown
    in the following screenshot:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 第 4 步用于构建测试混淆矩阵的分面图，如下面的截图所示：
- en: '![](img/00048.jpeg)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00048.jpeg)'
- en: In step 5, we define a helper function to plot the image along with a header
    containing both true and predicted classes. The input parameters of the `check.image`
    function are (`test`) flattened input dataset (`images.rgb`), image number (`index`),
    true label (`true_lab`*),* and predicted label (`pred_lab`). Here, the red, green,
    and blue pixels are initially parsed out, converted into a matrix, appended as
    a list, and displayed as an image using the *plot* function.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 5 步中，我们定义了一个辅助函数来绘制图像，标题中包含真实类和预测类。`check.image` 函数的输入参数是（`test`）扁平化输入数据集（`images.rgb`）、图像编号（`index`）、真实标签（`true_lab`*）、*和预测标签（`pred_lab`）。这里，红色、绿色和蓝色像素首先被解析出来，转换为矩阵，作为列表附加，并使用
    *plot* 函数显示为图像。
- en: 'In step 6, we plot misclassified test images using the helper function of step
    5\. The input parameters of the `plot.misclass.images` function are (`test`) flattened
    input dataset (`images.rgb`), a vector of true labels (`y_actual`), a vector of
    predicted labels (`y_predicted`), and a vector of unique ordered character labels
    (`labels`). Here, the indices of the misclassified images are obtained and an
    index is randomly selected to generate the plot. The following screenshot shows
    a set of six misclassified images with true and predicted labels:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 6 步中，我们使用第 5 步的辅助函数绘制误分类的测试图像。`plot.misclass.images` 函数的输入参数是（`test`）扁平化输入数据集（`images.rgb`）、真实标签的向量（`y_actual`）、预测标签的向量（`y_predicted`）和唯一有序字符标签的向量（`labels`）。在这里，获取误分类图像的索引，并随机选择一个索引生成绘图。以下截图显示了一组六个误分类图像及其真实和预测标签：
- en: '![](img/00050.jpeg)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00050.jpeg)'
