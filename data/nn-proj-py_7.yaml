- en: Implementing a Facial Recognition System with Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用神经网络实现人脸识别系统
- en: In this chapter, we will implement a facial recognition system using a **Siamese
    neural network**. Such facial recognition systems are prevalent in smartphones
    and other smart security systems in modern buildings and facilities. We will go
    through the theory behind Siamese neural networks, and why facial recognition
    problems are a special class of problems in image recognition, making it difficult
    for a conventional **convolutional neural networks** (**CNNs**) to solve them.
    We will train and implement a robust model that can recognize faces, even when
    the subject has different expressions and when the photo is taken from different
    angles. Finally, we will write our own program that uses the pre-trained neural
    network and a webcam, to authenticate the user sitting in front of the computer.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用**Siamese神经网络**实现人脸识别系统。此类人脸识别系统在智能手机及现代建筑和设施中的其他智能安防系统中广泛应用。我们将探讨Siamese神经网络背后的理论，并解释为什么人脸识别问题是图像识别中的一个特殊类别问题，使得传统的**卷积神经网络**（**CNNs**）难以解决。我们将训练并实现一个强大的模型，它能够识别面部，即使被识别对象的表情不同，或者照片拍摄角度不同。最后，我们将编写自己的程序，利用预训练的神经网络和网络摄像头来验证坐在电脑前的用户身份。
- en: 'Specifically, these are the topics that we will cover in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖的具体主题包括：
- en: The facial recognition problem
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸识别问题
- en: Face detection and face recognition
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸检测与人脸识别
- en: One-shot learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一次学习
- en: Siamese neural networks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Siamese神经网络
- en: Contrastive loss
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对比损失
- en: Faces dataset
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人脸数据集
- en: Training a Siamese neural network in Keras
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Keras中训练Siamese神经网络
- en: Creating your own facial recognition system
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建你自己的面部识别系统
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following Python libraries are required for this chapter:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章所需的Python库如下：
- en: Numpy 1.15.2
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Numpy 1.15.2
- en: Keras 2.2.4
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras 2.2.4
- en: OpenCV 3.4.2
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenCV 3.4.2
- en: PIL 5.4.1
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PIL 5.4.1
- en: The code for this chapter can be found in the GitHub repository for this book
    at [https://github.com/PacktPublishing/Neural-Network-Projects-with-Python/tree/master/Chapter07](https://github.com/PacktPublishing/Neural-Network-Projects-with-Python/tree/master/chapter7).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在本书的GitHub仓库中找到：[https://github.com/PacktPublishing/Neural-Network-Projects-with-Python/tree/master/Chapter07](https://github.com/PacktPublishing/Neural-Network-Projects-with-Python/tree/master/chapter7)
- en: 'To download the code onto your computer, you may run the following `git clone`
    command:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要将代码下载到你的计算机，可以运行以下`git clone`命令：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After the process is complete, there will be a folder entitled `Neural-Network-Projects-with-Python`.
    Enter the folder by running the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 完成流程后，会生成一个名为`Neural-Network-Projects-with-Python`的文件夹。通过运行以下命令进入该文件夹：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To install the required Python libraries in a virtual environment, run the
    following command:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要在虚拟环境中安装所需的Python库，请运行以下命令：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that you should have installed Anaconda on your computer first before
    running this command. To enter the virtual environment, run the following command:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在运行此命令之前，你应该先在计算机上安装Anaconda。要进入虚拟环境，请运行以下命令：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Navigate to the `Chapter07` folder by running the following command:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下命令，导航到`Chapter07`文件夹：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following files are located in the folder:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 文件夹中包含以下文件：
- en: '`face_detection.py` contains the Python code for face detection using OpenCV'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`face_detection.py`包含使用OpenCV进行人脸检测的Python代码'
- en: '`siamese_nn.py` contains the Python code to create and train a Siamese neural
    network'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`siamese_nn.py`包含创建和训练Siamese神经网络的Python代码'
- en: '`onboarding.py` contains the Python code for the onboarding process of the
    face recognition system'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`onboarding.py`包含人脸识别系统入职流程的Python代码'
- en: '`face_recognition_system.py` contains the complete face recognition system
    program'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`face_recognition_system.py`包含完整的人脸识别系统程序'
- en: 'Please run the Python files in this order:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 请按以下顺序运行Python文件：
- en: '`siamese_nn.py`: To train a Siamese neural network for face recognition'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`siamese_nn.py`：训练用于人脸识别的Siamese神经网络'
- en: '`onboarding.py`: To start the onboarding process for the face recognition system'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`onboarding.py`：启动人脸识别系统的入职流程'
- en: '`face_recognition_system.py`: The actual face recognition program that uses
    your webcam'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`face_recognition_system.py`：使用你的网络摄像头的实际人脸识别程序'
- en: 'To run each Python file, simply execute the files as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行每个Python文件，只需按以下方式执行文件：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Facial recognition systems
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸识别系统
- en: Facial recognition systems have become ubiquitous in our every lives. When the
    iPhone X was first unveiled in 2017, Apple boasted that their new state-of-the-art
    face ID system was able to instantaneously recognize and authenticate users with
    just a single glance. Driving this was the Apple A11 Bionic chip, which includes
    dedicated neural network hardware, allowing the iPhone to perform blazingly fast facial
    recognition and machine learning operations. Today, almost all smartphones have
    a facial recognition security system.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸识别系统已经在我们的日常生活中无处不在。当iPhone X于2017年首次发布时，苹果公司吹嘘其全新的先进面部识别系统能够通过一次简单的凝视立即识别并认证用户。其背后的驱动力是苹果A11仿生芯片，其中包含专门的神经网络硬件，使得iPhone能够快速进行人脸识别和机器学习操作。如今，几乎所有智能手机都配备了人脸识别安全系统。
- en: In 2016, Amazon started its first supermarket with advanced facial recognition
    capabilities, known as **Amazon Go**. Unlike traditional supermarkets, Amazon
    Go uses facial recognition to know when you first arrive at the supermarket and
    when you removed an item from the shelf. When you've finished shopping, you can
    simply walk out of the store, without waiting in line at the cashier, as all your
    purchases are captured by Amazon's AI systems. This allows busy shoppers to do
    their grocery shopping in person at the supermarket, without wasting time waiting
    in line for the cashier. No longer belonging to a dystopian future, facial recognition
    systems have already become an important part of our everyday lives.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 2016年，亚马逊开设了第一家具有先进人脸识别功能的超市，名为**Amazon Go**。与传统超市不同，Amazon Go使用人脸识别来知道你何时进入超市，以及你何时从货架上拿起物品。当你购物结束时，你可以直接走出商店，无需排队结账，因为所有购买的商品都已被亚马逊的AI系统记录。这使得繁忙的购物者能够亲自到超市购物，而无需浪费时间排队等候结账。人脸识别系统不再属于反乌托邦的未来，它们已经成为我们日常生活的重要组成部分。
- en: Breaking down the face recognition problem
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分解人脸识别问题
- en: 'Let''s break down the face recognition problem into smaller steps and subproblems.
    That way, we can better understand what''s going on under the hood of a facial
    recognition system. A face recognition problem can be broken down into the following
    smaller subproblems:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们把人脸识别问题分解成更小的步骤和子问题。这样，我们可以更好地理解人脸识别系统背后发生的事情。人脸识别问题可以分解成以下几个较小的子问题：
- en: '**Face** **detection**: Detect and isolate faces in the image. In an image
    with multiple faces, we need to detect each of them separately. In this step,
    we should also crop the detected faces from the original input image, to identify
    them separately.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人脸** **检测**：在图像中检测并隔离面部。在包含多张面孔的图像中，我们需要分别检测每张面孔。在此步骤中，我们还应从原始输入图像中裁剪出检测到的面孔，以便单独识别。'
- en: '**Face recognition**: For each detected face in the image, we run it through
    a neural network to classify the subject. Note that we need to repeat this step
    for each detected face.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人脸识别**：对于图像中每一张被检测到的面孔，我们将通过神经网络对其进行分类。请注意，我们需要对每一张被检测到的面孔重复此步骤。'
- en: Intuitively, this process makes a lot of sense. If we think of how humans recognize
    faces, we see that it is very similar to the process that we described. Given
    an image, our eyes immediately zoom into each face (face detection), and we recognize
    the faces individually (face recognition).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，这个过程非常有道理。如果我们思考人类如何识别人脸，我们会发现它与我们所描述的过程非常相似。给定一张图像，我们的眼睛立即会集中到每张面孔（人脸检测），然后我们会单独识别每一张面孔（人脸识别）。
- en: 'The following diagram illustrates the subprocesses in face recognition:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 下图说明了人脸识别中的子过程：
- en: '![](img/3d23ef1b-ff8d-41bd-bae8-09ae292d5ab1.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d23ef1b-ff8d-41bd-bae8-09ae292d5ab1.png)'
- en: Face detection
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸检测
- en: First of all, let's take a look at face detection. The face detection problem
    is actually a rather interesting problem in computer vision that researchers have
    worked on for many years. In 2001, Viola and Jones demonstrated how real-time,
    large-scale face detection can be done with minimal computational resources. This
    was a significant discovery at the time, as researchers seek to do real-time,
    large-scale face detection (for example, to monitor a large crowd in real-time).
    Today, face detection algorithms can be run on simple hardware such as our personal
    computers with just a few lines of code. In fact, as we shall see shortly, we
    will use OpenCV in Python to construct a face detector, using your own webcam.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们来看看人脸检测。人脸检测问题实际上是计算机视觉中的一个相当有趣的问题，研究人员在这方面工作了很多年。2001年，Viola 和 Jones
    演示了如何在最小计算资源下进行实时、大规模的人脸检测。这在当时是一个重要的发现，因为研究人员希望实现实时、大规模的人脸检测（例如，实时监控大规模人群）。今天，人脸检测算法可以在简单的硬件上运行，例如我们的个人计算机，只需几行代码。事实上，正如我们很快会看到的，我们将使用
    Python 中的 OpenCV 来构建一个人脸检测器，利用你自己的摄像头。
- en: 'There are several approaches to face detection, including the following:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸检测有多种方法，包含以下几种：
- en: Haar Cascades
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haar 级联
- en: Eigenfaces
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征脸
- en: '**Histogram of Oriented Gradients** (**HOG**)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**方向梯度直方图**（**HOG**）'
- en: We'll explain how to do face detection using Haar Cascades (as presented by
    Viola and Jones in 2001), and we'll see the beautiful simplicity in this algorithm.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将解释如何使用 Haar 级联进行人脸检测（由 Viola 和 Jones 在 2001 年提出），并且我们将看到该算法的优美简洁。
- en: 'The key idea behind the Viola-Jones algorithm is that all human faces share
    certain properties, such as the following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Viola-Jones 算法的核心思想是所有人类面部都有一些共同的特征，例如以下几点：
- en: The area of the eye is darker than the forehead and the cheeks
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 眼睛区域比额头和面颊区域更暗
- en: The area of the nose is brighter than the eyes
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鼻子区域比眼睛区域更亮
- en: 'In a frontal, non-occluded image of a human face, we can see features such
    as the eyes, the nose, and the lips. If we look closely at the area around the
    eyes, we see that there is a repeating pattern of dark and light pixels, as shown
    in the following diagram:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在正面、无遮挡的人脸图像中，我们可以看到如眼睛、鼻子和嘴巴等特征。如果我们仔细观察眼睛周围的区域，会发现有一种交替出现的明暗像素模式，如下图所示：
- en: '![](img/8a57d1f7-b0b9-472f-b431-4c0ef7dfa433.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8a57d1f7-b0b9-472f-b431-4c0ef7dfa433.png)'
- en: 'Of course, the preceding example is just one possible feature. We can also
    construct other features that capture other regions of the face, such as the nose,
    lips, chin, and so on. Some examples of other features are shown in the following
    diagram:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，前面的例子只是其中一种可能的特征。我们还可以构建其他特征来捕捉面部的其他区域，如鼻子、嘴巴、下巴等。以下图示展示了其他特征的一些例子：
- en: '![](img/e1edeb53-95bc-4219-b485-cedd8bd3b55a.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e1edeb53-95bc-4219-b485-cedd8bd3b55a.png)'
- en: These features with alternating regions of dark and light pixels are known as
    Haar features. Depending on your imagination, you can construct an almost infinite
    number of features. In fact, in the final algorithm presented by Viola and Jones,
    there were more than 6,000 Haar features used!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这些具有交替明暗像素区域的特征被称为 Haar 特征。根据你的想象力，你可以构建几乎无限数量的特征。事实上，在 Viola 和 Jones 提出的最终算法中，使用了超过
    6000 个 Haar 特征！
- en: 'Do you see the similarities between Haar features and convolutional filters?
    They both detect identifying geometric representations in images! The difference
    is that Haar features are handcrafted features that detect eyes, noses, lips,
    and so on, in human faces, based on what we know. On the other hand, convolutional
    filters are created during training, using a labeled dataset and are not handcrafted.
    However, they perform the same function: identifying geometric representation
    in images. The similarities between Haar features and convolutional filters show
    that many ideas in machine learning and AI are shared and improved iteratively
    over the years.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 你能看到 Haar 特征和卷积滤波器之间的相似之处吗？它们都在图像中检测出识别的几何表示！不同之处在于 Haar 特征是根据我们已知的知识手工制作的特征，能检测出眼睛、鼻子、嘴巴等面部特征。而卷积滤波器则是在训练过程中生成的，使用带标签的数据集，且不是手工制作的。然而，它们执行的是相同的功能：识别图像中的几何表示。Haar
    特征和卷积滤波器之间的相似性表明，机器学习和人工智能中的许多想法是共享的，并且多年来不断迭代改进。
- en: To use the Haar features, we slide them over every region in the image and compute
    the similarity of the pixels with the Haar features. However, since most areas
    in an image do not contain a face (think about the photos we take—faces are usually
    limited to a small area in the photo), it is computationally wasteful to test
    all the features. To overcome this, Viola and Jones introduced a cascade classifier**.**
    The idea is to start with the most simple Haar feature. If the candidate region
    fails, this simple Haar feature (that is, the prediction from this feature is
    that the region does not contain a face), we immediately move on to the next candidate
    region. This way, we do not waste computational resources on regions that do not
    contain a face. We progressively move on to more complex Haar features, and we
    repeat the process. Eventually, the regions in the image with a face are the regions
    that pass all the Haar features. This classifier is known as a **cascade classifier**.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 Haar 特征，我们将其滑动到图像中的每个区域，并计算该区域像素与 Haar 特征的相似度。然而，由于图像中的大多数区域并不包含人脸（想一想我们拍摄的照片——人脸通常只占照片中的一小部分区域），因此测试所有特征是计算上浪费的。为了解决这个问题，Viola
    和 Jones 引入了级联分类器**。**其思路是从最简单的 Haar 特征开始。如果候选区域失败，即该特征预测该区域不包含人脸，我们立即跳到下一个候选区域。这样，我们就不会把计算资源浪费在那些不包含人脸的区域。我们逐步使用更复杂的
    Haar 特征，重复这一过程。最终，图像中包含人脸的区域会通过所有 Haar 特征的测试。这个分类器被称为**级联分类器**。
- en: The Viola-Jones algorithm using Haar features demonstrated remarkable accuracy
    and false positive rates in face detection, while being computationally efficient.
    In fact, when the algorithm was first presented in 2001, it was running on a 700
    Mhz Pentium III processor!
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Haar 特征的 Viola-Jones 算法在人脸检测中展现出了显著的准确性和较低的假阳性率，同时计算效率也很高。事实上，当该算法在 2001
    年首次提出时，它是在一个 700 MHz 的奔腾 III 处理器上运行的！
- en: Face detection in Python
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 中的人脸检测
- en: Face detection can be implemented by the OpenCV library in Python. OpenCV is
    an open source computer vision library for computer vision tasks. Let's see how
    we can use OpenCV for face detection.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸检测可以通过 Python 中的 OpenCV 库实现。OpenCV 是一个开源计算机视觉库，适用于计算机视觉任务。让我们来看看如何使用 OpenCV
    进行人脸检测。
- en: 'First, we import OpenCV:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入 OpenCV：
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, let''s load a pre-trained cascade classifier for face detection. This
    cascade classifier can be found in the accompanying GitHub repository and should
    have been downloaded to your computer (refer to the *Technical requirements *section):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们加载一个预训练的级联分类器用于人脸检测。这个级联分类器可以在随附的 GitHub 仓库中找到，并应已下载到你的计算机上（请参考*技术要求*部分）：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next, we define a function that takes in an image, performs face detection
    on the image, and draws a bounding box around the image:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个函数，该函数接收一张图像，对图像进行人脸检测，并在图像上绘制一个边框：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let''s test our face detector on some sample images. The images can be found
    in the `''sample_faces''` folder, and they look like this:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一些示例图像上测试我们的人脸检测器。这些图像可以在 `'sample_faces'` 文件夹中找到，它们看起来是这样的：
- en: '![](img/6f9b5a39-b84c-4350-9e3a-4bfe7cee3bbc.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f9b5a39-b84c-4350-9e3a-4bfe7cee3bbc.png)'
- en: As we can see, there is a fair amount of noise (that is, non-face structures)
    in each image, which can potentially trip up our face detector. In the bottom-right
    image, we can also see that there are multiple faces.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，每张图像中都有相当多的噪声（即非人脸结构），这些噪声可能会影响我们的人脸检测器。在右下角的图像中，我们还可以看到多个面孔。
- en: 'We apply the `detect_faces` function that we defined earlier on these images:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用之前定义的 `detect_faces` 函数对这些图像进行处理：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We see the following output images saved in the `''sample_faces/detected_faces''` folder:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到以下输出图像被保存在 `'sample_faces/detected_faces'` 文件夹中：
- en: '![](img/75737513-8a3e-4437-8c8a-d6441259c7d9.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/75737513-8a3e-4437-8c8a-d6441259c7d9.png)'
- en: Fantastic! Our face detector passed with flying colors. The speed of the detection
    was really impressive as well. We can see that face detection using OpenCV in
    Python is simple and takes no time at all.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了！我们的面部检测器表现得非常好。检测速度也令人印象深刻。我们可以看到，使用 OpenCV 在 Python 中进行人脸检测是简单且快速的。
- en: Face recognition
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸识别
- en: 'With face detection complete, let''s turn our attention to the next step: face
    recognition. You might have noticed that face detection had nothing to do with
    neural networks! Face detection using Haar features is an old but reliable algorithm
    that is still widely used today. However, face detection only extracts the region
    that contains a face. Our next step would be to perform face recognition using
    the extracted faces.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 完成人脸检测后，我们将注意力转向下一步：人脸识别。你可能已经注意到，人脸检测与神经网络无关！使用Haar特征的人脸检测是一个古老但可靠的算法，至今仍被广泛使用。然而，人脸检测仅仅是提取包含面部的区域。我们的下一步是使用提取到的人脸进行人脸识别。
- en: Face recognition using neural networks is the main topic in this chapter. For
    the rest of the chapter, we'll focus on training a neural network for face recognition.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要内容是使用神经网络进行人脸识别。接下来的章节，我们将重点讨论如何训练一个神经网络来进行人脸识别。
- en: Requirements of face recognition systems
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸识别系统的要求
- en: At this point, you should be fairly familiar with using neural networks for
    image recognition tasks. In [Chapter 4](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml),
    *Cats Versus Dogs – Image Classification Using CNNs,* we built a CNN for classifying
    images of cats versus dogs. Can the same techniques be used in facial recognition?
    Sadly, CNNs fall short for this task. To understand why, we need to look at the
    requirements of facial recognition systems.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该对使用神经网络进行图像识别任务相当熟悉。在[第4章](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml)，*猫与狗——使用CNN进行图像分类*，我们构建了一个CNN，用于对猫和狗的图像进行分类。那么，相同的技术能否应用于人脸识别呢？遗憾的是，CNN在这一任务上存在不足。为了理解原因，我们需要了解人脸识别系统的要求。
- en: Speed
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 速度
- en: The first requirement of a facial recognition system is that they need to be
    fast. If we look at the onboarding process of the facial recognition systems in
    our smartphones, we usually need to use the front-facing camera in the phone to
    scan our face at various angles for a few seconds. During this short process,
    our phone captures images of our face, and uses an image to train a neural network
    to recognize us. This process needs to be fast.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸识别系统的第一个要求是需要足够快速。如果我们看看智能手机中人脸识别系统的注册过程，通常需要用手机的前置摄像头扫描我们的面部，捕捉不同角度的图像，持续几秒钟。在这个短暂的过程中，手机会捕捉我们的面部图像，并用这些图像来训练神经网络识别我们。这个过程需要足够迅速。
- en: 'The following picture shows the typical onboarding process for a facial recognition
    system in smartphones:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了智能手机中人脸识别系统的典型注册过程：
- en: '![](img/33ca966e-e49a-4837-9f0d-a833047c7a71.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/33ca966e-e49a-4837-9f0d-a833047c7a71.png)'
- en: Can a CNN satisfy this speed requirement? From the project that we built in
    [Chapter 4](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml), *Cats Versus Dogs – Image
    Classification Using CNNs,* we saw how slow it is to train a CNN to identify images
    of cats and dogs. Even with powerful GPUs, training a CNN can sometimes take hours
    (or even days!). From a user experience point of view, it is not practical for
    the onboarding process of facial recognition systems to take this long. Therefore,
    CNNs do not satisfy the speed requirement of facial recognition systems.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: CNN能够满足这一速度要求吗？在[第4章](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml)，*猫与狗——使用CNN进行图像分类*项目中，我们看到训练CNN来识别猫和狗的图像是多么缓慢。即便是使用强大的GPU，训练CNN有时也需要几个小时（甚至几天！）。从用户体验的角度来看，对于人脸识别系统的注册过程来说，这样的速度是不可接受的。因此，CNN无法满足人脸识别系统对速度的要求。
- en: Scalability
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可扩展性
- en: The second requirement of facial recognition systems is that it needs to be
    scalable. The model that we train must ultimately be able to scale to millions
    of different users, each with a unique face. Again, this is where CNNs fall short.
    Recall that in [Chapter 4](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml), *Cats
    Versus Dogs – Image Classification Using CNNs,* we trained a CNN to differentiate
    cats from dogs. This neural network is only able to identify and classify images
    of cats and dogs, and not of other animals, which it was not trained on. This
    means that if we were to use CNNs for facial recognition, we would have to train
    a separate neural network for each individual user. This would simply be unworkable
    from a scalability point of view! This would mean that Amazon would need to train
    an individual neural network for each of its millions of users, and to run through
    millions of different neural networks whenever a user walks through the doors
    of Amazon Go.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸识别系统的第二个要求是其需要具备可扩展性。我们训练的模型最终必须能够扩展到数百万个不同的用户，每个用户都有一个独特的面孔。同样，这就是卷积神经网络（CNN）无法满足的地方。回想一下，在[第4章](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml)中，*猫与狗——使用CNN进行图像分类*，我们训练了一个CNN来区分猫和狗。这个神经网络只能识别和分类猫和狗的图像，不能识别其他动物，因为它没有经过相关训练。这意味着，如果我们使用CNN进行人脸识别，我们必须为每个用户训练一个单独的神经网络。从可扩展性角度来看，这显然是不可行的！这就意味着亚马逊需要为其数百万个用户训练一个独立的神经网络，并且每当用户走进亚马逊Go的门时，都需要运行数百万个不同的神经网络。
- en: 'The following diagram illustrates the constraints faced by CNNs on facial recognition:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示说明了CNN在进行人脸识别时面临的限制：
- en: '![](img/cf156d05-e93d-4747-9587-30b7f6e81ca4.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cf156d05-e93d-4747-9587-30b7f6e81ca4.png)'
- en: Given the constraints in memory, it is impractical to train a neural network
    for every user. Such a system would get bogged down very quickly as the number
    of users grew. Therefore, CNNs fail to provide a scalable solution for facial
    recognition.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于内存的限制，为每个用户训练一个神经网络是不切实际的。随着用户数量的增加，这样的系统会迅速变得无法承载。因此，CNN无法为人脸识别提供可扩展的解决方案。
- en: High accuracy with small data
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小数据高精度
- en: The third requirement of a facial recognition system is that it needs to be
    sufficiently accurate (hence secure) while working with a small amount of training
    data. In [Chapter 4](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml), *Cats Versus
    Dogs – Image Classification Using CNNs,* we used a huge dataset containing thousands
    of images of cats and dogs for training our CNN. By contrast, we almost never
    get this luxury when it comes to the dataset size for facial recognition. Going
    back to the example of the onboarding process for facial recognition in smartphones,
    we can see that only a handful of photos are taken, and we need to be able to
    train our model, using this limited dataset.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸识别系统的第三个要求是，在使用少量训练数据时，它必须具有足够的准确性（因此也具有安全性）。在[第4章](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml)中，*猫与狗——使用CNN进行图像分类*，我们使用了包含成千上万张猫和狗图像的大型数据集来训练我们的CNN。相比之下，在人脸识别的数据集规模上，我们几乎从未享受过这种奢侈的条件。回到智能手机人脸识别的例子，我们可以看到，只拍摄了少数几张照片，而我们必须能够使用这个有限的数据集来训练我们的模型。
- en: Once again, CNNs do not satisfy this requirement, because we need lots of images
    to train a CNN. While CNNs are fairly accurate at image classification tasks,
    this comes at the expense of requiring a huge training set. Imagine having to
    take thousands of selfies with our smartphones before we can start using the facial
    recognition systems in our phones! This would simply not work for most facial
    recognition systems.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，CNN无法满足这一要求，因为我们需要大量图像来训练CNN。虽然CNN在图像分类任务中相当准确，但这也以需要巨大的训练集为代价。试想，如果我们在开始使用手机的人脸识别系统之前，需要用智能手机拍摄成千上万张自拍照！对于大多数人脸识别系统来说，这显然行不通。
- en: One-shot learning
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一次性学习
- en: Given the unique requirements and constraints faced by facial recognition systems,
    it is clear that the paradigm of training a CNN for classification using a huge
    dataset (known as batch learning classification) is unsuitable for the facial
    recognition problem. Instead, our objective is to create a neural network that
    can learn to recognize any face using just a single training sample. This form
    of neural network training is known as **one-shot learning**.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于人脸识别系统所面临的独特需求和限制，很明显，使用大量数据集来训练CNN进行分类的范式（即批量学习分类）不适用于人脸识别问题。相反，我们的目标是创建一个神经网络，它能够通过仅用一个训练样本来学习识别任何面孔。这种神经网络训练形式被称为**一次性学习**。
- en: One-shot learning brings about a new and interesting paradigm in machine learning
    problems. Thus far, we have thought of machine learning problems as mostly classification
    problems. In [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml), *Predicting
    Diabetes, with Multilayer Perceptrons*, we used an MLP to classify patients at
    risk of diabetes. In [Chapter 4](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml),
    *Cats Versus Dogs – Image Classification Using CNNs*,we used a CNN to classify
    images of cats and dogs. In [Chapter 6](21ef7df7-5976-4e0d-bec5-d736ec571d94.xhtml), *Sentiment
    Analysis of Movie Reviews Using LSTM*, we used an LSTM network to classify the
    sentiment of movie reviews. In this chapter, we need to approach facial recognition
    not simply as a classification problem, but also as an estimation of the similarity
    between two input images.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一次性学习带来了机器学习问题中的一种全新且有趣的范式。到目前为止，我们通常将机器学习问题视为分类问题。在[第2章](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml)，*多层感知机预测糖尿病*中，我们使用MLP来分类处于糖尿病风险中的患者。在[第4章](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml)，*猫与狗——使用CNN的图像分类*中，我们使用CNN来分类猫和狗的图像。在[第6章](21ef7df7-5976-4e0d-bec5-d736ec571d94.xhtml)，*使用LSTM进行电影评论情感分析*中，我们使用LSTM网络来分类电影评论的情感。在本章中，我们需要将人脸识别问题视为不仅仅是分类问题，还需要估算两张输入图像之间的相似度。
- en: 'As an example, a one-shot learning facial recognition model should perform
    the following tasks when determining whether the presented face belongs to an
    arbitrary person (say, person A):'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个一次性学习的人脸识别模型在判断给定的面孔是否属于某个特定人物（例如A人物）时，应执行以下任务：
- en: Retrieve the stored image of person A (obtained during the onboarding process).
    This is the *true* image of person A.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取存储的A人物图像（在入职过程中获得的）。这就是A人物的*真实*图像。
- en: At testing time (for example, when someone is is trying to unlock the phone
    of person A), capture the image of the person. This is the *test* image.
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试时（例如，当某人试图解锁A人物的手机时），捕捉该人物的图像。这就是*测试*图像。
- en: Using the *true* photo and the *test* photo, the neural network should output
    a similarity score of the faces in the two photos.
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用*真实*照片和*测试*照片，神经网络应输出两张照片中人脸的相似度评分。
- en: If the similarity score output by the neural network is below a certain threshold
    (that is, the people in the two photos look dissimilar), we deny access, and if
    they are above the threshold, we grant access.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果神经网络输出的相似度评分低于某个阈值（即两张照片中的人看起来不相似），我们将拒绝访问；如果高于阈值，则允许访问。
- en: 'The following diagram illustrates this process:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了这一过程：
- en: '![](img/2dae64c6-aa7e-41f7-90dd-08d55ef122e8.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2dae64c6-aa7e-41f7-90dd-08d55ef122e8.png)'
- en: Naive one-shot prediction – Euclidean distance between two vectors
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 幼稚的一次性预测——两向量之间的欧几里得距离
- en: Before we dive into how neural networks can be used for one-shot learning, let's
    look at one naive approach.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解神经网络如何应用于一次性学习之前，让我们先看一种简单的方式。
- en: 'Given the true image and a test image, one naive approach for a one-shot prediction
    is to simply measure the difference between the two images. As we have already
    seen, all images are simply three-dimensional vectors. We know that the Euclidean
    distance provides a mathematical formulation of the difference between two vectors.
    To refresh your memory, the Euclidean distance between two vectors is shown in
    the following diagram:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 给定真实图像和测试图像，一种简单的一次性预测方法是简单地衡量两张图像之间的差异。正如我们已经看到的，所有图像都是三维向量。我们知道，欧几里得距离提供了两个向量之间差异的数学公式。为了帮助回忆，两个向量之间的欧几里得距离如下图所示：
- en: '![](img/0635d454-58c0-4267-b65c-2eca8083c55d.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0635d454-58c0-4267-b65c-2eca8083c55d.png)'
- en: Measuring the Euclidean distance between two images provides us with a naive
    approach for a one-shot prediction. However, does it provide us with a satisfactory
    similar score for facial recognition? The answer is no. Although the Euclidean
    distance for facial recognition makes sense on paper, it has a poor practical
    value. In reality, photos can be different due to variations in angles and lighting,
    and also changes in the appearance of the subject, which can arise due to the
    wearing of accessories such as glasses. As you can imagine, a facial recognition
    system that uses the Euclidean distance alone would perform terribly in reality.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 测量两张图像之间的欧几里得距离为我们提供了一种简单的单次预测方法。然而，它是否为人脸识别提供了令人满意的相似度评分？答案是否定的。尽管欧几里得距离在人脸识别中理论上有意义，但它的实际价值较低。在现实中，照片可能由于角度和光照的变化以及主体外貌的变化（如佩戴眼镜）而不同。正如你可以想象的那样，仅使用欧几里得距离的人脸识别系统在现实中表现会很差。
- en: Siamese neural networks
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**暹罗神经网络**'
- en: So far, we have seen that a pure CNN and a pure Euclidean distance approach
    would not work well for facial recognition. However, we don't have to discard
    them entirely. Each of them provides something useful for us. Can we combine them
    together to form something better?
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到纯粹的CNN和纯粹的欧几里得距离方法在面部识别中效果不好。然而，我们不必完全舍弃它们。它们各自提供了一些对我们有用的东西。我们能否将它们结合起来，形成更好的方法呢？
- en: Intuitively, humans recognize faces by comparing their key features. For example,
    humans use features such as the shape of the eyes, the thickness of the eyebrows,
    the size of the nose, the overall shape of the face, and so on to recognize a
    person. This ability comes naturally to us, and we are seldom affected by variations
    in angles and lighting. Could we somehow teach a neural network to identify these
    features from images of faces, before using the Euclidean distance to measure
    the similarity between the identified features? This should sound familiar to
    you! As we have seen in the previous chapters, convolutional layers excel in finding
    such identifying features automatically. For facial recognition, researchers have
    found that when convolutional layers are applied to human faces, they extract
    spatial features, such as eyes and noses.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，人类通过比较面部的关键特征来识别人脸。例如，人类会利用眼睛的形状、眉毛的粗细、鼻子的大小、面部的整体轮廓等特征来识别一个人。这种能力对我们来说是自然而然的，我们很少受到角度和光照变化的影响。我们是否可以教会神经网络识别这些特征，从面部图像中提取出来，然后再使用欧几里得距离来衡量识别特征之间的相似度？这应该对你来说不陌生！正如我们在前几章中看到的，卷积层擅长自动寻找这种识别特征。对于人脸识别，研究人员发现，当卷积层应用于人脸时，它们会提取空间特征，如眼睛和鼻子。
- en: 'This insight forms the core of our algorithm for one-shot learning:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这个洞察力构成了我们单次学习算法的核心：
- en: Use convolutional layers to extract identifying features from faces. The output
    from the convolutional layers should be a mapping of the image to a lower-dimension
    feature space (for example, a 128 x 1 vector). The convolutional layers should
    map faces from the same subject close to one another in this lower-dimension feature space
    and vice versa, faces from different subjects should be as far away as possible
    in this lower-dimension feature space.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用卷积层从人脸中提取识别特征。卷积层的输出应该是将图像映射到一个低维特征空间（例如，一个128 x 1的向量）。卷积层应该将同一主体的人脸映射得尽可能靠近，而来自不同主体的人脸则应尽可能远离该低维特征空间。
- en: Using the Euclidean distance, measure the difference of the two lower-dimension
    vectors output from the convolutional layers. Note that there are two vectors,
    because we are comparing two images (the true image and the test image). The Euclidean
    distance is inversely proportional to the similarity between the two images.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用欧几里得距离，测量从卷积层输出的两个低维向量之间的差异。请注意，这里有两个向量，因为我们在比较两张图像（真实图像和测试图像）。欧几里得距离与两张图像之间的相似度成反比。
- en: This works better than the naive Euclidean distance approach from the previous
    section (applied to raw-image pixels), because the output from the convolutional
    layers in the first step represents identifying features in faces (such as eyes
    and noses), which are invariant to angles and lighting.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法比前面章节中提到的简单欧几里得距离方法（应用于原始图像像素）效果更好，因为卷积层在第一步的输出代表了人脸中的识别特征（如眼睛和鼻子），这些特征对于角度和光照是不变的。
- en: One last thing to note is that, since we are feeding two images into our neural
    network simultaneously, we need two separate sets of convolutional layers. However,
    we require the two separate sets of convolutional layers to share the same weights,
    because we want similar faces to be mapped to the same point in the lower-dimension
    feature space. If the weights from the two sets of convolutional layers are different,
    similar faces would be mapped to different points, and the Euclidean distance
    would not be a useful metric at all!
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的最后一点是，由于我们同时将两张图像输入到神经网络中，因此我们需要两组独立的卷积层。然而，我们要求这两组卷积层共享相同的权重，因为我们希望相似的面部图像被映射到低维特征空间中的同一点。如果这两组卷积层的权重不同，那么相似的面部将会被映射到不同的点，而欧氏距离将不再是一个有效的度量！
- en: 'We can thus think of these two sets of convolutional layers as twins, as they
    share the same weights. The following diagram provides an illustration of the
    neural network that we have just described:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以将这两组卷积层视为“孪生”，因为它们共享相同的权重。下面的图示说明了我们刚才描述的神经网络：
- en: '![](img/9450953e-02e9-42d5-a113-5b48fc61ed6e.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9450953e-02e9-42d5-a113-5b48fc61ed6e.png)'
- en: This neural network is known as a Siamese neural network, because just like
    a Siamese twin, it has a conjoined component at the convolutional layers.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这个神经网络被称为孪生神经网络，因为它就像一对连体婴儿，在卷积层部分有一个联合组件。
- en: Contrastive loss
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对比损失
- en: This new paradigm of training a neural network for distance-based predictions
    instead of classification-based predictions requires a new loss function. Recall
    that in previous chapters, we used simple loss functions such as categorical cross-entropy
    to measure the accuracy of our predictions in classification problems.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这种基于距离预测的神经网络训练新范式，不同于基于分类的预测，它需要一种新的损失函数。回想一下，在前面的章节中，我们使用了简单的损失函数，例如类别交叉熵，来衡量分类问题中预测的准确性。
- en: In distance-based predictions, loss functions based on accuracy would not work.
    Therefore, we require a new distance-based loss function to train our Siamese
    neural network for facial recognition. The distance-based loss function that we
    will be using is called the **contrastive loss function**.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于距离的预测中，基于准确率的损失函数是无法工作的。因此，我们需要一种新的基于距离的损失函数来训练我们的孪生神经网络进行面部识别。我们将使用的基于距离的损失函数被称为**对比损失函数**。
- en: 'Take a look at the following variables:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下以下变量：
- en: '*Y[true]*: Let *Y[true]* be *1* if the two input images are from the same subject
    (same face) and 0 if the two input images are from different subjects (different
    faces)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Y[true]*：如果两张输入图像来自同一主题（相同的面部），则让*Y[true]* = *1*；如果两张输入图像来自不同的主题（不同的面部），则让*Y[true]*
    = 0'
- en: '*D*: The predicted distance output from the neural network'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*D*：神经网络输出的预测距离'
- en: 'So, the *Contrastive Loss* is defined as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，*对比损失*定义如下：
- en: '![](img/6be69b84-79e2-48b6-85df-b47688f46533.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6be69b84-79e2-48b6-85df-b47688f46533.png)'
- en: Here, the margin is simply a constant regularizing term. Don't worry if the
    preceding equation looks scary! All it does is simply produce a high loss (that
    is, a penalty) when the predicted distance is large when the faces are similar,
    and a low loss when the predicted distance is small, and vice versa for the case
    when the faces are different.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，margin 只是一个常数正则化项。如果前面的公式看起来很吓人，不用担心！它的作用仅仅是：当预测距离较大且面部相似时，产生较大的损失（即惩罚），而当预测距离较小时产生较小的损失，面部不同的情况则相反。
- en: 'The following graph shows the loss for the increasing predicted distance, when
    the faces are similar (left) and when the faces are different (right):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了当面部相似（左）和面部不同（右）时，随着预测距离增大，损失的变化：
- en: '![](img/d12eef3c-5aa0-4c2b-abe1-b440e44c05f6.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d12eef3c-5aa0-4c2b-abe1-b440e44c05f6.png)'
- en: Simply put, the contrastive loss function ensures that our Siamese neural network
    learns to predict a small distance when the faces in the true and test images
    are the same, and a large distance when the faces in the true and test images
    are different.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，对比损失函数确保我们的孪生神经网络能够在真实图像和测试图像中的面部相同的情况下预测出较小的距离，而在面部不同的情况下预测出较大的距离。
- en: The faces dataset
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面部数据集
- en: Let's now look at the faces dataset that we will be using for this project.
    There are numerous publicly available faces dataset for use, as consolidated at [http://www.face-rec.org/databases/](http://www.face-rec.org/databases/).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下我们将在此项目中使用的面部数据集。网上有许多公开可用的面部数据集，具体内容可以参见[http://www.face-rec.org/databases/](http://www.face-rec.org/databases/)。
- en: While there are many face datasets that we can use, the most appropriate dataset
    for training a facial recognition system should contain photos of different subjects,
    with each subject having multiple photos taken from different angles. It should
    also ideally contain photos of the subject wearing different expressions (eyes
    closed and so on), as such photos are commonly encountered by facial recognition
    systems.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以使用许多面部数据集，但用于训练人脸识别系统的最合适数据集应该包含不同主体的照片，每个主体应有多张从不同角度拍摄的照片。理想情况下，数据集还应包含主体展示不同表情（如闭眼等）的照片，因为人脸识别系统通常会遇到此类照片。
- en: With these considerations in mind, the dataset that we have chosen is the Database
    of Faces, created by AT&T Laboratories, Cambridge. The database contains photos
    of 40 subjects, with 10 photos of each subject. The photos of each subject were
    taken under different lighting and angles, and they have different facial expressions.
    For certain subjects, multiple photos were taken of people with and without glasses.
    You may visit the website at [https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html](https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html) to
    learn more about the AT&T faces dataset.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些因素，我们选择的数据集是由AT&T实验室剑桥分部创建的《面部数据库》。该数据库包含40个主体的照片，每个主体有10张照片。每个主体的照片都在不同的光照和角度下拍摄，并且有不同的面部表情。对于某些主体，还拍摄了戴眼镜和不戴眼镜的多张照片。您可以访问[https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html](https://www.cl.cam.ac.uk/research/dtg/attarchive/facedatabase.html)了解更多有关AT&T面部数据集的信息。
- en: The faces dataset is provided together with the code for this chapter. To download
    the dataset and the code from the GitHub repository, please follow the instructions
    in the *Technical requirements* section earlier in the chapter.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 面部数据集与本章的代码一起提供。要从GitHub仓库下载数据集和代码，请按照本章前面*技术要求*部分中的说明操作。
- en: 'After downloading the GitHub repository, the dataset is located in the following
    path:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 下载GitHub仓库后，数据集位于以下路径：
- en: '[PRE10]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The images are stored in subfolders, with one subfolder per subject. Let''s
    import the raw-image files as NumPy arrays in Python. We start by declaring a
    variable with the file path:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图像存储在子文件夹中，每个子文件夹对应一个主体。让我们将原始图像文件导入为Python中的NumPy数组。我们首先声明一个包含文件路径的变量：
- en: '[PRE11]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Next, we want to iterate through each subfolder in the directory, and load
    each image in the subfolder as a NumPy array. To do that, we can import and use
    the `load_img` and `img_to_array` functions provided in `keras.preprocessing.image`:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们要遍历目录中的每个子文件夹，将每个子文件夹中的图像加载为NumPy数组。为此，我们可以导入并使用`keras.preprocessing.image`中的`load_img`和`img_to_array`函数：
- en: '[PRE12]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Since there are 40 subjects, let''s use images from the first 35 subjects as
    training samples and the remaining five subjects as testing samples. The following
    code iterates through each subfolder and loads the images into an `X_train` and
    an `X_test` array accordingly:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 由于共有40个主体，我们将前35个主体的图像用作训练样本，剩余的5个主体用作测试样本。以下代码会遍历每个子文件夹，并相应地将图像加载到`X_train`和`X_test`数组中：
- en: '[PRE13]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that the label in `Y_train` and `Y_test` is simply the index of the subfolders
    as we iterate through each of them (that is, the subject in the first subfolder
    is assigned label `1`, the subject in the second subfolder is assigned label `2`,
    and so on).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`Y_train`和`Y_test`中的标签仅仅是我们遍历每个子文件夹时的索引（即，第一个子文件夹中的主体被分配标签`1`，第二个子文件夹中的主体被分配标签`2`，依此类推）。
- en: 'Finally, we convert `X_train`, `Y_train`, `X_test`, and `X_test` into NumPy
    arrays:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将`X_train`、`Y_train`、`X_test`和`X_test`转换为NumPy数组：
- en: '[PRE14]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Good! We now have our training-and-testing dataset. We'll train our Siamese
    neural network using the training set and test it using the photos in the testing
    dataset.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 好的！现在我们已经有了训练和测试数据集。我们将使用训练集来训练我们的Siamese神经网络，并使用测试数据集中的照片进行测试。
- en: 'Now, let''s plot out some images from a subject to better understand the kind
    of data we are working with. The following code plots nine of the images from
    a particular subject (as entered in the `subject_idx` variable):'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们绘制出某个主体的一些图像，以更好地了解我们正在处理的数据类型。以下代码绘制了某个特定主体的九张图像（如`subject_idx`变量所示）：
- en: '[PRE15]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We see the following output:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到以下输出：
- en: '![](img/4d27829b-58e4-441a-81f1-c5f82e171b74.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4d27829b-58e4-441a-81f1-c5f82e171b74.png)'
- en: As we can see, each photo of the subject was taken at a different angle, and
    the subject had different facial expressions. In some photos, we can also see
    that the subject removed his glasses. There's certainly a lot of variation from
    image to image.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，每张照片中的主体都是在不同的角度拍摄的，且表情各异。在某些照片中，我们还能看到主体摘掉了眼镜。每张图像之间确实有很多差异。
- en: 'We can also plot a single image from the first nine subjects, using the following
    code:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用以下代码从前九个主题中绘制一张单独的图片：
- en: '[PRE16]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We''ll get the following output:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到以下输出：
- en: '![](img/6b3d9602-0cab-459b-8cc0-ff40b29a1eee.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6b3d9602-0cab-459b-8cc0-ff40b29a1eee.png)'
- en: Cool! It looks as though we have a diverse bunch of subjects to work with.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 很酷！看起来我们有一系列多样的主题可以处理。
- en: Creating a Siamese neural network in Keras
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Keras 中创建孪生神经网络
- en: We are finally ready to start creating a Siamese neural network in Keras. In
    the previous sections, we looked at the theory and the high-level structure of
    a Siamese neural network. Let's now look at the architecture of a Siamese neural
    network in greater detail.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于准备好在 Keras 中开始创建孪生神经网络了。在前面的部分中，我们讨论了孪生神经网络的理论和高层结构。现在，让我们更详细地了解孪生神经网络的架构。
- en: 'The following diagram shows the detailed architecture of the Siamese neural
    network we''ll build in this chapter:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了我们在本章中将构建的孪生神经网络的详细架构：
- en: '![](img/891ea05d-fa4d-468d-b4ce-dd340ae12b13.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](img/891ea05d-fa4d-468d-b4ce-dd340ae12b13.png)'
- en: Let's start by creating the shared convolutional network (boxed in the preceding
    diagram) in Keras. By now, you should be familiar with the **Conv** layer, **Pooling**
    layer, and **Dense** layer. If you need a refresher, feel free to refer to [Chapter
    4](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml), *Cats Versus Dogs – Image Classification** Using
    CNNs,* for their definitions.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从在 Keras 中创建共享的卷积网络（如前面图中的框选部分）开始。到目前为止，你应该已经熟悉了 **Conv** 层、**Pooling** 层和
    **Dense** 层。如果你需要回顾一下，随时可以参考 [第4章](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml)，*猫狗大战——使用
    CNN 进行图像分类*，以获取它们的定义。
- en: 'Let''s define a function that builds this shared convolutional network using
    the `Sequential` class in Keras:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个函数，使用 Keras 中的 `Sequential` 类来构建这个共享卷积网络：
- en: '[PRE17]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We can see that this function creates a convolutional network according to the
    architecture in the preceding diagram. At this point, you might be wondering,
    *how do we actually share weights across two twin networks in Keras?* Well, the
    short answer is that we don't actually need to create two different networks.
    We only need a single instance of the shared network to be declared in Keras.
    We can create the top and bottom convolutional network using this single instance.
    Because we are reusing this single instance, Keras will automatically understand
    that the weights are to be shared.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，这个函数根据前面的架构创建了一个卷积网络。此时，你可能会想，*我们如何在 Keras 中实现两个孪生网络共享权重呢？* 好吧，简短的回答是，我们实际上不需要创建两个不同的网络。我们只需要在
    Keras 中声明一个共享网络的单一实例。我们可以使用这个单一实例来创建上下卷积网络。由于我们重用了这个单一实例，Keras 会自动理解这些权重是要共享的。
- en: 'This is how we can do it. First, let''s create a single instance of the shared
    network, using the function that we defined previously:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们如何做的。首先，让我们使用我们之前定义的函数创建共享网络的单一实例：
- en: '[PRE18]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We specify the input for the top and bottom layers using the `Input` class:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过 `Input` 类指定上下层的输入：
- en: '[PRE19]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Next, we stack the shared network to the right of the input layers, using the
    `functional` method in Keras. The syntax to do this is as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将共享网络堆叠到输入层的右侧，使用 Keras 中的 `functional` 方法。执行此操作的语法如下：
- en: '[PRE20]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Now, this syntax may not be familiar to you, because we have been using the
    more user-friendly `Sequential` method for building models so far. Although it
    is simpler, it tends to lose a bit of flexibility, and there are certain things
    that we cannot do using the `Sequential` method alone, including building such
    a network, as shown. Therefore, we use the `functional` method for building such
    a model.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这种语法可能对你来说比较陌生，因为到目前为止我们一直在使用更为简便的 `Sequential` 方法来构建模型。虽然它较为简单，但它失去了一些灵活性，某些事情是我们仅通过
    `Sequential` 方法无法做到的，包括像这样构建网络。因此，我们使用 `functional` 方法来构建这种模型。
- en: 'At this point, this is what our model looks like:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们的模型看起来是这样的：
- en: '![](img/bdf6cbf4-30c2-4627-b039-9c1d59da7fed.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bdf6cbf4-30c2-4627-b039-9c1d59da7fed.png)'
- en: Great! All that's left is to combine the output from the top and bottom, and
    to measure the Euclidean distance between the two outputs. Remember, the outputs
    from the top and bottom at this point are 128 x 1-dimensional vectors, representing
    the lower-dimensional feature space.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 很好！剩下的就是将顶部和底部的输出组合起来，并计算这两个输出之间的欧几里得距离。记住，此时顶部和底部的输出是128 x 1维向量，表示低维特征空间。
- en: Since there is no layer in Keras that can readily compute the Euclidean distance
    between two arrays, we would have to define our own layer. The `Lambda` layer
    in Keras allows us to do exactly that by wrapping an arbitrary function as a `Layer`
    object.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Keras中没有可以直接计算两个数组之间欧几里得距离的层，因此我们需要定义自己的层。Keras中的`Lambda`层正是允许我们通过将任意函数封装为`Layer`对象来实现这一点。
- en: 'Let''s create a `euclidean_distance` function to compute the Euclidean distance
    between two vectors:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来创建一个`euclidean_distance`函数，用于计算两个向量之间的欧几里得距离：
- en: '[PRE21]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We can then wrap this `euclidean_distance` function inside a `Lambda` layer:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将这个`euclidean_distance`函数封装到一个`Lambda`层中：
- en: '[PRE22]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, we combine the `distance` layer defined in the previous line with
    our inputs to complete our model:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将前一行定义的`distance`层与输入结合起来，完成我们的模型：
- en: '[PRE23]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can verify the structure of our model by calling the `summary()` function:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过调用`summary()`函数来验证模型的结构：
- en: '[PRE24]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We''ll see the following output:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下输出：
- en: '![](img/429b03fb-4924-4bdf-be2a-67bf9469cf3a.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](img/429b03fb-4924-4bdf-be2a-67bf9469cf3a.png)'
- en: If we take a look at the summary in the previous screenshot, we can see that
    there are two input layers in our model, each of 112 x 92 x 1 in shape (because
    our images are 112 x 92 x 1). The two input layers are connected to a single shared
    convolutional network. The two outputs (each a 128-dimensional array) from the
    shared convolutional network are then combined into a `Lambda` layer, which calculates
    the Euclidean distance of the two 128-dimensional arrays. Finally, this Euclidean
    distance is output from our model.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看前一张截图中的摘要，可以看到模型中有两个输入层，每个层的形状为112 x 92 x 1（因为我们的图像是112 x 92 x 1）。这两个输入层连接到一个共享的卷积网络。共享卷积网络的两个输出（每个为128维数组）然后被组合到一个`Lambda`层，该层计算这两个128维数组之间的欧几里得距离。最后，这个欧几里得距离从我们的模型中输出。
- en: That's it! We have successfully created our Siamese neural network. We can see
    that most of the complexity in the network comes from the shared convolutional
    network. With this basic framework in place, we can easily tune and increase the
    complexity of the shared convolutional network as required.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们成功创建了我们的孪生神经网络。我们可以看到，网络中大部分的复杂性来自共享的卷积网络。有了这个基本框架，我们可以根据需要轻松调整和增加共享卷积网络的复杂度。
- en: Model training in Keras
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Keras中的模型训练
- en: Now that we have created our Siamese neural network, we can start to train our
    model. Training a Siamese neural network is slightly different than training a
    regular CNN. Recall that when training a CNN, the training samples are arrays
    of images, along with the corresponding class label for each image. In contrast,
    to train a Siamese neural network we need to use pairs of arrays of images, along
    with the corresponding class label for the pairs of images (that is, 1 if the
    pairs of images are from the same subject, and 0 if the pairs of images are from
    different subjects).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了孪生神经网络，可以开始训练模型了。训练孪生神经网络与训练常规CNN略有不同。回想一下，当训练CNN时，训练样本是图像数组，并且每个图像都有相应的类别标签。相比之下，训练孪生神经网络时，我们需要使用图像对的数组，并且每对图像有相应的类别标签（即，如果图像对来自同一对象，则标签为1；如果图像对来自不同对象，则标签为0）。
- en: 'The following diagram illustrates the differences between training a CNN and
    a Siamese neural network:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了训练CNN和孪生神经网络之间的差异：
- en: '![](img/f9afedd7-4853-4767-8daa-4016628d46fd.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f9afedd7-4853-4767-8daa-4016628d46fd.png)'
- en: So far, we have loaded the raw image into an `X_train` NumPy array, along with
    an array with the `Y_train` class labels. We need to write a function that creates
    these pairs of arrays of images from `X_train` and `Y_train`. An important point
    we need to note is that in the pair of arrays of images, the number of classes
    should be equal (that is, an equal number of positive and negative pairs, where
    *positive* refers to images from the same subject and *negative* refers to images
    from different subjects), and that we should alternate between positive and negative
    pairs. This prevents our model from being biased, and ensures that it learns both
    positive and negative pairs of images equally well.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经将原始图像加载到`X_train` NumPy数组中，并附带了`Y_train`类标签的数组。我们需要编写一个函数，从`X_train`和`Y_train`中创建这些图像数组对。一个需要注意的重要点是，在这对图像数组中，类的数量应该相等（即正负对的数量相同，*正对*指的是来自同一主题的图像，*负对*指的是来自不同主题的图像），并且我们应该交替使用正负对。这可以防止模型产生偏差，并确保它能够同等地学习正负对图像。
- en: 'The following function creates pairs of arrays of images and their labels from
    `X_train` and `Y_train`:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数从`X_train`和`Y_train`创建图像及其标签数组对：
- en: '[PRE25]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: There is one more thing to do before we can start training our model. We need
    to define a function for the contrastive loss, since contrastive loss is not a
    default loss function in Keras.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练模型之前，还有一件事需要做。我们需要为对比损失定义一个函数，因为对比损失不是Keras中的默认损失函数。
- en: 'To recap, this is the formula for *Contrastive Loss*:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，这是*对比损失*的公式：
- en: '![](img/49ca5015-0d84-4574-8003-9bf048113545.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/49ca5015-0d84-4574-8003-9bf048113545.png)'
- en: Where *Y[true]* is the true label of the training pairs and *D* is the predicted
    distance output from the neural network.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*Y[true]*是训练对的真实标签，*D*是神经网络输出的预测距离。
- en: 'We define the following function for calculating the contrastive loss:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为计算对比损失定义了以下函数：
- en: '[PRE26]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Notice that the function includes `K.mean`, `K.square`, and `K.maximum`. These
    are simply Keras's backend functions to simplify array calculations such as the
    mean, max, and square.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，函数中包含了`K.mean`、`K.square`和`K.maximum`。这些只是Keras的后端函数，用于简化数组计算，如均值、最大值和平方。
- en: 'Alright, we have all the necessary functions to train our Siamese neural network.
    As usual, we define the parameters of the training using the `compile` function:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们已经具备了训练我们的孪生神经网络所需的所有函数。像往常一样，我们使用`compile`函数定义训练的参数：
- en: '[PRE27]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'And we train our model for `10` epochs by calling the `fit` function:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们通过调用`fit`函数来训练模型`10`个周期：
- en: '[PRE28]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Once the training is complete, we''ll see the following output:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练完成，我们将看到以下输出：
- en: '![](img/99ea353c-a20b-4b61-b5d5-cbd018a506cd.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](img/99ea353c-a20b-4b61-b5d5-cbd018a506cd.png)'
- en: Analyzing the results
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分析结果
- en: Let's apply our model on the withheld testing set to see how well it does. Remember,
    our model has never seen the images and subjects from the testing set, so this
    is a good measurement of its real-world performance.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在保留的测试集上应用我们的模型，看看它表现如何。记住，我们的模型从未见过测试集中的图像和主题，因此这是衡量其现实世界表现的好方法。
- en: 'First, we pick two images from the same subject, plot them out side by side,
    and apply the model to this pair of images:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们从同一个主题中选择两张图片，将它们并排展示，并将模型应用于这对图片：
- en: '[PRE29]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We''ll see the following output:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下输出：
- en: '![](img/9aa4fab9-05c7-45de-8a3b-aa8d161f195a.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9aa4fab9-05c7-45de-8a3b-aa8d161f195a.png)'
- en: Note that the Dissimilarity Score is just the distance output by the model.
    The greater the distance, the greater the dissimilarity between the two faces.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Dissimilarity Score只是模型输出的距离。距离越大，两个面孔之间的差异越大。
- en: Our model works well! We can clearly see that the subjects in the photos are
    the same. In the first image, the subject is wearing glasses, looking into the
    camera, and smiling. In the second image, the same subject is not wearing glasses,
    not looking into the camera, and not smiling. Our face recognition model is still
    able to recognize that the two faces in this pair of photos belong to the same
    person, as we can see from the low dissimilarity score.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型表现很好！我们可以清楚地看到照片中的主体是相同的。在第一张图片中，主体戴着眼镜，正视镜头并微笑。在第二张图片中，同一主体没有戴眼镜，未正视镜头，也没有微笑。我们的面部识别模型仍然能够识别这对照片中的两张脸属于同一个人，从低相似度得分可以看出这一点。
- en: 'Next, we pick a pair of faces from different subjects and see how well our
    model performs:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们从不同的主题中选择一对面孔，看看我们的模型表现如何：
- en: '[PRE30]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We''ll see the following output:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下输出：
- en: '![](img/48f696f6-7131-4918-be02-aada15c3b4c8.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/48f696f6-7131-4918-be02-aada15c3b4c8.png)'
- en: 'Our model performs well for negative pairs (pairs of images where the subjects
    are different) as well. In this case, the Dissimilarity Score is 1.28\. We know
    that positive pairs have a low dissimilarity score and that negative pairs have
    a high dissimilarity score. But what is the threshold score that separates them?
    Let''s do more tests on positive and negative pairs to find out:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型对于负对（图像中的人物不同的对）表现得也很好。在这种情况下，差异得分是 1.28。我们知道，正对有低差异得分，而负对有高差异得分。但分隔它们的阈值分数是多少呢？让我们对正对和负对做更多的测试来找出答案：
- en: '[PRE31]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The following screenshot shows the results for certain pairs of subjects. Note
    that positive pairs are on the left, while negative pairs are on the right:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了某些人脸对的结果。请注意，正对位于左侧，负对位于右侧：
- en: '![](img/d09ea078-ce2e-4a4c-b9fc-43762e329705.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d09ea078-ce2e-4a4c-b9fc-43762e329705.png)'
- en: Did you spot anything interesting?  Judging from the preceding results, the
    threshold score seems to be around 0.5\. Anything below 0.5 should be classified
    as a positive pair (that is, faces match), and anything above 0.5 should be classified
    as a negative pair. Note that the negative pair on the second-row-to-the-right
    column is really near the threshold, with a score of 0.501\. Interestingly, the
    two subjects do look alike, with similar glasses and hairstyles!
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 你注意到什么有趣的事情了吗？ 从前面的结果来看，阈值分数似乎大约是 0.5。低于 0.5 的应该被归类为正对（即，面孔匹配），高于 0.5 的应该被归类为负对。请注意，第二行右侧列中的负对分数非常接近阈值，分数为
    0.501。有趣的是，这两个人确实很相似，戴着类似的眼镜和发型！
- en: Consolidating our code
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整合我们的代码
- en: At this point, it would be useful to consolidate our code. We have written a
    lot of code so far, including helper functions. Let's consolidate the helper functions
    into a `utils.py` file as follows.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，整合我们的代码会很有帮助。到目前为止，我们已经编写了很多代码，包括辅助函数。让我们将这些辅助函数整合到一个`utils.py`文件中，如下所示。
- en: 'First, we import the necessary libraries:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入必要的库：
- en: '[PRE32]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We include the `euclidean_distance`, `contrastive_loss`, and `accuracy` functions
    needed to train a Siamese neural network in the `utils.py` file:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在`utils.py`文件中包含了训练 Siamese 神经网络所需的`euclidean_distance`、`contrastive_loss`和`accuracy`函数：
- en: '[PRE33]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We include the `create_pairs` function in the `utils.py` file. Recall that
    this helper function is used to generate negative and positive pairs of images
    for training a Siamese neural network:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将`create_pairs`函数包含在`utils.py`文件中。回想一下，这个辅助函数用于生成用于训练 Siamese 神经网络的正对和负对图像：
- en: '[PRE34]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We also include the `create_shared_network` helper function in our `utils.py`
    file, which is used to create a Siamese neural network in Keras:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还在`utils.py`文件中包含了`create_shared_network`辅助函数，该函数用于在 Keras 中创建一个 Siamese 神经网络：
- en: '[PRE35]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The last helper function in our `utils.py` file is the `get_data` function.
    This function helps us to load the respective raw images into NumPy arrays:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`utils.py`文件中的最后一个辅助函数是`get_data`函数。该函数帮助我们将相应的原始图像加载到 NumPy 数组中：
- en: '[PRE36]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: You can see the `utils.py` file in the code we provided.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在我们提供的代码中看到`utils.py`文件。
- en: 'Similarly, we can create a `siamese_nn.py` file. This Python file will hold
    the main code to create and train our Siamese neural network:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以创建一个`siamese_nn.py`文件。这个 Python 文件将包含创建和训练我们 Siamese 神经网络的主要代码：
- en: '[PRE37]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This Python file is saved as `'Chapter07/siamese_nn.py'` in the code we provided.
    Notice how the code is a lot shorter than before, as we have refactored our code
    to call the helper functions in the `utils.py`.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Python 文件保存在我们提供的代码中，路径为`'Chapter07/siamese_nn.py'`。请注意，代码比之前短了很多，因为我们已经重构了代码，将辅助函数移到了`utils.py`中。
- en: Note that the last line in the preceding code saves the trained model at the
    `Chapter07/siamese_nn.h5` location. This allows us to easily import the trained
    model for face recognition, without retraining a model from scratch.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前面代码的最后一行将训练好的模型保存在`Chapter07/siamese_nn.h5`位置。这样，我们可以轻松地导入训练好的面部识别模型，而不需要从头开始重新训练模型。
- en: Creating a real-time face recognition program
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建实时人脸识别程序
- en: We have finally come to the most important part of the project. We are going
    to put together the code that we have written so far to create a real-time face
    recognition program. This program will use the webcam in our computer for facial
    recognition, and to authenticate whether the person sitting in front of the webcam
    is indeed you.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于来到了项目中最重要的部分。我们将把到目前为止编写的代码整合在一起，创建一个实时的人脸识别程序。这个程序将使用我们计算机中的网络摄像头进行人脸识别，验证坐在摄像头前的人是否真的是你。
- en: 'To do so, the program needs to do the following:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现这一点，程序需要完成以下任务：
- en: Train a Siamese neural network for facial recognition (this has already been
    done in the previous section).
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练一个用于人脸识别的Siamese神经网络（这部分已经在上一节完成）。
- en: Use the webcam to capture a true image of the authorized user. This is the onboarding
    process of the facial recognition system.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用网络摄像头捕捉授权用户的真实图像。这是人脸识别系统的注册过程。
- en: Subsequently, when a user wants to unlock the program, use the pre-trained Siamese
    neural network from *Step 1* and the true image from *Step 2* to authenticate
    the user.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随后，当用户想要解锁程序时，使用*步骤1*中的预训练Siamese神经网络和*步骤2*中的真实图像来验证用户身份。
- en: This part of the project requires a webcam (either the one in your laptop or
    an external webcam attached to your computer). If you do not have a webcam in
    your computer, you may skip this part of the project.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这个部分的项目需要一个网络摄像头（可以是你笔记本电脑内置的摄像头，也可以是你连接到计算机的外接摄像头）。如果你的计算机没有网络摄像头，可以跳过这个部分。
- en: The onboarding process
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注册过程
- en: 'Let''s write the code for the onboarding process. During the onboarding process,
    we need to activate the webcam to capture a true image of the authorized user.
    OpenCV has a function called `VideoCapture` that allows us to activate and capture
    the image from the computer''s webcam:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写注册过程的代码。在注册过程中，我们需要激活摄像头来捕捉授权用户的真实图像。OpenCV提供了一个名为`VideoCapture`的函数，它允许我们激活并从计算机的摄像头捕获图像：
- en: '[PRE38]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Let''s give the user five seconds to prepare before taking a photo using the
    webcam. We start a `counter` variable with an initial value of `5` and snap a
    photo using the webcam once the counter reaches `0`. Note that we use the code
    in the `face_detection.py` file that we have written earlier in the chapter to
    detect faces in front of the webcam. The photo will be saved as `''true_img.png''`
    in the same folder as the code:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用网络摄像头拍照之前，给用户五秒钟的准备时间。我们启动一个初始值为`5`的`counter`变量，当计时器达到`0`时，用摄像头拍照。注意，我们使用本章早些时候编写的`face_detection.py`文件中的代码来检测摄像头前的人脸。拍摄的照片将保存在与代码相同的文件夹下，命名为`'true_img.png'`：
- en: '[PRE39]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The onboarding process looks like this:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 注册过程如下所示：
- en: '![](img/c10f4692-85c4-40b6-b97a-4f8b6aa1bfe5.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c10f4692-85c4-40b6-b97a-4f8b6aa1bfe5.png)'
- en: 'This code is saved as `Chapter07/onboarding.py` in the files we provided. To
    run the onboarding process for yourself, simply execute the Python file from a
    command prompt (in Windows) or a Terminal (macOS/Linux) by calling the following:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码保存在我们提供的文件中，路径为`Chapter07/onboarding.py`。要运行注册过程，只需在命令提示符（Windows）或终端（macOS/Linux）中执行该Python文件，方法如下：
- en: '[PRE40]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Face recognition process
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人脸识别过程
- en: 'With the onboarding process complete, we can now move on to the actual face
    recognition process. We start by asking the user for their name. The name will
    be displayed above the detected face, as we shall see later. The `input` function
    in Python allows the user to enter their name:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 注册过程完成后，我们可以继续进行实际的人脸识别过程。我们首先询问用户的姓名。稍后该姓名将显示在人脸识别图像上，如我们所见。Python中的`input`函数允许用户输入姓名：
- en: '[PRE41]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The user will then enter a name on the command line when prompted.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，用户将在命令行中输入姓名。
- en: 'Next, let''s import our pre-trained Siamese neural network from earlier in
    the chapter:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们导入本章早些时候训练好的Siamese神经网络：
- en: '[PRE42]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Next, we load the true image of the user captured during the onboarding process
    and preprocess it by normalizing, resizing, and reshaping the image for our Siamese
    neural network:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们加载在注册过程中捕捉到的用户真实图像，并通过标准化、调整大小和重塑图像来为我们的Siamese神经网络预处理图像：
- en: '[PRE43]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The rest of the code uses the `VideoCapture` function in OpenCV to capture
    a video from the user''s webcam, and passes each frame from the video to our `face_detection`
    instance. We use a fixed-length list (implemented by Python''s `collections.deque`
    class) of 15 to collect the 15 most recent predictions (one prediction per frame).
    We average the scores from the 15 most recent predictions, and we authenticate
    the user if the average similarity scores is over a certain threshold. The rest
    of the code is shown as follows:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 其余的代码使用了OpenCV中的`VideoCapture`函数从用户的摄像头捕捉视频，并将视频中的每一帧传递给我们的`face_detection`实例。我们使用一个固定长度的列表（由Python的`collections.deque`类实现）来收集15个最新的预测结果（每一帧一个预测）。我们对这15个最新预测的得分进行平均，如果平均相似度得分超过某个阈值，我们就认证用户。其余代码如下所示：
- en: '[PRE44]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'This code is saved as `''Chapter07/face_recognition_system.py''` in the files
    we provided. To run the program for yourself, simply execute the Python file from
    a command prompt (in Windows) or a Terminal (macOS/Linux) by calling the following:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码保存在`'Chapter07/face_recognition_system.py'`文件中，您可以按照以下方法在命令提示符（Windows）或终端（macOS/Linux）中执行该Python文件来运行程序：
- en: '[PRE45]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Make sure that you run the onboarding program first (to capture a true image)
    before running the face recognition program.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 确保首先运行入职程序（以捕捉真实图像），然后再运行人脸识别程序。
- en: 'This is what it looks like when the program is trying to identify your face
    initially:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 这是程序初次尝试识别您面孔时的样子：
- en: '![](img/8b346220-2425-4bf5-8eff-8466625b0a7e.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b346220-2425-4bf5-8eff-8466625b0a7e.png)'
- en: 'After a few seconds, the program should recognize you:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 几秒钟后，程序应该会识别出您：
- en: '![](img/1d60c868-b71e-417f-b3e0-cff18f1a667e.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1d60c868-b71e-417f-b3e0-cff18f1a667e.png)'
- en: Future work
  id: totrans-284
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来的工作
- en: As we saw, our face recognition system certainly works well under simple conditions.
    However, it is definitely not fool-proof, and certainly not secure enough to be
    implemented in important applications. For one, the face detection system can
    be fooled by a static photo (try it yourself!). Theoretically, that means we can
    bypass the authentication by placing a static photo of an authorized user in front
    of the webcam.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，我们的人脸识别系统在简单条件下确实工作得很好。然而，它绝对不是万无一失的，当然也不足够安全，无法应用于重要的场景。首先，人脸检测系统会被静态照片欺骗（自己试试看！）。从理论上讲，这意味着我们可以通过将授权用户的静态照片放在摄像头前来绕过认证。
- en: 'Techniques to solve this problem are known as **anti-spoofing techniques**. Anti-spoofing
    techniques are a keenly studied area in face recognition. In general, there are
    two main anti-spoofing techniques used today:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的技术被称为**反欺骗技术**。反欺骗技术是人脸识别领域的一个重要研究方向。通常，今天使用的主要反欺骗技术有两种：
- en: '**Liveness detection**: Since a photo is a static two-dimensional image and
    a real face is dynamic and three-dimensional, we can check for the *liveness* of
    the detected face. Ways to perform liveness detection include checking the optic
    flow of the detected face, and checking the lighting and texture of the detected
    face in contrast to the surroundings.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**活体检测**：由于照片是静态的二维图像，而真实面孔是动态且三维的，我们可以检查检测到的面孔的*活体*。进行活体检测的方式包括检查检测到的面孔的光流，以及检查检测到的面孔与周围环境的光照和纹理对比。'
- en: '**Machine learning**: We can also differentiate a real face from an image by
    using machine learning! We can train a CNN to classify whether the detected face
    belongs to a real face or a static image. However, you would need plenty of labeled
    data (face versus non-face) to accomplish this.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器学习**：我们也可以通过使用机器学习来区分真实面孔和图片！我们可以训练一个卷积神经网络（CNN）来分类检测到的面孔是属于真实面孔还是静态图像。然而，您需要大量标注数据（面孔与非面孔）才能实现这一点。'
- en: 'Here''s a video from Andrew Ng, showing how face recognition (with liveness
    detection) is implemented in Baidu''s headquarters in China:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Andrew Ng的一段视频，展示了人脸识别（带活体检测）是如何在百度中国总部实现的：
- en: '[https://www.youtube.com/watch?v=wr4rx0Spihs](https://www.youtube.com/watch?v=wr4rx0Spihs)'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.youtube.com/watch?v=wr4rx0Spihs](https://www.youtube.com/watch?v=wr4rx0Spihs)'
- en: If you would like to understand how Apple implements its face ID system in iPhones,
    you can refer to the paper at [https://www.apple.com/business/site/docs/FaceID_Security_Guide.pdf](https://www.apple.com/business/site/docs/FaceID_Security_Guide.pdf) published
    by Apple.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想了解苹果是如何在iPhone中实现面部ID系统的，可以参考苹果发布的论文[https://www.apple.com/business/site/docs/FaceID_Security_Guide.pdf](https://www.apple.com/business/site/docs/FaceID_Security_Guide.pdf)。
- en: Apple's implementation of face ID is more secure than the system that we used
    in this chapter. Apple uses a TrueDepth camera to project infrared dots on your
    face, creating a depth map, which is then used for facial recognition.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 苹果的Face ID实现比我们在本章中使用的系统更为安全。苹果使用TrueDepth相机将红外线点投射到你的脸上，创建深度图，之后利用深度图进行人脸识别。
- en: Summary
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we created a face recognition system based on a Siamese neural
    network. The face recognition system uses a webcam to stream frames from a live
    video to a pre-trained Siamese neural network, and using a true image of the user,
    the system is able to authenticate the user in front of the webcam.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们创建了一个基于Siamese神经网络的人脸识别系统。该人脸识别系统使用摄像头从实时视频流中提取帧，传递给预训练的Siamese神经网络，并使用用户的真实图像，系统能够验证站在摄像头前的用户。
- en: We first dissected the face recognition problem into smaller subproblems, and
    we saw how a face recognition system first performs a face detection step to isolate
    the face from the rest of the image, before the actual face recognition step.
    We saw how face detection is commonly done by the Viola-Jones algorithm, which
    uses Haar features to detect faces in real time. Face detection using Haar filters
    is implemented in Python via the OpenCV library, which allows us to perform face
    detection in just a few lines of code.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将人脸识别问题分解成更小的子问题，我们看到人脸识别系统首先执行人脸检测步骤，将人脸从图像的其余部分分离出来，然后才进行实际的人脸识别步骤。我们看到人脸检测通常是通过Viola-Jones算法完成的，该算法使用Haar特征实时检测人脸。使用Haar滤波器的人脸检测在Python中通过OpenCV库实现，这使得我们只需几行代码就能执行人脸检测。
- en: We then focused on face recognition, and we discussed how the requirements of
    face recognition systems (speed, scalability, high accuracy with small data) makes
    CNNs unsuitable for this problem. We introduced the architecture of Siamese neural
    networks, and how distance-based predictions in Siamese neural networks can be
    used for face recognition. We trained a Siamese neural network from scratch in
    Keras, using the AT&T faces dataset.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后集中讨论了人脸识别，并讨论了人脸识别系统的需求（速度、可扩展性、在小数据下的高准确度）如何使得CNNs不适用于这个问题。我们介绍了Siamese神经网络的架构，以及如何利用Siamese神经网络中的基于距离的预测进行人脸识别。我们使用AT&T人脸数据集，从头开始在Keras中训练了一个Siamese神经网络。
- en: Lastly, using the pre-trained Siamese neural network, we created our own face
    recognition system in Python. The face recognition system consists of two steps.
    In the first step (the onboarding process), we used OpenCV's face detection API
    to capture an image of the user using a webcam, as the true image for the Siamese
    neural network. In the second step, the system uses the true image to recognize
    and authenticate users of the program.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，利用预训练的Siamese神经网络，我们在Python中创建了我们自己的人脸识别系统。人脸识别系统由两个步骤组成。在第一步（注册过程）中，我们使用OpenCV的人脸检测API，通过摄像头捕捉用户的图像，作为Siamese神经网络的真实图像。在第二步中，系统利用真实图像识别和验证程序用户。
- en: In the next and final chapter, [Chapter 8](cf13b5e9-5a3d-4cd7-ba65-aeee25e0e6bb.xhtml),
    *What's Next?*,we'll consolidate and recap the different projects that we've completed
    so far in this book. We'll also peer into the future, and see what neural networks
    and AI will look like in the next few years.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，也是最后一章，[第8章](cf13b5e9-5a3d-4cd7-ba65-aeee25e0e6bb.xhtml)，*接下来是什么？*，我们将总结和回顾到目前为止在本书中完成的不同项目。我们还将展望未来，看看神经网络和人工智能在未来几年会是什么样子。
- en: Questions
  id: totrans-299
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: How is face detection different than face recognition?
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人脸检测与人脸识别有何不同？
- en: The objective of face detection is to locate human faces in an image. The output
    from the face detection process is a bounding box around detected faces. On the
    other hand, the objective of face recognition is to classify faces (that is, identify
    subjects). Face detection and face recognition are the two key steps in every
    facial recognition system, and the output from the face detection step is passed
    as input to the face recognition step.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 人脸检测的目标是定位图像中的人脸。人脸检测过程的输出是围绕检测到的人脸的边界框。另一方面，人脸识别的目标是对人脸进行分类（即识别对象）。人脸检测和人脸识别是每个人脸识别系统中的两个关键步骤，人脸检测步骤的输出作为输入传递给人脸识别步骤。
- en: What is the Viola-Jones algorithm for face detection?
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Viola-Jones人脸检测算法是什么？
- en: The Viola-Jones algorithm uses Haar features for face detection. Haar features
    are filters with alternating dark and bright areas that represents the contrast
    in pixel intensity in human faces. For example, the eye area in an image of a
    human face has a darker pixel value than the forehead and the cheeks areas. These
    Haar filters are used to localize areas in an image that may contain faces.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: Viola-Jones 算法使用 Haar 特征进行人脸检测。Haar 特征是具有交替明暗区域的滤波器，表示人脸中像素强度的对比度。例如，人脸图像中的眼睛区域具有比额头和脸颊区域更暗的像素值。这些
    Haar 滤波器用于定位图像中可能包含人脸的区域。
- en: What is one-shot learning, and how is it different than batch learning?
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是单次学习（one-shot learning），它与批量学习（batch learning）有何不同？
- en: In one-shot learning, the objective is to train a machine learning model with
    very little data. In contrast, batch learning uses a big dataset to train a machine
    learning model. One-shot learning is often used in image recognition tasks, as
    the quantity of training samples can be very sparse.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在单次学习中，目标是使用非常少的数据来训练机器学习模型。与此不同，批量学习使用大量数据集来训练机器学习模型。单次学习通常用于图像识别任务，因为训练样本的数量可能非常稀疏。
- en: Describe the architecture of a Siamese neural network.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述 Siamese 神经网络的架构。
- en: Siamese neural networks consist of two conjoined convolutional layers with shared
    weights, accepting a pair of input images. The conjoined convolutional layers
    project the two input images to a lower-dimension feature space. Using a Euclidean
    distance layer, we compute and output the distance of the two lower-dimension
    vectors, which is inversely proportional to the similarity of the two images.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: Siamese 神经网络由两个共享权重的联合卷积层组成，接受一对输入图像。联合卷积层将两个输入图像映射到一个低维特征空间。通过欧几里得距离层，我们计算并输出这两个低维向量的距离，该距离与两张图像的相似度成反比。
- en: When training a Siamese neural network for face recognition, what is the loss
    function used?
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练用于人脸识别的 Siamese 神经网络时，使用的损失函数是什么？
- en: We use a contrastive loss function to train a Siamese neural network for face
    recognition. The contrastive loss function encourages a neural network to output
    a small distance when the pair of input images are similar, and vice versa, it
    encourages a large output distance when the pair of input images are different.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用对比损失函数来训练用于人脸识别的 Siamese 神经网络。对比损失函数鼓励神经网络在输入图像对相似时输出小距离，反之，在输入图像对不同时，鼓励输出较大的距离。
