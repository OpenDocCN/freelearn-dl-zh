- en: References
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Chapter 3
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三章
- en: 'Word representations: [https://dl.acm.org/citation.cfm?id=1858721](https://dl.acm.org/citation.cfm?id=1858721)'
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '词表示: [https://dl.acm.org/citation.cfm?id=1858721](https://dl.acm.org/citation.cfm?id=1858721)'
- en: 'One-hot encoding: [https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/)'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '独热编码: [https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/](https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/)'
- en: 'Representational learning: [https://github.com/anujgupta82/Representation-Learning-for-NLP](https://github.com/anujgupta82/Representation-Learning-for-NLP)'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '表示学习: [https://github.com/anujgupta82/Representation-Learning-for-NLP](https://github.com/anujgupta82/Representation-Learning-for-NLP)'
- en: N-grams: [http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.9367](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.9367)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: N-gram 模型: [http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.9367](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.9367)
- en: TF-IDF: [https://nlp.stanford.edu/IR-book/html/htmledition/inverse-document-frequency-1.html](https://nlp.stanford.edu/IR-book/html/htmledition/inverse-document-frequency-1.html)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TF-IDF: [https://nlp.stanford.edu/IR-book/html/htmledition/inverse-document-frequency-1.html](https://nlp.stanford.edu/IR-book/html/htmledition/inverse-document-frequency-1.html)
- en: 'Mikolov *et al.* 2013: [https://arxiv.org/abs/1310.4546](https://arxiv.org/abs/1310.4546)'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mikolov *等* 2013: [https://arxiv.org/abs/1310.4546](https://arxiv.org/abs/1310.4546)'
- en: 'Maas and cgpotts paper: [https://web.stanford.edu/~cgpotts/papers/wvSent_acl2011.pdf](https://web.stanford.edu/~cgpotts/papers/wvSent_acl2011.pdf)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Maas 和 cgpotts 论文: [https://web.stanford.edu/~cgpotts/papers/wvSent_acl2011.pdf](https://web.stanford.edu/~cgpotts/papers/wvSent_acl2011.pdf)'
- en: Bag of words in scikit-learn: [http://scikit-learn.org/stable/modules/feature_extraction.html#the-bag-of-words-representation](http://scikit-learn.org/stable/modules/feature_extraction.html#the-bag-of-words-representation)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn 中的词袋模型: [http://scikit-learn.org/stable/modules/feature_extraction.html#the-bag-of-words-representation](http://scikit-learn.org/stable/modules/feature_extraction.html#the-bag-of-words-representation)
- en: Kaggle word2vec [https://www.kaggle.com/c/word2vec-nlp-tutorial](https://www.kaggle.com/c/word2vec-nlp-tutorial)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaggle 上的 word2vec [https://www.kaggle.com/c/word2vec-nlp-tutorial](https://www.kaggle.com/c/word2vec-nlp-tutorial)
- en: Heap's law: [https://en.wikipedia.org/wiki/Heaps%27_law](https://en.wikipedia.org/wiki/Heaps%27_law)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heap 法则: [https://en.wikipedia.org/wiki/Heaps%27_law](https://en.wikipedia.org/wiki/Heaps%27_law)
- en: 'Distributed representations of sentences and documents, Mikolov *et al*: [https://cs.stanford.edu/~quocle/paragraph_vector.pdf](https://cs.stanford.edu/~quocle/paragraph_vector.pdf)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '句子和文档的分布式表示，Mikolov *等*: [https://cs.stanford.edu/~quocle/paragraph_vector.pdf](https://cs.stanford.edu/~quocle/paragraph_vector.pdf)'
- en: CBOW: [https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa](https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CBOW: [https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa](https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa)
- en: Skip-gram: McCormick, C. (2016, April 19), *Word2Vec Tutorial - The Skip-Gram
    Model* [http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Skip-gram: McCormick, C. (2016, April 19), *Word2Vec教程 - Skip-Gram模型* [http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)
- en: 'TensorFlow implementation of word2vec: [https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/examples/tutorials/word2vec/word2vec_basic.py](https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/examples/tutorials/word2vec/word2vec_basic.py)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'TensorFlow 中的 word2vec 实现: [https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/examples/tutorials/word2vec/word2vec_basic.py](https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/examples/tutorials/word2vec/word2vec_basic.py)'
- en: 'Word2vec explained: [https://arxiv.org/abs/1411.2738](https://arxiv.org/abs/1411.2738)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Word2vec 详解: [https://arxiv.org/abs/1411.2738](https://arxiv.org/abs/1411.2738)'
- en: 'Deriving negative sampling: [https://arxiv.org/abs/1402.3722](https://arxiv.org/abs/1402.3722)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '推导负采样: [https://arxiv.org/abs/1402.3722](https://arxiv.org/abs/1402.3722)'
- en: 'Compositional distributional semantics: [https://youtu.be/hTmKoHJw3Mg](https://youtu.be/hTmKoHJw3Mg)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '组合分布式语义学: [https://youtu.be/hTmKoHJw3Mg](https://youtu.be/hTmKoHJw3Mg)'
- en: 'The fastText and skipgram: [http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/09/28/fast-text-and-skip-gram/](http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/09/28/fast-text-and-skip-gram/)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'fastText 和 skipgram: [http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/09/28/fast-text-and-skip-gram/](http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/09/28/fast-text-and-skip-gram/)'
- en: The skip-gram and CBOW: [https://iksinc.online/tag/continuous-bag-of-words-cbow/](https://iksinc.online/tag/continuous-bag-of-words-cbow/)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: skip-gram和CBOW：[https://iksinc.online/tag/continuous-bag-of-words-cbow/](https://iksinc.online/tag/continuous-bag-of-words-cbow/)
- en: Stanford lectures on CBOW and skip-gram: [https://cs224d.stanford.edu/lecture_notes/notes1.pdf](https://cs224d.stanford.edu/lecture_notes/notes1.pdf)
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 斯坦福大学关于CBOW和skip-gram的讲座：[https://cs224d.stanford.edu/lecture_notes/notes1.pdf](https://cs224d.stanford.edu/lecture_notes/notes1.pdf)
- en: '[http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_II_The_Continuous_Bag-of-Words_Model.pdf](http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_II_The_Continuous_Bag-of-Words_Model.pdf)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_II_The_Continuous_Bag-of-Words_Model.pdf](http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_II_The_Continuous_Bag-of-Words_Model.pdf)'
- en: The fasttext PyTorch: [https://github.com/PetrochukM/PyTorch-NLP](https://github.com/PetrochukM/PyTorch-NLP)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: fasttext PyTorch：[https://github.com/PetrochukM/PyTorch-NLP](https://github.com/PetrochukM/PyTorch-NLP)
- en: Levy, Omer and Goldberg Yoav (2014), *Dependency-Based Word Embeddings*, 52nd
    Annual Meeting of the Association for Computational Linguistics, ACL 2014-Proceedings
    of the Conference, [2\. 302-308\. 10.3115/v1/P14-2050](http://www.aclweb.org/anthology/P14-2050)
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Levy，Omer 和 Goldberg Yoav（2014），*基于依赖关系的词嵌入*，第52届计算语言学协会年会，ACL 2014——会议论文集，[2.
    302-308. 10.3115/v1/P14-2050](http://www.aclweb.org/anthology/P14-2050)
- en: '*Notes on Noise Contrastive Estimation and Negative Sampling*: [https://arxiv.org/abs/1410.8251](https://arxiv.org/abs/1410.8251)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*噪声对比估计与负采样的笔记*：[https://arxiv.org/abs/1410.8251](https://arxiv.org/abs/1410.8251)'
- en: '*Sebastian Ruder, on word embeddings - Part 2: Approximating the Softmax*, [http://ruder.io/word-embeddings-softmax](http://ruder.io/word-embeddings-softmax),
    2016.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Sebastian Ruder，关于词嵌入 - 第二部分：逼近Softmax*，[http://ruder.io/word-embeddings-softmax](http://ruder.io/word-embeddings-softmax)，2016。'
- en: Scalable hierarchical distributed language model. [http://papers.nips.cc/paper/3583-a-scalable-hierarchical-distributed-language-model.pdf](http://papers.nips.cc/paper/3583-a-scalable-hierarchical-distributed-language-model.pdf)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可扩展的层次分布式语言模型。[http://papers.nips.cc/paper/3583-a-scalable-hierarchical-distributed-language-model.pdf](http://papers.nips.cc/paper/3583-a-scalable-hierarchical-distributed-language-model.pdf)
- en: Softmax function and its derivative. [https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Softmax函数及其导数。[https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)
- en: '*What is Softmax Regression and How is it Related to Logistic Regression?*,
    Sebastian Raschka. [https://www.kdnuggets.com/2016/07/softmax-regression-related-logistic-regression.html](https://www.kdnuggets.com/2016/07/softmax-regression-related-logistic-regression.html)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*什么是Softmax回归，它与逻辑回归有什么关系？*，Sebastian Raschka。[https://www.kdnuggets.com/2016/07/softmax-regression-related-logistic-regression.html](https://www.kdnuggets.com/2016/07/softmax-regression-related-logistic-regression.html)'
- en: '[https://web.stanford.edu/class/cs224n/reports/2758157.pdf](https://web.stanford.edu/class/cs224n/reports/2758157.pdf)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://web.stanford.edu/class/cs224n/reports/2758157.pdf](https://web.stanford.edu/class/cs224n/reports/2758157.pdf)'
- en: Softmax regression, [http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/](http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/)
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Softmax回归，[http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/](http://ufldl.stanford.edu/tutorial/supervised/SoftmaxRegression/)
- en: 'Google Allo: [https://research.googleblog.com/2016/05/chat-smarter-with-allo.html](https://research.googleblog.com/2016/05/chat-smarter-with-allo.html)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google Allo：[https://research.googleblog.com/2016/05/chat-smarter-with-allo.html](https://research.googleblog.com/2016/05/chat-smarter-with-allo.html)
- en: '*Hierarchical Probabilistic Neural Network Language Model*, Morin and Bengio,
    2005, [https://www.iro.umontreal.ca/~lisa/pointeurs/hierarchical-nnlm-aistats05.pdf](https://www.iro.umontreal.ca/~lisa/pointeurs/hierarchical-nnlm-aistats05.pdf)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*层次化概率神经网络语言模型*，Morin和Bengio，2005，[https://www.iro.umontreal.ca/~lisa/pointeurs/hierarchical-nnlm-aistats05.pdf](https://www.iro.umontreal.ca/~lisa/pointeurs/hierarchical-nnlm-aistats05.pdf)'
- en: '*A Scalable Hierarchical Distributed Language Model. Mnih, Andriy and Hinton*,
    Geoffrey E. 2009, [https://papers.nips.cc/paper/3583-a-scalable-hierarchical-distributed-language-model](https://papers.nips.cc/paper/3583-a-scalable-hierarchical-distributed-language-model)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可扩展的层次分布式语言模型。Mnih，Andriy和Hinton*，Geoffrey E. 2009，[https://papers.nips.cc/paper/3583-a-scalable-hierarchical-distributed-language-model](https://papers.nips.cc/paper/3583-a-scalable-hierarchical-distributed-language-model)'
- en: '*Self Organised Hierarchical Softmax*, [arXiv:1707.08588v1 [cs.CL] 26 Jul 2017](https://arxiv.org/pdf/1707.08588.pdf)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*自组织层次Softmax*，[arXiv:1707.08588v1 [cs.CL] 2017年7月26日](https://arxiv.org/pdf/1707.08588.pdf)'
- en: '*Effective Text Clustering Method Based on Huffman Encoding Algorithm*, Nikhil
    Pawar, 2012, [https://www.ijsr.net/archive/v3i12/U1VCMTQ1NjE=.pdf](https://www.ijsr.net/archive/v3i12/U1VCMTQ1NjE=.pdf)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于哈夫曼编码算法的有效文本聚类方法*, Nikhil Pawar, 2012年， [https://www.ijsr.net/archive/v3i12/U1VCMTQ1NjE=.pdf](https://www.ijsr.net/archive/v3i12/U1VCMTQ1NjE=.pdf)'
- en: 'Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado, and Jeffrey Dean,
    *Distributed representations of words and phrases and their compositionality*,
    *In Advances in Neural Information Processing Systems 26*: *27th Annual Conference
    on Neural Information Processing Systems 2013*, *Proceedings of a meeting held
    December 5-8, 2013, Lake Tahoe, Nevada, United States, pages 3111–3119, 2013*.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tomas Mikolov, Ilya Sutskever, Kai Chen, Gregory S. Corrado 和 Jeffrey Dean,
    *词和短语的分布式表示及其组合性,* *载于《神经信息处理系统进展》第26卷*：*第27届神经信息处理系统年会，2013年*，*会议论文集，2013年12月5-8日，美国内华达州湖塔霍，页3111-3119*。
- en: '[http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/09/28/fast-text-and-skip-gram/](http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/09/28/fast-text-and-skip-gram/)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/09/28/fast-text-and-skip-gram/](http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/09/28/fast-text-and-skip-gram/)'
- en: '[https://github.com/nzw0301/keras-examples/blob/master/Skip-gram-with-NS.ipynb](https://github.com/nzw0301/keras-examples/blob/master/Skip-gram-with-NS.ipynb)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/nzw0301/keras-examples/blob/master/Skip-gram-with-NS.ipynb](https://github.com/nzw0301/keras-examples/blob/master/Skip-gram-with-NS.ipynb)'
- en: Chapter 4
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章
- en: Vladimir Zolotov and David Kung 2017, *Analysis and Optimization of fastText
    Linear Text Classifier*, [http://arxiv.org/abs/1702.05531](http://arxiv.org/abs/1702.05531)
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vladimir Zolotov 和 David Kung 2017年，*fastText线性文本分类器的分析与优化*, [http://arxiv.org/abs/1702.05531](http://arxiv.org/abs/1702.05531)
- en: '*Text classification of linear models*, [http://www.cs.umd.edu/class/fall2017/cmsc723/slides/slides_03.pdf](http://www.cs.umd.edu/class/fall2017/cmsc723/slides/slides_03.pdf)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*线性模型的文本分类*, [http://www.cs.umd.edu/class/fall2017/cmsc723/slides/slides_03.pdf](http://www.cs.umd.edu/class/fall2017/cmsc723/slides/slides_03.pdf)'
- en: '*What is text classification*, Stanford, [https://nlp.stanford.edu/IR-book/html/htmledition/the-text-classification-problem-1.html#sec:classificationproblem](https://nlp.stanford.edu/IR-book/html/htmledition/the-text-classification-problem-1.html#sec:classificationproblem)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*什么是文本分类*，斯坦福，[https://nlp.stanford.edu/IR-book/html/htmledition/the-text-classification-problem-1.html#sec:classificationproblem](https://nlp.stanford.edu/IR-book/html/htmledition/the-text-classification-problem-1.html#sec:classificationproblem)'
- en: '[https://nlp.stanford.edu/IR-book/html/htmledition/text-classification-and-naive-bayes-1.html](https://nlp.stanford.edu/IR-book/html/htmledition/text-classification-and-naive-bayes-1.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://nlp.stanford.edu/IR-book/html/htmledition/text-classification-and-naive-bayes-1.html](https://nlp.stanford.edu/IR-book/html/htmledition/text-classification-and-naive-bayes-1.html)'
- en: '[https://research.fb.com/fasttext/](https://research.fb.com/fasttext/)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://research.fb.com/fasttext/](https://research.fb.com/fasttext/)'
- en: '*Bag of tricks for efficient classification,* [arXiv:1607.01759v3 [cs.CL] 9
    Aug 2016](https://arxiv.org/pdf/1607.01759.pdf)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*高效分类的技巧集,* [arXiv:1607.01759v3 [cs.CL] 2016年8月9日](https://arxiv.org/pdf/1607.01759.pdf)'
- en: '[https://github.com/poliglot/fasttext](https://github.com/poliglot/fasttext)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/poliglot/fasttext](https://github.com/poliglot/fasttext)'
- en: 'Joseph Turian, Lev Ratinov, and Yoshua Bengio, 2010, *Word representations:
    A simple and general method for semi-supervised learning,* *In* *Proceedings of
    the 48th Annual Meeting of the Association for Computational Linguistics* *(ACL
    ''10)*, *Association for Computational Linguistics, Stroudsburg, PA, USA, 384-394*.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Joseph Turian, Lev Ratinov, 和 Yoshua Bengio, 2010年，*词表示：一种简单而通用的半监督学习方法,* *载于* *第48届计算语言学协会年会论文集* *(ACL
    '10)*, *计算语言学协会，斯特劳兹堡，美国，384-394*。
- en: '[arXiv:1607.00570v1 [cs.IR] 2 Jul 2016](https://arxiv.org/abs/1607.00570)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[arXiv:1607.00570v1 [cs.IR] 2016年7月2日](https://arxiv.org/abs/1607.00570)'
- en: '*[Weinberger et al.2009] Kilian Weinberger, Anirban Dasgupta, John Langford,
    Alex Smola, and Josh Attenberg, 2009*, *Feature hashing for large scale multitask
    learning. In ICML*'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*[Weinberger 等, 2009] Kilian Weinberger, Anirban Dasgupta, John Langford, Alex
    Smola 和 Josh Attenberg, 2009年*, *特征哈希用于大规模多任务学习. 载于ICML会议*'
- en: '[https://developers.googleblog.com/2018/04/text-embedding-models-contain-bias.html](https://developers.googleblog.com/2018/04/text-embedding-models-contain-bias.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://developers.googleblog.com/2018/04/text-embedding-models-contain-bias.html](https://developers.googleblog.com/2018/04/text-embedding-models-contain-bias.html)'
- en: Softmax classifier in PyTorch: [https://www.youtube.com/watch?v=lvNdl7yg4Pg](https://www.youtube.com/watch?v=lvNdl7yg4Pg)
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch中的Softmax分类器：[https://www.youtube.com/watch?v=lvNdl7yg4Pg](https://www.youtube.com/watch?v=lvNdl7yg4Pg)
- en: '*Hierarchical loss for classification*: [arXiv:1709.01062v1 [cs.LG]](https://arxiv.org/abs/1709.01062),
    1 September 2017'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*分类的层次损失*：[arXiv:1709.01062v1 [cs.LG]](https://arxiv.org/abs/1709.01062)，2017年9月1日'
- en: Svenstrup, Dan & Meinertz Hansen, Jonas & Winther, Ole. (2017), Hash Embeddings
    for Efficient Word Representations
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Svenstrup，Dan & Meinertz Hansen，Jonas & Winther，Ole. (2017)，哈希嵌入用于高效的词表示
- en: Explanation kernel trick, [https://www.quora.com/How-does-Kernel-compute-inner-product-in-higher-dimensional-space-without-visiting-that-space/answer/Jeremy-McMinis](https://www.quora.com/How-does-Kernel-compute-inner-product-in-higher-dimensional-space-without-visiting-that-space/answer/Jeremy-McMinis)
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释核技巧，[https://www.quora.com/How-does-Kernel-compute-inner-product-in-higher-dimensional-space-without-visiting-that-space/answer/Jeremy-McMinis](https://www.quora.com/How-does-Kernel-compute-inner-product-in-higher-dimensional-space-without-visiting-that-space/answer/Jeremy-McMinis)
- en: '[https://medium.com/value-stream-design/introducing-one-of-the-best-hacks-in-machine-learning-the-hashing-trick-bf6a9c8af18f](https://medium.com/value-stream-design/introducing-one-of-the-best-hacks-in-machine-learning-the-hashing-trick-bf6a9c8af18f)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://medium.com/value-stream-design/introducing-one-of-the-best-hacks-in-machine-learning-the-hashing-trick-bf6a9c8af18f](https://medium.com/value-stream-design/introducing-one-of-the-best-hacks-in-machine-learning-the-hashing-trick-bf6a9c8af18f)'
- en: '*Extremely Fast Text Feature Extraction for Classification and Indexing* by
    George Forman and Evan Kirshenbaum'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*极快的文本特征提取用于分类和索引*，乔治·福尔曼和埃文·基尔申鲍姆著'
- en: 'Armand Joulin, [et. al. FastText.zip](https://arxiv.org/abs/1612.03651): *Compressing
    text classification model*, 2016, [https://arxiv.org/abs/1612.03651](https://arxiv.org/abs/1612.03651)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阿曼德·朱林， [等人. FastText.zip](https://arxiv.org/abs/1612.03651)： *压缩文本分类模型*，2016，
    [https://arxiv.org/abs/1612.03651](https://arxiv.org/abs/1612.03651)
- en: Vector quantization, [https://www.slideshare.net/rajanisharmaa/vector-quantization](https://www.slideshare.net/rajanisharmaa/vector-quantization)
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量量化， [https://www.slideshare.net/rajanisharmaa/vector-quantization](https://www.slideshare.net/rajanisharmaa/vector-quantization)
- en: '[http://shodhganga.inflibnet.ac.in/bitstream/10603/132782/14/12_chapter%204.pdf](http://shodhganga.inflibnet.ac.in/bitstream/10603/132782/14/12_chapter%204.pdf)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://shodhganga.inflibnet.ac.in/bitstream/10603/132782/14/12_chapter%204.pdf](http://shodhganga.inflibnet.ac.in/bitstream/10603/132782/14/12_chapter%204.pdf)'
- en: '*Voronoi Projection-Based Fast Nearest-Neighbor Search Algorithms: Box-Search
    and Mapping Table-Based Search Techniques, V. Ramasubramanian, K.K. Paliwa*l.
    1997, [https://www.sciencedirect.com/science/article/pii/S1051200497903006](https://www.sciencedirect.com/science/article/pii/S1051200497903006)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于Voronoi投影的快速最近邻搜索算法：盒子搜索和映射表搜索技术，V. 拉马苏布拉马尼安，K.K. 皮利瓦尔*。1997年，[https://www.sciencedirect.com/science/article/pii/S1051200497903006](https://www.sciencedirect.com/science/article/pii/S1051200497903006)'
- en: '*How To Implement Learning Vector Quantization From Scratch With Python. Jason
    Brownie*, 2016, [https://machinelearningmastery.com/implement-learning-vector-quantization-scratch-python/](https://machinelearningmastery.com/implement-learning-vector-quantization-scratch-python/)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*如何用Python从零实现学习向量量化。杰森·布朗尼*，2016，[https://machinelearningmastery.com/implement-learning-vector-quantization-scratch-python/](https://machinelearningmastery.com/implement-learning-vector-quantization-scratch-python/)'
- en: Herve Jegou, Matthijs Douze, and Cordelia Schmid, *Product quantization for
    nearest neighbor search*, IEEE Trans. PAMI, January 2011.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 赫尔维·热戈、马蒂斯·杜兹和科尔德莉亚·施密德，*用于最近邻搜索的产品量化*，IEEE Trans. PAMI，2011年1月。
- en: 'Song Han, Huizi Mao, and William J Dally. Deep compression: *Compressing deep
    neural networks with pruning, trained quantization and huffman coding*, *In ICLR*,
    2016'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 韩松、毛会子和威廉·J·达利。深度压缩：*通过修剪、训练量化和霍夫曼编码压缩深度神经网络*，*在ICLR中*，2016年
- en: Tiezheng Ge, Kaiming He, Qifa Ke, and Jian Sun, *Optimized product quantization
    for approximate nearest neighbor search*. *In CVPR*, June 2013
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 孙捷、何凯明、柯启发和孙剑，*优化的产品量化用于近似最近邻搜索*。 *在CVPR中*，2013年6月
- en: '*Expectation Maximisation*, Joydeep Bhattacharjee. [https://medium.com/technology-nineleaps/expectation-maximization-4bb203841757](https://medium.com/technology-nineleaps/expectation-maximization-4bb203841757)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*期望最大化*，乔伊迪普·巴塔查尔吉。[https://medium.com/technology-nineleaps/expectation-maximization-4bb203841757](https://medium.com/technology-nineleaps/expectation-maximization-4bb203841757)'
- en: Chen, Wenlin, Wilson, James T., Tyree, Stephen, Weinberger, Kilian Q, and Chen,
    Yixin, *Compressing neural networks with the hashing trick*, [arXiv:1504.04788,
    2015](https://arxiv.org/abs/1504.04788)
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈文林、詹姆斯·T·威尔逊、史蒂芬·泰瑞、基利安·Q·温伯格和陈逸欣，*利用哈希技巧压缩神经网络*， [arXiv:1504.04788, 2015](https://arxiv.org/abs/1504.04788)
- en: Kai Zeng, Kun She, and Xinzheng Niu, *Feature Selection with Neighborhood Entropy-Based
    Cooperative Game Theory*, *Computational Intelligence and Neuroscience*, vol.
    2014, Article ID 479289, 10 pages, 2014, [https://doi.org/10.1155/2014/479289](https://doi.org/10.1155/2014/479289).
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kai Zeng, Kun She, 和 Xinzheng Niu, *基于邻域熵的合作博弈理论特征选择*, *计算智能与神经科学*, vol. 2014,
    文章ID 479289, 10页, 2014, [https://doi.org/10.1155/2014/479289](https://doi.org/10.1155/2014/479289).
- en: Chapter 5
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章
- en: '*Software Framework for Topic Modelling with Large Corpora*, Radim, 2010'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*大规模语料主题建模软件框架*, Radim, 2010'
- en: 'Gensim fastText Tutorial: [https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gensim fastText教程: [https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb](https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/FastText_Tutorial.ipynb)'
- en: P. Bojanowski, E. Grave, A. Joulin, T. Mikolov, *Enriching Word Vectors with
    Subword Information*, [https://arxiv.org/abs/1607.04606](https://arxiv.org/abs/1607.04606)
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: P. Bojanowski, E. Grave, A. Joulin, T. Mikolov, *用子词信息丰富词向量*, [https://arxiv.org/abs/1607.04606](https://arxiv.org/abs/1607.04606)
- en: '[http://proceedings.mlr.press/v37/kusnerb15.pdf](http://proceedings.mlr.press/v37/kusnerb15.pdf)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://proceedings.mlr.press/v37/kusnerb15.pdf](http://proceedings.mlr.press/v37/kusnerb15.pdf)'
- en: Tomas Mikolov, Quoc V Le, Ilya Sutskever, 2013, (*Exploiting Similarities among
    Languages for Machine Translation*) ([https://arxiv.org/pdf/1309.4168.pdf](https://arxiv.org/pdf/1309.4168.pdf))
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tomas Mikolov, Quoc V Le, Ilya Sutskever, 2013, (*利用语言间相似性进行机器翻译*) ([https://arxiv.org/pdf/1309.4168.pdf](https://arxiv.org/pdf/1309.4168.pdf))
- en: Georgiana Dinu, Angelikie Lazaridou, and Marco Baroni. 2014, *Improving zero-shot
    learning by mitigating the hubness problem* ([https://arxiv.org/pdf/1412.6568.pdf](https://arxiv.org/pdf/1412.6568.pdf))
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Georgiana Dinu, Angelikie Lazaridou, 和 Marco Baroni. 2014, *通过缓解中心性问题改善零-shot学习*
    ([https://arxiv.org/pdf/1412.6568.pdf](https://arxiv.org/pdf/1412.6568.pdf))
- en: The fastText normalization, [https://www.kaggle.com/mschumacher/using-fasttext-models-for-robust-embeddings/notebook](https://www.kaggle.com/mschumacher/using-fasttext-models-for-robust-embeddings/notebook)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: fastText 标准化, [https://www.kaggle.com/mschumacher/using-fasttext-models-for-robust-embeddings/notebook](https://www.kaggle.com/mschumacher/using-fasttext-models-for-robust-embeddings/notebook)
- en: Luong, Minh-Thang and Socher, Richard and Manning, Christopher D. 2013, (*Better
    Word Representations with Recursive Neural Networks for Morphology*) ([https://nlp.stanford.edu/~lmthang/morphoNLM/](https://nlp.stanford.edu/~lmthang/morphoNLM/))
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luong, Minh-Thang 和 Socher, Richard 和 Manning, Christopher D. 2013, (*通过递归神经网络改善形态学词表示*)
    ([https://nlp.stanford.edu/~lmthang/morphoNLM/](https://nlp.stanford.edu/~lmthang/morphoNLM/))
- en: Chapter 6
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章
- en: Yoav Goldberg (2015), *A Primer on Neural Network Models for Natural*
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yoav Goldberg (2015), *神经网络模型入门：自然语言处理*
- en: '*Language Processing*, ([https://arxiv.org/abs/1510.00726](https://arxiv.org/abs/1510.00726))'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*语言处理*, ([https://arxiv.org/abs/1510.00726](https://arxiv.org/abs/1510.00726))'
- en: '[http://www.wildml.com/2015/11/understanding-convolutional-neural-networksfor-nlp/](http://www.wildml.com/2015/11/understanding-convolutional-neural-networksfor-nlp/)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.wildml.com/2015/11/understanding-convolutional-neural-networksfor-nlp/](http://www.wildml.com/2015/11/understanding-convolutional-neural-networksfor-nlp/)'
- en: '[http://mathworld.wolfram.com/Convolution.html](http://mathworld.wolfram.com/Convolution.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://mathworld.wolfram.com/Convolution.html](http://mathworld.wolfram.com/Convolution.html)'
- en: '[http://www.joshuakim.io/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-embeddings/](http://www.joshuakim.io/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-embeddings/)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.joshuakim.io/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-embeddings/](http://www.joshuakim.io/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-embeddings/)'
- en: '[https://machinelearningmastery.com/best-practices-document-classification-deep-learning/](https://machinelearningmastery.com/best-practices-document-classification-deep-learning/)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://machinelearningmastery.com/best-practices-document-classification-deep-learning/](https://machinelearningmastery.com/best-practices-document-classification-deep-learning/)'
- en: '[https://keras.io/layers/embeddings/](https://keras.io/layers/embeddings/)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://keras.io/layers/embeddings/](https://keras.io/layers/embeddings/)'
- en: '[https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)'
- en: '[https://pytorch.org/docs/master/nn.html](https://pytorch.org/docs/stable/nn.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://pytorch.org/docs/master/nn.html](https://pytorch.org/docs/stable/nn.html)'
- en: '[https://stackoverflow.com/a/35688187](https://stackoverflow.com/a/35688187)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://stackoverflow.com/a/35688187](https://stackoverflow.com/a/35688187)'
- en: '[http://www.brightideasinanalytics.com/rnn-pretrained-word-vectors/](http://www.brightideasinanalytics.com/rnn-pretrained-word-vectors/)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[http://www.brightideasinanalytics.com/rnn-pretrained-word-vectors/](http://www.brightideasinanalytics.com/rnn-pretrained-word-vectors/)'
- en: Chapter 7
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章
- en: '[https://developer.android.com/training/basics/firstapp/](https://developer.android.com/training/basics/firstapp/)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://developer.android.com/training/basics/firstapp/](https://developer.android.com/training/basics/firstapp/)'
- en: '[https://github.com/sszuev/fastText_java](https://github.com/sszuev/fastText_java)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/sszuev/fastText_java](https://github.com/sszuev/fastText_java)'
- en: '[https://stackoverflow.com/a/35369267](https://stackoverflow.com/a/35369267)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://stackoverflow.com/a/35369267](https://stackoverflow.com/a/35369267)'
- en: '[https://developer.android.com/studio/publish/app-signing](https://developer.android.com/studio/publish/app-signing)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://developer.android.com/studio/publish/app-signing](https://developer.android.com/studio/publish/app-signing)'
- en: '[https://github.com/vinhkhuc/JFastText/blob/master/examples/api/src/main/java/ApiExample.java](https://github.com/vinhkhuc/JFastText/blob/master/examples/api/src/main/java/ApiExample.java)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/vinhkhuc/JFastText/blob/master/examples/api/src/main/java/ApiExample.java](https://github.com/vinhkhuc/JFastText/blob/master/examples/api/src/main/java/ApiExample.java)'
- en: 'The fastText issues: [https://github.com/vinhkhuc/JFastText/issues/28](https://github.com/vinhkhuc/JFastText/issues/28)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: fastText 问题： [https://github.com/vinhkhuc/JFastText/issues/28](https://github.com/vinhkhuc/JFastText/issues/28)
- en: '[https://github.com/linkfluence/fastText4j/tree/master/src/main/java/fasttext](https://github.com/linkfluence/fastText4j/tree/master/src/main/java/fasttext)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/linkfluence/fastText4j/tree/master/src/main/java/fasttext](https://github.com/linkfluence/fastText4j/tree/master/src/main/java/fasttext)'
