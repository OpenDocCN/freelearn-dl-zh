- en: Chapter 5. Improved GANs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章：改进的GAN
- en: Since the introduction of the **Generative Adversarial Networks** (**GAN**s)
    in 2014[1], its popularity has rapidly increased. GANs have proved to be a useful
    generative model that can synthesize new data that look real. Many of the research
    papers in deep learning that followed, proposed measures to address the difficulties
    and limitations of the original GAN.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 自从2014年**生成对抗网络**（**GAN**）[1]被提出以来，它的普及速度迅速增加。GAN已被证明是一种有效的生成模型，能够合成看起来真实的新数据。随后的许多深度学习研究论文都提出了应对原始GAN困难和局限性的措施。
- en: As we discussed in previous chapters, GANs can be notoriously difficult to train
    and prone to mode collapse. Mode collapse is a situation where the generator is
    producing outputs that look the same even though the loss functions are already
    optimized. In the context of MNIST digits, with mode collapse, the generator may only
    be producing digits 4 and 9 since they look similar. **Wasserstein GAN** (**WGAN**)[2]
    addressed these problems by arguing that stable training and mode collapse can
    be avoided by simply replacing the GAN loss function based on Wasserstein 1 or
    **Earth-Mover distance** (**EMD**).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在前几章所讨论的那样，GAN训练 notoriously 难以进行，并且容易发生模式崩塌。模式崩塌是指生成器即使在损失函数已优化的情况下，也会生成看起来相同的输出。在MNIST数字的情境中，若发生模式崩塌，生成器可能只会生成数字4和9，因为它们看起来相似。**瓦瑟斯坦GAN**（**WGAN**）[2]通过认为可以通过简单地替换基于Wasserstein
    1或**地球搬运距离**（**EMD**）的GAN损失函数来避免稳定性训练和模式崩塌，解决了这些问题。
- en: However, the issue of stability is not the only problem of GANs. There is also
    the increasing need to improve the perceptive quality of the generated images.
    **Least Squares GAN** (**LSGAN**)[3] proposed to address both these problems simultaneously.
    The basic premise is that sigmoid cross entropy loss leads to a vanishing gradient
    during training. This results in poor image quality. Least squares loss does not
    induce vanishing gradients. The resulting generated images are of higher perceptive
    quality when compared to vanilla GAN generated images.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，稳定性问题并不是GAN唯一的难题。还有一个日益迫切的需求是提升生成图像的感知质量。**最小二乘GAN**（**LSGAN**）[3]提出了同时解决这两个问题的方法。基本前提是sigmoid交叉熵损失在训练过程中会导致梯度消失，这会导致图像质量差。最小二乘损失不会引发梯度消失。与传统的GAN生成图像相比，采用最小二乘损失生成的图像在感知质量上有显著提高。
- en: In the previous chapter, CGAN introduced a method for conditioning the output
    of the generator. For example, if we wanted to get digit 8, we would include the
    conditioning label in the input to the generator. Inspired by CGAN, the **Auxiliary
    Classifier GAN** (**ACGAN**)[4] proposed a modified conditional algorithm that
    results in better perceptive quality and diversity of the outputs.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，CGAN介绍了一种对生成器输出进行条件控制的方法。例如，如果我们想要得到数字8，我们会在输入生成器时加入条件标签。受CGAN启发，**辅助分类器GAN**（**ACGAN**）[4]提出了一种改进的条件算法，从而使得输出的感知质量和多样性得到了更好的提升。
- en: 'In summary, the goal of this chapter is to introduce these improved GANs and
    to present:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本章的目标是介绍这些改进的GAN并展示：
- en: The theoretical formulation of the WGAN
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WGAN的理论公式
- en: An understanding of the principles of LSGAN
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解LSGAN的原理
- en: An understanding of the principles of ACGAN
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解ACGAN的原理
- en: Knowledge of how to implement improved GANs - WGAN, LSGAN, and ACGAN using Keras
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知道如何使用Keras实现改进的GAN——WGAN、LSGAN和ACGAN
- en: Wasserstein GAN
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 瓦瑟斯坦GAN
- en: As we've mentioned before, GANs are notoriously hard to train. The opposing
    objectives of the two networks, the discriminator and the generator, can easily
    cause training instability. The discriminator attempts to correctly classify the
    fake data from the real data. Meanwhile, the generator tries its best to trick
    the discriminator. If the discriminator learns faster than the generator, the
    generator parameters will fail to optimize. On the other hand, if the discriminator
    learns more slowly, then the gradients may vanish before reaching the generator.
    In the worst case, if the discriminator is unable to converge, the generator is
    not going to be able to get any useful feedback.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前提到的，GAN的训练是非常困难的。两个网络——判别器和生成器的对立目标很容易导致训练不稳定。判别器试图正确区分真假数据，而生成器则尽力欺骗判别器。如果判别器学习得比生成器快，生成器的参数就无法得到优化。另一方面，如果判别器学习得较慢，那么梯度可能在到达生成器之前就消失了。在最糟糕的情况下，如果判别器无法收敛，生成器将无法获得任何有用的反馈。
- en: Distance functions
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 距离函数
- en: The stability in training a GAN can be understood by examining its loss functions. To better
    understand the GAN loss functions, we're going to review the common distance or
    divergence functions between two probability distributions. Our concern is the
    distance between *p*[data] for true data distribution and *p*[g] for generator
    data distribution. The goal of GANs is to make *p* [g] → *p*[data]. *Table 5.1.1*
    shows the divergence functions.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 GAN 的稳定性可以通过检查其损失函数来理解。为了更好地理解 GAN 的损失函数，我们将回顾两个概率分布之间的常见距离或散度函数。我们关心的是 *p*[data]（真实数据分布）与
    *p*[g]（生成器数据分布）之间的距离。GAN 的目标是使 *p*[g] → *p*[data]。*表 5.1.1* 显示了这些散度函数。
- en: In most maximum likelihood tasks, we'll use **Kullback-Leibler** (**KL**) divergence
    or *D*[KL] in the loss function as a measure of how far our neural network model
    prediction is from the true distribution function. As shown in *Equation* *5.1.1*,
    *D*[KL] is not symmetric since ![Distance functions](img/B08956_05_001.jpg).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数最大似然任务中，我们将使用 **Kullback-Leibler** (**KL**) 散度或 *D*[KL] 作为损失函数中的度量，来衡量我们神经网络模型预测与真实分布函数之间的差距。如
    *方程* *5.1.1* 所示，*D*[KL] 是不对称的，因为![距离函数](img/B08956_05_001.jpg)。
- en: '**Jensen-Shannon** (**JS**) or *D*[JS] is a divergence that is based on *D*[KL].
    However, unlike *D*[KL], *D*[JS] is symmetrical and will be finite. In this section,
    we''ll show that optimizing the GAN loss functions is equivalent to optimizing
    *D*[JS].'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**Jensen-Shannon** (**JS**) 或 *D*[JS] 是基于 *D*[KL] 的散度。然而，与 *D*[KL] 不同，*D*[JS]
    是对称的，并且是有限的。在这一部分，我们将展示优化 GAN 损失函数等价于优化 *D*[JS]。'
- en: '| Divergence | Expression |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| 散度 | 表达式 |'
- en: '| --- | --- |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Kullback-Leibler (KL)5.1.1 | ![Distance functions](img/B08956_05_002.jpg)![Distance
    functions](img/B08956_05_03.jpg) |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| Kullback-Leibler (KL) 5.1.1 | ![距离函数](img/B08956_05_002.jpg)![距离函数](img/B08956_05_03.jpg)
    |'
- en: '| Jensen-Shannon (JS)5.1.2 | ![Distance functions](img/B08956_05_004.jpg) |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| Jensen-Shannon (JS) 5.1.2 | ![距离函数](img/B08956_05_004.jpg) |'
- en: '| Earth-Mover Distance (EMD) or Wasserstein 15.1.3 | ![Distance functions](img/B08956_05_005.jpg)where![Distance
    functions](img/B08956_05_006.jpg) is the set of all joint distributions *y(x,y)*
    whose marginal are *p*[data] and *p*[g]. |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| Earth-Mover Distance (EMD) 或 Wasserstein 15.1.3 | ![距离函数](img/B08956_05_005.jpg)，其中![距离函数](img/B08956_05_006.jpg)
    是所有联合分布 *y(x,y)* 的集合，其边际分布为 *p*[data] 和 *p*[g]。 |'
- en: 'Table 5.1.1: The divergence functions between two probability distribution
    functions *p*[data] and *p*[g]'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5.1.1：两个概率分布函数 *p*[data] 和 *p*[g] 之间的散度函数
- en: '![Distance functions](img/B08956_05_01.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![距离函数](img/B08956_05_01.jpg)'
- en: 'Figure 5.1.1: The EMD is the weighted amount of mass from **x** to be transported
    in order to match the target distribution, **y**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1.1：EMD 是从 **x** 到目标分布 **y** 所需运输的质量的加权量
- en: The intuition behind EMD is that it is a measure of how much mass ![Distance
    functions](img/B08956_05_008.jpg) should be transported by *d* = ||*x* - *y*||
    for the probability distribution *p*[data] in order to match the probability distribution
    *p*[g]. ![Distance functions](img/B08956_05_009.jpg)is a joint distribution in
    the space of all possible joint distributions ![Distance functions](img/B08956_05_010.jpg).
    ![Distance functions](img/B08956_05_011.jpg) is also known as a transport plan
    to reflect the strategy for transporting masses to match the two probability distributions.
    There are many possible transport plans given the two probability distributions.
    Roughly speaking, *inf* indicates a transport plan with the minimum cost.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: EMD（地球搬运距离）的直觉是，它衡量了概率分布 *p*[data] 在与概率分布 *p*[g] 匹配时，需要通过 *d* = ||*x* - *y*||
    运输的质量量！[距离函数](img/B08956_05_008.jpg)。![距离函数](img/B08956_05_009.jpg)是所有可能的联合分布空间中的一个联合分布！[距离函数](img/B08956_05_010.jpg)。![距离函数](img/B08956_05_011.jpg)
    也称为运输计划，用于反映将质量运输到以匹配两个概率分布的策略。给定这两个概率分布，有许多可能的运输计划。粗略来说，*inf* 表示具有最小成本的运输计划。
- en: 'For example, *Figure 5.1.1* shows us two simple discrete distributions ![Distance
    functions](img/B08956_05_012.jpg) and ![Distance functions](img/B08956_05_013.jpg).
    ![Distance functions](img/B08956_05_014.jpg) has masses *m* *i* *for* i = 1, 2,
    3 and 4 at locations *x* *i* * for* i = 1, 2, 3 and 4\. Meanwhile ![Distance functions](img/B08956_05_015.jpg)
    has masses *m* *i* * for* i =1 and 2 at locations *y* *i* * for* i = 1 and 2\.
    To match the distribution ![Distance functions](img/B08956_05_016.jpg), the arrows
    show the minimum transport plan to move each mass *x* *i* by *d* *i*. The EMD
    is computed as:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，*图 5.1.1*展示了两个简单的离散分布![距离函数](img/B08956_05_012.jpg)和![距离函数](img/B08956_05_013.jpg)。![距离函数](img/B08956_05_014.jpg)在位置
    *x* *i*（i = 1, 2, 3 和 4）上有质量 *m* *i*，同时![距离函数](img/B08956_05_015.jpg)在位置 *y* *i*（i
    = 1 和 2）上有质量 *m* *i*。为了匹配分布![距离函数](img/B08956_05_016.jpg)，箭头展示了将每个质量 *x* *i* 移动
    *d* *i* 的最小运输方案。EMD计算公式为：
- en: '![Distance functions](img/B08956_05_017.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![距离函数](img/B08956_05_017.jpg)'
- en: (Equation 5.1.4)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: （方程 5.1.4）
- en: In *Figure 5.1.1*, the EMD can be interpreted as the least amount of work needed
    to move the pile of dirt ![Distance functions](img/B08956_05_018.jpg) to fill
    the hole ![Distance functions](img/B08956_05_019.jpg). While in this example,
    the *inf* can also be deduced from the figure, in most cases especially in continuous
    distributions, it is intractable to exhaust all possible transport plans. We will
    come back to this problem later on in this chapter. In the meantime, we'll show
    how the GAN loss functions are, in fact, minimizing the **Jensen-Shannon** (**JS**)
    divergence.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 5.1.1*中，EMD可以被解释为将土堆![距离函数](img/B08956_05_018.jpg)移到填满孔洞![距离函数](img/B08956_05_019.jpg)所需的最少工作量。虽然在这个例子中，*inf*也可以从图中推导出来，但在大多数情况下，特别是对于连续分布，穷举所有可能的运输方案是不可行的。我们将在本章稍后回到这个问题。与此同时，我们将展示GAN损失函数实际上是在最小化**詹森-香农**(**JS**)散度。
- en: Distance function in GANs
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GAN中的距离函数
- en: 'We''re now going to compute the optimal discriminator given any generator from
    the loss function in the previous chapter. We''ll recall the following equation:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将根据上一章中的损失函数，计算给定任何生成器的最优判别器。我们将回顾以下方程：
- en: '![Distance function in GANs](img/B08956_05_020.jpg) (Equation 4.1.1)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_020.jpg)（方程 4.1.1）'
- en: 'Instead of sampling from the noise distribution, the preceding equation can
    also be expressed as sampling from the generator distribution:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 除了从噪声分布进行采样，前述方程还可以表示为从生成器分布进行采样：
- en: '![Distance function in GANs](img/B08956_05_021.jpg) (Equation 5.1.5)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_021.jpg)（方程 5.1.5）'
- en: 'To find the minimum ![Distance function in GANs](img/B08956_05_022.jpg):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到最小值![GAN中的距离函数](img/B08956_05_022.jpg)：
- en: '![Distance function in GANs](img/B08956_05_023.jpg) (Equation 5.1.6)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_023.jpg)（方程 5.1.6）'
- en: '![Distance function in GANs](img/B08956_05_024.jpg) (Equation 5.1.7)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_024.jpg)（方程 5.1.7）'
- en: 'The term inside the integral is in the form of *y* → *a* log *y* + *b* log(1
    - *y*) which has a known maximum value at ![Distance function in GANs](img/B08956_05_025.jpg)
    for ![Distance function in GANs](img/B08956_05_026.jpg), for any ![Distance function
    in GANs](img/B08956_05_027.jpg) not including {0,0}. Since the integral does not
    change the location of the maximum value (or the minimum value of ![Distance function
    in GANs](img/B08956_05_028.jpg)) for this expression, the optimal discriminator
    is:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 积分内部的项呈 *y* → *a* log *y* + *b* log(1 - *y*) 形式，该式在![GAN中的距离函数](img/B08956_05_025.jpg)处达到已知的最大值，对于任何![GAN中的距离函数](img/B08956_05_026.jpg)，不包括
    {0,0} 的![GAN中的距离函数](img/B08956_05_027.jpg) 都成立。由于积分不会改变该表达式的最大值位置（或![GAN中的距离函数](img/B08956_05_028.jpg)的最小值），因此最优判别器为：
- en: '![Distance function in GANs](img/B08956_05_029.jpg) (Equation 5.1.8)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_029.jpg)（方程 5.1.8）'
- en: 'Consequently, the loss function is given the optimal discriminator:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，损失函数给出了最优判别器：
- en: '![Distance function in GANs](img/B08956_05_030.jpg) (Equation 5.1.9)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_030.jpg)（方程 5.1.9）'
- en: '![Distance function in GANs](img/B08956_05_031.jpg) (Equation 5.1.10)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_031.jpg)（方程 5.1.10）'
- en: '![Distance function in GANs](img/B08956_05_032.jpg) (Equation 5.1.11)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_032.jpg)（方程 5.1.11）'
- en: '![Distance function in GANs](img/B08956_05_033.jpg) (Equation 5.1.12)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_033.jpg)（方程 5.1.12）'
- en: We can observe from *Equation 5.1.12* that the loss function of the optimal
    discriminator is a constant minus twice the Jensen-Shannon divergence between
    the true distribution, *p*[data], and any generator distribution, *p*[g]. Minimizing
    ![Distance function in GANs](img/B08956_05_034.jpg) implies maximizing ![Distance
    function in GANs](img/B08956_05_035.jpg) or the discriminator must correctly classify
    fake from real data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从*方程5.1.12*中观察到，最优判别器的损失函数是一个常数减去真实分布*p*[data]与任何生成器分布*p*[g]之间的两倍Jensen-Shannon散度。最小化![GAN中的距离函数](img/B08956_05_034.jpg)意味着最大化![GAN中的距离函数](img/B08956_05_035.jpg)，或者判别器必须正确区分假数据和真实数据。
- en: 'Meanwhile, we can safely argue that the optimal generator is when the generator
    distribution is equal to the true data distribution:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，我们可以合理地认为，最优生成器是当生成器分布等于真实数据分布时：
- en: '![Distance function in GANs](img/B08956_05_036.jpg) (Equation 5.1.13)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_036.jpg)（方程5.1.13）'
- en: This makes sense since the objective of the generator is to fool the discriminator
    by learning the true data distribution. Effectively, we can arrive at the optimal
    generator by minimizing *D*[JS]*,* or by making *p*[g] → *p*[data]. Given an optimal
    generator, the optimal discriminator is ![Distance function in GANs](img/B08956_05_037.jpg)
    with ![Distance function in GANs](img/B08956_05_038.jpg).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是有道理的，因为生成器的目标是通过学习真实数据分布来欺骗判别器。实际上，我们可以通过最小化*D*[JS]*，*，或者通过使*p*[g] → *p*[data]来得到最优生成器。给定最优生成器，最优判别器是![GAN中的距离函数](img/B08956_05_037.jpg)，并且![GAN中的距离函数](img/B08956_05_038.jpg)。
- en: '![Distance function in GANs](img/B08956_05_02.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_02.jpg)'
- en: 'Figure 5.1.2: An example of two distributions with no overlap. ![Distance function
    in GANs](img/B08956_05_039.jpg) for *p*[g]'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1.2：没有重叠的两个分布示例。![GAN中的距离函数](img/B08956_05_039.jpg) 适用于*p*[g]
- en: 'The problem is that when the two distributions have no overlap, there''s no
    smooth function that will help to close the gap between them. Training the GANs
    will not converge by gradient descent. For example, let''s suppose:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是，当两个分布没有重叠时，没有平滑的函数可以帮助缩小它们之间的差距。通过梯度下降训练GAN将无法收敛。例如，假设：
- en: '*p*[data] =(*x*, *y*) where ![Distance function in GANs](img/B08956_05_040.jpg)
    (Equation 5.1.14)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*p*[data] = (*x*, *y*) 其中![GAN中的距离函数](img/B08956_05_040.jpg)（方程5.1.14）'
- en: '*p*[g] = (*x*, *y*) where ![Distance function in GANs](img/B08956_05_041.jpg)
    (Equation 5.1.15)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*p*[g] = (*x*, *y*) 其中![GAN中的距离函数](img/B08956_05_041.jpg)（方程5.1.15）'
- en: 'As shown in *Figure 5.1.2*. *U*(0,1) is the uniform distribution. The divergence
    for each distance function is as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图5.1.2*所示，*U*(0,1)是均匀分布。每个距离函数的散度如下：
- en: '![Distance function in GANs](img/B08956_05_42.jpg)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_42.jpg)'
- en: '![Distance function in GANs](img/B08956_05_043.jpg)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_043.jpg)'
- en: '![Distance function in GANs](img/B08956_05_44.jpg)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_44.jpg)'
- en: '![Distance function in GANs](img/B08956_05_045.jpg)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_IMG
  zh: '![GAN中的距离函数](img/B08956_05_045.jpg)'
- en: Since *D*[JS] is a constant, the GAN will not have a sufficient gradient to
    drive *p*[g] → *p*[data]. We'll also find that *D*[KL] or reverse *D*[KL] is not
    helpful either. However, with *W*(*p*[data],*p*[g]) we can have a smooth function
    in order to attain *p*[g] → *p*[data] by gradient descent. EMD or Wasserstein
    1 seems to be a more logical loss function in order to optimize GANs since *D*[JS]
    fails in situations when two distributions have minimal to no overlap.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 由于*D*[JS]是一个常数，GAN将没有足够的梯度来驱动*p*[g] → *p*[data]。我们还会发现*D*[KL]或反向*D*[KL]也无济于事。然而，通过*W*（*p*[data]，*p*[g]）我们可以得到一个平滑的函数，以便通过梯度下降使*p*[g]
    → *p*[data]。EMD或Wasserstein 1似乎是优化GAN的更合适的损失函数，因为*D*[JS]在两个分布几乎没有重叠的情况下无法发挥作用。
- en: For further understanding, an excellent discussion on distance functions can
    be found at [https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-W](https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-W)
    [GAN.html](http://GAN.html).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步理解，关于距离函数的精彩讨论可以在[https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-W](https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-W)
    [GAN.html](http://GAN.html)找到。
- en: Use of Wasserstein loss
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Wasserstein损失的使用
- en: 'Before using EMD or Wasserstein 1, there is one more problem to overcome. It
    is intractable to exhaust the space of ![Use of Wasserstein loss](img/B08956_05_046.jpg)
    to find ![Use of Wasserstein loss](img/B08956_05_047.jpg). The proposed solution
    is to use its Kantorovich-Rubinstein dual:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用EMD或Wasserstein 1之前，还需要克服一个问题。穷举![Wasserstein损失的使用](img/B08956_05_046.jpg)空间以找到![Wasserstein损失的使用](img/B08956_05_047.jpg)是不可行的。提出的解决方案是使用其Kantorovich-Rubinstein对偶：
- en: '![Use of Wasserstein loss](img/B08956_05_048.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_048.jpg)'
- en: (Equation 5.1.16)
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: （方程5.1.16）
- en: 'Equivalently, EMD, ![Use of Wasserstein loss](img/B08956_05_049.jpg), is the
    supremum (roughly, maximum value) over all the *K*-Lipschitz functions: ![Use
    of Wasserstein loss](img/B08956_05_050.jpg). *K*-Lipschitz functions satisfy the
    constraint:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 等价地，EMD，![Wasserstein损失的使用](img/B08956_05_049.jpg)，是所有*K*-Lipschitz函数的上确界（大致为最大值）：![Wasserstein损失的使用](img/B08956_05_050.jpg)。*K*-Lipschitz函数满足以下约束：
- en: '![Use of Wasserstein loss](img/B08956_05_51.jpg) (Equation 5.1.17)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_51.jpg) （方程5.1.17）'
- en: For all ![Use of Wasserstein loss](img/B08956_05_052.jpg), the *K*-Lipschitz
    functions have bounded derivatives and almost always continuously differentiable
    (for example, *f*(*x*), = |*x*| has bounded derivatives and continuous but not
    differentiable at *x* = 0).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有![Wasserstein损失的使用](img/B08956_05_052.jpg)，*K*-Lipschitz函数具有有界导数，且几乎总是连续可微（例如，*f*(*x*)
    = |*x*|具有有界导数且连续，但在*x* = 0处不可微）。
- en: '*Equation 5.1.16* can be solved by finding a family of *K*-Lipschitz functions
    ![Use of Wasserstein loss](img/B08956_05_053.jpg):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '*方程5.1.16*可以通过找到一系列*K*-Lipschitz函数来求解![Wasserstein损失的使用](img/B08956_05_053.jpg)：'
- en: '![Use of Wasserstein loss](img/B08956_05_54.jpg) (Equation 5.1.18)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_54.jpg) （方程5.1.18）'
- en: 'In the context of GANs, *Equation* *5.1.18* can be rewritten by sampling from
    *z*-noise distribution and replacing *f*[w] by the discriminator function, *D*[w]:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在GAN的上下文中，*方程* *5.1.18* 可以通过从*z*-噪声分布采样并将*f*[w]替换为判别器函数*D*[w]来重写：
- en: '![Use of Wasserstein loss](img/B08956_05_55.jpg) (Equation 5.1.19)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_55.jpg) （方程5.1.19）'
- en: 'We use the bold letter to highlight the generality to multi-dimensional samples.
    The final problem we face is how to find the family of functions ![Use of Wasserstein
    loss](img/B08956_05_056.jpg). The proposed solution we''re going to go over is
    that at every gradient update, the weights of the discriminator, *w*, are clipped
    between lower and upper bounds, (for example, -0.0,1 and 0.01):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用粗体字母来突出显示多维样本的通用性。我们面临的最终问题是如何找到函数系列![Wasserstein损失的使用](img/B08956_05_056.jpg)。我们将要讨论的提议解决方案是，在每次梯度更新时，判别器的权重*w*在下界和上界之间裁剪（例如，-0.0,
    1 和 0.01）：
- en: '![Use of Wasserstein loss](img/B08956_05_57.jpg) (Equation 5.1.20)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_57.jpg) （方程5.1.20）'
- en: The small values of *w* constrains the discriminator to a compact parameter
    space thus ensuring Lipschitz continuity.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*w*的较小值限制了判别器在紧凑的参数空间中，从而确保了Lipschitz连续性。'
- en: 'We can use *Equation 5.1.19* as the basis of our new GAN loss functions. EMD
    or Wasserstein 1 is the loss function that the generator aims to minimize, and
    the cost function that the discriminator tries to maximize (or minimize -*W*(*p*[data],*p*[g])):'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用*方程5.1.19*作为我们新GAN损失函数的基础。EMD或Wasserstein 1是生成器试图最小化的损失函数，而判别器试图最大化（或最小化-*W*(*p*[数据],
    *p*[生成]))：
- en: '![Use of Wasserstein loss](img/B08956_05_058.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_058.jpg)'
- en: (Equation 5.1.21)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: （方程5.1.21）
- en: '![Use of Wasserstein loss](img/B08956_05_59.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_59.jpg)'
- en: (Equation 5.1.22)
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: （方程5.1.22）
- en: In the generator loss function, the first term disappears since it is not directly
    optimizing with respect to the real data.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成器损失函数中，第一个项会消失，因为它并没有直接与真实数据进行优化。
- en: 'Following table shows the difference between the loss functions of GAN and
    WGAN. For conciseness, we''ve simplified the notation for ![Use of Wasserstein
    loss](img/B08956_05_060.jpg), and ![Use of Wasserstein loss](img/B08956_05_061.jpg).
    These loss functions are used in training the WGAN as shown in *Algorithm* *5.1.1*.
    *Figure 5.1.3* illustrates that the WGAN model is practically the same as the
    DCGAN model except for the fake/true data labels and loss functions:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格展示了GAN和WGAN的损失函数之间的差异。为简洁起见，我们简化了![Wasserstein损失的使用](img/B08956_05_060.jpg)
    和![Wasserstein损失的使用](img/B08956_05_061.jpg)的符号。这些损失函数用于训练WGAN，如*算法* *5.1.1*所示。*图5.1.3*展示了WGAN模型实际上与DCGAN模型相同，唯一的区别在于假数据/真实数据标签和损失函数：
- en: '| Network | Loss Functions | Equation |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 网络 | 损失函数 | 方程 |'
- en: '| --- | --- | --- |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| GAN | ![Use of Wasserstein loss](img/B08956_05_062.jpg)![Use of Wasserstein
    loss](img/B08956_05_063.jpg) | 4.1.14.1.5 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| GAN | ![Wasserstein损失的使用](img/B08956_05_062.jpg)![Wasserstein损失的使用](img/B08956_05_063.jpg)
    | 4.1.14.1.5 |'
- en: '| WGAN | ![Use of Wasserstein loss](img/B08956_05_064.jpg)![Use of Wasserstein
    loss](img/B08956_05_065.jpg)![Use of Wasserstein loss](img/B08956_05_066.jpg)
    | 5.1.215.1.225.1.20 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| WGAN | ![Wasserstein损失的使用](img/B08956_05_064.jpg)![Wasserstein损失的使用](img/B08956_05_065.jpg)![Wasserstein损失的使用](img/B08956_05_066.jpg)
    | 5.1.215.1.225.1.20 |'
- en: 'Table 5.1.1: A comparison between the loss functions of GAN and WGAN'
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 表 5.1.1：GAN与WGAN的损失函数比较
- en: '**Algorithm 5.1.1 WGAN**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**算法 5.1.1 WGAN**'
- en: The values of the parameters are ![Use of Wasserstein loss](img/B08956_05_067.jpg),
    *c* = 0.01 *m* = 64, and *n*[critic] = 5.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 参数的值是![Wasserstein损失的使用](img/B08956_05_067.jpg)，*c* = 0.01，*m* = 64，*n*[critic]
    = 5。
- en: '*Require*: ![Use of Wasserstein loss](img/B08956_05_068.jpg), the learning
    rate. *c*, the clipping parameter. *m*, the batch size. *n*[critic], the number
    of the critic (discriminator) iterations per generator iteration.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*需要*：![Wasserstein损失的使用](img/B08956_05_068.jpg)，学习率。*c*，裁剪参数。*m*，批量大小。*n*[critic]，每个生成器迭代中的判别器（鉴别器）迭代次数。'
- en: '*Require*: *w*[0], initial critic (discriminator) parameters. ![Use of Wasserstein
    loss](img/B08956_05_069.jpg), initial generator parameters'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*需要*：*w*[0]，初始判别器（鉴别器）参数。![Wasserstein损失的使用](img/B08956_05_069.jpg)，初始生成器参数'
- en: '`while`![Use of Wasserstein loss](img/B08956_05_070.jpg)'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`while`![Wasserstein损失的使用](img/B08956_05_070.jpg)'
- en: has not converged `do`
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 尚未收敛`do`
- en: '`for` *t* = 1, …, *n*[critic]`do`'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`for` *t* = 1, …, *n*[critic]`do`'
- en: Sample a batch![Use of Wasserstein loss](img/B08956_05_071.jpg)
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从均匀噪声分布中采样一个批次![Wasserstein损失的使用](img/B08956_05_071.jpg)
- en: from the real data
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 来自真实数据
- en: Sample a batch![Use of Wasserstein loss](img/B08956_05_72.jpg)
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从均匀噪声分布中采样一个批次![Wasserstein损失的使用](img/B08956_05_72.jpg)
- en: from the uniform noise distribution
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 来自均匀噪声分布
- en: '![Use of Wasserstein loss](img/B08956_05_073.jpg)'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_073.jpg)'
- en: ', compute the discriminator gradients'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ，计算鉴别器梯度
- en: '![Use of Wasserstein loss](img/B08956_05_074.jpg)'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_074.jpg)'
- en: ', update the discriminator parameters'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ，更新鉴别器参数
- en: '![Use of Wasserstein loss](img/B08956_05_075.jpg)'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_075.jpg)'
- en: ', clip discriminator weights'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ，裁剪鉴别器权重
- en: '`end for`'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`end for`'
- en: Sample a batch![Use of Wasserstein loss](img/B08956_05_076.jpg)
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从均匀噪声分布中采样一个批次![Wasserstein损失的使用](img/B08956_05_076.jpg)
- en: from the uniform noise distribution
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 来自均匀噪声分布
- en: '![Use of Wasserstein loss](img/B08956_05_077.jpg)'
  id: totrans-106
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_077.jpg)'
- en: ', compute the generator gradients'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ，计算生成器梯度
- en: '![Use of Wasserstein loss](img/B08956_05_078.jpg)'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_078.jpg)'
- en: ', update generator parameters'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ，更新生成器参数
- en: '`end while`'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`end while`'
- en: '![Use of Wasserstein loss](img/B08956_05_03.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_03.jpg)'
- en: 'Figure 5.1.3: Top: Training the WGAN discriminator requires fake data from
    the generator and real data from the true distribution. Bottom: Training the WGAN
    generator requires fake data from the generator pretending to be real.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1.3：上图：训练WGAN鉴别器需要来自生成器的假数据和来自真实分布的真实数据。下图：训练WGAN生成器需要来自生成器的假数据，这些数据假装是来自真实分布。
- en: Similar to GANs, WGAN alternately trains the discriminator and generator (through adversarial).
    However, in WGAN, the discriminator (also called the critic) trains *n*[critic]
    iterations (Lines 2 to 8) before training the generator for one iteration (Lines
    9 to 11). This in contrast to GANs with an equal number of training iteration
    for both discriminator and generator. Training the discriminator means learning
    the parameters (weights and biases) of the discriminator. This requires sampling
    a batch from the real data (Line 3) and a batch from the fake data (Line 4) and
    computing the gradient of discriminator parameters (Line 5) after feeding the
    sampled data to the discriminator network. The discriminator parameters are optimized
    using RMSProp (Line 6). Both lines 5 and 6 are the optimization of *Equation 5.1.21*.
    Adam was found to be unstable in WGAN.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于GAN，WGAN交替训练鉴别器和生成器（通过对抗）。然而，在WGAN中，鉴别器（也称为评论员）训练*n*[critic]次迭代（第2到第8行），然后再训练生成器一次迭代（第9到第11行）。与GAN相比，WGAN在训练过程中对鉴别器和生成器的训练次数不同。训练鉴别器意味着学习鉴别器的参数（权重和偏置）。这需要从真实数据中采样一个批次（第3行）和从假数据中采样一个批次（第4行），然后在将采样的数据传入鉴别器网络后计算鉴别器参数的梯度（第5行）。鉴别器参数使用RMSProp进行优化（第6行）。第5行和第6行是对*方程5.1.21*的优化。研究表明，在WGAN中，Adam优化器表现不稳定。
- en: Lastly, the Lipschitz constraint in the EM distance optimization is imposed
    by clipping the discriminator parameters (Line 7). Line 7 is the implementation
    of *Equation 5.1.20*. After *n*[critic] iterations of discriminator training,
    the discriminator parameters are frozen. The generator training starts by sampling
    a batch of fake data (Line 9). The sampled data is labeled as real (1.0) trying
    to fool the discriminator network. The generator gradients are computed in Line
    10 and optimized using the RMSProp in Line 11\. Lines 10 and 11 perform gradients
    update to optimize *Equation 5.1.22*.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，EM距离优化中的Lipschitz约束通过裁剪判别器参数（第7行）来施加。第7行实现了*方程5.1.20*。经过*n*[批评者]迭代的判别器训练后，判别器参数被冻结。生成器训练从采样一批假数据开始（第9行）。采样的数据被标记为真实（1.0），试图欺骗判别器网络。生成器的梯度在第10行计算，并在第11行使用RMSProp进行优化。第10行和第11行执行梯度更新，以优化*方程5.1.22*。
- en: After training the generator, the discriminator parameters are unfrozen, and
    another *n*[critic] discriminator training iterations start. We should take note
    that there is no need to freeze the generator parameters during discriminator
    training as the generator is only involved in the fabrication of data. Similar
    to GANs, the discriminator can be trained as a separate network. However, training
    the generator always requires the participation of the discriminator through the
    adversarial network since the loss is computed from the output of the generator
    network.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练完生成器后，判别器参数会被解冻，开始另一轮*n*[批评者]判别器训练迭代。需要注意的是，在判别器训练期间无需冻结生成器参数，因为生成器仅参与数据的生成。与GAN类似，判别器可以作为一个独立的网络进行训练。然而，训练生成器始终需要判别器的参与，因为损失是从生成器网络的输出计算的。
- en: 'Unlike GAN, in WGAN real data are labeled 1.0 while fake data are labeled -1.0
    as a workaround in computing the gradient in Line 5\. Lines 5-6 and 10-11 perform
    gradient update to optimize *Equations* *5.1.21* and *5.1.22* respectively. Each
    term in Lines 5 and 10 is modelled as:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 与GAN不同，在WGAN中，真实数据标记为1.0，而假数据标记为-1.0，这是为了在第5行计算梯度时作为一种解决方法。第5-6行和第10-11行执行梯度更新，分别优化*方程*
    *5.1.21*和*5.1.22*。第5行和第10行中的每一项都被建模为：
- en: '![Use of Wasserstein loss](img/B08956_05_079.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![Wasserstein损失的使用](img/B08956_05_079.jpg)'
- en: (Equation 5.1.23)
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: （方程5.1.23）
- en: 'Where *y*[label] = 1.0 for the real data and *y*[label] = -1.0 for the fake
    data. We removed the superscript (i) for simplicity of the notation. For discriminator,
    WGAN increases ![Use of Wasserstein loss](img/B08956_05_80.jpg) to minimize the
    loss function when training using the real data. When training using fake data,
    WGAN decreases ![Use of Wasserstein loss](img/B08956_05_081.jpg) to minimize the
    loss function. For the generator, WGAN increases ![Use of Wasserstein loss](img/B08956_05_082.jpg)
    as to minimize the loss function when the fake data is labeled as real during
    training. Note that *y*[label] has no direct contribution in the loss function
    other than its sign. In Keras, *Equation 5.1.23* is implemented as:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，*y*[标签] = 1.0表示真实数据，*y*[标签] = -1.0表示假数据。为了简化符号，我们移除了上标(i)。对于判别器，WGAN增加了![Wasserstein损失的使用](img/B08956_05_80.jpg)，以在使用真实数据进行训练时最小化损失函数。当使用假数据进行训练时，WGAN减少了![Wasserstein损失的使用](img/B08956_05_081.jpg)，以最小化损失函数。对于生成器，当假数据在训练过程中被标记为真实时，WGAN增加了![Wasserstein损失的使用](img/B08956_05_082.jpg)，以最小化损失函数。请注意，*y*[标签]在损失函数中的直接贡献仅限于它的符号。在Keras中，*方程5.1.23*实现为：
- en: '[PRE0]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: WGAN implementation using Keras
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Keras实现WGAN
- en: To implement WGAN within Keras, we can reuse the DCGAN implementation of GANs,
    something we introduced in the previous chapter. The DCGAN builder and utility
    functions are implemented in `gan.py` in `lib` folder as a module.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Keras中实现WGAN，我们可以重用前一章中介绍的GAN的DCGAN实现。DCGAN构建器和工具函数作为模块在`lib`文件夹中的`gan.py`中实现。
- en: 'The functions include:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 函数包括：
- en: '`generator()`: A generator model builder'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`generator()`: 生成器模型构建器'
- en: '`discriminator()`: Discriminator model builder'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`discriminator()`: 判别器模型构建器'
- en: '`train()`: DCGAN trainer'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train()`: DCGAN训练器'
- en: '`plot_images()`: Generic generator outputs plotter'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`plot_images()`: 通用生成器输出绘图工具'
- en: '`test_generator()`: Generic generator test utility'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`test_generator()`: 通用生成器测试工具'
- en: 'As shown in *Listing* *5.1.1*, we can build a discriminator by simply calling:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如*列表* *5.1.1*所示，我们可以通过简单调用来构建判别器：
- en: '[PRE1]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'WGAN uses linear output activation. For the generator, we execute:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: WGAN使用线性输出激活。对于生成器，我们执行：
- en: '[PRE2]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The overall network model in Keras is similar to the one seen in *Figure 4.2.1*
    for DCGAN.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Keras中的整体网络模型类似于*图4.2.1*中显示的DCGAN。
- en: '*Listing* *5.1.1* highlights the use of the RMSprop optimizer and Wasserstein
    loss function. The hyper-parameters in *Algorithm* *5.1.1* are used during training.
    *Listing* *5.1.2* is the training function that closely follows the *algorithm*.
    However, there is a minor tweak in the training of the discriminator. Instead
    of training the weights in a single combined batch of both real and fake data,
    we''ll train with one batch of real data first and then a batch of fake data.
    This tweak will prevent the gradient from vanishing because of the opposite sign
    in the label of real and fake data and the small magnitude of weights due to clipping.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表* *5.1.1* 强调了使用 RMSprop 优化器和 Wasserstein 损失函数。*算法* *5.1.1* 中的超参数在训练中使用。*列表*
    *5.1.2* 是紧密跟随该 *算法* 的训练函数。然而，在训练判别器时有一个小的调整。我们不再在一个包含真实和虚假数据的单一批次中训练权重，而是先使用一批真实数据进行训练，然后再使用一批虚假数据进行训练。这种调整将防止由于真实和虚假数据标签的符号相反以及由于裁剪导致的权重幅度较小而导致梯度消失。'
- en: Note
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'The complete code is available on GitHub:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 完整代码可在 GitHub 上找到：
- en: '[https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras](https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras](https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras)'
- en: '*Figure 5.1.4* shows the evolution of the WGAN outputs on MNIST dataset.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 5.1.4* 展示了 WGAN 在 MNIST 数据集上的输出演变。'
- en: 'Listing 5.1.1, `wgan-mnist-5.1.2.py`. The WGAN model instantiation and training.
    Both discriminator and generator use Wassertein 1 loss, `wasserstein_loss()`:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.1.1，`wgan-mnist-5.1.2.py`。WGAN 模型实例化和训练。判别器和生成器都使用 Wasserstein 1 损失，`wasserstein_loss()`：
- en: '[PRE3]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Listing 5.1.2, `wgan-mnist-5.1.2.py`. The training procedure for WGAN closely
    follows *Algorithm* *5.1.1*. The discriminator is trained *n*[critic] iterations
    per 1 generator training iteration:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 5.1.2，`wgan-mnist-5.1.2.py`。WGAN 的训练过程严格遵循 *算法* *5.1.1*。判别器每训练一次生成器，需要进行
    *n* [批判] 次迭代：
- en: '[PRE4]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![WGAN implementation using Keras](img/B08956_05_04.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Keras 实现的 WGAN](img/B08956_05_04.jpg)'
- en: 'Figure 5.1.4: The sample outputs of WGAN vs. training steps. WGAN does not
    suffer mode collapse in all the outputs during training and testing.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1.4：WGAN 的样本输出与训练步骤的对比。WGAN 在训练和测试过程中没有遭遇模式崩溃。
- en: WGAN is stable even under network configuration changes. For example, DCGAN is known
    to be unstable when batch normalization is inserted before the ReLU in the discriminator
    network. The same configuration is stable in WGAN.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在网络配置发生变化时，WGAN 也依然稳定。例如，众所周知，当批量归一化插入到判别器网络中的 ReLU 激活之前时，DCGAN 会变得不稳定。而相同的配置在
    WGAN 中是稳定的。
- en: 'Following figure shows us the outputs of both DCGAN and WGAN with batch normalization
    on the discriminator network:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了在判别器网络上应用批量归一化时，DCGAN 和 WGAN 的输出：
- en: '![WGAN implementation using Keras](img/B08956_05_05.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Keras 实现的 WGAN](img/B08956_05_05.jpg)'
- en: 'Figure 5.1.5: A comparison of the output of the DCGAN (Left) and WGAN (Right)
    when batch normalization is inserted before the ReLU activation in the discriminator
    network'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1.5：在判别器网络中，将批量归一化插入到 ReLU 激活之前时，DCGAN（左）和 WGAN（右）输出的对比
- en: 'Similar to the GAN training in the previous chapter, the trained model is saved
    on a file after 40,000 train steps. I would encourage you to run the trained generator
    model to see new synthesized MNIST digits images:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于上一章中的 GAN 训练，训练好的模型会在 40,000 次训练步骤后保存到文件中。我鼓励你运行训练好的生成器模型，查看生成的新 MNIST 数字图像：
- en: '[PRE5]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Least-squares GAN (LSGAN)
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最小二乘 GAN（LSGAN）
- en: As discussed in the previous section, the original GAN is difficult to train.
    The problem arises when the GAN optimizes its loss function; it's actually optimizing
    the *Jensen-Shannon* divergence, *D*[JS]. It is difficult to optimize *D*[JS]
    when there is little to no overlap between two distribution functions.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 正如上一节所讨论的，原始 GAN 很难训练。当 GAN 优化其损失函数时，实际上是在优化 *Jensen-Shannon* 散度，*D*[JS]。当两个分布函数之间几乎没有重叠时，优化
    *D*[JS] 是非常困难的。
- en: WGAN proposed to address the problem by using the EMD or Wasserstein 1 loss function
    which has a smooth differentiable function even when there is little or no overlap
    between the two distributions. However, WGAN is not concerned with the generated
    image quality. Apart from stability issues, there are still areas of improvement
    in terms of perceptive quality in the generated images of the original GAN. LSGAN
    theorizes that the twin problems can be solved simultaneously.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: WGAN提出了使用EMD或Wasserstein 1损失函数来解决这个问题，即使在两个分布几乎没有重叠的情况下，它也具有平滑的可微函数。然而，WGAN并不关注生成图像的质量。除了稳定性问题外，原始GAN生成的图像在感知质量方面仍有提升空间。LSGAN理论认为，这两个问题可以同时得到解决。
- en: LSGAN proposes the least squares loss. *Figure 5.2.1* demonstrates why the use
    of a sigmoid cross entropy loss in the GAN results in poorly generated data quality.
    Ideally, the fake samples distribution should be as close as possible to the true
    samples' distribution. However, for GANs, once the fake samples are already on the correct
    side of the decision boundary, the gradients vanish.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: LSGAN提出了最小二乘损失。*图5.2.1* 说明了为何在GAN中使用sigmoid交叉熵损失会导致生成的数据质量较差。理想情况下，假样本的分布应尽可能接近真实样本的分布。然而，对于GAN，一旦假样本已经处于正确的决策边界一侧，梯度就会消失。
- en: 'This prevents the generator from having enough motivation to improve the quality
    of the generated fake data. Fake samples far from the decision boundary will no
    longer attempt to move closer to the true samples'' distribution. Using the least
    squares loss function, the gradients do not vanish as long as the fake samples
    distribution is far from the real samples'' distribution. The generator will strive
    to improve its estimate of real density distribution even if the fake samples
    are already on the correct side of the decision boundary:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这防止了生成器有足够的动力来提升生成假数据的质量。远离决策边界的假样本将不再尝试接近真实样本的分布。使用最小二乘损失函数时，只要假样本分布远离真实样本分布，梯度就不会消失。即使假样本已经处于正确的决策边界一侧，生成器也会努力提高其对真实密度分布的估计：
- en: '![Least-squares GAN (LSGAN)](img/B08956_05_06.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![最小二乘GAN (LSGAN)](img/B08956_05_06.jpg)'
- en: 'Figure 5.2.1: Both real and fake samples distributions divided by respective
    decision boundaries: Sigmoid and Least squares'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2.1：真实样本和假样本的分布被各自的决策边界划分：Sigmoid和最小二乘
- en: '| Network | Loss Functions | Equation |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 网络 | 损失函数 | 方程 |'
- en: '| --- | --- | --- |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| GAN | ![Least-squares GAN (LSGAN)](img/B08956_05_083.jpg)![Least-squares
    GAN (LSGAN)](img/B08956_05_084.jpg) | 4.1.14.1.5 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| GAN | ![最小二乘GAN (LSGAN)](img/B08956_05_083.jpg)![最小二乘GAN (LSGAN)](img/B08956_05_084.jpg)
    | 4.1.14.1.5 |'
- en: '| LSGAN | ![Least-squares GAN (LSGAN)](img/B08956_05_085.jpg)![Least-squares
    GAN (LSGAN)](img/B08956_05_086.jpg) | 5.2.15.2.2 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| LSGAN | ![最小二乘GAN (LSGAN)](img/B08956_05_085.jpg)![最小二乘GAN (LSGAN)](img/B08956_05_086.jpg)
    | 5.2.15.2.2 |'
- en: 'Table 5.2.1: A comparison between the loss functions of GAN and LSGAN'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.2.1：GAN和LSGAN的损失函数比较
- en: The preceding table shows the comparison of the loss functions between GAN and
    LSGAN. Minimizing *Equation 5.2.1* or the discriminator loss function implies
    that the MSE between real data classification and true label 1.0 should be close
    to zero. In addition, the MSE between the fake data classification and the true
    label 0.0 should be close to zero.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 上表展示了GAN和LSGAN之间损失函数的比较。最小化*方程5.2.1*或判别器损失函数意味着真实数据分类与真实标签1.0之间的MSE应接近零。此外，假数据分类与真实标签0.0之间的MSE也应接近零。
- en: Similar to GANs, the LSGAN discriminator is trained to classify real from fake
    data samples. Minimizing *Equation 5.2.2* means fooling the discriminator to think
    that the generated fake sample data are real with label 1.0.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于GAN，LSGAN的判别器被训练来区分真实数据和假数据样本。最小化*方程5.2.2*意味着欺骗判别器，使其认为生成的假样本数据是标签为1.0的真实数据。
- en: 'Implementing LSGAN using the DCGAN code in the previous chapter as the basis requires
    few changes only. As shown in *Listing* *5.2.1*, the discriminator sigmoid activation
    is removed. The discriminator is built by calling:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上一章中的DCGAN代码作为基础来实现LSGAN只需少量更改。如*列表5.2.1*所示，移除了判别器的sigmoid激活函数。判别器通过以下方式构建：
- en: '[PRE6]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The generator is similar to the original DCGAN:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器类似于原始的DCGAN：
- en: '[PRE7]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Both the discriminator and adversarial loss functions are replaced by `mse`.
    All the network parameters are the same as in DCGAN. The network model of LSGAN
    in Keras is similar to *Figure 4.2.1* except that there is no linear or output
    activation. The training process is similar to that seen in DCGAN and is provided
    by the utility function:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器和对抗损失函数都被替换为 `mse`。所有网络参数与 DCGAN 中相同。LSGAN 在 Keras 中的网络模型与*图 4.2.1* 类似，唯一不同的是没有线性或输出激活。训练过程与
    DCGAN 中看到的相似，并由实用函数提供：
- en: '[PRE8]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Listing 5.2.1, `lsgan-mnist-5.2.1.py` shows how the discriminator and generator
    are the same in DCGAN except for the discriminator output activation and the use
    of MSE loss function:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 清单 5.2.1，`lsgan-mnist-5.2.1.py` 显示了判别器和生成器在 DCGAN 中是相同的，除了判别器输出激活和使用了 MSE 损失函数：
- en: '[PRE9]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Following figure shows generated samples after training LSGAN using the MNIST
    dataset for 40,000 training steps. The output images have better perceptual quality
    compared to *Figure 4.2.1* in DCGAN:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的图展示了使用 MNIST 数据集进行 40,000 步训练后，LSGAN 生成的样本。与 DCGAN 中的*图 4.2.1*相比，输出图像具有更好的感知质量：
- en: '![Least-squares GAN (LSGAN)](img/B08956_05_07.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![最小二乘 GAN (LSGAN)](img/B08956_05_07.jpg)'
- en: 'Figure 5.2.2: Sample outputs of LSGAN vs. training steps'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2.2：LSGAN 与训练步数的样本输出
- en: 'I encourage you to run the trained generator model to see the new synthesized
    MNIST digits images:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你运行训练好的生成器模型，查看新合成的 MNIST 数字图像：
- en: '[PRE10]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Auxiliary classifier GAN (ACGAN)
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 辅助分类器 GAN (ACGAN)
- en: 'ACGAN is similar in principle to the **Conditional GAN** (**CGAN**) that we
    discussed in the previous chapter. We''re going to compare both CGANand ACGAN.
    For both CGAN and ACGAN, the generator inputs are noise and its label. The output
    is a fake image belonging to the input class label. For CGAN, the inputs to the
    discriminator are an image (fake or real) and its label. The output is the probability
    that the image is real. For ACGAN, the input to the discriminator is an image,
    whilst the output is the probability that the image is real and its class label.
    Following figure highlights the difference between CGAN and ACGAN during generator
    training:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: ACGAN 在原理上与我们在上一章讨论的 **条件 GAN** (**CGAN**) 相似。我们将比较 CGAN 和 ACGAN。对于 CGAN 和 ACGAN，生成器的输入是噪声和标签。输出是属于输入类标签的假图像。对于
    CGAN，判别器的输入是图像（假图像或真实图像）及其标签。输出是图像为真实的概率。对于 ACGAN，判别器的输入是图像，而输出是图像为真实的概率及其类别标签。接下来的图突出显示了
    CGAN 和 ACGAN 在生成器训练中的区别：
- en: '![Auxiliary classifier GAN (ACGAN)](img/B08956_05_08.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![辅助分类器 GAN (ACGAN)](img/B08956_05_08.jpg)'
- en: 'Figure 5.3.1: CGAN vs. ACGAN generator training. The main difference is the
    input and output of the discriminator.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3.1：CGAN 与 ACGAN 生成器训练。主要区别在于判别器的输入和输出。
- en: Essentially, in CGAN we feed the network with side information (label). In ACGAN,
    we try to reconstruct the side information using an auxiliary class decoder network.
    ACGAN argued that forcing the network to do additional tasks is known to improve
    the performance of the original task. In this case, the additional task is image
    classification. The original task is the generation of fake images.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，在 CGAN 中，我们为网络提供边信息（标签）。在 ACGAN 中，我们尝试使用辅助类解码器网络来重建边信息。ACGAN 认为，强迫网络执行额外任务已被证明能提高原始任务的性能。在这种情况下，额外的任务是图像分类。原始任务是生成假图像。
- en: '| Network | Loss Functions | Number |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 网络 | 损失函数 | 数量 |'
- en: '| --- | --- | --- |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| CGAN | ![Auxiliary classifier GAN (ACGAN)](img/B08956_05_087.jpg)![Auxiliary
    classifier GAN (ACGAN)](img/B08956_05_088.jpg) | 4.3.14.3.2 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| CGAN | ![辅助分类器 GAN (ACGAN)](img/B08956_05_087.jpg)![辅助分类器 GAN (ACGAN)](img/B08956_05_088.jpg)
    | 4.3.14.3.2 |'
- en: '| ACGAN | ![Auxiliary classifier GAN (ACGAN)](img/B08956_05_089.jpg)![Auxiliary
    classifier GAN (ACGAN)](img/B08956_05_090.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '| ACGAN | ![辅助分类器 GAN (ACGAN)](img/B08956_05_089.jpg)![辅助分类器 GAN (ACGAN)](img/B08956_05_090.jpg)'
- en: 'Table 5.3.1: A comparison between the loss functions of CGAN and ACGAN'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5.3.1：CGAN 与 ACGAN 损失函数的比较
- en: '| 5.3.15.3.2 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 5.3.15.3.2 |'
- en: Preceding table shows the ACGAN loss functions as compared to CGAN. The ACGAN
    loss functions are the same as CGAN except for the additional classifier loss
    functions. Apart from the original task of identifying real from fake images (![Auxiliary
    classifier GAN (ACGAN)](img/B08956_05_091.jpg)), *Equation 5.3.1* of the discriminator
    has the additional task of correctly classifying real and fake images (![Auxiliary
    classifier GAN (ACGAN)](img/B08956_05_092.jpg)). *Equation* *5.3.2* of the generator
    means that apart from trying to fool the discriminator with fake images (![Auxiliary
    classifier GAN (ACGAN)](img/B08956_05_093.jpg)), it is asking the discriminator
    to correctly classify those fake images (![Auxiliary classifier GAN (ACGAN)](img/B08956_05_094.jpg)).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 上表展示了与CGAN相比的ACGAN损失函数。ACGAN的损失函数与CGAN相同，唯一不同的是额外的分类器损失函数。除了原本识别真假图像的任务 (![Auxiliary
    classifier GAN (ACGAN)](img/B08956_05_091.jpg))，判别器的*Equation 5.3.1*还有一个额外任务，即正确分类真假图像
    (![Auxiliary classifier GAN (ACGAN)](img/B08956_05_092.jpg))。生成器的*Equation* *5.3.2*意味着除了通过假图像来欺骗判别器
    (![Auxiliary classifier GAN (ACGAN)](img/B08956_05_093.jpg))，它还要求判别器正确分类这些假图像
    (![Auxiliary classifier GAN (ACGAN)](img/B08956_05_094.jpg))。
- en: Starting with the CGAN code, only the discriminator and the training function
    are modified to implement ACGAN. The discriminator and generator builder functions
    are also provided by `gan.py`. To see the changes made on the discriminator, following
    listing shows the builder function where the auxiliary decoder network that performs
    image classification and the dual outputs are highlighted.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 从CGAN代码开始，只需要修改判别器和训练函数以实现ACGAN。判别器和生成器构建函数也由`gan.py`提供。为了查看在判别器上做出的修改，以下*listing*展示了构建函数，其中突出了执行图像分类的辅助解码器网络和双输出。
- en: 'Listing 5.3.1, `gan.py` shows how the discriminator model builder is the same
    as in DCGAN predicting if an image is real, the first output. An auxiliary decoder
    network is added to perform the image classification and produce the second output:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 5.3.1*，`gan.py`展示了判别器模型构建与DCGAN相同，用于预测图像是否为真实，作为第一个输出。添加了一个辅助解码器网络来执行图像分类并产生第二个输出：'
- en: '[PRE11]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The discriminator is then built by calling:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 然后通过调用以下代码构建判别器：
- en: '[PRE12]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The generator is the same as the one in ACGAN. To recall, the generator builder
    is shown in the following listing. We should note that both *Listings* *5.3.1*
    and *5.3.2* are the same builder functions used by WGAN and LSGAN in the previous
    sections.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器与ACGAN中的生成器相同。回顾一下，生成器构建函数在以下*listing*中展示。我们需要注意的是，*Listings* *5.3.1*和*5.3.2*是WGAN和LSGAN在前面章节中使用的相同构建函数。
- en: 'Listing 5.3.2, `gan.py` shows the generator model builder is the same as in
    CGAN:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '*Listing 5.3.2*，`gan.py`展示了生成器模型构建与CGAN中的相同：'
- en: '[PRE13]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In ACGAN, the generator is instantiated as:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在ACGAN中，生成器被实例化为：
- en: '[PRE14]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Following figure shows the network model of ACGAN in Keras:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了Keras中ACGAN的网络模型：
- en: '![Auxiliary classifier GAN (ACGAN)](img/B08956_05_09.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![Auxiliary classifier GAN (ACGAN)](img/B08956_05_09.jpg)'
- en: 'Figure 5.3.2: The Keras model of ACGAN'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3.2：ACGAN的Keras模型
- en: As shown in *Listing* *5.3.3*, the discriminator and adversarial models are
    modified to accommodate the changes in the discriminator network. We now have
    two loss functions. The first is the original binary cross-entropy to train the
    discriminator in estimating the probability if the input image is real. The second
    is the image classifier predicting the class label. The output is a one-hot vector
    of 10 dimensions.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如*Listing* *5.3.3*所示，判别器和对抗模型已被修改以适应判别器网络中的变化。现在我们有了两个损失函数。第一个是原始的二元交叉熵，用于训练判别器估计输入图像是否真实。第二个是图像分类器，预测类别标签。输出是一个10维的独热向量。
- en: 'Referring to Listing 5.3.3, `acgan-mnist-5.3.1.py`, where highlighted are the
    changes implemented in the discriminator and adversarial models to accommodate
    the image classifier of the discriminator network. The two loss functions correspond
    to the two outputs of the discriminator:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 参考*Listing 5.3.3*，`acgan-mnist-5.3.1.py`，其中突出了为适应判别器网络的图像分类器，在判别器和对抗模型中实施的变化。两个损失函数分别对应判别器的两个输出：
- en: '[PRE15]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: In *Listing* *5.3.4*, we highlight the changes implemented in the training routine.
    The main difference compared to CGAN code is that the output label must be supplied
    during discriminator and adversarial training.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在*Listing* *5.3.4*中，我们突出了训练过程中实现的变化。与CGAN代码相比，主要的区别在于输出标签必须在判别器和对抗训练期间提供。
- en: 'As seen in Listing 5.3.4, `acgan-mnist-5.3.1.py`, the changes implemented in
    the train function are highlighted:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 如*Listing 5.3.4*中所示，`acgan-mnist-5.3.1.py`，train函数中实现的更改已突出显示：
- en: '[PRE16]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In turned out that with the additional task, the performance improvement in
    ACGAN is significant compared to all GANs that we have discussed previously. ACGAN
    training is stable as shown in *Figure 5.3.3* sample outputs of ACGAN for the following
    labels:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 结果发现，增加了这个额外任务后，ACGAN相比我们之前讨论过的所有GAN，性能有了显著提升。ACGAN的训练稳定性如*图 5.3.3*所示，展示了ACGAN生成的以下标签的样本输出：
- en: '[PRE17]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Unlike CGAN, the sample outputs appearance does not vary widely during training.
    The MNIST digit image perceptive quality is also better. *Figure 5.3.4* shows a
    side by side comparison of every MNIST digit produced by both CGAN and ACGAN.
    Digits 2-6 are of better quality in ACGAN than in CGAN.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 与CGAN不同，样本输出的外观在训练过程中不会大幅变化。MNIST数字图像的感知质量也更好。*图 5.3.4* 展示了由CGAN和ACGAN分别生成的每个MNIST数字的并排比较。数字2到6在ACGAN中的质量优于CGAN。
- en: 'I encourage you to run the trained generator model to see new synthesized MNIST
    digits images:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我鼓励你运行训练好的生成器模型，以查看新的合成MNIST数字图像：
- en: '[PRE18]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Alternatively, a specific digit (for example, 3) to be generated can also be
    requested:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，还可以请求生成特定的数字（例如，3）：
- en: '[PRE19]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![Auxiliary classifier GAN (ACGAN)](img/B08956_05_10.jpg)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![辅助分类器GAN（ACGAN）](img/B08956_05_10.jpg)'
- en: 'Figure 5.3.3: The sample outputs generated by the ACGAN as a function of train
    steps for labels [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3.3：ACGAN在训练步骤下生成的样本输出，标签为[0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]
- en: '![Auxiliary classifier GAN (ACGAN)](img/B08956_05_11.jpg)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![辅助分类器GAN（ACGAN）](img/B08956_05_11.jpg)'
- en: 'Figure 5.3.4: A side by side comparison of outputs of CGAN and ACGAN conditioned
    with digits 0 to 9'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3.4：由CGAN和ACGAN生成的0至9数字输出并排比较
- en: Conclusion
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In this chapter, we've presented various improvements in the original algorithm
    of GAN, first introduced in the previous chapter. WGAN proposed an algorithm to
    improve the stability of training by using the EMD or Wassertein 1 loss. LSGAN
    argued that the original cross-entropy function of GAN is prone to vanishing gradients,
    unlike least squares loss. LSGAN proposed an algorithm to achieve stable training
    and quality outputs. ACGAN convincingly improved the quality of the conditional
    generation of MNIST digits by requiring the discriminator to perform classification
    task on top of determining whether the input image is fake or real.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们展示了对GAN原始算法的多种改进，这些算法在上一章中首次介绍。WGAN提出了一种算法，通过使用EMD或Wasserstein 1损失来提高训练的稳定性。LSGAN认为GAN原始的交叉熵函数容易导致梯度消失，而最小二乘损失则不同。LSGAN提出了一种算法，实现了稳定的训练和高质量的输出。ACGAN通过要求判别器除了判断输入图像是否为假图像或真实图像外，还需要执行分类任务，从而显著提高了MNIST数字条件生成的质量。
- en: In the next chapter, we'll study how to control the attributes of generator
    outputs. Whilst CGAN and ACGAN are able to indicate the desired digits to produce;
    we have not analyzed GANs that can specify the attributes of outputs. For example,
    we may want to control the writing style of the MNIST digits such as roundness,
    tilt angle, and thickness. Therefore, the goal will be to introduce GANs with
    disentangled representations to control the specific attributes of the generator
    outputs.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习如何控制生成器输出的属性。尽管CGAN和ACGAN能够指示所需的数字进行生成，但我们尚未分析能够指定输出属性的GAN。例如，我们可能希望控制MNIST数字的书写风格，如圆度、倾斜角度和粗细。因此，本章的目标是介绍具有解耦表示的GAN，以控制生成器输出的特定属性。
- en: References
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: Ian Goodfellow and others. *Generative Adversarial Nets*. Advances in neural
    information processing systems, 2014([http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)).
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ian Goodfellow等人，*生成对抗网络*。神经信息处理系统进展，2014（[http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf](http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)）。
- en: Martin Arjovsky, Soumith Chintala, and Léon Bottou, *Wasserstein GAN*. arXiv
    preprint, 2017([https://arxiv.org/pdf/1701.07875.pdf](https://arxiv.org/pdf/1701.07875.pdf)).
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Martin Arjovsky、Soumith Chintala和Léon Bottou，*Wasserstein GAN*。arXiv预印本，2017（[https://arxiv.org/pdf/1701.07875.pdf](https://arxiv.org/pdf/1701.07875.pdf)）。
- en: Xudong Mao and others. *Least Squares Generative Adversarial Networks*. 2017
    IEEE International Conference on Computer Vision (ICCV). IEEE 2017([http://openaccess.thecvf.com/content_ICCV_2017/papers/Mao_Least_Squares_Generative_ICCV_2017_paper.pdf](http://openaccess.thecvf.com/content_ICCV_2017/papers/Mao_Least_Squares_Generative_ICCV_2017_paper.pdf)).
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Xudong Mao 等人。*最小二乘生成对抗网络*。2017年IEEE计算机视觉国际会议（ICCV）。IEEE 2017 ([http://openaccess.thecvf.com/content_ICCV_2017/papers/Mao_Least_Squares_Generative_ICCV_2017_paper.pdf](http://openaccess.thecvf.com/content_ICCV_2017/papers/Mao_Least_Squares_Generative_ICCV_2017_paper.pdf))。
- en: Augustus Odena, Christopher Olah, and Jonathon Shlens. *Conditional Image Synthesis
    with Auxiliary Classifier GANs*. ICML, 2017([http://proceedings.mlr.press/v70/odena17a/odena17a.pdf](http://proceedings.mlr.press/v70/odena17a/odena17a.pdf)).
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Augustus Odena、Christopher Olah 和 Jonathon Shlens。*带有辅助分类器GAN的条件图像合成*。ICML，2017
    ([http://proceedings.mlr.press/v70/odena17a/odena17a.pdf](http://proceedings.mlr.press/v70/odena17a/odena17a.pdf))。
