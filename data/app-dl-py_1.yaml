- en: Jupyter Fundamentals
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jupyter 基础
- en: Jupyter Notebooks are one of the most important tools for data scientists using
    Python. This is because they're an ideal environment for developing reproducible
    data analysis pipelines. Data can be loaded, transformed, and modeled all inside
    a single Notebook, where it's quick and easy to test out code and explore ideas
    along the way. Furthermore, all of this can be documented "**inline**" using formatted
    text, so you can make notes for yourself or even produce a structured report.
    Other comparable platforms - for example, RStudio or Spyder - present the user
    with multiple windows, which promote arduous tasks such as copy and pasting code
    around and rerunning code that has already been executed. These tools also tend
    to involve **Read Eval Prompt Loops (REPLs)** where code is run in a terminal
    session that has saved memory. This type of development environment is bad for
    reproducibility and not ideal for development either. Jupyter Notebooks solve
    all these issues by giving the user a single window where code snippets are executed
    and outputs are displayed inline. This lets users develop code efficiently and
    allows them to look back at previous work for reference, or even to make alterations.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebooks 是 Python 数据科学家使用的最重要工具之一。这是因为它们是开发可复现的数据分析管道的理想环境。数据可以在单一
    Notebook 中加载、转换和建模，在这里可以快速简便地测试代码和探索想法。此外，所有这些都可以通过格式化文本进行"**内联**"文档记录，因此你可以为自己做笔记，甚至生成结构化报告。其他类似的平台，例如
    RStudio 或 Spyder，向用户呈现多个窗口，这会导致繁琐的任务，比如复制粘贴代码和重新运行已执行的代码。这些工具通常涉及**读取求值提示循环（REPLs）**，其中代码在一个具有保存内存的终端会话中运行。这种开发环境对于可复现性不好，也不适合开发。Jupyter
    Notebooks 通过提供一个单一窗口解决了所有这些问题，在这个窗口中，代码片段被执行，输出结果则内联显示。这使得用户可以高效地开发代码，并允许他们回顾以前的工作以供参考，甚至进行修改。
- en: We'll start the chapter by explaining exactly what Jupyter Notebooks are and
    continue to discuss why they are so popular among data scientists. Then, we'll
    open a Notebook together and go through some exercises to learn how the platform
    is used. Finally, we'll dive into our first analysis and perform an exploratory
    analysis in the section *Basic Functionality and Features.*
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过解释什么是 Jupyter Notebook 开始本章，并继续讨论它为何在数据科学家中如此受欢迎。接着，我们将一起打开一个 Notebook，并通过一些练习学习如何使用该平台。最后，我们将在*基本功能和特点*一节中深入进行第一次分析，进行探索性分析。
- en: 'By the end of this chapter, you will be able to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将能够：
- en: Learn what a Jupyter Notebook is and why it's useful for data analysis
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解什么是 Jupyter Notebook，以及它为何对数据分析有用
- en: Use Jupyter Notebook features
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Jupyter Notebook 功能
- en: Study Python data science libraries
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习 Python 数据科学库
- en: Perform simple exploratory data analysis
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行简单的探索性数据分析
- en: All code from this book are available as chapter-specific IPython notebooks in
    the code bundle. All color plots from this book are also available in the code
    bundle.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的所有代码都可以在代码包中的章节特定 IPython 笔记本中找到。本书中的所有彩色图表也都包含在代码包中。
- en: Basic Functionality and Features
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本功能和特点
- en: In this section, we first demonstrate the usefulness of Jupyter Notebooks with
    examples and through discussion. Then, in order to cover the fundamentals of Jupyter
    Notebooks for beginners, we'll see the basic usage of them in terms of launching
    and interacting with the platform. For those who have used Jupyter Notebooks before,
    this will be mostly a review; however, you will certainly see new things in this
    topic as well.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们首先通过示例和讨论展示 Jupyter Notebooks 的实用性。接着，为了涵盖 Jupyter Notebooks 的基础知识，我们将看到如何启动和与平台互动的基本用法。对于那些已经使用过
    Jupyter Notebooks 的人来说，这部分内容大多是复习；不过，你一定也会在这一主题中看到新的内容。
- en: What is a Jupyter Notebook and Why is it Useful?
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 Jupyter Notebook，它为何有用？
- en: 'Jupyter Notebooks are locally run web applications which contain live code,
    equations, figures, interactive apps, and Markdown text. The standard language
    is Python, and that''s what we''ll be using for this book; however, note that
    a variety of alternatives are supported. This includes the other dominant data
    science language, R:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter Notebooks 是本地运行的 Web 应用程序，其中包含实时代码、公式、图形、交互式应用和 Markdown 文本。标准语言是 Python，这也是本书将使用的语言；然而，请注意，它也支持多种替代语言。其中包括另一个主要的数据科学语言
    R：
- en: '![](img/bd2128ae-e666-46c5-8c5a-5f7b892cac26.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bd2128ae-e666-46c5-8c5a-5f7b892cac26.png)'
- en: Those familiar with R will know about R Markdown. Markdown documents allow for
    Markdown-formatted text to be combined with executable code. Markdown is a simple
    language used for styling text on the web. For example, most GitHub repositories
    have a `README.md` `Markdown` file. This format is useful for basic text formatting.
    It's comparable to HTML but allows for much less customization.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 熟悉 R 的人会知道 R Markdown。Markdown 文档允许将 Markdown 格式的文本与可执行代码结合使用。Markdown 是一种用于在网页上格式化文本的简单语言。例如，大多数
    GitHub 仓库都有一个 `README.md` `Markdown` 文件。这个格式适用于基本的文本格式化。它与 HTML 相似，但允许的自定义程度要小得多。
- en: 'Commonly used symbols in Markdown include hashes (#) to make text into a heading,
    square and round brackets to insert hyperlinks, and stars to create italicized
    or bold text:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Markdown 中常用的符号包括井号（#）用来将文本设置为标题，方括号和圆括号用来插入超链接，星号用来创建斜体或粗体文本：
- en: '![](img/bb9fd5a0-5267-4233-8eae-2b8f3e37f867.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bb9fd5a0-5267-4233-8eae-2b8f3e37f867.png)'
- en: Having seen the basics of Markdown, let's come back to R Markdown, where Markdown
    text can be written alongside executable code. Jupyter Notebooks offer the equivalent
    functionality for Python, although, as we'll see, they function quite differently
    than R Markdown documents. For example, R Markdown assumes you are writing Markdown
    unless otherwise specified, whereas Jupyter Notebooks assume you are inputting
    code. This makes it more appealing to use Jupyter Notebooks for rapid development
    and testing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了 Markdown 的基本知识之后，让我们回到 R Markdown，Markdown 文本可以与可执行代码一起编写。Jupyter Notebooks
    为 Python 提供了等效的功能，尽管正如我们将看到的，它们与 R Markdown 文档的功能有很大不同。例如，R Markdown 假设除非另行指定，否则你在编写
    Markdown，而 Jupyter Notebooks 假设你在输入代码。这使得 Jupyter Notebooks 在快速开发和测试时更具吸引力。
- en: 'From a data science perspective, there are two primary types for a Jupyter
    Notebook depending on how they are used: lab-style and deliverable.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 从数据科学的角度来看，Jupyter Notebook 有两种主要类型，取决于其使用方式：实验室风格和交付风格。
- en: Lab-style Notebooks are meant to serve as the programming analog of research
    journals. These should contain all the work you've done to load, process, analyze,
    and model the data. The idea here is to document everything you've done for future
    reference, so it's usually not advisable to delete or alter previous lab-style
    Notebooks. It's also a good idea to accumulate multiple date-stamped versions
    of the Notebook as you progress through the analysis, in case you want to look
    back at previous states.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 实验室风格的 Notebook 旨在作为编程类比于研究期刊。这些应该包含你所做的所有工作，包括加载、处理、分析和建模数据。其目的是记录你所做的一切，以便将来参考，因此通常不建议删除或修改之前的实验室风格
    Notebook。同时，随着分析的进展，最好累积多个带有日期戳的 Notebook 版本，以防你想回顾之前的状态。
- en: Deliverable Notebooks are intended to be presentable and should contain only
    select parts of the lab-style Notebooks. For example, this could be an interesting
    discovery to share with your colleagues, an in-depth report of your analysis for
    a manager, or a summary of the key findings for stakeholders.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 交付风格的 Notebook 旨在展示成果，应该只包含实验室风格 Notebook 中的部分内容。例如，这可能是与同事分享的有趣发现，或者是给经理的详细分析报告，或是给利益相关者的关键发现总结。
- en: In either case, an important concept is reproducibility. If you've been diligent
    in documenting your software versions, anyone receiving the reports will be able
    to rerun the Notebook and compute the same results as you did. In the scientific
    community, where reproducibility is becoming increasingly difficult, this is a
    breath of fresh air.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何情况下，一个重要的概念是可重复性。如果你在记录软件版本时做得很细致，那么接收报告的人将能够重新运行 Notebook 并计算出与您相同的结果。在科学界，可重复性变得越来越困难，这无疑是一个清新的突破。
- en: Navigating the Platform
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导航平台
- en: Now, we are going to open up a Jupyter Notebook and start to learn the interface.
    Here, we will assume you have no prior knowledge of the platform and go over the
    basic usage.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将打开一个 Jupyter Notebook 并开始学习其界面。在这里，我们假设你对该平台没有先前的了解，并且会讲解基本的使用方法。
- en: Introducing Jupyter Notebooks
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Jupyter Notebooks
- en: Navigate to the companion material directory in the terminal.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中导航到配套材料目录。
- en: On Unix machines such as Mac or Linux, command-line navigation can be done using
    ls to display directory contents and `cd` to change directories. On Windows machines,
    use `dir` to display directory contents and use `cd` to change directories instead.
    If, for example, you want to change the drive from `C:` to `D:` , you should execute
    `d:` to change drives.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Mac 或 Linux 等 Unix 系统中，可以使用 `ls` 命令显示目录内容，使用 `cd` 命令更改目录。在 Windows 系统中，使用
    `dir` 显示目录内容，使用 `cd` 更改目录。如果您想将驱动器从 `C:` 更改为 `D:`，可以执行 `d:` 来切换驱动器。
- en: 'Start a new local Notebook server here by typing the following into the terminal:
    `jupyter notebook.`'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中输入以下命令，启动新的本地 Notebook 服务器：`jupyter notebook.`
- en: A new window or tab of your default browser will open the Notebook Dashboard to
    the working directory. Here, you will see a list of folders and files contained therein.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 默认浏览器的新窗口或标签页将打开 Notebook Dashboard，指向工作目录。在这里，您将看到该目录下的文件夹和文件列表。
- en: Click on a folder to navigate to that particular path and open a file by clicking
    on it. Although its main use is editing IPYNB Notebook files, Jupyter functions
    as a standard text editor as well.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击一个文件夹以导航到该路径，并点击文件以打开它。尽管它的主要用途是编辑 IPYNB Notebook 文件，Jupyter 也可以作为标准文本编辑器使用。
- en: 'Reopen the terminal window used to launch the app. We can see the `NotebookApp` being
    run on a local server. In particular, you should see a line like this:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新打开用于启动应用的终端窗口。我们可以看到 `NotebookApp` 正在本地服务器上运行。特别地，您应该能看到如下行：
- en: '`[I 20:03:01.045 NotebookApp] The Jupyter Notebook is running at: http:// localhost:8888/
    ? oken=e915bb06866f19ce462d959a9193a94c7c088e81765f9d8a`'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`[I 20:03:01.045 NotebookApp] Jupyter Notebook 正在运行，地址为：http:// localhost:8888/
    ? oken=e915bb06866f19ce462d959a9193a94c7c088e81765f9d8a`'
- en: Going to that HTTP address will load the app in your browser window, as was done
    automatically when starting the app. Closing the window does not stop the app;
    this should be done from the terminal by typing *Ctrl + C*.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 访问该 HTTP 地址将会在您的浏览器窗口中加载应用，正如启动应用时自动完成的操作。关闭窗口并不会停止应用；这应该在终端中通过输入 *Ctrl + C*
    来完成。
- en: Close the app by typing *Ctrl +* *C* in the terminal. You may also have to confirm
    by entering `y`. Close the web browser window as well.
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中按 *Ctrl + C* 来关闭应用。您可能还需要确认通过输入 `y`。同时关闭浏览器窗口。
- en: 'When loading the NotebookApp, there are various options available to you. In
    the terminal, see the list of available options by running the following:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 NotebookApp 时，您可以选择多种选项。在终端中，通过运行以下命令查看可用选项列表：
- en: '`jupyter notebook –-help.`'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`jupyter notebook –-help.`'
- en: 'One such option is to specify a specific port. Open a NotebookApp at `local
    port 9000` by running the following:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 其中一个选项是指定一个特定端口。通过运行以下命令，可以在 `本地端口 9000` 启动 NotebookApp：
- en: '`jupyter notebook --port 9000`'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`jupyter notebook --port 9000`'
- en: 'The primary way to create a new Jupyter Notebook is from the Jupyter Dashboard. Click
    **New** in the upper-right corner and select a kernel from the drop-down menu (that
    is, select something in the Notebooks section):'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建新 Jupyter Notebook 的主要方法是通过 Jupyter Dashboard。点击右上角的 **New**，并从下拉菜单中选择一个内核（即，选择
    Notebooks 部分中的某个选项）：
- en: '![](img/d1a81c3a-8d52-4977-91e0-103c9b8c8af3.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d1a81c3a-8d52-4977-91e0-103c9b8c8af3.png)'
- en: Kernels provide programming language support for the Notebook. If you have installed
    Python with Anaconda, that version should be the default kernel. Conda virtual
    environments will also be available here.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Kernels 为 Notebook 提供编程语言支持。如果您已经通过 Anaconda 安装了 Python，那么该版本应该是默认的内核。Conda
    虚拟环境也将在此可用。
- en: Virtual environments are a great tool for managing multiple projects on the
    same machine. Each virtual environment may contain a different version of Python
    and external libraries. Python has built-in virtual environments; however, the
    Conda virtual environment integrates better with Jupyter Notebooks and boasts
    other nice features. The documentation is available at [https://conda.io/docs/user-guide/tasks/manage-environments.html](https://conda.io/docs/user-guide/tasks/manage-environments.html).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟环境是管理同一台机器上多个项目的绝佳工具。每个虚拟环境可能包含不同版本的 Python 和外部库。Python 内置有虚拟环境；然而，Conda 虚拟环境与
    Jupyter Notebooks 的集成更好，并具有其他一些优点。相关文档请参阅 [https://conda.io/docs/user-guide/tasks/manage-environments.html](https://conda.io/docs/user-guide/tasks/manage-environments.html)。
- en: With the newly created blank Notebook, click in the top cell and type `print('hello
    world')` , or any other code snippet that writes to the screen. Execute it by
    clicking in the cell and pressing *Shift + Enter*, or by selecting **Run Cell**
    in the **Cell menu**.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在新创建的空白Notebook中，点击顶部单元格并输入`print('hello world')`，或者任何其他可以向屏幕输出的代码片段。通过点击单元格并按*Shift
    + Enter*来执行，或者在**Cell菜单**中选择**Run Cell**。
- en: Any `stdout` or `stderr` output from the code will be displayed beneath as the
    cell runs. Furthermore, the string representation of the object written in the
    final line will be displayed as well. This is very handy, especially for displaying
    tables, but sometimes we don't want the final object to be displayed. In such
    cases, a semicolon (; ) can be added to the end of the line to suppress the display.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 任何来自代码的`stdout`或`stderr`输出都会在单元格运行时显示在下面。此外，最后一行中写的对象的字符串表示也会显示出来。这非常方便，特别是在显示表格时，但有时我们不希望最后的对象被显示。在这种情况下，可以在行末添加分号（;
    ）来抑制显示。
- en: New cells expect and run code input by default; however, they can be changed
    to render Markdown instead.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 新单元格默认期望并运行代码输入；然而，它们也可以改为渲染Markdown格式的内容。
- en: 'Click into an empty cell and change it to accept Markdown-formatted text. This
    can be done from the drop-down menu icon in the toolbar or by selecting **Markdown**
    from the **Cell** menu. Write some text in here (any text will do), making sure
    to utilize Markdown formatting symbols such as #.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击一个空白单元格，并将其更改为接受Markdown格式的文本。这可以通过工具栏中的下拉菜单图标来完成，或者从**Cell**菜单中选择**Markdown**。在这里输入一些文本（任何文本都可以），并确保使用Markdown格式符号，如#。
- en: 'Focus on the toolbar at the top of the Notebook:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集中注意力在Notebook顶部的工具栏：
- en: '![](img/8f15ecf5-0db6-4dd2-9177-a2f88eb960c8.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8f15ecf5-0db6-4dd2-9177-a2f88eb960c8.png)'
- en: 'There is a Play icon in the toolbar, which can be used to run cells. As we''ll
    see later,however, it''s handier to use the keyboard shortcut *Shift +* *Enter*
    to run cells. Right next to this is a Stop icon, which can be used to stop cells
    from running. This is useful, for example, if a cell is taking too long to run:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 工具栏中有一个播放图标，可以用来运行单元格。然而，正如我们稍后会看到的，使用键盘快捷键*Shift +* *Enter* 来运行单元格更为便捷。紧挨着这个图标的是一个停止图标，可以用来停止单元格的运行。例如，如果某个单元格运行时间过长，这个功能就非常有用：
- en: '![](img/ed67bc3e-b989-4f56-99cf-2f4def9cfd55.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ed67bc3e-b989-4f56-99cf-2f4def9cfd55.png)'
- en: 'New cells can be manually added from the Insert menu:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 新单元格可以通过**Insert**菜单手动添加：
- en: '![](img/69a5c020-9d23-479c-be44-c375dfd0c9d5.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/69a5c020-9d23-479c-be44-c375dfd0c9d5.png)'
- en: 'Cells can be copied, pasted, and deleted using icons or by selecting options
    from the Edit menu:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用图标或通过**Edit菜单**中的选项来复制、粘贴和删除单元格：
- en: '![](img/5b346eda-8c8d-466f-9bd4-6135b2b0a7f6.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5b346eda-8c8d-466f-9bd4-6135b2b0a7f6.png)'
- en: '![](img/36336f67-aacc-4e60-9d6d-d2a213851bd4.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36336f67-aacc-4e60-9d6d-d2a213851bd4.png)'
- en: 'Cells can also be moved up and down this way:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 单元格也可以通过这种方式上下移动：
- en: '![](img/5f74be09-9e20-48a8-a404-9e40fe551ced.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f74be09-9e20-48a8-a404-9e40fe551ced.png)'
- en: 'There are useful options under the Cell menu to run a group of cells or the
    entire Notebook:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在**Cell**菜单下有一些有用的选项，可以运行一组单元格或整个Notebook：
- en: '![](img/eb8230f9-c773-4415-b903-0afa60e6f1ac.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eb8230f9-c773-4415-b903-0afa60e6f1ac.png)'
- en: Experiment with the toolbar options to move cells up and down, insert new cells,and
    delete cells.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 试验工具栏选项，移动单元格、插入新单元格和删除单元格。
- en: 'An important thing to understand about these Notebooks is the shared memory between
    cells. It''s quite simple: every cell existing on the sheet has access to the global
    set of variables. So, for example, a function defined in one cell could be called from
    any other, and the same applies to variables. As one would expect, anything within
    the scope of a function will not be a global variable and can only be accessed from
    within that specific function.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 了解这些Notebook的一个重要概念是单元格之间的共享内存。其实很简单：每个在工作表中存在的单元格都可以访问全局变量集。例如，在一个单元格中定义的函数可以在任何其他单元格中调用，变量也同样如此。正如预期的那样，函数作用域内的任何内容都不是全局变量，只能在该特定函数内访问。
- en: Open the Kernel menu to see the selections. The Kernel menu is useful for stopping script
    executions and restarting the Notebook if the kernel dies. Kernels can also be swapped
    here at any time, but it is unadvisable to use multiple kernels for a single Notebook
    due to reproducibility concerns.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开Kernel菜单以查看选项。Kernel菜单对于停止脚本执行以及在内核崩溃时重新启动Notebook非常有用。内核也可以随时在此处切换，但由于可复现性问题，不建议为单个Notebook使用多个内核。
- en: Open the **File** menu to see the selections. The **File** menu contains options
    for downloading the Notebook in various formats. In particular, it's recommended
    to save an HTML version of your Notebook, where the content is rendered statically
    and can be opened and viewed "as you would expect" in web browsers.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 **文件** 菜单查看选项。**文件** 菜单包含将 Notebook 下载为各种格式的选项。特别推荐保存为 HTML 版本的 Notebook，内容会被静态渲染，并且可以在网页浏览器中像预期一样打开和查看。
- en: The Notebook name will be displayed in the upper-left corner. New Notebooks
    will automatically be named **Untitled**.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Notebook 的名称会显示在左上角。新的 Notebooks 将自动命名为 **Untitled**。
- en: Change the name of your IPYNB `Notebook` file by clicking on the current name
    in the upper-left corner and typing the new name. Then, save the file.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击左上角当前名称来更改你的 IPYNB `Notebook` 文件的名称，并输入新的名称。然后，保存文件。
- en: Close the current tab in your web browser (exiting the Notebook) and go to the Jupyter
    Dashboard tab, which should still be open. (If it's not open, then reload it by
    copy and pasting the HTTP link from the terminal.)
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭浏览器中的当前标签页（退出 Notebook），然后进入仍然打开的 Jupyter 仪表盘标签页。（如果它没有打开，可以通过从终端复制并粘贴 HTTP
    链接来重新加载它。）
- en: Since we didn't shut down the Notebook, we just saved and exited, it will have
    a green book symbol next to its name in the Files section of the Jupyter Dashboard and
    will be listed as Running on the right side next to the last modified date. Notebooks
    can be shut down from here.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有关闭 Notebook，而只是保存并退出，它会在 Jupyter 仪表盘的文件部分旁边显示绿色的书本符号，并在右侧显示“运行中”，旁边是最后修改的日期。从这里可以关闭
    Notebooks。
- en: 'Quit the Notebook you have been working on by selecting it (checkbox to the
    left of the name) and clicking the orange Shutdown button:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过选择你正在使用的 Notebook（在名称左侧的复选框）并点击橙色的关闭按钮来退出该 Notebook：
- en: '![](img/fa60a534-064a-4c87-9ab3-ad6ae266a58b.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fa60a534-064a-4c87-9ab3-ad6ae266a58b.png)'
- en: If you plan to spend a lot of time working with Jupyter Notebooks, it's worthwhile
    to learn the keyboard shortcuts. This will speed up your workflow considerably.
    Particularly useful commands to learn are the shortcuts for manually adding new
    cells and converting cells from code to Markdown formatting. Click on **Keyboard
    Shortcuts** from the **Help menu** to see how.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你计划花费大量时间与 Jupyter Notebooks 一起工作，学习键盘快捷键是值得的。这将大大加快你的工作流程。特别有用的命令是学习手动添加新单元格以及将单元格从代码转换为
    Markdown 格式的快捷键。点击 **键盘快捷键**，在 **帮助菜单** 中查看相关内容。
- en: Jupyter Features
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jupyter 功能
- en: Jupyter has many appealing features that make for efficient Python programming.
    These include an assortment of things, from methods for viewing docstrings to
    executing Bash commands. Let's explore some of these features together in this
    section.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Jupyter 有许多吸引人的功能，使得 Python 编程更加高效。这些功能包括从查看文档字符串到执行 Bash 命令等各种方法。让我们一起在这一部分中探索这些功能。
- en: 'The official IPython documentation can be found here: [http://ipython.readthedocs.io/en/stable/](https://ipython.readthedocs.io/en/stable/).
    It has details on the features we will discuss here and others.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 官方的 IPython 文档可以在这里找到：[http://ipython.readthedocs.io/en/stable/](https://ipython.readthedocs.io/en/stable/)。其中包含了我们将在此讨论的功能以及其他功能的详细信息。
- en: Exploring some of Jupyter's most useful features
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索一些 Jupyter 最有用的功能
- en: From the Jupyter Dashboard, navigate to the `chapter-1` directory and open the `chapter-1-workbook.ipynb`
    file by selecting it. The standard file extension for Jupyter Notebooks is `.ipynb`,
    which was introduced back when they were called IPython Notebooks.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Jupyter 仪表盘中，导航到 `chapter-1` 目录，并通过选择它打开 `chapter-1-workbook.ipynb` 文件。Jupyter
    Notebooks 的标准文件扩展名是 `.ipynb`，这个扩展名是在它们被称为 IPython Notebooks 时引入的。
- en: 'Scroll down to Subtopic `Jupyter Features` in the Jupyter Notebook. We start by
    reviewing the basic keyboard shortcuts. These are especially helpful to avoid having
    to use the mouse so often, which will greatly speed up the workflow. Here are
    the most useful keyboard shortcuts. Learning to use these will greatly improve your
    experience with Jupyter Notebooks as well as your own efficiency:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动到 Jupyter Notebook 中的子主题 `Jupyter Features`。我们首先回顾基本的键盘快捷键。这些快捷键尤其有助于避免频繁使用鼠标，从而大大加快工作流程。以下是最有用的键盘快捷键。学会使用这些快捷键将大大提高你使用
    Jupyter Notebooks 的体验，并提升你的效率：
- en: '*Shift + Enter* is used to run a cell'
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Shift + Enter* 用于运行单元格'
- en: The *Esc* *key* is used to leave a cell
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Esc* *键* 用于退出单元格'
- en: The *M* key is used to change a cell to Markdown (after pressing Esc)
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*M* 键用于将单元格更改为 Markdown（按下 Esc 后）'
- en: The *Y* key is used to change a cell to code (after pressing Esc)
  id: totrans-79
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Y* 键用于将单元格切换为代码模式（按下 Esc 后使用）'
- en: '*Arrow keys* move cells (after pressing Esc)'
  id: totrans-80
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*箭头键* 用于移动单元格（按下 Esc 后使用）'
- en: The *Enter* *key* is used to enter a cell
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*回车* *键* 用于进入单元格'
- en: Moving on from shortcuts, the help option is useful for beginners and experienced
    coders alike. It can help provide guidance at each uncertain step.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 说到快捷键，帮助选项对初学者和经验丰富的编码人员都很有用。它能在每一个不确定的步骤上提供指导。
- en: Users can get help by adding a question mark to the end of any object and running
    the cell. Jupyter finds the docstring for that object and returns it in a pop-out
    window at the bottom of the app.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以通过在任何对象的末尾添加问号并运行单元格来获得帮助。Jupyter 会查找该对象的文档字符串，并在应用程序底部弹出的窗口中返回。
- en: 'Run the **Getting Help** section cells and check out how Jupyter displays the docstrings
    at the bottom of the Notebook. Add a cell in this section and get help on the
    object of your choice:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 **获取帮助** 部分的单元格，查看 Jupyter 如何在 Notebook 底部显示文档字符串。添加一个新单元格并获取你选择的对象的帮助：
- en: '![](img/0c4022a8-0948-487c-a807-8cf5cc5dc79f.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0c4022a8-0948-487c-a807-8cf5cc5dc79f.png)'
- en: 'Tab completion can be used to do the following:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Tab 补全可以用于以下操作：
- en: List available modules when importing external libraries
  id: totrans-87
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出导入外部库时可用的模块
- en: List available modules of imported external libraries
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出导入的外部库的可用模块
- en: Function and variable completion
  id: totrans-89
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 函数和变量补全
- en: This can be especially useful when you need to know the available input arguments for
    a module, when exploring a new library, to discover new modules, or simply to
    speed up workflow. They will save time writing out variable names or functions and
    reduce bugs from typos. The tab completion works so well that you may have difficulty
    coding Python in other editors after today!
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要了解一个模块的可用输入参数时，特别是当你探索一个新库，发现新模块，或者仅仅是为了加速工作流程时，这些命令特别有用。它们能节省写出变量名或函数的时间，并减少由于输入错误导致的
    bug。Tab 补全功能非常强大，今天你可能会发现，离开 Jupyter 后再用其他编辑器写 Python 时，可能会感到不习惯！
- en: 'Click into an empty code cell in the Tab Completion section and try using tab completion
    in the ways suggested immediately above. For example, the fist suggestion can
    be done by typing import (including the space after) and then pressing the Tab
    key:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 Tab 补全部分的一个空代码单元格，并尝试按照上面提到的方式使用 Tab 补全。例如，第一个建议可以通过键入 `import`（包括后面的空格），然后按
    Tab 键来完成：
- en: '![](img/095220a0-0d48-43b9-9b83-edada33dea2d.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/095220a0-0d48-43b9-9b83-edada33dea2d.png)'
- en: Last but not least of the basic Jupyter Notebook features are **magic** commands.
    These consist of one or two percent signs followed by the command. Magics starting
    with `%%` will apply to the entire cell, and magics starting with `%` will only
    apply to that line. This will make sense when seen in an example.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后但同样重要的基本 Jupyter Notebook 功能是**魔法**命令。这些命令由一个或两个百分号符号组成，后面跟着命令。以`%%`开头的魔法命令将作用于整个单元格，而以`%`开头的魔法命令只会作用于当前行。通过示例你会更容易理解这一点。
- en: 'Scroll to the **Jupyter Magic Functions** section and run the cells containing
    `%lsmagic and %matplotlib inline`:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动到 **Jupyter 魔法函数** 部分，运行包含 `%lsmagic 和 %matplotlib inline` 的单元格：
- en: '![](img/4a74b3cc-a816-4269-8a14-1c5eed6855c6.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4a74b3cc-a816-4269-8a14-1c5eed6855c6.png)'
- en: '`%lsmagic` lists the available options. We will discuss and show examples of
    some of the most useful ones. The most common magic command you will probably
    see is `%matplotlib inline`, which allows matplotlib figures to be displayed in
    the Notebook without having to explicitly use `plt.show()` .'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`%lsmagic` 列出可用的选项。我们将讨论并展示一些最常用的魔法命令。你最常见的魔法命令可能是 `%matplotlib inline`，它允许在
    Notebook 中直接显示 matplotlib 图形，而不需要显式使用 `plt.show()`。'
- en: 'The timing functions are very handy and come in two varieties: a standard timer
    `(%time or %%time)` and a timer that measures the average runtime of many iterations
    `(%timeit and %%timeit)`.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 计时功能非常实用，有两种类型：标准计时器 `(%time 或 %%time)` 和测量多次迭代平均运行时间的计时器 `(%timeit 和 %%timeit)`。
- en: Run the cells in the Timers section. Note the difference between using one and
    two percent signs.
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 **计时器** 部分的单元格。注意使用一个和两个百分号的区别。
- en: Even by using a Python kernel (as you are currently doing), other languages
    can be invoked using magic commands. The built-in options include JavaScript,
    R, Pearl, Ruby, and Bash. Bash is particularly useful, as you can use Unix commands
    to find out where you are currently (`pwd`), what's in the directory (`ls`), make
    new folders `(mkdir)`, and write file contents `(cat / head / tail)`.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 即使使用的是 Python 内核（正如你现在所做的），也可以通过魔法命令调用其他语言。内置选项包括 JavaScript、R、Pearl、Ruby 和
    Bash。Bash 特别有用，因为你可以使用 Unix 命令来查看当前目录位置（`pwd`）、查看目录内容（`ls`）、创建新文件夹（`mkdir`），以及写入文件内容（`cat
    / head / tail`）。
- en: 'Run the fist cell in the **Using bash in the notebook section**. This cell
    writes some text to a file in the working directory, prints the directory contents,
    prints an empty line, and then writes back the contents of the newly created file
    before removing it:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 **“在笔记本中使用 bash”** 部分的第一个单元。这一单元会向工作目录中的一个文件写入一些文本，打印目录内容，打印一个空行，然后写回新创建的文件的内容并将其删除：
- en: '![](img/1db82a4c-7baf-43f0-9bfe-eed4a3571ea2.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1db82a4c-7baf-43f0-9bfe-eed4a3571ea2.png)'
- en: Run the following cells containing only `ls` and `pwd`. Note how we did not
    have to explicitly use the Bash magic command for these to work.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下仅包含 `ls` 和 `pwd` 的单元。注意，我们不需要显式使用 Bash 魔法命令就能使其正常工作。
- en: There are plenty of external magic commands that can be installed. A popular
    one is `ipython-sql`, which allows for SQL code to be executed in cells.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多外部魔法命令可以安装。一个流行的命令是 `ipython-sql`，它允许在单元中执行 SQL 代码。
- en: 'If you''ve not already done so, install `ipython-sql` now. Open a new terminal
    window and execute the following code:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你还没有安装 `ipython-sql`，请现在进行安装。打开一个新的终端窗口并执行以下代码：
- en: '[PRE0]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '![](img/9f8aff1e-7c8b-44f9-a965-11a5fad0c8b9.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9f8aff1e-7c8b-44f9-a965-11a5fad0c8b9.png)'
- en: 'Run the `%load_ext sql` cell to load the external command into the Notebook:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 `%load_ext sql` 单元，将外部命令加载到 Notebook 中：
- en: '![](img/409e7029-b8f6-41f7-9f1b-52c8b005cba1.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/409e7029-b8f6-41f7-9f1b-52c8b005cba1.png)'
- en: This allows for connections to remote databases so that queries can be executed (and
    thereby documented) right inside the Notebook.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得可以连接到远程数据库，从而直接在 Notebook 中执行查询（并记录查询内容）。
- en: 'Run the cell containing the SQL sample query:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行包含 SQL 示例查询的单元：
- en: '![](img/4144970d-a09c-4d76-a1b9-78e6b28fb506.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4144970d-a09c-4d76-a1b9-78e6b28fb506.png)'
- en: Here, we first connect to the local sqlite source; however, this line could
    instead point to a specific database on a local or remote server. Then, we execute
    a simple `SELECT` to show how the cell has been converted to run SQL code instead
    of Python.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们首先连接到本地 sqlite 数据源；然而，这一行也可以指向本地或远程服务器上的特定数据库。然后，我们执行一个简单的 `SELECT` 查询，展示如何将单元转换为运行
    SQL 代码，而不是 Python 代码。
- en: Moving on to other useful magic functions, we'll briefly discuss one that helps
    with documentation. The command is `%version_information`, but it does not come
    as standard with Jupyter. Like the SQL one we just saw, it can be installed from
    the command line with pip.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们简要讨论一个有助于文档编写的魔法命令。这个命令是`%version_information`，但它并不是 Jupyter 的标准命令。像我们刚才看到的
    SQL 命令一样，它可以通过命令行使用 pip 安装。
- en: 'If not already done, install the version documentation tool now from the terminal
    using `pip`.Open up a new window and run the following code:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果还没有安装，请通过终端使用 `pip` 安装版本文档工具。打开一个新的窗口并运行以下代码：
- en: '[PRE1]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Once installed, it can then be imported into any Notebook using `%load_ext version_information`.
    Finally, once loaded, it can be used to display the versions of each piece of
    software in the Notebook.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，可以通过 `%load_ext version_information` 将其导入任何 Notebook。最后，一旦加载完成，就可以用来显示
    Notebook 中每个软件的版本信息。
- en: 'Run the cell that loads and calls the version_information command:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行加载并调用 `version_information` 命令的单元：
- en: '![](img/1078ccb9-2f8c-4ad7-9416-98dc5052755e.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1078ccb9-2f8c-4ad7-9416-98dc5052755e.png)'
- en: Converting a Jupyter Notebook to a Python Script
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 Jupyter Notebook 转换为 Python 脚本
- en: You can convert a Jupyter Notebook to a Python script. This is equivalent to
    copying and pasting the contents of each code cell into a single `.py` file. The
    Markdown sections are also included as comments.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将 Jupyter Notebook 转换为 Python 脚本。这相当于将每个代码单元的内容复制并粘贴到一个 `.py` 文件中。Markdown
    部分也会作为注释包含在内。
- en: 'The conversion can be done from the `NotebookApp` or in the command line as
    follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 转换可以通过`NotebookApp`或如下命令行进行：
- en: '`jupyter nbconvert --to=python chapter-1-notebook.ipynb`'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`jupyter nbconvert --to=python chapter-1-notebook.ipynb`'
- en: '![](img/d010e40c-459e-4aca-a2c1-f39f66d1ee7f.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d010e40c-459e-4aca-a2c1-f39f66d1ee7f.png)'
- en: This is useful, for example, when you want to determine the library requirements
    for a Notebook using a tool such as `pipreqs`. This tool determines the libraries
    used in a project and exports them into a `requirements.txt` file (and it can
    be installed by running `pip install pipreqs`).
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这很有用，例如，当你想使用像`pipreqs`这样的工具来确定Notebook的库需求时。该工具可以确定项目中使用的库，并将它们导出到`requirements.txt`文件中（你可以通过运行`pip
    install pipreqs`来安装该工具）。
- en: 'The command is called from outside the folder containing your `.py` files.
    For example, if the `.py` files are inside a folder called `chapter-1`, you could
    do the following:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令是从不包含`.py`文件的文件夹外部调用的。例如，如果`.py`文件位于名为`chapter-1`的文件夹中，你可以执行以下操作：
- en: '[PRE2]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![](img/f02a2880-0b50-4c03-87df-a78f2596315c.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f02a2880-0b50-4c03-87df-a78f2596315c.png)'
- en: 'The resulting `requirements.txt` file for `chapter-1-workbook.ipynb` looks
    like this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '`chapter-1-workbook.ipynb`生成的`requirements.txt`文件如下所示：'
- en: '[PRE3]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Python Libraries
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python库
- en: Having now seen all the basics of Jupyter Notebooks, and even some more advanced
    features, we'll shift our attention to the Python libraries we'll be using in
    this book. Libraries, in general, extend the default set of Python functions.
    Examples of commonly used standard libraries are `datetime`, `time`, and `os`.
    These are called standard libraries because they come standard with every installation
    of Python.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了Jupyter Notebook的基础知识，甚至包括一些更高级的功能，接下来我们将转向本书中将要使用的Python库。一般来说，库是扩展Python默认函数集的工具。常见的标准库包括`datetime`、`time`和`os`。这些被称为标准库，因为它们在每次安装Python时都会默认包含。
- en: For data science with Python, the most important libraries are external, which
    means they do not come standard with Python.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Python的数据科学，最重要的库是外部库，也就是说，它们并不是Python自带的。
- en: The external data science libraries we'll be using in this book are `NumPy`,
    `Pandas`, `Seaborn`, `matplotlib`, `scikit-learn`, `Requests`, and `Bokeh`. Let's
    briefly introduce each.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中我们将使用的外部数据科学库包括`NumPy`、`Pandas`、`Seaborn`、`matplotlib`、`scikit-learn`、`Requests`和`Bokeh`。我们将简要介绍每一个库。
- en: It's a good idea to import libraries using industry standards, for example,
    `import numpy` as `np`; this way, your code is more readable. Try to avoid doing
    things such as from `numpy import *`, as you may unwittingly overwrite functions.
    Furthermore, it's often nice to have modules linked to the library via a dot (.
    ) for code readability.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 使用行业标准导入库是一个好主意，例如，`import numpy as np`；这样，代码更具可读性。尽量避免使用如`from numpy import
    *`之类的方式，因为这可能会不小心覆盖已有的函数。此外，为了提高代码可读性，最好通过点号（.）将模块与库链接。
- en: '**NumPy** offers multi-dimensional data structures (arrays) on which operations
    can be performed far quicker than standard Python data structures (for example,
    lists). This is done in part by performing operations in the background using
    C. NumPy also offers various mathematical and data manipulation functions.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NumPy** 提供了多维数据结构（数组），其操作速度远快于标准的Python数据结构（例如，列表）。这部分是通过在后台使用C语言执行操作来实现的。NumPy还提供了各种数学和数据处理功能。'
- en: '**Pandas** is Python''s answer to the R DataFrame. It stores data in 2-D tabular
    structures where columns represent different variables and rows correspond to
    samples. Pandas provides many handy tools for data wrangling such as filling in
    `NaN` entries and computing statistical descriptions of the data. Working with
    Pandas DataFrames will be a big focus of this book.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pandas** 是Python对R中的DataFrame的回应。它以二维表格结构存储数据，其中列代表不同的变量，行对应于样本。Pandas提供了许多方便的数据处理工具，比如填充`NaN`条目和计算数据的统计描述。与Pandas
    DataFrame的工作是本书的重点之一。'
- en: '**Matplotlib** is a plotting tool inspired by the MATLAB platform. Those familiar
    with R can think of it as Python''s version of ggplot. It''s the most popular
    Python library for plotting figures and allows for a high level of customization.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Matplotlib** 是一种绘图库，灵感来源于MATLAB平台。熟悉R的人可以将其看作是Python版的ggplot。它是最流行的Python绘图库，支持高度自定义。'
- en: '**Seaborn** works as an extension to matplotlib, where various plotting tools
    useful for data science are included. Generally speaking, this allows for analysis
    to be done much faster than if you were to create the same things manually with
    libraries such as matplotlib and scikit-learn.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Seaborn** 是matplotlib的扩展，它包含了许多数据科学中有用的绘图工具。一般来说，这可以比手动使用matplotlib和scikit-learn等库来创建相同的内容更快地完成分析。'
- en: '**Scikit-learn** is the most commonly used machine learning library. It offers
    top-of the-line algorithms and a very elegant API where models are instantiated
    and then fit with data. It also provides data processing modules and other tools
    useful for predictive analytics.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Scikit-learn** 是最常用的机器学习库。它提供了顶级的算法和非常优雅的 API，模型通过实例化后再与数据进行拟合。它还提供了数据处理模块和其他有助于预测分析的工具。'
- en: '**Requests** is the go-to library for making HTTP requests. It makes it straightforward
    to get HTML from web pages and interface with APIs. For parsing the HTML, many
    choose `BeautifulSoup4`, which we will also cover in this book.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Requests** 是进行 HTTP 请求的首选库。它使得从网页获取 HTML 并与 API 接口变得非常简单。对于解析 HTML，许多人选择
    `BeautifulSoup4`，我们在本书中也会介绍这个库。'
- en: '**Bokeh** is an interactive visualization library. It functions similar to
    matplotlib, but allows us to add hover, zoom, click, and use other interactive
    tools to our plots. It also allows us to render and play with the plots inside
    our Jupyter Notebook.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Bokeh** 是一个交互式可视化库。它的功能类似于 matplotlib，但允许我们为图表添加悬停、缩放、点击等交互功能。它还允许我们在 Jupyter
    Notebook 中渲染并与图表进行互动。'
- en: Having introduced these libraries, let's go back to our Notebook and load them,
    by running the import statements. This will lead us into our fist analysis, where
    we finally start working with a dataset.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍了这些库之后，让我们回到 Notebook 中，通过运行导入语句来加载它们。这将引导我们进入第一次分析，开始使用数据集进行工作。
- en: Import the external libraries and set up the plotting environment
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 导入外部库并设置绘图环境
- en: Open up the `chapter 1` Jupyter Notebook and scroll to the `Python Libraries
    section`.
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 `chapter 1` Jupyter Notebook，滚动到 `Python Libraries` 部分。
- en: Just like for regular Python scripts, libraries can be imported into the Notebook
    at any time. It's best practice to put the majority of the packages you use at
    the top of the file. Sometimes it makes sense to load things midway through the
    Notebook and that is completely OK.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 就像常规的 Python 脚本一样，库可以在 Notebook 中的任何时候导入。最佳实践是将你使用的大部分包放在文件的顶部。有时，在 Notebook
    中途加载库也是完全可以的。
- en: 'Run the cells to import the external libraries and set the plotting options:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行单元格来导入外部库并设置绘图选项：
- en: '![](img/4df0e5af-ac74-49d4-aa62-88e8cec74570.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4df0e5af-ac74-49d4-aa62-88e8cec74570.png)'
- en: 'For a nice Notebook setup, it''s often useful to set various options along
    with the imports at the top. For example, the following can be run to change the
    figure appearance to something more aesthetically pleasing than the `matplotlib`
    and Seaborn defaults:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 Notebook 设置更加美观，通常在顶部与导入库一起设置各种选项是很有用的。例如，下面的代码可以运行，用于将图表外观更改为比 `matplotlib`
    和 Seaborn 默认值更具美感的样式：
- en: '[PRE4]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: So far in this book, we've gone over the basics of using Jupyter Notebooks for
    data science. We started by exploring the platform and finding our way around
    the interface. Then, we discussed the most useful features, which include tab
    completion and magic functions. Finally, we introduced the Python libraries we'll
    be using in this book.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本书中，我们已经介绍了如何使用 Jupyter Notebooks 进行数据科学的基础知识。我们从探索平台并熟悉界面开始。然后，我们讨论了最有用的功能，包括标签自动完成和魔法函数。最后，我们介绍了本书中将使用的
    Python 库。
- en: The next section will be very interactive as we perform our fist analysis together
    using the Jupyter Notebook.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的部分将非常互动，我们将一起使用 Jupyter Notebook 进行第一次分析。
- en: Our First Analysis - The Boston Housing Dataset
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们的第一次分析 - 波士顿房价数据集
- en: So far, this chapter has focused on the features and basic usage of Jupyter.
    Now, we'll put this into practice and do some data exploration and analysis.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本章主要集中在 Jupyter 的功能和基本使用上。现在，我们将把这些知识付诸实践，进行一些数据探索和分析。
- en: The dataset we'll look at in this section is the so-called *Boston housing dataset*.
    It contains US census data concerning houses in various areas around the city
    of Boston. Each sample corresponds to a unique area and has about a dozen measures.
    We should think of samples as rows and measures as columns. The data was fist
    published in 1978 and is quite small, containing only about 500 samples.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这一部分将要查看的数据集是所谓的 *波士顿房价数据集*。它包含了关于波士顿市不同地区房屋的美国人口普查数据。每个样本对应一个独特的地区，包含大约十几个测量指标。我们应该把样本看作行，把测量指标看作列。这个数据集最早发布于
    1978 年，非常小，只有大约 500 个样本。
- en: Now that we know something about the context of the dataset, let's decide on
    a rough plan for the exploration and analysis. If applicable, this plan would
    accommodate the relevant question(s) under study. In this case, the goal is not
    to answer a question but to instead show Jupyter in action and illustrate some
    basic data analysis methods.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们对数据集的背景有了一些了解，现在让我们为探索和分析制定一个大致的计划。如果适用，这个计划将包含正在研究的相关问题。在本例中，目标不是回答某个问题，而是展示
    Jupyter 的实际操作，并演示一些基本的数据分析方法。
- en: 'Our general approach to this analysis will be to do the following:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分析的一般方法将是：
- en: Load the data into Jupyter using a Pandas DataFrame
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Pandas DataFrame 将数据加载到 Jupyter 中
- en: Quantitatively understand the features
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定量理解特征
- en: Look for patterns and generate questions
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 寻找模式并生成问题
- en: Answer the questions to the problems
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解答问题
- en: Loading the Data into Jupyter Using a Pandas DataFrame
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Pandas DataFrame 将数据加载到 Jupyter 中
- en: Oftentimes, data is stored in tables, which means it can be saved as a `comma-separated
    variable (CSV)` file. This format, and many others, can be read into Python as
    a DataFrame object, using the Pandas library. Other common formats include `tab-separated
    variable (TSV)`, SQL tables, and JSON data structures. Indeed, Pandas has support
    for all of these. In this example, however, we are not going to load the data
    this way because the dataset is available directly through scikit-learn.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 数据通常存储在表格中，这意味着它可以保存为 `comma-separated variable (CSV)` 文件。该格式以及许多其他格式可以通过 Pandas
    库加载为 Python 中的 DataFrame 对象。其他常见的格式包括 `tab-separated variable (TSV)`、SQL 表格和 JSON
    数据结构。实际上，Pandas 支持所有这些格式。然而，在这个示例中，我们不会以这种方式加载数据，因为数据集可以直接通过 scikit-learn 获取。
- en: An important part after loading data for analysis is ensuring that it's clean.
    For example, we would generally need to deal with missing data and ensure that
    all columns have the correct datatypes. The dataset we use in this section has
    already been cleaned, so we will not need to worry about this. However, we'll
    see messier data in the second chapter and explore techniques for dealing with
    it.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据进行分析后，一个重要的步骤是确保数据是干净的。例如，我们通常需要处理缺失数据，并确保所有列都具有正确的数据类型。我们在本节中使用的数据集已经清理过，因此我们不需要担心这个问题。不过，在第二章中，我们会遇到更杂乱的数据，并探索处理它的技巧。
- en: Load the Boston housing dataset
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载波士顿住房数据集
- en: 'In the chapter 1 Jupyter Notebook, scroll to subtopic `Loading the Data into
    Jupyter Using a Pandas DataFrame`of `Our First Analysis`: `The Boston Housing
    Dataset`. The Boston housing dataset can be accessed from the `sklearn.datasets`
    module using the `load_boston` method.'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第1章的 Jupyter Notebook 中，滚动到子主题 `Using Pandas DataFrame 加载数据到 Jupyter`，位于 `Our
    First Analysis`：`波士顿住房数据集`。波士顿住房数据集可以通过 `sklearn.datasets` 模块使用 `load_boston`
    方法访问。
- en: 'Run the first two cells in this section to load the Boston dataset and see
    the data structures type:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行本节中的前两个单元格，以加载波士顿数据集并查看数据结构类型：
- en: '![](img/f8abc0d1-4ae2-486b-852e-367c2eeaf03d.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f8abc0d1-4ae2-486b-852e-367c2eeaf03d.png)'
- en: The output of the second cell tells us that it's a scikit-learn Bunch object.
    Let's get some more information about that to understand what we are dealing with.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个单元格的输出告诉我们它是一个 scikit-learn Bunch 对象。让我们获取更多关于它的信息，以便了解我们正在处理的内容。
- en: 'Run the next cell to import the base object from scikit-learn utils and print
    the docstring in our Notebook:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行下一个单元格以从 scikit-learn utils 导入基本对象，并在我们的 Notebook 中打印 docstring：
- en: '![](img/52761b21-8607-4edf-9a8d-50cdda5ceafc.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/52761b21-8607-4edf-9a8d-50cdda5ceafc.png)'
- en: Reading the resulting docstring suggests that it's basically a dictionary, and
    can essentially be treated as such.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读结果的 docstring 表明它本质上是一个字典，可以基本上当作字典来处理。
- en: 'Print the field names (that is, the keys to the dictionary) by running the
    next cell. We find these fields to be self-explanatory: [`''DESCR''`, `''target''`,
    `''data''`, `''feature_names''`] .'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行下一个单元格来打印字段名称（即字典的键）。我们发现这些字段是自解释的：[`'DESCR'`，`'target'`，`'data'`，`'feature_names'`]。
- en: 'Run the next cell to print the dataset description contained in boston[`''DESCR''`]
    . Note that in this call, we explicitly want to print the field value so that
    the Notebook renders the content in a more readable format than the string representation
    (that is, if we just type boston[`''DESCR''`] without wrapping it in a print statement).
    We then see the dataset information as we''ve previously summarized:'
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行下一个单元格，打印包含在 boston[`'DESCR'`] 中的数据集描述。注意，在这个调用中，我们显式地希望打印字段值，以便 Notebook
    能够以比字符串表示更可读的格式渲染内容（也就是说，如果我们只是输入 boston[`'DESCR'`]，而没有用 print 语句包装它）。我们随后看到数据集信息，正如我们之前总结的那样：
- en: '[PRE5]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Of particular importance here are the feature descriptions (under `Attribute Information`).
    We will use this as reference during our analysis.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 特别重要的是特征描述（在 `Attribute Information` 下）。我们将在分析过程中使用这些作为参考。
- en: 'Now, we are going to create a Pandas DataFrame that contains the data. This
    is beneficial for a few reasons: all of our data will be contained in one object,
    there are useful and computationally efficient DataFrame methods we can use, and
    other libraries such as Seaborn have tools that integrate nicely with DataFrames.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将创建一个包含数据的 Pandas DataFrame。这有几个好处：我们的所有数据都将包含在一个对象中，DataFrame 提供了有用且计算高效的方法，并且像
    Seaborn 这样的其他库有与 DataFrame 集成的工具。
- en: In this case, we will create our DataFrame with the standard constructor method.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将使用标准构造方法来创建 DataFrame。
- en: 'Run the cell where Pandas is imported and the docstring is retrieved for `pd.DataFrame`:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行 Pandas 导入和获取 `pd.DataFrame` 文档字符串的单元格：
- en: '![](img/0ab67f16-3da3-41d0-87c6-be2fe8d1009c.png)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0ab67f16-3da3-41d0-87c6-be2fe8d1009c.png)'
- en: The docstring reveals the DataFrame input parameters. We want to feed in boston[`'data'`]
    for the data and use boston[`'feature_names'`] for the headers.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 文档字符串显示了 DataFrame 输入参数。我们希望将 boston[`'data'`] 作为数据输入，并使用 boston[`'feature_names'`]
    作为列标题。
- en: 'Run the next few cells to print the data, its shape, and the feature names:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行接下来的几行代码来打印数据、数据的形状和特征名称：
- en: '![](img/97e175b0-4092-4f73-93a1-90ed07264741.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/97e175b0-4092-4f73-93a1-90ed07264741.png)'
- en: Looking at the output, we see that our data is in a `2D NumPy array`. Running
    the command boston[`'data'`].shape returns the length (number of samples) and
    the number of features as the first and second outputs, respectively
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中，我们看到数据是一个 `2D NumPy 数组`。运行命令 boston[`'data'`].shape 会返回样本数量（第一个输出）和特征数量（第二个输出）。
- en: 'Load the data into a Pandas DataFrame `df` by running the following:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下代码将数据加载到 Pandas DataFrame `df` 中：
- en: '[PRE6]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In machine learning, the variable that is being modeled is called the target
    variable; it's what you are trying to predict given the features. For this dataset,
    the suggested target is MEDV, the median house value in 1,000s of dollars
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，正在建模的变量称为目标变量；它是你试图根据特征预测的内容。对于这个数据集，建议的目标是 MEDV，即房屋中位数价值，以千美元为单位。
- en: 'Run the next cell to see the shape of the target:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行下一个单元格来查看目标的形状：
- en: '![](img/ffc414d7-7df4-4df1-aa4f-680e77eb0a19.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ffc414d7-7df4-4df1-aa4f-680e77eb0a19.png)'
- en: We see that it has the same length as the features, which is what we expect.
    It can therefore be added as a new column to the DataFrame.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到它的长度与特征的长度相同，这正是我们所期望的。因此，它可以作为新列添加到 DataFrame 中。
- en: 'Add the target variable to `df` by running the cell with the following:'
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行包含以下内容的单元格，将目标变量添加到 `df`：
- en: '[PRE7]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: To distinguish the target from our features, it can be helpful to store it at
    the front of our DataFrame.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了将目标与特征区分开来，将目标存储在 DataFrame 的前面会很有帮助。
- en: 'Move the target variable to the front of df by running the cell with the following:'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过运行包含以下内容的单元格，将目标变量移到 df 的前面：
- en: '[PRE8]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, we introduce a dummy variable y to hold a copy of the target column before
    removing it from the DataFrame. We then use the Pandas concatenation function
    to combine it with the remaining DataFrame along the 1st axis (as opposed to the
    0th axis, which combines rows).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们引入了一个虚拟变量 y 来保存目标列的副本，之后再从 DataFrame 中删除它。然后我们使用 Pandas 的连接函数，将其与剩余的 DataFrame
    按照第一轴（而不是第零轴，后者是合并行）连接起来。
- en: You will often see dot notation used to reference DataFrame columns. For example,
    previously we could have done `y = df.MEDV.copy()` . This does not work for deleting
    columns, however; `del df.MEDV` would raise an error.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 你经常会看到使用点符号来引用 DataFrame 的列。例如，以前我们可以写 `y = df.MEDV.copy()`。但是，这种方式无法用来删除列；`del
    df.MEDV` 会引发错误。
- en: Now that the data has been loaded in its entirety, let's take a look at the
    DataFrame.
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在数据已经完全加载，我们来看看 DataFrame。
- en: 'We can do `df.head()` or `df.tail()` to see a glimpse of the data and `len(df)`
    to make sure the number of samples is what we expect. Run the next few cells to
    see the head, tail, and length of `df`:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过`df.head()`或`df.tail()`查看数据的一个简略概况，使用`len(df)`来确保样本数量符合预期。运行接下来的几个单元格来查看`df`的头部、尾部和长度：
- en: '![](img/3407f927-6154-49ed-9a5d-32a9e90fcad9.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3407f927-6154-49ed-9a5d-32a9e90fcad9.png)'
- en: '![](img/5be64859-764c-43ca-8268-1d44953c0bc7.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5be64859-764c-43ca-8268-1d44953c0bc7.png)'
- en: Each row is labeled with an index value, as seen in bold on the left side of
    the table.By default, these are a set of integers starting at 0 and incrementing
    by one for each row.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 每一行都有一个索引值，在表格的左侧以**粗体**显示。默认情况下，这些是从0开始并按顺序递增的整数，每一行对应一个索引。
- en: Printing `df.dtypes` will show the datatype contained within each column.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印`df.dtypes`将显示每一列中包含的数据类型。
- en: Run the next cell to see the datatypes of each column.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 运行下一个单元格查看每一列的数据类型。
- en: For this dataset, we see that every field is a float and therefore most likely
    a continuous variable, including the target. This means that predicting the target
    variable is a regression problem.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个数据集，我们看到每个字段都是浮动类型，因此很可能是连续变量，包括目标变量。这意味着预测目标变量是一个回归问题。
- en: 'The next thing we need to do is clean the data by dealing with any missing
    data, which Pandas automatically sets as `NaN` values. These can be identified
    by running `df.isnull()` , which returns a Boolean DataFrame of the same shape
    as `df.` To get the number of NaN''s per column, we can do `df.isnull().sum()`
    . Run the next cell to calculate the number of `NaN` values in each column:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要做的是清理数据，处理任何缺失的数据，Pandas会将缺失数据自动标记为`NaN`。可以通过运行`df.isnull()`来识别这些缺失数据，它会返回与`df`相同形状的布尔型DataFrame。要获取每列中NaN的数量，我们可以使用`df.isnull().sum()`。运行下一个单元格来计算每列中`NaN`值的数量：
- en: '![](img/9d9256fa-2766-47dc-9fc8-9298a704a2b5.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9d9256fa-2766-47dc-9fc8-9298a704a2b5.png)'
- en: For this dataset, we see there are no NaN's, which means we have no immediate
    work to do in cleaning the data and can move on.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个数据集，我们看到没有NaN值，这意味着我们无需立即进行数据清理，可以继续分析。
- en: To simplify the analysis, the final thing we'll do before exploration is remove some
    of the columns. We won't bother looking at these, and instead focus on the remainder
    in more detail.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了简化分析，在探索之前我们将移除一些列。我们不会关注这些列，而是将重点放在其余的列上，进行更详细的分析。
- en: 'Remove some columns by running the cell that contains the following code:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行包含以下代码的单元格来移除一些列：
- en: '[PRE9]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Data Exploration
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据探索
- en: Since this is an entirely new dataset that we've never seen before, the first
    goal here is to understand the data. We've already seen the textual description
    of the data, which is important for qualitative understanding. We'll now compute
    a quantitative description.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个我们以前从未见过的全新数据集，首要目标是理解数据。我们已经看到了数据的文本描述，这对于定性理解非常重要。接下来我们将计算一个定量的描述。
- en: Explore the Boston housing dataset
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索波士顿住房数据集
- en: 'Navigate to Subtopic *Data exploration in the Jupyter Notebook* and run the cell
    containing `df.describe()` :'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到子主题*Jupyter Notebook中的数据探索*并运行包含`df.describe()`的单元格：
- en: '![](img/5b92da6c-2b53-4acc-a447-113021e353da.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5b92da6c-2b53-4acc-a447-113021e353da.png)'
- en: This computes various properties including the mean, standard deviation, minimum,
    and maximum for each column. This table gives a high-level idea of how everything
    is distributed. Note that we have taken the transform of the result by adding
    a .T to the output; this swaps the rows and columns. Going forward with the analysis,
    we will specify a set of columns to focus on.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码计算了每一列的各种属性，包括均值、标准差、最小值和最大值。这个表格提供了一个高层次的视图，展示了数据的分布情况。注意，我们通过在输出中添加`.T`来对结果进行转置，这会交换行和列。接下来的分析中，我们将指定一组列进行重点关注。
- en: 'Run the cell where these "focus columns" are defined:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行定义这些“焦点列”的单元格：
- en: '[PRE10]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This subset of columns can be selected from `df` using square brackets. Display
    this subset of the DataFrame by running `df[cols].head()` :'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以使用方括号从`df`中选择这个子集的列。运行`df[cols].head()`来显示这个DataFrame的子集：
- en: '![](img/d0f04873-7055-41ec-b6ef-4b1a0b7a2b70.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d0f04873-7055-41ec-b6ef-4b1a0b7a2b70.png)'
- en: 'As a reminder, let''s recall what each of these columns is. From the dataset documentation,
    we have the following:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下，让我们回顾一下这些列的含义。根据数据集文档，以下是我们所看到的：
- en: RM average number of rooms per dwelling
  id: totrans-222
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: RM 每个住宅的平均房间数
- en: AGE proportion of owner-occupied units built prior to 1940
  id: totrans-223
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: AGE 1940年之前建造的自有住房单元的比例
- en: TAX full-value property-tax rate per $10,000
  id: totrans-224
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: TAX 每$10,000的全值房产税率
- en: LSTAT % lower status of the population
  id: totrans-225
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: LSTAT % 低收入群体比例
- en: MEDV Median value of owner-occupied homes in $1000's
  id: totrans-226
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: MEDV 业主自住住房的中位数价值（以 $1000 为单位）
- en: To look for patterns in this data, we can start by calculating the pairwise correlations
    using `pd.DataFrame.corr`.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在这些数据中寻找模式，我们可以从计算成对相关性开始，使用 `pd.DataFrame.corr`。
- en: 'Calculate the pairwise correlations for our selected columns by running the
    cell containing the following code:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行包含以下代码的单元格，计算我们选择的列的成对相关性：
- en: '[PRE11]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](img/e79bc1bb-6cdf-4d9d-92cd-3be3db54084d.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e79bc1bb-6cdf-4d9d-92cd-3be3db54084d.png)'
- en: This resulting table shows the correlation score between each set of values.
    Large positive scores indicate a strong positive (that is, in the same direction)
    correlation.As expected, we see maximum values of 1 on the diagonal.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果表格显示了每对值之间的相关性得分。较大的正相关得分表示强正相关（即方向相同）。正如预期的那样，我们在对角线看到的最大值为 1。
- en: 'Pearson coefficient is defined as the co-variance between two variables,divided
    by the product of their standard deviations:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 皮尔逊系数被定义为两个变量之间的协方差，除以它们标准差的乘积：
- en: '![](img/c647c0e7-9bc6-4335-b95b-3ec6342cf11c.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c647c0e7-9bc6-4335-b95b-3ec6342cf11c.png)'
- en: 'The co-variance, in turn, is defined as follows:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 协方差则定义如下：
- en: '![](img/c6309711-d7e1-4a6d-ae40-9c909ad8b76d.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6309711-d7e1-4a6d-ae40-9c909ad8b76d.png)'
- en: Here, n is the number of samples, *x[i]* and *y[i]* are the individual samples
    being summed over, and ![](img/1f9d23ad-d253-4355-9289-7d79761bc52c.png) and ![](img/46020eb6-e869-471d-9fa5-2e3b323b128e.png)  are
    the means of each set.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，n 是样本数量，*x[i]* 和 *y[i]* 是被求和的单个样本，![](img/1f9d23ad-d253-4355-9289-7d79761bc52c.png)
    和 ![](img/46020eb6-e869-471d-9fa5-2e3b323b128e.png) 是每组的均值。
- en: Instead of straining our eyes to look at the preceding table, it's nicer to
    visualize it with a heatmap. This can be done easily with Seaborn.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 与其眼睛费力地看前面的表格，不如用热图将其可视化。这可以通过 Seaborn 轻松完成。
- en: 'Run the next cell to initialize the plotting environment, as discussed earlier
    in the chapter. Then, to create the heatmap, run the cell containing the following
    code:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行下一个单元格来初始化绘图环境，如本章前所述。然后，要创建热图，运行包含以下代码的单元格：
- en: '[PRE12]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '![](img/3ec1a261-49e6-4b0f-819e-f39c15ac38a2.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3ec1a261-49e6-4b0f-819e-f39c15ac38a2.png)'
- en: We call `sns.heatmap` and pass the pairwise correlation matrix as input. We
    use a custom color palette here to override the Seaborn default. The function
    returns a `matplotlib.axes` object which is referenced by the variable `ax`. The
    final figure is then saved as a high resolution PNG to the `figures` folder.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们调用 `sns.heatmap` 并传入成对相关矩阵作为输入。我们在这里使用自定义的颜色调色板来覆盖 Seaborn 默认设置。该函数返回一个 `matplotlib.axes`
    对象，变量 `ax` 引用该对象。最终图像会作为高分辨率 PNG 保存到 `figures` 文件夹中。
- en: For the final step in our dataset exploration exercise, we'll visualize our
    data using Seaborn's `pairplot` function.
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据集探索的最后一步，我们将使用 Seaborn 的 `pairplot` 函数来可视化我们的数据。
- en: 'Visualize the DataFrame using Seaborn''s pairplot function. Run the cell containing
    the following code:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Seaborn 的 `pairplot` 函数可视化 DataFrame。运行以下代码单元：
- en: '[PRE13]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](img/c86a31f8-972a-4b13-8cbb-e07e5d4a60c5.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c86a31f8-972a-4b13-8cbb-e07e5d4a60c5.png)'
- en: Having previously used a heatmap to visualize a simple overview of the correlations,
    this plot allows us to see the relationships in far more detail.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前使用热图可视化相关性概况后，这个图表可以让我们更加详细地观察各个关系。
- en: 'Looking at the histograms on the diagonal, we see the following:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 查看对角线上的直方图，我们可以看到以下内容：
- en: 'a: RM and MEDV have the closest shape to normal distributions.'
  id: totrans-248
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'a: RM 和 MEDV 的分布形态最接近正态分布。'
- en: 'b: AGE is skewed to the left and LSTAT is skewed to the right (this may seem counter
    intuitive but skew is defined in terms of where the mean is positioned in relation
    to the max).'
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'b: AGE 向左偏斜，而 LSTAT 向右偏斜（这可能看起来有点违反直觉，但偏斜是根据均值相对于最大值的位置来定义的）。'
- en: 'c: For TAX, we find a large amount of the distribution is around 700\. This
    is also'
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'c: 对于 TAX，我们发现大部分分布集中在 700 附近。这也是'
- en: evident from the scatter plots
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从散点图中可以看出
- en: Taking a closer look at the **MEDV** histogram in the bottom right, we actually
    see something similar to **TAX** where there is a large upper-limit bin around
    $50,000\. Recall when we did `df.describe()` , the min and max of **MDEV** was
    5k and 50k, respectively. This suggests that median house values in the dataset
    were capped at 50k.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察右下角的 **MEDV** 直方图，我们实际上看到了一些类似于 **TAX** 的现象，即在 $50,000 附近有一个较大的上限区间。回想一下我们在执行
    `df.describe()` 时，**MDEV** 的最小值和最大值分别是 5k 和 50k。这表明数据集中的房屋中位数价值被限制在了 50k。
- en: Introduction to Predictive Analytics with Jupyter Notebooks
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Jupyter Notebooks 进行预测分析简介
- en: Continuing our analysis of the Boston housing dataset, we can see that it presents
    us with a regression problem where we predict a continuous target variable given
    a set of features. In particular, we'll be predicting the median house value (**MEDV**).
    We'll train models that take only one feature as input to make this prediction.
    This way, the models will be conceptually simple to understand and we can focus
    more on the technical details of the scikit-learn API. Then, in the next chapter,
    you'll be more comfortable dealing with the relatively complicated models.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 继续分析波士顿房价数据集，我们可以看到它为我们提供了一个回归问题，在这个问题中，我们根据一组特征预测一个连续的目标变量。具体来说，我们将预测中位房价（**MEDV**）。我们将训练仅以一个特征作为输入的模型来进行预测。这样，模型在概念上简单易懂，我们可以更专注于
    scikit-learn API 的技术细节。然后，在下一章中，你将能够更轻松地处理相对复杂的模型。
- en: Linear models with Seaborn and scikit-learn
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Seaborn 和 scikit-learn 进行线性模型分析
- en: 'Scroll to Subtopic`Introduction to predictive analytics` in the Jupyter Notebook
    and look just above at the pairplot we created in the previous section. In particular,
    look at the scatter plots in the bottom-left corner:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到 Jupyter Notebook 中的子主题 `Introduction to predictive analytics`，并查看上方我们在前一节中创建的配对图。特别地，查看左下角的散点图：
- en: '![](img/7eb25257-8cc2-4530-af19-ec880503a76e.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eb25257-8cc2-4530-af19-ec880503a76e.png)'
- en: 'Note how the number of rooms per house (**RM**) and the % of the population
    that is lower class (**LSTAT**) are highly correlated with the median house value
    (**MDEV**). Let''s pose the following question: how well can we predict **MDEV**
    given these variables?'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，每个房屋的房间数（**RM**）和属于下层阶级的百分比（**LSTAT**）与中位房价（**MDEV**）高度相关。让我们提出以下问题：给定这些变量，我们能多好地预测
    **MDEV**？
- en: To help answer this, let's first visualize the relationships using Seaborn.
    We will draw the scatter plots along with the line of best fit linear models.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助回答这个问题，首先让我们使用 Seaborn 可视化这些关系。我们将绘制散点图，并加上最佳拟合线性模型。
- en: 'Draw scatter plots along with the linear models by running the cell that contains
    the following:'
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行包含以下内容的单元格来绘制散点图，并加上线性模型：
- en: '[PRE14]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![](img/e880df1f-bc8e-4f12-936c-bb362791395d.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e880df1f-bc8e-4f12-936c-bb362791395d.png)'
- en: The line of best fit is calculated by minimizing the ordinary least squares
    error function, something Seaborn does automatically when we call the `regplot`
    function. Also note the shaded areas around the lines, which represent 95% confidence
    intervals.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳拟合线是通过最小化普通最小二乘误差函数来计算的，这是 Seaborn 在我们调用 `regplot` 函数时自动完成的。还请注意线周围的阴影区域，表示95%的置信区间。
- en: These 95% confidence intervals are calculated by taking the standard deviation
    of data in bins perpendicular to the line of best fit, effectively determining
    the confidence intervals at each point along the line of best fit. In practice,
    this involves Seaborn bootstrapping the data, a process where new data is created
    through random sampling with replacement. The number of bootstrapped samples is
    automatically determined based on the size of the dataset, but can be manually
    set as well by passing the `n_boot` argument.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 这些95%的置信区间是通过在垂直于最佳拟合线的区间内取数据的标准差来计算的，有效地确定了最佳拟合线每个点的置信区间。实际上，这涉及到 Seaborn 对数据进行自助法（bootstrap）处理，这个过程通过带有放回的随机抽样生成新的数据。自助法样本的数量是根据数据集的大小自动确定的，但也可以通过传递
    `n_boot` 参数手动设置。
- en: 'Seaborn can also be used to plot the residuals for these relationships. Plot
    the residuals by running the cell containing the following:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Seaborn 还可以用来绘制这些关系的残差图。通过运行包含以下内容的单元格来绘制残差图：
- en: '[PRE15]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '![](img/ca395a1c-acc4-465a-b249-23a594b7248c.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ca395a1c-acc4-465a-b249-23a594b7248c.png)'
- en: Each point on these residual plots is the difference between that sample (y)
    and the linear model prediction ( ŷ). Residuals greater than zero are data points
    that would be underestimated by the model. Likewise, residuals less than zero
    are data points that would be overestimated by the model.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这些残差图上的每个点是该样本（y）与线性模型预测值（ŷ）之间的差异。大于零的残差表示模型低估了数据点。类似地，小于零的残差表示模型高估了数据点。
- en: Patterns in these plots can indicate sub optimal modeling. In each preceding
    case,we see diagonally arranged scatter points in the positive region. These are
    caused by the $50,000 cap on MEDV. The RM data is clustered nicely around 0, which indicates
    a good fit. On the other hand, LSTAT appears to be clustered lower than 0.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图中的模式可能表明模型存在不足。在前面的每个案例中，我们看到正区域内斜对角排列的散点。这是由MEDV的$50,000上限造成的。RM数据围绕0聚集，表明拟合效果良好。另一方面，LSTAT似乎聚集在0以下。
- en: 'Moving on from visualizations, the fits can be quantified by calculating the
    mean squared error. We''ll do this now using scikit-learn. Defile a function that
    calculates the line of best fit and mean squared error, by running the cell that
    contains the following:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 离开可视化后，拟合度可以通过计算均方误差来量化。我们现在将使用scikit-learn来完成这一步。通过运行包含以下内容的单元，定义一个计算最佳拟合线和均方误差的函数：
- en: '[PRE16]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: In the `get_mse` function, we first assign the variables y and x to the target
    **MDEV** and the dependent feature, respectively. These are cast as `NumPy` arrays
    by calling the values attribute. The dependent features array is reshaped to the
    format expected by scikit-learn; this is only necessary when modeling a one-dimensional
    feature space. The model is then instantiated and fitted on the data. For linear
    regression, the fitting consists of computing the model parameters using the ordinary
    least squares method (minimizing the sum of squared errors for each sample). Finally,
    after determining the parameters, we predict the target variable and use the results
    to calculate the MSE.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在`get_mse`函数中，我们首先将变量y和x分别赋值为目标**MDEV**和依赖特征。这些变量通过调用`values`属性被转换为`NumPy`数组。依赖特征数组被重新塑形为scikit-learn期望的格式；这仅在建模一维特征空间时才需要。接着，模型被实例化并在数据上进行拟合。对于线性回归，拟合过程包括使用最小二乘法计算模型参数（最小化每个样本的平方误差和）。最后，在确定参数后，我们预测目标变量，并使用结果计算MSE。
- en: 'Call the `get_mse` function for both RM and LSTAT, by running the cell containing the
    following:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行包含以下内容的单元来调用`get_mse`函数，分别对RM和LSTAT进行计算：
- en: '[PRE17]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '![](img/2f6eb116-2c27-4a0b-9655-bc72b31b0631.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2f6eb116-2c27-4a0b-9655-bc72b31b0631.png)'
- en: Comparing the **MSE**, it turns out the error is slightly lower for **LSTAT**.
    Looking back to the scatter plots, however, it appears that we might have even
    better success using a polynomial model for LSTAT. In the next activity, we will
    test this by computing a third order polynomial model with scikit-learn.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 比较**MSE**后，结果显示**LSTAT**的误差略低。然而，回顾散点图，似乎我们使用多项式模型来拟合LSTAT会取得更好的效果。在接下来的活动中，我们将通过使用scikit-learn计算三次多项式模型来验证这一点。
- en: 'Forgetting about our Boston housing dataset for a minute, consider another
    real-world situation where you might employ polynomial regression. The following
    example is modeling weather data. In the following plot, we see temperatures (lines)
    and precipitations (bars) for Vancouver, BC, Canada:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 暂时不考虑我们的波士顿住房数据集，想象另一个可能应用多项式回归的实际场景。以下示例是天气数据建模。在下图中，我们可以看到温度（线条）和降水量（柱状图）数据，来自加拿大不列颠哥伦比亚省温哥华市：
- en: '![](img/03049e0f-c8d0-41a5-94fa-18f6412ef434.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![](img/03049e0f-c8d0-41a5-94fa-18f6412ef434.png)'
- en: Any of these fields are likely to be fit quite well by a fourth-order polynomial.
    This would be a very valuable model to have, for example, if you were interested
    in predicting the temperature or precipitation for a continuous range of dates.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 这些字段中的任何一个都可能很好地拟合四次多项式。例如，如果你有兴趣预测连续日期范围内的温度或降水量，这将是一个非常有价值的模型。
- en: 'You can find the data source for this here:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到数据来源：
- en: '[http://climate.weather.gc.ca/climate_normals/results_e.html?stnID=888.](http://climate.weather.gc.ca/climate_normals/results_e.html?stnID=888.)'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://climate.weather.gc.ca/climate_normals/results_e.html?stnID=888.](http://climate.weather.gc.ca/climate_normals/results_e.html?stnID=888.)'
- en: Activity:Building a Third-Order Polynomial Model
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 活动：构建三次多项式模型
- en: 'Shifting our attention back to the Boston housing dataset, we would like to
    build a third order polynomial model to compare against the linear one. Recall
    the actual problem we are trying to solve: predicting the median house value,
    given the lower class population percentage. This model could benefit a prospective
    Boston house purchaser who cares about how much of their community would be lower
    class.'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 将注意力转回到波士顿住房数据集，我们希望建立一个三次多项式模型，来与线性模型进行比较。回想一下我们实际想要解决的问题：在给定低收入阶层人口百分比的情况下，预测中位数房价。这个模型可能会对有意购买波士顿房产、关心社区中低收入阶层比例的购房者有帮助。
- en: Use scikit-learn to fit a polynomial regression model to predict the median
    house value (MEDV), given the LSTAT values. We are hoping to build a model that
    has a lower meansquared error (MSE).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 来拟合一个多项式回归模型，以根据 LSTAT 值预测中位数房价 (MEDV)。我们希望建立一个具有较低均方误差（MSE）的模型。
- en: Linear models with Seaborn and scikit-learn
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Seaborn 和 scikit-learn 进行线性模型建模
- en: Scroll to the empty cells at the bottom of `Subtopic Introduction to Predictive
    Analysis in your Jupyter Notebook`.These will be found beneath the linear-model
    MSE calculation cell under the Activity heading.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 滚动到 Jupyter Notebook 中 `Subtopic Introduction to Predictive Analysis` 底部的空单元格。这些单元格位于线性模型
    MSE 计算单元格下方的 Activity 标题下。
- en: You should fill these empty cells in with code as we complete the activity.
    You may need to insert new cells as these become filled up; please do so as needed!
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们完成活动时，您应当将这些空单元格填充为代码。随着这些单元格的填充，您可能需要插入新的单元格；请根据需要进行操作！
- en: 'Given that our data is contained in the DataFrame `df`, we will fist pull out
    our dependent feature and target variable using the following:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们的数据包含在 DataFrame `df` 中，我们首先通过以下代码提取我们的依赖特征和目标变量：
- en: '[PRE18]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This is identical to what we did earlier for the linear model.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们之前为线性模型所做的完全相同。
- en: 'Check out what x looks like by printing the fist few samples with print(x[:3])
    :'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过打印前几个样本 `print(x[:3])` 来查看 x 的样子：
- en: '![](img/8abfeb62-7431-408c-8833-3eccf8787534.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8abfeb62-7431-408c-8833-3eccf8787534.png)'
- en: Notice how each element in the array is itself an array with length 1\. This
    is what` reshape(-1,1)` does, and it is the form expected by scikit-learn.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，每个数组中的元素本身是一个长度为 1 的数组。这就是 `reshape(-1, 1)` 的作用，它是 scikit-learn 所期望的格式。
- en: Next, we are going to transform x into "polynomial features". The rationale
    for this may not be immediately obvious but will be explained shortly.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将把 x 转换成“多项式特征”。这种做法的理由可能并不立即显而易见，但稍后会解释清楚。
- en: 'Import the appropriate transformation tool from scikit-learn and instantiate
    the third-degree polynomial feature transformer:'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从 scikit-learn 导入适当的转换工具并实例化一个三次多项式特征变换器：
- en: '[PRE19]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: At this point, we simply have an instance of our feature transformer. Now, let's
    use it to transform the LSTAT feature (as stored in the variable x) by running
    the `fit_transform` method.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此时，我们仅拥有特征变换器的一个实例。现在，让我们使用它通过运行 `fit_transform` 方法来转换 LSTAT 特征（存储在变量 x 中）。
- en: 'Build the polynomial feature set by running the following code:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下代码构建多项式特征集：
- en: '[PRE20]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Check out what `x_poly` looks like by printing the fist few samples with print(`x_poly[:3]`)
    .
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过打印前几个样本 `print(x_poly[:3])` 来查看 `x_poly` 的样子。
- en: '![](img/3f3370ee-c31c-4727-a552-c84ce7b6b512.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f3370ee-c31c-4727-a552-c84ce7b6b512.png)'
- en: Unlike x, the arrays in each row now have length 4, where the values have been calculated
    as x⁰, x¹, x² and x³.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 与 x 不同，每行中的数组现在具有 4 的长度，其中值已计算为 x⁰、x¹、x² 和 x³。
- en: 'We are now going to use this data to fit a linear model. Labeling the features
    as a, b, c, and d, we will calculate the coefficients α[0], α[1], α[2], and α[3]
    and of the linear model:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用这些数据来拟合一个线性模型。将特征标记为 a、b、c 和 d，我们将计算线性模型的系数 α[0]、α[1]、α[2] 和 α[3]：
- en: '![](img/f3d84ebf-c30f-4b47-9a2b-838a2180dc86.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f3d84ebf-c30f-4b47-9a2b-838a2180dc86.png)'
- en: 'We can plug in the definitions of a, b, c, and d, to get the following polynomial model,
    where the coefficients are the same as the previous ones:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以插入 a、b、c 和 d 的定义，得到以下多项式模型，其中系数与之前相同：
- en: '![](img/c6c3cd61-d065-4a26-92df-1986f0851a40.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6c3cd61-d065-4a26-92df-1986f0851a40.png)'
- en: 'We''ll import the Linear Regression class and build our linear classification
    model the same way as before, when we calculated the **MSE**. Run the following:'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将导入线性回归类，并像之前计算 **MSE** 时一样构建我们的线性分类模型。运行以下代码：
- en: '[PRE21]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Extract the coefficients and print the polynomial model using the following
    code:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取系数并使用以下代码打印出多项式模型：
- en: '[PRE22]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![](img/9b204ff8-27d6-41b5-b1c9-ac4b3b250c55.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9b204ff8-27d6-41b5-b1c9-ac4b3b250c55.png)'
- en: To get the actual model intercept, we have to add the `intercept_ and coef_[0]`attributes.
    The higher-order coefficients are then given by the remaining values of `coef_.`
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取实际的模型截距，我们必须添加 `intercept_` 和 `coef_[0]` 属性。然后，高阶系数由 `coef_` 的其余值给出。
- en: 'Determine the predicted values for each sample and calculate the residuals
    by running the following code:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下代码，确定每个样本的预测值并计算残差：
- en: '[PRE23]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Print some of the residual values by running print(`resid_MEDV[:10]`) :'
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行 `print(resid_MEDV[:10])` 打印一些残差值：
- en: '![](img/f2de5a79-3841-4241-a9a0-b08db4d56950.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f2de5a79-3841-4241-a9a0-b08db4d56950.png)'
- en: We'll plot these soon to compare with the linear model residuals, but first
    we will calculate the **MSE**.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很快会绘制这些结果，以便与线性模型的残差进行比较，但首先我们将计算**MSE**。
- en: 'Run the following code to print the MSE for the third-order polynomial model:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码来打印第三阶多项式模型的 MSE：
- en: '[PRE24]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](img/63360ff2-9188-47ac-9d96-324b2956b255.png)'
  id: totrans-320
  prefs: []
  type: TYPE_IMG
  zh: '![](img/63360ff2-9188-47ac-9d96-324b2956b255.png)'
- en: As can be seen, the **MSE** is significantly less for the polynomial model compared
    to the linear model (which was 38.5). This error metric can be converted to an
    average error in dollars by taking the square root. Doing this for the polynomial
    model, we find the average error for the median house value is only $5,300.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，与线性模型（其 MSE 为 38.5）相比，多项式模型的**MSE**显著更小。这个误差指标可以通过取平方根转换为平均误差（以美元为单位）。对于多项式模型，计算得出的房屋中位数值的平均误差仅为
    $5,300。
- en: Now, we'll visualize the model by plotting the polynomial line of best fit along
    with the data.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将通过绘制多项式最佳拟合线和数据点来可视化模型。
- en: 'Plot the polynomial model along with the samples by running the following:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下代码绘制多项式模型以及样本数据：
- en: '[PRE25]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](img/cad9c13c-603c-49df-9042-deea5d0a3073.png)'
  id: totrans-325
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cad9c13c-603c-49df-9042-deea5d0a3073.png)'
- en: Here, we are plotting the red curve by calculating the polynomial model predictions
    on an array of x values. The array of x values was created using `np.linspace`,
    resulting in 50 values arranged evenly between 2 and 38.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们通过在一组 x 值上计算多项式模型的预测值来绘制红色曲线。x 值的数组是使用`np.linspace`创建的，结果是从 2 到 38 之间均匀分布的
    50 个值。
- en: Now, we'll plot the corresponding residuals. Whereas we used Seaborn for this
    earlier, we'll have to do it manually to show results for a scikit-learn model.
    Since we already calculated the residuals earlier, as reference by the `resid_MEDV`
    variable, we simply need to plot this list of values on a scatter chart.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将绘制相应的残差图。之前我们使用了 Seaborn，但为了展示 scikit-learn 模型的结果，我们需要手动绘制。由于我们之前已经计算了残差，可以通过`resid_MEDV`变量作为参考，我们只需将这些数值绘制在散点图上。
- en: 'Plot the residuals by running the following:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下代码绘制残差图：
- en: '[PRE26]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](img/6f2a0295-d952-4279-b9f0-6b3c9783d272.png)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f2a0295-d952-4279-b9f0-6b3c9783d272.png)'
- en: Compared to the linear model LSTAT residual plot, the polynomial model residuals appear
    to be more closely clustered around y - ŷ = 0\. Note that y is the sample MEDV
    and ŷ is the predicted value. There are still clear patterns, such as the cluster near
    x = 7 and y = -7 that indicates suboptimal modeling.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 与线性模型的 LSTAT 残差图相比，多项式模型的残差似乎更紧密地集中在 y - ŷ = 0 附近。注意，y 是样本 MEDV，ŷ 是预测值。依然能看到明显的模式，比如在
    x = 7 和 y = -7 附近的聚集，这表明模型拟合不佳。
- en: Having successfully modeled the data using a polynomial model, let's finish
    up this chapter by looking at categorical features. In particular, we are going
    to build a set of categorical features and use them to explore the dataset in
    more detail.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功使用多项式模型拟合数据之后，让我们通过查看分类特征来完成这一章。特别地，我们将构建一组分类特征，并利用它们更详细地探索数据集。
- en: Using Categorical Features for Segmentation Analysis
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用分类特征进行分段分析
- en: Often, we find datasets where there are a mix of continuous and categorical
    fields. In such cases, we can learn about our data and find patterns by segmenting
    the continuous variables with the categorical fields.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 经常会遇到包含连续变量和分类变量的数据集。在这种情况下，我们可以通过将连续变量与分类字段进行分段，来学习数据并寻找模式。
- en: As a specific example, imagine you are evaluating the return on investment from
    an ad campaign. The data you have access to contain measures of some calculated
    **return on investment (ROI)** metric. These values were calculated and recorded
    daily and you are analyzing data from the previous year. You have been tasked
    with finding data-driven insights on ways to improve the ad campaign. Looking
    at the ROI daily time series, you see a weekly oscillation in the data. Segmenting
    by day of the week, you find the following ROI distributions (where 0 represents
    the fist day of the week and 6 represents the last).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 以一个具体的例子为例，假设你正在评估广告活动的投资回报率。你所能访问的数据包含某些计算出的**投资回报率（ROI）**指标。这些数值是按天计算并记录的，而你正在分析去年的数据。你的任务是从数据中找到改进广告活动的见解。查看
    ROI 的每日时间序列，你会看到数据中有一个每周的波动。通过按星期几进行分段，你可以发现以下 ROI 分布（其中 0 代表一周的第一天，6 代表最后一天）。
- en: '![](img/d5d7241b-a0c9-4edc-94fa-5587503134ce.png)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d5d7241b-a0c9-4edc-94fa-5587503134ce.png)'
- en: As a specific example, imagine you are evaluating the return on investment from
    an ad campaign. The data you have access to contain measures of some calculated
    return on investment (**ROI**) metric. These values were calculated and recorded
    daily and you are analyzing data from the previous year. You have been tasked
    with finding data-driven insights on ways to improve the ad campaign. Looking
    at the ROI daily time series, you see a weekly oscillation in the data. Segmenting
    by day of the week, you find the following ROI distributions (where 0 represents
    the fist day of the week and 6 represents the last).
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 举个具体例子，假设你正在评估一场广告活动的投资回报率。你能访问的数据包含一些计算出的投资回报率（**ROI**）指标。这些值是每天计算并记录的，你正在分析去年的数据。你的任务是从数据中挖掘改进广告活动的见解。查看ROI的日时间序列时，你会看到数据中有每周的波动。通过按星期几分段，你会发现以下的ROI分布（其中0表示一周的第一天，6表示最后一天）。
- en: Since we don't have any categorical fields in the Boston housing dataset we
    are working with, we'll create one by effectively discretizing a continuous field.
    In our case, this will involve binning the data into "low", "medium", and "high"
    categories. It's important to note that we are not simply creating a categorical
    data field to illustrate the data analysis concepts in this section. As will be
    seen, doing this can reveal insights from the data that would otherwise be difficult
    to notice or altogether unavailable.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在使用的波士顿住房数据集中没有类别字段，我们将通过有效地将连续字段离散化来创建一个。在我们的例子中，这将涉及将数据分为“低”、“中”和“高”类别。需要注意的是，我们创建类别数据字段并不是仅为了说明本节中的数据分析概念。如将要看到的那样，做此操作可以揭示数据中一些原本难以察觉或完全无法获得的见解。
- en: Create categorical filelds from continuous variables and make segmented visualizations
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从连续变量创建类别字段并进行分段可视化
- en: 'Scroll up to the pair plot in the Jupyter Notebook where we compared MEDV, LSTAT,
    TAX, AGE, and RM:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向上滚动至Jupyter Notebook中的配对图，我们在其中比较了MEDV、LSTAT、TAX、AGE和RM：
- en: '![](img/23eae59d-883a-422a-a632-3517aba32418.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![](img/23eae59d-883a-422a-a632-3517aba32418.png)'
- en: Take a look at the panels containing AGE. As a reminder, this feature is defined
    as the *proportion of owner-occupied units built prior to 1940*. We are going
    to convert this feature to a categorical variable. Once it's been converted, we'll
    be able to replot this figure with each panel segmented by color according to
    the age category.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 看看包含AGE的面板。作为提醒，这个特征定义为*1940年前建成的业主自住单元的比例*。我们将把这个特征转换为一个类别变量。转换后，我们将能够重新绘制这个图，并根据年龄类别使用颜色对每个面板进行分段。
- en: 'Scroll down to Subtopic `Building and exploring categorical features` and click
    into the first cell. Type and execute the following to plot the AGE cumulative
    distribution:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向下滚动至子主题`构建与探索类别特征`，点击进入第一个单元格。输入并执行以下命令以绘制AGE的累积分布：
- en: '[PRE27]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](img/c7a01b08-8166-44f5-9c8b-f3e35f74ee26.png)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c7a01b08-8166-44f5-9c8b-f3e35f74ee26.png)'
- en: 'Note that we set `kde_kws={''lw'': 0}` in order to bypass plotting the kernel
    density estimate in the preceding figure.'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '请注意，我们设置了`kde_kws={''lw'': 0}`以避免在前面的图中绘制核密度估计。'
- en: Looking at the plot, there are very few samples with low AGE, whereas there
    are far more with a very large AGE. This is indicated by the steepness of the
    distribution on the far right-hand side.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中可以看出，低AGE的样本非常少，而AGE较大的样本则更多。这一点可以从分布在右侧的陡峭程度看出。
- en: The red lines indicate 1/3 and 2/3 points in the distribution. Looking at the
    places where our distribution intercepts these horizontal lines, we can see that
    only about 33% of the samples have AGE less than 55 and 33% of the samples have
    AGE greater than 90! In other words, a third of the housing communities have less
    than 55% of homes built prior to 1940\. These would be considered relatively new
    communities. On the other end of the spectrum, another third of the housing communities
    have over 90% of homes built prior to 1940\. These would be considered very old.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 红色线条表示分布中的1/3和2/3点。通过观察分布与这些水平线的交点，我们可以看到大约33%的样本的AGE小于55，另外33%的样本的AGE大于90！换句话说，三分之一的住宅社区有不到55%的房屋是1940年前建造的。这些社区被视为相对较新的社区。而在另一端，另三分之一的住宅社区有超过90%的房屋是1940年前建造的。这些社区被视为非常旧的社区。
- en: 'We''ll use the places where the red horizontal lines intercept the distribution
    as a guide to split the feature into categories: **Relatively New**, R**elatively
    Old**, and **Very Old**.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用红色水平线与分布交点的地方作为指导，将特征划分为：**相对较新**、**相对较旧**和**非常旧**。
- en: 'Setting the segmentation points as 50 and 85, create a new categorical feature
    by running the following code:'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将分割点设置为50和85，通过运行以下代码创建一个新的分类特征：
- en: '[PRE28]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Here, we are using the very handy Pandas method apply, which applies a function
    to a given column or set of columns. The function being applied, in this case
    `get_ age_category`, should take one argument representing a row of data and return
    one value for the new column. In this case, the row of data being passed is just
    a single value, the AGE of the sample.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了非常实用的Pandas方法`apply`，它将一个函数应用到给定的列或列集。此处应用的函数`get_age_category`接受一个表示数据行的参数，并为新列返回一个值。在这种情况下，传递的数据行只是一个单一的值，即样本的`AGE`。
- en: The apply method is great because it can solve a variety of problems and allows
    for easily readable code. Often though, vectorized methods such as `pd.Series.str`
    can accomplish the same thing much faster. Therefore, it's advised to avoid using
    it if possible, especially when working with large datasets. We'll see some examples
    of vectorized methods in the upcoming chapters.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '`apply`方法很棒，因为它可以解决多种问题，并且使代码易于阅读。然而，通常情况下，像`pd.Series.str`这样的矢量化方法可以更快地完成相同的任务。因此，建议尽量避免使用它，特别是在处理大数据集时。我们将在接下来的章节中看到一些矢量化方法的示例。'
- en: Check on how many samples we've grouped into each age category by typing  `df.groupby('AGE_category').size()`
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过键入`df.groupby('AGE_category').size()`检查我们将多少样本分配到了每个年龄类别。
- en: into a new cell and running
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 进入一个新的单元格并运行
- en: '![](img/4f1ec257-1b37-4971-b906-e3830e0efde2.png)'
  id: totrans-356
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4f1ec257-1b37-4971-b906-e3830e0efde2.png)'
- en: Looking at the result, it can be seen that two class sizes are fairly equal,
    and the Very Old group is about 40% larger. We are interested in keeping the classes
    comparable in size, so that each is well-represented and it's straightforward
    to make inferences from the analysis.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 从结果来看，可以看到两个类别的样本量大致相等，**非常旧**组的样本量大约比其他组多40%。我们希望保持类别的大小相当，这样每个类别都能得到充分代表，且从分析中得出结论变得简单。
- en: 'It may not always be possible to assign samples into classes evenly, and in
    real-world situations, it''s very common to find highly imbalanced classes. In
    such cases, it''s important to keep in mind that it will be difficult to make
    statistically significant claims with respect to the under-represented class.
    Predictive analytics with imbalanced classes can be particularly difficult. The
    following blog post offers an excellent summary on methods for handling imbalanced
    classes when doing machine learning: [https://svds.com/learning-imbalanced-classes/](https://svds.com/learning-imbalanced-classes/).'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 可能并不总是能够将样本均匀地分配到各个类别中，在现实世界中，类别不平衡是非常常见的。在这种情况下，需要记住的是，关于代表性较少的类别，做出具有统计学意义的结论是很困难的。对于类别不平衡的数据进行预测分析尤其具有挑战性。以下博客文章提供了一个关于在进行机器学习时处理类别不平衡的优秀总结：[https://svds.com/learning-imbalanced-classes/](https://svds.com/learning-imbalanced-classes/)。
- en: Let's see how the target variable is distributed when segmented by our new feature `AGE_category`.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在新特征`AGE_category`的划分下，目标变量是如何分布的。
- en: 'Make a violin plot by running the following code:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下代码绘制小提琴图：
- en: '[PRE29]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![](img/c6ed1d55-c026-4cb8-b99e-9800c8c75191.png)'
  id: totrans-362
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c6ed1d55-c026-4cb8-b99e-9800c8c75191.png)'
- en: The violin plot shows a kernel density estimate of the median house value distribution
    for each age category. We see that they all resemble a normal distribution. The
    Very Old group contains the lowest median house value samples and has a relatively
    large width, whereas the other groups are more tightly centered around their average.
    The young group is skewed to the high end, which is evident from the enlarged
    right half and position of the white dot in the thick black line within the body
    of the distribution.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 小提琴图展示了每个年龄类别的中位数房价分布的核密度估计。我们可以看到，它们都类似于正态分布。**非常旧**组包含最低的中位数房价样本，并且宽度相对较大，而其他组则更集中在它们的平均值周围。年轻组则偏向高端，这从其右半部分的扩大以及分布中白点在粗黑线位置的变化可以明显看出。
- en: This white dot represents the mean and the thick black line spans roughly 50%
    of the population (it fills to the first quantile on either side of the white
    dot). The thin black line represents boxplot whiskers and spans 95% of the population.
    This inner visualization can be modified to show the individual data points instead
    by passing `inner='point' to sns.violinplot()` . Let's do that now.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 这个白色点表示均值，粗黑线大致覆盖了50%的人群（它填充了白点两侧的第一个四分位数）。细黑线表示箱线图的须，覆盖了95%的人群。通过传递`inner='point'`给`sns.violinplot()`，这个内部可视化可以修改为显示各个数据点。现在让我们来做一下。
- en: 'Redo the violin plot adding the inner=''point'' argument to the sns.violinplot call:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新制作小提琴图，将`inner='point'`参数添加到`sns.violinplot`调用中：
- en: '![](img/79627d7e-5d70-4123-bac1-dbc55c3ed7e1.png)'
  id: totrans-366
  prefs: []
  type: TYPE_IMG
  zh: '![](img/79627d7e-5d70-4123-bac1-dbc55c3ed7e1.png)'
- en: It's good to make plots like this for test purposes in order to see how the
    underlying data connects to the visual. We can see, for example, how there are
    no median house values lower than roughly $16,000 for the Relatively New segment,
    and therefore the distribution tail actually contains no data. Due to the small
    size of our dataset (only about 500 rows), we can see this is the case for each
    segment.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试目的，制作这样的图表是有益的，这样可以查看底层数据如何与可视化连接。例如，我们可以看到，**Relatively New**段的中位数房价大约没有低于16,000美元的，因此分布尾部实际上没有数据。由于我们的数据集很小（大约500行），我们可以看到每个段都是这种情况。
- en: 'Re-do the pairplot from earlier, but now include color labels for each AGE
    category.This is done by simply passing the hue argument, as follows:'
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新制作之前的pairplot，但现在为每个AGE类别添加颜色标签。只需传递`hue`参数，代码如下：
- en: '[PRE30]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '![](img/3387bd48-7536-44ce-b68f-5fbaeb4dd8c4.png)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3387bd48-7536-44ce-b68f-5fbaeb4dd8c4.png)'
- en: Looking at the histograms, the underlying distributions of each segment appear
    similar for **RM** and **TAX**. The **LSTAT** distributions, on the other hand,
    look more distinct. We can focus on them in more detail by again using a violin
    plot.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 从直方图来看，每个段的基础分布在**RM**和**TAX**上看起来类似。而**LSTAT**的分布则显得更为独特。我们可以通过再次使用小提琴图来更加深入地关注它们。
- en: 'Make a violin plot comparing the LSTAT distributions for each `AGE_category` segment:'
  id: totrans-372
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 制作一个小提琴图，比较每个`AGE_category`段的LSTAT分布：
- en: '![](img/284438ae-9698-441c-8476-b4b918a30101.png)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
  zh: '![](img/284438ae-9698-441c-8476-b4b918a30101.png)'
- en: Unlike the **MEDV** violin plot, where each distribution had roughly the same
    width, here we see the width increasing along with **AGE**. Communities with primarily
    old houses (the Very Old segment) contain anywhere from very few to many lower
    class residents, whereas Relatively New communities are much more likely to be
    predominantly higher class, with over 95% of samples having less lower class percentages
    than the Very Old communities. This makes sense, because Relatively New neighborhoods
    would be more expensive.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 与**MEDV**的小提琴图不同，其中每个分布的宽度大致相同，在这里我们看到宽度随着**AGE**的增加而增加。主要是老旧房屋的社区（非常旧的段）包含的下层居民从很少到很多不等，而相对较新的社区则更有可能以较高阶层为主，超过95%的样本中，低阶层的比例低于非常旧的社区。这是合理的，因为相对较新的社区房价会更贵。
- en: Summary
  id: totrans-375
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you have seen the fundamentals of data analysis in Jupyter.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，你已经了解了Jupyter数据分析的基本知识。
- en: We began with usage instructions and features of Jupyter such as magic functions
    and tab completion. Then, transitioning to data-science-specific material, we
    introduced the most important libraries for data science with Python.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从Jupyter的使用说明和一些功能（如魔法函数和自动补全）开始。接着，转向数据科学相关内容，我们介绍了Python数据科学中最重要的库。
- en: In the latter half of the chapter, we ran an exploratory analysis in a live
    Jupyter Notebook. Here, we used visual assists such as scatter plots, histograms,
    and violin plots to deepen our understanding of the data. We also performed simple
    predictive modeling, a topic which will be the focus of the following chapter
    in this book.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章后半部分，我们在一个实时Jupyter Notebook中进行了探索性分析。在这里，我们使用了散点图、直方图和小提琴图等可视化工具来加深对数据的理解。我们还进行了简单的预测建模，这一主题将在本书的下一章中深入探讨。
- en: In the next chapter, we will discuss how to approach predictive analytics, what
    things to consider when preparing the data for modeling, and how to implement
    and compare a variety of models using Jupyter Notebooks.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将讨论如何进行预测分析，准备数据建模时需要考虑的事项，以及如何使用Jupyter Notebooks实现并比较各种模型。
