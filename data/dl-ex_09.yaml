- en: Object Detection – Transfer Learning with CNNs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标检测 – 使用卷积神经网络（CNNs）进行迁移学习
- en: '"How individuals transfer in one context to another context that share similar
    characteristics"'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: “个体如何在一个情境中转移到另一个具有相似特征的情境”
- en: – *E. L. Thorndike*, *R. S. Woodworth (1991)*
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*E. L. Thorndike*，*R. S. Woodworth (1991)*'
- en: '**Transfer learning** (**TL**) is a research problem in data science that is
    mainly concerned with persisting knowledge acquired during solving a specific
    task and using this acquired knowledge to solve another different but similar
    task. In this chapter, we will demonstrate one of the modern practices and common
    themes used in the field of data science with TL. The idea here is how to get
    the help from domains with very large datasets to domains that have less dataset
    size. Finally, we will revisit our object detection example of CIFAR-10 and try
    to reduce both the training time and performance error via TL.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**迁移学习**（**TL**）是数据科学中的一个研究问题，主要关注在解决特定任务时获得的知识如何得以保存，并利用这些获得的知识来解决另一个不同但相似的任务。在本章中，我们将展示数据科学领域中使用迁移学习的现代实践和常见主题之一。这里的思想是如何从数据集非常大的领域获得帮助，转移到数据集较小的领域。最后，我们将重新审视我们在
    CIFAR-10 上的目标检测示例，并尝试通过迁移学习减少训练时间和性能误差。'
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Transfer learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迁移学习
- en: CIFAR-10 object detection revisited
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新审视 CIFAR-10 目标检测
- en: Transfer learning
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习
- en: Deep learning architectures are data greedy and having a few samples in a training
    set will not get us the best out of them. TL solves this problem by transferring
    learned or gained knowledge/representations from solving a task with a large dataset
    to another different but similar one with a smaller dataset.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习架构对数据的需求很大，训练集中的样本较少时无法充分发挥其潜力。迁移学习通过将从大数据集解决一个任务中学到的知识/表示转移到另一个不同但相似的小数据集任务中，解决了这一问题。
- en: TL is not only useful for the case of small training sets, but also we can use
    it to make the training process faster. Training large deep learning architectures
    from scratch can sometimes be very slow because we have millions of weights in
    these architectures that need to be learned. Instead, someone can make use of
    TL by just fine-tuning a learned weight on a similar problem to the one that he/she's
    trying to solve.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习不仅对小训练集有用，我们还可以用它来加速训练过程。从头开始训练大型深度学习架构有时会非常慢，因为这些架构中有数百万个权重需要学习。相反，可以通过迁移学习，只需微调在类似问题上学到的权重，而不是从头开始训练模型。
- en: The intuition behind TL
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习的直觉
- en: Let's build up the intuition behind TL by using the following teacher-student
    analogy. A teacher has many years of experience in the modules that he'she's teaching.
    On the other side, the students get a compact overview of the topic from the lectures
    that this teacher gives. So you can say that the teacher is transferring their
    knowledge in a concise and compact way to the students.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下师生类比来建立迁移学习的直觉。一位教师在他/她教授的模块中有多年的经验。另一方面，学生从这位教师的讲座中获得了该主题的简洁概述。所以你可以说，教师正在以简洁紧凑的方式将自己的知识传授给学生。
- en: The same analogy of the teacher and students can be applied to our case of transferring
    knowledge in deep learning, or in neural networks in general. So our model learns
    some representations from the data, which is represented by the *weights* of the
    network. These learned representations/features (weights) can be transferred to
    another different but similar task. This process of transferring the learned weights
    to another task will reduce the need for huge datasets for deep learning architectures
    to converge, and it will also reduce the time needed to adapt the model to the
    new dataset compared to training the model from scratch.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 教师与学生的类比同样适用于我们在深度学习或神经网络中知识迁移的情况。我们的模型从数据中学习一些表示，这些表示由网络的*权重*表示。这些学习到的表示/特征（权重）可以转移到另一个不同但相似的任务中。将学到的权重转移到另一个任务的过程将减少深度学习架构收敛所需的庞大数据集，并且与从头开始训练模型相比，它还会减少将模型适应新数据集所需的时间。
- en: 'Deep learning is widely used nowadays, but usually most people are using TL
    while training deep learning architectures; few of them train deep learning architectures
    from scratch, because most of the time it''s rare to have a dataset of sufficient
    size for deep learning to converge. So it''s very common to use a pre-trained
    model on a large dataset such as `ImageNet`, which has about 1.2 million images,
    and apply it to your new task. We can use the weights of that pre-trained model
    as a feature extractor, or we can just initialize our architecture with it and
    then fine-tune them to your new task. There are three major scenarios for using
    TL:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习现在广泛应用，但通常大多数人在训练深度学习架构时都会使用迁移学习（TL）；很少有人从零开始训练深度学习架构，因为大多数情况下，深度学习需要的数据集规模通常不足以支持收敛。所以，使用在大型数据集上预训练的模型，如`ImageNet`（大约有120万张图像），并将其应用到新任务上是非常常见的。我们可以使用该预训练模型的权重作为特征提取器，或者我们可以将其作为初始化模型，然后对其进行微调以适应新任务。使用迁移学习有三种主要场景：
- en: '**Use a convolution network as a fixed feature extractor**:In this scenario,
    you use a pre-trained convolution model on a large dataset such as ImageNet and
    adapt it to work on your problem. For instance, a pre-trained convolution model
    on ImageNet will have a fully connected layer with output scores for the 1,000
    categories that ImageNet has. So you need to remove this layer because you are
    not interested anymore in the classes of ImageNet. Then, you treat all other layers
    as a feature extractor. Once you have extracted the features using the pre-trained
    model, you can feed these features to any linear classifier, such as the softmax
    classifier, or even linear SVM.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用卷积网络作为固定特征提取器**：在这种场景下，你使用在大型数据集（如ImageNet）上预训练的卷积模型，并将其调整为适应你的问题。例如，一个在ImageNet上预训练的卷积模型将有一个全连接层，输出ImageNet上1,000个类别的得分。所以你需要移除这个层，因为你不再关心ImageNet的类别。然后，你将所有其他层当作特征提取器。一旦使用预训练模型提取了特征，你可以将这些特征输入到任何线性分类器中，比如softmax分类器，甚至是线性支持向量机（SVM）。'
- en: '**Fine-tune the convolution neural network**: The second scenario involves
    the first one but with an extra effort to fine-tune the pre-trained weights on
    your new task using backpropagation. Usually, people keep most of the layers fixed
    and only fine-tune the top end of the network. Trying to fine-tune the whole network
    or even most of the layers may result in overfitting. So, you might be interested
    in fine-tuning only those layers that are concerned with the semantic-level features
    of the images. The intuition behind leaving the earlier layers fixed is that they
    contain generic or low-level features that are common across most imaging tasks,
    such as corners, edges, and so on. Fine-tuning the higher level or the top end
    layers of the network will be useful if you''re introducing new classes that are
    not present in the original dataset that the model was pre-trained on.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微调卷积神经网络**：第二种场景涉及到第一种场景，但增加了使用反向传播在你的新任务上微调预训练权重的额外工作。通常，人们保持大部分层不变，只微调网络的顶部。尝试微调整个网络或大多数层可能导致过拟合。因此，你可能只对微调与图像的语义级别特征相关的那些层感兴趣。保持早期层固定的直觉是，它们包含了大多数图像任务中常见的通用或低级特征，如角点、边缘等。如果你正在引入模型在原始数据集中没有的新类别，那么微调网络的高层或顶部层会非常有用。'
- en: '![](img/7b634245-e286-449f-8f6a-5b7fee31ffef.png)'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/7b634245-e286-449f-8f6a-5b7fee31ffef.png)'
- en: 'Figure 10.1: Fine-tuning the pre-trained CNN for a new task'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1：为新任务微调预训练的卷积神经网络（CNN）
- en: '**Pre-trained models**: The third widely used scenario is to download checkpoints
    that people have made available on the internet. You may go for this scenario
    if you don''t have big computational power to train the model from scratch, so
    you just initialize the model with the released checkpoints and then do a little
    fine-tuning.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预训练模型**：第三种广泛使用的场景是下载互联网上人们提供的检查点。如果你没有足够的计算能力从零开始训练模型，可以选择这种场景，只需使用发布的检查点初始化模型，然后做一点微调。'
- en: Differences between traditional machine learning and TL
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传统机器学习和迁移学习（TL）的区别
- en: As you've noticed from the previous section, there's a clear difference between
    the traditional way we apply machine learning and machine learning that involves
    TL (as shown in the following diagram*)*. In traditional machine learning, you
    don't transfer any knowledge or representations to any other task, which is not
    the case in TL. Sometimes, people use TL in a wrong way, so we are going to mention
    a few conditions under which you can only use TL to maximize the gains.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如你从前一部分中注意到的，传统机器学习和涉及迁移学习（TL）的机器学习有明显的区别（如以下图示*所示）。在传统机器学习中，你不会将任何知识或表示迁移到其他任务中，而在迁移学习中却不同。有时，人们会错误地使用迁移学习，因此我们将列出一些条件，只有在这些条件下使用迁移学习才能最大化收益。
- en: 'The following are the conditions for applying TL:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是应用迁移学习（TL）的条件：
- en: Unlike traditional machine learning, the source and target task or domains don't
    have to come from the same distribution, but they have to be similar
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与传统的机器学习不同，源任务和目标任务或领域不需要来自相同的分布，但它们必须是相似的。
- en: You can also use TL in case of less training samples or if you don't have the
    necessary computational power
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果训练样本较少或你没有足够的计算能力，你也可以使用迁移学习。
- en: '![](img/ba7e27f6-a962-4f30-8c43-f6798ad21fe0.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ba7e27f6-a962-4f30-8c43-f6798ad21fe0.png)'
- en: 'Figure 10.2: Traditional machine learning versus machine learning with TL'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2：传统机器学习与迁移学习（TL）相结合的机器学习
- en: CIFAR-10 object detection – revisited
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CIFAR-10 目标检测—重新审视
- en: In the previous chapter, we trained a simple **convolution neural network**
    (**CNN**) model on the CIFAR-10 dataset. Here, we are going to demonstrate the
    case of using a pre-trained model as a feature extractor while removing the fully
    connected layer of the pre-trained model, and then we'll feed these extracted
    features or transferred values to a softmax layer.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们在 CIFAR-10 数据集上训练了一个简单的**卷积神经网络**（**CNN**）模型。在这里，我们将展示如何使用预训练模型作为特征提取器，同时移除预训练模型的全连接层，然后将提取的特征或迁移值输入
    Softmax 层。
- en: The pre-trained model in this implementation will be the inception model, which
    will be pre-trained on ImageNet. But bear in mind that this implementation builds
    on the previous two chapters that introduced CNN.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这次实现中的预训练模型将是 Inception 模型，它将在 ImageNet 上进行预训练。但请记住，这个实现是基于前两章介绍的 CNN。
- en: Solution outline
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案概述
- en: Again, we are going to replace the final fully connected layer of the pre-trained
    inception model and then use the rest of the inception model as a feature extractor.
    So, we first feed our raw images in the inception model, which will extract the
    features from them and then output our so-called transfer values.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将再次替换预训练 Inception 模型的最终全连接层，并使用其余部分作为特征提取器。因此，我们首先将原始图像输入 Inception 模型，模型会从中提取特征，然后输出我们所谓的迁移值。
- en: After getting the transfer values of the extracted features from the inception
    model, you might need to save them to your desk because it will take some time
    if you did it on the fly, so it's useful to persist them to your desk to save
    you time. In TensorFlow tutorials, they use the term bottleneck values instead
    of transfer values, but it's just a different name for the exact same thing.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在从 Inception 模型中获取提取特征的迁移值后，你可能需要将它们保存到本地，因为如果你实时处理，这可能需要一些时间，因此将它们持久化到本地可以节省时间。在
    TensorFlow 教程中，他们使用“瓶颈值”这一术语来代替迁移值，但这只是对相同概念的不同命名。
- en: After getting the transfer values or loading them from the desk, we can feed
    them to any linear classifier that's customized to our new task. Here, we will
    feed the extracted transfer values to another neural network and then train for
    the new classes of CIFAR-10.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在获得迁移值或从本地加载它们后，我们可以将它们输入到任何为新任务定制的线性分类器中。在这里，我们将提取的迁移值输入到另一个神经网络，并为 CIFAR-10
    的新类别进行训练。
- en: 'The following diagram, shows the general solution outline that we will be following:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了我们将遵循的一般解决方案概述：
- en: '![](img/389af43d-d01c-4193-b267-df995b4124a1.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/389af43d-d01c-4193-b267-df995b4124a1.png)'
- en: 'Figure 10.3: The solution outline for an object detection task using the CIFAR-10
    dataset with TL'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3：使用 CIFAR-10 数据集进行目标检测任务的解决方案概述（使用迁移学习）
- en: Loading and exploring CIFAR-10
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载和探索 CIFAR-10
- en: 'Let''s start off by importing the required packages for this implementation:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先导入本次实现所需的包：
- en: '[PRE0]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next up, we need to load another helper script that we can use to download
    the processing CIFAR-10 dataset:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要加载另一个辅助脚本，以便下载处理 CIFAR-10 数据集：
- en: '[PRE1]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If you haven''t done this already, you need to set the path for CIFAR-10\.
    This path will be used by the `cifar-10.py` script to persist the dataset:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有做过这一点，你需要设置 CIFAR-10 的路径。这个路径将被 `cifar-10.py` 脚本用来持久化数据集：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let''s see the categories that we have in the CIFAR-10 dataset:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下 CIFAR-10 数据集中的类别：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Output:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This returns `images`, the class-numbers as `integers`, and the class-numbers
    as one-hot encoded arrays called `labels`:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回 `images`，类别编号作为 `integers`，以及类别编号作为一种名为 `labels` 的 one-hot 编码数组：
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Output:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, let''s do the same for the testing set by loading the images and their
    corresponding integer representation of the target classes with their one-hot
    encoding:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们对测试集做相同的操作，加载图像及其相应的目标类别的整数表示和 one-hot 编码：
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let''s have a look at the distribution of the training and testing sets in
    CIFAR-10:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 CIFAR-10 中训练集和测试集的分布：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Output:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let''s define some helper functions that will enable us to explore the dataset.
    The following helper function plots a set of nine images in a grid:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一些辅助函数，以便我们可以探索数据集。以下辅助函数将把九张图片绘制成网格：
- en: '[PRE10]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s go ahead and visualize some images from the test set along with their
    corresponding actual class:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们可视化测试集中的一些图像，并查看它们相应的实际类别：
- en: '[PRE11]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Output:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '![](img/94ffc181-5c5d-4376-b599-6ecef7f9cf86.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/94ffc181-5c5d-4376-b599-6ecef7f9cf86.png)'
- en: 'Figure 10.4: The first nine images of the test set'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4：测试集的前九张图片
- en: Inception model transfer values
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Inception 模型传递值
- en: As we mentioned earlier, we will be using the pre-trained inception model on
    the ImageNet dataset. So, we need to download this pre-trained model from the
    internet.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将使用在 ImageNet 数据集上预训练的 Inception 模型。因此，我们需要从互联网上下载这个预训练的模型。
- en: 'Let''s start off by defining `data_dir` for the inception model:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先定义 `data_dir` 来为 Inception 模型设置路径：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The weights of the pre-trained inception model are about 85 MB. The following
    line of code will download it if it doesn''t exist in the `data_dir` defined previously:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练 Inception 模型的权重大约为 85 MB。如果它不在之前定义的 `data_dir` 中，以下代码行将下载该模型：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We will load the inception model so that we can use it as a feature extractor
    for our CIFAR-10 images:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将加载 Inception 模型，以便可以将其作为特征提取器来处理我们的 CIFAR-10 图像：
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'As we mentioned previously, calculating the transfer values for the CIFAR-10
    dataset will take some time, so we need to cache them for future use. Thankfully,
    there''s a helper function in the `inception` module that can help us do that:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，计算 CIFAR-10 数据集的传递值需要一些时间，因此我们需要将它们缓存以便将来使用。幸运的是，`inception` 模块中有一个辅助函数可以帮助我们做到这一点：
- en: '[PRE15]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next up, we need to set the file paths for the cached training and testing
    files:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要设置缓存的训练和测试文件的文件路径：
- en: '[PRE16]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As mentioned before, we have 50,000 images in the training set of the CIFAR-10
    dataset. So let''s check the shapes of the transfer values of these images. It
    should be 2,048 for each image in this training set:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，CIFAR-10 数据集的训练集中有 50,000 张图像。让我们检查这些图像的传递值的形状。每张图像的传递值应该是 2,048：
- en: '[PRE17]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Output:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE18]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'We need to do the same for the test set:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要对测试集做相同的操作：
- en: '[PRE19]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Output:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE20]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To intuitively understand how the transfer values look, we are going to define
    a helper function to enable us to use the plot the transfer values of a specific
    image from the training or the testing sets:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了直观地理解传递值的样子，我们将定义一个辅助函数，帮助我们绘制训练集或测试集中某张图像的传递值：
- en: '[PRE21]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](img/b7e00c35-26ef-40ae-95aa-8aed2b82d9ea.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b7e00c35-26ef-40ae-95aa-8aed2b82d9ea.png)'
- en: 'Figure 10.5: Input image'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5：输入图像
- en: 'Transfer values for the image using the inception model:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Inception 模型的传递值：
- en: '![](img/77a148f8-97e1-4f21-9498-5968fdbdbfce.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77a148f8-97e1-4f21-9498-5968fdbdbfce.png)'
- en: 'Figure 10.6: Transfer values for the input image in Figure 10.3'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6：图 10.3 中输入图像的传递值
- en: '[PRE22]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '![](img/a7e0afb5-7e8e-4566-bfd8-1e8259915cff.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a7e0afb5-7e8e-4566-bfd8-1e8259915cff.png)'
- en: 'Figure 10.7: Input image'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7：输入图像
- en: 'Transfer values for the image using the inception model:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Inception 模型的传递值：
- en: '![](img/190cc356-b9bd-40b0-b453-b2edde09a99c.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/190cc356-b9bd-40b0-b453-b2edde09a99c.png)'
- en: 'Figure 10.8: Transfer values for the input image in Figure 10.5'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8：图 10.5 中输入图像的传递值
- en: Analysis of transfer values
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 传递值分析
- en: In this section, we will do some analysis of the transferred values that we
    just got for the training images. The purpose of this analysis is to see whether
    these transfer values will be enough for classifying the images that we have in
    CIFAR-10 or not.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将分析刚刚为训练图像获得的传输值。这次分析的目的是看这些传输值是否足以对我们在CIFAR-10中的图像进行分类。
- en: 'We have 2,048 transfer values for each input image. In order to plot these
    transfer values and do further analysis on them, we can use dimensionality reduction
    techniques such as **Principal Component Analysis** (**PCA**) from scikit-learn.
    We''ll reduce the transfer values from 2,048 to 2  to be able to visualize it
    and see if they will be good features for discriminating between different categories
    of CIFAR-10:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 每张输入图像都有2,048个传输值。为了绘制这些传输值并对其进行进一步分析，我们可以使用像scikit-learn中的**主成分分析**（**PCA**）这样的降维技术。我们将传输值从2,048减少到2，以便能够可视化它，并查看它们是否能成为区分CIFAR-10不同类别的好特征：
- en: '[PRE23]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Next up, we need to create a PCA object wherein the number of components is
    only `2`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建一个PCA对象，其中组件数量为`2`：
- en: '[PRE24]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'It takes a lot of time to reduce the transfer values from 2,048 to 2, so we
    are going to subset only 3,000 out of the 5,000 images that we have transfer values
    for:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 将传输值从2,048减少到2需要花费很多时间，因此我们将只选取5,000张图像中的3,000张作为子集：
- en: '[PRE25]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We need to get the class numbers of these images as well:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要获取这些图像的类别编号：
- en: '[PRE26]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We can double-check our subsetting by printing the shape of the transfer values:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过打印传输值的形状来再次检查我们的子集：
- en: '[PRE27]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Output:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE28]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Next up, we use our PCA object to reduce the transfer values from 2,048 to
    just 2:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用我们的PCA对象将传输值从2,048减少到仅2：
- en: '[PRE29]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, let''s see the output of the PCA reduction process:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看PCA降维过程的输出：
- en: '[PRE30]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Output:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE31]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'After reducing the dimensionality of the transfer values to only 2, let''s
    plot these values:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在将传输值的维度减少到仅为2之后，让我们绘制这些值：
- en: '[PRE32]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Here, we are plotting the reduced transfer values of the subset from the training
    set. We have 10 classes in CIFAR-10, so we are going to plot their corresponding
    transfer values with different colors. As you can see from the following graph,
    the transfer values are grouped according to the corresponding class. The overlap
    between groups is because the reduction process of PCA can''t properly separate
    the transfer values:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们绘制的是训练集子集的减少后的传输值。CIFAR-10中有10个类别，所以我们将使用不同的颜色绘制它们对应的传输值。从下图可以看出，传输值根据对应的类别被分组。组与组之间的重叠是因为PCA的降维过程无法正确分离传输值：
- en: '[PRE33]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![](img/665d1102-3dcb-4584-9292-f80f1af46526.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/665d1102-3dcb-4584-9292-f80f1af46526.png)'
- en: 'Figure 10.9: Transfer values reduced using PCA'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9：使用PCA减少的传输值
- en: 'We can do a further analysis on our transfer values using a different dimensionality
    reduction method called **t-SNE**:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用另一种降维方法**t-SNE**进一步分析我们的传输值：
- en: '[PRE34]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Again, we''ll be reduce our dimensionality of the transfer values, which is
    2,048, but this time to 50 values and not 2:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们将减少传输值的维度，从2,048减少到50个值，而不是2：
- en: '[PRE35]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Next up, we stack the second dimensionality reduction technique and feed the
    output of the PCA process to it:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们堆叠第二种降维技术，并将PCA过程的输出传递给它：
- en: '[PRE36]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Finally, we use the reduced values from the PCA method and apply the t-SNE
    method to it:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用PCA方法减少后的值并将t-SNE方法应用于其上：
- en: '[PRE37]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'And double-check if it has the correct shape:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 并再次检查它是否具有正确的形状：
- en: '[PRE38]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Output:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE39]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Let's plot the reduced transfer values by the t-SNE method. As you can see in
    the next image, the t-SNE has been able to do better separation of grouped transfer
    values than the PCA one.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们绘制t-SNE方法减少后的传输值。正如你在下图中看到的，t-SNE比PCA更好地分离了分组的传输值。
- en: 'The takeaway from this analysis is that the extracted transfer values we got
    by feeding our input images to the pre-trained inception model can be used to
    separate training images into the 10 classes. This separation won''t be 100% accurate
    because of the small overlap in the following graph, but we can get rid of this
    overlap by doing some fine-tuning on our pre-trained model:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这次分析，我们得出的结论是，通过将输入图像输入预训练的Inception模型获得的提取传输值，可以用于将训练图像分为10个类别。由于下图中存在轻微的重叠，这种分离不会100%准确，但我们可以通过对预训练模型进行微调来消除这种重叠：
- en: '[PRE40]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![](img/35bdf697-4c8f-4a3d-a228-586343632d6c.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/35bdf697-4c8f-4a3d-a228-586343632d6c.png)'
- en: 'Figure 10.10: Transfer values reduced using t-SNE'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10：使用t-SNE减少的传输值
- en: Now we have transfer values extracted from our training images and we know that
    these values will be able to, to some extent, distinguish between the different
    classes that CIFAR-10 has. Next, we need to build a linear classifier and feed
    these transfer values to it to do the actual classification.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经提取了训练图像中的转移值，并且知道这些值能够在一定程度上区分CIFAR-10中的不同类别。接下来，我们需要构建一个线性分类器，并将这些转移值输入其中，进行实际分类。
- en: Model building and training
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型构建与训练
- en: 'So, let''s start off by specifying the input placeholder variables that will
    be fed to our neural network model. The shape of the first input variable (which
    will contain the extracted transfer values) will be `[None, transfer_len]`. The
    second placeholder variable will hold the actual class labels of the training
    set in a one-hot vector format:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们首先指定将要输入到神经网络模型中的输入占位符变量。第一个输入变量（将包含提取的转移值）的形状将是`[None, transfer_len]`。第二个占位符变量将以独热向量格式存储训练集的实际类别标签：
- en: '[PRE41]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We can also get the corresponding integer value of each class from 1 to 10
    by defining another placeholder variable:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过定义另一个占位符变量，获取每个类别从1到10的对应整数值：
- en: '[PRE42]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Next up, we need to build the actual classification neural network that will
    take these input placeholders and produce the predicted classes:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要构建实际的分类神经网络，该网络将接受这些输入占位符，并生成预测的类别：
- en: '[PRE43]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Then, we need to define an optimization criteria that will be used during the
    training of the classifier. In this implementation, we will use `AdamOptimizer`.
    The output of this classifier will be an array of 10 probability scores, corresponding
    to the number of classes that we have in the CIFAR-10 dataset. Then, we are going
    to apply the `argmax` operation over this array to assign the class of the largest
    score to this input sample:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们需要定义一个优化标准，作为分类器训练过程中使用的准则。在此实现中，我们将使用`AdamOptimizer`。该分类器的输出将是一个包含10个概率分数的数组，对应CIFAR-10数据集中类别的数量。接下来，我们将对这个数组应用`argmax`操作，将最大分数的类别分配给该输入样本：
- en: '[PRE44]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Next up, we need to define a TensorFlow session that will actually execute
    the graph and then initialize the variables that we defined earlier in this implementation:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要定义一个TensorFlow会话，实际执行计算图，并初始化我们之前在此实现中定义的变量：
- en: '[PRE45]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: In this implementation, we will be using **Stochastic Gradient Descent** (**SGD**),
    so we need to define a function to randomly generate batches of a particular size
    from our training set of 50,000 images.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个实现中，我们将使用**随机梯度下降**（**SGD**），因此我们需要定义一个函数，从我们包含50,000张图像的训练集中随机生成指定大小的批次。
- en: 'Thus, we are going to define a helper function for generating a random batch
    from the input training set of the transfer values:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将定义一个辅助函数，从输入的训练集转移值中生成一个随机批次：
- en: '[PRE46]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Next up, we need to define a helper function to do the actual optimization
    process, which will refine the weights of the network. It will generate a batch
    at each iteration and optimize the network based on that batch:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要定义一个辅助函数，进行实际的优化过程，优化网络的权重。它将在每次迭代时生成一个批次，并根据该批次优化网络：
- en: '[PRE47]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We are going to define some helper functions to show the results of the previous
    neural network and show the confusion matrix of the predicted results as well:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将定义一些辅助函数来显示之前神经网络的结果，并展示预测结果的混淆矩阵：
- en: '[PRE48]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Next, we need to define the helper function for plotting the confusion matrix:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要定义一个用于绘制混淆矩阵的辅助函数：
- en: '[PRE49]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Also, we are going to define another helper function to run the trained classifier
    over the test set and measure the accuracy of the trained model over the test
    set:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还将定义另一个辅助函数，用于在测试集上运行训练好的分类器，并测量训练模型在测试集上的准确性：
- en: '[PRE50]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Let''s see the performance of the previous neural network model before doing
    any optimization:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行任何优化之前，让我们看看之前神经网络模型的表现：
- en: '[PRE51]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'As you can see, the performance of the network is very low, but it will get
    better after doing some optimization based on the optimization criteria that we
    already defined. So we are going to run the optimizer for 10,000 iterations and
    test the model accuracy after that:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，网络的表现非常差，但在我们基于已定义的优化标准进行一些优化后，性能会有所提升。因此，我们将运行优化器进行10,000次迭代，并在此之后测试模型的准确性：
- en: '[PRE52]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '![](img/125c29c9-437c-4a01-be7d-f3769cc2940e.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/125c29c9-437c-4a01-be7d-f3769cc2940e.png)'
- en: 'Figure 10.11: Some misclassified images from the test set'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.11：来自测试集的部分误分类图像
- en: '[PRE53]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'To wrap this up, we are going to close the opened sessions:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将结束之前打开的会话：
- en: '[PRE54]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Summary
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we introduced one of the most widely used best practices of
    deep learning. TL is a very exciting tool that you can use to get deep learning
    architectures to learn from your small dataset, but make sure you use it in the
    right way.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了深度学习中最广泛使用的最佳实践之一。TL是一个非常令人兴奋的工具，您可以利用它让深度学习架构从小数据集进行学习，但请确保您以正确的方式使用它。
- en: 'Next up, we are going to introduce a widely used deep learning architecture
    for natural language processing. These recurrent-type architectures have achieved
    a breakthrough in most NLP domains: machine translation, speech recognition, language
    modeling, and sentiment analysis.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍一种广泛应用于自然语言处理的深度学习架构。这些递归型架构在大多数NLP领域取得了突破：机器翻译、语音识别、语言建模和情感分析。
