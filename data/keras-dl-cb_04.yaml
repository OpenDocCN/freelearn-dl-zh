- en: Convolutional Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: Convolutional networks (reference *LeCun[1]*, 2013), also known as **Convolutional** **neural
    networks**
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积网络（参考 *LeCun[1]*，2013），也被称为**卷积**神经网络
- en: or **CNNs**, are a particular type of neural network that process data with
    a grid-like topology. Examples include time-series data, which can be thought
    of as a 1D grid taking samples at regular time intervals, or image data that is
    a 2D grid of pixels. The name convolutional neural network means that the network
    employs a mathematical operation called **convolution**. Convolution is a specific
    kind of linear operation. Convolutional networks are neural networks that use
    convolution (a mathematical operation) in place of general matrix multiplication
    in at least one of their layers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 或**CNNs**，是一种特定类型的神经网络，它使用网格状拓扑处理数据。举例来说，时间序列数据可以看作是一个1D网格，按规律时间间隔采样，或者图像数据是一个二维像素网格。卷积神经网络的名字意味着该网络采用了一种叫做**卷积**的数学运算。卷积是一种特定的线性运算。卷积网络是使用卷积（一个数学运算）代替至少一层中的常规矩阵乘法的神经网络。
- en: First, we will describe the mathematical operation of convolution. Then we will
    discuss the concept of pooling and how it helps CNN. We will also look at convolution
    networks implementation in TensorFlow.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将描述卷积的数学运算。然后我们将讨论池化的概念以及它如何帮助CNN。我们还将探讨在TensorFlow中实现卷积网络。
- en: Toward the end of this chapter, we will use TensorFlow's CNN implementation
    to classify dogs and cats from the Stanford dataset.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的末尾，我们将使用TensorFlow的CNN实现来对斯坦福数据集中的狗和猫进行分类。
- en: Lecun[1] : [http://yann.lecun.com/exdb/lenet/](http://yann.lecun.com/exdb/lenet/)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Lecun[1] : [http://yann.lecun.com/exdb/lenet/](http://yann.lecun.com/exdb/lenet/)
- en: 'We will be covering the following topics in this chapter:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: An overview and the intuition of CNN
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNN概述与直觉
- en: Convolution operations
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积运算
- en: Pooling
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 池化
- en: Image classification with convolutional networks
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用卷积网络进行图像分类
- en: An overview and the intuition of CNN
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CNN概述与直觉
- en: CNN consists of multiple layers of convolutions, polling and finally fully connected
    layers. This is much more efficient than pure feedforward networks we discussed
    in [Chapter 2](99346436-65d0-4059-81eb-e29091747df3.xhtml), *Deep Feedforward
    Networks*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: CNN由多个卷积层、池化层和最终的全连接层组成。这比我们在[第2章](99346436-65d0-4059-81eb-e29091747df3.xhtml)中讨论的纯前馈网络更高效，*深度前馈网络*。
- en: '![](img/df7b7f21-ff98-4900-9eed-778fde9122d9.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/df7b7f21-ff98-4900-9eed-778fde9122d9.png)'
- en: The preceding diagram takes images through **Convolution Layer** | **Max Pooling**
    | **Convolution** | **Max Pooling** | **Fully Connected Layers** this is an CNN
    architecture
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图示通过**卷积层** | **最大池化** | **卷积** | **最大池化** | **全连接层**进行，这就是一个CNN架构
- en: Single Conv Layer Computation
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单一卷积层计算
- en: Let's first discuss what the conv layer computes intuitively. The Conv layer's
    parameters consist of a set of learnable filters (also called **tensors**). Each
    filter is small spatially (depth, width, and height), but extends through the
    full depth of the input volume (image). A filter on the first layer of a ConvNet
    typically has a size of 5 x 5 x 3 (that is, five pixels width and height, and
    three for depth, because images have three depths for color channels). During
    the forward pass, filters slide (or **convolve**) across the width and height
    of the input volume and compute the dot product between the entries of the filter
    and the input at any point. As the filter slides over the width and height of
    the input volume, it produces a 2D activation that gives the responses of that
    filter at every spatial position. The network will learn filters that activate
    when they see some kind of visual feature, such as an edge of some orientation
    or a blotch of some color on the first layer, or it might detect an entire honeycomb
    or wheel-like patterns on higher layers of the network. Once we have an entire
    set of filters in each conv layer (for example, 12 filters), each of them produces
    a separate 2D activation map. We stack these activation maps along the depth dimension
    and produce the output volume.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们直观地讨论卷积层的计算方式。卷积层的参数包括一组可学习的滤波器（也称为**张量**）。每个滤波器在空间上很小（深度、宽度和高度），但它会延伸到输入体积（图像）的完整深度。卷积神经网络的第一层滤波器通常大小为5
    x 5 x 3（即宽度和高度为五个像素，深度为三个，因为图像有三个颜色通道的深度）。在前向传播过程中，滤波器会在输入体积的宽度和高度上滑动（或**卷积**），并在任何点上计算滤波器与输入的点积。当滤波器在输入体积的宽度和高度上滑动时，它会产生一个二维激活图，显示该滤波器在每个空间位置的响应。网络将学习到，当它们看到某种视觉特征时，滤波器会激活，例如在第一层看到某种方向的边缘或某种颜色的斑点，或者在网络的更高层检测到整个蜂窝状或轮状的模式。一旦我们在每个卷积层中拥有一整套滤波器（例如，12个滤波器），每个滤波器都会产生一个独立的二维激活图。我们将这些激活图沿深度维度堆叠在一起，生成输出体积。
- en: '![](img/ee47f9f9-11ab-48ab-beb6-551faa50bb8d.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee47f9f9-11ab-48ab-beb6-551faa50bb8d.jpg)'
- en: Image of 32 x 32 pixels convolved by 5 x 5 filter
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 32 x 32像素的图像被5 x 5滤波器卷积处理
- en: The preceding image shows a 32 x 32 x 3 image on which a filter of 5 x 5 x 3
    is applied.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图像展示了一个32 x 32 x 3的图像，在其上应用了一个5 x 5 x 3的滤波器。
- en: '![](img/2d72b474-77a0-422b-82a5-4fb0c91002c1.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2d72b474-77a0-422b-82a5-4fb0c91002c1.jpg)'
- en: Each dot product between filter and image chunk results in a single number
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 每个滤波器与图像块之间的点积结果生成一个单一的数值
- en: Next, let's convolve the filter created above the whole image, moving it one
    pixel at a time. The final output will be sized 28 x 28 x 1\. This is called an
    **activation map**.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们对上面创建的滤波器进行卷积处理，遍历整个图像，每次移动一个像素。最终的输出将是28 x 28 x 1。这被称为**激活图**。
- en: '![](img/3bac5eb6-fd65-4de5-85f9-7c8b79337c3b.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3bac5eb6-fd65-4de5-85f9-7c8b79337c3b.jpg)'
- en: Activation map generated by applying a filter on a image
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对图像应用滤波器生成的激活图
- en: Consider using two filters one after the other; this will result in two activation
    maps of size 28 x 28 x 1.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑将两个滤波器依次使用，这将产生两个大小为28 x 28 x 1的激活图。
- en: '![](img/9eb97f4c-5cb4-46c7-9260-87f46e754008.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9eb97f4c-5cb4-46c7-9260-87f46e754008.jpg)'
- en: Applying two filters on a single image results in two activation maps
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对单个图像应用两个滤波器会生成两个激活图
- en: If we use six such filters, we will end up with a new image sized 28 x 28 x
    3\. A ConvNet is a sequence of such convolution layers interspersed with activation
    functions such as **Relu**.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用六个这样的滤波器，最终得到的图像大小将是28 x 28 x 3。卷积神经网络（ConvNet）是由这样的卷积层组成，并交替使用激活函数，如**Relu**。
- en: '![](img/1629fe0d-d370-4f34-bb9d-3bce9ec47bfe.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1629fe0d-d370-4f34-bb9d-3bce9ec47bfe.jpg)'
- en: Result of applying six filters of 5 x 5 x 3 on image results in activation map
    of 28 x 28 x 6
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 将六个5 x 5 x 3的滤波器应用到图像上，结果生成28 x 28 x 6的激活图
- en: Let us formally defined CNN according to TensorFlow parlance.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按照TensorFlow的术语正式定义卷积神经网络（CNN）。
- en: '**Definition**: A CNN is a neural network that has at least one layer (`tf.nn.conv2d`)
    that makes a convolution between its input and a configurable kernel generating
    the layer''s output. A convolution applies a kernel (filter) to every point in
    the input layer (a tensor). It generates a filtered output by sliding the kernel
    over an input tensor.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**定义**：卷积神经网络（CNN）是一种至少包含一层（`tf.nn.conv2d`）的神经网络，该层对输入和可配置的卷积核进行卷积运算，生成该层的输出。卷积通过将卷积核（滤波器）应用于输入层（张量）中的每一个点来进行。它通过滑动卷积核在输入张量上生成一个过滤后的输出。'
- en: '**Use Case**: Following example is an edge detection filter applied on an input
    image using  a Convolution'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用案例**：以下示例是一个边缘检测滤波器，应用于输入图像，使用卷积'
- en: '![](img/49356c6c-9b70-48f9-9701-5a61b24f70b9.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/49356c6c-9b70-48f9-9701-5a61b24f70b9.jpg)'
- en: Edge detection by applying kernel on an input image
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在输入图像上应用卷积核进行边缘检测
- en: CNNs follow a process that matches information similar to the structure found
    in the cellular layout of a cat's striate cortex. As signals are passed through
    a cat's striate cortex, certain layers signal when a visual pattern is highlighted.
    For example, one layer of cells activates (increases its output signal) when a
    horizontal line passes through it. A CNN will exhibit a similar behavior where
    clusters of neurons activate based on patterns learned from training. After training
    based on prelabeled data, a CNN will have certain layers that activate when a
    horizontal/vertical line passes through it.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 遵循一个过程，匹配的信息结构类似于猫的条纹皮层中的细胞布局结构。当信号通过猫的条纹皮层时，某些层会在视觉模式被突出时发出信号。例如，当水平线穿过某一层时，该层的细胞会激活（增加其输出信号）。CNN
    会表现出类似的行为，其中神经元簇会根据训练中学习到的模式进行激活。基于预标记数据进行训练后，CNN 会有某些层在水平/垂直线通过时激活。
- en: Matching horizontal/vertical lines would be a useful neural network architecture,
    but CNNs layer multiple simple patterns to match complex patterns. These patterns
    are called **filters** or **kernels**. The goal of training is to adjust these
    kernel weights to minimize the loss function. Training these filters is accomplished
    by combining multiple layers and learning weights using gradient descent or other
    optimization techniques.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配水平/垂直线将是一个有用的神经网络架构，但 CNN 通过将多个简单模式层叠来匹配复杂模式。这些模式被称为**滤波器**或**卷积核**。训练的目标是调整这些卷积核权重，以最小化损失函数。训练这些滤波器是通过结合多个层并使用梯度下降或其他优化技术来学习权重。
- en: CNN in TensorFlow
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 中的 CNN
- en: 'A CNN is composed of convolution layers (defined by `tf.nn.conv2d`), a non-linearity
    layer (`tf.nn.relu`), a max pool (`tf.nn.max_pool`), and fully connected layers
    (`tf.matmul`). The following image shows typical CNN layers and their corresponding
    implementations in TensorFlow:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: CNN 由卷积层（通过 `tf.nn.conv2d` 定义）、非线性层（`tf.nn.relu`）、最大池化层（`tf.nn.max_pool`）和全连接层（`tf.matmul`）组成。以下图像显示了典型的
    CNN 层及其在 TensorFlow 中的对应实现：
- en: '![](img/d7949c19-8b34-4a86-b6e7-5aa9746d84a4.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d7949c19-8b34-4a86-b6e7-5aa9746d84a4.jpg)'
- en: Mapping CNN layers to TensorFlow functions
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 将 CNN 层映射到 TensorFlow 函数
- en: Image loading in TensorFlow
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 中的图像加载
- en: 'Now let''s look at how TensorFlow loads images. Let''s define a constant with
    a small array of three images and load them into a session:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下 TensorFlow 如何加载图像。我们定义一个包含三个小图像的常量数组，并将它们加载到会话中：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output of the preceding listing shows the shape of the tensor and the first
    pixel of the first image. In this example code, an array of images is created
    that includes three images. Each image has a height of two pixels and a width
    of three pixels with an RGB color space. The output from the example code shows
    the number of images as the size of the first set of dimensions, Dimension(1).
    The height of each image is the size of the second set, Dimension(2), the width
    of each image comprises the third set, Dimension(3), and the array size of the
    color channel is the final set, Dimension(3):'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出显示了张量的形状以及第一张图像的第一个像素。在这个示例代码中，创建了一个包含三张图像的图像数组。每张图像的高度为两像素，宽度为三像素，并采用
    RGB 色彩空间。示例代码的输出显示图像的数量作为第一个维度的大小，Dimension(1)。每张图像的高度是第二个维度的大小，Dimension(2)，每张图像的宽度是第三个维度，Dimension(3)，而颜色通道的数组大小是最后一个维度，Dimension(3)：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Convolution operations
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积操作
- en: Convolution operations are key components of a CNN; these operations use an
    input tensor and a filter to compute the output. The key is deciding the parameters
    available to tune them.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积操作是卷积神经网络（CNN）的关键组成部分；这些操作使用输入张量和滤波器来计算输出。关键在于决定可用的参数来调整它们。
- en: Suppose we are tracking the location of an object. Its output is a single *x(t)*,
    which is the position of the object at time *t*. Both *x* and *t* are real-valued,
    that is, we can get a different reading at any instant in time. Suppose that our
    measurement is noisy. To obtain a less noisy estimate of the object's position,
    we would like to average together measurements. More recent measurements are more
    relevant for us; we want this to be a weighted average giving higher weight to
    recent measurements. We can compute this using a weighting function *w(a)*, where
    *a* is the age of a measurement (when the measurement was taken)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们在追踪一个物体的位置。它的输出是一个单一的 *x(t)*，表示物体在时间 *t* 的位置。*x* 和 *t* 都是实数值，也就是说，我们可以在任何时刻获得不同的读数。假设我们的测量有噪声。为了获得一个较少噪声的物体位置估计，我们希望将多个测量值进行平均。最近的测量对我们来说更为相关；我们希望这成为一个加权平均，赋予最近的测量更高的权重。我们可以使用加权函数
    *w(a)* 来计算，其中 *a* 是测量的时间（测量发生的时刻）。
- en: 'If we apply a weighted average operation at every moment, we obtain a new function
    providing a smoothed estimate of the position of the object:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在每个时刻应用加权平均操作，我们将得到一个新的函数，提供物体位置的平滑估计：
- en: '![](img/136f8c61-0fbb-4ab6-ad49-73cef018deee.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/136f8c61-0fbb-4ab6-ad49-73cef018deee.png)'
- en: 'This operation is called **convolution**. A convolution operation is denoted
    with an asterisk:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这个操作称为**卷积**。卷积操作用星号表示：
- en: '![](img/b4e11c31-065e-44d8-869c-7b8993d9072c.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b4e11c31-065e-44d8-869c-7b8993d9072c.png)'
- en: Here,
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，
- en: '*w* is the kernel'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w* 是卷积核'
- en: '*x* is the input'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x* 是输入'
- en: '*s* is the output, also called a **feature map**'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*s* 是输出，也称为**特征图**'
- en: Convolution on an image
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像上的卷积
- en: 'If we use a 2D image *I* as our input, we probably also want to use a 2D kernel
    *K*. The preceding equation will look as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用一个二维图像 *I* 作为输入，我们可能还想使用一个二维卷积核 *K*。前面的方程将如下所示：
- en: '![](img/2c8fcc55-c730-4e45-9931-07a02f67d6d7.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2c8fcc55-c730-4e45-9931-07a02f67d6d7.png)'
- en: 'As the convolution function is commutative, we can write the preceding equation
    as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 由于卷积函数是可交换的，我们可以将前面的方程写成如下形式：
- en: '![](img/5f2da051-543d-4049-81b0-4b8a86ce60a0.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5f2da051-543d-4049-81b0-4b8a86ce60a0.png)'
- en: 'Changing *i - m* and *j -n* to additions is referred to as cross-correlation,
    as that is what is implemented by TensorFlow:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 将 *i - m* 和 *j - n* 改为加法被称为互相关，因为这正是 TensorFlow 实现的：
- en: '![](img/a918398f-37c2-4aa0-bdef-076bd0417146.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a918398f-37c2-4aa0-bdef-076bd0417146.png)'
- en: 'Let''s define a simple input and a kernel and run the `conv2d` operation in
    TensorFlow. Let''s take a look at a simple image input and a kernel input. The
    following diagram shows a basic image, a kernel, and the expected output by applying
    the convolution operation:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个简单的输入和卷积核，并在 TensorFlow 中运行 `conv2d` 操作。我们来看一下简单的图像输入和卷积核输入。下图展示了一个基本的图像、卷积核和应用卷积操作后的期望输出：
- en: '![](img/5c93289c-7713-40b6-8a5f-2bd2d8ac2efb.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5c93289c-7713-40b6-8a5f-2bd2d8ac2efb.jpg)'
- en: Example of basic image and kernel applied to it
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 基本图像及应用于其上的卷积核示例
- en: 'Now let''s look at how the output is achieved with a stride of 1, 1, 1, 1:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一下当步幅为 1, 1, 1, 1 时如何得到输出：
- en: '![](img/be47e774-a84e-4442-9085-9f259093ba78.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/be47e774-a84e-4442-9085-9f259093ba78.jpg)'
- en: Calculating output by applying kernel to the input
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将卷积核应用于输入来计算输出
- en: 'Next, we will implement the same in TensorFlow:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在 TensorFlow 中实现相同的操作：
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output of the preceding listing is as follows--this is the same as the
    one we calculated manually:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码段的输出如下——这与我们手动计算的结果相同：
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Strides
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 步幅
- en: The primary purpose of convolutions is to reduce the dimensions of an image
    (width, height, and number of channels). The larger the image, the more processing
    time is required.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积的主要目的是减少图像的维度（宽度、高度和通道数）。图像越大，所需的处理时间就越长。
- en: The `strides` parameter causes a kernel to skip over pixels in an image and
    not include them in the output. The `strides` parameter determines how a convolution
    operation works with a kernel when a larger image and more complex kernel are
    used. As a convolution is sliding the kernel over the input, it is using the `strides`
    parameter to determine how it walks over the input, instead of going over every
    element of an input.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`strides` 参数使卷积核在图像中跳过一些像素，并且不将这些像素包含在输出中。`strides` 参数决定了当使用更大的图像和更复杂的卷积核时，卷积操作如何与卷积核一起工作。由于卷积是将卷积核滑动输入，因此它使用
    `strides` 参数来确定它如何遍历输入，而不是遍历输入的每一个元素。'
- en: 'Let''s take a look at the following example, where we are moving a 3 x 3 x
    1 kernel over a 6 x 6 x 1 image with a stride of 1, 3, 3, 1:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下下面的示例，我们将一个 3 x 3 x 1 的卷积核以步幅 1, 3, 3, 1 移动到一个 6 x 6 x 1 的图像上：
- en: '![](img/88babb37-5210-499f-8ed8-267661d6b995.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/88babb37-5210-499f-8ed8-267661d6b995.png)'
- en: Step 1 as kernel slides with stride of 1,3,3,1
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步，卷积核以步幅 1,3,3,1 滑动
- en: 'The kernel strides over the following elements in steps 3 and 4:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积核在步骤 3 和 4 中跨越以下元素：
- en: '![](img/d37b361e-768b-4670-a7c8-a5dc10beef9e.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d37b361e-768b-4670-a7c8-a5dc10beef9e.png)'
- en: Step 3 and 4 of kernel stride over input
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积核在输入上滑动的步骤 3 和 4
- en: 'Let''s implement this in TensorFlow; the output will be a 4 x 4 x 1 tensor:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 TensorFlow 中实现这个，输出将是一个 4 x 4 x 1 的张量：
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The output is similar to the following listing, in which 1, 3, 3, 1 stride
    leaders to four red boxes in the preceding image are being multiplied with the
    kernel:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 输出类似于下面的列表，其中 1、3、3、1 的步幅在前面的图像中形成了四个红色框，并与卷积核相乘：
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Pooling
  id: totrans-88
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 池化
- en: Pooling layers help with overfitting and improve performance by reducing the
    size of the input tensor. Typically, they are used to scale down the input, keeping
    important information. Pooling is a much faster mechanism for input size reduction
    compared with `tf.nn.conv2d`.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层通过减少输入张量的大小来帮助防止过拟合并提高性能。通常，它们用于缩小输入，保留重要信息。与 `tf.nn.conv2d` 相比，池化是一种更快速的输入大小缩减机制。
- en: 'The following pooling mechanisms are supported by TensorFlow:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 支持以下池化机制：
- en: Average
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均值
- en: Max
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大池化
- en: Max with argmax
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大值与索引
- en: Each pooling operation uses rectangular windows of size `ksize` separated by
    offset `strides`. If `strides` are all ones (1, 1, 1, 1), every window is used;
    if `strides` are all twos (1, 2, 2, 1), every other window is used in each dimension;
    and so on.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 每个池化操作使用大小为 `ksize` 的矩形窗口，窗口之间的间隔由 `strides` 决定。如果 `strides` 全部为 1（1, 1, 1,
    1），则每个窗口都会被使用；如果 `strides` 全部为 2（1, 2, 2, 1），则每个维度中会跳过一个窗口，以此类推。
- en: Max pool
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最大池化
- en: 'The following defined function provides max pooling for the input 4D tensor
    `tf.nn.max_pool`:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 以下定义的函数提供了对输入 4D 张量的最大池化 `tf.nn.max_pool`：
- en: '[PRE6]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The preceding arguments are explained here:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 上述参数的解释如下：
- en: '`value`: This is the 4D tensor with shape [batch, height, width, channels],
    type `tf.float32` on which max pooling needs to be done.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value`：这是一个形状为 [batch, height, width, channels] 的 4D 张量，类型为 `tf.float32`，需要进行最大池化操作。'
- en: '`ksize`: This is the list of ints that has `length >= 4`. The size of the window
    for each dimension of the input tensor.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ksize`：这是一个整数列表，`length >= 4`。输入张量每个维度的窗口大小。'
- en: '`strides`: This is the list of ints, `length >= 4`. A stride of the sliding
    window for each dimension of the input tensor.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strides`：这是一个整数列表，`length >= 4`。每个维度的滑动窗口步幅。'
- en: '`padding`: This is a string, either `VALID` or `SAME`. The padding algorithm.
    The following section explains `VALID` and `SAME` padding.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`padding`：这是一个字符串，可以是 `VALID` 或 `SAME`。填充算法。以下部分解释了 `VALID` 和 `SAME` 填充。'
- en: '![](img/12b26b0d-fafe-45c2-92ff-4701475b58a5.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/12b26b0d-fafe-45c2-92ff-4701475b58a5.png)'
- en: 'Reference: [https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t](https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 参考：[https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t](https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t)
- en: '`data_format`: This is a string. `NHWC` and `NCHW` are supported.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data_format`：这是一个字符串，支持 `NHWC` 和 `NCHW` 格式。'
- en: '`name`: This is the optional name for the operation.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：这是操作的可选名称。'
- en: Example code
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 示例代码
- en: 'The following code demonstrates max pooling on a tensor using a `VALID` padding
    scheme:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码演示了使用 `VALID` 填充模式对张量进行最大池化：
- en: '[PRE7]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output of the preceding listing will give the maximum values in the window
    3 x 3 x 1:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出将在 3 x 3 x 1 的窗口中给出最大值：
- en: '[PRE8]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following diagram explains how max pool logic works:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了最大池化的逻辑：
- en: '![](img/f500a11c-b10d-4cd6-b4bf-38f16e45446f.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f500a11c-b10d-4cd6-b4bf-38f16e45446f.png)'
- en: As can be seen, max pool selected the maximum value from the window based on
    a stride of 1, 1, 1.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，最大池化根据步幅为 1, 1, 1 的窗口选择了最大值。
- en: Average pool
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平均池化
- en: 'It performs the average pooling on the input tensor. Each entry in the output
    is the mean of the corresponding size `ksize` window in value. It is defined using
    the `tf.nn.avg_pool` method:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 它对输入张量执行平均池化。输出中的每个条目是相应大小的 `ksize` 窗口中的值的平均值。它通过 `tf.nn.avg_pool` 方法定义：
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let''s look at the code example where `avg_pool` is used in a simple 2D tensor:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来看看使用`avg_pool`的简单2D张量的代码示例：
- en: '[PRE10]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The output of the preceding listing is the average of all the values in the
    tensor.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的输出是张量中所有值的平均值。
- en: '*Average = (1.0 + 0.2 + 2.0 + 0.1 + 1.2 + 1.4 + 1.1 + 0.4 + 0\. 4) / 9 = 0.86666*'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '*平均值 = (1.0 + 0.2 + 2.0 + 0.1 + 1.2 + 1.4 + 1.1 + 0.4 + 0.4) / 9 = 0.86666*'
- en: '[PRE11]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Image classification with convolutional networks
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用卷积网络进行图像分类
- en: Let's look at a more realistic case for using CNNs; we will use the Stanford
    Dogs versus Cats dataset. This dataset has 100+ images of dogs and cats.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个更实际的CNN使用案例；我们将使用斯坦福狗与猫数据集。该数据集包含100多张狗和猫的图片。
- en: 'You can download this dataset (100 images each) from the following location:
    [https://s3.amazonaws.com/neural-networking-book/ch04/dogs_vs_cats.tar.gz](https://s3.amazonaws.com/neural-networking-book/ch04/dogs_vs_cats.tar.gz)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从以下位置下载该数据集（每类100张图片）：[https://s3.amazonaws.com/neural-networking-book/ch04/dogs_vs_cats.tar.gz](https://s3.amazonaws.com/neural-networking-book/ch04/dogs_vs_cats.tar.gz)
- en: 'Import the relevant functions and Python classes:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入相关的函数和Python类：
- en: '[PRE12]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We will define the parameters for the convolution layers. There are three convolution
    layers with the following parameters:'
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将定义卷积层的参数。共有三个卷积层，参数如下：
- en: '| **Layer number** | **Layer type** | **Number of filters/neurons** |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| **层编号** | **层类型** | **滤波器/神经元数量** |'
- en: '| 1 | Convolution | 32 filters |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 卷积 | 32 个滤波器 |'
- en: '| 2 | Convolution | 32 filters |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 卷积 | 32 个滤波器 |'
- en: '| 3 | Convolution | 64 filters |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 卷积 | 64 个滤波器 |'
- en: '| 4 | Fully connected | 128 neurons |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 全连接层 | 128 个神经元 |'
- en: 'The Network topolgy can be represented as shown in the following diagram:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 网络拓扑可以通过以下图示表示：
- en: '![](img/04579c56-ba76-4fc4-9c9d-c1282aa91ac6.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](img/04579c56-ba76-4fc4-9c9d-c1282aa91ac6.png)'
- en: 'The following code should be helpful for understanding the parameters:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码有助于理解参数：
- en: '[PRE13]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Define the constant for the number of classes (two, in this case) and other
    variables. We have taken the Stanford dataset and reduced it to 100 images each
    of dogs and cats for easier processing:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义类别数量（此处为两个类别）和其他变量。我们使用了斯坦福数据集，并将其缩减为每类100张狗和猫的图片，以便于处理：
- en: '[PRE14]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s first read the dataset into a tensor. The logic for the reading is defined
    in the `dataset` class:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们将数据集读入张量。读取逻辑在`dataset`类中定义：
- en: '[PRE15]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Here, `train_path`, `image_size`, `classes`, and `validation_size` are defined.
    Let''s look at the implementation of `read_train_sets(..)`:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，定义了`train_path`、`image_size`、`classes`和`validation_size`。让我们看看`read_train_sets(..)`的实现：
- en: '[PRE16]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This method, in turn, calls `load_train(...)` to return a `numpy.array` of
    the data types:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法进一步调用`load_train(...)`，返回一个数据类型为`numpy.array`的数据：
- en: '[PRE17]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The data loaded into training is a function of `validation_set`; it is calculated
    from the images array''s first dimension:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 加载到训练中的数据是`validation_set`的一个函数；它是根据图像数组的第一维计算得到的：
- en: '![](img/19940b2c-a831-4b0e-a3e1-515a1fb652d6.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/19940b2c-a831-4b0e-a3e1-515a1fb652d6.png)'
- en: 'We calculate `validation_size as` shown in the following code:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算`validation_size`，如下代码所示：
- en: '[PRE18]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'As we have kept validation size as `0.2`, it comes out to `58.2` rounded off
    to `58`:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将验证集大小设置为`0.2`，计算结果为`58.2`，四舍五入为`58`：
- en: '![](img/4686ba14-d906-429d-a911-2c5841fedc0d.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4686ba14-d906-429d-a911-2c5841fedc0d.png)'
- en: 'Similarly, we create the test dataset, `test_images` and `test_ids`:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们创建测试数据集，`test_images`和`test_ids`：
- en: '[PRE19]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here, `read_test_set(...)` is a function called internally:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`read_test_set(...)`是一个内部调用的函数：
- en: '[PRE20]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '`read_test_set(test_path, image_size)` in turn calls `load_test(test_path,
    image_size)`, for which the listing is given as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_test_set(test_path, image_size)`又会调用`load_test(test_path, image_size)`，其代码如下：'
- en: '[PRE21]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Let''s look at the sizes of the various `numpy` arrays created:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们来看看创建的各种`numpy`数组的尺寸：
- en: '[PRE22]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Plot nine random images in a grid of 3 x 3 with the appropriate classes:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在3 x 3网格中绘制九张随机图片，并标注相应的类别：
- en: '[PRE24]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Here, the `plot_images` function is defined in the following code block:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`plot_images`函数在以下代码块中定义：
- en: '[PRE25]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The following is the output of our code:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们代码的输出：
- en: '![](img/0baca6e1-e7d0-4d90-8a99-54c0f13843d1.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0baca6e1-e7d0-4d90-8a99-54c0f13843d1.png)'
- en: Nine random images from the dataset
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的九张随机图片
- en: Defining a tensor for input images and the first convolution layer
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义输入图像的张量和第一个卷积层
- en: Next, we will define a tensor for input images and the first convolution layer.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将为输入图像和第一个卷积层定义张量。
- en: Input tensor
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 输入张量
- en: 'Create a placeholder with `shape[None, img_size_flat]` and reshape it into
    `[-1, img_size, img_size, num_channels]`:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个占位符，形状为`shape[None, img_size_flat]`，并将其重塑为`[-1, img_size, img_size, num_channels]`：
- en: '[PRE26]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Here, the parameters `img_size` and `num_channels` have the following values:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，参数`img_size`和`num_channels`的值如下：
- en: '`img_size` = 128'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`img_size` = 128'
- en: '`num_channels` = 3'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_channels` = 3'
- en: First convolution layer
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一个卷积层
- en: 'After reshaping the input tensor into `x_image`, we will create the first convolution
    layer:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在将输入张量重塑为`x_image`后，我们将创建第一个卷积层：
- en: '[PRE27]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The `new_conv_layer(...)` function is defined here. Let''s look at the value
    of each variable being sent to this function:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`new_conv_layer(...)`函数在这里定义。让我们来看一下传递给该函数的每个变量的值：'
- en: '![](img/b8b1af64-88cf-40e5-aba0-c1b7f4704291.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b8b1af64-88cf-40e5-aba0-c1b7f4704291.png)'
- en: '[PRE28]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The variables have the following values at runtime:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时，变量的值如下：
- en: '![](img/94fc1581-7e56-4eea-8f6a-462173e18a4c.png)![](img/b86f9480-4130-4e9b-a42c-56e921259837.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![](img/94fc1581-7e56-4eea-8f6a-462173e18a4c.png)![](img/b86f9480-4130-4e9b-a42c-56e921259837.png)'
- en: 'If we run this, the output of the `print(..)` statement will be as follows:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行此代码，`print(..)`语句的输出将如下所示：
- en: '[PRE29]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The output shows the shape of the output tensor coming out of input layer 1.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示了从输入层1传出的输出张量的形状。
- en: Second convolution layer
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二个卷积层
- en: 'In the second convolution layer, we start with the first layer''s output as
    input and build a new layer with the following parameters:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个卷积层中，我们将第一个层的输出作为输入，并使用以下参数构建一个新层：
- en: '![](img/fe16178f-69ae-4b98-a2cd-c6db7d000c1f.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fe16178f-69ae-4b98-a2cd-c6db7d000c1f.png)'
- en: 'First, we define a placeholder for real `y` and the class of real `y` (the
    label of the class):'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们为真实的`y`和真实的`y`的类别（类别标签）定义一个占位符：
- en: '[PRE30]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The shape of these two variables is the following:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个变量的形状如下：
- en: '![](img/21d8c384-836d-44e2-84ea-c905f32cf6a3.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/21d8c384-836d-44e2-84ea-c905f32cf6a3.png)'
- en: '[PRE31]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'where following are the values:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，以下是各个值：
- en: '`num_input_channels` = 3'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_input_channels` = 3'
- en: '`filter_size` = 3'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filter_size` = 3'
- en: '`num_filters` = 32'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_filters` = 32'
- en: 'This is the output of the printout:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 这是打印输出的结果：
- en: '[PRE32]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Third convolution layer
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三个卷积层
- en: 'This layer takes the output of the second layer as the input. Let''s look at
    the inputs going into the creation of this layer:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 该层将第二层的输出作为输入。让我们看看输入是如何进入该层的：
- en: '![](img/2d0e1178-13c2-41d2-b055-3e003015ed40.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2d0e1178-13c2-41d2-b055-3e003015ed40.png)'
- en: '[PRE33]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[PRE35]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The shape of `layer_conv3` is as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '`layer_conv3`的形状如下：'
- en: '[PRE36]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Flatten the layer
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扁平化该层
- en: 'Next, we flatten the layer to the `num` of images and the `num` of features,
    which is 16,384 in this case. If you notice for the last layer''s output, we have
    flattened it with the following logic, 16 x 16 x 64 = 16,384:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将该层扁平化为`num`图像和`num`特征，在本例中为16,384。如果你注意到最后一层的输出，我们已经使用以下逻辑进行了扁平化：16 x
    16 x 64 = 16,384：
- en: '[PRE37]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'If we print these values, you will see the following output:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们打印这些值，你将看到以下输出：
- en: '[PRE38]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Fully connected layers
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全连接层
- en: 'In the fourth and fifth layers, we define fully connected layers:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在第四和第五层中，我们定义了全连接层：
- en: '[PRE39]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: where
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '`layer_flat`: the last layer flattened'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_flat`：最后一层的扁平化'
- en: '`num_features`: number of features'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_features`：特征数量'
- en: '`fc_size`: number of outputs'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fc_size`：输出数量'
- en: 'The following image shows the values that are passed to `new_fc_layer()`:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了传递给`new_fc_layer()`的值：
- en: '![](img/dd3e30ec-b8fb-4c02-ac90-428f32e4a762.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dd3e30ec-b8fb-4c02-ac90-428f32e4a762.png)'
- en: '[PRE40]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The value of the print is as follows:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 打印的值如下：
- en: '[PRE41]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Next is the fully connected layer 2, where the function takes the following
    parameters:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是第二个全连接层，其中该函数接受以下参数：
- en: '`layer_fc1`: the output from the first fully connected layer'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`layer_fc1`：来自第一个全连接层的输出'
- en: '`num_inputs`: 128'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inputs`：128'
- en: '`num_inputs`: `num_classes`, 2 in this case'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`num_inputs`：`num_classes`，此处为2'
- en: '`use_relu`: a Boolean function specifying whether to use `relu` or not; `False`
    in this case'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`use_relu`：一个布尔函数，用于指定是否使用`relu`；此处为`False`'
- en: '[PRE42]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Let''s take a look at the output of the second fully connected layer:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看第二个全连接层的输出：
- en: '[PRE43]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[PRE44]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Defining cost and optimizer
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义代价函数和优化器
- en: Apply Softmax on the output from `layer_fc2` (the fully connected second layer).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 对来自`layer_fc2`（第二个全连接层）的输出应用Softmax。
- en: 'In mathematics, the `softmax` function, or normalized exponential function,^([[1]](https://en.wikipedia.org/wiki/Softmax_function#cite_note-bishop-1))^(:198)
    is a generalization of the [logistic function](https://en.wikipedia.org/wiki/Logistic_function)
    that *squashes* a K-dimensional vector Z of arbitrary real values to a K-dimensional
    vector *σ(z)* of real values in the range [*0*, *1*] that add up to *1*. The function
    is given by the following formula:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在数学中，`softmax` 函数或归一化指数函数^([[1]](https://en.wikipedia.org/wiki/Softmax_function#cite_note-bishop-1))^(:198)
    是[逻辑斯蒂函数](https://en.wikipedia.org/wiki/Logistic_function)的推广，它将任意实值的 K 维向量 Z
    压缩为一个 K 维实值向量 *σ(z)*，该向量的取值范围为 [*0*，*1*]，并且所有值的和为 *1*。该函数的公式如下：
- en: '![](img/be5e10c9-6ffd-4ff8-bcf3-35b80c8c2454.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](img/be5e10c9-6ffd-4ff8-bcf3-35b80c8c2454.png)'
- en: '[PRE45]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Calculate the cross entropy:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 计算交叉熵：
- en: '[PRE46]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Optimizer
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化器
- en: Next, we define the optimizer, which is based on the Adam optimizer.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义基于 Adam 优化器的优化器。
- en: Adam is different to the stochastic gradient descent algorithm. Stochastic gradient
    descent maintains a single learning rate (called **alpha**) for all weight updates
    and the learning rate does not change during training.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: Adam 与随机梯度下降算法有所不同。随机梯度下降为所有权重更新维持一个单一的学习率（称为**alpha**），并且学习率在训练过程中不会改变。
- en: This algorithm maintains a learning rate for each network weight (parameter)
    and separately adapts as learning unfolds. It computes individual adaptive learning
    rates for different parameters from the estimates of the first and second moments
    of the gradients.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法为每个网络权重（参数）维持一个学习率，并随着学习的展开进行单独调整。它通过估计梯度的一阶和二阶矩，计算不同参数的自适应学习率。
- en: Adam combines the advantages of two other extensions of stochastic gradient
    descent.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: Adam结合了随机梯度下降的两种扩展的优点。
- en: The **adaptive gradient algorithm** (**AdaGrad**) maintains a per-parameter
    learning rate that improves performance for ML problems with sparse gradients
    (for example, natural language and computer vision problems). **Root mean square
    propagation** (**RMSProp**) maintains learning rates for each parameter; these
    are adapted based on the average of recent values of the gradients for the weight
    (how quickly it is changing).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '**自适应梯度算法**（**AdaGrad**）为每个参数维持一个单独的学习率，它在稀疏梯度的机器学习问题（例如自然语言处理和计算机视觉问题）中提高性能。**均方根传播**（**RMSProp**）为每个参数维持学习率；这些学习率根据最近的梯度平均值进行调整（即权重变化的速度）。'
- en: '[PRE47]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We also calculate the variables for `correct_prediction` and `accuracy`:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还计算了 `correct_prediction` 和 `accuracy` 的变量：
- en: '[PRE48]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: First epoch
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一轮
- en: 'Initialize the session and call the `optimize()` function for `num_iterations=1`:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化会话，并对 `num_iterations=1` 调用 `optimize()` 函数：
- en: '[PRE49]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Here, the `optimize()` function is defined in the following block:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`optimize()` 函数在以下代码块中定义：
- en: '[PRE50]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The output that prints the training, validation accuracy, and validation loss
    is listed here:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 输出打印了训练、验证准确率和验证损失，内容如下：
- en: '[PRE51]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Print the accuracy of `Test-Set`:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 打印 `Test-Set` 的准确率：
- en: '[PRE52]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Next, let''s optimize the model for `100` iterations:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们对模型进行 `100` 次迭代优化：
- en: '[PRE53]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'The output also shows false positives:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 输出中也显示了假阳性：
- en: '![](img/0701d3e7-93a0-4d1f-a3a1-b60938860ec7.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0701d3e7-93a0-4d1f-a3a1-b60938860ec7.png)'
- en: Output showing false positives
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 显示假阳性的输出
- en: Plotting filters and their effects on an image
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 绘制过滤器及其对图像的影响
- en: 'Let''s apply filters in two layers to two test images and see how that affects
    them:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对两张测试图像应用两层过滤器，看看它们的变化：
- en: '[PRE54]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The output of the `plot_image(image1)` function is shown in the following image:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '`plot_image(image1)` 函数的输出如下面的图像所示：'
- en: '![](img/e73c27ed-677f-4ced-a229-e7ae1b1f0828.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e73c27ed-677f-4ced-a229-e7ae1b1f0828.png)'
- en: '[PRE55]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The output of `image2` with filters applied is shown here:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 应用过滤器后的 `image2` 输出如下：
- en: '![](img/7a69fdcd-2edf-412c-8c87-2f3e61a606f0.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7a69fdcd-2edf-412c-8c87-2f3e61a606f0.png)'
- en: '**Convolution layer 1**: The following is the plot for weights for layer 1:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积层 1**：以下是层 1 权重的图示：'
- en: '![](img/148d381d-ae2f-431f-9f59-c5777a7ffdd3.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![](img/148d381d-ae2f-431f-9f59-c5777a7ffdd3.png)'
- en: 'Filters from layer 1 applied to i mage 1:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 层 1 的过滤器应用于图像 1：
- en: '[PRE56]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '![](img/0a7fcbe4-27aa-4810-8426-3dcfc2b29895.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0a7fcbe4-27aa-4810-8426-3dcfc2b29895.png)'
- en: 'Filters from Layer 1 applied to Image 2:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 层 1 的过滤器应用于图像 2：
- en: '[PRE57]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '![](img/c87f3e63-b355-43f2-a591-73c5adbff0c9.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c87f3e63-b355-43f2-a591-73c5adbff0c9.png)'
- en: '**Convolution layer 2**: Now plot the filter-weights for the second convolutional
    layer. There are 16 output channels from the first conv-layer, which means there
    are 16 input channels to the second conv-layer. The second Conv layer has a set
    of filter-weights for each of its input channels. We start by plotting the filter-weights
    for the first channel.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积层 2**：现在绘制第二个卷积层的滤波器权重。第一卷积层有 16 个输出通道，意味着第二个卷积层有 16 个输入通道。第二个卷积层每个输入通道都有一组滤波器权重。我们首先绘制第一个通道的滤波器权重。'
- en: 'Layer 2 weights:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: Layer 2 权重：
- en: '[PRE58]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '![](img/1fef67e7-1d91-4d12-8472-88ba49458be4.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1fef67e7-1d91-4d12-8472-88ba49458be4.png)'
- en: Weights for Conv2, input channel 0\. Positive weights are red and negative weights
    are blue
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: Conv2 的权重，输入通道 0。正权重为红色，负权重为蓝色
- en: 'There are 16 input channels to the second convolutional layer, so we can make
    another 15 plots of filter-weights like this. We just make one more with the filter-weights
    for the second channel:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个卷积层有 16 个输入通道，因此我们可以制作另外 15 个类似这样的滤波器权重图。我们只需再制作一个，用于第二个通道的滤波器权重：
- en: '[PRE59]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: '![](img/3940424f-1b26-4655-a8e6-33b1f835132c.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3940424f-1b26-4655-a8e6-33b1f835132c.png)'
- en: Positive weights are red and negative weights are blue
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 正权重为红色，负权重为蓝色
- en: 'Plot Images 1 and 2 with filters from convolution layer 2:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 使用第二个卷积层的滤波器绘制图像 1 和图像 2：
- en: '[PRE60]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '![](img/32a3fb47-36fc-4c28-a134-dbe122e429f9.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![](img/32a3fb47-36fc-4c28-a134-dbe122e429f9.png)'
- en: Weights for conv2, input channel 1\. Image displaying image1 filtered through
    a layer 2 filter
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: Conv2 的权重，输入通道 1。图像 1 经第 2 层滤波器过滤
- en: '![](img/cf75f4f8-7094-42de-93ae-a53ef5def00c.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cf75f4f8-7094-42de-93ae-a53ef5def00c.png)'
- en: Image displaying image 2 filtered through a layer 2 filter
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 显示经第 2 层滤波器过滤的图像 2
- en: '**Convolution Layer 3**: Let''s print the layer 3 weights; this layer has 64
    filters. This is how images 1 and 2 look passed through each of these filters:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积层 3**：让我们打印第 3 层的权重；这一层有 64 个滤波器。这是图像 1 和图像 2 通过每个滤波器后的效果：'
- en: '[PRE61]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: '![](img/75b0fedd-b2fc-4fd5-b618-1bfad5389d36.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![](img/75b0fedd-b2fc-4fd5-b618-1bfad5389d36.png)'
- en: Weights for Conv2, Input Channel 0, Positive weights are red and negative weights
    are blue
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: Conv2 的权重，输入通道 0。正权重为红色，负权重为蓝色
- en: '[PRE62]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '![](img/ee6baebb-0628-4681-b538-6049633ac2e8.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ee6baebb-0628-4681-b538-6049633ac2e8.png)'
- en: Weights for Conv2, input channel 1\. Positive weights are red and negative weights
    are blue.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: Conv2 的权重，输入通道 1。正权重为红色，负权重为蓝色。
- en: '**Plotting an image passed through layer 3 filters**: Execute the following
    statements to plot images 1 and 2 being passed from 64 filters of convolution
    layer 3:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '**通过第 3 层滤波器绘制通过的图像**：执行以下语句绘制通过第 3 层 64 个卷积滤波器的图像 1 和图像 2：'
- en: '[PRE63]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '![](img/0c6fbc09-09e5-4a7d-ae8b-9f7c14c9a579.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0c6fbc09-09e5-4a7d-ae8b-9f7c14c9a579.png)'
- en: Image 1, plotted with convolution filters from conv3
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图像 1，使用第 2 层滤波器绘制的图像
- en: 'The following is the image with convolution filters from conv3:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是来自 conv3 的卷积滤波器图像：
- en: '![](img/a8b2d685-5888-4864-b36a-f979f377d1ec.png)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a8b2d685-5888-4864-b36a-f979f377d1ec.png)'
- en: Image 2, plotted with convolution filters from conv3
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 图像 2，使用第 3 层滤波器绘制
- en: With this, we have completed the analysis of the Cats versus Dogs dataset, where
    we used a five-layer CNN with three hidden layers and two fully connected layers
    to build our model.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些，我们完成了猫与狗数据集的分析，在这里我们使用了一个五层 CNN，包括三个隐藏层和两个全连接层来构建我们的模型。
- en: Summary
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned the basics of convolution and why it is an effective
    mechanism for image label prediction. You learned about basic concepts such as
    `strides` and padding. This was followed by an example based on the Stanford dataset
    of Cats versus Dogs. We used three convolution layers to build the neural network
    and two fully connected layers to showcase how it is used to classify the images.
    We also plotted the weights for three layers and saw how filters modify the image.
    We also looked at concepts such as image pooling and how it helps make CNN more
    efficient.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学习了卷积的基础知识，以及为什么它是图像标签预测的有效机制。您学习了诸如 `strides` 和填充等基本概念。接着以斯坦福数据集中猫与狗的示例展开，我们使用了三个卷积层来构建神经网络，并使用两个全连接层展示如何用于图像分类。我们还绘制了三层的权重，并看到滤波器如何修改图像。我们还讨论了图像池化等概念，以及它如何帮助使
    CNN 更高效。
- en: In the next chapter we look at a different kind of neural network called a **Recurrent
    Neural Network** (**RNN**), which processes time series data or is used for **natural
    language processing** (**NLP**) to predict next word in a sequence
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将介绍一种不同类型的神经网络，叫做**循环神经网络**（**RNN**），它处理时间序列数据或用于**自然语言处理**（**NLP**），以预测序列中的下一个词。
