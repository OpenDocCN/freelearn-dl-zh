- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Forecasting with PyTorch Lightning
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PyTorch Lightning 进行预测
- en: In this chapter, we’ll build forecasting models using PyTorch Lightning. We’ll
    touch on several aspects of this framework, such as creating a data module to
    handle data preprocessing or creating a `LightningModel` structure that encapsulates
    the training process of neural networks. We’ll also explore **TensorBoard** to
    monitor the training process of neural networks. Then, we’ll describe a few metrics
    for evaluating deep neural networks for forecasting, such as **Mean Absolute Scaled
    Error** (**MASE**) and **Symmetric Mean Absolute Percentage Error** (**SMAPE**).
    In this chapter, we’ll focus on multivariate time series, which contain more than
    one variable.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用 PyTorch Lightning 构建预测模型。我们将探讨该框架的几个方面，例如创建数据模块来处理数据预处理，或创建 `LightningModel`
    结构来封装神经网络的训练过程。我们还将探索 **TensorBoard** 来监控神经网络的训练过程。接下来，我们将描述几种用于评估深度神经网络预测效果的指标，如
    **均方绝对缩放误差** (**MASE**) 和 **对称平均绝对百分比误差** (**SMAPE**)。在本章中，我们将重点讨论多变量时间序列，这些序列包含多个变量。
- en: 'This chapter will guide you through the following recipes:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将引导你完成以下几个实例：
- en: Preparing a multivariate time series for supervised learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备多变量时间序列进行监督学习
- en: Training a linear regression model for forecasting with a multivariate time
    series
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多变量时间序列训练线性回归预测模型
- en: Feedforward neural networks for multivariate time series forecasting
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于多变量时间序列预测的前馈神经网络
- en: LSTM neural networks for multivariate time series forecasting
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于多变量时间序列预测的 LSTM 神经网络
- en: Evaluating deep neural networks for forecasting
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估深度神经网络的预测效果
- en: Monitoring the training process using Tensorboard
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Tensorboard 监控训练过程
- en: Using callbacks – `EarlyStopping`
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用回调函数 – `EarlyStopping`
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, we’ll leverage the following Python libraries, all of which
    you can install using `pip`:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用以下 Python 库，所有这些库都可以通过 `pip` 安装：
- en: PyTorch Lightning (2.1.4)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch Lightning (2.1.4)
- en: PyTorch Forecasting (1.0.0)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch Forecasting (1.0.0)
- en: '`torch` (2.2.0)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`torch` (2.2.0)'
- en: '`ray` (2.9.2)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ray` (2.9.2)'
- en: '`numpy` (1.26.3)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy` (1.26.3)'
- en: '`pandas` (2.1.4)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pandas` (2.1.4)'
- en: '`scikit-learn` (1.4.0)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`scikit-learn` (1.4.0)'
- en: '`sktime` (0.26.0)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sktime` (0.26.0)'
- en: 'The code for this chapter can be found in this book’s GitHub repository: [https://github.com/PacktPublishing/Deep-Learning-for-Time-Series-Data-Cookbook](https://github.com/PacktPublishing/Deep-Learning-for-Time-Series-Data-Cookbook).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在本书的 GitHub 仓库找到：[https://github.com/PacktPublishing/Deep-Learning-for-Time-Series-Data-Cookbook](https://github.com/PacktPublishing/Deep-Learning-for-Time-Series-Data-Cookbook)。
- en: Preparing a multivariate time series for supervised learning
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备多变量时间序列进行监督学习
- en: The first recipe of this chapter addresses the problem of preparing a multivariate
    time series for supervised learning. We’ll show how the sliding window method
    we used in the previous chapter can be extended to solve this task. Then, we’ll
    demonstrate how to prepare a time series using `TimeSeriesDataSet`, a PyTorch
    Forecasting class that handles the preprocessing steps of time series.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的第一个实例解决了如何准备多变量时间序列进行监督学习的问题。我们将展示在上一章中使用的滑动窗口方法如何扩展来解决这个任务。接着，我们将演示如何使用
    `TimeSeriesDataSet`（一个 PyTorch Forecasting 类，用于处理时间序列的预处理步骤）来准备时间序列数据。
- en: Getting ready
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We’ll use the same time series we analyzed in [*Chapter 1*](B21145_01.xhtml#_idTextAnchor019).
    We’ll need to load the dataset with `pandas` using the following code:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用在 [*第 1 章*](B21145_01.xhtml#_idTextAnchor019) 中分析的相同时间序列。我们需要使用以下代码，通过
    `pandas` 加载数据集：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following figure shows a sample of the time series. Please note that the
    axes have been transposed for visualization purposes:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了时间序列的示例。请注意，为了便于可视化，坐标轴已被转置：
- en: '![Figure 4.1: Sample of a multivariate time series. The variables of the series
    are shown on the x axis for visualization purposes](img/B21145_04_001.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1：多变量时间序列示例。系列的变量显示在 x 轴上，以便于可视化](img/B21145_04_001.jpg)'
- en: 'Figure 4.1: Sample of a multivariate time series. The variables of the series
    are shown on the x axis for visualization purposes'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1：多变量时间序列示例。系列的变量显示在 x 轴上，以便于可视化
- en: The preceding dataset contains nine variables related to meteorological conditions.
    As we did in [*Chapter 3*](B21145_03.xhtml#_idTextAnchor178), the goal is to forecast
    the next solar radiation values. We’ll use the lags of the extra available variables
    as input explanatory variables. In the next chapter, you will learn how to prepare
    a multivariate time series for cases where you want to forecast several variables.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 上述数据集包含九个与气象条件相关的变量。就像在 [*第 3 章*](B21145_03.xhtml#_idTextAnchor178) 中一样，目标是预测下一个太阳辐射值。我们将使用额外可用变量的滞后值作为输入解释变量。在下一章中，你将学习如何为需要预测多个变量的情况准备多变量时间序列。
- en: How to do it…
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点……
- en: We’ll transform a multivariate time series for supervised learning. First, we’ll
    describe how to do this using the sliding window approach that we used in [*Chapter
    3*](B21145_03.xhtml#_idTextAnchor178). Then, we’ll show how this process can be
    simplified with the `TimeSeriesDataSet` data structure, which is based on PyTorch.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将对多变量时间序列进行监督学习的转换。首先，我们将描述如何使用我们在 [*第 3 章*](B21145_03.xhtml#_idTextAnchor178)
    中使用的滑动窗口方法。然后，我们将展示如何使用基于 PyTorch 的 `TimeSeriesDataSet` 数据结构简化此过程。
- en: Using a sliding window
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用滑动窗口
- en: 'In the previous chapter, we used a sliding window approach to transform a univariate
    time series from a sequence into a matrix format. Preparing a multivariate time
    series for supervised learning requires a similar process: we apply the sliding
    window technique to each variable and then combine the results. This process can
    be carried out as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们使用滑动窗口方法将单变量时间序列从一个序列转换为矩阵格式。为监督学习准备多变量时间序列需要类似的过程：我们对每个变量应用滑动窗口技术，然后将结果合并。这个过程可以按以下方式进行：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The preceding code follows these steps:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码遵循以下步骤：
- en: First, we define the number of lags and forecasting horizon. We set the number
    of lags to `7` (`N_LAGS=7`), the forecasting horizon to `1` (`HORIZON=1`), and
    the target variable to `Incoming Solar.`
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们定义滞后数和预测视野。我们将滞后数设置为 `7`（`N_LAGS=7`），预测视野设置为 `1`（`HORIZON=1`），目标变量设置为 `Incoming
    Solar.`。
- en: Then, we iterate over each time step in the multivariate time series. At each
    point, we retrieve the previous `N_LAGS`, add these to the `input_data`, and add
    the next value of solar radiation to the output data. This means we’ll use the
    past `7` values of each variable to forecast the next value of solar radiation.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们遍历多变量时间序列中的每个时间步骤。在每个点，我们检索前 `N_LAGS` 的数据，将其添加到 `input_data` 中，并将下一个太阳辐射值添加到输出数据中。这意味着我们将使用每个变量的过去
    `7` 个值来预测下一个太阳辐射值。
- en: Finally, we transform the input and output data from a `Python` list into a
    `NumPy` `array` structure.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将输入和输出数据从 `Python` 列表转换为 `NumPy` `array` 结构。
- en: '`output_data` is a one-dimensional vector that represents the future value
    of solar radiation. `input_data` has 3 dimensions: the first dimension refers
    to the number of samples, the second is the number of lags, and the third is the
    number of variables in the series.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '`output_data` 是一个一维向量，表示未来的太阳辐射值。`input_data` 有三个维度：第一个维度表示样本数量，第二个维度表示滞后数量，第三个维度表示序列中的变量数量。'
- en: Using the TimeSeriesDataSet class
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 `TimeSeriesDataSet` 类
- en: So far, we’ve been using a sliding window method to preprocess time series for
    supervised learning. This function and other preprocessing tasks that are required
    for training a neural network are automated by the `TimeSeriesDataSet` class,
    which is available in the PyTorch Forecasting library.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直在使用滑动窗口方法来预处理时间序列，供监督学习使用。这个功能和训练神经网络所需的其他预处理任务都通过 `TimeSeriesDataSet`
    类进行了自动化，该类可在 PyTorch Forecasting 库中找到。
- en: '`TimeSeriesDataSet` provides a simple and useful way of preparing and passing
    data to models. Let’s see how this structure can be used to handle multivariate
    time series. First, we need to shape the time series in a pandas DataFrame structure
    with three main pieces of information:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '`TimeSeriesDataSet` 提供了一种简单且有效的方法来准备数据并将其传递给模型。让我们来看一下如何使用这个结构来处理多变量时间序列。首先，我们需要将时间序列组织成一个包含三种主要信息的
    pandas DataFrame 结构：'
- en: '`group_id`: A column that identifies the name of a time series. If the dataset
    contains a single time series, this column will show a constant value. Some datasets
    involve multiple time series that can be distinguished by this variable.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`group_id`：一个列，用于标识时间序列的名称。如果数据集包含单一时间序列，该列将显示一个常量值。有些数据集涉及多个时间序列，可以通过此变量区分。'
- en: '`time_index`: This stores the time at which a value is captured by a given
    series.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time_index`：存储某一时间点上给定序列捕获的值。'
- en: '**Other variables**: Extra variables that store the value of the time series.
    A multivariate time series contains several variables.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**其他变量**：存储时间序列值的额外变量。多变量时间序列包含多个变量。'
- en: 'Our time series already contains several variables. Now, we need to add information
    about `time_index` and `group_id`, which can be done as follows:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的时间序列已经包含了多个变量。现在，我们需要添加关于`time_index`和`group_id`的信息，可以通过如下方式完成：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The value of `group_id` is constantly `0` since we’re working with a single
    time series. We use `0` arbitrarily. You can use any name that suits you. We use
    the `np.arange``()` function to create this time series’ `time_index`. This creates
    a variable that gives `0` for the first observation, `1` for the second observation,
    and so on.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`group_id`的值始终为`0`，因为我们正在处理单个时间序列。我们随便使用`0`。你可以使用任何适合的名称。我们使用`np.arange``()`函数来创建这个时间序列的`time_index`。这会创建一个变量，对第一个观察值给出`0`，对第二个观察值给出`1`，依此类推。'
- en: 'Then, we must create an instance of the `TimeSeriesDataSet` class, as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们必须创建`TimeSeriesDataSet`类的一个实例，如下所示：
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can transform a `TimeSeriesDataSet` dataset into a `DataLoader` class as
    follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将`TimeSeriesDataSet`数据集转换为`DataLoader`类，如下所示：
- en: '[PRE4]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`DataLoader` is used to pass observations to a model. Here’s an example of
    what an observation looks like:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataLoader`用于将观察值传递给模型。以下是一个观察值的示例：'
- en: '[PRE5]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We use the `next``()` and `iter``()` methods to get an observation from the
    data loader. This observation is stored as `x` and `y`, which represent the input
    and output data, respectively. The main input is the `encoder_cont` item, which
    denotes the `7` lags of each variable. This data is a PyTorch tensor with the
    shape (`1`, `7`, `9`) representing (batch size, number of lags, number of variables).
    The batch size is a parameter that represents the number of samples used in each
    training iteration of a neural network. The output data is a float that represents
    the next value of the solar radiation variable.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`next``()`和`iter``()`方法从数据加载器中获取一个观察值。这个观察值被存储为`x`和`y`，分别表示输入和输出数据。主要的输入是`encoder_cont`项，表示每个变量的`7`个滞后值。这个数据是一个PyTorch张量，形状为(`1`,
    `7`, `9`)，表示（批量大小、滞后数、变量数）。批量大小是一个参数，表示神经网络每次训练迭代中使用的样本数。输出数据是一个浮动值，表示太阳辐射变量的下一个值。
- en: How it works…
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: 'The `TimeSeriesDataSet` constructor requires a few parameters:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`TimeSeriesDataSet`构造函数需要一些参数：'
- en: '`data`: A time series dataset with the three elements described earlier'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data`：一个包含之前描述的三个元素的时间序列数据集'
- en: '`group_ids`: The column in `data` that identifies each time series in the dataset'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`group_ids`：`data`中标识数据集每个时间序列的列'
- en: '`target`: The column in `data` that we want to forecast (target variable)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target`：`data`中我们想要预测的列（目标变量）'
- en: '`time_idx`: The column in `data` that contains the time information of each
    observation'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time_idx`：`data`中包含每个观察值的时间信息的列'
- en: '`max_encoder_length`: The number of lags used to build the auto-regressive
    model'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_encoder_length`：用于构建自回归模型的滞后数'
- en: '`max_prediction_length`: The forecasting horizon – that is, how many future
    time steps should be predicted'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_prediction_length`：预测视野——即，应该预测多少未来时间步长'
- en: '`time_varying_unknown_reals`: A list of columns in `data` that describes which
    numeric variables vary over time'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`time_varying_unknown_reals`：`data`中列出的描述哪些数值变量随时间变化的列'
- en: There are other parameters related to `time_varying_unknown_reals`. This particular
    input details all numeric observations whose future is unknown to the user, such
    as the variables we want to forecast. Yet, in some cases, we know the future value
    of an observation, such as the price of a product. This type of variable should
    be included in the `time_varying_known_reals` input. There are also the `time_varying_known_categoricals`
    and `time_varying_unknown_categoricals` inputs, which can be used for categorical
    variables instead of numeric ones.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他与`time_varying_unknown_reals`相关的参数。这个特定的输入详细描述了所有未来值对用户未知的数值观测值，例如我们想要预测的变量。然而，在某些情况下，我们知道一个观测值的未来值，例如产品价格。这类变量应该包含在`time_varying_known_reals`输入中。还有`time_varying_known_categoricals`和`time_varying_unknown_categoricals`输入，可用于代替数值型变量的分类变量。
- en: Regarding the forecasting task, the transformation we carried out in this recipe
    is the basis of a type of modeling called **Auto-Regressive Distributed Lags**
    (**ARDL**). ARDL is an extension of auto-regression that also includes the lags
    of exogenous variables as input.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 关于预测任务，我们在这个示例中进行的转换是名为**自回归分布滞后模型**（**ARDL**）的一种建模方法的基础。ARDL是自回归的扩展，也包括外生变量的滞后作为输入。
- en: Training a linear regression model for forecasting with a multivariate time
    series
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用多元时间序列训练线性回归模型进行预测
- en: In this recipe, we’ll use PyTorch to train a linear regression model as our
    first forecasting model fit on a multivariate time series. We’ll show you how
    to use `TimeSeriesDataSet` to handle the preprocessing steps for training the
    model and passing data to it.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用PyTorch训练一个线性回归模型，作为我们第一个在多元时间序列上拟合的预测模型。我们将展示如何使用`TimeSeriesDataSet`处理训练模型的数据预处理步骤，并将数据传递给模型。
- en: Getting ready
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'We’ll start this recipe with the `mvtseries` dataset that we used in the previous
    recipe:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从之前示例中使用的`mvtseries`数据集开始：
- en: '[PRE6]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now, let’s see how we can use this dataset to train a PyTorch model.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何使用这个数据集来训练一个PyTorch模型。
- en: How to do it…
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'In the following code, we’ll describe the necessary steps to prepare the time
    series and build a linear regression model:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的代码中，我们将描述准备时间序列和构建线性回归模型所需的步骤：
- en: 'We start by preprocessing the time series. This includes creating the group
    identifier and time index columns:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从预处理时间序列开始。这包括创建组标识符和时间索引列：
- en: '[PRE7]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, we must split the data into different partitions. For this recipe, we’ll
    only keep the training indices:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们必须将数据划分为不同的部分。对于这个示例，我们只保留训练集的索引：
- en: '[PRE8]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, we must standardize the time series using the `StandardScaler` operator:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们必须使用`StandardScaler`操作符对时间序列进行标准化：
- en: '[PRE9]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preprocessed time series is passed onto a `TimeSeriesDataSet` instance:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理后的时间序列被传递给一个`TimeSeriesDataSet`实例：
- en: '[PRE10]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The `TimeSeriesDataSet` object is transformed into a data loader that can be
    used to pass batches of samples to a model. This is done using the `to_dataloader()`
    method. We encapsulate all these data preparation steps into a single function
    called `create_training_set`. You can check out the function’s source in this
    book’s GitHub repository.
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`TimeSeriesDataSet`对象被转换成一个数据加载器，可以用于将样本批次传递给模型。这是通过`to_dataloader()`方法完成的。我们将所有这些数据准备步骤封装成一个名为`create_training_set`的函数。你可以在本书的GitHub仓库中查看该函数的源代码。'
- en: 'Next, we call the `create_training_set``()` function to create the training
    dataset:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们调用`create_training_set()`函数来创建训练数据集：
- en: '[PRE11]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Then, we must define the linear regression model using PyTorch, as follows:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们必须使用PyTorch定义线性回归模型，如下所示：
- en: '[PRE12]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here, we define a class called `LinearRegressionModel` that implements the multiple
    linear regression model. It contains a single linear transformation layer (`nn.Linear`).
    This class takes the input and output sizes as input, which are the second dimension
    of the `train_input` and `train_output` objects, respectively. We created the
    model by calling the class with these parameters.
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们定义了一个名为`LinearRegressionModel`的类，来实现多元线性回归模型。它包含一个线性变换层（`nn.Linear`）。这个类接受输入和输出的大小作为输入，分别对应`train_input`和`train_output`对象的第二维。我们通过传入这些参数来创建该模型。
- en: 'Now, we will create an instance of this model, as follows:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将按照以下方式创建这个模型的一个实例：
- en: '[PRE13]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`num_vars` contains the number of variables in the time series. Then, we define
    the input of the model to `num_vars` times `N_LAGS` and the output to the forecasting
    horizon.'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`num_vars`包含时间序列中的变量数量。然后，我们将模型的输入定义为`num_vars`乘以`N_LAGS`，输出则定义为预测时长。'
- en: 'We can perform the training process using the following code:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用以下代码进行训练过程：
- en: '[PRE14]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Here, we set the learning rate to `0.001` and the optimizer to Adam. Adam is
    a popular alternative to approaches such as SGD that has better converge characteristics.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们将学习率设置为`0.001`，优化器设置为Adam。Adam是一个常见的替代方法，比SGD等方法具有更好的收敛特性。
- en: At each training epoch, we get the lags of each batch from the data loader and
    process them with the model. Note that each batch is reshaped into a two-dimensional
    format that is required by a linear model. This is done in the `forward()` method
    of the `LinearRegressionModel` class.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在每个训练周期，我们从数据加载器中获取每个批次的滞后，并使用模型对其进行处理。注意，每个批次都会被重新调整为线性模型所需的二维格式。这是在`LinearRegressionModel`类的`forward()`方法中完成的。
- en: How it works…
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: We used the `TimeSeriesDataSet` class to handle the data preparation process
    for us. Then, we converted the dataset into a `DataLoader` class using the `to_dataloader()`
    method. This data loader provides batches of data to the model. Although we did
    not define it explicitly, each batch follows an autoregressive way of modeling.
    The input is based on the past few observations of the time series, and the output
    represents the future observations.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`TimeSeriesDataSet`类来处理数据准备过程。然后，我们通过`to_dataloader()`方法将数据集转换为`DataLoader`类。这个数据加载器为模型提供数据批次。虽然我们没有显式定义它，但每个批次都遵循自回归的建模方式。输入基于时间序列的过去几次观测，输出代表未来的观测值。
- en: We implement the linear regression model as a class so that it follows the same
    structure as in the previous chapter. We could create the model with `model =
    nn.Linear(input_size, output_size)` for simplicity.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将线性回归模型实现为一个类，以便它遵循与上一章相同的结构。为了简化，我们可以通过`model = nn.Linear(input_size, output_size)`来创建模型。
- en: Feedforward neural networks for multivariate time series forecasting
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于多变量时间序列预测的前馈神经网络
- en: In this recipe, we’ll return our attention to deep neural networks. We’ll show
    you how to build a forecasting model for multivariate time series using a deep
    feedforward neural network. We’ll describe how to couple the `DataModule` class
    with `TimeSeriesDataSet` to encapsulate the data preprocessing steps. We’ll also
    place the `PyTorch` models within a `LightningModule` structure, which standardizes
    the training process of neural networks.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将重新关注深度神经网络。我们将展示如何使用深度前馈神经网络为多变量时间序列构建预测模型。我们将描述如何将`DataModule`类与`TimeSeriesDataSet`结合，以封装数据预处理步骤。我们还将把`PyTorch`模型放在`LightningModule`结构中，这样可以标准化神经网络的训练过程。
- en: Getting ready
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: 'We’ll continue to use the multivariate time series related to solar radiation
    forecasting:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续使用与太阳辐射预测相关的多变量时间序列：
- en: '[PRE15]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In this recipe, we’ll use a data module from `pytorch_lightning` to handle
    data preprocessing. Data modules are classes that contain all the steps for preprocessing
    data and sharing it with models. Here is the basic structure of a data module:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们将使用来自`pytorch_lightning`的数据模块来处理数据预处理。数据模块是包含所有数据预处理步骤并与模型共享数据的类。以下是数据模块的基本结构：
- en: '[PRE16]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'All data modules inherit from the `LightningDataModule` class. There are a
    few key methods that we need to implement:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 所有数据模块都继承自`LightningDataModule`类。我们需要实现几个关键方法：
- en: '`setup()`: This method includes all the main data preprocessing steps'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`setup()`：此方法包含所有主要的数据预处理步骤'
- en: '`train_dataloader()`, `val_dataloader()`, `test_dataloader()`, and `predict_dataloader()`:
    These are a set of methods that get the data loader for the respective dataset
    (training, validation, testing, and prediction)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`train_dataloader()`、`val_dataloader()`、`test_dataloader()`和`predict_dataloader()`：这些是获取相应数据集（训练、验证、测试和预测）数据加载器的一组方法'
- en: 'Besides a `DataModule` class, we’ll also leverage the `LightningModule` class
    to encapsulate all the model processes. These modules have the following structure:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`DataModule`类外，我们还将利用`LightningModule`类来封装所有模型过程。这些模块具有以下结构：
- en: '[PRE17]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let’s take a closer look at `ExampleModel`:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看`ExampleModel`：
- en: We define any necessary neural network elements in the attributes of the class
    (such as `self.network`)
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在类的属性中定义任何必要的神经网络元素（例如`self.network`）
- en: The `forward()` method defines how the elements of the network interact and
    model the time series
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`forward()`方法定义了网络元素如何相互作用并建模时间序列'
- en: '`training_step`, `validation_step`, and `testing_step` describe the training,
    validation, and testing processes of the network, respectively'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`training_step`、`validation_step`和`testing_step`分别描述了网络的训练、验证和测试过程'
- en: '`predict_step` details the process of getting the latest observations and making
    a forecast, mimicking a deployment scenario'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`predict_step`详细描述了获取最新观测值并进行预测的过程，模拟了部署场景'
- en: Finally, the `configure_optimizers``()` method details the optimization setup
    for the network
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，`configure_optimizers()`方法详细描述了网络的优化设置
- en: Let’s see how we can create a data module to preprocess a multivariate time
    series, and how it couples with `TimeSeriesDataSet`. Then, we’ll implement a `LightningModule`
    structure to handle the training and testing process of a feedforward neural network.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何创建一个数据模块来预处理多变量时间序列，以及它如何与`TimeSeriesDataSet`结合。然后，我们将实现一个`LightningModule`结构来处理前馈神经网络的训练和测试过程。
- en: How to do it…
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何进行…
- en: 'The following code shows how to define the data module to handle the preprocessing
    steps. First, let’s look at the class constructor:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码展示了如何定义数据模块以处理预处理步骤。首先，让我们看一下类的构造函数：
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In the constructor, we define all the necessary elements for data preparation,
    such as the number of lags, forecasting horizon, and datasets. This includes the
    initialization of the `target_scaler` attribute, which is used to standardize
    the value of the time series.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在构造函数中，我们定义了所有必要的数据准备元素，如滞后数、预测时间跨度和数据集。这包括初始化`target_scaler`属性，该属性用于标准化时间序列的值。
- en: 'Then, we create the `setup()` method, which includes the data preprocessing
    logic:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建`setup()`方法，其中包括数据预处理逻辑：
- en: '[PRE19]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Some of the methods, such as `self.preprocess_data()`, have been omitted for
    conciseness. You can find their source in this book’s GitHub repository.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一些方法，如`self.preprocess_data()`，已被省略以简化内容。你可以在本书的GitHub仓库中找到它们的源代码。
- en: 'Finally, we must build the data loaders that are responsible for passing data
    to models:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们必须构建数据加载器，负责将数据传递给模型：
- en: '[PRE20]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let’s take a closer look at this data module:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看看这个数据模块：
- en: The data preprocessing steps are carried out in the `setup()` method. This includes
    transforming the time series by including the `time_index` and `group_id` variables,
    as well as training, validation, and testing splits. The datasets are structured
    with a `TimeSeriesDataSet` class. Note that we only need to define a `TimeSeriesDataSet`
    instance for one of the datasets. We can use the `from_dataset``()` method to
    set up an existing `TimeSeriesDataSet` instance for another dataset.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据预处理步骤在`setup()`方法中完成。这包括通过包括`time_index`和`group_id`变量来转换时间序列，以及训练、验证和测试拆分。数据集使用`TimeSeriesDataSet`类来构建。请注意，我们只需要为其中一个数据集定义一个`TimeSeriesDataSet`实例。我们可以使用`from_dataset()`方法为另一个数据集设置一个现有的`TimeSeriesDataSet`实例。
- en: The information for the preprocessing steps can be passed in the constructor
    of the `DataModule` class, such as the number of lags (`n_lags`) or forecasting
    `horizon`.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预处理步骤的信息可以通过`DataModule`类的构造函数传递，例如滞后数（`n_lags`）或预测的`horizon`。
- en: The data loaders can be obtained by using the `to_dataloader()` method on the
    respective dataset.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据加载器可以通过在相应的数据集上使用`to_dataloader()`方法获得。
- en: 'Then, we can design the neural network architecture. We will create a class
    named `FeedForwardNet` that implements a feedforward neural network with three
    layers:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以设计神经网络架构。我们将创建一个名为`FeedForwardNet`的类，来实现一个包含三层的前馈神经网络：
- en: '[PRE21]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The network architecture is defined in the `self.net` attribute. The layers
    of the network are stacked on top of each other with the `nn.Sequential` container:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 网络架构在`self.net`属性中定义。网络的各层通过`nn.Sequential`容器堆叠在一起：
- en: The first layer receives the input data with a size of `input_size`. It is a
    linear transformation (`nn.Linear`) that contains `16` units with a `ReLU()` activation
    function (`nn.ReLU`).
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一层接收大小为`input_size`的输入数据。这是一个线性变换（`nn.Linear`），包含`16`个单元，并使用`ReLU()`激活函数（`nn.ReLU`）。
- en: The results are passed into the second layer of the same linear type and activation
    function. This layer contains `8` units.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果会传递到第二层，这一层也是线性变换类型和激活函数。该层包含`8`个单元。
- en: The final layer is also a linear transformation of the inputs coming from the
    previous one. Its size is the same as `output_size`, which in the case of a time
    series refers to the forecasting horizon.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一层也是对来自前一层的输入进行线性变换。其大小与`output_size`相同，在时间序列的情况下，指的是预测的时间跨度。
- en: 'Then, we insert this neural network within a `LightningModule` model class.
    First, let’s look at the class constructor and the `forward``()` method:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将此神经网络插入到`LightningModule`模型类中。首先，让我们看一下类的构造函数和`forward()`方法：
- en: '[PRE22]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The constructor stores the network elements, while the `forward()` method details
    how these elements interact in the forward pass of the network. The `forward()`
    method also transforms the output in the original data scale using the `to_network_output()`
    method. The training step and network optimizer are defined as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 构造函数存储网络元素，而`forward()`方法详细说明了这些元素在网络前向传播中的交互方式。`forward()`方法还使用`to_network_output()`方法将输出转化为原始数据尺度。训练步骤和网络优化器定义如下：
- en: '[PRE23]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The `configure_optimizers()` method is where we set up the optimization process.
    In the training step, we get a batch of samples, pass the input onto the neural
    network, and then compute the mean squared error using the actual data. Then,
    we store the error information in different attributes.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`configure_optimizers()`方法是我们设置优化过程的地方。在训练步骤中，我们获取一批样本，将输入传递给神经网络，然后使用实际数据计算均方误差。然后，我们将误差信息存储在不同的属性中。'
- en: 'The validation and testing steps work similarly to how they do in the training
    phase:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 验证和测试步骤与训练阶段的工作方式类似：
- en: '[PRE24]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'In the prediction step, we simply pass the input data on to the neural network
    and get its output in response:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在预测步骤中，我们只需将输入数据传递给神经网络，然后获取其输出：
- en: '[PRE25]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let’s take a look at the preceding `FeedForwardModel` module:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下前面的`FeedForwardModel`模块：
- en: The neural network based on `PyTorch` is defined in the `self.network` attribute
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于`PyTorch`的神经网络在`self.network`属性中定义
- en: The `forward()` method describes how the neural network processes an instance
    that it gets from a data loader
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`forward()`方法描述了神经网络如何处理从数据加载器获取的实例'
- en: The optimizer is set to `Adam` with a learning rate equal to `0.01`
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化器设置为`Adam`，学习率为`0.01`
- en: 'Finally, we use the `Trainer` class to train the model:'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们使用`Trainer`类来训练模型：
- en: '[PRE26]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The training process runs for `30` epochs. To test the model, we can use the
    `test()` method from the `Trainer` instance:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程运行`30`个周期。为了测试模型，我们可以使用`Trainer`实例中的`test()`方法：
- en: '[PRE27]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Future observations are forecasted by the `predict``()` method. In both cases,
    we pass both the model and the data module to the `Trainer` instance.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 未来的观察结果通过`predict()`方法进行预测。在这两种情况下，我们将模型和数据模块都传递给`Trainer`实例。
- en: How it works…
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The data module encapsulates all the preparation steps. Any specific transformation
    that you need to perform on the dataset can be included in the `setup()` method.
    The logic related to the model is handled in the `LightningModule` instance. Using
    a `DataModule` and `LightningModule` approach provides a modular and tidier way
    of developing deep learning models.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 数据模块封装了所有准备步骤。任何需要在数据集上执行的特定转换都可以包含在`setup()`方法中。与模型相关的逻辑由`LightningModule`实例处理。使用`DataModule`和`LightningModule`方法提供了一种模块化、更整洁的深度学习模型开发方式。
- en: 'The `scalers` argument in the `TimeSeriesDataSet` class is used to pass the
    scaler that should be used to preprocess the explanatory variables of the time
    series. In this case, we used the following:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`TimeSeriesDataSet`类中的`scalers`参数用于传递应该用于预处理时间序列的解释变量的缩放器。在这种情况下，我们使用了以下内容：'
- en: '[PRE28]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Here, we used `StandardScaler` to transform all explanatory variables into a
    common value range. We standardized the target variable of the time series using
    the `self.target_scaler` attribute, which includes a `StandardScaler` operator.
    We normalized the target variable outside of `TimeSeriesDataSet` to give us more
    control over the target variable. This can serve as an example of how to carry
    out transformations that may not be readily available in software packages.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`StandardScaler`将所有解释变量转换为一个共同的数值范围。我们通过`self.target_scaler`属性标准化了时间序列的目标变量，其中包括一个`StandardScaler`操作符。我们在`TimeSeriesDataSet`之外对目标变量进行了归一化，以便对目标变量拥有更多的控制权。这可以作为一个示例，展示如何进行那些在软件包中可能不可用的转换。
- en: There’s more…
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: 'We defined the feedforward neural network using the `nn.Sequential` container.
    Another possible approach is to define each element as its own class attribute
    and call them in the `forward` method explicitly:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`nn.Sequential`容器定义了前馈神经网络。另一种可能的方法是将每个元素定义为自己的类属性，并在`forward`方法中显式调用它们：
- en: '[PRE29]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Both approaches are equivalent. While the first one is tidier, the second one
    is more versatile.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 两种方法是等效的。虽然第一种方法更加整洁，但第二种方法更具灵活性。
- en: LSTM neural networks for multivariate time series forecasting
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用于多变量时间序列预测的LSTM神经网络
- en: In this recipe, we’ll continue the process of building a model to predict the
    next value of solar radiation using multivariate time series. This time, we’ll
    train an LSTM recurrent neural network to solve this task.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将继续构建一个模型，利用多变量时间序列预测太阳辐射的下一个值。这一次，我们将训练一个LSTM递归神经网络来解决这个任务。
- en: Getting ready
  id: totrans-167
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: The data setup is similar to what we did in the previous recipe. So, we’ll use
    the same data module we defined there. Now, let’s learn how to build an LSTM neural
    network with a `LightningModule` class.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 数据设置与我们在前面的食谱中所做的类似。所以，我们将使用之前定义的数据模块。现在，让我们学习如何使用`LightningModule`类构建LSTM神经网络。
- en: How to do it…
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作……
- en: 'The workflow for training an LSTM neural network with PyTorch Lightning is
    similar, with one small but important detail. For LSTM models, we keep the input
    data in a three-dimensional structure with a shape of (number of samples, number
    of lags, number of features). Here’s what the module looks like, starting with
    the constructor and the `forward``()` method:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 使用PyTorch Lightning训练LSTM神经网络的工作流程是相似的，但有一个小而重要的细节。对于LSTM模型，我们将输入数据保持在一个三维结构中，形状为（样本数、滞后数、特征数）。以下是模块的代码，从构造函数和`forward()`方法开始：
- en: '[PRE30]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This time, we don’t have to squeeze the inputs for the network into a two-dimensional
    vector since the LSTM takes a three-dimensional input. The logic behind the LSTM
    is implemented in the `forward()` method. The rest of the methods are identical
    to what we did in the previous recipe. Here’s `training_step` as an example:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，我们不需要将网络的输入压缩成二维向量，因为LSTM接受的是三维输入。LSTM背后的逻辑在`forward()`方法中实现。其余的方法与我们在前面食谱中所做的完全相同。以下是`training_step`的示例：
- en: '[PRE31]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: You can find the remaining methods in this book’s GitHub repository.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在本书的GitHub仓库中找到其余的方法。
- en: 'After defining the model, we can use it as follows:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 定义完模型后，我们可以按如下方式使用它：
- en: '[PRE32]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: As detailed in the preceding code, PyTorch Lightning makes the testing and predicting
    processes identical across models.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的代码所示，PyTorch Lightning使得测试和预测过程在各个模型中保持一致。
- en: How it works…
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: The LSTM is a recurrent neural network architecture that’s designed to model
    sequential data such as time series. This type of network contains a few extra
    elements relative to feedforward neural networks, such as an extra input dimension
    or hidden cell states. In this recipe, we stacked two fully connected layers on
    top of the LSTM layer. LSTM layers are usually passed on to a fully connected
    layer because the output of the former is an internal state. So, the fully connected
    layer processes this output in the particular dimension we need.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM是一种递归神经网络架构，旨在对时间序列等顺序数据进行建模。这类网络相较于前馈神经网络，包含一些额外的元素，如额外的输入维度或隐藏单元状态。在本节中，我们在LSTM层上堆叠了两个全连接层。LSTM层通常会传递给全连接层，因为前者的输出是一个内部状态。因此，全连接层会在我们所需的特定维度上处理该输出。
- en: The class constructor of the LSTM takes four parameters as input – the number
    of variables in the time series (`input_size`), the forecasting horizon (`output_size`),
    the number of `LSTM` layers (`num_layers`), and the number of hidden units in
    each `LSTM` layer (`hidden_size`).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM的类构造函数接收四个输入参数——时间序列中的变量数目（`input_size`）、预测的时间范围（`output_size`）、`LSTM`层的数量（`num_layers`）以及每个`LSTM`层中的隐藏单元数（`hidden_size`）。
- en: We defined three layers in the `__init__` constructor method. Besides the `LSTM`,
    we created two fully connected layers, one of which represents the output layer.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`__init__`构造函数方法中定义了三层。除了`LSTM`外，我们创建了两个全连接层，其中一个代表输出层。
- en: 'The forward pass of the network works like so:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 网络的前向传播如下工作：
- en: Initialize the hidden state (`h0`) and cell state (`c0`) with zeros. This is
    done by calling the `init_hidden_state``()` method.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用零初始化隐藏状态（`h0`）和单元状态（`c0`）。这是通过调用`init_hidden_state()`方法来完成的。
- en: Pass the input data to the LSTM stack. The LSTM returns its output and the hidden
    and cell states of each LSTM layer.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将输入数据传递给LSTM堆栈。LSTM返回它的输出以及每个LSTM层的隐藏状态和单元状态。
- en: Next, we get the hidden state of the last LSTM layer, which is passed onto a
    `ReLU``()` activation function.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们获取最后一个LSTM层的隐藏状态，将其传递给`ReLU()`激活函数。
- en: The results from `ReLU` are passed to the first fully connected layer, whose
    output is, once again, transformed with a `ReLU``()` activation function. Finally,
    the output is passed to a linear, fully connected output layer, which provides
    the forecasts.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ReLU`的输出被传递到第一个全连接层，其输出再次通过`ReLU`函数进行转换。最后，输出被传递到一个线性全连接输出层，该层提供预测结果。'
- en: This logic is coded in the `forward``()` method of the `LightningModule` instance.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 这一逻辑在`LightningModule`实例的`forward()`方法中进行了编写。
- en: There’s more…
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容……
- en: We created a deep neural network with a single LSTM layer (`num_layers=1`).
    However, we could increase this value according to our needs. A model with more
    than one LSTM layer is referred to as a **stacked** **LSTM** model.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个具有单个LSTM层的深度神经网络（`num_layers=1`）。然而，我们可以根据需要增加该值。具有多个LSTM层的模型被称为**堆叠**
    **LSTM**模型。
- en: Monitoring the training process using Tensorboard
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Tensorboard监控训练过程
- en: Training deep learning models often involves tuning numerous hyperparameters,
    assessing different architectures, and more. To facilitate these tasks, visualization
    and monitoring tools are essential. `tensorboard` is a powerful tool for tracking
    and visualizing various metrics during the training process. In this section,
    we will guide you through integrating `tensorboard` with PyTorch Lightning for
    monitoring the training process.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 训练深度学习模型通常需要调整多个超参数、评估不同的架构等。为了便于这些任务，必须使用可视化和监控工具。`tensorboard`是一个强大的工具，可以在训练过程中追踪和可视化各种指标。本节将指导你如何将`tensorboard`与PyTorch
    Lightning集成，用于监控训练过程。
- en: Getting ready
  id: totrans-192
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Before using `tensorboard` with PyTorch Lightning, you’ll need to have `tensorboard`
    installed. You can install it using the following command:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`tensorboard`与PyTorch Lightning之前，你需要先安装`tensorboard`。你可以使用以下命令进行安装：
- en: '[PRE33]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Once installed, make sure that you are utilizing PyTorch Lightning’s built-in
    `tensorboard` logging capabilities.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，确保你正在利用PyTorch Lightning内置的`tensorboard`日志记录功能。
- en: How to do it…
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现……
- en: 'Here’s how to use `tensorboard` to monitor the training process:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何使用`tensorboard`来监控训练过程：
- en: First, ensure that `tensorboard` is imported into your script.
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，确保`tensorboard`已导入到你的脚本中。
- en: 'Next, you’ll need to create a `tensorboard` logger and pass it to PyTorch Lightning’s
    `Trainer`:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你需要创建一个`tensorboard`日志记录器，并将其传递给PyTorch Lightning的`Trainer`：
- en: '[PRE34]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'You can then start `tensorboard` by running the following command in your terminal:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，你可以通过在终端运行以下命令来启动`tensorboard`：
- en: '[PRE35]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Open `tensorboard` in your web browser by navigating to the URL displayed in
    your terminal; usually, this is `http://localhost:6006`. You’ll see real-time
    updates on various metrics, such as the number of epochs, the train, validation,
    and test loss, and more.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的网页浏览器中打开`tensorboard`，通过访问终端中显示的URL；通常是`http://localhost:6006`。你将看到实时更新的各种指标，例如周期数、训练、验证和测试损失等。
- en: 'The following figure shows some plots of the LSTM’s performance from the previous
    recipe. In this case, we can see how the number of epochs, as well as training
    and validation losses, are evolving:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了上一章节中LSTM性能的一些图示。在此案例中，我们可以看到周期数以及训练和验证损失是如何变化的：
- en: '![Figure 4.2: Comparison of epochs, training loss, and validation loss](img/B21145_04_002.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图4.2：周期、训练损失和验证损失的比较](img/B21145_04_002.jpg)'
- en: 'Figure 4.2: Comparison of epochs, training loss, and validation loss'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2：周期、训练损失和验证损失的比较
- en: How it works…
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: '`tensorboard` provides visualizations for various training metrics, hyperparameter
    tuning, model graphs, and more. When integrated with PyTorch Lightning, the following
    occurs:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '`tensorboard`提供了各种训练指标、超参数调优、模型图形等的可视化。当与PyTorch Lightning集成时，以下内容会发生：'
- en: The logger sends the specified metrics to `tensorboard` during training
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在训练过程中，日志记录器将指定的指标发送到`tensorboard`
- en: '`tensorboard` reads the logs and provides interactive visualizations'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tensorboard`读取日志并提供交互式可视化'
- en: Users can monitor various aspects of training in real time
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户可以实时监控训练的各个方面
- en: There’s more…
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: 'Here are some additional details to keep in mind:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些需要注意的额外细节：
- en: You can log additional information such as images, text, histograms, and more
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以记录其他信息，例如图像、文本、直方图等
- en: By exploring different visualizations, you can gain insights into how your model
    is performing and make necessary adjustments
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过探索不同的可视化内容，你可以深入了解模型的表现，并进行必要的调整
- en: Tensorboard’s integration with PyTorch Lightning streamlines the monitoring
    process, enabling more efficient model development
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tensorboard与PyTorch Lightning的集成简化了监控过程，使得模型开发更加高效
- en: Using `tensorboard` with PyTorch Lightning offers a robust solution for monitoring
    and visualizing the training process, allowing for more informed decision-making
    in model development.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`tensorboard`与PyTorch Lightning提供了一个强大的解决方案，用于监控和可视化训练过程，使得在模型开发中可以做出更明智的决策。
- en: Evaluating deep neural networks for forecasting
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估用于预测的深度神经网络
- en: Evaluating the performance of forecasting models is essential to understand
    how well they generalize to unseen data. Popular metrics include the **Root Mean
    Squared Error** (**RMSE**), **Mean Absolute Percentage Error** (**MAPE**), **Mean
    Absolute Scaled Error** (**MASE**), and **Symmetric Mean Absolute Percentage Error**
    (**SMAPE**), among others. We will implement these metrics in Python and show
    you how they can be applied to evaluate our model’s performance.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 评估预测模型的表现对于理解它们如何对未见数据进行泛化至关重要。常用的评估指标包括**均方根误差**（**RMSE**）、**平均绝对百分比误差**（**MAPE**）、**平均绝对缩放误差**（**MASE**）和**对称平均绝对百分比误差**（**SMAPE**）等。我们将使用Python实现这些指标，并向您展示如何应用它们来评估模型的表现。
- en: Getting ready
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备好了吗
- en: We need predictions from our trained model and the corresponding ground truth
    values to calculate these metrics. Therefore, we must run our model on the test
    set first to obtain the predictions.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要来自训练模型的预测值和相应的真实值，以计算这些指标。因此，我们必须先在测试集上运行我们的模型，以获取预测结果。
- en: 'To simplify the implementation, we will use the `scikit-learn` and `sktime`
    libraries since they have useful classes and methods to help us with this task.
    Since we have not installed `sktime` yet, let’s run the following command:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化实现，我们将使用`scikit-learn`和`sktime`库，因为它们提供了有用的类和方法来帮助我们完成这个任务。由于我们还没有安装`sktime`，请运行以下命令：
- en: '[PRE36]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now, it is time to import the classes and methods for the different evaluation
    metrics:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候导入用于不同评估指标的类和方法了：
- en: '[PRE37]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: How to do it…
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何实现…
- en: To evaluate the performance of our model, we must calculate the `scikit-learn`
    library. For `sktime` library, which offers readily available functions for these
    metrics.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估我们的模型表现，我们必须计算`scikit-learn`库中的相关指标。对于`sktime`库，它提供了现成可用的函数来计算这些指标。
- en: 'Here’s the code detailing how to calculate these metrics:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是计算这些指标的代码：
- en: '[PRE38]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: How it works…
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: 'These metrics each evaluate different aspects of the model’s performance:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标各自评估模型表现的不同方面：
- en: '**RMSE**: This metric calculates the square root of the average squared differences
    between the predicted and actual values. It gives a higher penalty for large errors.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RMSE**：该指标计算预测值与实际值之间的平均平方差的平方根。它对较大误差给予更高的惩罚。'
- en: '`1` indicating performance equal to the naive forecast and a MASE value less
    than `1` indicating better performance than the naive forecast.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1`表示与朴素预测相等的表现，而MASE值小于`1`则表示模型表现优于朴素预测。'
- en: '**MAPE**: This metric computes the mean of the absolute percentage difference
    between the actual and predicted values. It expresses the average absolute error
    in terms of percentage, which can be useful when you want to understand the relative
    prediction error.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MAPE**：该指标计算实际值与预测值之间绝对百分比差异的平均值。它以百分比的形式表达平均绝对误差，这在您想了解相对预测误差时非常有用。'
- en: '**SMAPE**: This metric computes the average absolute percentage error, treating
    under and over-forecasts equally. It expresses the error as a percentage of the
    actual values, which can be useful for comparing models and predicting different
    scales.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SMAPE**：该指标计算平均绝对百分比误差，处理低估和高估的误差时给予同等的权重。它将误差表示为实际值的百分比，这对于比较模型和预测不同规模的数据非常有用。'
- en: There’s more…
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: Remember, the choice of evaluation metric depends on the specific problem and
    business requirements. For example, if it is more costly to have a model that
    under-predicts than over-predicts, a metric that treats these two types of errors
    differently may be more appropriate. Other metrics, such as MAE, can also be used,
    depending on the problem. Evaluating a model using multiple metrics is always
    a good idea to gain a more comprehensive understanding of its performance.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，评估指标的选择取决于具体问题和业务需求。例如，如果低估模型的成本高于高估模型的成本，那么一个区分这两种误差类型的指标可能更合适。根据问题的不同，其他指标，如MAE，也可以使用。使用多种指标评估模型始终是个好主意，这样可以更全面地了解模型的表现。
- en: Using callbacks – EarlyStopping
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用回调——EarlyStopping
- en: Callbacks in PyTorch Lightning are reusable components that allow you to inject
    custom behavior into various stages of the training, validation, and testing loops.
    They offer a way to encapsulate functionalities separate from the main training
    logic, providing a modular and extensible approach to manage auxiliary tasks such
    as logging metrics, saving checkpoints, early stopping, and more.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在PyTorch Lightning中，回调是可重用的组件，允许你在训练、验证和测试的各个阶段注入自定义行为。它们提供了一种将功能与主训练逻辑分离的方式，提供了一个模块化和可扩展的方法来管理辅助任务，例如记录指标、保存检查点、早停等。
- en: By defining a custom class that inherits from PyTorch Lightning’s base `Callback`
    class, you can override specific methods corresponding to different points in
    the training process, such as `on_epoch_start` or `on_batch_end`. When a trainer
    is initialized with one or more of these callback objects, the defined behavior
    is automatically executed at the corresponding stage of the training process.
    This makes callbacks powerful tools for organizing the training pipeline, adding
    flexibility without cluttering the main training code.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 通过定义一个自定义类继承自PyTorch Lightning的基础`Callback`类，你可以重写与训练过程中的不同阶段相对应的特定方法，例如`on_epoch_start`或`on_batch_end`。当训练器初始化时，如果传入一个或多个这些回调对象，定义的行为将自动在训练过程中的相应阶段执行。这使得回调成为组织训练管道的强大工具，能够增加灵活性而不使主训练代码变得混乱。
- en: Getting ready
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: After defining and training the LSTM model, as described in the previous section,
    we can further enhance the training process by incorporating a technique called
    early stopping. This is used to avoid overfitting by halting the training process
    when a specified metric stops improving. For this purpose, PyTorch Lightning provides
    an early stopping callback, which we’ll be integrating into our existing training
    code.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义并训练LSTM模型后，如上一节所述，我们可以通过引入早停技术进一步增强训练过程。该技术通过在指定的指标停止改进时暂停训练过程来避免过拟合。为此，PyTorch
    Lightning提供了一个早停回调，我们将把它集成到现有的训练代码中。
- en: How to do it…
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'To apply early stopping, we’ll need to modify our existing PyTorch Lightning
    `Trainer` by adding the `EarlyStopping` callback. Here’s the code to do so:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 要应用早停，我们需要通过添加`EarlyStopping`回调来修改现有的PyTorch Lightning `Trainer`。下面是实现该功能的代码：
- en: '[PRE39]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: In this code snippet, `monitor` is set to the validation loss (`val_loss`),
    and the training process will stop if this value does not decrease by at least
    `min_delta` for `patience` consecutive validation epochs.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，`monitor`设置为验证损失（`val_loss`），如果该值在`patience`连续的验证周期中没有至少减少`min_delta`，训练过程将停止。
- en: How it works…
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Early stopping is a regularization technique that prevents overfitting in neural
    networks. It monitors a specified metric (in this case, the validation loss) and
    halts the training process when this metric stops improving.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 早停是一种正则化技术，可以防止神经网络的过拟合。它监控一个指定的指标（在这里是验证损失），并在该指标停止改进时暂停训练过程。
- en: 'Here’s how it works in our LSTM model:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在我们LSTM模型中的工作方式：
- en: '`val_loss`) during the validation phase.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`val_loss`）在验证阶段。'
- en: '`min_delta` for `patience` consecutive epochs, the training process is halted.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于`patience`连续的训练周期，若`min_delta`未达到要求，训练过程将被暂停。
- en: '`mode` parameter can be set to `min` or `max`, indicating whether the monitored
    metric should be minimized or maximized. In our case, we want to minimize the
    validation loss.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mode`参数可以设置为`min`或`max`，表示被监控的指标应该最小化还是最大化。在我们的案例中，我们希望最小化验证损失。'
- en: By stopping the training process early, we can save time and resources, and
    also potentially obtain a model that generalizes better to unseen data.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 通过提前停止训练过程，我们可以节省时间和资源，并且可能获得一个在未见数据上泛化更好的模型。
- en: There’s more…
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: 'Let’s look at some further details:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些进一步的细节：
- en: The early stopping callback is highly configurable, allowing you to tailor its
    behavior to specific requirements – for example, you can change the `patience`
    parameter to make the stopping criterion more or less strict
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 早停回调（early stopping callback）是高度可配置的，允许你根据特定需求调整其行为——例如，你可以更改`patience`参数，使得停止标准更加严格或宽松。
- en: Early stopping can be combined with other callbacks and techniques, such as
    model checkpointing, to create a robust and efficient training pipeline
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 早停可以与其他回调和技术结合使用，例如模型检查点（model checkpointing），以创建一个强大而高效的训练管道。
- en: Utilizing early stopping appropriately can lead to models that perform better
    on unseen data as it prevents them from fitting too closely to the training data
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适当地使用早停可以使模型在未见数据上表现更好，因为它能防止模型过拟合训练数据。
- en: This `EarlyStopping` callback integrates seamlessly with PyTorch Lightning and
    our existing LSTM model, demonstrating the extensibility and ease of use of PyTorch
    Lightning’s callback system.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`EarlyStopping`回调与PyTorch Lightning以及我们现有的LSTM模型完美集成，展示了PyTorch Lightning回调系统的可扩展性和易用性。
