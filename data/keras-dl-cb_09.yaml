- en: Research in Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络研究
- en: 'In this chapter, we will look at some of the active research areas in neural
    networks. The following problems are analyzed from basic research areas to complex
    real-life problems:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看看神经网络中的一些活跃研究领域。以下问题从基础研究领域到复杂的现实问题进行了分析：
- en: Overfitting in neural networks
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 神经网络中的过拟合
- en: Large-scale video processing with a neural network
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用神经网络进行大规模视频处理
- en: Named entity recognition using a twisted neural network
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用扭曲神经网络进行命名实体识别
- en: Bidirectional recurrent neural networks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 双向递归神经网络
- en: Avoiding overfitting in neural networks
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免神经网络中的过拟合
- en: Let's understand the constituents of overfitting and how to avoid it in neural
    networks. Nitesh Srivastava, Geoffrey Hinton, et al. published a paper, [https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf),
    in 2014, which shows cases on how to avoid overfitting.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们理解过拟合的构成因素，以及如何在神经网络中避免它。Nitesh Srivastava、Geoffrey Hinton等人于2014年发布了一篇论文，[https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)，该论文展示了如何避免过拟合的案例。
- en: Problem statement
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题陈述
- en: Deep neural networks contain nonlinear hidden layers, and this makes them expressive
    models that can learn very complicated relationships between inputs and outputs.
    However, these complicated relationships will be the result of sampling noise.
    These complicated relationships might not exist in test data, leading to overfitting.
    Many techniques and methods have been developed to reduce this noise. These include
    stopping the training as soon as performance on a validation set starts getting
    worse, introducing weight penalties such as L1 and L2 regularization, and soft
    weight sharing (Nowlan and Hinton, 1992).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 深度神经网络包含非线性隐藏层，这使它们成为可以学习输入和输出之间非常复杂关系的表达性模型。然而，这些复杂的关系将是采样噪声的结果。这些复杂的关系可能在测试数据中不存在，从而导致过拟合。为减少这种噪声，已经开发了许多技术和方法。包括在验证集上的性能开始变差时立即停止训练，引入L1和L2正则化等权重惩罚，以及软权重共享（Nowlan和Hinton，1992）。
- en: Solution
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案
- en: Dropout is a technique that addresses performance issues of some of the other
    techniques such as averaging across multiple models. It also prevents overfitting
    and provides a way to combine exponentially many different neural network architectures
    efficiently. The term dropout means dropping out units (hidden and visible) in
    a neural network. By dropping a unit out, it means removing it from the network
    and its incoming and outgoing connections, as shown in the following figure.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout是一种解决一些其他技术性能问题的技术，例如在多个模型之间进行平均。它还防止了过拟合，并提供了一种有效地组合大量不同神经网络架构的方法。Dropout一词意味着在神经网络中删除单元（隐藏和可见）。通过删除一个单元，意味着将其从网络及其输入和输出连接中移除，如下图所示。
- en: The choice of which units to be dropped is usually random. In a simple case,
    each unit is retained with a probability p independent of other units. The technique
    to choose p can be a validation set or can be set at 0.5; this value is close
    to optimal for a wide range of networks and tasks.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 删除哪些单元的选择通常是随机的。在简单的情况下，每个单元以独立于其他单元的概率p保留。选择p的技巧可以是验证集，也可以设置为0.5；这个值对于广泛的网络和任务来说接近最优。
- en: For the input units, however, the optimal probability of retention is usually
    closer to 1 than to 0.5.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于输入单元，保留的最优概率通常更接近1而非0.5。
- en: '![](img/a1c5b947-8244-4601-9ba1-2c34e27a6638.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1c5b947-8244-4601-9ba1-2c34e27a6638.png)'
- en: 'Dropout neural net model:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout神经网络模型：
- en: A standard neural network with two hidden layers
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个标准的具有两个隐藏层的神经网络
- en: A thinned neural net produced by applying dropout to the network on the left;
    crossed units have been dropped
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个应用dropout后产生的稀疏神经网络，左侧的网络中已删除的单元用交叉标记表示
- en: Example of how Dropout can be applied in TensorFlow
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow中如何应用Dropout的示例
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'As can be seen above a Dropout of 0.5 is applied to the `LSTMCell`, where `output_keep_prob`:
    unit Tensor or float between 0 and 1, output keep probability; if it is constant
    and 1, no output dropout will be added.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，0.5的Dropout已应用于`LSTMCell`，其中`output_keep_prob`：单位张量或介于0和1之间的浮动值，表示输出保持的概率；如果它是常数且为1，则不会添加输出dropout。
- en: Results
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: 'Let''s look at how the dropout strategy affects the accuracy of the model:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看dropout策略如何影响模型的准确性：
- en: '![](img/3933cd47-acda-4760-89ac-019dfaf1d9c8.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3933cd47-acda-4760-89ac-019dfaf1d9c8.png)'
- en: As can be seen, the classification error decreases significantly with dropout.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，分类误差在使用dropout后显著下降。
- en: Large-scale video processing with neural networks
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用神经网络进行大规模视频处理
- en: In this paper, [https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf),
    the authors explore how CNNs could be used for large-scale video classification.
    In this use case, the neural networks have access to not only the appearance information
    in single, static images, but also the complex temporal evolution of the image.
    There are several challenges in extending and applying CNNs in this setting.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，[https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf)，作者探讨了卷积神经网络（CNN）如何应用于大规模视频分类。在这种应用场景中，神经网络不仅可以访问单一静态图像中的外观信息，还能处理图像的复杂时间演化。将CNN应用于这一领域面临着一些挑战。
- en: There are very few (or none) video classification benchmarks that match the
    scale and variety of existing image datasets as videos are significantly more
    challenging to collect, annotate, and store. To obtain sufficient amount of data
    needed to train our CNN architectures, authors collected a new Sports-1M dataset.
    This dataset contains 1 million videos (from YouTube) belonging to a taxonomy
    of 487 classes of sports. Sports-1M is also available to the research community
    to support future work in this area.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 很少有（或者根本没有）视频分类基准能够匹配现有图像数据集的规模和多样性，因为视频数据集比图像数据集更难以收集、注释和存储。为了获得足够的数据以训练我们的CNN架构，作者收集了一个新的Sports-1M数据集。该数据集包含来自YouTube的100万个视频，属于487个体育类别的分类体系。Sports-1M数据集也对研究界开放，以支持该领域未来的研究工作。
- en: In this work, the authors treat every video as a bag of short, fixed-sized clips.
    Each clip contains several contiguous frames in time, hence the connectivity of
    the network can be extended in a time dimension to learning spatio-temporal features.
    The authors describe three broad connectivity pattern categories (**Early Fusion**,
    **Late Fusion**, and **Slow Fusion**). Afterward, we will look at a multiresolution
    architecture to address the computational efficiency.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项工作中，作者将每个视频视为一个由多个短小的固定大小片段组成的袋子。每个片段包含几个时间上连续的帧，因此网络的连接性可以在时间维度上扩展，以学习时空特征。作者描述了三种广泛的连接模式类别（**早期融合**、**晚期融合**和**慢融合**）。之后，我们将探讨一种多分辨率架构，以提高计算效率。
- en: 'The following figure explains various techniques for fusion:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 下图解释了各种融合技术：
- en: '![](img/529a83c9-f956-4c19-905b-cacb2c394ba2.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/529a83c9-f956-4c19-905b-cacb2c394ba2.png)'
- en: Various fusion techniques to combine frames separated by time
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 各种融合技术用于组合时间上分离的帧
- en: Resolution improvements
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分辨率改进
- en: 'The authors used a multiresolution architecture that aimed to strike a compromise
    by having two separate streams of processing (called Fovea and Context Streams)
    over two spatial resolutions (see the following figure). A 178 × 178 frame video
    clip is the input to the network:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用了一个多分辨率架构，旨在通过在两个空间分辨率上分别处理两条流（称为视网膜流和上下文流）来实现妥协（参见下图）。178 × 178帧的视频片段作为网络的输入：
- en: '![](img/a7822995-bf74-4bbe-8995-a213dd0c66f6.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a7822995-bf74-4bbe-8995-a213dd0c66f6.png)'
- en: Multiresolution CNN
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 多分辨率卷积神经网络（CNN）
- en: The **context stream** receives the downsampled frames at half the original
    spatial resolution (89 × 89 pixels). The **fovea stream** receives the center
    89 × 89 region at the original resolution. In this way, the total input dimensionality
    is halved.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**上下文流**接收下采样后的帧，分辨率为原始空间分辨率的一半（89 × 89像素）。**视网膜流**接收中心89 × 89区域，分辨率保持原始分辨率。通过这种方式，总输入维度被减半。'
- en: Feature histogram baselines
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征直方图基准
- en: In addition to comparing CNN architectures with each other, the authors also
    report the accuracy of a feature-based approach. A standard bag-of-words pipeline
    was used to extract several types of features at all frames of the videos, followed
    by discretizing them using k-means vector quantization and accumulating words
    into histograms with spatial pyramid encoding and soft quantization.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 除了比较不同CNN架构之间的差异外，作者还报告了基于特征的方法的准确性。使用标准的词袋管道在视频的所有帧上提取了几种类型的特征，随后通过k-means向量量化对其进行离散化，并通过空间金字塔编码和软量化将词语累积成直方图。
- en: Quantitative results
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定量结果
- en: 'Sports-1M dataset test set results (200,000 videos and 4,000,000 clips) are
    summarized in the following table. The approach of multiple networks consistently
    and significantly outperforms the feature-based baseline. The feature-based approach
    computes visual words densely over the duration of the video and produces predictions
    that are based on the complete video-level feature vector, while the authors''
    networks only see 20 randomly sampled clips individually:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Sports-1M数据集测试集结果（200,000个视频和4,000,000个片段）总结如下表。多网络方法始终显著超越基于特征的基线方法。基于特征的方法在视频的持续时间内密集计算视觉词，并生成基于完整视频级特征向量的预测，而作者的网络仅单独查看20个随机采样的片段：
- en: '![](img/4133e9d9-37f1-44fd-826e-a4e6890ac9d2.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4133e9d9-37f1-44fd-826e-a4e6890ac9d2.png)'
- en: Results on the 200,000 videos of the Sports-1M test set. Hit@k values indicate
    the fraction of test samples that
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在Sports-1M测试集的200,000个视频上的结果。Hit@k值表示测试样本中
- en: contained at least one of the ground truth labels in the top k predictions.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 至少包含了前k个预测中的一个真实标签。
- en: The approach taken with network topology learns well despite label noise; the
    training videos are subject to some incorrect annotations and even the correctly-labeled
    videos often contain a large amount of artifacts such as text, effects, cuts,
    and logos, none of which we attempted to filter out explicitly.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 网络拓扑采用的方法尽管存在标签噪声，依然能够良好地学习；训练视频可能会出现一些错误注释，即使是正确标注的视频，也往往包含大量伪影，如文本、特效、剪辑和徽标，而我们并没有专门尝试过滤这些内容。
- en: Named entity recognition using a twisted neural network
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用扭曲神经网络的命名实体识别
- en: In this paper, [http://www.cs.cmu.edu/~leili/pubs/lu-baylearn2015-twinet.pdf,](http://www.cs.cmu.edu/~leili/pubs/lu-baylearn2015-twinet.pdf) the
    authors look at the problem of recognizing entities in natural language. This
    is often the first step in question answering, conversations, and a host of other
    NLP use cases. For a sequence of text tokens, a named entity recognizer identifies
    chunks of tokens that belong to a predefined category of persons and organizations.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，[http://www.cs.cmu.edu/~leili/pubs/lu-baylearn2015-twinet.pdf,](http://www.cs.cmu.edu/~leili/pubs/lu-baylearn2015-twinet.pdf)
    作者探讨了在自然语言中识别实体的问题。这通常是问答、对话及其他多个NLP用例的第一步。对于一段文本序列，命名实体识别器识别出属于预定义类别的实体，如人物和组织。
- en: Example of a named entity recognition
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命名实体识别示例
- en: IOB  tagging system is one of the convention for NER.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: IOB标记系统是命名实体识别的一种标准。
- en: 'The **IOB Tagging** system contains tags of the form:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**IOB标记** 系统包含如下格式的标签：'
- en: '`B-{CHUNK_TYPE}`: for the word in the **B**eginning chunk'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`B-{CHUNK_TYPE}`：表示**B**eginning块中的词'
- en: '`I-{CHUNK_TYPE}`: for words **I**nside the chunk'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`I-{CHUNK_TYPE}`: 用于块内部的词**I**nside'
- en: '`O`: **O**utside any chunk'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`O`：**O**utside任何块'
- en: '`B-PERSON` : Person Entity'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`B-PERSON` : 人物实体'
- en: '`B-GPE` : Geopolitical Entity'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`B-GPE` : 地缘政治实体'
- en: 'Th following text shows example of a names entities in a sentence:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下文本展示了句子中命名实体的示例：
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'However, it is quite challenging due to two reasons:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这个问题具有相当大的挑战，原因有二：
- en: Entity databases are often incomplete (given the number of new organizations
    being established)
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实体数据库往往不完整（考虑到新组织的不断成立）。
- en: The same phrase can refer to a different entity (or none entity) depending on
    the context
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相同的短语可以根据上下文指代不同的实体（或没有实体）。
- en: Defining Twinet
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义Twinet
- en: 'Twisting RNNs (Twinet) use two parallel branches. Each branch is composed of
    a recurrent network layer, a nonlinear perceptron layer, and a reversed recurrent
    network layer. Branches are *twisted*: the order of the layers is reversed in
    the second branch. The output of all the recurrent layers is collected toward
    the end.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 扭曲的RNN（Twinet）使用两个并行分支。每个分支由一个递归网络层、一个非线性感知器层和一个反向递归网络层组成。分支是*扭曲的*：第二个分支中层的顺序被反转。所有递归层的输出在最后集中。
- en: 'To recap, a **recurrent neural network** (**RNN**) takes a sequence of input
    vectors *x1..T*, and recurrently computes hidden states (also called **output
    labels**):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，**递归神经网络**（**RNN**）接受一系列输入向量 *x1..T*，并递归地计算隐藏状态（也称为**输出标签**）：
- en: '*h[t] = σ(U · x[t] + W · ht−1)*'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '*h[t] = σ(U · x[t] + W · ht−1)*'
- en: where,
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，
- en: '*t* is 1..T'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*t* 是 1..T'
- en: '*x[t]* is the external signal'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x[t]* 是外部信号'
- en: '*W* are the weights'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*W* 是权重'
- en: '*h[t-1]* is the hidden layer weights for time step *t-1*'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*h[t-1]* 是时间步 *t-1* 的隐藏层权重。'
- en: '*h[t]* weights being calculated for time step *t*'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*h[t]* 为时间步 *t* 计算的权重'
- en: '*U* is tan*h* layer which helps in creating weights for time step *t*'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*U* 是tan*h*层，用于为时间步 *t* 创建权重。'
- en: '*σ(·)* is a nonlinear activation function. In the experiments that the authors
    used, we used **rectified linear units** (**RELU**).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*σ(·)* 是一种非线性激活函数。在作者使用的实验中，我们使用了**修正线性单元**（**RELU**）。'
- en: Results
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: Twinet was compared to Stanford NER and Illinois NER and the results were quite
    favorable. Here  NER stands for60; (**Named Entity Recognizer**).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Twinet与斯坦福NER和伊利诺伊NER进行了比较，结果相当有利。此处NER代表**命名实体识别器**（Named Entity Recognizer）。
- en: '![](img/e70dfc38-aaec-400c-bd50-ceeb3c45a3c7.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e70dfc38-aaec-400c-bd50-ceeb3c45a3c7.png)'
- en: As can be seen from the preceding figure, the Precision-Recall as well as the
    F1 scores are all higher.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图中可以看出，精确度-召回率（Precision-Recall）以及F1分数都更高。
- en: Bidirectional RNNs
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 双向循环神经网络（Bidirectional RNNs）
- en: In this section, we will look at a new neural network topology that is gaining
    momentum in the area of NLP.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍一种在自然语言处理（NLP）领域越来越受到关注的新型神经网络拓扑结构。
- en: Schuster and Paliwal have introduced **Bidirectional Recurrent Neural Networks**
    (**BRNN**) in 1997\. BRNNs help increase the amount of input information available
    to the network. **Multilayer perceptrons** (**MLPs**) and **time delay neural
    networks** (**TDNNs**) are known to have limitations on the input data flexibility.
    RNNs also require their input data to be fixed. More advanced topologies like
    RNNs also have restrictions as the future input information cannot be predicted
    from the current state. BRNNs, on the contrary, do not need their input data to
    be fixed. Their future input information is reachable from the current state.
    The idea of BRNNs is to connect two hidden layers of opposite directions to the
    same output. With this structure, the output layer is able to get information
    from past and future states.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Schuster和Paliwal在1997年提出了**双向递归神经网络**（**BRNN**）。BRNN有助于增加可供网络使用的输入信息量。**多层感知器**（**MLPs**）和**时间延迟神经网络**（**TDNNs**）被认为在输入数据灵活性方面存在局限性。RNN也要求其输入数据是固定的。更先进的拓扑结构如RNN也有其限制，因为无法从当前状态预测未来的输入信息。相反，BRNN不需要其输入数据是固定的，其未来的输入信息可以从当前状态中获取。BRNN的基本思想是将两个相反方向的隐藏层连接到相同的输出层。通过这种结构，输出层可以同时获取来自过去和未来状态的信息。
- en: BRNNs are useful when the context of the input is needed. As an example, in
    handwriting recognition, the performance can be enhanced by knowledge of the letters
    located before and after the current letter.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当输入的上下文信息非常重要时，BRNN非常有用。例如，在手写识别中，通过了解当前字母前后的位置字母，可以提高识别性能。
- en: '![](img/807e2fd3-ea0e-4cc3-9554-d7dd4e059fa5.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/807e2fd3-ea0e-4cc3-9554-d7dd4e059fa5.png)'
- en: This depicts a Bidirectional RNN
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这图展示的是双向循环神经网络（Bidirectional RNN）
- en: BRNN on TIMIT dataset
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TIMIT数据集上的BRNN
- en: In this section, we will look at how a BRNN provides higher accuracy results
    on the TIMIT Dataset for phoneme text classification.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨双向RNN（BRNN）如何在TIMIT数据集上为音素文本分类提供更高的准确度。
- en: 'TIMIT is a corpus of phonemically and lexically transcribed speeches of American
    English speakers of different sexes and dialects. Each transcribed element has
    been delineated in time. TIMIT was designed to further acoustic-phonetic knowledge
    and automatic speech recognition systems:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: TIMIT是一个包含美国英语发音者不同性别和方言的音素及词汇转录语音的语料库。每个转录元素都已标注时间。TIMIT旨在推动声学-语音学知识和自动语音识别系统的发展：
- en: '![](img/037a0b0a-62a7-4c7a-a18b-d76acaec0920.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/037a0b0a-62a7-4c7a-a18b-d76acaec0920.png)'
- en: As can be seen from the preceding figure, the BRNN gives higher percent frames
    accurately as compared to MLP, both for the training set and testing set. BLSTM
    gives even higher accuracy.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图中可以看出，BRNN比MLP在训练集和测试集上的准确度更高，能够正确识别更多的帧。BLSTM的准确度更高。
- en: Summary
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we addressed some of the areas where research has been done
    on improving accuracy and avoiding overfitting. We also looked at some of the
    newer areas such as video classification. While it is outside the scope of this
    book to cover all the research areas in detail, we sincerely advise you to explore
    the research websites of Google, Facebook, and Baidu, in addition to Tier 1 ACM
    and IEEE conferences, to skim through new research being done.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了一些已经进行研究以提高准确性并避免过拟合的领域。我们还探讨了一些新的领域，如视频分类。尽管本书的范围不涵盖所有研究领域的详细内容，但我们真诚建议你浏览谷歌、Facebook和百度的研究网站，此外，还可以浏览顶级的ACM和IEEE会议，以便了解最新的研究进展。
