- en: Chapter 2. Classifying Handwritten Digits with a Feedforward Network
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章。使用前馈网络分类手写数字
- en: The first chapter presented Theano as a compute engine, with its different functions
    and specificities. With this knowledge, we'll go through an example and introduce
    some of the main concepts of deep learning, building three neural networks and
    training them on the problem of handwritten digit classification.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 第一章介绍了 Theano 作为一个计算引擎，以及它的不同功能和特点。有了这些知识，我们将通过一个例子来介绍深度学习的一些主要概念，并构建三个神经网络，对手写数字分类问题进行训练。
- en: 'Deep learning is a field of machine learning in which layers of modules are
    stacked on top of each of other: this chapter introduces a simple single-linear-layer
    model, then adds a second layer on top of it to create a **multi-layer perceptron**
    (**MLP**), and last uses multiple convolutional layers to create a **Convolutional
    Neural Network** (**CNN**).'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个领域，其中模块层被堆叠在彼此之上：本章介绍了一个简单的单线性层模型，然后在其上添加第二层来创建**多层感知器**（**MLP**），最后使用多个卷积层来创建**卷积神经网络**（**CNN**）。
- en: 'In the meantime, this chapter recaps the basic machine learning concepts, such
    as overfitting, validation, and loss analysis, for those who are not familiar
    with data science:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，本章还为不熟悉数据科学的人回顾了基本的机器学习概念，如过拟合、验证和损失分析：
- en: Small image classification
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小型图像分类
- en: Handwritten digit recognition challenge
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手写数字识别挑战
- en: Layer design to build a neural network
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 层设计以构建神经网络
- en: Design of a classical objective/loss function
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计经典目标/损失函数
- en: Back-propagation with stochastic gradient descent
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用随机梯度下降的反向传播
- en: Training on a dataset with validation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在验证集上训练数据集
- en: Convolutional neural networks
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络
- en: Towards state-of-art results for digit classification
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朝向手写数字分类的最新结果
- en: The MNIST dataset
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MNIST 数据集
- en: The **Modified National Institute of Standards and Technology** (**MNIST**)
    **dataset** is a very well-known dataset of handwritten digits {0,1,2,3,4,5,6,7,8,9}
    used to train and test classification models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**修改后的国家标准技术研究所**（**MNIST**）**数据集**是一个非常著名的手写数字数据集 {0,1,2,3,4,5,6,7,8,9}，用于训练和测试分类模型。'
- en: A classification model is a model that predicts the probabilities of observing
    a class, given an input.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 分类模型是一个根据输入预测类别观察概率的模型。
- en: Training is the task of *learning* the parameters to fit the model to the data
    as well as we can so that for any input image, the correct label is predicted.
    For this training task, the MNIST dataset contains 60,000 images with a target
    label (a number between 0 and 9) for each example.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 训练是*学习*参数，使模型尽可能适合数据，以便对于任何输入图像，都能预测出正确的标签。对于此训练任务，MNIST 数据集包含 60,000 个图像，每个示例有一个目标标签（介于0和9之间的数字）。
- en: 'To validate that the training is efficient and to decide when to stop the training,
    we usually split the training dataset into two datasets: 80% to 90% of the images
    are used for training, while the remaining 10-20% of images will not be presented
    to the algorithm for training but to validate that the model generalizes well
    on unobserved data.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证训练效果并决定何时停止训练，通常将训练数据集分成两个数据集：80%到90%的图像用于训练，而剩余的10%到20%的图像则不会用于训练算法，而是用于验证模型在未观察数据上的泛化能力。
- en: There is a separate dataset that the algorithm should never see during training,
    named the test set, which consists of 10,000 images in the MNIST dataset.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，应该避免看到的另一个单独的数据集，称为测试集，在 MNIST 数据集中包含 10,000 个图像。
- en: 'In the MNIST dataset, the input data of each example is a 28x28 normalized
    monochrome image and a label, represented as a simple integer between 0 and 9
    for each example. Let''s display some of them:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MNIST 数据集中，每个示例的输入数据是一个28x28的归一化单色图像和一个标签，表示每个示例的简单整数介于0和9之间。让我们展示其中一些：
- en: 'First, download a pre-packaged version of the dataset that makes it easier
    to load from Python:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，下载一个预打包版本的数据集，这样可以更容易地从 Python 中加载：
- en: '[PRE0]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then load the data into a Python session:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后将数据加载到 Python 会话中：
- en: '[PRE1]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: For `Python3`, we need `pickle.load(f, encoding='latin1')` due to the way it
    was serialized.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于 `Python3`，由于其序列化方式，我们需要使用 `pickle.load(f, encoding='latin1')`。
- en: '[PRE2]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The first nine samples from the dataset are displayed with the corresponding
    label (the *ground truth*, that is, the correct answer expected by the classification
    algorithm) on top of them:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的前九个样本显示了相应的标签（*地面实况*，即分类算法预期的正确答案）：
- en: '![The MNIST dataset](img/00010.jpeg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![MNIST数据集](img/00010.jpeg)'
- en: 'In order to avoid too many transfers to the GPU, and since the complete dataset
    is small enough to fit in the memory of the GPU, we usually place the full training
    set in shared variables:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免过多的数据传输到GPU，并且由于整个数据集足够小，能够适应GPU的内存，我们通常将整个训练集放入共享变量中：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Avoiding these data transfers allows us to train faster on the GPU, despite
    recent GPU and fast PCIe connections.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 避免这些数据传输可以让我们在GPU上更快地进行训练，尽管最近的GPU和高速PCIe连接也在帮助提升速度。
- en: More information on the dataset is available at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 更多关于数据集的信息请访问 [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)。
- en: Structure of a training program
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练程序结构
- en: 'The structure of a training program always consists of the following steps:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 训练程序的结构总是包含以下步骤：
- en: '**Set the script environment**: Such as package imports, the use of the GPU,
    and so on.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置脚本环境**：例如包的导入、GPU的使用等。'
- en: '**Load data**: A data loader class to access the data during training, usually
    in a random order to avoid too many similar examples of the same class, but sometimes
    in a precise order, for example, in the case of curriculum learning with simple
    examples first and complex ones last.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**加载数据**：数据加载器类，用于在训练期间访问数据，通常是随机顺序，以避免出现过多相似类别的示例，但有时也可能是精确顺序，例如在课程学习中，先使用简单示例，最后使用复杂示例。'
- en: '**Preprocess the data**: A set of transformations, such as swapping dimensions
    on images, adding blur or noise. It is very common to add some data augmentation
    transformations, such as random crop, scale, brightness, or contrast jittering
    to get more examples than the original ones, and reduce the risk of overfitting
    on data. If the number of free parameters in the model is too important with respect
    to the training dataset size, the model might learn from the available examples.
    Also, if the dataset is too small and too many iterations have been executed on
    the same data, the model might become too specific to the training examples and
    not generalize well on new unseen examples.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**预处理数据**：一组转换操作，例如交换图像的维度、添加模糊或噪声。常见的做法是添加一些数据增强转换，比如随机裁剪、缩放、亮度或对比度波动，从而获得比原始数据更多的示例，并减少过拟合的风险。如果模型中自由参数的数量相对于训练数据集的大小过多，模型可能会仅从可用示例中学习。而且，如果数据集太小并且对同一数据进行了过多的迭代，模型可能会过于特定于训练示例，而在新的未见过的示例上泛化能力较差。'
- en: '**Build a model**: Defining the model structure with the parameter in persistent
    variables (shared variables) to update their values during training in order to
    fit the training data'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**构建模型**：定义模型结构，并在持久变量（共享变量）中设置参数，以便在训练过程中更新其值，从而拟合训练数据。'
- en: '**Train**: There are different algorithms either training on the full dataset
    as a whole or training on each example step by step. The best convergence is usually
    achieved by training on a batch, a small subset of examples grouped together,
    from a few tens to a few hundreds.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**训练**：有不同的算法，可以是对整个数据集进行训练，也可以是逐个示例进行逐步训练。通常，最佳的收敛效果是通过对批量进行训练实现的，批量是将一小部分示例分组在一起，数量从几十个到几百个不等。'
- en: 'Another reason to use a batch is to improve the training speed of the GPU,
    because individual data transfers are costly and GPU memory is not sufficient
    to host the full dataset as well. The GPU is a parallel architecture, so processing
    a batch of examples is usually faster than processing the examples one by one,
    up to a certain point. Seeing more examples at the same time accelerates the convergence
    (in wall-time), up to a certain point. This is true even if the GPU memory is
    large enough to host the whole dataset: the diminishing returns on the batch size
    make it usually faster to have smaller batches than the whole dataset. Note that
    this is true for modern CPUs as well, but the optimal batch size is usually smaller.'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用批量的另一个原因是提高GPU的训练速度，因为单独的数据传输成本较高，并且GPU内存不足以容纳整个数据集。GPU是并行架构，因此处理一个批次的示例通常比逐个处理示例更快，直到达到某个点。一次性查看更多示例可以加速收敛（以墙时间为准），直到达到某个点。即使GPU内存足够大，可以容纳整个数据集，这一点也是成立的：批量大小的收益递减通常使得使用较小的批量比使用整个数据集更快。需要注意的是，这对于现代CPU也是成立的，但最优的批量大小通常较小。
- en: Note
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: An iteration defines a training on one batch. An epoch is a number of iterations
    required for the algorithm to see the full dataset.
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一次迭代定义了对一个批次的训练。一个epoch是算法查看完整数据集所需的迭代次数。
- en: During training, after a certain number of iterations, there is usually a **validation**
    using a split of the training data or a validation dataset that has not been used
    for learning. The loss is computed on this validation set. Though the algorithm
    has the objective to reduce the loss given the training data, it does not ensure
    generalization with unseen data. Validation data is unseen data used to estimate
    the generalization performance. A lack of generalization might occur when the
    training data is not representative, or is an exception and has not been sampled
    correctly, or if the model overfits the training data.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练过程中，在一定数量的迭代后，通常会使用训练数据的拆分或未用于学习的验证数据集进行**验证**。在该验证集上计算损失。尽管算法的目标是减少给定训练数据的损失，但它并不保证能在未见数据上进行泛化。验证数据是未见过的数据，用于估算泛化性能。当训练数据不具代表性、存在异常且未正确抽样，或模型过拟合训练数据时，可能会发生泛化不足的情况。
- en: 'Validation data verifies everything is OK, and stops training when validation
    loss does not decrease any more, even if training loss might continue to decrease:
    further training is not worth it any more and leads to overfitting.'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 验证数据验证一切是否正常，并在验证损失不再下降时停止训练，即使训练损失可能继续下降：进一步的训练已不再有价值，并可能导致过拟合。
- en: '**Saving model parameters** and displaying results, such as best training/validation
    loss values, train loss curves for convergence analysis.'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**保存模型参数**并显示结果，如最佳训练/验证损失值、用于收敛分析的训练损失曲线。'
- en: In the case of classification, we compute the accuracy (the percentage of correct
    classification) or the error (the percentage of misclassification) during training,
    as well as the loss. At the end of training, a confusion matrix helps evaluate
    the quality of the classifier.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在分类问题中，我们在训练过程中计算准确率（正确分类的百分比）或错误率（错误分类的百分比），以及损失。训练结束时，混淆矩阵有助于评估分类器的质量。
- en: 'Let''s see these steps in practice and start a Theano session in a Python shell
    session:'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 让我们在实践中看看这些步骤，并在Python shell会话中启动Theano会话：
- en: '[PRE4]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Classification loss function
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类损失函数
- en: The loss function is an objective function to minimize during training to get
    the best model. Many different loss functions exist.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数是一个目标函数，在训练过程中最小化它以获得最佳模型。存在许多不同的损失函数。
- en: 'In a classification problem, where the target is to predict the correct class
    among k classes, cross-entropy is commonly used as it measures the difference
    between the real probability distribution, *q*, and the predicted one, *p*, for
    each class:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类问题中，目标是在k个类别中预测正确类别，交叉熵通常被用作损失函数，因为它衡量的是每个类别的真实概率分布 *q* 和预测概率分布 *p* 之间的差异：
- en: '![Classification loss function](img/00011.jpeg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![分类损失函数](img/00011.jpeg)'
- en: Here, *i* is the index of the sample in the dataset, *n* is the number of samples
    in the dataset, and *k* is the number of classes.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*i*是数据集中的样本索引，*n*是数据集中的样本数量，*k*是类别的数量。
- en: 'While the real probability ![Classification loss function](img/00012.jpeg)
    of each class is unknown, it can simply be approximated in practice by the empirical
    distribution, that is, randomly drawing a sample out of the dataset in the dataset
    order. The same way, the cross-entropy of any predicted probability, `p`, can
    be approximated by the empirical cross-entropy:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然每个类别的真实概率 ![分类损失函数](img/00012.jpeg) 是未知的，但在实践中它可以通过经验分布来简单地近似，即按数据集顺序从数据集中随机抽取样本。同样，任何预测概率`p`的交叉熵也可以通过经验交叉熵来近似：
- en: '![Classification loss function](img/00013.jpeg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![分类损失函数](img/00013.jpeg)'
- en: Here, ![Classification loss function](img/00014.jpeg) is the probability estimated
    by the model for the correct class of example ![Classification loss function](img/00015.jpeg).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![分类损失函数](img/00014.jpeg) 是模型为正确类别示例 ![分类损失函数](img/00015.jpeg) 估算的概率。
- en: Accuracy and cross-entropy both evolve in the same direction but measure different
    things. Accuracy measures how much the predicted class is correct, while cross-entropy
    measure the distance between the probabilities. A decrease in cross-entropy explains
    that the probability to predict the correct class gets better, but the accuracy
    may remain constant or drop.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率和交叉熵都朝着相同的方向发展，但衡量的是不同的内容。准确率衡量预测类别的正确性，而交叉熵衡量概率之间的距离。交叉熵的下降说明预测正确类别的概率变得更高，但准确率可能保持不变或下降。
- en: While accuracy is discrete and not differentiable, the cross-entropy loss is
    a differentiable function that can be easily used for training a model.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然准确率是离散的且不可微分，但交叉熵损失是一个可微分的函数，便于用于模型训练。
- en: Single-layer linear model
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 单层线性模型
- en: 'The simplest model is the linear model, where for each class `c`, the output
    is a linear combination of the input values:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的模型是线性模型，其中对于每个类别`c`，输出是输入值的线性组合：
- en: '![Single-layer linear model](img/00016.jpeg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![单层线性模型](img/00016.jpeg)'
- en: This output is unbounded.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出是无界的。
- en: 'To get a probability distribution, `p[i]`, that sums to 1, the output of the
    linear model is passed into a softmax function:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了得到一个概率分布，`p[i]`，其总和为1，线性模型的输出被传入softmax函数：
- en: '![Single-layer linear model](img/00017.jpeg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![单层线性模型](img/00017.jpeg)'
- en: 'Hence, the estimated probability of class `c` for an input `x` is rewritten
    with vectors:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，类`c`对输入`x`的估计概率可以用向量重写：
- en: '![Single-layer linear model](img/00018.jpeg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![单层线性模型](img/00018.jpeg)'
- en: 'Translated in Python with:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python中的实现如下：
- en: '[PRE5]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The prediction for a given input is given by the most probable class (maximum
    probability):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 给定输入的预测由最可能的类别（最大概率）给出：
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In this model with a single linear layer, information moves from input to output:
    it is a **feedforward network**. The process to compute the output given the input
    is called **forward propagation**.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个单层线性模型中，信息从输入到输出流动：它是一个**前馈网络**。给定输入计算输出的过程称为**前向传播**。
- en: 'This layer is said fully connected because all outputs, ![Single-layer linear
    model](img/00019.jpeg), are the sum of (are linked to) all inputs values through
    a multiplicative coefficient:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这个层被称为全连接层，因为所有的输出，![单层线性模型](img/00019.jpeg)，是通过一个乘法系数将所有输入值的和连接在一起：
- en: '![Single-layer linear model](img/00020.jpeg)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![单层线性模型](img/00020.jpeg)'
- en: Cost function and errors
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 成本函数和错误
- en: 'The cost function given the predicted probabilities by the model is as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 给定模型预测的概率，成本函数如下：
- en: '[PRE7]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The error is the number of predictions that are different from the true class,
    averaged by the total number of values, which can be written as a mean:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 错误是与真实类别不同的预测数量，按总值数量平均，可以写成一个均值：
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: On the contrary, accuracy corresponds to the number of correct predictions divided
    by the total number of predictions. The sum of error and accuracy is one.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，准确率是正确预测的数量除以总预测数。错误和准确率的总和为1。
- en: 'For other types of problems, here are a few other loss functions and implementations:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他类型的问题，以下是一些其他的损失函数及实现：
- en: '| **Categorical cross entropy**An equivalent implementation of ours |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| **分类交叉熵**我们实现的等效版本 |'
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '|'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Binary cross entropy**For the case when output can take only two values
    {0,1}Typically used after a sigmoid activation predicting the probability, p |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| **二元交叉熵**当输出只能取两个值{0,1}时，通常在使用sigmoid激活预测概率p后使用 |'
- en: '[PRE10]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '|'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Mean squared error**L2 norm for regression problems |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| **均方误差**回归问题的L2范数 |'
- en: '[PRE11]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '|'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Mean absolute error**L1 norm for regression problems |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| **均绝对误差**回归问题的L1范数 |'
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '|'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Smooth L1**A mix between L1 for large values, and L2 for small valuesKnown
    as an outlier resistant loss for regressions |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| **平滑L1**L1用于大值，L2用于小值，通常作为回归问题中的抗异常值损失 |'
- en: '[PRE13]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '|'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Squared hinge loss**Particularly used in unsupervised problems |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| **平方铰链损失**特别用于无监督问题 |'
- en: '[PRE14]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '|'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Hinge loss** |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| **铰链损失** |'
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '|'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Backpropagation and stochastic gradient descent
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反向传播和随机梯度下降
- en: Backpropagation, or the backward propagation of errors, is the most commonly
    used supervised learning algorithm for adapting the connection weights.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播，或称为误差的反向传播，是最常用的监督学习算法，用于调整连接权重。
- en: 'Considering the error or the cost as a function of the weights *W* and *b*,
    a local minimum of the cost function can be approached with a gradient descent,
    which consists of changing weights along the negative error gradient:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 将错误或成本视为权重*W*和*b*的函数，可以通过梯度下降接近成本函数的局部最小值，梯度下降的过程是沿着负错误梯度改变权重：
- en: '![Backpropagation and stochastic gradient descent](img/00021.jpeg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![反向传播和随机梯度下降](img/00021.jpeg)'
- en: Here, ![Backpropagation and stochastic gradient descent](img/00022.jpeg) is
    the learning rate, a positive constant defining the speed of a descent.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![反向传播和随机梯度下降](img/00022.jpeg)是学习率，一个正的常数，定义了下降的速度。
- en: 'The following compiled function updates the variables after each feedforward
    run:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 以下编译的函数在每次前馈运行后更新变量：
- en: '[PRE16]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The input variable is the index of the batch, since all the dataset has been
    transferred in one pass to the GPU in shared variables.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 输入变量是批次的索引，因为所有数据集已经通过一次传递转移到 GPU 中的共享变量。
- en: 'Training consists of presenting each sample to the model iteratively (iterations)
    and repeating the operation many times (epochs):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程包括将每个样本迭代地呈现给模型（迭代次数），并多次重复操作（训练周期）：
- en: '[PRE17]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This only reports the loss and error on one mini-batch, though. It would be
    good to also report the average over the whole dataset.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这只报告了一个小批次的损失和误差，最好还能够报告整个数据集上的平均值。
- en: The error rate drops very quickly during the first iterations, then slows down.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几次迭代中，误差率快速下降，然后逐渐放缓。
- en: Execution time on a GPU GeForce GTX 980M laptop is 67.3 seconds, while on an
    Intel i7 CPU, it is 3 minutes and 7 seconds.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在一台 GPU GeForce GTX 980M 笔记本电脑上的执行时间是 67.3 秒，而在 Intel i7 CPU 上的时间为 3 分钟 7 秒。
- en: After a long while, the model converges to a 5.3 - 5.5% error rate, and with
    a few more iterations could go further down, but could also lead to overfitting,
    Overfitting occurs when the model fits the training data well but does not get
    the same error rate on unseen data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一段时间后，模型收敛到 5.3% - 5.5% 的误差率，再进行几轮迭代可能会进一步下降，但也可能导致过拟合。过拟合是指模型很好地拟合了训练数据，但在未见过的数据上表现不佳，误差率较高。
- en: In this case, the model is too simple to overfit on this data.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，模型过于简单，无法对这些数据进行过拟合。
- en: A model that is too simple cannot learn very well. The principle of deep learning
    is to add more layers, that is, increase the depth and build deeper networks to
    gain better accuracy.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 一个过于简单的模型无法很好地学习。深度学习的原则是添加更多的层，也就是增加深度，构建更深的网络，以获得更好的准确性。
- en: We'll see in the following section how to compute a better estimation of the
    model accuracy and the training stop.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的部分看到如何计算模型准确度的更好估计以及训练停止的时机。
- en: Multiple layer model
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多层模型
- en: 'A **multi-layer perceptron** (**MLP**) is a feedforward net with multiple layers.
    A second linear layer, named hidden layer, is added to the previous example:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**多层感知器**（**MLP**）是一个具有多层的前馈神经网络。在前面的例子中，增加了一个第二个线性层，称为隐藏层：'
- en: '![Multiple layer model](img/00023.jpeg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![多层模型](img/00023.jpeg)'
- en: Having two linear layers following each other is equivalent to having a single
    linear layer.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 两个线性层紧跟在一起等同于一个线性层。
- en: 'With a *non-linear function or non-linearity or transfer function* between
    the linearities, the model does not simplify into a linear one any more, and represents
    more possible functions in order to capture more complex patterns in the data:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用*非线性函数、非线性或转换函数*在各线性之间，模型不再简化为线性模型，并表示更多可能的函数，以捕捉数据中更复杂的模式：
- en: '![Multiple layer model](img/00024.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![多层模型](img/00024.jpeg)'
- en: Activation functions helps saturating (ON-OFF) and reproduces the biological
    neuron activations.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数有助于饱和（开-关），并重现生物神经元的激活。
- en: 'The **Rectified Linear Unit** (**ReLU**) graph is given as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**Rectified Linear Unit**（**ReLU**）的图形如下所示：'
- en: '*(x + T.abs_(x)) / 2.0*'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '*(x + T.abs_(x)) / 2.0*'
- en: '![Multiple layer model](img/00025.jpeg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![多层模型](img/00025.jpeg)'
- en: 'The **Leaky Rectifier Linear Unit** (**Leaky ReLU**) graph is given as follows:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**Leaky Rectifier Linear Unit**（**Leaky ReLU**）的图形如下所示：'
- en: '*( (1 + leak) * x + (1 – leak) * T.abs_(x) ) / 2.0*'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*((1 + leak) * x + (1 – leak) * T.abs_(x)) / 2.0*'
- en: '![Multiple layer model](img/00026.jpeg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![多层模型](img/00026.jpeg)'
- en: Here, `leak` is a parameter that defines the slope in the negative values. In
    leaky rectifiers, this parameter is fixed.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`leak` 是一个参数，定义了负值部分的斜率。在泄漏整流器中，这个参数是固定的。
- en: The activation named PReLU considers the `leak` parameter to be learned.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 名为 PReLU 的激活函数考虑了需要学习的 `leak` 参数。
- en: 'More generally speaking, a piecewise linear activation can be learned by adding
    a linear layer followed by a maxout activation of `n_pool` units:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地说，可以通过添加一个线性层，然后是 `n_pool` 单元的最大化激活，来学习分段线性激活：
- en: '[PRE18]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This will output `n_pool` values or units for the underlying learned linearities:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出 `n_pool` 个值或单元，代表底层学习到的线性关系：
- en: '**Sigmoid** (T.nnet.sigmoid)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sigmoid**（T.nnet.sigmoid）'
- en: '![Multiple layer model](img/00027.jpeg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![多层模型](img/00027.jpeg)'
- en: '**HardSigmoid** function is given as:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**HardSigmoid** 函数表示为：'
- en: '*T.clip(X + 0.5, 0., 1.)*'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*T.clip(X + 0.5, 0., 1.)*'
- en: '![Multiple layer model](img/00028.jpeg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![多层模型](img/00028.jpeg)'
- en: '**HardTanh** function is given as:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**HardTanh** 函数表示为：'
- en: '*T.clip(X, -1., 1.)*'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '*T.clip(X, -1., 1.)*'
- en: '![Multiple layer model](img/00029.jpeg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![多层模型](img/00029.jpeg)'
- en: '**Tanh** function is given as:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**Tanh** 函数定义如下：'
- en: '*T.tanh(x)*'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '*T.tanh(x)*'
- en: '![Multiple layer model](img/00030.jpeg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![多层模型](img/00030.jpeg)'
- en: 'This two-layer network model written in Python will be as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这个用 Python 编写的两层网络模型如下：
- en: '[PRE19]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: In deep nets, if weights are initialized to zero with the `shared_zeros` method,
    the signal will not flow through the network correctly from end to end. If weights
    are initialized with values that are too big, after a few steps, most activation
    functions saturate. So, we need to ensure that the values can be passed to the
    next layer during propagation, as well as for the gradients to the previous layer
    during back-propagation.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度网络中，如果权重通过 `shared_zeros` 方法初始化为零，信号将无法从头到尾正确流过网络。如果权重初始化为过大的值，经过几步后，大多数激活函数将会饱和。所以，我们需要确保在传播过程中值能够传递到下一层，并且在反向传播过程中，梯度能够传递到上一层。
- en: We also need to break the symmetry between neurons. If the weights of all neurons
    are zero (or if they are all equal), they will all evolve exactly in the same
    way, and the model will not learn much.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要打破神经元之间的对称性。如果所有神经元的权重都为零（或者它们都相等），它们将以完全相同的方式发展，模型将无法学习到很多东西。
- en: 'The researcher Xavier Glorot studied an algorithm to initialize weights in
    an optimal way. It consists in drawing the weights from a Gaussian or uniform
    distribution of zero mean and the following variance:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 研究员 Xavier Glorot 研究了一种算法来以最优方式初始化权重。该算法通过从均值为零的高斯或均匀分布中抽取权重，方差如下：
- en: '![Multiple layer model](img/00031.jpeg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![多层模型](img/00031.jpeg)'
- en: 'Here are the variables from the preceding formula:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这是前述公式中的变量：
- en: '`n[in]` is the number of inputs the layer receives during feedforward propagation'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n[in]` 是该层在前向传播过程中接收到的输入数量'
- en: '`n[out]` is the number of gradients the layer receives during back-propagation'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n[out]` 是该层在反向传播过程中接收到的梯度数量'
- en: In the case of a linear model, the shape parameter is a tuple, and `v` is simply
    `numpy.sum( shape[:2] )` (in this case, `numpy.prod(shape[2:])` is `1`).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性模型中，形状参数是一个元组，`v` 就是 `numpy.sum(shape[:2])`（在这种情况下，`numpy.prod(shape[2:])`
    为 `1`）。
- en: 'The variance of a uniform distribution on *[-a, a]* is given by *a**2 / 3*,
    then the bound `a` can be computed as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 均匀分布在 *[-a, a]* 上的方差为 *a**2 / 3*，那么可以通过以下方式计算边界 `a`：
- en: '![Multiple layer model](img/00032.jpeg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![多层模型](img/00032.jpeg)'
- en: 'The cost can be defined the same way as before, but the gradient descent needs
    to be adapted to deal with the list of parameters, `[W1,b1,W2,b2]`:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 成本可以像以前一样定义，但梯度下降需要适应处理参数列表 `[W1,b1,W2,b2]`：
- en: '[PRE20]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The training loop requires an updated training function:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 训练循环需要一个更新的训练函数：
- en: '[PRE21]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: In this case, learning rate is global to the net, with all weights being updated
    at the same rate. The learning rate is set to 0.01 instead of 0.13\. We'll speak
    about hyperparameter tuning in the training section.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，学习率对整个网络是全局的，所有权重以相同的速率更新。学习率设置为 0.01，而不是 0.13。我们将在训练部分讨论超参数调优。
- en: The training loop remains unchanged. The full code is given in the `2-multi.py`
    file.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 训练循环保持不变。完整的代码见`2-multi.py`文件。
- en: Execution time on the GPU is 5 minutes and 55 seconds, while on the CPU it is
    51 minutes and 36 seconds.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GPU 上的执行时间为 5 分钟 55 秒，而在 CPU 上为 51 分钟 36 秒。
- en: After 1,000 iterations, the error has dropped to 2%, which is a lot better than
    the previous 5% error rate, but part of it might be due to overfitting. We'll
    compare the different models later.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在 1000 次迭代后，误差降至 2%，比之前的 5% 错误率要好得多，但其中一部分可能是由于过拟合造成的。我们稍后会比较不同的模型。
- en: Convolutions and max layers
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积和最大池化层
- en: 'A great improvement in image classification has been achieved with the invention
    of the convolutional layers on the MNIST database:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在 MNIST 数据集上，卷积层的发明使得图像分类取得了巨大的进展：
- en: '![Convolutions and max layers](img/00033.jpeg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![卷积和最大池化层](img/00033.jpeg)'
- en: While previous fully-connected layers perform a computation with all input values
    (pixels in the case of an image) of the input, a 2D convolution layer will consider
    only a small patch or window or receptive field of NxN pixels of the 2D input
    image for each output unit. The dimensions of the patch are named kernel dimensions,
    N is the kernel size, and the coefficients/parameters are the kernel.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的全连接层对输入的所有值（图像的像素值）进行计算不同，2D 卷积层将仅考虑 2D 输入图像中 NxN 像素的小块、窗口或感受野来计算每个输出单元。该块的尺寸被称为卷积核尺寸，N
    为卷积核大小，系数/参数即为卷积核。
- en: 'At each position of the input image, the kernel produces a scalar, and all
    position values will lead to a matrix (2D tensor) called a *feature map*. Convolving
    the kernel on the input image as a sliding window creates a new output image.
    The stride of the kernel defines the number of pixels to shift the patch/window
    over the image: with a stride of 2, the convolution with the kernel is computed
    every 2 pixels.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在输入图像的每个位置，卷积核都会生成一个标量，所有位置的值将形成一个矩阵（2D 张量），称为 *特征图*。在输入图像上进行卷积操作，像滑动窗口一样，生成一个新的输出图像。卷积核的步幅定义了在图像上移动补丁/窗口的像素数：步幅为
    2 时，卷积核每隔 2 个像素计算一次卷积。
- en: 'For example, on a 224 x 224 input image, we get the following:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在一个 224 x 224 的输入图像上，我们得到如下结果：
- en: A 2x2 kernel with stride 1 outputs a 223 x 223 feature map
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 2x2 的卷积核，步幅为 1，将输出一个 223 x 223 的特征图。
- en: A 3x3 kernel with stride 1 outputs a 222 x 222 feature map
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 3x3 的卷积核，步幅为 1，将输出一个 222 x 222 的特征图。
- en: 'In order to keep the output feature map the same dimension as the input image,
    there is a type of zero-padding called *same* or *half* that enables the following:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持输出特征图与输入图像相同的尺寸，有一种叫做 *same* 或 *half* 的零填充方法，可以实现以下效果：
- en: Add a line and a column of zeros at the end of the input image in the case of
    a 2x2 kernel with stride 1
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在输入图像的末尾添加一行一列零，适用于步幅为 1 的 2x2 卷积核。
- en: Add two lines and two columns of zeros, one in front and one at the end of the
    input image vertically and horizontally in the case of a 3x3 kernel with stride
    1
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在输入图像的上下左右分别添加两行两列零，适用于步幅为 1 的 3x3 卷积核。
- en: So, the output dimensions are the same as the original ones, that is, a 224
    x 224 feature map.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，输出的尺寸与原始尺寸相同，也就是一个 224 x 224 的特征图。
- en: 'With zero padding:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 有零填充时：
- en: A 2x2 kernel with stride 2 and zero padding will output a 112 x 112 feature
    map
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 2x2 的卷积核，步幅为 2，并且有零填充，将输出一个 112 x 112 的特征图。
- en: A 3x3 kernel with stride 2 will output a 112 x 112 feature map
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 3x3 的卷积核，步幅为 2，将输出一个 112 x 112 的特征图。
- en: 'Without zero-padding, it gets more complicated:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有零填充，事情会变得更复杂：
- en: A 2x2 kernel with stride 2 will output a 112 x 112 feature map
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 2x2 的卷积核，步幅为 2，将输出一个 112 x 112 的特征图。
- en: A 3x3 kernel with stride 2 will output a 111 x 111 feature map
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 3x3 的卷积核，步幅为 2，将输出一个 111 x 111 的特征图。
- en: Note that kernel dimensions and strides can be different for each dimension.
    In this case, we say kernel width, kernel height, stride width, or stride height.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，卷积核的尺寸和步长在每个维度上可能不同。在这种情况下，我们说卷积核的宽度、卷积核的高度、步幅宽度或步幅高度。
- en: In one convolutional layer, it is possible to output multiple feature maps,
    each feature map being computed with a different kernel (and kernel weights) and
    representing one feature. We say outputs, neurons, kernels, features, feature
    maps, units, or output channels indifferently to give the number of these different
    convolutions with different kernels. To be precise, neuron usually refers to a
    specific position within a feature map. Kernels are the kernels themselves, and
    the other ones refer to the result of the convolution operation. The number of
    them is the same, which is why these words are often used to describe the same
    thing. I'll use the words channels, outputs, and features.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个卷积层中，可能输出多个特征图，每个特征图是用不同的卷积核（和卷积核权重）计算出来的，表示一个特征。我们可以用输出、神经元、卷积核、特征、特征图、单元或输出通道来表示这些不同卷积的数量。严格来说，神经元通常指的是特征图中的一个特定位置。卷积核就是卷积核本身，其他的则是卷积操作的结果。它们的数量是相同的，这就是这些词常常用来描述相同内容的原因。我将使用通道、输出和特征这几个词。
- en: The usual convolution operators can be applied to multi-channel inputs. This
    enables to apply them to three-channel images (RGB images, for example) or to
    the output of another convolution in order to be chained.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的卷积运算符可以应用于多通道输入。这使得它们可以应用于三通道图像（例如 RGB 图像）或另一个卷积的输出，以便进行级联。
- en: 'Let''s include two convolutions with a kernel size of 5 in front of the previous
    MLP mode:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在前面的 MLP 模型前面添加两个卷积层，卷积核大小为 5：
- en: '![Convolutions and max layers](img/00034.jpeg)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![卷积和最大池化层](img/00034.jpeg)'
- en: 'The 2D convolution operator requires a 4D tensor input. The first dimension
    is the batch size, the second the number of inputs or input channels (in the "channel-first
    format"), and the third and fourth the two dimensions of the feature map (in the
    "channel-last format", channels are the last dimension). MNIST gray images (one
    channel) stored in a one-dimensional vector need to be converted into a 28x28
    matrix, where 28 is the image height and width:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 2D卷积操作需要4D张量输入。第一维是批量大小，第二维是输入数量或输入通道数（采用“通道优先”格式），第三和第四维是特征图的两个维度（采用“通道后置”格式，通道是最后一个维度）。MNIST灰度图像（一个通道）以一维向量存储，需要转换为28x28的矩阵，其中28是图像的高度和宽度：
- en: '[PRE22]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then, adding a first convolution layer of 20 channels on top of the transformed
    input, we get this:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在变换后的输入上添加一个20通道的第一个卷积层，得到如下结果：
- en: '[PRE23]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: In this case, the Xavier initialization (from the name of its inventor, Xavier
    Glorot) multiplies the number of input/output channels by the number of parameters
    in the kernel, `numpy.prod(shape[2:]) = 5 x 5 = 25`, to get the total number of
    incoming input/output gradients in the initialization formula.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，Xavier初始化（以其发明者Xavier Glorot的名字命名）将输入/输出通道的数量与卷积核中的参数数量相乘，`numpy.prod(shape[2:])
    = 5 x 5 = 25`，从而得到初始化公式中输入/输出梯度的总数。
- en: The 20 kernels of size 5x5 and stride 1 on 28x28 inputs will produce 20 feature
    maps of size 24x24\. So the first convolution output is (`batch_size,20,24,24`).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在28x28的输入上使用大小为5x5，步幅为1的20个卷积核将产生20个24x24的特征图。所以第一个卷积层的输出是（`batch_size,20,24,24`）。
- en: 'Best performing nets use max pooling layers to encourage translation invariance
    and stability to noise. A max-pooling layer performs a maximum operation over
    a sliding window/patch to keep only one value out of the patch. As well as increasing
    speed performance, it reduces the size of the feature maps, and the total computation
    complexity and training time decreases:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳性能的网络使用最大池化层，以鼓励平移不变性并提高对噪声的稳定性。最大池化层在滑动窗口/补丁上执行最大操作，仅保留补丁中的一个值。除了提高速度性能外，它还减少了特征图的大小，总体计算复杂度和训练时间也因此降低：
- en: '[PRE24]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The output of the 2x2 max pooling layer will be (`batch_size,20,12,12`). The
    batch size and the number of channels stay constant. Only the feature map's size
    has changed.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 2x2最大池化层的输出将是（`batch_size,20,12,12`）。批量大小和通道数保持不变，只有特征图的大小发生了变化。
- en: 'Adding a second convolutional layer of 50 channels and max pooling layer on
    top of the previous one leads to an output of size (`batch_size,50,4,4`):'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个卷积层之上添加一个50通道的第二个卷积层和最大池化层，得到的输出尺寸为（`batch_size,50,4,4`）：
- en: '[PRE25]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'To create a classifier, we connect on top the MLP with its two fully-connected
    linear layers and a softmax, as seen before:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建分类器，我们在上面连接一个具有两个全连接线性层和一个softmax的MLP，如前所示：
- en: '[PRE26]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Such a model is named a **Convolutional Neural Net** (**CNN**).
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的模型被称为**卷积神经网络**（**CNN**）。
- en: The full code is given in the `3-cnn.py` file.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码可以在`3-cnn.py`文件中找到。
- en: 'Training is much slower because the number of parameters has been multiplied
    again, and the use of the GPU makes a lot more sense: total training time on the
    GPU has increased to 1 hour, 48 min and 27 seconds. Training on the CPU would
    take days.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 训练速度大大变慢，因为参数数量又被乘以了，使用GPU变得更加有意义：在GPU上训练的总时间已增加至1小时48分钟27秒。若在CPU上训练，将需要数天。
- en: The training error is zero after a few iterations, part of it due to overfitting.
    Let's see in the next section how to compute a testing loss and accuracy that
    better explains the model's efficiency.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 经过几次迭代后，训练误差为零，部分原因是过拟合。接下来我们将看到如何计算测试损失和准确度，以更好地解释模型的效率。
- en: Training
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练
- en: In order to get a good measure of how the model behaves on data that's unseen
    during training, the validation dataset is used to compute a validation loss and
    accuracy during training.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了得到模型在训练过程中未见数据上的表现的良好度量，使用验证数据集来计算训练过程中的验证损失和准确度。
- en: The validation dataset enables us to choose the best model, while the test dataset
    is only used at the end to get the final test accuracy/error of the model. The
    training, test, and validation datasets are discrete datasets, with no common
    examples. The validation dataset is usually 10 times smaller than the test dataset
    to slow the training process as little as possible. The test dataset is usually
    around 10-20% of the training dataset. Both the training and validation datasets
    are part of the training program, since the first one is used to learn, and the
    second is used to select the best model on unseen data at training time.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 验证数据集使我们能够选择最佳模型，而测试数据集仅在最后用于获得模型的最终测试准确率/错误率。训练、测试和验证数据集是离散的数据集，没有共同的示例。验证数据集通常是测试数据集的十分之一，以尽量减少对训练过程的影响。测试数据集通常占训练数据集的10%-20%。训练集和验证集都是训练程序的一部分，因为第一个用于学习，第二个则用于在训练时选择最佳模型，以便在未见数据上进行验证。
- en: The test dataset is completely outside the training process and is used to get
    the accuracy of the produced model, resulting from training and model selection.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据集完全独立于训练过程，仅用于获得经过训练和模型选择后的最终模型的准确性。
- en: If the model overfits the training set because it has been trained too many
    times on the same images, for example, then the validation and test sets will
    not suffer from this behavior and will provide a real estimation of the model's
    accuracy.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型因在相同图像上训练次数过多而过拟合训练集，例如，那么验证集和测试集将不会受到这种行为的影响，并将提供模型准确性的真实估计。
- en: Usually, a validation function is compiled without a gradient update of the
    model to simply compute only the cost and error on the input batch.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，验证函数是编译时不更新模型梯度的，仅计算输入批次的成本和误差。
- en: 'Batches of data *(x,y)* are commonly transferred to the GPU at every iteration
    because the dataset is usually too big to fit in the GPU''s memory. In this case,
    we could still use the trick with the shared variables to place the whole validation
    dataset in the GPU''s memory, but let''s see how we would do if we had to transfer
    the batches to the GPU at each step and not use the previous trick. We would use
    the more usual form:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 数据批次*(x,y)*通常在每次迭代时传输到GPU，因为数据集通常太大，无法完全放入GPU的内存中。在这种情况下，我们仍然可以使用共享变量的技巧将整个验证数据集放入GPU的内存中，但让我们看看如果每步都必须将批次传输到GPU而不使用之前的技巧，我们该如何操作。我们将使用更常见的形式：
- en: '[PRE27]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'It requires the transfer of batch inputs. Validation is computed not at every
    iteration, but at `validation_interval` iterations in the training `for` loop:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要批次输入的传输。验证不是在每次迭代时计算，而是在训练的`for`循环中的`validation_interval`次迭代时计算：
- en: '[PRE28]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let''s see the simple first model:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看简单的第一个模型：
- en: '[PRE29]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In a full training program, a validation interval corresponding to the total
    number of epochs, with an average validation score for the epoch, would make more
    sense.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在完整的训练程序中，验证间隔与总的训练周期数相对应，且周期的平均验证得分更有意义。
- en: 'To better estimate how the training performs, let''s plot the training and
    valid loss. In order to display the descent in early iterations, I''ll stop the
    drawing at 100 iterations. If I use 1,000 iterations in the plot, I won''t see
    the early iterations:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地评估训练效果，让我们绘制训练损失和验证损失的曲线。为了显示早期迭代中的下降情况，我会在100次迭代时停止绘图。如果我在图中使用1,000次迭代，就看不到早期迭代的情况：
- en: '![Training](img/00035.jpeg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![训练](img/00035.jpeg)'
- en: The training loss looks like a wide band because it oscillates between different
    values. Each of the values corresponds to one batch. The batch might be too small
    to provide a stable loss value. The mean value of the training loss over the epoch
    would provide a more stable value to compare with the valid loss and show overfitting.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 训练损失看起来像一条宽带，因为它在不同的值之间波动。每个值对应一个批次。该批次可能太小，无法提供稳定的损失值。通过整个周期的训练损失平均值，将提供一个更稳定的值，与验证损失进行比较，展示是否发生过拟合。
- en: Also note that the loss plot provides information on how the network converges,
    but does not give any valuable information on the error. So, it is also very important
    to plot the training error and the valid error.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要注意，损失曲线提供了网络收敛情况的信息，但并不提供任何关于错误的有价值信息。因此，绘制训练误差和验证误差也非常重要。
- en: 'For the second model:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个模型：
- en: '[PRE30]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Again, the training curves give better insights:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，训练曲线提供了更好的洞察：
- en: '![Training](img/00036.jpeg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![训练](img/00036.jpeg)'
- en: 'For the third model:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第三个模型：
- en: '[PRE31]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Refer to the following graph:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅下图：
- en: '![Training](img/00037.jpeg)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![训练](img/00037.jpeg)'
- en: Here we see the difference between train and valid, losses either due to a slight
    overfitting to the training data, or a difference between the training and test
    datasets.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们看到训练和验证的损失差异，可能是由于稍微的过拟合训练数据，或者训练和测试数据集之间的差异。
- en: 'The main causes of overfitting are as follows:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合的主要原因如下：
- en: '**Too small a dataset**: Collect more data'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集过小**：收集更多的数据。'
- en: '**Too high a learning rate**: The network is learning too quickly on earlier
    examples'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**学习率过高**：网络在早期的样本上学习得太快。'
- en: '**A lack of regularization**: Add more dropout (see next section), or a penalty
    on the norm of the weights in the loss function'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏正则化**：添加更多的 dropout（参见下一节），或在损失函数中对权重的范数施加惩罚。'
- en: '**Too small model**: Increase the number of filters/units in different layers'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型过小**：增加不同层中滤波器/单元的数量。'
- en: 'Validation loss and error gives a better estimate than training loss and error,
    which are more noisy, and during training, they are also used to decide which
    model parameters are the best:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 验证损失和误差比训练损失和误差更能准确估计模型的效果，因为训练损失和误差噪声较大，并且在训练过程中，它们还用来决定哪个模型参数是最优的：
- en: '**Simple model**: 6.96 % at epoch 518'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简单模型**：在第518个周期时，损失为6.96%。'
- en: '**MLP model**: 2.96 % at epoch 987'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLP模型**：在第987个周期时，损失为2.96%。'
- en: '**CNN model**: 1.06 % at epoch 722'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CNN模型**：在第722个周期时，损失为1.06%。'
- en: These results also indicate that the models might not improve much with further
    training.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果也表明，模型在进一步训练后可能不会有太大改进。
- en: 'Here''s a comparison of the three models'' validation losses:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这是三种模型验证损失的比较：
- en: '![Training](img/00038.jpeg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![Training](img/00038.jpeg)'
- en: Note that the MLP is still improving and the training has not finished, while
    the CNN and simple networks have converged.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，MLP模型仍在改进中，训练尚未结束，而CNN和简单网络已经收敛。
- en: With the selected model, you can easily compute the test loss and error on the
    test dataset to finalize it.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 使用已选择的模型，您可以轻松计算测试数据集上的测试损失和误差，从而最终确定模型。
- en: 'The last important concept of machine learning is hyperparameter tuning. An
    hyperparameter defines a parameter of the model that is not learned during training.
    Here are examples:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的最后一个重要概念是超参数调优。超参数定义了在训练过程中未学习到的模型参数。以下是一些示例：
- en: '[PRE32]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: For the learning rate, too slow a descent might prevent finding a more global
    minimum, while too fast a descent damages the final convergence. Finding the best
    initial learning rate is crucial. Then, it is common to decrease the learning
    rate after many iterations in order to have more precise fine-tuning of the model.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 对于学习率，下降过慢可能会阻止找到更全局的最小值，而下降过快则会破坏最终的收敛。找到最佳的初始学习率至关重要。然后，通常会在多次迭代后降低学习率，以便更精确地微调模型。
- en: Hyperparameter selection requires us to run the previous runs many times for
    different values of the hyperparameters; testing all combinations of hyperparameters
    can be done in a simple grid search, for example.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 超参数选择要求我们为不同的超参数值运行多次前面的实验；测试所有超参数的组合可以通过简单的网格搜索来实现。
- en: 'Here is an exercise for the reader:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个供读者练习的题目：
- en: Train the models with different hyperparameters and draw the training loss curves
    to see how hyperparameters influence the final loss.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用不同的超参数训练模型，并绘制训练损失曲线，以观察超参数如何影响最终损失。
- en: 'Visualize the content of the neurons of the first layer, once the model has
    been trained, to see what the features capture from the input image. For this
    task, compile a specific visualization function:'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模型训练完成后，您可以可视化第一层神经元的内容，以查看神经元从输入图像中提取的特征。为此任务，编写一个特定的可视化函数：
- en: '[PRE33]'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Dropout
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Dropout
- en: Dropout is a widely used technique to improve convergence and robustness of
    a neural net and prevent neural nets from overfitting. It consists of setting
    some random values to zero for the layers on which we'd like it to apply. It introduces
    some randomness in the data at every epoch.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout 是一种广泛使用的技术，用于提高神经网络的收敛性和鲁棒性，并防止神经网络过拟合。它通过将一些随机值设置为零，应用于我们希望其作用的层。它在每个周期引入一些数据的随机性。
- en: 'Usually, dropout is used before the fully connected layers and not used very
    often in convolutional layers. Let''s add the following lines before each of our
    two fully connected layers:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，dropout 用于全连接层之前，而在卷积层中使用得比较少。我们在两个全连接层之前添加以下代码：
- en: '[PRE34]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The full script is in `5-cnn-with-dropout.py`. After 1,000 iterations, the validation
    error of the CNN with dropout continues to drops down to 1.08%, while the validation
    error of the CNN without dropout will not go down by 1.22%.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的脚本位于`5-cnn-with-dropout.py`。经过1,000次迭代后，带有dropout的CNN的验证误差降至1.08%，而不带dropout的CNN的验证误差则停留在1.22%。
- en: Readers who would like to go further with dropout should have a look at maxout
    units. They work well with dropout and replace the tanh non-linearities to get
    even better results. As dropout does a kind of model averaging, maxout units try
    to find the optimal non-linearity to the problem.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 想要深入了解dropout的读者，应该看看maxout单元。它们与dropout一起工作，并替换tanh非线性函数，以获得更好的结果。由于dropout执行了一种模型平均，maxout单元试图找到问题的最佳非线性函数。
- en: Inference
  id: totrans-260
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推理
- en: Inference is the process of using the model to produce predictions.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 推理是使用模型进行预测的过程。
- en: 'For inference, the weight parameters do not need to be updated, so the inference
    function is simpler than the training function:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 对于推理，权重参数不需要更新，因此推理函数比训练函数更为简洁：
- en: '[PRE35]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Optimization and other update rules
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化和其他更新规则
- en: 'Learning rate is a very important parameter to set correctly. Too low a learning
    rate will make it difficult to learn and will train slower, while too high a learning
    rate will increase sensitivity to outlier values, increase the amount of noise
    in the data, train too fast to learn generalization, and get stuck in local minima:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率是一个非常重要的参数，必须正确设置。学习率过低会使得学习变得困难，且训练速度较慢；而学习率过高则会增加对异常值的敏感性，增加数据中的噪声，训练过快而无法进行有效的泛化，且可能陷入局部最小值：
- en: '![Optimization and other update rules](img/00039.jpeg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![优化和其他更新规则](img/00039.jpeg)'
- en: 'When training loss does not improve anymore for one or a few more iterations,
    the learning rate can be reduced by a factor:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练损失在一个或几个迭代后不再改进时，可以通过一个因子降低学习率：
- en: '![Optimization and other update rules](img/00040.jpeg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![优化和其他更新规则](img/00040.jpeg)'
- en: 'It helps the network learn fine-grained differences in the data, as shown when
    training residual networks ([Chapter 7](part0075_split_000.html#27GQ61-ccdadb29edc54339afcb9bdf9350ba6b
    "Chapter 7. Classifying Images with Residual Networks"), *Classifying Images with
    Residual Networks*):'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 它有助于网络学习数据中的细粒度差异，正如在训练残差网络时所展示的那样（[第7章](part0075_split_000.html#27GQ61-ccdadb29edc54339afcb9bdf9350ba6b
    "第7章 使用残差网络进行图像分类")，*使用残差网络进行图像分类*）：
- en: '![Optimization and other update rules](img/00041.jpeg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![优化和其他更新规则](img/00041.jpeg)'
- en: To check the training process, it is usual to print the norm of the parameters,
    the gradients, and the updates, as well as NaN values.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查训练过程，通常会打印参数的范数、梯度和更新，以及NaN值。
- en: 'The update rule seen in this chapter is the simplest form of update, known
    as **Stochastic Gradient Descent** (**SGD**). It is a good practice to clip the
    norm to avoid saturation and NaN values. The updates list given to the `theano`
    function becomes this:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中看到的更新规则是最简单的更新形式，称为**随机梯度下降法**（**SGD**）。为了避免饱和和NaN值，通常会将范数裁剪。传递给`theano`函数的更新列表如下：
- en: '[PRE36]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Some very simple variants have been experimented with in order to improve the
    descent, and are proposed in many deep learning libraries. Let's see them in Theano.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 一些非常简单的变体已被尝试用来改进下降，并在许多深度学习库中提出。我们来看一下它们在Theano中的实现。
- en: '**Momentum**'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '**动量**'
- en: For each parameter, a momentum (*v*, as velocity) is computed from the gradients
    accumulated over the iterations with a time decay. The previous momentum value
    is multiplied by a decay parameter between 0.5 and 0.9 (to be cross-validated)
    and added to the current gradient to provide the new momentum value.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个参数，都会从累积的梯度中计算动量（*v*，作为速度），并使用时间衰减。之前的动量值会乘以一个介于0.5和0.9之间的衰减参数（需交叉验证），然后与当前的梯度相加，得到新的动量值。
- en: 'The momentum of the gradients plays the role of a moment of inertia in the
    updates, in order to learn faster. The idea is also that oscillations in successive
    gradients will be canceled in the momentum, to move the parameter in a more direct
    path towards the solution:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度的动量在更新中起到了惯性力矩的作用，从而加速学习。其思路是，连续梯度中的振荡会在动量中被抵消，使得参数朝着解决方案的更直接路径移动：
- en: '![Optimization and other update rules](img/00042.jpeg)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![优化和其他更新规则](img/00042.jpeg)'
- en: 'The decay parameter between 0.5 and 0.9 is a hyperparameter usually referred
    to as the momentum, in an abuse of language:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 介于0.5和0.9之间的衰减参数是一个超参数，通常被称为动量，这里存在一种语言上的滥用：
- en: '[PRE37]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '**Nesterov Accelerated Gradient**'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '**Nesterov加速梯度**'
- en: 'Instead of adding *v* to the parameter, the idea is to add directory the future
    value of the momentum momentum `v - learning_rate g`, in order to have it compute
    the gradients in the next iteration directly at the next position:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 不是将*v*加到参数上，而是将动量`v - learning_rate g`的未来值直接加到参数上，以便在下一次迭代中直接计算下一位置的梯度：
- en: '[PRE38]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '**Adagrad**'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '**Adagrad**'
- en: 'This update rule, as well as the following rules consists of adapting the learning
    rate **parameter-wise** (differently for each parameter). The element-wise sum
    of squares of the gradients is accumulated into a shared variable for each parameter
    in order to decay the learning rate in an element-wise fashion:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这个更新规则，以及接下来的规则，包含了**逐参数**（对每个参数不同）地调整学习率。梯度的元素级平方和被积累到每个参数的共享变量中，以便按元素方式衰减学习率：
- en: '[PRE39]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '`Adagrad` is an aggressive method, and the next two rules, `AdaDelta` and `RMSProp`,
    try to reduce its aggression.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '`Adagrad`是一种激进的方法，接下来的两个规则，`AdaDelta`和`RMSProp`，尝试减少它的激进性。'
- en: '**AdaDelta**'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '**AdaDelta**'
- en: 'Two accumulators are created per parameter to accumulate the squared gradients
    and the updates in moving averages, parameterized by the decay `rho`:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 为每个参数创建两个累加器，用来积累平方梯度和移动平均中的更新，由衰减`rho`来参数化：
- en: '[PRE40]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '**RMSProp**'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '**RMSProp**'
- en: 'This updates rule is very effective in many cases. It is an improvement of
    the `Adagrad` update rule, using a moving average (parameterized by `rho`) to
    get a less aggressive decay:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 这个更新规则在许多情况下非常有效。它是`Adagrad`更新规则的改进，使用移动平均（由`rho`参数化）来获得较少的激进衰减：
- en: '[PRE41]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '**Adam**'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '**Adam**'
- en: 'This is `RMSProp` with momemtum, one of the best choices for the learning rule.
    The time step is kept track of in a shared variable, `t`. Two moving averages
    are computed, one for the past squared gradients, and the other for past gradient:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 这是带动量的`RMSProp`，是最好的学习规则选择之一。时间步长由共享变量`t`跟踪。计算了两个移动平均，一个用于过去的平方梯度，另一个用于过去的梯度：
- en: '[PRE42]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: To conclude on update rules, many recent research papers still prefer the simple
    SGD rule, and work the architecture and the initialization of the layers with
    the correct learning rate. For more complex networks, or if the data is sparse,
    the adaptive learning rate methods are better, sparing you the pain of finding
    the right learning rate.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下更新规则，许多最近的研究论文仍然更倾向于使用简单的SGD规则，并通过正确的学习率来调整网络架构和层的初始化。对于更复杂的网络，或者当数据稀疏时，适应性学习率方法更好，可以避免你在寻找合适学习率时的痛苦。
- en: Related articles
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 相关文章
- en: 'You can refer to the following documents for more insights into the topics
    covered in this chapter:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以参考以下文档，获取更多关于本章涵盖主题的见解：
- en: '*Deeplearning.net Theano tutorials: Single layer* ([http://deeplearning.net/tutorial/logreg.html](http://deeplearning.net/tutorial/logreg.html)),
    MLP ([http://deeplearning.net/tutorial/mlp.html](http://deeplearning.net/tutorial/mlp.html)),
    Convolutions ([http://deeplearning.net/tutorial/lenet.html](http://deeplearning.net/tutorial/lenet.html))'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Deeplearning.net Theano教程：单层*（[http://deeplearning.net/tutorial/logreg.html](http://deeplearning.net/tutorial/logreg.html)），MLP（[http://deeplearning.net/tutorial/mlp.html](http://deeplearning.net/tutorial/mlp.html)），卷积（[http://deeplearning.net/tutorial/lenet.html](http://deeplearning.net/tutorial/lenet.html)）'
- en: 'All loss functions: for classification, regression, and joint embedding ([http://christopher5106.github.io/deep/learning/2016/09/16/about-loss-functions-multinomial-logistic-logarithm-cross-entropy-square-errors-euclidian-absolute-frobenius-hinge.html](http://christopher5106.github.io/deep/learning/2016/09/16/about-loss-functions-multinomial-logistic-logarithm-cross-entropy-square-errors-euclidian-absolute-frobenius-hinge.html))'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有损失函数：用于分类、回归和联合嵌入（[http://christopher5106.github.io/deep/learning/2016/09/16/about-loss-functions-multinomial-logistic-logarithm-cross-entropy-square-errors-euclidian-absolute-frobenius-hinge.html](http://christopher5106.github.io/deep/learning/2016/09/16/about-loss-functions-multinomial-logistic-logarithm-cross-entropy-square-errors-euclidian-absolute-frobenius-hinge.html)）
- en: The last example corresponds to Yann Lecun's five-5 layer network as in Gradient
    based learning applied to document recognition ([http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf))
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一个例子对应于Yann Lecun的五层网络，如在《基于梯度的学习应用于文档识别》一文中所示（[http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)）
- en: Understanding the difficulty of training deep feedforward neural networks, Xavier
    Glorot, Yoshua Bengio, 2010
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解训练深度前馈神经网络的难度，Xavier Glorot, Yoshua Bengio，2010
- en: 'Maxout Networks: Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron
    Courville, Yoshua Bengio 2013'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maxout网络：Ian J. Goodfellow，David Warde-Farley，Mehdi Mirza，Aaron Courville，Yoshua
    Bengio 2013
- en: 'An overview of gradient descent algorithms: [http://sebastianruder.com/optimizing-gradient-descent/](http://sebastianruder.com/optimizing-gradient-descent/)'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度下降算法概述：[http://sebastianruder.com/optimizing-gradient-descent/](http://sebastianruder.com/optimizing-gradient-descent/)
- en: CS231n Convolutional Neural Networks for Visual Recognition, [http://cs231n.github.io/neural-networks-3/](http://cs231n.github.io/neural-networks-3/)
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CS231n 视觉识别卷积神经网络，[http://cs231n.github.io/neural-networks-3/](http://cs231n.github.io/neural-networks-3/)
- en: Yes you should understand backprop, Andrej Karpathy, 2016, [https://medium.com/@karpathy/](https://medium.com/@karpathy/)
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是的，你应该理解反向传播，Andrej Karpathy，2016，[https://medium.com/@karpathy/](https://medium.com/@karpathy/)
- en: 'Striving for Simplicity: The All Convolutional Net, Jost Tobias Springenberg,
    Alexey Dosovitskiy, Thomas Brox, Martin Riedmiller, 2014'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 追求简单：全卷积网络，Jost Tobias Springenberg，Alexey Dosovitskiy，Thomas Brox，Martin Riedmiller，2014
- en: Fractional Max-Pooling, Benjamin Graham, 2014
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分数最大池化，Benjamin Graham，2014
- en: 'Batch Normalization: Accelerating Deep Network Training by Reducing Internal
    Covariate Shift, Sergey Ioffe, Christian Szegedy, 2015'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量归一化：通过减少内部协变量偏移加速深度网络训练，Sergey Ioffe，Christian Szegedy，2015
- en: Visualizing and Understanding Convolutional Networks, Matthew D Zeiler, Rob
    Fergus, 2013
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化与理解卷积网络，Matthew D Zeiler，Rob Fergus，2013
- en: Going Deeper with Convolutions, Christian Szegedy, Wei Liu, Yangqing Jia, Pierre
    Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew
    Rabinovich, 2014
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入卷积，Christian Szegedy，Wei Liu，Yangqing Jia，Pierre Sermanet，Scott Reed，Dragomir
    Anguelov，Dumitru Erhan，Vincent Vanhoucke，Andrew Rabinovich，2014
- en: Summary
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Classification is a very wide topic in machine learning. It consists of predicting
    a class or a category, as we have shown with our handwritten digits example. In
    [Chapter 7](part0075_split_000.html#27GQ61-ccdadb29edc54339afcb9bdf9350ba6b "Chapter 7. Classifying
    Images with Residual Networks"), *Classifying Images with Residual Networks*,
    we'll see how to classify a wider set of natural images and objects.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是机器学习中一个非常广泛的话题。它包括预测一个类别或一个类，如我们在手写数字示例中所展示的那样。在[第7章](part0075_split_000.html#27GQ61-ccdadb29edc54339afcb9bdf9350ba6b
    "第7章. 使用残差网络分类图像")，*使用残差网络分类图像*，我们将看到如何分类更广泛的自然图像和物体。
- en: Classification can be applied to different problems and the cross-entropy/negative
    log likelihood is the common loss function to solve them through gradient descent.
    There are many other loss functions for problems such as regression (mean square
    error loss) or unsupervised joint learning (hinge loss).
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 分类可以应用于不同的问题，交叉熵/负对数似然是通过梯度下降解决这些问题的常见损失函数。对于回归问题（均方误差损失）或无监督联合学习（铰链损失）等问题，还有许多其他损失函数。
- en: In this chapter, we have been using a very simple update rule as gradient descent
    named stochastic gradient descent, and presented some other gradient descent variants
    (`Momentum`, `Nesterov`, `RMSprop`, `ADAM`, `ADAGRAD`, `ADADELTA`). There has
    been some research into second order optimizations, such as Hessian Free, or K-FAC,
    which provided better results in deep or recurrent networks but remain complex
    and costly, and have not be widely adopted until now. Researchers have been looking
    for new architectures that perform better without the need for such optimization
    techniques.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们使用了一个非常简单的更新规则作为梯度下降，命名为随机梯度下降，并介绍了其他一些梯度下降变体（`Momentum`、`Nesterov`、`RMSprop`、`ADAM`、`ADAGRAD`、`ADADELTA`）。有一些关于二阶优化的研究，例如
    Hessian Free 或 K-FAC，它们在深度或循环网络中提供了更好的结果，但仍然复杂且代价高昂，直到现在仍未得到广泛采用。研究人员一直在寻找不需要这些优化技术的、更好的新架构。
- en: 'When training networks, I would strongly encourage you to use the following
    two Linux commands:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练网络时，我强烈建议你使用以下两个 Linux 命令：
- en: '**Screen**: To detach your shell, run scripts on the server and reconnect later,
    since training usually takes a few days.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Screen**：分离你的终端，运行服务器上的脚本，并稍后重新连接，因为训练通常需要几天时间。'
- en: '**Tee**: To which you pipe the output of your running program, in order to
    save the displayed results to a file, while continuing to visualize the output
    in your shell. This will spare your code the burden of log functions and frameworks.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tee**：将正在运行程序的输出传递给它，以便在继续在终端中显示输出的同时将显示的结果保存到文件中。这将减轻你的代码中日志功能和框架的负担。'
