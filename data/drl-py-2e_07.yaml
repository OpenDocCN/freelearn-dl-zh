- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Deep Learning Foundations
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习基础
- en: So far in the previous chapters, we have learned how several reinforcement learning
    algorithms work and how they find the optimal policy. In the upcoming chapters,
    we will learn about **Deep Reinforcement Learning** (**DRL**), which is a combination
    of deep learning and reinforcement learning. To understand DRL, we need to have
    a strong foundation in deep learning. So, in this chapter, we will learn several
    important deep learning algorithms.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们已经学习了几个强化学习算法是如何工作的，以及它们如何找到最优策略。在接下来的章节中，我们将学习**深度强化学习**（**DRL**），它是深度学习和强化学习的结合。为了理解DRL，我们需要具备深度学习的坚实基础。因此，在本章中，我们将学习几种重要的深度学习算法。
- en: Deep learning is a subset of machine learning and it is all about neural networks.
    Deep learning has been around for a decade, but the reason it is so popular right
    now is because of the computational advancements and availability of huge volumes
    of data. With this huge volume of data, deep learning algorithms can outperform
    classic machine learning algorithms.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个子集，核心是神经网络。深度学习已经存在了十多年，但现在之所以如此流行，是因为计算能力的进步和海量数据的可获取性。借助这些大量数据，深度学习算法能够超越经典的机器学习算法。
- en: We will start off the chapter by understanding what biological and artificial
    neurons are, and then we will learn about **Artificial Neural Networks** (**ANN**s)
    and how to implement them. Moving forward, we will learn about several interesting
    deep learning algorithms such as the **Recurrent Neural Network** (**RNN**), **Long
    Short-Term Memory** (**LSTM**), **Convolutional Neural Network** (**CNN**), and
    **Generative Adversarial Network** (**GAN**).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从理解生物神经元和人工神经元开始，然后学习**人工神经网络**（**ANN**）及其实现方法。接下来，我们将学习一些有趣的深度学习算法，如**循环神经网络**（**RNN**）、**长短期记忆网络**（**LSTM**）、**卷积神经网络**（**CNN**）和**生成对抗网络**（**GAN**）。
- en: 'In this chapter, we will learn about the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将学习以下内容：
- en: Biological and artificial neurons
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生物神经元与人工神经元
- en: ANNs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ANNs
- en: RNNs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RNNs
- en: LSTM RNNs
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LSTM RNNs
- en: CNNs
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNNs
- en: GANs
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GANs
- en: Let's begin the chapter by understanding how biological and artificial neurons
    work.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从理解生物神经元和人工神经元的工作原理开始本章内容。
- en: Biological and artificial neurons
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生物神经元与人工神经元
- en: Before going ahead, first, we will explore what neurons are and how neurons
    in our brain actually work, and then we will learn about artificial neurons.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，我们首先要探索神经元是什么，以及我们大脑中的神经元是如何工作的，然后再学习人工神经元。
- en: A **neuron** can be defined as the basic computational unit of the human brain.
    Neurons are the fundamental units of our brain and nervous system. Our brain encompasses
    approximately 100 billion neurons. Each and every neuron is connected to one another
    through a structure called a **synapse**, which is accountable for receiving input
    from the external environment via sensory organs, for sending motor instructions
    to our muscles, and for performing other activities.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**神经元**可以被定义为人脑的基本计算单元。神经元是我们大脑和神经系统的基本单位。我们的大脑大约包含1000亿个神经元。每个神经元通过一种叫做**突触**的结构与其他神经元相连接，突触负责接收来自外部环境的输入信息（通过感觉器官），向我们的肌肉发送运动指令，并执行其他活动。'
- en: A neuron can also receive inputs from other neurons through a branchlike structure
    called a **dendrite**. These inputs are strengthened or weakened; that is, they
    are weighted according to their importance and then they are summed together in
    the cell body called the **soma**. From the cell body, these summed inputs are
    processed and move through the **axons** and are sent to the other neurons.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 神经元还可以通过一种叫做**树突**的分支结构从其他神经元接收输入。这些输入会被加强或削弱，也就是说，它们根据重要性进行加权，然后在细胞体（**胞体**）中相加。从细胞体中，这些加权后的输入会被处理并通过**轴突**传递，最终送到其他神经元。
- en: '*Figure 7.1* shows a basic single biological neuron:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.1* 显示了一个基本的单一生物神经元：'
- en: '![](img/B15558_07_01.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_01.png)'
- en: 'Figure 7.1: Biological neuron'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：生物神经元
- en: 'Now, let''s see how artificial neurons work. Let''s suppose we have three inputs
    *x*[1], *x*[2], and *x*[3], to predict the output *y*. These inputs are multiplied
    by weights *w*[1], *w*[2], and *w*[3] and are summed together as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看人工神经元是如何工作的。假设我们有三个输入 *x*[1]、*x*[2] 和 *x*[3]，用来预测输出 *y*。这些输入分别乘以权重 *w*[1]、*w*[2]
    和 *w*[3]，并按以下方式相加：
- en: '![](img/B15558_07_001.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_001.png)'
- en: 'But why are we multiplying these inputs by weights? Because all of the inputs
    are not equally important in calculating the output *y*. Let''s say that *x*[2]
    is more important in calculating the output compared to the other two inputs.
    Then, we assign a higher value to *w*[2] than the other two weights. So, upon
    multiplying weights with inputs, *x*[2] will have a higher value than the other
    two inputs. In simple terms, weights are used for strengthening the inputs. After
    multiplying inputs with the weights, we sum them together and we add a value called
    bias, *b*:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，为什么要将这些输入与权重相乘呢？因为在计算输出 *y* 时，并不是所有输入都同等重要。假设 *x*[2] 在计算输出时比其他两个输入更重要。那么，我们会为
    *w*[2] 分配一个比其他两个权重更高的值。这样，在将权重与输入相乘后，*x*[2] 的值将大于其他两个输入。简单来说，权重是用来增强输入的。在将输入与权重相乘后，我们将它们加在一起，再加上一个称为偏置
    *b* 的值：
- en: '![](img/B15558_07_002.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_002.png)'
- en: 'If you look at the preceding equation closely, it may look familiar. Doesn''t
    *z* look like the equation of linear regression? Isn''t it just the equation of
    a straight line? We know that the equation of a straight line is given as:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细观察前面的公式，它可能看起来很熟悉。*z* 看起来像是线性回归的公式，不是吗？它不就是一条直线的方程吗？我们知道，直线方程是这样的：
- en: '![](img/B15558_07_003.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_003.png)'
- en: Here, *m* is the weights (coefficients), *x* is the input, and *b* is the bias
    (intercept).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*m* 是权重（系数），*x* 是输入，*b* 是偏置（截距）。
- en: 'Well, yes. Then, what is the difference between neurons and linear regression?
    In neurons, we introduce non-linearity to the result, *z*, by applying a function
    *f*(.) called the **activation** or **transfer function**. Thus, our output becomes:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。那么，神经元和线性回归有什么区别呢？在神经元中，我们通过应用一个叫做**激活**或**传输函数**的函数 *f*(.)，为结果 *z* 引入了非线性。因此，我们的输出变成了：
- en: '![](img/B15558_07_004.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_004.png)'
- en: '*Figure 7.2* shows a single artificial neuron:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.2* 显示了一个单一的人工神经元：'
- en: '![](img/B15558_07_02.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_02.png)'
- en: 'Figure 7.2: Artificial neuron'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2：人工神经元
- en: So, a neuron takes the input, *x*, multiples it by weights, *w,* and adds bias,
    *b,* forms *z*, and then we apply the activation function on *z* and get the output,
    *y*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，一个神经元接收输入 *x*，将其与权重 *w* 相乘，再加上偏置 *b*，形成 *z*，然后我们对 *z* 应用激活函数，得到输出 *y*。
- en: ANN and its layers
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工神经网络及其层次结构
- en: While neurons are really cool, we cannot just use a single neuron to perform
    complex tasks. This is the reason our brain has billions of neurons, stacked in
    layers, forming a network. Similarly, artificial neurons are arranged in layers.
    Each and every layer will be connected in such a way that information is passed
    from one layer to another.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然神经元非常酷，但我们不能仅依靠一个神经元来执行复杂任务。这就是我们大脑拥有数十亿个神经元，按层堆叠形成网络的原因。同样，人工神经元也被按层排列。每一层都将以某种方式连接，以便信息从一层传递到另一层。
- en: 'A typical ANN consists of the following layers:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的人工神经网络包括以下层：
- en: Input layer
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入层
- en: Hidden layer
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐藏层
- en: Output layer
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出层
- en: Each layer has a collection of neurons, and the neurons in one layer interact
    with all the neurons in the other layers. However, neurons in the same layer will
    not interact with one another. This is simply because neurons from the adjacent
    layers have connections or edges between them; however, neurons in the same layer
    do not have any connections. We use the term **nodes** or **units** to represent
    the neurons in the ANN.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 每一层都有一组神经元，且一层的神经元与其他层的所有神经元都有交互。然而，同一层的神经元之间不会相互作用。这是因为相邻层的神经元之间有连接或边缘，但同一层的神经元之间没有任何连接。我们用**节点**或**单元**来表示人工神经网络中的神经元。
- en: '*Figure 7.3* shows a typical ANN:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.3* 显示了一个典型的人工神经网络（ANN）：'
- en: '![](img/B15558_07_03.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_03.png)'
- en: 'Figure 7.3: ANN'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3：人工神经网络（ANN）
- en: Input layer
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输入层
- en: The **input layer** is where we feed input to the network. The number of neurons
    in the input layer is the number of inputs we feed to the network. Each input
    will have some influence on predicting the output. However, no computation is
    performed in the input layer; it is just used for passing information from the
    outside world to the network.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入层** 是我们将输入数据提供给网络的地方。输入层中神经元的数量就是我们提供给网络的输入数量。每个输入都会对预测输出产生一定影响。然而，输入层并不执行任何计算；它仅用于将外界的信息传递给网络。'
- en: Hidden layer
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隐藏层
- en: Any layer between the input layer and the output layer is called a **hidden
    layer**. It processes the input received from the input layer. The hidden layer
    is responsible for deriving complex relationships between input and output. That
    is, the hidden layer identifies the pattern in the dataset. It is majorly responsible
    for learning the data representation and for extracting the features.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 输入层和输出层之间的任何层都称为**隐藏层**。它处理从输入层接收到的输入。隐藏层负责推导输入和输出之间的复杂关系。也就是说，隐藏层识别数据集中的模式。它主要负责学习数据表示和提取特征。
- en: There can be any number of hidden layers; however, we have to choose a number
    of hidden layers according to our use case. For a very simple problem, we can
    just use one hidden layer, but while performing complex tasks such as image recognition,
    we use many hidden layers, where each layer is responsible for extracting important
    features. The network is called a **deep neural network** when we have many hidden layers.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏层的数量可以是任意的；然而，我们必须根据使用场景选择隐藏层的数量。对于非常简单的问题，我们只需要使用一个隐藏层，但在执行复杂任务（如图像识别）时，我们使用许多隐藏层，每一层负责提取重要特征。当我们有许多隐藏层时，网络被称为**深度神经网络**。
- en: Output layer
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输出层
- en: After processing the input, the hidden layer sends its result to the output
    layer. As the name suggests, the output layer emits the output. The number of
    neurons in the output layer is based on the type of problem we want our network
    to solve.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理完输入后，隐藏层将其结果发送到输出层。顾名思义，输出层发出最终输出。输出层的神经元数量取决于我们希望网络解决的问题类型。
- en: If it is a binary classification, then the number of neurons in the output layer
    is one, and it tells us which class the input belongs to. If it is a multi-class
    classification say, with five classes, and if we want to get the probability of
    each class as an output, then the number of neurons in the output layer is five,
    each emitting the probability. If it is a regression problem, then we have one
    neuron in the output layer.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果是二分类问题，则输出层中的神经元数量为 1，表示输入属于哪个类别。如果是多分类问题，比如有五个类别，并且我们希望得到每个类别的概率作为输出，则输出层中的神经元数量为五，每个神经元输出一个概率。如果是回归问题，则输出层只有一个神经元。
- en: Exploring activation functions
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索激活函数
- en: An **activation function**, also known as a **transfer function**, plays a vital
    role in neural networks. It is used to introduce non-linearity in neural networks.
    As we learned before, we apply the activation function to the input, which is
    multiplied by weights and added to the bias, that is, *f*(*z*), where *z = (input
    * weights) + bias* and *f*(.) is the activation function.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**激活函数**，也称为**传输函数**，在神经网络中起着至关重要的作用。它用于引入神经网络中的非线性。正如我们之前所学，我们将激活函数应用于输入，输入会被权重乘以并加上偏置，即*f*(*z*)，其中
    *z = (输入 * 权重) + 偏置*，*f*(.) 是激活函数。'
- en: If we do not apply the activation function, then a neuron simply resembles the
    linear regression. The aim of the activation function is to introduce a non-linear
    transformation to learn the complex underlying patterns in the data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不应用激活函数，那么神经元就仅仅类似于线性回归。激活函数的目的是引入非线性变换，以学习数据中复杂的潜在模式。
- en: Now let's look at some of the interesting commonly used activation functions.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一些常用的激活函数。
- en: The sigmoid function
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Sigmoid 函数
- en: 'The **sigmoid function** is one of the most commonly used activation functions.
    It scales the value between 0 and 1\. The sigmoid function can be defined as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sigmoid 函数**是最常用的激活函数之一。它将值缩放到 0 和 1 之间。Sigmoid 函数可以定义如下：'
- en: '![](img/B15558_07_005.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_005.png)'
- en: 'It is an S-shaped curve shown in *Figure 7.4*:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 它是一个 S 形曲线，如*图 7.4*所示：
- en: '![](img/B15558_07_04.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_04.png)'
- en: 'Figure 7.4: Sigmoid function'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4：Sigmoid 函数
- en: It is differentiable, meaning that we can find the slope of the curve at any
    two points. It is **monotonic**, which implies it is either entirely non-increasing
    or non-decreasing. The sigmoid function is also known as a **logistic** function.
    As we know that probability lies between 0 and 1, and since the sigmoid function
    squashes the value between 0 and 1, it is used for predicting the probability
    of output.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 它是可微的，这意味着我们可以在任意两个点之间找到曲线的斜率。它是**单调**的，这意味着它要么完全是非递增的，要么是非递减的。Sigmoid 函数也被称为**逻辑斯蒂**函数。我们知道概率值介于
    0 和 1 之间，而由于 Sigmoid 函数将值压缩到 0 到 1 之间，它被用于预测输出的概率。
- en: The tanh function
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: tanh 函数
- en: 'A **hyperbolic tangent** (**tanh**) function outputs the value between -1 to
    +1 and is expressed as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**双曲正切**（**tanh**）函数输出的值介于-1到+1之间，表示如下：'
- en: '![](img/B15558_07_006.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_006.png)'
- en: 'It also resembles the S-shaped curve. Unlike the sigmoid function, which is
    centered on 0.5, the tanh function is 0-centered, as shown in the following diagram:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 它也类似于S形曲线。与sigmoid函数中心在0.5不同，tanh函数是以0为中心，如下图所示：
- en: '![](img/B15558_07_05.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_05.png)'
- en: 'Figure 7.5: tanh function'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5：tanh函数
- en: The Rectified Linear Unit function
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 修正线性单元函数
- en: 'The **Rectified Linear Unit** (**ReLU**) function is another one of the most
    commonly used activation functions. It outputs a value from zero to infinity.
    It is basically a **piecewise** function and can be expressed as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**修正线性单元**（**ReLU**）函数是另一个最常用的激活函数之一。它输出一个从零到无穷大的值。它本质上是一个**分段**函数，可以表示如下：'
- en: '![](img/B15558_07_007.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_007.png)'
- en: 'That is, *f*(*x*) returns zero when the value of *x* is less than zero and
    *f*(*x*) returns *x* when the value of *x* is greater than or equal to zero. It
    can also be expressed as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，当*x*的值小于零时，*f*(*x*)返回零；当*x*的值大于或等于零时，*f*(*x*)返回*x*。它也可以表示如下：
- en: '![](img/B15558_07_008.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_008.png)'
- en: '*Figure 7.6* shows the ReLU function:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.6*显示了ReLU函数：'
- en: '![](img/B15558_07_06.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_06.png)'
- en: 'Figure 7.6: ReLU function'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6：ReLU函数
- en: As we can see in the preceding diagram, when we feed any negative input to the
    ReLU function, it converts the negative input to zero.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在前面的图示中看到的，当我们将任何负输入传递给ReLU函数时，它会将负输入转换为零。
- en: The softmax function
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: softmax函数
- en: The **softmax function** is basically the generalization of the sigmoid function.
    It is usually applied to the final layer of the network and while performing multi-class
    classification tasks. It gives the probabilities of each class for being output
    and thus, the sum of softmax values will always equal 1.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**softmax函数**本质上是sigmoid函数的推广。它通常应用于网络的最后一层，并且在执行多类分类任务时使用。它给出每个类别的输出概率，因此，softmax值的总和总是等于1。'
- en: 'It can be represented as follows:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以表示如下：
- en: '![](img/B15558_07_009.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_009.png)'
- en: 'As shown in the *Figure 7.7*, the softmax function converts its inputs to probabilities:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图7.7*所示，softmax函数将其输入转换为概率：
- en: '![](img/B15558_07_07.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_07.png)'
- en: 'Figure 7.7: Softmax function'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7：Softmax函数
- en: Now that we have learned about different activation functions, in the next section,
    we will learn about forward propagation in ANNs.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了不同的激活函数，在接下来的部分中，我们将学习人工神经网络（ANNs）中的前向传播。
- en: Forward propagation in ANNs
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工神经网络中的前向传播
- en: 'In this section, we will see how an ANN learns where neurons are stacked up
    in layers. The number of layers in a network is equal to the number of hidden
    layers plus the number of output layers. We don''t take the input layer into account
    when calculating the number of layers in a network. Consider a two-layer neural
    network with one input layer, *x*, one hidden layer, *h*, and one output layer,
    *y*, as shown in the following diagram:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看到人工神经网络如何学习，其中神经元堆叠在不同的层中。网络中的层数等于隐藏层的数量加上输出层的数量。在计算网络的层数时，我们不考虑输入层。考虑一个包含一个输入层*x*、一个隐藏层*h*和一个输出层*y*的两层神经网络，如下图所示：
- en: '![](img/B15558_07_08.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_08.png)'
- en: 'Figure 7.8: Forward propagation in ANN'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8：ANN中的前向传播
- en: Let's consider we have two inputs, *x*[1] and *x*[2], and we have to predict
    the output, ![](img/B15558_07_010.png). Since we have two inputs, the number of
    neurons in the input layer is two. We set the number of neurons in the hidden
    layer to four, and the number of neurons in the output layer to one. Now, the
    inputs are multiplied by weights, and then we add bias and propagate the resultant
    value to the hidden layer where the activation function is applied.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有两个输入，*x*[1]和*x*[2]，我们需要预测输出，![](img/B15558_07_010.png)。由于我们有两个输入，输入层中的神经元数量为两个。我们将隐藏层的神经元数量设为四个，输出层的神经元数量设为一个。现在，输入会与权重相乘，然后我们加上偏差，并将结果值传递到隐藏层，在那里应用激活函数。
- en: Before that, we need to initialize the weight matrix. In the real world, we
    don't know which input is more important than the other so that we can weight
    them and compute the output. Therefore, we randomly initialize the weights and
    bias value. The weight and the bias value between the input to the hidden layer
    are represented by *W*[xh] and *b*[h], respectively. What about the dimensions
    of the weight matrix? The dimensions of the weight matrix must be *the number
    of neurons in the current layer* x *the number of neurons in the next layer*.
    Why is that?
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前，我们需要初始化权重矩阵。在实际中，我们不知道哪些输入比其他输入更重要，能够进行加权并计算输出。因此，我们随机初始化权重和偏置值。从输入层到隐藏层之间的权重和偏置值分别表示为
    *W*[xh] 和 *b*[h]。那权重矩阵的维度呢？权重矩阵的维度必须是 *当前层神经元的数量* x *下一层神经元的数量*。为什么是这样呢？
- en: 'Because it is a basic matrix multiplication rule. To multiply any two matrices,
    *AB*, the number of columns in matrix *A* must be equal to the number of rows
    in matrix *B*. So, the dimension of the weight matrix, *W*[xh], should be *the
    number of neurons in the input layer* x *the number of neurons in the hidden layer*,
    that is, 2 x 4:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 因为这是一个基本的矩阵乘法规则。要乘以任意两个矩阵 *AB*，矩阵 *A* 的列数必须等于矩阵 *B* 的行数。所以，权重矩阵 *W*[xh] 的维度应该是
    *输入层神经元的数量* x *隐藏层神经元的数量*，即 2 x 4：
- en: '![](img/B15558_07_011.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_011.png)'
- en: 'The preceding equation represents, ![](img/B15558_07_012.png). Now, this is
    passed to the hidden layer. In the hidden layer, we apply an activation function
    to *z*[1]. Let''s use the sigmoid ![](img/B15558_07_013.png) activation function.
    Then, we can write:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 上述方程表示， ![](img/B15558_07_012.png)。现在，这个值传递到隐藏层。在隐藏层，我们对 *z*[1] 应用激活函数。我们使用
    sigmoid 激活函数 ![](img/B15558_07_013.png)。然后，我们可以写成：
- en: '![](img/B15558_07_014.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_014.png)'
- en: 'After applying the activation function, we again multiply result *a*[1] by
    a new weight matrix and add a new bias value that is flowing between the hidden
    layer and the output layer. We can denote this weight matrix and bias as *W*[hy]
    and *b*[y], respectively. The dimension of the weight matrix, *W*[hy], will be
    *the number of neurons in the hidden layer* x *the number of neurons in the output
    layer*. Since we have four neurons in the hidden layer and one neuron in the output
    layer, the *W*[hy] matrix dimension will be 4 x 1\. So, we multiply *a*[1] by
    the weight matrix, *W*[hy], and add bias, *b*[y], and pass the result *z*[2] to
    the next layer, which is the output layer:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 应用激活函数后，我们再次将结果 *a*[1] 与新的权重矩阵相乘，并加上在隐藏层和输出层之间流动的新偏置值。我们可以分别将这个权重矩阵和偏置表示为 *W*[hy]
    和 *b*[y]。权重矩阵 *W*[hy] 的维度是 *隐藏层神经元的数量* x *输出层神经元的数量*。由于我们在隐藏层有四个神经元，输出层有一个神经元，*W*[hy]
    的矩阵维度将是 4 x 1。因此，我们将 *a*[1] 与权重矩阵 *W*[hy] 相乘，并加上偏置 *b*[y]，然后将结果 *z*[2] 传递给下一个层，即输出层：
- en: '![](img/B15558_07_015.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_015.png)'
- en: 'Now, in the output layer, we apply the sigmoid function to *z*[2], which will
    result in an output value:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在输出层，我们对 *z*[2] 应用 sigmoid 函数，得到一个输出值：
- en: '![](img/B15558_07_016.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_016.png)'
- en: 'This whole process from the input layer to the output layer is known as **forward
    propagation**. Thus, in order to predict the output value, inputs are propagated
    from the input layer to the output layer. During this propagation, they are multiplied
    by their respective weights on each layer and an activation function is applied
    on top of them. The complete forward propagation steps are given as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 从输入层到输出层的整个过程称为 **前向传播**。因此，为了预测输出值，输入从输入层传播到输出层。在传播过程中，它们会乘以每一层上的各自权重，并应用激活函数。完整的前向传播步骤如下所示：
- en: '![](img/B15558_07_011.png)![](img/B15558_07_014.png)![](img/B15558_07_015.png)![](img/B15558_07_016.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_011.png)![](img/B15558_07_014.png)![](img/B15558_07_015.png)![](img/B15558_07_016.png)'
- en: 'The preceding forward propagation steps can be implemented in Python as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的前向传播步骤可以通过以下 Python 代码实现：
- en: '[PRE0]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Forward propagation is cool, isn''t it? But how do we know whether the output
    generated by the neural network is correct? We define a new function called the
    **cost function** (*J*), also known as the **loss function** (*L*), which tells
    us how well our neural network is performing. There are many different cost functions.
    We will use the mean squared error as a cost function, which can be defined as
    the mean of the squared difference between the actual output and the predicted
    output:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 正向传播很酷，对吧？但我们怎么知道神经网络生成的输出是否正确呢？我们定义了一个新的函数，称为**成本函数**（*J*），也叫**损失函数**（*L*），它告诉我们神经网络的表现如何。成本函数有很多种不同的类型。我们将使用均方误差作为成本函数，可以定义为实际输出和预测输出之间平方差的平均值：
- en: '![](img/B15558_07_021.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_021.png)'
- en: Here, *n* is the number of training samples, *y* is the actual output, and ![](img/B15558_07_022.png)
    is the predicted output.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*n*是训练样本的数量，*y*是实际输出，![](img/B15558_07_022.png)是预测输出。
- en: Okay, so we learned that a cost function is used for assessing our neural network;
    that is, it tells us how good our neural network is at predicting the output.
    But the question is where is our network actually learning? In forward propagation,
    the network is just trying to predict the output. But how does it learn to predict
    the correct output? In the next section, we will examine this.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们了解到成本函数是用来评估神经网络的，也就是说，它告诉我们神经网络在预测输出方面的好坏。但是问题是，我们的网络到底是怎么学习的呢？在正向传播中，网络只是试图预测输出。那么它是如何学习预测正确的输出呢？在下一部分，我们将探讨这个问题。
- en: How does an ANN learn?
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络是如何学习的？
- en: If the cost or loss is very high, then it means that our network is not predicting
    the correct output. So, our objective is to minimize the cost function so that
    our neural network predictions will be better. How can we minimize the cost function?
    That is, how can we minimize the loss/cost? We learned that the neural network
    makes predictions using forward propagation. So, if we can change some values
    in the forward propagation, we can predict the correct output and minimize the
    loss. But what values can we change in the forward propagation? Obviously, we
    can't change input and output. We are now left with weights and bias values. Remember
    that we just initialized weight matrices randomly. Since the weights are random,
    they are not going to be perfect. Now, we will update these weight matrices (*W*[xh]
    and *W*[hy]) in such a way that our neural network gives a correct output. How
    do we update these weight matrices? Here comes a new technique called **gradient
    descent**.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果成本或损失非常高，那么说明我们的网络没有预测出正确的输出。因此，我们的目标是最小化成本函数，使得神经网络的预测更加准确。我们如何最小化成本函数呢？也就是说，我们如何最小化损失/成本呢？我们已经了解到，神经网络是通过正向传播来进行预测的。那么，如果我们能够在正向传播中改变一些值，我们就能预测出正确的输出并最小化损失。但我们可以改变正向传播中的哪些值呢？显然，我们不能改变输入和输出。现在，我们剩下的就是权重和偏置值。记住，我们刚开始是随机初始化了权重矩阵。由于这些权重是随机的，它们不可能是完美的。现在，我们将更新这些权重矩阵（*W*[xh]
    和 *W*[hy]），使得我们的神经网络能够给出正确的输出。我们如何更新这些权重矩阵呢？这时出现了一种新技术，叫做**梯度下降法**。
- en: With gradient descent, the neural network learns the optimal values of the randomly
    initialized weight matrices. With the optimal values of weights, our network can
    predict the correct output and minimize the loss.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 通过梯度下降法，神经网络可以学习到随机初始化的权重矩阵的最优值。有了这些最优的权重值，我们的网络就可以预测正确的输出并最小化损失。
- en: Now, we will explore how the optimal values of weights are learned using gradient
    descent. Gradient descent is one of the most commonly used optimization algorithms.
    It is used for minimizing the cost function, which allows us to minimize the error
    and obtain the lowest possible error value. But how does gradient descent find
    the optimal weights? Let's begin with an analogy.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将探讨如何使用梯度下降法学习权重的最优值。梯度下降法是最常用的优化算法之一。它用于最小化成本函数，从而帮助我们最小化误差并获得可能的最低误差值。但梯度下降法是如何找到最优权重的呢？我们从一个类比开始。
- en: Imagine we are on top of a hill, as shown in the following diagram, and we want
    to reach the lowest point on the hill. There could be many regions that look like
    the lowest points on the hill, but we have to reach the point that is actually
    the lowest of all.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们站在山顶，如下图所示，想要到达山的最低点。山上可能有许多看起来像是最低点的地方，但我们必须找到那个真正最低的点。
- en: 'That is, we should not be stuck at a point believing it is the lowest point
    when the global lowest point exists:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，我们不应该停留在一个点，认为它是最低点，尽管全局最低点存在：
- en: '![](img/B15558_07_09.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_09.png)'
- en: 'Figure 7.9: Analogy of gradient descent'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9：梯度下降的类比
- en: 'Similarly, we can represent our cost function as follows. It is a plot of cost
    against weights. Our objective is to minimize the cost function. That is, we have
    to reach the lowest point where the cost is the minimum. The solid dark point
    in the following diagram shows the randomly initialized weights. If we move this
    point downward, then we can reach the point where the cost is the minimum:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以将成本函数表示如下。它是成本与权重的图像。我们的目标是最小化成本函数。也就是说，我们必须到达成本最小的最低点。下图中的实心黑点表示随机初始化的权重。如果我们将这个点向下移动，就可以到达成本最小的点：
- en: '![](img/B15558_07_10.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_10.png)'
- en: 'Figure 7.10: Gradient descent'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10：梯度下降
- en: But how can we move this point (initial weight) downward? How can we descend
    and reach the lowest point? Gradients are used for moving from one point to another.
    So, we can move this point (initial weight) by calculating a gradient of the cost
    function with respect to that point (initial weights), which is ![](img/B15558_07_023.png).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何将这个点（初始权重）向下移动呢？我们如何下降并到达最低点？梯度用于从一个点移动到另一个点。因此，我们可以通过计算成本函数相对于该点（初始权重）的梯度来移动这个点（初始权重），即
    ![](img/B15558_07_023.png)。
- en: 'Gradients are the derivatives that are actually the slope of a tangent line,
    as illustrated in the following diagram. So, by calculating the gradient, we descend
    (move downward) and reach the lowest point where the cost is the minimum. Gradient
    descent is a first-order optimization algorithm, which means we only take into
    account the first derivative when performing the updates:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度是导数，实际上是切线的斜率，如下图所示。因此，通过计算梯度，我们可以下降（向下移动）并到达成本最小的最低点。梯度下降是一种一阶优化算法，这意味着我们在执行更新时只考虑一阶导数：
- en: '![](img/B15558_07_11.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_11.png)'
- en: 'Figure 7.11: Gradient descent'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11：梯度下降
- en: Thus, with gradient descent, we move our weights to a position where the cost
    is minimum. But still, how do we update the weights?
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用梯度下降，我们将权重移动到成本最小的位置。但仍然，如何更新权重呢？
- en: 'As a result of forward propagation, we are in the output layer. We will now
    **backpropagate** the network from the output layer to the input layer and calculate
    the gradient of the cost function with respect to all the weights between the
    output and the input layer so that we can minimize the error. After calculating
    gradients, we update our old weights using the weight update rule:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 通过前向传播，我们到达了输出层。现在，我们将从输出层反向传播网络到输入层，并计算成本函数相对于输出层和输入层之间所有权重的梯度，以便我们最小化误差。计算完梯度后，我们将使用权重更新规则来更新旧的权重：
- en: '![](img/B15558_07_024.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_024.png)'
- en: This implies *weights = weights -α* x *gradients*.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着 *权重 = 权重 - α* x *梯度*。
- en: What is ![](img/B15558_07_025.png)? It is called the **learning rate**. As shown
    in the following diagram, if the learning rate is small, then we take a small
    step downward and our gradient descent can be slow.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 那么 ![](img/B15558_07_025.png) 是什么？它被称为**学习率**。如以下图所示，如果学习率较小，那么我们会向下迈出较小的一步，梯度下降的速度可能会很慢。
- en: 'If the learning rate is large, then we take a large step and our gradient descent
    will be fast, but we might fail to reach the global minimum and become stuck at
    a local minimum. So, the learning rate should be chosen optimally:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果学习率较大，那么我们会迈出较大的一步，梯度下降的速度会很快，但我们可能无法到达全局最小值，而是停留在局部最小值。因此，学习率应该选择得最优：
- en: '![](img/B15558_07_12.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_12.png)'
- en: 'Figure 7.12: Effect of learning rate'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12：学习率的影响
- en: This whole process of backpropagating the network from the output layer to the
    input layer and updating the weights of the network using gradient descent to
    minimize the loss is called **backpropagation**. Now that we have a basic understanding
    of backpropagation, we will strengthen our understanding by learning about this
    in detail, step by step. We are going to look at some interesting math, so put
    on your calculus hats and follow the steps.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这个从输出层反向传播网络到输入层并使用梯度下降更新网络权重以最小化损失的过程被称为**反向传播**。现在我们已经对反向传播有了基本了解，我们将通过一步步详细学习来加深理解。接下来我们将探讨一些有趣的数学内容，所以戴上你的微积分帽子，跟着步骤走。
- en: 'So, we have two weights, one *W*[xh], which is the input to hidden layer weights,
    and the other *W*[hy], which is the hidden to output layer weights. We need to
    find the optimal values for these two weights that will give us the fewest errors.
    So, we need to calculate the derivative of the cost function *J* with respect
    to these weights. Since we are backpropagating, that is, going from the output
    layer to the input layer, our first weight will be *W*[hy]. So, now we need to
    calculate the derivative of *J* with respect to *W*[hy]. How do we calculate the
    derivative? First, let''s recall our cost function, *J*:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们有两个权重，一个是 *W*[xh]，即输入到隐藏层的权重，另一个是 *W*[hy]，即从隐藏层到输出层的权重。我们需要找到这两个权重的最优值，以使我们得到最少的误差。因此，我们需要计算成本函数
    *J* 关于这些权重的导数。由于我们正在进行反向传播，也就是从输出层到输入层，所以我们的第一个权重将是 *W*[hy]。因此，现在我们需要计算 *J* 对
    *W*[hy] 的导数。我们如何计算导数呢？首先，让我们回顾一下我们的成本函数 *J*：
- en: '![](img/B15558_07_021.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_021.png)'
- en: 'We cannot calculate the derivative directly from the preceding equation since
    there is no *W*[hy] term. So, instead of calculating the derivative directly,
    we calculate the partial derivative. Let''s recall our forward propagation equation:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能直接从前面的方程计算导数，因为没有 *W*[hy] 项。所以，我们不是直接计算导数，而是计算偏导数。让我们回顾一下我们的前向传播方程：
- en: '![](img/B15558_07_016.png)![](img/B15558_07_015.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_016.png)![](img/B15558_07_015.png)'
- en: 'First, we will calculate a partial derivative with respect to ![](img/B15558_07_029.png),
    and then from ![](img/B15558_07_030.png) we will calculate the partial derivative
    with respect to *z*[2]. From *z*[2], we can directly calculate our derivative
    *W*[hy]. It is basically the chain rule. So, the derivative of *J* with respect
    to *W*[hy] becomes as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将计算关于 ![](img/B15558_07_029.png) 的偏导数，然后从 ![](img/B15558_07_030.png) 中计算关于
    *z*[2] 的偏导数。从 *z*[2] 开始，我们可以直接计算导数 *W*[hy]。这基本上就是链式法则。所以，*J* 对 *W*[hy] 的导数变为如下：
- en: '![](img/B15558_07_031.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_031.png)'
- en: 'Now, we will compute each of the terms in the preceding equation:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将计算前述方程中的每一项：
- en: '![](img/B15558_07_032.png)![](img/B15558_07_033.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_032.png)![](img/B15558_07_033.png)'
- en: Here, ![](img/B15558_07_034.png) is the derivative of our sigmoid activation
    function. We know that the sigmoid function is ![](img/B15558_07_035.png), so
    the derivative of the sigmoid function would be ![](img/B15558_07_036.png).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，![](img/B15558_07_034.png) 是我们的 Sigmoid 激活函数的导数。我们知道 Sigmoid 函数是 ![](img/B15558_07_035.png)，所以
    Sigmoid 函数的导数将是 ![](img/B15558_07_036.png)。
- en: 'Next we have:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们有：
- en: '![](img/B15558_07_037.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_037.png)'
- en: 'Thus, substituting all the preceding terms in equation *(1)* we can write:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，将前述所有项代入方程 *(1)*，我们可以写成：
- en: '![](img/B15558_07_038.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_038.png)'
- en: Now we need to compute a derivative of *J* with respect to our next weight,
    *W*[xh].
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要计算 *J* 关于下一个权重 *W*[xh] 的导数。
- en: 'Similarly, we cannot calculate the derivative of *W*[xh] directly from *J*
    as we don''t have any *W*[xh] terms in *J*. So, we need to use the chain rule.
    Let''s recall the forward propagation steps again:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，由于我们在 *J* 中没有任何 *W*[xh] 项，我们不能直接计算 *W*[xh] 的导数。所以，我们需要使用链式法则。让我们再次回顾前向传播的步骤：
- en: '![](img/B15558_07_016.png)![](img/B15558_07_015.png)![](img/B15558_07_014.png)![](img/B15558_07_011.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_016.png)![](img/B15558_07_015.png)![](img/B15558_07_014.png)![](img/B15558_07_011.png)'
- en: 'Now, according to the chain rule, the derivative of *J* with respect to *W*[xh]
    is given as:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，根据链式法则，*J* 对 *W*[xh] 的导数为：
- en: '![](img/B15558_07_043.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_043.png)'
- en: 'We have already seen how to compute the first two terms in the preceding equation;
    now, we will see how to compute the rest of the terms:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到如何计算前述方程中的前两项；现在，我们将看到如何计算其余的项：
- en: '![](img/B15558_07_044.png)![](img/B15558_07_045.png)![](img/B15558_07_046.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_044.png)![](img/B15558_07_045.png)![](img/B15558_07_046.png)'
- en: 'Thus, substituting all the preceding terms in equation *(3)*, we can write:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，将前述所有项代入方程 *(3)*，我们可以写成：
- en: '![](img/B15558_07_047.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_047.png)'
- en: 'After we have computed gradients for both weights, *W*[hy] and *W*[xh], we
    will update our initial weights according to the weight update rule:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们计算了两个权重的梯度，*W*[hy] 和 *W*[xh] 之后，我们将根据权重更新规则更新初始权重：
- en: '![](img/B15558_07_048.png)![](img/B15558_07_049.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_048.png)![](img/B15558_07_049.png)'
- en: That's it! This is how we update the weights of a network and minimize the loss.
    Now, let's see how to implement the backpropagation algorithm in Python.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！这就是我们如何更新网络权重并最小化损失。现在，让我们看看如何在 Python 中实现反向传播算法。
- en: 'In both the equations *(2)* and *(4)*, we have the term ![](img/B15558_07_050.png),
    so instead of computing them again and again, we just call them `delta2`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在公式*(2)*和*(4)*中，我们都有项![](img/B15558_07_050.png)，因此为了避免重复计算，我们将其命名为`delta2`：
- en: '[PRE1]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, we compute the gradient with respect to *W*[hy]. Refer to equation *(2)*:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们计算关于*W*[hy]的梯度。参见公式*(2)*：
- en: '[PRE2]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We compute the gradient with respect to *W*[xh]. Refer to equation *(4)*:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算关于*W*[xh]的梯度。参见公式*(4)*：
- en: '[PRE3]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We will update the weights according to our weight update rule equation *(5)*
    and *(6)* as follows:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将根据权重更新规则公式*(5)*和*(6)*更新权重，具体如下：
- en: '[PRE4]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The complete code for the backpropagation is given as follows:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播的完整代码如下所示：
- en: '[PRE5]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: That's it. Apart from this, there are different variants of gradient descent
    methods such as stochastic gradient descent, mini-batch gradient descent, Adam,
    RMSprop, and more.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样。除此之外，还有不同变种的梯度下降方法，如随机梯度下降、小批量梯度下降、Adam、RMSprop等。
- en: 'Before moving on, let''s familiarize ourselves with some of the frequently
    used terminology in neural networks:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，让我们熟悉一些在神经网络中常用的术语：
- en: '**Forward pass**: Forward pass implies forward propagating from the input layer
    to the output layer.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前向传播**：前向传播意味着从输入层向输出层传播。'
- en: '**Backward pass**: Backward pass implies backpropagating from the output layer
    to the input layer.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**反向传播**：反向传播意味着从输出层回传到输入层。'
- en: '**Epoch**: The epoch specifies the number of times the neural network sees
    our whole training data. So, we can say one epoch is equal to one forward pass
    and one backward pass for all training samples.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**周期（Epoch）**：周期指定神经网络看到全部训练数据的次数。因此，我们可以说一个周期等于对所有训练样本进行一次前向传播和一次反向传播。'
- en: '**Batch size**: The batch size specifies the number of training samples we
    use in one forward pass and one backward pass.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**批量大小**：批量大小指定我们在一次前向传播和一次反向传播中使用的训练样本数。'
- en: '**Number of iterations**: The number of iterations implies the number of passes
    where *one pass = one forward pass + one backward pass*.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**迭代次数**：迭代次数指的是传递的次数，其中*一次传递 = 一次前向传播 + 一次反向传播*。'
- en: Say that we have 12,000 training samples and our batch size is 6,000\. Then
    it will take us two iterations to complete one epoch. That is, in the first iteration,
    we pass the first 6,000 samples and perform a forward pass and a backward pass;
    in the second iteration, we pass the next 6,000 samples and perform a forward
    pass and a backward pass. After two iterations, our neural network will see the
    whole 12,000 training samples, which makes it one epoch.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有12,000个训练样本，并且我们的批量大小为6,000。然后我们需要两次迭代来完成一个周期。也就是说，在第一次迭代中，我们传递前6,000个样本，并执行一次前向传播和一次反向传播；在第二次迭代中，我们传递接下来的6,000个样本，并执行一次前向传播和一次反向传播。经过两次迭代后，我们的神经网络将看到全部12,000个训练样本，这样就完成了一个周期。
- en: Putting it all together
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 综合起来
- en: 'Putting all the concepts we have learned so far together, we will see how to
    build a neural network from scratch. We will understand how the neural network
    learns to perform the XOR gate operation. The XOR gate returns 1 only when exactly
    only one of its inputs is 1, else it returns 0, as shown in *Table 7.1*:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 将我们到目前为止学习的所有概念结合起来，我们将看到如何从零开始构建一个神经网络。我们将理解神经网络如何学习执行XOR门操作。XOR门仅当且仅当其输入中恰好有一个为1时返回1，否则返回0，如*表7.1*所示：
- en: '![](img/B15558_07_13.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_13.png)'
- en: 'Table 7.1: XOR operation'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 表7.1：XOR运算
- en: Building a neural network from scratch
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从零开始构建神经网络
- en: 'To perform the XOR gate operation, we build a simple two-layer neural network,
    as shown in the following diagram. As you can see, we have an input layer with
    two nodes, a hidden layer with five nodes and an output layer comprising one node:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 为了执行XOR门操作，我们构建了一个简单的两层神经网络，如下图所示。如你所见，我们有一个包含两个节点的输入层、一个包含五个节点的隐藏层和一个包含一个节点的输出层：
- en: '![](img/B15558_07_14.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_14.png)'
- en: 'Figure 7.13: ANN'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.13：人工神经网络（ANN）
- en: 'We will understand step-by-step how a neural network learns the XOR logic:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐步理解神经网络如何学习XOR逻辑：
- en: 'First, import the libraries:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，导入所需的库：
- en: '[PRE6]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Prepare the data as shown in the preceding XOR table:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备数据，如前面所示的XOR表：
- en: '[PRE7]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Define the number of nodes in each layer:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义每一层的节点数：
- en: '[PRE8]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Initialize the weights and bias randomly. First, we initialize the input to
    hidden layer weights:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机初始化权重和偏置。首先，我们初始化输入到隐藏层的权重：
- en: '[PRE9]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, we initialize the hidden to output layer weights:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们初始化隐藏层到输出层的权重：
- en: '[PRE10]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Define the sigmoid activation function:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义Sigmoid激活函数：
- en: '[PRE11]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Define the derivative of the sigmoid function:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义 sigmoid 函数的导数：
- en: '[PRE12]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Define the forward propagation:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义前向传播：
- en: '[PRE13]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Define the backward propagation:'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义反向传播：
- en: '[PRE14]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Define the cost function:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义成本函数：
- en: '[PRE15]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Set the learning rate and the number of training iterations:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置学习率和训练迭代次数：
- en: '[PRE16]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, let''s start training the network with the following code:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们通过以下代码开始训练网络：
- en: '[PRE17]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Plot the cost function:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制成本函数：
- en: '[PRE18]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'As you can observe in the following plot, the loss decreases over the training
    iterations:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在下图中所观察到的，损失随着训练迭代次数的增加而减少：
- en: '![](img/B15558_07_15.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_15.png)'
- en: 'Figure 7.14: Cost function'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14：成本函数
- en: Thus, we have an overall understanding of ANNs and how they learn.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们对人工神经网络（ANNs）及其学习方式有了整体的理解。
- en: Recurrent Neural Networks
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 递归神经网络
- en: '*The sun rises in the ____.*'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '*The sun rises in the ____.*'
- en: If we were asked to predict the blank term in the preceding sentence, we would
    probably say east. Why would we predict that the word east would be the right
    word here? Because we read the whole sentence, understood the context, and predicted
    that the word east would be an appropriate word to complete the sentence.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们被要求预测前面句子中的空白部分，我们可能会说是east。为什么我们会预测单词east是正确的呢？因为我们读了整个句子，理解了上下文，并预测单词east是一个合适的词来完成这个句子。
- en: If we use a feedforward neural network (the one we learned in the previous section)
    to predict the blank, it would not predict the right word. This is due to the
    fact that in feedforward networks, each input is independent of other input and
    they make predictions based only on the current input, and they don't remember
    previous input.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用前馈神经网络（在上一节中学习的网络）来预测空白，它将无法预测正确的单词。这是因为在前馈网络中，每个输入都是独立的，它们仅根据当前输入进行预测，而不会记住之前的输入。
- en: Thus, the input to the network will just be the word preceding the blank, which
    is the word *the*. With this word alone as an input, our network cannot predict
    the correct word, because it doesn't know the context of the sentence, which means
    that it doesn't know the previous set of words to understand the context of the
    sentence and to predict an appropriate next word.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，网络的输入将仅是空白前的单词，即单词*the*。仅凭这个单词作为输入，我们的网络无法预测正确的单词，因为它无法理解句子的上下文，这意味着它不知道前面的一系列单词，因此无法理解句子的上下文并预测出一个合适的下一个单词。
- en: Here is where we use **Recurrent Neural Networks** (**RNNs**). They predict
    output not only based on the current input, but also on the previous hidden state.
    Why do they have to predict the output based on the current input and the previous
    hidden state? Why can't they just use the current input and the previous input?
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我们使用**递归神经网络**（**RNNs**）。它们不仅仅基于当前输入来预测输出，还会基于之前的隐藏状态进行预测。为什么它们必须基于当前输入和之前的隐藏状态来预测输出呢？为什么不能只使用当前输入和之前的输入呢？
- en: This is because the previous input will only store information about the previous
    word, while the previous hidden state will capture the contextual information
    about all the words in the sentence that the network has seen so far. Basically,
    the previous hidden state acts like memory, and it captures the context of the
    sentence. With this context and the current input, we can predict the relevant
    word.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为之前的输入只会存储关于前一个单词的信息，而之前的隐藏状态将捕获网络到目前为止所看到的句子中所有单词的上下文信息。基本上，之前的隐藏状态就像记忆一样，它捕获了句子的上下文。有了这些上下文信息和当前输入，我们就可以预测相关的单词。
- en: For instance, let's take the same sentence, *The sun rises in the ____.* As
    shown in the following figure, we first pass the word *the* as an input, and then
    we pass the next word, *sun*, as input; but along with this, we also pass the
    previous hidden state, *h*[0]. So, every time we pass the input word, we also
    pass a previous hidden state as an input.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，让我们来看这个句子，*The sun rises in the ____.* 如下图所示，我们首先将单词*the*作为输入，然后将下一个单词*sun*作为输入；但同时，我们还会传递之前的隐藏状态，*h*[0]。因此，每次我们传递输入单词时，我们也会传递之前的隐藏状态作为输入。
- en: 'In the final step, we pass the word *the*, and also the previous hidden state
    *h*[3], which captures the contextual information about the sequence of words
    that the network has seen so far. Thus, *h*[3] acts as the memory and stores information
    about all the previous words that the network has seen. With *h*[3] and the current
    input word (*the*), we can predict the relevant next word:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一步，我们传递单词 *the*，以及之前的隐藏状态 *h*[3]，它捕获了网络迄今为止看到的单词序列的上下文信息。因此，*h*[3] 充当记忆并存储网络已看到的所有前面的单词的信息。通过
    *h*[3] 和当前输入单词（*the*），我们可以预测下一个相关的单词：
- en: '![](img/B15558_07_16.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_16.png)'
- en: 'Figure 7.15: RNN'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.15：RNN
- en: In a nutshell, an RNN uses the previous hidden state as memory, which captures
    and stores the contextual information (input) that the network has seen so far.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，RNN 使用前一个隐藏状态作为记忆，这个记忆捕获并存储网络迄今为止看到的上下文信息（输入）。
- en: RNNs are widely applied for use cases that involve sequential data, such as
    time series, text, audio, speech, video, weather, and much more. They have been
    greatly used in various **natural language processing** (**NLP**) tasks, such
    as language translation, sentiment analysis, text generation, and so on.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: RNN 被广泛应用于涉及顺序数据的应用场景，如时间序列、文本、音频、语音、视频、天气等。它们在各种 **自然语言处理**（**NLP**）任务中得到了广泛应用，如语言翻译、情感分析、文本生成等。
- en: The difference between feedforward networks and RNNs
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前馈网络与 RNN 之间的区别
- en: 'A comparison between an RNN and a feedforward network is shown in the *Figure
    7.16*:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: RNN 与前馈网络的比较见 *图 7.16*：
- en: '![](img/B15558_07_17.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_17.png)'
- en: 'Figure 7.16: Difference between feedforward network and RNN'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.16：前馈网络与 RNN 的区别
- en: As you can observe in the preceding diagram, the RNN contains a looped connection
    in the hidden layer, which implies that we use the previous hidden state along
    with the input to predict the output.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，RNN 在隐藏层中包含一个循环连接，这意味着我们使用前一个隐藏状态以及输入来预测输出。
- en: Still confused? Let's look at the following unrolled version of an RNN. But
    wait; what is the unrolled version of an RNN?
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 还是不明白？让我们来看一下 RNN 的展开版本。但等等，RNN 的展开版本是什么？
- en: 'It means that we roll out the network for a complete sequence. Let''s suppose
    that we have an input sentence with *T* words; then, we will have 0 to *T*—1 layers,
    one for each word, as shown in *Figure 7.17*:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们将网络展开以适应完整的序列。假设我们有一个包含 *T* 个单词的输入句子；那么，我们将有从 0 到 *T*-1 的层，每个单词对应一个层，如
    *图 7.17* 所示：
- en: '![](img/B15558_07_18.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_18.png)'
- en: 'Figure 7.17: Unrolled RNN'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.17：展开的 RNN
- en: As you can see in *Figure 7.17*, at the time step *t* = 1, the output *y*[1]
    is predicted based on the current input *x*[1] and the previous hidden state *h*[0].
    Similarly, at time step *t* = 2, *y*[2] is predicted using the current input *x*[2]
    and the previous hidden state *h*[1]. This is how an RNN works; it takes the current
    input and the previous hidden state to predict the output.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如 *图 7.17* 所示，在时间步 *t* = 1 时，输出 *y*[1] 是基于当前输入 *x*[1] 和前一个隐藏状态 *h*[0] 预测的。类似地，在时间步
    *t* = 2 时，*y*[2] 是基于当前输入 *x*[2] 和前一个隐藏状态 *h*[1] 预测的。这就是 RNN 的工作原理；它通过当前输入和前一个隐藏状态来预测输出。
- en: Forward propagation in RNNs
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RNN 中的前向传播
- en: 'Let''s look at how an RNN uses forward propagation to predict the output; but
    before we jump right in, let''s get familiar with the notations:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 RNN 如何利用前向传播来预测输出；但在我们直接进入之前，先来了解一下符号的定义：
- en: '![](img/B15558_07_19.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_19.png)'
- en: 'Figure 7.18: Forward propagation in RNN'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.18：RNN 中的前向传播
- en: 'The preceding figure illustrates the following:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图示说明了以下内容：
- en: '*U* represents the input to hidden layer weight matrix'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*U* 表示输入到隐藏层的权重矩阵'
- en: '*W* represents the hidden to hidden layer weight matrix'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*W* 表示隐藏到隐藏层的权重矩阵'
- en: '*V* represents the hidden to output layer weight matrix'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*V* 表示隐藏到输出层的权重矩阵'
- en: 'The hidden state *h* at a time step *t* can be computed as follows:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间步 *t* 上的隐藏状态 *h* 可以通过以下公式计算：
- en: '![](img/B15558_07_051.png)'
  id: totrans-245
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_051.png)'
- en: That is, *the* *hidden state at a time step, t = tanh([input to hidden layer
    weight x input]* + *[hidden to hidden layer weight x previous hidden state])*.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 即，*时间步的隐藏状态，t = tanh([输入到隐藏层的权重 x 输入]* + *[隐藏到隐藏层的权重 x 前一个隐藏状态]*)。
- en: 'The output at a time step *t* can be computed as follows:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 时间步 *t* 上的输出可以通过以下公式计算：
- en: '![](img/B15558_07_052.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_052.png)'
- en: That is, *the* *output at a time step, t = softmax (hidden to output layer weight*
    x *hidden state at a time t)*.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 即，*时间步的输出，t = softmax（隐藏到输出层的权重* x *时间步 t 上的隐藏状态）*。
- en: 'We can also represent RNNs as shown in the following figure. As you can see,
    the hidden layer is represented by an RNN block, which implies that our network
    is an RNN, and previous hidden states are used in predicting the output:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以像下图所示表示RNN。正如你所看到的，隐藏层由一个RNN模块表示，这意味着我们的网络是一个RNN，且前一个隐藏状态被用于预测输出：
- en: '![](img/B15558_07_20.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_20.png)'
- en: 'Figure 7.19: Forward propagation in an RNN'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.19：RNN中的前向传播
- en: '*Figure 7.20* shows how forward propagation works in an unrolled version of
    an RNN:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.20* 显示了在RNN的展开版本中前向传播的工作方式：'
- en: '![](img/B15558_07_21.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_21.png)'
- en: 'Figure 7.20: Unrolled version – forward propagation in an RNN'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.20：展开版本——RNN中的前向传播
- en: 'We initialize the initial hidden state *h*[init] with random values. As you
    can see in the preceding figure, the output, ![](img/B15558_07_053.png), is predicted
    based on the current input, *x*[0] and the previous hidden state, which is an
    initial hidden state, *h*[init], using the following formula:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用随机值初始化初始隐藏状态 *h*[init]。正如你在前面的图中看到的，输出，![](img/B15558_07_053.png)，是基于当前输入，*x*[0]，和前一个隐藏状态（即初始隐藏状态
    *h*[init]）预测的，使用以下公式：
- en: '![](img/B15558_07_054.png)![](img/B15558_07_055.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_054.png)![](img/B15558_07_055.png)'
- en: 'Similarly, look at how the output, ![](img/B15558_07_056.png), is computed.
    It takes the current input, *x*[1], and the previous hidden state, *h*[0]:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，看看输出是如何计算的，![](img/B15558_07_056.png)。它使用当前输入，*x*[1]，以及前一个隐藏状态，*h*[0]：
- en: '![](img/B15558_07_057.png)![](img/B15558_07_058.png)'
  id: totrans-259
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_057.png)![](img/B15558_07_058.png)'
- en: Thus, in forward propagation to predict the output, RNN uses the current input
    and the previous hidden state.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在前向传播中预测输出时，RNN使用当前输入和前一个隐藏状态。
- en: Backpropagating through time
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反向传播
- en: 'We just learned how forward propagation works in RNNs and how it predicts the
    output. Now, we compute the loss, *L*, at each time step, *t*, to determine how
    well the RNN has predicted the output. We use the cross-entropy loss as our loss
    function. The loss *L* at a time step *t* can be given as follows:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚了解了RNN中前向传播的工作原理以及它是如何预测输出的。现在，我们计算每个时间步 *t* 的损失 *L*，以确定RNN预测输出的效果如何。我们使用交叉熵损失作为损失函数。时间步
    *t* 的损失 *L* 可以表示为：
- en: '![](img/B15558_07_059.png)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_059.png)'
- en: Here, *y*[t] is the actual output, and ![](img/B15558_07_060.png) is the predicted
    output at a time step *t*.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*y*[t] 是实际输出，而 ![](img/B15558_07_060.png) 是在时间步 *t* 预测的输出。
- en: 'The final loss is a sum of the loss at all the time steps. Suppose that we
    have *T* - 1 layers; then, the final loss can be given as follows:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 最终的损失是所有时间步损失的总和。假设我们有 *T* - 1 层，那么最终的损失可以表示为：
- en: '![](img/B15558_07_061.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_061.png)'
- en: '*Figure 7.21* shows that the final loss is obtained by the sum of loss at all
    the time steps:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.21* 显示了最终的损失是通过所有时间步的损失总和获得的：'
- en: '![](img/B15558_07_22.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_22.png)'
- en: 'Figure 7.21: Backpropagation in an RNN'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.21：RNN中的反向传播
- en: 'We computed the loss, now our goal is to minimize the loss. How can we minimize
    the loss? We can minimize the loss by finding the optimal weights of the RNN.
    As we learned, we have three weights in RNNs: input to hidden, *U*, hidden to
    hidden, *W*, and hidden to output, *V*.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们计算了损失，现在我们的目标是最小化损失。我们怎么做才能最小化损失呢？我们可以通过找到RNN的最佳权重来最小化损失。正如我们所学，RNN中有三种权重：从输入到隐藏的权重
    *U*，从隐藏到隐藏的权重 *W*，以及从隐藏到输出的权重 *V*。
- en: 'We need to find optimal values for all of these three weights to minimize the
    loss. We can use our favorite gradient descent algorithm to find the optimal weights.
    We begin by calculating the gradients of the loss function with respect to all
    the weights; then, we update the weights according to the weight update rule as
    follows:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为这三种权重找到最佳值，以最小化损失。我们可以使用我们喜欢的梯度下降算法来找到最佳权重。我们从计算损失函数关于所有权重的梯度开始，然后根据以下权重更新规则更新权重：
- en: '![](img/B15558_07_062.png)![](img/B15558_07_063.png)![](img/B15558_07_064.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_062.png)![](img/B15558_07_063.png)![](img/B15558_07_064.png)'
- en: However, we have a problem with the RNN. The gradient calculation involves calculating
    the gradient with respect to the activation function. When we calculate the gradient
    with respect to the sigmoid or tanh function, the gradient will become very small.
    When we further backpropagate the network over many time steps and multiply the
    gradients, the gradients will tend to get smaller and smaller. This is called
    a vanishing gradient problem.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，RNN 有一个问题。梯度计算涉及计算相对于激活函数的梯度。当我们计算相对于 sigmoid 或 tanh 函数的梯度时，梯度会变得非常小。当我们在多个时间步上进一步反向传播并乘以梯度时，梯度会趋向变得越来越小。这就是所谓的消失梯度问题。
- en: Since the gradient vanishes over time, we cannot learn information about long-term
    dependencies, that is, RNNs cannot retain information for a long time in the memory.
    The vanishing gradient problem occurs not only in RNNs but also in other deep
    networks where we have many hidden layers and when we use sigmoid/tanh functions.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 由于梯度随时间消失，我们无法学习关于长期依赖的信息，也就是说，RNN 无法在记忆中长时间保留信息。消失梯度问题不仅出现在 RNN 中，还出现在其他深度网络中，特别是在我们有多个隐藏层并使用
    sigmoid/tanh 函数时。
- en: One solution to avoid vanishing gradient problem is to use ReLU as an activation
    function. However, we have a variant of the RNN called **Long Short-Term Memory**
    (**LSTM**), which can solve the vanishing gradient problem effectively. We will
    see how it works in the upcoming section.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 解决消失梯度问题的一个方法是使用 ReLU 作为激活函数。然而，我们有一个 RNN 的变体叫做**长短期记忆**（**LSTM**），它能够有效地解决消失梯度问题。我们将在接下来的部分看到它是如何工作的。
- en: LSTM to the rescue
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LSTM 来解救
- en: 'While backpropagating an RNN, we learned about a problem called **vanishing
    gradients**. Due to the vanishing gradient problem, we cannot train the network
    properly, and this causes the RNN to not retain long sequences in the memory.
    To understand what we mean by this, let''s consider a small sentence:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在反向传播 RNN 时，我们学习了一个问题，叫做**消失梯度**。由于消失梯度问题，我们无法正确训练网络，这导致 RNN 无法在记忆中保持长序列。为了理解这个问题的含义，假设我们有一个简单的句子：
- en: '*The sky is __*.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '*The sky is __*.'
- en: 'An RNN can easily predict the blank as *blue* based on the information it has
    seen, but it cannot cover the long-term dependencies. What does that mean? Let''s
    consider the following sentence to understand the problem better:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: RNN 可以根据它所看到的信息轻松预测空白处为*蓝色*，但它无法涵盖长期的依赖关系。这是什么意思？我们通过以下句子来更好地理解这个问题：
- en: '*Archie lived in China for 13 years. He loves listening to good music. He is
    a fan of comics. He is fluent in ____.*'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '*Archie 在中国生活了 13 年。他喜欢听好音乐。他是漫画迷。他能流利地说 __。*'
- en: Now, if we were asked to predict the missing word in the preceding sentence,
    we would predict it as *Chinese*, but how did we predict that? We simply remembered
    the previous sentences and understood that Archie lived for 13 years in China.
    This led us to the conclusion that Archie might be fluent in Chinese. An RNN,
    on the other hand, cannot retain all of this information in its memory to say
    that Archie is fluent in Chinese.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们被要求预测前一句话中的缺失词，我们会预测它是*中文*，但我们是如何预测的呢？我们简单地记住了前面的句子，并理解到 Archie 在中国生活了
    13 年。这使我们得出结论，Archie 可能会说流利的中文。而 RNN 则无法将所有这些信息保存在记忆中，进而说出 Archie 能流利地讲中文。
- en: Due to the vanishing gradient problem, it cannot recollect/remember information
    for a long time in its memory. That is, when the input sequence is long, the RNN
    memory (hidden state) cannot hold all the information. To alleviate this, we use
    an LSTM cell.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 由于消失梯度问题，它无法在记忆中长时间回忆/记住信息。也就是说，当输入序列较长时，RNN 的记忆（隐藏状态）无法保存所有信息。为了解决这个问题，我们使用了
    LSTM 单元。
- en: 'LSTM is a variant of an RNN that resolves the vanishing gradient problem and
    retains information in the memory as long as it is required. Basically, RNN cells
    are replaced with LSTM cells in the hidden units, as shown in *Figure 7.22*:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM 是 RNN 的一种变体，能够解决消失梯度问题，并在需要时将信息保留在记忆中。基本上，RNN 单元在隐藏层中被 LSTM 单元替代，如*图 7.22*所示：
- en: '![](img/B15558_07_23.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_23.png)'
- en: 'Figure 7.22: LSTM network'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.22：LSTM 网络
- en: In the next section, we will understand how the LSTM cells works.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分中，我们将了解 LSTM 单元是如何工作的。
- en: Understanding the LSTM cell
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 LSTM 单元
- en: What makes LSTM cells so special? How do LSTM cells achieve long-term dependency?
    How does it know what information to keep and what information to discard from
    the memory?
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: LSTM 单元有什么特别之处？LSTM 单元是如何实现长期依赖的？它是如何知道哪些信息需要保留，哪些信息需要从记忆中丢弃的？
- en: 'This is all achieved by special structures called **gates**. As shown in the
    following diagram, a typical LSTM cell consists of three special gates called
    the input gate, output gate, and forget gate:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这一切都是通过名为**门**的特殊结构实现的。如以下图所示，一个典型的 LSTM 单元由三个特殊的门组成，分别是输入门、输出门和遗忘门：
- en: '![](img/B15558_07_24.jpg)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_24.jpg)'
- en: 'Figure 7.23: LSTM gates'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.23：LSTM 门
- en: 'These three gates are responsible for deciding what information to add, output,
    and forget from the memory. With these gates, an LSTM cell effectively keeps information
    in the memory only as long as required. *Figure 7.24* shows a typical LSTM cell:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个门负责决定从记忆中添加、输出和忘记哪些信息。有了这些门，LSTM 单元能够有效地仅在需要时保留信息在记忆中。*图 7.24* 展示了一个典型的 LSTM
    单元：
- en: '![](img/B15558_07_25.png)'
  id: totrans-293
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_25.png)'
- en: 'Figure 7.24: LSTM cell'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.24：LSTM 单元
- en: 'If you look at the LSTM cell, the top horizontal line is called the cell state.
    It is where the information flows. Information on the cell state will be constantly
    updated by LSTM gates. Now, we will see the function of these gates:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看 LSTM 单元，顶部的水平线被称为单元状态。它是信息流动的地方。单元状态上的信息将通过 LSTM 门不断更新。现在，我们将了解这些门的功能：
- en: '**Forget gate**: The forget gate is responsible for deciding what information
    should not be in the cell state. Look at the following statement:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '**遗忘门**：遗忘门负责决定哪些信息不应该出现在单元状态中。请看以下语句：'
- en: '*Harry is a good singer. He lives in New York. Zayn is also a good singer.*'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '*哈里是个好歌手。他住在纽约。赞恩也是个好歌手。*'
- en: As soon as we start talking about Zayn, the network will understand that the
    subject has been changed from Harry to Zayn and the information about Harry is
    no longer required. Now, the forget gate will remove/forget information about
    Harry from the cell state.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们开始谈论赞恩，网络会理解主题已经从哈里转移到赞恩，哈里的信息不再需要。现在，遗忘门会从单元状态中删除/忘记哈里的信息。
- en: '**Input gate**: The input gate is responsible for deciding what information
    should be stored in the memory. Let''s consider the same example:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入门**：输入门负责决定哪些信息应该被存储在记忆中。我们来看同一个例子：'
- en: '*Harry is a good singer. He lives in New York. Zayn is also a good singer.*'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '*哈里是个好歌手。他住在纽约。赞恩也是个好歌手。*'
- en: So, after the forget gate removes information from the cell state, the input
    gate decides what information has to be in the memory. Here, since the information
    about Harry is removed from the cell state by the forget gate, the input gate
    decides to update the cell state with the information about Zayn.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在遗忘门从单元状态中删除信息后，输入门决定哪些信息必须存在于记忆中。这里，由于哈里的信息被遗忘门从单元状态中移除，输入门决定更新单元状态，将赞恩的信息加入其中。
- en: '**Output gate**: The output gate is responsible for deciding what information
    should be shown from the cell state at a time, *t*. Now, consider the following
    sentence:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出门**：输出门负责决定在某一时刻 *t* 从单元状态中展示哪些信息。现在，考虑以下句子：'
- en: '*Zayn''s debut album was a huge success. Congrats ____.*'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '*赞恩的首张专辑取得了巨大成功。祝贺 __。*'
- en: Here, congrats is an adjective which is used to describe a noun. The output
    layer will predict Zayn (noun), to fill in the blank.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，"congrats" 是一个形容词，用来描述名词。输出层将预测赞恩（名词），以填补空白。
- en: Thus, using LSTM, we can overcome the vanishing gradient problem faced in RNN.
    In the next section, we will learn another interesting algorithm called the **Convolutional
    Neural Network** (**CNN**).
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用 LSTM，我们可以克服 RNN 中遇到的梯度消失问题。在下一节中，我们将学习另一种有趣的算法——**卷积神经网络**（**CNN**）。
- en: What are CNNs?
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 CNN？
- en: A CNN, also known as a **ConvNet**, is one of the most widely used deep learning
    algorithms for computer vision tasks. Let's say we are performing an image-recognition
    task. Consider the following image.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: CNN，也称为**卷积神经网络**，是计算机视觉任务中最广泛使用的深度学习算法之一。假设我们正在执行图像识别任务。请看以下图像。
- en: 'We want our CNN to recognize that it contains a horse:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望我们的 CNN 能识别出它包含一匹马：
- en: '![](img/B15558_07_26.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_26.png)'
- en: 'Figure 7.25: Image containing a horse'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.25：包含一匹马的图像
- en: How can we do that? When we feed the image to a computer, it basically converts
    it into a matrix of pixel values. The pixel values range from 0 to 255, and the
    dimensions of this matrix will be of [*image width* x *image height* x *number
    of channels*]. A grayscale image has one channel, and colored images have three
    channels, **red, green, and blue** (**RGB**).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何做到这一点呢？当我们将图像输入计算机时，它基本上会将图像转换为一个像素值矩阵。像素值的范围是0到255，矩阵的维度是[*图像宽度* x *图像高度*
    x *通道数*]。灰度图像有一个通道，彩色图像有三个通道，分别是**红色、绿色和蓝色**（**RGB**）。
- en: Let's say we have a colored input image with a width of 11 and a height of 11,
    that is 11 x 11, then our matrix dimension would be *[11* x *11* x *3]*. As you
    can see in *[11* x *11* x *3]*, 11 x 11 represents the image width and height
    and 3 represents the channel number, as we have a colored image. So, we will have
    a 3D matrix.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一张彩色输入图像，宽度为11，高度为11，即11 x 11，那么我们的矩阵维度将是*[11* x *11* x *3]*。如*11 x 11
    x 3*所示，11 x 11表示图像的宽度和高度，3表示通道数，因为我们有一张彩色图像。所以，我们将得到一个3D矩阵。
- en: But it is hard to visualize a 3D matrix, so, for the sake of understanding,
    let's consider a grayscale image as our input. Since the grayscale image has only
    one channel, we will get a 2D matrix.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，3D矩阵很难可视化，因此，为了便于理解，我们假设输入是灰度图像。由于灰度图像只有一个通道，所以我们将得到一个二维矩阵。
- en: 'As shown in the following diagram, the input grayscale image will be converted
    into a matrix of pixel values ranging from 0 to 255, with the pixel values representing
    the intensity of pixels at that point:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示，输入的灰度图像将被转换为一个像素值矩阵，像素值的范围是0到255，像素值表示该点的像素强度：
- en: '![](img/B15558_07_27.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_27.png)'
- en: 'Figure 7.26: Input image is converted to matrix of pixel values'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.26：输入图像被转换为像素值矩阵
- en: The values given in the input matrix are just arbitrary values for our understanding.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 输入矩阵中给出的值只是为了帮助我们理解而设置的任意值。
- en: 'Okay, now we have an input matrix of pixel values. What happens next? How does
    the CNN come to understand that the image contains a horse? CNNs consists of the
    following three important layers:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们有了一个像素值输入矩阵。接下来会发生什么呢？CNN是如何理解图像包含一匹马的呢？CNN由以下三个重要层组成：
- en: The convolutional layer
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积层
- en: The pooling layer
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 池化层
- en: The fully connected layer
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全连接层
- en: With the help of these three layers, the CNN recognizes that the image contains
    a horse. Now we will explore each of these layers in detail.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在这三层的帮助下，CNN识别出图像中包含马的特征。接下来我们将详细探讨这些层。
- en: Convolutional layers
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积层
- en: The convolutional layer is the first and core layer of the CNN. It is one of
    the building blocks of a CNN and is used for extracting important features from
    the image.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层是CNN的第一个也是核心的层。它是CNN的构建块之一，用于从图像中提取重要特征。
- en: We have an image of a horse. What do you think are the features that will help
    us to understand that this is an image of a horse? We can say body structure,
    face, legs, tail, and so on. But how does the CNN understand these features? This
    is where we use a convolution operation that will extract all the important features
    from the image that characterize the horse. So, the convolution operation helps
    us to understand what the image is all about.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一张马的图片。你认为有哪些特征可以帮助我们理解这是马的图片呢？我们可以说是身体结构、面部、四肢、尾巴等等。但卷积神经网络（CNN）是如何理解这些特征的呢？这就是我们使用卷积操作的地方，卷积操作将从图像中提取出所有能够表征马的关键特征。所以，卷积操作帮助我们理解图像的内容。
- en: Okay, what exactly is this convolution operation? How it is performed? How does
    it extract the important features? Let's look at this in detail.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这个卷积操作到底是什么？它是如何执行的？它如何提取重要特征？我们来详细了解一下。
- en: As we know, every input image is represented by a matrix of pixel values. Apart
    from the input matrix, we also have another matrix called the **filter matrix**.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所知，每个输入图像都由一个像素值矩阵表示。除了输入矩阵，我们还需要另一个矩阵，称为**滤波器矩阵**。
- en: 'The filter matrix is also known as a **kernel**, or simply a **filter**, as
    shown in the *Figure 7.27*:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波器矩阵也称为**核**，或者简单地称为**滤波器**，如*图7.27*所示：
- en: '![](img/B15558_07_28.png)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_28.png)'
- en: 'Figure 7.27: Input and filter matrix'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.27：输入和滤波器矩阵
- en: 'We take the filter matrix, slide it over the input matrix by one pixel, perform
    element-wise multiplication, sum the results, and produce a single number. That''s
    pretty confusing, isn''t it? Let''s understand this better with the aid of the
    following diagram:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们取滤波器矩阵，将它滑动到输入矩阵上一个像素，执行逐元素相乘，求和结果，最终得到一个数字。是不是有点让人困惑呢？让我们通过以下示意图更好地理解：
- en: '![](img/B15558_07_29.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_29.png)'
- en: 'Figure 7.28: Convolution operation'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.28：卷积操作
- en: 'As you can see in the previous diagram, we took the filter matrix and placed
    it on top of the input matrix, performed element-wise multiplication, summed their
    results, and produced the single number. This is demonstrated as follows:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在上面的示意图中看到的，我们将滤波器矩阵放在输入矩阵上方，执行逐元素相乘，求和结果，得到了一个数字。证明如下：
- en: '![](img/B15558_07_065.png)'
  id: totrans-335
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_065.png)'
- en: 'Now, we slide the filter over the input matrix by one pixel and perform the
    same steps, as shown in *Figure 7.29*:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将滤波器在输入矩阵上滑动一个像素，并执行相同的步骤，如*图7.29*所示：
- en: '![](img/B15558_07_30.png)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_30.png)'
- en: 'Figure 7.29: Convolution operation'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.29：卷积操作
- en: 'This is demonstrated as follows:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 证明如下：
- en: '![](img/B15558_07_066.png)'
  id: totrans-340
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_066.png)'
- en: 'Again, we slide the filter matrix by one pixel and perform the same operation,
    as shown in *Figure 7.30*:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将滤波器矩阵滑动一个像素，并执行相同的操作，如*图7.30*所示：
- en: '![](img/B15558_07_31.png)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_31.png)'
- en: 'Figure 7.30: Convolution operation'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.30：卷积操作
- en: 'This is demonstrated as follows:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 证明如下：
- en: '![](img/B15558_07_067.png)'
  id: totrans-345
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_067.png)'
- en: 'Now, again, we slide the filter matrix over the input matrix by one pixel and
    perform the same operation, as shown in *Figure 7.31*:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，再次，我们将滤波器矩阵滑动一个像素到输入矩阵上，并执行相同的操作，如*图7.31*所示：
- en: '![](img/B15558_07_32.png)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_32.png)'
- en: 'Figure 7.31: Convolution operation'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.31：卷积操作
- en: 'That is:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说：
- en: '![](img/B15558_07_068.png)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_068.png)'
- en: Okay. What are we doing here? We are basically sliding the filter matrix over
    the entire input matrix by one pixel, performing element-wise multiplication and
    summing their results, which creates a new matrix called a **feature map** or
    **activation map**. This is called the **convolution operation**.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们在这里做什么？我们基本上是将滤波器矩阵滑动到整个输入矩阵上，每次滑动一个像素，执行逐元素相乘并将结果相加，最终产生一个新的矩阵，称为**特征图**或**激活图**。这就是所谓的**卷积操作**。
- en: As we've learned, the convolution operation is used to extract features, and
    the new matrix, that is, the feature maps, represents the extracted features.
    If we plot the feature maps, then we can see the features extracted by the convolution
    operation.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所学，卷积操作用于提取特征，新的矩阵，即特征图，表示提取的特征。如果我们绘制特征图，那么我们就可以看到卷积操作提取出的特征。
- en: '*Figure 7.32* shows the actual image (the input image) and the convolved image
    (the feature map). We can see that our filter has detected the edges from the
    actual image as a feature:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.32*展示了实际图像（输入图像）和卷积后的图像（特征图）。我们可以看到，我们的滤波器已经从实际图像中检测到了边缘作为特征：'
- en: '![](img/B15558_07_33.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_33.png)'
- en: 'Figure 7.32: Conversion of actual image to convolved image'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.32：将实际图像转换为卷积后的图像
- en: 'Various filters are used for extracting different features from the image.
    For instance, if we use a sharpen filter, ![](img/B15558_07_069.png), then it
    will sharpen our image, as shown in the following figure:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 使用各种滤波器从图像中提取不同的特征。例如，如果我们使用锐化滤波器，![](img/B15558_07_069.png)，它将会锐化我们的图像，如下图所示：
- en: '![](img/B15558_07_34.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_34.png)'
- en: 'Figure 7.33: Sharpened image'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.33：锐化后的图像
- en: 'Thus, we have learned that with filters, we can extract important features
    from the image using the convolution operation. So, instead of using one filter,
    we can use multiple filters to extract different features from the image and produce
    multiple feature maps. So, the depth of the feature map will be the number of
    filters. If we use seven filters to extract different features from the image,
    then the depth of our feature map will be seven:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经了解到，利用滤波器，我们可以通过卷积操作从图像中提取重要特征。因此，我们不仅可以使用一个滤波器，还可以使用多个滤波器从图像中提取不同的特征，并生成多个特征图。这样，特征图的深度将是滤波器的数量。如果我们使用七个滤波器来提取图像中的不同特征，那么我们的特征图的深度将是七：
- en: '![](img/B15558_07_35.png)'
  id: totrans-360
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_35.png)'
- en: 'Figure 7.34: Feature maps'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.34：特征图
- en: Okay, we have learned that different filters extract different features from
    the image. But the question is, how can we set the correct values for the filter
    matrix so that we can extract the important features from the image? Worry not!
    We just initialize the filter matrix randomly, and the optimal values of the filter
    matrix, with which we can extract the important features from the images, will
    be learned through backpropagation. However, we just need to specify the size
    of the filter and the number of filters we want to use.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们已经学会了不同的滤波器从图像中提取不同的特征。但问题是，我们如何为滤波器矩阵设置正确的值，以便能够从图像中提取重要的特征呢？别担心！我们只需要随机初始化滤波器矩阵，而滤波器矩阵的最佳值——能够从图像中提取重要特征的值——会通过反向传播学习到。但是，我们只需要指定滤波器的大小以及我们想要使用的滤波器数量。
- en: Strides
  id: totrans-363
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步长
- en: We have just learned how a convolution operation works. We slide over the input
    matrix with the filter matrix by one pixel and perform the convolution operation.
    But we don't have to only slide over the input matrix by one pixel, we can also
    slide over the input matrix by any number of pixels.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚学习了卷积操作是如何工作的。我们以一个像素为单位，用滤波器矩阵滑动输入矩阵并执行卷积操作。但我们不一定要每次只滑动一个像素，也可以选择按任意数量的像素滑动输入矩阵。
- en: The number of pixels we slide over the input matrix by the filter matrix is
    called a **stride**.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波器矩阵滑动输入矩阵的像素数量称为**步长**。
- en: 'If we set the stride to 2, then we slide over the input matrix with the filter
    matrix by two pixels. *Figure 7.35* shows a convolution operation with a stride
    of 2:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将步长设置为2，那么我们就会以两个像素为单位，用滤波器矩阵滑动输入矩阵。*图7.35*展示了一个步长为2的卷积操作：
- en: '![](img/B15558_07_36.png)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_36.png)'
- en: 'Figure 7.35: Stride operation'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.35：步长操作
- en: But how do we choose the stride number? We just learned that a stride is the
    number of pixels along that we move our filter matrix. So, when the stride is
    set to a small number, we can encode a more detailed representation of the image
    than when the stride is set to a large number. However, a stride with a high value
    takes less time to compute than one with a low value.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何选择步长呢？我们刚刚了解到，步长是指我们滑动滤波器矩阵时沿某一方向移动的像素数量。所以，当步长设置为较小的数字时，我们可以比设置较大步长时更详细地编码图像的特征。然而，较大的步长值所需的计算时间比较小步长值要少。
- en: Padding
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 填充
- en: 'With the convolution operation, we are sliding over the input matrix with a
    filter matrix. But in some cases, the filter does not perfectly fit the input
    matrix. What do we mean by that? For example, let''s say we are performing a convolution
    operation with a stride of 2\. There exists a situation where, when we move our
    filter matrix by two pixels, it reaches the border and the filter matrix does
    not fit the input matrix. That is, some part of our filter matrix is outside the
    input matrix, as shown in the following diagram:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积操作中，我们是用滤波器矩阵在输入矩阵上滑动。但在某些情况下，滤波器无法完美地适配输入矩阵。这里是什么意思呢？举个例子，假设我们正在进行步长为2的卷积操作。在某些情况下，当我们将滤波器矩阵移动两个像素时，它会到达边界，而滤波器矩阵无法适配输入矩阵。也就是说，滤波器矩阵的一部分超出了输入矩阵，如下图所示：
- en: '![](img/B15558_07_37.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_37.png)'
- en: 'Figure 7.36: Padding operation'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.36：填充操作
- en: 'In this case, we perform padding. We can simply pad the input matrix with zeros
    so that the filter can fit the input matrix, as shown in *Figure 7.37*. Padding
    with zeros on the input matrix is called **same padding** or **zero padding**:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们执行填充操作。我们可以简单地用零填充输入矩阵，使得滤波器能够适配输入矩阵，如*图7.37*所示。用零填充输入矩阵的操作称为**相同填充**或**零填充**：
- en: '![](img/B15558_07_38.png)'
  id: totrans-375
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_38.png)'
- en: 'Figure 7.37: Same padding'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.37：相同填充
- en: 'Instead of padding them with zeros, we can also simply discard the region of
    the input matrix where the filter doesn''t fit in. This is called **valid padding**:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以选择不使用零填充，而是直接丢弃滤波器无法适配的输入矩阵区域。这称为**有效填充**：
- en: '![](img/B15558_07_39.png)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_39.png)'
- en: 'Figure 7.38: Valid padding'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.38：有效填充
- en: Pooling layers
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 池化层
- en: Okay. Now, we are done with the convolution operation. As a result of the convolution
    operation, we have some feature maps. But the feature maps are too large in dimension.
    In order to reduce the dimensions of feature maps, we perform a pooling operation.
    This reduces the dimensions of the feature maps and keeps only the necessary details
    so that the amount of computation can be reduced.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们已经完成了卷积操作。通过卷积操作，我们得到了特征图。但是特征图的维度太大了。为了减少特征图的维度，我们进行池化操作。池化操作减少了特征图的维度，只保留必要的细节，从而减少计算量。
- en: For example, to recognize a horse from the image, we need to extract and keep
    only the features of the horse; we can simply discard unwanted features, such
    as the background of the image and more. A pooling operation is also called a
    **downsampling** or **subsampling** operation, and it makes the CNN translation
    invariant. Thus, the pooling layer reduces spatial dimensions by keeping only
    the important features.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，为了从图像中识别马，我们需要提取并仅保留马的特征；我们可以简单地丢弃不需要的特征，例如图像的背景等。池化操作也叫做**下采样**或**子采样**操作，它使得CNN具有平移不变性。因此，池化层通过只保留重要特征来减少空间维度。
- en: There are different types of pooling operations, including max pooling, average
    pooling, and sum pooling.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同类型的池化操作，包括最大池化、平均池化和求和池化。
- en: 'In max pooling, we slide over the filter on the input matrix and simply take
    the maximum value from the filter window, as *Figure 7.39* shows:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在最大池化中，我们在输入矩阵上滑动滤波器，并简单地从滤波窗口中取最大值，如*图7.39*所示：
- en: '![](img/B15558_07_40.png)'
  id: totrans-385
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_40.png)'
- en: 'Figure 7.39: Max pooling'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.39：最大池化
- en: In average pooling, we take the average value of the input matrix within the
    filter window, and in sum pooling, we sum all the values of the input matrix within
    the filter window.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在平均池化中，我们在滤波窗口内取输入矩阵的平均值，在求和池化中，我们将滤波窗口内输入矩阵的所有值求和。
- en: Fully connected layers
  id: totrans-388
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全连接层
- en: So far, we've learned how convolutional and pooling layers work. A CNN can have
    multiple convolutional layers and pooling layers. However, these layers will only
    extract features from the input image and produce the feature map; that is, they
    are just the feature extractors.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了卷积层和池化层的工作原理。一个CNN可以有多个卷积层和池化层。然而，这些层仅仅从输入图像中提取特征并生成特征图；也就是说，它们只是特征提取器。
- en: Given any image, convolutional layers extract features from the image and produce
    a feature map. Now, we need to classify these extracted features. So, we need
    an algorithm that can classify these extracted features and tell us whether the
    extracted features are the features of a horse, or something else. In order to
    make this classification, we use a feedforward neural network. We flatten the
    feature map and convert it into a vector, and feed it as an input to the feedforward
    network.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 给定任何图像，卷积层从图像中提取特征并生成特征图。现在，我们需要对这些提取的特征进行分类。因此，我们需要一个算法来分类这些提取的特征，并告诉我们这些特征是马的特征，还是其他的特征。为了进行分类，我们使用前馈神经网络。我们将特征图扁平化并将其转换为一个向量，然后将其作为输入传递给前馈网络。
- en: 'The feedforward network takes this flattened feature map as an input, applies
    an activation function, such as sigmoid, and returns the output, stating whether
    the image contains a horse or not; this is called a fully connected layer and
    is shown in the following diagram:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 前馈网络将这个扁平化的特征图作为输入，应用激活函数，例如sigmoid，并返回输出，指出图像是否包含马；这被称为全连接层，下面的图示展示了这一过程：
- en: '![](img/B15558_07_41.png)'
  id: totrans-392
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_41.png)'
- en: 'Figure 7.40: Fully connected layer'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.40：全连接层
- en: Let's see how all this fits together.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这些如何融合在一起。
- en: The architecture of CNNs
  id: totrans-395
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CNN的架构
- en: '*Figure 7.41* shows the architecture of a CNN:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.41*展示了CNN的架构：'
- en: '![](img/B15558_07_42.png)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_42.png)'
- en: 'Figure 7.41: Architecture of CNN'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.41：CNN架构
- en: As you will notice, first we feed the input image to the convolutional layer,
    where we apply the convolution operation to extract important features from the
    image and create the feature maps. We then pass the feature maps to the pooling
    layer, where the dimensions of the feature maps will be reduced.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所注意到的，首先我们将输入图像传递给卷积层，在这里我们应用卷积操作，从图像中提取重要特征并创建特征图。然后，我们将特征图传递给池化层，在池化层中，特征图的维度将会被降低。
- en: As shown in the previous diagram, we can have multiple convolutional and pooling
    layers, and we should also note that the pooling layer does not necessarily have
    to be there after every convolutional layer; there can be many convolutional layers
    followed by a pooling layer.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的图所示，我们可以有多个卷积层和池化层，同时也需要注意，池化层不一定必须跟在每个卷积层之后；可以有多个卷积层，之后才接池化层。
- en: So, after the convolutional and pooling layers, we flatten the resultant feature
    maps and feed it to a fully connected layer, which is basically a feedforward
    neural network that classifies the given input image based on the feature maps.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，在卷积层和池化层之后，我们将结果特征图展平，并将其输入到全连接层，这基本上是一个前馈神经网络，依据特征图对给定的输入图像进行分类。
- en: Now that we have learned how CNNs work, in the next section, we will learn about
    another interesting algorithm called the generative adversarial network.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了卷积神经网络（CNN）的工作原理，在接下来的部分，我们将学习另一个有趣的算法——生成对抗网络。
- en: Generative adversarial networks
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: '**Generative Adversarial Networks** (**GANs**) was first introduced by Ian
    J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil
    Ozair, Aaron Courville, and Yoshua Bengio in their paper, *Generative Adversarial
    Networks*, in 2014.'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成对抗网络**（**GAN**）最早由Ian J. Goodfellow、Jean Pouget-Abadie、Mehdi Mirza、Bing
    Xu、David Warde-Farley、Sherjil Ozair、Aaron Courville和Yoshua Bengio在他们2014年的论文《生成对抗网络》中提出。'
- en: GANs are used extensively for generating new data points. They can be applied
    to any type of dataset, but they are popularly used for generating images. Some
    of the applications of GANs include generating realistic human faces, converting
    grayscale images to colored images, translating text descriptions into realistic
    images, and many more.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络（GAN）广泛用于生成新的数据点。它们可以应用于任何类型的数据集，但通常用于生成图像。生成对抗网络的一些应用包括生成逼真的人脸图像、将灰度图像转换为彩色图像、将文本描述转化为逼真的图像等。
- en: 'GANs have evolved so much in recent years that they can generate a very realistic
    image. The following figure shows the evolution of GANs in generating images over the
    course of five years:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，生成对抗网络（GAN）已经发展得非常成熟，能够生成非常逼真的图像。下图展示了生成对抗网络在五年内生成图像的演变过程：
- en: '![](img/B15558_07_43.png)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_43.png)'
- en: 'Figure 7.42: Evolution of GANs over the years'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.42：生成对抗网络的演变过程
- en: Excited about GANs already? Now, we will see how exactly they work. Before going
    ahead, let's consider a simple analogy. Let's say you are the police and your
    task is to find counterfeit money, and the role of the counterfeiter is to create
    fake money and cheat the police.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 对生成对抗网络（GAN）感到兴奋了吗？现在，我们将详细了解它们是如何工作的。在继续之前，让我们考虑一个简单的类比。假设你是警察，你的任务是找出伪钞，而伪钞制造者的角色是制造假钞并欺骗警察。
- en: 'The counterfeiter constantly tries to create fake money in a way that is so
    realistic that it cannot be differentiated from the real money. But the police
    have to identify whether the money is real or fake. So, the counterfeiter and
    the police essentially play a two-player game where one tries to defeat the other.
    GANs work something like this. They consist of two important components:'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 伪钞制造者不断尝试制造出与真钞几乎无法区分的假钞，但警察的任务是判断钞票是真是假。所以，伪钞制造者和警察实际上是在进行一场双人对抗游戏，其中一个试图战胜另一个。生成对抗网络的工作原理也类似。它们由两个重要的组件组成：
- en: Generator
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器
- en: Discriminator
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器
- en: You can perceive the generator as analogous to the counterfeiter, while the
    discriminator is analogous to the police. That is, the role of the generator is
    to create fake money, and the role of the discriminator is to identify whether
    the money is fake or real.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将生成器看作是伪钞制造者，而判别器则类似于警察。也就是说，生成器的角色是制造假钞，而判别器的角色是识别这些钞票是真是假。
- en: 'Without going into detail, first, we will get a basic understanding of GANs.
    Let''s say we want our GAN to generate handwritten digits. How can we do that?
    First, we will take a dataset containing a collection of handwritten digits; say,
    the MNIST dataset. The generator learns the distribution of images in our dataset.
    Thus, it learns the distribution of handwritten digits in our training set. Once,
    it learns the distribution of the images in our dataset, and we feed a random
    noise to the generator, it will convert the random noise into a new handwritten
    digit similar to the one in our training set based on the learned distribution:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 在不深入细节的情况下，我们首先对 GAN 有一个基本的了解。假设我们希望我们的 GAN 生成手写数字。我们该如何做到呢？首先，我们将获取一个包含手写数字的数据库，比如
    MNIST 数据集。生成器学习我们数据集中的图像分布。因此，它学习训练集中手写数字的分布。一旦它学习到数据集中的图像分布，我们向生成器输入随机噪声，它将根据学到的分布，将随机噪声转换为类似于我们训练集中手写数字的新图像：
- en: '![](img/B15558_07_44.png)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_44.png)'
- en: 'Figure 7.43: Generator'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7.43: 生成器'
- en: 'The goal of the discriminator is to perform a classification task. Given an
    image, it classifies it as real or fake; that is, whether the image is from the
    training set or the image is generated by the generator:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器的目标是执行分类任务。给定一张图像，它将其分类为真实或虚假；也就是说，判断该图像是来自训练集，还是由生成器生成的图像：
- en: '![](img/B15558_07_45.png)'
  id: totrans-418
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_45.png)'
- en: 'Figure 7.44: Discriminator'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7.44: 判别器'
- en: The generator component of GAN is basically a generative model, and the discriminator
    component is basically a discriminative model. Thus, the generator learns the
    distribution of the class and the discriminator learns the decision boundary of
    a class.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 的生成器组件基本上是一个生成模型，而判别器组件基本上是一个判别模型。因此，生成器学习类别的分布，判别器学习类别的决策边界。
- en: 'As *Figure 7.45* shows, we feed random noise to the generator, and it then
    converts this random noise into a new image similar to the one we have in our
    training set, but not exactly the same as the images in the training set. The
    image generated by the generator is called a fake image, and the images in our
    training set are called real images. We feed both the real and fake images to
    the discriminator, which tells us the probability of them being real. It returns
    0 if the image is fake and 1 if the image is real:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图 7.45*所示，我们向生成器输入随机噪声，生成器将这些随机噪声转换为一张新的图像，这张图像与我们训练集中的图像相似，但不完全相同。由生成器生成的图像称为假图像，而训练集中的图像称为真实图像。我们将真实图像和假图像都输入判别器，判别器告诉我们它们是“真实”的概率。如果图像是假的，它返回
    0；如果图像是真的，它返回 1：
- en: '![](img/B15558_07_46.png)'
  id: totrans-422
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_46.png)'
- en: 'Figure 7.45: GAN'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7.45: GAN'
- en: Now that we have a basic understanding of generators and discriminators, we
    will study each of the components in detail.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对生成器和判别器有了基本了解，我们将详细研究每个组件。
- en: Breaking down the generator
  id: totrans-425
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 解析生成器
- en: The generator component of a GAN is a generative model. When we say the generative
    model, there are two types of generative models—an **implicit** and an **explicit**
    density model. The implicit density model does not use any explicit density function
    to learn the probability distribution, whereas the explicit density model, as
    the name suggests, uses an explicit density function. GANs falls into the first
    category. That is, they are an implicit density model. Let's study in detail and
    understand how GANs are an implicit density model.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 的生成器组件是一个生成模型。我们所说的生成模型有两种类型——**隐式**和**显式**密度模型。隐式密度模型不使用任何显式密度函数来学习概率分布，而显式密度模型顾名思义，使用显式密度函数。GAN
    属于第一类。也就是说，它们是一个隐式密度模型。让我们详细研究并理解 GAN 是如何成为一个隐式密度模型的。
- en: Let's say we have a generator, *G*. It is basically a neural network parametrized
    by ![](img/B15558_07_070.png). The role of the generator network is to generate
    new images. How do they do that? What should be the input to the generator?
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个生成器，*G*。它基本上是一个由 ![](img/B15558_07_070.png) 参数化的神经网络。生成器网络的作用是生成新的图像。它们是如何做到这一点的呢？生成器的输入应该是什么？
- en: 'We sample a random noise, *z*, from a normal or uniform distribution, *P*[z].
    We feed this random noise, *z*, as an input to the generator and then it converts
    this noise to an image:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个正态分布或均匀分布中采样一个随机噪声，*z*，其概率分布为 *P*[z]。我们将这个随机噪声 *z* 作为输入传递给生成器，然后生成器将这个噪声转换为一张图像：
- en: '![](img/B15558_07_071.png)'
  id: totrans-429
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_071.png)'
- en: Surprising, isn't it? How does the generator convert random noise to a realistic
    image?
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 惊讶吧？生成器是如何将随机噪声转换为逼真的图像的呢？
- en: Let's say we have a dataset containing a collection of human faces and we want
    our generator to generate a new human face. First, the generator learns all the
    features of the face by learning the probability distribution of the images in
    our training set. Once the generator learns the correct probability distribution,
    it can generate totally new human faces.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个包含人脸图像的数据集，我们希望生成器生成一张新的面部图像。首先，生成器通过学习我们训练集中的图像概率分布来学习面部的所有特征。一旦生成器学会了正确的概率分布，它就能生成全新的面部图像。
- en: But how does the generator learn the distribution of the training set? That
    is, how does the generator learn the distribution of images of human faces in
    the training set?
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，生成器是如何学习训练集的分布的呢？也就是说，生成器是如何学习训练集中人脸图像的分布的？
- en: A generator is nothing but a neural network. So, what happens is that the neural
    network learns the distribution of the images in our training set implicitly;
    let's call this distribution a generator distribution, *P*[g]. At the first iteration,
    the generator generates a really noisy image. But over a series of iterations,
    it learns the exact probability distribution of our training set and learns to
    generate a correct image by tuning its ![](img/B15558_07_070.png) parameter.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器其实不过是一个神经网络。那么，发生的事情是，神经网络隐式地学习了我们训练集中的图像分布；我们把这个分布叫做生成器分布，*P*[g]。在第一次迭代时，生成器生成的是一张非常嘈杂的图像。但经过多次迭代后，它学会了我们训练集的确切概率分布，并通过调整其![](img/B15558_07_070.png)参数学会生成正确的图像。
- en: It is important to note that we are not using the uniform distribution *P*[z]
    for learning the distribution of our training set. It is only used for sampling
    random noise, and we feed this random noise as an input to the generator. The
    generator network implicitly learns the distribution of our training set and we
    call this distribution a generator distribution, *P*[g] and that is why we call
    our generator network an implicit density model.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，我们并没有使用均匀分布*P*[z]来学习训练集的分布。它只是用来采样随机噪声，我们将这些随机噪声作为输入馈送给生成器。生成器网络隐式地学习了我们训练集的分布，我们把这个分布叫做生成器分布，*P*[g]，这就是我们称生成器网络为隐式密度模型的原因。
- en: Now that we understand the generator, let's move on to the discriminator.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了生成器，让我们来看看鉴别器。
- en: Breaking down the discriminator
  id: totrans-436
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 拆解鉴别器
- en: As the name suggests, the discriminator is a discriminative model. Let's say
    we have a discriminator, *D*. It is also a neural network and it is parametrized
    by ![](img/B15558_07_073.png).
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 如名字所示，鉴别器是一个判别模型。假设我们有一个鉴别器，*D*。它也是一个神经网络，并且由![](img/B15558_07_073.png)参数化。
- en: 'The goal of the discriminator is to discriminate between two classes. That
    is, given an image *x*, it has to identify whether the image is from a real distribution
    or a fake distribution (generator distribution). That is, the discriminator has
    to identify whether the given input image is from the training set or the fake
    image generated by the generator:'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴别器的目标是区分两类图像。也就是说，给定一张图像*x*，它必须识别该图像是来自真实分布还是伪造分布（生成器分布）。也就是说，鉴别器必须识别输入的图像是来自训练集，还是来自生成器生成的伪造图像：
- en: '![](img/B15558_07_074.png)'
  id: totrans-439
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_074.png)'
- en: Let's call the distribution of our training set the real data distribution,
    which is represented by *P*[r]. We know that the generator distribution is represented
    by *P*[g].
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 我们把训练集的分布叫做真实数据分布，用*P*[r]表示。我们知道生成器分布用*P*[g]表示。
- en: So, the discriminator *D* essentially tries to discriminate whether the image
    *x* is from *P*[r] or *P*[g].
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，鉴别器*D*本质上是在尝试判断图像*x*是来自*P*[r]还是*P*[g]。
- en: How do they learn, though?
  id: totrans-442
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 那么，它们是如何学习的呢？
- en: So far, we just studied the role of the generator and discriminator, but how
    do they learn exactly? How does the generator learn to generate new realistic
    images and how does the discriminator learn to discriminate between images correctly?
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只研究了生成器和鉴别器的作用，但它们究竟是如何学习的呢？生成器是如何学会生成新的真实图像的，鉴别器又是如何学会正确区分图像的呢？
- en: We know that the goal of the generator is to generate an image in such a way
    as to fool the discriminator into believing that the generated image is from a
    real distribution.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道生成器的目标是生成一张图像，使得它能够欺骗鉴别器，让鉴别器相信生成的图像来自真实分布。
- en: In the first iteration, the generator generates a noisy image. When we feed
    this image to the discriminator, it can easily detect that the image is from a
    generator distribution. The generator takes this as a loss and tries to improve
    itself, as its goal is to fool the discriminator. That is, if the generator knows
    that the discriminator is easily detecting the generated image as a fake image,
    then it means that it is not generating an image similar to those in the training
    set. This implies that it has not learned the probability distribution of the
    training set yet.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次迭代中，生成器生成了一张噪声图像。当我们将此图像输入鉴别器时，它可以轻松地检测到该图像来自生成器分布。生成器将此视为一种损失并尝试改进自身，因为它的目标是欺骗鉴别器。也就是说，如果生成器知道鉴别器容易将生成的图像检测为虚假图像，那么这意味着它没有生成类似于训练集中图像的图像。这暗示着它还没有学习到训练集的概率分布。
- en: So, the generator tunes its parameters in such a way as to learn the correct
    probability distribution of the training set. As we know that the generator is
    a neural network, we simply update the parameters of the network through backpropagation.
    Once it has learned the probability distribution of the real images, then it can
    generate images similar to the ones in the training set.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，生成器调整其参数，以学习训练集的正确概率分布。正如我们所知，生成器是一个神经网络，我们只需通过反向传播更新网络的参数。一旦它学会了真实图像的概率分布，就能够生成与训练集中图像相似的图像。
- en: Okay, what about the discriminator? How does it learn? As we know, the role
    of the discriminator is to discriminate between real and fake images.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，鉴别器呢？它是如何学习的？如我们所知，鉴别器的作用是区分真实和虚假图像。
- en: If the discriminator incorrectly classifies the generated image; that is, if
    the discriminator classifies the fake image as a real image, then it implies that
    the discriminator has not learned to differentiate between the real and fake image.
    So, we update the parameter of the discriminator network through backpropagation
    to make the discriminator learn to classify between real and fake images.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 如果鉴别器错误地分类了生成的图像；也就是说，如果鉴别器将虚假图像分类为真实图像，那么就意味着鉴别器没有学会区分真实和虚假图像。因此，我们通过反向传播更新鉴别器网络的参数，使得鉴别器学会区分真实和虚假图像。
- en: So, basically, the generator is trying to fool the discriminator by learning
    the real data distribution, *P*[r], and the discriminator is trying to find out
    whether the image is from a real or fake distribution. Now the question is, when
    do we stop training the network in light of the fact that the generator and discriminator
    are competing against each other?
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，基本上，生成器通过学习真实数据分布*P*[r]来试图欺骗鉴别器，而鉴别器则试图判断图像是来自真实分布还是虚假分布。那么问题来了，我们应该在何时停止训练网络，因为生成器和鉴别器在相互竞争？
- en: Basically, the goal of the GAN is to generate images similar to the one in the
    training set. Say we want to generate a human face—we learn the distribution of
    images in the training set and generate new faces. So, for a generator, we need
    to find the optimal discriminator. What do we mean by that?
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，GAN的目标是生成与训练集中图像相似的图像。假设我们想生成一张人脸——我们学习训练集中图像的分布，然后生成新的面孔。因此，对于生成器，我们需要找到最佳的鉴别器。这是什么意思呢？
- en: 'We know that a generator distribution is represented by *P*[g] and the real
    data distribution is represented by *P*[r]. If the generator learns the real data
    distribution perfectly, then *P*[g] equals *P*[r], as *Figure 7.46* shows:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，生成器分布由*P*[g]表示，而真实数据分布由*P*[r]表示。如果生成器完美地学习了真实数据的分布，那么*P*[g]就等于*P*[r]，正如*图
    7.46*所示：
- en: '![](img/B15558_07_47.png)'
  id: totrans-452
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_47.png)'
- en: 'Figure 7.46: Generator and real data distribution'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.46：生成器和真实数据分布
- en: When *P*[g] = *P*[r], then the discriminator cannot differentiate between whether
    the input image is from a real or a fake distribution, so it will just return
    0.5 as a probability, as the discriminator will become confused between the two
    distributions when they are the same.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 当*P*[g] = *P*[r]时，鉴别器无法区分输入图像是来自真实分布还是虚假分布，因此它会返回0.5作为概率，因为当两者分布相同时，鉴别器会变得混淆。
- en: 'So, for a generator, the optimal discriminator can be given as follows:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于生成器，最佳的鉴别器可以定义如下：
- en: '![](img/B15558_07_075.png)'
  id: totrans-456
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_075.png)'
- en: So, when the discriminator just returns the probability of 0.5 for all the generator
    images, then we can say that the generator has learned the distribution of images
    in our training set and has fooled the discriminator successfully.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当判别器对所有生成器生成的图像返回 0.5 的概率时，我们可以说生成器已经学习到了训练集图像的分布，并成功欺骗了判别器。
- en: Architecture of a GAN
  id: totrans-458
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GAN 的架构
- en: '*Figure 7.47* shows the architecture of a GAN:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.47* 显示了 GAN 的架构：'
- en: '![](img/B15558_07_48.png)'
  id: totrans-460
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_48.png)'
- en: 'Figure 7.47: Architecture of GAN'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.47：GAN 的架构
- en: As shown in the preceding diagram, generator *G* takes the random noise, *z*,
    as input by sampling from a uniform or normal distribution and generates a fake
    image by implicitly learning the distribution of the training set.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的图示所示，生成器 *G* 将随机噪声 *z* 作为输入，通过从均匀分布或正态分布中采样，隐式学习训练集的分布并生成假图像。
- en: We sample an image, *x*, from the real data distribution, ![](img/B15558_07_076.png),
    and fake data distribution, ![](img/B15558_07_077.png), and feed it to the discriminator,
    *D*. We feed real and fake images to the discriminator and the discriminator performs
    a binary classification task. That is, it returns 0 when the image is fake and
    1 when the image is real.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从真实数据分布 ![](img/B15558_07_076.png) 和假数据分布 ![](img/B15558_07_077.png) 中采样图像
    *x*，并将其输入到判别器 *D* 中。我们将真实图像和假图像输入判别器，判别器执行二分类任务。也就是说，当图像是假的时，它返回 0，当图像是真的时，它返回
    1。
- en: Demystifying the loss function
  id: totrans-464
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 揭开损失函数的神秘面纱
- en: 'Now we will examine the loss function of the GAN. Before going ahead, let''s
    recap the notation:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将研究 GAN 的损失函数。在继续之前，先回顾一下符号：
- en: A noise that is fed as an input to the generator is represented by *z*
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为生成器输入的噪声用 *z* 表示
- en: The uniform or normal distribution from which the noise *z* is sampled is represented
    by *P*[z]
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 噪声 *z* 的采样来自均匀分布或正态分布，该分布用 *P*[z] 表示
- en: An input image is represented by *x*
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入图像由 *x* 表示
- en: The real data distribution or the distribution of our training set is represented
    by *P*[r]
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真实数据分布或训练集的分布用 *P*[r] 表示
- en: The fake data distribution or the distribution of the generator is represented
    by *P*[g]
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假数据分布或生成器的分布用 *P*[g] 表示
- en: When we write ![](img/B15558_07_078.png), it implies that image *x* is sampled
    from the real distribution, *P*[r]. Similarly, ![](img/B15558_07_079.png) denotes
    that image *x* is sampled from the generator distribution, *P*[g], and ![](img/B15558_07_080.png)
    implies that the generator input, *z*, is sampled from the uniform distribution,
    *P*[z].
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们写出 ![](img/B15558_07_078.png) 时，意味着图像 *x* 是从真实分布 *P*[r] 中采样的。同样，![](img/B15558_07_079.png)
    表示图像 *x* 是从生成器分布 *P*[g] 中采样的，而 ![](img/B15558_07_080.png) 则意味着生成器输入 *z* 是从均匀分布
    *P*[z] 中采样的。
- en: We've learned that both the generator and discriminator are neural networks
    and both of them update their parameters through backpropagation. We now need
    to find the optimal generator parameter, ![](img/B15558_07_081.png), and the discriminator
    parameter, ![](img/B15558_07_082.png).
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解到，生成器和判别器都是神经网络，且它们都会通过反向传播来更新其参数。现在我们需要找到最优的生成器参数 ![](img/B15558_07_081.png)
    和判别器参数 ![](img/B15558_07_082.png)。
- en: Discriminator loss
  id: totrans-473
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 判别器损失
- en: Now we will look at the loss function of the discriminator. We know that the
    goal of the discriminator is to classify whether the image is a real or a fake
    image. Let's denote the discriminator by *D*.
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看看判别器的损失函数。我们知道判别器的目标是分类图像是真实的还是假的。我们用 *D* 来表示判别器。
- en: 'The loss function of the discriminator is given as follows:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 判别器的损失函数如下所示：
- en: '![](img/B15558_07_083.png)'
  id: totrans-476
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_083.png)'
- en: What does this mean, though? Let's understand each of the terms one by one.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着什么呢？让我们逐个理解这些术语。
- en: First term
  id: totrans-478
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第一项
- en: 'Let''s look at the first term:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看第一项：
- en: '![](img/B15558_07_084.png)'
  id: totrans-480
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_084.png)'
- en: Here, ![](img/B15558_07_085.png) implies that we are sampling input *x* from
    the real data distribution, *P*[r], so *x* is a real image.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B15558_07_085.png) 表示我们从真实数据分布 *P*[r] 中采样输入 *x*，因此 *x* 是一张真实图像。
- en: '*D*(*x*) implies that we are feeding the input image *x* to the discriminator
    *D*, and the discriminator will return the probability of input image *x* to be
    a real image. As *x* is sampled from real data distribution *P*[r], we know that
    *x* is a real image. So, we need to maximize the probability of *D*(*x*):'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: '*D*(*x*) 表示我们将输入图像 *x* 提供给判别器 *D*，判别器将返回输入图像 *x* 是真实图像的概率。由于 *x* 是从真实数据分布 *P*[r]
    中采样的，我们知道 *x* 是一张真实图像。因此，我们需要最大化 *D*(*x*) 的概率：'
- en: '![](img/B15558_07_086.png)'
  id: totrans-483
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_086.png)'
- en: 'But instead of maximizing raw probabilities, we maximize log probabilities,
    so, we can write the following:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们不是最大化原始概率，而是最大化对数概率，因此，我们可以写出以下内容：
- en: '![](img/B15558_07_087.png)'
  id: totrans-485
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_087.png)'
- en: 'So, our final equation becomes the following:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们的最终方程变为以下形式：
- en: '![](img/B15558_07_088.png)'
  id: totrans-487
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_088.png)'
- en: '![](img/B15558_07_089.png) represents the expectations of the log-likelihood
    of input images sampled from the real data distribution being real.'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B15558_07_089.png) 表示从真实数据分布中采样的输入图像为真实图像的对数似然期望。'
- en: Second term
  id: totrans-489
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第二项
- en: 'Now, let''s look at the second term:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一下第二项：
- en: '![](img/B15558_07_090.png)'
  id: totrans-491
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_090.png)'
- en: Here, ![](img/B15558_07_091.png) shows that we are sampling a random noise *z*
    from the uniform distribution *P*[z]. *G*(*z*) implies that the generator *G*
    takes the random noise *z* as an input and returns a fake image based on its implicitly
    learned distribution *P*[g].
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B15558_07_091.png) 表示我们从均匀分布 *P*[z] 中采样一个随机噪声 *z*。*G*(*z*) 表示生成器
    *G* 以随机噪声 *z* 作为输入，并根据其隐式学习的分布 *P*[g] 返回一张假图像。
- en: '*D*(*G*(*z*)) implies that we are feeding the fake image generated by the generator
    to the discriminator *D* and it will return the probability of the fake input
    image being a real image.'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: '*D*(*G*(*z*)) 表示我们将生成器生成的假图像输入到判别器 *D* 中，判别器将返回该假输入图像是一个真实图像的概率。'
- en: 'If we subtract *D*(*G*(*z*)) from 1, then it will return the probability of
    the fake input image being a fake image:'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从 1 中减去 *D*(*G*(*z*))，那么它将返回假输入图像是一个假图像的概率：
- en: '![](img/B15558_07_092.png)'
  id: totrans-495
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_092.png)'
- en: 'Since we know *z* is not a real image, the discriminator will maximize this
    probability. That is, the discriminator maximizes the probability of *z* being
    classified as a fake image, so we write:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们知道 *z* 不是一张真实的图像，判别器将最大化这个概率。也就是说，判别器最大化 *z* 被分类为假图像的概率，因此我们写出：
- en: '![](img/B15558_07_093.png)'
  id: totrans-497
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_093.png)'
- en: 'Instead of maximizing raw probabilities, we maximize the log probability:'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不是最大化原始概率，而是最大化对数概率：
- en: '![](img/B15558_07_094.png)'
  id: totrans-499
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_094.png)'
- en: '![](img/B15558_07_095.png) implies the expectations of the log likelihood of
    the input images generated by the generator being fake.'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/B15558_07_095.png) 表示生成器生成的输入图像为假图像的对数似然期望。'
- en: Final term
  id: totrans-501
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 最后一项
- en: 'So, combining these two terms, the loss function of the discriminator is given
    as follows:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，结合这两项，判别器的损失函数表示为：
- en: '![](img/B15558_07_083.png)'
  id: totrans-503
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_083.png)'
- en: Here, ![](img/B15558_07_097.png) and ![](img/B15558_07_098.png) are the parameters
    of the generator and discriminator network respectively. So, the discriminator's
    goal is to find the right ![](img/B15558_07_099.png) so that it can classify the
    image correctly.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/B15558_07_097.png) 和 ![](img/B15558_07_098.png) 分别是生成器和判别器网络的参数。因此，判别器的目标是找到合适的
    ![](img/B15558_07_099.png)，以便它可以正确地分类图像。
- en: Generator loss
  id: totrans-505
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成器损失
- en: 'The loss function of the generator is given as follows:'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器的损失函数如下：
- en: '![](img/B15558_07_100.png)'
  id: totrans-507
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_100.png)'
- en: We know that the goal of the generator is to fool the discriminator to classify
    the fake image as a real image.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道生成器的目标是欺骗判别器，将假图像分类为真实图像。
- en: In the *Discriminator loss* section, we saw that ![](img/B15558_07_101.png)
    implies the probability of classifying the fake input image as a fake image, and
    the discriminator maximizes the probabilities for correctly classifying the fake
    image as fake.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *判别器损失* 部分，我们看到 ![](img/B15558_07_101.png) 表示将假输入图像分类为假图像的概率，而判别器最大化正确将假图像分类为假的概率。
- en: 'But the generator wants to minimize this probability. As the generator wants
    to fool the discriminator, it minimizes this probability of a fake input image
    being classified as fake by the discriminator. Thus, the loss function of the
    generator can be expressed as follows:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 但生成器希望最小化这个概率。由于生成器希望欺骗判别器，它最小化假输入图像被判别器分类为假图像的概率。因此，生成器的损失函数可以表示为：
- en: '![](img/B15558_07_100.png)'
  id: totrans-511
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_100.png)'
- en: Total loss
  id: totrans-512
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总损失
- en: 'We just learned the loss function of the generator and the discriminator combining
    these two losses, and we write our final loss function as follows:'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚了解了生成器和判别器的损失函数，通过结合这两者，我们将最终的损失函数写为：
- en: '![](img/B15558_07_103.png)'
  id: totrans-514
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_103.png)'
- en: So, our objective function is basically a min-max objective function, that is,
    a maximization for the discriminator and a minimization for the generator, and
    we find the optimal generator parameter, ![](img/B15558_07_104.png), and discriminator
    parameter, ![](img/B15558_07_105.png), through backpropagating the respective
    networks.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的目标函数本质上是一个min-max目标函数，也就是对判别器进行最大化，对生成器进行最小化，并且我们通过反向传播相应的网络来找到最优的生成器参数！[](img/B15558_07_104.png)，和判别器参数！[](img/B15558_07_105.png)。
- en: 'So, we perform gradient ascent; that is, maximization on the discriminator:'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们进行梯度上升；也就是说，对判别器进行最大化：
- en: '![](img/B15558_07_106.png)'
  id: totrans-517
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_106.png)'
- en: 'And, we perform gradient descent; that is, minimization on the generator:'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，我们进行梯度下降；也就是说，对生成器进行最小化：
- en: '![](img/B15558_07_107.png)'
  id: totrans-519
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15558_07_107.png)'
- en: Summary
  id: totrans-520
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概要
- en: We started off the chapter by understanding biological and artificial neurons.
    Then we learned about ANNs and their layers. We learned different types of activation
    functions and how they are used to introduce nonlinearity in the network.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过理解生物神经元和人工神经元开始了本章的学习。然后我们学习了ANN及其层次结构。我们了解了不同类型的激活函数以及它们如何在网络中引入非线性。
- en: Later, we learned about the forward and backward propagation in the neural network.
    Next, we learned how to implement an ANN. Moving on, we learned about RNNs and
    how they differ from feedforward networks. Next, we learned about the variant
    of the RNN called LSTM. Going forward, we learned about CNNs, how they use different
    types of layers, and the architecture of CNNs in detail.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 后来，我们学习了神经网络中的前向传播和反向传播。接着，我们学习了如何实现一个ANN。接下来，我们了解了RNN以及它们与前馈网络的不同之处。然后，我们学习了RNN的一个变种——LSTM。接着，我们学习了CNN，了解了它们如何使用不同类型的层，并详细探讨了CNN的架构。
- en: At the end of the chapter, we learned about an interesting algorithm called
    GAN. We understood the generator and discriminator component of GAN and we also
    explored the architecture of GAN in detail. Followed by that, we examined the
    loss function of GAN in detail.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，我们了解了一个有趣的算法——GAN。我们理解了GAN的生成器和判别器组件，并且详细探讨了GAN的架构。接着，我们详细研究了GAN的损失函数。
- en: In the next chapter, we will learn about one of the most popularly used deep
    learning frameworks, called TensorFlow.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习一个最受欢迎的深度学习框架——TensorFlow。
- en: Questions
  id: totrans-525
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Let''s assess our understanding of deep learning algorithms by answering the
    following questions:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过回答以下问题来评估我们对深度学习算法的理解：
- en: What is the activation function?
  id: totrans-527
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是激活函数？
- en: Define the softmax function.
  id: totrans-528
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义softmax函数。
- en: What is an epoch?
  id: totrans-529
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是一个epoch？
- en: What are some of the applications of RNNs?
  id: totrans-530
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RNN的一些应用是什么？
- en: Explain the vanishing gradient problem.
  id: totrans-531
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释消失梯度问题。
- en: What are the different types of pooling operations?
  id: totrans-532
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有哪些不同类型的池化操作？
- en: Explain the generator and discriminator components of GANs.
  id: totrans-533
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解释GAN的生成器和判别器组件。
- en: Further reading
  id: totrans-534
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: To learn more about deep learning algorithms, you can check out my book **Hands-on
    Deep Learning Algorithms with Python**, also published by Packt, at [https://www.packtpub.com/in/big-data-and-business-intelligence/hands-deep-learning-algorithms-python](https://www.packtpub.com/in/big-data-and-business-intelligence/hands-deep-learning-algorithms-python).
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 若要了解更多关于深度学习算法的内容，可以查看我出版的书籍《**Python深度学习算法实战**》，该书同样由Packt出版，链接：[https://www.packtpub.com/in/big-data-and-business-intelligence/hands-deep-learning-algorithms-python](https://www.packtpub.com/in/big-data-and-business-intelligence/hands-deep-learning-algorithms-python)。
