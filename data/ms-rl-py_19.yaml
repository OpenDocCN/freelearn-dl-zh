- en: '*Chapter 15*: Supply Chain Management'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第15章*：供应链管理'
- en: Effective supply chain management is a challenge for many businesses, yet it
    is key to their profitability and competitiveness. The difficulty in this area
    comes from a complex set of dynamics affecting supply and demand, the business
    constraints around handling these dynamics, and a level of great uncertainty throughout.
    **Reinforcement learning** (**RL**) provides us with a key set of capabilities
    to address such sequential decision-making problems.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的供应链管理是许多企业面临的挑战，但它对于企业的盈利能力和竞争力至关重要。这一领域的困难来自于影响供需关系的复杂动态、处理这些动态的商业约束，以及其中巨大的不确定性。**强化学习**（**RL**）为我们提供了一套关键能力，帮助解决这类序列决策问题。
- en: 'In this chapter, we focus in particular on two important problems: inventory
    and routing optimization. For the former, we go into the details of creating the
    environment, understanding the variance in the environment, and hyperparameter
    tuning to effectively solve it using RL. For the latter, we describe a realistic
    vehicle-routing problem of a gig driver working to deliver online meal orders.
    We then proceed to show why conventional neural networks are limiting while solving
    problems of varying sizes, and how pointer networks can overcome this.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们特别关注两个重要问题：库存和路由优化。对于前者，我们深入探讨了如何创建环境、理解环境中的变化，以及如何通过超参数调优有效地使用强化学习解决问题。对于后者，我们描述了一个现实的车辆路由问题——一名临时司机为在线餐饮订单提供配送服务。接着，我们展示了为什么传统的神经网络在解决不同规模的问题时存在局限性，以及指针网络如何克服这一问题。
- en: 'This is going to be a fun journey. We will cover the following topics in this
    chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这将是一段有趣的旅程。本章将涵盖以下内容：
- en: Optimizing inventory procurement decisions
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化库存采购决策
- en: Modeling routing problems
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路由问题建模
- en: Optimizing inventory procurement decisions
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化库存采购决策
- en: One of the most important decisions that almost all manufacturers, distributors,
    and retailers need to make all the time is how much inventory to carry to reliably
    satisfy customer demand while minimizing the costs. Effective inventory management
    is key to the profitability and survival of most companies, especially given the
    razor-thin margins and increased customer expectations in today's competitive
    landscape. In this section, we use RL to address this challenge and optimize inventory
    procurement decisions.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎所有制造商、分销商和零售商需要不断做出的最重要决策之一就是，如何保持足够的库存，以便可靠地满足客户需求，同时最小化成本。有效的库存管理对于大多数公司的盈利能力和生存至关重要，特别是在当今竞争激烈的环境中，考虑到薄弱的利润率和不断提升的客户期望。在本节中，我们将利用强化学习来解决这一挑战，并优化库存采购决策。
- en: The need for inventory and the trade-offs in its management
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 库存的需求及其管理中的权衡
- en: 'When you walk into a supermarket, you see items stacked on top of each other.
    There are probably more of those items in the depot of the supermarket, more still
    at the warehouse of the distributors, and even more at the sites of the manufacturers.
    If you think about it, there are those huge piles of products just sitting somewhere,
    waiting to be demanded by customers at some future time. If that sounds like a
    waste of resources, it largely is. On the other hand, companies have to carry
    some level of inventory, because of the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 当你走进超市时，你会看到物品堆积在一起。超市的仓库里可能有更多的这些物品，分销商的仓库里也有更多，制造商的工厂里更是如此。想一想，这些巨大的产品堆积物就静静地待在某个地方，等待着未来某个时刻被客户需求。如果这听起来像是资源浪费，那它在很大程度上确实是。另一方面，企业必须保持一定量的库存，因为以下原因：
- en: The future is uncertain. Customer demand, manufacturing capacity, transportation
    schedules, and raw material availability are all subject to unfolding in unplanned
    ways at some point.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未来充满不确定性。客户需求、制造能力、运输计划和原材料的可用性，都可能在某些时刻以无法预见的方式变化。
- en: It is impossible to operate in a perfect just-in-time manner, and manufacture
    and deliver an item to customers right at the moment they demand it.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不可能以完美的准时制方式运作，并在客户要求时立即制造并交付物品。
- en: 'Since carrying inventory is mostly unavoidable, the question is then how much.
    Answering it involves a tricky tradeoff:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于保持库存通常是不可避免的，那么问题就在于“多少”。回答这一问题涉及到一个复杂的权衡：
- en: Minimizing the chance of being unable to fulfill customer demand that loses
    profit, and more importantly, loyalty that will be hard to gain back.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小化无法满足客户需求的机会，这不仅会导致利润损失，更重要的是会损失客户忠诚度，而忠诚度一旦丧失，恢复将变得非常困难。
- en: Minimizing the inventory, as it has costs in terms of capital, labor, time,
    material, maintenance, and warehouse rent, and can lead to spoiled or obsolete
    items and organizational overhead.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 降低库存，因为它会带来资本、劳动力、时间、材料、维护和仓储租金等成本，还可能导致商品过期或过时以及组织管理的开销。
- en: 'So, how would you handle it? Would you make your customer satisfaction an absolute
    priority or prefer to keep your inventory under control? Well, this balancing
    act requires careful planning and the use of advanced methods, which not all companies
    have the means to do. As a result, most prefer to be "on the safe side" and carry
    more inventory than they need to, which helps to hide the lack of planning and
    associated issues. This phenomenon is commonly illustrated as a "sea of inventory"
    as in *Figure 15.1*:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你会如何处理这种情况？是将客户满意度作为绝对优先考虑，还是更愿意保持库存的可控？实际上，这种平衡行为需要仔细的规划和高级方法的应用，而并非所有公司都有能力做到这一点。因此，大多数公司更倾向于选择“保险策略”，即保持比实际需求更多的库存，这有助于掩盖缺乏规划和相关问题。这个现象通常被形象地描述为“库存之海”，如*图15.1*所示：
- en: '![Figure 15.1 – A sea of inventory hides many problems'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![图15.1 – 库存之海隐藏了许多问题'
- en: '](img/B14160_15_1.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14160_15_1.jpg)'
- en: Figure 15.1 – A sea of inventory hides many problems
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.1 – 库存之海隐藏了许多问题
- en: This is where RL could come to the rescue and optimize your inventory decisions
    in the face of uncertainty. Next, we start building our solution by discussing
    the components of an inventory optimization problem.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，强化学习（RL）可以发挥作用，在面对不确定性时优化库存决策。接下来，我们通过讨论库存优化问题的组成部分，开始构建我们的解决方案。
- en: Components of an inventory optimization problem
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 库存优化问题的组成部分。
- en: 'There are multiple factors that affect the dynamics of an inventory flow and
    what the best replenishment policy will look like for a given item:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个因素影响库存流动的动态，以及在给定商品的情况下，最佳补货政策将会是什么样子：
- en: The **price** of the item at which it is sold is a key factor.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 商品的**价格**是决定其销售价格的关键因素。
- en: The **cost of purchase** of the item is another key factor, which, together
    with the price, determines how much gross profit the business makes per item.
    This in turn affects how costly it is to lose a unit of customer demand.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 商品的**采购成本**是另一个关键因素，它与价格一起决定了每件商品所赚取的毛利润。这反过来影响了失去一个客户需求单位的成本。
- en: The **inventory holding cost** is the sum of all costs associated with carrying
    a single unit of inventory over a single time step (a day, week, or month, and
    so on). This includes things such as storage rent, the cost of capital, and any
    maintenance costs.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**库存持有成本**是指在单个时间步（例如一天、一周或一个月等）内，持有单个库存单位的所有成本总和。这包括存储租金、资本成本以及任何维护成本等。'
- en: '**Loss of customer goodwill** is the monetary cost associated with customer
    dissatisfaction due to a single unit of lost demand. After all, this reduces customer
    loyalty and affects future sales. Although dissatisfaction is usually a qualitative
    measure, businesses need to estimate the monetary equivalent of it to be able
    to use it in decision-making.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户信任流失**是由于丧失单个需求单位所导致的客户不满的货币成本。毕竟，这会减少客户忠诚度并影响未来的销售。虽然不满通常是定性衡量的，但企业需要估算其货币等价物，以便在决策中使用。'
- en: '**Customer demand** for the item in a single time step is one of the main factors
    affecting the decision.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对商品的**客户需求**在单个时间步中的变化是影响决策的主要因素之一。
- en: '**Vendor lead time** (**VLT**) is the lag between the placement of an order
    with a vendor till its arrival in the inventory. Not surprisingly, VLT is a key
    factor affecting when to place an order for some anticipated demand.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**供应商交货时间**（**VLT**）是指从向供应商下订单到商品到达库存的延迟时间。毫不奇怪，VLT是决定何时下订单以应对预期需求的关键因素。'
- en: '**Capacity** limitations, such as how many items can be ordered in a single
    batch, along with the firm''s storage capacity, will restrict the actions that
    the agent can take.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容量**限制，例如单次批量可订购商品的数量，以及公司的存储能力，将限制代理可以采取的行动。'
- en: 'These are the main factors that we will consider in our setting here. In addition,
    we will focus on the following:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我们在这里设置时需要考虑的主要因素。此外，我们还将重点关注以下内容：
- en: Single item scenario
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单一商品情景
- en: Stochastic customer demand with a Poisson distribution, which will have a deterministic
    and fixed mean over a given episode
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有泊松分布的随机客户需求，在给定时期内具有确定的且固定的均值。
- en: Deterministic factors other than demand
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除需求外的确定性因素
- en: This makes our case tractable while maintaining sufficient complexity.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得我们的案例在保持足够复杂性的同时变得可解。
- en: Tip
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: In a real-life setting, most dynamics involve uncertainties. For example, there
    could be defects in the arrived inventory; the price could change with how obsolete
    an item becomes; there could be a loss in the existing inventory due to weather;
    there could be items that need to be returned. Estimating the characteristics
    of all these factors and creating a simulation model of the process is a real
    challenge, placing a barrier in front of the adaptation of RL as a tool for such
    problems.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际环境中，大多数动态都涉及不确定性。例如，可能到达的库存存在缺陷；价格可能会随着物品的过时程度而变化；可能由于天气原因导致现有库存损失；可能有物品需要退货。估算所有这些因素的特征并创建过程的仿真模型是一个真正的挑战，成为了将强化学习作为此类问题工具的障碍。
- en: What we have described is a complex optimization problem, for which there is
    no tractable optimal solution. However, the single-step version of it, called
    the **newsvendor problem**, is well studied and widely used. It is a great simplification
    to develop an intuition about the problem, and it will also help us obtain a near-optimal
    benchmark for the multi-step case. Let's look into it.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所描述的是一个复杂的优化问题，当前没有可行的最优解。然而，它的单步版本，称为**新闻售货员问题**，已被广泛研究和应用。这是一个极好的简化方法，可以帮助我们形成对问题的直观理解，并且还将帮助我们为多步情况获得一个接近最优的基准。让我们深入研究一下。
- en: Single-step inventory optimization – the newsvendor problem
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单步库存优化 – 新闻售货员问题
- en: 'When an inventory optimization problem involves the following:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当库存优化问题涉及以下内容时：
- en: A single time step (so no VLT; deterministic arrival of inventory)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单一时间步长（因此没有VLT；库存到货是确定性的）
- en: A single item
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单一商品
- en: A known price, cost of purchase, and cost of unsold inventory
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已知价格、购买成本和未售出库存的成本
- en: A known (and conveniently Gaussian) demand distribution
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个已知的（且方便的高斯）需求分布
- en: 'Then the problem is called the newsvendor problem, for which we can obtain
    a closed-form solution. It describes a newspaper vendor who aims to plan how many
    copies to purchase for the day, at a unit cost ![](img/Formula_15_001.png), to
    sell at a unit price ![](img/Formula_15_002.png), and return the unsold copies
    at the end of the day at a unit price ![](img/Formula_15_003.png). We then define
    the following quantities:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，这个问题被称为新闻售货员问题，我们可以为其获得封闭形式的解。它描述了一个报纸销售员，旨在规划当天购买多少份报纸，单位成本为![](img/Formula_15_001.png)，以单位价格![](img/Formula_15_002.png)出售，并在当天结束时以单位价格![](img/Formula_15_003.png)退还未售出的份数。接着，我们定义以下量：
- en: 'The cost of underage, ![](img/Formula_15_004.png), is the profit lost due to
    a single unit of missed demand: ![](img/Formula_15_005.png).'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺货成本，![](img/Formula_15_004.png)，是由于错失一单位需求所造成的利润损失：![](img/Formula_15_005.png)。
- en: 'The cost of overage, ![](img/Formula_15_006.png), is the cost of an unsold
    unit: ![](img/Formula_15_007.png).'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过剩成本，![](img/Formula_15_006.png)，是未售出的单元成本：![](img/Formula_15_007.png)。
- en: 'To find the optimal ordering quantity, we then calculate a critical ratio,
    ![](img/Formula_15_008.png), as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到最优的订货量，我们接下来计算一个关键比率，![](img/Formula_15_008.png)，如下所示：
- en: '![](img/Formula_15_009.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_15_009.jpg)'
- en: 'Now, let''s unpack how this critical ratio changes with respect to the costs
    of underage and overage:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来分析这个关键比率如何随着缺货和过剩成本的变化而变化：
- en: As ![](img/Formula_15_010.png) gets higher, ![](img/Formula_15_011.png) increases.
    Higher ![](img/Formula_15_012.png) and ![](img/Formula_15_013.png) means it is
    costlier to miss customer demand. This suggests being more aggressive in replenishing
    the inventory to avoid leaving money on the table.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着![](img/Formula_15_010.png)的增加，![](img/Formula_15_011.png)增加。更高的![](img/Formula_15_012.png)和![](img/Formula_15_013.png)意味着错失客户需求的成本更高。这表明，在补充库存时应更加积极，以避免错失机会。
- en: As ![](img/Formula_15_014.png) gets higher, ![](img/Formula_15_015.png) decreases,
    and this means it is costlier to have unsold inventory. This suggests that we
    should be conservative in how much we carry.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着![](img/Formula_15_014.png)的增加，![](img/Formula_15_015.png)减少，这意味着未售出库存的成本更高。这表明我们在库存量上应该保持保守。
- en: It turns out that ![](img/Formula_15_016.png) gives us what percentage of the
    demand scenarios should be covered to optimize the expected profit at the end
    of the day. In other words, let's say the demand has a probability distribution
    function ![](img/Formula_15_017.png), and a **cumulative distribution function**
    (**CDF**) ![](img/Formula_15_018.png). The optimal order size is given by ![](img/Formula_15_019.png),
    where ![](img/Formula_15_020.png) is the inverse of the CDF.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明，![](img/Formula_15_016.png)给出了为了优化预期利润，应该覆盖的需求场景的百分比。换句话说，假设需求有一个概率分布函数![](img/Formula_15_017.png)，并且有一个**累积分布函数**（**CDF**）![](img/Formula_15_018.png)。最佳订货量由![](img/Formula_15_019.png)给出，其中![](img/Formula_15_020.png)是CDF的逆函数。
- en: Let's experiment with this in an example.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来进行实验。
- en: Newsvendor example
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新闻供应商示例
- en: Assume that the price of an expensive item is ![](img/Formula_15_021.png), which
    is sourced at ![](img/Formula_15_022.png). The item cannot be returned to the
    supplier if unsold, and it becomes waste. So, we have ![](img/Formula_15_023.png).
    In this case, the cost of underage is ![](img/Formula_15_024.png), and the cost
    of overage is ![](img/Formula_15_025.png), which give us a critical ratio ![](img/Formula_15_026.png)
    This suggests that the order size has an 80% chance of covering the demand. Assuming
    that the demand has a normal distribution with a mean of 20 items and a standard
    deviation of 5 items, the optimal order size is around 24 items.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 假设某昂贵商品的价格为![](img/Formula_15_021.png)，其来源为![](img/Formula_15_022.png)。如果该商品未售出，不能退还给供应商，且会变成废品。因此，我们有![](img/Formula_15_023.png)。在这种情况下，缺货成本为![](img/Formula_15_024.png)，过剩成本为![](img/Formula_15_025.png)，这使得我们得出临界比率![](img/Formula_15_026.png)。这表明订货量有80%的几率能满足需求。假设需求服从正态分布，均值为20件，标准差为5件，则最佳订货量约为24件。
- en: 'You can calculate and plot the optimal order size using the `calc_n_plot_critical_ratio`
    function defined in the `Newsvendor plots.ipynb` file:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用在`Newsvendor plots.ipynb`文件中定义的`calc_n_plot_critical_ratio`函数计算并绘制最佳订货量：
- en: Chapter15/Newsvendor plots.ipynb
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Chapter15/Newsvendor plots.ipynb
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'And you should see the output as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到如下输出：
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*Figure 15.2* illustrates the probability distribution of the demand, the CDF,
    and the value the critical ratio corresponds to for this problem:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*图15.2*展示了需求的概率分布、累积分布函数（CDF）以及该问题对应的临界比率值：'
- en: '![Figure 15.2 – Optimal order size for the example newsvendor problem'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![图15.2 – 示例新闻供应商问题的最佳订货量'
- en: '](img/B14160_15_2.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14160_15_2.jpg)'
- en: Figure 15.2 – Optimal order size for the example newsvendor problem
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.2 – 示例新闻供应商问题的最佳订货量
- en: This was to give you an intuition into what the solution looks like for a single-step
    inventory optimization problem. Now, a multi-step problem involves a bunch of
    other complexities, which we described in the previous section. For example, the
    inventory arrives with a lag, and the leftover inventory is carried to the next
    step with a holding cost incurred. Well, this is sequential decision-making under
    uncertainty, which is the forte of RL. So, let's use it.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这是为了让您对单步库存优化问题的解决方案有一个直观的了解。现在，多步问题涉及到许多其他复杂性，我们在上一节中进行了描述。例如，库存到货存在滞后，剩余库存会带到下一步并产生持有成本。这就是不确定性下的序列决策问题，而这正是强化学习的强项。所以，让我们来使用它。
- en: Simulating multi-step inventory dynamics
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模拟多步库存动态
- en: In this section, we create a simulation environment for the multi-step inventory
    optimization problem we described.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们创建了一个模拟环境，用于描述的多步库存优化问题。
- en: Info
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 信息
- en: The rest of this chapter closely follows the problems and environments defined
    in *Balaji et al., 2019*, for which the code is available at [https://github.com/awslabs/or-rl-benchmarks](https://github.com/awslabs/or-rl-benchmarks).
    We suggest you read the paper for more details on RL approaches to classical stochastic
    optimization problems.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的其余部分紧密跟随*Balaji等人，2019*中定义的问题和环境，其中的代码可在[https://github.com/awslabs/or-rl-benchmarks](https://github.com/awslabs/or-rl-benchmarks)找到。我们建议您阅读该论文，以获取有关经典随机优化问题的强化学习（RL）方法的更多细节。
- en: 'Before we start describing the environment, let''s discuss several considerations:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始描述环境之前，让我们讨论几个注意事项：
- en: We would like to create a policy not for a specific product-demand scenario,
    but a broad range of scenarios. Therefore, for each episode, we randomly generate
    the environment parameters, as you will see.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望创建一个不仅适用于特定产品需求场景的策略，而是适用于广泛场景的策略。因此，对于每个周期，我们会随机生成环境参数，正如您将看到的那样。
- en: This randomization increases the variance in the gradient estimates, which makes
    learning more challenging compared to static scenarios.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这种随机化增加了梯度估计的方差，使得学习过程比静态场景更加具有挑战性。
- en: With this, let's go into the details of the environment.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们来详细讨论一下环境的细节。
- en: Event calendar
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事件日历
- en: 'In order to correctly apply the step function for the environment, we need
    to understand when each event takes place. Let''s take a look:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确地应用环境的阶跃函数，我们需要了解每个事件发生的时间。让我们来看一下：
- en: At the beginning of each day, the inventory replenishment order is placed. Based
    on the lead time, we record this as "in-transit" inventory.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每天开始时，库存补货订单会被下达。根据提前期，我们将其记录为“运输中”库存。
- en: Next, the items scheduled for the current day arrive. If the lead time is zero,
    what is ordered at the beginning of the day arrives right away. If the lead time
    is one day, yesterday's order arrives, and so on.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，当前日程安排的物品到达。如果提前期为零，那么当天一开始就下的订单会立刻到达。如果提前期为一天，那么昨天的订单会到达，依此类推。
- en: After the shipment is received, the demand materializes throughout the day.
    If there is not enough inventory to meet the demand, the actual sales will be
    lower than the demand, and there will be a loss of customer goodwill.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在货物收到后，需求会在一天内逐渐显现。如果库存不足以满足需求，实际销售量将低于需求，并且会失去客户的好感。
- en: At the end of the day, we deduct the sold items (not the total demand) from
    the inventory and update the state accordingly.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一天结束时，我们从库存中扣除已售出的物品（不是总需求），并相应更新状态。
- en: Lastly, if the lead time is nonzero, we update the in-transit inventory (that
    is, we shift the inventory set to arrive on t + 2 to t + 1).
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，如果提前期非零，我们会更新运输中的库存（即，我们将原本在t + 2到达的库存移至t + 1）。
- en: Now, let's code what we have described.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们编码我们所描述的内容。
- en: Coding the environment
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 编码环境
- en: You can find the complete code for the environment in our GitHub repo at [https://github.com/PacktPublishing/Mastering-Reinforcement-Learning-with-Python/blob/master/Chapter15/inventory_env.py](https://github.com/PacktPublishing/Mastering-Reinforcement-Learning-with-Python/blob/master/Chapter15/inventory_env.py).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在我们的GitHub仓库中找到完整的环境代码，链接为：[https://github.com/PacktPublishing/Mastering-Reinforcement-Learning-with-Python/blob/master/Chapter15/inventory_env.py](https://github.com/PacktPublishing/Mastering-Reinforcement-Learning-with-Python/blob/master/Chapter15/inventory_env.py)。
- en: 'Here, we only describe some of the critical parts of the environment:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们只描述环境的一些关键部分：
- en: 'As mentioned earlier, each episode will sample certain environment parameters
    to be able to obtain a policy that can work across a broad set of price, demand,
    and other scenarios. We set the maximum values for those parameters, from which
    we will later generate episode-specific parameters:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述，每个回合将抽样某些环境参数，以便获得可以在广泛的价格、需求等场景中工作的策略。我们设置这些参数的最大值，然后从中生成特定回合的参数：
- en: '[PRE2]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We use a 5-day lead time, which will be important to determine the observation
    space (which can be considered equivalent to state space for this problem, so
    we use the terms interchangeably).
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们使用5天的提前期，这对确定观察空间非常重要（可以认为它等同于此问题中的状态空间，因此我们可以互换使用这两个术语）。
- en: 'The price, cost, holding cost, loss of goodwill, and expected demand are part
    of the state space, which we assume is also visible to the agent. In addition,
    we need to keep track of the on-hand inventory, along with the in-transit inventory
    if the lead-time is nonzero:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 价格、成本、持有成本、客户好感损失和预期需求是状态空间的一部分，我们假设这些也对代理可见。此外，我们需要追踪现有库存，以及如果提前期非零，还需要追踪运输中的库存：
- en: '[PRE3]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that for a lead time of 5, we have one dimension for the on-hand inventory
    and four dimensions (from ![](img/Formula_15_027.png) to ![](img/Formula_15_028.png))
    for the in-transit inventory. As you will see, by adding the in-transit inventory
    to the state at the end of the step calculation, we can avoid keeping track of
    the in-transit inventory that will arrive at ![](img/Formula_15_029.png) (in more
    general terms, we don't need ![](img/Formula_15_030.png), ![](img/Formula_15_031.png)
    being the lead time).
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，对于5天的提前期，我们有一个维度表示现有库存，四个维度（从![](img/Formula_15_027.png)到![](img/Formula_15_028.png)）表示运输中的库存。正如你将看到的，通过在步骤计算结束时将运输中库存添加到状态中，我们可以避免追踪将会到达![](img/Formula_15_029.png)的运输中库存（更一般地说，我们不需要![](img/Formula_15_030.png)，![](img/Formula_15_031.png)表示提前期）。
- en: 'We normalize the action to be between ![](img/Formula_15_032.png), where 1
    means ordering at the order limit:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将动作规范化为在 ![](img/Formula_15_032.png) 之间，其中 1 表示以订单限额下单：
- en: '[PRE4]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'One of the very important steps is to normalize the observations. Normally,
    the agent may not know the bounds of the observations to normalize them. Here,
    we assume that the agent has that information, so we conveniently do it within
    the environment class:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个非常重要的步骤是规范化观察值。通常，智能体可能不知道观察值的边界以便进行规范化。在这里，我们假设智能体有这个信息，因此我们在环境类中方便地处理了它：
- en: '[PRE5]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The episode-specific environment parameters are generated within the `reset`
    function:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 特定回合的环境参数是在 `reset` 函数中生成的：
- en: '[PRE6]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'And we implement the `step` function as we described in the previous section.
    First, we parse the initial state and received action:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们按照前一部分描述的方式实现 `step` 函数。首先，我们解析初始状态和接收到的动作：
- en: '[PRE7]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, we determine how much we can buy while observing the capacity, add what
    is bought to the inventory if there is no lead time, and sample the demand:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们在观察容量的同时确定可以购买的数量，如果没有提前期，就将购买的部分添加到库存中，并采样需求：
- en: '[PRE8]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The reward will be the revenue, from which we subtract the purchase cost, the
    inventory holding cost, and the cost of lost customer goodwill:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 奖励将是收入，我们从中扣除购买成本、库存持有成本和失去的客户信誉成本：
- en: '[PRE9]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Lastly, we update the inventory levels by shifting the in-transit inventory
    by a day, adding what is bought at the beginning of the day to the in-transit
    inventory if the VLT is nonzero:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们通过将在途库存移动一天来更新库存水平，如果VLT不为零，还需要将当日购买的物品添加到在途库存中：
- en: '[PRE10]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'At the end, we return the normalized observations and scaled reward to the
    agent:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将规范化后的观察值和缩放后的奖励返回给智能体：
- en: '[PRE11]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Take your time to understand how the inventory dynamics are reflected in the
    step function. Once you are ready, let's move to developing a benchmark policy.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 花时间理解库存动态是如何在步骤函数中体现的。一旦准备好，我们就可以开始开发基准策略。
- en: Developing a near-optimal benchmark policy
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发近似最优基准策略
- en: 'An exact solution to this problem is not available. Yet, a near-optimal approximation
    is obtained similar to the newsvendor policy, with two modifications:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的精确解不可得。然而，通过类似新闻商政策的两项修改，我们获得了一个近似最优的解：
- en: The aggregate demand over ![](img/Formula_15_033.png) time steps is taken into
    account, instead of a single step.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑到的总需求是在 ![](img/Formula_15_033.png) 时间步长内的需求，而不是单一时间步。
- en: We also add the loss of goodwill to the cost of underage in addition to the
    per-unit profit.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还将客户流失的损失加到缺货成本中，除了每单位的利润之外。
- en: The reason this is still approximate is that the formula treats multiple steps
    as a single step and aggregates the demand and supply, meaning that it assumes
    the demand arrived in a step, and can be backlogged and satisfied in one of the
    subsequent steps over the ![](img/Formula_15_034.png) step horizon. Still, this
    gives us a near-optimal solution.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 之所以仍然是近似解，是因为该公式将多个步骤视为一个单一步骤，并汇总需求和供应，意味着它假设需求在某个步骤到达，并可以在随后的步骤中积压并得到满足，这一过程持续在
    ![](img/Formula_15_034.png) 步长内进行。不过，这仍然为我们提供了一个近似最优的解决方案。
- en: 'Here is how we can code this benchmark policy:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何编写此基准策略的代码：
- en: '[PRE12]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Notice that after we calculate the critical ratio, we do the following:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在我们计算临界比率后，我们进行以下操作：
- en: We find the optimal aggregate supply for ![](img/Formula_15_035.png) steps.
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们为 ![](img/Formula_15_035.png) 步骤找到最优的总供应量。
- en: Then, we subtract the on-hand inventory and in-transit inventory for the next
    ![](img/Formula_15_036.png) time steps.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们减去下一步 ![](img/Formula_15_036.png) 时间步长内的在手库存和在途库存。
- en: Finally, we place the order to cover this deficit, capped by the limit on a
    single order.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们下单以弥补这一差额，但单次订单有上限。
- en: Next, let's look into how we can train an RL agent to solve this problem and
    how the RL solution compares to this benchmark.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何训练一个强化学习智能体来解决这个问题，以及强化学习解决方案与此基准的比较。
- en: A reinforcement learning solution for inventory management
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种用于库存管理的强化学习解决方案
- en: 'There are several factors to take into account while solving this problem:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决这个问题时，有几个因素需要考虑：
- en: Due to the randomizations in the environment, there is a high variance in the
    rewards across episodes.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于环境中的随机化，每一回合的奖励有很高的方差。
- en: This requires us to use higher-than-normal batch and minibatch sizes to better
    estimate the gradients and have more stable updates to the neural network's weights.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这要求我们使用高于正常的批量和小批量大小，以更好地估计梯度并对神经网络权重进行更稳定的更新。
- en: Selecting the winning model is also a problem in the presence of high variance.
    This is because if the number of test/evaluation episodes are not large enough,
    there is a chance of declaring a policy as the best just because we happen to
    evaluate it in a few lucky configurations.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在高方差的情况下，选择最佳模型也是一个问题。这是因为如果测试/评估的回合数不足，可能会仅仅因为在一些幸运的配置中评估了某个策略，就错误地认为它是最好的。
- en: 'To handle these challenges, we can adapt the following strategy:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些挑战，我们可以采取以下策略：
- en: Do limited hyperparameter tuning with a limited computation budget to identify
    a set of good hyperparameters.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在有限的计算预算下进行有限的超参数调优，以识别出一组好的超参数。
- en: Train the model with one or two of the best sets of hyperparameters. Save the
    best models along the way.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用一个或两个最佳超参数集来训练模型，并在训练过程中保存最佳模型。
- en: When you observe that the trend of the reward curve is dominated by the noise,
    increase the batch and minibatch sizes for finer estimation of the gradients and
    denoising the model performance metrics. Again, save the best model.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当你观察到奖励曲线的趋势被噪声主导时，增加批量和小批量的大小，以便更精确地估计梯度并去噪模型性能指标。再次保存最佳模型。
- en: Depending on your compute budget, repeat this multiple times and pick the winning
    model.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据您的计算预算，重复多次并选择最佳模型。
- en: So, let's implement these steps in Ray/RLlib to obtain our policy.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，让我们在 Ray/RLlib 中实现这些步骤以获得我们的策略。
- en: Initial hyperparameter sweep
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 初始超参数搜索
- en: 'We use Ray''s Tune library to do the initial hyperparameter tuning. There are
    two functions we will utilize:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 Ray 的 Tune 库进行初步的超参数调优。我们将使用两个函数：
- en: '`tune.grid_search()` does a grid search over the specified set of values.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tune.grid_search()` 在指定的值集合上进行网格搜索。'
- en: '`tune.choice()` does a random search within the specified set.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tune.choice()` 在指定的集合中进行随机搜索。'
- en: For each trial, we also specify the stopping criteria. In our case, we would
    like to run a trial for a million time steps.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个试验，我们还指定停止条件。在我们的案例中，我们希望运行一百万个时间步骤的试验。
- en: 'Here is the code for an example search:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个示例搜索的代码：
- en: '[PRE13]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'To calculate the total tuning budget, we do the following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算总的调优预算，我们执行以下操作：
- en: Take the cross-product of all grid searches, since each possible combination
    has to be tried by definition.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取所有网格搜索的交叉乘积，因为根据定义必须尝试每一个可能的组合。
- en: Multiply that cross-product with `num_samples`. That gives the total number
    of trials that will take place. With the preceding code, we will have 20 trials.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将交叉乘积与 `num_samples` 相乘，得到将要进行的试验总数。使用前面的代码，我们将有 20 次试验。
- en: During each trial, each `choice` function will select a parameter uniformly,
    at random, from the corresponding set.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每次试验中，每个 `choice` 函数会从相应的集合中随机均匀地选择一个参数。
- en: A given trial stops when the stopping criteria have been satisfied.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当满足停止条件时，给定的试验将停止。
- en: 'Whey you execute this, you will see the search progressing. It will look like
    *Figure 15.3*:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 执行时，您将看到搜索过程正在进行。它看起来像*图 15.3*：
- en: '![Figure 15.3 – Hyperparameter tuning with Ray''s Tune'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 15.3 – 使用 Ray 的 Tune 进行超参数调优'
- en: '](img/B14160_15_3.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14160_15_3.jpg)'
- en: Figure 15.3 – Hyperparameter tuning with Ray's Tune
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.3 – 使用 Ray 的 Tune 进行超参数调优
- en: 'Some trials will error out unless you are deliberate about the hyperparameter
    combinations that will form to prevent numerical issues. You can then select the
    best performing combinations for further training, as illustrated in *Figure 15.4*:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 一些试验会出错，除非你特别注意避免数值问题的超参数组合。然后，你可以选择表现最好的组合进行进一步的训练，如*图 15.4*所示：
- en: '![Figure 15.4 – A sample performance of a good set of hyperparameters obtained
    in the search'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 15.4 – 在搜索中获得的优质超参数集的样本性能'
- en: '](img/B14160_15_4.jpg)'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14160_15_4.jpg)'
- en: Figure 15.4 – A sample performance of a good set of hyperparameters obtained
    in the search
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.4 – 在搜索中获得的优质超参数集的样本性能
- en: Next, let's now do the extensive training.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们进行广泛的训练。
- en: Extensive training of the model
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型的广泛训练
- en: 'We now kick off a long training run using the selected hyperparameter set (or
    with multiple sets – in my case, the winning set in the previous exercise did
    not perform well, but the second set did):'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们开始使用选定的超参数集进行长时间训练（或者使用多个超参数集——在我的案例中，之前的最佳集表现不好，但第二个集表现良好）：
- en: Chapter15/train_inv_policy.py
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Chapter15/train_inv_policy.py
- en: '[PRE14]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Once you set the hyperparameters, you can kick off the training:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦设置了超参数，就可以开始训练：
- en: '[PRE15]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'One thing to note here is the size of the batch and minibatch: normally, the
    PPO default in RLlib is `"train_batch_size": 4000` and `"sgd_minibatch_size":
    128`. However, learning suffers with such small batches, given the variance in
    the environment and rewards. So, the tuning model picked higher batch and minibatch
    sizes.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '这里有一点需要注意，那就是批量和小批量的大小：通常情况下，RLlib中的PPO默认设置是`"train_batch_size": 4000`和`"sgd_minibatch_size":
    128`。然而，由于环境和奖励的方差，使用如此小的批量会导致学习效果不佳。因此，调优模型选择了更大的批量和小批量大小。'
- en: 'Now for the training. At this point, you can develop a logic to adjust various
    hyperparameters based on the training progress. For simplicity, we will manually
    observe the progress and then stop when the learning stalls or destabilizes. After
    that point, we can further train with increased batch sizes to obtain better gradient
    estimates in the final stages, such as `"train_batch_size": 200000` and `"sgd_minibatch_size":
    32768`. This is what such a training process looks like:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '现在进行训练。此时，您可以根据训练进度开发逻辑来调整各种超参数。为了简化起见，我们将手动观察进度，并在学习停滞或不稳定时停止。在那之后，我们可以进一步增加批量大小进行训练，以获得最终阶段的更好梯度估计，例如
    `"train_batch_size": 200000` 和 `"sgd_minibatch_size": 32768`。这就是训练过程的样子：'
- en: '![Figure 15.5 – Training started with a batch size of 20k and continued with
    a batch'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '![图15.5 – 训练从20k的批量大小开始，并继续使用200k的批量'
- en: size of 200k to reduce the noise
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 使用200k的批量大小来减少噪声
- en: '](img/B14160_15_5.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14160_15_5.jpg)'
- en: Figure 15.5 – Training started with a batch size of 20k and continued with a
    batch size of 200k to reduce the noise
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.5 – 训练从20k的批量大小开始，并继续使用200k的批量大小以减少噪声
- en: 'The fine-tuning with a higher batch size helps us denoise the rewards and identify
    truly high-performing models. We can then compare the benchmark and RL solutions.
    After 2,000 test episodes, the benchmark performance looks as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 更高的批量大小微调帮助我们去噪奖励并识别真正高效的模型。然后，我们可以比较基准和强化学习（RL）解决方案。经过2,000个测试回合后，基准性能如下所示：
- en: '[PRE16]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'And we can see the RL model performance here:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在这里看到RL模型的表现：
- en: '[PRE17]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Our RL model's performance is within 10% of the near-optimal benchmark solution.
    We can decrease the gap with further trials and training, but in the presence
    of such noise, it is a challenging and time-consuming undertaking. Note that *Balaji
    et al., 2019* report metrics that slightly improve the benchmarks, so it is doable.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的RL模型性能在接近最优基准解的10%以内。我们可以通过进一步的试验和训练来减少差距，但在如此噪声的环境下，这是一个具有挑战性且耗时的工作。请注意，*Balaji
    et al., 2019*报告的指标略微改善了基准，因此这是可行的。
- en: With this, we conclude our discussion on this problem. Great work! We have taken
    a realistic and noisy supply-chain problem from its initial form, modeled it using
    RL, and solved it via PPO on RLlib!
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，我们结束了对这个问题的讨论。做得好！我们已经将一个现实且噪声较大的供应链问题从初始形态中建模，使用RL进行建模，并通过RLlib上的PPO解决了它！
- en: Next, we describe two additional supply chain problems that can be solved via
    RL. Due to space limitations, we won't be able to solve them here, but refer you
    to [https://github.com/awslabs/or-rl-benchmarks/](https://github.com/awslabs/or-rl-benchmarks/)
    for more.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们描述两个可以通过RL解决的额外供应链问题。由于篇幅限制，我们在这里无法解决这些问题，但我们建议您参考[https://github.com/awslabs/or-rl-benchmarks/](https://github.com/awslabs/or-rl-benchmarks/)获取更多信息。
- en: So, let's discuss how you can model and solve a routing optimization problem
    using RL.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，接下来让我们讨论如何使用RL来建模和解决路由优化问题。
- en: Modeling routing problems
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 路由问题建模
- en: Routing problems are among the most challenging and well studied problems in
    combinatorial optimization. In fact, there are quite a few researchers who have
    dedicated their entire careers to this area. Recently, RL approaches to routing
    problems have emerged as an alternative to the traditional operations research
    methods. We start with a rather sophisticated routing problem, which is about
    the pick-up and delivery of online meal orders. The RL modeling of this problem,
    on the other hand, will not be that complex. We will later extend our discussion
    to more advanced RL models in line with the recent literature in this area.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 路由问题是组合优化中最具挑战性和最受研究的问题之一。事实上，有相当多的研究人员将毕生精力投入到这一领域。最近，RL方法作为一种替代传统运筹学方法的路由问题解决方案已经浮出水面。我们从一个相对复杂的路由问题开始，它是关于在线餐饮订单的取送。另一方面，这个问题的RL建模并不会太复杂。我们稍后将根据该领域的最新文献，扩展讨论更先进的RL模型。
- en: Pick-up and delivery of online meal orders
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在线餐饮订单的取送
- en: 'Consider a gig driver (our agent) who works for an online platform, similar
    to Uber Eats or Grubhub, to pick up orders from restaurants and deliver to customers.
    The goal of the driver is to collect as many tips as possible by delivering many
    expensive orders. Here are some more details about this environment:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个“零工”司机（我们的代理），他为一个在线平台工作，类似于Uber Eats或Grubhub，从餐厅接订单并配送给客户。司机的目标是通过配送更多高价值订单来赚取尽可能多的小费。以下是这个环境的更多细节：
- en: There are multiple restaurants in the city, which are the pick-up locations
    for the orders.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 城市中有多个餐厅，这些餐厅是订单的取件地点。
- en: Orders associated with one of these restaurants dynamically arrive on the delivery
    company's app.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与这些餐厅相关的订单会动态地出现在配送公司的应用程序上。
- en: The driver has to accept an order to be able to pick it up and deliver.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 司机必须接受一个订单才能去取件并进行配送。
- en: If an accepted order is not delivered within a certain time limit since the
    order creation, a high penalty is incurred.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果一个已接受的订单在创建后的一定时间内未被配送，则会遭受高额罚款。
- en: If an open order is not accepted by the driver, it disappears after a while,
    which implies that it is taken by competitive drivers.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果司机未接受一个开放订单，该订单会在一段时间后消失，意味着订单被竞争的其他司机抢走。
- en: The driver can accept as many orders as they want but can physically carry only
    a limited number of picked-up orders.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 司机可以接受任意数量的订单，但实际能携带的已取件订单数量有限。
- en: Different parts of the city generate orders at different rates and different
    sizes. For example, one region could be generating frequent and expensive orders,
    making it attractive for the driver.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 城市的不同区域以不同的速率和不同的规模生成订单。例如，一个区域可能生成频繁且高价值的订单，从而吸引司机。
- en: Traveling unnecessary distances results in costs of time, fuel, and opportunity
    to the driver.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不必要的行程会给司机带来时间、燃料和机会成本。
- en: 'Given this environment, at each time step, the driver takes one of the following
    actions:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个环境下，每个时间步，司机可以采取以下动作之一：
- en: Accept one of the open orders.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接受其中一个开放订单。
- en: Move one step toward a restaurant associated with a particular order (for pick-up).
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朝一个与特定订单相关的餐厅移动一步（取件）。
- en: Move one step toward a customer location (for delivery).
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朝客户位置移动一步（进行配送）。
- en: Wait and do nothing.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等待并什么都不做。
- en: Move one step toward one of the restaurants (not to pick up an existing order
    but with the hope that a good, expensive order could be placed soon from that
    restaurant).
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朝一个餐厅移动一步（不是去取现有订单，而是希望很快会从该餐厅接到一个高价值订单）。
- en: 'The agent observes the following state to make their decision:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 代理观察以下状态以做出决策：
- en: The coordinates of the driver, the restaurants, and the customers
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 司机、餐厅和客户的坐标
- en: The driver used and available capacity
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 司机使用的和可用的运载能力
- en: Order statuses (open, accepted, picked up, and inactive/delivered/not created)
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 订单状态（开放、已接受、已取件、非活动/已配送/未创建）
- en: Order-restaurant associations
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 订单与餐厅的关联
- en: The time elapsed since order creation
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从订单创建开始经过的时间
- en: The reward (tip) associated with each order
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个订单的奖励（小费）
- en: For more information, this environment is available at [https://github.com/awslabs/or-rl-benchmarks/blob/master/Vehicle%20Routing%20Problem/src/vrp_environment.py](https://github.com/awslabs/or-rl-benchmarks/blob/master/Vehicle%20Routing%20Problem/src/vrp_environment.py).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如需更多信息，可以访问此环境：[https://github.com/awslabs/or-rl-benchmarks/blob/master/Vehicle%20Routing%20Problem/src/vrp_environment.py](https://github.com/awslabs/or-rl-benchmarks/blob/master/Vehicle%20Routing%20Problem/src/vrp_environment.py)。
- en: '*Balaji et al., 2019* show that the RL solution to this problem outperforms
    a **mixed-integer** **programming** (**MIP**)-based approach. This is a rather
    surprising result, since MIP models can find the optimal solution in theory. The
    reason the MIP solution is outperformed in this case is as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '*Balaji et al., 2019* 研究表明，RL解决方案在此问题上的表现优于基于**混合整数** **规划**（**MIP**）的方法。这是一个相当令人惊讶的结果，因为MIP模型理论上可以找到最优解。MIP解决方案在此情况下被超越的原因如下：'
- en: It solves a myopic problem for an existing situation while the RL agent learns
    to anticipate future events and plan accordingly.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它解决了一个眼前问题，而RL代理学习预测未来事件并相应地进行规划。
- en: It uses a limited budget, as MIP solutions can take a really long time. RL inference,
    on the other hand, happens almost instantaneously once a policy is trained.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用了有限的预算，因为MIP解决方案可能需要很长时间，而RL推理一旦训练好策略后，几乎是瞬时发生的。
- en: The reported RL performance for such a complex problem is quite encouraging.
    On the other hand, the way we modeled the problem has limitations since it relies
    on a fixed state and action space size. In other words, if the state and action
    space are designed to handle a maximum of *N* number of orders/restaurants, the
    trained agent cannot be used for larger problems. On the other hand, MIP models
    can take any size of input (although large problems can take a really long time
    to solve).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 对于如此复杂的问题，报告的强化学习（RL）性能相当鼓舞人心。另一方面，我们所采用的问题建模方式有一定局限性，因为它依赖于固定的状态和动作空间大小。换句话说，如果状态和动作空间设计为处理最多
    *N* 个订单/餐馆，那么训练后的智能体无法用于更大的问题。另一方面，混合整数规划（MIP）模型可以接受任何大小的输入（尽管大规模问题可能需要很长时间才能解决）。
- en: Recent research in the field of deep learning has provided us with pointer networks
    to handle dynamic-size combinatorial optimization problems. Let's look into this
    next.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习领域的最新研究为我们提供了指针网络，用于处理动态大小的组合优化问题。接下来我们将深入探讨这个话题。
- en: Pointer networks for dynamic combinatorial optimization
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用于动态组合优化的指针网络
- en: 'A pointer network uses a content-based attention mechanism to point to one
    of its inputs, where the number of inputs can be anything. To explain this better,
    consider a traveling salesperson problem where the goal is to visit all the nodes
    located on a 2D plane, exactly once, and come back to the initial node at the
    end, and do so at the minimum total distance. A sample problem and its solution
    is illustrated in *Figure 15.6*:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 指针网络使用基于内容的注意力机制来指向其输入中的一个节点，输入的数量可以是任意的。为了更好地解释这一点，考虑一个旅行推销员问题，其目标是在二维平面上访问所有节点，每个节点仅访问一次，并在最后回到初始节点，且以最小的总距离完成。*图
    15.6* 展示了一个示例问题及其解决方案：
- en: '![Figure 15.6 – Solution to a traveling salesperson problem'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 15.6 – 旅行推销员问题的解决方案'
- en: '(source: https://en.wikipedia.org/wiki/Travelling_salesman_problem)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: （来源：[https://en.wikipedia.org/wiki/Travelling_salesman_problem](https://en.wikipedia.org/wiki/Travelling_salesman_problem)）
- en: '](img/B14160_15_6.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14160_15_6.jpg)'
- en: 'Figure 15.6 – Solution to a traveling salesperson problem (source: [https://en.wikipedia.org/wiki/Travelling_salesman_problem](https://en.wikipedia.org/wiki/Travelling_salesman_problem))'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.6 – 旅行推销员问题的解决方案（来源：[https://en.wikipedia.org/wiki/Travelling_salesman_problem](https://en.wikipedia.org/wiki/Travelling_salesman_problem)）
- en: 'Each node in this problem is represented by its ![](img/Formula_15_037.png)
    coordinates. A pointer network has the following attributes:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 该问题中的每个节点通过其 ![](img/Formula_15_037.png) 坐标表示。指针网络具有以下特点：
- en: Uses a recurrent neural network to obtain an embedding ![](img/Formula_15_038.png)
    from ![](img/Formula_15_039.png) of an input node ![](img/Formula_15_040.png)
    in the encoder, and similarly ![](img/Formula_15_041.png) in the decoder at the
    ![](img/Formula_15_042.png) step of the decoding.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用递归神经网络从编码器中的输入节点 ![](img/Formula_15_040.png) 的 ![](img/Formula_15_039.png)
    获得嵌入 ![](img/Formula_15_038.png)，并在解码的 ![](img/Formula_15_042.png) 步骤中类似地获得解码器中的
    ![](img/Formula_15_041.png)。
- en: 'Calculates attention on the input node ![](img/Formula_15_043.png) while decoding
    the ![](img/Formula_15_044.png) step as follows:'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在解码 ![](img/Formula_15_044.png) 步骤时，计算输入节点 ![](img/Formula_15_043.png) 的注意力，计算方式如下：
- en: '![](img/Formula_15_045.jpg)![](img/Formula_15_046.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_15_045.jpg)![](img/Formula_15_046.jpg)'
- en: where ![](img/Formula_15_047.png) and ![](img/Formula_15_048.png) are learnable
    parameters.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ![](img/Formula_15_047.png) 和 ![](img/Formula_15_048.png) 是可学习的参数。
- en: The input node ![](img/Formula_15_049.png) with the highest attention ![](img/Formula_15_050.png)
    becomes the ![](img/Formula_15_051.png) node to visit on the route.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有最高注意力 ![](img/Formula_15_050.png) 的输入节点 ![](img/Formula_15_049.png) 将成为路径中需要访问的
    ![](img/Formula_15_051.png) 节点。
- en: 'This attention approach is completely flexible and can point to a particular
    input node without any assumptions on the total number of input nodes. This mechanism
    is illustrated in *Figure 15.7*:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这种注意力方法完全灵活，可以在不对输入节点总数做任何假设的情况下指向特定的输入节点。该机制在 *图 15.7* 中得到了展示：
- en: '![Figure 15.7 – A pointer network (source: Vinyals et al., 2017)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 15.7 – 一个指针网络（来源：Vinyals 等，2017）'
- en: '](img/B14160_15_7.jpg)'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B14160_15_7.jpg)'
- en: 'Figure 15.7 – A pointer network (source: Vinyals et al., 2017)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.7 – 一个指针网络（来源：Vinyals 等，2017）
- en: Later work (*Nazari et al., 2018*) adapted pointer networks for use inside a
    policy-based RL model and obtained very promising results in fairly complex problems
    compared to open source routing optimizers. The details of pointer networks and
    how they are used in the context of RL deserves further space and discussion,
    which we defer to the papers we cite at the end of the chapter.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 后来的研究（*Nazari 等人，2018*）将指针网络应用于基于策略的强化学习模型，并在相对复杂的问题中取得了非常有前景的结果，与开源路径优化器相比具有优势。指针网络的细节及其在强化学习中的应用值得进一步的探讨，我们将在本章末尾引用的论文中深入讨论。
- en: With that, we conclude our discussion on RL applications for supply chain problems.
    Let's summarize what we have covered to close the chapter.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 通过上述内容，我们结束了关于强化学习在供应链问题中的应用讨论。让我们总结一下所涉及的内容，以便结束这一章节。
- en: Summary
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we covered two important classes of problems in supply chain
    management: inventory optimization and vehicle routing. These are both very complex
    problems, and RL has recently emerged as a competitive tool to address them. In
    this chapter, for the former problem, we provided you with a detailed discussion
    on how to create the environment and solve the corresponding RL problem. The challenge
    in this problem was the high variance across episodes, which we mitigated through
    a careful hyperparameter tuning procedure. For the latter problem, we described
    a realistic case of a gig driver who delivers meal orders that dynamically arrive
    from customers. We discussed how the model can be made more flexible to work with
    varying node sizes via pointer networks.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们讨论了供应链管理中的两个重要问题类别：库存优化和车辆路径规划。这些问题都非常复杂，强化学习（RL）最近作为一种竞争性工具出现，用于解决这些问题。在本章中，对于前者问题，我们提供了如何创建环境并解决相应强化学习问题的详细讨论。这个问题的挑战在于各个回合之间的高方差，我们通过细致的超参数调优程序来缓解这一问题。对于后者问题，我们描述了一个真实的案例，讲述了一名外卖司机如何处理来自顾客的动态订单。我们讨论了如何通过指针网络使得模型在处理不同节点大小时更加灵活。
- en: In the next chapter, we will discuss yet another exciting set of applications
    around personalization, marketing, and finance. See you there!
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章节中，我们将讨论另一组令人兴奋的应用，涉及个性化、市场营销和金融领域。我们在那里见！
- en: References
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: '*ORL: Reinforcement Learning Benchmarks for Online Stochastic Optimization
    Problems*, Balaji, Bharathan, et al. (2019): [http://arxiv.org/abs/1911.10641](http://arxiv.org/abs/1911.10641)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ORL: 在线随机优化问题的强化学习基准测试*，Balaji, Bharathan 等人（2019）：[http://arxiv.org/abs/1911.10641](http://arxiv.org/abs/1911.10641)'
- en: '*Pointer Networks*, Vinyals, Oriol, et al. (2017): [http://arxiv.org/abs/1506.03134](http://arxiv.org/abs/1506.03134)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*指针网络*，Vinyals, Oriol 等人（2017）：[http://arxiv.org/abs/1506.03134](http://arxiv.org/abs/1506.03134)'
- en: '*Reinforcement Learning for Solving the Vehicle Routing Problem*, Nazari, M,
    et al. (2018): [http://arxiv.org/abs/1802.04240](http://arxiv.org/abs/1802.04240)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*强化学习在解决车辆路径规划问题中的应用*，Nazari, M 等人（2018）：[http://arxiv.org/abs/1802.04240](http://arxiv.org/abs/1802.04240)'
