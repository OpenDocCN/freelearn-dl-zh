- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Sustainable Model Life Cycle Management, Feature Stores, and Model Calibration
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可持续模型生命周期管理、特征存储和模型校准
- en: The primary objective of this chapter is to provide you with sustainability-related
    best practices that should be followed during the model development process. This
    aligns with the previous chapter, where we discussed organizational goals related
    to sustainable AI. Our aim is to encourage people across different levels of an
    organizational hierarchy to restructure the organizational roadmap and build trustworthy
    AI solutions. You will get an understanding of the importance of all aspects of
    AI ethics and the best practices that need to be followed. We will illustrate
    how to incorporate privacy, security, and sustainability in a feature store example.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要目标是为你提供在模型开发过程中应遵循的与可持续性相关的最佳实践。这与上一章讨论的与可持续人工智能相关的组织目标一致。我们的目的是鼓励组织层级中的不同层级的人们重构组织路线图，建立可信的人工智能解决方案。你将了解人工智能伦理的各个方面的重要性，以及需要遵循的最佳实践。我们将通过一个特征存储的例子说明如何将隐私、安全和可持续性纳入其中。
- en: In this chapter, you will learn how to improve model probability estimates to
    yield more accurate outcomes. We will look at adaptable systems in the context
    of sustainability.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，你将学习如何改进模型的概率估计，以获得更准确的结果。我们将从可持续性的角度探讨可调节系统。
- en: By coupling sustainability with the concepts of model training and deployment,
    you will learn how to achieve sustainable, adaptable systems that facilitate collaboration
    and sharing. You will explore model calibration and learn about its importance
    when designing adaptable ethical AI solutions.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将可持续性与模型训练和部署的概念结合，你将学习如何实现可持续、可调节的系统，这些系统促进协作和共享。你将探索模型校准，并了解在设计可调节的伦理人工智能解决方案时它的重要性。
- en: 'In this chapter, we will cover the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容包括以下几点：
- en: Sustainable model development practices
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可持续模型开发实践
- en: Explainability, privacy, and sustainability in feature stores
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征存储中的可解释性、隐私和可持续性
- en: Exploring model calibration
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索模型校准
- en: Building sustainable, adaptable systems
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建可持续、可调节的系统
- en: Sustainable model development practices
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可持续模型开发实践
- en: Along with the ethical deployment of AI, sustainability helps us all to move
    one step closer to better ecological integrity and social justice. Throughout
    the process of building AI products – from idea generation to training, retuning,
    implementation, and governance – we should be aware of the environmental impact
    of our actions and AI solutions and ensure that they are friendly to future generations.
    When we consider the impact of our work using metrics, we work more responsibly
    and ethically. It is essential to have an organizational roadmap that describes
    best practices at each stage of model development so that change management is
    minimal and easy to track. This will also allow innovation in sustainable AI and
    compel organizations to hit CO2 emission targets for AI training, validation,
    deployment, and usage.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 除了道德地部署人工智能（AI）外，可持续性帮助我们所有人向更好的生态完整性和社会正义迈进。在构建人工智能产品的过程中——从创意生成到训练、调整、实施和治理——我们应该意识到我们的行动和人工智能解决方案对环境的影响，并确保它们对未来世代友好。当我们使用度量标准来考虑我们的工作影响时，我们会更负责任地和道德地开展工作。至关重要的是拥有一份描述模型开发各阶段最佳实践的组织路线图，这样变更管理最小且容易跟踪。这还将促进可持续人工智能的创新，并迫使组织为人工智能的训练、验证、部署和使用设定二氧化碳排放目标。
- en: In the next subsection, we will explore how organizations, people, and processes
    can be oriented toward sustainable AI model development. This will help teams
    to deploy models that are successful in the long run.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的子章节中，我们将探讨如何使组织、人员和流程能够朝着可持续人工智能模型开发的方向发展。这将帮助团队部署在长期内取得成功的模型。
- en: First, let’s look at how guidelines for building sustainable, trustworthy frameworks
    can be set out by organizations.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看组织如何制定构建可持续、可信框架的指南。
- en: Organizational standards for sustainable, trustworthy frameworks
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可持续、可信框架的组织标准
- en: 'In [*Chapter 3*](B18681_03.xhtml#_idTextAnchor066), we learned about regulations
    and policies surrounding trustworthy AI; the systems we deploy to production need
    to be 100% compliant with regulations. We have certain open source frameworks,
    as listed here, that can be reused and integrated into existing platforms:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [*第 3 章*](B18681_03.xhtml#_idTextAnchor066) 中，我们学习了关于可信 AI 的法规和政策；我们部署到生产的系统需要
    100% 符合这些法规。我们有一些可以重用并集成到现有平台中的开源框架，如下所示：
- en: '**TensorFlow Model Remediation**: This is a library developed by Google that
    aims to limit biases during model preprocessing training or postprocessing.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow 模型修正**：这是由 Google 开发的一个库，旨在限制模型预处理训练或后处理过程中产生的偏差。'
- en: '**TensorFlow Privacy**: This is a library developed by Google that enables
    ML optimizers to optimize the objective function of ML models while incorporating
    differential privacy.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow 隐私**：这是由 Google 开发的一个库，使机器学习优化器能够在融合差分隐私的同时优化机器学习模型的目标函数。'
- en: '**AI Fairness 360**: This is a library developed by IBM to detect and mitigate
    bias.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI 公平性 360**：这是 IBM 开发的一个库，用于检测和缓解偏差。'
- en: '**Responsible AI Toolbox**: This is a library developed by Microsoft to help
    access, develop, and deploy AI solutions ethically in a trustworthy environment.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负责任的 AI 工具箱**：这是由 Microsoft 开发的一个库，旨在帮助在可信环境中伦理地访问、开发和部署 AI 解决方案。'
- en: '**XAI**: This is a library that facilitates model explainability through model
    evaluation and monitoring.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**XAI**：这是一个通过模型评估和监控来促进模型可解释性的库。'
- en: '**TensorFlow Federated**: This is a library to support distributed training
    involving multiple clients.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow 联邦**：这是一个支持多个客户端参与的分布式训练的库。'
- en: 'In addition, we need to know how to incorporate the best practices in existing
    technological platforms, which can act as pointers for the evaluation of trustworthy
    frameworks. Let’s summarize the common model governance and risk management activities
    that should be practiced by organizational leadership. To establish the best ethical
    and sustainable practices in the development and deployment life cycle, the questions
    listed in *Figure 13**.1* need to be answered:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们需要知道如何将最佳实践融入现有技术平台中，这些平台可以作为评估可信框架的指引。让我们总结一下组织领导应当践行的常见模型治理和风险管理活动。为了在开发和部署生命周期中建立最佳的伦理和可持续实践，需要回答
    *图 13.1* 中列出的问题：
- en: '| **Model practice** | **Key questions** |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| **模型实践** | **关键问题** |'
- en: '| **Model development phase** |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| **模型开发阶段** |'
- en: '| Identification | Has the organization identified and listed key regulatory
    tools based on federal guidance?For example, for banking and insurance, certain
    financial and risk models need to be used to evaluate a framework. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 识别 | 组织是否根据联邦指导方针识别并列出了关键的合规工具？例如，对于银行和保险，某些金融和风险模型需要用于评估框架。 |'
- en: '| Inventorying | What is the model inventorying strategy?For example, is there
    a model classification process in place during the model development life cycle?Have
    different risks been accounted for, and how has this affected the ranking of the
    different models? |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 库存管理 | 模型库存管理策略是什么？例如，在模型开发生命周期中，是否有模型分类过程？不同的风险是否已被考虑，并且这如何影响不同模型的排名？ |'
- en: '| Naming policy and security | How is the model namespace managed?Does it take
    into consideration the domain problem as well as the business use case?How are
    the key stakeholders involved in model version control and security management?
    |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 命名策略和安全性 | 模型命名空间如何管理？是否考虑了领域问题以及业务用例？关键利益相关者如何参与模型版本控制和安全管理？ |'
- en: '| Formalized policy and procedure | Are there proper guidelines, audit checklists,
    and authorized personnel involved in formalizing the standards and guidelines
    for model development, validation, use, monitoring, and retirement? |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 正式化政策和程序 | 是否有适当的指南、审计检查清单以及授权人员参与正式化模型开发、验证、使用、监控和退休的标准和指南？ |'
- en: '| Compliance | Is there a regulatory requirements checklist?Are there frequent
    audits for regulatory requirements?Are there trained personnel involved who work
    closely with ML, data engineering, and analytics teams to verify that all enterprise
    systems abide by confirmation and compliance? |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 合规性 | 是否有合规要求清单？是否有针对合规要求的定期审计？是否有经过培训的人员参与，并与机器学习、数据工程和分析团队密切合作，以确保所有企业系统都遵守确认和合规性？
    |'
- en: '| Research and the application of best practices | Are there initiatives to
    deep dive and conduct research based on the problem that the model is serving?Are
    there properly trained personnel assigned to research and disseminate the current
    model’s best (standard) practices? |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 研究与最佳实践应用 | 是否有针对模型服务的实际问题进行深入研究的计划？是否有专门训练的人员负责研究并传播当前模型的最佳（标准）实践？'
- en: '| Documentation | Are there well-documented models within the scope of the
    problem definition and business objectives?Are there definitions of feature stores
    and established communication processes when teams share and reuse features, models,
    and data?How do we ensure data and model availability without violating security,
    while ensuring awareness among team members? |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 文档编制 | 是否有良好记录的模型，涵盖问题定义和业务目标的范围？是否有特征存储的定义，并在团队共享和重用特征、模型和数据时建立了沟通流程？如何确保数据和模型的可用性，同时不违反安全性，并确保团队成员的意识？
    |'
- en: '| Sharing and reuse | How are ML models and features shared in centralized
    and **Federated Learning** (**FL**)?How are built-in security, privacy, and notification
    strategies incorporated for feature updates across teams? |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 共享与重用 | 在集中式和**联邦学习**（**FL**）中，机器学习模型和特征是如何共享的？内建的安全、隐私和通知策略如何在团队之间的特征更新中应用？
    |'
- en: '| **Model validation phase** |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| **模型验证阶段** |'
- en: '| Testing and validation | How is the unit testing of models and system testing
    incorporated when models are put in place in the serving framework?What are the
    interventions and supervision techniques employed to ensure formal model validation
    procedures, along with the model-serving APIs?What are the guidelines and practices
    that are in place to certify model interoperability across platforms?What emission
    metrics have been considered? |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 测试与验证 | 当模型部署在服务框架中时，如何进行模型的单元测试和系统测试？为了确保正式的模型验证程序和模型服务API，采用了哪些干预和监督技术？为了确保跨平台的模型互操作性，已采取哪些准则和实践？考虑了哪些排放指标？
    |'
- en: '| Challenge/effective criticism | How are reviews/challenges encountered in
    model input, output, training, validation, and testing processes addressed?What
    agile processes are in place to incorporate incremental model changes to ensure
    that a model is accurate and, at the same time, private, fair, and interpretable?
    |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 挑战/有效批评 | 在模型输入、输出、训练、验证和测试过程中遇到的审查/挑战如何处理？有哪些敏捷流程被采用，以便纳入增量模型变更，确保模型准确，同时又符合隐私、公平和可解释性？
    |'
- en: '| **Model implementation phase** |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| **模型实施阶段** |'
- en: '| Implementation and use of governance | What are the standard operating procedures
    in place for models, with special reference to refreshes, queries, the use of
    links, data dumps, and the handling of input identification?Are the recommended
    practices for shared control tools being followed?Have shared techniques for users,
    such as watch windows, balance checks, and backups, been established? |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 治理的实施和使用 | 模型的标准操作程序是什么，特别是在刷新、查询、链接使用、数据转储和输入标识处理方面？是否遵循了共享控制工具的推荐实践？是否已经建立了共享用户技术，如监视窗口、平衡检查和备份？
    |'
- en: '| **Ongoing monitoring of models** |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| **模型的持续监控** |'
- en: '| Remediation | Is there the right sort of model tracking for remediation and
    the correction of errors?Are there defined metrics in place for sustainability
    across platforms, ML models, and data pipelines? |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 修复 | 是否有适当的模型追踪机制，用于修复和纠正错误？是否已经为平台、机器学习模型和数据管道的可持续性定义了指标？ |'
- en: '| Change management | How are model changes tracked and updated in documents?
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 变更管理 | 如何追踪和更新模型变更文档？ |'
- en: '| Auditing and reviewing | Are the best audit and review processes established
    to validate lines of defense and ensure the quality of model output?How have benchmarks
    been established to differentiate and scale models in larger enterprise-grade
    platforms?How will we effectively control costs from our benchmarks across different
    client platforms? |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 审计和审查 | 是否已建立最佳的审计和审查流程，以验证防御层并确保模型输出的质量？如何建立基准，以在更大规模的企业平台中区分和扩展模型？如何有效地控制不同客户平台上基准的成本？
    |'
- en: '| Definition of risk tolerance, appetite, and risk thresholds | What are the
    different threshold levels of model acceptance?Have we formulated a risk tolerance
    level based on the problem scope, domain, and volume of data that can be accepted
    within certain margins of uncertainty?Are we maintaining and establishing financial
    impact/dollar variances relative to the expectation of each of the models? |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 风险容忍度、风险偏好和风险阈值的定义 | 模型接受的不同阈值水平是什么？我们是否基于问题范围、领域和数据量制定了一个风险容忍度水平，并在一定的不确定性范围内接受？我们是否在维护和建立每个模型期望值的财务影响/美元差异？
    |'
- en: '| Identifying secondary risks | What are the techniques to assess risks arising
    out of managing other risks, such as delays in meeting a deadline or disrupting
    data schema? |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 识别次级风险 | 评估管理其他风险（例如延迟完成截止日期或干扰数据架构）所带来的风险的技术是什么？ |'
- en: '| Identifying operational risks | How do we define operational risks in which
    a model is implemented?Does this involve the consideration and periodic review
    of different features, such as the discount rate, or ensure the validation of
    operational procedures, such as version control? |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 识别操作风险 | 我们如何定义模型实施中的操作风险？这是否涉及考虑和定期审查不同特征，例如折扣率，或确保操作程序的验证，如版本控制？ |'
- en: '| Identifying emerging risks | What are the new or potential emerging risks
    due to continuous refreshes of models over time? |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 识别新兴风险 | 随着模型的持续更新，出现的新风险或潜在的风险是什么？ |'
- en: '| Tracking | What are the steps for model tracking for traditional-based, deep
    learning-based, and FL-based models?How do the tracking steps allow revisions
    and provide room for additional use throughout the entire model life cycle? |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 跟踪 | 传统模型、基于深度学习的模型和基于联邦学习的模型的跟踪步骤有哪些？这些跟踪步骤如何允许修改并在整个模型生命周期内提供额外使用的空间？ |'
- en: '| Ongoing monitoring | What monitoring tools and dashboards are in place to
    allow periodic monitoring over time of accuracy, relevance, and interpretability?How
    are model interpretability tools used to communicate to business stakeholders
    about business model risks, data, and concept drift? |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 持续监控 | 为了能够定期监控模型的准确性、相关性和可解释性，现有的监控工具和仪表盘有哪些？我们如何使用模型可解释性工具与业务利益相关者沟通关于商业模型的风险、数据以及概念漂移？
    |'
- en: '| **AI application usage** |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| **AI应用使用** |'
- en: '| Terms and conditions for licenses, terms of use, and click-thrus | What audit
    processes do we have to validate licenses, terms of use, and warranties? How do
    we ensure the proper usage of AI applications by including language dissuading
    the usage or liability of unintended applications? For example, allowing waivers
    for any use of life-saving equipment, mission-critical avionics, military applications,
    or munitions, and at the same time disavowing export to or use in embargoed countries.
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 许可协议、使用条款和点击协议的条款 | 我们有哪些审核流程来验证许可协议、使用条款和担保条款？我们如何确保通过包含语言来防止不当使用AI应用，避免因意外应用产生的责任？例如，允许针对任何用于生命救援设备、关键任务航空电子设备、军事应用或军火的豁免，并同时声明不允许向禁运国家出口或使用。
    |'
- en: Table 13.1 – Key model practices and questions
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 表 13.1 – 关键模型实践与问题
- en: Each business unit needs to answer the preceding questions to ensure the proper
    alignment of modeling processes to corporate strategies. This, in turn, helps
    organizations to become aware of sustainability practices and directs their focus
    to data and model development and governance strategies. Overall, the aim is to
    facilitate reuse and coordination in an environmentally friendly way. Hence, we
    need a unified model of chain management that prevents the potential misuse of
    ML models by increasing transparency and interpretability and reducing key-person
    dependence. It is also highly important to set the foundations on which the board
    of directors governs a corporation and the ethical boundaries under which the
    CxO office operates. CxO (where CxO refers to the roles of CEO, CTO, and CIO)
    initiatives that structure and drive the aforementioned processes under the purview
    of data teams are key to the success of any AI-driven business. Using such initiatives,
    we can not only increase profit margins by several percentage points but also
    save billions of dollars by using resources judiciously and employing trained
    data teams.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 每个业务单元都需要回答前述问题，以确保建模过程与公司战略的适当对接。这反过来有助于组织意识到可持续性实践，并将注意力集中在数据和模型开发以及治理策略上。总的来说，目标是以环保的方式促进重用和协调。因此，我们需要一个统一的链管理模型，通过提高透明度和可解释性并减少对关键人物的依赖，防止机器学习模型的潜在滥用。设定董事会治理公司和CxO办公室运作的伦理边界也是至关重要的。CxO（指CEO、CTO和CIO角色）发起的组织和推动上述过程的数据团队，是任何AI驱动的业务成功的关键。通过这样的举措，我们不仅可以提高几个百分点的利润率，还能通过明智使用资源和雇佣训练有素的数据团队，节省数十亿美元。
- en: Organizations that fail to answer the preceding questions and establish the
    required processes suffer from time and monetary losses. In addition, they fail
    to sustain their AI-driven business use cases in this competitive world.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 那些未能回答前面问题并建立所需流程的组织，通常会遭受时间和金钱的损失。此外，他们无法在这个竞争激烈的世界中维持基于AI的业务用例。
- en: Having understood this, we can now move on to looking at feature stores.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解了这一点后，我们可以继续深入研究特征存储。
- en: Explainability, privacy, and sustainability in feature stores
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征存储中的可解释性、隐私性和可持续性
- en: In [*Chapter 10*](B18681_10.xhtml#_idTextAnchor218), we introduced the concept
    of feature stores and demonstrated with an example how online feature stores can
    be used. Furthermore, in the previous section, we learned about the important
    aspects of sustainable model training and deployment and the best practices for
    tracking sustainable model metrics across different cloud providers. We also saw
    in [*Chapter 12*](B18681_12.xhtml#_idTextAnchor243) that FL provides a training
    environment to allow sustainability, by allowing the local training of devices.
    Hence, we must try to leverage FL in training ML models in healthcare, retail,
    banking, and other industry verticals in scenarios where generic model representation
    plays an important role as computational power is limited.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第10章*](B18681_10.xhtml#_idTextAnchor218)中，我们介绍了特征存储的概念，并通过一个例子演示了如何使用在线特征存储。此外，在前一节中，我们学习了可持续模型训练和部署的关键方面，并且了解了如何在不同的云服务商之间跟踪可持续模型指标的最佳实践。我们还在[*第12章*](B18681_12.xhtml#_idTextAnchor243)中看到，联邦学习（FL）通过允许设备本地训练，为可持续性提供了一个训练环境。因此，我们必须尝试在医疗保健、零售、银行等行业中，利用FL进行机器学习模型的训练，特别是在通用模型表示起到重要作用而计算能力有限的情况下。
- en: In this section, let’s dig deeper into creating explainable, private, and sustainable
    feature stores.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，让我们深入探讨如何创建可解释的、私密的和可持续的特征存储。
- en: Feature store components and functionalities
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征存储的组件和功能
- en: 'Let’s now explore how the different components of a feature store serve their
    functional roles in a distributed architecture, as shown in *Figure 13**.1*:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探索特征存储的不同组件如何在分布式架构中发挥其功能角色，如*图13.1*所示：
- en: '![Figure 13.1 – The different components of an ethical feature store](img/Figure_13.1_B18681.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图13.1 – 伦理特征存储的不同组件](img/Figure_13.1_B18681.jpg)'
- en: Figure 13.1 – The different components of an ethical feature store
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1 – 伦理特征存储的不同组件
- en: 'The following list looks at each component in more detail:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表详细介绍了每个组件：
- en: The first component is the data source unit, where data can be received and
    aggregated from third-party sources. The data can be raw data, SQL data, or event
    data. To build sustainable ML models and feature stores, we need to have FL capabilities
    built into the infrastructure, where the data is mostly event data from mobile
    devices, IoT devices, or **Internet of Medical Things** (**IoMTs**). FL definitely
    provides us with an opportunity to practice sustainable model development. However,
    without FL, having an automated feedback loop with re-training capabilities can
    also help us to create sustainable ML models.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个组件是数据源单元，在这里数据可以从第三方来源接收并聚合。数据可以是原始数据、SQL 数据或事件数据。为了构建可持续的机器学习模型和特征存储，我们需要在基础设施中构建联邦学习能力，其中数据主要来自移动设备、物联网设备或**医疗物联网**（**IoMTs**）的事件数据。联邦学习无疑为我们提供了实践可持续模型开发的机会。然而，如果没有联邦学习，具有自动反馈循环和再训练能力的系统也可以帮助我们创建可持续的机器学习模型。
- en: The second component comprises the ingestion and feature engineering pipelines,
    where data needs to be anonymized to protect **Personally Identifiable Information**
    (**PII**), which we discussed in [*Chapter 2*](B18681_02.xhtml#_idTextAnchor040).
    To highlight and build sustainable pipelines, we must support reuse in our design
    to extract relevant features that can be used across teams. In addition, to support
    federated collaboration-based learning methodologies and deployment strategies,
    feature engineering pipelines should be distributed across cloud and edge devices.
    This will help to distribute load and control the emission rates of centralized
    training procedures. For example, *Figure 13**.2* illustrates a working methodology
    of FL in edge networks using **Deep Neural Networks** (**DNNs**). We have also
    shown different kinds of cloud services (from Google Cloud Platform) that can
    be used in the server component.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个组件包括数据摄取和特征工程管道，在这里，数据需要匿名化以保护**个人身份信息**（**PII**），我们在[*第 2 章*](B18681_02.xhtml#_idTextAnchor040)中有讨论过。为了突出并构建可持续的管道，我们必须在设计中支持重用，以提取可以跨团队使用的相关特征。此外，为了支持基于联邦合作学习方法和部署策略，特征工程管道应该分布在云端和边缘设备上。这将有助于分配负载并控制集中训练程序的排放速率。例如，*图
    13.2*展示了在边缘网络中使用**深度神经网络**（**DNNs**）的联邦学习工作方法。我们还展示了可以在服务器组件中使用的不同类型的云服务（来自谷歌云平台）。
- en: '![Figure 13.2 – FL in edge networks](img/Figure_13.2_B18681.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.2 – 边缘网络中的联邦学习](img/Figure_13.2_B18681.jpg)'
- en: Figure 13.2 – FL in edge networks
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.2 – 边缘网络中的联邦学习
- en: In the preceding figure, *Figure 13.2*, the client aggregates data from numerous
    IoT devices and engages in local deep learning-based model training, while a few
    servers deployed at several edges are responsible for the first level of model
    aggregation, which ultimately gets aggregated in the cloud. The aggregated model
    is then pushed to the edges, and local clients continue with training on their
    local datasets.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，*图 13.2*，客户端从多个物联网设备收集数据，并进行基于本地深度学习的模型训练，而部署在多个边缘的少数服务器负责第一层模型聚合，最终将其聚合到云端。聚合后的模型随后被推送到边缘，客户端继续在本地数据集上进行训练。
- en: The third component involves feature management and explainability for online
    and offline processing. In [*Chapter 4*](B18681_04.xhtml#_idTextAnchor093), we
    discussed how we can create sandbox environments or isolation units through the
    use of appropriate security rules to process and store features as required by
    different teams with different levels of sensitivity (refer to *Figure 4**.12*
    in [*Chapter 4*](B18681_04.xhtml#_idTextAnchor093)). This component is also engaged
    in satisfying the pillars of AI ethics that govern feature explainability, bias
    identification, and feature recommendations. The fairness side of data and features
    also needs to be satisfied by this component, as biased datasets and extracted
    features can lead to biased ML models.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个组件涉及特征管理和在线与离线处理的可解释性。在[*第 4 章*](B18681_04.xhtml#_idTextAnchor093)中，我们讨论了如何通过使用适当的安全规则创建沙箱环境或隔离单元，以处理和存储不同团队所需的特征，这些团队具有不同的敏感性级别（请参见[*第
    4 章*](B18681_04.xhtml#_idTextAnchor093)中的*图 4.12*）。该组件还涉及满足规范特征可解释性、偏差识别和特征推荐的
    AI 伦理原则。数据和特征的公平性也需要通过该组件来满足，因为有偏的数据集和提取的特征可能导致有偏的机器学习模型。
- en: The fourth component is storage, where metadata, online, and offline features
    can be stored. This includes both SQL and NoSQL databases and the cache, where
    storage can be maintained on disk as well as in memory for fast retrieval.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四个组件是存储，在此存储元数据、在线和离线特征。这包括 SQL 和 NoSQL 数据库以及缓存，数据可以存储在磁盘上，也可以存储在内存中以便快速检索。
- en: The fifth component involves the ways that users can perform time-travel queries
    that execute high-speed searches to return data at a given point in time (where
    we can learn about the history of the data and record its lineage), the data for
    a given time interval, and the changes made to data since a given point in time.
    Time-travel queries are executed efficiently using indexes (bloom filters, *z*-indexes,
    and data-skipping indexes), which deserve special mention, as they reduce the
    amount of data that needs to be read from a filesystem or object store.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第五个组件涉及用户如何执行时间旅行查询，这些查询能够快速搜索并返回某一特定时间点的数据（我们可以了解数据的历史以及记录其沿革），某一时间区间的数据，以及自某一时间点以来数据所做的更改。时间旅行查询通过使用索引（布隆过滤器、*z*
    索引和数据跳过索引）高效执行，这些索引值得特别提及，因为它们减少了需要从文件系统或对象存储读取的数据量。
- en: The final component (along with model training, deployment, and monitoring)
    is also responsible for identifying model drift. With access privileges set on
    individual models, this component promotes the comparison of model scoring metrics
    in order to take quick action on model re-training.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后的组件（与模型训练、部署和监控一同）还负责识别模型漂移。通过对个别模型设置访问权限，该组件促使模型评分指标的比较，以便快速采取模型再训练的措施。
- en: Next, let’s move on to learning about feature stores for FL.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们继续学习 FL 的特征存储。
- en: Feature stores for FL
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FL 的特征存储
- en: We saw how feature stores play an important role in ML model reuse and features
    for centralized learning in [*Chapter 10*](B18681_10.xhtml#_idTextAnchor218).
    Now, let’s investigate how we can leverage some of the existing concepts of feature
    store pipelines for collaborative learning, as in the case of FL frameworks. This
    will facilitate the development and deployment of federated tools, allowing the
    technical teams of organizations, educational institutes, and partners to come
    together and share data, ML models, and their features.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到特征存储在 ML 模型重用和集中学习特征中的重要作用，在 [*第 10 章*](B18681_10.xhtml#_idTextAnchor218)
    中已经讨论过。现在，让我们探讨如何利用现有的特征存储管道概念来支持协作学习，特别是在 FL 框架的案例中。这将促进联合工具的开发和部署，允许组织、教育机构和合作伙伴的技术团队共同协作，分享数据、ML
    模型和特征。
- en: We will see how **FeatureCloud AI Store** for FL (primarily built for biomedical
    research) can be used across other domains by providing a platform to unify a
    set of ready-to-use apps.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到 **FeatureCloud AI Store** 如何为 FL（主要用于生物医学研究）提供一个平台，通过统一一组即用型应用来跨领域使用。
- en: '*Figure 13**.3* demonstrates the different components of FeatureCloud, explaining
    how collaborating parties can work together to create a certified feature store
    in the cloud that can include new third-party apps:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 13**.3* 展示了 FeatureCloud 的不同组件，解释了合作方如何协作创建一个可以包含新的第三方应用程序的云端认证特征存储：'
- en: '![Figure 13.3 – A private FeatureCloud store for FL](img/Figure_13.3_B18681.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.3 – 一个私有的 FeatureCloud 存储用于 FL](img/Figure_13.3_B18681.jpg)'
- en: Figure 13.3 – A private FeatureCloud store for FL
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.3 – 一个私有的 FeatureCloud 存储用于 FL
- en: These unified federated apps can yield similar results to centralized ML in
    scalable platforms. With increased collaboration, built-in privacy mechanisms
    such as **homomorphic encryption**, secure multi-party computation, and differential
    privacy become of great importance, as they protect sensitive information. FeatureCloud
    AI Store is a feature store that removes the restrictions of conventional FL-based
    modeling by redefining the **Application Programming Interface** (**API**), making
    it easier for developers to reuse and share novel apps from external developers.
    Along with an open API system, it has the support of deployment distribution,
    allowing the use of algorithms through configurable workflows. The feature store
    is transparent and open to external developers, who are free to add and publish
    their own federated apps, making the system an efficient collaboration medium
    for data, models, and apps.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这些统一的联邦应用可以在可扩展平台上产生类似于集中式机器学习的结果。随着协作的增加，内置的隐私机制如**同态加密**、安全多方计算和差分隐私变得极为重要，因为它们可以保护敏感信息。FeatureCloud
    AI Store 是一个特征存储，通过重新定义**应用程序接口**（**API**），消除了传统基于联邦学习（FL）建模的限制，使开发者可以更容易地重用和分享外部开发者的创新应用程序。配合开放的API系统，它支持部署分发，允许通过可配置的工作流程使用算法。该特征存储对外部开发者透明开放，开发者可以自由添加和发布自己的联邦应用，使该系统成为数据、模型和应用程序高效协作的媒介。
- en: The app interface available in the third-party apps, as shown in the preceding
    figure, provides detailed information on the different categories of apps by displaying
    basic information about them, including short descriptions, keywords, user ratings,
    and certification status. In addition, each app – as well as being classified
    into either preprocessing, analysis, or evaluation – is equipped with a graphical
    frontend or a simple configuration file to set app parameters and adapt them to
    different contexts.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，第三方应用中提供的应用接口提供了有关不同类别应用的详细信息，通过显示它们的基本信息，包括简短描述、关键词、用户评分和认证状态。此外，每个应用不仅被分类为预处理、分析或评估，还配备了图形化前端或简单配置文件，用于设置应用参数并使其适应不同的上下文。
- en: Any app that is part of FeatureCloud runs inside a Docker container, which can
    exchange data and other essential information with other apps using the FeatureCloud
    API. The stores accelerate the development of federated applications by providing
    a template and a test simulator for testing.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 任何在FeatureCloud中运行的应用都在一个Docker容器内运行，该容器可以通过FeatureCloud API与其他应用交换数据和其他关键信息。该存储通过提供模板和测试模拟器来加速联邦应用的开发。
- en: This kind of shared app environment comes with app documentation, search and
    filter functionality, and an app certification process to promote privacy standards
    in the AI store. The certification process enforces strong guidelines about testing
    frequently for privacy leaks; the failure of these tests leads to a notification
    for concerned developers to address the issue. However, it also comes with a functionality
    whereby a new certification process is issued whenever an application is updated.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这种共享应用环境带有应用文档、搜索和过滤功能，以及应用认证流程，以推动AI商店中的隐私标准。认证流程对频繁测试隐私泄露有严格的指导原则；如果测试失败，将通知相关开发者解决问题。然而，它也提供了一项功能，即每当应用更新时，都会发起一个新的认证流程。
- en: One key drawback of this kind of collaborative, sustainable platform is that
    the coordinator has access to all the individual models before aggregating them.
    Hence, the framework comes with different privacy measures, such as secure multi-party
    computation and differential privacy, to handle any privacy leaks.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这种协作型、可持续的平台的一个主要缺点是，协调者在聚合各个模型之前可以访问所有的单独模型。因此，该框架提供了不同的隐私保护措施，如安全多方计算和差分隐私，以防止任何隐私泄露。
- en: 'A federated workflow can be designed by bringing in all collaborating partners
    that download and start the client-side FeatureCloud controller on their machines
    using Docker. The coordination can be smoothly established across user apps from
    the AI store, as users can create an account on the FeatureCloud website. It facilitates
    cross-institutional data and algorithm sharing and analysis by integrating **Cross-Validation**
    (**CV**), standardization, model training, and model evaluation procedures through
    separate apps in the workflow, as shown in *Figure 13**.4*:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦工作流可以通过让所有协作伙伴在他们的机器上下载并启动客户端 FeatureCloud 控制器（使用 Docker）来设计。由于用户可以在 FeatureCloud
    网站上创建账户，跨用户应用程序的协调可以顺利建立。这通过在工作流中的独立应用程序中集成**交叉验证**（**CV**）、标准化、模型训练和模型评估程序，促进了跨机构的数据和算法共享与分析，如*图
    13.4*所示：
- en: '![Figure 13.4 – A FeatureCloud workflow using app-based FL](img/Figure_13.4_B18681.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.4 – 基于应用程序的 FL 的 FeatureCloud 工作流](img/Figure_13.4_B18681.jpg)'
- en: Figure 13.4 – A FeatureCloud workflow using app-based FL
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.4 – 基于应用程序的 FL 的 FeatureCloud 工作流
- en: As multiple apps form a workflow, the consecutive execution of those apps one
    after the other completes the running of a unique workflow. Outputs or results
    from one application can be consumed by another application, and the overall workflow
    progress can be tracked or monitored. The results from the workflow can be shared
    among the participating entities to understand and evaluate each step of the overall
    modeling process. FeatureCloud can solve practical problems in biomedicine and
    other domains.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 当多个应用程序形成一个工作流时，这些应用程序的连续执行完成了一个独特工作流的运行。一个应用程序的输出或结果可以被另一个应用程序消费，整体工作流的进展可以被追踪或监控。工作流的结果可以在参与方之间共享，以便理解和评估整体建模过程的每一步。FeatureCloud
    可以解决生物医学和其他领域的实际问题。
- en: Now that we understand how FeatureCloud operates, let’s try to understand some
    of its important properties.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了 FeatureCloud 的运作方式，让我们尝试了解一些它的重要属性。
- en: The properties of FeatureCloud
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FeatureCloud 的属性
- en: 'Here, we will learn how a collaborative cloud environment created through a
    set of apps in a federated setup can help us to serve better workflows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将学习如何通过一套在联合设置中创建的应用程序，构建一个协作云环境，帮助我们提供更好的工作流：
- en: FeatureCloud offers different combinations of ML algorithms to solve common
    problems, by efficiently utilizing them from apps in the AI store or app templates.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FeatureCloud 提供了多种机器学习算法的组合，来解决常见问题，通过高效地利用 AI 商店或应用模板中的应用程序。
- en: It uses a common standardized data format that offers an easy way to compose
    apps in a workflow, from data ingestion and mutual data consumption to the generation
    of the output.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使用一种通用的标准化数据格式，提供了一种简便的方法来组合应用程序进入工作流，从数据摄取和相互数据消费到输出生成。
- en: It drives collaborative research to serve broader objectives by bringing in
    less-experienced developers as well as experienced professionals to create customized
    workflows.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它推动了协作研究，通过引入经验较少的开发者和有经验的专业人士，共同创建定制化的工作流，以实现更广泛的目标。
- en: In this section, we learned about concepts related to federated feature stores
    that are ethically compliant. Now, let’s learn how to enhance predictability in
    AI/ML-governed systems by determining the likelihood of predictions for different
    classes. This will help us to design realistic systems with minimal drift.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解了与道德合规的联合特征存储相关的概念。现在，让我们了解如何通过确定不同类别预测的可能性，来增强 AI/ML 驱动系统的可预测性。这将帮助我们设计出具有最小漂移的现实系统。
- en: So, let’s explore model calibration, a postprocessing technique that not only
    improves model probability estimates but also helps to create sustainable, robust
    model predictions.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们探索模型校准，这是一种不仅能改善模型概率估计，还能帮助创建可持续、稳健的模型预测的后处理技术。
- en: Exploring model calibration
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索模型校准
- en: Calibration is a model postprocessing technique that is used to improve probability
    estimates. The objective is to improve a model in such a way that the distribution
    and behaviors of the predicted and observed probabilities match.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 校准是一种模型后处理技术，用于提高概率估计。其目标是改进模型，使得预测概率和观察到的概率的分布及行为相匹配。
- en: Model calibration is required for mission-critical applications where the likelihood
    of a data point being associated with a class is very important – for instance,
    building a model to predict the likelihood of an individual being ill.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于关键任务应用，需要进行模型校准，在这些应用中，数据点与某一类别相关联的概率非常重要——例如，构建一个预测个体生病概率的模型。
- en: Let’s try to understand calibration better with the help of a classic cat-dog
    classifier example.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过经典的猫狗分类器示例更好地理解校准。
- en: Let’s assume we’re working with a cat-dog classifier where all the input images
    are only cats or dogs. Now, if a model thinks that the input image is of a cat,
    it outputs `1`; conversely, if it thinks that the input image is of a dog, it
    outputs `0`. Our models are essentially continuous mapping functions – that is,
    they output values between `0` and `1`. This can be achieved mathematically, using
    approaches such as having a sigmoid function as the activation function in the
    final layer. A good classifier is likely to produce scores near `1` for cats and
    scores near `0` for dogs.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在使用一个猫狗分类器，其中所有输入图像要么是猫要么是狗。现在，如果模型认为输入图像是猫，它输出`1`；反之，如果它认为输入图像是狗，它输出`0`。我们的模型本质上是连续映射函数——也就是说，它们输出介于`0`和`1`之间的值。这可以通过数学方法实现，例如在最后一层使用sigmoid函数作为激活函数。一个好的分类器通常会为猫生成接近`1`的分数，为狗生成接近`0`的分数。
- en: But are these scores between `0` and `1` representative of actual probabilities?
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这些介于`0`和`1`之间的分数是否代表实际的概率呢？
- en: "![Figure 13.5 – A cat\uFEFF-dog classifier example](img/Figure_13.5_B18681.jpg)"
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图13.5 – 猫狗分类器示例](img/Figure_13.5_B18681.jpg)'
- en: Figure 13.5 – A cat-dog classifier example
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.5 – 猫狗分类器示例
- en: Does the score of 0.18 in the preceding figure mean that 18% of the input image
    is a cat? If a model is well calibrated, then hypothetically, yes! We can interpret
    its results as probabilities. The main concern is how to determine whether our
    model is well calibrated. Consider another real-life example – looking outside
    to see a storm brewing when the probability of rain given by your weather app
    is less than 5%. This happens when a model is not well calibrated and, thus, performs
    poorly. Let’s look at how to determine whether a model is well calibrated.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 上图中的0.18分数意味着输入图像中有18%是猫吗？如果模型经过良好校准，那么假设是的！我们可以将其结果解释为概率。主要问题是如何判断我们的模型是否已经校准好。考虑一个现实生活中的例子——当天气应用给出的降雨概率低于5%时，你却看到外面乌云密布。这通常发生在模型没有良好校准的情况下，从而导致其表现不佳。让我们来看看如何判断一个模型是否经过良好校准。
- en: Determining whether a model is well calibrated
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 判断模型是否经过良好校准
- en: Referring to the previous example of the cat-dog classifier, in order to understand
    whether these numbers can be seen as probabilities, we need to plot a reliability
    graph. In a reliability graph, the *x* axis plots the score given by the model
    – that is, the predicted probabilities of the positive class (in our example,
    the `cat` class). Whenever an image is received, it will be put in the correct
    bracket based on the score provided by the model – for instance, if the image
    has a score of 0.9, it will be placed in the 0.8 to 1 bracket, where the model
    presumes that it is more likely to be an image of a cat. For an image score of
    0.06, the image will be placed in the 0 to 0.2 bracket, for images that are very
    likely to be of a dog. We can continue in this manner for many images and keep
    populating our graph. Once have added a large number of images, we can look at
    the *y* axis, which plots the number of images that are actually of cats; in other
    words, the *y* axis represents the actual frequencies of the positive class. For
    a well-calibrated classifier, the points will be close to the diagonal line.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 参考之前的猫狗分类器示例，为了理解这些数字是否可以视为概率，我们需要绘制一个可靠性图。在可靠性图中，*x*轴绘制模型给出的分数——即正类的预测概率（在我们的例子中是`猫`类）。每当接收到一张图像时，它将根据模型给出的分数被放入正确的区间——例如，如果图像的分数为0.9，它将被放入0.8到1的区间，模型假定它更有可能是猫的图像。对于分数为0.06的图像，它将被放入0到0.2的区间，表示该图像很可能是狗的图像。我们可以以此类推，继续为许多图像绘制图表。当我们添加大量图像后，可以查看*y*轴，它表示实际为猫的图像数量；换句话说，*y*轴表示正类的实际频率。对于一个良好校准的分类器，这些点将接近对角线。
- en: '![Figure 13.6 – The scores output by the model and the proportion of images
    that were actually of cats](img/Figure_13.6_B18681.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图13.6 – 模型输出的分数与实际猫图像的比例](img/Figure_13.6_B18681.jpg)'
- en: Figure 13.6 – The scores output by the model and the proportion of images that
    were actually of cats
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.6 – 模型输出的分数与实际为猫的图像比例
- en: The preceding graph shows an example of a poorly calibrated model. For the range
    of 0.4 to 0.6, if the score truly represented a probability, then there would
    be a 40–60% chance of any particular image in the stack being of a cat. However,
    we only see a 25% chance of an image being of a cat in this bracket; this indicates
    a poorly calibrated model.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表展示了一个校准不准确的模型示例。在0.4到0.6的范围内，如果得分确实代表概率，那么某个图像是猫的概率应该是40%到60%。然而，我们只看到在这个区间内，图像为猫的概率为25%；这表明这是一个校准不准确的模型。
- en: Calibration applies to both classification and regression tasks. Here, we have
    discussed an example of a classification task. In regression tasks, we focus on
    estimating the probability distribution of the predicted values. The calibrated
    regressor model defines the mean prediction, and the expected distribution around
    this mean value reflects the uncertainty associated with the prediction.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 校准适用于分类任务和回归任务。这里我们讨论的是分类任务的示例。在回归任务中，我们关注的是估计预测值的概率分布。校准后的回归模型定义了平均预测值，并且围绕这个均值的预期分布反映了与预测相关的不确定性。
- en: Before delving into different calibration techniques, let’s first understand
    why miscalibration occurs.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨不同的校准技术之前，我们首先要了解为什么会发生校准不准确。
- en: Why miscalibration occurs
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么会发生校准不准确
- en: Miscalibration is a common problem for ML models that are not trained using
    a probabilistic framework and where there is bias in the training data. In most
    scenarios, an inherent characteristic of a model is responsible for whether that
    model ends up being calibrated or not. In the case of logistic regression, we
    leverage the loss function; hence, no additional post-training is required. This
    is due to the fact that the probabilities generated by it are calibrated in advance.
    The independence assumption in Gaussian Naive Bayes can cause poorly calibrated
    probability estimates, nudging them close to 0 or 1\. Nonetheless, in the case
    of a random forest classifier, values near 0 or 1 are rarely achieved, since an
    average of multiple inner decision trees is calculated. The only surefire way
    to accomplish 0 or 1 is when each model returns a value near 0 or 1, which is
    an intriguing occasion from a probability perspective.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 校准不准确是机器学习模型常见的问题，尤其是当模型没有在概率框架下训练，且训练数据存在偏差时。在大多数情况下，模型的固有特性决定了该模型是否最终会被校准。以逻辑回归为例，我们利用损失函数，因此无需额外的训练后处理。这是因为其生成的概率在前期已经过校准。高斯朴素贝叶斯中的独立性假设可能导致概率估计不准确，将其推向接近0或1的值。然而，在随机森林分类器的情况下，接近0或1的值很少出现，因为是多个内部决策树的平均值计算得出的。唯一能确保达到0或1的方式是每个模型返回一个接近0或1的值，这是从概率的角度来看非常有趣的情况。
- en: Let’s now learn about various calibration techniques.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们了解各种校准技术。
- en: Calibration techniques
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 校准技术
- en: Some classification models, such as **Support Vector Machines** (**SVMs**),
    **k-nearest neighbors**, and decision trees, either do not provide probability
    scores or give poor estimates. Such approaches need to be coerced into giving
    a probability-like score, and thus, calibration prior to usage is required.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 一些分类模型，如**支持向量机**（**SVM**）、**k近邻**和决策树，既不提供概率分数，或者给出的是不准确的估计值。这些方法需要被强制给出类似概率的分数，因此，在使用前必须进行校准。
- en: '**Platt scaling** and **isotonic regression** are two of the most prominent
    calibration techniques in use. Both of these approaches transform the output of
    the model into a likelihood score and, hence, calibrate it. We will study these
    techniques in the following sections.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**Platt 扩展**和**等距回归**是目前最为突出的两种校准技术。两者都将模型的输出转换为似然分数，从而实现校准。我们将在接下来的章节中研究这些技术。'
- en: Platt scaling
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Platt 扩展
- en: The principle of this technique involves the transformation of classification
    model output into a probability distribution. Put simply, Platt scaling is used
    when a calibration plot looks like a sigmoid curve and is efficient for small
    datasets.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这一技术的原理是将分类模型的输出转换为概率分布。简而言之，当校准图呈现S形曲线时，使用Platt扩展技术非常有效，尤其适用于小型数据集。
- en: "![Figure 13\uFEFF.7 – Platt scaling illustration](img/Figure_13.7_B18681.jpg)"
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.7 – Platt 扩展示意图](img/Figure_13.7_B18681.jpg)'
- en: Figure 13.7 – Platt scaling illustration
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.7 – Platt 扩展示意图
- en: Platt scaling is a modified sigmoid function and solves an optimization problem
    to get A and B. It returns a degree of certainty about the actual outcome instead
    of returning class labels. With classification models such as SVM, as discussed
    previously, we utilize particular transformation techniques in order to calibrate
    our model and obtain a probability as the outcome.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Platt 缩放是一个修改过的 S 型函数，通过求解优化问题来获得 A 和 B。它返回对实际结果的确定程度，而不是返回类别标签。对于诸如支持向量机（SVM）之类的分类模型，如前所述，我们采用特定的转换技术来校准模型，并获取概率作为输出。
- en: Isotonic regression
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 等距回归
- en: Compared to Platt scaling, isotonic regression is a more powerful calibration
    technique that is capable of correcting any monotonic distortion. It is used when
    a calibration plot does not look like a sigmoid curve. Isotonic regression breaks
    a curve into multiple linear models and, hence, requires more points than Platt
    scaling. This technique tries to find the best set of predictions that are non-decreasing
    and are as close as possible to the primal (original data) points. The approach
    entails implementing regression on the primal, or original, calibration curve
    when applied to the issue of calibration. Unlike Platt scaling, isotonic regression
    is not recommended for small datasets to avoid overfitting and is intended to
    be used on large datasets, due to its outlier sensitivity.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Platt 缩放相比，等距回归是一种更强大的校准技术，能够修正任何单调的失真。当校准图形看起来不像 S 型曲线时，它会被使用。等距回归将曲线分割为多个线性模型，因此需要比
    Platt 缩放更多的点。这种技术试图找到一组最佳的非递减预测，并尽可能接近原始数据点。该方法在应用于校准问题时，涉及在原始校准曲线上实施回归。与 Platt
    缩放不同，等距回归不推荐用于小型数据集，以避免过拟合，并且适用于大型数据集，因为它对离群点较为敏感。
- en: Next, we will see, with a hands-on example, how model calibration can affect
    model reliability.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过一个动手示例，展示模型校准如何影响模型的可靠性。
- en: Model calibration using scikit-learn
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 进行模型校准
- en: 'In this section, we will use the scikit-learn module to synthetically create
    data to compare the reliability and performance of uncalibrated and calibrated
    models. This is how we do this:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 scikit-learn 模块合成数据，以比较未校准模型和已校准模型的可靠性与性能。具体方法如下：
- en: 'As a first step, we import all the necessary modules. Here, we will be using
    scikit-learn both for synthetic data generation and to build classifiers – both
    uncalibrated and calibrated:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入所有必要的模块。在这里，我们将使用 scikit-learn 来生成合成数据，并构建分类器——包括未校准和已校准的分类器：
- en: '[PRE0]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here, we first consider a balanced dataset. The following statement generates
    10,000 samples, each with 10 features, and equal distribution for the two classes:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们首先考虑一个平衡的数据集。以下语句生成了 10,000 个样本，每个样本有 10 个特征，并且两类的分布是相等的：
- en: '[PRE1]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'For convenience, we will put the features and labels in respective DataFrames:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 为了方便，我们将特征和标签放入各自的 DataFrame 中：
- en: '[PRE2]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, let’s verify whether the data is balanced or not using the following code:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用以下代码验证数据是否平衡：
- en: '[PRE3]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'In the following plot, you can see equal distribution of the labels:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，您可以看到标签的均匀分布：
- en: '![Figure 13.8 – A bar chart showing class distribution in the synthetic data](img/Figure_13.8_B18681.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.8 – 显示合成数据中类别分布的条形图](img/Figure_13.8_B18681.jpg)'
- en: Figure 13.8 – A bar chart showing class distribution in the synthetic data
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.8 – 显示合成数据中类别分布的条形图
- en: 'Next, we split our data into training, validation, and test datasets with a
    ratio of 60:20:20:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将数据分为训练集、验证集和测试集，比例为 60:20:20：
- en: '[PRE4]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then, we train a simple logistic regression classifier on the training dataset:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 接着，我们在训练数据集上训练一个简单的逻辑回归分类器：
- en: '[PRE5]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s see the performance of our classifier using the area under the curve
    metric:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过曲线下面积指标来查看分类器的表现：
- en: '[PRE6]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `auc` value of our classifier is `0.92` – not bad!
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分类器的 `auc` 值是 `0.92`——还不错！
- en: 'We also check our classifier performance using the **Brier score**. It is a
    measure of the accuracy of probabilistic predictions, mathematically expressed
    as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用 **Brier 分数** 来检查分类器的表现。它是对概率预测准确度的衡量，数学表达式如下：
- en: Brier score = 1*N∑i* *=* 1*Np*(*y*i) *−* *o*(*y*i)2
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Brier 分数 = 1*N∑i* *=* 1*Np*(*y*i) *−* *o*(*y*i)²
- en: 'Here, *N* is the number of instances, *p*(*y*i) is the predicted probability
    that an instance, `i`, belongs to the *y*i class, and *o*(*y*i) is the actual
    outcome of the instance, `i`, with *o*(*y*i) = 1 if *y*i is the true class and
    *o*(*y*i) = 0 otherwise:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，*N* 是实例的数量，*p*(*y*i) 是实例 `i` 属于 *y*i 类的预测概率，*o*(*y*i) 是实例 `i` 的实际结果，若 *y*i
    为真实类别，则 *o*(*y*i) = 1，否则 *o*(*y*i) = 0：
- en: '[PRE7]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The Brier score ranges from 0 to 1, with a score of 0 indicating perfect accuracy
    and a score of 1 indicating the worst possible performance. Our classifier shows
    a Brier score of 0.11, again a good performance.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 布赖尔得分的范围从0到1，得分为0表示完美准确，得分为1表示最差的表现。我们的分类器显示布赖尔得分为0.11，表现依然优秀。
- en: 'Let’s now repeat the process for a calibrated classifier, for the same balanced
    dataset:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们为同一平衡数据集重复该过程，使用校准后的分类器：
- en: '[PRE8]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'From both the accuracy and Brier score values, we can see that for the balanced
    dataset, the uncalibrated classifier is as good as the calibrated classifier:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 从准确性和布赖尔得分（Brier score）值来看，我们可以看到，对于平衡数据集，未经校准的分类器与校准后的分类器表现相当：
- en: '[PRE9]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following plotted reliability curves confirm this:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 以下绘制的可靠性曲线证实了这一点：
- en: '![Figure 13.9 – A reliability curve for balanced data](img/Figure_13.9_B18681.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图13.9 - 平衡数据的可靠性曲线](img/Figure_13.9_B18681.jpg)'
- en: Figure 13.9 – A reliability curve for balanced data
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.9 - 平衡数据的可靠性曲线
- en: 'Let’s now repeat the process for an imbalanced dataset:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们为不平衡数据集重复该过程：
- en: '[PRE10]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can verify that the classes are highly imbalanced by plotting the frequency
    chart for labels:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过绘制标签的频率图来验证类别的高度不平衡：
- en: '[PRE11]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here is the plot for it:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是相应的图表：
- en: '![Figure 13.10 – A bar chart showing class distribution in the synthetic data](img/Figure_13.10_B18681.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图13.10 - 显示合成数据中类别分布的条形图](img/Figure_13.10_B18681.jpg)'
- en: Figure 13.10 – A bar chart showing class distribution in the synthetic data
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.10 - 显示合成数据中类别分布的条形图
- en: 'As before, we split the dataset into training, validation, and test datasets
    with a 60:20:20 ratio:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们将数据集按60:20:20的比例分为训练集、验证集和测试集：
- en: '[PRE12]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, we explore the uncalibrated model:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们探索未经校准的模型：
- en: '[PRE13]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'And finally, we explore the calibrated model:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们探索校准后的模型：
- en: '[PRE14]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here is the graph for it:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是相应的图表：
- en: '![Figure 13.11 – A reliability curve for unbalanced data](img/Figure_13.11_B18681.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图13.11 - 不平衡数据的可靠性曲线](img/Figure_13.11_B18681.jpg)'
- en: Figure 13.11 – A reliability curve for unbalanced data
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.11 - 不平衡数据的可靠性曲线
- en: We can see that calibrated models give a more reliable prediction compared to
    the uncalibrated model for unbalanced data.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，校准后的模型相比未经校准的模型，对于不平衡数据提供了更可靠的预测。
- en: Let’s now explore how to design adaptable systems by considering dynamic calibration
    curves.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过考虑动态校准曲线来探索如何设计适应性强的系统。
- en: Building sustainable, adaptable systems
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建可持续、适应性强的系统
- en: We have looked at the step-by-step processes for model governance and sustainable
    model training and deployment. We also now understand how important it is to build
    reusable feature stores.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经查看了模型治理、可持续模型训练和部署的逐步流程。我们现在也明白了构建可重用特征存储的重要性。
- en: We understand that without a feature store, we will end up with a separate feature
    engineering pipeline for each model that we want to deploy. Duplicate pipelines
    inevitably lead to added compute costs and data lineage overheads, as well as
    lots of engineering effort. However, the endeavor of building a sustainable feature
    store will be fruitless if it’s not robust and resilient enough to adapt to data
    and concept drift.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们了解到，如果没有特征存储（feature store），每个我们想要部署的模型都会有一个独立的特征工程流程。重复的流程不可避免地会导致计算成本增加、数据血统（lineage）开销增大以及大量工程工作。然而，如果建立的特征存储没有足够的鲁棒性和适应性以应对数据和概念漂移，那么建立可持续的特征存储的努力将是徒劳的。
- en: 'Even when we design large-scale distributed ML systems, we should think about
    building an adaptable system with the ability to detect data drift, concept drift,
    and calibration drift. This will facilitate continuous monitoring and mean that
    we can manage new, incoming data from different sources. For example, in a retail
    system, we may encounter new customers with varied buying patterns, while in a
    healthcare system, we might see new patients with new diseases coming into the
    system. To build adaptable systems that can deal with continuous change, we must
    understand how calibration and dynamic calibration curves help us to detect and
    improve model performance. While calibration curves provide diagrammatic representations
    of model performance across a range of predicted probabilities, dynamic calibration
    curves help us to visualize the development of true calibration curves over a
    time series by considering each observation in place. Furthermore, a dynamic curve,
    by representing the weighted distribution of predicted probabilities, helps us
    to estimate the fitted values on an evaluation set. This kind of fitting helps
    to evaluate the performance of the fitted curve. You can read more about this
    here: [https://www.sciencedirect.com/science/article/pii/S1532046420302392](https://www.sciencedirect.com/science/article/pii/S1532046420302392).'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在设计大规模分布式机器学习系统时，我们也应考虑构建一个具有检测数据漂移、概念漂移和校准漂移能力的适应性系统。这将有助于持续监控，并意味着我们可以管理来自不同来源的新数据。例如，在零售系统中，我们可能会遇到具有不同购买模式的新客户，而在医疗保健系统中，我们可能会看到新患者带来新的疾病。为了构建能够应对持续变化的适应性系统，我们必须理解校准和动态校准曲线如何帮助我们检测和改善模型性能。校准曲线提供了在一系列预测概率下的模型性能的图示，而动态校准曲线则通过考虑每个观察值的情况，帮助我们可视化时间序列上真实校准曲线的发展。此外，动态曲线通过表示预测概率的加权分布，帮助我们估算评估集上的拟合值。这种拟合有助于评估拟合曲线的性能。你可以在这里阅读更多内容：[https://www.sciencedirect.com/science/article/pii/S1532046420302392](https://www.sciencedirect.com/science/article/pii/S1532046420302392)。
- en: The feature stores we build should have automation built in to support dynamic
    calibration curves and evaluate changes in model performance from new observations.
    Feature store drift detectors can alert teams about miscalibration as new data
    accumulates and, furthermore, automate the re-training process using the recent
    data window. Most importantly, if we can accurately detect drift in time series,
    and the trends seem to be permanent, then we should also see a change in calibration.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建的特征存储应该内置自动化功能，以支持动态校准曲线，并评估来自新观察的模型性能变化。特征存储漂移检测器可以在新数据积累时提醒团队注意误校准，此外，还可以使用最近的数据窗口自动化重新训练过程。最重要的是，如果我们能够准确检测时间序列中的漂移，并且趋势似乎是永久性的，那么我们还应该看到校准的变化。
- en: MLOps teams should be cautious of the speed and magnitude of calibration drift
    once it begins, which can be efficiently detected by accurate monitoring systems.
    The change should come from a relatively high number of observations to give us
    confidence that there is indeed a transition from a calibrated to a miscalibrated
    model.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦校准漂移开始，MLOps 团队应警惕其速度和幅度，这可以通过精确的监控系统有效检测。变化应来自相对较高数量的观察，以确保我们有信心确定模型从已校准状态转变为误校准状态。
- en: Dynamic calibration curves are not strong enough to learn miscalibration in
    low-density, high-probability ranges, due to limited knowledge in the concerned
    probability area.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在相关概率区域内的知识有限，动态校准曲线在低密度、高概率范围内学习误校准的能力不够强。
- en: '*Figure 13**.12* illustrates a dynamic calibration curve, specifically how
    its response evolves over a period due to changes in model performance.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 13.12* 展示了动态校准曲线，特别是其响应如何因模型性能的变化而在一段时间内发展。'
- en: By miscalibration (et ), we mean the deviation of the curve from the ideal calibration,
    which is obtained by computing the absolute difference between an observation’s
    predicted probability (pt) and the fitted value of the current curve at the predicted
    probability ([https://www.sciencedirect.com/science/article/pii/S1532046420302392](https://www.sciencedirect.com/science/article/pii/S1532046420302392)).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 所谓误校准（et），是指曲线偏离理想校准的情况，其通过计算观察值的预测概率（pt）与当前曲线在预测概率处的拟合值之间的绝对差异来获得（[https://www.sciencedirect.com/science/article/pii/S1532046420302392](https://www.sciencedirect.com/science/article/pii/S1532046420302392)）。
- en: '![Figure 13.12 – Dynamic calibration curves over a period](img/Figure_13.12_B18681.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.12 – 一段时间内的动态校准曲线](img/Figure_13.12_B18681.jpg)'
- en: Figure 13.12 – Dynamic calibration curves over a period
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.12 – 一段时间内的动态标定曲线
- en: 'Some important areas of focus to detect calibration drift that necessitates
    model updates are listed here:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出了需要关注的一些重要领域，以检测需要更新模型的标定漂移：
- en: A dynamic calibration curve should aim to showcase performance degradation,
    even without highlighting the specific degradation.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态标定曲线应旨在展示性能衰退，即使不突出具体的衰退部分。
- en: Miscalibrations can exhibit fluctuations between over-prediction and under-prediction
    zones, with a wide boundary of probability. This is further signified by calibration
    errors varying before and after drift.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 错标定可能会在过度预测和欠预测区域之间出现波动，且概率边界较宽。这一点在漂移前后的标定误差变化中得到了进一步体现。
- en: Calibration drift often results from transitional states.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标定漂移通常源自过渡状态。
- en: Variance in dynamic calibration curves can be handled by tweaking the step size,
    or initial learning rate, of the Adam optimizer (a deep learning optimizer used
    for the first-order, gradient-based optimization of stochastic objective functions)
    to quickly respond to changes in model performance.
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态标定曲线的方差可以通过调整Adam优化器的步长或初始学习率来处理，从而快速响应模型性能的变化。（Adam优化器是一种深度学习优化器，用于随机目标函数的一阶基于梯度的优化）
- en: Significance margins for model performance need to be properly set and defined
    for very small changes in calibration.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于模型性能的显著性边际，需要为非常小的标定变化正确设置和定义。
- en: Based on model complexity, the minimum window size needs to be defined to capture
    sufficient samples for model updates.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据模型的复杂性，需要定义最小窗口大小，以捕获足够的样本进行模型更新。
- en: 'As you can see in *Figure 13**.13*, the online and offline feature spaces are
    shared to create a combined shared feature called **encoders**. Refer to the following
    figure:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在*图13.13*中看到的，在线和离线特征空间是共享的，创建了一个合并的共享特征，称为**编码器**。参见下图：
- en: '![](img/Figure_13.13_B18681.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Figure_13.13_B18681.jpg)'
- en: Figure 13.13 – The importance of a calibration drift detector in feature stores
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.13 – 特征存储中标定漂移检测器的重要性
- en: While **Team B** contributes to the offline feature generation process, **Team
    A** and **Team C** take part in the online feature generation process. If a sudden
    change in any of the online features triggers a calibration drift and harms the
    model’s performance, there must be an immediate alert triggered to **Team B**,
    as that team also accesses the shared feature space. A model trained using the
    shared features of **Team B** can also experience calibration drift and must take
    immediate corrective action by triggering re-training.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然**B队**参与离线特征生成过程，**A队**和**C队**则参与在线特征生成过程。如果任何在线特征的突然变化触发标定漂移并损害模型的性能，必须立即向**B队**触发警报，因为该队也访问共享特征空间。使用**B队**共享特征训练的模型也可能经历标定漂移，并且必须通过触发重新训练来立即进行修正。
- en: Here, we observe the importance of a calibration drift detection algorithm for
    running and triggering alerts.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们观察到运行和触发警报的标定漂移检测算法的重要性。
- en: In addition to calibration drift, we studied in [*Chapter 7*](B18681_07.xhtml#_idTextAnchor146)
    how data and concept drift play an important role and how adaptable frameworks
    have evolved to handle those kinds of drift. Now, it is also important that we
    broaden our scope to apply that in the context of sustainable training environments
    and incorporate adaptable frameworks in feature stores. We have learned about
    sustainable feature stores; now, let’s integrate the idea of concept drift into
    FL environments.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标定漂移，我们在[*第7章*](B18681_07.xhtml#_idTextAnchor146)中研究了数据和概念漂移如何发挥重要作用，以及适应性框架如何发展以应对这些漂移。现在，重要的是，我们要拓宽视野，将这一概念应用于可持续训练环境，并将适应性框架融入特征存储。我们已经了解了可持续特征存储；现在，让我们将概念漂移的思想整合到FL环境中。
- en: Concept drift-aware federated averaging (CDA-FedAvg)
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 考虑概念漂移的联邦平均（CDA-FedAvg）
- en: We have seen in FL design patterns that the asynchronous method of sending model
    updates serves power-hungry devices well, giving them the flexibility to participate
    in training whenever they have power available. It also aids in concept drift
    detection and adaptation techniques in a collaborative environment, with the server
    orchestrating the process.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在FL设计模式中看到，异步发送模型更新的方法对于电力消耗大的设备非常有利，使它们在有电的情况下灵活参与训练。它还帮助在协作环境中进行概念漂移检测和适应技术，服务器负责协调这一过程。
- en: The server acts as an orchestrator to aggregate models from individual devices,
    and the local devices become the deciding body to select the data and the time
    to trigger the process of local training.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器充当协调者，将来自各个设备的模型进行聚合，本地设备则成为决定性主体，选择数据和触发本地训练过程的时间。
- en: 'The model aggregated by the central server is globally agreed upon (each individual
    model from the participating entities is agreed upon and averaged by the server),
    and the server broadcasts it to all the clients. The clients become responsible
    for detecting and handling changes in data and model patterns. The clients train
    the models on their local training datasets and manage drift in a three-stage
    process:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 由中央服务器聚合的模型是全球公认的（参与实体的每个单独模型都经过服务器的同意并平均化），然后服务器将其广播到所有客户端。客户端负责检测和处理数据和模型模式的变化。客户端在其本地训练数据集上训练模型，并通过三阶段过程来管理漂移：
- en: Timing-based drift identification
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于时间的漂移识别
- en: Drift **Root Cause Analysis** (**RCA**) to identify the cause of the drift and
    the data instance where it starts to occur
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 漂移**根本原因分析**（**RCA**）用于识别漂移的原因和漂移开始发生的数据实例
- en: Response and mitigation methodology to adapt drift to yield high-accuracy models
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 响应与缓解方法以适应漂移，从而产生高精度模型
- en: As clients are exposed to newly collected data from several input sources, they
    are equipped with drift detection algorithms to identify new concepts (drift detection)
    and learn from them. The drift adaptation techniques built in help to analyze
    how the data or model differs between two timestamps, as well as analyzing the
    drift’s nature or what causes it, taking remedial actions accordingly. The local
    clients are equipped with short-term memory and long-term memory to respond to
    drift as soon as it is detected. While short-term memory helps to store and compare
    data instances collected by the client in the latest time interval, long-term
    memory stores data samples for events or concepts that were old and appeared in
    previous instances, as compared to a current point in time.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 当客户端接收到来自多个输入源的新收集数据时，它们会配备漂移检测算法以识别新概念（漂移检测）并从中学习。内建的漂移适应技术帮助分析数据或模型在两个时间戳之间的差异，以及分析漂移的性质或其原因，并采取相应的补救措施。当地客户端配备了短期记忆和长期记忆，以便在检测到漂移时立即做出响应。短期记忆帮助存储和比较客户端在最新时间间隔内收集的数据实例，而长期记忆则存储过去事件或概念的数据样本，这些事件或概念与当前时间点相比较。
- en: 'This kind of adaptation with short-term and long-term memory helps us to understand
    data, model patterns, and concepts and trigger model training or re-training locally,
    by storing data records over a long period. This process happens in a sequence
    of events, as shown in *Figure 13**.14*:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这种具有短期和长期记忆的适应性帮助我们理解数据、模型模式和概念，并通过长时间存储数据记录来触发本地模型训练或再训练。这个过程按照事件顺序发生，如*图13.14*所示：
- en: '![Figure 13.14 – CDA-FedAvg in FL clients](img/Figure_13.14_B18681.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图13.14 – CDA-FedAvg在FL客户端中的应用](img/Figure_13.14_B18681.jpg)'
- en: Figure 13.14 – CDA-FedAvg in FL clients
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.14 – CDA-FedAvg在FL客户端中的应用
- en: 'As shown in the preceding figure, we take actions based on the presence or
    absence of drift in the following manner:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所示图所示，我们基于漂移的存在与否采取以下行动：
- en: Both short-term and long-term memory are initialized as empty when the local
    training process has not kicked off yet.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当本地训练过程尚未启动时，短期和长期记忆都会初始化为空。
- en: Once the client acquires the first data, it gets stored in long-term memory
    as the initial concept and is used for the first training and local update.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦客户端获得首个数据，它将作为初始概念存储在长期记忆中，并用于首次训练和本地更新。
- en: Any subsequent data received by the client is stored in short-term memory to
    evaluate drift.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端收到的任何后续数据将存储在短期记忆中，以评估漂移。
- en: Upon identification of potential drift, the new data acquired that’s relevant
    to the new concept gets stored in long-term memory.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在识别到潜在漂移后，与新概念相关的新数据将被存储在长期记忆中。
- en: In addition, a new case of drift triggers a new round of training at the client’s
    end.
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，新的漂移案例会触发客户端的新的训练轮次。
- en: Thus, a well-designed system should not only run the best concept drift detection
    algorithm, whether in a centralized or FL environment, but also should be well
    calibrated to experience minimal drift due to changes in input data.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一个设计良好的系统不仅应运行最佳的概念漂移检测算法，无论是在集中式还是FL环境中，还应经过良好的校准，以确保由于输入数据变化导致的漂移最小。
- en: Summary
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have learned about the main guiding principles that leadership
    and stakeholders should use to take direct action to enable the best model-building
    practices in their organizational culture. This chapter gave us a deep insight
    into how to make the best use of FL in designing federated feature stores to encourage
    collaborative research through the use of APIs. In addition, we explored the concept
    of adaptable frameworks in feature stores that are also ethically compliant concerning
    privacy, interpretability, and fairness.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了领导者和利益相关者应采取的主要指导原则，以便采取直接行动，推动最佳的模型构建实践融入他们的组织文化。本章深入探讨了如何在设计联邦特征存储时充分利用联邦学习，鼓励通过使用API促进协作研究。此外，我们还探索了特征存储中可适应框架的概念，这些框架在隐私、可解释性和公平性方面也符合伦理要求。
- en: Furthermore, we learned how, with the help of calibration, to improve a model
    when its output suggests that it has regions of high probabilities, which may
    not be authentic. Metrics that take the prediction score as input can also be
    taken into consideration – for instance, the **Area Under the Curve-Receiver Operating
    Characteristics** (**AUC-ROC**) score is based on positioning predictions, but
    it falls short when it comes to accurately calibrated probabilities.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还学习了如何通过校准来改进模型，当模型输出显示存在高概率区域时，这些区域可能并不真实。也可以考虑将预测分数作为输入的指标——例如，**曲线下面积-接收者操作特征**（**AUC-ROC**）分数基于预测位置，但在准确校准的概率方面表现不佳。
- en: Calibration is advantageous in complex ML systems and real-world scenarios.
    It modifies the results of ML models after training and preserves the consistency
    of the output. Performing calibration can affect model accuracy, and in general,
    it is observed that calibrated models tend to be slightly less accurate than uncalibrated
    ones. However, this detrimental effect on accuracy is extremely low, and the advantages
    calibration offers are much more significant. Calibrating a model is a crucial
    step in improving prediction performance if a model’s objective is to achieve
    good probability prediction.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 校准在复杂的机器学习系统和实际场景中具有优势。它在训练后调整机器学习模型的结果，并保持输出的一致性。执行校准可能会影响模型的准确性，通常观察到校准后的模型准确度略低于未经校准的模型。然而，这种对准确性的负面影响非常低，而校准所带来的优势则要显著得多。如果模型的目标是实现良好的概率预测，校准模型是提高预测性能的关键步骤。
- en: In this chapter, we identified the sustainability aspects of ethical models
    and how FL and federated feature stores can be hooked together, with sustainable
    energy solutions, to compute and control carbon emissions. After gaining a thorough
    understanding of the best design frameworks for ethical ML modeling, in the next
    chapter, let’s study how to apply these patterns in different domains to solve
    real-world use cases.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们识别了伦理模型的可持续性方面，以及如何将联邦学习（FL）和联邦特征存储结合起来，通过可持续能源解决方案来计算和控制碳排放。在充分理解了最佳设计框架用于伦理机器学习建模之后，在下一章中，我们将学习如何将这些模式应用于不同领域，以解决实际的使用案例。
- en: Further reading
  id: totrans-222
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: '*The FeatureCloud AI Store for Federated Learning in Biomedicine and* *Beyond*:
    [https://arxiv.org/pdf/2105.05734.pdf](https://arxiv.org/pdf/2105.05734.pdf)'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*FeatureCloud AI Store 在生物医学和* *其他领域中的联邦学习应用*：[https://arxiv.org/pdf/2105.05734.pdf](https://arxiv.org/pdf/2105.05734.pdf)'
- en: '*Detection of calibration drift in clinical prediction models to inform model*
    *updating*: [https://www.sciencedirect.com/science/article/pii/S1532046420302392](https://www.sciencedirect.com/science/article/pii/S1532046420302392)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*临床预测模型中校准漂移的检测，以指导模型* *更新*：[https://www.sciencedirect.com/science/article/pii/S1532046420302392](https://www.sciencedirect.com/science/article/pii/S1532046420302392)'
- en: '*Calibration Techniques and it’s importance in Machine* *Learning*: [https://kingsubham27.medium.com/calibration-techniques-and-its-importance-in-machine-learning-71bec997b661](https://kingsubham27.medium.com/calibration-techniques-and-its-importance-in-machine-learning-71bec997b661)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*校准技术及其在机器* *学习中的重要性*：[https://kingsubham27.medium.com/calibration-techniques-and-its-importance-in-machine-learning-71bec997b661](https://kingsubham27.medium.com/calibration-techniques-and-its-importance-in-machine-learning-71bec997b661)'
- en: '*Calibration, Imbalanced* *Data*: [https://amueller.github.io/aml/04-model-evaluation/11-calibration.html](https://amueller.github.io/aml/04-model-evaluation/11-calibration.html)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*校准，数据不平衡*：[https://amueller.github.io/aml/04-model-evaluation/11-calibration.html](https://amueller.github.io/aml/04-model-evaluation/11-calibration.html)'
- en: '*Brier Score: Understanding Model* *Calibration*: [https://neptune.ai/blog/brier-score-and-model-calibration](https://neptune.ai/blog/brier-score-and-model-calibration)'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Brier分数：理解模型* *校准*: [https://neptune.ai/blog/brier-score-and-model-calibration](https://neptune.ai/blog/brier-score-and-model-calibration)'
- en: '*How to Calibrate Probabilities for Imbalanced* *Classification*: [https://machinelearningmastery.com/probability-calibration-for-imbalanced-classification/](https://machinelearningmastery.com/probability-calibration-for-imbalanced-classification/)'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*如何为不平衡* *分类校准概率*: [https://machinelearningmastery.com/probability-calibration-for-imbalanced-classification/](https://machinelearningmastery.com/probability-calibration-for-imbalanced-classification/)'
- en: '*Classifier* *calibration*: [https://towardsdatascience.com/classifier-calibration-7d0be1e05452](https://towardsdatascience.com/classifier-calibration-7d0be1e05452)'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*分类器* *校准*: [https://towardsdatascience.com/classifier-calibration-7d0be1e05452](https://towardsdatascience.com/classifier-calibration-7d0be1e05452)'
- en: '*Why model calibration matters and how to achieve* *it*: [https://www.unofficialgoogledatascience.com/2021/04/why-model-calibration-matters-and-how.html](https://www.unofficialgoogledatascience.com/2021/04/why-model-calibration-matters-and-how.html)'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*为什么模型校准很重要，如何实现* *？*: [https://www.unofficialgoogledatascience.com/2021/04/why-model-calibration-matters-and-how.html](https://www.unofficialgoogledatascience.com/2021/04/why-model-calibration-matters-and-how.html)'
- en: '*What does model calibration mean in ML in* *Python*: [https://www.projectpro.io/recipes/what-does-model-calibration-mean](https://www.projectpro.io/recipes/what-does-model-calibration-mean)'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Python中的模型校准是什么意思* *？*: [https://www.projectpro.io/recipes/what-does-model-calibration-mean](https://www.projectpro.io/recipes/what-does-model-calibration-mean)'
- en: '*A guide to model* *calibration*: [https://wttech.blog/blog/2021/a-guide-to-model-calibration/](https://wttech.blog/blog/2021/a-guide-to-model-calibration/)'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*模型* *校准指南*: [https://wttech.blog/blog/2021/a-guide-to-model-calibration/](https://wttech.blog/blog/2021/a-guide-to-model-calibration/)'
- en: '*Calibration in Machine* *Learning*: [https://medium.com/analytics-vidhya/calibration-in-machine-learning-e7972ac93555](https://medium.com/analytics-vidhya/calibration-in-machine-learning-e7972ac93555)'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器* *学习中的校准*: [https://medium.com/analytics-vidhya/calibration-in-machine-learning-e7972ac93555](https://medium.com/analytics-vidhya/calibration-in-machine-learning-e7972ac93555)'
- en: '*Prediction & Calibration Techniques to Optimize Performance of Machine Learning*
    *Models*: [https://towardsdatascience.com/calibration-techniques-of-machine-learning-models-d4f1a9c7a9cf](https://towardsdatascience.com/calibration-techniques-of-machine-learning-models-d4f1a9c7a9cf)'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*预测与校准技术以优化机器学习* *模型的表现*: [https://towardsdatascience.com/calibration-techniques-of-machine-learning-models-d4f1a9c7a9cf](https://towardsdatascience.com/calibration-techniques-of-machine-learning-models-d4f1a9c7a9cf)'
