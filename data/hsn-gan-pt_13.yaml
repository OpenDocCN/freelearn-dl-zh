- en: Reconstructing 3D models with GANs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用GAN重建3D模型
- en: So far, we've learned how to synthesize images, text, and audio with GANs. Now,
    it's time to explore the 3D world and learn how to use GANs to create convincing
    3D models.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学习了如何使用GAN合成图像、文本和音频。现在，是时候探索3D世界并学习如何使用GAN创建令人信服的3D模型了。
- en: In this chapter, you will learn how 3D objects are represented in **computer
    graphics** (**CG**). We will also look into the fundamental concepts of CG, including
    camera and projection matrices. By the end of this chapter, you will have learned
    how to create and train 3D_GAN to generate a point cloud of 3D objects, such as
    chairs.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习3D物体在**计算机图形学**（**CG**）中的表示方法。我们还将深入了解CG的基本概念，包括相机和投影矩阵。在本章结束时，你将学会如何创建和训练3D_GAN，以生成3D物体的点云，如椅子。
- en: You will know the fundamental knowledge of the representation of 3D objects
    and the basic concept of 3D convolution. Then, you will learn to construct a 3D-GAN
    model by 3D convolutions and train it to generate 3D objects. You will also get
    familiar with PrGAN, a model that generates 3D objects based on their black-and-white
    2D views.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 你将了解3D物体表示的基本知识和3D卷积的基本概念。然后，你将学习如何通过3D卷积构建3D-GAN模型，并训练它生成3D物体。你还将熟悉PrGAN，这是一种基于物体的黑白2D视图生成3D物体的模型。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Fundamental concepts in computer graphics
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机图形学的基本概念
- en: Designing GANs for 3D data synthesis
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计用于3D数据合成的GAN
- en: Fundamental concepts in computer graphics
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机图形学的基本概念
- en: In the previous chapters, we learned about various GAN models for image, text,
    and audio. Generally, we have been solely dealing with 1D and 2D data. In this
    chapter, we will expand on our knowledge of the GAN world by looking at the 3D
    domain. By the end of this chapter, you will have learned how to create your own
    3D objects with GANs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们学习了关于图像、文本和音频的各种GAN模型。通常，我们一直在处理1D和2D数据。在本章中，我们将通过研究3D领域，扩展我们对GAN世界的理解。在本章结束时，你将学会如何使用GAN创建自己的3D物体。
- en: Representation of 3D objects
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3D物体的表示
- en: It is essential to understand how 3D objects are represented in a computer before
    we dive into the details of the GAN model for 3D data synthesis. The creation
    and rendering of 3D objects, environments, and animations is called **computer
    graphics** (**CG**), which two of the major entertainment industries, that is
    video games and movies, heavily rely on. The most important task in CG is figuring
    out how to efficiently render the most convincing images on the screen. Thanks
    to the hard work of people in the CG field, we are now getting better visual effects
    in video games and movies.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解用于3D数据合成的GAN模型细节之前，必须理解3D物体在计算机中的表示方法。3D物体、环境和动画的创建与渲染被称为**计算机图形学**（**CG**），这是视频游戏和电影两个主要娱乐产业所依赖的领域。CG中最重要的任务是如何高效地渲染出最逼真的图像。得益于CG领域从业者的辛勤工作，我们现在在视频游戏和电影中获得了更好的视觉效果。
- en: Attributes of a 3D object
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3D物体的属性
- en: 'The most basic attributes a 3D object has are its shape and color. The color
    of each pixel we can see on a screen is affected by many factors, such as the
    color of its own texture, the light source, and even the other objects in the
    scene. This is also affected by the relative directions of the light source and
    our viewpoint to the pixel''s own surface, which are determined by the shape,
    position, and orientation of the object and the position of the camera. When it
    comes to shape, a 3D model basically consists of points, lines, and surfaces.
    An example of the creation of the shape and color of a 3D sports car can be seen
    in the following image:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个3D物体最基本的属性是其形状和颜色。我们在屏幕上看到的每个像素的颜色受多种因素的影响，例如其纹理本身的颜色、光源，甚至场景中的其他物体。这也受到光源和我们视角与像素自身表面相对方向的影响，这些方向由物体的形状、位置、朝向以及相机的位置决定。至于形状，3D模型基本由点、线和面组成。下面的图像展示了如何创建一个3D跑车的形状和颜色：
- en: '![](img/a2aa33c9-fac3-4267-b444-ab0eca87a4c4.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a2aa33c9-fac3-4267-b444-ab0eca87a4c4.png)'
- en: The creation of a sports car in Autodesk Maya shows how lines form surfaces
    and how textures provide colors in 3D models
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在Autodesk Maya中创建一辆跑车，展示了线条如何形成表面，以及纹理如何在3D模型中提供颜色
- en: 'A surface, either flat or curved, is mostly formed with triangles and quadrangles
    (which are generally called **polygons**). A polygon mesh (also called a **wireframe**)
    is defined by a set of 3D points and a set of segments connecting those points.
    Normally, having more polygons means that there will be more details in the 3D
    models. This can be seen in the following image:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 表面，无论是平坦的还是曲面的，大多由三角形和四边形（通常称为**多边形**）组成。多边形网格（也称为**线框**）由一组3D点和连接这些点的一组段定义。通常情况下，多边形越多，3D模型中的细节就越多。这可以从以下图像中看出：
- en: '![](img/224ddaca-470d-440c-ae18-be82840e4450.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](img/224ddaca-470d-440c-ae18-be82840e4450.png)'
- en: More polygons means more details in 3D models. Images captured in Autodesk Maya.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在3D模型中，多边形数量越多，细节就越丰富。由Autodesk Maya捕获的图像。
- en: 'Sometimes, a set of points (also known as a **point cloud** in some applications)
    is all we need to create 3D objects since there are several widely used methods
    for automatically creating segments in order to generate a polygon mesh (for example,
    the Delaunay triangulation method). Point clouds are often used to represent the
    results that are collected by 3D scanners. A point cloud is a set of three-dimensional
    vectors representing the spatial coordinates of each point. In this chapter, we
    are only interested in the generation of the point clouds of certain objects with
    GANs. A few examples of the point clouds of chairs can be seen in the following
    image:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，一组点（在某些应用程序中称为**点云**）就足以创建3D对象，因为有几种广泛使用的方法可以自动创建段以生成多边形网格（例如Delaunay三角剖分方法）。点云通常用于表示3D扫描仪收集的结果。点云是一组三维向量，表示每个点的空间坐标。在本章中，我们只关注使用GAN生成特定对象的点云。以下图像展示了几个椅子的点云示例：
- en: '![](img/c9de716c-bf8f-4b09-a65b-d85fc7894e2b.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c9de716c-bf8f-4b09-a65b-d85fc7894e2b.png)'
- en: Point clouds of chairs
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 椅子的点云
- en: Camera and projection
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摄像机和投影
- en: 'Once the shape and color of the 3D objects have been defined, there''s still
    a major factor that will affect the way they look on the screen: the **camera**.
    The camera is responsible for mapping the 3D points, lines, and surfaces to the
    2D image plane, which is usually our screen. If the camera isn''t configured correctly,
    we may not see our objects at all. The process of mapping from the 3D world to
    the 2D image plane is called **projection**.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义了3D对象的形状和颜色，仍然有一个重要因素会影响它们在屏幕上的显示：**摄像机**。摄像机负责将3D点、线和表面映射到通常是我们的屏幕上的2D图像平面。如果摄像机配置不正确，我们可能根本看不到我们的对象。从3D世界映射到2D图像平面的过程称为**投影**。
- en: 'There are two different commonly used projection methods in the field of CG: orthographic
    projection and perspective projection. Let''s go over them now:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在CG领域中有两种常用的投影方法：正交投影和透视投影。现在让我们来了解它们：
- en: '**Orthographic projection** is a process that maps everything in a cuboid (that
    is, a rectangular volume) to a standard cube. For more information about orthographic
    and perspective projection, please refer to [http://www.songho.ca/opengl/gl_projectionmatrix.html](http://www.songho.ca/opengl/gl_projectionmatrix.html).'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正交投影**是一种将长方体（即矩形体积）中的所有内容映射到标准立方体中的过程。有关正交投影和透视投影的更多信息，请参阅[http://www.songho.ca/opengl/gl_projectionmatrix.html](http://www.songho.ca/opengl/gl_projectionmatrix.html)。'
- en: In orthographic projection, all the parallel lines in the 3D space are still
    parallel in the 2D plane, except they have different lengths and orientations.
    More importantly, the size of the projected image of the same object is always
    the same, no matter how far away it is from the camera. However, this is not the
    way our eyes and most cameras capture images of the 3D world. Therefore, orthographic
    projection is mainly used in **Computer-Aided Design** (**CAD**) and other engineering
    applications, where the actual size of the components needs to be rendered correctly.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在正交投影中，3D空间中所有平行线在2D平面中仍然是平行的，只是长度和方向不同。更重要的是，同一对象的投影图像尺寸始终相同，无论它离摄像机有多远。然而，这并不是我们的眼睛和大多数摄像机捕捉3D世界图像的方式。因此，正交投影主要用于**计算机辅助设计**（**CAD**）和其他工程应用中，需要正确呈现组件的实际大小。
- en: '**Perspective projection** is a process that maps everything in a frustum (that
    is, a pyramid without its tip) to a standard cube, as shown in the preceding image.
    In perspective projection, objects that are closer to the camera look bigger than
    those far away from the camera. Therefore, parallel lines in the 3D space are
    not necessarily parallel in the 2D space. This is also how our eyes perceive the
    surrounding environment. Therefore, this type of projection gives us more realistic
    images and is often used for rendering visual effects in video games and movies.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**透视投影**是一种将截头体中的所有物体（即去掉顶部的金字塔）映射到标准立方体的过程，如上图所示。在透视投影中，离摄像机近的物体看起来比远离摄像机的物体大。因此，3D空间中的平行线在2D空间中不一定平行。这也是我们眼睛感知周围环境的方式。因此，这种投影方式能给我们更逼真的图像，常用于视频游戏和电影中的视觉效果渲染。'
- en: 'Orthographic and perspective projections are used together in some forms of
    CG software, such as Autodesk Maya, as shown in the following screenshots:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 正射投影和透视投影在一些计算机图形软件中是一起使用的，例如Autodesk Maya，如下图所示：
- en: '![](img/a36d37b6-e3d4-49ab-8ce4-5bad2a50d2e3.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a36d37b6-e3d4-49ab-8ce4-5bad2a50d2e3.png)'
- en: In the user interface of Autodesk Maya, orthographic projection is used to show
    the top, side, and front views (top left, bottom left, and bottom right), while
    perspective projection is used to preview the 3D models (top right). Image retrieved
    from https://knowledge.autodesk.com/support/maya/learn-explore/caas/simplecontent/content/maya-tutorials.html
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在Autodesk Maya的用户界面中，使用正射投影来显示顶部、侧面和正面视图（左上、左下和右下），而使用透视投影来预览3D模型（右上）。图片来自 https://knowledge.autodesk.com/support/maya/learn-explore/caas/simplecontent/content/maya-tutorials.html
- en: 'In this chapter, we will only take a closer look at perspective projection.
    In computer graphics, **homogeneous coordinates** are often used, which can conveniently
    represent infinite distance and turn translation, scaling, and rotation using
    simple matrix multiplication. For a set of homogeneous coordinates ![](img/9e97bf11-0927-4500-9838-1860b8b9342a.png),
    the corresponding Cartesian counterpart would be ![](img/2e2861a5-90fc-49d2-9116-a945f3f63e79.png).
    The mapping from the frustum in the 3D space to the ![](img/c78ba0be-6e60-4e82-abc2-07a553beff6e.png) cube
    is defined by the **projection matrix**:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将重点讲解透视投影。在计算机图形学中，经常使用**齐次坐标**，它可以方便地表示无限距离，并通过简单的矩阵乘法实现平移、缩放和旋转。对于一组齐次坐标 ![](img/9e97bf11-0927-4500-9838-1860b8b9342a.png)，其对应的笛卡尔坐标系为 ![](img/2e2861a5-90fc-49d2-9116-a945f3f63e79.png)。从3D空间的截头体到 ![](img/c78ba0be-6e60-4e82-abc2-07a553beff6e.png) 立方体的映射由**投影矩阵**定义：
- en: '![](img/f7bf133f-63c5-464a-9c04-6da213df7c16.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f7bf133f-63c5-464a-9c04-6da213df7c16.png)'
- en: In the projection matrix, ![](img/45548185-0989-4de4-8e79-e7a5520f9a91.png) is
    the near clipping plane and ![](img/709f4f14-d677-4e86-9199-5c129d46016f.png) is
    the far clipping plane. Also, ![](img/80102840-6f09-4b4f-baa4-3a4bf67d5474.png), ![](img/c4629faf-3a38-45e5-b2d2-62f0a0ae3d05.png), ![](img/d2b7a153-039a-495d-bff3-2544fabf45c4.png), and ![](img/7b1108b0-ae34-4483-9fba-292c452d7828.png) denote
    the top, bottom, left, and right boundaries of the near clipping plane, respectively.
    The multiplication between the projection matrix and the homogeneous coordinates
    gives us the corresponding coordinates where the projected points should be. If
    you are interested in the derivation of the projection matrix, feel free to check
    out the following article: [http://www.songho.ca/opengl/gl_projectionmatrix.html](http://www.songho.ca/opengl/gl_projectionmatrix.html).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在投影矩阵中， ![](img/45548185-0989-4de4-8e79-e7a5520f9a91.png) 是近裁剪平面， ![](img/709f4f14-d677-4e86-9199-5c129d46016f.png) 是远裁剪平面。此外， ![](img/80102840-6f09-4b4f-baa4-3a4bf67d5474.png)、 ![](img/c4629faf-3a38-45e5-b2d2-62f0a0ae3d05.png)、 ![](img/d2b7a153-039a-495d-bff3-2544fabf45c4.png)
    和 ![](img/7b1108b0-ae34-4483-9fba-292c452d7828.png) 分别表示近裁剪平面的顶部、底部、左侧和右侧边界。投影矩阵与齐次坐标的相乘给我们提供了投影点应该落在的对应坐标。如果你对投影矩阵的推导感兴趣，可以参考以下文章：[http://www.songho.ca/opengl/gl_projectionmatrix.html](http://www.songho.ca/opengl/gl_projectionmatrix.html)。
- en: Designing GANs for 3D data synthesis
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计用于3D数据合成的生成对抗网络（GAN）
- en: 3D-GAN, which was proposed by Jiajun Wu, Chengkai Zhang, and Tianfan Xue, et.
    al. in their paper, *Learning a Probabilistic Latent Space of Object Shapes via
    3D Generative-Adversarial Modeling*, was designed to generate a 3D point cloud
    of certain types of objects. The design and training process of 3D-GAN is very
    similar to the vanilla GAN, except that the input and output tensors of the 3D-GAN
    are five-dimensional, rather than four-dimensional.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 3D-GAN是由Jiajun Wu、Chengkai Zhang、Tianfan Xue等人在他们的论文*Learning a Probabilistic
    Latent Space of Object Shapes via 3D Generative-Adversarial Modeling*中提出的，旨在生成特定类型物体的3D点云。3D-GAN的设计和训练过程与传统的GAN非常相似，不同之处在于3D-GAN的输入和输出张量是五维的，而不是四维的。
- en: Generators and discriminators in 3D-GAN
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3D-GAN中的生成器和判别器
- en: 'The architecture of the generator network of 3D-GAN is as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 3D-GAN的生成器网络架构如下：
- en: '![](img/003fb212-8b6a-4876-9672-d89b03434961.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/003fb212-8b6a-4876-9672-d89b03434961.png)'
- en: Architecture of the generator network in 3D-GAN
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 3D-GAN中生成器网络的架构
- en: The generator network consists of five transposed convolution layers (`nn.ConvTranspose3d`),
    in which the first four layers are followed by the Batch Normalization layer (`nn.BatchNorm3d`)
    and ReLU activation function, and the last layer is followed by a Sigmoid activation
    function. The kernel size, stride size, and padding size are set to 4, 2 and 1
    in all the transposed convolution layers, respectively. Here, the input latent
    vector can be gradually expanded to a ![](img/4d4d6b88-58ab-4d09-b2aa-5c0e597be316.png) cube,
    which can be considered as a 1-channel 3D "image". In this 3D image, the "pixel"
    value is actually the possibility of whether a point exists at these ![](img/b444fc1b-f235-492c-930e-2e383c030969.png) grid
    locations. Normally, we reserve all the points with values higher than 0.5 to
    form the final point cloud.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器网络由五个反卷积层（`nn.ConvTranspose3d`）组成，其中前四个层后跟Batch Normalization层（`nn.BatchNorm3d`）和ReLU激活函数，最后一层后跟Sigmoid激活函数。在所有反卷积层中，卷积核大小、步长和填充大小分别设置为4、2和1。在这里，输入的潜在向量可以逐步扩展到一个！[](img/4d4d6b88-58ab-4d09-b2aa-5c0e597be316.png)立方体，这可以视为一个1通道的3D“图像”。在这个3D图像中，“像素”值实际上表示某个点在这些！[](img/b444fc1b-f235-492c-930e-2e383c030969.png)网格位置上是否存在的可能性。通常，我们会保留所有值高于0.5的点来形成最终的点云。
- en: In our case, the "pixels" in the 3D image are actually called **voxels**
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，3D图像中的“像素”实际上被称为**体素**。
- en: 'since the points in our point cloud are located at grid points in the ![](img/b444fc1b-f235-492c-930e-2e383c030969.png) cube.
    There are four attributes in a voxel: the x, y, and z coordinates and whether
    the voxel exists at (x, y, z). Unlike in 2D image synthesizing tasks, such as
    MNIST, where pixels with values between 0 and 1 (or between 0 and 255, if you
    prefer) are allowed (for example, at the edge of the digits), the existence of
    the voxel is a binary decision. Therefore, the tensor of our point cloud is, in
    fact, a sparse with many zeros and a few ones.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们点云中的点位于！[](img/b444fc1b-f235-492c-930e-2e383c030969.png)立方体的网格点上。每个体素有四个属性：x、y和z坐标，以及该体素是否存在于（x,
    y, z）位置。与2D图像合成任务（如MNIST）不同，在这些任务中像素的值可以在0到1之间（或者，如果你喜欢的话，也可以在0到255之间，例如数字边缘的像素），体素的存在是一个二元决策。因此，我们的点云张量实际上是稀疏的，包含许多零和少数的1。
- en: In this section, we will provide the full source code for 3D-GAN. The code files
    have been organized in the same way as they were in the previous chapters. The
    networks have been defined in a `model_3dgan.py` file (be sure to avoid starting
    your module name with numbers).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将提供3D-GAN的完整源代码。代码文件已按照与前几章相同的方式进行组织。网络已在`model_3dgan.py`文件中定义（请确保模块名称不要以数字开头）。
- en: 'The following code is the definition of `Generator`:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码是`Generator`的定义：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The architecture of the discriminator network of 3D-GAN is as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 3D-GAN的判别器网络架构如下：
- en: '![](img/645b8202-29c0-4f0d-b943-48d94a641af1.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/645b8202-29c0-4f0d-b943-48d94a641af1.png)'
- en: Architecture of the discriminator network in 3D-GAN
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 3D-GAN中判别器网络的架构
- en: The discriminator network consists of five convolution layers (`nn.Conv3d`),
    in which the first four layers are followed by a Batch Normalization layer and
    a Leaky-ReLU (`nn.LeakyReLU`) activation function, and the last layer is followed
    by a Sigmoid activation function. The kernel size, stride size, and padding size
    are set to 4, 2 and 1 in all the convolution layers, respectively. The ![](img/4d4d6b88-58ab-4d09-b2aa-5c0e597be316.png) cube
    of the 3D point cloud is mapped by the discriminator network to a single value,
    which specifies whether the confidence of the input object is authentic.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 判别网络由五个卷积层（`nn.Conv3d`）组成，其中前四个卷积层后跟一个批归一化层和一个 Leaky-ReLU（`nn.LeakyReLU`）激活函数，最后一层后跟一个
    Sigmoid 激活函数。所有卷积层的卷积核大小、步幅和填充大小分别设置为 4、2 和 1。判别网络将 3D 点云的 ![](img/4d4d6b88-58ab-4d09-b2aa-5c0e597be316.png)
    立方体映射为一个单一的值，用于指定输入对象的可信度是否为真实。
- en: Imagine what would happen if the dimension of the point cloud was set to ![](img/3b032dab-8b8e-4f7c-a7b6-25c798b10c2f.png). Can
    you create colorized 3D point clouds, such as fire, smoke, or clouds? Feel free
    to find or even create your own dataset and try this out!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果点云的维度设置为 ![](img/3b032dab-8b8e-4f7c-a7b6-25c798b10c2f.png) 会发生什么。你能创建带颜色的
    3D 点云，比如火焰、烟雾或云彩吗？可以随意查找或甚至创建你自己的数据集来试试这个！
- en: 'The following code is the definition of `Discriminator` (this can also be found
    in the `model_3dgan.py` file):'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码是 `Discriminator` 的定义（也可以在 `model_3dgan.py` 文件中找到）：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Training 3D-GAN
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练 3D-GAN
- en: 'The training process for 3D-GAN is similar to the process for the vanilla GAN.
    This can be seen in the following diagram:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 3D-GAN 的训练过程类似于传统 GAN 的训练过程。从以下图示可以看出：
- en: '![](img/ac7d1541-e561-4162-9665-ff7d2d8e8cbb.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ac7d1541-e561-4162-9665-ff7d2d8e8cbb.png)'
- en: The training process of 3D-GAN. Here, x* denotes real data, x denotes fake data,
    and z denotes the latent vector. The networks whose parameters are updated are
    marked with red boundaries.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 3D-GAN 的训练过程。在这里，x* 表示真实数据，x 表示伪造数据，z 表示潜在向量。参数会被更新的网络用红色边界标出。
- en: First, the discriminator network is trained to recognize the real 3D point cloud
    as true data and the synthesized point cloud that's generated by the generator
    network as fake data. BCE loss (`nn.BCELoss`) is used as the loss function for
    the discriminator network. Then, the generator network is trained by forcing the
    discriminator to recognize the synthesized 3D point cloud as true data so that
    it can learn to get better at fooling the discriminator in the future. BCE loss
    is used for training the generator network.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，训练判别网络来将真实的 3D 点云识别为真实数据，将由生成器网络生成的合成点云识别为伪造数据。判别网络使用 BCE 损失（`nn.BCELoss`）作为损失函数。然后，通过强迫判别器将合成的
    3D 点云识别为真实数据来训练生成器网络，这样生成器就能学会在未来更好地欺骗判别器。训练生成器网络时也使用 BCE 损失。
- en: 'The following is part of the source code for 3D-GAN training. Create a `build_gan.py`
    file and paste the following code into this file. Some of the training tricks
    have been borrowed from [https://github.com/rimchang/3DGAN-Pytorch](https://github.com/rimchang/3DGAN-Pytorch),
    which we will discuss later:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 3D-GAN 训练的部分源代码。创建一个 `build_gan.py` 文件并将以下代码粘贴到该文件中。部分训练技巧来自 [https://github.com/rimchang/3DGAN-Pytorch](https://github.com/rimchang/3DGAN-Pytorch)，我们稍后会进行讨论：
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You may have noticed that `real_label` and `fake_label` aren't set to 1 and
    0 like they usually are. Instead, randomly initialized labels (`uniform_(0.7,
    1.2)` and `uniform_(0, 0.3)`) are used. This technique is very similar to **soft
    targets**, which use the softmax output of a larger network as labels (instead
    of "hard" 0 or 1 labels) to train a smaller, yet identical, network in terms of
    input-output mappings (which is called **Knowledge Distillation**). This trick
    generates a smoother loss function over time since it introduces an assumption
    that the labels are random variables. You can always initialize `real_label` randomly
    and let `fake_label` be equal to `1-real_label`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到 `real_label` 和 `fake_label` 并不像通常那样设置为 1 和 0。相反，使用了随机初始化的标签（`uniform_(0.7,
    1.2)` 和 `uniform_(0, 0.3)`）。这种技术与 **软标签** 非常相似，它使用更大网络的 softmax 输出作为标签（而不是“硬”标签
    0 或 1），来训练一个较小但输入输出映射相同的网络（这被称为 **知识蒸馏**）。这个技巧随着时间的推移生成了一个更加平滑的损失函数，因为它假设标签是随机变量。你总是可以随机初始化
    `real_label`，并让 `fake_label` 等于 `1-real_label`。
- en: We already know that the desired output tensor is sparse and that it should
    be very easy to fully train the discriminator. Actually, the discriminator will
    overfit long before the generator is trained properly. Therefore, we only train
    the discriminator when its training accuracy is not higher than `d_loss_thresh`.
    Note that learning rate decay is used to optimize the generator.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道期望的输出张量是稀疏的，并且完全训练判别器应该是非常简单的。实际上，判别器会在生成器训练充分之前就过拟合。因此，我们只在判别器的训练准确率不超过`d_loss_thresh`时训练判别器。注意，学习率衰减用于优化生成器。
- en: 'In the preceding code, we visualized and exported the generated point cloud
    for every `export_interval` epochs. The code for rendering the point cloud is
    as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的代码中，我们可视化并导出了每隔`export_interval`个训练周期生成的点云。渲染点云的代码如下：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The next step is to prepare the training dataset for 3D-GAN. You can download
    the point clouds of 40 different types of objects from [http://3dshapenets.cs.princeton.edu/3DShapeNetsCode.zip](http://3dshapenets.cs.princeton.edu/3DShapeNetsCode.zip).
    After downloading and extracting the `zip` file, move the `volumetric_data` folder
    to any location you like (for example, `/media/john/DataAsgard/3d_models/volumetric_data`)
    and choose a category for model training.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的步骤是为3D-GAN准备训练数据集。你可以从[http://3dshapenets.cs.princeton.edu/3DShapeNetsCode.zip](http://3dshapenets.cs.princeton.edu/3DShapeNetsCode.zip)下载40种不同类型物体的点云数据。下载并解压`zip`文件后，将`volumetric_data`文件夹移动到你喜欢的位置（例如，`/media/john/DataAsgard/3d_models/volumetric_data`），并选择一个类别进行模型训练。
- en: 'The code for loading the training point cloud files is as follows (create a
    `datasets.py` file and paste the following code into it):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 用于加载训练点云文件的代码如下（创建一个`datasets.py`文件，并将以下代码粘贴到其中）：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, here is the code for the `main.py` file, which initializes and trains
    3D-GAN:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这里是`main.py`文件的代码，用于初始化和训练3D-GAN：
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We used code similar to this to create the command-line parser back in [Chapter
    5](685b2621-6dbb-4157-a258-f3cf2825728c.xhtml), *Generating Images Based on Label
    Information*. We''ll use the same idea here and add a few options into the mix:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第5章](685b2621-6dbb-4157-a258-f3cf2825728c.xhtml)中使用了类似的代码来创建命令行解析器，*基于标签信息生成图像*。我们将在这里使用相同的思路，并添加一些选项：
- en: '[PRE6]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, we can run the program by using the following command line. Be sure to
    provide your proper data directory:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用以下命令行运行程序。务必提供正确的数据目录：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here, we used the chair category example. It takes about 4 hours to finish 1,000
    epochs of training and costs about 1,023 MB GPU memory on a single NVIDIA GTX
    1080Ti graphics card. Note that, even though our implementation is heavily based
    on [https://github.com/rimchang/3DGAN-Pytorch](https://github.com/rimchang/3DGAN-Pytorch),
    the original code costs about 14 hours and 1,499 MB GPU memory to complete the
    same task.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了椅子类别作为示例。完成1,000个训练周期大约需要4小时，并且在单个NVIDIA GTX 1080Ti显卡上大约消耗1,023 MB的GPU内存。注意，尽管我们的实现重度依赖于[https://github.com/rimchang/3DGAN-Pytorch](https://github.com/rimchang/3DGAN-Pytorch)，但原始代码完成相同任务的时间为14小时，GPU内存消耗为1,499
    MB。
- en: 'The following are some of the 3D chair models that were generated by 3D-GAN.
    As we can see, despite a few outliers and the misplacement of voxels, the models
    look convincing in general. You can also check out the 3D-GAN website that was
    created by the authors of the paper, where an interactive showcase of generated
    chairs has been provided: [https://meetshah1995.github.io/gan/deep-learning/tensorflow/visdom/2017/04/01/3d-generative-adverserial-networks-for-volume-classification-and-generation.html](https://meetshah1995.github.io/gan/deep-learning/tensorflow/visdom/2017/04/01/3d-generative-adverserial-networks-for-volume-classification-and-generation.html):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些由3D-GAN生成的3D椅子模型。如我们所见，尽管存在一些异常值和体素位置错误，整体模型看起来还是相当逼真的。你还可以访问论文作者创建的3D-GAN官网，查看其中提供的生成椅子的互动展示：[https://meetshah1995.github.io/gan/deep-learning/tensorflow/visdom/2017/04/01/3d-generative-adverserial-networks-for-volume-classification-and-generation.html](https://meetshah1995.github.io/gan/deep-learning/tensorflow/visdom/2017/04/01/3d-generative-adverserial-networks-for-volume-classification-and-generation.html)：
- en: '![](img/48b45e16-c9ea-4238-bbe8-6a4fe321ce7d.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/48b45e16-c9ea-4238-bbe8-6a4fe321ce7d.png)'
- en: Chair models generated by 3D-GAN
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 3D-GAN生成的椅子模型
- en: Feel free to select a different object category or even give other datasets
    a try. Here is a list of point cloud datasets: [http://yulanguo.me/dataset.html](http://yulanguo.me/dataset.html).
    Here is a list of papers on 3D point cloud from the past years (at the time of
    writing): [https://github.com/Yochengliu/awesome-point-cloud-analysis](https://github.com/Yochengliu/awesome-point-cloud-analysis).
    I hope you can discover new applications with GANs and 3D point clouds!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 随意选择不同的对象类别，甚至尝试其他数据集。这里是一个点云数据集的列表：[http://yulanguo.me/dataset.html](http://yulanguo.me/dataset.html)。这里是过去几年关于3D点云的论文列表（截至撰写时）：[https://github.com/Yochengliu/awesome-point-cloud-analysis](https://github.com/Yochengliu/awesome-point-cloud-analysis)。希望你能用GAN和3D点云发现新的应用！
- en: Summary
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we learned about the fundamental concepts of computer graphics
    and how to train 3D-GAN to generate 3D objects.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了计算机图形学的基本概念，以及如何训练3D-GAN生成3D对象。
- en: In the next chapter, we will take a look back at all the useful tricks we have
    used in various GAN models and introduce more practical techniques that will assist
    you with model design and training GANs in the future.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将回顾我们在各种GAN模型中使用过的所有有用技巧，并介绍更多实用的技术，这些技术将帮助你未来设计和训练GAN模型。
- en: Further reading
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: Ahn S H. (2019). *OpenGL Projection Matrix*. Retrieved from [http://www.songho.ca/opengl/gl_projectionmatrix.html](http://www.songho.ca/opengl/gl_projectionmatrix.html).
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ahn S H. (2019). OpenGL投影矩阵。来源：[http://www.songho.ca/opengl/gl_projectionmatrix.html](http://www.songho.ca/opengl/gl_projectionmatrix.html)。
- en: Wu J, Zhang C, Xue T. (2016). *Learning a Probabilistic Latent Space of Object
    Shapes via 3D Generative-Adversarial Modeling*. NIPS.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Wu J, Zhang C, Xue T. (2016). 通过3D生成对抗建模学习对象形状的概率潜在空间。NIPS.
