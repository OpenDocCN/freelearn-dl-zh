- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Modeling the Human Body in 3D
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3D建模人体
- en: In the previous chapters, we explored ideas for modeling a 3D scene and the
    objects in them. Most of the objects we modeled were static and unchanging, but
    many applications of computer vision in real life center around humans in their
    natural habitat. We want to model their interactions with other humans and objects
    in the scene.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们探索了3D场景及其物体的建模方法。我们建模的大多数物体都是静态且不变的，但现实生活中，计算机视觉的许多应用都集中在人类及其自然环境中。我们希望建模人类与其他人和物体的互动。
- en: There are several applications for this. Snapchat filters, FaceRig, virtual
    try-on, and motion capture technology in Hollywood all benefit from accurate 3D
    body modeling. Consider, for example, an automated checkout technology. Here,
    a retail store is equipped with several depth-sensing cameras. They might want
    to detect whenever a person retrieves an object and modify their checkout basket
    accordingly. Such an application and many more will require us to accurately model
    the human body.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这一技术有多个应用。例如，Snapchat滤镜、FaceRig、虚拟试衣和好莱坞的动作捕捉技术都受益于精确的3D人体建模。例如，考虑一下自动结账技术。在这里，零售店配备了多个深度感应摄像头。它们可能希望检测到顾客拿起物品时，并相应地修改他们的结账篮。这类应用和更多的应用都需要我们精确建模人体。
- en: 'Human pose estimation is a cornerstone problem of human body modeling. Such
    a model can predict the location of joints such as shoulders, hips, and elbows
    to create a skeleton of the person in an image. They are then used for several
    downstream applications such as action recognition and human-object interaction.
    However, modeling a human body as a set of joints has its limitations:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 人体姿势估计是人体建模的一个核心问题。这样的模型可以预测关节的位置，例如肩膀、臀部和肘部，从而创建图像中人的骨架。然后，这些数据可用于多个下游应用，如动作识别和人机交互。然而，将人体建模为一组关节也有其局限性：
- en: Human joints are not visible and never interact with the physical world. So,
    we cannot rely on them to accurately model human-object interactions.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人体关节是不可见的，且永远不会与物理世界互动。因此，我们不能仅依靠它们来准确建模人机交互。
- en: Joints do not model the topology, volume, and surface of the body. For certain
    applications, such as modeling how clothing fits, joints alone are not useful.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关节并不能建模人体的拓扑结构、体积和表面。对于某些应用，如模拟衣物如何贴合，单纯的关节建模是无用的。
- en: 'We can come to an agreement that human pose models are functional for some
    applications but certainly not realistic. How can we realistically model the human
    body? Will that address these limitations? What other applications can this unlock?
    We answer these questions in this chapter. Concretely, we will cover the following
    topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以达成共识：人体姿势模型对某些应用是有效的，但绝对不够真实。我们如何才能更真实地建模人体？这是否能解决这些局限性？这将开启哪些新的应用？我们将在本章回答这些问题。具体来说，我们将涵盖以下主题：
- en: Formulating the 3D modeling problem
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制定3D建模问题
- en: Understanding the Linear Blend Skinning technique
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解线性混合蒙皮（Linear Blend Skinning）技术
- en: Understanding the SMPL model
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解SMPL模型
- en: Using the SMPL model
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SMPL模型
- en: Estimating 3D human pose and shape using SMPLify
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用SMPLify估计3D人体姿势与形状
- en: Exploring SMPLify
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索SMPLify
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The computation requirements for the code in this chapter are pretty low. However,
    running this in a Linux environment is recommended since it has better support
    for certain libraries. However, it is not impossible to run this in other environments.
    In the coding sections, we describe in detail how to set up the environment to
    successfully run the code. We will need the following technical requirements for
    this chapter:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本章代码的计算需求相对较低。然而，建议在Linux环境中运行，因为它对某些库有更好的支持。但在其他环境中运行也是可行的。在代码部分，我们将详细描述如何设置环境，以便成功运行代码。本章需要以下技术要求：
- en: Python 2.7
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 2.7
- en: Libraries such as opendr, matplotlib, opencv, and numpy.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 库：如opendr、matplotlib、opencv和numpy。
- en: The code snippets for this chapter can be found at [https://github.com/PacktPublishing/3D-Deep-Learning-with-Python](https://github.com/PacktPublishing/3D-Deep-Learning-with-Python).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码片段可以在[https://github.com/PacktPublishing/3D-Deep-Learning-with-Python](https://github.com/PacktPublishing/3D-Deep-Learning-with-Python)找到。
- en: Formulating the 3D modeling problem
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 制定3D建模问题
- en: '*“All models are wrong, but some are useful”* is a popular aphorism in statistics.
    It suggests that it is often hard to mathematically model all the tiny details
    of a problem. A model will always be an approximation of reality, but some models
    are more accurate and, therefore, more useful than others.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '*“所有模型都是错误的，但有些模型是有用的”* 这句名言在统计学中非常流行。它表明，通常很难精确地数学化问题中的所有细节。一个模型始终是对现实的近似，但有些模型比其他模型更准确，因此也更有用。'
- en: 'In the field of machine learning, modeling a problem generally involves the
    following two components:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习领域，建模一个问题通常包括以下两个组件：
- en: Mathematically formulating the problem
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数学化问题表述
- en: Building algorithms to solve that problem under the constraints and boundaries
    of that formulation
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在该表述的约束和边界下，构建解决问题的算法
- en: Good algorithms used on badly formulated problems often result in sub-optimal
    models. However, less powerful algorithms applied to a well-formulated model can
    sometimes result in great solutions. This insight is especially true for building
    3D human body models.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理不够明确的问题时，即使使用优秀的算法，通常也会得到次优的模型。然而，将较弱的算法应用于一个合理表述的模型，有时却能产生很好的解决方案。这一见解对于构建3D人体模型尤其适用。
- en: The goal of this modeling problem is to create realistic animated human bodies.
    More importantly, this should represent realistic body shapes and must deform
    naturally according to changes in body pose and capture soft tissue motions. Modeling
    the human body in 3D is a hard challenge. The human body has a mass of bones,
    organs, skin, muscles, and water and they interact with each other in complex
    ways. To exactly model the human body, we need to model the behavior of all these
    individual components and their interactions with each other. This is a hard challenge,
    and for some practical applications, this level of exactness is unnecessary. In
    this chapter, we will model the human body’s surface and shape in 3D as a proxy
    for modeling the entire human body. We do not need the model to be exact; we just
    need it to have a realistic external appearance. This makes the problem more approachable.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这个建模问题的目标是创建逼真的动画人体。更重要的是，这些模型应该能够真实地表现人体形状，并且必须根据人体姿势变化自然变形，同时捕捉软组织的运动。3D人体建模是一个艰巨的挑战。人体由大量的骨骼、器官、皮肤、肌肉和水分组成，它们之间以复杂的方式相互作用。为了精确地建模人体，我们需要建模所有这些个体组件的行为及它们之间的相互作用。这是一个艰难的挑战，对于一些实际应用来说，这种精确度并非必须。在本章中，我们将以建模人体表面和形状的方式，作为建模整个人体的代理。我们不需要模型完全精确；我们只需要它具有逼真的外观。这使得问题变得更加可处理。
- en: Defining a good representation
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义一个好的表示
- en: The goal is to represent the human body accurately with a low-dimensional representation.
    Joint models are low-dimensional representations (typically 17 to 25 points in
    3D space) but do not carry a lot of information about the shape and texture of
    the person. On another end, we can consider the voxel grid representation. This
    can model the 3D body shape and texture, but it is extremely highly dimensional
    and does not naturally lend itself to modeling body dynamics due to pose changes.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是用低维表示准确地描述人体。关节模型是低维表示（通常在3D空间中包含17到25个点），但它们并不包含很多关于人体形状和纹理的信息。另一方面，我们可以考虑体素网格表示。它可以建模3D人体的形状和纹理，但其维度极高，并且由于姿势变化，它并不自然适用于建模人体动态。
- en: Therefore, we need a representation that can jointly represent body joints and
    surfaces, which contains information about body volume. There are several candidate
    representations for surfaces; one such representation is a mesh of vertices. The
    **Skinned Multi-Person Linear** (**SMPL**) model uses this representation. Once
    specified, this mesh of vertices will describe the 3D shape of a human body.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们需要一种能够联合表示身体关节和表面的表示方法，包含有关身体体积的信息。有几种候选表示方法可以用于表示表面；其中一种表示方法是顶点网格。**Skinned
    Multi-Person Linear**（**SMPL**）模型就是使用这种表示方法。一旦指定，这个顶点网格就能描述人体的3D形状。
- en: Because there is a lot of history to this problem, we will find that many artists
    in the character animation industry have worked on building good body meshes.
    The SMPL model uses such expert insights to build a good initial template of a
    body mesh. This is an important first step because certain parts of the body have
    high-frequency variations (such as the face and hands). Such high-frequency variations
    need more densely packed points to describe them, but body parts with lower frequency
    variations (such as thighs) need less dense points to accurately describe them.
    Such a hand-crafted initial mesh will help bring down the dimensionality of the
    problem while keeping the necessary information to accurately model it. This mesh
    in the SMPL model is gender-neutral, but you can build variations for men and
    women separately.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个问题已有很多历史背景，我们会发现许多角色动画领域的艺术家都曾致力于构建良好的人体网格。SMPL 模型运用了这些专家的见解来构建人体网格的良好初始模板。这是一个重要的第一步，因为人体的某些部分存在高频变化（例如面部和手部）。这些高频变化需要更多密集的点来描述，而频率较低的部位（如大腿）则只需要较少的点来准确描述。这样的手工制作初始网格有助于降低问题的维度，同时保持准确建模所需的信息。SMPL
    模型中的这个网格是性别中立的，但你可以为男性和女性分别构建不同的变体。
- en: '![Figure 8.1 – The SMPL model template mesh in the resting pose ](img/B18217_08_01.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.1 – SMPL 模型静止姿势下的模板网格](img/B18217_08_01.jpg)'
- en: Figure 8.1 – The SMPL model template mesh in the resting pose
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 – SMPL 模型静止姿势下的模板网格
- en: More concretely, the initial template mesh consists of 6,890 points in 3D space
    to represent the human body surface. When this is vectorized, this template mesh
    has a vector length of 6,890 x 3 = 20,670\. Any human body can be obtained by
    distorting this template mesh vector to fit the body surface.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体来说，初始模板网格由 6,890 个三维空间中的点组成，用于表示人体表面。当该网格进行矢量化时，模板网格的矢量长度为 6,890 x 3 = 20,670。任何人体都可以通过扭曲这个模板网格矢量来适应人体表面。
- en: It sounds like a remarkably simple concept on paper, but the number of configurations
    of a 20,670-dimensional vector is extremely high. The set of configurations that
    represents a real human body is an extremely tiny subset of all the possibilities.
    The problem then becomes defining a method to obtain a plausible configuration
    that represents a real human body.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概念看起来在纸面上非常简单，但一个 20,670 维矢量的配置数量是极其庞大的。表示一个真实人体的配置集是所有可能性中的一个极其微小的子集。问题在于如何定义一种方法，以获得一个合理的配置来表示一个真实的人体。
- en: 'Before we understand how the SMPL model is designed, we need to learn about
    skinning models. In the next section, we will look at one of the simplest skinning
    techniques: the Linear Blend Skinning technique. This is important because the
    SMPL model is built on top of this technique.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们了解 SMPL 模型的设计之前，我们需要了解蒙皮模型。在接下来的部分，我们将探讨最简单的蒙皮技术之一：线性混合蒙皮技术。这一点很重要，因为 SMPL
    模型就是在这种技术基础上构建的。
- en: Understanding the Linear Blend Skinning technique
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解线性混合蒙皮技术
- en: Once we have a good representation of the 3D human body, we want to model how
    it looks in different poses. This is particularly important for character animation.
    The idea is that **skinning** involves enveloping an underlying skeleton with
    a skin (a surface) that conveys the appearance of the object being animated. This
    is a term used in the animation industry. Typically, this representation takes
    the form of vertices, which are then used to define connected polygons to form
    the surface.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们拥有了良好的三维人体表示，我们就希望模拟它在不同姿势下的表现。这对于角色动画尤其重要。**蒙皮**的概念是将一个基础骨架用一层皮肤（表面）包裹起来，这个皮肤展现了被动画化物体的外观。这是动画行业中的一个术语。通常，这种表示形式采用顶点的方式，然后利用这些顶点定义连接的多边形来形成表面。
- en: The Linear Blend Skinning model is used to take a skin in the resting pose and
    transform it into a skin in any arbitrary pose using a simple linear model. This
    is so efficient to render that many game engines support this technique, and it
    is also used to render game characters in real time.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 线性混合蒙皮模型（Linear Blend Skinning）用于将处于静止姿势的皮肤转换成任意姿势下的皮肤，使用的是一个简单的线性模型。由于其渲染效率高，许多游戏引擎支持这种技术，它也被用于实时渲染游戏角色。
- en: '![Figure 8.2 – Initial blend shape (left) and deformed mesh generated with
    blend skinning (right) ](img/B18217_08_02.jpg)![Figure 8.2 – Initial blend shape
    (left) and deformed mesh generated with blend skinning (right) ](img/B18217_08_03.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图8.2 – 初始混合形状（左）和使用混合蒙皮生成的变形网格（右）](img/B18217_08_02.jpg)![图8.2 – 初始混合形状（左）和使用混合蒙皮生成的变形网格（右）](img/B18217_08_03.jpg)'
- en: Figure 8.2 – Initial blend shape (left) and deformed mesh generated with blend
    skinning (right)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 初始混合形状（左）和使用混合蒙皮生成的变形网格（右）
- en: 'Let us now understand what this technique involves. This technique is a model
    that uses the following parameters:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来理解一下这个技术涉及的内容。该技术是一个使用以下参数的模型：
- en: A template mesh, *T,* with *N* vertices. In this case, N = 6,890.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个模板网格，*T*，具有*N*个顶点。在这个例子中，N = 6,890。
- en: We have the *K* joint locations represented by the vector *J*. These joints
    correspond to joints in the human body (such as shoulders, wrists, and ankles).
    There are 23 of these joints (K = 23).
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们有*K*个关节位置，由向量*J*表示。这些关节对应人体中的关节（如肩膀、手腕和脚踝）。共有23个这样的关节（K = 23）。
- en: Blend weights, *W*. This is typically a matrix of size *N* x *K* that captures
    the relationship between the *N* surface vertices and the *K* joints of the body.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合权重，*W*。这通常是一个*N* x *K*大小的矩阵，捕捉*N*个表面顶点与*K*个身体关节之间的关系。
- en: The pose parameters, Ɵ. These are the rotation parameters for each of the K
    joints. There are 3K of these parameters. In this case, we have 72 of them. 69
    of these parameters correspond to 23 joints and 3 correspond to the overall body
    rotation.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 姿势参数，Ɵ。这些是每个K个关节的旋转参数。总共有3K个这样的参数。在这个例子中，我们有72个参数。69个参数对应23个关节，3个参数对应整个身体的旋转。
- en: 'The skinning function takes the resting pose mesh, the joint locations, the
    blend weights, and the pose parameters as input and produces the output vertices:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 蒙皮函数将静止姿势网格、关节位置、混合权重和姿势参数作为输入，并生成输出顶点：
- en: '![](img/B18217_08_Formula.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18217_08_Formula.png)'
- en: 'In Linear Blend Skinning, the function takes the form of a simple linear function
    of the transformed template vertices as described in the following equation:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性混合蒙皮中，函数以简单的线性形式表示变换后的模板顶点，如下式所示：
- en: '![](img/Formula_08_002.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_08_002.png)'
- en: 'The meaning of these terms is the following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这些术语的含义如下：
- en: '*t_i* represents the vertices in the original mesh in the resting pose.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*t_i*表示处于静止姿势下原始网格中的顶点。'
- en: '*G*(Ɵ, J) is the matrix that transforms the joint k from the resting pose to
    the target pose.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*G*(Ɵ, J)是将关节k从静止姿势变换到目标姿势的矩阵。'
- en: '*w_k, i* are elements of the blend weights, *W*. They represent the amount
    of influence the joint k has on the vertex i.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w_k, i*是混合权重*W*的元素。它们表示关节k对顶点i的影响程度。'
- en: While this is an easy-to-use linear model and is very well used in the animation
    industry, it does not explicitly preserve volume. Therefore, transformations can
    look unnatural.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这是一个易于使用的线性模型，并且在动画行业中得到了广泛应用，但它并没有明确保留体积。因此，变换可能看起来不自然。
- en: In order to fix this problem, artists tweak the template mesh so that when the
    skinning model is applied, the outcome looks natural and realistic. Such linear
    deformations applied to the template mesh to obtain realistic-looking transformed
    mesh are called blend shapes. These blend shapes are artist-designed for all of
    the different poses the animated character can have. This is a very time-consuming
    process.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，艺术家调整模板网格，以便在应用蒙皮模型时，最终效果看起来自然且逼真。通过对模板网格应用线性变形以获得逼真外观的变形网格，这些被称为混合形状。这些混合形状是艺术家根据动画角色可以有的不同姿势设计的。这是一个非常耗时的过程。
- en: As we will see later, the SMPL model automatically calculates the blend shapes
    before applying the skinning model to them. In the next section, you will learn
    about how the SMPL model creates such pose-dependent blend shapes and how data
    is used to guide it.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们稍后将看到的，SMPL模型在应用蒙皮模型之前，会自动计算混合形状。在下一部分中，你将了解SMPL模型是如何创建这些依赖姿势的混合形状，以及数据是如何用来引导它的。
- en: Understanding the SMPL model
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解SMPL模型
- en: '**As the acronym of SMPL** suggests, this is a learned linear model trained
    on data from thousands of people. This model is built upon concepts from the Linear
    Blend Skinning model. It is an unsupervised and generative model that generates
    a 20,670-dimensional vector using the provided input parameters that we can control.
    This model calculates the blend shapes required to produce the correct deformations
    for varying input parameters. We need these input parameters to have the following
    important properties:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**正如 SMPL 的缩写**所暗示的那样，这是一个基于成千上万人的数据训练得到的线性学习模型。该模型建立在线性混合蒙皮模型的概念之上。它是一个无监督生成模型，通过提供的输入参数生成一个
    20,670 维的向量，而这些参数是我们可以控制的。该模型计算所需的混合形状，以产生正确的变形，适应不同的输入参数。我们需要这些输入参数具备以下重要特性：'
- en: It should correspond to a real tangible attribute of the human body.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它应该对应人体的真实可感知属性。
- en: The features must be low-dimensional in nature. This will enable us to easily
    control the generative process.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征必须本质上是低维的。这将使我们能够轻松地控制生成过程。
- en: The features must be disentangled and controllable in a predictable manner.
    That is, varying one parameter should not change the output characteristics attributed
    to other parameters.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特征必须是可解耦的，并以可预测的方式进行控制。也就是说，改变一个参数不应改变与其他参数相关的输出特征。
- en: 'Keeping these requirements in mind, the creators of the SMPL model came up
    with the two most important input attributes: some notion of body identity and
    body pose. The SMPL model decomposes the final 3D body mesh into an identity-based
    shape and pose-based shape (identity-based shape is also referred to as shape-based
    shape because the body shape is tied to a person’s identity). This gives the model
    the desired property of feature disentanglement. There are some other important
    factors such as breathing and soft tissue dynamics (when the body is in motion)
    that we do not explain in this chapter but are part of the SMPL model.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些要求，SMPL 模型的创建者提出了两个最重要的输入属性：身体身份的某种概念和身体姿势。SMPL 模型将最终的 3D 身体网格分解为基于身份的形状和基于姿势的形状（基于身份的形状也称为基于形状的形状，因为身体形状与一个人的身份紧密相关）。这使得该模型具有所需的特征解耦性质。还有一些其他重要因素，如呼吸和软组织动态（当身体处于运动状态时），我们在本章中不做详细解释，但它们是
    SMPL 模型的一部分。
- en: Most importantly, the SMPL model is an additive model of deformations. That
    is, the desired output body shape vector is obtained by adding deformations to
    the original template body vector. This additive property makes this model very
    intuitive to understand and optimize.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的是，SMPL 模型是一个加性变形模型。也就是说，所需的输出体形向量是通过将变形添加到原始模板体形向量中得到的。这种加性特性使得该模型非常直观，易于理解和优化。
- en: Defining the SMPL model
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义 SMPL 模型
- en: 'The SMPL model builds on top of the standard skinning models. It makes the
    following changes to it:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: SMPL 模型是在标准蒙皮模型的基础上构建的。它对其做出了以下改动：
- en: Rather than using the standard resting pose template, it uses a template mesh
    that is a function of the body shape and poses
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它不使用标准的静止姿势模板，而是使用一个依赖于身体形状和姿势的模板网格
- en: Joint locations are a function of the body shape
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关节位置是身体形状的函数
- en: 'The function specified by the SMPL model takes the following form:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: SMPL 模型指定的函数具有以下形式：
- en: '![](img/Formula_08_003.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_08_003.png)'
- en: 'The following is the meaning of the terms in the preceding definitions:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前述定义中各术语的含义：
- en: β is a vector representing the identity (also called the shape) of the body.
    We will later learn more about what it represents.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: β 是表示身份（也叫形状）向量。稍后我们将进一步了解它所表示的含义。
- en: Ɵ is the pose parameter corresponding to the target pose.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ɵ 是对应于目标姿势的姿势参数。
- en: W is the blend weight from the Linear Blend Skinning model.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: W 是来自线性混合蒙皮模型的混合权重。
- en: This function looks very similar to the Linear Blend Skinning model. In this
    function, the template mesh is a function of shape and pose parameters, and the
    joint’s location is a function of shape parameters. This is not the case in the
    Linear Blend Skinning model.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数看起来与线性混合蒙皮（Linear Blend Skinning）模型非常相似。在这个函数中，模板网格是形状和姿势参数的函数，关节位置是形状参数的函数。而在线性混合蒙皮模型中并非如此。
- en: Shape and pose-dependent template mesh
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 依赖形状和姿势的模板网格
- en: 'The redefined template mesh is an additive linear deformation of the standard
    template mesh:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 重新定义的模板网格是标准模板网格的加性线性变形：
- en: '![](img/Formula_08_004.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_08_004.png)'
- en: 'Here, we see the following:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们看到以下内容：
- en: '![](img/Image93832.png) is an additive deformation from the body shape parameters
    β. It is a learned deformation modeled as the first few principal components of
    the shape displacements. These principal components are obtained from the training
    data involving different people in the same resting pose.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/Image93832.png) 是来自身体形状参数 β 的加性形变。它是一个学习到的形变，建模为形状位移的前几个主成分。这些主成分是从训练数据中获得的，涉及到不同的人在相同静态姿势下的数据。'
- en: '![](img/Formula_08_006.png) is an additive pose deformation term. This is parametrized
    by Ɵ. This is also a linear function learned from a multi-pose dataset of people
    in different poses.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/Formula_08_006.png) 是一个加性姿势形变项。它由 Ɵ 参数化。这也是从一个包含不同姿势下人物的多姿势数据集中学习得到的线性函数。'
- en: Shape-dependent joints
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 形状依赖的关节
- en: 'Since joint locations depend on the body shape, they are redefined as a function
    of body shape. The SMPL model defines this in the following manner:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 由于关节位置依赖于身体形状，因此它们被重新定义为身体形状的函数。SMPL 模型将其定义如下：
- en: '![](img/Formula_08_007.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_08_007.png)'
- en: Here, ![](img/Formula_08_008.png) is the additive deformation from the body
    shape parameters β, and J is a matrix that transforms the rest template vertices
    to the rest template poses. The parameters of J are also learned from data.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![](img/Formula_08_008.png) 是来自身体形状参数 β 的加性形变，J 是一个矩阵，用于将静态模板顶点转换为静态模板姿势。J
    的参数也是从数据中学习得出的。
- en: Using the SMPL model
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 SMPL 模型
- en: Now that you have a high-level understanding of the SMPL model, we will look
    at how to use it to create 3D models of humans. In this section, we will start
    with a few basic functions; this will help you explore the SMPL model. We will
    load the SMPL model, and edit the shape and pose parameters to create a new 3D
    body. We will then save this as an object file and visualize it.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你对 SMPL 模型有了大致了解，我们将看看如何使用它来创建人类的 3D 模型。在这一部分中，我们将从几个基本函数开始，这将帮助你探索 SMPL 模型。我们将加载
    SMPL 模型，并编辑形状和姿势参数以创建一个新的 3D 身体。然后，我们将其保存为对象文件并进行可视化。
- en: 'This code was originally created by the authors of SMPL for `python2`. Therefore,
    we need to create a separate `python2` environment. The following are the instructions
    for this:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码最初是由 SMPL 的作者为 `python2` 创建的。因此，我们需要创建一个独立的 `python2` 环境。以下是创建环境的说明：
- en: '[PRE0]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This creates and activates the Python 2.7 conda environment and installs the
    required modules. Python 2.7 is being deprecated, so you might see warning messages
    when you try to use it. In order to create a 3D human body with random shape and
    pose parameters, run the following command.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这会创建并激活 Python 2.7 的 conda 环境，并安装所需的模块。由于 Python 2.7 已经被废弃，因此你在使用时可能会看到警告信息。为了创建一个具有随机形状和姿势参数的
    3D 人体，运行以下命令。
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This will pop up a window that shows the rendering of a human body in 3D. Our
    output will likely be different since `render_smpl.py` creates a human body with
    random pose and shape parameters.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这将弹出一个窗口，显示 3D 渲染的人体。我们的输出可能会有所不同，因为 `render_smpl.py` 会创建一个具有随机姿势和形状参数的人体。
- en: '![Figure 8.3 – An example rendering of the hello_smpl.obj created by explore_smpl.py
    ](img/B18217_08_04.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.3 – 由 explore_smpl.py 创建的 hello_smpl.obj 渲染示例](img/B18217_08_04.jpg)'
- en: Figure 8.3 – An example rendering of the hello_smpl.obj created by explore_smpl.py
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – 由 explore_smpl.py 创建的 hello_smpl.obj 渲染示例
- en: 'Now that we have run the code and obtained a visual output, let us explore
    what is happening in the `render_smpl.py` file:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经运行了代码并获得了可视化输出，让我们来看看 `render_smpl.py` 文件中的具体内容：
- en: 'Import all of the required modules:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必需的模块：
- en: '[PRE5]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Load the model weights of the basic SMPL model. Here, we load the neural body
    model:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载基础 SMPL 模型的模型权重。这里，我们加载了神经网络人体模型：
- en: '[PRE6]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we assign random pose and shape parameters. The following pose and shape
    parameters dictate how the 3D body mesh looks in the end:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们分配随机的姿势和形状参数。以下的姿势和形状参数决定了最终 3D 身体网格的外观：
- en: '[PRE7]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We now create a renderer and assign attributes to it, and we construct the light
    source. By default, we use the OpenDR renderer, but you can switch this to use
    the PyTorch3D renderer and light source. Before doing that, make sure to address
    any Python incompatibility issues.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们现在创建一个渲染器并为其分配属性，同时构建光源。默认情况下，我们使用 OpenDR 渲染器，但你可以切换为 PyTorch3D 渲染器和光源。在这样做之前，请确保解决任何
    Python 不兼容性问题。
- en: '[PRE8]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can now render the mesh and display it in an OpenCV window:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以渲染网格并在 OpenCV 窗口中显示它：
- en: '[PRE9]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We have now used the SMPL model to generate a random 3D human body. In reality,
    we might be interested in generating 3D shapes that are more controllable. We
    will look at how to do this in the next section.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经使用SMPL模型生成了一个随机的3D人体。实际上，我们可能更感兴趣的是生成更加可控的3D形状。我们将在下一节中讨论如何做到这一点。
- en: Estimating 3D human pose and shape using SMPLify
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SMPLify估计3D人体姿态和形状
- en: In the previous section, you explored the SMPL model and used it to generate
    a 3D human body with a random shape and pose. It is natural to wonder whether
    it is possible to use the SMPL model to fit a 3D human body onto a person in a
    2D image. This has multiple practical applications, such as understanding human
    actions or creating animations from 2D videos. This is indeed possible, and in
    this chapter, we are going to explore this idea in more detail.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你探索了SMPL模型，并用它生成了一个形状和姿势随机的3D人体。自然地，我们会想知道是否可以利用SMPL模型将3D人体拟合到二维图像中的一个人身上。这有多个实际应用，比如理解人体动作或从二维视频创建动画。事实上，这是可行的，在本章中，我们将更详细地探讨这一思路。
- en: Imagine that you are given a single RGB image of a person without any information
    about body pose, camera parameters, or shape parameters. Our goal is to deduce
    the 3D shape and pose from just this single image. Estimating the 3D shape from
    a 2D image is not always error-free. It is a challenging problem because of the
    complexity of the human body, articulation, occlusion, clothing, lighting, and
    the inherent ambiguity in inferring 3D from 2D (because multiple 3D poses can
    have the same 2D pose when projected). We also need an automatic way of estimating
    this without much manual intervention. It also needs to work on complex poses
    in natural images with a variety of backgrounds, lighting conditions, and camera
    parameters.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你得到了一张单独的RGB图像，图中有一个人，但没有任何关于身体姿态、相机参数或形状参数的信息。我们的目标是仅从这张图像推测出3D形状和姿态。从二维图像估计3D形状并非总是没有误差的。这是一个具有挑战性的问题，因为人体的复杂性、关节运动、遮挡、服装、光照，以及从二维推测三维本身存在固有的模糊性（因为多个3D姿态在投影时可能具有相同的2D姿态）。我们还需要一种自动估计方法，尽量减少人工干预。它还需要在自然图像中，面对各种背景、光照条件和相机参数时，也能有效工作。
- en: One of the best methods of doing this was invented by researchers from the Max
    Planck Institute of Intelligent Systems (where the SMPL model was invented), Microsoft,
    the University of Maryland, and the University of Tübingen. This approach is called
    SMPLify. Let us explore this approach in more detail.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法是由来自马普智能系统研究所（SMPL模型的发明地）、微软、马里兰大学和图宾根大学的研究人员发明的。这个方法被称为SMPLify。让我们更详细地探讨这个方法。
- en: 'The SMPLify approach consists of the following two stages:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: SMPLify方法包括以下两个阶段：
- en: Automatically detect 2D joints using established pose detection models such
    as OpenPose or DeepCut. Any 2D joint detectors can be used in their place as long
    as they are predicting the same joints.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用现有的姿态检测模型（如OpenPose或DeepCut）自动检测二维关节。只要它们预测的是相同的关节，任何二维关节检测器都可以替代使用。
- en: Use the SMPL model to generate the 3D shape. Directly optimize the parameters
    of the SMPL model so that the model joints of the SMPL model project to the 2D
    joints predicted in the previous stage.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用SMPL模型生成3D形状。直接优化SMPL模型的参数，使得SMPL模型的关节在二维上与前一阶段预测的关节相匹配。
- en: We know that SMPL captures shapes from just the joints. With the SMPL model,
    we can therefore capture information about body shape just from the joints. In
    the SMPL model, the body shape parameters are characterized by β. They are the
    coefficients of the principal components in the PCA shape model. The pose is parametrized
    by the relative rotation and theta of the 23 joints in the kinematic tree. We
    need to fit these parameters, β and theta, so that we minimize an objective function.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道SMPL仅通过关节捕捉形状。因此，通过SMPL模型，我们可以仅通过关节获取关于人体形状的信息。在SMPL模型中，身体形状参数由β表示。它们是PCA形状模型中主成分的系数。姿态通过运动学树中23个关节的相对旋转和θ来参数化。我们需要拟合这些参数β和θ，以使目标函数最小化。
- en: Defining the optimization objective function
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义优化目标函数
- en: 'Any objective function must capture our intention to minimize some notion of
    error. The more accurate this error calculation is, the more accurate the output
    of the optimization step will be. We will first look at the entire objective function,
    then look at each of the individual components of that function and explain why
    each of them is necessary:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 任何目标函数必须捕捉我们最小化某种误差的意图。误差计算越准确，优化步骤的输出结果就会越准确。我们将首先查看整个目标函数，然后逐一分析该函数的各个组成部分，并解释它们为何必要：
- en: '![](img/Formula_08_009.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Formula_08_009.png)'
- en: 'We want to minimize this objective function by optimizing parameters *β* and
    Ɵ. It consists of four terms and corresponding coefficients, *λ*Ɵ, *λ*a, *λ*sp,
    and *λ*β, which are hyperparameters of the optimization process. The following
    is what each of the individual terms means:'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们希望通过优化参数*β*和Ɵ来最小化这个目标函数。它包含四个项和相应的系数，*λ*Ɵ、*λ*a、*λ*sp和*λ*β，它们是优化过程中的超参数。以下是每个单独项的含义：
- en: '![](img/Formula_08_010.png)is the joint-based term that penalizes the distance
    between the 2D projected joint of the SMPL model and the predicted joint location
    from the 2D joint detector (such as DeepCut or OpenPose). *w_i* is the confidence
    score of each of the joints provided by the 2D joint detection model. When a joint
    is occluded, the confidence score for that joint will be low. Naturally, we should
    not place a lot of importance on such occluded joints.'
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/Formula_08_010.png)是一个基于关节的项，用于惩罚SMPL模型的2D投影关节与2D关节检测器（如DeepCut或OpenPose）预测的关节位置之间的距离。*w_i*是由2D关节检测模型提供的每个关节的置信度分数。当一个关节被遮挡时，该关节的置信度分数会很低。自然地，我们不应过于重视这些被遮挡的关节。'
- en: '![](img/Formula_08_011.png)is the pose that penalizes large angles between
    joints. For example, it ensures that elbows and knees do not bend unnaturally.'
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/Formula_08_011.png)是一个惩罚关节之间大角度的姿势项。例如，它确保肘部和膝盖不会不自然地弯曲。'
- en: '![](img/Formula_08_012.png)is a Gaussian mixture model fit on natural poses
    obtained from a very large dataset. This dataset is called the CMU Graphics Lab
    Motion Capture Database, consisting of nearly one million data points. This data-driven
    term in the optimization function ensures that the pose parameters are close to
    what we observe in reality.'
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/Formula_08_012.png)是一个拟合自然姿势的高斯混合模型，这些姿势是从一个非常大的数据集中获取的。这个数据集被称为CMU图形实验室动作捕捉数据库，包含近一百万个数据点。这个数据驱动项确保优化函数中的姿势参数接近我们在现实中观察到的姿势。'
- en: '![](img/Formula_08_013.png) is the self-penetration error. When the authors
    optimized the objective function without this error term, they saw unnatural self-penetrations,
    such as elbows and hands twisted and penetrating through the stomach. This is
    physically impossible. However, after adding this error term, they found naturally
    qualitative results. This error term consists of body parts that are approximated
    as a set of spheres. They define incompatible spheres and penalize the intersection
    of these incompatible spheres.'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/Formula_08_013.png)是自相交误差。当作者在优化目标函数时没有这个误差项时，他们看到了不自然的自相交现象，比如肘部和手部扭曲并穿透腹部。这在物理上是不可能的。然而，添加了这个误差项后，他们发现得到了自然的定性结果。这个误差项由身体部位组成，这些部位被近似为一组球体。他们定义了不兼容的球体，并惩罚这些不兼容球体的交集。'
- en: '![](img/Formula_08_014.png)is the shape obtained from the SMPL model. Note
    here that the principal component matrix is part of the SMPL model, which was
    obtained by training on the SMPL training dataset.'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '![](img/Formula_08_014.png)是从SMPL模型中获得的形状。这里需要注意的是，主成分矩阵是SMPL模型的一部分，它是通过在SMPL训练数据集上进行训练获得的。'
- en: In summary, the objective function consists of five components that, together,
    ensure that the solution to this objective function is a set of pose and shape
    parameters (theta and beta) that ensure that the 2D join projection distances
    are minimized while simultaneously ensuring that there are no large joint angles,
    no unnatural self-penetrations, and that the pose and shape parameters adhere
    to a prior distribution we see in a large dataset consisting of natural body poses
    and shapes.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，目标函数由五个组成部分构成，它们共同确保该目标函数的解是一组姿势和形状参数（theta和beta），既保证了2D关节投影距离的最小化，同时又确保没有大角度的关节、没有不自然的自相交，并且姿势和形状参数遵循我们在由自然体态和形状组成的大型数据集中观察到的先验分布。
- en: Exploring SMPLify
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索SMPLify
- en: 'Now that we have a broad overview of how to estimate the 3D body shape of a
    person in a 2D RGB image, let us get a hands-on experience with code. Concretely,
    we are going to fit a 3D body shape onto two 2D images from the **Leeds Sports
    Pose** (**LSP**) dataset. This dataset contains 2,000 pose-annotated images of
    mostly sportspeople gathered from Flickr. We will first run through the code and
    generate these fitted body shapes before we dig deeper into the code. All the
    code used in this section was adapted from the implementation of the paper titled
    *Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image*.
    We have only adapted it in a way that helps you, the learner, to quickly run the
    code and visualize the outputs yourself.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '现在我们已经对如何估计一个人 2D RGB 图像中的 3D 身体形状有了大致的了解，接下来让我们通过代码来实际操作。具体来说，我们将拟合 3D 身体形状到
    **Leeds Sports Pose** (**LSP**) 数据集中的两张 2D 图像。这些图像来自 Flickr，包含了 2,000 张带有姿势注释的运动员图像。我们将首先运行代码并生成这些拟合的身体形状，然后再深入探讨代码的细节。本节中使用的所有代码都来自论文
    *Keep it SMPL: Automatic Estimation of 3D Human Pose and Shape from a Single Image*
    的实现。我们仅对其进行了调整，以便帮助你这个学习者快速运行代码并自己可视化输出结果。'
- en: 'This code was originally created by the authors of SMPLify for `python2`. Therefore,
    we need to use the same `python2` environment we used while exploring the SMPL
    model. Before we run any code, let us quickly get an overview of how the code
    is structured:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码最初是由 SMPLify 的作者为 `python2` 创建的。因此，我们需要使用与探索 SMPL 模型时相同的 `python2` 环境。在运行任何代码之前，让我们快速了解代码的结构：
- en: '[PRE10]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Running the code
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行代码
- en: 'The main file you will be directly interacting with is `run_fir3d.py`. The
    folder named `images` will have some example images from the LSP dataset. However,
    before we run the code, make sure that `PYTHONPATH` is set correctly. This should
    point to the location of the `chap8` folder. You can run the following code for
    it:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你将直接与之交互的主要文件是 `run_fir3d.py`。名为 `images` 的文件夹中包含一些来自 LSP 数据集的示例图像。然而，在我们运行代码之前，请确保正确设置了
    `PYTHONPATH`。它应该指向 `chap8` 文件夹的位置。你可以运行以下代码来设置：
- en: '[PRE11]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, go to the right folder:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，进入正确的文件夹：
- en: '[PRE12]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can now run the following command to fit a 3D body onto images in the `images`
    folder:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以运行以下命令，将 3D 身体拟合到 `images` 文件夹中的图像上：
- en: '[PRE13]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This run will not use any interpenetration error since it will be faster to
    go through the optimization iterations. In the end, we will fit a body-neutral
    shape. You will be able to visualize the projected pose of the 3D body as it fits
    the person in the picture. Once the optimization is complete, you will see the
    following two images:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这次运行不会使用任何穿透误差，因为它会更快地进行优化迭代。最后，我们将拟合一个身体中立形状。你将能够可视化拟合到图像中的 3D 身体姿态。一旦优化完成，你将看到以下两张图像：
- en: '![Figure 8.4 – Image in the LSP dataset of a person running (left) and the
    3D body shape fitting this image (right) ](img/B18217_08_05.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.4 – LSP 数据集中一个正在跑步的人物图像（左）和与该图像相匹配的 3D 身体形状（右）](img/B18217_08_05.jpg)'
- en: Figure 8.4 – Image in the LSP dataset of a person running (left) and the 3D
    body shape fitting this image (right)
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – LSP 数据集中一个正在跑步的人物图像（左）和与该图像相匹配的 3D 身体形状（右）
- en: 'Another output is as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个输出如下：
- en: '![Figure 8.5 – Image in the LSP dataset of a soccer player in action (left)
    and the 3D body shape fitting this image (right) ](img/B18217_08_06.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.5 – LSP 数据集中一个正在踢足球的运动员图像（左）和与该图像相匹配的 3D 身体形状（右）](img/B18217_08_06.jpg)'
- en: Figure 8.5 – Image in the LSP dataset of a soccer player in action (left) and
    the 3D body shape fitting this image (right)
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – LSP 数据集中一个正在踢足球的运动员图像（左）和与该图像相匹配的 3D 身体形状（右）
- en: Exploring the code
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索代码
- en: 'Now that you have run the code to fit humans in 2D images, let us look at the
    code in more detail to understand some of the main components needed to achieve
    this. You will find all the components in `run_fit3d.py`. You need to perform
    the following steps:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经运行了代码来拟合 2D 图像中的人物，让我们更详细地查看代码，以理解实现这一目标所需的一些主要组件。你会在 `run_fit3d.py` 文件中找到所有这些组件。你需要执行以下步骤：
- en: 'Let us first import all of the modules we will need:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先导入我们需要的所有模块：
- en: '[PRE14]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let us now define where our SMPL model is located. This is done through the
    following:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们定义 SMPL 模型的位置。通过以下方法来完成：
- en: '[PRE15]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let us set some parameters required for the optimization method and define
    the directories where our images and results are located. The results folder will
    have joint estimates for all the images in the dataset. `viz` is set to `True`
    to enable visualization. We are using an SMPL model with 10 parameters (that is,
    it uses 10 principal components to model the body shape). `flength` refers to
    the focal length of the camera; this is kept fixed during optimization. `pix_thsh`
    refers to the threshold (in pixels). If the distance between shoulder joints in
    2D is lower than `pix_thsh`, the body orientation is ambiguous. This could happen
    when a person is standing perpendicular to the camera. As a consequence, it is
    hard to say whether they are facing left or right. So, a fit is run on both the
    estimated one and its flip:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们设置一些优化方法所需的参数，并定义图像和结果所在的目录。结果文件夹将包含数据集中所有图像的关节估计。`viz`被设置为`True`，以启用可视化。我们使用具有10个参数的SMPL模型（即，它使用10个主成分来建模身体形状）。`flength`是相机的焦距；在优化过程中保持固定。`pix_thsh`是阈值（以像素为单位）。如果2D肩部关节之间的距离低于`pix_thsh`，则身体朝向是模糊的。这种情况可能发生在一个人站在与相机垂直的位置时。因此，很难判断他们是面朝左侧还是右侧。于是，系统会对估计的关节和它的翻转版本都进行拟合：
- en: '[PRE16]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We should then load this gender-neutral SMPL model into memory:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们应该将这个性别中立的SMPL模型加载到内存中：
- en: '[PRE17]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We then need to load the joint estimates for the images in the LSP dataset.
    The LSP dataset itself contains joint estimates and corresponding joint confidence
    scores for all the images in the dataset. We are going to just use that directly.
    You can also provide your own joint estimates or use good joint estimators, such
    as OpenPose or DeepCut, to get the joint estimates:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要加载LSP数据集中图像的关节估计。LSP数据集本身包含所有图像的关节估计和相应的关节置信度分数。我们将直接使用它。你也可以提供自己的关节估计，或者使用好的关节估计器，如OpenPose或DeepCut，来获取关节估计：
- en: '[PRE18]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, we need to load images in the dataset and get the corresponding joint
    estimates and confidence scores:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要加载数据集中的图像，并获取相应的关节估计和置信度分数：
- en: '[PRE19]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'For each of the images in the dataset, use the `run_single_fit` function to
    fit the parameters beta and theta. The following function returns these parameters
    after running the optimization on an objective function similar to the SMPLify
    objective function we discussed in the previous section:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于数据集中的每一张图像，使用`run_single_fit`函数来拟合参数beta和theta。以下函数会在类似于我们前一节讨论的SMPLify目标函数上运行优化，并返回这些参数：
- en: '[PRE20]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'While the objective function is being optimized, this function creates a `matplotlib`
    window where the green circles are the 2D joint estimates from a 2D joint detection
    model (which are provided to you). The red circles are the projected joints of
    the SMPL 3D model that is being fitted onto the 2D image:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化目标函数的过程中，函数会创建一个`matplotlib`窗口，其中绿色圆圈是来自2D关节检测模型的2D关节估计（这些是由你提供的）。红色圆圈是正在拟合到2D图像上的SMPL
    3D模型的投影关节：
- en: '![Figure 8.6 – Visualization of the provided 2D joints (green) and the projected
    joints (red) of the SMPL model being fit to the 2D image ](img/B18217_08_07.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.6 – 可视化提供的2D关节（绿色）和正在拟合到2D图像上的SMPL模型的投影关节（红色）](img/B18217_08_07.jpg)'
- en: Figure 8.6 – Visualization of the provided 2D joints (green) and the projected
    joints (red) of the SMPL model being fit to the 2D image
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 – 可视化提供的2D关节（绿色）和正在拟合到2D图像上的SMPL模型的投影关节（红色）
- en: 'Next, we want to visualize the fitted 3D human body alongside the 2D RGB image.
    We use matplotlib for this. The following opens up an interactive window where
    you can save images to disk:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们想要将拟合好的3D人体与2D RGB图像一起进行可视化。我们使用matplotlib来完成此任务。以下代码将打开一个交互窗口，你可以在其中将图像保存到磁盘：
- en: '[PRE21]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We then want to save these parameters and visualization to disk with the following
    code:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们想要使用以下代码将这些参数和可视化结果保存到磁盘：
- en: '[PRE22]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In the preceding code, the most important function is `run_single_fit`. You
    can explore this function in more detail in `smplify.code.fit3d_utils.py`.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，最重要的函数是`run_single_fit`。你可以在`smplify.code.fit3d_utils.py`中更详细地查看这个函数。
- en: 'It is important to note here that the accuracy of the fitted 3D body is dependent
    on the accuracy of the 2D joints. Since the 2D joints are predicted using a joint
    detection model (such as OpenPose or DeepCut), the accuracy of such joint prediction
    models becomes very important and relevant to this problem. Estimating 2D joints
    is especially error-prone in the following scenarios:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，拟合的3D身体的精度取决于2D关节的精度。由于2D关节是通过关节检测模型（例如OpenPose或DeepCut）预测的，因此这些关节预测模型的准确性对这个问题非常重要。估计2D关节在以下场景中尤其容易出错：
- en: Joints that are not completely visible are hard to predict. This could happen
    due to a variety of reasons including self-occlusion, occlusion by other objects,
    unusual clothing, and so on.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不完全可见的关节很难预测。这可能由于多种原因导致，包括自遮挡、被其他物体遮挡、不寻常的衣物等。
- en: It is easy to confuse between left and right joints (for example, left wrist
    versus right wrist). This is especially true when the person is facing the camera
    sideways.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很容易混淆左右关节（例如，左手腕和右手腕）。当人面对镜头侧面时，这一点尤其明显。
- en: Detecting joints in unusual poses is hard if the model is not trained with those
    poses. This depends on the diversity in the dataset used to train the joint detector.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果模型没有针对这些姿势进行训练，检测不寻常姿势中的关节是很困难的。这取决于用于训练关节检测器的数据集的多样性。
- en: More broadly, a system consisting of multiple machine learning models interacting
    with each other sequentially (that is, when the output of one model becomes the
    input of another model) will suffer from cascading errors. Small errors in one
    component will result in large errors in outputs from downstream components. Such
    a problem is typically solved by training a system end to end. However, this strategy
    cannot be used here at the moment since there is no ground-truth data in the research
    community that directly maps a 2D input image to a 3D model.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 更广泛地说，一个由多个机器学习模型依次相互作用的系统（即，一个模型的输出成为另一个模型的输入）将会遭遇级联错误。在一个组件中出现的小错误将导致下游组件输出的大错误。通常通过端到端训练系统来解决这个问题。然而，由于目前研究界没有直接将2D输入图像映射到3D模型的真实数据，因此此策略暂时无法使用。
- en: Summary
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we got an overview of the mathematical formulation of modeling
    human bodies in 3D. We understood the power of good representation and used simple
    methods such as Linear Blend Skinning on a powerful representation to obtain realistic
    outputs. We then got a high-level overview of the SMPL model and used it to create
    a random 3D human body. Afterward, we went over the code used to generate it.
    Next, we looked at how SMPLify can be used to fit a 3D human body shape onto a
    person in a 2D RGB image. We learned about how this uses the SMPL model in the
    background. Moreover, we fit human body shapes to two images in the LSP dataset
    and understood the code we used to do this. With this, we got a high-level overview
    of modeling the human body in 3D.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们概览了3D人体建模的数学公式。我们理解了良好表示的强大功能，并通过简单的方法，如在强大表示上使用线性混合蒙皮（Linear Blend Skinning），获得了真实的输出。接着，我们对SMPL模型进行了高层次概述，并利用它创建了一个随机的3D人体。之后，我们回顾了生成它所用的代码。接下来，我们探讨了如何使用SMPLify将3D人体形状拟合到2D
    RGB图像中的人物身上。我们了解了它如何在后台使用SMPL模型。此外，我们还将人体形状拟合到LSP数据集中的两张图像，并理解了我们用于此目的的代码。通过这些，我们对3D人体建模有了高层次的概述。
- en: In the next chapter, we will explore the SynSin model, which is typically used
    for 3D reconstruction. The goal of the next chapter is to understand how to reconstruct
    an image from a different view, given just a single image.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将探讨SynSin模型，通常用于3D重建。下一章的目标是理解如何仅凭一张图像重建来自不同视角的图像。
