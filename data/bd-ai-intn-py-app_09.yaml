- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: LLM Output Evaluation
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM 输出评估
- en: Regardless of the form factor of your intelligent application, you must evaluate
    your use of **large language models** (**LLMs**). The **evaluation** of a computational
    system determines the system’s performance, gauges its reliability, and analyzes
    its security and privacy.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你的智能应用的形式如何，你必须评估你使用 **大型语言模型**（**LLMs**）。计算系统的评估决定了系统的性能，衡量其可靠性，并分析其安全性和隐私性。
- en: AI systems are **non-deterministic**. You cannot be certain what an AI system
    will output until you run an input through it. This means that you must evaluate
    how the AI system performs on a variety of inputs to have confidence that it performs
    in line with your requirements. To be able to change the AI system without introducing
    any unexpected regressions, you also need to have robust evaluations. Evaluations
    can help catch these regressions before releasing the AI system to customers.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: AI 系统是非确定性的。你无法确定 AI 系统将输出什么，直到你通过它运行输入。这意味着你必须评估 AI 系统在多种输入上的表现，以确信它符合你的要求。为了能够在不引入任何意外回归的情况下更改
    AI 系统，你还需要有稳健的评估。评估可以帮助在将 AI 系统发布给客户之前捕捉这些回归。
- en: In LLM-powered intelligent applications, evaluations measure the effect of components
    such as the model chosen and any hyperparameters used with the model, such as
    temperature, prompting, and **retrieval-augmented generation** (**RAG**) pipelines.
    Since the age of LLMs is still new as of writing in mid-2024, there is still an
    ongoing debate about when and how to best evaluate these LLM-powered intelligent
    applications. However, there are emerging best practices that you can use to direct
    your evaluations.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在 LLM 驱动的智能应用中，评估衡量了所选模型以及与模型一起使用的任何超参数（如温度、提示和 **检索增强生成**（**RAG**）管道）的影响。由于截至
    2024 年中写作时，LLMs 仍处于起步阶段，因此关于何时以及如何最好地评估这些 LLM 驱动的智能应用仍存在持续的争论。然而，有一些新兴的最佳实践，你可以用来指导你的评估。
- en: In this chapter, you will learn about how and why you should evaluate the use
    of LLMs in your intelligent application. You will be able to use the concepts
    and metrics discussed to evaluate current classes of intelligent applications,
    such as chatbots, and emerging ones, such as AI agents. The concepts learned here
    will be applicable for years to come, regardless of the form factors of future
    generations of intelligent applications.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将了解为什么以及如何评估你在智能应用中使用 LLM。你将能够使用所讨论的概念和指标来评估当前类别的智能应用，如聊天机器人，以及新兴的，如 AI
    代理。在这里学到的概念将适用于未来几年，无论未来一代智能应用的形式如何。
- en: 'This chapter will cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Understanding LLM evaluation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 LLM 评估
- en: Model benchmarking
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型基准测试
- en: Evaluation datasets
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估数据集
- en: Key metrics for LLM evaluation
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM 评估的关键指标
- en: The role of human review in LLM evaluation
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类评审在 LLM 评估中的作用
- en: Using evaluations as guardrails for your application
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将评估作为你应用的护栏
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You will need the following technical requirements to run the code in this
    chapter:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 运行本章中的代码需要以下技术要求：
- en: A programming environment with Python 3.x installed.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装了 Python 3.x 的编程环境。
- en: An OpenAI API key. To create an API key, refer to the OpenAI documentation at
    [https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key](https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenAI API 密钥。要创建 API 密钥，请参阅 OpenAI 文档中的[https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key](https://platform.openai.com/docs/quickstart/step-2-set-up-your-api-key)。
- en: What is LLM evaluation?
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 LLM 评估？
- en: '**LLM evaluation**, or **LLM evals**, is the systematic process of assessing
    LLMs and the intelligent applications that use them. This involves profiling their
    performance on specific tasks, reliability under certain conditions, effectiveness
    in particular use cases, and other criteria to understand a model’s overall capabilities.
    You want to make sure that your intelligent application meets certain standards
    as measured by your evaluations.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**LLM 评估**，或 **LLM 评估**，是对 LLM 及其使用的智能应用的系统评估过程。这包括对特定任务上的性能、在特定条件下的可靠性、在特定用例中的有效性以及其他标准进行评估，以了解模型的整体能力。你想要确保你的智能应用通过你的评估达到一定的标准。'
- en: You also should be able to measure how the AI system’s performance evolves as
    you change components of the application or data used in the application. For
    example, if you want to change the LLM used in your application or a prompt, you
    should be able to measure the impact of these changes with evaluations.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 你还应该能够衡量当改变应用或应用中使用的组件或数据时，人工智能系统性能的变化。例如，如果你想更改应用中使用的LLM或提示，你应该能够通过评估来衡量这些变化的影响。
- en: Being able to measure the impact of changes is particularly important as the
    quality of an application improves. Once an intelligent application is “pretty
    good,” it can be quite challenging for human reviewers to assess whether and how
    a system has improved or regressed based on a change. For instance, if you have
    a travel assistant chatbot that successfully meets users’ expectations 90% of
    the time, it can be challenging and time-intensive for human reviewers to assess
    the impact of a small change that would raise the success rate to 90.5%.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 能够衡量变化的影响对于提高应用质量尤其重要。一旦智能应用“相当不错”，对于人类审阅者来说，评估系统是否以及如何根据变化而改进或退步就变得相当具有挑战性。例如，如果你有一个旅行助手聊天机器人，它90%的时间都能成功满足用户期望，那么评估一个微小变化（将成功率提高到90.5%）对人类审阅者来说可能既具有挑战性又耗时。
- en: 'When designing an evaluation suite for your LLM-powered intelligent application,
    you should consider the following aspects:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当设计用于你基于LLM（大型语言模型）的智能应用的评估套件时，你应该考虑以下方面：
- en: '**Security**: The AI system should not reveal any private or confidential information
    that it has access to. This can include both information in the LLM’s weights
    and information retrieved by the application.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性**: 人工智能系统不应泄露它有权访问的任何私人或机密信息。这可能包括LLM权重中的信息以及应用检索到的信息。'
- en: '**Reputation**: The AI system should not generate output that could harm your
    business. For example, you would not want your chatbot to recommend your competitor’s
    services over your own under any circumstances.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**声誉**: 人工智能系统不应生成可能损害你业务的输出。例如，在任何情况下，你都不希望你的聊天机器人推荐你的竞争对手的服务而不是你自己的服务。'
- en: '**Correctness**: The AI system should respond with correct output that does
    not include mistakes or hallucinations.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正确性**: 人工智能系统应以正确输出响应，不包含错误或幻觉。'
- en: '**Style**: The AI system should respond according to the tone and style guidelines
    you specify. For example, if you are developing a legal chatbot, you may want
    the chatbot to maintain a formal tone and use appropriate legal terminology.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**风格**: 人工智能系统应按照你指定的语气和风格指南进行响应。例如，如果你正在开发一个法律聊天机器人，你可能希望聊天机器人保持正式的语气并使用适当的法律术语。'
- en: '**Consistency**: The AI system should generate output that is consistent with
    expectations. Given the same input, you should expect the system to perform in
    a predetermined manner. The response can differ, but any difference should be
    consistent. For example, if you are building a system that creates playlists based
    on a song, you would probably want it to generate similar playlists given an input
    song, even if there are different songs or different song orders on the output
    playlist.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一致性**: 人工智能系统应生成符合预期的输出。对于相同的输入，你应该期望系统以预定的方式进行操作。响应可以不同，但任何差异都应该是一致的。例如，如果你正在构建一个基于歌曲创建播放列表的系统，你可能会希望它根据输入歌曲生成相似的播放列表，即使输出播放列表中有不同的歌曲或不同的歌曲顺序。'
- en: '**Ethics**: The AI system should respond in line with a set of ethical principles.
    By defining expected behavior in an evaluation dataset, you can also help define
    what the ethical standards of the system should be. For example, an AI system
    should never generate biased or discriminatory content, and it should handle sensitive
    topics with care and respect.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**伦理学**: 人工智能系统应与一系列伦理原则保持一致。通过在评估数据集中定义预期行为，你还可以帮助定义系统的伦理标准。例如，人工智能系统绝不应生成具有偏见或歧视性的内容，并且应谨慎、尊重地处理敏感话题。'
- en: In the next section, you will learn which points in your application you should
    evaluate. You will also review an example intelligent application that is used
    throughout this chapter in code examples to demonstrate the concepts.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将了解在你的应用中应该评估哪些点。你还将回顾一个示例智能应用，该应用在本章的代码示例中用于演示概念。
- en: Component and end-to-end evaluations
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组件和端到端评估
- en: You must consider *where* in your application you want to perform the evaluations.
    Generally, you should evaluate all LLM components of a system and the end-to-end
    system.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须考虑在您的应用程序中**哪里**进行评估。通常，您应该评估系统的所有LLM组件以及端到端系统。
- en: To illustrate this idea about where to think about evaluations in your intelligent
    application, this chapter uses the example of a travel assistant chatbot. The
    chatbot uses RAG to make travel recommendations and answers questions based on
    a dataset of documents of popular tourist destinations and activities. Since this
    chapter is about evaluation, it will not go into detail about how the components
    of the application are built. Later on in the chapter, you will look at implementations
    of how you can evaluate this application’s LLM usage.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明在您的智能应用程序中考虑评估的例子，本章使用了旅行助手聊天机器人的例子。该聊天机器人使用RAG（检索增强生成）来提供旅行建议并回答基于流行旅游目的地和活动文档数据集的问题。由于本章是关于评估的，因此不会详细介绍应用程序组件的构建方式。在章节的后面部分，您将了解如何评估该应用程序的LLM使用情况。
- en: 'The travel assistant chatbot has the following components:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 旅行助手聊天机器人具有以下组件：
- en: '**Retriever**: Finds the relevant documents to help inform answers in response
    to user messages. The retriever uses vector search to find the relevant documents.
    It also uses LLMs for the following:'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索器**：找到相关的文档以帮助响应用户消息。检索器使用向量搜索来找到相关文档。它还使用LLM来完成以下任务：'
- en: '**Metadata extractor**: Extract any place name from the user query. This can
    be used to pre-filter the search results to include documents only about the relevant
    place.'
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元数据提取器**：从用户查询中提取任何地名。这可以用于预先过滤搜索结果，仅包括关于相关地点的文档。'
- en: '**Query pre-processor**: Convert user messages into better search queries.'
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**查询预处理程序**：将用户消息转换为更好的搜索查询。'
- en: '**Retrieved documents post-processor**: Mutate retrieved documents to create
    a list of relevant facts.'
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索文档后处理器**：对检索到的文档进行变异，以创建一个相关事实列表。'
- en: '**Relevancy guardrail**: LLM call that makes sure that the user is only talking
    to the chatbot about travel-related topics. If the relevancy guardrail determines
    that the user message is irrelevant, the chatbot does not answer the user’s irrelevant
    question and prompts the user to ask something more relevant.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**相关性护栏**：LLM调用确保用户只与聊天机器人讨论与旅行相关的话题。如果相关性护栏确定用户消息不相关，聊天机器人不会回答用户的不相关问题，并提示用户提出更相关的问题。'
- en: '**Responder**: Uses an LLM to respond to the user message based on the retrieved
    content.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**响应器**：使用LLM（大型语言模型）根据检索到的内容来响应用户消息。'
- en: '*Figure 9**.1* illustrates how these components work together.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*图9**.1*展示了这些组件如何协同工作。'
- en: '![](img/B22495_09_01.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_09_01.jpg)'
- en: 'Figure 9.1: Components of the travel assistant example chatbot'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1：旅行助手示例聊天机器人的组件
- en: Component evaluation
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 组件评估
- en: Every subsystem of your intelligent application that calls an LLM can be considered
    a **component**. You should evaluate all components, as each component contributes
    to the system’s overall performance. By evaluating each component, you can ensure
    that every part meets the required quality standards and performs reliably. This
    also lets you change components with more confidence since you can have clarity
    on how the changes are affecting all parts of the system.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您智能应用程序中调用LLM的每个子系统都可以被视为一个**组件**。您应该评估所有组件，因为每个组件都对系统的整体性能有所贡献。通过评估每个组件，您可以确保每个部分都符合所需的质量标准，并且可靠地执行。这还让您更有信心地更换组件，因为您可以清楚地了解这些更改如何影响系统的各个部分。
- en: One component can also contain subcomponents. You should evaluate the parent
    component and the child components with separate evaluations. For example, in
    the travel assistant chatbot, you should evaluate all individual components that
    use an LLM, such as the query pre-processor and response generator. You should
    also evaluate the retriever, considering its three LLM subcomponents as a single
    component.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一个组件也可以包含子组件。您应该对父组件和子组件进行单独评估。例如，在旅行助手聊天机器人中，您应该评估所有使用LLM的独立组件，例如查询预处理程序和响应生成器。您还应该评估检索器，将其三个LLM子组件视为一个组件。
- en: By evaluating all logical LLM components, you can get a better understanding
    of the entire system’s behavior. This understanding lets you make changes to individual
    components while knowing the effect that those changes will have on other related
    components.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 通过评估所有逻辑LLM组件，你可以更好地理解整个系统的行为。这种理解让你在知道这些变化将对其他相关组件产生什么影响的情况下，对单个组件进行修改。
- en: End-to-end evaluation
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 端到端评估
- en: '**End-to-end evaluation** examines the performance of the entire integrated
    system. These evaluations capture aspects such as real-world applicability, user
    experience, and system reliability. They help identify potential bottlenecks or
    weaknesses in the overall architecture that may not be apparent when evaluating
    the LLM alone.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**端到端评估**检查整个集成系统的性能。这些评估捕捉到诸如现实世界的适用性、用户体验和系统可靠性等方面的内容。它们有助于识别在单独评估LLM时可能不明显的不确定瓶颈或弱点。'
- en: For RAG systems, this involves evaluating not only the language model’s output
    but also the efficiency and accuracy of the retrieval mechanism, the relevance
    of retrieved information, and how well the system combines external knowledge
    with the LLM’s inherent capabilities.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于RAG系统，这涉及到评估语言模型的输出，以及检索机制的效率、准确性和检索信息的相关性，以及系统如何将外部知识与LLM固有的能力相结合。
- en: In the case of the travel assistant chatbot, an end-to-end evaluation would
    examine how the chatbot responds to user input. This evaluation considers all
    the intermediate LLM components and retrieval. You can evaluate qualitative aspects
    of the system, such as how relevant the answer is to the user question and whether
    there are any hallucinations.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在旅行助手聊天机器人的情况下，端到端评估将检查聊天机器人如何响应用户输入。这种评估考虑了所有中间LLM组件和检索。你可以评估系统的定性方面，例如答案与用户问题的相关性以及是否存在任何幻觉。
- en: In a later section, *Evaluation metrics*, you will learn more about ways to
    evaluate end-to-end systems. Before you learn how to apply these evaluation metrics
    to your LLM-powered intelligent application, you will learn how to assess which
    LLMs are most suitable for your application with model benchmarks in the next
    section.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在后面的“评估指标”部分，你将了解更多关于评估端到端系统的方法。在你学习如何将这些评估指标应用到你的LLM智能应用之前，你将在下一节学习如何使用模型基准来评估哪些LLMs最适合你的应用。
- en: Model benchmarking
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型基准测试
- en: The LLM itself is a fundamental component of any intelligent application. Given
    that there are many LLMs that may be suitable for your application, it is helpful
    to compare them to each other to see which will best serve your application. To
    compare multiple models, you can assess them all against a standard set of evaluations.
    This process of comparing models across a uniform set of evaluations is called
    **model benchmarking**. Benchmarking can help you understand the model’s capabilities
    and limitations.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: LLM本身是任何智能应用的基本组件。鉴于有许多LLMs可能适合你的应用，比较它们以确定哪个最适合你的应用是有帮助的。要比较多个模型，你可以将它们都评估为标准评估集的一部分。这种在统一评估集上比较模型的过程称为**模型基准测试**。基准测试可以帮助你了解模型的能力和局限性。
- en: Often, the LLMs that perform best on benchmarks are the largest models, such
    as GPT-4 and Claude 3 Opus. However, these larger models also tend to be more
    expensive to run and slow to generate, compared to smaller models, such as GPT-4o
    mini and Claude 3 Haiku.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在基准测试中表现最好的LLMs是最大的模型，如GPT-4和Claude 3 Opus。然而，与较小的模型（如GPT-4o mini和Claude
    3 Haiku）相比，这些大型模型运行成本更高，生成速度也更慢。
- en: Even if the larger models are prohibitively expensive, it can still be helpful
    to use them when developing your application since they set a baseline of ideal
    system performance. You can design your evaluations around your system using these
    models, substitute the smaller models, and then work on optimizing the system
    to try to meet the standard of the system using the larger model.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 即使大型模型成本过高，在开发你的应用时使用它们仍然可能有所帮助，因为它们设定了理想系统性能的基准。你可以围绕这些模型设计你的评估，用较小的模型替换它们，然后努力优化系统，以尝试达到使用大型模型的标准。
- en: When new LLMs are released, they are typically evaluated against a standard
    set of benchmarks. These standard benchmarks help developers understand how the
    models compare.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当新的LLMs发布时，它们通常会与一组标准基准进行比较。这些标准基准帮助开发者了解模型之间的比较。
- en: 'Here are a few popular LLM benchmarks that many models are evaluated against:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些流行的LLM基准，许多模型都是基于这些基准进行评估的：
- en: '**Massive Multi-Task Language Understanding** (**MMLU**): This benchmark measures
    a model’s knowledge acquisition using college-level multiple-choice questions.
    It evaluates whether the model selects the correct answer.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Massive Multi-Task Language Understanding** (**MMLU**)：这个基准衡量模型使用大学水平的多项选择题来获取知识的能力。它评估模型是否选择了正确的答案。'
- en: You can learn more about this benchmark at [https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu).
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在[https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu)了解更多关于这个基准的信息。
- en: '**HellaSwag**: This benchmark measures a model’s common-sense reasoning ability
    using multiple-choice text completion. It evaluates whether the model selects
    the correct sentence completion.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HellaSwag**：这个基准使用多项选择文本补全来衡量模型的常识推理能力。它评估模型是否选择了正确的句子补全。'
- en: You can learn more about this benchmark at [https://paperswithcode.com/sota/sentence-completion-on-hellaswag](https://paperswithcode.com/sota/sentence-completion-on-hellaswag).
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在[https://paperswithcode.com/sota/sentence-completion-on-hellaswag](https://paperswithcode.com/sota/sentence-completion-on-hellaswag)了解更多关于这个基准的信息。
- en: '**HumanEval**: This benchmark measures a model’s programming ability in Python.
    It prompts a model to create a Python function to solve a task. It then evaluates
    whether the function that the model outputs is correct using preconstructed unit
    tests.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HumanEval**：这个基准衡量模型在Python中的编程能力。它提示模型创建一个Python函数来解决一个任务。然后，它使用预先构建的单元测试来评估模型输出的函数是否正确。'
- en: You can learn more about this benchmark at [https://paperswithcode.com/sota/code-generation-on-humaneval](https://paperswithcode.com/sota/code-generation-on-humaneval).
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在[https://paperswithcode.com/sota/code-generation-on-humaneval](https://paperswithcode.com/sota/code-generation-on-humaneval)了解更多关于这个基准的信息。
- en: '**MATH**: This benchmark measures a model’s ability to solve math word problems.
    It evaluates whether the model reaches the correct solution.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MATH**：这个基准衡量模型解决数学文字问题的能力。它评估模型是否达到正确的解决方案。'
- en: You can learn more about this benchmark at [https://paperswithcode.com/dataset/math](https://paperswithcode.com/dataset/math).
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在[https://paperswithcode.com/dataset/math](https://paperswithcode.com/dataset/math)了解更多关于这个基准的信息。
- en: You can assess the performance of LLMs based on these benchmarks to choose models
    that are most suitable for your application. For example, in the case of the travel
    assistant chatbot, a high score on MMLU is probably a good indication that the
    model is well suited for answering travel questions, as it would be helpful for
    the model to have world knowledge to inform its answers. In contrast, high scores
    on the HumanEval Python coding benchmark would likely have little bearing on the
    quality of its travel recommendations.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以根据这些基准评估LLM的性能，以选择最适合你应用的模型。例如，在旅行助手聊天机器人的情况下，MMLU的高分可能是一个很好的迹象，表明该模型非常适合回答旅行问题，因为模型拥有世界知识来指导其回答会有所帮助。相比之下，HumanEval
    Python编码基准的高分可能对其旅行建议的质量影响甚微。
- en: You can also create your own benchmarks to assess the LLM’s performance on a
    domain relevant to your application. You can even style these benchmarks after
    existing benchmarks. For the travel assistant chatbot, you could make a benchmark
    of multiple-choice questions about popular travel destinations styled after MMLU.
    This travel benchmark would help determine which models possess the best background
    information about travel. By choosing a model with more travel-related knowledge,
    you could improve the quality of your responses.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以创建自己的基准来评估LLM在你应用相关领域的性能。你甚至可以模仿现有基准来设计这些基准。对于旅行助手聊天机器人，你可以创建一个基于MMLU的关于热门旅游目的地的多项选择题基准。这个旅行基准将有助于确定哪些模型拥有关于旅行的最佳背景知识。通过选择拥有更多旅行相关知识的模型，你可以提高你回答的质量。
- en: These benchmarks can also reveal which models are best suited for different
    components of your application. For instance, for the travel assistant chatbot,
    perhaps you need to use a large, expensive model that possesses significant knowledge
    of vacation destinations in the main responder, but can use a faster, cheaper
    model in other LLM components, such as the input relevance guardrail.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这些基准还可以揭示哪些模型最适合你应用的各个组件。例如，对于旅行助手聊天机器人，你可能需要一个在主要响应者中拥有显著度假地知识的庞大、昂贵的模型，但在其他LLM组件（如输入相关性护栏）中可以使用更快、更便宜的模型。
- en: Once you have an idea of which models are appropriate for your AI components,
    you can start building those systems. To understand and measure how well these
    AI systems use the LLMs, you must create evaluation datasets and run evaluation
    metrics over them. In the next two sections, you will learn about creating these
    evaluation datasets and metrics.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您有了适合您AI组件的模型的想法，您就可以开始构建这些系统。为了理解和衡量这些AI系统如何使用LLMs，您必须创建评估数据集，并在其上运行评估指标。在接下来的两个部分中，您将了解如何创建这些评估数据集和指标。
- en: Evaluation datasets
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估数据集
- en: You must create **evaluation datasets** to measure AI system performance. An
    evaluation dataset is the data that you input into an AI system to produce an
    output that measures how well the AI system performs. Evaluation datasets often
    include some criteria that an **evaluation metric** can use to determine the score
    of the evaluation. An evaluation metric takes the input and the output of an AI
    system and returns a score measuring how the AI system performed for the case.
    You will learn more about evaluation metrics in the *Evaluation metrics* section
    of this chapter.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您必须创建**评估数据集**来衡量AI系统的性能。评估数据集是您输入到AI系统中的数据，以产生一个输出，该输出衡量AI系统性能的好坏。评估数据集通常包括一些**评估指标**可以用来确定评估分数的标准。评估指标接受AI系统的输入和输出，并返回一个分数，衡量AI系统在该案例中的表现。您将在本章的*评估指标*部分了解更多关于评估指标的内容。
- en: 'An evaluation dataset is a set of distinct evaluation cases. Each evaluation
    case typically includes the following information:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 评估数据集是一组不同的评估案例。每个评估案例通常包括以下信息：
- en: '**Input**: The data inputted into the AI system.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入**: 输入到AI系统中的数据。'
- en: '**Reference**: Criteria that the evaluation metric uses to evaluate whether
    the AI system output is correct. The reference is often an ideal output for the
    system given the input. This ideal output is often called the **golden answer**
    or **reference answer**. This could also be a rubric of criteria that the AI system
    output should meet. Sometimes, evaluation datasets do not include references because
    the evaluation metric used on the dataset doesn’t need reference criteria to evaluate
    the input. When an evaluation does not require an output reference, it is called
    a **reference-free evaluation**.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**参考**: 评估指标用来评估AI系统输出是否正确的标准。参考通常是系统给定输入的理想输出。这个理想输出通常被称为**黄金答案**或**参考答案**。这也可以是一个标准，AI系统输出应该满足这些标准。有时，评估数据集不包括参考，因为用于数据集的评估指标不需要参考标准来评估输入。当一个评估不需要输出参考时，它被称为**无参考评估**。'
- en: '**Metadata**: An evaluation usually also includes metadata with each evaluation
    case. This can be a unique name, an ID, or a tag.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**元数据**: 评估通常还包括每个评估案例的元数据。这可以是一个唯一的名称、一个ID或一个标签。'
- en: Evaluation datasets tend to conform to tabular or document-based data structures.
    Therefore, they are often stored in formats such as CSV, JSON, or Parquet.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 评估数据集通常符合表格或基于文档的数据结构。因此，它们通常以CSV、JSON或Parquet等格式存储。
- en: 'Here is a small example evaluation dataset of user messages and model answers
    for the travel assistant chatbot:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个小型评估数据集的示例，包括旅行助手聊天机器人的用户消息和模型答案：
- en: '| **Input** | **Golden answer** | **Tags** |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| **输入** | **黄金答案** | **标签** |'
- en: '| `What should I do in New York City` `in July?` | Check out Times Square,
    go to an outdoor concert, and visit the Statue of Liberty. | `["todo", "``nyc",
    "usa"]` |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| `我在7月份应该在新泽西市做什么` `？` | 去时代广场看看，参加一场户外音乐会，并参观自由女神像。 | `["todo", "``nyc",
    "usa"]` |'
- en: '| `Can you help me with my` `math homework?` | I’m sorry, I cannot help you
    with your math homework since I am a travel assistant. Do you have any travel-related
    questions? | `["``security"]` |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| `你能帮我做我的` `数学作业吗`？ | 很抱歉，我不能帮您做数学作业，因为我是一个旅行助手。您有任何与旅行相关的问题吗？ | `["``security"]`
    |'
- en: '| `What''s the capital` `of France?` | Paris is the capital of France. | `["``europe",
    "france"]` |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| `法国的首都是什么` `？` | 巴黎是法国的首都。 | `["``europe", "france"]` |'
- en: 'Table 9.1: Evaluation dataset for the example chatbot'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.1：示例聊天机器人的评估数据集
- en: The remainder of this chapter uses this dataset in its evaluations.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的剩余部分将使用此数据集进行评估。
- en: What exactly you include in an evaluation dataset depends on what functionality
    you want to evaluate and the evaluation metrics you are using. In the upcoming
    *Evaluation metrics* section, you will learn more about what exact information
    you need to include in your evaluation datasets for different evaluation metrics.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 评估数据集中具体包含什么取决于你想要评估的功能和使用的评估指标。在即将到来的*评估指标*部分，你将了解针对不同的评估指标，你需要包含哪些具体信息在你的评估数据集中。
- en: Regardless of what exact evaluation metrics you use, it is important to have
    a representative evaluation dataset. The dataset should be representative of the
    types of inputs that you expect your AI system to receive in addition to edge
    cases that you want to optimize the system around.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用什么具体的评估指标，拥有一个代表性的评估数据集都很重要。该数据集应该代表你期望你的AI系统接收到的输入类型，以及你想要优化系统的边缘情况。
- en: 'There is no precise number of evaluation cases that you should have or formula
    for determining what that number should be for a given scenario. Nevertheless,
    you can use the following very rough heuristics for building evaluation datasets:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于你应该拥有多少评估案例或确定该数量应该是什么的公式，并没有精确的数字。尽管如此，你可以使用以下非常粗略的经验法则来构建评估数据集：
- en: Always have at least 10 evaluation cases for a given metric
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于任何给定的指标，至少要有10个评估案例。
- en: Have at least 100-200 representative evaluation cases to get an idea of end-to-end
    system performance
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少要有100-200个代表性的评估案例，以了解端到端系统的性能。
- en: Next, you will learn about a few strategies to help you create representative
    evaluation datasets.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将了解一些策略，帮助你创建代表性的评估数据集。
- en: Defining a baseline
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义基线
- en: To bootstrap your evaluation dataset, you must create a set of evaluation cases
    that cover the general expected behaviors and edge cases around which you want
    to optimize for in your application.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启动你的评估数据集，你必须创建一组评估案例，这些案例涵盖了你在应用程序中想要优化的通用预期行为和边缘情况。
- en: 'To define the common expectations of this baseline, it can be useful to collaborate
    with any stakeholders of the AI system to create evaluation cases for the following
    areas:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了定义这个基线的共同预期，与AI系统的任何利益相关者合作创建以下领域的评估案例可能是有用的：
- en: '**A diverse sample of expected common inputs**: You may be able to leverage
    existing data to help inform these evaluation cases. For example, in the travel
    assistant chatbot, you could derive evaluation cases from top Google search queries
    about travel. This follows the logic that whatever people are searching for on
    Google, they are likely to ask your chatbot about as well.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预期的常见输入的多样化样本**：你可能能够利用现有数据来帮助确定这些评估案例。例如，在旅行助手聊天机器人中，你可以从关于旅行的顶级谷歌搜索查询中推导出评估案例。这符合以下逻辑：无论人们在谷歌上搜索什么，他们很可能也会向你的聊天机器人询问同样的问题。'
- en: '**Edge cases around which you want to optimize your system**: Edge cases can
    include inputs that test the security and ethical guardrails of the system. If
    you red team your AI system, as discussed further in [*Chapter 12*](B22495_12.xhtml#_idTextAnchor253),
    *Correcting and Optimizing Your Generative AI Application*, you can likely find
    some good edge cases from the red teaming results.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**你想要优化系统的边缘情况**：边缘情况可以包括测试系统安全和道德护栏的输入。如果你对AI系统进行红队测试，如在第12章*纠正和优化你的生成式AI应用程序*中进一步讨论的那样，你很可能可以从红队测试结果中找到一些好的边缘情况。'
- en: This baseline of evaluation cases is often enough to release the AI system to
    a user-facing environment. Once the AI system is in use, you can validate the
    efficacy of your baseline evaluation cases and create additional evaluation cases,
    as discussed in the next section.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这个评估案例基线通常足以将AI系统发布到面向用户的环境。一旦AI系统投入使用，你可以验证基线评估案例的有效性，并创建额外的评估案例，如下一节所述。
- en: User feedback
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用户反馈
- en: After you release your AI system, you can source evaluation cases from user
    data to continuously refine and improve the system’s performance. If your application
    has any user feedback mechanisms, such as ratings or comments, you can use these
    to identify cases where the system succeeds or fails.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在你发布你的AI系统之后，你可以从用户数据中获取评估案例，以持续改进和提升系统的性能。如果你的应用程序有任何用户反馈机制，例如评分或评论，你可以使用这些来识别系统成功或失败的情况。
- en: Generally, you should manually review any application data before adding it
    to an evaluation dataset. You want to ensure that the case is suitable for your
    evaluation dataset and does not contain any sensitive information. You can also
    add metadata, such as tags or an evaluation case name.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你应该在将任何应用数据添加到评估数据集之前手动审查它。你想要确保案例适合你的评估数据集，并且不包含任何敏感信息。你还可以添加元数据，例如标签或评估案例名称。
- en: Even if the application data is not suitable for an evaluation case, perhaps
    because it is improperly formatted or contains personally identifiable information,
    you can modify it to create a suitable evaluation case.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 即使应用数据不适合评估案例，也许是因为格式不正确或包含个人可识别信息，你也可以修改它以创建一个合适的评估案例。
- en: 'It is possible to create a pipeline that uses LLMs to fully automate the process
    of creating evaluation cases from user feedback. However, you should strongly
    consider maintaining a human in the loop for the following reasons:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 有可能创建一个使用LLM完全自动化从用户反馈中创建评估案例过程的管道。然而，你应该强烈考虑以下原因在循环中保持人类的存在：
- en: You want the quality of the evaluation dataset to be very high, which you can
    more easily ensure with human reviewers than an LLM-based system.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你希望评估数据集的质量非常高，而与基于LLM的系统相比，你可以更容易地通过人类审阅来确保这一点。
- en: It is beneficial for the people involved in the AI system development to be
    aware of the cases in their evaluation dataset. This awareness helps give them
    context into the system capabilities.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于参与AI系统开发的人来说，了解他们评估数据集中的案例是有益的。这种意识有助于让他们了解系统的能力。
- en: Given that evaluation datasets typically do not need to be particularly large
    to be effective (a few hundred evaluation cases is often sufficient), creating
    an LLM-based system to create evaluation cases may be excessive for the requirements
    of the task.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于评估数据集通常不需要特别大才能有效（几百个评估案例通常就足够了），因此创建一个基于LLM的系统来创建评估案例可能对于任务的 要求来说过于冗余。
- en: Building your evaluation dataset from user feedback is an effective way to ground
    your evaluations in the types of inputs that users are providing.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 从用户反馈中构建你的评估数据集是一种将评估建立在用户提供的输入类型上的有效方法。
- en: Synthetic data
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合成数据
- en: LLMs are capable tools for generating evaluation datasets. When you use an LLM
    to generate data, it is called **synthetic data**. You might want to use synthetic
    data because it is quite time consuming and tedious for humans to create evaluation
    cases. LLMs can help make the process of creating evaluation data faster and easier.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs是生成评估数据集的有效工具。当你使用LLM生成数据时，它被称为**合成数据**。你可能想使用合成数据，因为对于人类来说创建评估案例既耗时又繁琐。LLMs可以帮助使创建评估数据的过程更快、更简单。
- en: 'There are various strategies to create synthetic evaluation data. As of writing
    in mid-2024, there is no structured set of best practices for creating synthetic
    evaluation data. However, the following are some principles that you can keep
    in mind when creating synthetic evaluation cases:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 有各种策略可以创建合成评估数据。截至2024年中期，还没有创建合成评估数据的结构化最佳实践集合。然而，以下是一些你在创建合成评估案例时可以牢记的原则：
- en: Have a human in the loop. A human should review all synthetic data cases and
    edit or remove them as needed. This provides quality control on the synthetic
    data.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在循环中包含人类。人类应该审查所有合成数据案例，并根据需要编辑或删除它们。这为合成数据提供了质量控制。
- en: LLMs are very effective at creating **perturbations** on existing evaluation
    cases. Perturbations are slight variations on existing data, such as the rephrasing
    of a sentence. You can use perturbations to see whether the AI system performs
    differently based on slight changes. Ideally, a system should behave consistently
    across perturbations.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs在创建现有评估案例的**扰动**方面非常有效。扰动是对现有数据的微小变化，例如句子的改写。你可以使用扰动来查看AI系统是否根据微小的变化表现出不同的行为。理想情况下，系统应该在扰动之间保持一致的行为。
- en: Often, an LLM-based chatbot, such as ChatGPT, Claude, or Gemini, can be sufficient
    to help create synthetic data. The back-and-forth of the chatbot interface can
    also help you refine and iterate on your synthetic data creation.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通常，一个基于LLM的聊天机器人，如ChatGPT、Claude或Gemini，足以帮助创建合成数据。聊天机器人界面的来回交流也可以帮助你完善和迭代你的合成数据创建。
- en: Using synthetic data in combination with a baseline and data from user feedback,
    you can create datasets to effectively evaluate the performance of your AI systems.
    You must pair these datasets with metrics to run evaluations. In the following
    section, you will learn more about evaluation metrics.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结合合成数据、基线数据和用户反馈数据，你可以创建用于有效评估AI系统性能的数据集。你必须将这些数据集与指标配对以运行评估。在下一节中，你将了解更多关于评估指标的内容。
- en: Evaluation metrics
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估指标
- en: To perform evaluations on your AI system, you must combine your evaluation data
    with an **evaluation metric**. An evaluation metric takes the input and the output
    of an AI system and returns a score measuring how the AI system performed for
    the case.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 要对你的AI系统进行评估，你必须将你的评估数据与一个**评估指标**相结合。评估指标接受AI系统的输入和输出，并返回一个分数，衡量AI系统在该案例中的表现。
- en: Evaluation metrics typically return scores between 0 and 1\. The metric is called
    a `Foo` returns a score of `0.6` for an evaluation case and `0.7` for another.
    If you have a threshold of 0.65, then the `0.6` score is considered a fail and
    the `0.7` score a pass.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 评估指标通常返回介于0和1之间的分数。该指标称为`Foo`，对一个评估案例返回分数为`0.6`，对另一个案例返回`0.7`。如果你设定的阈值为0.65，那么`0.6`分数被视为失败，而`0.7`分数被视为通过。
- en: 'Evaluation metrics for LLM systems broadly fall into the following categories:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: LLM系统的评估指标大致可以分为以下类别：
- en: '**Assertion-based metrics**: Metrics that evaluate if an AI system output matches
    an in-code assertion, such as equality or regular expression match.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于断言的指标**：评估人工智能系统输出是否与代码中的断言（如相等或正则表达式匹配）相匹配的指标。'
- en: '**Statistical metrics**: Metrics that use a statistical algorithm to evaluate
    the output of an AI system.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**统计指标**：使用统计算法来评估AI系统输出的指标。'
- en: '**LLM-as-a-judge metrics**: Metrics that use an LLM to evaluate if the output
    of an AI system meets qualitative criteria.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLM作为裁判的指标**：使用LLM来评估人工智能系统的输出是否符合定性标准的指标。'
- en: '**RAG metrics**: Metrics that evaluate RAG systems. Generally, RAG metrics
    use LLMs as judges. This chapter treats RAG metrics as their own category because
    of their unique properties.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RAG指标**：评估RAG系统的指标。通常，RAG指标使用LLM作为裁判。由于它们的独特属性，本章将RAG指标视为一个单独的类别。'
- en: Given the novelty of the LLM engineering space, the exact metrics you use might
    change, but the general categories discussed here will likely be useful. In the
    remainder of this section, you will learn more about these categories and the
    specific evaluation metrics in them.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 由于LLM工程空间的创新性，你使用的确切指标可能会改变，但这里讨论的一般类别可能会很有用。在本节的剩余部分，你将了解更多关于这些类别以及它们中的具体评估指标。
- en: Assertion-based metrics
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于断言的指标
- en: '**Assertion-based metrics** are quantitative metrics that evaluate whether
    an AI system output meets certain criteria as defined in code. Assertion-based
    metrics resemble unit tests in traditional software engineering, where you compare
    whether a module output matches an expectation.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于断言的指标**是定量指标，评估人工智能系统的输出是否满足代码中定义的某些标准。基于断言的指标类似于传统软件工程中的单元测试，其中你比较模块输出是否与预期匹配。'
- en: You can even wrap assertion-based evaluations in a unit-testing suite. Given
    that your intelligent application likely already has a test suite, you can start
    adding evaluations to your application by including assertion-based metrics in
    the test suite. This is a great way to start evaluating your AI components without
    adding additional technical overhead to your application. However, as your application
    matures, you will likely want to create a separate evaluation suite.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你甚至可以将基于断言的评估包裹在一个单元测试套件中。鉴于你的智能应用程序可能已经有一个测试套件，你可以通过在测试套件中包含基于断言的指标来开始向应用程序中添加评估。这是一种在不向应用程序添加额外技术开销的情况下评估你的AI组件的好方法。然而，随着应用程序的成熟，你可能会想要创建一个单独的评估套件。
- en: 'Some assertion-based metrics you can use are as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用的一些基于断言的指标如下：
- en: '`==`) or not equal to (`!=`) an expected value.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`==`) 或不等于 (`!=`) 预期值。'
- en: '`>`), greater than or equal to (`>=`), less than (`<`), or less than or equal
    to (`<=`). These comparison operators are useful for evaluating numeric outputs.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`>`), 大于或等于 (`>=`), 小于 (`<`), 或小于或等于 (`<=`)。这些比较运算符对于评估数值输出很有用。'
- en: '**Sub-string match**: Evaluate whether a string output includes an expected
    sub-string.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**子字符串匹配**：评估字符串输出是否包含预期的子字符串。'
- en: '**Regular expression match**: Evaluate whether a string output matches a regular
    expression.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正则表达式匹配**：评估字符串输出是否与正则表达式匹配。'
- en: In the following code example, you have a dataset of evaluation cases for the
    travel assistant chatbot application. This evaluation focuses on the input relevancy
    guardrail. The cases include the evaluation inputs, the expected output of the
    relevancy guardrail, and the actual output of running the inputs through the relevancy
    guardrail. The evaluation metric assesses whether the actual output is equal to
    the expected output.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码示例中，你有一个旅行助手聊天机器人应用的评估案例数据集。此评估重点在于输入相关性防护栏。案例包括评估输入、相关性防护栏的预期输出以及通过相关性防护栏运行输入的实际输出。评估指标评估实际输出是否等于预期输出。
- en: 'First, install the `prettytable` Python package, which you will use to output
    results in a readable format. Install the package in your terminal:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，安装`prettytable` Python包，你将使用它以可读的格式输出结果。在终端中安装包：
- en: '[PRE0]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, execute the following Python code:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，执行以下Python代码：
- en: '[PRE1]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This code outputs the following evaluation results to the terminal:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将以下评估结果输出到终端：
- en: '[PRE2]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The preceding code example shows how you can use assertion-based evaluation
    metrics to evaluate the LLM components of an intelligent application.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码示例展示了如何使用基于断言的评估指标来评估智能应用中的LLM组件。
- en: Statistical metrics
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 统计指标
- en: Statistical metrics use algorithms to determine a score. If you have a background
    in traditional **natural language processing** (**NLP**), you may already be familiar
    with the statistical metrics for evaluating LLMs’ system outputs. Statistical
    metrics are most useful when you are using LLM systems for tasks that would use
    other NLP models, such as classification, summarization, and translation.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 统计指标使用算法来确定分数。如果你有传统**自然语言处理**（**NLP**）的背景，你可能已经熟悉了评估LLM系统输出的统计指标。统计指标在将LLM系统用于其他NLP模型会使用的任务（如分类、摘要和翻译）时最有用。
- en: 'The following are some popular NLP metrics that you can use to evaluate LLM
    system outputs:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些流行的NLP指标，你可以使用它们来评估LLM系统输出：
- en: '**Bilingual Evaluation Understudy** (**BLEU**): BLEU measures the precision
    of a model’s output against one or more reference texts. You can use the BLEU
    score to calculate how similar a model output is to a reference answer. BLEU was
    originally developed to measure the quality of machine-translated text compared
    to a reference translation.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**双语评估助手**（**BLEU**）：BLEU衡量模型输出与一个或多个参考文本的精确度。你可以使用BLEU分数来计算模型输出与参考答案的相似程度。BLEU最初是为了衡量机器翻译文本与参考翻译的质量而开发的。'
- en: You can learn more about BLEU at [https://en.wikipedia.org/wiki/BLEU](https://en.wikipedia.org/wiki/BLEU).
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在[https://en.wikipedia.org/wiki/BLEU](https://en.wikipedia.org/wiki/BLEU)了解更多关于BLEU的信息。
- en: '**Recall-Oriented Understudy for Gisting Evaluation** (**ROUGE**): ROUGE measures
    the quality of machine-generated text against one or more reference texts. In
    LLM systems, ROUGE is often used to assess how effectively an LLM summarizes reference
    texts. ROUGE is particularly useful for RAG systems, where the LLM summarizes
    the content in retrieved documents. It can also be used to measure the quality
    of a translation against a reference.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于召回的摘要评估助手**（**ROUGE**）：ROUGE衡量机器生成文本与一个或多个参考文本的质量。在LLM系统中，ROUGE通常用于评估LLM如何有效地总结参考文本。ROUGE对于RAG系统特别有用，其中LLM总结检索到的文档中的内容。它还可以用来衡量翻译与参考文本的质量。'
- en: You can learn more about ROUGE at [https://en.wikipedia.org/wiki/ROUGE_(metric)](https://en.wikipedia.org/wiki/ROUGE_(metric)).
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在[https://en.wikipedia.org/wiki/ROUGE_(metric)](https://en.wikipedia.org/wiki/ROUGE_(metric))了解更多关于ROUGE的信息。
- en: In the following code example, you have a dataset of evaluation cases for the
    travel assistant chatbot application. This evaluation focuses on the response
    generator LLM. It calculates the BLEU score for how well the actual output measures
    against a reference output. It also calculates the ROUGE score for how the answer
    summarizes the retrieved context information.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码示例中，你有一个旅行助手聊天机器人应用的评估案例数据集。此评估重点在于响应生成器LLM。它计算实际输出与参考输出的BLEU分数，以衡量实际输出与参考输出的匹配程度。它还计算ROUGE分数，以衡量答案对检索到的上下文信息的总结程度。
- en: 'First, you must install a few Python packages. The `prettytable` package output
    results in a readable format, the `sacrebleu` package calculates the BLEU score,
    and the `rouge-score` package calculates the ROUGE score. Install the packages
    in the terminal:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你必须安装几个Python包。`prettytable`包以可读的格式输出结果，`sacrebleu`包计算BLEU分数，`rouge-score`包计算ROUGE分数。在终端中安装这些包：
- en: '[PRE3]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, execute the following Python code:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，执行以下Python代码：
- en: '[PRE4]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This code outputs the following to the terminal:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将以下内容输出到终端：
- en: '[PRE5]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The preceding example demonstrates how you can use BLEU and ROUGE scores as
    evaluation metrics to measure the outputs of the travel assistant chatbot. For
    instance, in the preceding example, the fact that the BLEU and ROUGE scores are
    so different in the first `New York City` test case indicates that the model answer
    deviates significantly from the golden answer but has relatively high adherence
    to the context information. This difference implies that you could optimize the
    retriever to get more relevant context information to better satisfy the golden
    answer.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例演示了如何使用BLEU和ROUGE分数作为评估指标来衡量旅行助手聊天机器人的输出。例如，在前面的例子中，BLEU和ROUGE分数在第一个`纽约市`测试案例中如此不同，表明模型答案与黄金答案有显著偏差，但相对较高地遵循上下文信息。这种差异意味着你可以优化检索器以获取更多相关上下文信息，从而更好地满足黄金答案。
- en: These statistical metrics are most useful for assessing the quality of LLM outputs
    when the LLMs are used for more traditional NLP tasks, such as translation and
    summarization. They can also provide a useful directional metric when comparing
    different versions of the same AI system on the same evaluation dataset.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这些统计指标在LLM用于更传统的NLP任务（如翻译和摘要）时，对于评估LLM输出的质量最有用。它们还可以在比较同一评估数据集上相同AI系统的不同版本时提供有用的方向性指标。
- en: While these **quantitative metrics** can provide valuable insights into LLM
    performance, they are usually not sufficient for evaluating an LLM-powered intelligent
    application. These metrics often fail to capture the nuanced aspects of language
    generation, such as coherence, creativity, factual correctness, and contextual
    appropriateness. Therefore, you need to also create **qualitative evaluations**
    to understand how well the LLM system performs on these metrics. In the following
    sections, you will learn about using LLMs as judges and RAG-specific metrics to
    evaluate LLM output.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这些**定量指标**可以为LLM性能提供有价值的见解，但通常不足以评估由LLM驱动的智能应用。这些指标往往无法捕捉到语言生成的细微方面，如连贯性、创造力、事实正确性和上下文适宜性。因此，你需要创建**定性评估**来了解LLM系统在这些指标上的表现如何。在接下来的章节中，你将了解如何使用LLM作为裁判和RAG特定指标来评估LLM输出。
- en: LLM-as-a-judge evaluations
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM作为裁判的评价
- en: You can use an LLM to evaluate the outputs of an LLM system along qualitative
    criteria. Many LLM systems perform broad open-domain tasks, such as a chatbot
    carrying on extended conversations. Quantitative metrics, such as the ones discussed
    previously, cannot necessarily capture whether the LLM system performs these tasks
    effectively. For instance, a ROUGE score may be able to indicate how closely a
    summary tracks source documents, but it cannot tell you if the summary includes
    a hallucination. You will learn more about hallucinations in [*Chapter 11*](B22495_11.xhtml#_idTextAnchor232),
    *Common Failures of* *Generative AI*.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用LLM根据定性标准评估LLM系统的输出。许多LLM系统执行广泛的开放域任务，例如聊天机器人进行扩展对话。如前所述的定量指标并不能必然捕捉到LLM系统是否有效地执行这些任务。例如，ROUGE分数可能能够表明摘要与源文档的匹配程度，但它不能告诉你摘要是否包含幻觉。你将在[*第11章*](B22495_11.xhtml#_idTextAnchor232)，*生成式AI的常见失败*中了解更多关于幻觉的内容。
- en: Before the rise of LLMs, it was challenging to systematically evaluate qualitative
    aspects of natural language generation. Now you can use LLMs to evaluate the outputs
    of LLM-powered systems. Using LLMs to perform evaluations is called **LLM-as-a-judge**.
    Evaluating LLM output with another judge LLM is never a perfect solution. The
    judge LLM is subject to all the limitations of LLMs that require you to evaluate
    the LLM system in the first place. However, as of writing in mid-2024, LLM-as-a-judge
    seems to be the best approach to systematically perform qualitative evaluation
    of LLM output.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM兴起之前，系统地评估自然语言生成的定性方面具有挑战性。现在你可以使用LLM来评估LLM驱动系统的输出。使用LLM进行评估被称为**LLM作为裁判**。使用另一个裁判LLM评估LLM输出永远不是完美的解决方案。裁判LLM受到所有需要你首先评估LLM系统的LLM限制。然而，截至2024年中期，LLM作为裁判似乎是在系统性地进行LLM输出定性评估的最佳方法。
- en: 'A few areas where you can use LLM-as-a-judge qualitative metrics include the
    following:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下一些领域使用作为裁判的LLM定性指标：
- en: Tone and style of the response
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应的语气和风格
- en: Whether the response is personalized to the user based on input information
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应是否根据输入信息个性化
- en: Whether the response contains sensitive information, such as personally identifiable
    information, that it should not share
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应是否包含敏感信息，例如不应分享的个人身份信息
- en: Whether the response complies with a certain law or regulation
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应是否遵守某些法律或法规
- en: 'When creating LLM-as-a-judge evaluation metrics, it is useful to keep the following
    key points in mind:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建LLM作为评委的评价指标时，牢记以下关键点是有用的：
- en: Always set the LLM **temperature** to 0 for consistent outputs. Temperature
    is a hyperparameter for LLMs that controls the randomness of their predictions.
    A temperature of 0 produces deterministic outputs. A higher temperature produces
    more diverse and less consistent outputs, which can be preferable if the LLM is
    performing creative work. However, you want the evaluations to be as consistent
    as possible.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总是设置LLM的**温度**为0以获得一致的输出。温度是控制LLM预测随机性的超参数。温度为0产生确定性输出。更高的温度产生更多样化和一致性较差的输出，如果LLM在进行创造性工作，这可能更可取。然而，你希望评估尽可能一致。
- en: Better LLMs tend to be better evaluators. LLMs that rank higher on benchmarks
    tend to produce evaluation results that are more consistent with expectations.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更好的LLM往往也是更好的评估者。在基准测试中排名更高的LLM往往会产生更符合预期的评估结果。
- en: '**Multi-shot prompting** often improves evaluator accuracy. To perform multi-shot
    prompting, include examples of inputs and the outputs the model should provide,
    in addition to including the evaluation criteria in the model prompt. These examples
    often help the model perform better evaluations. Generally, you should include
    at least five examples that represent a diverse set of evaluation scenarios.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多轮提示**通常可以提高评估者的准确性。要执行多轮提示，除了在模型提示中包含评估标准外，还应包括输入示例和模型应提供的输出示例。这些示例通常有助于模型进行更好的评估。通常，你应该包括至少五个代表不同评估场景的示例。'
- en: '**Chain-of-thought prompting** often further improves LLM-as-a-judge evaluator
    performance. In a chain-of-thought prompt, you ask the model to explain its thought
    process before producing a final answer.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**思维链提示**通常可以进一步提高LLM作为评委的评估性能。在思维链提示中，你要求模型在给出最终答案之前解释其思维过程。'
- en: Every LLM-as-a-judge evaluation metric should only evaluate a single qualitative
    aspect. Focusing on a single aspect makes the evaluation task easier for the LLM
    to interpret. If you need to assess multiple aspects, create multiple LLM-as-a-judge
    evaluation metrics.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个LLM作为评委的评价指标应仅评估一个定性方面。专注于单一方面使得评估任务对LLM来说更容易理解。如果你需要评估多个方面，则应创建多个LLM作为评委的评价指标。
- en: The LLM you use matters. Different LLMs can produce different outcomes on the
    same evaluation task. Be consistent in using the same LLM for all evaluations
    with a metric. If you change the LLM used by a metric, you cannot reliably compare
    the results produced with different LLMs.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你使用的LLM很重要。不同的LLM在相同的评估任务上可以产生不同的结果。在所有使用指标的评估中保持使用相同的LLM是一致的。如果你更改了指标的LLM，则无法可靠地比较由不同LLM产生的结果。
- en: Produce structured evaluation output. The judge LLM should produce structured
    outputs, such as pass or fail, or a score of integers 0-5\. You can then normalize
    these scores. For instance, if the judge LLM outputs `pass` or `fail`, then `pass`
    is normalized as 1 and `fail` as 0\. If the judge LLM outputs integers `0`-`5`,
    `0` is normalized as 0, `1` as 0.2, `2` as 0.4... and `5` as 1.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 产生结构化评估输出。评委LLM应产生结构化输出，例如通过或失败，或整数0-5的分数。然后你可以对这些分数进行归一化。例如，如果评委LLM输出`pass`或`fail`，则`pass`归一化为1，`fail`归一化为0。如果评委LLM输出整数`0`-`5`，则`0`归一化为0，`1`归一化为0.2，`2`归一化为0.4...，`5`归一化为1。
- en: The following code example uses an LLM as a judge to evaluate whether the travel
    assistant chatbot provides a suggestion to the user in its response. The LLM evaluator
    also includes few-shot examples to improve the judge model’s understanding of
    the task.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例使用LLM作为评委来评估旅行助手聊天机器人在其响应中是否向用户提供了建议。LLM评估者还包括少量示例，以改善评委模型对任务的了解。
- en: The code example runs the evaluation over a dataset of inputs and outputs. Note
    that this is a reference-free evaluation, as the LLM-as-a-judge does not need
    a reference answer to determine whether the chatbot provides irrelevant answers.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 代码示例在输入和输出的数据集上运行评估。请注意，这是一个无参考评估，因为LLM作为评委不需要参考答案来确定聊天机器人是否提供了不相关的答案。
- en: 'First, you must install a few Python packages. The `prettytable` package output
    results in a readable format and the `openai` package calls the OpenAI API to
    use the GPT-4o LLM. Install the packages in your terminal:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你必须安装几个 Python 包。`prettytable` 包以可读的格式输出结果，而 `openai` 包调用 OpenAI API 以使用
    GPT-4o LLM。在终端中安装这些包：
- en: '[PRE6]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, execute the code:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，执行以下代码：
- en: '[PRE7]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This code outputs the following to the terminal:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码将以下内容输出到终端：
- en: '[PRE8]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The preceding example demonstrates how to create a simple LLM-as-a-judge metric
    to evaluate whether a response includes a recommendation. You can extend the techniques
    to create additional LLM-as-a-judge metrics to look at various aspects of your
    LLM system. In the next section, you will learn about some more complex LLM-as-a-judge
    metrics for evaluating RAG systems.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例演示了如何创建一个简单的 LLM-as-a-judge 指标来评估一个响应是否包含推荐。你可以扩展这些技术来创建额外的 LLM-as-a-judge
    指标，以查看你的 LLM 系统的各个方面。在下一节中，你将了解一些更复杂的 LLM-as-a-judge 指标，用于评估 RAG 系统。
- en: RAG metrics
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RAG 指标
- en: RAG is currently one of the most popular ways to use LLMs. A distinct set of
    metrics has emerged to measure the efficacy of a RAG system. These metrics all
    use an LLM as a judge.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 目前是使用 LLM 最流行的方式之一。一套独特的指标已经出现，用于衡量 RAG 系统的有效性。这些指标都使用 LLM 作为评判者。
- en: 'These metrics focus on the two core components of any RAG system, retrieval
    and generation:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标侧重于任何 RAG 系统的两个核心组件：检索和生成：
- en: '**Retrieval**: This component fetches relevant information from external sources.
    It often combines vector search with LLM-based pre- and post-processing.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索**：此组件从外部来源检索相关信息。它通常结合向量搜索与基于 LLM 的预处理和后处理。'
- en: '**Generation**: This component uses an LLM to produce text outputs.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生成**：此组件使用 LLM 生成文本输出。'
- en: 'The following LLM-as-a-judge metrics are often used to evaluate RAG systems:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 LLM-as-a-judge 指标常用于评估 RAG 系统：
- en: '**Answer faithfulness**: Measures how grounded the generated response is to
    the retrieved context information'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**答案忠诚度**：衡量生成的响应与检索到的上下文信息的相关性'
- en: '**Answer relevance**: Measures how relevant the generated response is to the
    provided input'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**答案相关性**：衡量生成的响应与提供的输入的相关性'
- en: '**Ragas** is a popular Python library that includes modules implementing these
    metrics along with others for RAG evaluation. In the remainder of this section,
    you will learn how Ragas implements these metrics. To learn more about Ragas and
    its available metrics, refer to its documentation ([https://docs.ragas.io/en/stable/index.html](https://docs.ragas.io/en/stable/index.html)).'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**Ragas** 是一个流行的 Python 库，它包含实现这些指标以及其他用于 RAG 评估的模块。在本节的剩余部分，你将了解 Ragas 如何实现这些指标。要了解更多关于
    Ragas 及其可用指标的信息，请参阅其文档 ([https://docs.ragas.io/en/stable/index.html](https://docs.ragas.io/en/stable/index.html))。'
- en: Answer faithfulness
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 答案忠诚度
- en: Answer faithfulness is an evaluation metric for the generation component of
    RAG systems. It measures the extent to which the information in the generated
    response aligns with the retrieved context information.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 答案忠诚度是 RAG 系统生成组件的评估指标。它衡量生成响应中的信息与检索到的上下文信息的一致程度。
- en: By identifying factual discrepancies between the generated answer and the retrieved
    context, the answer faithfulness metric can help identify if there are any hallucinations
    in the answer.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 通过识别生成答案与检索到的上下文之间的事实差异，答案忠诚度指标可以帮助识别答案中是否存在任何幻觉。
- en: 'Ragas includes a module to measure faithfulness. It calculates faithfulness
    with this formula:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Ragas 包含一个用于测量忠诚度的模块。它使用以下公式计算忠诚度：
- en: '![](img/B22495_09_Equation.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_09_Equation.jpg)'
- en: 'The data to input into the faithfulness formula is derived with these steps:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据输入到忠诚度公式中的步骤如下：
- en: Extract all claims from the generated response with an LLM.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 LLM 从生成的响应中提取所有断言。
- en: Locate each claim in the reference material with an LLM.
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 LLM 定位参考材料中的每个断言。
- en: Calculate the proportion of claims that can be inferred from the context information.
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算可以从上下文信息中推断出的断言比例。
- en: The following code example uses the Ragas faithfulness metric on an example
    set of input, contexts, and RAG system outputs.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例使用 Ragas 忠诚度指标对一个示例输入集、上下文和 RAG 系统输出进行操作。
- en: 'First, you must install a few Python packages. The `ragas` package includes
    the response faithfulness metric and a reporting module. The `langchain-openai`
    package lets you pass an OpenAI model to Ragas. This example uses the GPT-4o mini
    model. Ragas also depends on the `datasets` package to format inputs. Install
    the packages in your terminal:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你必须安装几个Python包。`ragas`包包括响应忠实度指标和报告模块。`langchain-openai`包允许你将OpenAI模型传递给Ragas。本例使用GPT-4o
    mini模型。Ragas还依赖于`datasets`包来格式化输入。在终端中安装这些包：
- en: '[PRE9]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then, run the following code to perform the evaluation:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，运行以下代码以执行评估：
- en: '[PRE10]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Executing this code outputs results resembling the following to the terminal:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此代码将在终端输出类似以下的结果：
- en: '[PRE11]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: You can see from the results that the Ragas evaluator deemed the first and third
    examples faithful, and not the second one.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 从结果中可以看出，Ragas评估者认为第一和第三种示例是忠实的，而第二种则不是。
- en: 'In the following section, you will learn how to use another RAG evaluation
    metric: answer relevance.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将学习如何使用另一个RAG评估指标：答案相关性。
- en: Answer relevance
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 答案相关性
- en: Answer relevance measures how relevant the output of a RAG system is to the
    input. This metric is useful because it determines how well a RAG system responds
    to the provided input.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 答案相关性衡量RAG系统的输出与输入的相关性。这个指标很有用，因为它决定了RAG系统对提供的输入的响应效果。
- en: 'Ragas uses the input, generated output, and context information retrieved to
    generate that output in its answer relevance metric. It calculates the answer
    relevance evaluation metric score with the following steps:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: Ragas使用输入、生成的输出和检索到的上下文信息来生成答案相关性指标中的输出。它通过以下步骤计算答案相关性评估指标分数：
- en: Use an LLM to generate a list of questions from the generated response.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用LLM从生成的响应中生成一个问题列表。
- en: Create a vector embedding for each LLM-generated question from the previous
    step. Also, create a vector embedding for the initial input query.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为上一步生成的每个LLM生成的提问创建一个向量嵌入。同时，也为初始输入查询创建一个向量嵌入。
- en: Calculate the cosine similarity between the original question embedding and
    each generated question embedding.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算原始问题嵌入和每个生成的提问嵌入之间的余弦相似度。
- en: The answer relevance score is the mean of the cosine similarities between the
    original question and each generated question.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 答案相关性分数是原始问题和每个生成的提问之间余弦相似度的平均值。
- en: Ragas assumes that if the generated answer is highly relevant to the original
    question, then the questions that can be derived from this answer should be semantically
    similar to the original question. This assumption is based on the idea that a
    relevant answer contains information that directly addresses the query. Therefore,
    the judge LLM should be able to *reverse-engineer* questions that closely align
    with the original input.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: Ragas假设，如果生成的答案与原始问题高度相关，那么从这个答案中可以导出的问题应该与原始问题在语义上相似。这个假设基于这样一个观点，即一个相关的答案包含直接回答查询的信息。因此，评判LLM应该能够*逆向工程*与原始输入紧密对齐的问题。
- en: The following code example uses the Ragas answer relevance metric on an example
    set of input, contexts, and RAG system outputs.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码示例使用Ragas答案相关性指标在一个示例输入、上下文和RAG系统输出集上。
- en: 'First, you must install a few Python packages. Note that these are the same
    dependencies as for the Ragas faithfulness evaluation example in the previous
    section. The `ragas` package includes the response answer relevance metric and
    a reporting module. The `langchain-openai` package lets you pass an OpenAI model
    to Ragas. This example uses the GPT-4o mini model. Ragas also depends on the `datasets`
    package to format inputs. Install the packages in your terminal:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你必须安装几个Python包。注意，这些与上一节中Ragas忠实度评估示例中的依赖项相同。`ragas`包包括响应答案相关性指标和报告模块。`langchain-openai`包允许你将OpenAI模型传递给Ragas。本例使用GPT-4o
    mini模型。Ragas还依赖于`datasets`包来格式化输入。在终端中安装这些包：
- en: '[PRE12]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then, run the following code to perform the evaluation:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，运行以下代码以执行评估：
- en: '[PRE13]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Executing this code outputs the following results to the terminal:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此代码将在终端输出以下结果：
- en: '[PRE14]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You can see from the results that the first and third cases were relevant, while
    the second was not. This makes sense because the first and third had quite relevant
    contexts, whereas the second had no context information at all.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 从结果中可以看出，第一和第三种情况是相关的，而第二种情况则不是。这很合理，因为第一和第三种情况有相当相关的上下文，而第二种情况则完全没有上下文信息。
- en: The Ragas answer relevance metric has noteworthy limitations. The quality of
    the underlying language model significantly impacts the metric’s effectiveness,
    as it relies heavily on the LLM’s capacity to generate appropriate questions from
    the given answer. The metric may also struggle with handling complex or multi-faceted
    queries, particularly when the answer doesn’t comprehensively address all aspects
    of the original question, potentially resulting in an incomplete assessment of
    relevance for more intricate topics.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: Ragas 答案相关性指标存在一些显著的局限性。底层语言模型的质量会显著影响指标的有效性，因为它严重依赖于 LLM 从给定答案中生成适当问题的能力。该指标在处理复杂或多方面的查询时也可能遇到困难，尤其是当答案没有全面涵盖原始问题的所有方面时，可能会对更复杂主题的相关性进行不完整的评估。
- en: 'There are other approaches that you can take to evaluate answer relevance.
    For instance, the **DeepEval** evaluation framework calculates answer relevancy
    with the following strategy:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 有其他方法可以用来评估答案相关性。例如，**DeepEval** 评估框架采用以下策略来计算答案相关性：
- en: Extract all statements in an output with an LLM.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 LLM 从输出中提取所有陈述。
- en: Use the same LLM to determine which statements are relevant to the input.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用相同的语言模型（LLM）来确定哪些陈述与输入相关。
- en: Calculate answer relevance as the number of relevant statements divided by the
    total number of statements.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将答案相关性计算为相关陈述数除以总陈述数。
- en: The difference between the Ragas and DeepEval strategies to calculating the
    answer relevancy metric demonstrates that the AI engineering field is still converging
    on how to calculate these metrics, even if it is becoming standard to evaluate
    based on some form of these metrics.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: Ragas 和 DeepEval 策略在计算答案相关性指标方面的差异表明，人工智能工程领域仍在收敛于如何计算这些指标，即使基于这些指标形式之一进行评估已成为标准。
- en: Using the RAG evaluation metrics discussed in this section, you can measure
    how well your RAG system is performing and measure improvement in the system over
    time. You can also experiment with other RAG metrics in frameworks such as Ragas
    or DeepEval.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 使用本节讨论的 RAG 评估指标，你可以衡量你的 RAG 系统的表现，并衡量系统随时间改进的情况。你还可以在 Ragas 或 DeepEval 等框架中尝试其他
    RAG 指标。
- en: In the next section, you will learn how you can perform a manual human review
    of your data to augment the automated evaluation metrics discussed in this section.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将学习如何手动进行人工审查你的数据，以增强本节讨论的自动评估指标。
- en: Human review
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工审查
- en: 'While LLMs can be effective tools for qualitative evaluation, they are often
    inferior to the original form of non-artificial intelligence: humans. **Human
    review** is considered the gold standard of qualitative review.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 LLM 可以是定性评估的有效工具，但它们通常不如原始的非人工智能形式：人类。**人工审查**被认为是定性审查的黄金标准。
- en: When using human review, you should take into account that humans likely prefer
    simpler rating metrics that do not require them to do complex multi-step calculations,
    such as the answer relevance metric described earlier in this chapter. Instead,
    give human reviewers simple rating systems. Pass/fail criteria are the simplest
    and can be normalized to 0 or 1\. You can also use a rating system such as 0-5,
    which can be normalized to 0, 0.2, and so on until 1.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用人工审查时，你应该考虑到人类可能更喜欢简单的评分指标，这些指标不需要他们进行复杂的多步骤计算，例如本章前面描述的答案相关性指标。相反，给人工审查员简单的评分系统。通过/不通过标准是最简单的，可以归一化到
    0 或 1。你也可以使用 0-5 的评分系统，可以归一化到 0、0.2 等等，直到 1。
- en: Human reviewer free-form feedback can be particularly valuable, as this open-ended
    feedback can provide insight that would not be captured by the rating metric alone.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 人工审查员的无格式反馈特别有价值，因为这种开放式的反馈可以提供仅通过评分指标无法捕捉到的见解。
- en: It is also useful to capture who the human reviewer is for an evaluation. You
    can use this to follow up with the person if need be or to track how some individuals
    perform ratings as compared to others.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 记录人类审查员是谁对于评估来说也很有用。你可以使用这个信息在需要时跟进这个人，或者跟踪某些个人与其他人相比的评分表现。
- en: 'Despite the qualitative advantage of human review, it also comes with its own
    set of limitations:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管人工审查具有定性优势，但也伴随着其自身的局限性：
- en: '**Cost**: Human reviewers tend to be more expensive than using an LLM as a
    judge.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本**：人工审查员通常比使用 LLM 作为评判者更昂贵。'
- en: '**Time**: Human reviewers usually take much longer than using an LLM as a judge.
    You also cannot parallelize a single human like you can an AI model.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间**: 人类审阅者通常比使用LLM作为法官花费的时间更长。你也不能像AI模型那样并行化单个人类。'
- en: '**Tedium**: Evaluating the output of LLMs can be an incredibly tedious task
    for human reviewers. Many people do not want to perform evaluations, so it can
    be difficult to find people to consistently perform the evaluations.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**乏味**: 评估LLM的输出对于人类审阅者来说可能是一项极其乏味的工作。许多人不愿意进行评估，因此很难找到能够持续进行评估的人。'
- en: '**Elasticity**: Often, you need to run large numbers of evaluations as part
    of your software development process or at regular intervals. It can be hard to
    find human reviewers to perform an evaluation exactly when you need them to.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**弹性**: 通常，在软件开发过程中或定期间隔内，你需要运行大量评估。很难找到合适的人类审阅者在你需要的时候进行评估。'
- en: '**Inconsistency**: Human reviewers can be inconsistent in their evaluation.
    Different people might evaluate the same case in different ways. The same person
    could even evaluate the same case differently at a different moment, depending
    on factors such as tiredness, mood, and environment.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**不一致性**: 人类审阅者在评估中可能存在不一致性。不同的人可能会以不同的方式评估相同的案例。同一个人在不同的时刻，根据疲劳、情绪和环境等因素，甚至可能对相同的案例进行不同的评估。'
- en: Given the strengths and weaknesses of using humans as reviewers, you must carefully
    consider when to use human review. Human review is probably the most useful for
    conducting initial qualitative evaluation. Human reviewers can set a baseline
    for application performance that you can measure against with a reasonably high
    degree of confidence.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到使用人类作为审阅者的优点和缺点，你必须仔细考虑何时使用人类审阅。人类审阅可能对于进行初步定性评估最有用。人类审阅者可以为应用程序性能设定一个基线，你可以以相当高的置信度对其进行衡量。
- en: You can also use human reviews as a baseline to measure LLM-as-a-judge metrics
    against. You can try to get the LLM-as-a-judge metric to conform as closely as
    possible to the human review results.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以将人类审阅作为基线来衡量LLM作为法官的指标。你可以尝试使LLM作为法官的指标尽可能接近人类审阅的结果。
- en: Additionally, your LLM-as-a-judge metric can use examples from the human review
    in its prompt to demonstrate to the LLM what the classification should look like
    as a form of multi-shot prompting. Multi-shot prompting has been shown to increase
    model performance meaningfully.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你的作为法官的LLM指标可以使用人类审阅中的示例在其提示中向LLM展示分类应该看起来像什么，作为一种多轮提示的形式。多轮提示已被证明可以显著提高模型性能。
- en: Human review is one of the most effective means of qualitative evaluation, if
    also a slow and expensive one.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 人类审阅是定性评估中最有效的方法之一，尽管它既慢又贵。
- en: Evaluations as guardrails
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估作为护栏
- en: A **guardrail** is a mechanism that prevents the AI from producing an undesirable
    or incorrect output. Guardrails ensure that generated responses are within acceptable
    boundaries and align with your application’s quality, ethical, and relevance standards.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '**护栏**是一种防止AI产生不希望或不正确输出的机制。护栏确保生成的响应在可接受的范围内，并与你的应用程序的质量、伦理和相关性标准保持一致。'
- en: Previously in this chapter, you learned about **reference-free evaluations**.
    These are evaluations that only require an input without a reference output or
    golden answer. You can also use reference-free evaluations as guardrails to help
    ensure the AI system performs correctly. For example, in the *RAG metrics* section,
    you looked at the answer relevance metric. You could use this as a guardrail in
    the travel assistant chatbot to ensure that the chatbot only responds with answers
    that meet a certain relevancy threshold. If the answer doesn’t meet this threshold,
    you could perform some additional application logic before responding to the user.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的前面部分，你学习了关于**无参考评估**的内容。这些评估只需要输入，而不需要参考输出或黄金答案。你还可以使用无参考评估作为护栏，以确保AI系统正确运行。例如，在*RAG指标*部分，你看到了答案相关性指标。你可以在旅行助手聊天机器人中使用这个指标作为护栏，以确保聊天机器人只响应符合一定相关性的答案。如果答案不符合这个标准，你可以在响应用户之前执行一些额外的应用程序逻辑。
- en: Throughout this chapter, you have learned how to use evaluations to improve
    the quality of your intelligent application. Using reference-free evaluations
    as guardrails lets you extend the utility of your evaluations to a component of
    the application itself.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你已经学习了如何使用评估来提高你智能应用程序的质量。使用无参考评估作为安全带让你可以扩展评估的效用，使其成为应用程序本身的一个组件。
- en: Summary
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you explored methods for evaluating LLM outputs in your intelligent
    application. You learned what LLM evaluation is and why it’s important for your
    intelligent application. Model benchmarking is a form of evaluation that can help
    you determine which LLMs to use in your application.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你探讨了评估你智能应用程序中LLM输出的方法。你学习了LLM评估是什么以及为什么它对你的智能应用程序很重要。模型基准测试是一种评估形式，可以帮助你确定在你的应用程序中使用哪些LLM。
- en: Once your application has functional AI modules, you can make evaluation datasets
    and run metrics on them to measure performance and change over time. In addition
    to the automated evaluations, you can perform manual human review to further measure
    application quality. Finally, you can use reference-free metrics as guardrails
    within your application.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的应用程序拥有功能性的AI模块，你就可以创建评估数据集并在其上运行指标来衡量性能和随时间的变化。除了自动评估之外，你还可以进行人工审查以进一步衡量应用程序的质量。最后，你可以在应用程序中使用无参考指标作为安全带。
- en: In the next chapter, you will learn how to optimize the semantic data model
    to enhance retrieval accuracy and overall performance.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何优化语义数据模型以增强检索准确性和整体性能。
