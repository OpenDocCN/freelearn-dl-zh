- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Working with MXNet and Visualizing Datasets – Gluon and DataLoader
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MXNet和数据集可视化 – Gluon和DataLoader
- en: In the previous chapter, we learned how to set up MXNet. We also verified how
    MXNet could leverage our hardware to provide maximum performance. Before applying
    **deep learning** (**DL**) to solve specific problems, we need to understand how
    to load, manage, and visualize the datasets we will be working with. In this chapter,
    we will start using MXNet to analyze some toy datasets in the domains of numerical
    regression, data classification, image classification, and text classification.
    To manage those tasks efficiently, we will see new MXNet libraries and functions
    such as Gluon (an API for DL) and DataLoader.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们学习了如何设置MXNet。我们还验证了MXNet如何利用我们的硬件以提供最佳性能。在应用**深度学习**（**DL**）解决特定问题之前，我们需要了解如何加载、管理和可视化我们将使用的数据集。在本章中，我们将开始使用MXNet分析一些玩具数据集，涉及数值回归、数据分类、图像分类和文本分类领域。为了高效处理这些任务，我们将看到新的MXNet库和函数，如Gluon（用于DL的API）和DataLoader。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Understanding regression datasets – loading, managing, and visualizing the *House*
    *Sales* dataset
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解回归数据集 – 加载、管理和可视化*House* *Sales*数据集
- en: Understanding classification datasets – loading, managing, and visualizing the
    Iris dataset
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解分类数据集 – 加载、管理和可视化鸢尾花数据集
- en: Understanding image datasets – loading, managing, and visualizing the Fashion-MNIST
    dataset
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解图像数据集 – 加载、管理和可视化时尚-MNIST数据集
- en: Understanding text datasets – loading, managing, and visualizing the Enron Email
    dataset
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解文本数据集 – 加载、管理和可视化安然电子邮件数据集
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: Apart from the technical requirements specified in the *Preface*, no other requirements
    apply to this chapter.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 除了*前言*中指定的技术要求外，本章不适用其他要求。
- en: 'The code for this chapter can be found at the following GitHub URL: [https://github.com/PacktPublishing/Deep-Learning-with-MXNet-Cookbook/tree/main/ch02](https://github.com/PacktPublishing/Deep-Learning-with-MXNet-Cookbook/tree/main/ch02)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在以下GitHub URL找到：[https://github.com/PacktPublishing/Deep-Learning-with-MXNet-Cookbook/tree/main/ch02](https://github.com/PacktPublishing/Deep-Learning-with-MXNet-Cookbook/tree/main/ch02)
- en: Furthermore, you can directly access each recipe from Google Colab; for example,
    for the first recipe of this chapter, visit [https://colab.research.google.com/github/PacktPublishing/Deep-Learning-with-MXNet-Cookbook/blob/main/ch02/2_1_Toy_Dataset_for_Regression_Load_Manage_and_Visualize_House_Sales_Dataset.ipynb](https://colab.research.google.com/github/PacktPublishing/Deep-Learning-with-MXNet-Cookbook/blob/main/ch02/2_1_Toy_Dataset_for_Regression_Load_Manage_and_Visualize_House_Sales_Dataset.ipynb).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您可以直接从Google Colab访问每个配方；例如，对于本章的第一个配方，请访问[https://colab.research.google.com/github/PacktPublishing/Deep-Learning-with-MXNet-Cookbook/blob/main/ch02/2_1_Toy_Dataset_for_Regression_Load_Manage_and_Visualize_House_Sales_Dataset.ipynb](https://colab.research.google.com/github/PacktPublishing/Deep-Learning-with-MXNet-Cookbook/blob/main/ch02/2_1_Toy_Dataset_for_Regression_Load_Manage_and_Visualize_House_Sales_Dataset.ipynb)。
- en: Understanding regression datasets – loading, managing, and visualizing the House
    Sales dataset
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解回归数据集 – 加载、管理和可视化房屋销售数据集
- en: 'The training process of **machine learning** (**ML**) models can be divided
    into three main sub-groups:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）模型的训练过程可以分为三个主要子组：'
- en: '**Supervised learning (SL)**: The expected outputs are known for at least some
    data'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习（SL）**：至少某些数据的预期输出是已知的'
- en: '**Unsupervised learning (UL)**: The expected outputs are not known but the
    data has some features that could help with understanding its internal distribution'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习（UL）**：预期输出未知，但数据具有某些特征，有助于理解其内部分布'
- en: '**Reinforcement learning (RL)**: An agent explores the environment and makes
    decisions based on the inputs acquired from the environment'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**强化学习（RL）**：一个代理探索环境，并根据从环境获取的输入做出决策'
- en: 'There is also an approach that falls in between the first two sub-groups called
    **weakly SL**, where there are not enough known outputs to follow an SL approach
    for one of the following reasons:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种方法介于前两个子组之间，称为**弱监督学习（weakly SL）**，其中没有足够已知的输出来跟随SL方法，原因之一是：
- en: The outputs are inaccurate
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出不准确
- en: Only some of the output features are known (incomplete)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有部分输出特征是已知的（不完整）
- en: They are not exactly the expected outputs but are connected/related to the task
    we intend to achieve (inexact)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们并非完全符合预期的输出，但与我们打算实现的任务相关联（不精确）
- en: 'With SL, one of the most common problem types is **regression**. In regression
    problems, we want to estimate numerical outputs given a variable number of input
    features. In this recipe, we will analyze a toy regression dataset from Kaggle:
    *House Sales in King* *County, USA*.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SL，最常见的问题类型之一是**回归**。在回归问题中，我们希望根据输入特征的数量来估算数值输出。在这个案例中，我们将分析一个来自Kaggle的玩具回归数据集：*美国金县的房屋销售*。
- en: 'The House Sales dataset presents the problem of estimating the price of a house
    (in $) given the following 19 features:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 房屋销售数据集呈现了一个问题，即根据以下19个特征来估算房价（以$为单位）：
- en: '`Date` of the home sale'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 房屋销售的`Date`
- en: '`Number` `of` `bedrooms`'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`卧室` `数量`'
- en: '`Number` `of` `bathrooms`, where `0.5` accounts for a room with a toilet but
    no shower'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`浴室` `数量`，其中`0.5`表示一个有厕所但没有淋浴的房间'
- en: '`Sqft_living`: Square feet of the apartment’s interior living space'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Sqft_living`：公寓内部生活空间的平方英尺数'
- en: '`Sqft_lot`: Square feet of the land space'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Sqft_lot`：土地面积的平方英尺数'
- en: '`Number` `of` `floors`'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`楼层` `数量`'
- en: '`Waterfront` view or not'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有`Waterfront`视野
- en: An index from 0 to 4 of how good the view of the property is
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该物业视野好坏的指数，范围从0到4
- en: An index from 1 to 5 on the condition of the apartment
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 房屋状况的指数，范围从1到5
- en: '`Grade`: An index from 1 to 13, with 1 being the worst and 13 the best'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Grade`：1到13的指数，1为最差，13为最好'
- en: '`Sqft_above`: Square feet of the interior housing space that is above ground
    level'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Sqft_above`：地面以上的住宅空间的平方英尺数'
- en: '`Sqft_basement`: Square feet of the interior housing space that is below ground
    level'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Sqft_basement`：地下室内部住宅空间的平方英尺数'
- en: '`Yr_built`: The year the house was initially built'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Yr_built`：房屋最初建造的年份'
- en: '`Yr_renovated`: The year of the house’s last renovation'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Yr_renovated`：房屋最后一次翻新的年份'
- en: '`Zipcode` area the house is in'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Zipcode`：房屋所在的邮政编码区域'
- en: Latitude (`Lat`)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纬度（`Lat`）
- en: Longitude (`Long`)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经度（`Long`）
- en: '`Sqft_living15`: Square feet of interior housing living space for the nearest
    15 neighbors'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Sqft_living15`：最近15个邻居的住宅内部生活空间的平方英尺数'
- en: '`Sqft_lot15`: Square feet of the land lots of the nearest 15 neighbors'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Sqft_lot15`：最近15个邻居的土地面积的平方英尺数'
- en: These data features are provided for *21,613* houses along with the price (value
    to be estimated).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据特征提供了*21,613*套房屋及其价格（需估算的值）。
- en: Getting ready
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: The following dataset is provided under the *CC0 Public Domain* license and
    can be downloaded from [https://www.kaggle.com/harlfoxem/housesalesprediction](https://www.kaggle.com/harlfoxem/housesalesprediction).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 以下数据集采用*CC0 公共领域*许可证提供，可从[https://www.kaggle.com/harlfoxem/housesalesprediction](https://www.kaggle.com/harlfoxem/housesalesprediction)下载。
- en: 'To read the data, we are going to use a very well-known library to manage data,
    `pandas`, and we will use the most common data structure for the library, `matplotlib`,
    `pyplot`, and `seaborn` libraries. Therefore, we must run the following code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 为了读取数据，我们将使用一个非常著名的库——`pandas`，并将使用该库中最常见的数据结构，`matplotlib`，`pyplot`和`seaborn`库。因此，我们必须运行以下代码：
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you do not have these libraries installed, they can be easily installed
    with the following terminal commands:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有安装这些库，可以通过以下终端命令轻松安装：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Therefore, to load the data, we can simply retrieve the file containing the
    dataset (available in the GitHub repository for the book) and process it:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了加载数据，我们可以简单地检索包含数据集的文件（该文件可在本书的GitHub存储库中找到）并进行处理：
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This is all we need to start working with our regression dataset.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们开始使用回归数据集所需的一切。
- en: How to do it...
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'In this section, we will run an **exploratory data analysis** (**EDA**) that
    will help us understand which features are important (and which are not) to predict
    the price of a house:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将进行一次**探索性数据分析**（**EDA**），帮助我们理解哪些特征对预测房价很重要（哪些不重要）：
- en: Data structure
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据结构
- en: Correlation study
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关性研究
- en: Living square feet analysis, square feet above ground level analysis, and neighbors’
    living square feet analysis
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生活平方英尺分析、地面以上平方英尺分析和邻居生活平方英尺分析
- en: Grade analysis
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等级分析
- en: Rooms (bedrooms and bathrooms) analysis
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 房间（卧室和浴室）分析
- en: Views analysis
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 景观分析
- en: Year-built and year-renovated analysis
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 年建造和翻新年份分析
- en: Location analysis
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 位置分析
- en: Data structure
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据结构
- en: 'Let’s analyze what our data looks like. For this, we will use common operations
    on `pandas` DataFrames:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下我们的数据是什么样的。为此，我们将使用常见的`pandas` DataFrame操作：
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'From the output, we can draw the following conclusions:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中，我们可以得出以下结论：
- en: The data is complete (all columns have 21,613 values, as expected).
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据完整（所有列都有21,613个值，如预期）。
- en: There are no `NULL` values (the data is clean!).
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有`NULL`值（数据很干净！）。
- en: Apart from the features described previously, there is a feature called `id`.
    This feature is not needed as the index already allows us to uniquely identify
    each property.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了前述的特征，还有一个叫做`id`的特征。由于索引已经能够唯一标识每个属性，因此这个特征是不需要的。
- en: 'In order to grasp what the values look like, let’s display the first five properties:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了掌握数值的外观，让我们显示前五个属性：
- en: '[PRE4]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'So far, we have had a look at the features. Now, let’s take a look at the price
    distribution:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看过了这些特征。现在，让我们看看价格分布：
- en: '[PRE5]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'These commands will display a histogram of prices that shows how many houses
    in the dataset have a certain price (column selected in the previous commands).
    Histograms work in ranges (also known as *buckets* or *bins*); in our case, we
    have chosen 24\. As the maximum price is $8M, when applying 24 ranges, we have
    3 ranges per million dollars, specifically (all values in millions of $): [0 –
    0.33), [0.33 - 0.66), [0.66 - 1), ... until [7.66 - 8].'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这些命令将显示一个价格直方图，显示数据集中有多少房屋具有某个价格（在前面命令中选择的列）。直方图以范围（也称为*桶*或*箱*）工作；在我们的情况下，我们选择了24个。因为最大价格为8百万美元，所以在应用24个范围时，我们每百万美元有3个范围，具体来说是（所有值以百万美元为单位）：[0
    – 0.33)、[0.33 - 0.66)、[0.66 - 1)，直到[7.66 - 8]。
- en: 'The following is the output:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '![Figure 2.1 – Price distribution](img/B16591_02_1.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图2.1 – 价格分布](img/B16591_02_1.jpg)'
- en: Figure 2.1 – Price distribution
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.1 – 价格分布
- en: Correlation study
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关性研究
- en: Here, we will analyze how each feature correlates with each other and, most
    importantly, how each feature correlates with the price.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将分析每个特征之间的相关性，尤其是每个特征与价格的相关性。
- en: 'First, as previously discussed, we are going to remove the `id` feature:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，正如之前讨论的那样，我们将删除`id`特征：
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We can now compute the pairwise correlation diagram:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以计算成对相关性图表：
- en: '[PRE7]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To easily visualize the calculated correlations, we will plot a heatmap:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更直观地显示计算出的相关性，我们将绘制一个热力图：
- en: '[PRE8]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'These code statements yield the following result:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这些代码语句产生以下结果：
- en: '![Figure 2.2 – House features correlation matrix](img/B16591_02_2.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图2.2 – 房屋特征相关矩阵](img/B16591_02_2.jpg)'
- en: Figure 2.2 – House features correlation matrix
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2 – 房屋特征相关矩阵
- en: Note in *Figure 2**.2* that the darker the cell is, the larger the correlation
    value.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图2.2*中请注意，单元格越暗，相关值越大。
- en: 'To emphasize the first row (which is the most important as it shows the relationship
    between price and the input features), we will run the following code:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 为了强调第一行（它显示了价格与输入特征之间的关系最重要），我们将运行以下代码：
- en: '[PRE9]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'And we have the following result:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下结果：
- en: '![Figure 2.3 – House features: price correlation](img/B16591_02_3.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图2.3 – 房屋特征：价格相关性](img/B16591_02_3.jpg)'
- en: 'Figure 2.3 – House features: price correlation'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.3 – 房屋特征：价格相关性
- en: 'The following conclusions can be drawn from *Figures 2.2* and *2.3*:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图2.2*和*2.3*可以得出以下结论：
- en: '`Living square feet` and `grade` are the most highly correlated features with
    price (0.7 and 0.67 respectively)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`生活面积`和`等级`是与价格最高度相关的特征（分别为0.7和0.67）'
- en: '`Above square feet` and `neighbors'' living square feet` are very correlated
    with `living square feet` (0.88 and 0.76, respectively, which points to a degree
    of redundancy)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`上方平方英尺`和`邻居的生活面积`与`生活面积`高度相关（分别为0.88和0.76，这指向一定程度的冗余）'
- en: 'The number of each type of room has the following correlation coefficients:'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每种房间类型的数量有以下相关系数：
- en: '**Number of** **bathrooms**: 0.53'
  id: totrans-98
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**浴室数量**：0.53'
- en: '**Number of** **bedrooms**: 0.31'
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卧室数量**：0.31'
- en: '**Number of** **floors**: 0.26'
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**楼层数量**：0.26'
- en: '`View`, `waterfront`, and `renovation year` have some correlation with `price`
    (0.4, 0.27, and 0.13)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`视图`、`水滨`和`翻新年份`与`价格`有一定的相关性（分别为0.4、0.27和0.13）'
- en: '`Location` is correlated with `price` as well, with `latitude` being the most
    important location feature (0.31)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`位置`与`价格`相关，其中`纬度`是最重要的位置特征（0.31）'
- en: The rest of the features seem not to make a large contribution to the price
    of the property
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其余的特征似乎对房产价格的贡献不大
- en: 'Therefore, from an initial analysis, the most correlated features with *price*
    are, by order of importance: `living square feet`, `grade`, `number of bathrooms`,
    `view`, and `latitude`.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从初步分析来看，与*价格*最相关的特征按重要性排序依次为：`生活面积`、`等级`、`浴室数量`、`视图`和`纬度`。
- en: In the next sections, we will confirm these initial conclusions.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将确认这些初步结论。
- en: Square feet analysis
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 平方英尺分析
- en: 'From the correlation diagram, we identified a strong correlation between *living
    square feet* and *price* (as expected), and a potential redundancy with *above
    square feet* and *neighbors’ living square feet*. To analyze this in more detail,
    let’s plot each variable versus price:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 从相关性图中，我们发现*居住面积*与*价格*之间有很强的相关性（正如预期的那样），同时*楼上面积*与*邻居居住面积*也存在潜在的冗余性。为了更详细地分析这一点，我们将每个变量与价格的关系绘制出来：
- en: '![Figure 2.4 – Price compared with several features: a) living square feet,
    b) above square feet, c) neighbors’ living square feet](img/B16591_02_4.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.4 – 价格与多个特征的比较：a）居住面积，b）楼上面积，c）邻居居住面积](img/B16591_02_4.jpg)'
- en: 'Figure 2.4 – Price compared with several features: a) living square feet, b)
    above square feet, c) neighbors’ living square feet'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 – 价格与多个特征的比较：a）居住面积，b）楼上面积，c）邻居居住面积
- en: As expected, the plots are very similar, which indicates a high correlation
    (and redundancy) among these variables. Furthermore, we can observe the largest
    density of data points occurs for prices less than $3M and less than 5,000 square
    feet. As most of our data lies in these areas, we can consider houses outside
    these ranges as outliers and remove them.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期，绘制的图表非常相似，表明这些变量之间存在高度的相关性（以及冗余性）。此外，我们还可以观察到，数据点的最大密度出现在价格低于300万美元和面积小于5,000平方英尺的区域。由于我们大部分数据位于这些区域，我们可以将这些范围之外的房屋视为异常值并将其移除。
- en: Grade analysis
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 等级分析
- en: 'Similarly, we can compare the *grade* feature against the price:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以将*等级*特征与价格进行比较：
- en: '![Figure 2.5 – House grade versus price](img/B16591_02_5.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.5 – 房屋等级与价格的关系](img/B16591_02_5.jpg)'
- en: Figure 2.5 – House grade versus price
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5 – 房屋等级与价格的关系
- en: There is a clear direct correlation between the grade and the price; the higher
    the grade, the higher the price. It is also noteworthy that the highest values
    of grade are much less frequent.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 等级与价格之间有明显的直接相关性；等级越高，价格越高。值得注意的是，等级最高的房屋出现频率较低。
- en: Rooms analysis
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 房间分析
- en: 'Let’s display in more detail the relationship between the price and the number
    of *floors*, *bedrooms*, and *bathrooms*:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地展示价格与*楼层数*、*卧室数*和*浴室数*之间的关系：
- en: '![Figure 2.6 – Price compared with several features: a) number of floors, b)
    number of bedrooms, c) number of bathrooms](img/B16591_02_6.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.6 – 价格与多个特征的比较：a）楼层数，b）卧室数，c）浴室数](img/B16591_02_6.jpg)'
- en: 'Figure 2.6 – Price compared with several features: a) number of floors, b)
    number of bedrooms, c) number of bathrooms'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 – 价格与多个特征的比较：a）楼层数，b）卧室数，c）浴室数
- en: 'From the figure, you can observe the following:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中可以观察到以下几点：
- en: In *Figure 2**.6 (a)*, we can see for a small number of floors (1-3), there
    is a direct correlation between the price of the house and this number. However,
    from the fourth floor, this correlation disappears, indicating a lack of data
    on this segment (houses with four or more floors are much less common).
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*图 2**.6 (a)*中，我们可以看到，对于较少的楼层数（1-3层），房价与楼层数之间有直接的相关性。然而，从第四层开始，这种相关性消失了，这表明该段数据缺乏样本（四层或更多层的房子较为少见）。
- en: '*Figure 2**.6 (b)*, the comparison with the number of bedrooms, is a similar
    scenario to the previous chart comparing the number of floors. We can see how
    for a small number of bedrooms, there is a direct correlation between the price
    of the house and this number. However, from four bedrooms up, this correlation
    disappears, and other features need to be taken into account.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*图 2**.6 (b)*中，与卧室数量的比较情况与前一个楼层数量的比较图表相似。我们可以看到，对于较少卧室的房子，房价与卧室数之间有直接的相关性。然而，从四间卧室开始，这种相关性消失，其他特征需要被考虑进去。
- en: Important note
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: When looking carefully at the data, you will realize that in the row with index
    `15870`, there is an outlier; it is a house with 33 bedrooms. I do not know if
    this is the actual number of bedrooms of the house (I expect not!), but to properly
    analyze the dataset, this house, an outlier, was removed from it. See the code
    for details.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细查看数据时，你会发现，在索引为`15870`的那一行中，存在一个异常值；那是一栋有33间卧室的房子。我不知道这是否为房子的实际卧室数（我预计不是！），但为了正确分析数据集，这栋房子作为异常值已被从中移除。详情请查看代码。
- en: In *Figure 2**.6 (c)*, we can see there is a direct correlation between the
    number of bathrooms; nevertheless, there is also some uncertainty (the chart grows
    wider as we increase the number of bathrooms).
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*图 2**.6 (c)*中，我们可以看到浴室数量与价格之间有直接的相关性；然而，也存在一定的不确定性（随着浴室数量的增加，图表变得更宽）。
- en: Views analysis
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 视野分析
- en: 'In this section, we will take a look in more detail at how *view* quality and
    a *waterfront view* (whether the house has this view or not) have a connection
    with the price:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将更详细地分析*视野*质量和*水滨视野*（房屋是否有水滨视野）与价格之间的联系：
- en: '![Figure 2.7 – View quality (a) and waterfront view (b) versus price](img/B16591_02_7.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![图2.7 – 视野质量（a）和水滨视野（b）与价格的关系](img/B16591_02_7.jpg)'
- en: Figure 2.7 – View quality (a) and waterfront view (b) versus price
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.7 – 视野质量（a）和水滨视野（b）与价格的关系
- en: From these plots individually, it is a little bit more difficult to draw conclusions.
    Other variables seem to be needed to see a clear connection between the view quality
    and the price, and similarly with the waterfront view.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 从这些单独的图表中，得出结论稍微有些困难。似乎还需要其他变量来看到视野质量与价格之间的明显联系，水滨视野也是如此。
- en: Year-built and year-renovated analysis
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 建造年份和翻新年份分析
- en: 'The following plots show how the features of which year a house was built and
    if and when a house was renovated are correlated with price:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了房屋建造年份和是否以及何时翻新的特征与价格的相关性：
- en: '![Figure 2.8 – Price compared with construction year (a) and renovation (b)](img/B16591_02_8.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![图2.8 – 价格与建造年份（a）和翻新（b）的比较](img/B16591_02_8.jpg)'
- en: Figure 2.8 – Price compared with construction year (a) and renovation (b)
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.8 – 价格与建造年份（a）和翻新（b）的比较
- en: 'From the figure, you can observe the following:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 从图中，你可以观察到以下几点：
- en: In *Figure 2**.8 (a)*, we can see a slight linear increase in the price, suggesting
    that the more recently the house was built, the more expensive it is.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*图2.8（a）*中，我们可以看到价格呈现轻微的线性上升，表明房屋建造得越新，价格就越贵。
- en: For *Figure 2**.8 (b)*, instead of analyzing the year, we split the dataset
    into two categories – houses that had been renovated and those that had not –
    and we plotted these two categories against price. Regardless, it is a little
    bit more difficult to draw conclusions. Other variables seem to be needed to see
    a clear connection between the renovation year and the price.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于*图2.8（b）*，我们没有分析年份，而是将数据集分为两类——翻新过的房屋和未翻新过的房屋——并将这两类与价格进行对比。无论如何，这样做得出结论稍微有些困难。似乎还需要其他变量来看到翻新年份与价格之间的明显联系。
- en: Location analysis
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 位置分析
- en: 'In this section, we will take a look in more detail at how latitude and longitude
    are connected to price:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将更详细地分析纬度和经度与价格之间的联系：
- en: '![Figure 2.9 – Location versus price](img/B16591_02_9.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图2.9 – 位置与价格的关系](img/B16591_02_9.jpg)'
- en: Figure 2.9 – Location versus price
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.9 – 位置与价格的关系
- en: From *Figure 2**.9*, we can conclude that location plays an important role in
    the price of a house. Very clearly, the northern area of King County is more valued
    than the southern area. And there is a particular central region where houses
    are significantly more expensive than other nearby regions.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图2.9*中，我们可以得出结论：位置在房屋价格中起着重要作用。显然，金县的北部地区比南部地区更为高价。而且有一个特定的中心区域，这里的房屋比附近的其他地区明显更贵。
- en: How it works...
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的……
- en: Regression problems are one of the most common problems where SL approaches
    can be applied. By studying in depth a classic regression dataset, *King County
    House Price Prediction*, we can discover the most important connections between
    the input features (square feet, grade, and number of bathrooms) and the output
    feature (price). This analysis will help us build a model to predict the price
    in the next chapter.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 回归问题是应用SL方法的最常见问题之一。通过深入研究一个经典的回归数据集——*金县房价预测*，我们可以发现输入特征（建筑面积、等级和浴室数量）与输出特征（价格）之间最重要的联系。这项分析将帮助我们在下一章构建一个预测房价的模型。
- en: There’s more…
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多……
- en: In this section, we focused on an individual analysis of each feature against
    price. However, some features are better understood when combined with others
    or preprocessed. We did a simple exploration of this topic, by combining the houses
    that have been renovated in one category and comparing this with the category
    of non-renovated houses. Furthermore, for the location analysis, we used a 2D
    map to plot the latitude and longitude to discover patterns.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们专注于每个特征与价格的单独分析。然而，有些特征在与其他特征结合或经过预处理后，更容易理解。我们对这个主题做了一个简单的探索，通过将已经翻新的房屋归为一类，并与未翻新房屋的类别进行对比。此外，在位置分析中，我们使用了二维地图绘制纬度和经度，以发现模式。
- en: However, there are plenty of relationships and analyses to be done, and I suggest
    you explore the dataset by yourself, create your own hypothese or hunches, and
    analyze the data to discover new insights.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，还有很多关系和分析需要完成，我建议你自己探索这个数据集，提出自己的假设或直觉，并分析数据以发现新的见解。
- en: 'Furthermore, there are many other regression datasets to play with; a small
    suggestion can be found here: [https://www.kaggle.com/rtatman/datasets-for-regression-analysis](https://www.kaggle.com/rtatman/datasets-for-regression-analysis).'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有许多其他回归数据集可以进行练习；一个小建议可以在这里找到：[https://www.kaggle.com/rtatman/datasets-for-regression-analysis](https://www.kaggle.com/rtatman/datasets-for-regression-analysis)。
- en: Understanding classification datasets – loading, managing, and visualizing the
    Iris dataset
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解分类数据集——加载、管理和可视化鸢尾花数据集
- en: 'In the previous recipe, we studied one of the most common problem types in
    SL: regression. In this recipe, we will take a closer look at another of these
    problem types: **classification**.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一个教程中，我们学习了监督学习（SL）中最常见的一个问题类型：回归。在本教程中，我们将更深入地研究另一个常见的问题类型：**分类**。
- en: 'In classification problems, we want to estimate a categorial output, a class,
    from a set of given classes, using a variable number of input features. In this
    recipe, we will analyze a toy classification dataset from Kaggle: the Iris dataset,
    one of the most renowned classification datasets.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类问题中，我们希望从一组给定的类别中，使用一定数量的输入特征来估计一个类别输出。在本教程中，我们将分析一个来自 Kaggle 的玩具分类数据集：鸢尾花数据集，它是最著名的分类数据集之一。
- en: 'The Iris dataset presents the problem of estimating the `iris` class of the
    flower of plants, from three classes (iris setosa, iris versicolor, and iris virginica)
    with the help of the following four features:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 鸢尾花数据集呈现了从三种鸢尾花类别（鸢尾花 Setosa、鸢尾花 Versicolor 和鸢尾花 Virginica）中估计花卉类别（`iris`）的问题，利用以下四个特征：
- en: Sepal length (in cm)
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花萼长度（单位：厘米）
- en: Sepal width (in cm)
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花萼宽度（单位：厘米）
- en: Petal length (in cm)
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花瓣长度（单位：厘米）
- en: Petal width (in cm)
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花瓣宽度（单位：厘米）
- en: These data features are provided for 150 flowers, with 50 instances for each
    of the 3 classes (making it a balanced dataset).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据特征是为 150 朵花提供的，每个类别有 50 个实例（使其成为一个平衡的数据集）。
- en: Getting ready
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: This dataset is provided under the *CC0 Public Domain* license and can be downloaded
    from [https://www.kaggle.com/uciml/iris](https://www.kaggle.com/uciml/iris).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集在 *CC0 公共领域* 许可下提供，可以从 [https://www.kaggle.com/uciml/iris](https://www.kaggle.com/uciml/iris)
    下载。
- en: 'To read, manage, and visualize the data, we are going to follow a similar approach
    to the toy regression dataset in the previous recipe. We will use `pandas` to
    manage the data, and we will use the most common data structure for the library,
    DataFrames. Moreover, in order to plot the data and several visualizations we
    will compute, we will use the `matplotlib`, `pyplot`, and `seaborn` libraries.
    Therefore, we must run the following code:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 为了读取、管理和可视化数据，我们将采取类似于前一个教程中玩具回归数据集的方法。我们将使用 `pandas` 来管理数据，并使用该库最常见的数据结构：数据框（DataFrames）。此外，为了绘制数据及我们将计算的多个可视化图形，我们将使用
    `matplotlib`、`pyplot` 和 `seaborn` 库。因此，我们必须运行以下代码：
- en: '[PRE10]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To load the data, we will introduce a new library that is very useful for managing
    datasets, called `scikit-learn`. This library comes pre-installed with a set of
    datasets, including the Iris dataset:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加载数据，我们将引入一个非常有用的库，名为 `scikit-learn`，它非常适合管理数据集。这个库预装了一组数据集，其中包括鸢尾花数据集：
- en: '[PRE11]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If you do not have the previously mentioned libraries installed, they can be
    easily installed with the following terminal commands:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有安装之前提到的库，可以使用以下终端命令轻松安装：
- en: '[PRE12]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Therefore, to load the data, we can simply read the dataset by making use of
    `scikit-learn` library functions:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了加载数据，我们可以简单地通过使用 `scikit-learn` 库函数来读取数据集：
- en: '[PRE13]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This is all we need to start working with our classification dataset.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们开始处理分类数据集所需的一切。
- en: How to do it...
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何进行操作...
- en: 'In this section, we will run an EDA that will help us understand which features
    are important (and which are not) to predict the iris class of a flower by completing
    the following:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将进行一个探索性数据分析（EDA），帮助我们理解哪些特征对于预测花卉的鸢尾花类别很重要（哪些不重要），通过完成以下任务：
- en: Data structure
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据结构
- en: Correlation study
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相关性研究
- en: One-versus-one comparison (pair plots)
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一对一比较（配对图）
- en: Violin plot
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小提琴图
- en: Data structure
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据结构
- en: 'Let’s analyze what our data looks like. For this, we will use common operations
    on `pandas` DataFrames:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下数据的结构。为此，我们将使用在 `pandas` 数据框中的常见操作：
- en: '[PRE14]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'From the output, we can draw the following conclusions:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中，我们可以得出以下结论：
- en: The data is complete (all columns have 150 values, as expected)
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是完整的（所有列都有150个值，符合预期）
- en: There are no `NULL` values (the data is clean!)
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有`NULL`值（数据是干净的！）
- en: 'In order to grasp what the values look like, let’s display the first five properties:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解这些值的样子，让我们显示前五个属性：
- en: '[PRE15]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'So far, we have looked at what the features look like. Now, let’s take a look
    at what the iris class distribution looks like:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们看了特征的表现。现在，让我们看看鸢尾花类别的分布情况：
- en: '[PRE16]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This results in the following output:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE17]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'If we want to confirm that there are 50 instances per class, we can run the
    following:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想确认每个类别有50个实例，可以运行以下代码：
- en: '[PRE18]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This yields the following output:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '[PRE19]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Here, `0` corresponds to `setosa`, `1` to `versicolor`, and `2` to `virginica`.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`0`对应`setosa`，`1`对应`versicolor`，`2`对应`virginica`。
- en: Correlation study
  id: totrans-192
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关性研究
- en: Here, we will analyze how each feature correlates with each other and, most
    importantly, how each feature correlates with the iris class.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将分析每个特征之间的相关性，最重要的是，每个特征与鸢尾花类别之间的相关性。
- en: 'We can compute a pairwise correlation diagram:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以计算成对相关性图：
- en: '[PRE20]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To easily visualize the calculated correlations, we will plot a heatmap:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于可视化计算出的相关性，我们将绘制热图：
- en: '[PRE21]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'These code statements yield the following result:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这些代码语句产生了以下结果：
- en: '![Figure 2.10 – Flower features correlation matrix](img/B16591_02_10.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.10 – 花朵特征相关性矩阵](img/B16591_02_10.jpg)'
- en: Figure 2.10 – Flower features correlation matrix
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10 – 花朵特征相关性矩阵
- en: Let’s note in *Figure 2**.10* that the darker the cell is, the larger the correlation
    value.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意在*图 2.10*中，单元格越深，相关性值越大。
- en: 'To emphasize the first row (most important as it shows the relationship between
    the iris class and the input features), we will run the following code:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 为了强调第一行（最重要的是它显示了鸢尾花类别与输入特征之间的关系），我们将运行以下代码：
- en: '[PRE22]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'And we have the following result:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们得到的结果：
- en: '![Figure 2.11 – Flower features: iris class correlation](img/B16591_02_11.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.11 – 花朵特征：鸢尾花类别相关性](img/B16591_02_11.jpg)'
- en: 'Figure 2.11 – Flower features: iris class correlation'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11 – 花朵特征：鸢尾花类别相关性
- en: 'The following conclusions can be drawn from *Figures 2.10* and *2.11*:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图 2.10*和*图 2.11*中可以得出以下结论：
- en: Petal measurements (length and width) are highly correlated; analyzing and training
    both might not yield any additional information.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花瓣的测量（长度和宽度）高度相关；分析和训练这两个特征可能不会带来额外的信息。
- en: Petal measurements are the most highly correlated features with the iris class.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花瓣的测量值是与鸢尾花类别相关性最强的特征。
- en: Sepal length and width are highly correlated as well but in opposite ways (sepal
    length is positively correlated while sepal width is negatively correlated).
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 萼片长度和宽度也高度相关，但方向相反（萼片长度是正相关的，而萼片宽度是负相关的）。
- en: One-versus-one comparison (pair plots)
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一对一比较（成对图）
- en: 'In classification problems, hue/brightness can be used to indicate the class
    of a plot. Moreover, as in this dataset we are able to work with a limited set
    of features (four), a pair plot diagram will be very useful to compare all features
    in a single plot. The code to plot this diagram is shown here:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在分类问题中，色调/亮度可以用来指示图表的类别。此外，由于在这个数据集中我们只能使用有限的特征集（四个特征），成对图将非常有用，可以在单个图表中比较所有特征。绘制此图的代码如下所示：
- en: '[PRE23]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'And here’s the displayed diagram:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这是显示的图表：
- en: '![Figure 2.12 – Flower features pair plot](img/B16591_02_12.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.12 – 花朵特征对比图](img/B16591_02_12.jpg)'
- en: Figure 2.12 – Flower features pair plot
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12 – 花朵特征对比图
- en: 'From this set of plots, we can draw the following conclusions:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 从这组图表中，我们可以得出以下结论：
- en: Setosa iris is easily differentiated using any of the features
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Setosa 鸢尾花可以通过任何特征轻松区分
- en: Sepal features overlap among the different iris classes
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同鸢尾花类别之间的萼片特征有重叠
- en: Petal features have a direct relationship with the iris class; that is, the
    smallest numbers point to **setosa**, medium numbers point to **versicolor**,
    and the largest numbers point to **virginica**
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 花瓣特征与鸢尾花类别直接相关；也就是说，最小的数值指向**setosa**，中等的数值指向**versicolor**，而最大的数值指向**virginica**
- en: There is a region on the boundaries of **versicolor** and **virginica** where
    both groups overlap, for a petal length larger than ~5 cm and a petal width larger
    than ~1.5 cm
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**versicolor**和**virginica**的边界上存在一个重叠区域，当花瓣长度大于约5厘米且花瓣宽度大于约1.5厘米时，两个类别会重叠。
- en: Violin plot
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 小提琴图
- en: 'Another plot that might help with understanding the relationships between features
    and the iris class is a violin plot. The code to generate this plot is the following:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个可能帮助理解特征与鸢尾花类别之间关系的图是小提琴图。生成此图的代码如下：
- en: '[PRE24]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'And here’s the displayed diagram:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是展示的图表：
- en: '![Figure 2.13 – Flower features violin plot](img/B16591_02_13.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.13 – 花卉特征小提琴图](img/B16591_02_13.jpg)'
- en: Figure 2.13 – Flower features violin plot
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.13 – 花卉特征小提琴图
- en: In these plots, the conclusions we found are even clearer, with the setosa (`0`)
    iris class clearly separable and where there is substantial overlap for versicolor
    (`1`) and virginica (`2`).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些图中，我们得出的结论更加清晰，setosa（`0`）鸢尾花类别明显可分离，而versicolor（`1`）和virginica（`2`）则有相当大的重叠。
- en: 'The violin plot also provides an indication of the distribution of the values
    in our case (starting with 0 to match the indexes of the classes in the code):'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 小提琴图还提供了我们数据值分布的指示（从0开始，以匹配代码中类别的索引）：
- en: '**Setosa**: Values are more likely to be found around the mean (~1.5 cm for
    petal length and ~0.25 cm for petal width).'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Setosa**：值更可能出现在均值附近（大约为花瓣长度1.5 cm和花瓣宽度0.25 cm）。'
- en: '**Versicolor**: Normal distribution with mean values ~4.25 cm and ~1.3 cm,
    and standard distribution values ~0.5 cm and ~0.2 cm (for petal length and petal
    width respectively).'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Versicolor**：正态分布，均值大约为4.25 cm和1.3 cm，标准差分别为0.5 cm和0.2 cm（对应花瓣长度和花瓣宽度）。'
- en: '**Virginica**: Uniform distribution between [~5.1, ~5.9] cm and [~1.8, ~2.3]
    cm (for petal length and petal width respectively).'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Virginica**：在[~5.1, ~5.9] cm和[~1.8, ~2.3] cm之间呈均匀分布（分别对应花瓣长度和花瓣宽度）。'
- en: How it works...
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: Classification problems are one of the most common problems where **supervised
    ML** (**SML**) approaches can be applied. By studying a classic classification
    dataset, Iris Class in depth we can discover the connections between the input
    features (petal length and petal width) and the output feature (iris class). This
    analysis will help us build a model to predict the class in the next chapter.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 分类问题是**监督式机器学习**（**SML**）方法应用最广泛的问题之一。通过深入研究经典的分类数据集——鸢尾花类别，我们可以发现输入特征（花瓣长度和花瓣宽度）与输出特征（鸢尾花类别）之间的关联。这一分析将帮助我们在下一章中构建模型来预测类别。
- en: There’s more…
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In this section, we focused on an individual analysis of each feature against
    the iris class. This was similar in principle to the analysis done for regression
    datasets, with the added information about the hue/brightness for each plot. A
    similar suggestion to the reader follows, to continue and deepen the analysis
    by themselves to discover new insights.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们重点分析了每个特征与鸢尾花类别之间的关系。这在原则上类似于回归数据集的分析，且每个图都有额外的信息，即色调/亮度。我们建议读者继续自己进行分析，以发现新的洞察。
- en: 'We mentioned the Iris dataset is one of the classical classification datasets;
    nonetheless, it dates back to 1936! Original reference: [https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-1809.1936.tb02137.x](https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-1809.1936.tb02137.x).'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到鸢尾花数据集是经典的分类数据集之一，然而，它的历史可以追溯到1936年！原始参考文献：[https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-1809.1936.tb02137.x](https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-1809.1936.tb02137.x)。
- en: Furthermore, as we will explore in the next chapter, classification problems
    can be seen as a special case of regression problems. In the regression recipe,
    we studied the prices of houses, and presented them in a way that would allow
    a buyer to determine which are affordable, by taking the price and comparing it
    with a threshold, which could be, for example, our budget limit. Therefore, we
    can use that threshold to classify houses that are below it as affordable and
    above it as not affordable. We will explore this connection in depth in the next
    chapter.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，正如我们将在下一章探讨的那样，分类问题可以视为回归问题的特殊情况。在回归案例中，我们研究了房价，并通过将其与阈值进行比较（例如我们的预算限额）来帮助买家判断哪些是可负担的。因此，我们可以使用该阈值将低于阈值的房子分类为可负担的，将高于阈值的房子分类为不可负担的。我们将在下一章深入探讨这一联系。
- en: 'Furthermore, there are many other classification datasets to play with; a small
    selection can be found here: [https://www.kaggle.com/search?q=classification+tags%3Aclassification](https://www.kaggle.com/search?q=classification+tags%3Aclassification).'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有许多其他分类数据集可以使用；可以在这里找到一小部分：[https://www.kaggle.com/search?q=classification+tags%3Aclassification](https://www.kaggle.com/search?q=classification+tags%3Aclassification)。
- en: Understanding image datasets – loading, managing, and visualizing the Fashion-MNIST
    dataset
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解图像数据集——加载、管理和可视化 Fashion-MNIST 数据集
- en: One of the fields that has grown considerably in DL in the last years has been
    **computer vision** (**CV**). Since the AlexNet revolution in 2012, CV has expanded
    from lab research to surpassing human performance in real-world datasets (known
    as “in the wild”).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，**计算机视觉**（**CV**）是深度学习领域增长显著的一个方向。自2012年AlexNet革命以来，计算机视觉从实验室研究扩展到在真实世界数据集（即“野外”数据集）中超越了人类表现。
- en: 'In this recipe, we will explore the simplest CV task: **image classification**.
    Given a set of images, our task is to correctly classify that image among a given
    set of labels (classes).'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将探讨最简单的计算机视觉任务：**图像分类**。给定一组图像，我们的任务是将这些图像正确地分类到预定的标签（类别）中。
- en: 'One of the most classic image classification datasets is the **MNIST** (which
    stands for the **Modified National Institute of Standards and Technology**) database.
    Similarly sized, but more suited for current CV analysis, is the *Fashion-MNIST
    dataset*. This dataset is a multi-label image classification dataset, with a training
    set of 60k examples and a test set of 10k examples, with each example belonging
    to 1 of these 10 categories (starting with 0 to match the indexes of the classes
    in the code):'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 最经典的图像分类数据集之一是**MNIST**（即**修改版国家标准与技术研究院**）数据库。同样大小，但更适合当前的计算机视觉分析的是*Fashion-MNIST
    数据集*。这个数据集是一个多标签图像分类数据集，训练集包含60k个示例，测试集包含10k个示例，每个示例属于这10个类别之一（从0开始，以匹配代码中的类别索引）：
- en: T-shirt/top
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: T恤/上衣
- en: Trouser
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 长裤
- en: Pullover
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 套头衫
- en: Dress
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连衣裙
- en: Coat
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 外套
- en: Sandal
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 凉鞋
- en: Shirt
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 衬衫
- en: Sneaker
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运动鞋
- en: Bag
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包
- en: Ankle boot
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 踝靴
- en: Each image is grayscale with 28x28 pixel dimensions. This can be seen as each
    data point having 784 features. The dataset is composed of 6k images per class
    in the training set and 1k images per class in the test set (balanced dataset).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 每张图像为灰度图，尺寸为28x28像素。这可以看作每个数据点具有784个特征。该数据集由每个类别6k张图像的训练集和每个类别1k张图像的测试集组成（平衡数据集）。
- en: Getting ready
  id: totrans-255
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'This dataset is provided under the *MIT* license and can be downloaded from
    the following URL: [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集提供在*MIT*许可证下，可以从以下网址下载：[https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist)
- en: 'This dataset is directly available from MXNet Gluon, and therefore we will
    use this library to access it. Moreover, as this dataset is significantly larger
    than the others we have explored so far, to handle the data efficiently, we will
    use the Gluon DataLoader functionality:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集可以直接通过MXNet Gluon获取，因此我们将使用这个库来访问它。此外，由于这个数据集比我们迄今为止探索的其他数据集要大得多，为了高效处理数据，我们将使用Gluon
    DataLoader功能：
- en: '[PRE25]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Tip
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: Gluon is installed with MXNet; no further steps are required.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: Gluon随MXNet一起安装；无需其他步骤。
- en: This is all we need to start working with the Fashion-MNIST dataset.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们开始使用Fashion-MNIST数据集所需的所有内容。
- en: Important note
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Sometimes, data needs to be modified (transformed) for some operations. This
    can be done by defining a `transform` function and passing it as a parameter (`transform=<function_name>`).
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候，数据需要为某些操作进行修改（转化）。这可以通过定义一个`transform`函数并将其作为参数（`transform=<function_name>`）传递来完成。
- en: How to do it...
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: 'In this section, we will run an EDA that will help us understand which features
    are important (and which are not) to predict the category of a garment, with the
    help of the following steps:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将进行一次探索性数据分析（EDA），帮助我们理解哪些特征对于预测服装类别是重要的（哪些是不重要的），以下是帮助我们进行分析的步骤：
- en: Identifying the data structure
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定数据结构
- en: Describing examples per class
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述每个类别的示例
- en: Understanding dimensionality reduction techniques
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 理解降维技术
- en: Visualizing **Principal Component** **Analysis** (**PCA**)
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化**主成分** **分析**（**PCA**）
- en: Visualizing **t-distributed Stochastic Neighbor** **Embedding** (**t-SNE**)
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化**t分布随机邻域** **嵌入**（**t-SNE**）
- en: Visualizing **Uniform Manifold Approximation and** **Projection** (**UMAP**)
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化**统一流形近似与** **投影**（**UMAP**）
- en: Visualizing **Python Minimum-Distortion** **Embedding** (**PyMDE**)
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化**Python最小失真** **嵌入**（**PyMDE**）
- en: Identifying the data structure
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 确定数据结构
- en: In order to optimize memory usage to work with large-scale datasets, instead
    of loading the full dataset in memory, datasets are usually accessed through **batches**,
    which are smaller packets of data.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化内存使用，以便处理大规模数据集，通常不是将完整的数据集加载到内存中，而是通过**批次**访问数据集，批次是较小的数据包。
- en: 'Gluon has its own way of generating batches, while also applying `128`:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: Gluon有自己生成批次的方式，同时应用`128`：
- en: '[PRE26]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Important note
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: DataLoader does not return a data structure but an iterator. Therefore, to access
    the data we need to iterate upon it, we use constructs such as `for` loops.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: DataLoader不会返回数据结构，而是返回一个迭代器。因此，为了访问数据，我们需要对其进行迭代，使用诸如`for`循环等构造。
- en: 'Let’s verify the data structure is as expected:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们验证数据结构是否符合预期：
- en: '[PRE27]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We obtain the expected output:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了预期的输出：
- en: '[PRE28]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Important note
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Gluon loads grayscale images as images with one channel, and the dimension for
    each batch is (batch size, height, width, number of channels); in our example,
    (128, 28, 28, 1).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: Gluon加载灰度图像时会将其视为具有一个通道的图像，每个批次的维度为（批次大小，高度，宽度，通道数）；在我们的示例中是（128，28，28，1）。
- en: Describing examples per class
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每个类别的示例描述
- en: 'The Fashion-MNIST dataset is a balanced dataset with 6k examples per class:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: Fashion-MNIST 数据集是一个平衡的数据集，每个类别有6k个示例：
- en: '![Figure 2.14 – Fashion-MNIST dataset labels](img/B16591_02_14.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.14 – Fashion-MNIST 数据集标签](img/B16591_02_14.jpg)'
- en: Figure 2.14 – Fashion-MNIST dataset labels
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.14 – Fashion-MNIST 数据集标签
- en: 'Let’s take a look at what each class looks like. In order to do this, we can
    plot 10 examples per class:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看每个类别的样本长什么样。为了实现这一点，我们可以绘制每个类别的10个示例：
- en: '![Figure 2.15 – Fashion-MNIST dataset](img/B16591_02_15.jpg)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.15 – Fashion-MNIST 数据集](img/B16591_02_15.jpg)'
- en: Figure 2.15 – Fashion-MNIST dataset
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.15 – Fashion-MNIST 数据集
- en: As we can see in *Figure 2**.15*, all instances can be differentiated fairly
    well by a human, except for the `T-shirt`/`top`, `Pullover`, `Coat`, and `Shirt`
    classes.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在*图 2.15*中看到的那样，所有实例几乎都可以被人类很好地区分，除了`T-shirt`/`top`、`Pullover`、`Coat`和`Shirt`类别。
- en: Understanding dimensionality reduction techniques
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解降维技术
- en: Apart from the large number of data points that our dataset contains, the number
    of features in the image (that is, the number of pixels per image) is very high.
    In our toy dataset, each image has 784 features, which can be seen as 1 point
    in 784-dimensional space. In this space, it is extremely difficult to analyze
    relationships among features (for example, correlation, as we explored in previous
    datasets). Furthermore, it is not rare to work with higher-quality images, with
    resolutions over 1 MP (more than 1 million features). For a 4k image, the number
    of features is ~8 million.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据集中包含的大量数据点外，图像中的特征数量（即每个图像的像素数）也非常高。在我们的玩具数据集中，每张图像有784个特征，可以看作是784维空间中的1个点。在这个空间中，分析特征之间的关系（例如我们在前面的数据集中探索的相关性）是非常困难的。此外，处理更高质量的图像（分辨率超过1百万像素，即超过100万个特征）并不罕见。对于一张4K图像，特征数量约为800万个。
- en: Therefore, in this subsection and the next ones (on *PCA*, *t-SNE*, *UMAP*,
    and *PyMDE*), we will work with techniques known as **dimensionality reduction**
    techniques. The idea behind these techniques is to be able to visualize high-dimensional
    features easily, typically in 2D or 3D, which are the kinds of visualizations
    humans are used to working with. These embeddings have two or three components
    that can be plotted in 2D or 3D. These representations are dataset-dependent;
    they are *learned* representations.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在本小节以及接下来的小节（关于*PCA*、*t-SNE*、*UMAP*和*PyMDE*），我们将使用称为**降维**的技术。降维技术的核心思想是能够轻松地可视化高维特征，通常是2D或3D，这是人类习惯使用的可视化方式。这些嵌入具有两个或三个组件，可以在2D或3D中绘制。这些表示是数据集依赖的；它们是*学习*得到的表示。
- en: Each technique described has a different way of achieving this result. In this
    book, we will not deepen our knowledge of how each technique works, but the interested
    reader can find more information in the *There’s* *more...* section.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 每种技术都有不同的方式来实现这一结果。在本书中，我们不会深入了解每种技术的原理，但感兴趣的读者可以在*There’s* *more...*部分找到更多信息。
- en: Please also note that although each technique is different, all of them require
    a vector as an input (feature vector). This means that there is some spatial information
    that is lost. In our example, from 28x28 images, we will input 784 feature vectors.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 还请注意，尽管每种技术不同，但它们都要求输入一个向量（特征向量）。这意味着一些空间信息会丢失。在我们的示例中，从28x28的图像中，我们将输入784个特征向量。
- en: Visualizing PCA
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化PCA
- en: 'As expected, we can see some large clusters (**Sneaker** and **Ankle boot**),
    and others are mostly overlapping (**T-shirt**, **Pullover** and **Coat**):'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，我们可以看到一些大簇（**Sneaker** 和 **Ankle boot**），而其他簇大多是重叠的（**T-shirt**、**Pullover**
    和 **Coat**）：
- en: '![Figure 2.16 – Fashion-MNIST 2D PCA](img/B16591_02_16.jpg)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.16 – Fashion-MNIST 2D PCA](img/B16591_02_16.jpg)'
- en: Figure 2.16 – Fashion-MNIST 2D PCA
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.16 – Fashion-MNIST 2D PCA
- en: Visualizing t-SNE
  id: totrans-302
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化 t-SNE
- en: 'Another technique for dimensionality reduction is t-SNE. This technique is
    based on the idea of computing a probability distribution that represents similarities
    among neighbors. A recommended preliminary step is to compute PCA for 50 features
    and then pass these 50 feature vectors to the t-SNE algorithm. This is what we
    did to generate the following graph:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种降维技术是 t-SNE。该技术基于计算表示邻居相似性的概率分布。推荐的预处理步骤是先对 50 个特征进行 PCA，然后将这 50 个特征向量传递给
    t-SNE 算法。这就是我们用来生成以下图表的方法：
- en: '![Figure 2.17 – Fashion-MNIST 2D t-SNE](img/B16591_02_17.jpg)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.17 – Fashion-MNIST 2D t-SNE](img/B16591_02_17.jpg)'
- en: Figure 2.17 – Fashion-MNIST 2D t-SNE
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.17 – Fashion-MNIST 2D t-SNE
- en: In this plot, we can see in a clearer way how easily distinguishable objects
    are clustered in isolation (**Trouser**, on the lower right, and **Bag**, on the
    upper left).
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个图中，我们可以更清楚地看到，如何将易于区分的对象孤立成簇（**Trouser** 在右下角，**Bag** 在左上角）。
- en: Important note
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'For PCA and t-SNE, we can choose three components instead of two, which will
    yield a 3D plot. For the code, visit the GitHub repository of the book: [https://github.com/PacktPublishing/Deep-Learning-with-MXNet-Cookbook](https://github.com/PacktPublishing/Deep-Learning-with-MXNet-Cookbook).'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 PCA 和 t-SNE，我们可以选择三个主成分而不是两个，这样会生成一个 3D 图。关于代码，请访问本书的 GitHub 仓库：[https://github.com/PacktPublishing/Deep-Learning-with-MXNet-Cookbook](https://github.com/PacktPublishing/Deep-Learning-with-MXNet-Cookbook)。
- en: Visualizing UMAP
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化 UMAP
- en: 'Another method for dimensionality reduction is **UMAP**. UMAP allows us to
    play with different parameters, such as the *number of neighbors*, which helps
    the visualization of how to balance a local versus global structure. For an example
    with five neighbors, this is the visualization:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种降维方法是 **UMAP**。UMAP 允许我们调整不同的参数，比如*邻居的数量*，这有助于我们可视化如何平衡局部结构与全局结构。以下是五个邻居的可视化示例：
- en: '![Figure 2.18 – Fashion-MNIST UMA](img/B16591_02_18.jpg)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.18 – Fashion-MNIST UMA](img/B16591_02_18.jpg)'
- en: Figure 2.18 – Fashion-MNIST UMA
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.18 – Fashion-MNIST UMA
- en: In this visualization, we can observe similar trends as in previous plots; that
    is, **Bag** is clustered in the upper-center region, and **Trouser** in the lower-center
    region. However, in this visualization, we can also note that there is a cluster
    on the left that contains data for **Ankle boot**, **Sneaker**, and **Sandal**,
    and another important cluster on the right for **Shirt**, **Coat**, **Dress**,
    and **T-shirt/top**, and we can see how these clusters overlap with each other.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在此可视化中，我们可以观察到与前面图表中类似的趋势；即，**Bag** 被聚集在上中部区域，**Trouser** 被聚集在下中部区域。然而，在此可视化中，我们还可以注意到左侧有一个簇，包含了**Ankle
    boot**、**Sneaker** 和 **Sandal**的数据，而右侧有一个重要的簇，包含了**Shirt**、**Coat**、**Dress**
    和 **T-shirt/top**的数据，我们可以看到这些簇是如何相互重叠的。
- en: 'To install UMAP, please run this command:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 UMAP，请运行以下命令：
- en: '[PRE29]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Visualizing PyMDE
  id: totrans-316
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化 PyMDE
- en: 'Another popular technique that provides insightful visualizations is **PyMDE**.
    PyMDE allows two main approaches, to preserve neighbors (local structure of the
    data is preserved) and to preserve distances. This preserves relationship attributes
    such as pairwise distances in the data. The approach to preserve neighbors is
    similar to the plots we are seeing:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种流行的技术是 **PyMDE**，它提供了有洞察力的可视化。PyMDE 允许两种主要方法：保持邻居关系（即保留数据的局部结构）和保持距离关系。这保持了数据中一对一距离等关系属性。保持邻居关系的方法类似于我们所看到的图表：
- en: '![Figure 2.19 – Fashion-MNIST PyMDE](img/B16591_02_19.jpg)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.19 – Fashion-MNIST PyMDE](img/B16591_02_19.jpg)'
- en: Figure 2.19 – Fashion-MNIST PyMDE
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.19 – Fashion-MNIST PyMDE
- en: As we can see in *Figure 2**.19*, very similar conclusions to UMAP can be drawn
    from a PyMDE visualization.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在*图 2.19*中所见，PyMDE 可得出与 UMAP 非常相似的结论。
- en: 'To install UMAP, please run the following command:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 UMAP，请运行以下命令：
- en: '[PRE30]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: How it works...
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: To understand an image dataset, we need to understand the underlying connections
    among images in that dataset. One useful method to achieve this is with different
    visualizations.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解一个图像数据集，我们需要理解该数据集中图像之间的潜在联系。实现这一目标的一种有用方法是使用不同的可视化技术。
- en: 'In this recipe, we have learned how to discover patterns in our image datasets.
    We selected a well-researched dataset, Fashion-MNIST, and learned one of the most
    important approaches for working with large-scale datasets: **batching**.'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们学习了如何发现图像数据集中的模式。我们选择了一个经过充分研究的数据集——Fashion-MNIST，并学习了处理大规模数据集的最重要方法之一：**批处理**。
- en: We analyzed our dataset by taking a look at its internal structure and what
    the actual images looked like and tried to foresee where potential classification
    algorithms could have issues (such as similarities between coats and shirts and
    ankle boots and sneakers).
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过查看数据集的内部结构以及实际图像的样貌来分析数据集，并尝试预测潜在的分类算法可能遇到的问题（例如外套和衬衫、短靴和运动鞋之间的相似性）。
- en: 'Every pixel is a dimension/feature of each image, and, therefore, to work with
    them, we learned about some dimensionality reduction techniques: PCA, t-SNE, UMAP,
    and PyMDE. With these visualizations, we were able to verify and extend our knowledge
    of the dataset.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 每个像素都是每张图像的一个维度/特征，因此，为了处理它们，我们了解了一些降维技术：PCA、t-SNE、UMAP和PyMDE。通过这些可视化，我们能够验证并扩展我们对数据集的知识。
- en: There’s more…
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'There are many resources for MNIST and Fashion-MNIST, as these are well-researched
    datasets. I personally recommend the following:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 由于MNIST和Fashion-MNIST是经过充分研究的数据集，因此有许多资源可供参考。我个人推荐以下资源：
- en: '**MNIST** **database:** [https://en.wikipedia.org/wiki/MNIST_database](https://en.wikipedia.org/wiki/MNIST_database)'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MNIST** **数据库**: [https://en.wikipedia.org/wiki/MNIST_database](https://en.wikipedia.org/wiki/MNIST_database)'
- en: '**zalandoresearch/fashion-mnist:** [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist)'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**zalandoresearch/fashion-mnist**: [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist)'
- en: 'We introduced some dimensionality reduction techniques, but we did not deepen
    our knowledge of them. If you want to understand better how each of these techniques
    works, I suggest the following resources:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了一些降维技术，但并没有深入了解它们。如果你想更好地理解每种技术的工作原理，我建议以下资源：
- en: '**PCA (from** **Caltech)**: [http://web.ipac.caltech.edu/staff/fmasci/home/astro_refs/PrincipalComponentAnalysis.pdf](http://web.ipac.caltech.edu/staff/fmasci/home/astro_refs/PrincipalComponentAnalysis.pdf)'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PCA（来自** **加州理工学院）**: [http://web.ipac.caltech.edu/staff/fmasci/home/astro_refs/PrincipalComponentAnalysis.pdf](http://web.ipac.caltech.edu/staff/fmasci/home/astro_refs/PrincipalComponentAnalysis.pdf)'
- en: '**t-SNE**: [https://lvdmaaten.github.io/tsne/](https://lvdmaaten.github.io/tsne/)'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**t-SNE**: [https://lvdmaaten.github.io/tsne/](https://lvdmaaten.github.io/tsne/)'
- en: '**UMAP**: [https://umap-learn.readthedocs.io/](https://umap-learn.readthedocs.io/)'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**UMAP**: [https://umap-learn.readthedocs.io/](https://umap-learn.readthedocs.io/)'
- en: '**PyMDE**: [https://pymde.org/](https://pymde.org/)'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PyMDE**: [https://pymde.org/](https://pymde.org/)'
- en: In the code, you can find how to obtain the visualizations included. Furthermore,
    for PCA and t-SNE, as the number of components is a variable, 3D plots for both
    of them are included.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，你可以找到如何获取包含的可视化内容。此外，对于PCA和t-SNE，由于组件数是一个变量，因此两者的3D图都被包含在内。
- en: 'Finally, for readers interested in learning more about DL and its history,
    I recommend the following link: [https://www.skynettoday.com/overviews/neural-net-history](https://www.skynettoday.com/overviews/neural-net-history).'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对于那些有兴趣深入了解深度学习及其历史的读者，我推荐以下链接：[https://www.skynettoday.com/overviews/neural-net-history](https://www.skynettoday.com/overviews/neural-net-history)。
- en: Understanding text datasets – loading, managing, and visualizing the Enron Email
    dataset
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解文本数据集 – 加载、管理和可视化Enron邮件数据集
- en: Another field that has grown considerably in DL in recent years is **natural
    language processing** (**NLP**). Similarly to CV, this field aims to surpass human
    performance in real-world datasets.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，**自然语言处理**（**NLP**）是深度学习领域一个快速发展的领域。与计算机视觉（CV）类似，该领域的目标是在人类表现基础上超越现实世界数据集的表现。
- en: 'In this recipe, we will explore one of the simplest NLP tasks: **text classification**.
    Given a set of sentences and paragraphs, our task is to correctly classify that
    text among a given set of labels (classes).'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将探索最简单的NLP任务之一：**文本分类**。给定一组句子和段落，我们的任务是正确地将这些文本分类到给定的标签（类别）中。
- en: One of the most classic text classification tasks is to distinguish whether
    received email is spam or not (ham). These datasets are binary text classification
    datasets (only two labels to assign, `0` and `1`, or `ham` and `spam`).
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 最经典的文本分类任务之一是区分收到的邮件是否是垃圾邮件（spam）或非垃圾邮件（ham）。这些数据集是二元文本分类数据集（只有两个标签要分配，`0` 和
    `1`，或者 `ham` 和 `spam`）。
- en: In our specific scenario, we will use a real-world email dataset. This set of
    emails was made public during the investigation of the Enron scandal in the early
    2000s by the US Government. This dataset was first published in 2004 and is composed
    of emails from ~150 users, mostly senior management at Enron. Only a subset (known
    as `enron1`) is used in this section.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的特定场景中，我们将使用一个真实世界的邮件数据集。该数据集是在2000年代初美国政府对安然丑闻进行调查时公开的。这一数据集首次发布于2004年，包含约150名用户的邮件，主要是安然公司高级管理层的邮件。本节仅使用其中的一个子集（称为`enron1`）。
- en: 'It contains 5,171 emails, with no training/test split (labels are provided
    for all examples). Being a real-world dataset, emails vary heavily with respect
    to subjects, content length, word count, and word length, and out of the box,
    the dataset only contains two features:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含5,171封邮件，没有训练/测试集划分（所有示例都提供标签）。作为一个真实世界的数据集，邮件在主题、内容长度、词数和单词长度等方面差异很大，且默认情况下，数据集仅包含两个特征：
- en: '`0` corresponds to `Ham` and `1` to `Spam`'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0`表示`正常邮件`，`1`表示`垃圾邮件`'
- en: '**Text**: Includes the subject and the body of the email'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本**：包括邮件的主题和正文'
- en: The dataset is composed of 3,672 examples of ham email (~70%) and 1,499 examples
    of spam email (~30%); it is a highly imbalanced dataset.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集包含3,672封正常邮件（约占70%）和1,499封垃圾邮件（约占30%）；它是一个高度不平衡的数据集。
- en: Getting ready
  id: totrans-348
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: This dataset is provided under the *CC0 Public Domain* license and can be downloaded
    from [https://www.kaggle.com/venky73/spam-mails-dataset](https://www.kaggle.com/venky73/spam-mails-dataset).
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集遵循*CC0公共领域*许可证，可以从[https://www.kaggle.com/venky73/spam-mails-dataset](https://www.kaggle.com/venky73/spam-mails-dataset)
    下载。
- en: 'To read the data, we are going to follow a similar approach as seen in the
    recipe for regression tasks. We are going to load the data from a CSV file, and
    we are going to work with the data using very well-known Python libraries: `pandas`,
    `pyplot`, and `seaborn`. Therefore, we must run the following code:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 为了读取数据，我们将遵循与回归任务中类似的方法。我们将从CSV文件加载数据，并使用非常著名的Python库：`pandas`、`pyplot` 和 `seaborn`
    来处理数据。因此，我们需要运行以下代码：
- en: '[PRE31]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Therefore, to load the data, we can simply read the file containing it (the
    file can be found in the book’s GitHub repository):'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了加载数据，我们只需读取包含数据的文件（该文件可以从书籍的GitHub仓库中找到）：
- en: '[PRE32]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This is all we need to start working with our spam email dataset.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们开始处理垃圾邮件数据集所需的全部内容。
- en: How to do it...
  id: totrans-355
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何执行...
- en: 'In this section, we will run an EDA that will help us understand which features
    are important (and which are not) to predict whether an email is spam or not,
    the following are not worded as steps. please either reword this to a more suitable
    lead-in or reword the following as steps. if the latter, please change the circular
    bullets to numbering:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将进行探索性数据分析（EDA），帮助我们理解哪些特征对于预测邮件是否为垃圾邮件至关重要（哪些不重要）。以下内容不是以步骤形式呈现，请重新组织为更合适的引言或以步骤形式重新编排，并将圆点符号改为编号：
- en: Data structure
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据结构
- en: Examples per class
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个类别的示例
- en: Content analysis
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内容分析
- en: Data cleaning
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据清洗
- en: N-grams
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: N-gram模型
- en: Word processing (tokenizing, stop words, stemming, and lemmatization)
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 词处理（分词、停用词、词干提取和词形还原）
- en: Word clouds
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 词云
- en: Word embeddings (word2vec and **Global Vectors for Word** **Representation**
    (**GloVe**))
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 词嵌入（word2vec 和 **全局词表示模型** (**GloVe**))
- en: PCA and t-SNE
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主成分分析（PCA）和t-SNE
- en: Data structure
  id: totrans-366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据结构
- en: 'The first step we will carry out will be to reformat the dataset for our purposes:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要进行的第一步是根据我们的需求重新格式化数据集：
- en: '[PRE33]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'After these modifications, the shape of our email DataFrame is as follows:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 经这些修改后，我们的邮件数据框架（DataFrame）形状如下：
- en: '[PRE34]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Examples per class
  id: totrans-371
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每个类别的示例
- en: 'We will now take a look at each class distribution:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将查看每个类别的分布：
- en: '[PRE35]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The following is the output:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出结果：
- en: '![Figure 2.20 – Spam emails dataset](img/B16591_02_20.jpg)'
  id: totrans-375
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.20 – 垃圾邮件数据集](img/B16591_02_20.jpg)'
- en: Figure 2.20 – Spam emails dataset
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.20 – 垃圾邮件数据集
- en: As we can see, the dataset is highly imbalanced.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，数据集存在严重的类别不平衡问题。
- en: Content analysis
  id: totrans-378
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内容分析
- en: 'In this section, we are going to analyze the emails’ length and their distribution:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将分析邮件的长度及其分布：
- en: '![Figure 2.21 – Emails’ length](img/B16591_02_21.jpg)'
  id: totrans-380
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.21 – 邮件长度](img/B16591_02_21.jpg)'
- en: Figure 2.21 – Emails’ length
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.21 – 邮件长度
- en: 'There is a large outlier set corresponding to emails with more than 5,000 characters.
    Let’s zoom in to the area where most of the emails lie and graph the length and
    the word count:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 存在一个大范围的异常值集，对应邮件字符数超过5,000的情况。让我们聚焦于大多数邮件所在的区域，并绘制邮件长度和单词数的图表：
- en: '![Figure 2.22 – Emails’ length (detailed)](img/B16591_02_22.jpg)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.22 – 邮件长度（详细）](img/B16591_02_22.jpg)'
- en: Figure 2.22 – Emails’ length (detailed)
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.22 – 邮件长度（详细）
- en: '![Figure 2.23 – Emails’ word count](img/B16591_02_23.jpg)'
  id: totrans-385
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.23 – 邮件词汇数量](img/B16591_02_23.jpg)'
- en: Figure 2.23 – Emails’ word count
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.23 – 邮件词汇数量
- en: Important note
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In *Figure 2**.23*, we have defined a word without any semantic or dictionary
    approach, simply by specifying that each space-separated entity constitutes a
    word. This approach has disadvantages that we will analyze further in this recipe
    and in [*Chapter 5*](B16591_05.xhtml#_idTextAnchor098).
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 2.23*中，我们通过指定每个以空格分隔的实体构成一个词，定义了一个没有语义或字典方法的词汇。这种方法有缺点，我们将在本节和[*第 5 章*](B16591_05.xhtml#_idTextAnchor098)中进一步分析。
- en: By looking at this graph, we can conclude that in terms of emails’ length and
    word count, there is no significant difference between spam and legitimate emails.
    We will need to understand more about the words, their meaning, and their relationships
    to improve our analysis.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看该图，我们可以得出结论：在邮件长度和单词数方面，垃圾邮件和合法邮件之间没有显著差异。我们需要更多地了解这些词汇，它们的含义及其之间的关系，以改善我们的分析。
- en: 'Therefore, let’s start by looking at which words are most frequent in the dataset:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们首先看看数据集中哪些词最常见：
- en: '![Figure 2.24 – Most frequent words](img/B16591_02_24.jpg)'
  id: totrans-391
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.24 – 最常见的词汇](img/B16591_02_24.jpg)'
- en: Figure 2.24 – Most frequent words
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.24 – 最常见的词汇
- en: The first and most important conclusion after seeing *Figure 2**.24* is that
    our initial space-separation approach to differentiate words was not enough when
    dealing with real-world datasets. Punctuation errors and typos are very common,
    and furthermore, as expected, very common words such as “the” and “to” yield no
    real benefit in understanding the differences between spam and legitimate emails.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 看到*图 2.24*后的第一个也是最重要的结论是，我们最初的空格分隔方法在处理真实世界的数据集时并不足够。标点符号错误和拼写错误非常常见，而且，正如预期的那样，像“the”和“to”这样的常见词对于区分垃圾邮件和合法邮件没有实质性帮助。
- en: Data cleaning
  id: totrans-394
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据清理
- en: 'Let’s get rid of some common issues when working with real-world text datasets:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解决处理真实世界文本数据集时的一些常见问题：
- en: Punctuation
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标点符号
- en: Trailing characters
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尾随字符
- en: Clarifications” (text between square brackets)
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “说明”（方括号中的文本）
- en: Words containing numbers and links
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含数字和链接的词汇
- en: The word *subject* (specific to our email dataset structure)
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词汇*subject*（特定于我们的邮件数据集结构）
- en: 'After processing our corpus (text data specific to our problem) through our
    cleaning function, the results are more similar to our expectations:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 经过我们通过清理函数处理语料库（特定于我们问题的文本数据）后，结果更接近我们的预期：
- en: '![Figure 2.25 – Most frequent words (clean)](img/B16591_02_25.jpg)'
  id: totrans-402
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.25 – 最常见的词汇（清理过）](img/B16591_02_25.jpg)'
- en: Figure 2.25 – Most frequent words (clean)
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.25 – 最常见的词汇（清理过）
- en: In *Figure 2**.25*, we can see how the new word corpus we are analyzing contains
    real words. However, it is very clear that the most frequent words don't help
    to distinguish between spam and legitimate emails; words such as “the” and “to”
    are too common in the English language to be used properly for this classification.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 2.25*中，我们可以看到我们正在分析的新词汇语料库包含了真实的词汇。然而，很明显，最常见的词汇并未帮助区分垃圾邮件和合法邮件；像“the”和“to”这样的词在英语中过于常见，无法有效用于此分类。
- en: N-grams
  id: totrans-405
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: N-gram
- en: 'N-grams from a corpus in NLP are a set of *N* co-occurring words in the corpus.
    Typically in NLP, the most common N-grams are *unigrams* (one word), *bigrams*
    (two words), and *trigrams* (three words). Plotting the most frequent N-grams
    helps us understand relationships among words and classes (spam or not). A unigram
    is simply the most frequent word graph, as plotted in the previous section in
    *Figure 2**.25*. For bigrams (per class), see the following:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 在自然语言处理（NLP）中，语料库中的N-gram是指语料库中一组*同时出现的N*个词。通常在NLP中，最常见的N-gram是*unigrams*（一个词）、*bigrams*（两个词）和*trigrams*（三个词）。绘制最常见的N-gram有助于我们理解词语与类别（垃圾邮件或非垃圾邮件）之间的关系。Unigram只是最常见的词的图形，如在前面的*图
    2.25*中所绘制。对于bigrams（按类别），请参见下文：
- en: '![Figure 2.26 – Most frequent bigrams in ham (a) and spam (b)](img/B16591_02_26.jpg)'
  id: totrans-407
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.26 – 在“ham”（a）和“spam”（b）中最常见的二元组](img/B16591_02_26.jpg)'
- en: Figure 2.26 – Most frequent bigrams in ham (a) and spam (b)
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.26 – 在“ham”（a）和“spam”（b）中最常见的二元组
- en: 'For trigrams (per class), see the following:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 对于trigrams（按类别），请参见下文：
- en: '![Figure 2.27 – Most frequent trigrams in ham (a) and spam (b)](img/B16591_02_27.jpg)'
  id: totrans-410
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.27 – 在“ham”（a）和“spam”（b）中最常见的三元组](img/B16591_02_27.jpg)'
- en: Figure 2.27 – Most frequent trigrams in ham (a) and spam (b)
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.27 – 正常邮件（a）和垃圾邮件（b）中最常见的三元组
- en: 'In these graphs, we can start to grasp the underlying differences between the
    two classes:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些图表中，我们可以开始把握两类之间的潜在差异：
- en: If there is a mention of *Enron Corp*, it is very likely to be a legitimate
    email
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提到了*Enron公司*，那很可能是一封合法的电子邮件。
- en: If there is a polite call to action (“please let me know”), it is very likely
    to be a legitimate email
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果有礼貌的行动号召（“please let me know”），那很可能是一封合法的电子邮件。
- en: If there is a link, it is very likely to be spam
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果有链接，那很可能是垃圾邮件。
- en: If there are typos (*hou* instead of *how*, *ect* instead of *etc*, and so on),
    it is very likely to be a legitimate email
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果有拼写错误（*hou*代替*how*，*ect*代替*etc*，等等），那很可能是一封合法的电子邮件。
- en: If *pills* are mentioned, it is very likely to be spam (plus a bonus for repetitiveness)
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提到*pills*（药丸），那很可能是垃圾邮件（而且有重复的嫌疑）。
- en: 'We have also discovered that there are some nuances related to how the emails
    have been coded: `nbsp` (for non-breaking space). It is very likely that the email
    parser found some kind of unstructured spaces in the text and has redacted them
    with the `nbsp` keyword. Coincidentally, these types of parsing nuances are much
    more common in spam emails than in legitimate ones, which will help us in our
    analysis.'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还发现了一些与电子邮件编码方式相关的细微差别：`nbsp`（用于非断行空格）。很可能是电子邮件解析器在文本中发现了一些结构不清的空格，并用`nbsp`关键字进行了替换。巧合的是，这些解析细节在垃圾邮件中比在合法邮件中出现得要多，这将有助于我们的分析。
- en: Word processing
  id: totrans-419
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文字处理
- en: 'Processing words in text is typically composed of four steps:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 处理文本中的单词通常由四个步骤组成：
- en: Tokenizing
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分词
- en: Stop-words filtering
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 停用词过滤
- en: Stemming
  id: totrans-423
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 词干提取
- en: Lemmatization
  id: totrans-424
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 词形还原
- en: 'These steps have their own individual complexity, and therefore we will use
    libraries available to run these steps, such as the **Natural Language Toolkit**
    (**NLTK**). To install it, run the following command:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤各自具有一定的复杂性，因此我们将使用可用的库来执行这些步骤，例如**自然语言工具包**（**NLTK**）。要安装它，请运行以下命令：
- en: '[PRE36]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '**Tokenizing** is the step that processes a text and returns a list of **tokens**.
    Each word is a token, but if there are also punctuation marks, these would become
    separate tokens. Nevertheless, for our corpus, these have been removed in a previous
    step.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: '**分词**是处理文本并返回**标记**列表的步骤。每个单词是一个标记，但如果有标点符号，它们会成为单独的标记。不过，对于我们的语料库，这些在之前的步骤中已被移除。'
- en: Please note that in this step, we have moved from a list of sentences and paragraphs
    per email, the corpus, to what is known as **bag of words** or **BOW**, which
    is directly connected to the vocabulary used in the corpus.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这个步骤中，我们已经从每封电子邮件的句子和段落列表（语料库）转换到所谓的**词袋模型**（**BOW**），它与语料库中使用的词汇直接相关。
- en: After we have each word as an entity, we can remove those common words we had
    already identified such as “the” or “to." These are known as stop words, and NLTK
    contains a set of these stop words for several languages. We will use this available
    set to filter our corpus.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们将每个单词作为一个实体之后，我们可以移除之前已识别出的常见词，如“the”或“to”。这些被称为停用词，NLTK包含多个语言的停用词集。我们将使用这个可用的集合来过滤我们的语料库。
- en: Stemming is the process of reducing derived (and inflected, if we want to be
    formal) words to their root, known as the stem.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 词干提取是将派生（如果我们想更正式些，也包括屈折）词汇缩减到其词根的过程，词根称为词干。
- en: 'Lemmatization is the process of grouping together several different forms that
    can be analyzed as a single item, identified by the word’s lemma, or dictionary
    form:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 词形还原是将多个不同形式的词汇归类为一个单一项的过程，这个单一项由单词的词根或词典形式（lemma）标识：
- en: '![Figure 2.28 – Stemming and lemmatization](img/B16591_02_28.jpg)'
  id: totrans-432
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.28 – 词干提取和词形还原](img/B16591_02_28.jpg)'
- en: Figure 2.28 – Stemming and lemmatization
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.28 – 词干提取和词形还原
- en: 'After processing our BOW through these steps, we have reduced the number of
    words we are working with to ~10% of the corpus:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 经过这些步骤处理后，我们的词袋模型中剩下的单词数量大约是语料库的10%：
- en: '[PRE37]'
  id: totrans-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Word clouds
  id: totrans-436
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词云
- en: 'With our postprocessed BOW, we can generate one of the most impactful and popular
    visualizations of a text corpus, a word cloud:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们后处理的词袋模型（BOW），我们可以生成文本语料库的最具影响力和最受欢迎的可视化图像之一——词云：
- en: '![Figure 2.29 – Word clouds for (a) ham and (b) spam](img/B16591_02_29.jpg)'
  id: totrans-438
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.29 – 正常邮件（a）和垃圾邮件（b）中的词云](img/B16591_02_29.jpg)'
- en: Figure 2.29 – Word clouds for (a) ham and (b) spam
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.29 – 正常邮件（a）和垃圾邮件（b）中的词云
- en: In these visualizations we can clearly see how *Enron*, *please*, and *let know*
    are relevant for legitimate emails, whereas *new*, *nbsp*, *compani*, *market*,
    and *product* are typically connected to spam emails.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些可视化中，我们可以清楚地看到*Enron*、*please*和*let know*对合法邮件是相关的，而*new*、*nbsp*、*compani*、*market*和*product*通常与垃圾邮件相关。
- en: Word embeddings
  id: totrans-441
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词嵌入
- en: So far, we have taken a look at how individual words behave (frequency and length)
    and their connections to other words in terms of the most frequent N-grams (bigrams
    and trigrams). However, we have not connected the meaning of the words among them.
    For example, one would expect that *Enron*, *corp*, and *company* (*compani*,
    its stemmed counterpart) are close from a semantic point of view. Therefore, we
    would like to have a representation where words with a similar meaning would have
    a similar representation. Furthermore, if that representation had a constant number
    of dimensions, we could easily make comparisons (find similarities) among words.
    These are word embeddings, and the representation is a vector.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了单个单词的表现（频率和长度）及其与其他单词的连接，主要通过最常见的N-gram（双字组和三字组）。然而，我们还没有将这些单词之间的意义进行连接。例如，我们会预期*Enron*、*corp*和*company*（*compani*，它的词干形式）在语义上是相近的。因此，我们希望有一种表示方式，使得具有相似意义的单词有相似的表示方式。此外，如果这种表示方式具有固定数量的维度，我们就能方便地对单词进行比较（找出相似性）。这些就是词嵌入（word
    embeddings），其表示就是一个向量。
- en: There are infinite ways of generating vectors from words; for example, the most
    naive way to accomplish this is to generate as many dimensions (features of our
    vector, columns in a matrix representation) as our vocabulary, and then in each
    email (a row in the matrix representation), for each word that it contains, we
    can put a *1* (checkmark) in the column for that word in the vocabulary, resulting
    in vectors of the form [0, 0, 0, 0 ......, 1, 0, 0, 0,...., 1.....]. This representation
    is called one-hot encoding, but it is very inefficient as the number of features
    is the number of distinct words in the corpus, the length of the vocabulary, which
    is typically very high (~500k with our reduced vocabulary).
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 从单词生成向量的方法有无数种；例如，实现这一目标的最简单方法是生成与我们的词汇量相同数量的维度（向量的特征，即矩阵表示中的列），然后在每封邮件中（矩阵表示中的一行），对于每个包含的单词，我们可以在该单词在词汇表中的列中标注*1*（打钩），从而得到形如[0,
    0, 0, 0......, 1, 0, 0, 0,..., 1....]的向量表示。这种表示方法称为独热编码，但它效率非常低，因为特征的数量等于语料库中不同单词的数量，也就是词汇表的长度，这通常是非常大的（我们的简化词汇表约有50万个单词）。
- en: 'Therefore, we will take a look at more optimal ways to represent our words:
    word2vec and GloVe:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将看一看更优化的单词表示方式：word2vec和GloVe：
- en: '**word2vec**: This algorithm was developed by Google in 2013 and is available
    pre-trained on the *Google News* corpus. It has a corpus of 3 billion words and
    a vocabulary of 3 million distinct words, each represented with 300 features.
    The intuition behind this algorithm is to calculate the probability of a given
    word by taking into account its context (surrounding words). The window size (how
    many words are being looked at the same time) is a parameter of the model and
    is a constant, which makes the model rely solely on the local context of each
    word.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**word2vec**：该算法由谷歌于2013年开发，并在*Google News*语料库上进行了预训练。它的语料库包含30亿个单词，词汇量有300万个不同的单词，每个单词用300个特征表示。该算法的直观思路是通过考虑上下文（周围单词）来计算给定单词的概率。窗口大小（一次查看多少个单词）是模型的一个参数，并且是常量，这使得模型仅依赖于每个单词的局部上下文。'
- en: '`word2vec` combined with word co-occurrence (global statistics) to provide
    a more complete representation.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`word2vec`结合了单词共现（全局统计）来提供更完整的表示。'
- en: 'With these representations, we can now compute operations in words in their
    new vector representations:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些表示，我们现在可以在单词的新的向量表示中计算操作：
- en: '`stronger` is to `strong` what `weaker` is to `weak`:'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`stronger`与`strong`的关系就像`weaker`与`weak`的关系：'
- en: '[PRE38]'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This generates an output of `~1.9`, which is close.
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将生成约为`~1.9`的输出，结果接近。
- en: '`king`:'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`king`：'
- en: '[PRE39]'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The observant reader will have realized that word embeddings are similar to
    the techniques we saw in the previous recipe for dimensionality reduction, as
    those were learned representations as well. However, in this case, we are actually
    increasing the dimensionality to obtain new advantages (constant number of features
    and similar meaning representation).
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 细心的读者会意识到，词嵌入与我们在前一个维度降维的例子中看到的技术相似，因为那也是学习到的表示。然而，在这种情况下，我们实际上是增加了维度，以获得新的优势（固定数量的特征和相似的意义表示）。
- en: Important note
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Word embeddings are typically *learned* representations; that is, the representations
    are trained to minimize the distance among words that have a similar meaning or,
    in our case, are classified with the same label. In this recipe, we will use pre-trained
    representations for `word2vec` and GloVe, and in [*Chapter 5*](B16591_05.xhtml#_idTextAnchor098),
    we will take a look at training.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 词嵌入通常是*学习*出来的表示；也就是说，这些表示通过训练来最小化具有相似含义的词语之间的距离，或者在我们的案例中，是通过相同标签分类的词语。在这个食谱中，我们将使用`word2vec`和GloVe的预训练表示，在[*第5章*](B16591_05.xhtml#_idTextAnchor098)中，我们将学习如何进行训练。
- en: PCA and t-SNE
  id: totrans-456
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PCA和t-SNE
- en: As discussed in "the subsection", our current embeddings have either 300 features
    (`word2vec`) or 50 (GloVe). For proper visualizations, we need to apply dimensionality
    reduction techniques, as we saw in the previous recipe for CV.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 正如“子章节”中所讨论的那样，我们当前的嵌入包含300个特征（`word2vec`）或50个特征（GloVe）。为了进行合适的可视化，我们需要应用降维技术，正如我们在之前关于计算机视觉的食谱中所看到的那样。
- en: 'For this dataset, we can apply PCA:'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个数据集，我们可以应用PCA：
- en: '![Figure 2.30 – PCA for (a) word2vec and (b) GloVe embeddings](img/B16591_02_30.jpg)'
  id: totrans-459
  prefs: []
  type: TYPE_IMG
  zh: '![图2.30 – PCA用于(a) word2vec和(b) GloVe嵌入](img/B16591_02_30.jpg)'
- en: Figure 2.30 – PCA for (a) word2vec and (b) GloVe embeddings
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.30 – PCA用于(a) word2vec和(b) GloVe嵌入
- en: 'Moreover, we can apply t-SNE as well:'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还可以应用t-SNE：
- en: '![Figure 2.31 – t-SNE for (a) word2vec and (b) GloVe embeddings](img/B16591_02_31.jpg)'
  id: totrans-462
  prefs: []
  type: TYPE_IMG
  zh: '![图2.31 – t-SNE用于(a) word2vec和(b) GloVe嵌入](img/B16591_02_31.jpg)'
- en: Figure 2.31 – t-SNE for (a) word2vec and (b) GloVe embeddings
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.31 – t-SNE用于(a) word2vec和(b) GloVe嵌入
- en: From the preceding plots, we can see how the ham and spam words in our embedding
    space are very close to each other, making it very difficult to separate the clusters.
    This is due to the fact that we are using pre-trained embeddings, from the news
    and Wikipedia datasets. These datasets and the corresponding embeddings are not
    suited to our task at hand. We will see how to train word embeddings to achieve
    better results in [*Chapter 5*](B16591_05.xhtml#_idTextAnchor098).
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 从之前的图中，我们可以看到垃圾邮件和正常邮件的词汇在我们的嵌入空间中非常接近，这使得分离这些簇变得非常困难。这是因为我们使用的是预训练的嵌入，来自新闻和维基百科数据集。这些数据集及其相应的嵌入并不适合我们的任务。我们将在[*第5章*](B16591_05.xhtml#_idTextAnchor098)中看到如何训练词嵌入以获得更好的结果。
- en: Important note
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'For PCA and t-SNE, we can choose three components instead of two, which will
    yield a 3D plot. For the code, visit the GitHub repository of the book: [https://github.com/PacktPublishing/Deep-Learning-with-MXNet-Cookbook](https://github.com/PacktPublishing/Deep-Learning-with-MXNet-Cookbook).'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 对于PCA和t-SNE，我们可以选择三个组件，而不是两个，这样可以得到一个三维图。有关代码，请访问本书的GitHub仓库：[https://github.com/PacktPublishing/Deep-Learning-with-MXNet-Cookbook](https://github.com/PacktPublishing/Deep-Learning-with-MXNet-Cookbook)。
- en: How it works...
  id: totrans-467
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: To understand the corpus of a text dataset, we need to understand the underlying
    connections among words in that corpus. One useful method to achieve this is with
    different visualizations of the corpus.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解文本数据集的语料库，我们需要理解该语料库中单词之间的潜在联系。实现这一目标的一个有用方法是通过不同的语料库可视化来帮助我们理解。
- en: In this recipe, we have learned how to discover patterns in our text datasets.
    We selected an imbalanced dataset, the *Enron Email* dataset, and we learned how
    to deal with binary classification datasets.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个食谱中，我们学会了如何发现文本数据集中的模式。我们选择了一个不平衡的数据集——*Enron电子邮件*数据集，并学习了如何处理二分类数据集。
- en: We analyzed our dataset by taking a look at its internal structure and what
    the class imbalance looked like and checked the most common words in search of
    patterns and errors. We cleaned the dataset by removing punctuation marks, and
    we graphed the most frequent **bigrams** and **trigrams** and noticed several
    keywords that would help us classify our emails correctly.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过查看数据集的内部结构，了解类不平衡的情况，并检查最常见的词汇，寻找其中的模式和错误。我们清理了数据集，移除了标点符号，并绘制了最常见的**二元组**和**三元组**，并注意到几个有助于我们正确分类电子邮件的关键词。
- en: We learned how to generate some cool visualizations such as **word clouds**,
    and we understood why **word embeddings** are important and plotted them using
    the **dimensionality reduction techniques** we learned previously.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学会了如何生成一些酷炫的可视化效果，如**词云**，并且理解了为什么**词嵌入**如此重要，并使用我们之前学到的**降维技术**对其进行了绘制。
- en: There’s more…
  id: totrans-472
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多内容…
- en: 'If you want to know more about the Enron Email dataset and the Enron scandal,
    the following links will help:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于Enron电子邮件数据集和Enron丑闻的信息，以下链接将有所帮助：
- en: '**Enron Email** **dataset**: [http://www.cs.cmu.edu/~enron/](http://www.cs.cmu.edu/~enron/)'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安然电子邮件** **数据集**: [http://www.cs.cmu.edu/~enron/](http://www.cs.cmu.edu/~enron/)'
- en: '**Enron** **scandal**: [https://en.wikipedia.org/wiki/Enron_scandal](https://en.wikipedia.org/wiki/Enron_scandal)'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安然** **丑闻**: [https://en.wikipedia.org/wiki/Enron_scandal](https://en.wikipedia.org/wiki/Enron_scandal)'
- en: 'We had a brief overview of several important concepts I invite you to learn
    more about:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简要概述了几个重要的概念，我邀请你进一步了解：
- en: '**BOW**: [https://machinelearningmastery.com/gentle-introduction-bag-words-model/](https://machinelearningmastery.com/gentle-introduction-bag-words-model/)'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BOW**: [https://machinelearningmastery.com/gentle-introduction-bag-words-model/](https://machinelearningmastery.com/gentle-introduction-bag-words-model/)'
- en: '**N-grams**: [https://web.stanford.edu/~jurafsky/slp3/3.pdf](https://web.stanford.edu/~jurafsky/slp3/3.pdf)'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**N-grams**: [https://web.stanford.edu/~jurafsky/slp3/3.pdf](https://web.stanford.edu/~jurafsky/slp3/3.pdf)'
- en: '**Word** **clouds**: [https://amueller.github.io/word_cloud/](https://amueller.github.io/word_cloud/)'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**词云**: [https://amueller.github.io/word_cloud/](https://amueller.github.io/word_cloud/)'
- en: 'Furthermore, we barely scratched the surface of what word embeddings can offer:'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们只是浅尝辄止地触及了词嵌入所能提供的内容：
- en: '**word2vec**: [https://code.google.com/archive/p/word2vec/](https://code.google.com/archive/p/word2vec/)'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**word2vec**: [https://code.google.com/archive/p/word2vec/](https://code.google.com/archive/p/word2vec/)'
- en: '**GloVe**: [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GloVe**: [https://nlp.stanford.edu/projects/glove/](https://nlp.stanford.edu/projects/glove/)'
