- en: ChapterÂ 6
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ç¬¬6ç« 
- en: Using the Standard Toolbox for Bayesian Deep Learning
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨æ ‡å‡†å·¥å…·ç®±è¿›è¡Œè´å¶æ–¯æ·±åº¦å­¦ä¹ 
- en: As we saw in previous chapters, vanilla NNs often produce poor uncertainty estimates
    and tend to make overconfident predictions, and some arenâ€™t capable of producing
    uncertainty estimates at all. By contrast, probabilistic architectures offer principled
    means to obtain high-quality uncertainty estimates; however, they have a number
    of limitations when it comes to scaling and adaptability.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚æˆ‘ä»¬åœ¨å‰é¢çš„ç« èŠ‚ä¸­çœ‹åˆ°çš„ï¼Œæ™®é€šçš„ç¥ç»ç½‘ç»œå¾€å¾€äº§ç”Ÿè¾ƒå·®çš„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œå¹¶ä¸”å¾€å¾€ä¼šåšå‡ºè¿‡äºè‡ªä¿¡çš„é¢„æµ‹ï¼Œè€Œæœ‰äº›ç”šè‡³æ ¹æœ¬æ— æ³•ç”Ÿæˆä¸ç¡®å®šæ€§ä¼°è®¡ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œæ¦‚ç‡æ¶æ„æä¾›äº†è·å¾—é«˜è´¨é‡ä¸ç¡®å®šæ€§ä¼°è®¡çš„åŸåˆ™æ€§æ–¹æ³•ï¼›ç„¶è€Œï¼Œåœ¨æ‰©å±•æ€§å’Œé€‚åº”æ€§æ–¹é¢ï¼Œå®ƒä»¬æœ‰ä¸€äº›å±€é™æ€§ã€‚
- en: While both PBP and BBB can be implemented with popular ML frameworks (as shown
    in our previous TensorFlow examples), they are very complex. As we saw in the
    last chapter, implementing even a simple network isnâ€™t straightforward. This means
    that adapting them to new architectures is awkward and time-consuming (particularly
    for PBP, although it is possible â€“ see *Fully Bayesian Recurrent Neural Networks
    for Safe Reinforcement* *Learning*). For simple tasks, such as the examples from
    *Chapter 5, Principled* *Approaches for Bayesian Deep Learning*, this isnâ€™t an
    issue. But in many real-world tasks, such as
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡PBPå’ŒBBBéƒ½å¯ä»¥é€šè¿‡æµè¡Œçš„æœºå™¨å­¦ä¹ æ¡†æ¶æ¥å®ç°ï¼ˆæ­£å¦‚æˆ‘ä»¬åœ¨ä¹‹å‰çš„TensorFlowç¤ºä¾‹ä¸­æ‰€å±•ç¤ºçš„ï¼‰ï¼Œä½†å®ƒä»¬éå¸¸å¤æ‚ã€‚æ­£å¦‚æˆ‘ä»¬åœ¨ä¸Šä¸€ç« ä¸­çœ‹åˆ°çš„ï¼Œå®ç°ä¸€ä¸ªç®€å•çš„ç½‘ç»œä¹Ÿå¹¶éæ˜“äº‹ã€‚è¿™æ„å‘³ç€å°†å®ƒä»¬é€‚åº”åˆ°æ–°æ¶æ„ä¸­æ˜¯ä¸€ä¸ªç¬¨æ‹™ä¸”è€—æ—¶çš„è¿‡ç¨‹ï¼ˆç‰¹åˆ«æ˜¯PBPï¼Œå°½ç®¡æ˜¯å¯èƒ½çš„â€”â€”å‚è§*å®Œå…¨è´å¶æ–¯é€’å½’ç¥ç»ç½‘ç»œç”¨äºå®‰å…¨å¼ºåŒ–*
    *å­¦ä¹ *ï¼‰ã€‚å¯¹äºä¸€äº›ç®€å•ä»»åŠ¡ï¼Œä¾‹å¦‚*ç¬¬5ç« ï¼Œè´å¶æ–¯æ·±åº¦å­¦ä¹ çš„åŸåˆ™æ€§æ–¹æ³•*ä¸­çš„ç¤ºä¾‹ï¼Œè¿™å¹¶ä¸æ˜¯é—®é¢˜ã€‚ä½†åœ¨è®¸å¤šç°å®ä¸–ç•Œçš„ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚
- en: machine translation or object recognition, far more sophisticated network architectures
    are necessary.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨ç¿»è¯‘æˆ–ç‰©ä½“è¯†åˆ«ç­‰ä»»åŠ¡ï¼Œéœ€è¦æ›´ä¸ºå¤æ‚çš„ç½‘ç»œæ¶æ„ã€‚
- en: While some academic institutions or large research organizations may have the
    time and resources required to adapt these complex probabilistic methods to a
    variety of sophisticated architectures, in many cases this simply is not viable.
    Additionally, more and more industry researchers and engineers are turning to
    transfer learning-based methods, using pre-trained networks as the backbone of
    their models. In these cases, itâ€™s impossible to simply add probabilistic machinery
    to predefined architectures.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶ä¸€äº›å­¦æœ¯æœºæ„æˆ–å¤§å‹ç ”ç©¶ç»„ç»‡å¯èƒ½å…·å¤‡è¶³å¤Ÿçš„æ—¶é—´å’Œèµ„æºæ¥å°†è¿™äº›å¤æ‚çš„æ¦‚ç‡æ–¹æ³•é€‚åº”åˆ°å„ç§å¤æ‚çš„æ¶æ„ä¸­ï¼Œä½†åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œè¿™å¹¶ä¸å¯è¡Œã€‚æ­¤å¤–ï¼Œè¶Šæ¥è¶Šå¤šçš„è¡Œä¸šç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆæ­£åœ¨è½¬å‘åŸºäºè¿ç§»å­¦ä¹ çš„æ–¹æ³•ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„ç½‘ç»œä½œä¸ºæ¨¡å‹çš„éª¨å¹²ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œç®€å•åœ°å°†æ¦‚ç‡æœºåˆ¶æ·»åŠ åˆ°é¢„å®šä¹‰æ¶æ„ä¸­æ˜¯ä¸å¯è¡Œçš„ã€‚
- en: To address this, in this chapter, we will explore how common paradigms in deep
    learning can be harnessed to develop probabilistic models. The methods introduced
    here show that, with relatively minor tweaks, you can easily adapt large, sophisticated
    architectures to produce high-quality uncertainty estimates. Weâ€™ll even introduce
    techniques that will enable you to get uncertainty estimates from networks youâ€™ve
    already trained!
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬ç« å°†æ¢è®¨å¦‚ä½•åˆ©ç”¨æ·±åº¦å­¦ä¹ ä¸­çš„å¸¸è§èŒƒå¼æ¥å¼€å‘æ¦‚ç‡æ¨¡å‹ã€‚è¿™é‡Œä»‹ç»çš„æ–¹æ³•è¡¨æ˜ï¼Œé€šè¿‡ç›¸å¯¹è¾ƒå°çš„è°ƒæ•´ï¼Œæ‚¨å¯ä»¥è½»æ¾åœ°å°†å¤§å‹å¤æ‚æ¶æ„é€‚åº”åˆ°é«˜è´¨é‡çš„ä¸ç¡®å®šæ€§ä¼°è®¡ä¸­ã€‚æˆ‘ä»¬ç”šè‡³ä¼šä»‹ç»ä¸€äº›æŠ€æœ¯ï¼Œä½¿æ‚¨èƒ½å¤Ÿä»å·²è®­ç»ƒçš„ç½‘ç»œä¸­è·å–ä¸ç¡®å®šæ€§ä¼°è®¡ï¼
- en: The chapter will cover three key approaches for facilitating model uncertainty
    estimation easily with common deep learning frameworks. First, we will look at
    **Monte Carlo Dropout** (**MC dropout**), a method that induces variance across
    predictions by utilizing dropout at inference time. Second, we will introduce
    deep ensembles, whereby multiple neural networks are combined to facilitate both
    uncertainty estimation and improved model performance. Finally, we will explore
    various methods for adding a Bayesian layer to our model, allowing any model to
    produce uncertainty estimates.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ç« å°†æ¶µç›–ä¸‰ç§å…³é”®æ–¹æ³•ï¼Œä»¥ä¾¿åœ¨å¸¸è§çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­è½»æ¾è¿›è¡Œæ¨¡å‹ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å°†ä»‹ç»**è’™ç‰¹å¡æ´› Dropout**ï¼ˆ**MC dropout**ï¼‰ï¼Œä¸€ç§é€šè¿‡åœ¨æ¨ç†æ—¶ä½¿ç”¨Dropoutæ¥å¼•å…¥é¢„æµ‹æ–¹å·®çš„æ–¹æ³•ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å°†ä»‹ç»æ·±åº¦é›†æˆæ–¹æ³•ï¼Œå³é€šè¿‡ç»“åˆå¤šä¸ªç¥ç»ç½‘ç»œæ¥ä¿ƒè¿›ä¸ç¡®å®šæ€§ä¼°è®¡å’Œæé«˜æ¨¡å‹æ€§èƒ½ã€‚æœ€åï¼Œæˆ‘ä»¬å°†æ¢ç´¢å°†è´å¶æ–¯å±‚æ·»åŠ åˆ°æ¨¡å‹ä¸­çš„å„ç§æ–¹æ³•ï¼Œä½¿ä»»ä½•æ¨¡å‹éƒ½èƒ½äº§ç”Ÿä¸ç¡®å®šæ€§ä¼°è®¡ã€‚
- en: 'These topics will be covered in the following sections:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹å†…å®¹å°†åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­è®¨è®ºï¼š
- en: Introducing approximate Bayesian inference via dropout
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é€šè¿‡Dropoutå¼•å…¥è¿‘ä¼¼è´å¶æ–¯æ¨æ–­
- en: Using ensembles for model uncertainty estimates
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä½¿ç”¨é›†æˆæ–¹æ³•è¿›è¡Œæ¨¡å‹ä¸ç¡®å®šæ€§ä¼°è®¡
- en: Exploring neural network augmentation with Bayesian last-layer methods
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¢ç´¢é€šè¿‡è´å¶æ–¯æœ€åä¸€å±‚æ–¹æ³•å¢å¼ºç¥ç»ç½‘ç»œ
- en: 6.1 Technical requirements
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 æŠ€æœ¯è¦æ±‚
- en: 'To complete the practical tasks in this chapter, you will need a Python 3.8
    environment with the SciPy stack and the following additional Python packages
    installed:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¦å®Œæˆæœ¬ç« çš„å®é™…ä»»åŠ¡ï¼Œæ‚¨éœ€è¦ä¸€ä¸ª Python 3.8 ç¯å¢ƒï¼Œå¹¶å®‰è£… SciPy å †æ ˆä»¥åŠä»¥ä¸‹é™„åŠ çš„ Python åŒ…ï¼š
- en: TensorFlow 2.0
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow 2.0
- en: TensorFlow Probability
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow æ¦‚ç‡
- en: 'All of the code for this book can be found on the GitHub repository for the
    book: [https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference](https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬ä¹¦çš„æ‰€æœ‰ä»£ç å¯ä»¥åœ¨æœ¬ä¹¦çš„ GitHub ä»“åº“æ‰¾åˆ°ï¼š[https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference](https://github.com/PacktPublishing/Enhancing-Deep-Learning-with-Bayesian-Inference)ã€‚
- en: 6.2 Introducing approximate Bayesian inference via dropout
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 é€šè¿‡ dropout å¼•å…¥è¿‘ä¼¼è´å¶æ–¯æ¨æ–­
- en: '**Dropout** is traditionally used to prevent overfitting an NN. First introduced
    in 2012, it is now used in many common NN architectures and is one of the easiest
    and most widely used regularization methods. The idea of dropout is to randomly
    turn off (or drop) certain units of a neural network during training. Because
    of this, the model cannot solely rely on a particular small subset of neurons
    to solve the task it was given. Instead, the model is forced to find different
    ways to solve its task. This improves the robustness of the model and makes it
    less likely to overfit.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dropout** ä¼ ç»Ÿä¸Šç”¨äºé˜²æ­¢ç¥ç»ç½‘ç»œçš„è¿‡æ‹Ÿåˆã€‚å®ƒæœ€æ—©åœ¨ 2012 å¹´æå‡ºï¼Œç°åœ¨è¢«å¹¿æ³›åº”ç”¨äºè®¸å¤šå¸¸è§çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œå¹¶ä¸”æ˜¯æœ€ç®€å•ä¸”æœ€å¸¸ç”¨çš„æ­£åˆ™åŒ–æ–¹æ³•ä¹‹ä¸€ã€‚Dropout
    çš„æ ¸å¿ƒæ€æƒ³æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœºå…³é—­ï¼ˆæˆ–ä¸¢å¼ƒï¼‰ç¥ç»ç½‘ç»œçš„æŸäº›å•å…ƒã€‚å› æ­¤ï¼Œæ¨¡å‹ä¸èƒ½ä»…ä¾èµ–æŸä¸€å°éƒ¨åˆ†ç¥ç»å…ƒæ¥è§£å†³ä»»åŠ¡ã€‚ç›¸åï¼Œæ¨¡å‹è¢«è¿«æ‰¾åˆ°ä¸åŒçš„æ–¹å¼æ¥å®Œæˆä»»åŠ¡ã€‚è¿™æé«˜äº†æ¨¡å‹çš„é²æ£’æ€§ï¼Œå¹¶ä½¿å…¶ä¸å¤ªå¯èƒ½è¿‡æ‹Ÿåˆã€‚'
- en: 'If we simplify a network to *y* = *Wx*, where *y* is the output of our network,
    *x* the input, and *W* our model weights, we can think of dropout as:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬ç®€åŒ–ä¸€ä¸ªç½‘ç»œä¸º *y* = *Wx*ï¼Œå…¶ä¸­ *y* æ˜¯æˆ‘ä»¬ç½‘ç»œçš„è¾“å‡ºï¼Œ*x* æ˜¯è¾“å…¥ï¼Œ*W* æ˜¯æˆ‘ä»¬çš„æ¨¡å‹æƒé‡ï¼Œæˆ‘ä»¬å¯ä»¥å°† dropout ç†è§£ä¸ºï¼š
- en: '![ ( { wj, p wË†j = ( 0, otherwise ](img/file139.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![ ( { wj, p wË†j = ( 0, otherwise ](img/file139.jpg)'
- en: where *w*[*j*] is the new weights after applying dropout, *w*[*j*] is our weights
    before applying dropout, and *p* is our probability of *not* applying dropout.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: å…¶ä¸­ *w*[*j*] æ˜¯åº”ç”¨ dropout åçš„æ–°æƒé‡ï¼Œ*w*[*j*] æ˜¯åº”ç”¨ dropout å‰çš„æƒé‡ï¼Œ*p* æ˜¯æˆ‘ä»¬ä¸åº”ç”¨ dropout çš„æ¦‚ç‡ã€‚
- en: 'The original dropout paper recommends randomly dropping 50% of the units in
    a network and applying dropout to all layers. Input layers should not have the
    same dropout probability because this would mean that we throw away 50% of the
    input information for our network, which makes it more difficult for the model
    to converge. In practice, you can experiment with different dropout probabilities
    to find the dropout rate that works well for your specific dataset and model;
    that is another hyperparameter you can optimize. Dropout is typically available
    as a standalone layer in all standard neural network libraries you can find online.
    You typically add it after your activation function:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: åŸå§‹çš„ dropout è®ºæ–‡å»ºè®®éšæœºä¸¢å¼ƒç½‘ç»œä¸­ 50% çš„å•å…ƒï¼Œå¹¶å¯¹æ‰€æœ‰å±‚åº”ç”¨ dropoutã€‚è¾“å…¥å±‚çš„ dropout æ¦‚ç‡ä¸åº”ç›¸åŒï¼Œå› ä¸ºè¿™æ„å‘³ç€æˆ‘ä»¬ä¸¢å¼ƒäº†
    50% çš„è¾“å…¥ä¿¡æ¯ï¼Œè¿™ä¼šä½¿æ¨¡å‹æ›´éš¾æ”¶æ•›ã€‚å®é™…ä¸Šï¼Œæ‚¨å¯ä»¥å°è¯•ä¸åŒçš„ dropout æ¦‚ç‡ï¼Œæ‰¾åˆ°æœ€é€‚åˆæ‚¨çš„ç‰¹å®šæ•°æ®é›†å’Œæ¨¡å‹çš„ä¸¢å¼ƒç‡ï¼›è¿™æ˜¯å¦ä¸€ä¸ªæ‚¨å¯ä»¥ä¼˜åŒ–çš„è¶…å‚æ•°ã€‚Dropout
    é€šå¸¸ä½œä¸ºä¸€ä¸ªç‹¬ç«‹çš„å±‚ï¼Œåœ¨æ‰€æœ‰æ ‡å‡†çš„ç¥ç»ç½‘ç»œåº“ä¸­éƒ½å¯ä»¥æ‰¾åˆ°ã€‚æ‚¨é€šå¸¸åœ¨æ¿€æ´»å‡½æ•°ä¹‹åæ·»åŠ å®ƒï¼š
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now that weâ€™ve been reminded of the vanilla application of dropout, letâ€™s look
    at how we can use it for Bayesian inference.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»å›é¡¾äº† dropout çš„åŸºæœ¬åº”ç”¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•å°†å…¶ç”¨äºè´å¶æ–¯æ¨æ–­ã€‚
- en: 6.2.1 Using dropout for approximate Bayesian inference
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.1 ä½¿ç”¨ dropout è¿›è¡Œè¿‘ä¼¼è´å¶æ–¯æ¨æ–­
- en: 'Traditional dropout methods make the prediction of dropout networks deterministic
    at test time by turning off dropout during inference. However, we can also use
    the stochasticity of dropout to our advantage. This is called **Monte** **Carlo
    (MC)** dropout, and the idea is as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: ä¼ ç»Ÿçš„ dropout æ–¹æ³•ä½¿å¾—åœ¨æµ‹è¯•æ—¶ dropout ç½‘ç»œçš„é¢„æµ‹æ˜¯ç¡®å®šæ€§çš„ï¼Œå› ä¸ºåœ¨æ¨ç†è¿‡ç¨‹ä¸­å…³é—­äº† dropoutã€‚ç„¶è€Œï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥åˆ©ç”¨ dropout
    çš„éšæœºæ€§æ¥ä¸ºæˆ‘ä»¬å¸¦æ¥ä¼˜åŠ¿ã€‚è¿™å°±æ˜¯æ‰€è°“çš„ **è’™ç‰¹å¡ç½— (MC)** dropoutï¼Œå…¶æ€æƒ³å¦‚ä¸‹ï¼š
- en: We use dropout during test time.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨æµ‹è¯•æ—¶ä½¿ç”¨ dropoutã€‚
- en: Instead of running inference once, we run it many times (for example, 30-100
    times).
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸æ˜¯åªè¿è¡Œä¸€æ¬¡æ¨ç†ï¼Œè€Œæ˜¯è¿è¡Œå¤šæ¬¡ï¼ˆä¾‹å¦‚ï¼Œ30-100 æ¬¡ï¼‰ã€‚
- en: We then average the predictions to get our uncertainty estimates.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯¹é¢„æµ‹ç»“æœå–å¹³å‡ï¼Œä»¥è·å¾—æˆ‘ä»¬çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚
- en: Why is this beneficial? As we said before, using dropout forces the model to
    learn different ways to solve its task. So, when we keep dropout enabled during
    inference, we use slightly different networks that all process the input via a
    slightly different path through the model. This diversity is helpful when we want
    a calibrated uncertainty score, as we will see in the next section, where we will
    discuss the concept of deep ensembles. Instead of predicting a point estimate
    (a single value) for each input, our network now produces a distribution of values
    (made up of multiple forward passes). We can use this distribution to compute
    a mean and variance associated with each input data point, as shown in *Figure*
    [*6.1*](#x1-85011r1).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆè¿™æœ‰ç›Šï¼Ÿæ­£å¦‚æˆ‘ä»¬ä¹‹å‰æ‰€è¯´ï¼Œä½¿ç”¨dropoutå¯ä»¥è¿«ä½¿æ¨¡å‹å­¦ä¹ è§£å†³ä»»åŠ¡çš„ä¸åŒæ–¹æ³•ã€‚å› æ­¤ï¼Œå½“æˆ‘ä»¬åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¿æŒå¯ç”¨dropoutæ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ç¨å¾®ä¸åŒçš„ç½‘ç»œï¼Œè¿™äº›ç½‘ç»œé€šè¿‡æ¨¡å‹çš„ä¸åŒè·¯å¾„å¤„ç†è¾“å…¥æ•°æ®ã€‚è¿™ç§å¤šæ ·æ€§åœ¨æˆ‘ä»¬å¸Œæœ›è·å¾—æ ¡å‡†çš„**ä¸ç¡®å®šæ€§è¯„åˆ†**æ—¶éå¸¸æœ‰ç”¨ï¼Œæ­£å¦‚æˆ‘ä»¬åœ¨ä¸‹ä¸€èŠ‚ä¸­æ‰€çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬å°†è®¨è®ºæ·±åº¦é›†æˆçš„æ¦‚å¿µã€‚æˆ‘ä»¬ç°åœ¨ä¸å†ä¸ºæ¯ä¸ªè¾“å…¥é¢„æµ‹ä¸€ä¸ªç‚¹ä¼°è®¡ï¼ˆä¸€ä¸ªå•ä¸€å€¼ï¼‰ï¼Œè€Œæ˜¯è®©ç½‘ç»œç”Ÿæˆä¸€ç»„å€¼çš„åˆ†å¸ƒï¼ˆç”±å¤šä¸ªå‰å‘ä¼ é€’ç»„æˆï¼‰ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªåˆ†å¸ƒæ¥è®¡ç®—æ¯ä¸ªè¾“å…¥æ•°æ®ç‚¹çš„å‡å€¼å’Œæ–¹å·®ï¼Œå¦‚*å›¾*
    [*6.1*](#x1-85011r1)æ‰€ç¤ºã€‚
- en: '![PIC](img/file140.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file140.png)'
- en: 'FigureÂ 6.1: Example of MC dropout'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾ 6.1ï¼šMC dropout ç¤ºä¾‹
- en: 'We can also interpret MC dropout in a Bayesian way. Using these slightly different
    networks with dropout can be seen as sampling from a distribution of all possible
    models: the posterior distribution over all of the parameters (or weights) of
    our network:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨è´å¶æ–¯çš„æ–¹å¼æ¥è§£é‡ŠMC dropoutã€‚ä½¿ç”¨è¿™äº›ç¨å¾®ä¸åŒçš„ç½‘ç»œè¿›è¡Œdropoutå¯ä»¥çœ‹ä½œæ˜¯ä»æ‰€æœ‰å¯èƒ½æ¨¡å‹çš„åˆ†å¸ƒä¸­è¿›è¡Œé‡‡æ ·ï¼šç½‘ç»œæ‰€æœ‰å‚æ•°ï¼ˆæˆ–æƒé‡ï¼‰ä¸Šçš„åéªŒåˆ†å¸ƒï¼š
- en: '![ğœƒt âˆ¼ P (ğœƒ|D ) ](img/file141.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![ğœƒt âˆ¼ P (ğœƒ|D ) ](img/file141.jpg)'
- en: Here, *ğœƒ*[*t*] is a dropout configuration and âˆ¼ a single sample from our posterior
    distribution *P*(*ğœƒ*|*D*). This way, MC dropout is equivalent to a form of approximate
    Bayesian inference, similar to the methods we saw in [*ChapterÂ 5*](CH5.xhtml#x1-600005),
    [*Principled Approaches for Bayesian Deep Learning*](CH5.xhtml#x1-600005).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œ*ğœƒ*[*t*]æ˜¯ä¸€ä¸ªdropouté…ç½®ï¼Œâˆ¼è¡¨ç¤ºä»æˆ‘ä»¬çš„åéªŒåˆ†å¸ƒ*P*(*ğœƒ*|*D*)ä¸­æŠ½å–çš„å•ä¸ªæ ·æœ¬ã€‚è¿™æ ·ï¼ŒMC dropoutå°±ç›¸å½“äºä¸€ç§è¿‘ä¼¼è´å¶æ–¯æ¨æ–­çš„æ–¹æ³•ï¼Œç±»ä¼¼äºæˆ‘ä»¬åœ¨[*ç¬¬5ç« *](CH5.xhtml#x1-600005)ä¸­çœ‹åˆ°çš„æ–¹æ³•ï¼Œ[*è´å¶æ–¯æ·±åº¦å­¦ä¹ çš„åŸåˆ™æ€§æ–¹æ³•*](CH5.xhtml#x1-600005)ã€‚
- en: Now that we have an idea of how MC dropout works, letâ€™s implement it in TensorFlow.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»å¯¹MC dropoutçš„å·¥ä½œåŸç†æœ‰æ‰€äº†è§£ï¼Œè®©æˆ‘ä»¬åœ¨TensorFlowä¸­å®ç°å®ƒã€‚
- en: 6.2.2 Implementing MC dropout
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.2 å®ç°MC dropout
- en: 'Letâ€™s assume we have trained a model with the convolutional architecture described
    in this chapterâ€™s first hands-on exercise. We can now use dropout at inference
    by setting `training=True`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾æˆ‘ä»¬å·²ç»è®­ç»ƒäº†æœ¬ç« ç¬¬ä¸€ä¸ªå®è·µç»ƒä¹ ä¸­æè¿°çš„å·ç§¯æ¶æ„çš„æ¨¡å‹ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å°†`training=True`æ¥åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä½¿ç”¨dropoutï¼š
- en: '[PRE1]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This allows us to get our mean and variance for every prediction of our model.
    Each row of our `Predictions` variable contains the predictions associated with
    each input, obtained from consecutive forward passes. From these predictions,
    we can compute the means and variances, as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿å¾—æˆ‘ä»¬èƒ½å¤Ÿä¸ºæ¨¡å‹çš„æ¯æ¬¡é¢„æµ‹è®¡ç®—å‡å€¼å’Œæ–¹å·®ã€‚æˆ‘ä»¬çš„`Predictions`å˜é‡çš„æ¯ä¸€è¡Œéƒ½åŒ…å«ä¸æ¯ä¸ªè¾“å…¥ç›¸å…³çš„é¢„æµ‹ç»“æœï¼Œè¿™äº›é¢„æµ‹æ˜¯é€šè¿‡è¿ç»­çš„å‰å‘ä¼ é€’è·å¾—çš„ã€‚ä»è¿™äº›é¢„æµ‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡å€¼å’Œæ–¹å·®ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As with all neural networks, Bayesian neural networks require some degree of
    fine-tuning via hyperparameters. The following three hyperparameters are particularly
    important for MC dropout:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸æ‰€æœ‰ç¥ç»ç½‘ç»œä¸€æ ·ï¼Œè´å¶æ–¯ç¥ç»ç½‘ç»œéœ€è¦é€šè¿‡è¶…å‚æ•°è¿›è¡Œä¸€å®šç¨‹åº¦çš„å¾®è°ƒã€‚ä»¥ä¸‹ä¸‰ä¸ªè¶…å‚æ•°å¯¹äºMC dropoutå°¤ä¸ºé‡è¦ï¼š
- en: '**Number of dropout layers**: How many layers (in our `Sequential` object)
    will use dropout, and which layers these will be.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Dropoutå±‚æ•°**ï¼šåœ¨æˆ‘ä»¬çš„`Sequential`å¯¹è±¡ä¸­ï¼Œä½¿ç”¨dropoutçš„å±‚æ•°æ˜¯å¤šå°‘ï¼Œå…·ä½“æ˜¯å“ªäº›å±‚ã€‚'
- en: '**Dropout rate**: The likelihood that nodes will be dropped.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Dropoutç‡**ï¼šèŠ‚ç‚¹è¢«ä¸¢å¼ƒçš„æ¦‚ç‡ã€‚'
- en: '**The number of MC dropout samples**: A new hyperparameter specific to MC dropout.
    Shown here as `nb_inference` , this defines the number of times to sample from
    the MC dropout network at inference time.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MC dropoutæ ·æœ¬æ•°é‡**ï¼šè¿™æ˜¯MC dropoutç‰¹æœ‰çš„ä¸€ä¸ªæ–°è¶…å‚æ•°ã€‚è¿™é‡Œè¡¨ç¤ºä¸º`nb_inference`ï¼Œå®ƒå®šä¹‰äº†åœ¨æ¨ç†æ—¶ä»MC dropoutç½‘ç»œä¸­é‡‡æ ·çš„æ¬¡æ•°ã€‚'
- en: Weâ€™ve now seen how MC dropout can be used in a new way, giving us an easy and
    intuitive method to compute Bayesian uncertainties using familiar tools. But this
    isnâ€™t the only method we have available to us. In the next section, weâ€™ll see
    how ensembling can be applied to neural networks; providing another straightforward
    approach for approximating BNNs.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç°åœ¨å·²ç»çœ‹åˆ°MC dropoutå¯ä»¥ä»¥ä¸€ç§æ–°çš„æ–¹å¼ä½¿ç”¨ï¼Œæä¾›äº†ä¸€ç§ç®€å•ç›´è§‚çš„æ–¹æ³•æ¥åˆ©ç”¨ç†Ÿæ‚‰çš„å·¥å…·è®¡ç®—è´å¶æ–¯ä¸ç¡®å®šæ€§ã€‚ä½†è¿™å¹¶ä¸æ˜¯æˆ‘ä»¬å”¯ä¸€å¯ä»¥ä½¿ç”¨çš„æ–¹æ³•ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†çœ‹åˆ°å¦‚ä½•å°†é›†æˆæ–¹æ³•åº”ç”¨äºç¥ç»ç½‘ç»œï¼›è¿™ä¸ºæˆ‘ä»¬æä¾›äº†å¦ä¸€ç§é€¼è¿‘BNNçš„ç›´æ¥æ–¹æ³•ã€‚
- en: 6.3 Using ensembles for model uncertainty estimates
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.3 ä½¿ç”¨é›†æˆæ–¹æ³•è¿›è¡Œæ¨¡å‹ä¸ç¡®å®šæ€§ä¼°è®¡
- en: 'This section will introduce you to deep ensembles: a popular method for obtaining
    Bayesian uncertainty estimates using an ensemble of deep networks.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬èŠ‚å°†ä»‹ç»æ·±åº¦é›†æˆæ–¹æ³•ï¼šè¿™æ˜¯ä¸€ç§é€šè¿‡æ·±åº¦ç½‘ç»œé›†æˆæ¥è·å¾—è´å¶æ–¯ä¸ç¡®å®šæ€§ä¼°è®¡çš„æµè¡Œæ–¹æ³•ã€‚
- en: 6.3.1 Introducing ensembling methods
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.1 ä»‹ç»é›†æˆæ–¹æ³•
- en: 'A common strategy in machine learning is to combine several single models into
    a committee of models. The process of learning such a combination of models is
    called **ensemble learning**, and the resulting committee of models is called
    an ensemble. Ensemble learning involves two main components: first, the different
    single models need to be trained. There are various strategies to obtain different
    models from the same training data: the models can be trained on different subsets
    of data, we can train different model types or models with different architectures,
    or we can initialize the same model types with different hyperparameters. Second,
    the outputs of the different single models need to be combined. Common strategies
    for combining the predictions of single models are simply taking their average
    or taking a majority vote among all members of the ensemble. More advanced strategies
    are taking a weighted average or, if more training data is available, learning
    an additional model to combine the different predictions of the ensemble members.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: æœºå™¨å­¦ä¹ ä¸­ä¸€ä¸ªå¸¸è§çš„ç­–ç•¥æ˜¯å°†å¤šä¸ªå•ä¸€æ¨¡å‹ç»„åˆæˆä¸€ä¸ªæ¨¡å‹å§”å‘˜ä¼šã€‚å­¦ä¹ è¿™ç§æ¨¡å‹ç»„åˆçš„è¿‡ç¨‹ç§°ä¸º**é›†æˆå­¦ä¹ **ï¼Œè€Œå¾—åˆ°çš„æ¨¡å‹å§”å‘˜ä¼šåˆ™ç§°ä¸ºé›†æˆæ¨¡å‹ã€‚é›†æˆå­¦ä¹ åŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼šé¦–å…ˆï¼Œå¤šä¸ªå•ä¸€æ¨¡å‹éœ€è¦è¢«è®­ç»ƒã€‚æœ‰å¤šç§ç­–ç•¥å¯ä»¥ä»ç›¸åŒçš„è®­ç»ƒæ•°æ®ä¸­è·å¾—ä¸åŒçš„æ¨¡å‹ï¼šå¯ä»¥åœ¨ä¸åŒçš„æ•°æ®å­é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼Œæˆ–è€…è®­ç»ƒä¸åŒç±»å‹çš„æ¨¡å‹æˆ–å…·æœ‰ä¸åŒæ¶æ„çš„æ¨¡å‹ï¼Œäº¦æˆ–æ˜¯ä½¿ç”¨ä¸åŒè¶…å‚æ•°åˆå§‹åŒ–ç›¸åŒç±»å‹çš„æ¨¡å‹ã€‚å…¶æ¬¡ï¼Œéœ€è¦å°†ä¸åŒå•ä¸€æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œç»„åˆã€‚å¸¸è§çš„ç»„åˆå•ä¸€æ¨¡å‹é¢„æµ‹çš„ç­–ç•¥æ˜¯ç›´æ¥å–å…¶å¹³å‡å€¼ï¼Œæˆ–è€…å¯¹é›†æˆæ¨¡å‹ä¸­çš„æ‰€æœ‰æˆå‘˜è¿›è¡Œå¤šæ•°æŠ•ç¥¨ã€‚æ›´é«˜çº§çš„ç­–ç•¥åŒ…æ‹¬å–åŠ æƒå¹³å‡å€¼ï¼Œæˆ–è€…å¦‚æœæœ‰æ›´å¤šçš„è®­ç»ƒæ•°æ®ï¼Œåˆ™å¯ä»¥å­¦ä¹ ä¸€ä¸ªé¢å¤–çš„æ¨¡å‹æ¥ç»“åˆé›†æˆæˆå‘˜çš„ä¸åŒé¢„æµ‹ç»“æœã€‚
- en: Ensembles are very popular in machine learning because they tend to improve
    predictive performance by minimizing the risk of accidentally picking a model
    with poor performance. In fact, ensembles are guaranteed to perform at least as
    well as any single model. Furthermore, ensembles will perform better than single
    models if there is enough diversity among the predictions of ensemble members.
    Diversity here means that different ensemble members make different mistakes on
    a given data sample. If, for example, some ensemble members misclassify the image
    of a dog as â€œcat,â€ but the majority of ensemble members make the correct prediction
    (â€œdogâ€), then the combined ensemble output will still be correct (â€œdogâ€). More
    generally, as long as every single model has an accuracy greater than 50% and
    the models make independent mistakes, then the predictive performance of the ensemble
    will approach 100% accuracy as we add more and more ensemble members.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: é›†æˆæ–¹æ³•åœ¨æœºå™¨å­¦ä¹ ä¸­éå¸¸æµè¡Œï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸é€šè¿‡æœ€å°åŒ–æ„å¤–é€‰æ‹©æ€§èƒ½è¾ƒå·®æ¨¡å‹çš„é£é™©æ¥æé«˜é¢„æµ‹æ€§èƒ½ã€‚äº‹å®ä¸Šï¼Œé›†æˆæ¨¡å‹è‡³å°‘èƒ½å¤Ÿä¸ä»»ä½•å•ä¸€æ¨¡å‹ä¸€æ ·å¥½åœ°æ‰§è¡Œã€‚æ›´é‡è¦çš„æ˜¯ï¼Œå¦‚æœé›†æˆæˆå‘˜çš„é¢„æµ‹å­˜åœ¨è¶³å¤Ÿçš„å¤šæ ·æ€§ï¼Œé›†æˆæ–¹æ³•çš„è¡¨ç°å°†ä¼˜äºå•ä¸€æ¨¡å‹ã€‚è¿™é‡Œçš„å¤šæ ·æ€§æ„å‘³ç€ä¸åŒçš„é›†æˆæˆå‘˜åœ¨ç»™å®šçš„æ•°æ®æ ·æœ¬ä¸Šä¼šçŠ¯ä¸åŒçš„é”™è¯¯ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸€äº›é›†æˆæˆå‘˜å°†ä¸€åªç‹—çš„å›¾åƒè¯¯åˆ†ç±»ä¸ºâ€œçŒ«â€ï¼Œä½†å¤§å¤šæ•°é›†æˆæˆå‘˜åšå‡ºäº†æ­£ç¡®çš„é¢„æµ‹ï¼ˆâ€œç‹—â€ï¼‰ï¼Œé‚£ä¹ˆé›†æˆæ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºä»ç„¶æ˜¯æ­£ç¡®çš„ï¼ˆâ€œç‹—â€ï¼‰ã€‚æ›´ä¸€èˆ¬æ¥è¯´ï¼Œåªè¦æ¯ä¸ªå•ä¸€æ¨¡å‹çš„å‡†ç¡®ç‡è¶…è¿‡50%ï¼Œå¹¶ä¸”æ¨¡å‹çš„é”™è¯¯æ˜¯ç‹¬ç«‹çš„ï¼Œé‚£ä¹ˆéšç€é›†æˆæˆå‘˜æ•°é‡çš„å¢åŠ ï¼Œé›†æˆçš„é¢„æµ‹æ€§èƒ½å°†æ¥è¿‘100%çš„å‡†ç¡®åº¦ã€‚
- en: In addition to improving predictive performance, we can leverage the degree
    of agreement (or disagreement) among ensemble members to obtain an uncertainty
    estimate along with the prediction of the ensemble. In the context of image classification,
    for example, if almost all ensemble members predict that the image shows a dog,
    then we can say that the ensemble predicted â€œdogâ€ with high confidence (or low
    uncertainty). Conversely, if there is significant disagreement among the predictions
    of different ensemble members, then we will observe high uncertainty in the form
    of significant variance across the outputs from the ensemble members, telling
    us that the prediction has low confidence.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: é™¤äº†æé«˜é¢„æµ‹æ€§èƒ½å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åˆ©ç”¨é›†æˆæˆå‘˜ä¹‹é—´çš„ä¸€è‡´æ€§ï¼ˆæˆ–ä¸ä¸€è‡´æ€§ï¼‰æ¥è·å¾—ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œå¹¶ä¸é›†æˆçš„é¢„æµ‹ç»“æœä¸€èµ·ä½¿ç”¨ã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾åƒåˆ†ç±»çš„æƒ…å†µä¸‹ï¼Œå¦‚æœå‡ ä¹æ‰€æœ‰é›†æˆæˆå‘˜éƒ½é¢„æµ‹å›¾åƒæ˜¾ç¤ºçš„æ˜¯ä¸€åªç‹—ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥è¯´é›†æˆæ¨¡å‹ä»¥é«˜ç½®ä¿¡åº¦ï¼ˆæˆ–ä½ä¸ç¡®å®šæ€§ï¼‰é¢„æµ‹ä¸ºâ€œç‹—â€ã€‚ç›¸åï¼Œå¦‚æœä¸åŒé›†æˆæˆå‘˜çš„é¢„æµ‹å­˜åœ¨æ˜¾è‘—çš„ä¸ä¸€è‡´ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°†è§‚å¯Ÿåˆ°é«˜ä¸ç¡®å®šæ€§ï¼Œå³é›†æˆæˆå‘˜è¾“å‡ºä¹‹é—´çš„æ–¹å·®è¾ƒå¤§ï¼Œè¿™è¡¨æ˜é¢„æµ‹çš„ç½®ä¿¡åº¦è¾ƒä½ã€‚
- en: Now that we are equipped with a basic understanding of ensembles, it is worth
    highlighting that MC dropout, which we explored in the previous section, may also
    be seen as an ensemble method. When we enable dropout during inference, we effectively
    run inference with a slightly different (sub-)network every time. The combination
    of these different sub-networks can be considered as a committee of different
    models, and therefore an ensemble. This observation led a team at Google to look
    into alternative ways of creating ensembles from DNNs, which led to the discovery
    of deep ensembles (Lakshminarayan et al, 2016) , which are introduced in the following
    section.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»å…·å¤‡äº†å¯¹é›†æˆæ–¹æ³•çš„åŸºæœ¬ç†è§£ï¼Œå€¼å¾—æŒ‡å‡ºçš„æ˜¯ï¼Œæˆ‘ä»¬åœ¨å‰ä¸€èŠ‚ä¸­æ¢è®¨çš„MC Dropoutä¹Ÿå¯ä»¥çœ‹ä½œä¸€ç§é›†æˆæ–¹æ³•ã€‚å½“æˆ‘ä»¬åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¯ç”¨Dropoutæ—¶ï¼Œæˆ‘ä»¬å®é™…ä¸Šæ¯æ¬¡éƒ½åœ¨è¿è¡Œä¸€ä¸ªç•¥æœ‰ä¸åŒçš„ï¼ˆå­ï¼‰ç½‘ç»œã€‚è¿™äº›ä¸åŒå­ç½‘ç»œçš„ç»„åˆå¯ä»¥çœ‹ä½œæ˜¯å¤šä¸ªæ¨¡å‹çš„å§”å‘˜ä¼šï¼Œå› æ­¤ä¹Ÿæ˜¯ä¸€ç§é›†æˆæ–¹æ³•ã€‚è¿™ä¸€è§‚å¯Ÿä¿ƒä½¿è°·æ­Œå›¢é˜Ÿç ”ç©¶ä»æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰åˆ›å»ºé›†æˆçš„æ›¿ä»£æ–¹æ³•ï¼Œæœ€ç»ˆå‘ç°äº†æ·±åº¦é›†æˆï¼ˆLakshminarayanç­‰ï¼Œ2016ï¼‰ï¼Œè¿™ä¸€æ–¹æ³•å°†åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ä»‹ç»ã€‚
- en: 6.3.2 Introducing deep ensembles
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.2 å¼•å…¥æ·±åº¦é›†æˆ
- en: 'The main idea behind deep ensembles is straightforward: train several different
    DNN models, then combine their predictions via averaging to improve model performance
    and leverage the agreement among the predictions of these models to obtain an
    estimate of predictive uncertainty.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: æ·±åº¦é›†æˆçš„ä¸»è¦æ€æƒ³å¾ˆç®€å•ï¼šè®­ç»ƒå¤šä¸ªä¸åŒçš„æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰æ¨¡å‹ï¼Œç„¶åé€šè¿‡å¹³å‡å®ƒä»¬çš„é¢„æµ‹ç»“æœæ¥æé«˜æ¨¡å‹æ€§èƒ½ï¼Œå¹¶åˆ©ç”¨è¿™äº›æ¨¡å‹é¢„æµ‹ç»“æœçš„ä¸€è‡´æ€§æ¥ä¼°è®¡é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚
- en: More formally, assume that we have some training data **X**, where *X* âˆˆâ„^(*D*),
    and corresponding target labels **y**. For example, in image classification the
    training data would be images, and the target labels would be integers that denote
    which object class is shown in the corresponding image, so *y* âˆˆ{1*,...,K*} where
    *K* is the total number of classes. Training a single neural network means that
    we model the probabilistic predictive distribution *p*[*ğœƒ*](*y*|*x*) over the
    labels and optimize *ğœƒ*, the parameters of the NN. For deep ensembles, we train
    **M** neural networks whose parameters can be described as {*ğœƒ*[*m*]}[*m*=1]^(*M*),
    where each *ğœƒ*[*m*] is optimized independently using **X** and **y** (meaning
    that we train each NN independently on the same data). The predictions of the
    deep ensemble members are combined via averaging, using *p*(*y*|*x*) = *M*^(âˆ’1)
    âˆ‘ [*m*=1]^(*M*)*p*[*ğœƒ*[m]](*y*|*x,ğœƒ*[*m*]).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´æ­£å¼åœ°è¯´ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€äº›è®­ç»ƒæ•°æ®**X**ï¼Œå…¶ä¸­ *X* âˆˆâ„^(*D*)ï¼Œä»¥åŠç›¸åº”çš„ç›®æ ‡æ ‡ç­¾**y**ã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾åƒåˆ†ç±»ä¸­ï¼Œè®­ç»ƒæ•°æ®æ˜¯å›¾åƒï¼Œç›®æ ‡æ ‡ç­¾æ˜¯è¡¨ç¤ºå›¾åƒä¸­æ˜¾ç¤ºçš„æ˜¯å“ªä¸€ç±»ç‰©ä½“çš„æ•´æ•°ï¼Œæ‰€ä»¥
    *y* âˆˆ{1*,...,K*}ï¼Œå…¶ä¸­ *K* æ˜¯ç±»åˆ«çš„æ€»æ•°ã€‚è®­ç»ƒä¸€ä¸ªå•ä¸€çš„ç¥ç»ç½‘ç»œæ„å‘³ç€æˆ‘ä»¬å¯¹æ ‡ç­¾å»ºæ¨¡æ¦‚ç‡é¢„æµ‹åˆ†å¸ƒ *p*[*ğœƒ*](*y*|*x*)ï¼Œå¹¶ä¼˜åŒ–
    *ğœƒ*ï¼Œå³ç¥ç»ç½‘ç»œçš„å‚æ•°ã€‚å¯¹äºæ·±åº¦é›†æˆï¼Œæˆ‘ä»¬è®­ç»ƒ**M**ä¸ªç¥ç»ç½‘ç»œï¼Œå®ƒä»¬çš„å‚æ•°å¯ä»¥è¡¨ç¤ºä¸º{*ğœƒ*[*m*]}[*m*=1]^(*M*)ï¼Œå…¶ä¸­æ¯ä¸ª *ğœƒ*[*m*]
    éƒ½æ˜¯ä½¿ç”¨**X**å’Œ**y**ç‹¬ç«‹ä¼˜åŒ–çš„ï¼ˆè¿™æ„å‘³ç€æˆ‘ä»¬åœ¨ç›¸åŒçš„æ•°æ®ä¸Šç‹¬ç«‹è®­ç»ƒæ¯ä¸ªç¥ç»ç½‘ç»œï¼‰ã€‚æ·±åº¦é›†æˆæˆå‘˜çš„é¢„æµ‹é€šè¿‡å¹³å‡å€¼è¿›è¡Œç»“åˆï¼Œä½¿ç”¨ *p*(*y*|*x*)
    = *M*^(âˆ’1) âˆ‘ [*m*=1]^(*M*)*p*[*ğœƒ*[m]](*y*|*x,ğœƒ*[*m*])ã€‚
- en: '*Figure* [*6.2*](#x1-89003r2) illustrates the idea behind deep ensembles. Here,
    we have trained *M* = 3 different feed-forward NNs. Notice that each network has
    its own unique set of network weights, as illustrated by the varying thickness
    of the edges connecting the network notes. Each of the three networks will output
    its own prediction score, as illustrated by the green nodes, and we combine these
    scores via averaging.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾* [*6.2*](#x1-89003r2) è¯´æ˜äº†æ·±åº¦é›†æˆçš„æ€æƒ³ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è®­ç»ƒäº† *M* = 3 ä¸ªä¸åŒçš„å‰é¦ˆç¥ç»ç½‘ç»œã€‚è¯·æ³¨æ„ï¼Œæ¯ä¸ªç½‘ç»œéƒ½æœ‰è‡ªå·±ç‹¬ç‰¹çš„ç½‘ç»œæƒé‡é›†ï¼Œæ­£å¦‚é€šè¿‡è¿æ¥ç½‘ç»œèŠ‚ç‚¹çš„è¾¹ç¼˜åšåº¦ä¸åŒæ‰€ç¤ºã€‚ä¸‰ä¸ªç½‘ç»œä¸­çš„æ¯ä¸€ä¸ªéƒ½ä¼šè¾“å‡ºè‡ªå·±çš„é¢„æµ‹åˆ†æ•°ï¼Œå¦‚ç»¿è‰²èŠ‚ç‚¹æ‰€ç¤ºï¼Œæˆ‘ä»¬é€šè¿‡å¹³å‡è¿™äº›åˆ†æ•°æ¥è¿›è¡Œç»“åˆã€‚'
- en: '![PIC](img/file142.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file142.png)'
- en: 'FigureÂ 6.2: Example of a deep ensemble. Note that the three networks differ
    in their weights, as illustrated by edges with different thicknesses'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾6.2ï¼šæ·±åº¦é›†æˆç¤ºä¾‹ã€‚è¯·æ³¨æ„ï¼Œä¸‰ä¸ªç½‘ç»œåœ¨æƒé‡ä¸Šæœ‰æ‰€ä¸åŒï¼Œæ­£å¦‚é€šè¿‡ä¸åŒåšåº¦çš„è¾¹ç¼˜æ‰€ç¤ºã€‚
- en: 'How can we train several different neural network models if only one dataset
    is available for training? The strategy proposed in the original paper (and still
    the most commonly used strategy) is to start every training with a random initialization
    of the networkâ€™s weights. If every training starts with a different set of weights,
    the different training runs are likely to produce networks with different function
    approximations of the training data. This is because NNs tend to have many more
    weight parameters than there are samples in the training dataset. Therefore, the
    same observations in the training dataset can be approximated by many different
    weight parameter combinations. During training, the different NN models will each
    converge to their own parameter combination and will occupy different local optima
    on the loss landscape. Because of this, the different NNs will also often have
    differing perspectives on a given data sample, for example, the image of a dog.
    This also means that the different NNs will make different mistakes, for example,
    when classifying the data sample. The degree of consensus between the different
    networks in an ensemble provides information about how certain an ensemble is
    in its predictions for a given data point: the more the networks agree, the more
    confident we can be in the prediction.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœåªæœ‰ä¸€ä¸ªæ•°æ®é›†å¯ä¾›è®­ç»ƒï¼Œæˆ‘ä»¬å¦‚ä½•è®­ç»ƒå¤šä¸ªä¸åŒçš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ŸåŸå§‹è®ºæ–‡æå‡ºçš„ç­–ç•¥ï¼ˆä¹Ÿæ˜¯ç›®å‰æœ€å¸¸ç”¨çš„ç­–ç•¥ï¼‰æ˜¯æ¯æ¬¡è®­ç»ƒéƒ½ä»ç½‘ç»œæƒé‡çš„éšæœºåˆå§‹åŒ–å¼€å§‹ã€‚å¦‚æœæ¯æ¬¡è®­ç»ƒéƒ½ä»ä¸åŒçš„æƒé‡é›†åˆå¼€å§‹ï¼Œé‚£ä¹ˆä¸åŒçš„è®­ç»ƒè¿è¡Œå¯èƒ½ä¼šäº§ç”Ÿä¸åŒçš„ç½‘ç»œï¼Œå…¶è®­ç»ƒæ•°æ®çš„å‡½æ•°é€¼è¿‘æ–¹å¼ä¹Ÿä¼šæœ‰æ‰€ä¸åŒã€‚è¿™æ˜¯å› ä¸ºç¥ç»ç½‘ç»œå¾€å¾€æ‹¥æœ‰æ¯”è®­ç»ƒæ•°æ®é›†ä¸­çš„æ ·æœ¬æ•°é‡æ›´å¤šçš„æƒé‡å‚æ•°ã€‚å› æ­¤ï¼Œè®­ç»ƒæ•°æ®é›†ä¸­çš„ç›¸åŒè§‚æµ‹å€¼å¯ä»¥é€šè¿‡è®¸å¤šä¸åŒçš„æƒé‡å‚æ•°ç»„åˆæ¥é€¼è¿‘ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸åŒçš„ç¥ç»ç½‘ç»œæ¨¡å‹å°†å„è‡ªæ”¶æ•›åˆ°è‡ªå·±çš„å‚æ•°ç»„åˆï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°çš„å±€éƒ¨æœ€ä¼˜ç‚¹ä¸Šå æ®ä¸åŒä½ç½®ã€‚å› æ­¤ï¼Œä¸åŒçš„ç¥ç»ç½‘ç»œé€šå¸¸ä¼šå¯¹ç»™å®šçš„æ•°æ®æ ·æœ¬ï¼ˆä¾‹å¦‚ï¼Œä¸€åªç‹—çš„å›¾åƒï¼‰æœ‰ä¸åŒçš„çœ‹æ³•ã€‚è¿™ä¹Ÿæ„å‘³ç€ä¸åŒçš„ç¥ç»ç½‘ç»œåœ¨åˆ†ç±»æ•°æ®æ ·æœ¬æ—¶å¯èƒ½ä¼šçŠ¯ä¸åŒçš„é”™è¯¯ã€‚é›†æˆä¸­ä¸åŒç½‘ç»œä¹‹é—´çš„å…±è¯†ç¨‹åº¦æä¾›äº†å…³äºé›†æˆæ¨¡å‹å¯¹æŸä¸€æ•°æ®ç‚¹é¢„æµ‹çš„ç½®ä¿¡åº¦ä¿¡æ¯ï¼šç½‘ç»œè¶Šä¸€è‡´ï¼Œæˆ‘ä»¬å¯¹é¢„æµ‹çš„ä¿¡å¿ƒå°±è¶Šå¼ºã€‚
- en: 'Alternative ways to train different NN models with the same training data set
    are: to use a random ordering of mini-batches during training, to use different
    hyperparameters for every training run, or to use different network architecture
    for every model altogether. These strategies can also be combined, and understanding
    exactly which combination of strategies leads to the best outcomes, in terms predictive
    performance and predictive uncertainty, is an active field of research.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨ç›¸åŒè®­ç»ƒæ•°æ®é›†è®­ç»ƒä¸åŒç¥ç»ç½‘ç»œæ¨¡å‹çš„æ›¿ä»£æ–¹æ³•åŒ…æ‹¬ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨è¿·ä½ æ‰¹æ¬¡çš„éšæœºæ’åºã€ä¸ºæ¯æ¬¡è®­ç»ƒè¿è¡Œä½¿ç”¨ä¸åŒçš„è¶…å‚æ•°ï¼Œæˆ–ä¸ºæ¯ä¸ªæ¨¡å‹ä½¿ç”¨ä¸åŒçš„ç½‘ç»œæ¶æ„ã€‚è¿™äº›ç­–ç•¥ä¹Ÿå¯ä»¥ç»“åˆä½¿ç”¨ï¼Œç²¾ç¡®ç†è§£å“ªäº›ç­–ç•¥ç»„åˆèƒ½å¸¦æ¥æœ€ä½³ç»“æœï¼ˆæ— è®ºæ˜¯é¢„æµ‹æ€§èƒ½è¿˜æ˜¯é¢„æµ‹ä¸ç¡®å®šæ€§ï¼‰ä»ç„¶æ˜¯ä¸€ä¸ªæ´»è·ƒçš„ç ”ç©¶é¢†åŸŸã€‚
- en: 6.3.3 Implementing a deep ensemble
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.3 å®ç°æ·±åº¦é›†æˆ
- en: The following code example illustrates how to train a deep ensemble using the
    strategy of random weight initialization to obtain differing ensemble members.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: ä»¥ä¸‹ä»£ç ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨éšæœºæƒé‡åˆå§‹åŒ–ç­–ç•¥è®­ç»ƒæ·±åº¦é›†æˆæ¨¡å‹ï¼Œä»¥è·å¾—ä¸åŒçš„é›†æˆæˆå‘˜ã€‚
- en: 'Step 1: Importing libraries'
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 1ï¼šå¯¼å…¥åº“
- en: 'We start by importing the relevant packages and setting the number of ensembles
    to `3` for this code example:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬é¦–å…ˆå¯¼å…¥ç›¸å…³çš„åŒ…ï¼Œå¹¶å°†é›†æˆæ•°é‡è®¾ç½®ä¸º`3`ï¼Œç”¨äºæœ¬ä»£ç ç¤ºä¾‹ï¼š
- en: '[PRE3]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Step 2: Obtaining data'
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 2ï¼šè·å–æ•°æ®
- en: 'We then download the `MNIST``Â Fashion` dataset, which is a dataset that contains
    images of ten different clothing items:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬ä¸‹è½½`MNIST``Â Fashion`æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«åç§ä¸åŒæœè£…é¡¹ç›®å›¾åƒçš„æ•°æ®é›†ï¼š
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Step 3: Constructing our ensemble model'
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 3ï¼šæ„å»ºé›†æˆæ¨¡å‹
- en: 'Next, we create a helper function that defines our model. As you can see, we
    use a simple image classifier structure that consists of two convolutional layers,
    each followed by a max-pooling operation, and several fully connected layers:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥å®šä¹‰æˆ‘ä»¬çš„æ¨¡å‹ã€‚å¦‚ä½ æ‰€è§ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„å›¾åƒåˆ†ç±»å™¨ç»“æ„ï¼ŒåŒ…å«ä¸¤ä¸ªå·ç§¯å±‚ï¼Œæ¯ä¸ªå·ç§¯å±‚åè·Ÿä¸€ä¸ªæœ€å¤§æ± åŒ–æ“ä½œï¼Œä»¥åŠè‹¥å¹²å…¨è¿æ¥å±‚ï¼š
- en: '[PRE5]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We also create another helper function that compiles the model for us, using
    `Adam` as our optimizer and a categorical cross-entropy loss:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜åˆ›å»ºäº†å¦ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œä½¿ç”¨`Adam`ä½œä¸ºä¼˜åŒ–å™¨ï¼Œå¹¶é‡‡ç”¨ç±»åˆ«äº¤å‰ç†µæŸå¤±æ¥ç¼–è¯‘æ¨¡å‹ï¼š
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Step 4: Training'
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 4ï¼šè®­ç»ƒ
- en: 'We then train three different networks on the same dataset. Since the network
    weights are initialized at random, this will result in three different models.
    You will see that the training accuracy varies slightly between models:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬åœ¨ç›¸åŒçš„æ•°æ®é›†ä¸Šè®­ç»ƒä¸‰ä¸ªä¸åŒçš„ç½‘ç»œã€‚ç”±äºç½‘ç»œæƒé‡æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œè¿™å°†å¯¼è‡´ä¸‰ä¸ªä¸åŒçš„æ¨¡å‹ã€‚ä½ ä¼šçœ‹åˆ°ä¸åŒæ¨¡å‹çš„è®­ç»ƒå‡†ç¡®åº¦ç•¥æœ‰å·®å¼‚ï¼š
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Step 5: Inference'
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 5ï¼šæ¨ç†
- en: 'We can then perform inference and obtain the Predictions for each of the models
    for all images in the test split. We can also take the mean across the predictions
    of the three models, which will give us one prediction vector per image:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥æ‰§è¡Œæ¨ç†å¹¶è·å¾—æµ‹è¯•é›†ä¸­çš„æ¯ä¸ªæ¨¡å‹å¯¹æ‰€æœ‰å›¾åƒçš„é¢„æµ‹ç»“æœã€‚æˆ‘ä»¬è¿˜å¯ä»¥å¯¹ä¸‰ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœå–å¹³å‡å€¼ï¼Œè¿™æ ·æ¯ä¸ªå›¾åƒå°±ä¼šæœ‰ä¸€ä¸ªé¢„æµ‹å‘é‡ï¼š
- en: '[PRE8]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Thatâ€™s it. We have trained an ensemble of networks and performed inference.
    Given that we have several predictions per image now, we can also look at images
    where the three models disagree.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ã€‚æˆ‘ä»¬å·²ç»è®­ç»ƒäº†ä¸€ä¸ªç½‘ç»œé›†æˆå¹¶è¿›è¡Œäº†æ¨ç†ã€‚ç”±äºç°åœ¨æ¯ä¸ªå›¾åƒéƒ½æœ‰å¤šä¸ªé¢„æµ‹ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥æŸ¥çœ‹ä¸‰ä¸ªæ¨¡å‹é¢„æµ‹ç»“æœä¸ä¸€è‡´çš„å›¾åƒã€‚
- en: 'Letâ€™s, for example, find the image with the highest disagreement and visualize
    it:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯”å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æ‰¾åˆ°é¢„æµ‹ç»“æœä¸ä¸€è‡´æœ€å¤šçš„å›¾åƒå¹¶å°†å…¶å¯è§†åŒ–ï¼š
- en: '[PRE9]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Looking at the image in *Figure* [*6.3*](#x1-95107r3), even for a human it
    is hard to tell whether there is a t-shirt, shirt, or bag in the image:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: çœ‹çœ‹*å›¾* [*6.3*](#x1-95107r3)ä¸­çš„å›¾åƒï¼Œç”šè‡³å¯¹äºäººç±»æ¥è¯´ï¼Œä¹Ÿå¾ˆéš¾åˆ¤æ–­å›¾åƒä¸­æ˜¯Tæ¤ã€è¡¬è¡«è¿˜æ˜¯åŒ…ï¼š
- en: '![PIC](img/file143.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![PIC](img/file143.png)'
- en: 'FigureÂ 6.3: Image with highest variance among ensemble predictions. The correct
    ground truth label is â€t-shirt,â€ but it is hard to tell, even for a human'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: å›¾6.3ï¼šé›†æˆé¢„æµ‹ä¸­æ–¹å·®æœ€å¤§çš„å›¾åƒã€‚æ­£ç¡®çš„çœŸå®æ ‡ç­¾æ˜¯"t-shirt"ï¼Œä½†å³ä½¿æ˜¯äººç±»ä¹Ÿå¾ˆéš¾åˆ¤æ–­ã€‚
- en: While weâ€™ve seen that deep ensembles have several favorable qualities, they
    are not without limitations. In the next section, weâ€™ll explore what kinds of
    things we may wish to bear in mind when considering deep ensembles.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æˆ‘ä»¬å·²ç»çœ‹åˆ°æ·±åº¦é›†æˆæœ‰å‡ ä¸ªæœ‰åˆ©çš„ç‰¹æ€§ï¼Œä½†å®ƒä»¬ä¹Ÿä¸æ˜¯æ²¡æœ‰å±€é™æ€§ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨åœ¨è€ƒè™‘æ·±åº¦é›†æˆæ—¶å¯èƒ½éœ€è¦æ³¨æ„çš„äº‹é¡¹ã€‚
- en: 6.3.4 Practical limitations of deep ensembles
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3.4 æ·±åº¦é›†æˆçš„å®é™…å±€é™æ€§
- en: Some practical limitations of ensembles become obvious when taking them from
    the research environment to production at scale. We know that, in theory, the
    predictive performance and the uncertainty estimate of an ensemble is expected
    to improve as we add more ensemble members. However, there is a cost of adding
    more ensemble members as the memory footprint and inference cost of ensembles
    increases linearly with the number of ensemble members. This can make deploying
    ensembles in a production setting a costly choice. For every NN that we add to
    the ensemble, we will need to store an extra set of network weights, which significantly
    increases memory requirements. Equally, for every network, we will also need to
    run an additional forward pass during inference. Even though the inferences of
    different networks can be run in parallel, and the impact on inference time can
    therefore be mitigated, such an approach will still require more compute resources
    than single models. As more compute resources tend to translate to higher costs,
    the decision of using an ensemble versus a single model will need to trade off
    the benefits of better performance and uncertainty estimation with the increase
    in cost.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ä»ç ”ç©¶ç¯å¢ƒåˆ°å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒä¸­åº”ç”¨é›†æˆæ¨¡å‹æ—¶ï¼Œä¸€äº›å®é™…å±€é™æ€§å˜å¾—æ˜¾è€Œæ˜“è§ã€‚æˆ‘ä»¬çŸ¥é“ï¼Œç†è®ºä¸Šï¼Œéšç€æˆ‘ä»¬å¢åŠ æ›´å¤šçš„é›†æˆæˆå‘˜ï¼Œé›†æˆæ¨¡å‹çš„é¢„æµ‹æ€§èƒ½å’Œä¸ç¡®å®šæ€§ä¼°è®¡ä¼šæœ‰æ‰€æå‡ã€‚ç„¶è€Œï¼Œå¢åŠ æ›´å¤šé›†æˆæˆå‘˜æ˜¯æœ‰ä»£ä»·çš„ï¼Œå› ä¸ºé›†æˆæ¨¡å‹çš„å†…å­˜å ç”¨å’Œæ¨ç†æˆæœ¬ä¼šéšç€é›†æˆæˆå‘˜æ•°é‡çš„å¢åŠ è€Œçº¿æ€§å¢é•¿ã€‚è¿™å¯èƒ½ä½¿å¾—åœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²é›†æˆæ¨¡å‹æˆä¸ºä¸€ä¸ªé«˜æˆæœ¬çš„é€‰æ‹©ã€‚å¯¹äºæˆ‘ä»¬æ·»åŠ åˆ°é›†æˆä¸­çš„æ¯ä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬éƒ½éœ€è¦å­˜å‚¨ä¸€ç»„é¢å¤–çš„ç½‘ç»œæƒé‡ï¼Œè¿™ä¼šæ˜¾è‘—å¢åŠ å†…å­˜éœ€æ±‚ã€‚åŒæ ·ï¼Œå¯¹äºæ¯ä¸ªç½‘ç»œï¼Œæˆ‘ä»¬è¿˜éœ€è¦åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿›è¡Œé¢å¤–çš„å‰å‘ä¼ é€’ã€‚å°½ç®¡ä¸åŒç½‘ç»œçš„æ¨ç†å¯ä»¥å¹¶è¡Œè¿›è¡Œï¼Œå› æ­¤æ¨ç†æ—¶é—´çš„å½±å“å¯ä»¥å¾—åˆ°ç¼“è§£ï¼Œä½†è¿™ç§æ–¹æ³•ä»ç„¶éœ€è¦æ¯”å•ä¸€æ¨¡å‹æ›´å¤šçš„è®¡ç®—èµ„æºã€‚ç”±äºæ›´å¤šçš„è®¡ç®—èµ„æºå¾€å¾€æ„å‘³ç€æ›´é«˜çš„æˆæœ¬ï¼Œä½¿ç”¨é›†æˆæ¨¡å‹ä¸å•ä¸€æ¨¡å‹ä¹‹é—´çš„å†³ç­–éœ€è¦åœ¨æ›´å¥½çš„æ€§èƒ½å’Œä¸ç¡®å®šæ€§ä¼°è®¡çš„å¥½å¤„ä¸æˆæœ¬å¢åŠ ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚
- en: 'Recent research has tried to address or mitigate these practical limitations.
    In an approach called BatchEnsembles ([**?**]), for example, all ensemble members
    share one underlying weight matrix. The final weight matrix for each ensemble
    member is obtained by element-wise multiplication of this shared weight matrix
    with a rank-one matrix that is unique to each ensemble member. This reduces the
    number of parameters that need to be stored for each additional ensemble member
    and thus reduces memory footprint. The ensembleâ€™s computational cost is also reduced
    because the BatchEnsembles can exploit vectorization, and the output for all ensemble
    members can be computed in a single forward pass. In a different approach, called
    **multi-input/multi-output** **processing** (**MIMO**; [**?**]), a single network
    is encouraged to learn several independent sub-networks. During training, multiple
    inputs are passed along with multiple, correspondingly labeled outputs. The network
    will, for example, be presented with three images: of a dog, a cat and a chicken.
    Corresponding output labels are passed and the network will need to learn to predict
    â€dogâ€ on its first output node, â€catâ€ on its second output node, and â€chickenâ€
    on its third. During inference, one single image will be repeated three times
    and the MIMO ensemble will produce three different predictions (one on each output
    node). As a result, the memory footprint and computational cost of the MIMO approach
    is almost as little as that of a single neural network, while still providing
    all the benefits of an ensemble.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€è¿‘çš„ç ”ç©¶å°è¯•è§£å†³æˆ–å‡è½»è¿™äº›å®é™…é™åˆ¶ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€ç§å«åšBatchEnsemblesï¼ˆ[**?**]ï¼‰çš„æ–¹æ³•ä¸­ï¼Œæ‰€æœ‰é›†æˆæˆå‘˜å…±äº«ä¸€ä¸ªåŸºç¡€æƒé‡çŸ©é˜µã€‚æ¯ä¸ªé›†æˆæˆå‘˜çš„æœ€ç»ˆæƒé‡çŸ©é˜µæ˜¯é€šè¿‡å°†è¯¥å…±äº«æƒé‡çŸ©é˜µä¸ä¸€ä¸ªå”¯ä¸€çš„ç§©ä¸€çŸ©é˜µæŒ‰å…ƒç´ ç›¸ä¹˜å¾—åˆ°çš„ï¼Œè¿™ä¸ªç§©ä¸€çŸ©é˜µå¯¹æ¯ä¸ªé›†æˆæˆå‘˜éƒ½æ˜¯å”¯ä¸€çš„ã€‚è¿™å‡å°‘äº†æ¯å¢åŠ ä¸€ä¸ªé›†æˆæˆå‘˜éœ€è¦å­˜å‚¨çš„å‚æ•°æ•°é‡ï¼Œä»è€Œå‡å°äº†å†…å­˜å ç”¨ã€‚BatchEnsemblesçš„è®¡ç®—æˆæœ¬ä¹Ÿå¾—åˆ°äº†é™ä½ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥åˆ©ç”¨å‘é‡åŒ–ï¼Œå¹¶ä¸”æ‰€æœ‰é›†æˆæˆå‘˜çš„è¾“å‡ºå¯ä»¥åœ¨ä¸€æ¬¡å‰å‘ä¼ é€’ä¸­è®¡ç®—å‡ºæ¥ã€‚åœ¨å¦ä¸€ç§æ–¹æ³•ä¸­ï¼Œç§°ä¸º**å¤šè¾“å…¥/å¤šè¾“å‡º**å¤„ç†ï¼ˆ**MIMO**ï¼›[**?**]ï¼‰ï¼Œå•ä¸ªç½‘ç»œè¢«é¼“åŠ±å­¦ä¹ å¤šä¸ªç‹¬ç«‹çš„å­ç½‘ç»œã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¤šä¸ªè¾“å…¥ä¸å¤šä¸ªç›¸åº”æ ‡æ³¨çš„è¾“å‡ºä¸€èµ·ä¼ é€’ã€‚ä¾‹å¦‚ï¼Œç½‘ç»œä¼šè¢«å‘ˆç°ä¸‰å¼ å›¾ç‰‡ï¼šä¸€å¼ ç‹—çš„ã€ä¸€å¼ çŒ«çš„å’Œä¸€å¼ é¸¡çš„ã€‚ç›¸åº”çš„è¾“å‡ºæ ‡ç­¾ä¹Ÿä¼šä¼ é€’ï¼Œç½‘ç»œéœ€è¦å­¦ä¹ åœ¨ç¬¬ä¸€ä¸ªè¾“å‡ºèŠ‚ç‚¹ä¸Šé¢„æµ‹â€œç‹—â€ï¼Œåœ¨ç¬¬äºŒä¸ªè¾“å‡ºèŠ‚ç‚¹ä¸Šé¢„æµ‹â€œçŒ«â€ï¼Œåœ¨ç¬¬ä¸‰ä¸ªè¾“å‡ºèŠ‚ç‚¹ä¸Šé¢„æµ‹â€œé¸¡â€ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œä¸€å¼ å•ç‹¬çš„å›¾ç‰‡ä¼šè¢«é‡å¤ä¸‰æ¬¡ï¼ŒMIMOé›†æˆä¼šäº§ç”Ÿä¸‰ä¸ªä¸åŒçš„é¢„æµ‹ï¼ˆæ¯ä¸ªè¾“å‡ºèŠ‚ç‚¹ä¸€ä¸ªï¼‰ã€‚å› æ­¤ï¼ŒMIMOæ–¹æ³•çš„å†…å­˜å ç”¨å’Œè®¡ç®—æˆæœ¬å‡ ä¹ä¸å•ä¸€ç¥ç»ç½‘ç»œç›¸å½“ï¼ŒåŒæ—¶ä»èƒ½æä¾›é›†æˆæ–¹æ³•çš„æ‰€æœ‰ä¼˜åŠ¿ã€‚
- en: 6.4 Exploring neural network augmentation with Bayesian last-layer methods
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.4 æ¢ç´¢è´å¶æ–¯æœ€åä¸€å±‚æ–¹æ³•åœ¨ç¥ç»ç½‘ç»œå¢å¼ºä¸­çš„åº”ç”¨
- en: 'Through the course of [*ChapterÂ 5*](CH5.xhtml#x1-600005), [*Principled Approaches
    for Bayesian Deep* *Learning*](CH5.xhtml#x1-600005) and [*ChapterÂ 6*](#x1-820006),
    [*Using the Standard Toolbox for Bayesian Deep* *Learning*](#x1-820006), weâ€™ve
    explored a variety of methods for Bayesian inference with DNNs. These methods
    have incorporated some form of uncertainty information at every layer, whether
    through the use of explicitly probabilistic means or via ensemble-based or dropout-based
    approximations. These methods have certain advantages. Their consistent Bayesian
    (or, more accurately, approximately Bayesian) mechanics mean that they are consistent:
    the same principles are applied at each layer, both in terms of network architecture
    and update rules. This makes them easier to justify from a theoretical standpoint,
    as we know that any theoretical guarantees apply at each layer. In addition to
    this, it means that we have the benefit of being able to access uncertainties
    at every level: we can exploit embeddings in these networks just as we exploit
    embeddings in standard deep learning models, and weâ€™ll have access to uncertainties
    along with those embeddings.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: é€šè¿‡[*ç¬¬5ç« *](CH5.xhtml#x1-600005)ã€ã€Š[*è´å¶æ–¯æ·±åº¦å­¦ä¹ çš„åŸåˆ™æ–¹æ³•*](CH5.xhtml#x1-600005)ã€‹å’Œ[*ç¬¬6ç« *](#x1-820006)ã€ã€Š[*ä½¿ç”¨æ ‡å‡†å·¥å…·ç®±è¿›è¡Œè´å¶æ–¯æ·±åº¦å­¦ä¹ *](#x1-820006)ã€‹ï¼Œæˆ‘ä»¬æ¢ç´¢äº†å¤šç§ç”¨äºæ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰çš„è´å¶æ–¯æ¨ç†æ–¹æ³•ã€‚è¿™äº›æ–¹æ³•åœ¨æ¯ä¸€å±‚ä¸­éƒ½å¼•å…¥äº†æŸç§å½¢å¼çš„ä¸ç¡®å®šæ€§ä¿¡æ¯ï¼Œæ— è®ºæ˜¯é€šè¿‡æ˜¾å¼çš„æ¦‚ç‡æ–¹æ³•ï¼Œè¿˜æ˜¯é€šè¿‡åŸºäºé›†æˆæˆ–ä¸¢å¼ƒæ³•çš„è¿‘ä¼¼ã€‚è¿™äº›æ–¹æ³•æœ‰å…¶ç‹¬ç‰¹çš„ä¼˜åŠ¿ã€‚å®ƒä»¬ä¸€è‡´çš„è´å¶æ–¯ï¼ˆæˆ–è€…æ›´å‡†ç¡®åœ°è¯´ï¼Œè¿‘ä¼¼è´å¶æ–¯ï¼‰æœºåˆ¶æ„å‘³ç€å®ƒä»¬æ˜¯ä¸€è‡´çš„ï¼šç›¸åŒçš„åŸç†åœ¨æ¯ä¸€å±‚éƒ½å¾—åˆ°åº”ç”¨ï¼Œæ— è®ºæ˜¯åœ¨ç½‘ç»œæ¶æ„è¿˜æ˜¯æ›´æ–°è§„åˆ™æ–¹é¢ã€‚è¿™ä½¿å¾—ä»ç†è®ºè§’åº¦è§£é‡Šå®ƒä»¬å˜å¾—æ›´å®¹æ˜“ï¼Œå› ä¸ºæˆ‘ä»¬çŸ¥é“ä»»ä½•ç†è®ºä¸Šçš„ä¿è¯éƒ½é€‚ç”¨äºæ¯ä¸€å±‚ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œè¿™è¿˜æ„å‘³ç€æˆ‘ä»¬èƒ½å¤Ÿåœ¨æ¯ä¸€å±‚è®¿é—®ä¸ç¡®å®šæ€§ï¼šæˆ‘ä»¬å¯ä»¥åƒåœ¨æ ‡å‡†æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­åˆ©ç”¨åµŒå…¥ä¸€æ ·ï¼Œåˆ©ç”¨è¿™äº›ç½‘ç»œä¸­çš„åµŒå…¥ï¼Œå¹¶ä¸”æˆ‘ä»¬å°†èƒ½å¤ŸåŒæ—¶è®¿é—®è¿™äº›åµŒå…¥çš„ä¸ç¡®å®šæ€§ã€‚
- en: However, these networks also come with some drawbacks. As weâ€™ve seen, methods
    such as PBP and BBB have more complicated mechanics, which makes them more difficult
    to apply to more sophisticated neural network architectures. The topics earlier
    in this chapter demonstrate that we can get around this by using MC dropout or
    deep ensembles, but they increase our overheads in terms of computation and/or
    memory footprint. This is where **Bayesian Last-Layer** (**BLL**) methods (see
    *Figure* [*6.4*](#x1-97005r4)) come in. This class of methods gives us both the
    flexibility of using any NN architecture, while also being more computationally
    and memory efficient than MC dropout or deep ensembles.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œè¿™äº›ç½‘ç»œä¹Ÿæœ‰ä¸€äº›ç¼ºç‚¹ã€‚æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œåƒ PBP å’Œ BBB è¿™æ ·çš„ç®—æ³•å…·æœ‰æ›´å¤æ‚çš„æœºåˆ¶ï¼Œè¿™ä½¿å¾—å®ƒä»¬æ›´éš¾åº”ç”¨äºæ›´å¤æ‚çš„ç¥ç»ç½‘ç»œæ¶æ„ã€‚æœ¬ç« å‰é¢è®¨è®ºçš„å†…å®¹è¡¨æ˜ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨
    MC dropout æˆ–æ·±åº¦é›†æˆæ¥ç»•è¿‡è¿™äº›é—®é¢˜ï¼Œä½†å®ƒä»¬ä¼šå¢åŠ æˆ‘ä»¬çš„è®¡ç®—å’Œ/æˆ–å†…å­˜å¼€é”€ã€‚æ­¤æ—¶ï¼Œ**è´å¶æ–¯æœ€åä¸€å±‚**ï¼ˆ**BLL**ï¼‰æ–¹æ³•ï¼ˆå‚è§*å›¾* [*6.4*](#x1-97005r4)ï¼‰ä¾¿æ´¾ä¸Šç”¨åœºã€‚è¿™ç±»æ–¹æ³•æ—¢èƒ½è®©æˆ‘ä»¬çµæ´»åœ°ä½¿ç”¨ä»»ä½•ç¥ç»ç½‘ç»œæ¶æ„ï¼ŒåŒæ—¶æ¯”
    MC dropout æˆ–æ·±åº¦é›†æˆæ–¹æ³•åœ¨è®¡ç®—å’Œå†…å­˜ä¸Šæ›´ä¸ºé«˜æ•ˆã€‚
- en: '![PIC](img/file144.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![å›¾ç‰‡](img/file144.png)'
- en: 'FigureÂ 6.4: Vanilla NN compared to a BLL network'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 'å›¾ 6.4: Vanilla NN ä¸ BLL ç½‘ç»œçš„æ¯”è¾ƒ'
- en: 'As youâ€™ve probably guessed, the fundamental principle behind BLL methods is
    to estimate uncertainties only at the last-layer. But what you may not have guessed
    is why this is possible. Deep learningâ€™s success is due to the non-linear nature
    of NNs: the successive layers of non-linear transformations enable them to learn
    rich lower-dimensional representations of high-dimensional data. However, this
    non-linearity makes model uncertainty estimation difficult. Closed-form solutions
    for model uncertainty estimation are available for a variety of linear models,
    but unfortunately, this isnâ€™t the case for our highly non-linear DNNs. So, what
    can we do?'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚ä½ å¯èƒ½å·²ç»çŒœåˆ°çš„ï¼ŒBLL æ–¹æ³•èƒŒåçš„åŸºæœ¬åŸç†æ˜¯ä»…åœ¨æœ€åä¸€å±‚ä¼°è®¡ä¸ç¡®å®šæ€§ã€‚ä½†æ˜¯ä½ å¯èƒ½æ²¡æœ‰çŒœåˆ°çš„æ˜¯ï¼Œä¸ºä»€ä¹ˆè¿™ä¼šæˆä¸ºå¯èƒ½ã€‚æ·±åº¦å­¦ä¹ çš„æˆåŠŸå½’å› äºç¥ç»ç½‘ç»œçš„éçº¿æ€§ç‰¹æ€§ï¼šè¿ç»­çš„éçº¿æ€§å˜æ¢ä½¿å…¶èƒ½å¤Ÿå­¦ä¹ é«˜ç»´æ•°æ®çš„ä¸°å¯Œä½ç»´è¡¨ç¤ºã€‚ç„¶è€Œï¼Œè¿™ç§éçº¿æ€§ä½¿å¾—æ¨¡å‹ä¸ç¡®å®šæ€§ä¼°è®¡å˜å¾—å›°éš¾ã€‚çº¿æ€§æ¨¡å‹çš„æ¨¡å‹ä¸ç¡®å®šæ€§ä¼°è®¡æœ‰ç°æˆçš„å°é—­å½¢å¼è§£ï¼Œä½†ä¸å¹¸çš„æ˜¯ï¼Œå¯¹äºæˆ‘ä»¬é«˜åº¦éçº¿æ€§çš„
    DNN æ¥è¯´ï¼Œæƒ…å†µå¹¶éå¦‚æ­¤ã€‚é‚£ä¹ˆï¼Œæˆ‘ä»¬èƒ½åšä»€ä¹ˆå‘¢ï¼Ÿ
- en: 'Well, fortunately for us, the representations learned by the DNNs can also
    serve as inputs to simpler linear models. In this way, we let the DNN do the heavy
    lifting: condensing our high-dimensional input space down to a task-specific low-dimensional
    representation. Because of this, the penultimate layer in the NN is far easier
    to deal with; after all, in most cases our output is simply some linear transformation
    of this layer. This means we can apply a linear model to this layer, which in
    turn means we can apply closed-form solutions for model uncertainty estimation.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: å¹¸è¿çš„æ˜¯ï¼ŒDNN å­¦åˆ°çš„è¡¨ç¤ºä¹Ÿå¯ä»¥ä½œä¸ºæ›´ç®€å•çº¿æ€§æ¨¡å‹çš„è¾“å…¥ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬è®© DNN æ¥æ‰¿æ‹…ç¹é‡çš„å·¥ä½œï¼šå°†é«˜ç»´è¾“å…¥ç©ºé—´å‹ç¼©ä¸ºç‰¹å®šä»»åŠ¡çš„ä½ç»´è¡¨ç¤ºã€‚å› æ­¤ï¼Œç¥ç»ç½‘ç»œä¸­çš„å€’æ•°ç¬¬äºŒå±‚è¦å¤„ç†èµ·æ¥å®¹æ˜“å¾—å¤šï¼›æ¯•ç«Ÿï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬çš„è¾“å‡ºä»…ä»…æ˜¯è¯¥å±‚çš„æŸç§çº¿æ€§å˜æ¢ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥å°†çº¿æ€§æ¨¡å‹åº”ç”¨äºè¯¥å±‚ï¼Œè¿™ä¹Ÿæ„å‘³ç€æˆ‘ä»¬å¯ä»¥åº”ç”¨å°é—­å½¢å¼è§£æ¥è¿›è¡Œæ¨¡å‹ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚
- en: We can make use of other last-layer approaches too; recent work has demonstrated
    that MC dropout is effective when applied only at the last layer. While this still
    requires multiple forward passes, these forward passes only need to be done for
    a single layer, making them much more computationally efficient, particularly
    for larger models.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¹Ÿå¯ä»¥åˆ©ç”¨å…¶ä»–æœ€åä¸€å±‚æ–¹æ³•ï¼›æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œå½“ä»…åœ¨æœ€åä¸€å±‚åº”ç”¨æ—¶ï¼ŒMC dropout ä¹Ÿå¾ˆæœ‰æ•ˆã€‚å°½ç®¡è¿™ä»ç„¶éœ€è¦å¤šæ¬¡å‰å‘ä¼ æ’­ï¼Œä½†è¿™äº›å‰å‘ä¼ æ’­åªéœ€åœ¨å•ä¸€å±‚ä¸­å®Œæˆï¼Œå› æ­¤åœ¨è®¡ç®—ä¸Šæ›´åŠ é«˜æ•ˆï¼Œå°¤å…¶æ˜¯å¯¹äºè¾ƒå¤§çš„æ¨¡å‹ã€‚
- en: 6.4.1 Last-layer methods for Bayesian inference
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4.1 è´å¶æ–¯æ¨ç†çš„æœ€åä¸€å±‚æ–¹æ³•
- en: The method proposed by Jasper Snoek et al. in their 2015 paper, *Scalable* *Bayesian
    Optimization Using Deep Neural Networks*, introduces the concept of using a post-hoc
    Bayesian linear regressor to obtain model uncertainties for DNNs. This method
    was devised as a way of achieving Gaussian Process-like high-quality uncertainties
    with improved scalability.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Jasper Snoek ç­‰äººåœ¨ä»–ä»¬2015å¹´çš„è®ºæ–‡ã€Š*å¯æ‰©å±•* *è´å¶æ–¯ä¼˜åŒ–ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œ*ã€‹ä¸­æå‡ºçš„æ–¹æ³•ï¼Œå¼•å…¥äº†ä½¿ç”¨äº‹åè´å¶æ–¯çº¿æ€§å›å½’å™¨æ¥è·å¾— DNN
    æ¨¡å‹ä¸ç¡®å®šæ€§çš„æ¦‚å¿µã€‚è¯¥æ–¹æ³•è¢«è®¾è®¡ä¸ºä¸€ç§å®ç°ç±»ä¼¼é«˜æ–¯è¿‡ç¨‹çš„é«˜è´¨é‡ä¸ç¡®å®šæ€§ä¼°è®¡çš„æ–¹å¼ï¼Œå¹¶ä¸”å…·æœ‰æ›´å¥½çš„å¯æ‰©å±•æ€§ã€‚
- en: The method first involves training a NN on some data *X* and targets **y**.
    This training phase trains a linear output layer, **z**[*i*], resulting in a network
    that produces point estimates (typical of a standard DNN). We then take the penultimate
    layer (or the last hidden layer), **z**[*i*âˆ’1], as our set of basis functions.
    From here, itâ€™s simply a case of replacing our final layer with a Bayesian linear
    regressor. Now, instead of our point estimates, our network will produce a predictive
    mean and variance. For further details on this method and adaptive basis regression,
    we point the reader to Jasper Snoek et al.â€™s paper, and to Christopher Bishopâ€™s
    *Pattern Recognition and Machine* *Learning*.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è¯¥æ–¹æ³•é¦–å…ˆæ¶‰åŠåœ¨ä¸€äº›æ•°æ®*X*å’Œç›®æ ‡**y**ä¸Šè®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œï¼ˆNNï¼‰ã€‚è¿™ä¸ªè®­ç»ƒé˜¶æ®µè®­ç»ƒä¸€ä¸ªçº¿æ€§è¾“å‡ºå±‚ï¼Œ**z**[*i*]ï¼Œç»“æœæ˜¯ä¸€ä¸ªç”Ÿæˆç‚¹ä¼°è®¡çš„ç½‘ç»œï¼ˆè¿™åœ¨æ ‡å‡†çš„æ·±åº¦ç¥ç»ç½‘ç»œä¸­æ˜¯å…¸å‹çš„ï¼‰ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†å€’æ•°ç¬¬äºŒå±‚ï¼ˆæˆ–æœ€åä¸€å±‚éšè—å±‚ï¼‰**z**[*i*âˆ’1]ä½œä¸ºæˆ‘ä»¬çš„åŸºç¡€å‡½æ•°é›†ã€‚ä»è¿™é‡Œå¼€å§‹ï¼Œåªéœ€è¦å°†æœ€åä¸€å±‚æ›¿æ¢ä¸ºè´å¶æ–¯çº¿æ€§å›å½’å™¨ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬çš„ç½‘ç»œå°†ç”Ÿæˆé¢„æµ‹çš„å‡å€¼å’Œæ–¹å·®ï¼Œè€Œä¸æ˜¯ç‚¹ä¼°è®¡ã€‚å…³äºè¯¥æ–¹æ³•å’Œè‡ªé€‚åº”åŸºç¡€å›å½’çš„æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚é˜…Jasper
    Snoekç­‰äººçš„è®ºæ–‡ï¼Œä»¥åŠChristopher Bishopçš„*æ¨¡å¼è¯†åˆ«ä¸æœºå™¨å­¦ä¹ *ã€‚
- en: Now, letâ€™s see how we achieve this in code.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•é€šè¿‡ä»£ç å®ç°è¿™ä¸€è¿‡ç¨‹ã€‚
- en: 'Step 1: Creating and training our base model'
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 1ï¼šåˆ›å»ºå’Œè®­ç»ƒæˆ‘ä»¬çš„åŸºç¡€æ¨¡å‹
- en: 'First, we set up and train our network:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬è®¾ç½®å¹¶è®­ç»ƒæˆ‘ä»¬çš„ç½‘ç»œï¼š
- en: '[PRE10]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Step 2: Using a neural network layer as a basis function'
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 2ï¼šä½¿ç”¨ç¥ç»ç½‘ç»œå±‚ä½œä¸ºåŸºç¡€å‡½æ•°
- en: 'Now that we have our base network, we just need to access the penultimate layer
    so that we can feed this as our basis function to our Bayesian regressor. This
    is easily done using TensorFlowâ€™s high-level API, for example:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å·²ç»æœ‰äº†åŸºç¡€ç½‘ç»œï¼Œæˆ‘ä»¬åªéœ€è¦è®¿é—®å€’æ•°ç¬¬äºŒå±‚ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å°†å…¶ä½œä¸ºåŸºç¡€å‡½æ•°ä¼ é€’ç»™æˆ‘ä»¬çš„è´å¶æ–¯å›å½’å™¨ã€‚è¿™å¯ä»¥é€šè¿‡ä½¿ç”¨TensorFlowçš„é«˜çº§APIè½»æ¾å®Œæˆï¼Œä¾‹å¦‚ï¼š
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This will build a model that will allow us to obtain the output of the second
    hidden layer by simply calling its `predict` method:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°†æ„å»ºä¸€ä¸ªæ¨¡å‹ï¼Œå…è®¸æˆ‘ä»¬é€šè¿‡ç®€å•åœ°è°ƒç”¨å…¶`predict`æ–¹æ³•æ¥è·å¾—ç¬¬äºŒä¸ªéšè—å±‚çš„è¾“å‡ºï¼š
- en: '[PRE12]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This is all thatâ€™s needed to prepare our basis function for passing to our Bayesian
    linear regressor.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å°±æ˜¯æˆ‘ä»¬ä¸ºä¼ é€’ç»™è´å¶æ–¯çº¿æ€§å›å½’å™¨å‡†å¤‡åŸºç¡€å‡½æ•°æ‰€éœ€è¦åšçš„ä¸€åˆ‡ã€‚
- en: 'Step 3: Preparing our variables for Bayesian linear regression'
  id: totrans-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 3ï¼šä¸ºè´å¶æ–¯çº¿æ€§å›å½’å‡†å¤‡æˆ‘ä»¬çš„å˜é‡
- en: 'For the Bayesian regressor, we assume that our outputs, *y*[*i*] âˆˆ **y**, are
    conditionally normally distributed according to a linear relationship with our
    inputs, **x**[*i*] âˆˆ *X*:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè´å¶æ–¯å›å½’å™¨ï¼Œæˆ‘ä»¬å‡è®¾æˆ‘ä»¬çš„è¾“å‡ºï¼Œ*y*[*i*] âˆˆ **y**ï¼Œæ ¹æ®ä¸è¾“å…¥**x**[*i*] âˆˆ *X*çš„çº¿æ€§å…³ç³»æ¡ä»¶åœ°æœä»æ­£æ€åˆ†å¸ƒï¼š
- en: '![yi = ğ’© (Î± + xâŠºiÎ², Ïƒ2) ](img/file145.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![yi = ğ’© (Î± + xâŠºiÎ², ÏƒÂ²) ](img/file145.jpg)'
- en: 'Here, *Î±* is our bias term, *Î²* are our model coefficients, and *Ïƒ*Â² is the
    variance associated with our predictions. Weâ€™ll also make some prior assumptions
    about these parameters, namely:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œï¼Œ*Î±*æ˜¯æˆ‘ä»¬çš„åç½®é¡¹ï¼Œ*Î²*æ˜¯æˆ‘ä»¬çš„æ¨¡å‹ç³»æ•°ï¼Œ*Ïƒ*Â²æ˜¯ä¸æˆ‘ä»¬çš„é¢„æµ‹ç›¸å…³çš„æ–¹å·®ã€‚æˆ‘ä»¬è¿˜å°†å¯¹è¿™äº›å‚æ•°åšå‡ºä¸€äº›å…ˆéªŒå‡è®¾ï¼Œå³ï¼š
- en: '![Î± â‰ˆ ğ’© (0,1) ](img/file146.jpg)![Î² â‰ˆ ğ’© (0,1) ](img/file147.jpg)![Ïƒ2 â‰ˆ |ğ’© (0,1)|
    ](img/file148.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![Î± â‰ˆ ğ’© (0,1) ](img/file146.jpg)![Î² â‰ˆ ğ’© (0,1) ](img/file147.jpg)![ÏƒÂ² â‰ˆ |ğ’© (0,1)|
    ](img/file148.jpg)'
- en: 'Note that equation 6.6 denotes the half-normal of a Gaussian distribution.
    To wrap up the Bayesian regressor in such a way that itâ€™s easy (and practical)
    to integrate it with our Keras model, weâ€™ll create a `BayesianLastLayer` class.
    This class will use the TensorFlow Probability library to allow us to implement
    the probability distributions and sampling functions weâ€™ll need for our Bayesian
    regressor. Letâ€™s walk through the various components of our class:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: è¯·æ³¨æ„ï¼Œå…¬å¼6.6è¡¨ç¤ºçš„æ˜¯é«˜æ–¯åˆ†å¸ƒçš„åŠæ­£æ€åˆ†å¸ƒã€‚ä¸ºäº†å°†è´å¶æ–¯å›å½’å™¨åŒ…è£…æˆæ˜“äºï¼ˆä¸”å®ç”¨åœ°ï¼‰ä¸æˆ‘ä»¬çš„Kerasæ¨¡å‹é›†æˆçš„å½¢å¼ï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª`BayesianLastLayer`ç±»ã€‚è¿™ä¸ªç±»å°†ä½¿ç”¨TensorFlow
    Probabilityåº“ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿå®ç°è´å¶æ–¯å›å½’å™¨æ‰€éœ€çš„æ¦‚ç‡åˆ†å¸ƒå’Œé‡‡æ ·å‡½æ•°ã€‚è®©æˆ‘ä»¬é€æ­¥äº†è§£æˆ‘ä»¬ç±»çš„å„ä¸ªç»„ä»¶ï¼š
- en: '[PRE13]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'As we see here, our class requires at least two arguments at instantiation:
    `model`, which is our Keras model, and `basis``_layer`, which is the layer output
    we wanted to feed to our Bayesian regressor. The following arguments are all parameters
    for the **Hamiltonian Monte-Carlo** (**HMC**) sampling for which we define some
    default values. These values may need to be changed depending on the input. For
    example, for a higher dimensional input (for instance, if youâ€™re using `layer``_1`),
    you may want to further reduce the step size and increase both the number of burn-in
    steps and the overall number of samples.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æˆ‘ä»¬æ‰€è§ï¼Œæˆ‘ä»¬çš„ç±»åœ¨å®ä¾‹åŒ–æ—¶è‡³å°‘éœ€è¦ä¸¤ä¸ªå‚æ•°ï¼š`model`ï¼Œå³æˆ‘ä»¬çš„Kerasæ¨¡å‹ï¼›å’Œ`basis``_layer`ï¼Œå³æˆ‘ä»¬å¸Œæœ›é¦ˆé€ç»™è´å¶æ–¯å›å½’å™¨çš„å±‚è¾“å‡ºã€‚æ¥ä¸‹æ¥çš„å‚æ•°éƒ½æ˜¯**å“ˆå¯†é¡¿è’™ç‰¹å¡ç½—**ï¼ˆ**HMC**ï¼‰é‡‡æ ·çš„å‚æ•°ï¼Œæˆ‘ä»¬ä¸ºå…¶å®šä¹‰äº†ä¸€äº›é»˜è®¤å€¼ã€‚æ ¹æ®è¾“å…¥çš„ä¸åŒï¼Œè¿™äº›å€¼å¯èƒ½éœ€è¦è°ƒæ•´ã€‚ä¾‹å¦‚ï¼Œå¯¹äºæ›´é«˜ç»´åº¦çš„è¾“å…¥ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœä½ ä½¿ç”¨çš„æ˜¯`layer``_1`ï¼‰ï¼Œä½ å¯èƒ½å¸Œæœ›è¿›ä¸€æ­¥å‡å°æ­¥é•¿å¹¶å¢åŠ ç‡ƒçƒ§æœŸæ­¥éª¤çš„æ•°é‡ä»¥åŠæ€»ä½“æ ·æœ¬æ•°ã€‚
- en: 'Step 4: Connecting our basis function model'
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬4æ­¥ï¼šè¿æ¥æˆ‘ä»¬çš„åŸºç¡€å‡½æ•°æ¨¡å‹
- en: 'Next, we simply define a few functions for creating our basis function model
    and for obtaining its outputs:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ç®€å•å®šä¹‰å‡ ä¸ªå‡½æ•°ï¼Œç”¨äºåˆ›å»ºæˆ‘ä»¬çš„åŸºç¡€å‡½æ•°æ¨¡å‹å¹¶è·å–å…¶è¾“å‡ºï¼š
- en: '[PRE14]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Step 5: Creating a method to fit our Bayesian linear regression parameters'
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬5æ­¥ï¼šåˆ›å»ºé€‚é…è´å¶æ–¯çº¿æ€§å›å½’å‚æ•°çš„æ–¹æ³•
- en: Now things get a little more complicated. We need to define the `fit()` method,
    which will use HMC sampling to find our model parameters *Î±*, *Î²*, and *Ïƒ*Â². Weâ€™ll
    provide an overview of what the code is doing here, but for more (hands-on) information
    on sampling, we direct the reader to *Bayesian Analysis with Python* by Osvaldo
    Martin.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨äº‹æƒ…å˜å¾—æœ‰äº›å¤æ‚ã€‚æˆ‘ä»¬éœ€è¦å®šä¹‰`fit()`æ–¹æ³•ï¼Œå®ƒå°†ä½¿ç”¨HMCé‡‡æ ·æ¥æ‰¾åˆ°æˆ‘ä»¬çš„æ¨¡å‹å‚æ•°*Î±*ã€*Î²*å’Œ*Ïƒ*Â²ã€‚æˆ‘ä»¬å°†åœ¨è¿™é‡Œæä¾›ä»£ç åšäº†ä»€ä¹ˆçš„æ¦‚è¿°ï¼Œä½†å…³äºé‡‡æ ·çš„æ›´å¤šï¼ˆå®è·µï¼‰ä¿¡æ¯ï¼Œæˆ‘ä»¬æ¨èè¯»è€…å‚è€ƒOsvaldo
    Martinçš„ã€ŠPythonè´å¶æ–¯åˆ†æã€‹ã€‚
- en: 'Firstly, we define a joint distribution using the priors described in equations
    4.3-4.5\. Thanks to TensorFlow Probabilityâ€™s `distributions` module, this is pretty
    straightforward:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬ä½¿ç”¨æ–¹ç¨‹4.3-4.5ä¸­æè¿°çš„å…ˆéªŒå®šä¹‰ä¸€ä¸ªè”åˆåˆ†å¸ƒã€‚å¾—ç›ŠäºTensorFlow Probabilityçš„`distributions`æ¨¡å—ï¼Œè¿™éå¸¸ç®€å•ï¼š
- en: '[PRE15]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We then go on to set up our sampler using TensorFlow Probabilityâ€™s `HamiltonianMonteCarlo`
    sampler class. To do this, weâ€™ll need to define our target log probability function.
    The `distributions` module makes this fairly trivial, but we still need to define
    a function to feed our model parameters to the distribution objectâ€™s `log``_prob()`
    method (line 28). We can then pass this to the instantiation of `hmc``_kernel`:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨TensorFlow Probabilityçš„`HamiltonianMonteCarlo`é‡‡æ ·å™¨ç±»æ¥è®¾ç½®æˆ‘ä»¬çš„é‡‡æ ·å™¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ç›®æ ‡å¯¹æ•°æ¦‚ç‡å‡½æ•°ã€‚`distributions`æ¨¡å—ä½¿å¾—è¿™ä¸€è¿‡ç¨‹ç›¸å½“ç®€å•ï¼Œä½†æˆ‘ä»¬ä»ç„¶éœ€è¦å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œå°†æˆ‘ä»¬çš„æ¨¡å‹å‚æ•°ä¼ é€’ç»™åˆ†å¸ƒå¯¹è±¡çš„`log``_prob()`æ–¹æ³•ï¼ˆç¬¬28è¡Œï¼‰ã€‚ç„¶åæˆ‘ä»¬å°†å…¶ä¼ é€’ç»™`hmc``_kernel`çš„å®ä¾‹åŒ–ï¼š
- en: '[PRE16]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now that things are set up, weâ€™re ready to run our sampler. To do this, we
    call the `mcmc.sample``_chain()` function, passing in our HMC parameters, an initial
    state for our model parameters, and our HMC sampler. We then run our sampling,
    which returns `states`, which comprises our parameter samples, and `kernel``_results`,
    which contains some information about the sampling process. The information we
    care about here is to do with the proportion of accepted samples. If our sampler
    has run successfully, then weâ€™ll have a good proportion of accepted samples (indicating
    a high acceptance rate). If it hasnâ€™t been successful, then our acceptance rate
    will be low (perhaps even 0%!) and we may need to tune our sampler parameters.
    We print this to the console so that we can keep an eye on the acceptance rate
    (we wrap the call to `sample``_chain()` in a `run``_chain()` function so that
    it can be extended to sampling with multiple chains):'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ä¸€åˆ‡å·²ç»è®¾ç½®å¥½ï¼Œæˆ‘ä»¬å‡†å¤‡è¿è¡Œé‡‡æ ·å™¨äº†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è°ƒç”¨`mcmc.sample``_chain()`å‡½æ•°ï¼Œä¼ å…¥æˆ‘ä»¬çš„HMCå‚æ•°ã€æ¨¡å‹å‚æ•°çš„åˆå§‹çŠ¶æ€å’Œæˆ‘ä»¬çš„HMCé‡‡æ ·å™¨ã€‚ç„¶åæˆ‘ä»¬è¿è¡Œé‡‡æ ·ï¼Œå®ƒä¼šè¿”å›`states`ï¼Œå…¶ä¸­åŒ…å«æˆ‘ä»¬çš„å‚æ•°æ ·æœ¬ï¼Œä»¥åŠ`kernel``_results`ï¼Œå…¶ä¸­åŒ…å«ä¸€äº›å…³äºé‡‡æ ·è¿‡ç¨‹çš„ä¿¡æ¯ã€‚æˆ‘ä»¬å…³å¿ƒçš„ä¿¡æ¯æ˜¯å…³äºæ¥å—æ ·æœ¬çš„æ¯”ä¾‹ã€‚å¦‚æœé‡‡æ ·å™¨è¿è¡ŒæˆåŠŸï¼Œæˆ‘ä»¬å°†æœ‰ä¸€ä¸ªè¾ƒé«˜æ¯”ä¾‹çš„æ¥å—æ ·æœ¬ï¼ˆè¡¨ç¤ºæ¥å—ç‡å¾ˆé«˜ï¼‰ã€‚å¦‚æœé‡‡æ ·å™¨æ²¡æœ‰æˆåŠŸï¼Œæ¥å—ç‡ä¼šå¾ˆä½ï¼ˆç”šè‡³å¯èƒ½æ˜¯0%ï¼ï¼‰ï¼Œè¿™æ—¶æˆ‘ä»¬å¯èƒ½éœ€è¦è°ƒæ•´é‡‡æ ·å™¨çš„å‚æ•°ã€‚æˆ‘ä»¬ä¼šå°†è¿™ä¸ªä¿¡æ¯æ‰“å°åˆ°æ§åˆ¶å°ï¼Œä»¥ä¾¿éšæ—¶ç›‘æ§æ¥å—ç‡ï¼ˆæˆ‘ä»¬å°†å¯¹`sample``_chain()`çš„è°ƒç”¨å°è£…åœ¨`run``_chain()`å‡½æ•°ä¸­ï¼Œè¿™æ ·å®ƒå¯ä»¥æ‰©å±•ä¸ºå¤šé“¾é‡‡æ ·ï¼‰ï¼š
- en: '[PRE17]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Once weâ€™ve run our sampler, we can fetch our model parameters. We take them
    from the post-burn-in samples and assign them to class variables for later use
    in inference:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸€æ—¦æˆ‘ä»¬è¿è¡Œäº†é‡‡æ ·å™¨ï¼Œæˆ‘ä»¬å°±å¯ä»¥è·å–æˆ‘ä»¬çš„æ¨¡å‹å‚æ•°ã€‚æˆ‘ä»¬ä»åç‡ƒçƒ§æ ·æœ¬ä¸­æå–å®ƒä»¬ï¼Œå¹¶å°†å…¶åˆ†é…ç»™ç±»å˜é‡ï¼Œä»¥ä¾¿åç»­æ¨æ–­ä½¿ç”¨ï¼š
- en: '[PRE18]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Step 6: Inference'
  id: totrans-133
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬6æ­¥ï¼šæ¨æ–­
- en: 'The last thing we need to do is implement a function to make predictions using
    the learned parameters of our joint distribution. To do this, weâ€™ll define two
    functions: `get``_divd``_dist()`, which will obtain the posterior predictive distribution
    given our input, and `predict()`, which will call `get``_divd``_dist()` and compute
    our mean (*Î¼*) and standard deviation (*Ïƒ*) from our posterior distribution:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦åšçš„æœ€åä¸€ä»¶äº‹æ˜¯å®ç°ä¸€ä¸ªå‡½æ•°ï¼Œåˆ©ç”¨æˆ‘ä»¬è”åˆåˆ†å¸ƒçš„å­¦ä¹ åˆ°çš„å‚æ•°æ¥è¿›è¡Œé¢„æµ‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å®šä¹‰ä¸¤ä¸ªå‡½æ•°ï¼š`get``_divd``_dist()`ï¼Œå®ƒå°†æ ¹æ®æˆ‘ä»¬çš„è¾“å…¥è·å–åéªŒé¢„æµ‹åˆ†å¸ƒï¼›ä»¥åŠ`predict()`ï¼Œå®ƒå°†è°ƒç”¨`get``_divd``_dist()`å¹¶è®¡ç®—æˆ‘ä»¬åéªŒåˆ†å¸ƒçš„å‡å€¼ï¼ˆ*Î¼*ï¼‰å’Œæ ‡å‡†å·®ï¼ˆ*Ïƒ*ï¼‰ï¼š
- en: '[PRE19]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'And thatâ€™s it! We have our BLL implementation! With this class, we have a powerful
    and principled means of obtaining Bayesian uncertainty estimates by using penultimate
    NN layers as basis functions for Bayesian regression. Making use of it is as simple
    as passing our model and defining which layer we want to use as our basis function:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: å°±è¿™æ ·ï¼æˆ‘ä»¬å®ç°äº†BLLï¼é€šè¿‡è¿™ä¸ªç±»ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨å€’æ•°ç¬¬äºŒå±‚ç¥ç»ç½‘ç»œä½œä¸ºè´å¶æ–¯å›å½’çš„åŸºå‡½æ•°ï¼Œè·å¾—å¼ºå¤§è€Œæœ‰åŸåˆ™çš„è´å¶æ–¯ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚ä½¿ç”¨å®ƒçš„æ–¹æ³•éå¸¸ç®€å•ï¼Œåªéœ€ä¼ å…¥æˆ‘ä»¬çš„æ¨¡å‹å¹¶å®šä¹‰æˆ‘ä»¬å¸Œæœ›ä½¿ç”¨å“ªä¸ªå±‚ä½œä¸ºåŸºå‡½æ•°ï¼š
- en: '[PRE20]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'While this is a powerful tool, itâ€™s not always suited for the task at hand.
    You can experiment with this yourself: try creating a model with a larger embedding
    layer. As the size of the layer increases, you should start to see that the acceptance
    rate of the sampler drops. Once itâ€™s large enough, the acceptance rate may even
    fall to 0%. So, weâ€™ll need to modify the parameters of our sampler: reducing the
    step size, increasing the number of samples, and increasing the number of burn-in
    samples. As the dimensionality of the embedding grows, it becomes more and more
    difficult to obtain a representative set of samples for the distribution.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶è¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å·¥å…·ï¼Œä½†å¹¶ä¸æ€»æ˜¯é€‚åˆå½“å‰ä»»åŠ¡ã€‚ä½ å¯ä»¥è‡ªå·±è¿›è¡Œå®éªŒï¼šå°è¯•åˆ›å»ºä¸€ä¸ªæ›´å¤§çš„åµŒå…¥å±‚ã€‚éšç€å±‚çš„å¤§å°å¢åŠ ï¼Œä½ åº”è¯¥ä¼šçœ‹åˆ°é‡‡æ ·å™¨çš„æ¥å—ç‡ä¸‹é™ã€‚ä¸€æ—¦å®ƒå˜å¾—è¶³å¤Ÿå¤§ï¼Œæ¥å—ç‡ç”šè‡³å¯èƒ½ä¸‹é™åˆ°0%ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹é‡‡æ ·å™¨çš„å‚æ•°ï¼šå‡å°‘æ­¥é•¿ï¼Œå¢åŠ æ ·æœ¬æ•°ï¼Œå¹¶å¢åŠ çƒ§å…¥æ ·æœ¬æ•°ã€‚éšç€åµŒå…¥ç»´åº¦çš„å¢åŠ ï¼Œè·å–ä¸€ä¸ªä»£è¡¨æ€§æ ·æœ¬é›†æ¥æè¿°åˆ†å¸ƒå˜å¾—è¶Šæ¥è¶Šå›°éš¾ã€‚
- en: 'For some applications, this isnâ€™t an issue, but when dealing with complex,
    high-dimensional data, this can quickly become problematic. Applications in domains
    such as computer vision, speech processing, and molecular modeling all rely on
    high-dimensional embeddings. One solution here is to reduce these embeddings further,
    for example, via dimensionality reduction. But doing so can have an unpredictable
    effect on these encodings: in fact, by reducing the dimensionality, you could
    be unintentionally removing sources of uncertainty, resulting in poorer quality
    uncertainty estimates.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºä¸€äº›åº”ç”¨æ¥è¯´ï¼Œè¿™ä¸æ˜¯é—®é¢˜ï¼Œä½†åœ¨å¤„ç†å¤æ‚çš„é«˜ç»´æ•°æ®æ—¶ï¼Œè¿™å¯èƒ½å¾ˆå¿«æˆä¸ºä¸€ä¸ªé—®é¢˜ã€‚è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³å¤„ç†å’Œåˆ†å­å»ºæ¨¡ç­‰é¢†åŸŸçš„åº”ç”¨éƒ½ä¾èµ–äºé«˜ç»´åµŒå…¥ã€‚è¿™é‡Œçš„ä¸€ä¸ªè§£å†³æ–¹æ¡ˆæ˜¯è¿›ä¸€æ­¥é™ä½è¿™äº›åµŒå…¥çš„ç»´åº¦ï¼Œä¾‹å¦‚é€šè¿‡é™ç»´ã€‚ä½†è¿™æ ·åšå¯èƒ½ä¼šå¯¹è¿™äº›ç¼–ç äº§ç”Ÿä¸å¯é¢„æµ‹çš„å½±å“ï¼šäº‹å®ä¸Šï¼Œé€šè¿‡é™ä½ç»´åº¦ï¼Œä½ å¯èƒ½ä¼šæ— æ„ä¸­å»é™¤ä¸€äº›ä¸ç¡®å®šæ€§çš„æ¥æºï¼Œä»è€Œå¯¼è‡´æ›´å·®çš„è´¨é‡çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚
- en: So, what can we do instead? Fortunately, there are a few other last-layer options
    we can employ. Next, weâ€™ll see how we can use last-layer dropout to approximate
    the Bayesian linear regression approach introduced here.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆï¼Œæˆ‘ä»¬èƒ½åšäº›ä»€ä¹ˆå‘¢ï¼Ÿå¹¸è¿çš„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€äº›å…¶ä»–çš„æœ€åä¸€å±‚é€‰é¡¹ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†çœ‹çœ‹å¦‚ä½•ä½¿ç”¨æœ€åä¸€å±‚çš„ä¸¢å¼ƒæ³•ï¼ˆdropoutï¼‰æ¥é€¼è¿‘è¿™é‡Œä»‹ç»çš„è´å¶æ–¯çº¿æ€§å›å½’æ–¹æ³•ã€‚
- en: 6.4.2 Last-layer MC dropout
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4.2 æœ€åä¸€å±‚MCä¸¢å¼ƒ
- en: 'Earlier in the chapter, we saw how we can use dropout at test time to obtain
    a distribution over our model predictions. Here, weâ€™ll combine that concept with
    the concept of last-layer uncertainties: adding an MC dropout layer, but only
    as a single layer that we add to a pre-trained network.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬ç« æ—©äº›æ—¶å€™ï¼Œæˆ‘ä»¬çœ‹åˆ°å¦‚ä½•åœ¨æµ‹è¯•æ—¶ä½¿ç”¨ä¸¢å¼ƒæ³•è·å–æ¨¡å‹é¢„æµ‹çš„åˆ†å¸ƒã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†è¿™ä¸ªæ¦‚å¿µä¸æœ€åä¸€å±‚ä¸ç¡®å®šæ€§æ¦‚å¿µç»“åˆï¼šæ·»åŠ ä¸€ä¸ªMCä¸¢å¼ƒå±‚ï¼Œä½†ä»…ä½œä¸ºæˆ‘ä»¬æ·»åŠ åˆ°é¢„è®­ç»ƒç½‘ç»œä¸­çš„ä¸€ä¸ªå•ä¸€å±‚ã€‚
- en: 'Step 1: Connecting to our base model'
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 1ï¼šè¿æ¥åˆ°æˆ‘ä»¬çš„åŸºç¡€æ¨¡å‹
- en: 'Similarly to the Bayesian last-layer method, we first need to obtain the output
    from our modelâ€™s penultimate layer:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸è´å¶æ–¯æœ€åä¸€å±‚æ–¹æ³•ç±»ä¼¼ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦ä»æ¨¡å‹çš„å€’æ•°ç¬¬äºŒå±‚è·å–è¾“å‡ºï¼š
- en: '[PRE21]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Step 2: Adding an MC dropout layer'
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 2ï¼šæ·»åŠ MCä¸¢å¼ƒå±‚
- en: 'Now, instead of implementing a Bayesian regressor, weâ€™ll simply instantiate
    a new output layer, which applies dropout to the penultimate layer:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæˆ‘ä»¬ä¸å†å®ç°ä¸€ä¸ªè´å¶æ–¯å›å½’å™¨ï¼Œè€Œæ˜¯ç®€å•åœ°å®ä¾‹åŒ–ä¸€ä¸ªæ–°çš„è¾“å‡ºå±‚ï¼Œåº”ç”¨ä¸¢å¼ƒæ³•ï¼ˆdropoutï¼‰åˆ°å€’æ•°ç¬¬äºŒå±‚ï¼š
- en: '[PRE22]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Step 3: Training the MC dropout last-layer'
  id: totrans-149
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: æ­¥éª¤ 3ï¼šè®­ç»ƒMCä¸¢å¼ƒçš„æœ€åä¸€å±‚
- en: 'Because weâ€™ve now added a new final layer, we need to run an additional step
    of training so that it can learn the mapping from our penultimate layer to the
    new output; but because our original model is doing all of the heavy lifting,
    this training is both computationally cheap and quick to run:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: å› ä¸ºæˆ‘ä»¬ç°åœ¨å¢åŠ äº†ä¸€ä¸ªæ–°çš„æœ€ç»ˆå±‚ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œé¢å¤–çš„è®­ç»ƒæ­¥éª¤ï¼Œè®©å®ƒèƒ½å¤Ÿå­¦ä¹ ä»å€’æ•°ç¬¬äºŒå±‚åˆ°æ–°è¾“å‡ºçš„æ˜ å°„ï¼›ä½†ç”±äºæˆ‘ä»¬åŸå§‹æ¨¡å‹å·²ç»å®Œæˆäº†å¤§éƒ¨åˆ†å·¥ä½œï¼Œè¿™ä¸ªè®­ç»ƒè¿‡ç¨‹æ—¢è®¡ç®—æˆæœ¬ä½ï¼Œåˆè¿è¡Œå¿«é€Ÿï¼š
- en: '[PRE23]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Step 4: Obtaining uncertainties'
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬4æ­¥ï¼šè·å–ä¸ç¡®å®šæ€§
- en: 'Now that our last layer is trained, we can implement a function to obtain the
    mean and standard deviation for our predictions using multiple forward passes
    of our MC dropout layer; line 3 onwards should be familiar from earlier in the
    chapter, and line 2 simply obtains the output from our original modelâ€™s penultimate
    layer:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬çš„æœ€åä¸€å±‚å·²ç»è®­ç»ƒå®Œæˆï¼Œæˆ‘ä»¬å¯ä»¥å®ç°ä¸€ä¸ªå‡½æ•°ï¼Œé€šè¿‡å¯¹MC dropoutå±‚è¿›è¡Œå¤šæ¬¡å‰å‘ä¼ é€’æ¥è·å–é¢„æµ‹çš„å‡å€¼å’Œæ ‡å‡†å·®ï¼›ä»ç¬¬3è¡Œå¼€å§‹åº”è¯¥å’Œæœ¬ç« å‰é¢çš„å†…å®¹ç›¸ä¼¼ï¼Œç¬¬2è¡Œåªæ˜¯è·å–æˆ‘ä»¬åŸå§‹æ¨¡å‹å€’æ•°ç¬¬äºŒå±‚çš„è¾“å‡ºï¼š
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Step 5: Inference'
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¬¬5æ­¥ï¼šæ¨ç†
- en: 'All thatâ€™s left is to call this function and obtain our new model outputs,
    complete with uncertainty estimates:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: å‰©ä¸‹çš„å°±æ˜¯è°ƒç”¨è¿™ä¸ªå‡½æ•°ï¼Œè·å–æˆ‘ä»¬çš„æ–°æ¨¡å‹è¾“å‡ºï¼Œå¹¶é™„å¸¦ä¸ç¡®å®šæ€§ä¼°è®¡ï¼š
- en: '[PRE25]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Last-layer MC dropout is by far one of the easiest ways to obtain uncertainty
    estimates from pre-trained networks. Unlike standard MC dropout, it doesnâ€™t require
    training a model from scratch, so you can apply this post-hoc to networks youâ€™ve
    already trained. Additionally, unlike the other last-layer methods, it can be
    implemented in just a few straightforward steps that never stray from TensorFlowâ€™s
    standard API.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸€å±‚MC dropoutè¿„ä»Šä¸ºæ­¢æ˜¯ä»é¢„è®­ç»ƒç½‘ç»œä¸­è·å¾—ä¸ç¡®å®šæ€§ä¼°è®¡çš„æœ€ç®€å•æ–¹æ³•ã€‚ä¸æ ‡å‡†çš„MC dropoutä¸åŒï¼Œå®ƒä¸éœ€è¦ä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œå› æ­¤ä½ å¯ä»¥å°†å…¶åº”ç”¨äºä½ å·²ç»è®­ç»ƒå¥½çš„ç½‘ç»œã€‚æ­¤å¤–ï¼Œä¸å…¶ä»–æœ€åä¸€å±‚æ–¹æ³•ä¸åŒï¼Œå®ƒåªéœ€è¦å‡ ä¸ªç®€å•çš„æ­¥éª¤å³å¯å®ç°ï¼Œå¹¶ä¸”å§‹ç»ˆéµå¾ªTensorFlowçš„æ ‡å‡†APIã€‚
- en: 6.4.3 Recap of last-layer methods
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4.3 æœ€åä¸€å±‚æ–¹æ³•å›é¡¾
- en: Last-layer methods are an excellent tool for when you need to obtain uncertainty
    estimates from a pre-trained network. Given how expensive and time-consuming neural
    network training can be, itâ€™s nice not to have to start from scratch just because
    you need some predictive uncertainties. Additionally, given that more and more
    machine learning practitioners are relying on state-of-the-art pre-trained models,
    these kinds of techniques are a practical way to incorporate model uncertainties
    after the fact.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸€å±‚æ–¹æ³•æ˜¯å½“ä½ éœ€è¦ä»é¢„è®­ç»ƒç½‘ç»œä¸­è·å–ä¸ç¡®å®šæ€§ä¼°è®¡æ—¶çš„ä¸€ä¸ªæå¥½çš„å·¥å…·ã€‚è€ƒè™‘åˆ°ç¥ç»ç½‘ç»œè®­ç»ƒçš„é«˜æ˜‚æˆæœ¬å’Œè€—æ—¶ï¼Œèƒ½å¤Ÿåœ¨ä¸ä»å¤´å¼€å§‹çš„æƒ…å†µä¸‹ä»…å› ä¸ºéœ€è¦é¢„æµ‹ä¸ç¡®å®šæ€§è€Œé¿å…é‡æ–°è®­ç»ƒï¼Œå®åœ¨æ˜¯éå¸¸ä¾¿åˆ©ã€‚æ­¤å¤–ï¼Œéšç€è¶Šæ¥è¶Šå¤šçš„æœºå™¨å­¦ä¹ ä»ä¸šè€…ä¾èµ–äºæœ€å…ˆè¿›çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™äº›æŠ€æœ¯åœ¨äº‹åç»“åˆæ¨¡å‹ä¸ç¡®å®šæ€§æ˜¯ä¸€ä¸ªéå¸¸å®ç”¨çš„æ–¹æ³•ã€‚
- en: 'But there are drawbacks to last-layer methods too. Unlike other methods, weâ€™re
    relying on a fairly limited source of variance: the penultimate layer of our model.
    This limits how much stochasticity we can induce over our model outputs, meaning
    weâ€™re at risk of over-confident predictions. Bear this in mind when using last-layer
    methods and, if you see the hallmark signs of over-confidence, consider using
    a more comprehensive method to obtain your predictive uncertainties.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯ï¼Œæœ€åä¸€å±‚æ–¹æ³•ä¹Ÿæœ‰å…¶ç¼ºç‚¹ã€‚ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬ä¾èµ–çš„æ˜¯ä¸€ä¸ªç›¸å¯¹æœ‰é™çš„æ–¹å·®æ¥æºï¼šæˆ‘ä»¬æ¨¡å‹çš„å€’æ•°ç¬¬äºŒå±‚ã€‚è¿™é™åˆ¶äº†æˆ‘ä»¬èƒ½å¤Ÿåœ¨æ¨¡å‹è¾“å‡ºä¸Šå¼•å…¥çš„éšæœºæ€§ï¼Œå› æ­¤æˆ‘ä»¬æœ‰å¯èƒ½ä¼šé¢ä¸´è¿‡äºè‡ªä¿¡çš„é¢„æµ‹ã€‚åœ¨ä½¿ç”¨æœ€åä¸€å±‚æ–¹æ³•æ—¶è¯·è®°ä½è¿™ä¸€ç‚¹ï¼Œå¦‚æœä½ çœ‹åˆ°è¿‡åº¦è‡ªä¿¡çš„å…¸å‹è¿¹è±¡ï¼Œè€ƒè™‘ä½¿ç”¨æ›´å…¨é¢çš„æ–¹æ³•æ¥è·å–é¢„æµ‹çš„ä¸ç¡®å®šæ€§ã€‚
- en: 6.5 Summary
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.5 å°ç»“
- en: 'In this chapter, weâ€™ve seen how familiar machine learning and deep learning
    concepts can be used to develop models with predictive uncertainties. Weâ€™ve also
    seen how, with relatively minor modifications, we can add uncertain estimates
    to pre-trained models. This means we can go beyond the point-estimate approach
    of standard NNs: using uncertainties to gain valuable insights into the performance
    of our models, and allowing us to develop more robust applications.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨è¿™ä¸€ç« ä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†å¦‚ä½•åˆ©ç”¨ç†Ÿæ‚‰çš„æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ¦‚å¿µå¼€å‘å¸¦æœ‰é¢„æµ‹ä¸ç¡®å®šæ€§çš„æ¨¡å‹ã€‚æˆ‘ä»¬è¿˜çœ‹åˆ°äº†ï¼Œé€šè¿‡ç›¸å¯¹å°‘é‡çš„ä¿®æ”¹ï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¸ç¡®å®šæ€§ä¼°è®¡æ·»åŠ åˆ°é¢„è®­ç»ƒæ¨¡å‹ä¸­ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥è¶…è¶Šæ ‡å‡†ç¥ç»ç½‘ç»œçš„ç‚¹ä¼°è®¡æ–¹æ³•ï¼šåˆ©ç”¨ä¸ç¡®å®šæ€§è·å¾—å…³äºæ¨¡å‹æ€§èƒ½çš„å®è´µè§è§£ï¼Œä»è€Œä½¿æˆ‘ä»¬èƒ½å¤Ÿå¼€å‘æ›´ç¨³å¥çš„åº”ç”¨ã€‚
- en: However, as with the methods introduced in [*ChapterÂ 5*](CH5.xhtml#x1-600005),
    [*Principled Approaches* *for Bayesian Deep Learning*](CH5.xhtml#x1-600005), all
    techniques have advantages and disadvantages. For example, last-layer methods
    may give us the flexibility to add uncertainties to any model, but theyâ€™re limited
    by the representation that the model has already learned. This could result in
    very low variance outputs, resulting in an overconfident model. Similarly, while
    ensemble methods allow us to capture variance across every layer of the network,
    they come at significant computational cost, requiring that we have multiple networks,
    rather than just a single network.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶è€Œï¼Œå°±åƒ[*ç¬¬äº”ç« *](CH5.xhtml#x1-600005)ï¼Œ[*è´å¶æ–¯æ·±åº¦å­¦ä¹ çš„åŸåˆ™æ–¹æ³•*](CH5.xhtml#x1-600005)ä¸­ä»‹ç»çš„æ–¹æ³•ä¸€æ ·ï¼Œæ‰€æœ‰æŠ€æœ¯éƒ½æœ‰å…¶ä¼˜ç‚¹å’Œç¼ºç‚¹ã€‚ä¾‹å¦‚ï¼Œæœ€åä¸€å±‚æ–¹æ³•å¯èƒ½ä½¿æˆ‘ä»¬èƒ½å¤Ÿå‘ä»»ä½•æ¨¡å‹æ·»åŠ ä¸ç¡®å®šæ€§ï¼Œä½†å®ƒä»¬å—åˆ°æ¨¡å‹å·²ç»å­¦ä¹ åˆ°çš„è¡¨ç¤ºçš„é™åˆ¶ã€‚è¿™å¯èƒ½å¯¼è‡´è¾“å‡ºçš„æ–¹å·®éå¸¸ä½ï¼Œä»è€Œäº§ç”Ÿè¿‡äºè‡ªä¿¡çš„æ¨¡å‹ã€‚åŒæ ·ï¼Œé›†æˆæ–¹æ³•è™½ç„¶å…è®¸æˆ‘ä»¬æ•è·ç½‘ç»œæ¯ä¸€å±‚çš„æ–¹å·®ï¼Œä½†å®ƒä»¬éœ€è¦æ˜¾è‘—çš„è®¡ç®—æˆæœ¬ï¼Œéœ€è¦æˆ‘ä»¬æœ‰å¤šä¸ªç½‘ç»œï¼Œè€Œä¸ä»…ä»…æ˜¯å•ä¸ªç½‘ç»œã€‚
- en: In the next chapter, we will examine the advantages and disadvantages in more
    detail, and learn how we can address some of the shortcomings of these methods.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ›´è¯¦ç»†åœ°æ¢è®¨ä¼˜ç¼ºç‚¹ï¼Œå¹¶å­¦ä¹ å¦‚ä½•è§£å†³è¿™äº›æ–¹æ³•çš„ä¸€äº›ç¼ºç‚¹ã€‚
