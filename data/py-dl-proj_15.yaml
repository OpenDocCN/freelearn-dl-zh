- en: Summary and Next Steps in Your Deep Learning Career
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习职业生涯总结与下一步
- en: This has been a fantastic journey and you've been quite productive as a member
    of the team! We hope that you've enjoyed our practical approach to teaching *Python
    Deep Learning Projects*. Furthermore, it was our intention to provide you with
    thought-provoking and exciting experiences that will further your intuition and
    form the technical foundation for your career in deep learning engineering.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一次精彩的旅程，作为团队的一员，你非常高效！我们希望你喜欢我们实践性的*Python深度学习项目*教学方法。此外，我们的目标是为你提供激发思考、令人兴奋的体验，进一步增强你的直觉，并为你的深度学习工程师职业生涯奠定技术基础。
- en: 'Each chapter was structured similarly to participating as a member of our Intelligence
    Factory team, where, by going through the material, we achieved the following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 每一章的结构都类似于作为我们智能工厂团队的一员，随着学习材料的推进，我们达成了以下目标：
- en: Saw the big picture of the real-world use case and identified the success criteria
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 看到了实际应用场景的大局，并确定了成功的标准
- en: Got focused and into the code, loaded dependencies and data, and built, trained,
    and evaluated our models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集中精力进入代码，加载依赖项和数据，构建、训练并评估我们的模型
- en: Expanded back out to the big picture to confirm that we achieved our goal
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回到大局观，确认我们已达成目标
- en: We love solving problems and building smart solutions, insights, and people!
    Let's review some key learning, summarize some of our intuition, and look at what
    could be next in your deep learning career.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们热衷于解决问题，构建智能的解决方案、洞察力和人才！让我们回顾一下关键学习，总结一些直觉，并展望你深度学习职业生涯的下一个阶段。
- en: Python deep learning – building the foundation – two projects
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 深度学习 – 构建基础 – 两个项目
- en: The foundation of a common working environment enables us to work together,
    and empowers our learning of cool and powerful deep learning technologies in the
    fields of **computer vision** (**CV**) and **natural language processing** (**NLP**).
    The first two chapters in this book provide the establishing experience that you
    will use time and again in your professional career as a data scientist.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一个共同的工作环境基础使我们能够合作，并促使我们在**计算机视觉**（**CV**）和**自然语言处理**（**NLP**）领域学习酷炫且强大的深度学习技术。本书的前两章提供了建立经验，你将多次在数据科学家的职业生涯中使用这些经验。
- en: Chapter 1 – Building the Deep Learning Environment
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 – 构建深度学习环境
- en: The main goal in this chapter was to standardize the toolset for our work together
    to achieve consistently accurate results. We want to establish a process for building
    applications using deep learning algorithms that can scale for production. Towards
    the end, we identified the components of our common deep learning environment,
    and initially set up a local deep learning environment, which expanded to a cloud-based
    environment. Throughout the projects that followed, you gained experience with
    Ubuntu, Anaconda, Python, TensorFlow, Keras, and **Google Cloud Platform** (**GCP**),
    to highlight but a few core technologies. These will continue to be of value to
    you in your deep learning engineering career!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主要目标是标准化我们的工具集，以便共同工作并取得一致准确的结果。我们希望建立一种使用深度学习算法构建可扩展生产应用的流程。在最后，我们识别了共同深度学习环境的组成部分，并最初设置了一个本地深度学习环境，随后扩展到基于云的环境。在随后的项目中，你获得了使用Ubuntu、Anaconda、Python、TensorFlow、Keras和**Google
    Cloud Platform**（**GCP**）等核心技术的经验。这些将继续对你在深度学习工程师的职业生涯中产生价值！
- en: Chapter 2 – Training NN for Prediction Using Regression
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章 – 使用回归训练神经网络进行预测
- en: 'In [Chapter 2](027b6171-1cf7-4589-b9a2-e417dbe53d8b.xhtml), *Training NN for
    Prediction Using Regression*, we identified our first business use case—one that
    would become a theme for a number of projects: that of a restaurant chain seeking
    to automate some of its processes. Specifically, in this chapter, the business
    use case was to build a deep learning classifier using a **multi-layer perceptron**
    (**MLP**), the basic building block in deep learning, to accurately classify handwritten
    digits of a customer''s phone number. If you recall, the goal was to accurately
    classify (digitize) the handwritten phone number on an iPad so that the patron
    could receive a text that their table was ready.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](027b6171-1cf7-4589-b9a2-e417dbe53d8b.xhtml)《*使用回归训练神经网络进行预测*》中，我们确定了第一个商业用例——这将成为多个项目的主题：即一个餐饮连锁希望自动化其部分流程。具体来说，在本章中，商业用例是构建一个使用**多层感知器**（**MLP**）的深度学习分类器，MLP是深度学习中的基本构建块，用来准确分类顾客电话号码的手写数字。如果你还记得，目标是准确地分类（数字化）iPad上的手写电话号码，以便顾客能够收到一条短信，告知他们桌位已准备好。
- en: We built a two-layer (minimally deep) neural network in TensorFlow and trained
    it on the classic MNIST dataset. This project provided us the opportunity to address
    overfitting, underfitting, hyperparameter tuning, and activation functions in
    our exploration of the model's performance. What we found particularly interesting
    was the impact of the business use case on interpreting the utility of the model's
    performance. Our accuracy with this simple model initially seemed adequate, until
    we thought about what a single digit error in a phone number would mean to the
    accurate delivery of a text to the right patron. In this context, we quickly understood
    we would need to do much better. Fortunately, we had an opportunity later in the
    book to take a second run at the problem, and in [Chapter 8](acee9abb-ee8f-4b59-8e5e-44ed24ad05c2.xhtml), *Handwritten
    Digits Classification Using ConvNets*, we employed a more complex deep learning model
    that performed much better!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在TensorFlow中构建了一个两层（最小深度）神经网络，并在经典的MNIST数据集上进行训练。这个项目为我们提供了一个机会，去解决过拟合、欠拟合、超参数调优以及激活函数等问题，以便探索模型的表现。我们发现尤其有趣的是商业用例对模型表现的实用性解读的影响。最初，使用这个简单的模型，我们的准确率看起来足够了，直到我们考虑到电话号码中的一个数字错误对准确传送短信给正确顾客的影响。在这个背景下，我们很快明白，我们需要做得更好。幸运的是，在书的后面，我们有机会再次尝试这个问题，在[第8章](acee9abb-ee8f-4b59-8e5e-44ed24ad05c2.xhtml)《*使用卷积神经网络进行手写数字分类*》中，我们使用了一个更复杂的深度学习模型，效果更好！
- en: Python deep learning – NLP – 5 projects
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python深度学习 – 自然语言处理 – 5个项目
- en: A third of our *Python Deep Learning Projects* are in the field of computational
    linguistics. Unstructured text data is everywhere, and is being generated at an
    astonishing rate. We split up the approaches and technologies employed into five
    parts, to adequately handle the breadth of information. Let's review how the projects
    in [Chapters 3](4dcd4b65-934b-4a8a-a252-9af7513a4787.xhtml), *Word Representation
    Using word2vec*, through [Chapter 8](acee9abb-ee8f-4b59-8e5e-44ed24ad05c2.xhtml), *Handwritten
    Digits Classification Using ConvNets*, relate and build on one another.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的*Python深度学习项目*中，有三分之一集中在计算语言学领域。非结构化文本数据无处不在，而且生成的速度惊人。我们将所使用的技术和方法分为五个部分，以充分应对信息的广度。让我们回顾一下[第3章](4dcd4b65-934b-4a8a-a252-9af7513a4787.xhtml)《*使用word2vec进行单词表示*》到[第8章](acee9abb-ee8f-4b59-8e5e-44ed24ad05c2.xhtml)《*使用卷积神经网络进行手写数字分类*》中的项目，看看它们是如何相互关联并逐步构建的。
- en: Chapter 3 – Word Representations Using word2vec
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章 – 使用word2vec进行单词表示
- en: Core to computational linguistics is an effective representation of words and
    the features they embody. word2vec was used to transform the words into dense
    vectors (that is, tensors), creating embedding representations for the corpus.
    We then created a **convolutional neural network** (**CNN**) to build a language
    model for sentiment analysis. To help us frame this task we envisioned the hypothetical
    use case of our restaurant chain client asking us to make sense of the response
    texts that they were receiving from their patrons getting the notification that
    their table was ready. Particularly interesting was the realization that CNNs
    can be applied to more than just image data! We also took this project as an opportunity
    to explore data visualization with **t-distributed stochastic neighbor embedding**
    (**t-SNE**) and TensorBoard.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 计算语言学的核心是对词语及其所体现特征的有效表示。word2vec 被用来将词语转化为密集向量（即张量），为语料库创建嵌入表示。我们接着创建了一个**卷积神经网络**（**CNN**）来构建情感分析的语言模型。为了帮助我们框定这个任务，我们设想了一个假设的使用案例：我们的餐厅连锁客户要求我们分析他们收到的顾客反馈文本，这些文本是顾客收到他们的桌位准备好通知时的回复。特别有趣的是意识到，CNN
    不仅可以应用于图像数据！我们还利用这个项目作为探索数据可视化的机会，使用了**t-分布随机邻居嵌入**（**t-SNE**）和 TensorBoard。
- en: Chapter 4 – Build an NLP Pipeline for Building Chatbots
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章 – 构建自然语言处理管道用于构建聊天机器人
- en: We dive deeper into computational linguistics in this project by exploring the
    deep learning techniques (building blocks) for language models. word2vec models
    like ours in [Chapter 3](https://cdp.packtpub.com/python_deep_learning_projects/wp-admin/post.php?post=39&action=edit#post_26), *Word
    Representation Using word2vec*, are made possible by NLP pipelines. Our task was
    to create a natural language pipeline that would power a chatbot for open-domain
    question-answering. We pictured our (hypothetical) restaurant chain as having
    a website with their menu, history, location, hours, and other information, and
    that they would like the added ability for a website visitor to ask a question
    in a query box, and for our deep-learning NLP chatbot to find the relevant information
    and present that back.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们通过探索语言模型的深度学习技术（构建块）深入研究了计算语言学。像我们在[第3章](https://cdp.packtpub.com/python_deep_learning_projects/wp-admin/post.php?post=39&action=edit#post_26)中提到的word2vec模型，*使用word2vec的词表示*，是通过自然语言处理（NLP）管道实现的。我们的任务是创建一个自然语言处理管道，为开放域问答的聊天机器人提供支持。我们设想我们的（假设的）餐厅连锁有一个网站，包含菜单、历史、位置、营业时间和其他信息，并且他们希望在网站上增加一个查询框，访客可以提出问题，我们的深度学习NLP聊天机器人能够找到相关信息并返回答案。
- en: The NLP pipeline tokenized the corpus, tagged parts of speech, determined the
    relationship between words with dependency parsing, and conducted **named entity
    recognition** (**NER**). This prepared us to use TF-IDF to vectorize the features
    in the document to create a simple FAQ-type chatbot. We enhanced this with NER
    and the implementation of Rasa NLU. We were then able to build a bot that understood
    the context (intent) of a piece of text, and could also extract the entities,
    because we created an NLP pipeline that could perform intent classification, along
    with NER extraction, to allow it to provide an accurate response.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理管道对语料库进行了分词，标注了词性，使用依存句法分析确定了词与词之间的关系，并进行了**命名实体识别**（**NER**）。这使我们能够使用TF-IDF对文档中的特征进行向量化，从而创建一个简单的FAQ类型聊天机器人。我们通过NER和Rasa
    NLU的实现进一步增强了这一点。随后，我们能够构建一个能够理解文本意图（上下文）的机器人，并且还能够提取实体，因为我们创建了一个可以进行意图分类以及NER提取的NLP管道，使得它能够提供准确的回复。
- en: Chapter 5 – Sequence-to-Sequence Models for Building Chatbots
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章 – 序列到序列模型构建聊天机器人
- en: This chapter builds directly on [Chapter 4](c6f638a5-96bf-4488-9e14-4fbc9b969a42.xhtml), *Build
    NLP Pipeline for Building Chatbots* to build a more advanced chatbot for our hypothetical
    restaurant chain to automate the process of fielding call in orders. We combined
    our learning on a number of technologies to make a chatbot that is more contextually
    aware and robust. We avoided some of the limitations of CNNs in chatbots by building
    a **recurrent neural network** (**RNN**) model with **long short-term memory**
    (**LSTM**) units, specifically designed to capture the signal represented in sequences
    of characters or words.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本章直接在[第四章](c6f638a5-96bf-4488-9e14-4fbc9b969a42.xhtml)，*为建立聊天机器人构建NLP管道*的基础上，为我们假设的餐厅连锁店构建了一个更先进的聊天机器人，以自动化电话点餐的过程。我们结合了多种技术的学习，制作了一个更具上下文意识和鲁棒性的聊天机器人。通过构建具有**循环神经网络**（**RNN**）模型和**长短期记忆**（**LSTM**）单元的模型，专门设计用于捕捉字符或单词序列中表示的信号，避免了聊天机器人中CNN的一些限制。
- en: We implemented a language model, with an encoder-decoder RNN based on the LSTM
    unit, for a simple sequence-to-sequence question-answer task. This model was able
    to handle inputs and outputs of different sizes, preserve the state of information,
    and adequately handle complex context. An additional learning of ours was that
    of the importance of obtaining a sufficient amount of the right training data
    as the outputs of the model are put up against a very high standard for speech
    interpretability. However, with the right training data, it would be possible
    to use this model to achieve the hypothetical restaurant chain's goal of building
    a robust chatbot (in combination with other computational linguistic technologies
    we've explored) that could automate the over-the-phone process of ordering food.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们实现了一个语言模型，使用基于LSTM单元的编码器-解码器RNN，用于简单的序列到序列问答任务。这个模型能够处理不同大小的输入和输出，保持信息状态，并足够处理复杂的上下文。我们的另一个学习是，获得足够数量和正确训练数据的重要性，因为模型的输出要符合非常高的语音可解释性标准。然而，通过正确的训练数据，可以使用这个模型实现假设的餐厅连锁店建立强大聊天机器人的目标（结合我们探索过的其他计算语言学技术）。
- en: Chapter 6 – Generative Language Model for Content Creation
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第六章 – 生成语言模型用于内容创作
- en: 'In this project, we not only take the next step in our computational linguistics
    journey; we take a profound leap to generate new content! We defined the business
    use case goal of providing a deep learning solution that generates new content
    that can be used in movie scripts, song lyrics, and music. We asked ourselves:
    how can we leverage our experience in solving problems for restaurant chains and
    apply it to different industries? Upon reflection on what we learned in past projects
    regarding the inputs and outputs of the models, we gained confidence that novel
    content was just another type of output. We demonstrated that we could take an
    image as input, and output a class label ([Chapter 2](027b6171-1cf7-4589-b9a2-e417dbe53d8b.xhtml), *Training
    NN for Prediction Using Regression*). We trained a model to take inputs of text
    and output sentiment classifications ([Chapter 3](4dcd4b65-934b-4a8a-a252-9af7513a4787.xhtml), *Word
    Representation Using word2vec*), and we built a NLP pipeline for an open-domain
    question-answering chatbot, where we took text as input, and identified text in
    a corpus to present the appropriate output ([Chapter 4](c6f638a5-96bf-4488-9e14-4fbc9b969a42.xhtml), *Build
    NLP Pipeline for Building Chatbots*). We then expanded that chatbot functionality
    to be able to serve a restaurant with an automated ordering system ([Chapter 5](856ccfef-cfe1-462f-9998-73f2b5168ae7.xhtml), *Sequence-to-Sequence
    Models for Building Chatbots*).'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们不仅在计算语言学的旅程中迈出了下一步，还跨越了一个深刻的鸿沟来生成新内容！我们定义了业务使用案例目标，提供一种深度学习解决方案，用于生成可以用于电影剧本、歌词和音乐的新内容。我们问自己：我们如何利用我们在解决餐厅连锁店问题方面的经验，并将其应用于不同的行业？反思过去项目中关于模型输入和输出的学习，我们相信新颖的内容只是另一种输出形式。我们证明了我们可以将图像作为输入，并输出一个类别标签（[第二章](027b6171-1cf7-4589-b9a2-e417dbe53d8b.xhtml)，*使用回归进行预测的NN训练*）。我们训练了一个模型，接受文本输入并输出情感分类（[第三章](4dcd4b65-934b-4a8a-a252-9af7513a4787.xhtml)，*使用word2vec进行词表示*），并为开放域问答聊天机器人建立了一个NLP管道，其中我们将文本作为输入，并在语料库中识别文本以呈现适当的输出（[第四章](c6f638a5-96bf-4488-9e14-4fbc9b969a42.xhtml)，*为建立聊天机器人构建NLP管道*）。然后，我们扩展了该聊天机器人功能，以便为餐厅提供自动点餐系统服务（[第五章](856ccfef-cfe1-462f-9998-73f2b5168ae7.xhtml)，*用于构建聊天机器人的序列到序列模型*）。
- en: In this chapter, we implemented a generative model to generate content using
    the **long short-term memory** (**LSTM**), variational autoencoders, and **g****enerative
    adversarial networks** (**GANs**). We effectively implemented models, for both
    text and music, that can generate song lyrics, scripts, and music for artists
    and various creative businesses.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们实现了一个生成模型，使用**长短期记忆网络**（**LSTM**）、变分自编码器和**生成对抗网络**（**GANs**）来生成内容。我们成功地为文本和音乐领域实现了模型，这些模型能够为艺术家和各种创意行业生成歌曲歌词、剧本和音乐。
- en: Chapter 7 – Building Speech Recognition with DeepSpeech2
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第七章 – 构建基于DeepSpeech2的语音识别系统
- en: This project on building speech recognition with DeepSpeech2 is the capstone
    in the *Natural Language Processing* section of the *Python Deep Learning Projects*
    book. So far, we've explored chatbots, natural language processing, and speech
    recognition with RNNs (both uni- and bi-directional, with and without LSTM components)
    and CNNs. We've seen the power of these technologies to provide intelligence to
    existing business processes, as well as to create entirely new and smart systems.
    This is exciting work at the cutting edge of applied AI using deep learning!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目是《*Python深度学习项目*》一书中*自然语言处理*章节的一个集大成项目，旨在构建基于DeepSpeech2的语音识别系统。到目前为止，我们已经探讨了聊天机器人、自然语言处理和使用RNN（包括单向和双向、含有和不含LSTM组件的RNN）以及CNN的语音识别技术。我们见识了这些技术为现有商业流程提供智能支持的强大能力，并且能够创造出全新的智能系统。这是应用AI最前沿的令人兴奋的工作，运用了深度学习技术！
- en: The goal of this project was to build and train an **automatic speech recognition** (**ASR**)
    system to take in and convert an audio call to text, which could then be used
    as the input for a text-based chatbot that was capable of parsing the input and
    responding appropriately. We made a deep dive into speech data, performing feature
    engineering to allow us to extract various kinds of features from the data, to
    then build a speech recognition system which can detect a users voice. In the
    end, we demonstrated mastery by building a system, using the DeepSpeech2 model,
    that recognizes English speech. We worked with speech and spectograms to build an end-to-end
    speech recognition system using the **c****onnectionist temporal classification**
    (**CTC**) loss function, batch normalization, and SortaGrad for the RNNs.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目的目标是构建并训练一个**自动语音识别**（**ASR**）系统，能够接收并将语音通话转换为文本，然后可以作为文本聊天机器人的输入，后者能够解析这些输入并做出适当回应。我们深入研究了语音数据，进行特征工程，以便从数据中提取各种特征，并构建一个能够识别用户语音的语音识别系统。最终，我们通过构建一个基于DeepSpeech2模型的系统，展示了我们对英语语音识别的掌握。我们结合语音和频谱图，使用**连接时序分类**（**CTC**）损失函数、批量归一化（Batch
    Normalization）和SortaGrad优化方法，搭建了一个端到端的语音识别系统，基于RNN技术。
- en: Deep learning – computer vision – 6 projects
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习 – 计算机视觉 – 6个项目
- en: The following six Python deep learning projects, focusing on CV, represent the
    largest portion of the content of this book. We've already seen how some of the
    deep learning technologies we explore in detail, with reference to CV, have some
    applicability to other types of data, and in particular, to text-based data. In
    no small part, that is because of the enormous utility of CNNs in feature extraction
    and hierarchical representation. There is no magic tool that is perfect for all
    jobs—being a deep learning engineer in data science is no exception. But you should
    not underestimate the familiarity you'll get with CNNs, as you'll find yourself
    using them time and again, across many different datasets and business use cases.
    Being a data scientist without CNN skills is like being a carpenter without a
    hammer. The obvious caveat is that not everything in data science is the equivalent
    of a nail!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下六个Python深度学习项目，专注于计算机视觉（CV），是本书内容的主要部分。我们已经看到，部分深度学习技术，尤其是与计算机视觉相关的技术，如何能够应用于其他类型的数据，尤其是文本数据。很大程度上，这是因为CNN在特征提取和层次化表示上的巨大效用。没有哪种工具可以适用于所有工作——成为数据科学领域的深度学习工程师也不例外。但你不应低估你对CNN的熟悉程度，因为你会在许多不同的数据集和商业用例中反复使用它们。没有CNN技能的数据科学家，就像没有锤子的木匠。显然的警告是，并非数据科学中的所有任务都可以简单地比作钉子！
- en: Chapter 8 – Handwritten Digit Classification Using ConvNets
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第八章 – 使用卷积神经网络（ConvNets）进行手写数字分类
- en: This chapter reminds us of the first deep neural net we created in [Chapter
    2](027b6171-1cf7-4589-b9a2-e417dbe53d8b.xhtml), *Training NN for Prediction Using
    Regression*, and the business use case to which it was applied. The purpose of
    that chapter was to provide a foundation for our understanding of deep neural
    networks and how they operate. The complexity of the math underlying deep learning
    was highlighted when we compared the model architecture with the more advanced
    techniques afforded when we build deeper and more robust models. Complexity isn't
    cool just because it's complex; in this case, it's cool because of the improvement
    in realized performance utility that it provides.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提醒我们回顾在[第2章](027b6171-1cf7-4589-b9a2-e417dbe53d8b.xhtml)《使用回归训练神经网络进行预测》中创建的第一个深度神经网络，以及它所应用的商业用例。本章的目的是为我们理解深度神经网络及其运行原理提供基础。在比较模型架构与更先进的技术时，我们强调了深度学习背后的数学复杂性，尤其是在我们构建更深、更强大的模型时所能获得的进步。复杂性并不是因为它复杂而“酷”；在这个情况下，它之所以“酷”是因为它带来了实际性能的提升。
- en: We spent a considerable amount of time examining the convolution operation,
    pooling, and dropout regularization. These are the levers you'll adjust in tuning
    your models in your career, so getting a solid understanding of them early is
    essential. In reference to the business use case, we see the value of deploying
    a more complex model, in that the performance gain supports the parent product
    implementation. The error rate obtained in [Chapter 2](https://cdp.packtpub.com/python_deep_learning_projects/wp-admin/post.php?post=39&action=edit#post_25), *Training
    NN for Prediction Using Regression*, was such that, in the worse case, not a single
    text would have been appropriately delivered to the right patron at the hypothetical
    restaurant chain (and in the best case, it was still dismal and effectively not
    functional). The CNN model on the same dataset produces results that mean that,
    in the new worst-case scenario, 90% of the patrons would receive the text notifications,
    and in the best case, 99% would get the text!
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们花了大量时间研究卷积操作、池化和Dropout正则化。这些是你在职业生涯中调节模型时所需要调整的杠杆，所以尽早理解它们非常重要。回到商业用例，我们看到部署更复杂模型的价值，因为性能提升支持了母产品的实施。在[第2章](https://cdp.packtpub.com/python_deep_learning_projects/wp-admin/post.php?post=39&action=edit#post_25)《使用回归训练神经网络进行预测》中获得的误差率，在最坏情况下，假设餐饮连锁店中的每个顾客都没有收到正确的文本信息（即使在最好情况下，效果依然很差，基本上无法使用）。而相同数据集上的CNN模型则产生了这样的结果：在新的最坏情况下，90%的顾客会收到文本通知，在最好情况下，99%的人会收到通知！
- en: Chapter 9 – Object Detection Using OpenCV and TensorFlow
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章 – 使用OpenCV和TensorFlow进行物体检测
- en: Let's think about what we accomplished in [Chapter 8](acee9abb-ee8f-4b59-8e5e-44ed24ad05c2.xhtml), *Handwritten
    Digits Classification Using ConvNets*, where we were able to train an image classifier,
    with a CNN, to accurately classify handwritten digits in an image. The data was
    less complicated than it could have been, because each image only had one handwritten
    digit in it, and our goal was to accurately assign a class label to the image.
    What would have happened if each image had multiple handwritten digits in it,
    or different types of objects? What if we had a video? What if we want to identify
    *where* the digits are in the image? These questions represent the challenges
    that real-world data embodies, and drives our data science innovation toward new
    models and capabilities.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下在[第8章](acee9abb-ee8f-4b59-8e5e-44ed24ad05c2.xhtml)《使用卷积神经网络进行手写数字分类》中所取得的成果，我们成功地训练了一个图像分类器，利用CNN准确地分类了图像中的手写数字。数据的复杂度比实际可能的要低，因为每个图像中只有一个手写数字，而我们的目标是为图像准确分配一个类别标签。如果每个图像中包含多个手写数字，或者不同类型的物体会怎样呢？如果我们有一个视频呢？如果我们想识别图像中数字的位置会怎样？这些问题代表了现实世界数据所面临的挑战，并推动我们的数据科学创新朝着新的模型和能力发展。
- en: Object detection and classification is no trivial task for a computer, particularly
    at scale and hitting speed requirements. We employed data inputs in this project
    that were much more informationally complex than what we've had in previous projects,
    and the outcomes, when we got them right, were that much more impressive. We found
    that the deep learning package YOLOv2 performed very well, and saw our model architecture
    get deeper and more complex with good results.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对计算机而言，目标检测和分类绝非一件简单的事情，尤其是在大规模和高速度要求下。在这个项目中，我们采用了比以往项目中更加信息复杂的数据输入，当我们成功处理这些数据时，结果也更加令人印象深刻。我们发现，深度学习包YOLOv2表现得非常出色，并且看到了我们的模型架构变得更加深度和复杂，同时也取得了不错的效果。
- en: Chapter 10 – Building Facial Recognition Using OpenFace
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章 – 使用OpenFace构建人脸识别
- en: 'In [Chapter 9](d3a16c16-a745-4cd4-ae4b-4afcec887ada.xhtml), *Object Detection
    Using OpenCV and TensorFlow*, we demonstrated mastery in the skills needed to
    build a deep learning object detection and classification model. Building on that,
    we set our objective at a refinement of that classification operation: is the
    object identical to another? In our case, we were looking to build a facial recognition
    system of the kind that we see in spy movies, and now in high tech security systems. Facial
    recognition is a combination of two major operations: face detection, followed
    by face classification.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第9章](d3a16c16-a745-4cd4-ae4b-4afcec887ada.xhtml)，*使用OpenCV和TensorFlow进行目标检测*中，我们展示了构建深度学习目标检测和分类模型所需技能的掌握。在此基础上，我们的目标是对这一分类操作进行进一步细化：物体是否与另一个物体相同？在我们的案例中，我们希望构建一种类似间谍电影中看到的人脸识别系统，现在这种系统已经应用于高科技安防系统中。人脸识别是两项主要操作的结合：人脸检测和人脸分类。
- en: Using OpenFace in this project, we built a model that looked at a picture and
    identified all the possible faces in it, then performed face extraction to understand
    the quality of the part of the image containing faces. We then performed feature
    extraction on the face, identifying parts of the image that gave us the basis
    for comparison with another data point (a labeled image of the person's face). This
    Python deep learning project demonstrates the exciting potential for this technology,
    and the future for the engineers that excel at working on these applications.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们使用OpenFace构建了一个模型，该模型能够查看图片并识别其中的所有可能人脸，然后进行人脸提取，以了解包含人脸的图像部分的质量。接着，我们对人脸进行了特征提取，识别图像中可为与另一数据点（该人脸的标记图像）进行比较的部分。这个Python深度学习项目展示了这项技术的令人兴奋的潜力，也展现了擅长这些应用的工程师们的未来。
- en: Chapter 11 – Automated Image Captioning
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章 – 自动化图像标题生成
- en: In [Chapter 9](d3a16c16-a745-4cd4-ae4b-4afcec887ada.xhtml), *Object Detection
    Using OpenCV and TensorFlow*, we learned how to detect and classify objects in
    an image, and in [Chapter 10](78e388c6-e8f4-49f4-84d6-ab7c20fd6b71.xhtml), *Building
    Face Recognition Using FaceNet*, we learned how to detect, classify, and identify
    objects as being the same thing (for example, identifying the same person from
    two different facial images). In this project, we did something even more complicated
    and cool! We combined the current state-of-the-art techniques that we've learned
    so far in our Python deep learning projects, in both CV andNLP, to form a complete
    image description approach. This model was capable of constructing computer-generated
    natural language descriptions of any image provided.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第9章](d3a16c16-a745-4cd4-ae4b-4afcec887ada.xhtml)，*使用OpenCV和TensorFlow进行目标检测*中，我们学习了如何检测和分类图像中的物体；在[第10章](78e388c6-e8f4-49f4-84d6-ab7c20fd6b71.xhtml)，*使用FaceNet构建人脸识别*中，我们学习了如何检测、分类和识别物体是否为同一事物（例如，识别两张不同人脸图片中的同一人）。在这个项目中，我们做了更为复杂和酷炫的事情！我们结合了到目前为止在Python深度学习项目中学到的最先进技术，在计算机视觉（CV）和自然语言处理（NLP）领域，形成了一种完整的图像描述方法。这个模型能够为提供的任何图像生成计算机生成的自然语言描述。
- en: The clever idea that made this possible was to replace the encoder (the RNN
    layer) in an encoder-decoder architecture with a deep CNN, trained to classify
    objects in images. Normally, the CNN's last layer is the softmax layer, which
    assigns the probability that each object might be in the image. But when we remove
    that softmax layer from the CNN, we can feed the CNN's rich encoding of the image
    into the decoder (the language generation component of the RNN) designed to produce
    phrases. We can then train the whole system directly on images and their captions,
    maximizing the likelihood that the descriptions it produces best match the training
    descriptions for each image. This deep learning technology is the backbone of
    many intelligence factory solutions!
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 使这一切成为可能的巧妙想法是，用一个深度卷积神经网络（CNN）替代了编码器-解码器架构中的编码器（RNN层），并训练它来分类图像中的物体。通常，CNN的最后一层是softmax层，用于为每个物体分配其出现在图像中的概率。但是，当我们去除CNN的softmax层时，我们可以将CNN对图像的丰富编码输入到解码器中（RNN的语言生成组件），该解码器的设计目的是生成短语。然后，我们可以直接在图像及其描述上训练整个系统，最大化它生成的描述与每个图像的训练描述最匹配的可能性。这项深度学习技术是许多智能工厂解决方案的核心！
- en: Chapter 12 – Pose Estimation on 3D Models Using ConvNets
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章 – 使用卷积神经网络（ConvNets）在3D模型上进行姿态估计
- en: Data that we apply to our models are representations of the real world. This
    is the fundamental truth that unites computational linguistics and CV. With respect
    to CV, we need to remember that 2D images represent a 3D world, in the same way
    that video represents 4D, with the added aspects of time and movement. Recalling
    this obvious fact lets us ask ever more interesting questions and develop deep
    learning technologies with increasing utility. Our hypothetical use case was to
    enable visual effects specialists to easily estimate the pose of actors (particularly
    the shoulders, neck, and head) on frames of a video. Our task was to build the
    intelligence for this application.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用于模型的数据是现实世界的表现。这是计算语言学和计算机视觉（CV）之间的基本联系。对于计算机视觉，我们需要记住，二维图像代表的是三维世界，就像视频代表的是四维世界，时间和运动是其中的额外维度。回忆这个显而易见的事实可以让我们提出越来越有趣的问题，并发展出具有更大实用性的深度学习技术。我们假设的应用场景是让视觉特效专家能够轻松估算演员在视频帧中的姿态（特别是肩膀、脖子和头部）。我们的任务是为这个应用程序构建智能系统。
- en: We successfully built a deep CNN/VGG16 model in Keras on **frames labeled in
    cinema** (**FLIC**) images. We got hands-on experience in preparing the images
    for modeling. We successfully implemented transfer learning, and understood that
    doing so will save us a lot of time. We defined some key hyperparameters, as well
    as understanding why we did what we did. Finally, we tested the modified VGG16
    model performance on unseen data, and determined that we succeeded in achieving
    our goals.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们成功地在Keras中构建了一个深度CNN/VGG16模型，使用的是**电影标注帧**（**FLIC**）图像。我们在为建模准备图像时获得了实际操作经验。我们成功实施了迁移学习，并明白了这样做将节省我们大量的时间。我们定义了一些关键的超参数，并理解了为什么我们要这么做。最后，我们在未见过的数据上测试了修改后的VGG16模型的性能，并确定我们成功达成了目标。
- en: Chapter 13 – Image Translation Using GANs for Style Transfer
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第13章 – 使用生成对抗网络（GAN）进行风格迁移的图像翻译
- en: 'GANs are just downright cool. When we look back at the skills and intuition
    we''ve built throughout these projects, we had an interesting idea. Could we predict
    missing information? Or, stated in a different way: can we create data that should
    be in an image, but that''s not there? If we can take text input and generate
    novel text output, and if we can take a 2D image and generate or predict a 3D
    positional output, then it would seem possible that, if we have a 2D image that''s
    missing some information, maybe we ought to be able to generate the missing information?
    So, in this chapter, we built a neural network that fills in the missing part
    of a handwritten digit. We previously built a digit classifier for a hypothetical
    restaurant chain client. Error rates could be attributable to the digits not being
    accurately captured, and the resulting image having incompletely drawn digits. We focused
    our efforts on the new part of the model creation—the generation/reconstruction
    of the missing sections of a digit with the help of neural inpainting with GANs.
    We then reconstructed the missing parts of the handwritten numbers, so that the
    classifier received clear handwritten numbers for conversion into digits. With
    this, the classifier was able to do a much more accurate job of classifying the
    handwritten digits (and our mythical restaurant patrons were able to receive their
    notification texts and get seated promptly).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络（GANs）简直太酷了。当我们回顾在这些项目中积累的技能和直觉时，我们有了一个有趣的想法。我们能否预测缺失的信息？换句话说：我们能否生成图像中应该有的，但实际上缺失的数据？如果我们能够接受文本输入并生成新的文本输出，或者能够接受
    2D 图像并生成或预测 3D 位置输出，那么似乎是可能的：如果我们有一张缺少一些信息的 2D 图像，也许我们应该能够生成缺失的部分？因此，在这一章中，我们构建了一个神经网络，用来填补手写数字的缺失部分。我们之前为一个假设的餐厅连锁客户构建了一个数字分类器。误差率可能与数字未被准确捕捉、导致图像中的数字部分未完全绘制有关。我们将精力集中在模型创建的新增部分——通过使用生成对抗网络（GANs）进行神经修复，重建缺失的数字部分。然后我们重建了手写数字的缺失部分，以便分类器能够接收到清晰的手写数字，从而进行数字转换。通过这一过程，分类器能够更准确地分类手写数字（而我们假设的餐厅顾客也能及时收到通知并迅速入座）。
- en: Python deep learning – autonomous agents – 1 project
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 深度学习 – 自主代理 – 1 项目
- en: The final project in our book is unlike anything we've done so far, and deserves
    its own treatment. Robotic process automation and optimization, and autonomous
    agents, such as drones and vehicles, require our deep learning models to learn
    from environmental cues in a reinforcement learning paradigm. Unlike previous
    projects, where we've been primarily focused on solving supervised learning problems, in
    this chapter, we learned to build and train a deep reinforcement learning model
    capable of playing games.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们书中的最终项目与之前的任何项目都不同，因此值得单独处理。机器人过程自动化与优化，以及自主代理（如无人机和车辆）要求我们的深度学习模型能够在强化学习范式中从环境线索中学习。与之前专注于解决监督学习问题的项目不同，在这一章中，我们学习了如何构建并训练一个能够玩游戏的深度强化学习模型。
- en: We employed a deep Q-learning and deep **state-action-reward-state-action** (**SARSA**)
    learning model. Unlike programming simple models by defining heuristics, deep
    learning models mapping A-B in a supervised learning environment, or determining
    decision boundaries in cluster analysis in unsupervised learning, it is the rules
    of the game or environment (as expressed in the delivery of reinforcement) that
    provide the feedback for training in reinforcement learning. The deep learning
    model, also called the agent in reinforcement-learning terms, interacts with the
    game environment and learns how to play the game, seeking to maximize rewards
    after several attempts at playing.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们采用了深度 Q 学习和深度**状态-动作-奖励-状态-动作**（**SARSA**）学习模型。与通过定义启发式规则编程简单模型、在监督学习环境中映射
    A-B 或在无监督学习中确定聚类分析的决策边界不同，强化学习中的反馈来自于游戏或环境的规则（通过强化传递）。该深度学习模型，也就是强化学习中的代理，与游戏环境进行互动，学习如何玩游戏，并在多次尝试后寻求最大化奖励。
- en: Chapter 14 – Develop an Autonomous Agent with Deep Reinforcement Learning
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第14章 – 使用深度强化学习开发自主代理
- en: In this project, we built a deep reinforcement learning model to successfully
    play the game of CartPole-v1, from OpenAI Gym. Demonstrating mastery here first,
    we could then extend it to other complex games, such as those by Atari.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我们构建了一个深度强化学习模型，成功地玩转了 OpenAI Gym 中的 CartPole-v1 游戏。首先展示我们在此方面的掌握，我们然后可以将其扩展到其他复杂的游戏，如
    Atari 的游戏。
- en: We learned how to interact with the Gym toolkit, Q-learning, and SARSA learning;
    how to code the reinforcement learning model and define hyperparameters; and how
    to build the training loop and test the model. We found that our SARSA model performed
    quite a bit better than the Q-learning model. Further training and tuning of hyperparameters,
    and our own capture of reinforcement units (better scores by our models), should
    shape our behavior to build better models that ultimately result in the nearly
    perfect performance of our agent!
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学会了如何与Gym工具包、Q学习和SARSA学习进行交互；如何编码强化学习模型并定义超参数；以及如何构建训练循环并测试模型。我们发现我们的SARSA模型比Q学习模型表现得要好得多。进一步的训练和超参数调整，以及我们自己捕获的强化单位（我们模型的更高分数），应当塑造我们的行为，构建出更好的模型，最终实现我们的代理几乎完美的表现！
- en: Next steps – AI strategy and platforms
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下一步——AI战略和平台
- en: Throughout this book, you've gained experiences that form the technical foundations
    for professional work in deep learning projects. However, the scope of the book
    was such that our focus could only be on a subset of the entire production-scale
    data science pipeline. We spent our time in the context of a business use case
    to ground our thinking on the domain and success criteria, but quickly dove into
    deep-learning model training, evaluation, and validation. These components, comprising
    the bulk of the training in our projects, are certainly the core of a data science
    pipeline for an enterprise, but cannot function in a vacuum. Additional considerations
    and training in AI strategy and data science platforms are the natural next steps
    in your education and career.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，你获得了构建深度学习项目技术基础的经验。然而，本书的范围使得我们的重点只能集中在整个生产规模数据科学管道的一部分。我们花时间以商业用例为背景，帮助我们在领域和成功标准上进行思考，但很快就深入到了深度学习模型的训练、评估和验证中。这些组成了我们项目中训练的主体，毫无疑问，它们是企业数据科学管道的核心，但不能孤立运作。进一步的AI战略和数据科学平台的学习和训练是你教育和职业发展的自然下一步。
- en: AI strategy
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI战略
- en: 'AI strategy is about gaining knowledge from the client that empowers you to
    determine the following:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: AI战略是通过从客户处获取知识，使你能够确定以下内容：
- en: The client's grand vision for an intelligence-based competitive advantage
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 客户基于智能的竞争优势的宏大愿景
- en: 'How to translate that vision into an effective production-scale data science
    pipeline:'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将这一愿景转化为一个有效的生产规模数据科学管道：
- en: Take into account the current and near-term digital maturity of the client
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑客户当前和近期的数字化成熟度
- en: Processes of data ingestion, analysis, and transformation
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据摄取、分析和转换的过程
- en: Technology and engineering resources and constraints
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 技术和工程资源与约束
- en: The analytics team's current capabilities
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析团队目前的能力
- en: Model selection, customization, training, evaluation, validation, and serving
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型选择、定制、训练、评估、验证和服务
- en: Achievement of KPIs and ROI that meets the objectives of the client's leadership
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 达成与客户领导目标一致的KPI和ROI
- en: AI strategy consulting uncovers goals and expectations, while aligning outcomes
    with machine learning and deep learning technologies. Building an AI solution
    architecture must take all of this into account to be successful. You should look
    to mentors in the industry, read available case studies, and keep this in mind
    as your career advances, and you are called in to provide guidance and opinions
    earlier and earlier in the solution-building process.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: AI战略咨询揭示了目标和期望，同时将结果与机器学习和深度学习技术对齐。构建AI解决方案架构必须考虑到所有这些因素，才能取得成功。你应该向行业导师学习，阅读可用的案例研究，并在你的职业发展过程中时刻牢记这一点，随着你越来越早地被召唤在解决方案构建过程中提供指导和意见。
- en: Deep learning platforms – TensorFlow Extended (TFX)
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习平台——TensorFlow Extended (TFX)
- en: Data science platforms, designed to meet the demands for production-scale deployment,
    require significant engineering support. At the Intelligence Factory and Skejul,
    we've built deep learning platforms that take in live feeds of constantly updating
    data to produce intelligence-based outputs within milliseconds, to be delivered
    via a cloud-based web application using API gateways. It's extraordinarily complex
    and rewarding, once you get all the pieces to come together!
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为满足生产规模部署需求而设计的数据科学平台需要大量的工程支持。在智能工厂和Skejul，我们构建了深度学习平台，能够接收不断更新的实时数据流，在毫秒内生成基于智能的输出，通过基于云的Web应用程序使用API网关交付。这是一个异常复杂且有回报的过程，一旦你把所有环节拼接起来，就能看到其巨大价值！
- en: One technology that will aid in your deep learning and data science career is
    TFX. This is Google's TensorFlow-based production-scale machine learning platform.
    The first few lines from their abstract from the article
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一项能够帮助您在深度学习和数据科学职业生涯中取得成功的技术是TFX。这是Google基于TensorFlow的生产级机器学习平台。以下是它们文章摘要中的前几行
- en: '*TFX: A TensorFlow-Based Production-Scale Machine Learning Platform* ([https://ai.google/research/pubs/pub46484](https://ai.google/research/pubs/pub46484))
    summarize the potential of the TFX and similar platforms:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*TFX: 基于TensorFlow的生产级机器学习平台* ([https://ai.google/research/pubs/pub46484](https://ai.google/research/pubs/pub46484))
    总结了TFX及类似平台的潜力：'
- en: '"Creating and maintaining a platform for reliably producing and deploying machine
    learning models requires careful orchestration of many components—a learner for
    generating models based on training data, modules for analyzing and validating
    both data as well as models, and finally infrastructure for serving models in
    production. This becomes particularly challenging when data changes over time
    and fresh models need to be produced continuously."'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '"创建和维护一个可靠地生成和部署机器学习模型的平台，需要对许多组件进行精心的协调——一个基于训练数据生成模型的学习器，分析和验证数据以及模型的模块，最后是用于在生产环境中服务模型的基础设施。当数据随时间变化并且需要不断生成新的模型时，这变得尤为具有挑战性。"'
- en: Data science platform engineering that's based on a smartly crafted AI strategy
    is our next step in training, and we look forward to the opportunity to share
    those experiences with you too!
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 基于精心策划的AI战略的数据科学平台工程是我们训练的下一步，我们也期待与您分享这些经验！
- en: Conclusion and thank you!
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论与感谢！
- en: We want to thank you for choosing our book, *Python Deep Learning Projects*,
    as part of your data science education! It's our hope that you found the projects
    and the business use cases intriguing and informative, and that you feel more
    professionally prepared than when you started. We look forward to the opportunity
    to engage with you via our respective blogs, on social media, and possibly even
    at conferences or on working together on delivering AI-based solutions to clients
    around the world.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢您选择我们的书籍《*Python深度学习项目*》作为您数据科学教育的一部分！我们希望您觉得这些项目和商业用例既引人入胜又富有信息性，并且比开始时更加专业地准备好了。我们期待有机会通过我们的博客、社交媒体，甚至在会议上与您互动，或者一起为全球客户提供基于AI的解决方案。
- en: We've been happy to have you in our weekly AI team meetings in these projects. Now
    that we've learned a bunch of stuff, and had some fun with really cool and powerful
    data science technologies, let's go out to do great work based on these Python
    deep learning projects!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 很高兴您参与了我们每周的AI团队会议，参与这些项目。现在我们已经学到了很多东西，并且享受了使用非常酷且强大的数据科学技术的乐趣，让我们基于这些Python深度学习项目去做伟大的工作吧！
