- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Abstract Image Classification with Convolutional Neural Networks (CNNs)
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用卷积神经网络（CNN）进行抽象图像分类
- en: The invention of **convolutional neural networks** (**CNNs**) applied to vision
    represents by far one of the most innovative achievements in the history of applied
    mathematics. With their multiple layers (visible and hidden), CNNs have brought
    artificial intelligence from machine learning to deep learning.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）在视觉领域的发明，至今仍是应用数学史上最具创新性的成就之一。凭借其多层（可见层和隐藏层）结构，CNN 将人工智能从机器学习带入了深度学习的领域。
- en: In *Chapter 8*, *Solving the XOR Problem with a Feedforward Neural Network*,
    we saw that *f*(*x*, *w*) is the building block of any neural network. A function
    *f* will transform an input *x* with weights *w* to produce an output. This output
    can be used as such or fed into another layer. In this chapter, we will generalize
    this principle and introduce several layers. At the same time, we will use datasets
    with images. We will have a dataset for training and a dataset for validation
    to confirm that our model works.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第8章*《使用前馈神经网络解决 XOR 问题》中，我们看到 *f*（*x*，*w*）是任何神经网络的构建块。一个函数 *f* 会将输入 *x* 和权重
    *w* 转换为输出。这个输出可以直接使用，或者输入到另一个层中。在本章中，我们将概括这个原理并引入多个层。同时，我们将使用带有图像的数据集。我们将拥有一个训练数据集和一个验证数据集，以确认我们的模型有效。
- en: 'A CNN relies on two basic tools of linear algebra: kernels and functions, applying
    them to convolutions as described in this chapter. These tools have been used
    in mathematics for decades.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）依赖于线性代数的两大基本工具：卷积核和函数，并将它们应用于本章所述的卷积操作。这些工具在数学中已经使用了数十年。
- en: However, it took the incredible imagination of Yann LeCun, Yoshua Bengio, and
    others—who built a mathematical model of several layers—to solve real-life problems
    with CNNs.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，解决现实问题的突破来自于 Yann LeCun、Yoshua Bengio 等人的非凡想象力——他们构建了一个多层的数学模型，才使 CNN 能够应用于实际问题。
- en: This chapter describes the marvels of CNNs, one of the pillars of **artificial
    neural networks** (**ANNs**). A CNN will be built from scratch, trained, and saved.
    The classification model described will detect production failures on a food-processing
    production line. Image detection will go beyond object recognition and produce
    abstract results in the form of concepts.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章描述了卷积神经网络（CNN）的奇妙之处，它是**人工神经网络**（**ANNs**）的支柱之一。我们将从零开始构建、训练并保存一个 CNN。所描述的分类模型将用于检测食品加工生产线上的生产故障。图像检测将超越物体识别，并以概念的形式产生抽象结果。
- en: A Python TensorFlow 2 program will be built layer by layer and trained. Additional
    sample programs will illustrate key functions.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 Python TensorFlow 2 程序将逐层构建并训练。附加示例程序将展示关键功能。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The differences between 1D, 2D, and 3D CNNs
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1D、2D 和 3D CNN 之间的区别
- en: Adding layers to a convolutional neural network
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向卷积神经网络添加层
- en: Kernels and filters
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积核和滤波器
- en: Shaping images
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像处理
- en: The ReLU activation function
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ReLU 激活函数
- en: Kernel initialization
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心初始化
- en: Pooling
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 池化
- en: Flattening
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扁平化
- en: Dense layers
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 全连接层
- en: Compiling the model
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译模型
- en: The cross-entropy loss function
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 交叉熵损失函数
- en: The Adam optimizer
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adam 优化器
- en: Training the model
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练模型
- en: Saving the model
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存模型
- en: Visualizing the PNG of a model
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化模型的 PNG
- en: We'll begin by introducing CNNs and defining what they are.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从介绍 CNN 开始，并定义它们是什么。
- en: Introducing CNNs
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入卷积神经网络（CNN）
- en: This section describes the basic components of a CNN. `CNN_SRATEGY_MODEL.py`
    will illustrate the basic CNN components used to build a model for abstract image
    detection. For machines, as for humans, concepts are the building blocks of cognition.
    CNNs constitute one of the pillars of deep learning (multiple layers and neurons).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了卷积神经网络的基本组件。`CNN_SRATEGY_MODEL.py` 将展示构建抽象图像检测模型所需的基本 CNN 组件。对于机器和人类而言，概念是认知的构建块。CNN
    是深度学习的支柱之一（多层和神经元）。
- en: In this chapter, TensorFlow 2 with Python will be running using Keras libraries
    that are now part of TensorFlow. If you do not have Python or do not wish to follow
    the programming exercises, the chapter is self-contained, with graphs and explanations.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将使用 Python 的 TensorFlow 2 版本，并通过现在已并入 TensorFlow 的 Keras 库来运行。如果你没有安装 Python
    或不想进行编程练习，本章是自包含的，包含图表和解释。
- en: Defining a CNN
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义卷积神经网络（CNN）
- en: A convolutional neural network processes information, such as an image, for
    example, and makes sense out of it.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络处理信息，比如图像，并从中提取意义。
- en: For example, imagine you have to represent the sun with an ordinary pencil and
    a piece of paper. It is a sunny day, and the sun is shining very brightly—too
    brightly. You put on a special pair of very dense sunglasses. Now you can look
    at the sun for a few seconds. You have just applied a color reduction filter,
    one of the first operations of a convolutional network.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，假设你需要用一支普通铅笔和一张纸来表现太阳。那是一个阳光明媚的日子，太阳非常明亮—亮得有些过头。你戴上了一副非常厚重的太阳镜。现在你可以看太阳几秒钟。你刚刚应用了一个颜色降低滤镜，这是卷积神经网络中的第一步操作之一。
- en: 'Then, you try to draw the sun. You draw a circle and put some gray in the middle.
    You have just applied an edge filter. Finally, you go over the circle several
    times to make it easy to recognize, progressively reducing what you saw into a
    representation of it. Now, with the circle, some gray in the middle, and a few
    lines of rays around it, anybody can see you drew the sun. You smile; you did
    it! You took a color image of the sun and made a mathematical representation of
    it as a circle, which would probably look something like this:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你试图画出太阳。你画了一个圆圈，圆圈中间涂了一些灰色。你刚刚应用了一个边缘滤波器。最后，你多次在圆圈上描摹，使它更容易被识别，逐渐将你看到的内容转化为它的表现形式。现在，画出了一个圆圈，圆圈中间有一些灰色，周围有几条射线，任何人都能看出你画的是太阳。你微笑了；你做到了！你拍摄了一张太阳的彩色图像，并将它的数学表现形式转化为一个圆圈，这大概长得像这样：
- en: '![](img/B15438_09_01.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_01.png)'
- en: 'Figure 9.1: Mathematical representation of a circle'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1：圆形的数学表示
- en: You just went through the basic processes of a convolutional network.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚经历了一个卷积神经网络的基本过程。
- en: The word **convolutional** means that you transformed the sun you were looking
    at into a drawing, area by area. But, you did not look at the whole sky at once.
    You made many eye movements to capture the sun, area by area, and you did the
    same when drawing. If you made a mathematical representation of the way you transformed
    each area from your vision to your paper abstraction, it would be a kernel. You
    can see that the convolutional operation converts an object into a more abstract
    representation. This is not limited to images but can apply to any type of data
    (words, sounds and video) we want to draw patterns from.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**卷积**这个词意味着你将你看到的太阳逐区域地转化成了一幅画。但是，你并不是一次性地看完整个天空。你进行了多次眼动，以逐区域地捕捉太阳，画画时也是如此。如果你用数学方式表示你如何将每个区域从视觉转化为纸面上的抽象，那将是一个卷积核。你可以看到，卷积操作将一个对象转换为更抽象的表现形式。这不仅限于图像，还可以应用于任何类型的数据（文字、声音和视频），我们希望从中提取模式。'
- en: With that concept in mind, the following graph shows the successive mathematical
    steps to follow in this chapter's model for a machine to process an image just
    as you did. A convolutional network is a succession of steps that will transform
    what you see into a classification status.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个概念，下面的图表展示了本章模型中的连续数学步骤，用于让机器处理图像，就像你所做的那样。卷积神经网络是一系列步骤，将把你看到的内容转化为分类状态。
- en: In the graph, each box represents a layer. Each layer has an input that comes
    from the previous layer. Each layer will then transform the input and then produce
    an output that will become the input of the next layer. At each layer, the key
    features that are necessary to classify the images will be isolated.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在图表中，每个方框代表一个层。每个层有一个来自前一层的输入。每一层将转换输入并生成一个输出，作为下一个层的输入。在每一层，分类图像所必需的关键特征将被提取。
- en: In your example, it would serve to find out whether your drawing represents
    the sun or not. This falls under a binary classification model (yes or no, or
    1 or 0).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的例子中，它的作用是判断你的画作是否代表太阳。这属于一个二分类模型（是或不是，或者1或0）。
- en: '![](img/B15438_09_02.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_02.png)'
- en: 'Figure 9.2: Architecture of a CNN'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2：CNN的架构
- en: Notice that the size of the outputs diminishes progressively until the outputs
    reach 1, the binary classification status that will return (1 or 0). These successive
    steps, or layers, represent what you did when you went from observing the sun
    to drawing it. In the end, if we draw poorly and nobody recognizes the sun, it
    means that we'll have to go back to step 1 and change some parameters (weights
    in this case). That way, we train to represent the sun better until somebody says,
    "Yes, it is a sun!" That is probability = 1\. Another person may say that it is
    not a sun (probability = 0). In that case, more training would be required.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，输出的大小逐渐减少，直到输出达到1，即二元分类状态（返回1或0）。这些连续的步骤或层，代表了你从观察太阳到绘制它的过程。如果我们绘制得不好，没人认出那是太阳，这意味着我们需要回到第1步并更改一些参数（在这种情况下是权重）。这样，我们就能通过训练更好地表示太阳，直到有人说，“是的，那是太阳！”
    那时概率 = 1。另一个人可能会说那不是太阳（概率 = 0）。在这种情况下，可能需要更多的训练。
- en: If you carry out this experiment of drawing the sun, you will notice that, as
    a human, you transform one area at a time with your eye and pencil. You repeat
    the way you do it in each area. The mathematical repetition you perform is your
    **kernel**. Using a kernel per area is the fastest way to draw. For us humans,
    in fact, it is the only way we can draw. A CNN is based on this process.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你进行绘制太阳的实验，你会注意到，作为人类，你一次用眼睛和铅笔转化一个区域。你会在每个区域中重复相同的方式。你所做的数学重复就是你的**卷积核**。每个区域使用一个卷积核是最快的绘制方式。对我们人类来说，事实上，这也是我们唯一能绘制的方式。CNN就是基于这个过程。
- en: In this section, we looked at some key aspects of a CNN model, using the analogy
    of representing the sun as a drawing. This is just one way to start a convolutional
    neural network, and there are hundreds of different ways to do so. However, once you
    understand one model, you will have the understanding necessary to implement other
    variations.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们通过用绘制太阳的比喻，探讨了CNN模型的一些关键方面。这只是开始卷积神经网络的一种方式，实际上有成百上千种不同的方法。然而，一旦你理解了某个模型，你就具备了实现其他变体所需的理解。
- en: In the following section, we'll see how to initialize and build our own CNN.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将看到如何初始化并构建我们自己的CNN。
- en: Initializing the CNN
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始化CNN
- en: '`CNN_SRATEGY_MODEL.py` builds the CNN using TensorFlow 2\. TensorFlow 2 has
    made tremendous improvements in terms of development. The Keras datasets, layers,
    and models are now part of the TensorFlow instance:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`CNN_SRATEGY_MODEL.py`使用TensorFlow 2构建CNN。TensorFlow 2在开发方面进行了巨大的改进。Keras的数据集、层和模型现在都是TensorFlow实例的一部分：'
- en: '[PRE0]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The CNN only requires two lines of headers to build the layers! In TensorFlow
    2, for each layer, we simply have to call `layers.<add your layer here>` and that's
    it!
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: CNN只需要两行代码就可以构建层！在TensorFlow 2中，对于每一层，我们只需调用`layers.<add your layer here>`，就完成了！
- en: 'The model used is a Keras `sequential()` called from the TensorFlow `from tensorflow.keras`
    instance:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的模型是一个Keras `sequential()`，通过TensorFlow `from tensorflow.keras`实例调用：
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: And that's it. We have just started to build our own CNN in just a few lines
    of code. TensorFlow 2 has simplified the whole process of creating a CNN, making
    it an easy, intuitive process, as we will see throughout this chapter.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，我们只用了几行代码就开始构建了自己的CNN。TensorFlow 2简化了整个创建CNN的过程，使其变得简单直观，正如我们将在本章中看到的那样。
- en: Let's begin to build upon the foundations of our CNN in the following section
    and add a convolutional layer.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在接下来的部分开始在我们CNN的基础上构建，并添加一个卷积层。
- en: Adding a 2D convolution layer
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 添加一个二维卷积层
- en: 'In this chapter, we will be using a two-dimensional model as our example. Two-dimensional
    relationships can be real-life images and also many other objects, as described
    in this chapter. This chapter describes a two-dimensional network, although others
    exist:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用二维模型作为示例。二维关系可以是现实生活中的图像，也可以是本章中描述的其他许多物体。本章描述了一个二维网络，尽管也有其他类型的网络。
- en: A one-dimensional CNN mostly describes a temporal mode, for example, a sequence
    of sounds (phonemes = parts of words), words, numbers, and any other type of sequence.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一维CNN主要描述的是时间模式，例如，一系列声音（音素 = 词的部分）、单词、数字以及其他任何类型的序列。
- en: A volumetric module is a 3D convolution, such as recognizing a cube or a video.
    For example, for a self-driving car, it is critical to recognize the difference
    between a 2D picture of a person in an advertisement near a road and a real 3D
    image of a pedestrian that is starting to cross the same road!
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 体积模块是三维卷积，例如识别一个立方体或视频。例如，对于自动驾驶汽车来说，区分一张广告上人物的二维图片和一个即将横穿道路的行人三维图像是至关重要的！
- en: In this chapter, a spatial 2D convolution module will be applied to images of
    different kinds. The main program, `CNN_STRATEGY_MODEL.py`, will describe how
    to build and save a model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，将会对不同种类的图像应用一个二维空间卷积模块。主要程序`CNN_STRATEGY_MODEL.py`将描述如何构建和保存一个模型。
- en: '`classifier.add` will add a layer to the model. The name **classifier** does
    not represent a function but simply the arbitrary name that was given to this
    model in this particular program. The model will end up with *n* layers. Look
    at the following line of code:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`classifier.add`将会向模型中添加一层。**classifier**这个名字并不代表一个函数，它只是这个特定程序中随便给这个模型起的名字。模型最终将拥有*n*层。请看下面这一行代码：'
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This line of code contains a lot of information: the filters (applied with
    kernels), the input shape, and an activation function. The function contains many
    more options. Once you understand these in-depth, you can implement other options
    one by one, as you deem necessary, for each project you have to work on.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这行代码包含了大量信息：滤波器（应用了卷积核）、输入形状和激活函数。这个函数还包含了更多的选项。一旦你深入理解这些内容，你就可以根据自己每个项目的需要，逐一实现其他选项。
- en: Kernel
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 卷积核
- en: Just to get started, intuitively, let's take another everyday model. This model
    is a bit more mathematical and closer to a CNN's kernel representation. Imagine
    a floor of very small square tiles in an office building. You would like each
    floor tile to be converted from dirty to clean, for example.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了开始直观地理解，我们来看一个日常模型。这个模型稍微有点数学化，且更接近于卷积神经网络（CNN）的核表示。想象一下在一栋办公楼的地板上铺满了非常小的方形瓷砖。你希望每一块瓷砖从脏变干净，例如。
- en: You can imagine a cleaning machine capable of converting 3×3 small tiles (pixels)
    one at a time from dirty to clean. You would laugh if you saw somebody come with one
    enormous cleaning machine to clean all of the 32×32 tiles (pixels) at the same
    time. You know it would be very bulky, slow, and difficult to use, intuitively.
    On top of that, you would need one big machine per surface size! Not only is a
    kernel an efficient way to filter, but a kernel convolution is also a time-saving
    resource process. The small cleaning machine is the kernel (dirty-to-clean filter),
    which will save you time performing the convolution (going over all of the tiles
    to clean a 3×3 area), transforming the floor from dirty to clean.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象一个清洁机器，能够一次性将3×3的小瓷砖（像素）从脏变干净。如果看到有人拿着一台巨大的清洁机器来同时清理所有32×32块瓷砖（像素），你一定会笑出声来。你知道它会非常笨重、缓慢且难以使用。更何况，你还需要每一块地面大小都配一个大机器！卷积核不仅是一种高效的滤波方式，卷积核卷积还是一种节省时间的资源处理方式。那个小清洁机器就是卷积核（脏到干净的滤波器），它将帮助你节省时间，执行卷积操作（清理一个3×3区域的所有瓷砖），将地面从脏到干净地转变。
- en: 'In this case, 32 different filters have been added with 3×3 sized kernels:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，已经添加了32个不同的滤波器，每个滤波器使用的是3×3大小的卷积核：
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The use of kernels as filters is the core of a convolutional network. `(32,
    (3,3))` means `(number of filters, (size of kernels))`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用卷积核作为滤波器是卷积神经网络的核心。`(32, (3,3))`表示`(滤波器数量, (卷积核大小))`。
- en: An intuitive approach
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一种直观的方法
- en: To understand a kernel intuitively, keep the sun and cleaning tiles examples
    in mind. In this section, a photograph of a cat will show how kernels work.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了直观地理解卷积核，可以参考阳光和清洁瓷砖的例子。在这一节中，猫的照片将展示卷积核是如何工作的。
- en: 'In a model analyzing cats, the initial photograph would look like this:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个分析猫的模型中，初始的照片应该是这样的：
- en: '![](img/B15438_09_03.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_03.png)'
- en: 'Figure 9.3: Cat photograph for model analysis'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3：猫的照片用于模型分析
- en: 'On the first run of this layer, even with no training, an untrained kernel
    would transform the photograph:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个层的第一次运行中，即使没有经过训练，一个未经训练的卷积核也会转化这张照片：
- en: '![](img/B15438_09_04.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_04.png)'
- en: 'Figure 9.4: Cat photograph transformation'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4：猫的照片转化
- en: 'The first layer has already begun isolating the features of the cat. The edges
    have begun to appear: the cat''s body, ears, nose, and eyes. In itself, this first
    filter (one of 32) with a size 3×3 kernel—in the first layer and with no training—already
    produces effective results. The size of a kernel can vary according to your needs.
    A 3×3 kernel will require a larger number of weights than a 1×1 kernel, for example.
    A 1×1 kernel will have only one weight, which restricts the size of the features
    to represent. The rule is that the smaller the kernel, the fewer weights we have
    to find. It will also perform a feature reduction. When the size of the kernel
    increases, the number of weights and features to find increases as well as the
    number of features represented.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 第一层已经开始隔离猫的特征。边缘开始显现：猫的身体、耳朵、鼻子和眼睛。单单这个第一滤波器（32个之一），使用一个3×3的卷积核—在没有训练的情况下—已经产生了有效的结果。卷积核的大小可以根据需要变化。例如，一个3×3的卷积核需要比1×1的卷积核更多的权重。1×1的卷积核只有一个权重，这限制了它表示的特征的大小。规则是卷积核越小，我们需要找到的权重就越少，也会进行特征压缩。当卷积核的大小增加时，权重和特征的数量也会增加，同时所表示的特征数量也会增加。
- en: Each subsequent layer will make the features stand out much better, with smaller
    and smaller matrices and vectors, until the program obtains a clear mathematical
    representation.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 每一层都会使特征更加突出，使用越来越小的矩阵和向量，直到程序获得清晰的数学表示。
- en: Now that we have an intuitive view of how a filter works, let's explore a developer's
    approach.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了一个直观的滤波器工作方式的理解，接下来让我们探索一下开发者的方法。
- en: The developers' approach
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 开发者的方法
- en: Developers like to see the result first to decide how to approach a problem.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者喜欢先看到结果，以决定如何解决问题。
- en: 'Let''s take a quick, tangible shortcut to understand kernels through `Edge_detection_Kernel.py`
    with an edge detection kernel:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过`Edge_detection_Kernel.py`和一个边缘检测卷积核，快速而具体地理解卷积核：
- en: '[PRE4]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The kernel is a 3×3 matrix, like the cat example. But the values are preset,
    and not trained with weights. There is no learning here; only a matrix needs to
    be applied. The major difference with a CNN is that it will learn how to optimize
    kernels itself through weights and biases.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积核是一个3×3的矩阵，就像猫的例子一样。但其数值是预设的，而不是通过权重进行训练的。这里没有学习过程；只是需要应用一个矩阵。与卷积神经网络（CNN）不同的是，CNN会通过权重和偏置来自动学习如何优化卷积核。
- en: '`img.bmp` is loaded, and the 3×3 matrix is applied to the pixels of the loaded
    image, area by area:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`img.bmp` 被加载，3×3的矩阵被应用到加载图像的每个区域：'
- en: '[PRE5]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The image before the convolution applying the kernel is the letter **A** (letter
    recognition):'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积应用前的图像是字母**A**（字母识别）：
- en: '![](img/B15438_09_05.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_05.png)'
- en: 'Figure 9.5: The letter "A"'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5：字母“A”
- en: 'Now the convolution transforms the image, as shown in the following code:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，卷积对图像进行转换，如以下代码所示：
- en: '[PRE6]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The edges of A now appear clearly in white, as shown in the following graph:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在字母A的边缘清晰地以白色显示，如下图所示：
- en: '![](img/B15438_09_06.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_06.png)'
- en: 'Figure 9.6: The white edges of A are visible'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.6：A字母的白色边缘可见
- en: The original image on top displayed a very thick A. The preceding graph displays
    a thin, identifiable A feature through thin edges that a neural network can classify
    within a few mathematical operations. The first layers of a convolutional network
    train to find the right weights to generate the right kernel automatically.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 顶部的原始图像显示了一个非常粗的A。前面的图表展示了一个通过细边缘识别的、清晰的A特征，神经网络可以通过少量数学操作对其进行分类。卷积神经网络的第一层会训练找到正确的权重，从而自动生成正确的卷积核。
- en: Now that we have an intuitive and practical developer's view of a filter, let's
    add some mathematics to our approach.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了一个直观且实用的开发者视角来理解滤波器，接下来让我们将一些数学方法加入到我们的思路中。
- en: A mathematical approach
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 一种数学方法
- en: 'The initial image has a set of values you can display, as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 初始图像有一组可以显示的值，如下所示：
- en: '[PRE7]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The code will print a numerical output of the image, as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将打印出图像的数值输出，如下所示：
- en: '[PRE8]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The convolution filter is applied using `filter.convolve`, a mathematical function,
    to transform the image and filter it.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积滤波器通过数学函数`filter.convolve`来应用，以变换图像并进行滤波。
- en: 'The convolution filter function uses several variables:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积滤波器函数使用多个变量：
- en: The spatial index for the 3×3 kernel to apply; in this case, it must know how
    to access the data. This is performed through a spatial index, *j*, which manages
    data in grids. Databases also use spatial indexes to access data. The axes of
    those grids determine the density of a spatial index. Kernels and the image are
    convolved using *j* over *W*, the weights kernel.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3×3核的空间索引以便应用；在这种情况下，它必须知道如何访问数据。通过空间索引* j *来执行此操作，它管理网格中的数据。数据库也使用空间索引来访问数据。这些网格的轴决定了空间索引的密度。核和图像使用*j*在*W*（加权核）上进行卷积。
- en: '*W* is the weights kernel.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*W*是加权核。'
- en: '*I* is the input image.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*I*是输入图像。'
- en: '*k* is the coordinate of the center of *W*. The default value is 0 in this
    case.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*k*是*W*中心的坐标。在此情况下，默认值为0。'
- en: 'These variables then enter the `filter.convolve` function as represented by
    the following equation:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变量然后作为以下方程表示的`filter.convolve`函数的输入：
- en: '![](img/B15438_09_001.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_001.png)'
- en: 'A CNN relies on kernels. Take all the time you need to explore convolutions
    through the three dimensions required to master AI: an intuitive approach, development
    testing, and mathematical representation.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: CNN依赖于核。花足够的时间通过掌握AI所需的三维领域来探索卷积：直观方法、开发测试和数学表示。
- en: Now that we have a mathematical idea on how a convolutional filter works, let's
    determine the shape and the activation function to the convolutional layer.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对卷积滤波器的工作原理有了数学上的理解，接下来我们来确定卷积层的形状和激活函数。
- en: Shape
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 形状
- en: '`input_shape` defines the size of the image, which is 64×64 pixels (height×width),
    as shown here:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`input_shape`定义了图像的大小，这里是64×64像素（高度×宽度）：'
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`3` indicates the number of channels. In this case, `3` indicates the three
    parameters of an RGB color. Each channel can have a given value of 0 to 255.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`3`表示通道数。在此情况下，`3`表示RGB颜色的三个参数。每个通道的值可以在0到255之间。'
- en: ReLU
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ReLU
- en: 'Activation functions provide useful ways to influence the transformation of
    weighted data calculations. Their output will change the course of classification,
    a prediction, or whatever goal the network was built for. This model applies a
    **rectified linear unit** (**ReLU**), as shown in the following code:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数提供了影响加权数据计算转化的有用方式。它们的输出将改变分类、预测或网络所构建的其他目标的过程。此模型应用了**整流线性单元**（**ReLU**），如下代码所示：
- en: '[PRE10]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'ReLU activation functions apply variations of the following function to an
    input value:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ReLU激活函数将以下函数的变体应用于输入值：
- en: '*f*(*x*) = max{0, *x*}'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '*f*(*x*) = max{0, *x*}'
- en: The function returns 0 for negative values; it returns positive values as *x*;
    it returns 0 for 0 values. Half of the domain of the function will return zeros.
    This means that when you provide positive values, the derivative will always be
    1\. ReLU avoids the squashing effect of the logistic sigmoid function, for example.
    However, the decision to use one activation function rather than another will
    depend on the goal of each ANN model.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数对负值返回0；对正值返回*x*；对0值返回0。函数的一半域将返回零。这意味着，当你提供正值时，导数将始终为1。ReLU避免了像逻辑sigmoid函数的压缩效应。然而，选择使用一个激活函数而不是另一个将取决于每个ANN模型的目标。
- en: In mathematical terms, a **rectified linear unit (ReLU)** function will take
    all the negative values and apply 0 to them. And all the positive values remain
    unchanged.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 用数学术语来说，**整流线性单元（ReLU）**函数将所有负值变为0，而所有正值保持不变。
- en: The `ReLU.py` program provides some functions, including a NumPy function, to
    test how ReLU works.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`ReLU.py`程序提供了一些函数，包括一个NumPy函数，用于测试ReLU的工作原理。'
- en: 'You can enter test values or use the ones in the source code:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以输入测试值，也可以使用源代码中的值：
- en: '[PRE11]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '`nx` expects a negative value, and `px` expects a positive value for testing
    purposes for the `relu(x)` and `lrelu(x)` functions. Use the `f(x)` function if
    you wish to include zeros in your testing session.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`nx`期望一个负值，`px`期望一个正值，用于测试`relu(x)`和`lrelu(x)`函数。如果你希望在测试过程中包含零值，请使用`f(x)`函数。'
- en: 'The `relu(x)` function will calculate the ReLU value:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`relu(x)`函数将计算ReLU值：'
- en: '[PRE12]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In this case, the program will return the following result:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，程序将返回以下结果：
- en: '[PRE13]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The result of a negative value becomes 0, and a positive value remains unchanged.
    The derivative or slope is thus always 1, which is practical in many cases and
    provides good visibility when debugging a CNN or any other ANN.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 负值的结果变为0，正值保持不变。因此，导数或斜率始终为1，这在许多情况下是实用的，并且在调试CNN或其他任何ANN时提供了良好的可见性。
- en: 'The NumPy function, defined as follows, will provide the same results:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 定义如下的NumPy函数将提供相同的结果：
- en: '[PRE14]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Through trial and error, ANN research has come up with several variations of
    ReLU.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 通过反复试验，ANN研究提出了几种ReLU的变种。
- en: One important example occurs when many input values are negative. ReLU will
    constantly produce zeros, making gradient descent difficult, if not impossible.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的例子发生在许多输入值为负时。ReLU会不断产生零值，使得梯度下降变得困难，甚至不可能。
- en: 'A clever solution was found using a leaky ReLU. A leaky ReLU does not return
    0 for a negative value but a small value you can choose, 0.1 instead of 0, for
    example. See the following equation:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用泄漏ReLU，找到了一种巧妙的解决方案。泄漏ReLU不会对负值返回0，而是返回一个可以选择的小值，例如0.1而不是0。见以下方程：
- en: '*f*(*x*) = max{0.1, *x*}'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*f*(*x*) = max{0.1, *x*}'
- en: The leaky ReLU fixes the problem of "dying" neurons. Suppose you have a layer
    that keeps returning negative values when activating neurons. The ReLU activation
    will always return 0 in this case. That means that these neurons are "dead." They
    will never be activated. To avoid these "dying" neurons, a leaky ReLU provides
    the small positive value seen previously (0.1) that makes sure that a neuron does
    not "die."
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 泄漏ReLU解决了“死亡”神经元的问题。假设你有一层在激活神经元时总是返回负值。此时，ReLU激活将总是返回0。这意味着这些神经元“死了”。它们将永远不会被激活。为避免这些“死亡”神经元，泄漏ReLU提供了之前看到的小正值（0.1），确保神经元不会“死”。
- en: 'Now gradient descent will work fine. In the sample code, the function is implemented
    as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在梯度下降会正常工作。在示例代码中，该函数的实现如下：
- en: '[PRE15]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Although many other variations of ReLU exist, with this in mind, you have an
    idea of what it does.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管ReLU有许多其他变种，但有了这些，你就能了解它的作用。
- en: 'Enter some values of your own, and the program will display the results, as
    shown here:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 输入一些自己的值，程序将显示结果，如下所示：
- en: '[PRE16]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The results will display the ReLU results as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将显示如下ReLU结果：
- en: '[PRE17]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We have processed a large representation of the input image. We now need to
    reduce the size of our representation to obtain a better, more abstract representation.
    By pooling some of the pixels we will also reduce the calculations of the subsequent
    layers.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经处理了输入图像的一个大表示。现在我们需要缩小表示的大小，以便获得更好、更抽象的表示。通过池化一些像素，我们还将减少后续层的计算量。
- en: Pooling
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 池化
- en: 'A CNN contains hidden layers. The input is visible. Then as the layers work
    to transform the data, "hidden" work goes on. The output layer is visible again.
    Let''s continue to explore the "hidden" layers! Pooling reduces the size of an
    input representation, in this case, an image. Max pooling consists of applying
    a max pooling window to a layer of the image:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: CNN包含隐藏层。输入是可见的。然后，随着各层工作以转换数据，“隐藏”的工作在进行。输出层再次是可见的。让我们继续探索这些“隐藏”层！池化减少了输入表示的大小，在本例中是图像。最大池化是将最大池化窗口应用于图像的某一层：
- en: '[PRE18]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This `pool_size` 2×2 window will first find the maximum value of the 2×2 matrix
    at the top left of the image matrix. This first maximum value is 4\. It is thus
    the first value of the pooling window on the right.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`pool_size` 2×2的窗口将首先找到图像矩阵左上角2×2矩阵的最大值。这个第一个最大值是4。因此，它是右侧池化窗口的第一个值。
- en: 'Then, the max pooling window hops over 2 squares and finds that 5 is the highest
    value. 5 is written in the max pooling window. The hop action is called a **stride**.
    A stride value of 2 will avoid overlapping, although some CNN models have strides
    that overlap. It all depends on your goal. Look at the following diagram:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，最大池化窗口跳过2个格子，找到5是最高值。5被写入最大池化窗口。这个跳跃动作称为**步幅**。步幅值为2将避免重叠，尽管一些CNN模型的步幅会有重叠。这一切都取决于你的目标。请看下面的示意图：
- en: '![](img/B15438_09_07.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_07.png)'
- en: 'Figure 9.7: Pooling example'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.7：池化示例
- en: 'The output size has now gone from a 62×62×32 (number of filters) to a 31×31×32,
    as shown in the following diagram:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 输出大小现在从62×62×32（滤波器数量）变为31×31×32，如下图所示：
- en: '![](img/B15438_09_08.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_08.png)'
- en: 'Figure 9.8: Output size changes (pooling)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.8：输出大小变化（池化）
- en: Other pooling methods exist, such as average pooling, which uses the average
    of the pooling window and not the maximum value. This depends on the model and
    shows the hard work that needs to be put in to train a model.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他池化方法，例如平均池化，它使用池化窗口的平均值，而不是最大值。这取决于模型，并展示了训练模型时需要付出的辛勤努力。
- en: Next convolution and pooling layer
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 接下来的卷积和池化层
- en: 'The next two layers of the CNN repeat the same method as the first two described
    previously, and it is implemented as follows in the source code:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: CNN的接下来的两层与之前描述的前两层采用相同的方法，源代码实现如下：
- en: '[PRE19]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'These two layers have drastically downsized the input to 14×14×32, as shown
    in this diagram:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这两层将输入大幅缩小为14×14×32，如下图所示：
- en: '![](img/B15438_09_09.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_09.png)'
- en: 'Figure 9.9: Convolution and pooling layer'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.9：卷积层和池化层
- en: It is possible to insert a padding layer on a CNN. As we shrink our image layer
    by layer, the filters in a convolutional network will impact the center pixels
    more than the outer pixels. Suppose you start drawing on a piece of paper. You
    tend to fill the center of the paper and avoid the edges. The edges of the piece
    of paper contain less information. If you decide to apply padding to the edges,
    the image will be more complete. In a neural network, padding has the same function.
    It makes sure the edges are taken into account by adding values. Padding can be
    implemented before or after pooling, for example. We will implement an example
    of padding in *Chapter 13*, *Visualizing Networks with TensorFlow 2.x and TensorBoard*.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积神经网络中，可以插入一个填充层。随着我们逐层缩小图像，卷积网络中的滤波器会对中心像素产生比对外部像素更大的影响。假设你开始在一张纸上绘画，你倾向于填充纸的中心而避开边缘。纸的边缘包含的信息较少。如果你决定对边缘应用填充，图像将更加完整。在神经网络中，填充具有相同的功能。它通过添加值确保边缘也被考虑进去。填充可以在池化之前或之后实现。例如，我们将在*第13章*，*使用TensorFlow
    2.x和TensorBoard可视化网络*中实现一个填充的例子。
- en: The next layer can apply flattening to the output of the pooling of this section,
    as we'll see in the next section.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 下一层可以对池化部分的输出应用展平，如我们将在下一节中看到的。
- en: Flattening
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 展平
- en: 'The flattening layer takes the output of the max pooling layer and transforms
    the vector of size *x* * *y* * *z* into a flattened vector, as shown in the following
    code:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 展平层将最大池化层的输出转换为一个大小为 *x* * *y* * *z* 的向量，像下面的代码所示：
- en: '[PRE20]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In this case, the layer vector will be 14 × 14 × 32 = 6,272, as shown in the
    following diagram:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，层向量将是14 × 14 × 32 = 6,272，如下图所示：
- en: '![](img/B15438_09_10.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_10.png)'
- en: 'Figure 9.10: Flattening layer'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.10：展平层
- en: This operation creates a standard layer with 6,272 very practical connections
    for the dense operations that follow. After flattening has been carried out, a
    fully connected dense network can be implemented.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 该操作创建了一个标准层，具有6,272个非常实用的连接，用于后续的全连接操作。展平操作完成后，可以实现一个完全连接的全连接网络。
- en: Dense layers
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全连接层
- en: Dense layers are fully connected. Full connections are possible through the
    size reductions calculated so far, as shown before.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 全连接层是完全连接的。通过到目前为止计算的尺寸缩减，可以实现完全连接，如前所示。
- en: 'The successive layers in this sequential model have brought the size of the
    image down enough to use dense layers to finish the job. `dense_1` comes first,
    as shown here:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这个顺序模型中的连续层已经将图像的大小缩小到足以使用全连接层来完成任务。`dense_1`是第一层，如下所示：
- en: '![](img/B15438_09_11.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_11.png)'
- en: 'Figure 9.11: Dense layer'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.11：全连接层
- en: The flattening layer produced a 14×14×32 size 6,272 layer with a weight for
    each input. If it had not gone through the previous layers, the flattening would
    have produced a much larger layer, slowing feature extractions down. The result
    would produce nothing effective.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 展平层生成了一个14×14×32大小的6,272层，每个输入都有一个权重。如果没有经过前面的层，展平层会生成一个更大的层，这会减慢特征提取的速度。结果将无法有效生成任何东西。
- en: 'With the main features extracted by the filters through successive layers and
    size reduction, the dense operations will lead directly to a prediction using
    ReLU on the dense operation and then the logistic sigmoid function to produce
    the final result:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 通过连续的层和尺寸缩减，滤波器提取了主要特征，接下来的全连接操作将直接通过ReLU激活进行预测，然后使用逻辑Sigmoid函数生成最终结果：
- en: '[PRE21]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Now that we have the dense layer, let's explore the dense layer's activation
    functions.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了全连接层，让我们来探讨全连接层的激活函数。
- en: Dense activation functions
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 全连接层激活函数
- en: The ReLU activation function can be applied to a dense layer as in other layers.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: ReLU激活函数可以像其他层一样应用于全连接层。
- en: 'The domain of the ReLU activation function is applied to the result of the
    first dense operation. The ReLU activation function will output the initial input
    for values >=0 and will output 0 for values <0:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: ReLU激活函数的定义域应用于第一次全连接操作的结果。ReLU激活函数将对值>=0的输入输出初始输入，对值<0的输入输出0：
- en: '*f*(input_value) = max{0, input_value)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '*f*(input_value) = max{0, input_value)'
- en: The logistic activation function is applied to the second dense operation, as
    described in *Chapter 2*, *Building a Reward Matrix – Designing Your Datasets*.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 如*第二章*《构建奖励矩阵——设计你的数据集》所述，逻辑激活函数应用于第二个全连接层操作。
- en: 'It will produce a value between 0 and 1:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 它会产生一个介于 0 和 1 之间的值：
- en: '*LS*(*x*)={0,1}'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '*LS*(*x*)={0,1}'
- en: We have now built the last dense layer after the *LS* activation function.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经在*LS*激活函数后构建了最后一个全连接层。
- en: 'The last dense layer is of size 1 and will classify the initial input—an image
    in this case:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个全连接层的大小为1，将对初始输入进行分类——在此案例中为图像：
- en: '![](img/B15438_09_12.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_12.png)'
- en: 'Figure 9.12: Dense layer 2'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.12：第二个全连接层
- en: The layers of the model have now been added. Training can begin.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型的各个层已经添加完毕，训练可以开始了。
- en: Training a CNN model
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练一个CNN模型
- en: 'Training a CNN model involves four phases: compiling the model, loading the
    training data, loading the test data, and running the model through epochs of
    loss evaluation and parameter-updating cycles.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 训练CNN模型包括四个阶段：编译模型、加载训练数据、加载测试数据，以及通过多轮损失评估和参数更新周期运行模型。
- en: In this section, the choice of theme for the training dataset will be an example
    from the food-processing industry. The idea here is not only to recognize an object
    but to form a concept. We will explore concept learning neural networks further
    in *Chapter 10*, *Conceptual Representation Learning*. For the moment, let's train
    our model.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，训练数据集的主题选择将是来自食品加工行业的一个示例。这里的思想不仅是识别物体，而是形成一个概念。我们将在*第10章*《概念表示学习》中进一步探讨概念学习神经网络。暂时让我们先训练我们的模型。
- en: The goal
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 目标
- en: The primary goal of this model consists of detecting production efficiency flaws
    on a food-processing conveyor belt. The use of CIFAR-10 (images) and MNIST (a handwritten
    digit database) proves useful to understand and train some models. However, in
    this example, the goal is not to recognize objects but a concept.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的主要目标是检测食品加工传送带上的生产效率缺陷。使用CIFAR-10（图像）和MNIST（手写数字数据库）有助于理解和训练一些模型。然而，在这个例子中，目标不是识别物体，而是识别概念。
- en: 'The following image shows a section of the conveyor belt that contains an acceptable level
    of products, in this case, portions of chocolate cake:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图像展示了一个包含可接受产品数量的传送带段，这里是巧克力蛋糕的部分：
- en: '![](img/B15438_09_13.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_13.png)'
- en: 'Figure 9.13: Portions of chocolate cake example'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.13：巧克力蛋糕部分示例
- en: The images can represent anything from chocolate cakes, cars on a road or any
    other type of object. The main point is to detect when there are "gaps" or "holes"
    in the rows of objects. To train the CNN, I used images containing objects I sometimes
    drew just to train the system to "see" gaps.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这些图像可以代表从巧克力蛋糕到道路上的汽车或任何其他类型的物体。重点是检测物体行列中是否存在“差距”或“空隙”。为了训练CNN，我使用了包含我偶尔画的物体的图像，目的是训练系统“看”到这些差距。
- en: 'However, sometimes production slows down, and the output goes down to an alert
    level, as shown in the following photograph:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时生产会放慢，输出会下降到警报级别，如下图所示：
- en: '![](img/B15438_09_14.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_14.png)'
- en: 'Figure 9.14: Portions of chocolate cake example'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.14：巧克力蛋糕部分示例
- en: The alert-level image shows a gap that will slow down the packaging section
    of the factory dramatically. There are three lines of objects in the preceding
    image. On line one, you can see five little objects (here pieces of cake), on
    line two, only three. On line three, you can only see two objects. There are thus
    objects missing on lines two and three. This constitutes a gap in this case that
    is a real problem on production lines. The level of the number of acceptable objects
    in a frame is a parameter.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 警报级别图像显示了一个差距，这将显著减慢工厂包装部分的速度。前面的图像中有三行物体。在第一行，可以看到五个小物体（这里是蛋糕块），在第二行，只有三个。在第三行，只有两个物体。因此，第二行和第三行缺少物体。在这种情况下，这个差距是生产线上的一个真实问题。每帧中可接受物体的数量是一个参数。
- en: Now that we have our goal, let's begin compiling the model.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了目标，开始编译模型吧。
- en: Compiling the model
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编译模型
- en: 'Compiling a TensorFlow 2 model requires a minimum of two options: a loss function and
    an optimizer. You evaluate how much you are losing and then optimize your parameters,
    just as in real life. A metric option has been added to measure the performance
    of the model. With a metric, you can analyze your losses and optimize your situation,
    as shown in the following code:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 编译一个TensorFlow 2模型需要至少两个选项：损失函数和优化器。你评估你损失了多少，然后优化你的参数，就像在现实生活中一样。已经增加了一个度量选项来衡量模型的表现。通过度量，你可以分析你的损失并优化你的情况，如以下代码所示：
- en: '[PRE22]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Let's take a look at some specific aspects of model compiling, starting with
    the loss function.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下模型编译的一些具体方面，从损失函数开始。
- en: The loss function
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 损失函数
- en: The loss function provides information on how far the state of the model *y*[1]
    (weights and biases) is from its target state *y*.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数提供了模型的状态 *y*[1]（权重和偏置）与其目标状态 *y* 之间的距离信息。
- en: A description of the quadratic loss function precedes that of the binary cross-entropy functions
    applied to the case study model in this chapter.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 二次损失函数的描述在本章中应用于案例研究模型的二进制交叉熵函数之前。
- en: The quadratic loss function
  id: totrans-213
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 二次损失函数
- en: 'Let''s refresh the concept of gradient descent. Imagine you are on a hill and
    want to walk down that hill. Your goal is to get to *y*, the bottom of the hill.
    Presently, you are at location *a*. Google Maps shows you that you still have
    to go a certain distance:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们刷新一下梯度下降的概念。假设你在一座山丘上，想要走下山。你的目标是到达 *y*，山谷的底部。现在你的位置是 *a*。谷歌地图显示你仍然需要走一段距离：
- en: '*y* – *a*'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '*y* – *a*'
- en: That formula is great for the moment. But now suppose you are almost at the
    bottom of the hill, and the person walking in front of you has dropped a coin.
    You have to slow down now, and Google Maps is not helping much because at this zoom
    level.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式在目前是很不错的。但现在假设你几乎到了山底，而前面的人丢了一枚硬币。你现在必须放慢速度，而谷歌地图在这个缩放级别下并没有太多帮助。
- en: 'You must then zoom into smaller distances with a quadratic objective (or cost)
    function:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你必须通过一个二次目标（或成本）函数来缩小到更小的距离：
- en: '*O* = (*y* – *a*)²'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '*O* = (*y* – *a*)²'
- en: 'To make it more comfortable to analyze, *O* is divided by 2, producing a standard
    quadratic cost function:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于分析，*O* 被除以2，得到一个标准的二次成本函数：
- en: '![](img/B15438_09_002.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_002.png)'
- en: '*y* is the goal. *a* is the result of the operation of applying the weights,
    biases, and finally, the activation functions.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '*y* 是目标。*a* 是应用权重、偏置，最后应用激活函数的操作结果。'
- en: With the derivatives of the results, the weights and biases can be updated.
    In our hill example, if you move one meter (*y*) per step (*x*), that is much
    more than moving 0.5 meters (*y*) per step. Depending on your position on the
    hill, you can see that you cannot apply a constant learning rate (conceptually,
    the length of your step); you adapt it just like Adam, the optimizer, does.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结果的导数，可以更新权重和偏置。在我们的山丘示例中，如果每步移动一米（*y*），那比每步移动0.5米（*y*）要多得多。根据你在山丘上的位置，你可以看到，不能应用一个恒定的学习率（从概念上讲，就是你的步长）；你需要像优化器Adam一样进行调整。
- en: Binary cross-entropy
  id: totrans-223
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 二进制交叉熵
- en: Cross-entropy comes in handy when the learning slows down. In the hill example,
    it slowed down at the bottom. But, remember, a path can lead you sideways, meaning
    you are momentarily stuck at a given height. Cross-entropy solves that by being
    able to function well with very small values (steps on the hill).
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 当学习速度变慢时，交叉熵非常有用。在山丘的例子中，它在底部变慢了。但请记住，一条路可能会把你带到旁边，也就是说，你暂时被卡住在某个高度。交叉熵通过能够在非常小的值（山上的步伐）下正常工作来解决这个问题。
- en: 'Suppose you have the following structure:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有以下结构：
- en: Inputs = {*x*[1], *x*[2], …, *x*[n]}
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入 = {*x*[1], *x*[2], …, *x*[n]}
- en: Weights = {*w*[1], *w*[2], …, *w*[n]}
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 权重 = {*w*[1], *w*[2], …, *w*[n]}
- en: A bias (or sometimes more) is *b*
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 偏置（或有时更多）是 *b*
- en: An activation function (ReLU, logistic sigmoid, or other)
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 激活函数（ReLU、逻辑Sigmoid或其他）
- en: 'Before the activation, *z* represents the sum of the classical operations:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在激活之前，*z*表示经典操作的总和：
- en: '![](img/B15438_09_003.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_003.png)'
- en: Now the activation function is applied to *z* to obtain the present output of
    the model.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将激活函数应用于 *z*，以获得模型的当前输出。
- en: '*y*[1] = *act*(*z*)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '*y*[1] = *act*(*z*)'
- en: 'With this in mind, the cross-entropy loss formula can be explained:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个思路，可以解释交叉熵损失公式：
- en: '![](img/B15438_09_004.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_09_004.png)'
- en: 'In this function:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个函数中：
- en: '*n* is the total number of items of the input training, with multiclass data.
    The choice of the logarithm base (2, *e*, 10) will produce different effects.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*n*是输入训练集的总项目数，对于多类数据，选择对数的底数（2，*e*，10）会产生不同的效果。'
- en: '*y* is the output goal.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y*是输出目标。'
- en: '*y*[1] is the present value, as described previously.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*y*[1]是之前描述的当前值。'
- en: This loss function is always positive; the values have a minus sign in front
    of them, and the function starts with a minus. The output produces small numbers
    that tend to zero as the system progresses.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这个损失函数始终为正，值前有负号，且函数以负号开始。输出产生的小数字趋向于零，随着系统的进展而变小。
- en: The loss function uses this basic concept with more mathematical inputs to update
    the parameters.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数使用这个基本概念，结合更多的数学输入来更新参数。
- en: A binary cross-entropy loss function is a binomial function that will produce
    a probability output of 0 or 1 and not a value between 0 and 1 as in standard
    cross-entropy. In the binomial classification model, the output will be 0 or 1.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 二元交叉熵损失函数是一个二项式函数，它会输出0或1的概率，而不是像标准交叉熵那样输出0和1之间的值。在二项分类模型中，输出将是0或1。
- en: 'In this case, the sum ![](img/B15438_09_005.png) is not necessary when *M*
    (number of classes) = 2\. The binary cross-entropy loss function is then as follows:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，当*M*（类别数量）= 2时，不需要求和！[](img/B15438_09_005.png)。二元交叉熵损失函数如下所示：
- en: Loss = –*y* log *y*[1] + (1 – *y*) log (1 – *y*[1])
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 损失 = –*y* log *y*[1] + (1 – *y*) log (1 – *y*[1])
- en: The whole concept of this loss function method is for the CNN network to provide
    information for the optimizer to adapt the weights accordingly and automatically.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 该损失函数方法的核心概念是让CNN网络为优化器提供信息，以便相应地自动调整权重。
- en: The Adam optimizer
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Adam优化器
- en: In the hill example, you first walked with big strides down the hill using momentum
    (larger strides because you are going in the right direction). Then, you had to
    take smaller steps to find the object. You adapted your estimation of your moment
    to your need; hence, the name **adaptive moment estimation** (**Adam**).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在山坡示例中，你首先用大步伐通过惯性下坡（因为你朝着正确的方向走，步伐较大）。然后，你需要走得更小一步，去找到物体。你根据需要调整你的步伐，这就是**自适应动量估计**（**Adam**）的含义。
- en: Adam constantly compares mean past gradients to present gradients. In the hill
    example, it compares how fast you were going.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: Adam不断地将过去的平均梯度与当前梯度进行比较。在山坡示例中，它比较的是你行进的速度。
- en: The Adam optimizer represents an alternative to the classical gradient descent
    method. Adam goes further by applying its optimizer to random (stochastic) mini-batches
    of the dataset. This approach is an efficient version of stochastic gradient descent.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: Adam优化器是经典梯度下降方法的替代方案。Adam进一步通过将其优化器应用于数据集的随机（随机）小批量来进行扩展。这种方法是随机梯度下降的高效版本。
- en: Then, with even more inventiveness, Adam adds **root-mean-square deviation**
    (**RMSprop**) to the process by applying per-parameter learning weights. It analyzes
    how fast the means of the weights are changing (such as the gradients in our hill
    slope example) and adapts the learning weights.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，Adam通过将**均方根偏差**（**RMSprop**）加入过程，进一步创新，应用每个参数的学习权重。它分析权重均值的变化速度（例如我们山坡示例中的梯度变化），并相应地调整学习权重。
- en: Metrics
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 度量标准
- en: Metrics are there to measure the performance of your model during the training
    process. The metric function behaves like a loss function. However, it is not
    used to train the model.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 度量标准用于在训练过程中评估模型的表现。度量函数的行为像一个损失函数。然而，它并不用于训练模型。
- en: 'In this case, the `accuracy` parameter was this:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`accuracy`参数为：
- en: '[PRE23]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Here, a value that descends toward 0 shows whether the training is on the right
    track and moves up to 1 when the training requires Adam function optimizing to set
    the training on track again.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，值趋向0表明训练是否在正确的轨道上，值升高到1时，表明训练需要Adam函数优化，以便重新调整训练轨道。
- en: With this, we have compiled our model. We can now consider our training dataset.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们已经编译好了我们的模型。现在我们可以考虑我们的训练数据集。
- en: The training dataset
  id: totrans-257
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练数据集
- en: The training dataset is available on GitHub. The dataset contains the image
    shown previously for the food-processing conveyor belt example. I created a training
    dataset with a repetition of a few images that I used to illustrate the architecture
    of a CNN simply. In a real-life project, it will take careful designing with a
    trial-and-error approach to create a proper dataset that represents all of the
    cases that the CNN will face.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据集可以在 GitHub 上获取。数据集包含了之前提到的用于食品加工传送带示例的图像。我创建了一个包含一些重复图像的训练数据集，用来简单地说明 CNN
    的架构。在实际项目中，需要通过反复试验精心设计，创建一个合适的数据集，以涵盖 CNN 面临的所有情况。
- en: The class `A` directory contains the acceptable level images of a production
    line that is producing acceptable levels of products. The class `B` directory
    contains the alert-level images of a production line that is producing unacceptable
    levels of products.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 类 `A` 目录包含生产线所生产的合格产品的合格级别图像。类 `B` 目录包含生产线所生产的不可接受产品的警报级别图像。
- en: 'The number of images in the dataset is limited because of the following:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的图像数量有限，原因如下：
- en: For experimental training purposes, the images produced good results
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在实验训练过程中，生成的图像得到了良好的结果。
- en: The training-testing phase runs faster to study the program
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和测试阶段运行得更快，以便研究该程序。
- en: The goal of the model is to detect the alert levels, an abstract conceptual
    application of a CNN.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的目标是检测警报级别，这是 CNN 的一个抽象概念应用。
- en: Data augmentation
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据增强
- en: Data augmentation increases the size of the dataset by generating distorted
    versions of the images provided.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强通过生成扭曲版本的图像来增加数据集的大小。
- en: 'The `ImageDataGenerator` function generates batches of all images found in
    tensor formats. It will perform data augmentation by distorting the images (shear
    range, for example). Data augmentation is a fast way to use the images you have
    and create more virtual images through distortions:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '`ImageDataGenerator` 函数生成所有图像批次，图像以张量格式呈现。它会通过扭曲图像（例如剪切范围）进行数据增强。数据增强是一种快速利用已有图像并通过扭曲创建更多虚拟图像的方法：'
- en: '[PRE24]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The code description is as follows:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的描述如下：
- en: '`rescale` will rescale the input image if not `0` (or `None`). In this case,
    the data is multiplied by 1/255 before applying any other operation.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rescale` 将在输入图像不为 `0`（或 `None`）时进行缩放。在本例中，数据将乘以 1/255 后再进行其他操作。'
- en: '`shear_range` will displace each value in the same direction, determined in
    this case by the `0.2`. It will slightly distort the image at one point, giving
    some more virtual images to train.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`shear_range` 将每个值按相同的方向偏移，在本例中由 `0.2` 确定。它会在某一点略微扭曲图像，产生更多虚拟图像以进行训练。'
- en: '`zoom_range` is the value of zoom.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`zoom_range` 是缩放的值。'
- en: '`horizontal_flip` is set to `True`. This is a Boolean that randomly flips inputs horizontally.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`horizontal_flip` 设置为 `True`。这是一个布尔值，随机地将输入水平翻转。'
- en: '`ImageDataGenerator` provides many more options for real-time data augmentation,
    such as rotation range, height shift, and others.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '`ImageDataGenerator` 提供了更多的实时数据增强选项，如旋转范围、高度偏移等。'
- en: Loading the data
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载数据
- en: 'Loading the data goes through the `train_datagen` preprocessing image function
    (described previously) and is implemented in the following code:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 加载数据通过 `train_datagen` 图像预处理函数（如前所述）进行，并在以下代码中实现：
- en: '[PRE25]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The flow in this program uses the following options:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 本程序中的流程使用了以下选项：
- en: '`flow_from_directory` sets the directory + `''training_set''` to the path where
    the two binary classes to train are stored.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flow_from_directory` 将目录 + `''training_set''` 设置为存储两个二进制类别的路径，用于训练。'
- en: '`target_size` will be resized to that dimension. In this case, it is 64×64.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`target_size` 将图像调整为指定的尺寸。在这个例子中，是 64×64。'
- en: '`batch_size` is the size of the batches of data. The default value is 32, and
    it''s set to `10` in this case.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`batch_size` 是每批数据的大小。默认值是 32，在本例中设置为 10。'
- en: '`class_mode` determines the label arrays returned: `None` or `''categorical''`
    will be 2D one-hot encoded labels. In this case, `''binary''` returns 1D binary
    labels.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`class_mode` 决定返回的标签数组：`None` 或 `''categorical''` 将返回二维的独热编码标签。在这种情况下，`''binary''`
    返回一维的二进制标签。'
- en: Having looked at the training dataset, let's move on to the testing dataset.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 看过训练数据集后，让我们继续看测试数据集。
- en: The testing dataset
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试数据集
- en: The testing dataset flow follows the same structure as the training dataset
    flow described previously. However, for testing purposes, the task can be made
    easier or more difficult, depending on the choice of the model. To make the task
    more difficult, add images with defects or noise. This will force the system to
    train more and the project team to do more hard work to fine-tune the model. I
    chose to use a small dataset to illustrate the architecture of a CNN. In a real-life
    project choosing the right data that contains all of the cases that the CNN will
    face takes time and a trial-and-error approach.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 测试数据集流遵循与训练数据集流相同的结构。不过，出于测试目的，可以根据模型选择使任务更简单或更困难。为了使任务更具挑战性，可以添加带有缺陷或噪声的图像。这将迫使系统进行更多的训练，并促使项目团队更加努力地进行模型的微调。我选择使用一个小型数据集来展示CNN的架构。在实际项目中，选择包含CNN将面临的所有情况的正确数据需要时间，并且是一个反复试错的过程。
- en: Data augmentation provides an efficient way of producing distorted images without adding
    images to the dataset. Both methods, among many others, can be applied at the
    same time when necessary.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强提供了一种高效的方式来生成扭曲的图像，而无需向数据集中添加图像。许多其他方法可以在必要时同时应用。
- en: Data augmentation on the testing dataset
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在测试数据集上的数据增强
- en: 'In this model, the data only goes through rescaling. Many other options could
    be added to complicate the training task to avoid overfitting, for example, or
    simply because the dataset is small:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，数据仅通过重缩放处理。可以添加许多其他选项来使训练任务更加复杂，例如避免过拟合，或者仅仅因为数据集较小：
- en: '[PRE26]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Building datasets is one of the most difficult tasks in an artificial intelligence
    project. Data augmentation can be a solution if the results are efficient. If
    not, other techniques must be used. One technique is to gather very large datasets
    when that is possible and then use data augmentation just to distort the data
    a bit for training purposes.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 构建数据集是人工智能项目中最困难的任务之一。如果数据增强有效，它可以成为一种解决方案。如果无效，必须使用其他技术。一种技术是，在可能的情况下，收集非常大的数据集，然后仅通过数据增强稍微扭曲数据以用于训练。
- en: Loading the data
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载数据
- en: 'Loading the testing data remains limited to what is necessary for this model.
    Other options can fine-tune the task at hand:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 加载测试数据仅限于模型所需的部分。其他选项可以微调当前任务：
- en: '[PRE27]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Never underestimate dataset fine-tuning. Sometimes, this phase can last weeks
    before finding the right dataset and arguments.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 永远不要低估数据集微调。有时候，这一阶段可能会持续几周，才能找到合适的数据集和参数。
- en: Once the data is loaded, the CNN classifier is ready to be trained. Let's now
    see how this is done.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据加载完成，CNN 分类器就可以开始训练了。现在我们来看看如何进行训练。
- en: Training with the classifier
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用分类器进行训练
- en: 'The classifier has been built and can be run:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 分类器已构建并可以运行：
- en: '[PRE28]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: You will notice that, in this chapter, we have a directory for the training
    data and a separate directory for the test data. In *Chapter 5*, *How to Use Decision
    Trees to Enhance K-Means Clustering*, we split the datasets into training subsets
    and testing subsets. This can be applied to a CNN's dataset as well. This is a
    decision you will need to make, depending on the situation.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到，在本章中，我们为训练数据和测试数据分别设置了不同的目录。在*第5章*，*如何使用决策树增强K均值聚类*中，我们将数据集拆分为训练子集和测试子集。这同样可以应用于CNN的数据集。这是一个你需要根据具体情况做出的决定。
- en: For example, sometimes, the test set will be more difficult than the training
    set, which justifies a separate directory. In other cases, splitting the data
    can be the most efficient method.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，有时测试集会比训练集更具挑战性，这也证明了分开存放的目录是合理的。在其他情况下，分割数据可能是最有效的方法。
- en: 'The `fit_generator` function, which fits the model generated batch by batch,
    contains the main hyperparameters to run the training session through the following
    arguments in this model. The hyperparameter settings determine the behavior of
    the training algorithm:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '`fit_generator` 函数，它按批次生成模型并进行拟合，包含了通过以下参数运行训练会话的主要超参数。超参数设置决定了训练算法的行为：'
- en: '`training_set` is the training set flow described previously.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`training_set` 是前面描述的训练集流。'
- en: '`steps_per_epoch` is the total number of steps (batches of samples) to yield
    from the generator. The variable used in the following code is `estep`.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`steps_per_epoch` 是从生成器中输出的步骤总数（样本批次）。以下代码中使用的变量是 `estep`。'
- en: '`epochs` is the variable of the total number of iterations made on the data
    input. The variable used is `ep` in the preceding code.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`epochs`是对数据输入进行的总迭代次数的变量。前面代码中使用的变量是`ep`。'
- en: '`validation_data=test_set` is the testing data flow.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`validation_data=test_set`是测试数据流。'
- en: '`validation_steps=vs` is used with the generator and defines the number of
    batches of samples to test as defined by `vs` in the following code at the beginning
    of the program:'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`validation_steps=vs`与生成器一起使用，定义了程序开始时在以下代码中通过`vs`定义的测试样本批次数量：'
- en: '[PRE29]'
  id: totrans-306
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'While the training runs, measurements are displayed: loss, accuracy, epochs,
    information on the structure of the layers, and the steps calculated by the algorithm.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，会显示一些度量指标：损失、准确率、迭代次数、层结构信息，以及算法计算的步骤。
- en: 'Here is an example of the loss and accuracy data displayed:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是显示的损失和准确率数据示例：
- en: '[PRE30]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Now that we have built and trained the model, we need to save it. Saving the
    model will avoid having to train the model each time we wish to use it.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经构建并训练了模型，需要保存它。保存模型将避免每次使用时都重新训练模型。
- en: Saving the model
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保存模型
- en: By saving the model, we will not have to train it again every time to use it.
    We will only go back to training when it's required to fine-tune it.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 通过保存模型，我们就不需要每次使用时重新训练它。只有在需要微调时，我们才会重新进行训练。
- en: 'TensorFlow 2 provides a method to save the structure of the model and the weights
    in a single line of code and a single serialized file:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 2提供了一种方法，通过一行代码和一个序列化文件来保存模型的结构和权重：
- en: '`model3.h5` saved in the following code, contains serialized data with the
    model structure and weights. It contains the parameters and options of each layer.
    This information is very useful to fine-tune the model:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码中保存的`model3.h5`包含了模型结构和权重的序列化数据。它包含了每一层的参数和选项。这些信息对微调模型非常有用：
- en: '[PRE31]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The model has been built, trained, and saved.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 模型已经构建、训练并保存。
- en: Next steps
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下一步
- en: The model has been built and trained. In *Chapter 10*, *Conceptual Representation
    Learning*, we will explore how to load and run it with no training.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 模型已经构建并训练完成。在*第10章*，*概念表示学习*中，我们将探索如何加载并运行该模型，而无需重新训练。
- en: Summary
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Building and training a CNN will only succeed with hard work, choosing the model,
    the right datasets, and hyperparameters. The model must contain convolutions,
    pooling, flattening, dense layers, activation functions, and optimizing parameters
    (weights and biases) to form solid building blocks to train and use a model.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 构建和训练CNN只有通过辛勤工作、选择模型、合适的数据集和超参数才能成功。模型必须包含卷积、池化、展平、全连接层、激活函数和优化参数（权重和偏差），这些都是训练和使用模型的坚实基础。
- en: Training a CNN to solve a real-life problem can help sell AI to a manager or
    a sales prospect. In this case, using the model to help a food-processing factory
    solve a conveyor belt productivity problem takes AI a step further into everyday
    corporate life.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 训练CNN以解决现实生活中的问题可以帮助向经理或销售潜在客户推销AI。在这种情况下，使用该模型帮助食品加工厂解决输送带生产力问题，进一步将AI引入日常企业生活。
- en: A CNN that recognizes abstract concepts within an image takes deep learning
    one step closer to powerful machine thinking. A machine that can detect objects
    in an image and extract concepts from the results represents the true final level
    of AI.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 一个能够识别图像中抽象概念的CNN将深度学习推向更强大的机器思维。能够检测图像中的物体并从结果中提取概念的机器代表了AI的真正最终水平。
- en: Once the training is over, saving the model provides a practical way to use
    it by loading it and applying it to new images to classify them. This chapter
    concluded after we had trained and saved the model.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦训练完成，保存模型提供了一种实用的方法，可以通过加载并应用它来对新图像进行分类。本章在我们训练并保存模型后结束。
- en: '*Chapter 10*, *Conceptual Representation Learning*, will dive deeper into how
    to design symbolic neural networks.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '*第10章*，*概念表示学习*将深入探讨如何设计符号神经网络。'
- en: Questions
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: A CNN can only process images. (Yes | No)
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CNN只能处理图像。（是 | 否）
- en: A kernel is a preset matrix used for convolutions. (Yes | No)
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 核函数是用于卷积的预设矩阵。（是 | 否）
- en: Does pooling have a pooling matrix, or is it random?
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 池化是否有池化矩阵，还是随机的？
- en: The size of the dataset always has to be large. (Yes | No)
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集的大小总是需要很大。（是 | 否）
- en: Finding a dataset is not a problem with all the available image banks on the
    web. (Yes | No)
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在网络上，所有可用的图像库使得找到数据集不再是问题。（是 | 否）
- en: Once a CNN is built, training it does not take much time. (Yes | No)
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦构建了CNN，训练它不会花费太多时间。（是 | 否）
- en: A trained CNN model applies to only one type of image. (Yes | No)
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练好的CNN模型只适用于一种类型的图像。（是 | 否）
- en: A quadratic loss function is not very efficient compared to a cross-entropy
    function. (Yes | No)
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相比于交叉熵函数，二次损失函数的效率较低。（是 | 否）
- en: The performance of a deep learning CNN does not present a real issue with modern
    CPUs and GPUs. (Yes | No)
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现代CPU和GPU的性能下，深度学习CNN的表现不再是一个实际问题。（是 | 否）
- en: Further reading and references
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读和参考资料
- en: 'TensorFlow 2: [https://www.tensorflow.org/beta](https://www.tensorflow.org/beta)'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'TensorFlow 2: [https://www.tensorflow.org/beta](https://www.tensorflow.org/beta)'
