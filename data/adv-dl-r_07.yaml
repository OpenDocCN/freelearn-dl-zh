- en: Image Classification and Recognition
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像分类和识别
- en: In the previous chapters, we looked at the process of developing deep neural
    network models for classification and regression problems. In both cases, we were
    dealing with structured data and the models were of the supervised learning type,
    where target variables were available. Images or pictures belong to the unstructured
    category of data. In this chapter, we will illustrate the use of deep learning
    neural networks for image classification and recognition using the Keras package
    with the help of an easy-to-follow example. We will get started with a small sample
    size to illustrate the steps involved in developing an image-classification model.
    We will apply this model to a supervised learning situation involving the labeling
    of images or pictures.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们讨论了为分类和回归问题开发深度神经网络模型的过程。在这两种情况下，我们处理的是结构化数据，且模型属于监督学习类型，目标变量是已知的。图像或照片属于非结构化数据类别。在本章中，我们将演示如何使用
    Keras 包，通过一个易于跟随的示例，使用深度学习神经网络进行图像分类和识别。我们将从一个小样本开始，说明开发图像分类模型的步骤。我们将把这个模型应用于一个涉及图像或照片标注的监督学习情境。
- en: Keras contains several built-in datasets for image classification, such as CIFAR10,
    CIFAR100, MNIST, and fashion-MNIST. CIFAR10 contains 50,000 32 x 32 color training
    images and 10,000 testing images with 10 label categories. CIFAR100, on the other
    hand, contains 50,000 32 x 32 color training images and 10,000 testing images
    with as many as 100 label categories. The MNIST dataset has 60,000 28 x 28 grayscale
    images for training and 10,000 images for testing with 10 different digits. The
    fashion-MNIST dataset has 60,000 28 x 28 grayscale images for training and 10,000
    images for testing with 10 fashion categories. These datasets are already in a
    format that can be used straightaway to develop deep neural network models with
    a minimal need for data-preparation-related steps. However, to get a better handle
    on dealing with image data, we will start by reading raw images from our computer
    into RStudio and go over all the steps needed to make image data ready for building
    a classification model.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 包含几个内置的数据集，用于图像分类，例如 CIFAR10、CIFAR100、MNIST 和 fashion-MNIST。CIFAR10 包含
    50,000 张 32 x 32 彩色训练图像和 10,000 张测试图像，包含 10 个标签类别。CIFAR100 包含 50,000 张 32 x 32
    彩色训练图像和 10,000 张测试图像，包含多达 100 个标签类别。MNIST 数据集包含 60,000 张 28 x 28 灰度图像用于训练，10,000
    张图像用于测试，涵盖 10 个不同的数字。fashion-MNIST 数据集包含 60,000 张 28 x 28 灰度图像用于训练，10,000 张图像用于测试，包含
    10 个时尚类别。这些数据集已经是可以直接用于开发深度神经网络模型的格式，几乎不需要数据准备步骤。然而，为了更好地处理图像数据，我们将从将原始图像从计算机读取到
    RStudio 开始，并逐步介绍准备图像数据以构建分类模型的所有步骤。
- en: The steps involved include exploring image data, resizing and reshaping images,
    one-hot encoding, developing a sequential model, compiling the model, fitting
    the model, evaluating the model, making predictions, and model-performance assessment
    using a confusion matrix.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 相关步骤包括探索图像数据、调整图像大小和形状、进行独热编码、开发顺序模型、编译模型、拟合模型、评估模型、进行预测，并使用混淆矩阵评估模型性能。
- en: 'More specifically, in this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，在本章中，我们将覆盖以下主题：
- en: Handling image data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理图像数据
- en: Data preparation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据准备
- en: Creating and fitting the model
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和拟合模型
- en: Model evaluation and prediction
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型评估与预测
- en: Performance optimization tips and best practices
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能优化建议和最佳实践
- en: Handling image data
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理图像数据
- en: 'In this section, we will read image data into R and explore it further to understand
    the various characteristics of image data. The code for reading and displaying
    images is as follows:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将把图像数据读取到 R 中，并进一步探索以了解图像数据的各种特性。读取和显示图像的代码如下：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see from the preceding code, we will make use of the `keras` and
    `EBImage` libraries. The `EBImage` library is useful for handling and exploring
    image data. We will start by reading 18 JPEG image files that are stored in the `image18`
    folder of my computer. These images each contain 6 pictures of bicycles, cars,
    and airplanes that were downloaded from the internet. These image files are read
    using the `readImage` function and are stored in `mypic`.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面的代码所示，我们将使用 `keras` 和 `EBImage` 库。`EBImage` 库对于处理和探索图像数据非常有用。我们将从读取保存在我计算机的
    `image18` 文件夹中的 18 张 JPEG 图像文件开始。这些图像每个包含 6 张来自互联网的自行车、汽车和飞机照片。我们将使用 `readImage`
    函数读取这些图像文件，并将其存储在 `mypic` 中。
- en: 'All 18 images are shown in the following screenshot:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了所有18张图片：
- en: '![](img/44e3c243-de5b-4199-b4ae-dd2183181391.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](img/44e3c243-de5b-4199-b4ae-dd2183181391.png)'
- en: 'From the preceding screenshot, we can see the six images of bicycles, cars,
    and airplanes. You might have noticed that not all of the pictures are of the
    same size. For example, the fifth and sixth bicycles noticeably vary in size.
    Similarly, the fourth and fifth airplanes are clearly of different sizes, too.
    Let''s take a closer look at the data for the fifth bicycle using the following
    code:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的截图中，我们可以看到六张关于自行车、汽车和飞机的图片。你可能注意到，并不是所有图片的大小都相同。例如，第五和第六张自行车的尺寸明显不同。同样，第四和第五张飞机的尺寸也明显不同。让我们通过以下代码详细查看第五张自行车的数据：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using the `print` function, we can look at how the image of a bicycle (unstructured
    data) has been converted into numbers (structured data). The dimensions for the
    fifth bicycle are 299 x 169 x 3, which leads to a total of 151,593 data points,
    or pixels, obtained by multiplying the three numbers. The first number, 299, represents
    the image width in terms of pixels and the second number, 169, represents the
    image height in terms of pixels. Note that a colored image consists of three channels
    representing the colors red, blue, and green. The small table extracted from the
    data shows the first five rows of data in the *x*-dimension, and the first six
    rows of data in the *y*-dimension, and the value for the *z*-dimension is one.
    Although all values in the body of the table are `1`, they are expected to vary
    between `0` and `1`.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`print`函数，我们可以查看自行车的图像（非结构化数据）是如何转化为数字（结构化数据）的。第五张自行车的尺寸为299 x 169 x 3，总共有151,593个数据点或像素，这是通过将这三个数字相乘得到的。第一个数字299表示图像的宽度（以像素为单位），第二个数字169表示图像的高度（以像素为单位）。请注意，彩色图像由三个通道组成，分别代表红色、蓝色和绿色。从数据中提取的小表格显示了*x*维度的前五行数据，*y*维度的前六行数据，而*z*维度的值为1。尽管表格中的所有值都是`1`，但它们应该在`0`和`1`之间变化。
- en: A color image has red, green, and blue channels. A grayscale image has only
    one channel.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 彩色图像具有红色、绿色和蓝色通道。而灰度图像只有一个通道。
- en: 'These data points for the fifth bicycle are used for creating a histogram,
    as shown in the following screenshot:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了用于创建直方图的第五张自行车的数据：
- en: '![](img/e4f078ef-6f58-4453-80e3-65b411e56765.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e4f078ef-6f58-4453-80e3-65b411e56765.png)'
- en: The preceding histogram shows the distribution of intensity values for the fifth
    image's data. It can be seen that most of the data points have high-intensity
    values for this image.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的直方图显示了第五张图片数据的强度值分布。可以看出，大多数数据点的强度值较高。
- en: 'Let''s now look at the following histogram of data based on the 16th image
    (that of an airplane) for comparison:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来看一下基于第16张图片（飞机）的数据直方图进行对比：
- en: '![](img/00dbaf85-4c53-4c46-a5d5-fcfb93c55782.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00dbaf85-4c53-4c46-a5d5-fcfb93c55782.png)'
- en: From the preceding histogram, we can see that this image has different intensity
    values for the red, green, and blue colors. In general, intensity values lie between
    zero and one. Data points that are closer to zero represent a darker color in
    the image and those closer to one indicate a brighter color in the image.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的直方图可以看出，这张图片的红色、绿色和蓝色通道有不同的强度值。一般来说，强度值介于零和一之间。接近零的数据点代表图像中较暗的颜色，而接近一的数据点表示图像中的较亮颜色。
- en: 'Let''s take a look at data related to the 16th image, of an airplane, using
    the following code:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过以下代码查看与第16张图片（飞机）相关的数据：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: From the output provided in the preceding code, we can see that the two images
    have different dimensions. The dimensions for the 16th image are 318 x 159 x 3,
    which results in a total of 151,686 data points or pixels.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面代码的输出结果来看，我们可以看到这两张图片的尺寸不同。第16张图片的尺寸为318 x 159 x 3，总共有151,686个数据点或像素。
- en: In order to prepare this data for developing an image classification model,
    we will start by resizing all images to the same dimensions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备这些数据以开发图像分类模型，我们将从调整所有图片的大小到相同尺寸开始。
- en: Data preparation
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据准备
- en: In this section, we will go over the steps for making our image data ready for
    developing an image classification model. These steps will involve resizing images
    to obtain the same size for all images, followed by reshaping, data partitioning,
    and the one-hot encoding of the response variables.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍使图像数据准备好用于开发图像分类模型的步骤。这些步骤将涉及调整图像大小以确保所有图像具有相同的尺寸，然后进行重塑、数据划分和响应变量的热编码。
- en: Resizing and reshaping
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整大小和重塑
- en: 'To prepare the data for developing a classification model, we start by resizing
    the dimensions of all 18 images to the same size using the following code:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备数据以开发分类模型，我们首先使用以下代码将所有18张图像的维度调整为相同的大小：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As can be seen from the preceding code, all images are now resized to 28 x
    28 x 3\. Let''s plot all the images again to see the impact of resizing using
    the following code:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码可以看到，所有图像现在的大小已调整为28 x 28 x 3。我们可以使用以下代码再次绘制所有图像，看看调整大小的影响：
- en: '[PRE4]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'When we reduce the dimensions of a picture, it will lead to a lower number
    of pixels, which in turn will cause pictures to have lower quality, as can be
    seen in the following screenshot:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们减少图像的维度时，它将导致像素数减少，从而导致图像质量降低，正如以下截图所示：
- en: '![](img/0e274d67-8078-4686-97f5-f43f485b07b4.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0e274d67-8078-4686-97f5-f43f485b07b4.png)'
- en: 'Next, we will reshape the dimensions of 28 x 28 x 3 into a single dimension
    of 28 x 28 x 3 (or 2,352 vectors) using the following code:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用以下代码将28 x 28 x 3的维度重塑为28 x 28 x 3的单维度（或2,352个向量）：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: By observing the structure of the preceding data using `str(mypic)`, we can
    see that there are 18 different items in the list that correspond to the 18 images
    that we started with.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用`str(mypic)`观察前面数据的结构，我们可以看到列表中有18个不同的项，分别对应我们开始时的18张图像。
- en: Next, we will create training, validation, and test data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建训练、验证和测试数据。
- en: Training, validation, and test data
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练、验证和测试数据
- en: 'We will use the first three images of the bicycles, cars, and airplanes respectively
    for training, the fourth image of each type for validation, and the remaining
    two images of each type for testing. Thus, the training data will have nine images,
    the validation data will have three images, and the test data will have six images.
    The following is the code to achieve this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将分别使用自行车、汽车和飞机的前三张图像进行训练，每种类型的第四张图像用于验证，剩下的每种类型的两张图像用于测试。因此，训练数据将包含九张图像，验证数据将包含三张图像，测试数据将包含六张图像。以下是实现此操作的代码：
- en: '[PRE6]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you can see from the preceding code, we will use the `rbind` function to
    combine the rows of data that we have for each image when creating training, validation,
    and `test` data. After combining the rows of data from the nine images, the structure
    of `trainx` indicates that there are 9 rows and 2,352 columns. Similarly, for
    the validation data, we have 3 rows and 2,352 columns, and for the test data,
    we have 6 rows and 2,352 columns.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码可以看到，我们将使用`rbind`函数将我们为每个图像创建的训练、验证和`test`数据的行进行合并。将九个图像的数据行合并后，`trainx`的结构表明共有9行和2,352列。类似地，对于验证数据，我们有3行和2,352列，对于测试数据，我们有6行和2,352列。
- en: One-hot encoding
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 热编码
- en: 'For the one-hot encoding of the response variables, we use the following code:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对响应变量进行热编码时，我们使用以下代码：
- en: '[PRE7]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'From the preceding code, we can see the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码可以看到以下内容：
- en: We have stored target values for each image in `trainy` , `validy`, and `testy`,
    where `0`, `1`, and `2` indicate bicycle, car, and airplane images respectively.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已经将每个图像的目标值存储在`trainy`、`validy`和`testy`中，其中`0`、`1`和`2`分别表示自行车、汽车和飞机图像。
- en: We carry out one-hot encoding of `trainy` , `validy`, and `testy` by using the `to_categorical`
    function. One-hot encoding here helps to convert a factor variable into a combination
    of zeros and ones.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通过使用`to_categorical`函数对`trainy`、`validy`和`testy`进行了一次热编码。此处的热编码有助于将因子变量转换为零和一的组合。
- en: Now we have the data in a format that can be used for developing a deep neural
    network classification model, and that is what we will do in the next section.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将数据转换为可以用于开发深度神经网络分类模型的格式，这也是我们在下一节中将要做的事情。
- en: Creating and fitting the model
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建并拟合模型
- en: In this section, we will develop an image classification model to classify the
    images of the bicycles, cars, and airplanes. We will first specify a model architecture,
    then we will compile the model, and then fit the model using training and validation
    data.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将开发一个图像分类模型，用于分类自行车、汽车和飞机的图像。我们将首先指定模型架构，然后编译模型，再使用训练数据和验证数据拟合模型。
- en: Developing the model architecture
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开发模型架构
- en: 'When developing the model architecture, we start by creating a sequential model
    and then add various layers. The following is the code:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发模型架构时，我们从创建一个顺序模型开始，然后添加各种层。以下是代码：
- en: '[PRE8]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As can be seen from the preceding code, the input layer has  `2352` units (28
    x 28 x 3). For the initial model, we use two hidden layers with 256 and 128 units
    respectively. For both hidden layers, we will use the `relu` activation function.
    For the output layer, we will use 3 units since the target variable has 3 classes,
    representing a bicycle, car, and airplane. The total number of parameters for
    this model is 635,651.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的代码所示，输入层有 `2352` 个单元（28 x 28 x 3）。对于初始模型，我们使用两个隐藏层，分别具有 256 和 128 个单元。对于这两个隐藏层，我们将使用
    `relu` 激活函数。对于输出层，我们将使用 3 个单元，因为目标变量有 3 个类别，分别表示自行车、汽车和飞机。该模型的总参数数量为 635,651。
- en: Compiling the model
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编译模型
- en: 'After developing the model architecture, we can compile the model using the
    following code:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发完模型架构之后，我们可以使用以下代码编译模型：
- en: '[PRE9]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: We compile the model by using `categorical_crossentropy` for loss, since we
    are doing multiclass classification. We have specified `adam` and `accuracy` for
    the optimizer and metrics, respectively.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `categorical_crossentropy` 作为损失函数编译模型，因为我们正在进行多类分类。我们分别指定 `adam` 作为优化器和
    `accuracy` 作为度量标准。
- en: Fitting the model
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拟合模型
- en: 'Now we are ready to train the model. The following is the code for this:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备好训练模型了。以下是实现这一点的代码：
- en: '[PRE10]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'From the preceding code, we can see the following facts:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以得出以下结论：
- en: We can fit the model using `independent` variables stored in `trainx` and `target`
    variables stored in `trainLabels`. To safeguard against overfitting, we will use
    `validation_data`.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用存储在 `trainx` 中的 `independent` 变量和存储在 `trainLabels` 中的 `target` 变量来拟合模型。为了防止过拟合，我们将使用
    `validation_data`。
- en: Note that, in the previous chapters, we made use of `validation_split` by specifying
    a certain percentage, such as 20%; however, if we used `validation_split` with
    a 20% rate, it would have used the last 20% of the training data (all airplane
    images) for validation.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在前几章中，我们使用了 `validation_split` 并指定了一个百分比，例如 20%；然而，如果我们使用 20% 的 `validation_split`，它将使用训练数据的最后
    20%（所有飞机图像）作为验证数据。
- en: This would have created a situation where the training data had no sample from
    the airplane images and the classification model would have been based on bicycle
    and car images only.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这将导致一种情况，即训练数据中没有来自飞机图像的样本，而分类模型将仅基于自行车和汽车图像。
- en: Therefore, the resulting image classification model would be biased and would
    have performed well only with bicycle and car images. Therefore, instead of using
    the `validation_split `function, in this situation, we make use of `validation_data`, where
    we have made sure that we have a sample of each type represented in both the training
    and validation data.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，得到的图像分类模型会有偏差，并且仅对自行车和汽车图像表现良好。因此，在这种情况下，我们不使用`validation_split`函数，而是使用`validation_data`，并确保训练数据和验证数据中每种类型的样本都得到了充分代表。
- en: 'The following graphs show the loss and accuracy for 30 epochs separately for
    training and validation data:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表分别展示了训练数据和验证数据在 30 个 epoch 中的损失和准确度：
- en: '![](img/90692e5d-7fe2-4fd2-b639-2de1f207dc26.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/90692e5d-7fe2-4fd2-b639-2de1f207dc26.png)'
- en: 'We can make the following observations from the preceding plots:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从前面的图表中得出以下观察结果：
- en: From the parts of the graphs dealing with accuracy, we can see that from the
    eighteenth epoch onward, the accuracy values for the training data attain the
    highest value of 1.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从与准确度相关的图表部分，我们可以看到，从第十八个 epoch 开始，训练数据的准确度值达到了最高值 1。
- en: On the other hand, the accuracy based on the validation data is mainly around
    two thirds, or 66.7%. Since we have data from three images that is used for validation,
    if all three images' from validation data is correctly classified, the reported
    accuracy will be 1\. In this case, two out of three images are correctly classified,
    and that leads to accuracy of 66.7%.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，基于验证数据的准确度主要保持在三分之二左右，即66.7%。由于我们有来自三张图像的数据用于验证，如果这三张验证数据的图像都被正确分类，那么报告的准确度将为1。在这种情况下，三张图像中有两张被正确分类，导致准确度为66.7%。
- en: From the parts of the graphs dealing with loss, we can see that for the training
    data, the loss values drop significantly from about 3 to less than 1 after 8 epochs.
    They continue to reduce from then on; however, the rate of decrease in the loss
    values slows down.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从处理损失的图表部分，我们可以看到，对于训练数据，损失值从大约3下降到1以下，经过8个周期后下降显著。之后，它们继续下降；然而，损失值的下降速度放缓。
- en: An approximately similar pattern can be seen based on the validation data.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于验证数据，也可以看到一个大致相似的模式。
- en: In addition, since the loss uses probability values in its calculation, we observe
    a clearer trend for the loss-related plot compared to the accuracy-related plot.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，由于损失在计算中使用了概率值，我们观察到与准确度相关的图表相比，损失相关图表呈现出更加明显的趋势。
- en: Next, let's evaluate the model's image classification performance in greater
    detail to understand its behavior.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将更详细地评估模型的图像分类性能，以便了解其行为。
- en: Model evaluation and prediction
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型评估与预测
- en: In this section, we will carry out model evaluation and create a confusion matrix
    with the help of predictions, both for training and test data. Let's start by
    evaluating the image classification performance of the model using training data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将进行模型评估，并借助预测结果创建训练数据和测试数据的混淆矩阵。我们从使用训练数据评估图像分类性能开始。
- en: Loss, accuracy, and confusion matrices for training data
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练数据的损失、准确度和混淆矩阵
- en: 'We will now obtain loss and accuracy values for the training data and then
    create a confusion matrix using the following code:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先获取训练数据的损失和准确度值，然后使用以下代码创建混淆矩阵：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As you can see from the preceding output, the loss and accuracy values are `0.056`
    and `1` respectively. The confusion matrix based on the training data indicates
    that all nine images are correctly classified into three categories, and therefore
    the resulting accuracy is 1.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的输出所示，损失值和准确度值分别为`0.056`和`1`。基于训练数据的混淆矩阵显示，所有九张图像都已正确分类到三个类别中，因此 resulting的准确度为1。
- en: Prediction probabilities for training data
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练数据的预测概率
- en: 'We can now look at the probabilities of the three classes for all nine images
    in the training data that this model provides. The following is the code:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以查看该模型为训练数据中所有九张图像提供的三个类别的概率。以下是代码：
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In the preceding output, the first three columns show the probability of an
    image being a bicycle, car, or airplane, and the total of these three probabilities
    is 1\. We can make the following observations from the output:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，前三列显示了图像属于自行车、汽车或飞机的概率，这三者的总和为1。我们可以从输出中做出以下观察：
- en: The probabilities for the first image in the training data are `0.943`, `0.007`,
    and `0.049` for bicycle, car, and airplane respectively. Since the highest probability
    is for the first class, the predicted class based on the model is `0` (for bicycle),
    and this is also the actual class of the image.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练数据中第一张图像的分类概率分别为：自行车`0.943`，汽车`0.007`，飞机`0.049`。由于最高概率对应于第一个类别，因此模型预测的类别是`0`（自行车），这也是该图像的实际类别。
- en: Although all 9 images are correctly classified, the probability of correct classification
    varies from `0.806` (image 2) to `0.998` (image 5).
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管所有9张图像都已正确分类，但正确分类的概率从`0.806`（图像2）到`0.998`（图像5）不等。
- en: For the car images (rows 4 to 6), the probability of correct classification
    ranges from `0.989` to `0.998` and is consistently high for all three images.
    Therefore, this classification model gives its best performance when classifying
    car images.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于汽车图像（第4行到第6行），正确分类的概率从`0.989`到`0.998`，并且所有三张图像的概率都 consistently很高。因此，当分类汽车图像时，该分类模型表现最佳。
- en: For bicycle images (rows 1 to 3), the probability of correct classification
    ranges from `0.806` to `0.956`, which indicates some difficulty in correctly classifying
    bicycle images.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于自行车图像（第1到第3行），正确分类的概率范围从`0.806`到`0.956`，这表明正确分类自行车图像存在一定难度。
- en: For the second sample, which represents a bicycle image, the second-highest
    probability is `0.189` of being an airplane image. Clearly, this model is little
    bit confused when it comes to deciding whether this image is a bicycle or an airplane.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于第二个样本，它代表了一张自行车图像，其第二高的概率为`0.189`，即被判定为飞机图像。显然，当模型决定这张图像是自行车还是飞机时，它有些困惑。
- en: For the airplane images (rows 7 to 9), the probability of correct classification
    ranges from `0.931` to `0.959`, which is  also consistently high for all three
    images.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于飞机图像（第7到第9行），正确分类的概率范围从`0.931`到`0.959`，并且所有三张图像的概率都保持在较高水平。
- en: Looking at prediction probabilities allows us to dig deeper into the classification
    performance of the model, which cannot be obtained only by looking at the accuracy
    value. However, while good performance with training data is necessary, it is
    not sufficient to arrive at a reliable image-classification model. When a classification
    model suffers from an overfitting problem, we have difficulty replicating good
    results based on training data on test data that the model has not seen. Therefore,
    a real test of a good classification model is when it performs well with the test
    data. Let's now review the image-classification performance of the model for test
    data.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 观察预测概率让我们能更深入地分析模型的分类性能，这些是仅通过查看准确率值无法获得的。然而，尽管在训练数据上表现良好是必要的，但它不足以构建一个可靠的图像分类模型。当分类模型出现过拟合问题时，我们很难在测试数据上复制基于训练数据获得的好结果。
    因此，检验一个优秀分类模型的真正标准是它在测试数据上的表现。现在让我们回顾一下该模型在测试数据上的图像分类性能。
- en: Loss, accuracy, and confusion matrices for test data
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试数据的损失、准确率和混淆矩阵
- en: 'We can now obtain loss and accuracy values for the test data and then create
    a confusion matrix using the following code:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以获取测试数据的损失和准确率值，然后使用以下代码创建混淆矩阵：
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As you can see from the preceding output, the loss and accuracy values for the
    images in the test data are `0.552` and `0.833` respectively. These results are
    slightly inferior to the numbers that we saw for the training data; however, some
    amount of performance deterioration is expected when a model is assessed based
    on unseen data. The confusion matrix indicates one incorrectly classified image,
    where an image of a car is mistaken for an image of an airplane. Therefore, with
    five out of six correct classifications, the model accuracy based on the test
    data is 83.3%. Let's now look more deeply into the model's prediction performance
    by investigating the probability values based on images in the test data.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中可以看到，测试数据中图像的损失值和准确率值分别为`0.552`和`0.833`。这些结果略逊色于训练数据的数值；然而，当模型在未见过的数据上进行评估时，性能出现一些下降是可以预期的。混淆矩阵显示有一张图像被错误分类，其中一张汽车图像被误判为飞机图像。因此，基于测试数据的模型准确率为83.3%，正确分类了六张中的五张。现在我们通过研究基于测试数据图像的概率值，进一步分析模型的预测性能。
- en: Prediction probabilities for test data
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试数据的预测概率
- en: 'We can now review the probabilities for the three classes for all six images
    in the test data. The following is the code:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以回顾测试数据中所有六张图像的三种类别的概率。以下是代码：
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Looking at these predicted probabilities, we can make the following observations:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看这些预测概率，我们可以得出以下观察结果：
- en: Bicycle images are predicted correctly, as shown by the first two samples. However,
    prediction probabilities are relatively lower at `0.587` and `0.533`.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自行车图像的预测是正确的，如前两个样本所示。然而，预测概率相对较低，分别为`0.587`和`0.533`。
- en: The results for car images (rows 3 and 4) are mixed, with the fourth sample,
    correctly predicted with a high probability of `0.985`, but the third car image
    is misclassified as an airplane with about `0.7` probability.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 汽车图像（第3和第4行）的结果混合，第4个样本被正确预测，并具有`0.985`的高概率，而第3张汽车图像则被误分类为飞机，概率约为`0.7`。
- en: Airplane images are represented by the fifth and sixth samples. The prediction
    probabilities for these two images are `0.739` and `0.867` respectively.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 飞机图像由第五和第六个样本表示。这两张图像的预测概率分别为`0.739`和`0.867`。
- en: Although five out of six images are correctly classified, many prediction probabilities
    are relatively low when compared to the model's performance on training data.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管六张图像中有五张被正确分类，但与模型在训练数据上的表现相比，许多预测概率相对较低。
- en: Therefore, overall, we can say that there is definitely some scope to improve
    the model's performance further. In the next section, we will explore improving
    the model's performance.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总体而言，我们可以说模型的性能确实还有进一步提升的空间。在下一节中，我们将探讨如何提高模型的性能。
- en: Performance optimization tips and best practices
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 性能优化技巧和最佳实践
- en: In this section, we will explore a deeper network for improving the performance
    of the image-classification model. We will look at the results for comparison.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨一个更深的网络，以提高图像分类模型的性能。我们将查看结果进行对比。
- en: Deeper networks
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更深的网络
- en: 'The code used for experimenting with a deeper network in this section are as
    follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，用于实验更深网络的代码如下：
- en: '[PRE15]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'From the preceding code, we can see the following:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 从前述代码中，我们可以看到以下内容：
- en: We are increasing the number of units in the first and second hidden layers
    to `512` and `256` respectively.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将第一层和第二层隐藏层的单元数分别增加到`512`和`256`。
- en: We are also adding dropout layers after each hidden layer with a 10% dropout
    rate.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还在每个隐藏层后添加了丢弃层，丢弃率为10%。
- en: The total number of parameters with this change has now gone up to `1336835`.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行此更改后，参数总数已增加到`1336835`。
- en: This time, we will also run the model for 50 epochs. We do not make any other
    changes to the model.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这次，我们还将运行模型进行50个周期。我们不会对模型做其他更改。
- en: 'The following graphs provide accuracy and loss values for the training and
    validation data for 50 epochs:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表提供了50个周期内训练数据和验证数据的准确度和损失值：
- en: '![](img/b84682d8-3b5d-46f7-9e11-b4a021d69b5c.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b84682d8-3b5d-46f7-9e11-b4a021d69b5c.png)'
- en: 'From the preceding graphs, we can see the following:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 从前述图表中，我们可以看到以下内容：
- en: There are some major changes observed in the accuracy and loss values compared
    to the earlier model.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与之前的模型相比，我们观察到准确度和损失值有一些显著变化。
- en: The accuracy for both the training and validation data after 50 epochs is 100%.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经过50个周期后，训练数据和验证数据的准确度均达到了100%。
- en: In addition, the closeness of the training- and validation-related curves for
    loss and accuracy indicate that this image-classification model is not likely
    to suffer from an overfitting problem.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，训练数据和验证数据的损失与准确度曲线的接近度表明，这个图像分类模型不太可能遭遇过拟合问题。
- en: Results
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果
- en: 'To further explore any changes in the image-classification performance of the
    model that may not be obvious from a graphical summary, let''s look at some numerical
    summaries:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步探索模型在图像分类性能方面的变化，尤其是那些图形摘要中不容易发现的变化，我们来查看一些数值摘要：
- en: 'We will look at the results based on the training data first, and will make
    use of the following code:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将首先查看基于训练数据的结果，并将使用以下代码：
- en: '[PRE16]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: From the preceding output, we can see that the loss value has now reduced to
    `0.034` and the accuracy is maintained at `1.0`. We obtain the same confusion
    matrix results for the training data as we did earlier as all nine images are
    correctly classified by the model, which gives an accuracy level of 100%.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 从前述输出中，我们可以看到损失值现在已降至`0.034`，且准确度保持在`1.0`。我们得到了与之前相同的混淆矩阵结果，因为模型正确分类了所有九张图像，准确度为100%。
- en: 'To look more deeply at the classification performance of the model, we make
    use of the following code and output:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了更深入地了解模型的分类性能，我们使用以下代码和输出：
- en: '[PRE17]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'From the preceding prediction probabilities that we obtain as an output of
    the training data, we can make the following observations:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们从训练数据输出中获得的前述预测概率，我们可以做出以下观察：
- en: Correct classifications are now made with higher probability values than the
    earlier model.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正确分类现在比之前的模型具有更高的概率值。
- en: The lowest correct classification probability based on the second row is `0.899`.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据第二行，最低的正确分类概率为`0.899`。
- en: Therefore, this model seems to be more sure when correctly classifying images
    compared to what was observed with the previous model.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，与前一个模型相比，这个模型在正确分类图像时似乎更加确信。
- en: 'Now let''s see whether this improvement is also seen with the test data. We
    will use the following codes and output:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们看看这种改进是否也出现在测试数据上。我们将使用以下代码和输出：
- en: '[PRE18]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As indicated in the preceding output, the test data loss and accuracy values
    are `0.401` and `0.833` respectively. We do see some improvement in loss values;
    however, the accuracy value is again the same as it was earlier. Looking at the
    confusion matrix, we can see that this time, an image of a car is misclassified
    as an airplane. Therefore, we do not see any major differences based on the confusion
    matrix.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如前述输出所示，测试数据的损失值和准确率分别为 `0.401` 和 `0.833`。我们确实看到损失值有所改善；然而，准确率值仍与之前相同。通过查看混淆矩阵，我们可以看到这一次，一张汽车的图像被错误分类为飞机。因此，我们没有看到基于混淆矩阵的任何重大差异。
- en: 'Next, let''s review the prediction probabilities using the following code and
    its output:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们通过以下代码及其输出回顾预测概率：
- en: '[PRE19]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Using the prediction probabilities for the test data, we can make the following
    two observations:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 使用测试数据的预测概率，我们可以做出以下两点观察：
- en: We see a consistently similar pattern to the one that we observed based on the
    results from the training data. This model correctly classifies images in the
    test data with higher probabilities (`0.74` to `0.99`) than the earlier model
    (`0.53` to `0.98`).
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们看到的模式与在训练数据结果中观察到的模式一致。该模型正确地将测试数据中的图像分类为具有比早期模型（`0.53` 到 `0.98`）更高的概率（`0.74`
    到 `0.99`）。
- en: For the fourth sample in the test data, the model seems to be confused between
    the image of a bicycle and an airplane, when in reality, this image is of a car.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于测试数据中的第四个样本，模型似乎在自行车和飞机的图像之间感到困惑，而实际上，这张图像是汽车的图像。
- en: Therefore, overall, we have observed that by developing a deeper neural network,
    we are able to improve the model's performance. The improvement in the performance
    was not obvious from the accuracy calculation; however, the calculation of prediction
    probabilities allowed us to develop better insights and compare model performance.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总的来说，我们观察到，通过开发更深的神经网络，我们能够提高模型的性能。虽然从准确度计算中无法明显看到性能提升；然而，预测概率的计算使我们能够获得更好的洞察力，并比较模型的表现。
- en: Summary
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored image data and a deep neural network image-classification
    model. We used data from 18 images of bicycles, cars, and airplanes, and carried
    out appropriate data processing to make the data ready to use with the Keras library.
    We partitioned image data into training, validation, and test data, and subsequently
    developed a deep neural model using training data and evaluated its performance
    by looking at the loss, accuracy, confusion matrix, and probability values for
    both the training and test data. We also made modifications to the model to improve
    its classification performance. In addition, we observed that when the confusion
    matrix provides the same level of performance, prediction probabilities may be
    able to help in extracting finer differences between the two models.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探索了图像数据和深度神经网络图像分类模型。我们使用了来自 18 张自行车、汽车和飞机图像的数据，并进行了适当的数据处理，使数据能够与 Keras
    库兼容。我们将图像数据划分为训练数据、验证数据和测试数据，并随后使用训练数据开发了一个深度神经网络模型，并通过查看训练数据和测试数据的损失、准确率、混淆矩阵和概率值来评估其性能。我们还对模型进行了修改，以提高其分类性能。此外，我们观察到，当混淆矩阵提供相同水平的性能时，预测概率可能有助于提取两个模型之间的细微差异。
- en: In the next chapter, we will go over the steps to develop a deep neural network
    image-classification model using **convolutional neural networks** (**CNNs**),
    which are becoming very popular when it comes to image classification applications.
    CNNs are regarded as the gold standard for image-classification problems, and
    are very effective for large-scale image-classification applications.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍使用**卷积神经网络**（**CNNs**）开发深度神经网络图像分类模型的步骤，卷积神经网络在图像分类应用中越来越受欢迎。CNN
    被认为是图像分类问题的金标准，并且在大规模图像分类应用中非常有效。
