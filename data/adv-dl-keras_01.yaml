- en: Chapter 1. Introducing Advanced Deep Learning with Keras
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一章。介绍使用 Keras 的高级深度学习
- en: In this first chapter, we will introduce the three deep learning artificial
    neural networks that we will be using throughout the book. These deep learning
    models are MLPs, CNNs, and RNNs, which are the building blocks to the advanced
    deep learning topics covered in this book, such as Autoencoders and GANs.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍本书中将使用的三种深度学习人工神经网络。这些深度学习模型是 MLP、CNN 和 RNN，它们是本书中所涵盖的高级深度学习主题（如自编码器和
    GANs）的构建模块。
- en: Together, we'll implement these deep learning models using the Keras library
    in this chapter. We'll start by looking at why Keras is an excellent choice as
    a tool for us. Next, we'll dig into the installation and implementation details
    within the three deep learning models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将一起使用 Keras 库实现这些深度学习模型。我们将首先了解为什么 Keras 是我们使用的优秀工具。接下来，我们将深入探讨三种深度学习模型的安装和实现细节。
- en: 'This chapter will:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容将包括：
- en: Establish why the Keras library is a great choice to use for advanced deep learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释为什么 Keras 库是用于高级深度学习的绝佳选择。
- en: Introduce MLPs, CNNs, and RNNs – the core building blocks of most advanced deep
    learning models, which we'll be using throughout this book
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 MLP、CNN 和 RNN —— 这是大多数高级深度学习模型的核心构建模块，我们将在本书中使用它们。
- en: Provide examples of how to implement MLPs, CNNs, and RNNs using Keras and TensorFlow
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供如何使用 Keras 和 TensorFlow 实现 MLP、CNN 和 RNN 的示例。
- en: Along the way, start to introduce important deep learning concepts, including
    optimization, regularization, and loss function
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在过程中，我们将开始介绍一些重要的深度学习概念，包括优化、正则化和损失函数。
- en: By the end of this chapter, we'll have the fundamental deep learning models
    implemented using Keras. In the next chapter, we'll get into the advanced deep
    learning topics that build on these foundations, such as Deep Networks, Autoencoders,
    and GANs.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，我们将使用 Keras 实现基本的深度学习模型。在下一章中，我们将探讨基于这些基础的高级深度学习主题，如深度网络、自编码器和生成对抗网络（GANs）。
- en: Why is Keras the perfect deep learning library?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么 Keras 是完美的深度学习库？
- en: Keras [*Chollet, François. "Keras (2015)." (2017)*] is a popular deep learning
    library with over 250,000 developers at the time of writing, a number that is
    more than doubling every year. Over 600 contributors actively maintain it. Some
    of the examples we'll use in this book have been contributed to the official Keras
    GitHub repository. Google's **TensorFlow**, a popular open source deep learning
    library, uses Keras as a high-level API to its library. In the industry, Keras
    is used by major technology companies like Google, Netflix, Uber, and NVIDIA.
    In this chapter, we introduce how to use **Keras Sequential API**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Keras [*Chollet, François. "Keras (2015)." (2017)*] 是一个流行的深度学习库，写作时已有超过 250,000
    名开发者使用，每年这个数字翻倍。超过 600 名贡献者积极维护它。本书中使用的一些示例已贡献至官方 Keras GitHub 仓库。谷歌的**TensorFlow**，一个流行的开源深度学习库，将
    Keras 作为其高层 API。在工业界，Keras 被谷歌、Netflix、Uber 和 NVIDIA 等大公司广泛使用。本章中，我们将介绍如何使用 **Keras
    Sequential API**。
- en: We have chosen Keras as our tool of choice to work within this book because
    Keras is a library dedicated to accelerating the implementation of deep learning
    models. This makes Keras ideal for when we want to be practical and hands-on,
    such as when we're exploring the advanced deep learning concepts in this book.
    Because Keras is intertwined with deep learning, it is essential to learn the
    key concepts of deep learning before someone can maximize the use of Keras libraries.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择 Keras 作为本书中的工具，因为 Keras 是一个致力于加速深度学习模型实现的库。这使得 Keras 成为我们在实践和动手操作时的理想选择，尤其是在探索本书中的高级深度学习概念时。由于
    Keras 与深度学习紧密相连，在最大化使用 Keras 库之前，了解深度学习的关键概念是至关重要的。
- en: Note
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'All examples in this book can be found on GitHub at the following link: [https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras](https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的所有示例都可以在 GitHub 上找到，链接如下：[https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras](https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras)。
- en: Keras is a deep learning library that enables us to build and train models efficiently.
    In the library, layers are connected to one another like pieces of Lego, resulting
    in a model that is clean and easy to understand. Model training is straightforward
    requiring only data, a number of epochs of training, and metrics to monitor. The
    end result is that most deep learning models can be implemented with a significantly
    smaller number of lines of code. By using Keras, we'll gain productivity by saving
    time in code implementation which can instead be spent on more critical tasks
    such as formulating better deep learning algorithms. We're combining Keras with
    deep learning, as it offers increased efficiency when introduced with the three
    deep learning networks that we will introduce in the following sections of this
    chapter.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 是一个深度学习库，使我们能够高效地构建和训练模型。在该库中，层像乐高积木一样相互连接，生成的模型简洁且易于理解。模型训练非常直接，只需要数据、若干训练周期和用于监控的指标。最终结果是，大多数深度学习模型都可以通过显著更少的代码行数来实现。通过使用
    Keras，我们能够提高生产力，通过节省在代码实现上的时间，将其投入到更重要的任务中，例如制定更好的深度学习算法。我们将 Keras 与深度学习结合使用，因为在引入本章接下来部分的三种深度学习网络时，它能提供更高的效率。
- en: Likewise, Keras is ideal for the rapid implementation of deep learning models,
    like the ones that we will be using in this book. Typical models can be built
    in few lines of code using the **Sequential Model API**. However, do not be misled
    by its simplicity. Keras can also build more advanced and complex models using
    its API and `Model` and `Layer` classes which can be customized to satisfy unique
    requirements. Functional API supports building graph-like models, layers reuse,
    and models that are behaving like Python functions. Meanwhile, `Model` and `Layer`
    classes provide a framework for implementing uncommon or experimental deep learning
    models and layers.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，Keras 非常适合快速实现深度学习模型，就像我们将在本书中使用的模型一样。典型的模型可以通过少量的代码行使用 **Sequential Model
    API** 构建。然而，不要被它的简洁性误导。Keras 也可以通过其 API 和 `Model` 和 `Layer` 类构建更先进和复杂的模型，这些模型可以定制以满足独特的需求。功能性
    API 支持构建图形化的模型、层的重用以及表现像 Python 函数的模型。同时，`Model` 和 `Layer` 类提供了一个框架，用于实现不常见或实验性的深度学习模型和层。
- en: Installing Keras and TensorFlow
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Keras 和 TensorFlow
- en: Keras is not an independent deep learning library. As shown in *Figure 1.1.1*,
    it is built on top of another deep learning library or backend. This could be
    Google's **TensorFlow**, MILA's **Theano** or Microsoft's **CNTK**. Support for
    Apache's **MXNet** is nearly completed. We'll be testing examples in this book
    on a **TensorFlow backend using Python 3**. This due to the popularity of TensorFlow,
    which makes it a common backend.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 不是一个独立的深度学习库。如 *图 1.1.1* 所示，它建立在其他深度学习库或后端之上。可以是 Google 的 **TensorFlow**，MILA
    的 **Theano** 或 Microsoft 的 **CNTK**。对 Apache 的 **MXNet** 的支持几乎已经完成。我们将在本书中使用 **TensorFlow
    后端和 Python 3** 进行测试。之所以选择 TensorFlow，是因为它的流行，使其成为一个常见的后端。
- en: We can easily switch from one back-end to another by editing the Keras configuration
    file `.keras/keras.json` in Linux or macOS. Due to the differences in the way
    low-level algorithms are implemented, networks can often have different speeds
    on different backends.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过编辑 Linux 或 macOS 中的 Keras 配置文件 `.keras/keras.json`，轻松地在不同的后端之间切换。由于底层算法实现方式的不同，网络在不同的后端上可能会有不同的速度。
- en: On hardware, Keras runs on a CPU, GPU, and Google's TPU. In this book, we'll be testing
    on a CPU and NVIDIA GPUs (Specifically, the GTX 1060 and GTX 1080Ti models).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在硬件上，Keras 可以运行在 CPU、GPU 和 Google 的 TPU 上。在本书中，我们将使用 CPU 和 NVIDIA GPU（特别是 GTX
    1060 和 GTX 1080Ti 型号）进行测试。
- en: '![Installing Keras and TensorFlow](img/B08956_01_01.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![安装 Keras 和 TensorFlow](img/B08956_01_01.jpg)'
- en: 'Figure 1.1.1: Keras is a high-level library that sits on top of other deep
    learning models. Keras is supported on CPU, GPU, and TPU.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1.1：Keras 是一个高级库，建立在其他深度学习模型之上。Keras 支持在 CPU、GPU 和 TPU 上运行。
- en: 'Before proceeding with the rest of the book, we need to ensure that Keras and TensorFlow
    are correctly installed. There are multiple ways to perform the installation;
    one example is installing using `pip3`:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续阅读本书的其余内容之前，我们需要确保 Keras 和 TensorFlow 已正确安装。有多种方法可以进行安装；其中一种示例是使用 `pip3`
    安装：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If we have a supported NVIDIA GPU, with properly installed drivers, and both
    NVIDIA''s **CUDA** Toolkit and **cuDNN Deep Neural Network library**, it is recommended
    that we install the GPU-enabled version since it can accelerate both training
    and prediction:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们拥有支持的 NVIDIA GPU，并且已正确安装驱动程序，以及 NVIDIA 的 **CUDA** 工具包和 **cuDNN 深度神经网络库**，建议安装支持
    GPU 的版本，因为它可以加速训练和预测：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The next step for us is to then install Keras:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来的步骤是安装 Keras：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The examples presented in this book will require additional packages, such as
    `pydot`, `pydot_ng`, `vizgraph`, `python3-tk` and `matplotlib`. We'll need to
    install these packages before proceeding beyond this chapter.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的示例需要额外的包，如 `pydot`、`pydot_ng`、`vizgraph`、`python3-tk` 和 `matplotlib`。在继续进行本章后，请先安装这些包。
- en: 'The following should not generate any error if both TensorFlow and Keras are
    installed along with their dependencies:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果已安装 TensorFlow 和 Keras 及其依赖项，则以下内容不应产生任何错误：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The warning message about `SSE4.2 AVX AVX2 FMA`, which is similar to the one
    below can be safely ignored. To remove the warning message, you'll need to recompile
    and install the TensorFlow source code from [https://github.com/tensorflow/tensorflow](https://github.com/tensorflow/tensorflow).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 `SSE4.2 AVX AVX2 FMA` 的警告信息（如下所示）可以安全忽略。要去除警告信息，你需要从 [https://github.com/tensorflow/tensorflow](https://github.com/tensorflow/tensorflow)
    重新编译并安装 TensorFlow 源代码。
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This book does not cover the complete Keras API. We'll only be covering the
    materials needed to explain the advanced deep learning topics in this book. For
    further information, we can consult the official Keras documentation, which can
    be found at [https://keras.io](https://keras.io).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本书不覆盖完整的 Keras API。我们只会介绍解释本书中高级深度学习主题所需的材料。如需更多信息，请参考官方 Keras 文档，网址为 [https://keras.io](https://keras.io)。
- en: Implementing the core deep learning models - MLPs, CNNs, and RNNs
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现核心深度学习模型 - MLPs、CNNs 和 RNNs
- en: 'We''ve already mentioned that we''ll be using three advanced deep learning
    models, they are:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提到过，我们将使用三种高级深度学习模型，它们是：
- en: '**MLPs**: Multilayer perceptrons'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLPs**：多层感知机'
- en: '**RNNs**: Recurrent neural networks'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RNNs**：递归神经网络'
- en: '**CNNs**: Convolutional neural networks'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CNNs**：卷积神经网络'
- en: These are the three networks that we will be using throughout this book. Despite
    the three networks being separate, you'll find that they are often combined together
    in order to take advantage of the strength of each model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们在本书中将使用的三种网络。尽管这三种网络是独立的，但你会发现它们常常会结合在一起，以便充分利用每种模型的优势。
- en: In the following sections of this chapter, we'll discuss these building blocks
    one by one in more detail. In the following sections, MLPs are covered together
    with other important topics such as loss function, optimizer, and regularizer.
    Following on afterward, we'll cover both CNNs and RNNs.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的接下来的部分中，我们将逐一详细讨论这些构建模块。在随后的部分中，MLPs将与其他重要主题一起讨论，如损失函数、优化器和正则化器。之后，我们将覆盖
    CNNs 和 RNNs。
- en: The difference between MLPs, CNNs, and RNNs
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MLPs、CNNs 和 RNNs 之间的区别
- en: Multilayer perceptrons or MLPs are a fully-connected network. You'll often find
    them referred to as either deep feedforward networks or feedforward neural networks
    in some literature. Understanding these networks in terms of known target applications
    will help us get insights about the underlying reasons for the design of the advanced
    deep learning models. MLPs are common in simple logistic and linear regression
    problems. However, MLPs are not optimal for processing sequential and multi-dimensional
    data patterns. By design, MLPs struggle to remember patterns in sequential data
    and requires a substantial number of parameters to process multi-dimensional data.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 多层感知机（MLPs）是一个全连接网络。在一些文献中，你常常会看到它们被称为深度前馈网络或前馈神经网络。从已知的目标应用角度理解这些网络将帮助我们深入理解设计高级深度学习模型的基本原因。MLPs
    在简单的逻辑回归和线性回归问题中很常见。然而，MLPs 并不适合处理序列数据和多维数据模式。由于设计上的原因，MLPs 很难记住序列数据中的模式，并且需要大量的参数来处理多维数据。
- en: For sequential data input, RNNs are popular because the internal design allows
    the network to discover dependency in the history of data that is useful for prediction.
    For multi-dimensional data like images and videos, a CNN excels in extracting
    feature maps for classification, segmentation, generation, and other purposes.
    In some cases, a CNN in the form of a 1D convolution is also used for networks
    with sequential input data. However, in most deep learning models, MLPs, RNNs,
    and CNNs are combined to make the most out of each network.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于顺序数据输入，RNNs 因其内部设计允许网络发现对预测有用的历史数据依赖关系，因此非常受欢迎。对于多维数据，如图像和视频，CNN 在提取特征图以进行分类、分割、生成等方面表现出色。在某些情况下，CNN
    也以一维卷积的形式用于具有顺序输入数据的网络。然而，在大多数深度学习模型中，MLPs、RNNs 和 CNNs 会结合使用，以充分发挥每个网络的优势。
- en: MLPs, RNNs, and CNNs do not complete the whole picture of deep networks. There is
    a need to identify an *objective* or *loss function*, *an optimizer*, and a *regularizer*.
    The goal is to reduce the loss function value during training since it is a good
    guide that a model is learning. To minimize this value, the model employs an optimizer.
    This is an algorithm that determines how weights and biases should be adjusted
    at each training step. A trained model must work not only on the training data
    but also on a test or even on unforeseen input data. The role of the regularizer
    is to ensure that the trained model generalizes to new data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: MLPs、RNNs 和 CNNs 并没有完整展示深度网络的全貌。我们还需要识别一个*目标*或*损失函数*，*优化器*，以及一个*正则化器*。目标是在训练过程中减少损失函数的值，因为这可以作为模型正在学习的良好指引。为了最小化这个值，模型使用优化器。这是一个算法，用于确定每个训练步骤中权重和偏差应该如何调整。一个训练好的模型不仅要在训练数据上工作，还要在测试数据甚至是未曾预见的输入数据上有效。正则化器的作用是确保训练好的模型能够泛化到新数据。
- en: Multilayer perceptrons (MLPs)
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多层感知机（MLPs）
- en: The first of the three networks we will be looking at is known as a **multilayer
    perceptrons or (MLPs)**. Let's suppose that the objective is to create a neural
    network for identifying numbers based on handwritten digits. For example, when
    the input to the network is an image of a handwritten number 8, the corresponding
    prediction must also be the digit 8\. This is a classic job of classifier networks
    that can be trained using logistic regression. To both train and validate a classifier
    network, there must be a sufficiently large dataset of handwritten digits. The
    Modified National Institute of Standards and Technology dataset or MNIST for short,
    is often considered as the *Hello World!* of deep learning and is a suitable dataset
    for handwritten digit classification.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要查看的三种网络中的第一种被称为**多层感知机（MLPs）**。假设目标是创建一个神经网络，用于基于手写数字来识别数字。例如，当网络的输入是手写数字
    8 的图像时，相应的预测也必须是数字 8。这是分类器网络的经典任务，可以通过逻辑回归进行训练。为了训练和验证一个分类器网络，必须有一个足够大的手写数字数据集。修改版国家标准与技术研究院数据集（简称
    MNIST）通常被认为是深度学习的*Hello World!*，并且是一个适合手写数字分类的数据集。
- en: 'Before we discuss the multilayer perceptron model, it''s essential that we
    understand the MNIST dataset. A large number of the examples in this book use
    the MNIST dataset. MNIST is used to explain and validate deep learning theories
    because the 70,000 samples it contains are small, yet sufficiently rich in information:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论多层感知机模型之前，必须先理解 MNIST 数据集。书中大量的示例使用了 MNIST 数据集。MNIST 被用来解释和验证深度学习理论，因为它包含的
    70,000 个样本虽然不大，却包含了足够丰富的信息：
- en: '![Multilayer perceptrons (MLPs)](img/B08956_01_02.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![多层感知机（MLPs）](img/B08956_01_02.jpg)'
- en: 'Figure 1.3.1: Example images from the MNIST dataset. Each image is 28 × 28-pixel
    grayscale.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3.1：MNIST 数据集中的示例图像。每张图像为 28 × 28 像素的灰度图。
- en: MNIST dataset
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MNIST 数据集
- en: MNIST is a collection of handwritten digits ranging from the number 0 to 9\.
    It has a training set of 60,000 images, and 10,000 test images that are classified
    into corresponding categories or labels. In some literature, the term **target**
    or **ground truth** is also used to refer to the **label**.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: MNIST 是一个包含从 0 到 9 的手写数字集合。它有一个包含 60,000 张图像的训练集和 10,000 张测试图像，这些图像被分类到相应的类别或标签中。在一些文献中，**目标**或**真实标签**一词也用来指代**标签**。
- en: In the preceding figure sample images of the MNIST digits, each being sized
    at 28 X 28-pixel grayscale, can be seen. To use the MNIST dataset in Keras, an
    API is provided to download and extract images and labels automatically. *Listing 1.3.1*
    demonstrates how to load the MNIST dataset in just one line, allowing us to both
    count the train and test labels and then plot random digit images.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中可以看到MNIST数字的样本图像，每个图像的大小为28×28像素的灰度图。要在Keras中使用MNIST数据集，提供了一个API来自动下载和提取图像与标签。*Listing
    1.3.1*展示了如何用一行代码加载MNIST数据集，使我们能够计算训练集和测试集的标签数量，并随机绘制数字图像。
- en: 'Listing 1.3.1, `mnist-sampler-1.3.1.py`. Keras code showing how to access MNIST
    dataset, plot 25 random samples, and count the number of labels for train and
    test datasets:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Listing 1.3.1，`mnist-sampler-1.3.1.py`。Keras代码展示了如何访问MNIST数据集，绘制25个随机样本，并计算训练集和测试集标签的数量：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `mnist.load_data()` method is convenient since there is no need to load
    all 70,000 images and labels individually and store them in arrays. Executing
    `python3 mnist-sampler-1.3.1.py` on command line prints the distribution of labels
    in the train and test datasets:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '`mnist.load_data()`方法非常方便，因为不需要单独加载所有70,000张图像和标签并将其存储在数组中。在命令行中执行`python3
    mnist-sampler-1.3.1.py`会打印出训练集和测试集标签的分布：'
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Afterward, the code will plot 25 random digits as shown in the preceding figure,
    *Figure 1.3.1*.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，代码将绘制25个随机数字，如前面的图*图1.3.1*所示。
- en: 'Before discussing the multilayer perceptron classifier model, it is essential
    to keep in mind that while MNIST data are 2D tensors, they should be reshaped
    accordingly depending on the type of input layer. The following figure shows how
    a 3 × 3 grayscale image is reshaped for MLPs, CNNs, and RNNs input layers:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论多层感知机分类器模型之前，必须记住，虽然MNIST数据是二维张量，但应根据输入层的类型进行相应的重塑。下图展示了如何将一个3×3的灰度图像重塑为MLP、CNN和RNN的输入层：
- en: '![MNIST dataset](img/B08956_01_03.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![MNIST数据集](img/B08956_01_03.jpg)'
- en: 'Figure 1.3.2: An input image similar to the MNIST data is reshaped depending
    on the type of input layer. For simplicity, reshaping of a 3 × 3 grayscale image
    is shown.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3.2：一个类似于MNIST数据的输入图像，根据输入层的类型进行重塑。为简化起见，展示了如何将一个3×3的灰度图像进行重塑。
- en: MNIST digits classifier model
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: MNIST数字分类器模型
- en: The proposed MLP model shown in *Figure 1.3.3* can be used for MNIST digit classification.
    When the units or perceptrons are exposed, the MLP model is a fully connected
    network as shown in *Figure 1.3.4*. It will also be shown how the output of the
    perceptron is computed from inputs as a function of weights, *w*[i] and bias,
    *b* [n] for the n^(th) unit. The corresponding Keras implementation is illustrated
    in *Listing 1.3.2*.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图1.3.3*所示，提出的MLP模型可用于MNIST数字分类。当单元或感知机被展示时，MLP模型是一个完全连接的网络，如*图1.3.4*所示。接下来还会展示如何根据输入计算感知机的输出，作为权重*w*[i]和偏置*b*[n]（n为第n个单元）的函数。相应的Keras实现请参见*Listing
    1.3.2*。
- en: '![MNIST digits classifier model](img/B08956_01_04.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![MNIST数字分类器模型](img/B08956_01_04.jpg)'
- en: 'Figure 1.3.3: MLP MNIST digit classifier model'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3.3：MLP MNIST数字分类器模型
- en: '![MNIST digits classifier model](img/B08956_01_05.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![MNIST数字分类器模型](img/B08956_01_05.jpg)'
- en: 'Figure 1.3.4: The MLP MNIST digit classifier in Figure 1.3.3 is made up of
    fully connected layers. For simplicity, the activation and dropout are not shown.
    One unit or perceptron is also shown.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3.4：图1.3.3中的MLP MNIST数字分类器由全连接层组成。为简化起见，激活函数和dropout未显示。同时也展示了一个单元或感知机。
- en: 'Listing 1.3.2, `mlp-mnist-1.3.2.py` shows the Keras implementation of the MNIST
    digit classifier model using MLP:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Listing 1.3.2，`mlp-mnist-1.3.2.py`展示了使用MLP的MNIST数字分类器模型的Keras实现：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Before discussing the model implementation, the data must be in the correct
    shape and format. After loading the MNIST dataset, the number of labels is computed
    as:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论模型实现之前，数据必须是正确的形状和格式。加载MNIST数据集后，标签数量的计算方式如下：
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Hard coding `num_labels = 10` is also an option. But, it's always a good practice
    to let the computer do its job. The code assumes that `y_train` has labels 0 to
    9.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 硬编码`num_labels = 10`也是一种选择。但是，最好让计算机完成其工作。代码假设`y_train`包含标签0到9。
- en: At this point, the labels are in digits format, 0 to 9\. This sparse scalar
    representation of labels is not suitable for the neural network prediction layer
    that outputs probabilities per class. A more suitable format is called a **one-hot
    vector**, a 10-dim vector with all elements 0, except for the index of the digit
    class. For example, if the label is 2, the equivalent one-hot vector is `[0,0,1,0,0,0,0,0,0,0]`.
    The first label has index `0`.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，标签为数字格式，范围从0到9。标签的稀疏标量表示法不适用于输出每类概率的神经网络预测层。更合适的格式是称为**one-hot向量**的格式，这是一个10维向量，所有元素为0，除了数字类的索引。例如，如果标签是2，则等效的one-hot向量为`[0,0,1,0,0,0,0,0,0,0]`。第一个标签的索引为`0`。
- en: 'The following lines convert each label into a one-hot vector:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下几行将每个标签转换为one-hot向量：
- en: '[PRE9]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In deep learning, data is stored in **tensors**. The term tensor applies to
    a scalar (0D tensor), vector (1D tensor), matrix (2D tensor), and a multi-dimensional
    tensor. From this point, the term tensor is used unless scalar, vector, or matrix
    makes the explanation clearer.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，数据存储在**张量**中。张量一词适用于标量（0D张量）、向量（1D张量）、矩阵（2D张量）和多维张量。从现在开始，除非标量、向量或矩阵能使解释更清晰，否则将使用张量一词。
- en: The rest computes the image dimensions, `input_size` of the first `Dense` layer
    and scales each pixel value from 0 to 255 to range from 0.0 to 1.0\. Although
    raw pixel values can be used directly, it is better to normalize the input data
    as to avoid large gradient values that could make training difficult. The output
    of the network is also normalized. After training, there is an option to put everything
    back to the integer pixel values by multiplying the output tensor by 255.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 剩余部分计算图像尺寸，第一层`Dense`的`input_size`，并将每个像素值从0到255的范围缩放到0.0到1.0之间。虽然可以直接使用原始像素值，但最好对输入数据进行归一化，以避免大梯度值，这可能会使训练变得困难。网络的输出也会进行归一化。训练完成后，有一个选项可以通过将输出张量乘以255，将所有值恢复为整数像素值。
- en: The proposed model is based on MLP layers. Therefore, the input is expected
    to be a 1D tensor. As such, `x_train` and `x_test` are reshaped to [60000, 28
    * 28] and [10000, 28 * 28], respectively.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的模型基于MLP层。因此，输入预计为1D张量。因此，`x_train`和`x_test`分别被重塑为[60000, 28 * 28]和[10000,
    28 * 28]。
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Building a model using MLPs and Keras
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用MLP和Keras构建模型
- en: After data preparation, building the model is next. The proposed model is made
    of three MLP layers. In Keras, an MLP layer is referred to as **Dense**, which
    stands for the densely connected layer. Both the first and second MLP layers are
    identical in nature with 256 units each, followed by `relu` activation and `dropout`.
    256 units are chosen since 128, 512 and 1,024 units have lower performance metrics.
    At 128 units, the network converges quickly, but has a lower test accuracy. The
    added number units for 512 or 1,024 does not increase the test accuracy significantly.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 数据准备好后，接下来是构建模型。提议的模型由三层MLP构成。在Keras中，MLP层被称为**Dense**，即密集连接层。第一层和第二层MLP在结构上完全相同，每层有256个单元，后跟`relu`激活和`dropout`。选择256个单元是因为128、512和1,024个单元的性能指标较低。在128个单元时，网络收敛较快，但测试准确率较低。增加512或1,024个单元并未显著提高测试准确率。
- en: The number of units is a **hyperparameter**. It controls the *capacity* of the
    network. The capacity is a measure of the complexity of the function that the
    network can approximate. For example, for polynomials, the degree is the hyperparameter.
    As the degree increases, the capacity of the function also increases.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 单元数是一个**超参数**。它控制网络的*容量*。容量是网络能够逼近的函数复杂度的度量。例如，对于多项式，次数就是超参数。随着次数的增加，函数的容量也随之增加。
- en: As shown in the following model, the classifier model is implemented using a sequential
    model API of Keras. This is sufficient if the model requires one input and one
    output processed by a sequence of layers. For simplicity, we'll use this in the meantime,
    however, in [Chapter 2](ch02.html "Chapter 2. Deep Neural Networks"), *Deep Neural
    Networks*, the Functional API of Keras will be introduced to implement advanced
    deep learning models.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示的模型，分类器模型是使用Keras的顺序模型API实现的。如果模型只需要一个输入和一个输出，并通过一系列层进行处理，这种方法已经足够简单。为了简单起见，我们暂时使用这个方法，但在[第2章](ch02.html
    "第2章. 深度神经网络")《深度神经网络》中，将介绍Keras的函数式API来实现更复杂的深度学习模型。
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Since a `Dense` layer is a linear operation, a sequence of `Dense` layers can
    only approximate a linear function. The problem is that the MNIST digit classification
    is inherently a non-linear process. Inserting a `relu` activation between `Dense`
    layers will enable MLPs to model non-linear mappings. `relu` or **Rectified Linear
    Unit** (**ReLU**) is a simple non-linear function. It''s very much like a filter
    that allows positive inputs to pass through unchanged while clamping everything
    else to zero. Mathematically, `relu` is expressed in the following equation and
    plotted in *Figure 1.3.5*:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `Dense` 层是线性操作，若仅有一系列 `Dense` 层，它们只能逼近线性函数。问题在于，MNIST 手写数字分类本质上是一个非线性过程。在
    `Dense` 层之间插入 `relu` 激活函数将使得多层感知机（MLP）能够建模非线性映射。`relu` 或 **修正线性单元** (**ReLU**)
    是一个简单的非线性函数。它就像一个过滤器，允许正输入保持不变，而将其它输入压制为零。数学上，`relu` 可以通过以下公式表示，并在 *图 1.3.5* 中绘制：
- en: '*relu*(x) = *max*(0,*x*)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '*relu*(x) = *max*(0,*x*)'
- en: '![Building a model using MLPs and Keras](img/B08956_01_06.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![使用 MLP 和 Keras 构建模型](img/B08956_01_06.jpg)'
- en: 'Figure 1.3.5: Plot of ReLU function. The ReLU function introduces non-linearity
    in neural networks.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3.5：ReLU 函数的图像。ReLU 函数在神经网络中引入了非线性。
- en: 'There are other non-linear functions that can be used such as `elu`, `selu`,
    `softplus`, `sigmoid`, and `tanh`. However, `relu` is the most commonly used in
    the industry and is computationally efficient due to its simplicity. The `sigmoid`
    and `tanh` are used as activation functions in the output layer and described
    later. *Table 1.3.1* shows the equation for each of these activation functions:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他非线性函数可以使用，如 `elu`、`selu`、`softplus`、`sigmoid` 和 `tanh`。然而，`relu` 是行业中最常用的，并且由于其简单性，在计算上非常高效。`sigmoid`
    和 `tanh` 被用作输出层的激活函数，后文将详细描述。*表 1.3.1* 展示了这些激活函数的方程：
- en: '| `relu` | *relu*(x) = *max*(0,*x*) | 1.3.1 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| `relu` | *relu*(x) = *max*(0,*x*) | 1.3.1 |'
- en: '| `softplus` | *softplus*(*x*) = log(1 + *e* *x*) | 1.3.2 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| `softplus` | *softplus*(*x*) = log(1 + *e* *x*) | 1.3.2 |'
- en: '| `elu` | ![Building a model using MLPs and Keras](img/B08956_01_001.jpg)where![Building
    a model using MLPs and Keras](img/B08956_01_002.jpg)and is a tunable hyperparameter
    | 1.3.3 |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| `elu` | ![使用 MLP 和 Keras 构建模型](img/B08956_01_001.jpg)，其中 ![使用 MLP 和 Keras
    构建模型](img/B08956_01_002.jpg)，并且是一个可调超参数 | 1.3.3 |'
- en: '| `selu` | *selu*(*x*) = *k* × *elu*(*x,a*)where *k* = 1.0507009873554804934193349852946
    and *a* = 1.6732632423543772848170429916717 | 1.3.4 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `selu` | *selu*(*x*) = *k* × *elu*(*x,a*)，其中 *k* = 1.0507009873554804934193349852946
    和 *a* = 1.6732632423543772848170429916717 | 1.3.4 |'
- en: 'Table 1.3.1: Definition of common non-linear activation functions'
  id: totrans-93
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 表 1.3.1：常见非线性激活函数的定义
- en: Regularization
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则化
- en: A neural network has the tendency to memorize its training data especially if
    it contains more than enough capacity. In such a case, the network fails catastrophically
    when subjected to the test data. This is the classic case of the network failing
    to generalize. To avoid this tendency, the model uses a regularizing layer or
    function. A common regularizing layer is referred to as a **dropout**.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络有记忆训练数据的倾向，特别是当它的容量足够大时。在这种情况下，网络在面对测试数据时会发生灾难性的失败。这是网络无法泛化的经典案例。为了避免这种倾向，模型使用了正则化层或正则化函数。一个常见的正则化层被称为
    **dropout**。
- en: The idea of dropout is simple. Given a dropout rate (here, it is set to `dropout=0.45`),
    the `Dropout` layer randomly removes that fraction of units from participating
    in the next layer. For example, if the first layer has 256 units, after `dropout=0.45`
    is applied, only *(1 - 0.45) * 256 units = 140* units from layer 1 participate
    in layer 2\. The `Dropout` layer makes neural networks robust to unforeseen input
    data because the network is trained to predict correctly, even if some units are
    missing. It's worth noting that dropout is not used in the output layer and it
    is only active during training. Moreover, dropout is not present during prediction.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: dropout 的思想很简单。给定一个 dropout 率（这里设为 `dropout=0.45`），`Dropout` 层会随机移除该比例的神经元，使其不参与下一层的计算。例如，如果第一层有
    256 个神经元，应用 `dropout=0.45` 后，只有 *(1 - 0.45) * 256 = 140* 个神经元会参与第二层的计算。`Dropout`
    层使得神经网络能够应对不可预见的输入数据，因为网络经过训练后，即使部分神经元缺失，依然能够正确预测。值得注意的是，dropout 不会用于输出层，并且它只在训练过程中起作用，预测时不会使用
    dropout。
- en: There are regularizers that can be used other than dropouts like `l1` or `l2`.
    In Keras, the bias, weight and activation output can be regularized per layer.
    `l1` and `l2` favor smaller parameter values by adding a penalty function. Both
    `l1` and `l2` enforce the penalty using a fraction of the sum of absolute (`l1`)
    or square (`l2`) of parameter values. In other words, the penalty function forces
    the optimizer to find parameter values that are small. Neural networks with small
    parameter values are more insensitive to the presence of noise from within the
    input data.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 除了dropout外，还有其他正则化器可以使用，如`l1`或`l2`。在Keras中，可以对每个层的偏置、权重和激活输出进行正则化。`l1`和`l2`通过添加惩罚函数来偏向较小的参数值。`l1`和`l2`通过参数值的绝对值和平方的和的分数来强制实施惩罚。换句话说，惩罚函数强迫优化器找到较小的参数值。具有较小参数值的神经网络对输入数据中的噪声更不敏感。
- en: 'As an example, `l2` weight regularizer with `fraction=0.001` can be implemented
    as:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`l2`权重正则化器与`fraction=0.001`可以实现为：
- en: '[PRE12]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: No additional layer is added if `l1` or `l2` regularization is used. The regularization
    is imposed in the `Dense` layer internally. For the proposed model, dropout still
    has a better performance than `l2`.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用了`l1`或`l2`正则化，则不会添加额外的层。正则化会在`Dense`层内部强制执行。对于所提出的模型，dropout仍然比`l2`正则化表现更好。
- en: Output activation and loss function
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 输出激活和损失函数
- en: 'The output layer has 10 units followed by `softmax` activation. The 10 units
    correspond to the 10 possible labels, classes or categories. The `softmax` activation
    can be expressed mathematically as shown in the following equation:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 输出层有10个单元，并采用`softmax`激活函数。10个单元对应着10个可能的标签、类别或分类。`softmax`激活函数可以通过以下方程表示：
- en: '![Output activation and loss function](img/B08956_01_003.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![输出激活与损失函数](img/B08956_01_003.jpg)'
- en: (Equation 1.3.5)
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: （方程 1.3.5）
- en: 'The equation is applied to all *N* = 10 outputs, *x* *i* *for i* = 0, 1 … 9
    for the final prediction. The idea of `softmax` is surprisingly simple. It squashes
    the outputs into probabilities by normalizing the prediction. Here, each predicted
    output is a probability that the index is the correct label of the given input
    image. The sum of all the probabilities for all outputs is 1.0\. For example,
    when the `softmax` layer generates a prediction, it will be a 10-dim 1D tensor
    that may look like the following output:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 该方程适用于所有*N* = 10个输出，*x* *i* *for i* = 0, 1 … 9的最终预测。`softmax`的概念出奇地简单。它通过标准化预测，将输出压缩为概率。在这里，每个预测的输出是给定输入图像的正确标签的概率。所有输出的概率总和为1.0。例如，当`softmax`层生成预测时，它将是一个10维的1D张量，输出可能类似于以下内容：
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The prediction output tensor suggests that the input image is going to be 7
    given that its index has the highest probability. The `numpy.argmax()` method
    can be used to determine the index of the element with the highest value.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 预测输出张量表明，输入图像的标签应该是7，因为其索引具有最高的概率。可以使用`numpy.argmax()`方法来确定具有最大值的元素的索引。
- en: There are other choices of output activation layer, like `linear`, `sigmoid`,
    and `tanh`. The `linear` activation is an identity function. It copies its input
    to its output. The `sigmoid` function is more specifically known as a **logistic
    sigmoid**. This will be used if the elements of the prediction tensor should be
    mapped between 0.0 and 1.0 independently. The summation of all elements of the
    predicted tensor is not constrained to 1.0 unlike in `softmax`. For example, `sigmoid`
    is used as the last layer in sentiment prediction (0.0 is bad to 1.0, which is
    good) or in image generation (0.0 is 0 to 1.0 is 255-pixel values).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他可以选择的输出激活层，例如`linear`、`sigmoid`和`tanh`。`linear`激活函数是一个恒等函数，它将输入直接复制到输出。`sigmoid`函数更具体地被称为**逻辑sigmoid**。当预测张量的元素需要独立地映射到0.0到1.0之间时，将使用`sigmoid`。与`softmax`不同，预测张量中所有元素的总和不被限制为1.0。例如，在情感预测（0.0表示坏，1.0表示好）或图像生成（0.0表示0，1.0表示255像素值）中，`sigmoid`被用作最后一层。
- en: The `tanh` function maps its input in the range -1.0 to 1.0\. This is important
    if the output can swing in both positive and negative values. The `tanh` function
    is more popularly used in the internal layer of recurrent neural networks but
    has also been used as output layer activation. If `tanh` is used to replace `sigmoid`
    in the output activation, the data used must be scaled appropriately. For example,
    instead of scaling each grayscale pixel in the range [0.0 1.0] using
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`tanh`函数将其输入映射到-1.0到1.0的范围。这在输出可以正负波动时非常重要。`tanh`函数更常用于循环神经网络的内部层，但也曾作为输出层激活函数使用。如果`tanh`替代`sigmoid`作为输出激活函数，所使用的数据必须进行适当的缩放。例如，代替在[0.0,
    1.0]范围内缩放每个灰度像素'
- en: '![Output activation and loss function](img/B08956_01_004.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![输出激活和损失函数](img/B08956_01_004.jpg)'
- en: ', it is assigned in the range [-1.0 1.0] by'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 它被指定在范围[-1.0, 1.0]内
- en: '![Output activation and loss function](img/B08956_01_005.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![输出激活和损失函数](img/B08956_01_005.jpg)'
- en: .
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: 'The following graph shows the `sigmoid` and `tanh` functions. Mathematically,
    `sigmoid` can be expressed in equation as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了`sigmoid`和`tanh`函数。从数学上讲，`sigmoid`可以通过以下方程式表示：
- en: '![Output activation and loss function](img/B08956_01_006.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![输出激活和损失函数](img/B08956_01_006.jpg)'
- en: (Equation 1.3.6)
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: （方程式 1.3.6）
- en: '![Output activation and loss function](img/B08956_01_07.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![输出激活和损失函数](img/B08956_01_07.jpg)'
- en: 'Figure 1.3.6: Plots of sigmoid and tanh'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3.6：`sigmoid`与`tanh`函数图
- en: How far the predicted tensor is from the one-hot ground truth vector is called
    loss. One type of loss function is `mean_squared_error` (**mse**), or the average
    of the squares of the differences between target and prediction. In the current
    example, we are using `categorical_crossentropy`. It's the negative of the sum
    of the product of the target and the logarithm of the prediction. There are other
    loss functions that are available in Keras, such as `mean_absolute_error`, and
    `binary_crossentropy`. The choice of the loss function is not arbitrary but should
    be a criterion that the model is learning. For classification by category, `categorical_crossentropy`
    or `mean_squared_error` is a good choice after the `softmax` activation layer.
    The `binary_crossentropy` loss function is normally used after the `sigmoid` activation
    layer while `mean_squared_error` is an option for `tanh` output.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 预测张量与独热编码真实标签向量的差异被称为损失。一种损失函数是`mean_squared_error`（**均方误差**），即目标值与预测值之间差异的平方的平均值。在当前示例中，我们使用的是`categorical_crossentropy`。它是目标与预测值的乘积与预测值对数的总和的负值。Keras中还提供了其他损失函数，如`mean_absolute_error`和`binary_crossentropy`。损失函数的选择并非随意，而应该是模型正在学习的标准。对于分类问题，`categorical_crossentropy`或`mean_squared_error`是`softmax`激活层之后的一个不错的选择。而`binary_crossentropy`损失函数通常在`sigmoid`激活层之后使用，`mean_squared_error`则是`tanh`输出的一个选择。
- en: Optimization
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化
- en: With optimization, the objective is to minimize the loss function. The idea
    is that if the loss is reduced to an acceptable level, the model has indirectly
    learned the function mapping input to output. Performance metrics are used to
    determine if a model has learned the underlying data distribution. The default
    metric in Keras is **loss**. During training, validation, and testing, other metrics
    such as **accuracy** can also be included. Accuracy is the percent, or fraction,
    of correct predictions based on ground truth. In deep learning, there are many
    other performance metrics. However, it depends on the target application of the
    model. In literature, performance metrics of the trained model on the test dataset
    is reported for comparison to other deep learning models.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化过程中，目标是最小化损失函数。其思想是，如果损失减少到可接受的水平，模型就间接地学习了将输入映射到输出的函数。性能指标用于确定模型是否学习到了潜在的数据分布。Keras中的默认指标是**损失**。在训练、验证和测试过程中，还可以包括其他指标，如**准确率**。准确率是基于真实标签的正确预测的百分比或分数。在深度学习中，还有许多其他的性能指标。然而，这取决于模型的目标应用。在文献中，通常会报告训练模型在测试数据集上的性能指标，以便与其他深度学习模型进行比较。
- en: In Keras, there are several choices for optimizers. The most commonly used optimizers
    are; **Stochastic Gradient Descent** (**SGD**), **Adaptive Moments** (**Adam**),
    and **Root Mean Squared Propagation** (**RMSprop**). Each optimizer features tunable
    parameters like learning rate, momentum, and decay. Adam and RMSprop are variations
    of SGD with adaptive learning rates. In the proposed classifier network, Adam
    is used since it has the highest test accuracy.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Keras 中，有几种优化器可供选择。最常用的优化器包括；**随机梯度下降**（**SGD**）、**自适应矩估计**（**Adam**）和**均方根传播**（**RMSprop**）。每个优化器都有可调参数，如学习率、动量和衰减。Adam
    和 RMSprop 是 SGD 的变种，具有自适应学习率。在所提出的分类器网络中，使用了 Adam，因为它具有最高的测试准确率。
- en: SGD is considered the most fundamental optimizer. It's a simpler version of
    the gradient descent in calculus. In **gradient descent** (**GD**), tracing the
    curve of a function downhill finds the minimum value, much like walking downhill
    in a valley or opposite the gradient until the bottom is reached.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: SGD 被认为是最基本的优化器。它是微积分中梯度下降的简化版本。在**梯度下降**（**GD**）中，沿着函数曲线向下追踪找到最小值，就像在山谷中或沿着梯度的反方向走，直到到达底部。
- en: The GD algorithm is illustrated in *Figure 1.3.7*. Let's suppose *x* is the
    parameter (for example, weight) being tuned to find the minimum value of *y* (for
    example, loss function). Starting at an arbitrary point of *x* = -0.5 with the
    gradient being
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: GD 算法如*图 1.3.7*所示。假设 *x* 是正在调节的参数（例如，权重），目的是找到 *y*（例如，损失函数）的最小值。从 *x* = -0.5
    的任意位置开始，梯度为
- en: '![Optimization](img/B08956_01_007.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_007.jpg)'
- en: . The GD algorithm imposes that *x* is then updated to
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: GD 算法要求 *x* 随后更新为
- en: '![Optimization](img/B08956_01_008.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_008.jpg)'
- en: . The new value of *x* is equal to the old value, plus the opposite of the gradient
    scaled by
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 新的 *x* 值等于旧的值，加上梯度的相反方向并按比例缩放。
- en: '![Optimization](img/B08956_01_009.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_009.jpg)'
- en: . The small number
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 。这个小数字
- en: '![Optimization](img/B08956_01_010.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_010.jpg)'
- en: refers to the learning rate. If
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 指的是学习率。如果
- en: '![Optimization](img/B08956_01_011.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_011.jpg)'
- en: ', then the new value of *x* = -0.48.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ，新值的 *x* = -0.48。
- en: GD is performed iteratively. At each step, *y* will get closer to its minimum
    value. At *x* = 0.5
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: GD 通过迭代执行。在每一步中，*y* 将越来越接近其最小值。在 *x* = 0.5 时，
- en: '![Optimization](img/B08956_01_012.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_012.jpg)'
- en: ', the GD has found the absolute minimum value of *y* = -1.25\. The gradient
    recommends no further change in *x*.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: ，GD 已经找到了 *y* = -1.25 的绝对最小值。梯度建议 *x* 不再改变。
- en: The choice of learning rate is crucial. A large value of
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率的选择至关重要。一个较大的值
- en: '![Optimization](img/B08956_01_013.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_013.jpg)'
- en: may not find the minimum value since the search will just swing back and forth
    around the minimum value. On the other hand, too small value of
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 可能无法找到最小值，因为搜索可能会在最小值附近来回摆动。另一方面，过小的值
- en: '![Optimization](img/B08956_01_014.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_014.jpg)'
- en: may take a significant number of iterations before the minimum is found. In
    the case of multiple minima, the search might get stuck in a local minimum.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 可能需要进行大量的迭代才能找到最小值。在多重极小值的情况下，搜索可能会陷入局部最小值。
- en: '![Optimization](img/B08956_01_08.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_08.jpg)'
- en: 'Figure 1.3.7: Gradient descent is similar to walking downhill on the function
    curve until the lowest point is reached. In this plot, the global minimum is at
    x = 0.5.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3.7：梯度下降类似于沿着函数曲线走下坡，直到到达最低点。在这个图中，全局最小值位于 *x* = 0.5。
- en: An example of multiple minima can be seen in *Figure 1.3.8*. If for some reason
    the search started at the left side of the plot and the learning rate is very
    small, there is a high probability that GD will find *x* = -1.51 as the minimum
    value of *y*. GD will not find the global minimum at *x* = 1.66\. A sufficiently
    valued learning rate will enable the gradient descent to overcome the hill at
    *x* = 0.0\. In deep learning practice, it is normally recommended to start at
    a bigger learning rate (for example. 0.1 to 0.001) and gradually decrease as the
    loss gets closer to the minimum.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 多重极小值的例子可以在*图 1.3.8*中看到。如果出于某种原因搜索从图的左侧开始，且学习率非常小，则GD有很高的概率将 *x* = -1.51 作为
    *y* 的最小值，而不会找到 *x* = 1.66 的全局最小值。一个足够的学习率将使梯度下降能够越过 *x* = 0.0 处的小山。在深度学习实践中，通常建议从较大的学习率（例如
    0.1 到 0.001）开始，并随着损失接近最小值逐渐减小学习率。
- en: '![Optimization](img/B08956_01_09.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_09.jpg)'
- en: 'Figure 1.3.8: Plot of a function with 2 minima, x = -1.51 and x = 1.66\. Also
    shown is the derivative of the function.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3.8：具有两个最小值的函数图，x = -1.51 和 x = 1.66。图中还显示了该函数的导数。
- en: 'Gradient descent is not typically used in deep neural networks since you''ll
    often come upon millions of parameters that need to be trained. It is computationally
    inefficient to perform a full gradient descent. Instead, SGD is used. In SGD,
    a mini batch of samples is chosen to compute an approximate value of the descent.
    The parameters (for example, weights and biases) are adjusted by the following
    equation:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降在深度神经网络中通常不使用，因为你经常会遇到需要训练的数百万个参数。执行完全的梯度下降在计算上效率低下。相反，使用了 SGD（随机梯度下降）。在
    SGD 中，选择一个小批量样本来计算下降的近似值。参数（例如权重和偏置）通过以下公式进行调整：
- en: '![Optimization](img/B08956_01_015.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_015.jpg)'
- en: (Equation 1.3.7)
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: （公式 1.3.7）
- en: In this equation,
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个公式中，
- en: '![Optimization](img/B08956_01_016.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_016.jpg)'
- en: and
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: '![Optimization](img/B08956_01_017.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![优化](img/B08956_01_017.jpg)'
- en: are the parameters and gradients tensor of the loss function respectively. The
    **g** is computed from partial derivatives of the loss function. The mini-batch
    size is recommended to be a power of 2 for GPU optimization purposes. In the proposed
    network, `batch_size=128`.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 分别是损失函数的参数和梯度张量。**g** 是通过损失函数的偏导数计算得到的。为了优化 GPU 性能，建议将小批量大小设置为 2 的幂。在所提议的网络中，`batch_size=128`。
- en: '*Equation 1.3.7* computes the last layer parameter updates. So, how do we adjust
    the parameters of the preceding layers? For this case, the chain rule of differentiation
    is applied to propagate the derivatives to the lower layers and compute the gradients
    accordingly. This algorithm is known as **backpropagation** in deep learning.
    The details of backpropagation are beyond the scope of this book. However, a good
    online reference can be found at [http://neuralnetworksanddeeplearning.com](http://neuralnetworksanddeeplearning.com).'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*公式 1.3.7* 计算了最后一层的参数更新。那么，如何调整前面层的参数呢？对于这种情况，应用微分的链式法则将导数传播到更低的层，并相应地计算梯度。这个算法在深度学习中被称为**反向传播**。反向传播的细节超出了本书的范围。不过，可以在[http://neuralnetworksanddeeplearning.com](http://neuralnetworksanddeeplearning.com)找到一个很好的在线参考。'
- en: Since optimization is based on differentiation, it follows that an important
    criterion of the loss function is that it must be smooth or differentiable. This
    is an important constraint to keep in mind when introducing a new loss function.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 由于优化是基于微分的，因此损失函数的一个重要标准是它必须是平滑的或可微分的。当引入新的损失函数时，这个约束是非常重要的。
- en: 'Given the training dataset, the choice of the loss function, the optimizer,
    and the regularizer, the model can now be trained by calling the `fit()` function:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 给定训练数据集、损失函数、优化器和正则化器的选择，现在可以通过调用 `fit()` 函数来训练模型：
- en: '[PRE14]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This is another helpful feature of Keras. By just supplying both the *x* and
    *y* data, the number of epochs to train, and the batch size, `fit()` does the
    rest. In other deep learning frameworks, this translates to multiple tasks such
    as preparing the input and output data in the proper format, loading, monitoring,
    and so on. While all of these must be done inside a `for` loop! In Keras, everything
    is done in just one line.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Keras 另一个有用的功能。只需提供 *x* 和 *y* 数据、训练的 epoch 数量和批量大小，`fit()` 就会处理剩下的部分。在其他深度学习框架中，这需要执行多个任务，比如将输入和输出数据转换为正确的格式、加载、监控等。所有这些都必须在
    `for` 循环内完成！在 Keras 中，所有工作都在一行代码中完成。
- en: In the `fit()` function, an epoch is the complete sampling of the entire training
    data. The `batch_size` parameter is the sample size of the number of inputs to
    process at each training step. To complete one epoch, `fit()` requires the size
    of train dataset divided by batch size, plus 1 to compensate for any fractional
    part.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `fit()` 函数中，epoch 是对整个训练数据集的完整采样。`batch_size` 参数是每次训练步骤处理的输入样本数量。要完成一个 epoch，`fit()`
    需要用训练数据集的大小除以批量大小，再加 1 以补偿任何小数部分。
- en: Performance evaluation
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能评估
- en: At this point, the model for the **MNIST** digit classifier is now complete.
    Performance evaluation will be the next crucial step to determine if the proposed
    model has come up with a satisfactory solution. Training the model for 20 epochs
    will be sufficient to obtain comparable performance metrics.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，**MNIST** 数字分类器的模型已经完成。性能评估将是下一个关键步骤，以确定所提出的模型是否提供了令人满意的解决方案。训练模型 20 个
    epoch 足以获得可比的性能指标。
- en: The following table, *Table 1.3.2*, shows the different network configurations
    and corresponding performance measures. Under *Layers*, the number of units is
    shown for layers 1 to 3\. For each optimizer, the default parameters in Keras
    are used. The effects of varying the regularizer, optimizer and number of units
    per layer can be observed. Another important observation in *Table 1.3.2* is that
    bigger networks do not necessarily translate to better performance.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格 *表 1.3.2* 显示了不同网络配置和相应的性能指标。在 *Layers* 列中，展示了第 1 到第 3 层的单元数。对于每个优化器，使用了
    Keras 中的默认参数。可以观察到改变正则化器、优化器和每层单元数的效果。在 *表 1.3.2* 中的另一个重要观察结果是，较大的网络不一定会带来更好的性能。
- en: Increasing the depth of this network shows no added benefits in terms of accuracy
    for both training and testing datasets. On the other hand, a smaller number of
    units, like 128, could also lower both the test and train accuracy. The best train
    accuracy at 99.93% is obtained when the regularizer is removed, and 256 units
    per layer are used. The test accuracy, however, is much lower at 98.0%, as a result
    of the network overfitting.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 增加网络深度对于训练和测试数据集的准确性没有带来额外的好处。另一方面，像 128 这样的较小单元数也可能会降低测试和训练的准确率。当去除正则化器并使用每层
    256 个单元时，获得了 99.93%的最佳训练准确率。然而，由于网络过拟合，测试准确率要低得多，为 98.0%。
- en: The highest test accuracy is with the Adam optimizer and `Dropout(0.45)` at
    98.5%. Technically, there is still some degree of overfitting given that its training
    accuracy is 99.39%. Both the train and test accuracy are the same at 98.2% for
    256-512-256, `Dropout(0.45)` and SGD. Removing both the *Regularizer* and *ReLU*
    layers results in it having the worst performance. Generally, we'll find that
    the `Dropout` layer has better performance than `l2`.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 最高的测试准确率是在使用 Adam 优化器和 `Dropout(0.45)` 时达到 98.5%。从技术上讲，仍然存在一定程度的过拟合，因为其训练准确率为
    99.39%。对于 256-512-256、`Dropout(0.45)` 和 SGD，训练和测试准确率都是 98.2%。去除 *Regularizer*
    和 *ReLU* 层会导致最差的性能。通常，我们会发现 `Dropout` 层的性能优于 `l2`。
- en: 'Following table demonstrates a typical deep neural network performance during tuning.
    The example indicates that there is a need to improve the network architecture.
    In the following section, another model using CNNs shows a significant improvement
    in test accuracy:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格展示了在调优过程中典型的深度神经网络性能。该示例表明，网络架构需要改进。在接下来的部分中，另一个使用 CNN 的模型显示了测试准确率的显著提高：
- en: '| Layers | Regularizer | Optimizer | ReLU | Train Accuracy, % | Test Accuracy,
    % |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 层数 | 正则化器 | 优化器 | ReLU | 训练准确率，% | 测试准确率，% |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 256-256-256 | None | SGD | None | 93.65 | 92.5 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 256-256-256 | 无 | SGD | 否 | 93.65 | 92.5 |'
- en: '| 256-256-256 | L2(0.001) | SGD | Yes | 99.35 | 98.0 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 256-256-256 | L2(0.001) | SGD | 是 | 99.35 | 98.0 |'
- en: '| 256-256-256 | L2(0.01) | SGD | Yes | 96.90 | 96.7 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 256-256-256 | L2(0.01) | SGD | 是 | 96.90 | 96.7 |'
- en: '| 256-256-256 | None | SGD | Yes | 99.93 | 98.0 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 256-256-256 | 无 | SGD | 是 | 99.93 | 98.0 |'
- en: '| 256-256-256 | Dropout(0.4) | SGD | Yes | 98.23 | 98.1 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| 256-256-256 | Dropout(0.4) | SGD | 是 | 98.23 | 98.1 |'
- en: '| 256-256-256 | Dropout(0.45) | SGD | Yes | 98.07 | 98.1 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 256-256-256 | Dropout(0.45) | SGD | 是 | 98.07 | 98.1 |'
- en: '| 256-256-256 | Dropout(0.5) | SGD | Yes | 97.68 | 98.1 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 256-256-256 | Dropout(0.5) | SGD | 是 | 97.68 | 98.1 |'
- en: '| 256-256-256 | Dropout(0.6) | SGD | Yes | 97.11 | 97.9 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 256-256-256 | Dropout(0.6) | SGD | 是 | 97.11 | 97.9 |'
- en: '| 256-512-256 | Dropout(0.45) | SGD | Yes | 98.21 | 98.2 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 256-512-256 | Dropout(0.45) | SGD | 是 | 98.21 | 98.2 |'
- en: '| 512-512-512 | Dropout(0.2) | SGD | Yes | 99.45 | 98.3 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 512-512-512 | Dropout(0.2) | SGD | 是 | 99.45 | 98.3 |'
- en: '| 512-512-512 | Dropout(0.4) | SGD | Yes | 98.95 | 98.3 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 512-512-512 | Dropout(0.4) | SGD | 是 | 98.95 | 98.3 |'
- en: '| 512-1024-512 | Dropout(0.45) | SGD | Yes | 98.90 | 98.2 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 512-1024-512 | Dropout(0.45) | SGD | 是 | 98.90 | 98.2 |'
- en: '| 1024-1024-1024 | Dropout(0.4) | SGD | Yes | 99.37 | 98.3 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 1024-1024-1024 | Dropout(0.4) | SGD | 是 | 99.37 | 98.3 |'
- en: '| 256-256-256 | Dropout(0.6) | Adam | Yes | 98.64 | 98.2 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 256-256-256 | Dropout(0.6) | Adam | 是 | 98.64 | 98.2 |'
- en: '| 256-256-256 | Dropout(0.55) | Adam | Yes | 99.02 | 98.3 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 256-256-256 | Dropout(0.55) | Adam | 是 | 99.02 | 98.3 |'
- en: '| 256-256-256 | Dropout(0.45) | Adam | Yes | 99.39 | 98.5 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 256-256-256 | Dropout(0.45) | Adam | 是 | 99.39 | 98.5 |'
- en: '| 256-256-256 | Dropout(0.45) | RMSprop | Yes | 98.75 | 98.1 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 256-256-256 | Dropout(0.45) | RMSprop | 是 | 98.75 | 98.1 |'
- en: '| 128-128-128 | Dropout(0.45) | Adam | Yes | 98.70 | 97.7 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 128-128-128 | Dropout(0.45) | Adam | 是 | 98.70 | 97.7 |'
- en: Model summary
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型总结
- en: 'Using the Keras library provides us with a quick mechanism to double check
    the model description by calling:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Keras 库可以通过调用以下方法快速验证模型描述：
- en: '[PRE15]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '*Listing* *1.3.2* shows the model summary of the proposed network. It requires
    a total of 269,322 parameters. This is substantial considering that we have a
    simple task of classifying MNIST digits. MLPs are not parameter efficient. The
    number of parameters can be computed from *Figure 1.3.4* by focusing on how the
    output of the perceptron is computed. From input to Dense layer: 784 × 256 + 256
    = 200,960\. From first Dense to second Dense: 256 × 256 + 256 = 65,792\. From
    second Dense to the output layer: 10 × 256 + 10 = 2,570\. The total is 269,322.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '*清单* *1.3.2*展示了提出的网络模型的总结。该模型需要总计269,322个参数。考虑到我们只是一个简单的MNIST数字分类任务，这个参数数量相当可观。MLP模型并不高效。参数的数量可以通过*图1.3.4*来计算，重点关注感知机如何计算输出。从输入到Dense层：784
    × 256 + 256 = 200,960。第一个Dense到第二个Dense：256 × 256 + 256 = 65,792。从第二个Dense到输出层：10
    × 256 + 10 = 2,570。总数为269,322。'
- en: 'Listing 1.3.2 shows a summary of an MLP MNIST digit classifier model:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 清单1.3.2展示了MLP MNIST数字分类器模型的总结：
- en: '[PRE16]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Another way of verifying the network is by calling:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种验证网络的方法是调用：
- en: '[PRE17]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '*Figure 1.3.9* shows the plot. You''ll find that this is similar to the results
    of `summary()` but graphically shows the interconnection and I/O of each layer.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.3.9*展示了该图形结果。你会发现，这与`summary()`的结果类似，但以图形化的方式显示了每一层的相互连接和输入输出。'
- en: '![Model summary](img/B08956_01_10.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![模型总结](img/B08956_01_10.jpg)'
- en: 'Figure 1.3.9: The graphical description of the MLP MNIST digit classifier'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3.9：MLP MNIST数字分类器的图形描述
- en: Convolutional neural networks (CNNs)
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNNs）
- en: We're now going to move onto the second artificial neural network, **Convolutional
    Neural Networks** (**CNNs**). In this section, we're going solve the same MNIST
    digit classification problem, instead this time using CNNs.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将进入第二种人工神经网络——**卷积神经网络**（**CNNs**）。在本节中，我们将解决相同的MNIST数字分类问题，不过这次我们将使用CNN。
- en: '*Figure 1.4.1* shows the CNN model that we''ll use for the MNIST digit classification,
    while its implementation is illustrated in *Listing* *1.4.1*. Some changes in
    the previous model will be needed to implement the CNN model. Instead of having
    input vector, the input tensor now has new dimensions (height, width, channels)
    or (image_size, image_size, 1) = (28, 28, 1) for the grayscale MNIST images. Resizing
    the train and test images will be needed to conform to this input shape requirement.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.4.1*展示了我们将用于MNIST数字分类的CNN模型，模型的实现细节则在*清单* *1.4.1*中进行了说明。为了实现CNN模型，之前模型的一些部分需要做出调整。输入向量不再是原来的形式，而是新的维度（高度、宽度、通道数），对于灰度的MNIST图像来说，输入形状是（image_size,
    image_size, 1） = (28, 28, 1)。因此，训练和测试图像需要重新调整大小以符合这一输入形状要求。'
- en: '![Convolutional neural networks (CNNs)](img/B08956_01_11.jpg)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![卷积神经网络（CNNs）](img/B08956_01_11.jpg)'
- en: 'Figure 1.4.1: CNN model for MNIST digit classification'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4.1：用于MNIST数字分类的CNN模型
- en: 'Listing 1.4.1, `cnn-mnist-1.4.1.py` shows the Keras code for the MNIST digit
    classification using CNN:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 清单1.4.1，`cnn-mnist-1.4.1.py`展示了使用CNN进行MNIST数字分类的Keras代码：
- en: '[PRE18]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The major change here is the use of `Conv2D` layers. The `relu` activation function
    is already an argument of `Conv2D`. The `relu` function can be brought out as
    an `Activation` layer when the **batch normalization** layer is included in the
    model. Batch normalization is used in deep CNNs so that large learning rates can
    be used without causing instability during training.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的主要变化是使用了`Conv2D`层。`relu`激活函数已经是`Conv2D`的一个参数。使用**批量归一化**层时，`relu`函数可以作为一个`Activation`层单独使用。批量归一化在深度CNN中非常常见，可以使得在训练过程中使用较大的学习率，而不会引起不稳定。
- en: Convolution
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积
- en: If in the MLP model the number of units characterizes the `Dense` layers, the
    kernel characterizes the CNN operations. As shown in *Figure 1.4.2*, the kernel
    can be visualized as a rectangular patch or window that slides through the whole
    image from left to right, and top to bottom. This operation is called **convolution**.
    It transforms the input image into a **feature maps**, which is a representation
    of what the kernel has *learned* from the input image. The feature maps are then
    transformed into another feature maps in the succeeding layer and so on. The number
    of feature maps generated per `Conv2D` is controlled by the `filters` argument.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在MLP模型中，单元的数量表示`Dense`层的特点，那么卷积核则代表CNN操作的特点。如*图1.4.2*所示，卷积核可以视为一个矩形的图像块或窗口，它从左到右、从上到下滑过整个图像。这一操作被称为**卷积**。它将输入图像转化为**特征图**，特征图代表了卷积核从输入图像中*学习*到的内容。特征图随后会被转化为下一层的特征图，依此类推。每个`Conv2D`生成的特征图的数量由`filters`参数控制。
- en: '![Convolution](img/B08956_01_12.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![卷积](img/B08956_01_12.jpg)'
- en: 'Figure 1.4.2: A 3 × 3 kernel is convolved with an MNIST digit image. The convolution
    is shown in steps t[n] and t[n+1] where the kernel moved by a stride of 1 pixel
    to the right.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4.2：一个3 × 3的卷积核与MNIST数字图像进行卷积。卷积过程通过步骤t[n]和t[n+1]展示，其中卷积核向右移动了1个像素的步幅。
- en: 'The computation involved in the convolution is shown in *Figure 1.4.3*. For
    simplicity, a 5 × 5 input image (or input feature map) where a 3 × 3 kernel is
    applied is illustrated. The resulting feature map is shown after the convolution.
    The value of one element of the feature map is shaded. You''ll notice that the
    resulting feature map is smaller than the original input image, this is because
    the convolution is only performed on valid elements. The kernel cannot go beyond
    the borders of the image. If the dimensions of the input should be the same as
    the output feature maps, `Conv2D` will accept the option `padding=''same''`. The
    input is padded with zeroes around its borders to keep the dimensions unchanged
    after the convolution:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积过程中涉及的计算如*图1.4.3*所示。为了简便起见，假设输入图像（或输入特征图）是一个5 × 5的矩阵，应用了一个3 × 3的卷积核。卷积后的特征图也在图中展示。图中特征图中的一个元素已被阴影标出。你会注意到，卷积后的特征图比原始输入图像要小，这是因为卷积只在有效元素上进行，卷积核不能越过图像的边界。如果希望输入和输出特征图的尺寸保持一致，可以将`Conv2D`的参数设置为`padding='same'`。输入图像的边界会被零填充，从而在卷积后保持尺寸不变：
- en: '![Convolution](img/B08956_01_13.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![卷积](img/B08956_01_13.jpg)'
- en: 'Figure 1.4.3: The convolution operation shows how one element of the feature
    map is computed'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4.3：卷积操作展示了特征图中一个元素是如何被计算出来的
- en: Pooling operations
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 池化操作
- en: 'The last change is the addition of a `MaxPooling2D` layer with the argument
    `pool_size=2`. `MaxPooling2D` compresses each feature map. Every patch of size `pool_size`
    × `pool_size` is reduced to one pixel. The value is equal to the maximum pixel
    value within the patch. `MaxPooling2D` is shown in the following figure for two
    patches:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的变化是添加了一个`MaxPooling2D`层，参数为`pool_size=2`。`MaxPooling2D`会压缩每个特征图。每个大小为`pool_size`
    × `pool_size`的区域都会被缩减为一个像素，值等于该区域内的最大像素值。以下图展示了两个区域的`MaxPooling2D`操作：
- en: '![Pooling operations](img/B08956_01_14.jpg)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![池化操作](img/B08956_01_14.jpg)'
- en: 'Figure 1.4.4: MaxPooling2D operation. For simplicity, the input feature map
    is 4 × 4 resulting in a 2 × 2 feature map.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4.4：MaxPooling2D操作。为了简便起见，输入特征图为4 × 4，得到一个2 × 2的特征图。
- en: The significance of `MaxPooling2D` is the reduction in feature maps size which
    translates to increased kernel coverage. For example, after `MaxPooling2D(2)`,
    the 2 × 2 kernel is now approximately convolving with a 4 × 4 patch. The CNN has learned
    a new set of feature maps for a different coverage.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '`MaxPooling2D`的意义在于特征图大小的减少，从而实现了卷积核覆盖范围的增加。例如，在`MaxPooling2D(2)`之后，2 × 2的卷积核大约是与一个4
    × 4的区域进行卷积。CNN学习到了新的特征图集，涵盖了不同的区域。'
- en: There are other means of pooling and compression. For example, to achieve a
    50% size reduction as `MaxPooling2D(2)`, `AveragePooling2D(2)` takes the average
    of a patch instead of finding the maximum. Strided convolution, `Conv2D(strides=2,…)`
    will skip every two pixels during convolution and will still have the same 50%
    size reduction effect. There are subtle differences in the effectiveness of each
    reduction technique.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他池化和压缩方式。例如，为了实现与`MaxPooling2D(2)`相同的50%尺寸缩小，`AveragePooling2D(2)`通过取一个区域的平均值来代替找到最大值。步幅卷积`Conv2D(strides=2,…)`会在卷积过程中跳过每两个像素，仍然能达到相同的50%尺寸缩小效果。不同的缩减技术在效果上有细微差别。
- en: In `Conv2D` and `MaxPooling2D`, both `pool_size` and `kernel` can be non-square.
    In these cases, both the row and column sizes must be indicated. For example,
    `pool_size=(1, 2)` and `kernel=(3, 5)`.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Conv2D`和`MaxPooling2D`中，`pool_size`和`kernel`都可以是非方形的。在这种情况下，必须同时指定行和列的大小。例如，`pool_size=(1,
    2)`和`kernel=(3, 5)`。
- en: The output of the last `MaxPooling2D` is a stack of feature maps. The role of
    `Flatten` is to convert the stack of feature maps into a vector format that is
    suitable for either `Dropout` or `Dense` layers, similar to the MLP model output
    layer.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个`MaxPooling2D`层的输出是一个堆叠的特征图。`Flatten`的作用是将这些堆叠的特征图转换为适合`Dropout`或`Dense`层的向量格式，类似于MLP模型的输出层。
- en: Performance evaluation and model summary
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 性能评估和模型总结
- en: As shown in *Listing* *1.4.2*, the CNN model in *Listing* *1.4.1* requires a
    smaller number of parameters at 80,226 compared to 269,322 when MLP layers are
    used. The `conv2d_1` layer has 640 parameters because each kernel has 3 × 3 =
    9 parameters, and each of the 64 feature maps has one kernel and one bias parameter.
    The number of parameters for other convolution layers can be computed in a similar
    way. *Figure 1.4.5* shows the graphical representation of the CNN MNIST digit
    classifier.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 如*列表* *1.4.2*所示，与使用 MLP 层时的 269,322 相比，*列表* *1.4.1* 中的 CNN 模型所需参数较少，为 80,226。`conv2d_1`
    层有 640 个参数，因为每个卷积核有 3 × 3 = 9 个参数，且每个 64 个特征图都有一个卷积核和一个偏置参数。其他卷积层的参数数量可以通过类似的方式计算。*图
    1.4.5* 显示了 CNN MNIST 数字分类器的图形表示。
- en: '*Table 1.4.1* shows that the maximum test accuracy of 99.4% which can be achieved
    for a 3–layer network with 64 feature maps per layer using the Adam optimizer
    with `dropout=0.2`. CNNs are more parameter efficient and have a higher accuracy
    than MLPs. Likewise, CNNs are also suitable for learning representations from
    sequential data, images, and videos.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '*表 1.4.1* 显示了使用 Adam 优化器和 `dropout=0.2` 的 3 层网络，每层 64 个特征图时，最大测试准确率为 99.4%。CNN
    在参数效率上更高，并且具有比 MLP 更高的准确性。同样，CNN 也适合用于从顺序数据、图像和视频中学习表示。'
- en: 'Listing 1.4.2 shows a summary of a CNN MNIST digit classifier:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 1.4.2 显示了 CNN MNIST 数字分类器的总结：
- en: '[PRE19]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![Performance evaluation and model summary](img/B08956_01_15.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![性能评估和模型总结](img/B08956_01_15.jpg)'
- en: 'Figure 1.4.5: Graphical description of the CNN MNIST digit classifier'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.4.5：CNN MNIST 数字分类器的图形描述
- en: '| Layers | Optimizer | Regularizer | Train Accuracy, % | Test Accuracy, % |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 层数 | 优化器 | 正则化器 | 训练准确率，% | 测试准确率，% |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 64-64-64 | SGD | Dropout(0.2) | 97.76 | 98.50 |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 64-64-64 | SGD | Dropout(0.2) | 97.76 | 98.50 |'
- en: '| 64-64-64 | RMSprop | Dropout(0.2) | 99.11 | 99.00 |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| 64-64-64 | RMSprop | Dropout(0.2) | 99.11 | 99.00 |'
- en: '| 64-64-64 | Adam | Dropout(0.2) | 99.75 | 99.40 |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 64-64-64 | Adam | Dropout(0.2) | 99.75 | 99.40 |'
- en: '| 64-64-64 | Adam | Dropout(0.4) | 99.64 | 99.30 |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| 64-64-64 | Adam | Dropout(0.4) | 99.64 | 99.30 |'
- en: Recurrent neural networks (RNNs)
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 递归神经网络（RNNs）
- en: We're now going to look at the last of our three artificial neural networks,
    Recurrent neural networks, or RNNs.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看看我们三个人工神经网络中的最后一个——递归神经网络（RNNs）。
- en: 'RNNs are a family of networks that are suitable for learning representations
    of sequential data like text in **Natural Language Processing** (**NLP**) or stream
    of sensor data in instrumentation. While each MNIST data sample is not sequential
    in nature, it is not hard to imagine that every image can be interpreted as a
    sequence of rows or columns of pixels. Thus, a model based on RNNs can process
    each MNIST image as a sequence of 28-element input vectors with **timesteps**
    equal to 28\. The following listing shows the code for the RNN model in *Figure
    1.5.1*:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: RNNs 是一类适用于学习顺序数据表示的网络，例如**自然语言处理**（**NLP**）中的文本或仪器中的传感器数据流。虽然每个 MNIST 数据样本本身并非顺序数据，但不难想象，每个图像都可以被解释为一系列像素行或列的顺序。因此，基于
    RNN 的模型可以将每个 MNIST 图像处理为 28 元素输入向量的序列，**时间步**等于 28。以下列表显示了*图 1.5.1*中 RNN 模型的代码：
- en: '![Recurrent neural networks (RNNs)](img/B08956_01_16.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![递归神经网络（RNNs）](img/B08956_01_16.jpg)'
- en: 'Figure 1.5.1: RNN model for MNIST digit classification'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5.1：用于 MNIST 数字分类的 RNN 模型
- en: 'In the following listing, *Listing 1.5.1*, the `rnn-mnist-1.5.1.py` shows the
    Keras code for MNIST digit classification using RNNs:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下列表中，*列表 1.5.1*，`rnn-mnist-1.5.1.py` 显示了使用 RNNs 进行 MNIST 数字分类的 Keras 代码：
- en: '[PRE20]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'There are the two main differences between RNNs and the two previous models.
    First is the `input_shape = (image_size, image_size)` which is actually `input_shape
    = (timesteps, input_dim)` or a sequence of `input_dim`—dimension vectors of `timesteps`
    length. Second is the use of a `SimpleRNN` layer to represent an RNN cell with
    `units=256`. The `units` variable represents the number of output units. If the
    CNN is characterized by the convolution of kernel across the input feature map,
    the RNN output is a function not only of the present input but also of the previous
    output or hidden state. Since the previous output is also a function of the previous
    input, the current output is also a function of the previous output and input
    and so on. The `SimpleRNN` layer in Keras is a simplified version of the true RNN.
    The following, equation describes the output of SimpleRNN:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: RNN与前两种模型之间有两个主要区别。首先是`input_shape = (image_size, image_size)`，实际上是`input_shape
    = (timesteps, input_dim)`，即一个长度为`timesteps`的`input_dim`维度向量序列。其次是使用`SimpleRNN`层来表示一个具有`units=256`的RNN单元。`units`变量表示输出单元的数量。如果CNN的特点是卷积核在输入特征图上进行卷积，那么RNN的输出不仅是当前输入的函数，还与上一输出或隐藏状态有关。由于上一输出也是上一输入的函数，因此当前输出也是上一输出和输入的函数，依此类推。Keras中的`SimpleRNN`层是RNN的简化版本。以下方程描述了SimpleRNN的输出：
- en: '**h**t = tanh(**b** + W**h**t-1 + U**x**t) (1.5.1)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '**h**t = tanh(**b** + W**h**t-1 + U**x**t) (1.5.1)'
- en: In this equation, **b** is the bias, while **W** and **U** are called recurrent
    kernel (weights for previous output) and kernel (weights for the current input)
    respectively. Subscript *t* is used to indicate the position in the sequence.
    For `SimpleRNN` layer with `units=256`, the total number of parameters is 256
    + 256 × 256 + 256 × 28 = 72,960 corresponding to **b**, **W,** and **U** contributions.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在此方程中，**b**是偏置项，**W**和**U**分别被称为递归核（上一输出的权重）和核（当前输入的权重）。下标*t*用于表示序列中的位置。对于`SimpleRNN`层，`units=256`时，总参数数量为256
    + 256 × 256 + 256 × 28 = 72,960，分别对应**b**、**W**和**U**的贡献。
- en: 'Following figure shows the diagrams of both SimpleRNN and RNN that were used
    in the MNIST digit classification. What makes `SimpleRNN` simpler than RNN is
    the absence of the output values **O**t = V**h**t + **c** before the softmax is
    computed:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了在MNIST数字分类中使用的SimpleRNN和RNN的示意图。`SimpleRNN`比RNN更简单的原因是缺少在softmax计算之前的输出值**O**t
    = V**h**t + **c**：
- en: '![Recurrent neural networks (RNNs)](img/B08956_01_17.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![递归神经网络 (RNN)](img/B08956_01_17.jpg)'
- en: 'Figure 1.5.2: Diagram of SimpleRNN and RNN'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5.2：SimpleRNN和RNN的示意图
- en: RNNs might be initially harder to understand when compared to MLPs or CNNs.
    In MLPs, the perceptron is the fundamental unit. Once the concept of the perceptron
    is understood, MLPs are just a network of perceptrons. In CNNs, the kernel is
    a patch or window that slides through the feature map to generate another feature
    map. In RNNs, the most important is the concept of self-loop. There is in fact
    just one cell.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 与MLP或CNN相比，RNN在初始阶段可能更难理解。在MLP中，感知机是基本单元。一旦理解了感知机的概念，MLP就只是感知机的网络。在CNN中，卷积核是一个滑过特征图以生成另一个特征图的窗口。在RNN中，最重要的是自循环的概念。实际上，只有一个单元。
- en: The illusion of multiple cells appears because a cell exists per timestep but
    in fact, it is just the same cell reused repeatedly unless the network is unrolled.
    The underlying neural networks of RNNs are shared across cells.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 多个单元的错觉出现是因为每个时间步长都有一个单元，但实际上，除非网络被展开，否则它只是相同的单元被重复使用。RNN的底层神经网络在单元之间是共享的。
- en: The summary in *Listing* *1.5.2* indicates that using a `SimpleRNN` requires
    a fewer number of parameters. *Figure 1.5.3* shows the graphical description of
    the RNN MNIST digit classifier. The model is very concise. *Table 1.5.1* shows
    that the `SimpleRNN` has the lowest accuracy among the networks presented.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '*列表* *1.5.2*中的总结指出，使用`SimpleRNN`需要较少的参数。*图1.5.3*展示了RNN MNIST数字分类器的图形描述。该模型非常简洁。*表1.5.1*显示，`SimpleRNN`在所展示的网络中具有最低的准确率。'
- en: 'Listing 1.5.2, RNN MNIST digit classifier summary:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 列表1.5.2，RNN MNIST数字分类器总结：
- en: '[PRE21]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![Recurrent neural networks (RNNs)](img/B08956_01_18.jpg)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![递归神经网络 (RNN)](img/B08956_01_18.jpg)'
- en: 'Figure 1.5.3: The RNN MNIST digit classifier graphical description'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5.3：RNN MNIST数字分类器的图形描述
- en: '| Layers | Optimizer | Regularizer | Train Accuracy, % | Test Accuracy, % |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 层数 | 优化器 | 正则化器 | 训练准确率，% | 测试准确率，% |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 256 | SGD | Dropout(0.2) | 97.26 | 98.00 |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 256 | SGD | Dropout(0.2) | 97.26 | 98.00 |'
- en: '| 256 | RMSprop | Dropout(0.2) | 96.72 | 97.60 |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 256 | RMSprop | Dropout(0.2) | 96.72 | 97.60 |'
- en: '| 256 | Adam | Dropout(0.2) | 96.79 | 97.40 |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 256 | Adam | Dropout(0.2) | 96.79 | 97.40 |'
- en: '| 512 | SGD | Dropout(0.2) | 97.88 | 98.30 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 512 | SGD | Dropout(0.2) | 97.88 | 98.30 |'
- en: 'Table 1.5.1: The different SimpleRNN network configurations and performance
    measures'
  id: totrans-261
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 表 1.5.1：不同的SimpleRNN网络配置和性能测量
- en: In many deep neural networks, other members of the RNN family are more commonly
    used. For example, **Long Short-Term Memory** (**LSTM**) networks have been used
    in both machine translation and question answering problems. LSTM networks address
    the problem of long-term dependency or remembering relevant past information to
    the present output.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多深度神经网络中，RNN家族的其他成员更常被使用。例如，**长短期记忆**（**LSTM**）网络已广泛应用于机器翻译和问答问题。LSTM网络解决了长期依赖问题，即将相关的过去信息记忆到当前输出。
- en: 'Unlike RNNs or SimpleRNN, the internal structure of the LSTM cell is more complex.
    *Figure 1.5.4* shows a diagram of LSTM in the context of MNIST digit classification.
    LSTM uses not only the present input and past outputs or hidden states; it introduces
    a cell state, **s**t, that carries information from one cell to the other. Information
    flow between cell states is controlled by three gates, **f**t, **i**t and **q**t.
    The three gates have the effect of determining which information should be retained
    or replaced and the amount of information in the past and current input that should
    contribute to the current cell state or output. We will not discuss the details
    of the internal structure of the LSTM cell in this book. However, an intuitive
    guide to LSTM can be found at: [http://colah.github.io/posts/2015-08-Understanding-LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs).'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 与RNN或SimpleRNN不同，LSTM单元的内部结构更为复杂。*图 1.5.4*展示了在MNIST数字分类上下文中的LSTM示意图。LSTM不仅使用当前输入和过去的输出或隐藏状态，还引入了一个单元状态，**s**t，用于将信息从一个单元传递到另一个单元。单元状态之间的信息流由三个门控控制，分别是**f**t、**i**t和**q**t。这三个门控的作用是决定哪些信息应被保留或替换，以及过去和当前输入中的哪些信息应对当前单元状态或输出做出贡献。本书中不讨论LSTM单元的内部结构的详细内容。但是，关于LSTM的直观指南可以参考：[http://colah.github.io/posts/2015-08-Understanding-LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs)。
- en: The `LSTM()` layer can be used as a drop-in replacement to `SimpleRNN()`. If
    LSTM is overkill for the task at hand, a simpler version called **Gated Recurrent
    Unit** (**GRU**) can be used. GRU simplifies LSTM by combining the cell state
    and hidden state together. GRU also reduces the number of gates by one. The `GRU()`
    function can also be used as a drop-in replacement for `SimpleRNN()`.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '`LSTM()`层可以作为`SimpleRNN()`的直接替代。如果LSTM对当前任务而言过于复杂，可以使用一个更简单的版本，称为**门控循环单元**（**GRU**）。GRU通过将单元状态和隐藏状态结合来简化LSTM。GRU还通过减少一个门控来降低复杂度。`GRU()`函数也可以作为`SimpleRNN()`的直接替代。'
- en: '![Recurrent neural networks (RNNs)](img/B08956_01_19.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![递归神经网络（RNN）](img/B08956_01_19.jpg)'
- en: 'Figure 1.5.4: Diagram of LSTM. The parameters are not shown for clarity'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.5.4：LSTM的示意图。为了清晰起见，参数未显示。
- en: There are many other ways to configure RNNs. One way is making an RNN model that
    is bidirectional. By default, RNNs are unidirectional in the sense that the current
    output is only influenced by the past states and the current input. In bidirectional
    RNNs, future states can also influence the present state and the past states by
    allowing information to flow backward. Past outputs are updated as needed depending
    on the new information received. RNNs can be made bidirectional by calling a wrapper
    function. For example, the implementation of bidirectional LSTM is `Bidirectional(LSTM())`.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 配置RNN的方式有很多种。一种方式是创建一个双向的RNN模型。默认情况下，RNN是单向的，即当前输出仅受过去状态和当前输入的影响。而在双向RNN中，未来状态也可以通过允许信息反向流动来影响当前状态和过去状态。过去的输出会根据接收到的新信息进行更新。可以通过调用包装函数将RNN转为双向。例如，双向LSTM的实现是`Bidirectional(LSTM())`。
- en: For all types of RNNs, increasing the units will also increase the capacity.
    However, another way of increasing the capacity is by stacking the RNN layers.
    You should note though that as a general rule of thumb, the capacity of the model
    should only be increased if needed. Excess capacity may contribute to overfitting,
    and as a result, both longer training time and slower performance during prediction.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有类型的RNN，增加单元数也会增加模型的容量。然而，增加容量的另一种方式是通过堆叠RNN层。不过，作为一般经验法则，只有在必要时才应增加模型容量。过多的容量可能导致过拟合，从而导致训练时间延长并在预测时出现较慢的性能。
- en: Conclusion
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: This chapter provided an overview of the three deep learning models – MLPs,
    RNNs, CNNs – and also introduced Keras, a library for the rapid development, training
    and testing those deep learning models. The sequential API of Keras was also discussed.
    In the next chapter, the Functional API will be presented, which will enable us
    to build more complex models specifically for advanced deep neural networks.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 本章概述了三种深度学习模型——MLP、RNN 和 CNN——并介绍了 Keras，这是一个用于快速开发、训练和测试这些深度学习模型的库。本章还讨论了 Keras
    的顺序 API。在下一章中，将介绍功能性 API，它将使我们能够构建更复杂的模型，特别是针对高级深度神经网络。
- en: This chapter also reviewed the important concepts of deep learning such as optimization,
    regularization, and loss function. For ease of understanding, these concepts were
    presented in the context of the MNIST digit classification. Different solutions
    to the MNIST digit classification using artificial neural networks, specifically
    MLPs, CNNs, and RNNs, which are important building blocks of deep neural networks,
    were also discussed together with their performance measures.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还回顾了深度学习中的重要概念，如优化、正则化和损失函数。为了便于理解，这些概念是在 MNIST 数字分类的背景下呈现的。我们还讨论了使用人工神经网络（特别是
    MLP、CNN 和 RNN）解决 MNIST 数字分类的不同方法，并讨论了它们的性能评估。MLP、CNN 和 RNN 是深度神经网络的重要构建块。
- en: With the understanding of deep learning concepts, and how Keras can be used
    as a tool with them, we are now equipped to analyze advanced deep learning models.
    After discussing Functional API in the next chapter, we'll move onto the implementation
    of popular deep learning models. Subsequent chapters will discuss advanced topics
    such as autoencoders, GANs, VAEs, and reinforcement learning. The accompanying
    Keras code implementations will play an important role in understanding these
    topics.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对深度学习概念的理解，以及如何将 Keras 用作这些概念的工具，我们现在已经准备好分析高级深度学习模型。在下一章讨论功能性 API 后，我们将进入流行深度学习模型的实现。后续章节将讨论一些高级主题，如自编码器、GAN、VAE
    和强化学习。配套的 Keras 代码实现将对理解这些主题起到重要作用。
- en: References
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'LeCun, Yann, Corinna Cortes, and C. J. Burges. MNIST handwritten digit database.
    AT&T Labs [Online]. Available: [http://yann. lecun. com/exdb/mnist 2 (2010)](http://yann.%20lecun.%20com/exdb/mnist%202%20(2010)).'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LeCun, Yann, Corinna Cortes, 和 C. J. Burges. MNIST 手写数字数据库。AT&T 实验室 [在线]. 可用链接：[http://yann.
    lecun. com/exdb/mnist 2 (2010)](http://yann.%20lecun.%20com/exdb/mnist%202%20(2010))。
