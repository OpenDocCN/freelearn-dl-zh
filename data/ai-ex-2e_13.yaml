- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: Visualizing Networks with TensorFlow 2.x and TensorBoard
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow 2.x和TensorBoard可视化网络
- en: In this chapter, we are going to take a peek inside a machine's "mind" while
    it's "thinking" through the layers of a deep learning neural network. The number
    of lines of code required to build a sequential classifier for a **convolutional
    neural network** (**CNN**) has been drastically reduced with TensorFlow 2\. Running
    the classifier only takes a click. However, to understand the program when something
    goes wrong is a more difficult task, and visualizing the outputs of the layers
    can be very productive.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将窥视机器在“思考”过程中，如何通过深度学习神经网络的各层进行处理。使用TensorFlow 2构建**卷积神经网络**（**CNN**）的顺序分类器所需的代码行数大大减少。运行分类器只需点击一下。然而，当程序出现问题时，理解程序的运行逻辑变得更加困难，而可视化各层的输出可以大有裨益。
- en: Visualizing the output of the layers of a CNN can provide an in-depth knowledge
    of each individual step comprising the whole process.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化CNN各层的输出可以深入了解组成整个过程的每个独立步骤。
- en: In this chapter, as in several of the preceding chapters, we will define the
    layers of a CNN. This time, we will add more layers and extract the output of
    each layer to create output images. We will build this process from scratch in
    a bottom-to-top approach in TensorFlow 2 in Python.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，和前几章一样，我们将定义CNN的各层。这一次，我们将增加更多层并提取每一层的输出，生成输出图像。我们将从头开始，采用从下到上的方法，使用Python中的TensorFlow
    2构建此过程。
- en: Once the outputs have been defined, we will display the output of the convolutional,
    pooling, dropout, flattening, and dense layers.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦输出被定义，我们将显示卷积层、池化层、丢弃层、扁平化层和全连接层的输出。
- en: Viewing the output of the layers provides an intuitive sense of what the layers
    are doing. Being able to visualize the global graph of the model makes the architecture
    of the CNN visible.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 查看各层的输出提供了对各层功能的直观理解。能够可视化模型的全局图使得CNN的架构得以显现。
- en: We will use TensorBoard to explore the conceptual model, the epochs versus the
    accuracy, and the detail of the operations of mathematical functions. These graphs
    and measurements will be built using a top-to-bottom approach using Google Colaboratory.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用TensorBoard来探索概念模型、训练轮次与准确度的关系，以及数学函数操作的细节。这些图表和测量将通过从上到下的方法，使用Google Colaboratory构建。
- en: Google Colaboratory provides a free server with ready-to-use libraries and modules.
    We will use a Google Colaboratory notebook to explore TensorBoard functions. The
    chapter is divided into three main sections. The first two sections describe how
    to build a sequential classifier with TensorFlow 2.2 and display the outputs of
    the layers with TensorFlow 2.2\. The third section describes how to display the
    graph information and accuracy measurement with the TensorFlow 2 version of TensorBoard.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Google Colaboratory提供了一个免费服务器，预装了可用的库和模块。我们将使用Google Colaboratory笔记本来探索TensorBoard的功能。本章分为三个主要部分。前两部分介绍如何使用TensorFlow
    2.2构建一个顺序分类器并显示各层的输出。第三部分介绍如何使用TensorFlow 2版本的TensorBoard展示图形信息和准确度测量。
- en: 'The topics covered in this chapter will provide visual insights into CNNs:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍以下主题，并为CNN提供视觉上的深入理解：
- en: Building a CNN layer by layer
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一层一层地构建CNN
- en: Displaying the dataset
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示数据集
- en: Displaying the output of the layers of the CNN
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示CNN各层的输出
- en: Using Google Colaboratory
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Google Colaboratory
- en: Visualizing the architecture of a neural network with TensorBoard
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorBoard可视化神经网络架构
- en: Visualizing accuracy measurements with TensorBoard
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TensorBoard可视化准确度测量
- en: Let's start off this chapter by discussing how we can explore the output of
    the layers within a CNN.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从讨论如何在CNN中探索各层的输出开始本章内容。
- en: Exploring the output of the layers of a CNN in two steps with TensorFlow
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TensorFlow以两步法探索CNN各层的输出
- en: Many corporate contracts in the field of business intelligence require an explanation
    process for any algorithm that makes automatic and critical decisions. It is often
    mandatory for the editor of algorithms, artificial intelligence or not, to provide
    an explanation. We need to be prepared for that.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 许多商业智能领域的企业合同要求对任何自动化和关键决策算法进行解释过程。对于算法编辑者，无论是否为人工智能，提供解释通常是强制性的要求。我们需要为此做好准备。
- en: Also, maintenance becomes critical once artificial intelligence runs in production.
    Developers often move from one department to another, from one company to another.
    The person that has to maintain the program needs to understand it in detail.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一旦人工智能在生产环境中运行，维护变得至关重要。开发人员经常从一个部门转到另一个部门，从一个公司转到另一个公司。必须维护程序的人需要详细了解它。
- en: Exploring and visualizing a CNN is a good way to get our hands dirty, open the hood
    of our roadster and see how the engine works!
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 探索和可视化CNN是一个很好的方式，让我们亲自实践，打开跑车的引擎盖，看看引擎是如何运作的！
- en: First, we will first build the CNN layer by layer. We will be building the sequential
    classifier with TensorFlow 2 from the bottom to the top.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们将逐层构建CNN。我们将使用TensorFlow 2从底到顶构建顺序分类器。
- en: 'We will not be using a Keras model directly; we''ll use TensorFlow''s integrated
    Keras module, which brings the number of lines of header down to only two lines:'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们不会直接使用Keras模型；我们将使用TensorFlow集成的Keras模块，这样将标题的行数减少到只有两行：
- en: '[PRE0]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Then we will explore the visual output of the layers to gain insights into the
    way it "thinks."
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们将探索各层的可视化输出，以深入了解它是如何“思考”的。
- en: With that, let's get on with building!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在让我们开始构建吧！
- en: Building the layers of a CNN
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建CNN的各层
- en: A CNN was described in *Chapter 9*, *Abstract Image Classification with Convolutional
    Neural Networks (CNNs)*. In the example to follow, the CNN will contain more layers
    to visualize the way a neural network extracts features step by step.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第9章*中描述了CNN，*使用卷积神经网络（CNN）进行抽象图像分类*。在接下来的示例中，CNN将包含更多层，以便逐步可视化神经网络如何提取特征。
- en: We will be using a dataset that uses a single image to explore the layers of
    a CNN. This image is repeated several times for the training dataset and the test
    dataset is enough to build and run the model to visualize the layers of the neural
    network.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个数据集，通过一个图像探索CNN的各层。该图像在训练数据集中重复多次，而测试数据集足够用来构建和运行模型以可视化神经网络的各层。
- en: The dataset contains an image of a flower repeated several times—an iris.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中包含一张重复多次的花朵图像——一朵虹膜花。
- en: '![](img/B15438_13_01.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_01.png)'
- en: 'Figure 13.1: The image of the image we are exploring in this chapter'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1：我们在本章中探索的图像
- en: 'The goal is not to have many variations of the image, but to simply see how
    a CNN represents an iris layer by layer. The dataset contains a repeated image.
    However, you can change these images and use a dataset of your own then display
    the images as follows using the same code:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 目标不是让图像有很多变化，而是简单地看看CNN是如何逐层表示虹膜的。数据集中包含了一张重复的图像。然而，你可以更改这些图像，使用你自己的数据集，然后使用相同的代码如下所示展示图像：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The result will be a figure with lines of images from the dataset:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 结果将是一个包含来自数据集的图像行的图形：
- en: '![](img/B15438_13_02.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_02.png)'
- en: 'Figure 13.2: Displaying the dataset'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.2：显示数据集
- en: 'We will first import the neural network modules:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先导入神经网络模块：
- en: '[PRE2]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Building the CNN only takes a few lines. This makes it deceptively simple because
    it appears to be a black box. In our example, the structure described in *Chapter
    9*, *Abstract Image Classification with Convolutional Neural Networks (CNNs)*,
    in its enhanced version here, only requires a few minutes to create from lines
    30 to 68:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 构建CNN只需要几行代码。这看起来非常简单，因为它似乎是一个黑箱。在我们的例子中，*第9章*中描述的结构，*使用卷积神经网络（CNN）进行抽象图像分类*，在这里的增强版，只需几分钟就能从第30行到第68行创建：
- en: '[PRE3]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We will go back to these layers in the next section when we explore their output.
    The main point to focus on here remains the simplicity of the code. Building a
    CNN as a black box in a few minutes might work. However, understanding each layer
    when a problem comes up requires a deeper understanding of the representations
    of the layers.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们探索各层的输出时，我们将在下一节回到这些层。这里需要关注的主要点是代码的简洁性。虽然在几分钟内构建一个CNN作为一个黑箱可能行得通，但当问题出现时，要理解每一层需要对各层的表示有更深入的理解。
- en: 'Before exploring those layers, the program prints the structure of the classifier
    (CNN):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索这些层之前，程序会打印分类器（CNN）的结构：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The model contains a fair number of layers to explore:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 模型包含相当数量的层来进行探索：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Keep an eye on this summary. It will prove useful when choosing the number of
    layers you wish to explore to visualize the outputs.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意这个总结。当选择你想要探索的层数以可视化输出时，它将非常有用。
- en: 'The model is then compiled:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，模型被编译：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then training and test datasets are processed (rescaled) and defined:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后处理（重新缩放）并定义训练和测试数据集：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: If we stop here, the CNN will work. But will we have really understood the model?
    I don't think so. Of course, it only takes a simple click to get the CNN to run
    after installing a ready-to-use dataset. This black box approach can work, but
    exploring the visual output of a layer provides a better representation of the
    network. Let's take a look at that next.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在这里停下来，CNN 就能正常工作。但我们真正理解了这个模型吗？我觉得不是。当然，安装好一个现成的数据集后，只需点击几下即可运行 CNN。这种黑盒子的方法固然可行，但是探索一层的视觉输出能更好地代表网络。接下来我们来看看这个。
- en: Processing the visual output of the layers of a CNN
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理 CNN 层的视觉输出
- en: The idea is to focus on an image and actually *see* the "mental," visual, representation
    a CNN calculates, layer by layer.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于专注于一幅图像，实际上 *看见* CNN 逐层计算的“心理”、视觉表示。
- en: 'To process the layers, the program first selects an image for the activation
    model to work on:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理这些层，程序首先选择一个图像供激活模型使用：
- en: '[PRE8]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then the visualization process runs in a few steps, which will take us inside
    the CNN:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 然后可视化过程分几步进行，这将带领我们深入 CNN：
- en: '**Selecting the number of layers to visualize using the** `e` **variable**:
    Going back to the model summary displayed previously, you can choose the layer you
    want to stop at. In this example, we''re stopping at `e=12`. You can choose to
    start with `e=4` to visualize the first convolutional and pooling layers:'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选择要可视化的层数量使用** `e` **变量**：回到之前显示的模型摘要，你可以选择要停在哪一层。在这个例子中，我们选择停在 `e=12`。你可以选择从
    `e=4` 开始可视化第一卷积和池化层：'
- en: '[PRE9]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If `e=3`, the program will stop at `max_pooling2d`:'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果 `e=3`，程序会在 `max_pooling2d` 处停止：
- en: '[PRE10]'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '**Selecting the top n layers that will be explored**: The program refers to
    `layer_outputs` to extract the information it needs to visualize the target layers:'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选择要探索的前 n 个层**：程序参考 `layer_outputs` 提取它需要可视化目标层的信息：'
- en: '[PRE11]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**Applying the activation model to extract the requested layers**: Activating
    the model forces the classifier to get to work and run through the layers. That
    way, we can peek inside its "thought" process and see how it represents inputs:'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用激活模型来提取请求的层**：激活模型迫使分类器开始工作并通过层。这样，我们可以窥探其“思考”过程，看看它如何表示输入：'
- en: '[PRE12]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '**Retrieving the layer names to display, along with the visual representation
    of the layer**: Layer names help us understand what we are looking at. Use the
    model summary we printed earlier as a map to see where you are when the layer
    name is displayed, along with the representation of the output of that same layer:'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索层名称以及层的视觉表示以显示**：层名称帮助我们理解我们正在观察什么。使用我们之前打印的模型摘要作为地图，查看当显示层名称时所处的位置，以及该层输出的表示：'
- en: '[PRE13]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**Processing layer outputs and organizing them into grids**: To avoid having
    to watch a sequential display of the variations of the representations in a given
    layer, we are going to organize them in one grid image:'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理层输出并将其组织成网格**：为了避免观看给定层表示的变化的顺序显示，我们将它们组织成一个网格图像：'
- en: '[PRE14]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '**Displaying the processed layer outputs**: Now that the work is done, we just
    have to display the layer names along with the corresponding grids:'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**显示处理后的层输出**：现在工作已经完成，我们只需显示层名称以及相应的网格：'
- en: '[PRE15]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note that the figures are saved by `plt.savefig` in an output directory for
    later use.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这些图像是通过 `plt.savefig` 保存在输出目录中以便后续使用。
- en: 'You will obtain a list of figures with the name of the layer for the layers
    you chose to visualize. For example, you can view the images of the first seven
    layers. You can look at them in the following figures or by running the program.
    In any case, the best way to analyze the layers is to look closely at the first
    layer and then at the last layer. You will see that the CNN is carefully extracting
    an abstract representation of the image and displaying higher dimensions. The
    reason the differences between the layers are difficult to perceive with the human
    eye comes from two factors:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你将获得一个图层名称列表，其中包含你选择可视化的图层。例如，你可以查看前七个图层的图像。你可以通过以下图表或运行程序查看它们。无论如何，分析层的最佳方法是仔细观察第一层，然后再观察最后一层。你会发现，CNN
    正在精确地提取图像的抽象表示，并显示更高的维度。难以用人眼感知层之间差异的原因有两个因素：
- en: The number of elements to analyze is extremely difficult for us to observe.
    Usually our brain does this without us having to think about it!
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分析的元素数量对我们来说极为困难。通常我们的大脑会在我们不知不觉中完成这个过程！
- en: There are several convolutional layers versus one layer that would rush through
    the process of obtaining an abstract representation of the image. It's going layer
    by layer, just like a human brain processes an image step-by-step.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有多个卷积层，而不是一个层，后者会迅速完成获取图像抽象表示的过程。它是逐层处理的，就像人类大脑一步步处理图像一样。
- en: Look at the following first layer then the last one, then go back and observe
    the differences between the layers.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下第一个层和最后一个层，然后回过头来观察各层之间的差异。
- en: '![Une image contenant équipement électronique, capture d’écran  Description
    générée automatiquement](img/B15438_13_03.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![一张包含电子设备的截图，自动生成的描述](img/B15438_13_03.png)'
- en: 'Figure 13.3: Convolutional layer'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.3：卷积层
- en: '![Une image contenant équipement électronique, afficher  Description générée
    automatiquement](img/B15438_13_04.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![一张包含电子设备的图片，自动生成的描述](img/B15438_13_04.png)'
- en: 'Figure 13.4: Convolutional layer'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.4：卷积层
- en: '![Une image contenant équipement électronique, afficher  Description générée
    automatiquement](img/B15438_13_05.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![一张包含电子设备的图片，自动生成的描述](img/B15438_13_05.png)'
- en: 'Figure 13.5: Pooling layer'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.5：池化层
- en: '![Une image contenant équipement électronique, afficher  Description générée
    automatiquement](img/B15438_13_06.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![一张包含电子设备的图片，自动生成的描述](img/B15438_13_06.png)'
- en: 'Figure 13.6: Dropout layer'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.6：丢弃层
- en: '![Une image contenant tableau de points, afficher, équipement électronique  Description
    générée automatiquement](img/B15438_13_07.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![一张包含点阵图的图片，电子设备，自动生成的描述](img/B15438_13_07.png)'
- en: 'Figure 13.7: Convolutional layer'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.7：卷积层
- en: '![Une image contenant tableau de points, texte  Description générée automatiquement](img/B15438_13_08.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![一张包含点阵图的图片，文本，自动生成的描述](img/B15438_13_08.png)'
- en: 'Figure 13.8: Convolutional layer'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.8：卷积层
- en: '![Une image contenant tableau de points, texte  Description générée automatiquement](img/B15438_13_09.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![一张包含点阵图的图片，文本，自动生成的描述](img/B15438_13_09.png)'
- en: 'Figure 13.9: Pooling layer'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.9：池化层
- en: Visualizing the output of the layers of a CNN provides a fantastic way to understand and
    analyze a neural network. Let's go a step further and analyze the layers.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化 CNN 层的输出提供了一个绝佳的方式来理解和分析神经网络。让我们更进一步，分析这些层。
- en: Analyzing the visual output of the layers of a CNN
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分析 CNN 层的视觉输出
- en: An input image is chaos until some form of intelligence makes sense of it. Any
    form of intelligence will detect patterns and structures. Machine intelligence
    works on the same grounds by increasing the level of abstraction through dimensionality
    reduction. The process of going from chaos to an organized representation is at
    the heart of the fantastic invention of present-day neural networks.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 输入图像是混乱的，直到某种形式的智能将其理清。任何形式的智能都会检测出其中的模式和结构。机器智能通过增加抽象层级来实现同样的目标，方法是通过降维。将混乱转化为有序表示的过程是当今神经网络这一伟大发明的核心。
- en: When running `cnn_layers.py`, the layer outputs will be displayed. Let's explore
    some of the layers. You can explore some or all of them by simply changing the
    value of the `e = <number-of-layers>` variable on line 107.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 `cnn_layers.py` 时，层输出将会显示。让我们来探索其中的一些层。你可以通过简单地更改第107行中 `e = <number-of-layers>`
    变量的值来探索其中的部分或全部层。
- en: Convolutional layer activation functions
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 卷积层激活函数
- en: 'One of the key options of a convolutional layer is the activation function.
    `relu` is used in the following `cnn_layers.py`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层的一个关键选项是激活函数。在以下的 `cnn_layers.py` 中使用了 `relu`：
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: For more on ReLU, please go the explanation in *Chapter 9*, *Abstract Image
    Classification with Convolutional Neural Networks (CNNs)*.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 ReLU 的更多内容，请参阅*第9章*，*使用卷积神经网络（CNN）进行抽象图像分类*。
- en: '`relu` produces the following output for the `Conv2d` layer:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`relu` 为 `Conv2d` 层生成以下输出：'
- en: '![](img/B15438_13_10.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_10.png)'
- en: 'Figure 13.10: conv2d output 1'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.10：conv2d 输出 1
- en: 'Now go to line 33 and replace `relu` with `softmax` as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在去第33行，将 `relu` 替换为 `softmax`，如下所示：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The output is quite different, as we can see:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 输出有很大不同，正如我们所看到的：
- en: '![](img/B15438_13_11.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_11.png)'
- en: 'Figure 13.11: conv2d output 2'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.11：conv2d 输出 2
- en: It takes some time for the human eye to adjust to the change. Look at each version.
    Try to memorize it for a few seconds by closing your eyes and then looking at
    the other one. Our brain does this implicitly which is why it takes an effort
    to do this explicitly.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 人眼需要一些时间来适应这种变化。看看每个版本。试着在闭上眼睛几秒钟后记住它，然后再看另一个版本。我们的脑海里会下意识地做这件事，这也是为什么我们需要刻意做这个练习的原因。
- en: Which one should you use? Welcome to deep learning! There is no certain answer
    to that question. It is a trial-and-error process. An activation function might
    fit one model and not another. Even if the accuracy of the network is acceptable
    during the training process, you might have to change the activation function
    over time when new data produces bad results.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该使用哪一个？欢迎来到深度学习！对于这个问题没有确定的答案。这是一个试错的过程。一个激活函数可能适合某个模型，而不适合另一个模型。即使在训练过程中网络的准确度是可以接受的，当新数据产生不良结果时，你可能需要随着时间的推移更改激活函数。
- en: For more on softmax, please go back to the explanation in *Chapter 2*, *Building
    a Reward Matrix – Designing Your Datasets*.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 softmax 的更多信息，请回到*第二章*中的解释，*构建奖励矩阵 - 设计你的数据集*。
- en: 'Let''s try the logistic sigmoid activation function, `sigmoid`, also described
    in *Chapter 2*:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试`sigmoid`逻辑斯谛激活函数，它也在*第二章*中有描述：
- en: '![](img/B15438_13_12.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_12.png)'
- en: 'Figure 13.12: conv2d output 3'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.12：conv2d 输出 3
- en: Notice the differences again. Observe the last image on row 1 for each activation
    function. The differences are fascinating because they provide a variety of possible
    representations.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 再次注意差异。观察每个激活函数下第1行的最后一张图像。这些差异非常有趣，因为它们提供了各种可能的表示。
- en: Try other activation functions to get the feel of the way an artificial neural
    network transforms what it perceives into a higher level of abstraction through
    a reduction of the dimensions that it has to process.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试其他激活函数，感受一下人工神经网络如何通过减少需要处理的维度，将它所感知到的信息转化为更高层次的抽象。
- en: Convolutional layers higher-level representations through the layers
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 卷积层通过各层传递的高层次表示
- en: Notice the incredible level of abstraction the sequential classifier reaches
    through the following outputs going from `conv2d` to `conv2d_5`, which is, in
    fact, the sixth (0 to 5) convolutional layer of `cnn_layers.py`.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，通过以下输出，从`conv2d`到`conv2d_5`，顺序分类器所达到的惊人抽象级别，实际上这是`cnn_layers.py`中的第六层（0 到
    5）卷积层。
- en: The network starts at a relatively figurative representation to reach a highly
    abstract level at `conv2d_5`. We are literally inside the machine's "mind," watching
    it think and learn!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 网络从一个相对形象化的表示开始，逐步达到 `conv2d_5` 的高度抽象级别。我们实际上处于机器的“思维”中，观察它思考和学习！
- en: '![](img/B15438_13_13.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_13.png)'
- en: 'Figure 13.13: Initial conv2d output'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.13：初始 conv2d 输出
- en: '![](img/B15438_13_14.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_14.png)'
- en: 'Figure 13.14: conv2d_1 output'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.14：conv2d_1 输出
- en: '![](img/B15438_13_15.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_15.png)'
- en: 'Figure 13.15: conv2d_2 output'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.15：conv2d_2 输出
- en: '![](img/B15438_13_16.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_16.png)'
- en: 'Figure 13.16: conv2d_3 output'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.16：conv2d_3 输出
- en: '![](img/B15438_13_17.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_17.png)'
- en: 'Figure 13.17: conv2d_4 output'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.17：conv2d_4 输出
- en: '![](img/B15438_13_18.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_18.png)'
- en: 'Figure 13.18: conv2d_5 output'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.18：conv2d_5 输出
- en: This abstraction process owes a lot to the other layers, such as the pooling
    layer.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这一抽象过程在很大程度上得益于其他层次，如池化层。
- en: Pooling layers to obtain higher-level representations
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 池化层获取更高层次表示
- en: 'The pooling layer is going to reduce the number of dimensions of its input
    and choose the most representative features it finds:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 池化层将减少输入的维度数量，并选择它找到的最具代表性的特征：
- en: '[PRE18]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let''s explore the evolution of the first two pooling layers in this example:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨一下这个例子中前两个池化层的演变：
- en: '![](img/B15438_13_19.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_19.png)'
- en: 'Figure 13.19: max_pooling2d output'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.19：max_pooling2d 输出
- en: '![](img/B15438_13_20.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_20.png)'
- en: 'Figure 13.20: max_pooling2d_1 output'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.20：max_pooling2d_1 输出
- en: Once again, we can see the powerful level of abstraction a CNN can attain.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们可以看到CNN所能达到的强大抽象级别。
- en: For more information on the pooling layer, please read the explanations in *Chapter
    9*, *Abstract Image Classification with Convolutional Neural Networks (CNNs)*.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 关于池化层的更多信息，请阅读*第九章*中的解释，*使用卷积神经网络（CNNs）进行抽象图像分类*。
- en: Dropout layer higher-level representations through the layers
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Dropout层通过各层传递的高层次表示
- en: 'The dropout layers provide a way to abandon many features in order to reach
    a simplified higher level of representation:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: dropout 层提供了一种放弃许多特征的方式，以达到简化的更高层次表示：
- en: '[PRE19]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: It is not always necessary to add a dropout layer because it depends on the
    productivity and architecture of the model you are exploring. For this example,
    the first two dropout layers are quite instructive. Dropouts are also a way to
    avoid overfitting. The model learns how to extract key features to obtain an abstract
    representation, not a literal one.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 并非总是需要添加 dropout 层，因为这取决于你正在探索的模型的生产力和架构。在这个例子中，前两个 dropout 层是非常具有指导意义的。dropout
    也是一种避免过拟合的方式。模型学习如何提取关键特征以获得抽象表示，而不是字面表示。
- en: '![](img/B15438_13_21.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_21.png)'
- en: 'Figure 13.21: dropout output'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.21：dropout 输出
- en: '![](img/B15438_13_22.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_22.png)'
- en: 'Figure 13.22: dropout_1 output'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.22：dropout_1 输出
- en: Observe again how the dropout layers accelerate the abstraction process. We
    can see the CNN's "mind" working.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 再次观察 dropout 层如何加速抽象过程。我们可以看到 CNN 的“大脑”在运作。
- en: Recommendation
  id: totrans-149
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 推荐
- en: I recommend you try different activation functions and various options for the layers of
    this example. Then run the program and get a feel of what is going inside a CNN's
    "machine thinking" process. Even if it is a purely mathematical architecture,
    it provides a good idea of how a CNN, while not human at all, has its own "machine
    thinking" approach.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议你尝试不同的激活函数和各种层的选项，然后运行程序，感受一下 CNN “机器思维”过程中的运作。即使它是一个纯粹的数学架构，它也能很好地展示 CNN
    的“机器思维”方式，尽管它完全不是人类，但它有自己的“机器思维”方法。
- en: Now that we have explored a CNN from bottom to top, let's see how to observe
    the accuracy of a CNN from top to bottom using TensorBoard.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经从下到上探索了 CNN，让我们看看如何使用 TensorBoard 从上到下观察 CNN 的准确性。
- en: Analyzing the accuracy of a CNN using TensorBoard
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorBoard 分析 CNN 的准确性
- en: In this section, we will first get started with a free Google Colaboratory server
    and then explore some of the TensorBoard ANN measurement functions.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将首先开始使用免费的 Google Colaboratory 服务器，然后探索一些 TensorBoard ANN 测量功能。
- en: Getting started with Google Colaboratory
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始使用 Google Colaboratory
- en: 'You can get access to your free instance of Google Colaboratory server in just
    a few steps:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需几个步骤就能获得免费的 Google Colaboratory 服务器实例：
- en: Make sure you have a Google account and log into it.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保你有一个 Google 账户并登录。
- en: 'Click on the following link, which takes leads you to Google Colaboratory:
    [https://colab.research.google.com/notebooks/welcome.ipynb#recent=true](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true)'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击以下链接，它将带你到 Google Colaboratory：[https://colab.research.google.com/notebooks/welcome.ipynb#recent=true](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true)
- en: 'You will be taken to the following page:'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你将被带到以下页面：
- en: '![](img/B15438_13_23.png)'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![](img/B15438_13_23.png)'
- en: 'Figure 13.23: Colaboratory initial landing page'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.23：Colaboratory 初始登陆页面
- en: Click on the **UPLOAD** option in the top right:![](img/B15438_13_24.png)
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击右上角的**UPLOAD**选项：![](img/B15438_13_24.png)
- en: 'Figure 13.24: Upload option'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.24：上传选项
- en: You can choose or drag and drop a file, then upload it.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以选择或拖放一个文件，然后上传它。
- en: Upload `TF_2_graphs.ipynb`.
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上传 `TF_2_graphs.ipynb`。
- en: 'You can download the program from this link and then upload it: [https://github.com/PacktPublishing/Artificial-Intelligence-By-Example-Second-Edition/blob/master/CH13/TF_2_graphs.ipynb](https://github.com/PacktPublishing/Artificial-Intelligence-By-Example-Second-Edition/blob/master/CH1)'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以从这个链接下载程序并上传它：[https://github.com/PacktPublishing/Artificial-Intelligence-By-Example-Second-Edition/blob/master/CH13/TF_2_graphs.ipynb](https://github.com/PacktPublishing/Artificial-Intelligence-By-Example-Second-Edition/blob/master/CH1)
- en: Once the program is open, you will see the following page:![](img/B15438_13_25.png)
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序打开后，你将看到以下页面：![](img/B15438_13_25.png)
- en: 'Figure 13.25: A Colaboratory notebook'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13.25：一个 Colaboratory 笔记本
- en: 'Go to **File** in the menu and save the notebook to your Google Drive:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在菜单中点击**文件**并将笔记本保存到你的 Google Drive：
- en: '![](img/B15438_13_26.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_26.png)'
- en: 'Figure 13.26: The File menu'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.26：文件菜单
- en: Once the file is saved, you are ready to go!
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 文件保存后，你就准备好了！
- en: You have many runtime options, such as making a choice between using a CPU or
    a GPU, display options (background, for example), and many more ways to use Google
    Colaboratory. I recommend reading the document to find the many options available.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 你有许多运行时选项，例如选择使用 CPU 还是 GPU，显示选项（例如背景），以及更多使用 Google Colaboratory 的方式。我推荐阅读文档以了解可用的众多选项。
- en: You are on your free Colaboratory server, and you're ready to explore your notebook.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在在自己的免费Colaboratory服务器上，准备好探索你的笔记本。
- en: Defining and training the model
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义并训练模型
- en: We will run the notebook and then analyze the results. This should provide an
    introduction to both Google Colaboratory and some TensorBoard functions.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将运行笔记本，然后分析结果。这将提供对Google Colaboratory以及一些TensorBoard功能的介绍。
- en: 'First, run the program by clicking on the **Run all** option in the **Runtime**
    menu:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，通过点击**运行所有**选项来运行程序，位于**运行时**菜单中：
- en: '![](img/B15438_13_27.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_27.png)'
- en: 'Figure 13.27: Runtime options'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.27：运行时选项
- en: The program will then go through its cells and provide information on the training
    process. To obtain this information, we will explore some of TensorBoard's key
    functions.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 程序将遍历其单元格并提供关于训练过程的信息。为了获取这些信息，我们将探索TensorBoard的一些关键功能。
- en: We will first install TensorFlow and then run TensorBoard.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先安装TensorFlow，然后运行TensorBoard。
- en: '**Installing TensorFlow and getting TensorBoard running**: As you saw in the previous
    section, you do not need to run the program cell by cell unless a cell contains
    an error. In that case, click on the run button in the cell:'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安装TensorFlow并启动TensorBoard**：如你在前一节看到的，除非单元格包含错误，否则你无需逐个运行程序单元。在这种情况下，点击单元格中的运行按钮：'
- en: '![](img/B15438_13_28.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_28.png)'
- en: 'Figure 13.28: Running a cell'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.28：运行单元格
- en: 'The cell will execute the code. In this case, it will install TensorFlow 2.x:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 单元格将执行代码。在这种情况下，它将安装TensorFlow 2.x：
- en: '[PRE20]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Once the installation is finished and TensorBoard is loaded, the program runs
    through the headers to import the necessary modules.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成并加载TensorBoard后，程序会遍历头部导入必要的模块。
- en: Be careful with TensorBoard versions! You might have a previous or different
    version installed that you are using for another project. Before running this
    program, check any application that is using TensorBoard in your environment.
    Check your configuration carefully before doing anything. If there is a risk,
    use another environment or just read the notebook without running it.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 小心TensorBoard版本！你可能安装了一个旧版本或者是用于其他项目的不同版本。在运行此程序之前，检查一下你环境中任何正在使用TensorBoard的应用。运行之前仔细检查配置。如果存在风险，使用另一个环境或仅查看笔记本而不运行它。
- en: '**The program now defines a simplified model you are now familiar with**: The
    following model has been simplified. The goal here is to show how TensorBoard
    works. You can, of course, add more layers once you have explored the notebook:'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**程序现在定义了一个简化的模型，你现在已经熟悉**：以下模型已简化，目的是展示TensorBoard的工作原理。当然，在探索完笔记本后，你可以添加更多的层。'
- en: '[PRE21]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '**The model is then compiled with an optimizer and accuracy metrics**: The
    model now needs to be compiled and run to provide measurement output:'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型接着使用优化器和准确率指标进行编译**：现在需要编译并运行模型，以便提供测量输出：'
- en: '[PRE22]'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: For more on the Adam optimizer and cross-entropy, see *Chapter 9*, *Abstract
    Image Classification with Convolutional Neural Networks (CNNs)*.
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于Adam优化器和交叉熵的更多内容，参见*第9章*，*使用卷积神经网络（CNN）进行抽象图像分类*。
- en: The model is now trained and ready for metric callbacks for TensorBoard.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 模型现在已经训练完成，准备接受TensorBoard的度量回调。
- en: While the program was running the training, it was saving a log of the main
    functionalities to display. The graph of the model can be displayed in TensorBoard
    with one line along with many other functions.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在程序运行训练时，它将保存主要功能的日志以供展示。模型的图表可以通过一行在TensorBoard中显示，且有许多其他功能。
- en: '[PRE23]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following graph of the model contains many details:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是模型的图表，包含了许多细节：
- en: '![](img/B15438_13_29.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_29.png)'
- en: 'Figure 13.29: TensorFlow graph'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.29：TensorFlow图表
- en: 'If you want to have a simplified view, a conceptual view of the model is also
    displayed:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要简化视图，模型的概念性视图也已展示：
- en: '![](img/B15438_13_30.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_30.png)'
- en: 'Figure 13.30: A partial view of the TensorFlow graph'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.30：TensorFlow图表的部分视图
- en: We have explored the architecture of a neural network model using TensorBoard graphs.
    Let's see how to visualize the measurements of the training process of our model.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过TensorBoard图表探索了神经网络模型的架构。接下来，让我们看看如何可视化模型训练过程中的度量。
- en: Introducing some of the measurements
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入一些度量
- en: While training, the program saved key information in its log directory that
    can now be displayed.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，程序将关键信息保存在日志目录中，现在可以显示这些信息。
- en: '**Epoch accuracy**: If the accuracy increases with the epochs, the classifier
    is progressing, and it is learning correctly. If it decreases, we are in trouble!
    We will have to go back and check the dataset, the activation functions, and how
    the layers were designed.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Epoch 准确性**：如果准确性随着 Epoch 增加而提高，说明分类器在进展，并且学习是正确的。如果准确性下降了，我们就有麻烦了！我们需要回头检查数据集、激活函数以及层的设计。'
- en: '![](img/B15438_13_31.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_31.png)'
- en: 'Figure 13.31: Accuracy of the model'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.31：模型的准确性
- en: '**Basic flow, including an activation function**: TensorBoard has drill-down
    functionality. You can drill down into the actual operations TensorFlow 2.x is calculating:'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础流程，包括激活函数**：TensorBoard 具有深入功能。你可以深入查看 TensorFlow 2.x 正在计算的实际操作：'
- en: '![](img/B15438_13_32.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_32.png)'
- en: 'Figure 13.32: The activation function'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.32：激活函数
- en: '**Exploring the details of an activation function**: Once you have seen the
    flow of an operation, you can even peek inside it to see how it is built:'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**探索激活函数的细节**：一旦你看到了操作的流程，你甚至可以深入查看它是如何构建的：'
- en: '![](img/B15438_13_33.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_13_33.png)'
- en: 'Figure 13.33: The activation function'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.33：激活函数
- en: These TensorBoard graphs and measurements help you dig into the mechanics of
    your model. They provide insights that will add to the ones you acquired when
    exploring the outputs of layers in the first section of this chapter.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 TensorBoard 图形和测量结果帮助你深入了解模型的工作原理。它们提供了对第一节中探索各层输出时所获得的见解的补充。
- en: In this section, we have explored the architecture functions of TensorBoard
    through the many graphs available as well as tools to measure the training performance
    of our model.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们通过多种可用的图形和工具，探讨了 TensorBoard 的架构功能，并衡量了我们模型的训练表现。
- en: Summary
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we explored deep learning from the inside. We saw that building
    a CNN is now easy with TensorFlow 2.x, but peeking inside the way it "thinks"
    gives critical insight.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们从内部探索了深度学习。我们看到，使用 TensorFlow 2.x 构建 CNN 现在变得容易，但深入了解其“思维”方式提供了关键的见解。
- en: We first built a CNN with many layers. The level of abstraction of a CNN increases
    through each layer. Reducing the number of dimensions per layer makes patterns
    appear. A neural network can be described as a process that goes from chaos to
    meaning.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先构建了一个拥有多层的 CNN。CNN 的抽象层次随着每一层的增加而提高。每层减少维度数使得模式显现。神经网络可以被描述为一个从混乱到有意义的过程。
- en: After building the CNN, we wrote a program that can read the "mental" images
    of the layers. The output of each layer shows how the network is creating patterns
    and structures. Since we humans often think using mental images, the output images of
    the CNN help us understand how a machine learns.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建完 CNN 后，我们编写了一个程序，可以读取各层的“心智”图像。每层的输出展示了网络如何创建模式和结构。由于我们人类通常通过心智图像思考，CNN
    的输出图像帮助我们理解机器是如何学习的。
- en: Finally, we used a Google Colaboratory server to visualize the measurements
    of the CNN's learning process with TensorBoard running on top of TensorFlow 2.x.
    Measuring the accuracy of the training process of a CNN is critical. Visualizing
    these measurements makes it easier to see what is going wrong. TensorBoard provides
    a graph of a model to help us go from source code to a mental representation of
    an ANN.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们使用了 Google Colaboratory 服务器，通过在 TensorFlow 2.x 上运行的 TensorBoard 可视化了 CNN
    学习过程的测量结果。衡量 CNN 训练过程的准确性至关重要。通过可视化这些测量结果，可以更容易地看出问题所在。TensorBoard 提供了一个模型图，帮助我们从源代码到人工神经网络（ANN）的心智模型进行转换。
- en: To sum this chapter up in a nutshell, we can say that artificial intelligence,
    through mathematics, transforms the chaos surrounding us into intelligible structures
    and patterns.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 总结这一章，我们可以说，人工智能通过数学将我们周围的混乱转化为可理解的结构和模式。
- en: 'In the next chapter, we are going to go further and learn how to visualize
    another aspect of a neural network: weights. We are going to use the weights of
    a restricted Boltzmann machine (RBM) to create a visual representation in TensorBoard
    using principal component analysis.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将进一步探讨并学习如何可视化神经网络的另一个方面：权重。我们将使用限制玻尔兹曼机（RBM）的权重，结合主成分分析，在 TensorBoard
    中创建可视化表示。
- en: Questions
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: A CNN always has the same number of layers. (Yes | No)
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个 CNN 总是有相同数量的层。（是 | 否）
- en: ReLU is the best activation function. (Yes | No)
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ReLU 是最佳激活函数。（是 | 否）
- en: It is not necessary to compile a sequential classifier. (Yes | No)
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不需要编译一个顺序分类器。（是 | 否）
- en: The output of a layer is best viewed without running a prediction. (Yes | No)
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最好在不运行预测的情况下查看层的输出。（是 | 否）
- en: The names of the layers mean nothing when viewing their outputs. (Yes | No)
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看层的输出时，层的名称没有任何意义。（是 | 否）
- en: TensorFlow 2.x does not include Keras. (Yes | No)
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TensorFlow 2.x 不包括 Keras。（是 | 否）
- en: Google Colaboratory is just a repository, like GitHub. (Yes | No)
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Google Colaboratory 只是一个存储库，类似于 GitHub。（是 | 否）
- en: Google Colaboratory cannot run notebooks. (Yes | No)
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Google Colaboratory 无法运行笔记本。（是 | 否）
- en: It is possible to run TensorBoard in Google Colaboratory notebooks. (Yes | No)
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以在 Google Colaboratory 笔记本中运行 TensorBoard。（是 | 否）
- en: Accuracy is displayed in TensorBoard. (Yes | No)
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准确度在 TensorBoard 中显示。（是 | 否）
- en: Further reading
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: For more information on activation functions, visit [https://keras.io/activations/](https://keras.io/activations/).
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关激活函数的更多信息，请访问 [https://keras.io/activations/](https://keras.io/activations/)。
- en: 'Click on this link for more information on Google Colaboratory: [https://colab.research.google.com/notebooks/welcome.ipynb#recent=true](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true).'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击此链接查看更多关于 Google Colaboratory 的信息：[https://colab.research.google.com/notebooks/welcome.ipynb#recent=true](https://colab.research.google.com/notebooks/welcome.ipynb#recent=true)。
