- en: Predicting Taxi Fares with Deep Feedforward Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度前馈网络预测出租车费用
- en: In this chapter, we will use a deep feedforward neural network to predict taxi
    fares in **New York City** (**NYC**), given inputs such as the pickup and drop
    off locations.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用深度前馈神经网络预测**纽约市**（**NYC**）的出租车费用，输入包括接送地点等。
- en: In the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons*, we saw how we can use a MLP
    with two hidden layers to perform a classification task (whether the patient is
    at risk of diabetes or not). In this chapter, we will build a deep neural network
    to perform a regression task of estimating taxi fares. As we shall see, we will
    need a deeper (that is, more complex) neural network to achieve this goal.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章，[第 2 章](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml)，*使用多层感知器预测糖尿病*，我们看到如何使用具有两个隐藏层的
    MLP 执行分类任务（患者是否有糖尿病风险）。在本章中，我们将构建一个深度神经网络来执行回归任务，即估算出租车费用。正如我们所见，我们需要一个更深的（即更复杂的）神经网络来实现这一目标。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The motivation for the problem that we're trying to tackle—making accurate predictions
    of taxi fares
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们要解决的问题的动机——准确预测出租车费用
- en: Classification versus regression problems in machine learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习中的分类问题与回归问题
- en: In-depth analysis of the NYC taxi fares dataset, including geolocation data
    visualization
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对纽约市出租车费用数据集的深入分析，包括地理位置数据可视化
- en: Architecture of a deep feedforward neural network
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度前馈神经网络的架构
- en: Training a deep feedforward neural network in Keras for regression problems
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Keras 中训练用于回归问题的深度前馈神经网络
- en: Analysis of our results
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们结果的分析
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The key Python libraries required for this chapter are as follows:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章所需的关键 Python 库如下：
- en: matplotlib 3.0.2
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: matplotlib 3.0.2
- en: pandas 0.23.4
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas 0.23.4
- en: Keras 2.2.4
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras 2.2.4
- en: NumPy 1.15.2
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NumPy 1.15.2
- en: scikit-learn 0.20.2
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: scikit-learn 0.20.2
- en: To download the dataset required for this project, please refer to the instructions
    at [https://raw.githubusercontent.com/PacktPublishing/Neural-Network-Projects-with-Python/master/Chapter03/how_to_download_the_dataset.txt](https://raw.githubusercontent.com/PacktPublishing/Neural-Network-Projects-with-Python/master/chapter3/how_to_download_the_dataset.txt).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要下载本项目所需的数据集，请参阅[https://raw.githubusercontent.com/PacktPublishing/Neural-Network-Projects-with-Python/master/Chapter03/how_to_download_the_dataset.txt](https://raw.githubusercontent.com/PacktPublishing/Neural-Network-Projects-with-Python/master/chapter3/how_to_download_the_dataset.txt)中的说明。
- en: The code for this chapter can be found in the GitHub repository for the book
    at [https://github.com/PacktPublishing/Neural-Network-Projects-with-Python](https://github.com/PacktPublishing/Neural-Network-Projects-with-Python).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在本书的 GitHub 仓库中找到，地址为[https://github.com/PacktPublishing/Neural-Network-Projects-with-Python](https://github.com/PacktPublishing/Neural-Network-Projects-with-Python)。
- en: 'To download the code into your computer, run the following `git clone` command:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要将代码下载到你的计算机，请运行以下`git clone`命令：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After the process is complete, there will be a folder titled `Neural-Network-Projects-with-Python`.
    Enter the folder by running the following command:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 处理完成后，将会生成一个名为`Neural-Network-Projects-with-Python`的文件夹。通过运行以下命令进入该文件夹：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'To install the required Python libraries in a virtual environment, run the
    following command:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要在虚拟环境中安装所需的 Python 库，请运行以下命令：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that you should have installed Anaconda on your computer first before
    running this command. To enter the virtual environment, run the following command:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在运行此命令之前，你应该先在计算机上安装了 Anaconda。要进入虚拟环境，请运行以下命令：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Navigate to the `Chapter03` folder by running the following command:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下命令进入`Chapter03`文件夹：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following files are located in this folder:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下文件位于此文件夹中：
- en: '`main.py`: This is the main code for the neural network.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`main.py`：这是神经网络的主要代码。'
- en: '`utils.py`: This file contains auxiliary utility code that will help us in
    the implementation of our neural network.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`utils.py`：此文件包含辅助工具代码，帮助我们实现神经网络。'
- en: '`visualize.py`: This file contains all the necessary code for exploratory data
    analysis and data visualization. Every plot in this chapter can be recreated by
    running this file.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`visualize.py`：此文件包含所有必要的代码，用于探索性数据分析和数据可视化。本章中的每个图表都可以通过运行此文件重新创建。'
- en: 'To run the code for the neural network, simply execute the `main.py` file:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行神经网络的代码，只需执行`main.py`文件：
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To recreate the data visualizations covered in this chapter, execute the `visualize.py` file:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 要重现本章中涵盖的数据可视化，执行`visualize.py`文件：
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Predicting taxi fares in New York City
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预测纽约市出租车费用
- en: Yellow cabs in NYC are perhaps one of the most recognizable icons in the city.
    Tens of thousands of commuters in NYC rely on taxis as a mode of transportation
    around the bustling metropolis. In recent years, the taxi industry in NYC has
    been put under increasing pressure from ride-hailing apps such as Uber.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 纽约市的黄色出租车可能是城市中最具标志性的象征之一。纽约市数以万计的通勤者依靠出租车在这个繁华的大都市中进行交通。近年来，纽约市的出租车行业受到Uber等乘车应用的日益增加的压力。
- en: In order to rise to the challenge from ride-hailing apps, yellow cabs in NYC
    are looking to modernize their operations, and to provide a user experience on
    par with Uber. In August 2018, the Taxi and Limousine Commission of NYC launched
    a new app that allows commuters to book a yellow cab from their phones. The app
    provides fare pricing upfront before they hail a cab. Creating an algorithm to
    provide fare pricing upfront is no simple feat. The algorithm needs to consider
    various environmental variables such as traffic conditions, time of day, and pick
    up and drop off locations in order to make an accurate fare prediction. The best
    way to do that is to leverage machine learning. By the end of this chapter, you
    will have created and trained a neural network to do exactly that.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对乘车应用的挑战，纽约市的黄色出租车正在寻求现代化运营，并提供与Uber相当的用户体验。2018年8月，纽约市出租车和豪华轿车管理委员会推出了一个新的应用程序，允许通勤者通过手机预订黄色出租车。该应用程序在乘车前提供预先定价。创建一个算法以提供预先定价并不是一件简单的事情。该算法需要考虑各种环境变量，如交通状况、时间和上下车地点，以便准确预测车费。利用机器学习是实现这一目标的最佳方式。到本章结束时，您将创建并训练一个神经网络来实现这一目标。
- en: The NYC taxi fares dataset
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 纽约市出租车费用数据集
- en: The dataset that we will be using for this project is the NYC taxi fares dataset,
    as provided by Kaggle. The original dataset contains a massive 55 million trip
    records from 2009 to 2015, including data such as the pick up and drop off locations,
    number of passengers, and pickup datetime. This dataset provides an interesting
    opportunity to use big datasets in machine learning projects, as well to visualize
    geolocation data.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在此项目中使用的数据集是Kaggle提供的纽约市出租车费用数据集。原始数据集包含来自2009年至2015年的5500万次行程记录，包括上车和下车地点、乘客数量和上车时间。这个数据集为在机器学习项目中使用大数据集提供了有趣的机会，同时也可以可视化地理位置数据。
- en: Exploratory data analysis
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索性数据分析
- en: Let's dive right into the dataset. The instructions to download the NYC taxi
    fares dataset can be found in the accompanying GitHub repository for the book
    (refer to the *Technical requirements* section). Unlike in the previous chapter,
    [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml), *Predicting Diabetes
    with Multilayer Perceptrons*, we're not going to import the original dataset of
    55 million rows. In fact, most computers would not be able to store the entire
    dataset in memory! Instead, let's just import the first 0.5 million rows. Doing
    this does have its drawbacks, but it is a necessary tradeoff in order to use the
    dataset in an efficient manner.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们直接深入数据集。下载纽约市出租车费用数据集的说明可以在本书的GitHub存储库中找到（请参阅*技术要求*部分）。与上一章不同的是，[第二章](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml)，*使用多层感知器预测糖尿病*，我们不打算导入5500万行的原始数据集。事实上，大多数计算机无法将整个数据集存储在内存中！相反，让我们只导入前500万行。这样做确实有其缺点，但这是在有效使用数据集的必要权衡。
- en: 'To do this, run the `read_csv()` function with `pandas`:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要做到这一点，使用`pandas`的`read_csv()`函数：
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `parse_dates` parameter in `read_csv` allows `pandas` to easily recognize
    certain columns as dates, giving us the flexibility to work with such `datetime`
    values, as we shall see later in the chapter.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_csv`中的`parse_dates`参数允许`pandas`轻松识别某些列作为日期，这使我们可以灵活处理这些`datetime`值，正如我们将在本章后面看到的那样。'
- en: 'Let''s take a look at the first five rows of the dataset by calling the `df.head()`
    command:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调用`df.head()`命令，让我们看看数据集的前五行：
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We get the following output:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/1e0a77f4-ec95-4867-9af1-d8c38ed500ed.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1e0a77f4-ec95-4867-9af1-d8c38ed500ed.png)'
- en: 'We can see that there are eight columns in the dataset:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到数据集中有八列：
- en: '`key`: This column seems identical to the `pickup_datetime` column. It was
    probably used as an unique identifier in the database it was stored in. We can
    safely remove this column without any loss of information.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`key`：这一列看起来与`pickup_datetime`列相同。它可能是数据库中作为唯一标识符使用的。我们可以安全地删除这一列，而不会丢失任何信息。'
- en: '`fare_amount`: This is the target variable we are trying to predict, the fare
    amount paid at the end of the trip.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fare_amount`：这是我们尝试预测的目标变量，即旅行结束时支付的票价金额。'
- en: '`pickup_datetime`: This column contains information on the pickup date (year,
    month, day of month), as well as the time (hour, minute, seconds).'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pickup_datetime`：这一列包含了接送日期（年份、月份、日）以及时间（小时、分钟、秒）。'
- en: '`pickup_longitude` and `pickup_latitude`: The longitude and latitude of the
    pickup location.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pickup_longitude`和`pickup_latitude`：接送地点的经度和纬度。'
- en: '`dropoff_longitude` and `dropoff_latitude`: The longitude and latitude of the
    drop off location.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dropoff_longitude`和`dropoff_latitude`：下车地点的经度和纬度。'
- en: '`passenger_count`: The number of passengers.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`passenger_count`：乘客数量。'
- en: Visualizing geolocation data
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可视化地理位置信息
- en: The pick-up and drop-off longitude and latitude data are crucial to predicting
    the fare amount. After all, fares in NYC taxis are largely determined by the distance
    traveled.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 接送地点的经纬度数据对于预测票价至关重要。毕竟，纽约市出租车的票价主要由行驶的距离决定。
- en: First, let's understand what latitude and longitude represents. Latitude and longitude
    are coordinates in a geographic coordinate system. Basically, the latitude and longitude
    allows us to specify any location on Earth using a set of coordinates.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们了解纬度和经度代表什么。纬度和经度是地理坐标系统中的坐标。基本上，纬度和经度允许我们通过一组坐标来指定地球上的任何位置。
- en: 'The following diagram shows the **Latitude** and **Longitude** coordinate system:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了**纬度**和**经度**坐标系统：
- en: '![](img/395f3948-8e35-4a17-82ce-9103a7cb785d.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/395f3948-8e35-4a17-82ce-9103a7cb785d.png)'
- en: We can think of the Earth as a scatterplot, with the **Longitude** and the **Latitude**
    being the axes. Then, every location on Earth is simply a point on the scatterplot.
    In fact, let's do exactly that; let's plot the pickup and drop off latitudes and
    longitudes on a scatterplot.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以把地球看作是一个散点图，**经度**和**纬度**是坐标轴。然后，地球上的每个位置就只是散点图上的一个点。事实上，来，我们就按这个方式做；让我们在散点图上绘制接送和下车的纬度和经度。
- en: 'First, let''s restrict our data points to only pickups and drop offs within
    NYC. NYC has an approximate longitude range of `-74.05` to `-73.75` and a latitude
    range of `40.63` to `40.85`:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们将数据点限制为仅包含纽约市的接送和下车位置。纽约市的经度范围大致为`-74.05`到`-73.75`，纬度范围为`40.63`到`40.85`：
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note that we copied the original DataFrame, `df`, into a new DataFrame, `df2`,
    to avoid overwriting the original DataFrame.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们将原始数据框`df`复制到一个新的数据框`df2`中，以避免覆盖原始数据框。
- en: 'Now, let''s define a new function that will take our DataFrame as an input,
    and plot the pickup locations on a scatterplot. We are also interested in overlaying
    the scatterplot with a few key landmarks in NYC. A quick Google search tells us
    that there are two main airports in NYC (JFK and LaGuardia), and their coordinates,
    along with the main districts in NYC, are as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们定义一个新函数，该函数将以我们的数据框作为输入，并在散点图上绘制接送位置。我们还希望在散点图上叠加一些纽约市的关键地标。快速的谷歌搜索告诉我们，纽约市有两个主要机场（JFK和拉瓜迪亚机场），它们的坐标，以及纽约市的主要区县如下：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'And here''s our function using `matplotlib` to plot the pickup locations on
    a scatterplot:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们使用`matplotlib`绘制接送位置散点图的函数：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let''s run the function we just defined:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行刚才定义的函数：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We''ll see the following scatterplot showing the pickup locations:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下显示接送位置的散点图：
- en: '![](img/fe040127-a79a-4ea7-8fe8-5a9e12a42bff.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fe040127-a79a-4ea7-8fe8-5a9e12a42bff.png)'
- en: 'Isn''t it beautiful? Just by plotting the pickup locations on a scatterplot,
    we can clearly see a map of NYC, along with the grids that streets in NYC are
    known for. From the preceding scatterplot, we can make a few observations:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 不觉得这很美吗？仅仅通过在散点图上绘制接送位置，我们就能清楚地看到纽约市的地图，以及纽约街道的网格布局。从前面的散点图中，我们可以得出一些观察结果：
- en: In Manhattan, most pickups were around the `Midtown` area, followed by `Lower
    Manhattan`. In comparison, there are much fewer pickups in `Upper Manhattan`.
    This makes sense, since `Upper Manhattan` is a residential area, whereas more
    offices and tourist attractions are located at `Midtown` and `Lower Manhattan`.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在曼哈顿，大多数接送发生在`中城`区域，其次是`下曼哈顿`。相比之下，`上曼哈顿`的接送数量要少得多。这是有道理的，因为`上曼哈顿`是一个住宅区，而更多的办公室和旅游景点位于`中城`和`下曼哈顿`。
- en: Pickups are sparse outside Manhattan. The only two outliers were at `LaGuardia
    Airport` and `JFK Airport`.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 曼哈顿以外的接送稀少。唯一的两个异常点出现在`拉瓜迪亚机场`和`JFK机场`。
- en: 'Let''s also plot the scatterplot for drop off locations and see how it differs:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们还绘制下车位置的散点图，并看看它与接送位置的差异。
- en: '[PRE13]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We''ll see the following scatterplot:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下散点图：
- en: '![](img/f329a110-c91c-4f23-a810-8ccbcd5fd9e5.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f329a110-c91c-4f23-a810-8ccbcd5fd9e5.png)'
- en: Comparing the pickup and drop off scatterplots, we can clearly see that there
    are more drop offs than pickups in residential areas such as `Upper Manhattan`
    and `Brooklyn`. Neat!
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 比较接送和下车的散点图，我们可以清楚地看到，在像`上曼哈顿`和`布鲁克林`这样的住宅区，下车次数比接送次数多。很有趣！
- en: Ridership by day and hour
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 按天和小时的骑行情况
- en: Next, let's investigate how the number of rides varies by day and hour.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们研究一下每天和每小时的骑行数量变化。
- en: 'Recall that the raw data contains a single `pickup_datetime` column that contains
    the pickup date and time in `datetime` format. First, let''s separate the pickup
    year, month, day, day of week, and hour from the original `pickup_datetime` column
    into different columns:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，原始数据包含一个单一的`pickup_datetime`列，其中包含接送日期和时间（`datetime`格式）。首先，让我们将接送的年份、月份、日期、星期几和小时从原始的`pickup_datetime`列中分离出来，放入不同的列中：
- en: '[PRE14]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Since we have previously used the `parse_dates` parameter when we imported the
    data into pandas, we can easily identify and separate the year, month, day and
    hour components using the `dt` function in pandas.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们之前在将数据导入pandas时使用了`parse_dates`参数，因此我们可以很容易地使用pandas中的`dt`函数识别并分离年份、月份、日期和小时组件。
- en: 'Now, let''s plot a histogram to analyze the distribution of rides throughout
    the week:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们绘制一个直方图来分析一周内骑行的分布：
- en: '[PRE15]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We''ll see the following histogram:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下直方图：
- en: '![](img/31adca56-d945-4d6a-928e-a54c26a5a8d2.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/31adca56-d945-4d6a-928e-a54c26a5a8d2.png)'
- en: Interestingly, we can see that the number of rides is not evenly distributed
    across each weekday. Instead, the number of rides increases linearly from Monday
    through Friday, and peaking on Friday. The weekends see a slight drop in the number
    of rides on Saturday, before falling sharply on Sunday.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们可以看到，骑行数量在每个工作日并不均匀分布。相反，骑行数量从周一到周五线性增加，并在周五达到峰值。周末的骑行数量略微下降，周六有所减少，而周日则急剧下降。
- en: 'We can also visualize ridership by hour:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以按小时可视化骑行人数：
- en: '[PRE16]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We''ll see the following histogram for pickup hour:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下关于接送小时的直方图：
- en: '![](img/1c522d25-0791-4ae9-a9f8-9d1ea24ac8fd.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1c522d25-0791-4ae9-a9f8-9d1ea24ac8fd.png)'
- en: We can see that there are more rides during the evening rush hour, as compared
    to the morning rush hour. In fact, the number of rides is pretty constant throughout
    the day. Starting at 6 P.M., the number of rides increases and peaks at 7 P.M.,
    before falling from 11 P.M. onwards.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在晚上高峰时段，骑行次数比早高峰时段更多。事实上，骑行数量在一天内基本保持恒定。从下午6点开始，骑行数量逐渐增加，并在晚上7点达到峰值，然后从晚上11点开始下降。
- en: Data preprocessing
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: Recall from the previous project that we had to preprocess the data by removing
    missing values and other data anomalies. In this project, we'll perform the same
    process. We'll also perform feature engineering to improve both the quality and
    quantity of the features before training our neural network on it.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下之前的项目，我们必须通过删除缺失值和其他数据异常来预处理数据。在这个项目中，我们将执行相同的过程。我们还将进行特征工程，以在训练神经网络之前提升特征的质量和数量。
- en: Handling missing values and data anomalies
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理缺失值和数据异常
- en: 'Let''s do a check to see whether there are any missing values in our dataset:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下数据集中是否有缺失值：
- en: '[PRE17]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We''ll see the following output showing the number of missing values in each
    column:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下输出，显示每列中的缺失值数量：
- en: '![](img/899f7a52-83c3-49c1-9e0b-7489fa94b96f.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/899f7a52-83c3-49c1-9e0b-7489fa94b96f.png)'
- en: 'We can see that there are only five rows (out of 500,000 rows) with missing
    data. With a missing data percentage of just 0.001%, it seems that we don''t have
    a problem with missing data. Let''s go ahead and remove those five rows with missing
    data:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，只有五行数据（共500,000行）缺失。缺失数据的比例仅为0.001%，看起来我们没有缺失数据的问题。我们接下来将删除这五行缺失数据：
- en: '[PRE18]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'At this point, we should also check the data for outliers. In a dataset as
    massive as this, there are bound to be outliers, which can skew our model. Let''s
    run a quick statistical summary on our data to look at the distribution:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们还应检查数据中是否存在异常值。在如此庞大的数据集中，必定会有异常值，这些异常值可能会扭曲我们的模型。让我们对数据进行快速的统计汇总，以查看其分布：
- en: '[PRE19]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The `describe` method produces the following table:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`describe`方法生成了如下表格：'
- en: '![](img/1c460353-de5a-42ba-8ad2-308e0922ef01.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1c460353-de5a-42ba-8ad2-308e0922ef01.png)'
- en: 'The lowest fare in the dataset is $-44.90\. That doesn''t make sense; fares
    can''t be negative! Also, the highest fare is $500\. Did the passenger get ripped
    off? Or was it just an error? Let''s plot a histogram to better understand the
    distribution of fares:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的最低票价是$-44.90。这不合理；票价不可能是负数！此外，最高票价是$500。乘客是不是被坑了？还是只是一个错误？让我们绘制一个直方图，更好地理解票价的分布：
- en: '[PRE20]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We''ll get the following histogram:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将得到以下直方图：
- en: '![](img/66030931-26cf-436f-bdf1-a0ab4abc1964.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/66030931-26cf-436f-bdf1-a0ab4abc1964.png)'
- en: It doesn't seem like that there are too many outliers, so we can safely remove
    them. Another interesting trend that we can observe from the histogram is that
    there is a small spike in fares around $50\. Could this be a fixed fare from a
    specific location? Cities usually implement fixed fares for trips to and from
    airports. A quick Google search tells us that trips to and from JFK airport incurs
    a flat fare of $52 plus tolls. This could be the reason for the spike in the histogram
    around $50! We'll keep this important fact in mind when we do feature engineering
    later on.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来并没有太多异常值，因此我们可以安全地删除它们。我们还可以从直方图中观察到一个有趣的趋势，即票价在$50附近出现了一个小的尖峰。这是否可能是某个特定地点的固定票价？城市通常会为往返机场的行程实施固定票价。通过快速的谷歌搜索，我们发现，往返JFK机场的行程会收取$52的固定票价，加上过路费。这可能就是票价在$50附近出现尖峰的原因！当我们进行特征工程时，我们会记住这个重要的事实。
- en: 'For now, let''s remove rows with fares less than $0 and more than $100:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，让我们删除票价低于$0或高于$100的行：
- en: '[PRE21]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'From the previous table, we can see that there are also outliers in the `passenger_count` column.
    Let''s plot a histogram of `Passenger Count` to look at its distribution:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的表格中，我们可以看到，`passenger_count`列中也存在异常值。让我们绘制`乘客数量`的直方图，看看它的分布：
- en: '[PRE22]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This gives us the following histogram:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给我们带来以下直方图：
- en: '![](img/313b50db-941d-46d9-aeae-aa5563eb9c94.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/313b50db-941d-46d9-aeae-aa5563eb9c94.png)'
- en: 'We can see that there''s a small percentage of rows with `0` passenger counts.
    Instead of discarding those rows, let''s replace the outliers with the mode (that
    is, `1` passenger count):'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，有一小部分行的乘客数量为`0`。我们不会删除这些行，而是将异常值替换为众数（即`1`名乘客）：
- en: '[PRE23]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We can also remove these outliers entirely, since only a few rows are affected.
    Instead, we chose to replace the outlier passenger count with the mode. Both methods
    are perfectly valid, but we chose the latter to illustrate the importance of visualizing
    your data with a histogram to identify outlier values, as well as the mode.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以完全删除这些异常值，因为只有少数几行受影响。不过，我们选择将异常的乘客数量替换为众数。这两种方法都是有效的，但我们选择后者来说明通过直方图可视化数据以识别异常值和众数的重要性。
- en: 'Next, let''s inspect the pickup and drop off latitude and longitude data to
    check for outliers. In the previous section on data visualization, we plotted
    a scatterplot with the restriction that the points should be located within the
    boundaries of NYC. Let''s plot a scatterplot now without that restriction:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们检查上车和下车的纬度和经度数据，查看是否有异常值。在前一节关于数据可视化中，我们绘制了一个散点图，并且限制了点应位于纽约市的边界内。现在，我们不加限制地绘制一个散点图：
- en: '[PRE24]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We''ll see the following scatterplot:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到如下散点图：
- en: '![](img/77a6482f-4a29-4473-b1c0-9f55e6ea3aeb.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/77a6482f-4a29-4473-b1c0-9f55e6ea3aeb.png)'
- en: 'Do you see where the outliers are? The dots at the periphery of the scatterplot
    are outliers. They have latitude values as high as 1000 and as low as -3000\.
    Earth''s geographic coordinate system does not have such extreme latitudes and
    longitudes! Let''s remove these outliers:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 你看到异常值的位置了吗？散点图外围的点是异常值。它们的纬度值高达1000，低至-3000。地球的地理坐标系统没有如此极端的纬度和经度！让我们移除这些异常值：
- en: '[PRE25]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Let's summarize what we have done for data preprocessing. We first saw that
    missing values only constitute 0.001% of the dataset, so we can remove them safely
    without affecting the quantity of our training data. Next, we saw that there are
    outliers in `fare_amount`, and `passenger_count`, as well as the pickup and drop
    off latitude and longitude. We removed the outliers for the `fare_amount`, latitude
    and longitude. For the `passenger_count`, we replaced those rows that had a `0`
    passenger count with the `passenger count` = `1` mode.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一下数据预处理的工作。我们首先看到缺失值仅占数据集的0.001%，因此我们可以安全地移除它们，而不影响训练数据的数量。接着，我们看到`fare_amount`、`passenger_count`以及提车和下车的纬度和经度存在异常值。我们移除了`fare_amount`、纬度和经度的异常值。对于`passenger_count`，我们将那些乘客数为`0`的行替换为`passenger
    count` = `1`的众数。
- en: Let's create a helper function to help us do all that data preprocessing. In
    machine learning projects, the number of steps can often get out of hand. It is
    important to adhere to strong software engineering practices, such as code modularization,
    to keep our project on track.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个辅助函数，帮助我们完成所有这些数据预处理工作。在机器学习项目中，步骤数量往往会变得难以控制。因此，遵循强有力的软件工程实践，比如代码模块化，对于保持项目进展至关重要。
- en: 'The following code takes a pandas DataFrame as input, and returns the DataFrame
    after performing data preprocessing:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码接受一个pandas DataFrame作为输入，返回经过数据预处理后的DataFrame：
- en: '[PRE26]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We'll save this helper function under `utils.py` in our project folder. Then,
    to call our helper function for data preprocessing, we just have to call `from
    utils import preprocess` and we'll have access to this helper function. This keeps
    our code neat and manageable!
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把这个辅助函数保存在项目文件夹中的`utils.py`文件下。然后，为了调用我们的数据预处理辅助函数，我们只需调用`from utils import
    preprocess`，就可以使用这个辅助函数了。这使得我们的代码更加整洁和可维护！
- en: Feature engineering
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程
- en: As briefly discussed in the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons* feature engineering is the process
    of using one's domain knowledge of the problem to create new features for the
    machine learning algorithm. In this section, we shall create features based on
    the date and time of pickup, and location-related features.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一章中简要讨论的，[第二章](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml)，*使用多层感知器预测糖尿病*，特征工程是利用个人对问题的领域知识为机器学习算法创建新特征的过程。在这一部分，我们将基于提车的日期和时间，以及与位置相关的特征来创建特征。
- en: Temporal features
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间特征
- en: As we've seen earlier in the section on data visualization, ridership volume
    depends heavily on the day of the week, as well as the time of day.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在数据可视化部分看到的，乘客量在很大程度上取决于星期几以及一天中的时间。
- en: 'Let''s look at the format of the `pickup_datetime` column by running the following
    code:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过运行以下代码来看一下`pickup_datetime`列的格式：
- en: '[PRE27]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We get the following output:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/06303f0f-b30d-4301-a70e-5a88645314f0.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/06303f0f-b30d-4301-a70e-5a88645314f0.png)'
- en: 'Recall that neural networks require numerical features. Therefore, we can''t
    train our neural network using such a datetime string. Let''s separate the `pickup_datetime` column
    into different columns for `year`, `month`, `day`, `day_of_week`, and `hour`:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，神经网络需要数值特征。因此，我们不能使用这种日期时间字符串来训练我们的神经网络。让我们将`pickup_datetime`列分离成不同的列，分别为`year`、`month`、`day`、`day_of_week`和`hour`：
- en: '[PRE28]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let''s take a look at the new columns:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看新列：
- en: '[PRE29]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We get the following output:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/b5fa9eba-a1fb-4f52-87bb-2e510ebd4dc8.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b5fa9eba-a1fb-4f52-87bb-2e510ebd4dc8.png)'
- en: 'We can see that the new columns capture the original information from the `pickup_datetime` column
    in a format that''s suitable for our neural network. Let''s drop the `pickup_datetime` column
    from our DataFrame:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，新列以适合我们神经网络的格式捕捉了`pickup_datetime`列中的原始信息。让我们从DataFrame中删除`pickup_datetime`列：
- en: '[PRE30]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Geolocation features
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 地理定位特征
- en: As we have seen earlier, the dataset contains information regarding the pickup
    and drop off coordinates. However, there is no information regarding the distance
    between the pickup and drop off points, which is arguably the most important factor
    in deciding taxi fares. Therefore, let's create a new feature that calculates
    the distance between each pair of pickup and drop off points.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所看到的，数据集中包含了关于上下车坐标的信息。然而，数据集中并没有包含上下车点之间的距离信息，而这正是决定出租车费用的最重要因素之一。因此，让我们创建一个新特征，计算每对上下车点之间的距离。
- en: 'Recall from geometry that the *Euclidean Distance* is the straight-line distance
    between any two points:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 回想几何学中的*欧几里得距离*，它是任何两点之间的直线距离：
- en: '![](img/d72541e9-883b-416a-a1ed-b6f1ac2758b2.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d72541e9-883b-416a-a1ed-b6f1ac2758b2.png)'
- en: 'Let''s define a function to calculate the Euclidean distance between any two
    points, given the latitude and longitudes of the two points:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个函数，计算给定两个点的纬度和经度之间的欧几里得距离：
- en: '[PRE31]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'And let''s apply the function to the DataFrame to create the new `distance`
    column:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将这个函数应用到数据框中，创建新的`distance`列：
- en: '[PRE32]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Our hypothesis was that the trip fare is closely correlated to the distance
    traveled. We can now plot the two variables on a scatterplot to analyze the correlation
    and see if our intuition was right:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的假设是，车费与行驶的距离密切相关。现在我们可以在散点图上绘制这两个变量，以分析它们的相关性，并查看我们的直觉是否正确：
- en: '[PRE33]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We get the following scatterplot:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下散点图：
- en: '![](img/2c85bc07-2e52-4871-85d1-532bc29e1868.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2c85bc07-2e52-4871-85d1-532bc29e1868.png)'
- en: Nice! We can clearly see that our hypothesis is right. However, the distance
    traveled alone does not tell the whole story. If we look at the center of the
    graph, we can see three vertical lines of dots. These outlier data seems to suggest
    that there are certain trips where the distance traveled did not have an impact
    on the fare amount (which is between $40 and $60 for these outliers). Recall in
    the previous section on data visualization where we saw that there are certain
    pickups near airports, and these airport pickups have a flat fare of $52 plus
    tolls. This could explain the three vertical lines of dots between $40 and $60!
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 很好！我们可以清楚地看到我们的假设是正确的。然而，单纯依赖行驶的距离并不能完整说明问题。如果我们看一下图表的中心部分，会看到三条垂直的点线。这些离群数据似乎表明，在某些情况下，行驶的距离并没有对车费产生影响（这些离群点的车费在$40到$60之间）。回想我们在数据可视化部分看到的，靠近机场的某些上下车点的车费是固定的$52，再加上通行费。这可能解释了这三条$40到$60之间的垂直点线！
- en: Clearly, we need to engineer a new feature that informs our neural network of
    the pickup and drop off distance from the three major airports in NYC. When we
    train the neural network on this feature, it should then learn that pickups and
    drop offs near airports have a flat fare between $40 and $60.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，我们需要构造一个新特征，告知神经网络从纽约市三个主要机场到上下车地点的距离。当我们在这个特征上训练神经网络时，它应该会学习到，靠近机场的上下车点的车费是一个固定的范围，在$40到$60之间。
- en: 'We can use the `euc_distance` function that we defined earlier to calculate
    the pickup and drop off distance from the three major airports in NYC:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用之前定义的`euc_distance`函数，计算从纽约市三个主要机场到上下车地点的距离：
- en: '[PRE34]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Let''s print out the first few rows, along with a few relevant columns to verify
    that the Euclidean distance function is functioning as intended:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们打印出前几行，并查看一些相关列，以验证欧几里得距离函数是否按预期工作：
- en: '[PRE35]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We get the following output:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/0665247a-2e68-49fa-abea-abcf6e154b57.png)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0665247a-2e68-49fa-abea-abcf6e154b57.png)'
- en: 'We can do a quick calculation on the preceding rows to verify that the Euclidean
    distance function works correctly. Lastly, notice that there is still a `key`
    column in the dataset. This column is similar to the `pickup_datetime` column,
    and it was probably used as a unique identifier in the database it was stored
    in. We can safely remove this column without any loss of information. To remove
    the `key` column, use this command:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对前面的几行进行快速计算，验证欧几里得距离函数是否正常工作。最后，注意到数据集中仍然存在一个`key`列。这个列类似于`pickup_datetime`列，可能在数据库中作为唯一标识符使用。我们可以安全地删除此列，而不会丢失任何信息。要删除`key`列，可以使用以下命令：
- en: '[PRE36]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: To recap, in this section, we used feature engineering to construct new features
    based on our own domain knowledge of the problem. From the raw datetime information
    provided, we extracted and constructed new features for the pickup year, month,
    day, day of the week, and hour. We also constructed distance-based features that
    are crucial to the prediction of fares, such as the distance between pickup and
    drop off points, as well as the pickup and drop off distance from the three main
    airports in NYC.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，在这一部分，我们使用特征工程根据我们自己对问题的领域知识构造了新的特征。通过提供的原始日期时间信息，我们提取并构造了关于提车年份、月份、日期、星期几和小时的新特征。我们还构造了基于距离的特征，这些特征对于预测车费至关重要，例如提车点和下车点之间的距离，以及从纽约三大机场到提车点和下车点的距离。
- en: 'Similar to the previous *Data preprocessing *section, we''re going to construct
    a helper function to summarize what we have done for feature engineering. This
    code modularization approach will help keep our code manageable:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的*数据预处理*部分类似，我们将构建一个辅助函数来总结我们在特征工程中所做的工作。这个代码模块化方法将帮助我们保持代码的可管理性：
- en: '[PRE37]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Feature scaling
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征缩放
- en: As a final preprocessing step, we should also scale our features before passing
    them to the neural network. Recall from the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons*, that scaling ensures that all
    features have a uniform range of scale. This ensures that features with a greater
    scale (for example, year has a scale of > 2000) does not dominate features with
    a smaller scale (for example, passenger count has a scale between 1 to 6).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后的预处理步骤，我们还应该在将特征传递给神经网络之前对它们进行缩放。回顾前一章，[第2章](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml)，*使用多层感知机预测糖尿病*，缩放确保所有特征具有统一的缩放范围。这确保了具有较大缩放的特征（例如，年份的缩放范围大于2000）不会主导具有较小缩放的特征（例如，乘客人数的缩放范围为1到6）。
- en: 'Before we scale the features in the DataFrame, it''s a good idea to keep a
    copy of the prescaled DataFrame. The values of the features will be transformed
    after scaling (for example, year 2010 may be transformed to a value such as -0.134
    after scaling), which can make it difficult for us to interpret the values. By
    keeping a copy of the prescaled DataFrame, we can easily reference the original
    values:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们对DataFrame中的特征进行缩放之前，最好先保留一个原始DataFrame的副本。特征的值在缩放后会发生变化（例如，2010年可能会被转换成一个值，例如-0.134），这会使我们难以解释这些值。通过保留原始DataFrame的副本，我们可以轻松地引用原始值：
- en: '[PRE38]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We should also drop the `fare_amount` target variable before scaling, as we
    do not want to modify the target variable:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该在缩放之前删除`fare_amount`目标变量，因为我们不希望修改目标变量：
- en: '[PRE39]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Then, scale the features by calling the `scale` function from scikit-learn:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过调用scikit-learn中的`scale`函数来缩放特征：
- en: '[PRE40]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Lastly, convert the object returned by the `scale` function into a pandas DataFrame
    and concatenate the original `fare_amount` column that was dropped before scaling:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将`scale`函数返回的对象转换为pandas DataFrame，并将原先在缩放之前删除的`fare_amount`列拼接回来：
- en: '[PRE41]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Deep feedforward networks
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度前馈神经网络
- en: So far in this chapter, we have done an in-depth visualization of the dataset,
    cleaned up the dataset by handling outliers, and also performed feature engineering
    to create useful features for our model. For the rest of the chapter, we'll talk
    about the architecture of deep feedforward neural networks, and we'll train one
    in Keras for a regression task.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本章中，我们对数据集进行了深入的可视化分析，处理了数据集中的异常值，并且进行了特征工程以创建有用的特征供我们的模型使用。在本章的剩余部分，我们将讨论深度前馈神经网络的架构，并在Keras中为回归任务训练一个模型。
- en: Model architecture
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型架构
- en: In the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons*,we used a relatively simple
    MLP as our neural network. For this project, since there are more features, we
    shall use a deeper model to account for the additional complexity. The deep feedforward
    network will have four hidden layers. The first hidden layer will have 128 nodes,
    with each successive hidden layer having half the nodes of its predecessor. This
    neural network size is a good starting point for us and it should not take too
    long to train this neural network. A general rule of thumb is that we should start
    with a small neural network and only increase its complexity (size) as required.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章，[第二章](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml)，*使用多层感知器预测糖尿病*中，我们使用了一个相对简单的
    MLP 作为我们的神经网络。在这个项目中，由于特征更多，我们将使用一个更深的模型来处理额外的复杂性。深度前馈网络将有四个隐藏层。第一个隐藏层将有 128 个节点，每个后续的隐藏层节点数将是前一个隐藏层的一半。这个神经网络的大小是我们一个不错的起点，训练这个神经网络应该不会花费太长时间。一个常见的经验法则是，我们应该从一个较小的神经网络开始，只有在需要时才增加它的复杂性（大小）。
- en: In between each hidden layer, we will use the ReLU activation function to introduce
    non-linearity in the model. Since this is a regression problem, there will only
    be one node in the output layer (more on regression in the next sub-section).
    Note that we do not apply the ReLU activation function for the output layer as
    doing so would transform our predictions.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个隐藏层之间，我们将使用 ReLU 激活函数来引入模型的非线性。由于这是一个回归问题，输出层中将只有一个节点（有关回归的更多信息，请参见下一小节）。请注意，我们不会对输出层应用
    ReLU 激活函数，因为这样会改变我们的预测结果。
- en: 'The following diagram illustrates the model architecture of the deep feedforward
    neural network:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示说明了深度前馈神经网络的模型架构：
- en: '![](img/f9782fed-7257-48fd-bdb2-64a446305674.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f9782fed-7257-48fd-bdb2-64a446305674.png)'
- en: Loss functions for regression problems
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归问题的损失函数
- en: It is important to understand what regression is, and how it affects the architecture
    of our neural network. Our task in this project is to predict taxi fares, which
    is a continuous variable. We can contrast this with the classification project
    that we did in the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons*, where we designed a neural
    network to output a binary prediction (1 or 0), indicating whether the patient
    was at risk of diabetes.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 了解什么是回归以及它如何影响我们神经网络的架构非常重要。我们在这个项目中的任务是预测出租车费用，这是一个连续变量。我们可以将其与上一章，[第二章](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml)，*使用多层感知器预测糖尿病*中所做的分类项目进行对比，我们设计了一个神经网络来输出一个二元预测（1
    或 0），表示患者是否处于糖尿病风险之中。
- en: Another way to think about regression and classification is that in regression,
    we are trying to predict the value of a continuous variable (for example, cost,
    time, or height), whereas in classification, we are trying to predict a class
    (for example, diabetes or no diabetes).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种思考回归和分类的方式是，在回归中，我们试图预测一个连续变量的值（例如，费用、时间或身高），而在分类中，我们试图预测一个类别（例如，糖尿病或无糖尿病）。
- en: Recall that in the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons*,we used percentage accuracy
    as a metric for measuring how strong our predictions are. In regression, the **root
    mean square error** (**RMSE**) is often used as the error metric.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，在上一章，[第二章](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml)，*使用多层感知器预测糖尿病*中，我们使用了百分比准确率作为衡量我们预测强度的标准。在回归中，**均方根误差**（**RMSE**）通常用作误差度量。
- en: 'The formula for *RMSE* is as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '*RMSE* 的公式如下：'
- en: '![](img/f0ee13e0-65b8-4183-bcb9-9df1e6c8f8a8.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f0ee13e0-65b8-4183-bcb9-9df1e6c8f8a8.png)'
- en: Notice how the formula takes the square of the difference between the predicted
    value and the actual value. This is to ensure that over estimations and under
    estimations are penalized equally (since the square of the error would be the
    same for both). We take the square-root to ensure that the magnitude of the error
    is similar to the actual values. The RMSE provides a loss function for our neural
    network, allowing it to tune its weights during the training process in order
    to reduce the error of its predictions.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，公式如何计算预测值与实际值之间差异的平方。这是为了确保过高估计和过低估计被同等惩罚（因为误差的平方对于两者是相同的）。我们取平方根是为了确保误差的幅度与实际值相似。RMSE
    提供了一个损失函数，供我们的神经网络在训练过程中调整权重，以减少预测的误差。
- en: Model building in Python using Keras
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Keras 在 Python 中构建模型
- en: Now, let's implement our model architecture in Keras. Just like in the previous
    project, we're going to build our model layer by layer in Keras using the `Sequential`
    class.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在 Keras 中实现我们的模型架构。就像在上一个项目中一样，我们将使用 `Sequential` 类逐层构建我们的模型。
- en: 'First, split the DataFrame into the training features (`X`) and the target
    variable that we''re trying to predict (`y`):'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，将 DataFrame 拆分为训练特征（`X`）和我们要预测的目标变量（`y`）：
- en: '[PRE42]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Then, split the data into a training set (80%) and a testing set (20%):'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将数据拆分为训练集（80%）和测试集（20%）：
- en: '[PRE43]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Next, let''s build our `Sequential` model in Keras according to the neural
    network architecture we outlined earlier:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们根据之前概述的神经网络架构，在 Keras 中构建我们的 `Sequential` 模型：
- en: '[PRE44]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Before we start training our model, it is a good practice to verify the structure
    of our model:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始训练模型之前，验证模型的结构是一个良好的实践：
- en: '[PRE45]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The `summary()` function produces a table showing the number of layers and number
    of nodes in each layer, as well as the number of parameters in each layer (that
    is, the weights and biases). We can verify that this is consistent with the model
    architecture we outlined earlier.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '`summary()` 函数生成一个表格，显示每一层的层数和每层的节点数，以及每层的参数数量（即权重和偏差）。我们可以验证这与之前概述的模型架构一致。'
- en: 'Here''s the table produced by the `summary()` function:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 `summary()` 函数生成的表格：
- en: '![](img/e06ec328-b384-447c-ac11-1e8cc6a32805.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e06ec328-b384-447c-ac11-1e8cc6a32805.png)'
- en: 'Finally, we can compile and train our neural network on the training data:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以在训练数据上编译并训练我们的神经网络：
- en: '[PRE46]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Since there''s a fair bit of data, it would take some time to train the neural
    network. After a few minutes, Keras would output the following at the end of the
    training epoch:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据量较大，训练神经网络需要一些时间。几分钟后，Keras 会在训练周期结束时输出以下内容：
- en: '![](img/3b56dc90-735b-4b31-8723-a8421736e8ba.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3b56dc90-735b-4b31-8723-a8421736e8ba.png)'
- en: Results analysis
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结果分析
- en: Now that we have our neural network trained, let's use it to make some predictions
    to understand its accuracy.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练好了神经网络，让我们用它来进行一些预测，以了解它的准确性。
- en: 'We can create a function to make a prediction using a random sample from the
    testing set:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个函数，使用测试集中的随机样本进行预测：
- en: '[PRE47]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The `predict_random` function will pull a random row from the testing set and
    feed it to the model for prediction. The function will then calculate and display
    the RMSE of the prediction. Note that `df_prescaled` is required to provide us
    with the original values for day of week and hour, as the values in the testing
    set have already been transformed earlier and are no longer human-readable (for
    example, a day of week value of -0.018778 does not make much sense to us).
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict_random` 函数会从测试集随机抽取一行数据，并将其输入模型进行预测。然后，函数会计算并显示预测的 RMSE。请注意，`df_prescaled`
    是必要的，因为它提供了星期几和小时的原始值，因为测试集中的值已经被转换过，不再是人类可读的（例如，星期几的值 -0.018778 对我们来说没有意义）。'
- en: 'Let''s run the `predict_random` function, shown as follows and see what kind
    of results we get:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行下面的 `predict_random` 函数，看看会得到什么样的结果：
- en: '[PRE48]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The trip details output by the `predict_random` function is as follows:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict_random` 函数输出的旅行详情如下：'
- en: '[PRE49]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The following map depicts the travel details:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 以下地图显示了旅行详情：
- en: '![](img/6138bc84-5f7e-4ce7-a0d3-ce5b0d87383b.png)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6138bc84-5f7e-4ce7-a0d3-ce5b0d87383b.png)'
- en: The pickup and drop off points are visualized in the preceding map. The `Actual
    fare` was `$4.90`, while the `Predicted fare` is `$5.60`, giving us an error of
    `$0.70`. It looks like our model is working well and the predictions are fairly
    accurate! Note that the map and route shown in the preceding screenshot is purely
    for visualization and is not part of the original dataset or code.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 接送点在上面的地图中可视化。`实际费用`为`$4.90`，而`预测费用`为`$5.60`，误差为`$0.70`。看起来我们的模型运行良好，预测也相当准确！请注意，上面截图中的地图和路线仅用于可视化，并不是原始数据集或代码的一部分。
- en: 'Let''s run `predict_random` a few more times to get more results:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再运行`predict_random`几次，获取更多的结果：
- en: '![](img/52e43b14-a1f0-4ec2-b273-919509000146.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](img/52e43b14-a1f0-4ec2-b273-919509000146.png)'
- en: 'The trip details output by the `predict_random` function is as follows:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict_random`函数输出的行程详情如下：'
- en: '[PRE50]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Our prediction for this trip was almost spot on! The `Actual fare` was `$6.10`,
    while the fare predicted by our neural network is `$6.30`. It seems like our neural
    network makes really good predictions for short distance trips.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对这次行程的预测几乎完全准确！`实际费用`为`$6.10`，而我们的神经网络预测的票价为`$6.30`。看来我们的神经网络对于短途行程的预测非常准确。
- en: 'Let''s see how well it does when the trip is further and more prone to traffic
    delays:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当行程更远且更容易受到交通延误影响时，神经网络的表现如何：
- en: '![](img/5fe3e94c-d089-4091-9a2e-e891a48fb306.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5fe3e94c-d089-4091-9a2e-e891a48fb306.png)'
- en: 'The trip details output by the `predict_random` function:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict_random`函数输出的行程详情：'
- en: '[PRE51]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: As we can see from this sample, our neural network works really well even for
    long distance trips. The `Actual fare` was `$35.80`, while our neural network
    predicted a fare of `$38.11`. The error of `$2.31` (~6% discrepancy) is pretty
    impressive given the distance of the trip.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个示例中我们可以看到，即使是长途旅行，我们的神经网络也表现得非常好。`实际费用`为`$35.80`，而我们的神经网络预测的费用为`$38.11`。误差为`$2.31`（约6%的偏差），考虑到行程的距离，这个结果非常令人印象深刻。
- en: 'As a final example, let''s see how our neural network performs for fixed-rate
    trips. Recall that all trips to/from JFK airport incur a fixed fare of $52 plus
    tolls, no matter the distance traveled:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最后一个示例，让我们看看我们的神经网络在固定票价行程中的表现。回想一下，从JFK机场出发或前往JFK机场的所有行程都需要支付固定的票价$52，再加上过路费，无论行程的距离如何：
- en: '![](img/4d80be80-e731-4b09-8ece-96f7b82bcf52.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4d80be80-e731-4b09-8ece-96f7b82bcf52.png)'
- en: 'The trip details output by the `predict_random` function is as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict_random`函数输出的行程详情如下：'
- en: '[PRE52]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Nice! Our neural network understands that the trip started from JFK airport,
    and hence the fare should be close to `$52`. This was made possible through feature
    engineering, where we introduced new features that represents the pickup and drop
    off distance away from JFK airport. These new features allowed our neural network
    to learn that trips to/from JFK airport should have a fare close to `$52`. This
    shows the importance of feature engineering!
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 很好！我们的神经网络理解到这次行程是从JFK机场出发的，因此票价应该接近`$52`。这一点是通过特征工程实现的，我们引入了表示从JFK机场接送距离的新特征。这些新特征使得我们的神经网络学会了从JFK机场出发的行程应当具有接近`$52`的票价。这也说明了特征工程的重要性！
- en: 'Finally, let''s conclude the results by calculating the RMSE for the entire
    training and testing set:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们通过计算整个训练集和测试集的RMSE来总结结果：
- en: '[PRE53]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'We get the following output:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到以下输出：
- en: '![](img/7d1cee54-86bb-4881-81ff-3d2286e00ac4.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7d1cee54-86bb-4881-81ff-3d2286e00ac4.png)'
- en: The RMSE values show that on average, our model predicts a fare that is accurate
    within ~$3.50.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: RMSE值显示，平均而言，我们的模型预测的票价准确度在 ~$3.50 之内。
- en: Putting it all together
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将所有内容整合起来
- en: We have accomplished a lot in this chapter. Let's do a quick recap of the code
    that we have written so far.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中我们已经完成了很多内容。让我们快速回顾一下目前为止我们写的代码。
- en: 'We started off by defining a function for preprocessing. This `preprocess`
    function takes a DataFrame as an input and performs the following actions:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义了一个用于数据预处理的函数。这个`preprocess`函数接受一个DataFrame作为输入，并执行以下操作：
- en: Removing missing values
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除缺失值
- en: Removing outliers in the fare amount
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除票价中的异常值
- en: Replacing outliers in passenger count with the mode
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用众数替换乘客数量中的异常值
- en: Removing outliers in latitude and longitude (that is, only considering points
    within NYC)
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除纬度和经度中的异常值（即只考虑纽约市内的点）
- en: This function is saved under `utils.py` in our project folder.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数保存在我们项目文件夹中的`utils.py`文件下。
- en: 'Next, we also defined a `feature_engineer` function for feature engineering.
    This function takes a DataFrame as an input and performs the following actions:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们还定义了一个`feature_engineer`函数用于特征工程。该函数以 DataFrame 作为输入，并执行以下操作：
- en: Creating new columns for year, month, day, day of the week, and hour
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为年份、月份、日期、星期几和小时创建新列
- en: Creating new column for the Euclidean distance between the pickup and drop off
    points
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为接送点之间的欧几里得距离创建新列
- en: Creating new columns for the pickup and drop off distances away from JFK, Laguardia,
    and Newark airports
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建了关于 JFK、拉瓜迪亚和纽瓦克机场的接送距离的新列
- en: This function is also saved under `utils.py` in our project folder.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数也保存在我们的项目文件夹中的`utils.py`文件下。
- en: Now that we have defined our helper functions, we can proceed with our main
    neural network code. Let's create a new Python file, `main.py`, to house our main
    neural network code.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了辅助函数，我们可以继续编写主神经网络代码。让我们创建一个新的 Python 文件`main.py`，用于存放我们的主神经网络代码。
- en: 'First, we import the necessary modules:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入必要的模块：
- en: '[PRE54]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Next, we import the first `500000` rows of the raw tabular data:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们导入原始表格数据的前`500000`行：
- en: '[PRE55]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'We perform preprocessing and feature engineering using the functions that we
    defined previously:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用之前定义的函数进行预处理和特征工程：
- en: '[PRE56]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Next, we scale the features:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们对特征进行缩放：
- en: '[PRE57]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Next, we split the DataFrame into training and testing sets:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将 DataFrame 拆分为训练集和测试集：
- en: '[PRE58]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'We build and train our deep feedforward neural network in Keras:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 Keras 中构建并训练了我们的深度前馈神经网络：
- en: '[PRE59]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Finally, we analyze our results:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们分析了我们的结果：
- en: '[PRE60]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: That's all of our code! Notice how creating helper functions for preprocessing
    and feature engineering in `utils.py` allows our main code to be relatively short.
    By modularizing our code into separate helper functions, we can focus on the implementation
    of each step of the machine learning framework.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们所有的代码！请注意，在`utils.py`中为预处理和特征工程创建辅助函数使得我们的主代码相对简短。通过将代码模块化为单独的辅助函数，我们可以专注于实现机器学习框架的每个步骤。
- en: Summary
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we designed and implemented a deep feedforward neural network
    capable of predicting taxi fares in NYC within an error of ~$3.50\. We first performed
    exploratory data analysis, where we gained important insights on the factors that
    affect taxi fares. With these insights, we then performed feature engineering,
    which is the process of using your domain knowledge of the problem to create new
    features. We also introduced the concept of modularizing our functions in machine
    learning projects, which allowed us to keep our main code relatively short and
    neat.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们设计并实现了一个深度前馈神经网络，能够在纽约市预测出租车费用，误差约为 ~$3.50。我们首先进行了探索性数据分析，从中获得了关于影响出租车费用的重要见解。基于这些见解，我们进行了特征工程，即运用问题领域知识创建新特征。我们还介绍了在机器学习项目中模块化函数的概念，这使得我们的主代码保持相对简洁。
- en: We created our deep feedforward neural network in Keras, and trained it using
    the preprocessed data. Our results show that the neural network is able to make
    highly accurate predictions for both short and long distance trips. Even for fixed-rate
    trips, our neural network was able to produce highly accurate predictions.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 Keras 中创建了深度前馈神经网络，并使用预处理过的数据进行了训练。我们的结果显示，神经网络能够对短途和长途旅行做出高度准确的预测。即使是固定费率的旅行，我们的神经网络也能够给出非常准确的预测。
- en: This concludes the chapter on using a deep feedforward neural network for a
    regression prediction task. Together with the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons*, we have seen how we can use
    neural networks for classification and regression. In the next chapter, [Chapter
    4](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml), *Cats Versus Dogs – Image Classification
    Using* *CNNs*,we will introduce more complex neural networks for computer vision
    projects.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 本章结束了使用深度前馈神经网络进行回归预测任务的内容。结合前一章，[第2章](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml)，*使用多层感知机预测糖尿病*，我们已经看到如何利用神经网络进行分类和回归预测。在下一章，[第4章](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml)，*猫与狗
    – 使用CNN进行图像分类*，我们将介绍更多复杂的神经网络，适用于计算机视觉项目。
- en: Questions
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: When reading a CSV file using pandas, how does pandas recognize that certain
    columns are datetime?
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 读取 CSV 文件时，pandas 如何识别某些列是日期时间类型？
- en: We can use the `parse_dates` argument when reading the CSV file using the `read_csv`
    function in pandas.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`read_csv`函数读取CSV文件时，我们可以使用`parse_dates`参数。
- en: How can we filter a DataFrame to only select rows within a certain range of
    values, assuming that we have a DataFrame, `df`, and we want to select rows with
    height values within the range of `160` and `180`?
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设我们有一个DataFrame `df`，并且我们想选择身高值在`160`到`180`之间的行，如何筛选DataFrame来只选择这些行？
- en: 'We can filter a DataFrame like so:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像这样筛选DataFrame：
- en: '[PRE61]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: This returns a new DataFrame with range of height values between `160` and `180`.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回一个新的DataFrame，包含身高值在`160`和`180`之间的范围。
- en: How can we use code modularization to organize our neural network projects?
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何使用代码模块化来组织我们的神经网络项目？
- en: We can compartmentalize our functions using modular pieces of code. For example,
    in this project, we defined a `preprocess` and `feature_engineer` function in
    `utils.py`, which allows us to focus on the implementation of the preprocessing
    and feature engineering functions separately.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过模块化代码来组织我们的函数。例如，在这个项目中，我们在`utils.py`中定义了`preprocess`和`feature_engineer`函数，这使我们能够将预处理和特征工程功能的实现分开进行。
- en: How is regression different from classification tasks?
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回归任务与分类任务有什么区别？
- en: In regression, we are trying to predict the value of a continuous variable (for
    example, taxi fare) whereas in classification, we are trying to predict a class
    (for example, diabetes or no diabetes).
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在回归中，我们尝试预测一个连续变量的值（例如，出租车费用），而在分类中，我们尝试预测一个类别（例如，是否患糖尿病）。
- en: True or false? For regression tasks, we should apply an activation function
    for the output layer.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对还是错？对于回归任务，我们应该在输出层应用激活函数。
- en: False. For regression tasks, we should never apply an activation function for
    the output layer because doing so will transform our predictions, which then affects
    the model performance.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 错误。对于回归任务，我们永远不应该在输出层应用激活函数，因为这样做会改变我们的预测结果，从而影响模型的性能。
- en: What loss function is typically used when training a neural network for regression
    tasks?
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练神经网络进行回归任务时，通常使用什么损失函数？
- en: The RMSE is a common loss function for regression tasks. The RMSE measures the
    absolute difference between the prediction and the actual target variable.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: RMSE是回归任务中常用的损失函数。RMSE衡量的是预测值与实际目标变量之间的绝对差异。
