- en: '*Chapter 1*: Deep Learning Life Cycle and MLOps Challenges'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第1章*：深度学习生命周期与MLOps挑战'
- en: The past few years have seen great success in **Deep Learning** (**DL**) for
    solving practical business, industrial, and scientific problems, particularly
    for tasks such as **Natural Language Processing** (**NLP**), image, video, speech
    recognition, and conversational understanding. While research in these areas has
    made giant leaps, bringing these DL models from offline experimentation to production
    and continuously improving the models to deliver sustainable values is still a
    challenge. For example, a recent article by VentureBeat ([https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/](https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/))
    found that 87% of data science projects never make it to production. While there
    might be business reasons for such a low production rate, a major contributing
    factor is the difficulty caused by the lack of experiment management and a mature
    model production and feedback platform.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，**深度学习**（**DL**）在解决实际业务、工业和科学问题方面取得了巨大成功，特别是在**自然语言处理**（**NLP**）、图像、视频、语音识别和对话理解等任务中。尽管这些领域的研究取得了巨大的进展，但将这些深度学习模型从离线实验推广到生产环境，并持续改进模型以提供可持续的价值，仍然是一个挑战。例如，VentureBeat最近的一篇文章（[https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/](https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/)）发现，87%的数据科学项目从未进入生产。虽然这种低生产率可能有商业原因，但一个主要的因素是缺乏实验管理和成熟的模型生产与反馈平台所带来的困难。
- en: This chapter will help us to understand the challenges and bridge these gaps
    by learning the concepts, steps, and components that are commonly used in the
    full life cycle of DL model development. Additionally, we will learn about the
    challenges of an emerging field known as **Machine Learning Operations** (**MLOps**),
    which aims to standardize and automate ML life cycle development, deployment,
    and operation. Having a solid understanding of these challenges will motivate
    us to learn the skills presented in the rest of this book using MLflow, an open
    source, ML full life cycle platform. The business values of adopting MLOps' best
    practices are numerous; they include faster time-to-market of model-derived product
    features, lower operating costs, agile A/B testing, and strategic decision making
    to ultimately improve customer experience. By the end of this chapter, we will
    have learned about the critical role that MLflow plays in the four pillars of
    MLOps (that is, data, model, code, and explainability), implemented our first
    working DL model, and grasped a clear picture of the challenges with data, models,
    code, and explainability in DL.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将帮助我们理解这些挑战，并通过学习在深度学习模型开发的整个生命周期中常用的概念、步骤和组件来弥合这些差距。此外，我们还将学习一个新兴领域——**机器学习运维**（**MLOps**）的挑战，MLOps旨在标准化和自动化机器学习生命周期的开发、部署和运营。深入理解这些挑战将激励我们学习本书其余部分中介绍的使用MLflow的技能，MLflow是一个开源的机器学习全生命周期平台。采用MLOps最佳实践的商业价值有很多，其中包括更快的模型派生产品功能的市场推出、更低的运营成本、更灵活的A/B测试以及更具战略性的决策制定，从而最终改善客户体验。在本章结束时，我们将了解MLflow在MLOps四大支柱（即数据、模型、代码和可解释性）中所发挥的关键作用，实施我们的第一个工作深度学习模型，并清晰地理解数据、模型、代码和可解释性在深度学习中的挑战。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将覆盖以下主要内容：
- en: Understanding the DL life cycle and MLOps challenges
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解深度学习（DL）生命周期和MLOps挑战
- en: Understanding DL data challenges
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解深度学习（DL）数据挑战
- en: Understanding DL model challenges
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解深度学习（DL）模型的挑战
- en: Understanding DL code challenges
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解深度学习（DL）代码挑战
- en: Understanding DL explainability challenges
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解深度学习（DL）可解释性挑战
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'All of the code examples for this book can be found at the following GitHub
    URL: [https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本书所有的代码示例都可以在以下GitHub网址找到：[https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow)。
- en: You need to have Miniconda ([https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html))
    installed on your development environment. In this chapter, we will walk through
    the process of installing the PyTorch `lightning-flash` library ([https://github.com/PyTorchLightning/lightning-flash](https://github.com/PyTorchLightning/lightning-flash)),
    which can be used to build our first DL model in the *Implementing a basic DL
    sentiment classifier* section. Alternatively, you can sign up for a free Databricks
    Community Edition account at [https://community.cloud.databricks.com/login.html](https://community.cloud.databricks.com/login.html)
    and use a GPU cluster and a notebook to carry out the model development described
    in this book.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要在开发环境中安装Miniconda（[https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)）。在本章中，我们将逐步介绍安装PyTorch
    `lightning-flash`库的过程（[https://github.com/PyTorchLightning/lightning-flash](https://github.com/PyTorchLightning/lightning-flash)），该库可以用于在*实现一个基本的深度学习情感分类器*部分中构建我们的第一个深度学习模型。或者，你也可以注册一个免费的Databricks社区版账户（[https://community.cloud.databricks.com/login.html](https://community.cloud.databricks.com/login.html)），使用GPU集群和笔记本来进行本书中描述的模型开发。
- en: In addition to this, if you are a Microsoft Windows user, we recommend that
    you install WSL2 ([https://www.windowscentral.com/how-install-wsl2-windows-10](https://www.windowscentral.com/how-install-wsl2-windows-10))
    so that you have a Linux environment to run the command lines that are present
    in this book.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果你是微软Windows用户，我们建议你安装WSL2（[https://www.windowscentral.com/how-install-wsl2-windows-10](https://www.windowscentral.com/how-install-wsl2-windows-10)），这样你就能拥有一个Linux环境来运行本书中的命令行。
- en: Understanding the DL life cycle and MLOps challenges
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解深度学习生命周期和MLOps的挑战
- en: 'Nowadays, the most successful DL models that are deployed in production primarily
    observe the following two steps:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，成功部署到生产中的大多数深度学习模型主要遵循以下两个步骤：
- en: '**Self-supervised learning**: This refers to the pretraining of a model in
    a data-rich domain that does not require labeled data. This step produces a pretrained
    model, which is also called a **foundation model**, for example, BERT, GPT-3 for
    NLP, and VGG-NETS for computer vision.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自监督学习**：指的是在数据丰富的领域中进行模型的预训练，该领域不需要标签数据。这一步生成了一个预训练模型，也称为**基础模型**，例如，BERT、GPT-3用于自然语言处理（NLP），以及VGG-NETS用于计算机视觉。'
- en: '**Transfer learning**: This refers to the fine-tuning of the pretrained model
    in a specific prediction task such as text sentiment classification, which requires
    labeled training data.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**迁移学习**：指的是在特定预测任务中对预训练模型进行微调，例如文本情感分类，这需要有标签的训练数据。'
- en: One ground-breaking and successful example of a DL model in production is the
    *Buyer Sentiment Analysis* model, which is built on top of BERT for classifying
    sales engagement email messages, providing critical fine-grained insights into
    buyer emotions and signals beyond simple activity metrics such as reply, click,
    and open rates ([https://www.prnewswire.com/news-releases/outreach-unveils-groundbreaking-ai-powered-buyer-sentiment-analysis-transforming-sales-engagement-301188622.html](https://www.prnewswire.com/news-releases/outreach-unveils-groundbreaking-ai-powered-buyer-sentiment-analysis-transforming-sales-engagement-301188622.html)).
    There are different variants regarding how this works, but in this book, we will
    primarily focus on the **Transfer Learning** paradigm of developing and deploying
    DL models, as it exemplifies a practical DL life cycle.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一个开创性且成功的深度学习（DL）模型生产实例是*买家情感分析*模型，该模型基于BERT构建，用于分类销售互动邮件信息，提供对买家情感和信号的细致洞察，超越简单的活动指标，如回复、点击和打开率（[https://www.prnewswire.com/news-releases/outreach-unveils-groundbreaking-ai-powered-buyer-sentiment-analysis-transforming-sales-engagement-301188622.html](https://www.prnewswire.com/news-releases/outreach-unveils-groundbreaking-ai-powered-buyer-sentiment-analysis-transforming-sales-engagement-301188622.html)）。关于其工作原理有不同的变体，但在本书中，我们将主要聚焦于**迁移学习**范式，开发和部署深度学习模型，因为它展示了一个实用的深度学习生命周期。
- en: 'Let''s walk through an example to understand a typical core DL development
    paradigm. For example, the popular BERT model released in late 2018 (a basic version
    of the BERT model can be found at [https://huggingface.co/bert-base-uncased](https://huggingface.co/bert-base-uncased))
    was initially pretrained on raw texts (without human labeling) from over 11,000
    books from BookCorpus and the entire English Wikipedia. This pretrained language
    model was then fine-tuned to many downstream NLP tasks, such as text classification
    and sentiment analysis, in different application domains such as movie review
    classifications by using labeled movie review data ([https://huggingface.co/datasets/imdb](https://huggingface.co/datasets/imdb)).
    Note that sometimes, it might be necessary to further pretrain a foundation model
    (for example, BERT) within the application domain by using unlabeled data before
    fine-tuning to boost the final model performance in terms of accuracy. This core
    DL development paradigm is illustrated in *Figure 1.1*:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来了解典型的核心深度学习开发范式。例如，2018年底发布的流行BERT模型（BERT模型的基础版本可以在[https://huggingface.co/bert-base-uncased](https://huggingface.co/bert-base-uncased)找到）最初是在来自BookCorpus的11,000多本书籍以及整个英文维基百科的原始文本上进行预训练的（没有人工标注）。然后，使用该预训练语言模型对许多下游自然语言处理任务进行了微调，如文本分类和情感分析，应用于不同的领域，比如通过使用标注的电影评论数据进行电影评论分类（[https://huggingface.co/datasets/imdb](https://huggingface.co/datasets/imdb)）。需要注意的是，有时为了提高最终模型在准确度方面的性能，可能需要使用无标签数据在应用领域内进一步预训练基础模型（例如BERT），然后再进行微调。这个核心的深度学习开发范式如*图1.1*所示：
- en: '![Figure 1.1 – A typical core DL development paradigm'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.1 – 一个典型的核心深度学习开发范式'
- en: '](img/B18120_01_001.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_01_001.jpg)'
- en: Figure 1.1 – A typical core DL development paradigm
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 – 一个典型的核心深度学习开发范式
- en: Note that while *Figure 1.1* represents a common development paradigm, not all
    of these steps are necessary for a specific application scenario. For example,
    you might only need to do fine-tuning using a publicly available pretrained DL
    model with your labeled application-specific data. Therefore, you don't need to
    do your own pretraining or carry out further pretraining using unlabeled data
    since other people or organizations have already done the pretraining step for
    you.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，虽然*图1.1*代表了一个常见的开发范式，但并不是所有的步骤在特定的应用场景中都是必要的。例如，你可能只需要使用公开的预训练深度学习模型和你标注好的应用特定数据进行微调。因此，你不需要进行自己的预训练或使用无标签数据进一步预训练，因为其他人或组织已经为你完成了预训练步骤。
- en: DL over Classical ML
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习与传统机器学习
- en: Unlike classical ML model development, where, usually, a feature engineering
    step is required to extract and transform raw data into features to train an ML
    model such as decision tree or logistic regression, DL can learn the features
    automatically, which is especially attractive for modeling unstructured data such
    as texts, images, videos, audio, and speeches. DL is also called *representational
    learning* due to this characteristic. In addition to this, DL is usually data-
    and compute-intensive, requiring **Graphics Process Units** (**GPUs**), **Tensor
    Process Units** (**TPU**), or other types of computing hardware accelerators for
    at-scale training and inference. Explainability for DL models is also harder to
    implement, compared with traditional ML models, although recent progress has now
    made that possible.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统的机器学习模型开发不同，通常需要进行特征工程步骤，将原始数据提取并转化为特征，以训练如决策树或逻辑回归这样的机器学习模型，深度学习能够自动学习特征，这一点对于建模非结构化数据（如文本、图像、视频、音频和语音）尤其有吸引力。由于这一特点，深度学习也被称为*表征学习*。除此之外，深度学习通常是数据密集型和计算密集型的，需要**图形处理单元**（**GPUs**）、**张量处理单元**（**TPU**）或其他类型的计算硬件加速器来进行大规模训练和推理。相比传统机器学习模型，深度学习模型的可解释性也更难实现，尽管近期的进展已经使得这一点成为可能。
- en: Implementing a basic DL sentiment classifier
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现一个基本的深度学习情感分类器
- en: 'To set up the development of a basic DL sentiment classifier, you need to create
    a virtual environment in your local environment. Let''s assume that you have `dl_model`
    and install the PyTorch `lightning-flash` package so that the model can be built:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了设置基本的深度学习情感分类器开发环境，你需要在本地创建一个虚拟环境。假设你已经有了`dl_model`，并且安装了PyTorch的`lightning-flash`包，这样模型就能被构建：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Depending on your local machine''s memory, the preceding commands might take
    about 10 minutes to finish. You can verify the success of your installation by
    running the following command:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你本地机器的内存情况，前面的命令可能需要大约10分钟才能完成。你可以通过运行以下命令来验证安装是否成功：
- en: '[PRE1]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If you see output similar to the following, your installation was successful:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你看到类似以下的输出，说明安装成功：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now you are ready to build your first DL model!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经准备好构建你的第一个深度学习模型了！
- en: 'To begin building a DL model, complete the following steps:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始构建一个深度学习模型，请完成以下步骤：
- en: 'Import the necessary `torch` and `flash` libraries, and import `download_data`,
    `TextClassificationData`, and `TextClassifier` from the `flash` subpackages:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的`torch`和`flash`库，并从`flash`子包中导入`download_data`、`TextClassificationData`和`TextClassifier`：
- en: '[PRE3]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To get the dataset for fine-tuning, use `download_data` to download the `imdb.zip`
    file, which is the public domain binary sentiment classification (positive/negative)
    dataset from `train.csv`
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了进行微调，使用`download_data`下载`imdb.zip`文件，它是来自`train.csv`的公共领域二元情感分类（正面/负面）数据集。
- en: '`valid.csv`'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`valid.csv`'
- en: '`test.csv`'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`test.csv`'
- en: 'Each file contains two columns: `review` and `sentiment`. We then use `TextClassificationData.from_csv`
    to declare a `datamodule` variable that assigns the "review" to `input_fields`,
    and the "sentiment" to `target_fields`. Additionally, it assigns the `train.csv`
    file to `train_file`, the `valid.csv` file to `val_file`, and the `test.csv` file
    to the `test_file` properties of `datamodule`, respectively:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 每个文件包含两列：`review`和`sentiment`。然后，我们使用`TextClassificationData.from_csv`声明一个`datamodule`变量，将“review”分配给`input_fields`，将“sentiment”分配给`target_fields`。此外，它还将`train.csv`文件分配给`train_file`，将`valid.csv`文件分配给`val_file`，将`test.csv`文件分配给`test_file`属性：
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Once we have the data, we can now perform fine-tuning using a foundation model.
    First, we declare `classifier_model` by calling `TextClassifier` with a backbone
    assigned to `prajjwal1/bert-tiny` (which is a much smaller BERT-like pretrained
    model located in the Hugging Face model repository: [https://huggingface.co/prajjwal1/bert-tiny](https://huggingface.co/prajjwal1/bert-tiny)).
    This means our model will be based on the `bert-tiny` model.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们有了数据，我们现在可以使用基础模型进行微调。首先，通过调用`TextClassifier`并将骨干网络（backbone）设置为`prajjwal1/bert-tiny`来声明`classifier_model`（`prajjwal1/bert-tiny`是一个更小的类似BERT的预训练模型，位于Hugging
    Face模型库中：[https://huggingface.co/prajjwal1/bert-tiny](https://huggingface.co/prajjwal1/bert-tiny)）。这意味着我们的模型将基于`bert-tiny`模型。
- en: 'The next step is to set up the trainer by defining how many epochs we want
    to run and how many GPUs we want to use to run them. Here, `torch.cuda.device_count()`
    will return either *0* (no GPU) or *1* to *N*, where *N* is the maximum number
    of GPUs you can have in your running environment. Now we are ready to call `trainer.finetune`
    to train a binary sentiment classifier for the IMDb dataset:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是通过定义我们希望运行的轮数（epochs）和希望使用的GPU数量来设置训练器。这里，`torch.cuda.device_count()`将返回*0*（没有GPU）或*1*到*N*，其中*N*是你运行环境中最大可用GPU的数量。现在，我们已经准备好调用`trainer.finetune`来训练一个二元情感分类器，使用的是IMDb数据集：
- en: '[PRE5]'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Once the fine-tuning step is complete, we will test the accuracy of the model
    by running `trainer.test()`:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 微调步骤完成后，我们将通过运行`trainer.test()`来测试模型的准确性：
- en: '[PRE6]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The output of the test should look similar to the following screenshot, whichindicates
    that the final model accuracy is about 52%:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 测试结果的输出应该类似于以下屏幕截图，表明最终模型的准确率大约为52%：
- en: '![Figure 1.2 – The test results of our first DL model'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.2 – 我们的第一个深度学习模型的测试结果'
- en: '](img/B18120_01_002.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_01_002.jpg)'
- en: Figure 1.2 – The test results of our first DL model
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.2 – 我们的第一个深度学习模型的测试结果
- en: The test result shown in the preceding diagram indicates that we have a basic
    version of the model, as we only fine-tuned the foundation model for three epochs
    and haven't used any advanced techniques such as hyperparameter tuning or better
    fine-tuning strategies. However, this is a great accomplishment since you now
    have a working knowledge of how the core DL model paradigm works! We will explore
    more advanced model training techniques in later chapters of this book.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 前面图表中显示的测试结果表明，我们有了模型的基本版本，因为我们只对基础模型进行了三轮微调，并且没有使用诸如超参数调优或更好的微调策略等高级技术。然而，这是一个很大的成就，因为你现在已经掌握了核心深度学习模型的工作原理！我们将在本书的后续章节中探索更高级的模型训练技术。
- en: Understanding DL's full life cycle development
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解深度学习的完整生命周期开发
- en: By now, you should have your first DL model ready and should feel proud of it.
    Now, let's explore the full DL life cycle together to fully understand its concepts,
    components, and challenges.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该已经准备好第一个深度学习模型，并应该为此感到自豪。现在，让我们一起探索完整的深度学习生命周期，充分理解其概念、组成部分和挑战。
- en: 'You might have gathered that the core DL development paradigm revolves around
    three key artifacts: *Data*, *Model*, and *Code*. In addition to this, *Explainability*
    is another major artifact that is required in many mission-critical application
    scenarios such as medical diagnoses, the financial industry, and decision making
    for criminal justice. As DL is usually considered a black box, providing explainability
    for DL increasingly becomes a key requirement before and after shipping to production.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经了解到，核心的深度学习开发范式围绕着三个关键要素：*数据*、*模型*和*代码*。除此之外，*可解释性*是另一个在许多关键任务应用场景中所需的重要要素，如医学诊断、金融行业以及刑事司法决策。由于深度学习通常被视为“黑盒”，因此在部署到生产环境之前和之后，提供可解释性越来越成为一个关键要求。
- en: Note that *Figure 1.1* is still considered offline experimentation if we are
    still trying to figure out which model works using a dataset in a lab-like environment.
    Even in such an offline experimentation environment, things will quickly become
    complicated. Additionally, we would like to know and track which experiments we
    have or have not performed so that we don't waste time repeating the same experiments,
    whatever parameters and datasets we have used, and whatever kind of metrics we
    have for a specific model. Once we have a model that's good enough for the use
    cases and customer scenarios, the complexity increases as we need a way to continuously
    deploy and update the model in production, monitor the model and data drift, and
    then retrain the model when necessary. This complexity further increases when
    at-scale training, deployment, monitoring, and explainability are needed.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果我们仍在试图通过实验室环境中的数据集确定哪个模型有效，那么*图 1.1* 仍然被视为离线实验。即使在这种离线实验环境中，情况也会迅速变得复杂。此外，我们希望了解并追踪我们已经或尚未执行过哪些实验，以便避免浪费时间重复相同的实验，无论我们使用了哪些参数和数据集，或者对于特定模型，我们采用了什么样的指标。一旦我们拥有一个足够适用于用例和客户场景的模型，复杂性将增加，因为我们需要一种持续部署和更新模型的方法，监控模型和数据的漂移，并在必要时重新训练模型。当需要大规模训练、部署、监控和可解释性时，这种复杂性会进一步增加。
- en: 'Let''s examine what a DL life cycle looks like (see *Figure 1.3*). There are
    five stages:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看深度学习生命周期的样子（见*图 1.3*）。有五个阶段：
- en: Data collection, cleaning, and annotation/labeling.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据收集、清洗和注释/标注。
- en: Model development (which is also known as offline experimentation). The core
    DL development paradigm in *Figure 1.1* is considered part of the *model development*
    stage, which itself can be an iterative process.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型开发（也称为离线实验）。*图 1.1* 中的核心深度学习开发范式被视为模型开发阶段的一部分，而该阶段本身可以是一个迭代过程。
- en: Model deployment and serving in production.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型部署与生产环境中的服务。
- en: Model validation and A/B testing (which is also known as online experimentation;
    this is usually in a production environment).
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型验证与 A/B 测试（也称为在线实验；通常在生产环境中进行）。
- en: Monitoring and feedback data collection during production.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在生产过程中进行监控和反馈数据收集。
- en: '*Figure 1.3* provides a diagram to show that it is a continuous development
    cycle for a DL model:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 1.3* 提供了一个图示，展示了这是一个持续发展的深度学习模型开发周期：'
- en: '![Figure 1.3 – The full DL development life cycle'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.3 – 完整的深度学习开发生命周期'
- en: '](img/B18120_01_003.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_01_003.jpg)'
- en: Figure 1.3 – The full DL development life cycle
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3 – 完整的深度学习开发生命周期
- en: 'In addition to this, we want to point out that the backbone of these five stages,
    as shown in *Figure 1.3*, essentially revolves around the four artifacts: data,
    model, code, and explainability. We will examine the challenges related to these
    four artifacts in the life cycle in the following sections. However, first, let''s
    explore and understand MLOps, which is an evolving platform concept and framework
    that supports the full life cycle of ML. This will help us understand these challenges
    in a big-picture context.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，我们还想指出，正如*图 1.3* 所示，这五个阶段的支柱实际上围绕着四个要素：数据、模型、代码和可解释性。我们将在接下来的章节中探讨这些要素在生命周期中的挑战。然而，首先，让我们了解并理解
    MLOps，这是一个不断发展的平台概念和框架，支持机器学习的完整生命周期。这将帮助我们在更宏观的背景下理解这些挑战。
- en: Understanding MLOps challenges
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 MLOps 挑战
- en: 'MLOps has some connections to DevOps, where a set of technology stacks and
    standard operational procedures are used for software development and deployment
    combined with IT operations. Unlike traditional software development, ML and especially
    DL represent a new era of software development paradigms called **Software 2.0**
    ([https://karpathy.medium.com/software-2-0-a64152b37c35](https://karpathy.medium.com/software-2-0-a64152b37c35)).
    The key differentiator of Software 2.0 is that the behavior of the software does
    not just depend on well-understood programming language code (which is the characteristic
    of Software 1.0) but depends on the learned weights in a neural network that''s
    difficult to write as code. In other words, there exists an inseparable integration
    of the code, data, and model that must be managed together. Therefore, MLOps is
    being developed and is still evolving to accommodate this new Software 2.0 paradigm.
    In this book, MLOps is defined as an operational automation platform that consists
    of three foundation layers and four pillars. They are listed as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps与DevOps有一些联系，DevOps使用一系列技术栈和标准操作流程来进行软件开发和部署，并结合IT运维。与传统软件开发不同，机器学习（ML）尤其是深度学习（DL）代表着一种新的软件开发范式——**软件2.0**（[https://karpathy.medium.com/software-2-0-a64152b37c35](https://karpathy.medium.com/software-2-0-a64152b37c35)）。软件2.0的关键区别在于，软件的行为不仅依赖于人们已经理解的编程语言代码（这是软件1.0的特点），还依赖于神经网络中学习到的权重，而这些权重很难写成代码。换句话说，代码、数据和模型的整合是不可分割的，必须共同管理。因此，MLOps正在发展，并且仍在不断演变，以适应这一新的软件2.0范式。本书中，MLOps被定义为一个由三大基础层和四大支柱组成的运营自动化平台。它们如下所示：
- en: 'Here are the three foundation layers:'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下面是三大基础层：
- en: Infrastructure management and automation
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础设施管理与自动化
- en: Application life cycle management and **Continuous Integration and Continuous
    Deployment** (**CI/CD**)
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用生命周期管理与**持续集成与持续部署**（**CI/CD**）
- en: Service system observability
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务系统可观测性
- en: 'Here are the four pillars:'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下面是四大支柱：
- en: Data observability and management
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可观测性与管理
- en: Model observability and life cycle management
  id: totrans-74
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型可观测性与生命周期管理
- en: Explainability and **Artificial Intelligence** (**AI**) observability
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可解释性与**人工智能**（**AI**）可观测性
- en: Code reproducibility and observability
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码可复现性与可观测性
- en: 'Additionally, we will explain MLflow''s roles in these MLOps layers and pillars
    so that we have a clear picture regarding what MLflow can do to build up the MLOps
    layers in their entirety:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还将解释MLflow在这些MLOps层和支柱中的角色，以便我们清楚地了解MLflow如何在整体上构建MLOps层：
- en: '**Infrastructure management and automation**: This includes, but is not limited
    to, *Kubernetes* (also known as k8s) for automated container orchestration and
    *Terraform* (commonly used for managing hundreds of cloud services and access
    control). These tools are adapted to manage ML and DL applications that have deployed
    models as service endpoints. These infrastructure layers are not the focus of
    this book; instead, we will focus on how to deploy a trained DL model using MLflow''s
    provided capabilities.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施管理与自动化**：这包括但不限于用于自动化容器编排的*Kubernetes*（也称为k8s）和用于管理数百个云服务及访问控制的*Terraform*（常用于此）。这些工具已适应于管理已部署为服务端点的机器学习（ML）和深度学习（DL）应用程序。书中并不专注于这些基础设施层；相反，我们将专注于如何使用MLflow提供的功能来部署训练好的深度学习模型。'
- en: '**Application life cycle management and CI/CD**: This includes, but is not
    limited to, *Docker* containers for virtualization, container life cycle management
    tools such as Kubernetes, and *CircleCI* or *Concourse* for **CI** and **CD**.
    Usually, CI means that whenever there are code or model changes in a GitHub repository,
    a series of automatic tests will be triggered to make sure no breaking changes
    are introduced. Once these tests have been passed, new changes will be automatically
    released as part of a new package. This will then trigger a new deployment process
    (CD) to deploy the new package to the production environment (often, this will
    include human approval as a safety gate). Note that these tools are not unique
    to ML applications but have been adapted to ML and DL applications, especially
    when we require GPU and distributed clusters for the training and testing of DL
    models. In this book, we will not focus on these tools but will mention the integration
    points or examples when needed.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用生命周期管理和CI/CD**：这包括但不限于用于虚拟化的*Docker*容器、如Kubernetes这样的容器生命周期管理工具，以及用于**CI**和**CD**的*CircleCI*或*Concourse*。通常，CI指的是每当GitHub仓库中的代码或模型发生变化时，一系列自动化测试将被触发，以确保不会引入破坏性更改。一旦这些测试通过，新的更改将自动发布为新包的一部分。这将触发一个新的部署过程（CD），将新包部署到生产环境中（通常，这将包括人为批准作为安全门）。请注意，这些工具并非ML应用程序独有，而是已被调整为适应ML和DL应用，尤其是当我们需要GPU和分布式集群来训练和测试DL模型时。本书中，我们不会专注于这些工具，但会在需要时提及集成点或示例。'
- en: '**Service system observability**: This is mostly for monitoring the hardware/clusters/CPU/memory/storage,
    operating system, service availability, latency, and throughput. This includes
    tools such as *Grafana*, *Datadog*, and more. Again, these are not unique to ML
    and DL applications and are not the focus of this book.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务系统可观察性**：这主要是用于监控硬件/集群/CPU/内存/存储、操作系统、服务可用性、延迟和吞吐量。这包括如*Grafana*、*Datadog*等工具。同样，这些工具并非ML和DL应用独有，也不是本书的重点。'
- en: '**Data observability and management**: This is traditionally under-represented
    in the DevOps world but becomes very important in MLOps as data is critical within
    the full life cycle of ML/DL models. This includes *data quality monitoring*,
    *outlier detection*, *data drift* and *concept drift detection*, *bias detection*,
    *secured* and *compliant data sharing*, *data provenance tracking* and *versioning*,
    and more. The tool stacks in this area that are suitable for ML and DL applications
    are still emerging. A few examples include **DataFold** ([https://www.datafold.com/](https://www.datafold.com/))
    and **Databand** ([https://databand.ai/open-source/](https://databand.ai/open-source/)).
    A recent development in data management is a unified lakehouse architecture and
    implementation called **Delta Lake** ([http://delta.io](http://delta.io)) that
    can be used for ML data management. MLflow has native integration points with
    Delta Lake, and we will cover that integration in this book.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据可观察性和管理**：这在传统的DevOps世界中表现得相对不足，但在MLOps中变得非常重要，因为数据在ML/DL模型的整个生命周期中至关重要。这包括*数据质量监控*、*异常检测*、*数据漂移*和*概念漂移检测*、*偏差检测*、*安全*和*合规的数据共享*、*数据来源追踪*和*版本管理*等。这一领域适用于ML和DL应用的工具栈仍在不断涌现。一些例子包括**DataFold**（[https://www.datafold.com/](https://www.datafold.com/)）和**Databand**（[https://databand.ai/open-source/](https://databand.ai/open-source/)）。数据管理中的一个最新发展是一个统一的湖仓架构和实现，称为**Delta
    Lake**（[http://delta.io](http://delta.io)），可用于ML数据管理。MLflow与Delta Lake有原生集成点，我们将在本书中介绍该集成。'
- en: '**Model observability and life cycle management**: This is unique to ML/DL
    models, and it only became widely available recently due to the rise of MLflow.
    This includes tools for model training, testing, versioning, registration, deployment,
    serialization, model drift monitoring, and more. We will learn about the exciting
    capabilities that MLflow provides in this area. Note that once we combine CI/CD
    tools with MLflow training/monitoring, user feedback loops, and human annotations,
    we can achieve **Continuous Training**, **Continuous Testing**, and **Continuous
    Labeling**. MLflow provides the foundational capabilities so that further automation
    in MLOps becomes possible, although such complete automation will not be the focus
    of this book. Interested readers can find relevant references at the end of this
    chapter to explore this area further.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型可观察性和生命周期管理**：这是ML/DL模型特有的，且由于MLflow的兴起，这一功能直到最近才得以广泛应用。这包括模型训练、测试、版本管理、注册、部署、序列化、模型漂移监控等工具。我们将学习MLflow在这一领域所提供的令人兴奋的能力。值得注意的是，一旦将CI/CD工具与MLflow的训练/监控、用户反馈回路和人工标注结合起来，我们就可以实现**持续训练**、**持续测试**和**持续标注**。MLflow提供了基础能力，使得MLOps中的进一步自动化成为可能，尽管这种完全自动化并不是本书的重点。有兴趣的读者可以在本章末尾找到相关参考资料，以便深入探索这一领域。'
- en: '**Explainability and AI observability**: This is unique to ML/DL models and
    is especially important for DL models, as traditionally, DL models are treated
    as black boxes. Understanding why the model provides certain predictions is critical
    for societally important applications. For example, in medical, financial, juridical,
    and many human-in-the-loop decision support applications, such as civilian and
    military emergency response, the demand for explainability is increasingly higher.
    MLflow provides native integration with a popular explainability framework called
    SHAP, which we will cover in this book.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性和AI可观察性**：这是ML/DL模型特有的，尤其对DL模型而言尤为重要，因为传统上，DL模型被视为“黑箱”。理解模型为何给出某些预测，对于社会影响深远的应用至关重要。例如，在医疗、金融、司法和许多人机协作的决策支持应用中，如民用和军事应急响应，对可解释性的需求日益增加。MLflow与一种叫做SHAP的流行可解释性框架原生集成，本书将详细介绍该框架。'
- en: '**Code reproducibility and observability**: This is not entirely unique to
    ML/DL applications. However, DL models face some special challenges as the number
    of DL code frameworks are diverse and the need to reproduce a model is not entirely
    up to the code alone (we also need data and execution environments such as GPU
    clusters). In addition to this, notebooks are commonly used in model development
    and production. How to manage the notebooks along with the model run is important.
    Usually, GitHub is used to manage the code repository; however, we need to structure
    the ML project code in a way that''s reproducible either locally (such as on a
    local laptop) or remotely (for example, in a Databricks'' GPU cluster). MLflow
    provides this capability to allow DL projects that have been written once to run
    anywhere, whether this is in an offline experimentation environment or an online
    production environment. We will cover MLflow''s MLproject capability in this book.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代码可复现性和可观察性**：这并不完全是ML/DL应用程序所特有的。然而，DL模型面临一些特殊挑战，因为DL代码框架种类繁多，且复现模型的需求不仅仅依赖于代码本身（我们还需要数据和执行环境，如GPU集群）。此外，笔记本通常用于模型的开发和生产。如何管理笔记本与模型运行之间的关系非常重要。通常，GitHub被用于管理代码库；然而，我们需要以可复现的方式构建ML项目代码，无论是在本地（例如本地笔记本电脑）还是远程（例如，在Databricks的GPU集群中）。MLflow提供了这一能力，允许已经编写的DL项目在任何地方运行，无论是在离线实验环境中，还是在在线生产环境中。本书将介绍MLflow的MLproject功能。'
- en: 'In summary, MLflow plays a critical and foundational role in MLOps. It fills
    in the gaps that DevOps traditionally does not cover and, thus, is the focus of
    this book. The following diagram (*Figure 1.4*) shows the central roles of MLflow
    in the still-evolving MLOps world:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，MLflow在MLOps中扮演着至关重要且基础性的角色。它填补了DevOps传统上未覆盖的空白，因此是本书的重点。下图（*图1.4*）展示了MLflow在不断发展的MLOps世界中所扮演的核心角色：
- en: '![Figure 1.4 – The three layers and four pillars of MLOps and MLflow''s roles'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.4 – MLOps的三层结构和四大支柱，以及MLflow的作用'
- en: '](img/B18120_01_004.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_01_004.jpg)'
- en: Figure 1.4 – The three layers and four pillars of MLOps and MLflow's roles
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 – MLOps的三层结构和四大支柱，以及MLflow的作用
- en: While the bottom two layers and the topmost layer are common within many software
    development and deployment processes, the middle four pillars are either entirely
    unique to ML/DL applications or partially unique to ML/DL applications. MLflow
    plays a critical role in all four of these pillars in MLOps. This book will help
    you to confidently apply MLflow to solve the issues of these four pillars while
    also equipping you to further integrate with other tools in the MLOps layers depicted
    in *Figure 1.4* for full automation depending on your scenario requirements.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然底部的两个层和最上层在许多软件开发和部署过程中是常见的，但中间的四个支柱要么完全独特于机器学习/深度学习应用，要么部分独特于机器学习/深度学习应用。MLflow在MLOps的这四个支柱中起着至关重要的作用。本书将帮助你自信地应用MLflow解决这四个支柱的问题，同时为你提供进一步集成其他工具的能力，结合*图1.4*所示的MLOps层，依据你的场景需求实现全自动化。
- en: Understanding DL data challenges
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解深度学习数据挑战
- en: 'In this section, we will discuss the data challenges at each stage of the DL
    life cycle, as illustrated in *Figure 1.3*. Essentially, DL is a data-centric
    AI, unlike symbolic AI where human knowledge can be used without lots of data.
    The challenges for data in DL are pervasive in all stages of the full life cycle:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论深度学习生命周期各个阶段的数据挑战，如*图1.3*所示。本质上，深度学习是数据中心的人工智能，与符号人工智能不同，符号人工智能可以在没有大量数据的情况下利用人类知识。深度学习中的数据挑战贯穿整个生命周期的所有阶段：
- en: '**Data collection/cleaning/annotation**: One of DL''s first successes began
    with **ImageNet** ([https://www.image-net.org/](https://www.image-net.org/)),
    where millions of images are collected and annotated according to the English
    nouns in the WordNet database ([https://wordnet.princeton.edu/](https://wordnet.princeton.edu/)).
    This led to the successful development of pretrained DL models for computer vision
    such as VGG-NETS ([https://pytorch.org/hub/pytorch_vision_vgg/](https://pytorch.org/hub/pytorch_vision_vgg/)),
    which can perform state-of-the-art image classification and is widely used for
    industrial and business applications. The main challenge of this kind of large-scale
    data collection and annotation is the unknown bias, which is hard to measure in
    this process ([https://venturebeat.com/2020/11/03/researchers-show-that-computer-vision-algorithms-pretrained-on-imagenet-exhibit-multiple-distressing-biases/](https://venturebeat.com/2020/11/03/researchers-show-that-computer-vision-algorithms-pretrained-on-imagenet-exhibit-multiple-distressing-biases/)).
    Another example is the sales engagement platform **Outreach** ([https://www.outreach.io/](https://www.outreach.io/)),
    where we can classify a potential buyer''s sentiment. For instance, we might start
    by collecting email messages of 100 paid organizations to train a DL model. Following
    this, we would need to collect email messages from more organizations, either
    due to an accuracy requirement or expanded language coverage (such as from English
    only to other languages such as German and French). These many iterations of data
    collection and annotation will generate quite a lot of datasets. There is a tendency
    to just name the version of the dataset with hardcoded version numbers as part
    of a dataset filename such as the following:'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据收集/清洗/标注**：深度学习的首个成功之一始于**ImageNet** ([https://www.image-net.org/](https://www.image-net.org/))，该平台收集并根据WordNet数据库中的英文名词对数百万张图像进行了标注
    ([https://wordnet.princeton.edu/](https://wordnet.princeton.edu/))。这促成了预训练深度学习模型在计算机视觉领域的成功发展，如VGG-NETS
    ([https://pytorch.org/hub/pytorch_vision_vgg/](https://pytorch.org/hub/pytorch_vision_vgg/))，该模型能够执行最先进的图像分类，并广泛应用于工业和商业领域。这种大规模数据收集和标注的主要挑战是未知的偏差，这在这一过程中很难测量
    ([https://venturebeat.com/2020/11/03/researchers-show-that-computer-vision-algorithms-pretrained-on-imagenet-exhibit-multiple-distressing-biases/](https://venturebeat.com/2020/11/03/researchers-show-that-computer-vision-algorithms-pretrained-on-imagenet-exhibit-multiple-distressing-biases/))。另一个例子是销售参与平台**Outreach**
    ([https://www.outreach.io/](https://www.outreach.io/))，我们可以在其中分类潜在买家的情绪。例如，我们可以从收集100个付费组织的电子邮件信息开始，以训练一个深度学习模型。接下来，我们需要收集更多组织的电子邮件信息，可能是出于准确性要求或扩展语言覆盖范围（例如从仅限英语到其他语言，如德语和法语）。这些反复的数据收集和标注会生成大量的数据集。通常，我们会仅仅用硬编码的版本号为数据集命名，并将其作为数据集文件名的一部分，例如以下所示：'
- en: '[PRE7]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This seems to work until some changes are required in any one of the vX.0 datasets
    due to the need to correct annotation errors or remove email messages because
    of customer churn. Also, what happens if we need to combine several datasets together
    or perform some data cleaning and transformation to train a new DL model? What
    if we need to implement data augmentation to artificially generate some datasets?
    Evidently, simply changing the names of the files is neither scalable nor sustainable.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎有效，直到由于需要修正注释错误或因客户流失而移除电子邮件消息时，某些vX.0数据集需要更改。如果我们需要将多个数据集结合起来，或者进行一些数据清洗和转换以训练一个新的深度学习模型，怎么办？如果我们需要实施数据增强来人工生成一些数据集呢？显然，简单地更改文件名既不可扩展也不可持续。
- en: '**Model development**: We need to understand that the bias in the data we use
    to train/pretrain a DL model will reflect in the prediction when applying the
    model. While we do not focus on de-biasing data in this book, we must implement
    data versioning and data provenance as first-class artifacts when training and
    serving a DL model so that we can track all model experiments. When fine-tuning
    a pretrained model for our use cases, as we did earlier, we also need to track
    the versioning of the fine-tuning dataset we use. In our previous example, we
    use a variant of the BERT model to fine-tune the IMDb review data. While, in our
    first example, we did not care about the versioning or source of the data, this
    is important for a practical and real application. In summary, DL models need
    to link to a particular version of datasets using a scalable approach. We will
    provide solutions to this topic in this book.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型开发**：我们需要理解，用于训练/预训练深度学习模型的数据中的偏差会在应用模型时反映到预测中。虽然本书不会专注于消除数据偏差，但我们必须在训练和服务深度学习模型时，实施数据版本控制和数据来源管理，将其作为首要的构建模块，这样我们才能跟踪所有模型实验。在针对我们的使用场景对预训练模型进行微调时，正如我们之前所做的那样，我们还需要跟踪微调数据集的版本。在我们之前的例子中，我们使用了BERT模型的一个变种来微调IMDb评论数据。虽然在第一个例子中我们并没有关心数据的版本或来源，但对于实际应用来说，这是非常重要的。总的来说，深度学习模型需要通过一种可扩展的方法与特定版本的数据集关联。本书将提供有关此主题的解决方案。'
- en: '**Model deployment and serving in production**: This is for deploying into
    the production environment to serve online traffic. DL model serving latency is
    of particular importance and is interesting to collect at this stage. This might
    allow you to adjust the hardware environment used for inference.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署与线上服务**：这是将模型部署到生产环境中以服务在线流量的过程。深度学习模型的服务延迟在这一阶段尤为重要，值得收集。这可能使你能够调整用于推理的硬件环境。'
- en: '**Model validation and A/B testing**: The data we collect at this stage is
    mostly for user behavior metrics in the online experimentation environment ([https://www.slideshare.net/pavel/ab-testing-ai-global-artificial-intelligence-conference-2019](https://www.slideshare.net/pavel/ab-testing-ai-global-artificial-intelligence-conference-2019)).
    Online data traffic also needs to be characterized in order to understand whether
    there is a statistical difference in the input to the model between offline experimentation
    and online experimentation. Only if we pass the A/B testing and validate that
    the model indeed works better than its previous version in terms of user behavior
    metrics do we roll out to production for all users.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型验证与A/B测试**：我们在这一阶段收集的数据主要是在线实验环境中的用户行为指标（[https://www.slideshare.net/pavel/ab-testing-ai-global-artificial-intelligence-conference-2019](https://www.slideshare.net/pavel/ab-testing-ai-global-artificial-intelligence-conference-2019)）。还需要对在线数据流量进行特征分析，以便了解模型输入在离线实验与在线实验之间是否存在统计差异。只有通过A/B测试并验证模型确实在用户行为指标方面优于之前的版本，我们才会将其推向生产环境，供所有用户使用。'
- en: '**Monitoring and feedback loops**: In this stage, note that the data will need
    to be continuously collected to detect data drift and concept drift. For example,
    in the buyer sentiment classification example discussed earlier, if buyers start
    to use terminology that is not encountered in the training data, the performance
    of the model could suffer.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控与反馈循环**：在这一阶段，需要注意的是，数据需要持续收集，以便检测数据漂移和概念漂移。例如，在前面讨论的买家情绪分类案例中，如果买家开始使用训练数据中未出现的术语，模型的性能可能会下降。'
- en: In summary, data tracking and observability are major challenges in all stages
    of the DL life cycle.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，数据跟踪和可观测性是深度学习（DL）生命周期各个阶段中的主要挑战。
- en: Understanding DL model challenges
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解深度学习模型的挑战
- en: 'In this section, we will discuss DL model challenges. Let''s look at the challenges
    at each stage of the DL life cycle, as depicted in *Figure 1.3*:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论深度学习（DL）模型的挑战。让我们看看深度学习生命周期各阶段的挑战，如*图 1.3* 所示：
- en: '**Data collection/cleaning/annotation**: While the data challenge has already
    been stated, the challenge of linking data to the model of interest still exists.
    MLflow has native integration with Delta Lake so that any trained model can be
    traced back to a particular version within Delta Lake.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据收集/清理/标注**：虽然数据挑战已经被提到，但将数据与目标模型关联的挑战仍然存在。MLflow 与 Delta Lake 原生集成，以便任何训练过的模型都可以追溯到
    Delta Lake 中的特定版本。'
- en: '`pickle`.([https://github.com/cloudpipe/cloudpickle](https://github.com/cloudpipe/cloudpickle))
    is usually used in serializing the model written in Python. However, TorchScript
    ([https://pytorch.org/docs/stable/jit.html](https://pytorch.org/docs/stable/jit.html))
    is now highly performant for PyTorch models. In addition, Open Neural Network
    Exchange or ONNX ([https://onnx.ai/](https://onnx.ai/)) tries to provide more
    framework-agnostic DL serialization. Finally, we need to log the serialized model
    and register the model so that we can track model versioning. MLflow is one of
    the first open source tools to overcome these challenges.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pickle`([https://github.com/cloudpipe/cloudpickle](https://github.com/cloudpipe/cloudpickle))
    通常用于序列化用 Python 编写的模型。然而，TorchScript ([https://pytorch.org/docs/stable/jit.html](https://pytorch.org/docs/stable/jit.html))
    目前在 PyTorch 模型中表现出色。此外，Open Neural Network Exchange 或 ONNX ([https://onnx.ai/](https://onnx.ai/))
    尝试提供更具框架无关性的深度学习序列化。最后，我们需要记录序列化的模型并注册该模型，以便跟踪模型版本。MLflow 是第一个克服这些挑战的开源工具之一。'
- en: '**Model deployment and serving in production**: An easy-to-use model deployment
    tool that can tie into the model registry is a challenge. MLflow can be used to
    alleviate that, allowing you to load models for production deployment with full
    provenance tracking.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生产环境中的模型部署和服务**：一个易于使用的模型部署工具，能够与模型注册表进行连接，是一项挑战。MLflow 可以帮助解决这个问题，允许你加载模型进行生产部署，并完整追踪模型的来源。'
- en: '**Model validation and A/B testing**: During online validation and experimentation,
    model performance needs to be validated and user behavior metrics need to be collected.
    This is so that we can easily roll back or redeploy a particular version of the
    models. A model registry is critical for at-scale online model production validation
    and experimentation.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型验证和 A/B 测试**：在在线验证和实验过程中，需要验证模型性能并收集用户行为指标。这样我们可以轻松回滚或重新部署特定版本的模型。模型注册表对大规模在线模型生产验证和实验至关重要。'
- en: '**Monitoring and feedback loops**: Model drifting and degradation over time
    is a real challenge. The visibility of model performance in production needs to
    be continuously monitored. Feedback data can be used to decide whether a model
    needs to be retrained.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控和反馈回路**：模型漂移和性能退化是一个现实的挑战。需要持续监控生产环境中模型的性能。反馈数据可用于决定是否需要重新训练模型。'
- en: In summary, DL model challenges in the full life cycle are unique. It is also
    worth pointing out a common framework that can assist the model development and
    online production back-and-forth is of great importance, as we don't want to use
    different tools just because the execution environment is different. MLflow provides
    this unified framework to bridge such gaps.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，深度学习模型在整个生命周期中的挑战是独特的。同样值得指出的是，一个能够帮助模型开发与在线生产之间反复切换的通用框架至关重要，因为我们不希望仅仅因为执行环境不同就使用不同的工具。MLflow
    提供了这个统一的框架来弥合这些差距。
- en: Understanding DL code challenges
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解深度学习代码的挑战
- en: 'In this section, we will discuss DL code challenges. Let''s look at how these
    code challenges are manifested in each of the stages described in *Figure 1.3*.
    In this section, and within the context of DL development, code refers to the
    source code that''s written in certain programming languages such as Python for
    data processing and implementation, while a model refers to the model logic and
    architecture in its serialized format (for example, pickle, TorchScript, or ONNX):'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论深度学习代码的挑战。让我们看看这些代码挑战是如何在*图 1.3*所描述的各个阶段中表现出来的。在本节中，在深度学习开发的背景下，代码指的是用某些编程语言（如
    Python）编写的数据处理和实现的源代码，而模型指的是以序列化格式（例如 pickle、TorchScript 或 ONNX）表示的模型逻辑和架构：
- en: '**Data collection/cleaning/annotation**: While data is the central piece in
    this stage, the code that does the query, **extraction/transformation/loading**
    (**ETL**), and data cleaning and augmentation is of critical importance. We cannot
    decouple the development of the model from the data pipelines that provide the
    data feeds to the model. Therefore, data pipelines that implement ETL need to
    be treated as one of the integrated steps in both offline experimentation and
    online production. A common mistake is that we use different data ETL and cleaning
    pipelines in offline experimentation, and then implement different data ETL/cleaning
    pipelines in online production, which could cause different model behaviors. We
    need to version and serialize the data pipeline as part of the entire model pipeline.
    MLflow provides several ways to allow us to implement such multistep pipelines.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据收集/清洗/标注**：尽管数据是这一阶段的核心，但执行查询、**提取/转换/加载**（**ETL**）以及数据清洗和增强的代码也至关重要。我们无法将模型的开发与为模型提供数据流的数据管道分离开来。因此，实施ETL的数据管道需要作为离线实验和在线生产中的集成步骤之一来对待。一个常见的错误是，我们在离线实验中使用不同的数据ETL和清洗管道，然后在在线生产中实现不同的数据ETL/清洗管道，这可能会导致模型行为的不同。我们需要为数据管道进行版本控制并将其序列化，作为整个模型管道的一部分。MLflow提供了几种方法来帮助我们实现这种多步骤管道。'
- en: '**Model development**: During offline experiments, in addition to different
    versions of data pipeline code, we might also have different versions of notebooks
    or use different versions of DL library code. The usage of notebooks is particularly
    unique in ML/DL life cycles. Tracking which model results are produced by which
    notebook/model pipeline/data pipeline needs to be done for each run. MLflow does
    that with automatic code version tracking and dependencies. In addition, code
    reproducibility in different running environments is unique to DL models, as DL
    models usually require hardware accelerators such as GPUs or TPUs. The flexibility
    of running either locally, or remotely, on a CPU or GPU environment is of great
    importance. MLflow provides a lightweight approach in which to organize the ML
    projects so that code can be written once and run everywhere.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型开发**：在离线实验中，除了不同版本的数据管道代码外，我们还可能有不同版本的笔记本，或者使用不同版本的深度学习库代码。在机器学习/深度学习的生命周期中，笔记本的使用尤其独特。需要对每次运行跟踪哪个模型结果是由哪个笔记本/模型管道/数据管道产生的。MLflow通过自动代码版本追踪和依赖关系管理来实现这一点。此外，不同运行环境中的代码可复现性对深度学习模型来说也具有独特性，因为深度学习模型通常需要硬件加速器，如GPU或TPU。无论是在本地运行，还是在CPU或GPU环境中远程运行的灵活性都非常重要。MLflow提供了一种轻量级的方法来组织机器学习项目，从而使得代码可以编写一次并在任何地方运行。'
- en: '**Model deployment and serving in production**: While the model is serving
    production traffic, any bugs will need to be traced back to both the model and
    code. Thus, tracking code provenance is critical. It is also critical to track
    all the dependency code library versions for a particular version of the model.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署与生产服务**：当模型服务生产流量时，任何错误都需要追溯到模型和代码。因此，追踪代码来源至关重要。同时，跟踪特定版本模型的所有依赖库版本也同样至关重要。'
- en: '**Model validation and A/B testing**: Online experiments could use multiple
    versions of models using different data feeds. Debugging any experimentation will
    require not only knowing which model is used but also which code is used to produce
    that model.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型验证与A/B测试**：在线实验可能会使用不同版本的模型和不同的数据源。调试任何实验时，不仅需要知道使用了哪个模型，还需要知道哪些代码被用于生成该模型。'
- en: '**Monitoring and feedback loops**: This stage is similar to the previous stage
    in terms of code challenges, where we need to know whether model degradation is
    due to code bugs or model and data drifting. The monitoring pipeline needs to
    collect all the metrics for both data and model performance.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控与反馈循环**：这一阶段与之前的阶段在代码挑战上相似，我们需要知道模型降级是由于代码错误还是模型和数据漂移。监控管道需要收集所有数据和模型性能的指标。'
- en: In summary, DL code challenges are especially unique because DL frameworks are
    still evolving (for example, **TensorFlow**, **PyTorch**, **Keras**, **Hugging
    Face**, and **SparkNLP**). MLflow provides a lightweight framework to overcome
    many common challenges and can interface with many DL frameworks seamlessly.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，深度学习的代码挑战特别独特，因为深度学习框架仍在不断发展（例如，**TensorFlow**、**PyTorch**、**Keras**、**Hugging
    Face**和**SparkNLP**）。MLflow提供了一个轻量级的框架，能够克服许多常见挑战，并能无缝地与多个深度学习框架进行对接。
- en: Understanding DL explainability challenges
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解深度学习可解释性挑战
- en: 'In this section, we will discuss DL explainability challenges at each of the
    stages described in *Figure 1.3*. It is increasingly important to view explainability
    as an integral and necessary mechanism to define, test, debug, validate, and monitor
    models across the entire model life cycle. Embedding explainability early will
    make subsequent model validation and operations easier. Also, to maintain ongoing
    trust in ML/DL models, it is critical to be able to explain and debug ML/DL models
    after they go live in production:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论在*图 1.3*所描述的各个阶段，深度学习可解释性面临的挑战。越来越重要的是将可解释性视为一个 integral 且必要的机制，用于在整个模型生命周期中定义、测试、调试、验证和监控模型。尽早嵌入可解释性将使后续的模型验证和运维变得更加容易。此外，为了维持对机器学习/深度学习模型的持续信任，能够在模型上线后解释和调试模型是至关重要的：
- en: '**Data collection/cleaning/annotation**: As we have gathered, explainability
    is critical for model prediction. The root cause of any model''s trustworthiness
    or bias can be traced back to the data used to train the model. Explainability
    for the data is still an emerging area but is critical. So, what could go wrong
    and become a challenge during the data collection/cleaning/annotation stage? For
    example, let''s suppose we have an ML/DL model, and its prediction outcome is
    about whether a loan applicant will pay back a loan or not. If the data collected
    has certain correlations between age and the loan payback outcome, this will cause
    the model to use age as a predictor. However, a loan decision based on a person''s
    age is against the law and not allowed even if the model works well. So, during
    data collection, it could be that the sampling strategy is not sufficient to represent
    certain subpopulations such as different loan applicants in different age groups.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据收集/清洗/注释**：正如我们所了解的，模型预测的可解释性至关重要。任何模型的可信度或偏见的根源都可以追溯到用于训练模型的数据。数据的可解释性仍然是一个新兴领域，但它至关重要。那么，在数据收集/清洗/注释阶段可能会发生什么问题并成为挑战呢？举个例子，假设我们有一个机器学习/深度学习模型，它的预测结果是关于一个贷款申请人是否会还款。如果收集到的数据中存在年龄和贷款还款结果之间的某些相关性，这将导致模型使用年龄作为预测变量。然而，基于个人年龄做出贷款决定是违法的，即使模型效果很好，这也是不允许的。所以，在数据收集过程中，可能会出现采样策略不足以代表某些子人群的问题，例如不同年龄组的贷款申请人。'
- en: 'A subpopulation could have lots of missing fields and then be dropped during
    data cleaning. This could result in underrepresentation following the data cleaning
    process. Human annotations could favor the privileged group and other possible
    unconscious biases. A metric called **Disparate Impact** could reveal the hidden
    biases in the data, which compares the proportion of individuals that receive
    a positive outcome for two groups: an unprivileged group and a privileged group.
    If the unprivileged group (for example, persons with age > 60) receives a positive
    outcome (for example, loan approval) less than 80% of the proportion of the privileged
    group (persons with age < 60), this is a disparate impact violation based on the
    current common industry standard (a four-fifths rule). Tools such as **Dataiku**
    could help to automate the disparate impact and subpopulation analysis to find
    groups of people who may be treated unfairly or differently because of the data
    used for model training.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 一个子人群可能会有大量缺失字段，之后在数据清洗过程中被剔除。这可能会导致在数据清洗后的代表性不足。人工注释可能会偏向特权群体，并可能存在其他潜在的无意识偏见。一种叫做**差异化影响**的度量指标可以揭示数据中的隐藏偏见，它比较两个群体中获得积极结果的个体比例：一个是弱势群体，另一个是特权群体。如果弱势群体（例如，年龄>60岁的人）获得积极结果（例如，贷款批准）的比例少于特权群体（例如，年龄<60岁的人）比例的80%，这就是根据当前常见行业标准（五分之四规则）违反了差异化影响。像**Dataiku**这样的工具可以帮助自动化差异化影响和子人群分析，找出可能因模型训练使用的数据而受到不公平或不同对待的群体。
- en: '**Model development**: Model explainability during offline experimentation
    is very important to not only help understand why a model behaves a certain way
    but also help with model selection to decide which model to use if we need to
    put it into production. Accuracy might not be the only criteria to select a winning
    model. There are a few DL explainability tools, such as SHAP (please refer to
    *Figure 1.5*). MLflow integration with SHAP provides a way to implement DL explainability:'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型开发**：在离线实验阶段，模型的可解释性非常重要，不仅有助于理解模型为何以某种方式表现，还有助于模型选择，决定如果需要将其投入生产，应使用哪个模型。准确性可能不是选择优胜模型的唯一标准。这里有一些深度学习可解释性工具，例如SHAP（请参阅*图
    1.5*）。MLflow与SHAP的集成提供了一种实现深度学习可解释性的方法：'
- en: '![Figure 1.5 – NLP text SHAP Variable Importance Plot when using a DL model'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.5 – 使用深度学习模型时的NLP文本SHAP变量重要性图'
- en: '](img/B18120_01_005.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_01_005.jpg)'
- en: Figure 1.5 – NLP text SHAP Variable Importance Plot when using a DL model
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 – 使用深度学习模型时的NLP文本SHAP变量重要性图
- en: '*Figure 1.5* shows that this NLP model''s prediction results'' number one feature
    is the word `impressive`, followed by `rent`. Essentially, this breaks the black
    box of the DL model, giving much confidence to the usage of DL models in production.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*图1.5* 显示了这个自然语言处理（NLP）模型预测结果的主要特征，第一个特征是词汇`impressive`，其次是`rent`。从本质上讲，这揭示了深度学习（DL）模型的“黑箱”，这大大增强了我们在生产环境中使用深度学习模型的信心。'
- en: '**Model deployment and serving in production**: During the production stage,
    if the explainability of the model prediction can be readily provided to users,
    then not only will the usability (user-friendliness) of the model be improved,
    but also, we can collect better feedback data as users are more incentivized to
    give more meaningful feedback. A good explainability solution should provide point-level
    decisions for any prediction outcome. This means that we should be able to answer
    why a particular person''s loan is rejected and how this rejection compares to
    other people in a similar or different age group. So, the challenge is to have
    explainability as one of the gated deployment criteria for releasing a new version
    of the model. However, unlike accuracy metrics, it is very difficult to measure
    explainability as scores or thresholds, although certain case-based reasoning
    could be applied and automated. For example, if we have certain hold-out test
    cases where we expect the same or similar explanations regardless of the versions
    of the model, then we could use that as a gated release criterion.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署和生产环境中的服务**：在生产阶段，如果能够轻松向用户提供模型预测的可解释性，不仅可以提高模型的可用性（用户友好性），还可以收集到更好的反馈数据，因为用户更愿意提供更有意义的反馈。一个好的可解释性解决方案应该为任何预测结果提供点级决策。这意味着我们应该能够回答为什么某个人的贷款被拒绝，以及这个拒绝与其他人（无论是相似还是不同的年龄组）相比如何。因此，挑战在于将可解释性作为发布新版本模型的一个必要部署标准。然而，与准确性指标不同，衡量可解释性作为分数或阈值是非常困难的，尽管某些基于案例的推理可以被应用并自动化。例如，如果我们有某些保留的测试用例，无论模型版本如何，我们都期望得到相同或类似的解释，那么我们可以将其作为一个部署标准。'
- en: '**Model validation and A/B testing**: During online experimentation and ongoing
    production model validation, we would need explainability to understand whether
    the model has been applied to the right data or whether the prediction is trustworthy.
    Usually, ML/DL models encode complex and non-linear relationships. During this
    stage, it is often desirable to understand how the model influences the metrics
    of user behavior (for example, a higher conversion rate on a shopping website).
    Influence sensitivity analysis could provide insights regarding whether a certain
    user feature such as a user''s income has a positive or negative impact on the
    outcome. If during this stage, we found, for some reason, that higher incomes
    cause a negative loan approval rate or a lower conversion rate, then this should
    be automatically flagged. However, automated sensitivity analysis during model
    validation and A/B testing is still not widely available and remains a challenging
    problem. A few vendors such as TruEra provide potential solutions to this space.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型验证与A/B测试**：在在线实验和持续的生产模型验证过程中，我们需要可解释性来理解模型是否已应用于正确的数据，或预测是否可信。通常，机器学习（ML）/深度学习（DL）模型编码了复杂的非线性关系。在这一阶段，通常希望了解模型如何影响用户行为的度量指标（例如，购物网站上的更高转化率）。影响敏感性分析可以提供有关某些用户特征（例如用户的收入）对结果是否有正面或负面影响的见解。如果在这一阶段，我们发现由于某些原因，高收入导致贷款批准率下降或转化率降低，那么这一点应该被自动标记。然而，在模型验证和A/B测试过程中，自动化的敏感性分析仍然不广泛可用，且仍然是一个具有挑战性的问题。一些供应商，如TruEra，提供了该领域的潜在解决方案。'
- en: '**Monitoring and feedback loops**: While model performance metrics and data
    characteristics are of importance here, explainability can provide an incentive
    for users to provide valuable feedback and user behavior metrics to identify drivers
    and causes of model degradation if there are any. As we know, ML/DL models are
    prone to overfitting and cannot generalize well beyond their training data. One
    important explainability solution during model production monitoring is to measure
    how feature importance shifts across different data splits (for example, pre-COVID
    versus post-COVID). This can help data scientists to identify where degradation
    in model performance is due to changing data (such as a statistical distribution
    shift) or changing relationships between variables (such as a concept shift).
    A recent example provided by TruEra ([https://truera.com/machine-learning-explainability-is-just-the-beginning/](https://truera.com/machine-learning-explainability-is-just-the-beginning/))
    illustrates that a loan model changes its prediction behavior due to changes in
    people''s annual income and loan purposes before and after the COVID periods.
    This explainability of **Feature Importance Shift** greatly helps to identify
    the root causes of changes in model behavior during the model production monitoring
    stage.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控与反馈循环**：虽然模型性能指标和数据特征在这里非常重要，但可解释性可以为用户提供激励，促使他们提供有价值的反馈和用户行为指标，从而识别模型降级的驱动因素和原因（如果有的话）。正如我们所知，ML/DL
    模型容易过拟合，且难以在训练数据之外做出良好的泛化。在模型生产监控过程中，一个重要的可解释性解决方案是衡量不同数据切分下特征重要性的变化（例如，COVID
    之前与COVID之后）。这有助于数据科学家识别模型性能降级是由于数据变化（如统计分布变化）还是变量之间关系的变化（如概念漂移）。TruEra 提供的一个近期例子（[https://truera.com/machine-learning-explainability-is-just-the-beginning/](https://truera.com/machine-learning-explainability-is-just-the-beginning/)）说明了由于COVID前后人们的年收入和贷款目的的变化，贷款模型改变了其预测行为。这种**特征重要性变化**的可解释性在模型生产监控阶段对于识别模型行为变化的根本原因非常有帮助。'
- en: In summary, DL explainability is a major challenge where ongoing research is
    still needed. However, MLflow's integration with SHAP now provides a ready-to-use
    tool for practical DL applications, which we will cover in our advanced chapter
    later in this book.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，DL 可解释性是一个重大挑战，仍需要持续的研究。然而，MLflow 与 SHAP 的集成现在为实际的 DL 应用提供了一个现成的工具，稍后我们将在本书的进阶章节中进行介绍。
- en: Summary
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this opening chapter, we implemented our first DL model by following the
    pretrain plus fine-tuning core DL development paradigm using PyTorch `lightning-flash`
    for a text sentiment classification model. We learned about the five stages of
    the full life cycle of DL. We defined the concept of MLOps along with the three
    foundation layers and four ML/DL pillars, where MLflow plays critical roles in
    all four pillars (data, model, code, and explainability). Finally, we described
    the challenges in DL data, model, code, and explainability.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章开篇中，我们通过使用 PyTorch `lightning-flash`，遵循预训练加微调的核心深度学习（DL）开发范式，实施了我们的第一个 DL
    模型，目标是进行文本情感分类。我们了解了 DL 的完整生命周期的五个阶段。我们定义了 MLOps 的概念，并介绍了其三个基础层和四个 ML/DL 支柱，其中
    MLflow 在所有四个支柱（数据、模型、代码和可解释性）中都扮演着关键角色。最后，我们描述了 DL 中数据、模型、代码和可解释性方面的挑战。
- en: With the knowledge and first DL model experience gained in this chapter, we
    are now ready to learn about and implement MLflow in our DL model in the following
    chapters. In the next chapter, we will start with the implementation of a DL model
    with MLflow autologging enabled.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中获得的知识和第一个 DL 模型的经验后，我们现在已经准备好在接下来的章节中学习并实施 MLflow。在下一章中，我们将从启用 MLflow 自动记录功能的
    DL 模型实现开始。
- en: Further reading
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To further your knowledge, please consult the following resources and documentation:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步提升您的知识，敬请查阅以下资源和文档：
- en: '*On the Opportunities and Risks of Foundation Models* (Stanford University):
    [https://arxiv.org/abs/2108.07258](https://arxiv.org/abs/2108.07258)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*关于基础模型的机遇与风险*（斯坦福大学）：[https://arxiv.org/abs/2108.07258](https://arxiv.org/abs/2108.07258)'
- en: '*MLOps: not as Boring as it Sounds*: [https://itnext.io/mlops-not-as-boring-as-it-sounds-eaebe73e3533](https://itnext.io/mlops-not-as-boring-as-it-sounds-eaebe73e3533)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MLOps: 不像它听起来那么无聊*：[https://itnext.io/mlops-not-as-boring-as-it-sounds-eaebe73e3533](https://itnext.io/mlops-not-as-boring-as-it-sounds-eaebe73e3533)'
- en: '*AI is Driving Software 2.0… with Minimal Human Intervention*: [https://www.datasciencecentral.com/profiles/blogs/ai-is-driving-software-2-0-with-minimal-human-intervention](https://www.datasciencecentral.com/profiles/blogs/ai-is-driving-software-2-0-with-minimal-human-intervention)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*人工智能正在推动软件2.0……并且几乎无需人工干预*： [https://www.datasciencecentral.com/profiles/blogs/ai-is-driving-software-2-0-with-minimal-human-intervention](https://www.datasciencecentral.com/profiles/blogs/ai-is-driving-software-2-0-with-minimal-human-intervention)'
- en: '*MLOps: Continuous delivery and automation pipelines in machine learning* (Google):
    [https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MLOps：机器学习中的持续交付与自动化管道*（Google）： [https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning)'
- en: '*Deep Learning Development Cycle* (Salesforce): [https://metamind.readme.io/docs/deep-learning-dev-cycle](https://metamind.readme.io/docs/deep-learning-dev-cycle)'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*深度学习开发周期*（Salesforce）： [https://metamind.readme.io/docs/deep-learning-dev-cycle](https://metamind.readme.io/docs/deep-learning-dev-cycle)'
- en: '*MLOps – The Missing Piece In The Enterprise AI Puzzle*: [https://www.forbes.com/sites/janakirammsv/2021/01/05/mlopsthe-missing-piece-in-the-enterprise-ai-puzzle/?sh=3d5c89dd24ad](https://www.forbes.com/sites/janakirammsv/2021/01/05/mlopsthe-missing-piece-in-the-enterprise-ai-puzzle/?sh=3d5c89dd24ad)'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MLOps — 企业AI难题中的缺失环节*： [https://www.forbes.com/sites/janakirammsv/2021/01/05/mlopsthe-missing-piece-in-the-enterprise-ai-puzzle/?sh=3d5c89dd24ad](https://www.forbes.com/sites/janakirammsv/2021/01/05/mlopsthe-missing-piece-in-the-enterprise-ai-puzzle/?sh=3d5c89dd24ad)'
- en: '*MLOps: What It Is, Why It Matters, and How to Implement It*: [https://neptune.ai/blog/mlops](https://neptune.ai/blog/mlops)'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MLOps：它是什么，为什么重要，以及如何实施*： [https://neptune.ai/blog/mlops](https://neptune.ai/blog/mlops)'
- en: '*Explainable Deep Learning: A Field Guide for the Uninitiated*: [https://arxiv.org/abs/2004.14545](https://arxiv.org/abs/2004.14545)'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可解释深度学习：初学者指南*： [https://arxiv.org/abs/2004.14545](https://arxiv.org/abs/2004.14545)'
- en: '*Machine learning explainability is just the beginning*: [https://truera.com/machine-learning-explainability-is-just-the-beginning/](https://truera.com/machine-learning-explainability-is-just-the-beginning/)'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习的可解释性仅仅是开始*： [https://truera.com/machine-learning-explainability-is-just-the-beginning/](https://truera.com/machine-learning-explainability-is-just-the-beginning/)'
- en: '*AI Fairness — Explanation of Disparate Impact Remover*: [https://towardsdatascience.com/ai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1](https://towardsdatascience.com/ai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*人工智能公平性 — 不公平影响消除器的解释*： [https://towardsdatascience.com/ai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1](https://towardsdatascience.com/ai-fairness-explanation-of-disparate-impact-remover-ce0da59451f1)'
- en: '*Datasheets for Datasets*: [https://arxiv.org/pdf/1803.09010.pdf](https://arxiv.org/pdf/1803.09010.pdf)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据集的数据表*： [https://arxiv.org/pdf/1803.09010.pdf](https://arxiv.org/pdf/1803.09010.pdf)'
