- en: Appendix
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录
- en: 1\. Introduction to Machine Learning with Keras
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 使用 Keras 进行机器学习简介
- en: 'Activity 1.01: Adding Regularization to the Model'
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 1.01：向模型添加正则化
- en: In this activity, we will utilize the same logistic regression model from the
    scikit-learn package. This time, however, we will add regularization to the model
    and search for the optimum regularization parameter - a process often called `hyperparameter
    tuning`. After training the models, we will test the predictions and compare the
    model evaluation metrics to the ones that were produced by the baseline model
    and the model without regularization.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将使用来自 scikit-learn 包的相同逻辑回归模型。然而，这一次，我们将向模型中添加正则化，并搜索最佳正则化参数——这个过程通常称为
    `超参数调优`。在训练模型后，我们将测试预测结果，并将模型评估指标与基准模型和未加正则化的模型的评估指标进行比较。
- en: 'Load the feature data from *Exercise 1.03*, *Appropriate Representation of
    the Data*, and the target data from *Exercise 1.02*, *Cleaning the Data*:'
  id: totrans-4
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 *练习 1.03*，*数据的适当表示* 加载特征数据，从 *练习 1.02*，*数据清理* 加载目标数据：
- en: '[PRE0]'
  id: totrans-5
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Create a `test` and `train` dataset. Train the data using the training dataset.
    This time, however, use part of the `training` dataset for validation in order
    to choose the most appropriate hyperparameter.
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 `test` 和 `train` 数据集。使用训练数据集训练数据。然而，这一次，请使用部分 `training` 数据集进行验证，以选择最合适的超参数。
- en: 'Once again, we will use `test_size = 0.2`, which means that `20%` of the data
    will be reserved for testing. The size of our validation set will be determined
    by how many validation folds we have. If we do `10-fold cross-validation`, this
    equates to reserving `10%` of the `training` dataset to validate our model on.
    Each fold will use a different `10%` of the `training` dataset, and the average
    error across all folds is used to compare models with different hyperparameters.
    Assign a random value to the `random_state` variable:'
  id: totrans-7
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 再次使用 `test_size = 0.2`，这意味着将 `20%` 的数据保留用于测试。我们的验证集的大小将由验证折数决定。如果我们进行 `10折交叉验证`，则相当于将
    `10%` 的 `training` 数据集保留用于验证模型。每一折将使用不同的 `10%` 训练数据集，而所有折的平均误差将用于比较具有不同超参数的模型。为
    `random_state` 变量分配一个随机值：
- en: '[PRE1]'
  id: totrans-8
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Check the dimensions of the DataFrames:'
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查数据框的维度：
- en: '[PRE2]'
  id: totrans-10
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The preceding code produces the following output:'
  id: totrans-11
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码产生以下输出：
- en: '[PRE3]'
  id: totrans-12
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, instantiate the models. Try two types of regularization parameters, `l1`
    and `l2`, with 10-fold cross-validation. Iterate our regularization parameter
    from 1x10-2 to 1x106 equally in the logarithmic space to observe how the parameters
    affect the results:'
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，实例化模型。尝试两种正则化参数，`l1` 和 `l2`，并使用 10 倍交叉验证。将我们的正则化参数从 1x10-2 到 1x106 在对数空间中均匀遍历，以观察这些参数如何影响结果：
- en: '[PRE4]'
  id: totrans-14
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: For a logistic regression model with the `l1` regularization parameter, only
    the `liblinear` solver can be used.
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于具有 `l1` 正则化参数的逻辑回归模型，只能使用 `liblinear` 求解器。
- en: 'Next, fit the models to the training data:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将模型拟合到训练数据：
- en: '[PRE5]'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图显示了上述代码的输出：
- en: '![Figure 1.37: Output of the fit command indicating all of the model training
    parameters'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.37：fit 命令的输出，显示所有模型训练参数](img/B15777_01_37.jpg)'
- en: '](img/B15777_01_37.jpg)'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_37.jpg)'
- en: 'Figure 1.37: Output of the fit command indicating all of the model training
    parameters'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.37：fit 命令的输出，显示所有模型训练参数
- en: 'Here, we can see what the value of the regularization parameter was for the
    two different models. The regularization parameter is chosen according to which
    produced a model with the lowest error:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到两种不同模型的正则化参数值。正则化参数是根据哪个模型产生了最低误差来选择的：
- en: '[PRE6]'
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The preceding code produces the following output:'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码产生以下输出：
- en: '[PRE7]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The `C_` attribute is only available once the model has been trained because
    it is set once the best parameter from the cross-validation process has been determined.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`C_` 属性只有在模型训练完成后才能使用，因为它是在交叉验证过程确定最佳参数后设置的。'
- en: 'To evaluate the performance of the models, make predictions on the `test` set,
    which we''ll compare against the `true` values:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了评估模型的性能，请对 `test` 集合进行预测，并将其与 `true` 值进行比较：
- en: '[PRE8]'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To compare these models, calculate the evaluation metrics. First, look at the
    accuracy of the model:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了比较这些模型，计算评估指标。首先，查看模型的准确度：
- en: '[PRE9]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The preceding code produces the following output:'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码产生以下输出：
- en: '[PRE10]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Also, look at the other evaluation metrics:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另外，还请查看其他评估指标：
- en: '[PRE11]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The preceding code produces the following output:'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码会产生以下输出：
- en: '[PRE12]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Observe the values of the coefficients once the model has been trained:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 观察模型训练完成后系数的值：
- en: '[PRE13]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The `coef_` attribute is only available once the model has been trained because
    it is set once the best parameter from the cross-validation process has been determined.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`coef_`属性仅在模型训练完成后可用，因为它是在交叉验证过程中确定最佳参数后设置的。'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了前面代码的输出：
- en: '![Figure 1.38: The feature column names and the value of their respective coefficients'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.38：特征列名称及其相应系数的值'
- en: for the model with l1 regularization
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于具有l1正则化的模型
- en: '](img/B15777_01_38.jpg)'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_38.jpg)'
- en: 'Figure 1.38: The feature column names and the value of their respective coefficients
    for the model with l1 regularization'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1.38：具有l1正则化的模型的特征列名称及其相应系数的值
- en: 'Do the same for the model with an `l2` regularization parameter type:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对具有`l2`正则化参数类型的模型执行相同操作：
- en: '[PRE14]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了前面代码的输出：
- en: '![Figure 1.39: The feature column names and the value of their respective coefficients'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.39：特征列名称及其相应系数的值'
- en: for the model with l2 regularization
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于具有l2正则化的模型
- en: '](img/B15777_01_39.jpg)'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_39.jpg)'
- en: 'Figure 1.39: The feature column names and the value of their respective coefficients
    for the model with l2 regularization'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.39：具有l2正则化的模型的特征列名称及其相应系数的值
- en: Note
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2VIoe5M](https://packt.live/2VIoe5M).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该特定部分的源代码，请参考[https://packt.live/2VIoe5M](https://packt.live/2VIoe5M)。
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 本节目前没有在线交互式示例，需要在本地运行。
- en: 2\. Machine Learning versus Deep Learning
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 机器学习与深度学习
- en: 'Activity 2.01: Creating a Logistic Regression Model Using Keras'
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动2.01：使用Keras创建逻辑回归模型
- en: In this activity, we are going to create a basic model using the Keras library.
    The model that we will build will classify users of a website into those that
    will purchase a product from a website and those that will not. To do this, we
    will utilize the same online shopping purchasing intention dataset that we did
    previously and attempt to predict the same variables that we did in *Chapter 1*,
    *Introduction to Machine Learning with Keras*.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将使用Keras库创建一个基本模型。我们将构建的模型将把网站用户分为两类：一类是会从网站购买产品的用户，另一类则不会。为了实现这一目标，我们将使用之前相同的在线购物购买意图数据集，并尝试预测我们在*第一章*中预测的相同变量，即*使用Keras进行机器学习入门*。
- en: 'Perform the following steps to complete this activity:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤完成此活动：
- en: Open a Jupyter notebook from the start menu to implement this activity. Load
    in the online shopping purchasing intention datasets, which you can download from
    the GitHub repository. We will use the pandas library for data loading, so import
    the `pandas` library. Ensure you have saved the csv files to an appropriate data
    folder for this chapter first. Alternatively, you can change the path to the files
    that you use in your code.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开开始菜单中的Jupyter笔记本以实现此活动。加载在线购物购买意图数据集，你可以从GitHub仓库下载。我们将使用`pandas`库进行数据加载，因此请先导入`pandas`库。确保你已经将csv文件保存到本章适当的数据文件夹中，或者可以更改代码中使用的文件路径。
- en: '[PRE15]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'For the purposes of this activity, we will not perform any further preprocessing.
    As we did in the previous chapter, we will split the dataset into training and
    testing and leave the testing until the very end when we evaluate our models.
    We will reserve `20%` of our data for testing by setting the `test_size=0.2` parameter,
    and we will create a `random_state` parameter so that we can recreate the results:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于本次活动，我们不进行进一步的预处理。和上一章一样，我们将数据集拆分为训练集和测试集，并将测试推迟到最后，在评估模型时进行。我们将保留`20%`的数据用于测试，通过设置`test_size=0.2`参数，并创建一个`random_state`参数，以便重现结果：
- en: '[PRE16]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Set a seed in `numpy` and `tensorflow` for reproducibility. Begin creating
    the model by initializing a model of the `Sequential` class:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`numpy`和`tensorflow`中设置随机种子以保证可复现性。通过初始化`Sequential`类的模型开始创建模型：
- en: '[PRE17]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'To add a fully connected layer to the model, add a layer of the `Dense` class.
    Here, we include the number of nodes in the layer. In our case, this will be one
    since we are performing binary classification and our desired output is `zero`
    or `one`. Also, specify the input dimensions, which is only done on the first
    layer of the model. It is there to indicate the format of the input data. Pass
    the number of features:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要向模型中添加一个全连接层，请添加一个`Dense`类的层。在这里，我们需要包括该层中的节点数。在我们的例子中，由于我们正在执行二分类，且期望输出为`zero`或`one`，所以该值将为1。此外，还需要指定输入维度，这只需要在模型的第一层中指定。它的作用是表示输入数据的格式。传入特征的数量：
- en: '[PRE18]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Add a sigmoid activation function to the output of the previous layer to replicate
    the `logistic regression` algorithm:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在前一层的输出上添加一个sigmoid激活函数，以复制`logistic regression`算法：
- en: '[PRE19]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Once we have all the model components in the correct order, we must compile
    the model so that all the learning processes are configured. Use the `adam` optimizer,
    a `binary_crossentropy` for the loss, and track the accuracy of the model by passing
    the parameter into the `metrics` argument:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们将所有模型组件按正确顺序排列，我们必须编译模型，以便所有的学习过程都能被配置。使用`adam`优化器，`binary_crossentropy`作为损失函数，并通过将参数传入`metrics`参数来跟踪模型的准确率：
- en: '[PRE20]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Print the model summary to verify the model is as we expect it to be:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印模型摘要，以验证模型是否符合我们的预期：
- en: '[PRE21]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图展示了前面代码的输出：
- en: '![Figure 2.19: A summary of the model'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图2.19：模型摘要'
- en: '](img/B15777_02_19.jpg)'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_02_19.jpg)'
- en: 'Figure 2.19: A summary of the model'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.19：模型摘要
- en: 'Next, fit the model using the `fit` method of the `model` class. Provide the
    training data, as well as the number of epochs and how much data to use for validation
    after each epoch:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用`model`类的`fit`方法拟合模型。提供训练数据，以及训练周期数和每个周期后用于验证的数据量：
- en: '[PRE22]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图展示了前面代码的输出：
- en: '![Figure 2.20: Using the fit method on the model'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图2.20：在模型上使用fit方法'
- en: '](img/B15777_02_20.jpg)'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_02_20.jpg)'
- en: 'Figure 2.20: Using the fit method on the model'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.20：在模型上使用fit方法
- en: 'The values for the loss and accuracy have been stored within the `history`
    variable. Plot the values for each using the loss and accuracy we tracked after
    each epoch:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 损失和准确率的值已存储在`history`变量中。使用每个训练周期后我们跟踪的损失和准确率，绘制每个值的图表：
- en: '[PRE23]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following plots show the output of the preceding code:'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图表展示了前面代码的输出：
- en: '![Figure 2.21: The loss and accuracy while fitting the model'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图2.21：拟合模型时的损失和准确率'
- en: '](img/B15777_02_21.jpg)'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_02_21.jpg)'
- en: 'Figure 2.21: The loss and accuracy while fitting the model'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图2.21：拟合模型时的损失和准确率
- en: 'Finally, evaluate the model on the test data we held out from the beginning,
    which will give an objective evaluation of the performance of the model:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，在我们从一开始就保留的测试数据上评估模型，这将为模型的性能提供客观评价：
- en: '[PRE24]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output of the preceding code can be found below. Here, the model predicts
    the purchasing intention of users in the test dataset and evaluates the performance
    by comparing it to the real values in `y_test`. Evaluating the model on the test
    dataset produces loss and accuracy values that we can print out:'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面代码的输出如下所示。在这里，模型预测了测试数据集中用户的购买意图，并通过将其与`y_test`中的真实值进行比较来评估性能。在测试数据集上评估模型将产生损失和准确率值，我们可以打印出来：
- en: '[PRE25]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Note
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注
- en: To access the source code for this specific section, please refer to
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考
- en: '[https://packt.live/3dVTQLe](https://packt.live/3dVTQLe).'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://packt.live/3dVTQLe](https://packt.live/3dVTQLe)。'
- en: You can also run this example online at [https://packt.live/2ZxEhV4](https://packt.live/2ZxEhV4).
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你还可以在[https://packt.live/2ZxEhV4](https://packt.live/2ZxEhV4)在线运行此示例。
- en: 3\. Deep Learning with Keras
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 使用Keras进行深度学习
- en: 'Activity 3.01: Building a Single-Layer Neural Network for Performing Binary
    Classification'
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动3.01：构建一个单层神经网络进行二分类
- en: 'In this activity, we will compare the results of a logistic regression model
    and single-layer neural networks of different node sizes and different activation
    functions. The dataset we will use represents the normalized test results of aircraft
    propeller inspections, while the class represents whether they passed or failed
    a manual visual inspection. We will create models to predict the results of the
    manual inspection when given the automated test results. Follow these steps to
    complete this activity:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，我们将比较逻辑回归模型和不同节点大小以及不同激活函数的单层神经网络的结果。我们将使用的数据集表示飞机螺旋桨检查的标准化测试结果，而类别表示它们是否通过了人工视觉检查。我们将创建模型来预测给定自动化测试结果时的人工检查结果。请按照以下步骤完成此活动：
- en: 'Load all the required packages:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载所有必要的包：
- en: '[PRE26]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Set up a `seed`:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置一个`seed`：
- en: '[PRE27]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Load the simulated dataset and print the size of `X` and `Y` and the number
    of examples:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载模拟数据集并打印`X`和`Y`的大小以及示例的数量：
- en: '[PRE28]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '**Expected output**:'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**预期输出**：'
- en: '[PRE29]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Plot the dataset. The x and y coordinates of each point will be the two input
    features. The color of each record represents the `pass`/`fail` result:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制数据集。每个点的 x 和 y 坐标将是两个输入特征。每条记录的颜色代表`通过`/`失败`结果：
- en: '[PRE30]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The following image shows the output of the preceding code:'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图像显示了前述代码的输出：
- en: '![Figure 3.19: Simulated training data points'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.19：模拟训练数据点'
- en: '](img/B15777_03_19.jpg)'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_19.jpg)'
- en: 'Figure 3.19: Simulated training data points'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.19：模拟训练数据点
- en: 'Build the `logistic regression` model, which will be a one-node sequential
    model with no hidden layers and a `sigmoid activation` function:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建`逻辑回归`模型，这是一个没有隐藏层的单节点顺序模型，使用`sigmoid 激活`函数：
- en: '[PRE31]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Fit the model to the training data:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据：
- en: '[PRE32]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '`100` epochs = `0.3537`:'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`100`轮 = `0.3537`：'
- en: '![Figure 3.20: The loss details of the last 5 epochs out of 100'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.20：100轮中的最后5轮的损失详情'
- en: '](img/B15777_03_20.jpg)'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_20.jpg)'
- en: 'Figure 3.20: The loss details of the last 5 epochs out of 100'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.20：100轮中的最后5轮的损失详情
- en: 'Plot the decision boundary on the training data:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在训练数据上绘制决策边界：
- en: '[PRE33]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The following image shows the output of the preceding code:'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图像显示了前述代码的输出：
- en: '![Figure 3.21: The decision boundary of the logistic regression model'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.21：逻辑回归模型的决策边界'
- en: '](img/B15777_03_21.jpg)'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_21.jpg)'
- en: 'Figure 3.21: The decision boundary of the logistic regression model'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.21：逻辑回归模型的决策边界
- en: The linear decision boundary of the logistic regression model is obviously unable
    to capture the circular decision boundary between the two classes and predicts
    all the results as a passed result.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 逻辑回归模型的线性决策边界显然无法捕捉到两类之间的圆形决策边界，并将所有结果预测为通过结果。
- en: 'Create a neural network with one hidden layer with three nodes and a `relu
    activation function` and an output layer with one node and a `sigmoid activation
    function`. Finally, compile the model:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个包含三个节点的单隐藏层神经网络，并使用`relu 激活函数`，输出层为一个节点，并使用`sigmoid 激活函数`。最后，编译模型：
- en: '[PRE34]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Fit the model to the training data:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据：
- en: '[PRE35]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '`200` epochs = `0.0260`:'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`200`轮 = `0.0260`：'
- en: '![Figure 3.22: The loss details of the last 5 epochs out of 200'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.22：200轮中的最后5轮的损失详情'
- en: '](img/B15777_03_22.jpg)'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_22.jpg)'
- en: 'Figure 3.22: The loss details of the last 5 epochs out of 200'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.22：200轮中的最后5轮的损失详情
- en: 'Plot the decision boundary that was created:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制所创建的决策边界：
- en: '[PRE36]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The following image shows the output of the preceding code:'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图像显示了前述代码的输出：
- en: '![Figure 3.23: The decision boundary for the neural network with a hidden layer'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.23：带有隐藏层的神经网络的决策边界'
- en: size of 3 and a ReLU activation function
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 3个节点的大小和ReLU激活函数
- en: '](img/B15777_03_23.jpg)'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_23.jpg)'
- en: 'Figure 3.23: The decision boundary for the neural network with a hidden layer
    size of 3 and a ReLU activation function'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.23：带有3个节点的隐藏层和ReLU激活函数的神经网络决策边界
- en: Having three processing units instead of one dramatically improved the capability
    of the model in capturing the non-linear boundary between the two classes. Notice
    that the loss value decreased drastically in comparison to the previous step.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用三个处理单元代替一个显著提高了模型捕捉两类之间非线性边界的能力。注意，与上一步相比，损失值显著下降。
- en: 'Create a neural network with one hidden layer with six nodes and a `relu activation
    function` and an output layer with one node and a `sigmoid activation function`.
    Finally, compile the model:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个神经网络，包含一个具有六个节点的隐藏层和一个`relu 激活函数`，输出层有一个节点，并使用`sigmoid 激活函数`。最后，编译模型：
- en: '[PRE37]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Fit the model to the training data:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据：
- en: '[PRE38]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '`400` epochs = `0.0231`:'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`400` 轮次 = `0.0231`：'
- en: '![Figure 3.24: The loss details of the last 5 epochs out of 400'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.24：最后 5 个 epoch（共 400 个）的损失详情'
- en: '](img/B15777_03_24.jpg)'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_24.jpg)'
- en: 'Figure 3.24: The loss details of the last 5 epochs out of 400'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.24：最后 5 个 epoch（共 400 个）的损失详情
- en: 'Plot the decision boundary:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制决策边界：
- en: '[PRE39]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The following image shows the output of the preceding code:'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图像显示了前述代码的输出：
- en: '![Figure 3.25: The decision boundary for the neural network with a hidden layer'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.25：具有隐藏层的神经网络的决策边界'
- en: size of 6 and the ReLU activation function
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 隐藏层大小为 6 且使用 ReLU 激活函数
- en: '](img/B15777_03_25.jpg)'
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_25.jpg)'
- en: 'Figure 3.25: The decision boundary for the neural network with a hidden layer
    size of 6 and the ReLU activation function'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.25：具有隐藏层大小为 6 且使用 ReLU 激活函数的神经网络的决策边界
- en: By doubling the number of units in the hidden layer, the decision boundary of
    the model gets closer to a true circular shape, and the loss value is decreased
    even more in comparison to the previous step.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过将隐藏层中的单元数加倍，模型的决策边界更加接近真实的圆形，而且与前一步相比，损失值进一步减少。
- en: 'Create a neural network with one hidden layer with three nodes and a `tanh
    activation function` and an output layer with one node and a `sigmoid activation
    function`. Finally, compile the model:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个神经网络，包含一个具有三个节点的隐藏层和一个`tanh 激活函数`，输出层有一个节点，并使用`sigmoid 激活函数`。最后，编译模型：
- en: '[PRE40]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Fit the model to the training data:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据：
- en: '[PRE41]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '`200` epochs = `0.0426`:'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`200` 轮次 = `0.0426`：'
- en: '![Figure 3.26: The loss details of the last 5 epochs out of 200'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.26：最后 5 个 epoch（共 200 个）的损失详情'
- en: '](img/B15777_03_26.jpg)'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_26.jpg)'
- en: 'Figure 3.26: The loss details of the last 5 epochs out of 200'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.26：最后 5 个 epoch（共 200 个）的损失详情
- en: 'Plot the decision boundary:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制决策边界：
- en: '[PRE42]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The following image shows the output of the preceding code:'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图像显示了前述代码的输出：
- en: '![Figure 3.27: The decision boundary for the neural network with a hidden layer'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.27：具有隐藏层的神经网络的决策边界'
- en: size of 3 and the tanh activation function
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 隐藏层大小为 3 且使用 tanh 激活函数
- en: '](img/B15777_03_27.jpg)'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_27.jpg)'
- en: 'Figure 3.27: The decision boundary for the neural network with a hidden layer
    size of 3 and the tanh activation function'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.27：具有隐藏层大小为 3 且使用 tanh 激活函数的神经网络的决策边界
- en: Using the `tanh` activation function has eliminated the sharp edges in the decision
    boundary. In other words, it has made the decision boundary smoother. However,
    the model is not performing better since we can see an increase in the loss value.
    We achieved similar loss and accuracy scores when we evaluated on the test dataset,
    despite mentioning previously that the learning parameters for `tanh` are slower
    than they are for `relu`.
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用`tanh`激活函数消除了决策边界中的尖锐边缘。换句话说，它使得决策边界变得更加平滑。然而，由于我们看到损失值的增加，模型并没有表现得更好。尽管之前提到过`tanh`的学习速度比`relu`慢，但在对测试数据集进行评估时，我们得到了相似的损失和准确度评分。
- en: 'Create a neural network with one hidden layer with six nodes and a `tanh activation
    function` and an output layer with one node and a `sigmoid activation function`.
    Finally, compile the model:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个神经网络，包含一个具有六个节点的隐藏层和一个`tanh 激活函数`，输出层有一个节点，并使用`sigmoid 激活函数`。最后，编译模型：
- en: '[PRE43]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Fit the model to the training data:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据：
- en: '[PRE44]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '`400` epochs = `0.0215`:'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`400` 轮次 = `0.0215`：'
- en: '![Figure 3.28: The loss details of the last 5 epochs out of 400'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.28：最后 5 个 epoch（共 400 个）的损失详情'
- en: '](img/B15777_03_28.jpg)'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_28.jpg)'
- en: 'Figure 3.28: The loss details of the last 5 epochs out of 400'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.28：最后 5 个 epoch（共 400 个）的损失详情
- en: 'Plot the decision boundary:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制决策边界：
- en: '[PRE45]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'The following image shows the output of the preceding code:'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图像显示了前述代码的输出：
- en: '![Figure 3.29: The decision boundary for the neural network with a hidden layer
    size'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.29：具有隐藏层大小为 6 且使用 ReLU 激活函数的神经网络的决策边界'
- en: of 6 and the tanh activation function
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 具有 6 个节点和 tanh 激活函数
- en: '](img/B15777_03_29.jpg)'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_29.jpg)'
- en: 'Figure 3.29: The decision boundary for the neural network with a hidden layer
    size of 6 and the tanh activation function'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.29：具有隐藏层大小为 6 且使用 tanh 激活函数的神经网络的决策边界
- en: Again, using the `tanh` activation function instead of `relu` and adding more
    nodes to our hidden layer has smoothed the curves on the decision boundary more,
    fitting the training data better according to the accuracy of the training data.
    We should be careful not to add too many nodes to the hidden layer as we may begin
    to overfit the data. This can be observed by evaluating the test set, where there
    is a slight decrease in the accuracy of the neural network with six nodes compared
    to a neural network with three.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 再次使用`tanh`激活函数代替`relu`，并将更多的节点添加到隐藏层中，使决策边界的曲线更加平滑，训练数据的拟合效果更好，依据训练数据的准确性来判断。我们应当小心，不要向隐藏层中添加过多的节点，否则可能会导致过拟合数据。这可以通过评估测试集来观察，在拥有六个节点的神经网络上，相比于具有三个节点的神经网络，准确度有所下降。
- en: Note
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 注：
- en: To access the source code for this specific section, please refer to [https://packt.live/3iv0wn1](https://packt.live/3iv0wn1).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/3iv0wn1](https://packt.live/3iv0wn1)。
- en: You can also run this example online at [https://packt.live/2BqumZt](https://packt.live/2BqumZt).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在[https://packt.live/2BqumZt](https://packt.live/2BqumZt)上在线运行此示例。
- en: 'Activity 3.02: Advanced Fibrosis Diagnosis with Neural Networks'
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 3.02：使用神经网络进行高级纤维化诊断
- en: 'In this activity, you are going to use a real dataset to predict whether a
    patient has advanced fibrosis based on measurements such as age, gender, and BMI.
    The dataset consists of information for 1,385 patients who underwent treatment
    dosages for hepatitis C. For each patient, `28` different attributes are available,
    as well as a class label, which can only take two values: `1`, indicating advanced
    fibrosis, and `0`, indicating no indication of advanced fibrosis. This is a binary/two-class
    classification problem with an input dimension equal to 28\.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，您将使用一个真实数据集来预测患者是否存在高级纤维化，基于的测量指标包括年龄、性别和BMI。该数据集包含1,385名接受过丙型肝炎治疗剂量的患者信息。每个患者都有`28`个不同的属性，并且有一个类别标签，该标签只能取两个值：`1`表示高级纤维化，`0`表示没有高级纤维化迹象。这是一个二分类问题，输入维度为28。
- en: 'In this activity, you will implement different deep neural network architectures
    to perform this classification, plot the trends in training error rates and test
    error rates, and determine how many epochs the final classifier needs to be trained
    for. Follow these steps to complete this activity:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，您将实现不同的深度神经网络架构来执行此分类任务，绘制训练误差率和测试误差率的趋势，并确定最终分类器需要训练多少个epoch。请按照以下步骤完成此活动：
- en: 'Import all the necessary libraries and load the dataset using the pandas `read_csv`
    function:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必要的库，并使用pandas的`read_csv`函数加载数据集：
- en: '[PRE46]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Print the number of `records` and `features` in the `feature` dataset and the
    number of unique classes in the `target` dataset:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印`records`和`features`在`feature`数据集中的数量，以及`target`数据集中唯一类别的数量：
- en: '[PRE47]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '**Expected output**:'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**预期输出**：'
- en: '[PRE48]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Normalize the data and scale it. Following this, split the dataset into the
    `training` and `test` sets:'
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对数据进行归一化并进行缩放。然后，将数据集拆分为`训练`集和`测试`集：
- en: '[PRE49]'
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '**Expected output**:'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**预期输出**：'
- en: '[PRE50]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Implement a deep neural network with one hidden layer of size `3` and a `tanh
    activation function`, an output layer with one node, and a `sigmoid activation
    function`. Finally, compile the model and print out a summary of the model:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个具有一个隐藏层，隐藏层大小为`3`，激活函数为`tanh`，输出层为一个节点，并使用`sigmoid`激活函数的深度神经网络。最后，编译模型并打印出模型的摘要：
- en: '[PRE51]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The following image shows the output of the preceding code:'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图像显示了前述代码的输出：
- en: '![Figure 3.30: The architecture of the neural network'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.30：神经网络的架构'
- en: '](img/B15777_03_30.jpg)'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_30.jpg)'
- en: 'Figure 3.30: The architecture of the neural network'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.30：神经网络的架构
- en: 'Fit the model to the training data:'
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据中：
- en: '[PRE52]'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Plot the `training error rate` and `test error rate` for every epoch:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制每个epoch的`训练误差率`和`测试误差率`：
- en: '[PRE53]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '**Expected output**:'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**预期输出**：'
- en: '![Figure 3.31: A plot of the training error rate and test error rate while
    training the model'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.31：训练模型时训练误差率和测试误差率的变化图'
- en: '](img/B15777_03_31.jpg)'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_31.jpg)'
- en: 'Figure 3.31: A plot of the training error rate and test error rate while training
    the model'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.31：训练模型时训练误差率和测试误差率的变化图
- en: Print the values of the best accuracy that was reached on the training set and
    on the test set, as well as the `loss` and `accuracy` that was evaluated on the
    `test` dataset.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出在训练集和测试集上达到的最佳准确率值，以及在`test`数据集上评估的`loss`和`accuracy`值。
- en: '[PRE54]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The following image shows the output of the preceding code:'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图展示了前面代码的输出结果：
- en: '[PRE55]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Implement a deep neural network with two hidden layers of sizes `4` and `2`
    with a `tanh activation function`, an output layer with one node, and a `sigmoid
    activation function`. Finally, compile the model and print out a summary of the
    model:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实现一个具有两个隐藏层的深度神经网络，第一个隐藏层的大小为`4`，第二个隐藏层的大小为`2`，使用`tanh 激活函数`，输出层有一个节点，使用`sigmoid
    激活函数`。最后，编译模型并打印出模型的总结：
- en: '[PRE56]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '![Figure 3.32: The architecture of the neural network'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.32：神经网络架构'
- en: '](img/B15777_03_32.jpg)'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_32.jpg)'
- en: 'Figure 3.32: The architecture of the neural network'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.32：神经网络架构
- en: 'Fit the model to the training data:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据：
- en: '[PRE57]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Plot training and test error plots with two hidden layers of size 4 and 2\.
    Print the best accuracy that was reached on the training and test sets:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制具有两个隐藏层（大小分别为 4 和 2）的训练和测试误差图。打印在训练集和测试集上达到的最佳准确率：
- en: '[PRE58]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '**Expected output**:'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**预期输出**：'
- en: '![Figure 3.33: A plot of the training error and test error rates while training
    the model'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 3.33：训练误差和测试误差率在训练模型时的变化图'
- en: '](img/B15777_03_33.jpg)'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_03_33.jpg)'
- en: 'Figure 3.33: A plot of the training error and test error rates while training
    the model'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 3.33：训练误差和测试误差率在训练模型时的变化图
- en: Print the values of the best accuracy that was achieved on the `training` set
    and on the `test` set, as well as the `loss` and `accuracy` that was evaluated
    on the test dataset.
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印在`训练`集和`测试`集上达到的最佳准确率，以及在测试数据集上评估的`损失`和`准确率`值。
- en: '[PRE59]'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'The following shows the output of the preceding code:'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下展示了前面代码的输出结果：
- en: '[PRE60]'
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Note
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2BrIRMF](https://packt.live/2BrIRMF).
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 若要访问该部分的源代码，请参考 [https://packt.live/2BrIRMF](https://packt.live/2BrIRMF)。
- en: You can also run this example online at [https://packt.live/2NUl22A](https://packt.live/2NUl22A).
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个例子，访问 [https://packt.live/2NUl22A](https://packt.live/2NUl22A)。
- en: 4\. Evaluating Your Model with Cross-Validation Using Keras Wrappers
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 使用 Keras 封装器进行交叉验证评估模型
- en: 'Activity 4.01: Model Evaluation Using Cross-Validation for an Advanced Fibrosis
    Diagnosis Classifier'
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 4.01：使用交叉验证评估高级肝纤维化诊断分类器模型
- en: 'In this activity, we are going to use what we learned in this topic to train
    and evaluate a deep learning model using `k-fold cross-validation`. We will use
    the model that resulted in the best test error rate from the previous activity
    and the goal will be to compare the cross-validation error rate with the training
    set/test set approach error rate. The dataset we will use is the hepatitis C dataset,
    in which we will build a classification model to predict which patients get advanced
    fibrosis. Follow these steps to complete this activity:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将使用本主题中学到的内容，使用`k折交叉验证`训练和评估深度学习模型。我们将使用前一个活动中得到的最佳测试误差率的模型，目标是将交叉验证的误差率与训练集/测试集方法的误差率进行比较。我们将使用的数据库是丙型肝炎
    C 数据集，在该数据集中，我们将构建一个分类模型，预测哪些患者会患上晚期肝纤维化。按照以下步骤完成此活动：
- en: 'Load the dataset and print the number of records and features in the dataset,
    as well as the number of possible classes in the target dataset:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集并打印数据集中的记录数和特征数，以及目标数据集中可能的类别数：
- en: '[PRE61]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Here''s the expected output:'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '[PRE62]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Define the function that returns the Keras model. First, import the necessary
    libraries for Keras. Inside the function, instantiate the sequential model and
    add two dense layers, with the first of `size 4` and the second of `size 2`, both
    with `tanh activation` functions. Add the output layer with a `sigmoid activation`
    function. Compile the model and return the model from the function:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个返回 Keras 模型的函数。首先，导入 Keras 所需的库。在函数内部，实例化顺序模型并添加两个全连接层，第一个层的大小为`4`，第二个层的大小为`2`，两者均使用`tanh
    激活`函数。添加输出层并使用`sigmoid 激活`函数。编译模型并返回模型：
- en: '[PRE63]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Scale the training data using the `StandardScaler` function. Set the seed so
    that the model is reproducible. Define the `n_folds`, `epochs`, and `batch_size`
    hyperparameters. Then, build the Keras wrapper with scikit-learn, define the `cross-validation`
    iterator, perform `k-fold cross-validation`, and store the scores:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`StandardScaler`函数对训练数据进行缩放。设置种子，以便模型可复现。定义超参数`n_folds`、`epochs`和`batch_size`。然后，使用
    scikit-learn 构建 Keras 封装器，定义`cross-validation`迭代器，执行`k折交叉验证`并存储得分：
- en: '[PRE64]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'For each of the folds, print the accuracy stored in the `results` parameter:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每一折，打印存储在`results`参数中的准确率：
- en: '[PRE65]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Here''s the expected output:'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期的输出：
- en: '[PRE66]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Note
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3eWgR2b](https://packt.live/3eWgR2b).
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/3eWgR2b](https://packt.live/3eWgR2b)。
- en: You can also run this example online at [https://packt.live/3iBYtOi](https://packt.live/3iBYtOi).
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个示例，网址为：[https://packt.live/3iBYtOi](https://packt.live/3iBYtOi)。
- en: 'Activity 4.02: Model Selection Using Cross-Validation for the Advanced Fibrosis
    Diagnosis Classifier'
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动4.02：使用交叉验证为高级纤维化诊断分类器选择模型
- en: 'In this activity, we are going to improve our classifier for the hepatitis
    C dataset by using cross-validation for model selection and hyperparameter selection.
    Follow these steps to complete this activity:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在此活动中，我们将通过使用交叉验证来选择模型和超参数，从而改进针对肝炎C数据集的分类器。按照以下步骤完成此活动：
- en: 'Import all the required packages and load the dataset. Scale the dataset using
    the `StandardScaler` function:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有所需的包并加载数据集。使用`StandardScaler`函数对数据集进行标准化：
- en: '[PRE67]'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Define three functions, each returning a different Keras model. The first model
    should have three hidden layers of `size 4`, the second model should have two
    hidden layers, the first of `size 4` and the second of `size 2`, and the third
    model should have two hidden layers of `size 8`. Use function parameters for the
    activation functions and optimizers so that they can be passed through to the
    model. The goal is to find out which of these three models leads to the lowest
    cross-validation error rate:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义三个函数，每个函数返回一个不同的Keras模型。第一个模型应具有三个隐藏层，每层`大小为4`，第二个模型应具有两个隐藏层，第一个隐藏层`大小为4`，第二个隐藏层`大小为2`，第三个模型应具有两个隐藏层，`大小为8`。使用函数参数来传递激活函数和优化器，以便它们可以传递给模型。目标是找出这三个模型中哪一个导致了最低的交叉验证误差率：
- en: '[PRE68]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Write the code that will loop over the three models and perform `5-fold cross-validation`.
    Set the seed so that the models are reproducible and define the `n_folds`, `batch_size`,
    and `epochs` hyperparameters. Store the results from applying the `cross_val_score`
    function when training the models:'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 编写代码，循环遍历三个模型并执行`5折交叉验证`。设置随机种子以确保模型可重复，并定义`n_folds`、`batch_size`和`epochs`超参数。在训练模型时，存储应用`cross_val_score`函数的结果：
- en: '[PRE69]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Here''s an example output. In this instance, **Model 2** has the best cross-validation
    test accuracy, as you can see below:'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是一个示例输出。在此实例中，**模型2**具有最佳的交叉验证测试准确率，具体如下所示：
- en: '[PRE70]'
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Choose the model with the highest accuracy score and repeat *step 2* by iterating
    over the `epochs = [100, 200]` and `batches = [10, 20]` values and performing
    `5-fold cross-validation`:'
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择具有最高准确率得分的模型，并通过遍历`epochs = [100, 200]`和`batches = [10, 20]`的值并执行`5折交叉验证`来重复*步骤2*：
- en: '[PRE71]'
  id: totrans-279
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Here''s an example output:'
  id: totrans-280
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是一个示例输出：
- en: '[PRE72]'
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: In this case, the `batch_size= 10`, `epochs=200` pair has the best cross-validation
    test accuracy.
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在此案例中，`batch_size= 10`，`epochs=200`的组合具有最佳的交叉验证测试准确率。
- en: 'Choose the batch size and epochs with the highest accuracy score and repeat
    *step 3* by iterating over the `optimizers = [''rmsprop'', ''adam'',''sgd'']`
    and `activations = [''relu'', ''tanh'']` values and performing `5-fold cross-validation`:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择具有最高准确率得分的批处理大小和训练轮数，并通过遍历`optimizers = ['rmsprop', 'adam', 'sgd']`和`activations
    = ['relu', 'tanh']`的值并执行`5折交叉验证`来重复*步骤3*：
- en: '[PRE73]'
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'Here''s the expected output:'
  id: totrans-285
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期的输出：
- en: '[PRE74]'
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE74]'
- en: Here, the `activation='relu'` and `optimizer='rmsprop'` pair has the best cross-validation
    test accuracy. Also, the `activation='tanh'` and `optimizer='sgd'` pair results
    in the second-best performance.
  id: totrans-287
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，`activation='relu'`和`optimizer='rmsprop'`的组合具有最佳的交叉验证测试准确率。此外，`activation='tanh'`和`optimizer='sgd'`的组合则取得了第二好的性能。
- en: Note
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2D3AIhD](https://packt.live/2D3AIhD).
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/2D3AIhD](https://packt.live/2D3AIhD)。
- en: You can also run this example online at [https://packt.live/2NUpiiC](https://packt.live/2NUpiiC).
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个示例，网址为：[https://packt.live/2NUpiiC](https://packt.live/2NUpiiC)。
- en: 'Activity 4.03: Model Selection Using Cross-validation on a Traffic Volume Dataset'
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动4.03：使用交叉验证选择交通量数据集的模型
- en: 'In this activity, you are going to practice model selection using cross-validation
    one more time. Here, we are going to use a simulated dataset that represents a
    target variable representing the volume of traffic in cars/hour across a city
    bridge and various normalized features related to traffic data such as time of
    day and the traffic volume on the previous day. Our goal is to build a model that
    predicts the traffic volume across the city bridge given the various features.
    Follow these steps to complete this activity:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，你将再次练习使用交叉验证进行模型选择。在这里，我们将使用一个模拟数据集，表示一个目标变量，表示城市桥梁上每小时的交通量，以及与交通数据相关的各种归一化特征，如一天中的时间和前一天的交通量。我们的目标是建立一个模型，根据这些特征预测城市桥梁上的交通量。按照以下步骤完成此活动：
- en: 'Import all the required packages and load the dataset:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必需的包并加载数据集：
- en: '[PRE75]'
  id: totrans-294
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Load the dataset, print the input and output size for the feature dataset,
    and print the possible classes in the target dataset. Also, print the range of
    the output:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集，打印特征数据集的输入和输出大小，并打印目标数据集中的可能类别。同时，打印输出的范围：
- en: '[PRE76]'
  id: totrans-296
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Here''s the expected output:'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '[PRE77]'
  id: totrans-298
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Define three functions, each returning a different Keras model. The first model
    should have one hidden layer of `size 10`, the second model should have two hidden
    layers of `size 10`, and the third model should have three hidden layers of `size
    10`. Use function parameters for the optimizers so that they can be passed through
    to the model. The goal is to find out which of these three models leads to the
    lowest cross-validation error rate:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义三个函数，每个函数返回一个不同的Keras模型。第一个模型应有一个`大小为10`的隐藏层，第二个模型应有两个`大小为10`的隐藏层，第三个模型应有三个`大小为10`的隐藏层。使用函数参数来传递优化器，以便它们可以传递给模型。目标是找出这三种模型中哪个能带来最低的交叉验证错误率：
- en: '[PRE78]'
  id: totrans-300
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE78]'
- en: 'Write the code that will loop over the three models and perform `5-fold cross-validation`.
    Set the seed so that the models are reproducible and define the `n_folds` hyperparameters.
    Store the results from applying the `cross_val_score` function when training the
    models:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写代码，循环遍历三个模型并执行`5折交叉验证`。设置随机种子以确保模型可复现，并定义`n_folds`超参数。存储在训练模型时应用`cross_val_score`函数的结果：
- en: '[PRE79]'
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'The following is the expected output:'
  id: totrans-303
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期的输出：
- en: '[PRE80]'
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE80]'
- en: '`Model 2` (a two-layer neural network) has the lowest test error rate.'
  id: totrans-305
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`模型2`（一个两层神经网络）具有最低的测试错误率。'
- en: 'Choose the model with the lowest test error rate and repeat *step 4* while
    iterating over `epochs = [80, 100]` and `batches = [50, 25]` and performing `5-fold
    cross-validation`:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择具有最低测试错误率的模型，并在迭代`epochs = [80, 100]`和`batches = [50, 25]`时重复*步骤4*，同时执行`5折交叉验证`：
- en: '[PRE81]'
  id: totrans-307
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Here''s the expected output:'
  id: totrans-308
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '[PRE82]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE82]'
- en: The `batch_size=5` and `epochs=100` pair has the lowest test error rate.
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`batch_size=5`和`epochs=100`的组合具有最低的测试错误率。'
- en: 'Choose the model with the highest accuracy score and repeat *step 2* by iterating
    over `optimizers = [''rmsprop'', ''sgd'', ''adam'']` and performing `5-fold cross-validation`:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择具有最高准确度的模型，并重复*步骤2*，通过迭代`optimizers = ['rmsprop', 'sgd', 'adam']`并执行`5折交叉验证`：
- en: '[PRE83]'
  id: totrans-312
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Here''s the expected output:'
  id: totrans-313
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是预期的输出：
- en: '[PRE84]'
  id: totrans-314
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE84]'
- en: '`optimizer=''sgd''` has the lowest test error rate, so we should proceed with
    this particular model.'
  id: totrans-315
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`optimizer=''sgd''`具有最低的测试错误率，因此我们应继续使用这个模型。'
- en: Note
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/31TcYaD](https://packt.live/31TcYaD).
  id: totrans-317
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/31TcYaD](https://packt.live/31TcYaD)。
- en: You can also run this example online at [https://packt.live/3iq6iqb](https://packt.live/3iq6iqb).
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/3iq6iqb](https://packt.live/3iq6iqb)在线运行这个示例。
- en: 5\. Improving Model Accuracy
  id: totrans-319
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 改进模型准确性
- en: 'Activity 5.01: Weight Regularization on an Avila Pattern Classifier'
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动5.01：在Avila模式分类器上应用权重正则化
- en: 'In this activity, you will build a Keras model to perform classification on
    the Avila pattern dataset according to given network architecture and hyperparameter
    values. The goal is to apply different types of weight regularization on the model,
    that is, `L1` and `L2`, and observe how each type changes the result. Follow these
    steps to complete this activity:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在此活动中，你将构建一个Keras模型，根据给定的网络架构和超参数值对Avila模式数据集进行分类。目标是对模型应用不同类型的权重正则化，即`L1`和`L2`，并观察每种类型如何改变结果。按照以下步骤完成此活动：
- en: 'Load the dataset and split the dataset into a `training set` and a `test set`:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集，并将数据集拆分为`训练集`和`测试集`：
- en: '[PRE85]'
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Define a Keras sequential model with three hidden layers, the first of `size
    10`, the second of `size 6`, and the third of `size 4`. Finally, compile the model:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个包含三个隐藏层的 Keras 顺序模型，第一个隐藏层为 `size 10`，第二个隐藏层为 `size 6`，第三个隐藏层为 `size 4`。最后，编译模型：
- en: '[PRE86]'
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Fit the model to the training data to perform the classification, saving the
    results of the training process:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据上以执行分类，并保存训练过程的结果：
- en: '[PRE87]'
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Plot the trends in training error and test error by importing the necessary
    libraries for plotting the loss and validation loss and saving them in the variable
    that was created when the model was fit to the training process. Print out the
    maximum validation accuracy:'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过导入必要的库来绘制训练误差和测试误差的趋势，绘制损失和验证损失，并将它们保存在模型拟合训练过程时创建的变量中。打印出最大验证准确度：
- en: '[PRE88]'
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'The following is the expected output:'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期输出：
- en: '![Figure 5.13: A plot of the training error and validation error during training'
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.13：训练过程中模型训练误差和验证误差的图'
- en: for the model without regularization
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于没有正则化的模型
- en: '](img/B15777_05_13.jpg)'
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_05_13.jpg)'
- en: 'Figure 5.13: A plot of the training error and validation error during training
    for the model without regularization'
  id: totrans-334
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.13：训练过程中模型在没有正则化情况下的训练误差和验证误差图
- en: The validation loss keeps decreasing along with the training loss. Despite having
    no regularization, this is a fairly good example of the training process since
    the bias and variance are fairly low.
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 验证损失随训练损失不断减少。尽管没有使用正则化，这仍然是一个相当不错的训练过程示例，因为偏差和方差都比较低。
- en: 'Redefine the model, adding `L2 regularizers` with `lambda=0.01` to each hidden
    layer of the model. Repeat *steps 3* and *4* to train the model and plot the `training
    error` and `validation error`:'
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新定义模型，为每个隐藏层添加 `L2 正则化器`，`lambda=0.01`。重复 *步骤 3* 和 *步骤 4* 来训练模型并绘制 `训练误差` 和
    `验证误差`：
- en: '[PRE89]'
  id: totrans-337
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'The following is the expected output:'
  id: totrans-338
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期输出：
- en: '![Figure 5.14: A plot of the training error and validation error during training'
  id: totrans-339
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.14：训练过程中模型训练误差和验证误差的图'
- en: for the model with L2 weight regularization (lambda=0.01)
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于具有 L2 权重正则化（lambda=0.01）的模型
- en: '](img/B15777_05_14.jpg)'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_05_14.jpg)'
- en: 'Figure 5.14: A plot of the training error and validation error during training
    for the model with L2 weight regularization (lambda=0.01)'
  id: totrans-342
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.14：训练过程中具有 L2 权重正则化（lambda=0.01）模型的训练误差和验证误差图
- en: As shown from the preceding plots, the test error almost plateaus after being
    decreased to a certain amount. The gap between the training error and the validation
    error at the end of the training process (the bias) is slightly smaller, which
    is indicative of reduced overfitting of the model for the training examples.
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从前面的图中可以看出，测试误差在降到一定程度后几乎趋于平稳。训练过程结束时训练误差和验证误差之间的差距（偏差）稍微缩小，这表明模型对训练样本的过拟合有所减少。
- en: 'Repeat the previous step with `lambda=0.1` for the `L2 parameter`—redefine
    the model with the new lambda parameter, fit the model to the training data, and
    repeat *step 4* to plot the training error and validation error:'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `lambda=0.1` 的 `L2 参数` 重复前一步骤——使用新的 lambda 参数重新定义模型，拟合模型到训练数据，并重复 *步骤 4*
    绘制训练误差和验证误差：
- en: '[PRE90]'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'The following is the expected output:'
  id: totrans-346
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期输出：
- en: '![Figure 5.15: A plot of the training error and validation error during training'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.15：训练过程中模型训练误差和验证误差的图'
- en: for the model with L2 weight regularization (lambda=0.1)
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于具有 L2 权重正则化（lambda=0.1）的模型
- en: '](img/B15777_05_15.jpg)'
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_05_15.jpg)'
- en: 'Figure 5.15: A plot of the training error and validation error during training
    for the model with L2 weight regularization (lambda=0.1)'
  id: totrans-350
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.15：训练过程中具有 L2 权重正则化（lambda=0.1）模型的训练误差和验证误差图
- en: The training and validation error quickly plateau and are much higher than they
    were for the models we created with a lower `L2 parameter`, indicating that we
    have penalized the model so much that it has not had the flexibility to learn
    the underlying function of the training data. Following this, we will reduce the
    value of the regularization parameter to prevent it from penalizing the model
    as much.
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练和验证误差迅速达到平稳状态，且远高于我们使用较低 `L2 参数` 创建的模型，这表明我们对模型的惩罚过多，导致它没有足够的灵活性去学习训练数据的潜在函数。接下来，我们将减少正则化参数的值，以防止它对模型造成过多惩罚。
- en: 'Repeat the previous step, this time with `lambda=0.005`. Repeat *step 4* to
    plot the training error and validation error:'
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复前一步骤，这次使用 `lambda=0.005`。重复 *步骤 4* 绘制训练误差和验证误差：
- en: '[PRE91]'
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'The following is the expected output:'
  id: totrans-354
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期的输出：
- en: '![Figure 5.16: A plot of the training error and validation error during training
    for the model with L2 weight regularization (lambda=0.005)'
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.16：带有 L2 权重正则化（lambda=0.005）的模型在训练过程中训练误差和验证误差的图示'
- en: '](img/B15777_05_16.jpg)'
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_05_16.jpg)'
- en: 'Figure 5.16: A plot of the training error and validation error during training
    for the model with L2 weight regularization (lambda=0.005)'
  id: totrans-357
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.16：带有 L2 权重正则化（lambda=0.005）的模型在训练过程中训练误差和验证误差的图示
- en: The value for the `L2 weight` regularization achieves the highest accuracy that
    was evaluated on the validation data of all the models with `L2 regularization`,
    but it is slightly lower than without regularization. Again, the test error does
    not increase a significant amount after being decreased to a certain value, which
    is indicative of the model not overfitting the training examples. It seems that
    `L2 weight regularization` with `lambda=0.005` achieves the lowest validation
    error while preventing the model from overfitting.
  id: totrans-358
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`L2 权重` 正则化的值在所有使用 `L2 正则化` 的模型中，在验证数据上评估时，获得了最高的准确度，但稍微低于没有正则化时的准确度。同样，在被减少到某个值之后，测试误差并没有显著增加，这表明模型没有过拟合训练样本。看起来
    `lambda=0.005` 的 `L2 权重正则化` 获得了最低的验证误差，同时防止了模型的过拟合。'
- en: 'Add `L1 regularizers` with `lambda=0.01` to the hidden layers of your model.
    Redefine the model with the new lambda parameter, fit the model to the training
    data, and repeat *step 4* to plot the training error and validation error:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向模型的隐藏层添加 `L1 正则化器`，其中 `lambda=0.01`。重新定义模型，使用新的 lambda 参数，拟合模型到训练数据，并重复 *步骤
    4* 来绘制训练误差和验证误差：
- en: '[PRE92]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'The following is the expected output:'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期的输出：
- en: '![Figure 5.17: A plot of the training error and validation error during training'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.17：训练过程中训练误差和验证误差的图示'
- en: for the model with L1 weight regularization (lambda=0.01)
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于带有 L1 权重正则化（lambda=0.01）的模型
- en: '](img/B15777_05_17.jpg)'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_05_17.jpg)'
- en: 'Figure 5.17: A plot of the training error and validation error during training
    for the model with L1 weight regularization (lambda=0.01)'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.17：带有 L1 权重正则化（lambda=0.01）的模型在训练过程中训练误差和验证误差的图示
- en: 'Repeat the previous step with `lambda=0.005` for the `L1 parameter`—redefine
    the model with the new lambda parameter, fit the model to the training data, and
    repeat *step 4* to plot the `training error` and `validation error`:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复之前的步骤，将 `lambda=0.005` 应用于 `L1 参数`—使用新的 lambda 参数重新定义模型，拟合模型到训练数据，并重复 *步骤
    4* 来绘制 `训练误差` 和 `验证误差`：
- en: '[PRE93]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'The following is the expected output:'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期的输出：
- en: '![Figure 5.18: The plot of the training error and validation error during training
    for the model with L1 weight regularization (lambda=0.005)'
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.18：带有 L1 权重正则化（lambda=0.005）的模型在训练过程中训练误差和验证误差的图示'
- en: '](img/B15777_05_18.jpg)'
  id: totrans-370
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_05_18.jpg)'
- en: 'Figure 5.18: The plot of the training error and validation error during training
    for the model with L1 weight regularization (lambda=0.005)'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.18：带有 L1 权重正则化（lambda=0.005）的模型在训练过程中训练误差和验证误差的图示
- en: It seems that `L1 weight regularization` with `lambda=0.005` achieves a better
    test error while preventing the model from overfitting since the value of `lambda=0.01`
    is too restrictive and prevents the model from learning the underlying function
    of the training data.
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 看起来 `lambda=0.005` 的 `L1 权重正则化` 在防止模型过拟合的同时，获得了更好的测试误差，因为 `lambda=0.01` 的值过于严格，导致模型无法学习训练数据的潜在函数。
- en: 'Add `L1` and `L2 regularizers` with an `L1` of `lambda=0.005` and an `L2` of
    `lambda = 0.005` to the hidden layers of your model. Then, repeat *step 4* to
    plot the training error and validation error:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向模型的隐藏层添加 `L1` 和 `L2 正则化器`，其中 `L1` 为 `lambda=0.005`，`L2` 为 `lambda = 0.005`。然后，重复
    *步骤 4* 来绘制训练误差和验证误差：
- en: '[PRE94]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'The following is the expected output:'
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期的输出：
- en: '![Figure 5.19: A plot of the training error and validation error during training
    for the model with L1 lambda equal to 0.005 and L2 lambda equal to 0.005'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.19：带有 L1 lambda 等于 0.005 和 L2 lambda 等于 0.005 的模型在训练过程中训练误差和验证误差的图示'
- en: '](img/B15777_05_19.jpg)'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_05_19.jpg)'
- en: 'Figure 5.19: A plot of the training error and validation error during training
    for the model with L1 lambda equal to 0.005 and L2 lambda equal to 0.005'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.19：带有 L1 lambda 等于 0.005 和 L2 lambda 等于 0.005 的模型在训练过程中训练误差和验证误差的图示
- en: While `L1` and `L2 regularization` are successful in preventing the model from
    overfitting, the variance in the model is very low. However, the accuracy that's
    obtained on the validation data is not as high as the model that was trained with
    no regularization or the model that was trained with the `L2 regularization` `lambda=0.005`
    or `L1 regularization` `lambda=0.005` parameters individually.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管`L1`和`L2 正则化`成功防止了模型的过拟合，但模型的方差非常低。然而，验证数据上的准确率并不像没有正则化训练的模型，或者使用`L2 正则化`
    `lambda=0.005`或`L1 正则化` `lambda=0.005`参数单独训练的模型那样高。
- en: Note
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/31BUf34](https://packt.live/31BUf34).
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/31BUf34](https://packt.live/31BUf34)。
- en: You can also run this example online at [https://packt.live/38n291s](https://packt.live/38n291s).
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/38n291s](https://packt.live/38n291s)上在线运行这个示例。
- en: 'Activity 5.02: Dropout Regularization on the Traffic Volume Dataset'
  id: totrans-383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 5.02：在交通量数据集上使用 dropout 正则化
- en: 'In this activity, you will start with the model from *Activity 4.03*, *Model
    Selection Using Cross-Validation on a Traffic Volume Dataset*, of *Chapter 4*,
    *Evaluating Your Model with Cross-Validation Using Keras Wrappers*. You will use
    the training set/test set approach to train and evaluate the model, plot the trends
    in training error and the generalization error, and observe the model overfitting
    the data examples. Then, you will attempt to improve model performance by addressing
    the overfitting issue through the use of dropout regularization. In particular,
    you will try to find out which layers you should add dropout regularization to
    and what `rate` value will improve this specific model the most. Follow these
    steps to complete this exercise:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，你将从*活动 4.03*，*使用交叉验证对交通量数据集进行模型选择*，*第4章*，*使用 Keras 包装器进行交叉验证评估模型*开始。你将使用训练集/测试集方法来训练和评估模型，绘制训练误差和泛化误差的趋势，并观察模型对数据示例的过拟合情况。然后，你将尝试通过使用
    dropout 正则化来解决过拟合问题，从而提高模型的性能。特别地，你将尝试找出应该在模型的哪些层添加 dropout 正则化，以及什么`rate`值能够最大程度地提高该特定模型的性能。按照以下步骤完成这个练习：
- en: 'Load the dataset using the pandas `read_csv` function, split the dataset into
    a training set and test set into an `80-20` ratio using `train_test_split`, and
    scale the input data using `StandardScaler`:'
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 的`read_csv`函数加载数据集，使用`train_test_split`将数据集按`80-20`比例划分为训练集和测试集，并使用`StandardScaler`对输入数据进行标准化：
- en: '[PRE95]'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Set a seed so that the model can be reproduced. Next, define a Keras sequential
    model with two hidden layers of `size 10`, both with `ReLU activation` functions.
    Add an output layer with no activation function and compile the model with the
    given hyperparameters:'
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置一个随机种子，以便模型可以复现。接下来，定义一个包含两个`size 10`的隐藏层的 Keras 顺序模型，每个隐藏层都使用`ReLU 激活`函数。添加一个没有激活函数的输出层，并使用给定的超参数编译模型：
- en: '[PRE96]'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Train the model on the training data with the given hyperparameters:'
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用给定的超参数训练模型：
- en: '[PRE97]'
  id: totrans-390
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'Plot the trends for the `training error` and `test error`. Print the best accuracy
    that was reached for the training and validation set:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制`训练误差`和`测试误差`的趋势。打印在训练集和验证集上达到的最佳准确率：
- en: '[PRE98]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The following is the expected output:'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期的输出：
- en: '[PRE99]'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE99]'
- en: '![Figure 5.20: A plot of the training error and validation error during training'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 5.20：训练过程中训练误差和验证误差的图表'
- en: for the model without regularization
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于没有正则化的模型
- en: '](img/B15777_05_20.jpg)'
  id: totrans-397
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_05_20.jpg)'
- en: 'Figure 5.20: A plot of the training error and validation error during training
    for the model without regularization'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 5.20：没有正则化的模型在训练过程中训练误差和验证误差的图表
- en: In the training error and validation error values, there is a very small gap
    between the training error and validation error, which is indicative of a low
    variance model, which is good.
  id: totrans-399
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在训练误差和验证误差值中，训练误差和验证误差之间的差距非常小，这表明模型的方差很低，这是一个好兆头。
- en: 'Redefine the model by creating the same model architecture. However, this time,
    add a dropout regularization with `rate=0.1` to the first hidden layer of your
    model. Repeat *step 3* to train the model on the training data and repeat *step
    4* to plot the trends for the training and validation errors. Then, print the
    best accuracy that was reached on the validation set:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新定义模型，创建相同的模型架构。然而，这一次，在模型的第一个隐藏层添加`rate=0.1`的 dropout 正则化。重复*步骤 3*，使用训练数据训练模型，并重复*步骤
    4*绘制训练误差和验证误差的趋势。然后，打印在验证集上达到的最佳准确率：
- en: '[PRE100]'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'The following is the expected output:'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期输出：
- en: '[PRE101]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE101]'
- en: '![Figure 5.21: A plot of the training error and validation error during training
    for the model with dropout regularization (rate=0.1) in the first layer'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.21：在使用dropout正则化（第一层rate=0.1）训练模型时，训练误差和验证误差的曲线图]'
- en: '](img/B15777_05_21.jpg)'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_05_21.jpg)'
- en: 'Figure 5.21: A plot of the training error and validation error during training
    for the model with dropout regularization (rate=0.1) in the first layer'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.21：在使用dropout正则化（第一层rate=0.1）训练模型时，训练误差和验证误差的曲线图
- en: There is a small gap between the training error and the validation error; however,
    the validation error is lower than the training error, indicating that the model
    is not overfitting the training data.
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练误差和验证误差之间存在小的差距；然而，验证误差低于训练误差，表明模型没有对训练数据发生过拟合。
- en: 'Repeat the previous step, this time adding dropout regularization with `rate=0.1`
    to both hidden layers of your model. Repeat *step 3* to train the model on the
    training data and repeat *step 4* to plot the trends for the training and validation
    errors. Then, print the best accuracy that was reached on the validation set:'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复上一步，这次为模型的两个隐藏层添加`rate=0.1`的dropout正则化。重复*步骤3*，在训练数据上训练模型，并重复*步骤4*，绘制训练误差和验证误差的趋势。然后，打印在验证集上达到的最佳准确率：
- en: '[PRE102]'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'The following is the expected output:'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期输出：
- en: '[PRE103]'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE103]'
- en: '![Figure 5.22: A plot of the training error and validation error during training
    for'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.22：在使用dropout正则化（rate=0.1）训练模型时，训练误差和验证误差的曲线图]'
- en: the model with dropout regularization (rate=0.1) in both layers
  id: totrans-413
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用dropout正则化（rate=0.1）在两个层上的模型
- en: '](img/B15777_05_22.jpg)'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_05_22.jpg)'
- en: 'Figure 5.22: A plot of the training error and validation error during training
    for the model with dropout regularization (rate=0.1) in both layers'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图5.22：在使用dropout正则化（rate=0.1）训练模型时，训练误差和验证误差的曲线图
- en: The gap between the training error and validation error is slightly higher here,
    mostly due to the increase in the training error as a result of the additional
    regularization on the second hidden layer of the model.
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这里训练误差和验证误差之间的差距略有增大，主要是由于在模型第二个隐藏层上增加了正则化，导致训练误差的增加。
- en: 'Repeat the previous step, this time adding dropout regularization with `rate=0.2`
    in the first layer and `rate=0.1` in the second layer of your model. Repeat *step
    3* to train the model on the training data and repeat *step 4* to plot the trends
    for the training and validation errors. Then, print the best accuracy that was
    reached on the validation set:'
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复上一步，这次为模型的第一层添加`rate=0.2`的dropout正则化，为第二层添加`rate=0.1`的dropout正则化。重复*步骤3*，在训练数据上训练模型，并重复*步骤4*，绘制训练误差和验证误差的趋势。然后，打印在验证集上达到的最佳准确率：
- en: '[PRE104]'
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE104]'
- en: 'The following is the expected output:'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期输出：
- en: '[PRE105]'
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE105]'
- en: '![Figure 5.23: A plot of training errors and validation errors while training
    the model with dropout regularization, with rate=0.2 in the first layer and rate
    0.1 in the second layer'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图5.23：在使用dropout正则化（第一层rate=0.2，第二层rate=0.1）训练模型时，训练误差和验证误差的曲线图]'
- en: '](img/B15777_05_23.jpg)'
  id: totrans-422
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_05_23.jpg)'
- en: 'Figure 5.23: A plot of training errors and validation errors while training
    the model with dropout regularization, with rate=0.2 in the first layer and rate
    0.1 in the second layer'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.23：在使用dropout正则化（第一层rate=0.2，第二层rate=0.1）训练模型时，训练误差和验证误差的曲线图
- en: The gap between the training error and validation error is slightly larger due
    to the increase in regularization. In this case, there was no overfitting in the
    original model. As a result, regularization increased the error rate on the training
    and validation dataset.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 由于正则化的增加，训练误差和验证误差之间的差距略有增大。在这种情况下，原始模型没有发生过拟合。因此，正则化增加了训练和验证数据集上的误差率。
- en: Note
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/38mtDo7](https://packt.live/38mtDo7).
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 若要查看此特定部分的源代码，请参考[https://packt.live/38mtDo7](https://packt.live/38mtDo7)。
- en: You can also run this example online at [https://packt.live/31Isdmu](https://packt.live/31Isdmu).
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/31Isdmu](https://packt.live/31Isdmu)上在线运行这个示例。
- en: 'Activity 5.03: Hyperparameter Tuning on the Avila Pattern Classifier'
  id: totrans-428
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动5.03：Avila模式分类器的超参数调整
- en: 'In this activity, you will build a Keras model similar to those in the previous
    activities, but this time, you will add regularization methods to your model as
    well. Then, you will use scikit-learn optimizers to perform tuning on the model
    hyperparameters, including the hyperparameters of the regularizers. Follow these
    steps to complete this activity:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次活动中，你将构建一个类似于前几次活动中的Keras模型，但这次你将向模型中添加正则化方法。然后，你将使用scikit-learn优化器对模型的超参数进行调优，包括正则化器的超参数。按照以下步骤完成本次活动：
- en: 'Load the dataset and import the libraries:'
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据集并导入库：
- en: '[PRE106]'
  id: totrans-431
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE106]'
- en: 'Define a function that returns a Keras model with three hidden layers, the
    first of `size 10`, the second of `size 6`, and the third of `size 4`, and apply
    `L2 weight regularization` and a `ReLU activation` function on each hidden layer.
    Compile the model with the given parameters and return it from the model:'
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个函数，返回一个Keras模型，该模型具有三层隐藏层，第一层大小为`10`，第二层大小为`6`，第三层大小为`4`，并在每个隐藏层上应用`L2权重正则化`和`ReLU激活`函数。使用给定的参数编译模型并返回模型：
- en: '[PRE107]'
  id: totrans-433
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE107]'
- en: 'Set a seed, use a scikit-learn wrapper to wrap the model that we created in
    the previous step, and define the hyperparameters to scan. Finally, perform `GridSearchCV()`
    on the model using the hyperparameter''s grid and fit the model:'
  id: totrans-434
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置随机种子，使用scikit-learn封装器对我们在上一步中创建的模型进行封装，并定义要扫描的超参数。最后，使用超参数网格对模型执行`GridSearchCV()`并拟合模型：
- en: '[PRE108]'
  id: totrans-435
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'Print the results for the best cross-validation score that''s stored within
    the variable we created in the fit process. Iterate through all the parameters
    and print the mean of the accuracy across all the folds, the standard deviation
    of the accuracy, and the parameters themselves:'
  id: totrans-436
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印在拟合过程中我们创建的变量中存储的最佳交叉验证分数的结果。遍历所有参数并打印各折的准确率均值、准确率标准差以及参数本身：
- en: '[PRE109]'
  id: totrans-437
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE109]'
- en: 'The following is the expected output:'
  id: totrans-438
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期的输出：
- en: '[PRE110]'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE110]'
- en: 'Repeat *step 3* using `GridSearchCV()`, `lambda_parameter = [0.001, 0.01, 0.05,
    0.1]`, `batch_size = [20]`, and `epochs = [100]`. Fit the model to the training
    data using `5-fold cross-validation` and print the results for the entire grid:'
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*步骤3*，使用`GridSearchCV()`、`lambda_parameter = [0.001, 0.01, 0.05, 0.1]`、`batch_size
    = [20]`和`epochs = [100]`。使用`5折交叉验证`对模型进行拟合，并打印整个网格的结果：
- en: '[PRE111]'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE111]'
- en: 'The following is the expected output:'
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期的输出：
- en: '[PRE112]'
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE112]'
- en: 'Redefine a function that returns a Keras model with three hidden layers, the
    first of `size 10`, the second of `size 6`, and the third of `size 4`, and apply
    `dropout regularization` and a `ReLU activation` function on each hidden layer.
    Compile the model with the given parameters and return it from the function:'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新定义一个函数，返回一个Keras模型，该模型具有三层隐藏层，第一层大小为`10`，第二层大小为`6`，第三层大小为`4`，并在每个隐藏层上应用`dropout正则化`和`ReLU激活`函数。使用给定的参数编译模型并从函数中返回：
- en: '[PRE113]'
  id: totrans-445
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE113]'
- en: 'Use `rate = [0, 0.1, 0.2]` and `epochs = [50, 100]` and perform `GridSearchCV()`
    on the model. Fit the model to the training data using `5-fold cross-validation`
    and print the results for the entire grid:'
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`rate = [0, 0.1, 0.2]`和`epochs = [50, 100]`，对模型进行`GridSearchCV()`调优。使用`5折交叉验证`对模型进行拟合，并打印整个网格的结果：
- en: '[PRE114]'
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE114]'
- en: 'The following is the expected output:'
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期的输出：
- en: '[PRE115]'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE115]'
- en: 'Repeat *step 5* using `rate = [0.0, 0.05, 0.1]` and `epochs = [100]`. Fit the
    model to the training data using `5-fold cross-validation` and print the results
    for the entire grid:'
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复*步骤5*，使用`rate = [0.0, 0.05, 0.1]`和`epochs = [100]`。使用`5折交叉验证`对模型进行拟合，并打印整个网格的结果：
- en: '[PRE116]'
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE116]'
- en: 'The following is the expected output:'
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是预期的输出：
- en: '[PRE117]'
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE117]'
- en: Note
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2D7HN0L](https://packt.live/2D7HN0L).
  id: totrans-455
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/2D7HN0L](https://packt.live/2D7HN0L)。
- en: This section does not currently have an online interactive example and will
    need to be run locally.
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本节目前没有在线互动示例，需要在本地运行。
- en: 6\. Model Evaluation
  id: totrans-457
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. 模型评估
- en: 'Activity 6.01: Computing the Accuracy and Null Accuracy of a Neural Network
    When We Change the Train/Test Split'
  id: totrans-458
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动6.01：当我们改变训练/测试数据集的拆分时，计算神经网络的准确率和空准确率
- en: 'In this activity, we will see that our `null accuracy` and `accuracy` will
    be affected by changing the `train`/`test` split. To implement this, the part
    of the code where the train/test split was defined has to be changed. We will
    use the same dataset that we used in *Exercise 6.02*, *Computing Accuracy and
    Null Accuracy with APS Failure for Scania Trucks Data*. Follow these steps to
    complete this activity:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将看到`null accuracy`和`accuracy`会受到`train`/`test`划分的影响。为实现这一点，需要修改定义训练/测试划分的代码部分。我们将使用在*练习6.02*中使用的相同数据集，即*使用Scania卡车数据计算准确率和零准确率*。按照以下步骤完成此活动：
- en: 'Import the required libraries. Load the dataset using the pandas `read_csv`
    function and look at the first `five` rows of the dataset:'
  id: totrans-460
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库。使用pandas的`read_csv`函数加载数据集，并查看数据集的前`五`行：
- en: '[PRE118]'
  id: totrans-461
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'The following table shows the output of the preceding code:'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下表显示了前面代码的输出：
- en: '![Figure 6.13: Initial five rows of the dataset'
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.13：数据集的初始五行'
- en: '](img/B15777_06_13.jpg)'
  id: totrans-464
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_06_13.jpg)'
- en: 'Figure 6.13: Initial five rows of the dataset'
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.13：数据集的初始五行
- en: 'Change the `test_size` and `random_state` from `0.20` to `0.3` and `42` to
    `13`, respectively:'
  id: totrans-466
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`test_size`和`random_state`从`0.20`和`42`分别更改为`0.3`和`13`：
- en: '[PRE119]'
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE119]'
- en: Note
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: If you use a different `random_state`, you may get a different `train`/`test`
    split, which may yield slightly different final results.
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果使用不同的`random_state`，可能会得到不同的`train`/`test`划分，这可能会导致稍微不同的最终结果。
- en: 'Scale the data using the `StandardScaler` function and use the scaler to scale
    the test data. Convert both into pandas DataFrames:'
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`StandardScaler`函数对数据进行缩放，并使用缩放器对测试数据进行缩放。将两者转换为pandas DataFrame：
- en: '[PRE120]'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE120]'
- en: Note
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The `sc.fit_transform()` function transforms the data, and the data is also
    converted into a `NumPy` array. We may need the data later for analysis as a DataFrame
    object, so the `pd.DataFrame()` function reconverts data into a DataFrame.
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`sc.fit_transform()`函数转换数据，同时数据也被转换为`NumPy`数组。我们可能稍后需要将数据作为DataFrame对象进行分析，因此使用`pd.DataFrame()`函数将数据重新转换为DataFrame。'
- en: 'Import the libraries that are required to build a neural network architecture:'
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入构建神经网络架构所需的库：
- en: '[PRE121]'
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'Initiate the `Sequential` class:'
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动`Sequential`类：
- en: '[PRE122]'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE122]'
- en: 'Add five `Dense` layers to the network with `Dropout`. Set the first hidden
    layer so that it has a size of `64` with a dropout rate of `0.5`, the second hidden
    layer so that it has a size of `32` with a dropout rate of `0.4`, the third hidden
    layer so that it has a size of `16` with a dropout rate of `0.3`, the fourth hidden
    layer so that it has a size of `8` with a dropout rate of `0.2`, and the final
    hidden layer so that it has a size of `4` with a dropout rate of `0.1`. Set all
    the activation functions to `ReLU`:'
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向网络中添加五个`Dense`层，并使用`Dropout`。设置第一个隐藏层的大小为`64`，丢弃率为`0.5`；第二个隐藏层的大小为`32`，丢弃率为`0.4`；第三个隐藏层的大小为`16`，丢弃率为`0.3`；第四个隐藏层的大小为`8`，丢弃率为`0.2`；最后一个隐藏层的大小为`4`，丢弃率为`0.1`。将所有激活函数设置为`ReLU`：
- en: '[PRE123]'
  id: totrans-479
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE123]'
- en: 'Add an output `Dense` layer with a `sigmoid` activation function:'
  id: totrans-480
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个输出`Dense`层，并使用`sigmoid`激活函数：
- en: '[PRE124]'
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE124]'
- en: Note
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Since the output is binary, we are using the `sigmoid` function. If the output
    is multiclass (that is, more than two classes), then the `softmax` function should
    be used.
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于输出是二分类的，我们使用`sigmoid`函数。如果输出是多类的（即超过两个类别），则应使用`softmax`函数。
- en: 'Compile the network and fit the model. The metric that''s being used here is `accuracy`:'
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译网络并拟合模型。这里使用的度量标准是`accuracy`：
- en: '[PRE125]'
  id: totrans-485
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE125]'
- en: Note
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The metric name, which in our case is `accuracy`, is defined in the preceding
    code.
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在我们这例中，度量标准是`accuracy`，已在前面的代码中定义。
- en: 'Fit the model with `100` epochs, a batch size of `20`, and a validation split
    of `0.2`:'
  id: totrans-488
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`100`轮训练、批量大小为`20`、验证集划分比例为`0.2`来训练模型：
- en: '[PRE126]'
  id: totrans-489
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE126]'
- en: 'Evaluate the model on the test dataset and print out the values for the `loss`
    and `accuracy`:'
  id: totrans-490
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试数据集上评估模型，并打印出`loss`和`accuracy`的值：
- en: '[PRE127]'
  id: totrans-491
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE127]'
- en: 'The preceding code produces the following output:'
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码产生以下输出：
- en: '[PRE128]'
  id: totrans-493
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE128]'
- en: The model returns an accuracy of `98.9833%`. But is it good enough? We can only
    get the answer to this question by comparing it against the null accuracy.
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型返回的准确率为`98.9833%`。但这足够好吗？我们只能通过与零准确率进行比较来回答这个问题。
- en: 'Now, compute the null accuracy. The `null accuracy` can be calculated using
    the `value_count` function of the `pandas` library, which we used in *Exercise
    6.01*, *Calculating Null Accuracy on a Pacific Hurricanes Dataset*, of this chapter:'
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，计算空准确率。`空准确率`可以使用`pandas`库的`value_count`函数计算，之前在本章的*练习6.01*中，*计算太平洋飓风数据集上的空准确率*时，我们已经用过这个函数：
- en: '[PRE129]'
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE129]'
- en: 'The preceding code produces the following output:'
  id: totrans-497
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码将产生以下输出：
- en: '[PRE130]'
  id: totrans-498
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE130]'
- en: 'Calculate the `null accuracy`:'
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算`空准确率`：
- en: '[PRE131]'
  id: totrans-500
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE131]'
- en: 'The preceding code produces the following output:'
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码将产生以下输出：
- en: '[PRE132]'
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE132]'
- en: Note
  id: totrans-503
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3eY7y1E](https://packt.live/3eY7y1E).
  id: totrans-504
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/3eY7y1E](https://packt.live/3eY7y1E)。
- en: You can also run this example online at [https://packt.live/2BzBO4n](https://packt.live/2BzBO4n).
  id: totrans-505
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/2BzBO4n](https://packt.live/2BzBO4n)在线运行此示例。
- en: 'Activity 6.02: Calculating the ROC Curve and AUC Score'
  id: totrans-506
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动6.02：计算ROC曲线和AUC得分
- en: 'The `ROC curve` and `AUC score` is an effective way to easily evaluate the
    performance of a binary classifier. In this activity, we will plot the `ROC curve`
    and calculate the `AUC score` of a model. We will use the same dataset and train
    the same model that we used in *Exercise 6.03*, *Deriving and Computing Metrics
    Based on a Confusion Matrix*. Continue with the same APS failure data, plot the
    `ROC curve`, and compute the `AUC score` of the model. Follow these steps to complete
    this activity:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: '`ROC曲线`和`AUC得分`是一种有效的方式，能够轻松评估二分类器的性能。在这个活动中，我们将绘制`ROC曲线`并计算模型的`AUC得分`。我们将使用相同的数据集并训练与*练习6.03*中相同的模型，*基于混淆矩阵推导和计算指标*。继续使用相同的APS故障数据，绘制`ROC曲线`并计算模型的`AUC得分`。按照以下步骤完成这个活动：'
- en: 'Import the necessary libraries and load the data using the pandas `read_csv` function:'
  id: totrans-508
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的库，并使用pandas的`read_csv`函数加载数据：
- en: '[PRE133]'
  id: totrans-509
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE133]'
- en: 'Split the data into training and test datasets using the `train_test_split`
    function:'
  id: totrans-510
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`train_test_split`函数将数据集分割为训练集和测试集：
- en: '[PRE134]'
  id: totrans-511
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE134]'
- en: 'Scale the feature data so that it has a `mean` of `0` and a `standard deviation`
    of `1` using the `StandardScaler` function. Fit the scaler in the `training data`
    and apply it to the `test data`:'
  id: totrans-512
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`StandardScaler`函数对特征数据进行缩放，使其具有`0`的`均值`和`1`的`标准差`。对`训练数据`进行拟合，并将其应用于`测试数据`：
- en: '[PRE135]'
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE135]'
- en: 'Import the Keras libraries that are required for creating the model. Instantiate
    a Keras model of the `Sequential` class and add five hidden layers to the model,
    including dropout for each layer. The first hidden layer should have a size of
    `64` and a dropout rate of `0.5`. The second hidden layer should have a size of
    `32` and a dropout rate of `0.4`. The third hidden layer should have a size of
    `16` and a dropout rate of `0.3`. The fourth hidden layer should have a size of
    `8` and a dropout rate of `0.2`. The final hidden layer should have a size of
    `4` and a dropout rate of `0.1`. All the hidden layers should have `ReLU activation`
    functions and set `kernel_initializer = ''uniform''`. Add a final output layer
    to the model with a sigmoid activation function. Compile the model by calculating
    the accuracy metric during the training process:'
  id: totrans-514
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入创建模型所需的Keras库。实例化一个`Sequential`类的Keras模型，并向模型中添加五个隐藏层，包括每层的丢弃层。第一个隐藏层应具有`64`的大小和`0.5`的丢弃率。第二个隐藏层应具有`32`的大小和`0.4`的丢弃率。第三个隐藏层应具有`16`的大小和`0.3`的丢弃率。第四个隐藏层应具有`8`的大小和`0.2`的丢弃率。最后一个隐藏层应具有`4`的大小和`0.1`的丢弃率。所有隐藏层应具有`ReLU激活`函数，并将`kernel_initializer
    = 'uniform'`。在模型中添加一个最终的输出层，并使用sigmoid激活函数。通过计算训练过程中准确率指标来编译模型：
- en: '[PRE136]'
  id: totrans-515
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE136]'
- en: 'Fit the model to the training data by training for `100` epochs with `batch_size=20`
    and with `validation_split=0.2`:'
  id: totrans-516
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`100`个训练周期、`batch_size=20`和`validation_split=0.2`将模型拟合到训练数据：
- en: '[PRE137]'
  id: totrans-517
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE137]'
- en: 'Once the model has finished fitting to the training data, create a variable
    that is the result of the model''s prediction on the test data using the model''s
    `predict_proba` methods:'
  id: totrans-518
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型完成了对训练数据的拟合，创建一个变量，该变量是模型对测试数据的预测结果，使用模型的`predict_proba`方法：
- en: '[PRE138]'
  id: totrans-519
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE138]'
- en: 'Import `roc_curve` from scikit-learn and run the following code:'
  id: totrans-520
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从scikit-learn导入`roc_curve`并运行以下代码：
- en: '[PRE139]'
  id: totrans-521
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE139]'
- en: '`fpr` = False positive rate (1 - specificity)'
  id: totrans-522
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`fpr` = 假阳性率（1 - 特异性）'
- en: '`tpr` = True positive rate (sensitivity)'
  id: totrans-523
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`tpr` = 真阳性率（灵敏度）'
- en: '`thresholds` = The threshold value of `y_pred_prob`'
  id: totrans-524
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`thresholds` = `y_pred_prob`的阈值'
- en: 'Run the following code to plot the `ROC curve` using `matplotlib.pyplot`:'
  id: totrans-525
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下代码使用`matplotlib.pyplot`绘制`ROC曲线`：
- en: '[PRE140]'
  id: totrans-526
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE140]'
- en: 'The following plot shows the output of the preceding code:'
  id: totrans-527
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图表显示了前述代码的输出：
- en: '![Figure 6.14: ROC curve of the APS failure dataset'
  id: totrans-528
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.14：APS失败数据集的ROC曲线](img/B15777_06_14.jpg)'
- en: '](img/B15777_06_14.jpg)'
  id: totrans-529
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_06_14.jpg)'
- en: 'Figure 6.14: ROC curve of the APS failure dataset'
  id: totrans-530
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.14：APS失败数据集的ROC曲线
- en: 'Calculate the AUC score using the `roc_auc_score` function:'
  id: totrans-531
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`roc_auc_score`函数计算AUC分数：
- en: '[PRE141]'
  id: totrans-532
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE141]'
- en: 'The following is the output of the preceding code:'
  id: totrans-533
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是前述代码的输出：
- en: '[PRE142]'
  id: totrans-534
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE142]'
- en: The AUC score of `94.4479%` suggests that our model is excellent, as per the
    general acceptable `AUC score` shown above.
  id: totrans-535
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`94.4479%`的AUC分数表明我们的模型表现优秀，符合上面列出的普遍可接受的`AUC分数`标准。'
- en: Note
  id: totrans-536
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2NUOgyh](https://packt.live/2NUOgyh).
  id: totrans-537
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 若要访问此特定部分的源代码，请参考[https://packt.live/2NUOgyh](https://packt.live/2NUOgyh)。
- en: You can also run this example online at [https://packt.live/2As33NH](https://packt.live/2As33NH).
  id: totrans-538
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/2As33NH](https://packt.live/2As33NH)在线运行此示例。
- en: 7\. Computer Vision with Convolutional Neural Networks
  id: totrans-539
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7. 卷积神经网络的计算机视觉
- en: 'Activity 7.01: Amending Our Model with Multiple Layers and the Use of softmax'
  id: totrans-540
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动7.01：通过多个层和使用softmax来修改我们的模型
- en: 'Let''s try and improve the performance of our image classification algorithm.
    There are many ways to improve its performance, and one of the most straightforward
    ways is by adding multiple ANN layers to the model, which we will learn about
    in this activity. We will also change the activation from sigmoid to softmax.
    Then, we can compare the result with that of the previous exercise. Follow these
    steps to complete this activity:'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试提高图像分类算法的性能。有很多方法可以提升性能，其中最直接的一种方式就是向模型中添加多个ANN层，这将在本活动中讲解。我们还将把激活函数从sigmoid更改为softmax。然后，我们可以将结果与之前练习的结果进行比较。按照以下步骤完成此活动：
- en: 'Import the `numpy` library and the necessary Keras libraries and classes:'
  id: totrans-542
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`库以及必要的Keras库和类：
- en: '[PRE143]'
  id: totrans-543
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE143]'
- en: 'Now, initiate the model with the `Sequential` class:'
  id: totrans-544
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用`Sequential`类初始化模型：
- en: '[PRE144]'
  id: totrans-545
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE144]'
- en: 'Add the first layer of the CNN, set the input shape to `(64, 64, 3)`, the dimension
    of each image, and the activation function as a ReLU. Then, add `32` feature detectors
    of size `(3, 3)`. Add two additional convolutional layers with `32` feature detectors
    of size `(3, 3)`, also with `ReLU activation` functions:'
  id: totrans-546
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加CNN的第一层，设置输入形状为`(64, 64, 3)`，即每个图像的维度，并设置激活函数为ReLU。然后，添加`32`个大小为`(3, 3)`的特征检测器。再添加两层卷积层，每层有`32`个大小为`(3,
    3)`的特征检测器，且都使用`ReLU激活`函数：
- en: '[PRE145]'
  id: totrans-547
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE145]'
- en: '`32, (3, 3)` means that there are `32` feature detectors of size `3x3`. As
    a good practice, always start with `32`; you can add `64` or `128` later.'
  id: totrans-548
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`32, (3, 3)`表示有`32`个大小为`3x3`的特征检测器。作为良好的实践，始终从`32`开始；你可以稍后添加`64`或`128`。'
- en: 'Now, add the pooling layer with an image size of `2x2`:'
  id: totrans-549
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，添加池化层，图像大小为`2x2`：
- en: '[PRE146]'
  id: totrans-550
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE146]'
- en: 'Flatten the output of the pooling layer by adding a flattening layer to the
    `CNN model`:'
  id: totrans-551
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过向`CNN模型`添加flatten层，来展平池化层的输出：
- en: '[PRE147]'
  id: totrans-552
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE147]'
- en: 'Add the first dense layer of the ANN. Here, `128` is the output of the number
    of nodes. As a good practice, `128` is good to get started. `activation` is `relu`.
    As a good practice, the power of two is preferred:'
  id: totrans-553
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加ANN的第一层密集层。此处，`128`是节点数量的输出。作为一个良好的实践，`128`是一个不错的起点。`activation`是`relu`。作为一个良好的实践，建议使用2的幂：
- en: '[PRE148]'
  id: totrans-554
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE148]'
- en: 'Add three more layers to the ANN of the same size, `128`, along with `ReLU
    activation` functions:'
  id: totrans-555
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向ANN中添加三层相同大小为`128`的层，并配以`ReLU激活`函数：
- en: '[PRE149]'
  id: totrans-556
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE149]'
- en: 'Add the output layer of the ANN. Replace the sigmoid function with `softmax`:'
  id: totrans-557
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加ANN的输出层。将sigmoid函数替换为`softmax`：
- en: '[PRE150]'
  id: totrans-558
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE150]'
- en: 'Compile the network with an `Adam optimizer` and compute the accuracy during
    the training process:'
  id: totrans-559
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`Adam优化器`编译网络，并在训练过程中计算准确率：
- en: '[PRE151]'
  id: totrans-560
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE151]'
- en: 'Create training and test data generators. Rescale the training and test images
    by `1/255` so that all the values are between `0` and `1`. Set these parameters
    for the training data generators only – `shear_range=0.2`, `zoom_range=0.2`, and
    `horizontal_flip=True`:'
  id: totrans-561
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建训练和测试数据生成器。通过`1/255`重新缩放训练和测试图像，使所有值都介于`0`和`1`之间。仅为训练数据生成器设置以下参数：`shear_range=0.2`、`zoom_range=0.2`和`horizontal_flip=True`：
- en: '[PRE152]'
  id: totrans-562
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE152]'
- en: 'Create a training set from the `training set` folder. `''../dataset/training_set''`
    is the folder where our data has been placed. Our CNN model has an image size
    of `64x64`, so the same size should be passed here too. `batch_size` is the number
    of images in a single batch, which is `32`. `class_mode` is set to `binary` since
    we are working on binary classifiers:'
  id: totrans-563
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`training set`文件夹创建训练集。`'../dataset/training_set'`是我们存放数据的文件夹。我们的CNN模型的图像大小为`64x64`，因此这里也应该传递相同的大小。`batch_size`是每个批次中的图像数量，设置为`32`。`class_mode`设置为`binary`，因为我们正在处理二分类器：
- en: '[PRE153]'
  id: totrans-564
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE153]'
- en: 'Repeat *step 6* for the test by setting the folder to the location of the test
    images, that is, `''../dataset/test_set''`:'
  id: totrans-565
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对测试数据重复*步骤6*，将文件夹设置为测试图像的所在位置，即`'../dataset/test_set'`：
- en: '[PRE154]'
  id: totrans-566
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE154]'
- en: 'Finally, fit the data. Set the `steps_per_epoch` to `10000` and the `validation_steps`
    to `2500`. The following step might take some time to execute:'
  id: totrans-567
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，拟合数据。将`steps_per_epoch`设置为`10000`，将`validation_steps`设置为`2500`。以下步骤可能需要一些时间来执行：
- en: '[PRE155]'
  id: totrans-568
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE155]'
- en: 'The preceding code produces the following output:'
  id: totrans-569
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '[PRE156]'
  id: totrans-570
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE156]'
- en: Note that the accuracy has decreased to `46.91%` due to the new softmax activation
    function.
  id: totrans-571
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，由于新的softmax激活函数，准确率已降至`46.91%`。
- en: Note
  id: totrans-572
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3gj0TiA](https://packt.live/3gj0TiA).
  id: totrans-573
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/3gj0TiA](https://packt.live/3gj0TiA)。
- en: You can also run this example online at [https://packt.live/2VIDj7e](https://packt.live/2VIDj7e).
  id: totrans-574
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您也可以在线运行此示例：[https://packt.live/2VIDj7e](https://packt.live/2VIDj7e)。
- en: 'Activity 7.02: Classifying a New Image'
  id: totrans-575
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 7.02：分类新图像
- en: 'In this activity, you will try to classify another new image, just like we
    did in the preceding exercise. The image hasn''t been exposed to the algorithm,
    so we will use this activity to test our algorithm. You can run any of the algorithms
    in this chapter (although the one that gets the highest accuracy is preferred)
    and then use the model to classify your images. Follow these steps to complete
    this activity:'
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次活动中，您将尝试分类另一张新图像，就像我们在前面的练习中所做的那样。该图像尚未暴露于算法，因此我们将使用此活动来测试我们的算法。您可以运行本章中的任何算法（虽然推荐使用获得最高准确率的算法），然后使用该模型对您的图像进行分类。按照以下步骤完成此活动：
- en: Run one of the algorithms from this chapter.
  id: totrans-577
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行本章中的一个算法。
- en: 'Load the image and process it. `''test_image_2.jpg''` is the path of the test
    image. Change the path in the code where you have saved the dataset:'
  id: totrans-578
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载图像并处理它。`'test_image_2.jpg'`是测试图像的路径。请在代码中更改为您保存数据集的路径：
- en: '[PRE157]'
  id: totrans-579
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE157]'
- en: 'You can view the class labels using the following code:'
  id: totrans-580
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以使用以下代码查看类标签：
- en: '[PRE158]'
  id: totrans-581
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE158]'
- en: 'Process the image by converting it into a `numpy` array using the `img_to_array`
    function. Then, add an additional dimension along the 0th axis using numpy''s
    `expand_dims` function:'
  id: totrans-582
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用`img_to_array`函数将图像转换为`numpy`数组来处理图像。然后，使用`numpy`的`expand_dims`函数沿第0轴添加一个额外的维度：
- en: '[PRE159]'
  id: totrans-583
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE159]'
- en: 'Predict the new image by calling the `predict` method of the classifier:'
  id: totrans-584
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过调用分类器的`predict`方法来预测新图像：
- en: '[PRE160]'
  id: totrans-585
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE160]'
- en: 'Use the `class_indices` method with an `if…else` statement to map the 0 or
    1 output of the prediction to a class label:'
  id: totrans-586
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`class_indices`方法结合`if…else`语句，将预测的0或1输出映射到一个类标签：
- en: '[PRE161]'
  id: totrans-587
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE161]'
- en: 'The preceding code produces the following output:'
  id: totrans-588
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成以下输出：
- en: '[PRE162]'
  id: totrans-589
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE162]'
- en: '`test_image_2` is an image of a flower and was predicted to be a flower.'
  id: totrans-590
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`test_image_2`是一张花卉图像，预测结果为花卉。'
- en: Note
  id: totrans-591
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/38ny95E](https://packt.live/38ny95E).
  id: totrans-592
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/38ny95E](https://packt.live/38ny95E)。
- en: You can also run this example online at [https://packt.live/2VIM4Ow](https://packt.live/2VIM4Ow).
  id: totrans-593
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您也可以在线运行此示例：[https://packt.live/2VIM4Ow](https://packt.live/2VIM4Ow)。
- en: 8\. Transfer Learning and Pre-Trained Models
  id: totrans-594
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8\. 转移学习与预训练模型
- en: 'Activity 8.01: Using the VGG16 Network to Train a Deep Learning Network to
    Identify Images'
  id: totrans-595
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 8.01：使用VGG16网络训练深度学习网络以识别图像
- en: 'Use the `VGG16` network to predict the image given (`test_image_1`). Before
    you start, ensure that you have downloaded the image (`test_image_1`) to your
    working directory. Follow these steps to complete this activity:'
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`VGG16`网络预测给定的图像（`test_image_1`）。在开始之前，请确保您已将图像（`test_image_1`）下载到工作目录中。按照以下步骤完成此活动：
- en: 'Import the `numpy` library and the necessary `Keras` libraries:'
  id: totrans-597
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入`numpy`库和必要的`Keras`库：
- en: '[PRE163]'
  id: totrans-598
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE163]'
- en: 'Initiate the model (note that, at this point, you can also view the architecture
    of the network, as shown in the following code):'
  id: totrans-599
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化模型（注意，此时您还可以查看网络架构，如以下代码所示）：
- en: '[PRE164]'
  id: totrans-600
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE164]'
- en: '`classifier.summary()` shows us the architecture of the network. The following
    points should be noted: it has a four-dimensional input shape (`None, 224, 224,
    3`) and it has three convolutional layers.'
  id: totrans-601
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`classifier.summary()` 显示了网络的架构。需要注意以下几点：它具有四维输入形状（`None, 224, 224, 3`），并且有三层卷积层。'
- en: 'The last four layers of the output are as follows:'
  id: totrans-602
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输出的最后四层如下：
- en: '![Figure 8.16: The architecture of the network'
  id: totrans-603
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.16：网络的架构'
- en: '](img/B15777_08_16.jpg)'
  id: totrans-604
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_16.jpg)'
- en: 'Figure 8.16: The architecture of the network'
  id: totrans-605
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.16：网络的架构
- en: 'Load the image. `''../Data/Prediction/test_image_1.jpg''` is the path of the
    image on our system. It will be different on your system:'
  id: totrans-606
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载图像。 `'../Data/Prediction/test_image_1.jpg'` 是我们系统中图像的路径，在您的系统上会有所不同：
- en: '[PRE165]'
  id: totrans-607
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE165]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-608
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了前面代码的输出：
- en: '![Figure 8.17: The sample motorbike image'
  id: totrans-609
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.17：示例摩托车图像'
- en: '](img/B15777_08_17.jpg)'
  id: totrans-610
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_17.jpg)'
- en: 'Figure 8.17: The sample motorbike image'
  id: totrans-611
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.17：示例摩托车图像
- en: The target size should be `224x 224` since `VGG16` only accepts (`224,224`).
  id: totrans-612
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标大小应该是 `224x 224`，因为 `VGG16` 仅接受（`224, 224`）。
- en: 'Change the image into an array by using the `img_to_array` function:'
  id: totrans-613
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `img_to_array` 函数将图像转换为数组：
- en: '[PRE166]'
  id: totrans-614
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE166]'
- en: 'The preceding code provides the following output:'
  id: totrans-615
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码提供了以下输出：
- en: '[PRE167]'
  id: totrans-616
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE167]'
- en: 'The image should be in a four-dimensional form for `VGG16` to allow further
    processing. Expand the dimension of the image, as follows:'
  id: totrans-617
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图像应该是四维形式的，以便 `VGG16` 允许进一步处理。按如下方式扩展图像的维度：
- en: '[PRE168]'
  id: totrans-618
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE168]'
- en: 'The preceding code provides the following output:'
  id: totrans-619
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码提供了以下输出：
- en: '[PRE169]'
  id: totrans-620
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE169]'
- en: 'Preprocess the image:'
  id: totrans-621
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理图像：
- en: '[PRE170]'
  id: totrans-622
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE170]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-623
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了前面代码的输出：
- en: '![Figure 8.18: Image preprocessing'
  id: totrans-624
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.18：图像预处理'
- en: '](img/B15777_08_18.jpg)'
  id: totrans-625
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_18.jpg)'
- en: 'Figure 8.18: Image preprocessing'
  id: totrans-626
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.18：图像预处理
- en: 'Create the `predictor` variable:'
  id: totrans-627
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 `predictor` 变量：
- en: '[PRE171]'
  id: totrans-628
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE171]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-629
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了前面代码的输出：
- en: '![Figure 8.19: Creating the predictor variable'
  id: totrans-630
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.19：创建预测变量'
- en: '](img/B15777_08_19.jpg)'
  id: totrans-631
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_19.jpg)'
- en: 'Figure 8.19: Creating the predictor variable'
  id: totrans-632
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.19：创建预测变量
- en: 'Check the shape of the image. It should be (`1,1000`). It''s `1000` because,
    as we mentioned previously, the ImageNet database has `1000` categories of images.
    The predictor variable shows the probabilities of our image being one of those images:'
  id: totrans-633
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查图像的形状。它应该是（`1,1000`）。之所以是 `1000`，是因为如前所述，ImageNet 数据库有 `1000` 个图像类别。预测变量显示了我们图像属于这些图像类别之一的概率：
- en: '[PRE172]'
  id: totrans-634
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE172]'
- en: 'The preceding code provides the following output:'
  id: totrans-635
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码提供了以下输出：
- en: '[PRE173]'
  id: totrans-636
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE173]'
- en: 'Print the top five probabilities of what our image is using the `decode_predictions`
    function and pass the function of the predictor variable, `y_pred`, and the number
    of predictions and corresponding labels to output:'
  id: totrans-637
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `decode_predictions` 函数打印我们图像的前五个概率，并传递预测变量 `y_pred` 的函数，以及预测数量和对应标签以输出：
- en: '[PRE174]'
  id: totrans-638
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE174]'
- en: 'The preceding code provides the following output:'
  id: totrans-639
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码提供了以下输出：
- en: '[PRE175]'
  id: totrans-640
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE175]'
- en: The first column of the array is an internal code number. The second is the
    label, while the third is the probability of the image being the label.
  id: totrans-641
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数组的第一列是内部编码号，第二列是标签，第三列是图像属于该标签的概率。
- en: 'Transform the predictions into a human-readable format. We need to extract
    the most probable label from the output, as follows:'
  id: totrans-642
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预测转换为人类可读的格式。我们需要从输出中提取最可能的标签，如下所示：
- en: '[PRE176]'
  id: totrans-643
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE176]'
- en: 'The preceding code provides the following output:'
  id: totrans-644
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码提供了以下输出：
- en: '[PRE177]'
  id: totrans-645
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE177]'
- en: Here, we can see that we have an `84.33%` probability that the picture is of
    a moped, which is close enough to a motorbike and probably represents the fact
    that motorbikes in the ImageNet dataset were labeled as mopeds.
  id: totrans-646
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到该图片有 `84.33%` 的概率是摩托车，这与摩托车足够接近，可能表示在 ImageNet 数据集中摩托车被标记为踏板车。
- en: Note
  id: totrans-647
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2C4nqRo](https://packt.live/2C4nqRo).
  id: totrans-648
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 若要访问此特定部分的源代码，请参考 [https://packt.live/2C4nqRo](https://packt.live/2C4nqRo)。
- en: You can also run this example online at [https://packt.live/31JMPL4](https://packt.live/31JMPL4).
  id: totrans-649
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您还可以在 [https://packt.live/31JMPL4](https://packt.live/31JMPL4) 在线运行此示例。
- en: 'Activity 8.02: Image Classification with ResNet'
  id: totrans-650
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 8.02：使用 ResNet 进行图像分类
- en: 'In this activity, we will use another pre-trained network, known as `ResNet`.
    We have an image of television located at `../Data/Prediction/test_image_4`. We
    will use the `ResNet50` network to predict the image. Follow these steps to complete
    this activity:'
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: 在本活动中，我们将使用另一个预训练网络，称为 `ResNet`。我们有一张位于 `../Data/Prediction/test_image_4` 的电视图像。我们将使用
    `ResNet50` 网络来预测这张图像。请按照以下步骤完成此活动：
- en: 'Import the `numpy` library and the necessary `Keras` libraries:'
  id: totrans-652
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `numpy` 库和必要的 `Keras` 库：
- en: '[PRE178]'
  id: totrans-653
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE178]'
- en: 'Initiate the ResNet50 model and print a summary of the model:'
  id: totrans-654
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化 ResNet50 模型并打印模型的总结：
- en: '[PRE179]'
  id: totrans-655
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE179]'
- en: '`classifier.summary()` shows us the architecture of the network. The following
    points should be noted:'
  id: totrans-656
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`classifier.summary()` 显示了网络的架构，以下几点需要注意：'
- en: '![Figure 8.20: The last four layers of the output'
  id: totrans-657
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.20：输出的最后四层'
- en: '](img/B15777_08_20.jpg)'
  id: totrans-658
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_20.jpg)'
- en: 'Figure 8.20: The last four layers of the output'
  id: totrans-659
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.20：输出的最后四层
- en: Note
  id: totrans-660
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The last layer predictions (`Dense`) have `1000` values. This means that `VGG16`
    has a total of `1000` labels and that our image will be one of those `1000` labels.
  id: totrans-661
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后一层预测（`Dense`）有 `1000` 个值。这意味着 `VGG16` 总共有 `1000` 个标签，我们的图像将属于这 `1000` 个标签中的一个。
- en: 'Load the image. `''../Data/Prediction/test_image_4.jpg''` is the path of the
    image on our system. It will be different on your system:'
  id: totrans-662
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载图像。`'../Data/Prediction/test_image_4.jpg'` 是我们系统上图像的路径，在你的系统中会有所不同：
- en: '[PRE180]'
  id: totrans-663
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE180]'
- en: 'The following is the output of the preceding code:'
  id: totrans-664
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是上述代码的输出：
- en: '![Figure 8.21: A sample image of a television'
  id: totrans-665
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 8.21：一张电视的示例图像'
- en: '](img/B15777_08_21.jpg)'
  id: totrans-666
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_08_21.jpg)'
- en: 'Figure 8.21: A sample image of a television'
  id: totrans-667
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 8.21：一张电视的示例图像
- en: The target size should be `224x224` since `ResNet50` only accepts (`224,224`).
  id: totrans-668
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标大小应该是 `224x224`，因为 `ResNet50` 只接受 (`224,224`)。
- en: 'Change the image into an array by using the `img_to_array` function:'
  id: totrans-669
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `img_to_array` 函数将图像转换为数组：
- en: '[PRE181]'
  id: totrans-670
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE181]'
- en: 'The image has to be in a four-dimensional form for `ResNet50` to allow further
    processing. Expand the dimensions of the image along the 0th axis using the `expand_dims`
    function:'
  id: totrans-671
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了使 `ResNet50` 允许进一步处理，图像必须为四维形式。使用 `expand_dims` 函数沿第 0 维扩展图像的维度：
- en: '[PRE182]'
  id: totrans-672
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE182]'
- en: 'Preprocess the image using the `preprocess_input` function:'
  id: totrans-673
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `preprocess_input` 函数对图像进行预处理：
- en: '[PRE183]'
  id: totrans-674
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE183]'
- en: 'Create the predictor variable by using the classifier to predict the image
    using it''s `predict` method:'
  id: totrans-675
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用分类器的 `predict` 方法，通过创建预测变量来预测图像：
- en: '[PRE184]'
  id: totrans-676
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE184]'
- en: 'Check the shape of the image. It should be (`1,1000`):'
  id: totrans-677
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查图像的形状。它应该是（`1,1000`）：
- en: '[PRE185]'
  id: totrans-678
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE185]'
- en: 'The preceding code provides the following output:'
  id: totrans-679
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码提供了以下输出：
- en: '[PRE186]'
  id: totrans-680
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE186]'
- en: 'Select the top five probabilities of what our image is using the `decode_predictions`
    function and by passing the predictor variable, `y_pred`, as the argument and
    the top number of predictions and corresponding labels:'
  id: totrans-681
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `decode_predictions` 函数，传递预测变量 `y_pred` 作为参数，选择最顶端的五个概率及其对应的标签：
- en: '[PRE187]'
  id: totrans-682
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE187]'
- en: 'The preceding code provides the following output:'
  id: totrans-683
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码提供了以下输出：
- en: '[PRE188]'
  id: totrans-684
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE188]'
- en: The first column of the array is an internal code number. The second is the
    label, while the third is the probability of the image matching the label.
  id: totrans-685
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数组的第一列是内部代码编号，第二列是标签，第三列是图像与标签匹配的概率。
- en: 'Put the predictions in a human-readable format. Print the most probable label
    from the output from the result of the `decode_predictions` function:'
  id: totrans-686
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将预测结果转化为人类可读的格式。从 `decode_predictions` 函数的输出中打印最可能的标签：
- en: '[PRE189]'
  id: totrans-687
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE189]'
- en: 'The preceding code produces the following output:'
  id: totrans-688
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码产生了以下输出：
- en: '[PRE190]'
  id: totrans-689
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE190]'
- en: Note
  id: totrans-690
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/38rEe0M](https://packt.live/38rEe0M).
  id: totrans-691
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考 [https://packt.live/38rEe0M](https://packt.live/38rEe0M)。
- en: You can also run this example online at [https://packt.live/2YV5xxo](https://packt.live/2YV5xxo).
  id: totrans-692
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在网上运行这个示例，网址是 [https://packt.live/2YV5xxo](https://packt.live/2YV5xxo)。
- en: 9\. Sequential Modeling with Recurrent Neural Networks
  id: totrans-693
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9\. 使用递归神经网络进行序列建模
- en: 'Activity 9.01: Predicting the Trend of Amazon''s Stock Price Using an LSTM
    with 50 Units (Neurons)'
  id: totrans-694
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 9.01：使用 50 个单元（神经元）的 LSTM 预测亚马逊股价趋势
- en: 'In this activity, we will examine the stock price of Amazon for the last 5
    years—from January 1, 2014, to December 31, 2018\. In doing so, we will try to
    predict and forecast the company''s future trend for January 2019 using an `RNN`
    and `LSTM`. We have the actual values for January 2019, so we can compare our
    predictions to the actual values later. Follow these steps to complete this activity:'
  id: totrans-695
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将研究亚马逊过去5年的股票价格——从2014年1月1日到2018年12月31日。通过这一过程，我们将尝试使用`RNN`和`LSTM`预测2019年1月该公司的未来趋势。我们拥有2019年1月的实际数据，因此可以稍后将预测结果与实际值进行比较。按照以下步骤完成这个活动：
- en: 'Import the required libraries:'
  id: totrans-696
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库：
- en: '[PRE191]'
  id: totrans-697
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE191]'
- en: 'Import the dataset using the pandas `read_csv` function and look at the first
    five rows of the dataset using the `head` method:'
  id: totrans-698
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用pandas的`read_csv`函数导入数据集，并使用`head`方法查看数据集的前五行：
- en: '[PRE192]'
  id: totrans-699
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE192]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-700
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图示显示了上述代码的输出：
- en: '![Figure 9.24: The first five rows of the dataset'
  id: totrans-701
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.24：数据集的前五行](img/B15777_09_24.jpg)'
- en: '](img/B15777_09_24.jpg)'
  id: totrans-702
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_09_24.jpg)'
- en: 'Figure 9.24: The first five rows of the dataset'
  id: totrans-703
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图9.24：数据集的前五行
- en: 'We are going to make our prediction using the `Open` stock price; therefore,
    select the `Open` stock price column from the dataset and print the values:'
  id: totrans-704
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`Open`股票价格进行预测；因此，从数据集中选择`Open`股票价格列并打印其值：
- en: '[PRE193]'
  id: totrans-705
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE193]'
- en: 'The preceding code produces the following output:'
  id: totrans-706
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE194]'
  id: totrans-707
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE194]'
- en: 'Then, perform feature scaling by normalizing the data using `MinMaxScaler`
    and setting the range of the features so that they have a minimum value of zero
    and a maximum value of one. Use the `fit_transform` method of the scaler on the
    training data:'
  id: totrans-708
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，通过使用`MinMaxScaler`进行特征缩放来规范化数据，设定特征的范围，使它们的最小值为0，最大值为1。使用缩放器的`fit_transform`方法对训练数据进行处理：
- en: '[PRE195]'
  id: totrans-709
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE195]'
- en: 'The preceding code produces the following output:'
  id: totrans-710
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE196]'
  id: totrans-711
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE196]'
- en: 'Create the data to get `60` timestamps from the current instance. We chose
    `60` here as it will give us a sufficient number of previous instances in order
    to understand the trend; technically, this can be any number, but `60` is the
    optimal value. Additionally, the upper bound value here is `1258`, which is the
    index or count of rows (or records) in the training set:'
  id: totrans-712
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建数据以从当前实例获取`60`个时间戳。我们选择`60`是因为它能为我们提供足够的前置实例来理解趋势；从技术上讲，这个数字可以是任何值，但`60`是最优值。此外，这里的上界值是`1258`，它是训练集中的行数（或记录数）索引：
- en: '[PRE197]'
  id: totrans-713
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE197]'
- en: 'Reshape the data to add an extra dimension to the end of `X_train` using NumPy''s
    `reshape` function:'
  id: totrans-714
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用NumPy的`reshape`函数重塑数据，为`X_train`的末尾添加一个额外的维度：
- en: '[PRE198]'
  id: totrans-715
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE198]'
- en: 'Import the following libraries to build the RNN:'
  id: totrans-716
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下库来构建RNN：
- en: '[PRE199]'
  id: totrans-717
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE199]'
- en: 'Set the seed and initiate the sequential model, as follows:'
  id: totrans-718
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置随机种子并初始化顺序模型，如下所示：
- en: '[PRE200]'
  id: totrans-719
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE200]'
- en: 'Add an `LSTM` layer to the network with `50` units, set the `return_sequences`
    argument to `True`, and set the `input_shape` argument to `(X_train.shape[1],
    1)`. Add three additional `LSTM` layers, each with `50` units, and set the `return_sequences`
    argument to `True` for the first two. Add a final output layer of size 1:'
  id: totrans-720
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向网络中添加一个`LSTM`层，设定`50`个单元，将`return_sequences`参数设置为`True`，并将`input_shape`参数设置为`(X_train.shape[1],
    1)`。添加三个额外的`LSTM`层，每个层有`50`个单元，并为前两个层将`return_sequences`参数设置为`True`。最后，添加一个大小为1的输出层：
- en: '[PRE201]'
  id: totrans-721
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE201]'
- en: 'Compile the network with an `adam` optimizer and use `Mean Squared Error` for
    the loss. Fit the model to the training data for `100` epochs with a batch size
    of `32`:'
  id: totrans-722
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`adam`优化器并使用`均方误差`作为损失函数编译网络。将模型拟合到训练数据，进行`100`个周期的训练，批量大小为`32`：
- en: '[PRE202]'
  id: totrans-723
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE202]'
- en: 'Load and process the test data (which is treated as actual data here) and select
    the column representing the value of `Open` stock data:'
  id: totrans-724
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载并处理测试数据（在这里视为实际数据），并选择表示`Open`股票数据的列：
- en: '[PRE203]'
  id: totrans-725
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE203]'
- en: 'Concatenate the data since we will need `60` previous instances to get the
    stock price for each day. Therefore, we will need both the training and test data:'
  id: totrans-726
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 连接数据，因为我们需要`60`个前一个实例来获得每天的股票价格。因此，我们将需要训练数据和测试数据：
- en: '[PRE204]'
  id: totrans-727
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE204]'
- en: 'Reshape and scale the input to prepare the test data. Note that we are predicting
    the January monthly trend, which has `21` financial days, so in order to prepare
    the test set, we take the lower bound value as `60` and the upper bound value
    as `81`. This ensures that the difference of `21` is maintained:'
  id: totrans-728
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重塑并缩放输入数据以准备测试数据。请注意，我们正在预测1月的月度趋势，这一月份有`21`个金融工作日，因此为了准备测试集，我们将下界值设为`60`，上界值设为`81`。这样可以确保`21`的差值得以保持：
- en: '[PRE205]'
  id: totrans-729
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE205]'
- en: 'Visualize the results by plotting the actual stock price and plotting the predicted
    stock price:'
  id: totrans-730
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过绘制实际股价和预测股价来可视化结果：
- en: '[PRE206]'
  id: totrans-731
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE206]'
- en: Please note that your results may differ slightly from the actual stock price
    of Amazon.
  id: totrans-732
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，您的结果可能会与亚马逊的实际股价略有不同。
- en: '**Expected output**:'
  id: totrans-733
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**预期输出**：'
- en: '![Figure 9.25: Real versus predicted stock prices'
  id: totrans-734
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图9.25：实际股价与预测股价'
- en: '](img/B15777_09_25.jpg)'
  id: totrans-735
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_09_25.jpg)'
- en: 'Figure 9.25: Real versus predicted stock prices'
  id: totrans-736
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.25：实际股价与预测股价
- en: As shown in the preceding plot, the trends of the predicted and real prices
    are pretty much the same; the line has the same peaks and troughs. This is possible
    because of LSTM's ability to remember sequenced data. A traditional feedforward
    neural network would not have been able to forecast this result. This is the true
    power of `LSTM` and `RNNs`.
  id: totrans-737
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的图所示，预测股价和实际股价的趋势几乎相同；两条线的波峰和波谷一致。这是因为LSTM能够记住序列数据。传统的前馈神经网络无法预测出这一结果。这正是`LSTM`和`RNNs`的真正强大之处。
- en: Note
  id: totrans-738
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3goQO3I](https://packt.live/3goQO3I).
  id: totrans-739
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅[https://packt.live/3goQO3I](https://packt.live/3goQO3I)。
- en: You can also run this example online at [https://packt.live/2VIMq7O](https://packt.live/2VIMq7O).
  id: totrans-740
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/2VIMq7O](https://packt.live/2VIMq7O)上在线运行此示例。
- en: 'Activity 9.02: Predicting Amazon''s Stock Price with Added Regularization'
  id: totrans-741
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动9.02：使用正则化预测亚马逊的股价
- en: 'In this activity, we will examine the stock price of Amazon over the last 5
    years, from January 1, 2014, to December 31, 2018\. In doing so, we will try to
    predict and forecast the company''s future trend for January 2019 using RNNs and
    an LSTM. We have the actual values for January 2019, so we will be able to compare
    our predictions with the actual values later. Initially, we predicted the trend
    of Amazon''s stock price using an LSTM with 50 units (or neurons). In this activity,
    we will also add dropout regularization and compare the results with *Activity
    9.01*, *Predicting the Trend of Amazon''s Stock Price Using an LSTM with 50 Units
    (Neurons)*. Follow these steps to complete this activity:'
  id: totrans-742
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将研究亚马逊过去5年的股价，从2014年1月1日到2018年12月31日。在此过程中，我们将尝试使用RNN和LSTM预测并预测2019年1月亚马逊股价的未来趋势。我们已拥有2019年1月的实际值，因此稍后我们将能够将我们的预测与实际值进行比较。最初，我们使用50个单元（或神经元）的LSTM预测了亚马逊股价的趋势。在本次活动中，我们还将添加Dropout正则化，并将结果与*活动9.01*、*使用50个单元（神经元）的LSTM预测亚马逊股价趋势*进行比较。按照以下步骤完成此活动：
- en: 'Import the required libraries:'
  id: totrans-743
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库：
- en: '[PRE207]'
  id: totrans-744
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE207]'
- en: 'Import the dataset using the pandas `read_csv` function and look at the first
    five rows of the dataset using the `head` method:'
  id: totrans-745
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用pandas的`read_csv`函数导入数据集，并使用`head`方法查看数据集的前五行：
- en: '[PRE208]'
  id: totrans-746
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE208]'
- en: 'We are going to make our prediction using the `Open` stock price; therefore,
    select the `Open` stock price column from the dataset and print the values:'
  id: totrans-747
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用`Open`股票价格来进行预测；因此，从数据集中选择`Open`股票价格列并打印其值：
- en: '[PRE209]'
  id: totrans-748
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE209]'
- en: 'The preceding code produces the following output:'
  id: totrans-749
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码产生了以下输出：
- en: '[PRE210]'
  id: totrans-750
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE210]'
- en: 'Then, perform feature scaling by normalizing the data using `MinMaxScaler`
    and setting the range of the features so that they have a minimum value of `0`
    and a maximum value of one. Use the `fit_transform` method of the scaler on the
    training data:'
  id: totrans-751
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，通过使用`MinMaxScaler`对数据进行特征缩放，并设置特征的范围，使其最小值为`0`，最大值为1。使用缩放器的`fit_transform`方法对训练数据进行处理：
- en: '[PRE211]'
  id: totrans-752
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE211]'
- en: 'The preceding code produces the following output:'
  id: totrans-753
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码产生了以下输出：
- en: '[PRE212]'
  id: totrans-754
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE212]'
- en: 'Create the data to get `60` timestamps from the current instance. We chose
    `60` here as it will give us a sufficient number of previous instances in order
    to understand the trend; technically, this can be any number, but `60` is the
    optimal value. Additionally, the upper bound value here is `1258`, which is the
    index or count of rows (or records) in the training set:'
  id: totrans-755
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建数据以获取来自当前实例的`60`个时间戳。我们选择`60`，因为它将为我们提供足够的先前实例，以便理解趋势；技术上讲，这可以是任何数字，但`60`是最优值。此外，这里的上限值是`1258`，这是训练集中的索引或行数（或记录数）：
- en: '[PRE213]'
  id: totrans-756
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE213]'
- en: 'Reshape the data to add an extra dimension to the end of `X_train` using NumPy''s
    `reshape` function:'
  id: totrans-757
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用NumPy的`reshape`函数将数据重塑，以便在`X_train`的末尾添加一个额外的维度：
- en: '[PRE214]'
  id: totrans-758
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE214]'
- en: 'Import the following Keras libraries to build the RNN:'
  id: totrans-759
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下Keras库以构建RNN：
- en: '[PRE215]'
  id: totrans-760
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE215]'
- en: 'Set the seed and initiate the sequential model, as follows:'
  id: totrans-761
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置种子并初始化顺序模型，如下所示：
- en: '[PRE216]'
  id: totrans-762
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE216]'
- en: 'Add an LSTM layer to the network with 50 units, set the `return_sequences`
    argument to `True`, and set the `input_shape` argument to `(X_train.shape[1],
    1)`. Add dropout to the model with `rate=0.2`. Add three additional LSTM layers,
    each with `50` units, and set the `return_sequences` argument to `True` for the
    first two. After each `LSTM` layer, add a dropout with `rate=0.2`. Add a final
    output layer of size `1`:'
  id: totrans-763
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在网络中添加一个LSTM层，设置50个单元，将`return_sequences`参数设置为`True`，并将`input_shape`参数设置为`(X_train.shape[1],
    1)`。为模型添加丢弃层，`rate=0.2`。再添加三个LSTM层，每个LSTM层有`50`个单元，前两个LSTM层的`return_sequences`参数设置为`True`。在每个`LSTM`层后，添加丢弃层，`rate=0.2`。最后添加一个大小为`1`的输出层：
- en: '[PRE217]'
  id: totrans-764
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE217]'
- en: 'Compile the network with an `adam` optimizer and use `Mean Squared Error` for
    the loss. Fit the model to the training data for `100` epochs with a batch size
    of `32`:'
  id: totrans-765
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`adam`优化器编译网络，并使用`均方误差`作为损失函数。将模型拟合到训练数据，训练`100`个周期，批量大小为`32`：
- en: '[PRE218]'
  id: totrans-766
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE218]'
- en: 'Load and process the test data (which is treated as actual data here) and select
    the column representing the value of `Open` stock data:'
  id: totrans-767
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载并处理测试数据（这里将其视为实际数据），并选择表示`Open`股票数据的列：
- en: '[PRE219]'
  id: totrans-768
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE219]'
- en: 'Concatenate the data since we will need `60` previous instances to get the
    stock price for each day. Therefore, we will need both the training and test data:'
  id: totrans-769
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据连接起来，因为我们需要`60`个前序实例来获取每天的股票价格。因此，我们将需要训练数据和测试数据：
- en: '[PRE220]'
  id: totrans-770
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE220]'
- en: 'Reshape and scale the input to prepare the test data. Note that we are predicting
    the January monthly trend, which has `21` financial days, so in order to prepare
    the test set, we take the lower bound value as `60` and the upper bound value
    as `81`. This ensures that the difference of `21` is maintained:'
  id: totrans-771
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对输入数据进行重塑和缩放，以准备测试数据。请注意，我们正在预测1月的月度趋势，1月有`21`个交易日，因此为了准备测试集，我们将下界值设为`60`，上界值设为`81`。这确保了`21`的差异得以保持：
- en: '[PRE221]'
  id: totrans-772
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE221]'
- en: 'Visualize the results by plotting the actual stock price and plotting the predicted
    stock price:'
  id: totrans-773
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过绘制实际股票价格与预测股票价格的图表来可视化结果：
- en: '[PRE222]'
  id: totrans-774
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE222]'
- en: Please note that your results may differ slightly to the actual stock price.
  id: totrans-775
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您的结果可能与实际股票价格略有不同。
- en: '**Expected output**:'
  id: totrans-776
  prefs: []
  type: TYPE_NORMAL
  zh: '**预期输出**：'
- en: '![Figure 9.26: Real versus predicted stock prices'
  id: totrans-777
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.26：实际股票价格与预测股票价格的对比](img/B15777_09_26.jpg)'
- en: '](img/B15777_09_26.jpg)'
  id: totrans-778
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_09_26.jpg)'
- en: 'Figure 9.26: Real versus predicted stock prices'
  id: totrans-779
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.26：实际股票价格与预测股票价格的对比
- en: 'In the following figure, the first plot displays the predicted output of the
    model with regularization from Activity 9.02, and the second displays the predicted
    output without regularization from Activity 9.01\. As you can see, adding dropout
    regularization does not fit the data as accurately. So, in this case, it is better
    not to use regularization, or to use dropout regularization with a lower dropout
    rate :'
  id: totrans-780
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，第一个图展示了来自活动9.02的带正则化的模型预测输出，第二个图展示了来自活动9.01的没有正则化的模型预测输出。正如你所见，加入丢弃正则化并没有更精确地拟合数据。因此，在这种情况下，最好不要使用正则化，或者使用丢弃正则化并设置较低的丢弃率：
- en: '![Figure 9.27: Comparing the results of Activity 9.01 and Activity 9.02'
  id: totrans-781
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.27：比较活动9.01与活动9.02的结果](img/B15777_09_27.jpg)'
- en: '](img/B15777_09_27.jpg)'
  id: totrans-782
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_09_27.jpg)'
- en: 'Figure 9.27: Comparing the results of Activity 9.01 and Activity 9.02'
  id: totrans-783
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.27：比较活动9.01与活动9.02的结果
- en: Note
  id: totrans-784
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2YTpxR7](https://packt.live/2YTpxR7).
  id: totrans-785
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该特定部分的源代码，请参考[https://packt.live/2YTpxR7](https://packt.live/2YTpxR7)。
- en: You can also run this example online at [https://packt.live/3dY5Bku](https://packt.live/3dY5Bku).
  id: totrans-786
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个示例，网址是[https://packt.live/3dY5Bku](https://packt.live/3dY5Bku)。
- en: 'Activity 9.03: Predicting the Trend of Amazon''s Stock Price Using an LSTM
    with an Increasing Number of LSTM Neurons (100 Units)'
  id: totrans-787
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 9.03：使用增加数量的LSTM神经元（100个单元）预测亚马逊股票价格的趋势
- en: 'In this activity, we will examine the stock price of Amazon over the last 5
    years, from January 1, 2014, to December 31, 2018\. We will try to predict and
    forecast the company''s future trend for January 2019 using `RNNs` with four `LSTM`
    layers, each with `100` units. We have the actual values for January 2019, so
    we will be able to compare our predictions with the actual values later. You can
    also compare the output difference with *Activity 9.01*, *Predicting the Trend
    of Amazon''s Stock Price Using an LSTM with 50 Units (Neurons)*. Follow these
    steps to complete this activity:'
  id: totrans-788
  prefs: []
  type: TYPE_NORMAL
  zh: 在此活动中，我们将分析亚马逊过去 5 年（2014年1月1日到2018年12月31日）的股价。我们将使用四个 `LSTM` 层的 `RNN`，每个层有
    `100` 个单元，尝试预测并预测 2019 年 1 月的公司未来趋势。我们已知 2019 年 1 月的实际股价，因此之后可以将我们的预测与实际值进行对比。你也可以将输出差异与
    *活动 9.01*，*使用 50 个单元（神经元）的 LSTM 预测亚马逊股价趋势* 进行比较。按照以下步骤完成此活动：
- en: 'Import the required libraries:'
  id: totrans-789
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库：
- en: '[PRE223]'
  id: totrans-790
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE223]'
- en: 'Import the dataset using the pandas `read_csv` function and look at the first
    five rows of the dataset using the `head` method:'
  id: totrans-791
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 pandas 的 `read_csv` 函数导入数据集，并使用 `head` 方法查看数据集的前五行：
- en: '[PRE224]'
  id: totrans-792
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE224]'
- en: 'We are going to make our prediction using the `Open` stock price; therefore,
    select the `Open` stock price column from the dataset and print the values:'
  id: totrans-793
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用 `Open` 股票价格进行预测；因此，从数据集中选择 `Open` 股票价格列并打印值：
- en: '[PRE225]'
  id: totrans-794
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE225]'
- en: 'Then, perform feature scaling by normalizing the data using `MinMaxScaler`
    and setting the range of the features so that they have a minimum value of zero
    and a maximum value of one. Use the `fit_transform` method of the scaler on the
    training data:'
  id: totrans-795
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，使用 `MinMaxScaler` 对数据进行特征缩放，并设置特征的范围，使其最小值为零，最大值为一。对训练数据使用 `fit_transform`
    方法：
- en: '[PRE226]'
  id: totrans-796
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE226]'
- en: 'Create the data to get `60` timestamps from the current instance. We chose
    `60` here as it will give us a sufficient number of previous instances in order
    to understand the trend; technically, this can be any number, but `60` is the
    optimal value. Additionally, the upper bound value here is `1258`, which is the
    index or count of rows (or records) in the training set:'
  id: totrans-797
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建数据，从当前实例获取 `60` 个时间戳。我们选择 `60`，因为它能为我们提供足够的前期数据，以帮助理解趋势；技术上讲，这个数字可以是任何值，但
    `60` 是最佳值。此外，这里的上界值为 `1258`，即训练集中行（或记录）的索引或数量：
- en: '[PRE227]'
  id: totrans-798
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE227]'
- en: 'Reshape the data to add an extra dimension to the end of `X_train` using NumPy''s
    `reshape` function:'
  id: totrans-799
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重塑数据，通过使用 NumPy 的 `reshape` 函数，在 `X_train` 末尾添加一个额外的维度：
- en: '[PRE228]'
  id: totrans-800
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE228]'
- en: 'Import the following Keras libraries to build the RNN:'
  id: totrans-801
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入以下 Keras 库以构建 RNN：
- en: '[PRE229]'
  id: totrans-802
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE229]'
- en: 'Set the seed and initiate the sequential model:'
  id: totrans-803
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置种子并初始化顺序模型：
- en: '[PRE230]'
  id: totrans-804
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE230]'
- en: 'Add an LSTM layer to the network with `100` units, set the `return_sequences`
    argument to `True`, and set the `input_shape` argument to `(X_train.shape[1],
    1)`. Add three additional `LSTM` layers, each with `100` units, and set the `return_sequences`
    argument to `True` for the first two. Add a final output layer of size `1`:'
  id: totrans-805
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向网络中添加一个 `100` 单元的 LSTM 层，将 `return_sequences` 参数设置为 `True`，并将 `input_shape`
    参数设置为 `(X_train.shape[1], 1)`。再添加三个 `LSTM` 层，每个层有 `100` 个单元，前两个层的 `return_sequences`
    参数设置为 `True`。最后添加一个大小为 `1` 的输出层：
- en: '[PRE231]'
  id: totrans-806
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE231]'
- en: 'Compile the network with an `adam` optimizer and use `Mean Squared Error` for
    the loss. Fit the model to the training data for `100` epochs with a batch size
    of `32`:'
  id: totrans-807
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `adam` 优化器编译网络，并使用 `均方误差（Mean Squared Error）` 作为损失函数。将模型拟合到训练数据上，训练 `100`
    个周期，批量大小为 `32`：
- en: '[PRE232]'
  id: totrans-808
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE232]'
- en: 'Load and process the test data (which is treated as actual data here) and select
    the column representing the value of open stock data:'
  id: totrans-809
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载并处理测试数据（这里视为实际数据），并选择表示开盘股价数据的列：
- en: '[PRE233]'
  id: totrans-810
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE233]'
- en: 'Concatenate the data since we will need `60` previous instances to get the
    stock price for each day. Therefore, we will need both the training and test data:'
  id: totrans-811
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合并数据，因为我们需要 `60` 个前期数据来获取每天的股价。因此，我们将需要训练数据和测试数据：
- en: '[PRE234]'
  id: totrans-812
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE234]'
- en: 'Reshape and scale the input to prepare the test data. Note that we are predicting
    the January monthly trend, which has `21` financial days, so in order to prepare
    the test set, we take the lower bound value as `60` and the upper bound value
    as `81`. This ensures that the difference of `21` is maintained:'
  id: totrans-813
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重塑并缩放输入数据以准备测试数据。请注意，我们预测的是一月的月度趋势，`21` 个交易日，因此，为了准备测试集，我们将下界值设置为 `60`，上界值设置为
    `81`。这确保了 `21` 的差值得以保持：
- en: '[PRE235]'
  id: totrans-814
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE235]'
- en: 'Visualize the results by plotting the actual stock price and plotting the predicted
    stock price:'
  id: totrans-815
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过绘制实际股价和预测股价来可视化结果：
- en: '[PRE236]'
  id: totrans-816
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE236]'
- en: Please note that your results may differ slightly from the actual stock price.
  id: totrans-817
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请注意，你的结果可能会与实际股价略有不同。
- en: '**Expected output**:'
  id: totrans-818
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**预期输出**：'
- en: '![Figure 9.28: Real versus predicted stock prices'
  id: totrans-819
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 9.28：实际股票价格与预测股票价格](img/B15777_09_28.jpg)'
- en: '](img/B15777_09_28.jpg)'
  id: totrans-820
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_09_28.jpg)'
- en: 'Figure 9.28: Real versus predicted stock prices'
  id: totrans-821
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.28：实际股票价格与预测股票价格
- en: 'So, if we compare the results of the `LSTM` with `50` units (from *Activity
    9.01*, *Predicting the Trend of Amazon''s Stock Price Using an LSTM with 50 Units
    (Neurons)*) and the `LSTM` with `100` units in this activity, we get trends with
    `100` units. Also, note that when we run the `LSTM` with `100` units, it takes
    more computational time than the `LSTM` with `50` units. A trade-off needs to
    be considered in such cases:'
  id: totrans-822
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们将本节中的`LSTM`（50个单元，来自*活动9.01*，*使用50个单元（神经元）的LSTM预测亚马逊股票价格趋势*）与`LSTM`（100个单元）进行比较，我们会得到100个单元的趋势。另外，请注意，当我们运行`LSTM`（100个单元）时，它比运行`LSTM`（50个单元）需要更多的计算时间。在这种情况下需要考虑权衡：
- en: '![Figure 9.29: Comparing the real versus predicted stock price with 50 and
    100 units'
  id: totrans-823
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 9.29：比较50个和100个单元的实际股票价格与预测股票价格](img/B15777_09_29.jpg)'
- en: '](img/B15777_09_29.jpg)'
  id: totrans-824
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_09_29.jpg)'
- en: 'Figure 9.29: Comparing the real versus predicted stock price with 50 and 100
    units'
  id: totrans-825
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.29：比较50个和100个单元的实际股票价格与预测股票价格
- en: Note
  id: totrans-826
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/31NQkQy](https://packt.live/31NQkQy).
  id: totrans-827
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参阅 [https://packt.live/31NQkQy](https://packt.live/31NQkQy)。
- en: You can also run this example online at [https://packt.live/2ZCZ4GR](https://packt.live/2ZCZ4GR).
  id: totrans-828
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在网上运行此示例，访问 [https://packt.live/2ZCZ4GR](https://packt.live/2ZCZ4GR)。
