- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Mastering Rule-Based Matching
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 掌握基于规则的匹配
- en: Rule-based information extraction is indispensable for any **natural language
    processing** ( **NLP** ) pipeline. Certain types of entities, such as times, dates,
    and telephone numbers, have distinct formats that can be recognized by a set of
    rules without having to train statistical models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 基于规则的实体抽取对于任何自然语言处理（NLP）流程都是必不可少的。某些类型的实体，如时间、日期和电话号码，具有独特的格式，可以通过一组规则进行识别，而无需训练统计模型。
- en: In this chapter, you will learn how to quickly extract information from text
    by matching patterns and phrases. You will use **morphological** **features**
    , **parts-of-speech** ( **POS** ) tags, **regular expressions** ( **regexes**
    ), and other spaCy features to form pattern objects to feed to **Matcher** objects.
    You will continue with fine-graining statistical models with rule-based matching
    to lift statistical models to better accuracies.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何通过匹配模式和短语快速从文本中提取信息。你将使用 **形态学** **特征**、**词性**（**POS**）标签、**正则表达式**（**regexes**）以及其他
    spaCy 特征来形成模式对象，并将其提供给 **Matcher** 对象。你将继续使用基于规则的匹配进行细粒度统计模型，以提高统计模型的准确性。
- en: By the end of this chapter, you will know about a vital part of information
    extraction. You will also be able to extract entities of specific formats, as
    well as entities specific to your domain.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将了解信息提取的一个关键部分。你还将能够提取特定格式的实体，以及特定领域的实体。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Token-based matching
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于标记的匹配
- en: Creating patterns with **PhraseMatcher**
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 **PhraseMatcher** 创建模式
- en: Creating patterns with **SpanRuler**
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 **SpanRuler** 创建模式
- en: Combining spaCy models and matchers
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合 spaCy 模型和匹配器
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: The code of this chapter can be found at [https://github.com/PacktPublishing/Mastering-spaCy-Second-Edition](https://github.com/PacktPublishing/Mastering-spaCy-Second-Edition)
    . We are using **Python 3.10** and **spaCy 3.7.4** .
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在[https://github.com/PacktPublishing/Mastering-spaCy-Second-Edition](https://github.com/PacktPublishing/Mastering-spaCy-Second-Edition)找到。我们使用
    **Python 3.10** 和 **spaCy 3.7.4**。
- en: Token-based matching
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于标记的匹配
- en: Some NLU tasks can be solved without the help of any statistical model. One
    of those ways is a **regex** , which we use to match a predefined set of patterns
    to our text.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一些自然语言理解（NLU）任务可以在不借助任何统计模型的情况下解决。其中一种方法就是使用 **正则表达式**，我们用它来将预定义的模式集与我们的文本进行匹配。
- en: A regex is a sequence of characters that specifies a search pattern. A regex
    describes a set of strings that follows the specified pattern. These patterns
    can include letters, digits, and characters with special meanings, such as **?**
    , **.** , and ***** . Python’s built-in library, **re** , provides great support
    to define and match regexes.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式是一系列字符，用于指定搜索模式。正则表达式描述了一组遵循指定模式的字符串。这些模式可以包括字母、数字和具有特殊意义的字符，如 **?**、**.**
    和 *****。Python 内置库 **re** 提供了强大的支持来定义和匹配正则表达式。
- en: 'What does a regex look like, then? The following regex matches the following
    strings:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，正则表达式看起来是什么样子呢？以下正则表达式匹配以下字符串：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This pattern can be read as follows: the string **Barack** can be followed
    optionally by the string **Hussein** (the **?** character in a regex means optional;
    that is, **0** or **1** occurrence) and should be followed by the string **Obama**
    . The inter-word spaces can be a single-space character, a tab, or any other whitespace
    character ( **\s** matches all sorts of whitespace characters, including the newline
    character).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模式可以这样读取：字符串 **Barack** 可以可选地后跟字符串 **Hussein**（正则表达式中的 **?** 字符表示可选；即 **0**
    或 **1** 次出现）并且应该后跟字符串 **Obama**。单词间的空格可以是一个空格字符、一个制表符或任何其他空白字符（**\s** 匹配所有类型的空白字符，包括换行符）。
- en: 'It’s not very readable, even for such a short and uncomplicated pattern, is
    it? Some downsides of regexes are as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是如此简短且简单的模式，也不太易读，对吧？正则表达式的缺点如下：
- en: Difficult to read
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 难以阅读
- en: Difficult to debug
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试困难
- en: Error-prone with space, punctuation, and number characters
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空格、标点符号和数字字符容易出错
- en: 'For these reasons, many software engineers don’t like to work with regexes
    in their production code. spaCy provides a very clean, readable, production-level,
    and maintainable alternative: the **Matcher** class. The **Matcher** class can
    match our predefined rules to the sequence of tokens in **Doc** and **Span** objects.
    As we will see in this chapter, the rules can also refer to the token or its linguistic
    attributes.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些原因，许多软件工程师不喜欢在生产代码中使用正则表达式。spaCy提供了一个非常干净、易读、生产级和可维护的替代方案：**Matcher** 类。**Matcher**
    类可以将我们预定义的规则与 **Doc** 和 **Span** 对象中的标记序列进行匹配。正如我们将在本章中看到的，规则还可以引用标记或其语言属性。
- en: 'Let’s start with a basic example of how to call the **Matcher** class:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从如何调用 **Matcher** 类的基本示例开始：
- en: 'First, we import the library, the **Matcher** object, the **Span** token, and
    load the model:'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们导入库、**Matcher** 对象、**Span** 标记，并加载模型：
- en: '[PRE1]'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, we instantiate the **Matcher** object passing the vocabulary of the model,
    define a pattern, and add it to the **Matcher** object with the label **morningGreeting**
    :'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们实例化 **Matcher** 对象，传入模型的词汇表，定义一个模式，并将其以标签 **morningGreeting** 添加到 **Matcher**
    对象中：
- en: '[PRE2]'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Finally, we can process the text. To visualize the **Span** objects with **displaCy**
    , we will add the **Span** objects to a list and attribute **doc.spans["sc"]**
    to this list. The **sc** instance is the default **span_key** value (group of
    arbitrary **Span** objects). Here is the code:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以处理文本。为了使用 displaCy 可视化 **Span** 对象，我们将 **Span** 对象添加到列表中，并将 **doc.spans["sc"]**
    赋值给此列表。**sc** 实例是默认的 **span_key** 值（任意 **Span** 对象的组）。以下是代码：
- en: '[PRE3]'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, let’s show the spans with **displacy** :'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用 **displacy** 显示 spans：
- en: '[PRE4]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Figure 4* *.1* shows the result of the previous code block:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4* *.1* 展示了上一段代码块的结果：'
- en: '![Figure 4.1 – Span matches of our first Matcher pattern](img/B22441_04_01.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.1 – 第一个 Matcher 模式的 Span 匹配](img/B22441_04_01.jpg)'
- en: Figure 4.1 – Span matches of our first Matcher pattern
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1 – 第一个 Matcher 模式的 Span 匹配
- en: 'You can read the **Matcher** pattern of the preceding *step 2* list as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按以下方式读取前一个 *步骤 2* 列表中的 **Matcher** 模式：
- en: A token whose lowered text is **good**
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个文本转换为小写后为 **good** 的标记
- en: A token whose lowered text is **morning**
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个文本转换为小写后为 **morning** 的标记
- en: A token that is punctuation (that is, the **IS_PUNCT** feature is **True** )
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个标点符号（即，**IS_PUNCT** 特征为 **True**）
- en: A match result is a list of triplets in the form **(match id** , **start position**
    , and **end position)** . As you might have noticed, the whitespace between **Good**
    and **morning** didn’t matter at all. Indeed, we could have put two whitespaces
    in between, written down **Good morning** , and the result would be identical.
    Why? Because **Matcher** matches only tokens and token attributes.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配结果是一个三元组列表，形式为 **(match id**，**起始位置**，和 **结束位置**）。你可能已经注意到，**Good** 和 **morning**
    之间的空白根本不重要。事实上，我们可以在它们之间放两个空格，写下 **Good morning**，结果将是相同的。为什么？因为 **Matcher** 只匹配标记和标记属性。
- en: 'A pattern always refers to a continuous sequence of token objects, and every
    item in bracelets corresponds to one token object. Let’s go back to the pattern
    in the preceding code snippet:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 模式始终引用标记对象的连续序列，并且每个括号中的项对应一个标记对象。让我们回到前面代码片段中的模式：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The result is always a three-token match. Can we add more than one pattern?
    The answer is yes. Let’s see it with an example, as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 结果始终是三个标记的匹配。我们能否添加多个模式？答案是肯定的。让我们通过以下示例看看：
- en: 'Import the libraries and set the **Matcher** object just as before:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如前所述，导入库并设置 **Matcher** 对象：
- en: '[PRE6]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Define the two patterns and add them to the **Matcher** object:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义两个模式并将它们添加到 **Matcher** 对象中：
- en: '[PRE7]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Process the text, send the **doc** object to the **Matcher** object and store
    the **Span** objects in a list:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理文本，将 **doc** 对象发送到 **Matcher** 对象，并将 **Span** 对象存储在列表中：
- en: '[PRE8]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, we can display the **Span** objects with displacy:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 displacy 显示 **Span** 对象：
- en: '[PRE9]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '*Figure 4* *.2* shows the result using the new pattern:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4* *.2* 展示了使用新模式的匹配结果：'
- en: '![Figure 4.2 – Span matches using two patterns](img/B22441_04_02.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.2 – 使用两种模式进行 Span 匹配](img/B22441_04_02.jpg)'
- en: Figure 4.2 – Span matches using two patterns
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 使用两种模式进行 Span 匹配
- en: 'In the preceding code example, **pattern1** and **pattern2** differ only by
    one token: **evening** / **morning** . Instead of writing two patterns, can we
    say evening or morning using the **IN** attribute. Let’s learn more about it in
    the next section.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码示例中，**pattern1** 和 **pattern2** 只在单个标记上有所不同：**evening** / **morning**。我们是否可以用
    **IN** 属性来表示晚上或早上，而不是编写两个模式？让我们在下一节中了解更多。
- en: Extended syntax support
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展语法支持
- en: '**Matcher** allows patterns to be more expressive by allowing some operators
    inside the curly braces. These operators are for extended comparison and look
    similar to Python’s **in** , **not in** , and **comparison** operators. You can
    see a full list of attributes in spaCy’s documentation, available at [https://spacy.io/api/matcher/#patterns](https://spacy.io/api/matcher/#patterns)
    . Previously we matched **good evening** and **good morning** with two different
    patterns. Now, we can match **good morning** / **evening** with one pattern with
    the help of **IN** as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**Matcher** 允许在花括号内使用一些运算符，从而使模式更加丰富。这些运算符用于扩展比较，类似于 Python 的 **in**、**not
    in** 和 **比较** 运算符。您可以在 spaCy 的文档中查看完整的属性列表，文档可在 [https://spacy.io/api/matcher/#patterns](https://spacy.io/api/matcher/#patterns)
    找到。之前我们使用两个不同的模式匹配了 **good evening** 和 **good morning**。现在，我们可以通过使用 **IN** 来匹配
    **good morning** / **evening**，如下所示：'
- en: '[PRE10]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Comparison operators usually go together with the **LENGTH** attribute. Here’s
    an example of finding long tokens:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 比较运算符通常与 **LENGTH** 属性一起使用。以下是一个查找长标记的示例：
- en: '[PRE11]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*Figure 4* *.3* shows the matches using this pattern:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4* *.3* 展示了使用此模式的匹配结果：'
- en: '![Figure 4.3 – Matches using LENGTH pattern](img/B22441_04_03.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.3 – 使用 LENGTH 模式匹配的结果](img/B22441_04_03.jpg)'
- en: Figure 4.3 – Matches using LENGTH pattern
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.3 – 使用 LENGTH 模式匹配的结果
- en: In the next section, we will explore some of the most used token attributes
    used to create patterns.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨一些最常用的标记属性，这些属性用于创建模式。
- en: Token attributes
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标记属性
- en: 'Let’s go over some useful token pattern keys with examples. We used **LOWER**
    in the preceding examples; it means the lowercase form of the token text. **ORTH**
    and **TEXT** are similar to **LOWER** : they mean an exact match of the token
    text, including the case. Here’s an example:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一些示例来回顾一些有用的标记模式键。在前面的例子中我们使用了 **LOWER**；它表示标记文本的小写形式。**ORTH** 和 **TEXT**
    与 **LOWER** 类似：它们表示对标记文本的精确匹配，包括大小写。以下是一个示例：
- en: '[PRE12]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The preceding code will match **Bill** but not **bill** .
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将匹配 **Bill** 但不会匹配 **bill**。
- en: 'The next block of token attributes is **IS_ALPHA** , **IS_ASCII** , and **IS_DIGIT**
    . These features are handy for finding number tokens and ordinary words. The following
    pattern matches a sequence of two tokens, a number followed by an ordinary word:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个标记属性块是 **IS_ALPHA**、**IS_ASCII** 和 **IS_DIGIT**。这些特性对于查找数字标记和普通单词很有用。以下模式匹配两个标记的序列，一个数字后面跟一个普通单词：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'In the preceding code segment, **2 o''clock** didn’t match the pattern because
    **o''clock** contains an apostrophe, which is not an alphabetic character (alphabetic
    characters are digits, letters, and the underscore character). Let’s test the
    pattern using another sentence:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码段中，**2 o'clock** 没有匹配到模式，因为 **o'clock** 包含撇号，这不是一个字母字符（字母字符是数字、字母和下划线字符）。让我们使用另一个句子来测试这个模式：
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '*Figure 4* *.4* shows that **2 apples** matched because the **apples** token
    consists of letters:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4* *.4* 显示了 **2 个苹果** 匹配的原因是 **apples** 标记由字母组成：'
- en: '![Figure 4.4 – Match using number and plain word pattern](img/B22441_04_04.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4 – 使用数字和平常单词模式匹配](img/B22441_04_04.jpg)'
- en: Figure 4.4 – Match using number and plain word pattern
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – 使用数字和平常单词模式匹配
- en: '**IS_LOWER** , **IS_UPPER** , and **IS_TITLE** are useful attributes for recognizing
    the token’s casing. **IS_UPPER** is **True** if the token is all uppercase letters,
    and **IS_TITLE** is **True** if the token starts with a capital letter. **IS_LOWER**
    is **True** if the token is all lowercase letters. Imagine we want to find emphasized
    words in a text; one way is to look for tokens with all uppercase letters. Uppercase
    tokens usually have significant weights in sentiment analysis models. Here is
    an example:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**IS_LOWER**、**IS_UPPER** 和 **IS_TITLE** 是用于识别标记大小写的有用属性。如果标记全部为大写字母，则 **IS_UPPER**
    为 **True**；如果标记以大写字母开头，则 **IS_TITLE** 为 **True**。如果标记全部为小写字母，则 **IS_LOWER** 为
    **True**。想象一下，如果我们想在文本中找到强调的单词；一种方法就是寻找全部为大写字母的标记。大写标记通常在情感分析模型中具有显著的重要性。以下是一个示例：'
- en: '[PRE15]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '**IS_PUNCT** , **IS_SPACE** , and **IS_STOP** are usually used in patterns
    that include some helper tokens and correspond to punctuation, space, and stopword
    tokens (stopwords are common words of a language that do not carry much information,
    such as *a* , *an* , and *the* in English). **IS_SENT_START** is another useful
    attribute; it matches sentence start tokens. Here’s a pattern for sentences that
    start with the word *can* and the second word has a capitalized first letter:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**IS_PUNCT**、**IS_SPACE** 和 **IS_STOP** 通常用于包含一些辅助标记的模式中，分别对应于标点符号、空格和停用词标记（停用词是语言中不携带太多信息的常见单词，例如英语中的
    *a*、*an* 和 *the*）。**IS_SENT_START** 是另一个有用的属性；它匹配句子开头的标记。以下是一个以单词 *can* 开头且第二个单词首字母大写的句子模式：'
- en: 'In this pattern, we will put two attributes into one brace. The first item
    in **pattern** means that a token that is the first token of the sentence and
    whose lowered text is **can** :'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个模式中，我们将把两个属性放入一个大括号中。**pattern** 中的第一个项目意味着一个标记是句子的第一个标记，并且其小写文本为 **can**：
- en: '[PRE16]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we process the text and show the matches:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们处理文本并显示匹配结果：
- en: '[PRE17]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '*Figure 4* *.5* shows the matches of the preceding list:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4* *.5* 显示了前面列表的匹配结果：'
- en: '![Figure 4.5 – Match using two tokens](img/B22441_04_05.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图4.5 – 使用两个标记进行匹配](img/B22441_04_05.jpg)'
- en: Figure 4.5 – Match using two tokens
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 – 使用两个标记进行匹配
- en: 'We can add as many attributes to the braces as we like. For instance, **{"IS_SENT_START":
    False, "IS_TITLE": True, "LOWER": "bill"}** is a completely v alid attribute dictionary,
    and it describes a token that is capitalized, not the first token of the sentence,
    and has the text **bill** . So, it is the set of **bill** instances that do not
    appear as the first word of a sentence.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '我们可以给大括号添加任意多的属性。例如，**{"IS_SENT_START": False, "IS_TITLE": True, "LOWER": "bill"}**
    是一个完全有效的属性字典，它描述了一个大写字母开头、不是句子第一个标记，并且文本为 **bill** 的标记。因此，它是那些作为句子第一个单词不出现的 **bill**
    实例的集合。'
- en: '**LIKE_NUM** , **LIKE_URL** , and **LIKE_EMAIL** are attributes that are related
    to token shape; – we discussed them in [*Chapter 3*](B22441_03.xhtml#_idTextAnchor045)
    . These attributes match tokens that look like numbers, URLs, and emails.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**LIKE_NUM**、**LIKE_URL** 和 **LIKE_EMAIL** 是与标记形状相关的属性；我们在 [*第3章*](B22441_03.xhtml#_idTextAnchor045)
    中讨论了它们。这些属性匹配看起来像数字、URL和电子邮件的标记。'
- en: 'Now, let’s see the **POS** , **TAG** , **DEP** , **LEMMA** , and **SHAPE**
    linguistic attributes. You saw these token attributes in the previous chapter;
    now, we’ll use them in token matching. The following code snippet spots sentences
    that start with an auxiliary verb:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看 **POS**、**TAG**、**DEP**、**LEMMA** 和 **SHAPE** 语言属性。您在上一章中看到了这些标记属性；现在，我们将使用它们进行标记匹配。以下代码片段查找以助动词开头的句子：
- en: '[PRE18]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**MD** is the tag for modal and auxiliary verbs. The preceding code snippet
    is a standard way of finding yes/no question sentences. In such cases, we usually
    look for sentences that start with a modal or an auxiliary verb.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**MD** 是情态动词和助动词的标记。前面的代码片段是查找是/否疑问句的标准方法。在这种情况下，我们通常寻找以情态动词或助动词开头的句子。'
- en: 'When we want to extract the meaning of a word, we usually combine **TEXT/LEMMA**
    with **POS/TAG** . For instance, the word match is to go together when it’s a
    verb, or it can be a fire starter tool when it’s a noun. In this case, we make
    the distinction as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要提取一个单词的含义时，我们通常将 **TEXT/LEMMA** 与 **POS/TAG** 结合。例如，当 match 是动词时，它需要与 **POS/TAG**
    结合，或者当它是名词时，它可以是一个点火工具。在这种情况下，我们做出以下区分：
- en: '**{"LEMMA": "match", "** **POS": "VERB"}**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**{"LEMMA": "match", "** **POS": "VERB"}**'
- en: '**{"LEMMA": "match", "** **POS": "NOUN"}**'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**{"LEMMA": "match", "** **POS": "NOUN"}**'
- en: Similarly, you can combine other linguistic features with token shape attributes
    to make sure that you extract only the pattern you mean to.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你可以将其他语言特征与标记形状属性结合，以确保只提取你想要的模式。
- en: 'We’ll see more examples of combining linguistic features with the **Matcher**
    class in the upcoming sections. Now, we’ll move on to another very practical feature
    of **Matcher** patterns: regex-like operators.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将看到更多将语言特征与 **Matcher** 类结合的示例。现在，我们将继续探讨 **Matcher** 模式的一个非常实用的特性：类似正则表达式的操作符。
- en: Regex-like operators
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 类似正则表达式的操作符
- en: 'At the beginning of the chapter, we pointed out that spaCy’s **Matcher** class
    offers a cleaner and more readable equivalent to regex operations, indeed much
    cleaner and much more readable. The most common regex operations are optional
    match ( **?** ), match at least once ( **+** ), and match 0 or more times ( *****
    ). You can see a full list of spaCy’s **Matcher** operators here: [https://spacy.io/api/matcher/#patterns](https://spacy.io/api/matcher/#patterns)
    . The very first example regex of this chapter was matching Barack Obama’s first
    name, with the middle name being optional. The regex was as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的开头，我们指出spaCy的**Matcher**类提供了对正则表达式操作的更干净、更易读的等效方法，确实更干净、更易读。最常见的正则表达式操作是可选匹配（**?**）、至少匹配一次（**+**）和匹配0次或多次（*****）。您可以在以下位置查看spaCy的**Matcher**运算符的完整列表：[https://spacy.io/api/matcher/#patterns](https://spacy.io/api/matcher/#patterns)。本章的第一个正则表达式示例是匹配Barack
    Obama的名字，中间名是可选的。正则表达式如下：
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The **?** operator after **Hussein** means the pattern in the brackets is optional,
    hence this regex matches both **Barack Obama** and **Barack Hussein Obama** .
    We use the **?** operator in a **Matcher** pattern as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**?**运算符在**Hussein**之后表示括号内的模式是可选的，因此这个正则表达式可以匹配**Barack Obama**和**Barack Hussein
    Obama**。我们在**Matcher**模式中使用**?**运算符如下：'
- en: '[PRE20]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Here, by using **"OP": "?"** in the second list item, we made this token optional.
    The matcher picked **Barack Obama** in the first **doc** object and **Barack Hussein
    Obama** in the second one, as you can see in *Figure 4* *.6* :'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '在这里，通过在第二个列表项中使用**"OP": "?"**，我们使这个标记可选。匹配器选择了第一个**doc**对象中的**Barack Obama**和第二个中的**Barack
    Hussein Obama**，正如你在*图4* *.6*中可以看到：'
- en: '![Figure 4.6 – Matches using regex](img/B22441_04_06.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图4.6 – 使用正则表达式进行匹配](img/B22441_04_06.jpg)'
- en: Figure 4.6 – Matches using regex
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6 – 使用正则表达式进行匹配
- en: 'We previously pointed out that the **+** and ***** operators have the same
    meaning as their regex counterparts. **+** means the token should occur at least
    once, and ***** means the token can occur 0 or more times. Let’s see some examples:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前指出，**+**和*****运算符与它们的正则表达式对应物具有相同的意义。**+**表示标记至少出现一次，而*****表示标记可以出现0次或多次。让我们看看一些例子：
- en: '[PRE21]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '*Figure 4* *.7* shows what happens when we use the **+** operator:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4* *.7*显示了当我们使用**+**运算符时会发生什么：'
- en: '![Figure 4.7 – Matches using the + operator](img/B22441_04_07.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图4.7 – 使用+运算符进行匹配](img/B22441_04_07.jpg)'
- en: Figure 4.7 – Matches using the + operator
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.7 – 使用+运算符进行匹配
- en: In the pattern, the first token reads as any one of **hello** , **hi** , **hallo**
    should occur one or more times. Notice the greedy nature of the pattern (each
    **hello** instance gets a match). The second doc also has a match, but the third
    one doesn’t (since it does not have any of the **hello** , **hi** , or **hallo**
    words).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在模式中，第一个标记读作**hello**、**hi**或**hallo**中的任何一个，应该出现一次或多次。注意模式的贪婪性质（每个**hello**实例都得到匹配）。第二个doc也有匹配，但第三个没有（因为它没有**hello**、**hi**或**hallo**中的任何词）。
- en: When we come to the results of the first doc objects matches, we see that there
    are not one but three distinct matches. This is completely normal because there
    are indeed three sequences matching the pattern. If you have a closer look at
    the match results, all of them match the pattern we created, because they all
    match the **(** **hello)+** pattern.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看第一个doc对象匹配的结果时，我们看到不仅有一次，而是有三个不同的匹配。这是完全正常的，因为确实有三个序列与模式匹配。如果你仔细查看匹配结果，你会发现它们都匹配我们创建的模式，因为它们都匹配**(**
    **hello)+**模式。
- en: 'Let’s do the same pattern with ***** and see what happens this time:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用*****来做同样的模式，看看这次会发生什么：
- en: '[PRE22]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '*Figure 4* *.8* shows the results:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4* *.8*显示了结果：'
- en: '![Figure 4.8 – Matches using the * operator](img/B22441_04_08.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图4.8 – 使用*运算符进行匹配](img/B22441_04_08.jpg)'
- en: Figure 4.8 – Matches using the * operator
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8 – 使用*运算符的匹配
- en: Now, punctuation marks alone without a greeting word are picked. This is not
    what you want in your NLP applications, probably.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，仅凭标点符号而没有问候词被选中。这可能不是你希望在NLP应用中看到的情况。
- en: The preceding example is a good example that we should be careful of while creating
    our patterns; sometimes, we get unwanted matches. For this reason, we usually
    consider using **IS_SENT_START** and take care of the rest with the ***** operator.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 上述例子是一个很好的例子，说明我们在创建模式时应该小心；有时我们会得到不想要的匹配。因此，我们通常考虑使用**IS_SENT_START**并使用*****运算符来处理其余部分。
- en: 'The spaCy **Matcher** class also accepts a very special pattern, a wildcard
    token pattern. A wildcard token will match any token. We usually use it for words
    we want to pick independent from their text or attributes or for words we ignore.
    Let’s see an example:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: spaCy **Matcher**类还接受一个非常特殊的模式，即通配符标记模式。通配符标记将匹配任何标记。我们通常用它来选择我们想要独立于它们的文本或属性或忽略的单词。让我们看一个例子：
- en: '[PRE23]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Here, we wanted to capture the first names in the sentence. We achieved it
    by parsing out token sequences in the form **name is/was/be firstname** . The
    first token pattern, **LOWER: "name"** , matches the tokens whose lowered text
    is **name** . The second token pattern, **LEMMA: "be"** , matches the **is** ,
    **was** , and **be** tokens. The third token is the wildcard token, **{}** , which
    means any token. We pick up any token that comes after **name is/was/be** with
    this pattern. *Figure 4* *.9* shows the results:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '在这里，我们想要捕捉句子中的名字。我们通过解析形式为**name is/was/be firstname**的标记序列实现了这一点。第一个标记模式，**LOWER:
    "name"**，匹配文本小写后的文本为**name**的标记。第二个标记模式，**LEMMA: "be"**，匹配**is**、**was**和**be**标记。第三个标记是通配符标记，**{}**，表示任何标记。我们使用这个模式拾取任何在**name
    is/was/be**之后的标记。*图4.9* *.9*显示了结果：'
- en: '![Figure 4.9 – Matches using wildcard token](img/B22441_04_09.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图4.9 – 使用通配符标记的匹配](img/B22441_04_09.jpg)'
- en: Figure 4.9 – Matches using wildcard token
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.9 – 使用通配符标记的匹配
- en: 'We also use a wildcard token when we want to ignore a token. Let’s make an
    example together:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要忽略一个标记时，我们也会使用通配符标记。让我们一起来做一个例子：
- en: '[PRE24]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: It’s just the opposite of the previous example. Here, we wanted to pick up **forward
    email** sequences, and we allowed that one token to come between **forward** and
    **email** . In this case, the semantically important part is the forwarding an
    email action; whose email is it doesn’t matter much.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这与前面的例子正好相反。在这里，我们想要捕捉**forward email**序列，并且允许一个标记在**forward**和**email**之间。在这种情况下，语义上重要的部分是转发电子邮件的动作；它是谁的电子邮件并不重要。
- en: We have mentioned regexes quite a lot in this chapter so far, so now, it’s time
    to see how spaCy’s **Matcher** class makes use of regex syntax.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经在本章中提到了很多正则表达式，现在是时候看看spaCy的**Matcher**类如何使用正则表达式语法了。
- en: Regex support
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则表达式支持
- en: 'When we match individual tokens, usually we want to allow some variations,
    such as common typos, UK/US English character differences, and so on. Regexes
    are very handy for this task, and spaCy **Matcher** offers full support for token-level
    regex matching. Let’s explore how we can use regexes for our applications:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们匹配单个标记时，通常我们想要允许一些变化，例如常见的拼写错误、UK/US英语字符差异等。正则表达式非常适合这项任务，spaCy **Matcher**提供了对标记级正则表达式匹配的全支持。让我们探索如何为我们自己的应用使用正则表达式：
- en: '[PRE25]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Here, our second token pattern is **[Tt]ravell?ed** , which means the token
    can be capitalized or not. Also, there’s an optional **l** instance after the
    first **l** instance. Allowing twin vowels and ise/ize alteration is a standard
    way of dealing with British and American English variations.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们的第二个标记模式是**[Tt]ravell?ed**，这意味着标记可以是首字母大写也可以不是。此外，在第一个**l**实例之后有一个可选的**l**实例。允许双元音和ise/ize变化是处理英国和美式英语变化的标准方式。
- en: Another way of using regexes is using them not only with text but also with
    POS tags. What does the following code segment do?
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 使用正则表达式还有另一种方式，即不仅与文本一起使用，还与POS标签一起使用。以下代码段做了什么？
- en: '[PRE26]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We have extracted all the finite verbs (you can think of a finite verb as a
    non-modal verb). How did we do it? Our token pattern includes the regex **^V**
    , which means all fine-grained POS tags that start with V: **VB** , **VGD** ,
    **VBG** , **VBN** , **VBP** , and **VBZ** . Then, we extracted tokens with verbal
    POS tags.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提取了所有的有限动词（你可以将有限动词视为非情态动词）。我们是如何做到这一点的呢？我们的标记模式包括正则表达式**^V**，这意味着所有以V开头的细粒度POS标签：**VB**、**VGD**、**VBG**、**VBN**、**VBP**和**VBZ**。然后，我们提取了具有动词POS标签的标记。
- en: Matcher online demo
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Matcher在线演示
- en: 'spaCy **Matcher** offers a tool on its online demo page: [https://explosion.ai/demos/matcher](https://explosion.ai/demos/matcher)
    . We can create patterns and test them against the text we want, interactively.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: spaCy **Matcher**在其在线演示页面上提供了一个工具：[https://explosion.ai/demos/matcher](https://explosion.ai/demos/matcher)。我们可以创建模式并交互式地测试它们与我们要测试的文本。
- en: 'In *Figure 4* *.10* , we can see a match example. On the right side, we can
    select the attributes, values, and operators (such as **+** , ***** , **!** ,
    and **?** ). After making this selection, the demo outputs the corresponding pattern
    string on the right side, below the checkboxes. On the left side, we first choose
    the spaCy language model we want (in this example, English core small), then see
    the results:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *图 4* *.10* 中，我们可以看到一个匹配示例。在右侧，我们可以选择属性、值和运算符（如 **+** 、 ***** 、 **!** 和 **?**）。在做出此选择后，演示在复选框下方右侧输出相应的模式字符串。在左侧，我们首先选择我们想要的
    spaCy 语言模型（在本例中为英语核心小型），然后查看结果：
- en: '![Figure 4.10 – spaCy’s Rule-based Matcher Explorer](img/B22441_04_10.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.10 – spaCy 的基于规则的 Matcher 探索器](img/B22441_04_10.jpg)'
- en: Figure 4.10 – spaCy’s Rule-based Matcher Explorer
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – spaCy 的基于规则的 Matcher 探索器
- en: spaCy’s **Matcher** demo helps you to see why your pattern matched or didn’t
    match.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: spaCy 的 **Matcher** 示例帮助你了解为什么你的模式匹配或未匹配。
- en: Creating patterns with PhraseMatcher
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PhraseMatcher 创建模式
- en: While processing financial, medical, or legal text, we often have long lists
    and dictionaries and we want to scan the text against our lists. As we saw in
    the previous section, **Matcher** patterns are quite handcrafted; we coded each
    token individually. If you have a long list of phrases, **Matcher** is not very
    handy. It’s not possible to code all the terms one by one.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理金融、医疗或法律文本时，我们经常有长列表和字典，我们希望将文本与我们的列表进行扫描。正如我们在上一节中看到的，**Matcher** 模式相当是手工制作的；我们逐个编码每个标记。如果你有一长串短语列表，**Matcher**
    并不很方便。不可能逐个编码所有术语。
- en: 'spaCy offers a solution for comparing text against long dictionaries – the
    **PhraseMatcher** class. The **PhraseMatcher** class helps us match long dictionaries.
    Let’s get started with a basic example of using **PhraseMatcher** to match terms
    defined in a list:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: spaCy 为比较文本与长字典提供了一种解决方案 – **PhraseMatcher** 类。**PhraseMatcher** 类帮助我们匹配长字典。让我们从一个使用
    **PhraseMatcher** 匹配列表中定义的术语的基本示例开始：
- en: 'Import the library and the class and instantiate the **nlp** pipeline as usual:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入库和类，并像往常一样实例化 **nlp** 管道：
- en: '[PRE27]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now we can instantiate the **PhraseMatcher** object and call **nlp.make_doc()**
    on the terms one by one to create patterns:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以实例化 **PhraseMatcher** 对象，并对每个术语逐个调用 **nlp.make_doc()** 来创建模式：
- en: '[PRE28]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Finally, we check the matches:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们检查匹配项：
- en: '[PRE29]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This way, we match the patterns by their exact text values, as shown in *Figure
    4* *.11* :'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们通过它们的精确文本值来匹配模式，如图 *图 4* *.11* 所示：
- en: '![Figure 4.11 – Matches using PhraseMatcher](img/B22441_04_11.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.11 – 使用 PhraseMatcher 进行匹配](img/B22441_04_11.jpg)'
- en: Figure 4.11 – Matches using PhraseMatcher
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.11 – 使用 PhraseMatcher 进行匹配
- en: What if we want to match them with other attributes? Here’s an example of matching
    by the **LOWER** attribute.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想用其他属性进行匹配怎么办？这里是一个通过 **LOWER** 属性进行匹配的示例。
- en: 'First, we create a **PhraseMatcher** instance, passing an additional argument,
    **attr=LOWER** . This way, **PhraseMatcher** uses the **token.lower** attribute
    during the match:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建一个 **PhraseMatcher** 实例，传递一个额外的参数，**attr=LOWER**。这样，**PhraseMatcher**
    在匹配时使用 **token.lower** 属性：
- en: '[PRE30]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, let’s display the results:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们显示结果：
- en: '[PRE31]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '*Figure 4* *.12* shows the match results:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4* *.12* 显示了匹配结果：'
- en: '![Figure 4.12 – Matches using the PhraseMatcher LOWER attribute](img/B22441_04_12.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.12 – 使用 PhraseMatcher LOWER 属性进行匹配](img/B22441_04_12.jpg)'
- en: Figure 4.12 – Matches using the PhraseMatcher LOWER attribute
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.12 – 使用 PhraseMatcher LOWER 属性进行匹配
- en: 'Another possible usage of **PhraseMatcher** is matching the **SHAPE** attribute.
    This matching strategy can be used on system logs, where IP numbers, dates, and
    other numerical values occur a lot. The good thing here is that you do not need
    to worry about how the numbers are tokenized; you just leave it to **PhraseMatcher**
    . Let’s see an example:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**PhraseMatcher** 的另一个可能的用法是匹配 **SHAPE** 属性。这种匹配策略可以用于系统日志，其中 IP 地址、日期和其他数值出现很多。这里的好事是您不必担心数字是如何分词的；您只需将其留给
    **PhraseMatcher**。让我们看一个例子：'
- en: '[PRE32]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '*Figure 4* *.13* shows the results:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4* *.13* 显示了结果：'
- en: '![Figure 4.13 – Matches using the PhraseMatcher SHAPE attribute](img/B22441_04_13.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.13 – 使用 PhraseMatcher SHAPE 属性进行匹配](img/B22441_04_13.jpg)'
- en: Figure 4.13 – Matches using the PhraseMatcher SHAPE attribute
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.13 – 使用 PhraseMatcher SHAPE 属性进行匹配
- en: Handy, right? We matched the tokens and phrases successfully; now, let’s move
    on to **named entity recognition** ( **NER** ). Named entity extraction is an
    essential component of any NLP system, and most of the pipelines you’ll design
    will include an NER component. The next section is devoted to rule-based named
    entity extraction.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 很方便，对吧？我们成功匹配了标记和短语；现在，让我们继续到**命名实体识别**（**NER**）。命名实体提取是任何NLP系统的基本组成部分，你将要设计的多数管道都将包括一个NER组件。下一节将专注于基于规则的命名实体提取。
- en: Creating patterns with SpanRuler
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用SpanRuler创建模式
- en: spaCy’s **SpanRuler** component allows us to add spans to the **Doc.spans**
    and/or **Doc.ents** dictionaries using token-based rules or exact phrase matches.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: spaCy的**SpanRuler**组件允许我们使用基于标记的规则或精确短语匹配将跨度添加到**Doc.spans**和/或**Doc.ents**字典中。
- en: '**SpanRuler** is not a matcher; it’s a pipeline component that we can add to
    our pipeline via **nlp.add_pipe** . When it finds a match, the match is appended
    to **doc.ents** or **doc.spans** . If adding to **doc.ents** , **ent_type** will
    be the label we pass in the pattern. Let’s see it in action:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**SpanRuler**不是一个匹配器；它是一个管道组件，我们可以通过**nlp.add_pipe**将其添加到我们的管道中。当它找到匹配项时，匹配项将被追加到**doc.ents**或**doc.spans**中。如果添加到**doc.ents**，**ent_type**将是我们在模式中传递的标签。让我们看看它是如何工作的：'
- en: 'First, define a pattern for the entity:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，为实体定义一个模式：
- en: '[PRE33]'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Now, we add the **SpanRuler** component. By default, it adds the spans to **doc.spans**
    , and we want to add it to **doc.ents** , so we specify that in the config:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们添加**SpanRuler**组件。默认情况下，它将跨度添加到**doc.spans**中，而我们希望将其添加到**doc.ents**中，所以我们在配置中指定了这一点：
- en: '[PRE34]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Now, we can add the pattern to the component and process the text:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以将模式添加到组件中并处理文本：
- en: '[PRE35]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '*Figure 4* *.14* shows the entity we’ve matched:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.14*显示了我们所匹配的实体：'
- en: '![Figure 4.14 – Entity created with SpanRuler](img/B22441_04_14.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图4.14 – 使用SpanRuler创建的实体](img/B22441_04_14.jpg)'
- en: Figure 4.14 – Entity created with SpanRuler
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.14 – 使用SpanRuler创建的实体
- en: 'We can see in *Figure 4* *.14* that the **chime** token was added to the **Doc.ents**
    dictionary. If you don’t want to override the existing entities, you can set **overwrite**
    to **False** . Let’s try that:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在*图4.14*中看到，**chime**标记被添加到了**Doc.ents**字典中。如果你不想覆盖现有的实体，可以将**overwrite**设置为**False**。让我们试试：
- en: '[PRE36]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '*Figure 4* *.15* shows the result. Now, the entity added by the **ner** component
    is also present (you will learn more about components and pipelines in [*Chapter
    5*](B22441_05.xhtml#_idTextAnchor074) ):'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.15*显示了结果。现在，由**ner**组件添加的实体也出现了（你将在[*第五章*](B22441_05.xhtml#_idTextAnchor074)中了解更多关于组件和管道的内容）：'
- en: '![Figure 4.15 – Entities created with SpanRuler and the ner component](img/B22441_04_15.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图4.15 – 使用SpanRuler和ner组件创建的实体](img/B22441_04_15.jpg)'
- en: Figure 4.15 – Entities created with SpanRuler and the ner component
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.15 – 使用SpanRuler和ner组件创建的实体
- en: That’s it – easy, yet powerful. We added our own entity with just a couple of
    lines.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样——简单，却强大。我们只用了几行代码就添加了自己的实体。
- en: Now that we’ve seen how to use the **Matcher** class and **SpanRuler** to extract
    information, we’ll move on to an exclusive section of quick and very handy recipes.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了如何使用**Matcher**类和**SpanRuler**提取信息，我们将继续到一个专门的部分，快速且非常实用的食谱。
- en: Combining spaCy models and matchers
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结合spaCy模型和匹配器
- en: In this section, we’ll go through some recipes that will guide you through the
    entity extraction types you might encounter in your NLP journey. All the examples
    are ready-to-use and real-world recipes. Let’s start with number-formatted entities.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍一些食谱，这些食谱将指导你了解你可能在NLP旅程中遇到的实体提取类型。所有示例都是现成的、真实世界的食谱。让我们从数字格式化的实体开始。
- en: Extracting an IBAN
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取IBAN
- en: An **IBAN** is an important entity type that occurs in finance and banking frequently.
    We’ll learn how to parse it out.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '**IBAN**是金融和银行业中经常出现的重要实体类型。我们将学习如何解析它。'
- en: An IBAN is an international number format for bank account numbers. It has the
    format of a two-digit country code followed by numbers.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: IBAN是一种国际银行账户号码格式。它由两位数字的国家代码和随后的数字组成。
- en: 'How can we create a pattern for an IBAN? We start with two capital letters,
    followed by two digits. Then, any number of digits can follow. We can express
    the country code and the next two digits as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何创建一个IBAN的模式？我们首先用两个大写字母开始，然后是两个数字。接着，可以跟任意数量的数字。我们可以这样表示国家代码和接下来的两个数字：
- en: '[PRE37]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Here, **XX** corresponds to two capital letters, and **dd** is two digits.
    Then, the **XXdd** pattern matches the first block of the IBAN perfectly. How
    about the rest of the digit blocks? For the rest of the blocks, we need to match
    a block of one to four digits. The **\d{1,4}** regex means a token consisting
    of one to four digits. This pattern will match a digit block:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，**XX** 代表两个大写字母，而**dd** 是两个数字。然后，**XXdd** 模式完美地匹配IBAN的第一个数字块。那么其他数字块呢？对于其他块，我们需要匹配一个一到四个数字的块。**\d{1,4}**正则表达式表示一个由一到四个数字组成的标记。这个模式将匹配一个数字块：
- en: '[PRE38]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We have a number of these blocks, so the pattern to match the digit blocks
    of an IBAN is as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有这些块的数量，所以匹配IBAN数字块的模式如下：
- en: '[PRE39]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Then, we combine the first shape block with the rest of the blocks. Let’s check
    the full code of the pattern:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将第一个形状块与其他块结合起来。让我们检查模式的完整代码：
- en: 'Define the pattern and add it to the **Matcher** object:'
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义模式并将其添加到**Matcher**对象中：
- en: '[PRE40]'
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, let’s add the code to display the matches:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们添加代码来显示匹配项：
- en: '[PRE41]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '*Figure 4* *.16* shows the result. You can always follow a similar strategy
    when parsing numeric entities: first, divide the entity into some meaningful parts/blocks,
    then try to determine the shape or the length of the individual blocks:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.16* 显示了结果。在解析数字实体时，你可以始终遵循类似的策略：首先，将实体分成一些有意义的部分/块，然后尝试确定各个块的形式或长度：'
- en: '![Figure 4.16 – Extracting IBANs](img/B22441_04_16.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![图4.16 – 提取IBAN](img/B22441_04_16.jpg)'
- en: Figure 4.16 – Extracting IBANs
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.16 – 提取IBAN
- en: 'We successfully parsed IBANs. Now, we’ll extract another type of common numeric
    entity: phone numbers.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们成功解析了IBAN。现在，我们将提取另一种常见的数字实体：电话号码。
- en: Extracting phone numbers
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取电话号码
- en: Phone numbers can have very different formats depending on the country, and
    matching phone numbers is often a tricky business. The best strategy here is to
    be specific about the country phone number format you want to parse. If there
    are several countries, you can add corresponding individual patterns to the matcher.
    If you have too many countries, then you can relax some conditions and go for
    a more general pattern (we’ll see how to do that).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 电话号码的格式因国家而异，匹配电话号码通常是一项棘手的工作。这里的最佳策略是明确你想要解析的国家电话号码格式。如果有多个国家，你可以在匹配器中添加相应的单个模式。如果你有太多的国家，那么你可以放宽一些条件，采用更通用的模式（我们将看到如何做到这一点）。
- en: 'Let’s start with the US phone number format. A US number is written as (541)
    754-3010 domestically or +1 (541) 754-3010 internationally. We can form our pattern
    with an optional **+1** instance, then a three-digit area code, then two blocks
    of numbers separated with an optional **-** instance. Here is the pattern:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从美国的电话号码格式开始。美国国内电话号码写作（541）754-3010，国际电话号码写作+1（541）754-3010。我们可以用一个可选的**+1**实例，然后是一个三位数的区号，然后是两个用可选的**-**实例分隔的数字块来形成我们的模式。以下是模式：
- en: '[PRE42]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Let’s see an example of the pattern:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看模式的例子：
- en: '[PRE43]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Next, we have some example sentences and the code to display the matches:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有一些示例句子和显示匹配项的代码：
- en: '[PRE44]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '*Figure 4* *.17* shows the results. How about we make the pattern more general
    to apply to other countries as well? In this case, we can start with a one-to-three-digit
    country code, followed by some digit blocks. It will match a broader set of numbers,
    so it’s better to be careful not to match other numeric entities in your text:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.17* 显示了结果。我们是否可以将模式变得更通用，以便也适用于其他国家？在这种情况下，我们可以从一个一到三位数的国家代码开始，后面跟一些数字块。这将匹配更广泛的数字集合，因此最好小心不要匹配文本中的其他数字实体：'
- en: '![Figure 4.17 – Extracting phone numbers](img/B22441_04_17.jpg)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![图4.17 – 提取电话号码](img/B22441_04_17.jpg)'
- en: Figure 4.17 – Extracting phone numbers
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.17 – 提取电话号码
- en: We’ll move on to textual entities from numeric entities. Now, we’ll process
    social media text and extract different types of entities that can occur in social
    media text.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把文本实体从数字实体中提取出来。现在，我们将处理社交媒体文本并提取社交媒体文本中可能出现的不同类型的实体。
- en: Extracting mentions
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提取提及
- en: 'Imagine analyzing a dataset of social media posts about companies and products,
    and your task is to find out which companies are mentioned in which ways. The
    dataset will contain these sorts of sentences:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下分析关于公司和个人产品的社交媒体帖子数据集，你的任务是找出以何种方式提及了哪些公司。数据集将包含这些类型的句子：
- en: '[PRE45]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'What we’re looking for is, most probably, patterns of the **BusinessName is/was/be
    adverb*** adjective form. The following pattern would work:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要找的可能是**BusinessName is/was/be adverb**形容词形式的模式。以下模式将有效：
- en: '[PRE46]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Here, we look for an organization type entity, followed by an **is/was/be**
    instance, then optional adverbs, and finally, an adjective.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们寻找一个组织类型实体，然后是一个**is/was/be**实例，接着是可选的副词，最后是一个形容词。
- en: 'What if you want to extract a specific business – let’s say, the company ACME?
    All you have to do is replace the first token with the specific company name:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想提取一个特定的商业实体——比如说，ACME公司？你只需要将第一个标记替换为特定的公司名称：
- en: '[PRE47]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: That’s it – easy peasy! After extracting the social media mentions, the next
    thing to do is to extract the hashtags.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样——简单易懂！在提取社交媒体提及之后，接下来要做的事情是提取哈希标签。
- en: Hashtag extraction
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 哈希标签提取
- en: 'Processing social media text has some challenges. Social media text has an
    unusual token type: **hashtags** . They have a huge impact on the text’s meaning.
    The hashtag refers to the subject/object of the sentence.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 处理社交媒体文本有一些挑战。社交媒体文本有一个不寻常的标记类型：**hashtags**。它们对文本的意义有巨大影响。哈希标签指的是句子的主题/对象。
- en: 'A hashtag consists of a **#** character at the beginning, then followed by
    a word of ASCII characters, with no inter-word spaces. Some examples are **#MySpace**
    , **#MondayMotivation** , and so on. The spaCy tokenizer tokenizes these words
    into two tokens:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希标签由一个**#**字符开头，然后是一个ASCII字符的单词，没有单词间空格。一些例子是**#MySpace**，**#MondayMotivation**等等。spaCy分词器将这些单词分词成两个标记：
- en: '[PRE48]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'As a result, our pattern needs to match two tokens: the **#** character and
    the rest. The following pattern will match a hashtag easily:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的模式需要匹配两个标记：**#**字符和其余部分。以下模式可以轻松匹配hashTag：
- en: '[PRE49]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The following pattern extracts a hashtag:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 以下模式提取了一个哈希标签：
- en: '[PRE50]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now, let’s display the matches using the sentence **"Start working out** **now
    #WeekendShred"** :'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '现在，让我们使用句子**"Start working out** **now #WeekendShred"**来显示匹配结果：'
- en: '[PRE51]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Pretty easy as well. *Figure 4* *.18* shows the result:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 同样简单。*图4* *.18* 展示了结果：
- en: '![Figure 4.18 – Matches the hashTag pattern](img/B22441_04_18.jpg)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
  zh: '![图4.18 – 匹配hashTag模式](img/B22441_04_18.jpg)'
- en: Figure 4.18 – Matches the hashTag pattern
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.18 – 匹配hashTag模式
- en: Emoji is another unusual token and has the potential to assign the sentiment
    to a sentence. We can also extract emoji tokens using the spacymoji package (
    [https://spacy.io/universe/project/spacymoji](https://spacy.io/universe/project/spacymoji)
    ).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 表情符号是另一种不寻常的标记，它有可能将情感赋予一个句子。我们还可以使用spacymoji包（[https://spacy.io/universe/project/spacymoji](https://spacy.io/universe/project/spacymoji)）提取表情符号标记。
- en: Now, let’s extract some entities. We’ll start with the common procedure of expanding
    named entities in the next section.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们提取一些实体。我们将在下一节中介绍扩展命名实体的常用方法。
- en: Expanding named entities
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展命名实体
- en: Often, we would like to expand a named entity’s span to the left or to the right.
    Imagine you want to extract **PERSON** type named entities with titles so that
    you can deduce the gender or profession easily. spaCy’s **NER** class already
    extracts person names, so how about the titles?
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们希望将命名实体的范围扩展到左侧或右侧。想象一下，你想提取带有标题的**PERSON**类型命名实体，这样你可以轻松推断性别或职业。spaCy的**NER**类已经提取了人名，那么标题呢？
- en: '[PRE52]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'As you see, the word **Ms.** is not included in the named entity because it’s
    not a part of the person’s name. A quick solution is to make a new entity type
    called **TITLE** :'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，单词**Ms.**没有包含在命名实体中，因为它不是人名的一部分。一个快速的解决方案是创建一个新的实体类型，称为**TITLE**：
- en: '[PRE53]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Now, let’s display the matches again:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们再次显示匹配结果：
- en: '[PRE54]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '*Figure 4* *.19* shows the result:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4* *.19* 展示了结果：'
- en: '![Figure 4.19 – Expanding entities with Matcher](img/B22441_04_19.jpg)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![图4.19 – 使用Matcher扩展实体](img/B22441_04_19.jpg)'
- en: Figure 4.19 – Expanding entities with Matcher
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.19 – 使用Matcher扩展实体
- en: This is a quick and very handy recipe. You’ll come across parsing titles a lot
    if you process wiki text or financial text.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个快速且非常实用的方法。如果你处理维基文本或财经文本，经常会遇到解析标题。
- en: Summary
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned how to do rule-based matching with linguistic and
    token-level features. You learned about the **Matcher** class, spaCy’s rule-based
    matcher. We explored the **Matcher** class by using it with different token features,
    such as shape, lemma, text, and entity type.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何使用语言和标记级特征进行基于规则的匹配。你学习了关于**Matcher**类，spaCy的基于规则的匹配器。我们通过使用不同的标记特征，如形状、词元、文本和实体类型，来探索**Matcher**类。
- en: Then, you learned about **SpanRuler** , another lifesaving class that you can
    achieve a lot with. You also learned how to extract named entities with the **SpanRuler**
    class.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你学习了关于**SpanRuler**的知识，这是一个可以让你取得很多成就的救命工具。你还学习了如何使用**SpanRuler**类提取命名实体。
- en: Finally, we put together what you learned in this chapter and your previous
    knowledge and combined linguistic features with rule-based matching with several
    examples. You learned how to extract patterns, entities of specific formats, and
    entities specific to your domain.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将本章所学内容与你的先前知识相结合，并通过几个示例将语言特征与基于规则的匹配相结合。你学习了如何提取模式、特定格式的实体以及特定领域的实体。
- en: With this chapter, you completed the linguistic features. In the next chapter,
    we’ll use all this knowledge to extract semantic representations from text using
    spaCy pipelines.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章，你完成了语言特征的构建。在下一章中，我们将利用所有这些知识，通过spaCy管道从文本中提取语义表示。
