- en: Chapter 12. Learning Features with Unsupervised Generative Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 12 章：使用无监督生成网络学习特征
- en: This chapter focuses on a new type of model, the generative models, which include
    **Restricted Boltzmann Machines**, **Deep Belief Networks**, **Variational Auto
    Encoders**, **Autoregressive models, and Generative Adversarial** Networks. For
    the first nets, we've limited the presentation to the theory, while the last is
    explained in detail with practical code and advice.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章重点介绍一种新型模型——生成模型，包括 **限制玻尔兹曼机**、**深度信念网络**、**变分自编码器**、**自回归模型** 和 **生成对抗网络**。对于前者，我们将介绍其理论，而后者则通过实践代码和建议详细解释。
- en: These nets do not require any labels to be trained, which is called *unsupervised
    learning*. Unsupervised learning helps compute features from the data, without
    the bias of the labels. These models are generative in the sense that they are
    trained to generate new data that sounds real.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这些网络不需要任何标签进行训练，这就是所谓的 *无监督学习*。无监督学习帮助从数据中计算特征，而不受标签的偏差影响。这些模型是生成式的，因为它们经过训练以生成听起来真实的新数据。
- en: 'The following points will be covered:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 以下内容将会涵盖：
- en: Generative models
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成模型
- en: Unsupervised learning
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Restricted Boltzmann Machines
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制玻尔兹曼机
- en: Deep belief networks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度信念网络
- en: Generative adversarial models
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成对抗模型
- en: Semi-supervised learning
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 半监督学习
- en: Generative models
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型
- en: 'A generative model in neural processing is a model that generates data given
    a noise vector *z* as input:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 神经处理中的生成模型是一个模型，给定一个噪声向量 *z* 作为输入，生成数据：
- en: '![Generative models](img/00233.jpeg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![生成模型](img/00233.jpeg)'
- en: The purpose of the training is to find the parameters to generate data as close
    as possible to the real data.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的目的是找到能够生成尽可能接近真实数据的数据的参数。
- en: Applications of generative networks include data dimensionality reduction, synthetic
    data generation, unsupervised feature learning, and pre-training / training efficiency.
    Pre-training helps generalization because pre-training focuses on the patterns
    in the data, and less on the data-label relation.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 生成网络的应用包括数据维度减少、合成数据生成、无监督特征学习和预训练/训练效率。预训练有助于泛化，因为预训练侧重于数据中的模式，而不是数据与标签之间的关系。
- en: Restricted Boltzmann Machines
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制玻尔兹曼机
- en: 'A Restricted Boltzmann Machine is the simplest generative net, composed of
    one fully connected hidden layer, as shown in the picture:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 限制玻尔兹曼机是最简单的生成网络，由一个完全连接的隐藏层组成，如图所示：
- en: '![Restricted Boltzmann Machines](img/00234.jpeg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![限制玻尔兹曼机](img/00234.jpeg)'
- en: The full Boltzmann Machines have also hidden-to-hidden and visible-to-visible
    loop connections, while the *Restricted* version does not have any.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 完全玻尔兹曼机还具有隐藏到隐藏和可见到可见的循环连接，而 *限制* 版本则没有任何这种连接。
- en: 'In the general case, RBM are defined as *energy-based models*, which means
    that they define a probability distribution through an energy function:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在一般情况下，RBM 被定义为 *基于能量的模型*，这意味着它们通过能量函数定义了一个概率分布：
- en: '![Restricted Boltzmann Machines](img/00235.jpeg)![Restricted Boltzmann Machines](img/00236.jpeg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![限制玻尔兹曼机](img/00235.jpeg)![限制玻尔兹曼机](img/00236.jpeg)'
- en: '*Z* is the **partition function**, and *E(v)* is the **free energy** function
    (does not depend on the hidden state).'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*Z* 是 **配分函数**，*E(v)* 是 **自由能** 函数（不依赖于隐藏状态）。'
- en: Note
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Minimizing the negative log likelihood is equivalent to minimizing the energy
    function.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最小化负对数似然等价于最小化能量函数。
- en: 'The RBM defines the energy function as a linearity in the parameters of the
    model:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: RBM 定义了一个作为模型参数线性函数的能量函数：
- en: '![Restricted Boltzmann Machines](img/00237.jpeg)![Restricted Boltzmann Machines](img/00238.jpeg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![限制玻尔兹曼机](img/00237.jpeg)![限制玻尔兹曼机](img/00238.jpeg)'
- en: 'The relation between the energy and the free energy is given by:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 能量与自由能之间的关系由以下公式给出：
- en: '![Restricted Boltzmann Machines](img/00239.jpeg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![限制玻尔兹曼机](img/00239.jpeg)'
- en: 'In the case of the RBM:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在 RBM 的情况下：
- en: '![Restricted Boltzmann Machines](img/00240.jpeg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![限制玻尔兹曼机](img/00240.jpeg)'
- en: Here ![Restricted Boltzmann Machines](img/00241.jpeg) denotes the sum over possible
    values of the i-th hidden neuron.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这里 ![限制玻尔兹曼机](img/00241.jpeg) 表示对第 i 个隐藏神经元的可能值进行求和。
- en: 'The RBM are usually considered in the particular case where `v` and `h` are
    binomial values in *{0,1}*, so:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: RBM 通常考虑在特定情况下，其中 `v` 和 `h` 是 *{0,1}* 中的二项值，因此：
- en: '![Restricted Boltzmann Machines](img/00242.jpeg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![限制玻尔兹曼机](img/00242.jpeg)'
- en: 'The model is symmetric, following the symmetry in the model: hidden and visible
    have the same place in the energy function:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型是对称的，遵循模型中的对称性：隐藏层和可见层在能量函数中占据相同的位置：
- en: '![Restricted Boltzmann Machines](img/00243.jpeg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![限制玻尔兹曼机](img/00243.jpeg)'
- en: RBM works as a simple stochastic fully connected layer in both directions (from
    input to hidden, and from hidden to input).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: RBM在两个方向上都作为一个简单的随机完全连接层工作（从输入到隐藏，从隐藏到输入）。
- en: 'The gradient or derivative of the negative log-likelihood for the RBM has two
    terms, defined as **positive and negative phases**, where the first term increases
    the probability of data, and the second term decreases the probability of generated
    samples:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: RBM的负对数似然的梯度或导数有两个项，分别定义为**正相位**和**负相位**，其中第一项增加数据的概率，第二项减少生成样本的概率：
- en: '![Restricted Boltzmann Machines](img/00244.jpeg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![限制玻尔兹曼机](img/00244.jpeg)'
- en: Here, the sum is over all possible inputs ![Restricted Boltzmann Machines](img/00245.jpeg)
    weighted by its probability (the expectation). At the minima, any increase in
    the free energy of our data sample will decrease the expectation of the total
    data.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，求和是对所有可能的输入 ![限制玻尔兹曼机](img/00245.jpeg) 按其概率（期望）加权。在最小值处，任何自由能的增加都会减少总数据的期望。
- en: 'Empirically, such a sum in the negative phase can be transformed into a sum
    over *N* observed (*v,h*):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，负相位中的这种求和可以转化为对*V*观察到的*（v,h）*的求和：
- en: '![Restricted Boltzmann Machines](img/00246.jpeg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![限制玻尔兹曼机](img/00246.jpeg)'
- en: To compute such a sum in practice, the probability of observing the sample (*v,h*)
    has to satisfy *p(v | h)* given by the above formula as well as *p(h | v)*.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在实践中计算这样的求和，观察到的样本*（v,h）*的概率必须满足 *p(v | h)*，由上式给出，同时满足 *p(h | v)*。
- en: 'Sampling is performed via the contrastive divergence algorithm, in practice:
    *v* is sampled from the dataset, while *h* is drawn following its above distribution
    given *v*. This operation is repeated, to produce a new *v* given *h*, then a
    new *h* given *v*. In practice, this is sufficient to achieve samples closely
    distributed to the real distribution. These observed samples for *v* and *h* are
    referred to as **negative particles**, and the second term in the cost function
    decreases the probability of these generated samples, while the first term increases
    the probability of the data.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 采样是通过对比散度算法进行的，实践中：*v* 从数据集中采样，而 *h* 则根据上述分布在给定 *v* 的条件下绘制。这个操作会重复进行，以产生给定 *h*
    的新 *v*，然后是给定 *v* 的新 *h*。在实践中，这足以生成与真实分布非常接近的样本。这些观察到的 *v* 和 *h* 样本被称为**负粒子**，成本函数中的第二项减少这些生成样本的概率，而第一项则增加数据的概率。
- en: 'Here is what the computation of the partition function with the negative particules
    would look like:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是计算带有负粒子的配分函数的结果：
- en: '[PRE0]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The pictures of the filters trained on MNIST dataset after 15 epochs:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在MNIST数据集上训练15轮后的过滤器图像：
- en: '![Restricted Boltzmann Machines](img/00247.jpeg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![限制玻尔兹曼机](img/00247.jpeg)'
- en: 'And a mini-batch of negative particles (1,000 steps of sampling between each
    row):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一小批负粒子（每行之间有1,000步的采样）：
- en: '![Restricted Boltzmann Machines](img/00248.jpeg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![限制玻尔兹曼机](img/00248.jpeg)'
- en: Deep belief bets
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度信念网络
- en: A **deep belief network** (**DBN**) is a stack of multiple RBMs to increase
    their representative power and better capture patterns in the data.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**深度信念网络**（**DBN**）是多个RBM堆叠在一起，旨在增强它们的表示能力，更好地捕捉数据中的模式。'
- en: 'The training occurs layer by layer, first considering there is only one RBM
    with the hidden state ![Deep belief bets](img/00249.jpeg). Once the weights of
    the RBM have been trained, these weights are kept fixed and the hidden layer of
    the first RBM ![Deep belief bets](img/00249.jpeg) is considered as the visible
    layer for a second RBM, with one hidden state ![Deep belief bets](img/00250.jpeg).
    Each new RBM will capture patterns that have not been captured by the previous
    RBM as in the following diagram:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程是逐层进行的，首先假设只有一个RBM，带有隐藏状态 ![深度信念网络](img/00249.jpeg)。一旦RBM的权重被训练好，这些权重将保持固定，第一个RBM的隐藏层
    ![深度信念网络](img/00249.jpeg) 被视为第二个RBM的可见层，第二个RBM有一个隐藏状态 ![深度信念网络](img/00250.jpeg)。每个新的RBM将捕捉到之前的RBM没有捕捉到的模式，如下图所示：
- en: '![Deep belief bets](img/00251.jpeg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![深度信念网络](img/00251.jpeg)'
- en: It can be shown that each add-on of a new RBM on top of the stack decreases
    the negative log likelihood.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 可以证明，在堆叠中每增加一个新的RBM，会减少负对数似然值。
- en: As last step, it is possible to use these weights in a classification network,
    by simply adding a linear layer and a softmax layer on top of the final hidden
    state, and fine-tuning all the weights via gradient descent training, as usual.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是可以将这些权重应用到分类网络中，通过在最终的隐藏状态上简单地添加一个线性层和一个Softmax层，然后像往常一样通过梯度下降训练微调所有权重。
- en: 'The application to data dimensionality remains the same, with the unrolling
    of all layers to produce a decoder network, with weights equal to the transpose
    of the weights in the encoder network (initial multi-layer RBM):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据维度的应用保持不变，将所有层展开以产生解码器网络，权重等于编码器网络中的权重转置（初始多层RBM）：
- en: '![Deep belief bets](img/00252.jpeg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![深度信念网络](img/00252.jpeg)'
- en: Such an unrolled network is called an **auto encoder**.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这种展开的网络被称为**自编码器**。
- en: In practice, training directly via a gradient descent without the greedy layer
    by layer training would require finding the right initialization, which could
    be a lot trickier, as the weight initialization has to be close enough to the
    solution. That is why the commonly used approach for auto encoders is to train
    each RBM separately.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，如果没有贪婪的逐层训练，直接通过梯度下降进行训练需要找到合适的初始化，这可能会更加棘手，因为权重初始化必须足够接近解决方案。这就是为什么常用的自编码器方法是分别训练每个RBM。
- en: Generative adversarial networks
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: Since the partition function in the previous models is untractable and requires
    contrastive divergence algorithm with Gibbs sampling, game theory has recently
    delivered a new class of methods for learning generative models, the **Generative
    adversarial networks** (**GANs**), which enjoys great success today.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于之前模型中的分区函数不可解且需要使用吉布斯采样的对比散度算法，博弈论最近为学习生成模型提供了一类新方法，即**生成对抗网络**（**GANs**），并且这种方法今天取得了巨大成功。
- en: 'Generative adversarial networks are composed of two models that are alternatively
    trained to compete with each other. The generator network **G** is optimized to
    reproduce the true data distribution, by generating data that is difficult for
    the discriminator **D** to differentiate from real data. Meanwhile, the second
    network D is optimized to distinguish real data and synthetic data generated by
    G. Overall, the training procedure is similar to a two-player min-max game with
    the following objective function:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络由两个模型组成，这两个模型交替训练以相互竞争。生成器网络**G**的优化目标是通过生成难以被判别器**D**与真实数据区分的数据，来重现真实数据的分布。与此同时，第二个网络D的优化目标是区分真实数据和由G生成的合成数据。总体而言，训练过程类似于一个双人博弈的最小-最大游戏，目标函数如下：
- en: '![Generative adversarial networks](img/00253.jpeg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![生成对抗网络](img/00253.jpeg)'
- en: 'Here, *x* is real data sampled from real data distribution, and *z* the noise
    vector of the generative model. In some ways, the discriminator and the generator
    can be seen as the police and the thief: to be sure the training works correctly,
    the police is trained twice as much as the thief.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*x*是真实数据，来自真实数据分布，*z*是生成模型的噪声向量。从某种意义上来说，判别器和生成器可以看作是警察和小偷：为了确保训练正确进行，警察的训练次数是小偷的两倍。
- en: Let's illustrate GANs with the case of images as data. In particular, let's
    again take our example from [Chapter 2](part0026_split_000.html#OPEK1-ccdadb29edc54339afcb9bdf9350ba6b
    "Chapter 2. Classifying Handwritten Digits with a Feedforward Network"), *Classifying
    Handwritten Digits with a Feedforward Network* about MNIST digits, and consider
    training a generative adversarial network, to generate images, conditionally on
    the digit we want.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过图像作为数据的案例来说明GANs。特别地，仍然采用[第2章](part0026_split_000.html#OPEK1-ccdadb29edc54339afcb9bdf9350ba6b
    "第2章：使用前馈网络分类手写数字")的例子，*使用前馈网络分类手写数字*，关于MNIST数字，考虑训练一个生成对抗网络，根据我们想要的数字生成图像。
- en: 'The GAN method consists of training the generative model using a second model,
    the discriminative network, to discriminate input data between real and fake.
    In this case, we can simply reuse our MNIST image classification model as discriminator,
    with two classes, `real` or `fake`, for the prediction output, and also condition
    it on the label of the digit that is supposed to be generated. To condition the
    net on the label, the digit label is concatenated with the inputs:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 方法包括使用第二个模型——判别网络，来训练生成模型，判别输入数据是否为真实或伪造。在这种情况下，我们可以简单地重用我们的 MNIST 图像分类模型作为判别器，进行
    `real` 或 `fake` 的预测输出，并且将其条件化为应生成的数字标签。为了将网络条件化为标签，数字标签与输入数据进行拼接：
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Tip
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: Note the use of two leaky rectified linear units, with a leak of 0.2, as activation
    for the first two convolutions.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 注意使用了两个泄漏修正线性单元（leaky ReLU），泄漏系数为 0.2，作为前两个卷积的激活函数。
- en: 'To generate an image given noise and label, the generator network consists
    of a stack of deconvolutions, using an input noise vector z that consists of 100
    real numbers ranging from 0 to 1:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了根据噪声和标签生成图像，生成器网络由一系列反卷积组成，使用一个包含 100 个从 0 到 1 之间的实数的输入噪声向量 z：
- en: '![Generative adversarial networks](img/00254.jpeg)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![生成对抗网络](img/00254.jpeg)'
- en: 'To create a deconvolution in Theano, a dummy convolutional forward pass is
    created, which gradient is used as deconvolution:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Theano 中创建反卷积时，创建一个虚拟的卷积前向传播，并将其梯度作为反卷积的使用。
- en: '[PRE2]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Real data is given by the tuple (X,Y), while generated data is built from noise
    and label (Z,Y):'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 真实数据由元组 (X,Y) 给出，而生成的数据则由噪声和标签 (Z,Y) 构建：
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Generator and discriminator models compete during adversarial learning:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 生成器和判别器模型在对抗学习中竞争：
- en: 'The discriminator is trained to label real data as real (`1`) and label generated
    data as generated (`0`), hence minimizing the following cost function:'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器被训练为将真实数据标记为真实（`1`），并将生成数据标记为生成（`0`），从而最小化以下成本函数：
- en: '[PRE4]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The generator is trained to deceive the discriminator as much as possible.
    The training signal for the generator is provided by the discriminator network
    (p_gen) to the generator:'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成器被训练成尽可能欺骗判别器。生成器的训练信号由判别器网络（p_gen）提供给生成器：
- en: '[PRE5]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The same as usual follows. Cost with respect to the parameters for each model
    is computed and training optimizes the weights of each model alternatively, with
    two times more the discriminator. In the case of GANs, competition between discriminator
    and generator does not lead to decreases in each loss.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 和通常一样，计算每个模型的参数成本，并交替优化每个模型的权重，判别器的训练次数是生成器的两倍。在 GANs 的情况下，判别器和生成器之间的竞争不会导致每个损失的减少。
- en: 'From the first epoch:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 从第一轮开始：
- en: '![Generative adversarial networks](img/00255.jpeg)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![生成对抗网络](img/00255.jpeg)'
- en: 'To the 45th epoch:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 到第 45 轮：
- en: '![Generative adversarial networks](img/00256.jpeg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![生成对抗网络](img/00256.jpeg)'
- en: 'Generated examples look closer to real ones:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的示例看起来更接近真实数据：
- en: '![Generative adversarial networks](img/00257.jpeg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![生成对抗网络](img/00257.jpeg)'
- en: Improve GANs
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 改进 GANs
- en: GANs are recent and very promising but still undergoing heavy research today.
    Yet, there are ways to improve the previous results.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: GANs 是近期出现的、非常有前景的技术，但目前仍在进行深入研究。然而，仍然有方法可以改进之前的结果。
- en: 'First, as for RBM and other networks, GANs can be stacked in order to increase
    their generative power. As an example, the StackGan model proposes to use two
    stacked GANs for high quality image generation: the first GAN generates a coarse
    and low resolution image, while the second uses this generated sample as the input
    to generate an image of higher definition and realism, in which details of the
    objects are precised.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，和 RBM 及其他网络一样，GANs 可以通过堆叠来增加它们的生成能力。例如，StackGan 模型提出使用两个堆叠的 GANs 进行高质量图像生成：第一个
    GAN 生成粗糙的低分辨率图像，而第二个 GAN 将这个生成的样本作为输入，生成更高定义和更具真实感的图像，其中物体的细节更加精确。
- en: 'One of the main issues with GAN is the **model collapse**, which makes them
    difficult to train. Model collapse occurs when the generator begins to ignore
    the input noise and learns to generate only one sample, always the same. Diversity
    in the generation has collapsed. One very nice way to deal with this comes from
    the S-GAN model, and consists of adding a third net to train with the generator.
    The purpose of this net is to predict back the noise given the input:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: GAN的一个主要问题是**模型崩溃**，这使得它们很难训练。模型崩溃发生在生成器开始忽视输入噪声并学习仅生成一个样本时，这个样本总是相同的。生成中的多样性崩溃了。解决这个问题的一种非常有效的方法来自S-GAN模型，它通过向生成器中添加一个第三个网络来进行训练。这个网络的目的是根据输入预测噪声：
- en: '![Improve GANs](img/00258.jpeg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![改进GANs](img/00258.jpeg)'
- en: 'To optimize this third net with the generator, an entropy loss is added to
    the generator loss, to encourage the generated images *x* to be sufficiently dependent
    on the noise *z*. In other words, the conditional entropy *H(x | z)* has to be
    as low as possible:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与生成器一起优化这个第三个网络，会向生成器损失中添加一个熵损失，以鼓励生成的图像 *x* 足够依赖噪声 *z*。换句话说，条件熵 *H(x | z)*
    必须尽可能低：
- en: '![Improve GANs](img/00259.jpeg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![改进GANs](img/00259.jpeg)'
- en: This third net predicts an auxiliary distribution Q to approximate the true
    posterior *P(z | x)* and can be proved to be a variational higher bound for *H(x
    | z)*. Such a loss function helps the generator not to ignore the input noise.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这个第三个网络预测一个辅助分布Q，用来逼近真实后验 *P(z | x)*，并且可以证明它是 *H(x | z)* 的变分上界。这样的损失函数有助于生成器不忽视输入噪声。
- en: Semi-supervised learning
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 半监督学习
- en: Last but not least, such generative adversarial networks can be used to enhance
    supervised learning itself.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，这种生成对抗网络可以用来增强监督学习本身。
- en: Suppose the objective is to classify *K* classes, for which an amount of labeled
    data is available. It is possible to add some generated samples to the dataset,
    which come from a generative model, and consider them as belonging to a *(K+1)th*
    class, the fake data class.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 假设目标是分类 *K* 类，并且有一定数量的标记数据。可以将一些来自生成模型的生成样本添加到数据集中，并将它们视为属于 *(K+1)th* 类，即伪数据类。
- en: 'Decomposing the training cross-entropy loss of the new classifier between the
    two sets (real data and fake data) leads to the following formula:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 将新分类器在两个数据集（真实数据和伪数据）之间的训练交叉熵损失分解为以下公式：
- en: '![Semi-supervised learning](img/00260.jpeg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![半监督学习](img/00260.jpeg)'
- en: 'Here, ![Semi-supervised learning](img/00261.jpeg) is the probability predicted
    by the model:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，![半监督学习](img/00261.jpeg) 是模型预测的概率：
- en: '![Semi-supervised learning](img/00262.jpeg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![半监督学习](img/00262.jpeg)'
- en: 'Note that if we know that the data is real:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果我们知道数据是真实的：
- en: '![Semi-supervised learning](img/00263.jpeg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![半监督学习](img/00263.jpeg)'
- en: 'And training on real data (K classes) would have led to the loss:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 而在真实数据（K类）上的训练会导致以下损失：
- en: '![Semi-supervised learning](img/00264.jpeg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![半监督学习](img/00264.jpeg)'
- en: 'Hence the loss of the global classifier can be rewritten:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，全球分类器的损失可以重写为：
- en: '![Semi-supervised learning](img/00265.jpeg)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![半监督学习](img/00265.jpeg)'
- en: 'The second term of the loss corresponds to the standard unsupervised loss for
    GAN:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 损失的第二项对应于GAN的标准无监督损失：
- en: '![Semi-supervised learning](img/00266.jpeg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![半监督学习](img/00266.jpeg)'
- en: The interaction introduced between the supervised and the unsupervised loss
    is still not well understood but, when the classification is not trivial, an unsupervised
    loss helps.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 监督损失和无监督损失之间引入的交互作用仍然不完全理解，但当分类问题不简单时，无监督损失是有帮助的。
- en: Further reading
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'You can refer to the following topics for more insights:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考以下主题以获取更多见解：
- en: '*Deeplearning.net tutorial on RBM*: [http://deeplearning.net/tutorial/rbm.html](http://deeplearning.net/tutorial/rbm.html)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Deeplearning.net RBM教程*：[http://deeplearning.net/tutorial/rbm.html](http://deeplearning.net/tutorial/rbm.html)'
- en: '*Deeplearning.net tutorial on Deep Belief Nets*: [http://deeplearning.net/tutorial/DBN.html](http://deeplearning.net/tutorial/DBN.html)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Deeplearning.net 深度信念网络教程*：[http://deeplearning.net/tutorial/DBN.html](http://deeplearning.net/tutorial/DBN.html)'
- en: '*Deeplearning.net tutorial on generating with RBM-RNN*: [http://deeplearning.net/tutorial/rnnrbm.html](http://deeplearning.net/tutorial/rnnrbm.html)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Deeplearning.net 使用RBM-RNN生成的教程*：[http://deeplearning.net/tutorial/rnnrbm.html](http://deeplearning.net/tutorial/rnnrbm.html)'
- en: '*Modeling Temporal Dependencies in High-Dimensional Sequences: Application
    to Polyphonic Music Generation and Transcription*, Nicolas Boulanger-Lewandowski,
    Yoshua Bengio, Pascal Vincent, 2012'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*建模高维序列中的时间依赖性：应用于多声部音乐生成与转录*，Nicolas Boulanger-Lewandowski，Yoshua Bengio，Pascal
    Vincent，2012'
- en: Generative Adversarial Networks, Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi
    Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio,
    2014
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成对抗网络，Ian J. Goodfellow，Jean Pouget-Abadie，Mehdi Mirza，Bing Xu，David Warde-Farley，Sherjil
    Ozair，Aaron Courville，Yoshua Bengio，2014
- en: '*Gans will* *change the world*, Nikolai Yakovenko, 2016 [https://medium.com/@Moscow25/](https://medium.com/@Moscow25/)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*生成对抗网络将* *改变世界*，Nikolai Yakovenko，2016 [https://medium.com/@Moscow25/](https://medium.com/@Moscow25/)'
- en: '*Pixel Recurrent Neural Networks*, Aaron van den Oord, Nal Kalchbrenner, Koray
    Kavukcuoglu, 2016'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*像素递归神经网络*，Aaron van den Oord，Nal Kalchbrenner，Koray Kavukcuoglu，2016'
- en: '*InfoGAN: Interpretable Representation Learning by Information Maximizing Generative
    Adversarial Nets,* Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever,
    Pieter Abbeel, 2016'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*InfoGAN：通过信息最大化生成对抗网络进行可解释的表示学习*，Xi Chen，Yan Duan，Rein Houthooft，John Schulman，Ilya
    Sutskever，Pieter Abbeel，2016'
- en: '*StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial
    Networks*, Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaolei Huang, Xiaogang
    Wang, Dimitris Metaxas, 2016'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*StackGAN：使用堆叠生成对抗网络将文本转换为逼真的图像合成*，Han Zhang，Tao Xu，Hongsheng Li，Shaoting Zhang，Xiaolei
    Huang，Xiaogang Wang，Dimitris Metaxas，2016'
- en: '*Stacked Generative Advanced Networks*, Xun Huang, Yixuan Li, Omid Poursaeed,
    John Hopcroft, Serge Belongie, 2016'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*堆叠生成对抗网络*，Xun Huang，Yixuan Li，Omid Poursaeed，John Hopcroft，Serge Belongie，2016'
- en: '*Adversarial Learning for Neural Dialogue Generation*, Jiwei Li, Will Monroe,
    Tianlin Shi, Sébastien Jean, Alan Ritter, Dan Jurafsky, 2017'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*神经对话生成的对抗学习*，Jiwei Li，Will Monroe，Tianlin Shi，Sébastien Jean，Alan Ritter，Dan
    Jurafsky，2017'
- en: '*Improved Techniques for Training GANs*, Tim Salimans, Ian Goodfellow, Wojciech
    Zaremba, Vicki Cheung, Alec Radford, Xi Chen, 2016'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*改进的GAN训练技术*，Tim Salimans，Ian Goodfellow，Wojciech Zaremba，Vicki Cheung，Alec
    Radford，Xi Chen，2016'
- en: '*Unsupervised Representation Learning with Deep Convolutional Generative Adversarial
    Networks*, Alec Radford, Luke Metz, Soumith Chintala, 2015'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*无监督表示学习与深度卷积生成对抗网络*，Alec Radford，Luke Metz，Soumith Chintala，2015'
- en: Summary
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Generative adversarial networks are a very active area of research today. They
    belong to the family of generative models, which includes RBM and deep belief
    networks.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络如今是一个非常活跃的研究领域。它们属于生成模型家族，包括RBM和深度置信网络。
- en: Generative models aim at generating more data, or learning better features for
    supervised and other tasks in an unsupervised way.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型旨在生成更多数据，或以无监督的方式学习更好的特征，用于监督学习和其他任务。
- en: Generative models can be conditioned on some environmental input, and try to
    find the hidden variables behind the real data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型可以根据一些环境输入进行条件化，并尝试找到真实数据背后的隐藏变量。
- en: These models, the most advanced, complete the overview of deep learning nets
    with Theano. The next chapter will look at some advanced concepts to extend Theano
    and the future of deep learning.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型是最先进的，完成了与Theano的深度学习网络概述。下一章将介绍一些高级概念，以扩展Theano并探讨深度学习的未来。
