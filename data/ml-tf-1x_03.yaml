- en: The TensorFlow Toolbox
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 工具箱
- en: Most machine learning platforms are focused toward scientists and practitioners
    in academic or industrial settings. Accordingly, while quite powerful, they are
    often rough around the edges and have few user-experience features.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习平台面向的是学术或工业领域的科学家和从业人员。因此，尽管它们功能强大，但往往比较粗糙，缺乏许多用户体验功能。
- en: Quite a bit of effort goes into peeking at the model at various stages and viewing
    and aggregating performance across models and runs. Even viewing the neural network
    can involve far more effort than expected.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在各个阶段查看模型并查看和汇总不同模型和运行的性能是需要付出相当多的努力的。即使是查看神经网络，所需的努力也可能比预期的要多。
- en: While this was acceptable when neural networks were simple and only a few layers
    deep, today's networks are far deeper. In 2015, Microsoft won the annual **ImageNet**
    competition using a deep network with 152 layers. Visualizing such networks can
    be difficult, and peeking at weights and biases can be overwhelming.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在神经网络简单且仅有几层时，这样做是可以接受的，但今天的网络要深得多。2015 年，微软使用一款具有 152 层的深度网络赢得了年度 **ImageNet**
    大赛。可视化这样深的网络可能会很困难，查看权重和偏差可能会让人不知所措。
- en: Practitioners started using home-built visualizers and bootstrapped tools to
    analyze their networks and run performance. TensorFlow changed this by releasing
    TensorBoard directly alongside their overall platform release. TensorBoard runs
    out of the box with no additional installations or setup.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 从业者们开始使用自建的可视化工具和引导工具来分析他们的网络并进行性能评估。TensorFlow 通过在整体平台发布时直接发布 TensorBoard 改变了这一点。TensorBoard
    开箱即用，无需额外安装或设置。
- en: Users just need to instrument their code according to what they wish to capture.
    It features plotting of events, learning rate, and loss over time; histograms,
    for weights and biases; and images. The Graph Explorer allows interactive reviews
    of the neural network.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 用户只需要根据他们想要捕捉的内容来为代码添加监控。它具有绘制事件、学习率和损失随时间变化的图表；权重和偏差的直方图；以及图像。图形浏览器允许交互式地查看神经网络。
- en: 'In this chapter, we will focus on several areas, which are as follows:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点讨论以下几个领域：
- en: We will start with the instrumentation required to feed TensorBoard using four
    common models and datasets as examples, highlighting the required changes.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将从使用四个常见模型和数据集作为示例，介绍为 TensorBoard 提供输入所需的监控内容，并突出所需的更改。
- en: We will then review the data captured and ways to interpret it.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们将回顾捕捉到的数据和如何解读它们。
- en: Finally, we will review common graphs as visualized by Graph Explorer. This
    will help you visualize common neural network setups, which will be introduced
    in later chapters and projects. It will also be a visual introduction to common
    networks.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们将回顾图形浏览器可视化的常见图形。这将帮助您可视化常见的神经网络设置，这些设置将在后续章节和项目中介绍。这也是对常见网络的可视化入门。
- en: A quick preview
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速预览
- en: 'Without even having TensorFlow installed, you can play with a reference implementation
    of TensorBoard. You can get started here:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 即使没有安装 TensorFlow，您也可以尝试 TensorBoard 的参考实现。您可以从这里开始：
- en: '[https://www.tensorflow.org/tensorboard/index.html#graphs.](https://www.tensorflow.org/tensorboard/index.html#graphs)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.tensorflow.org/tensorboard/index.html#graphs.](https://www.tensorflow.org/tensorboard/index.html#graphs)'
- en: 'You can follow along with the code here:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在这里跟随代码：
- en: '[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/model'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/model'
- en: s/image/cifar10/cifar10_train.py.](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_train.py)
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: s/image/cifar10/cifar10_train.py.](https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_train.py)
- en: The example uses the **CIFAR-10** image set. The CIFAR-10 dataset consists of
    60,000 images in 10 classes compiled by Alex Krizhevsky, Vinod Nair, and Geoffrey
    Hinton. The dataset has become one of several standard learning tools and benchmarks
    for machine learning efforts.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 该示例使用 **CIFAR-10** 图像集。CIFAR-10 数据集包含 60,000 张图像，分为 10 类，由 Alex Krizhevsky、Vinod
    Nair 和 Geoffrey Hinton 编制。该数据集已成为机器学习领域的几个标准学习工具和基准之一。
- en: 'Let''s start with the Graph Explorer. We can immediately see a convolutional
    network being used. This is not surprising as we''re trying to classify images
    here:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从图形浏览器开始。我们可以立即看到正在使用卷积网络。这并不令人惊讶，因为我们在这里尝试对图像进行分类：
- en: '![](img/cfe3a5b8-cf8d-4c87-b8de-bc605accc81b.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cfe3a5b8-cf8d-4c87-b8de-bc605accc81b.png)'
- en: This is just one possible view of the graph. You can try the Graph Explorer
    as well. It allows deep dives into individual components.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是图形的其中一种视图。您也可以尝试使用图形浏览器。它允许深入查看单个组件。
- en: 'Our next stop on the quick preview is the EVENTS tab. This tab shows scalar
    data over time. The different statistics are grouped into individual tabs on the
    right-hand side. The following screenshot shows a number of popular scalar statistics,
    such as loss, learning rate, cross entropy, and sparsity across multiple parts
    of the network:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在快速预览中的下一站是**EVENTS**标签页。该标签页展示了随时间变化的标量数据。不同的统计信息被分组到右侧的单独标签中。以下截图展示了多个网络部分的常见标量统计数据，例如损失、学习率、交叉熵和稀疏度：
- en: '![](img/79150dc7-ed50-4625-92d6-ae45e73df412.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](img/79150dc7-ed50-4625-92d6-ae45e73df412.png)'
- en: The HISTOGRAMS tab is a close cousin as it shows tensor data over time. Despite
    the name, as of TensorFlow v0.7, it does not actually display histograms. Rather,
    it shows summaries of tensor data using percentiles.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**HISTOGRAMS**标签页是一个近亲，它展示了随时间变化的张量数据。尽管名字是直方图，但从TensorFlow v0.7开始，它实际上并不显示直方图。相反，它通过百分位数来展示张量数据的汇总信息。'
- en: The summary view is shown in the following figure. Just like with the EVENTS
    tab, the data is grouped into tabs on the right-hand side. Different runs can
    be toggled on and off and runs can be shown overlaid, allowing interesting comparisons.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 总结视图如下图所示。就像在**EVENTS**标签页中一样，数据被分组到右侧的标签中。可以切换不同的运行，并且可以将多个运行叠加显示，便于进行有趣的对比。
- en: It features three runs, which we can see on the left side, and we'll look at
    just the `softmax` function and associated parameters.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 它展示了三次运行，我们可以在左侧看到，我们将只查看`softmax`函数及其相关参数。
- en: 'For now, don''t worry too much about what these mean, we''re just looking at
    what we can achieve for our own classifiers:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 暂时不必太担心这些的含义，我们只需要看看我们为自己的分类器能做到什么：
- en: '![](img/df6ca2ab-fc79-440f-b643-a7b5e04d0387.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/df6ca2ab-fc79-440f-b643-a7b5e04d0387.png)'
- en: 'However, the summary view does not do justice to the utility of the HISTOGRAMS
    tab. Instead, we will zoom into a single graph to observe what is going on. This
    is shown in the following figure:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，总结视图无法充分体现**HISTOGRAMS**标签页的实用性。相反，我们将放大单个图表，观察具体情况。如下图所示：
- en: '![](img/6d7a15f4-8379-4e90-8744-27d72f8ba579.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6d7a15f4-8379-4e90-8744-27d72f8ba579.png)'
- en: Notice that each histogram chart shows a time series of nine lines. The top
    is the maximum, in middle the median, and the bottom the minimum. The three lines
    directly above and below the median are 1½ standard deviation, 1 standard deviation,
    and ½ standard deviation marks.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，每个直方图图表展示了九条时间序列线。顶部是最大值，中间是中位数，底部是最小值。中位数上下的三条线分别表示1½标准差、1标准差和½标准差的位置。
- en: Obviously, this does represent multimodal distributions as it is not a histogram.
    However, it does provide a quick gist of what would otherwise be a mountain of
    data to shift through.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这确实表示了多模态分布，因为它不是一个直方图。然而，它确实提供了一个快速的概览，否则这些数据将会是需要翻阅的大量数据。
- en: A couple of things to note are how data can be collected and segregated by runs,
    how different data streams can be collected, how we can enlarge the views, and
    how we can zoom into each of the graphs.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 有几点需要注意：数据如何按运行收集和分隔，如何收集不同的数据流，如何放大视图，以及如何缩放到每个图表。
- en: Enough of graphics, let's jump into the code so we can run this for ourselves!
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 够了，先放下这些图形，让我们跳进代码中，亲自运行一下吧！
- en: Installing TensorBoard
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装TensorBoard
- en: TensorFlow comes prepackaged with TensorBoard, so it will already be installed.
    It runs as a locally served web application accessible via the browser at `http://0.0.0.0:6006`.
    Conveniently, there is no server-side code or configurations required.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow已经预装了TensorBoard，因此它会自动安装。它作为本地提供的Web应用程序运行，通过浏览器访问`http://0.0.0.0:6006`。方便的是，不需要任何服务器端的代码或配置。
- en: 'Depending on where your paths are, you may be able to run it directly, as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 根据路径的不同，您可能能够直接运行它，如下所示：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If your paths are not correct, you may need to prefix the application accordingly,
    as shown in the following command line:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果路径不正确，您可能需要根据需要在应用程序前加上前缀，如以下命令行所示：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'On Linux, you can run it in the background and just let it keep running, as
    follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux上，您可以将其在后台运行，并让它保持运行，如下所示：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Some thought should be put into the directory structure though. The Runs list
    on the left side of the dashboard is driven by subdirectories in the `logdir`
    location. The following image shows two runs--`MNIST_Run1` and `MNIST_Run2`. Having
    an organized `runs` folder will allow plotting successive runs side by side to
    see differences:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，目录结构应当谨慎考虑。仪表板左侧的“Runs”列表是由`logdir`位置中的子目录驱动的。以下图片展示了两个运行——`MNIST_Run1`和`MNIST_Run2`。组织良好的`runs`文件夹可以帮助并排绘制连续的运行结果，从而查看不同之处：
- en: '![](img/35fdd820-9895-4675-9d99-eb11d699cb78.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/35fdd820-9895-4675-9d99-eb11d699cb78.png)'
- en: 'When initializing `writer`, you will pass in the directory for the log as the
    first parameter, as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在初始化`writer`时，您需要将日志的目录作为第一个参数传递，示例如下：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Consider saving a base location and appending run-specific subdirectories for
    each run. This will help organize outputs without expending more thought on it.
    We'll discuss more about this later.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑保存一个基础位置，并为每次运行附加特定的子目录。这将有助于组织输出，而无需再多加思考。我们稍后会进一步讨论这一点。
- en: Incorporating hooks into our code
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将hooks集成到我们的代码中
- en: The best way to get started with TensorBoard is by taking existing working examples
    and instrument them with the code required for TensorBoard. We will do this for
    several common training scripts.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorBoard的最佳方法是通过借用现有的工作示例并用TensorBoard所需的代码进行标记。我们将针对几个常见的训练脚本进行这样的操作。
- en: Handwritten digits
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手写数字
- en: Let's start with the typical Hello World of machine learning with images--the
    MNIST handwritten numeral classification exercise.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从典型的机器学习入门例子——MNIST手写数字分类练习开始。
- en: The MNIST database being used has 60,000 images for training and another 10,000
    for testing. It was originally collected by Chris Burges and Corinna Cortes and
    enhanced by Yann LeCun. You can find out more about the dataset on Yann LeCun's
    website ([http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 正在使用的MNIST数据库包含60,000张用于训练的图像和10,000张用于测试的图像。该数据最初由Chris Burges和Corinna Cortes收集，并由Yann
    LeCun进行了增强。您可以在Yann LeCun的官方网站上了解更多关于数据集的信息（[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)）。
- en: TensorFlow conveniently comes with a test script demonstrating a convolutional
    neural network using the MSNIST handwritten, available at [https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py](https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow方便地提供了一个测试脚本，演示了如何使用MNIST手写数据集构建卷积神经网络，代码可以在[https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py](https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py)找到。
- en: Let's modify this script to allow TensorBoard usage. If you wish to peek ahead,
    download a golden copy or see deltas; our full set of changes is available on
    the book's GitHub repository ([https://github.com/mlwithtf/mlwithtf](https://github.com/mlwithtf/mlwithtf)
    ).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们修改这个脚本以便使用TensorBoard。如果您希望提前查看、下载金标准或查看更改，完整的修改集可以在本书的GitHub仓库中找到（[https://github.com/mlwithtf/mlwithtf](https://github.com/mlwithtf/mlwithtf)）。
- en: For now, we recommend following along and making changes incrementally to understand
    the process.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们建议您跟着教程一步步修改，以理解整个过程。
- en: 'Early on in the `main` class, we will define holders for `convn_weights`, `convn_biases`,
    and other parameters. Directly afterward, we will write the following code to
    add them to the `histogram`:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在`main`类的早期，我们将定义`convn_weights`、`convn_biases`和其他参数的占位符。紧接着，我们将编写以下代码，将它们添加到`histogram`中：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The preceding lines capture the values for the HISTOGRAMS tab. Notice that
    the captured values form subsections on the HISTOGRAMS tab, which is shown in
    the following screenshot:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的几行捕获了“HISTOGRAMS”标签页中的值。请注意，捕获的值会在“HISTOGRAMS”标签页上形成子部分，以下截图展示了这一点：
- en: '![](img/71d949ac-fed1-4f05-9faf-941dace523fb.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/71d949ac-fed1-4f05-9faf-941dace523fb.png)'
- en: 'Next, let''s record some `loss` figures. We have the following code to start
    with:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们记录一些`loss`数据。我们有如下代码作为起点：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We will add a `scalar` summary for the `loss` figures after the preceding line:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在前面的行之后为`loss`数字添加一个`scalar`汇总：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Similarly, we will start with the standard code calculating the `learning_rate`:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们将从计算`learning_rate`的标准代码开始：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We will add a `scalar` summary for the `learning_rate` figures, which is as
    follows:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为`learning_rate`数据添加一个`scalar`汇总，代码如下：
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Just these two preceding lines help us capture these to important scalar metrics
    in our EVENTS tab:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 就这两行代码，帮助我们在“EVENTS”标签页中捕获这两个重要的标量指标：
- en: '![](img/53e4b291-5aed-43a5-8b61-de36d742b671.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](img/53e4b291-5aed-43a5-8b61-de36d742b671.png)'
- en: 'Finally, let''s instruct our script to save the graph setup. Let''s find the
    section of the script which creates the `session`:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们指示脚本保存图形设置。我们来找到创建`session`的脚本部分：
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Just after defining the `sess` handle, we will capture the graph as follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义`sess`句柄之后，我们将如下捕获图形：
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We will need to add our `merged` object when running the session. We originally
    had the following code:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在运行会话时需要添加我们的`merged`对象。我们原本有以下代码：
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We will add our `merged` object when running the session as such:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在运行会话时添加我们的`merged`对象，如下所示：
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Finally, we will need to write summaries at specified steps, much like we typically
    output validation set accuracy periodically. So, we do add one more line after
    the `sum_string` is computed:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要在指定步骤写入摘要，就像我们通常定期输出验证集的准确度一样。因此，我们在计算`sum_string`后添加了一行：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'That is all! We have just captured our loss and learning rates, key intermediate
    parameters on our neural network, and the structure of the graph. We have already
    examined the EVENTS and HISTOGRAMS tab, now let''s look at the GRAPH tab:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！我们刚刚捕获了我们的损失和学习率、神经网络的关键中间参数以及图形结构。我们已经查看了EVENTS和HISTOGRAMS标签，现在让我们看看GRAPH标签：
- en: '![](img/fab51f74-7ad0-49f0-b2fd-c76ae470ce87.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fab51f74-7ad0-49f0-b2fd-c76ae470ce87.png)'
- en: AlexNet
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AlexNet
- en: Anyone involved in deep learning with images should become familiar with AlexNet.
    The network was introduced in the landmark paper, *ImageNet Classification with
    Deep Convolutional Neural Networks*, by Alex Krizhevsky, Ilya Sutskever, and Geoffrey
    E. Hinton. The paper can be viewed at [http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf](http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 任何参与图像深度学习的人都应该熟悉AlexNet。该网络是在Alex Krizhevsky、Ilya Sutskever和Geoffrey E. Hinton的标志性论文《*ImageNet
    Classification with Deep Convolutional Neural Networks*》中介绍的。论文可以在[http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf](http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf)查看。
- en: 'This network architecture achieved then-record accuracy on the annual ImageNet
    competition. The architecture is described in their paper, as shown in the following
    image. We will be using this network architecture in later chapters, but for now,
    let''s browse through the network using TensorBoard:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 该网络架构在当时的ImageNet年度竞赛中取得了创纪录的准确率。该架构在他们的论文中有所描述，如下图所示。我们将在后续章节中使用此网络架构，但现在，让我们通过TensorBoard浏览网络：
- en: '![](img/fc55270a-7218-4c5c-9351-d3573279583a.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fc55270a-7218-4c5c-9351-d3573279583a.png)'
- en: We will not review line-by-line changes to the existing AlexNet code, but the
    reader can easily see changes by noting differences between the original model
    code provided by Google and the revised code that we have included with the book's
    code repository.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会逐行审查现有的AlexNet代码更改，但读者可以通过注意Google提供的原始模型代码与我们包含在书本代码库中的修订代码之间的差异，轻松看到更改。
- en: 'The original AlexNet TensorFlow implementation from Google is available at:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 来自Google的原始AlexNet TensorFlow实现可以在以下位置找到：
- en: '[https://github.com/tensorflow/models/blob/master/tutorials/image/alexnet/alexnet_benchmark.py.](https://github.com/tensorflow/models/blob/master/tutorials/image/alexnet/alexnet_benchmark.py)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/tensorflow/models/blob/master/tutorials/image/alexnet/alexnet_benchmark.py.](https://github.com/tensorflow/models/blob/master/tutorials/image/alexnet/alexnet_benchmark.py)'
- en: 'The revised AlexNet TensorFlow implementation with TensorBoard instrumentation
    can be found at:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 修订后的AlexNet TensorFlow实现与TensorBoard工具集成可以在以下位置找到：
- en: '[https://github.com/mlwithtf/mlwithtf/blob/master/chapter_03/alexnet_benchmark.py.](https://github.com/mlwithtf/mlwithtf/blob/master/chapter_03/alexnet_benchmark.py)'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/mlwithtf/mlwithtf/blob/master/chapter_03/alexnet_benchmark.py.](https://github.com/mlwithtf/mlwithtf/blob/master/chapter_03/alexnet_benchmark.py)'
- en: The changes introduced are very similar to those done for our MNIST example.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 所做的更改与我们为MNIST示例所做的非常相似。
- en: 'First, find the location of this code:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，找到以下代码的位置：
- en: '[PRE14]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, replace it with the following code:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，用以下代码替换它：
- en: '[PRE15]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, you can run the Python file `alexnet_benchmark.py` and TensorBoard
    command to visualize the graph:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以运行Python文件`alexnet_benchmark.py`并使用TensorBoard命令来可视化图形：
- en: '[PRE16]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Our focus for this section is just the graph. The following figure shows a section
    of the Graph Explorer. We have deep dived into convolutional layer 3 of 5 and
    we are looking at weights and biases for this layer.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的重点是图形部分。下图显示了Graph Explorer的一个部分。我们深入研究了第3层卷积层，正在查看该层的权重和偏差。
- en: 'Clicking on the weights node on the graph is interesting because we see details
    such as the shape: `{"shape":{"dim":[{"size":3},{"size":3},{"size":192},{"size":384}]}}`.
    We can match many of these details right back to the original paper and the previously
    referenced diagram! We can also trace details back to the network setup in the
    code:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 点击图中的权重节点很有趣，因为我们可以看到形状等细节：`{"shape":{"dim":[{"size":3},{"size":3},{"size":192},{"size":384}]}}`。我们可以将这些细节与原始论文和之前提到的图表进行匹配！我们还可以追溯这些细节到代码中的网络设置：
- en: '[PRE17]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The details in the Graph Explorer and code are equivalent, but the flow of
    data is very easily visualized using TensorBoard. It is also easy to collapse
    repetitive sections and expand sections of interest:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图形浏览器和代码中的细节是等价的，但使用 TensorBoard 可以更直观地查看数据流。你还可以轻松地折叠重复的部分，展开感兴趣的部分：
- en: '![](img/73088eb4-aab7-46fb-86e4-58655412e4e9.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/73088eb4-aab7-46fb-86e4-58655412e4e9.png)'
- en: The graph is the most interesting part of this section, but of course, you can
    also run our revised script and review the training performance, as well as a
    host of other data we're capturing. You can even capture additional data. Give
    it a try!
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图形是本节最有趣的部分，当然，你也可以运行我们修改过的脚本并查看训练性能，以及我们捕获的其他大量数据。你甚至可以捕获更多的数据。试试看吧！
- en: Automating runs
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化运行
- en: When trying to train a classifier, we will often end up with multiple variables
    for which we don't know a good setting. Viewing values used by solutions for similar
    problems is a good starting point. However, we are often left with an array of
    possible values that we need to test. To make things more complicated, we often
    have several such parameters, resulting in numerous combinations that we may need
    to test.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练分类器时，我们通常会遇到多个我们不知道合适设置的变量。查看类似问题的解决方案所使用的值是一个很好的起点。然而，我们通常会面临一组需要测试的可能值。更复杂的是，我们通常有多个这样的参数，这将导致需要测试的组合数量大大增加。
- en: For such situations, we suggest keeping the parameters of interest as values
    that can be passed into the trainer. Then, a `wrapper` script can pass in various
    combinations of the parameters, along with a unique output log subdirectory that
    is possibly tagged with a descriptive name.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这种情况，我们建议将感兴趣的参数保留为可以传递给训练器的值。然后，`wrapper` 脚本可以传递不同的参数组合，并带有一个可能带有描述性名称的唯一输出日志子目录。
- en: 'This will allow an easy comparison of results and intermediate values across
    multiple tests. The following figure shows four runs'' losses plotted together.
    We can easily see the underperforming and overperforming pairs:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使得跨多个测试结果和中间值的比较变得简单。下图展示了四次运行的损失曲线图。我们可以轻松看到表现不佳和表现过好的组合：
- en: '![](img/09e61965-8300-46e9-a02a-9833e1f82cdd.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/09e61965-8300-46e9-a02a-9833e1f82cdd.png)'
- en: Summary
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the major areas of TensorBoard--EVENTS, HISTOGRAMS,
    and viewing GRAPH. We modified popular models to see the exact changes required
    before TensorBoard could be up and running. This should have demonstrated the
    fairly minimal effort required to get started with TensorBoard.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们覆盖了 TensorBoard 的主要区域——EVENTS、HISTOGRAMS 和查看 GRAPH。我们修改了流行模型，以查看 TensorBoard
    启动所需的精确变化。这应该展示了启动 TensorBoard 所需的非常少的工作量。
- en: Finally, we focused on various popular models by viewing their network design.
    We did this by instrumenting the code with TensorBoard hooks and using the TensorBoard
    Graph Explorer to deep dive into the network setups.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过查看流行模型的网络设计进行了重点研究。我们通过在代码中插入 TensorBoard hooks，并使用 TensorBoard 图形浏览器深入了解网络设置来实现这一点。
- en: The reader should now be able to use TensorBoard more effectively, gauge training
    performance, and plan runs and modify training scripts.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 读者现在应该能够更有效地使用 TensorBoard，评估训练性能，计划运行并修改训练脚本。
- en: Next, we're going to jump into convolutional networks. We'll use parts of our
    prior work so we can hit the ground running. But, we'll focus on more advanced
    neural network setups to achieve better accuracy. The focus on training accuracy
    reflects the focus of most practitioner's efforts, so it is the time we face the
    challenge.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入探讨卷积网络。我们将使用之前工作的部分内容，以便可以迅速开始。但我们将集中精力在更高级的神经网络设置上，以获得更好的准确性。对训练准确度的关注反映了大多数从业者的努力方向，因此，这是我们面临挑战的时刻。
