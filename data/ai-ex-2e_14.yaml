- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: Preparing the Input of Chatbots with Restricted Boltzmann Machines (RBMs) and
    Principal Component Analysis (PCA)
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用限制玻尔兹曼机（RBM）和主成分分析（PCA）准备聊天机器人的输入
- en: In the following chapters, we will explore chatbot frameworks and build chatbots.
    You will find that creating a chatbot structure only takes a few clicks. However,
    no chatbot can be built without designing the input to prepare the desired dialog
    flow. The goal of this chapter is to demonstrate how to extract features from
    a dataset and then use them to gather the basic information to build a chatbot
    in *Chapter 15*, *Setting up a Cognitive NLP UI/CUI Chatbot*.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将探索聊天机器人框架并构建聊天机器人。你会发现，创建一个聊天机器人的结构只需几次点击。然而，任何聊天机器人都无法在没有设计输入以准备所需对话流程的情况下建立。本章的目标是展示如何从数据集中提取特征，然后使用这些特征收集基本信息，以便在*第15章*，*搭建认知NLP
    UI/CUI聊天机器人*中构建一个聊天机器人。
- en: The input of a dialog requires in-depth research and designing. In this chapter,
    we will build a **restricted Boltzmann machine** (**RBM**) that will analyze a
    dataset. In *Chapter 13*, *Visualizing Networks with TensorFlow 2.x and TensorBoard*,
    we examined the layers of a convolutional neural network (CNN) and displayed their
    outputs. This time, we will explore the weights of the RBM. We will go further
    and use the weights of the RBM as features. The weights of an RBM can be transformed
    into feature vectors for a **principal component analysis** (**PCA**) algorithm.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 对话的输入需要深入研究和设计。在本章中，我们将构建一个**限制玻尔兹曼机**（**RBM**），它将分析一个数据集。在*第13章*，*使用TensorFlow
    2.x和TensorBoard可视化网络*中，我们研究了卷积神经网络（CNN）的层并显示了它们的输出。这次，我们将探索RBM的权重。我们将进一步使用RBM的权重作为特征。RBM的权重可以转换为特征向量，供**主成分分析**（**PCA**）算法使用。
- en: We will use the feature vectors generated by the RBM to build a PCA display
    using TensorBoard Embedding Projector's functionality. We will then use the statistics
    obtained to lay the grounds for the inputs of a chatbot.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用RBM生成的特征向量，利用TensorBoard Embedding Projector的功能构建一个PCA展示。然后，我们将使用获得的统计数据为聊天机器人的输入打下基础。
- en: To illustrate the whole process, we will use streaming platform data as an example of how
    this is done. Streaming has become a central activity of almost all smartphone
    owners. The problem facing Netflix, YouTube, Amazon, or any platform offering
    streaming services is to offer us the right video to watch. If a viewer watches
    a video, and the platform does not display a pertinent similar one to watch next,
    the viewer might choose to use another platform.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明整个过程，我们将使用流媒体平台数据作为示例，展示这一过程是如何完成的。流媒体已成为几乎所有智能手机拥有者的核心活动。Netflix、YouTube、Amazon或任何提供流媒体服务的平台面临的问题是如何向我们推荐合适的视频。如果观众观看了一部视频，而平台没有展示一个相关的类似视频供其观看，观众可能会选择使用另一个平台。
- en: 'This chapter is divided into two parts:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章分为两部分：
- en: Building an RBM and then extending it to an automatic feature vector generator
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建RBM并将其扩展为自动特征向量生成器
- en: Using PCA to represent the weights of an RBM as features. TensorFlow's Embedding
    Projector possesses an inbuilt PCA function. The statistics produced will provide
    the basis of the dialog structure for *Chapter 15*, *Setting Up a Cognitive NLP
    UI/CUI Chatbot*.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PCA来表示RBM的权重作为特征。TensorFlow的Embedding Projector具有内置的PCA功能。生成的统计数据将为*第15章*，*搭建认知NLP
    UI/CUI聊天机器人*中的对话结构提供基础。
- en: Let's first define the basic terms we are using and our goals.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先定义我们正在使用的基本术语和目标。
- en: Defining basic terms and goals
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义基本术语和目标
- en: The goal of this chapter is to prepare data to create the input of a chatbot
    we will build in *Chapter 15*, *Setting Up a Cognitive NLP UI/CUI Chatbot*.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目标是准备数据，以便创建我们将在*第15章*，*搭建认知NLP UI/CUI聊天机器人*中构建的聊天机器人的输入。
- en: Creating a chatbot requires preparation. We cannot just step into a project
    without a minimum amount of information. In our case, we will examine a dataset
    I created based on movie preferences. I did not choose to download huge datasets
    because we need to first focus on understanding the process and building a model
    using basic data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个聊天机器人需要准备工作。我们不能在没有足够信息的情况下直接进入项目。在本案例中，我们将检查一个基于电影偏好的数据集。我没有选择下载庞大的数据集，因为我们首先需要专注于理解过程，并使用基础数据构建模型。
- en: The size of the datasets increase daily on an online platform. When we watch
    a movie on a streaming platform, on Netflix for example, we can like the movie
    or click on the thumbs-down button.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的大小在在线平台上每天都在增加。当我们在流媒体平台上观看电影时，例如Netflix，我们可以喜欢这部电影或点击“点踩”按钮。
- en: 'When we approve or disapprove of a movie on an online platform, our preferences
    are recorded. The features of these movies provide valuable information for the
    platform, which can then display choices we prefer: action, adventure, romantic,
    comedy, and more.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在在线平台上对一部电影表示赞同或不赞同时，我们的偏好会被记录下来。这些电影的特征为平台提供了宝贵的信息，平台可以根据这些信息展示我们偏好的电影：动作、冒险、浪漫、喜剧等。
- en: In this chapter, we will first use an RBM to extract a description (such as
    action, adventure, or comedy, for example) of the movies watched by a user or
    a group of users. We will take the output weights produced by the RBM to create
    a file of features reflecting the user's preferences.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先使用RBM提取用户或一组用户观看过的电影的描述（例如动作片、冒险片或喜剧片）。我们将利用RBM生成的输出权重，创建一个反映用户偏好的特征文件。
- en: This file of features of a user's preferences can be considered as a "mental
    dataset" of a person. The name might seem strange at first. However, a "mental"
    representation of a person goes beyond the standard age, income, and other impersonal
    data. Features such as "love," "violence," and "horizons" (wider views, adventure)
    give us a deeper understanding of a person than information we can find on a driving
    license.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 用户偏好的特征文件可以被视为一个人的“心智数据集”。这个名称一开始可能听起来有些陌生。然而，一个人的“心智”表示超越了标准的年龄、收入和其他无关紧要的数据。像“爱情”、“暴力”和“视野”（更广阔的视野、冒险）这样的特征，能让我们比驾照上的信息更深入地了解一个人。
- en: In the second part of the chapter, we will use the RBM's output of features
    of a person's "mind" as the input of a PCA. The PCA will calculate how the features
    relate to each other and how they vary, and we will display them in TensorBoard.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的第二部分，我们将使用RBM的输出，即一个人“心智”的特征，作为PCA的输入。PCA将计算这些特征之间的关联性以及它们的变化，并且我们将通过TensorBoard展示这些结果。
- en: We will then actually *see* a representation of a person's mind through the
    key features drawn from the RBM. This information will then be used to help us
    create a customized chatbot in *Chapter 15*.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将通过RBM提取的关键特征，*看到*一个人心智的表现。这些信息将帮助我们在*第15章*中创建一个定制化的聊天机器人。
- en: Let's move on to the first phase and build an RBM.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入第一阶段，构建一个RBM。
- en: Introducing and building an RBM
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍并构建RBM
- en: 'RBMs are random and undirected graph models generally built with a visible
    and a hidden layer. They were used in a Netflix competition to predict future
    user behavior. The goal here is not to predict what a viewer will do but establish
    who the viewer is and store the data in a viewer''s profile-structured mind dataset.
    The input data represents the features to be trained to learn about viewer X.
    Each column represents a feature of X''s potential personality and tastes. Each
    line represents the features of a movie that X has watched. The following code
    (and this section) is in `RBM_01.py`:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: RBM是随机且无向的图模型，通常由一个可见层和一个隐藏层构成。它们曾在Netflix的竞赛中被用于预测未来的用户行为。这里的目标不是预测观众将会做什么，而是确定观众是谁，并将数据存储在观众的个人档案结构化的心智数据集中。输入数据代表了要训练的特征，以了解观众X。每一列代表X潜在个性和品味的特征，每一行代表X观看过的电影的特征。以下代码（以及本节内容）在`RBM_01.py`中：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The goal of this RBM is to define a profile of X by computing the features of
    the movies watched. The input data could also be images, words, and other forms
    of data, as in any neural network.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 该RBM的目标是通过计算观看过的电影特征，定义X的个人档案。输入数据也可以是图像、文字或其他形式的数据，和任何神经网络一样。
- en: First, we will explore the architecture and define what an energy-driven neural
    network is. Then, we will build an RBM from scratch in Python.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将探索架构并定义什么是基于能量的神经网络。接着，我们将在Python中从零开始构建一个RBM。
- en: The architecture of an RBM
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RBM的架构
- en: 'The RBM model used contains two layers: a visible layer and a hidden layer.
    Many types of RBMs exist, but generally, they contain the following properties:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用的RBM模型包含两层：可见层和隐藏层。存在多种类型的RBM，但通常它们具有以下特性：
- en: There is no connection between the visible units, which is why it is *restricted*.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可见单元之间没有连接，这就是它被称为*限制性*的原因。
- en: There is no connection between the hidden units enforcing the restricted property
    of the network.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 隐藏单元之间也没有连接，进一步强化了网络的限制属性。
- en: There is no direction as in a feedforward neural network (FNN), as explored
    in *Chapter 8*, *Solving the XOR Problem with a Feedforward Neural Network*. An RBM's
    model is thus an *undirected* graph.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与前馈神经网络（FNN）不同，RBM没有像在*第8章*《使用前馈神经网络解决XOR问题》中所探讨的那样的方向性。因此，RBM的模型是一个*无向*图。
- en: 'The visible and hidden layers are connected by a weight matrix and a bias vector,
    which are the lines in the following diagram:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可见层和隐藏层通过一个权重矩阵和一个偏置向量连接，它们是以下图中的线条：
- en: '![](img/B15438_14_01.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_01.png)'
- en: 'Figure 14.1: The connection between visible and hidden units'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.1：可见单元和隐藏单元之间的连接
- en: The network contains six visible and two hidden units, producing a weight matrix
    of 2×6 values to which we will add bias values.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 网络包含六个可见单元和两个隐藏单元，产生一个2×6的权重矩阵，我们将为其添加偏置值。
- en: You will note that there is no output. The system runs from the visible units
    to the hidden units and back. We are operating feature extraction with this type
    of network. In this chapter, for example, we will use the weights as features.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到没有输出。系统从可见单元运行到隐藏单元再返回。我们正在使用这种类型的网络进行特征提取。例如，在本章中，我们将使用权重作为特征。
- en: By forcing the network to represent its data contained in 6 units in 2 units
    through a weight matrix, the RBM creates feature representations. The hidden units,
    weights, and biases can be used for feature extraction.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过强制网络通过一个权重矩阵将其包含在 6 个单元中的数据表示为 2 个单元，RBM 创建了特征表示。隐藏单元、权重和偏置可以用于特征提取。
- en: An energy-based model
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一种基于能量的模型
- en: An RBM is an energy-based model. The higher the energy, the lower the probability
    of obtaining the correct information; the lower the energy, the higher the probability
    – in other words, the higher the accuracy.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: RBM 是一种基于能量的模型。能量越高，获得正确信息的概率越低；能量越低，概率越高——换句话说，准确度越高。
- en: 'To understand this, let''s go back to the cup of tea we observed in *Chapter
    1*, *Getting Started with Next-Generation Artificial Intelligence through Reinforcement
    Learning*:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这一点，我们回到在《第一章，*通过强化学习开始下一代人工智能*》中观察的那杯茶：
- en: '![](img/B15438_14_02.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_02.png)'
- en: 'Figure 14.2: The complexity of a cup of tea'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.2：一杯茶的复杂性
- en: In *Chapter 1*, we observed a microstate of the cup through its global content
    and temperature. Then, we went on to use the Markov decision process (MDP) to
    run microstate calculations.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在《第一章》中，我们通过茶杯的全局内容和温度观察了它的微观状态。然后，我们使用马尔科夫决策过程（MDP）来进行微观状态计算。
- en: 'This time, we will focus on the temperature of the cup of tea. *x* will be
    the global temperature of all the molecules in the cup of tea:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，我们将关注茶杯的温度。*x* 将是茶杯中所有分子的全球温度：
- en: If *x* = 1, this means the temperature is very hot. The tea has just boiled.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 *x* = 1，这意味着温度非常高。茶刚刚沸腾。
- en: If *x* = 0.5, this means the temperature has gone down.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 *x* = 0.5，这意味着温度已经下降。
- en: If *x* = 0.1, this means the temperature is still a bit warm, but the tea is
    cooling.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果 *x* = 0.1，这意味着温度还是有点暖和，但茶正在冷却。
- en: The higher the temperature, the more the molecules will be bouncing around in
    the cup with a high level of energy, making it feel hot.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 温度越高，分子在茶杯中越活跃，能量水平越高，感觉就越热。
- en: However, the hotter it is, the closer to very hot, the lower the probability
    we can drink it.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，温度越高，越接近非常热，我们能喝下它的概率就越低。
- en: 'This leads to a probability *p* for a temperature *x*:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了温度 *x* 的概率 *p*：
- en: '*x* -> 1, *p* -> 0'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x* -> 1, *p* -> 0'
- en: '*x* -> 0, *p* -> 1'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*x* -> 0, *p* -> 1'
- en: As you can see, in an energy-driven system, we will strive to lower the energy
    level. Let's say we have a person with an unknown tolerance for hot drinks, and
    we want to wager whether they can drink our cup of tea. Nobody wants to drink
    cold (low-energy) tea, sure, but if our focus is on the likelihood of a person
    being able to drink the tea without finding it too hot (high-energy), then we
    want that tea to be as low-energy (that is, cool) as possible!
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，在一个能量驱动的系统中，我们会努力降低能量水平。假设我们有一个对热饮耐受度未知的人，我们想知道他们是否能喝下我们的这杯茶。没人愿意喝冷的（低能量）茶，当然，但是如果我们关注的是一个人能否喝下这杯茶而不觉得太烫（高能量），那么我们就希望这杯茶的能量尽可能低（也就是冷却）！
- en: To illustrate the *p*(*x*) system of our cup of tea, we will use Euler's number
    *e*, which is equal to 2.718281\. *p*(*x*) is the probability that we can drink
    our cup of tea, with *p* being the probability, and *x* the temperature or energy.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明我们这杯茶的 *p*(*x*) 系统，我们将使用欧拉数 *e*，它的值为 2.718281。*p*(*x*) 是我们能否喝下这杯茶的概率，*p*
    是概率，*x* 是温度或能量。
- en: 'We will begin to introduce a simple energy function in which *p*(*x*) = *e*^((–)^x^):'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将开始引入一个简单的能量函数，其中 *p*(*x*) = *e*^((–)^x^)：
- en: '*p*(*e*^((–1))) = 0.36'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p*(*e*^((–1))) = 0.36'
- en: '*p*(*e*^((–0.5))) = 0.60'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p*(*e*^((–0.5))) = 0.60'
- en: '*p*(*e*^((–0.1))) = 0.90'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*p*(*e*^((–0.1))) = 0.90'
- en: You can see that as –*x* (energy) decreases, the probability *p*(*x*) increases.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，随着 –*x*（能量）减小，概率 *p*(*x*) 增加。
- en: The goal of the learning function of an RBM is to decrease the energy level
    by optimizing the weights and biases. By doing this, the RBM increases the probability
    that the hidden units, the weights, and biases are optimized.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: RBM 学习函数的目标是通过优化权重和偏置来降低能量水平。通过这样做，RBM 增加了优化隐藏单元、权重和偏置的概率。
- en: 'To calculate the energy of an RBM, we will take the complete architecture of
    the network into account. Let''s display our model again as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了计算 RBM 的能量，我们将考虑网络的完整架构。让我们再次显示我们的模型，如下所示：
- en: '![](img/B15438_14_03.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_03.png)'
- en: 'Figure 14.3: The connection between visible and hidden units'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.3：可见单元和隐藏单元之间的连接
- en: 'This RBM model contains the following values:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 该 RBM 模型包含以下值：
- en: '*E*(*v*, *h*), which is the energy function that takes the visible units (input
    data) and hidden units into account.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*E*(*v*, *h*) 是能量函数，考虑了可见单元（输入数据）和隐藏单元。'
- en: '*v*[i] = the states of the visible units (input).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*v*[i] = 可见单元（输入）的状态。'
- en: '*a*[i] = the biases of the visible units.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*a*[i] = 可见单元的偏置。'
- en: '*h*[j] = the states of the hidden units.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*h*[j] = 隐藏单元的状态。'
- en: '*b*[j] = the biases of the hidden units.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*b*[j] = 隐藏单元的偏置。'
- en: '*w*[ij] = the weight matrix.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*w*[ij] = 权重矩阵。'
- en: 'With these variables in mind, we can define the energy function of an RBM for
    ![](img/B15438_14_001.png), ![](img/B15438_14_002.png), and *ij* as the lines
    and columns of the weight matrix as follows:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 结合这些变量，我们可以为 ![](img/B15438_14_001.png)、![](img/B15438_14_002.png) 和 *ij*（作为权重矩阵的行和列）定义
    RBM 的能量函数，如下所示：
- en: '![](img/B15438_14_003.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_003.png)'
- en: Now that we've got a better idea of what an RBM is and the principles behind
    it, let's start to consider how to build an RBM from scratch using Python.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对 RBM 有了更好的理解，并了解了其背后的原理，让我们开始考虑如何从零开始使用 Python 构建一个 RBM。
- en: Building the RBM in Python
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Python 中构建 RBM
- en: We will build an RBM using `RBM_01.py` from scratch using our bare hands with
    no pre-built library. The idea is to understand an RBM from top to bottom to see
    how it ticks. We will explore more RBM theory as we build the machine.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 `RBM_01.py` 从头开始构建一个 RBM，完全手动，不依赖任何预构建的库。这样做的目的是从上到下理解一个 RBM，看看它是如何工作的。在构建机器的过程中，我们将深入探索更多的
    RBM 理论。
- en: Creating a class and the structure of the RBM
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建类和 RBM 的结构
- en: 'First, the RBM class is created:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，创建 RBM 类：
- en: '[PRE1]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The first function of the class will receive the number of hidden units (`2`)
    and the number of visible units (`6`).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 类的第一个函数将接收隐藏单元的数量（`2`）和可见单元的数量（`6`）。
- en: 'The weight matrix is initialized with random weight values at line 20:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 权重矩阵在第 20 行使用随机权重值进行初始化：
- en: '[PRE2]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The bias units will now be inserted in the first row and the first column at
    line 27:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 偏置单元现在将在第 27 行插入到第一行和第一列：
- en: '[PRE3]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The goal of this model will be to observe the behavior of the weights. Observing
    the weights will determine how to interpret the result in this model based on
    calculations between the visible and hidden units.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的目标是观察权重的行为。观察权重将决定如何根据可见单元和隐藏单元之间的计算来解释该模型的结果。
- en: The first row and column are the biases, as shown in the preceding code snippets.
    Only the weights will be analyzed for the profiling functions. The weights and
    biases are now in place.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行和第一列是偏置，如前面的代码片段所示。仅对权重进行分析，以便进行性能分析。现在，权重和偏置已就位。
- en: Creating a training function in the RBM class
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 RBM 类中创建训练函数
- en: 'On line 30, the training function is created:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 30 行，创建了训练函数：
- en: '[PRE4]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In this function:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在此函数中：
- en: '`self` is the class'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`self` 是类。'
- en: '`data` is the 6×6 input array, containing 6 lines of movies and 6 columns of
    features of the movies:'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data` 是一个 6×6 的输入数组，包含 6 行电影和 6 列电影特征：'
- en: '[PRE5]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The RBM model in this chapter is using **visible binary units**, as shown in
    the input, which is the training data of this model. The RBM will use the input
    as training data.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本章中的 RBM 模型使用的是 **可见二进制单元**，如输入所示，这是该模型的训练数据。RBM 将使用输入作为训练数据。
- en: 'An RBM can contain other types of units: softmax units, Gaussian visible units,
    binomial units, rectified linear units, and more. Our model focuses on binary
    units.'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个 RBM 可以包含其他类型的单元：softmax 单元、高斯可见单元、二项单元、修正线性单元等。我们的模型专注于二进制单元。
- en: '`max_epochs` is the number of epochs that the RBM will run to train.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_epochs` 是 RBM 训练的轮数。'
- en: '`learning_rate` is the learning rate that will be applied to the weight matrix containing
    the weights and the biases.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learning_rate`是应用于包含权重和偏置的权重矩阵的学习率。'
- en: 'We will now insert bias units of `1` in the first column on line 35:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第35行的第一列插入偏置单元`1`：
- en: '[PRE6]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: There are other strategies to initialize biases. This is a trial-and-error process,
    depending on your project. In this case, bias units of `1` are sufficient to do
    the job.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化偏置的策略还有其他方法。这是一个试错过程，取决于你的项目。在这种情况下，`1`的偏置单元足以完成任务。
- en: Computing the hidden units in the training function
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练函数中计算隐藏单元
- en: 'On line 37, we start training the RBM during `max_epochs` by computing the
    value of the hidden units:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在第37行，我们通过计算隐藏单元的值，开始训练RBM，持续`max_epochs`：
- en: '[PRE7]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The first phase is to focus on the hidden units. We activate the probabilities
    of the hidden units with our weight matrix using dot matrix multiplication:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个阶段是专注于隐藏单元。我们通过点积矩阵乘法激活隐藏单元的概率：
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, we apply the logistic function as we saw in *Chapter 2*, *Building a
    Reward Matrix – Designing Your Datasets*:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们应用了逻辑函数，如同在*第2章*中所看到的，*构建奖励矩阵 - 设计你的数据集*：
- en: '[PRE9]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The logistic function called is on line 63:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑函数在第63行被调用：
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We set the biases to `1`:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将偏置设置为`1`：
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We now have computed the first epoch of the probabilities of the hidden states
    with random weights.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经计算出了带有随机权重的隐藏状态概率的第一次迭代。
- en: Random sampling of the hidden units for the reconstruction and contractive divergence
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为重建和对比散度随机采样隐藏单元
- en: There are many sampling methods, such as Gibbs sampling, for example, which
    has a randomized approach to avoid deterministic samples.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多采样方法，例如吉布斯采样，它具有随机化方法，以避免确定性样本。
- en: 'In this model, we will choose a random sample that chooses the values of the
    hidden probabilities that exceed the values of a random sample of values. The
    `random.rand` function creates a random matrix with values between `0` and `1`,
    with a size of `num_examples`×`self.num_hidden+1`:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，我们将选择一个随机样本，该样本选择的隐藏概率值超过一个随机值样本的值。`random.rand`函数生成一个随机矩阵，值介于`0`和`1`之间，矩阵的大小为`num_examples`×`self.num_hidden+1`：
- en: '[PRE12]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This sample will be used for the **reconstruction** phase we will explore in
    the next section.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这个样本将用于我们将在下一节中探讨的**重建**阶段。
- en: 'We also need to compute an association for the **contrastive divergence** (the
    function used to update the weight matrix) phase, which is explained hereinunder:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要计算用于**对比散度**（更新权重矩阵的函数）阶段的关联，这是接下来所解释的：
- en: '[PRE13]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This dot product of the visible data units *v* × the hidden units *h* can be
    represented as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 可见数据单元*v*与隐藏单元*h*的点积可以表示如下：
- en: '![](img/B15438_14_004.png)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_004.png)'
- en: Now that the dot product has been implemented, we will build the reconstruction
    phase.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在点积已经实现，我们将构建重建阶段。
- en: Reconstruction
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 重建
- en: An RBM uses its input data as its training data, computes the hidden weights
    using a random weight matrix, and then *reconstructs* the visible units. Instead
    of an output layer as in other neural networks, an RBM reconstructs the visible
    units and compares them to the original data.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: RBM使用其输入数据作为训练数据，使用随机权重矩阵计算隐藏权重，然后*重建*可见单元。与其他神经网络的输出层不同，RBM重建可见单元并将其与原始数据进行比较。
- en: 'The following code applies the same approach as for the hidden units described
    previously to generate visible units:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码应用与之前描述的隐藏单元相同的方法来生成可见单元：
- en: '[PRE14]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: These negative visible units will be used to evaluate the error level of the
    RBM, as explained here.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这些负向可见单元将用于评估RBM的误差水平，如此处所解释。
- en: 'Now that we have generated visible units with our sample of hidden unit states,
    we move on and generate the corresponding hidden states:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经通过隐藏单元状态样本生成了可见单元，接下来我们生成相应的隐藏状态：
- en: '[PRE15]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Note that `neg_associations` can be represented in the following form:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`neg_associations`可以表示为以下形式：
- en: '![](img/B15438_14_005.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_005.png)'
- en: 'Here, we have done the following:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们已经完成了以下操作：
- en: Computed positive hidden states using the visible units containing the training
    data
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用包含训练数据的可见单元计算正向隐藏状态
- en: Selected a random sample of those positive hidden states
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从这些正向隐藏状态中随机选择一个样本
- en: Reconstructed negative (generated from the hidden states, not the data) visible
    states
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重建负向（从隐藏状态生成的，而非数据）可见状态
- en: And, in turn, generated hidden states from the visible states produced
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，由可见状态生成的隐藏状态
- en: We have *reconstructed* visible states through this process. However, we need
    to evaluate the result and update the weights.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过此过程*重构*了可见状态。然而，我们需要评估结果并更新权重。
- en: Contrastive divergence
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对比散度
- en: 'To update the weights, we do not use gradient descent. In this energy model,
    we use contrastive divergence, which can be expressed as follows:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更新权重，我们不使用梯度下降。在这个能量模型中，我们使用对比散度，它可以表达如下：
- en: '![](img/B15438_14_006.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_006.png)'
- en: The letter ![](img/B15438_14_007.png) is the learning rate. The learning rate
    should be a small value and can be optimized throughout the training process.
    I applied a small value, 0.001 overall.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 字母![](img/B15438_14_007.png)是学习率。学习率应该是一个小值，并且可以在整个训练过程中进行优化。我总共使用了一个较小的值0.001。
- en: 'The source code for updating the weights is as follows:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 更新权重的源代码如下：
- en: '[PRE16]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Over the epochs, the weights will adjust, bringing the energy and error level
    down and, hence, bringing the accuracy of the probabilities up.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个时代中，权重会进行调整，从而降低能量和误差水平，进而提高概率的准确性。
- en: At this point, we will display the error level and the energy value of the RBM
    throughout the epochs.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们将展示RBM在整个训练过程中误差水平和能量值的变化。
- en: Error and energy function
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 误差和能量函数
- en: 'On line 56, the error function calculates the squared sum of the difference
    between the visible units provided by the data and the reconstructed visible units:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 在第56行，误差函数计算数据提供的可见单元与重构的可见单元之间差异的平方和：
- en: '[PRE17]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'For the energy function, we can use our original energy equation:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对于能量函数，我们可以使用原始的能量方程：
- en: '![](img/B15438_14_008.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_008.png)'
- en: In our code, we will not use the biases since we often set them to `1`.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的代码中，我们不会使用偏置，因为我们通常将其设置为`1`。
- en: We will also need a function to measure the evolution of the energy of the RBM.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一个函数来衡量RBM能量的演变。
- en: 'The energy will be measured with a probabilistic function *p*:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 能量将通过概率函数*p*来衡量：
- en: '![](img/B15438_14_009.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_009.png)'
- en: '*Z* is a **partition function** for making sure that the sum of the probabilities
    of each *x* input does not exceed 1:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '*Z*是一个**配分函数**，用于确保每个*x*输入的概率之和不超过1：'
- en: '![](img/B15438_14_010.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_010.png)'
- en: 'The partition function is the sum of all the individual probabilities of each
    *x*:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 配分函数是每个*x*的所有单独概率之和：
- en: '![](img/B15438_14_011.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_011.png)'
- en: 'The corresponding code will calculate the energy of the RBM, which will decrease
    over time as the RBM goes through the epochs:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 相应的代码将计算RBM的能量，随着RBM经历多个时代，能量会逐渐降低：
- en: '[PRE18]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: You will note that neither the error function nor the energy function influences
    the training process. The training process is based on contrastive divergence.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到，误差函数和能量函数都不会影响训练过程。训练过程基于对比散度。
- en: The error and energy values will measure the efficiency of the model by providing
    some insight into the behavior of the RBM as it trains.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 误差和能量值将通过提供有关RBM训练行为的一些见解，来衡量模型的效率。
- en: 'Here is an example of these measurement values at the beginning of the process
    and at the end:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在过程开始时和结束时这些测量值的示例：
- en: '[PRE19]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: At epoch 0, the error is high, and the energy is high, too.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在第0个时代，误差很高，能量也很高。
- en: At epoch 4999, the error is sufficiently low for the model to produce correct
    feature extraction values. The energy has significantly diminished.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在第4999个时代，误差足够低，模型能够生成正确的特征提取值。能量显著降低。
- en: Running the epochs and analyzing the results
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行时代并分析结果
- en: 'Once the RBM has optimized the weight-bias matrix for *n* epochs, the matrix
    will provide the following information for the profiler system of person X, for
    example:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦RBM为*n*个时代优化了权重-偏置矩阵，该矩阵将为X人物的分析系统提供以下信息：
- en: '[PRE20]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: An RBM model uses random values and will produce slightly different results
    each time it is trained.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 一个RBM模型使用随机值，每次训练时都会产生稍有不同的结果。
- en: The RBM will train the input and display the features added to X's profile.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: RBM将训练输入并显示添加到X个人档案中的特征。
- en: 'The weights of the features have been trained for person X. The first line
    is the bias and examines columns 2 and 3\. The following six lines are the weights
    of X''s features:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 特征的权重已经为X人物进行了训练。第一行是偏置，检查第2列和第3列。接下来的六行是X人物特征的权重：
- en: '[PRE21]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The weights (in bold) are lines 2 to 6 and columns 2 to 3\. The first line and
    first column are the biases.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 权重（以粗体显示）是第 2 到第 6 行，第 2 到第 3 列。第一行和第一列是偏置项。
- en: 'The way to interpret the weights of an RBM remains a careful strategy to build.
    In this case, a creative approach is experimented with to determine marketing
    behavior. There are many other uses of an RBM, such as image processing, for example.
    In this case, the weight matrix will provide a profile of X by summing the weight
    lines of the feature, as shown in the following code:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 解释 RBM 权重的方式仍然是需要小心构建的策略。在这种情况下，尝试了一种创新方法来确定营销行为。RBM 还有许多其他用途，例如图像处理。在这种情况下，权重矩阵将通过汇总特征的权重行来提供
    X 的个人档案，如下代码所示：
- en: '[PRE22]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The features are now labeled, as displayed in this output:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，特征已被标记，如下输出所示：
- en: '[PRE23]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We can see that beyond standard movie classifications, X likes horizons somewhat,
    does not like violence, and likes action. X finds happiness and love important,
    but not family at this point.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，除了标准的电影分类之外，X 喜欢一些广阔的视野，不喜欢暴力，并且喜欢动作片。X 认为幸福和爱情很重要，但目前并不看重家庭。
- en: The RBM has provided a personal profile of X—not a prediction, but getting ready
    for a suggestion through a chatbot or just building X's machine mind-dataset.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: RBM 已为 X 提供了个人档案——这不是一个预测，而是通过聊天机器人准备好建议，或者只是构建 X 的机器心智数据集。
- en: We have taken a dataset and extracted the main features from it using an RBM.
    The next step will be to use the weights as feature vectors for PCA.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已从数据集中提取了主要特征，并使用 RBM 对其进行处理。接下来的步骤是将权重作为特征向量用于 PCA。
- en: Using the weights of an RBM as feature vectors for PCA
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 RBM 的权重作为 PCA 的特征向量
- en: In this section, we will be writing an enhanced version of `RBM_01.py`. `RBM_01.py`
    produces the feature vector of one viewer named X. The goal now is to extract
    the features of 12,000 viewers, for example, to have a sufficient number of feature
    vectors for PCA.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将编写一个增强版的 `RBM_01.py`。`RBM_01.py` 生成了一个名为 X 的观众的特征向量。现在的目标是提取 12,000
    个观众的特征向量，例如，为主成分分析（PCA）提供足够数量的特征向量。
- en: In `RBM_01.py`, viewer X's favorite movies were first provided in a matrix.
    The goal now is to produce a random sample of 12,000 viewer vectors.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `RBM_01.py` 中，首先在矩阵中提供了观众 X 喜欢的电影。现在的目标是生成 12,000 个观众特征向量的随机样本。
- en: The first task at hand is to create an RBM launcher to run the RBM 12,000 times
    to simulate a random choice of viewers and their favorite movies, which are the
    ones the viewer liked. Then, the feature vector of each viewer will be stored.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的任务是创建一个 RBM 启动器，运行 RBM 12,000 次，以模拟随机选择观众及其喜欢的电影，即观众喜欢的电影。然后，每个观众的特征向量将被存储。
- en: '`RBM_launcher.py` first imports RBM as `rp`:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '`RBM_launcher.py` 首先将 RBM 导入为 `rp`：'
- en: '[PRE24]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The primary goal of `RBM_launcher.py` is to carry out the basic functions to
    run RBM. Once `RBM` is imported, the feature vector''s `.tsv` file is created:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`RBM_launcher.py` 的主要目标是执行运行 RBM 的基本功能。一旦 `RBM` 被导入，特征向量的 `.tsv` 文件将被创建：'
- en: '[PRE25]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: When `rp`, the `RBM` function imported as `rp`, is called, it will append the
    feature file.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当调用导入的 `RBM` 函数 `rp` 时，它将附加特征文件。
- en: 'The next step is to create the label file containing the metadata:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建包含元数据的标签文件：
- en: '[PRE26]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: You will notice the use of the word "emotion." In this context, "emotion" refers
    to features for sentiment analysis in general, not human emotions in particular.
    Please read "emotions" in this context as sentiment analysis features.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到“情感”一词的使用。在这里，“情感”指的是情感分析的特征，而不是特指人类情感。在此背景下，请将“情感”理解为情感分析特征。
- en: 'Now, we are ready to run RBM 12,000+ times, for example:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备运行 RBM 12,000 次以上，例如：
- en: '[PRE27]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '`rp.main()` calls the `main()` function in `RBM.py` that we will now enhance
    for this process.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`rp.main()` 调用了 `RBM.py` 中的 `main()` 函数，我们将增强此函数以适应当前的过程。'
- en: 'We will enhance `RBM_01.py` step-by-step in another file named `RBM.py`. We
    will adapt the code starting line 65 to create an RBM launcher option:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐步在另一个名为 `RBM.py` 的文件中增强 `RBM_01.py`。我们将从第 65 行开始调整代码，创建一个 RBM 启动器选项：
- en: 'A variable name `pt` is set to `0` or `1`, depending on whether we wish to
    display intermediate information:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一个名为 `pt` 的变量被设置为 `0` 或 `1`，取决于是否希望显示中间信息：
- en: '[PRE28]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Since this is an automatic process, `pt` is set to `0`.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个自动化过程，`pt` 设置为 `0`。
- en: 'The metadata of 10 movies is stored in `titles`:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 10 部电影的元数据存储在 `titles` 中：
- en: '[PRE29]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'A feature matrix of movies with six features per movie is created starting
    at line 71, with the same features as in `RBM_01.py`:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 从第 71 行开始，创建了一个包含每部电影六个特征的电影特征矩阵，其特征与 `RBM_01.py` 中的特征相同：
- en: '[PRE30]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Each line of the matrix contains a movie, and each column one of the six features
    of that movie. If the value is `0`, the feature is not present; if the value is
    `1`, the feature is present.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵的每一行包含一部电影，每一列代表该电影的六个特征之一。如果值为`0`，表示该特征不存在；如果值为`1`，表示该特征存在。
- en: In the years to come, the number of features per movie will be extended to an
    indefinite number of features per movie to fine-tune our preferences.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来几年，每部电影的特征数量将扩展为无限数量，以进一步优化我们的偏好。
- en: 'An empty output matrix is created. In `RBM_01.py`, the result was provided.
    In this example, it will be filled with random choices:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个空的输出矩阵。在`RBM_01.py`中，结果已经给出。在这个例子中，它将被随机选择填充：
- en: '[PRE31]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Now, the random movie selector will generate likes or dislikes per movie and
    per viewer:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，随机电影选择器将为每部电影和每位观众生成喜欢或不喜欢的选择：
- en: '[PRE32]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We can choose whether to display the input:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以选择是否显示输入：
- en: '[PRE33]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The dialog output is the data collected by the platform through its like/dislike
    interface. The RBM runs its training session:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 对话输出是平台通过其喜欢/不喜欢界面收集的数据。RBM正在进行训练会话：
- en: '[PRE34]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The results of the RBM training session are now processed from line 185 to
    line 239 to transform the weights obtained into feature vectors and the corresponding
    metadata:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，RBM训练会话的结果从第185行到第239行被处理，用以将获得的权重转换为特征向量及相应的元数据：
- en: '[PRE35]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The goal is now to select the primary feature of a given movie chosen by a
    given viewer. This feature could be "love" or "violence" for example:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的目标是选择由特定观众挑选的某部电影的主要特征。例如，这个特征可以是“爱情”或“暴力”：
- en: '[PRE36]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The secondary feature is also very interesting. It often provides more information
    than the primary feature. A viewer will tend to view a certain type of movie.
    However, the secondary features vary from movie to movie. For example, suppose
    a young viewer likes action movies. "Violence" could be the primary feature, but
    the secondary feature could be "love" in one case or "family" in another. The secondary
    featured is stored in the feature vector of this viewer:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 次要特征同样非常有趣。它通常提供比主要特征更多的信息。观众通常会倾向于观看某一类型的电影。然而，次要特征因电影而异。例如，假设一位年轻观众喜欢动作片。“暴力”可能是主要特征，但在某些情况下，次要特征可能是“爱情”，而在其他情况下则是“家庭”。次要特征存储在该观众的特征向量中：
- en: '[PRE37]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The metadata is saved in the label file:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据保存在标签文件中：
- en: '[PRE38]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: This process will be repeated 12,000 times in this example.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，这个过程将重复12,000次。
- en: 'The feature vector `features.tsv` file has been created:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 特征向量`features.tsv`文件已经创建：
- en: '![](img/B15438_14_04.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_04.png)'
- en: 'Figure 14.4: The feature vector file'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.4：特征向量文件
- en: 'The feature vector `labels.tsv` metadata file matches the feature vector file:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 特征向量`labels.tsv`元数据文件与特征向量文件匹配：
- en: '[PRE39]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: You will note that "love" and "violence" appear often. This comes from the way
    I built the dataset based mostly on movies that contain action and some form of warm
    relationship between the characters, which is typical in movies for the younger
    generations.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到“爱情”和“暴力”出现得很频繁。这是因为我构建数据集时，大多数选择了包含动作和某种形式的角色之间温馨关系的电影，这在年轻一代的电影中很典型。
- en: Now that the feature vectors and the metadata file have been created, we can
    use PCA to represent the points.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 现在特征向量和元数据文件已创建，我们可以使用PCA来表示这些点。
- en: Understanding PCA
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解PCA
- en: PCA is applied very efficiently to marketing by Facebook, Amazon, Google, Microsoft,
    IBM, and many other corporations, among other feature processing algorithms.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: PCA在营销中被Facebook、Amazon、Google、Microsoft、IBM和许多其他公司高效应用，此外，还有其他特征处理算法。
- en: Probabilistic machine learning training remains efficient when targeting apparel,
    food, books, music, travel, cars, and other market consumer segments.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 面向服装、食品、书籍、音乐、旅游、汽车及其他市场消费者群体的概率机器学习训练仍然非常高效。
- en: However, humans are not just consumers; they are human beings. When they contact websites
    or call centers, standard answers or stereotyped emotional tone analysis approaches
    can depend on one's nerves. When humans are in contact with doctors, lawyers,
    and other professional services, a touch of humanity is necessary if major personal
    crises occur.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，人类不仅仅是消费者；他们是有感情的个体。当他们联系网站或呼叫中心时，标准答案或刻板的情感语调分析方法可能会受到一个人神经状态的影响。当人类与医生、律师及其他专业服务人员接触时，若发生重大个人危机，需要一种人情味。
- en: The goal of the PCA, in this context, is to extract key features to describe
    an individual or a population. The PCA phase will help us build a mental representation
    of X's profile, either to communicate with X or use X's mind as a powerful, *mindful*
    chatbot or decision-maker.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，PCA 的目标是提取关键特征来描述一个个体或一个群体。PCA 阶段将帮助我们建立 X 的心智表示，无论是与 X 沟通，还是将 X 的心智作为一个强大、*深思熟虑*
    的聊天机器人或决策者来使用。
- en: PCA isn't a simple concept, so let's take some time to understand it properly.
    We'll start with an intuitive explanation, and after that, we'll get into the
    mathematics behind it.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 不是一个简单的概念，所以我们需要花些时间来正确理解它。我们将从一个直观的解释开始，然后再深入了解背后的数学原理。
- en: PCA takes data and represents it at a higher level.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 将数据表示为更高层次的形式。
- en: For example, imagine you are in your bedroom. You have some books, magazines,
    and music (maybe on your smartphone) around the room. If you consider your room as
    a 3D Cartesian coordinate system, the objects in your room are all in specific *x*,
    *y*, *z* coordinates.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，假设你在你的卧室里。房间里有一些书、杂志和音乐（可能在你的智能手机上）。如果你把你的房间看作一个三维笛卡尔坐标系，房间里的物品就会有特定的 *x*、*y*、*z*
    坐标。
- en: For experimentation purposes, take your favorite objects and put them on your
    bed. Put the objects you like the most near one another, and your second choices
    a bit further away. If you imagine your bed as a 2D Cartesian space, you have
    just made your objects change dimensions. You have brought the objects that you
    value the most into a higher dimension. They are now more visible than the ones
    that have less value for you.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行实验，将你最喜欢的物品放在你的床上。将你最喜欢的物品放在一起，次喜欢的物品稍微远一些。如果你将你的床想象成一个二维笛卡尔空间，你就刚刚让你的物品改变了维度。你把你最重视的物品带入了更高的维度。现在，它们比那些对你来说价值较小的物品更为显眼。
- en: They are not in their usual place anymore; they are on your bed and at specific
    coordinates depending on your taste.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 它们不再处于原来的位置；它们现在在你的床上，并且根据你的兴趣，位于特定的坐标上。
- en: That is the philosophy of PCA. If the number of data points in the dataset is
    very large, the PCA of a "mental dataset" of one person will always be different
    from the PCA representation of another person, like DNA. A "mental dataset" is
    a collection of thoughts, images, words, and feelings of a given person. It is
    more than the classic age, gender, income, and other neutral features. A "mental
    dataset" will take us inside somebody's mind.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 PCA 的哲学。如果数据集中的数据点数量非常庞大，那么一个人的“心智数据集”的 PCA 总是会与另一个人的 PCA 表示不同，像 DNA 一样。“心智数据集”是一个人思想、图像、文字和情感的集合。它不仅仅是经典的年龄、性别、收入等中性特征。“心智数据集”将带我们走进某个人的内心世界。
- en: That is what a conceptual representation learning metamodel (CRLMM) is about
    as applied to a person's mental representation. Each person is different, and
    each person deserves a customized chatbot or bot treatment.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是概念表示学习元模型（CRLMM）应用于一个人心智表示的方式。每个人都是不同的，每个人都值得拥有一个定制化的聊天机器人或机器人处理。
- en: Mathematical explanation
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数学解释
- en: The main steps in calculating PCA are important for understanding how to go
    from the intuitive approach to how TensorBoard Embedding Projector represents
    datasets using PCA.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 计算 PCA 的主要步骤对于理解如何从直观方法过渡到 TensorBoard 嵌入投影仪使用 PCA 表示数据集非常重要。
- en: Variance
  id: totrans-242
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 方差
- en: Variance is when a value changes. For example, as the sun rises in summer, the
    temperature gets warmer and warmer. The variance is represented by the difference
    between the temperature at a given hour and then the temperature a few hours later.
    Covariance is when two variables change together. For example, the hotter it gets
    when we are outside, the more we will sweat to cool our bodies down.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 方差是指一个值发生变化的情况。例如，夏天太阳升起时，温度逐渐变暖。方差由某一时刻的温度和几小时后的温度之间的差异来表示。协方差是指两个变量一起变化的情况。例如，当我们在外面时，天气越来越热，我们会出更多的汗来使身体降温。
- en: '**Step 1**: Calculate the mean of the array `data1`. You can check this with
    `mathfunction.py`, as shown in the following function:'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 1**：计算数组 `data1` 的均值。你可以通过 `mathfunction.py` 来检查这一点，如下所示的函数：'
- en: '[PRE40]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The answer is 2.5\. The mean is not the median (the middle value of an array).
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是 2.5。均值并不是中位数（数组中的中间值）。
- en: '**Step 2**: Calculate the mean of array `data2`. The mean calculation is executed
    with the following standard function:'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 2**：计算数组`data2`的均值。均值的计算是通过以下标准函数实现的：'
- en: '[PRE41]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: The answer is ![](img/B15438_14_012.png). The bar above the *X* signifies that
    it is a mean.
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 答案是 ![](img/B15438_14_012.png)。*X* 上方的横线表示它是一个均值。
- en: '**Step 3**: Calculate the variance using the following equation:'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**步骤 3**：使用以下方程计算方差：'
- en: '![](img/B15438_14_013.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_013.png)'
- en: 'Now, NumPy will calculate the variance with the absolute value of each *x*
    minus the mean, sum them up, and divide the sum by *n*, as shown in the following
    code snippet:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，NumPy 将通过计算每个 *x* 减去均值的绝对值，求和并将总和除以 *n* 来计算方差，代码示例如下：
- en: '[PRE42]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Some variances are calculated with *n* – 1 depending on the population of the
    dataset.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 一些方差根据数据集的总体来计算，使用 *n* - 1。
- en: 'The result of the program for variances is as displayed in the following output:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 程序输出的方差结果如下所示：
- en: '[PRE43]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We can already see that `data2` varies a lot more than `data1`. Do they fit
    together? Are their variances close or not? Do they vary in the same way? Our
    goal in the following section is to find out whether two words, for example, will
    often be found together or close to one another, taking the output of the embedding
    program into account.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经可以看到 `data2` 的变化远大于 `data1`。它们是否匹配？它们的方差是否接近？它们是否以相同的方式变化？我们接下来要做的目标是，了解两个词语，举例来说，是否经常一起出现或靠得很近，同时考虑到嵌入程序的输出。
- en: Covariance
  id: totrans-258
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 协方差
- en: 'The covariance will tell us whether these datasets vary together or not. The
    equation follows the same philosophy as variance, but now both variances are joined
    to see whether they belong together:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 协方差将告诉我们这些数据集是否一起变化。该方程遵循与方差相同的理念，不过现在两个方差被结合在一起，看它们是否属于同一组：
- en: '![](img/B15438_14_014.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_014.png)'
- en: 'As with the variance, the denominator can be *n* – 1 depending on your model.
    Also, in this equation, the numerator is expanded to visualize the co-part of
    covariance, as implemented in the following array in `mathfunction.py`:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 与方差类似，分母可以是 *n* - 1，这取决于你的模型。此外，在这个方程中，分子被展开，以便可视化协方差的共同部分，如 `mathfunction.py`
    中的以下数组实现：
- en: '[PRE44]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'NumPy''s output is a covariance matrix, `a`:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 的输出是协方差矩阵 `a`：
- en: '[PRE45]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: If you increase some of the values of the dataset, it will increase the value
    of the parts of the matrix. If you decrease some of the values of the dataset,
    the elements of the covariance matrix will decrease.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你增加数据集中的一些值，它将增加矩阵部分的值。如果你减少数据集中的一些值，协方差矩阵的元素将会减少。
- en: Looking at some of the elements of the matrix increase or decrease that way
    takes time and observation. What if we could find one or two values that would
    give us that information?
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 观察矩阵中某些元素的增减变化需要时间和观察。如果我们能找到一个或两个值来为我们提供这些信息呢？
- en: Eigenvalues and eigenvectors
  id: totrans-267
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 特征值和特征向量
- en: To make sense of the covariance matrix, the eigenvector will point to the direction
    in which the covariances are going. The eigenvalues will express the magnitude
    or importance of a given feature.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解协方差矩阵，特征向量会指向协方差的方向。特征值将表达给定特征的大小或重要性。
- en: To sum it up, an eigenvector will provide the direction and the eigenvalue of
    the importance for the covariance matrix, `a`. With those results, we will be
    able to represent the PCA with TensorBoard Embedding Projector in a multidimensional
    space.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，特征向量将提供方向，特征值则提供协方差矩阵 `a` 的重要性。通过这些结果，我们将能够在多维空间中使用 TensorBoard 嵌入投影器表示
    PCA。
- en: 'Let `w` be an eigenvalue(s) of `a`. An eigenvalue(s) must satisfy the following
    equation:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 设 `w` 为 `a` 的特征值。特征值必须满足以下方程：
- en: '[PRE46]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: There must exist a vector, `v`, for which `dot(a,v)` is the same as `w*v`.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 必须存在一个向量 `v`，使得 `dot(a,v)` 与 `w*v` 相同。
- en: 'NumPy will do the math through the following function:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 将通过以下函数来进行计算：
- en: '[PRE47]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The eigenvalues are displayed (in ascending order) in the following output:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值（按升序排列）将在以下输出中显示：
- en: '[PRE48]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now, we need the eigenvectors to see in which direction these values should
    be applied. NumPy provides a function to calculate both the eigenvalues and eigenvectors
    together. That is because eigenvectors are calculated using the eigenvalues of
    a matrix, as shown in this code snippet:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要特征向量来查看这些值应该应用的方向。NumPy 提供了一个函数来同时计算特征值和特征向量。因为特征向量是通过矩阵的特征值计算的，如下代码所示：
- en: '[PRE49]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The output of the program is as follows:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的输出如下所示：
- en: '[PRE50]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Eigenvalues come in a 1D array with the eigenvalues of `a`.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值以 1D 数组的形式出现，包含 `a` 的特征值。
- en: Eigenvectors come in a 2D square array with the corresponding value (for each
    eigenvalue) in columns.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 特征向量以二维方阵形式呈现，列中包含相应的值（每个特征值的值）。
- en: Creating the feature vector
  id: totrans-283
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 创建特征向量
- en: 'The remaining step is to sort the eigenvalues from the highest to the lowest
    value. The highest eigenvalue will provide the principal component (most important).
    The eigenvector that goes with it will be its feature vector. You can choose to
    ignore the lowest values or features. In the dataset, there will be hundreds,
    and often thousands, of features to represent. Now we have the feature vector:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的步骤是将特征值从最高到最低进行排序。最高的特征值将提供主成分（最重要的部分）。与其对应的特征向量将是其特征向量。你可以选择忽略最低的特征值或特征。在数据集中，将会有数百个，甚至通常是数千个特征需要表示。现在我们得到了特征向量：
- en: feature vector = FV = {eigenvector[1], eigenvector[2] … *n*}
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 特征向量 = FV = {特征向量[1]，特征向量[2] … *n*}
- en: '*n* means that there could be many more features to transform into a PCA feature
    vector.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '*n*表示可能有更多特征需要转换为PCA特征向量。'
- en: Deriving the dataset
  id: totrans-287
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 推导数据集
- en: 'The final step is to transpose the feature vector and original dataset and
    multiply the row feature vector by row data:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是转置特征向量和原始数据集，并将行特征向量与行数据相乘：
- en: Data that will be displayed = row of feature vector * row of data
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 显示的数据 = 特征向量行 * 数据行
- en: Summing it up
  id: totrans-290
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 总结
- en: The highest value of eigenvalues is the principal component. The eigenvector
    will determine in which direction the data points will be oriented when multiplied
    by that vector.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 特征值的最高值是主成分。与其对应的特征向量将决定数据点在乘以该向量后将朝哪个方向排列。
- en: Using TensorFlow's Embedding Projector to represent PCA
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用TensorFlow的嵌入式投影仪表示PCA
- en: TensorBoard Embedding Projector offers an in-built PCA function that can be
    rapidly configured to fit our needs. TensorBoard can be called as a separate program
    or embedded in a program as we saw in *Chapter 13*, *Visualizing Networks with
    TensorFlow 2.x and TensorBoard*.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: TensorBoard嵌入式投影仪提供了一个内置的PCA功能，可以快速配置以满足我们的需求。TensorBoard可以作为独立程序调用，也可以嵌入程序中，如我们在*第13章*中看到的，*使用TensorFlow
    2.x和TensorBoard可视化网络*。
- en: We will then extract key information on the viewer marketing segment that will
    be used to start building a chatbot in *Chapter 15*, *Setting Up a Cognitive NLP
    UI/CUI Chatbot*.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将提取观众营销细分的关键信息，这些信息将用于开始构建*第15章*中的聊天机器人，*设置认知NLP UI/CUI聊天机器人*。
- en: 'First, go to this link: [https://projector.tensorflow.org/](https://projector.tensorflow.org/)'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，访问此链接：[https://projector.tensorflow.org/](https://projector.tensorflow.org/)
- en: 'For the following functions, bear in mind that TensorBoard Embedding Projector
    is working at each step and that it might take some time depending on your machine.
    We load the data produced by `RBM_launcher.py` and `RBM.py` by clicking on **Load**:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以下功能，请记住，TensorBoard嵌入式投影仪在每个步骤中都在工作，具体时间可能根据你的机器不同而有所不同。我们通过点击**加载**来加载由`RBM_launcher.py`和`RBM.py`生成的数据：
- en: '![](img/B15438_14_05.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_05.png)'
- en: 'Figure 14.5: The Load button'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.5：加载按钮
- en: 'Once the **Load data from your computer** windows appear, we load the feature
    vector `features.tsv` file by clicking on **Choose file**:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 当**从计算机加载数据**窗口出现时，我们通过点击**选择文件**来加载特征向量`features.tsv`文件：
- en: '![](img/B15438_14_06.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_06.png)'
- en: 'Figure 14.6: Loading the feature vector file'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.6：加载特征向量文件
- en: 'We load the `labels.tsv` metadata file by clicking on **Choose file** in **Step
    2 (optional)**:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过点击**步骤2（可选）**中的**选择文件**来加载`labels.tsv`元数据文件：
- en: '![](img/B15438_14_07.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_07.png)'
- en: 'Figure 14.7: Loading a TSV file'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.7：加载TSV文件
- en: 'To obtain a good representation of our 12,000+ features, click on **Sphereize
    data,** which is not checked in default mode:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得我们12,000多个特征的良好表示，请点击**球形化数据**，默认模式下该选项未勾选：
- en: '![](img/B15438_14_08.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_08.png)'
- en: 'Figure 14.8: Sphereizing data'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.8：球形化数据
- en: 'We now choose label by **secondary_emotion**, color by **secondary_emotion**,
    along with edit by **secondary_emotion**:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在选择标签为**secondary_emotion**，颜色为**secondary_emotion**，并按**secondary_emotion**进行编辑：
- en: '![](img/B15438_14_09.png)'
  id: totrans-309
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_09.png)'
- en: 'Figure 14.9: Managing labels'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.9：管理标签
- en: 'To get a nice view of the data, we activate night mode so that the moon should
    be active:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得数据的良好视图，我们激活夜间模式，以使月亮应处于活动状态：
- en: '![](img/B15438_14_10.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_10.png)'
- en: 'Figure 14.10: Activating the night mode'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.10：激活夜间模式
- en: 'At this point, we have a nice PCA representation that turns like Earth, the
    ideas in our mind, or the minds of all of the viewers we are analyzing depending
    on how we use the features. The dots on the image are datapoints representing
    the features we calculated with an RBM and then represented with an image using
    PCA. It is like peeking inside the mind:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们有一个漂亮的 PCA 表示法，它像地球一样旋转，或者像我们大脑中的想法，或我们正在分析的所有观众的想法，具体取决于我们如何使用这些特征。图像中的点是数据点，表示我们通过
    RBM 计算的特征，然后通过 PCA 使用图像进行表示。这就像窥探内心世界：
- en: '![](img/B15438_14_11.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_11.png)'
- en: 'Figure 14.11: A PCA representation of features'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.11：特征的 PCA 表示法
- en: The PCA representation of the features of a given person or a group of people
    provides vital information to create dialogs in a chatbot. Let's analyze the PCA
    to prepare data for a chatbot.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个人或一组人的特征的 PCA 表示法提供了创建聊天机器人对话的重要信息。让我们分析 PCA，以准备聊天机器人的数据。
- en: Analyzing the PCA to obtain input entry points for a chatbot
  id: totrans-318
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分析 PCA 以获取聊天机器人的输入入口点
- en: The goal is to gather some information to get started with our cognitive chatbot.
    We will use the filters provided by TensorBoard.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是收集一些信息，以启动我们的认知聊天机器人。我们将使用 TensorBoard 提供的过滤器。
- en: 'Choose **secondary_emotion** as the basis of our filters:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 选择**secondary_emotion**作为我们过滤器的基础：
- en: '![](img/B15438_14_12.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_12.png)'
- en: 'Figure 14.12: Filtering data'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.12：过滤数据
- en: 'The features we are analyzing are as follows:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在分析的特征如下：
- en: '[PRE51]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: We need to see the statistics per feature.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要查看每个特征的统计数据。
- en: 'We type the feature in TensorBoard''s search option, such as "love," for example,
    and then we click the down arrow:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 TensorBoard 的搜索选项中键入特征，如“爱情”，然后点击下拉箭头：
- en: '![](img/B15438_14_13.png)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_13.png)'
- en: 'Figure 14.13: TensorBoard''s search option'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.13：TensorBoard 的搜索选项
- en: 'The PCA representation changes its view in realtime:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 表示法会实时改变其视图：
- en: '![](img/B15438_14_14.png)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15438_14_14.png)'
- en: 'Figure 14.14: PCA representation of the RBM features'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.14：RBM 特征的 PCA 表示法
- en: There are 643 points for "love." Notice that the "love" points are grouped in
    a relatively satisfactory way. They are mostly in the same area of the image and
    not spread out all over the image. This grouping shows that the weights of the
    RBM provided features that turned out to be sufficiently correct in the PCA for
    this experiment.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: “爱情”有 643 个点。注意，“爱情”点位聚集在一个相对令人满意的位置。它们大多集中在图像的同一区域，而不是分散在整个图像中。这种分组表明，RBM 提供的特征在本次实验的
    PCA 中是足够正确的。
- en: 'We repeat the process for each feature, to obtain the number of points per
    feature and visualize them. For the dataset supplied on GitHub for this chapter,
    we obtain:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对每个特征重复该过程，以获取每个特征的点数并进行可视化。在 GitHub 上为本章提供的数据集中，我们得到了：
- en: 'Love: 643'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 爱情：643
- en: 'Happiness: 2267'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 幸福感：2267
- en: 'Family: 0'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Family: 0'
- en: 'Horizons: 1521'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Horizions: 1521'
- en: 'Action: 2976'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动作：2976
- en: 'Violence: 4594'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 暴力：4594
- en: '**Important**: This result will naturally change if `RBM_launcher.py` runs
    again since it''s a random viewer-movie choice process.'
  id: totrans-340
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**重要**：如果再次运行`RBM_launcher.py`，该结果会发生变化，因为这是一个随机的观看者电影选择过程。'
- en: 'The results provide interesting information on the marketing segment we are
    targeting for the chatbot:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 结果提供了关于我们为聊天机器人所针对的营销领域的有趣信息：
- en: Violence and action point to action movies.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 暴力和动作指向动作电影。
- en: Family=0 points to younger viewers; teenagers, for example, more interested
    in action than creating a family.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Family=0 表示更年轻的观众；例如，青少年更感兴趣的是动作而不是创建家庭。
- en: Discovering happiness and love are part of the horizons they are looking for.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现幸福感和爱情是他们正在寻找的视野的一部分。
- en: This is typical of superhero series and movies. Superheroes are often solitary
    individuals.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常出现在超级英雄系列和电影中。超级英雄通常是孤独的个体。
- en: We will see how this works out when we build our chatbot in *Chapter 15*, *Setting
    Up a Cognitive NLP UI/CUI Chatbot*.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在*第15章*中看到如何构建聊天机器人并实现此目标，*设置认知 NLP UI/CUI 聊天机器人*。
- en: Summary
  id: totrans-347
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we prepared key information to create the input dialog of a
    chatbot. Using the weights of an RBM as features constituted the first step. We
    saw that we could use neural networks to extract features from datasets and represent
    them using the optimized weights.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们准备了创建聊天机器人输入对话框的关键信息。使用 RBM 的权重作为特征是第一步。我们看到，可以使用神经网络从数据集中提取特征，并通过优化的权重进行表示。
- en: Processing the likes/dislikes of a movie viewer reveals the features of the
    movies that, in turn, provide a mental representation of a marketing segment.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 处理电影观众的喜好/不喜欢可以揭示电影的特征，这些特征进一步提供了一个市场细分的心理表征。
- en: PCA chained to an RBM will generate a vector space that can be viewed in TensorBoard
    Embedding Projector in a few clicks.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 将PCA与RBM链式连接，可以生成一个向量空间，几次点击即可在TensorBoard嵌入投影器中查看。
- en: Once TensorBoard was set up, we analyzed the statistics to understand the marketing
    segment the dataset originated from. By listing the points per feature, we found
    the main features that drove this marketing segment.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦设置好TensorBoard，我们分析了统计数据，以了解数据集来源的市场细分。通过列出每个特征的点数，我们找出了驱动该市场细分的主要特征。
- en: Having discovered some of the key features of the marketing segment we were
    analyzing, we can now move on to the next chapter and start building a chatbot
    for the viewers. At the same time, we will keep backdoors available in case the
    dialogs show that we need to fine-tune our feature vector statistics.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在发现我们分析的市场细分的一些关键特征后，我们可以进入下一章，开始为观众构建聊天机器人。同时，我们将保持后门可用，以防对话表明我们需要微调特征向量统计数据。
- en: Questions
  id: totrans-353
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: RBMs are based on directed graphs. (Yes | No)
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RBM基于有向图。（是 | 否）
- en: The hidden units of an RBM are generally connected to one another. (Yes | No)
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RBM的隐藏单元通常是相互连接的。（是 | 否）
- en: Random sampling is not used in an RBM. (Yes | No)
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在RBM中不使用随机采样。（是 | 否）
- en: PCA transforms data into higher dimensions. (Yes | No)
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PCA将数据转换为更高的维度。（是 | 否）
- en: In a covariance matrix, the eigenvector shows the direction of the vector representing
    that matrix, and the eigenvalue shows the size of that vector. (Yes | No)
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在协方差矩阵中，特征向量显示了表示该矩阵的向量方向，而特征值显示了该向量的大小。（是 | 否）
- en: It is impossible to represent a human mind in a machine. (Yes | No)
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无法在机器中表示人类大脑。（是 | 否）
- en: A machine cannot learn concepts, which is why classical applied mathematics
    is enough to make efficient artificial intelligence programs for every field.
    (Yes | No)
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 机器无法学习概念，这就是为什么经典的应用数学足以为各个领域制作高效的人工智能程序。（是 | 否）
- en: Further reading
  id: totrans-361
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more on RBMs, refer to: [https://skymind.ai/wiki/restricted-boltzmann-machine](https://skymind.ai/wiki/restricted-boltzmann-machine)'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想了解更多关于RBM的内容，请参考：[https://skymind.ai/wiki/restricted-boltzmann-machine](https://skymind.ai/wiki/restricted-boltzmann-machine)
- en: 'The original reference site for the source code in this chapter can be found
    here: [https://github.com/echen/restricted-boltzmann-machines/blob/master/README.md](https://github.com/echen/restricted-boltzmann-machines/blob/master/README.md)'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章源代码的原始参考网站可以在这里找到：[https://github.com/echen/restricted-boltzmann-machines/blob/master/README.md](https://github.com/echen/restricted-boltzmann-machines/blob/master/README.md)
- en: 'The original Geoffrey Hinton paper can be found here: [http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf](http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf)'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原始的Geoffrey Hinton论文可以在这里找到：[http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf](http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf)
- en: 'For more on PCA, refer to this link: [https://www.sciencedirect.com/topics/engineering/principal-component-analysis](https://www.sciencedirect.com/topics/engineering/principal-component-analysis)'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 想了解更多关于PCA的内容，请参考这个链接：[https://www.sciencedirect.com/topics/engineering/principal-component-analysis](https://www.sciencedirect.com/topics/engineering/principal-component-analysis)
- en: 'Ready-to-use RBM resources are located here: [https://pypi.org/project/pydbm/](https://pypi.org/project/pydbm/)'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可直接使用的RBM资源可以在这里找到：[https://pypi.org/project/pydbm/](https://pypi.org/project/pydbm/)
