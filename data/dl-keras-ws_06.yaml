- en: 6\. Model Evaluation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. 模型评估
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter covers model evaluation in depth. We will discuss alternatives
    to accuracy to evaluate the performance of a model when standard techniques are
    not feasible, especially where there are imbalanced classes. Finally, we will
    utilize confusion matrices, sensitivity, specificity, precision, FPR, ROC curves,
    and AUC scores to evaluate the performance of classifiers. By the end of this
    chapter, you will have an in-depth understanding of accuracy and null accuracy
    and will be able to understand and combat the challenges of imbalanced datasets.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将深入讨论模型评估。我们将讨论在标准技术不可行时，如何使用其他方法来评估模型的性能，特别是在类别不平衡的情况下。最后，我们将利用混淆矩阵、敏感性、特异性、精确度、假阳性率（FPR）、ROC
    曲线和 AUC 分数来评估分类器的性能。在本章结束时，你将深入理解准确度和零准确度，并能够理解并应对不平衡数据集的挑战。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: In the previous chapter, we covered `regularization` techniques for neural networks.
    `Regularization` is an important technique when it comes to combatting how a model
    overfits the training data and helps the model perform well on new, unseen data
    examples. One of the regularization techniques we covered involved `L1` and `L2`
    weight regularizations, in which penalization is added to the weights. The other
    regularization technique we learned about was `dropout regularization`, in which
    some units of layers are randomly removed from the model fitting process at each
    iteration. Both regularization techniques are designed to prevent individual weights
    or units by influencing them too strongly and allowing them to generalize as well.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了神经网络的 `正则化` 技术。`正则化` 是一种重要的技术，用于防止模型对训练数据过拟合，并帮助模型在新的、未见过的数据样本上表现良好。我们讨论的正则化技术之一是
    `L1` 和 `L2` 权重正则化，在其中对权重进行惩罚。我们还学习了另一种正则化技术——`丢弃正则化`，在每次迭代中，随机移除模型中的某些层单元，防止它们过度影响模型拟合过程。这两种正则化技术的设计目的是防止单个权重或单元被过度影响，从而使模型能够更好地泛化。
- en: In this chapter, we will learn about some different evaluation techniques other
    than `accuracy`. For any data scientist, the first step after building a model
    is to evaluate it, and the easiest way to evaluate a model is through its accuracy.
    However, in real-world scenarios, particularly where there are classification
    tasks with highly imbalanced classes such as for predicting the presence of hurricanes,
    predicting the presence of a rare disease, or predicting if someone will default
    on a loan, evaluating the model using its accuracy score is not the best evaluation
    technique.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习一些与 `准确度` 不同的评估技术。对于任何数据科学家来说，构建模型后的第一步是评估模型，而评估模型的最简单方法就是通过其准确度。然而，在现实世界的场景中，特别是在分类任务中，当类别高度不平衡时，比如预测飓风的发生、预测罕见疾病的出现或预测某人是否会违约时，使用准确度分数来评估模型并不是最好的评估方法。
- en: This chapter explores core concepts such as imbalanced datasets and how different
    evaluation techniques can be used to work through these imbalanced datasets. This
    chapter begins with an introduction to accuracy and its limitations. Then, we
    will explore the concepts of `null accuracy`, `imbalanced datasets`, `sensitivity`,
    `specificity`, `precision`, `false positives`, `ROC curves`, and `AUC scores`.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章探讨了核心概念，如不平衡数据集以及如何使用不同的评估技术来处理这些不平衡数据集。本章首先介绍准确度及其局限性。然后，我们将探索 `零准确度`、`不平衡数据集`、`敏感性`、`特异性`、`精确度`、`假阳性`、`ROC
    曲线` 和 `AUC 分数` 等概念。
- en: Accuracy
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准确度
- en: To understand accuracy properly, let's explore model evaluation. Model evaluation
    is an integral part of the model development process. Once you've built your model
    and executed it, the next step is to evaluate your model.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确理解准确度，让我们探索模型评估。模型评估是模型开发过程中的一个关键部分。一旦你构建并执行了模型，下一步就是评估你的模型。
- en: A model is built on a `training dataset` and evaluating a model's performance
    on the same training dataset is bad practice in data science. Once a model has
    been trained on a training dataset, it should be evaluated on a dataset that is
    completely different from the training dataset. This dataset is known as the `test
    dataset`. The objective should always be to build a model that generalizes, which
    means the model should produce similar (but not the same) results, or relatively
    similar results, on any dataset. This can only be achieved if we evaluate the
    model on data that is unknown to it.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是基于 `训练数据集` 构建的，在同一个训练数据集上评估模型的表现在数据科学中是不推荐的。一旦模型在训练数据集上训练完成，它应该在与训练数据集完全不同的数据集上进行评估。这个数据集被称为
    `测试数据集`。目标始终是构建一个具有泛化能力的模型，也就是说，模型应该在任何数据集上都能产生类似（但不完全相同）的结果，或者是相对相似的结果。只有在使用模型未知的数据进行评估时，才能实现这一目标。
- en: 'The model evaluation process requires a metric that can quantify a model''s
    performance. The simplest metric for model evaluation is accuracy. `Accuracy`
    is the fraction of predictions that our model gets right. This is the formula
    for calculating `accuracy`:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 模型评估过程需要一个能够量化模型表现的指标。模型评估中最简单的指标就是准确率。`准确率` 是我们的模型预测正确的比例。计算 `准确率` 的公式如下：
- en: '*Accuracy = (Number of correct predictions) / (Total number of predictions)*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*准确率 = （正确预测数量）/（总预测数量）*'
- en: For example, if we have `10` records and `7` are predicted correctly, then we
    can say that the accuracy of our model is `70%`. This is calculated as `7/10`
    = `0.7` or `70%`.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们有 `10` 条记录，其中 `7` 条预测正确，那么我们可以说模型的准确率是 `70%`。计算方法为 `7/10` = `0.7` 或 `70%`。
- en: '`Null accuracy` is the accuracy that can be achieved by predicting the most
    frequent class. If we don''t run an algorithm and just predict accuracy based
    on the most frequent outcome, then the accuracy that''s calculated based on this
    prediction is known as `null accuracy`:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '`Null accuracy` 是通过预测最频繁类别可以达到的准确率。如果我们不运行算法，而只是基于最频繁的结果预测准确率，那么基于此预测计算得到的准确率就是
    `null accuracy`：'
- en: '*Null accuracy = (Total number of instances of the frequently occurring class)
    / (Total number of instances)*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*Null accuracy = （最频繁类别的实例总数）/（实例总数）*'
- en: 'Take a look at this example:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下这个例子：
- en: '10 actual outcomes: [1,0,0,0,0,0,0,0,1,0].'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '10 个实际结果: [1,0,0,0,0,0,0,0,1,0]。'
- en: '`Prediction`: [0,0,0,0,0,0,0,0,0,0]'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`预测`: [0,0,0,0,0,0,0,0,0,0]'
- en: '`Null accuracy` = 8/10 = 0.8 or 80%'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '`Null accuracy` = 8/10 = 0.8 或 80%'
- en: So, our null accuracy is `80%`, meaning we are correct `80%` of the time. This
    means we have achieved `80%` accuracy without running an algorithm. Always remember
    that when null accuracy is high, it means that the distribution of response variables
    is skewed in favor of the frequently occurring class.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的 `null accuracy` 是 `80%`，意味着我们在 `80%` 的情况下预测是正确的。这意味着我们在没有运行任何算法的情况下就达到了
    `80%` 的准确率。请记住，当 null accuracy 较高时，表示响应变量的分布偏向于频繁出现的类别。
- en: Let's work on an exercise to find the null accuracy of a dataset. The null accuracy
    of a dataset can be found by using the `value_count` function in the pandas library.
    The `value_count` function returns a series containing counts of unique values.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来做一个练习，计算数据集的 null accuracy。可以通过使用 pandas 库中的 `value_count` 函数来找到数据集的 null
    accuracy。`value_count` 函数返回一个包含唯一值计数的序列。
- en: Note
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: All the Jupyter Notebooks for the exercises and activities in this chapter are
    available on GitHub at [https://packt.live/37jHNUR](https://packt.live/37jHNUR).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中所有的 Jupyter Notebook 练习和活动可在 GitHub 上找到：[https://packt.live/37jHNUR](https://packt.live/37jHNUR)。
- en: 'Exercise 6.01: Calculating Null Accuracy on a Pacific Hurricanes Dataset'
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 6.01：计算太平洋飓风数据集的 Null Accuracy
- en: 'We have a dataset documenting whether a `hurricane` has been observed in the
    Pacific Ocean that has two columns, `Date` and `hurricane`. The `Date` column
    indicates the date of the observation, while the `hurricane` column indicates
    whether there was a hurricane on that date. Rows with a `hurricane` value of `1`
    means there was a hurricane, while `0` means there was no hurricane. Find the
    `null accuracy` of the dataset by following these steps:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个数据集，记录了是否在太平洋上观察到 `飓风`，该数据集有两列，`日期` 和 `飓风`。`日期` 列表示观察的日期，而 `飓风` 列表示该日期是否有飓风发生。`飓风`
    列的值为 `1` 表示发生了飓风，值为 `0` 表示没有飓风发生。通过以下步骤可以计算该数据集的 `null accuracy`：
- en: 'Open a Jupyter notebook. Import all the required libraries and load the `pacific_hurricanes.csv`
    file into the `data` folder from this book''s GitHub repository:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Jupyter笔记本。导入所有必要的库，并从本书的GitHub仓库中将`pacific_hurricanes.csv`文件加载到`data`文件夹中：
- en: '[PRE0]'
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following is the output of the preceding code:'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下是前面代码的输出：
- en: '![Figure 6.1: Data exploration of the pacific hurricanes dataset'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图6.1：太平洋飓风数据集的探索'
- en: '](img/B15777_06_01.jpg)'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_06_01.jpg)'
- en: 'Figure 6.1: Data exploration of the pacific hurricanes dataset'
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图6.1：太平洋飓风数据集的探索
- en: 'Use the built-in `value_count` function from the pandas library to get the
    distribution for the data of the `hurricane` column. The `value_count` function
    shows the total instances of unique values:'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`pandas`库内置的`value_count`函数来获取`hurricane`列数据的分布。`value_count`函数显示了唯一值的总实例：
- en: '[PRE1]'
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The preceding code produces the following output:'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码产生的输出如下：
- en: '[PRE2]'
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Use the `value_count` function and set the `normalize` parameter to `True`.
    To find the null accuracy, you will have to index the `pandas` series that was
    produced for index `0` to get the proportion of values related to no hurricanes
    occurring on a given day:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`value_count`函数并将`normalize`参数设置为`True`。为了找到空值准确度，你需要索引为`0`的`pandas`序列，来获取与某一天没有发生飓风相关的值的比例：
- en: '[PRE3]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The preceding code produces the following output:'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码产生的输出如下：
- en: '[PRE4]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The calculated `null accuracy` of the dataset is `92.4126%`.
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 计算出的数据集`空值准确度`为`92.4126%`。
- en: Here, we can see that our dataset has a very high null accuracy of `92.4126%`.
    So, if we just make a dumb model that predicts the majority class for all outcomes,
    our model will be `92.4126%` accurate.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到数据集的空值准确度非常高，达到了`92.4126%`。因此，如果我们仅仅创建一个傻瓜模型，对所有结果预测多数类，那么我们的模型将会有`92.4126%`的准确度。
- en: Note
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/31FtQBm](https://packt.live/31FtQBm).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/31FtQBm](https://packt.live/31FtQBm)。
- en: You can also run this example online at [https://packt.live/2ArNwNT](https://packt.live/2ArNwNT).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在[https://packt.live/2ArNwNT](https://packt.live/2ArNwNT)在线运行这个示例。
- en: Later in this chapter, in *Activity 6.01*, *Computing the Accuracy and Null
    Accuracy of a Neural Network When We Change the Train/Test Split,* we will see
    how null accuracy changes as we change the `test`/`train` split.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章后面，在*活动6.01*中，*在我们更改训练/测试拆分时计算神经网络的准确度和空值准确度*，我们将看到空值准确度如何随着`test`/`train`拆分的变化而变化。
- en: Advantages and Limitations of Accuracy
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准确度的优缺点
- en: 'The advantages of accuracy are as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 准确度的优点如下：
- en: '**Easy to use**: Accuracy is very easy to compute and understand as it is just
    a simple fraction formula.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于使用**：准确度的计算非常简单，容易理解，因为它只是一个简单的分数公式。'
- en: '**Popular compared to other techniques**: Since it is the easiest metric to
    compute, it is also the most popular and is universally accepted as the first
    step of evaluating a model. Most introductory books on data science teach accuracy
    as an evaluation metric.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与其他技术相比更流行**：由于它是最容易计算的度量，它也是最受欢迎的，并且被普遍接受作为评估模型的第一步。大多数数据科学入门书籍都会将准确度作为评估指标来讲解。'
- en: '**Good for comparing different models**: Suppose you are trying to solve a
    problem with different models. You can always trust the model that gives the highest
    accuracy.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**适用于比较不同的模型**：假设你正在尝试使用不同的模型解决问题。你总是可以信任那个给出最高准确度的模型。'
- en: 'The limitations of accuracy are as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 准确度的局限性如下：
- en: '`response`/`dependent` variable. If we get an accuracy of `80%` in our model,
    we have no idea how the response variable is distributed and what the null accuracy
    of the dataset is. If the null accuracy of our dataset is above `70%`, then an
    `80%` accurate model is pretty useless.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`response`/`dependent`变量。如果我们模型的准确度为`80%`，我们并不知道响应变量是如何分布的，以及数据集的空值准确度是多少。如果我们数据集的空值准确度超过`70%`，那么一个`80%`准确的模型就毫无意义。'
- en: '`Accuracy` also gives us no information about `type 1` and `type 2` errors
    of the model. A `type 1` error is when a class is `negative` and we have predicted
    it as `positive`, while a `type 2` error is when a class is positive and we have
    predicted it as negative. We will be studying both of these errors later in this
    chapter. In the next section, we will cover the imbalanced datasets. The accuracy
    scores for models classifying imbalanced datasets can be particularly misleading,
    which is why other evaluation metrics are useful for model evaluation.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`准确率`同样无法提供关于模型的`类型1`和`类型2`错误的任何信息。`类型1`错误是当某一类为`负`类时，我们将其预测为`正`类，而`类型2`错误则是当某一类为正类时，我们将其预测为负类。我们将在本章稍后研究这两种错误。在下一节中，我们将讨论不平衡数据集。对于分类不平衡数据集的模型来说，准确率分数可能会特别具有误导性，这也是为什么其他评估指标对模型评估很有用的原因。'
- en: Imbalanced Datasets
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不平衡数据集
- en: Imbalanced datasets are a distinct case for classification problems where the
    class distribution varies between the classes. In such datasets, one class is
    overwhelmingly dominant. In other words, the `null accuracy` of an imbalanced
    dataset is very high.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 不平衡数据集是分类问题中的一种特殊情况，其中类分布在各个类别之间存在差异。在这种数据集中，某一类别占据主导地位。换句话说，不平衡数据集的`空准确率`非常高。
- en: 'Consider an example of credit card fraud. If we have a dataset of credit card
    transactions, then we will find that, of all the transactions, a very minuscule
    number of transactions were fraudulent and the majority of transactions were normal
    transactions. If `1` represents a fraudulent transaction and `0` represents a
    normal transaction, then there will be many 0s and hardly any 1s. The `null accuracy`
    of the dataset may be more than `99%`. This means that the majority class (in
    this case, `0`) is overwhelmingly greater than the minority class (in this case,
    `1`). Such sets are imbalanced datasets. Consider the following figure, which
    shows a general imbalanced dataset `scatter plot`:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以信用卡欺诈为例。如果我们有一个信用卡交易的数据集，那么我们会发现，在所有交易中，欺诈交易的数量非常少，而大多数交易都是正常交易。如果`1`代表欺诈交易，`0`代表正常交易，那么数据中会有许多`0`，几乎没有`1`。该数据集的`空准确率`可能会超过`99%`。这意味着多数类（在此案例中是`0`）远大于少数类（在此案例中是`1`）。这就是不平衡数据集的特点。请看下面的图表，它展示了一个一般的不平衡数据集的`散点图`：
- en: '![Figure 6.2: A general imbalanced dataset scatter plot'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.2：一个一般的、不平衡数据集的散点图'
- en: '](img/B15777_06_02.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_06_02.jpg)'
- en: 'Figure 6.2: A general imbalanced dataset scatter plot'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2：一个一般的、不平衡数据集的散点图
- en: The preceding plot shows a generalized scatter plot of an imbalanced dataset,
    where the stars represent the minority class and the circles represent the majority
    class. As we can see, there are many more circles than stars; this can make it
    difficult for machine learning models to distinguish between the two classes.
    In the next section, we will cover some approaches to working with imbalanced
    datasets.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表展示了一个不平衡数据集的广义散点图，其中星星代表少数类，圆圈代表多数类。正如我们所见，圆圈的数量远多于星星；这可能使得机器学习模型很难区分这两类。在下一节中，我们将讨论一些处理不平衡数据集的方法。
- en: Working with Imbalanced Datasets
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理不平衡数据集
- en: 'In machine learning, there are two ways of overcoming the shortcomings of imbalanced
    datasets, which are as follows:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，有两种方法可以克服不平衡数据集的缺点，具体如下：
- en: '`90%`, then sampling techniques struggle to give the correct representation
    of majority-minority classes in the data and our model may overfit. So, the best
    way is to modify our evaluation techniques.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`90%`，然后采样技术很难正确地表现数据中多数类和少数类的比例，这可能导致我们的模型过拟合。因此，最好的方法是修改我们的评估技术。'
- en: '**Modifying model evaluation techniques**: When working with highly imbalanced
    datasets, it is better to modify model evaluation techniques. This is the most
    robust way to get good results, which means using these methods will likely achieve
    good results on new, unseen data. There are many evaluation metrics other than
    accuracy that can be modified to evaluate a model. To learn about all those techniques,
    it is important to understand the concept of the confusion matrix.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修改模型评估技术**：当处理高度不平衡的数据集时，最好修改模型评估技术。这是获得良好结果的最稳健的方法，意味着使用这些方法很可能会在新数据上获得好结果。除了准确率外，还有许多其他评估指标可以修改来评估模型。要了解所有这些技术，首先需要理解混淆矩阵的概念。'
- en: Confusion Matrix
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混淆矩阵
- en: 'A `confusion matrix` describes the performance of the classification model.
    In other words, a confusion matrix is a way to summarize classifier performance.
    The following table shows a basic representation of a confusion matrix and represents
    how the predicted results by the model compared to the true values:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`混淆矩阵`描述了分类模型的性能。换句话说，混淆矩阵是总结分类器性能的一种方式。下表展示了混淆矩阵的基本表示，并表示模型预测结果与实际值的比较：'
- en: '![Figure 6.3: Basic representation of a confusion matrix'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.3：混淆矩阵的基本表示'
- en: '](img/B15777_06_03.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_06_03.jpg)'
- en: 'Figure 6.3: Basic representation of a confusion matrix'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.3：混淆矩阵的基本表示
- en: 'Let''s go over the meanings of the abbreviations that were used in the preceding
    table:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下前表中使用的缩写的含义：
- en: '**TN** (**True negative**): This is the count of outcomes that were originally
    negative and were predicted negative.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TN**（**真负例**）：这是指原本为负的结果被预测为负的数量。'
- en: '**FP** (**False positive**): This is the count of outcomes that were originally
    negative but were predicted positive. This error is also called a **type 1 error**.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FP**（**假正例**）：这是指原本为负的结果被预测为正的数量。这种错误也叫做**第一类错误**。'
- en: '**FN** (**False negative**): This is the count of outcomes that were originally
    positive but were predicted negative. This error is also called a **type 2 error**.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FN**（**假负例**）：这是指原本为正的结果被预测为负的数量。这种错误也叫做**第二类错误**。'
- en: '**TP** (**True positive**): This is the count of outcomes that were originally
    positive and were predicted as positive.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TP**（**真正例**）：这是指原本为正的结果被预测为正的数量。'
- en: The goal is to maximize the values in the **TN** and **TP** boxes in the preceding
    table, that is, the true negatives and true positives, and minimize the values
    in the **FN** and **FP** boxes, that is, the false negatives and false positives.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是最大化前表中**TN**和**TP**框中的值，即真正负例和真正正例，同时最小化**FN**和**FP**框中的值，即假负例和假正例。
- en: 'The following code is an example of a confusion matrix:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码是混淆矩阵的一个示例：
- en: '[PRE5]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The preceding code produces the following output:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码会生成如下输出：
- en: '[PRE6]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The aim of all machine learning and deep learning algorithms is to maximize
    TN and TP and minimize FN and FP. The following example code calculates TN, FP,
    FN, and TP:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 所有机器学习和深度学习算法的目标都是最大化TN和TP，最小化FN和FP。以下示例代码计算了TN、FP、FN和TP：
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Accuracy does not help us understand type 1 and type 2 errors.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率无法帮助我们理解第一类错误和第二类错误。
- en: Metrics Computed from a Confusion Matrix
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从混淆矩阵计算的指标
- en: 'The metrics that can be derived from a `confusion matrix` are `sensitivity`,
    `specificity`, `precision`, `FP rate`, `ROC`, and `AUC`:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 从`混淆矩阵`中可以推导出以下指标：`灵敏度`、`特异性`、`精度`、`假阳性率`、`ROC`和`AUC`：
- en: '`1`, divided by the total number of patients who are actually `1`:'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1`，除以实际为`1`的患者总数：'
- en: '*Sensitivity = TP / (TP+FN)*'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*灵敏度 = TP / (TP+FN)*'
- en: Sensitivity refers to how often the prediction is correct when the actual value
    is positive. In cases such as building a model to predict patient readmission
    at a hospital, we need our model to be highly sensitive. We need 1 to be predicted
    as `1`. If a `0` is predicted as `1`, it is acceptable, but if a `1` is predicted
    as `0`, it means a patient who was readmitted is predicted as not readmitted,
    and this will cause severe penalties for the hospital.
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 灵敏度是指当实际值为正时，预测正确的频率。在构建如预测患者再入院的模型等情况下，我们需要模型具有很高的灵敏度。我们需要将`1`预测为`1`。如果`0`被预测为`1`，是可以接受的，但如果`1`被预测为`0`，意味着本应再入院的患者被预测为没有再入院，这会对医院造成严重的惩罚。
- en: '`0` divided by the total number of patients who were actually `0`. Specificity
    is also known as the true negative rate:'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`0`，除以实际为`0`的患者总数。特异性也称为真负例率：'
- en: '*Specificity = TN / (TN+FP)*'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*特异性 = TN / (TN+FP)*'
- en: Specificity refers to how often the prediction is correct when the actual value
    is negative. There are cases, such as spam email detection, where we need our
    algorithm to be more specific. The model predicts `1` when an email is spam and
    `0` when it isn't. We want the model to predict `0` as always `0`, because if
    a non-spam email is classified as spam, important emails may end up in the spam
    folder. Sensitivity can be compromised here because some spam emails may arrive
    in our inbox, but non-spam emails should never go to the spam folder.
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 特异性指的是当实际值为负时，预测正确的频率。比如在垃圾邮件检测中，我们希望算法更具特异性。当一封邮件是垃圾邮件时，模型预测为`1`；当不是垃圾邮件时，预测为`0`。我们希望模型总是将非垃圾邮件预测为`0`，因为如果一个非垃圾邮件被误分类为垃圾邮件，重要邮件可能会进入垃圾邮件文件夹。这里灵敏度可能会有所妥协，因为一些垃圾邮件可能会进入收件箱，但非垃圾邮件绝对不应该进入垃圾邮件文件夹。
- en: Note
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: As we discussed previously, whether a model should be sensitive or specific
    totally depends on the business problem.
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，模型应该偏向灵敏度还是特异性完全取决于业务问题。
- en: '**Precision**: This is the true positive prediction divided by the total number
    of positive predictions. Precision refers to how often we are correct when the
    value predicted is positive:'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**精确度**：这是正确预测的正样本数量除以总的正样本预测数量。精确度指的是当预测值为正时，我们预测正确的频率：'
- en: '*Precision = TP / (TP+FP)*'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*精确度 = TP / (TP+FP)*'
- en: '`FPR` is calculated as the ratio between the number of false-positive events
    and the total number of actual negative events. `FPR` refers to how often we are
    incorrect when the actual value is negative. `FPR` is also equal to `1` - specificity:'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FPR`的计算方法是将假阳性事件的数量与实际负样本总数相除。`FPR`指的是当实际值为负时，我们预测错误的频率。`FPR`也等于`1` - 特异性：'
- en: '*False positive rate = FP / (FP+TN)*'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*假阳性率 = FP / (FP+TN)*'
- en: '`ROC curve`. A `ROC curve` is a plot between the true positive rate (`sensitivity`)
    and the `FPR` (`1 - specificity`). The following plot shows an example of an `ROC
    curve`:![Figure 6.4: An example of ROC curve'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ROC曲线`。`ROC曲线`是一个图形，表示真实正例率（`灵敏度`）和`FPR`（`1 - 特异性`）之间的关系。以下图展示了一个`ROC曲线`的示例：![图6.4：ROC曲线的示例'
- en: '](img/B15777_06_04.jpg)'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_06_04.jpg)'
- en: 'Figure 6.4: An example of ROC curve'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4：ROC曲线的示例
- en: 'To decide which `ROC curve` is the best among multiple curves, we need to look
    at the empty space on the upper left of the curve—the smaller the space, the better
    the result. The following plot shows an example of multiple `ROC curves`:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了决定在多个曲线中哪个`ROC曲线`最好，我们需要查看曲线左上方的空白区域——空白区域越小，结果越好。以下图展示了多个`ROC曲线`的示例：
- en: '![Figure 6.5: An example of multiple ROC curves'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.5：多个ROC曲线的示例'
- en: '](img/B15777_06_05.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_06_05.jpg)'
- en: 'Figure 6.5: An example of multiple ROC curves'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5：多个ROC曲线的示例
- en: Note
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The red curve is better than the blue curve because it leaves less space in
    the upper-left corner.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 红色曲线比蓝色曲线更好，因为它在左上角留下的空白更少。
- en: The `ROC curve` of a model tells us the relationship between `sensitivity` and
    `specificity`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的`ROC曲线`告诉我们`灵敏度`和`特异性`之间的关系。
- en: '`ROC curve`. Sometimes, `AUC` is also written as `AUROC`, meaning the area
    under the `ROC curve`. Basically, `AUC` is a numeric value that represents the
    area under a `ROC curve`. The larger the area under the `ROC`, the better, and
    the bigger the `AUC score`, the better. The preceding plot shows us an example
    of an `AUC`.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ROC曲线`。有时，`AUC`也写作`AUROC`，表示`ROC曲线`下的面积。基本上，`AUC`是一个数值，表示`ROC曲线`下的面积。`ROC`下的面积越大越好，`AUC分数`越大越好。前面的图展示了一个`AUC`的示例。'
- en: 'In the preceding plot, the `AUC` of the red curve is greater than the `AUC`
    of the blue curve, which means the `AUC` of the red curve is better than the AUC
    of the blue curve. There is no standard rule for the `AUC score`, but here are
    some generally acceptable values and how they relate to model quality:'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的图中，红色曲线的`AUC`大于蓝色曲线的`AUC`，这意味着红色曲线的`AUC`优于蓝色曲线的`AUC`。`AUC分数`没有标准规则，但以下是一些普遍可接受的值及其与模型质量的关系：
- en: '![Figure 6.6: General acceptable AUC score'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '![图6.6：一般可接受的AUC分数'
- en: '](img/B15777_06_06.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_06_06.jpg)'
- en: 'Figure 6.6: General acceptable AUC score'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6：一般可接受的AUC分数
- en: Now that we understand the theory behind the various metrics, let's complete
    some activities and exercises to implement what we have learned.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了各种度量背后的理论，让我们通过一些活动和练习来实施所学的内容。
- en: 'Exercise 6.02: Computing Accuracy and Null Accuracy with APS Failure for Scania
    Trucks Data'
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习6.02：使用Scania卡车数据计算准确率和空值准确率
- en: The dataset that we will be using in this exercise consists of data that's been
    collected from heavy Scania trucks in everyday usage that have failed in some
    way. The system in focus is the `Air pressure system` (`APS`), which generates
    pressurized air that is utilized in various functions in a truck, such as braking
    and gear changes. The positive class in the dataset represents component failures
    for a specific component in the APS, while the negative class represents failures
    for components not related to the APS.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本练习中使用的数据集来自于重型斯堪尼亚卡车在日常使用中的故障数据。关注的系统是 `空气压力系统`（`APS`），该系统生成的加压空气用于卡车的各种功能，如刹车和换挡。数据集中的正类表示
    APS 中某个特定部件的故障，而负类表示与 APS 无关的部件的故障。
- en: The objective of this exercise is to predict which trucks have had failures
    due to the APS so that the repair and maintenance mechanics have the information
    they can work with when checking why the truck failed and which area of the truck
    needs to be inspected.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的目标是预测哪些卡车由于 APS 系统发生故障，以便修理和维护人员能够在检查卡车故障原因时获得有用的信息，并了解卡车需要检查的具体部件。
- en: Note
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The dataset for this exercise can be downloaded from this book's GitHub repository
    at [https://packt.live/2SGEEsH](https://packt.live/2SGEEsH).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的数据集可以从本书的 GitHub 仓库下载，地址为 [https://packt.live/2SGEEsH](https://packt.live/2SGEEsH)。
- en: Throughout this exercise, you may get slightly different results due to the
    random nature of the internal mathematical operations.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在整个练习过程中，由于内部数学运算的随机性，你可能会获得略微不同的结果。
- en: '**Data preprocessing and exploratory data analysis**:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据预处理和探索性数据分析**：'
- en: 'Import the required libraries. Load the dataset using the pandas `read_csv`
    function and explore the first `five` rows of the dataset:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所需的库。使用 pandas 的 `read_csv` 函数加载数据集，并查看数据集的前 `five` 行：
- en: '[PRE8]'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following table shows the output of the preceding code:'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下表展示了前述代码的输出：
- en: '![Figure 6.7: First five rows of the patient readmission dataset'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.7：患者重新入院数据集的前五行'
- en: '](img/B15777_06_07.jpg)'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_06_07.jpg)'
- en: 'Figure 6.7: First five rows of the patient readmission dataset'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.7：患者重新入院数据集的前五行
- en: 'Describe the feature values in the dataset using the `describe` method:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `describe` 方法描述数据集中的特征值：
- en: '[PRE9]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following table shows the output of the preceding code:'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下表展示了前述代码的输出：
- en: '![Figure 6.8: Numerical metadata of the patient readmission dataset'
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.8：患者重新入院数据集的数值元数据'
- en: '](img/B15777_06_08.jpg)'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_06_08.jpg)'
- en: 'Figure 6.8: Numerical metadata of the patient readmission dataset'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.8：患者重新入院数据集的数值元数据
- en: Note
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Independent variables are also known as explanatory variables, while dependent
    variables are also known as `response variables`. Also, remember that indexing
    in Python starts from `0`.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自变量也被称为解释变量，而因变量则被称为 `响应变量`。另外，请记住，Python 中的索引是从 `0` 开始的。
- en: 'Explore `y` using the `head` function:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `head` 函数查看 `y` 的内容：
- en: '[PRE10]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following table shows the output of the preceding code:'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下表展示了前述代码的输出：
- en: '![Figure 6.9: The first five rows of the y variable of the patient readmission
    dataset'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.9：患者重新入院数据集 `y` 变量的前五行'
- en: '](img/B15777_06_09.jpg)'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_06_09.jpg)'
- en: 'Figure 6.9: The first five rows of the y variable of the patient readmission
    dataset'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.9：患者重新入院数据集 `y` 变量的前五行
- en: 'Split the data into test and train sets by using the `train_test_split` function
    from the scikit-learn library. To make sure we all get the same results, set the
    `random_state` parameter to `42`. The data is split with an `80:20 ratio`, meaning
    `80%` of the data is `training data` and the remaining `20%` is `test data`:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 库中的 `train_test_split` 函数将数据拆分为测试集和训练集。为了确保我们获得相同的结果，设置 `random_state`
    参数为 `42`。数据按 `80:20` 比例拆分，即 `80%` 为 `训练数据`，剩余的 `20%` 为 `测试数据`：
- en: '[PRE11]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Scale the training data using the `StandardScaler` function and use the scaler
    to scale the `test data`:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `StandardScaler` 函数对训练数据进行缩放，并使用该缩放器对 `test data` 进行缩放：
- en: '[PRE12]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The `sc.fit_transform()` function transforms the data and the data is converted
    into a `NumPy` array. We may need the data for further analysis in the DataFrame
    objects, so the `pd.DataFrame()` function reconverts data into a DataFrame.
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`sc.fit_transform()` 函数对数据进行转换，数据会被转换成 `NumPy` 数组。我们可能需要在数据框对象中进行进一步分析，因此 `pd.DataFrame()`
    函数将数据重新转换为数据框。'
- en: This completes the data preprocessing part of this exercise. Now, we need to
    build a neural network and calculate the `accuracy`.
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这完成了本次练习的数据预处理部分。现在，我们需要构建神经网络并计算`准确率`。
- en: 'Import the libraries that are required for creating the neural network architecture:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入创建神经网络架构所需的库：
- en: '[PRE13]'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Initiate the `Sequential` class:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化`Sequential`类：
- en: '[PRE14]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Add `five` hidden layers of the `Dense` class and the add `Dropout` after each.
    Build the first hidden layer so that it has a size of `64` and with a dropout
    rate of `0.5`. The second hidden layer will have a size of `32` and a dropout
    rate of `0.4`. The third hidden layer will have a size of `16` and a dropout rate
    of `0.3`. The fourth hidden layer will have a size of `8` and dropout rate of
    `0.2`. The final hidden layer will have a size of `4` and a dropout rate of `0.1`.
    Each hidden layer will have a `ReLU activation` function and the kernel initializer
    will be set to `uniform`:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加`五`个`Dense`类的隐藏层，并在每个隐藏层后面加上`Dropout`。构建第一个隐藏层，大小为`64`，丢弃率为`0.5`。第二个隐藏层的大小为`32`，丢弃率为`0.4`。第三个隐藏层的大小为`16`，丢弃率为`0.3`。第四个隐藏层的大小为`8`，丢弃率为`0.2`。最后一个隐藏层的大小为`4`，丢弃率为`0.1`。每个隐藏层使用`ReLU激活`函数，并且权重初始化器设置为`uniform`：
- en: '[PRE15]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Add an output `Dense` layer with a `sigmoid` activation function:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个输出层，使用`sigmoid`激活函数：
- en: '[PRE16]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Since the output is binary, we are using the `sigmoid` function. If the output
    is multiclass (that is, more than two classes), then the `softmax` function should
    be used.
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于输出是二分类，我们使用`sigmoid`函数。如果输出是多分类（即超过两个类别），则应该使用`softmax`函数。
- en: 'Compile the network and fit the model. Calculate the accuracy during the training
    process by setting `metrics=[''accuracy'']`:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译网络并拟合模型。在训练过程中，通过设置`metrics=['accuracy']`来计算准确率：
- en: '[PRE17]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Fit the model with `100` epochs, a batch size of `20`, and a validation split
    of `20%`:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`100`个训练周期（epochs），批处理大小为`20`，验证集比例为`20%`来训练模型：
- en: '[PRE18]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Evaluate the model on the `test` dataset:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`test`数据集上评估模型：
- en: '[PRE19]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The preceding code produces the following output:'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE20]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The model returns an accuracy of `98.9917%`. But is it good enough? We can only
    get the answer to this question by comparing it with the null accuracy.
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型返回的准确率为`98.9917%`。但是，这个结果够好吗？我们只能通过与空准确率进行比较来回答这个问题。
- en: '**Compute the null accuracy:**'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**计算空准确率：**'
- en: 'The null accuracy can be calculated using the `value_count` function of the
    pandas library, which we used in *Exercise 6.01*, *Calculating Null Accuracy on
    a Pacific Hurricanes Dataset*, of this chapter:'
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 空准确率可以通过使用`pandas`库的`value_count`函数来计算，我们在本章的*练习6.01*中使用了它，*在太平洋飓风数据集上计算空准确率*：
- en: '[PRE21]'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The preceding code produces the following output:'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE22]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Calculate the `null` accuracy:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算`空`准确率：
- en: '[PRE23]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The preceding code produces the following output:'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE24]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Here, we have obtained the null accuracy of the model. As we conclude this
    exercise, the following points must be noted: the accuracy of our model is `98.9917%`,
    approximately. Under ideal conditions, `98.9917%` accuracy is very `good` accuracy,
    but here, the `null accuracy` is `very high`, which helps put our model''s performance
    into perspective. The `null accuracy` of our model is `98.2333%`. Since the `null
    accuracy` of the model is `so high`, an `accuracy` of `98.9917%` is not significant
    but certainly respectable, and `accuracy` in such cases is not the correct metric
    to evaluate an algorithm with.'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们得到了模型的空准确率。随着我们结束这个练习，以下几点必须注意：我们模型的准确率大约是`98.9917%`。在理想情况下，`98.9917%`的准确率是非常`好`的准确率，但这里，`空准确率`非常高，这有助于我们将模型的表现放到一个合理的视角下。我们模型的`空准确率`为`98.2333%`。由于模型的`空准确率`如此之高，`98.9917%`的准确率并不具有显著意义，但肯定是值得尊敬的，而在这种情况下，`准确率`并不是评估算法的正确指标。
- en: Note
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/31FUb2d](https://packt.live/31FUb2d).
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要访问该部分的源代码，请参阅[https://packt.live/31FUb2d](https://packt.live/31FUb2d)。
- en: You can also run this example online at [https://packt.live/3goL0ax](https://packt.live/3goL0ax).
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个示例：[https://packt.live/3goL0ax](https://packt.live/3goL0ax)。
- en: Now, let's go through activity on computing the accuracy and null accuracy of
    the neural network model when we change the train/test split.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过活动来计算神经网络模型在我们改变训练/测试数据集划分时的准确率和空准确率。
- en: 'Activity 6.01: Computing the Accuracy and Null Accuracy of a Neural Network
    When We Change the Train/Test Split'
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 6.01：计算神经网络在我们改变训练/测试数据集划分时的准确率和空准确率
- en: 'A train/test split is a random sampling technique. In this activity, we will
    see that our null accuracy and accuracy will be affected by changing the `train`/`test`
    split. To implement this, the part of the code where the train/test split was
    defined has to be changed. We will use the same dataset that we used in *Exercise
    6.02*, *Computing Accuracy and Null Accuracy with APS Failure for Scania Trucks
    Data*. Follow these steps to complete this activity:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 训练/测试划分是一种随机采样技术。在此活动中，我们将看到，通过改变`train`/`test`划分，我们的零准确度和准确度会受到影响。要实现这一点，必须更改定义`train/test`划分的代码部分。我们将使用在*练习
    6.02*中使用的相同数据集，*计算斯堪尼亚卡车数据的准确度和零准确度*。按照以下步骤完成此活动：
- en: Import all the necessary dependencies and load the dataset.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必要的依赖项并加载数据集。
- en: Change `test_size` and `random_state` from `0.20` to `0.30` and `42` to `13`,
    respectively.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`test_size`和`random_state`分别从`0.20`更改为`0.30`，从`42`更改为`13`。
- en: Scale the data using the `StandardScaler` function.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`StandardScaler`函数对数据进行缩放。
- en: Import the libraries that are required to build a neural network architecture
    and initiate the `Sequential` class.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入构建神经网络架构所需的库，并初始化`Sequential`类。
- en: Add the `Dense` layers with `Dropout`. Set the first hidden layer so that it
    has a size of `64` with a dropout rate of `0.5`, the second hidden layer so that
    it has a size of `32` with a dropout rate of `0.4`, the third hidden layer so
    that is has a size of `16` with a dropout rate of `0.3`, the fourth hidden layer
    so that it has a size of `8` with a dropout rate of `0.2`, and the final hidden
    layer so that it has a size of `4` with a dropout rate of `0.1`. Set all the activation
    functions to `ReLU`.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加带有`Dropout`的`Dense`层。设置第一个隐藏层，使其大小为`64`，丢弃率为`0.5`，第二个隐藏层设置为`32`，丢弃率为`0.4`，第三个隐藏层设置为`16`，丢弃率为`0.3`，第四个隐藏层设置为`8`，丢弃率为`0.2`，最后一个隐藏层设置为`4`，丢弃率为`0.1`。将所有激活函数设置为`ReLU`。
- en: Add an output `Dense` layer with the `sigmoid` activation function.
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个输出`Dense`层，并使用`sigmoid`激活函数。
- en: Compile the network and fit the model using accuracy. Fit the model with 100
    epochs and a batch size of 20.
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编译网络并使用准确度拟合模型。用100个epoch和20的批量大小拟合模型。
- en: Fit the model to the training data while saving the results from the fit process.
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据，并保存拟合过程中的结果。
- en: Evaluate the model on the test dataset.
  id: totrans-190
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在测试数据集上评估模型。
- en: Count the number of values in each class of the test target dataset.
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 统计测试目标数据集中每个类别的值的数量。
- en: Calculate the null accuracy using the pandas `value_count` function.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用pandas的`value_count`函数计算零准确度。
- en: Note
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: In this activity, you may get slightly different results due to the random nature
    of internal mathematical operations.
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在此活动中，由于内部数学操作的随机性质，您可能会得到略有不同的结果。
- en: Here, we can see that the accuracy and null accuracy will change as we change
    the `train`/`test` split. We will not cover any sampling techniques in this chapter
    as we have a very highly imbalanced dataset, and sampling techniques will not
    yield any fruitful results.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，随着`train`/`test`划分的变化，准确度和零准确度也会发生变化。由于我们的数据集极度不平衡，并且采样技术不会带来有效的结果，本章不涉及任何采样技术。
- en: Note
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 430.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 本活动的解决方案可以在第430页找到。
- en: Let's move on to the next exercise and compute the metrics that have been derived
    from the confusion matrix.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续进行下一个练习，并计算基于混淆矩阵得出的指标。
- en: 'Exercise 6.03: Deriving and Computing Metrics Based on a Confusion Matrix'
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 6.03：基于混淆矩阵推导并计算指标
- en: The dataset that we will be using in this exercise consists of data that has
    been collected from heavy Scania trucks in everyday usage that have failed in
    some way. The system that's in focus is the `Air Pressure System` (`APS`), which
    generates pressurized air that is utilized in various functions in a truck, such
    as braking and gear changes. The positive class in the dataset represents component
    failures for a specific component in the APS, while the negative class represents
    failures for components not related to the APS.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本次练习中使用的数据集包含来自重型斯堪尼亚卡车的日常使用数据，这些卡车在某些方面发生了故障。焦点系统是`空气压力系统`（`APS`），它生成的加压空气被用于卡车的各种功能，如刹车和换档。数据集中的正类表示`APS`中某个特定组件的故障，而负类表示与`APS`无关的组件故障。
- en: 'The objective of this exercise is to predict which trucks have had failures
    due to the APS, much like we did in the previous exercise. We will derive the
    sensitivity, specificity, precision, and false positive rate of the neural network
    model to evaluate its performance. Finally, we will adjust the threshold value
    and recompute the sensitivity and specificity. Follow these steps to complete
    this exercise:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的目标是预测哪些卡车由于APS发生故障，就像我们在前一个练习中所做的那样。我们将推导出神经网络模型的灵敏度、特异性、精确度和假阳性率，以评估其性能。最后，我们将调整阈值并重新计算灵敏度和特异性。按照以下步骤完成此练习：
- en: Note
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The dataset for this exercise can be downloaded from this book's GitHub repository
    at [https://packt.live/2SGEEsH](https://packt.live/2SGEEsH).
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的数据集可以从本书的GitHub仓库下载：[https://packt.live/2SGEEsH](https://packt.live/2SGEEsH)。
- en: You may get slightly different results due to the random nature of internal
    mathematical operations.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 由于内部数学运算的随机性，您可能会得到略微不同的结果。
- en: 'Import the necessary libraries and load the data using the pandas `read_csv`
    function:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的库并使用pandas的`read_csv`函数加载数据：
- en: '[PRE25]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Next, split the data into training and test datasets using the `train_test_split`
    function:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用`train_test_split`函数将数据分割为训练集和测试集：
- en: '[PRE26]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Following this, scale the feature data so that it has a `mean` of `0` and a
    `standard deviation` of `1` using the `StandardScaler` function. Fit the scaler
    to the `training data` and apply it to the `test data`:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，使用`StandardScaler`函数对特征数据进行缩放，使其具有`0`的`均值`和`1`的`标准差`。将缩放器拟合到`训练数据`并将其应用于`测试数据`：
- en: '[PRE27]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Next, import the `Keras` libraries that are required to create the model. Instantiate
    a `Keras` model of the `Sequential` class and add five hidden layers to the model,
    including dropout for each layer. The first hidden layer should have a size of
    `64` and a dropout rate of `0.5`. The second hidden layer should have a size of
    `32` and a dropout rate of `0.4`. The third hidden layer should have a size of
    `16` and a dropout rate of `0.3`. The fourth hidden layer should have a size of
    `8` and a dropout rate of `0.2`. The final hidden layer should have a size of
    `4` and a dropout rate of `0.1`. All the hidden layers should have `ReLU activation`
    functions and have `kernel_initializer = ''uniform''`. Add a final output layer
    to the model with a `sigmoid activation` function. Compile the model by calculating
    the accuracy metric during the training process:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，导入创建模型所需的`Keras`库。实例化一个`Keras`的`Sequential`类模型，并向模型中添加五个隐藏层，每个层都包括dropout。第一个隐藏层的大小应为`64`，dropout率为`0.5`。第二个隐藏层的大小应为`32`，dropout率为`0.4`。第三个隐藏层的大小应为`16`，dropout率为`0.3`。第四个隐藏层的大小应为`8`，dropout率为`0.2`。最后一个隐藏层的大小应为`4`，dropout率为`0.1`。所有隐藏层都应使用`ReLU激活`函数，并且`kernel_initializer
    = 'uniform'`。为模型添加一个最终的输出层，并使用`sigmoid激活`函数。通过在训练过程中计算准确性指标来编译模型：
- en: '[PRE28]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Next, fit the model to the training data by training for `100` epochs with
    `batch_size=20` and `validation_split=0.2`:'
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，通过训练`100`个周期，`batch_size=20`，并设置`validation_split=0.2`来拟合模型：
- en: '[PRE29]'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Once the model has finished fitting to the `training data`, create a variable
    that is the result of the model''s prediction on the `test data` using the model''s
    `predict` and `predict_proba` methods:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦模型完成对`训练数据`的拟合，创建一个变量，该变量是使用模型的`predict`和`predict_proba`方法对`测试数据`进行预测的结果：
- en: '[PRE30]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Next, compute the predicted class by setting the value of the prediction on
    the `test set` to `1` if the value is above `0.5` and `0` if it''s below `0.5`.
    Compute the `confusion matrix` using the `confusion_matrix` function from `scikit-learn`:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，通过设置`测试集`上预测值大于`0.5`时的预测值为`1`，小于`0.5`时为`0`来计算预测类别。使用`scikit-learn`的`confusion_matrix`函数计算`混淆矩阵`：
- en: '[PRE31]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The preceding code produces the following output:'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码会产生以下输出：
- en: '[PRE32]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Always use `y_test` as the first parameter and `y_pred_class1` as the second
    parameter so that you always get the correct results.
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 始终将`y_test`作为第一个参数，将`y_pred_class1`作为第二个参数，以确保始终获得正确的结果。
- en: 'Calculate the true negative (`TN`), false negative (`FN`), false positive (`FP`),
    and true positive (`TP`):'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算真正例（`TN`）、假负例（`FN`）、假阳性（`FP`）和真正阳性（`TP`）：
- en: '[PRE33]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Note
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Using `y_test` and `y_pred_class1` in that order is necessary because if they
    are used in reverse order, the matrix will still be computed without errors, but
    will be incorrect.
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 按照`y_test`和`y_pred_class1`的顺序使用是必要的，因为如果顺序颠倒，矩阵仍然会被计算，但结果将不正确。
- en: 'Calculate the `sensitivity`:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算`灵敏度`：
- en: '[PRE34]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The preceding code produces the following output:'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE35]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Calculate the `specificity`:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算`特异性`：
- en: '[PRE36]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The preceding code produces the following output:'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE37]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Calculate the `precision`:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算`精确度`：
- en: '[PRE38]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The preceding code produces the following output:'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE39]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Calculate the `false positive rate`:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算`假阳性率`：
- en: '[PRE40]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The preceding code produces the following output:'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE41]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The following image shows the output of the values:'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了值的输出：
- en: '![Figure 6.10: Metrics summary'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.10：指标汇总](img/B15777_06_10.jpg)'
- en: '](img/B15777_06_10.jpg)'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_06_10.jpg)'
- en: 'Figure 6.10: Metrics summary'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.10：指标汇总
- en: Note
  id: totrans-246
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Sensitivity is inversely proportional to specificity.
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 灵敏度与特异性成反比。
- en: As we discussed previously, our model should be more sensitive, but it looks
    more specific and less sensitive. So, how do we solve this? The answer lies in
    the threshold probabilities. The sensitivity of the model can be increased by
    adjusting the threshold value for classifying the dependent variable as `1` or
    `0`. Recall that, originally, we set the value of `y_pred_class1` to greater than
    `0.5`. Let's change the threshold to `0.3` and rerun the code to check the results.
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的那样，我们的模型应该更敏感，但它看起来更具特异性，且灵敏度较低。那么，我们该如何解决这个问题呢？答案在于阈值概率。通过调整分类依赖变量为`1`或`0`的阈值，可以提高模型的灵敏度。回想一下，最初我们将`y_pred_class1`的值设置为大于`0.5`。让我们将阈值更改为`0.3`，并重新运行代码来检查结果。
- en: 'Go to *step 7*, change the threshold from `0.5` to `0.3`, and rerun the code:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到*步骤7*，将阈值从`0.5`改为`0.3`，并重新运行代码：
- en: '[PRE42]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Now, create a `confusion matrix` and calculate the `specificity` and `sensitivity`:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建一个`混淆矩阵`并计算`特异性`和`灵敏度`：
- en: '[PRE43]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The preceding code produces the following output:'
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE44]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'For comparison, the following is the previous `confusion matrix` with a `threshold`
    of `0.5`:'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了对比，以下是阈值为`0.5`的之前的`混淆矩阵`：
- en: '[PRE45]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Note
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: Always remember that the original values of `y_test` should be passed as the
    first parameter and `y_pred` as the second parameter.
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 始终记得，`y_test`的原始值应该作为第一个参数传递，而`y_pred`作为第二个参数。
- en: 'Compute the various components of the `confusion matrix`:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算`混淆矩阵`的各个组件：
- en: '[PRE46]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Calculate the new `sensitivity`:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算新的`灵敏度`：
- en: '[PRE47]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The preceding code produces the following output:'
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE48]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Calculate the `specificity`:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算`特异性`：
- en: '[PRE49]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The preceding code produces the following output:'
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE50]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'There is a clear increase in `sensitivity` and `specificity` after decreasing
    the threshold:'
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 降低阈值后，`灵敏度`和`特异性`明显增加：
- en: '![Figure 6.11: Sensitivity and specificity comparison'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 6.11：灵敏度与特异性对比](img/B15777_06_10.jpg)'
- en: '](img/B15777_06_11.jpg)'
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_06_11.jpg)'
- en: 'Figure 6.11: Sensitivity and specificity comparison'
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.11：灵敏度与特异性对比
- en: So, clearly, decreasing the threshold value increases the sensitivity.
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所以，显然，降低阈值会增加灵敏度。
- en: 'Visualize the data distribution. To understand why decreasing the threshold
    value increases the sensitivity, we need to see a histogram of our predicted probabilities.
    Recall that we created the `y_pred_prob` variable to predict the probabilities
    of the classifier:'
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化数据分布。为了理解为什么降低阈值会增加灵敏度，我们需要查看预测概率的直方图。回想一下，我们创建了`y_pred_prob`变量来预测分类器的概率：
- en: '[PRE51]'
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The following plot shows the output of the preceding code:'
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了上述代码的输出：
- en: '![Figure 6.12: A histogram of the probabilities of patient readmission from
    the dataset'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.12：数据集中患者再次入院的概率直方图](img/B15777_06_12.jpg)'
- en: '](img/B15777_06_12.jpg)'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_06_12.jpg)'
- en: 'Figure 6.12: A histogram of the probabilities of patient readmission from the
    dataset'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.12：数据集中患者再次入院的概率直方图
- en: This histogram clearly shows that most of the probabilities for the predicted
    classifier lie in a range from `0.0` to `0.1`, which is indeed very low. Unless
    we set the threshold very low, we cannot increase the sensitivity of the model.
    Also, note that sensitivity is inversely proportional to specificity, so when
    one increases, the other decreases.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 该直方图清楚地显示，大多数预测分类器的概率位于`0.0`到`0.1`的范围内，确实非常低。除非我们将阈值设置得非常低，否则无法提高模型的灵敏度。还要注意，灵敏度与特异性成反比，因此当灵敏度增加时，特异性会减少，反之亦然。
- en: Note
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/31E6v32](https://packt.live/31E6v32).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/31E6v32](https://packt.live/31E6v32)。
- en: You can also run this example online at [https://packt.live/3gquh6y](https://packt.live/3gquh6y).
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以在[https://packt.live/3gquh6y](https://packt.live/3gquh6y)在线运行这个例子。
- en: There is no universal value of the threshold, though the value of `0.5` is commonly
    used as a default. One method for selecting the threshold is to plot a histogram
    and then select the threshold manually. In our case, any threshold between `0.1`
    and `0.7` can be used as the model as there are few predictions between those
    values, as can be seen from the histogram that was produced at the end of the
    previous exercise.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值没有一个普遍适用的值，尽管`0.5`的值通常作为默认值。选择阈值的一种方法是绘制直方图，然后手动选择阈值。在我们的案例中，任何在`0.1`到`0.7`之间的阈值都可以使用，因为在这些值之间的预测较少，正如在前一个练习结束时生成的直方图所示。
- en: Another method for choosing the threshold is to plot the `ROC curve`, which
    plots the true positive rate as a function of the false positive rate. Depending
    on your tolerance for each, the threshold value can be selected. Plotting the
    `ROC curve` is also a good technique if we wish to evaluate the performance of
    the model because the area under the `ROC curve` is a direct measure of the model's
    performance. In the next activity, we will explore the performance of our model
    using the `ROC curve` and the `AUC score`.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 选择阈值的另一种方法是绘制`ROC曲线`，该曲线将真正例率与假正例率进行比较。根据你对每个值的容忍度，可以选择合适的阈值。如果我们希望评估模型的性能，绘制`ROC曲线`也是一个很好的方法，因为`ROC曲线`下的面积是评估模型性能的直接指标。在接下来的活动中，我们将使用`ROC曲线`和`AUC分数`来探索我们模型的性能。
- en: 'Activity 6.02: Calculating the ROC Curve and AUC Score'
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动6.02：计算ROC曲线和AUC分数
- en: 'The `ROC curve` and `AUC score` is an effective way to easily evaluate the
    performance of a binary classifier. In this activity, we will plot the `ROC curve`
    and calculate the `AUC score` of a model. We will use the same dataset and train
    the same model that we used in *Exercise 6.03*, *Deriving and Computing Metrics
    Based on a Confusion Matrix*. Use the APS failure data and calculate the `ROC
    curve` and `AUC score`. Follow these steps to complete this activity:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '`ROC曲线`和`AUC分数`是有效且简便的二分类器性能评估方法。在本次活动中，我们将绘制`ROC曲线`并计算模型的`AUC分数`。我们将使用与*练习6.03*中相同的数据集和模型，该练习是*基于混淆矩阵推导与计算指标*。使用APS故障数据，计算`ROC曲线`和`AUC分数`。按照以下步骤完成此活动：'
- en: Import all the necessary dependencies and load the dataset.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入所有必要的依赖项并加载数据集。
- en: Split the data into training and test datasets using the `train_test_split`
    function.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`train_test_split`函数将数据集分割为训练集和测试集。
- en: Scale the training and test data using the `StandardScaler` function.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`StandardScaler`函数对训练数据和测试数据进行缩放。
- en: Import the libraries that are required to build a neural network architecture
    and initiate the `Sequential` class. Add five `Dense` layers with `Dropout`. Set
    the first hidden layer so that it has a size of `64` with a dropout rate of `0.5`,
    the second hidden layer so that it has a size of `32` with a dropout rate of `0.4`,
    the third hidden layer so that it has a size of `16` with a dropout rate of `0.3`,
    the fourth hidden layer so that it has a size of `8` with a dropout rate of `0.2`,
    and the final hidden layer so that it has a size of `4`, with a dropout rate of
    `0.1`. Set all the activation functions to `ReLU`.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入构建神经网络架构所需的库，并初始化`Sequential`类。添加五个`Dense`层和`Dropout`层。设置第一个隐藏层的大小为`64`，并且丢弃率为`0.5`；第二个隐藏层的大小为`32`，丢弃率为`0.4`；第三个隐藏层的大小为`16`，丢弃率为`0.3`；第四个隐藏层的大小为`8`，丢弃率为`0.2`；最后一个隐藏层的大小为`4`，丢弃率为`0.1`。将所有激活函数设置为`ReLU`。
- en: Add an output `Dense` layer with the `sigmoid` activation function. Compile
    the network then fit the model using accuracy. Fit the model with `100` epochs
    and a batch size of `20`.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个输出`Dense`层，使用`sigmoid`激活函数。编译网络并使用准确度来拟合模型。用`100`个epochs和`20`的批次大小来训练模型。
- en: Fit the model to the training data, saving the results from the fit process.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到训练数据，并保存拟合过程中的结果。
- en: Create a variable representing the predicted classes of the test dataset.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个变量，表示测试数据集的预测类别。
- en: Calculate the false positive rate and true positive rate using the `roc_curve`
    function from `sklearn.metrics`. The false positive rate and true positive rate
    are the first and second of three return variables. Pass the true values and the
    predicted values to the function.
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `sklearn.metrics` 中的 `roc_curve` 函数计算假阳性率和真阳性率。假阳性率和真阳性率是三个返回变量中的第一和第二个。将真实值和预测值传递给函数。
- en: Plot the ROC curve, which is the true positive rate as a function of the false
    positive rate.
  id: totrans-296
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绘制 ROC 曲线，这是真正阳性率作为假阳性率的函数。
- en: Calculate the AUC score using the `roc_auc_score` from `sklearn.metrics` while
    passing the true values and predicted values of the model.
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `sklearn.metrics` 中的 `roc_auc_score` 计算 AUC 分数，同时传递模型的真实值和预测值。
- en: 'After implementing these steps, you should get the following output:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 实施这些步骤后，您应该获得以下输出：
- en: '[PRE52]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Note
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 434.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 此活动的解决方案可在第 434 页找到。
- en: In this activity, we learned how to calculate a `ROC` and an `AUC score` with
    the APS failure dataset. We also learned how specificity and sensitivity change
    with different threshold values.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在此活动中，我们学习了如何使用 APS 失效数据集计算 `ROC` 和 `AUC` 分数。我们还学习了特异性和敏感性如何随不同阈值变化。
- en: Summary
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered model evaluation and accuracy in depth. We learned
    how accuracy is not the most appropriate technique for evaluation when our dataset
    is imbalanced. We also learned how to compute a confusion matrix using scikit-learn
    and how to derive other metrics, such as sensitivity, specificity, precision,
    and false positive rate.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入讨论了模型评估和准确性。当数据集不平衡时，我们学到了准确性不是评估的最合适技术。我们还学习了如何使用 scikit-learn 计算混淆矩阵，以及如何推导其他指标，如敏感性、特异性、精确度和假阳性率。
- en: Finally, we understood how to use threshold values to adjust metrics and how
    `ROC curves` and `AUC scores` help us evaluate our models. It is very common to
    deal with imbalanced datasets in real-life problems. Problems such as credit card
    fraud detection, disease prediction, and spam email detection all have imbalanced
    data in different proportions.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们了解了如何使用阈值值来调整指标，以及 `ROC 曲线` 和 `AUC 分数` 如何帮助我们评估模型。在现实生活中处理不平衡数据集非常常见。信用卡欺诈检测、疾病预测和垃圾邮件检测等问题都有不同比例的不平衡数据。
- en: In the next chapter, we will learn about a different kind of neural network
    architecture (convolutional neural networks) that performs well on image classification
    tasks. We will test performance by classifying images into two classes and experiment
    with different architectures and activation functions.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习一种不同类型的神经网络架构（卷积神经网络），它在图像分类任务上表现良好。我们将通过将图像分类为两类并尝试不同的架构和激活函数来测试性能。
