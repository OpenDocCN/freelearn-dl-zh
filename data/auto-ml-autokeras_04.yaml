- en: '*Chapter 3*: Automating the Machine Learning Pipeline with AutoKeras'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第3章*：使用AutoKeras自动化机器学习管道'
- en: Automating the machine learning pipeline involves automating a series of processes
    such as **data exploration**, **data preprocessing**, **feature engineering**,
    **algorithm selection**, **model training**, and **hyperparameter tuning**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化机器学习管道涉及自动化一系列过程，如**数据探索**、**数据预处理**、**特征工程**、**算法选择**、**模型训练**和**超参数调整**。
- en: This chapter explains the standard machine learning pipeline and how to automate
    some of them with **AutoKeras**. We will also describe the main data preparation
    best practices to apply before training a model. The post-data preparation steps
    are performed by AutoKeras and we will see them in depth in later chapters.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将解释标准机器学习管道以及如何使用**AutoKeras**自动化其中的一些步骤。我们还将描述训练模型之前需要应用的主要数据准备最佳实践。数据准备后的步骤由AutoKeras执行，我们将在后面的章节中深入了解这些步骤。
- en: As we saw in the first chapter, AutoKeras can automate all pipeline modeling
    steps by applying hyperparameter optimization and **Neural Architecture Search**
    (**NAS**), but some data preprocessing before these steps must be done by hand
    or with other tools.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第一章中看到的，AutoKeras可以通过应用超参数优化和**神经架构搜索**（**NAS**）来自动化所有管道建模步骤，但在这些步骤之前，某些数据预处理仍需手动完成或使用其他工具。
- en: We will explain the data representations expected by our model, as well as the
    basic preprocessing techniques that AutoKeras applies. By the end of this chapter,
    you will have learned the main data formats and techniques for feeding your models
    in a suitable and optimal way.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将解释模型所期望的数据表示形式，以及AutoKeras应用的基本预处理技术。在本章结束时，您将学到适合且最佳的方式来为模型提供数据的主要格式和技术。
- en: 'The main topics that will be covered are as follows:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要主题：
- en: Understanding tensors
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解张量
- en: Preparing the data to feed deep learning models
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为深度学习模型准备数据
- en: Loading data into AutoKeras in multiple formats
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以多种格式将数据加载到AutoKeras中
- en: Splitting your dataset for training and evaluation
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据集分割用于训练和评估
- en: In this chapter, we will look at some basic preprocessing techniques and how
    to use the AutoKeras helpers to apply them, but first, let's explain what kind
    of data structures are expected by our model and how are they represented.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍一些基本的预处理技术，以及如何使用AutoKeras助手来应用它们，但首先，让我们解释一下模型所期望的数据结构是什么以及它们是如何表示的。
- en: Understanding tensors
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解张量
- en: In the MNIST example, the digit images were stored in NumPy matrices, also called
    tensors. These tensors are the basic data structures for machine learning models.
    Now that we know what fuels our models, let's dig deeper into understanding what
    tensors are and their different types.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在MNIST示例中，数字图像被存储在NumPy矩阵中，也叫张量。这些张量是机器学习模型的基本数据结构。现在我们已经知道了模型所需的输入，让我们更深入地了解张量是什么以及它们的不同类型。
- en: What is a tensor?
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是张量？
- en: A tensor is basically a multi-dimensional array of numbers, usually floating-point
    numbers of N dimensions (also called *axes*).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 张量基本上是一个多维数组，通常是N维的浮动点数（也叫做*轴*）。
- en: 'A tensor is defined by three key attributes: the number of axes or rank, the
    dimension of each axes or shape, and the type of data it contains. Let''s explain
    them in detail:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 张量由三个关键属性定义：轴的数量或秩、每个轴的维度或形状，以及它包含的数据类型。让我们详细解释一下：
- en: '`numpy` nomenclature (`ndim`). For instance, a scalar (a single number) has
    no axes, a vector (a list of numbers) has one, a matrix (a list of vectors) has
    two, and a 3D tensor (a list of matrices) has three. Let''s look at a practical
    example:'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`numpy`命名法（`ndim`）。例如，标量（单个数字）没有轴，向量（数字列表）有一个，矩阵（向量列表）有两个，而3D张量（矩阵列表）有三个。我们来看一个实际的例子：'
- en: '[PRE0]'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the previous code snippet, we created a matrix and printed its rank (`2`).
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们创建了一个矩阵并打印了它的秩（`2`）。
- en: '**Shape (each axis dimension)**: This is the dimension of each axis and returns
    a tuple with the lengths of the corresponding array dimensions. In the case of
    a matrix, the first item would correspond to the number of rows and the second
    item would correspond to the number of columns, as shown in the following code:'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**形状（每个轴的维度）**：这是每个轴的维度，并返回一个元组，包含相应数组维度的长度。对于矩阵，第一个项对应行数，第二个项对应列数，如以下代码所示：'
- en: '[PRE1]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This time, we have created a matrix and printed its shape (4 rows, 3 columns).
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这一次，我们创建了一个矩阵并打印了它的形状（4行，3列）。
- en: '**Data type**: The type of data that''s contained in the tensor is usually
    floating-point numbers because the computer works in a more optimal way with this
    type of data. For instance, in the following matrix, the stored items are integers:'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据类型**：张量中包含的数据类型通常是浮点数，因为计算机在处理这种数据时更加高效。例如，在以下矩阵中，存储的项目是整数：'
- en: '[PRE2]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now that we've explained the key attributes of a tensor, let's see what types
    of tensors we can use.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经解释了张量的关键属性，接下来看看我们可以使用哪些类型的张量。
- en: Types of tensors
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 张量的类型
- en: 'Based on their dimensions, we can classify tensors like so:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 根据它们的维度，我们可以将张量分类如下：
- en: '**Scalar (N=0)**: A tensor containing just one number is called a scalar; let''s
    create one:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标量（N=0）**：只包含一个数字的张量被称为标量；让我们创建一个：'
- en: '[PRE3]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: By creating a scalar and printing its rank, we can see its value is 0.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过创建一个标量并打印它的阶数，我们可以看到它的值是 0。
- en: '**Vector (N=1)**: A 1D tensor is a called vector. It''s an array of numbers
    of 1 dimension, as shown in the following code:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向量（N=1）**：1D 张量被称为向量。它是一个一维的数字数组，如下代码所示：'
- en: '[PRE4]'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, we have created a vector of 1 dimension and printed its rank.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们创建了一个 1 维的向量并打印了它的阶数。
- en: '`[1, 2, 3]` and the first column is `[1, 4, 7]`, respectively.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`[1, 2, 3]` 和第一列是 `[1, 4, 7]`，分别表示。'
- en: '**3D tensors (N=3)**: A 3D tensor is an array of matrices. This tensor is typically
    used to represent images using a 3-matrice array, with each matrix representing
    a color (red, green, or blue) of the pixel. You can imagine it as a cube filled
    with numbers. Let''s create one using the following code:'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**3D 张量（N=3）**：3D 张量是矩阵的数组。这个张量通常用来表示图像，使用 3 个矩阵数组，其中每个矩阵代表像素的一个颜色（红色、绿色或蓝色）。你可以将它想象为一个充满数字的立方体。让我们用以下代码创建一个：'
- en: '[PRE5]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, we can see that the rank that's returned for the 3D tensor is 3.
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，对于 3D 张量返回的阶数是 3。
- en: '**4D tensors (N=4)**: 4D tensors are arrays of 3D tensors. This complex structure
    is often used to store video, which is basically a batch of frames, where each
    frame is an image represented by a 3D tensor.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**4D 张量（N=4）**：4D 张量是 3D 张量的数组。这种复杂结构常用于存储视频，视频基本上是一批帧，每一帧是由 3D 张量表示的图像。'
- en: 'The following is a visual representation of these ranks:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是这些阶数的视觉表示：
- en: '![Figure 3.1 – A visual representation of tensors with different ranks'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.1 – 不同阶数的张量视觉表示'
- en: '](img/B16953_03_01.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16953_03_01.jpg)'
- en: Figure 3.1 – A visual representation of tensors with different ranks
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.1 – 不同阶数的张量视觉表示
- en: A 3D tensor can store an RGB image or frame, while a 4D tensor can contain a
    video as an array of frames.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 3D 张量可以存储 RGB 图像或帧，而 4D 张量可以将视频作为一组帧的数组来存储。
- en: Preparing the data to feed deep learning models
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为深度学习模型准备数据
- en: In the previous chapter, we explained that AutoKeras is a framework that specializes
    in deep learning that uses neural networks as a learning engine. We also learned
    how to create end-to-end classifier/regressor models for the MNIST dataset of
    handwritten digits as input data. This dataset had already been preprocessed to
    be used by the model, which means all the images had the same attributes (same
    size, color, and so on), but this is not always the case.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们解释了 AutoKeras 是一个专门用于深度学习的框架，使用神经网络作为学习引擎。我们还学会了如何为 MNIST 手写数字数据集创建端到端的分类/回归模型。该数据集已经过预处理，可以供模型使用，这意味着所有图像都有相同的属性（相同的大小、颜色等），但情况并非总是如此。
- en: Once we know what a tensor is, we are ready to learn how to feed our neural
    networks. Most of the data preprocessing techniques are domain-specific, and we
    will explain them in the following chapters when we need to use them in specific
    examples. But first, we will present some fundamentals that are the basis for
    each specific technique.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们知道了什么是张量，就可以开始学习如何输入我们的神经网络。大多数数据预处理技术是特定领域的，我们将在需要在特定示例中使用时在后续章节中解释它们。但首先，我们将介绍一些基础知识，这些知识是每个具体技术的基础。
- en: Data preprocessing operations for neural network models
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经网络模型的数据预处理操作
- en: In this section, we will look at some of the operations we can use to transform
    the raw input data into a more appropriate format. This will allow us to feed
    the neural network in order to improve the learning performance of the model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论一些可以用来将原始输入数据转换为更合适格式的操作。这将使我们能够将数据输入神经网络，从而提高模型的学习性能。
- en: 'The main data preprocessing operations are feature engineering, data normalization,
    data vectorization, and missing values processing. Let''s look at them in detail:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的数据预处理操作包括特征工程、数据归一化、数据向量化和缺失值处理。让我们详细了解一下：
- en: '**Feature engineering**: This is the process of extracting features from raw
    data using the domain knowledge of human experts, in such a way that these extracted
    features improve the performance of our models.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征工程**：这是从原始数据中提取特征的过程，利用领域专家的知识，这些提取的特征能够改善我们模型的性能。'
- en: In traditional machine learning, function engineering is critical but with deep
    learning, this process is not as important because neural networks can automatically
    extract the relevant characteristics from the raw input data. However, there are
    cases where function engineering is still crucial, such as when we don't have
    a large dataset, the input data is structured, or we have limited resources. In
    these cases, this step is key to achieving our goals.
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在传统的机器学习中，特征工程至关重要，但在深度学习中，这个过程的重要性不那么突出，因为神经网络能够自动从原始输入数据中提取相关特征。然而，在某些情况下，特征工程仍然至关重要，例如当我们没有足够大的数据集、输入数据是结构化的，或者资源有限时。在这些情况下，这一步对于实现我们的目标至关重要。
- en: '**Data normalization**: Neural networks work much better with small input values,
    usually between 0 and 1\. It is easier for the model to learn from small numbers
    because the learning algorithms are based on gradient updates being made to its
    weight parameters, in such a way that small values will cause faster updates,
    thus speeding up the process, while larger values will slow it down. Usually,
    the dataset comes with larger values, so before we incorporate them into our model,
    we need to change and scale them to a range of 0 to 1\. This technique is called
    normalization. AutoKeras already does this for us. In the previous digit classification
    example, the dataset contained images encoded as integers from 0 to 255\. However,
    we fed our model without performing normalization because AutoKeras did it for
    us automatically.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据归一化**：神经网络在处理小的输入值时效果更好，通常在0到1之间。因为学习算法是基于梯度更新权重参数的方式进行的，所以小的数值会导致更快的更新，从而加速训练过程，而较大的数值则会减慢训练过程。通常，数据集包含较大的数值，因此在将它们输入到模型之前，我们需要将它们缩放到0到1的范围内。这种技术叫做归一化。AutoKeras已经为我们完成了这一过程。在前面的数字分类示例中，数据集包含了从0到255的整数编码图像。然而，我们将数据喂入模型时并未执行归一化，因为AutoKeras已经自动为我们处理了这个问题。'
- en: '`MINST` example shown in the previous chapter, the dataset has already been
    vectorized, so this process was not necessary.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 前一章中展示的`MINST`示例，数据集已经被向量化，因此这个过程并不必要。
- en: '**Missing values processing**: Datasets often contain missing values in some
    records. How should your model handle these incomplete records? Generally, for
    deep learning models, initializing missing values to 0 is a common practice, as
    long as 0 is not already a significant value. Once the neural network model learns
    that 0 means a missing value, it will ignore it every time. It is important to
    note that if your model will be exposed to missing values in the real world and
    you trained it without them, it will not learn to ignore them. So, a common practice
    in this case is to artificially generate missing values to force your model to
    learn how to handle them.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺失值处理**：数据集通常在某些记录中包含缺失值。那么您的模型应该如何处理这些不完整的记录呢？通常，对于深度学习模型，将缺失值初始化为0是一种常见做法，只要0不是一个重要的数值。一旦神经网络模型学会了0代表缺失值，它就会在每次遇到时忽略它。需要注意的是，如果您的模型将在现实世界中接触到缺失值，而您在训练时没有考虑到它们，它将无法学会忽略这些缺失值。因此，在这种情况下，一个常见的做法是人工生成缺失值，强迫您的模型学习如何处理它们。'
- en: Now that we've learned about the main data structures and their `transform`
    operations, we will look at what data formats are supported by AutoKeras and what
    utilities it has to convert raw data into a more suitable format.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了主要的数据结构及其`transform`操作，接下来我们将探讨AutoKeras支持的数据格式以及它如何将原始数据转换为更适合的格式。
- en: Loading data into AutoKeras in multiple formats
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将数据以多种格式加载到AutoKeras中
- en: As we mentioned previously, AutoKeras performs normalization automatically.
    However, in the following chapters, you will see that you can create your model
    in a more personalized way by stacking blocks. More specifically, you can use
    special blocks to normalize your data.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，AutoKeras会自动执行归一化。然而，在接下来的章节中，您将看到通过堆叠模块，您可以以更个性化的方式创建模型。更具体地说，您可以使用特定的模块来归一化数据。
- en: Now, let's look at the different data structures that we can use to feed our
    model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看可以用来为模型提供输入的不同数据结构。
- en: 'AutoKeras models accept three types of input:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: AutoKeras 模型接受三种类型的输入：
- en: A **NumPy array** is an array that's commonly used by **Scikit-Learn** and many
    other Python-based libraries. This is always the fastest option, as long as your
    data fits in memory.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NumPy 数组**是**Scikit-Learn**和许多其他基于 Python 的库常用的数组类型。只要数据能适应内存，这是最快的选择。'
- en: '**Python generators** load batches of data from disk to memory, so this is
    a good option when the entire dataset does not fit in memory.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Python 生成器**将数据批次从磁盘加载到内存，因此当整个数据集无法适应内存时，这是一个不错的选择。'
- en: '**TensorFlow Dataset** is a high-performance option that is similar to Python
    generators, but it is best suited for deep learning and large datasets. This is
    because data can be streamed from disk or from a distributed filesystem.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow Dataset**是一种高性能选项，类似于 Python 生成器，但更适合深度学习和大规模数据集。这是因为数据可以从磁盘或分布式文件系统中流式传输。'
- en: 'You can prepare your data in one of these formats before feeding it to your
    AutoKeras model. If you are working with large datasets and need to train in GPUs,
    the best choice is to use the **TensorFlow Dataset** object, because they have
    many advantages in terms of performance and versatility, such as the following:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在将数据提供给 AutoKeras 模型之前，你可以将数据准备为以下格式之一。如果你使用大规模数据集并且需要在 GPU 上训练，最佳选择是使用**TensorFlow
    Dataset**对象，因为它们在性能和灵活性方面有许多优势，例如：
- en: It can perform asynchronous preprocessing and data queuing.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以执行异步预处理和数据排队。
- en: It provides GPU memory data preloading, so that it is available after the GPU
    finishes processing the previous batch.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了 GPU 内存数据预加载功能，因此在 GPU 完成处理前一个批次之后，数据将立即可用。
- en: It provides transformation primitives, so that you can apply a function to each
    element of the dataset that's generating a new transformed dataset.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了转换原语，让你可以对数据集中的每个元素应用一个函数，从而生成一个新的转换后的数据集。
- en: A cache that maintains the latest batches that have been read from the dataset
    in memory.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个缓存，保持已从数据集读取的最新批次数据在内存中。
- en: You can load from several sources (**NumPy arrays**, **Python generators**,
    **CSV files**, text files, folders, and so on).
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以从多个来源加载数据（**NumPy 数组**、**Python 生成器**、**CSV 文件**、文本文件、文件夹等等）。
- en: 'The following diagram represents all the different data sources that can use
    a TensorFlow Dataset object as input:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示表示所有可以使用 TensorFlow Dataset 对象作为输入的数据源类型：
- en: '![Figure 3.2 – A visual representation of a TensorFlow Dataset object''s input
    sources](img/B16953_03_02.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.2 – TensorFlow Dataset 对象输入源的可视化表示](img/B16953_03_02.jpg)'
- en: Figure 3.2 – A visual representation of a TensorFlow Dataset object's input
    sources
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 – TensorFlow Dataset 对象输入源的可视化表示
- en: 'AutoKeras has very useful utilities to help you convert raw data on disk into
    a TensorFlow Dataset:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: AutoKeras 提供了非常有用的工具，帮助你将磁盘上的原始数据转换为 TensorFlow Dataset：
- en: '`autokeras.image_dataset_from_directory` converts image files stored in a directory
    in a specific way into a tagged dataset of image tensors. Let''s learn how to
    process a images directory.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`autokeras.image_dataset_from_directory`将以特定方式存储在目录中的图像文件转换为带标签的图像张量数据集。让我们学习如何处理图像目录。'
- en: 'The following directory is well-structured, which means we can feed it to AutoKeras.
    There''s a subfolder for each class of images:'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下目录结构合理，这意味着我们可以将其提供给 AutoKeras。每个类别的图像都有一个子文件夹：
- en: '[PRE6]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, we must pass this folder path to the `autokeras` function in order to
    create a dataset from the images directory:'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现在，我们必须将此文件夹路径传递给`autokeras`函数，以便从图像目录创建数据集：
- en: '[PRE7]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: There are several parameters, but only the path directory (`main_directory`)
    is required; the rest of the parameters are set by default. We will explain them
    in more detail in later chapters.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 有几个参数，但只有路径目录（`main_directory`）是必需的；其余的参数默认设置。我们将在后续章节中详细解释它们。
- en: '`autokeras.text_dataset_from_directory` generates a Tensorflow Dataset from
    text files stored in a directory in a specific way. As we saw previously with
    the images, we have to create a subfolder for every category:'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`autokeras.text_dataset_from_directory`从以特定方式存储在目录中的文本文件生成 TensorFlow Dataset。正如我们之前看到的图像一样，我们必须为每个类别创建一个子文件夹：'
- en: '[PRE8]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As we mentioned previously, with images, only the path directory (`directory`)
    is required; the rest of the parameters, if they haven't been initialized, will
    be set by default. We will explain these in more detail in later chapters as well.
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如前所述，处理图像时，只需要路径目录（`directory`）；其他参数如果没有初始化，将会默认设置。我们将在后面的章节中更详细地解释这些内容。
- en: Furthermore, AutoKeras can work with CSV files by directly passing the filename
    as a parameter to its structured data models; that is, `autokeras.StructuredDataClassifier`
    and `autokeras.StructuredDataRegressor`. Now that we know what kind of data is
    best suited for AutoKeras and what utilities it has for preprocessing it, we will
    learn how to divide our dataset so that we can properly evaluate and test our
    model.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，AutoKeras 可以通过直接将文件名作为参数传递给其结构化数据模型来处理 CSV 文件；也就是说，`autokeras.StructuredDataClassifier`
    和 `autokeras.StructuredDataRegressor`。现在我们已经知道哪些数据类型最适合 AutoKeras 以及它为数据预处理提供了哪些工具，接下来我们将学习如何划分数据集，以便正确地评估和测试模型。
- en: Splitting your dataset for training and evaluation
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拆分你的数据集以进行训练和评估
- en: 'To evaluate a model, you must divide your dataset into three subsets: a training
    set, a validation set, and a test set. During the training phase, AutoKeras will
    train your model with the training dataset, while using the validation dataset
    to evaluate its performance. Once you are ready, the final evaluation will be
    done using the test dataset.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要评估一个模型，你必须将数据集分为三个子集：训练集、验证集和测试集。在训练阶段，AutoKeras 会使用训练数据集来训练模型，同时使用验证数据集来评估模型的性能。一旦准备好，最终的评估将使用测试数据集进行。
- en: Why you should split your dataset
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么你应该拆分数据集
- en: Having a separate test dataset that is not used during training is really important
    to avoid information leaks.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有一个在训练过程中不被使用的独立测试数据集对于避免信息泄漏非常重要。
- en: As we mentioned previously, the validation set is used to tune the hyperparameters
    of your model based on the performance of the model, but some information about
    the validation data is filtered into the model. Due to this, you run the risk
    of ending up with a model that works artificially well with the validation data,
    because that's what you trained it for. However, the actual performance of the
    model is due to us using previously unseen data, not validation data, so we must
    use a different and never-before-seen dataset to evaluate our model. This is known
    as the test dataset.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，验证集用于根据模型的表现来调整模型的超参数，但一些关于验证数据的信息会被过滤到模型中。因此，你可能会面临一个模型在验证数据上表现得非常好，因为它是为此训练的。然而，模型的实际表现应基于我们使用之前未见过的数据，而不是验证数据，所以我们必须使用一个不同且全新的数据集来评估模型。这就是所谓的测试数据集。
- en: To avoid information leaks, it is very important that your model has never had
    access to any information about the test set, not even indirectly. This is why
    it's so important to have a separate test dataset.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免信息泄漏，确保模型从未接触过测试集的任何信息，甚至是间接的，这一点非常重要。这就是为什么拥有一个独立的测试数据集如此重要的原因。
- en: How to split your dataset
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何拆分数据集
- en: 'In the MNIST example in the previous chapter, we did not split the dataset
    explicitly because the `load_data` method did this split for us. However, often,
    these datasets are just one set of records that you will have to split. The following
    is a visual representation of dataset splitting:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章的 MNIST 示例中，我们没有明确拆分数据集，因为 `load_data` 方法为我们完成了拆分。然而，通常这些数据集只是一个记录集，你需要自行拆分。以下是数据集拆分的可视化表示：
- en: '![Figure 3.3 – A visual representation of dataset splitting](img/B16953_03_03.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.3 – 数据集拆分的可视化表示](img/B16953_03_03.jpg)'
- en: Figure 3.3 – A visual representation of dataset splitting
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3 – 数据集拆分的可视化表示
- en: 'When AutoKeras is training a model, it will reserve 20% of the training set
    for validation by default, but you can always define a different percent using
    `validation_split param` in the `fit` function. In the following code, we are
    using this parameter to split the training data and using the last 15% as validation
    data:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当 AutoKeras 在训练模型时，默认会将 20% 的训练集保留用于验证，但你始终可以通过在 `fit` 函数中使用 `validation_split
    param` 来定义不同的百分比。在以下代码中，我们使用这个参数将训练数据拆分，并使用最后 15% 作为验证数据：
- en: '[PRE9]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can also manually create the validation dataset and pass it as `validation_data
    param: split = 5000`:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '我们也可以手动创建验证数据集并将其作为 `validation_data param: split = 5000` 传递：'
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can also use to split the `train_test_split` function:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用 `train_test_split` 函数来进行拆分：
- en: '[PRE11]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now, let's summarize what we learned in this chapter.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们总结一下本章所学的内容。
- en: Summary
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we learned about tensors, the main data structures for networks,
    some data preprocessing operations for neural networks, and the AutoKeras data
    formats that are supported, as well as its data-preprocessing utilities. Finally,
    we learned how to split a dataset in a quick and easy way. Now, you are ready
    to power your AutoKeras models in the most appropriate way.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章，我们学习了张量，它是网络的主要数据结构；一些神经网络的数据预处理操作；AutoKeras 支持的数据格式，以及它的数据预处理工具。最后，我们还学习了如何快速简便地划分数据集。现在，你已经准备好以最合适的方式为你的
    AutoKeras 模型提供动力。
- en: In the next chapter, we will learn how AutoKeras works with images. We will
    also introduce some techniques we can use to extract specific characteristics
    from images and how to apply them.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将学习如何使用 AutoKeras 处理图像。我们还将介绍一些技术，教你如何从图像中提取特定特征，并应用这些技术。
