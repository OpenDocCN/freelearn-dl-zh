- en: '*Chapter 1*: Introduction to Automated Machine Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 1 章*：自动化机器学习概述'
- en: In this chapter, we cover the main concepts relating to **Automated Machine
    Learning** (**AutoML**) with an overview of the types of AutoML methods and its
    software systems.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍与**自动化机器学习**（**AutoML**）相关的主要概念，并概述不同类型的 AutoML 方法及其软件系统。
- en: If you are a developer working with AutoML, you will be able to put your knowledge
    to work with this practical guide to develop and use state-of-the-art AI algorithms
    in your projects. By the end of this chapter, you will have a clear understanding
    of the anatomy of the **Machine Learning** (**ML**) workflow, what AutoML is,
    and its different types.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您是一位从事 AutoML 的开发人员，您将能够利用这本实用指南，在项目中开发和使用最先进的 AI 算法。到本章结束时，您将清楚了解**机器学习**（**ML**）工作流的结构、AutoML
    的定义及其不同类型。
- en: Through clear explanations of essential concepts and practical examples, you
    will see the differences between the standard ML and the AutoML approaches and
    the pros and cons of each.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对基本概念的清晰解释和实际示例，您将看到标准 ML 方法与 AutoML 方法的差异，以及各自的优缺点。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: The anatomy of a standard ML workflow
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准 ML 工作流的结构
- en: What is AutoML?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 AutoML？
- en: Types of AutoML
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AutoML 的类型
- en: The anatomy of a standard ML workflow
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准 ML 工作流的结构
- en: In a traditional ML application, professionals have to train a model using a
    set of input data. If this data is not in the proper form, an expert may have
    to apply some data preprocessing techniques, such as feature extraction, feature
    engineering, or feature selection.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的 ML 应用中，专业人员需要使用一组输入数据来训练模型。如果这些数据不符合正确的格式，专家可能需要应用一些数据预处理技术，如特征提取、特征工程或特征选择。
- en: 'Once the data is ready and the model can be trained, the next step is to select
    the right algorithm and optimize the hyperparameters to maximize the accuracy
    of the model''s predictions. Each step involves time-consuming challenges, and
    typically also requires a data scientist with the experience and knowledge to
    be successful. In the following figure, we can see the main steps represented
    in a typical ML pipeline:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据准备好并且模型可以进行训练，下一步就是选择合适的算法并优化超参数，以最大化模型预测的准确性。每个步骤都涉及耗时的挑战，并且通常还需要具备经验和知识的数据科学家才能成功完成。下图中，我们可以看到典型
    ML 流水线中的主要步骤：
- en: '![Figure 1.1 – ML pipeline steps'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.1 – ML 流水线步骤'
- en: '](img/B16953_01_01.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16953_01_01.jpg)'
- en: Figure 1.1 – ML pipeline steps
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.1 – ML 流水线步骤
- en: Each of these pipeline processes involves a series of steps. In the following
    sections, we describe each process and related concepts in more detail.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 每个流水线过程都涉及一系列步骤。在接下来的章节中，我们将更详细地描述每个过程及其相关概念。
- en: Data ingestion
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据摄取
- en: Piping incoming data to a data store is the first step in any ML workflow. The
    target here is to store that raw data without doing any transformation, to allow
    us to have an immutable record of the original dataset. The data can be obtained
    from various data sources, such as databases, message buses, streams, and so on.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 将传入数据传输到数据存储是任何 ML 工作流中的第一步。这里的目标是将原始数据存储起来，不进行任何转换，以便保留原始数据集的不可变记录。数据可以来自各种数据源，如数据库、消息总线、流等。
- en: Data preprocessing
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据预处理
- en: 'The second phase, data preprocessing, is one of the most time-consuming tasks
    in the pipeline and involves many sub-tasks, such as **data cleaning**, **feature
    extraction**, **feature selection**, **feature engineering**, and **data segregation**.
    Let''s take a closer look at each one:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 第二阶段，数据预处理，是流水线中最耗时的任务之一，并涉及许多子任务，如**数据清洗**、**特征提取**、**特征选择**、**特征工程**和**数据分割**。让我们仔细看看每个子任务：
- en: The **data cleaning** process is responsible for detecting and fixing (or deleting)
    corrupt or wrong records from a dataset. Because the data is unprocessed and unstructured,
    it is rarely in the correct form to be processed; it implies filling in missing
    fields, removing duplicate rows, or normalizing and fixing other errors in the
    data.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据清洗**过程负责检测和修复（或删除）数据集中存在的错误或损坏的记录。由于数据是未经处理且无结构的，通常不符合处理的正确形式；这意味着需要填补缺失的字段、删除重复的行，或规范化并修复数据中的其他错误。'
- en: '**Feature extraction** is a procedure for reducing the number of resources
    required in a large dataset by creating new features from the combination of others
    (and eliminating the original ones). The main problem when analyzing large datasets
    is the number of variables to take into account. Processing a large number of
    variables generally requires a lot of hardware resources, such as memory and computing
    power, and can also cause overfitting, which means that the algorithm works very
    well for training samples and generalizes poorly for new samples. Feature extraction
    is based on the construction of new variables, combining existing ones to solve
    these problems without losing precision in the data.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征提取**是通过将多个特征组合成新特征来减少大数据集所需资源的过程，并且可以删除原始特征。分析大数据集时的主要问题是需要考虑的变量数量。处理大量变量通常需要大量硬件资源，如内存和计算能力，并且可能导致过拟合，这意味着算法对训练样本表现很好，但对新样本的泛化能力较差。特征提取基于构建新变量，结合现有变量，解决这些问题，而不会丢失数据的精度。'
- en: '**Feature selection** is the process of selecting a subset of variables to
    use in building the model. Performing feature selection simplifies the model (making
    it more interpretable for humans), reduces training times, and improves generalization
    by reducing overfitting. The main reason to apply feature selection methods is
    that the data contains some features that can be redundant or irrelevant, so removing
    them wouldn''t incur much loss of information.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征选择**是选择一组变量来用于构建模型的过程。进行特征选择可以简化模型（使其对人类更具可解释性），减少训练时间，并通过减少过拟合来提高泛化能力。应用特征选择方法的主要原因是，数据中可能包含一些冗余或无关的特征，因此删除这些特征不会造成太大的信息损失。'
- en: '**Feature engineering** is the process by which, through data mining techniques,
    features are extracted from raw data using domain knowledge. This typically requires
    a knowledgeable expert and is used to improve the performance of ML algorithms.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**特征工程**是通过数据挖掘技术，利用领域知识从原始数据中提取特征的过程。通常需要一位专业的专家，并且用于提升机器学习算法的性能。'
- en: '**Data segregation** consists of dividing the dataset into two subsets: a **train
    dataset** for training the model and a **test dataset** for testing the prediction
    modeling.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据分割**是将数据集划分为两个子集：一个用于训练模型的**训练数据集**和一个用于测试预测模型的**测试数据集**。'
- en: 'Modeling is divided into three parts:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 建模分为三个部分：
- en: Choose candidate models to evaluate.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择候选模型进行评估。
- en: Train the chosen model (improve it).
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练所选择的模型（提高其性能）。
- en: Evaluate the model (compare it with others).
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 评估模型（与其他模型进行比较）。
- en: 'This process is iterative and involves testing various models until one is
    obtained that solves the problem in an efficient way. The following figure shows
    a detailed schema of the modeling phases of the ML pipeline:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程是迭代的，涉及测试各种模型，直到找到一种能够高效解决问题的模型。下图展示了 ML 流水线建模阶段的详细框架：
- en: '![Figure 1.2 – Modeling phases of the ML pipeline](img/B16953_01_02.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.2 – ML 流水线建模阶段](img/B16953_01_02.jpg)'
- en: Figure 1.2 – Modeling phases of the ML pipeline
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2 – ML 流水线建模阶段
- en: After taking an overview of the modeling phase, let's look at each modeling
    step in more detail.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在概述建模阶段后，让我们更详细地了解每个建模步骤。
- en: Let's dive deeper into the three parts of modeling to have a detailed understanding
    of them.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更深入地探讨建模的三个部分，以便对它们有更详细的理解。
- en: Model selection
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型选择
- en: In choosing a candidate model to use, in addition to performance, it is important
    to consider several factors, such as readability (by humans), ease of debugging,
    the amount of data available, as well as hardware limitations for training and
    prediction.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择候选模型时，除了考虑性能外，还需要考虑几个因素，如可读性（人类可读性）、调试便捷性、可用数据量以及用于训练和预测的硬件限制。
- en: 'The main points to take into account for selecting a model would be as follows:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 选择模型时需要考虑的主要点如下：
- en: '**Interpretability and ease of debugging**: How to know why a model made a
    specific decision. How do we fix the errors?'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可解释性和调试便捷性**：如何了解模型为什么做出特定决策。我们如何修正错误？'
- en: '**Dataset type**: There are algorithms that are more suitable for specific
    types of data.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集类型**：某些算法更适合特定类型的数据。'
- en: '**Dataset size**: How much data is available and will this change in the future?'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据集大小**：可用数据量是多少？将来是否会发生变化？'
- en: '**Resources**: How much time and resources do you have for training and prediction?'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源**：你为训练和预测准备了多少时间和资源？'
- en: Model training
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型训练
- en: This process uses the training dataset to feed each chosen candidate model,
    allowing the models to learn from it by applying a backpropagation algorithm that
    extracts the patterns found in the training samples.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程使用训练数据集来为每个选定的候选模型提供数据，让模型通过应用反向传播算法，从训练样本中提取出模式进行学习。
- en: The model is fed with the output data from the data preprocessing step. This
    dataset is sent to the chosen model and once trained, both the model configuration
    and the learned parameters will be used in the model evaluation.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 模型通过数据预处理步骤的输出数据进行训练。该数据集被发送到选定的模型，训练完成后，模型配置和学习到的参数将用于模型评估。
- en: Model evaluation
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型评估
- en: This step is responsible for evaluating model performance using test datasets
    to measure the accuracy of the prediction. This process involves tuning and improving
    the model, generating a new candidate model version to be trained again.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这一步负责使用测试数据集评估模型性能，以衡量预测的准确性。这个过程包括调整和改进模型，生成新的候选模型版本以重新训练。
- en: Model tuning
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型调优
- en: This model evaluation step involves modifying hyperparameters such as the learning
    rate, the optimization algorithm, or model-specific architecture parameters, such
    as the number of layers and types of operations for neural networks. In standard
    ML, these procedures need to be performed manually by an expert.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型评估步骤包括修改超参数，例如学习率、优化算法或模型特定的架构参数，如神经网络的层数和操作类型。在标准的机器学习中，这些步骤通常需要专家手动执行。
- en: Other times, the evaluated model is discarded, and another new model is chosen
    for training. Often, starting with a previously trained model through transfer
    learning leads to shortened training time as well as better precision on the final
    model predictions.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 其他时候，评估过的模型会被丢弃，选择另一个新的模型进行训练。通常，通过迁移学习从先前训练的模型开始，能缩短训练时间，并提高最终模型预测的精度。
- en: Since the main bottleneck is the training time, the adjustment of the models
    should focus on efficiency and reproducibility so that the training is as fast
    as possible and someone can reproduce the steps that have been taken to improve
    performance.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于主要瓶颈是训练时间，因此模型的调整应关注效率和可复现性，以便训练尽可能快速，并且其他人能够复现已经采取的步骤来提升性能。
- en: Model deployment
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型部署
- en: Once the best model is chosen, it is usually put into production through an
    API service to be consumed by the end user or other internal services.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦选定最佳模型，通常通过 API 服务将其投入生产，以便最终用户或其他内部服务使用。
- en: 'Usually, the best model is selected to be deployed in one of two deployment
    modes:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，最佳模型会被选择以在两种部署模式之一中部署：
- en: '**Offline** (**asynchronous**): In this case, the model predictions are calculated
    in a batch process periodically and stored in a data warehouse as a key-value
    database.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**离线**（**异步**）：在这种情况下，模型预测是在定期的批处理过程中计算的，并作为键值数据库存储在数据仓库中。'
- en: '**Online** (**synchronous**): In this mode, the predictions are calculated
    in real time.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在线**（**同步**）：在这种模式下，预测是在实时计算中进行的。'
- en: Deployment consists of exposing your model to a real-world application. This
    application can be anything, from recommending videos to users of a streaming
    platform to predicting the weather on a mobile application.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 部署包括将模型暴露给实际应用。这个应用可以是任何东西，从向流媒体平台的用户推荐视频，到在移动应用上预测天气。
- en: Releasing an ML model into production is a complex process that generally involves
    multiple technologies (version control, containerization, caching, hot swapping,
    a/b testing, and so on) and is outside the scope of this book.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 将机器学习模型发布到生产环境是一个复杂的过程，通常涉及多种技术（版本控制、容器化、缓存、热交换、A/B 测试等），且超出了本书的讨论范围。
- en: Model monitoring
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型监控
- en: 'Once in production, the model is monitored to see how it performs in the real
    world and calibrated accordingly. This schema represents the continuous model
    cycle, from data ingestion to deployment:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦进入生产环境，模型会被监控，以查看它在现实世界中的表现，并根据需要进行校准。这个架构表示了持续的模型周期，从数据摄取到部署：
- en: '![Figure 1.3 – Model cycle phases'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.3 – 模型周期阶段'
- en: '](img/B16953_01_03.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16953_01_03.jpg)'
- en: Figure 1.3 – Model cycle phases
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3 – 模型周期阶段
- en: In the following sections, we will explain the main reasons why it's really
    important to monitor your production model.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将解释监控生产模型的主要原因。
- en: Why monitor your model?
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么要监控你的模型？
- en: Your model predictions will degrade over time. This phenomenon is called drift.
    Drift is a consequence of input data changes, so over time, the predictions get
    worse in a natural way.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你的模型预测会随着时间的推移而下降。这种现象称为漂移。漂移是输入数据变化的结果，因此随着时间的推移，预测自然会变得更差。
- en: Let's look at the users of a search engine as an example. A predictive model
    can use user features such as your personal information, search types, and clicked
    results to predict which ads to show. But after a while, these searches may not
    represent current user behavior.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以搜索引擎的用户为例。一个预测模型可以利用用户特征，如个人信息、搜索类型和点击的结果来预测展示哪些广告。但过了一段时间，这些搜索可能不再代表当前的用户行为。
- en: A possible solution would be to retrain the model with the most recent data,
    but this is not always possible and sometimes may even be counterproductive. Imagine
    training the model with searches at the start of the COVID-19 pandemic. This would
    only show ads for products related to the pandemic, causing a sharp decline in
    the number of sales for the rest of the products.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可能的解决方案是用最新的数据重新训练模型，但这并不总是可行的，有时甚至可能适得其反。假设用COVID-19疫情初期的搜索数据来训练模型，这样只会展示与疫情相关的广告，导致其他产品的销量急剧下降。
- en: A smarter alternative to combat drift is to monitor our model, and by knowing
    what is happening, we can decide when and how to retrain it.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗漂移的一个更智能的替代方法是监控我们的模型，通过了解发生了什么，我们可以决定何时以及如何重新训练模型。
- en: How can you monitor your model?
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何监控你的模型？
- en: In cases where you have the actual values to compare to the prediction in no
    time—I mean you have the true labels right after making a prediction—you just
    need to monitor the performance measures such as accuracy, F1 score, and so on.
    But often, there is a delay between the prediction and the basic truth; for example,
    in predicting spam in emails, users can report that an email is spam up to several
    months after it was created. In this case, you must use other measurement methods
    based on statistical approaches.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在有实际值可以及时与预测进行对比的情况下——我的意思是，在做出预测后，你立刻就能得到真实标签——你只需要监控准确率、F1分数等性能指标。然而，通常预测与真实情况之间会有延迟；例如，在预测邮件是否为垃圾邮件时，用户可能会在邮件创建后的几个月才报告某封邮件为垃圾邮件。在这种情况下，你必须使用基于统计方法的其他度量方法。
- en: For other complex processes, sometimes it is easier to do traffic/case splitting
    and monitor pure business metrics, in a case where it is difficult to consider
    direct relationships between classical ML evaluation metrics and real-world-related
    instances.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他复杂的过程，有时候进行流量/案例拆分并监控纯业务指标会更容易，尤其是在很难考虑经典机器学习评估指标与现实世界实例之间的直接关系的情况下。
- en: What should you monitor in your model?
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你应该在模型中监控什么？
- en: 'Any ML pipeline involves performance data monitoring. Some possible variables
    of the model to monitor are as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 任何机器学习管道都涉及性能数据监控。以下是一些可能需要监控的模型变量：
- en: '**Chosen model**: What kind of model was chosen, and what are the architecture
    type, the optimizer algorithm, and the hyperparameter values?'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选择的模型**：选择了哪种类型的模型，它的架构类型、优化算法和超参数值是什么？'
- en: '**Input data distribution**: By comparing the distribution of the training
    data with the distribution of the input data, we can detect whether the data used
    for the training represents what is happening now in the real world.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**输入数据分布**：通过将训练数据的分布与输入数据的分布进行比较，我们可以检测出用于训练的数据是否代表了当前真实世界中的情况。'
- en: '**Deployment date**: Date of the release of the model.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署日期**：模型发布的日期。'
- en: '**Features used**: Variables used as input for the model. Sometimes there are
    relevant features in production that we are not using in our model.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用的特征**：作为模型输入的变量。有时，生产环境中有一些相关特征，但我们没有在模型中使用它们。'
- en: '**Expected versus observed**: A scatter plot comparing expected and observed
    values is often the most widely used approach.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预期与实际**：通过散点图比较预期值和实际值，这通常是最广泛使用的方法。'
- en: '**Times published**: The number of times a model was published, represented
    usually using model version numbers.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**发布次数**：模型发布的次数，通常用模型版本号表示。'
- en: '**Time running**: How long has it been since the model was deployed?'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运行时间**：自模型部署以来已经过去多久？'
- en: Now that we have seen the different components of the pipeline, we are ready
    to introduce the main AutoML concepts in the next section.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看过管道的不同组件，准备好在下一节介绍主要的AutoML概念了。
- en: What is AutoML?
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是AutoML？
- en: The main task in the modeling phase is to select the different models to be
    evaluated and adjust the different hyperparameters of each one. This work that
    data scientists normally perform requires a lot of time as well as experienced
    professionals. From a computational point of view, hyperparameter tuning is a
    comprehensive search process, so it can be automated.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在建模阶段的主要任务是选择要评估的不同模型，并调整每个模型的不同超参数。数据科学家通常需要花费大量时间并拥有丰富经验才能完成这些工作。从计算角度来看，超参数调优是一个全面的搜索过程，因此可以自动化。
- en: '**AutoML** is a process that automates, using AI algorithms, every step of
    the ML pipeline described previously, from the data preprocessing to the deployment
    of the ML model, allowing non-data scientists (such as software developers) to
    use ML techniques without the need for experience in the field. In the following
    figure, we can see a simple representation of the inputs and outputs of an AutoML
    system:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**AutoML**是一个自动化的过程，利用人工智能算法自动执行先前描述的机器学习流程中的每一个步骤，从数据预处理到机器学习模型的部署，使非数据科学家（如软件开发人员）也能使用机器学习技术，而无需该领域的经验。在下图中，我们可以看到AutoML系统的输入和输出的简单表示：'
- en: '![Figure 1.4 – How AutoML works'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.4 – AutoML的工作原理'
- en: '](img/B16953_01_04.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16953_01_04.jpg)'
- en: Figure 1.4 – How AutoML works
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4 – AutoML的工作原理
- en: AutoML is also capable of producing simpler solutions, more agile proof-of-concept
    creation, and unattended training of models that often outperform those created
    manually, dramatically improving the predictive performance of the model and allowing
    data scientists to perform more complex tasks that are more difficult to automate,
    such as data preprocessing and feature engineering, defined in the *Model monitoring*
    section. Before introducing the AutoML types, let's take a quick look at the main
    differences between AutoML and traditional ML.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML还能够生成更简单的解决方案，更灵活的概念验证创建，以及无人值守的模型训练，这些模型通常优于手动创建的模型，显著提高模型的预测性能，并使数据科学家能够执行更复杂、难以自动化的任务，例如数据预处理和特征工程，这些任务在*模型监控*部分有定义。在介绍AutoML的类型之前，先快速了解一下AutoML与传统机器学习的主要区别。
- en: Differences from the standard approach
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与标准方法的区别
- en: In the standard ML approach, data scientists have an input dataset to train.
    Usually, this raw data is not ready for the training algorithms, so an expert
    must apply different methods, such as data preprocessing, feature engineering,
    and feature extraction methods, as well as model tuning through algorithm selection
    and hyperparameter optimization, to maximize the model's predictive performance.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准的机器学习方法中，数据科学家有一个输入数据集来进行训练。通常，这些原始数据并未准备好供训练算法使用，因此专家必须应用不同的方法，如数据预处理、特征工程和特征提取方法，并通过算法选择和超参数优化来调整模型，以最大化模型的预测性能。
- en: All of these steps are time-consuming and resource-intensive, being the main
    obstacle to putting ML into practice.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些步骤都耗时且资源密集，是将机器学习（ML）应用到实际中的主要障碍。
- en: With AutoML, we simplify these steps for non-experts, making it possible to
    apply ML to solve a problem in an easier and faster way.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 通过AutoML，我们简化了这些步骤，使非专家也能以更简便、更快速的方式应用机器学习解决问题。
- en: Now that the main concepts of AutoML have been explained, we can put them into
    practice. But first, we will see what the main types of AutoML are and some of
    the widely used tools to perform AutoML.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 既然已经解释了AutoML的主要概念，我们可以将其付诸实践。但首先，我们将了解AutoML的主要类型以及一些广泛使用的工具来执行AutoML。
- en: Types of AutoML
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AutoML的类型
- en: This chapter will explore the frameworks available today for each of the previously
    listed AutoML types, giving you an idea of what is possible now in terms of AutoML.
    But first, let's briefly discuss the end-to-end ML pipeline and see where each
    process occurs in that pipeline.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨当前为每种先前列出的AutoML类型提供的框架，让您了解目前在AutoML方面可以实现的内容。但首先，让我们简要讨论一下端到端机器学习流程，并看看每个过程在该流程中发生的位置。
- en: As we saw in the previous workflow diagram, the ML pipeline involves more steps
    than the modeling ones, such as data steps and deployment steps. In this book,
    we will focus on the automation of modeling because it is one of the phases that
    require more investment of time and as we will see later, AutoKeras, the AutoML
    framework we will work on, uses neural architecture search and hyperparameter
    optimization methods, both applied in the modeling phase.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在之前的工作流程图中看到的，机器学习流水线涉及比建模更多的步骤，如数据步骤和部署步骤。在本书中，我们将专注于建模的自动化，因为这是一个需要更多时间投入的阶段，正如我们稍后将看到的，AutoKeras，我们将使用的AutoML框架，使用了神经架构搜索和超参数优化方法，这两者都应用在建模阶段。
- en: 'AutoML tries to automate each of the steps in the pipeline but the main time-consuming
    steps to automate usually are the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML试图自动化管道中的每个步骤，但通常需要自动化的主要耗时步骤如下：
- en: Automated feature engineering
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动特征工程
- en: Automated model selection and hyperparameter tuning
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动模型选择和超参数调整
- en: Automated neural network architecture selection
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动神经网络架构选择
- en: Automated feature engineering
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动特征工程
- en: The features used by the model have a direct impact on the performance of an
    ML algorithm. Feature engineering requires a large investment of time and human
    resources (data scientists) and involves a lot of trial and error, as well as
    deep domain knowledge.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 模型使用的特征直接影响机器学习算法的性能。特征工程需要大量时间和人力资源（数据科学家），并涉及大量的试验和错误，以及深入的领域知识。
- en: Automated feature engineering is based on creating new sets of features iteratively
    until the ML model achieves good prediction performance.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 自动特征工程基于迭代地创建新的特征集，直到机器学习模型达到良好的预测性能。
- en: 'In a standard feature engineering process, a dataset is collected, for example,
    a dataset from a job search website that collects data on the behavior of candidates.
    Usually, a data scientist will create new features if they are not already in
    the data, such as the following:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准的特征工程过程中，例如从一个职位搜索网站收集的数据集中，通常数据科学家会创建新的特征（如果数据中还没有），例如以下内容：
- en: Search keywords
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索关键字
- en: Titles of the job offers read by the candidates
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 候选人阅读的职位名称
- en: Candidate application frequency
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 候选人申请频率
- en: Time since the last application
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上次申请以来的时间
- en: Type of job offers to which the candidate applies
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 候选人申请的职位类型
- en: Feature engineering automation tries to create an algorithm that automatically
    generates or obtains these types of features from the data.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 特征工程自动化尝试创建一种算法，该算法可以自动从数据中生成或获取这些类型的特征。
- en: There is also a specialized form of ML called deep learning, in which features
    are extracted from images, text, and videos automatically using matrix transformations
    on the model layers.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种称为深度学习的专门形式的机器学习，其中特征是通过在模型层上的矩阵变换自动从图像、文本和视频中提取的。
- en: Automated model choosing and hyperparameter optimization
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动模型选择和超参数优化
- en: After the data preprocessing phase, an ML algorithm has to be searched to train
    with these features so that it is able to predict from new observations. In contrast
    to the previous step, the selection of models is full of options to choose from.
    There are classification and regression models, neural network-based models, clustering
    models, and many more.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据预处理阶段之后，需要搜索一个机器学习算法来训练这些特征，以便能够预测新的观测结果。与前一步骤相比，模型选择有很多可供选择的选项。有分类和回归模型，基于神经网络的模型，聚类模型等等。
- en: Each algorithm is suitable for a certain class of problems and with automated
    model selection, we can find the optimal model by executing all the appropriate
    models for a particular task and selecting the one that is most accurate. There
    is no ML algorithm that works well with all datasets and there are some algorithms
    that require more hyperparameter tuning than others. In fact, during model selection,
    we tend to experiment with different hyperparameters.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 每种算法适用于某类问题，通过自动化模型选择，我们可以执行所有适合特定任务的适当模型，并选择最准确的模型。没有一种机器学习算法适用于所有数据集，有些算法需要比其他算法更多的超参数调整。事实上，在模型选择过程中，我们倾向于尝试不同的超参数。
- en: What are hyperparameters?
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是超参数？
- en: 'In the training phase of the model, there are many variables to be set. Basically,
    we can group them into two types: **parameters** and **hyperparameters**. **Parameters**
    are those that are learned in the model training process, such as weight and bias
    in a neural network, while **hyperparameters** are those that are initialized
    just before the training process as a learning rate, dropout factor, and so on.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型的训练阶段，有许多变量需要设置。基本上，我们可以将它们分为两类：**参数**和**超参数**。**参数**是在模型训练过程中学习到的，例如神经网络中的权重和偏置，而**超参数**是在训练过程开始前初始化的，例如学习率、丢弃率等。
- en: Types of search methods
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 搜索方法类型
- en: 'There are many algorithms to find the optimal hyperparameters of a model. The
    following figure highlights the best-known ones that are also used by AutoKeras:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多算法可以找到模型的最优超参数。下图突出显示了最著名的几种算法，这些算法也被AutoKeras使用：
- en: '![Figure 1.5 – Hyperparameter search method paths'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.5 – 超参数搜索方法路径'
- en: '](img/B16953_01_05.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16953_01_05.jpg)'
- en: Figure 1.5 – Hyperparameter search method paths
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5 – 超参数搜索方法路径
- en: 'Let''s try to understand these methods in more detail:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地理解这些方法：
- en: '**Grid search**: Given a set of variables (hyperparameters) and a set of values
    for each variable, grid search performs an exhaustive search, testing all possible
    combinations of these values in the variables to find the best possible model
    based on a defined evaluation metric, such as precision. In the case of a neural
    network with learning rate and dropout as hyperparameters to tune, we can define
    a learning rate set of values as [0.1, 0,01] and a dropout set of values as [0.2,
    0,5], so grid search will train the model with these combinations:'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网格搜索**：给定一组变量（超参数）和每个变量的值集合，网格搜索执行一种穷尽搜索，测试这些值在变量中的所有可能组合，以根据定义的评估标准（如精度）找到最佳的模型。在一个神经网络中，假设学习率和丢弃率作为超参数进行调整，我们可以将学习率的值集合定义为[0.1,
    0.01]，丢弃率的值集合定义为[0.2, 0.5]，因此网格搜索将使用这些组合训练模型：'
- en: '(a) *learning_rate*: 0.1, dropout=0.2 => Model version 1'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (a) *学习率*：0.1，丢弃率=0.2 => 模型版本 1
- en: '(b) *learning_rate*: 0.01, dropout=0.2 => Model version 2'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (b) *学习率*：0.01，丢弃率=0.2 => 模型版本 2
- en: '(c) *learning_rate*: 0.1, dropout=0.5 => Model version 3'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (c) *学习率*：0.1，丢弃率=0.5 => 模型版本 3
- en: '(d) *learning_rate*: 0.01, dropout=0.5 => Model version 4'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: (d) *学习率*：0.01，丢弃率=0.5 => 模型版本 4
- en: '**Random search**: This is similar to grid search but runs the training of
    the model combinations in a random order. That random exploration feature makes
    random search usually cheaper than grid search.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机搜索**：这与网格搜索类似，但它以随机顺序运行模型组合的训练。由于其随机探索特性，随机搜索通常比网格搜索便宜。'
- en: '**Bayesian search**: This method performs a hyperparameter fit based on the
    Bayesian theorem that explores only combinations that maximize the probability
    function.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**贝叶斯搜索**：该方法基于贝叶斯定理执行超参数拟合，只探索那些最大化概率函数的组合。'
- en: '**Hyperband**: This is a novel variation of random search that tries to resolve
    the exploration/exploitation dilemma using a bandit-based approach to hyperparameter
    optimization.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hyperband**：这是一种新型的随机搜索变体，尝试通过基于老虎机的方法解决探索/利用困境，以进行超参数优化。'
- en: Automated neural network architecture selection
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动化神经网络架构选择
- en: The design of neural network architectures is one of the most complex and tedious
    tasks in the world of ML. Typically, in traditional ML, data scientists spend
    a lot of time iterating through different neural network architectures with different
    hyperparameters to optimize a model objective function. This is time-consuming,
    requires deep knowledge, and is prone to errors at times.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络架构的设计是机器学习领域最复杂和最繁琐的任务之一。通常，在传统机器学习中，数据科学家会花费大量时间迭代不同的神经网络架构和超参数，以优化模型的目标函数。这既耗时，又需要深厚的知识，有时还容易出错。
- en: In the middle of the 2010s, the idea of implementing neural network search by
    employing evolutionary algorithms and reinforcement learning to design and find
    an optimal neural network architecture was introduced. It was called **Network
    Architecture Search** (**NAS**). Basically, it trains a model to create layers,
    stacking them to create a deep neural network architecture.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在2010年代中期，提出了通过使用进化算法和强化学习来设计和寻找最优神经网络架构的想法。这被称为**网络架构搜索**（**NAS**）。基本上，它训练一个模型来创建层，并堆叠这些层以构建一个深度神经网络架构。
- en: 'A NAS system involves these three main components:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 一个NAS系统包括以下三个主要组件：
- en: '**Search space**: Consists of a set of blocks of operations (full connected,
    convolution, and so on) and how these operations are connected to each other to
    form valid network architectures. Traditionally, the design of the search space
    is done by a data scientist.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**搜索空间**：由一组操作块（全连接、卷积等）以及这些操作如何相互连接以形成有效的网络架构组成。传统上，搜索空间的设计由数据科学家完成。'
- en: '**Search algorithm**: A NAS search algorithm tests a number of candidate network
    architecture models. From the metrics obtained, it selects the candidates with
    the highest performance.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**搜索算法**：NAS 搜索算法测试一系列候选网络架构模型。从获得的指标中，它选择表现最好的候选模型。'
- en: '**Evaluation strategy**: As a large number of models are required to be tested
    in order to obtain successful results, the process is computationally very expensive,
    so new methods appear every so often to save time or computing resources.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估策略**：为了获得成功的结果，需要测试大量的模型，因此该过程在计算上非常昂贵，因此新的方法时常出现，以节省时间或计算资源。'
- en: 'In the next figure, you can see the relationships between the three described
    components:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个图中，你可以看到三个描述的组件之间的关系：
- en: '![Figure 1.6 – NAS component relationships'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.6 – NAS 组件关系'
- en: '](img/B16953_01_06.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16953_01_06.jpg)'
- en: Figure 1.6 – NAS component relationships
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6 – NAS 组件关系
- en: 'Currently, NAS is a new area of research that is attracting a lot of attention
    and several research papers have been published: [http://www.ml4aad.org/automl/literature-on-neural-architecture-search/](http://www.ml4aad.org/automl/literature-on-neural-architecture-search/).
    Some of the most cited papers are as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，NAS 是一个新兴的研究领域，吸引了大量关注，并且已经发布了若干研究论文：[http://www.ml4aad.org/automl/literature-on-neural-architecture-search/](http://www.ml4aad.org/automl/literature-on-neural-architecture-search/)。以下是一些被引用最多的论文：
- en: '**NASNet** ([https://arxiv.org/abs/1707.07012](https://arxiv.org/abs/1707.07012))
    – *Learning Transferable Architecture for Scalable Image Recognition*: High-precision
    models for image classification are based on very complex neural networks with
    lots of layers. NASNet is a method of learning model architectures directly from
    the dataset of interest. Due to the high cost of doing so when the dataset is
    very large, it first looks for an architectural building block in a small dataset,
    and then transfers the block to a larger dataset. This approach is a successful
    example of what you can achieve with AutoML, because NASNet-generated models often
    outperform state-of-the-art, human-designed models. In the following figure, we
    can see how NASNet works:'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NASNet** ([https://arxiv.org/abs/1707.07012](https://arxiv.org/abs/1707.07012))
    – *可转移架构的学习用于可扩展图像识别*：基于非常复杂的神经网络（具有大量层）的高精度图像分类模型。NASNet 是一种直接从感兴趣的数据集学习模型架构的方法。由于在数据集非常大的情况下，执行该操作的成本很高，因此它首先在一个小数据集中寻找架构构建模块，然后将该模块转移到更大的数据集上。这种方法是
    AutoML 成功应用的一个典范，因为 NASNet 生成的模型通常优于最先进的人工设计模型。在下图中，我们可以看到 NASNet 是如何工作的：'
- en: '![Figure 1.7 – Overview of NAS'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.7 – NAS 概览'
- en: '](img/B16953_01_07.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16953_01_07.jpg)'
- en: Figure 1.7 – Overview of NAS
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7 – NAS 概览
- en: '**AmoebaNet** – *Regularized Evolution for Image Classifier Architecture Search*:
    This approach uses an evolutionary algorithm to efficiently discover high-quality
    architectures. To date, the evolutionary algorithms applied to image classification
    have not exceeded those created by humans. AmoebaNet-A surpasses them for the
    first time. The key has been to modify the selection algorithm by introducing
    an age property to favor the youngest genotypes. AmoebaNet-A has a similar precision
    to the latest generation ImageNet models discovered with more complex architecture
    search methods, showing that evolution can obtain results faster with the same
    hardware, especially in the early search stages, something that is especially
    important when there are few computational resources available. The following
    figure shows the correlation between precision and model size for some representative
    next-generation image classification models in history. The dotted circle shows
    84.3% accuracy for an AmoebaNet model:'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AmoebaNet** – *图像分类器架构搜索的正则化进化*：该方法使用进化算法高效地发现高质量的架构。迄今为止，应用于图像分类的进化算法尚未超越人工设计的架构。而
    **AmoebaNet-A** 首次超越了这些架构。关键在于通过引入年龄属性来修改选择算法，偏向选择最年轻的基因型。**AmoebaNet-A** 的精度与采用更复杂架构搜索方法发现的最新一代
    ImageNet 模型相似，表明进化算法能够在相同硬件上更快地取得结果，特别是在搜索的早期阶段，这在计算资源有限时尤为重要。下图展示了历史上一些代表性的下一代图像分类模型的精度与模型大小之间的相关性。虚线圆圈显示了
    **AmoebaNet** 模型的 84.3% 精度：'
- en: '![Figure 1.8 – Correlation between the top-1 accuracy and model size for state-of-the-art
    image classification models using the ImageNet dataset ](img/B16953_01_08.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图 1.8 – 使用 ImageNet 数据集的最先进图像分类模型中，top-1 精度与模型大小之间的相关性](img/B16953_01_08.jpg)'
- en: Figure 1.8 – Correlation between the top-1 accuracy and model size for state-of-the-art
    image classification models using the ImageNet dataset
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8 – 使用 ImageNet 数据集的最先进图像分类模型中，top-1 精度与模型大小之间的相关性
- en: '**Efficient Neural Architecture Search** (**ENAS**): This variant of NASNet
    improves its efficiency by allowing all child models to share their weights, so
    it is not necessary to train each child model from scratch. This optimization
    significantly improves classification performance.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Efficient Neural Architecture Search** (**ENAS**)：该 NASNet 的变种通过允许所有子模型共享权重，避免每个子模型从头开始训练，从而提高了效率。这一优化显著提高了分类性能。'
- en: 'There are many ML tools available, all of them with similar goals, to automate
    the different steps of the ML pipeline. The following are some of the most used
    tools:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多机器学习工具可用，它们的目标都相似，旨在自动化机器学习管道的不同步骤。以下是一些最常用的工具：
- en: '**AutoKeras**: An AutoML system based on the deep learning framework Keras
    and using hyperparameter searching and NAS.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AutoKeras**：一个基于深度学习框架 Keras 的 AutoML 系统，采用超参数搜索和神经架构搜索（NAS）。'
- en: '**auto-sklearn**: An AutoML toolkit that allows you to use a special type of
    scikit-learn estimator, which automates algorithm selection and hyperparameter
    tuning, using Bayesian optimization, meta-learning, and model ensembling.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**auto-sklearn**：一个 AutoML 工具包，允许你使用一种特殊类型的 scikit-learn 估算器，自动选择算法和调整超参数，使用贝叶斯优化、元学习和模型集成。'
- en: '**DataRobot**: An AI platform that automates the end-to-end process for building,
    deploying, and maintaining AI at scale.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DataRobot**：一个 AI 平台，自动化构建、部署和维护大规模 AI 的端到端过程。'
- en: '**Darwin**: An AI tool that automates the slowest steps in the model life cycle,
    ensuring long-term quality and the scalability of models.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Darwin**：一个 AI 工具，自动化模型生命周期中最慢的步骤，确保模型的长期质量和可扩展性。'
- en: '**H2O-DriverlessAI**: An AI platform for AutoML.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**H2O-DriverlessAI**：一个 AutoML 的 AI 平台。'
- en: '**Google''s AutoML**: A suite of ML products that enable developers with no
    ML experience to train and use high-performance models in their projects. To do
    this, this tool uses Google''s powerful next-generation transfer learning and
    neural architecture search technology.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google''s AutoML**：一套机器学习产品，使没有机器学习经验的开发人员也能在项目中训练和使用高性能模型。为此，该工具采用了 Google
    强大的下一代迁移学习和神经架构搜索技术。'
- en: '**Microsoft Azure AutoML**: This cloud service creates many pipelines in parallel
    that try different algorithms and parameters for you.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Microsoft Azure AutoML**：此云服务并行创建多个管道，尝试不同的算法和参数。'
- en: '**Tree-based Pipeline Optimization Tool** (**TPOT**): A Python Automated Machine
    Learning tool that optimizes machine learning pipelines using genetic programming.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于树的管道优化工具** (**TPOT**): 一个Python自动化机器学习工具，使用遗传编程优化机器学习管道。'
- en: We can see an exhaustive comparison of the main AutoML tools that currently
    exist in the paper *Evaluation and Comparison of AutoML Approaches and Tools*,
    and from it we can conclude that while the main commercial solutions, such as
    H2O-DriverlessAI, DataRobot, and Darwin, allow us to detect the data schema, execute
    the feature engineering, and analyze detailed results for interpretation purposes,
    open source tools are more focused on automating the modeling tasks, training,
    and model evaluation, leaving the data-oriented tasks to the data scientists.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在论文*《AutoML方法与工具的评估与比较》*中看到目前存在的主要AutoML工具的详尽比较，从中我们可以得出结论，虽然主要的商业解决方案，如H2O-DriverlessAI、DataRobot和Darwin，允许我们检测数据架构、执行特征工程，并分析详细结果以供解释，但开源工具则更多专注于自动化建模任务、训练和模型评估，将数据相关的任务留给数据科学家。
- en: The study also concludes that in the various evaluations and benchmarks tested,
    AutoKeras is the most stable and efficient tool, which is very important in a
    production environment where both performance and stability are key factors. These
    good features, in addition to being a widely used tool, are the main reason why
    AutoKeras was the AutoML framework chosen when writing this book.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 研究还得出结论，在各种评估和基准测试中，AutoKeras是最稳定和高效的工具，这在生产环境中非常重要，因为在这种环境中，性能和稳定性是关键因素。这些优良特性，加上它是一个广泛使用的工具，是选择AutoKeras作为本书编写时所选AutoML框架的主要原因。
- en: Summary
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we defined the purpose and benefits of AutoML, from describing
    the different phases of an ML pipeline to detailing the types of algorithms for
    hyperparameter optimization and neural architecture searching.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们定义了AutoML的目的和好处，从描述ML管道的不同阶段到详细说明超参数优化和神经架构搜索的算法类型。
- en: Now that we have learned the main concepts of AutoML, we are ready to move on
    to the next chapter, where you will learn how to install AutoKeras and how to
    use it to train a simple network and then train advanced models as you progress
    to more complicated techniques.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了AutoML的主要概念，准备进入下一章，您将在那里学习如何安装AutoKeras，如何使用它训练一个简单的网络，并随着学习更复杂的技术，训练更高级的模型。
- en: Further reading
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Bayes'' theorem: [https://towardsdatascience.com/bayes-theorem-the-holy-grail-of-data-science-55d93315defb](https://towardsdatascience.com/bayes-theorem-the-holy-grail-of-data-science-55d93315defb)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '贝叶斯定理: [https://towardsdatascience.com/bayes-theorem-the-holy-grail-of-data-science-55d93315defb](https://towardsdatascience.com/bayes-theorem-the-holy-grail-of-data-science-55d93315defb)'
- en: 'The exploration versus exploitation dilemma: [https://towardsdatascience.com/intuition-exploration-vs-exploitation-c645a1d37c7a](https://towardsdatascience.com/intuition-exploration-vs-exploitation-c645a1d37c7a)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '探索与利用的困境: [https://towardsdatascience.com/intuition-exploration-vs-exploitation-c645a1d37c7a](https://towardsdatascience.com/intuition-exploration-vs-exploitation-c645a1d37c7a)'
- en: 'Multiarmed bandit: [https://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf](https://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '多臂赌博机: [https://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf](https://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf)'
- en: 'AmoebaNet: [https://arxiv.org/abs/1802.01548](https://arxiv.org/abs/1802.01548)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'AmoebaNet: [https://arxiv.org/abs/1802.01548](https://arxiv.org/abs/1802.01548)'
- en: 'ENAS: [https://arxiv.org/abs/1802.03268](https://arxiv.org/abs/1802.03268)'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ENAS: [https://arxiv.org/abs/1802.03268](https://arxiv.org/abs/1802.03268)'
- en: 'Evaluation and comparison of AutoML approaches and tools: [https://arxiv.org/pdf/1908.05557.pdf](https://arxiv.org/pdf/1908.05557.pdf)'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'AutoML方法与工具的评估与比较: [https://arxiv.org/pdf/1908.05557.pdf](https://arxiv.org/pdf/1908.05557.pdf)'
