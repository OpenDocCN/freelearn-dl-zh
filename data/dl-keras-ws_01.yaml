- en: 1\. Introduction to Machine Learning with Keras
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1. 使用Keras的机器学习介绍
- en: Overview
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 概述
- en: This chapter introduces machine learning with Python. We will use real-life
    datasets to demonstrate the basics of machine learning, which include preprocessing
    data for machine learning models and building a classification model using the
    logistic regression model with scikit-learn. We will then advance our model-building
    skills by incorporating regularization into our models and evaluating their performance
    with model evaluation metrics. By the end of this chapter, you will be able to
    confidently create models to solve classification tasks using the scikit-learn
    library in Python and evaluate the performance of those models effectively.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了Python中的机器学习。我们将使用实际数据集来演示机器学习的基础知识，包括为机器学习模型进行数据预处理，并使用scikit-learn构建逻辑回归模型进行分类。然后，我们将通过在模型中加入正则化技术，提升我们的模型构建技巧，并通过模型评估指标来评估模型的表现。到本章结束时，你将能够自信地使用Python中的scikit-learn库构建分类任务模型，并有效地评估这些模型的性能。
- en: Introduction
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Machine learning is the science of utilizing machines to emulate human tasks
    and to have the machine improve its performance of that task over time. By feeding
    machines data in the form of observations of real-world events, they can develop
    patterns and relationships that will optimize an objective function, such as the
    accuracy of a binary classification task or the error in a regression task.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是利用机器模拟人类任务的科学，并让机器随着时间的推移提高其执行任务的能力。通过将现实世界事件的观察数据输入到机器中，机器可以发展出优化目标函数的模式和关系，例如二分类任务的准确度或回归任务的误差。
- en: In general, the usefulness of machine learning is in the machine's ability to
    learn highly complex and non-linear relationships in large datasets and to replicate
    the results of that learning many times. One branch of machine learning algorithms
    has shown a lot of promise in learning highly complex and non-linear relationships
    associated with large, often unstructured datasets such as images, audio, and
    text data—**Artificial Neural Networks** (**ANNs**). ANNs, however, can be complicated
    to program, train, and evaluate, and this can be intimidating for beginners in
    the field. Keras is a Python library that presents a facile introduction to building,
    training, and evaluating ANNs that is incredibly useful to those studying machine
    learning.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，机器学习的价值在于机器能够学习大规模数据集中高度复杂和非线性的关系，并且能够多次复制这种学习的结果。机器学习算法的一个分支在学习与大规模、通常是非结构化数据集（如图像、音频和文本数据）相关的复杂非线性关系方面显示出了很大的潜力——**人工神经网络**（**ANNs**）。然而，人工神经网络的编程、训练和评估可能很复杂，对于该领域的初学者来说可能会感到有些令人畏惧。Keras是一个Python库，提供了构建、训练和评估人工神经网络的简单入门方法，对于学习机器学习的人来说非常有用。
- en: 'Take, for example, the classification of a dataset of pictures of either dogs
    or cats into classes of their respective type. For a human, this is simple, and
    the accuracy would likely be very high. However, it may take around a second to
    categorize each picture and scaling the task can only be achieved by increasing
    the number of humans, which may not be feasible. While it may be difficult, though
    certainly not impossible, for machines to reach the same level of accuracy as
    humans for this task, machines can classify many images per second, and scaling
    can be easily done by increasing the processing power of a single machine or making
    the algorithm more efficient:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 以将包含狗或猫的图片数据集分类为相应类型的任务为例。对于人类来说，这是简单的，准确度很可能会非常高。然而，每张图片的分类可能需要大约一秒钟，且要扩大这一任务的规模只能通过增加人力来实现，这可能并不现实。虽然对于机器来说，达到与人类相同的准确度可能比较困难（但并非不可能），但机器可以每秒处理大量的图像，且通过增加单台机器的处理能力或优化算法效率，任务的规模扩展可以轻松实现：
- en: '![Figure 1.1: The classification of images as either dog or cat is a simple
    task for humans, but quite difficult for machines'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.1：将图像分类为狗或猫是人类的简单任务，但对机器来说相当困难](img/B15777_01_01.jpg)'
- en: '](img/B15777_01_01.jpg)'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_01.jpg)'
- en: 'Figure 1.1: The classification of images as either dog or cat is a simple task
    for humans, but quite difficult for machines'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1：将图像分类为狗或猫是人类的简单任务，但对机器来说相当困难
- en: 'While the trivial task of classifying dogs and cats may be simple for us humans,
    the same principles that are used to create a machine learning model that classifies
    dogs and cats can be applied to other classification tasks that humans may struggle
    with. An example of this is identifying tumors in Magnetic Resonance Images (MRIs).
    For humans, this task requires a medical professional with years of experience,
    whereas a machine may only need a dataset of labeled images. The following image
    shows MRI images of the brain, some of which include tumors:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然分类狗和猫的简单任务对我们人类来说可能很简单，但用于创建分类狗和猫的机器学习模型的相同原理可以应用于其他人类可能会遇到困难的分类任务。一个例子就是识别磁共振成像（MRI）中的肿瘤。对人类而言，这项任务需要一位具有多年经验的医疗专业人员，而机器可能只需要一个标注过的图像数据集。以下图像显示了大脑的
    MRI 图像，其中一些图像包含肿瘤：
- en: '![Figure 1.2: A non-trivial classification task for humans – MRIs of brains,
    some of which include the presence of tumors'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.2：一个非平凡的分类任务——大脑的 MRI 图像，其中一些图像包含肿瘤的存在'
- en: '](img/B15777_01_02.jpg)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_02.jpg)'
- en: 'Figure 1.2: A non-trivial classification task for humans – MRIs of brains,
    some of which include the presence of tumors'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.2：一个非平凡的分类任务——大脑的 MRI 图像，其中一些图像包含肿瘤的存在
- en: Data Representation
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据表示
- en: We build models so that we can learn something about the data we are training
    on and about the relationships between the features of the dataset. This learning
    can inform us when we encounter new observations. However, we must realize that
    the observations we interact within the real world and the format of the data
    that's needed to train machine learning models are very different. Working with
    text data is a prime example of this. When we read the text, we are able to understand
    each word and apply the context that's given by each word in relation to the surrounding
    words—not a trivial task. However, machines are unable to interpret this contextual
    information. Unless it is specifically encoded, they have no idea how to convert
    text into something that can be a numerical input. Therefore, we must represent
    the data appropriately, often by converting non-numerical data types—for example,
    converting text, dates, and categorical variables into numerical ones.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建模型是为了从我们正在训练的数据中学习某些信息，并了解数据集特征之间的关系。这种学习可以在我们遇到新观察时为我们提供帮助。然而，我们必须意识到，我们在现实世界中互动的观察和训练机器学习模型所需的数据格式是非常不同的。处理文本数据就是一个典型的例子。当我们阅读文本时，我们能够理解每个单词，并根据每个单词与周围单词的关系来应用上下文——这并非易事。然而，机器无法解释这些上下文信息。除非它们被专门编码，否则它们根本不知道如何将文本转换为可以作为数值输入的内容。因此，我们必须以适当的方式表示数据，通常是通过将非数值数据类型——例如，将文本、日期和类别变量转换为数值型数据。
- en: Tables of Data
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据表
- en: 'Much of the data that''s fed into machine learning problems is two-dimensional
    and can be represented as rows or columns. Images are a good example of a dataset
    that may be three-or even four-dimensional. The shape of each image will be two-dimensional
    (a height and a width), the number of images together will add a third dimension,
    and a color channel (red, green, and blue) will add a fourth:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分输入机器学习问题的数据是二维的，可以表示为行或列。图像是一个很好的例子，它可能是三维甚至四维的。每个图像的形状将是二维的（高度和宽度），所有图像加在一起将增加第三维度，颜色通道（红色、绿色和蓝色）将增加第四维度：
- en: '![Figure 1.3: A color image and its representation as red, green, and blue
    images'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.3：一张彩色图像及其作为红、绿、蓝图像的表示'
- en: '](img/B15777_01_03.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_03.jpg)'
- en: 'Figure 1.3: A color image and its representation as red, green, and blue images'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.3：一张彩色图像及其作为红、绿、蓝图像的表示
- en: The following figure shows a few rows from a dataset that has been taken from
    the UCI repository, which documents the online session activity of various users
    of a shopping website. The columns of the dataset represent various attributes
    of the session activity and general attributes of the page, while the rows represent
    the various sessions, all corresponding to different users. The column named `Revenue`
    represents whether the user ended the session by purchasing products from the website.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了来自 UCI 数据库的数据集中的几行数据，该数据集记录了购物网站不同用户的在线会话活动。数据集的列代表会话活动的不同属性和页面的常规属性，而行代表不同用户的各个会话。名为
    `Revenue` 的列表示用户是否通过购买网站上的产品结束了会话。
- en: Note
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'The dataset that documents the online session activity of various users of
    a shopping website can be found here: [https://packt.live/39rdA7S](https://packt.live/39rdA7S).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 记录购物网站各个用户在线会话活动的数据集可以在这里找到：[https://packt.live/39rdA7S](https://packt.live/39rdA7S)。
- en: 'One objective of analyzing the dataset could be to try and use the information
    given to predict whether a given user will purchase any products from the website.
    We can then check whether we were correct by comparing our predictions to the
    column named `Revenue`. The long-term benefit of this is that we could then use
    our model to identify important attributes of a session or web page that may predict
    purchase intent:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 分析数据集的一个目标可能是尝试利用提供的信息预测某个用户是否会从网站购买产品。然后，我们可以通过将我们的预测与名为`Revenue`的列进行比较来检查是否正确。长期来看，使用我们的模型可以识别会话或网页的关键特征，这些特征可能会预测购买意图：
- en: '![Figure 1.4: An image showing the first 20 instances of the online shoppers
    purchasing intention dataset'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.4：一张显示在线购物者购买意图数据集前20个实例的图片]'
- en: '](img/B15777_01_04.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_04.jpg)'
- en: 'Figure 1.4: An image showing the first 20 instances of the online shoppers
    purchasing intention dataset'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4：一张显示在线购物者购买意图数据集前20个实例的图片
- en: Loading Data
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载数据
- en: Data can be in different forms and can be available in many places. Datasets
    for beginners are often given in a flat format, which means that they are two-dimensional,
    with rows and columns. Other common forms of data may include images, `JSON` objects,
    and text documents. Each type of data format has to be loaded in specific ways.
    For example, numerical data can be loaded into memory using the `NumPy` library,
    which is an efficient library for working with matrices in Python.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以以不同的形式存在，并且可以存储在许多不同的位置。对于初学者来说，数据集通常以平面格式提供，也就是说它们是二维的，有行和列。其他常见的数据形式包括图像、`JSON`对象和文本文件。每种数据格式必须以特定的方式加载。例如，数值数据可以通过`NumPy`库加载到内存中，`NumPy`是一个在Python中处理矩阵的高效库。
- en: However, we would not be able to load our marketing data `.csv` file into memory
    using the `NumPy` library because the dataset contains string values. For our
    dataset, we will use the `pandas` library because of its ability to easily work
    with various data types, such as strings, integers, floats, and binary values.
    In fact, `pandas` is dependent on `NumPy` for operations on numerical data types.
    `pandas` is also able to read JSON, Excel documents, and databases using SQL queries,
    which makes the library common among practitioners for loading and manipulating
    data in Python.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们无法使用`NumPy`库将我们的营销数据`.csv`文件加载到内存中，因为数据集包含字符串值。对于我们的数据集，我们将使用`pandas`库，因为它能够轻松处理各种数据类型，如字符串、整数、浮动数字和二进制值。事实上，`pandas`依赖于`NumPy`来处理数值数据类型。`pandas`还能够通过SQL查询读取JSON、Excel文档和数据库，这使得该库在Python中加载和处理数据时非常常见。
- en: 'Here is an example of how to load a CSV file using the `NumPy` library. We
    use the `skiprows` argument in case there is a header, which usually contains
    column names:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何使用`NumPy`库加载CSV文件的示例。我们使用`skiprows`参数，以防文件中有标题行，标题通常包含列名：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Here''s an example of loading data using the `pandas` library:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是使用`pandas`库加载数据的示例：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here, we are loading in a `.CSV` file. The default delimiter is a comma, so
    passing this as an argument is not necessary but is useful to see. The pandas
    library can also handle non-numeric datatypes, which makes the library more flexible:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，我们加载一个`.CSV`文件。默认的分隔符是逗号，所以传递该参数并非必须，但它有助于展示。`pandas`库还可以处理非数字数据类型，这使得它更加灵活：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `pandas` library will flatten out the JSON and return a `DataFrame`.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`pandas`库将会展平JSON并返回一个`DataFrame`。'
- en: 'The library can even connect to a database, queries can be fed directly into
    the function, and the table that''s returned will be loaded as a `pandas` DataFrame:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 该库甚至可以连接到数据库，查询可以直接传入函数，返回的表格将作为`pandas` DataFrame加载：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We have to pass a database connection to the function in order for this to work.
    There is a myriad of ways for this to be achieved, depending on the database flavor.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将数据库连接传递给函数才能使其工作。根据数据库类型，这可以通过多种方式实现。
- en: Other forms of data that are common in deep learning, such as images and text,
    can also be loaded in and will be discussed later in this course.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 其他常见的数据形式，如图像和文本，也可以加载，并将在本课程后续讨论。
- en: Note
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find all the documentation for pandas here: [https://pandas.pydata.org/pandas-docs/stable/](https://pandas.pydata.org/pandas-docs/stable/).
    The documentation for NumPy can be found here: [https://docs.scipy.org/doc/](https://docs.scipy.org/doc/).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到 pandas 的所有文档：[https://pandas.pydata.org/pandas-docs/stable/](https://pandas.pydata.org/pandas-docs/stable/)。NumPy
    的文档可以在这里找到：[https://docs.scipy.org/doc/](https://docs.scipy.org/doc/)。
- en: 'Exercise 1.01: Loading a Dataset from the UCI Machine Learning Repository'
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 1.01：从 UCI 机器学习库加载数据集
- en: Note
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'For all the exercises and activities in this chapter, you will need to have
    Python 3.7, Jupyter, and pandas installed on your system. Refer to the *Preface*
    for installation instructions. The exercises and activities are performed in Jupyter
    notebooks. It is recommended to keep a separate notebook for different assignments.
    You can download all the notebooks from this book''s GitHub repository, which
    can be found here: [https://packt.live/2OL5E9t](https://packt.live/2OL5E9t).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章中的所有练习和活动，你需要在系统上安装 Python 3.7、Jupyter 和 pandas。安装说明请参考 *前言* 部分。所有的练习和活动都在
    Jupyter notebook 中进行。建议为不同的任务保持单独的 notebook。你可以从本书的 GitHub 仓库下载所有的 notebooks，仓库地址为：[https://packt.live/2OL5E9t](https://packt.live/2OL5E9t)。
- en: In this exercise, we will be loading the `online shoppers purchasing intention`
    dataset from the UCI Machine Learning Repository. The goal of this exercise will
    be to load in the CSV data and identify a target variable to predict and the feature
    variables to use to model the target variable. Finally, we will separate the feature
    and target columns and save them to `.CSV` files so that we can use them in subsequent
    activities and exercises.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将从 UCI 机器学习库加载 `online shoppers purchasing intention` 数据集。这个练习的目标是加载
    CSV 数据，并确定一个目标变量来进行预测，以及用于建模目标变量的特征变量。最后，我们将分离特征列和目标列，并将它们保存为 `.CSV` 文件，以便在后续活动和练习中使用。
- en: 'The dataset is related to the online behavior and activity of customers of
    an online store and indicates whether the user purchased any products from the
    website. You can find the dataset in the GitHub repository at: [https://packt.live/39rdA7S](https://packt.live/39rdA7S).'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集与在线商店客户的在线行为和活动相关，并指示用户是否从网站购买了任何产品。你可以在 GitHub 仓库中找到该数据集：[https://packt.live/39rdA7S](https://packt.live/39rdA7S)。
- en: 'Follow these steps to complete this exercise:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤完成本练习：
- en: 'Open a new Jupyter Notebook and load the data into memory using the pandas
    library with the `read_csv` function. Import the `pandas` library and read in
    the `data` file:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的 Jupyter Notebook，并使用 pandas 库的 `read_csv` 函数将数据加载到内存中。导入 `pandas` 库并读取
    `data` 文件：
- en: '[PRE4]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The code above assumes that you are using the same folder and file structure
    as in the GitHub repository. If you get an error that the file cannot be found,
    then check to make sure your working directory is correctly structured. Alternatively,
    you can edit the file path in the code so that it points to the correct file location
    on your system, though you will need to ensure you are consistent with this when
    saving and loading files in later exercises.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码假设你使用的是与 GitHub 仓库中相同的文件夹和文件结构。如果出现找不到文件的错误，请检查你的工作目录是否正确构建。或者，你可以编辑代码中的文件路径，使其指向系统中正确的文件位置，但你需要确保在后续练习中保存和加载文件时保持一致。
- en: 'To verify that we have loaded the data into the memory correctly, we can print
    the first few rows. Let''s print out the top `20` values of the variable:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了验证我们是否已正确将数据加载到内存中，我们可以打印出前几行。让我们打印出变量的前`20`个值：
- en: '[PRE5]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The printed output should look like this:'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 打印输出应如下所示：
- en: '![Figure 1.5: The first 20 rows and first 8 columns of the pandas DataFrame'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.5：pandas 数据框的前 20 行和前 8 列'
- en: '](img/B15777_01_05.jpg)'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_05.jpg)'
- en: 'Figure 1.5: The first 20 rows and first 8 columns of the pandas DataFrame'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.5：pandas 数据框的前 20 行和前 8 列
- en: 'We can also print the `shape` of the `DataFrame`:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们还可以打印出 `DataFrame` 的 `shape`：
- en: '[PRE6]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The printed output should look as follows, showing that the DataFrame has `12330`
    rows and `18` columns:'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 打印输出应如下所示，显示数据框（DataFrame）有`12330`行和`18`列：
- en: '[PRE7]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We have successfully loaded the data into memory, so now we can manipulate and
    clean the data so that a model can be trained using this data. Remember that machine
    learning models require data to be represented as numerical data types in order
    to be trained. We can see from the first few rows of the dataset that some of
    the columns are string types, so we will have to convert them into numerical data
    types later in this chapter.
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们已成功将数据加载到内存中，现在可以对数据进行操作和清理，以便使用这些数据训练模型。请记住，机器学习模型需要数据以数值数据类型表示，才能进行训练。从数据集的前几行中我们可以看到，有些列是字符串类型，因此我们稍后需要将它们转换为数值数据类型。
- en: 'We can see that there is a given output variable for the dataset, known as
    `Revenue`, which indicates whether or not the user purchased a product from the
    website. This seems like an appropriate target to predict, since the design of
    the website and the choice of the products featured may be based upon the user''s
    behavior and whether they resulted in purchasing a particular product. Create
    `feature` and `target` datasets as follows, providing the `axis=1` argument:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到数据集中有一个名为`Revenue`的输出变量，表示用户是否在网站上购买了产品。这看起来是一个合适的预测目标，因为网站的设计和所展示的产品选择可能会基于用户的行为以及他们是否购买了特定的产品。请按照以下方式创建`feature`和`target`数据集，并提供`axis=1`参数：
- en: '[PRE8]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The `axis=1` argument tells the function to drop columns rather than rows.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`axis=1`参数告诉函数删除列，而不是删除行。'
- en: 'To verify that the shapes of the datasets are as expected, print out the number
    of `rows` and `columns` of each:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了验证数据集的形状是否符合预期，请打印出每个数据集的`行`和`列`数量：
- en: '[PRE9]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'This preceding code produces the following output:'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码生成了以下输出：
- en: '[PRE10]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can see two important things here that we should always verify before continuing:
    first, the number of rows of the `feature` DataFrame and `target` DataFrame are
    the same. Here, we can see that both have `12330` rows. Second, the number of
    columns of the feature DataFrame should be one fewer than the total DataFrame,
    and the target DataFrame has exactly one column.'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以在这里看到两个重要的事项，应该在继续之前始终验证：首先，`feature` DataFrame和`target` DataFrame的行数是相同的。在这里，我们看到两者都有`12330`行。其次，`feature`
    DataFrame的列数应该比总DataFrame少一列，而`target` DataFrame恰好有一列。
- en: Regarding the second point, we have to verify that the target is not contained
    in the feature dataset; otherwise, the model will quickly find that this is the
    only column needed to minimize the total error, all the way down to zero. The
    target column doesn't necessarily have to be one column, but for binary classification,
    as in our case, it will be. Remember that these machine learning models are trying
    to minimize some cost function in which the `target` variable will be part of
    that cost function, usually a difference function between the predicted value
    and `target` variable.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于第二点，我们必须验证目标数据集不包含在特征数据集中；否则，模型会快速发现这是唯一一个需要的列，从而将总误差降到零。目标列不一定必须是单列，但对于二元分类，如我们的案例，它会是。请记住，这些机器学习模型试图最小化某个代价函数，其中`target`变量会作为该代价函数的一部分，通常是预测值和`target`变量之间的差异函数。
- en: 'Finally, save the DataFrames as CSV files so that we can use them later:'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，将DataFrame保存为CSV文件，以便以后使用：
- en: '[PRE11]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Note
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The `header='Revenue'` parameter is used to provide a column name. We will do
    this to reduce confusion later on. The `index=False` parameter is used so that
    the index column is not saved.
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`header=''Revenue''`参数用于提供列名。我们将这样做以减少后续的混淆。`index=False`参数用于确保索引列不会被保存。'
- en: In this section, we have successfully demonstrated how to load data into Python
    using the `pandas` library. This will form the basis of loading data into memory
    for most tabular data. Images and large documents, both of which are other common
    forms of data for machine learning applications, have to be loaded in using other
    methods, all of which will be discussed later in this book.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们已经成功演示了如何使用`pandas`库将数据加载到Python中。这将成为加载大多数表格数据到内存中的基础。图像和大型文档是机器学习应用中其他常见的数据形式，必须使用其他方法加载，这些内容将在本书后面讨论。
- en: Note
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2YZRAyB](https://packt.live/2YZRAyB).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/2YZRAyB](https://packt.live/2YZRAyB)。
- en: You can also run this example online at [https://packt.live/3dVR0pF](https://packt.live/3dVR0pF).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行这个示例，网址是[https://packt.live/3dVR0pF](https://packt.live/3dVR0pF)。
- en: Data Preprocessing
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据预处理
- en: 'To fit models to the data, it must be represented in numerical format since
    the mathematics used in all machine learning algorithms only works on matrices
    of numbers (you cannot perform linear algebra on an image). This will be one goal
    of this section: to learn how to encode all the features into numerical representations.
    For example, in binary text, values that contain one of two possible values may
    be represented as zeros or ones. An example of this can be seen in the following
    diagram. Since there are only two possible values, the value `0` is assumed to
    be a `cat` and the value `1` is assumed to be a `dog`.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将模型拟合到数据中，数据必须以数值格式表示，因为所有机器学习算法中使用的数学仅适用于数字矩阵（你无法对图像执行线性代数运算）。这将是本节的一个目标：学习如何将所有特征编码为数值表示。例如，在二进制文本中，包含两个可能值之一的值可以表示为零或一。以下图示展示了这一点。由于只有两个可能的值，值`0`假设为`cat`（猫），值`1`假设为`dog`（狗）。
- en: 'We can also rename the column for interpretation:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以重新命名列以便解释：
- en: '![Figure 1.6: A numerical encoding of binary text values'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.6：二进制文本值的数值编码'
- en: '](img/B15777_01_06.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_06.jpg)'
- en: 'Figure 1.6: A numerical encoding of binary text values'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6：二进制文本值的数值编码
- en: 'Another goal will be to appropriately represent the data in numerical format
    - by appropriately, we mean that we want to encode relevant information numerically
    through the distribution of numbers. For example, one method to encode the months
    of the year would be to use the number of the month in the year. For example,
    `January` would be encoded as `1`, since it is the first month, and `December`
    would be `12`. Here''s an example of how this would look in practice:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个目标是将数据适当地表示为数值格式——这里的“适当”是指我们希望通过数字的分布将相关信息进行数值编码。例如，将年份的月份进行编码的一种方法是使用月份在年份中的数字表示。例如，`January`（一月）会被编码为`1`，因为它是第一个月，而`December`（十二月）会被编码为`12`。以下是这个过程的实际示例：
- en: '![Figure 1.7: A numerical encoding of months'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.7：月份的数值编码'
- en: '](img/B15777_01_07.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_07.jpg)'
- en: 'Figure 1.7: A numerical encoding of months'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7：月份的数值编码
- en: Not encoding information appropriately into numerical features can lead to machine
    learning models learning unintuitive representations, as well as relationships
    between the `feature` data and `target` variables that will prove useless for
    human interpretation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果未将信息恰当地编码为数值特征，可能会导致机器学习模型学习到不直观的表示，以及`feature`数据和`target`变量之间的关系，这些关系对人类的解释毫无帮助。
- en: An understanding of the machine learning algorithms you are looking to use will
    also help encode features into numerical representations appropriately. For example,
    algorithms for classification tasks such as Artificial Neural Networks (ANNs)
    and logistic regression are susceptible to large variations in the scale between
    the features that may hamper their model-fitting ability.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你对所使用的机器学习算法的理解也有助于将特征适当地编码为数值表示。例如，像人工神经网络（ANN）和逻辑回归这样的分类任务算法对特征间尺度的巨大差异很敏感，这种差异可能会影响它们的模型拟合能力。
- en: Take, for example, a regression problem attempting to fit house attributes,
    such as the area in square feet and the number of bedrooms, to the house price.
    The bounds of the area may be anywhere from `0` to `5000`, whereas the number
    of bedrooms may only vary from `0` to `6`, so there is a large difference between
    the scale of the variables.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，假设有一个回归问题，试图将房屋属性（例如平方英尺面积和卧室数量）拟合到房价上。面积的范围可能从`0`到`5000`不等，而卧室的数量可能只在`0`到`6`之间变化，因此变量之间的尺度差异很大。
- en: An effective way to combat the large variation in scale between the features
    is to normalize the data. Normalizing the data will scale the data appropriately
    so that it is all of a similar magnitude. This ensures that any model coefficients
    or weights can be compared correctly. Algorithms such as decision trees are unaffected
    by data scaling, so this step can be omitted for models using tree-based algorithms.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 解决特征间尺度差异大的有效方法是对数据进行归一化。归一化数据将适当地缩放数据，使其具有相似的大小。这确保了任何模型的系数或权重可以正确地进行比较。像决策树这样的算法不受数据缩放的影响，因此使用基于树的算法的模型可以省略这一步。
- en: In this section, we demonstrated a number of different ways to encode information
    numerically. There is a myriad of alternative techniques that can be explored
    elsewhere. Here, we will show some simple and popular methods that can be used
    to tackle common data formats.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了多种不同的数字编码方式。还有许多其他技术可以在其他地方进行探索。在这里，我们将展示一些简单且流行的方法，用于解决常见的数据格式问题。
- en: 'Exercise 1.02: Cleaning the Data'
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习1.02：清理数据
- en: 'It is important that we clean the data appropriately so that it can be used
    for training models. This often includes converting non-numerical datatypes into
    numerical datatypes. This will be the focus of this exercise - to convert all
    the columns in the feature dataset into numerical columns. To complete the exercise,
    perform the following steps:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须适当清理数据，以便可以用于训练模型。这通常包括将非数值数据类型转换为数值数据类型。这将是本练习的重点——将特征数据集中的所有列转换为数值列。为完成该练习，请执行以下步骤：
- en: 'First, we load the `feature` dataset into memory:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将`feature`数据集加载到内存中：
- en: '[PRE12]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Again, look at the first `20` rows to check out the data:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次查看前`20`行以检查数据：
- en: '[PRE13]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following screenshot shows the output of the preceding code:'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图显示了前述代码的输出：
- en: '![Figure 1.8: First 20 rows and 8 columns of the pandas feature DataFrame'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.8：pandas特征DataFrame的前20行和8列'
- en: '](img/B15777_01_08.jpg)'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_08.jpg)'
- en: 'Figure 1.8: First 20 rows and 8 columns of the pandas feature DataFrame'
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1.8：pandas特征DataFrame的前20行和8列
- en: Here, we can see that there are a number of columns that need to be converted
    into the numerical format. The numerical columns we may not need to modify are
    the columns named `>2`) that the column can take. These are the columns named
    **Month** and **VisitorType**.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到有一些列需要转换为数值格式。我们可能不需要修改的数值列是名为`>2`)的列。这些列是名为**Month**和**VisitorType**的列。
- en: 'For the numerical columns, use the `describe` function to get a quick indication
    of the bounds of the numerical columns:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于数值列，使用`describe`函数快速查看数值列的范围：
- en: '[PRE14]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following screenshot shows the output of the preceding code:'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图显示了前述代码的输出：
- en: '![Figure 1.9: Output of the describe function in the feature DataFrame'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.9：特征DataFrame中describe函数的输出'
- en: '](img/B15777_01_09.jpg)'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_09.jpg)'
- en: 'Figure 1.9: Output of the describe function in the feature DataFrame'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1.9：特征DataFrame中describe函数的输出
- en: Convert the binary column, `1` and the other into `0`. If appropriate, rename
    the column for interpretability.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将二进制列`1`转换为`0`，如果适当，重命名该列以提高可解释性。
- en: 'For context, it is helpful to see the distribution of each value. We can do
    that using the `value_counts` function. We can try this out on the `Weekend` column:'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了提供上下文，查看每个值的分布是有帮助的。我们可以使用`value_counts`函数来做到这一点。我们可以在`Weekend`列上尝试：
- en: '[PRE15]'
  id: totrans-117
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We can also look at these values as a bar graph by plotting the value counts
    by calling the `plot` method of the resulting DataFrame and passing the `kind=''bar''`
    argument:'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们还可以通过调用结果DataFrame的`plot`方法并传入`kind='bar'`参数，以柱状图的形式查看这些值：
- en: '[PRE16]'
  id: totrans-119
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: 'The `kind=''bar''` argument will plot the data as a bar graph. The default
    is a `line graph`. When plotting in Jupyter notebooks, in order to make the plots
    within the notebook, the following command may need to be run: `%matplotlib inline`.'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`kind=''bar''`参数将数据绘制为柱状图。默认是`折线图`。在Jupyter笔记本中绘图时，为了在笔记本中生成图表，可能需要运行以下命令：`%matplotlib
    inline`。'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图表显示了前述代码的输出：
- en: '![Figure 1.10: A plot of the distribution of values of the default column'
  id: totrans-123
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.10：默认列值分布的绘图'
- en: '](img/B15777_01_10.jpg)'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_10.jpg)'
- en: 'Figure 1.10: A plot of the distribution of values of the default column'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图1.10：默认列值分布的绘图
- en: 'Here, we can see that this distribution is skewed toward `false` values. This
    column represents whether the visit to the website occurred on a weekend, corresponding
    to a `true` value, or a weekday, corresponding to a `false` value. Since there
    are more weekdays than weekends, this skewed distribution makes sense. Convert
    the column into a numerical value by converting the `True` values into `1` and
    the `False` values into `0`. We can also change the name of the column from its
    default to `is_weekend`. This makes it a bit more obvious what the column means:'
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到这个分布偏向于 `false` 值。这个列表示访问网站是否发生在周末，`true` 表示周末，`false` 表示工作日。由于工作日比周末多，所以这个偏斜的分布是合理的。通过将
    `True` 值转换为 `1`，`False` 值转换为 `0`，将该列转换为数值值。我们还可以将列的名称从默认名称改为 `is_weekend`，这样可以更清楚地表示列的含义：
- en: '[PRE17]'
  id: totrans-127
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The `apply` function iterates through each element in the column and applies
    the function provided as the argument. A function has to be supplied as the argument.
    Here, a `lambda` function is supplied.
  id: totrans-129
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`apply` 函数会遍历列中的每个元素，并应用作为参数传递的函数。必须提供一个函数作为参数。这里，提供了一个 `lambda` 函数。'
- en: 'Take a look at the original and converted columns side by side. Take a sample
    of the last few rows to see examples of both values being manipulated so that
    they''re numerical data types:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 看看原始列和转换后的列并排展示。取样最后几行，查看值如何被处理，以便它们成为数值数据类型：
- en: '[PRE18]'
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The `tail` function is identical to the `head` function, except the function
    returns the bottom `n` values of the DataFrame instead of the top `n`.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`tail` 函数与 `head` 函数相同，不同之处在于它返回的是 DataFrame 底部的 `n` 个值，而不是顶部的 `n` 个值。'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图展示了前面代码的输出结果：
- en: '![Figure 1.11: The original and manipulated column'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.11: 原始列与处理后的列'
- en: '](img/B15777_01_11.jpg)'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_11.jpg)'
- en: 'Figure 1.11: The original and manipulated column'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '图 1.11: 原始列与处理后的列'
- en: Here, we can see that `True` is converted into `1` and `False` is converted
    into `0`.
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到 `True` 被转换为 `1`，`False` 被转换为 `0`。
- en: 'Now we can drop the `Weekend` column, as only the `is_weekend` column is needed:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们可以删除 `Weekend` 列，因为只需要 `is_weekend` 列：
- en: '[PRE19]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Next, we have to deal with categorical columns. We will approach the conversion
    of categorical columns into numerical values slightly differently than with binary
    text columns, but the concept will be the same. Convert each categorical column
    into a set of dummy columns. With dummy columns, each categorical column will
    be converted into `n` columns, where `n` is the number of unique values in the
    category. The columns will be `0` or `1`, depending on the value of the categorical column.
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要处理分类列。我们将以略有不同于二进制文本列的方式来转换分类列为数值，但概念是相同的。将每个分类列转换为一组虚拟列。通过虚拟列，每个分类列将被转换为
    `n` 列，其中 `n` 是该类别中唯一值的数量。列的值将是 `0` 或 `1`，具体取决于分类列的值。
- en: 'This is achieved with the `get_dummies` function. If we need any help understanding
    this function, we can use the `help` function or any function:'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这可以通过 `get_dummies` 函数实现。如果我们需要任何关于这个函数的帮助，可以使用 `help` 函数或其他任何函数：
- en: '[PRE20]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图展示了前面代码的输出结果：
- en: '![Figure 1.12: The output of the help command being applied to the pd.get_dummies
    function'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.12: 对 pd.get_dummies 函数应用 help 命令后的输出结果'
- en: '](img/B15777_01_12.jpg)'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_12.jpg)'
- en: 'Figure 1.12: The output of the help command being applied to the pd.get_dummies
    function'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '图 1.12: 对 pd.get_dummies 函数应用 help 命令后的输出结果'
- en: 'Let''s demonstrate how to manipulate categorical columns with the `age` column.
    Again, it is helpful to see the distribution of values, so look at the value counts
    and plot them:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们演示如何操作 `age` 列的分类列。同样，查看值的分布是很有帮助的，因此可以查看值的计数并绘制图表：
- en: '[PRE21]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图展示了前面代码的输出结果：
- en: '![Figure 1.13: A plot of the distribution of values of the age column'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.13: 年龄列值分布的图示'
- en: '](img/B15777_01_13.jpg)'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_13.jpg)'
- en: 'Figure 1.13: A plot of the distribution of values of the age column'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '图 1.13: 年龄列值分布的图示'
- en: 'Call the `get_dummies` function on the `VisitorType` column and take a look
    at the rows alongside the original:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对 `VisitorType` 列调用 `get_dummies` 函数，并查看原始列旁边的行：
- en: '[PRE22]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图展示了前面代码的输出结果：
- en: '![Figure 1.14: Dummy columns from the VisitorType column'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.14: 来自 VisitorType 列的虚拟列'
- en: '](img/B15777_01_14.jpg)'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_14.jpg)'
- en: 'Figure 1.14: Dummy columns from the VisitorType column'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.14：来自 VisitorType 列的虚拟列
- en: Here, we can see that, in each of the rows, there can be one value of `1`, which
    is in the column corresponding to the value in the `VisitorType` column.
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到，在每一行中，只有一个值为 `1`，它出现在与 `VisitorType` 列中值对应的列中。
- en: In fact, when using dummy columns, there is some redundant information. Because
    we know there are three values, if two of the values in the dummy columns are
    `0` for a particular row, then the remaining column must be equal to `1`. It is
    important to eliminate any redundancy and correlations in features as it becomes
    difficult to determine which feature is the most important in minimizing the total
    error.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实际上，使用虚拟列时，有一些冗余信息。因为我们知道有三个值，如果某一行的两个虚拟列的值为 `0`，那么剩下的列的值一定为 `1`。去除特征中的任何冗余和相关性非常重要，因为这样会导致难以确定哪个特征对于最小化总误差最为重要。
- en: 'To remove the interdependency, drop the `VisitorType_Other` column because
    it occurs with the lowest frequency:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了消除相互依赖性，删除 `VisitorType_Other` 列，因为它的出现频率最低：
- en: '[PRE23]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: In the `drop` function, the `inplace` argument will apply the function in place,
    so a new variable does not have to be declared.
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 `drop` 函数中，`inplace` 参数会就地应用函数，因此不需要声明新变量。
- en: 'Looking at the first few rows, we can see what remains of our dummy columns
    for the original `VisitorType` column:'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 看一下前几行，我们可以看到原始 `VisitorType` 列的虚拟列剩余部分：
- en: '![Figure 1.15: Final dummy columns from the VisitorType column'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.15：来自 VisitorType 列的最终虚拟列'
- en: '](img/B15777_01_15.jpg)'
  id: totrans-168
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_15.jpg)'
- en: 'Figure 1.15: Final dummy columns from the VisitorType column'
  id: totrans-169
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.15：来自 VisitorType 列的最终虚拟列
- en: 'Finally, add these dummy columns to the original feature data by concatenating
    the two DataFrames column-wise and dropping the original column:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，通过按列拼接两个数据框，将这些虚拟列添加到原始特征数据中，并删除原始列：
- en: '[PRE24]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Repeat the exact same steps with the remaining categorical column, `Month`.
    First, examine the distribution of column values, which is an optional step. Second,
    create dummy columns. Third, drop one of the columns to remove redundancy. Fourth,
    concatenate the dummy columns into a feature dataset. Finally, drop the original
    column if it remains in the dataset. You can do this using the following code:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对剩下的分类列 `Month` 重复相同的步骤。首先，检查列值的分布，这是一个可选步骤。其次，创建虚拟列。第三，删除其中一个列以去除冗余。第四，将虚拟列拼接成特征数据集。最后，如果原始列仍然保留在数据集中，则删除它。你可以使用以下代码做到这一点：
- en: '[PRE25]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now, we should have our entire dataset as numerical columns. Check the types
    of each column to verify this:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们应该已经将整个数据集转换为数值列。检查每一列的数据类型以验证这一点：
- en: '[PRE26]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-176
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图展示了前面代码的输出：
- en: '![Figure 1.16: The datatypes of the processed feature dataset'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.16：处理后的特征数据集的数据类型'
- en: '](img/B15777_01_16.jpg)'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_16.jpg)'
- en: 'Figure 1.16: The datatypes of the processed feature dataset'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.16：处理后的特征数据集的数据类型
- en: 'Now that we have verified the datatypes, we have a dataset we can use to train
    a model, so let''s save this for later:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们已经验证了数据类型，我们有一个可以用来训练模型的数据集，所以让我们稍后保存它：
- en: '[PRE27]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let''s do the same for the `target` variable. First, load the data in, convert
    the column into a numerical datatype, and save the column as a CSV file:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们对 `target` 变量也做同样的操作。首先，加载数据，转换列为数值数据类型，并将该列保存为 CSV 文件：
- en: '[PRE28]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图展示了前面代码的输出：
- en: '![Figure 1.17: First 10 rows of the target dataset'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.17：目标数据集的前 10 行'
- en: '](img/B15777_01_17.jpg)'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_17.jpg)'
- en: 'Figure 1.17: First 10 rows of the target dataset'
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.17：目标数据集的前 10 行
- en: Here, we can see that this is a `Boolean` datatype and that there are two unique values.
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到这是一个 `Boolean` 数据类型，并且有两个唯一值。
- en: 'Convert this into a binary numerical column, much like we did with the binary
    columns in the feature dataset:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其转换为二进制数值列，就像我们在特征数据集中处理二进制列一样：
- en: '[PRE29]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-191
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图展示了前面代码的输出：
- en: '![Figure 1.18: First 10 rows of the target dataset when converted into integers'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.18：目标数据集的前 10 行在转换为整数时的情况'
- en: '](img/B15777_01_18.jpg)'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_18.jpg)'
- en: 'Figure 1.18: First 10 rows of the target dataset when converted into integers'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.18：目标数据集的前 10 行在转换为整数时的情况
- en: 'Finally, save the target dataset to a CSV file:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，将目标数据集保存为 CSV 文件：
- en: '[PRE30]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In this exercise, we learned how to clean the data appropriately so that it
    can be used to train models. We converted the non-numerical datatypes into numerical
    datatypes; that is, we converted all the columns in the feature dataset into numerical
    columns. Lastly, we saved the target dataset as a CSV file so that we can use
    it in the following exercises and activities.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们学习了如何适当清洗数据，以便用它来训练模型。我们将非数值数据类型转换为数值数据类型；也就是说，我们将特征数据集中的所有列转换为数值列。最后，我们将目标数据集保存为CSV文件，以便在接下来的练习和活动中使用。
- en: Note
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2YW1DVi](https://packt.live/2YW1DVi).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/2YW1DVi](https://packt.live/2YW1DVi)。
- en: You can also run this example online at [https://packt.live/2BpO4EI](https://packt.live/2BpO4EI).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在线运行此示例，网址是[https://packt.live/2BpO4EI](https://packt.live/2BpO4EI)。
- en: Appropriate Representation of the Data
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据的适当表示
- en: In our online shoppers purchase intention dataset, we have some columns that
    are defined as numerical variables when, upon closer inspection, they are actually
    categorical variables that have been given numerical labels. These columns are
    `OperatingSystems`, `Browser`, `TrafficType`, and `Region`. Currently, we have
    treated them as numerical variables, though they are categorical, which should
    be encoded into the features if we want the models we build to learn the relationships
    between the features and the target.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的在线购物者购买意图数据集中，有些列被定义为数值变量，但仔细观察后发现，它们实际上是已经被赋予数值标签的分类变量。这些列包括`OperatingSystems`、`Browser`、`TrafficType`和`Region`。目前，我们将它们当作数值变量处理，尽管它们应该是分类变量。如果我们希望构建的模型能学习特征和目标之间的关系，这些分类变量应该被编码为特征。
- en: We do this because we may be encoding some misleading relationships in the features.
    For example, if the value of the `OperatingSystems` field is equal to `2`, does
    that mean it is twice the value as that which has the value `1`? Probably not,
    since it refers to the operating system. For this reason, we will convert the
    field into a categorical variable. The same may be applied to the `Browser`, `TrafficType`,
    and `Region` columns.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这么做是因为我们可能会在特征中编码一些误导性关系。例如，如果`OperatingSystems`字段的值为`2`，这是否意味着它是值为`1`的两倍？可能不是，因为它指的是操作系统。基于这个原因，我们将把该字段转换为分类变量。同样的处理也适用于`Browser`、`TrafficType`和`Region`列。
- en: 'Exercise 1.03: Appropriate Representation of the Data'
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 1.03：数据的适当表示
- en: 'In this exercise, we will convert the `OperatingSystems`, `Browser`, `TrafficType`,
    and `Region` columns into categorical types to accurately reflect the information.
    To do this, we will create dummy variables from the column in a similar manner
    to what we did in *Exercise 1.02*, *Cleaning the Data*. To do so, perform the
    following steps:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将把`OperatingSystems`、`Browser`、`TrafficType`和`Region`列转换为分类类型，以准确反映信息。为此，我们将像在*练习
    1.02*《*清洗数据*》中那样，从这些列创建虚拟变量。具体步骤如下：
- en: Open a Jupyter Notebook.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个Jupyter Notebook。
- en: 'Load the dataset into memory. We can use the same feature dataset that was
    the output from *Exercise 1.02*, *Cleaning the Data*, which contains the original
    numerical versions of the `OperatingSystems`, `Browser`, `TrafficType`, and `Region`
    columns:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据集加载到内存中。我们可以使用*练习 1.02*《*清洗数据*》中的输出数据集，该数据集包含`OperatingSystems`、`Browser`、`TrafficType`和`Region`列的原始数值版本：
- en: '[PRE31]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Look at the distribution of values in the `OperatingSystems` column:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看`OperatingSystems`列中的值分布：
- en: '[PRE32]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图显示了前面代码的输出：
- en: '![Figure 1.19: The distribution of values in the OperatingSystems column'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.19：操作系统列中值的分布'
- en: '](img/B15777_01_19.jpg)'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_19.jpg)'
- en: 'Figure 1.19: The distribution of values in the OperatingSystems column'
  id: totrans-214
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.19：操作系统列中值的分布
- en: 'Create dummy variables from the `OperatingSystem` column:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`OperatingSystem`列创建虚拟变量：
- en: '[PRE33]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Drop the dummy variable representing the value with the lowest occurring frequency
    and join back with the original data:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除表示出现频率最低的值的虚拟变量，并与原始数据合并：
- en: '[PRE34]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Repeat this for the `Browser` column:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对`Browser`列重复此操作：
- en: '[PRE35]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图显示了前面代码的输出：
- en: '![Figure 1.20: The distribution of values in the Browser column'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.20：浏览器列中值的分布'
- en: '](img/B15777_01_20.jpg)'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_20.jpg)'
- en: 'Figure 1.20: The distribution of values in the Browser column'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.20：浏览器列中值的分布
- en: 'Create dummy variables, drop the dummy variable with the lowest occurring frequency,
    and join back with the original data:'
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建虚拟变量，删除出现频率最低的虚拟变量，并将其与原始数据连接：
- en: '[PRE36]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Repeat this for the `TrafficType` and `Region` columns:'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对`TrafficType`和`Region`列重复此操作：
- en: '[PRE37]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Check the column types to verify they are all numerical:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查列类型，验证它们是否全部为数值型：
- en: '[PRE38]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图表显示了前面代码的输出：
- en: '![Figure 1.21: The datatypes of the processed feature dataset'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.21：处理后特征数据集的数据类型'
- en: '](img/B15777_01_21.jpg)'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_21.jpg)'
- en: 'Figure 1.21: The datatypes of the processed feature dataset'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.21：处理后特征数据集的数据类型
- en: 'Finally, save the dataset to a CSV file for later use:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，将数据集保存为CSV文件以便后续使用：
- en: '[PRE39]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Now, we can accurately test whether the browser type, operating system, traffic
    type, or region will affect the target variable. This exercise has demonstrated
    how to appropriately represent data for use in machine learning algorithms. We
    have presented some techniques that we can use to convert data into numerical
    datatypes that cover many situations that may be encountered when working with
    tabular data.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以准确地测试浏览器类型、操作系统、流量类型或地区是否会影响目标变量。这个练习展示了如何正确地表示数据，以便在机器学习算法中使用。我们介绍了一些技术，可以将数据转换为数值型数据类型，这些技术覆盖了处理表格数据时可能遇到的多种情况。
- en: Note
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/3dXOTBy](https://packt.live/3dXOTBy).
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考[https://packt.live/3dXOTBy](https://packt.live/3dXOTBy)。
- en: You can also run this example online at [https://packt.live/3iBvDxw](https://packt.live/3iBvDxw).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在[https://packt.live/3iBvDxw](https://packt.live/3iBvDxw)上在线运行此示例。
- en: Life Cycle of Model Creation
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型创建的生命周期
- en: In this section, we will cover the life cycle of creating performant machine
    learning models, from engineering features to fitting models to training data,
    and evaluating our models using various metrics. The following diagram demonstrates
    the iterative process of building machine learning models. Features are engineered
    that represent potential correlations between the features and the target, the
    model is fit, and then models are evaluated.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍创建高效机器学习模型的生命周期，从特征工程到拟合模型，再到训练数据，并使用各种评估指标评估模型。以下图表展示了构建机器学习模型的迭代过程。我们通过工程化特征来表示特征与目标之间的潜在关联，之后拟合模型，并对模型进行评估。
- en: 'Depending on how the model is scored according to the model''s evaluation metrics,
    the features are engineered further, and the process continues. Many of the steps
    that are implemented to create models are highly transferable between all machine
    learning libraries. We''ll start with scikit-learn, which has the advantage of
    being widely used, and as such, there is a lot of documentation, tutorials, and
    learning materials to be found across the internet:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 根据模型评分标准和评估指标的不同，特征会进一步工程化，整个过程不断重复。许多用于创建模型的步骤在所有机器学习库之间都是高度可转移的。我们将从广泛使用的scikit-learn开始，它有一个优点就是互联网上有大量的文档、教程和学习资料：
- en: '![Figure 1.22: The life cycle of model creation'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.22：模型创建的生命周期'
- en: '](img/B15777_01_22.jpg)'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_22.jpg)'
- en: 'Figure 1.22: The life cycle of model creation'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.22：模型创建的生命周期
- en: Machine Learning Libraries
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习库
- en: While this book is an introduction to deep learning with Keras, as we mentioned
    earlier, we will start by utilizing scikit-learn. This will help us establish
    the fundamentals of building a machine learning model using the Python programming language.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然本书是Keras深度学习的入门书籍，但正如我们之前提到的，我们将首先使用scikit-learn。这将帮助我们建立使用Python编程语言构建机器学习模型的基础。
- en: Similar to scikit-learn, Keras makes it easy to create models in the Python
    programming language through an easy-to-use API. However, the goal of Keras is
    the creation and training of neural networks, rather than machine learning models
    in general. ANNs represent a large class of machine learning algorithms, and they
    are so-called because their architecture resembles the neurons in the human brain.
    The Keras library has many general-purpose functions built-in, such as `optimizers`,
    `activation functions`, and `layer properties`, so that users, like in scikit-learn,
    do not have to code these algorithms from scratch.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 与 scikit-learn 类似，Keras 通过易于使用的 API 使得在 Python 编程语言中创建模型变得简单。然而，Keras 的目标是创建和训练神经网络，而不是一般的机器学习模型。人工神经网络（ANNs）代表了一个大型的机器学习算法类别，它们之所以被称为“神经网络”，是因为它们的架构类似于人类大脑中的神经元。Keras
    库内置了许多通用功能，如 `优化器`、`激活函数` 和 `层属性`，使得用户像在 scikit-learn 中一样，不必从零开始编写这些算法。
- en: scikit-learn
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: scikit-learn
- en: Scikit-learn was initially created by David Cournapeau in 2007 as a way to easily
    create machine learning models in the Python programming language. Since its inception,
    the library has grown immensely in popularity because of its ease of use, wide
    adoption within the machine learning community, and flexibility of use. scikit-learn
    is usually the first machine learning package that's implemented by practitioners
    using Python because of the large number of algorithms available for `classification`,
    `regression`, and `clustering` tasks and the speed with which results can be obtained.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn 最初是由 David Cournapeau 于 2007 年创建的，目的是为了在 Python 编程语言中轻松创建机器学习模型。自从它问世以来，这个库因为易用性、在机器学习社区的广泛采用以及灵活性而迅速获得了巨大的流行。因为提供了大量的
    `分类`、`回归` 和 `聚类` 算法，并且能够快速获得结果，scikit-learn 通常是使用 Python 的从业者首先实现的机器学习包。
- en: For example, scikit-learn's `LinearRegression` class is an excellent choice
    if you wish to quickly train a simple regression model, whereas if a more complex
    algorithm is required that's capable of learning nonlinear relationships, scikit-learn's
    `GradientBoostingRegressor` or any one of the `support vector machine` algorithms
    are great choices. Likewise, with classification or clustering tasks, scikit-learn
    offers a wide variety of algorithms to choose from.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你希望快速训练一个简单的回归模型，scikit-learn 的 `LinearRegression` 类是一个优秀的选择，而如果需要一个更复杂的算法来学习非线性关系，scikit-learn
    的 `GradientBoostingRegressor` 或任何一种 `支持向量机` 算法都是很好的选择。同样，对于分类或聚类任务，scikit-learn
    提供了多种算法供你选择。
- en: The following are a few of the advantages and disadvantages of using scikit-learn
    for machine learning purposes.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用 scikit-learn 进行机器学习时的一些优缺点：
- en: 'The advantages of scikit-learn are as follows:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn 的优点如下：
- en: '**Mature**: Scikit-learn is well-established within the community and used
    by members of the community of all skill levels. The package includes most of
    the common machine learning algorithms for classification, regression, and clustering
    tasks.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成熟**：Scikit-learn 在社区中已经得到了很好的建立，社区内各个技能层次的成员都在使用该包。该包包括了大部分常见的机器学习算法，适用于分类、回归和聚类任务。'
- en: '**User-friendly**: Scikit-learn features an easy-to-use API that allows beginners
    to efficiently prototype without having to have a deep understanding or having
    to code each specific mode.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户友好**：Scikit-learn 具有易于使用的 API，使得初学者能够高效地进行原型设计，而无需深入理解或编写每个特定模型的代码。'
- en: '**Open source**: There is an active open source community working to improve
    the library, add documentation, and release regular updates, which ensures that
    the package is stable and up to date.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开源**：有一个活跃的开源社区致力于改进这个库，添加文档并发布定期更新，这确保了包的稳定性和最新状态。'
- en: 'The disadvantage of scikit-learn is as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: Scikit-learn 的缺点如下：
- en: '**Neural network support is lacking**: Estimators with ANN algorithms are minimal.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '**缺乏神经网络支持**：具有 ANN 算法的估计器非常少。'
- en: Note
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find all the documentation for the scikit-learn library here: [https://scikit-learn.org/stable/documentation.html](https://scikit-learn.org/stable/documentation.html).'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到 scikit-learn 库的所有文档：[https://scikit-learn.org/stable/documentation.html](https://scikit-learn.org/stable/documentation.html)。
- en: The estimators in scikit-learn can generally be classified into supervised learning
    and unsupervised learning techniques. Supervised learning occurs when a `target`
    variable is present. A `target` variable is a variable of the dataset that you
    are trying to predict, given the other variables. `Supervised learning` requires
    the target variable to be known and models are trained to correctly predict this
    variable. `Binary classification` using `logistic regression` is a good example
    of a supervised learning technique.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn中的估计器通常可以分为监督学习和无监督学习技术。监督学习发生在存在`目标`变量时。`目标`变量是你试图预测的数据集中的变量，前提是其他变量已知。`监督学习`要求目标变量已知，并且模型需要训练以正确预测该变量。使用`逻辑回归`进行的`二分类`是监督学习技术的一个典型例子。
- en: In `unsupervised learning`, no target variable is given in the training data,
    but models aim to assign a target variable. An example of an unsupervised learning
    technique is k-means clustering. This algorithm partitions data into a given number
    of clusters based on its proximity to neighboring data points. The `target` variable
    that's assigned may be either the cluster number or cluster center.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在`无监督学习`中，训练数据中没有给定目标变量，但模型的目标是分配一个目标变量。k-means聚类是无监督学习技术的一个例子。该算法根据数据点之间的邻近关系，将数据划分为指定数量的聚类。分配的`目标`变量可能是聚类编号或聚类中心。
- en: An example of utilizing a clustering example in practice may look as follows.
    Imagine that you are a jacket manufacturer and your goal is to develop dimensions
    for various jacket sizes. You cannot create a custom-fit jacket for each customer,
    so one option you have to determine the dimensions for jackets is to sample the
    population of customers for various parameters that may be correlated to fit,
    such as height and weight. Then, you can group the population into clusters using
    scikit-learn's `k-means clustering` algorithm with a cluster number that matches
    the number of jacket sizes you wish to produce. The cluster-centers that are created
    from the clustering algorithm become the parameters that the jacket sizes are
    based on.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中使用聚类示例的一个例子可能如下所示。假设你是一个夹克制造商，目标是为各种夹克尺码开发尺寸。你无法为每个客户定制夹克，因此，你可以选择通过样本调查顾客群体，收集与合身相关的各种参数，如身高和体重。然后，你可以使用scikit-learn的`k-means聚类`算法，根据你希望生产的夹克尺码的数量，来将顾客群体划分为相应数量的聚类。由聚类算法创建的聚类中心将成为夹克尺码的参数基础。
- en: 'This is visualized in the following figure:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示：
- en: '![Figure 1.23: An unsupervised learning example of grouping customer parameters
    into clusters'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.23：一个无监督学习的示例，将客户参数分组到不同的聚类中'
- en: '](img/B15777_01_23.jpg)'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_23.jpg)'
- en: 'Figure 1.23: An unsupervised learning example of grouping customer parameters
    into clusters'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.23：一个无监督学习的示例，将客户参数分组到不同的聚类中
- en: There are even `semi-supervised learning` techniques in which unlabeled data
    is used in the training of machine learning models. This technique may be used
    if there is only a small amount of labeled data and a copious amount of unlabeled
    data. In practice, semi-supervised learning produces a significant improvement
    in model performance compared to unsupervised learning.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 甚至还有`半监督学习`技术，其中未标记的数据用于机器学习模型的训练。如果只有少量标记数据，而未标记数据量很大，那么可以使用这种技术。在实践中，半监督学习相较于无监督学习，能够显著提高模型性能。
- en: The scikit-learn library is ideal for beginners as the general concepts for
    building machine learning pipelines can be learned easily. Concepts such as data
    preprocessing (the preparation of data for use in machine learning models), hyperparameter
    tuning (the process of selecting the appropriate model parameters), model evaluation
    (the quantitative evaluation of a model's performance), and many more are all
    included in the library. Even experienced users find the library easy to use in
    order to rapidly prototype models before using a more specialized machine learning
    library.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: scikit-learn库非常适合初学者，因为构建机器学习管道的一般概念可以轻松学习。诸如数据预处理（为机器学习模型准备数据）、超参数调优（选择适当的模型参数的过程）、模型评估（模型性能的定量评估）等概念都包含在该库中。即使是经验丰富的用户，也能轻松使用该库快速原型化模型，然后再使用更专业的机器学习库。
- en: Indeed, the various machine learning techniques we've discussed, such as supervised
    and unsupervised learning, can be applied with Keras using neural networks with
    different architectures, all of which will be discussed throughout this book.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，我们讨论过的各种机器学习技术，如监督学习和无监督学习，都可以通过 Keras 使用不同架构的神经网络进行应用，这些内容将在本书中详细讲解。
- en: Keras
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Keras
- en: Keras is designed to be a high-level neural network API that is built on top
    of frameworks such as TensorFlow, CNTK, and Theano. One of the great benefits
    of using Keras as an introduction to deep learning for beginners is that it is
    very user-friendly; advanced functions such as optimizers and layers are already
    built into the library and do not have to be written from scratch. This is why
    Keras is popular not only among beginners but also seasoned experts. Also, the
    library allows the rapid prototyping of neural networks, supports a wide variety
    of network architectures, and can be run on both CPUs and GPUs.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 被设计为一个高层次的神经网络 API，构建在 TensorFlow、CNTK 和 Theano 等框架之上。使用 Keras 作为深度学习入门的一个大好处是它非常用户友好；如优化器和层等高级功能已经内置在库中，无需从零开始编写。因此，Keras
    不仅在初学者中受欢迎，在资深专家中也同样广泛使用。此外，该库支持神经网络的快速原型设计，支持多种网络架构，并且可以在 CPU 和 GPU 上运行。
- en: Note
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can find the library and all the documentation for Keras here: [https://Keras.io/](https://Keras.io/).'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到 Keras 库和所有文档：[https://Keras.io/](https://Keras.io/)。
- en: Keras is used to create and train neural networks and does not offer much in
    terms of other machine learning algorithms, including supervised algorithms such
    as support vector machines and unsupervised algorithms such as `k-means clustering`.
    What Keras does offer, though, is a well-designed API that can be used to create
    and train neural networks, which takes away much of the effort that's required
    to apply linear algebra and multivariate calculus accurately.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 用于创建和训练神经网络，在其他机器学习算法方面提供的功能较少，包括监督学习算法（如支持向量机）和无监督学习算法（如 `k-means 聚类`）。然而，Keras
    提供了一个设计良好的 API，用于创建和训练神经网络，这大大减少了准确应用线性代数和多变量微积分所需的工作量。
- en: The specific modules that are available from the Keras library, such as `neural
    layers`, `cost functions`, `optimizers`, `initialization schemes`, `activation
    functions`, and `regularization schemes`, will be explained thoroughly throughout
    this book. All these modules have relevant functions that can be used to optimize
    performance for training neural networks for specific tasks.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 本书将全面讲解 Keras 库中可用的特定模块，如 `神经层`、`代价函数`、`优化器`、`初始化方案`、`激活函数` 和 `正则化方案`。所有这些模块都有相关的功能，可以用来优化训练神经网络以执行特定任务的性能。
- en: Advantages of Keras
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Keras 的优势
- en: 'Here are a few of the main advantages of using Keras for machine learning purposes:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用 Keras 进行机器学习的一些主要优势：
- en: '**User-friendly**: Much like scikit-learn, Keras features an easy-to-use API
    that allows users to focus on model-building rather than the specifics of the algorithms.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户友好**：与 scikit-learn 类似，Keras 具有易于使用的 API，允许用户专注于模型构建，而非算法的具体细节。'
- en: '**Modular**: The API consists of fully configurable modules that can all be
    plugged together and work seamlessly.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模块化**：API 由完全可配置的模块组成，这些模块可以无缝连接并一起工作。'
- en: '**Extensible**: It is relatively simple to add new modules to the library.
    This allows users to take advantage of the many robust modules within the library
    while providing them the flexibility to create their own.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展**：向库中添加新模块相对简单。这使得用户可以充分利用库中的许多强大模块，同时为他们提供创建自定义模块的灵活性。'
- en: '**Open source**: Keras is an open source library and is constantly improving
    and adding modules to its code base thanks to the work of many collaborators working
    in conjunction to build improvements and help create a robust library for all.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开源**：Keras 是一个开源库，并且由于许多合作开发者的共同努力，Keras 的代码库不断改进和增加模块，从而帮助构建一个强大的库供所有人使用。'
- en: '**Works with Python**: Keras models are declared directly in Python rather
    than in separate configuration files, which allows Keras to take advantage of
    working with Python, such as ease of debugging and extensibility.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与 Python 兼容**：Keras 模型直接在 Python 中声明，而不是在单独的配置文件中，这使得 Keras 能够充分利用 Python
    的优势，比如调试和扩展性。'
- en: Disadvantages of Keras
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Keras 的缺点
- en: 'Here are a few of the main disadvantages of using Keras for machine learning purposes:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用 Keras 进行机器学习的一些主要缺点：
- en: '**Advanced customization**: While simple surface-level customization such as
    creating simple custom loss functions or neural layers is facile, it can be difficult
    to change how the underlying architecture works.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高级自定义**：虽然像创建简单的自定义损失函数或神经网络层这样的表面级自定义是容易的，但改变底层架构的工作方式可能会很困难。'
- en: '**Lack of examples**: Beginners often rely on examples to kick-start their
    learning. Advanced examples can be lacking in the Keras documentation, which can
    prevent beginners from advancing in their learning.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缺乏示例**：初学者通常依赖示例来启动他们的学习。在 Keras 文档中，高级示例可能缺乏，这可能会阻碍初学者的学习进展。'
- en: Keras offers those familiar with the Python programming language and machine
    learning the ability to create neural network architectures easily. Since neural
    networks are quite complicated, we will use scikit-learn to introduce many machine
    learning concepts before applying them to the Keras library.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 为熟悉 Python 编程语言和机器学习的人提供了轻松创建神经网络架构的能力。由于神经网络相当复杂，我们将在使用 Keras 库之前，先通过
    scikit-learn 引入许多机器学习概念。
- en: More Than Building Models
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不仅仅是构建模型
- en: 'While machine learning libraries such as scikit-learn and Keras were created
    to help build and train predictive models, their practicality extends much further.
    One common use case of building models is that they can be utilized to perform
    predictions on new data. Once a model has been trained, new observations can be
    fed into the model to generate predictions. Models may even be used as intermediate
    steps. For example, neural network models can be used as `feature extractors`,
    classifying objects in an image that can then be fed into a subsequent model,
    as illustrated in the following image:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管像 scikit-learn 和 Keras 这样的机器学习库是为了帮助构建和训练预测模型而创建的，但它们的实用性远不止于此。构建模型的一个常见用途是可以用它们对新数据进行预测。一旦模型训练完成，就可以将新的观察数据输入模型，从而生成预测结果。模型甚至可以作为中间步骤使用。例如，神经网络模型可以用作`特征提取器`，对图像中的物体进行分类，然后将其输入到后续模型中，如下图所示：
- en: '![Figure 1.24: Classifying objects using deep learning'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.24：使用深度学习进行物体分类'
- en: '](img/B15777_01_24.jpg)'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_24.jpg)'
- en: 'Figure 1.24: Classifying objects using deep learning'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.24：使用深度学习进行物体分类
- en: 'Another common use case for models is that they can be used to summarize datasets
    by learning representations of the data. Such models are known as auto-encoders,
    a type of neural network architecture that can be used to learn such representations
    of a given dataset. Therefore, the dataset can thus be represented in a reduced
    dimension with minimal loss of information:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的模型使用案例是，模型可以通过学习数据的表示来总结数据集。这类模型被称为自编码器，是一种神经网络架构，可以用于学习给定数据集的表示。因此，数据集可以在减少维度的同时，尽量减少信息损失：
- en: '![Figure 1.25: An example of using deep learning for text summarization'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.25：使用深度学习进行文本摘要的示例'
- en: '](img/B15777_01_25.jpg)'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_25.jpg)'
- en: 'Figure 1.25: An example of using deep learning for text summarization'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.25：使用深度学习进行文本摘要的示例
- en: Model Training
  id: totrans-299
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型训练
- en: In this section, we will begin fitting our model to the datasets that we have
    created. In this chapter, we will review the minimum steps that are required to
    create a machine learning model that can be applied when building models with
    any machine learning library, including scikit-learn and Keras.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将开始将模型拟合到我们创建的数据集上。在本章中，我们将回顾在使用任何机器学习库（包括 scikit-learn 和 Keras）构建模型时，创建机器学习模型所需的最小步骤。
- en: Classifiers and Regression Models
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类器和回归模型
- en: This book is concerned with applications of deep learning. The vast majority
    of deep learning tasks are supervised learning, in which there is a given target,
    and we want to fit a model so that we can understand the relationship between
    the features and the target.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 本书关注的是深度学习的应用。绝大多数深度学习任务都是监督学习，其中有一个给定的目标，我们希望拟合一个模型，以便理解特征与目标之间的关系。
- en: 'An example of supervised learning is identifying whether a picture contains
    a `dog` or a `cat`. We want to determine the relationship between the `input`
    (a matrix of pixel values) and the `target` variable, that is, whether the image
    is of a `dog` or a `cat`:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的一个例子是识别一张图片是否包含`狗`或`猫`。我们想要确定`输入`（像素值矩阵）与`目标`变量之间的关系，也就是说，图像是`狗`还是`猫`：
- en: '![Figure 1.26: A simple supervised learning task to classify images as dogs
    and cats'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.26：一个简单的监督学习任务，将图像分类为狗和猫'
- en: '](img/B15777_01_26.jpg)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_26.jpg)'
- en: 'Figure 1.26: A simple supervised learning task to classify images as dogs and
    cats'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.26：一个简单的监督学习任务，用于将图像分类为狗和猫
- en: Of course, we may need many more images in our training dataset to robustly
    classify new images, but models that are trained on such a dataset are able to
    identify the various relationships that differentiate cats and dogs, which can
    then be used to predict labels for new data.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们可能需要更多的图像作为训练数据集，以便更稳健地对新图像进行分类，但在这样的数据集上训练的模型能够识别出区分猫和狗的各种关系，从而用于预测新数据的标签。
- en: '**Supervised learning models** are generally used for either classification
    or regression tasks.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '**监督学习模型**通常用于分类或回归任务。'
- en: Classification Tasks
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类任务
- en: The goal of classification tasks is to fit models from data with discrete categories
    that can be used to label `unlabeled data`. For example, these types of models
    can be used to classify images as dogs or cats. But it doesn't stop at binary
    classification; multi-label classification is also possible. Another example of
    how this may be a `classification` task would be to predict the existence of dogs
    within the images. A positive prediction would indicate the presence of dogs within
    the images, while a negative prediction would indicate no presence of dogs. Note
    that this could easily be converted into a `regression` task, that is, the estimation
    of a continuous variable as opposed to a discrete variable, which classification
    tasks estimate, by predicting the number of dogs within the images.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 分类任务的目标是从具有离散类别的数据中拟合模型，并用于标记`无标签数据`。例如，这类模型可以用于将图像分类为狗或猫。但分类并不限于二分类；多标签分类也是可能的。另一个可能是`分类`任务的例子是预测图像中是否存在狗。正向预测表示图像中存在狗，而负向预测表示图像中没有狗。注意，这可以很容易地转化为`回归`任务，即预测一个连续变量，而不是分类任务估计的离散变量，例如预测图像中狗的数量。
- en: 'Most classification tasks output a probability for each unique class. This
    prediction is determined as the class with the highest probability, as can be
    seen in the following figure:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数分类任务会为每个独特类别输出一个概率。这个预测由具有最高概率的类别决定，如下图所示：
- en: '![Figure 1.27: An illustration of a classification model labeling an image'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.27：分类模型标记图像的示意图'
- en: '](img/B15777_01_27.jpg)'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_27.jpg)'
- en: 'Figure 1.27: An illustration of a classification model labeling an image'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.27：分类模型标记图像的示意图
- en: 'Some of the most common classification algorithms are as follows:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些最常见的分类算法：
- en: '**Logistic regression**: This algorithm is similar to linear regression, in
    which feature coefficients are learned and predictions are made by taking the
    sum of the product of the feature coefficients and features.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逻辑回归**：该算法类似于线性回归，在此过程中学习特征系数，通过特征系数与特征的乘积求和来进行预测。'
- en: '**Decision trees**: This algorithm follows a tree-like structure. Decisions
    are made at each node and branches represent possible options at the node, terminating
    in the predicted result.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策树**：该算法遵循树状结构。在每个节点上做出决策，分支代表节点上的可能选项，最终得到预测结果。'
- en: '**ANNs**: ANNs replicate the structure and performance of a biological neural
    network to perform pattern recognition tasks. An ANN consists of interconnected
    neurons, laid out with a set architecture, that pass information to each other
    until a result is achieved.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工神经网络（ANNs）**：人工神经网络模仿生物神经网络的结构和性能，用于执行模式识别任务。ANN由互联的神经元组成，按照一定的架构排列，神经元之间传递信息，直到得出结果。'
- en: Regression Tasks
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回归任务
- en: While the aim of `classification` tasks is to label datasets with discrete variables,
    the aim of `regression` tasks is to provide input data with continuous variables
    and output a numerical value. For example, if you have a dataset of stock market
    prices, a classification task may predict whether to buy, sell, or hold, whereas
    a regression task will predict what the stock market price will be.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`分类`任务的目的是为数据集贴上离散变量的标签，但`回归`任务的目的是为输入数据提供连续变量，并输出一个数值。例如，如果你有一个股市价格的数据集，分类任务可能预测是否买入、卖出或持有，而回归任务则会预测股市价格。
- en: A simple yet very popular algorithm for regression tasks is linear regression.
    It consists of only one independent feature (`x`), whose relationship with its
    dependent feature (`y`) is linear. Due to its simplicity, it is often overlooked,
    even though it performs very well for simple data problems.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 一种简单但非常流行的回归任务算法是线性回归。它只包含一个独立特征（`x`），其与依赖特征（`y`）的关系是线性的。由于其简单性，它常常被忽视，尽管它对于简单的数据问题表现得非常好。
- en: 'Some of the most common regression algorithms are as follows:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 一些最常见的回归算法如下：
- en: '**Linear regression**: This algorithm learns feature coefficients and predictions
    are made by taking the sum of the product of the feature coefficients and features.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性回归**：该算法通过学习特征系数来进行预测，预测值是特征系数与特征乘积之和。'
- en: '**Support Vector Machines**: This algorithm uses kernels to map input data
    into a multi-dimensional feature space to understand relationships between features
    and the target.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持向量机（SVM）**：该算法使用核函数将输入数据映射到多维特征空间，以理解特征与目标之间的关系。'
- en: '**ANNs**: ANNs replicate the structure and performance of a biological neural
    network to perform pattern recognition tasks. An ANN consists of interconnected
    neurons, laid out with a set architecture, that pass information to each other
    until a result is achieved.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人工神经网络（ANNs）**：人工神经网络模仿生物神经网络的结构和性能，执行模式识别任务。一个ANN由互联的神经元组成，这些神经元按照一定的架构排列，彼此传递信息直到达到结果。'
- en: Training Datasets and Test Datasets
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练数据集和测试数据集
- en: Whenever we create machine learning models, we separate the data into `training`
    and `test` datasets. The training data is the set of data that's used to train
    the model. Typically, it is a large proportion—around `80%`—of the total dataset.
    The test dataset is a sample of the dataset that is held out from the beginning
    and is used to provide an unbiased evaluation of the model. The test dataset should
    represent real-world data as accurately as possible. Any model evaluation metrics
    that are reported should be applied to the test dataset unless it's explicitly
    stated that the metrics have been evaluated on the training dataset. The reason
    for this is that models will typically perform better on the data they are trained
    on.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们创建机器学习模型时，我们会将数据分为`训练`数据集和`测试`数据集。训练数据是用于训练模型的数据集。通常，它占总数据集的很大一部分——大约`80%`。测试数据集是从一开始就被分离出来的样本，用于对模型进行无偏评估。测试数据集应尽可能准确地代表真实世界的数据。任何报告的模型评估指标都应该应用于测试数据集，除非明确说明这些指标是在训练数据集上评估的。原因在于，模型通常在它们所训练的数据上表现得更好。
- en: Furthermore, models can overfit the training dataset, meaning that they perform
    well on the training dataset but perform poorly on the `test` dataset. A model
    is said to be overfitted to the data if the model's performance is very good when
    evaluated on the `training` dataset, but it performs poorly on the `test` dataset.
    Conversely, a model can be underfitted to the data. In this case, the model will
    fail to learn relationships between the `features` and the `target`, which will
    lead to poor performance when evaluated on both the `training` and `test` datasets.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，模型可能会出现过拟合训练数据集的情况，这意味着它在训练数据集上表现良好，但在`测试`数据集上表现差。若模型在评估`训练`数据集时表现非常好，但在`测试`数据集上表现差，则说明模型过拟合了数据。相反，模型也可能出现欠拟合的情况。在这种情况下，模型未能学习`特征`和`目标`之间的关系，这会导致在评估`训练`和`测试`数据集时都表现不佳。
- en: 'We aim for a balance of the two, not relying so heavily on the `training` dataset
    that we overfit but allowing the model to learn the relationships between the
    `features` and the `target` so that the model generalizes well to new data. This
    concept is illustrated in the following figure:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是这两者之间的平衡，既不依赖过多的`训练`数据集以至于出现过拟合，又能让模型学习`特征`和`目标`之间的关系，以便模型能很好地泛化到新数据。这一概念在下图中得到了说明：
- en: '![Figure 1.28: An example of underfitting and overfitting a dataset'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.28：欠拟合和过拟合数据集的示例'
- en: '](img/B15777_01_28.jpg)'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_28.jpg)'
- en: 'Figure 1.28: An example of underfitting and overfitting a dataset'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.28：欠拟合和过拟合数据集的示例
- en: There are many ways to split the dataset via `sampling` methods. One way to
    split a dataset into training is to simply randomly sample the data until you
    have the desired number of data points. This is often the default method in functions
    such as the scikit-learn `train_test_spilt` function.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多通过`抽样`方法来拆分数据集的方式。一种拆分数据集为训练集的方法是简单地随机抽样，直到你得到所需数量的数据点。这通常是像 scikit-learn
    中的`train_test_split`函数的默认方法。
- en: Another method is to stratify the sampling. In stratified sampling, each subpopulation
    is sampled independently. Each subpopulation is determined by the target variable.
    This can be advantageous in examples such as `binary classification`, where the
    target variable is highly skewed toward one value or another, and random sampling
    may not provide data points of both values in the `training` and `test` datasets.
    There are also validation datasets, which we will address later in this chapter.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是进行分层抽样。在分层抽样中，每个子群体都被独立抽样。每个子群体是由目标变量决定的。在像`二分类`这样的例子中，目标变量可能高度偏向某一个值，而随机抽样可能在`训练`和`测试`数据集中没有两个值的数据点。这种方法在某些情况下是有利的。还有验证数据集，我们将在本章稍后讨论。
- en: Model Evaluation Metrics
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型评估指标
- en: It is important to be able to evaluate our models effectively, not just in terms
    of the model's performance but also in the context of the problem we are trying
    to solve. For example, let's say we built a `classification` task to predict whether
    to buy, sell, or hold stock based on historical stock market prices. If our model
    only predicted to buy every time, this would not be a useful result because we
    may not have infinite resources to buy stock. It may be better to be less accurate
    yet also include some sell predictions.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 能够有效评估我们的模型非常重要，这不仅仅是从模型的表现角度来看，还需要结合我们试图解决的问题背景。例如，假设我们建立了一个`分类`任务来预测是否基于历史股市价格购买、出售或持有股票。如果我们的模型每次都预测买入，这将不是一个有用的结果，因为我们可能没有无限的资源来购买股票。或许更好的方法是降低准确度，同时包括一些卖出预测。
- en: 'Common evaluation metrics for `classification` tasks include accuracy, precision,
    recall, and f1 score. `Accuracy` is defined as the number of correct predictions
    divided by the total number of predictions. `Accuracy` is very interpretable and
    relatable and good for when there are balanced classes. When the classes are highly
    skewed, accuracy can be misleading, however:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的`分类`任务评估指标包括准确率、精确度、召回率和 F1 分数。`准确率（Accuracy）`定义为正确预测的数量除以总预测数量。`准确率`非常容易理解并且具有可比性，适用于类别平衡的情况。然而，当类别严重失衡时，准确率可能会误导：
- en: '![Figure 1.29: Formula to calculate accuracy'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.29：计算准确率的公式](img/B15777_01_29.jpg)'
- en: '](img/B15777_01_29.jpg)'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_29.jpg)'
- en: 'Figure 1.29: Formula to calculate accuracy'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.29：计算准确率的公式
- en: '`Precision` is another useful metric. It''s defined as the number of true positive
    results divided by the total number of positive results (true and false) predicted
    by the model:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '`精确度（Precision）`是另一个有用的指标。它被定义为模型预测的正类结果中，真正正类（True Positive）占的比例：'
- en: '![Figure 1.30: Formula to calculate precision'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.30：计算精确度的公式](img/B15777_01_30.jpg)'
- en: '](img/B15777_01_30.jpg)'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_30.jpg)'
- en: 'Figure 1.30: Formula to calculate precision'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.30：计算精确度的公式
- en: '`Recall` is defined as the number of correct positive results divided by all
    the positive results from the ground truth:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '`召回率（Recall）`定义为正确的正类结果占所有真实正类结果的比例：'
- en: '![Figure 1.31: Formula to calculate recall'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.31：计算召回率的公式](img/B15777_01_31.jpg)'
- en: '](img/B15777_01_31.jpg)'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_31.jpg)'
- en: 'Figure 1.31: Formula to calculate recall'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.31：计算召回率的公式
- en: 'Both `precision` and `recall` are scored between `zero` and `one` but scoring
    well on one may mean scoring poorly on the other. For example, a model may have
    high precision but low recall, which indicates that the model is very accurate
    but misses a large number of positive instances. It is useful to have a metric
    that combines recall and precision. Enter the `F1 score`, which determines how
    precise and robust your model is:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '`精确度`和`召回率`的得分在`零`和`一`之间，但在一个指标上得分高可能意味着在另一个指标上得分较低。例如，一个模型可能精确度很高，但召回率很低，这表明该模型非常准确，但遗漏了大量正类实例。因此，结合召回率和精确度的综合指标是非常有用的。这里的`F1
    分数`可以衡量模型的精确性和鲁棒性：'
- en: '![Figure 1.32: Formula to calculate the F1 score'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.32：计算 F1 分数的公式](img/B15777_01_32.jpg)'
- en: '](img/B15777_01_32.jpg)'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_32.jpg)'
- en: 'Figure 1.32: Formula to calculate the F1 score'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.32：计算 F1 分数的公式
- en: When evaluating models, it is helpful to look at a range of different evaluation
    metrics. They will help determine the most appropriate model and evaluate where
    the model is misclassifying predictions.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估模型时，查看一系列不同的评估指标是非常有帮助的。它们有助于确定最合适的模型，并评估模型在预测中的误分类情况。
- en: For example, take a model that helps doctors predict the presence of a rare
    disease in their patients. By predicting a negative result for every instance,
    the model might provide a highly accurate evaluation, but this would not help
    the doctors or patients very much. Instead, examining the `precision` or `recall`
    may be much more informative.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个帮助医生预测患者是否患有罕见疾病的模型。通过对每个实例预测负面结果，模型可能会提供一个高度准确的评估，但这对医生或患者的帮助不大。相反，检查`精确度`或`召回率`可能会提供更多有用的信息。
- en: A high precision model is very picky and will likely ensure that all predictions
    labeled positive are indeed positive. A high recall model is likely to recall
    many of the `true` positive instances, at the cost of incurring many false positives.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 高精度模型非常挑剔，可能会确保所有标记为正的预测结果实际上都是正的。高召回率模型则可能召回许多`true`正例，代价是可能出现许多假阳性。
- en: A `high precision model` is desired when you want to be sure the predictions
    labeled as `true` have a high likelihood of being true. In our example, this may
    be desired if the cost of treating a rare disease or risk of treatment complications
    is high. A `high recall model` is desired if you want to make sure your model
    recalls as many `true` positives as possible. In our example, this may be the
    case if the rare disease is highly contagious and we want to be sure all cases
    of the disease are treated.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 当你希望确保被标记为`true`的预测结果具有较高的真实概率时，应该使用`高精度模型`。在我们的示例中，如果治疗一种罕见疾病的费用很高或治疗并发症的风险很大，那么可能需要这种模型。若希望确保模型能尽可能多地召回`true`正例，则应使用`高召回率模型`。在我们的示例中，如果罕见疾病具有高度传染性，我们希望确保所有病例都得到治疗，那么就需要这种模型。
- en: 'Exercise 1.04: Creating a Simple Model'
  id: totrans-357
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 1.04：创建一个简单的模型
- en: In this exercise, we will create a simple `logistic regression model` from the
    `scikit-learn` package. Then, we will create some model evaluation metrics and
    test the predictions against those model evaluation metrics.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个练习中，我们将从`scikit-learn`包中创建一个简单的`逻辑回归模型`。然后，我们将创建一些模型评估指标，并根据这些评估指标测试预测结果。
- en: 'We should always approach training any machine learning model as an iterative
    approach, beginning with a simple model and using model evaluation metrics to
    evaluate the performance of the models. In this model, our goal is to classify
    the users in the online shoppers purchasing intention dataset into those that
    will purchase during their session and those that will not. Follow these steps
    to complete this exercise:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该始终将训练任何机器学习模型视为一个迭代过程，从一个简单的模型开始，并使用模型评估指标来评估模型的性能。在这个模型中，我们的目标是将在线购物者的购买意图数据集中的用户分类为在会话中会购买的用户和不会购买的用户。请按照以下步骤完成此练习：
- en: 'Load in the data:'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载数据：
- en: '[PRE40]'
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Begin by creating a `test` and `training` dataset. Train the data using the
    `training` dataset and evaluate the performance of the model on the `test` dataset.
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从创建`test`和`training`数据集开始。使用`training`数据集训练模型，并在`test`数据集上评估模型的性能。
- en: 'We will use `test_size = 0.2`, which means that `20%` of the data will be reserved
    for testing, and we will set a number for the `random_state` parameter:'
  id: totrans-363
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将使用`test_size = 0.2`，意味着`20%`的数据将用于测试，并为`random_state`参数设置一个值：
- en: '[PRE41]'
  id: totrans-364
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Print out the `shape` of each DataFrame to verify that the dimensions are correct:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印每个数据框的`shape`以验证维度是否正确：
- en: '[PRE42]'
  id: totrans-366
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The preceding code produces the following output:'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述代码产生如下输出：
- en: '[PRE43]'
  id: totrans-368
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: These dimensions look correct; each of the `target` datasets has a single column,
    the training feature and `target` DataFrames have the same number of rows, the
    same applies to the `test` feature and `target` DataFrames, and the test DataFrames
    are `20%` of the total dataset.
  id: totrans-369
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些维度看起来正确；每个`target`数据集只有一列，训练特征和`target`数据框的行数相同，`test`特征和`target`数据框也是如此，且测试数据框占整个数据集的`20%`。
- en: 'Next, instantiate the model:'
  id: totrans-370
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，实例化模型：
- en: '[PRE44]'
  id: totrans-371
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: While there are many arguments we can add to scikit-learn's logistic regression
    model (such as the type and value of the regularization parameter, the type of
    solver, and the maximum number of iterations for the model to have), we will only
    pass `random_state`.
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 虽然我们可以向scikit-learn的逻辑回归模型添加许多参数（例如正则化参数的类型和值、求解器的类型，以及模型的最大迭代次数），但我们只会传递`random_state`。
- en: 'Then, `fit` the model to the training data:'
  id: totrans-373
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，`fit`模型以适应训练数据：
- en: '[PRE45]'
  id: totrans-374
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'To test the performance of the model, compare the predictions of the model
    with the true values:'
  id: totrans-375
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了测试模型的性能，将模型的预测结果与真实值进行比较：
- en: '[PRE46]'
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'There are many types of model evaluation metrics that we can use. Let''s start
    with the `accuracy`, which is defined as the proportion of predicted values that
    equal the true values:'
  id: totrans-377
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以使用多种类型的模型评估指标。我们先从`accuracy`开始，`accuracy`定义为预测值等于真实值的比例：
- en: '[PRE47]'
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The preceding code produces the following output:'
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码生成了以下输出：
- en: '[PRE48]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Other common evaluation metrics for classification models include `precision`,
    `recall`, and `fscore`. Use the scikit-learn `precison_recall_fscore_support`
    function, which can calculate all three:'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 分类模型的其他常见评估指标包括`precision`、`recall`和`fscore`。使用scikit-learn的`precison_recall_fscore_support`函数，可以计算这三者：
- en: '[PRE49]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Since these metrics are scored between `0` and `1`, the `recall` and `fscore`
    are not as impressive as the `accuracy`, though looking at all of these metrics
    together can help us find where our models are doing well and where they could
    be improved by examining in which observations the model gets predictions incorrect.
  id: totrans-383
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于这些度量值的评分范围是`0`到`1`，`recall`和`fscore`的表现不如`accuracy`，尽管将这些度量值一起考虑可以帮助我们找出模型表现良好的地方，以及通过检查模型在哪些观察值上做出了错误预测，找出可以改进的地方。
- en: 'Look at the coefficients that the model outputs to observe which features have
    a greater impact on the overall result of the prediction:'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查看模型输出的系数，以观察哪些特征对预测结果的整体影响更大：
- en: '[PRE50]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下图显示了前面代码的输出结果：
- en: '![Figure 1.33: The sorted important features of the model with their respective
    coefficients'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图1.33：模型的排序重要特征及其相应的系数](img/B15777_01_33.jpg)'
- en: '](img/B15777_01_33.jpg)'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_33.jpg)'
- en: 'Figure 1.33: The sorted important features of the model with their respective
    coefficients'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.33：模型的排序重要特征及其相应的系数
- en: This exercise has taught us how to create and train a predictive model to predict
    a `target` variable when given `feature` variables. We split the `feature` and
    `target` dataset into `training` and `test` datasets. Then, we trained our model
    on the `training` dataset and evaluated our model on the `test` dataset. Finally,
    we observed the trained coefficients for this model.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 这个练习教会了我们如何创建和训练一个预测模型，在给定`feature`变量的情况下预测`target`变量。我们将`feature`和`target`数据集划分为`training`和`test`数据集。然后，我们在`training`数据集上训练模型，并在`test`数据集上评估模型。最后，我们观察了该模型的训练系数。
- en: Note
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/2Aq3ZCc](https://packt.live/2Aq3ZCc).
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问该部分的源代码，请参阅[https://packt.live/2Aq3ZCc](https://packt.live/2Aq3ZCc)。
- en: You can also run this example online at [https://packt.live/2VIRSaL](https://packt.live/2VIRSaL).
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在[https://packt.live/2VIRSaL](https://packt.live/2VIRSaL)上在线运行此示例。
- en: Model Tuning
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型调优
- en: In this section, we will delve further into evaluating model performance and
    examine techniques that we can use to generalize models to new data using `regularization`.
    Providing the context of a model's performance is extremely important. Our aim
    is to determine whether our model is performing well compared to trivial or obvious
    approaches. We do this by creating a baseline model against which machine learning
    models we train are compared. It is important to stress that all model evaluation
    metrics are evaluated and reported via the `test` dataset since that will give
    us an understanding of how the model will perform on new data.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将进一步深入评估模型性能，并检查可以用来通过`regularization`对模型进行泛化到新数据的技术。提供模型性能的上下文非常重要。我们的目标是确定我们的模型是否比简单或显而易见的方法表现更好。我们通过创建一个基准模型，将其与训练的机器学习模型进行比较，从而实现这一目标。需要强调的是，所有模型评估指标都是通过`test`数据集进行评估和报告的，因为这将帮助我们了解模型在新数据上的表现。
- en: Baseline Models
  id: totrans-396
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基准模型
- en: A baseline model should be a simple and well-understood procedure, and the performance
    of this model should be the lowest acceptable performance for any model we build.
    For classification models, a useful and easy baseline model is to calculate the
    model outcome value. For example, if there are `60%` `false` values, our baseline
    model would be to predict false for every value, which would give us an `accuracy`
    of `60%`. For `regression models`, the `mean` or `median` can be used as the baseline.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 基线模型应该是一个简单且容易理解的过程，该模型的性能应该是我们构建的任何模型所能接受的最低性能。对于分类模型，一个有用且简单的基线模型是计算模型结果值。例如，如果有
    `60%` 的 `false` 值，我们的基线模型就是预测每个值为 false，这样我们就能得到 `60%` 的 `accuracy`。对于 `regression
    models`，可以使用 `mean` 或 `median` 作为基线。
- en: 'Exercise 1.05: Determining a Baseline Model'
  id: totrans-398
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 练习 1.05：确定基线模型
- en: 'In this exercise, we will put the model performance into context. The accuracy
    we attained from our model seemed good, but we need something to compare it to.
    Since machine learning model performance is relative, it is important to develop
    a robust baseline with which to compare models. Once again, we are using the online
    shoppers purchasing intention dataset, and our `target` variable is whether or
    not each user will purchase a product in their session. Follow these steps to
    complete this exercise:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 在本练习中，我们将把模型的表现放在一个背景下。我们从模型中获得的准确率看起来不错，但我们需要一些对比的标准。由于机器学习模型的表现是相对的，因此建立一个强健的基线模型用于比较是非常重要的。再次提醒，我们使用的是在线购物者购买意图数据集，而我们的
    `target` 变量是每个用户是否会在他们的会话中购买产品。按照以下步骤完成这个练习：
- en: 'Import the `pandas` library and load in the `target` dataset:'
  id: totrans-400
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入 `pandas` 库并加载 `target` 数据集：
- en: '[PRE51]'
  id: totrans-401
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Next, calculate the relative proportion of each value of the `target` variables:'
  id: totrans-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，计算 `target` 变量每个值的相对比例：
- en: '[PRE52]'
  id: totrans-403
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'The following figure shows the output of the preceding code:'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图显示了前面代码的输出：
- en: '![Figure 1.34: Relative proportion of each value'
  id: totrans-405
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '![图 1.34：每个值的相对比例'
- en: '](img/B15777_01_34.jpg)'
  id: totrans-406
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B15777_01_34.jpg)'
- en: 'Figure 1.34: Relative proportion of each value'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 1.34：每个值的相对比例
- en: 'Here, we can see that `0` is represented `84.525547%` of the time—that is,
    there is no purchase by the user, and this is our `baseline` accuracy. Now, for
    the other model evaluation metrics:'
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到 `0` 出现的比例为 `84.525547%`——即用户没有购买，这是我们的 `baseline` 准确率。现在，来看其他模型评估指标：
- en: '[PRE53]'
  id: totrans-409
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Here, we've set the baseline model to predict `0` and have repeated the value
    so that it's the same as the number of rows in the `test` dataset.
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们设置基线模型为预测 `0`，并重复该值，使其与 `test` 数据集中的行数相同。
- en: Note
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: The average parameter in the `precision_recall_fscore_support` function has
    to be set to `macro` because when it is set to `binary`, as it was previously,
    the function is looking for `true` values, and our `baseline` model only consists
    of `false` values.
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`precision_recall_fscore_support` 函数中的平均参数必须设置为 `macro`，因为当它设置为 `binary` 时（如之前所设置），该函数会查找
    `true` 值，而我们的 `baseline` 模型仅由 `false` 值组成。'
- en: 'Print the final output for precision, recall, and fscore:'
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打印出最终的精确度、召回率和 fscore 输出：
- en: '[PRE54]'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The preceding code produces the following output:'
  id: totrans-415
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 前面的代码会产生以下输出：
- en: '[PRE55]'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: Now, we have a baseline model that we can compare to our previous model, as
    well as any subsequent models. By doing this, we can tell that while the accuracy
    of our previous model seemed high, it did not score much better than this `baseline` model.
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了一个基线模型，可以与之前的模型以及任何后续模型进行比较。通过这样做，我们可以看出，尽管之前模型的准确度看起来较高，但它并没有比这个 `baseline`
    模型好多少。
- en: Note
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: To access the source code for this specific section, please refer to [https://packt.live/31MD1jH](https://packt.live/31MD1jH).
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问此特定部分的源代码，请参考 [https://packt.live/31MD1jH](https://packt.live/31MD1jH)。
- en: You can also run this example online at [https://packt.live/2VFFSXO](https://packt.live/2VFFSXO).
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在网上运行这个例子，访问 [https://packt.live/2VFFSXO](https://packt.live/2VFFSXO)。
- en: Regularization
  id: totrans-421
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则化
- en: Earlier in this chapter, we learned about `overfitting` and what it looks like.
    The hallmark of `overfitting` is when a model is trained on the training data
    and performs extremely well yet performs terribly on `test` data. One reason for
    this could be that the model may be relying too heavily on certain features that
    lead to good performance in the training dataset but do not generalize well to
    new observations of data or the test dataset.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的早些时候，我们了解了`过度拟合`及其表现。 `过度拟合`的特征是，模型在训练数据上表现非常好，但在`测试`数据上表现糟糕。 这可能的一个原因是模型可能过于依赖某些在训练数据集中表现良好但不能很好泛化到新数据或测试数据集的特征。
- en: One technique that can be used to avoid this is called `regularization`. Regularization
    constrains the values of the coefficients toward zero, which discourages a complex
    model. There are many different types of regularization techniques. For example,
    in `linear` and `logistic` regression, `ridge` and `lasso` regularization are
    most common. In tree-based models, limiting the maximum depth of the trees acts
    as regularization.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这种情况，可以使用一种称为`正则化`的技术。 正则化会限制系数向零的值，从而抑制复杂模型的生成。 有许多不同类型的正则化技术。 例如，在`线性`和`逻辑`回归中，最常见的是`岭`和`套索`正则化。
    在基于树的模型中，通过限制树的最大深度来进行正则化。
- en: There are two different types of regularization, namely `L1` and `L2`. This
    term is either the `L2` norm (the sum of the squared values) of the weights or
    the `L1` norm (the sum of the absolute values) of the weights. Since the `l1`
    regularization parameter acts as a feature selector, it is able to reduce the
    coefficient of features to zero. We can use the output of this model to observe
    which features do not contribute much to the performance and remove them entirely
    if desired. The `l2` regularization parameter will not reduce the coefficient
    of features to zero, so we will observe that they all have non-zero values.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种不同类型的正则化，即`L1`和`L2`。 这个术语可以是权重的`L2`范数（平方和）或权重的`L1`范数（绝对值之和）。 由于`L1`正则化参数作为特征选择器，它能够将特征的系数减少到零。
    我们可以使用此模型的输出来观察哪些特征对性能贡献不大，并在需要时完全删除它们。 `L2`正则化参数不会将特征的系数减少到零，因此我们将观察到它们所有具有非零值。
- en: 'The following code shows how to instantiate the models using these regularization techniques:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了如何使用这些正则化技术实例化模型：
- en: '[PRE56]'
  id: totrans-426
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The following code shows how to fit the models:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了如何拟合这些模型：
- en: '[PRE57]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'The same concepts in lasso and ridge regularization can be applied to ANNs.
    However, penalization occurs on the weight matrices rather than the coefficients.
    Dropout is another form of regularization that''s used to prevent overfitting
    in ANNs. Dropout randomly selects nodes at each iteration and removes them, along
    with their connections, as shown in the following figure:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 套索和岭正则化中的相同概念可以应用于ANN。 但是，惩罚发生在权重矩阵而不是系数上。 Dropout是防止ANN中过度拟合的另一种形式的正则化。 在每次迭代中，Dropout会随机选择节点并移除它们及其连接，如下图所示：
- en: '![Figure 1.35: Dropout regularization in ANNs'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '![图1.35：ANN中的Dropout正则化'
- en: '](img/B15777_01_35.jpg)'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_35.jpg)'
- en: 'Figure 1.35: Dropout regularization in ANNs'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.35：ANN中的Dropout正则化
- en: Cross-Validation
  id: totrans-433
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉验证
- en: Cross-validation is often used in conjunction with regularization to help tune
    hyperparameters. Take, for example, the `penalization` parameter in ridge and
    lasso regression, or the proportion of nodes to drop out at each iteration using
    the dropout technique with ANNs. How will you determine which parameter to use?
    One way is to run models for each value of the regularization parameter and evaluate
    them on the test set; however, using the test set often can introduce bias into
    the model.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证通常与正则化一起使用以帮助调整超参数。 例如，在岭和套索回归中使用的`惩罚`参数，或者在ANN中使用Dropout技术时每次迭代中要放弃的节点比例。
    您将如何确定使用哪个参数？ 一种方法是对每个正则化参数的值运行模型，并在测试集上评估它们; 但是，经常使用测试集可能会引入模型的偏差。
- en: One popular example of cross-validation is called k-fold cross-validation. This
    technique gives us the ability to test our model on unseen data while retaining
    a test set that we will use to test at the end. Using this method, the data is
    divided into `k` subsets. In each of the `k` iterations, `k-1` of the subsets
    are used as training data and the remaining subset is used as a validation set.
    This is repeated `k` times until all *k* subsets have been used as validation
    sets.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证的一个常见例子叫做 k 折交叉验证。这个技术使我们能够在保留一个测试集的同时，在未见过的数据上测试我们的模型，并在最后进行测试。使用这种方法，数据被分成`k`个子集。在每一次的`k`次迭代中，`k-1`个子集作为训练数据，剩下的子集作为验证集。这一过程重复`k`次，直到所有*k*个子集都作为验证集使用过。
- en: By using this technique, there is a significant reduction in bias, since most
    of the data is used for fitting. There is also a reduction in variation since
    most of the data is also used for validation. Typically, there are between `5`
    and `10` folds, and the technique can even be stratified, which is useful when
    there is a large imbalance of classes.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种技术，可以显著减少偏差，因为大部分数据用于拟合。同时，由于大部分数据也用于验证，因此变化性也会减少。通常，折数在`5`到`10`之间，这项技术甚至可以进行分层，这对于类别严重不平衡时非常有用。
- en: 'The following example shows `5-fold cross-validation` with `20%` of the data
    being held out as a test set. The remaining `80%` is separated into 5 folds. Four
    of those folds comprise the training data, and the remaining fold is the validation
    data. This is repeated a total of five times until every fold has been used once
    for validation:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例展示了`5折交叉验证`，其中`20%`的数据被保留作为测试集，剩下的`80%`数据被分为5个折叠。四个折叠作为训练数据，剩下的一个折叠作为验证数据。这个过程总共重复五次，直到每个折叠都被用作一次验证集：
- en: '![Figure 1.36: A figure demonstrating how 5-fold cross-validation works'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 1.36：演示如何进行 5 折交叉验证的图示'
- en: '](img/B15777_01_36.jpg)'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B15777_01_36.jpg)'
- en: 'Figure 1.36: A figure demonstrating how 5-fold cross-validation works'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.36：演示如何进行 5 折交叉验证的图示
- en: 'Activity 1.01: Adding Regularization to the Model'
  id: totrans-441
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活动 1.01：为模型添加正则化
- en: In this activity, we will utilize the same logistic regression model from the
    scikit-learn package. This time, however, we will add regularization to the model
    and search for the optimum regularization parameter—a process often called hyperparameter
    tuning. After training the models, we will test the predictions and compare the
    model evaluation metrics to those produced by the baseline model and the model
    without regularization.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个活动中，我们将使用来自 scikit-learn 包的相同逻辑回归模型。然而，这次我们将为模型添加正则化，并搜索最优的正则化参数——这个过程通常称为超参数调优。在训练完模型后，我们将测试预测结果，并将模型评估指标与基准模型以及没有正则化的模型进行比较。
- en: 'The steps we will take are as follows:'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将采取的步骤如下：
- en: Load in the feature and target datasets of the online shoppers purchasing intention
    dataset from `'../data/OSI_feats_e3.csv'` and `'../data/OSI_target_e2.csv'`.
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`'../data/OSI_feats_e3.csv'`和`'../data/OSI_target_e2.csv'`加载在线购物者购买意图数据集的特征和目标数据。
- en: Create `training` and `test` datasets for each of the `feature` and `target`
    datasets. The `training` datasets will be used to train on, and the models will
    be evaluated using the `test` datasets.
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个`feature`和`target`数据集创建`training`和`test`数据集。`training`数据集将用于训练，模型的评估将使用`test`数据集。
- en: Instantiate a model instance of the `LogisticRegressionCV` class of scikit-learn's
    `linear_model` package.
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例化一个`scikit-learn`的`linear_model`包中`LogisticRegressionCV`类的模型实例。
- en: Fit the model to the `training` data.
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型拟合到`training`数据。
- en: Make predictions on the `test` dataset using the trained model.
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用训练后的模型对`test`数据集进行预测。
- en: Evaluate the models by comparing how they scored against the `true` values using
    the evaluation metrics.
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过比较模型的得分与`true`值来评估模型的表现，并使用评估指标。
- en: 'After implementing these steps, you should get the following expected output:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 实施这些步骤后，您应该得到以下预期输出：
- en: '[PRE58]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Note
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The solution for this activity can be found on page 348.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 这个活动的解决方案可以在第348页找到。
- en: This activity has taught us how to use `regularization` in `conjunction` with
    `cross-validation` to appropriately score a model. We have learned how to fit
    a model to data using regularization and cross-validation. Regularization is an
    important technique to use to ensure that models don't overfit the training data.
    Models that have been trained with regularization will perform better on new data,
    which is generally the goal of machine learning models—to predict a target when
    given new observations of the input data. Choosing the optimal regularization
    parameter may require iterating over a number of different choices.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 这项活动教会了我们如何将`正则化`与`交叉验证`结合使用，以适当地对模型进行评分。我们已经学习了如何使用正则化和交叉验证将模型拟合到数据上。正则化是确保模型不对训练数据过拟合的一个重要技术。通过正则化训练的模型在新数据上的表现通常会更好，这也是机器学习模型的一般目标——在给定输入数据的新观测时预测目标。选择最优的正则化参数可能需要遍历多个不同的选择。
- en: '`Cross-validation` is a technique that''s used to determine which set of regularization
    parameters fit the data best. Cross-validation will train multiple models with
    different values for the regularization parameters on different cuts of the data.
    This technique ensures the best set of regularization parameters are chosen, without
    adding bias and minimizing variance.'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: '`交叉验证`是一种技术，用于确定哪组正则化参数最适合数据。交叉验证将使用不同的正则化参数值，在数据的不同划分上训练多个模型。这项技术确保选择最优的正则化参数组合，既不引入偏差，又能最小化方差。'
- en: Summary
  id: totrans-456
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered how to prepare data and construct machine learning
    models. We achieved this by utilizing Python and libraries such as pandas and
    scikit-learn. We also used the algorithms in scikit-learn to build our machine
    learning models.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讲解了如何准备数据并构建机器学习模型。我们通过使用 Python 和诸如 pandas、scikit-learn 等库来实现这一点。我们还使用了
    scikit-learn 中的算法来构建我们的机器学习模型。
- en: Then, we learned how to load data into Python, as well as how to manipulate
    data so that a machine learning model can be trained on the data. This involved
    converting all the columns into numerical data types. We also created a basic
    logistic regression classification model using scikit-learn algorithms. We divided
    the dataset into training and test datasets and fit the model to the training
    dataset. We evaluated the performance of the model on the test dataset using the
    model evaluation metrics, that is, accuracy, precision, recall, and fscore.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们学习了如何将数据加载到 Python 中，并且学会了如何操作数据，使得机器学习模型能够在这些数据上进行训练。这包括将所有列转换为数值数据类型。我们还使用
    scikit-learn 算法创建了一个基础的逻辑回归分类模型。我们将数据集分为训练集和测试集，并将模型拟合到训练集上。我们使用模型评估指标（即准确率、精确度、召回率和
    F-score）来评估模型在测试集上的表现。
- en: Finally, we iterated on this basic model by creating two models with different
    types of regularization for the model. We utilized cross-validation to determine
    the optimal parameter to use for the regularization parameter.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过创建两种不同类型的正则化模型，对这个基础模型进行了迭代。我们利用交叉验证来确定正则化参数的最优值。
- en: In the next chapter, we will use these same concepts to create the model using
    the Keras library. We will use the same dataset and attempt to predict the same
    target value for the same classification task. By doing so, we will learn how
    to use `regularization`, `cross-validation`, and `model evaluation metrics` when
    fitting our neural network to the data.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将使用相同的概念，通过 Keras 库来创建模型。我们将使用相同的数据集，并尝试预测相同的目标值，以完成相同的分类任务。通过这样做，我们将学习如何在将神经网络拟合到数据时使用`正则化`、`交叉验证`和`模型评估指标`。
