- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Embedding Models
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌入模型
- en: '**Embedding models** are powerful machine learning techniques that simplify
    high-dimensional data into lower-dimensional space, while preserving essential
    features. Crucial in **natural language processing** (**NLP**), they transform
    sparse word representations into dense vectors, capturing semantic similarities
    between words. Embedding models also process images, audio, video, and structured
    data, enhancing applications in recommendation systems, anomaly detection, and
    clustering.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**嵌入模型**是强大的机器学习技术，它将高维数据简化为低维空间，同时保留基本特征。在**自然语言处理**（**NLP**）中至关重要，它们将稀疏的词表示转换为密集的向量，捕捉词语之间的语义相似性。嵌入模型还可以处理图像、音频、视频和结构化数据，增强推荐系统、异常检测和聚类等应用。'
- en: 'Here is an example of an embedding model in action. Suppose the full plot in
    a database of movies has been previously embedded using OpenAI’s `text-embedding-ada-002`
    embedding model. Your goal is to find all movies and animations for *Guardians
    of the Galaxy*, but not by traditional phonetic or lexical matching (where you
    would type some of the words in the title). Instead, you will search by semantic
    means, say, the phrase `Awkward team of space defenders`. You will then use the
    same embedding model again to embed this phrase and query the embedded movie plots.
    *Table 4.1* shows an excerpt of the resulting embedding:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个嵌入模型实际应用的例子。假设数据库中电影的完整情节已经使用 OpenAI 的 `text-embedding-ada-002` 嵌入模型预先嵌入。您的目标是找到所有与《银河护卫队》相关的电影和动画，但不是通过传统的音韵或词汇匹配（您会输入标题中的某些单词）。相反，您将通过语义方式进行搜索，例如，短语“尴尬的太空防御队”。然后，您将再次使用相同的嵌入模型来嵌入这个短语并查询嵌入的电影情节。*表
    4.1* 展示了结果的嵌入片段：
- en: '| **Dimension** | **Value** |'
  id: totrans-4
  prefs: []
  type: TYPE_TB
  zh: '| **维度** | **值** |'
- en: '| 1 | 0.00262913 |'
  id: totrans-5
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.00262913 |'
- en: '| 2 | 0.031449784 |'
  id: totrans-6
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.031449784 |'
- en: '| 3 | 0.0020321296 |'
  id: totrans-7
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.0020321296 |'
- en: '| ... | ... |'
  id: totrans-8
  prefs: []
  type: TYPE_TB
  zh: '| ... | ... |'
- en: '| 1535 | -0.01821267 |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| 1535 | -0.01821267 |'
- en: '| 1536 | 0.0014683881 |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| 1536 | 0.0014683881 |'
- en: 'Table 4.1: Excerpt of embedding'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.1：嵌入摘录
- en: This chapter will help you understand embedding models in depth. You’ll also
    implement an example using the Python language and the `langchain-openai` library.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将帮助您深入了解嵌入模型。您还将使用 Python 语言和 `langchain-openai` 库实现一个示例。
- en: 'This chapter will cover the following topics:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Differentiation between embedding models and LLMs
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分嵌入模型和 LLM
- en: Types of embedding models
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 嵌入模型的类型
- en: How to choose an embedding model
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何选择嵌入模型
- en: Vector representations
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量表示
- en: Technical requirements
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To follow the examples in this chapter, you will need the following prerequisites:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随本章中的示例，您需要以下先决条件：
- en: A MongoDB Atlas cluster. An Atlas `M0` free cluster should be sufficient as
    you will store a small set of documents and create only one vector index.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 MongoDB Atlas 集群。一个 `M0` 免费集群应该足够了，因为您将存储一小组文档并仅创建一个向量索引。
- en: An OpenAI account and API key with access to the `text-embedding-3-large` model.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 OpenAI 账户和 API 密钥，可以访问 `text-embedding-3-large` 模型。
- en: A Python 3 working environment.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Python 3 工作环境。
- en: 'You will also need to have installed Python libraries for MongoDB, LangChain,
    and OpenAI. You can install these libraries in your Python 3 environment as follows:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 您还需要安装 MongoDB、LangChain 和 OpenAI 的 Python 库。您可以在 Python 3 环境中按照以下步骤安装这些库：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'To successfully execute the example in this chapter, you will need a MongoDB
    Atlas Vector Index created on the MongoDB Atlas cluster. The index name must be
    `text_vector_index`, created on the `embeddings.text` collection as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要成功执行本章中的示例，您需要在 MongoDB Atlas 集群上创建一个 MongoDB Atlas 向量索引。索引名称必须是 `text_vector_index`，在
    `embeddings.text` 集合上创建，如下所示：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: What is an embedding model?
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌入模型是什么？
- en: Embedding models are a type of tool used in machine learning and artificial
    intelligence that simplifies large and complex data into a more manageable form.
    This process, known as **embedding**, involves reducing the data’s dimensions.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入模型是机器学习和人工智能中用于简化大型和复杂数据的工具类型，将数据简化为更易于管理的形式。这个过程称为**嵌入**，涉及减少数据的维度。
- en: Imagine going from a detailed world map with highways, railroads, rivers, trails,
    and so on, to a simpler, summarized version with only country boundaries and capital
    cities. This not only makes computation faster and less resource-intensive, but
    also helps identify and understand relationships within the data. Because embedding
    models streamline the processing and analyzing of large datasets, they are particularly
    useful in areas of language (text) processing, image and sound recognition, and
    recommendation systems.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下从包含高速公路、铁路、河流、小径等详细的世界地图，转换到一个只有国家边界和首都的简化、总结版本。这不仅使计算更快、资源消耗更少，还有助于识别和理解数据中的关系。由于嵌入模型简化了大数据集的处理和分析，它们在语言（文本）处理、图像和声音识别以及推荐系统等领域特别有用。
- en: 'Consider a vast library where each book stands for one point in high dimensions.
    Embedding models can help reorganize the library to improve ease of navigation,
    such as by grouping the books on related topics closer together and reducing the
    library’s overall size. *Figure 4**.1* illustrates this concept:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个庞大的图书馆，其中每本书代表高维空间中的一个点。嵌入模型可以帮助重新组织图书馆，以改善导航的便捷性，例如通过将相关主题的书籍聚集在一起并减少图书馆的整体规模。*图4.1*展示了这一概念：
- en: '![](img/B22495_04_01.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_04_01.jpg)'
- en: 'Figure 4.1: An embedding model example for a library use case'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1：用于图书馆用例的嵌入模型示例
- en: This conversion or reduction from a high-dimensional or original representation
    to a lower-dimensional representation created the basis for advancements in NLP,
    computer vision, and more.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这种从高维或原始表示到低维表示的转换或降低，为自然语言处理（NLP）、计算机视觉等领域的发展奠定了基础。
- en: How do embedding models differ from LLMs?
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌入模型与LLMs有何不同？
- en: Embedding models are specialized algorithms that reduce high-dimensional data
    (such as text, images, or sound) into a low-dimensional space of dense vectors.
    On the other hand, LLMs are effective artificial neural networks pre-trained on
    gigantic corpora of textual data.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入模型是专门算法，可以将高维数据（如文本、图像或声音）降低到密集向量的低维空间。另一方面，LLMs是预先在庞大的文本语料库上训练的有效人工神经网络。
- en: While both are rooted in neural networks, they employ distinct methodologies.
    LLMs are designed for generating coherent and contextually relevant text. LLMs
    leverage massive amounts of data to understand and predict language patterns.
    Their basic building blocks include transformer architectures, attention mechanisms,
    and large-scale pre-training followed by fine-tuning.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然两者都基于神经网络，但它们采用了不同的方法。大型语言模型（LLMs）旨在生成连贯且与上下文相关的文本。LLMs利用大量数据来理解和预测语言模式。它们的基本构建块包括变换器架构、注意力机制以及大规模预训练后进行微调。
- en: In contrast, embedding models focus on mapping words, phrases, or even entire
    sentences into dense vector spaces where semantic relationships are preserved.
    They often use techniques such as **contrastive loss**, which helps in distinguishing
    between similar and dissimilar pairs during training. Positive and negative sampling
    is another technique employed by embedding models. **Positive samples** are similar
    items (such as synonyms or related sentences), while **negative samples** are
    dissimilar items (such as unrelated words or sentences). *Figure 4**.2* visualizes
    an example of contrastive loss and positive and negative sampling in 2D space.
    This sampling aids the model in learning meaningful representations by minimizing
    the distance between positive pairs and maximizing the distance between negative
    pairs in the vector space.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，嵌入模型专注于将单词、短语甚至整个句子映射到密集的向量空间中，其中语义关系得到保留。它们通常使用诸如**对比损失**等技术，这些技术有助于在训练期间区分相似和不同的成对项。正负样本采样是嵌入模型采用的另一种技术。**正样本**是相似项（如同义词或相关句子），而**负样本**是不相似项（如无关的单词或句子）。*图4.2*展示了在二维空间中对比损失和正负样本采样的一个示例。这种采样有助于模型通过最小化正样本对之间的距离并最大化负样本对之间的距离在向量空间中学习有意义的表示。
- en: '![](img/B22495_04_02.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_04_02.jpg)'
- en: 'Figure 4.2: 2D visualization of contrastive loss and positive and negative
    sampling'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2：对比损失和正负样本采样的二维可视化
- en: To summarize, while LLMs excel in language generation tasks, embedding models
    are optimized for capturing and leveraging semantic similarities. Both enhance
    NLP by enabling machines to grasp and produce human language more effectively.
    Now, let’s look at an example of each.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，虽然 LLMs 在语言生成任务上表现出色，但嵌入模型优化于捕捉和利用语义相似性。两者都通过使机器更有效地理解和生成人类语言来增强自然语言处理（NLP）。现在，让我们看看每个的例子。
- en: '**Word2vec** (developed by Google) transforms words into vectors and discerns
    semantic relationships, such as “king” is to “man” as “queen” is to “woman.” It’s
    useful for sentiment analysis, translation, and content recommendations, enhancing
    natural language understanding for machines.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**Word2vec**（由 Google 开发）将单词转换为向量，并辨别语义关系，例如“king”对“man”就像“queen”对“woman”。它在情感分析、翻译和内容推荐方面很有用，增强了机器的自然语言理解。'
- en: '**GPT-4** (developed by OpenAI) is an LLM that is characterized by its ability
    to generate human-like text based on the input it receives. GPT-4 excels in a
    range of language-based tasks, including conversation, content generation, summarization,
    and translation. Its architecture allows it to comprehend the intricate details
    and nuances of language, enabling it to perform tasks that require a deep understanding
    of context, humor, irony, and cultural references.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**GPT-4**（由 OpenAI 开发）是一种 LLM，其特点是根据接收到的输入生成类似人类的文本。GPT-4 在一系列基于语言的任务上表现出色，包括对话、内容生成、摘要和翻译。其架构允许它理解语言的复杂细节和细微差别，使其能够执行需要深入理解上下文、幽默、讽刺和文化引用的任务。'
- en: When to use embedding models versus LLMs
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 何时使用嵌入模型与 LLMs
- en: 'Embedding models are used in scenarios where the goal is to capture and leverage
    the relationships within data. They are the ideal choice for the following tasks:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入模型用于那些旨在捕捉和利用数据内部关系的场景。它们是以下任务的理想选择：
- en: '**Semantic similarity**: Finding or recommending items (such as documents or
    products) that are like a given item.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语义相似性**：找到或推荐与给定项目类似的项目（如文档或产品）。'
- en: '**Clustering**: Grouping entities based on their semantic properties.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类**：根据实体的语义属性进行分组。'
- en: '**Information retrieval**: Enhancing search functionalities by understanding
    the semantic content of queries.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息检索**：通过理解查询的语义内容来增强搜索功能。'
- en: 'LLMs are the go-to for tasks that require text understanding, generation, or
    both, such as the following:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 是处理需要文本理解、生成或两者兼备的任务的首选，例如以下任务：
- en: '**Content creation**: Generating text that is coherent, contextually relevant,
    and stylistically appropriate. For example, generating a synopsis from the full
    plot of a movie.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容创作**：生成连贯、上下文相关且风格适当的文本。例如，从一部电影的完整剧情中生成摘要。'
- en: '**Conversational AI**: Building chatbots and virtual assistants that can understand
    and engage in human-like dialogue, such as answering questions about employment
    policies and employee benefits.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对话式人工智能**：构建能够理解和参与类似人类对话的聊天机器人和虚拟助手，例如回答有关就业政策和员工福利的问题。'
- en: '**Language translation**: The extensive training on language-diverse datasets
    allows LLMs to handle idiomatic expressions, cultural nuances, and specialized
    terminology.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**语言翻译**：在语言多样化的数据集上进行广泛训练，使得大型语言模型（LLMs）能够处理惯用语、文化细微差别和专门术语。'
- en: Embedding models and LLMs both play crucial roles in AI. Embedding models capture
    and manipulate semantic properties compactly, while LLMs excel in generating and
    interpreting text. Using both, and selecting the right embedding models based
    on your goals, can unlock AI’s full potential in your projects.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入模型和 LLMs 都在人工智能中扮演着至关重要的角色。嵌入模型紧凑地捕捉和操作语义属性，而 LLMs 在生成和解释文本方面表现出色。使用两者，并根据您的目标选择合适的嵌入模型，可以释放您项目中人工智能的完整潜力。
- en: Types of embedding models
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌入模型类型
- en: Word-level models, including **Global Vectors for Word Representation** (**GloVe**)
    and **Bidirectional Encoder Representations from Transformers** (**BERT**), capture
    broader textual meanings. Specialized models such as **fastText** adapt to linguistic
    challenges. All of these reflect the evolving landscape of embedding models.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 单词级模型，包括 **全局单词表示向量**（**GloVe**）和 **从 Transformer 获取的双向编码器表示**（**BERT**），捕捉更广泛的文本意义。专门模型如
    **fastText** 适应语言挑战。所有这些都反映了嵌入模型不断发展的格局。
- en: 'In this section, you will explore many types of embedding models: word, sentence,
    document, contextual, specialized, non-text, and multi-modal.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将探索许多类型的嵌入模型：单词、句子、文档、上下文、专门化、非文本和多模态。
- en: Word embeddings
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单词嵌入
- en: '`n` adjacent symbols in a particular order), which helps to better handle prefixes,
    suffixes, and rare words. Word2vec and GloVe are examples of these models.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '`n` 个相邻符号按特定顺序排列），这有助于更好地处理前缀、后缀和罕见词语。Word2vec 和 GloVe 是这些模型的例子。'
- en: '**Word2vec** was the first attempt of embedding models to learn the representation
    of words as vectors based on their contextual similarities. Developed by a team
    from Google, it uses two architectures: **Continuous Bag of Words** (**CBOW**),
    which predicts a word given a context, and **skip-gram**, which predicts a context
    for a given word. Word2vec has been seen to capture the relationship in the syntax
    of words, evidenced by its ability to deduce meanings from arithmetic operations
    performed with word vectors.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**Word2vec** 是嵌入模型首次尝试根据词语的上下文相似性将词语表示为向量的方法。由谷歌团队开发，它使用两种架构：**连续词袋模型**（**CBOW**），它根据上下文预测一个词语，以及**跳字模型**，它根据一个词语预测上下文。Word2vec
    已被证明能够捕捉词语的句法关系，这体现在它能够从与词语向量进行的算术运算中推断出意义。'
- en: '**GloVe**, developed at Stanford University, merges the benefits of two leading
    word representation approaches: global matrix factorization with co-occurrence
    statistics and context window methods. By constructing a co-occurrence matrix
    from the corpus and applying dimensionality reduction techniques, GloVe captures
    both global statistics and local context, which is invaluable for tasks that require
    a deep understanding of word relationships.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**GloVe**，由斯坦福大学开发，结合了两种领先的词语表示方法的优点：全局矩阵分解与共现统计和上下文窗口方法。通过从语料库构建共现矩阵并应用降维技术，GloVe
    捕捉了全局统计和局部上下文，这对于需要深入理解词语关系的任务来说是无价的。'
- en: Sentence and document embeddings
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 句子和文档嵌入
- en: '**Sentence and document embedding models** capture the overall semantic meaning
    of text blocks by considering word context and arrangement. A common approach
    aggregates word vectors into a coherent vector for the whole text unit. These
    models are useful in document similarity, information retrieval, and text summarization,
    such as synopses versus full movie plots. Notable models include Doc2vec and BERT.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**句子和文档嵌入模型**通过考虑词语上下文和排列来捕捉文本块的整体语义意义。一种常见的方法是将词语向量聚合为一个连贯的向量，用于整个文本单元。这些模型在文档相似性、信息检索和文本摘要（如摘要与完整电影剧情）等方面非常有用。显著的模型包括
    Doc2vec 和 BERT。'
- en: Building on Word2vec, **Doc2vec**, which is also known as **Paragraph Vector**,
    encapsulates whole sentences or documents as vectors. Introducing a document ID
    token that allows the model to learn document-level embeddings alongside word
    embeddings aids significantly in tasks such as document classification and similarity
    comparison.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 Word2vec，**Doc2vec**（也称为**段落向量**），将整个句子或文档封装为向量。引入一个文档 ID 标记，允许模型在词语嵌入的同时学习文档级别的嵌入，这在文档分类和相似性比较等任务中起到了显著的帮助作用。
- en: Google’s **BERT** employs context-aware embeddings, reading the entire sequence
    of words concurrently, unlike its predecessors that processed text linearly. This
    approach enables BERT to understand a word’s context from all surrounding words,
    resulting in more dynamic and nuanced embeddings and setting new standards across
    various NLP tasks.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌的 **BERT** 采用上下文感知嵌入，同时读取整个单词序列，与先前的线性处理文本的前辈不同。这种方法使得 BERT 能够从所有周围词语中理解一个词语的上下文，从而产生更动态和细微的嵌入，并在各种自然语言处理任务中设定了新的标准。
- en: Contextual embeddings
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 上下文嵌入
- en: '**Contextual embedding models** are designed to produce word vectors that vary
    according to the context of use in a sentence. These models use deep learning
    architectures by examining the whole sentence, or at times the surrounding sentences.
    The contextual model produces dynamic embeddings that capture nuances based on
    a word’s particular context and linguistic environment. A model architecture of
    this kind uses a bi-directional framework to process text both forward and in
    reverse, thereby capturing fine semantic and syntactic dependencies within the
    preceding and following contexts. They are useful in sentiment analysis (such
    as to interpret the tone of the text in an IT support ticket) and question-answering
    tasks where the exact meaning of words for interpretation is necessary. ELMo and
    GPT are two examples.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**上下文嵌入模型**旨在生成根据句子中使用的上下文而变化的词向量。这些模型通过检查整个句子，有时是周围的句子，使用深度学习架构。上下文模型产生动态嵌入，根据单词的特定上下文和语言环境捕捉细微差别。这种类型的模型架构使用双向框架来处理文本的前向和反向，从而捕捉前后的上下文中的精细语义和句法依赖关系。它们在情感分析（如解释IT支持票中的文本语气）和需要精确解释单词意义的问答任务中很有用。ELMo和GPT是两个例子。'
- en: '**Embeddings from Language Models** (**ELMo**) introduced dynamic, context-dependent
    embeddings, producing variable embeddings based on a word’s linguistic context.
    This approach greatly enhances performance on downstream NLP tasks by providing
    a richer language understanding.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**语言模型嵌入（ELMo**）引入了动态、上下文相关的嵌入，根据单词的语言环境产生可变的嵌入。这种方法通过提供更丰富的语言理解，大大提高了下游NLP任务的性能。'
- en: OpenAI’s **GPT series** leverages transformer technology to offer embeddings
    pre-trained on extensive text corpora and fine-tuned for specific tasks. GPT’s
    success underscores the efficacy of combining large-scale language models with
    transformer architectures in NLP.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的**GPT系列**利用转换器技术，在大量文本语料库上预训练嵌入，并针对特定任务进行微调。GPT的成功强调了将大规模语言模型与转换器架构相结合在自然语言处理中的有效性。
- en: Specialized embeddings
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 专用嵌入
- en: '**Specialized embedding models** capture specific linguistic properties, such
    as places, people, tone, and mood, in vector space. Some are language- or dialect-specific,
    while others analyze sentiment and emotional dimensions. Applications include
    legal document analysis, support ticket triage, sentiment analysis in marketing,
    and multilingual content management.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**专用嵌入模型**能够捕捉特定语言属性，例如地点、人物、语气和情绪，在向量空间中。有些是针对特定语言或方言的，而有些则分析情感和情感维度。应用包括法律文件分析、支持票务分类、市场营销中的情感分析和多语言内容管理。'
- en: '**fastText** is an example of a specialized embedding model. Developed by Facebook’s
    AI Research lab, fastText enhances Word2vec by treating words as bags of character
    n-grams, which proves particularly helpful for handling **out-of-vocabulary**
    (**OOV**) words. OOV words are words not seen during training and thus lack pre-learned
    vector representations, posing challenges for traditional models. fastText enables
    embeddings for OOV words through the summation of their sub-word embeddings. This
    makes it especially suitable for handling rare words and morphologically complex
    languages, which are languages with rich and varied word structures that use extensive
    prefixes, suffixes, and inflections to convey different grammatical meanings,
    such as Finnish, Turkish, and Arabic.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**fastText**是专用嵌入模型的一个例子。由Facebook的人工智能研究实验室开发，fastText通过将单词视为字符n-gram的包来增强Word2vec，这对于处理**词汇表外（OOV**）单词特别有帮助。OOV单词是在训练期间没有看到的单词，因此缺乏预学习的向量表示，这对传统模型构成了挑战。fastText通过其子词嵌入的总和来实现OOV单词的嵌入。这使得它特别适合处理罕见单词和形态学复杂的语言，这些语言具有丰富和多样的词结构，使用大量的前缀、后缀和屈折变化来传达不同的语法意义，例如芬兰语、土耳其语和阿拉伯语。'
- en: Other non-text embedding models
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他非文本嵌入模型
- en: 'Embedding models go beyond converting only text to vector representations.
    Images, audio, video, and even JSON data itself can be represented in vector form:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入模型不仅限于将文本转换为向量表示。图像、音频、视频，甚至JSON数据本身都可以以向量形式表示：
- en: '**Images**: Models such as **Visual Geometry Group** (**VGG**) and **Residual
    Network** (**ResNet**) set benchmarks for the translation of raw images into dense
    vectors. These models capture important visual features, such as edges, textures,
    and color gradients, which are vital to many computer vision tasks, including
    image classification and object recognition. VGG works well at recognizing visual
    patterns, while ResNet improves accuracy in complex image-processing tasks, such
    as image segmentation or photo tagging.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图像**：例如**视觉几何组**（**VGG**）和**残差网络**（**ResNet**）等模型为将原始图像转换为密集向量设定了基准。这些模型捕捉了重要的视觉特征，如边缘、纹理和颜色梯度，这些特征对于许多计算机视觉任务至关重要，包括图像分类和物体识别。VGG在识别视觉模式方面表现良好，而ResNet在复杂的图像处理任务中提高了准确性，例如图像分割或照片标记。'
- en: '**Audio**: OpenL3 and VGGish are models for audio. **OpenL3** is a model adapted
    from the L3-Net architecture that is used in audio event detection and environmental
    sound classification to embed audio into a temporal and spectral context-rich
    space. **VGGish** is born out of the VGG architecture for images, and so follows
    the same principle of converting sound waves into patterns of small, compact vectors.
    This simplifies tasks such as recognition of speech and music genres.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**音频**：OpenL3和VGGish是音频模型。**OpenL3**是一个从L3-Net架构中改编的模型，用于音频事件检测和环境声音分类，将音频嵌入到时间和频谱上下文丰富的空间中。**VGGish**源于图像的VGG架构，因此遵循将声波转换为小型、紧凑向量模式的相同原则。这简化了诸如语音和音乐类型识别等任务。'
- en: '**Video**: **3D Convolutional Neural Networks** (**3D CNNs** or **3D ConvNets**)
    and **Inflated 3D** (**I3D**) expand the capabilities of image embeddings in perceiving
    the temporal dynamics paramount to both action recognition and for video content
    analysis. 3D ConvNets apply convolutional filters in three dimensions (height,
    width, time) capturing spatial and temporal dependencies in volumetric data, making
    them particularly effective for spatiotemporal data, such as video analysis, medical
    imaging, and 3D object recognition. I3D uses a spatiotemporal architecture that
    combines the outputs of two 3D ConvNets: one processes RGB frames, while the other
    handles optical flow predictions between consecutive frames. I3D models are useful
    for sports analytics and surveillance systems.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视频**：**3D卷积神经网络**（**3D CNNs**或**3D ConvNets**）和**膨胀3D**（**I3D**）扩展了图像嵌入在感知动作识别和视频内容分析中至关重要的时间动态的能力。3D
    ConvNets在三维（高度、宽度、时间）上应用卷积滤波器，捕捉体积数据中的空间和时间依赖性，使它们特别适用于时空数据，如视频分析、医学成像和3D物体识别。I3D使用时空架构，结合两个3D
    ConvNets的输出：一个处理RGB帧，而另一个处理连续帧之间的光流预测。I3D模型对于体育分析和监控系统很有用。'
- en: '**Graph data**: Node2vec and DeepWalk capture connectivity patterns of nodes
    within a graph and are applied in the domains of social network analysis, fraud
    detection, and recommendation systems. **Node2vec** learns continuous vector representations
    for nodes by performing biased random walks on the graph. This captures the diverse
    node relationships and community structures, improving the performance of tasks
    such as node classification and link prediction. **DeepWalk** treats random walks
    as sequences of nodes like sentences in NLP by capturing the structural relationships
    between nodes and encodes them into continuous vector representations, which can
    be used for node classification and clustering.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**图数据**：Node2vec和DeepWalk捕捉图中节点的连接模式，并应用于社交网络分析、欺诈检测和推荐系统等领域。**Node2vec**通过在图上执行有偏随机游走来学习节点的连续向量表示，这捕捉了多样的节点关系和社区结构，从而提高了节点分类和链接预测等任务的性能。**DeepWalk**将随机游走视为节点序列，类似于自然语言处理中的句子，通过捕捉节点之间的结构关系并将它们编码为连续向量表示，这些表示可用于节点分类和聚类。'
- en: '**JSON data**: There are even JSON data embedding models, such as **Tree-LSTM**,
    which is a variation of the traditional **long short-term memory** (**LSTM**)
    networks, adapted specifically to handle data with a hierarchical tree structure,
    such as JSON. Unlike standard LSTM units that process data sequentially, Tree-LSTM
    operates over tree-structured data by incorporating states from multiple child
    nodes into a parent node, effectively capturing the dependencies in nested structures.
    This makes it particularly suitable for tasks such as semantic parsing and sentiment
    analysis, where understanding the hierarchical relationships within data can significantly
    improve performance. **json2vec** is an implementation of this kind of embedding
    model.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**JSON数据**：甚至有JSON数据嵌入模型，例如**Tree-LSTM**，这是一种传统的**长短期记忆**（**LSTM**）网络的变体，专门用于处理具有层次树结构的JSON等数据。与按顺序处理数据的标准LSTM单元不同，Tree-LSTM通过将多个子节点的状态合并到父节点中，在树结构数据上操作，有效地捕捉嵌套结构中的依赖关系。这使得它特别适合语义解析和情感分析等任务，在这些任务中，理解数据中的层次关系可以显著提高性能。**json2vec**是这种嵌入模型的一种实现。'
- en: After single-mode models, you can explore multi-modal models. These analyze
    multiple data types simultaneously and are crucial for applications such as autonomous
    driving, where merging data from sensors, cameras, and LiDAR builds a comprehensive
    view of the driving environment.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在单模态模型之后，你可以探索多模态模型。这些模型能够同时分析多种数据类型，对于自动驾驶等应用至关重要，在这些应用中，从传感器、摄像头和激光雷达中合并数据可以构建对驾驶环境的全面视图。
- en: Multi-modal models
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多模态模型
- en: '**Multi-modal embedding models** process and integrate information from many
    types of data sources into a unified embedding space. This approach is incredibly
    useful when different modalities complement or reinforce each other and together
    can lead to better AI applications. Multi-modal models are excellent for in-depth
    comprehension of multisensory input content, such as the tasks of multi-media
    search engines, automated content moderation, and interactive AI systems that
    can engage the user via visual and verbal interaction. Here are a few examples:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**多模态嵌入模型**处理和整合来自多种数据源的信息到一个统一的嵌入空间。当不同模态相互补充或加强，并共同导致更好的AI应用时，这种方法非常有用。多模态模型非常适合深入理解多感官输入内容，例如多媒体搜索引擎、自动内容审核和可以通过视觉和语言交互吸引用户的交互式AI系统。以下是一些例子：'
- en: '**CLIP**: A well-known multi-modal model by OpenAI. It learns how to correlate
    visual images with textual descriptions in such a way that it can recognize images
    it has never seen during training, based on natural language queries.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CLIP**：OpenAI的一个知名多模态模型。它学习如何将视觉图像与文本描述相关联，以便在训练期间根据自然语言查询识别它从未见过的图像。'
- en: '**LXMERT**: A model that focuses on processing both visual and text inputs.
    It can improve the performance of tasks such as answering questions with a visual
    aspect, which includes object detection.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LXMERT**：一个专注于处理视觉和文本输入的模型。它可以提高包括目标检测在内的视觉问答等任务的性能。'
- en: '**ViLBERT**: **Vision-and-Language BERT** (**ViLBERT**) extends the BERT architecture
    to process both visual and textual inputs simultaneously by using a two-stream
    model where one stream handles visual features extracted from images using a pre-trained
    **convolutional neural network** (**CNN** or **ConvNet**), and the other processes
    textual data with cross-attention layers facilitating interaction between the
    two modalities. ViLBERT is used for tasks such as visual question answering and
    visual commonsense reasoning, where understanding image-text relationships is
    essential.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ViLBERT**：**视觉和语言BERT**（**ViLBERT**）通过使用双流模型扩展了BERT架构，该模型能够同时处理视觉和文本输入。其中一个流使用预训练的**卷积神经网络**（**CNN**或**ConvNet**）从图像中提取视觉特征，另一个流使用交叉注意力层处理文本数据，促进两种模态之间的交互。ViLBERT用于视觉问答和视觉常识推理等任务，在这些任务中，理解图像和文本之间的关系至关重要。'
- en: '**VisualBERT**: Integrates visual and textual information by combining image
    features with contextualized word embeddings from a BERT-like architecture. It
    is commonly used for tasks such as image-text retrieval and image captioning,
    where aligning and understanding both visual and textual information are essential.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VisualBERT**：通过结合图像特征和来自类似BERT架构的上下文化词嵌入来整合视觉和文本信息。它通常用于图像-文本检索和图像字幕等任务，在这些任务中，对视觉和文本信息的对齐和理解至关重要。'
- en: You have now explored word, image, and multi-modal embeddings. Next, you’ll
    learn how to choose embedding models based on your application’s needs.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在已经探索了单词、图像和多模态嵌入。接下来，你将学习如何根据应用程序的需求选择嵌入模型。
- en: Choosing embedding models
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择嵌入模型
- en: Embedding models impact an application’s performance, its ability to understand
    language and other forms of data, and ultimately, a project’s success. The following
    sections look at the parameters for choosing the right embedding model that aligns
    with the task requirements, characteristics of your dataset, and computational
    resources. This section explains vector dimensionality and model leaderboards
    as additional information to consider when choosing embedding models. For a quick
    overview of this section, you can consult *Table 4.2*.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入模型影响应用程序的性能、理解语言和其他形式数据的能力，以及最终项目的成功。以下几节将探讨选择与任务需求、数据集特征和计算资源相匹配的正确嵌入模型的参数。本节解释了向量维度和模型排行榜，作为选择嵌入模型时需要考虑的附加信息。为了快速了解本节内容，你可以参考*表
    4.2*。
- en: Task requirements
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 任务需求
- en: Each type of task may benefit from different embedding models based on how they
    process and represent text data. For instance, tasks such as text classification
    and sentiment analysis often require a deep understanding of semantic relationships
    at the word level. Word2vec or GloVe are particularly beneficial in these cases,
    as they provide robust word-level embeddings that capture semantic meanings.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 根据它们处理和表示文本数据的方式，每种任务可能从不同的嵌入模型中受益。例如，文本分类和情感分析等任务通常需要深入理解单词层面的语义关系。在这种情况下，Word2vec
    或 GloVe 特别有益，因为它们提供了强大的单词级嵌入，能够捕捉语义含义。
- en: For more complex linguistic tasks such as **named entity recognition** (**NER**)
    and **part-of-speech** (**POS**) tagging, the ability to understand the context
    in which a word is used becomes critical. Here, models such as BERT or ELMo show
    their strengths as they generate embeddings that vary dynamically based on the
    surrounding text, providing a richer and more precise understanding of each word’s
    role within a sentence. This deep contextual awareness is essential for accurately
    identifying entities and tagging parts of speech, as it allows the model to differentiate
    between words with multiple meanings based on their usage.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更复杂的语言任务，如**命名实体识别**（NER）和**词性标注**（POS），理解单词使用的上下文的能力变得至关重要。在这里，BERT 或 ELMo
    等模型显示出它们的优势，因为它们根据周围的文本动态生成嵌入，提供了对每个单词在句子中角色的更丰富和更精确的理解。这种深层次的上下文意识对于准确识别实体和标注词性至关重要，因为它允许模型根据其用法区分具有多个含义的单词。
- en: Advanced models such as BERT, GPT, and Doc2vec are ideal for tasks requiring
    nuanced language understanding, such as question answering, machine translation,
    document similarity, and clustering. These models handle complex dependencies
    within text, making them suitable for analyzing entire documents. Doc2vec excels
    in comparing thematic similarities between documents, like finding similar news
    or sports articles.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如 BERT、GPT 和 Doc2vec 这样的高级模型非常适合需要细微语言理解的任务，如问答、机器翻译、文档相似性和聚类。这些模型处理文本中的复杂依赖关系，使它们适合分析整个文档。Doc2vec
    在比较文档之间的主题相似性方面表现出色，例如找到相似的新闻或体育文章。
- en: Dataset characteristics
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集特征
- en: When choosing an embedding model, consider the dataset’s size and characteristics.
    For morphologically rich languages or datasets with many OOV words, models such
    as fastText, which capture sub-word information, are advantageous. They handle
    new or rare words effectively. For texts with polysemous words (words with multiple
    meanings), contextual embeddings such as ELMo or BERT are essential, as they provide
    dynamic, context-specific representations.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择嵌入模型时，请考虑数据集的大小和特征。对于形态丰富的语言或包含许多未知单词的数据集，如 fastText 这样的模型具有优势，因为它们能够捕捉子词信息，有效地处理新词或罕见词。对于含有多义词（具有多个含义的词）的文本，如
    ELMo 或 BERT 这样的上下文嵌入至关重要，因为它们提供动态的、特定于上下文的表现形式。
- en: The dataset size influences the choice of embedding model. Larger datasets benefit
    from complex models such as BERT, GPT, and OpenAI’s `text-embedding-3-large`,
    which capture deep linguistic nuances but require substantial computational power.
    Smaller datasets might benefit from simpler models such as `text-embedding-3-small`,
    offering robust performance with less computational demand. This ensures even
    modest datasets can yield significant insights with the appropriate model.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集的大小影响嵌入模型的选择。大型数据集从复杂模型中受益，如BERT、GPT和OpenAI的`text-embedding-3-large`，这些模型能够捕捉深层次的语用细微差别，但需要大量的计算能力。小型数据集可能从简单模型中受益，如`text-embedding-3-small`，提供稳健的性能，同时计算需求较低。这确保了即使是小型数据集也能通过适当的模型获得重要的见解。
- en: Computational resources
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算资源
- en: Computational cost is crucial when selecting an embedding model due to varying
    resource demands. Larger models such as GPT-4 require extensive computational
    power, making them less accessible to smaller organizations or projects with limited
    budgets.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 由于资源需求不同，计算成本在选择嵌入模型时至关重要。像GPT-4这样的大型模型需要大量的计算能力，这使得它们对预算有限的小型组织或项目来说不太容易获得。
- en: Choosing a lightweight model or fine-tuning one for specific tasks can reduce
    computational needs, speed up development, and improve response times. Efficient
    models are essential for real-time tasks such as translation, speech recognition,
    and instant recommendations in gaming, media streaming, and e-commerce.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 选择轻量级模型或针对特定任务进行微调可以减少计算需求，加快开发速度，并提高响应时间。高效模型对于实时任务至关重要，如翻译、语音识别以及游戏、媒体流和电子商务中的即时推荐。
- en: Some level of iterative experimentation helps identify the most suitable models.
    Staying updated on the latest developments is critical, as newer models frequently
    supersede older ones. Model leaderboards can help track advancements in the field
    and are covered later in this section.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一定程度的迭代实验有助于确定最合适的模型。关注最新发展至关重要，因为新模型经常取代旧模型。模型排行榜可以帮助跟踪该领域的进展，将在本节后面进行介绍。
- en: Vector representations
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 向量表示
- en: The size of a vector in an embedding model affects its ability to capture data
    complexity. Large vectors encode more information, allowing finer distinctions,
    but require more computation. Small vectors are more efficient but might miss
    subtle nuances. Choosing a vector size involves balancing detailed representation
    with practical constraints like memory and speed.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入模型中向量的尺寸影响其捕捉数据复杂性的能力。大向量编码更多信息，允许更精细的区分，但需要更多的计算。小向量更高效，但可能会错过细微的差别。选择向量大小需要平衡详细表示与实际约束，如内存和速度。
- en: Why do vector dimensions matter?
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向量维度为什么很重要？
- en: Knowing the relationship between a vector, its size, and the second-last layer
    of a neural network is crucial for understanding the quality of the model’s output.
    The penultimate or second-last layer often serves as a feature extractor, where
    the dimensions of the output vector represent the learned features of the input
    data, as visualized in *Figure 4**.3*. The size of this vector directly influences
    the granularity of the representation.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 了解向量、其尺寸和神经网络倒数第二层之间的关系对于理解模型输出的质量至关重要。倒数第二层或第二层通常作为特征提取器，其中输出向量的维度代表输入数据学习到的特征，如图*图4**.3*所示。这个向量的尺寸直接影响表示的粒度。
- en: '![](img/B22495_04_03.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22495_04_03.jpg)'
- en: 'Figure 4.3: Penultimate layer of a neural network'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3：神经网络的最后一层
- en: To obtain these vectors, the output layer (the last layer) of the neural network
    is removed, and the output from the preceding layer—the penultimate or second-last
    layer—is captured. Typically, the final layer outputs the model’s prediction,
    prompting the use of the output from the layer just before it. The data that is
    fed into the network’s predictive layer is known as **vector embedding**.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得这些向量，神经网络输出层（最后一层）被移除，并捕获前一层的输出——倒数第二层或第二层。通常，最后一层输出模型的预测，这促使使用其前一层的输出。输入到网络预测层的这些数据被称为**向量嵌入**。
- en: The dimensionality of a vector embedding aligns with the size of the penultimate
    layer of the underlying neural network of the model being used, making it synonymous
    with the vector’s size or length. Dimensionalities such as 384 (by SBERT’s `all-MiniLM-L6-v2`),
    768 (by SBERT’s `all-mpnet-base-v2`), 1,536 (by OpenAI’s `text-embedding-ada-002`),
    and 2,048 (from ResNet-50 by Microsoft Research) are common. Larger vectors are
    becoming available now, such as 3,072 by OpenAI’s `text-embedding-3-large`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 向量嵌入的维度与所使用模型的底层神经网络的倒数第二层的大小相匹配，使其与向量的尺寸或长度同义。例如，384（由SBERT的`all-MiniLM-L6-v2`提供），768（由SBERT的`all-mpnet-base-v2`提供），1,536（由OpenAI的`text-embedding-ada-002`提供），以及2,048（由微软研究机构的ResNet-50提供）是常见的维度。现在，更大的向量也变得可用，例如OpenAI的`text-embedding-3-large`提供的3,072。
- en: What does a vector embedding mean, and how is it typically used?
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向量嵌入是什么意思，它通常是如何被使用的？
- en: Vector embeddings are the output of an embedding model, expressed as an array
    of floating-point numbers that typically range from –1.0 to +1.0\. Each position
    in the array represents a dimension.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 向量嵌入是嵌入模型的输出，表示为浮点数数组，通常范围从-1.0到+1.0。数组中的每个位置代表一个维度。
- en: Vector embeddings play a key role in context-retrieval use cases, such as semantic
    search in chatbots. Data is embedded and stored in a vector database upfront,
    and queries must use the same embedding model for accurate results. Each embedding
    model produces unique embeddings based on its training data, making them specific
    to the model’s domain and not interchangeable. For example, the embedding obtained
    from a model trained on full documents of legal text will differ from one trained
    on healthcare data for patient history.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 向量嵌入在上下文检索用例中扮演着关键角色，例如聊天机器人的语义搜索。数据预先嵌入并存储在向量数据库中，查询必须使用相同的嵌入模型才能获得准确的结果。每个嵌入模型根据其训练数据产生独特的嵌入，这使得它们特定于模型的领域，不可互换。例如，从训练在法律全文上的模型获得的嵌入将与训练在患者病史上的医疗数据模型获得的嵌入不同。
- en: 'You may recall the example of trying to find movies for *Guardians of the Galaxy*
    at the beginning of this chapter. You now understand why you had to embed the
    search string (which is also called the query vector) using the same embedding
    model. This workflow, common in AI applications, is explained in *Figure 4**.4*:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能还记得本章开头尝试为*银河护卫队*寻找电影的例子。你现在应该明白为什么你不得不使用相同的嵌入模型来嵌入搜索字符串（也称为查询向量）。这种在AI应用中常见的流程，在*图4.4*中得到了解释。4*：
- en: '![](img/B22495_04_04.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图片](img/B22495_04_04.jpg)'
- en: 'Figure 4.4: Typical data flow for embedding source data into the vector store
    and query vectors'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4：将源数据嵌入向量存储和查询向量的典型数据流
- en: 'The workflow shows the *Transform into embedding* step twice: one for embedding
    existing data into a vector database (on the left) and another for real-time embedding
    of the query (on the right). Both steps must use the same embedding model.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程显示了两次“转换为嵌入”步骤：一次是将现有数据嵌入到向量数据库中（在左侧），另一次是实时嵌入查询（在右侧）。这两个步骤都必须使用相同的嵌入模型。
- en: Embedding model leaderboards
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌入模型排行榜
- en: With such a variety of existing models and new models constantly evolving, how
    can you stay up to date? **Embedding model leaderboards**, such as those offered
    by platforms like Hugging Face, help gauge the performance of various models across
    numerous tasks. They provide transparent and competitive rankings of models based
    on criteria, such as accuracy and efficiency. By measuring models against standardized
    datasets and benchmark tasks, these leaderboards pinpoint state-of-the-art models
    and their trade-offs.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 面对如此众多的现有模型和不断涌现的新模型，你如何保持更新？**嵌入模型排行榜**，如Hugging Face等平台提供的，有助于评估各种模型在众多任务中的性能。它们基于准确性、效率等标准提供透明且具有竞争力的模型排名。通过将模型与标准数据集和基准任务进行比较，这些排行榜可以精确地指出最先进的模型及其权衡。
- en: 'The **Massive Text Embedding Benchmark** (**MTEB**) leaderboard from Hugging
    Face is a critical resource. It offers a comprehensive overview of the performance
    benchmarks of text embedding models. To see which models are setting the standard,
    visit the Hugging Face MTEB leaderboard: [https://huggingface.co/spaces/mteb/leaderboard](https://huggingface.co/spaces/mteb/leaderboard).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face的**大规模文本嵌入基准**（**MTEB**）排行榜是一个关键资源。它提供了文本嵌入模型性能基准的全面概述。要查看哪些模型正在设定标准，请访问Hugging
    Face MTEB排行榜：[https://huggingface.co/spaces/mteb/leaderboard](https://huggingface.co/spaces/mteb/leaderboard)。
- en: You can also consult other leaderboards as you select the components of your
    AI/ML application architecture. Hugging Face hosts the Open LLM leaderboard ([https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard))
    and language-specific leaderboards, such as the Open Portuguese LLM leaderboard,
    the Open Ko-LLM leaderboard (Korean), and the Spanish Embeddings leaderboard.
    There are even industry-specific leaderboards, such as the Open Medical-LLM leaderboard.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择您的 AI/ML 应用架构组件时，您还可以参考其他排行榜。Hugging Face 托管了 Open LLM 排行榜（[https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard)）以及特定语言的排行榜，例如
    Open 葡萄牙 LLM 排行榜、Open Ko-LLM 排行榜（韩语）和西班牙嵌入排行榜。甚至还有行业特定的排行榜，例如 Open 医疗-LLM 排行榜。
- en: Embedding models overview
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌入模型概述
- en: '*Table 4.2* provides a quick overview of some of the embedding models covered
    in this chapter, focusing on their quality and ease of use. Each model’s description
    includes the quality of embeddings based on factors such as accuracy in downstream
    tasks and the richness of semantic representation, ease of use, documentation
    quality, and computational requirements.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '*表 4.2* 提供了本章中涵盖的一些嵌入模型的快速概述，重点关注其质量和易用性。每个模型的描述都包括基于下游任务中的准确性、语义表示的丰富性、易用性、文档质量以及计算需求等因素的嵌入质量。'
- en: '| **Embedding model** | **Embedding quality and ease** **of use** |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| **嵌入模型** | **嵌入质量** **和易用性** |'
- en: '| --- | --- |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Word2vec | High-quality, contextually rich embeddings. Available on TensorFlow
    and others, but limited availability online. |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| Word2vec | 高质量、上下文丰富的嵌入。可在 TensorFlow 等平台上使用，但在线上可用性有限。|'
- en: '| GloVe | Robust embeddings, especially for less frequent words. Available
    on TensorFlow and others, but limited availability online. |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| GloVe | 强健的嵌入，尤其是对于不常用词汇。可在 TensorFlow 等平台上使用，但在线上可用性有限。|'
- en: '| BERT | Contextualized embeddings that are rich and adaptable. Available online.
    |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| BERT | 丰富且适应性强的上下文嵌入。可在网上找到。|'
- en: '| GPT | High-quality embeddings that excel in generative and language understanding
    tasks. Available online. |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| GPT | 在生成和语言理解任务中表现出色的优质嵌入。可在网上找到。|'
- en: '| Doc2vec | Suitable for document-level tasks; embeddings reflect broader context
    than word-level models. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| Doc2vec | 适用于文档级任务；嵌入反映了比词级模型更广泛的上下文。|'
- en: '| fastText | Captures OOV words effectively. Open source and remarkably lightweight.
    Works on standard hardware and can produce models small enough for mobile devices.
    |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| fastText | 有效地捕捉 OOV（Out-of-Vocabulary）词汇。开源且非常轻量级。在标准硬件上运行，可以生成足够小的模型，适用于移动设备。|'
- en: '| `text-embedding-3-large` | High-quality embeddings for sophisticated NLP
    tasks, capturing nuanced context. Replaced OpenAI’s `text-embedding-ada-002`.
    Can produce smaller vectors while maintaining high embedding quality. |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| `text-embedding-3-large` | 适用于复杂 NLP 任务的优质嵌入，能够捕捉细微的上下文。取代了 OpenAI 的 `text-embedding-ada-002`。在保持高嵌入质量的同时，可以生成更小的向量。|'
- en: '| `text-embedding-3-small` | Good-quality embeddings for standard NLP tasks,
    balancing performance and computational requirements. |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| `text-embedding-3-small` | 适用于标准 NLP 任务的优质嵌入，平衡性能和计算需求。|'
- en: 'Table 4.2: Embedding quality and ease of use in various embedding models'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.2：各种嵌入模型中的嵌入质量和易用性
- en: While this comparison should serve as a guide to selecting the most suitable
    embedding model for specific needs, the MTEB leaderboard mentioned previously,
    as well as online documentation, should always be consulted given the fast-moving
    development in this space.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个比较应该作为选择最适合特定需求的嵌入模型的指南，但鉴于该领域快速发展的态势，应始终参考之前提到的 MTEB 排行榜以及在线文档。
- en: Do you always need an embedding model?
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你是否总是需要一个嵌入模型？
- en: No, you don’t need an embedding model *always*. Not all situations call for
    the intricate details of an embedding model to represent data in the required
    vector form. For some applications, more straightforward vectorization methods
    are entirely adequate.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 不，你并不总是需要一个嵌入模型。并非所有情况都需要嵌入模型的复杂细节来以所需的向量形式表示数据。对于某些应用，更直接的向量化方法就足够了。
- en: In some cases, complex public embedding models or bespoke models are unnecessary.
    Tasks with narrow focus, clear rules, or structured data can thrive on simple
    vector representations. This approach suits straightforward clustering, precise
    similarity measurements, and situations with limited computing power.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，复杂的公共嵌入模型或定制模型是不必要的。那些具有狭窄焦点、明确规则或结构化数据的任务可以在简单的向量表示上蓬勃发展。这种方法适用于简单的聚类、精确的相似度测量以及计算能力有限的场合。
- en: For instance, **one-hot encoding** is a straightforward technique that turns
    categorical data into binary vectors, fitting perfectly for cases where categories
    are nominal without any intrinsic order. Similarly, **term frequency-inverse document
    frequency** (**TF-IDF**) vectors adeptly convey text significance for information
    retrieval and ranking tasks by highlighting the relevance of terms within documents
    in relation to the whole corpus.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，**独热编码**是一种简单技术，将分类数据转换为二进制向量，非常适合那些类别是名义的且没有内在顺序的情况。同样，**词频-逆文档频率**（**TF-IDF**）向量巧妙地传达了文本的重要性，通过突出显示文档中术语与整个语料库的相关性来用于信息检索和排名任务。
- en: These alternatives may lack the semantic depth of embedding models but provide
    computational efficiency and simplicity for tasks where intricate context isn’t
    required. Opting for simple vector representations enhances transparency, reduces
    computational demands or advanced scientific skill, and is ideal for swift performance
    or resource-limited environments, such as embedded systems or mobile devices.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这些替代方案可能缺乏嵌入模型的语义深度，但为那些不需要复杂上下文的任务提供了计算效率和简单性。选择简单的向量表示增强了透明度，减少了计算需求或高级科学技能，并且对于快速性能或资源受限的环境（如嵌入式系统或移动设备）来说非常理想。
- en: With your understanding of embedding models established, you can now move on
    to a practical demonstration using Python, LangChain, MongoDB Atlas, and OpenAI.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在你建立了嵌入模型的理解之后，你现在可以继续使用Python、LangChain、MongoDB Atlas和OpenAI进行实际演示。
- en: Executing code from LangChain
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行LangChain中的代码
- en: 'Now that you have explored the diverse types of embedding models, you will
    see what it is like to use them with working code. The following Python script
    (named `semantic_search.py`) uses the `langchain-openai` library to embed textual
    data with OpenAI’s `text-embedding-3-large` model, tailored to produce 1,024 dimensional
    vectors versus 3,072:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经探索了各种嵌入模型类型，你将看到使用它们的工作代码是什么样的。以下Python脚本（命名为`semantic_search.py`）使用`langchain-openai`库，结合OpenAI的`text-embedding-3-large`模型嵌入文本数据，该模型定制为产生1,024维向量而不是3,072维：
- en: '[PRE2]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The console output will be as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 控制台输出将如下所示：
- en: '[PRE3]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The example sets up the environment, authenticating to OpenAI with API keys,
    and connecting to MongoDB Atlas. Plots for three movies are then embedded and
    stored in MongoDB Atlas (the vector store) and different vector searches are then
    executed to demonstrate semantic search with ranked results.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 示例设置了环境，使用API密钥对OpenAI进行身份验证，并连接到MongoDB Atlas。然后嵌入并存储在MongoDB Atlas（向量存储）中的三个电影的图，然后执行不同的向量搜索以展示具有排序结果的语义搜索。
- en: Best practices
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最佳实践
- en: Selecting the most appropriate embedding models and vector size is not merely
    a technical decision, but a strategic one that aligns with the unique characteristics,
    technical and organizational constraints, and objectives of your project.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 选择最合适的嵌入模型和向量大小不仅是一个技术决策，而且是一个战略决策，它符合你项目的独特特征、技术和组织约束以及目标。
- en: Maintaining computational efficiency and cost is another cornerstone of effectively
    using embedding models. As some models can be resource-intensive and have higher
    response times and higher cost, optimizing the computational aspects without sacrificing
    the quality of the output is essential. Designing your system to use different
    embedding models depending on the task at hand will yield a more resilient application
    architecture.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 维护计算效率和成本是有效使用嵌入模型的另一个基石。由于某些模型可能资源密集，响应时间更长，成本更高，因此优化计算方面而不牺牲输出质量是至关重要的。根据手头的任务设计系统以使用不同的嵌入模型将产生更健壮的应用程序架构。
- en: It’s imperative to regularly evaluate your embedding model to ensure your AI/ML
    application continues to perform as expected. This involves routinely checking
    performance metrics and making necessary adjustments. Tweaking your model usage
    could mean altering vector sizes to avoid **overfitting**—where the model is too
    finely tuned to training data and performs poorly on unseen data.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 定期评估您的嵌入模型至关重要，以确保您的AI/ML应用持续按预期表现。这包括定期检查性能指标并进行必要的调整。调整模型使用可能意味着改变向量大小以避免**过拟合**——即模型对训练数据过于精细调整，在未见过的数据上表现不佳。
- en: It is essential to monitor vector search response times versus the embedding
    models being used and vector sizes, as these impact the user experience of AI-driven
    applications. Also consider the costs of maintaining and updating embedding models,
    including monetary, time, and resource expenses for re-embedding data. Planning
    for these helps make informed decisions on when updates are needed and balancing
    performance, cost-efficiency, and technological advancement.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 监控向量搜索响应时间与所使用的嵌入模型和向量大小至关重要，因为这些会影响AI驱动应用的用户体验。同时考虑维护和更新嵌入模型的成本，包括重新嵌入数据的货币、时间和资源费用。为这些计划有助于在需要更新时做出明智的决定，并平衡性能、成本效益和技术进步。
- en: Summary
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter covered the realm of embedding models, which are essential tools
    in AI/ML applications. They facilitate the transformation of high-dimensional
    data into a more manageable, lower-dimensional space. This process, known as embedding,
    significantly boosts computational efficiency and enhances the ability to describe
    and quantify relationships within data. Selecting the right embedding models for
    different types of data, such as text, audio, video, images, and structured data,
    is essential for expanding the reach of use cases and different workloads.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了嵌入模型领域，这些模型是AI/ML应用中的基本工具。它们促进了将高维数据转换为更易于管理的低维空间。这个过程称为嵌入，显著提高了计算效率，并增强了描述和量化数据中关系的能力。为不同类型的数据选择合适的嵌入模型，如文本、音频、视频、图像和结构化数据，对于扩展用例和工作负载至关重要。
- en: The chapter also highlighted the importance of consulting leaderboards to gauge
    the effectiveness across the vast list of available models and the delicate balance
    necessary when choosing vector sizes, emphasizing the trade-offs between detail,
    efficiency, performance, and cost. While embedding models provide deep, contextual
    insights, simpler vectorization methods might be adequate for certain tasks.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还强调了咨询排行榜以评估大量可用模型的有效性以及选择向量大小时所需的微妙平衡的重要性，强调了在细节、效率、性能和成本之间的权衡。虽然嵌入模型提供深入、情境化的洞察，但简单的向量化方法可能适用于某些任务。
- en: The next chapter will delve into aspects of vector databases, examining the
    role of vector search in AI/ML applications with use cases.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将深入探讨向量数据库的方面，检查向量搜索在AI/ML应用中的作用，并使用案例研究。
