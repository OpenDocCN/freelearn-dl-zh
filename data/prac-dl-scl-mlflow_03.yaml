- en: '*Chapter 2*: Getting Started with MLflow for Deep Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第二章*：使用 MLflow 开始进行深度学习'
- en: One of the key capabilities of MLflow is to enable **Machine Learning** (**ML**)
    experiment management. This is critical because data science requires reproducibility
    and traceability so that a **Deep Learning** (**DL**) model can be easily reproduced
    with the same data, code, and execution environment. This chapter will help us
    get started with how to implement DL experiment management quickly. We will learn
    about MLflow experiment management concepts and capabilities, set up an MLflow
    development environment, and complete our first DL experiment using MLflow. By
    the end of this chapter, we will have a working MLflow tracking server showing
    our first DL experiment results.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 的一个关键功能是支持**机器学习**（**ML**）实验管理。这一点至关重要，因为数据科学需要可重复性和可追溯性，这样一个**深度学习**（**DL**）模型就能使用相同的数据、代码和执行环境轻松重现。本章将帮助我们快速了解如何实施
    DL 实验管理。我们将学习 MLflow 实验管理的概念和功能，设置 MLflow 开发环境，并使用 MLflow 完成我们的第一个 DL 实验。在本章结束时，我们将拥有一个运行中的
    MLflow 跟踪服务器，展示我们的第一个 DL 实验结果。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: Setting up MLflow
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置 MLflow
- en: Implementing our first MLflow logging-enabled DL experiment
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现我们的第一个启用 MLflow 日志记录的深度学习实验
- en: Exploring MLflow's components and usage patterns
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索 MLflow 的组件和使用模式
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To complete the experiment in this chapter, we will need the following tools,
    libraries, and GitHub repositories installed or checked out on our computer:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成本章的实验，我们需要在计算机上安装或检出以下工具、库和 GitHub 仓库：
- en: 'VS Code: The version we use in this book is August 2021 (that is, version 1.60).
    We use VS Code for our local code development environment. This is the recommended
    way for local developments. Please refer to [https://code.visualstudio.com/updates/v1_60](https://code.visualstudio.com/updates/v1_60).'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VS Code：本书中使用的版本是 2021 年 8 月（即版本 1.60）。我们使用 VS Code 作为本地代码开发环境。这是推荐的本地开发方式。请参见[https://code.visualstudio.com/updates/v1_60](https://code.visualstudio.com/updates/v1_60)。
- en: 'MLflow: Version 1.20.2\. In this chapter, in the *Setting up MLflow* section,
    we will walk through how to set up MLflow locally or remotely. Please refer to
    [https://github.com/mlflow/mlflow/releases/tag/v1.20.2](https://github.com/mlflow/mlflow/releases/tag/v1.20.2).'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow：版本 1.20.2。本章的*设置 MLflow*部分将讲解如何在本地或远程设置 MLflow。请参见[https://github.com/mlflow/mlflow/releases/tag/v1.20.2](https://github.com/mlflow/mlflow/releases/tag/v1.20.2)。
- en: 'Miniconda: Version 4.10.3\. Please refer to [https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html).'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miniconda：版本 4.10.3。请参见[https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)。
- en: 'PyTorch `lightning-flash`: 0.5.0\. Please refer to [https://github.com/PyTorchLightning/lightning-flash/releases/tag/0.5.0](https://github.com/PyTorchLightning/lightning-flash/releases/tag/0.5.0).'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'PyTorch `lightning-flash`: 版本 0.5.0。请参见[https://github.com/PyTorchLightning/lightning-flash/releases/tag/0.5.0](https://github.com/PyTorchLightning/lightning-flash/releases/tag/0.5.0)。'
- en: 'The GitHub URL for the code in this chapter: You can find this at [https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/tree/main/chapter02](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/tree/main/chapter02).'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章代码的 GitHub URL：你可以在[https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/tree/main/chapter02](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/tree/main/chapter02)找到。
- en: Setting up MLflow
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 MLflow
- en: '**MLflow** is an open source tool that is primarily written in Python. It has
    over 10,000 stars tagged in its GitHub source repository ([https://github.com/mlflow/mlflow](https://github.com/mlflow/mlflow)).
    The benefits of using MLflow are numerous, but we can illustrate one benefit with
    the following scenario: Let''s say you are starting a new ML project, trying to
    evaluate different algorithms and model parameters. Within a few days, you run
    hundreds of experiments with lots of code changes using different ML/DL libraries
    and get different models with different parameters and accuracies. You need to
    compare which model works better and also allow your team members to reproduce
    the results for model review purposes. Do you prepare a spreadsheet and write
    down the model name, parameters, accuracies, and location of the models? How can
    someone else rerun your code or use your trained model with a different set of
    evaluation datasets? This can quickly become unmanageable when you have lots of
    iterations for different projects. MLflow can help you to track your experiments,
    compare your model runs and allow others to reproduce your results easily, reuse
    your trained models for review purposes, and even deploy your model to production
    with ease.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**MLflow** 是一个开源工具，主要用 Python 编写。它在 GitHub 源代码库中获得了超过 10,000 个 stars（星标）([https://github.com/mlflow/mlflow](https://github.com/mlflow/mlflow))。使用
    MLflow 的好处有很多，但我们可以通过以下场景来说明其中一个好处：假设您正在开始一个新的 ML 项目，试图评估不同的算法和模型参数。在几天之内，您运行了数百次实验，使用了不同的
    ML/DL 库，并得到了不同的模型和不同的参数与准确度。您需要比较哪个模型效果更好，并且还要让您的团队成员能够重现结果以进行模型评审。您是否准备了一份电子表格，写下模型名称、参数、准确度以及模型位置？那么，其他人如何重新运行您的代码或使用您训练的模型与不同的评估数据集进行测试呢？当您为不同的项目进行大量迭代时，这可能会变得难以管理。MLflow
    可以帮助您跟踪实验、比较模型运行，并让其他人轻松重现您的结果，重用您训练的模型进行评审，甚至轻松地将模型部署到生产环境中。'
- en: Sound exciting? Well, let's set up MLflow so that we can explore its components
    and patterns. MLflow allows both a local setup and a cloud-based setup. We will
    walk through both of these setup scenarios in the following sections.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来很令人兴奋吧？那么，来设置一下 MLflow，让我们探索它的组件和模式。MLflow 支持本地设置和基于云的设置。我们将在接下来的章节中详细介绍这两种设置场景。
- en: Setting up MLflow locally using miniconda
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 miniconda 本地设置 MLflow
- en: First, let's set up MLflow in a local development environment. This allows quick
    prototyping and helps you to get familiar with the basic functionality of the
    MLflow tool. Additionally, it allows you to interact with a remote MLflow cloud
    server when required. Follow these instructions to set up MLflow.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们在本地开发环境中设置 MLflow。这可以快速进行原型设计，并帮助您熟悉 MLflow 工具的基本功能。此外，它还允许您在需要时与远程的 MLflow
    云服务器进行交互。请按照以下说明设置 MLflow。
- en: 'Assuming you already have a virtual conda environment created from [*Chapter
    1*](B18120_01_ePub.xhtml#_idTextAnchor015), *Deep Learning Life Cycle and MLOps
    Challenges*, you are ready to install MLflow in the same virtual environment:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您已经根据 [*第一章*](B18120_01_ePub.xhtml#_idTextAnchor015)，“*深度学习生命周期与 MLOps 挑战*”创建了一个虚拟
    conda 环境，那么您可以准备在同一个虚拟环境中安装 MLflow：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding command will install the latest version of MLflow. If you want
    to install a specific version of MLflow, you can use the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将安装最新版本的 MLflow。如果您想安装特定版本的 MLflow，可以使用以下命令：
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As you can see, I have installed MLflow version 1.20.2\. By default, MLflow
    will use the local filesystem to store all of the experiment artifacts (for example,
    a serialized model) and metadata (parameters, metrics, and more). If a relational
    database is needed as MLflow''s backend storage, additional installation and configuration
    are required. For now, let''s use the filesystem for storage. You can verify your
    MLflow installation locally by typing the following into the command line:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我已安装了 MLflow 版本 1.20.2。默认情况下，MLflow 将使用本地文件系统来存储所有实验文档（例如，序列化模型）和元数据（参数、指标等）。如果需要关系型数据库作为
    MLflow 的后端存储，则需要额外的安装和配置。现在，我们先使用文件系统进行存储。您可以通过在命令行中输入以下内容来验证本地的 MLflow 安装：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, it will show the installed MLflow version, as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它将显示已安装的 MLflow 版本，如下所示：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This confirms that we have installed version 1.20.2 of MLflow on our local
    development environment. Additionally, you can launch the MLflow UI locally to
    see the MLflow tracking server UI, as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明我们已经在本地开发环境中安装了版本 1.20.2 的 MLflow。此外，您还可以在本地启动 MLflow UI，查看 MLflow 跟踪服务器
    UI，如下所示：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Following this, you will see that the UI web server is running:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将看到 UI 网页服务器正在运行：
- en: '![Figure 2.1 – Starting the MLflow UI in a local environment'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.1 – 在本地环境中启动 MLflow UI'
- en: '](img/B18120_02_001.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_001.jpg)'
- en: Figure 2.1 – Starting the MLflow UI in a local environment
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – 在本地环境中启动 MLflow UI
- en: '*Figure 2.1* shows the local MLflow UI website: `http://127.0.0.1:5000/`. If
    you click on this URL, you will see the following MLflow UI showing up in your
    browser window. Since this is a brand new MLflow installation, there is only one
    **Default** experiment with no runs under it yet (please refer to *Figure 2.2*):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.1* 显示了本地 MLflow UI 网站：`http://127.0.0.1:5000/`。如果你点击这个 URL，你将在浏览器窗口中看到如下
    MLflow UI。由于这是一个全新的 MLflow 安装，当前只有一个 **默认** 实验，且尚未有任何运行记录（请参见 *图 2.2*）：'
- en: '![Figure 2.2 – The MLflow Default Experiments UI web page'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.2 – MLflow 默认实验 UI 网页'
- en: '](img/B18120_02_002.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_002.jpg)'
- en: Figure 2.2 – The MLflow Default Experiments UI web page
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2 – MLflow 默认实验 UI 网页
- en: Seeing the default MLflow UI page up and running concludes the successful setup
    of MLflow locally with a local working MLflow tracking server.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 看到默认的 MLflow UI 页面已经成功启动，标志着本地 MLflow 跟踪服务器的成功设置。
- en: Setting up MLflow to interact with a remote MLflow server
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 MLflow 与远程 MLflow 服务器的交互
- en: 'In a corporate production environment, MLflow is usually hosted on a cloud
    server, which could be self-hosted or one of the Databricks'' managed services
    in one of the cloud providers (such as AWS, Azure, or Google Cloud). In those
    cases, there is a requirement to set up your local development environment so
    that you can run your ML/DL experiment locally but interact with the MLflow server
    remotely. Next, we will describe how to do this using environment variables with
    the help of the following three steps:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业生产环境中，MLflow 通常托管在云服务器上，可以是自托管的，也可以是 Databricks 在云提供商（如 AWS、Azure 或 Google
    Cloud）中提供的托管服务之一。在这种情况下，需要设置本地开发环境，以便能够在本地运行 ML/DL 实验，同时与远程 MLflow 服务器进行交互。接下来，我们将通过以下三个步骤介绍如何使用环境变量来实现这一目标：
- en: 'In a bash shell command-line environment, define three new environment variables
    if you are using a Databricks-managed MLflow tracking server. The first environment
    variable is `MLFLOW_TRACKING_URI`, and the assigned value is `databricks`:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 bash shell 命令行环境中，如果你正在使用 Databricks 管理的 MLflow 跟踪服务器，请定义三个新的环境变量。第一个环境变量是
    `MLFLOW_TRACKING_URI`，其值为 `databricks`：
- en: '[PRE5]'
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The second environment variable is `DATABRICKS_HOST`. If your Databricks managed
    website looks like `https://dbc-*.cloud.databricks.com/`, then that's the value
    of the `DATABRICKS_HOST` variable (replace `*` with your actual website string).
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第二个环境变量是 `DATABRICKS_HOST`。如果你的 Databricks 管理网站地址是 `https://dbc-*.cloud.databricks.com/`，那么这就是
    `DATABRICKS_HOST` 变量的值（将 `*` 替换为你的实际网站字符串）。
- en: 'The third environment variable is `DATABRICKS_TOKEN`. Navigate to your Databricks-managed
    website at `https://dbc-*.cloud.databricks.com/#setting/account`, click on **Access
    Tokens**, and then click on **Generate New Token**. You will see a pop-up window
    with a **Comment** field (which can be used to record why this token will be used)
    and expiration date, as shown in *Figure 2.3*:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三个环境变量是 `DATABRICKS_TOKEN`。前往你的 Databricks 管理网站 `https://dbc-*.cloud.databricks.com/#setting/account`，点击
    **访问令牌**，然后点击 **生成新令牌**。你将看到一个弹出窗口，其中包含一个 **备注** 字段（用于记录此令牌的用途）和过期日期，如 *图 2.3*
    所示：
- en: '![Figure 2.3 – Generating a Databricks access token'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.3 – 生成 Databricks 访问令牌'
- en: '](img/B18120_02_003.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_003.jpg)'
- en: Figure 2.3 – Generating a Databricks access token
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 – 生成 Databricks 访问令牌
- en: 'Click on the `DATABRICKS_TOKEN` environment variable as the value:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 点击 `DATABRICKS_TOKEN` 环境变量作为其值：
- en: '![Figure 2.4 – Copying the generated token that will be used for the environment
    variable'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.4 – 复制生成的令牌，将用于环境变量'
- en: '](img/B18120_02_004.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_004.jpg)'
- en: Figure 2.4 – Copying the generated token that will be used for the environment
    variable
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4 – 复制生成的令牌，将用于环境变量
- en: Once you have these three environment variables set up, you will be able to
    interact with the Databricks-managed MLflow server in the future. Note that the
    access token has an expiration date for security reasons, which can be revoked
    at any time by the administrator, so make sure you have the environment variable
    updated accordingly when the token is refreshed.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦设置好这三个环境变量，您就可以在未来与 Databricks 管理的 MLflow 服务器进行交互。请注意，出于安全原因，访问令牌有有效期，管理员可以随时撤销该令牌，因此请确保在令牌更新时及时更新环境变量。
- en: In summary, we have learned how to set up MLflow locally to interact with a
    local MLflow tracking server or a remote MLflow tracking server. This will allow
    us to implement our first MLflow tracking-enabled DL model in the next section
    so that we can explore MLflow concepts and components in a hands-on way.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们已经学会了如何在本地设置 MLflow，以便与本地 MLflow 追踪服务器或远程 MLflow 追踪服务器进行交互。这将允许我们在下一节中实现第一个启用
    MLflow 追踪的深度学习模型，从而以动手的方式探索 MLflow 的概念和组件。
- en: Implementing our first DL experiment with MLflow autologging
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 MLflow 自动日志记录实现我们的第一个深度学习实验
- en: 'Let''s use the DL sentiment classifier we built in [*Chapter 1*](B18120_01_ePub.xhtml#_idTextAnchor015),
    *Deep Learning Life Cycle and MLOps Challenges*, and add MLflow autologging to
    it to explore MLflow''s tracking capabilities:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用在 [*第 1 章*](B18120_01_ePub.xhtml#_idTextAnchor015) 中构建的深度学习情感分类器，*深度学习生命周期与
    MLOps 挑战*，并向其添加 MLflow 自动日志记录，以探索 MLflow 的追踪功能：
- en: 'First, we need to import the MLflow module:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要导入 MLflow 模块：
- en: '[PRE6]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This will provide MLflow **Application Programming Interfaces** (**APIs**) for
    logging and loading models.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为记录和加载模型提供 MLflow **应用程序编程接口** (**APIs**)。
- en: 'Just before we run the training code, we need to set up an active experiment
    using `mlflow.set_experiment` for the current running code:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在运行训练代码之前，我们需要使用 `mlflow.set_experiment` 为当前运行的代码设置一个活动实验：
- en: '[PRE7]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This sets an experiment named `dl_model_chapter02` to be the current active
    experiment. If this experiment does not exist in your current tracking server,
    it will be created automatically.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这将设置一个名为 `dl_model_chapter02` 的实验为当前活动实验。如果此实验在当前的追踪服务器中不存在，它将自动创建。
- en: Environment Variable
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 环境变量
- en: 'Note that you might need to set the tracking server URI using the `MLFLOW_TRACKING_URI`
    environment variable before you run your first experiment. If you are using a
    hosted Databricks server, implement the following:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在运行第一个实验之前，您可能需要使用 `MLFLOW_TRACKING_URI` 环境变量设置追踪服务器的 URI。如果您使用的是托管的 Databricks
    服务器，请执行以下操作：
- en: '`export MLFLOW_TRACKING_URI=databricks`'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`export MLFLOW_TRACKING_URI=databricks`'
- en: 'If you are using a local server, then set this environment variable to empty
    or the default localhost at port number `5000` as follows (note that this is our
    current section''s scenario and assumes you are using a local server):'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用的是本地服务器，则将此环境变量设置为空或默认的本地主机端口号 `5000`，如下所示（请注意，这是我们当前章节的场景，并假设您正在使用本地服务器）：
- en: '`export MLFLOW_TRACKING_URI= http://127.0.0.1:5000`'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`export MLFLOW_TRACKING_URI=http://127.0.0.1:5000`'
- en: 'Next, add one line of code to enable autologging in MLflow:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，添加一行代码以启用 MLflow 的自动日志记录功能：
- en: '[PRE8]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This will allow the default parameters, metrics, and model to be automatically
    logged to the MLflow tracking server.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这将允许默认的参数、指标和模型自动记录到 MLflow 追踪服务器。
- en: Autologging in MLflow
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 自动日志记录
- en: Autologging in MLflow is still in experiment mode (as of version 1.20.2) and
    might change in the future. Here, we use it to explore the MLflow components since
    it only requires one line of code to automatically log everything of interest.
    In the upcoming chapters, we will learn about and implement additional ways to
    perform tracking and logging in MLflow. Also, note that currently, autologging
    in MLflow for PyTorch (as of version 1.20.2) only works for the PyTorch Lightning
    framework, not any arbitrary PyTorch code.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 中的自动日志记录仍处于实验模式（截至版本 1.20.2），未来可能会发生变化。在这里，我们使用它来探索 MLflow 组件，因为只需要一行代码就能自动记录所有相关信息。在接下来的章节中，我们将学习并实现更多关于在
    MLflow 中进行追踪和日志记录的方法。此外，请注意，目前 MLflow 中的 PyTorch 自动日志记录（截至版本 1.20.2）仅适用于 PyTorch
    Lightning 框架，而不适用于任意的 PyTorch 代码。
- en: 'Use the Python context manager `with` statement to start the experiment run
    by calling `mlflow.start_run`:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Python 上下文管理器 `with` 语句，通过调用 `mlflow.start_run` 来开始实验运行：
- en: '[PRE9]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Notice that all lines of code underneath the `with` block are the regular DL
    model fine-tuning and testing steps. We only enable automatic MLflow logging so
    that we can observe the metadata that is being tracked/logged by the MLflow tracking
    server.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`with` 块下方的所有代码行都是常规的 DL 模型微调和测试步骤。我们只是启用了自动 MLflow 日志记录，这样我们就可以观察到 MLflow
    跟踪服务器记录的元数据。
- en: 'Next, you can run the entire code of `first_dl_with_mlflow.py` (the full code
    can be viewed in this chapter''s GitHub at [https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/blob/main/chapter02/first_dl_with_mlflow.py](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/blob/main/chapter02/first_dl_with_mlflow.py))
    using the following command line:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你可以使用以下命令行运行整个 `first_dl_with_mlflow.py` 的代码（完整代码可以在本章的 GitHub 上查看：[https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/blob/main/chapter02/first_dl_with_mlflow.py](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow/blob/main/chapter02/first_dl_with_mlflow.py)）：
- en: '[PRE10]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'On a non-GPU macOS laptop, the entire run takes less than 10 minutes. You should
    have an output on your screen, as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有 GPU 的 macOS 笔记本上，整个运行过程不到 10 分钟。你应该能在屏幕上看到以下输出：
- en: '![Figure 2.5 – DL model training/testing with MLflow autologging enabled'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.5 – 启用 MLflow 自动日志记录的 DL 模型训练/测试'
- en: '](img/B18120_02_005.jpg)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_005.jpg)'
- en: Figure 2.5 – DL model training/testing with MLflow autologging enabled
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5 – 启用 MLflow 自动日志记录的 DL 模型训练/测试
- en: 'If you are running this for the first time, you will see that the experiment
    with the name of `dl_model_chapter02` does not exist. Instead, MLflow automatically
    creates this experiment for you:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是你第一次运行，你会看到名为 `dl_model_chapter02` 的实验不存在。相反，MLflow 会为你自动创建这个实验：
- en: '![Figure 2.6 – MLflow automatically creates a new environment if it does not
    exist'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.6 – 如果环境不存在，MLflow 会自动创建一个新的环境'
- en: '](img/B18120_02_006.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_006.jpg)'
- en: Figure 2.6 – MLflow automatically creates a new environment if it does not exist
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 – 如果环境不存在，MLflow 会自动创建一个新的环境
- en: 'Now, we can open the MLflow UI locally to see what has been logged in the local
    tracking server by navigating to `http://127.0.0.1:5000/`. Here, you will see
    that a new experiment (`dl_model_chapter02`) with a new run (`chapter02`) has
    been logged:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以在本地打开 MLflow UI，通过访问 `http://127.0.0.1:5000/` 来查看本地跟踪服务器记录的内容。在这里，你会看到一个新的实验（`dl_model_chapter02`）和一个新的运行（`chapter02`）已被记录：
- en: '![Figure 2.7 – The MLflow tracking server UI shows a new experiment with a
    new run'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.7 – MLflow 跟踪服务器 UI 显示一个新的实验和新的运行'
- en: '](img/B18120_02_007.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_007.jpg)'
- en: Figure 2.7 – The MLflow tracking server UI shows a new experiment with a new
    run
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7 – MLflow 跟踪服务器 UI 显示一个新的实验和新的运行
- en: 'Now, click on the hyperlink of the **Start Time** column in *Figure 2.7*. You
    will see the details of the logged metadata of the run:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，点击 *图 2.7* 中 **开始时间** 列的超链接。你将看到该运行记录的元数据详情：
- en: '![Figure 2.8 – The MLflow run UI shows the metadata details about the experiment
    run'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.8 – MLflow 运行 UI 显示实验运行的元数据详情'
- en: '](img/B18120_02_008.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_008.jpg)'
- en: Figure 2.8 – The MLflow run UI shows the metadata details about the experiment
    run
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.8 – MLflow 运行 UI 显示实验运行的元数据详情
- en: If you can view this screen in your own local environment, then congratulations!
    You just completed the implementation of MLflow tracking for our first DL model!
    In the next section, we will explore central concepts and components in MLflow
    using our working example.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你能在自己的本地环境中看到这个屏幕，那么恭喜你！你刚刚完成了我们第一个 DL 模型的 MLflow 跟踪实现！在下一节中，我们将通过实际示例来探索
    MLflow 的核心概念和组件。
- en: Exploring MLflow's components and usage patterns
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索 MLflow 的组件和使用模式
- en: Let's use the working example implemented in the previous section to explore
    the following central concepts, components, and usages in MLflow. These include
    experiments, runs, metadata about experiments, artifacts for experiments, models,
    and code.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用上一节中实现的工作示例，探索 MLflow 中以下核心概念、组件和用法。这些包括实验、运行、实验的元数据、实验的工件、模型和代码。
- en: Exploring experiments and runs in MLflow
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 MLflow 中探索实验和运行
- en: '**Experiment** is a first-class entity in the MLflow APIs. This makes sense
    as data scientists and ML engineers need to run lots of experiments in order to
    build a working model that meets the requirements. However, the idea of an experiment
    goes beyond just the model development stage and extends to the entire life cycle
    of the ML/DL development and deployment. So, this means that when we do retraining
    or training for a production version of the model, we need to treat them as *production-quality*
    experiments. This unified view of experiments builds a bridge between the offline
    and online production environments. Each experiment consists of many runs where
    you can either change the model parameters, input data, or even model type for
    each run. So, an experiment is an umbrella entity containing a series of runs.
    The following diagram (*Figure 2.9*) illustrates that a data scientist could carry
    out both offline experiments and online production experiments across multiple
    stages of the life cycle of ML/DL models:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**实验** 是 MLflow APIs 中的一等实体。这是有道理的，因为数据科学家和 ML 工程师需要运行大量实验，以构建符合要求的工作模型。然而，实验的概念不仅限于模型开发阶段，还延伸到整个
    ML/DL 开发和部署的生命周期。因此，这意味着当我们对模型进行重训练或为生产版本进行训练时，我们需要将它们视为*生产质量*实验。这种对实验的统一视图建立了线下和线上生产环境之间的桥梁。每个实验由许多运行组成，您可以在每次运行时更改模型参数、输入数据，甚至是模型类型。因此，实验是一个包含一系列运行的总体实体。下图（*图
    2.9*）说明了数据科学家可以在 ML/DL 模型生命周期的多个阶段进行线下实验和在线生产实验：'
- en: '![Figure 2.9 – Experiments across the offline and online production life cycles
    of ML/DL models'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.9 – 跨机器学习（ML）/深度学习（DL）模型线下和线上生产生命周期的实验'
- en: '](img/B18120_02_009.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_009.jpg)'
- en: Figure 2.9 – Experiments across the offline and online production life cycles
    of ML/DL models
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9 – 跨机器学习（ML）/深度学习（DL）模型线下和线上生产生命周期的实验
- en: As you can see from *Figure 2.9*, during the model development stage, a data
    scientist could run multiple runs of the same experiment or multiple experiments
    depending on the project scenarios. If it is a small ML project, having all runs
    under one single offline experiment could be enough. If it is a complex ML project,
    it is reasonable to design different experiments and conduct runs under each experiment.
    A good reference for designing ML experiments can be found at [https://machinelearningmastery.com/controlled-experiments-in-machine-learning/](https://machinelearningmastery.com/controlled-experiments-in-machine-learning/).
    Then, during the model production phase, it is desirable to set up production-quality
    experiments, as we need to perform model improvement and continuous deployment
    with model retraining. A production experiment will provide a gated accuracy check
    to prevent regression of the new model. Often, this is achieved by running automatic
    model evaluation and validation against a hold-out test dataset to check whether
    a new model still meets the release bar in terms of accuracy.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如您从*图 2.9*中所见，在模型开发阶段，数据科学家可以根据项目情况运行多个相同实验的运行或多个实验。如果是一个小型 ML 项目，将所有运行放在一个单一的线下实验中可能足够了。如果是一个复杂的
    ML 项目，则设计不同的实验并在每个实验下进行运行是合理的。关于设计 ML 实验的良好参考资料可以在[https://machinelearningmastery.com/controlled-experiments-in-machine-learning/](https://machinelearningmastery.com/controlled-experiments-in-machine-learning/)找到。然后，在模型生产阶段，最好设置生产质量的实验，因为我们需要进行模型改进和连续部署与模型重训练。生产实验将提供一个门控准确性检查，以防止新模型的回归。通常，这是通过运行自动模型评估和针对保留测试数据集的验证来实现的，以检查新模型在准确性方面是否仍符合发布标准。
- en: 'Now, let''s explore the MLflow experiments in a hands-on way. Run the following
    MLflow command line to interact with the tracking server:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们以实际操作的方式探索 MLflow 实验。运行以下 MLflow 命令行与跟踪服务器进行交互：
- en: '[PRE11]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'If your `MLFLOW_TRACKING_URI` environment variable points to a remote tracking
    server, then it will list all the experiments that you have read access to. If
    you want to see what''s in the local tracking server, you could set `MLFLOW_TRACKING_URI`
    to nothing (that is, empty), as follows (note that you don''t need to do this
    if you have never had this environment variable in your local user profile; however,
    doing this will make sure you use a local tracking server):'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的`MLFLOW_TRACKING_URI`环境变量指向远程跟踪服务器，则将列出您具有读取权限的所有实验。如果要查看本地跟踪服务器中的内容，可以将`MLFLOW_TRACKING_URI`设置为空（即为空），如下所示（请注意，如果您的本地用户配置文件中从未有过此环境变量，则无需执行此操作；但是，执行此操作将确保您使用本地跟踪服务器）：
- en: '[PRE12]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Prior to your first implementation of the DL model with MLflow autologging
    enabled, the output of listing all your experiments should look similar to *Figure
    2.10* (note that this also depends on where you run the command line; the following
    output assumes you run the command in your local folder where you can check the
    code for [*Chapter 2*](B18120_02_ePub.xhtml#_idTextAnchor027) on GitHub):'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在你第一次实现启用 MLflow 自动日志记录的 DL 模型之前，列出所有实验的输出应类似于 *图 2.10*（注意，这也取决于你运行命令行的位置；以下输出假设你在本地文件夹中运行该命令，并且可以查看
    [*第 2 章*](B18120_02_ePub.xhtml#_idTextAnchor027) 的 GitHub 代码）：
- en: '![Figure 2.10 – The default MLflow experiment list in a local environment'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.10 – 本地环境中默认的 MLflow 实验列表'
- en: '](img/B18120_02_010.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_010.jpg)'
- en: Figure 2.10 – The default MLflow experiment list in a local environment
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10 – 本地环境中默认的 MLflow 实验列表
- en: '*Figure 2.10* lists the three columns of the experiment property: `mlruns`
    folder underneath the directory where you execute the MLflow commands). The `mlruns`
    folder is used by a filesystem-based MLflow tracking server to store all the metadata
    of experiment runs and artifacts.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.10* 列出了实验属性的三列：`mlruns` 文件夹（位于执行 MLflow 命令的目录下）。`mlruns` 文件夹由基于文件系统的 MLflow
    跟踪服务器使用，用于存储所有实验运行和工件的元数据。'
- en: The Command-Line Interface (CLI) versus REST APIs versus Programming Language-Specific
    APIs
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 命令行界面（CLI）与 REST API 与编程语言特定的 API
- en: MLflow provides three different types of tools and APIs to interact with the
    tracking server. Here, the CLI is used so that we can explore the MLflow components.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 提供了三种不同类型的工具和 API 与跟踪服务器进行交互。在这里，我们使用 CLI 来探索 MLflow 组件。
- en: 'So, let''s explore a specific MLflow experiment, as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们探索一个特定的 MLflow 实验，如下所示：
- en: 'First, create a new experiment using the MLflow CLI, as follows:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，使用 MLflow CLI 创建一个新的实验，如下所示：
- en: '[PRE13]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The preceding command creates a new experiment named `dl_model_chapter02`.
    If you have already run the first DL model with MLflow autologging in the previous
    section, the preceding command will cause an error message, as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令创建了一个名为 `dl_model_chapter02` 的新实验。如果你在前一节已经使用 MLflow 自动日志记录运行了第一个 DL 模型，执行上述命令将会报错，如下所示：
- en: '[PRE14]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This is to be expected, and you have done nothing wrong. Now if you list all
    the experiments in the local tracking server, it should include the newly created
    experiment, as shown here:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期的结果，你并没有做错什么。现在，如果你列出本地跟踪服务器上的所有实验，它应该会包括刚创建的实验，如下所示：
- en: '![Figure 2.11 – The new MLflow experiments list after creating a new experiment'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.11 – 创建新实验后，新的 MLflow 实验列表'
- en: '](img/B18120_02_011.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_011.jpg)'
- en: Figure 2.11 – The new MLflow experiments list after creating a new experiment
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11 – 创建新实验后，新的 MLflow 实验列表
- en: 'Now, let''s examine the relationship between experiments and runs. If you look
    carefully at the URL of the run page (*Figure 2.8*), you will see something similar
    to the following:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们检查实验与运行之间的关系。如果你仔细查看运行页面的 URL (*图 2.8*)，你将看到类似以下内容：
- en: '`http://127.0.0.1:5000/#/experiments/1/runs/2f2ec6e72a5042f891abe0d3a533eec7`'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`http://127.0.0.1:5000/#/experiments/1/runs/2f2ec6e72a5042f891abe0d3a533eec7`'
- en: As you might have gathered, the integer after the `experiments` path is the
    experiment ID. Then, after the experiment ID, there is a `runs` path, followed
    by a GUID-like random string, which is the run ID. So, now we understand how the
    runs are organized under the experiment with a globally unique ID (called a run
    ID).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经理解的那样，`experiments` 路径后的整数就是实验的 ID。然后，在实验 ID 后面，有一个 `runs` 路径，接着是一个类似
    GUID 的随机字符串，这就是运行 ID。所以，现在我们了解了如何通过一个全球唯一的 ID（称为运行 ID）组织实验下的运行。
- en: 'Knowing a run''s globally unique ID is very useful. This is because we can
    retrieve the run''s logged data using `run_id`. If you use the `mlflow runs describe
    --run-id <run_id>` command line, you can get the list of metadata that this run
    has logged. For the experiment we just ran, the following shows the full command
    with the run ID:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 知道运行的全球唯一 ID 非常有用。因为我们可以通过 `run_id` 检索该运行的日志数据。如果你使用命令 `mlflow runs describe
    --run-id <run_id>`，你可以获得该运行记录的元数据列表。对于我们刚才运行的实验，下面显示了包含运行 ID 的完整命令：
- en: '[PRE15]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The output snippets of this command line are as follows (*Figure 2.12*):'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令行的输出片段如下 (*图 2.12*)：
- en: '![Figure 2.12 – The MLflow command line describes the run in the JSON data
    format'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.12 – MLflow 命令行以 JSON 数据格式描述运行'
- en: '](img/B18120_02_012.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_012.jpg)'
- en: Figure 2.12 – The MLflow command line describes the run in the JSON data format
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.12 – MLflow 命令行以 JSON 数据格式描述运行
- en: Note that *Figure 2.12* presents all the metadata about this run in JSON format.
    This metadata includes parameters used by the model training; metrics for measuring
    the accuracy of the model in training, validation, and testing; and more. The
    same data is also presented in the MLflow UI in *Figure 2.8*. Note that the powerful
    MLflow CLI will allow very convenient exploration of the MLflow logged metadata
    and artifacts as well as enabling shell script-based automation, as we will explore
    in the upcoming chapters.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，*图 2.12* 展示了以 JSON 格式呈现的该运行的所有元数据。这些元数据包括模型训练过程中使用的参数；用于衡量模型在训练、验证和测试中的准确度的度量标准等。相同的数据也会在
    MLflow 用户界面中以 *图 2.8* 的形式展示。请注意，强大的 MLflow 命令行界面（CLI）将允许非常方便地探索 MLflow 记录的元数据和工件，并支持基于
    shell 脚本的自动化，这将在接下来的章节中进一步探讨。
- en: Exploring MLflow models and their usages
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 MLflow 模型及其用途
- en: 'Now, let''s explore how the DL model artifacts are logged in the MLflow tracking
    server. On the same run page, as shown in *Figure 2.8*, if you scroll down toward
    the bottom, you will see the Artifacts section (*Figure 2.13*). This lists all
    the metadata regarding the model and the serialized model itself:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们探索在 MLflow 跟踪服务器中如何记录 DL 模型工件。在同一运行页面上，如 *图 2.8* 所示，如果你向下滚动到页面底部，你将看到工件部分（*图
    2.13*）。这里列出了有关模型的所有元数据和序列化模型本身：
- en: '![Figure 2.13 – The model artifacts logged by MLflow'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.13 – MLflow 记录的模型工件'
- en: '](img/B18120_02_013.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_013.jpg)'
- en: Figure 2.13 – The model artifacts logged by MLflow
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.13 – MLflow 记录的模型工件
- en: The MLflow Tracking Server's Backend Store and Artifact Store
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 跟踪服务器的后端存储和工件存储
- en: 'An MLflow tracking server has two types of storage: first, a backend store,
    which stores experiments and runs metadata along with params, metrics, and tags
    for runs; and second, an artifact store, which stores larger files such as serialized
    models, text files, or even generated plots for visualizing model results. For
    the purpose of simplicity, in this chapter, we are using a local filesystem for
    both the backend store and the artifact store. However, some of the more advanced
    features such as model registry are not available in a filesystem-based artifact
    store. In later chapters, we will learn how to use a model registry.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 跟踪服务器有两种类型的存储：第一种是后端存储，用于存储实验和运行的元数据，以及运行的参数、度量标准和标签；第二种是工件存储，用于存储较大的文件，如序列化的模型、文本文件，甚至是生成的可视化图表。为了简化起见，本章中我们使用本地文件系统作为后端存储和工件存储。然而，像模型注册表等一些更高级的功能在基于文件系统的工件存储中不可用。在后续章节中，我们将学习如何使用模型注册表。
- en: 'Let''s look at the list of artifacts, one by one:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一查看这些工件列表：
- en: '`model_summary.txt`: At the `root` folder level, this file looks similar to
    the following output if you click on it. It describes the model metrics and the
    layers of the DL model (please refer to *Figure 2.14*):'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model_summary.txt`：在 `root` 文件夹级别，这个文件点击后看起来类似于以下输出。它描述了模型的度量标准和深度学习（DL）模型的层次结构（请参见
    *图 2.14*）：'
- en: '![Figure 2.14 – The model summary file logged by MLflow'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.14 – MLflow 记录的模型摘要文件'
- en: '](img/B18120_02_014.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_014.jpg)'
- en: Figure 2.14 – The model summary file logged by MLflow
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.14 – MLflow 记录的模型摘要文件
- en: '*Figure 2.14* provides a quick overview of what the DL model looks like in
    terms of the number and type of neural network layers, the number and size of
    the parameters, and the type of metrics used in training and validation. This
    is very helpful when the DL model architecture is needed to be shared and communicated
    among team members or stakeholders.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.14* 提供了 DL 模型的简要概述，包括神经网络层的数量和类型、参数的数量和大小，以及训练和验证中使用的度量标准类型。当需要在团队成员或利益相关者之间共享和交流
    DL 模型架构时，这非常有帮助。'
- en: 'The `model` folder: This folder contains a subfolder, called `data`, and three
    files called `MLmodel`, `conda.yaml`, and `requirements.txt`:'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`model` 文件夹：此文件夹包含一个名为 `data` 的子文件夹，并且包含三个文件：`MLmodel`、`conda.yaml` 和 `requirements.txt`：'
- en: '`MLmodel`: This file describes the flavor of the model that MLflow supports.
    `MLmodel` file (*Figure 2.15*):'
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MLmodel`：此文件描述了 MLflow 支持的模型类型。`MLmodel` 文件（*图 2.15*）：'
- en: '![Figure 2.15 – Content of the MLmodel file for our first DL model run with
    MLflow'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.15 – 我们首次使用 MLflow 运行的 DL 模型的 MLmodel 文件内容'
- en: '](img/B18120_02_015.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_015.jpg)'
- en: Figure 2.15 – Content of the MLmodel file for our first DL model run with MLflow
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.15 – 我们首次使用 MLflow 运行的 DL 模型的 MLmodel 文件内容
- en: '*Figure 2.15* illustrates that this is a PyTorch flavor model with `run_id`
    that we have just run.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 2.15* 展示了这是一个 PyTorch 类型的模型，并且我们刚刚运行了具有 `run_id` 的模型。'
- en: '`conda.yaml`: This is a conda environment definition file used by the model
    to describe our dependencies. *Figure 2.16* lists the content logged by MLflow
    in the run we just completed:'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`conda.yaml`: 这是模型使用的 conda 环境定义文件，用于描述我们的依赖关系。*图 2.16* 列出了 MLflow 在我们刚刚完成的运行中记录的内容：'
- en: '![Figure 2.16 – The content of the conda.yaml file logged by MLflow'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.16 – MLflow 记录的 conda.yaml 文件的内容'
- en: '](img/B18120_02_016.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18120_02_016.jpg)'
- en: Figure 2.16 – The content of the conda.yaml file logged by MLflow
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.16 – MLflow 记录的 conda.yaml 文件的内容
- en: '`requirements.txt`: This is a Python `pip`-specific dependency definition file.
    It is just like the `pip` section in the `conda.yaml` file, as shown in *Figure
    2.16*.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requirements.txt`: 这是一个特定于 Python `pip` 的依赖定义文件。它就像 *图 2.16* 中 `conda.yaml`
    文件中的 `pip` 部分一样。'
- en: '`data`: This is a folder that contains the actual serialized model, called
    `model.pth`, and a description file, called `pickle_module_info.txt`, whose content
    for our first DL experiment is as follows:'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`data`: 这是一个包含实际序列化模型的文件夹，名为 `model.pth`，以及一个描述文件，名为 `pickle_module_info.txt`，我们第一个
    DL 实验的内容如下：'
- en: '[PRE16]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This means the model is serialized using a PyTorch-compatible pickle serialization
    method provided by MLflow. This allows MLflow to load the model back to memory
    later if needed.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着模型使用了 MLflow 提供的 PyTorch 兼容的 pickle 序列化方法进行序列化。这允许 MLflow 在需要时重新加载模型到内存中。
- en: Model Registry versus Model Logging
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 模型注册表与模型日志记录
- en: The MLflow model registry requires a relational database such as MySQL as the
    artifact store, not just a plain filesystem. Therefore, in this chapter, we will
    not explore it yet. Note that a model registry is different from model logging
    in that, for each run, you want to log model metadata and artifacts. However,
    only for certain runs that meet your production requirements, you may want to
    register them in the model registry for production deployment and version control.
    In later chapters, we will learn how to register models.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: MLflow 模型注册表需要关系数据库，如 MySQL，作为工件存储，而不仅仅是普通的文件系统。因此，在本章中我们不会深入探讨它。请注意，模型注册表与模型日志记录不同，对于每次运行，您希望记录模型的元数据和工件。但是，仅对符合您的生产要求的特定运行，您可能希望将它们注册到模型注册表以进行生产部署和版本控制。在后续章节中，我们将学习如何注册模型。
- en: By now, you should have a good understanding of the list of files and metadata
    about the model and the serialized model (along with the `.pth` file extension
    in our experiment, which refers to a PyTorch serialized model) logged in the MLflow
    artifact store. In the upcoming chapters, we will learn more about how the MLflow
    model flavor works and how to use the logged model for model registry and deployment.
    MLflow model flavors are model frameworks such as PyTorch, TensorFlow, and scikit-learn,
    which are supported by MLflow. Interested readers can find more details about
    the current built-in model flavors supported by MLflow from the official MLflow
    documentation site at [https://www.mlflow.org/docs/latest/models.html#built-in-model-flavors](https://www.mlflow.org/docs/latest/models.html#built-in-model-flavors).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您应该对我们实验中的文件列表和关于模型以及序列化模型的元数据有了很好的理解（包括我们实验中的 `.pth` 文件扩展名，这指的是 PyTorch
    序列化模型）。在接下来的章节中，我们将学习更多关于 MLflow 模型风格的工作原理以及如何将记录的模型用于模型注册和部署。MLflow 模型风格是 MLflow
    支持的模型框架，如 PyTorch、TensorFlow 和 scikit-learn。有兴趣的读者可以在 MLflow 官方文档网站上找到关于当前内置模型风格的更多详细信息，网址为
    [https://www.mlflow.org/docs/latest/models.html#built-in-model-flavors](https://www.mlflow.org/docs/latest/models.html#built-in-model-flavors)。
- en: Exploring MLflow code tracking and its usages
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 MLflow 代码跟踪及其用法
- en: 'When exploring the metadata of the run, we can also discover how the code is
    being tracked. As shown in the MLflow UI and the command-line output in JSON,
    the code is tracked in three ways: a filename, a Git commit hash, and a source
    type. You can execute the following command line:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当探索运行的元数据时，我们还可以发现代码是如何被跟踪的。如 MLflow UI 和 JSON 中的命令行输出所示，代码以三种方式进行跟踪：文件名、Git
    提交哈希和源类型。您可以执行以下命令行：
- en: '[PRE17]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'You should be able to find the following segments of JSON key-value pairs in
    the output:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能在输出中找到以下 JSON 键值对的片段：
- en: '[PRE18]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Based on this `ad6c7338a416ff4c2848d726b092057457c22408` Git commit hash, we
    can go on to find the exact copy of the Python code we used: [https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/blob/ad6c7338a416ff4c2848d726b092057457c22408/chapter02/first_dl_with_mlflow.py](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/blob/ad6c7338a416ff4c2848d726b092057457c22408/chapter02/first_dl_with_mlflow.py).'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 基于这个`ad6c7338a416ff4c2848d726b092057457c22408`的Git提交哈希，我们可以继续查找我们使用的Python代码的确切副本：[https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/blob/ad6c7338a416ff4c2848d726b092057457c22408/chapter02/first_dl_with_mlflow.py](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/blob/ad6c7338a416ff4c2848d726b092057457c22408/chapter02/first_dl_with_mlflow.py)。
- en: Note that, here, the source type is `LOCAL`. This means that we execute the
    MLflow-enabled source code from a local copy of the code. In later chapters, we
    will learn about other source types.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这里的源类型是`LOCAL`。这意味着我们从代码的本地副本中执行启用MLflow的源代码。在后面的章节中，我们将了解其他源类型。
- en: LOCAL versus Remote GitHub Code
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 本地与远程GitHub代码
- en: 'If the source is a local copy of the code, there is a caveat regarding the
    Git commit hash that you see in the MLflow tracking server. If you make code changes
    locally but forget to commit them and then immediately start an MLflow experiment
    tracking run, MLflow will only log the most recent Git commit hash. We can solve
    this problem in one of two ways:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 如果源代码是本地副本，那么在MLflow跟踪服务器中看到的Git提交哈希存在一个警告。如果你在本地做了代码更改，但忘记提交它们，然后立即开始MLflow实验跟踪运行，MLflow只会记录最近的Git提交哈希。我们可以通过两种方式解决这个问题：
- en: 1\. Commit our code changes before running the MLflow experiment.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 在运行MLflow实验之前提交我们的代码更改。
- en: 2\. Use remote GitHub code to run the experiment.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 使用远程GitHub代码运行实验。
- en: Since the first method is not easily enforceable, the second method is preferred.
    Using remote GitHub code to run a DL experiment is an advanced topic that we will
    explore in later chapters.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 由于第一种方法不容易强制执行，因此推荐使用第二种方法。使用远程GitHub代码运行DL实验是一个高级话题，我们将在后面的章节中探讨。
- en: So far, we have learned about the MLflow tracking server, experiments, and runs.
    Additionally, we have logged metadata about runs such as parameters and metrics,
    examined code tracking, and explored model logging. These tracking and logging
    capabilities ensure that we have a solid ML experiment management system, not
    only for model development but also for model deployment in the future, as we
    need to track which runs produce the model for production. *Reproducibility* and
    *provenance-tracking* are the hallmarks of what MLflow provides. In addition to
    this, MLflow provides other components such as **MLproject** for standardized
    ML project code organization, a model registry for model versioning control, model
    deployment capabilities, and model explainability tools. All of these MLflow components
    cover the whole life cycle of ML/DL development, deployment, and production, which
    we will examine in more depth in future chapters.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了MLflow跟踪服务器、实验和运行。此外，我们还记录了关于运行的元数据，如参数和指标，检查了代码跟踪，并探讨了模型日志记录。这些跟踪和日志记录功能确保我们有一个扎实的ML实验管理系统，不仅用于模型开发，还为未来的模型部署提供支持，因为我们需要跟踪哪些运行生成了用于生产的模型。*可重复性*和*来源追踪*是MLflow提供的标志性特点。除此之外，MLflow还提供了其他组件，如用于标准化ML项目代码组织的**MLproject**、用于模型版本控制的模型注册表、模型部署功能和模型可解释性工具。所有这些MLflow组件涵盖了ML/DL开发、部署和生产的整个生命周期，我们将在后续章节中更深入地探讨这些内容。
- en: Summary
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned how to set up MLflow to work with either a local
    MLflow tracking server or a remote MLflow tracking server. Then, we implemented
    our first DL model with MLflow autologging enabled. This allowed us to explore
    MLflow in a hands-on way to understand a few central concepts and foundational
    components such as experiments, runs, metadata about experiments and runs, code
    tracking, model logging, and model flavor. The knowledge and first-round experiences
    gained in this chapter will help us to learn more in-depth MLflow tracking APIs
    in the next chapter.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何设置MLflow，使其与本地MLflow跟踪服务器或远程MLflow跟踪服务器一起工作。然后，我们实现了第一个启用自动日志记录的DL模型。这样，我们就可以通过实践的方式探索MLflow，理解一些核心概念和基础组件，如实验、运行、实验和运行的元数据、代码跟踪、模型日志记录和模型风味。本章中获得的知识和首次经验将帮助我们在下一章深入学习MLflow跟踪API。
- en: Further reading
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To further your knowledge, you can consult the following resources and documentation:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步拓展你的知识，你可以参考以下资源和文档：
- en: 'The MLflow *Command-Line Interface* documentation: [https://www.mlflow.org/docs/latest/cli.html](https://www.mlflow.org/docs/latest/cli.html)'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow *命令行接口* 文档：[https://www.mlflow.org/docs/latest/cli.html](https://www.mlflow.org/docs/latest/cli.html)
- en: 'The MLflow PyTorch autologging documentation: [https://www.mlflow.org/docs/latest/tracking.html#pytorch-experimental](https://www.mlflow.org/docs/latest/tracking.html#pytorch-experimental)'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow PyTorch自动记录文档：[https://www.mlflow.org/docs/latest/tracking.html#pytorch-experimental](https://www.mlflow.org/docs/latest/tracking.html#pytorch-experimental)
- en: 'The MLflow PyTorch model flavor documentation: [https://www.mlflow.org/docs/latest/python_api/mlflow.pytorch.html#module-mlflow.pytorch](https://www.mlflow.org/docs/latest/python_api/mlflow.pytorch.html#module-mlflow.pytorch)'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MLflow PyTorch模型风味文档：[https://www.mlflow.org/docs/latest/python_api/mlflow.pytorch.html#module-mlflow.pytorch](https://www.mlflow.org/docs/latest/python_api/mlflow.pytorch.html#module-mlflow.pytorch)
- en: '*MLflow and PyTorch — Where Cutting Edge AI meets MLOps*: [https://medium.com/pytorch/mlflow-and-pytorch-where-cutting-edge-ai-meets-mlops-1985cf8aa789](https://medium.com/pytorch/mlflow-and-pytorch-where-cutting-edge-ai-meets-mlops-1985cf8aa789)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*MLflow与PyTorch——前沿AI与MLOps的结合*：[https://medium.com/pytorch/mlflow-and-pytorch-where-cutting-edge-ai-meets-mlops-1985cf8aa789](https://medium.com/pytorch/mlflow-and-pytorch-where-cutting-edge-ai-meets-mlops-1985cf8aa789)'
- en: '*Controlled Experiments in Machine Learning*: [https://machinelearningmastery.com/controlled-experiments-in-machine-learning/](https://machinelearningmastery.com/controlled-experiments-in-machine-learning/)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*机器学习中的对照实验*：[https://machinelearningmastery.com/controlled-experiments-in-machine-learning/](https://machinelearningmastery.com/controlled-experiments-in-machine-learning/)'
