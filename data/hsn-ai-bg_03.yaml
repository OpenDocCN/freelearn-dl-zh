- en: Platforms and Other Essentials
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 平台和其他必需品
- en: 'In this chapter, we''ll discuss important libraries and frameworks that one
    needs to get started in **Artificial Intelligence** (**AI**). We''ll cover the
    basic functions of the three most popular deep learning frameworks—TensorFlow,
    PyTorch, and Keras—show you how to get up and running in each of these frameworks,
    as we will be utilizing them in the following chapters. We''ll touch upon computing
    for AI, and discuss how GPUs and other advanced memory units can improve it. Lastly,
    we''ll discuss the fundamentals of two popular cloud computing frameworks for
    deep learning: AWS and Google Cloud.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论重要的库和框架，以便开始**人工智能**（**AI**）。我们将介绍三种最流行的深度学习框架——TensorFlow、PyTorch
    和 Keras——的基本功能，展示如何在每个框架中启动和运行，因为我们将在接下来的章节中使用它们。我们将涉及用于 AI 的计算，并讨论如何通过 GPU 和其他先进的存储单元来改进它。最后，我们将讨论两种流行的深度学习云计算框架的基础知识：AWS
    和 Google Cloud。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: 'Essential libraries for deep learning in Python: TensorFlow, PyTorch, and Keras'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 中深度学习的基本库：TensorFlow、PyTorch 和 Keras
- en: CPUs, GPUs, and compute frameworks that are used for AI
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于 AI 的 CPU、GPU 和计算框架
- en: The fundamentals of AWS and Google Cloud
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS 和 Google Cloud 的基础知识
- en: Technical requirements
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'We will be working with TensorFlow, PyTorch, and Keras in Python 3. It is recommended
    that you have an NVIDIA GPU on your computer. The following models are recommended:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 Python 3 中使用 TensorFlow、PyTorch 和 Keras 进行工作。建议您的计算机上配备 NVIDIA GPU。建议以下模型：
- en: GTX 1080 Ti
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GTX 1080 Ti
- en: GTX 1070
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GTX 1070
- en: GTX 1060
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GTX 1060
- en: If you do not have an NVIDIA GPU, please follow the prompts in the *Cloud Computing*
    section to utilize a GPU instance on AWS.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有 NVIDIA GPU，请按照 *云计算* 部分的提示在 AWS 上使用 GPU 实例。
- en: You must also have an AWS and Google Cloud account; both are free, and you can
    sign up at their respective websites.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您还必须拥有 AWS 和 Google Cloud 账户；两者均免费，您可以在各自的网站上注册。
- en: TensorFlow, PyTorch, and Keras
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow、PyTorch 和 Keras
- en: 'In this section, we''ll introduce three of the most popular deep learning frameworks:
    TensorFlow, PyTorch, and Keras. While we''ll look at the basic functionality of
    each of the packages, we''ll learn about specific deep learning functions for
    each of the frameworks in later chapters as part of our hands-on approach to learning
    AI.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍三种最流行的深度学习框架：TensorFlow、PyTorch 和 Keras。虽然我们将了解每个包的基本功能，但作为我们实践学习
    AI 的一部分，我们将在后续章节中学习每个框架特定的深度学习功能。
- en: TensorFlow
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow
- en: '**TensorFlow** is the most popular, and most contributed to, deep learning
    library. Originally developed by Google Brain for use on Google''s own AI products,
    it was open sourced in 2015 and has since become the standard for deep learning.
    TensorFlow underlies all of Google''s own deep learning based products such as
    Google Translate and the Google Cloud Platform''s machine learning APIs. Google
    has setup TensorFlow specifically to be parallelized, and as such it performs
    really well in distributed environments.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**TensorFlow** 是最流行、最贡献的深度学习库。最初由 Google Brain 开发，用于 Google 自己的 AI 产品，2015
    年开源以来已成为深度学习的标准。TensorFlow 是 Google 自己的所有基于深度学习的产品的基础，如 Google 翻译和 Google Cloud
    平台的机器学习 API。Google 特意设置 TensorFlow 以便并行化，因此在分布式环境中表现非常出色。'
- en: TensorFlow provides APIs for Python, C++, Java, and others; however, in this
    book we are going to stick to utilizing Python. TensorFlow can be installed from
    PyPy with the simple: `pip install tensorflow`.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 提供了 Python、C++、Java 等的 API；然而，在本书中，我们将继续使用 Python。可以通过简单的 `pip install
    tensorflow` 命令从 PyPy 安装 TensorFlow。
- en: Basic building blocks
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本构建块
- en: As you may have guessed from the name, TensorFlow relies on the algebraic concept
    of tensors that we learned about in the previous chapter. Everything, from input
    data to parameters, is stored in a tensor in TensorFlow. As such, TensorFlow has
    its own functions for many of the basic operations normally handled by NumPy.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如您可能从名称中猜到的那样，TensorFlow 依赖于我们在前一章中学到的张量的代数概念。从输入数据到参数，所有东西都存储在 TensorFlow 中的张量中。因此，TensorFlow
    拥有其自己的函数来处理 NumPy 通常处理的许多基本操作。
- en: 'When writing tensors in TensorFlow, we''re really writing everything in an
    array structure. Remember how an array can be a rank 1 tensor? That is exactly
    what we are passing in the preceding example. If we wanted to pass a rank 3 tensor,
    we''d simply write `x = tf.constant([1,2,3,4],[5,6,7,8],[9,10,11,12])`. You''ll
    notice that we defined constants in the following code; these are just one of
    three types of data structure we can use in TensorFlow:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在 TensorFlow 中编写张量时，实际上我们是在编写一个数组结构。记得数组如何可以是一个秩为 1 的张量吗？这正是我们在前面的例子中传递的内容。如果我们想传递一个秩为
    3 的张量，我们只需写 `x = tf.constant([1,2,3,4],[5,6,7,8],[9,10,11,12])`。你会注意到，我们在下面的代码中定义了常量；这些只是
    TensorFlow 中三种数据结构中的一种：
- en: '**Constants**: Defined values that cannot change'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**常量**：定义的不可改变的值'
- en: '**Placeholders**: Objects that will be assigned a value during a TensorFlow
    **session**'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**占位符**：将在 TensorFlow **会话**中赋值的对象'
- en: '**Variables**: Like constants, only the values can change'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变量**：与常量类似，只是值可以改变'
- en: Alright, back to the code. If we had run the following code block, we would
    have been left with a **TensorFlow object**, which looks something like tensor
    (`"Mul:0"`, `shape=(4,), dtype=int32`).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，回到代码。如果我们运行以下代码块，我们将得到一个 **TensorFlow 对象**，看起来像张量（`"Mul:0"`，`shape=(4,)`，`dtype=int32`）。
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Why? because TensorFlow runs on the concept of **sessions**. The underlying
    code of TensorFlow is written in C++, and a session allows a high-level TensorFlow
    package to communicate with the low-level C++ runtime.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么？因为 TensorFlow 基于 **会话** 的概念运行。TensorFlow 的底层代码是用 C++ 编写的，会话允许高层的 TensorFlow
    包与低层的 C++ 运行时进行通信。
- en: Before we run a TensorFlow session, we need to tell it to initialize all of
    the variables we declared, and then run the initialization## In Tensorflow, we
    must first initialize a session object
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行 TensorFlow 会话之前，我们需要告诉它初始化我们声明的所有变量，然后运行初始化程序## 在 TensorFlow 中，我们必须先初始化一个会话对象
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'One last important concept in TensorFlow is that of **scopes**. Scopes help
    us control various operational blocks within our model:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 中最后一个重要的概念是 **作用域**。作用域帮助我们控制模型中的各个操作块：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: That's it! We've successfully performed out first operation in TensorFlow. We'll
    also be learning more about the in-depth operations of TensorFlow in the next
    chapter on building **Artificial Neural Networks **(**ANNs**).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！我们已经成功地在 TensorFlow 中执行了第一个操作。在接下来的章节中，我们将学习更多关于 TensorFlow 在构建 **人工神经网络（ANNs）**
    中的深入操作。
- en: The TensorFlow graph
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow 图
- en: One of the more important and powerful features of TensorFlow is its graph.
    When you define one of the three types of TensorFlow data structures previously
    described, you automatically add a **node** and an **edge** to your graph. Nodes
    represent operations and edges represent tensors, so if we were to do basic multiplication
    such as the preceding example, `const1` and `const2` would represent edges in
    the graph, `tf.multiply` would represent a node, and `product` would represent
    an outgoing edge from that node. TensorFlow's graph is **static**, which means
    we cannot change it at runtime.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow 最重要和强大的功能之一是它的图。当你定义了前面描述的三种 TensorFlow 数据结构之一时，你会自动将一个 **节点** 和一个
    **边** 添加到图中。节点代表操作，边代表张量，因此如果我们执行基本的乘法运算，如前面的例子中所示，`const1` 和 `const2` 将表示图中的边，`tf.multiply`
    将表示一个节点，而 `product` 将表示该节点的输出边。TensorFlow 的图是 **静态** 的，这意味着我们不能在运行时更改它。
- en: Remember, an ANN performs hundreds of computations; computing and interpreting
    at each step would be extremely compute-intensive. The TensorFlow graph ...
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，ANN（人工神经网络）执行数百次计算；在每一步计算和解释时会极其消耗计算资源。TensorFlow 图...
- en: PyTorch
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch
- en: '**PyTorch** is a newer, but growing deep learning library that is based on
    the Torch framework used for Facebook''s deep learning algorithms. Unlike TensorFlow,
    PyTorch is not a wrapper that compiles to an underlying language, but is written
    to mimic native Python. If you have had any experience with Python programming,
    PyTorch will feel extremely familiar to you.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**PyTorch** 是一个较新的但正在快速发展的深度学习库，基于用于 Facebook 深度学习算法的 Torch 框架。与 TensorFlow
    不同，PyTorch 不是一个编译到底层语言的封装器，而是直接用 Python 编写，模仿 Python 的原生语法。如果你有过 Python 编程经验，PyTorch
    会让你感觉非常熟悉。'
- en: 'PyTorch can be easily installed with:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过以下命令轻松安装 PyTorch：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Currently, PyTorch does not have a Windows distribution, which may make it out
    of reach for some users.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，PyTorch 没有 Windows 版本，这可能会使一些用户无法使用。
- en: Basic building blocks
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本构建块
- en: 'Such as TensorFlow, PyTorch represents data in tensor form. Torch tensors are
    defined as standard data types, such as `torch.FloatTensor()` , `torch.charTensor()`,
    and `torch.intTensor()`. As mentioned, operations in PyTorch are highly Pythonic.
    To repeat the exact same multiplication operation that we performed in preceding
    TensorFlow:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 和TensorFlow一样，PyTorch以张量形式表示数据。Torch张量被定义为标准数据类型，如`torch.FloatTensor()`、`torch.charTensor()`和`torch.intTensor()`。如前所述，PyTorch中的操作非常符合Python的风格。为了重复我们在前面TensorFlow中执行的相同乘法操作：
- en: '[PRE4]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As a result of it native Python feel, PyTorch allows for easy interaction between
    standard numpy arrays and PyTorch tensors. It''s easy to switch back and forth
    between the two:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其原生的Python风格，PyTorch允许标准的numpy数组与PyTorch张量之间的轻松互动。在两者之间切换非常容易：
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The PyTorch graph
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch图
- en: PyTorch seems more Pythonic because of its **dynamic graph compute structure**.
    Since Python is an interpreted language, meaning that operations are executed
    at runtime, PyTorch's graphing feature seeks to replicate this by allowing us
    to alter variables in the graph at runtime. In simpler words, PyTorch's graphs
    are created at the time you actually execute the code, not defined statically
    beforehand like in TensorFlow. Architecturally, this means that you can actually
    change your network architecture during training, which means PyTorch can accommodate
    a lot more cutting edge, dynamic architectures.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch看起来更符合Python风格，因为它具有**动态图计算结构**。由于Python是一种解释型语言，意味着操作是在运行时执行的，PyTorch的图形功能旨在通过允许我们在运行时修改图中的变量来复制这一点。简单来说，PyTorch的图是在你实际执行代码时创建的，而不像TensorFlow那样预先静态定义。架构上，这意味着你实际上可以在训练过程中改变网络架构，这使得PyTorch能够适应更多前沿、动态的架构。
- en: Keras
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Keras
- en: '**Keras** is the most high-level deep learning library available, and is often
    where people begin on their AI journey. While we will focus on applications with
    TensorFlow in this book, it is important to introduce Keras because of its ubiquity
    and ease of use.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**Keras**是目前最为高级的深度学习库，通常是人们在AI之旅中开始的地方。尽管本书将重点介绍使用TensorFlow的应用，但由于Keras的普及性和易用性，介绍它是非常重要的。'
- en: Written by François Chollet at Google, Keras is a wrapper that can run on top
    of TensorFlow or other libraries such as Apache, MXNet, or Theano. Like the other
    libraries, it is available through PyPy by running `pip install keras` in your
    terminal or command line. Functionally, it's very similar to the way the scikit-learn
    works, and hence is a popular library for those who wish to get their hands dirty
    with deep learning as quickly as possible.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由谷歌的François Chollet编写，Keras是一个可以在TensorFlow或其他库（如Apache、MXNet或Theano）之上运行的封装库。像其他库一样，可以通过在终端或命令行中运行`pip
    install keras`来通过PyPy安装。功能上，它与scikit-learn的工作方式非常相似，因此是那些希望尽快动手实践深度学习的人的热门库。
- en: Like PyTorch, Keras was designed to ...
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 像PyTorch一样，Keras的设计旨在...
- en: Basic building blocks
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本构建块
- en: 'As Keras is designed as a model-level library, it does not contain methods
    for doing basic operations as PyTorch of base TensorFlow does. Instead, it utilizes
    TensorFlow as a backend. As such, its basic operations are the same as basic TensorFlow
    operations:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Keras被设计为一个模型级别的库，它不包含像PyTorch或基础TensorFlow那样进行基本操作的方法。相反，它利用TensorFlow作为后端。因此，它的基本操作与TensorFlow的基本操作相同：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Keras also uses the same graph structure as Tensorflow. We'll learn more about
    Keras model building methods in the next chapter on *Your First Artificial Neural
    Networks*.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Keras也使用与TensorFlow相同的图结构。我们将在下一章的*你的第一个人工神经网络*中学习更多关于Keras模型构建的方法。
- en: Wrapping up
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'So, what is the best library to use? As you can see in the following screenshot,
    one benchmark places PyTorch firmly in the lead when compared with other deep
    learning libraries when running an ANN:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，最好的库是什么呢？正如你在以下截图中看到的，一个基准测试将PyTorch与其他深度学习库进行比较时，PyTorch牢牢占据了领先地位：
- en: '![](img/60eaf104-5f98-440f-af9d-4444555f98d5.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](img/60eaf104-5f98-440f-af9d-4444555f98d5.png)'
- en: 'Ultimately, your choice of library mostly comes down to personal preference;
    however, in general:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，你选择的库主要取决于个人偏好；不过，一般来说：
- en: '**Keras**: Best for beginners or those looking to do *quick and dirty* work
    on ANNs'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Keras**：最适合初学者或那些希望在ANN上做*快速粗糙*工作的用户'
- en: '**TensorFlow**: Widely used, there are great code bases and tutorials available
    online and it is widely integrated into cloud machine images and all types of
    computing frameworks'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow**：广泛使用，有很多优秀的代码库和教程可以在线获取，并且在云计算机镜像和各种计算框架中有广泛的集成。'
- en: '**PyTorch**: Provides exceptional speed and ease of use, but is largely still
    underdeveloped, ...'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PyTorch**：提供卓越的速度和易用性，但仍然在开发中，...'
- en: Cloud computing essentials
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云计算基础
- en: Often, on-premise GPU clusters are not always available or practical. More often
    than not, many businesses are migrating their AI applications to the cloud, utilizing
    popular cloud provider services such as **Amazon Web Services** (**AWS**) or the
    **Google Cloud Platform** (**GCP**). When we talk about the cloud, we are really
    talking about database and compute resources, offered as a service. Cloud solution
    providers such as AWS and GCP have data centers across the world that store data
    and run computing jobs for people remotely. When your data is in the cloud, or
    when you are running a program in the cloud, you are really running or storing
    in one of these data centers. In cloud terminology, we call these data centers
    or cluster of data centers **regions**.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，本地 GPU 集群并不总是可用或实际可行。更多时候，许多企业正在将它们的 AI 应用程序迁移到云端，利用像 **亚马逊云服务**（**AWS**）或
    **谷歌云平台**（**GCP**）这样的流行云服务提供商。当我们谈论云时，我们实际上是在谈论作为服务提供的数据库和计算资源。像 AWS 和 GCP 这样的云解决方案提供商在全球各地拥有数据中心，远程存储数据并运行计算任务。当你的数据在云中，或者你在云中运行程序时，实际上是在这些数据中心之一运行或存储。在云计算术语中，我们将这些数据中心或数据中心集群称为
    **区域**。
- en: 'Cloud services are divided into three different offering structures:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务分为三种不同的提供结构：
- en: '**Infrastructure as a Service** (**IaaS**): Raw computing and network resources
    that you can use to build infrastructure, just as you would locally'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施即服务**（**IaaS**）：原始计算和网络资源，你可以用来构建基础设施，像在本地一样'
- en: '**Platform as a Service** (**PaaS**): Managed services that obfuscate away
    infrastructure components'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**平台即服务**（**PaaS**）：托管服务，隐藏了基础设施组件'
- en: '**Software as a Service** (**SaaS**): Fully managed solutions, such as online
    email'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**软件即服务**（**SaaS**）：完全托管的解决方案，如在线电子邮件'
- en: In this section, we'll cover both IaaS solutions, as well as PaaS solutions.
    While cloud providers do offer SaaS solutions for AI, they are a bit too high
    level for our needs. In this section, we'll discuss the basic tools that you'll
    need to utilize the compute power of the cloud. Towards the end of this chapter,
    we'll discuss cloud computing in more detail in the *Maintaining AI applications* section.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论 IaaS 解决方案和 PaaS 解决方案。虽然云服务提供商确实为 AI 提供 SaaS 解决方案，但它们对我们需求来说过于高层。在本节中，我们将讨论你需要利用云计算能力的基本工具。在本章的最后，我们将在
    *维护 AI 应用程序* 一节中更详细地讨论云计算。
- en: AWS basics
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS 基础
- en: '**AWS** is the most popular cloud computing provider on the market. In this
    section, we''ll explore the basics for getting set up in the cloud, including
    creating and connecting to EC2 instances (Amazon''s main cloud computing framework),
    as well as how to set up virtual machines in the cloud.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**AWS** 是市场上最受欢迎的云计算提供商。在本节中，我们将探索云端设置的基础知识，包括创建和连接 EC2 实例（亚马逊的主要云计算框架），以及如何在云中设置虚拟机。'
- en: We'll also touch upon how to utilize Amazon's bulk storage component, S3. While
    AWS offers several machine learning services, we're going to focus solely on the
    basic need to utilize AWS cloud computing architectures to power your AI systems.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将简要介绍如何利用亚马逊的批量存储组件 S3。虽然 AWS 提供了多种机器学习服务，但我们将专注于如何利用 AWS 云计算架构为你的 AI 系统提供支持。
- en: EC2 and virtual machines
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EC2 和虚拟机
- en: The building block for AWS systems is the **Elastic Cloud Compute **(**EC2**)
    instance; it is a virtual server that allows you to run applications in the cloud.
    In this chapter, EC2 will be the basis for our cloud computing work. For developers
    and data scientists, Amazon has a suite of virtual machines called **Amazon Machine
    Images** (**AMI**) that come preloaded with everything you need to get up and
    running with deep learning in the cloud. For our purposes, Amazon has both an
    Ubuntu AMI as well as an Amazon Linux distribution AMI, which are preloaded with
    Python 3 and TensorFlow, PyTorch, and Keras.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 系统的构建模块是 **弹性云计算**（**EC2**）实例；它是一个虚拟服务器，允许你在云中运行应用程序。在本章中，EC2 将是我们云计算工作的基础。对于开发者和数据科学家，亚马逊提供了一套名为
    **亚马逊机器镜像**（**AMI**）的虚拟机，其中预装了你所需的一切，以便在云中开始深度学习。就我们的目的而言，亚马逊有一个 Ubuntu AMI 以及一个亚马逊
    Linux 发行版 AMI，预装了 Python 3 和 TensorFlow、PyTorch 和 Keras。
- en: 'To get started with utilizing EC2 for deep learning, we''ll just have to follow
    a few steps:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 EC2 进行深度学习，我们只需按照几个步骤操作：
- en: Log in to your Amazon Web Services Account.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到您的 Amazon Web Services 账户。
- en: Search for EC2 in the Search bar and select the service to open a new console.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在搜索栏中搜索 EC2 并选择该服务以打开新的控制台。
- en: Choose the Launch Instance button and search for the AWS deep learning AMI in
    the AWS Marketplace. You can select either the Ubuntu version or Amazon Linux.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择“启动实例”按钮并在 AWS 市场中搜索 AWS 深度学习 AMI。您可以选择 Ubuntu 版本或 Amazon Linux。
- en: Select a GPU instance to run your image on. We suggest either a G2 or P2 instance.
    Choose Next on each page until you reach Configure Security Group. Under Source,
    choose My IP to allow access using only your IP address.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个 GPU 实例来运行您的镜像。我们建议选择 G2 或 P2 实例。每一页都选择“下一步”，直到到达“配置安全组”页面。在“源”下，选择“我的 IP”以仅允许使用您的
    IP 地址访问。
- en: Click Launch Instance.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击“启动实例”。
- en: Create a new Private Key and store this somewhere locally; this will help you
    connect to your instance later on.
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新的私钥并将其保存在本地；这将帮助您稍后连接到您的实例。
- en: 'Now, you should have your AMI set up and ready to utilize. If you already have
    an EC2 instance up and running 0n your AWS account, select the instance and right-click
    on Image, Create Image under the dropdown for that instance:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您应该已经设置好并准备好使用您的 AMI。如果您在 AWS 账户中已经有一个正在运行的 EC2 实例，选择该实例，然后右键点击“镜像”选项，选择“创建镜像”：
- en: '![](img/59fb62db-96e8-42cf-b8a7-fb7a62dc4784.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/59fb62db-96e8-42cf-b8a7-fb7a62dc4784.png)'
- en: Follow the prompts and select Create Image. Afterwards, you can find that AMI
    by selecting EC2 -> AMIs under the main Explorer toolbar. If you still can't see
    your AMI, you can find more detailed instructions on AWS website [https://docs.aws.amazon.com/toolkit-for-visual-studio/latest/user-guide/tkv-create-ami-from-instance.html](https://docs.aws.amazon.com/toolkit-for-visual-studio/latest/user-guide/tkv-create-ami-from-instance.html).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 按照提示选择“创建镜像”。之后，您可以通过选择 EC2 -> AMIs 来找到该 AMI，位于主资源管理工具栏下。如果您仍然看不到您的 AMI，可以在
    AWS 网站上找到更详细的说明：[https://docs.aws.amazon.com/toolkit-for-visual-studio/latest/user-guide/tkv-create-ami-from-instance.html](https://docs.aws.amazon.com/toolkit-for-visual-studio/latest/user-guide/tkv-create-ami-from-instance.html)。
- en: 'To utilize your new virtual machine, first launch the instance on AWS. Here `ssh`
    is initialized by utilizing the following command (make sure you are in the same
    directory as the `pem` key file you just downloaded):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用您的新虚拟机，首先在 AWS 上启动实例。此处通过使用以下命令初始化 `ssh`（确保您在刚刚下载的 `pem` 密钥文件所在的目录）：
- en: '[PRE7]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Once you've connected with your terminal or command line, you can utilize the
    interface just as you would the command line on your local computer.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您连接了终端或命令行，就可以像在本地计算机上使用命令行一样使用该界面。
- en: S3 Storage
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: S3 存储
- en: '**Amazon Simple Storage Service** (**Amazon S3**), is AWS''s bulk cloud storage
    solution. S3 is designed to be simple, cheap, and efficient - it works just like
    a local directory on your computer would. These storage locations are known as
    **Buckets**, and can store up to 5 Terabytes of data.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon 简单存储服务**（**Amazon S3**），是 AWS 的大规模云存储解决方案。S3 被设计为简单、便宜且高效——它的工作方式就像您计算机上的本地目录一样。这些存储位置被称为**存储桶**，可以存储最多
    5 TB 的数据。'
- en: To setup an S3, log onto your AWS console, find the S3 service, and click Create
    bucket
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置 S3，登录到您的 AWS 控制台，找到 S3 服务，然后点击“创建存储桶”。
- en: '![](img/5003b9fd-4865-4250-9f01-dc2f33954891.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5003b9fd-4865-4250-9f01-dc2f33954891.png)'
- en: You can set permissions for who can and cannot access the data in an S3 bucket,
    should you need to restrict access.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以设置权限，控制谁可以访问 S3 存储桶中的数据，以便在需要限制访问时进行管理。
- en: AWS Sagemaker
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS Sagemaker
- en: 'SageMaker is Amazon''s fully managed cloud machine learning offering. As a
    **Platform as a Service** (**PaaS**) product, SageMaker is one of the simplest
    ways in which you can deploy a machine learning model. Unlike it''s competitors,
    Amazon SageMaker only runs Python 2.7. SageMaker has two options for handling
    machine learning services in the cloud:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: SageMaker 是 Amazon 提供的完全托管的云机器学习服务。作为**平台即服务**（**PaaS**）产品，SageMaker 是部署机器学习模型的最简单方式之一。与竞争对手不同，Amazon
    SageMaker 仅运行 Python 2.7。SageMaker 在云中处理机器学习服务有两个选项：
- en: Creating and training your model in a hosted Jupyter notebook
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在托管的 Jupyter notebook 中创建并训练您的模型
- en: Training from a dockerized version of the model
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 Docker 化版本的模型开始训练
- en: We'll be diving into how to train and deploy models with SageMaker in the coming
    sections.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将深入探讨如何使用 SageMaker 训练和部署模型。
- en: Google Cloud Platform basics
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Google Cloud Platform 基础
- en: While AWS is the major player in the cloud marketplace and has been for some
    time now, over the past few years the **Google Cloud Platform** (**GCP**) has
    been gaining popularity, especially in the field of machine learning. You can
    sign up for GCP for free by navigating to [https://cloud.google.com/free/](https://cloud.google.com/free/),
    and entering the console. Keep in mind that you do need a Google user account,
    such as a gmail account, to sign up for Google services. While many small tasks
    can be completed within the platform's free tier, GCP offers a $300.00 credit
    to new users to get started.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 AWS 是云市场的主要玩家，并且已经占据了一段时间的市场主导地位，但在过去几年中，**Google Cloud Platform**（**GCP**）逐渐获得了人气，尤其是在机器学习领域。你可以通过访问[https://cloud.google.com/free/](https://cloud.google.com/free/)并进入控制台，免费注册
    GCP。请记住，你需要一个 Google 用户账户，例如 Gmail 账户，才能注册 Google 服务。尽管很多小任务可以在平台的免费层级中完成，GCP
    也为新用户提供了 $300.00 的信用额度以帮助入门。
- en: All services in GCP run under the umbrella of a project. Projects are tools
    for organizing computing tools, users and access rights, as well as billing. ...
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: GCP 中的所有服务都在项目的框架下运行。项目是用于组织计算工具、用户和访问权限，以及计费的工具…
- en: GCP cloud storage
  id: totrans-100
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GCP 云存储
- en: Cloud storage is a simple, bucket-structured storage option that is similar
    to AWS S3\. Like AWS, GCP cloud storage holds up to 5 Terabytes of data. As opposed
    to competitors such as AWS, or even Microsoft Azure, GCP's cloud storage has upload
    and download speeds for large files that are about three times faster than it's
    competitors. Cloud storage also has some of the fastest **throughput** on the
    market. Throughput, a cloud concept that measures how much data is processed at
    a given time - in simpler words, how fast can data be processed. When creating
    certain applications that rely on streaming data, this can be critical. Cloud
    storage also has the option to create buckets that span across service regions,
    which helps with fault tolerance and availability of your data.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 云存储是一个简单的、桶式结构的存储选项，类似于 AWS S3。像 AWS 一样，GCP 云存储可容纳最多 5 TB 的数据。与 AWS 或 Microsoft
    Azure 等竞争对手不同，GCP 的云存储在大文件的上传和下载速度上大约比竞争对手快三倍。云存储还拥有市场上最快的 **吞吐量**。吞吐量是一个云概念，衡量在特定时间内处理的数据量——简而言之，就是数据处理的速度。当创建依赖于流数据的某些应用时，这一点至关重要。云存储还支持创建跨服务区域的桶，这有助于提高数据的容错性和可用性。
- en: 'To setup a Cloud storage bucket, log-on to the GCP console, search for storage,
    and click CREATE BUCKET:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置一个 Cloud 存储桶，请登录 GCP 控制台，搜索存储，然后点击创建存储桶：
- en: '![](img/a568ade9-aab8-439a-bc9a-15ef47c75f14.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a568ade9-aab8-439a-bc9a-15ef47c75f14.png)'
- en: In addition to their standard compute and storage services, the GCP has another
    tool, ML engine, which provides seamless training and deployment operations for
    machine learning models.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标准的计算和存储服务外，GCP 还有另一个工具——ML 引擎，它为机器学习模型提供无缝的训练和部署操作。
- en: GCP Cloud ML Engine
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GCP Cloud ML 引擎
- en: Google Cloud Platform's Cloud ML Engine is Google's equivalent to AWS SageMaker.
    As a managed PaaS, Cloud ML handles the training and deployment processes for
    machine learning algorithms. If you're thinking - what about a basic compute service
    like EC2 on AWS? GCP has that as well. Compute Engine is GCP's answer to Amazon
    EC2; it provides basic, scalable cloud compute services. While we could use Compute
    Engine to setup AI platforms, GCP has made it extremely simple for us to build
    with Cloud ML Engine and as such, we will note be covering the basic Compute Engine.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud Platform 的 Cloud ML Engine 相当于 AWS SageMaker。作为一个托管 PaaS，Cloud
    ML 处理机器学习算法的训练和部署过程。如果你在想——那像 AWS 上的基础计算服务 EC2 呢？GCP 也有类似服务。Compute Engine 是 GCP
    对 Amazon EC2 的回应；它提供基础的、可扩展的云计算服务。虽然我们可以使用 Compute Engine 来搭建 AI 平台，但 GCP 已经使得通过
    Cloud ML Engine 构建变得异常简单，因此我们将不会涵盖基础的 Compute Engine。
- en: 'Let''s dive into the details. Cloud ML engine allows you to:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解细节。Cloud ML 引擎允许你：
- en: Train scikit-learn and TensorFlow models both locally for testing and in the
    cloud
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本地进行测试并在云端训练 scikit-learn 和 TensorFlow 模型
- en: Create retrainable ...
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建可重训练的…
- en: CPUs, GPUs, and other compute frameworks
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CPUs、GPUs 和其他计算框架
- en: Progress in AI has always been tied to our compute abilities. In this section,
    we will discuss CPUs and GPUs for powering AI applications, and how to set up
    your system to work with accelerated GPU processing.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: AI 的进步始终与我们的计算能力密切相关。在本节中，我们将讨论用于驱动 AI 应用程序的 CPUs 和 GPUs，以及如何设置系统以支持加速的 GPU
    处理。
- en: The main computational hardware in your computer is known as the **central processing
    unit **(**CPUs**); CPUs are designed for general computing workloads. While your
    local CPU can be used to train a deep learning model, you might find your computer
    hanging up on the training process for hours. When training AI applications on
    hardware, it's smarter to use the CPU's cousin, the **Graphics Processing Unit**
    (**GPU**). GPUs are designed to process in parallel, just as an ANN process in
    parallel. As we learned in the last chapter, AI applications require many linear
    algebra operations, the exact same type of operations that are required for video
    games. GPUs, originally designed for the gaming industry, provide us with thousands
    of cores to process these operations as well as parallelize them. In this manner,
    they lend themselves naturally to constructing deep learning algorithms.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机中的主要计算硬件被称为 **中央处理单元** (**CPU**)，CPU 设计用于一般计算任务。虽然本地 CPU 可以用来训练深度学习模型，但你可能会发现训练过程中计算机会长时间卡顿。训练
    AI 应用时，使用 CPU 的“表亲”——**图形处理单元** (**GPU**) 更加聪明。GPU 设计用于并行处理，正如人工神经网络（ANN）进行并行处理一样。正如我们在上一章中学到的，AI
    应用需要大量的线性代数运算，而这些正是视频游戏所需要的运算类型。最初为游戏行业设计的 GPU，提供了成千上万个核心来处理这些运算，并进行并行化处理。这样，GPU
    自然适合于构建深度学习算法。
- en: 'When selecting a GPU to utilize in deep learning applications, we''re looking
    at three main characteristics:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择用于深度学习应用的 GPU 时，我们需要关注三个主要特征：
- en: '**Processing power**: How fast the GPU can compute; defined as *cores* x *speed*'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理能力**：GPU 的计算速度；定义为 *核心数* x *速度*'
- en: '**Memory**: The ability of the GPU to handle various sizes of data'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存**：GPU 处理不同大小数据的能力'
- en: '**RAM**: The amount of data you can have on your GPU at any given time'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RAM**：你可以在任何给定时刻在 GPU 上处理的数据量'
- en: In this section, we'll be focusing on utilizing the most popular GPU brand for
    deep learning, **NVIDIA**, whose CUDA toolkit makes out-of-the-box deep learning
    an easy task. As the major competitor to NVIDIA, Radeon AMD GPUs utilize a toolkit
    called **OpenCL**, which does not have direct compatibility with most deep learning
    libraries out of the box. While AMD GPUs provide great hardware at a reasonable
    price, it is best to go with an NVIDIA product to make getting up to speed easy.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将重点介绍使用最受欢迎的深度学习 GPU 品牌——**NVIDIA**，其 CUDA 工具包让开箱即用的深度学习变得非常简单。作为 NVIDIA 的主要竞争对手，Radeon
    AMD GPU 使用一个名为 **OpenCL** 的工具包，而该工具包与大多数深度学习库的兼容性并不是开箱即用的。尽管 AMD GPU 提供了价格合理的强大硬件，但为了更顺利地上手，最好选择
    NVIDIA 产品。
- en: Should you have another GPU on your computer or no GPU at all, it is recommended
    that you utilize a GPU instance on AWS to follow the steps.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的计算机没有 GPU 或者有其他 GPU，建议你利用 AWS 上的 GPU 实例来跟随本教程的步骤。
- en: Installing GPU libraries and drivers
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装 GPU 库和驱动程序
- en: Now, let's get our computers set up for building AI applications. If you wish
    to do this task on your local computer, it's advised that you have either Windows
    or a Linux distribution installed. Unfortunately, most macOS are not built to
    accommodate GPUs, and therefore we will not be touching on macOS in this section.
    If you do not have an NVIDIA GPU on your computer, please perform the following
    steps. If you do have an NVIDIA GPU, you may choose to follow along with the AWS-based
    section, or skip to the following section.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们为构建 AI 应用程序设置计算机。如果你希望在本地计算机上执行此任务，建议你安装 Windows 或 Linux 发行版。不幸的是，大多数
    macOS 不支持 GPU，因此我们在本节中不会涉及 macOS。如果你的计算机没有 NVIDIA GPU，请按照以下步骤操作。如果你有 NVIDIA GPU，你可以选择跟随
    AWS 部分，或者跳到以下部分。
- en: 'If you''re not sure whether you have an NVIDIA GPU, you can check for its existence
    with the following terminal command:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不确定是否拥有 NVIDIA GPU，可以使用以下终端命令检查其是否存在：
- en: '[PRE8]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: With Linux (Ubuntu)
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Linux (Ubuntu)
- en: Linux and AI go together such as natural complements. When you talk to Google
    Assistant on your Android phone, talk to Cortana on your Windows device, or wonder
    how Watson won a round at Jeopardy on TV, it's all based on Linux.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Linux 和 AI 就像天作之合。当你在 Android 手机上与 Google Assistant 对话，或者在 Windows 设备上与 Cortana
    对话，抑或是在电视上看 Watson 如何赢得《危险边缘》游戏的那一局时，这一切都基于 Linux。
- en: When we talk about Linux in this chapter, we'll be talking about a particular
    distribution called **Ubuntu**,one of the most popular distributions of the Linux
    operating system. It's recommended that you stick with an older, more stable version
    of Ubuntu (Version 14.04), as although it will do wonders for your AI applications;
    it's certainly not as stable as your standard Windows OS.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在本章讨论 Linux 时，我们指的是一种特定的发行版，叫做 **Ubuntu**，它是 Linux 操作系统中最受欢迎的发行版之一。推荐你使用旧版的、更稳定的
    Ubuntu（版本 14.04），虽然它会对你的 AI 应用产生很好的效果，但它肯定没有标准的 Windows 操作系统那么稳定。
- en: 'If you''d like to use Ubuntu on your local machine, check out Ubuntu''s tutorials
    for installing on a Windows machine ([https://tutorials.ubuntu.com/tutorial/tutorial-ubuntu-on-windows#0](https://tutorials.ubuntu.com/tutorial/tutorial-ubuntu-on-windows#0)).
    If you don''t have a PC or you''d like to set up a virtual instance, AWS has a
    great tutorial ([https://aws.amazon.com/getting-started/tutorials/launch-a-virtual-machine/](https://aws.amazon.com/getting-started/tutorials/launch-a-virtual-machine/))
    to walk you through the steps:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在本地机器上使用 Ubuntu，查看 Ubuntu 的教程，了解如何在 Windows 机器上安装它（[https://tutorials.ubuntu.com/tutorial/tutorial-ubuntu-on-windows#0](https://tutorials.ubuntu.com/tutorial/tutorial-ubuntu-on-windows#0)）。如果你没有
    PC 或者想设置虚拟实例，AWS 有一个很棒的教程（[https://aws.amazon.com/getting-started/tutorials/launch-a-virtual-machine/](https://aws.amazon.com/getting-started/tutorials/launch-a-virtual-machine/)），帮助你一步步完成设置：
- en: 'To get started with deep learning for GPUs on Ubuntu, we first have to install
    the GPU''s driver. In this example, we''re going to utilize `wget` and `chmod`
    to retrieve and set up read/write access:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在 Ubuntu 上开始使用 GPU 深度学习，我们首先需要安装 GPU 驱动程序。在此示例中，我们将使用 `wget` 和 `chmod` 来获取并设置读写权限：
- en: '[PRE9]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Once the installation finishes, you can check if it was intalled correctly with
    a simple `nvidia-smi` command.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装完成后，你可以通过运行简单的 `nvidia-smi` 命令检查安装是否成功。
- en: 'Next, let''s install NVIDIA CUDA. CUDA is a NVIDIA package that allows us to
    run TensorFlow models on our GPUs:'
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们安装 NVIDIA CUDA。CUDA 是一个 NVIDIA 软件包，它允许我们在 GPU 上运行 TensorFlow 模型：
- en: '[PRE10]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, let''s add the library to our system path:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们将库添加到系统路径中：
- en: '[PRE11]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Lastly, we need to install a higher-level package called cuNN, which is a specific
    library that sits on top of CUDA and provides highly-tuned procedures for typical
    deep learning operations:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们需要安装一个更高级别的软件包，叫做 cuNN，这是一个位于 CUDA 之上的特定库，为典型的深度学习操作提供高度优化的过程：
- en: '[PRE12]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'One last step to move the files to the correct place:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后一步是将文件移动到正确的位置：
- en: '[PRE13]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'And there you are, we''re set up on Ubuntu for GPU acceleration. Our last step
    is to simply install the GPU-enabled version of TensorFlow with Python 3:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就这样，我们在 Ubuntu 上已经为 GPU 加速做好了准备。我们的最后一步是简单地安装支持 GPU 的 TensorFlow 版本，并使用 Python
    3：
- en: '[PRE14]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: With Windows
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Windows 上
- en: To set up your GPU for deep learning on Windows, you must be running Windows
    7 or higher. You can verify that you have a CUDA-capable GPU through the **display
    adapters** section in the **Windows Device Manager**. Here, you will find the
    vendor name and model of your graphics card.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Windows 上为深度学习设置 GPU，你必须运行 Windows 7 或更高版本。你可以通过 **Windows 设备管理器** 中的 **显示适配器**
    部分验证是否拥有支持 CUDA 的 GPU。在这里，你会找到显卡的厂商名称和型号。
- en: 'To see what type of GPU you have, open a command line prompt and run:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看你拥有什么类型的 GPU，打开命令行并运行：
- en: '[PRE15]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If you do not have the driver installed for your NVIDIA GPU, or would like to
    update the drivers, you can find the correct driver based on your device on the
    NVIDIA website: [http://www.nvidia.com/Download/index.aspx?lang=en-us](http://www.nvidia.com/Download/index.aspx?lang=en-us).
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你没有为你的 NVIDIA GPU 安装驱动程序，或者想要更新驱动程序，你可以在 NVIDIA 网站上根据你的设备找到正确的驱动程序：[http://www.nvidia.com/Download/index.aspx?lang=en-us](http://www.nvidia.com/Download/index.aspx?lang=en-us)。
- en: Next, go ahead and grab the CUDA toolkit ([https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads))
    form NVIDIA. Select **CUDA Version ...**
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，去 NVIDIA 网站获取 CUDA 工具包（[https://developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads)）。选择
    **CUDA 版本 ...**
- en: Basic GPU operations
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本的 GPU 操作
- en: 'Now that we have our GPUs set up for deep learning, let''s learn how to utilize
    them. In TensorFlow, GPUs are represented as strings:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的 GPU 已经为深度学习做好了设置，让我们学习如何使用它们。在 TensorFlow 中，GPU 以字符串的形式表示：
- en: '`/cpu:0`: The CPU of your machine'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/cpu:0`：你机器的 CPU'
- en: '`/device:GPU:0`: The GPU of your machine, if you have one'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/device:GPU:0`：你机器的 GPU，如果有的话'
- en: '`/device:GPU:1`: The second GPU of your machine, and so on'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/device:GPU:1`：你机器的第二个 GPU，依此类推'
- en: '**Distributed training** is the practice of training a network across several
    GPUs, and it''s becoming an increasingly common way to train models in the AI
    field. TensorFlow, Keras, and PyTorch all support distributed training.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**分布式训练**是指跨多个GPU训练网络的做法，它正成为AI领域中训练模型的越来越常见的方法。TensorFlow、Keras和PyTorch都支持分布式训练。'
- en: '**Logging** is an operation in TensorFlow to assign a particular set of commands
    to a particular GPU or CPU on your system. With logging, we can also **parallelize**
    our operations, meaning that we can distribute training across several GPUs at
    the same time. To do this, we utilize a simple loop structure:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**日志记录**是TensorFlow中的一项操作，用于将特定的命令集分配给系统上的特定GPU或CPU。通过日志记录，我们还可以**并行化**我们的操作，这意味着我们可以同时跨多个GPU分配训练任务。为了做到这一点，我们使用一个简单的循环结构：'
- en: '[PRE16]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We first create an empty set, and use an iterator to assign the matrix multiplication
    procedure across two GPUs: GPU1 and GPU2\. Another procedure, a simple sum, gets
    assigned to our CPU. We then run both through a TensorFlow session to execute
    the operations as we did before.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建一个空集，并使用迭代器将矩阵乘法过程分配到两个GPU上：GPU1和GPU2。另一个过程，即简单的加法，被分配给我们的CPU。然后，我们将这两个过程都通过TensorFlow会话执行，正如我们之前所做的那样。
- en: Keep in mind that this type of device management is for local devices, and that
    management is different for cloud architectures.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这种设备管理适用于本地设备，云架构的管理方式是不同的。
- en: The future – TPUs and more
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 未来—TPU及更多
- en: Google has recently released a new piece of hardware known as the **Tensor Processing
    Unit **(**TPU**), which is specifically designed for AI applications. These TPUs
    deliver 15-30x higher performance and 30-80x higher performance-per-watt than
    a CPU or GPU can deliver. Weights in large scale, production-level AI applications
    can number from five million to 100 million, and these TPUs excel in performing
    these operations.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: Google最近发布了一款名为**张量处理单元**（**TPU**）的新硬件，专门为AI应用设计。这些TPU提供比CPU或GPU高15到30倍的性能，并且在每瓦性能上高出30到80倍。大规模生产级AI应用中的权重数量可以从五百万到一亿不等，而这些TPU在执行这些操作时表现出色。
- en: TPUs are specifically tailored for TensorFlow processing, and are currently
    available on Google Cloud for use. If you're interested in exploring their functionality,
    GCP has a great tutorial ([https://cloud.google.com/tpu/docs/quickstart](https://cloud.google.com/tpu/docs/quickstart)) on
    how to get started.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: TPU专门为TensorFlow处理量身定制，目前可在Google Cloud上使用。如果你有兴趣探索它们的功能，GCP提供了一个很棒的教程（[https://cloud.google.com/tpu/docs/quickstart](https://cloud.google.com/tpu/docs/quickstart)）来帮助你入门。
- en: Summary
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: The landscape for AI platforms and methods is diverse; in this chapter, we've
    outlined some of the most promising and well regarded technologies in the AI arena.
    For deep learning packages, we learned about TensorFlow, PyTorch, and Keras. TensorFlow,
    released by Google, is the most popular and robust of the deep learning libraries.
    It utilizes sessions and static graphs to compile to its underlying C++ code. PyTorch,
    on the other hand, is a newer library that features a dynamic graph for runtime
    execution, which allows it to feel like native Python. Lastly, Keras is a high-level
    library that runs on top of TensorFlow, and can be useful for creating straightforward
    networks where customization is not needed.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: AI平台和方法的领域非常广泛；在本章中，我们概述了AI领域中一些最有前景且广受好评的技术。对于深度学习包，我们了解了TensorFlow、PyTorch和Keras。TensorFlow由Google发布，是深度学习库中最受欢迎和最强大的一个。它利用会话和静态图来编译其底层的C++代码。另一方面，PyTorch是一个较新的库，采用动态图进行运行时执行，这使得它的使用感觉更像是原生Python。最后，Keras是一个高层次的库，运行在TensorFlow之上，适用于创建不需要太多定制的简单网络。
- en: We also discussed cloud computing, utilizing AWS as the most popular cloud computing
    service, with its primary workhorses being the EC2 instance and the s3 Bucket.
    EC2 consists of virtual servers that can be used for scaling AI applications where
    hardware doesn't exist/is not needed. S3, Amazon's Simple Storage Service gives
    us the ability to store data and other resources that are necessary for running
    our applications. Lastly, we walked through enabling your computer and languages
    for GPU-accelerated deep learning. In the next chapter, we'll put this to use
    by creating our first ANNs.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了云计算，利用 AWS 作为最流行的云计算服务，其主要的工作组件是 EC2 实例和 S3 桶。EC2 由虚拟服务器组成，可以用于扩展人工智能应用程序，在没有硬件或不需要硬件的情况下运行。S3，亚马逊的简单存储服务，使我们能够存储运行应用程序所需的数据和其他资源。最后，我们讲解了如何为你的计算机和编程语言启用
    GPU 加速深度学习。在下一章，我们将通过创建我们的第一个人工神经网络（ANNs）来应用这些知识。
- en: In the next chapter, we'll put together the fundamental knowledge that learned
    in [Chapter 2](c72aa49d-41f1-4a15-bee5-9efc9190f282.xhtml), *Machine Learning
    Basics*, with the platform knowledge from this chapter to create our first ANNs.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将把[第 2 章](c72aa49d-41f1-4a15-bee5-9efc9190f282.xhtml)《*机器学习基础*》中学到的基本知识与本章的平台注册知识结合起来，创建我们的第一个人工神经网络（ANNs）。
