- en: Use Cases of Neural Networks – Advanced Topics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络的应用案例——高级主题
- en: With **Artificial Neural Networks** (**ANN**), let's try to simulate typical
    brain activities such as image perception, pattern recognition, language understanding,
    sense-motor coordination, and so on. ANN models are composed of a system of nodes,
    equivalent to neurons of a human brain, which are interconnected by weighted links,
    equivalent to synapses between neurons. The output of the network is modified
    iteratively from link weights to convergence.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 使用**人工神经网络**（**ANN**），让我们尝试模拟典型的大脑活动，如图像感知、模式识别、语言理解、感觉-运动协调等。ANN模型由一个节点系统组成，等同于人脑的神经元，这些节点通过加权连接互相连接，类似于神经元之间的突触。网络的输出通过不断迭代的方式从连接权重调整至收敛状态。
- en: This final chapter presents ANN applications from different use cases and how
    neural networks can be used in the AI world. We will see some use cases and their
    implementation in R. You can adapt the same set of programs for other real work
    scenarios.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章最后，我们将展示ANN的不同应用案例，并探讨神经网络如何在人工智能领域中使用。我们将看到一些应用案例及其在R中的实现。你可以将相同的程序集应用到其他实际工作场景中。
- en: 'The following topics will be covered:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: TensorFlow integration with R
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow与R的集成
- en: Keras integration with R
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras与R的集成
- en: Handwritten digit recognition using `MNIST` dataset with `H2O`
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`MNIST`数据集和`H2O`进行手写数字识别
- en: Building LSTM with mxnet
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用mxnet构建LSTM
- en: Clustering data using auto encoders with `H2O`
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`H2O`的自编码器进行数据聚类
- en: '**Principal Component Analysis** (**PCA**) using `H2O`'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`H2O`进行**主成分分析**（**PCA**）
- en: Breast cancer detection using the `darch` package
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`darch`包进行乳腺癌检测
- en: By the end of this chapter, you will have understood the advanced concepts of
    the learning process and their implementation in the R environment. We will apply
    different types of algorithms to implement a neural network. We will review how
    to train, test, and deploy a model. We will look again at how to perform a correct
    valuation procedure. We will also cover more of deep learning in our use cases
    as deep learning is the latest thing that is based on advanced neural networks.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将理解学习过程的高级概念及其在R环境中的实现。我们将应用不同类型的算法来实现一个神经网络。我们将复习如何训练、测试和部署模型。我们还会再次讨论如何执行正确的评估程序。此外，随着深度学习的快速发展，我们将更多地涵盖其在应用中的使用，深度学习是基于先进神经网络的最新技术。
- en: TensorFlow integration with R
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TensorFlow与R的集成
- en: TensorFlow is an open source numerical computing library provided by Google
    for machine intelligence. It hides all of the programming required to build deep
    learning models and gives the developers a black box interface to program. The
    Keras API for TensorFlow provides a high-level interface for neural networks.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow是Google提供的一个开源数值计算库，用于机器智能。它隐藏了构建深度学习模型所需的所有编程工作，提供了一个“黑盒”接口供开发者使用。TensorFlow的Keras
    API为神经网络提供了一个高级接口。
- en: Python is the **de facto** programming language for deep learning, but R is
    catching up. Deep learning libraries are now available with R and a developer
    can easily download TensorFlow or Keras similar to other R libraries and use them.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Python是深度学习的**事实标准**编程语言，但R也在赶超。现在，R也有深度学习库，开发者可以像使用其他R库一样，轻松下载TensorFlow或Keras并加以使用。
- en: In TensorFlow, nodes in the graph represent mathematical operations, while the
    graph edges represent the multidimensional data arrays (tensors) communicated
    between them. TensorFlow was originally developed by the Google Brain Team within
    Google's machine intelligence research for machine learning and deep neural networks
    research, but it is now available in the public domain. TensorFlow exploits GPU
    processing when configured appropriately.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow中，图中的节点代表数学运算，而图的边缘则代表在节点之间传递的多维数据数组（张量）。TensorFlow最初由Google Brain团队在Google的机器智能研究中开发，用于机器学习和深度神经网络研究，但现在已经公开发布。TensorFlow在配置得当时，可以利用GPU进行处理。
- en: 'The generic use cases for TensorFlow are as follows:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow的通用应用案例如下：
- en: Image recognition
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像识别
- en: Computer vision
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: Voice/sound recognition
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 声音/语音识别
- en: Time series analysis
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列分析
- en: Language detection
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言检测
- en: Language translation
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 语言翻译
- en: Text-based processing
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于文本的处理
- en: '**Handwriting Recognition** (**HWR**)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**手写识别**（**HWR**）'
- en: Many others
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他许多应用
- en: In this section, we will see how we can bring TensorFlow libraries into R. This
    will open up a huge number of possibilities with deep learning using TensorFlow
    in R. In order to use TensorFlow, we must first install Python. If you don't have
    a Python installation on your machine, it's time to get it.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何将 TensorFlow 库引入 R。这样就能在 R 中使用 TensorFlow 进行深度学习，开辟了大量的可能性。为了使用
    TensorFlow，我们必须先安装 Python。如果你的机器上没有 Python 环境，现在是时候安装它了。
- en: Python is a dynamic **Object-Oriented Programming** (**OOP**) language that
    can be used for many types of software development. It offers strong support for
    integration with other languages and programs, is provided with a large standard
    library, and can be learned within a few days. Many Python programmers can confirm
    a substantial increase in productivity and feel that it encourages the development
    of higher quality code and maintainability. Python runs on Windows, Linux/Unix,
    macOS X, OS/2, Amiga, Palm Handhelds, and Nokia phones. It also works on Java
    and .NET virtual machines. Python is licensed under the OSI-approved open source
    license; its use is free, including for commercial products.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Python 是一种动态的 **面向对象编程**（**OOP**）语言，可以用于许多类型的软件开发。它强有力地支持与其他语言和程序的集成，提供了丰富的标准库，并且可以在几天内学会。许多
    Python 程序员确认，通过使用 Python，他们的生产力有了显著提升，并认为它有助于开发更高质量、易于维护的代码。Python 可以运行在 Windows、Linux/Unix、macOS
    X、OS/2、Amiga、Palm 手持设备和诺基亚手机上。它还可以在 Java 和 .NET 虚拟机上运行。Python 采用 OSI 批准的开源许可证，使用是免费的，包括用于商业产品。
- en: Python was created in the early 1990s by Guido van Rossum at Stichting Mathematisch
    Centrum in the Netherlands as a successor of a language called **ABC**. Guido
    remains Python's principal author, although it includes many contributions from
    others.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Python 由 Guido van Rossum 于 1990 年代初在荷兰的 Stichting Mathematisch Centrum 创建，作为一种名为
    **ABC** 的语言的继承者。尽管 Python 现在包含了许多其他人的贡献，但 Guido 仍然是 Python 的主要作者。
- en: If you do not know which version to use, there is an (English) document that
    could help you choose. In principle, if you have to start from scratch, we recommend
    choosing Python 3, and if you need to use third-party software packages that may
    not be compatible with Python 3, we recommend using Python 2.7\. All information
    about the available versions and how to install Python is given at [https://www.python.org/](https://www.python.org/).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不知道选择哪个版本，可以参考一个（英文）文档，它能帮助你做出选择。原则上，如果你必须从零开始，我们推荐选择 Python 3；如果你需要使用可能与
    Python 3 不兼容的第三方软件包，我们推荐使用 Python 2.7。所有有关可用版本及如何安装 Python 的信息可以在[https://www.python.org/](https://www.python.org/)找到。
- en: 'After properly installing the Python version of our machine, we have to worry
    about installing TensorFlow. We can retrieve all library information and available
    versions of the operating system from the following link: [https://www.tensorflow.org/](https://www.tensorflow.org/).'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在正确安装了机器上的 Python 版本后，我们需要关注如何安装 TensorFlow。我们可以通过以下链接获取操作系统的所有库信息及可用版本：[https://www.tensorflow.org/](https://www.tensorflow.org/)。
- en: 'Also, in the install section, we can find a series of guides that explain how
    to install a version of TensorFlow that allows us to write applications in Python.
    Guides are available for the following operating systems:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在安装部分，我们可以找到一系列指南，解释如何安装允许我们用 Python 编写应用程序的 TensorFlow 版本。以下操作系统有相关的安装指南：
- en: Installing TensorFlow on Ubuntu
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Ubuntu 上安装 TensorFlow
- en: Installing TensorFlow on macOS X
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 macOS X 上安装 TensorFlow
- en: Installing TensorFlow on Windows
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Windows 上安装 TensorFlow
- en: Installing TensorFlow from sources
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从源码安装 TensorFlow
- en: 'For example, to install Tensorflow on Windows, we must choose one of the following
    types:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要在 Windows 上安装 TensorFlow，我们必须选择以下类型之一：
- en: TensorFlow with CPU support only
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅支持 CPU 的 TensorFlow
- en: TensorFlow with GPU support
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持 GPU 的 TensorFlow
- en: 'To install TensorFlow, start a terminal with privileges as administrator. Then
    issue the appropriate `pip3` install command in that terminal. To install the
    CPU-only version, enter the following command:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装 TensorFlow，首先启动具有管理员权限的终端。然后在该终端中输入适当的 `pip3` 安装命令。若要安装仅支持 CPU 的版本，请输入以下命令：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'A series of code lines will be displayed on the video to keep us informed of
    the execution of the installation procedure, as shown in the following figure:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 安装过程的执行状态将通过一系列代码行在视频中显示，如下图所示：
- en: '![](img/00137.gif)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00137.gif)'
- en: At this point, we can return to our favorite environment; I am referring to
    the R development environment. We will need to install the interface to TensorFlow.
    The R interface to TensorFlow lets you work productively using the high-level
    Keras and Estimator APIs, and when you need more control, it provides full access
    to the core TensorFlow API. To install the R interface to TensorFlow, we will
    use the following procedure.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们可以回到我们最喜欢的环境；我指的是R开发环境。我们需要安装TensorFlow的接口。R接口让你能够高效地使用高级Keras和Estimator
    API，且当需要更多控制时，它提供对核心TensorFlow API的完全访问权限。为了安装R接口到TensorFlow，我们将按照以下步骤操作。
- en: 'First, install the `tensorflow` R package from CRAN as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，从CRAN安装`tensorflow` R包，如下所示：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Then, use the **install_tensorflow()** function to install TensorFlow (for
    a proper installation procedure, you must have administrator privileges):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用**install_tensorflow()**函数来安装TensorFlow（为了正确安装，你需要管理员权限）：
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can confirm that the installation succeeded:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以确认安装成功：
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This will provide you with a default installation of TensorFlow suitable for
    use with the `tensorflow` R package. Read on if you want to learn about additional
    installation options, including installing a version of TensorFlow that takes
    advantage of NVIDIA GPUs if you have the correct CUDA libraries installed. In
    the following code, we can check the success of the installation:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为你提供一个默认的TensorFlow安装，适用于`tensorflow` R包。如果你想了解更多安装选项，包括安装支持NVIDIA GPU的TensorFlow版本（前提是你已安装相应的CUDA库），请继续阅读。在以下代码中，我们可以检查安装是否成功：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Keras integration with R
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Keras与R的集成
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'By default, RStudio loads the CPU version of TensorFlow. Once Keras is loaded,
    we have a powerful set of deep learning libraries that can be utilized by R programmers
    to execute neural networks and deep learning. To install Keras for R, use this
    code:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，RStudio加载的是TensorFlow的CPU版本。一旦加载了Keras，我们便有了一套强大的深度学习库，R程序员可以利用这些库来执行神经网络和深度学习任务。要安装Keras
    for R，使用以下代码：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'At this point, we load the `keras` library:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们加载`keras`库：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Finally, we check whether keras is installed correctly by loading the `MNIST`
    dataset:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过加载`MNIST`数据集来检查keras是否正确安装：
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: MNIST HWR using R
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用R进行MNIST HWR
- en: Handwriting Recognition (HWR) is a very commonly used procedure in modern technology.
    The image of the written text can be detected offline from a piece of paper by
    optical scanning (**optical character recognition** (**OCR**)) or intelligent
    word recognition. Alternatively, pen tip movements can be detected online (for
    example, from a pen-computer surface, a task that is generally easier since there
    are more clues available). Technically, recognition of handwriting is the ability
    of a computer to receive and interpret a handwritten intelligible input from sources
    such as paper documents, photos, touchscreens, and other devices.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 手写识别（HWR）是现代技术中非常常见的过程。通过光学扫描（**光学字符识别**（**OCR**））或智能词识别，可以离线从纸张上的文本图像中检测到书写内容。或者，可以通过在线检测笔尖的运动（例如，从笔-计算机表面进行，通常较容易，因为有更多的线索可用）。从技术上讲，手写识别是指计算机从纸质文档、照片、触摸屏及其他设备等来源接收并解释可理解的手写输入的能力。
- en: HWR is performed through various techniques that generally require OCR. However,
    a complete script recognition system also manages formatting, carries out correct
    character segmentation, and finds the most plausible words.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: HWR通过各种技术进行处理，通常需要OCR。然而，一个完整的脚本识别系统还管理格式，执行正确的字符分割，并找出最合理的单词。
- en: '**Modified National Institute of Standards and Technology** (**MNIST**) is
    a large database of handwritten digits. It has a set of 70,000 examples of data.
    It is a subset of NIST''s larger dataset. The digits are of 28x28 pixel resolution
    and are stored in a matrix of 70,000 rows and 785 columns; 784 columns form each
    pixel value from the 28x28 matrix and one value is the actual digit. The digits
    have been size-normalized and centered in a fixed-size image.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**修改版国家标准与技术研究院**（**MNIST**）是一个大型手写数字数据库。它包含70,000个数据样本。它是NIST更大数据集的一个子集。这些数字的分辨率为28x28像素，并以70,000行和785列的矩阵形式存储；784列形成每个像素值，来自28x28矩阵，且一个值是实际的数字。数字已经被尺寸标准化并集中在一个固定大小的图像中。'
- en: The digit images in the MNIST set were originally selected and experimented
    with by Chris Burges and Corinna Cortes using bounding-box normalization and centering.
    Yann LeCun's version uses centering by center of mass within in a larger window.
    The data is available on Yann LeCun's website at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`MNIST`数据集中的数字图像最初由Chris Burges和Corinna Cortes使用边界框归一化和居中进行选择和实验。Yann LeCun的版本使用较大窗口中的质量中心进行居中。数据可以在Yann
    LeCun的官方网站上获取：[http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)。'
- en: 'Each image is created as 28x28\. Here is a sample of images of *0-8* from the
    MNIST dataset:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 每张图像的大小为28x28。以下是来自`MNIST`数据集的*0-8*数字的图像样本：
- en: '![](img/00138.jpeg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00138.jpeg)'
- en: MNIST has a sample of several handwritten digits. This dataset can be fed for
    our training to an R program and our code can recognize any new handwritten digit
    that is presented as data for prediction. This is a case where the neural network
    architecture functions as a computer vision system for an AI application.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`MNIST`数据集包含多个手写数字样本。我们可以将此数据集输入到R程序中进行训练，代码可以识别任何新的手写数字，并作为预测数据进行处理。这是神经网络架构作为计算机视觉系统应用于人工智能（AI）的一种情况。'
- en: 'The following table shows the distribution of the `MNIST` dataset available
    on LeCun''s website:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 下表展示了LeCun网站上可用的`MNIST`数据集的分布情况：
- en: '| **Digit** | **Count** |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| **数字** | **计数** |'
- en: '| *0* | *5923* |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| *0* | *5923* |'
- en: '| *1* | *6742* |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| *1* | *6742* |'
- en: '| *2* | *5958* |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| *2* | *5958* |'
- en: '| *3* | *6131* |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| *3* | *6131* |'
- en: '| *4* | *5842* |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| *4* | *5842* |'
- en: '| *5* | *5421* |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| *5* | *5421* |'
- en: '| *6* | *5918* |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| *6* | *5918* |'
- en: '| *7* | *6265* |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| *7* | *6265* |'
- en: '| *8* | *5851* |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| *8* | *5851* |'
- en: '| *9* | *5949* |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| *9* | *5949* |'
- en: We will not use the `h2o` package for deep learning to train and test the `MNIST`
    dataset. We will split the dataset of 70,000 rows into 60,000 training rows and
    10,000 test rows. Then, we'll find the accuracy of the model. The model can then
    be used to predict any incoming dataset of 28x28 pixel handwritten digits containing
    numbers between zero and nine. Finally, we will reduce the file size to 100 rows
    for demo training processing on two datasets in `.csv` format, named `mnist_train_100.csv`
    and `mnist_test_10.csv`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会使用`h2o`包进行深度学习训练和测试`MNIST`数据集。我们将70,000行的数据集拆分为60,000行训练数据和10,000行测试数据。然后，我们将计算模型的准确率。该模型可以用于预测任何包含0到9之间手写数字的28x28像素的输入数据集。最后，我们将文件大小压缩到100行，用于在两个`.csv`格式的数据集上进行演示训练处理，文件名为`mnist_train_100.csv`和`mnist_test_10.csv`。
- en: 'For our sample R code, we use a 100-row training dataset and a 10-row test
    dataset. The R code is presented here:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的示例R代码，我们使用了一个包含100行的训练数据集和一个包含10行的测试数据集。以下是R代码的展示：
- en: '[PRE9]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, let''s go through the code to learn how to apply the `h2o` package to
    solve a HWR problem. We''ve already properly introduced the `h2o` package in [Chapter
    3](part0081.html#2D7TI0-263fb608a19f4bb5955f37a7741ba5c4), *Deep Learning Using
    Multilayer Neural Networks*. The `h2o` is included and initiated through the following
    code:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过代码了解如何应用`h2o`包来解决手写数字识别问题。我们在[第3章](part0081.html#2D7TI0-263fb608a19f4bb5955f37a7741ba5c4)中已经详细介绍了`h2o`包，*使用多层神经网络的深度学习*。`h2o`包通过以下代码引入并初始化：
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following results are displayed in the R prompt:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 以下结果显示在R提示符下：
- en: '[PRE11]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The training file is opened using a handle. It is set to have 100 rows to simplify
    the demo work. The complete dataset can be downloaded from the URL suggested before.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 训练文件通过句柄打开，设置为100行以简化演示工作。完整的数据集可以从之前建议的网址下载。
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This command sets the working directory where we will have inserted the dataset
    for the next reading.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令设置了工作目录，我们将在其中插入用于下一次读取的数据集。
- en: '[PRE13]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This piece of code first loads the training dataset of `MNIST`, reducing the
    file size to 100 rows for demo training processing. Then we use the `attach()`
    function to attach the database to the R search path. This means that the database
    is searched by R when evaluating a variable, so objects in the database can be
    accessed by simply giving their names. Finally, we use the `names()` function
    to set the names of the dataset. The same thing we will do for the dataset to
    be used in the testing phase:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码首先加载了`MNIST`的训练数据集，将文件大小减少到100行以进行演示训练处理。然后我们使用`attach()`函数将数据库附加到R的搜索路径中。这意味着R在评估变量时会搜索该数据库，因此可以通过简单地给出变量名来访问数据库中的对象。最后，我们使用`names()`函数来设置数据集的名称。我们将在测试阶段使用的同样方式处理数据集：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'At this point, we create a 28x28 matrix with pixel color values by taking the
    tenth row of the dataset, which contains the number zero:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们通过提取数据集中的第十行（包含数字零），创建一个28x28的矩阵，其中包含像素颜色值：
- en: '[PRE15]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s see what we''ve got by plotting an object `image`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过绘制对象`image`来看一下我们得到了什么：
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In the following is shown the image of the handwritten digit:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 以下展示的是手写数字的图像：
- en: '![](img/00139.jpeg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00139.jpeg)'
- en: 'Now let''s create a mirror image of the handwritten digit:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建手写数字的镜像：
- en: '[PRE17]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Then, view the image to verify the operation just made:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，查看图像以验证刚刚执行的操作：
- en: '[PRE18]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'In the following is shown the mirror image:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 以下展示的是镜像图像：
- en: '![](img/00140.jpeg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00140.jpeg)'
- en: 'Now, let''s do the same for the first six rows in the dataset:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们对数据集中的前六行做同样的操作：
- en: '[PRE19]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'These are the images of the handwritten digits contained in the first six rows
    of the dataset:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是数据集中前六行手写数字的图像：
- en: '![](img/00141.jpeg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00141.jpeg)'
- en: 'Reset the plot options back to default:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 重置图表选项为默认设置：
- en: '[PRE20]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The next command lets us do some explanatory analysis of the training data:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个命令让我们进行一些关于训练数据的解释性分析：
- en: '[PRE21]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This command finds the count of each number in the training matrix:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令用于查找训练矩阵中每个数字的数量：
- en: '[PRE22]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The results are shown here:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示如下：
- en: '[PRE23]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Above are displayed the number of occurrences of each digit in the dataset.
    It''s time to build and train the model:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 上面显示的是数据集中每个数字出现的次数。现在是构建并训练模型的时候了：
- en: '[PRE24]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, to produce the summaries of the results of the `model` fitting function,
    we will use the `summary()` function:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了生成`model`拟合函数的结果摘要，我们将使用`summary()`函数：
- en: '[PRE25]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The following figure shows some of the results obtained:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示显示了部分得到的结果：
- en: '![](img/00142.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00142.jpeg)'
- en: 'We can understand the evolution of the algorithm used, by checking the performance
    of the training model:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过检查训练模型的性能来理解算法的演变：
- en: '[PRE26]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'At this point, we have a properly trained `model`, so we can use it to make
    predictions. In our case, we will use it to recognize handwritten digits:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们已经有了一个训练良好的`model`，因此可以用它进行预测。在我们的案例中，我们将用它来识别手写数字：
- en: '[PRE27]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now that we have used `model`, we need to format the actual and expected matrices
    to verify the accuracy:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经使用了`model`，我们需要格式化实际和预期的矩阵来验证准确性：
- en: '[PRE28]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Enter the names of the variables inserted into the matrix:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 输入插入矩阵的变量名称：
- en: '[PRE29]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Finally, check the output:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，检查输出：
- en: '[PRE30]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The results are shown here:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示如下：
- en: '[PRE31]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'As can be seen from the analysis of the table just proposed, for the test data,
    the model has predicted 60 percent (six out of ten) correctly. This accuracy is
    only for the small training dataset. The model can be improved further by:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 从刚才提出的表格分析可以看出，对于测试数据，模型正确预测了60%（10个中有6个）。这个准确度仅适用于小型训练数据集。模型可以通过以下方式进一步改进：
- en: Increasing the training dataset count
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 增加训练数据集的数量
- en: Tweaking the parameters of the `h20.deeplearning` function
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整`h20.deeplearning`函数的参数
- en: Allocating more memory to the `h2o` JVM
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为`h2o` JVM分配更多内存
- en: Expanding the test dataset
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展测试数据集
- en: LSTM using the iris dataset
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用鸢尾花数据集的LSTM
- en: 'Continuing with the LSTM architecture for RNN introduced in [Chapter 6](part0111.html#39REE0-263fb608a19f4bb5955f37a7741ba5c4),
    *Recurrent and Convolutional Neural Networks*, we present the `iris` dataset processing
    using the `mxnet` LSTM function. The function expects all inputs and outputs as
    numeric. It is particularly useful for processing text sequences, but here we
    will train an LSTM model on the `iris` dataset. The input values are `petal.length`,
    `petal.width`, `sepal.length`, and `sepal.width`. The output variable is `Species`,
    which is converted to a numeric value between one and three. The `iris` dataset
    has been detailed in [Chapter 4](part0088.html#2JTHG0-263fb608a19f4bb5955f37a7741ba5c4),
    *Perceptron Neural Network Modeling – Basic Models*:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 继续使用[第6章](part0111.html#39REE0-263fb608a19f4bb5955f37a7741ba5c4)中介绍的LSTM架构用于RNN，*递归神经网络与卷积神经网络*，我们展示了使用`mxnet`
    LSTM函数处理`iris`数据集。该函数期望所有输入和输出为数值型。它特别适用于处理文本序列，但在这里我们将训练一个LSTM模型，基于`iris`数据集。输入值为`petal.length`、`petal.width`、`sepal.length`和`sepal.width`，输出变量是`Species`，它被转换为介于1和3之间的数值。`iris`数据集已在[第4章](part0088.html#2JTHG0-263fb608a19f4bb5955f37a7741ba5c4)中详细介绍，*感知器神经网络建模
    - 基本模型*：
- en: '[PRE32]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The program requires `mxnet`, which needs to be installed. `mxnet` for R is
    available for both CPUs and GPUs and for the following OSes: Linux, macOS, and
    Windows.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 程序需要安装`mxnet`。`mxnet`支持R语言，并可用于CPU和GPU，支持以下操作系统：Linux、macOS和Windows。
- en: 'We will only indicate the installation procedures for Windows machines and
    CPU versions. Refer to the following URL for information on installation procedures
    for other architectures: [https://mxnet.incubator.apache.org/get_started/install.html](https://mxnet.incubator.apache.org/get_started/install.html).'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们仅说明Windows机器和CPU版本的安装程序。有关其他架构的安装程序信息，请参考以下网址：[https://mxnet.incubator.apache.org/get_started/install.html](https://mxnet.incubator.apache.org/get_started/install.html)。
- en: 'To install `mxnet` on a computer with a CPU processor, we use the prebuilt
    binary package. We can install the package directly on the R console through the
    following code:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 要在CPU处理器的计算机上安装`mxnet`，我们使用预构建的二进制包。我们可以通过以下代码直接在R控制台中安装该包：
- en: '[PRE33]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The following packages are installed:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 安装了以下包：
- en: '[PRE34]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'As you can see the installation of the `mxnet` package, install in addition
    to several packages. So, we already have everything we need to proceed. This `mxnet`
    library contains the `mx.lstm` function we are going to use:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，安装`mxnet`包时，除了安装`mxnet`外，还安装了其他几个包。所以，我们已经准备好继续了。这个`mxnet`库包含了我们将要使用的`mx.lstm`函数：
- en: '[PRE35]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'In the following code, the internal dataset `iris` is loaded and the `x` and
    `y` variables are set with independent and target variables, respectively. The
    Species variable is converted to a number between one and three:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，加载了内部数据集`iris`，并将`x`和`y`变量分别设置为自变量和目标变量。`Species`变量被转换为介于1到3之间的数字：
- en: '[PRE36]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Just an explanation, with the following code:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 只是一个解释，使用以下代码：
- en: '[PRE37]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We asked R to select from the `iris` dataset, which consists of 150 lines and
    five columns, only lines one to four, leaving out the fifth. This procedure will
    also be performed for multiples of five, so in the end, we will omit every multiple
    row of five from our selection. We will also omit the fifth column. At the end,
    we will get 120 rows and four columns.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要求R从`iris`数据集中选择150行五列中的1到4行，省略掉第五行。这个过程还将对5的倍数进行，因此最后我们会从选择中省略每个倍数为5的行。同时，我们也会省略第五列。最终，我们将得到120行和四列。
- en: 'We now set the input and output:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们设置输入和输出：
- en: '[PRE38]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Then we set the dataframe we will use for the test, by selecting only the lines
    we had previously omitted:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们通过选择之前省略的行来设置用于测试的数据框：
- en: '[PRE39]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The `mx.lstm` function is called with the input and output values so that the
    model is trained with the LSTM on the RNN with the dataset:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`mx.lstm`函数，使用输入和输出值来训练RNN上的LSTM模型，数据集为：
- en: '[PRE40]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now we can make predictions:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进行预测：
- en: '[PRE41]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Finally, we print the results to compare the model performance:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们打印结果以比较模型性能：
- en: '[PRE42]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Here are the results:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是结果：
- en: '[PRE43]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: From the comparison between the test data and those obtained from the forecast
    it can be noticed that the best results were obtained for the versicolor species.
    From the results obtained, it is clear that the model needs to be improved because
    the forecasts it is able to perform are not at the level of those obtained in
    the models we obtained in the previous examples.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 从测试数据和预测结果的比较中可以看出，最好的结果是针对`versicolor`物种获得的。从结果来看，模型需要改进，因为它能够进行的预测还不如我们在前面示例中获得的模型那样好。
- en: Working with autoencoders
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自编码器
- en: We have seen autoencoders in the deep learning chapter for unsupervised learning.
    Autoencoders utilize neural networks to perform non-linear dimensionality reduction.
    They represent data in a better way, by finding latent features in it using universal
    function approximators. Autoencoders try to combine or compress input data in
    a different way.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在深度学习章节中已经看到过自编码器，它们用于无监督学习。自编码器利用神经网络执行非线性降维。通过使用通用函数逼近器，它们能以更好的方式表示数据，找出数据中的潜在特征。自编码器试图以不同的方式结合或压缩输入数据。
- en: 'A sample representation using MLP is shown here:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了一个使用MLP的示例表示：
- en: '![](img/00143.jpeg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00143.jpeg)'
- en: PCA using H2O
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用H2O的PCA
- en: One of the greatest difficulties encountered in multivariate statistical analysis
    is the problem of displaying a dataset with many variables. Fortunately, in datasets
    with many variables, some pieces of data are often closely related to each other.
    This is because they actually contain the same information, as they measure the
    same quantity that governs the behavior of the system. These are therefore redundant
    variables that add nothing to the model we want to build. We can then simplify
    the problem by replacing a group of variables with a new variable that encloses
    the information content.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在多元统计分析中，遇到的最大困难之一是如何显示具有多个变量的数据集。幸运的是，在具有多个变量的数据集中，一些数据往往彼此紧密相关。这是因为它们实际上包含相同的信息，因为它们测量的是支配系统行为的同一量。因此，这些是冗余变量，对我们想要构建的模型没有任何贡献。我们可以通过用一个包含信息内容的新变量替换一组变量来简化问题。
- en: PCA generates a new set of variables, among them uncorrelated, called principal
    components; each main component is a linear combination of the original variables.
    All principal components are orthogonal to each other, so there is no redundant
    information. The principal components as a whole constitute an orthogonal basis
    for the data space. The goal of PCA is to explain the maximum amount of variance
    with the fewest number of principal components. It is a form of multidimensional
    scaling. It is a linear transformation of the variables into a lower dimensional
    space that retains the maximum amount of information about the variables. A principal
    component is therefore a combination of the original variables after a linear
    transformation.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: PCA 生成了一组新的变量，其中包含不相关的变量，称为主成分；每个主成分是原始变量的线性组合。所有主成分彼此正交，因此没有冗余信息。主成分整体构成了数据空间的正交基。PCA
    的目标是用最少数量的主成分解释最多的方差。这是一种多维缩放方法。它是将变量线性变换到一个较低维度的空间，保留关于变量的最大信息。因此，主成分是原始变量在进行线性变换后的组合。
- en: 'In the following example, we use `h2o` to achieve PCA. The `prcomp()` function
    is used find the principal components of a set of input features. This is unsupervised
    learning:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们使用`h2o`实现 PCA。`prcomp()`函数用于寻找一组输入特征的主成分。这是无监督学习：
- en: '[PRE44]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Now, let's go through the code to understand how to apply the `h2o` package
    to apply PCA.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过代码来了解如何应用 `h2o` 包进行 PCA。
- en: 'We can proceed with loading the library:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续加载库：
- en: '[PRE45]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'This command loads the library into the R environment. The following function
    initiates the `h2o` engine with a maximum memory size of `2` GB and two parallel
    cores:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将库加载到 R 环境中。以下函数以最大内存大小为`2` GB和两个并行核心初始化`h2o`引擎：
- en: '[PRE46]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The following messages are returned:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 返回以下消息：
- en: '[PRE47]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We follow the directions on the R prompt:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们按照 R 提示符上的指示操作：
- en: '[PRE48]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The `h20.init` function initiates the `h2o` engine with a maximum memory size
    of `2` GB and two parallel cores. The following commands load the data into the
    R environment:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '`h20.init` 函数以最大内存大小为 `2` GB 和两个并行核心初始化 `h2o` 引擎。以下命令将数据加载到 R 环境中：'
- en: '[PRE49]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'The first instruction generates the path that contains the file to upload.
    To upload a file in a directory local to your `h2o` instance, use `h2o.uploadFile()`,
    which can also upload data local to your `h2o` instance in addition to your R
    session. In the parentheses, specify the `h2o` reference object in R and the complete
    URL or normalized file path for the file. Let''s see now that it''s inside:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条指令生成包含要上传文件的路径。要上传位于 `h2o` 实例本地目录中的文件，使用 `h2o.uploadFile()`，它除了能够上传本地文件数据外，还能上传
    R 会话中的数据。在括号内，指定 R 中的 `h2o` 引用对象以及文件的完整 URL 或规范化文件路径。现在让我们来看一下它在其中：
- en: '[PRE50]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Now let''s print a brief summary of the dataset:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们打印数据集的简要总结：
- en: '![](img/00144.jpeg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00144.jpeg)'
- en: 'To perform PCA on the given dataset, we will use the `prcomp()` function:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 要对给定的数据集执行 PCA，我们将使用`prcomp()`函数：
- en: '[PRE51]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Now let''s print a brief `summary` of the model:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们打印模型的简要`总结`：
- en: '[PRE52]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'In the following figure, we see a summary of the PCA model:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们看到 PCA 模型的总结：
- en: '![](img/00145.jpeg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00145.jpeg)'
- en: To better understand the results, we can make a scree plot of the percent variability
    explained by each principal component. The percent variability explained is contained
    in the model importance variables from the PCA model.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解结果，我们可以绘制一个 scree 图，显示每个主成分解释的方差百分比。解释的方差百分比包含在 PCA 模型的模型重要性变量中。
- en: 'The following figure shows a scree plot of the percent variability explained
    by each principal component:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图展示了每个主成分解释的百分比方差的碎石图：
- en: '![](img/00146.gif)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00146.gif)'
- en: The bar plot shows the proportion of variance for each principal component;
    as you can see, the first two components have about 70 percent of the variance.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 条形图显示了每个主成分的方差比例；如你所见，前两个主成分约占方差的70%。
- en: Autoencoders using H2O
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用H2O的自编码器
- en: An autoencoder is an ANN used for learning without efficient coding control.
    The purpose of an autoencoder is to learn coding for a set of data, typically
    to reduce dimensionality.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是一种用于无效编码控制的人工神经网络（ANN）。自编码器的目的是学习一组数据的编码，通常用于减少数据的维度。
- en: Architecturally, the simplest form of autoencoder is an advanced and non-recurring
    neural network very similar to the MLP, with an input level, an output layer,
    and one or more hidden layers that connect them, but with the layer outputs having
    the same number of input level nodes for rebuilding their inputs.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 从架构上看，自编码器的最简单形式是一个先进的、非递归的神经网络，类似于多层感知机（MLP），具有输入层、输出层和一个或多个连接它们的隐藏层，但层的输出与输入层的节点数相同，用于重建输入。
- en: In the following is proposed an example of autoencoder using `h2o` on a `movie`
    dataset.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用`h2o`在`movie`数据集上进行自编码器的示例：
- en: The dataset used in this example is a set of movies and genre taken from [https://grouplens.org/datasets/movielens](https://grouplens.org/datasets/movielens).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 本示例中使用的数据集是一组来自[https://grouplens.org/datasets/movielens](https://grouplens.org/datasets/movielens)的电影和类型数据。
- en: 'We use the movies.csv file, which has three columns:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的`movies.csv`文件包含三列：
- en: '`movieId`'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`movieId`'
- en: '`title`'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`title`'
- en: '`genres`'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`genres`'
- en: 'There are 164,979 rows of data for clustering. We will use `h2o.deeplearning`
    to have the `autoencoder` parameter fix the clusters. The objective of the exercise
    is to cluster the movies based on genre, which can then be used to recommend similar
    movies or same-genre movies to the users. The program uses `h20.deeplearning`,
    with the `autoencoder` parameter set to `T`:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类的数据有164,979行。我们将使用`h2o.deeplearning`来让`autoencoder`参数修正聚类。这个练习的目的是根据类型对电影进行聚类，然后可以用来向用户推荐相似的电影或同类型的电影。程序使用`h20.deeplearning`，并将`autoencoder`参数设置为`T`：
- en: '[PRE53]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Now, let''s go through the code:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来浏览代码：
- en: '[PRE54]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'These commands load the library in the R environment and set the working directory
    where we will have inserted the dataset for the next reading. Then we load the
    data:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这些命令会在R环境中加载库，并设置工作目录，之后我们会将数据集插入该目录进行下一步读取。然后，我们加载数据：
- en: '[PRE55]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'To visualize the type of data contained in the dataset, we analyze a preview
    of one of these variables:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化数据集中包含的数据类型，我们分析了其中一个变量的预览：
- en: '[PRE56]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The following figure shows the first `20` rows of the `movie` dataset:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了`movie`数据集的前`20`行：
- en: '![](img/00147.jpeg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00147.jpeg)'
- en: 'Now we build and train `model`:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们构建并训练`model`：
- en: '[PRE57]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Let''s analyze some of the information contained in `model`:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下`model`中包含的一些信息：
- en: '[PRE58]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'This is an extract from the results of the `summary()` function:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`summary()`函数结果的一个摘录：
- en: '![](img/00148.jpeg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00148.jpeg)'
- en: 'In the next command, we use the `h2o.deepfeatures()` function to extract the
    non-linear feature from an `h2o` dataset using an H2O deep learning model:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的命令中，我们使用`h2o.deepfeatures()`函数从`h2o`数据集提取非线性特征，使用的是H2O深度学习模型：
- en: '[PRE59]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'In the following code, the first six rows of the features extracted from the
    model are shown:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，显示了从模型中提取的前六行特征：
- en: '[PRE60]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Finally, we plot a diagram where we want to see how the model grouped the movies
    through the results obtained from the analysis:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们绘制一个图表，查看模型如何通过分析结果将电影分组：
- en: '[PRE61]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: The plot of the movies, once clustering is done, is shown next. We have plotted
    only 100 movie titles due to space issues. We can see some movies being closely
    placed, meaning they are of the same genre. The titles are clustered based on
    distances between them, based on genre.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 完成聚类后，接下来显示的是电影的图形。由于空间限制，我们只绘制了100个电影标题。我们可以看到一些电影被紧密排列在一起，意味着它们属于相同类型。电影标题根据它们之间的距离进行了聚类，基于的是类型。
- en: '![](img/00149.jpeg)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00149.jpeg)'
- en: Given the large number of titles, the movie names cannot be distinguished, but
    what appears to be clear is that the model has grouped the movies into three distinct
    groups.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 由于电影标题数量庞大，无法区分电影名称，但明显可以看出模型已经将电影分为三组。
- en: Breast cancer detection using darch
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用DARCH进行乳腺癌检测
- en: In this section, we will use the `darch` package, which is used for deep architectures
    and **Restricted Boltzmann Machines** (**RBM**). The `darch` package is built
    on the basis of the code from G. E. Hinton and R. R. Salakhutdinov (available
    under MATLAB code for **Deep Belief Nets** (**DBN**)). This package is for generating
    neural networks with many layers (deep architectures) and training them with the
    method introduced by the authors.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将使用 `darch` 包，该包用于深度架构和**限制玻尔兹曼机**（**RBM**）。`darch` 包是基于 G. E. Hinton
    和 R. R. Salakhutdinov 的代码（可以通过 MATLAB 代码获得，适用于**深度信念网络**（**DBN**））构建的。此包用于生成具有多层的神经网络（深度架构）并通过作者提出的方法对其进行训练。
- en: This method includes a pre-training with the contrastive divergence method and
    fine-tuning with commonly known training algorithms such as backpropagation or
    conjugate gradients. Additionally, supervised fine-tuning can be enhanced with
    maxout and dropout, two recently developed techniques used to improve fine-tuning
    for deep learning.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法包括使用对比散度方法进行预训练，并使用常见的训练算法（如反向传播或共轭梯度法）进行微调。此外，监督微调可以通过 maxout 和 dropout
    两种新近发展的技术进行增强，这些技术用于改善深度学习的微调。
- en: The basis of the example is classification based on a set of inputs. To do this,
    we will use the data contained in the dataset named BreastCancer.csv that we just
    used in [Chapter 5](part0096.html#2RHM00-263fb608a19f4bb5955f37a7741ba5c4), *Training
    and Visualizing a Neural Network in R*. This data has been taken from the UCI
    Repository Of Machine Learning. The dataset is periodically updated as soon as
    Dr. Wolberg reports his clinical cases. The data is of breast cancer patients
    with a classification of benign or malignant tumor based on a set of ten independent
    variables.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 示例的基础是基于一组输入进行分类。为此，我们将使用数据集 BreastCancer.csv 中的数据，该数据集在 [第 5 章](part0096.html#2RHM00-263fb608a19f4bb5955f37a7741ba5c4)中提到过，*在
    R 中训练和可视化神经网络*。该数据取自 UCI 机器学习仓库，数据集会在 Wolberg 博士报告其临床病例后定期更新。数据包含乳腺癌患者的资料，并根据十个独立变量对良性或恶性肿瘤进行分类。
- en: To get the data, we draw on the large collection of data available in the UCI
    Machine Learning Repository at [http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取数据，我们借用了 UCI 机器学习仓库中大量可用的数据，网址为 [http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)。
- en: 'Details of the data are as follows:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的详细信息如下：
- en: '**Number of instances**: 699 (as of 15 July 1992)'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实例数量**：699（截至 1992 年 7 月 15 日）'
- en: '**Number of attributes**: 10 plus the class attribute'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性数量**：10 个加上类属性'
- en: '**Attribute information**: The class attribute has been moved to the last column'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**属性信息**：类属性已移至最后一列'
- en: 'The description of the attributes is shown here:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 属性的描述如下：
- en: '[PRE62]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: To understand the `darch` function, we first set up an XOR gate and then use
    it for training and verification. The `darch` function uses output data and input
    attributes to build the model, which can be tested internally by `darch` itself.
    In this case, we achieve 0 percent error and 100 percent accuracy.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解 `darch` 函数，我们首先设置一个 XOR 门，然后将其用于训练和验证。`darch` 函数使用输出数据和输入属性来构建模型，该模型可以由
    `darch` 本身进行内部测试。在这种情况下，我们达到了 0% 的错误率和 100% 的准确率。
- en: 'Next, we use the breast cancer data to build the `darch` model and then check
    the accuracy:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用乳腺癌数据构建 `darch` 模型，并检查其准确性：
- en: '[PRE63]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'We begin analyzing the code line by line, explaining in detail all the features
    applied to capture the results:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始逐行分析代码，详细解释所有用于捕捉结果的特性：
- en: '[PRE64]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: The first two lines of the initial code are used to load the libraries needed
    to run the analysis.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 初始代码的前两行用于加载运行分析所需的库。
- en: Remember that, to install a library that is not present in the initial distribution
    of R, you must use the `install.package` function. This is the main function to
    install packages. It takes a vector of names and a destination library, downloads
    the packages from the repositories and installs them. This function should be
    used only once and not every time you run the code.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，要安装初始 R 发行版中未包含的库，必须使用 `install.package` 函数。这是安装软件包的主要函数。它接受一个名称向量和目标库，从仓库下载并安装软件包。此函数应仅使用一次，而不是每次运行代码时都调用。
- en: The `mlbench` library contains a collection of artificial and real-world machine
    learning benchmark problems, including, for example, several datasets from the
    UCI repository.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '`mlbench` 库包含了一系列人工和真实世界的机器学习基准问题，例如包括来自 UCI 仓库的几个数据集。'
- en: 'The `darch` library is a package for deep architectures and RBM:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '`darch` 库是一个用于深度架构和 RBM 的包：'
- en: '[PRE65]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'With this command, we upload the dataset named `BreastCancer`, as mentioned,
    in the `mlbench` library. Let''s see now that it''s inside:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个命令，我们加载了名为 `BreastCancer` 的数据集，正如在 `mlbench` 库中提到的。现在让我们看看它是否已经加载：
- en: '[PRE66]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: With this command, we see a brief summary by using the `summary()` function.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个命令，我们可以通过 `summary()` 函数查看简要的总结。
- en: Remember, the `summary()` function is a generic function used to produce result
    summaries of the results of various model fitting functions. The function invokes
    particular methods that depend on the class of the first argument.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，`summary()` 函数是一个通用函数，用于生成各种模型拟合函数的结果摘要。该函数会调用特定的方法，这些方法取决于第一个参数的类。
- en: 'In this case, the function has been applied to a dataframe and the results
    are listed in the following figure:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，函数已应用于数据框，结果列在下图中：
- en: '![](img/00150.jpeg)'
  id: totrans-263
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00150.jpeg)'
- en: The `summary()` function returns a set of statistics for each variable. In particular,
    it is useful to highlight the result provided for the `Class` variable, which
    contains the diagnosis of the cancer mass. In this case, `458` cases of `benign`
    class and `241` cases of `malignant` class were detected. Another feature to highlight
    is the `Bare.nuclei` variable. For this variable, `16` cases of missing values
    were detected.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '`summary()` 函数返回每个变量的一组统计信息。特别有用的是突出显示 `Class` 变量的结果，该变量包含癌症肿块的诊断信息。在这种情况下，检测到
    `458` 个 `良性` 类别和 `241` 个 `恶性` 类别的病例。另一个需要强调的特征是 `Bare.nuclei` 变量。对于该变量，检测到 `16`
    个缺失值的案例。'
- en: 'To remove missing values, we can use the `na.omit()` function:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 为了去除缺失值，我们可以使用 `na.omit()` 函数：
- en: '[PRE67]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Now we build and train the model:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们构建并训练模型：
- en: '[PRE68]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'To evaluate the `model` performance, we can plot the raw network error:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估 `model` 的性能，我们可以绘制原始网络误差图：
- en: '[PRE69]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The plot of error versus epoch is shown in the following figure:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 错误与周期（epoch）的图形如下所示：
- en: '![](img/00151.gif)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00151.gif)'
- en: We get the minimum error at 34 epochs.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 34 个周期时得到了最小的错误。
- en: 'We finally have the network trained and ready for use; now we can use it to
    make our predictions:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最终训练好了网络并准备好使用；现在我们可以用它来进行预测：
- en: '[PRE70]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'We used the entire set of data at our disposal to make our forecast using the
    model. All we have to do is compare the results obtained with the model predictions
    and the data available in the dataset:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了我们所有可用的数据集来进行预测。我们只需要将模型预测结果与数据集中可用的实际结果进行比较：
- en: '[PRE71]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The results are shown as follows:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '[PRE72]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'The results are really good! Only two wrong classifications! I would say that
    we can be content with the fact that they started from `683` observations. To
    better understand what the errors were, we build a confusion matrix:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 结果真的很好！只有两个错误的分类！我认为我们可以对从 `683` 个观测值开始的结果感到满意。为了更好地理解错误是什么，我们构建了一个混淆矩阵：
- en: '[PRE73]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'The results are shown here:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 结果如下所示：
- en: '[PRE74]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Although in a simple way, the matrix tells us that we only made two errors
    equally distributed between the two values of the class. For more information
    on the confusion matrix, we can use the `CrossTable()` function contained in the
    `gmodels` package. As always, before loading the book, you need to install it:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是一种简单的方式，矩阵告诉我们我们仅犯了两个错误，并且错误在类别的两个值之间均匀分布。有关混淆矩阵的更多信息，我们可以使用 `gmodels` 包中的
    `CrossTable()` 函数。和往常一样，在加载这个包之前，您需要先安装它：
- en: '[PRE75]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'The confusion matrix obtained by using the `CrossTable()` function is shown
    in the following figure:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `CrossTable()` 函数获得的混淆矩阵如下图所示：
- en: '![](img/00152.jpeg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00152.jpeg)'
- en: 'As we had anticipated in the classification, our model has only two errors:
    *FP* and *FN*. Then calculate the accuracy; as indicated in [Chapter 2](part0056.html#1LCVG0-263fb608a19f4bb5955f37a7741ba5c4),
    *Learning Processes in Neural Networks*, it is given by the following formula:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在分类中预期的那样，我们的模型只有两个错误：*FP* 和 *FN*。然后计算准确率；如[第2章](part0056.html#1LCVG0-263fb608a19f4bb5955f37a7741ba5c4)《神经网络中的学习过程》所示，准确率由以下公式给出：
- en: '![](img/00153.jpeg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00153.jpeg)'
- en: 'Let''s calculate the accuracy in R environment:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 R 环境中计算准确率：
- en: '[PRE76]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: As mentioned before, the classifier has achieved excellent results.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，分类器取得了非常好的成绩。
- en: Summary
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this final chapter, we saw some use cases with neural networks and deep learning.
    This should form the basis of your future work on neural networks. The usage is
    common in most cases, with changes in the dataset involved for the model during
    training and testing.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后，我们看到了神经网络和深度学习的一些应用案例。这些内容应该构成你未来从事神经网络工作的基础。在大多数情况下，使用方法是常见的，训练和测试过程中模型所涉及的数据集会有所变化。
- en: 'We saw the following examples in this chapter:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中看到以下示例：
- en: Integrating TensorFlow and Keras with R, which opens up vast set of use cases
    to be built using R
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将TensorFlow和Keras与R集成，这为使用R构建广泛的应用案例开辟了巨大空间
- en: Building a digit recognizer through classification using H2O
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用H2O构建数字识别器，通过分类实现
- en: Understanding the LSTM function with MxNet
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用MxNet理解LSTM函数
- en: PCA using H2O
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用H2O进行PCA
- en: Building an autoencoder using H2O
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用H2O构建自编码器
- en: Usage of `darch` for classification problems
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`darch`解决分类问题
- en: R is a very flexible and a major statistical programming language for data scientists
    across the world. A grasp of neural networks with R will help the community evolve
    further and increase the usage of R for deep learning and newer use cases.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: R是一种非常灵活的统计编程语言，是全球数据科学家的主要工具。掌握R中的神经网络将有助于社区的进一步发展，并增加R在深度学习和新兴应用中的使用。
