- en: '*Chapter 17*: Visualizing Insights from Handwritten Content'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第17章*：从手写内容中可视化见解'
- en: In the previous chapters, we talked about and learned how to build **Intelligent
    Document Processing** (**IDP**) pipelines using **Amazon Textract**, **Amazon
    Comprehend**, and **Amazon A2I**. The advantage of setting up such pipelines is
    that you introduce automation into your operational processes and unlock insights
    that were previously not so evident. Speaking of insights, what are they exactly
    and why is everyone so interested in mining text, and of what use can they be?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们讨论并学习了如何使用**Amazon Textract**、**Amazon Comprehend**和**Amazon A2I**构建**智能文档处理**（**IDP**）流水线。设置此类流水线的优势在于，你可以将自动化引入到你的运营流程中，并解锁以前不太明显的见解。说到见解，它们究竟是什么？为什么每个人都如此热衷于从文本中挖掘见解，它们到底有什么用呢？
- en: 'To answer this, let''s summon *Doc Brown* and *Marty McFly''s* time-traveling
    car, the *DeLorean* from the movie *Back to the Future*, and travel back to [*Chapter
    1*](B17528_01_Final_SB_ePub.xhtml#_idTextAnchor020), *NLP in the Business Context
    and Introduction to AWS AI Services*, to re-read the *Understanding why NLP is
    becoming mainstream* section. Remember now? Maybe this will help: according to
    *Webster''s dictionary* ([https://www.merriam-webster.com/](https://www.merriam-webster.com/)),
    the word "*insight*" is defined as "*the act or result of apprehending the inner
    nature of things or of seeing intuitively*." You got it – it is all about uncovering
    useful information from seemingly vague or even mundane data. Simply put, it means
    to "*see with clarity*."'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解答这个问题，让我们召唤*Doc Brown*和*马蒂·麦克弗莱*的时光旅行车，电影*回到未来*中的*DeLorean*，回到[*第1章*](B17528_01_Final_SB_ePub.xhtml#_idTextAnchor020)，*商业环境中的NLP及AWS
    AI服务简介*，重新阅读*理解为什么NLP正在成为主流*这一部分。你现在记得了吗？也许这样能帮到你：根据*韦伯斯特词典*（[https://www.merriam-webster.com/](https://www.merriam-webster.com/)），“*见解*”一词被定义为“*理解事物内在本质或直觉性地看到的行为或结果*”。你明白了——这就是从看似模糊甚至平凡的数据中发现有用信息。简单来说，它意味着“*清晰地看到*”。
- en: This chapter is all about how to visualize insights from text – that is, handwritten
    text – and make use of it to drive decision-making. According to Wikipedia, the
    earliest known handwritten script was **Cuneiform** ([https://en.wikipedia.org/wiki/Cuneiform](https://en.wikipedia.org/wiki/Cuneiform)),
    which was prevalent almost 5,500 years ago. Equally old in spoken and written
    form is the native language of one of the authors, the Tamil language. That said,
    let's now head back to our favorite fictional organization, **LiveRight Holdings**,
    to solve a new challenge they seem to be having.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍如何将文本中的见解可视化——也就是手写文本——并利用这些见解推动决策制定。根据维基百科，已知最早的手写文字是**楔形文字**（[https://en.wikipedia.org/wiki/Cuneiform](https://en.wikipedia.org/wiki/Cuneiform)），大约出现在5500多年前。与此一样古老的，还有其中一位作者的母语——泰米尔语，无论是在口语还是书写形式上都已有几千年的历史。话虽如此，现在让我们回到我们最喜爱的虚构组织——**LiveRight
    Holdings**，解决他们似乎遇到的新挑战。
- en: You have been given the task of running the Founder's Day for the firm, which
    is touted to be a spectacular gala, considering how popular LiveRight has become.
    To keep up with LiveRight's culture of benefiting the community, you will have
    to work with several local vendors to source what you need, such as furniture,
    food, and other items, for the event. You have been told that the management needs
    aggregated reports of all expenditure, so you decide to use your existing Document
    Processing pipeline to process their receipts. However, to your chagrin, you discover
    that the local vendors only provide handwritten receipts. You remember from a
    previous solution you built that Amazon Textract supports handwritten content,
    so you start thinking about how best to design for the situation.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你被赋予了为公司举办创始人日的任务，这场活动预计将是一场盛大的庆典，因为LiveRight的知名度日益提高。为了跟上LiveRight文化，推动社区利益，你需要与几家当地供应商合作，为活动提供所需的家具、食物及其他物品。你被告知管理层需要所有支出的汇总报告，所以你决定使用现有的文档处理流水线来处理他们的收据。然而，令你沮丧的是，你发现当地供应商仅提供手写收据。你记得你之前构建的一个解决方案中，Amazon
    Textract支持手写内容，于是你开始思考如何最好地设计这个解决方案。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Extracting text from handwritten images
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从手写图像中提取文本
- en: Visualizing insights using Amazon QuickSight
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon QuickSight 可视化见解
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you will need access to an AWS account, which you can do at
    [https://aws.amazon.com/console/](https://aws.amazon.com/console/). Please refer
    to the *Signing up for an AWS account* sub-section within the *Setting up your
    AWS environment* section of [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027),
    *Introducing Amazon Textract*, for detailed instructions on how you can signup
    for an AWS account and sign into the **AWS Management Console**.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要你拥有一个AWS账户，你可以在[https://aws.amazon.com/console/](https://aws.amazon.com/console/)注册。有关如何注册AWS账户并登录**AWS管理控制台**的详细说明，请参考[*第2章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)中的*注册AWS账户*小节，*介绍Amazon
    Textract*部分。
- en: The Python code and sample datasets for the solution discussed in this chapter
    can be found at [https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2017](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2017).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论的解决方案的Python代码和示例数据集可以在[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2017](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2017)找到。
- en: Check out the following video to see the Code in Action at [https://bit.ly/3vLX5j0](https://bit.ly/3vLX5j0).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看以下视频，了解代码的实际操作：[https://bit.ly/3vLX5j0](https://bit.ly/3vLX5j0)。
- en: Extracting text from handwritten images
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从手写图像中提取文本
- en: At this point, you are ready to start designing and building the approach. You
    realize that what will you build for this use case will become an extension of
    the existing Document Processing solution, so it will have long-term usage within
    the organization. So, you need to design for future scalability. With this in
    mind, you decide to use **Amazon S3** ([https://aws.amazon.com/s3/](https://aws.amazon.com/s3/))
    for object storage, **Amazon Textract** ([https://aws.amazon.com/textract/](https://aws.amazon.com/textract/))
    for handwriting detection, and **Amazon QuickSight** ([https://aws.amazon.com/quicksight/](https://aws.amazon.com/quicksight/)),
    a serverless ML-powered business intelligence service, for visualizing the insights
    from the handwritten content. We will be using an Amazon SageMaker Jupyter notebook
    for text extraction, followed by the AWS Management Console to set up the QuickSight
    visualizations. Let's get started.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你已经准备好开始设计和构建方案。你意识到，为这个用例所构建的内容将成为现有文档处理解决方案的扩展，因此将在组织内长期使用。所以，你需要为未来的可扩展性进行设计。考虑到这一点，你决定使用**Amazon
    S3**（[https://aws.amazon.com/s3/](https://aws.amazon.com/s3/)）作为对象存储，**Amazon
    Textract**（[https://aws.amazon.com/textract/](https://aws.amazon.com/textract/)）进行手写识别，**Amazon
    QuickSight**（[https://aws.amazon.com/quicksight/](https://aws.amazon.com/quicksight/)），这是一项无服务器的、由机器学习驱动的商业智能服务，用于可视化手写内容的洞察。我们将使用Amazon
    SageMaker Jupyter notebook进行文本提取，然后使用AWS管理控制台来设置QuickSight可视化。让我们开始吧。
- en: Creating the SageMaker Jupyter notebook
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建SageMaker Jupyter notebook
- en: If you have not done so in the previous chapters, you will have to create an
    Amazon SageMaker Jupyter notebook and set up **Identity and Access Management**
    (**IAM**) permissions for that Notebook Role to access the AWS services we will
    use in this notebook. After that, you will need to clone this book's GitHub repository
    ([https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services)),
    create an Amazon S3 bucket ([https://aws.amazon.com/s3/](https://aws.amazon.com/s3/)),
    and provide the bucket name in the notebook to start execution.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在前面的章节中没有进行过此操作，你需要创建一个Amazon SageMaker Jupyter notebook，并为该Notebook角色设置**身份和访问管理**（**IAM**）权限，以便访问我们将在此notebook中使用的AWS服务。之后，你需要克隆本书的GitHub仓库（[https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services](https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services)），创建一个Amazon
    S3存储桶（[https://aws.amazon.com/s3/](https://aws.amazon.com/s3/)），并在notebook中提供存储桶名称以开始执行。
- en: Note
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Please ensure you have completed the tasks mentioned in the *Technical requirements*
    section.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保你已完成*技术要求*部分中提到的任务。
- en: 'Follow these steps to complete these tasks before we execute the cells from
    our notebook:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行notebook中的单元格之前，请按照以下步骤完成这些任务：
- en: Follow the instructions documented in the *Creating an Amazon SageMaker Jupyter
    notebook instance* sub-section in the *Setting up your AWS environment* section
    of [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027), *Introducing
    Amazon Textract*, to create your Jupyter notebook instance.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照[*第2章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)中*设置你的AWS环境*章节下的*创建一个Amazon
    SageMaker Jupyter笔记本实例*子章节中的说明，创建你的Jupyter笔记本实例。
- en: IAM Role Permissions While Creating Amazon SageMaker Jupyter Notebooks
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 创建Amazon SageMaker Jupyter笔记本时的IAM角色权限
- en: Accept the default for the IAM Role at notebook creation time to allow access
    to an S3 bucket.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在创建笔记本时接受IAM角色的默认设置，以允许访问S3存储桶。
- en: Once you have created the notebook instance and its status is **InService**,
    click on **Open Jupyter** from the **Actions** menu heading to get the notebook
    instance.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你创建了笔记本实例并且其状态为**InService**，点击**操作**菜单中的**打开Jupyter**，以获取笔记本实例。
- en: This will take you to the home folder of your notebook instance.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将带你进入笔记本实例的主文件夹。
- en: Click on **New** and select **Terminal**.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**新建**并选择**终端**。
- en: If you've not done so already, in the terminal window, type `cd SageMaker`,
    followed by `git clone https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services`.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你还没有这样做，在终端窗口中输入`cd SageMaker`，然后输入`git clone https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services`。
- en: Now, exit the terminal window and go back to the home folder; you will see a
    folder called `Natural-Language-Processing-with-AWS-AI-Services`. Click this folder
    to bring up the chapter folders and click on **Chapter 17**.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，退出终端窗口并返回到主文件夹；你将看到一个名为`Natural-Language-Processing-with-AWS-AI-Services`的文件夹。点击该文件夹，打开章节文件夹，并点击**第17章**。
- en: Open this folder by clicking on it. You should see a notebook called `chapter17-deriving-insights-from-handwritten-content-forGitHub.ipynb`.
    Open this notebook by clicking on it. We will need this notebook in the upcoming
    sections. For now, leave this window open.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击该文件夹以打开。你应该会看到一个名为`chapter17-deriving-insights-from-handwritten-content-forGitHub.ipynb`的笔记本。点击它以打开。我们将在接下来的章节中使用此笔记本。现在，请保持此窗口打开。
- en: Next, we'll cover some additional IAM prerequisites.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将介绍一些额外的IAM先决条件。
- en: Additional IAM prerequisites
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 额外的IAM先决条件
- en: 'We have to enable additional policies for our SageMaker notebook role. Please
    refer to the *Changing IAM permissions and trust relationships for the Amazon
    SageMaker notebook execution role* sub-section in the *Setting up your AWS environment*
    section of [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027), *Introducing
    Amazon Textract*, for detailed instructions for executing the following steps:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为SageMaker笔记本角色启用额外的策略。请参考[*第2章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)中*设置你的AWS环境*章节下的*更改IAM权限和信任关系以便于Amazon
    SageMaker笔记本执行角色*子章节中的详细说明，执行以下步骤：
- en: Please attach all the `TextractFullAccess` policies to your Amazon SageMaker
    Notebook IAM Role if you haven't done so already.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你还没有这样做，请将所有`TextractFullAccess`策略附加到你的Amazon SageMaker笔记本IAM角色上。
- en: 'Add an `iam:PassRole` permission as an inline policy to your SageMaker Notebook
    Execution Role:'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`iam:PassRole`权限作为内联策略添加到你的SageMaker笔记本执行角色中：
- en: '[PRE0]'
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now that we have set up our Notebook and set up an IAM Role to run the walkthrough
    notebook, in the next section, we will create an Amazon S3 bucket.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经设置好了笔记本并为运行演练笔记本设置了IAM角色，在接下来的章节中，我们将创建一个Amazon S3存储桶。
- en: Creating an Amazon S3 bucket
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个Amazon S3存储桶
- en: 'Follow the instructions documented in the *Creating an Amazon S3 bucket, a
    folder, and uploading objects* sub-section in the *Setting up your AWS environment*
    section of [*Chapter 2*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027), *Introducing
    Amazon Textract*, to create your Amazon S3 bucket. If you created an S3 bucket
    in the previous sections, please reuse that bucket. For this chapter, you just
    need to create the S3 bucket; we will create the folders and upload the necessary
    objects directly from the notebook. Let''s get started:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 按照[*第2章*](B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027)中*设置你的AWS环境*章节下的*创建一个Amazon
    S3存储桶、一个文件夹，并上传对象*子章节中的说明，创建你的Amazon S3存储桶。如果你在前面的章节中已经创建了S3存储桶，请重新使用该存储桶。对于本章，你只需创建S3存储桶；我们将直接通过笔记本创建文件夹并上传必要的对象。让我们开始吧：
- en: 'Once you have the bucket''s name, please type it in *STEP 0 – CELL 1* of the
    notebook:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦你有了存储桶的名称，请在笔记本的*STEP 0 – CELL 1*中输入该名称：
- en: '[PRE1]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Execute *STEP 0 – CELL 1* of the notebook by clicking the **Run** button at
    the top menu of the notebook UI. Alternatively, you can press **Shift** **+ Enter**
    to execute the cell. This will import the libraries we need, initialize their
    variables, and get our kernel ready for the next set of steps.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过点击笔记本UI顶部菜单中的**运行**按钮，执行*步骤 0 – 单元格 1*。或者，你也可以按**Shift** **+ Enter**来执行该单元格。这将导入我们需要的库，初始化它们的变量，并为下一组步骤准备好内核。
- en: Now that we have created the S3 bucket and imported the libraries we need, let's
    extract the contents using **Amazon Textract**.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了S3存储桶并导入了所需的库，接下来让我们使用**Amazon Textract**提取内容。
- en: Extracting text using Amazon Textract
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Amazon Textract提取文本
- en: 'We will now continue executing the rest of the cells in the notebook to update
    the QuickSight manifest file with our bucket and prefix entries. The manifest
    file provides metadata for the QuickSight dataset to correctly import the content
    for visualization. Please see the documentation ([https://docs.aws.amazon.com/quicksight/latest/user/create-a-data-set-s3.html](https://docs.aws.amazon.com/quicksight/latest/user/create-a-data-set-s3.html))
    for more details. Let''s get started:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将继续执行笔记本中的其余单元格，以更新QuickSight清单文件，包含我们的存储桶和前缀条目。清单文件为QuickSight数据集提供元数据，以便正确导入内容进行可视化。更多详情，请参阅文档（[https://docs.aws.amazon.com/quicksight/latest/user/create-a-data-set-s3.html](https://docs.aws.amazon.com/quicksight/latest/user/create-a-data-set-s3.html)）。让我们开始吧：
- en: Execute *STEP 1 – CELL 1* in the notebook to format the manifest file with the
    bucket and prefix names.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行*步骤 1 – 单元格 1*以格式化清单文件，加入存储桶和前缀名称。
- en: 'Now, execute *STEP 1 – CELL 2* to upload the formatted manifest file to the
    S3 bucket:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，执行*步骤 1 – 单元格 2*将格式化后的清单文件上传到S3存储桶：
- en: '[PRE2]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will get the following output. Take a copy of the S3 location that is printed
    here as we will need it when we set up QuickSight:'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将得到以下输出。请复制这里打印出的S3位置，稍后在设置QuickSight时需要用到：
- en: '[PRE3]'
  id: totrans-47
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, execute *STEP 2 – CELL 1* to install the **Amazon Textract Response Parser**
    (**TRP**) ([https://github.com/aws-samples/amazon-textract-response-parser/blob/master/src-python/README.md](https://github.com/aws-samples/amazon-textract-response-parser/blob/master/src-python/README.md)),
    a helper library that provides you with an easy way to parse the JSON response
    from Textract:'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，执行*步骤 2 – 单元格 1*以安装**Amazon Textract Response Parser**（**TRP**）（[https://github.com/aws-samples/amazon-textract-response-parser/blob/master/src-python/README.md](https://github.com/aws-samples/amazon-textract-response-parser/blob/master/src-python/README.md)），这是一个帮助库，提供了一种简便的方法来解析Textract的JSON响应：
- en: '[PRE4]'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Execute *STEP 2 – CELL 2* to import the parser's Document class, which we need
    to initialize the boto3 handle for Textract.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行*步骤 2 – 单元格 2*以导入解析器的Document类，我们需要它来初始化boto3处理程序以用于Textract。
- en: '*STEP 2 – CELL 3* does a few things, so let''s examine it in parts. First,
    it searches the current directory for the presence of files ending with a *.jpg*
    extension. These are our input image files of the receipts. The following is one
    of these receipts:![Figure 17.1 – A sample handwritten receipt'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*步骤 2 – 单元格 3*做了几件事，让我们分部分来看。首先，它会在当前目录中查找以*.jpg*扩展名结尾的文件。这些是我们手写收据的输入图像文件。以下是其中一张收据：![图
    17.1 – 一张手写收据的示例'
- en: '](img/B17528_17_01.jpg)'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_17_01.jpg)'
- en: Figure 17.1 – A sample handwritten receipt
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 17.1 – 一张手写收据的示例
- en: 'When they''re found, the files are read one at a time and converted into bytearrays:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当找到这些文件时，会逐个读取并转换成字节数组：
- en: '[PRE5]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, it calls the `AnalyzeDocument` Textract API and passes `bytearray` as
    an input, specifically looking for tables and forms from the input image. The
    Textract response is then parsed by the Textract Response Parser library and the
    results are stored in a variable. Then, we must loop through the results to get
    to the table and initialize a variable denoting the CSV file we will write to:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，它调用`AnalyzeDocument` Textract API，并将`bytearray`作为输入，特别是从输入图像中寻找表格和表单。然后，Textract响应会被Textract
    Response Parser库解析，结果存储在一个变量中。接着，我们必须遍历这些结果，找到表格，并初始化一个变量，表示我们将写入的CSV文件：
- en: '[PRE6]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Finally, the individual cell values are written to the CSV file, along with
    the column headings by stripping spaces, if any, as well as the `$` symbol, denoting
    the currency. Finally, the newly created CSV files are uploaded to the S3 bucket.
    This is repeated for each image file that''s found in the input folder:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终，单个单元格的值会写入CSV文件中，同时去除空格（如果有的话）以及表示货币的`$`符号。最后，新的CSV文件会上传到S3存储桶。对于输入文件夹中找到的每个图像文件，都会重复此过程：
- en: '[PRE7]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Execute *STEP 2 – CELL 3* to complete the tasks outlined in the preceding steps.
    We will get the following output. Please make a note of the S3 location of the
    CSV files. The manifest file we formatted earlier contains these locations to
    allow QuickSight to upload these CSV files:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行*步骤 2 – 单元格 3* 完成前述步骤中概述的任务。我们将得到以下输出。请记下 CSV 文件的 S3 位置。我们之前格式化的清单文件包含这些位置，允许
    QuickSight 上传这些 CSV 文件：
- en: '[PRE8]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Note
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意
- en: You can also use **Amazon A2I** in this solution to set up a human loop to review
    the Textract outputs, as well as to make changes to the content as required, before
    creating the CSV files. For more details, please refer to [*Chapter 13*](B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151),
    *Improving the Accuracy of Document Processing Workflows*, onward.
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您还可以在此解决方案中使用**Amazon A2I**，设置人工循环来审查 Textract 输出，并根据需要对内容进行更改，然后创建 CSV 文件。更多详细信息，请参考[*第
    13 章*](B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151)，*提高文档处理工作流的准确性*，继续阅读。
- en: This concludes the steps from the notebook. Now, we will log into the AWS Management
    Console to set up QuickSight for visualization.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这标志着笔记本中的步骤已经完成。接下来，我们将登录 AWS 管理控制台，设置 QuickSight 以进行可视化。
- en: Visualizing insights using Amazon QuickSight
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon QuickSight 进行洞察可视化
- en: 'First, we need to enable QuickSight for your AWS account before we can import
    the data and run the visualizations. Please execute the following steps to proceed:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要为您的 AWS 账户启用 QuickSight，才能导入数据并运行可视化。请执行以下步骤继续：
- en: Log into AWS Management Console (refer to the *Technical requirements* section
    if you don't have access to the AWS Management Console) and type `QuickSight`
    in the services search bar at the top center of the page. Click **QuickSight**
    from the results to be navigated to the **QuickSight registration** page.
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到 AWS 管理控制台（如果没有访问权限，请参考*技术要求*部分），并在页面顶部中间的服务搜索框中输入`QuickSight`。点击搜索结果中的**QuickSight**，进入**QuickSight
    注册**页面。
- en: Enter your email address and click **Continue**:![Figure 17.2 – Registering
    for QuickSight](img/B17528_17_02.jpg)
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入您的电子邮件地址并点击**继续**：![图 17.2 – 注册 QuickSight](img/B17528_17_02.jpg)
- en: Figure 17.2 – Registering for QuickSight
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 17.2 – 注册 QuickSight
- en: Once you've logged in, click **Datasets** on the left pane and click the **New
    dataset** button at the top right:![Figure 17.3 – New dataset
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录后，点击左侧面板中的**数据集**，然后点击右上角的**新建数据集**按钮：![图 17.3 – 新建数据集
- en: '](img/B17528_17_03.jpg)'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_17_03.jpg)'
- en: Figure 17.3 – New dataset
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 17.3 – 新建数据集
- en: Click on **S3** on the **Datasets** page:![Figure 17.4 – S3
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**数据集**页面上的**S3**：![图 17.4 – S3
- en: '](img/B17528_17_04.jpg)'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_17_04.jpg)'
- en: Figure 17.4 – S3
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 17.4 – S3
- en: In the popup that appears, for `handwritten-receipts`. In the **Upload a manifest
    file** input area, copy and paste the S3 location that was printed in the Jupyter
    notebook in *STEP 1 – CELL 2*. Then, click on **Connect**:![Figure 17.5 – Specifying
    the S3 manifest file
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在弹出的窗口中，对于`handwritten-receipts`，在**上传清单文件**输入区域，复制并粘贴在 Jupyter 笔记本中 *步骤 1 –
    单元格 2* 打印的 S3 位置。然后，点击**连接**：![图 17.5 – 指定 S3 清单文件
- en: '](img/B17528_17_05.jpg)'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_17_05.jpg)'
- en: Figure 17.5 – Specifying the S3 manifest file
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 17.5 – 指定 S3 清单文件
- en: Once the dataset has been imported, click the `Chapter17/dashboard` prefix:![Figure
    17.6 – Dataset import successful
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据集导入完成后，点击`Chapter17/dashboard`前缀：![图 17.6 – 数据集导入成功
- en: '](img/B17528_17_06.jpg)'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_17_06.jpg)'
- en: Figure 17.6 – Dataset import successful
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 17.6 – 数据集导入成功
- en: You should see the column names from the CSV file displayed to the left, under
    **Fields list**. You should see a center pane with space for a graph named **AutoGraph**.
    When you add fields from the list on the left, QuickSight automatically creates
    the appropriate graph based on your data.
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您应该看到左侧显示来自 CSV 文件的列名，位于**字段列表**下方。您应该看到一个中间面板，里面有一个名为**AutoGraph**的图形空间。当您从左侧列表中添加字段时，QuickSight
    会根据您的数据自动创建适当的图形。
- en: For our use case, we will create a pie chart and a donut chart to visualize
    the quantity of furniture that's been ordered and how much it cost us. Under the
    **Visual types** section on the left, click on the symbol for the pie chart and
    add fields from **Fields list** to the chart, as shown here:![Figure 17.7 – Visualizing
    furniture quantities across types](img/B17528_17_07.jpg)
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于我们的使用案例，我们将创建饼图和甜甜圈图来可视化已订购的家具数量及其费用。在左侧的**视觉类型**部分，点击饼图符号，并将字段从**字段列表**添加到图表中，如下所示：![图
    17.7 – 可视化各类家具的数量](img/B17528_17_07.jpg)
- en: Figure 17.7 – Visualizing furniture quantities across types
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 17.7 – 可视化各类家具的数量
- en: Now, let's add a new visual to this dashboard. Click on **Add** at the top left
    and select **Add visual**:![Figure 17.8 – Add visual
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们向这个仪表板添加一个新的可视化。点击左上方的 **Add**，然后选择 **Add visual**：![Figure 17.8 – 添加可视化
- en: '](img/B17528_17_08.jpg)'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B17528_17_08.jpg)'
- en: Figure 17.8 – Add visual
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Figure 17.8 – 添加可视化
- en: Now, add a donut chart to display the total costs and cost by furniture type,
    as shown in the following screenshot. Begin by selecting the donut visual in the
    **Visual types** section on the left, select **ITEM** and **PRICE**, and then
    add them to the **Group/Color** and **Value** fields:![Figure 17.9 – Donut chart
    for visualizing the total costs and cost by furniture type](img/B17528_17_09.jpg)
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，添加一个甜甜圈图来显示总成本和按家具类型分类的成本，如下图所示。首先，在左侧的 **Visual types** 部分选择甜甜圈可视化，选择 **ITEM**
    和 **PRICE**，然后将它们添加到 **Group/Color** 和 **Value** 字段中：![Figure 17.9 – 用于可视化总成本和按家具类型分类的成本的甜甜圈图](img/B17528_17_09.jpg)
- en: Figure 17.9 – Donut chart for visualizing the total costs and cost by furniture
    type
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Figure 17.9 – 用于可视化总成本和按家具类型分类的成本的甜甜圈图
- en: 'Click on the **Insights** option on the middle left of the console to display
    the insights that QuickSight was able to gather from our data:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在控制台左侧中间点击 **Insights** 选项，显示 QuickSight 能够从我们的数据中提取的见解：
- en: '![Figure 17.10 – QuickSight insights from our data'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![Figure 17.10 – QuickSight 从我们的数据中提取的见解'
- en: '](img/B17528_17_10.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17528_17_10.jpg)'
- en: Figure 17.10 – QuickSight insights from our data
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 17.10 – QuickSight 从我们的数据中提取的见解
- en: 'It is as simple as that. Feel free to try out the other visual types, as well
    as ML-powered forecasting and insights. For more details, please refer to the
    following documentation: [https://docs.aws.amazon.com/quicksight/latest/user/making-data-driven-decisions-with-ml-in-quicksight.html](https://docs.aws.amazon.com/quicksight/latest/user/making-data-driven-decisions-with-ml-in-quicksight.html).
    You can set up, share, publish, or export your dashboard for consumption by your
    management and other stakeholders. And that concludes the solution build for this
    use case.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 就这么简单。随时可以尝试其他类型的可视化，以及 ML 驱动的预测和见解。有关更多详情，请参考以下文档：[https://docs.aws.amazon.com/quicksight/latest/user/making-data-driven-decisions-with-ml-in-quicksight.html](https://docs.aws.amazon.com/quicksight/latest/user/making-data-driven-decisions-with-ml-in-quicksight.html)。您可以设置、共享、发布或导出仪表板，以供管理层和其他利益相关者使用。这也标志着本用例解决方案构建的结束。
- en: Summary
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We have just scratched the surface with what we can do with written text with
    this use case – the possibilities are truly endless! With just a few steps, by
    leveraging the advanced AI capabilities offered by services such as Amazon Textract,
    and the serverless scalable visualization offered by Amazon QuickSight, we were
    able to create powerful visuals from content scribbled on a piece of paper.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个用例中，我们只是触及了我们能够处理书面文本的一小部分——可能性真的是无穷无尽的！只需几个步骤，通过利用 Amazon Textract 等服务提供的先进
    AI 能力，以及 Amazon QuickSight 提供的无服务器可扩展可视化，我们就能够从一张纸上潦草的内容中创建出强大的可视化效果。
- en: We began by creating the SageMaker Jupyter notebook instance we needed for this
    solution, cloned the GitHub repository for this chapter, created an S3 bucket,
    and executed the steps in the notebook to format the QuickSight S3 manifest file.
    Then, we used Amazon Textract and the Textract Response Parser library to read
    the contents of the handwritten receipts before creating CSV files that were uploaded
    to the S3 bucket. We concluded the notebook after executing these steps and then
    logged into the AWS Management Console and registered to use Amazon QuickSight.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建了这个解决方案所需的 SageMaker Jupyter notebook 实例，克隆了本章的 GitHub 仓库，创建了一个 S3 存储桶，并在
    notebook 中执行了步骤以格式化 QuickSight S3 清单文件。然后，我们使用 Amazon Textract 和 Textract Response
    Parser 库读取手写收据的内容，之后创建了 CSV 文件并上传到 S3 存储桶。在执行完这些步骤后，我们结束了 notebook，并登录到 AWS 管理控制台，注册使用
    Amazon QuickSight。
- en: In QuickSight, we imported the S3 dataset, which comprised our CSV files, and
    created two visuals and an insight. The first visual was a pie chart that showed
    the items that have been ordered against their quantities, while the second visual
    was a donut chart that showed the total cost of the two receipts, along with the
    cost per item. Finally, we displayed the insights that QuickSight had automatically
    generated, giving us a summary of what it was able to read from our content. We
    briefly discussed how we can export or share the dashboard and QuickSight's ML-based
    insights. And that concluded our solution build for this chapter.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在QuickSight中，我们导入了包含CSV文件的S3数据集，并创建了两个可视化图表和一个洞察。第一个图表是一个饼图，显示了已订购物品与其数量的对比，第二个图表是一个甜甜圈图，显示了两张收据的总成本，以及每个物品的成本。最后，我们展示了QuickSight自动生成的洞察，提供了它从我们的内容中读取到的摘要。我们简要讨论了如何导出或分享仪表板及QuickSight的基于ML的洞察。这也完成了本章的解决方案构建。
- en: Based on the myriad of use cases we have covered in this book so far, you know
    how to solve mainstream challenges in NLP for you and your customers, and we did
    all this without the need to tune a hyperparameter or train a model from the ground
    up. Granted, we trained a few custom Comprehend models, but that was without the
    overhead of a traditional ML workflow.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 基于本书至今覆盖的众多使用案例，你已经知道如何为你和你的客户解决NLP中的主流挑战，而且我们完成这一切时没有需要调优任何超参数或从零开始训练模型。当然，我们训练了几个自定义的Comprehend模型，但那是没有传统机器学习工作流开销的。
- en: In the next chapter, we will conclude this book, so we thought we would leave
    you with some best practices, techniques, and guidelines to keep in your back
    pocket as you navigate your career as an NLP and AI expert. We will talk about
    document pre-processing, post-processing, and other items to consider during solution
    design. We are almost there!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将结束本书，因此我们想留下些最佳实践、技巧和指南，供你在作为NLP和AI专家的职业生涯中随时参考。我们将讨论文档的预处理、后处理以及在解决方案设计过程中需要考虑的其他事项。我们快到了！
