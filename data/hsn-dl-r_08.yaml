- en: Neural Collaborative Filtering Using Embeddings
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用嵌入的神经协同过滤
- en: In the previous chapter, you learned how to implement a **multilayer perceptron**
    (**MLP**) neural network for signal detection.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了如何实现**多层感知机**（**MLP**）神经网络进行信号检测。
- en: In this chapter, you will explore how to build a recommender system using collaborative
    filtering with neural network-based embeddings. We will briefly introduce recommender
    systems and then proceed from concept to implementation. Specifically, you will
    learn how to use the custom Keras API to construct a neural network-based recommender
    system with embedded layers to predict user ratings.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将带你探索如何使用基于神经网络嵌入的协同过滤构建推荐系统。我们将简要介绍推荐系统，然后从概念讲解到实际实现。具体来说，你将学习如何使用自定义Keras
    API构建基于神经网络的推荐系统，通过嵌入层来预测用户评分。
- en: 'This chapter covers the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涉及以下主题：
- en: Introducing recommender systems
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍推荐系统
- en: Collaborative filtering with neural networks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用神经网络的协同过滤
- en: Preparing, preprocessing, and exploring data
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备、预处理并探索数据
- en: Performing exploratory data analysis
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行探索性数据分析
- en: Creating user and item embeddings
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建用户和物品嵌入
- en: Building and training a neural recommender system
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建和训练神经推荐系统
- en: Evaluating results and tuning hyperparameters
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估结果和调整超参数
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: We will use the Keras (TensorFlow API) library in this chapter.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将使用Keras（TensorFlow API）库。
- en: We will be using the `steam200k.csv` dataset. This dataset was generated from
    publicly available Steam data, which is one of the world's most popular gaming
    hubs. This data contains a list of items (`game-title`), users (`user-id`), and
    two user behaviors (`own` and `value`), where `value` represents the number of
    hours played for each game. You can find the dataset at: [https://www.kaggle.com/tamber/steam-video-games/version/1#steam-200k.csv](https://www.kaggle.com/tamber/steam-video-games/version/1#steam-200k.csv).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`steam200k.csv`数据集。该数据集来源于公开的Steam数据，Steam是全球最受欢迎的游戏平台之一。该数据包含了物品（`game-title`）、用户（`user-id`）以及两种用户行为（`own`和`value`），其中`value`表示每款游戏的游戏时长。你可以在以下网址找到该数据集：[https://www.kaggle.com/tamber/steam-video-games/version/1#steam-200k.csv](https://www.kaggle.com/tamber/steam-video-games/version/1#steam-200k.csv)。
- en: You can find the code files of this chapter on GitHub: [https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R](https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在GitHub上找到本章的代码文件：[https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R](https://github.com/PacktPublishing/Hands-on-Deep-Learning-with-R)。
- en: Introducing recommender systems
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍推荐系统
- en: Recommender systems are information filtering systems designed to generate accurate
    and relevant item suggestions for users based on available data. Netflix, Amazon,
    YouTube, and Spotify are some popular services with recommender systems in commercial
    use today.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统是信息过滤系统，旨在基于可用数据为用户生成准确且相关的物品建议。Netflix、Amazon、YouTube和Spotify等都是目前在商业中使用推荐系统的流行服务。
- en: 'There are three primary types of recommender systems:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统有三种主要类型：
- en: '**Collaborative filtering**: Item recommendations reflect personalized preferences
    based on similarity to other users. Preferences can be **explicit** (item ratings)
    or **implicit** (item ratings per user-item interactions such as views, purchases,
    and so on).'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**协同过滤**：物品推荐基于与其他用户的相似性，反映了个性化的偏好。偏好可以是**显式的**（物品评分）或**隐式的**（通过用户-物品互动，如观看、购买等进行的物品评分）。'
- en: '**Content-based filtering**: Item recommendations reflect contextual factors
    such as item attributes or user demographics; item suggestions can also use temporal
    factors such as location, date, and time where applicable.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于内容的过滤**：物品推荐反映了上下文因素，如物品属性或用户人口统计信息；物品建议还可以使用时间因素，如适用的地理位置、日期和时间。'
- en: '**Hybrid**: Item recommendations combine a variety (ensemble) of collaborative
    and content-based filtering methods, which have been used in notable competitions
    such as the Netflix Prize (2009).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合**：物品推荐结合了多种（集成）协同过滤和基于内容的过滤方法，这些方法曾在Netflix奖（2009年）等著名竞赛中使用。'
- en: See [https://www.netflixprize.com](https://www.netflixprize.com/) for historical
    details about the Netflix Prize (2009) and various recommender system approaches.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有关Netflix奖（2009年）及各种推荐系统方法的历史细节，请参见[https://www.netflixprize.com](https://www.netflixprize.com/)。
- en: Recommender systems often use data in the form of a sparse matrix of users and
    the items you wish to recommend to them. As its name suggests, a sparse matrix
    is a matrix whose data elements primarily comprise zero values.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统通常使用用户和你希望推荐的物品的稀疏矩阵数据。顾名思义，稀疏矩阵是一个数据元素主要由零值组成的矩阵。
- en: Many recommender system algorithms seek to fill in a user-item interaction matrix
    with item suggestions based on various types of interactions between users and
    items. If there is no item preference or user interaction data available, this
    is frequently referred to as a **cold start problem**, which can be addressed
    with hybrid methods (collaborative and content-based filtering), contextual models
    (temporal, demographic, and metadata), as well as random item and feedback sampling
    strategies, among others. While these interventions are beyond the scope of this
    chapter, it is important to be aware of the diverse, experimental, and rapidly
    evolving types of techniques available.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 许多推荐系统算法旨在通过用户与物品之间的各种交互类型，填充用户-物品交互矩阵，并根据这些交互提供物品建议。如果没有可用的物品偏好或用户交互数据，这通常被称为**冷启动问题**，可以通过混合方法（协同过滤与基于内容的过滤）、上下文模型（时间、人口统计和元数据）以及随机物品和反馈采样策略等方法来解决。尽管这些干预措施超出了本章的范围，但重要的是要意识到可用的多种实验性和快速发展的技术类型。
- en: For purposes of illustration, we will focus our attention on collaborative filtering,
    which is a popular technique that generates recommendations based on user-item
    interactions. Moreover, collaborative filtering is particularly suitable for our
    user-item dataset. In the absence of explicit ratings such as user-item preferences
    (for example, 1 to 5, and like or dislike), we will create implicit preferences
    of user-item ratings based on the hours of gameplay, which is available in our
    dataset.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于说明，我们将重点关注协同过滤，这是一种基于用户-物品交互生成推荐的流行技术。此外，协同过滤特别适合我们的用户-物品数据集。在没有显式评分（例如，1到5，喜欢或不喜欢）时，我们将根据游戏时长创建隐式的用户-物品评分偏好，这些数据在我们的数据集中是可用的。
- en: Collaborative filtering with neural networks
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用神经网络的协同过滤
- en: '**Collaborative filtering** (**CF**) is a core method used by recommender systems
    to filter suggestions by collecting and analyzing preferences about other similar
    users. CF techniques use available information and preference pattern data to
    make predictions (filters) about a particular user''s interests.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**协同过滤**（**CF**）是推荐系统用于通过收集和分析其他相似用户的偏好来过滤建议的核心方法。CF技术利用现有的信息和偏好模式数据，预测（过滤）特定用户的兴趣。'
- en: The collaborative aspect of CF is associated with the notion that relevant recommendations
    are derived from other user preferences. CF also assumes that two individuals
    with similar preferences are more likely to share preferences for a particular
    item than two other individuals selected at random. Accordingly, the primary task
    of CF is to generate item suggestions (predictions) based on other (collaborative)
    similar users within the system.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: CF的协同特性与以下观点相关：相关的推荐是从其他用户的偏好中得出的。CF还假设，两个具有相似偏好的个体，比随机选择的两个个体，更可能对某一物品有共同的偏好。因此，CF的主要任务是基于系统中其他（协同）相似用户生成物品建议（预测）。
- en: To identify similar users and find ratings (preferences) of unrated items, recommender
    systems *typically* need an index of similarity between users and user-item preferences
    based on available input data. Traditional memory-based approaches include calculating
    similarity using distance metrics (cosine similarity, Jaccard), correlations (Pearson),
    or taking a weighted average of user preferences. Other machine learning approaches
    to determine user-item preferences of unrated items include generalized matrix
    factorization methods such as **Principal Component Analysis** (**PCA**), **Singular
    Value Decomposition** (**SVD**), and deep learning matrix factorization, among
    others.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了识别相似的用户并找到未评分物品的评分（偏好），推荐系统*通常*需要基于可用输入数据，使用用户与用户-物品偏好之间的相似度索引。传统的基于记忆的方法包括使用距离度量（余弦相似度、杰卡德相似度）计算相似性，相关性（皮尔逊相关系数），或对用户偏好进行加权平均。其他用于确定未评分物品的用户-物品偏好的机器学习方法包括广义矩阵分解方法，如**主成分分析**（**PCA**）、**奇异值分解**（**SVD**）以及深度学习矩阵分解等。
- en: Exploring embeddings
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索嵌入表示
- en: Broadly speaking, deep neural networks seek to minimize the loss (error) associated
    with non-linear data representations used for learning important features from
    input data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 广义而言，深度神经网络旨在最小化与用于学习输入数据中重要特征的非线性数据表示相关的损失（误差）。
- en: In addition to traditional dimensionality reduction methods such as clustering
    and KNN or matrix factorization (PCA, clustering, and other probabilistic techniques),
    recommender systems can use neural network embeddings to support dimensionality
    reduction and distributed, non-linear data representations in scalable and efficient
    ways.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 除了传统的降维方法（如聚类、KNN 或矩阵分解（PCA、聚类及其他概率技术））外，推荐系统还可以使用神经网络嵌入来支持降维和分布式非线性数据表示，以可扩展和高效的方式进行处理。
- en: '**Embeddings** are low-dimensional representations (vectors) of continuous
    numbers learned from representations (vectors) of discrete input variables in
    neural networks.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**嵌入**是通过神经网络从离散输入变量的表示（向量）中学习的低维连续数字表示（向量）。'
- en: 'Neural network embeddings offer several advantages such as the following:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络嵌入提供了多个优势，如下所示：
- en: Reduced computational time and costs (scalability)
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 减少计算时间和成本（可扩展性）
- en: Decreased amount of input data required for some learning activation functions
    (sparsity)
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对某些学习激活函数所需的输入数据量减少（稀疏性）
- en: Representations of complex, non-linear relationships (flexibility)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂非线性关系的表示（灵活性）
- en: Automated feature importance and selection (efficiency)
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动特征重要性和选择（效率）
- en: Let's take a look at an introductory example of how to prepare data in order
    to implement collaborative filtering using neural networks with embeddings.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个关于如何准备数据以实现基于神经网络嵌入的协同过滤的入门示例。
- en: Preparing, preprocessing, and exploring data
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备、预处理和探索数据
- en: 'Before we build a model, we need to first explore the input data to understand
    what is available for user-item recommendations. In this section, we will prepare,
    process, and explore the data, which includes users, items (games), and interactions
    (hours of gameplay), using the following steps:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建模型之前，我们需要先探索输入数据，以了解有哪些数据可用于用户-物品推荐。在本节中，我们将通过以下步骤准备、处理和探索数据，这些数据包括用户、物品（游戏）和互动（游戏时长）：
- en: 'First, let''s load some R packages for preparing and processing our input data:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们加载一些 R 包，用于准备和处理输入数据：
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, let''s load the data into R:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们将数据加载到 R 中：
- en: '[PRE1]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let''s inspect the input data using `glimpse()`:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们使用 `glimpse()` 检查输入数据：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This results in the following output:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/fa9b5a1b-a7f1-4b6a-bd4a-bbebbf8df07e.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fa9b5a1b-a7f1-4b6a-bd4a-bbebbf8df07e.png)'
- en: 'Let''s manually add column labels to organize this data:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们手动添加列标签，以便整理这些数据：
- en: '[PRE3]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let''s remove any blank columns or extraneous whitespace characters:'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们删除任何空白列或多余的空白字符：
- en: '[PRE4]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we need to create sequential user and item IDs so we can later specify
    an appropriate size for our lookup matrix via the following code:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们需要创建顺序的用户和物品 ID，以便稍后通过以下代码为我们的查找矩阵指定合适的大小：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let''s rename the `item` and `value` fields to clarify we are exploring user-item
    interaction data and implicitly defining user ratings based on the `value` field,
    which represents the total number of hours played for a particular game:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们重命名 `item` 和 `value` 字段，以明确我们正在探索用户-物品互动数据，并根据 `value` 字段（表示某个游戏的总游戏时长）隐式定义用户评分：
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This dataset contains user, item, and interaction data. Let''s use the following
    code to identify the number of users and items available for analysis:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个数据集包含用户、物品和互动数据。让我们使用以下代码来识别可用于分析的用户和物品数量：
- en: '[PRE7]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We identified there are 11,350 users (players) and 3,598 items (games) to explore
    for analysis and recommendations. Since we don't have explicit item ratings (yes/no,
    1-5, for example), we will generate item (game) recommendations based on implicit
    feedback (hours of gameplay) for illustration purposes. Alternatively, we could
    seek to acquire additional user-item data (such as contextual, temporal, or content),
    but we have enough baseline item-interaction data to build our preliminary CF-based
    recommender system with neural network embeddings.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已确定有 11,350 名用户（玩家）和 3,598 个物品（游戏）可供分析和推荐。由于我们没有明确的物品评分（例如，是否/否定、1-5等），我们将基于隐式反馈（游戏时长）生成物品（游戏）推荐以作示范。或者，我们可以尝试获取额外的用户-物品数据（如上下文、时间或内容数据），但我们拥有足够的基础物品互动数据来构建基于神经网络嵌入的初步协同过滤推荐系统。
- en: 'Before proceeding, we need to normalize our rating (user-item interaction)
    data, which can be implemented using standard techniques such as min-max normalization:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在继续之前，我们需要对评分（用户-物品交互）数据进行归一化，这可以通过标准技术如最小-最大归一化来实现：
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, we will split the data into training and test data:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将数据拆分为训练数据和测试数据：
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now we will create matrices of users, items, and ratings for the training and
    test data:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将为训练数据和测试数据创建用户、物品和评分的矩阵：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Prior to building our neural network models, we will first conduct **Exploratory
    data analysis** (**EDA**) to better understand the scope, type, and characteristics
    of the underlying data.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建我们的神经网络模型之前，我们将首先进行**探索性数据分析**（**EDA**），以更好地理解潜在数据的范围、类型和特征。
- en: Performing exploratory data analysis
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进行探索性数据分析
- en: Recommender systems seek to use available information and preference pattern
    data to generate predictions about a particular user's interests.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统试图利用可用信息和偏好模式数据来预测特定用户的兴趣。
- en: 'As a starting point, we can use EDA to identify important patterns and trends
    in the underlying data to inform our understanding and subsequent analysis:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 作为起点，我们可以使用EDA来识别潜在数据中的重要模式和趋势，以帮助我们理解并进行后续分析：
- en: 'Let''s identify the top 10 items based on implicit ratings constructed from
    user-item interaction data using the following code:'
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用以下代码识别基于用户-物品交互数据构建的隐式评分的前10个物品：
- en: '[PRE11]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '*Dota 2* is the most popular item (game) by collective hours played:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '*Dota 2*是按总游戏时间计算的最受欢迎物品（游戏）：'
- en: '![](img/e104ac05-7f83-4e51-9df8-abed47b00ab7.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e104ac05-7f83-4e51-9df8-abed47b00ab7.png)'
- en: 'Let''s produce some summary statistics of user-item interactions to identify
    insights with the following code:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用以下代码生成用户-物品交互的汇总统计，以识别一些洞察：
- en: '[PRE12]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'According to this exploratory analysis, Sid Meier''s *Civilization V* is the
    most popular game by individual hours played:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 根据这次探索性分析，Sid Meier的*文明 V*是按个人游戏时间计算的最受欢迎游戏：
- en: '![](img/fd549d49-a53c-4123-9a22-cc43f45c77cc.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fd549d49-a53c-4123-9a22-cc43f45c77cc.png)'
- en: 'Now, let''s identify and visualize the top 10 games by hours played:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们识别并可视化按游戏时间排列的前10个游戏：
- en: '[PRE13]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This results in the following output:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/d5bd6e83-92c3-4bff-b343-fa94a7bc9516.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d5bd6e83-92c3-4bff-b343-fa94a7bc9516.png)'
- en: 'Next, let''s identify the most popular games by total users:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们识别按总用户数计算的最受欢迎游戏：
- en: '[PRE14]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This results in the following output:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/f09f6a4c-bd55-43e2-b7af-cf1a8dd61c02.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f09f6a4c-bd55-43e2-b7af-cf1a8dd61c02.png)'
- en: 'Now, let''s calculate summary statistics of user-item interaction with the
    following code:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用以下代码计算用户-物品交互的汇总统计：
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This results in the following output:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/a621b44c-ce34-4533-bddd-04c70ee80ba8.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a621b44c-ce34-4533-bddd-04c70ee80ba8.png)'
- en: 'The summary statistics for overall user-item interaction show average (median)
    interaction is `4.5` hours and average (mean) interaction is `48.88` hours, which
    makes sense when you take into consideration the max (outlier) interaction value:
    `11,754` hours of Sid Meier''s *Civilization V*!'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 整体用户-物品交互的汇总统计数据显示，平均（中位数）交互时间为`4.5`小时，平均（算术平均）交互时间为`48.88`小时，这在考虑到最大（离群值）交互值时是合理的：Sid
    Meier的*文明 V*的交互时间为`11,754`小时！
- en: 'Next, let''s take a look at the distribution of items by individual hours played:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们查看按个人游戏时间分布的物品：
- en: '[PRE16]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Here is the resultant output of items by hours played:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是按游戏时间排列的物品结果输出：
- en: '![](img/7f5c977a-db29-4f36-aeb2-0b6cb17c5f46.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7f5c977a-db29-4f36-aeb2-0b6cb17c5f46.png)'
- en: 'Since it''s difficult to determine any clear user-item interaction patterns
    with this approach, let''s re-examine items by hours played with a log transformation
    of hours to reveal any other distributional patterns:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于这种方法很难确定明确的用户-物品交互模式，让我们通过对游戏时间进行对数变换，再次检查按游戏时间排列的物品，以揭示其他分布模式：
- en: '[PRE17]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This results in the following output:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/d22db659-6848-4e12-962b-fc68142da942.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d22db659-6848-4e12-962b-fc68142da942.png)'
- en: By applying a simple log transformation of hours played, we can clearly see
    the majority of games in this dataset are associated with 1,000 hours of gameplay
    or less.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对游戏时间进行简单的对数变换，我们可以清楚地看到大多数数据集中的游戏与1,000小时或更少的游戏时间相关。
- en: Now that we have a better sense of the underlying data, let's focus our attention
    on building a neural network with embeddings to predict user ratings.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对潜在数据有了更好的理解，接下来让我们将注意力集中在构建一个神经网络模型，通过嵌入来预测用户评分。
- en: Creating user and item embeddings
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建用户和物品嵌入
- en: Recommender systems can use deep neural networks to support complex, non-linear
    data representations in flexible, scalable, and efficient ways.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统可以使用深度神经网络以灵活、可扩展且高效的方式支持复杂的非线性数据表示。
- en: Embeddings are low-dimensional representations (vectors) of continuous numbers
    learned from representations (vectors) of discrete input variables in neural networks.
    As previously noted in this chapter, recommender systems *typically* need an index
    of similarity between users and user-item preferences to identify similar users
    and find ratings (preferences) of unrated items.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入是从神经网络中离散输入变量的表示（向量）学习到的连续数字的低维表示（向量）。如本章前面所述，推荐系统*通常*需要一个用户和用户-物品偏好的相似度索引，以识别相似用户并找到未评分物品的评分（偏好）。
- en: However, unlike traditional collaborative filtering approaches that use generalized
    matrix factorization methods to produce user-item affinity vectors, neural networks
    can store important information about user-item affinity in a latent (hidden)
    space using distributed, low-dimensional representational (embeddings).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，与使用广义矩阵分解方法生成用户-物品亲和向量的传统协同过滤方法不同，神经网络可以通过使用分布式、低维表示（嵌入）在潜在（隐藏）空间中存储关于用户-物品亲和的重要信息。
- en: 'Accordingly, as long as we have representations (embeddings) of users and items
    (games) accessible within the same latent space, we can determine the mutual importance
    of the relationship between users and items (games) using a dot product function.
    Presuming user and item vectors have already been normalized, this is effectively
    the same as using **cosine similarity**, cos(Θ), as a distance metric, where A[i]
    and B[i] are components of vector A and B, respectively:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，只要我们在同一个潜在空间中拥有用户和物品（游戏）的表示（嵌入），就可以使用点积函数确定用户和物品（游戏）之间关系的相互重要性。假设用户和物品向量已经被规范化，这实际上等同于使用**余弦相似度**，cos(Θ)，作为距离度量，其中A[i]和B[i]分别是向量A和B的分量：
- en: '![](img/1c38318b-5925-4998-a1ea-ea83007eb433.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1c38318b-5925-4998-a1ea-ea83007eb433.png)'
- en: By creating neural network embeddings for users and items, we can decrease the
    amount of input data required for some learning activation functions, which is
    especially helpful with the data sparsity conditions typically encountered with
    user-item data in CF systems. In the next section, we will outline how to build,
    compile, and train a neural recommender system.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 通过为用户和物品创建神经网络嵌入，我们可以减少某些学习激活函数所需的输入数据量，这在协同过滤系统中遇到的典型用户-物品数据稀疏条件下尤为有用。在下一部分，我们将概述如何构建、编译和训练一个神经推荐系统。
- en: Building and training a neural recommender system
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建和训练神经推荐系统
- en: 'We are now going to build, compile, and train our model using our user-item
    ratings data. Specifically, we will use Keras to construct a customized neural
    network with embedded layers (one for users and one for items) and a lambda function
    that computes the dot product to build a working prototype of a neural network-based
    recommender system:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用我们的用户-物品评分数据来构建、编译和训练我们的模型。具体来说，我们将使用Keras构建一个定制的神经网络，具有嵌入层（一个用于用户，一个用于物品），并使用一个lambda函数计算点积来构建一个基于神经网络的推荐系统的工作原型：
- en: 'Let''s get started using the following code:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们通过以下代码开始：
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In the preceding code, we defined a custom model with user and item embeddings
    using the `keras_model_custom` function. You will notice that the input size of
    each embedding layer is initialized to the size of the input data (`n_users` and
    `n_items`, respectively).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用`keras_model_custom`函数定义了一个带有用户和物品嵌入的自定义模型。您会注意到，每个嵌入层的输入大小被初始化为输入数据的大小（分别为`n_users`和`n_items`）。
- en: 'In the following code, we define the size of the embedding parameter (`embedding_dim`)
    and define the architecture of our neural collaborative filtering model and vector
    representations (embeddings) to predict user ratings:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下代码中，我们定义了嵌入参数的大小（`embedding_dim`），并定义了我们神经协同过滤模型的架构和向量表示（嵌入），以预测用户评分：
- en: '[PRE19]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, let''s compile our model:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们编译我们的模型：
- en: '[PRE20]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Next, let''s train our model with the following code:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们使用以下代码训练我们的模型：
- en: '[PRE21]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This results in the following output:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/3c5f7a78-aca3-4c1e-beaf-468f314d3df9.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c5f7a78-aca3-4c1e-beaf-468f314d3df9.png)'
- en: 'Now, let''s inspect the baseline architecture of our model for reference:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们查看我们模型的基础架构以供参考：
- en: '[PRE22]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Here is a printout of our model''s architecture:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们模型架构的打印输出：
- en: '![](img/856206c9-0157-49b2-a53a-97e0561b7592.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](img/856206c9-0157-49b2-a53a-97e0561b7592.png)'
- en: In the following section, we will evaluate the model results, tune parameters,
    and make some iterative adjustments to improve performance in terms of loss metrics.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将评估模型结果，调整参数，并进行一些迭代调整，以在损失度量方面改善性能。
- en: Evaluating results and tuning hyperparameters
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 评估结果并调整超参数
- en: 'Building a recommender system, evaluating its performance, and tuning the hyperparameters
    is a highly iterative process. Ultimately, the goal is to maximize the model''s
    performance and results. Now that we have built and trained our baseline model,
    we can monitor and evaluate its performance during the training process using
    the following code:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 构建推荐系统、评估其性能并调整超参数是一个高度迭代的过程。最终目标是最大化模型的性能和结果。现在我们已经构建并训练了基准模型，可以通过以下代码在训练过程中监控和评估其性能：
- en: '[PRE23]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This results in the following model performance output:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下模型性能输出：
- en: '![](img/8b359981-0508-44fd-beb9-0b47e5e4f604.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8b359981-0508-44fd-beb9-0b47e5e4f604.png)'
- en: In the following sections, we will experiment with tuning model parameters to
    improve its performance.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将尝试调整模型参数，以提高其性能。
- en: Hyperparameter tuning
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超参数调整
- en: 'Let''s try changing the `embedding_dim` hyperparameter to `32` and the `batch_size` hyperparameter
    to `50` to see if we get improved results:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试将`embedding_dim`超参数更改为`32`，并将`batch_size`超参数更改为`50`，以查看是否能获得更好的结果：
- en: '[PRE24]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Here is a printout of the model''s architecture:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是模型架构的打印输出：
- en: '![](img/8574203f-50c1-4e3e-b135-ecea2d9bc01d.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8574203f-50c1-4e3e-b135-ecea2d9bc01d.png)'
- en: 'Now, we will plot the results as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将绘制结果，如下所示：
- en: '[PRE25]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This results in the following output:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/d9108ec2-4d64-43f3-be24-5603fd8b6936.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d9108ec2-4d64-43f3-be24-5603fd8b6936.png)'
- en: Unfortunately, these model performance results do not look significantly different
    than our baseline model, so let's explore some additional model configurations.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这些模型性能结果与我们的基准模型没有显著区别，因此我们需要探索一些额外的模型配置。
- en: Adding dropout layers
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加丢弃层
- en: 'In the following code, we will add dropout layers and encourage you to experiment
    with different dropout rates to see what empirically leads to optimal results:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码中，我们将添加丢弃层，并鼓励您尝试不同的丢弃率，以观察哪些配置在经验上能带来最佳结果：
- en: '[PRE26]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'In the preceding code, we added dropout layers using `layer_dropout()`, which
    adds some complexity to our preliminary model. In the following code, we define,
    compile, and train our custom model with dropout layers:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用`layer_dropout()`添加了丢弃层，这增加了我们初步模型的复杂性。在以下代码中，我们定义、编译并训练我们自定义的带有丢弃层的模型：
- en: '[PRE27]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This results in the following output:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下输出：
- en: '![](img/69700d96-0c27-40f1-8a41-5e98765e010e.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![](img/69700d96-0c27-40f1-8a41-5e98765e010e.png)'
- en: 'Now, we print out a summary of our model, as follows:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将输出模型的摘要，如下所示：
- en: '[PRE28]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Here''s a summary of the model architecture:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这是模型架构的摘要：
- en: '![](img/cc77c7cb-1790-4300-b455-8cc778bf2d14.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cc77c7cb-1790-4300-b455-8cc778bf2d14.png)'
- en: 'Now, we will plot the results, as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将绘制结果，如下所示：
- en: '[PRE29]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This results in the following model performance output:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生以下模型性能输出：
- en: '![](img/f87a7148-3617-4da2-899d-65aed9c043e4.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f87a7148-3617-4da2-899d-65aed9c043e4.png)'
- en: While we added dropout layers, the observed model improvements are minimal.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们添加了丢弃层，但观察到的模型改进非常有限。
- en: Let's revisit our underlying assumptions and try another approach.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新审视我们的基本假设并尝试另一种方法。
- en: Adjusting for user-item bias
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调整用户-项目偏差
- en: It is important to recognize that some users, in reality, may interact with
    items (games) differently than other users in terms of gaming frequency and affinity
    by proxy. This discrepancy, in turn, could potentially translate to different
    implicit ratings based on the user-item interaction (hours of gameplay) data available
    for this particular analysis.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要认识到，实际上，一些用户与项目（游戏）的互动可能与其他用户在游戏频率和偏好上有所不同。这个差异可能会导致根据用户与项目的互动（游戏时间）数据，推导出不同的隐式评分，这些数据是本分析中可用的。
- en: 'Based on our previous findings, we will now modify the model to account for
    user and item biases by including embeddings for average users and items (games)
    using the following code:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们之前的发现，我们将修改模型，通过为平均用户和项目（游戏）包含嵌入层来考虑用户和项目偏差，使用以下代码：
- en: '[PRE30]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'In the preceding code, we create a custom model with user and item embeddings
    (`user_embedding` and `item_embedding`) and embeddings for user bias and item
    bias (`user_bias` and `item_bias`). In the following code, we add dropout layers
    for both users and items and encourage you to experiment with different dropout
    rates for optimal results:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，我们创建了一个自定义模型，包含用户和物品的嵌入（`user_embedding`和`item_embedding`），以及用户偏差和物品偏差的嵌入（`user_bias`和`item_bias`）。在下面的代码中，我们为用户和物品添加了dropout层，并鼓励你尝试不同的dropout率，以获得最佳结果：
- en: '[PRE31]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Next, let''s define, compile, and train our modified neural network model:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们定义、编译并训练我们修改后的神经网络模型：
- en: '[PRE32]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'This results in the following output:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下输出：
- en: '![](img/ff39e817-e0be-4a77-95ba-624dcecb1ffd.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ff39e817-e0be-4a77-95ba-624dcecb1ffd.png)'
- en: 'Now, we will print out the summary:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将打印出总结：
- en: '[PRE33]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'By adding these additional layers of embeddings and tuning the hyperparameters,
    we have nearly doubled the total number of trainable parameters from our original
    baseline neural network, as reflected in the following model summary:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 通过添加这些额外的嵌入层并调整超参数，我们几乎将训练参数的总数量翻倍，具体体现在以下的模型总结中：
- en: '![](img/43bb18d7-548f-4fd3-92b3-44883005f12f.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](img/43bb18d7-548f-4fd3-92b3-44883005f12f.png)'
- en: 'Finally, we plot the results of the model as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们绘制了模型的结果如下：
- en: '[PRE34]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'This results in the following output:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这将产生如下输出：
- en: '![](img/d87d93c2-a800-44cc-96ee-774810eec733.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d87d93c2-a800-44cc-96ee-774810eec733.png)'
- en: Through a succession of iterative configurations and empirically guided adjustments,
    we have improved overfitting relative to our previous models and achieved a notable
    RMSE below 0.1 on our validation dataset. With additional hyperparameter tuning
    and dropout layer rate configurations, we might be able to further improve the
    performance of this model. Future recommendations to build on this model would
    be to acquire and implement explicit rating data, as well as to experiment with
    additional contextual information and user demographic data to better understand
    the relationships and factors associated with user-item interactions.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一系列迭代配置和经验指导的调整，我们改善了相对于先前模型的过拟合问题，并在验证数据集上达到了显著低于0.1的RMSE。通过进一步调优超参数和dropout层的比例配置，我们可能会进一步提升模型的性能。未来的推荐是基于此模型继续扩展，获取并实施显式评分数据，此外，尝试更多的上下文信息和用户人口统计数据，以更好地理解用户与物品交互之间的关系和相关因素。
- en: Summary
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned how to use the custom Keras API and embeddings
    to construct a deep neural network recommender system. We briefly introduced collaborative
    filtering concepts and saw how to prepare data for building a custom neural network.
    During this iterative process, we created user and item embeddings, trained a
    deep neural network using embedded layers, tuned hyperparameters, and evaluated
    results using common performance metrics. In the next chapter, you will continue
    applying neural network approaches to other domains, such as natural language
    processing.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你学习了如何使用自定义的Keras API和嵌入（embeddings）来构建一个深度神经网络推荐系统。我们简要介绍了协同过滤的概念，并展示了如何准备数据以构建自定义神经网络。在这一迭代过程中，我们创建了用户和物品的嵌入，使用嵌入层训练了深度神经网络，调优了超参数，并使用常见的性能指标评估了结果。在下一章中，你将继续将神经网络方法应用于其他领域，例如自然语言处理。
